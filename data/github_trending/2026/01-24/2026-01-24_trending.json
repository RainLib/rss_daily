{
  "date": "2026-01-24",
  "name": "trending",
  "repositories": [
    {
      "id": 274495425,
      "name": "remotion",
      "full_name": "remotion-dev/remotion",
      "description": "üé•      Make videos programmatically with React",
      "html_url": "https://github.com/remotion-dev/remotion",
      "stars": 28484,
      "forks": 1688,
      "language": "TypeScript",
      "topics": [
        "javascript",
        "react",
        "video"
      ],
      "created_at": "2020-06-23T19:49:10Z",
      "updated_at": "2026-01-24T02:05:50Z",
      "pushed_at": "2026-01-23T19:04:58Z",
      "open_issues": 89,
      "owner": {
        "login": "remotion-dev",
        "avatar_url": "https://avatars.githubusercontent.com/u/85344006?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://github.com/remotion-dev/logo\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/remotion-dev/logo/raw/main/animated-logo-banner-dark.apng\">\n      <img alt=\"Animated Remotion Logo\" src=\"https://github.com/remotion-dev/logo/raw/main/animated-logo-banner-light.gif\">\n    </picture>\n  </a>\n</p>\n\n[![Discord Shield](https://img.shields.io/discord/809501355504959528?color=000000&label=Discord&logo=fdgssdf)](https://remotion.dev/discord)\n[![NPM Version](https://img.shields.io/npm/v/remotion.svg?style=flat&color=black)](https://www.npmjs.org/package/remotion)\n[![NPM Downloads](https://img.shields.io/npm/dm/remotion.svg?style=flat&color=black&label=Downloads)](https://npmcharts.com/compare/remotion?minimal=true)\n[![Open Bounties](https://img.shields.io/endpoint?url=https%3A%2F%2Fconsole.algora.io%2Fapi%2Fshields%2Fremotion%2Fbounties%3Fstatus%3Dopen&style=flat&color=black&labelColor=grey&label=Open+Bounties)](https://github.com/remotion-dev/remotion/issues?q=is%3Aopen+label%3A%22%F0%9F%92%8E+Bounty%22+sort%3Aupdated-desc)\n<a href=\"https://twitter.com/remotion\"><img src=\"https://img.shields.io/twitter/follow/remotion?label=Twitter&color=black\" alt=\"Twitter\"></a>\n\nRemotion is a framework for **creating videos programmatically using React.**\n\n## Why create videos in React?\n\n- **Leverage web technologies**: Use all of CSS, Canvas, SVG, WebGL, etc.\n- **Leverage programming**: Use variables, functions, APIs, math and algorithms to create new effects\n- **Leverage React**: Reusable components, Powerful composition, Fast Refresh, Package ecosystem\n\n## Created with Remotion\n\n<table>\n<tr>\n<td align=\"center\">\n<img style=\"width: 290px\" src=\"https://pub-646d808d9cb240cea53bedc76dd3cd0c.r2.dev/fireship-quick.gif\" />\n<p>\"This video was made with code\" <em>- Fireship</em> <a href=\"https://youtu.be/deg8bOoziaE\">Watch</a> ‚Ä¢ <a href=\"https://github.com/wcandillon/remotion-fireship\">Source</a></p>\n</td>\n<td align=\"center\">\n<img style=\"width: 240px\" src=\"https://pub-646d808d9cb240cea53bedc76dd3cd0c.r2.dev/unwrapped-2023.gif\" />\n<p>GitHub Unwrapped - Personalized Year in Review <a href=\"https://www.githubunwrapped.com\">Try</a> ‚Ä¢ <a href=\"https://github.com/remotion-dev/github-unwrapped\">Source</a></p>\n</td>\n<td align=\"center\">\n<em>View more in the <a href=\"https://remotion.dev/showcase\">Remotion Showcase</a>!</em>\n</td>\n</tr>\n</table>\n\n## Get started\n\nIf you already have Node.JS installed, type\n\n```console\nnpx create-video@latest\n```\n\nto get started. Otherwise, read the [installation page](https://www.remotion.dev/docs/) in the documentation.\n\n## Documentation\n\nDocumentation: [**remotion.dev/docs**](https://www.remotion.dev/docs)  \nAPI Reference: [**remotion.dev/api**](https://www.remotion.dev/api)\n\n## License\n\nBe aware of that Remotion has a special license and requires obtaining a company license in some cases. Read the [LICENSE](LICENSE.md) page for more information.\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](CONTRIBUTING.md) to learn about contributing to this project.\n",
      "stars_today": 1618
    },
    {
      "id": 815634288,
      "name": "tambo",
      "full_name": "tambo-ai/tambo",
      "description": "Generative UI SDK for React",
      "html_url": "https://github.com/tambo-ai/tambo",
      "stars": 4664,
      "forks": 230,
      "language": "TypeScript",
      "topics": [
        "agent",
        "agents",
        "ai",
        "assistant",
        "assistant-chat-bots",
        "generative-ui",
        "js",
        "react",
        "reactjs",
        "ui",
        "ui-components"
      ],
      "created_at": "2024-06-15T17:11:37Z",
      "updated_at": "2026-01-24T02:03:21Z",
      "pushed_at": "2026-01-24T01:36:07Z",
      "open_issues": 53,
      "owner": {
        "login": "tambo-ai",
        "avatar_url": "https://avatars.githubusercontent.com/u/187570293?v=4"
      },
      "readme": "<div align=\"center\">\n  <img src=\"assets/octo-white-background-rounded.png\" width=\"150\">\n  <h1>Tambo AI</h1>\n  <h3>Generative UI for React</h3>\n  <p>Build apps that adapt to your users.</p>\n</div>\n\n<p align=\"center\">\n  <a href=\"https://www.npmjs.com/package/@tambo-ai/react\"><img src=\"https://img.shields.io/npm/v/%40tambo-ai%2Freact?logo=npm\" alt=\"npm version\" /></a>\n  <a href=\"https://github.com/tambo-ai/tambo/blob/main/LICENSE\"><img src=\"https://img.shields.io/github/license/tambo-ai/tambo\" alt=\"License\" /></a>\n  <a href=\"https://github.com/tambo-ai/tambo/commits/main\"><img src=\"https://img.shields.io/github/last-commit/tambo-ai/tambo\" alt=\"Last Commit\" /></a>\n  <a href=\"https://discord.gg/dJNvPEHth6\"><img src=\"https://img.shields.io/discord/1251581895414911016?color=7289da&label=discord\" alt=\"Discord\"></a>\n  <a href=\"https://github.com/tambo-ai/tambo\"><img src=\"https://img.shields.io/github/stars/tambo-ai/tambo\" alt=\"GitHub stars\" /></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://trendshift.io/repositories/15734\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://trendshift.io/api/badge/repositories/15734\" alt=\"tambo-ai/tambo | Trendshift\" width=\"250\" height=\"55\" /></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://docs.tambo.co\">Documentation</a> ‚Ä¢\n  <a href=\"https://discord.gg/dJNvPEHth6\">Discord</a>\n</p>\n\n---\n\n## What is Tambo?\n\nTambo is a generative UI SDK for React. Register your components, and the AI decides which ones to render based on natural language conversations.\n\nhttps://github.com/user-attachments/assets/8381d607-b878-4823-8b24-ecb8053bef23\n\n## Why We Built This\n\nMost software is built around a one-size-fits-all mental model that doesn't fit every user.\n\n**Users shouldn't have to learn your app.** Generative UI shows the right components based on what someone is trying to do. First-time users and power users see different things.\n\n**Users shouldn't have to click through your workflows.** \"Show me sales from last quarter grouped by region\" should just work. The AI translates what users want into the right interface.\n\n```tsx\nconst components: TamboComponent[] = [{\n  name: \"Graph\",\n  description: \"Displays data as charts\",\n  component: Graph,\n  propsSchema: z.object({ data: z.array(...), type: z.enum([\"line\", \"bar\", \"pie\"]) })\n}];\n```\n\n## Get Started\n\n```bash\nnpx tambo create-app my-tambo-app\ncd my-tambo-app\nnpx tambo init      # choose cloud or self-hosted\nnpm run dev\n```\n\n**Tambo Cloud** is a free hosted backend. **Self-hosted** runs on your own infrastructure.\n\nCheck out the [pre-built component library](https://ui.tambo.co) for ready-made primitives, or fork a template:\n\n| Template                                                                 | Description                                       |\n| ------------------------------------------------------------------------ | ------------------------------------------------- |\n| [AI Chat with Generative UI](https://github.com/tambo-ai/tambo-template) | Chat interface with dynamic component generation  |\n| [AI Analytics Dashboard](https://github.com/tambo-ai/analytics-template) | Analytics dashboard with AI-powered visualization |\n\nhttps://github.com/user-attachments/assets/6cbc103b-9cc7-40f5-9746-12e04c976dff\n\n## How It Works\n\nTambo supports two kinds of components.\n\n**Generative components** render once in response to a message. Charts, summaries, data visualizations.\n\nhttps://github.com/user-attachments/assets/3bd340e7-e226-4151-ae40-aab9b3660d8b\n\n**Interactable components** persist and update as users refine requests. Shopping carts, spreadsheets, task boards.\n\nhttps://github.com/user-attachments/assets/12d957cd-97f1-488e-911f-0ff900ef4062\n\n### Registering Components\n\nTell the AI which components it can use. Zod schemas define the props.\n\n```tsx\n// Generative: AI creates on-demand\nconst components: TamboComponent[] = [\n  {\n    name: \"Graph\",\n    description: \"Displays data as charts using Recharts library\",\n    component: Graph,\n    propsSchema: z.object({\n      data: z.array(z.object({ name: z.string(), value: z.number() })),\n      type: z.enum([\"line\", \"bar\", \"pie\"]),\n    }),\n  },\n];\n\n// Interactable: persists and updates by ID\nconst InteractableNote = withInteractable(Note, {\n  componentName: \"Note\",\n  description: \"A note supporting title, content, and color modifications\",\n  propsSchema: z.object({\n    title: z.string(),\n    content: z.string(),\n    color: z.enum([\"white\", \"yellow\", \"blue\", \"green\"]).optional(),\n  }),\n});\n```\n\nDocs: [generative components](https://docs.tambo.co/concepts/components/defining-tambo-components), [interactable components](https://docs.tambo.co/concepts/components/interactable-components)\n\n### The Provider\n\nWrap your app with `TamboProvider`.\n\n```tsx\n<TamboProvider\n  apiKey={process.env.NEXT_PUBLIC_TAMBO_API_KEY!}\n  components={components}\n>\n  <Chat />\n  <InteractableNote id=\"note-1\" title=\"My Note\" content=\"Start writing...\" />\n</TamboProvider>\n```\n\nFor apps with signed-in users, pass a per-user `userToken` (OAuth access token) to `TamboProvider` to enable per-user auth and connect Tambo to your app's end-user identity. See [User Authentication](https://docs.tambo.co/concepts/user-authentication) for details.\n\nDocs: [provider options](https://docs.tambo.co/api-reference/tambo-provider)\n\n### Hooks\n\nSend messages with `useTamboThreadInput`. `useTamboThread` handles streaming, including props for generated components and tool calls.\n\n```tsx\nconst { value, setValue, submit, isPending } = useTamboThreadInput();\n\n<input value={value} onChange={(e) => setValue(e.target.value)} />\n<button onClick={() => submit()} disabled={isPending}>Send</button>\n```\n\n```tsx\nconst { thread } = useTamboThread();\n\n{\n  thread.messages.map((message) => (\n    <div key={message.id}>\n      {Array.isArray(message.content) ? (\n        message.content.map((part, i) =>\n          part.type === \"text\" ? <p key={i}>{part.text}</p> : null,\n        )\n      ) : (\n        <p>{String(message.content)}</p>\n      )}\n      {message.renderedComponent}\n    </div>\n  ));\n}\n```\n\nTrack streaming status if you want progressive loading:\n\n```tsx\nconst { streamStatus, propStatus } = useTamboStreamStatus();\n\nif (!streamStatus.isSuccess) return <Spinner />;\n{\n  propStatus[\"title\"]?.isSuccess && <h3>{title}</h3>;\n}\n```\n\nDocs: [threads and messages](https://docs.tambo.co/concepts/message-threads), [streaming status](https://docs.tambo.co/concepts/streaming/component-streaming-status)\n\n<p align=\"center\">\n  <a href=\"https://docs.tambo.co/getting-started/quickstart\">Full tutorial</a>\n</p>\n\n## Features\n\n### MCP Integrations\n\nConnect to Linear, Slack, databases, or your own MCP servers. Tambo supports the full MCP protocol: tools, prompts, elicitations, and sampling.\n\n```tsx\nimport { MCPTransport } from \"@tambo-ai/react/mcp\";\n\nconst mcpServers = [\n  {\n    name: \"filesystem\",\n    url: \"http://localhost:8261/mcp\",\n    transport: MCPTransport.HTTP,\n  },\n];\n\n<TamboProvider components={components} mcpServers={mcpServers}>\n  <App />\n</TamboProvider>;\n```\n\nhttps://github.com/user-attachments/assets/c7a13915-8fed-4758-be1b-30a60fad0cda\n\nSupports the full MCP protocol: tools, prompts, elicitations, and sampling.\n\nDocs: [MCP integration](https://docs.tambo.co/concepts/model-context-protocol)\n\n### Local Tools\n\nSometimes you need functions that run in the browser. DOM manipulation, authenticated fetches, accessing React state. Define them as tools and the AI can call them.\n\n```tsx\nconst tools: TamboTool[] = [\n  {\n    name: \"getWeather\",\n    description: \"Fetches weather for a location\",\n    tool: async (params: { location: string }) =>\n      fetch(`/api/weather?q=${encodeURIComponent(params.location)}`).then((r) =>\n        r.json(),\n      ),\n    inputSchema: z.object({\n      location: z.string(),\n    }),\n    outputSchema: z.object({\n      temperature: z.number(),\n      condition: z.string(),\n      location: z.string(),\n    }),\n  },\n];\n\n<TamboProvider tools={tools} components={components}>\n  <App />\n</TamboProvider>;\n```\n\nDocs: [local tools](https://docs.tambo.co/concepts/tools/adding-tools)\n\n### Context, Auth, and Suggestions\n\n**Additional context** lets you pass metadata to give the AI better responses. User state, app settings, current page. **User authentication** passes tokens from your auth provider. **Suggestions** generates prompts users can click based on what they're doing.\n\n```tsx\n<TamboProvider\n  userToken={userToken}\n  contextHelpers={{\n    selectedItems: () => ({\n      key: \"selectedItems\",\n      value: selectedItems.map((i) => i.name).join(\", \"),\n    }),\n    currentPage: () => ({ key: \"page\", value: window.location.pathname }),\n  }}\n/>\n```\n\n```tsx\nconst { suggestions, accept } = useTamboSuggestions({ maxSuggestions: 3 });\n\nsuggestions.map((s) => (\n  <button key={s.id} onClick={() => accept(s)}>\n    {s.title}\n  </button>\n));\n```\n\nDocs: [additional context](https://docs.tambo.co/concepts/additional-context), [user authentication](https://docs.tambo.co/concepts/user-authentication), [suggestions](https://docs.tambo.co/concepts/suggestions)\n\n### Supported LLM Providers\n\nOpenAI, Anthropic, Cerebras, Google Gemini, Mistral, and any OpenAI-compatible provider. [Full list](https://docs.tambo.co/models). Missing one? [Let us know](https://github.com/tambo-ai/tambo/issues).\n\n## How Tambo Compares\n\n| Feature                            | Tambo                                 | Vercel AI SDK                    | CopilotKit                       | Assistant UI         |\n| ---------------------------------- | ------------------------------------- | -------------------------------- | -------------------------------- | -------------------- |\n| **Component selection**            | AI decides which components to render | Manual tool-to-component mapping | Via agent frameworks (LangGraph) | Chat-focused tool UI |\n| **MCP integration**                | Built-in                              | Experimental (v4.2+)             | Recently added                   | Requires AI SDK v5   |\n| **Persistent stateful components** | Yes                                   | No                               | Shared state patterns            | No                   |\n| **Client-side tool execution**     | Declarative, automatic                | Manual via onToolCall            | Agent-side only                  | No                   |\n| **Self-hostable**                  | MIT (SDK + backend)                   | Apache 2.0 (SDK only)            | MIT                              | MIT                  |\n| **Hosted option**                  | Tambo Cloud                           | No                               | CopilotKit Cloud                 | Assistant Cloud      |\n| **Best for**                       | Full app UI control                   | Streaming and tool abstractions  | Multi-agent workflows            | Chat interfaces      |\n\n<p align=\"center\">\n  <a href=\"https://docs.tambo.co\">Full documentation</a>\n</p>\n\n---\n\n## Pricing\n\n### Self-Hosted\n\nFree forever. MIT licensed. 5-minute Docker setup.\n\n```bash\nnpx tambo init\n# Select \"Self-hosted\"\n```\n\n### Tambo Cloud\n\nFree tier, then pay as you grow.\n\n- **Free**: 10,000 messages/month\n- **Growth**: $25/mo for 200k messages + email support\n- **Enterprise**: Custom volume, SLA, SOC 2, HIPAA\n\n[Pricing details](https://tambo.co/pricing)\n\n## Repository Structure\n\nThis Turborepo hosts the React SDK ecosystem and Tambo Cloud platform.\n\n`apps/` has the web dashboard (Next.js), the API (NestJS), and MCP services.\n\n`packages/` has shared code. Database schema (Drizzle), LLM helpers, pure utilities, and tooling configs.\n\nThe root holds framework packages: `react-sdk/`, `cli/`, `showcase/`, `docs/`, `create-tambo-app/`.\n\n## Development\n\nYou'll need Node.js 22+, npm 11+, and optionally Docker.\n\n```bash\ngit clone https://github.com/tambo-ai/tambo.git\ncd tambo\nnpm install\nnpm run dev        # apps/web + apps/api\n```\n\nUseful commands:\n\n```bash\nnpm run build        # Build everything\nnpm run lint         # Lint (lint:fix to autofix)\nnpm run check-types  # Type check\nnpm test             # Run tests\n```\n\nDatabase (requires Docker):\n\n```bash\nnpm run db:generate  # Generate migrations\nnpm run db:migrate   # Apply migrations\nnpm run db:studio    # Open Drizzle Studio\n```\n\nDocker workflow lives in `scripts/cloud/`. See [README.DOCKER.md](./README.DOCKER.md) for details.\n\n[Contributing Guide](./CONTRIBUTING.md)\n\n## Community\n\n[Discord](https://discord.gg/dJNvPEHth6) for help and discussion. [GitHub](https://github.com/tambo-ai/tambo) to contribute. [@tambo_ai](https://twitter.com/tambo_ai) for updates.\n\n### Built with Tambo\n\n| Project                                                                                           | Preview                                                           | Description                                                                                             | Links                                                                                      |\n| ------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------ |\n| **[db-thing](https://db-thing.vercel.app)** by [@akinloluwami](https://github.com/akinloluwami)   | <img src=\"community/db-thing.png\" alt=\"db-thing\" width=\"300\">     | Database design through conversation. Create schemas, generate ERDs, get optimization tips, export SQL. | [GitHub](https://github.com/akinloluwami/db-thing) ‚Ä¢ [Demo](https://db-thing.vercel.app)   |\n| **[CheatSheet](https://cheatsheet.tambo.co)** by [@michaelmagan](https://github.com/michaelmagan) | <img src=\"community/cheatsheet.png\" alt=\"CheatSheet\" width=\"300\"> | Spreadsheet editor with natural language. Edit cells, create charts, connect external data via MCP.     | [GitHub](https://github.com/michaelmagan/cheatsheet) ‚Ä¢ [Demo](https://cheatsheet.tambo.co) |\n\nBuilt something? [Open a PR](https://github.com/tambo-ai/tambo/pulls) or [share it in Discord](https://discord.gg/dJNvPEHth6).\n\n---\n\n## License\n\nUnless otherwise noted in a workspace (app or package), code in this repo is\nlicensed under MIT (see the root [LICENSE](LICENSE)).\n\nSome workspaces are licensed under Apache-2.0; see the accompanying `LICENSE`\nand `NOTICE` files in those workspaces.\n\n---\n\n<p align=\"center\">\n  <img src=\"assets/tambo-animation.gif\" alt=\"Tambo AI Animation\" width=\"800\">\n</p>\n\n---\n\n**For AI/LLM agents:** [docs.tambo.co/llms.txt](https://docs.tambo.co/llms.txt)\n",
      "stars_today": 853
    },
    {
      "id": 1081230042,
      "name": "VidBee",
      "full_name": "nexmoe/VidBee",
      "description": "Download videos from almost any website worldwide",
      "html_url": "https://github.com/nexmoe/VidBee",
      "stars": 5197,
      "forks": 358,
      "language": "TypeScript",
      "topics": [
        "downloader",
        "facebook",
        "tiktok",
        "twitter",
        "youtube"
      ],
      "created_at": "2025-10-22T13:43:42Z",
      "updated_at": "2026-01-24T02:04:26Z",
      "pushed_at": "2026-01-23T14:50:43Z",
      "open_issues": 32,
      "owner": {
        "login": "nexmoe",
        "avatar_url": "https://avatars.githubusercontent.com/u/16796652?v=4"
      },
      "readme": "<div align=\"center\">\n  <a href=\"https://github.com/nexmoe/VidBee\">\n    <img src=\"build/icon.png\" alt=\"Logo\" width=\"80\" height=\"80\">\n  </a>\n\n  <h3>VidBee</h3>\n  <p>\n    <a href=\"https://github.com/nexmoe/VidBee/stargazers\"><img src=\"https://img.shields.io/github/stars/nexmoe/VidBee?color=ffcb47&labelColor=black&logo=github&label=Stars\" /></a>\n    <a href=\"https://github.com/nexmoe/VidBee/graphs/contributors\"><img src=\"https://img.shields.io/github/contributors/nexmoe/VidBee?ogo=github&label=Contributors&labelColor=black\" /></a>\n    <a href=\"https://github.com/nexmoe/VidBee/releases\"><img src=\"https://img.shields.io/github/downloads/nexmoe/VidBee/total?color=369eff&labelColor=black&logo=github&label=Downloads\" /></a>\n    <a href=\"https://github.com/nexmoe/VidBee/releases/latest\"><img src=\"https://img.shields.io/github/v/release/nexmoe/VidBee?color=369eff&labelColor=black&logo=github&label=Latest%20Release\" /></a>\n    <a href=\"https://x.com/intent/follow?screen_name=nexmoex\"><img src=\"https://img.shields.io/badge/Follow-blue?color=1d9bf0&logo=x&labelColor=black\" /></a>\n    <a href=\"https://deepwiki.com/nexmoe/VidBee\"><img src=\"https://deepwiki.com/badge.svg\" alt=\"Ask DeepWiki\"></a>\n    <br />\n    <br />\n    <a href=\"https://github.com/nexmoe/VidBee/releases/latest\" target=\"_blank\"><img src=\"screenshots/main-interface.png\" alt=\"VidBee Desktop\" width=\"46%\"/></a>\n    <a href=\"https://github.com/nexmoe/VidBee/releases/latest\" target=\"_blank\"><img src=\"screenshots/download-queue.png\" alt=\"VidBee Download Queue\" width=\"46%\"/></a>\n    <br />\n    <br />\n  </p>\n</div>\n\nVidBee is a modern, open-source video downloader that lets you download videos and audios from 1000+ websites worldwide. Built with Electron and powered by yt-dlp, VidBee offers a clean, intuitive interface with powerful features for all your downloading needs, including RSS auto-download automation that automatically subscribes to feeds and downloads new videos from your favorite creators in the background.\n\n## üëãüèª Getting Started\n\nVidBee is currently under active development, and feedback is welcome for any [issue](https://github.com/nexmoe/VidBee/issues) encountered.\n\n[üì• Download VidBee](https://vidbee.org/download/) | [üìö Documentation](https://docs.vidbee.org)\n\n> [!IMPORTANT]\n>\n> **Star Us**, You will receive all release notifications from GitHub without any delay ~\n\n<a href=\"https://next.ossinsight.io/widgets/official/compose-last-28-days-stats?repo_id=1081230042\" target=\"_blank\" style=\"display: block\" align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://next.ossinsight.io/widgets/official/compose-last-28-days-stats/thumbnail.png?repo_id=1081230042&image_size=auto&color_scheme=dark\" width=\"655\" height=\"auto\">\n    <img alt=\"Performance Stats of nexmoe/VidBee - Last 28 days\" src=\"https://next.ossinsight.io/widgets/official/compose-last-28-days-stats/thumbnail.png?repo_id=1081230042&image_size=auto&color_scheme=light\" width=\"655\" height=\"auto\">\n  </picture>\n</a>\n\n<!-- Made with [OSS Insight](https://ossinsight.io/) -->\n\n## ‚ú® Features\n\n### üåç Global Video Download Support\n\nDownload videos from almost any website worldwide through the powerful yt-dlp engine. Support for 1000+ sites including YouTube, TikTok, Instagram, Twitter, and many more.\n\n![VidBee Main Interface](screenshots/main-interface.png)\n\n### üé® Best-in-class UI Experience\n\nModern, clean interface with intuitive operations. One-click pause/resume/retry, real-time progress tracking, and comprehensive download queue management.\n\n![VidBee Download Queue](screenshots/download-queue.png)\n\n### üì° RSS Auto Download\n\nAutomatically subscribe to RSS feeds and auto-download new videos in the background from your favorite creators across YouTube, TikTok, and more. Set up RSS subscriptions once, and VidBee will automatically download new uploads without manual intervention, perfect for keeping up with your favorite channels and creators.\n\n## üåê Supported Sites\n\nVidBee supports 1000+ video and audio platforms through yt-dlp. For the complete list of supported sites, visit [https://vidbee.org/supported-sites/](https://vidbee.org/supported-sites/)\n\n## ü§ù Contributing\n\nYou are welcome to join the open source community to build together. For more details, check out:\n\n- [Contributing Guide](./CONTRIBUTING.md)\n- [DeepWiki Documentation](https://deepwiki.com/nexmoe/VidBee)\n\n## üìÑ License\n\nThis project is distributed under the MIT License. See [`LICENSE`](LICENSE) for details.\n\n## üôè Thanks\n\n- [yt-dlp](https://github.com/yt-dlp/yt-dlp) - The powerful video downloader engine\n- [FFmpeg](https://ffmpeg.org/) - The multimedia framework for video and audio processing\n- [Electron](https://www.electronjs.org/) - Build cross-platform desktop apps\n- [React](https://react.dev/) - The UI library\n- [Vite](https://vitejs.dev/) - Next generation frontend tooling\n- [Tailwind CSS](https://tailwindcss.com/) - Utility-first CSS framework\n- [shadcn/ui](https://ui.shadcn.com/) - Beautifully designed components\n",
      "stars_today": 845
    },
    {
      "id": 1076426995,
      "name": "dexter",
      "full_name": "virattt/dexter",
      "description": "An autonomous agent for deep financial research",
      "html_url": "https://github.com/virattt/dexter",
      "stars": 8753,
      "forks": 1073,
      "language": "TypeScript",
      "topics": [],
      "created_at": "2025-10-14T21:02:00Z",
      "updated_at": "2026-01-24T01:57:07Z",
      "pushed_at": "2026-01-23T23:07:34Z",
      "open_issues": 31,
      "owner": {
        "login": "virattt",
        "avatar_url": "https://avatars.githubusercontent.com/u/901795?v=4"
      },
      "readme": "# Dexter ü§ñ\n\nDexter is an autonomous financial research agent that thinks, plans, and learns as it works. It performs analysis using task planning, self-reflection, and real-time market data. Think Claude Code, but built specifically for financial research.\n\n\n<img width=\"1098\" height=\"659\" alt=\"Screenshot 2026-01-21 at 5 25 10‚ÄØPM\" src=\"https://github.com/user-attachments/assets/3bcc3a7f-b68a-4f5e-8735-9d22196ff76e\" />\n\n\n## Overview\n\nDexter takes complex financial questions and turns them into clear, step-by-step research plans. It runs those tasks using live market data, checks its own work, and refines the results until it has a confident, data-backed answer.  \n\n**Key Capabilities:**\n- **Intelligent Task Planning**: Automatically decomposes complex queries into structured research steps\n- **Autonomous Execution**: Selects and executes the right tools to gather financial data\n- **Self-Validation**: Checks its own work and iterates until tasks are complete\n- **Real-Time Financial Data**: Access to income statements, balance sheets, and cash flow statements\n- **Safety Features**: Built-in loop detection and step limits to prevent runaway execution\n\n[![Twitter Follow](https://img.shields.io/twitter/follow/virattt?style=social)](https://twitter.com/virattt)\n\n<img width=\"875\" height=\"558\" alt=\"Screenshot 2026-01-21 at 5 22 19‚ÄØPM\" src=\"https://github.com/user-attachments/assets/72d28363-69ea-4c74-a297-dfa60aa347f7\" />\n\n\n### Prerequisites\n\n- [Bun](https://bun.com) runtime (v1.0 or higher)\n- OpenAI API key (get [here](https://platform.openai.com/api-keys))\n- Financial Datasets API key (get [here](https://financialdatasets.ai))\n- Exa API key (get [here](https://exa.ai)) - optional, for web search (preferred)\n- Tavily API key (get [here](https://tavily.com)) - optional, fallback web search\n\n#### Installing Bun\n\nIf you don't have Bun installed, you can install it using curl:\n\n**macOS/Linux:**\n```bash\ncurl -fsSL https://bun.com/install | bash\n```\n\n**Windows:**\n```bash\npowershell -c \"irm bun.sh/install.ps1|iex\"\n```\n\nAfter installation, restart your terminal and verify Bun is installed:\n```bash\nbun --version\n```\n\n### Installing Dexter\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/virattt/dexter.git\ncd dexter\n```\n\n2. Install dependencies with Bun:\n```bash\nbun install\n```\n\n3. Set up your environment variables:\n```bash\n# Copy the example environment file (from parent directory)\ncp env.example .env\n\n# Edit .env and add your API keys (if using cloud providers)\n# OPENAI_API_KEY=your-openai-api-key\n# ANTHROPIC_API_KEY=your-anthropic-api-key\n# GOOGLE_API_KEY=your-google-api-key\n# XAI_API_KEY=your-xai-api-key\n\n# (Optional) If using Ollama locally\n# OLLAMA_BASE_URL=http://127.0.0.1:11434\n\n# Other required keys\n# FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key\n\n# Web Search (Exa preferred, Tavily fallback)\n# EXA_API_KEY=your-exa-api-key\n# TAVILY_API_KEY=your-tavily-api-key\n```\n\n### Usage\n\nRun Dexter in interactive mode:\n```bash\nbun start\n```\n\nOr with watch mode for development:\n```bash\nbun dev\n```\n\n## How to Contribute\n\n1. Fork the repository\n2. Create a feature branch\n3. Commit your changes\n4. Push to the branch\n5. Create a Pull Request\n\n**Important**: Please keep your pull requests small and focused.  This will make it easier to review and merge.\n\n\n## License\n\nThis project is licensed under the MIT License.\n\n",
      "stars_today": 552
    },
    {
      "id": 846698999,
      "name": "goose",
      "full_name": "block/goose",
      "description": "an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM",
      "html_url": "https://github.com/block/goose",
      "stars": 27610,
      "forks": 2493,
      "language": "Rust",
      "topics": [
        "mcp"
      ],
      "created_at": "2024-08-23T19:03:36Z",
      "updated_at": "2026-01-24T02:05:05Z",
      "pushed_at": "2026-01-24T01:44:35Z",
      "open_issues": 309,
      "owner": {
        "login": "block",
        "avatar_url": "https://avatars.githubusercontent.com/u/185116535?v=4"
      },
      "readme": "<div align=\"center\">\n\n# goose\n\n_a local, extensible, open source AI agent that automates engineering tasks_\n\n<p align=\"center\">\n  <a href=\"https://opensource.org/licenses/Apache-2.0\">\n    <img src=\"https://img.shields.io/badge/License-Apache_2.0-blue.svg\">\n  </a>\n  <a href=\"https://discord.gg/goose-oss\">\n    <img src=\"https://img.shields.io/discord/1287729918100246654?logo=discord&logoColor=white&label=Join+Us&color=blueviolet\" alt=\"Discord\">\n  </a>\n  <a href=\"https://github.com/block/goose/actions/workflows/ci.yml\">\n     <img src=\"https://img.shields.io/github/actions/workflow/status/block/goose/ci.yml?branch=main\" alt=\"CI\">\n  </a>\n</p>\n</div>\n\ngoose is your on-machine AI agent, capable of automating complex development tasks from start to finish. More than just code suggestions, goose can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows, and interact with external APIs - _autonomously_.\n\nWhether you're prototyping an idea, refining existing code, or managing intricate engineering pipelines, goose adapts to your workflow and executes tasks with precision.\n\nDesigned for maximum flexibility, goose works with any LLM and supports multi-model configuration to optimize performance and cost, seamlessly integrates with MCP servers, and is available as both a desktop app as well as CLI - making it the ultimate AI assistant for developers who want to move faster and focus on innovation.\n\n[![Watch the video](https://github.com/user-attachments/assets/ddc71240-3928-41b5-8210-626dfb28af7a)](https://youtu.be/D-DpDunrbpo)\n\n# Quick Links\n- [Quickstart](https://block.github.io/goose/docs/quickstart)\n- [Installation](https://block.github.io/goose/docs/getting-started/installation)\n- [Tutorials](https://block.github.io/goose/docs/category/tutorials)\n- [Documentation](https://block.github.io/goose/docs/category/getting-started)\n- [Responsible AI-Assisted Coding Guide](https://github.com/block/goose/blob/main/HOWTOAI.md)\n- [Governance](https://github.com/block/goose/blob/main/GOVERNANCE.md)\n\n## Need Help?\n- [Diagnostics & Reporting](https://block.github.io/goose/docs/troubleshooting/diagnostics-and-reporting)\n- [Known Issues](https://block.github.io/goose/docs/troubleshooting/known-issues)\n\n# a little goose humor ü¶¢\n\n> Why did the developer choose goose as their AI agent?\n> \n> Because it always helps them \"migrate\" their code to production! üöÄ\n\n# goose around with us  \n- [Discord](https://discord.gg/goose-oss)\n- [YouTube](https://www.youtube.com/@goose-oss)\n- [LinkedIn](https://www.linkedin.com/company/goose-oss)\n- [Twitter/X](https://x.com/goose_oss)\n- [Bluesky](https://bsky.app/profile/opensource.block.xyz)\n- [Nostr](https://njump.me/opensource@block.xyz)\n",
      "stars_today": 491
    },
    {
      "id": 685877018,
      "name": "res-downloader",
      "full_name": "putyy/res-downloader",
      "description": "ËßÜÈ¢ëÂè∑„ÄÅÂ∞èÁ®ãÂ∫è„ÄÅÊäñÈü≥„ÄÅÂø´Êâã„ÄÅÂ∞èÁ∫¢‰π¶„ÄÅÁõ¥Êí≠ÊµÅ„ÄÅm3u8„ÄÅÈÖ∑Áãó„ÄÅQQÈü≥‰πêÁ≠âÂ∏∏ËßÅÁΩëÁªúËµÑÊ∫ê‰∏ãËΩΩ!",
      "html_url": "https://github.com/putyy/res-downloader",
      "stars": 14152,
      "forks": 1761,
      "language": "Go",
      "topics": [
        "douyin",
        "kuaishou",
        "res-downloader",
        "wechat",
        "wechat-video",
        "xiaohongshu"
      ],
      "created_at": "2023-09-01T08:03:47Z",
      "updated_at": "2026-01-24T02:06:01Z",
      "pushed_at": "2025-12-31T02:24:50Z",
      "open_issues": 38,
      "owner": {
        "login": "putyy",
        "avatar_url": "https://avatars.githubusercontent.com/u/31536789?v=4"
      },
      "readme": "<div align=\"center\">\n\n<a href=\"https://github.com/putyy/res-downloader\"><img src=\"build/appicon.png\" width=\"120\"/></a>\n<h1>res-downloader</h1>\n<h4>üìñ ‰∏≠Êñá | <a href=\"https://github.com/putyy/res-downloader/blob/master/README-EN.md\">English</a></h4>\n\n[![GitHub stars](https://img.shields.io/github/stars/putyy/res-downloader)](https://github.com/putyy/res-downloader/stargazers)\n[![GitHub forks](https://img.shields.io/github/forks/putyy/res-downloader)](https://github.com/putyy/res-downloader/fork)\n[![GitHub release](https://img.shields.io/github/release/putyy/res-downloader)](https://github.com/putyy/res-downloader/releases)\n![GitHub All Releases](https://img.shields.io/github/downloads/putyy/res-downloader/total)\n[![License](https://img.shields.io/github/license/putyy/res-downloader)](https://github.com/putyy/res-downloader/blob/master/LICENSE)\n\n</div>\n\n---\n\n### üéâ Áà±‰∫´Á¥†Êùê‰∏ãËΩΩÂô®\n\n> ‰∏ÄÊ¨æÂü∫‰∫é Go + [Wails](https://github.com/wailsapp/wails) ÁöÑË∑®Âπ≥Âè∞ËµÑÊ∫ê‰∏ãËΩΩÂ∑•ÂÖ∑ÔºåÁÆÄÊ¥ÅÊòìÁî®ÔºåÊîØÊåÅÂ§öÁßçËµÑÊ∫êÂóÖÊé¢‰∏é‰∏ãËΩΩ„ÄÇ\n\n## ‚ú® ÂäüËÉΩÁâπËâ≤\n\n- üöÄ **ÁÆÄÂçïÊòìÁî®**ÔºöÊìç‰ΩúÁÆÄÂçïÔºåÁïåÈù¢Ê∏ÖÊô∞ÁæéËßÇ\n- üñ•Ô∏è **Â§öÂπ≥Âè∞ÊîØÊåÅ**ÔºöWindows / macOS / Linux\n- üåê **Â§öËµÑÊ∫êÁ±ªÂûãÊîØÊåÅ**ÔºöËßÜÈ¢ë / Èü≥È¢ë / ÂõæÁâá / m3u8 / Áõ¥Êí≠ÊµÅÁ≠â\n- üì± **Âπ≥Âè∞ÂÖºÂÆπÂπøÊ≥õ**ÔºöÊîØÊåÅÂæÆ‰ø°ËßÜÈ¢ëÂè∑„ÄÅÂ∞èÁ®ãÂ∫è„ÄÅÊäñÈü≥„ÄÅÂø´Êâã„ÄÅÂ∞èÁ∫¢‰π¶„ÄÅÈÖ∑ÁãóÈü≥‰πê„ÄÅQQÈü≥‰πêÁ≠â\n- üåç **‰ª£ÁêÜÊäìÂåÖ**ÔºöÊîØÊåÅËÆæÁΩÆ‰ª£ÁêÜËé∑ÂèñÂèóÈôêÁΩëÁªú‰∏ãÁöÑËµÑÊ∫ê\n\n## üìö ÊñáÊ°£ & ÁâàÊú¨\n\n- üìò [Âú®Á∫øÊñáÊ°£](https://res.putyy.com/)\n- üí¨ [Âä†ÂÖ•‰∫§ÊµÅÁæ§](https://www.putyy.com/app/admin/upload/img/20250418/6801d9554dc7.webp)\n- üß© [ÊúÄÊñ∞Áâà](https://github.com/putyy/res-downloader/releases) ÔΩú [MiniÁâà ‰ΩøÁî®ÈªòËÆ§ÊµèËßàÂô®Â±ïÁ§∫UI](https://github.com/putyy/resd-mini) ÔΩú [ElectronÊóßÁâà ÊîØÊåÅWin7](https://github.com/putyy/res-downloader/tree/old)\n  > *Áæ§Êª°Êó∂ÂèØÂä†ÂæÆ‰ø° `AmorousWorld`ÔºåËØ∑Â§áÊ≥®‚Äúgithub‚Äù*\n\n## üß© ‰∏ãËΩΩÂú∞ÂùÄ\n\n- üÜï [GitHub ‰∏ãËΩΩ](https://github.com/putyy/res-downloader/releases)\n- üÜï [ËìùÂ•è‰∫ë‰∏ãËΩΩÔºàÂØÜÁ†ÅÔºö9vs5Ôºâ](https://wwjv.lanzoum.com/b04wgtfyb)\n- ‚ö†Ô∏è *Win7 Áî®Êà∑ËØ∑‰∏ãËΩΩ `2.3.0` ÁâàÊú¨*\n\n\n## üñºÔ∏è È¢ÑËßà\n\n![È¢ÑËßà](docs/images/show.webp)\n--- \n\n## üöÄ ‰ΩøÁî®ÊñπÊ≥ï\n\n> ËØ∑Êåâ‰ª•‰∏ãÊ≠•È™§Êìç‰Ωú‰ª•Ê≠£Á°Æ‰ΩøÁî®ËΩØ‰ª∂Ôºö\n\n1. ÂÆâË£ÖÊó∂Âä°ÂøÖ **ÂÖÅËÆ∏ÂÆâË£ÖËØÅ‰π¶Êñá‰ª∂** Âπ∂ **ÂÖÅËÆ∏ÁΩëÁªúËÆøÈóÆ**\n2. ÊâìÂºÄËΩØ‰ª∂ ‚Üí È¶ñÈ°µÂ∑¶‰∏äËßíÁÇπÂáª **‚ÄúÂêØÂä®‰ª£ÁêÜ‚Äù**\n3. ÈÄâÊã©Ë¶ÅËé∑ÂèñÁöÑËµÑÊ∫êÁ±ªÂûãÔºàÈªòËÆ§ÂÖ®ÈÉ®Ôºâ\n4. Âú®Â§ñÈÉ®ÊâìÂºÄËµÑÊ∫êÈ°µÈù¢ÔºàÂ¶ÇËßÜÈ¢ëÂè∑„ÄÅÂ∞èÁ®ãÂ∫è„ÄÅÁΩëÈ°µÁ≠âÔºâ\n5. ËøîÂõûËΩØ‰ª∂È¶ñÈ°µÔºåÂç≥ÂèØÁúãÂà∞ËµÑÊ∫êÂàóË°®\n\n## ‚ùì Â∏∏ËßÅÈóÆÈ¢ò\n\n### üì∫ m3u8 ËßÜÈ¢ëËµÑÊ∫ê\n\n- Âú®Á∫øÈ¢ÑËßàÔºö[m3u8play](https://m3u8play.com/)\n- ËßÜÈ¢ë‰∏ãËΩΩÔºö[m3u8-down](https://m3u8-down.gowas.cn/)\n\n### üì° Áõ¥Êí≠ÊµÅËµÑÊ∫ê\n\n- Êé®Ëçê‰ΩøÁî® [OBS](https://obsproject.com/) ËøõË°åÂΩïÂà∂ÔºàÊïôÁ®ãËØ∑ÁôæÂ∫¶Ôºâ\n\n### üê¢ ‰∏ãËΩΩÊÖ¢„ÄÅÂ§ßÊñá‰ª∂Â§±Ë¥•Ôºü\n\n- Êé®ËçêÂ∑•ÂÖ∑Ôºö\n  - [Neat Download Manager](https://www.neatdownloadmanager.com/index.php/en/)\n  - [Motrix](https://motrix.app/download)\n- ËßÜÈ¢ëÂè∑ËµÑÊ∫ê‰∏ãËΩΩÂêéÂèØÂú®Êìç‰ΩúÈ°πÁÇπÂáª `ËßÜÈ¢ëËß£ÂØÜÔºàËßÜÈ¢ëÂè∑Ôºâ`\n\n### üß© ËΩØ‰ª∂Êó†Ê≥ïÊã¶Êà™ËµÑÊ∫êÔºü\n\n- Ê£ÄÊü•ÊòØÂê¶Ê≠£Á°ÆËÆæÁΩÆÁ≥ªÁªü‰ª£ÁêÜÔºö  \n  Âú∞ÂùÄÔºö127.0.0.1\n  Á´ØÂè£Ôºö8899\n\n### üåê ÂÖ≥Èó≠ËΩØ‰ª∂ÂêéÊó†Ê≥ï‰∏äÁΩëÔºü\n\n- ÊâãÂä®ÂÖ≥Èó≠Á≥ªÁªü‰ª£ÁêÜËÆæÁΩÆ\n\n### üß† Êõ¥Â§öÈóÆÈ¢ò\n\n- [GitHub Issues](https://github.com/putyy/res-downloader/issues)\n- [Áà±‰∫´ËÆ∫ÂùõËÆ®ËÆ∫Â∏ñ](https://s.gowas.cn/d/4089)\n\n## üí° ÂÆûÁé∞ÂéüÁêÜ & ÂàùË°∑\n\nÊú¨Â∑•ÂÖ∑ÈÄöËøá‰ª£ÁêÜÊñπÂºèÂÆûÁé∞ÁΩëÁªúÊäìÂåÖÔºåÂπ∂Á≠õÈÄâÂèØÁî®ËµÑÊ∫ê„ÄÇ‰∏é Fiddler„ÄÅCharles„ÄÅÊµèËßàÂô® DevTools ÂéüÁêÜÁ±ª‰ººÔºå‰ΩÜÂØπËµÑÊ∫êËøõË°å‰∫ÜÊõ¥ÂèãÂ•ΩÁöÑÁ≠õÈÄâ„ÄÅÂ±ïÁ§∫ÂíåÂ§ÑÁêÜÔºåÂ§ßÂπÖÂ∫¶Èôç‰Ωé‰∫Ü‰ΩøÁî®Èó®ÊßõÔºåÊõ¥ÈÄÇÂêàÂ§ß‰ºóÁî®Êà∑‰ΩøÁî®„ÄÇ\n\n---\n\n## ‚ö†Ô∏è ÂÖçË¥£Â£∞Êòé\n\n> Êú¨ËΩØ‰ª∂‰ªÖ‰æõÂ≠¶‰π†‰∏éÁ†îÁ©∂Áî®ÈÄîÔºåÁ¶ÅÊ≠¢Áî®‰∫é‰ªª‰ΩïÂïÜ‰∏öÊàñËøùÊ≥ïÁî®ÈÄî„ÄÇ  \nÂ¶ÇÂõ†Ê≠§‰∫ßÁîüÁöÑ‰ªª‰ΩïÊ≥ïÂæãË¥£‰ªªÔºåÊ¶Ç‰∏é‰ΩúËÄÖÊó†ÂÖ≥ÔºÅ\n",
      "stars_today": 394
    },
    {
      "id": 1014938055,
      "name": "pg_textsearch",
      "full_name": "timescale/pg_textsearch",
      "description": "PostgreSQL extension for BM25 relevance-ranked full-text search. Postgres OSS licensed.",
      "html_url": "https://github.com/timescale/pg_textsearch",
      "stars": 2630,
      "forks": 64,
      "language": "C",
      "topics": [
        "bm25",
        "c-extension",
        "full-text-search",
        "postgresql"
      ],
      "created_at": "2025-07-06T17:45:50Z",
      "updated_at": "2026-01-24T01:33:48Z",
      "pushed_at": "2026-01-24T02:05:32Z",
      "open_issues": 15,
      "owner": {
        "login": "timescale",
        "avatar_url": "https://avatars.githubusercontent.com/u/8986001?v=4"
      },
      "readme": "# pg_textsearch\n\n[![CI](https://github.com/timescale/pg_textsearch/actions/workflows/ci.yml/badge.svg)](https://github.com/timescale/pg_textsearch/actions/workflows/ci.yml)\n[![Benchmarks](https://github.com/timescale/pg_textsearch/actions/workflows/benchmark.yml/badge.svg)](https://timescale.github.io/pg_textsearch/benchmarks/)\n[![Coverity Scan](https://scan.coverity.com/projects/32822/badge.svg)](https://scan.coverity.com/projects/pg_textsearch)\n\nModern ranked text search for Postgres.\n\n- Simple syntax: `ORDER BY content <@> 'search terms'`\n- BM25 ranking with configurable parameters (k1, b)\n- Works with Postgres text search configurations (english, french, german, etc.)\n- Fast top-k queries via Block-Max WAND optimization\n- Parallel index builds for large tables\n- Supports partitioned tables\n- Best in class performance and scalability\n\n‚ö†Ô∏è **Pre-release**: v0.5.0-dev - GA expected Feb 2026. Query performance is competitive with other leading Postgres-based solutions; see [benchmarks](https://timescale.github.io/pg_textsearch/benchmarks/comparison.html). This release adds index compression; parallel builds coming soon. See [ROADMAP.md](ROADMAP.md) for details.\n\n![Tapir and Friends](images/tapir_and_friends_v0.5.0-dev.png)\n\n*The theme of v0.5.0 is parallel indexing.*\n\n## Historical note\n\nThe original name of the project was Tapir - **T**extual **A**nalysis for **P**ostgres **I**nformation **R**etrieval.  We still use the tapir as our\nmascot and the name occurs in various places in the source code.\n\n## PostgreSQL Version Compatibility\n\npg_textsearch supports PostgreSQL 17 and 18.\n\n## Installation\n\n### Pre-built Binaries\n\nDownload pre-built binaries from the\n[Releases page](https://github.com/timescale/pg_textsearch/releases).\nAvailable for Linux and macOS (amd64 and arm64), PostgreSQL 17 and 18.\n\n### Build from Source\n\n```sh\ncd /tmp\ngit clone https://github.com/timescale/pg_textsearch\ncd pg_textsearch\nmake\nmake install # may need sudo\n```\n\n## Getting Started\n\nEnable the extension (do this once in each database where you want to use it)\n\n```sql\nCREATE EXTENSION pg_textsearch;\n```\n\nCreate a table with text content\n\n```sql\nCREATE TABLE documents (id bigserial PRIMARY KEY, content text);\nINSERT INTO documents (content) VALUES\n    ('PostgreSQL is a powerful database system'),\n    ('BM25 is an effective ranking function'),\n    ('Full text search with custom scoring');\n```\n\nCreate a pg_textsearch index on the text column\n\n```sql\nCREATE INDEX docs_idx ON documents USING bm25(content) WITH (text_config='english');\n```\n\n## Querying\n\nGet the most relevant documents using the `<@>` operator\n\n```sql\nSELECT * FROM documents\nORDER BY content <@> 'database system'\nLIMIT 5;\n```\n\nNote: `<@>` returns the negative BM25 score since Postgres only supports `ASC` order index scans on operators. Lower scores indicate better matches.\n\nThe index is automatically detected from the column. For explicit index specification:\n```sql\nSELECT * FROM documents\nWHERE content <@> to_bm25query('database system', 'docs_idx') < -1.0;\n```\n\nSupported operations:\n- `text <@> 'query'` - Score text against a query (index auto-detected)\n- `text <@> bm25query` - Score text with explicit index specification\n\n### Verifying Index Usage\n\nCheck query plan with EXPLAIN:\n```sql\nEXPLAIN SELECT * FROM documents\nORDER BY content <@> 'database system'\nLIMIT 5;\n```\n\nFor small datasets, PostgreSQL may prefer sequential scans. Force index usage:\n```sql\nSET enable_seqscan = off;\n```\n\nNote: Even if EXPLAIN shows a sequential scan, `<@>` and `to_bm25query` always use the index for corpus statistics (document counts, average length) required for BM25 scoring.\n\n### Filtering with WHERE Clauses\n\nThere are two ways filtering interacts with BM25 index scans:\n\n**Pre-filtering** uses a separate index (B-tree, etc.) to reduce rows before scoring:\n```sql\n-- Create index on filter column\nCREATE INDEX ON documents (category_id);\n\n-- Query filters first, then scores matching rows\nSELECT * FROM documents\nWHERE category_id = 123\nORDER BY content <@> 'search terms'\nLIMIT 10;\n```\n\n**Post-filtering** applies the BM25 index scan first, then filters results:\n```sql\nSELECT * FROM documents\nWHERE content <@> to_bm25query('search terms', 'docs_idx') < -5.0\nORDER BY content <@> 'search terms'\nLIMIT 10;\n```\n\n**Performance considerations**:\n\n- **Pre-filtering tradeoff**: If the filter matches many rows (e.g., 100K+), scoring\n  all of them can be expensive. The BM25 index is most efficient when it can use\n  top-k optimization (ORDER BY + LIMIT) to avoid scoring every matching document.\n\n- **Post-filtering tradeoff**: The index returns top-k results *before* filtering.\n  If your WHERE clause eliminates most results, you may get fewer rows than\n  requested. Increase LIMIT to compensate, then re-limit in application code.\n\n- **Best case**: Pre-filter with a selective condition (matches <10% of rows), then\n  let BM25 score the reduced set with ORDER BY + LIMIT.\n\nThis is similar to the [filtering behavior in pgvector](https://github.com/pgvector/pgvector?tab=readme-ov-file#filtering),\nwhere approximate indexes also apply filtering after the index scan.\n\n## Indexing\n\nCreate a BM25 index on your text columns:\n\n```sql\nCREATE INDEX ON documents USING bm25(content) WITH (text_config='english');\n```\n\n### Index Options\n\n- `text_config` - PostgreSQL text search configuration to use (required)\n- `k1` - term frequency saturation parameter (1.2 by default)\n- `b` - length normalization parameter (0.75 by default)\n\n```sql\nCREATE INDEX ON documents USING bm25(content) WITH (text_config='english', k1=1.5, b=0.8);\n```\n\nAlso supports different text search configurations:\n\n```sql\n-- English documents with stemming\nCREATE INDEX docs_en_idx ON documents USING bm25(content) WITH (text_config='english');\n\n-- Simple text processing without stemming\nCREATE INDEX docs_simple_idx ON documents USING bm25(content) WITH (text_config='simple');\n\n-- Language-specific configurations\nCREATE INDEX docs_fr_idx ON french_docs USING bm25(content) WITH (text_config='french');\nCREATE INDEX docs_de_idx ON german_docs USING bm25(content) WITH (text_config='german');\n```\n\n## Data Types\n\n### bm25query\n\nThe `bm25query` type represents queries for BM25 scoring with optional index context:\n\n```sql\n-- Create a bm25query with index name (required for WHERE clause and standalone scoring)\nSELECT to_bm25query('search query text', 'docs_idx');\n-- Returns: docs_idx:search query text\n\n-- Embedded index name syntax (alternative form using cast)\nSELECT 'docs_idx:search query text'::bm25query;\n-- Returns: docs_idx:search query text\n\n-- Create a bm25query without index name (only works in ORDER BY with index scan)\nSELECT to_bm25query('search query text');\n-- Returns: search query text\n```\n\n**Note**: In PostgreSQL 18, the embedded index name syntax using single colon (`:`) allows the\nquery planner to determine the index name even when evaluating SELECT clause expressions early.\nThis ensures compatibility across different query evaluation strategies.\n\n#### bm25query Functions\n\nFunction | Description\n--- | ---\nto_bm25query(text) ‚Üí bm25query | Create bm25query without index name (for ORDER BY only)\nto_bm25query(text, text) ‚Üí bm25query | Create bm25query with query text and index name\ntext <@> bm25query ‚Üí double precision | BM25 scoring operator (returns negative scores)\nbm25query = bm25query ‚Üí boolean | Equality comparison\n\n## Performance\n\npg_textsearch indexes use a memtable architecture for efficient writes. Like other index types, it's faster to create an index after loading your data.\n\n```sql\n-- Load data first\nINSERT INTO documents (content) VALUES (...);\n\n-- Then create index\nCREATE INDEX docs_idx ON documents USING bm25(content) WITH (text_config='english');\n```\n\n### Parallel Index Builds\n\npg_textsearch supports parallel index builds for faster indexing of large tables.\nPostgres automatically uses parallel workers based on table size and configuration.\n\n```sql\n-- Configure parallel workers (optional, uses server defaults otherwise)\nSET max_parallel_maintenance_workers = 4;\n\n-- Create index (parallel workers used automatically for large tables)\nCREATE INDEX docs_idx ON documents USING bm25(content) WITH (text_config='english');\n```\n\nYou'll see a notice when parallel build is used:\n```\nNOTICE:  Using parallel index build with 4 workers (1000000 tuples)\n```\n\nFor partitioned tables, each partition builds its index independently with parallel\nworkers if the partition is large enough. This allows efficient indexing of very\nlarge partitioned datasets.\n\n## Monitoring\n\n```sql\n-- Check index usage\nSELECT schemaname, tablename, indexname, idx_scan, idx_tup_read, idx_tup_fetch\nFROM pg_stat_user_indexes\nWHERE indexrelid::regclass::text ~ 'pg_textsearch';\n```\n\n### Configuration\n\nOptional settings in `postgresql.conf`:\n\n```bash\n# Query limit when no LIMIT clause detected\npg_textsearch.default_limit = 1000           # default 1000\n\n# Auto-spill thresholds (set to 0 to disable)\npg_textsearch.bulk_load_threshold = 100000    # terms per transaction\npg_textsearch.memtable_spill_threshold = 32000000  # posting entries (~1M docs/segment)\n\n# Compression (v0.4.0+)\npg_textsearch.compress_segments = on          # default on\n\n# Query optimization\npg_textsearch.enable_bmw = on                 # Block-Max WAND for top-k queries\n```\n\nThe `memtable_spill_threshold` controls when the in-memory index spills to\ndisk segments. When the memtable reaches this many posting entries, it\nautomatically flushes to a segment at transaction commit. This keeps memory\nusage bounded while maintaining good query performance.\n\n**Crash recovery**: The memtable is rebuilt from the heap on startup, so no\ndata is lost if Postgres crashes before spilling to disk.\n\n## Examples\n\n### Basic Search\n\n```sql\nCREATE TABLE articles (id serial PRIMARY KEY, title text, content text);\nCREATE INDEX articles_idx ON articles USING bm25(content) WITH (text_config='english');\n\nINSERT INTO articles (title, content) VALUES\n    ('Database Systems', 'PostgreSQL is a powerful relational database system'),\n    ('Search Technology', 'Full text search enables finding relevant documents quickly'),\n    ('Information Retrieval', 'BM25 is a ranking function used in search engines');\n\n-- Find relevant documents\nSELECT title, content <@> 'database search' as score\nFROM articles\nORDER BY score;\n```\n\nAlso supports different languages and custom parameters:\n\n```sql\n-- Different languages\nCREATE INDEX fr_idx ON french_articles USING bm25(content) WITH (text_config='french');\nCREATE INDEX de_idx ON german_articles USING bm25(content) WITH (text_config='german');\n\n-- Custom parameters\nCREATE INDEX custom_idx ON documents USING bm25(content)\n    WITH (text_config='english', k1=2.0, b=0.9);\n```\n\n\n## Limitations\n\n### Partitioned Tables\n\nBM25 indexes on partitioned tables use **partition-local statistics**. Each\npartition maintains its own:\n- Document count (`total_docs`)\n- Average document length (`avg_doc_len`)\n- Per-term document frequencies for IDF calculation\n\nThis means:\n- Queries targeting a single partition compute accurate BM25 scores using that\n  partition's statistics\n- Queries spanning multiple partitions return scores computed independently per\n  partition, which may not be directly comparable across partitions\n\n**Example**: If partition A has 1000 documents and partition B has 10 documents,\nthe term \"database\" would have different IDF values in each partition. Results\nfrom both partitions would have scores on different scales.\n\n**Recommendations**:\n- For time-partitioned data, query individual partitions when score comparability\n  matters\n- Use partitioning schemes where queries naturally target single partitions\n- Consider this behavior when designing partition strategies for search workloads\n\n```sql\n-- Query single partition (scores are accurate within partition)\nSELECT * FROM docs\nWHERE created_at >= '2024-01-01' AND created_at < '2025-01-01'\nORDER BY content <@> 'search terms'\nLIMIT 10;\n\n-- Cross-partition query (scores computed per-partition)\nSELECT * FROM docs\nORDER BY content <@> 'search terms'\nLIMIT 10;\n```\n\n### Word Length Limit\n\npg_textsearch inherits PostgreSQL's tsvector word length limit of 2047 characters.\nWords exceeding this limit are ignored during tokenization (with an INFO message).\nThis is defined by `MAXSTRLEN` in PostgreSQL's text search implementation.\n\nFor typical natural language text, this limit is never encountered. It may affect\ndocuments containing very long tokens such as base64-encoded data, long URLs, or\nconcatenated identifiers.\n\nThis behavior is similar to other search engines:\n- Elasticsearch: Truncates tokens (configurable via `truncate` filter, default 10 chars)\n- Tantivy: Truncates to 255 bytes by default\n\n### PL/pgSQL and Stored Procedures\n\nThe implicit `text <@> 'query'` syntax relies on planner hooks to automatically\ndetect the BM25 index. These hooks don't run inside PL/pgSQL DO blocks, functions,\nor stored procedures.\n\n**Inside PL/pgSQL**, use explicit index names with `to_bm25query()`:\n\n```sql\n-- This won't work in PL/pgSQL:\n-- SELECT * FROM docs ORDER BY content <@> 'search terms' LIMIT 10;\n\n-- Use explicit index name instead:\nSELECT * FROM docs\nORDER BY content <@> to_bm25query('search terms', 'docs_idx')\nLIMIT 10;\n```\n\nRegular SQL queries (outside PL/pgSQL) support both forms.\n\n## Troubleshooting\n\n```sql\n-- List available text search configurations\nSELECT cfgname FROM pg_ts_config;\n\n-- List BM25 indexes\nSELECT indexname FROM pg_indexes WHERE indexdef LIKE '%USING bm25%';\n```\n\n\n## Installation Notes\n\nIf your machine has multiple Postgres installations, specify the path to `pg_config`:\n\n```sh\nexport PG_CONFIG=/Library/PostgreSQL/18/bin/pg_config  # or 17\nmake clean && make && make install\n```\n\nIf you get compilation errors, install Postgres development files:\n\n```sh\n# Ubuntu/Debian\nsudo apt install postgresql-server-dev-17  # for PostgreSQL 17\nsudo apt install postgresql-server-dev-18  # for PostgreSQL 18\n```\n\n## Reference\n\n### Index Options\n\nOption | Type | Default | Description\n--- | --- | --- | ---\ntext_config | string | required | PostgreSQL text search configuration to use\nk1 | real | 1.2 | Term frequency saturation parameter (0.1 to 10.0)\nb | real | 0.75 | Length normalization parameter (0.0 to 1.0)\n\n### Text Search Configurations\n\nAvailable configurations depend on your Postgres installation:\n```\n# SELECT cfgname FROM pg_ts_config;\n  cfgname\n------------\n simple\n arabic\n armenian\n basque\n catalan\n danish\n dutch\n english\n finnish\n french\n german\n greek\n hindi\n hungarian\n indonesian\n irish\n italian\n lithuanian\n nepali\n norwegian\n portuguese\n romanian\n russian\n serbian\n spanish\n swedish\n tamil\n turkish\n yiddish\n(29 rows)\n```\nFurther language support is available via extensions such as [zhparser](https://github.com/amutu/zhparser).\n\n### Development Functions\n\nThese functions are for debugging and development use only. Their interface may\nchange in future releases without notice.\n\nFunction | Description\n--- | ---\nbm25_dump_index(index_name) ‚Üí text | Dump internal index structure (truncated)\nbm25_dump_index(index_name, file_path) ‚Üí text | Dump full index structure to file\nbm25_summarize_index(index_name) ‚Üí text | Show index statistics without content\nbm25_spill_index(index_name) ‚Üí int4 | Force memtable spill to disk segment\n\n```sql\n-- Quick overview of index statistics\nSELECT bm25_summarize_index('docs_idx');\n\n-- Detailed dump for debugging (truncated output)\nSELECT bm25_dump_index('docs_idx');\n\n-- Full dump to file (includes hex data)\nSELECT bm25_dump_index('docs_idx', '/tmp/docs_idx_dump.txt');\n\n-- Force spill to disk (returns number of entries spilled)\nSELECT bm25_spill_index('docs_idx');\n```\n\n## Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for development setup, code style, and\nhow to submit pull requests.\n\n- **Bug Reports**: [Create an issue](https://github.com/timescale/pg_textsearch/issues/new?labels=bug&template=bug_report.md)\n- **Feature Requests**: [Request a feature](https://github.com/timescale/pg_textsearch/issues/new?labels=enhancement&template=feature_request.md)\n- **General Discussion**: [Start a discussion](https://github.com/timescale/pg_textsearch/discussions)\n",
      "stars_today": 344
    },
    {
      "id": 839037098,
      "name": "mastra",
      "full_name": "mastra-ai/mastra",
      "description": "From the team behind Gatsby, Mastra is a framework for building AI-powered applications and agents with a modern TypeScript stack.",
      "html_url": "https://github.com/mastra-ai/mastra",
      "stars": 20350,
      "forks": 1461,
      "language": "TypeScript",
      "topics": [
        "agents",
        "ai",
        "chatbots",
        "evals",
        "javascript",
        "llm",
        "mcp",
        "nextjs",
        "nodejs",
        "reactjs",
        "tts",
        "typescript",
        "workflows"
      ],
      "created_at": "2024-08-06T20:44:31Z",
      "updated_at": "2026-01-24T01:33:03Z",
      "pushed_at": "2026-01-24T01:50:09Z",
      "open_issues": 344,
      "owner": {
        "login": "mastra-ai",
        "avatar_url": "https://avatars.githubusercontent.com/u/149120496?v=4"
      },
      "readme": "# Mastra\n\n[![npm version](https://badge.fury.io/js/@mastra%2Fcore.svg)](https://www.npmjs.com/package/@mastra/core)\n[![CodeQl](https://github.com/mastra-ai/mastra/actions/workflows/github-code-scanning/codeql/badge.svg)](https://github.com/mastra-ai/mastra/actions/workflows/github-code-scanning/codeql)\n[![GitHub Repo stars](https://img.shields.io/github/stars/mastra-ai/mastra)](https://github.com/mastra-ai/mastra/stargazers)\n[![Discord](https://img.shields.io/discord/1309558646228779139?logo=discord&label=Discord&labelColor=white&color=7289DA)](https://discord.gg/BTYqqHKUrf)\n[![Twitter Follow](https://img.shields.io/twitter/follow/mastra_ai?style=social)](https://x.com/mastra_ai)\n[![NPM Downloads](https://img.shields.io/npm/dm/%40mastra%252Fcore)](https://www.npmjs.com/package/@mastra/core)\n[![Static Badge](https://img.shields.io/badge/Y%20Combinator-W25-orange)](https://www.ycombinator.com/companies?batch=W25)\n\nMastra is a framework for building AI-powered applications and agents with a modern TypeScript stack.\n\nIt includes everything you need to go from early prototypes to production-ready applications. Mastra integrates with frontend and backend frameworks like React, Next.js, and Node, or you can deploy it anywhere as a standalone server. It's the easiest way to build, tune, and scale reliable AI products.\n\n## Why Mastra?\n\nPurpose-built for TypeScript and designed around established AI patterns, Mastra gives you everything you need to build great AI applications out-of-the-box.\n\nSome highlights include:\n\n- [**Model routing**](https://mastra.ai/models) - Connect to 40+ providers through one standard interface. Use models from OpenAI, Anthropic, Gemini, and more.\n\n- [**Agents**](https://mastra.ai/docs/agents/overview) - Build autonomous agents that use LLMs and tools to solve open-ended tasks. Agents reason about goals, decide which tools to use, and iterate internally until the model emits a final answer or an optional stopping condition is met.\n\n- [**Workflows**](https://mastra.ai/docs/workflows/overview) - When you need explicit control over execution, use Mastra's graph-based workflow engine to orchestrate complex multi-step processes. Mastra workflows use an intuitive syntax for control flow (`.then()`, `.branch()`, `.parallel()`).\n\n- [**Human-in-the-loop**](https://mastra.ai/docs/workflows/suspend-and-resume) - Suspend an agent or workflow and await user input or approval before resuming. Mastra uses [storage](https://mastra.ai/docs/server-db/storage) to remember execution state, so you can pause indefinitely and resume where you left off.\n\n- **Context management** - Give your agents the right context at the right time. Provide [conversation history](https://mastra.ai/docs/memory/conversation-history), [retrieve](https://mastra.ai/docs/rag/overview) data from your sources (APIs, databases, files), and add human-like [working](https://mastra.ai/docs/memory/working-memory) and [semantic](https://mastra.ai/docs/memory/semantic-recall) memory so your agents behave coherently.\n\n- **Integrations** - Bundle agents and workflows into existing React, Next.js, or Node.js apps, or ship them as standalone endpoints. When building UIs, integrate with agentic libraries like Vercel's AI SDK UI and CopilotKit to bring your AI assistant to life on the web.\n\n- [**MCP servers**](https://mastra.ai/docs/tools-mcp/mcp-overview) - Author Model Context Protocol servers, exposing agents, tools, and other structured resources via the MCP interface. These can then be accessed by any system or agent that supports the protocol.\n\n- **Production essentials** - Shipping reliable agents takes ongoing insight, evaluation, and iteration. With built-in [evals](https://mastra.ai/docs/evals/overview) and [observability](https://mastra.ai/docs/observability/overview), Mastra gives you the tools to observe, measure, and refine continuously.\n\n## Get started\n\nThe **recommended** way to get started with Mastra is by running the command below:\n\n```shell\nnpm create mastra@latest\n```\n\nFollow the [Installation guide](https://mastra.ai/docs/getting-started/installation) for step-by-step setup with the CLI or a manual install.\n\nIf you're new to AI agents, check out our [templates](https://mastra.ai/docs/getting-started/templates), [course](https://mastra.ai/course), and [YouTube videos](https://youtube.com/@mastra-ai) to start building with Mastra today.\n\n## Documentation\n\nVisit our [official documentation](https://mastra.ai/docs).\n\n## MCP Servers\n\nLearn how to make your IDE a Mastra expert by following the [`@mastra/mcp-docs-server` guide](https://mastra.ai/docs/getting-started/mcp-docs-server).\n\n## Contributing\n\nLooking to contribute? All types of help are appreciated, from coding to testing and feature specification.\n\nIf you are a developer and would like to contribute with code, please open an issue to discuss before opening a Pull Request.\n\nInformation about the project setup can be found in the [development documentation](./DEVELOPMENT.md)\n\n## Support\n\nWe have an [open community Discord](https://discord.gg/BTYqqHKUrf). Come and say hello and let us know if you have any questions or need any help getting things running.\n\nIt's also super helpful if you leave the project a star here at the [top of the page](https://github.com/mastra-ai/mastra)\n\n## Security\n\nWe are committed to maintaining the security of this repo and of Mastra as a whole. If you discover a security finding\nwe ask you to please responsibly disclose this to us at [security@mastra.ai](mailto:security@mastra.ai) and we will get\nback to you.\n",
      "stars_today": 309
    },
    {
      "id": 1031912724,
      "name": "cc-switch",
      "full_name": "farion1231/cc-switch",
      "description": "A cross-platform desktop All-in-One assistant tool for Claude Code, Codex, OpenCode & Gemini CLI.",
      "html_url": "https://github.com/farion1231/cc-switch",
      "stars": 13290,
      "forks": 851,
      "language": "Rust",
      "topics": [
        "ai-tools",
        "claude-code",
        "codex",
        "desktop-app",
        "kimi-k2-thiking",
        "mcp",
        "minimax",
        "open-source",
        "opencode",
        "provider-management",
        "rust",
        "skills",
        "skills-management",
        "tauri",
        "typescript",
        "wsl-support"
      ],
      "created_at": "2025-08-04T14:16:16Z",
      "updated_at": "2026-01-24T02:00:26Z",
      "pushed_at": "2026-01-23T15:07:14Z",
      "open_issues": 139,
      "owner": {
        "login": "farion1231",
        "avatar_url": "https://avatars.githubusercontent.com/u/44939412?v=4"
      },
      "readme": "<div align=\"center\">\n\n# All-in-One Assistant for Claude Code, Codex & Gemini CLI\n\n[![Version](https://img.shields.io/badge/version-3.10.0-blue.svg)](https://github.com/farion1231/cc-switch/releases)\n[![Platform](https://img.shields.io/badge/platform-Windows%20%7C%20macOS%20%7C%20Linux-lightgrey.svg)](https://github.com/farion1231/cc-switch/releases)\n[![Built with Tauri](https://img.shields.io/badge/built%20with-Tauri%202-orange.svg)](https://tauri.app/)\n[![Downloads](https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/downloads/farion1231/cc-switch/total)](https://github.com/farion1231/cc-switch/releases/latest)\n\n<a href=\"https://trendshift.io/repositories/15372\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/15372\" alt=\"farion1231%2Fcc-switch | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\nEnglish | [‰∏≠Êñá](README_ZH.md) | [Êó•Êú¨Ë™û](README_JA.md) | [Changelog](CHANGELOG.md)\n\n</div>\n\n## ‚ù§Ô∏èSponsor\n\n[![Zhipu GLM](assets/partners/banners/glm-en.jpg)](https://z.ai/subscribe?ic=8JVLJQFSKB)\n\nThis project is sponsored by Z.ai, supporting us with their GLM CODING PLAN.GLM CODING PLAN is a subscription service designed for AI coding, starting at just $3/month. It provides access to their flagship GLM-4.6 model across 10+ popular AI coding tools (Claude Code, Cline, Roo Code, etc.), offering developers top-tier, fast, and stable coding experiences.Get 10% OFF the GLM CODING PLAN with [this link](https://z.ai/subscribe?ic=8JVLJQFSKB)!\n\n---\n\n<table>\n<tr>\n<td width=\"180\"><a href=\"https://www.packyapi.com/register?aff=cc-switch\"><img src=\"assets/partners/logos/packycode.png\" alt=\"PackyCode\" width=\"150\"></a></td>\n<td>Thanks to PackyCode for sponsoring this project! PackyCode is a reliable and efficient API relay service provider, offering relay services for Claude Code, Codex, Gemini, and more. PackyCode provides special discounts for our software users: register using <a href=\"https://www.packyapi.com/register?aff=cc-switch\">this link</a> and enter the \"cc-switch\" promo code during recharge to get 10% off.</td>\n</tr>\n\n<tr>\n<td width=\"180\"><a href=\"https://aigocode.com/invite/CC-SWITCH\"><img src=\"assets/partners/logos/aigocode.png\" alt=\"AIGoCode\" width=\"150\"></a></td>\n<td>Thanks to AIGoCode for sponsoring this project! AIGoCode is an all-in-one platform that integrates Claude Code, Codex, and the latest Gemini models, providing you with stable, efficient, and highly cost-effective AI coding services. The platform offers flexible subscription plans, zero risk of account suspension, direct access with no VPN required, and lightning-fast responses. AIGoCode has prepared a special benefit for CC Switch users: if you register via <a href=\"https://aigocode.com/invite/CC-SWITCH\">this link</a>, you'll receive an extra 10% bonus credit on your first top-up!</td>\n</tr>\n\n<tr>\n<td width=\"180\"><a href=\"https://www.dmxapi.cn/register?aff=bUHu\"><img src=\"assets/partners/logos/dmx-en.jpg\" alt=\"DMXAPI\" width=\"150\"></a></td>\n<td>Thanks to DMXAPI for sponsoring this project! DMXAPI provides global large model API services to 200+ enterprise users. One API key for all global models. Features include: instant invoicing, unlimited concurrency, starting from $0.15, 24/7 technical support. GPT/Claude/Gemini all at 32% off, domestic models 20-50% off, Claude Code exclusive models at 66% off! <a href=\"https://www.dmxapi.cn/register?aff=bUHu\">Register here</a></td>\n</tr>\n\n<tr>\n<td width=\"180\"><a href=\"https://cubence.com/signup?code=CCSWITCH&source=ccs\"><img src=\"assets/partners/logos/cubence.png\" alt=\"Cubence\" width=\"150\"></a></td>\n<td>Thanks to Cubence for sponsoring this project! Cubence is a reliable and efficient API relay service provider, offering relay services for Claude Code, Codex, Gemini, and more with flexible billing options including pay-as-you-go and monthly plans. Cubence provides special discounts for CC Switch users: register using <a href=\"https://cubence.com/signup?code=CCSWITCH&source=ccs\">this link</a> and enter the \"CCSWITCH\" promo code during recharge to get 10% off every top-up!</td>\n</tr>\n\n</table>\n\n## Screenshots\n\n|                  Main Interface                   |                  Add Provider                  |\n| :-----------------------------------------------: | :--------------------------------------------: |\n| ![Main Interface](assets/screenshots/main-en.png) | ![Add Provider](assets/screenshots/add-en.png) |\n\n## Features\n\n### Current Version: v3.10.0 | [Full Changelog](CHANGELOG.md) | [Release Notes](docs/release-note-v3.9.0-en.md)\n\n**v3.8.0 Major Update (2025-11-28)**\n\n**Persistence Architecture Upgrade & Brand New UI**\n\n- **SQLite + JSON Dual-layer Architecture**\n  - Migrated from JSON file storage to SQLite + JSON dual-layer structure\n  - Syncable data (providers, MCP, Prompts, Skills) stored in SQLite\n  - Device-level data (window state, local paths) stored in JSON\n  - Lays the foundation for future cloud sync functionality\n  - Schema version management for database migrations\n\n- **Brand New User Interface**\n  - Completely redesigned interface layout\n  - Unified component styles and smoother animations\n  - Optimized visual hierarchy\n  - Tailwind CSS downgraded from v4 to v3.4 for better browser compatibility\n\n- **Japanese Language Support**\n  - Added Japanese interface support (now supports Chinese/English/Japanese)\n\n- **Auto Launch on Startup**\n  - One-click enable/disable in settings\n  - Platform-native APIs (Registry/LaunchAgent/XDG autostart)\n\n- **Skills Recursive Scanning**\n  - Support for multi-level directory structures\n  - Allow same-named skills from different repositories\n\n- **Critical Bug Fixes**\n  - Fixed custom endpoints lost when updating providers\n  - Fixed Gemini configuration write issues\n  - Fixed Linux WebKitGTK rendering issues\n\n**v3.7.0 Highlights**\n\n**Six Core Features, 18,000+ Lines of New Code**\n\n- **Gemini CLI Integration**\n  - Third supported AI CLI (Claude Code / Codex / Gemini)\n  - Dual-file configuration support (`.env` + `settings.json`)\n  - Complete MCP server management\n  - Presets: Google Official (OAuth) / PackyCode / Custom\n\n- **Claude Skills Management System**\n  - Auto-scan skills from GitHub repositories (3 pre-configured curated repos)\n  - One-click install/uninstall to `~/.claude/skills/`\n  - Custom repository support + subdirectory scanning\n  - Complete lifecycle management (discover/install/update)\n\n- **Prompts Management System**\n  - Multi-preset system prompt management (unlimited presets, quick switching)\n  - Cross-app support (Claude: `CLAUDE.md` / Codex: `AGENTS.md` / Gemini: `GEMINI.md`)\n  - Markdown editor (CodeMirror 6 + real-time preview)\n  - Smart backfill protection, preserves manual modifications\n\n- **MCP v3.7.0 Unified Architecture**\n  - Single panel manages MCP servers across three applications\n  - New SSE (Server-Sent Events) transport type\n  - Smart JSON parser + Codex TOML format auto-correction\n  - Unified import/export + bidirectional sync\n\n- **Deep Link Protocol**\n  - `ccswitch://` protocol registration (all platforms)\n  - One-click import provider configs via shared links\n  - Security validation + lifecycle integration\n\n- **Environment Variable Conflict Detection**\n  - Auto-detect cross-app configuration conflicts (Claude/Codex/Gemini/MCP)\n  - Visual conflict indicators + resolution suggestions\n  - Override warnings + backup before changes\n\n**Core Capabilities**\n\n- **Provider Management**: One-click switching between Claude Code, Codex, and Gemini API configurations\n- **Speed Testing**: Measure API endpoint latency with visual quality indicators\n- **Import/Export**: Backup and restore configs with auto-rotation (keep 10 most recent)\n- **i18n Support**: Complete Chinese/English localization (UI, errors, tray)\n- **Claude Plugin Sync**: One-click apply/restore Claude plugin configurations\n\n**v3.6 Highlights**\n\n- Provider duplication & drag-and-drop sorting\n- Multi-endpoint management & custom config directory (cloud sync ready)\n- Granular model configuration (4-tier: Haiku/Sonnet/Opus/Custom)\n- WSL environment support with auto-sync on directory change\n- 100% hooks test coverage & complete architecture refactoring\n\n**System Features**\n\n- System tray with quick switching\n- Single instance daemon\n- Built-in auto-updater\n- Atomic writes with rollback protection\n\n## Download & Installation\n\n### System Requirements\n\n- **Windows**: Windows 10 and above\n- **macOS**: macOS 10.15 (Catalina) and above\n- **Linux**: Ubuntu 22.04+ / Debian 11+ / Fedora 34+ and other mainstream distributions\n\n### Windows Users\n\nDownload the latest `CC-Switch-v{version}-Windows.msi` installer or `CC-Switch-v{version}-Windows-Portable.zip` portable version from the [Releases](../../releases) page.\n\n### macOS Users\n\n**Method 1: Install via Homebrew (Recommended)**\n\n```bash\nbrew tap farion1231/ccswitch\nbrew install --cask cc-switch\n```\n\nUpdate:\n\n```bash\nbrew upgrade --cask cc-switch\n```\n\n**Method 2: Manual Download**\n\nDownload `CC-Switch-v{version}-macOS.zip` from the [Releases](../../releases) page and extract to use.\n\n> **Note**: Since the author doesn't have an Apple Developer account, you may see an \"unidentified developer\" warning on first launch. Please close it first, then go to \"System Settings\" ‚Üí \"Privacy & Security\" ‚Üí click \"Open Anyway\", and you'll be able to open it normally afterwards.\n\n### Arch Linux Users\n\n**Install via paru (Recommended)**\n\n```bash\nparu -S cc-switch-bin\n```\n\n### Linux Users\n\nDownload the latest Linux build from the [Releases](../../releases) page:\n\n- `CC-Switch-v{version}-Linux.deb` (Debian/Ubuntu)\n- `CC-Switch-v{version}-Linux.rpm` (Fedora/RHEL/openSUSE)\n- `CC-Switch-v{version}-Linux.AppImage` (Universal)\n- `CC-Switch-v{version}-Linux.flatpak` (Flatpak)\n\nFlatpak install & run:\n\n```bash\nflatpak install --user ./CC-Switch-v{version}-Linux.flatpak\nflatpak run com.ccswitch.desktop\n```\n\n## Quick Start\n\n### Basic Usage\n\n1. **Add Provider**: Click \"Add Provider\" ‚Üí Choose preset or create custom configuration\n2. **Switch Provider**:\n   - Main UI: Select provider ‚Üí Click \"Enable\"\n   - System Tray: Click provider name directly (instant effect)\n3. **Takes Effect**: Restart your terminal or Claude Code / Codex / Gemini clients to apply changes\n4. **Back to Official**: Select the \"Official Login\" preset (Claude/Codex) or \"Google Official\" preset (Gemini), restart the corresponding client, then follow its login/OAuth flow\n\n### MCP Management\n\n- **Location**: Click \"MCP\" button in top-right corner\n- **Add Server**:\n  - Use built-in templates (mcp-fetch, mcp-filesystem, etc.)\n  - Support stdio / http / sse transport types\n  - Configure independent MCP servers for different apps\n- **Enable/Disable**: Toggle switches to control which servers sync to live config\n- **Sync**: Enabled servers auto-sync to each app's live files\n- **Import/Export**: Import existing MCP servers from Claude/Codex/Gemini config files\n\n### Skills Management (v3.7.0 New)\n\n- **Location**: Click \"Skills\" button in top-right corner\n- **Discover Skills**:\n  - Auto-scan pre-configured GitHub repositories (Anthropic official, ComposioHQ, community, etc.)\n  - Add custom repositories (supports subdirectory scanning)\n- **Install Skills**: Click \"Install\" to one-click install to `~/.claude/skills/`\n- **Uninstall Skills**: Click \"Uninstall\" to safely remove and clean up state\n- **Manage Repositories**: Add/remove custom GitHub repositories\n\n### Prompts Management (v3.7.0 New)\n\n- **Location**: Click \"Prompts\" button in top-right corner\n- **Create Presets**:\n  - Create unlimited system prompt presets\n  - Use Markdown editor to write prompts (syntax highlighting + real-time preview)\n- **Switch Presets**: Select preset ‚Üí Click \"Activate\" to apply immediately\n- **Sync Mechanism**:\n  - Claude: `~/.claude/CLAUDE.md`\n  - Codex: `~/.codex/AGENTS.md`\n  - Gemini: `~/.gemini/GEMINI.md`\n- **Protection Mechanism**: Auto-save current prompt content before switching, preserves manual modifications\n\n### Configuration Files\n\n**Claude Code**\n\n- Live config: `~/.claude/settings.json` (or `claude.json`)\n- API key field: `env.ANTHROPIC_AUTH_TOKEN` or `env.ANTHROPIC_API_KEY`\n- MCP servers: `~/.claude.json` ‚Üí `mcpServers`\n\n**Codex**\n\n- Live config: `~/.codex/auth.json` (required) + `config.toml` (optional)\n- API key field: `OPENAI_API_KEY` in `auth.json`\n- MCP servers: `~/.codex/config.toml` ‚Üí `[mcp_servers]` tables\n\n**Gemini**\n\n- Live config: `~/.gemini/.env` (API key) + `~/.gemini/settings.json` (auth mode)\n- API key field: `GEMINI_API_KEY` or `GOOGLE_GEMINI_API_KEY` in `.env`\n- Environment variables: Support `GOOGLE_GEMINI_BASE_URL`, `GEMINI_MODEL`, etc.\n- MCP servers: `~/.gemini/settings.json` ‚Üí `mcpServers`\n- Tray quick switch: Each provider switch rewrites `~/.gemini/.env`, no need to restart Gemini CLI\n\n**CC Switch Storage (v3.8.0 New Architecture)**\n\n- Database (SSOT): `~/.cc-switch/cc-switch.db` (SQLite, stores providers, MCP, Prompts, Skills)\n- Local settings: `~/.cc-switch/settings.json` (device-level settings)\n- Backups: `~/.cc-switch/backups/` (auto-rotate, keep 10)\n\n### Cloud Sync Setup\n\n1. Go to Settings ‚Üí \"Custom Configuration Directory\"\n2. Choose your cloud sync folder (Dropbox, OneDrive, iCloud, etc.)\n3. Restart app to apply\n4. Repeat on other devices to enable cross-device sync\n\n> **Note**: First launch auto-imports existing Claude/Codex configs as default provider.\n\n## Architecture Overview\n\n### Design Principles\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ                    Frontend (React + TS)                    ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n‚îÇ  ‚îÇ Components  ‚îÇ  ‚îÇ    Hooks     ‚îÇ  ‚îÇ  TanStack Query  ‚îÇ    ‚îÇ\n‚îÇ  ‚îÇ   (UI)      ‚îÇ‚îÄ‚îÄ‚îÇ (Bus. Logic) ‚îÇ‚îÄ‚îÄ‚îÇ   (Cache/Sync)   ‚îÇ    ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                         ‚îÇ Tauri IPC\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ                  Backend (Tauri + Rust)                     ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n‚îÇ  ‚îÇ  Commands   ‚îÇ  ‚îÇ   Services   ‚îÇ  ‚îÇ  Models/Config   ‚îÇ    ‚îÇ\n‚îÇ  ‚îÇ (API Layer) ‚îÇ‚îÄ‚îÄ‚îÇ (Bus. Layer) ‚îÇ‚îÄ‚îÄ‚îÇ     (Data)       ‚îÇ    ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n**Core Design Patterns**\n\n- **SSOT** (Single Source of Truth): All data stored in `~/.cc-switch/cc-switch.db` (SQLite)\n- **Dual-layer Storage**: SQLite for syncable data, JSON for device-level settings\n- **Dual-way Sync**: Write to live files on switch, backfill from live when editing active provider\n- **Atomic Writes**: Temp file + rename pattern prevents config corruption\n- **Concurrency Safe**: Mutex-protected database connection avoids race conditions\n- **Layered Architecture**: Clear separation (Commands ‚Üí Services ‚Üí DAO ‚Üí Database)\n\n**Key Components**\n\n- **ProviderService**: Provider CRUD, switching, backfill, sorting\n- **McpService**: MCP server management, import/export, live file sync\n- **ConfigService**: Config import/export, backup rotation\n- **SpeedtestService**: API endpoint latency measurement\n\n**v3.6 Refactoring**\n\n- Backend: 5-phase refactoring (error handling ‚Üí command split ‚Üí tests ‚Üí services ‚Üí concurrency)\n- Frontend: 4-stage refactoring (test infra ‚Üí hooks ‚Üí components ‚Üí cleanup)\n- Testing: 100% hooks coverage + integration tests (vitest + MSW)\n\n## Development\n\n### Environment Requirements\n\n- Node.js 18+\n- pnpm 8+\n- Rust 1.85+\n- Tauri CLI 2.8+\n\n### Development Commands\n\n```bash\n# Install dependencies\npnpm install\n\n# Dev mode (hot reload)\npnpm dev\n\n# Type check\npnpm typecheck\n\n# Format code\npnpm format\n\n# Check code format\npnpm format:check\n\n# Run frontend unit tests\npnpm test:unit\n\n# Run tests in watch mode (recommended for development)\npnpm test:unit:watch\n\n# Build application\npnpm build\n\n# Build debug version\npnpm tauri build --debug\n```\n\n### Rust Backend Development\n\n```bash\ncd src-tauri\n\n# Format Rust code\ncargo fmt\n\n# Run clippy checks\ncargo clippy\n\n# Run backend tests\ncargo test\n\n# Run specific tests\ncargo test test_name\n\n# Run tests with test-hooks feature\ncargo test --features test-hooks\n```\n\n### Testing Guide (v3.6 New)\n\n**Frontend Testing**:\n\n- Uses **vitest** as test framework\n- Uses **MSW (Mock Service Worker)** to mock Tauri API calls\n- Uses **@testing-library/react** for component testing\n\n**Test Coverage**:\n\n- Hooks unit tests (100% coverage)\n  - `useProviderActions` - Provider operations\n  - `useMcpActions` - MCP management\n  - `useSettings` series - Settings management\n  - `useImportExport` - Import/export\n- Integration tests\n  - App main application flow\n  - SettingsDialog complete interaction\n  - MCP panel functionality\n\n**Running Tests**:\n\n```bash\n# Run all tests\npnpm test:unit\n\n# Watch mode (auto re-run)\npnpm test:unit:watch\n\n# With coverage report\npnpm test:unit --coverage\n```\n\n## Tech Stack\n\n**Frontend**: React 18 ¬∑ TypeScript ¬∑ Vite ¬∑ TailwindCSS 4 ¬∑ TanStack Query v5 ¬∑ react-i18next ¬∑ react-hook-form ¬∑ zod ¬∑ shadcn/ui ¬∑ @dnd-kit\n\n**Backend**: Tauri 2.8 ¬∑ Rust ¬∑ serde ¬∑ tokio ¬∑ thiserror ¬∑ tauri-plugin-updater/process/dialog/store/log\n\n**Testing**: vitest ¬∑ MSW ¬∑ @testing-library/react\n\n## Project Structure\n\n```\n‚îú‚îÄ‚îÄ src/                      # Frontend (React + TypeScript)\n‚îÇ   ‚îú‚îÄ‚îÄ components/           # UI components (providers/settings/mcp/ui)\n‚îÇ   ‚îú‚îÄ‚îÄ hooks/                # Custom hooks (business logic)\n‚îÇ   ‚îú‚îÄ‚îÄ lib/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/              # Tauri API wrapper (type-safe)\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ query/            # TanStack Query config\n‚îÇ   ‚îú‚îÄ‚îÄ i18n/locales/         # Translations (zh/en)\n‚îÇ   ‚îú‚îÄ‚îÄ config/               # Presets (providers/mcp)\n‚îÇ   ‚îî‚îÄ‚îÄ types/                # TypeScript definitions\n‚îú‚îÄ‚îÄ src-tauri/                # Backend (Rust)\n‚îÇ   ‚îî‚îÄ‚îÄ src/\n‚îÇ       ‚îú‚îÄ‚îÄ commands/         # Tauri command layer (by domain)\n‚îÇ       ‚îú‚îÄ‚îÄ services/         # Business logic layer\n‚îÇ       ‚îú‚îÄ‚îÄ app_config.rs     # Config data models\n‚îÇ       ‚îú‚îÄ‚îÄ provider.rs       # Provider domain models\n‚îÇ       ‚îú‚îÄ‚îÄ mcp.rs            # MCP sync & validation\n‚îÇ       ‚îî‚îÄ‚îÄ lib.rs            # App entry & tray menu\n‚îú‚îÄ‚îÄ tests/                    # Frontend tests\n‚îÇ   ‚îú‚îÄ‚îÄ hooks/                # Unit tests\n‚îÇ   ‚îî‚îÄ‚îÄ components/           # Integration tests\n‚îî‚îÄ‚îÄ assets/                   # Screenshots & partner resources\n```\n\n## Changelog\n\nSee [CHANGELOG.md](CHANGELOG.md) for version update details.\n\n## Legacy Electron Version\n\n[Releases](../../releases) retains v2.0.3 legacy Electron version\n\nIf you need legacy Electron code, you can pull the electron-legacy branch\n\n## Contributing\n\nIssues and suggestions are welcome!\n\nBefore submitting PRs, please ensure:\n\n- Pass type check: `pnpm typecheck`\n- Pass format check: `pnpm format:check`\n- Pass unit tests: `pnpm test:unit`\n- üí° For new features, please open an issue for discussion before submitting a PR\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=farion1231/cc-switch&type=Date)](https://www.star-history.com/#farion1231/cc-switch&Date)\n\n## License\n\nMIT ¬© Jason Young\n",
      "stars_today": 244
    },
    {
      "id": 912559512,
      "name": "sim",
      "full_name": "simstudioai/sim",
      "description": "Open-source platform to build and deploy AI agent workflows.",
      "html_url": "https://github.com/simstudioai/sim",
      "stars": 26054,
      "forks": 3255,
      "language": "TypeScript",
      "topics": [
        "agent-workflow",
        "agentic-workflow",
        "agents",
        "ai",
        "aiagents",
        "anthropic",
        "artificial-intelligence",
        "automation",
        "chatbot",
        "deepseek",
        "gemini",
        "low-code",
        "nextjs",
        "no-code",
        "openai",
        "rag",
        "react",
        "typescript"
      ],
      "created_at": "2025-01-05T22:47:49Z",
      "updated_at": "2026-01-24T00:30:25Z",
      "pushed_at": "2026-01-24T01:48:43Z",
      "open_issues": 147,
      "owner": {
        "login": "simstudioai",
        "avatar_url": "https://avatars.githubusercontent.com/u/199344406?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://sim.ai\" target=\"_blank\" rel=\"noopener noreferrer\">\n    <img src=\"apps/sim/public/logo/reverse/text/large.png\" alt=\"Sim Logo\" width=\"500\"/>\n  </a>\n</p>\n\n<p align=\"center\">Build and deploy AI agent workflows in minutes.</p>\n\n<p align=\"center\">\n  <a href=\"https://sim.ai\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://img.shields.io/badge/sim.ai-6F3DFA\" alt=\"Sim.ai\"></a>\n  <a href=\"https://discord.gg/Hr4UWYEcTT\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://img.shields.io/badge/Discord-Join%20Server-5865F2?logo=discord&logoColor=white\" alt=\"Discord\"></a>\n  <a href=\"https://x.com/simdotai\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://img.shields.io/twitter/follow/simdotai?style=social\" alt=\"Twitter\"></a>\n  <a href=\"https://docs.sim.ai\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://img.shields.io/badge/Docs-6F3DFA.svg\" alt=\"Documentation\"></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://deepwiki.com/simstudioai/sim\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://deepwiki.com/badge.svg\" alt=\"Ask DeepWiki\"></a>  <a href=\"https://cursor.com/link/prompt?text=Help%20me%20set%20up%20Sim%20locally.%20Follow%20these%20steps%3A%0A%0A1.%20First%2C%20verify%20Docker%20is%20installed%20and%20running%3A%0A%20%20%20docker%20--version%0A%20%20%20docker%20info%0A%0A2.%20Clone%20the%20repository%3A%0A%20%20%20git%20clone%20https%3A%2F%2Fgithub.com%2Fsimstudioai%2Fsim.git%0A%20%20%20cd%20sim%0A%0A3.%20Start%20the%20services%20with%20Docker%20Compose%3A%0A%20%20%20docker%20compose%20-f%20docker-compose.prod.yml%20up%20-d%0A%0A4.%20Wait%20for%20all%20containers%20to%20be%20healthy%20(this%20may%20take%201-2%20minutes)%3A%0A%20%20%20docker%20compose%20-f%20docker-compose.prod.yml%20ps%0A%0A5.%20Verify%20the%20app%20is%20accessible%20at%20http%3A%2F%2Flocalhost%3A3000%0A%0AIf%20there%20are%20any%20errors%2C%20help%20me%20troubleshoot%20them.%20Common%20issues%3A%0A-%20Port%203000%2C%203002%2C%20or%205432%20already%20in%20use%0A-%20Docker%20not%20running%0A-%20Insufficient%20memory%20(needs%2012GB%2B%20RAM)%0A%0AFor%20local%20AI%20models%20with%20Ollama%2C%20use%20this%20instead%20of%20step%203%3A%0A%20%20%20docker%20compose%20-f%20docker-compose.ollama.yml%20--profile%20setup%20up%20-d\"><img src=\"https://img.shields.io/badge/Set%20Up%20with-Cursor-000000?logo=cursor&logoColor=white\" alt=\"Set Up with Cursor\"></a>\n</p>\n\n### Build Workflows with Ease\nDesign agent workflows visually on a canvas‚Äîconnect agents, tools, and blocks, then run them instantly.\n\n<p align=\"center\">\n  <img src=\"apps/sim/public/static/workflow.gif\" alt=\"Workflow Builder Demo\" width=\"800\"/>\n</p>\n\n### Supercharge with Copilot\nLeverage Copilot to generate nodes, fix errors, and iterate on flows directly from natural language.\n\n<p align=\"center\">\n  <img src=\"apps/sim/public/static/copilot.gif\" alt=\"Copilot Demo\" width=\"800\"/>\n</p>\n\n### Integrate Vector Databases\nUpload documents to a vector store and let agents answer questions grounded in your specific content.\n\n<p align=\"center\">\n  <img src=\"apps/sim/public/static/knowledge.gif\" alt=\"Knowledge Uploads and Retrieval Demo\" width=\"800\"/>\n</p>\n\n## Quickstart\n\n### Cloud-hosted: [sim.ai](https://sim.ai)\n\n<a href=\"https://sim.ai\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://img.shields.io/badge/sim.ai-6F3DFA?logo=data:image/svg%2bxml;base64,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&logoColor=white\" alt=\"Sim.ai\"></a>\n\n### Self-hosted: NPM Package\n\n```bash\nnpx simstudio\n```\n‚Üí http://localhost:3000\n\n#### Note\nDocker must be installed and running on your machine.\n\n#### Options\n\n| Flag | Description |\n|------|-------------|\n| `-p, --port <port>` | Port to run Sim on (default `3000`) |\n| `--no-pull` | Skip pulling latest Docker images |\n\n### Self-hosted: Docker Compose\n\n```bash\ngit clone https://github.com/simstudioai/sim.git && cd sim\ndocker compose -f docker-compose.prod.yml up -d\n```\n\nOpen [http://localhost:3000](http://localhost:3000)\n\n#### Using Local Models with Ollama\n\nRun Sim with local AI models using [Ollama](https://ollama.ai) - no external APIs required:\n\n```bash\n# Start with GPU support (automatically downloads gemma3:4b model)\ndocker compose -f docker-compose.ollama.yml --profile setup up -d\n\n# For CPU-only systems:\ndocker compose -f docker-compose.ollama.yml --profile cpu --profile setup up -d\n```\n\nWait for the model to download, then visit [http://localhost:3000](http://localhost:3000). Add more models with:\n```bash\ndocker compose -f docker-compose.ollama.yml exec ollama ollama pull llama3.1:8b\n```\n\n#### Using an External Ollama Instance\n\nIf Ollama is running on your host machine, use `host.docker.internal` instead of `localhost`:\n\n```bash\nOLLAMA_URL=http://host.docker.internal:11434 docker compose -f docker-compose.prod.yml up -d\n```\n\nOn Linux, use your host's IP address or add `extra_hosts: [\"host.docker.internal:host-gateway\"]` to the compose file.\n\n#### Using vLLM\n\nSim supports [vLLM](https://docs.vllm.ai/) for self-hosted models. Set `VLLM_BASE_URL` and optionally `VLLM_API_KEY` in your environment.\n\n### Self-hosted: Dev Containers\n\n1. Open VS Code with the [Remote - Containers extension](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers)\n2. Open the project and click \"Reopen in Container\" when prompted\n3. Run `bun run dev:full` in the terminal or use the `sim-start` alias\n   - This starts both the main application and the realtime socket server\n\n### Self-hosted: Manual Setup\n\n**Requirements:** [Bun](https://bun.sh/), [Node.js](https://nodejs.org/) v20+, PostgreSQL 12+ with [pgvector](https://github.com/pgvector/pgvector)\n\n1. Clone and install:\n\n```bash\ngit clone https://github.com/simstudioai/sim.git\ncd sim\nbun install\n```\n\n2. Set up PostgreSQL with pgvector:\n\n```bash\ndocker run --name simstudio-db -e POSTGRES_PASSWORD=your_password -e POSTGRES_DB=simstudio -p 5432:5432 -d pgvector/pgvector:pg17\n```\n\nOr install manually via the [pgvector guide](https://github.com/pgvector/pgvector#installation).\n\n3. Configure environment:\n\n```bash\ncp apps/sim/.env.example apps/sim/.env\ncp packages/db/.env.example packages/db/.env\n# Edit both .env files to set DATABASE_URL=\"postgresql://postgres:your_password@localhost:5432/simstudio\"\n```\n\n4. Run migrations:\n\n```bash\ncd packages/db && bunx drizzle-kit migrate --config=./drizzle.config.ts\n```\n\n5. Start development servers:\n\n```bash\nbun run dev:full  # Starts both Next.js app and realtime socket server\n```\n\nOr run separately: `bun run dev` (Next.js) and `cd apps/sim && bun run dev:sockets` (realtime).\n\n## Copilot API Keys\n\nCopilot is a Sim-managed service. To use Copilot on a self-hosted instance:\n\n- Go to https://sim.ai ‚Üí Settings ‚Üí Copilot and generate a Copilot API key\n- Set `COPILOT_API_KEY` environment variable in your self-hosted apps/sim/.env file to that value\n\n## Environment Variables\n\nKey environment variables for self-hosted deployments. See [`.env.example`](apps/sim/.env.example) for defaults or [`env.ts`](apps/sim/lib/core/config/env.ts) for the full list.\n\n| Variable | Required | Description |\n|----------|----------|-------------|\n| `DATABASE_URL` | Yes | PostgreSQL connection string with pgvector |\n| `BETTER_AUTH_SECRET` | Yes | Auth secret (`openssl rand -hex 32`) |\n| `BETTER_AUTH_URL` | Yes | Your app URL (e.g., `http://localhost:3000`) |\n| `NEXT_PUBLIC_APP_URL` | Yes | Public app URL (same as above) |\n| `ENCRYPTION_KEY` | Yes | Encrypts environment variables (`openssl rand -hex 32`) |\n| `INTERNAL_API_SECRET` | Yes | Encrypts internal API routes (`openssl rand -hex 32`) |\n| `API_ENCRYPTION_KEY` | Yes | Encrypts API keys (`openssl rand -hex 32`) |\n| `COPILOT_API_KEY` | No | API key from sim.ai for Copilot features |\n\n## Troubleshooting\n\n### Ollama models not showing in dropdown (Docker)\n\nIf you're running Ollama on your host machine and Sim in Docker, change `OLLAMA_URL` from `localhost` to `host.docker.internal`:\n\n```bash\nOLLAMA_URL=http://host.docker.internal:11434 docker compose -f docker-compose.prod.yml up -d\n```\n\nSee [Using an External Ollama Instance](#using-an-external-ollama-instance) for details.\n\n### Database connection issues\n\nEnsure PostgreSQL has the pgvector extension installed. When using Docker, wait for the database to be healthy before running migrations.\n\n### Port conflicts\n\nIf ports 3000, 3002, or 5432 are in use, configure alternatives:\n\n```bash\n# Custom ports\nNEXT_PUBLIC_APP_URL=http://localhost:3100 POSTGRES_PORT=5433 docker compose up -d\n```\n\n## Tech Stack\n\n- **Framework**: [Next.js](https://nextjs.org/) (App Router)\n- **Runtime**: [Bun](https://bun.sh/)\n- **Database**: PostgreSQL with [Drizzle ORM](https://orm.drizzle.team)\n- **Authentication**: [Better Auth](https://better-auth.com)\n- **UI**: [Shadcn](https://ui.shadcn.com/), [Tailwind CSS](https://tailwindcss.com)\n- **State Management**: [Zustand](https://zustand-demo.pmnd.rs/)\n- **Flow Editor**: [ReactFlow](https://reactflow.dev/)\n- **Docs**: [Fumadocs](https://fumadocs.vercel.app/)\n- **Monorepo**: [Turborepo](https://turborepo.org/)\n- **Realtime**: [Socket.io](https://socket.io/)\n- **Background Jobs**: [Trigger.dev](https://trigger.dev/)\n- **Remote Code Execution**: [E2B](https://www.e2b.dev/)\n\n## Contributing\n\nWe welcome contributions! Please see our [Contributing Guide](.github/CONTRIBUTING.md) for details.\n\n## License\n\nThis project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.\n\n<p align=\"center\">Made with ‚ù§Ô∏è by the Sim Team</p>\n",
      "stars_today": 191
    },
    {
      "id": 936473202,
      "name": "FlashMLA",
      "full_name": "deepseek-ai/FlashMLA",
      "description": "FlashMLA: Efficient Multi-head Latent Attention Kernels",
      "html_url": "https://github.com/deepseek-ai/FlashMLA",
      "stars": 12323,
      "forks": 963,
      "language": "C++",
      "topics": [],
      "created_at": "2025-02-21T06:31:27Z",
      "updated_at": "2026-01-24T02:03:40Z",
      "pushed_at": "2026-01-20T16:05:02Z",
      "open_issues": 84,
      "owner": {
        "login": "deepseek-ai",
        "avatar_url": "https://avatars.githubusercontent.com/u/148330874?v=4"
      },
      "readme": "# FlashMLA\n\n## Introduction\n\nFlashMLA is DeepSeek's library of optimized attention kernels, powering the [DeepSeek-V3](https://github.com/deepseek-ai/DeepSeek-V3) and [DeepSeek-V3.2-Exp](https://github.com/deepseek-ai/DeepSeek-V3.2-Exp) models. This repository contains the following implementations:\n\n**Sparse Attention Kernels**\n\n*These kernels power DeepSeek Sparse Attention (DSA), as introduced in [this paper](https://github.com/deepseek-ai/DeepSeek-V3.2-Exp).*\n\n- Token-level sparse attention for the prefill stage\n- Token-level sparse attention for the decoding stage, with FP8 KV cache\n\n**Dense Attention Kernels**\n\n- Dense attention for the prefill stage\n- Dense attention for the decoding stage\n\n## News\n\n- **2025.09.29 Release of Sparse Attention Kernels**: With the launch of [DeepSeek-V3.2](https://github.com/deepseek-ai/DeepSeek-V3.2-Exp), we are releasing the corresponding token-level sparse attention kernels. These kernels power the model's DeepSeek Sparse Attention (DSA) and achieve up to 640 TFlops during prefilling and 410 TFlops during decoding. We also release a deep-dive blog for our new FP8 sparse decoding kernel. Check it out [here](docs/20250929-hopper-fp8-sparse-deep-dive.md).\n- **2025.08.01 Kernels for MHA on SM100**: Thanks to [NVIDIA's PR](https://github.com/deepseek-ai/FlashMLA/pull/76) for MHA forward / backward kernels on SM100!\n- **2025.04.22 Deep-Dive Blog**: We'd love to share the technical details behind the new FlashMLA kernel! Check out our deep-dive write-up [here](docs/20250422-new-kernel-deep-dive.md).\n- **2025.04.22 Performance Update**: We're excited to announce the new release of Flash MLA, which delivers 5% ~ 15% performance improvement for compute-bound workloads, achieving up to 660 TFlops on NVIDIA H800 SXM5 GPUs. The interface of the new version is fully compatible with the old one. Simply upgrade to the new version for an immediate performance boost! üöÄüöÄüöÄ\n\n## Performance\n\n#### Test & benchmark MLA decoding (Sparse & Dense):\n\n```bash\npython tests/test_flash_mla_dense_decoding.py\npython tests/test_flash_mla_sparse_decoding.py\n```\n\nThe dense MLA decoding kernel achieves up to 3000 GB/s in memory-bound configuration and 660 TFLOPS in computation-bound configuration on H800 SXM5 with CUDA 12.8. The token-level sparse MLA decoding kernel (which uses an FP8 KV cache while performing the matrix multiplication in bfloat16) achieves 410 TFLOPS in compute-bound configuration on H800 SXM5 with CUDA 12.8, and achieves up to 350 TFlops on B200 (which is not really optimized yet).\n\n#### Test & benchmark MHA prefill (Dense):\n\n```bash\npython tests/test_fmha_sm100.py\n```\n\nIt achieves up to 1460 TFlops in forward and 1000 TFlops in backward computation on B200, as reported by NVIDIA.\n\n#### Test & benchmark MLA prefill (Sparse):\n\n```bash\npython tests/test_flash_mla_sparse_prefill.py\n```\n\nIt achieves up to 640 TFlops in forward computation on H800 SXM5 with CUDA 12.8, and achieves up to 1450 TFlops on B200, CUDA 12.9.\n\n## Requirements\n\n- SM90 / SM100 (See the support matrix below)\n- CUDA 12.8 and above (CUDA 12.9+ is required for SM100 kernels)\n- PyTorch 2.0 and above\n\nSupport matrix:\n\n| Kernel | GPU Architecture | MLA Mode [2] | KVCache Format |\n| :---: | :---: | :---: | :---: |\n| Dense Decoding | SM90 | MQA | BF16 |\n| Sparse Decoding | SM90 & SM100 | MQA | FP8 [1] |\n| Dense Prefill | SM100 | MHA |  |\n| Sparse Prefill | SM90 & SM100 | MQA |  |\n\n[1]: For more details on using FP8 KV cache, see documents below.\n\n[2]: Here \"MLA Mode\" refers to the mode used for MLA calculation. MQA stands for Multi-Query Attention mode (i.e. `head_dim_k` =  576 with `head_dim_v` = 512), while MHA stands for Multi-Head Attention mode (i.e. `head_dim_k` = 192 / 128 with `head_dim_v` = 128). For a detailed explanation of these modes, please refer to the appendix of [DeepSeek V3.2's Paper](https://github.com/deepseek-ai/DeepSeek-V3.2-Exp).\n\n## Installation\n\n```bash\ngit clone https://github.com/deepseek-ai/FlashMLA.git flash-mla\ncd flash-mla\ngit submodule update --init --recursive\npip install -v .\n```\n\n## Usage\n\n### MLA Decoding\n\nTo use the MLA decoding kernels, call get_mla_metadata once before the decoding loop to get the tile scheduler metadata. Then, call flash_mla_with_kvcache in each decoding step. For example:\n\n```python\nfrom flash_mla import get_mla_metadata, flash_mla_with_kvcache\n\ntile_scheduler_metadata, num_splits = get_mla_metadata(\n    cache_seqlens,\n    s_q * h_q // h_kv,\n    h_kv,\n    h_q,\n    is_fp8,\n    topk,\n)\n\nfor i in range(num_layers):\n    ...\n    o_i, lse_i = flash_mla_with_kvcache(\n        q_i, kvcache_i, block_table, cache_seqlens, dv,\n        tile_scheduler_metadata, num_splits,\n        is_causal, is_fp8_kvcache, indices,\n    )\n    ...\n```\n\nWhere\n\n- `s_q` is the number of q tokens per q sequence. If MTP (speculative decoding) is disabled, it should be 1.\n- `h_kv` is the number of key-value heads.\n- `h_q` is the number of query heads.\n\n**FP8 KV Cache:**\nIf `is_fp8_kvcache` is set to `True`, the kernel reads the KV cache in the \"FP8 with scale\" format (described below). It dequantizes the cache to bfloat16 and performs attention computation in bfloat16. The output is also in bfloat16.\n\nIn the \"FP8 with scale\" format, each token's KV cache is 656 Bytes, structured as:\n-   **First 512 bytes:** The \"quantized NoPE\" part, containing 512 `float8_e4m3` values.\n-   **Next 16 bytes:** Scale factors, containing 4 `float32` values. The first `float32` is the scale for the first 128 `float8_e4m3` values, the second for the next 128, and so on.\n-   **Last 128 bytes:** The \"RoPE\" part, containing 64 `bfloat16` values. This part is not quantized for accuracy.\n\nSee `tests/quant.py` for quantization and dequantization details.\n\n**Sparse Attention (`indices` tensor):**\nThe `indices` tensor (if provided) enables token-level sparse attention by instructing the kernel to compute attention only for specified tokens.\n\n-   **Shape:** `indices` should be a 3D tensor of shape `(batch_size, seq_len_q, topk)`.\n-   **Format:** `indices_in_kvcache[i][j][k] = (the index of the page block where token t resides) * page_block_size + (the offset of token t within the page block)`, where `t` is the k-th token for the j-th query sequence in the i-th batch. Since the index of the page block has already been encoded into `indices_in_kvcache`, the kernel does not require the `block_table` parameter.\n-   **Invalid entries:** Set invalid indices to `-1`.\n\n**Return Values:**\nThe kernel returns `(out, lse)`, where:\n-   `out` is the attention result.\n-   `lse` is the log-sum-exp value of the attention scores for each query head.\n\nSee `tests/test_flash_mla_decoding.py` for a complete example.\n\n### Sparse MLA Prefill\n\nFor the sparse MLA prefill kernel, call `flash_mla_sparse_fwd` directly with the following parameters:\n-   `q`: Query tensor of shape `[s_q, h_q, d_qk]`\n-   `kv`: Key-Value tensor of shape `[s_kv, h_kv, d_qk]`\n-   `indices`: Indices tensor of shape `[s_q, h_kv, topk]`\n-   `sm_scale`: A scalar value\n\n**Note on batching:** This kernel does not support a batch dimension. For multi-batch inference, reshape the input tensors and adjust the `indices` parameter to simulate batch processing.\n\n**Invalid indices:** Set invalid entries in `indices` to `-1` or any number `>= s_kv`.\n\n**Return Values and Equivalent PyTorch Code:**\nThe kernel returns `(out, max_logits, lse)`. This is equivalent to the following PyTorch operations:\n\n```python\nQ: [s_q, h_q, d_qk], bfloat16\nkv: [s_kv, h_kv, d_qk], bfloat16\nindices: [s_q, h_kv, topk], int32\n\nkv = kv.squeeze(1)  # [s_kv, d_qk], h_kv must be 1\nindices = indices.squeeze(1)    # [s_q, topk]\nfocused_kv = kv[indices]    # For the i-th sequence (s_q), the corresponding KV tokens are selected from the KV cache based on indices[i, :]. This operation results in a tensor of shape [s_q, topk, d_qk].\n\nP = (Q @ focused_kv.transpose(-1, -2)) * sm_scale * math.log2(math.e)    # [s_q, h_q, topk]\nmax_logits = P.max(dim=-1) # [s_q, h_q]\nlse = log2sumexp2(P, dim=-1, base=2)   # [s_q, h_q]Ôºå\"log2sumexp2\" means that the exponentiation and logarithm are base-2\nS = exp2(P - lse)      # [s_q, h_q, topk]\nout = S @ focused_kv  # [s_q, h_q, d_qk]\n\nreturn (out, max_logits, lse)\n```\n\nSee `tests/test_flash_mla_prefill.py` for a complete example.\n\n### Dense MHA Prefill\n\nThis kernel implements the standard dense Multi-Head Attention (MHA) forward and backward operations. It can be called using:\n-   `flash_attn_varlen_func`\n-   `flash_attn_varlen_qkvpacked_func`\n-   `flash_attn_varlen_kvpacked_func`\n\nThe usage is similar to the `flash_attn` package. See `tests/test_fmha_sm100.py` for a complete example.\n\n## Acknowledgement\n\nFlashMLA is inspired by [FlashAttention 2&3](https://github.com/dao-AILab/flash-attention/) and [cutlass](https://github.com/nvidia/cutlass) projects.\n\n## Community Support\n\n### MetaX\nFor MetaX GPUs, visit the official website: [MetaX](https://www.metax-tech.com).\n\nThe corresponding FlashMLA version can be found at: [MetaX-MACA/FlashMLA](https://github.com/MetaX-MACA/FlashMLA)\n\n\n### Moore Threads\nFor the Moore Threads GPU, visit the official website: [Moore Threads](https://www.mthreads.com/).\n\nThe corresponding FlashMLA version is available on GitHub: [MooreThreads/MT-flashMLA](https://github.com/MooreThreads/MT-flashMLA).\n\n\n### Hygon DCU\nFor the Hygon DCU, visit the official website: [Hygon Developer](https://developer.sourcefind.cn/).\n\nThe corresponding FlashMLA version is available here: [OpenDAS/MLAttention](https://developer.sourcefind.cn/codes/OpenDAS/MLAttention).\n\n\n### Intellifusion\nFor the Intellifusion NNP, visit the official website: [Intellifusion](https://www.intellif.com).\n\nThe corresponding FlashMLA version is available on Gitee: [Intellifusion/tyllm](https://gitee.com/Intellifusion_2025/tyllm/blob/master/python/tylang/flash_mla.py).\n\n\n### Iluvatar Corex\nFor Iluvatar Corex GPUs, visit the official website: [Iluvatar Corex](https://www.iluvatar.com).\n\nThe corresponding FlashMLA version is available on GitHub: [Deep-Spark/FlashMLA](https://github.com/Deep-Spark/FlashMLA/tree/iluvatar_flashmla)\n\n\n### AMD Instinct\nFor AMD Instinct GPUs, visit the official website: [AMD Instinct](https://www.amd.com/en/products/accelerators/instinct.html).\n\nThe corresponding FlashMLA version can be found at: [AITER/MLA](https://github.com/ROCm/aiter/blob/main/aiter/mla.py)\n\n## Citation\n\n```bibtex\n@misc{flashmla2025,\n      title={FlashMLA: Efficient Multi-head Latent Attention Kernels},\n      author={Jiashi Li, Shengyu Liu},\n      year={2025},\n      publisher = {GitHub},\n      howpublished = {\\url{https://github.com/deepseek-ai/FlashMLA}},\n}\n```\n",
      "stars_today": 184
    },
    {
      "id": 1000362065,
      "name": "awesome-copilot",
      "full_name": "github/awesome-copilot",
      "description": "Community-contributed instructions, prompts, and configurations to help you make the most of GitHub Copilot.",
      "html_url": "https://github.com/github/awesome-copilot",
      "stars": 18721,
      "forks": 2142,
      "language": "JavaScript",
      "topics": [
        "ai",
        "github-copilot",
        "hacktoberfest",
        "prompt-engineering"
      ],
      "created_at": "2025-06-11T16:57:39Z",
      "updated_at": "2026-01-24T01:37:26Z",
      "pushed_at": "2026-01-23T00:07:45Z",
      "open_issues": 13,
      "owner": {
        "login": "github",
        "avatar_url": "https://avatars.githubusercontent.com/u/9919?v=4"
      },
      "readme": "# ü§ñ Awesome GitHub Copilot Customizations\n[![Powered by Awesome Copilot](https://img.shields.io/badge/Powered_by-Awesome_Copilot-blue?logo=githubcopilot)](https://aka.ms/awesome-github-copilot) [![GitHub contributors from allcontributors.org](https://img.shields.io/github/all-contributors/github/awesome-copilot?color=ee8449)](#contributors-)\n\n\nA community created collection of custom agents, prompts, and instructions to supercharge your GitHub Copilot experience across different domains, languages, and use cases.\n\n## üöÄ What is Awesome GitHub Copilot?\n\nThis repository provides a comprehensive toolkit for enhancing GitHub Copilot with specialized:\n\n- **üëâ [Awesome Agents](docs/README.agents.md)** - Specialized GitHub Copilot agents that integrate with MCP servers to provide enhanced capabilities for specific workflows and tools\n- **üëâ [Awesome Prompts](docs/README.prompts.md)** - Focused, task-specific prompts for generating code, documentation, and solving specific problems\n- **üëâ [Awesome Instructions](docs/README.instructions.md)** - Comprehensive coding standards and best practices that apply to specific file patterns or entire projects\n- **üëâ [Awesome Skills](docs/README.skills.md)** - Self-contained folders with instructions and bundled resources that enhance AI capabilities for specialized tasks\n- **üëâ [Awesome Collections](docs/README.collections.md)** - Curated collections of related prompts, instructions, agents, and skills organized around specific themes and workflows\n\n## üåü Featured Collections\n\nDiscover our curated collections of prompts, instructions, and agents organized around specific themes and workflows.\n\n| Name | Description | Items | Tags |\n| ---- | ----------- | ----- | ---- |\n| [Awesome Copilot](collections/awesome-copilot.md) | Meta prompts that help you discover and generate curated GitHub Copilot agents, collections, instructions, prompts, and skills. | 5 items | github-copilot, discovery, meta, prompt-engineering, agents |\n| [Copilot SDK](collections/copilot-sdk.md) | Build applications with the GitHub Copilot SDK across multiple programming languages. Includes comprehensive instructions for C#, Go, Node.js/TypeScript, and Python to help you create AI-powered applications. | 4 items | copilot-sdk, sdk, csharp, go, nodejs, typescript, python, ai, github-copilot |\n| [Partners](collections/partners.md) | Custom agents that have been created by GitHub partners | 20 items | devops, security, database, cloud, infrastructure, observability, feature-flags, cicd, migration, performance |\n\n\n## MCP Server\n\nTo make it easy to add these customizations to your editor, we have created a [MCP Server](https://developer.microsoft.com/blog/announcing-awesome-copilot-mcp-server) that provides a prompt for searching and installing prompts, instructions, agents, and skills directly from this repository. You'll need to have Docker installed and running to run the server.\n\n[![Install in VS Code](https://img.shields.io/badge/VS_Code-Install-0098FF?logo=visualstudiocode&logoColor=white)](https://aka.ms/awesome-copilot/mcp/vscode) [![Install in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install-24bfa5?logo=visualstudiocode&logoColor=white)](https://aka.ms/awesome-copilot/mcp/vscode-insiders) [![Install in Visual Studio](https://img.shields.io/badge/Visual_Studio-Install-C16FDE?logo=visualstudio&logoColor=white)](https://aka.ms/awesome-copilot/mcp/vs)\n\n<details>\n<summary>Show MCP Server JSON configuration</summary>\n\n```json\n{\n  \"servers\": {\n    \"awesome-copilot\": {\n      \"type\": \"stdio\",\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"ghcr.io/microsoft/mcp-dotnet-samples/awesome-copilot:latest\"\n      ]\n    }\n  }\n}\n```\n\n</details>\n\n## üîß How to Use\n\n### ü§ñ Custom Agents\n\nCustom agents can be used in Copilot coding agent (CCA), VS Code, and Copilot CLI (coming soon). For CCA, when assigning an issue to Copilot, select the custom agent from the provided list. In VS Code, you can activate the custom agent in the agents session, alongside built-in agents like Plan and Agent.\n\n### üéØ Prompts\n\nUse the `/` command in GitHub Copilot Chat to access prompts:\n\n```plaintext\n/awesome-copilot create-readme\n```\n\n### üìã Instructions\n\nInstructions automatically apply to files based on their patterns and provide contextual guidance for coding standards, frameworks, and best practices.\n\n## üéØ Why Use Awesome GitHub Copilot?\n\n- **Productivity**: Pre-built agents, prompts and instructions save time and provide consistent results.\n- **Best Practices**: Benefit from community-curated coding standards and patterns.\n- **Specialized Assistance**: Access expert-level guidance through specialized custom agents.\n- **Continuous Learning**: Stay updated with the latest patterns and practices across technologies.\n\n## ü§ù Contributing\n\nWe welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details on how to:\n\n- Add new prompts, instructions, agents, or skills\n- Improve existing content\n- Report issues or suggest enhancements\n\nFor AI coding agents working with this project, refer to [AGENTS.md](AGENTS.md) for detailed technical guidance on development workflows, setup commands, and contribution standards.\n\n### Quick Contribution Guide\n\n1. Follow our file naming conventions and frontmatter requirements\n2. Test your contributions thoroughly\n3. Update the appropriate README tables\n4. Submit a pull request with a clear description\n\n## üìñ Repository Structure\n\n```plaintext\n‚îú‚îÄ‚îÄ prompts/          # Task-specific prompts (.prompt.md)\n‚îú‚îÄ‚îÄ instructions/     # Coding standards and best practices (.instructions.md)\n‚îú‚îÄ‚îÄ agents/           # AI personas and specialized modes (.agent.md)\n‚îú‚îÄ‚îÄ collections/      # Curated collections of related items (.collection.yml)\n‚îú‚îÄ‚îÄ scripts/          # Utility scripts for maintenance\n‚îî‚îÄ‚îÄ skills/           # AI capabilities for specialized tasks\n```\n\n## üìÑ License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## üõ°Ô∏è Security & Support\n\n- **Security Issues**: Please see our [Security Policy](SECURITY.md)\n- **Support**: Check our [Support Guide](SUPPORT.md) for getting help\n- **Code of Conduct**: We follow the [Contributor Covenant](CODE_OF_CONDUCT.md)\n\n## ‚ÑπÔ∏è Disclaimer\n\nThe customizations in this repository are sourced from and created by third-party developers. GitHub does not verify, endorse, or guarantee the functionality or security of these agents. Please carefully inspect any agent and its documentation before installing to understand permissions it may require and actions it may perform.\n\n---\n\n**Ready to supercharge your coding experience?** Start exploring our [prompts](docs/README.prompts.md), [instructions](docs/README.instructions.md), and [custom agents](docs/README.agents.md)!\n\n## Contributors ‚ú®\n\nThanks goes to these wonderful people ([emoji key](./CONTRIBUTING.md#contributors-recognition)):\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.aaron-powell.com/\"><img src=\"https://avatars.githubusercontent.com/u/434140?v=4?s=100\" width=\"100px;\" alt=\"Aaron Powell\"/><br /><sub><b>Aaron Powell</b></sub></a><br /><a href=\"#agents-aaronpowell\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=aaronpowell\" title=\"Code\">üíª</a> <a href=\"#collections-aaronpowell\" title=\"Curated collections of related content\">üéÅ</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=aaronpowell\" title=\"Documentation\">üìñ</a> <a href=\"#infra-aaronpowell\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">üöá</a> <a href=\"#instructions-aaronpowell\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#maintenance-aaronpowell\" title=\"Maintenance\">üöß</a> <a href=\"#prompts-aaronpowell\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://codemilltech.com/\"><img src=\"https://avatars.githubusercontent.com/u/2053639?v=4?s=100\" width=\"100px;\" alt=\"Matt Soucoup\"/><br /><sub><b>Matt Soucoup</b></sub></a><br /><a href=\"#infra-codemillmatt\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">üöá</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.buymeacoffee.com/troystaylor\"><img src=\"https://avatars.githubusercontent.com/u/44444967?v=4?s=100\" width=\"100px;\" alt=\"Troy Simeon Taylor\"/><br /><sub><b>Troy Simeon Taylor</b></sub></a><br /><a href=\"#agents-troystaylor\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#collections-troystaylor\" title=\"Curated collections of related content\">üéÅ</a> <a href=\"#instructions-troystaylor\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-troystaylor\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/abbas133\"><img src=\"https://avatars.githubusercontent.com/u/7757139?v=4?s=100\" width=\"100px;\" alt=\"Abbas\"/><br /><sub><b>Abbas</b></sub></a><br /><a href=\"#agents-abbas133\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-abbas133\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://calva.io/\"><img src=\"https://avatars.githubusercontent.com/u/30010?v=4?s=100\" width=\"100px;\" alt=\"Peter Str√∂mberg\"/><br /><sub><b>Peter Str√∂mberg</b></sub></a><br /><a href=\"#agents-PEZ\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#collections-PEZ\" title=\"Curated collections of related content\">üéÅ</a> <a href=\"#instructions-PEZ\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-PEZ\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://danielscottraynsford.com/\"><img src=\"https://avatars.githubusercontent.com/u/7589164?v=4?s=100\" width=\"100px;\" alt=\"Daniel Scott-Raynsford\"/><br /><sub><b>Daniel Scott-Raynsford</b></sub></a><br /><a href=\"#agents-PlagueHO\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#collections-PlagueHO\" title=\"Curated collections of related content\">üéÅ</a> <a href=\"#instructions-PlagueHO\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-PlagueHO\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jhauga\"><img src=\"https://avatars.githubusercontent.com/u/10998676?v=4?s=100\" width=\"100px;\" alt=\"John Haugabook\"/><br /><sub><b>John Haugabook</b></sub></a><br /><a href=\"#instructions-jhauga\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-jhauga\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://witter.cz/@pavel\"><img src=\"https://avatars.githubusercontent.com/u/7853836?v=4?s=100\" width=\"100px;\" alt=\"Pavel Simsa\"/><br /><sub><b>Pavel Simsa</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=psimsa\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://digitarald.de/\"><img src=\"https://avatars.githubusercontent.com/u/8599?v=4?s=100\" width=\"100px;\" alt=\"Harald Kirschner\"/><br /><sub><b>Harald Kirschner</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=digitarald\" title=\"Code\">üíª</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=digitarald\" title=\"Documentation\">üìñ</a> <a href=\"#maintenance-digitarald\" title=\"Maintenance\">üöß</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://mubaidr.js.org/\"><img src=\"https://avatars.githubusercontent.com/u/2222702?v=4?s=100\" width=\"100px;\" alt=\"Muhammad Ubaid Raza\"/><br /><sub><b>Muhammad Ubaid Raza</b></sub></a><br /><a href=\"#agents-mubaidr\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-mubaidr\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tmeschter\"><img src=\"https://avatars.githubusercontent.com/u/10506730?v=4?s=100\" width=\"100px;\" alt=\"Tom Meschter\"/><br /><sub><b>Tom Meschter</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=tmeschter\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.aungmyokyaw.com/\"><img src=\"https://avatars.githubusercontent.com/u/9404824?v=4?s=100\" width=\"100px;\" alt=\"Aung Myo Kyaw\"/><br /><sub><b>Aung Myo Kyaw</b></sub></a><br /><a href=\"#agents-AungMyoKyaw\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#prompts-AungMyoKyaw\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/JasonYeMSFT\"><img src=\"https://avatars.githubusercontent.com/u/39359541?v=4?s=100\" width=\"100px;\" alt=\"JasonYeMSFT\"/><br /><sub><b>JasonYeMSFT</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=JasonYeMSFT\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/jrc356/\"><img src=\"https://avatars.githubusercontent.com/u/37387479?v=4?s=100\" width=\"100px;\" alt=\"Jon Corbin\"/><br /><sub><b>Jon Corbin</b></sub></a><br /><a href=\"#agents-Jrc356\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#prompts-Jrc356\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/troytaylor-msft\"><img src=\"https://avatars.githubusercontent.com/u/248058374?v=4?s=100\" width=\"100px;\" alt=\"troytaylor-msft\"/><br /><sub><b>troytaylor-msft</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=troytaylor-msft\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://delatorre.dev/\"><img src=\"https://avatars.githubusercontent.com/u/38289677?v=4?s=100\" width=\"100px;\" alt=\"Emerson Delatorre\"/><br /><sub><b>Emerson Delatorre</b></sub></a><br /><a href=\"#instructions-fazedordecodigo\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/burkeholland\"><img src=\"https://avatars.githubusercontent.com/u/686963?v=4?s=100\" width=\"100px;\" alt=\"Burke Holland\"/><br /><sub><b>Burke Holland</b></sub></a><br /><a href=\"#agents-burkeholland\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#infra-burkeholland\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">üöá</a> <a href=\"#instructions-burkeholland\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-burkeholland\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://yaooqinn.github.io/\"><img src=\"https://avatars.githubusercontent.com/u/8326978?v=4?s=100\" width=\"100px;\" alt=\"Kent Yao\"/><br /><sub><b>Kent Yao</b></sub></a><br /><a href=\"#instructions-yaooqinn\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-yaooqinn\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.devprodlogs.com/\"><img src=\"https://avatars.githubusercontent.com/u/51440732?v=4?s=100\" width=\"100px;\" alt=\"Daniel Meppiel\"/><br /><sub><b>Daniel Meppiel</b></sub></a><br /><a href=\"#prompts-danielmeppiel\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/yeelam-gordon\"><img src=\"https://avatars.githubusercontent.com/u/73506701?v=4?s=100\" width=\"100px;\" alt=\"Gordon Lam\"/><br /><sub><b>Gordon Lam</b></sub></a><br /><a href=\"#instructions-yeelam-gordon\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.madskristensen.net/\"><img src=\"https://avatars.githubusercontent.com/u/1258877?v=4?s=100\" width=\"100px;\" alt=\"Mads Kristensen\"/><br /><sub><b>Mads Kristensen</b></sub></a><br /><a href=\"#instructions-madskristensen\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://ks6088ts.github.io/\"><img src=\"https://avatars.githubusercontent.com/u/1254960?v=4?s=100\" width=\"100px;\" alt=\"Shinji Takenaka\"/><br /><sub><b>Shinji Takenaka</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=ks6088ts\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/spectatora\"><img src=\"https://avatars.githubusercontent.com/u/1385755?v=4?s=100\" width=\"100px;\" alt=\"spectatora\"/><br /><sub><b>spectatora</b></sub></a><br /><a href=\"#agents-spectatora\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=spectatora\" title=\"Code\">üíª</a> <a href=\"#maintenance-spectatora\" title=\"Maintenance\">üöß</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sinedied\"><img src=\"https://avatars.githubusercontent.com/u/593151?v=4?s=100\" width=\"100px;\" alt=\"Yohan Lasorsa\"/><br /><sub><b>Yohan Lasorsa</b></sub></a><br /><a href=\"#instructions-sinedied\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-sinedied\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/VamshiVerma\"><img src=\"https://avatars.githubusercontent.com/u/21999324?v=4?s=100\" width=\"100px;\" alt=\"Vamshi Verma\"/><br /><sub><b>Vamshi Verma</b></sub></a><br /><a href=\"#instructions-VamshiVerma\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-VamshiVerma\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://montemagno.com/\"><img src=\"https://avatars.githubusercontent.com/u/1676321?v=4?s=100\" width=\"100px;\" alt=\"James Montemagno\"/><br /><sub><b>James Montemagno</b></sub></a><br /><a href=\"#agents-jamesmontemagno\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=jamesmontemagno\" title=\"Documentation\">üìñ</a> <a href=\"#instructions-jamesmontemagno\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-jamesmontemagno\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/alefragnani\"><img src=\"https://avatars.githubusercontent.com/u/3781424?v=4?s=100\" width=\"100px;\" alt=\"Alessandro Fragnani\"/><br /><sub><b>Alessandro Fragnani</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=alefragnani\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/ambilykk/\"><img src=\"https://avatars.githubusercontent.com/u/10282550?v=4?s=100\" width=\"100px;\" alt=\"Ambily\"/><br /><sub><b>Ambily</b></sub></a><br /><a href=\"#agents-ambilykk\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-ambilykk\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/krushideep\"><img src=\"https://avatars.githubusercontent.com/u/174652083?v=4?s=100\" width=\"100px;\" alt=\"krushideep\"/><br /><sub><b>krushideep</b></sub></a><br /><a href=\"#prompts-krushideep\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mihsoft\"><img src=\"https://avatars.githubusercontent.com/u/53946345?v=4?s=100\" width=\"100px;\" alt=\"devopsfan\"/><br /><sub><b>devopsfan</b></sub></a><br /><a href=\"#agents-mihsoft\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://tgrall.github.io/\"><img src=\"https://avatars.githubusercontent.com/u/541250?v=4?s=100\" width=\"100px;\" alt=\"Tugdual Grall\"/><br /><sub><b>Tugdual Grall</b></sub></a><br /><a href=\"#instructions-tgrall\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-tgrall\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.promptboost.dev/\"><img src=\"https://avatars.githubusercontent.com/u/5461862?v=4?s=100\" width=\"100px;\" alt=\"Oren Me\"/><br /><sub><b>Oren Me</b></sub></a><br /><a href=\"#agents-OrenMe\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-OrenMe\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mjrousos\"><img src=\"https://avatars.githubusercontent.com/u/10077254?v=4?s=100\" width=\"100px;\" alt=\"Mike Rousos\"/><br /><sub><b>Mike Rousos</b></sub></a><br /><a href=\"#instructions-mjrousos\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-mjrousos\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://devkimchi.com/\"><img src=\"https://avatars.githubusercontent.com/u/1538528?v=4?s=100\" width=\"100px;\" alt=\"Justin Yoo\"/><br /><sub><b>Justin Yoo</b></sub></a><br /><a href=\"#instructions-justinyoo\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/guiopen\"><img src=\"https://avatars.githubusercontent.com/u/94094527?v=4?s=100\" width=\"100px;\" alt=\"Guilherme do Amaral Alves \"/><br /><sub><b>Guilherme do Amaral Alves </b></sub></a><br /><a href=\"#instructions-guiopen\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/griffinashe/\"><img src=\"https://avatars.githubusercontent.com/u/6391612?v=4?s=100\" width=\"100px;\" alt=\"Griffin Ashe\"/><br /><sub><b>Griffin Ashe</b></sub></a><br /><a href=\"#agents-griffinashe\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#collections-griffinashe\" title=\"Curated collections of related content\">üéÅ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/anchildress1\"><img src=\"https://avatars.githubusercontent.com/u/6563688?v=4?s=100\" width=\"100px;\" alt=\"Ashley Childress\"/><br /><sub><b>Ashley Childress</b></sub></a><br /><a href=\"#agents-anchildress1\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=anchildress1\" title=\"Documentation\">üìñ</a> <a href=\"#instructions-anchildress1\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#infra-anchildress1\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">üöá</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=anchildress1\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.senseof.tech/\"><img src=\"https://avatars.githubusercontent.com/u/50712277?v=4?s=100\" width=\"100px;\" alt=\"Adrien Clerbois\"/><br /><sub><b>Adrien Clerbois</b></sub></a><br /><a href=\"#agents-AClerbois\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=AClerbois\" title=\"Documentation\">üìñ</a> <a href=\"#prompts-AClerbois\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Vhivi\"><img src=\"https://avatars.githubusercontent.com/u/38220028?v=4?s=100\" width=\"100px;\" alt=\"ANGELELLI David\"/><br /><sub><b>ANGELELLI David</b></sub></a><br /><a href=\"#agents-Vhivi\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://markdav.is/\"><img src=\"https://avatars.githubusercontent.com/u/311063?v=4?s=100\" width=\"100px;\" alt=\"Mark Davis\"/><br /><sub><b>Mark Davis</b></sub></a><br /><a href=\"#instructions-markdav-is\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/MattVevang\"><img src=\"https://avatars.githubusercontent.com/u/20714898?v=4?s=100\" width=\"100px;\" alt=\"Matt Vevang\"/><br /><sub><b>Matt Vevang</b></sub></a><br /><a href=\"#instructions-MattVevang\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://max.irro.at/\"><img src=\"https://avatars.githubusercontent.com/u/589073?v=4?s=100\" width=\"100px;\" alt=\"Maximilian Irro\"/><br /><sub><b>Maximilian Irro</b></sub></a><br /><a href=\"#instructions-mpgirro\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nullchimp\"><img src=\"https://avatars.githubusercontent.com/u/58362593?v=4?s=100\" width=\"100px;\" alt=\"NULLchimp\"/><br /><sub><b>NULLchimp</b></sub></a><br /><a href=\"#agents-nullchimp\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pkarda\"><img src=\"https://avatars.githubusercontent.com/u/12649718?v=4?s=100\" width=\"100px;\" alt=\"Peter Karda\"/><br /><sub><b>Peter Karda</b></sub></a><br /><a href=\"#prompts-pkarda\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sdolgin\"><img src=\"https://avatars.githubusercontent.com/u/576449?v=4?s=100\" width=\"100px;\" alt=\"Saul Dolgin\"/><br /><sub><b>Saul Dolgin</b></sub></a><br /><a href=\"#agents-sdolgin\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-sdolgin\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-sdolgin\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/shubham070\"><img src=\"https://avatars.githubusercontent.com/u/5480589?v=4?s=100\" width=\"100px;\" alt=\"Shubham Gaikwad\"/><br /><sub><b>Shubham Gaikwad</b></sub></a><br /><a href=\"#agents-shubham070\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-shubham070\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-shubham070\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/TheovanKraay\"><img src=\"https://avatars.githubusercontent.com/u/24420698?v=4?s=100\" width=\"100px;\" alt=\"Theo van Kraay\"/><br /><sub><b>Theo van Kraay</b></sub></a><br /><a href=\"#instructions-TheovanKraay\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/TianqiZhang\"><img src=\"https://avatars.githubusercontent.com/u/5326582?v=4?s=100\" width=\"100px;\" alt=\"Tianqi Zhang\"/><br /><sub><b>Tianqi Zhang</b></sub></a><br /><a href=\"#agents-TianqiZhang\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://blog.miniasp.com/\"><img src=\"https://avatars.githubusercontent.com/u/88981?v=4?s=100\" width=\"100px;\" alt=\"Will ‰øùÂì•\"/><br /><sub><b>Will ‰øùÂì•</b></sub></a><br /><a href=\"#agents-doggy8088\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#prompts-doggy8088\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://tsubalog.hatenablog.com/\"><img src=\"https://avatars.githubusercontent.com/u/1592808?v=4?s=100\" width=\"100px;\" alt=\"Yuta Matsumura\"/><br /><sub><b>Yuta Matsumura</b></sub></a><br /><a href=\"#instructions-tsubakimoto\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/anschnapp\"><img src=\"https://avatars.githubusercontent.com/u/17565996?v=4?s=100\" width=\"100px;\" alt=\"anschnapp\"/><br /><sub><b>anschnapp</b></sub></a><br /><a href=\"#agents-anschnapp\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/hizahizi-hizumi\"><img src=\"https://avatars.githubusercontent.com/u/163728895?v=4?s=100\" width=\"100px;\" alt=\"hizahizi-hizumi\"/><br /><sub><b>hizahizi-hizumi</b></sub></a><br /><a href=\"#instructions-hizahizi-hizumi\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://jianminhuang.cc/\"><img src=\"https://avatars.githubusercontent.com/u/6296280?v=4?s=100\" width=\"100px;\" alt=\"ÈªÉÂÅ•Êóª Vincent Huang\"/><br /><sub><b>ÈªÉÂÅ•Êóª Vincent Huang</b></sub></a><br /><a href=\"#prompts-Jian-Min-Huang\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://brunoborges.io/\"><img src=\"https://avatars.githubusercontent.com/u/129743?v=4?s=100\" width=\"100px;\" alt=\"Bruno Borges\"/><br /><sub><b>Bruno Borges</b></sub></a><br /><a href=\"#collections-brunoborges\" title=\"Curated collections of related content\">üéÅ</a> <a href=\"#instructions-brunoborges\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.movinglive.ca/\"><img src=\"https://avatars.githubusercontent.com/u/14792628?v=4?s=100\" width=\"100px;\" alt=\"Steve Magne\"/><br /><sub><b>Steve Magne</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=MovingLive\" title=\"Documentation\">üìñ</a> <a href=\"#instructions-MovingLive\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://shaneneuville.com/\"><img src=\"https://avatars.githubusercontent.com/u/5375137?v=4?s=100\" width=\"100px;\" alt=\"Shane Neuville\"/><br /><sub><b>Shane Neuville</b></sub></a><br /><a href=\"#agents-PureWeen\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-PureWeen\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://asilva.dev/\"><img src=\"https://avatars.githubusercontent.com/u/2493377?v=4?s=100\" width=\"100px;\" alt=\"Andr√© Silva\"/><br /><sub><b>Andr√© Silva</b></sub></a><br /><a href=\"#agents-askpt\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-askpt\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/agreaves-ms\"><img src=\"https://avatars.githubusercontent.com/u/111466195?v=4?s=100\" width=\"100px;\" alt=\"Allen Greaves\"/><br /><sub><b>Allen Greaves</b></sub></a><br /><a href=\"#agents-agreaves-ms\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-agreaves-ms\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/AmeliaRose802\"><img src=\"https://avatars.githubusercontent.com/u/26167931?v=4?s=100\" width=\"100px;\" alt=\"Amelia Payne\"/><br /><sub><b>Amelia Payne</b></sub></a><br /><a href=\"#agents-AmeliaRose802\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/BBoyBen\"><img src=\"https://avatars.githubusercontent.com/u/34445365?v=4?s=100\" width=\"100px;\" alt=\"BBoyBen\"/><br /><sub><b>BBoyBen</b></sub></a><br /><a href=\"#instructions-BBoyBen\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://azureincubations.io/\"><img src=\"https://avatars.githubusercontent.com/u/45323234?v=4?s=100\" width=\"100px;\" alt=\"Brooke Hamilton\"/><br /><sub><b>Brooke Hamilton</b></sub></a><br /><a href=\"#instructions-brooke-hamilton\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/GeekTrainer\"><img src=\"https://avatars.githubusercontent.com/u/6109729?v=4?s=100\" width=\"100px;\" alt=\"Christopher Harrison\"/><br /><sub><b>Christopher Harrison</b></sub></a><br /><a href=\"#instructions-GeekTrainer\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/breakid\"><img src=\"https://avatars.githubusercontent.com/u/1446918?v=4?s=100\" width=\"100px;\" alt=\"Dan\"/><br /><sub><b>Dan</b></sub></a><br /><a href=\"#instructions-breakid\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://blog.codewithdan.com/\"><img src=\"https://avatars.githubusercontent.com/u/1767249?v=4?s=100\" width=\"100px;\" alt=\"Dan Wahlin\"/><br /><sub><b>Dan Wahlin</b></sub></a><br /><a href=\"#agents-DanWahlin\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://debbie.codes/\"><img src=\"https://avatars.githubusercontent.com/u/13063165?v=4?s=100\" width=\"100px;\" alt=\"Debbie O'Brien\"/><br /><sub><b>Debbie O'Brien</b></sub></a><br /><a href=\"#agents-debs-obrien\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-debs-obrien\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-debs-obrien\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/echarrod\"><img src=\"https://avatars.githubusercontent.com/u/1381991?v=4?s=100\" width=\"100px;\" alt=\"Ed Harrod\"/><br /><sub><b>Ed Harrod</b></sub></a><br /><a href=\"#prompts-echarrod\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://learn.microsoft.com/dotnet\"><img src=\"https://avatars.githubusercontent.com/u/24882762?v=4?s=100\" width=\"100px;\" alt=\"Genevieve Warren\"/><br /><sub><b>Genevieve Warren</b></sub></a><br /><a href=\"#prompts-gewarren\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/guigui42\"><img src=\"https://avatars.githubusercontent.com/u/2376010?v=4?s=100\" width=\"100px;\" alt=\"Guillaume\"/><br /><sub><b>Guillaume</b></sub></a><br /><a href=\"#agents-guigui42\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#prompts-guigui42\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/riqueufmg\"><img src=\"https://avatars.githubusercontent.com/u/108551585?v=4?s=100\" width=\"100px;\" alt=\"Henrique Nunes\"/><br /><sub><b>Henrique Nunes</b></sub></a><br /><a href=\"#prompts-riqueufmg\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jeremiah-snee-openx\"><img src=\"https://avatars.githubusercontent.com/u/113928685?v=4?s=100\" width=\"100px;\" alt=\"Jeremiah Snee\"/><br /><sub><b>Jeremiah Snee</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=jeremiah-snee-openx\" title=\"Code\">üíª</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kartikdhiman\"><img src=\"https://avatars.githubusercontent.com/u/59189590?v=4?s=100\" width=\"100px;\" alt=\"Kartik Dhiman\"/><br /><sub><b>Kartik Dhiman</b></sub></a><br /><a href=\"#instructions-kartikdhiman\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://kristiyanvelkov.com/\"><img src=\"https://avatars.githubusercontent.com/u/40764277?v=4?s=100\" width=\"100px;\" alt=\"Kristiyan Velkov\"/><br /><sub><b>Kristiyan Velkov</b></sub></a><br /><a href=\"#agents-kristiyan-velkov\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/msalaman\"><img src=\"https://avatars.githubusercontent.com/u/28122166?v=4?s=100\" width=\"100px;\" alt=\"msalaman\"/><br /><sub><b>msalaman</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=msalaman\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://soderlind.no/\"><img src=\"https://avatars.githubusercontent.com/u/1649452?v=4?s=100\" width=\"100px;\" alt=\"Per S√∏derlind\"/><br /><sub><b>Per S√∏derlind</b></sub></a><br /><a href=\"#instructions-soderlind\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://dotneteers.net/\"><img src=\"https://avatars.githubusercontent.com/u/28162552?v=4?s=100\" width=\"100px;\" alt=\"Peter Smulovics\"/><br /><sub><b>Peter Smulovics</b></sub></a><br /><a href=\"#instructions-psmulovics\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/madvimer\"><img src=\"https://avatars.githubusercontent.com/u/3188898?v=4?s=100\" width=\"100px;\" alt=\"Ravish Rathod\"/><br /><sub><b>Ravish Rathod</b></sub></a><br /><a href=\"#instructions-madvimer\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://ricksm.it/\"><img src=\"https://avatars.githubusercontent.com/u/7207783?v=4?s=100\" width=\"100px;\" alt=\"Rick Smit\"/><br /><sub><b>Rick Smit</b></sub></a><br /><a href=\"#agents-ricksmit3000\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pertrai1\"><img src=\"https://avatars.githubusercontent.com/u/442374?v=4?s=100\" width=\"100px;\" alt=\"Rob Simpson\"/><br /><sub><b>Rob Simpson</b></sub></a><br /><a href=\"#instructions-pertrai1\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/inquinity\"><img src=\"https://avatars.githubusercontent.com/u/406234?v=4?s=100\" width=\"100px;\" alt=\"Robert Altman\"/><br /><sub><b>Robert Altman</b></sub></a><br /><a href=\"#instructions-inquinity\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://salih.guru/\"><img src=\"https://avatars.githubusercontent.com/u/76786120?v=4?s=100\" width=\"100px;\" alt=\"Salih\"/><br /><sub><b>Salih</b></sub></a><br /><a href=\"#instructions-salihguru\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://graef.io/\"><img src=\"https://avatars.githubusercontent.com/u/19261257?v=4?s=100\" width=\"100px;\" alt=\"Sebastian Gr√§f\"/><br /><sub><b>Sebastian Gr√§f</b></sub></a><br /><a href=\"#agents-segraef\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-segraef\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/SebastienDegodez\"><img src=\"https://avatars.githubusercontent.com/u/2349146?v=4?s=100\" width=\"100px;\" alt=\"Sebastien DEGODEZ\"/><br /><sub><b>Sebastien DEGODEZ</b></sub></a><br /><a href=\"#instructions-SebastienDegodez\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sesmyrnov\"><img src=\"https://avatars.githubusercontent.com/u/59627981?v=4?s=100\" width=\"100px;\" alt=\"Sergiy Smyrnov\"/><br /><sub><b>Sergiy Smyrnov</b></sub></a><br /><a href=\"#prompts-sesmyrnov\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/SomeSolutionsArchitect\"><img src=\"https://avatars.githubusercontent.com/u/139817767?v=4?s=100\" width=\"100px;\" alt=\"SomeSolutionsArchitect\"/><br /><sub><b>SomeSolutionsArchitect</b></sub></a><br /><a href=\"#agents-SomeSolutionsArchitect\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kewalaka\"><img src=\"https://avatars.githubusercontent.com/u/3146590?v=4?s=100\" width=\"100px;\" alt=\"Stu Mace\"/><br /><sub><b>Stu Mace</b></sub></a><br /><a href=\"#agents-kewalaka\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#collections-kewalaka\" title=\"Curated collections of related content\">üéÅ</a> <a href=\"#instructions-kewalaka\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/STRUDSO\"><img src=\"https://avatars.githubusercontent.com/u/1543732?v=4?s=100\" width=\"100px;\" alt=\"S√∏ren Truds√∏ Mahon\"/><br /><sub><b>S√∏ren Truds√∏ Mahon</b></sub></a><br /><a href=\"#instructions-STRUDSO\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://enakdesign.com/\"><img src=\"https://avatars.githubusercontent.com/u/14024037?v=4?s=100\" width=\"100px;\" alt=\"Tj Vita\"/><br /><sub><b>Tj Vita</b></sub></a><br /><a href=\"#agents-semperteneo\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pelikhan\"><img src=\"https://avatars.githubusercontent.com/u/4175913?v=4?s=100\" width=\"100px;\" alt=\"Peli de Halleux\"/><br /><sub><b>Peli de Halleux</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=pelikhan\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.paulomorgado.net/\"><img src=\"https://avatars.githubusercontent.com/u/470455?v=4?s=100\" width=\"100px;\" alt=\"Paulo Morgado\"/><br /><sub><b>Paulo Morgado</b></sub></a><br /><a href=\"#prompts-paulomorgado\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://paul.crane.net.nz/\"><img src=\"https://avatars.githubusercontent.com/u/808676?v=4?s=100\" width=\"100px;\" alt=\"Paul Crane\"/><br /><sub><b>Paul Crane</b></sub></a><br /><a href=\"#agents-pcrane\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.pamelafox.org/\"><img src=\"https://avatars.githubusercontent.com/u/297042?v=4?s=100\" width=\"100px;\" alt=\"Pamela Fox\"/><br /><sub><b>Pamela Fox</b></sub></a><br /><a href=\"#prompts-pamelafox\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://oskarthornblad.se/\"><img src=\"https://avatars.githubusercontent.com/u/640102?v=4?s=100\" width=\"100px;\" alt=\"Oskar Thornblad\"/><br /><sub><b>Oskar Thornblad</b></sub></a><br /><a href=\"#instructions-prewk\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nischays\"><img src=\"https://avatars.githubusercontent.com/u/54121853?v=4?s=100\" width=\"100px;\" alt=\"Nischay Sharma\"/><br /><sub><b>Nischay Sharma</b></sub></a><br /><a href=\"#agents-nischays\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Naikabg\"><img src=\"https://avatars.githubusercontent.com/u/19915620?v=4?s=100\" width=\"100px;\" alt=\"Nikolay Marinov\"/><br /><sub><b>Nikolay Marinov</b></sub></a><br /><a href=\"#agents-Naikabg\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/niksac\"><img src=\"https://avatars.githubusercontent.com/u/20246918?v=4?s=100\" width=\"100px;\" alt=\"Nik Sachdeva\"/><br /><sub><b>Nik Sachdeva</b></sub></a><br /><a href=\"#agents-niksacdev\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#collections-niksacdev\" title=\"Curated collections of related content\">üéÅ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://onetipaweek.com/\"><img src=\"https://avatars.githubusercontent.com/u/833231?v=4?s=100\" width=\"100px;\" alt=\"Nick Taylor\"/><br /><sub><b>Nick Taylor</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=nickytonline\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://nicholasdbrady.github.io/cookbook/\"><img src=\"https://avatars.githubusercontent.com/u/18353756?v=4?s=100\" width=\"100px;\" alt=\"Nick Brady\"/><br /><sub><b>Nick Brady</b></sub></a><br /><a href=\"#agents-nicholasdbrady\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nastanford\"><img src=\"https://avatars.githubusercontent.com/u/1755947?v=4?s=100\" width=\"100px;\" alt=\"Nathan Stanford Sr\"/><br /><sub><b>Nathan Stanford Sr</b></sub></a><br /><a href=\"#instructions-nastanford\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/matebarabas\"><img src=\"https://avatars.githubusercontent.com/u/22733424?v=4?s=100\" width=\"100px;\" alt=\"M√°t√© Barab√°s\"/><br /><sub><b>M√°t√© Barab√°s</b></sub></a><br /><a href=\"#instructions-matebarabas\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mikeparker104\"><img src=\"https://avatars.githubusercontent.com/u/12763221?v=4?s=100\" width=\"100px;\" alt=\"Mike Parker\"/><br /><sub><b>Mike Parker</b></sub></a><br /><a href=\"#instructions-mikeparker104\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mikekistler\"><img src=\"https://avatars.githubusercontent.com/u/85643503?v=4?s=100\" width=\"100px;\" alt=\"Mike Kistler\"/><br /><sub><b>Mike Kistler</b></sub></a><br /><a href=\"#prompts-mikekistler\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/giomartinsdev\"><img src=\"https://avatars.githubusercontent.com/u/125399281?v=4?s=100\" width=\"100px;\" alt=\"Giovanni de Almeida Martins\"/><br /><sub><b>Giovanni de Almeida Martins</b></sub></a><br /><a href=\"#instructions-giomartinsdev\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dgh06175\"><img src=\"https://avatars.githubusercontent.com/u/77305722?v=4?s=100\" width=\"100px;\" alt=\"Ïù¥ÏÉÅÌòÑ\"/><br /><sub><b>Ïù¥ÏÉÅÌòÑ</b></sub></a><br /><a href=\"#instructions-dgh06175\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/zooav\"><img src=\"https://avatars.githubusercontent.com/u/12625412?v=4?s=100\" width=\"100px;\" alt=\"Ankur Sharma\"/><br /><sub><b>Ankur Sharma</b></sub></a><br /><a href=\"#prompts-zooav\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/webreidi\"><img src=\"https://avatars.githubusercontent.com/u/55603905?v=4?s=100\" width=\"100px;\" alt=\"Wendy Breiding\"/><br /><sub><b>Wendy Breiding</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=webreidi\" title=\"Code\">üíª</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/voidfnc\"><img src=\"https://avatars.githubusercontent.com/u/194750710?v=4?s=100\" width=\"100px;\" alt=\"voidfnc\"/><br /><sub><b>voidfnc</b></sub></a><br /><a href=\"#agents-voidfnc\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://about.me/shane-lee\"><img src=\"https://avatars.githubusercontent.com/u/5466825?v=4?s=100\" width=\"100px;\" alt=\"shane lee\"/><br /><sub><b>shane lee</b></sub></a><br /><a href=\"#instructions-shavo007\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sdanzo-hrb\"><img src=\"https://avatars.githubusercontent.com/u/136493100?v=4?s=100\" width=\"100px;\" alt=\"sdanzo-hrb\"/><br /><sub><b>sdanzo-hrb</b></sub></a><br /><a href=\"#agents-sdanzo-hrb\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nativebpm\"><img src=\"https://avatars.githubusercontent.com/u/33398121?v=4?s=100\" width=\"100px;\" alt=\"sauran\"/><br /><sub><b>sauran</b></sub></a><br /><a href=\"#instructions-isauran\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/samqbush\"><img src=\"https://avatars.githubusercontent.com/u/74389839?v=4?s=100\" width=\"100px;\" alt=\"samqbush\"/><br /><sub><b>samqbush</b></sub></a><br /><a href=\"#prompts-samqbush\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pareenaverma\"><img src=\"https://avatars.githubusercontent.com/u/59843121?v=4?s=100\" width=\"100px;\" alt=\"pareenaverma\"/><br /><sub><b>pareenaverma</b></sub></a><br /><a href=\"#agents-pareenaverma\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/oleksiyyurchyna\"><img src=\"https://avatars.githubusercontent.com/u/10256765?v=4?s=100\" width=\"100px;\" alt=\"oleksiyyurchyna\"/><br /><sub><b>oleksiyyurchyna</b></sub></a><br /><a href=\"#collections-oleksiyyurchyna\" title=\"Curated collections of related content\">üéÅ</a> <a href=\"#prompts-oleksiyyurchyna\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/time-by-waves\"><img src=\"https://avatars.githubusercontent.com/u/34587654?v=4?s=100\" width=\"100px;\" alt=\"oceans-of-time\"/><br /><sub><b>oceans-of-time</b></sub></a><br /><a href=\"#instructions-time-by-waves\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kshashank57\"><img src=\"https://avatars.githubusercontent.com/u/57212456?v=4?s=100\" width=\"100px;\" alt=\"kshashank57\"/><br /><sub><b>kshashank57</b></sub></a><br /><a href=\"#agents-kshashank57\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-kshashank57\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/hueanmy\"><img src=\"https://avatars.githubusercontent.com/u/20430626?v=4?s=100\" width=\"100px;\" alt=\"Meii\"/><br /><sub><b>Meii</b></sub></a><br /><a href=\"#agents-hueanmy\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/factory-davidgu\"><img src=\"https://avatars.githubusercontent.com/u/229352262?v=4?s=100\" width=\"100px;\" alt=\"factory-davidgu\"/><br /><sub><b>factory-davidgu</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=factory-davidgu\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dangelov-qa\"><img src=\"https://avatars.githubusercontent.com/u/92313553?v=4?s=100\" width=\"100px;\" alt=\"dangelov-qa\"/><br /><sub><b>dangelov-qa</b></sub></a><br /><a href=\"#agents-dangelov-qa\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/BenoitMaucotel\"><img src=\"https://avatars.githubusercontent.com/u/54392431?v=4?s=100\" width=\"100px;\" alt=\"BenoitMaucotel\"/><br /><sub><b>BenoitMaucotel</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=BenoitMaucotel\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/benjisho-aidome\"><img src=\"https://avatars.githubusercontent.com/u/218995725?v=4?s=100\" width=\"100px;\" alt=\"benjisho-aidome\"/><br /><sub><b>benjisho-aidome</b></sub></a><br /><a href=\"#agents-benjisho-aidome\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-benjisho-aidome\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-benjisho-aidome\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/yukiomoto\"><img src=\"https://avatars.githubusercontent.com/u/38450410?v=4?s=100\" width=\"100px;\" alt=\"Yuki Omoto\"/><br /><sub><b>Yuki Omoto</b></sub></a><br /><a href=\"#instructions-yukiomoto\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/wschultz-boxboat\"><img src=\"https://avatars.githubusercontent.com/u/110492948?v=4?s=100\" width=\"100px;\" alt=\"Will Schultz\"/><br /><sub><b>Will Schultz</b></sub></a><br /><a href=\"#agents-wschultz-boxboat\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://bio.warengonzaga.com/\"><img src=\"https://avatars.githubusercontent.com/u/15052701?v=4?s=100\" width=\"100px;\" alt=\"Waren Gonzaga\"/><br /><sub><b>Waren Gonzaga</b></sub></a><br /><a href=\"#agents-warengonzaga\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://linktr.ee/vincentkoc\"><img src=\"https://avatars.githubusercontent.com/u/25068?v=4?s=100\" width=\"100px;\" alt=\"Vincent Koc\"/><br /><sub><b>Vincent Koc</b></sub></a><br /><a href=\"#agents-vincentkoc\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Vaporjawn\"><img src=\"https://avatars.githubusercontent.com/u/15694665?v=4?s=100\" width=\"100px;\" alt=\"Victor Williams\"/><br /><sub><b>Victor Williams</b></sub></a><br /><a href=\"#agents-Vaporjawn\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://vesharma.dev/\"><img src=\"https://avatars.githubusercontent.com/u/62218708?v=4?s=100\" width=\"100px;\" alt=\"Ve Sharma\"/><br /><sub><b>Ve Sharma</b></sub></a><br /><a href=\"#agents-VeVarunSharma\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.ferryhopper.com/\"><img src=\"https://avatars.githubusercontent.com/u/19361558?v=4?s=100\" width=\"100px;\" alt=\"Vasileios Lahanas\"/><br /><sub><b>Vasileios Lahanas</b></sub></a><br /><a href=\"#instructions-vlahanas\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://tinyurl.com/3p5j9mwe\"><img src=\"https://avatars.githubusercontent.com/u/9591887?v=4?s=100\" width=\"100px;\" alt=\"Udaya Veeramreddygari\"/><br /><sub><b>Udaya Veeramreddygari</b></sub></a><br /><a href=\"#instructions-udayakumarreddyv\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/iletai\"><img src=\"https://avatars.githubusercontent.com/u/26614687?v=4?s=100\" width=\"100px;\" alt=\"T√†i L√™\"/><br /><sub><b>T√†i L√™</b></sub></a><br /><a href=\"#prompts-iletai\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://tsubasaogawa.me/\"><img src=\"https://avatars.githubusercontent.com/u/7788821?v=4?s=100\" width=\"100px;\" alt=\"Tsubasa Ogawa\"/><br /><sub><b>Tsubasa Ogawa</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=tsubasaogawa\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://glsauto.com/\"><img src=\"https://avatars.githubusercontent.com/u/132710946?v=4?s=100\" width=\"100px;\" alt=\"Troy Witthoeft (glsauto)\"/><br /><sub><b>Troy Witthoeft (glsauto)</b></sub></a><br /><a href=\"#instructions-twitthoeft-gls\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://jfversluis.dev/\"><img src=\"https://avatars.githubusercontent.com/u/939291?v=4?s=100\" width=\"100px;\" alt=\"Gerald Versluis\"/><br /><sub><b>Gerald Versluis</b></sub></a><br /><a href=\"#instructions-jfversluis\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/geoder101\"><img src=\"https://avatars.githubusercontent.com/u/145904?v=4?s=100\" width=\"100px;\" alt=\"George Dernikos\"/><br /><sub><b>George Dernikos</b></sub></a><br /><a href=\"#prompts-geoder101\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/gautambaghel\"><img src=\"https://avatars.githubusercontent.com/u/22324290?v=4?s=100\" width=\"100px;\" alt=\"Gautam\"/><br /><sub><b>Gautam</b></sub></a><br /><a href=\"#agents-gautambaghel\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/feapaydin\"><img src=\"https://avatars.githubusercontent.com/u/19946639?v=4?s=100\" width=\"100px;\" alt=\"Furkan Enes\"/><br /><sub><b>Furkan Enes</b></sub></a><br /><a href=\"#instructions-feapaydin\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/fmuecke\"><img src=\"https://avatars.githubusercontent.com/u/7921024?v=4?s=100\" width=\"100px;\" alt=\"Florian M√ºcke\"/><br /><sub><b>Florian M√ºcke</b></sub></a><br /><a href=\"#agents-fmuecke\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.felixarjuna.dev/\"><img src=\"https://avatars.githubusercontent.com/u/79026094?v=4?s=100\" width=\"100px;\" alt=\"Felix Arjuna\"/><br /><sub><b>Felix Arjuna</b></sub></a><br /><a href=\"#instructions-felixarjuna\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ewega\"><img src=\"https://avatars.githubusercontent.com/u/26189114?v=4?s=100\" width=\"100px;\" alt=\"Eldrick Wega\"/><br /><sub><b>Eldrick Wega</b></sub></a><br /><a href=\"#prompts-ewega\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/danchev\"><img src=\"https://avatars.githubusercontent.com/u/12420863?v=4?s=100\" width=\"100px;\" alt=\"Dobri Danchev\"/><br /><sub><b>Dobri Danchev</b></sub></a><br /><a href=\"#prompts-danchev\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://dgamboa.com/\"><img src=\"https://avatars.githubusercontent.com/u/7052267?v=4?s=100\" width=\"100px;\" alt=\"Diego Gamboa\"/><br /><sub><b>Diego Gamboa</b></sub></a><br /><a href=\"#prompts-difegam\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/derekclair\"><img src=\"https://avatars.githubusercontent.com/u/5247629?v=4?s=100\" width=\"100px;\" alt=\"Derek Clair\"/><br /><sub><b>Derek Clair</b></sub></a><br /><a href=\"#agents-derekclair\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#prompts-derekclair\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://dev.to/davidortinau\"><img src=\"https://avatars.githubusercontent.com/u/41873?v=4?s=100\" width=\"100px;\" alt=\"David Ortinau\"/><br /><sub><b>David Ortinau</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=davidortinau\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/danielabbatt\"><img src=\"https://avatars.githubusercontent.com/u/8926756?v=4?s=100\" width=\"100px;\" alt=\"Daniel Abbatt\"/><br /><sub><b>Daniel Abbatt</b></sub></a><br /><a href=\"#instructions-danielabbatt\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/CypherHK\"><img src=\"https://avatars.githubusercontent.com/u/230935834?v=4?s=100\" width=\"100px;\" alt=\"CypherHK\"/><br /><sub><b>CypherHK</b></sub></a><br /><a href=\"#agents-CypherHK\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#prompts-CypherHK\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/craigbekker\"><img src=\"https://avatars.githubusercontent.com/u/1115912?v=4?s=100\" width=\"100px;\" alt=\"Craig Bekker\"/><br /><sub><b>Craig Bekker</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=craigbekker\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.peug.net/\"><img src=\"https://avatars.githubusercontent.com/u/3845786?v=4?s=100\" width=\"100px;\" alt=\"Christophe Peugnet\"/><br /><sub><b>Christophe Peugnet</b></sub></a><br /><a href=\"#instructions-tossnet\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lechnerc77\"><img src=\"https://avatars.githubusercontent.com/u/22294087?v=4?s=100\" width=\"100px;\" alt=\"Christian Lechner\"/><br /><sub><b>Christian Lechner</b></sub></a><br /><a href=\"#instructions-lechnerc77\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/charris-msft\"><img src=\"https://avatars.githubusercontent.com/u/74415662?v=4?s=100\" width=\"100px;\" alt=\"Chris Harris\"/><br /><sub><b>Chris Harris</b></sub></a><br /><a href=\"#agents-charris-msft\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/artemsaveliev\"><img src=\"https://avatars.githubusercontent.com/u/15679218?v=4?s=100\" width=\"100px;\" alt=\"Artem Saveliev\"/><br /><sub><b>Artem Saveliev</b></sub></a><br /><a href=\"#instructions-artemsaveliev\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://javaetmoi.com/\"><img src=\"https://avatars.githubusercontent.com/u/838318?v=4?s=100\" width=\"100px;\" alt=\"Antoine Rey\"/><br /><sub><b>Antoine Rey</b></sub></a><br /><a href=\"#prompts-arey\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/PiKa919\"><img src=\"https://avatars.githubusercontent.com/u/96786190?v=4?s=100\" width=\"100px;\" alt=\"Ankit Das\"/><br /><sub><b>Ankit Das</b></sub></a><br /><a href=\"#instructions-PiKa919\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/alineavila\"><img src=\"https://avatars.githubusercontent.com/u/24813256?v=4?s=100\" width=\"100px;\" alt=\"Aline √Åvila\"/><br /><sub><b>Aline √Åvila</b></sub></a><br /><a href=\"#instructions-alineavila\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/martin-cod\"><img src=\"https://avatars.githubusercontent.com/u/33550246?v=4?s=100\" width=\"100px;\" alt=\"Alexander Martinkevich\"/><br /><sub><b>Alexander Martinkevich</b></sub></a><br /><a href=\"#agents-martin-cod\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/aldunchev\"><img src=\"https://avatars.githubusercontent.com/u/4631021?v=4?s=100\" width=\"100px;\" alt=\"Aleksandar Dunchev\"/><br /><sub><b>Aleksandar Dunchev</b></sub></a><br /><a href=\"#agents-aldunchev\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.qreate.it/\"><img src=\"https://avatars.githubusercontent.com/u/1868590?v=4?s=100\" width=\"100px;\" alt=\"Alan Sprecacenere\"/><br /><sub><b>Alan Sprecacenere</b></sub></a><br /><a href=\"#instructions-tegola\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/akashxlr8\"><img src=\"https://avatars.githubusercontent.com/u/58072860?v=4?s=100\" width=\"100px;\" alt=\"Akash Kumar Shaw\"/><br /><sub><b>Akash Kumar Shaw</b></sub></a><br /><a href=\"#instructions-akashxlr8\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/abdidaudpropel\"><img src=\"https://avatars.githubusercontent.com/u/51310019?v=4?s=100\" width=\"100px;\" alt=\"Abdi Daud\"/><br /><sub><b>Abdi Daud</b></sub></a><br /><a href=\"#agents-abdidaudpropel\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/AIAlchemyForge\"><img src=\"https://avatars.githubusercontent.com/u/253636689?v=4?s=100\" width=\"100px;\" alt=\"AIAlchemyForge\"/><br /><sub><b>AIAlchemyForge</b></sub></a><br /><a href=\"#instructions-AIAlchemyForge\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/4regab\"><img src=\"https://avatars.githubusercontent.com/u/178603515?v=4?s=100\" width=\"100px;\" alt=\"4regab\"/><br /><sub><b>4regab</b></sub></a><br /><a href=\"#instructions-4regab\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/MiguelElGallo\"><img src=\"https://avatars.githubusercontent.com/u/60221874?v=4?s=100\" width=\"100px;\" alt=\"Miguel P Z\"/><br /><sub><b>Miguel P Z</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=MiguelElGallo\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://a11ysupport.io/\"><img src=\"https://avatars.githubusercontent.com/u/498678?v=4?s=100\" width=\"100px;\" alt=\"Michael Fairchild\"/><br /><sub><b>Michael Fairchild</b></sub></a><br /><a href=\"#instructions-mfairchild365\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/michael-volz/\"><img src=\"https://avatars.githubusercontent.com/u/129928?v=4?s=100\" width=\"100px;\" alt=\"Michael A. Volz (Flynn)\"/><br /><sub><b>Michael A. Volz (Flynn)</b></sub></a><br /><a href=\"#prompts-michaelvolz\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Mike-Hanna\"><img src=\"https://avatars.githubusercontent.com/u/50142889?v=4?s=100\" width=\"100px;\" alt=\"Michael\"/><br /><sub><b>Michael</b></sub></a><br /><a href=\"#instructions-Mike-Hanna\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.mehmetalierol.com/\"><img src=\"https://avatars.githubusercontent.com/u/16721723?v=4?s=100\" width=\"100px;\" alt=\"Mehmet Ali EROL\"/><br /><sub><b>Mehmet Ali EROL</b></sub></a><br /><a href=\"#agents-mehmetalierol\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://maxprilutskiy.com/\"><img src=\"https://avatars.githubusercontent.com/u/5614659?v=4?s=100\" width=\"100px;\" alt=\"Max Prilutskiy\"/><br /><sub><b>Max Prilutskiy</b></sub></a><br /><a href=\"#agents-maxprilutskiy\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mbianchidev\"><img src=\"https://avatars.githubusercontent.com/u/37507190?v=4?s=100\" width=\"100px;\" alt=\"Matteo Bianchi\"/><br /><sub><b>Matteo Bianchi</b></sub></a><br /><a href=\"#agents-mbianchidev\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://marknoble.com/\"><img src=\"https://avatars.githubusercontent.com/u/3819700?v=4?s=100\" width=\"100px;\" alt=\"Mark Noble\"/><br /><sub><b>Mark Noble</b></sub></a><br /><a href=\"#agents-marknoble\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ManishJayaswal\"><img src=\"https://avatars.githubusercontent.com/u/9527491?v=4?s=100\" width=\"100px;\" alt=\"Manish Jayaswal\"/><br /><sub><b>Manish Jayaswal</b></sub></a><br /><a href=\"#agents-ManishJayaswal\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://linktr.ee/lukemurray\"><img src=\"https://avatars.githubusercontent.com/u/24467442?v=4?s=100\" width=\"100px;\" alt=\"Luke Murray\"/><br /><sub><b>Luke Murray</b></sub></a><br /><a href=\"#agents-lukemurraynz\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/LouellaCreemers\"><img src=\"https://avatars.githubusercontent.com/u/46204894?v=4?s=100\" width=\"100px;\" alt=\"Louella Creemers\"/><br /><sub><b>Louella Creemers</b></sub></a><br /><a href=\"#instructions-LouellaCreemers\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/saikoumudi\"><img src=\"https://avatars.githubusercontent.com/u/22682497?v=4?s=100\" width=\"100px;\" alt=\"Sai Koumudi Kaluvakolanu\"/><br /><sub><b>Sai Koumudi Kaluvakolanu</b></sub></a><br /><a href=\"#agents-saikoumudi\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/whiteken\"><img src=\"https://avatars.githubusercontent.com/u/20211937?v=4?s=100\" width=\"100px;\" alt=\"Kenny White\"/><br /><sub><b>Kenny White</b></sub></a><br /><a href=\"#instructions-whiteken\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/KaloyanGenev\"><img src=\"https://avatars.githubusercontent.com/u/42644424?v=4?s=100\" width=\"100px;\" alt=\"KaloyanGenev\"/><br /><sub><b>KaloyanGenev</b></sub></a><br /><a href=\"#agents-KaloyanGenev\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Ranrar\"><img src=\"https://avatars.githubusercontent.com/u/95967772?v=4?s=100\" width=\"100px;\" alt=\"Kim Skov Rasmussen\"/><br /><sub><b>Kim Skov Rasmussen</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=Ranrar\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.julien-dubois.com/\"><img src=\"https://avatars.githubusercontent.com/u/316835?v=4?s=100\" width=\"100px;\" alt=\"Julien Dubois\"/><br /><sub><b>Julien Dubois</b></sub></a><br /><a href=\"#prompts-jdubois\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://digio.es/\"><img src=\"https://avatars.githubusercontent.com/u/173672918?v=4?s=100\" width=\"100px;\" alt=\"Jos√© Antonio Garrido\"/><br /><sub><b>Jos√© Antonio Garrido</b></sub></a><br /><a href=\"#instructions-josegarridodigio\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.sugbo4j.co.nz/\"><img src=\"https://avatars.githubusercontent.com/u/15100839?v=4?s=100\" width=\"100px;\" alt=\"Joseph Gonzales\"/><br /><sub><b>Joseph Gonzales</b></sub></a><br /><a href=\"#instructions-josephgonzales01\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-josephgonzales01\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/yortch\"><img src=\"https://avatars.githubusercontent.com/u/4576246?v=4?s=100\" width=\"100px;\" alt=\"Jorge Balderas\"/><br /><sub><b>Jorge Balderas</b></sub></a><br /><a href=\"#instructions-yortch\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://johnpapa.net/\"><img src=\"https://avatars.githubusercontent.com/u/1202528?v=4?s=100\" width=\"100px;\" alt=\"John Papa\"/><br /><sub><b>John Papa</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=johnpapa\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.johnlokerse.dev/\"><img src=\"https://avatars.githubusercontent.com/u/3514513?v=4?s=100\" width=\"100px;\" alt=\"John\"/><br /><sub><b>John</b></sub></a><br /><a href=\"#agents-johnlokerse\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://joe-watkins.io/\"><img src=\"https://avatars.githubusercontent.com/u/3695795?v=4?s=100\" width=\"100px;\" alt=\"Joe Watkins\"/><br /><sub><b>Joe Watkins</b></sub></a><br /><a href=\"#instructions-joe-watkins\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://jan-v.nl/\"><img src=\"https://avatars.githubusercontent.com/u/462356?v=4?s=100\" width=\"100px;\" alt=\"Jan de Vries\"/><br /><sub><b>Jan de Vries</b></sub></a><br /><a href=\"#agents-Jandev\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nohwnd\"><img src=\"https://avatars.githubusercontent.com/u/5735905?v=4?s=100\" width=\"100px;\" alt=\"Jakub Jare≈°\"/><br /><sub><b>Jakub Jare≈°</b></sub></a><br /><a href=\"#prompts-nohwnd\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jaxn\"><img src=\"https://avatars.githubusercontent.com/u/29095?v=4?s=100\" width=\"100px;\" alt=\"Jackson Miller\"/><br /><sub><b>Jackson Miller</b></sub></a><br /><a href=\"#instructions-jaxn\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Ioana37\"><img src=\"https://avatars.githubusercontent.com/u/69301842?v=4?s=100\" width=\"100px;\" alt=\"Ioana A\"/><br /><sub><b>Ioana A</b></sub></a><br /><a href=\"#instructions-Ioana37\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/hunterhogan\"><img src=\"https://avatars.githubusercontent.com/u/2958419?v=4?s=100\" width=\"100px;\" alt=\"Hunter Hogan\"/><br /><sub><b>Hunter Hogan</b></sub></a><br /><a href=\"#agents-hunterhogan\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/hashimwarren\"><img src=\"https://avatars.githubusercontent.com/u/6027587?v=4?s=100\" width=\"100px;\" alt=\"Hashim Warren\"/><br /><sub><b>Hashim Warren</b></sub></a><br /><a href=\"#agents-hashimwarren\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Arggon\"><img src=\"https://avatars.githubusercontent.com/u/20962238?v=4?s=100\" width=\"100px;\" alt=\"Gonzalo\"/><br /><sub><b>Gonzalo</b></sub></a><br /><a href=\"#prompts-Arggon\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://hachyderm.io/@0gis0\"><img src=\"https://avatars.githubusercontent.com/u/175379?v=4?s=100\" width=\"100px;\" alt=\"Gisela Torres\"/><br /><sub><b>Gisela Torres</b></sub></a><br /><a href=\"#agents-0GiS0\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/shibicr93\"><img src=\"https://avatars.githubusercontent.com/u/6803434?v=4?s=100\" width=\"100px;\" alt=\"Shibi Ramachandran\"/><br /><sub><b>Shibi Ramachandran</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=shibicr93\" title=\"Code\">üíª</a></td>\n    </tr>\n  </tbody>\n  <tfoot>\n    <tr>\n      <td align=\"center\" size=\"13px\" colspan=\"7\">\n        <img src=\"https://raw.githubusercontent.com/all-contributors/all-contributors-cli/1b8533af435da9854653492b1327a23a4dbd0a10/assets/logo-small.svg\">\n          <a href=\"https://all-contributors.js.org/docs/en/bot/usage\">Add your contributions</a>\n        </img>\n      </td>\n    </tr>\n  </tfoot>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n\nThis project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification. Contributions of any kind welcome!\n\n## üìö Additional Resources\n\n- [VS Code Copilot Customization Documentation](https://code.visualstudio.com/docs/copilot/copilot-customization) - Official Microsoft documentation\n- [GitHub Copilot Chat Documentation](https://code.visualstudio.com/docs/copilot/chat/copilot-chat) - Complete chat feature guide\n- [VS Code Settings](https://code.visualstudio.com/docs/getstarted/settings) - General VS Code configuration guide\n\n## ‚Ñ¢Ô∏è Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft\ntrademarks or logos is subject to and must follow\n[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\nAny use of third-party trademarks or logos are subject to those third-party's policies.\n",
      "stars_today": 165
    },
    {
      "id": 1073224021,
      "name": "compound-engineering-plugin",
      "full_name": "EveryInc/compound-engineering-plugin",
      "description": "Official Claude Code compound engineering plugin",
      "html_url": "https://github.com/EveryInc/compound-engineering-plugin",
      "stars": 6165,
      "forks": 488,
      "language": "TypeScript",
      "topics": [],
      "created_at": "2025-10-09T19:43:46Z",
      "updated_at": "2026-01-24T01:53:22Z",
      "pushed_at": "2026-01-23T16:54:29Z",
      "open_issues": 37,
      "owner": {
        "login": "EveryInc",
        "avatar_url": "https://avatars.githubusercontent.com/u/76073155?v=4"
      },
      "readme": "# Compound Marketplace\n\nA Claude Code plugin marketplace featuring the **Compound Engineering Plugin** ‚Äî tools that make each unit of engineering work easier than the last.\n\n## Claude Code Install\n\n```bash\n/plugin marketplace add https://github.com/EveryInc/compound-engineering-plugin\n/plugin install compound-engineering\n```\n\n## OpenCode + Codex (experimental) Install\n\nThis repo includes a Bun/TypeScript CLI that converts Claude Code plugins to OpenCode and Codex.\n\n```bash\n# convert the compound-engineering plugin into OpenCode format\nbunx @every-env/compound-plugin install compound-engineering --to opencode\n\n# convert to Codex format\nbunx @every-env/compound-plugin install compound-engineering --to codex\n```\n\nLocal dev:\n\n```bash\nbun run src/index.ts install ./plugins/compound-engineering --to opencode\n```\n\nOpenCode output is written to `~/.opencode` by default, with `opencode.json` at the root and `agents/`, `skills/`, and `plugins/` alongside it.\nBoth provider targets are experimental and may change as the formats evolve.\nCodex output is written to `~/.codex/prompts` and `~/.codex/skills`, with each Claude command converted into both a prompt and a skill (the prompt instructs Codex to load the corresponding skill). Generated Codex skill descriptions are truncated to 1024 characters (Codex limit).\n\n## Workflow\n\n```\nPlan ‚Üí Work ‚Üí Review ‚Üí Compound ‚Üí Repeat\n```\n\n| Command | Purpose |\n|---------|---------|\n| `/workflows:plan` | Turn feature ideas into detailed implementation plans |\n| `/workflows:work` | Execute plans with worktrees and task tracking |\n| `/workflows:review` | Multi-agent code review before merging |\n| `/workflows:compound` | Document learnings to make future work easier |\n\nEach cycle compounds: plans inform future plans, reviews catch more issues, patterns get documented.\n\n## Philosophy\n\n**Each unit of engineering work should make subsequent units easier‚Äînot harder.**\n\nTraditional development accumulates technical debt. Every feature adds complexity. The codebase becomes harder to work with over time.\n\nCompound engineering inverts this. 80% is in planning and review, 20% is in execution:\n- Plan thoroughly before writing code\n- Review to catch issues and capture learnings\n- Codify knowledge so it's reusable\n- Keep quality high so future changes are easy\n\n## Learn More\n\n- [Full component reference](plugins/compound-engineering/README.md) - all agents, commands, skills\n- [Compound engineering: how Every codes with agents](https://every.to/chain-of-thought/compound-engineering-how-every-codes-with-agents)\n- [The story behind compounding engineering](https://every.to/source-code/my-ai-had-already-fixed-the-code-before-i-saw-it)\n",
      "stars_today": 147
    },
    {
      "id": 658928958,
      "name": "ollama",
      "full_name": "ollama/ollama",
      "description": "Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models.",
      "html_url": "https://github.com/ollama/ollama",
      "stars": 160360,
      "forks": 14256,
      "language": "Go",
      "topics": [
        "deepseek",
        "gemma",
        "gemma3",
        "gemma3n",
        "go",
        "golang",
        "gpt-oss",
        "llama",
        "llama2",
        "llama3",
        "llava",
        "llm",
        "llms",
        "mistral",
        "ollama",
        "phi4",
        "qwen"
      ],
      "created_at": "2023-06-26T19:39:32Z",
      "updated_at": "2026-01-24T01:25:58Z",
      "pushed_at": "2026-01-24T02:01:57Z",
      "open_issues": 2379,
      "owner": {
        "login": "ollama",
        "avatar_url": "https://avatars.githubusercontent.com/u/151674099?v=4"
      },
      "readme": "<div align=\"center\">\n¬† <a href=\"https://ollama.com\">\n    <img alt=\"ollama\" width=\"240\" src=\"https://github.com/ollama/ollama/assets/3325447/0d0b44e2-8f4a-4e99-9b52-a5c1c741c8f7\">\n  </a>\n</div>\n\n# Ollama\n\nGet up and running with large language models.\n\n### macOS\n\n[Download](https://ollama.com/download/Ollama.dmg)\n\n### Windows\n\n[Download](https://ollama.com/download/OllamaSetup.exe)\n\n### Linux\n\n```shell\ncurl -fsSL https://ollama.com/install.sh | sh\n```\n\n[Manual install instructions](https://docs.ollama.com/linux#manual-install)\n\n### Docker\n\nThe official [Ollama Docker image](https://hub.docker.com/r/ollama/ollama) `ollama/ollama` is available on Docker Hub.\n\n### Libraries\n\n- [ollama-python](https://github.com/ollama/ollama-python)\n- [ollama-js](https://github.com/ollama/ollama-js)\n\n### Community\n\n- [Discord](https://discord.gg/ollama)\n- [Reddit](https://reddit.com/r/ollama)\n\n## Quickstart\n\nTo run and chat with [Gemma 3](https://ollama.com/library/gemma3):\n\n```shell\nollama run gemma3\n```\n\n## Model library\n\nOllama supports a list of models available on [ollama.com/library](https://ollama.com/library \"ollama model library\")\n\nHere are some example models that can be downloaded:\n\n| Model              | Parameters | Size  | Download                         |\n| ------------------ | ---------- | ----- | -------------------------------- |\n| Gemma 3            | 1B         | 815MB | `ollama run gemma3:1b`           |\n| Gemma 3            | 4B         | 3.3GB | `ollama run gemma3`              |\n| Gemma 3            | 12B        | 8.1GB | `ollama run gemma3:12b`          |\n| Gemma 3            | 27B        | 17GB  | `ollama run gemma3:27b`          |\n| QwQ                | 32B        | 20GB  | `ollama run qwq`                 |\n| DeepSeek-R1        | 7B         | 4.7GB | `ollama run deepseek-r1`         |\n| DeepSeek-R1        | 671B       | 404GB | `ollama run deepseek-r1:671b`    |\n| Llama 4            | 109B       | 67GB  | `ollama run llama4:scout`        |\n| Llama 4            | 400B       | 245GB | `ollama run llama4:maverick`     |\n| Llama 3.3          | 70B        | 43GB  | `ollama run llama3.3`            |\n| Llama 3.2          | 3B         | 2.0GB | `ollama run llama3.2`            |\n| Llama 3.2          | 1B         | 1.3GB | `ollama run llama3.2:1b`         |\n| Llama 3.2 Vision   | 11B        | 7.9GB | `ollama run llama3.2-vision`     |\n| Llama 3.2 Vision   | 90B        | 55GB  | `ollama run llama3.2-vision:90b` |\n| Llama 3.1          | 8B         | 4.7GB | `ollama run llama3.1`            |\n| Llama 3.1          | 405B       | 231GB | `ollama run llama3.1:405b`       |\n| Phi 4              | 14B        | 9.1GB | `ollama run phi4`                |\n| Phi 4 Mini         | 3.8B       | 2.5GB | `ollama run phi4-mini`           |\n| Mistral            | 7B         | 4.1GB | `ollama run mistral`             |\n| Moondream 2        | 1.4B       | 829MB | `ollama run moondream`           |\n| Neural Chat        | 7B         | 4.1GB | `ollama run neural-chat`         |\n| Starling           | 7B         | 4.1GB | `ollama run starling-lm`         |\n| Code Llama         | 7B         | 3.8GB | `ollama run codellama`           |\n| Llama 2 Uncensored | 7B         | 3.8GB | `ollama run llama2-uncensored`   |\n| LLaVA              | 7B         | 4.5GB | `ollama run llava`               |\n| Granite-3.3        | 8B         | 4.9GB | `ollama run granite3.3`          |\n\n> [!NOTE]\n> You should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.\n\n## Customize a model\n\n### Import from GGUF\n\nOllama supports importing GGUF models in the Modelfile:\n\n1. Create a file named `Modelfile`, with a `FROM` instruction with the local filepath to the model you want to import.\n\n   ```\n   FROM ./vicuna-33b.Q4_0.gguf\n   ```\n\n2. Create the model in Ollama\n\n   ```shell\n   ollama create example -f Modelfile\n   ```\n\n3. Run the model\n\n   ```shell\n   ollama run example\n   ```\n\n### Import from Safetensors\n\nSee the [guide](https://docs.ollama.com/import) on importing models for more information.\n\n### Customize a prompt\n\nModels from the Ollama library can be customized with a prompt. For example, to customize the `llama3.2` model:\n\n```shell\nollama pull llama3.2\n```\n\nCreate a `Modelfile`:\n\n```\nFROM llama3.2\n\n# set the temperature to 1 [higher is more creative, lower is more coherent]\nPARAMETER temperature 1\n\n# set the system message\nSYSTEM \"\"\"\nYou are Mario from Super Mario Bros. Answer as Mario, the assistant, only.\n\"\"\"\n```\n\nNext, create and run the model:\n\n```\nollama create mario -f ./Modelfile\nollama run mario\n>>> hi\nHello! It's your friend Mario.\n```\n\nFor more information on working with a Modelfile, see the [Modelfile](https://docs.ollama.com/modelfile) documentation.\n\n## CLI Reference\n\n### Create a model\n\n`ollama create` is used to create a model from a Modelfile.\n\n```shell\nollama create mymodel -f ./Modelfile\n```\n\n### Pull a model\n\n```shell\nollama pull llama3.2\n```\n\n> This command can also be used to update a local model. Only the diff will be pulled.\n\n### Remove a model\n\n```shell\nollama rm llama3.2\n```\n\n### Copy a model\n\n```shell\nollama cp llama3.2 my-model\n```\n\n### Multiline input\n\nFor multiline input, you can wrap text with `\"\"\"`:\n\n```\n>>> \"\"\"Hello,\n... world!\n... \"\"\"\nI'm a basic program that prints the famous \"Hello, world!\" message to the console.\n```\n\n### Multimodal models\n\n```\nollama run llava \"What's in this image? /Users/jmorgan/Desktop/smile.png\"\n```\n\n> **Output**: The image features a yellow smiley face, which is likely the central focus of the picture.\n\n### Pass the prompt as an argument\n\n```shell\nollama run llama3.2 \"Summarize this file: $(cat README.md)\"\n```\n\n> **Output**: Ollama is a lightweight, extensible framework for building and running language models on the local machine. It provides a simple API for creating, running, and managing models, as well as a library of pre-built models that can be easily used in a variety of applications.\n\n### Show model information\n\n```shell\nollama show llama3.2\n```\n\n### List models on your computer\n\n```shell\nollama list\n```\n\n### List which models are currently loaded\n\n```shell\nollama ps\n```\n\n### Stop a model which is currently running\n\n```shell\nollama stop llama3.2\n```\n\n### Generate embeddings from the CLI\n\n```shell\nollama run embeddinggemma \"Your text to embed\"\n```\n\nYou can also pipe text for scripted workflows:\n\n```shell\necho \"Your text to embed\" | ollama run embeddinggemma\n```\n\n### Start Ollama\n\n`ollama serve` is used when you want to start ollama without running the desktop application.\n\n## Building\n\nSee the [developer guide](https://github.com/ollama/ollama/blob/main/docs/development.md)\n\n### Running local builds\n\nNext, start the server:\n\n```shell\n./ollama serve\n```\n\nFinally, in a separate shell, run a model:\n\n```shell\n./ollama run llama3.2\n```\n\n## Building with MLX (experimental)\n\nFirst build the MLX libraries:\n\n```shell\ncmake --preset MLX\ncmake --build --preset MLX --parallel\ncmake --install build --component MLX\n```\n\nWhen building with the `-tags mlx` flag, the main `ollama` binary includes MLX support for experimental features like image generation:\n\n```shell\ngo build -tags mlx .\n```\n\nFinally, start the server:\n\n```\n./ollama serve\n```\n\n### Building MLX with CUDA\n\nWhen building with CUDA, use the preset \"MLX CUDA 13\" or \"MLX CUDA 12\" to enable CUDA with default architectures:\n\n```shell\ncmake --preset 'MLX CUDA 13'\ncmake --build --preset 'MLX CUDA 13' --parallel\ncmake --install build --component MLX\n```\n\n## REST API\n\nOllama has a REST API for running and managing models.\n\n### Generate a response\n\n```shell\ncurl http://localhost:11434/api/generate -d '{\n  \"model\": \"llama3.2\",\n  \"prompt\":\"Why is the sky blue?\"\n}'\n```\n\n### Chat with a model\n\n```shell\ncurl http://localhost:11434/api/chat -d '{\n  \"model\": \"llama3.2\",\n  \"messages\": [\n    { \"role\": \"user\", \"content\": \"why is the sky blue?\" }\n  ]\n}'\n```\n\nSee the [API documentation](./docs/api.md) for all endpoints.\n\n## Community Integrations\n\n### Web & Desktop\n\n- [Onyx](https://github.com/onyx-dot-app/onyx)\n- [Open WebUI](https://github.com/open-webui/open-webui)\n- [SwiftChat (macOS with ReactNative)](https://github.com/aws-samples/swift-chat)\n- [Enchanted (macOS native)](https://github.com/AugustDev/enchanted)\n- [Hollama](https://github.com/fmaclen/hollama)\n- [Lollms WebUI (Single user)](https://github.com/ParisNeo/lollms-webui)\n- [Lollms (Multi users)](https://github.com/ParisNeo/lollms)\n- [LibreChat](https://github.com/danny-avila/LibreChat)\n- [Bionic GPT](https://github.com/bionic-gpt/bionic-gpt)\n- [HTML UI](https://github.com/rtcfirefly/ollama-ui)\n- [AI-UI](https://github.com/bajahaw/ai-ui)\n- [Saddle](https://github.com/jikkuatwork/saddle)\n- [TagSpaces](https://www.tagspaces.org) (A platform for file-based apps, [utilizing Ollama](https://docs.tagspaces.org/ai/) for the generation of tags and descriptions)\n- [Chatbot UI](https://github.com/ivanfioravanti/chatbot-ollama)\n- [Chatbot UI v2](https://github.com/mckaywrigley/chatbot-ui)\n- [Typescript UI](https://github.com/ollama-interface/Ollama-Gui?tab=readme-ov-file)\n- [Minimalistic React UI for Ollama Models](https://github.com/richawo/minimal-llm-ui)\n- [Ollamac](https://github.com/kevinhermawan/Ollamac)\n- [big-AGI](https://github.com/enricoros/big-AGI)\n- [Cheshire Cat assistant framework](https://github.com/cheshire-cat-ai/core)\n- [Amica](https://github.com/semperai/amica)\n- [chatd](https://github.com/BruceMacD/chatd)\n- [Ollama-SwiftUI](https://github.com/kghandour/Ollama-SwiftUI)\n- [Dify.AI](https://github.com/langgenius/dify)\n- [MindMac](https://mindmac.app)\n- [NextJS Web Interface for Ollama](https://github.com/jakobhoeg/nextjs-ollama-llm-ui)\n- [Msty](https://msty.app)\n- [Chatbox](https://github.com/Bin-Huang/Chatbox)\n- [WinForm Ollama Copilot](https://github.com/tgraupmann/WinForm_Ollama_Copilot)\n- [NextChat](https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web) with [Get Started Doc](https://docs.nextchat.dev/models/ollama)\n- [Alpaca WebUI](https://github.com/mmo80/alpaca-webui)\n- [OllamaGUI](https://github.com/enoch1118/ollamaGUI)\n- [OpenAOE](https://github.com/InternLM/OpenAOE)\n- [Odin Runes](https://github.com/leonid20000/OdinRunes)\n- [LLM-X](https://github.com/mrdjohnson/llm-x) (Progressive Web App)\n- [AnythingLLM (Docker + MacOs/Windows/Linux native app)](https://github.com/Mintplex-Labs/anything-llm)\n- [Ollama Basic Chat: Uses HyperDiv Reactive UI](https://github.com/rapidarchitect/ollama_basic_chat)\n- [Ollama-chats RPG](https://github.com/drazdra/ollama-chats)\n- [IntelliBar](https://intellibar.app/) (AI-powered assistant for macOS)\n- [Jirapt](https://github.com/AliAhmedNada/jirapt) (Jira Integration to generate issues, tasks, epics)\n- [ojira](https://github.com/AliAhmedNada/ojira) (Jira chrome plugin to easily generate descriptions for tasks)\n- [QA-Pilot](https://github.com/reid41/QA-Pilot) (Interactive chat tool that can leverage Ollama models for rapid understanding and navigation of GitHub code repositories)\n- [ChatOllama](https://github.com/sugarforever/chat-ollama) (Open Source Chatbot based on Ollama with Knowledge Bases)\n- [CRAG Ollama Chat](https://github.com/Nagi-ovo/CRAG-Ollama-Chat) (Simple Web Search with Corrective RAG)\n- [RAGFlow](https://github.com/infiniflow/ragflow) (Open-source Retrieval-Augmented Generation engine based on deep document understanding)\n- [StreamDeploy](https://github.com/StreamDeploy-DevRel/streamdeploy-llm-app-scaffold) (LLM Application Scaffold)\n- [chat](https://github.com/swuecho/chat) (chat web app for teams)\n- [Lobe Chat](https://github.com/lobehub/lobe-chat) with [Integrating Doc](https://lobehub.com/docs/self-hosting/examples/ollama)\n- [Ollama RAG Chatbot](https://github.com/datvodinh/rag-chatbot.git) (Local Chat with multiple PDFs using Ollama and RAG)\n- [BrainSoup](https://www.nurgo-software.com/products/brainsoup) (Flexible native client with RAG & multi-agent automation)\n- [macai](https://github.com/Renset/macai) (macOS client for Ollama, ChatGPT, and other compatible API back-ends)\n- [RWKV-Runner](https://github.com/josStorer/RWKV-Runner) (RWKV offline LLM deployment tool, also usable as a client for ChatGPT and Ollama)\n- [Ollama Grid Search](https://github.com/dezoito/ollama-grid-search) (app to evaluate and compare models)\n- [Olpaka](https://github.com/Otacon/olpaka) (User-friendly Flutter Web App for Ollama)\n- [Casibase](https://casibase.org) (An open source AI knowledge base and dialogue system combining the latest RAG, SSO, ollama support, and multiple large language models.)\n- [OllamaSpring](https://github.com/CrazyNeil/OllamaSpring) (Ollama Client for macOS)\n- [LLocal.in](https://github.com/kartikm7/llocal) (Easy to use Electron Desktop Client for Ollama)\n- [Shinkai Desktop](https://github.com/dcSpark/shinkai-apps) (Two click install Local AI using Ollama + Files + RAG)\n- [AiLama](https://github.com/zeyoyt/ailama) (A Discord User App that allows you to interact with Ollama anywhere in Discord)\n- [Ollama with Google Mesop](https://github.com/rapidarchitect/ollama_mesop/) (Mesop Chat Client implementation with Ollama)\n- [R2R](https://github.com/SciPhi-AI/R2R) (Open-source RAG engine)\n- [Ollama-Kis](https://github.com/elearningshow/ollama-kis) (A simple easy-to-use GUI with sample custom LLM for Drivers Education)\n- [OpenGPA](https://opengpa.org) (Open-source offline-first Enterprise Agentic Application)\n- [Painting Droid](https://github.com/mateuszmigas/painting-droid) (Painting app with AI integrations)\n- [Kerlig AI](https://www.kerlig.com/) (AI writing assistant for macOS)\n- [AI Studio](https://github.com/MindWorkAI/AI-Studio)\n- [Sidellama](https://github.com/gyopak/sidellama) (browser-based LLM client)\n- [LLMStack](https://github.com/trypromptly/LLMStack) (No-code multi-agent framework to build LLM agents and workflows)\n- [BoltAI for Mac](https://boltai.com) (AI Chat Client for Mac)\n- [Harbor](https://github.com/av/harbor) (Containerized LLM Toolkit with Ollama as default backend)\n- [PyGPT](https://github.com/szczyglis-dev/py-gpt) (AI desktop assistant for Linux, Windows, and Mac)\n- [Alpaca](https://github.com/Jeffser/Alpaca) (An Ollama client application for Linux and macOS made with GTK4 and Adwaita)\n- [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT/blob/master/docs/content/platform/ollama.md) (AutoGPT Ollama integration)\n- [Go-CREW](https://www.jonathanhecl.com/go-crew/) (Powerful Offline RAG in Golang)\n- [PartCAD](https://github.com/openvmp/partcad/) (CAD model generation with OpenSCAD and CadQuery)\n- [Ollama4j Web UI](https://github.com/ollama4j/ollama4j-web-ui) - Java-based Web UI for Ollama built with Vaadin, Spring Boot, and Ollama4j\n- [PyOllaMx](https://github.com/kspviswa/pyOllaMx) - macOS application capable of chatting with both Ollama and Apple MLX models.\n- [Cline](https://github.com/cline/cline) - Formerly known as Claude Dev is a VS Code extension for multi-file/whole-repo coding\n- [Void](https://github.com/voideditor/void) (Open source AI code editor and Cursor alternative)\n- [Cherry Studio](https://github.com/kangfenmao/cherry-studio) (Desktop client with Ollama support)\n- [ConfiChat](https://github.com/1runeberg/confichat) (Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)\n- [Archyve](https://github.com/nickthecook/archyve) (RAG-enabling document library)\n- [crewAI with Mesop](https://github.com/rapidarchitect/ollama-crew-mesop) (Mesop Web Interface to run crewAI with Ollama)\n- [Tkinter-based client](https://github.com/chyok/ollama-gui) (Python tkinter-based Client for Ollama)\n- [LLMChat](https://github.com/trendy-design/llmchat) (Privacy focused, 100% local, intuitive all-in-one chat interface)\n- [Local Multimodal AI Chat](https://github.com/Leon-Sander/Local-Multimodal-AI-Chat) (Ollama-based LLM Chat with support for multiple features, including PDF RAG, voice chat, image-based interactions, and integration with OpenAI.)\n- [ARGO](https://github.com/xark-argo/argo) (Locally download and run Ollama and Huggingface models with RAG and deep research on Mac/Windows/Linux)\n- [OrionChat](https://github.com/EliasPereirah/OrionChat) - OrionChat is a web interface for chatting with different AI providers\n- [G1](https://github.com/bklieger-groq/g1) (Prototype of using prompting strategies to improve the LLM's reasoning through o1-like reasoning chains.)\n- [Web management](https://github.com/lemonit-eric-mao/ollama-web-management) (Web management page)\n- [Promptery](https://github.com/promptery/promptery) (desktop client for Ollama.)\n- [Ollama App](https://github.com/JHubi1/ollama-app) (Modern and easy-to-use multi-platform client for Ollama)\n- [chat-ollama](https://github.com/annilq/chat-ollama) (a React Native client for Ollama)\n- [SpaceLlama](https://github.com/tcsenpai/spacellama) (Firefox and Chrome extension to quickly summarize web pages with ollama in a sidebar)\n- [YouLama](https://github.com/tcsenpai/youlama) (Webapp to quickly summarize any YouTube video, supporting Invidious as well)\n- [DualMind](https://github.com/tcsenpai/dualmind) (Experimental app allowing two models to talk to each other in the terminal or in a web interface)\n- [ollamarama-matrix](https://github.com/h1ddenpr0cess20/ollamarama-matrix) (Ollama chatbot for the Matrix chat protocol)\n- [ollama-chat-app](https://github.com/anan1213095357/ollama-chat-app) (Flutter-based chat app)\n- [Perfect Memory AI](https://www.perfectmemory.ai/) (Productivity AI assists personalized by what you have seen on your screen, heard, and said in the meetings)\n- [Hexabot](https://github.com/hexastack/hexabot) (A conversational AI builder)\n- [Reddit Rate](https://github.com/rapidarchitect/reddit_analyzer) (Search and Rate Reddit topics with a weighted summation)\n- [OpenTalkGpt](https://github.com/adarshM84/OpenTalkGpt) (Chrome Extension to manage open-source models supported by Ollama, create custom models, and chat with models from a user-friendly UI)\n- [VT](https://github.com/vinhnx/vt.ai) (A minimal multimodal AI chat app, with dynamic conversation routing. Supports local models via Ollama)\n- [Nosia](https://github.com/nosia-ai/nosia) (Easy to install and use RAG platform based on Ollama)\n- [Witsy](https://github.com/nbonamy/witsy) (An AI Desktop application available for Mac/Windows/Linux)\n- [Abbey](https://github.com/US-Artificial-Intelligence/abbey) (A configurable AI interface server with notebooks, document storage, and YouTube support)\n- [Minima](https://github.com/dmayboroda/minima) (RAG with on-premises or fully local workflow)\n- [aidful-ollama-model-delete](https://github.com/AidfulAI/aidful-ollama-model-delete) (User interface for simplified model cleanup)\n- [Perplexica](https://github.com/ItzCrazyKns/Perplexica) (An AI-powered search engine & an open-source alternative to Perplexity AI)\n- [Ollama Chat WebUI for Docker ](https://github.com/oslook/ollama-webui) (Support for local docker deployment, lightweight ollama webui)\n- [AI Toolkit for Visual Studio Code](https://aka.ms/ai-tooklit/ollama-docs) (Microsoft-official VS Code extension to chat, test, evaluate models with Ollama support, and use them in your AI applications.)\n- [MinimalNextOllamaChat](https://github.com/anilkay/MinimalNextOllamaChat) (Minimal Web UI for Chat and Model Control)\n- [Chipper](https://github.com/TilmanGriesel/chipper) AI interface for tinkerers (Ollama, Haystack RAG, Python)\n- [ChibiChat](https://github.com/CosmicEventHorizon/ChibiChat) (Kotlin-based Android app to chat with Ollama and Koboldcpp API endpoints)\n- [LocalLLM](https://github.com/qusaismael/localllm) (Minimal Web-App to run ollama models on it with a GUI)\n- [Ollamazing](https://github.com/buiducnhat/ollamazing) (Web extension to run Ollama models)\n- [OpenDeepResearcher-via-searxng](https://github.com/benhaotang/OpenDeepResearcher-via-searxng) (A Deep Research equivalent endpoint with Ollama support for running locally)\n- [AntSK](https://github.com/AIDotNet/AntSK) (Out-of-the-box & Adaptable RAG Chatbot)\n- [MaxKB](https://github.com/1Panel-dev/MaxKB/) (Ready-to-use & flexible RAG Chatbot)\n- [yla](https://github.com/danielekp/yla) (Web interface to freely interact with your customized models)\n- [LangBot](https://github.com/RockChinQ/LangBot) (LLM-based instant messaging bots platform, with Agents, RAG features, supports multiple platforms)\n- [1Panel](https://github.com/1Panel-dev/1Panel/) (Web-based Linux Server Management Tool)\n- [AstrBot](https://github.com/Soulter/AstrBot/) (User-friendly LLM-based multi-platform chatbot with a WebUI, supporting RAG, LLM agents, and plugins integration)\n- [Reins](https://github.com/ibrahimcetin/reins) (Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)\n- [Flufy](https://github.com/Aharon-Bensadoun/Flufy) (A beautiful chat interface for interacting with Ollama's API. Built with React, TypeScript, and Material-UI.)\n- [Ellama](https://github.com/zeozeozeo/ellama) (Friendly native app to chat with an Ollama instance)\n- [screenpipe](https://github.com/mediar-ai/screenpipe) Build agents powered by your screen history\n- [Ollamb](https://github.com/hengkysteen/ollamb) (Simple yet rich in features, cross-platform built with Flutter and designed for Ollama. Try the [web demo](https://hengkysteen.github.io/demo/ollamb/).)\n- [Writeopia](https://github.com/Writeopia/Writeopia) (Text editor with integration with Ollama)\n- [AppFlowy](https://github.com/AppFlowy-IO/AppFlowy) (AI collaborative workspace with Ollama, cross-platform and self-hostable)\n- [Lumina](https://github.com/cushydigit/lumina.git) (A lightweight, minimal React.js frontend for interacting with Ollama servers)\n- [Tiny Notepad](https://pypi.org/project/tiny-notepad) (A lightweight, notepad-like interface to chat with ollama available on PyPI)\n- [macLlama (macOS native)](https://github.com/hellotunamayo/macLlama) (A native macOS GUI application for interacting with Ollama models, featuring a chat interface.)\n- [GPTranslate](https://github.com/philberndt/GPTranslate) (A fast and lightweight, AI powered desktop translation application written with Rust and Tauri. Features real-time translation with OpenAI/Azure/Ollama.)\n- [ollama launcher](https://github.com/NGC13009/ollama-launcher) (A launcher for Ollama, aiming to provide users with convenient functions such as ollama server launching, management, or configuration.)\n- [ai-hub](https://github.com/Aj-Seven/ai-hub) (AI Hub supports multiple models via API keys and Chat support via Ollama API.)\n- [Mayan EDMS](https://gitlab.com/mayan-edms/mayan-edms) (Open source document management system to organize, tag, search, and automate your files with powerful Ollama driven workflows.)\n- [Serene Pub](https://github.com/doolijb/serene-pub) (Beginner friendly, open source AI Roleplaying App for Windows, Mac OS and Linux. Search, download and use models with Ollama all inside the app.)\n- [Andes](https://github.com/aqerd/andes) (A Visual Studio Code extension that provides a local UI interface for Ollama models)\n- [KDeps](https://github.com/kdeps/kdeps) (Kdeps is an offline-first AI framework for building Dockerized full-stack AI applications declaratively using Apple PKL and integrates APIs with Ollama on the backend.)\n- [Clueless](https://github.com/KashyapTan/clueless) (Open Source & Local Cluely: A desktop application LLM assistant to help you talk to anything on your screen using locally served Ollama models. Also undetectable to screenshare)\n- [ollama-co2](https://github.com/carbonatedWaterOrg/ollama-co2) (FastAPI web interface for monitoring and managing local and remote Ollama servers with real-time model monitoring and concurrent downloads)\n- [Hillnote](https://hillnote.com) (A Markdown-first workspace designed to supercharge your AI workflow. Create documents ready to integrate with Claude, ChatGPT, Gemini, Cursor, and more - all while keeping your work on your device.)\n\n### Cloud\n\n- [Google Cloud](https://cloud.google.com/run/docs/tutorials/gpu-gemma2-with-ollama)\n- [Fly.io](https://fly.io/docs/python/do-more/add-ollama/)\n- [Koyeb](https://www.koyeb.com/deploy/ollama)\n\n### Tutorial\n\n- [handy-ollama](https://github.com/datawhalechina/handy-ollama) (Chinese Tutorial for Ollama by [Datawhale ](https://github.com/datawhalechina) - China's Largest Open Source AI Learning Community)\n\n### Terminal\n\n- [oterm](https://github.com/ggozad/oterm)\n- [Ellama Emacs client](https://github.com/s-kostyaev/ellama)\n- [Emacs client](https://github.com/zweifisch/ollama)\n- [neollama](https://github.com/paradoxical-dev/neollama) UI client for interacting with models from within Neovim\n- [gen.nvim](https://github.com/David-Kunz/gen.nvim)\n- [ollama.nvim](https://github.com/nomnivore/ollama.nvim)\n- [ollero.nvim](https://github.com/marco-souza/ollero.nvim)\n- [ollama-chat.nvim](https://github.com/gerazov/ollama-chat.nvim)\n- [ogpt.nvim](https://github.com/huynle/ogpt.nvim)\n- [gptel Emacs client](https://github.com/karthink/gptel)\n- [Oatmeal](https://github.com/dustinblackman/oatmeal)\n- [cmdh](https://github.com/pgibler/cmdh)\n- [ooo](https://github.com/npahlfer/ooo)\n- [shell-pilot](https://github.com/reid41/shell-pilot)(Interact with models via pure shell scripts on Linux or macOS)\n- [tenere](https://github.com/pythops/tenere)\n- [llm-ollama](https://github.com/taketwo/llm-ollama) for [Datasette's LLM CLI](https://llm.datasette.io/en/stable/).\n- [typechat-cli](https://github.com/anaisbetts/typechat-cli)\n- [ShellOracle](https://github.com/djcopley/ShellOracle)\n- [tlm](https://github.com/yusufcanb/tlm)\n- [podman-ollama](https://github.com/ericcurtin/podman-ollama)\n- [gollama](https://github.com/sammcj/gollama)\n- [ParLlama](https://github.com/paulrobello/parllama)\n- [Ollama eBook Summary](https://github.com/cognitivetech/ollama-ebook-summary/)\n- [Ollama Mixture of Experts (MOE) in 50 lines of code](https://github.com/rapidarchitect/ollama_moe)\n- [vim-intelligence-bridge](https://github.com/pepo-ec/vim-intelligence-bridge) Simple interaction of \"Ollama\" with the Vim editor\n- [x-cmd ollama](https://x-cmd.com/mod/ollama)\n- [bb7](https://github.com/drunkwcodes/bb7)\n- [SwollamaCLI](https://github.com/marcusziade/Swollama) bundled with the Swollama Swift package. [Demo](https://github.com/marcusziade/Swollama?tab=readme-ov-file#cli-usage)\n- [aichat](https://github.com/sigoden/aichat) All-in-one LLM CLI tool featuring Shell Assistant, Chat-REPL, RAG, AI tools & agents, with access to OpenAI, Claude, Gemini, Ollama, Groq, and more.\n- [PowershAI](https://github.com/rrg92/powershai) PowerShell module that brings AI to terminal on Windows, including support for Ollama\n- [DeepShell](https://github.com/Abyss-c0re/deepshell) Your self-hosted AI assistant. Interactive Shell, Files and Folders analysis.\n- [orbiton](https://github.com/xyproto/orbiton) Configuration-free text editor and IDE with support for tab completion with Ollama.\n- [orca-cli](https://github.com/molbal/orca-cli) Ollama Registry CLI Application - Browse, pull, and download models from Ollama Registry in your terminal.\n- [GGUF-to-Ollama](https://github.com/jonathanhecl/gguf-to-ollama) - Importing GGUF to Ollama made easy (multiplatform)\n- [AWS-Strands-With-Ollama](https://github.com/rapidarchitect/ollama_strands) - AWS Strands Agents with Ollama Examples\n- [ollama-multirun](https://github.com/attogram/ollama-multirun) - A bash shell script to run a single prompt against any or all of your locally installed ollama models, saving the output and performance statistics as easily navigable web pages. ([Demo](https://attogram.github.io/ai_test_zone/))\n- [ollama-bash-toolshed](https://github.com/attogram/ollama-bash-toolshed) - Bash scripts to chat with tool using models. Add new tools to your shed with ease. Runs on Ollama.\n- [hle-eval-ollama](https://github.com/mags0ft/hle-eval-ollama) - Runs benchmarks like \"Humanity's Last Exam\" (HLE) on your favorite local Ollama models and evaluates the quality of their responses\n- [VT Code](https://github.com/vinhnx/vtcode) - VT Code is a Rust-based terminal coding agent with semantic code intelligence via Tree-sitter. Ollama integration for running local/cloud models with configurable endpoints.\n\n### Apple Vision Pro\n\n- [SwiftChat](https://github.com/aws-samples/swift-chat) (Cross-platform AI chat app supporting Apple Vision Pro via \"Designed for iPad\")\n- [Enchanted](https://github.com/AugustDev/enchanted)\n\n### Database\n\n- [pgai](https://github.com/timescale/pgai) - PostgreSQL as a vector database (Create and search embeddings from Ollama models using pgvector)\n  - [Get started guide](https://github.com/timescale/pgai/blob/main/docs/vectorizer-quick-start.md)\n- [MindsDB](https://github.com/mindsdb/mindsdb/blob/staging/mindsdb/integrations/handlers/ollama_handler/README.md) (Connects Ollama models with nearly 200 data platforms and apps)\n- [chromem-go](https://github.com/philippgille/chromem-go/blob/v0.5.0/embed_ollama.go) with [example](https://github.com/philippgille/chromem-go/tree/v0.5.0/examples/rag-wikipedia-ollama)\n- [Kangaroo](https://github.com/dbkangaroo/kangaroo) (AI-powered SQL client and admin tool for popular databases)\n\n### Package managers\n\n- [Pacman](https://archlinux.org/packages/extra/x86_64/ollama/)\n- [Gentoo](https://github.com/gentoo/guru/tree/master/app-misc/ollama)\n- [Homebrew](https://formulae.brew.sh/formula/ollama)\n- [Helm Chart](https://artifacthub.io/packages/helm/ollama-helm/ollama)\n- [Guix channel](https://codeberg.org/tusharhero/ollama-guix)\n- [Nix package](https://search.nixos.org/packages?show=ollama&from=0&size=50&sort=relevance&type=packages&query=ollama)\n- [Flox](https://flox.dev/blog/ollama-part-one)\n\n### Libraries\n\n- [LangChain](https://python.langchain.com/docs/integrations/chat/ollama/) and [LangChain.js](https://js.langchain.com/docs/integrations/chat/ollama/) with [example](https://js.langchain.com/docs/tutorials/local_rag/)\n- [Firebase Genkit](https://firebase.google.com/docs/genkit/plugins/ollama)\n- [crewAI](https://github.com/crewAIInc/crewAI)\n- [Yacana](https://remembersoftwares.github.io/yacana/) (User-friendly multi-agent framework for brainstorming and executing predetermined flows with built-in tool integration)\n- [Strands Agents](https://github.com/strands-agents/sdk-python) (A model-driven approach to building AI agents in just a few lines of code)\n- [Spring AI](https://github.com/spring-projects/spring-ai) with [reference](https://docs.spring.io/spring-ai/reference/api/chat/ollama-chat.html) and [example](https://github.com/tzolov/ollama-tools)\n- [LangChainGo](https://github.com/tmc/langchaingo/) with [example](https://github.com/tmc/langchaingo/tree/main/examples/ollama-completion-example)\n- [LangChain4j](https://github.com/langchain4j/langchain4j) with [example](https://github.com/langchain4j/langchain4j-examples/tree/main/ollama-examples/src/main/java)\n- [LangChainRust](https://github.com/Abraxas-365/langchain-rust) with [example](https://github.com/Abraxas-365/langchain-rust/blob/main/examples/llm_ollama.rs)\n- [LangChain for .NET](https://github.com/tryAGI/LangChain) with [example](https://github.com/tryAGI/LangChain/blob/main/examples/LangChain.Samples.OpenAI/Program.cs)\n- [LLPhant](https://github.com/theodo-group/LLPhant?tab=readme-ov-file#ollama)\n- [LlamaIndex](https://docs.llamaindex.ai/en/stable/examples/llm/ollama/) and [LlamaIndexTS](https://ts.llamaindex.ai/modules/llms/available_llms/ollama)\n- [LiteLLM](https://github.com/BerriAI/litellm)\n- [OllamaFarm for Go](https://github.com/presbrey/ollamafarm)\n- [OllamaSharp for .NET](https://github.com/awaescher/OllamaSharp)\n- [Ollama for Ruby](https://github.com/gbaptista/ollama-ai)\n- [Ollama-rs for Rust](https://github.com/pepperoni21/ollama-rs)\n- [Ollama-hpp for C++](https://github.com/jmont-dev/ollama-hpp)\n- [Ollama4j for Java](https://github.com/ollama4j/ollama4j)\n- [ModelFusion Typescript Library](https://modelfusion.dev/integration/model-provider/ollama)\n- [OllamaKit for Swift](https://github.com/kevinhermawan/OllamaKit)\n- [Ollama for Dart](https://github.com/breitburg/dart-ollama)\n- [Ollama for Laravel](https://github.com/cloudstudio/ollama-laravel)\n- [LangChainDart](https://github.com/davidmigloz/langchain_dart)\n- [Semantic Kernel - Python](https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/ai/ollama)\n- [Haystack](https://github.com/deepset-ai/haystack-integrations/blob/main/integrations/ollama.md)\n- [Elixir LangChain](https://github.com/brainlid/langchain)\n- [Ollama for R - rollama](https://github.com/JBGruber/rollama)\n- [Ollama for R - ollama-r](https://github.com/hauselin/ollama-r)\n- [Ollama-ex for Elixir](https://github.com/lebrunel/ollama-ex)\n- [Ollama Connector for SAP ABAP](https://github.com/b-tocs/abap_btocs_ollama)\n- [Testcontainers](https://testcontainers.com/modules/ollama/)\n- [Portkey](https://portkey.ai/docs/welcome/integration-guides/ollama)\n- [PromptingTools.jl](https://github.com/svilupp/PromptingTools.jl) with an [example](https://svilupp.github.io/PromptingTools.jl/dev/examples/working_with_ollama)\n- [LlamaScript](https://github.com/Project-Llama/llamascript)\n- [llm-axe](https://github.com/emirsahin1/llm-axe) (Python Toolkit for Building LLM Powered Apps)\n- [Gollm](https://docs.gollm.co/examples/ollama-example)\n- [Gollama for Golang](https://github.com/jonathanhecl/gollama)\n- [Ollamaclient for Golang](https://github.com/xyproto/ollamaclient)\n- [High-level function abstraction in Go](https://gitlab.com/tozd/go/fun)\n- [Ollama PHP](https://github.com/ArdaGnsrn/ollama-php)\n- [Agents-Flex for Java](https://github.com/agents-flex/agents-flex) with [example](https://github.com/agents-flex/agents-flex/tree/main/agents-flex-llm/agents-flex-llm-ollama/src/test/java/com/agentsflex/llm/ollama)\n- [Parakeet](https://github.com/parakeet-nest/parakeet) is a GoLang library, made to simplify the development of small generative AI applications with Ollama.\n- [Haverscript](https://github.com/andygill/haverscript) with [examples](https://github.com/andygill/haverscript/tree/main/examples)\n- [Ollama for Swift](https://github.com/mattt/ollama-swift)\n- [Swollama for Swift](https://github.com/guitaripod/Swollama) with [DocC](https://guitaripod.github.io/Swollama/documentation/swollama)\n- [GoLamify](https://github.com/prasad89/golamify)\n- [Ollama for Haskell](https://github.com/tusharad/ollama-haskell)\n- [multi-llm-ts](https://github.com/nbonamy/multi-llm-ts) (A Typescript/JavaScript library allowing access to different LLM in a unified API)\n- [LlmTornado](https://github.com/lofcz/llmtornado) (C# library providing a unified interface for major FOSS & Commercial inference APIs)\n- [Ollama for Zig](https://github.com/dravenk/ollama-zig)\n- [Abso](https://github.com/lunary-ai/abso) (OpenAI-compatible TypeScript SDK for any LLM provider)\n- [Nichey](https://github.com/goodreasonai/nichey) is a Python package for generating custom wikis for your research topic\n- [Ollama for D](https://github.com/kassane/ollama-d)\n- [OllamaPlusPlus](https://github.com/HardCodeDev777/OllamaPlusPlus) (Very simple C++ library for Ollama)\n- [any-llm](https://github.com/mozilla-ai/any-llm) (A single interface to use different llm providers by [mozilla.ai](https://www.mozilla.ai/))\n- [any-agent](https://github.com/mozilla-ai/any-agent) (A single interface to use and evaluate different agent frameworks by [mozilla.ai](https://www.mozilla.ai/))\n- [Neuro SAN](https://github.com/cognizant-ai-lab/neuro-san-studio) (Data-driven multi-agent orchestration framework) with [example](https://github.com/cognizant-ai-lab/neuro-san-studio/blob/main/docs/user_guide.md#ollama)\n- [achatbot-go](https://github.com/ai-bot-pro/achatbot-go) a multimodal(text/audio/image) chatbot.\n- [Ollama Bash Lib](https://github.com/attogram/ollama-bash-lib) - A Bash Library for Ollama. Run LLM prompts straight from your shell, and more\n\n### Mobile\n\n- [SwiftChat](https://github.com/aws-samples/swift-chat) (Lightning-fast Cross-platform AI chat app with native UI for Android, iOS, and iPad)\n- [Enchanted](https://github.com/AugustDev/enchanted)\n- [Maid](https://github.com/Mobile-Artificial-Intelligence/maid)\n- [Ollama App](https://github.com/JHubi1/ollama-app) (Modern and easy-to-use multi-platform client for Ollama)\n- [ConfiChat](https://github.com/1runeberg/confichat) (Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)\n- [Ollama Android Chat](https://github.com/sunshine0523/OllamaServer) (No need for Termux, start the Ollama service with one click on an Android device)\n- [Reins](https://github.com/ibrahimcetin/reins) (Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)\n\n### Extensions & Plugins\n\n- [Raycast extension](https://github.com/MassimilianoPasquini97/raycast_ollama)\n- [Discollama](https://github.com/mxyng/discollama) (Discord bot inside the Ollama discord channel)\n- [Continue](https://github.com/continuedev/continue)\n- [Vibe](https://github.com/thewh1teagle/vibe) (Transcribe and analyze meetings with Ollama)\n- [Obsidian Ollama plugin](https://github.com/hinterdupfinger/obsidian-ollama)\n- [Logseq Ollama plugin](https://github.com/omagdy7/ollama-logseq)\n- [NotesOllama](https://github.com/andersrex/notesollama) (Apple Notes Ollama plugin)\n- [Dagger Chatbot](https://github.com/samalba/dagger-chatbot)\n- [Discord AI Bot](https://github.com/mekb-turtle/discord-ai-bot)\n- [Ollama Telegram Bot](https://github.com/ruecat/ollama-telegram)\n- [Hass Ollama Conversation](https://github.com/ej52/hass-ollama-conversation)\n- [Rivet plugin](https://github.com/abrenneke/rivet-plugin-ollama)\n- [Obsidian BMO Chatbot plugin](https://github.com/longy2k/obsidian-bmo-chatbot)\n- [Cliobot](https://github.com/herval/cliobot) (Telegram bot with Ollama support)\n- [Copilot for Obsidian plugin](https://github.com/logancyang/obsidian-copilot)\n- [Obsidian Local GPT plugin](https://github.com/pfrankov/obsidian-local-gpt)\n- [Open Interpreter](https://docs.openinterpreter.com/language-model-setup/local-models/ollama)\n- [Llama Coder](https://github.com/ex3ndr/llama-coder) (Copilot alternative using Ollama)\n- [Ollama Copilot](https://github.com/bernardo-bruning/ollama-copilot) (Proxy that allows you to use Ollama as a copilot like GitHub Copilot)\n- [twinny](https://github.com/rjmacarthy/twinny) (Copilot and Copilot chat alternative using Ollama)\n- [Wingman-AI](https://github.com/RussellCanfield/wingman-ai) (Copilot code and chat alternative using Ollama and Hugging Face)\n- [Page Assist](https://github.com/n4ze3m/page-assist) (Chrome Extension)\n- [Plasmoid Ollama Control](https://github.com/imoize/plasmoid-ollamacontrol) (KDE Plasma extension that allows you to quickly manage/control Ollama model)\n- [AI Telegram Bot](https://github.com/tusharhero/aitelegrambot) (Telegram bot using Ollama in backend)\n- [AI ST Completion](https://github.com/yaroslavyaroslav/OpenAI-sublime-text) (Sublime Text 4 AI assistant plugin with Ollama support)\n- [Discord-Ollama Chat Bot](https://github.com/kevinthedang/discord-ollama) (Generalized TypeScript Discord Bot w/ Tuning Documentation)\n- [ChatGPTBox: All in one browser extension](https://github.com/josStorer/chatGPTBox) with [Integrating Tutorial](https://github.com/josStorer/chatGPTBox/issues/616#issuecomment-1975186467)\n- [Discord AI chat/moderation bot](https://github.com/rapmd73/Companion) Chat/moderation bot written in python. Uses Ollama to create personalities.\n- [Headless Ollama](https://github.com/nischalj10/headless-ollama) (Scripts to automatically install ollama client & models on any OS for apps that depend on ollama server)\n- [Terraform AWS Ollama & Open WebUI](https://github.com/xuyangbocn/terraform-aws-self-host-llm) (A Terraform module to deploy on AWS a ready-to-use Ollama service, together with its front-end Open WebUI service.)\n- [node-red-contrib-ollama](https://github.com/jakubburkiewicz/node-red-contrib-ollama)\n- [Local AI Helper](https://github.com/ivostoykov/localAI) (Chrome and Firefox extensions that enable interactions with the active tab and customisable API endpoints. Includes secure storage for user prompts.)\n- [LSP-AI](https://github.com/SilasMarvin/lsp-ai) (Open-source language server for AI-powered functionality)\n- [QodeAssist](https://github.com/Palm1r/QodeAssist) (AI-powered coding assistant plugin for Qt Creator)\n- [Obsidian Quiz Generator plugin](https://github.com/ECuiDev/obsidian-quiz-generator)\n- [AI Summary Helper plugin](https://github.com/philffm/ai-summary-helper)\n- [TextCraft](https://github.com/suncloudsmoon/TextCraft) (Copilot in Word alternative using Ollama)\n- [Alfred Ollama](https://github.com/zeitlings/alfred-ollama) (Alfred Workflow)\n- [TextLLaMA](https://github.com/adarshM84/TextLLaMA) A Chrome Extension that helps you write emails, correct grammar, and translate into any language\n- [Simple-Discord-AI](https://github.com/zyphixor/simple-discord-ai)\n- [LLM Telegram Bot](https://github.com/innightwolfsleep/llm_telegram_bot) (telegram bot, primary for RP. Oobabooga-like buttons, [A1111](https://github.com/AUTOMATIC1111/stable-diffusion-webui) API integration e.t.c)\n- [mcp-llm](https://github.com/sammcj/mcp-llm) (MCP Server to allow LLMs to call other LLMs)\n- [SimpleOllamaUnity](https://github.com/HardCodeDev777/SimpleOllamaUnity) (Unity Engine extension for communicating with Ollama in a few lines of code. Also works at runtime)\n- [UnityCodeLama](https://github.com/HardCodeDev777/UnityCodeLama) (Unity Editor tool to analyze scripts via Ollama)\n- [NativeMind](https://github.com/NativeMindBrowser/NativeMindExtension) (Private, on-device AI Assistant, no cloud dependencies)\n- [GMAI - Gradle Managed AI](https://gmai.premex.se/) (Gradle plugin for automated Ollama lifecycle management during build phases)\n- [NOMYO Router](https://github.com/nomyo-ai/nomyo-router) (A transparent Ollama proxy with model deployment aware routing which auto-manages multiple Ollama instances in a given network)\n\n### Supported backends\n\n- [llama.cpp](https://github.com/ggml-org/llama.cpp) project founded by Georgi Gerganov.\n\n### Observability\n\n- [Opik](https://www.comet.com/docs/opik/cookbook/ollama) is an open-source platform to debug, evaluate, and monitor your LLM applications, RAG systems, and agentic workflows with comprehensive tracing, automated evaluations, and production-ready dashboards. Opik supports native integration to Ollama.\n- [Lunary](https://lunary.ai/docs/integrations/ollama) is the leading open-source LLM observability platform. It provides a variety of enterprise-grade features such as real-time analytics, prompt templates management, PII masking, and comprehensive agent tracing.\n- [OpenLIT](https://github.com/openlit/openlit) is an OpenTelemetry-native tool for monitoring Ollama Applications & GPUs using traces and metrics.\n- [HoneyHive](https://docs.honeyhive.ai/integrations/ollama) is an AI observability and evaluation platform for AI agents. Use HoneyHive to evaluate agent performance, interrogate failures, and monitor quality in production.\n- [Langfuse](https://langfuse.com/docs/integrations/ollama) is an open source LLM observability platform that enables teams to collaboratively monitor, evaluate and debug AI applications.\n- [MLflow Tracing](https://mlflow.org/docs/latest/llms/tracing/index.html#automatic-tracing) is an open source LLM observability tool with a convenient API to log and visualize traces, making it easy to debug and evaluate GenAI applications.\n\n### Security\n\n- [Ollama Fortress](https://github.com/ParisNeo/ollama_proxy_server)\n",
      "stars_today": 132
    },
    {
      "id": 965415649,
      "name": "codex",
      "full_name": "openai/codex",
      "description": "Lightweight coding agent that runs in your terminal",
      "html_url": "https://github.com/openai/codex",
      "stars": 57002,
      "forks": 7386,
      "language": "Rust",
      "topics": [],
      "created_at": "2025-04-13T05:37:54Z",
      "updated_at": "2026-01-24T01:49:04Z",
      "pushed_at": "2026-01-24T01:47:11Z",
      "open_issues": 884,
      "owner": {
        "login": "openai",
        "avatar_url": "https://avatars.githubusercontent.com/u/14957082?v=4"
      },
      "readme": "<p align=\"center\"><code>npm i -g @openai/codex</code><br />or <code>brew install --cask codex</code></p>\n<p align=\"center\"><strong>Codex CLI</strong> is a coding agent from OpenAI that runs locally on your computer.\n<p align=\"center\">\n  <img src=\"./.github/codex-cli-splash.png\" alt=\"Codex CLI splash\" width=\"80%\" />\n</p>\n</br>\nIf you want Codex in your code editor (VS Code, Cursor, Windsurf), <a href=\"https://developers.openai.com/codex/ide\">install in your IDE.</a>\n</br>If you are looking for the <em>cloud-based agent</em> from OpenAI, <strong>Codex Web</strong>, go to <a href=\"https://chatgpt.com/codex\">chatgpt.com/codex</a>.</p>\n\n---\n\n## Quickstart\n\n### Installing and running Codex CLI\n\nInstall globally with your preferred package manager:\n\n```shell\n# Install using npm\nnpm install -g @openai/codex\n```\n\n```shell\n# Install using Homebrew\nbrew install --cask codex\n```\n\nThen simply run `codex` to get started.\n\n<details>\n<summary>You can also go to the <a href=\"https://github.com/openai/codex/releases/latest\">latest GitHub Release</a> and download the appropriate binary for your platform.</summary>\n\nEach GitHub Release contains many executables, but in practice, you likely want one of these:\n\n- macOS\n  - Apple Silicon/arm64: `codex-aarch64-apple-darwin.tar.gz`\n  - x86_64 (older Mac hardware): `codex-x86_64-apple-darwin.tar.gz`\n- Linux\n  - x86_64: `codex-x86_64-unknown-linux-musl.tar.gz`\n  - arm64: `codex-aarch64-unknown-linux-musl.tar.gz`\n\nEach archive contains a single entry with the platform baked into the name (e.g., `codex-x86_64-unknown-linux-musl`), so you likely want to rename it to `codex` after extracting it.\n\n</details>\n\n### Using Codex with your ChatGPT plan\n\nRun `codex` and select **Sign in with ChatGPT**. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan. [Learn more about what's included in your ChatGPT plan](https://help.openai.com/en/articles/11369540-codex-in-chatgpt).\n\nYou can also use Codex with an API key, but this requires [additional setup](https://developers.openai.com/codex/auth#sign-in-with-an-api-key).\n\n## Docs\n\n- [**Codex Documentation**](https://developers.openai.com/codex)\n- [**Contributing**](./docs/contributing.md)\n- [**Installing & building**](./docs/install.md)\n- [**Open source fund**](./docs/open-source-fund.md)\n\nThis repository is licensed under the [Apache-2.0 License](LICENSE).\n",
      "stars_today": 123
    },
    {
      "id": 1023959202,
      "name": "runanywhere-sdks",
      "full_name": "RunanywhereAI/runanywhere-sdks",
      "description": "Production ready toolkit to run AI locally",
      "html_url": "https://github.com/RunanywhereAI/runanywhere-sdks",
      "stars": 4068,
      "forks": 133,
      "language": "Kotlin",
      "topics": [
        "agent-framework",
        "android",
        "apple-intelligence",
        "edge",
        "edge-ai",
        "foundational-models",
        "inference",
        "ios",
        "kotlin",
        "llamacpp",
        "llm",
        "multimodal",
        "ollama",
        "on-device-ai",
        "privacy",
        "swift",
        "voice-ai",
        "voice-assistant"
      ],
      "created_at": "2025-07-22T01:23:34Z",
      "updated_at": "2026-01-24T01:07:51Z",
      "pushed_at": "2026-01-23T22:22:43Z",
      "open_issues": 24,
      "owner": {
        "login": "RunanywhereAI",
        "avatar_url": "https://avatars.githubusercontent.com/u/220821781?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"examples/logo.svg\" alt=\"RunAnywhere Logo\" width=\"140\"/>\n</p>\n\n<h1 align=\"center\">RunAnywhere</h1>\n\n<p align=\"center\">\n  <strong>On-device AI for mobile apps.</strong><br/>\n  Run LLMs, speech-to-text, and text-to-speech locally‚Äîprivate, offline, fast.\n</p>\n\n<p align=\"center\">\n  <a href=\"https://apps.apple.com/us/app/runanywhere/id6756506307\">\n    <img src=\"https://img.shields.io/badge/App_Store-Download-0D96F6?style=for-the-badge&logo=apple&logoColor=white\" alt=\"Download on App Store\" />\n  </a>\n  &nbsp;\n  <a href=\"https://play.google.com/store/apps/details?id=com.runanywhere.runanywhereai\">\n    <img src=\"https://img.shields.io/badge/Google_Play-Download-34A853?style=for-the-badge&logo=google-play&logoColor=white\" alt=\"Get it on Google Play\" />\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/RunanywhereAI/runanywhere-sdks/stargazers\"><img src=\"https://img.shields.io/github/stars/RunanywhereAI/runanywhere-sdks?style=flat-square\" alt=\"GitHub Stars\" /></a>\n  <a href=\"LICENSE\"><img src=\"https://img.shields.io/badge/License-Apache%202.0-blue?style=flat-square\" alt=\"License\" /></a>\n  <a href=\"https://discord.gg/N359FBbDVd\"><img src=\"https://img.shields.io/badge/Discord-Join-5865F2?style=flat-square&logo=discord&logoColor=white\" alt=\"Discord\" /></a>\n</p>\n\n<p align=\"center\">\n  <img src=\"docs/screenshots/main-screenshot.jpg\" alt=\"Chat\" width=\"180\"/>\n  &nbsp;&nbsp;\n  <img src=\"examples/ios/RunAnywhereAI/docs/screenshots/chat-interface.png\" alt=\"Analytics\" width=\"180\"/>\n  &nbsp;&nbsp;\n  <img src=\"examples/ios/RunAnywhereAI/docs/screenshots/quiz-flow.png\" alt=\"Structured Output\" width=\"180\"/>\n  &nbsp;&nbsp;\n  <img src=\"examples/ios/RunAnywhereAI/docs/screenshots/voice-ai.png\" alt=\"Voice AI\" width=\"180\"/>\n</p>\n\n---\n\n## What is RunAnywhere?\n\nRunAnywhere lets you add AI features to your mobile app that run entirely on-device:\n\n- **LLM Chat** ‚Äî Llama, Mistral, Qwen, SmolLM, and more\n- **Speech-to-Text** ‚Äî Whisper-powered transcription\n- **Text-to-Speech** ‚Äî Neural voice synthesis\n- **Voice Assistant** ‚Äî Full STT ‚Üí LLM ‚Üí TTS pipeline\n\nNo cloud. No latency. No data leaves the device.\n\n---\n\n## SDKs\n\n| Platform | Status | Installation | Documentation |\n|----------|--------|--------------|---------------|\n| **Swift** (iOS/macOS) | Stable | [Swift Package Manager](#swift-ios--macos) | [docs.runanywhere.ai/swift](https://docs.runanywhere.ai/swift/introduction) |\n| **Kotlin** (Android) | Stable | [Gradle](#kotlin-android) | [docs.runanywhere.ai/kotlin](https://docs.runanywhere.ai/kotlin/introduction) |\n| **React Native** | Beta | [npm](#react-native) | [docs.runanywhere.ai/react-native](https://docs.runanywhere.ai/react-native/introduction) |\n| **Flutter** | Beta | [pub.dev](#flutter) | [docs.runanywhere.ai/flutter](https://docs.runanywhere.ai/flutter/introduction) |\n\n---\n\n## Quick Start\n\n### Swift (iOS / macOS)\n\n```swift\nimport RunAnywhere\nimport LlamaCPPRuntime\n\n// 1. Initialize\nLlamaCPP.register()\ntry RunAnywhere.initialize()\n\n// 2. Load a model\ntry await RunAnywhere.downloadModel(\"smollm2-360m\")\ntry await RunAnywhere.loadModel(\"smollm2-360m\")\n\n// 3. Generate\nlet response = try await RunAnywhere.chat(\"What is the capital of France?\")\nprint(response) // \"Paris is the capital of France.\"\n```\n\n**Install via Swift Package Manager:**\n\n```\nhttps://github.com/RunanywhereAI/runanywhere-sdks\n```\n\n[Full documentation ‚Üí](https://docs.runanywhere.ai/swift/introduction) ¬∑ [Source code](sdk/runanywhere-swift/)\n\n---\n\n### Kotlin (Android)\n\n```kotlin\nimport com.runanywhere.sdk.public.RunAnywhere\nimport com.runanywhere.sdk.public.extensions.*\n\n// 1. Initialize\nLlamaCPP.register()\nRunAnywhere.initialize(environment = SDKEnvironment.DEVELOPMENT)\n\n// 2. Load a model\nRunAnywhere.downloadModel(\"smollm2-360m\").collect { println(\"${it.progress * 100}%\") }\nRunAnywhere.loadLLMModel(\"smollm2-360m\")\n\n// 3. Generate\nval response = RunAnywhere.chat(\"What is the capital of France?\")\nprintln(response) // \"Paris is the capital of France.\"\n```\n\n**Install via Gradle:**\n\n```kotlin\ndependencies {\n    implementation(\"com.runanywhere.sdk:runanywhere-kotlin:0.1.4\")\n    implementation(\"com.runanywhere.sdk:runanywhere-core-llamacpp:0.1.4\")\n}\n```\n\n[Full documentation ‚Üí](https://docs.runanywhere.ai/kotlin/introduction) ¬∑ [Source code](sdk/runanywhere-kotlin/)\n\n---\n\n### React Native\n\n```typescript\nimport { RunAnywhere, SDKEnvironment } from '@runanywhere/core';\nimport { LlamaCPP } from '@runanywhere/llamacpp';\n\n// 1. Initialize\nawait RunAnywhere.initialize({ environment: SDKEnvironment.Development });\nLlamaCPP.register();\n\n// 2. Load a model\nawait RunAnywhere.downloadModel('smollm2-360m');\nawait RunAnywhere.loadModel(modelPath);\n\n// 3. Generate\nconst response = await RunAnywhere.chat('What is the capital of France?');\nconsole.log(response); // \"Paris is the capital of France.\"\n```\n\n**Install via npm:**\n\n```bash\nnpm install @runanywhere/core @runanywhere/llamacpp\n```\n\n[Full documentation ‚Üí](https://docs.runanywhere.ai/react-native/introduction) ¬∑ [Source code](sdk/runanywhere-react-native/)\n\n---\n\n### Flutter\n\n```dart\nimport 'package:runanywhere/runanywhere.dart';\nimport 'package:runanywhere_llamacpp/runanywhere_llamacpp.dart';\n\n// 1. Initialize\nawait RunAnywhere.initialize();\nawait LlamaCpp.register();\n\n// 2. Load a model\nawait RunAnywhere.downloadModel('smollm2-360m');\nawait RunAnywhere.loadModel('smollm2-360m');\n\n// 3. Generate\nfinal response = await RunAnywhere.chat('What is the capital of France?');\nprint(response); // \"Paris is the capital of France.\"\n```\n\n**Install via pub.dev:**\n\n```yaml\ndependencies:\n  runanywhere: ^0.15.11\n  runanywhere_llamacpp: ^0.15.11\n```\n\n[Full documentation ‚Üí](https://docs.runanywhere.ai/flutter/introduction) ¬∑ [Source code](sdk/runanywhere-flutter/)\n\n---\n\n## Sample Apps\n\nFull-featured demo applications demonstrating SDK capabilities:\n\n| Platform | Source Code | Download |\n|----------|-------------|----------|\n| iOS | [examples/ios/RunAnywhereAI](examples/ios/RunAnywhereAI/) | [App Store](https://apps.apple.com/us/app/runanywhere/id6756506307) |\n| Android | [examples/android/RunAnywhereAI](examples/android/RunAnywhereAI/) | [Google Play](https://play.google.com/store/apps/details?id=com.runanywhere.runanywhereai) |\n| React Native | [examples/react-native/RunAnywhereAI](examples/react-native/RunAnywhereAI/) | Build from source |\n| Flutter | [examples/flutter/RunAnywhereAI](examples/flutter/RunAnywhereAI/) | Build from source |\n\n---\n\n## Features\n\n| Feature | iOS | Android | React Native | Flutter |\n|---------|-----|---------|--------------|---------|\n| LLM Text Generation | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |\n| Streaming | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |\n| Speech-to-Text | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |\n| Text-to-Speech | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |\n| Voice Assistant Pipeline | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |\n| Model Download + Progress | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |\n| Structured Output (JSON) | ‚úÖ | ‚úÖ | üîú | üîú |\n| Apple Foundation Models | ‚úÖ | ‚Äî | ‚Äî | ‚Äî |\n\n---\n\n## Supported Models\n\n### LLM (GGUF format via llama.cpp)\n\n| Model | Size | RAM Required | Use Case |\n|-------|------|--------------|----------|\n| SmolLM2 360M | ~400MB | 500MB | Fast, lightweight |\n| Qwen 2.5 0.5B | ~500MB | 600MB | Multilingual |\n| Llama 3.2 1B | ~1GB | 1.2GB | Balanced |\n| Mistral 7B Q4 | ~4GB | 5GB | High quality |\n\n### Speech-to-Text (Whisper via ONNX)\n\n| Model | Size | Languages |\n|-------|------|-----------|\n| Whisper Tiny | ~75MB | English |\n| Whisper Base | ~150MB | Multilingual |\n\n### Text-to-Speech (Piper via ONNX)\n\n| Voice | Size | Language |\n|-------|------|----------|\n| Piper US English | ~65MB | English (US) |\n| Piper British English | ~65MB | English (UK) |\n\n---\n\n## Repository Structure\n\n```\nrunanywhere-sdks/\n‚îú‚îÄ‚îÄ sdk/\n‚îÇ   ‚îú‚îÄ‚îÄ runanywhere-swift/          # iOS/macOS SDK\n‚îÇ   ‚îú‚îÄ‚îÄ runanywhere-kotlin/         # Android SDK\n‚îÇ   ‚îú‚îÄ‚îÄ runanywhere-react-native/   # React Native SDK\n‚îÇ   ‚îú‚îÄ‚îÄ runanywhere-flutter/        # Flutter SDK\n‚îÇ   ‚îî‚îÄ‚îÄ runanywhere-commons/        # Shared C++ core\n‚îÇ\n‚îú‚îÄ‚îÄ examples/\n‚îÇ   ‚îú‚îÄ‚îÄ ios/RunAnywhereAI/          # iOS sample app\n‚îÇ   ‚îú‚îÄ‚îÄ android/RunAnywhereAI/      # Android sample app\n‚îÇ   ‚îú‚îÄ‚îÄ react-native/RunAnywhereAI/ # React Native sample app\n‚îÇ   ‚îî‚îÄ‚îÄ flutter/RunAnywhereAI/      # Flutter sample app\n‚îÇ\n‚îî‚îÄ‚îÄ docs/                           # Documentation\n```\n\n---\n\n## Requirements\n\n| Platform | Minimum | Recommended |\n|----------|---------|-------------|\n| iOS | 17.0+ | 17.0+ |\n| macOS | 14.0+ | 14.0+ |\n| Android | API 24 (7.0) | API 28+ |\n| React Native | 0.74+ | 0.76+ |\n| Flutter | 3.10+ | 3.24+ |\n\n**Memory:** 2GB minimum, 4GB+ recommended for larger models\n\n---\n\n## Contributing\n\nWe welcome contributions. See our [Contributing Guide](CONTRIBUTING.md) for details.\n\n```bash\n# Clone the repo\ngit clone https://github.com/RunanywhereAI/runanywhere-sdks.git\n\n# Set up a specific SDK (example: Swift)\ncd runanywhere-sdks/sdk/runanywhere-swift\n./scripts/build-swift.sh --setup\n\n# Run the sample app\ncd ../../examples/ios/RunAnywhereAI\nopen RunAnywhereAI.xcodeproj\n```\n\n---\n\n## Support\n\n- **Discord:** [Join our community](https://discord.gg/N359FBbDVd)\n- **GitHub Issues:** [Report bugs or request features](https://github.com/RunanywhereAI/runanywhere-sdks/issues)\n- **Email:** founders@runanywhere.ai\n- **Twitter:** [@RunanywhereAI](https://twitter.com/RunanywhereAI)\n\n---\n\n## License\n\nApache 2.0 ‚Äî see [LICENSE](LICENSE) for details.\n",
      "stars_today": 112
    },
    {
      "id": 865675427,
      "name": "zhihu-plus-plus",
      "full_name": "zly2006/zhihu-plus-plus",
      "description": "ÂéªÂπøÂëä„ÄÅÂç†Áî®‰Ωé„ÄÅAIÂ§ßÊ®°ÂûãpoweredÁöÑÊñ∞Êó∂‰ª£Áü•‰πéÂÆâÂçìÁ´Ø‰ΩìÈ™å„ÄÇ",
      "html_url": "https://github.com/zly2006/zhihu-plus-plus",
      "stars": 503,
      "forks": 17,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2024-09-30T23:44:47Z",
      "updated_at": "2026-01-24T01:54:05Z",
      "pushed_at": "2026-01-23T18:45:35Z",
      "open_issues": 7,
      "owner": {
        "login": "zly2006",
        "avatar_url": "https://avatars.githubusercontent.com/u/66198935?v=4"
      },
      "readme": "# Zhihu++ÔºöÊ≥®ÈáçÈöêÁßÅ„ÄÅ‰∫íËÅîÁΩë‰∏™‰∫∫ÊùÉÂà©ÂíåÊó†ÂπøÂëäÁöÑÁü•‰πéÂÆ¢Êà∑Á´Ø\n\n[![GitHub release](https://img.shields.io/github/v/release/zly2006/zhihu-plus-plus) ![](https://img.shields.io/github/downloads/zly2006/zhihu-plus-plus/total)](https://github.com/zly2006/zhihu-plus-plus/releases)\n\n<img src=\"misc/zhihu_shit.png\" width=\"100\" height=\"100\" />\n\n**ÂÖ≥‰∫éÂõæÊ†á:** ÊàëÁöÑÊú¨ÊÑèÊòØÊÉ≥ËØ¥Áü•‰πéÂÆòÊñπÂÆ¢Êà∑Á´ØÂ∞±ÊòØ‰∏ÄÂù®Ôºå‰ΩÜÊòØ‰πüÊúâÂæàÂ§ö‰∫∫Ë°®Á§∫ÂΩ±ÂìçËßÇÊÑüÔºåÊïÖÂú®Ê≠§ÂæÅÈõÜÂõæÊ†áËÆæËÆ°ÔºåÊúÄÂ•Ω‰∏çË¶Å‰æµÁäØÁü•‰πéÁöÑÂïÜÊ†áÊùÉ„ÄÇÊ¨¢ËøéÂèëIssueËÆ®ËÆ∫„ÄÇ\n\nÊú¨È°πÁõÆËøò‰∏çÂ§üÂÆåÂñÑÔºåÊ¨¢ËøéPRÔºåÂ¶ÇÊûúÂØπÁ¨¨‰∏âÊñπÁü•‰πéÂÆ¢Êà∑Á´ØÊúâÂÖ¥Ë∂£Ôºå‰πüÂèØ‰ª•ËØïËØïÊó∂Èó¥Êõ¥Êó©„ÄÅÂäüËÉΩÊõ¥ÂÖ®Èù¢ÁöÑ[Hydrogen](https://github.com/zhihulite/Hydrogen)\n\nZhihu++Áã¨ÂàõÊú¨Âú∞Êé®ËçêÁÆóÊ≥ïÔºåÊääÂÜÖÂÆπÊé®ËçêÂÆåÂÖ®ÊîæÂú®Êú¨Âú∞ËøõË°åÔºå‰∏∫ÊÇ®Êèê‰æõÂíåÁ≠õÈÄâÈ´òË¥®ÈáèÂÜÖÂÆπ„ÄÇ\nÊú¨Âú∞Êé®ËçêÁÆóÊ≥ïÂÆåÂÖ®Áã¨Á´ã‰∫éÁü•‰πéÁÆóÊ≥ïÔºå‰æùËµñÁà¨Ëô´ËøêË°åÔºåÂèØ‰ª•Ëá™Áî±ÂÆöÂà∂ÂêÑÁßçÊé®ËçêÊùÉÈáçÔºå‰øùËØÅÁúãÂà∞Ëá™Â∑±ÊÉ≥ÁúãÁöÑÂÜÖÂÆπ„ÄÇ\nÊàëÁõ∏‰ø°ÔºåËøôÁÇπÁªµËñÑ‰πãÂäõÂèØ‰ª•Â∏ÆÂä©ÂπøÂ§ßÁî®Êà∑‰ªéÂ§ßÂÖ¨Âè∏ÁöÑÊâã‰∏≠Â§∫ÂõûÊú¨ËØ•Â±û‰∫éÊàë‰ª¨ÁöÑÊùÉÂà©‚Äî‚ÄîÈÄâÊã©Ëá™Â∑±ÁöÑÁîüÊ¥ªÔºå‰∏çË¢´ÁÆóÊ≥ïÂ•¥ÂΩπÁöÑÊùÉÂà©„ÄÇ\n\n[‰∫§ÊµÅÁæ§](https://qm.qq.com/q/Rz6KFswFoK) Áæ§Âè∑Ôºö619307382\n\n[‰∫§ÊµÅ„ÄÅÂèçÈ¶à discord](https://discord.gg/YCPFZV5XSA) ÔºàËØ∑Âú® my-other-apps/zhihu-plus-plus È¢ëÈÅìËÆ®ËÆ∫Ôºâ\n\nÁü•‰πéÊâãÊú∫ÂÆ¢Êà∑Á´ØÔºåËπ≤ÂùëÁ•ûÂô®„ÄÇÂéªÂπøÂëäÔºåÂéªÊé®ÂπøËΩØÊñáÔºåÂéªÊé®ÈîÄÂ∏¶Ë¥ßÔºåÂéªÁõêÈÄâ‰∏ìÊ†è„ÄÇ\n\nÊîØÊåÅÊâãÊú∫Á´Ø/ÁΩëÈ°µÁ´Ø/Ê∑∑ÂêàÁ≠âÂ§öÁßçÊé®ËçêÊñπÊ°à„ÄÇ\n\nÂèØ‰ª•ËÆæÁΩÆÂ±èËîΩËØç„ÄÅAIÂ±èËîΩÂõûÁ≠î„ÄÅÂ±èËîΩÁî®Êà∑„ÄÅÂ±èËîΩËØùÈ¢òÁ≠â„ÄÇ\n\nÊú¨È°πÁõÆ‰∏çÊòØÁªèÂÖ∏ÊÑè‰πâ‰∏äÁöÑËá™Áî±ËΩØ‰ª∂ÔºåËØ¶ËßÅ[ÊéàÊùÉÂçèËÆÆ](LICENSE.md)„ÄÇ\n\n## ‰∏ãËΩΩ\n\nÂëäÂà´Áü•‰πé 110MB+ ÁöÑÂÆ¢Êà∑Á´ØÔºåÂè™Ë¶Å 3 MBÔºÅ\n\n[ÁÇπÊàë‰∏ãËΩΩ](https://github.com/zly2006/zhihu-plus-plus/releases)\n\n[‰∏ãËΩΩÊúÄÊñ∞ÂºÄÂèëÁâàÊú¨](https://github.com/zly2006/zhihu-plus-plus/releases/tag/nightly)\n\n## Ë∑ØÁ∫øÂõæ\n\n### Â∑≤ÁªèÂÆûÁé∞ÁöÑÂäüËÉΩ\n\n- ÁôªÂΩï\n  - ÊîØÊåÅÊâãÊú∫È™åËØÅÁ†ÅÁôªÂΩï\n  - ÊîØÊåÅÈÄöËøáÊâ´Á†ÅÂú®ÁîµËÑëÁ´ØÁôªÂΩï\n  - ÊîØÊåÅÊâãÂä®ËÆæÁΩÆcookieÁôªÂΩï\n- È¶ñÈ°µÊé®Ëçê\n  - ÊîØÊåÅ Web Á´ØÊé®ËçêÁÆóÊ≥ï\n  - ÊîØÊåÅÂÆâÂçìÁ´ØÊé®ËçêÁÆóÊ≥ï\n  - ÊîØÊåÅÂàáÊç¢ **ÁôªÂΩïÁä∂ÊÄÅ / ÈùûÁôªÂΩïÁä∂ÊÄÅ** ‰∏ãÁöÑÊé®ËçêÔºåÈò≤Ê≠¢‰ø°ÊÅØËåßÊàø\n- ÈòÖËØªÂõûÁ≠î\n- ÈòÖËØªÊñáÁ´†\n- ÊúóËØªÂÜÖÂÆπ\n  - Âê¨ÊñáÁ´†\n  - Âê¨ÂõûÁ≠î\n- ÂõûÁ≠îÈ°µÈïøÊåâ‰øùÂ≠òÂõæÁâá **Êó†Ê∞¥Âç∞**\n- ËøáÊª§ÂπøÂëä„ÄÅËΩØÊñáÂíå‰ΩéË¥®ÈáèÂÜÖÂÆπ\n- ÊµèËßàÂô®Âî§Ëµ∑\n- ÂéÜÂè≤ËÆ∞ÂΩï\n- Êî∂ËóèÂ§π\n- Â±èËîΩËØç\n- Â±èËîΩÁî®Êà∑\n- ËØÑËÆ∫Âå∫\n- ÈÄöÁü•\n- Ë°®ÊÉÖÂåÖ\n  - ÁªèÂÖ∏Ë°®ÊÉÖ`[ÊÉäÂñú]`Âº∫ÂäøÂõûÂΩíÔºÅ\n- ÂÖ∂‰ªñ\n  - ÊîØÊåÅ zse96 v2 Á≠æÂêçÁÆóÊ≥ïÔºàÂèØ‰ª•Ë∞ÉÁî®99%ÁöÑÁΩëÈ°µÁ´ØAPIÔºâ\n  - ÊîØÊåÅÊ®°ÊãüÂÆâÂçìÁ´Ø API Ë∞ÉÁî®\n- ÂÖ∂‰ªñÔºàÈùûÁü•‰πéÔºâ\n  - Êèê‰æõ‰∫Ü‰∫åÁª¥Á†ÅÊâ´Á†ÅÁªìÊûúÂ±ïÁ§∫ÂíåÂ§çÂà∂ÂäüËÉΩÔºåÂèØÁî®‰∫éÊèêÂèñÁΩëÂùÄ„ÄÅWi-FiÂØÜÁ†ÅÁ≠â‰ø°ÊÅØ\n\n### ËÆ°ÂàíÂÆûÁé∞ÁöÑÂäüËÉΩ\n\n> [TODO](TODO.md)\n\n- Â±èËîΩËØùÈ¢ò\n",
      "stars_today": 101
    },
    {
      "id": 612354784,
      "name": "llama.cpp",
      "full_name": "ggml-org/llama.cpp",
      "description": "LLM inference in C/C++",
      "html_url": "https://github.com/ggml-org/llama.cpp",
      "stars": 93613,
      "forks": 14590,
      "language": "C++",
      "topics": [
        "ggml"
      ],
      "created_at": "2023-03-10T18:58:00Z",
      "updated_at": "2026-01-24T00:38:23Z",
      "pushed_at": "2026-01-23T19:01:39Z",
      "open_issues": 1037,
      "owner": {
        "login": "ggml-org",
        "avatar_url": "https://avatars.githubusercontent.com/u/134263123?v=4"
      },
      "readme": "# llama.cpp\n\n![llama](https://user-images.githubusercontent.com/1991296/230134379-7181e485-c521-4d23-a0d6-f7b3b61ba524.png)\n\n[![License: MIT](https://img.shields.io/badge/license-MIT-blue.svg)](https://opensource.org/licenses/MIT)\n[![Release](https://img.shields.io/github/v/release/ggml-org/llama.cpp)](https://github.com/ggml-org/llama.cpp/releases)\n[![Server](https://github.com/ggml-org/llama.cpp/actions/workflows/server.yml/badge.svg)](https://github.com/ggml-org/llama.cpp/actions/workflows/server.yml)\n\n[Manifesto](https://github.com/ggml-org/llama.cpp/discussions/205) / [ggml](https://github.com/ggml-org/ggml) / [ops](https://github.com/ggml-org/llama.cpp/blob/master/docs/ops.md)\n\nLLM inference in C/C++\n\n## Recent API changes\n\n- [Changelog for `libllama` API](https://github.com/ggml-org/llama.cpp/issues/9289)\n- [Changelog for `llama-server` REST API](https://github.com/ggml-org/llama.cpp/issues/9291)\n\n## Hot topics\n\n- **[guide : using the new WebUI of llama.cpp](https://github.com/ggml-org/llama.cpp/discussions/16938)**\n- [guide : running gpt-oss with llama.cpp](https://github.com/ggml-org/llama.cpp/discussions/15396)\n- [[FEEDBACK] Better packaging for llama.cpp to support downstream consumers ü§ó](https://github.com/ggml-org/llama.cpp/discussions/15313)\n- Support for the `gpt-oss` model with native MXFP4 format has been added | [PR](https://github.com/ggml-org/llama.cpp/pull/15091) | [Collaboration with NVIDIA](https://blogs.nvidia.com/blog/rtx-ai-garage-openai-oss) | [Comment](https://github.com/ggml-org/llama.cpp/discussions/15095)\n- Multimodal support arrived in `llama-server`: [#12898](https://github.com/ggml-org/llama.cpp/pull/12898) | [documentation](./docs/multimodal.md)\n- VS Code extension for FIM completions: https://github.com/ggml-org/llama.vscode\n- Vim/Neovim plugin for FIM completions: https://github.com/ggml-org/llama.vim\n- Hugging Face Inference Endpoints now support GGUF out of the box! https://github.com/ggml-org/llama.cpp/discussions/9669\n- Hugging Face GGUF editor: [discussion](https://github.com/ggml-org/llama.cpp/discussions/9268) | [tool](https://huggingface.co/spaces/CISCai/gguf-editor)\n\n----\n\n## Quick start\n\nGetting started with llama.cpp is straightforward. Here are several ways to install it on your machine:\n\n- Install `llama.cpp` using [brew, nix or winget](docs/install.md)\n- Run with Docker - see our [Docker documentation](docs/docker.md)\n- Download pre-built binaries from the [releases page](https://github.com/ggml-org/llama.cpp/releases)\n- Build from source by cloning this repository - check out [our build guide](docs/build.md)\n\nOnce installed, you'll need a model to work with. Head to the [Obtaining and quantizing models](#obtaining-and-quantizing-models) section to learn more.\n\nExample command:\n\n```sh\n# Use a local model file\nllama-cli -m my_model.gguf\n\n# Or download and run a model directly from Hugging Face\nllama-cli -hf ggml-org/gemma-3-1b-it-GGUF\n\n# Launch OpenAI-compatible API server\nllama-server -hf ggml-org/gemma-3-1b-it-GGUF\n```\n\n## Description\n\nThe main goal of `llama.cpp` is to enable LLM inference with minimal setup and state-of-the-art performance on a wide\nrange of hardware - locally and in the cloud.\n\n- Plain C/C++ implementation without any dependencies\n- Apple silicon is a first-class citizen - optimized via ARM NEON, Accelerate and Metal frameworks\n- AVX, AVX2, AVX512 and AMX support for x86 architectures\n- RVV, ZVFH, ZFH, ZICBOP and ZIHINTPAUSE support for RISC-V architectures\n- 1.5-bit, 2-bit, 3-bit, 4-bit, 5-bit, 6-bit, and 8-bit integer quantization for faster inference and reduced memory use\n- Custom CUDA kernels for running LLMs on NVIDIA GPUs (support for AMD GPUs via HIP and Moore Threads GPUs via MUSA)\n- Vulkan and SYCL backend support\n- CPU+GPU hybrid inference to partially accelerate models larger than the total VRAM capacity\n\nThe `llama.cpp` project is the main playground for developing new features for the [ggml](https://github.com/ggml-org/ggml) library.\n\n<details>\n<summary>Models</summary>\n\nTypically finetunes of the base models below are supported as well.\n\nInstructions for adding support for new models: [HOWTO-add-model.md](docs/development/HOWTO-add-model.md)\n\n#### Text-only\n\n- [X] LLaMA ü¶ô\n- [x] LLaMA 2 ü¶ôü¶ô\n- [x] LLaMA 3 ü¶ôü¶ôü¶ô\n- [X] [Mistral 7B](https://huggingface.co/mistralai/Mistral-7B-v0.1)\n- [x] [Mixtral MoE](https://huggingface.co/models?search=mistral-ai/Mixtral)\n- [x] [DBRX](https://huggingface.co/databricks/dbrx-instruct)\n- [x] [Jamba](https://huggingface.co/ai21labs)\n- [X] [Falcon](https://huggingface.co/models?search=tiiuae/falcon)\n- [X] [Chinese LLaMA / Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca) and [Chinese LLaMA-2 / Alpaca-2](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2)\n- [X] [Vigogne (French)](https://github.com/bofenghuang/vigogne)\n- [X] [BERT](https://github.com/ggml-org/llama.cpp/pull/5423)\n- [X] [Koala](https://bair.berkeley.edu/blog/2023/04/03/koala/)\n- [X] [Baichuan 1 & 2](https://huggingface.co/models?search=baichuan-inc/Baichuan) + [derivations](https://huggingface.co/hiyouga/baichuan-7b-sft)\n- [X] [Aquila 1 & 2](https://huggingface.co/models?search=BAAI/Aquila)\n- [X] [Starcoder models](https://github.com/ggml-org/llama.cpp/pull/3187)\n- [X] [Refact](https://huggingface.co/smallcloudai/Refact-1_6B-fim)\n- [X] [MPT](https://github.com/ggml-org/llama.cpp/pull/3417)\n- [X] [Bloom](https://github.com/ggml-org/llama.cpp/pull/3553)\n- [x] [Yi models](https://huggingface.co/models?search=01-ai/Yi)\n- [X] [StableLM models](https://huggingface.co/stabilityai)\n- [x] [Deepseek models](https://huggingface.co/models?search=deepseek-ai/deepseek)\n- [x] [Qwen models](https://huggingface.co/models?search=Qwen/Qwen)\n- [x] [PLaMo-13B](https://github.com/ggml-org/llama.cpp/pull/3557)\n- [x] [Phi models](https://huggingface.co/models?search=microsoft/phi)\n- [x] [PhiMoE](https://github.com/ggml-org/llama.cpp/pull/11003)\n- [x] [GPT-2](https://huggingface.co/gpt2)\n- [x] [Orion 14B](https://github.com/ggml-org/llama.cpp/pull/5118)\n- [x] [InternLM2](https://huggingface.co/models?search=internlm2)\n- [x] [CodeShell](https://github.com/WisdomShell/codeshell)\n- [x] [Gemma](https://ai.google.dev/gemma)\n- [x] [Mamba](https://github.com/state-spaces/mamba)\n- [x] [Grok-1](https://huggingface.co/keyfan/grok-1-hf)\n- [x] [Xverse](https://huggingface.co/models?search=xverse)\n- [x] [Command-R models](https://huggingface.co/models?search=CohereForAI/c4ai-command-r)\n- [x] [SEA-LION](https://huggingface.co/models?search=sea-lion)\n- [x] [GritLM-7B](https://huggingface.co/GritLM/GritLM-7B) + [GritLM-8x7B](https://huggingface.co/GritLM/GritLM-8x7B)\n- [x] [OLMo](https://allenai.org/olmo)\n- [x] [OLMo 2](https://allenai.org/olmo)\n- [x] [OLMoE](https://huggingface.co/allenai/OLMoE-1B-7B-0924)\n- [x] [Granite models](https://huggingface.co/collections/ibm-granite/granite-code-models-6624c5cec322e4c148c8b330)\n- [x] [GPT-NeoX](https://github.com/EleutherAI/gpt-neox) + [Pythia](https://github.com/EleutherAI/pythia)\n- [x] [Snowflake-Arctic MoE](https://huggingface.co/collections/Snowflake/arctic-66290090abe542894a5ac520)\n- [x] [Smaug](https://huggingface.co/models?search=Smaug)\n- [x] [Poro 34B](https://huggingface.co/LumiOpen/Poro-34B)\n- [x] [Bitnet b1.58 models](https://huggingface.co/1bitLLM)\n- [x] [Flan T5](https://huggingface.co/models?search=flan-t5)\n- [x] [Open Elm models](https://huggingface.co/collections/apple/openelm-instruct-models-6619ad295d7ae9f868b759ca)\n- [x] [ChatGLM3-6b](https://huggingface.co/THUDM/chatglm3-6b) + [ChatGLM4-9b](https://huggingface.co/THUDM/glm-4-9b) + [GLMEdge-1.5b](https://huggingface.co/THUDM/glm-edge-1.5b-chat) + [GLMEdge-4b](https://huggingface.co/THUDM/glm-edge-4b-chat)\n- [x] [GLM-4-0414](https://huggingface.co/collections/THUDM/glm-4-0414-67f3cbcb34dd9d252707cb2e)\n- [x] [SmolLM](https://huggingface.co/collections/HuggingFaceTB/smollm-6695016cad7167254ce15966)\n- [x] [EXAONE-3.0-7.8B-Instruct](https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct)\n- [x] [FalconMamba Models](https://huggingface.co/collections/tiiuae/falconmamba-7b-66b9a580324dd1598b0f6d4a)\n- [x] [Jais](https://huggingface.co/inceptionai/jais-13b-chat)\n- [x] [Bielik-11B-v2.3](https://huggingface.co/collections/speakleash/bielik-11b-v23-66ee813238d9b526a072408a)\n- [x] [RWKV-6](https://github.com/BlinkDL/RWKV-LM)\n- [x] [QRWKV-6](https://huggingface.co/recursal/QRWKV6-32B-Instruct-Preview-v0.1)\n- [x] [GigaChat-20B-A3B](https://huggingface.co/ai-sage/GigaChat-20B-A3B-instruct)\n- [X] [Trillion-7B-preview](https://huggingface.co/trillionlabs/Trillion-7B-preview)\n- [x] [Ling models](https://huggingface.co/collections/inclusionAI/ling-67c51c85b34a7ea0aba94c32)\n- [x] [LFM2 models](https://huggingface.co/collections/LiquidAI/lfm2-686d721927015b2ad73eaa38)\n- [x] [Hunyuan models](https://huggingface.co/collections/tencent/hunyuan-dense-model-6890632cda26b19119c9c5e7)\n- [x] [BailingMoeV2 (Ring/Ling 2.0) models](https://huggingface.co/collections/inclusionAI/ling-v2-68bf1dd2fc34c306c1fa6f86)\n\n#### Multimodal\n\n- [x] [LLaVA 1.5 models](https://huggingface.co/collections/liuhaotian/llava-15-653aac15d994e992e2677a7e), [LLaVA 1.6 models](https://huggingface.co/collections/liuhaotian/llava-16-65b9e40155f60fd046a5ccf2)\n- [x] [BakLLaVA](https://huggingface.co/models?search=SkunkworksAI/Bakllava)\n- [x] [Obsidian](https://huggingface.co/NousResearch/Obsidian-3B-V0.5)\n- [x] [ShareGPT4V](https://huggingface.co/models?search=Lin-Chen/ShareGPT4V)\n- [x] [MobileVLM 1.7B/3B models](https://huggingface.co/models?search=mobileVLM)\n- [x] [Yi-VL](https://huggingface.co/models?search=Yi-VL)\n- [x] [Mini CPM](https://huggingface.co/models?search=MiniCPM)\n- [x] [Moondream](https://huggingface.co/vikhyatk/moondream2)\n- [x] [Bunny](https://github.com/BAAI-DCAI/Bunny)\n- [x] [GLM-EDGE](https://huggingface.co/models?search=glm-edge)\n- [x] [Qwen2-VL](https://huggingface.co/collections/Qwen/qwen2-vl-66cee7455501d7126940800d)\n- [x] [LFM2-VL](https://huggingface.co/collections/LiquidAI/lfm2-vl-68963bbc84a610f7638d5ffa)\n\n</details>\n\n<details>\n<summary>Bindings</summary>\n\n- Python: [ddh0/easy-llama](https://github.com/ddh0/easy-llama)\n- Python: [abetlen/llama-cpp-python](https://github.com/abetlen/llama-cpp-python)\n- Go: [go-skynet/go-llama.cpp](https://github.com/go-skynet/go-llama.cpp)\n- Node.js: [withcatai/node-llama-cpp](https://github.com/withcatai/node-llama-cpp)\n- JS/TS (llama.cpp server client): [lgrammel/modelfusion](https://modelfusion.dev/integration/model-provider/llamacpp)\n- JS/TS (Programmable Prompt Engine CLI): [offline-ai/cli](https://github.com/offline-ai/cli)\n- JavaScript/Wasm (works in browser): [tangledgroup/llama-cpp-wasm](https://github.com/tangledgroup/llama-cpp-wasm)\n- Typescript/Wasm (nicer API, available on npm): [ngxson/wllama](https://github.com/ngxson/wllama)\n- Ruby: [yoshoku/llama_cpp.rb](https://github.com/yoshoku/llama_cpp.rb)\n- Rust (more features): [edgenai/llama_cpp-rs](https://github.com/edgenai/llama_cpp-rs)\n- Rust (nicer API): [mdrokz/rust-llama.cpp](https://github.com/mdrokz/rust-llama.cpp)\n- Rust (more direct bindings): [utilityai/llama-cpp-rs](https://github.com/utilityai/llama-cpp-rs)\n- Rust (automated build from crates.io): [ShelbyJenkins/llm_client](https://github.com/ShelbyJenkins/llm_client)\n- C#/.NET: [SciSharp/LLamaSharp](https://github.com/SciSharp/LLamaSharp)\n- C#/VB.NET (more features - community license): [LM-Kit.NET](https://docs.lm-kit.com/lm-kit-net/index.html)\n- Scala 3: [donderom/llm4s](https://github.com/donderom/llm4s)\n- Clojure: [phronmophobic/llama.clj](https://github.com/phronmophobic/llama.clj)\n- React Native: [mybigday/llama.rn](https://github.com/mybigday/llama.rn)\n- Java: [kherud/java-llama.cpp](https://github.com/kherud/java-llama.cpp)\n- Java: [QuasarByte/llama-cpp-jna](https://github.com/QuasarByte/llama-cpp-jna)\n- Zig: [deins/llama.cpp.zig](https://github.com/Deins/llama.cpp.zig)\n- Flutter/Dart: [netdur/llama_cpp_dart](https://github.com/netdur/llama_cpp_dart)\n- Flutter: [xuegao-tzx/Fllama](https://github.com/xuegao-tzx/Fllama)\n- PHP (API bindings and features built on top of llama.cpp): [distantmagic/resonance](https://github.com/distantmagic/resonance) [(more info)](https://github.com/ggml-org/llama.cpp/pull/6326)\n- Guile Scheme: [guile_llama_cpp](https://savannah.nongnu.org/projects/guile-llama-cpp)\n- Swift [srgtuszy/llama-cpp-swift](https://github.com/srgtuszy/llama-cpp-swift)\n- Swift [ShenghaiWang/SwiftLlama](https://github.com/ShenghaiWang/SwiftLlama)\n- Delphi [Embarcadero/llama-cpp-delphi](https://github.com/Embarcadero/llama-cpp-delphi)\n- Go (no CGo needed): [hybridgroup/yzma](https://github.com/hybridgroup/yzma)\n- Android: [llama.android](/examples/llama.android)\n\n</details>\n\n<details>\n<summary>UIs</summary>\n\n*(to have a project listed here, it should clearly state that it depends on `llama.cpp`)*\n\n- [AI Sublime Text plugin](https://github.com/yaroslavyaroslav/OpenAI-sublime-text) (MIT)\n- [BonzAI App](https://apps.apple.com/us/app/bonzai-your-local-ai-agent/id6752847988) (proprietary)\n- [cztomsik/ava](https://github.com/cztomsik/ava) (MIT)\n- [Dot](https://github.com/alexpinel/Dot) (GPL)\n- [eva](https://github.com/ylsdamxssjxxdd/eva) (MIT)\n- [iohub/collama](https://github.com/iohub/coLLaMA) (Apache-2.0)\n- [janhq/jan](https://github.com/janhq/jan) (AGPL)\n- [johnbean393/Sidekick](https://github.com/johnbean393/Sidekick) (MIT)\n- [KanTV](https://github.com/zhouwg/kantv?tab=readme-ov-file) (Apache-2.0)\n- [KodiBot](https://github.com/firatkiral/kodibot) (GPL)\n- [llama.vim](https://github.com/ggml-org/llama.vim) (MIT)\n- [LARS](https://github.com/abgulati/LARS) (AGPL)\n- [Llama Assistant](https://github.com/vietanhdev/llama-assistant) (GPL)\n- [LLMFarm](https://github.com/guinmoon/LLMFarm?tab=readme-ov-file) (MIT)\n- [LLMUnity](https://github.com/undreamai/LLMUnity) (MIT)\n- [LMStudio](https://lmstudio.ai/) (proprietary)\n- [LocalAI](https://github.com/mudler/LocalAI) (MIT)\n- [LostRuins/koboldcpp](https://github.com/LostRuins/koboldcpp) (AGPL)\n- [MindMac](https://mindmac.app) (proprietary)\n- [MindWorkAI/AI-Studio](https://github.com/MindWorkAI/AI-Studio) (FSL-1.1-MIT)\n- [Mobile-Artificial-Intelligence/maid](https://github.com/Mobile-Artificial-Intelligence/maid) (MIT)\n- [Mozilla-Ocho/llamafile](https://github.com/Mozilla-Ocho/llamafile) (Apache-2.0)\n- [nat/openplayground](https://github.com/nat/openplayground) (MIT)\n- [nomic-ai/gpt4all](https://github.com/nomic-ai/gpt4all) (MIT)\n- [ollama/ollama](https://github.com/ollama/ollama) (MIT)\n- [oobabooga/text-generation-webui](https://github.com/oobabooga/text-generation-webui) (AGPL)\n- [PocketPal AI](https://github.com/a-ghorbani/pocketpal-ai) (MIT)\n- [psugihara/FreeChat](https://github.com/psugihara/FreeChat) (MIT)\n- [ptsochantaris/emeltal](https://github.com/ptsochantaris/emeltal) (MIT)\n- [pythops/tenere](https://github.com/pythops/tenere) (AGPL)\n- [ramalama](https://github.com/containers/ramalama) (MIT)\n- [semperai/amica](https://github.com/semperai/amica) (MIT)\n- [withcatai/catai](https://github.com/withcatai/catai) (MIT)\n- [Autopen](https://github.com/blackhole89/autopen) (GPL)\n\n</details>\n\n<details>\n<summary>Tools</summary>\n\n- [akx/ggify](https://github.com/akx/ggify) ‚Äì download PyTorch models from HuggingFace Hub and convert them to GGML\n- [akx/ollama-dl](https://github.com/akx/ollama-dl) ‚Äì download models from the Ollama library to be used directly with llama.cpp\n- [crashr/gppm](https://github.com/crashr/gppm) ‚Äì launch llama.cpp instances utilizing NVIDIA Tesla P40 or P100 GPUs with reduced idle power consumption\n- [gpustack/gguf-parser](https://github.com/gpustack/gguf-parser-go/tree/main/cmd/gguf-parser) - review/check the GGUF file and estimate the memory usage\n- [Styled Lines](https://marketplace.unity.com/packages/tools/generative-ai/styled-lines-llama-cpp-model-292902) (proprietary licensed, async wrapper of inference part for game development in Unity3d with pre-built Mobile and Web platform wrappers and a model example)\n- [unslothai/unsloth](https://github.com/unslothai/unsloth) ‚Äì ü¶• exports/saves fine-tuned and trained models to GGUF (Apache-2.0)\n\n</details>\n\n<details>\n<summary>Infrastructure</summary>\n\n- [Paddler](https://github.com/intentee/paddler) - Open-source LLMOps platform for hosting and scaling AI in your own infrastructure\n- [GPUStack](https://github.com/gpustack/gpustack) - Manage GPU clusters for running LLMs\n- [llama_cpp_canister](https://github.com/onicai/llama_cpp_canister) - llama.cpp as a smart contract on the Internet Computer, using WebAssembly\n- [llama-swap](https://github.com/mostlygeek/llama-swap) - transparent proxy that adds automatic model switching with llama-server\n- [Kalavai](https://github.com/kalavai-net/kalavai-client) - Crowdsource end to end LLM deployment at any scale\n- [llmaz](https://github.com/InftyAI/llmaz) - ‚ò∏Ô∏è Easy, advanced inference platform for large language models on Kubernetes.\n</details>\n\n<details>\n<summary>Games</summary>\n\n- [Lucy's Labyrinth](https://github.com/MorganRO8/Lucys_Labyrinth) - A simple maze game where agents controlled by an AI model will try to trick you.\n\n</details>\n\n\n## Supported backends\n\n| Backend | Target devices |\n| --- | --- |\n| [Metal](docs/build.md#metal-build) | Apple Silicon |\n| [BLAS](docs/build.md#blas-build) | All |\n| [BLIS](docs/backend/BLIS.md) | All |\n| [SYCL](docs/backend/SYCL.md) | Intel and Nvidia GPU |\n| [MUSA](docs/build.md#musa) | Moore Threads GPU |\n| [CUDA](docs/build.md#cuda) | Nvidia GPU |\n| [HIP](docs/build.md#hip) | AMD GPU |\n| [ZenDNN](docs/build.md#zendnn) | AMD CPU |\n| [Vulkan](docs/build.md#vulkan) | GPU |\n| [CANN](docs/build.md#cann) | Ascend NPU |\n| [OpenCL](docs/backend/OPENCL.md) | Adreno GPU |\n| [IBM zDNN](docs/backend/zDNN.md) | IBM Z & LinuxONE |\n| [WebGPU [In Progress]](docs/build.md#webgpu) | All |\n| [RPC](https://github.com/ggml-org/llama.cpp/tree/master/tools/rpc) | All |\n| [Hexagon [In Progress]](docs/backend/hexagon/README.md) | Snapdragon |\n\n## Obtaining and quantizing models\n\nThe [Hugging Face](https://huggingface.co) platform hosts a [number of LLMs](https://huggingface.co/models?library=gguf&sort=trending) compatible with `llama.cpp`:\n\n- [Trending](https://huggingface.co/models?library=gguf&sort=trending)\n- [LLaMA](https://huggingface.co/models?sort=trending&search=llama+gguf)\n\nYou can either manually download the GGUF file or directly use any `llama.cpp`-compatible models from [Hugging Face](https://huggingface.co/) or other model hosting sites, such as [ModelScope](https://modelscope.cn/), by using this CLI argument: `-hf <user>/<model>[:quant]`. For example:\n\n```sh\nllama-cli -hf ggml-org/gemma-3-1b-it-GGUF\n```\n\nBy default, the CLI would download from Hugging Face, you can switch to other options with the environment variable `MODEL_ENDPOINT`. For example, you may opt to downloading model checkpoints from ModelScope or other model sharing communities by setting the environment variable, e.g. `MODEL_ENDPOINT=https://www.modelscope.cn/`.\n\nAfter downloading a model, use the CLI tools to run it locally - see below.\n\n`llama.cpp` requires the model to be stored in the [GGUF](https://github.com/ggml-org/ggml/blob/master/docs/gguf.md) file format. Models in other data formats can be converted to GGUF using the `convert_*.py` Python scripts in this repo.\n\nThe Hugging Face platform provides a variety of online tools for converting, quantizing and hosting models with `llama.cpp`:\n\n- Use the [GGUF-my-repo space](https://huggingface.co/spaces/ggml-org/gguf-my-repo) to convert to GGUF format and quantize model weights to smaller sizes\n- Use the [GGUF-my-LoRA space](https://huggingface.co/spaces/ggml-org/gguf-my-lora) to convert LoRA adapters to GGUF format (more info: https://github.com/ggml-org/llama.cpp/discussions/10123)\n- Use the [GGUF-editor space](https://huggingface.co/spaces/CISCai/gguf-editor) to edit GGUF meta data in the browser (more info: https://github.com/ggml-org/llama.cpp/discussions/9268)\n- Use the [Inference Endpoints](https://ui.endpoints.huggingface.co/) to directly host `llama.cpp` in the cloud (more info: https://github.com/ggml-org/llama.cpp/discussions/9669)\n\nTo learn more about model quantization, [read this documentation](tools/quantize/README.md)\n\n## [`llama-cli`](tools/cli)\n\n#### A CLI tool for accessing and experimenting with most of `llama.cpp`'s functionality.\n\n- <details open>\n    <summary>Run in conversation mode</summary>\n\n    Models with a built-in chat template will automatically activate conversation mode. If this doesn't occur, you can manually enable it by adding `-cnv` and specifying a suitable chat template with `--chat-template NAME`\n\n    ```bash\n    llama-cli -m model.gguf\n\n    # > hi, who are you?\n    # Hi there! I'm your helpful assistant! I'm an AI-powered chatbot designed to assist and provide information to users like you. I'm here to help answer your questions, provide guidance, and offer support on a wide range of topics. I'm a friendly and knowledgeable AI, and I'm always happy to help with anything you need. What's on your mind, and how can I assist you today?\n    #\n    # > what is 1+1?\n    # Easy peasy! The answer to 1+1 is... 2!\n    ```\n\n    </details>\n\n- <details>\n    <summary>Run in conversation mode with custom chat template</summary>\n\n    ```bash\n    # use the \"chatml\" template (use -h to see the list of supported templates)\n    llama-cli -m model.gguf -cnv --chat-template chatml\n\n    # use a custom template\n    llama-cli -m model.gguf -cnv --in-prefix 'User: ' --reverse-prompt 'User:'\n    ```\n\n    </details>\n\n- <details>\n    <summary>Constrain the output with a custom grammar</summary>\n\n    ```bash\n    llama-cli -m model.gguf -n 256 --grammar-file grammars/json.gbnf -p 'Request: schedule a call at 8pm; Command:'\n\n    # {\"appointmentTime\": \"8pm\", \"appointmentDetails\": \"schedule a a call\"}\n    ```\n\n    The [grammars/](grammars/) folder contains a handful of sample grammars. To write your own, check out the [GBNF Guide](grammars/README.md).\n\n    For authoring more complex JSON grammars, check out https://grammar.intrinsiclabs.ai/\n\n    </details>\n\n\n## [`llama-server`](tools/server)\n\n#### A lightweight, [OpenAI API](https://github.com/openai/openai-openapi) compatible, HTTP server for serving LLMs.\n\n- <details open>\n    <summary>Start a local HTTP server with default configuration on port 8080</summary>\n\n    ```bash\n    llama-server -m model.gguf --port 8080\n\n    # Basic web UI can be accessed via browser: http://localhost:8080\n    # Chat completion endpoint: http://localhost:8080/v1/chat/completions\n    ```\n\n    </details>\n\n- <details>\n    <summary>Support multiple-users and parallel decoding</summary>\n\n    ```bash\n    # up to 4 concurrent requests, each with 4096 max context\n    llama-server -m model.gguf -c 16384 -np 4\n    ```\n\n    </details>\n\n- <details>\n    <summary>Enable speculative decoding</summary>\n\n    ```bash\n    # the draft.gguf model should be a small variant of the target model.gguf\n    llama-server -m model.gguf -md draft.gguf\n    ```\n\n    </details>\n\n- <details>\n    <summary>Serve an embedding model</summary>\n\n    ```bash\n    # use the /embedding endpoint\n    llama-server -m model.gguf --embedding --pooling cls -ub 8192\n    ```\n\n    </details>\n\n- <details>\n    <summary>Serve a reranking model</summary>\n\n    ```bash\n    # use the /reranking endpoint\n    llama-server -m model.gguf --reranking\n    ```\n\n    </details>\n\n- <details>\n    <summary>Constrain all outputs with a grammar</summary>\n\n    ```bash\n    # custom grammar\n    llama-server -m model.gguf --grammar-file grammar.gbnf\n\n    # JSON\n    llama-server -m model.gguf --grammar-file grammars/json.gbnf\n    ```\n\n    </details>\n\n\n## [`llama-perplexity`](tools/perplexity)\n\n#### A tool for measuring the [perplexity](tools/perplexity/README.md) [^1] (and other quality metrics) of a model over a given text.\n\n- <details open>\n    <summary>Measure the perplexity over a text file</summary>\n\n    ```bash\n    llama-perplexity -m model.gguf -f file.txt\n\n    # [1]15.2701,[2]5.4007,[3]5.3073,[4]6.2965,[5]5.8940,[6]5.6096,[7]5.7942,[8]4.9297, ...\n    # Final estimate: PPL = 5.4007 +/- 0.67339\n    ```\n\n    </details>\n\n- <details>\n    <summary>Measure KL divergence</summary>\n\n    ```bash\n    # TODO\n    ```\n\n    </details>\n\n[^1]: [https://huggingface.co/docs/transformers/perplexity](https://huggingface.co/docs/transformers/perplexity)\n\n## [`llama-bench`](tools/llama-bench)\n\n#### Benchmark the performance of the inference for various parameters.\n\n- <details open>\n    <summary>Run default benchmark</summary>\n\n    ```bash\n    llama-bench -m model.gguf\n\n    # Output:\n    # | model               |       size |     params | backend    | threads |          test |                  t/s |\n    # | ------------------- | ---------: | ---------: | ---------- | ------: | ------------: | -------------------: |\n    # | qwen2 1.5B Q4_0     | 885.97 MiB |     1.54 B | Metal,BLAS |      16 |         pp512 |      5765.41 ¬± 20.55 |\n    # | qwen2 1.5B Q4_0     | 885.97 MiB |     1.54 B | Metal,BLAS |      16 |         tg128 |        197.71 ¬± 0.81 |\n    #\n    # build: 3e0ba0e60 (4229)\n    ```\n\n    </details>\n\n## [`llama-simple`](examples/simple)\n\n#### A minimal example for implementing apps with `llama.cpp`. Useful for developers.\n\n- <details>\n    <summary>Basic text completion</summary>\n\n    ```bash\n    llama-simple -m model.gguf\n\n    # Hello my name is Kaitlyn and I am a 16 year old girl. I am a junior in high school and I am currently taking a class called \"The Art of\n    ```\n\n    </details>\n\n\n## Contributing\n\n- Contributors can open PRs\n- Collaborators will be invited based on contributions\n- Maintainers can push to branches in the `llama.cpp` repo and merge PRs into the `master` branch\n- Any help with managing issues, PRs and projects is very appreciated!\n- See [good first issues](https://github.com/ggml-org/llama.cpp/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) for tasks suitable for first contributions\n- Read the [CONTRIBUTING.md](CONTRIBUTING.md) for more information\n- Make sure to read this: [Inference at the edge](https://github.com/ggml-org/llama.cpp/discussions/205)\n- A bit of backstory for those who are interested: [Changelog podcast](https://changelog.com/podcast/532)\n\n## Other documentation\n\n- [cli](tools/cli/README.md)\n- [completion](tools/completion/README.md)\n- [server](tools/server/README.md)\n- [GBNF grammars](grammars/README.md)\n\n#### Development documentation\n\n- [How to build](docs/build.md)\n- [Running on Docker](docs/docker.md)\n- [Build on Android](docs/android.md)\n- [Performance troubleshooting](docs/development/token_generation_performance_tips.md)\n- [GGML tips & tricks](https://github.com/ggml-org/llama.cpp/wiki/GGML-Tips-&-Tricks)\n\n#### Seminal papers and background on the models\n\nIf your issue is with model generation quality, then please at least scan the following links and papers to understand the limitations of LLaMA models. This is especially important when choosing an appropriate model size and appreciating both the significant and subtle differences between LLaMA models and ChatGPT:\n- LLaMA:\n    - [Introducing LLaMA: A foundational, 65-billion-parameter large language model](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)\n    - [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971)\n- GPT-3\n    - [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)\n- GPT-3.5 / InstructGPT / ChatGPT:\n    - [Aligning language models to follow instructions](https://openai.com/research/instruction-following)\n    - [Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155)\n\n## XCFramework\nThe XCFramework is a precompiled version of the library for iOS, visionOS, tvOS,\nand macOS. It can be used in Swift projects without the need to compile the\nlibrary from source. For example:\n```swift\n// swift-tools-version: 5.10\n// The swift-tools-version declares the minimum version of Swift required to build this package.\n\nimport PackageDescription\n\nlet package = Package(\n    name: \"MyLlamaPackage\",\n    targets: [\n        .executableTarget(\n            name: \"MyLlamaPackage\",\n            dependencies: [\n                \"LlamaFramework\"\n            ]),\n        .binaryTarget(\n            name: \"LlamaFramework\",\n            url: \"https://github.com/ggml-org/llama.cpp/releases/download/b5046/llama-b5046-xcframework.zip\",\n            checksum: \"c19be78b5f00d8d29a25da41042cb7afa094cbf6280a225abe614b03b20029ab\"\n        )\n    ]\n)\n```\nThe above example is using an intermediate build `b5046` of the library. This can be modified\nto use a different version by changing the URL and checksum.\n\n## Completions\nCommand-line completion is available for some environments.\n\n#### Bash Completion\n```bash\n$ build/bin/llama-cli --completion-bash > ~/.llama-completion.bash\n$ source ~/.llama-completion.bash\n```\nOptionally this can be added to your `.bashrc` or `.bash_profile` to load it\nautomatically. For example:\n```console\n$ echo \"source ~/.llama-completion.bash\" >> ~/.bashrc\n```\n\n## Dependencies\n\n- [yhirose/cpp-httplib](https://github.com/yhirose/cpp-httplib) - Single-header HTTP server, used by `llama-server` - MIT license\n- [stb-image](https://github.com/nothings/stb) - Single-header image format decoder, used by multimodal subsystem - Public domain\n- [nlohmann/json](https://github.com/nlohmann/json) - Single-header JSON library, used by various tools/examples - MIT License\n- [miniaudio.h](https://github.com/mackron/miniaudio) - Single-header audio format decoder, used by multimodal subsystem - Public domain\n- [subprocess.h](https://github.com/sheredom/subprocess.h) - Single-header process launching solution for C and C++ - Public domain\n",
      "stars_today": 90
    },
    {
      "id": 215654064,
      "name": "temporal",
      "full_name": "temporalio/temporal",
      "description": "Temporal service",
      "html_url": "https://github.com/temporalio/temporal",
      "stars": 17876,
      "forks": 1306,
      "language": "Go",
      "topics": [
        "cronjob-scheduler",
        "distributed-cron",
        "distributed-systems",
        "golang",
        "microservice-framework",
        "microservice-orchestration",
        "microservices-architecture",
        "orchestrator",
        "service-bus",
        "service-fabric",
        "workflow-automation",
        "workflow-engine",
        "workflow-management",
        "workflow-management-system",
        "workflows"
      ],
      "created_at": "2019-10-16T22:15:35Z",
      "updated_at": "2026-01-24T02:03:09Z",
      "pushed_at": "2026-01-24T02:03:11Z",
      "open_issues": 650,
      "owner": {
        "login": "temporalio",
        "avatar_url": "https://avatars.githubusercontent.com/u/56493103?v=4"
      },
      "readme": "<div class=\"title-block\" style=\"text-align: center;\" align=\"center\">\n\n# Temporal‚Äîdurable execution platform\n\n<p><img title=\"temporal logo\" src=\"https://avatars.githubusercontent.com/u/56493103?s=320\" width=\"320\" height=\"320\"></p>\n\n[![GitHub Release](https://img.shields.io/github/v/release/temporalio/temporal)](https://github.com/temporalio/temporal/releases/latest)\n[![GitHub License](https://img.shields.io/github/license/temporalio/temporal)](https://github.com/temporalio/temporal/blob/main/LICENSE)\n[![Code Coverage](https://img.shields.io/badge/codecov-report-blue)](https://app.codecov.io/gh/temporalio/temporal)\n[![Community](https://img.shields.io/static/v1?label=community&message=get%20help&color=informational)](https://community.temporal.io)\n[![Go Report Card](https://goreportcard.com/badge/github.com/temporalio/temporal)](https://goreportcard.com/report/github.com/temporalio/temporal)\n\n**[Introduction](#introduction) &nbsp;&nbsp;&bull;&nbsp;&nbsp;**\n**[Getting Started](#getting-started) &nbsp;&nbsp;&bull;&nbsp;&nbsp;**\n**[Contributing](#contributing) &nbsp;&nbsp;&bull;&nbsp;&nbsp;**\n**[Temporal Docs](https://docs.temporal.io/) &nbsp;&nbsp;&bull;&nbsp;&nbsp;**\n**[Temporal 101](https://learn.temporal.io/courses/temporal_101/)**\n\n</div>\n\n## Introduction\n\nTemporal is a durable execution platform that enables developers to build scalable applications without sacrificing productivity or reliability.\nThe Temporal server executes units of application logic called Workflows in a resilient manner that automatically handles intermittent failures, and retries failed operations.\n\nTemporal is a mature technology that originated as a fork of Uber's Cadence.\nIt is developed by [Temporal Technologies](https://temporal.io/), a startup by the creators of Cadence.\n\n[![image](https://github.com/temporalio/temporal/assets/251288/693d18b5-01de-4a3b-b47b-96347b84f610)](https://youtu.be/wIpz4ioK0gI 'Getting to know Temporal')\n\n## Getting Started\n\n### Download and Start Temporal Server Locally\n\nExecute the following commands to start a pre-built image along with all the dependencies.\n\n```bash\nbrew install temporal\ntemporal server start-dev\n```\n\nRefer to [Temporal CLI](https://docs.temporal.io/cli/#installation) documentation for more installation options.\n\n### Run the Samples\n\nClone or download samples for [Go](https://github.com/temporalio/samples-go) or [Java](https://github.com/temporalio/samples-java) and run them with the local Temporal server.\nWe have a number of [HelloWorld type scenarios](https://github.com/temporalio/samples-java#helloworld) available, as well as more advanced ones. Note that the sets of samples are currently different between Go and Java.\n\n### Use CLI\n\nUse [Temporal CLI](https://docs.temporal.io/cli/) to interact with the running Temporal server.\n\n```bash\ntemporal operator namespace list\ntemporal workflow list\n```\n\n### Use Temporal Web UI\n\nTry [Temporal Web UI](https://docs.temporal.io/web-ui) by opening [http://localhost:8233](http://localhost:8233) for viewing your sample workflows executing on Temporal.\n\n## Repository\n\nThis repository contains the source code of the Temporal server. To implement Workflows, Activities and Workers, use one of the [supported languages](https://docs.temporal.io/dev-guide/).\n\n## Contributing\n\nWe'd love your help in making Temporal great.\n\nHelpful links to get started:\n\n- [work on or propose a new feature](https://github.com/temporalio/proposals)\n- [learn about the Temporal Server architecture](./docs/architecture/README.md)\n- [learn how to build and run the Temporal Server locally](./CONTRIBUTING.md)\n- [learn about Temporal Server testing tools and best practices](./docs/development/testing.md)\n- join the Temporal community [forum](https://community.temporal.io) and [Slack](https://t.mp/slack)\n\n## License\n\n[MIT License](https://github.com/temporalio/temporal/blob/main/LICENSE)\n",
      "stars_today": 79
    },
    {
      "id": 186733095,
      "name": "v2rayNG",
      "full_name": "2dust/v2rayNG",
      "description": "A V2Ray client for Android, support Xray core and v2fly core",
      "html_url": "https://github.com/2dust/v2rayNG",
      "stars": 49959,
      "forks": 6835,
      "language": "Kotlin",
      "topics": [
        "android",
        "proxy",
        "shadowsocks",
        "socks5",
        "trojan",
        "v2fly",
        "v2ray",
        "vless",
        "vmess",
        "vpn",
        "xray",
        "xtls"
      ],
      "created_at": "2019-05-15T02:15:31Z",
      "updated_at": "2026-01-24T02:03:48Z",
      "pushed_at": "2026-01-23T11:41:33Z",
      "open_issues": 5,
      "owner": {
        "login": "2dust",
        "avatar_url": "https://avatars.githubusercontent.com/u/31833384?v=4"
      },
      "readme": "# v2rayNG\n\nA V2Ray client for Android, support [Xray core](https://github.com/XTLS/Xray-core) and [v2fly core](https://github.com/v2fly/v2ray-core)\n\n[![API](https://img.shields.io/badge/API-24%2B-yellow.svg?style=flat)](https://developer.android.com/about/versions/lollipop)\n[![Kotlin Version](https://img.shields.io/badge/Kotlin-2.3.0-blue.svg)](https://kotlinlang.org)\n[![GitHub commit activity](https://img.shields.io/github/commit-activity/m/2dust/v2rayNG)](https://github.com/2dust/v2rayNG/commits/master)\n[![CodeFactor](https://www.codefactor.io/repository/github/2dust/v2rayng/badge)](https://www.codefactor.io/repository/github/2dust/v2rayng)\n[![GitHub Releases](https://img.shields.io/github/downloads/2dust/v2rayNG/latest/total?logo=github)](https://github.com/2dust/v2rayNG/releases)\n[![Chat on Telegram](https://img.shields.io/badge/Chat%20on-Telegram-brightgreen.svg)](https://t.me/v2rayn)\n\n### Telegram Channel\n[github_2dust](https://t.me/github_2dust)\n\n### Usage\n\n#### Geoip and Geosite\n- geoip.dat and geosite.dat files are in `Android/data/com.v2ray.ang/files/assets` (path may differ on some Android device)\n- download feature will get enhanced version in this [repo](https://github.com/Loyalsoldier/v2ray-rules-dat) (Note it need a working proxy)\n- latest official [domain list](https://github.com/Loyalsoldier/v2ray-rules-dat) and [ip list](https://github.com/Loyalsoldier/geoip) can be imported manually\n- possible to use third party dat file in the same folder, like [h2y](https://guide.v2fly.org/routing/sitedata.html#%E5%A4%96%E7%BD%AE%E7%9A%84%E5%9F%9F%E5%90%8D%E6%96%87%E4%BB%B6)\n\n### More in our [wiki](https://github.com/2dust/v2rayNG/wiki)\n\n### Development guide\n\nAndroid project under V2rayNG folder can be compiled directly in Android Studio, or using Gradle wrapper. But the v2ray core inside the aar is (probably) outdated.  \nThe aar can be compiled from the Golang project [AndroidLibV2rayLite](https://github.com/2dust/AndroidLibV2rayLite) or [AndroidLibXrayLite](https://github.com/2dust/AndroidLibXrayLite).\nFor a quick start, read guide for [Go Mobile](https://github.com/golang/go/wiki/Mobile) and [Makefiles for Go Developers](https://tutorialedge.net/golang/makefiles-for-go-developers/)\n\nv2rayNG can run on Android Emulators. For WSA, VPN permission need to be granted via\n`appops set [package name] ACTIVATE_VPN allow`\n",
      "stars_today": 72
    },
    {
      "id": 606220217,
      "name": "skip",
      "full_name": "skiptools/skip",
      "description": "Skip enables the creation of native SwiftUI apps for iOS and Android",
      "html_url": "https://github.com/skiptools/skip",
      "stars": 2397,
      "forks": 70,
      "language": "Swift",
      "topics": [
        "android",
        "ios",
        "swift"
      ],
      "created_at": "2023-02-24T21:55:33Z",
      "updated_at": "2026-01-24T02:03:16Z",
      "pushed_at": "2026-01-23T22:35:36Z",
      "open_issues": 94,
      "owner": {
        "login": "skiptools",
        "avatar_url": "https://avatars.githubusercontent.com/u/126294127?v=4"
      },
      "readme": "# Skip\n\n[![CI](https://github.com/skiptools/skip/actions/workflows/ci.yml/badge.svg)](https://github.com/skiptools/skip/actions/workflows/ci.yml)\n[![Slack](https://img.shields.io/badge/slack-chat-informational.svg?label=Slack&logo=slack)](https://www.skip.dev/slack)\n\nSkip is a technology for creating dual-platform apps in Swift that run on iOS and Android.\nRead the [documentation](https://skip.dev/docs/) to learn more about Skip.\n\nThis repository hosts the Skip Xcode and SwiftPM build plugin[^plugins]. It works works hand-in-hand with the [skipstone](https://github.com/skiptools/skipstone) tool, which is the binary distribution that powers both the `skip` CLI and the plugin commands. Most of the interesting code is in `skipstone`, but this is the package which Skip projects will directly depend on. For more information on how Skip packages are architected, see the [Framework Structure docs](https://skip.dev/docs/project-types/#framework_structure), or see one of the sample projects like [Hello Skip](https://github.com/skiptools/skipapp-hello).\n\n[^plugins]: Extend package manager functionality with build or command plugins. ‚Äî [https://docs.swift.org/swiftpm/documentation/packagemanagerdocs/plugins/](https://docs.swift.org/swiftpm/documentation/packagemanagerdocs/plugins/)\n\nFor those who want to dive _right_ in without delay, the [Getting Started Guide](https://skip.dev/docs/gettingstarted/) can be summarized like so:\n\n```console\nbrew install skiptools/skip/skip\nskip checkup\nskip create\n```\n\n‚Ä¶and your Skip project will be created and opened in Xcode.\n\nThis repository also hosts the Skip forums for [support and discussions](http://community.skip.dev) as well as specific [issues and bug reports](https://github.com/skiptools/skip/issues).\n\n\n",
      "stars_today": 68
    },
    {
      "id": 649170660,
      "name": "anything-llm",
      "full_name": "Mintplex-Labs/anything-llm",
      "description": "The all-in-one Desktop & Docker AI application with built-in RAG, AI agents, No-code agent builder, MCP compatibility,  and more.",
      "html_url": "https://github.com/Mintplex-Labs/anything-llm",
      "stars": 53744,
      "forks": 5770,
      "language": "JavaScript",
      "topics": [
        "ai-agents",
        "custom-ai-agents",
        "deepseek",
        "kimi",
        "llama3",
        "llm",
        "lmstudio",
        "local-llm",
        "localai",
        "mcp",
        "mcp-servers",
        "moonshot",
        "multimodal",
        "no-code",
        "ollama",
        "qwen3",
        "rag",
        "vector-database",
        "web-scraping"
      ],
      "created_at": "2023-06-04T02:29:14Z",
      "updated_at": "2026-01-24T01:12:23Z",
      "pushed_at": "2026-01-24T01:12:17Z",
      "open_issues": 283,
      "owner": {
        "login": "Mintplex-Labs",
        "avatar_url": "https://avatars.githubusercontent.com/u/134426827?v=4"
      },
      "readme": "<a name=\"readme-top\"></a>\n\n<p align=\"center\">\n  <a href=\"https://anythingllm.com\"><img src=\"https://github.com/Mintplex-Labs/anything-llm/blob/master/images/wordmark.png?raw=true\" alt=\"AnythingLLM logo\"></a>\n</p>\n\n<div align='center'>\n<a href=\"https://trendshift.io/repositories/2415\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/2415\" alt=\"Mintplex-Labs%2Fanything-llm | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</div>\n\n<p align=\"center\">\n    <b>AnythingLLM:</b> The all-in-one AI app you were looking for.<br />\n    Chat with your docs, use AI Agents, hyper-configurable, multi-user, & no frustrating setup required.\n</p>\n\n<p align=\"center\">\n  <a href=\"https://discord.gg/6UyHPeGZAC\" target=\"_blank\">\n      <img src=\"https://img.shields.io/badge/chat-mintplex_labs-blue.svg?style=flat&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAMAAABEpIrGAAAAIGNIUk0AAHomAACAhAAA+gAAAIDoAAB1MAAA6mAAADqYAAAXcJy6UTwAAAH1UExURQAAAP////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////r6+ubn5+7u7/3+/v39/enq6urq6/v7+97f39rb26eoqT1BQ0pOT4+Rkuzs7cnKykZKS0NHSHl8fdzd3ejo6UxPUUBDRdzc3RwgIh8jJSAkJm5xcvHx8aanqB4iJFBTVezt7V5hYlJVVuLj43p9fiImKCMnKZKUlaaoqSElJ21wcfT09O3u7uvr6zE0Nr6/wCUpK5qcnf7+/nh7fEdKTHx+f0tPUOTl5aipqiouMGtubz5CRDQ4OsTGxufn515hY7a3uH1/gXBydIOFhlVYWvX29qaoqCQoKs7Pz/Pz87/AwUtOUNfY2dHR0mhrbOvr7E5RUy8zNXR2d/f39+Xl5UZJSx0hIzQ3Odra2/z8/GlsbaGjpERHSezs7L/BwScrLTQ4Odna2zM3Obm7u3x/gKSmp9jZ2T1AQu/v71pdXkVISr2+vygsLiInKTg7PaOlpisvMcXGxzk8PldaXPLy8u7u7rm6u7S1tsDBwvj4+MPExbe4ueXm5s/Q0Kyf7ewAAAAodFJOUwAABClsrNjx/QM2l9/7lhmI6jTB/kA1GgKJN+nea6vy/MLZQYeVKK3rVA5tAAAAAWJLR0QB/wIt3gAAAAd0SU1FB+cKBAAmMZBHjXIAAAISSURBVDjLY2CAAkYmZhZWNnYODnY2VhZmJkYGVMDIycXNw6sBBbw8fFycyEoYGfkFBDVQgKAAPyMjQl5IWEQDDYgIC8FUMDKKsmlgAWyiEBWMjGJY5YEqxMAqGMWFNXAAYXGgAkYJSQ2cQFKCkYFRShq3AmkpRgYJbghbU0tbB0Tr6ukbgGhDI10gySfBwCwDUWBsYmpmDqQtLK2sbTQ0bO3sHYA8GWYGWWj4WTs6Obu4ami4OTm7exhqeHp5+4DCVJZBDmqdr7ufn3+ArkZgkJ+fU3CIRmgYWFiOARYGvo5OQUHhEUAFTkF+kVHRsLBgkIeyYmLjwoOc4hMSk5JTnINS06DC8gwcEEZ6RqZGlpOfc3ZObl5+gZ+TR2ERWFyBQQFMF5eklmqUpQb5+ReU61ZUOvkFVVXXQBSAraitq29o1GiKcfLzc29u0mjxBzq0tQ0kww5xZHtHUGeXhkZhdxBYgZ4d0LI6c4gjwd7siQQraOp1AivQ6CuAKZCDBBRQQQNQgUb/BGf3cqCCiZOcnCe3QQIKHNRTpk6bDgpZjRkzg3pBQTBrdtCcuZCgluAD0vPmL1gIdvSixUuWgqNs2YJ+DUhkEYxuggkGmOQUcckrioPTJCOXEnZ5JS5YslbGnuyVERlDDFvGEUPOWvwqaH6RVkHKeuDMK6SKnHlVhTgx8jeTmqy6Eij7K6nLqiGyPwChsa1MUrnq1wAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAyMy0xMC0wNFQwMDozODo0OSswMDowMB9V0a8AAAAldEVYdGRhdGU6bW9kaWZ5ADIwMjMtMTAtMDRUMDA6Mzg6NDkrMDA6MDBuCGkTAAAAKHRFWHRkYXRlOnRpbWVzdGFtcAAyMDIzLTEwLTA0VDAwOjM4OjQ5KzAwOjAwOR1IzAAAAABJRU5ErkJggg==\" alt=\"Discord\">\n  </a> |\n  <a href=\"https://github.com/Mintplex-Labs/anything-llm/blob/master/LICENSE\" target=\"_blank\">\n      <img src=\"https://img.shields.io/static/v1?label=license&message=MIT&color=white\" alt=\"License\">\n  </a> |\n  <a href=\"https://docs.anythingllm.com\" target=\"_blank\">\n    Docs\n  </a> |\n   <a href=\"https://my.mintplexlabs.com/aio-checkout?product=anythingllm\" target=\"_blank\">\n    Hosted Instance\n  </a>\n</p>\n\n<p align=\"center\">\n  <b>English</b> ¬∑ <a href='./locales/README.zh-CN.md'>ÁÆÄ‰Ωì‰∏≠Êñá</a> ¬∑ <a href='./locales/README.ja-JP.md'>Êó•Êú¨Ë™û</a>\n</p>\n\n<p align=\"center\">\nüëâ AnythingLLM for desktop (Mac, Windows, & Linux)! <a href=\"https://anythingllm.com/download\" target=\"_blank\"> Download Now</a>\n</p>\n\nA full-stack application that enables you to turn any document, resource, or piece of content into context that any LLM can use as a reference during chatting. This application allows you to pick and choose which LLM or Vector Database you want to use as well as supporting multi-user management and permissions.\n\n![Chatting](https://github.com/Mintplex-Labs/anything-llm/assets/16845892/cfc5f47c-bd91-4067-986c-f3f49621a859)\n\n<details>\n<summary><kbd>Watch the demo!</kbd></summary>\n\n[![Watch the video](/images/youtube.png)](https://youtu.be/f95rGD9trL0)\n\n</details>\n\n### Product Overview\n\nAnythingLLM is a full-stack application where you can use commercial off-the-shelf LLMs or popular open source LLMs and vectorDB solutions to build a private ChatGPT with no compromises that you can run locally as well as host remotely and be able to chat intelligently with any documents you provide it.\n\nAnythingLLM divides your documents into objects called `workspaces`. A Workspace functions a lot like a thread, but with the addition of containerization of your documents. Workspaces can share documents, but they do not talk to each other so you can keep your context for each workspace clean.\n\n## Cool features of AnythingLLM\n\n- üÜï [**Full MCP-compatibility**](https://docs.anythingllm.com/mcp-compatibility/overview)\n- üÜï [**No-code AI Agent builder**](https://docs.anythingllm.com/agent-flows/overview)\n- üñºÔ∏è **Multi-modal support (both closed and open-source LLMs!)**\n- [**Custom AI Agents**](https://docs.anythingllm.com/agent/custom/introduction)\n- üë§ Multi-user instance support and permissioning _Docker version only_\n- ü¶æ Agents inside your workspace (browse the web, etc)\n- üí¨ [Custom Embeddable Chat widget for your website](https://github.com/Mintplex-Labs/anythingllm-embed/blob/main/README.md) _Docker version only_\n- üìñ Multiple document type support (PDF, TXT, DOCX, etc)\n- Simple chat UI with Drag-n-Drop functionality and clear citations.\n- 100% Cloud deployment ready.\n- Works with all popular [closed and open-source LLM providers](#supported-llms-embedder-models-speech-models-and-vector-databases).\n- Built-in cost & time-saving measures for managing very large documents compared to any other chat UI.\n- Full Developer API for custom integrations!\n- Much more...install and find out!\n\n### Supported LLMs, Embedder Models, Speech models, and Vector Databases\n\n**Large Language Models (LLMs):**\n\n- [Any open-source llama.cpp compatible model](/server/storage/models/README.md#text-generation-llm-selection)\n- [OpenAI](https://openai.com)\n- [OpenAI (Generic)](https://openai.com)\n- [Azure OpenAI](https://azure.microsoft.com/en-us/products/ai-services/openai-service)\n- [AWS Bedrock](https://aws.amazon.com/bedrock/)\n- [Anthropic](https://www.anthropic.com/)\n- [NVIDIA NIM (chat models)](https://build.nvidia.com/explore/discover)\n- [Google Gemini Pro](https://ai.google.dev/)\n- [Hugging Face (chat models)](https://huggingface.co/)\n- [Ollama (chat models)](https://ollama.ai/)\n- [LM Studio (all models)](https://lmstudio.ai)\n- [LocalAI (all models)](https://localai.io/)\n- [Together AI (chat models)](https://www.together.ai/)\n- [Fireworks AI  (chat models)](https://fireworks.ai/)\n- [Perplexity (chat models)](https://www.perplexity.ai/)\n- [OpenRouter (chat models)](https://openrouter.ai/)\n- [DeepSeek (chat models)](https://deepseek.com/)\n- [Mistral](https://mistral.ai/)\n- [Groq](https://groq.com/)\n- [Cohere](https://cohere.com/)\n- [KoboldCPP](https://github.com/LostRuins/koboldcpp)\n- [LiteLLM](https://github.com/BerriAI/litellm)\n- [Text Generation Web UI](https://github.com/oobabooga/text-generation-webui)\n- [Apipie](https://apipie.ai/)\n- [xAI](https://x.ai/)\n- [Z.AI (chat models)](https://z.ai/model-api)\n- [Novita AI (chat models)](https://novita.ai/model-api/product/llm-api?utm_source=github_anything-llm&utm_medium=github_readme&utm_campaign=link)\n- [PPIO](https://ppinfra.com?utm_source=github_anything-llm)\n- [Gitee AI](https://ai.gitee.com/)\n- [Moonshot AI](https://www.moonshot.ai/)\n- [Microsoft Foundry Local](https://github.com/microsoft/Foundry-Local)\n- [CometAPI (chat models)](https://api.cometapi.com/)\n- [Docker Model Runner](https://docs.docker.com/ai/model-runner/)\n\n**Embedder models:**\n\n- [AnythingLLM Native Embedder](/server/storage/models/README.md) (default)\n- [OpenAI](https://openai.com)\n- [Azure OpenAI](https://azure.microsoft.com/en-us/products/ai-services/openai-service)\n- [LocalAI (all)](https://localai.io/)\n- [Ollama (all)](https://ollama.ai/)\n- [LM Studio (all)](https://lmstudio.ai)\n- [Cohere](https://cohere.com/)\n\n**Audio Transcription models:**\n\n- [AnythingLLM Built-in](https://github.com/Mintplex-Labs/anything-llm/tree/master/server/storage/models#audiovideo-transcription) (default)\n- [OpenAI](https://openai.com/)\n\n**TTS (text-to-speech) support:**\n\n- Native Browser Built-in (default)\n- [PiperTTSLocal - runs in browser](https://github.com/rhasspy/piper)\n- [OpenAI TTS](https://platform.openai.com/docs/guides/text-to-speech/voice-options)\n- [ElevenLabs](https://elevenlabs.io/)\n- Any OpenAI Compatible TTS service.\n\n**STT (speech-to-text) support:**\n\n- Native Browser Built-in (default)\n\n**Vector Databases:**\n\n- [LanceDB](https://github.com/lancedb/lancedb) (default)\n- [PGVector](https://github.com/pgvector/pgvector)\n- [Astra DB](https://www.datastax.com/products/datastax-astra)\n- [Pinecone](https://pinecone.io)\n- [Chroma & ChromaCloud](https://trychroma.com)\n- [Weaviate](https://weaviate.io)\n- [Qdrant](https://qdrant.tech)\n- [Milvus](https://milvus.io)\n- [Zilliz](https://zilliz.com)\n\n### Technical Overview\n\nThis monorepo consists of six main sections:\n\n- `frontend`: A viteJS + React frontend that you can run to easily create and manage all your content the LLM can use.\n- `server`: A NodeJS express server to handle all the interactions and do all the vectorDB management and LLM interactions.\n- `collector`: NodeJS express server that processes and parses documents from the UI.\n- `docker`: Docker instructions and build process + information for building from source.\n- `embed`: Submodule for generation & creation of the [web embed widget](https://github.com/Mintplex-Labs/anythingllm-embed).\n- `browser-extension`: Submodule for the [chrome browser extension](https://github.com/Mintplex-Labs/anythingllm-extension).\n\n## üõ≥ Self-Hosting\n\nMintplex Labs & the community maintain a number of deployment methods, scripts, and templates that you can use to run AnythingLLM locally. Refer to the table below to read how to deploy on your preferred environment or to automatically deploy.\n| Docker | AWS | GCP | Digital Ocean | Render.com |\n|----------------------------------------|----|-----|---------------|------------|\n| [![Deploy on Docker][docker-btn]][docker-deploy] | [![Deploy on AWS][aws-btn]][aws-deploy] | [![Deploy on GCP][gcp-btn]][gcp-deploy] | [![Deploy on DigitalOcean][do-btn]][do-deploy] | [![Deploy on Render.com][render-btn]][render-deploy] |\n\n| Railway | RepoCloud | Elestio | Northflank |\n| --- | --- | --- | --- |\n| [![Deploy on Railway][railway-btn]][railway-deploy] | [![Deploy on RepoCloud][repocloud-btn]][repocloud-deploy] | [![Deploy on Elestio][elestio-btn]][elestio-deploy] | [![Deploy on Northflank][northflank-btn]][northflank-deploy] |\n\n[or set up a production AnythingLLM instance without Docker ‚Üí](./BARE_METAL.md)\n\n## How to setup for development\n\n- `yarn setup` To fill in the required `.env` files you'll need in each of the application sections (from root of repo).\n  - Go fill those out before proceeding. Ensure `server/.env.development` is filled or else things won't work right.\n- `yarn dev:server` To boot the server locally (from root of repo).\n- `yarn dev:frontend` To boot the frontend locally (from root of repo).\n- `yarn dev:collector` To then run the document collector (from root of repo).\n\n[Learn about documents](./server/storage/documents/DOCUMENTS.md)\n\n[Learn about vector caching](./server/storage/vector-cache/VECTOR_CACHE.md)\n\n## External Apps & Integrations\n\n_These are apps that are not maintained by Mintplex Labs, but are compatible with AnythingLLM. A listing here is not an endorsement._\n\n- [Midori AI Subsystem Manager](https://io.midori-ai.xyz/subsystem/anythingllm/) - A streamlined and efficient way to deploy AI systems using Docker container technology.\n- [Coolify](https://coolify.io/docs/services/anythingllm/) - Deploy AnythingLLM with a single click.\n- [GPTLocalhost for Microsoft Word](https://gptlocalhost.com/demo/) - A local Word Add-in for you to use AnythingLLM in Microsoft Word.\n\n## Telemetry & Privacy\n\nAnythingLLM by Mintplex Labs Inc contains a telemetry feature that collects anonymous usage information.\n\n<details>\n<summary><kbd>More about Telemetry & Privacy for AnythingLLM</kbd></summary>\n\n### Why?\n\nWe use this information to help us understand how AnythingLLM is used, to help us prioritize work on new features and bug fixes, and to help us improve AnythingLLM's performance and stability.\n\n### Opting out\n\nSet `DISABLE_TELEMETRY` in your server or docker .env settings to \"true\" to opt out of telemetry. You can also do this in-app by going to the sidebar > `Privacy` and disabling telemetry.\n\n### What do you explicitly track?\n\nWe will only track usage details that help us make product and roadmap decisions, specifically:\n\n- Type of your installation (Docker or Desktop)\n\n- When a document is added or removed. No information _about_ the document. Just that the event occurred. This gives us an idea of use.\n\n- Type of vector database in use. This helps us prioritize changes when updates arrive for that provider.\n\n- Type of LLM provider & model tag in use. This helps us prioritize changes when updates arrive for that provider or model, or combination thereof. eg: reasoning vs regular, multi-modal models, etc.\n\n- When a chat is sent. This is the most regular \"event\" and gives us an idea of the daily-activity of this project across all installations. Again, only the **event** is sent - we have no information on the nature or content of the chat itself.\n\nYou can verify these claims by finding all locations `Telemetry.sendTelemetry` is called. Additionally these events are written to the output log so you can also see the specific data which was sent - if enabled. **No IP or other identifying information is collected**. The Telemetry provider is [PostHog](https://posthog.com/) - an open-source telemetry collection service.\n\nWe take privacy very seriously, and we hope you understand that we want to learn how our tool is used, without using annoying popup surveys, so we can build something worth using. The anonymous data is _never_ shared with third parties, ever.\n\n[View all telemetry events in source code](https://github.com/search?q=repo%3AMintplex-Labs%2Fanything-llm%20.sendTelemetry\\(&type=code)\n\n</details>\n\n## üëã Contributing\n\n- [Contributing to AnythingLLM](./CONTRIBUTING.md) - How to contribute to AnythingLLM.\n\n## üíñ Sponsors\n\n### Premium Sponsors\n\n<!-- premium-sponsors (reserved for $100/mth sponsors who request to be called out here and/or are non-private sponsors) -->\n<a href=\"https://www.dcsdigital.co.uk\" target=\"_blank\">\n  <img src=\"https://a8cforagenciesportfolio.wordpress.com/wp-content/uploads/2024/08/logo-image-232621379.png\" height=\"100px\" alt=\"User avatar: DCS DIGITAL\" />\n</a>\n<!-- premium-sponsors -->\n\n### All Sponsors\n\n<!-- all-sponsors --><a href=\"https://github.com/jaschadub\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;jaschadub.png\" width=\"60px\" alt=\"User avatar: Jascha\" /></a><a href=\"https://github.com/KickingAss2024\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;KickingAss2024.png\" width=\"60px\" alt=\"User avatar: KickAss\" /></a><a href=\"https://github.com/ShadowArcanist\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;ShadowArcanist.png\" width=\"60px\" alt=\"User avatar: ShadowArcanist\" /></a><a href=\"https://github.com/AtlasVIA\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;AtlasVIA.png\" width=\"60px\" alt=\"User avatar: Atlas\" /></a><a href=\"https://github.com/cope\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;cope.png\" width=\"60px\" alt=\"User avatar: Predrag Stojadinoviƒá\" /></a><a href=\"https://github.com/DiegoSpinola\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;DiegoSpinola.png\" width=\"60px\" alt=\"User avatar: Diego Spinola\" /></a><a href=\"https://github.com/PortlandKyGuy\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;PortlandKyGuy.png\" width=\"60px\" alt=\"User avatar: Kyle\" /></a><a href=\"https://github.com/peperunas\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;peperunas.png\" width=\"60px\" alt=\"User avatar: Giulio De Pasquale\" /></a><a href=\"https://github.com/jasoncdavis0\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;jasoncdavis0.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/macstadium\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;macstadium.png\" width=\"60px\" alt=\"User avatar: MacStadium\" /></a><a href=\"https://github.com/armlynobinguar\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;armlynobinguar.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/MikeHago\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;MikeHago.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/maaisde\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;maaisde.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/mhollier117\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;mhollier117.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/pleabargain\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;pleabargain.png\" width=\"60px\" alt=\"User avatar: Dennis\" /></a><a href=\"https://github.com/broichan\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;broichan.png\" width=\"60px\" alt=\"User avatar: Michael Hamilton, Ph.D.\" /></a><a href=\"https://github.com/azim-charaniya\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;azim-charaniya.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/gabriellemon\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;gabriellemon.png\" width=\"60px\" alt=\"User avatar: TernaryLabs\" /></a><a href=\"https://github.com/CelaDaniel\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;CelaDaniel.png\" width=\"60px\" alt=\"User avatar: Daniel Cela\" /></a><a href=\"https://github.com/altrsadmin\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;altrsadmin.png\" width=\"60px\" alt=\"User avatar: Alesso\" /></a><a href=\"https://github.com/bitjungle\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;bitjungle.png\" width=\"60px\" alt=\"User avatar: Rune Mathisen\" /></a><a href=\"https://github.com/pcrossleyAC\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;pcrossleyAC.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/saroj-pattnaik\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;saroj-pattnaik.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/techmedic5\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;techmedic5.png\" width=\"60px\" alt=\"User avatar: Alan\" /></a><a href=\"https://github.com/ddocta\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;ddocta.png\" width=\"60px\" alt=\"User avatar: Damien Peters\" /></a><a href=\"https://github.com/dcsdigital\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;dcsdigital.png\" width=\"60px\" alt=\"User avatar: DCS Digital\" /></a><a href=\"https://github.com/pm7y\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;pm7y.png\" width=\"60px\" alt=\"User avatar: Paul Mcilreavy\" /></a><a href=\"https://github.com/tilwolf\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;tilwolf.png\" width=\"60px\" alt=\"User avatar: Til Wolf\" /></a><a href=\"https://github.com/ozzyoss77\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;ozzyoss77.png\" width=\"60px\" alt=\"User avatar: Leopoldo Crhistian Riverin Gomez\" /></a><a href=\"https://github.com/AlphaEcho11\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;AlphaEcho11.png\" width=\"60px\" alt=\"User avatar: AJEsau\" /></a><a href=\"https://github.com/svanomm\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;svanomm.png\" width=\"60px\" alt=\"User avatar: Steven VanOmmeren\" /></a><a href=\"https://github.com/socketbox\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;socketbox.png\" width=\"60px\" alt=\"User avatar: Casey Boettcher\" /></a><a href=\"https://github.com/zebbern\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;zebbern.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/avineetbespin\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;avineetbespin.png\" width=\"60px\" alt=\"User avatar: Avineet\" /></a><a href=\"https://github.com/invictus-1\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;invictus-1.png\" width=\"60px\" alt=\"User avatar: Chris\" /></a><a href=\"https://github.com/mirbyte\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;mirbyte.png\" width=\"60px\" alt=\"User avatar: mirko\" /></a><a href=\"https://github.com/bisonbet\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;bisonbet.png\" width=\"60px\" alt=\"User avatar: Tim Champ\" /></a><a href=\"https://github.com/Sinkingdev\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;Sinkingdev.png\" width=\"60px\" alt=\"User avatar: Peter Mathisen\" /></a><a href=\"https://github.com/Ed-STEM\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;Ed-STEM.png\" width=\"60px\" alt=\"User avatar: Ed di Girolamo\" /></a><a href=\"https://github.com/milkowski\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;milkowski.png\" width=\"60px\" alt=\"User avatar: Wojciech Mi≈Çkowski\" /></a><a href=\"https://github.com/ADS-Fund\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;ADS-Fund.png\" width=\"60px\" alt=\"User avatar: ADS Fund\" /></a><a href=\"https://github.com/arc46-io\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;arc46-io.png\" width=\"60px\" alt=\"User avatar: arc46 GmbH\" /></a><!-- all-sponsors -->\n\n## üåü Contributors\n\n[![anythingllm contributors](https://contrib.rocks/image?repo=mintplex-labs/anything-llm)](https://github.com/mintplex-labs/anything-llm/graphs/contributors)\n\n[![Star History Chart](https://api.star-history.com/svg?repos=mintplex-labs/anything-llm&type=Timeline)](https://star-history.com/#mintplex-labs/anything-llm&Date)\n\n## üîó More Products\n\n- **[VectorAdmin][vector-admin]:** An all-in-one GUI & tool-suite for managing vector databases.\n- **[OpenAI Assistant Swarm][assistant-swarm]:** Turn your entire library of OpenAI assistants into one single army commanded from a single agent.\n\n<div align=\"right\">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n---\n\nCopyright ¬© 2025 [Mintplex Labs][profile-link]. <br />\nThis project is [MIT](./LICENSE) licensed.\n\n<!-- LINK GROUP -->\n\n[back-to-top]: https://img.shields.io/badge/-BACK_TO_TOP-222628?style=flat-square\n[profile-link]: https://github.com/mintplex-labs\n[vector-admin]: https://github.com/mintplex-labs/vector-admin\n[assistant-swarm]: https://github.com/Mintplex-Labs/openai-assistant-swarm\n[docker-btn]: ./images/deployBtns/docker.png\n[docker-deploy]: ./docker/HOW_TO_USE_DOCKER.md\n[aws-btn]: ./images/deployBtns/aws.png\n[aws-deploy]: ./cloud-deployments/aws/cloudformation/DEPLOY.md\n[gcp-btn]: https://deploy.cloud.run/button.svg\n[gcp-deploy]: ./cloud-deployments/gcp/deployment/DEPLOY.md\n[do-btn]: https://www.deploytodo.com/do-btn-blue.svg\n[do-deploy]: ./cloud-deployments/digitalocean/terraform/DEPLOY.md\n[render-btn]: https://render.com/images/deploy-to-render-button.svg\n[render-deploy]: https://render.com/deploy?repo=https://github.com/Mintplex-Labs/anything-llm&branch=render\n[render-btn]: https://render.com/images/deploy-to-render-button.svg\n[render-deploy]: https://render.com/deploy?repo=https://github.com/Mintplex-Labs/anything-llm&branch=render\n[railway-btn]: https://railway.app/button.svg\n[railway-deploy]: https://railway.app/template/HNSCS1?referralCode=WFgJkn\n[repocloud-btn]: https://d16t0pc4846x52.cloudfront.net/deploylobe.svg\n[repocloud-deploy]: https://repocloud.io/details/?app_id=276\n[elestio-btn]: https://elest.io/images/logos/deploy-to-elestio-btn.png\n[elestio-deploy]: https://elest.io/open-source/anythingllm\n[northflank-btn]: https://assets.northflank.com/deploy_to_northflank_smm_36700fb050.svg\n[northflank-deploy]: https://northflank.com/stacks/deploy-anythingllm\n",
      "stars_today": 64
    },
    {
      "id": 709588939,
      "name": "awesome-leetcode-resources",
      "full_name": "ashishps1/awesome-leetcode-resources",
      "description": "Awesome LeetCode resources to learn Data Structures and Algorithms and prepare for Coding Interviews.",
      "html_url": "https://github.com/ashishps1/awesome-leetcode-resources",
      "stars": 15410,
      "forks": 3345,
      "language": "Java",
      "topics": [
        "algorithms",
        "coding",
        "data-structures",
        "dsa",
        "leetcode",
        "leetcode-patterns"
      ],
      "created_at": "2023-10-25T01:48:19Z",
      "updated_at": "2026-01-24T01:45:14Z",
      "pushed_at": "2025-11-25T13:00:27Z",
      "open_issues": 12,
      "owner": {
        "login": "ashishps1",
        "avatar_url": "https://avatars.githubusercontent.com/u/8646889?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"images/leetcode-repo-logo.png\" width=\"350\" height=\"200\">\n</p>\n<p align=\"center\">\n  <a href=\"https://blog.algomaster.io/\">Join Free Newsletter</a>\n</p>\n\nThis repository contains awesome LeetCode resources to learn Data Structures and Algorithms (DSA) and prepare for Coding interviews.\n\nüëâ If you want to master DSA patterns, checkout [AlgoMaster.io](https://algomaster.io)\n\n## üí° Tips\n- [How I Mastered DSA](https://blog.algomaster.io/p/how-i-mastered-data-structures-and-algorithms)\n- [How to Start LeetCode](https://blog.algomaster.io/p/how-to-start-leetcode-in-2025)\n- [15 Leetcode Patterns](https://blog.algomaster.io/p/15-leetcode-patterns)\n\n## üìå Fundamental Concepts\n- [Algorithmic Complexity](https://blog.algomaster.io/p/57bd4963-462f-4294-a972-4012691fc729)\n- [Big-O Cheat Sheet](https://www.bigocheatsheet.com/)\n- [Arrays](https://www.youtube.com/watch?v=SlNq09scdWE&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Bit Manipulation Techniques](https://blog.algomaster.io/p/c650df76-f978-46ee-a572-eb13c354905d)\n- [Sorting Algorithms](https://medium.com/jl-codes/understanding-sorting-algorithms-af6222995c8)\n- [Linked List](https://www.youtube.com/watch?v=FbHf0ii0WDg&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Queues](https://medium.com/basecs/to-queue-or-not-to-queue-2653bcde5b04)\n- [Stacks](https://medium.com/basecs/stacks-and-overflows-dbcf7854dc67)\n- [Hash Tables](https://medium.com/basecs/taking-hash-tables-off-the-shelf-139cbf4752f0)\n- [Heaps](https://medium.com/basecs/learning-to-love-heaps-cef2b273a238)\n- [Recursion](https://leetcode.com/discuss/study-guide/1733447/become-master-in-recursion)\n- [Backtracking](https://medium.com/algorithms-and-leetcode/backtracking-e001561b9f28)\n- [Trees](https://leetcode.com/discuss/study-guide/1820334/Become-Master-in-Tree)\n- [Tries](https://medium.com/basecs/trying-to-understand-tries-3ec6bede0014)\n- [Binary Search](https://leetcode.com/discuss/study-guide/786126/Python-Powerful-Ultimate-Binary-Search-Template.-Solved-many-problems)\n- [Greedy Algorithm](https://www.freecodecamp.org/news/greedy-algorithms/)\n- [Dynamic Programming](https://medium.com/basecs/less-repetition-more-dynamic-programming-43d29830a630)\n- [Graph Theory](https://www.youtube.com/watch?v=xN5VGzK9_FQ&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Master Graph Algorithms](https://blog.algomaster.io/p/master-graph-algorithms-for-coding)\n- [DFS Traversal](https://medium.com/basecs/deep-dive-through-a-graph-dfs-traversal-8177df5d0f13)\n- [BFS Traversal](https://medium.com/basecs/going-broad-in-a-graph-bfs-traversal-959bd1a09255)\n- [Union-Find](https://leetcode.com/discuss/general-discussion/1072418/Disjoint-Set-Union-(DSU)Union-Find-A-Complete-Guide)\n- [Dijkstra Algorithm](https://leetcode.com/discuss/study-guide/1059477/A-guide-to-Dijkstra's-Algorithm)\n- [Minimum Spanning Tree](https://www.hackerearth.com/practice/algorithms/graphs/minimum-spanning-tree/tutorial/)\n\n## üöÄ Patterns\n- [15 Leetcode Patterns](https://blog.algomaster.io/p/15-leetcode-patterns)\n- [20 DP Patterns](https://blog.algomaster.io/p/20-patterns-to-master-dynamic-programming)\n- [Two Pointers Pattern](https://www.youtube.com/watch?v=QzZ7nmouLTI&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Sliding Window Pattern](https://www.youtube.com/watch?v=y2d0VHdvfdc&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Prefix Sum Pattern](https://www.youtube.com/watch?v=yuws7YK0Yng&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Fast and Slow Pointers Pattern](https://www.youtube.com/watch?v=b139yf7Ik-E&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Top 'K' Elements Pattern](https://www.youtube.com/watch?v=6_v6OoxvMOE&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Kadane's Algorithm](https://www.youtube.com/watch?v=NUWAXbSlsws&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Linked List In-place Reversal Pattern](https://www.youtube.com/watch?v=auoTGovuo9A&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Monotonic Stack Pattern](https://www.youtube.com/watch?v=DtJVwbbicjQ&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Overlapping Intervals Pattern](https://blog.algomaster.io/p/812e72f7-eced-4256-a4c1-00606ae50679)\n- [Backtracking Pattern](https://blog.algomaster.io/p/81d42ca2-600c-4252-aa33-a56462090048)\n- [Modified Binary Search Pattern](https://blog.algomaster.io/p/d0d81b04-4c2a-4b45-a101-5137c3146686)\n- [Tree Patterns](https://leetcode.com/discuss/study-guide/937307/Iterative-or-Recursive-or-DFS-and-BFS-Tree-Traversal-or-In-Pre-Post-and-LevelOrder-or-Views)\n  - [Tree Iterative Traversal](https://medium.com/leetcode-patterns/leetcode-pattern-0-iterative-traversals-on-trees-d373568eb0ec)\n  - [Tree Question Pattern](https://leetcode.com/discuss/study-guide/2879240/TREE-QUESTION-PATTERN-2023-oror-TREE-STUDY-GUIDE) \n- [Graph Patterns](https://leetcode.com/discuss/study-guide/655708/Graph-For-Beginners-Problems-or-Pattern-or-Sample-Solutions)\n- [DFS + BFS Patterns (1)](https://medium.com/leetcode-patterns/leetcode-pattern-1-bfs-dfs-25-of-the-problems-part-1-519450a84353)\n- [DFS + BFS Patterns (2)](https://medium.com/leetcode-patterns/leetcode-pattern-2-dfs-bfs-25-of-the-problems-part-2-a5b269597f52)\n\n## üìù Must-Read Leetcode Articles\n- [Sliding Window Template](https://leetcode.com/problems/frequency-of-the-most-frequent-element/solutions/1175088/C++-Maximum-Sliding-Window-Cheatsheet-Template/)\n- [Two Pointers Patterns](https://leetcode.com/discuss/study-guide/1688903/Solved-all-two-pointers-problems-in-100-days)\n- [Collections of Important String Questions](https://leetcode.com/discuss/study-guide/2001789/Collections-of-Important-String-questions-Pattern)\n- [Substring Problem Template](https://leetcode.com/problems/minimum-window-substring/solutions/26808/Here-is-a-10-line-template-that-can-solve-most-'substring'-problems/)\n- [Binary Search Template](https://leetcode.com/discuss/study-guide/786126/Python-Powerful-Ultimate-Binary-Search-Template.-Solved-many-problems)\n- [A General Approach to Backtracking Questions](https://leetcode.com/problems/permutations/solutions/18239/A-general-approach-to-backtracking-questions-in-Java-(Subsets-Permutations-Combination-Sum-Palindrome-Partioning)/)\n- [Monotonic Stack Template](https://leetcode.com/discuss/study-guide/2347639/A-comprehensive-guide-and-template-for-monotonic-stack-based-problems)\n- [Heap Patterns](https://leetcode.com/discuss/general-discussion/1127238/master-heap-by-solving-23-questions-in-4-patterns-category)\n- [Bit Manipulation Patterns](https://leetcode.com/discuss/study-guide/4282051/all-types-of-patterns-for-bits-manipulations-and-how-to-use-it)\n- [Dynamic Programming Patterns](https://leetcode.com/discuss/study-guide/458695/Dynamic-Programming-Patterns)\n- [Stock Series Patterns](https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/solutions/108870/most-consistent-ways-of-dealing-with-the-series-of-stock-problems/)\n\n## ‚úÖ Curated Problems\n- [AlgoMaster 300](https://algomaster.io/practice/dsa-patterns)\n- [Blind 75](https://leetcode.com/discuss/general-discussion/460599/blind-75-leetcode-questions)\n- [Leetcode Top 100 Liked](https://leetcode.com/studyplan/top-100-liked/)\n- [Leetcode Top Interview 150](https://leetcode.com/studyplan/top-interview-150/)\n\n## üì∫ YouTube Playlist\n- [AlgoMaster DSA Playlist](https://www.youtube.com/playlist?list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2&pp=gAQB)\n- [AlgoMaster LeetCode Pattern Playlist](https://www.youtube.com/playlist?list=PLK63NuByH5o-tqaMUHRA4r8ObRW7PWz45)\n- [Abdul Bari's Algorithms Playlist](https://www.youtube.com/playlist?list=PLDN4rrl48XKpZkf03iYFl-O29szjTrs_O)\n- [William Fiset's Data Structure Playlist](https://www.youtube.com/playlist?list=PLDV1Zeh2NRsB6SWUrDFW2RmDotAfPbeHu)\n- [William Fiset's Graphs Playlist](https://www.youtube.com/playlist?list=PLDV1Zeh2NRsDGO4--qE8yH72HFL1Km93P)\n- [Tushar Roy's Dynamic Programming Playlist](https://www.youtube.com/playlist?list=PLrmLmBdmIlpsHaNTPP_jHHDx_os9ItYXr)\n\n## üìá Courses\n- [Coursera - Algorithms, Part I](https://www.coursera.org/learn/algorithms-part1)\n- [Coursera - Algorithms, Part 2](https://www.coursera.org/learn/algorithms-part2)\n\n## üìö Books\n- [Data Structures And Algorithms Made Easy](https://www.amazon.in/dp/B08CMLS7LZ)\n- [Cracking the Coding Interview](https://www.amazon.in/dp/0984782850)\n\n## üì© Newsletter\n- [AlgoMaster Newsletter](https://blog.algomaster.io/)\n\n## üîé Visualization\n- [AlgoMaster DSA Animations](https://algomaster.io/animations/dsa)\n- [VisuAlgo](https://visualgo.net/en)\n\n## üìé LeetCode Extensions\n- [LeetCode Timer](https://chromewebstore.google.com/detail/leetcode-timer/gfkgelnlcnomnahkfmhemgpahgmibofd): Easily time your leetcode practise sessions with automatic time setting based on difficulty.\n- [LeetCode Video Solutions](https://chromewebstore.google.com/detail/leetcode-video-solutions/ilnmgkahgjdpkoliooildngldmilhelm): Watch free LeetCode video ‚ñ∂ solutions on the problem page itself.\n- [LeetCode Format](https://chromewebstore.google.com/detail/leetcode-format/imogghebhifnnlgogigikjecilkicfpp): Adds Format code button on leetcode to format the code using Prettier code formatter.\n- [LeetHub v2](https://chromewebstore.google.com/detail/leethub-v2/mhanfgfagplhgemhjfeolkkdidbakocm?hl=en): Automatically integrate your Leetcode & GeeksforGeeks submissions to GitHub.\n- [LeetCode VS Code Extension](https://marketplace.visualstudio.com/items?itemName=LeetCode.vscode-leetcode): Solve LeetCode problems in VS Code.\n\nYour contributions are most welcome!\n\n---\n\n<p align=\"center\">\n  <i>If you find this resource helpful, please give it a star ‚≠êÔ∏è and share it with others!</i>\n</p>\n",
      "stars_today": 63
    },
    {
      "id": 719980575,
      "name": "awesome-low-level-design",
      "full_name": "ashishps1/awesome-low-level-design",
      "description": "Learn Low Level Design (LLD) and prepare for interviews using free resources.",
      "html_url": "https://github.com/ashishps1/awesome-low-level-design",
      "stars": 21313,
      "forks": 5244,
      "language": "Java",
      "topics": [
        "awesome",
        "design-patterns",
        "interview",
        "interview-practice",
        "interview-questions",
        "lld",
        "low-level-design",
        "machine-coding",
        "object-oriented-programming",
        "oops",
        "solid-principles",
        "uml"
      ],
      "created_at": "2023-11-17T10:15:12Z",
      "updated_at": "2026-01-24T01:14:41Z",
      "pushed_at": "2026-01-12T19:05:31Z",
      "open_issues": 58,
      "owner": {
        "login": "ashishps1",
        "avatar_url": "https://avatars.githubusercontent.com/u/8646889?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"images/lld-repo-logo.png\" width=\"350\" height=\"200\">\n</p>\n<p align=\"center\">\n  <a href=\"https://blog.algomaster.io/\">Join Free Newsletter</a>\n</p>\n\nThis repository contains resources to learn Low Level Design (LLD) / Object Oriented Design (OOD) and prepare for interviews.\n\nüëâ For a better and more comprehensive experience, checkout the [LLD page at AlgoMaster.io](https://algomaster.io/learn/lld)\n\n## üß± OOP Fundamentals\n- [Classes and Objects](https://algomaster.io/learn/lld/classes-and-objects)\n- [Enums](https://algomaster.io/learn/lld/enums)\n- [Interfaces](https://algomaster.io/learn/lld/interfaces)\n- [Encapsulation](https://algomaster.io/learn/lld/encapsulation)\n- [Abstraction](https://algomaster.io/learn/lld/abstraction)\n- [Inheritance](https://algomaster.io/learn/lld/inheritance)\n- [Polymorphism](https://algomaster.io/learn/lld/polymorphism)\n\n## üîó Class Relationships\n- [Association](https://algomaster.io/learn/lld/association)\n- [Aggregation](https://algomaster.io/learn/lld/aggregation)\n- [Composition](https://algomaster.io/learn/lld/composition)\n- [Dependency](https://algomaster.io/learn/lld/dependency)\n\n## üß≠ Design Principles\n- [DRY Principle](https://algomaster.io/learn/lld/dry)\n- [YAGNI Principle](https://algomaster.io/learn/lld/yagni)\n- [KISS Principle](https://algomaster.io/learn/lld/kiss)\n- [SOLID Principles with Pictures](https://medium.com/backticks-tildes/the-s-o-l-i-d-principles-in-pictures-b34ce2f1e898)\n- [SOLID Principles with Code](https://blog.algomaster.io/p/solid-principles-explained-with-code)\n\n## üß© Design Patterns\n\n| **Creational Patterns**                                                       | **Structural Patterns**                                         | **Behavioral Patterns**                                                               |\n| ----------------------------------------------------------------------------- | --------------------------------------------------------------- | ------------------------------------------------------------------------------------- |\n| [Singleton](https://algomaster.io/learn/lld/singleton)            | [Adapter](https://algomaster.io/learn/lld/adapter)     | [Iterator](https://algomaster.io/learn/lld/iterator)                         |\n| [Factory Method](https://algomaster.io/learn/lld/factory-method)     | [Bridge](https://algomaster.io/learn/lld/bridge)       | [Observer](https://algomaster.io/learn/lld/observer)                         |\n| [Abstract Factory](https://algomaster.io/learn/lld/abstract-factory) | [Composite](https://algomaster.io/learn/lld/composite) | [Strategy](https://algomaster.io/learn/lld/strategy)                         |\n| [Builder](https://algomaster.io/learn/lld/builder)                   | [Decorator](https://algomaster.io/learn/lld/decorator) | [Command](https://algomaster.io/learn/lld/command)                           |\n| [Prototype](https://algomaster.io/learn/lld/prototype)               | [Facade](https://algomaster.io/learn/lld/facade)       | [State](https://algomaster.io/learn/lld/state)                               |\n|                                                                               | [Flyweight](https://algomaster.io/learn/lld/flyweight) | [Template Method](https://algomaster.io/learn/lld/template-method)           |\n|                                                                               | [Proxy](https://algomaster.io/learn/lld/proxy)         | [Visitor](https://algomaster.io/learn/lld/visitor)                           |\n|                                                                               |                                                                 | [Mediator](https://algomaster.io/learn/lld/mediator)                         |\n|                                                                               |                                                                 | [Memento](https://algomaster.io/learn/lld/memento)                           |\n|                                                                               |                                                                 | [Chain of Responsibility](https://algomaster.io/learn/lld/chain-of-responsibility) |\n\n## üóÇÔ∏è UML\n- [Class Diagram](https://blog.algomaster.io/p/uml-class-diagram-explained-with-examples)\n- [Use Case Diagram](https://blog.algomaster.io/p/119449cd-b003-46da-9e4d-0eb356d216d8)\n- [Sequence Diagram](https://blog.algomaster.io/p/4dd99bdc-5c35-4a80-bc53-1777cb57aa05)\n- [Activity Diagram](https://www.visual-paradigm.com/guide/uml-unified-modeling-language/what-is-activity-diagram/)\n- [State Machine Diagram](https://www.visual-paradigm.com/guide/uml-unified-modeling-language/what-is-state-machine-diagram/)\n\n## ‚úÖ [How to Answer a LLD Interview Problem](https://blog.algomaster.io/p/how-to-answer-a-lld-interview-problem)\n<img src=\"images/interview-template.png\" width=\"350\" height=\"250\">\n\n## üíª Low Level Design Interview Problems\n### Easy Problems\n\n- [Design Parking Lot](problems/parking-lot.md)\n- [Design Stack Overflow](problems/stack-overflow.md)\n- [Design a Vending Machine](problems/vending-machine.md)\n- [Design Logging Framework](problems/logging-framework.md)\n- [Design Traffic Signal Control System](problems/traffic-signal.md)\n- [Design Coffee Vending Machine](problems/coffee-vending-machine.md)\n- [Design a Task Management System](problems/task-management-system.md)\n\n### Medium Problems\n\n- [Design ATM](problems/atm.md)\n- [Design LinkedIn](problems/linkedin.md)\n- [Design LRU Cache](problems/lru-cache.md)\n- [Design Tic Tac Toe Game](problems/tic-tac-toe.md)\n- [Design Pub Sub System](problems/pub-sub-system.md)\n- [Design an Elevator System](problems/elevator-system.md)\n- [Design Car Rental System](problems/car-rental-system.md)\n- [Design an Online Auction System](problems/online-auction-system.md)\n- [Design Hotel Management System](problems/hotel-management-system.md)\n- [Design a Digital Wallet Service](problems/digital-wallet-service.md)\n- [Design Airline Management System](problems/airline-management-system.md)\n- [Design a Library Management System](problems/library-management-system.md)\n- [Design a Social Network like Facebook](problems/social-networking-service.md)\n- [Design Restaurant Management System](problems/restaurant-management-system.md)\n- [Design a Concert Ticket Booking System](problems/concert-ticket-booking-system.md)\n\n### Hard Problems\n\n- [Design CricInfo](problems/cricinfo.md)\n- [Design Splitwise](problems/splitwise.md)\n- [Design Chess Game](problems/chess-game.md)\n- [Design a Snake and Ladder game](problems/snake-and-ladder.md)\n- [Design Ride-Sharing Service like Uber](problems/ride-sharing-service.md)\n- [Design Course Registration System](problems/course-registration-system.md)\n- [Design Movie Ticket Booking System](problems/movie-ticket-booking-system.md)\n- [Design Online Shopping System like Amazon](problems/online-shopping-service.md)\n- [Design Online Stock Brokerage System](problems/online-stock-brokerage-system.md)\n- [Design Music Streaming Service like Spotify](problems/music-streaming-service.md)\n- [Design Online Food Delivery Service like Swiggy](problems/food-delivery-service.md)\n\n## üìá Courses\n- [Master LLD Interviews - AlgoMaster.io](https://algomaster.io/learn/lld/course-introduction)\n\n## üìö Books\n- [Head First Design Patterns](https://www.amazon.in/dp/9385889753)\n- [Clean Code](https://www.amazon.in/dp/B001GSTOAM)\n- [Refactoring: Improving the Design of Existing Code](https://www.amazon.in/dp/0134757599)\n\n## üì© Newsletter\n- [AlgoMaster Newsletter](https://blog.algomaster.io/)\n\n## Additional resources\n- [Coursera - Object-Oriented Design](https://www.coursera.org/learn/object-oriented-design)\n- [Coursera - Design Patterns](https://www.coursera.org/learn/design-patterns)\n- [Github - Awesome Design Patterns](https://github.com/DovAmir/awesome-design-patterns)\n\n## ü§ù Contributing\nContributions are welcome! If you'd like to add a new problem, improve existing content, or fix errors:\n1. Fork the repository\n2. Create a feature branch: `git checkout -b feature/your-feature-name`\n3. Commit your changes: `git commit -m 'Add some feature'`\n4. Push to the branch: `git push origin feature/your-feature-name`\n5. Submit a pull request\n\nPlease make sure to update Readme files and documentation as appropriate.\n\n---\n\n<p align=\"center\">\n  <i>If you find this resource helpful, please give it a star and share it with others!</i>\n</p>\n",
      "stars_today": 62
    },
    {
      "id": 1052259802,
      "name": "ralph-orchestrator",
      "full_name": "mikeyobrien/ralph-orchestrator",
      "description": "An improved implementation of the Ralph Wiggum technique for autonomous AI agent orchestration",
      "html_url": "https://github.com/mikeyobrien/ralph-orchestrator",
      "stars": 1291,
      "forks": 142,
      "language": "Rust",
      "topics": [
        "ai",
        "ai-agents",
        "ai-agents-framework",
        "ai-developer-tools",
        "claude-code",
        "claude-code-cli",
        "codex-cli",
        "development-tools",
        "development-workflow",
        "gemini-cli",
        "kiro",
        "kiro-cli",
        "opencode",
        "ralph-loop",
        "ralph-wiggum"
      ],
      "created_at": "2025-09-07T18:17:13Z",
      "updated_at": "2026-01-24T00:13:22Z",
      "pushed_at": "2026-01-24T00:31:45Z",
      "open_issues": 7,
      "owner": {
        "login": "mikeyobrien",
        "avatar_url": "https://avatars.githubusercontent.com/u/11792047?v=4"
      },
      "readme": "# Ralph Orchestrator\n\n[![License](https://img.shields.io/badge/license-MIT-blue)](LICENSE)\n[![Rust](https://img.shields.io/badge/rust-1.75+-orange)](https://www.rust-lang.org/)\n[![Build](https://img.shields.io/github/actions/workflow/status/mikeyobrien/ralph-orchestrator/ci.yml?branch=main&label=CI)](https://github.com/mikeyobrien/ralph-orchestrator/actions)\n[![Coverage](https://img.shields.io/badge/coverage-65%25-yellowgreen)](coverage/index.html)\n[![Mentioned in Awesome Claude Code](https://awesome.re/mentioned-badge.svg)](https://github.com/hesreallyhim/awesome-claude-code)\n[![Docs](https://img.shields.io/badge/docs-mkdocs-blue)](https://mikeyobrien.github.io/ralph-orchestrator/)\n\n\nA hat-based orchestration framework that keeps Ralph in a loop until the task is done.\n\n> \"Me fail English? That's unpossible!\" - Ralph Wiggum\n\n**Notice:** Ralph Orchestrator is under active development. It works today, but expect rough edges and breaking changes between releases.\n\nv1.0.0 was ralphed into existence with little oversight and guidance. v2.0.0 is a simpler, more-structured implementation. Looking for the old version? See [v1.2.3](https://github.com/mikeyobrien/ralph-orchestrator/tree/v1.2.3). \n\n<img width=\"912\" height=\"712\" alt=\"Screenshot 2026-01-20 at 10 27 57‚ÄØAM\" src=\"https://github.com/user-attachments/assets/91b08b47-8b0a-4e2c-b66e-88551c2c5cc6\" />\n\n## Table of Contents\n\n- [What is Ralph?](#what-is-ralph)\n- [Features](#features)\n- [Installation](#installation)\n- [Quick Start](#quick-start)\n- [Configuration](#configuration)\n- [Custom Backends and Per-Hat Configuration](#custom-backends-and-per-hat-configuration)\n- [Presets](#presets)\n- [Key Concepts](#key-concepts)\n- [Orchestration and Coordination Patterns](#orchestration-and-coordination-patterns)\n- [CLI Reference](#cli-reference)\n- [Architecture](#architecture)\n- [Building & Testing](#building--testing)\n- [Contributing](#contributing)\n- [License](#license)\n- [Acknowledgments](#acknowledgments)\n\n## What is Ralph?\n\nRalph implements the [Ralph Wiggum technique](https://ghuntley.com/ralph/) ‚Äî autonomous task completion through continuous iteration.\n\n> \"The orchestrator is a thin coordination layer, not a platform. Ralph is smart; let Ralph do the work.\"\n\n### Two Modes of Operation\n\nRalph supports two orchestration styles:\n\n| Mode | Description | Best For |\n|------|-------------|----------|\n| **Traditional** | Simple loop ‚Äî Ralph iterates until done | Quick tasks, simple automation, minimal config |\n| **Hat-Based** | Ralph can wear many hats ‚Äî specialized personas coordinate through events | Complex workflows, multi-step processes, role separation |\n\n**Traditional mode** is the original Ralph Wiggum approach: start a loop, let it run until it outputs the completion promise. No roles, no events, just iteration.\n\n**Hat-based mode** adds structure: specialized personas coordinate through events. You define the roles that fit your workflow ‚Äî reviewers, testers, documenters, whatever makes sense. Presets provide ready-made patterns like TDD or spec-driven development.\n\n### The Ralph Tenets\n\n1. **Fresh Context Is Reliability** ‚Äî Each iteration clears context. Re-read specs, plan, code every cycle.\n2. **Backpressure Over Prescription** ‚Äî Don't prescribe how; create gates that reject bad work.\n3. **The Plan Is Disposable** ‚Äî Regeneration costs one planning loop. Cheap.\n4. **Disk Is State, Git Is Memory** ‚Äî Files are the handoff mechanism.\n5. **Steer With Signals, Not Scripts** ‚Äî Add signs, not scripts.\n6. **Let Ralph Ralph** ‚Äî Sit *on* the loop, not *in* it.\n\nSee [AGENTS.md](AGENTS.md) for the full philosophy.\n\n## Features\n\n- **Multi-Backend Support** ‚Äî Works with Claude Code, Kiro, Gemini CLI, Codex, Amp, Copilot CLI, and OpenCode\n- **Hat System** ‚Äî Specialized Ralph personas with distinct behaviors\n- **Event-Driven Coordination** ‚Äî Hats communicate through typed events with glob pattern matching\n- **Backpressure Enforcement** ‚Äî Gates that reject incomplete work (tests, lint, typecheck)\n- **Presets Library** ‚Äî 20+ pre-configured workflows for common development patterns\n- **Interactive TUI** ‚Äî Real-time terminal UI for monitoring Ralph's activity (enabled by default)\n- **Memories** ‚Äî Persistent learning across sessions stored in `.agent/memories.md`\n- **Tasks** ‚Äî Runtime work tracking stored in `.agent/tasks.jsonl`\n- **Session Recording** ‚Äî Record and replay sessions for debugging and testing (experimental)\n\n## Installation\n\n### Prerequisites\n\n- [Rust](https://rustup.rs/) 1.75+\n- At least one AI CLI:\n  - [Claude Code](https://github.com/anthropics/claude-code) (recommended)\n  - [Kiro](https://kiro.dev/)\n  - [Gemini CLI](https://github.com/google-gemini/gemini-cli)\n  - [Codex](https://github.com/openai/codex)\n  - [Amp](https://github.com/sourcegraph/amp)\n  - [Copilot CLI](https://docs.github.com/copilot) (`npm install -g @github/copilot`)\n  - [OpenCode](https://opencode.ai/) (`curl -fsSL https://opencode.ai/install | bash`)\n\n### Via npm (Recommended)\n\n```bash\n# Install globally\nnpm install -g @ralph-orchestrator/ralph-cli\n\n# Or run directly with npx\nnpx @ralph-orchestrator/ralph-cli --version\n```\n\n### Via Homebrew (macOS)\n\n```bash\nbrew install ralph-orchestrator\n```\n\n### Via Cargo\n\n```bash\ncargo install ralph-cli\n```\n\n### From Source\n\n```bash\ngit clone https://github.com/mikeyobrien/ralph-orchestrator.git\ncd ralph-orchestrator\ncargo build --release\n\n# Add to PATH\nexport PATH=\"$PATH:$(pwd)/target/release\"\n\n# Or create symlink\nsudo ln -s $(pwd)/target/release/ralph /usr/local/bin/ralph\n```\n\n### Verify Installation\n\n```bash\nralph --version\nralph --help\n```\n\n### Migrating from v1 (Python)\n\nIf you have the old Python-based Ralph v1 installed, uninstall it first to avoid conflicts:\n\n```bash\n# If installed via pip\npip uninstall ralph-orchestrator\n\n# If installed via pipx\npipx uninstall ralph-orchestrator\n\n# If installed via uv\nuv tool uninstall ralph-orchestrator\n\n# Verify removal\nwhich ralph  # Should return nothing or point to new Rust version\n```\n\nThe v1 Python version is no longer maintained. See [v1.2.3](https://github.com/mikeyobrien/ralph-orchestrator/tree/v1.2.3) for historical reference.\n\n## Quick Start\n\n### 1. Initialize a Project\n\n```bash\n# Traditional mode ‚Äî simple loop, no hats (recommended for getting started)\nralph init --backend claude\n\n# Hat-based mode ‚Äî use a preset workflow with specialized personas\nralph init --preset tdd-red-green\n\n# Combine preset with different backend\nralph init --preset spec-driven --backend kiro\n\n# See all available presets\nralph init --list-presets\n```\n\nThis creates `ralph.yml` in your current directory. Without a preset, you get traditional mode (no hats). With a preset, you get hat-based orchestration.\n\n### 2. Define Your Task\n\n**Option A:** Create a `PROMPT.md` file:\n\n```bash\ncat > PROMPT.md << 'EOF'\nBuild a REST API with the following endpoints:\n- POST /users - Create a new user\n- GET /users/:id - Get user by ID\n- PUT /users/:id - Update user\n- DELETE /users/:id - Delete user\n\nUse Express.js with TypeScript. Include input validation\nand proper error handling.\nEOF\n```\n\n**Option B:** Pass inline prompt when running:\n\n```bash\nralph run -p \"Add input validation to the user API endpoints\"\n```\n\n### 3. Run Ralph\n\n```bash\n# TUI mode (default) ‚Äî real-time terminal UI for monitoring\nralph run\n\n# With inline prompt\nralph run -p \"Implement the login endpoint with JWT authentication\"\n\n# Headless mode (no TUI)\nralph run --no-tui\n\n# Resume interrupted session\nralph run --continue\n\n# Dry run (show what would execute)\nralph run --dry-run\n```\n\n### Alternative: SOP-Driven Sessions\n\nFor standalone planning and task generation (without Ralph's event loop), use these commands:\n\n```bash\n# Start an interactive PDD planning session\nralph plan                           # SOP prompts for input\nralph plan \"build a REST API\"        # Provide idea inline\nralph plan --backend kiro \"my idea\"  # Use specific backend\n\n# Generate code task files from descriptions\nralph task                           # SOP prompts for input\nralph task \"add authentication\"      # From description\nralph task specs/feature/plan.md     # From PDD plan file\n```\n\nThese commands spawn an interactive AI session with bundled SOPs ‚Äî perfect for one-off planning without configuring a full workflow.\n\n## Configuration\n\nRalph uses a YAML configuration file (`ralph.yml` by default).\n\n### Traditional Mode (No Hats)\n\nThe simplest configuration ‚Äî just a loop that runs until completion:\n\n```yaml\n# ralph.yml ‚Äî Traditional mode\ncli:\n  backend: \"claude\"\n\nevent_loop:\n  completion_promise: \"LOOP_COMPLETE\"\n  max_iterations: 100\n```\n\nThis runs Ralph in a loop. No hats, no events, no role switching. Ralph iterates until it outputs `LOOP_COMPLETE` or hits the iteration limit.\n\n### Hat-Based Mode (Specialized Personas)\n\n> Ralph can wear many hats.\n\nAdd a `hats` section to enable role-based orchestration. Hats subscribe to events (triggers) and publish events when done:\n\n```yaml\n# ralph.yml ‚Äî Hat-based mode (example structure)\ncli:\n  backend: \"claude\"\n\nevent_loop:\n  completion_promise: \"LOOP_COMPLETE\"\n  max_iterations: 100\n  starting_event: \"task.start\"\n\nhats:\n  my_hat:\n    name: \"üéØ My Hat\"\n    triggers: [\"task.start\"]        # Events that activate this hat\n    publishes: [\"work.done\"]        # Events this hat can emit\n    instructions: |\n      Your instructions here...\n```\n\nWith hats, Ralph publishes a starting event, which triggers the matching hat. That hat does its work and publishes an event, potentially triggering other hats. This event-driven handoff continues until completion.\n\n> **Tip:** Use `ralph init --preset <name>` to get pre-configured hat workflows. See [Presets](#presets) for ready-made patterns like TDD, spec-driven development, and more.\n\n### Full Configuration Reference\n\n```yaml\n# Event loop settings\nevent_loop:\n  completion_promise: \"LOOP_COMPLETE\"  # Output that signals completion\n  max_iterations: 100                   # Maximum orchestration loops\n  max_runtime_seconds: 14400            # 4 hours max runtime\n  idle_timeout_secs: 1800               # 30 min idle timeout\n  starting_event: \"task.start\"          # First event published\n\n# CLI backend settings\ncli:\n  backend: \"claude\"                     # claude, kiro, gemini, codex, amp, copilot, opencode, custom\n  prompt_mode: \"arg\"                    # arg (CLI argument) or stdin\n\n# Core behaviors (always injected into prompts)\ncore:\n  scratchpad: \".agent/scratchpad.md\"    # Shared memory across iterations\n  specs_dir: \"./specs/\"                 # Directory for specifications\n  guardrails:                           # Rules injected into every prompt\n    - \"Fresh context each iteration - scratchpad is memory\"\n    - \"Don't assume 'not implemented' - search first\"\n    - \"Backpressure is law - tests/typecheck/lint must pass\"\n\n# Memories ‚Äî persistent learning across sessions (enabled by default)\nmemories:\n  enabled: true                         # Set false to disable\n  inject: auto                          # auto, manual, or none\n\n# Tasks ‚Äî runtime work tracking (enabled by default)\ntasks:\n  enabled: true                         # Set false to use scratchpad-only mode\n\n# Custom hats (omit to use default planner/builder)\nhats:\n  my_hat:\n    name: \"My Hat Name\"                 # Display name\n    triggers: [\"some.event\"]            # Events that activate this hat\n    publishes: [\"other.event\"]          # Events this hat can emit\n    instructions: |                     # Prompt instructions\n      What this hat should do...\n```\n\n\n## Custom Backends and Per-Hat Configuration\n\n### Custom Backends\n\nBeyond the built-in backends (Claude, Kiro, Gemini, Codex, Amp, Copilot, OpenCode), you can define custom backends to integrate any CLI-based AI agent:\n\n```yaml\ncli:\n  backend: \"custom\"\n  command: \"my-agent\"\n  args: [\"--headless\", \"--auto-approve\"]\n  prompt_mode: \"arg\"        # \"arg\" or \"stdin\"\n  prompt_flag: \"-p\"         # Optional: flag for prompt argument\n```\n\n| Field | Description |\n|-------|-------------|\n| `command` | The CLI command to execute |\n| `args` | Arguments inserted before the prompt |\n| `prompt_mode` | How to pass the prompt: `arg` (command-line argument) or `stdin` |\n| `prompt_flag` | Flag preceding the prompt (e.g., `-p`, `--prompt`). If omitted, prompt is positional. |\n\n### Per-Hat Backend Configuration\n\nDifferent hats can use different backends, enabling specialized tools for specialized tasks:\n\n```yaml\ncli:\n  backend: \"claude\"  # Default for Ralph and hats without explicit backend\n\nhats:\n  builder:\n    name: \"üî® Builder\"\n    description: \"Implements code\"\n    triggers: [\"build.task\"]\n    publishes: [\"build.done\"]\n    backend: \"claude\"        # Explicit: Claude for coding\n\n  researcher:\n    name: \"üîç Researcher\"\n    description: \"Researches technical questions\"\n    triggers: [\"research.task\"]\n    publishes: [\"research.done\"]\n    backend:                 # Kiro with custom agent (has MCP tools)\n      type: \"kiro\"\n      agent: \"researcher\"\n\n  reviewer:\n    name: \"üëÄ Reviewer\"\n    description: \"Reviews code changes\"\n    triggers: [\"review.task\"]\n    publishes: [\"review.done\"]\n    backend: \"gemini\"        # Different model for fresh perspective\n```\n\n**Backend Types:**\n\n| Type | Syntax | Invocation |\n|------|--------|------------|\n| Named | `backend: \"claude\"` | Uses standard backend configuration |\n| Kiro Agent | `backend: { type: \"kiro\", agent: \"builder\" }` | `kiro-cli --agent builder ...` |\n| Custom | `backend: { command: \"...\", args: [...] }` | Your custom command |\n\n**When to mix backends:**\n\n| Scenario | Recommended Backend |\n|----------|---------------------|\n| Complex coding | Claude (best reasoning) |\n| AWS/cloud tasks | Kiro with agent (MCP tools) |\n| Code review | Different model (fresh perspective) |\n| Internal tools | Custom backend |\n| Cost optimization | Faster/cheaper model for simple tasks |\n\nHats without explicit `backend` inherit from `cli.backend`.\n\n## Presets\n\nPresets are pre-configured workflows for common development patterns.\n\n### Development Workflows\n\n| Preset | Pattern | Description |\n|--------|---------|-------------|\n| `feature` | Planner-Builder | Standard feature development |\n| `feature-minimal` | Single hat | Minimal feature development |\n| `tdd-red-green` | Test-Implement-Refactor | TDD with red-green-refactor cycle |\n| `spec-driven` | Spec-Build-Verify | Specification-first development |\n| `refactor` | Analyze-Plan-Execute | Code refactoring workflow |\n\n### Debugging & Investigation\n\n| Preset | Pattern | Description |\n|--------|---------|-------------|\n| `debug` | Investigate-Fix-Verify | Bug investigation and fixing |\n| `incident-response` | Triage-Fix-Postmortem | Production incident handling |\n| `code-archaeology` | Explore-Document-Present | Legacy code understanding |\n\n### Review & Quality\n\n| Preset | Pattern | Description |\n|--------|---------|-------------|\n| `review` | Analyze-Critique-Suggest | Code review workflow |\n| `pr-review` | Multi-Perspective | PR review with specialized reviewers |\n| `adversarial-review` | Critic-Defender | Devil's advocate review style |\n\n### Documentation\n\n| Preset | Pattern | Description |\n|--------|---------|-------------|\n| `docs` | Write-Review-Publish | Documentation writing |\n| `documentation-first` | Doc-Implement-Sync | Doc-first development |\n\n### Specialized\n\n| Preset | Pattern | Description |\n|--------|---------|-------------|\n| `api-design` | Design-Implement-Document | API-first development |\n| `migration-safety` | Analyze-Migrate-Verify | Safe code migrations |\n| `performance-optimization` | Profile-Optimize-Benchmark | Performance tuning |\n| `scientific-method` | Hypothesis-Experiment-Conclude | Experimental approach |\n| `mob-programming` | Rotate roles | Simulated mob programming |\n| `socratic-learning` | Question-Answer-Synthesize | Learning through dialogue |\n| `research` | Gather-Analyze-Synthesize | Research and analysis |\n| `gap-analysis` | Current-Target-Plan | Gap identification |\n\n### Using Presets\n\n```bash\n# List all available presets\nralph init --list-presets\n\n# Initialize with a preset\nralph init --preset tdd-red-green\n\n# Use preset with different backend\nralph init --preset spec-driven --backend gemini\n\n# Override existing config\nralph init --preset debug --force\n```\n\n## Key Concepts\n\n### Hats\n\nHats are specialized Ralph personas. Each hat has:\n\n- **Triggers**: Events that activate this hat\n- **Publishes**: Events this hat can emit\n- **Instructions**: Prompt injected when hat is active\n\nView event history:\n\n```bash\nralph events\n```\n\n## Orchestration and Coordination Patterns\n\nRalph's hat system enables sophisticated multi-agent workflows through event-driven coordination. This section covers the architectural patterns, event routing mechanics, and built-in workflow templates.\n\n### How Hat-Based Orchestration Works\n\n#### The Event-Driven Model\n\nHats communicate through a **pub/sub event system**:\n\n1. **Ralph publishes a starting event** (e.g., `task.start`)\n2. **The matching hat activates** ‚Äî the hat subscribed to that event takes over\n3. **The hat does its work** and publishes an event when done\n4. **The next hat activates** ‚Äî triggered by the new event\n5. **The cycle continues** until a termination event or `LOOP_COMPLETE`\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  task.start ‚Üí [Test Writer] ‚Üí test.written ‚Üí [Implementer] ‚Üí   ‚îÇ\n‚îÇ  test.passing ‚Üí [Refactorer] ‚Üí refactor.done ‚îÄ‚îÄ‚îê                ‚îÇ\n‚îÇ                                                ‚îÇ                ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚Üí (loops back to Test Writer for next test)                 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n#### Ralph as the Constant Coordinator\n\nIn hat-based mode, **Ralph is always present**:\n\n- Ralph cannot be removed or replaced\n- Custom hats define the **topology** (who triggers whom)\n- Ralph executes with **topology awareness** ‚Äî knowing which hats exist and their relationships\n- Ralph serves as the **universal fallback** ‚Äî orphaned events automatically route to Ralph\n\nThis means custom hats don't execute directly. Instead, Ralph reads all pending events across all hats and decides what to do based on the defined topology. Ralph then either:\n- Delegates to the appropriate hat by publishing an event\n- Handles the work directly if no hat is suited\n\n#### Event Routing and Topic Matching\n\nEvents route to hats using **glob-style pattern matching**:\n\n| Pattern | Matches |\n|---------|---------|\n| `task.start` | Exactly `task.start` |\n| `build.*` | `build.done`, `build.blocked`, `build.task`, etc. |\n| `*.done` | `build.done`, `review.done`, `test.done`, etc. |\n| `*` | Everything (global wildcard ‚Äî used by Ralph as fallback) |\n\n**Priority Rules:**\n- Specific patterns take precedence over wildcards\n- If multiple hats have specific subscriptions, that's an error (ambiguous routing)\n- Global wildcard (`*`) only triggers if no specific handler exists\n\n### Coordination Patterns\n\nRalph presets implement several proven coordination patterns:\n\n#### 1. Linear Pipeline\n\nThe simplest pattern ‚Äî work flows through a sequence of specialists.\n\n```\nInput ‚Üí Hat A ‚Üí Event ‚Üí Hat B ‚Üí Event ‚Üí Hat C ‚Üí Output\n```\n\n**Example: TDD Red-Green-Refactor** (`tdd-red-green.yml`)\n\n```yaml\nhats:\n  test_writer:\n    triggers: [\"tdd.start\", \"refactor.done\"]\n    publishes: [\"test.written\"]\n\n  implementer:\n    triggers: [\"test.written\"]\n    publishes: [\"test.passing\"]\n\n  refactorer:\n    triggers: [\"test.passing\"]\n    publishes: [\"refactor.done\", \"cycle.complete\"]\n```\n\n```\ntdd.start ‚Üí üî¥ Test Writer ‚Üí test.written ‚Üí üü¢ Implementer ‚Üí\ntest.passing ‚Üí üîµ Refactorer ‚Üí refactor.done ‚îÄ‚îê\n                                              ‚îÇ\n              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n              ‚îî‚îÄ‚îÄ‚Üí (back to Test Writer)\n```\n\n**When to use:** Workflows with clear sequential phases where each step builds on the previous.\n\n#### 2. Contract-First Pipeline\n\nA variant where work must pass validation gates before proceeding.\n\n**Example: Spec-Driven Development** (`spec-driven.yml`)\n\n```yaml\nhats:\n  spec_writer:\n    triggers: [\"spec.start\", \"spec.rejected\"]\n    publishes: [\"spec.ready\"]\n\n  spec_reviewer:\n    triggers: [\"spec.ready\"]\n    publishes: [\"spec.approved\", \"spec.rejected\"]\n\n  implementer:\n    triggers: [\"spec.approved\", \"spec.violated\"]\n    publishes: [\"implementation.done\"]\n\n  verifier:\n    triggers: [\"implementation.done\"]\n    publishes: [\"task.complete\", \"spec.violated\"]\n```\n\n```\nspec.start ‚Üí üìã Spec Writer ‚îÄ‚îÄ‚Üí spec.ready ‚îÄ‚îÄ‚Üí üîé Spec Critic\n                 ‚Üë                                   ‚îÇ\n                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ spec.rejected ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n                                                     ‚Üì\n                                               spec.approved\n                                                     ‚îÇ\n                                                     ‚Üì\ntask.complete ‚Üê‚îÄ‚îÄ ‚úÖ Verifier ‚Üê‚îÄ‚îÄ impl.done ‚Üê‚îÄ‚îÄ ‚öôÔ∏è Implementer\n                       ‚îÇ                              ‚Üë\n                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ spec.violated ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n**When to use:** High-stakes changes where the spec must be rock-solid before implementation begins.\n\n#### 3. Cyclic Rotation\n\nMultiple roles take turns, each bringing a different perspective.\n\n**Example: Mob Programming** (`mob-programming.yml`)\n\n```yaml\nhats:\n  navigator:\n    triggers: [\"mob.start\", \"observation.noted\"]\n    publishes: [\"direction.set\", \"mob.complete\"]\n\n  driver:\n    triggers: [\"direction.set\"]\n    publishes: [\"code.written\"]\n\n  observer:\n    triggers: [\"code.written\"]\n    publishes: [\"observation.noted\"]\n```\n\n```\nmob.start ‚Üí üß≠ Navigator ‚Üí direction.set ‚Üí ‚å®Ô∏è Driver ‚Üí\ncode.written ‚Üí üëÅÔ∏è Observer ‚Üí observation.noted ‚îÄ‚îê\n                                                ‚îÇ\n              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n              ‚îî‚îÄ‚îÄ‚Üí (back to Navigator)\n```\n\n**When to use:** Complex features that benefit from multiple perspectives and continuous feedback.\n\n#### 4. Adversarial Review\n\nTwo roles with opposing objectives ensure robustness.\n\n**Example: Red Team / Blue Team** (`adversarial-review.yml`)\n\n```yaml\nhats:\n  builder:\n    name: \"üîµ Blue Team (Builder)\"\n    triggers: [\"security.review\", \"fix.applied\"]\n    publishes: [\"build.ready\"]\n\n  red_team:\n    name: \"üî¥ Red Team (Attacker)\"\n    triggers: [\"build.ready\"]\n    publishes: [\"vulnerability.found\", \"security.approved\"]\n\n  fixer:\n    triggers: [\"vulnerability.found\"]\n    publishes: [\"fix.applied\"]\n```\n\n```\nsecurity.review ‚Üí üîµ Blue Team ‚Üí build.ready ‚Üí üî¥ Red Team\n                      ‚Üë                            ‚îÇ\n                      ‚îÇ                            ‚îú‚îÄ‚Üí security.approved ‚úì\n                      ‚îÇ                            ‚îÇ\n                      ‚îÇ                            ‚îî‚îÄ‚Üí vulnerability.found\n                      ‚îÇ                                        ‚îÇ\n                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ fix.applied ‚Üê‚îÄ‚îÄ üõ°Ô∏è Fixer ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n**When to use:** Security-sensitive code, authentication systems, or any code where adversarial thinking improves quality.\n\n#### 5. Hypothesis-Driven Investigation\n\nThe scientific method applied to debugging.\n\n**Example: Scientific Method** (`scientific-method.yml`)\n\n```yaml\nhats:\n  observer:\n    triggers: [\"science.start\", \"hypothesis.rejected\"]\n    publishes: [\"observation.made\"]\n\n  theorist:\n    triggers: [\"observation.made\"]\n    publishes: [\"hypothesis.formed\"]\n\n  experimenter:\n    triggers: [\"hypothesis.formed\"]\n    publishes: [\"hypothesis.confirmed\", \"hypothesis.rejected\"]\n\n  fixer:\n    triggers: [\"hypothesis.confirmed\"]\n    publishes: [\"fix.applied\"]\n```\n\n```\nscience.start ‚Üí üî¨ Observer ‚Üí observation.made ‚Üí üß† Theorist ‚Üí\nhypothesis.formed ‚Üí üß™ Experimenter ‚îÄ‚îÄ‚î¨‚îÄ‚Üí hypothesis.confirmed ‚Üí üîß Fixer\n                                      ‚îÇ\n                                      ‚îî‚îÄ‚Üí hypothesis.rejected ‚îÄ‚îê\n                                                               ‚îÇ\n              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n              ‚îî‚îÄ‚îÄ‚Üí (back to Observer with new data)\n```\n\n**When to use:** Complex bugs where the root cause isn't obvious. Forces systematic investigation over random fixes.\n\n#### 6. Coordinator-Specialist (Fan-Out)\n\nA coordinator delegates to specialists based on the work type.\n\n**Example: Gap Analysis** (`gap-analysis.yml`)\n\n```yaml\nhats:\n  analyzer:\n    triggers: [\"gap.start\", \"verify.complete\", \"report.complete\"]\n    publishes: [\"analyze.spec\", \"verify.request\", \"report.request\"]\n\n  verifier:\n    triggers: [\"analyze.spec\", \"verify.request\"]\n    publishes: [\"verify.complete\"]\n\n  reporter:\n    triggers: [\"report.request\"]\n    publishes: [\"report.complete\"]\n```\n\n```\n                    ‚îå‚îÄ‚Üí analyze.spec ‚îÄ‚îÄ‚Üí üîç Verifier ‚îÄ‚îÄ‚îê\n                    ‚îÇ                                  ‚îÇ\ngap.start ‚Üí üìä Analyzer ‚Üê‚îÄ‚îÄ verify.complete ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                    ‚îÇ\n                    ‚îî‚îÄ‚Üí report.request ‚îÄ‚îÄ‚Üí üìù Reporter ‚îÄ‚îÄ‚Üí report.complete\n```\n\n**When to use:** Work that naturally decomposes into independent specialist tasks (analysis, verification, reporting).\n\n#### 7. Adaptive Entry Point\n\nA bootstrapping hat detects input type and routes to the appropriate workflow.\n\n**Example: Code-Assist** (`code-assist.yml`)\n\n```yaml\nhats:\n  planner:\n    triggers: [\"build.start\"]\n    publishes: [\"tasks.ready\"]\n    # Detects: PDD directory vs. code task file vs. description\n\n  builder:\n    triggers: [\"tasks.ready\", \"validation.failed\", \"task.complete\"]\n    publishes: [\"implementation.ready\", \"task.complete\"]\n\n  validator:\n    triggers: [\"implementation.ready\"]\n    publishes: [\"validation.passed\", \"validation.failed\"]\n\n  committer:\n    triggers: [\"validation.passed\"]\n    publishes: [\"commit.complete\"]\n```\n\n```\nbuild.start ‚Üí üìã Planner ‚îÄ‚îÄ‚îÄ (detects input type) ‚îÄ‚îÄ‚îÄ‚Üí tasks.ready\n                                                            ‚îÇ\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n    ‚îÇ\n    ‚Üì\n‚öôÔ∏è Builder ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ validation.failed ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n    ‚îÇ                                               ‚îÇ\n    ‚îú‚îÄ‚îÄ task.complete ‚îÄ‚îÄ‚Üí (loop for PDD mode) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n    ‚îÇ                                               ‚îÇ\n    ‚îî‚îÄ‚îÄ implementation.ready ‚îÄ‚îÄ‚Üí ‚úÖ Validator ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n                                      ‚îÇ             ‚îÇ\n                                      ‚îî‚îÄ‚Üí validation.passed\n                                              ‚îÇ\n                                              ‚Üì\n                                        üì¶ Committer ‚Üí commit.complete\n```\n\n**When to use:** Workflows that need to handle multiple input formats or adapt their behavior based on context.\n\n### Designing Custom Hat Collections\n\n#### Hat Configuration Schema\n\n```yaml\nhats:\n  my_hat:\n    name: \"üéØ Display Name\"      # Shown in TUI and logs\n    description: \"What this hat does\"  # REQUIRED ‚Äî Ralph uses this for delegation\n    triggers: [\"event.a\", \"event.b\"]   # Events that activate this hat\n    publishes: [\"event.c\", \"event.d\"]  # Events this hat can emit\n    default_publishes: \"event.c\"       # Fallback if hat forgets to emit\n    max_activations: 10                # Optional cap on activations\n    backend: \"claude\"                  # Optional backend override\n    instructions: |\n      Prompt injected when this hat is active.\n      Tell the hat what to do, not how to do it.\n```\n\n#### Design Principles\n\n1. **Description is critical** ‚Äî Ralph uses hat descriptions to decide when to delegate. Make them clear and specific.\n\n2. **One hat, one responsibility** ‚Äî Each hat should have a clear, focused purpose. If you're writing \"and\" in the description, consider splitting.\n\n3. **Events are routing signals, not data** ‚Äî Keep payloads brief. Store detailed output in files and reference them in events.\n\n4. **Design for recovery** ‚Äî If a hat fails or forgets to publish, Ralph catches the orphaned event. Your topology should handle unexpected states gracefully.\n\n5. **Test with simple prompts first** ‚Äî Complex topologies can have emergent behavior. Start simple, validate the flow, then add complexity.\n\n#### Validation Rules\n\nRalph validates hat configurations:\n\n- **Required description**: Every hat must have a description (Ralph needs it for delegation context)\n- **Reserved triggers**: `task.start` and `task.resume` are reserved for Ralph\n- **No ambiguous routing**: Each trigger pattern must map to exactly one hat\n\n```\nERROR: Ambiguous routing for trigger 'build.done'.\nBoth 'planner' and 'reviewer' trigger on 'build.done'.\n```\n\n### Event Emission\n\nHats emit events to signal completion or hand off work:\n\n```bash\n# Simple event with payload\nralph emit \"build.done\" \"tests: pass, lint: pass\"\n\n# Event with JSON payload\nralph emit \"review.done\" --json '{\"status\": \"approved\", \"issues\": 0}'\n\n# Direct handoff to specific hat (bypasses routing)\nralph emit \"handoff\" --target reviewer \"Please review the changes\"\n```\n\n**In agent output**, events are embedded as XML tags:\n\n```xml\n<event topic=\"impl.done\">Implementation complete</event>\n<event topic=\"handoff\" target=\"reviewer\">Please review</event>\n```\n\n### Choosing a Pattern\n\n| Scenario | Recommended Pattern | Preset |\n|----------|---------------------|--------|\n| Sequential workflow with clear phases | Linear Pipeline | `tdd-red-green` |\n| Spec must be approved before coding | Contract-First | `spec-driven` |\n| Need multiple perspectives | Cyclic Rotation | `mob-programming` |\n| Security review required | Adversarial | `adversarial-review` |\n| Debugging complex issues | Hypothesis-Driven | `scientific-method` |\n| Work decomposes into specialist tasks | Coordinator-Specialist | `gap-analysis` |\n| Multiple input formats | Adaptive Entry | `code-assist` |\n| Standard feature development | Basic delegation | `feature` |\n\n### When Not to Use Hats\n\nHat-based orchestration adds complexity. Use **traditional mode** (no hats) when:\n\n- The task is straightforward and single-focused\n- You don't need role separation or handoffs\n- You're prototyping and want minimal configuration\n- The work doesn't naturally decompose into distinct phases\n\nTraditional mode is just Ralph in a loop until completion ‚Äî simpler, faster to set up, and often sufficient.\n\n### Memories and Tasks\n\nRalph uses two complementary systems for persistent state (both enabled by default):\n\n**Memories** (`.agent/memories.md`) ‚Äî Accumulated wisdom across sessions:\n- Codebase patterns and conventions discovered\n- Architectural decisions and rationale\n- Recurring problem solutions (fixes)\n- Project-specific context\n\n**Tasks** (`.agent/tasks.jsonl`) ‚Äî Runtime work tracking:\n- Create, list, and close tasks during orchestration\n- Track dependencies between tasks\n- Used for loop completion verification\n\nWhen memories and tasks are enabled, they replace the scratchpad for state management. Set `memories.enabled: false` and `tasks.enabled: false` to use the legacy scratchpad-only mode.\n\n### Scratchpad (Legacy Mode)\n\nWhen memories/tasks are disabled, all hats share `.agent/scratchpad.md` ‚Äî persistent memory across iterations. This enables hats to build on previous work rather than starting fresh.\n\nThe scratchpad is the primary mechanism for:\n- Task tracking (with `[ ]`, `[x]`, `[~]` markers)\n- Context preservation between iterations\n- Handoff between hats\n\n### Backpressure\n\nRalph enforces quality gates through backpressure. When a builder publishes `build.done`, it must include evidence:\n\n```\ntests: pass, lint: pass, typecheck: pass\n```\n\n## CLI Reference\n\n### Commands\n\n| Command | Description |\n|---------|-------------|\n| `ralph run` | Run the orchestration loop (default) |\n| `ralph resume` | Resume from existing scratchpad |\n| `ralph plan` | Start an interactive PDD planning session |\n| `ralph task` | Start an interactive code-task-generator session |\n| `ralph events` | View event history |\n| `ralph init` | Initialize configuration file |\n| `ralph clean` | Clean up `.agent/` directory |\n| `ralph emit` | Emit an event to the event log |\n| `ralph tools` | Runtime tools for memories and tasks (agent-facing) |\n\n### Global Options\n\n| Option | Description |\n|--------|-------------|\n| `-c, --config <FILE>` | Config file path (default: `ralph.yml`) |\n| `-v, --verbose` | Verbose output |\n| `--color <MODE>` | Color output: `auto`, `always`, `never` |\n\n### `ralph run` Options\n\n| Option | Description |\n|--------|-------------|\n| `-p, --prompt <TEXT>` | Inline prompt text |\n| `-P, --prompt-file <FILE>` | Prompt file path |\n| `--max-iterations <N>` | Override max iterations |\n| `--completion-promise <TEXT>` | Override completion trigger |\n| `--dry-run` | Show what would execute |\n| `--no-tui` | Disable TUI mode (TUI is enabled by default) |\n| `-a, --autonomous` | Force headless mode |\n| `--idle-timeout <SECS>` | TUI idle timeout (default: 30) |\n| `--record-session <FILE>` | Record session to JSONL |\n| `-q, --quiet` | Suppress output (for CI) |\n| `--continue` | Resume from existing scratchpad |\n\n### `ralph init` Options\n\n| Option | Description |\n|--------|-------------|\n| `--backend <NAME>` | Backend: `claude`, `kiro`, `gemini`, `codex`, `amp`, `copilot`, `opencode` |\n| `--preset <NAME>` | Use preset configuration |\n| `--list-presets` | List available presets |\n| `--force` | Overwrite existing config |\n\n### `ralph plan` Options\n\n| Option | Description |\n|--------|-------------|\n| `<IDEA>` | Optional rough idea to develop (SOP prompts if not provided) |\n| `-b, --backend <BACKEND>` | Backend to use (overrides config and auto-detection) |\n\n### `ralph task` Options\n\n| Option | Description |\n|--------|-------------|\n| `<INPUT>` | Optional description text or path to PDD plan file |\n| `-b, --backend <BACKEND>` | Backend to use (overrides config and auto-detection) |\n\n### `ralph tools` Subcommands\n\nThe `tools` command provides agent-facing utilities for runtime state management:\n\n```bash\n# Memory management (persistent learning)\nralph tools memory add \"content\" -t pattern --tags tag1,tag2\nralph tools memory search \"query\"\nralph tools memory list\nralph tools memory show <id>\nralph tools memory delete <id>\n\n# Task management (runtime tracking)\nralph tools task add \"Title\" -p 2              # Create task (priority 1-5)\nralph tools task add \"X\" --blocked-by Y        # With dependency\nralph tools task list                           # All tasks\nralph tools task ready                          # Unblocked tasks only\nralph tools task close <id>                     # Mark complete\n```\n\n## Architecture\n\nRalph is organized as a Cargo workspace with seven crates:\n\n| Crate | Purpose |\n|-------|---------|\n| `ralph-proto` | Protocol types: Event, Hat, Topic, Error |\n| `ralph-core` | Business logic: EventLoop, HatRegistry, Config |\n| `ralph-adapters` | CLI backend integrations (Claude, Kiro, Gemini, etc.) |\n| `ralph-tui` | Terminal UI with ratatui |\n| `ralph-cli` | Binary entry point and CLI parsing |\n| `ralph-e2e` | End-to-end test harness for backend validation |\n| `ralph-bench` | Benchmarking harness (dev-only) |\n\n## Building & Testing\n\n### Build\n\n```bash\ncargo build           # Debug build\ncargo build --release # Release build\n```\n\n### Test\n\n```bash\n# Run all tests (includes smoke tests with JSONL replay)\ncargo test\n\n# Run smoke tests specifically\ncargo test -p ralph-core smoke_runner\n\n# Run Kiro-specific smoke tests\ncargo test -p ralph-core kiro\n```\n\n### Smoke Tests\n\nSmoke tests use recorded JSONL fixtures instead of live API calls ‚Äî fast, free, and deterministic.\n\n**Fixture locations:**\n- `crates/ralph-core/tests/fixtures/basic_session.jsonl` ‚Äî Claude CLI session\n- `crates/ralph-core/tests/fixtures/kiro/` ‚Äî Kiro CLI sessions\n\n**Recording new fixtures:**\n\n```bash\n# Record a session\nralph run -c ralph.yml --record-session session.jsonl -p \"your prompt\"\n\n# Or capture raw CLI output\nclaude -p \"your prompt\" 2>&1 | tee output.txt\n```\n\n### Linting\n\n```bash\ncargo clippy --all-targets --all-features\ncargo fmt --check\n```\n\n## Contributing\n\nContributions are welcome! Please:\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Write tests for new functionality\n4. Ensure `cargo test` passes\n5. Run `cargo clippy` and `cargo fmt`\n6. Commit your changes (`git commit -m 'Add amazing feature'`)\n7. Push to the branch (`git push origin feature/amazing-feature`)\n8. Open a Pull Request\n\nSee [AGENTS.md](AGENTS.md) for development philosophy and conventions.\n\n## License\n\nMIT License ‚Äî See [LICENSE](LICENSE) for details.\n\n## Acknowledgments\n\n- **[Geoffrey Huntley](https://ghuntley.com/ralph/)** ‚Äî Creator of the Ralph Wiggum technique\n- **[Harper Reed](https://harper.blog/)** ‚Äî Spec-driven development methodology\n- **[Strands Agent SOPs](https://github.com/strands-agents/agent-sop)** ‚Äî Natural language workflows that enable AI agents to perform complex, multi-step tasks with consistency and reliability. \n- **[ratatui](https://ratatui.rs/)** ‚Äî Terminal UI framework\n- **[portable-pty](https://crates.io/crates/portable-pty)** ‚Äî Cross-platform PTY support\n\n---\n\n*\"I'm learnding!\" - Ralph Wiggum*\n\n---\n\n[![Star History Chart](https://api.star-history.com/svg?repos=mikeyobrien/ralph-orchestrator&type=date&legend=top-left)](https://www.star-history.com/#mikeyobrien/ralph-orchestrator&type=date&legend=top-left)\n",
      "stars_today": 57
    },
    {
      "id": 709589487,
      "name": "awesome-system-design-resources",
      "full_name": "ashishps1/awesome-system-design-resources",
      "description": "Learn System Design concepts and prepare for interviews using free resources.",
      "html_url": "https://github.com/ashishps1/awesome-system-design-resources",
      "stars": 29263,
      "forks": 6714,
      "language": "Java",
      "topics": [
        "awesome",
        "backend",
        "computer-science",
        "distributed-systems",
        "high-level-design",
        "hld",
        "interview",
        "interview-questions",
        "scalability",
        "system-design"
      ],
      "created_at": "2023-10-25T01:50:42Z",
      "updated_at": "2026-01-23T23:34:54Z",
      "pushed_at": "2026-01-11T14:54:34Z",
      "open_issues": 7,
      "owner": {
        "login": "ashishps1",
        "avatar_url": "https://avatars.githubusercontent.com/u/8646889?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"diagrams/system-design-github-logo.png\" width=\"350\" height=\"200\">\n</p>\n\nThis repository contains free resources to learn System Design concepts and prepare for interviews.\n\nüëâ Subscribe to my [AlgoMaster Newsletter](https://bit.ly/amghsd) and get a **FREE System Design Interview Handbook** in your inbox.\n\n‚úÖ If you are new to System Design, start here: [System Design was HARD until I Learned these 30 Concepts](https://blog.algomaster.io/p/30-system-design-concepts)\n\n## ‚öôÔ∏è Core Concepts\n- [Scalability](https://algomaster.io/learn/system-design/scalability)\n- [Availability](https://algomaster.io/learn/system-design/availability)\n- [Reliability](https://algomaster.io/learn/system-design/reliability)\n- [CAP Theorem](https://blog.algomaster.io/p/cap-theorem-explained)\n- [Consistent Hashing](https://blog.algomaster.io/p/consistent-hashing-explained)\n- [SPOF](https://blog.algomaster.io/p/system-design-how-to-avoid-single-point-of-failures)\n- [Failover](https://www.druva.com/glossary/what-is-a-failover-definition-and-related-faqs)\n- [Fault Tolerance](https://www.cockroachlabs.com/blog/what-is-fault-tolerance/)\n\n## üåê Networking Fundamentals\n- [OSI Model](https://algomaster.io/learn/system-design/osi)\n- [IP Addresses](https://algomaster.io/learn/system-design/ip-address)\n- [Domain Name System (DNS)](https://blog.algomaster.io/p/how-dns-actually-works)\n- [Proxy vs Reverse Proxy](https://blog.algomaster.io/p/proxy-vs-reverse-proxy-explained)\n- [HTTP/HTTPS](https://algomaster.io/learn/system-design/http-https)\n- [TCP vs UDP](https://algomaster.io/learn/system-design/tcp-vs-udp)\n- [Load Balancing](https://blog.algomaster.io/p/load-balancing-algorithms-explained-with-code)\n- [Checksums](https://algomaster.io/learn/system-design/checksums)\n\n## üîå API Fundamentals\n- [APIs](https://algomaster.io/learn/system-design/what-is-an-api)\n- [API Gateway](https://blog.algomaster.io/p/what-is-an-api-gateway)\n- [REST vs GraphQL](https://blog.algomaster.io/p/rest-vs-graphql)\n- [WebSockets](https://blog.algomaster.io/p/websockets)\n- [Webhooks](https://algomaster.io/learn/system-design/webhooks)\n- [Idempotency](https://algomaster.io/learn/system-design/idempotency)\n- [Rate limiting](https://blog.algomaster.io/p/rate-limiting-algorithms-explained-with-code)\n- [API Design](https://abdulrwahab.medium.com/api-architecture-best-practices-for-designing-rest-apis-bf907025f5f)\n\n## üóÑÔ∏è Database Fundamentals\n- [ACID Transactions](https://algomaster.io/learn/system-design/acid-transactions)\n- [SQL vs NoSQL](https://algomaster.io/learn/system-design/sql-vs-nosql)\n- [Database Indexes](https://algomaster.io/learn/system-design/indexing)\n- [Database Sharding](https://algomaster.io/learn/system-design/sharding)\n- [Data Replication](https://redis.com/blog/what-is-data-replication/)\n- [Database Scaling](https://blog.algomaster.io/p/system-design-how-to-scale-a-database)\n- [Databases Types](https://blog.algomaster.io/p/15-types-of-databases)\n- [Bloom Filters](https://algomaster.io/learn/system-design/bloom-filters)\n- [Database Architectures](https://www.mongodb.com/developer/products/mongodb/active-active-application-architectures/)\n\n## ‚ö° Caching Fundamentals\n- [Caching 101](https://algomaster.io/learn/system-design/what-is-caching)\n- [Caching Strategies](https://algomaster.io/learn/system-design/caching-strategies)\n- [Cache Eviction Policies](https://blog.algomaster.io/p/7-cache-eviction-strategies)\n- [Distributed Caching](https://blog.algomaster.io/p/distributed-caching)\n- [Content Delivery Network (CDN)](https://algomaster.io/learn/system-design/content-delivery-network-cdn)\n\n## üîÑ Asynchronous Communication\n- [Pub/Sub](https://algomaster.io/learn/system-design/pub-sub)\n- [Message Queues](https://algomaster.io/learn/system-design/message-queues)\n- [Change Data Capture (CDC)](https://algomaster.io/learn/system-design/change-data-capture-cdc)\n\n## üß© Distributed System and Microservices\n- [HeartBeats](https://blog.algomaster.io/p/heartbeats-in-distributed-systems)\n- [Service Discovery](https://blog.algomaster.io/p/service-discovery-in-distributed-systems)\n- [Consensus Algorithms](https://medium.com/@sourabhatta1819/consensus-in-distributed-system-ac79f8ba2b8c)\n- [Distributed Locking](https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html)\n- [Microservices Guidelines](https://newsletter.systemdesign.one/p/netflix-microservices) \n- [Gossip Protocol](http://highscalability.com/blog/2023/7/16/gossip-protocol-explained.html)\n- [Circuit Breaker](https://medium.com/geekculture/design-patterns-for-microservices-circuit-breaker-pattern-276249ffab33)\n- [Disaster Recovery](https://cloud.google.com/learn/what-is-disaster-recovery)\n- [Distributed Tracing](https://www.dynatrace.com/news/blog/what-is-distributed-tracing/)\n\n## üñáÔ∏è Architectural Patterns\n- [Client-Server Architecture](https://algomaster.io/learn/system-design/client-server-architecture)\n- [Microservices Architecture](https://medium.com/hashmapinc/the-what-why-and-how-of-a-microservices-architecture-4179579423a9)\n- [Serverless Architecture](https://blog.algomaster.io/p/2edeb23b-cfa5-4b24-845e-3f6f7a39d162)\n- [Event-Driven Architecture](https://www.confluent.io/learn/event-driven-architecture/)\n- [Peer-to-Peer (P2P) Architecture](https://www.spiceworks.com/tech/networking/articles/what-is-peer-to-peer/)\n\n## ‚öñÔ∏è System Design Tradeoffs\n- [Top 15 Tradeoffs](https://blog.algomaster.io/p/system-design-top-15-trade-offs)\n- [Vertical vs Horizontal Scaling](https://algomaster.io/learn/system-design/vertical-vs-horizontal-scaling)\n- [Concurrency vs Parallelism](https://blog.algomaster.io/p/concurrency-vs-parallelism)\n- [Long Polling vs WebSockets](https://blog.algomaster.io/p/long-polling-vs-websockets)\n- [Batch vs Stream Processing](https://blog.algomaster.io/p/batch-processing-vs-stream-processing)\n- [Stateful vs Stateless Design](https://blog.algomaster.io/p/stateful-vs-stateless-architecture)\n- [Strong vs Eventual Consistency](https://blog.algomaster.io/p/strong-vs-eventual-consistency)\n- [Read-Through vs Write-Through Cache](https://blog.algomaster.io/p/59cae60d-9717-4e20-a59e-759e370db4e5)\n- [Push vs Pull Architecture](https://blog.algomaster.io/p/af5fe2fe-9a4f-4708-af43-184945a243af)\n- [REST vs RPC](https://blog.algomaster.io/p/106604fb-b746-41de-88fb-60e932b2ff68)\n- [Synchronous vs. asynchronous communications](https://blog.algomaster.io/p/aec1cebf-6060-45a7-8e00-47364ca70761)\n- [Latency vs Throughput](https://aws.amazon.com/compare/the-difference-between-throughput-and-latency/)\n\n## ‚úÖ [How to Answer a System Design Interview Problem](https://algomaster.io/learn/system-design-interviews/answering-framework)\n\n## üíª System Design Interview Problems\n### Easy\n- [Design URL Shortener like TinyURL](https://algomaster.io/learn/system-design-interviews/design-url-shortener)\n- [Design Autocomplete for Search Engines](https://algomaster.io/learn/system-design-interviews/design-instagram)\n- [Design Load Balancer](https://algomaster.io/learn/system-design-interviews/design-load-balancer)\n- [Design Content Delivery Network (CDN)](https://www.youtube.com/watch?v=8zX0rue2Hic)\n- [Design Parking Garage](https://www.youtube.com/watch?v=NtMvNh0WFVM)\n- [Design Vending Machine](https://www.youtube.com/watch?v=D0kDMUgo27c)\n- [Design Distributed Key-Value Store](https://www.youtube.com/watch?v=rnZmdmlR-2M)\n- [Design Distributed Cache](https://www.youtube.com/watch?v=iuqZvajTOyA)\n- [Design Authentication System](https://www.youtube.com/watch?v=uj_4vxm9u90)\n- [Design Unified Payments Interface (UPI)](https://www.youtube.com/watch?v=QpLy0_c_RXk)\n### Medium\n- [Design WhatsApp](https://algomaster.io/learn/system-design-interviews/design-whatsapp)\n- [Design Spotify](https://algomaster.io/learn/system-design-interviews/design-spotify)\n- [Design Instagram](https://algomaster.io/learn/system-design-interviews/design-instagram)\n- [Design Notification Service](https://algomaster.io/learn/system-design-interviews/design-notification-service)\n- [Design Distributed Job Scheduler](https://blog.algomaster.io/p/design-a-distributed-job-scheduler)\n- [Design Tinder](https://www.youtube.com/watch?v=tndzLznxq40)\n- [Design Facebook](https://www.youtube.com/watch?v=9-hjBGxuiEs)\n- [Design Twitter](https://www.youtube.com/watch?v=wYk0xPP_P_8)\n- [Design Reddit](https://www.youtube.com/watch?v=KYExYE_9nIY)\n- [Design Netflix](https://www.youtube.com/watch?v=psQzyFfsUGU)\n- [Design Youtube](https://www.youtube.com/watch?v=jPKTo1iGQiE)\n- [Design Google Search](https://www.youtube.com/watch?v=CeGtqouT8eA)\n- [Design E-commerce Store like Amazon](https://www.youtube.com/watch?v=EpASu_1dUdE)\n- [Design TikTok](https://www.youtube.com/watch?v=Z-0g_aJL5Fw)\n- [Design Shopify](https://www.youtube.com/watch?v=lEL4F_0J3l8)\n- [Design Airbnb](https://www.youtube.com/watch?v=YyOXt2MEkv4)\n- [Design Rate Limiter](https://www.youtube.com/watch?v=mhUQe4BKZXs)\n- [Design Distributed Message Queue like Kafka](https://www.youtube.com/watch?v=iJLL-KPqBpM)\n- [Design Flight Booking System](https://www.youtube.com/watch?v=qsGcfVGvFSs)\n- [Design Online Code Editor](https://www.youtube.com/watch?v=07jkn4jUtso)\n- [Design an Analytics Platform (Metrics & Logging)](https://www.youtube.com/watch?v=kIcq1_pBQSY)\n- [Design Payment System](https://www.youtube.com/watch?v=olfaBgJrUBI)\n- [Design a Digital Wallet](https://www.youtube.com/watch?v=4ijjIUeq6hE)\n### Hard\n- [Design Location Based Service like Yelp](https://www.youtube.com/watch?v=M4lR_Va97cQ)\n- [Design Uber](https://www.youtube.com/watch?v=umWABit-wbk)\n- [Design Food Delivery App like Doordash](https://www.youtube.com/watch?v=iRhSAR3ldTw)\n- [Design Google Docs](https://www.youtube.com/watch?v=2auwirNBvGg)\n- [Design Google Maps](https://www.youtube.com/watch?v=jk3yvVfNvds)\n- [Design Zoom](https://www.youtube.com/watch?v=G32ThJakeHk)\n- [Design Distributed Counter](https://systemdesign.one/distributed-counter-system-design/)\n- [Design File Sharing System like Dropbox](https://www.youtube.com/watch?v=U0xTu6E2CT8)\n- [Design Ticket Booking System like BookMyShow](https://www.youtube.com/watch?v=lBAwJgoO3Ek)\n- [Design Distributed Web Crawler](https://www.youtube.com/watch?v=BKZxZwUgL3Y)\n- [Design Code Deployment System](https://www.youtube.com/watch?v=q0KGYwNbf-0)\n- [Design Distributed Cloud Storage like S3](https://www.youtube.com/watch?v=UmWtcgC96X8)\n- [Design Distributed Locking Service](https://www.youtube.com/watch?v=v7x75aN9liM)\n- [Design Slack](https://systemdesign.one/slack-architecture/)\n- [Design Live Comments](https://systemdesign.one/live-comment-system-design/)\n\n## üìá Courses\n- [System Design Fundamentals](https://algomaster.io/learn/system-design/course-introduction)\n- [System Design Interviews](https://algomaster.io/learn/system-design-interviews/introduction)\n\n## üì© Newsletters\n- [AlgoMaster Newsletter](https://blog.algomaster.io/)\n\n## üìö Books\n- [Designing Data-Intensive Applications](https://www.amazon.in/dp/9352135245)\n\n## üì∫ YouTube Channels\n- [Tech Dummies Narendra L](https://www.youtube.com/@TechDummiesNarendraL)\n- [Gaurav Sen](https://www.youtube.com/@gkcs)\n- [codeKarle](https://www.youtube.com/@codeKarle)\n- [ByteByteGo](https://www.youtube.com/@ByteByteGo)\n- [System Design Interview](https://www.youtube.com/@SystemDesignInterview)\n- [sudoCODE](https://www.youtube.com/@sudocode)\n- [Success in Tech](https://www.youtube.com/@SuccessinTech/videos)\n\n## üìú Must-Read Engineering Articles\n- [How Discord stores trillions of messages](https://discord.com/blog/how-discord-stores-trillions-of-messages)\n- [Building In-Video Search at Netflix](https://netflixtechblog.com/building-in-video-search-936766f0017c)\n- [How Canva scaled Media uploads from Zero to 50 Million per Day](https://www.canva.dev/blog/engineering/from-zero-to-50-million-uploads-per-day-scaling-media-at-canva/)\n- [How Airbnb avoids double payments in a Distributed Payments System](https://medium.com/airbnb-engineering/avoiding-double-payments-in-a-distributed-payments-system-2981f6b070bb)\n- [Stripe‚Äôs payments APIs - The first 10 years](https://stripe.com/blog/payment-api-design)\n- [Real time messaging at Slack](https://slack.engineering/real-time-messaging/)\n\n## üóûÔ∏è Must-Read Distributed Systems Papers\n- [Paxos: The Part-Time Parliament](https://lamport.azurewebsites.net/pubs/lamport-paxos.pdf)\n- [MapReduce: Simplified Data Processing on Large Clusters](https://research.google.com/archive/mapreduce-osdi04.pdf)\n- [The Google File System](https://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf)\n- [Dynamo: Amazon‚Äôs Highly Available Key-value Store](https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf)\n- [Kafka: a Distributed Messaging System for Log Processing](https://notes.stephenholiday.com/Kafka.pdf)\n- [Spanner: Google‚Äôs Globally-Distributed Database](https://static.googleusercontent.com/media/research.google.com/en//archive/spanner-osdi2012.pdf)\n- [Bigtable: A Distributed Storage System for Structured Data](https://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf)\n- [ZooKeeper: Wait-free coordination for Internet-scale systems](https://www.usenix.org/legacy/event/usenix10/tech/full_papers/Hunt.pdf)\n- [The Log-Structured Merge-Tree (LSM-Tree)](https://www.cs.umb.edu/~poneil/lsmtree.pdf)\n- [The Chubby lock service for loosely-coupled distributed systems](https://static.googleusercontent.com/media/research.google.com/en//archive/chubby-osdi06.pdf)\n\n---\n\n<p align=\"center\">\n  <i>If you find this resource helpful, please give it a star ‚≠êÔ∏è and share it with others!</i>\n</p>\n",
      "stars_today": 54
    },
    {
      "id": 120156076,
      "name": "cloudreve",
      "full_name": "cloudreve/cloudreve",
      "description": "üå© Self-hosted file management and sharing system, supports multiple storage providers",
      "html_url": "https://github.com/cloudreve/cloudreve",
      "stars": 26717,
      "forks": 3786,
      "language": "Go",
      "topics": [
        "cloud",
        "cloud-storage",
        "cloudreve",
        "file",
        "file-manager",
        "file-sharing",
        "golang"
      ],
      "created_at": "2018-02-04T04:56:38Z",
      "updated_at": "2026-01-24T02:06:40Z",
      "pushed_at": "2026-01-23T07:32:10Z",
      "open_issues": 240,
      "owner": {
        "login": "cloudreve",
        "avatar_url": "https://avatars.githubusercontent.com/u/48898462?v=4"
      },
      "readme": "[‰∏≠ÊñáÁâàÊú¨](https://github.com/cloudreve/cloudreve/blob/master/README_zh-CN.md)\n\n<h1 align=\"center\">\n  <br>\n  <a href=\"https://cloudreve.org/\" alt=\"logo\" ><img src=\"https://raw.githubusercontent.com/cloudreve/frontend/master/public/static/img/logo192.png\" width=\"150\"/></a>\n  <br>\n  Cloudreve\n  <br>\n</h1>\n<h4 align=\"center\">Self-hosted file management system with multi-cloud support.</h4>\n\n<p align=\"center\">\n  <a href=\"https://dev.azure.com/abslantliu/cloudreve/_build?definitionId=6\">\n    <img src=\"https://img.shields.io/github/check-runs/cloudreve/cloudreve/master\"\n         alt=\"Azure pipelines\">\n  </a>\n  <a href=\"https://github.com/cloudreve/cloudreve/releases\">\n    <img src=\"https://img.shields.io/github/v/release/cloudreve/cloudreve?include_prereleases\" />\n  </a>\n  <a href=\"https://github.com/cloudreve/cloudreve/releases\">\n     <img src=\"https://badgen.net/static/release%20size/34%20MB/blue\"/>\n  </a>\n  <a href=\"https://hub.docker.com/r/cloudreve/cloudreve\">\n  <img alt=\"Docker Pulls\" src=\"https://img.shields.io/docker/pulls/cloudreve/cloudreve\" />\n  </a>\n</p>\n<p align=\"center\">\n  <a href=\"https://cloudreve.org\">Homepage</a> ‚Ä¢\n  <a href=\"https://demo.cloudreve.org\">Try it</a> ‚Ä¢\n  <a href=\"https://github.com/cloudreve/cloudreve/discussions\">Discussion</a> ‚Ä¢\n  <a href=\"https://docs.cloudreve.org\">Documents</a> ‚Ä¢\n  <a href=\"https://github.com/cloudreve/cloudreve/releases\">Download</a> ‚Ä¢\n  <a href=\"https://t.me/cloudreve_official\">Telegram</a> ‚Ä¢\n  <a href=\"https://discord.com/invite/WTpMFpZT76\">Discord</a>\n</p>\n\n![Screenshot](https://raw.githubusercontent.com/cloudreve/docs/master/images/homepage.png)\n\n## :sparkles: Features\n\n- :cloud: Support storing files into Local, Remote node, OneDrive, S3 compatible API, Qiniu Kodo, Aliyun OSS, Tencent COS, Huawei Cloud OBS, Kingsoft Cloud KS3, Upyun.\n- :outbox_tray: Upload/Download in directly transmission from client to storage providers.\n- üíæ Integrate with Aria2/qBittorrent to download files in background, use multiple download nodes to share the load.\n- üìö Compress/Extract/Preview archived files, download files in batch.\n- üíª WebDAV support covering all storage providers.\n- :zap:Drag&Drop to upload files or folders, with parallel resumable upload support.\n- :card_file_box: Extract media metadata from files, search files by metadata or tags.\n- :family_woman_girl_boy: Multi-users with multi-groups.\n- :link: Create share links for files and folders with expiration date.\n- :eye_speech_bubble: Preview videos, images, audios, ePub files online; edit texts, diagrams, Markdown, images, Office documents online.\n- :art: Customize theme colors, dark mode, PWA application, SPA, i18n.\n- :rocket: All-in-one packaging, with all features out of the box.\n- üåà ... ...\n\n## :hammer_and_wrench: Deploy\n\nTo deploy Cloudreve, you can refer to [Getting started](https://docs.cloudreve.org/overview/quickstart) for a quick local deployment to test.\n\nWhen you're ready to deploy Cloudreve to a production environment, you can refer to [Deploy](https://docs.cloudreve.org/overview/deploy/) for a complete deployment.\n\n## :gear: Build\n\nPlease refer to [Build](https://docs.cloudreve.org/overview/build/) for how to build Cloudreve from source code.\n\n## :rocket: Contributing\n\nIf you're interested in contributing to Cloudreve, please refer to [Contributing](https://docs.cloudreve.org/api/contributing/) for how to contribute to Cloudreve.\n\n## :alembic: Stacks\n\n- [Go](https://golang.org/) + [Gin](https://github.com/gin-gonic/gin) + [ent](https://github.com/ent/ent)\n- [React](https://github.com/facebook/react) + [Redux](https://github.com/reduxjs/redux) + [Material-UI](https://github.com/mui-org/material-ui)\n\n## :scroll: License\n\nGPL V3\n",
      "stars_today": 52
    },
    {
      "id": 942771284,
      "name": "github-mcp-server",
      "full_name": "github/github-mcp-server",
      "description": "GitHub's official MCP Server",
      "html_url": "https://github.com/github/github-mcp-server",
      "stars": 26231,
      "forks": 3437,
      "language": "Go",
      "topics": [
        "github",
        "mcp",
        "mcp-server"
      ],
      "created_at": "2025-03-04T16:42:04Z",
      "updated_at": "2026-01-24T02:05:10Z",
      "pushed_at": "2026-01-23T16:36:50Z",
      "open_issues": 258,
      "owner": {
        "login": "github",
        "avatar_url": "https://avatars.githubusercontent.com/u/9919?v=4"
      },
      "readme": "[![Go Report Card](https://goreportcard.com/badge/github.com/github/github-mcp-server)](https://goreportcard.com/report/github.com/github/github-mcp-server)\n\n# GitHub MCP Server\n\nThe GitHub MCP Server connects AI tools directly to GitHub's platform. This gives AI agents, assistants, and chatbots the ability to read repositories and code files, manage issues and PRs, analyze code, and automate workflows. All through natural language interactions.\n\n### Use Cases\n\n- Repository Management: Browse and query code, search files, analyze commits, and understand project structure across any repository you have access to.\n- Issue & PR Automation: Create, update, and manage issues and pull requests. Let AI help triage bugs, review code changes, and maintain project boards.\n- CI/CD & Workflow Intelligence: Monitor GitHub Actions workflow runs, analyze build failures, manage releases, and get insights into your development pipeline.\n- Code Analysis: Examine security findings, review Dependabot alerts, understand code patterns, and get comprehensive insights into your codebase.\n- Team Collaboration: Access discussions, manage notifications, analyze team activity, and streamline processes for your team.\n\nBuilt for developers who want to connect their AI tools to GitHub context and capabilities, from simple natural language queries to complex multi-step agent workflows.\n\n---\n\n## Remote GitHub MCP Server\n\n[![Install in VS Code](https://img.shields.io/badge/VS_Code-Install_Server-0098FF?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&config=%7B%22type%22%3A%20%22http%22%2C%22url%22%3A%20%22https%3A%2F%2Fapi.githubcopilot.com%2Fmcp%2F%22%7D) [![Install in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_Server-24bfa5?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&config=%7B%22type%22%3A%20%22http%22%2C%22url%22%3A%20%22https%3A%2F%2Fapi.githubcopilot.com%2Fmcp%2F%22%7D&quality=insiders)\n\nThe remote GitHub MCP Server is hosted by GitHub and provides the easiest method for getting up and running. If your MCP host does not support remote MCP servers, don't worry! You can use the [local version of the GitHub MCP Server](https://github.com/github/github-mcp-server?tab=readme-ov-file#local-github-mcp-server) instead.\n\n### Prerequisites\n\n1. A compatible MCP host with remote server support (VS Code 1.101+, Claude Desktop, Cursor, Windsurf, etc.)\n2. Any applicable [policies enabled](https://github.com/github/github-mcp-server/blob/main/docs/policies-and-governance.md)\n\n### Install in VS Code\n\nFor quick installation, use one of the one-click install buttons above. Once you complete that flow, toggle Agent mode (located by the Copilot Chat text input) and the server will start. Make sure you're using [VS Code 1.101](https://code.visualstudio.com/updates/v1_101) or [later](https://code.visualstudio.com/updates) for remote MCP and OAuth support.\n\nAlternatively, to manually configure VS Code, choose the appropriate JSON block from the examples below and add it to your host configuration:\n\n<table>\n<tr><th>Using OAuth</th><th>Using a GitHub PAT</th></tr>\n<tr><th align=left colspan=2>VS Code (version 1.101 or greater)</th></tr>\n<tr valign=top>\n<td>\n\n```json\n{\n  \"servers\": {\n    \"github\": {\n      \"type\": \"http\",\n      \"url\": \"https://api.githubcopilot.com/mcp/\"\n    }\n  }\n}\n```\n\n</td>\n<td>\n\n```json\n{\n  \"servers\": {\n    \"github\": {\n      \"type\": \"http\",\n      \"url\": \"https://api.githubcopilot.com/mcp/\",\n      \"headers\": {\n        \"Authorization\": \"Bearer ${input:github_mcp_pat}\"\n      }\n    }\n  },\n  \"inputs\": [\n    {\n      \"type\": \"promptString\",\n      \"id\": \"github_mcp_pat\",\n      \"description\": \"GitHub Personal Access Token\",\n      \"password\": true\n    }\n  ]\n}\n```\n\n</td>\n</tr>\n</table>\n\n### Install in other MCP hosts\n\n- **[GitHub Copilot in other IDEs](/docs/installation-guides/install-other-copilot-ides.md)** - Installation for JetBrains, Visual Studio, Eclipse, and Xcode with GitHub Copilot\n- **[Claude Applications](/docs/installation-guides/install-claude.md)** - Installation guide for Claude Desktop and Claude Code CLI\n- **[Codex](/docs/installation-guides/install-codex.md)** - Installation guide for Open AI Codex\n- **[Cursor](/docs/installation-guides/install-cursor.md)** - Installation guide for Cursor IDE\n- **[Windsurf](/docs/installation-guides/install-windsurf.md)** - Installation guide for Windsurf IDE\n- **[Rovo Dev CLI](/docs/installation-guides/install-rovo-dev-cli.md)** - Installation guide for Rovo Dev CLI\n\n> **Note:** Each MCP host application needs to configure a GitHub App or OAuth App to support remote access via OAuth. Any host application that supports remote MCP servers should support the remote GitHub server with PAT authentication. Configuration details and support levels vary by host. Make sure to refer to the host application's documentation for more info.\n\n### Configuration\n\n#### Toolset configuration\n\nSee [Remote Server Documentation](docs/remote-server.md) for full details on remote server configuration, toolsets, headers, and advanced usage. This file provides comprehensive instructions and examples for connecting, customizing, and installing the remote GitHub MCP Server in VS Code and other MCP hosts.\n\nWhen no toolsets are specified, [default toolsets](#default-toolset) are used.\n\n#### Insiders Mode\n\n> **Try new features early!** The remote server offers an insiders version with early access to new features and experimental tools.\n\n<table>\n<tr><th>Using URL Path</th><th>Using Header</th></tr>\n<tr valign=top>\n<td>\n\n```json\n{\n  \"servers\": {\n    \"github\": {\n      \"type\": \"http\",\n      \"url\": \"https://api.githubcopilot.com/mcp/insiders\"\n    }\n  }\n}\n```\n\n</td>\n<td>\n\n```json\n{\n  \"servers\": {\n    \"github\": {\n      \"type\": \"http\",\n      \"url\": \"https://api.githubcopilot.com/mcp/\",\n      \"headers\": {\n        \"X-MCP-Insiders\": \"true\"\n      }\n    }\n  }\n}\n```\n\n</td>\n</tr>\n</table>\n\nSee [Remote Server Documentation](docs/remote-server.md#insiders-mode) for more details and examples.\n\n#### GitHub Enterprise\n\n##### GitHub Enterprise Cloud with data residency (ghe.com)\n\nGitHub Enterprise Cloud can also make use of the remote server.\n\nExample for `https://octocorp.ghe.com` with GitHub PAT token:\n\n```\n{\n    ...\n    \"proxima-github\": {\n      \"type\": \"http\",\n      \"url\": \"https://copilot-api.octocorp.ghe.com/mcp\",\n      \"headers\": {\n        \"Authorization\": \"Bearer ${input:github_mcp_pat}\"\n      }\n    },\n    ...\n}\n```\n\n> **Note:** When using OAuth with GitHub Enterprise with VS Code and GitHub Copilot, you also need to configure your VS Code settings to point to your GitHub Enterprise instance - see [Authenticate from VS Code](https://docs.github.com/en/enterprise-cloud@latest/copilot/how-tos/configure-personal-settings/authenticate-to-ghecom)\n\n##### GitHub Enterprise Server\n\nGitHub Enterprise Server does not support remote server hosting. Please refer to [GitHub Enterprise Server and Enterprise Cloud with data residency (ghe.com)](#github-enterprise-server-and-enterprise-cloud-with-data-residency-ghecom) from the local server configuration.\n\n---\n\n## Local GitHub MCP Server\n\n[![Install with Docker in VS Code](https://img.shields.io/badge/VS_Code-Install_Server-0098FF?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&inputs=%5B%7B%22id%22%3A%22github_token%22%2C%22type%22%3A%22promptString%22%2C%22description%22%3A%22GitHub%20Personal%20Access%20Token%22%2C%22password%22%3Atrue%7D%5D&config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%22-e%22%2C%22GITHUB_PERSONAL_ACCESS_TOKEN%22%2C%22ghcr.io%2Fgithub%2Fgithub-mcp-server%22%5D%2C%22env%22%3A%7B%22GITHUB_PERSONAL_ACCESS_TOKEN%22%3A%22%24%7Binput%3Agithub_token%7D%22%7D%7D) [![Install with Docker in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_Server-24bfa5?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&inputs=%5B%7B%22id%22%3A%22github_token%22%2C%22type%22%3A%22promptString%22%2C%22description%22%3A%22GitHub%20Personal%20Access%20Token%22%2C%22password%22%3Atrue%7D%5D&config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%22-e%22%2C%22GITHUB_PERSONAL_ACCESS_TOKEN%22%2C%22ghcr.io%2Fgithub%2Fgithub-mcp-server%22%5D%2C%22env%22%3A%7B%22GITHUB_PERSONAL_ACCESS_TOKEN%22%3A%22%24%7Binput%3Agithub_token%7D%22%7D%7D&quality=insiders)\n\n### Prerequisites\n\n1. To run the server in a container, you will need to have [Docker](https://www.docker.com/) installed.\n2. Once Docker is installed, you will also need to ensure Docker is running. The Docker image is available at `ghcr.io/github/github-mcp-server`. The image is public; if you get errors on pull, you may have an expired token and need to `docker logout ghcr.io`.\n3. Lastly you will need to [Create a GitHub Personal Access Token](https://github.com/settings/personal-access-tokens/new).\nThe MCP server can use many of the GitHub APIs, so enable the permissions that you feel comfortable granting your AI tools (to learn more about access tokens, please check out the [documentation](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens)).\n\n<details><summary><b>Handling PATs Securely</b></summary>\n\n### Environment Variables (Recommended)\n\nTo keep your GitHub PAT secure and reusable across different MCP hosts:\n\n1. **Store your PAT in environment variables**\n\n   ```bash\n   export GITHUB_PAT=your_token_here\n   ```\n\n   Or create a `.env` file:\n\n   ```env\n   GITHUB_PAT=your_token_here\n   ```\n\n2. **Protect your `.env` file**\n\n   ```bash\n   # Add to .gitignore to prevent accidental commits\n   echo \".env\" >> .gitignore\n   ```\n\n3. **Reference the token in configurations**\n\n   ```bash\n   # CLI usage\n   claude mcp update github -e GITHUB_PERSONAL_ACCESS_TOKEN=$GITHUB_PAT\n\n   # In config files (where supported)\n   \"env\": {\n     \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"$GITHUB_PAT\"\n   }\n   ```\n\n> **Note**: Environment variable support varies by host app and IDE. Some applications (like Windsurf) require hardcoded tokens in config files.\n\n### Token Security Best Practices\n\n- **Minimum scopes**: Only grant necessary permissions\n  - `repo` - Repository operations\n  - `read:packages` - Docker image access\n  - `read:org` - Organization team access\n- **Separate tokens**: Use different PATs for different projects/environments\n- **Regular rotation**: Update tokens periodically\n- **Never commit**: Keep tokens out of version control\n- **File permissions**: Restrict access to config files containing tokens\n\n  ```bash\n  chmod 600 ~/.your-app/config.json\n  ```\n\n</details>\n\n### GitHub Enterprise Server and Enterprise Cloud with data residency (ghe.com)\n\nThe flag `--gh-host` and the environment variable `GITHUB_HOST` can be used to set\nthe hostname for GitHub Enterprise Server or GitHub Enterprise Cloud with data residency.\n\n- For GitHub Enterprise Server, prefix the hostname with the `https://` URI scheme, as it otherwise defaults to `http://`, which GitHub Enterprise Server does not support.\n- For GitHub Enterprise Cloud with data residency, use `https://YOURSUBDOMAIN.ghe.com` as the hostname.\n\n``` json\n\"github\": {\n    \"command\": \"docker\",\n    \"args\": [\n    \"run\",\n    \"-i\",\n    \"--rm\",\n    \"-e\",\n    \"GITHUB_PERSONAL_ACCESS_TOKEN\",\n    \"-e\",\n    \"GITHUB_HOST\",\n    \"ghcr.io/github/github-mcp-server\"\n    ],\n    \"env\": {\n        \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"${input:github_token}\",\n        \"GITHUB_HOST\": \"https://<your GHES or ghe.com domain name>\"\n    }\n}\n```\n\n## Installation\n\n### Install in GitHub Copilot on VS Code\n\nFor quick installation, use one of the one-click install buttons above. Once you complete that flow, toggle Agent mode (located by the Copilot Chat text input) and the server will start.\n\nMore about using MCP server tools in VS Code's [agent mode documentation](https://code.visualstudio.com/docs/copilot/chat/mcp-servers).\n\nInstall in GitHub Copilot on other IDEs (JetBrains, Visual Studio, Eclipse, etc.)\n\nAdd the following JSON block to your IDE's MCP settings.\n\n```json\n{\n  \"mcp\": {\n    \"inputs\": [\n      {\n        \"type\": \"promptString\",\n        \"id\": \"github_token\",\n        \"description\": \"GitHub Personal Access Token\",\n        \"password\": true\n      }\n    ],\n    \"servers\": {\n      \"github\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"-i\",\n          \"--rm\",\n          \"-e\",\n          \"GITHUB_PERSONAL_ACCESS_TOKEN\",\n          \"ghcr.io/github/github-mcp-server\"\n        ],\n        \"env\": {\n          \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"${input:github_token}\"\n        }\n      }\n    }\n  }\n}\n```\n\nOptionally, you can add a similar example (i.e. without the mcp key) to a file called `.vscode/mcp.json` in your workspace. This will allow you to share the configuration with other host applications that accept the same format.\n\n<details>\n<summary><b>Example JSON block without the MCP key included</b></summary>\n<br>\n\n```json\n{\n  \"inputs\": [\n    {\n      \"type\": \"promptString\",\n      \"id\": \"github_token\",\n      \"description\": \"GitHub Personal Access Token\",\n      \"password\": true\n    }\n  ],\n  \"servers\": {\n    \"github\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\",\n        \"GITHUB_PERSONAL_ACCESS_TOKEN\",\n        \"ghcr.io/github/github-mcp-server\"\n      ],\n      \"env\": {\n        \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"${input:github_token}\"\n      }\n    }\n  }\n}\n```\n\n</details>\n\n### Install in Other MCP Hosts\n\nFor other MCP host applications, please refer to our installation guides:\n\n- **[GitHub Copilot in other IDEs](/docs/installation-guides/install-other-copilot-ides.md)** - Installation for JetBrains, Visual Studio, Eclipse, and Xcode with GitHub Copilot\n- **[Claude Code & Claude Desktop](docs/installation-guides/install-claude.md)** - Installation guide for Claude Code and Claude Desktop\n- **[Cursor](docs/installation-guides/install-cursor.md)** - Installation guide for Cursor IDE\n- **[Google Gemini CLI](docs/installation-guides/install-gemini-cli.md)** - Installation guide for Google Gemini CLI\n- **[Windsurf](docs/installation-guides/install-windsurf.md)** - Installation guide for Windsurf IDE\n\nFor a complete overview of all installation options, see our **[Installation Guides Index](docs/installation-guides)**.\n\n> **Note:** Any host application that supports local MCP servers should be able to access the local GitHub MCP server. However, the specific configuration process, syntax and stability of the integration will vary by host application. While many may follow a similar format to the examples above, this is not guaranteed. Please refer to your host application's documentation for the correct MCP configuration syntax and setup process.\n\n### Build from source\n\nIf you don't have Docker, you can use `go build` to build the binary in the\n`cmd/github-mcp-server` directory, and use the `github-mcp-server stdio` command with the `GITHUB_PERSONAL_ACCESS_TOKEN` environment variable set to your token. To specify the output location of the build, use the `-o` flag. You should configure your server to use the built executable as its `command`. For example:\n\n```JSON\n{\n  \"mcp\": {\n    \"servers\": {\n      \"github\": {\n        \"command\": \"/path/to/github-mcp-server\",\n        \"args\": [\"stdio\"],\n        \"env\": {\n          \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"<YOUR_TOKEN>\"\n        }\n      }\n    }\n  }\n}\n```\n\n### CLI utilities\n\nThe `github-mcp-server` binary includes a few CLI subcommands that are helpful for debugging and exploring the server.\n\n- `github-mcp-server tool-search \"<query>\"` searches tools by name, description, and input parameter names. Use `--max-results` to return more matches.\nExample (color output requires a TTY; use `docker run -t` (or `-it`) when running in Docker):\n```bash\ndocker run -it --rm ghcr.io/github/github-mcp-server tool-search \"issue\" --max-results 5\ngithub-mcp-server tool-search \"issue\" --max-results 5\n```\n\n## Tool Configuration\n\nThe GitHub MCP Server supports enabling or disabling specific groups of functionalities via the `--toolsets` flag. This allows you to control which GitHub API capabilities are available to your AI tools. Enabling only the toolsets that you need can help the LLM with tool choice and reduce the context size.\n\n_Toolsets are not limited to Tools. Relevant MCP Resources and Prompts are also included where applicable._\n\nWhen no toolsets are specified, [default toolsets](#default-toolset) are used.\n\n> **Looking for examples?** See the [Server Configuration Guide](./docs/server-configuration.md) for common recipes like minimal setups, read-only mode, and combining tools with toolsets.\n\n#### Specifying Toolsets\n\nTo specify toolsets you want available to the LLM, you can pass an allow-list in two ways:\n\n1. **Using Command Line Argument**:\n\n   ```bash\n   github-mcp-server --toolsets repos,issues,pull_requests,actions,code_security\n   ```\n\n2. **Using Environment Variable**:\n\n   ```bash\n   GITHUB_TOOLSETS=\"repos,issues,pull_requests,actions,code_security\" ./github-mcp-server\n   ```\n\nThe environment variable `GITHUB_TOOLSETS` takes precedence over the command line argument if both are provided.\n\n#### Specifying Individual Tools\n\nYou can also configure specific tools using the `--tools` flag. Tools can be used independently or combined with toolsets and dynamic toolsets discovery for fine-grained control.\n\n1. **Using Command Line Argument**:\n\n   ```bash\n   github-mcp-server --tools get_file_contents,issue_read,create_pull_request\n   ```\n\n2. **Using Environment Variable**:\n\n   ```bash\n   GITHUB_TOOLS=\"get_file_contents,issue_read,create_pull_request\" ./github-mcp-server\n   ```\n\n3. **Combining with Toolsets** (additive):\n\n   ```bash\n   github-mcp-server --toolsets repos,issues --tools get_gist\n   ```\n\n   This registers all tools from `repos` and `issues` toolsets, plus `get_gist`.\n\n4. **Combining with Dynamic Toolsets** (additive):\n\n   ```bash\n   github-mcp-server --tools get_file_contents --dynamic-toolsets\n   ```\n\n   This registers `get_file_contents` plus the dynamic toolset tools (`enable_toolset`, `list_available_toolsets`, `get_toolset_tools`).\n\n**Important Notes:**\n\n- Tools, toolsets, and dynamic toolsets can all be used together\n- Read-only mode takes priority: write tools are skipped if `--read-only` is set, even if explicitly requested via `--tools`\n- Tool names must match exactly (e.g., `get_file_contents`, not `getFileContents`). Invalid tool names will cause the server to fail at startup with an error message\n- When tools are renamed, old names are preserved as aliases for backward compatibility. See [Deprecated Tool Aliases](docs/deprecated-tool-aliases.md) for details.\n\n### Using Toolsets With Docker\n\nWhen using Docker, you can pass the toolsets as environment variables:\n\n```bash\ndocker run -i --rm \\\n  -e GITHUB_PERSONAL_ACCESS_TOKEN=<your-token> \\\n  -e GITHUB_TOOLSETS=\"repos,issues,pull_requests,actions,code_security\" \\\n  ghcr.io/github/github-mcp-server\n```\n\n### Using Tools With Docker\n\nWhen using Docker, you can pass specific tools as environment variables. You can also combine tools with toolsets:\n\n```bash\n# Tools only\ndocker run -i --rm \\\n  -e GITHUB_PERSONAL_ACCESS_TOKEN=<your-token> \\\n  -e GITHUB_TOOLS=\"get_file_contents,issue_read,create_pull_request\" \\\n  ghcr.io/github/github-mcp-server\n\n# Tools combined with toolsets (additive)\ndocker run -i --rm \\\n  -e GITHUB_PERSONAL_ACCESS_TOKEN=<your-token> \\\n  -e GITHUB_TOOLSETS=\"repos,issues\" \\\n  -e GITHUB_TOOLS=\"get_gist\" \\\n  ghcr.io/github/github-mcp-server\n```\n\n### Special toolsets\n\n#### \"all\" toolset\n\nThe special toolset `all` can be provided to enable all available toolsets regardless of any other configuration:\n\n```bash\n./github-mcp-server --toolsets all\n```\n\nOr using the environment variable:\n\n```bash\nGITHUB_TOOLSETS=\"all\" ./github-mcp-server\n```\n\n#### \"default\" toolset\n\nThe default toolset `default` is the configuration that gets passed to the server if no toolsets are specified.\n\nThe default configuration is:\n\n- context\n- repos\n- issues\n- pull_requests\n- users\n\nTo keep the default configuration and add additional toolsets:\n\n```bash\nGITHUB_TOOLSETS=\"default,stargazers\" ./github-mcp-server\n```\n\n### Insiders Mode\n\nThe local GitHub MCP Server offers an insiders version with early access to new features and experimental tools.\n\n1. **Using Command Line Argument**:\n\n   ```bash\n   ./github-mcp-server --insider-mode\n   ```\n\n2. **Using Environment Variable**:\n\n   ```bash\n   GITHUB_INSIDER_MODE=true ./github-mcp-server\n   ```\n\nWhen using Docker:\n\n```bash\ndocker run -i --rm \\\n  -e GITHUB_PERSONAL_ACCESS_TOKEN=<your-token> \\\n  -e GITHUB_INSIDER_MODE=true \\\n  ghcr.io/github/github-mcp-server\n```\n\n### Available Toolsets\n\nThe following sets of tools are available:\n\n<!-- START AUTOMATED TOOLSETS -->\n|     | Toolset                 | Description                                                   |\n| --- | ----------------------- | ------------------------------------------------------------- |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/person-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/person-light.png\"><img src=\"pkg/octicons/icons/person-light.png\" width=\"20\" height=\"20\" alt=\"person\"></picture> | `context`               | **Strongly recommended**: Tools that provide context about the current user and GitHub context you are operating in |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/workflow-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/workflow-light.png\"><img src=\"pkg/octicons/icons/workflow-light.png\" width=\"20\" height=\"20\" alt=\"workflow\"></picture> | `actions` | GitHub Actions workflows and CI/CD operations |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/codescan-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/codescan-light.png\"><img src=\"pkg/octicons/icons/codescan-light.png\" width=\"20\" height=\"20\" alt=\"codescan\"></picture> | `code_security` | Code security related tools, such as GitHub Code Scanning |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/dependabot-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/dependabot-light.png\"><img src=\"pkg/octicons/icons/dependabot-light.png\" width=\"20\" height=\"20\" alt=\"dependabot\"></picture> | `dependabot` | Dependabot tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/comment-discussion-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/comment-discussion-light.png\"><img src=\"pkg/octicons/icons/comment-discussion-light.png\" width=\"20\" height=\"20\" alt=\"comment-discussion\"></picture> | `discussions` | GitHub Discussions related tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/logo-gist-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/logo-gist-light.png\"><img src=\"pkg/octicons/icons/logo-gist-light.png\" width=\"20\" height=\"20\" alt=\"logo-gist\"></picture> | `gists` | GitHub Gist related tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/git-branch-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/git-branch-light.png\"><img src=\"pkg/octicons/icons/git-branch-light.png\" width=\"20\" height=\"20\" alt=\"git-branch\"></picture> | `git` | GitHub Git API related tools for low-level Git operations |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/issue-opened-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/issue-opened-light.png\"><img src=\"pkg/octicons/icons/issue-opened-light.png\" width=\"20\" height=\"20\" alt=\"issue-opened\"></picture> | `issues` | GitHub Issues related tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/tag-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/tag-light.png\"><img src=\"pkg/octicons/icons/tag-light.png\" width=\"20\" height=\"20\" alt=\"tag\"></picture> | `labels` | GitHub Labels related tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/bell-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/bell-light.png\"><img src=\"pkg/octicons/icons/bell-light.png\" width=\"20\" height=\"20\" alt=\"bell\"></picture> | `notifications` | GitHub Notifications related tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/organization-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/organization-light.png\"><img src=\"pkg/octicons/icons/organization-light.png\" width=\"20\" height=\"20\" alt=\"organization\"></picture> | `orgs` | GitHub Organization related tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/project-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/project-light.png\"><img src=\"pkg/octicons/icons/project-light.png\" width=\"20\" height=\"20\" alt=\"project\"></picture> | `projects` | GitHub Projects related tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/git-pull-request-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/git-pull-request-light.png\"><img src=\"pkg/octicons/icons/git-pull-request-light.png\" width=\"20\" height=\"20\" alt=\"git-pull-request\"></picture> | `pull_requests` | GitHub Pull Request related tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/repo-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/repo-light.png\"><img src=\"pkg/octicons/icons/repo-light.png\" width=\"20\" height=\"20\" alt=\"repo\"></picture> | `repos` | GitHub Repository related tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/shield-lock-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/shield-lock-light.png\"><img src=\"pkg/octicons/icons/shield-lock-light.png\" width=\"20\" height=\"20\" alt=\"shield-lock\"></picture> | `secret_protection` | Secret protection related tools, such as GitHub Secret Scanning |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/shield-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/shield-light.png\"><img src=\"pkg/octicons/icons/shield-light.png\" width=\"20\" height=\"20\" alt=\"shield\"></picture> | `security_advisories` | Security advisories related tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/star-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/star-light.png\"><img src=\"pkg/octicons/icons/star-light.png\" width=\"20\" height=\"20\" alt=\"star\"></picture> | `stargazers` | GitHub Stargazers related tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/people-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/people-light.png\"><img src=\"pkg/octicons/icons/people-light.png\" width=\"20\" height=\"20\" alt=\"people\"></picture> | `users` | GitHub User related tools |\n<!-- END AUTOMATED TOOLSETS -->\n\n### Additional Toolsets in Remote GitHub MCP Server\n\n| Toolset                 | Description                                                   |\n| ----------------------- | ------------------------------------------------------------- |\n| `copilot` | Copilot related tools (e.g. Copilot Coding Agent) |\n| `copilot_spaces` | Copilot Spaces related tools |\n| `github_support_docs_search` | Search docs to answer GitHub product and support questions |\n\n## Tools\n\n<!-- START AUTOMATED TOOLS -->\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/workflow-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/workflow-light.png\"><img src=\"pkg/octicons/icons/workflow-light.png\" width=\"20\" height=\"20\" alt=\"workflow\"></picture> Actions</summary>\n\n- **cancel_workflow_run** - Cancel workflow run\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **delete_workflow_run_logs** - Delete workflow logs\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **download_workflow_run_artifact** - Download workflow artifact\n  - **Required OAuth Scopes**: `repo`\n  - `artifact_id`: The unique identifier of the artifact (number, required)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **get_job_logs** - Get job logs\n  - **Required OAuth Scopes**: `repo`\n  - `failed_only`: When true, gets logs for all failed jobs in run_id (boolean, optional)\n  - `job_id`: The unique identifier of the workflow job (required for single job logs) (number, optional)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `return_content`: Returns actual log content instead of URLs (boolean, optional)\n  - `run_id`: Workflow run ID (required when using failed_only) (number, optional)\n  - `tail_lines`: Number of lines to return from the end of the log (number, optional)\n\n- **get_workflow_run** - Get workflow run\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **get_workflow_run_logs** - Get workflow run logs\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **get_workflow_run_usage** - Get workflow usage\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **list_workflow_jobs** - List workflow jobs\n  - **Required OAuth Scopes**: `repo`\n  - `filter`: Filters jobs by their completed_at timestamp (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **list_workflow_run_artifacts** - List workflow artifacts\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **list_workflow_runs** - List workflow runs\n  - **Required OAuth Scopes**: `repo`\n  - `actor`: Returns someone's workflow runs. Use the login for the user who created the workflow run. (string, optional)\n  - `branch`: Returns workflow runs associated with a branch. Use the name of the branch. (string, optional)\n  - `event`: Returns workflow runs for a specific event type (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n  - `status`: Returns workflow runs with the check run status (string, optional)\n  - `workflow_id`: The workflow ID or workflow file name (string, required)\n\n- **list_workflows** - List workflows\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n\n- **rerun_failed_jobs** - Rerun failed jobs\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **rerun_workflow_run** - Rerun workflow run\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **run_workflow** - Run workflow\n  - **Required OAuth Scopes**: `repo`\n  - `inputs`: Inputs the workflow accepts (object, optional)\n  - `owner`: Repository owner (string, required)\n  - `ref`: The git reference for the workflow. The reference can be a branch or tag name. (string, required)\n  - `repo`: Repository name (string, required)\n  - `workflow_id`: The workflow ID (numeric) or workflow file name (e.g., main.yml, ci.yaml) (string, required)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/codescan-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/codescan-light.png\"><img src=\"pkg/octicons/icons/codescan-light.png\" width=\"20\" height=\"20\" alt=\"codescan\"></picture> Code Security</summary>\n\n- **get_code_scanning_alert** - Get code scanning alert\n  - **Required OAuth Scopes**: `security_events`\n  - **Accepted OAuth Scopes**: `repo`, `security_events`\n  - `alertNumber`: The number of the alert. (number, required)\n  - `owner`: The owner of the repository. (string, required)\n  - `repo`: The name of the repository. (string, required)\n\n- **list_code_scanning_alerts** - List code scanning alerts\n  - **Required OAuth Scopes**: `security_events`\n  - **Accepted OAuth Scopes**: `repo`, `security_events`\n  - `owner`: The owner of the repository. (string, required)\n  - `ref`: The Git reference for the results you want to list. (string, optional)\n  - `repo`: The name of the repository. (string, required)\n  - `severity`: Filter code scanning alerts by severity (string, optional)\n  - `state`: Filter code scanning alerts by state. Defaults to open (string, optional)\n  - `tool_name`: The name of the tool used for code scanning. (string, optional)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/person-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/person-light.png\"><img src=\"pkg/octicons/icons/person-light.png\" width=\"20\" height=\"20\" alt=\"person\"></picture> Context</summary>\n\n- **get_me** - Get my user profile\n  - No parameters required\n\n- **get_team_members** - Get team members\n  - **Required OAuth Scopes**: `read:org`\n  - **Accepted OAuth Scopes**: `admin:org`, `read:org`, `write:org`\n  - `org`: Organization login (owner) that contains the team. (string, required)\n  - `team_slug`: Team slug (string, required)\n\n- **get_teams** - Get teams\n  - **Required OAuth Scopes**: `read:org`\n  - **Accepted OAuth Scopes**: `admin:org`, `read:org`, `write:org`\n  - `user`: Username to get teams for. If not provided, uses the authenticated user. (string, optional)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/dependabot-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/dependabot-light.png\"><img src=\"pkg/octicons/icons/dependabot-light.png\" width=\"20\" height=\"20\" alt=\"dependabot\"></picture> Dependabot</summary>\n\n- **get_dependabot_alert** - Get dependabot alert\n  - **Required OAuth Scopes**: `security_events`\n  - **Accepted OAuth Scopes**: `repo`, `security_events`\n  - `alertNumber`: The number of the alert. (number, required)\n  - `owner`: The owner of the repository. (string, required)\n  - `repo`: The name of the repository. (string, required)\n\n- **list_dependabot_alerts** - List dependabot alerts\n  - **Required OAuth Scopes**: `security_events`\n  - **Accepted OAuth Scopes**: `repo`, `security_events`\n  - `owner`: The owner of the repository. (string, required)\n  - `repo`: The name of the repository. (string, required)\n  - `severity`: Filter dependabot alerts by severity (string, optional)\n  - `state`: Filter dependabot alerts by state. Defaults to open (string, optional)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/comment-discussion-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/comment-discussion-light.png\"><img src=\"pkg/octicons/icons/comment-discussion-light.png\" width=\"20\" height=\"20\" alt=\"comment-discussion\"></picture> Discussions</summary>\n\n- **get_discussion** - Get discussion\n  - **Required OAuth Scopes**: `repo`\n  - `discussionNumber`: Discussion Number (number, required)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **get_discussion_comments** - Get discussion comments\n  - **Required OAuth Scopes**: `repo`\n  - `after`: Cursor for pagination. Use the endCursor from the previous page's PageInfo for GraphQL APIs. (string, optional)\n  - `discussionNumber`: Discussion Number (number, required)\n  - `owner`: Repository owner (string, required)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n\n- **list_discussion_categories** - List discussion categories\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name. If not provided, discussion categories will be queried at the organisation level. (string, optional)\n\n- **list_discussions** - List discussions\n  - **Required OAuth Scopes**: `repo`\n  - `after`: Cursor for pagination. Use the endCursor from the previous page's PageInfo for GraphQL APIs. (string, optional)\n  - `category`: Optional filter by discussion category ID. If provided, only discussions with this category are listed. (string, optional)\n  - `direction`: Order direction. (string, optional)\n  - `orderBy`: Order discussions by field. If provided, the 'direction' also needs to be provided. (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name. If not provided, discussions will be queried at the organisation level. (string, optional)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/logo-gist-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/logo-gist-light.png\"><img src=\"pkg/octicons/icons/logo-gist-light.png\" width=\"20\" height=\"20\" alt=\"logo-gist\"></picture> Gists</summary>\n\n- **create_gist** - Create Gist\n  - **Required OAuth Scopes**: `gist`\n  - `content`: Content for simple single-file gist creation (string, required)\n  - `description`: Description of the gist (string, optional)\n  - `filename`: Filename for simple single-file gist creation (string, required)\n  - `public`: Whether the gist is public (boolean, optional)\n\n- **get_gist** - Get Gist Content\n  - `gist_id`: The ID of the gist (string, required)\n\n- **list_gists** - List Gists\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `since`: Only gists updated after this time (ISO 8601 timestamp) (string, optional)\n  - `username`: GitHub username (omit for authenticated user's gists) (string, optional)\n\n- **update_gist** - Update Gist\n  - **Required OAuth Scopes**: `gist`\n  - `content`: Content for the file (string, required)\n  - `description`: Updated description of the gist (string, optional)\n  - `filename`: Filename to update or create (string, required)\n  - `gist_id`: ID of the gist to update (string, required)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/git-branch-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/git-branch-light.png\"><img src=\"pkg/octicons/icons/git-branch-light.png\" width=\"20\" height=\"20\" alt=\"git-branch\"></picture> Git</summary>\n\n- **get_repository_tree** - Get repository tree\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (username or organization) (string, required)\n  - `path_filter`: Optional path prefix to filter the tree results (e.g., 'src/' to only show files in the src directory) (string, optional)\n  - `recursive`: Setting this parameter to true returns the objects or subtrees referenced by the tree. Default is false (boolean, optional)\n  - `repo`: Repository name (string, required)\n  - `tree_sha`: The SHA1 value or ref (branch or tag) name of the tree. Defaults to the repository's default branch (string, optional)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/issue-opened-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/issue-opened-light.png\"><img src=\"pkg/octicons/icons/issue-opened-light.png\" width=\"20\" height=\"20\" alt=\"issue-opened\"></picture> Issues</summary>\n\n- **add_issue_comment** - Add comment to issue\n  - **Required OAuth Scopes**: `repo`\n  - `body`: Comment content (string, required)\n  - `issue_number`: Issue number to comment on (number, required)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **assign_copilot_to_issue** - Assign Copilot to issue\n  - **Required OAuth Scopes**: `repo`\n  - `base_ref`: Git reference (e.g., branch) that the agent will start its work from. If not specified, defaults to the repository's default branch (string, optional)\n  - `custom_instructions`: Optional custom instructions to guide the agent beyond the issue body. Use this to provide additional context, constraints, or guidance that is not captured in the issue description (string, optional)\n  - `issue_number`: Issue number (number, required)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **get_label** - Get a specific label from a repository.\n  - **Required OAuth Scopes**: `repo`\n  - `name`: Label name. (string, required)\n  - `owner`: Repository owner (username or organization name) (string, required)\n  - `repo`: Repository name (string, required)\n\n- **issue_read** - Get issue details\n  - **Required OAuth Scopes**: `repo`\n  - `issue_number`: The number of the issue (number, required)\n  - `method`: The read operation to perform on a single issue.\n    Options are:\n    1. get - Get details of a specific issue.\n    2. get_comments - Get issue comments.\n    3. get_sub_issues - Get sub-issues of the issue.\n    4. get_labels - Get labels assigned to the issue.\n     (string, required)\n  - `owner`: The owner of the repository (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: The name of the repository (string, required)\n\n- **issue_write** - Create or update issue.\n  - **Required OAuth Scopes**: `repo`\n  - `assignees`: Usernames to assign to this issue (string[], optional)\n  - `body`: Issue body content (string, optional)\n  - `duplicate_of`: Issue number that this issue is a duplicate of. Only used when state_reason is 'duplicate'. (number, optional)\n  - `issue_number`: Issue number to update (number, optional)\n  - `labels`: Labels to apply to this issue (string[], optional)\n  - `method`: Write operation to perform on a single issue.\n    Options are:\n    - 'create' - creates a new issue.\n    - 'update' - updates an existing issue.\n     (string, required)\n  - `milestone`: Milestone number (number, optional)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `state`: New state (string, optional)\n  - `state_reason`: Reason for the state change. Ignored unless state is changed. (string, optional)\n  - `title`: Issue title (string, optional)\n  - `type`: Type of this issue. Only use if the repository has issue types configured. Use list_issue_types tool to get valid type values for the organization. If the repository doesn't support issue types, omit this parameter. (string, optional)\n\n- **list_issue_types** - List available issue types\n  - **Required OAuth Scopes**: `read:org`\n  - **Accepted OAuth Scopes**: `admin:org`, `read:org`, `write:org`\n  - `owner`: The organization owner of the repository (string, required)\n\n- **list_issues** - List issues\n  - **Required OAuth Scopes**: `repo`\n  - `after`: Cursor for pagination. Use the endCursor from the previous page's PageInfo for GraphQL APIs. (string, optional)\n  - `direction`: Order direction. If provided, the 'orderBy' also needs to be provided. (string, optional)\n  - `labels`: Filter by labels (string[], optional)\n  - `orderBy`: Order issues by field. If provided, the 'direction' also needs to be provided. (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n  - `since`: Filter by date (ISO 8601 timestamp) (string, optional)\n  - `state`: Filter by state, by default both open and closed issues are returned when not provided (string, optional)\n\n- **search_issues** - Search issues\n  - **Required OAuth Scopes**: `repo`\n  - `order`: Sort order (string, optional)\n  - `owner`: Optional repository owner. If provided with repo, only issues for this repository are listed. (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `query`: Search query using GitHub issues search syntax (string, required)\n  - `repo`: Optional repository name. If provided with owner, only issues for this repository are listed. (string, optional)\n  - `sort`: Sort field by number of matches of categories, defaults to best match (string, optional)\n\n- **sub_issue_write** - Change sub-issue\n  - **Required OAuth Scopes**: `repo`\n  - `after_id`: The ID of the sub-issue to be prioritized after (either after_id OR before_id should be specified) (number, optional)\n  - `before_id`: The ID of the sub-issue to be prioritized before (either after_id OR before_id should be specified) (number, optional)\n  - `issue_number`: The number of the parent issue (number, required)\n  - `method`: The action to perform on a single sub-issue\n    Options are:\n    - 'add' - add a sub-issue to a parent issue in a GitHub repository.\n    - 'remove' - remove a sub-issue from a parent issue in a GitHub repository.\n    - 'reprioritize' - change the order of sub-issues within a parent issue in a GitHub repository. Use either 'after_id' or 'before_id' to specify the new position.\n    \t\t\t\t (string, required)\n  - `owner`: Repository owner (string, required)\n  - `replace_parent`: When true, replaces the sub-issue's current parent issue. Use with 'add' method only. (boolean, optional)\n  - `repo`: Repository name (string, required)\n  - `sub_issue_id`: The ID of the sub-issue to add. ID is not the same as issue number (number, required)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/tag-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/tag-light.png\"><img src=\"pkg/octicons/icons/tag-light.png\" width=\"20\" height=\"20\" alt=\"tag\"></picture> Labels</summary>\n\n- **get_label** - Get a specific label from a repository.\n  - **Required OAuth Scopes**: `repo`\n  - `name`: Label name. (string, required)\n  - `owner`: Repository owner (username or organization name) (string, required)\n  - `repo`: Repository name (string, required)\n\n- **label_write** - Write operations on repository labels.\n  - **Required OAuth Scopes**: `repo`\n  - `color`: Label color as 6-character hex code without '#' prefix (e.g., 'f29513'). Required for 'create', optional for 'update'. (string, optional)\n  - `description`: Label description text. Optional for 'create' and 'update'. (string, optional)\n  - `method`: Operation to perform: 'create', 'update', or 'delete' (string, required)\n  - `name`: Label name - required for all operations (string, required)\n  - `new_name`: New name for the label (used only with 'update' method to rename) (string, optional)\n  - `owner`: Repository owner (username or organization name) (string, required)\n  - `repo`: Repository name (string, required)\n\n- **list_label** - List labels from a repository\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (username or organization name) - required for all operations (string, required)\n  - `repo`: Repository name - required for all operations (string, required)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/bell-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/bell-light.png\"><img src=\"pkg/octicons/icons/bell-light.png\" width=\"20\" height=\"20\" alt=\"bell\"></picture> Notifications</summary>\n\n- **dismiss_notification** - Dismiss notification\n  - **Required OAuth Scopes**: `notifications`\n  - `state`: The new state of the notification (read/done) (string, required)\n  - `threadID`: The ID of the notification thread (string, required)\n\n- **get_notification_details** - Get notification details\n  - **Required OAuth Scopes**: `notifications`\n  - `notificationID`: The ID of the notification (string, required)\n\n- **list_notifications** - List notifications\n  - **Required OAuth Scopes**: `notifications`\n  - `before`: Only show notifications updated before the given time (ISO 8601 format) (string, optional)\n  - `filter`: Filter notifications to, use default unless specified. Read notifications are ones that have already been acknowledged by the user. Participating notifications are those that the user is directly involved in, such as issues or pull requests they have commented on or created. (string, optional)\n  - `owner`: Optional repository owner. If provided with repo, only notifications for this repository are listed. (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Optional repository name. If provided with owner, only notifications for this repository are listed. (string, optional)\n  - `since`: Only show notifications updated after the given time (ISO 8601 format) (string, optional)\n\n- **manage_notification_subscription** - Manage notification subscription\n  - **Required OAuth Scopes**: `notifications`\n  - `action`: Action to perform: ignore, watch, or delete the notification subscription. (string, required)\n  - `notificationID`: The ID of the notification thread. (string, required)\n\n- **manage_repository_notification_subscription** - Manage repository notification subscription\n  - **Required OAuth Scopes**: `notifications`\n  - `action`: Action to perform: ignore, watch, or delete the repository notification subscription. (string, required)\n  - `owner`: The account owner of the repository. (string, required)\n  - `repo`: The name of the repository. (string, required)\n\n- **mark_all_notifications_read** - Mark all notifications as read\n  - **Required OAuth Scopes**: `notifications`\n  - `lastReadAt`: Describes the last point that notifications were checked (optional). Default: Now (string, optional)\n  - `owner`: Optional repository owner. If provided with repo, only notifications for this repository are marked as read. (string, optional)\n  - `repo`: Optional repository name. If provided with owner, only notifications for this repository are marked as read. (string, optional)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/organization-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/organization-light.png\"><img src=\"pkg/octicons/icons/organization-light.png\" width=\"20\" height=\"20\" alt=\"organization\"></picture> Organizations</summary>\n\n- **search_orgs** - Search organizations\n  - **Required OAuth Scopes**: `read:org`\n  - **Accepted OAuth Scopes**: `admin:org`, `read:org`, `write:org`\n  - `order`: Sort order (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `query`: Organization search query. Examples: 'microsoft', 'location:california', 'created:>=2025-01-01'. Search is automatically scoped to type:org. (string, required)\n  - `sort`: Sort field by category (string, optional)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/project-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/project-light.png\"><img src=\"pkg/octicons/icons/project-light.png\" width=\"20\" height=\"20\" alt=\"project\"></picture> Projects</summary>\n\n- **add_project_item** - Add project item\n  - **Required OAuth Scopes**: `project`\n  - `item_id`: The numeric ID of the issue or pull request to add to the project. (number, required)\n  - `item_type`: The item's type, either issue or pull_request. (string, required)\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `project_number`: The project's number. (number, required)\n\n- **delete_project_item** - Delete project item\n  - **Required OAuth Scopes**: `project`\n  - `item_id`: The internal project item ID to delete from the project (not the issue or pull request ID). (number, required)\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `project_number`: The project's number. (number, required)\n\n- **get_project** - Get project\n  - **Required OAuth Scopes**: `read:project`\n  - **Accepted OAuth Scopes**: `project`, `read:project`\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `project_number`: The project's number (number, required)\n\n- **get_project_field** - Get project field\n  - **Required OAuth Scopes**: `read:project`\n  - **Accepted OAuth Scopes**: `project`, `read:project`\n  - `field_id`: The field's id. (number, required)\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `project_number`: The project's number. (number, required)\n\n- **get_project_item** - Get project item\n  - **Required OAuth Scopes**: `read:project`\n  - **Accepted OAuth Scopes**: `project`, `read:project`\n  - `fields`: Specific list of field IDs to include in the response (e.g. [\"102589\", \"985201\", \"169875\"]). If not provided, only the title field is included. (string[], optional)\n  - `item_id`: The item's ID. (number, required)\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `project_number`: The project's number. (number, required)\n\n- **list_project_fields** - List project fields\n  - **Required OAuth Scopes**: `read:project`\n  - **Accepted OAuth Scopes**: `project`, `read:project`\n  - `after`: Forward pagination cursor from previous pageInfo.nextCursor. (string, optional)\n  - `before`: Backward pagination cursor from previous pageInfo.prevCursor (rare). (string, optional)\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `per_page`: Results per page (max 50) (number, optional)\n  - `project_number`: The project's number. (number, required)\n\n- **list_project_items** - List project items\n  - **Required OAuth Scopes**: `read:project`\n  - **Accepted OAuth Scopes**: `project`, `read:project`\n  - `after`: Forward pagination cursor from previous pageInfo.nextCursor. (string, optional)\n  - `before`: Backward pagination cursor from previous pageInfo.prevCursor (rare). (string, optional)\n  - `fields`: Field IDs to include (e.g. [\"102589\", \"985201\"]). CRITICAL: Always provide to get field values. Without this, only titles returned. (string[], optional)\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `per_page`: Results per page (max 50) (number, optional)\n  - `project_number`: The project's number. (number, required)\n  - `query`: Query string for advanced filtering of project items using GitHub's project filtering syntax. (string, optional)\n\n- **list_projects** - List projects\n  - **Required OAuth Scopes**: `read:project`\n  - **Accepted OAuth Scopes**: `project`, `read:project`\n  - `after`: Forward pagination cursor from previous pageInfo.nextCursor. (string, optional)\n  - `before`: Backward pagination cursor from previous pageInfo.prevCursor (rare). (string, optional)\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `per_page`: Results per page (max 50) (number, optional)\n  - `query`: Filter projects by title text and open/closed state; permitted qualifiers: is:open, is:closed; examples: \"roadmap is:open\", \"is:open feature planning\". (string, optional)\n\n- **update_project_item** - Update project item\n  - **Required OAuth Scopes**: `project`\n  - `item_id`: The unique identifier of the project item. This is not the issue or pull request ID. (number, required)\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `project_number`: The project's number. (number, required)\n  - `updated_field`: Object consisting of the ID of the project field to update and the new value for the field. To clear the field, set value to null. Example: {\"id\": 123456, \"value\": \"New Value\"} (object, required)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/git-pull-request-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/git-pull-request-light.png\"><img src=\"pkg/octicons/icons/git-pull-request-light.png\" width=\"20\" height=\"20\" alt=\"git-pull-request\"></picture> Pull Requests</summary>\n\n- **add_comment_to_pending_review** - Add review comment to the requester's latest pending pull request review\n  - **Required OAuth Scopes**: `repo`\n  - `body`: The text of the review comment (string, required)\n  - `line`: The line of the blob in the pull request diff that the comment applies to. For multi-line comments, the last line of the range (number, optional)\n  - `owner`: Repository owner (string, required)\n  - `path`: The relative path to the file that necessitates a comment (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n  - `side`: The side of the diff to comment on. LEFT indicates the previous state, RIGHT indicates the new state (string, optional)\n  - `startLine`: For multi-line comments, the first line of the range that the comment applies to (number, optional)\n  - `startSide`: For multi-line comments, the starting side of the diff that the comment applies to. LEFT indicates the previous state, RIGHT indicates the new state (string, optional)\n  - `subjectType`: The level at which the comment is targeted (string, required)\n\n- **create_pull_request** - Open new pull request\n  - **Required OAuth Scopes**: `repo`\n  - `base`: Branch to merge into (string, required)\n  - `body`: PR description (string, optional)\n  - `draft`: Create as draft PR (boolean, optional)\n  - `head`: Branch containing changes (string, required)\n  - `maintainer_can_modify`: Allow maintainer edits (boolean, optional)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `title`: PR title (string, required)\n\n- **list_pull_requests** - List pull requests\n  - **Required OAuth Scopes**: `repo`\n  - `base`: Filter by base branch (string, optional)\n  - `direction`: Sort direction (string, optional)\n  - `head`: Filter by head user/org and branch (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n  - `sort`: Sort by (string, optional)\n  - `state`: Filter by state (string, optional)\n\n- **merge_pull_request** - Merge pull request\n  - **Required OAuth Scopes**: `repo`\n  - `commit_message`: Extra detail for merge commit (string, optional)\n  - `commit_title`: Title for merge commit (string, optional)\n  - `merge_method`: Merge method (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n- **pull_request_read** - Get details for a single pull request\n  - **Required OAuth Scopes**: `repo`\n  - `method`: Action to specify what pull request data needs to be retrieved from GitHub. \n    Possible options: \n     1. get - Get details of a specific pull request.\n     2. get_diff - Get the diff of a pull request.\n     3. get_status - Get status of a head commit in a pull request. This reflects status of builds and checks.\n     4. get_files - Get the list of files changed in a pull request. Use with pagination parameters to control the number of results returned.\n     5. get_review_comments - Get review threads on a pull request. Each thread contains logically grouped review comments made on the same code location during pull request reviews. Returns threads with metadata (isResolved, isOutdated, isCollapsed) and their associated comments. Use cursor-based pagination (perPage, after) to control results.\n     6. get_reviews - Get the reviews on a pull request. When asked for review comments, use get_review_comments method.\n     7. get_comments - Get comments on a pull request. Use this if user doesn't specifically want review comments. Use with pagination parameters to control the number of results returned.\n     (string, required)\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n- **pull_request_review_write** - Write operations (create, submit, delete) on pull request reviews.\n  - **Required OAuth Scopes**: `repo`\n  - `body`: Review comment text (string, optional)\n  - `commitID`: SHA of commit to review (string, optional)\n  - `event`: Review action to perform. (string, optional)\n  - `method`: The write operation to perform on pull request review. (string, required)\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n- **request_copilot_review** - Request Copilot review\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n- **search_pull_requests** - Search pull requests\n  - **Required OAuth Scopes**: `repo`\n  - `order`: Sort order (string, optional)\n  - `owner`: Optional repository owner. If provided with repo, only pull requests for this repository are listed. (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `query`: Search query using GitHub pull request search syntax (string, required)\n  - `repo`: Optional repository name. If provided with owner, only pull requests for this repository are listed. (string, optional)\n  - `sort`: Sort field by number of matches of categories, defaults to best match (string, optional)\n\n- **update_pull_request** - Edit pull request\n  - **Required OAuth Scopes**: `repo`\n  - `base`: New base branch name (string, optional)\n  - `body`: New description (string, optional)\n  - `draft`: Mark pull request as draft (true) or ready for review (false) (boolean, optional)\n  - `maintainer_can_modify`: Allow maintainer edits (boolean, optional)\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number to update (number, required)\n  - `repo`: Repository name (string, required)\n  - `reviewers`: GitHub usernames to request reviews from (string[], optional)\n  - `state`: New state (string, optional)\n  - `title`: New title (string, optional)\n\n- **update_pull_request_branch** - Update pull request branch\n  - **Required OAuth Scopes**: `repo`\n  - `expectedHeadSha`: The expected SHA of the pull request's HEAD ref (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/repo-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/repo-light.png\"><img src=\"pkg/octicons/icons/repo-light.png\" width=\"20\" height=\"20\" alt=\"repo\"></picture> Repositories</summary>\n\n- **create_branch** - Create branch\n  - **Required OAuth Scopes**: `repo`\n  - `branch`: Name for new branch (string, required)\n  - `from_branch`: Source branch (defaults to repo default) (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **create_or_update_file** - Create or update file\n  - **Required OAuth Scopes**: `repo`\n  - `branch`: Branch to create/update the file in (string, required)\n  - `content`: Content of the file (string, required)\n  - `message`: Commit message (string, required)\n  - `owner`: Repository owner (username or organization) (string, required)\n  - `path`: Path where to create/update the file (string, required)\n  - `repo`: Repository name (string, required)\n  - `sha`: The blob SHA of the file being replaced. (string, optional)\n\n- **create_repository** - Create repository\n  - **Required OAuth Scopes**: `repo`\n  - `autoInit`: Initialize with README (boolean, optional)\n  - `description`: Repository description (string, optional)\n  - `name`: Repository name (string, required)\n  - `organization`: Organization to create the repository in (omit to create in your personal account) (string, optional)\n  - `private`: Whether repo should be private (boolean, optional)\n\n- **delete_file** - Delete file\n  - **Required OAuth Scopes**: `repo`\n  - `branch`: Branch to delete the file from (string, required)\n  - `message`: Commit message (string, required)\n  - `owner`: Repository owner (username or organization) (string, required)\n  - `path`: Path to the file to delete (string, required)\n  - `repo`: Repository name (string, required)\n\n- **fork_repository** - Fork repository\n  - **Required OAuth Scopes**: `repo`\n  - `organization`: Organization to fork to (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **get_commit** - Get commit details\n  - **Required OAuth Scopes**: `repo`\n  - `include_diff`: Whether to include file diffs and stats in the response. Default is true. (boolean, optional)\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n  - `sha`: Commit SHA, branch name, or tag name (string, required)\n\n- **get_file_contents** - Get file or directory contents\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (username or organization) (string, required)\n  - `path`: Path to file/directory (string, optional)\n  - `ref`: Accepts optional git refs such as `refs/tags/{tag}`, `refs/heads/{branch}` or `refs/pull/{pr_number}/head` (string, optional)\n  - `repo`: Repository name (string, required)\n  - `sha`: Accepts optional commit SHA. If specified, it will be used instead of ref (string, optional)\n\n- **get_latest_release** - Get latest release\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **get_release_by_tag** - Get a release by tag name\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `tag`: Tag name (e.g., 'v1.0.0') (string, required)\n\n- **get_tag** - Get tag details\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `tag`: Tag name (string, required)\n\n- **list_branches** - List branches\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n\n- **list_commits** - List commits\n  - **Required OAuth Scopes**: `repo`\n  - `author`: Author username or email address to filter commits by (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n  - `sha`: Commit SHA, branch or tag name to list commits of. If not provided, uses the default branch of the repository. If a commit SHA is provided, will list commits up to that SHA. (string, optional)\n\n- **list_releases** - List releases\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n\n- **list_tags** - List tags\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n\n- **push_files** - Push files to repository\n  - **Required OAuth Scopes**: `repo`\n  - `branch`: Branch to push to (string, required)\n  - `files`: Array of file objects to push, each object with path (string) and content (string) (object[], required)\n  - `message`: Commit message (string, required)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **search_code** - Search code\n  - **Required OAuth Scopes**: `repo`\n  - `order`: Sort order for results (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `query`: Search query using GitHub's powerful code search syntax. Examples: 'content:Skill language:Java org:github', 'NOT is:archived language:Python OR language:go', 'repo:github/github-mcp-server'. Supports exact matching, language filters, path filters, and more. (string, required)\n  - `sort`: Sort field ('indexed' only) (string, optional)\n\n- **search_repositories** - Search repositories\n  - **Required OAuth Scopes**: `repo`\n  - `minimal_output`: Return minimal repository information (default: true). When false, returns full GitHub API repository objects. (boolean, optional)\n  - `order`: Sort order (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `query`: Repository search query. Examples: 'machine learning in:name stars:>1000 language:python', 'topic:react', 'user:facebook'. Supports advanced search syntax for precise filtering. (string, required)\n  - `sort`: Sort repositories by field, defaults to best match (string, optional)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/shield-lock-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/shield-lock-light.png\"><img src=\"pkg/octicons/icons/shield-lock-light.png\" width=\"20\" height=\"20\" alt=\"shield-lock\"></picture> Secret Protection</summary>\n\n- **get_secret_scanning_alert** - Get secret scanning alert\n  - **Required OAuth Scopes**: `security_events`\n  - **Accepted OAuth Scopes**: `repo`, `security_events`\n  - `alertNumber`: The number of the alert. (number, required)\n  - `owner`: The owner of the repository. (string, required)\n  - `repo`: The name of the repository. (string, required)\n\n- **list_secret_scanning_alerts** - List secret scanning alerts\n  - **Required OAuth Scopes**: `security_events`\n  - **Accepted OAuth Scopes**: `repo`, `security_events`\n  - `owner`: The owner of the repository. (string, required)\n  - `repo`: The name of the repository. (string, required)\n  - `resolution`: Filter by resolution (string, optional)\n  - `secret_type`: A comma-separated list of secret types to return. All default secret patterns are returned. To return generic patterns, pass the token name(s) in the parameter. (string, optional)\n  - `state`: Filter by state (string, optional)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/shield-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/shield-light.png\"><img src=\"pkg/octicons/icons/shield-light.png\" width=\"20\" height=\"20\" alt=\"shield\"></picture> Security Advisories</summary>\n\n- **get_global_security_advisory** - Get a global security advisory\n  - **Required OAuth Scopes**: `security_events`\n  - **Accepted OAuth Scopes**: `repo`, `security_events`\n  - `ghsaId`: GitHub Security Advisory ID (format: GHSA-xxxx-xxxx-xxxx). (string, required)\n\n- **list_global_security_advisories** - List global security advisories\n  - **Required OAuth Scopes**: `security_events`\n  - **Accepted OAuth Scopes**: `repo`, `security_events`\n  - `affects`: Filter advisories by affected package or version (e.g. \"package1,package2@1.0.0\"). (string, optional)\n  - `cveId`: Filter by CVE ID. (string, optional)\n  - `cwes`: Filter by Common Weakness Enumeration IDs (e.g. [\"79\", \"284\", \"22\"]). (string[], optional)\n  - `ecosystem`: Filter by package ecosystem. (string, optional)\n  - `ghsaId`: Filter by GitHub Security Advisory ID (format: GHSA-xxxx-xxxx-xxxx). (string, optional)\n  - `isWithdrawn`: Whether to only return withdrawn advisories. (boolean, optional)\n  - `modified`: Filter by publish or update date or date range (ISO 8601 date or range). (string, optional)\n  - `published`: Filter by publish date or date range (ISO 8601 date or range). (string, optional)\n  - `severity`: Filter by severity. (string, optional)\n  - `type`: Advisory type. (string, optional)\n  - `updated`: Filter by update date or date range (ISO 8601 date or range). (string, optional)\n\n- **list_org_repository_security_advisories** - List org repository security advisories\n  - **Required OAuth Scopes**: `security_events`\n  - **Accepted OAuth Scopes**: `repo`, `security_events`\n  - `direction`: Sort direction. (string, optional)\n  - `org`: The organization login. (string, required)\n  - `sort`: Sort field. (string, optional)\n  - `state`: Filter by advisory state. (string, optional)\n\n- **list_repository_security_advisories** - List repository security advisories\n  - **Required OAuth Scopes**: `security_events`\n  - **Accepted OAuth Scopes**: `repo`, `security_events`\n  - `direction`: Sort direction. (string, optional)\n  - `owner`: The owner of the repository. (string, required)\n  - `repo`: The name of the repository. (string, required)\n  - `sort`: Sort field. (string, optional)\n  - `state`: Filter by advisory state. (string, optional)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/star-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/star-light.png\"><img src=\"pkg/octicons/icons/star-light.png\" width=\"20\" height=\"20\" alt=\"star\"></picture> Stargazers</summary>\n\n- **list_starred_repositories** - List starred repositories\n  - **Required OAuth Scopes**: `repo`\n  - `direction`: The direction to sort the results by. (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `sort`: How to sort the results. Can be either 'created' (when the repository was starred) or 'updated' (when the repository was last pushed to). (string, optional)\n  - `username`: Username to list starred repositories for. Defaults to the authenticated user. (string, optional)\n\n- **star_repository** - Star repository\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **unstar_repository** - Unstar repository\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/people-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/people-light.png\"><img src=\"pkg/octicons/icons/people-light.png\" width=\"20\" height=\"20\" alt=\"people\"></picture> Users</summary>\n\n- **search_users** - Search users\n  - **Required OAuth Scopes**: `repo`\n  - `order`: Sort order (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `query`: User search query. Examples: 'john smith', 'location:seattle', 'followers:>100'. Search is automatically scoped to type:user. (string, required)\n  - `sort`: Sort users by number of followers or repositories, or when the person joined GitHub. (string, optional)\n\n</details>\n<!-- END AUTOMATED TOOLS -->\n\n### Additional Tools in Remote GitHub MCP Server\n\n<details>\n\n<summary>Copilot</summary>\n\n- **create_pull_request_with_copilot** - Perform task with GitHub Copilot coding agent\n  - `owner`: Repository owner. You can guess the owner, but confirm it with the user before proceeding. (string, required)\n  - `repo`: Repository name. You can guess the repository name, but confirm it with the user before proceeding. (string, required)\n  - `problem_statement`: Detailed description of the task to be performed (e.g., 'Implement a feature that does X', 'Fix bug Y', etc.) (string, required)\n  - `title`: Title for the pull request that will be created (string, required)\n  - `base_ref`: Git reference (e.g., branch) that the agent will start its work from. If not specified, defaults to the repository's default branch (string, optional)\n\n</details>\n\n<details>\n\n<summary>Copilot Spaces</summary>\n\n- **get_copilot_space** - Get Copilot Space\n  - `owner`: The owner of the space. (string, required)\n  - `name`: The name of the space. (string, required)\n\n- **list_copilot_spaces** - List Copilot Spaces\n\n</details>\n\n<details>\n\n<summary>GitHub Support Docs Search</summary>\n\n- **github_support_docs_search** - Retrieve documentation relevant to answer GitHub product and support questions. Support topics include: GitHub Actions Workflows, Authentication, GitHub Support Inquiries, Pull Request Practices, Repository Maintenance, GitHub Pages, GitHub Packages, GitHub Discussions, Copilot Spaces\n  - `query`: Input from the user about the question they need answered. This is the latest raw unedited user message. You should ALWAYS leave the user message as it is, you should never modify it. (string, required)\n\n</details>\n\n## Dynamic Tool Discovery\n\n**Note**: This feature is currently in beta and is not available in the Remote GitHub MCP Server. Please test it out and let us know if you encounter any issues.\n\nInstead of starting with all tools enabled, you can turn on dynamic toolset discovery. Dynamic toolsets allow the MCP host to list and enable toolsets in response to a user prompt. This should help to avoid situations where the model gets confused by the sheer number of tools available.\n\n### Using Dynamic Tool Discovery\n\nWhen using the binary, you can pass the `--dynamic-toolsets` flag.\n\n```bash\n./github-mcp-server --dynamic-toolsets\n```\n\nWhen using Docker, you can pass the toolsets as environment variables:\n\n```bash\ndocker run -i --rm \\\n  -e GITHUB_PERSONAL_ACCESS_TOKEN=<your-token> \\\n  -e GITHUB_DYNAMIC_TOOLSETS=1 \\\n  ghcr.io/github/github-mcp-server\n```\n\n## Read-Only Mode\n\nTo run the server in read-only mode, you can use the `--read-only` flag. This will only offer read-only tools, preventing any modifications to repositories, issues, pull requests, etc.\n\n```bash\n./github-mcp-server --read-only\n```\n\nWhen using Docker, you can pass the read-only mode as an environment variable:\n\n```bash\ndocker run -i --rm \\\n  -e GITHUB_PERSONAL_ACCESS_TOKEN=<your-token> \\\n  -e GITHUB_READ_ONLY=1 \\\n  ghcr.io/github/github-mcp-server\n```\n\n## Lockdown Mode\n\nLockdown mode limits the content that the server will surface from public repositories. When enabled, the server checks whether the author of each item has push access to the repository. Private repositories are unaffected, and collaborators keep full access to their own content.\n\n```bash\n./github-mcp-server --lockdown-mode\n```\n\nWhen running with Docker, set the corresponding environment variable:\n\n```bash\ndocker run -i --rm \\\n  -e GITHUB_PERSONAL_ACCESS_TOKEN=<your-token> \\\n  -e GITHUB_LOCKDOWN_MODE=1 \\\n  ghcr.io/github/github-mcp-server\n```\n\nThe behavior of lockdown mode depends on the tool invoked.\n\nFollowing tools will return an error when the author lacks the push access:\n\n- `issue_read:get`\n- `pull_request_read:get`\n\nFollowing tools will filter out content from users lacking the push access:\n\n- `issue_read:get_comments`\n- `issue_read:get_sub_issues`\n- `pull_request_read:get_comments`\n- `pull_request_read:get_review_comments`\n- `pull_request_read:get_reviews`\n\n## i18n / Overriding Descriptions\n\nThe descriptions of the tools can be overridden by creating a\n`github-mcp-server-config.json` file in the same directory as the binary.\n\nThe file should contain a JSON object with the tool names as keys and the new\ndescriptions as values. For example:\n\n```json\n{\n  \"TOOL_ADD_ISSUE_COMMENT_DESCRIPTION\": \"an alternative description\",\n  \"TOOL_CREATE_BRANCH_DESCRIPTION\": \"Create a new branch in a GitHub repository\"\n}\n```\n\nYou can create an export of the current translations by running the binary with\nthe `--export-translations` flag.\n\nThis flag will preserve any translations/overrides you have made, while adding\nany new translations that have been added to the binary since the last time you\nexported.\n\n```sh\n./github-mcp-server --export-translations\ncat github-mcp-server-config.json\n```\n\nYou can also use ENV vars to override the descriptions. The environment\nvariable names are the same as the keys in the JSON file, prefixed with\n`GITHUB_MCP_` and all uppercase.\n\nFor example, to override the `TOOL_ADD_ISSUE_COMMENT_DESCRIPTION` tool, you can\nset the following environment variable:\n\n```sh\nexport GITHUB_MCP_TOOL_ADD_ISSUE_COMMENT_DESCRIPTION=\"an alternative description\"\n```\n\n## Library Usage\n\nThe exported Go API of this module should currently be considered unstable, and subject to breaking changes. In the future, we may offer stability; please file an issue if there is a use case where this would be valuable.\n\n## License\n\nThis project is licensed under the terms of the MIT open source license. Please refer to [MIT](./LICENSE) for the full terms.\n",
      "stars_today": 49
    },
    {
      "id": 835103731,
      "name": "colanode",
      "full_name": "colanode/colanode",
      "description": "Open-source and local-first Slack and Notion alternative that puts you in control of your data",
      "html_url": "https://github.com/colanode/colanode",
      "stars": 4505,
      "forks": 250,
      "language": "TypeScript",
      "topics": [
        "chat",
        "chat-application",
        "crdt",
        "editor",
        "electron",
        "knowledge-base",
        "local-first",
        "notion",
        "notion-alternative",
        "realtime-collaboration",
        "self-hosted",
        "slack",
        "sqlite",
        "team-collaboration",
        "wiki",
        "yjs"
      ],
      "created_at": "2024-07-29T07:02:36Z",
      "updated_at": "2026-01-24T01:38:06Z",
      "pushed_at": "2026-01-19T21:17:35Z",
      "open_issues": 31,
      "owner": {
        "login": "colanode",
        "avatar_url": "https://avatars.githubusercontent.com/u/185852128?v=4"
      },
      "readme": "<div align=\"center\">\n<img alt=\"Colanode cover\" src=\"assets/images/colanode-github-cover.jpg\">\n<p></p>\n<a target=\"_blank\" href=\"https://opensource.org/licenses/Apache-2.0\" style=\"background:none\">\n    <img src=\"https://img.shields.io/badge/Licene-Apache_2.0-blue\" style=\"height: 22px;\" />\n</a>\n<a target=\"_blank\" href=\"https://discord.gg/ZsnDwW3289\" style=\"background:none\">\n    <img alt=\"\" src=\"https://img.shields.io/badge/Discord-Colanode-%235865F2\" style=\"height: 22px;\" />\n</a>\n<a href=\"https://x.com/colanode\" target=\"_blank\">\n  <img alt=\"\" src=\"https://img.shields.io/twitter/follow/colanode.svg?style=social&label=Follow\" style=\"height: 22px;\" />\n</a>\n</div>\n\n# Colanode\n\n### Open-source & local-first collaboration workspace that you can self-host\n\nColanode is an all-in-one platform for easy collaboration, built to prioritize your data privacy and control. Designed with a **local-first** approach, it helps teams communicate, organize, and manage projects‚Äîwhether online or offline. With Colanode, you get the flexibility of modern collaboration tools, plus the peace of mind that comes from owning your data.\n\n### What can you do with Colanode?\n\n- **Real-Time Chat:** Stay connected with instant messaging for teams and individuals.\n- **Rich Text Pages:** Create documents, wikis, and notes using an intuitive editor, similar to Notion.\n- **Customizable Databases:** Organize information with structured data, custom fields and dynamic views (table, kanban, calendar).\n- **File Management:** Store, share, and manage files effortlessly within secure workspaces.\n\nBuilt for both individuals and teams, Colanode adapts to your needs, whether you're running a small project, managing a team, or collaborating across an entire organization. With its self-hosted model, you retain full control over your data while enjoying a polished, feature-rich experience.\n\n![Colanode preview](assets/images/colanode-desktop-preview.gif)\n\n## How it works\n\nColanode includes a client app (web or desktop) and a self-hosted server. You can connect to multiple servers with a single app, each containing one or more **workspaces** for different teams or projects. After logging in, you pick a workspace to start collaborating‚Äîsending messages, editing pages, or updating database records.\n\n### Local-first workflow\n\nAll changes you make are saved to a local SQLite database first and then synced to the server. A background process handles this synchronization so you can keep working even if your computer or the server goes offline. Data reads also happen locally, ensuring immediate access to any content you have permissions to view.\n\n### Concurrent edits\n\nColanode relies on **Conflict-free Replicated Data Types (CRDTs)** - powered by [Yjs](https://docs.yjs.dev/) - to allow real-time collaboration on entries like pages or database records. This means multiple people can edit at the same time, and the system gracefully merges everyone's updates. Deletions are also tracked as specialized transactions. Messages and file operations don't support concurrent edits and use simpler database tables.\n\n## Get started for free\n\nThe easiest way to start using Colanode is through our **web app**, accessible instantly at [app.colanode.com](https://app.colanode.com). Simply log in to get started immediately, without any installation. _Please note, the web app is currently in early preview and under testing; you may encounter bugs or compatibility issues in certain browsers._\n\nFor optimal performance, you can install our **desktop app**, available from our [downloads page](https://colanode.com/downloads). Both the web and desktop apps allow you to connect to any of our free beta cloud servers:\n\n- **Colanode Cloud (EU)** ‚Äì hosted in Europe.\n- **Colanode Cloud (US)** ‚Äì hosted in the United States.\n\nBoth cloud servers are currently available in beta and free to use; pricing details will be announced soon.\n\n### Self-host\n\nIf you prefer to host your own Colanode server, check out the [`hosting/`](hosting/) folder which contains the Docker Compose file and deployment configurations. For Kubernetes deployments, see the [`hosting/kubernetes/`](hosting/kubernetes/) folder which includes Helm charts and additional documentation. Here's what you need to run Colanode yourself:\n\n- **Postgres** with the **pgvector** extension.\n- **Redis** (any Redis-compatible service will work, e.g., Valkey).\n- **Storage backend** for user files. Colanode defaults to local filesystem storage, but you can switch to **S3-compatible**, **Google Cloud Storage**, or **Azure Blob Storage** backends by setting `STORAGE_TYPE`.\n- **Colanode server API**, provided as a Docker image.\n\n#### Configuration model\n\n- The server image now ships with a full `config.json`, so most defaults are ready to go without touching env vars.\n- The config file is the single source of truth. Use `env://VAR_NAME` to pull sensitive values from env vars, or `file://path/to/secret.pem` to inline the contents of a mounted file (append `?` to make either optional). Only `POSTGRES_URL` and `REDIS_URL` are required out of the box.\n- To customize settings:\n  1. Copy `apps/server/config.json`, edit it, and mount/bind it when using Docker Compose (see `hosting/docker/docker-compose.yaml`).\n  2. For Helm, enable `colanode.configFile.enabled` and pass your file via `--set-file colanode.configFile.data=./config.json` (details in [`hosting/kubernetes/README.md`](hosting/kubernetes/README.md)).\n  3. Keep secrets as env vars so you don't have to bake them into JSON; the loader resolves `env://` pointers at runtime.\n\nEnvironment variables no longer override regular config fields‚Äîonly values explicitly tagged with `env://` are read from the environment. Refer to [`hosting/docker/docker-compose.yaml`](hosting/docker/docker-compose.yaml) and [`hosting/kubernetes/README.md`](hosting/kubernetes/README.md) for mounting instructions and the handful of required secrets.\n\n### Running locally\n\nTo run Colanode locally in development mode:\n\n1. Clone the repository:\n\n   ```bash\n   git clone https://github.com/colanode/colanode.git\n   cd colanode\n   ```\n\n2. Install dependencies at the project root:\n\n   ```bash\n   npm install\n   ```\n\n3. Start the apps you want to run locally:\n\n   **Server**\n\n   ```bash\n   cd apps/server\n\n   # Copy the environment variable template and adjust values as needed\n   cp .env.example .env\n\n   npm run dev\n   ```\n\n   To spin up the local dependencies (Postgres, Redis, and Mail server) with Docker Compose‚Äîusing filesystem storage\n   by default‚Äîrun this from\n   the project root:\n\n   ```bash\n   docker compose -f hosting/docker/docker-compose.yaml up -d\n   ```\n\n   When you prefer an S3-compatible backend locally, enable the optional MinIO service with the `s3` profile:\n\n   ```bash\n   docker compose -f hosting/docker/docker-compose.yaml --profile s3 up -d\n   ```\n\n   The compose file includes a `server` service. When you want to run the API locally with `npm run dev`, comment\n   out (or override) that service so only the supporting services are started.\n\n   **Web**\n\n   ```bash\n   cd apps/web\n   npm run dev\n   ```\n\n   **Desktop**\n\n   ```bash\n   cd apps/desktop\n   npm run dev\n   ```\n\n## License\n\nColanode is released under the [Apache 2.0 License](LICENSE).\n",
      "stars_today": 47
    },
    {
      "id": 53809090,
      "name": "anime",
      "full_name": "juliangarnier/anime",
      "description": "JavaScript animation engine",
      "html_url": "https://github.com/juliangarnier/anime",
      "stars": 66161,
      "forks": 4428,
      "language": "JavaScript",
      "topics": [
        "animation",
        "anime",
        "canvas",
        "css",
        "javascript",
        "javascript-library",
        "svg"
      ],
      "created_at": "2016-03-13T21:37:45Z",
      "updated_at": "2026-01-23T23:52:18Z",
      "pushed_at": "2026-01-23T17:00:12Z",
      "open_issues": 83,
      "owner": {
        "login": "juliangarnier",
        "avatar_url": "https://avatars.githubusercontent.com/u/1268691?v=4"
      },
      "readme": "# Anime.js\n\n<p align=\"center\">\n  <picture align=\"center\">\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/images/animejs-v4-logo-animation-dark.gif\">\n    <img align=\"center\" alt=\"Anime.js V4 logo animation\" src=\"./assets/images/animejs-v4-logo-animation.gif\" width=\"560\">\n  </picture>\n</p>\n\n<p align=\"center\">\n  <strong>\n  <em>Anime.js</em> is a fast, multipurpose and lightweight JavaScript animation library with a simple, yet powerful API.<br>\n  It works with CSS properties, SVG, DOM attributes and JavaScript Objects.\n  </strong>\n</p>\n\n\n<p align=\"center\">\n  <img alt=\"NPM Downloads\" src=\"https://img.shields.io/npm/dm/animejs?style=flat-square&logo=npm\">\n  <img alt=\"jsDelivr hits (npm)\" src=\"https://img.shields.io/jsdelivr/npm/hm/animejs?style=flat-square&logo=jsdeliver\">\n  <img alt=\"GitHub Sponsors\" src=\"https://img.shields.io/github/sponsors/juliangarnier?style=flat-square&logo=github\">\n</p>\n\n## Sponsors\n\nAnime.js is 100% free and is only made possible with the help of our sponsors.\nHelp the project become sustainable by sponsoring us on <a target=\"_blank\" href=\"https://github.com/sponsors/juliangarnier\">GitHub Sponsors</a>.\n\n### Platinum sponsors\n\n<table>\n  <tbody>\n    <tr>\n      <td>\n        <a target=\"_blank\" href=\"https://ice.io/?ref=animejs\">\n          <picture>\n            <source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/sponsors/ice-open-network-logomark.png?v=200126\">\n            <img align=\"center\" src=\"./assets/sponsors/ice-open-network-logomark-dark.png?v=200126\" width=\"310\">\n          </picture>\n        </a>\n      </td>\n      <td>\n        <a target=\"_blank\" href=\"https://hyperswitch.io/?utm_source=julian&utm_medium=github&utm_campaign=animejs_sponsorship\">\n          <picture>\n            <source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/sponsors/juspay-logomark.png?v=200126\">\n            <img align=\"center\" src=\"./assets/sponsors/juspay-logomark-dark.png?v=200126\" width=\"310\">\n          </picture>\n        </a>\n      </td>\n      <td>\n        <a target=\"_blank\" href=\"https://github.com/sponsors/juliangarnier\">\n          <picture>\n            <img align=\"center\" src=\"./assets/sponsors/placeholder-large.png?v=200126\" width=\"310\">\n          </picture>\n        </a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n### Silver sponsors\n\n<table>\n  <tbody>\n    <tr>\n      <td>\n        <a target=\"_blank\" href=\"https://www.testmu.ai?utm_source=animeJS&utm_medium=organic&utm_campaign=july_08&utm_term=sk&utm_content=opensource\">\n          <picture>\n            <source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/sponsors/testmu-ai-logomark.png?v=200126\">\n            <img align=\"center\" src=\"./assets/sponsors/testmu-ai-logomark-dark.png?v=200126\" width=\"141\">\n          </picture>\n        </a>\n      </td>\n      <td>\n        <a target=\"_blank\" href=\"https://inspatialapp.com/?ref=animejs\">\n          <picture>\n            <source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/sponsors/inspatial-logomark.png?v=200126\">\n            <img align=\"center\" src=\"./assets/sponsors/inspatial-logomark-dark.png?v=200126\" width=\"141\">\n          </picture>\n        </a>\n      </td>\n      <td>\n        <a target=\"_blank\" href=\"https://github.com/sponsors/juliangarnier\">\n          <picture>\n            <img align=\"center\" src=\"./assets/sponsors/placeholder-small.png?v=200126\" width=\"141\">\n          </picture>\n        </a>\n      </td>\n      <td>\n        <a target=\"_blank\" href=\"https://github.com/sponsors/juliangarnier\">\n          <picture>\n            <img align=\"center\" src=\"./assets/sponsors/placeholder-small.png?v=200126\" width=\"141\">\n          </picture>\n        </a>\n      </td>\n      <td>\n        <a target=\"_blank\" href=\"https://github.com/sponsors/juliangarnier\">\n          <picture>\n            <img align=\"center\" src=\"./assets/sponsors/placeholder-small.png?v=200126\" width=\"141\">\n          </picture>\n        </a>\n      </td>\n      <td>\n        <a target=\"_blank\" href=\"https://github.com/sponsors/juliangarnier\">\n          <picture>\n            <img align=\"center\" src=\"./assets/sponsors/placeholder-small.png?v=200126\" width=\"141\">\n          </picture>\n        </a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\nGet featured here by becoming a <a target=\"_blank\" href=\"https://github.com/sponsors/juliangarnier\">GitHub Sponsor</a>.\n\n\n## Usage\n\nAnime.js V4 works by importing ES modules like so:\n\n\n<table>\n<tr>\n  <td>\n\n```javascript\nimport {\n  animate,\n  stagger,\n} from 'animejs';\n\nanimate('.square', {\n  x: 320,\n  rotate: { from: -180 },\n  duration: 1250,\n  delay: stagger(65, { from: 'center' }),\n  ease: 'inOutQuint',\n  loop: true,\n  alternate: true\n});\n```\n\n  </td>\n  <td>\n    <img align=\"center\" alt=\"Anime.js code example\" src=\"./assets/images/usage-example-result.gif\">\n  </td>\n</tr>\n</table>\n\n## V4 Documentation\n\nThe full documentation is available [here](https://animejs.com/documentation).\n\n## V3 Migration guide\n\nYou can find the v3 to v4 migration guide [here](https://github.com/juliangarnier/anime/wiki/Migrating-from-v3-to-v4).\n\n## NPM development scripts\n\nFirst, run `npm i` to install all the necessary packages.\nThen, execute the following scripts with `npm run <script>`.\n\n| script | action |\n| ------ | ------ |\n| `dev` | Watches for changes in `src/**/*.js`, bundles the ESM version to `lib/` and creates type declarations in `types/` |\n| `dev:test` | Runs `dev` and `test:browser` concurrently |\n| `build` | Bundles ESM / UMD / CJS / IIFE versions to `lib/` and creates type declarations in `types/` |\n| `test:browser` | Starts a local server and runs all browser-related tests |\n| `test:node` | Starts Node-related tests |\n| `open:examples` | Starts a local server to browse the examples locally |\n\n¬© [Julian Garnier](http://juliangarnier.com) | [MIT License](LICENSE.md)\n",
      "stars_today": 44
    },
    {
      "id": 1060001762,
      "name": "astron-agent",
      "full_name": "iflytek/astron-agent",
      "description": "Enterprise-grade, commercial-friendly agentic workflow platform for building next-generation SuperAgents.",
      "html_url": "https://github.com/iflytek/astron-agent",
      "stars": 8841,
      "forks": 1111,
      "language": "Java",
      "topics": [
        "agent",
        "agentic-workflow",
        "ai",
        "enterprise",
        "llm",
        "low-code",
        "mcp",
        "multi-agent",
        "next-gen",
        "orchestration",
        "python",
        "superagent",
        "workflow"
      ],
      "created_at": "2025-09-19T08:46:01Z",
      "updated_at": "2026-01-24T00:39:51Z",
      "pushed_at": "2026-01-23T10:04:50Z",
      "open_issues": 69,
      "owner": {
        "login": "iflytek",
        "avatar_url": "https://avatars.githubusercontent.com/u/26786495?v=4"
      },
      "readme": "[![Astron_Readme](./docs/imgs/Astron_Readme.png)](https://agent.xfyun.cn)\n\n<div align=\"center\">\n\n[![License](https://img.shields.io/badge/license-apache2.0-blue.svg)](LICENSE)\n[![GitHub Stars](https://img.shields.io/github/stars/iflytek/astron-agent?style=social)](https://github.com/iflytek/astron-agent/stargazers)\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/iflytek/astron-agent)\n\nEnglish | [ÁÆÄ‰Ωì‰∏≠Êñá](docs/README-zh.md)\n\n</div>\n\n## üî≠ What is Astron Agent\nAstron Agent is an **enterprise-grade, commercial-friendly** Agentic Workflow development platform that integrates AI workflow orchestration, model management, AI and MCP tool integration, RPA automation, and team collaboration features.\nThe platform supports **high-availability** deployment, enabling organizations to rapidly build **scalable, production-ready** intelligent agent applications and establish their AI foundation for the future.\n\n### Why Choose Astron Agent?\n- **Stable and Reliable**: Built on the same core technology as the iFLYTEK Astron Agent Platform, providing enterprise-grade reliability with a fully available high-availability version open source.\n- **Cross-System Integration**: Natively integrates intelligent RPA, efficiently connecting internal and external enterprise systems, enabling seamless interaction between Agents and enterprise systems.\n- **Enterprise-Grade Open Ecosystem**: Deeply compatible with various industry models and tools, supporting custom extensions and flexibly adapting to diverse enterprise scenarios.\n- **Business-Friendly**: Released under the Apache 2.0 License, with no commercial restrictions, allowing free commercial use.\n\n### Key Features\n- **Enterprise-Grade High Availability:** Full-stack capabilities for development, building, optimization, and management. Supports one-click deployment with strong reliability.  \n- **Intelligent RPA Integration:** Enables cross-system process automation, empowering Agents with controllable execution to achieve a complete loop ‚Äúfrom decision to action.‚Äù  \n- **Ready-to-Use Tool Ecosystem:** Integrates massive AI capabilities and tools from the [iFLYTEK Open Platform](https://www.xfyun.cn), validated by millions of developers, supporting plug-and-play integration without extra development.  \n- **Flexible Large Model Support:** Offers diverse access methods, from rapid API-based model access and validation to one-click deployment of enterprise-level MaaS (Model as a Service) on-premises clusters, meeting needs of all scales.  \n\n## üì∞ News\n\n- **[Astron Hackathon @ 2025 iFLYTEK Global 1024 Developer Festival](https://luma.com/9zmbc6xb)**  üé§ <a href=\"https://github.com/mklong\"><img src=\"https://github.com/mklong.png\" width=\"20\" align=\"center\" /> @mklong</a>\n- **[Astron Agent Zhengzhou Meetup](https://github.com/iflytek/astron-agent/discussions/672)**  üé§ <a href=\"https://github.com/lyj715824\"><img src=\"https://github.com/lyj715824.png\" width=\"20\" align=\"center\" /> @lyj715824</a> <a href=\"https://github.com/wowo-zZ\"><img src=\"https://github.com/wowo-zZ.png\" width=\"20\" align=\"center\" /> @wowo-zZ</a>\n- **[Astron on Campus @ Zhejiang University of Finance and Economics](https://mp.weixin.qq.com/s/oim_Z0ckgpFwf5jOskoJuA)**  üé§ <a href=\"https://github.com/lyj715824\"><img src=\"https://github.com/lyj715824.png\" width=\"20\" align=\"center\" /> @lyj715824</a>\n- **[Astron Agent & RPA ¬∑ Qingdao Meetup Brings Agentic AI!](https://github.com/iflytek/astron-agent/discussions/740)**  üé§ <a href=\"https://github.com/vsxd\"><img src=\"https://github.com/vsxd.png\" width=\"20\" align=\"center\" /> @vsxd</a> <a href=\"https://github.com/doctorbruce\"><img src=\"https://github.com/doctorbruce.png\" width=\"20\" align=\"center\" /> @doctorbruce</a> <a href=\"https://github.com/MaxwellJean\"><img src=\"https://github.com/MaxwellJean.png\" width=\"20\" align=\"center\" /> @MaxwellJean</a>\n- **[Astron Training Camp ¬∑ Cohort #1](https://www.aidaxue.com/astronCamp)**  üé§ <a href=\"https://github.com/lyj715824\"><img src=\"https://github.com/lyj715824.png\" width=\"20\" align=\"center\" /> @lyj715824</a>\n- **[Astron Talk @ Chongqing Mini Tech Fest](https://mp.weixin.qq.com/s/HROf1zZpkPVDSsCQrv2jRg)**  üé§ <a href=\"https://github.com/lyj715824\"><img src=\"https://github.com/lyj715824.png\" width=\"20\" align=\"center\" /> @lyj715824</a>\n\n## üöÄ Quick Start\n\nWe offer two deployment methods to meet different scenarios:\n\n### Option 1: Docker Compose (Recommended for Quick Start)\n\n```bash\n# Clone the repository\ngit clone https://github.com/iflytek/astron-agent.git\n\n# Navigate to astronAgent directory\ncd docker/astronAgent\n\n# Copy environment configuration\ncp .env.example .env\n\n# Configure environment variables\nvim .env\n```\n\nFor environment variable configuration, please refer to the documentation:[DEPLOYMENT_GUIDE_WITH_AUTH.md](https://github.com/iflytek/astron-agent/blob/main/docs/DEPLOYMENT_GUIDE_WITH_AUTH.md#step-2-configure-astronagent-environment-variables)\n\n```bash\n# Start all services (including Casdoor)\ndocker compose -f docker-compose-with-auth.yaml up -d\n```\n\n#### üìä Service Access Addresses\n\nAfter startup, you can access the services at the following addresses:\n\n**Authentication Service**\n- **Casdoor Admin Interface**: http://localhost:8000\n\n**AstronAgent**\n- **Application Frontend (nginx proxy)**: http://localhost/\n\n**Note**\n- Default Casdoor login credentials: username: `admin`, password: `123`\n\n### Option 2: Helm (For Kubernetes Environments)\n\n> üöß **Note**: Helm charts are currently under development. Stay tuned for updates!\n\n```bash\n# Coming soon\n# helm repo add astron-agent https://iflytek.github.io/astron-agent\n# helm install astron-agent astron-agent/astron-agent\n```\n\n---\n\n> üìñ For complete deployment instructions and configuration details, see [Deployment Guide](docs/DEPLOYMENT_GUIDE_WITH_AUTH.md)\n\n## üìñ Using Astron Cloud\n\n**Try Astron**ÔºöAstron Cloud provides a ready-to-use environment for creating and managing Agents.Free quick access [https://agent.xfyun.cn](https://agent.xfyun.cn).\n\n**Using Guide**ÔºöFor detailed usage instructions, please refer to [Quick Start Guide](https://www.xfyun.cn/doc/spark/Agent03-%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.html).\n\n## üìö Documentation\n\n- [üöÄ Deployment Guide](docs/DEPLOYMENT_GUIDE.md)\n- [üîß Configuration](docs/CONFIGURATION.md)\n- [üöÄ Quick Start](https://www.xfyun.cn/doc/spark/Agent02-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B.html)\n- [üìò Development Guide](https://www.xfyun.cn/doc/spark/Agent03-%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.html#_1-%E6%8C%87%E4%BB%A4%E5%9E%8B%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%80%E5%8F%91)\n- [üí° Best Practices](https://www.xfyun.cn/doc/spark/AgentNew-%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5%E6%A1%88%E4%BE%8B.html)\n- [üì± Use Cases](https://www.xfyun.cn/doc/spark/Agent05-%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B.html)\n- [‚ùì FAQ](https://www.xfyun.cn/doc/spark/Agent06-FAQ.html)\n\n## ü§ù Contributing\n\nWe welcome contributions of all kinds! Please see our [Contributing Guide](CONTRIBUTING.md)\n\n## üåü Star History\n\n<div align=\"center\">\n  <img src=\"https://api.star-history.com/svg?repos=iflytek/astron-agent&type=Date\" alt=\"Star History Chart\" width=\"600\">\n</div>\n\n## üìû Support\n\n- üí¨ Community Discussion: [GitHub Discussions](https://github.com/iflytek/astron-agent/discussions)\n- üêõ Bug Reports: [Issues](https://github.com/iflytek/astron-agent/issues)\n- üë• WeChat Work Group:\n\n<div align=\"center\">\n  <img src=\"./docs/imgs/WeCom_Group.png\" alt=\"WeChat Work Group\" width=\"300\">\n</div>\n\n## üìÑ Open Source License\n\nThis project is licensed under the [Apache 2.0 License](LICENSE), allowing free use, modification, distribution, and commercial use without any restrictions.\n\n",
      "stars_today": 43
    },
    {
      "id": 1019432584,
      "name": "claude-relay-service",
      "full_name": "Wei-Shaw/claude-relay-service",
      "description": "CRS-Ëá™Âª∫Claude CodeÈïúÂÉèÔºå‰∏ÄÁ´ôÂºèÂºÄÊ∫ê‰∏≠ËΩ¨ÊúçÂä°ÔºåËÆ© Claude„ÄÅOpenAI„ÄÅGemini„ÄÅDroid ËÆ¢ÈòÖÁªü‰∏ÄÊé•ÂÖ•ÔºåÊîØÊåÅÊãºËΩ¶ÂÖ±‰∫´ÔºåÊõ¥È´òÊïàÂàÜÊëäÊàêÊú¨ÔºåÂéüÁîüÂ∑•ÂÖ∑Êó†Áºù‰ΩøÁî®„ÄÇ",
      "html_url": "https://github.com/Wei-Shaw/claude-relay-service",
      "stars": 7409,
      "forks": 1236,
      "language": "JavaScript",
      "topics": [
        "claude",
        "claude-api",
        "claude-code",
        "claude-proxy",
        "codex-cli",
        "crs",
        "droid",
        "droid-cli",
        "droid2api",
        "gemini-cli"
      ],
      "created_at": "2025-07-14T10:11:32Z",
      "updated_at": "2026-01-24T01:54:10Z",
      "pushed_at": "2026-01-23T11:17:05Z",
      "open_issues": 177,
      "owner": {
        "login": "Wei-Shaw",
        "avatar_url": "https://avatars.githubusercontent.com/u/26101719?v=4"
      },
      "readme": "# Claude Relay Service\n\n> [!CAUTION]\n> **ÂÆâÂÖ®Êõ¥Êñ∞ÈÄöÁü•**Ôºöv1.1.248 Âèä‰ª•‰∏ãÁâàÊú¨Â≠òÂú®‰∏•ÈáçÁöÑÁÆ°ÁêÜÂëòËÆ§ËØÅÁªïËøáÊºèÊ¥ûÔºåÊîªÂáªËÄÖÂèØÊú™ÊéàÊùÉËÆøÈóÆÁÆ°ÁêÜÈù¢Êùø„ÄÇ\n>\n> **ËØ∑Á´ãÂç≥Êõ¥Êñ∞Âà∞ v1.1.249+ ÁâàÊú¨**ÔºåÊàñËøÅÁßªÂà∞Êñ∞‰∏Ä‰ª£È°πÁõÆ **[CRS 2.0 (sub2api)](https://github.com/Wei-Shaw/sub2api)**\n\n<div align=\"center\">\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Node.js](https://img.shields.io/badge/Node.js-18+-green.svg)](https://nodejs.org/)\n[![Redis](https://img.shields.io/badge/Redis-6+-red.svg)](https://redis.io/)\n[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)\n[![Docker Build](https://github.com/Wei-Shaw/claude-relay-service/actions/workflows/auto-release-pipeline.yml/badge.svg)](https://github.com/Wei-Shaw/claude-relay-service/actions/workflows/auto-release-pipeline.yml)\n[![Docker Pulls](https://img.shields.io/docker/pulls/weishaw/claude-relay-service)](https://hub.docker.com/r/weishaw/claude-relay-service)\n\n**üîê Ëá™Ë°åÊê≠Âª∫Claude API‰∏≠ËΩ¨ÊúçÂä°ÔºåÊîØÊåÅÂ§öË¥¶Êà∑ÁÆ°ÁêÜ**\n\n[English](README_EN.md) ‚Ä¢ [Âø´ÈÄüÂºÄÂßã](https://pincc.ai/) ‚Ä¢ [ÊºîÁ§∫Á´ôÁÇπ](https://demo.pincc.ai/admin-next/login) ‚Ä¢ [ÂÖ¨ÂëäÈ¢ëÈÅì](https://t.me/claude_relay_service)\n\n</div>\n\n---\n\n## üíé Claude/Codex ÊãºËΩ¶ÊúçÂä°Êé®Ëçê\n\n<div align=\"center\">\n\n| Âπ≥Âè∞ | Á±ªÂûã | ÊúçÂä° | ‰ªãÁªç |\n|:---|:---|:---|:---|\n| **[pincc.ai](https://pincc.ai/)** | üèÜ **ÂÆòÊñπËøêËê•** | <small>‚úÖ Claude Code<br>‚úÖ Codex CLI</small> | È°πÁõÆÁõ¥Ëê•ÔºåÊèê‰æõÁ®≥ÂÆöÁöÑ Claude Code / Codex CLI ÊãºËΩ¶ÊúçÂä° |\n| **[ctok.ai](https://ctok.ai/)** | ü§ù Âêà‰Ωú‰ºô‰º¥ | <small>‚úÖ Claude Code<br>‚úÖ Codex CLI</small> | Á§æÂå∫ËÆ§ËØÅÔºåÊèê‰æõ Claude Code / Codex CLI ÊãºËΩ¶ |\n\n\n</div>\n\n---\n\n## ‚ö†Ô∏è ÈáçË¶ÅÊèêÈÜí\n\n**‰ΩøÁî®Êú¨È°πÁõÆÂâçËØ∑‰ªîÁªÜÈòÖËØªÔºö**\n\nüö® **ÊúçÂä°Êù°Ê¨æÈ£éÈô©**: ‰ΩøÁî®Êú¨È°πÁõÆÂèØËÉΩËøùÂèçAnthropicÁöÑÊúçÂä°Êù°Ê¨æ„ÄÇËØ∑Âú®‰ΩøÁî®Ââç‰ªîÁªÜÈòÖËØªAnthropicÁöÑÁî®Êà∑ÂçèËÆÆÔºå‰ΩøÁî®Êú¨È°πÁõÆÁöÑ‰∏ÄÂàáÈ£éÈô©Áî±Áî®Êà∑Ëá™Ë°åÊâøÊãÖ„ÄÇ\n\nüìñ **ÂÖçË¥£Â£∞Êòé**: Êú¨È°πÁõÆ‰ªÖ‰æõÊäÄÊúØÂ≠¶‰π†ÂíåÁ†îÁ©∂‰ΩøÁî®Ôºå‰ΩúËÄÖ‰∏çÂØπÂõ†‰ΩøÁî®Êú¨È°πÁõÆÂØºËá¥ÁöÑË¥¶Êà∑Â∞ÅÁ¶Å„ÄÅÊúçÂä°‰∏≠Êñ≠ÊàñÂÖ∂‰ªñÊçüÂ§±ÊâøÊãÖ‰ªª‰ΩïË¥£‰ªª„ÄÇ\n\n\n## ü§î Ëøô‰∏™È°πÁõÆÈÄÇÂêà‰Ω†ÂêóÔºü\n\n- üåç **Âú∞Âå∫ÈôêÂà∂**: ÊâÄÂú®Âú∞Âå∫Êó†Ê≥ïÁõ¥Êé•ËÆøÈóÆClaude CodeÊúçÂä°Ôºü\n- üîí **ÈöêÁßÅÊãÖÂøß**: ÊãÖÂøÉÁ¨¨‰∏âÊñπÈïúÂÉèÊúçÂä°‰ºöËÆ∞ÂΩïÊàñÊ≥ÑÈú≤‰Ω†ÁöÑÂØπËØùÂÜÖÂÆπÔºü\n- üë• **ÊàêÊú¨ÂàÜÊëä**: ÊÉ≥ÂíåÊúãÂèã‰∏ÄËµ∑ÂàÜÊëäClaude Code MaxËÆ¢ÈòÖË¥πÁî®Ôºü\n- ‚ö° **Á®≥ÂÆöÊÄß**: Á¨¨‰∏âÊñπÈïúÂÉèÁ´ôÁªèÂ∏∏ÊïÖÈöú‰∏çÁ®≥ÂÆöÔºåÂΩ±ÂìçÊïàÁéá Ôºü\n\nÂ¶ÇÊûúÊúâ‰ª•‰∏äÂõ∞ÊÉëÔºåÈÇ£Ëøô‰∏™È°πÁõÆÂèØËÉΩÈÄÇÂêà‰Ω†„ÄÇ\n\n### ÈÄÇÂêàÁöÑÂú∫ÊôØ\n\n‚úÖ **ÊâæÊúãÂèãÊãºËΩ¶**: ‰∏â‰∫îÂ•ΩÂèã‰∏ÄËµ∑ÂàÜÊëäClaude Code MaxËÆ¢ÈòÖ  \n‚úÖ **ÈöêÁßÅÊïèÊÑü**: ‰∏çÊÉ≥ËÆ©Á¨¨‰∏âÊñπÈïúÂÉèÁúãÂà∞‰Ω†ÁöÑÂØπËØùÂÜÖÂÆπ  \n‚úÖ **ÊäÄÊúØÊäòËÖæ**: ÊúâÂü∫Êú¨ÁöÑÊäÄÊúØÂü∫Á°ÄÔºåÊÑøÊÑèËá™Â∑±Êê≠Âª∫ÂíåÁª¥Êä§  \n‚úÖ **Á®≥ÂÆöÈúÄÊ±Ç**: ÈúÄË¶ÅÈïøÊúüÁ®≥ÂÆöÁöÑClaudeËÆøÈóÆÔºå‰∏çÊÉ≥ÂèóÂà∂‰∫éÈïúÂÉèÁ´ô  \n‚úÖ **Âú∞Âå∫ÂèóÈôê**: Êó†Ê≥ïÁõ¥Êé•ËÆøÈóÆClaudeÂÆòÊñπÊúçÂä°\n\n---\n\n## üí≠ ‰∏∫‰ªÄ‰πàË¶ÅËá™Â∑±Êê≠Ôºü\n\n### Áé∞ÊúâÈïúÂÉèÁ´ôÂèØËÉΩÁöÑÈóÆÈ¢ò\n\n- üïµÔ∏è **ÈöêÁßÅÈ£éÈô©**: ‰Ω†ÁöÑÂØπËØùÂÜÖÂÆπÈÉΩË¢´‰∫∫ÂÆ∂ÁúãÂæó‰∏ÄÊ∏Ö‰∫åÊ•öÔºåÂïÜ‰∏öÊú∫ÂØÜ‰ªÄ‰πàÁöÑÂ∞±Âà´ÊÉ≥‰∫Ü\n- üêå **ÊÄßËÉΩ‰∏çÁ®≥**: Áî®ÁöÑ‰∫∫Â§ö‰∫ÜÂ∞±ÊÖ¢ÔºåÈ´òÂ≥∞ÊúüÁªèÂ∏∏Âç°Ê≠ª\n- üí∞ **‰ª∑Ê†º‰∏çÈÄèÊòé**: ‰∏çÁü•ÈÅìÂÆûÈôÖÊàêÊú¨\n\n### Ëá™Âª∫ÁöÑÂ•ΩÂ§Ñ\n\n- üîê **Êï∞ÊçÆÂÆâÂÖ®**: ÊâÄÊúâÊé•Âè£ËØ∑Ê±ÇÈÉΩÂè™ÁªèËøá‰Ω†Ëá™Â∑±ÁöÑÊúçÂä°Âô®ÔºåÁõ¥ËøûAnthropic API\n- ‚ö° **ÊÄßËÉΩÂèØÊéß**: Â∞±‰Ω†‰ª¨Âá†‰∏™‰∫∫Áî®ÔºåMax 200ÂàÄÂ•óÈ§êÂü∫Êú¨‰∏äÂèØ‰ª•ÁàΩÁî®Opus\n- üí∞ **ÊàêÊú¨ÈÄèÊòé**: Áî®‰∫ÜÂ§öÂ∞ëtoken‰∏ÄÁõÆ‰∫ÜÁÑ∂ÔºåÊåâÂÆòÊñπ‰ª∑Ê†ºÊç¢ÁÆó‰∫ÜÂÖ∑‰ΩìË¥πÁî®\n- üìä **ÁõëÊéßÂÆåÊï¥**: ‰ΩøÁî®ÊÉÖÂÜµ„ÄÅÊàêÊú¨ÂàÜÊûê„ÄÅÊÄßËÉΩÁõëÊéßÂÖ®ÈÉΩÊúâ\n\n---\n\n## üöÄ Ê†∏ÂøÉÂäüËÉΩ\n\n### Âü∫Á°ÄÂäüËÉΩ\n\n- ‚úÖ **Â§öË¥¶Êà∑ÁÆ°ÁêÜ**: ÂèØ‰ª•Ê∑ªÂä†Â§ö‰∏™ClaudeË¥¶Êà∑Ëá™Âä®ËΩÆÊç¢\n- ‚úÖ **Ëá™ÂÆö‰πâAPI Key**: ÁªôÊØè‰∏™‰∫∫ÂàÜÈÖçÁã¨Á´ãÁöÑKey\n- ‚úÖ **‰ΩøÁî®ÁªüËÆ°**: ËØ¶ÁªÜËÆ∞ÂΩïÊØè‰∏™‰∫∫Áî®‰∫ÜÂ§öÂ∞ëtoken\n\n### È´òÁ∫ßÂäüËÉΩ\n\n- üîÑ **Êô∫ËÉΩÂàáÊç¢**: Ë¥¶Êà∑Âá∫ÈóÆÈ¢òËá™Âä®Êç¢‰∏ã‰∏Ä‰∏™\n- üöÄ **ÊÄßËÉΩ‰ºòÂåñ**: ËøûÊé•Ê±†„ÄÅÁºìÂ≠òÔºåÂáèÂ∞ëÂª∂Ëøü\n- üìä **ÁõëÊéßÈù¢Êùø**: WebÁïåÈù¢Êü•ÁúãÊâÄÊúâÊï∞ÊçÆ\n- üõ°Ô∏è **ÂÆâÂÖ®ÊéßÂà∂**: ËÆøÈóÆÈôêÂà∂„ÄÅÈÄüÁéáÊéßÂà∂„ÄÅÂÆ¢Êà∑Á´ØÈôêÂà∂\n- üåê **‰ª£ÁêÜÊîØÊåÅ**: ÊîØÊåÅHTTP/SOCKS5‰ª£ÁêÜ\n\n---\n\n## üìã ÈÉ®ÁΩ≤Ë¶ÅÊ±Ç\n\n### Á°¨‰ª∂Ë¶ÅÊ±ÇÔºàÊúÄ‰ΩéÈÖçÁΩÆÔºâ\n\n- **CPU**: 1Ê†∏ÂøÉÂ∞±Â§ü‰∫Ü\n- **ÂÜÖÂ≠ò**: 512MBÔºàÂª∫ËÆÆ1GBÔºâ\n- **Á°¨Áõò**: 30GBÂèØÁî®Á©∫Èó¥\n- **ÁΩëÁªú**: ËÉΩËÆøÈóÆÂà∞Anthropic APIÔºàÂª∫ËÆÆ‰ΩøÁî®USÂú∞Âå∫ÁöÑÊú∫Âô®Ôºâ\n- **Âª∫ËÆÆ**: 2Ê†∏4GÁöÑÂü∫Êú¨Â§ü‰∫ÜÔºåÁΩëÁªúÂ∞ΩÈáèÈÄâÂõûÂõΩÁ∫øË∑ØÂø´‰∏ÄÁÇπÁöÑÔºà‰∏∫‰∫ÜÊèêÈ´òÈÄüÂ∫¶ÔºåÂª∫ËÆÆ‰∏çË¶ÅÂºÄ‰ª£ÁêÜÊàñËÄÖËÆæÁΩÆÊúçÂä°Âô®ÁöÑIPÁõ¥ËøûÔºâ\n- **ÁªèÈ™å**: ÈòøÈáå‰∫ë„ÄÅËÖæËÆØ‰∫ëÁöÑÊµ∑Â§ñ‰∏ªÊú∫ÁªèÊµãËØï‰ºöË¢´CloudflareÊã¶Êà™ÔºåÊó†Ê≥ïÁõ¥Êé•ËÆøÈóÆclaude api\n\n### ËΩØ‰ª∂Ë¶ÅÊ±Ç\n\n- **Node.js** 18ÊàñÊõ¥È´òÁâàÊú¨\n- **Redis** 6ÊàñÊõ¥È´òÁâàÊú¨\n- **Êìç‰ΩúÁ≥ªÁªü**: Âª∫ËÆÆLinux\n\n### Ë¥πÁî®‰º∞ÁÆó\n\n- **ÊúçÂä°Âô®**: ËΩªÈáè‰∫ëÊúçÂä°Âô®Ôºå‰∏Ä‰∏™Êúà30-60Âùó\n- **ClaudeËÆ¢ÈòÖ**: Áúã‰Ω†ÊÄé‰πàÂàÜÊëä‰∫Ü\n- **ÂÖ∂‰ªñ**: ÂüüÂêçÔºàÂèØÈÄâÔºâ\n\n---\n\n## üöÄ ËÑöÊú¨ÈÉ®ÁΩ≤ÔºàÊé®ËçêÔºâ\n\nÊé®Ëçê‰ΩøÁî®ÁÆ°ÁêÜËÑöÊú¨ËøõË°å‰∏ÄÈîÆÈÉ®ÁΩ≤ÔºåÁÆÄÂçïÂø´Êç∑ÔºåËá™Âä®Â§ÑÁêÜÊâÄÊúâ‰æùËµñÂíåÈÖçÁΩÆ„ÄÇ\n\n### Âø´ÈÄüÂÆâË£Ö\n\n```bash\ncurl -fsSL https://pincc.ai/manage.sh -o manage.sh && chmod +x manage.sh && ./manage.sh install\n```\n\n### ËÑöÊú¨ÂäüËÉΩ\n\n- ‚úÖ **‰∏ÄÈîÆÂÆâË£Ö**: Ëá™Âä®Ê£ÄÊµãÁ≥ªÁªüÁéØÂ¢ÉÔºåÂÆâË£Ö Node.js 18+„ÄÅRedis Á≠â‰æùËµñ\n- ‚úÖ **‰∫§‰∫íÂºèÈÖçÁΩÆ**: ÂèãÂ•ΩÁöÑÈÖçÁΩÆÂêëÂØºÔºåËÆæÁΩÆÁ´ØÂè£„ÄÅRedis ËøûÊé•Á≠â\n- ‚úÖ **Ëá™Âä®ÂêØÂä®**: ÂÆâË£ÖÂÆåÊàêÂêéËá™Âä®ÂêØÂä®ÊúçÂä°Âπ∂ÊòæÁ§∫ËÆøÈóÆÂú∞ÂùÄ\n- ‚úÖ **‰æøÊç∑ÁÆ°ÁêÜ**: ÈÄöËøá `crs` ÂëΩ‰ª§ÈöèÊó∂ÁÆ°ÁêÜÊúçÂä°Áä∂ÊÄÅ\n\n### ÁÆ°ÁêÜÂëΩ‰ª§\n\n```bash\ncrs install   # ÂÆâË£ÖÊúçÂä°\ncrs start     # ÂêØÂä®ÊúçÂä°\ncrs stop      # ÂÅúÊ≠¢ÊúçÂä°\ncrs restart   # ÈáçÂêØÊúçÂä°\ncrs status    # Êü•ÁúãÁä∂ÊÄÅ\ncrs update    # Êõ¥Êñ∞ÊúçÂä°\ncrs uninstall # Âç∏ËΩΩÊúçÂä°\n```\n\n### ÂÆâË£ÖÁ§∫‰æã\n\n```bash\n$ crs install\n\n# ‰ºö‰æùÊ¨°ËØ¢ÈóÆÔºö\nÂÆâË£ÖÁõÆÂΩï (ÈªòËÆ§: ~/claude-relay-service):\nÊúçÂä°Á´ØÂè£ (ÈªòËÆ§: 3000): 8080\nRedis Âú∞ÂùÄ (ÈªòËÆ§: localhost):\nRedis Á´ØÂè£ (ÈªòËÆ§: 6379):\nRedis ÂØÜÁ†Å (ÈªòËÆ§: Êó†ÂØÜÁ†Å):\n\n# ÂÆâË£ÖÂÆåÊàêÂêéËá™Âä®ÂêØÂä®Âπ∂ÊòæÁ§∫Ôºö\nÊúçÂä°Â∑≤ÊàêÂäüÂÆâË£ÖÂπ∂ÂêØÂä®ÔºÅ\n\nËÆøÈóÆÂú∞ÂùÄÔºö\n  Êú¨Âú∞ Web: http://localhost:8080/web\n  ÂÖ¨ÁΩë Web: http://YOUR_IP:8080/web\n\nÁÆ°ÁêÜÂëòË¥¶Âè∑‰ø°ÊÅØÂ∑≤‰øùÂ≠òÂà∞: data/init.json\n```\n\n### Á≥ªÁªüË¶ÅÊ±Ç\n\n- ÊîØÊåÅÁ≥ªÁªü: Ubuntu/Debian„ÄÅCentOS/RedHat„ÄÅArch Linux„ÄÅmacOS\n- Ëá™Âä®ÂÆâË£Ö Node.js 18+ Âíå Redis\n- Redis ‰ΩøÁî®Á≥ªÁªüÈªòËÆ§‰ΩçÁΩÆÔºåÊï∞ÊçÆÁã¨Á´ã‰∫éÂ∫îÁî®\n\n---\n\n## üì¶ ÊâãÂä®ÈÉ®ÁΩ≤\n\n### Á¨¨‰∏ÄÊ≠•ÔºöÁéØÂ¢ÉÂáÜÂ§á\n\n**Ubuntu/DebianÁî®Êà∑Ôºö**\n\n```bash\n# ÂÆâË£ÖNode.js\ncurl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -\nsudo apt-get install -y nodejs\n\n# ÂÆâË£ÖRedis\nsudo apt update\nsudo apt install redis-server\nsudo systemctl start redis-server\n```\n\n**CentOS/RHELÁî®Êà∑Ôºö**\n\n```bash\n# ÂÆâË£ÖNode.js\ncurl -fsSL https://rpm.nodesource.com/setup_18.x | sudo bash -\nsudo yum install -y nodejs\n\n# ÂÆâË£ÖRedis\nsudo yum install redis\nsudo systemctl start redis\n```\n\n### Á¨¨‰∫åÊ≠•Ôºö‰∏ãËΩΩÂíåÈÖçÁΩÆ\n\n```bash\n# ‰∏ãËΩΩÈ°πÁõÆ\ngit clone https://github.com/Wei-Shaw//claude-relay-service.git\ncd claude-relay-service\n\n# ÂÆâË£Ö‰æùËµñ\nnpm install\n\n# Â§çÂà∂ÈÖçÁΩÆÊñá‰ª∂ÔºàÈáçË¶ÅÔºÅÔºâ\ncp config/config.example.js config/config.js\ncp .env.example .env\n```\n\n### Á¨¨‰∏âÊ≠•ÔºöÈÖçÁΩÆÊñá‰ª∂ËÆæÁΩÆ\n\n**ÁºñËæë `.env` Êñá‰ª∂Ôºö**\n\n```bash\n# Ëøô‰∏§‰∏™ÂØÜÈí•Èöè‰æøÁîüÊàêÔºå‰ΩÜË¶ÅËÆ∞‰Ωè\nJWT_SECRET=‰Ω†ÁöÑË∂ÖÁ∫ßÁßòÂØÜÂØÜÈí•\nENCRYPTION_KEY=32‰ΩçÁöÑÂä†ÂØÜÂØÜÈí•Èöè‰æøÂÜô\n\n# RedisÈÖçÁΩÆ\nREDIS_HOST=localhost\nREDIS_PORT=6379\nREDIS_PASSWORD=\n\n```\n\n**ÁºñËæë `config/config.js` Êñá‰ª∂Ôºö**\n\n```javascript\nmodule.exports = {\n  server: {\n    port: 3000, // ÊúçÂä°Á´ØÂè£ÔºåÂèØ‰ª•Êîπ\n    host: '0.0.0.0' // ‰∏çÁî®Êîπ\n  },\n  redis: {\n    host: '127.0.0.1', // RedisÂú∞ÂùÄ\n    port: 6379 // RedisÁ´ØÂè£\n  }\n  // ÂÖ∂‰ªñÈÖçÁΩÆ‰øùÊåÅÈªòËÆ§Â∞±Ë°å\n}\n```\n\n### Á¨¨ÂõõÊ≠•ÔºöÂÆâË£ÖÂâçÁ´Ø‰æùËµñÂπ∂ÊûÑÂª∫\n\n```bash\n# ÂÆâË£ÖÂâçÁ´Ø‰æùËµñ\nnpm run install:web\n\n# ÊûÑÂª∫ÂâçÁ´ØÔºàÁîüÊàê dist ÁõÆÂΩïÔºâ\nnpm run build:web\n```\n\n### Á¨¨‰∫îÊ≠•ÔºöÂêØÂä®ÊúçÂä°\n\n```bash\n# ÂàùÂßãÂåñ\nnpm run setup # ‰ºöÈöèÊú∫ÁîüÊàêÂêéÂè∞Ë¥¶Âè∑ÂØÜÁ†Å‰ø°ÊÅØÔºåÂ≠òÂÇ®Âú® data/init.json\n# ÊàñËÄÖÈÄöËøáÁéØÂ¢ÉÂèòÈáèÈ¢ÑËÆæÁÆ°ÁêÜÂëòÂá≠ÊçÆÔºö\n# export ADMIN_USERNAME=cr_admin_custom\n# export ADMIN_PASSWORD=your-secure-password\n\n# ÂêØÂä®ÊúçÂä°\nnpm run service:start:daemon   # ÂêéÂè∞ËøêË°å\n\n# Êü•ÁúãÁä∂ÊÄÅ\nnpm run service:status\n```\n\n---\n\n## üê≥ Docker ÈÉ®ÁΩ≤\n\n### Docker compose\n\n#### Á¨¨‰∏ÄÊ≠•Ôºö‰∏ãËΩΩÊûÑÂª∫docker-compose.ymlÊñá‰ª∂ÁöÑËÑöÊú¨Âπ∂ÊâßË°å\n```bash\ncurl -fsSL https://pincc.ai/crs-compose.sh -o crs-compose.sh && chmod +x crs-compose.sh && ./crs-compose.sh\n```\n\n#### Á¨¨‰∫åÊ≠•ÔºöÂêØÂä®\n```bash\ndocker-compose up -d\n```\n\n### Docker Compose ÈÖçÁΩÆ\n\ndocker-compose.yml Â∑≤ÂåÖÂê´Ôºö\n\n- ‚úÖ Ëá™Âä®ÂàùÂßãÂåñÁÆ°ÁêÜÂëòË¥¶Âè∑\n- ‚úÖ Êï∞ÊçÆÊåÅ‰πÖÂåñÔºàlogsÂíådataÁõÆÂΩïËá™Âä®ÊåÇËΩΩÔºâ\n- ‚úÖ RedisÊï∞ÊçÆÂ∫ì\n- ‚úÖ ÂÅ•Â∫∑Ê£ÄÊü•\n- ‚úÖ Ëá™Âä®ÈáçÂêØ\n\n### ÁéØÂ¢ÉÂèòÈáèËØ¥Êòé\n\n#### ÂøÖÂ°´È°π\n\n- `JWT_SECRET`: JWTÂØÜÈí•ÔºåËá≥Â∞ë32‰∏™Â≠óÁ¨¶\n- `ENCRYPTION_KEY`: Âä†ÂØÜÂØÜÈí•ÔºåÂøÖÈ°ªÊòØ32‰∏™Â≠óÁ¨¶\n\n#### ÂèØÈÄâÈ°π\n\n- `ADMIN_USERNAME`: ÁÆ°ÁêÜÂëòÁî®Êà∑ÂêçÔºà‰∏çËÆæÁΩÆÂàôËá™Âä®ÁîüÊàêÔºâ\n- `ADMIN_PASSWORD`: ÁÆ°ÁêÜÂëòÂØÜÁ†ÅÔºà‰∏çËÆæÁΩÆÂàôËá™Âä®ÁîüÊàêÔºâ\n- `LOG_LEVEL`: Êó•ÂøóÁ∫ßÂà´ÔºàÈªòËÆ§ÔºöinfoÔºâ\n- Êõ¥Â§öÈÖçÁΩÆÈ°πËØ∑ÂèÇËÄÉ `.env.example` Êñá‰ª∂\n\n### ÁÆ°ÁêÜÂëòÂá≠ÊçÆËé∑ÂèñÊñπÂºè\n\n1. **Êü•ÁúãÂÆπÂô®Êó•Âøó**\n\n   ```bash\n   docker logs claude-relay-service\n   ```\n\n2. **Êü•ÁúãÊåÇËΩΩÁöÑÊñá‰ª∂**\n\n   ```bash\n   cat ./data/init.json\n   ```\n\n3. **‰ΩøÁî®ÁéØÂ¢ÉÂèòÈáèÈ¢ÑËÆæ**\n   ```bash\n   # Âú® .env Êñá‰ª∂‰∏≠ËÆæÁΩÆ\n   ADMIN_USERNAME=cr_admin_custom\n   ADMIN_PASSWORD=your-secure-password\n   ```\n\n---\n\n## üéÆ ÂºÄÂßã‰ΩøÁî®\n\n### 1. ÊâìÂºÄÁÆ°ÁêÜÁïåÈù¢\n\nÊµèËßàÂô®ËÆøÈóÆÔºö`http://‰Ω†ÁöÑÊúçÂä°Âô®IP:3000/web`\n\nÁÆ°ÁêÜÂëòË¥¶Âè∑Ôºö\n\n- Ëá™Âä®ÁîüÊàêÔºöÊü•Áúã data/init.json\n- ÁéØÂ¢ÉÂèòÈáèÈ¢ÑËÆæÔºöÈÄöËøá ADMIN_USERNAME Âíå ADMIN_PASSWORD ËÆæÁΩÆ\n- Docker ÈÉ®ÁΩ≤ÔºöÊü•ÁúãÂÆπÂô®Êó•Âøó `docker logs claude-relay-service`\n\n### 2. Ê∑ªÂä†ClaudeË¥¶Êà∑\n\nËøô‰∏ÄÊ≠•ÊØîËæÉÂÖ≥ÈîÆÔºåÈúÄË¶ÅOAuthÊéàÊùÉÔºö\n\n1. ÁÇπÂáª„ÄåClaudeË¥¶Êà∑„ÄçÊ†áÁ≠æ\n2. Â¶ÇÊûú‰Ω†ÊãÖÂøÉÂ§ö‰∏™Ë¥¶Âè∑ÂÖ±Áî®1‰∏™IPÊÄïË¢´Â∞ÅÁ¶ÅÔºåÂèØ‰ª•ÈÄâÊã©ËÆæÁΩÆÈùôÊÄÅ‰ª£ÁêÜIPÔºàÂèØÈÄâÔºâ\n3. ÁÇπÂáª„ÄåÊ∑ªÂä†Ë¥¶Êà∑„Äç\n4. ÁÇπÂáª„ÄåÁîüÊàêÊéàÊùÉÈìæÊé•„ÄçÔºå‰ºöÊâìÂºÄ‰∏Ä‰∏™Êñ∞È°µÈù¢\n5. Âú®Êñ∞È°µÈù¢ÂÆåÊàêClaudeÁôªÂΩïÂíåÊéàÊùÉ\n6. Â§çÂà∂ËøîÂõûÁöÑAuthorization Code\n7. Á≤òË¥¥Âà∞È°µÈù¢ÂÆåÊàêÊ∑ªÂä†\n\n**Ê≥®ÊÑè**: Â¶ÇÊûú‰Ω†Âú®ÂõΩÂÜÖÔºåËøô‰∏ÄÊ≠•ÂèØËÉΩÈúÄË¶ÅÁßëÂ≠¶‰∏äÁΩë„ÄÇ\n\n### 3. ÂàõÂª∫API Key\n\nÁªôÊØè‰∏™‰ΩøÁî®ËÄÖÂàÜÈÖç‰∏Ä‰∏™KeyÔºö\n\n1. ÁÇπÂáª„ÄåAPI Keys„ÄçÊ†áÁ≠æ\n2. ÁÇπÂáª„ÄåÂàõÂª∫Êñ∞Key„Äç\n3. ÁªôKeyËµ∑‰∏™ÂêçÂ≠óÔºåÊØîÂ¶Ç„ÄåÂº†‰∏âÁöÑKey„Äç\n4. ËÆæÁΩÆ‰ΩøÁî®ÈôêÂà∂ÔºàÂèØÈÄâÔºâÔºö\n   - **ÈÄüÁéáÈôêÂà∂**: ÈôêÂà∂ÊØè‰∏™Êó∂Èó¥Á™óÂè£ÁöÑËØ∑Ê±ÇÊ¨°Êï∞ÂíåToken‰ΩøÁî®Èáè\n   - **Âπ∂ÂèëÈôêÂà∂**: ÈôêÂà∂ÂêåÊó∂Â§ÑÁêÜÁöÑËØ∑Ê±ÇÊï∞\n   - **Ê®°ÂûãÈôêÂà∂**: ÈôêÂà∂ÂèØËÆøÈóÆÁöÑÊ®°ÂûãÂàóË°®\n   - **ÂÆ¢Êà∑Á´ØÈôêÂà∂**: ÈôêÂà∂Âè™ÂÖÅËÆ∏ÁâπÂÆöÂÆ¢Êà∑Á´Ø‰ΩøÁî®ÔºàÂ¶ÇClaudeCode„ÄÅGemini-CLIÁ≠âÔºâ\n5. ‰øùÂ≠òÔºåËÆ∞‰∏ãÁîüÊàêÁöÑKey\n\n### 4. ÂºÄÂßã‰ΩøÁî® Claude Code Âíå Gemini CLI\n\nÁé∞Âú®‰Ω†ÂèØ‰ª•Áî®Ëá™Â∑±ÁöÑÊúçÂä°ÊõøÊç¢ÂÆòÊñπAPI‰∫ÜÔºö\n\n**Claude Code ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáèÔºö**\n\n\n**‰ΩøÁî®Ê†áÂáÜ Claude Ë¥¶Âè∑Ê±†**\n\nÈªòËÆ§‰ΩøÁî®Ê†áÂáÜ Claude Ë¥¶Âè∑Ê±†Ôºö\n\n```bash\nexport ANTHROPIC_BASE_URL=\"http://127.0.0.1:3000/api/\" # Ê†πÊçÆÂÆûÈôÖÂ°´ÂÜô‰Ω†ÊúçÂä°Âô®ÁöÑipÂú∞ÂùÄÊàñËÄÖÂüüÂêç\nexport ANTHROPIC_AUTH_TOKEN=\"ÂêéÂè∞ÂàõÂª∫ÁöÑAPIÂØÜÈí•\"\n```\n\n**‰ΩøÁî® Antigravity Ë¥¶Êà∑Ê±†**\n\nÈÄÇÁî®‰∫éÈÄöËøá Antigravity Ê∏†ÈÅì‰ΩøÁî® Claude Ê®°ÂûãÔºàÂ¶Ç `claude-opus-4-5` Á≠âÔºâ„ÄÇ\n\n```bash\n# 1. ËÆæÁΩÆ Base URL ‰∏∫ Antigravity ‰∏ìÁî®Ë∑ØÂæÑ\nexport ANTHROPIC_BASE_URL=\"http://127.0.0.1:3000/antigravity/api/\"\n\n# 2. ËÆæÁΩÆ API KeyÔºàÂú®ÂêéÂè∞ÂàõÂª∫ÔºåÊùÉÈôêÈúÄÂåÖÂê´ 'all' Êàñ 'gemini'Ôºâ\nexport ANTHROPIC_AUTH_TOKEN=\"ÂêéÂè∞ÂàõÂª∫ÁöÑAPIÂØÜÈí•\"\n\n# 3. ÊåáÂÆöÊ®°ÂûãÂêçÁß∞ÔºàÁõ¥Êé•‰ΩøÁî®Áü≠ÂêçÔºåÊó†ÈúÄÂâçÁºÄÔºÅÔºâ\nexport ANTHROPIC_MODEL=\"claude-opus-4-5\"\n\n# 4. ÂêØÂä®\nclaude\n```\n\n**VSCode Claude Êèí‰ª∂ÈÖçÁΩÆÔºö**\n\nÂ¶ÇÊûú‰ΩøÁî® VSCode ÁöÑ Claude Êèí‰ª∂ÔºåÈúÄË¶ÅÂú® `~/.claude/config.json` Êñá‰ª∂‰∏≠ÈÖçÁΩÆÔºö\n\n```json\n{\n    \"primaryApiKey\": \"crs\"\n}\n```\n\nÂ¶ÇÊûúËØ•Êñá‰ª∂‰∏çÂ≠òÂú®ÔºåËØ∑ÊâãÂä®ÂàõÂª∫„ÄÇWindows Áî®Êà∑Ë∑ØÂæÑ‰∏∫ `C:\\Users\\‰Ω†ÁöÑÁî®Êà∑Âêç\\.claude\\config.json`„ÄÇ\n\n> üí° **IntelliJ IDEA Áî®Êà∑Êé®Ëçê**Ôºö[Claude Code Plus](https://github.com/touwaeriol/claude-code-plus) - Â∞Ü Claude Code Áõ¥Êé•ÈõÜÊàêÂà∞ IDEÔºåÊîØÊåÅ‰ª£Á†ÅÁêÜËß£„ÄÅÊñá‰ª∂ËØªÂÜô„ÄÅÂëΩ‰ª§ÊâßË°å„ÄÇÊèí‰ª∂Â∏ÇÂú∫ÊêúÁ¥¢ `Claude Code Plus` Âç≥ÂèØÂÆâË£Ö„ÄÇ\n\n**Gemini CLI ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáèÔºö**\n\n**ÊñπÂºè‰∏ÄÔºàÊé®ËçêÔºâÔºöÈÄöËøá Gemini Assist API ÊñπÂºèËÆøÈóÆ**\n\n```bash\nCODE_ASSIST_ENDPOINT=\"http://127.0.0.1:3000/gemini\"  # Ê†πÊçÆÂÆûÈôÖÂ°´ÂÜô‰Ω†ÊúçÂä°Âô®ÁöÑipÂú∞ÂùÄÊàñËÄÖÂüüÂêç\nGOOGLE_CLOUD_ACCESS_TOKEN=\"ÂêéÂè∞ÂàõÂª∫ÁöÑAPIÂØÜÈí•\"\nGOOGLE_GENAI_USE_GCA=\"true\"\nGEMINI_MODEL=\"gemini-2.5-pro\" # Â¶ÇÊûú‰Ω†Êúâgemini3ÊùÉÈôêÂèØ‰ª•Â°´Ôºö gemini-3-pro-preview\n```\n\n> **ËÆ§ËØÅ**ÔºöÂè™ËÉΩÈÄâ ```Login with Google``` ËøõË°åËÆ§ËØÅÔºåÂ¶ÇÊûúË∑≥ GoogleËØ∑Âà†Èô§ ```~/.gemini/settings.json``` ÂêéÂÜçÂ∞ùËØïÂêØÂä®```gemini```„ÄÇ  \n> **Ê≥®ÊÑè**Ôºögemini-cli ÊéßÂà∂Âè∞‰ºöÊèêÁ§∫ `Failed to fetch user info: 401 Unauthorized`Ôºå‰ΩÜ‰ΩøÁî®‰∏çÂèó‰ªª‰ΩïÂΩ±Âìç„ÄÇ  \n\n**ÊñπÂºè‰∫åÔºöÈÄöËøá Gemini API ÊñπÂºèËÆøÈóÆ**\n\n\n```bash\nGOOGLE_GEMINI_BASE_URL=\"http://127.0.0.1:3000/gemini\"  # Ê†πÊçÆÂÆûÈôÖÂ°´ÂÜô‰Ω†ÊúçÂä°Âô®ÁöÑipÂú∞ÂùÄÊàñËÄÖÂüüÂêç\nGEMINI_API_KEY=\"ÂêéÂè∞ÂàõÂª∫ÁöÑAPIÂØÜÈí•\"\nGEMINI_MODEL=\"gemini-2.5-pro\" # Â¶ÇÊûú‰Ω†Êúâgemini3ÊùÉÈôêÂèØ‰ª•Â°´Ôºö gemini-3-pro-preview\n```\n\n> **ËÆ§ËØÅ**ÔºöÂè™ËÉΩÈÄâ ```Use Gemini API Key``` ËøõË°åËÆ§ËØÅÔºåÂ¶ÇÊûúÊèêÁ§∫ ```Enter Gemini API Key``` ËØ∑Áõ¥Êé•ÁïôÁ©∫ÊåâÂõûËΩ¶„ÄÇÂ¶ÇÊûú‰∏ÄÊâìÂºÄÂ∞±Ë∑≥ GoogleËØ∑Âà†Èô§ ```~/.gemini/settings.json``` ÂêéÂÜçÂ∞ùËØïÂêØÂä®```gemini```„ÄÇ\n\n> üí° **ËøõÈò∂Áî®Ê≥ï**ÔºöÊÉ≥Âú® Claude Code ‰∏≠Áõ¥Êé•‰ΩøÁî® Gemini 3 Ê®°ÂûãÔºüËØ∑ÂèÇËÄÉ [Claude Code Ë∞ÉÁî® Gemini 3 Ê®°ÂûãÊåáÂçó](docs/claude-code-gemini3-guide/README.md)\n\n**‰ΩøÁî® Claude CodeÔºö**\n\n```bash\nclaude\n```\n\n**‰ΩøÁî® Gemini CLIÔºö**\n\n```bash\ngemini  # ÊàñÂÖ∂‰ªñ Gemini CLI ÂëΩ‰ª§\n```\n\n**Codex ÈÖçÁΩÆÔºö**\n\nÂú® `~/.codex/config.toml` Êñá‰ª∂**ÂºÄÂ§¥**Ê∑ªÂä†‰ª•‰∏ãÈÖçÁΩÆÔºö\n\n```toml\nmodel_provider = \"crs\"\nmodel = \"gpt-5.1-codex-max\"\nmodel_reasoning_effort = \"high\"\ndisable_response_storage = true\npreferred_auth_method = \"apikey\"\n\n[model_providers.crs]\nname = \"crs\"\nbase_url = \"http://127.0.0.1:3000/openai\"  # Ê†πÊçÆÂÆûÈôÖÂ°´ÂÜô‰Ω†ÊúçÂä°Âô®ÁöÑipÂú∞ÂùÄÊàñËÄÖÂüüÂêç\nwire_api = \"responses\"\nrequires_openai_auth = true\nenv_key = \"CRS_OAI_KEY\"\n```\n\nÂú® `~/.codex/auth.json` Êñá‰ª∂‰∏≠ÈÖçÁΩÆAPIÂØÜÈí•‰∏∫ nullÔºö\n\n```json\n{\n    \"OPENAI_API_KEY\": null  \n}\n```\n\nÁéØÂ¢ÉÂèòÈáèËÆæÁΩÆÔºö\n\n```bash\nexport CRS_OAI_KEY=\"ÂêéÂè∞ÂàõÂª∫ÁöÑAPIÂØÜÈí•\"\n```\n\n> ‚ö†Ô∏è Âú®ÈÄöËøá Nginx ÂèçÂêë‰ª£ÁêÜ CRS ÊúçÂä°Âπ∂‰ΩøÁî® Codex CLI Êó∂ÔºåÈúÄË¶ÅÂú® http Âùó‰∏≠Ê∑ªÂä† underscores_in_headers on;„ÄÇÂõ†‰∏∫ Nginx ÈªòËÆ§‰ºöÁßªÈô§Â∏¶‰∏ãÂàíÁ∫øÁöÑËØ∑Ê±ÇÂ§¥ÔºàÂ¶Ç session_idÔºâÔºå‰∏ÄÊó¶ËØ•Â§¥Ë¢´‰∏¢ÂºÉÔºåÂ§öË¥¶Âè∑ÁéØÂ¢É‰∏ãÁöÑÁ≤òÊÄß‰ºöËØùÂäüËÉΩÂ∞ÜÂ§±Êïà„ÄÇ\n\n**Droid CLI ÈÖçÁΩÆÔºö**\n\nDroid CLI ËØªÂèñ `~/.factory/config.json`„ÄÇÂèØ‰ª•Âú®ËØ•Êñá‰ª∂‰∏≠Ê∑ªÂä†Ëá™ÂÆö‰πâÊ®°Âûã‰ª•ÊåáÂêëÊú¨ÊúçÂä°ÁöÑÊñ∞Á´ØÁÇπÔºö\n\n```json\n{\n  \"custom_models\": [\n    {\n      \"model_display_name\": \"Opus 4.5 [crs]\",\n      \"model\": \"claude-opus-4-5-20251101\",\n      \"base_url\": \"http://127.0.0.1:3000/droid/claude\",\n      \"api_key\": \"ÂêéÂè∞ÂàõÂª∫ÁöÑAPIÂØÜÈí•\",\n      \"provider\": \"anthropic\",\n      \"max_tokens\": 64000\n    },\n    {\n      \"model_display_name\": \"GPT5-Codex [crs]\",\n      \"model\": \"gpt-5-codex\",\n      \"base_url\": \"http://127.0.0.1:3000/droid/openai\",\n      \"api_key\": \"ÂêéÂè∞ÂàõÂª∫ÁöÑAPIÂØÜÈí•\",\n      \"provider\": \"openai\",\n      \"max_tokens\": 16384\n    },\n    {\n      \"model_display_name\": \"Gemini-3-Pro [crs]\",\n      \"model\": \"gemini-3-pro-preview\",\n      \"base_url\": \"http://127.0.0.1:3000/droid/comm/v1/\",\n      \"api_key\": \"ÂêéÂè∞ÂàõÂª∫ÁöÑAPIÂØÜÈí•\",\n      \"provider\": \"generic-chat-completion-api\",\n      \"max_tokens\": 65535\n    },\n    {\n      \"model_display_name\": \"GLM-4.6 [crs]\",\n      \"model\": \"glm-4.6\",\n      \"base_url\": \"http://127.0.0.1:3000/droid/comm/v1/\",\n      \"api_key\": \"ÂêéÂè∞ÂàõÂª∫ÁöÑAPIÂØÜÈí•\",\n      \"provider\": \"generic-chat-completion-api\",\n      \"max_tokens\": 202800\n    }\n  ]\n}\n```\n\n> üí° Â∞ÜÁ§∫‰æã‰∏≠ÁöÑ `http://127.0.0.1:3000` ÊõøÊç¢‰∏∫‰Ω†ÁöÑÊúçÂä°ÂüüÂêçÊàñÂÖ¨ÁΩëÂú∞ÂùÄÔºåÂπ∂ÂÜôÂÖ•ÂêéÂè∞ÁîüÊàêÁöÑ API ÂØÜÈí•Ôºàcr_ ÂºÄÂ§¥Ôºâ„ÄÇ\n\n### 5. Á¨¨‰∏âÊñπÂ∑•ÂÖ∑APIÊé•ÂÖ•\n\nÊú¨ÊúçÂä°ÊîØÊåÅÂ§öÁßçAPIÁ´ØÁÇπÊ†ºÂºèÔºåÊñπ‰æøÊé•ÂÖ•‰∏çÂêåÁöÑÁ¨¨‰∏âÊñπÂ∑•ÂÖ∑ÔºàÂ¶ÇCherry StudioÁ≠âÔºâ„ÄÇ\n\n#### Cherry Studio Êé•ÂÖ•Á§∫‰æã\n\nCherry StudioÊîØÊåÅÂ§öÁßçAIÊúçÂä°ÁöÑÊé•ÂÖ•Ôºå‰∏ãÈù¢ÊòØ‰∏çÂêåË¥¶Âè∑Á±ªÂûãÁöÑËØ¶ÁªÜÈÖçÁΩÆÔºö\n\n**1. ClaudeË¥¶Âè∑Êé•ÂÖ•Ôºö**\n\n```\n# APIÂú∞ÂùÄ\nhttp://‰Ω†ÁöÑÊúçÂä°Âô®:3000/claude\n\n# Ê®°ÂûãIDÁ§∫‰æã\nclaude-sonnet-4-5-20250929 # Claude Sonnet 4.5\nclaude-opus-4-20250514     # Claude Opus 4\n```\n\nÈÖçÁΩÆÊ≠•È™§Ôºö\n- ‰æõÂ∫îÂïÜÁ±ªÂûãÈÄâÊã©\"Anthropic\"\n- APIÂú∞ÂùÄÂ°´ÂÖ•Ôºö`http://‰Ω†ÁöÑÊúçÂä°Âô®:3000/claude`\n- API KeyÂ°´ÂÖ•ÔºöÂêéÂè∞ÂàõÂª∫ÁöÑAPIÂØÜÈí•Ôºàcr_ÂºÄÂ§¥Ôºâ\n\n**2. GeminiË¥¶Âè∑Êé•ÂÖ•Ôºö**\n\n```\n# APIÂú∞ÂùÄ\nhttp://‰Ω†ÁöÑÊúçÂä°Âô®:3000/gemini\n\n# Ê®°ÂûãIDÁ§∫‰æã\ngemini-2.5-pro             # Gemini 2.5 Pro\n```\n\nÈÖçÁΩÆÊ≠•È™§Ôºö\n- ‰æõÂ∫îÂïÜÁ±ªÂûãÈÄâÊã©\"Gemini\"\n- APIÂú∞ÂùÄÂ°´ÂÖ•Ôºö`http://‰Ω†ÁöÑÊúçÂä°Âô®:3000/gemini`\n- API KeyÂ°´ÂÖ•ÔºöÂêéÂè∞ÂàõÂª∫ÁöÑAPIÂØÜÈí•Ôºàcr_ÂºÄÂ§¥Ôºâ\n\n**3. CodexÊé•ÂÖ•Ôºö**\n\n```\n# APIÂú∞ÂùÄ\nhttp://‰Ω†ÁöÑÊúçÂä°Âô®:3000/openai\n\n# Ê®°ÂûãIDÔºàÂõ∫ÂÆöÔºâ\ngpt-5                      # Codex‰ΩøÁî®Âõ∫ÂÆöÊ®°ÂûãID\n```\n\nÈÖçÁΩÆÊ≠•È™§Ôºö\n- ‰æõÂ∫îÂïÜÁ±ªÂûãÈÄâÊã©\"Openai-Response\"\n- APIÂú∞ÂùÄÂ°´ÂÖ•Ôºö`http://‰Ω†ÁöÑÊúçÂä°Âô®:3000/openai`\n- API KeyÂ°´ÂÖ•ÔºöÂêéÂè∞ÂàõÂª∫ÁöÑAPIÂØÜÈí•Ôºàcr_ÂºÄÂ§¥Ôºâ\n- **ÈáçË¶Å**ÔºöCodexÂè™ÊîØÊåÅOpenai-ResponseÊ†áÂáÜ\n\n\n**Cherry Studio Âú∞ÂùÄÊ†ºÂºèÈáçË¶ÅËØ¥ÊòéÔºö**\n\n- ‚úÖ **Êé®ËçêÊ†ºÂºè**Ôºö`http://‰Ω†ÁöÑÊúçÂä°Âô®:3000/claude`Ôºà‰∏çÂä†ÁªìÂ∞æ `/`ÔºåËÆ© Cherry Studio Ëá™Âä®Âä†‰∏ä v1Ôºâ\n- ‚úÖ **Á≠âÊïàÊ†ºÂºè**Ôºö`http://‰Ω†ÁöÑÊúçÂä°Âô®:3000/claude/v1/`ÔºàÊâãÂä®ÊåáÂÆö v1 Âπ∂Âä†ÁªìÂ∞æ `/`Ôºâ\n- üí° **ËØ¥Êòé**ÔºöËøô‰∏§ÁßçÊ†ºÂºèÂú® Cherry Studio ‰∏≠ÊòØÂÆåÂÖ®Á≠âÊïàÁöÑ\n- ‚ùå **ÈîôËØØÊ†ºÂºè**Ôºö`http://‰Ω†ÁöÑÊúçÂä°Âô®:3000/claude/`ÔºàÂçïÁã¨ÁöÑ `/` ÁªìÂ∞æ‰ºöË¢´ Cherry Studio ÂøΩÁï• v1 ÁâàÊú¨Ôºâ\n\n#### ÂÖ∂‰ªñÁ¨¨‰∏âÊñπÂ∑•ÂÖ∑Êé•ÂÖ•\n\n**Êé•ÂÖ•Ë¶ÅÁÇπÔºö**\n\n- ÊâÄÊúâË¥¶Âè∑Á±ªÂûãÈÉΩ‰ΩøÁî®Áõ∏ÂêåÁöÑAPIÂØÜÈí•ÔºàÂú®ÂêéÂè∞Áªü‰∏ÄÂàõÂª∫Ôºâ\n- Ê†πÊçÆ‰∏çÂêåÁöÑË∑ØÁî±ÂâçÁºÄËá™Âä®ËØÜÂà´Ë¥¶Âè∑Á±ªÂûã\n- `/claude/` - ‰ΩøÁî®ClaudeË¥¶Âè∑Ê±†\n- `/antigravity/api/` - ‰ΩøÁî®AntigravityË¥¶Âè∑Ê±†ÔºàÊé®ËçêÁî®‰∫éClaude CodeÔºâ\n- `/droid/claude/` - ‰ΩøÁî®DroidÁ±ªÂûãClaudeË¥¶Âè∑Ê±†ÔºàÂè™Âª∫ËÆÆapiË∞ÉÁî®ÊàñDroid Cli‰∏≠‰ΩøÁî®Ôºâ\n- `/gemini/` - ‰ΩøÁî®GeminiË¥¶Âè∑Ê±†\n- `/openai/` - ‰ΩøÁî®CodexË¥¶Âè∑ÔºàÂè™ÊîØÊåÅOpenai-ResponseÊ†ºÂºèÔºâ\n- `/droid/openai/` - ‰ΩøÁî®DroidÁ±ªÂûãOpenAIÂÖºÂÆπË¥¶Âè∑Ê±†ÔºàÂè™Âª∫ËÆÆapiË∞ÉÁî®ÊàñDroid Cli‰∏≠‰ΩøÁî®Ôºâ\n- ÊîØÊåÅÊâÄÊúâÊ†áÂáÜAPIÁ´ØÁÇπÔºàmessages„ÄÅmodelsÁ≠âÔºâ\n\n**ÈáçË¶ÅËØ¥ÊòéÔºö**\n\n- Á°Æ‰øùÂú®ÂêéÂè∞Â∑≤Ê∑ªÂä†ÂØπÂ∫îÁ±ªÂûãÁöÑË¥¶Âè∑ÔºàClaude/Gemini/CodexÔºâ\n- APIÂØÜÈí•ÂèØ‰ª•ÈÄöÁî®ÔºåÁ≥ªÁªü‰ºöÊ†πÊçÆË∑ØÁî±Ëá™Âä®ÈÄâÊã©Ë¥¶Âè∑Á±ªÂûã\n- Âª∫ËÆÆ‰∏∫‰∏çÂêåÁî®Êà∑ÂàõÂª∫‰∏çÂêåÁöÑAPIÂØÜÈí•‰æø‰∫é‰ΩøÁî®ÁªüËÆ°\n\n---\n\n## üîß Êó•Â∏∏Áª¥Êä§\n\n### ÊúçÂä°ÁÆ°ÁêÜ\n\n```bash\n# Êü•ÁúãÊúçÂä°Áä∂ÊÄÅ\nnpm run service:status\n\n# Êü•ÁúãÊó•Âøó\nnpm run service:logs\n\n# ÈáçÂêØÊúçÂä°\nnpm run service:restart:daemon\n\n# ÂÅúÊ≠¢ÊúçÂä°\nnpm run service:stop\n```\n\n### ÁõëÊéß‰ΩøÁî®ÊÉÖÂÜµ\n\n- **WebÁïåÈù¢**: `http://‰Ω†ÁöÑÂüüÂêç:3000/web` - Êü•Áúã‰ΩøÁî®ÁªüËÆ°\n- **ÂÅ•Â∫∑Ê£ÄÊü•**: `http://‰Ω†ÁöÑÂüüÂêç:3000/health` - Á°ÆËÆ§ÊúçÂä°Ê≠£Â∏∏\n- **Êó•ÂøóÊñá‰ª∂**: `logs/` ÁõÆÂΩï‰∏ãÁöÑÂêÑÁßçÊó•ÂøóÊñá‰ª∂\n\n### ÂçáÁ∫ßÊåáÂçó\n\nÂΩìÊúâÊñ∞ÁâàÊú¨ÂèëÂ∏ÉÊó∂ÔºåÊåâÁÖß‰ª•‰∏ãÊ≠•È™§ÂçáÁ∫ßÊúçÂä°Ôºö\n\n```bash\n# 1. ËøõÂÖ•È°πÁõÆÁõÆÂΩï\ncd claude-relay-service\n\n# 2. ÊãâÂèñÊúÄÊñ∞‰ª£Á†Å\ngit pull origin main\n\n# Â¶ÇÊûúÈÅáÂà∞ package-lock.json ÂÜ≤Á™ÅÔºå‰ΩøÁî®ËøúÁ®ãÁâàÊú¨\ngit checkout --theirs package-lock.json\ngit add package-lock.json\n\n# 3. ÂÆâË£ÖÊñ∞ÁöÑ‰æùËµñÔºàÂ¶ÇÊûúÊúâÔºâ\nnpm install\n\n# 4. ÂÆâË£ÖÂπ∂ÊûÑÂª∫ÂâçÁ´Ø\nnpm run install:web\nnpm run build:web\n\n# 5. ÈáçÂêØÊúçÂä°\nnpm run service:restart:daemon\n\n# 6. Ê£ÄÊü•ÊúçÂä°Áä∂ÊÄÅ\nnpm run service:status\n```\n\n**Ê≥®ÊÑè‰∫ãÈ°πÔºö**\n\n- ÂçáÁ∫ßÂâçÂª∫ËÆÆÂ§á‰ªΩÈáçË¶ÅÈÖçÁΩÆÊñá‰ª∂Ôºà.env, config/config.jsÔºâ\n- Êü•ÁúãÊõ¥Êñ∞Êó•Âøó‰∫ÜËß£ÊòØÂê¶ÊúâÁ†¥ÂùèÊÄßÂèòÊõ¥\n- Â¶ÇÊûúÊúâÊï∞ÊçÆÂ∫ìÁªìÊûÑÂèòÊõ¥Ôºå‰ºöËá™Âä®ËøÅÁßª\n\n---\n\n## üîí ÂÆ¢Êà∑Á´ØÈôêÂà∂ÂäüËÉΩ\n\n### ÂäüËÉΩËØ¥Êòé\n\nÂÆ¢Êà∑Á´ØÈôêÂà∂ÂäüËÉΩÂÖÅËÆ∏‰Ω†ÊéßÂà∂ÊØè‰∏™API KeyÂèØ‰ª•Ë¢´Âì™‰∫õÂÆ¢Êà∑Á´Ø‰ΩøÁî®ÔºåÈÄöËøáUser-AgentËØÜÂà´ÂÆ¢Êà∑Á´ØÔºåÊèêÈ´òAPIÁöÑÂÆâÂÖ®ÊÄß„ÄÇ\n\n### ‰ΩøÁî®ÊñπÊ≥ï\n\n1. **Âú®ÂàõÂª∫ÊàñÁºñËæëAPI KeyÊó∂ÂêØÁî®ÂÆ¢Êà∑Á´ØÈôêÂà∂**Ôºö\n   - ÂãæÈÄâ\"ÂêØÁî®ÂÆ¢Êà∑Á´ØÈôêÂà∂\"\n   - ÈÄâÊã©ÂÖÅËÆ∏ÁöÑÂÆ¢Êà∑Á´ØÔºàÊîØÊåÅÂ§öÈÄâÔºâ\n\n2. **È¢ÑÂÆö‰πâÂÆ¢Êà∑Á´Ø**Ôºö\n   - **ClaudeCode**: ÂÆòÊñπClaude CLIÔºàÂåπÈÖç `claude-cli/x.x.x (external, cli)` Ê†ºÂºèÔºâ\n   - **Gemini-CLI**: GeminiÂëΩ‰ª§Ë°åÂ∑•ÂÖ∑ÔºàÂåπÈÖç `GeminiCLI/vx.x.x (platform; arch)` Ê†ºÂºèÔºâ\n\n3. **Ë∞ÉËØïÂíåËØäÊñ≠**Ôºö\n   - Á≥ªÁªü‰ºöÂú®Êó•Âøó‰∏≠ËÆ∞ÂΩïÊâÄÊúâËØ∑Ê±ÇÁöÑUser-Agent\n   - ÂÆ¢Êà∑Á´ØÈ™åËØÅÂ§±Ë¥•Êó∂‰ºöËøîÂõû403ÈîôËØØÂπ∂ËÆ∞ÂΩïËØ¶ÁªÜ‰ø°ÊÅØ\n   - ÈÄöËøáÊó•ÂøóÂèØ‰ª•Êü•ÁúãÂÆûÈôÖÁöÑUser-AgentÊ†ºÂºèÔºåÊñπ‰æøÈÖçÁΩÆËá™ÂÆö‰πâÂÆ¢Êà∑Á´Ø\n\n\n### Êó•ÂøóÁ§∫‰æã\n\nËÆ§ËØÅÊàêÂäüÊó∂ÁöÑÊó•ÂøóÔºö\n\n```\nüîì Authenticated request from key: ÊµãËØïKey (key-id) in 5ms\n   User-Agent: \"claude-cli/1.0.58 (external, cli)\"\n```\n\nÂÆ¢Êà∑Á´ØÈôêÂà∂Ê£ÄÊü•Êó•ÂøóÔºö\n\n```\nüîç Checking client restriction for key: key-id (ÊµãËØïKey)\n   User-Agent: \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n   Allowed clients: claude_code, gemini_cli\nüö´ Client restriction failed for key: key-id (ÊµãËØïKey) from 127.0.0.1, User-Agent: Mozilla/5.0...\n```\n\n### Â∏∏ËßÅÈóÆÈ¢òÂ§ÑÁêÜ\n\n**RedisËøû‰∏ç‰∏äÔºü**\n\n```bash\n# Ê£ÄÊü•RedisÊòØÂê¶ÂêØÂä®\nredis-cli ping\n\n# Â∫îËØ•ËøîÂõû PONG\n```\n\n**OAuthÊéàÊùÉÂ§±Ë¥•Ôºü**\n\n- Ê£ÄÊü•‰ª£ÁêÜËÆæÁΩÆÊòØÂê¶Ê≠£Á°Æ\n- Á°Æ‰øùËÉΩÊ≠£Â∏∏ËÆøÈóÆ claude.ai\n- Ê∏ÖÈô§ÊµèËßàÂô®ÁºìÂ≠òÈáçËØï\n\n**APIËØ∑Ê±ÇÂ§±Ë¥•Ôºü**\n\n- Ê£ÄÊü•API KeyÊòØÂê¶Ê≠£Á°Æ\n- Êü•ÁúãÊó•ÂøóÊñá‰ª∂ÊâæÈîôËØØ‰ø°ÊÅØ\n- Á°ÆËÆ§ClaudeË¥¶Êà∑Áä∂ÊÄÅÊ≠£Â∏∏\n\n---\n\n## üõ†Ô∏è ËøõÈò∂\n\n### ÂèçÂêë‰ª£ÁêÜÈÉ®ÁΩ≤ÊåáÂçó\n\nÂú®Áîü‰∫ßÁéØÂ¢É‰∏≠ÔºåÂª∫ËÆÆÈÄöËøáÂèçÂêë‰ª£ÁêÜËøõË°åËøûÊé•Ôºå‰ª•‰æø‰ΩøÁî®Ëá™Âä® HTTPS„ÄÅÂÆâÂÖ®Â§¥ÈÉ®ÂíåÊÄßËÉΩ‰ºòÂåñ„ÄÇ‰∏ãÈù¢Êèê‰æõ‰∏§ÁßçÂ∏∏Áî®ÊñπÊ°àÔºö **Caddy** Âíå **Nginx Proxy Manager (NPM)**„ÄÇ\n\n---\n\n## Caddy ÊñπÊ°à\n\nCaddy ÊòØ‰∏ÄÊ¨æËá™Âä®ÁÆ°ÁêÜ HTTPS ËØÅ‰π¶ÁöÑ Web ÊúçÂä°Âô®ÔºåÈÖçÁΩÆÁÆÄÂçï„ÄÅÊÄßËÉΩ‰ºòÁßÄÔºåÂæàÈÄÇÂêà‰∏çÈúÄË¶Å Docker ÁéØÂ¢ÉÁöÑÈÉ®ÁΩ≤ÊñπÊ°à„ÄÇ\n\n**1. ÂÆâË£Ö Caddy**\n\n```bash\n# Ubuntu/Debian\nsudo apt install -y debian-keyring debian-archive-keyring apt-transport-https\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | sudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | sudo tee /etc/apt/sources.list.d/caddy-stable.list\nsudo apt update\nsudo apt install caddy\n\n# CentOS/RHEL/Fedora\nsudo yum install yum-plugin-copr\nsudo yum copr enable @caddy/caddy\nsudo yum install caddy\n```\n\n**2. Caddy ÈÖçÁΩÆ**\n\nÁºñËæë `/etc/caddy/Caddyfile` Ôºö\n\n```caddy\nyour-domain.com {\n    # ÂèçÂêë‰ª£ÁêÜÂà∞Êú¨Âú∞ÊúçÂä°\n    reverse_proxy 127.0.0.1:3000 {\n        # ÊîØÊåÅÊµÅÂºèÂìçÂ∫îÊàñ SSE\n        flush_interval -1\n\n        # ‰º†ÈÄíÁúüÂÆû IP\n        header_up X-Real-IP {remote_host}\n        header_up X-Forwarded-For {remote_host}\n        header_up X-Forwarded-Proto {scheme}\n\n        # ÈïøËØª/ÂÜôË∂ÖÊó∂ÈÖçÁΩÆ\n        transport http {\n            read_timeout 300s\n            write_timeout 300s\n            dial_timeout 30s\n        }\n    }\n\n    # ÂÆâÂÖ®Â§¥ÈÉ®\n    header {\n        Strict-Transport-Security \"max-age=31536000; includeSubDomains\"\n        X-Frame-Options \"DENY\"\n        X-Content-Type-Options \"nosniff\"\n        -Server\n    }\n}\n```\n\n**3. ÂêØÂä® Caddy**\n\n```bash\nsudo caddy validate --config /etc/caddy/Caddyfile\nsudo systemctl start caddy\nsudo systemctl enable caddy\nsudo systemctl status caddy\n```\n\n**4. ÊúçÂä°ÈÖçÁΩÆ**\n\nCaddy ‰ºöËá™Âä®ÁÆ°ÁêÜ HTTPSÔºåÂõ†Ê≠§ÂèØ‰ª•Â∞ÜÊúçÂä°ÈôêÂà∂Âú®Êú¨Âú∞ËøõË°åÁõëÂê¨Ôºö\n\n```javascript\n// config/config.js\nmodule.exports = {\n  server: {\n    port: 3000,\n    host: '127.0.0.1' // Âè™ÁõëÂê¨Êú¨Âú∞\n  }\n}\n```\n\n**Caddy ÁâπÁÇπ**\n\n* üîí Ëá™Âä® HTTPSÔºåÈõ∂ÈÖçÁΩÆËØÅ‰π¶ÁÆ°ÁêÜ\n* üõ°Ô∏è ÂÆâÂÖ®ÈªòËÆ§ÈÖçÁΩÆÔºåÂêØÁî®Áé∞‰ª£ TLS Â•ó‰ª∂\n* ‚ö° HTTP/2 ÂíåÊµÅÂºè‰º†ËæìÊîØÊåÅ\n* üîß ÈÖçÁΩÆÊñá‰ª∂ÁÆÄÊ¥ÅÔºåÊòì‰∫éÁª¥Êä§\n\n---\n\n## Nginx Proxy Manager (NPM) ÊñπÊ°à\n\nNginx Proxy Manager ÈÄöËøáÂõæÂΩ¢ÂåñÁïåÈù¢ÁÆ°ÁêÜÂèçÂêë‰ª£ÁêÜÂíå HTTPS ËØÅ‰π¶Ôºå‰∏¶‰ª• Docker ÂÆπÂô®ÈÉ®ÁΩ≤„ÄÇ\n\n**1. Âú® NPM ÂàõÂª∫Êñ∞ÁöÑ Proxy Host**\n\nDetails ÈÖçÁΩÆÂ¶Ç‰∏ãÔºö\n\n| È°πÁõÆ                    | ËÆæÁΩÆ                      |\n| --------------------- | ----------------------- |\n| Domain Names          | relay.example.com       |\n| Scheme                | http                    |\n| Forward Hostname / IP | 192.168.0.1 (docker Êú∫Âô® IP) |\n| Forward Port          | 3000                    |\n| Block Common Exploits | ‚òëÔ∏è                      |\n| Websockets Support    | ‚ùå **ÂÖ≥Èó≠**                |\n| Cache Assets          | ‚ùå **ÂÖ≥Èó≠**                |\n| Access List           | Publicly Accessible     |\n\n> Ê≥®ÊÑèÔºö\n> - ËØ∑Á°Æ‰øù Claude Relay Service **ÁõëÂê¨ host ‰∏∫ `0.0.0.0` „ÄÅÂÆπÂô® IP ÊàñÊú¨Êú∫ IP**Ôºå‰ª•‰æø NPM ÂÆûÁé∞ÂÜÖÁΩëËøûÊé•„ÄÇ\n> - **Websockets Support Âíå Cache Assets ÂøÖÈ°ªÂÖ≥Èó≠**ÔºåÂê¶Âàô‰ºöÂØºËá¥ SSE / ÊµÅÂºèÂìçÂ∫îÂ§±Ë¥•„ÄÇ\n\n**2. Custom locations**\n\nÁÑ°ÈúÄÊ∑ªÂä†‰ªª‰ΩïÂÜÖÂÆπÔºå‰øùÊåÅ‰∏∫Á©∫„ÄÇ\n\n**3. SSL ËÆæÁΩÆ**\n\n* **SSL Certificate**: Request a new SSL Certificate (Let's Encrypt) ÊàñÂ∑≤ÊúâËØÅ‰π¶\n* ‚òëÔ∏è **Force SSL**\n* ‚òëÔ∏è **HTTP/2 Support**\n* ‚òëÔ∏è **HSTS Enabled**\n* ‚òëÔ∏è **HSTS Subdomains**\n\n**4. Advanced ÈÖçÁΩÆ**\n\nCustom Nginx Configuration ‰∏≠Ê∑ªÂä†‰ª•‰∏ãÂÜÖÂÆπÔºö\n\n```nginx\n# ‰º†ÈÄíÁúüÂÆûÁî®Êà∑ IP\nproxy_set_header X-Real-IP $remote_addr;\nproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\nproxy_set_header X-Forwarded-Proto $scheme;\n\n# ÊîØÊåÅ WebSocket / SSE Á≠âÊµÅÂºèÈÄö‰ø°\nproxy_http_version 1.1;\nproxy_set_header Upgrade $http_upgrade;\nproxy_set_header Connection \"upgrade\";\nproxy_buffering off;\n\n# ÈïøËøûÊé• / Ë∂ÖÊó∂ËÆæÁΩÆÔºàÈÄÇÂêà AI ËÅäÂ§©ÊµÅÂºè‰º†ËæìÔºâ\nproxy_read_timeout 300s;\nproxy_send_timeout 300s;\nproxy_connect_timeout 30s;\n\n# ---- ÂÆâÂÖ®ÊÄßËÆæÁΩÆ ----\n# ‰∏•Ê†º HTTPS Á≠ñÁï• (HSTS)\nadd_header Strict-Transport-Security \"max-age=31536000; includeSubDomains\" always;\n\n# ÈòªÊå°ÁÇπÂáªÂä´ÊåÅ‰∏éÂÜÖÂÆπÂóÖÊé¢\nadd_header X-Frame-Options \"DENY\" always;\nadd_header X-Content-Type-Options \"nosniff\" always;\n\n# Referrer / Permissions ÈôêÂà∂Á≠ñÁï•\nadd_header Referrer-Policy \"no-referrer-when-downgrade\" always;\nadd_header Permissions-Policy \"camera=(), microphone=(), geolocation=()\" always;\n\n# ÈöêËóèÊúçÂä°Âô®‰ø°ÊÅØÔºàÁ≠âÊïà‰∫é Caddy ÁöÑ `-Server`Ôºâ\nproxy_hide_header Server;\n\n# ---- ÊÄßËÉΩÂæÆË∞É ----\n# ÂÖ≥Èó≠‰ª£ÁêÜÁ´ØÁºìÂ≠òÔºåÁ°Æ‰øùÂç≥Êó∂ÂìçÂ∫îÔºàSSE / StreamingÔºâ\nproxy_cache_bypass $http_upgrade;\nproxy_no_cache $http_upgrade;\nproxy_request_buffering off;\n```\n\n**4. ÂêØÂä®ÂíåÈ™åËØÅ**\n\n* ‰øùÂ≠òÂêéÁ≠âÂæÖ NPM Ëá™Âä®Áî≥ËØ∑ Let's Encrypt ËØÅ‰π¶ÔºàÂ¶ÇÊûúÊúâÔºâ„ÄÇ\n* Dashboard ‰∏≠Êü•Áúã Proxy Host Áä∂ÊÄÅÔºåÁ°Æ‰øùÊòæÁ§∫‰∏∫ \"Online\"„ÄÇ\n* ËÆøÈóÆ `https://relay.example.com`ÔºåÂ¶ÇÊûúÊòæÁ§∫ÁªøËâ≤ÈîÅÂõæÊ†áÂç≥Ë°®Á§∫ HTTPS Ê≠£Â∏∏„ÄÇ\n\n**NPM ÁâπÁÇπ**\n\n* üîí Ëá™Âä®Áî≥ËØ∑ÂíåÁª≠ÊúüËØÅ‰π¶\n* üîß ÂõæÂΩ¢ÂåñÁïåÈù¢ÔºåÊñπ‰æøÁÆ°ÁêÜÂ§öÊúçÂä°\n* ‚ö° ÂéüÁîüÊîØÊåÅ HTTP/2 / HTTPS\n* üöÄ ÈÄÇÂêà Docker ÂÆπÂô®ÈÉ®ÁΩ≤\n\n---\n\n‰∏äËø∞‰∏§ÁßçÊñπÊ°àÂùáÂèØÁî®‰∫éÁîü‰∫ßÈÉ®ÁΩ≤„ÄÇ\n\n---\n\n## üí° ‰ΩøÁî®Âª∫ËÆÆ\n\n### Ë¥¶Êà∑ÁÆ°ÁêÜ\n\n- **ÂÆöÊúüÊ£ÄÊü•**: ÊØèÂë®ÁúãÁúãË¥¶Êà∑Áä∂ÊÄÅÔºåÂèäÊó∂Â§ÑÁêÜÂºÇÂ∏∏\n- **ÂêàÁêÜÂàÜÈÖç**: ÂèØ‰ª•Áªô‰∏çÂêåÁöÑ‰∫∫ÂàÜÈÖç‰∏çÂêåÁöÑapikeyÔºåÂèØ‰ª•Ê†πÊçÆ‰∏çÂêåÁöÑapikeyÊù•ÂàÜÊûêÁî®Èáè\n\n### ÂÆâÂÖ®Âª∫ËÆÆ\n\n- **‰ΩøÁî®HTTPS**: Âº∫ÁÉàÂª∫ËÆÆ‰ΩøÁî®CaddyÂèçÂêë‰ª£ÁêÜÔºàËá™Âä®HTTPSÔºâÔºåÁ°Æ‰øùÊï∞ÊçÆ‰º†ËæìÂÆâÂÖ®\n- **ÂÆöÊúüÂ§á‰ªΩ**: ÈáçË¶ÅÈÖçÁΩÆÂíåÊï∞ÊçÆË¶ÅÂ§á‰ªΩ\n- **ÁõëÊéßÊó•Âøó**: ÂÆöÊúüÊü•ÁúãÂºÇÂ∏∏Êó•Âøó\n- **Êõ¥Êñ∞ÂØÜÈí•**: ÂÆöÊúüÊõ¥Êç¢JWTÂíåÂä†ÂØÜÂØÜÈí•\n- **Èò≤ÁÅ´Â¢ôËÆæÁΩÆ**: Âè™ÂºÄÊîæÂøÖË¶ÅÁöÑÁ´ØÂè£Ôºà80, 443ÔºâÔºåÈöêËóèÁõ¥Êé•ÊúçÂä°Á´ØÂè£\n\n---\n\n## üÜò ÈÅáÂà∞ÈóÆÈ¢òÊÄé‰πàÂäûÔºü\n\n### Ëá™Âä©ÊéíÊü•\n\n1. **Êü•ÁúãÊó•Âøó**: `logs/` ÁõÆÂΩï‰∏ãÁöÑÊó•ÂøóÊñá‰ª∂\n2. **Ê£ÄÊü•ÈÖçÁΩÆ**: Á°ÆËÆ§ÈÖçÁΩÆÊñá‰ª∂ËÆæÁΩÆÊ≠£Á°Æ\n3. **ÊµãËØïËøûÈÄöÊÄß**: Áî® curl ÊµãËØïAPIÊòØÂê¶Ê≠£Â∏∏\n4. **ÈáçÂêØÊúçÂä°**: ÊúâÊó∂ÂÄôÈáçÂêØ‰∏Ä‰∏ãÂ∞±Â•Ω‰∫Ü\n\n### ÂØªÊ±ÇÂ∏ÆÂä©\n\n- **GitHub Issues**: Êèê‰∫§ËØ¶ÁªÜÁöÑÈîôËØØ‰ø°ÊÅØ\n- **Êü•ÁúãÊñáÊ°£**: ‰ªîÁªÜÈòÖËØªÈîôËØØ‰ø°ÊÅØÂíåÊñáÊ°£\n- **Á§æÂå∫ËÆ®ËÆ∫**: ÁúãÁúãÂÖ∂‰ªñ‰∫∫ÊòØÂê¶ÈÅáÂà∞Á±ª‰ººÈóÆÈ¢ò\n\n---\n\n## ‚ù§Ô∏è ËµûÂä©ÊîØÊåÅ\n\nÂ¶ÇÊûúÊÇ®ËßâÂæóËøô‰∏™È°πÁõÆÂØπÊÇ®ÊúâÂ∏ÆÂä©ÔºåËØ∑ËÄÉËôëËµûÂä©ÊîØÊåÅÈ°πÁõÆÁöÑÊåÅÁª≠ÂºÄÂèë„ÄÇÊÇ®ÁöÑÊîØÊåÅÊòØÊàë‰ª¨ÊúÄÂ§ßÁöÑÂä®ÂäõÔºÅ\n\n<div align=\"center\">\n\n<a href=\"https://afdian.com/a/claude-relay-service\" target=\"_blank\">\n  <img src=\"https://img.shields.io/badge/ËØ∑ÊàëÂñùÊùØÂíñÂï°-Áà±ÂèëÁîµ-946ce6?style=for-the-badge&logo=buy-me-a-coffee&logoColor=white\" alt=\"Sponsor\">\n</a>\n\n<table>\n  <tr>\n    <td><img src=\"docs/sponsoring/wechat.jpg\" width=\"200\" alt=\"wechat\" /></td>\n    <td><img src=\"docs/sponsoring/alipay.jpg\" width=\"200\" alt=\"alipay\" /></td>\n  </tr>\n</table>\n\n</div>\n\n---\n\n## üìÑ ËÆ∏ÂèØËØÅ\n\nÊú¨È°πÁõÆÈááÁî® [MITËÆ∏ÂèØËØÅ](LICENSE)„ÄÇ\n\n---\n\n<div align=\"center\">\n\n**‚≠ê ËßâÂæóÊúâÁî®ÁöÑËØùÁªô‰∏™StarÂëóÔºåËøôÊòØÂØπ‰ΩúËÄÖÊúÄÂ§ßÁöÑÈºìÂä±ÔºÅ**\n\n**ü§ù ÊúâÈóÆÈ¢òÊ¨¢ËøéÊèêIssueÔºåÊúâÊîπËøõÂª∫ËÆÆÊ¨¢ËøéPR**\n\n</div>\n",
      "stars_today": 43
    },
    {
      "id": 738128540,
      "name": "log-lottery",
      "full_name": "LOG1997/log-lottery",
      "description": "üéàüéàüéàüéàÂπ¥‰ºöÊäΩÂ•ñÁ®ãÂ∫èÔºåthreejs+vue3 3DÁêÉ‰ΩìÂä®ÊÄÅÊäΩÂ•ñÂ∫îÁî®„ÄÇ",
      "html_url": "https://github.com/LOG1997/log-lottery",
      "stars": 2836,
      "forks": 663,
      "language": "TypeScript",
      "topics": [
        "3d",
        "daisyui",
        "lottery",
        "lucky",
        "lucky-draw",
        "prizes",
        "raffle",
        "threejs",
        "vue3",
        "vue3-typescript"
      ],
      "created_at": "2024-01-02T13:47:14Z",
      "updated_at": "2026-01-24T01:53:06Z",
      "pushed_at": "2026-01-23T09:42:00Z",
      "open_issues": 34,
      "owner": {
        "login": "LOG1997",
        "avatar_url": "https://avatars.githubusercontent.com/u/26322485?v=4"
      },
      "readme": "<div align=\"center\">\n    <a href=\"https://log1997.github.io/log-lottery/\">\n        <img src=\"./static/images/lottery.png\" width=\"100\" height=\"100\" />\n    </a>\n\n# log-lottery üöÄüöÄüöÄüöÄ\n\n[![github stars](https://img.shields.io/github/stars/log1997/log-lottery)](https://github.com/LOG1997/log-lottery)\n[![version](https://img.shields.io/github/package-json/v/log1997/log-lottery)](https://github.com/LOG1997/log-lottery)\n[![License MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://github.com/LOG1997/log-lottery)\n[![github author](https://img.shields.io/badge/Author-log1997-blue.svg)](https://github.com/log1997)\n[![build](https://img.shields.io/github/actions/workflow/status/log1997/log-lottery/release.yml)](https://github.com/log1997)\n[![docker](https://img.shields.io/docker/pulls/log1997/log-lottery)](<https://hub.docker.com/r/log1997/log-lottery>)\n[![github downloads](https://img.shields.io/github/downloads/log1997/log-lottery/total)](https://github.com/LOG1997/log-lottery/releases)\n[![release data](https://img.shields.io/github/release-date/log1997/log-lottery)](https://github.com/LOG1997/log-lottery/releases)\n[![last commit](https://img.shields.io/github/last-commit/log1997/log-lottery/dev)](https://github.com/LOG1997/log-lottery/commits/dev/)\n</div>\n\nlog-lotteryÊòØ‰∏Ä‰∏™ÂèØÈÖçÁΩÆÂèØÂÆöÂà∂ÂåñÁöÑÊäΩÂ•ñÂ∫îÁî®ÔºåÁÇ´ÈÖ∑3DÁêÉ‰ΩìÔºåÂèØÁî®‰∫éÂπ¥‰ºöÊäΩÂ•ñÁ≠âÊ¥ªÂä®ÔºåÊîØÊåÅÂ•ñÂìÅ„ÄÅ‰∫∫Âëò„ÄÅÁïåÈù¢„ÄÅÂõæÁâáÈü≥‰πêÈÖçÁΩÆ„ÄÇ\n\n> Â¶ÇÊûúËøõÂÖ•ÁΩëÁ´ôÈÅáÂà∞ÂõæÁâáÊó†Ê≥ïÊòæÁ§∫ÊàñÊúâÊä•ÈîôÁöÑÊÉÖÂÜµÔºåËØ∑ÂÖàÂà∞„ÄêÂÖ®Â±ÄÈÖçÁΩÆ„Äë-„ÄêÁïåÈù¢ÈÖçÁΩÆ„ÄëËèúÂçï‰∏≠ÁÇπÂáª„ÄêÈáçÁΩÆÊâÄÊúâÊï∞ÊçÆ„ÄëÊåâÈíÆÊ∏ÖÈô§Êï∞ÊçÆÂêéËøõË°åÊõ¥Êñ∞„ÄÇ\n\n> ‰∏çÊîØÊåÅÂÜÖÂÆöÂäüËÉΩ\n\n## Ë¶ÅÊ±Ç\n\n‰ΩøÁî®PCÁ´ØÊúÄÊñ∞ÁâàChromeÊàñEdgeÊµèËßàÂô®„ÄÇ\n\nËÆøÈóÆÂú∞ÂùÄÔºö\n\n<https://lottery.to2026.xyz/log-lottery>\n\nor\n\n<https://log1997.github.io/log-lottery/>\n\nÂºÄÂèë‰ªì‰øÉÔºåËã•‰ª•‰∏äÁΩëÁ´ôÂÜÖÂÆπÂ≠òÂú®bugËøòËØ∑ÂÆΩÂÆπ„ÄÇ\nÂ¶ÇÊûúÊÉ≥Ë¶ÅËÆøÈóÆ2025Âπ¥12Êúà31Êó•ÂâçÁöÑÁâàÊú¨ÔºåËØ∑ÂâçÂæÄÔºö<https://to2026.xyz/log-lottery>\n\n## TODO\n\n- [x] üïç ÁÇ´ÈÖ∑3DÁêÉ‰ΩìÔºåÂπ¥‰ºöÊäΩÂ•ñÂøÖÂ§áÔºåÂºÄÁÆ±Âç≥Áî®\n- [x] üíæ Êú¨Âú∞ÊåÅ‰πÖÂåñÂ≠òÂÇ®\n- [x] üéÅ Â•ñÂìÅÂ•ñÈ°πÈÖçÁΩÆ\n- [x] üë± ÊäΩÂ•ñÂêçÂçïËÆæÁΩÆÁÆ°ÁêÜ\n- [x] üéº Êí≠ÊîæËÉåÊôØÈü≥‰πê\n- [x] üñºÔ∏è excelË°®Ê†ºÂØºÂÖ•‰∫∫ÂëòÂêçÂçï„ÄÅÊäΩÂ•ñÁªìÊûú‰ΩøÁî®excelÂØºÂá∫\n- [x] üéà ÂèØÂ¢ûÂä†‰∏¥Êó∂ÊäΩÂ•ñ\n- [x] üß® ÂõΩÈôÖÂåñÂ§öËØ≠Ë®Ä\n- [x] üçÉ Êõ¥Êç¢ËÉåÊôØÂõæÁâá\n- [x] üöÖ Ê∑ªÂä†dockerÊûÑÂª∫\n- [x] üòò ÂºπÂπïÔºàÂºÄÂèë‰∏≠Ôºâ\n- [ ] üßµ Âç°ÁâáÁªÑÊàêÂ§öÁßçÂΩ¢Áä∂\n\n...\nÈúÄË¶ÅÊõ¥Â§öÂäüËÉΩÊàñÂèëÁé∞bugËØ∑ÁïôË®Ä[issues](https://github.com/LOG1997/log-lottery/issues)\n\n## ËØ¶ÁªÜ‰ªãÁªç\n\n### ÈÖçÁΩÆÂèÇ‰∏é‰∫∫Âëò\n\n‰∫é‰∫∫ÂëòÈÖçÁΩÆÁÆ°ÁêÜÁïåÈù¢‰∏ãËΩΩexcelÊ®°ÊùøÔºåÊåâË¶ÅÊ±ÇÂ°´Â•ΩÊï∞ÊçÆÂêéÂØºÂÖ•Âç≥ÂèØ„ÄÇ\n\n### ÈÖçÁΩÆÂ•ñÈ°π\n\n‰∫éÂ•ñÈ°πÈÖçÁΩÆÁÆ°ÁêÜÁïåÈù¢Ê∑ªÂä†Â•ñÈ°πÂêéÔºåËá™ÂÆö‰πâ‰øÆÊîπÂêçÁß∞„ÄÅÊäΩÂèñ‰∫∫Êï∞„ÄÅÊòØÂê¶ÂÖ®ÂëòÂèÇÂä†„ÄÅÂõæÁâáÊòæÁ§∫„ÄÇ\n\n### ÁïåÈù¢ÈÖçÁΩÆ\n\nÂèØËá™ÂÆö‰πâÈÖçÁΩÆÊ†áÈ¢ò„ÄÅÂàóÊï∞„ÄÅÂç°ÁâáÈ¢úËâ≤„ÄÅÈ¶ñÈ°µÂõæÊ°àÁ≠â„ÄÇ\n\n### ÂõæÁâáÂíåÈü≥‰πêÁÆ°ÁêÜ\n\n‰∏ä‰º†ÂõæÁâáÊàñÈü≥‰πêÂç≥ÂèØÔºåÊï∞ÊçÆ‰ΩøÁî®indexdbÂú®ÊµèËßàÂô®Êú¨Âú∞ËøõË°åÂ≠òÂÇ®„ÄÇ\n\n## È¢ÑËßà\n\nÈ¶ñÈ°µ\n<div align=\"center\">\n    <img src=\"./static/images/home.png\" alt=\"img2-1\" width=\"400\" style=\"border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); margin: 8px;\">\n    <img src=\"./static//images/home_prizelist.png\" alt=\"img2-2\" width=\"400\" style=\"border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); margin: 8px;\">\n</div>\n\nÊäΩÂ•ñ\n<div align=\"center\">\n    <img src=\"./static/images/lottery-enter.png\" alt=\"img2-1\" width=\"400\" style=\"border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); margin: 8px;\">\n    <img src=\"./static/images/lottery-done.png\" alt=\"img2-2\" width=\"400\" style=\"border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); margin: 8px;\">\n</div>\n\nÈÖçÁΩÆ\n<div align=\"center\">\n    <img src=\"./static/images/config_personall.png\" alt=\"img2-1\" width=\"400\" style=\"border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); margin: 8px;\">\n    <img src=\"./static/images/config_prize.png\" alt=\"img2-1\" width=\"400\" style=\"border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); margin: 8px;\">\n    <img src=\"./static/images/config-view.png\" alt=\"img2-1\" width=\"400\" style=\"border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); margin: 8px;\">\n    <img src=\"./static/images/config_pattern.png\" alt=\"img2-1\" width=\"400\" style=\"border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); margin: 8px;\">\n</div>\n\nÂõæÁâáÈü≥‰πêÈÖçÁΩÆ\n\n## ÊäÄÊúØ\n\n- vue3\n- threejs\n- indexdb\n- pinia\n- daisyui\n\n## ÂºÄÂèë\n\nÂÆâË£Ö‰æùËµñ\n\n```bash\npnpm i\nor\nnpm install\n```\n\nÂºÄÂèëËøêË°å\n\n```bash\npnpm dev\nor\nnpm run dev\n```\n\nÊâìÂåÖ\n\n```bash\npnpm build\nor\nnpm run build\n```\n\n> È°πÁõÆÊÄùË∑ØÊù•Ê∫ê‰∫é <https://github.com/moshang-xc/lottery>\n\n## DockerÊîØÊåÅ\n\n‰ª•‰∏ã‰ªªÊÑèÊñπÂºèÈÄâ‰∏ÄÁßçÂç≥ÂèØ\n\n1. ÊãâÂèñÈïúÂÉèÔºå‰ªéDocker HubÊãâÂèñÈïúÂÉè[log-lottery](https://hub.docker.com/r/log1997/log-lottery)\n\n    ```bash\n    docker pull log1997/log-lottery:latest\n    ```\n\n    ËøêË°åÂÆπÂô®\n\n    ```bash\n    docker run -d --name log-lottery -p 9279:80 log1997/log-lottery:latest\n    ```\n\n2. ÊâãÂä®ÊûÑÂª∫ÈïúÂÉè\n\n    ```bash\n    docker build -t log-lottery .\n    ```\n\n    ËøêË°åÂÆπÂô®\n\n    ```bash\n    docker run -d -p 9279:80 log-lottery\n    ```\n\n    ÂÆπÂô®ËøêË°åÊàêÂäüÂêéÂç≥ÂèØÂú®Êú¨Âú∞ÈÄöËøá<http://localhost:9279/log-lottery/>ËÆøÈóÆ\n\n## ËΩØ‰ª∂ÂÆâË£ÖÂåÖ\n\nÂèØÂâçÂæÄ[Releases](https://github.com/LOG1997/log-lottery/releases)‰∏ãËΩΩ„ÄÇ\n\nÁõÆÂâçÂè™ÊîØÊåÅwindowsÂπ≥Âè∞‰ΩøÁî®ÔºåË∑®Âπ≥Âè∞ÂÆâË£ÖÂåÖÊöÇ‰∏çÊîØÊåÅÔºåÂ¶ÇÊúâÈúÄË¶ÅËØ∑Ëá™Ë°åÁºñËØëÔºåÂèÇÁÖß[Ë¥°ÁåÆÊñáÊ°£](https://github.com/LOG1997/log-lottery/blob/main/.github/CONTRIBUTING.md)\n\n## ÊîØÊåÅÈ°πÁõÆ\n\n<h3>üíù ËµûÂä©ÊîØÊåÅ</h3>\n\n<p><em>Â¶ÇÊûúÊÇ®ËßâÂæó log-lottery ÂØπÊÇ®ÊúâÂ∏ÆÂä©ÔºåÊ¨¢ËøéËµûÂä©ÊîØÊåÅÔºåÊÇ®ÁöÑÊîØÊåÅÊòØÊàë‰ª¨‰∏çÊñ≠ÂâçËøõÁöÑÂä®ÂäõÔºÅ</em></p>\n\n<div>\n <img src=\"./static/images/ZanShang.png\" height=\"240\" alt=\"WeChat Code\">\n</div>\n\n<br>\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=LOG1997/log-lottery&type=Date)](https://star-history.com/#LOG1997/log-lottery&Date)\n\n## License\n\n[MIT](http://opensource.org/licenses/MIT)\n",
      "stars_today": 41
    },
    {
      "id": 4118776,
      "name": "shotcut",
      "full_name": "mltframework/shotcut",
      "description": "cross-platform (Qt), open-source (GPLv3) video editor",
      "html_url": "https://github.com/mltframework/shotcut",
      "stars": 13315,
      "forks": 1307,
      "language": "C++",
      "topics": [
        "cross-platform",
        "gplv3",
        "mlt",
        "shotcut",
        "video-editor"
      ],
      "created_at": "2012-04-23T22:37:04Z",
      "updated_at": "2026-01-24T02:05:06Z",
      "pushed_at": "2026-01-23T20:01:30Z",
      "open_issues": 50,
      "owner": {
        "login": "mltframework",
        "avatar_url": "https://avatars.githubusercontent.com/u/1558770?v=4"
      },
      "readme": "[![build-shotcut-linux](https://github.com/mltframework/shotcut/workflows/build-shotcut-linux/badge.svg)](https://github.com/mltframework/shotcut/actions?query=workflow%3Abuild-shotcut-linux+is%3Acompleted+branch%3Amaster)\n[![build-shotcut-macos](https://github.com/mltframework/shotcut/workflows/build-shotcut-macos/badge.svg)](https://github.com/mltframework/shotcut/actions?query=workflow%3Abuild-shotcut-macos+is%3Acompleted+branch%3Amaster)\n[![build-shotcut-windows](https://github.com/mltframework/shotcut/workflows/build-shotcut-windows/badge.svg)](https://github.com/mltframework/shotcut/actions?query=workflow%3Abuild-shotcut-windows+is%3Acompleted+branch%3Amaster)\n\n\n# Shotcut - a free, open source, cross-platform **video editor**\n\n<div align=\"center\">\n\n<img src=\"https://www.shotcut.org/assets/img/screenshots/Shotcut-18.11.18.png\" alt=\"screenshot\" />\n\n</div>\n\n- Features: https://www.shotcut.org/features/\n- Roadmap: https://www.shotcut.org/roadmap/\n\n## Install\n\nBinaries are regularly built and are available at https://www.shotcut.org/download/.\n\n## Contributors\n\n- Dan Dennedy <<http://www.dennedy.org>> : main author\n- Brian Matherly <<code@brianmatherly.com>> : contributor\n\n## Dependencies\n\nShotcut's direct (linked or hard runtime) dependencies are:\n\n- [MLT](https://www.mltframework.org/): multimedia authoring framework\n- [Qt 6 (6.4 mininum)](https://www.qt.io/): application and UI framework\n- [FFTW](https://fftw.org/)\n- [FFmpeg](https://www.ffmpeg.org/): multimedia format and codec libraries\n- [Frei0r](https://www.dyne.org/software/frei0r/): video plugins\n- [SDL](http://www.libsdl.org/): cross-platform audio playback\n\nSee https://shotcut.org/credits/ for a more complete list including indirect\nand bundled dependencies.\n\n## License\n\nGPLv3. See [COPYING](COPYING).\n\n## How to build\n\n**Warning**: building Shotcut should only be reserved to beta testers or contributors who know what they are doing.\n\n### Qt Creator\n\nThe fastest way to build and try Shotcut development version is through [Qt Creator](https://www.qt.io/download#qt-creator).\n\n### From command line\n\nFirst, check dependencies are satisfied and various paths are correctly set to find different libraries and include files (Qt, MLT, frei0r and so forth).\n\n#### Configure\n\nIn a new directory in which to make the build (separate from the source):\n\n```\ncmake -DCMAKE_INSTALL_PREFIX=/usr/local/ /path/to/shotcut\n```\n\nWe recommend using the Ninja generator by adding `-GNinja` to the above command line.\n\n#### Build\n\n```\ncmake --build .\n```\n\n#### Install\n\nIf you do not install, Shotcut may fail when you run it because it cannot locate its QML\nfiles that it reads at run-time.\n\n```\ncmake --install .\n```\n\n## Translation\n\nIf you want to translate Shotcut to another language, please use [Transifex](https://explore.transifex.com/ddennedy/shotcut/).\n",
      "stars_today": 37
    },
    {
      "id": 960420129,
      "name": "winboat",
      "full_name": "TibixDev/winboat",
      "description": "Run Windows apps on üêß Linux with ‚ú® seamless integration",
      "html_url": "https://github.com/TibixDev/winboat",
      "stars": 18233,
      "forks": 475,
      "language": "TypeScript",
      "topics": [
        "docker",
        "docker-compose",
        "linux",
        "rdp",
        "virtualization",
        "windows"
      ],
      "created_at": "2025-04-04T12:03:11Z",
      "updated_at": "2026-01-24T01:28:30Z",
      "pushed_at": "2026-01-04T08:22:35Z",
      "open_issues": 269,
      "owner": {
        "login": "TibixDev",
        "avatar_url": "https://avatars.githubusercontent.com/u/21055141?v=4"
      },
      "readme": "<div align=\"left\">\n  <table>\n    <tr>\n      <td>\n        <img src=\"icons/winboat_logo.svg\" alt=\"WinBoat Logo\" width=\"150\">\n      </td>\n      <td>\n        <h1 style=\"color: #7C86FF; margin: 0; font-size: 32px;\">WinBoat</h1>\n        <p style=\"color: oklch(90% 0 0); font-size: 14px; margin: 5px 0;\">Windows for Penguins.<br>\n        Run Windows apps on üêß Linux with ‚ú® seamless integration</p>\n      </td>\n    </tr>\n  </table>\n</div>\n\n## Screenshots\n\n<div align=\"center\">\n  <img src=\"gh-assets/features/feat_dash.png\" alt=\"WinBoat Dashboard\" width=\"45%\">\n  <img src=\"gh-assets/features/feat_apps.png\" alt=\"WinBoat Apps\" width=\"45%\">\n  <img src=\"gh-assets/features/feat_native.png\" alt=\"Native Windows\" width=\"45%\">\n</div>\n\n## ‚ö†Ô∏è Work in Progress ‚ö†Ô∏è\n\nWinBoat is currently in beta, so expect to occasionally run into hiccups and bugs. You should be comfortable with some level of troubleshooting if you decide to try it, however we encourage you to give it a shot anyway.\n\n## Features\n\n- **üé® Elegant Interface**: Sleek and intuitive interface that seamlessly integrates Windows into your Linux desktop environment, making it feel like a native experience\n- **üì¶ Automated Installs**: Simple installation process through our interface - pick your preferences & specs and let us handle the rest\n- **üöÄ Run Any App**: If it runs on Windows, it can run on WinBoat. Enjoy the full range of Windows applications as native OS-level windows in your Linux environment\n- **üñ•Ô∏è Full Windows Desktop**: Access the complete Windows desktop experience when you need it, or run individual apps seamlessly integrated into your Linux workflow\n- **üìÅ Filesystem Integration**: Your home directory is mounted in Windows, allowing easy file sharing between the two systems without any hassle\n- **‚ú® And many more**: Smartcard passthrough, resource monitoring, and more features being added regularly\n\n## How Does It Work?\n\nWinBoat is an Electron app which allows you to run Windows apps on Linux using a containerized approach. Windows runs as a VM inside a Docker/Podman container, we communicate with it using the [WinBoat Guest Server](https://github.com/TibixDev/winboat/tree/main/guest_server) to retrieve data we need from Windows. For compositing applications as native OS-level windows, we use FreeRDP together with Windows's RemoteApp protocol.\n\n## Prerequisites\n\nBefore running WinBoat, ensure your system meets the following requirements:\n\n- **RAM**: At least 4 GB of RAM\n- **CPU**: At least 2 CPU threads\n- **Storage**: At least 32 GB free space on the drive your selected install folder corresponds to\n- **Virtualization**: KVM enabled in BIOS/UEFI\n    - [How to enable virtualization](https://duckduckgo.com/?t=h_&q=how+to+enable+virtualization+in+%3Cmotherboard+brand%3E+bios&ia=web)\n- **In case of Docker:**\n  - **Docker**: Required for containerization\n      - [Installation Guide](https://docs.docker.com/engine/install/)\n      - **‚ö†Ô∏è NOTE:** Docker Desktop is **not** supported, you will run into issues if you use it\n  - **Docker Compose v2**: Required for compatibility with docker-compose.yml files\n      - [Installation Guide](https://docs.docker.com/compose/install/#plugin-linux-only)\n  - **Docker User Group**: Add your user to the `docker` group\n      - [Setup Instructions](https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user)\n- **In case of Podman:**\n  - **Podman**: Required for containerization\n      - [Installation Guide](https://podman.io/docs/installation#installing-on-linux)\n  - **Podman Compose**: Required for compatibility with podman-compose.yml files\n      - [Installation Guide](https://github.com/containers/podman-compose?tab=readme-ov-file#installation)\n- **FreeRDP**: Required for remote desktop connection (Please make sure you have **Version 3.x.x** with sound support included)\n    - [Installation Guide](https://github.com/FreeRDP/FreeRDP/wiki/PreBuilds)\n- [OPTIONAL] **Kernel Modules**: The `iptables` / `nftables` and `iptable_nat` kernel modules can be loaded for network autodiscovery and better shared filesystem performance, but this is not obligatory in newer versions of WinBoat\n    - [Module loading instructions](https://rentry.org/rmfq2e5e)\n\n## Downloading\n\nYou can download the latest Linux builds under the [Releases](https://github.com/TibixDev/winboat/releases) tab. We currently offer four variants:\n\n- **AppImage:** A popular & portable app format which should run fine on most distributions\n- **Unpacked:** The raw unpacked files, simply run the executable (`linux-unpacked/winboat`)\n- **.deb:** The intended format for Debian based distributions\n- **.rpm:** The intended format for Fedora based distributions\n\n## Known Issues About Container Runtimes\n\n- Docker Desktop is **unsupported** for now\n- USB passthrough via Podman is currently **unsupported**\n\n## Building WinBoat\n\n- For building you need to have NodeJS and Go installed on your system\n- Clone the repo (`git clone https://github.com/TibixDev/WinBoat`)\n- Install the dependencies (`npm i`)\n- Build the app and the guest server using `npm run build:linux-gs`\n- You can now find the built app under `dist` with an AppImage and an Unpacked variant\n\n## Running WinBoat in development mode\n\n- Make sure you meet the [prerequisites](#prerequisites)\n- Additionally, for development you need to have NodeJS and Go installed on your system\n- Clone the repo (`git clone https://github.com/TibixDev/WinBoat`)\n- Install the dependencies (`npm i`)\n- Build the guest server (`npm run build:gs`)\n- Run the app (`npm run dev`)\n\n## Contributing\n\nContributions are welcome! Whether it's bug fixes, feature improvements, or documentation updates, we appreciate your help making WinBoat better.\n\n**Please note**: We maintain a focus on technical contributions only. Pull requests containing political/sexual content, or other sensitive/controversial topics will not be accepted. Let's keep things focused on making great software! üöÄ\n\nFeel free to:\n\n- Report bugs and issues\n- Submit feature requests\n- Contribute code improvements\n- Help with documentation\n- Share feedback and suggestions\n\nCheck out our issues page to get started, or feel free to open a new issue if you've found something that needs attention.\n\n## License\n\nWinBoat is licensed under the [MIT](https://github.com/TibixDev/winboat/blob/main/LICENSE) license\n\n## Inspiration / Alternatives\n\nThese past few years some cool projects have surfaced with similar concepts, some of which we've also taken inspirations from.\\\nThey're awesome and you should check them out:\n\n- [WinApps](https://github.com/winapps-org/winapps)\n- [Cassowary](https://github.com/casualsnek/cassowary)\n- [dockur/windows](https://github.com/dockur/windows) (üåü Also used in WinBoat)\n\n## Socials & Contact\n\n- [![Website](https://img.shields.io/badge/Website-winboat.app-blue?style=flat&logo=googlechrome&logoColor=white)](https://www.winboat.app/)\n- [![Twitter](https://img.shields.io/badge/Twitter-@winboat__app-1DA1F2?style=flat&logo=x&logoColor=white)](https://x.com/winboat_app)\n- [![Mastodon](https://img.shields.io/badge/Mastodon-@winboat-6364FF?style=flat&logo=mastodon&logoColor=white)](https://fosstodon.org/@winboat)\n- [![Bluesky](https://img.shields.io/badge/Bluesky-winboat.app-00A8E8?style=flat&logo=bluesky&logoColor=white)](http://bsky.app/profile/winboat.app)\n- [![Discord](https://img.shields.io/badge/Discord-Join_Community-5865F2?style=flat&logo=discord&logoColor=white)](http://discord.gg/MEwmpWm4tN)\n- [![Email](https://img.shields.io/badge/Email-staff@winboat.app-D14836?style=flat&logo=gmail&logoColor=white)](mailto:staff@winboat.app)\n- [![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/TibixDev/winboat)\n\n## Star History\n\n<a href=\"https://www.star-history.com/#tibixdev/winboat&Date\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=tibixdev/winboat&type=Date&theme=dark\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=tibixdev/winboat&type=Date\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=tibixdev/winboat&type=Date\" />\n </picture>\n</a>\n",
      "stars_today": 37
    },
    {
      "id": 942206898,
      "name": "dynamo",
      "full_name": "ai-dynamo/dynamo",
      "description": "A Datacenter Scale Distributed Inference Serving Framework",
      "html_url": "https://github.com/ai-dynamo/dynamo",
      "stars": 5918,
      "forks": 807,
      "language": "Rust",
      "topics": [],
      "created_at": "2025-03-03T18:40:07Z",
      "updated_at": "2026-01-24T01:57:38Z",
      "pushed_at": "2026-01-24T01:35:37Z",
      "open_issues": 456,
      "owner": {
        "login": "ai-dynamo",
        "avatar_url": "https://avatars.githubusercontent.com/u/201626793?v=4"
      },
      "readme": "<!--\nSPDX-FileCopyrightText: Copyright (c) 2024-2026 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\nSPDX-License-Identifier: Apache-2.0\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n-->\n\n![Dynamo banner](./docs/images/frontpage-banner.png)\n\n[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n[![GitHub Release](https://img.shields.io/github/v/release/ai-dynamo/dynamo)](https://github.com/ai-dynamo/dynamo/releases/latest)\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/ai-dynamo/dynamo)\n[![Discord](https://dcbadge.limes.pink/api/server/D92uqZRjCZ?style=flat)](https://discord.gg/D92uqZRjCZ) ![Community Contributors](https://img.shields.io/badge/community_contributors-70%2B-brightgreen) ![Community PRs](https://img.shields.io/badge/PRs_merged-130%2B-blue)\n\n| **[Roadmap](https://github.com/ai-dynamo/dynamo/issues/5506)** | **[Support Matrix](https://github.com/ai-dynamo/dynamo/blob/main/docs/reference/support-matrix.md)** | **[Docs](https://docs.nvidia.com/dynamo/latest/index.html)** | **[Recipes](https://github.com/ai-dynamo/dynamo/tree/main/recipes)** | **[Examples](https://github.com/ai-dynamo/dynamo/tree/main/examples)** | **[Prebuilt Containers](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/collections/ai-dynamo)** | **[Design Proposals](https://github.com/ai-dynamo/enhancements)** | **[Blogs](https://developer.nvidia.com/blog/tag/nvidia-dynamo)**\n\n# NVIDIA Dynamo\n\nHigh-throughput, low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments.\n\n## Why Dynamo\n\n<p align=\"center\">\n  <img src=\"./docs/images/frontpage-gpu-vertical.png\" alt=\"Multi Node Multi-GPU topology\" width=\"600\" />\n</p>\n\nLarge language models exceed single-GPU capacity. Tensor parallelism spreads layers across GPUs but creates coordination challenges. Dynamo closes this orchestration gap.\n\nDynamo is inference engine agnostic (supports TRT-LLM, vLLM, SGLang) and provides:\n\n- **Disaggregated Prefill & Decode** ‚Äì Maximizes GPU throughput with latency/throughput trade-offs\n- **Dynamic GPU Scheduling** ‚Äì Optimizes performance based on fluctuating demand\n- **LLM-Aware Request Routing** ‚Äì Eliminates unnecessary KV cache re-computation\n- **Accelerated Data Transfer** ‚Äì Reduces inference response time using NIXL\n- **KV Cache Offloading** ‚Äì Leverages multiple memory hierarchies for higher throughput\n\n<p align=\"center\">\n  <img src=\"./docs/images/frontpage-architecture.png\" alt=\"Dynamo architecture\" width=\"600\" />\n</p>\n\nBuilt in Rust for performance and Python for extensibility, Dynamo is fully open-source with an OSS-first development approach.\n\n## Framework Support Matrix\n\n| Feature                                                              | [vLLM](docs/backends/vllm/README.md) | [SGLang](docs/backends/sglang/README.md) | [TensorRT-LLM](docs/backends/trtllm/README.md) |\n| -------------------------------------------------------------------- | :--: | :----: | :----------: |\n| [**Disaggregated Serving**](docs/design_docs/disagg_serving.md)      | ‚úÖ   | ‚úÖ     | ‚úÖ           |\n| [**KV-Aware Routing**](docs/router/kv_cache_routing.md)              | ‚úÖ   | ‚úÖ     | ‚úÖ           |\n| [**SLA-Based Planner**](docs/planner/sla_planner.md)                 | ‚úÖ   | ‚úÖ     | ‚úÖ           |\n| [**KVBM**](docs/kvbm/kvbm_architecture.md)                           | ‚úÖ   | üöß     | ‚úÖ           |\n| [**Multimodal**](docs/multimodal/index.md)                           | ‚úÖ   | ‚úÖ     | ‚úÖ           |\n| [**Tool Calling**](docs/agents/tool-calling.md)                      | ‚úÖ   | ‚úÖ     | ‚úÖ           |\n\n> **[Full Feature Matrix ‚Üí](feature-matrix.md)** ‚Äî Detailed compatibility including LoRA, Request Migration, Speculative Decoding, and feature interactions.\n\n## Latest News\n\n- [12/05] [Moonshot AI's Kimi K2 achieves 10x inference speedup with Dynamo on GB200](https://quantumzeitgeist.com/kimi-k2-nvidia-ai-ai-breakthrough/)\n- [12/02] [Mistral AI runs Mistral Large 3 with 10x faster inference using Dynamo](https://www.marktechpost.com/2025/12/02/nvidia-and-mistral-ai-bring-10x-faster-inference-for-the-mistral-3-family-on-gb200-nvl72-gpu-systems/)\n- [12/01] [InfoQ: NVIDIA Dynamo simplifies Kubernetes deployment for LLM inference](https://www.infoq.com/news/2025/12/nvidia-dynamo-kubernetes/)\n- [11/20] [Dell integrates PowerScale with Dynamo's NIXL for 19x faster TTFT](https://www.dell.com/en-us/dt/corporate/newsroom/announcements/detailpage.press-releases~usa~2025~11~dell-technologies-and-nvidia-advance-enterprise-ai-innovation.htm)\n- [11/20] [WEKA partners with NVIDIA on KV cache storage for Dynamo](https://siliconangle.com/2025/11/20/nvidia-weka-kv-cache-solution-ai-inferencing-sc25/)\n- [11/13] [Dynamo Office Hours Playlist](https://www.youtube.com/playlist?list=PL5B692fm6--tgryKu94h2Zb7jTFM3Go4X)\n- [10/16] [How Baseten achieved 2x faster inference with NVIDIA Dynamo](https://www.baseten.co/blog/how-baseten-achieved-2x-faster-inference-with-nvidia-dynamo/)\n\n## Get Started\n\n| Path | Use Case | Time | Requirements |\n|------|----------|------|--------------|\n| [**Local Quick Start**](#local-quick-start) | Test on a single machine | ~5 min | 1 GPU, Ubuntu 24.04 |\n| [**Kubernetes Deployment**](#kubernetes-deployment) | Production multi-node clusters | ~30 min | K8s cluster with GPUs |\n\n## Contributing\n\nWant to help shape the future of distributed LLM inference? We welcome contributors at all levels‚Äîfrom doc fixes to new features.\n\n- **[Contributing Guide](CONTRIBUTING.md)** ‚Äì How to get started\n- **[Report a Bug](https://github.com/ai-dynamo/dynamo/issues/new?template=bug_report.yml)** ‚Äì Found an issue?\n- **[Feature Request](https://github.com/ai-dynamo/dynamo/issues/new?template=feature_request.yml)** ‚Äì Have an idea?\n\n# Local Quick Start\n\nThe following examples require a few system level packages.\nRecommended to use Ubuntu 24.04 with a x86_64 CPU. See [docs/reference/support-matrix.md](docs/reference/support-matrix.md)\n\n## 1. Initial Setup\n\nThe Dynamo team recommends the `uv` Python package manager, although any way works. Install uv:\n\n```\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n### Install Python Development Headers\n\nBackend engines require Python development headers for JIT compilation. Install them with:\n\n```bash\nsudo apt install python3-dev\n```\n\n## 2. Select an Engine\n\nWe publish Python wheels specialized for each of our supported engines: vllm, sglang, and trtllm. The examples that follow use SGLang; continue reading for other engines.\n\n```\nuv venv venv\nsource venv/bin/activate\nuv pip install pip\n\n# Choose one\nuv pip install \"ai-dynamo[sglang]\"  #replace with [vllm], [trtllm], etc.\n```\n\n## 3. Run Dynamo\n\n### Sanity Check (Optional)\n\nBefore trying out Dynamo, you can verify your system configuration and dependencies:\n\n```bash\npython3 deploy/sanity_check.py\n```\n\nThis is a quick check for system resources, development tools, LLM frameworks, and Dynamo components.\n\n### Running an LLM API Server\n\nDynamo provides a simple way to spin up a local set of inference components including:\n\n- **OpenAI Compatible Frontend** ‚Äì High performance OpenAI compatible http api server written in Rust.\n- **Basic and Kv Aware Router** ‚Äì Route and load balance traffic to a set of workers.\n- **Workers** ‚Äì Set of pre-configured LLM serving engines.\n\n```bash\n# Start an OpenAI compatible HTTP server with prompt templating, tokenization, and routing.\n# For local dev: --store-kv file avoids etcd (workers and frontend must share a disk)\npython3 -m dynamo.frontend --http-port 8000 --store-kv file\n\n# Start the SGLang engine. You can run several of these for the same or different models.\n# The frontend will discover them automatically.\npython3 -m dynamo.sglang --model-path deepseek-ai/DeepSeek-R1-Distill-Llama-8B --store-kv file\n```\n\n> **Note:** vLLM workers publish KV cache events by default, which requires NATS. For dependency-free local development with vLLM, add `--kv-events-config '{\"enable_kv_cache_events\": false}'`. This keeps local prefix caching enabled while disabling event publishing. See [Service Discovery and Messaging](#service-discovery-and-messaging) for details.\n\n#### Send a Request\n\n```bash\ncurl localhost:8000/v1/chat/completions   -H \"Content-Type: application/json\"   -d '{\n    \"model\": \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\",\n    \"messages\": [\n    {\n        \"role\": \"user\",\n        \"content\": \"Hello, how are you?\"\n    }\n    ],\n    \"stream\":false,\n    \"max_tokens\": 300\n  }' | jq\n```\n\nRerun with `curl -N` and change `stream` in the request to `true` to get the responses as soon as the engine issues them.\n\n### What's Next?\n\n- **Scale up**: Deploy on Kubernetes with [Recipes](recipes/)\n- **Add features**: Enable [KV-aware routing](docs/router/kv_cache_routing.md), [disaggregated serving](docs/design_docs/disagg_serving.md)\n- **Benchmark**: Use [AIPerf](docs/benchmarks/benchmarking.md) to measure performance\n- **Try other engines**: [vLLM](docs/backends/vllm/), [SGLang](docs/backends/sglang/), [TensorRT-LLM](docs/backends/trtllm/)\n\n# Kubernetes Deployment\n\nFor production deployments on Kubernetes clusters with multiple GPUs.\n\n## Prerequisites\n\n- Kubernetes cluster with GPU nodes\n- [Dynamo Platform installed](docs/kubernetes/README.md)\n- HuggingFace token for model downloads\n\n## Production Recipes\n\nPre-built deployment configurations for common models and topologies:\n\n| Model | Framework | Mode | GPUs | Recipe |\n|-------|-----------|------|------|--------|\n| Llama-3.1-70B | vLLM | Aggregated | 4x H100 | [View](recipes/vllm/llama-3.1-70b/) |\n| DeepSeek-R1 | SGLang | Disaggregated | 8x H200 | [View](recipes/sglang/deepseek-r1/) |\n| Qwen3-32B | TensorRT-LLM | Disaggregated | 8x GPU | [View](recipes/trtllm/qwen3-32b/) |\n\nSee [recipes/README.md](recipes/README.md) for the full list and deployment instructions.\n\n## Cloud Deployment Guides\n\n- [Amazon EKS](examples/deployments/EKS/)\n- [Google GKE](examples/deployments/GKE/)\n\n# Concepts\n\n## Engines\n\nDynamo is inference engine agnostic. Install the wheel for your chosen engine and run with `python3 -m dynamo.<engine> --help`.\n\n| Engine | Install | Docs | Best For |\n|--------|---------|------|----------|\n| vLLM | `uv pip install ai-dynamo[vllm]` | [Guide](docs/backends/vllm/) | Broadest feature coverage |\n| SGLang | `uv pip install ai-dynamo[sglang]` | [Guide](docs/backends/sglang/) | High-throughput serving |\n| TensorRT-LLM | `pip install --pre --extra-index-url https://pypi.nvidia.com ai-dynamo[trtllm]` | [Guide](docs/backends/trtllm/) | Maximum performance |\n\n> **Note:** TensorRT-LLM requires `pip` (not `uv`) due to URL-based dependencies. See the [TRT-LLM guide](docs/backends/trtllm/) for container setup and prerequisites.\n\nUse `CUDA_VISIBLE_DEVICES` to specify which GPUs to use. Engine-specific options (context length, multi-GPU, etc.) are documented in each backend guide.\n\n## Service Discovery and Messaging\n\nDynamo uses TCP for inter-component communication. External services are optional for most deployments:\n\n| Deployment | etcd | NATS | Notes |\n|------------|------|------|-------|\n| **Kubernetes** | ‚ùå Not required | ‚ùå Not required | K8s-native discovery; TCP request plane |\n| **Local Development** | ‚ùå Not required | ‚ùå Not required | Pass `--store-kv file`; vLLM also needs `--kv-events-config '{\"enable_kv_cache_events\": false}'` |\n| **KV-Aware Routing** | ‚Äî | ‚úÖ Required | Prefix caching enabled by default requires NATS |\n\nFor local development without external dependencies, pass `--store-kv file` (avoids etcd) to both the frontend and workers. vLLM users should also pass `--kv-events-config '{\"enable_kv_cache_events\": false}'` to disable KV event publishing (avoids NATS) while keeping local prefix caching enabled; SGLang and TRT-LLM don't require this flag.\n\nFor distributed non-Kubernetes deployments or KV-aware routing:\n\n- [etcd](https://etcd.io/) can be run directly as `./etcd`.\n- [nats](https://nats.io/) needs JetStream enabled: `nats-server -js`.\n\nTo quickly setup both: `docker compose -f deploy/docker-compose.yml up -d`\n\n# Advanced Topics\n\n## Benchmarking\n\nDynamo provides comprehensive benchmarking tools:\n\n- **[Benchmarking Guide](docs/benchmarks/benchmarking.md)** ‚Äì Compare deployment topologies using AIPerf\n- **[SLA-Driven Deployments](docs/planner/sla_planner_quickstart.md)** ‚Äì Optimize deployments to meet SLA requirements\n\n## Frontend OpenAPI Specification\n\nThe OpenAI-compatible frontend exposes an OpenAPI 3 spec at `/openapi.json`. To generate without running the server:\n\n```bash\ncargo run -p dynamo-llm --bin generate-frontend-openapi\n```\n\nThis writes to `docs/frontends/openapi.json`.\n\n# Building from Source\n\nFor contributors who want to build Dynamo from source rather than installing from PyPI.\n\n## 1. Install Libraries\n\n**Ubuntu:**\n\n```\nsudo apt install -y build-essential libhwloc-dev libudev-dev pkg-config libclang-dev protobuf-compiler python3-dev cmake\n```\n\n**macOS:**\n\n- [Homebrew](https://brew.sh/)\n\n```\n# if brew is not installed on your system, install it\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n```\n\n- [Xcode](https://developer.apple.com/xcode/)\n\n```\nbrew install cmake protobuf\n\n## Check that Metal is accessible\nxcrun -sdk macosx metal\n```\n\nIf Metal is accessible, you should see an error like `metal: error: no input files`, which confirms it is installed correctly.\n\n## 2. Install Rust\n\n```\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\nsource $HOME/.cargo/env\n```\n\n## 3. Create a Python Virtual Environment\n\nFollow the instructions in [uv installation](https://docs.astral.sh/uv/#installation) guide to install uv if you don't have `uv` installed. Once uv is installed, create a virtual environment and activate it.\n\n- Install uv\n\n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n- Create a virtual environment\n\n```bash\nuv venv dynamo\nsource dynamo/bin/activate\n```\n\n## 4. Install Build Tools\n\n```\nuv pip install pip maturin\n```\n\n[Maturin](https://github.com/PyO3/maturin) is the Rust<->Python bindings build tool.\n\n## 5. Build the Rust Bindings\n\n```\ncd lib/bindings/python\nmaturin develop --uv\n```\n\n## 6. Install GPU Memory Service\n\nThe GPU Memory Service is a Python package with a C++ extension. It requires only Python development headers and a C++ compiler (g++).\n\n```bash\ncd $PROJECT_ROOT\nuv pip install -e lib/gpu_memory_service\n```\n\n## 7. Install the Wheel\n\n```\ncd $PROJECT_ROOT\nuv pip install -e .\n```\n\nYou should now be able to run `python3 -m dynamo.frontend`.\n\nFor local development, pass `--store-kv file` to avoid external dependencies (see Service Discovery and Messaging section).\n\nSet the environment variable `DYN_LOG` to adjust the logging level; for example, `export DYN_LOG=debug`. It has the same syntax as `RUST_LOG`.\n\nIf you use vscode or cursor, we have a .devcontainer folder built on [Microsofts Extension](https://code.visualstudio.com/docs/devcontainers/containers). For instructions see the [ReadMe](.devcontainer/README.md) for more details.\n\n<!-- Reference links for Feature Compatibility Matrix -->\n[disagg]: docs/design_docs/disagg_serving.md\n[kv-routing]: docs/router/kv_cache_routing.md\n[planner]: docs/planner/sla_planner.md\n[kvbm]: docs/kvbm/kvbm_architecture.md\n[mm]: examples/multimodal/\n[migration]: docs/fault_tolerance/request_migration.md\n[lora]: examples/backends/vllm/deploy/lora/README.md\n[tools]: docs/agents/tool-calling.md\n",
      "stars_today": 33
    },
    {
      "id": 277621205,
      "name": "umbrel",
      "full_name": "getumbrel/umbrel",
      "description": "A beautiful home server OS for self-hosting with an app store. Buy a pre-built Umbrel Home with umbrelOS, or install on a Raspberry Pi or any x86 system.",
      "html_url": "https://github.com/getumbrel/umbrel",
      "stars": 10347,
      "forks": 691,
      "language": "TypeScript",
      "topics": [
        "bitcoin",
        "docker",
        "home-server",
        "homeserver",
        "lightning",
        "personal-server",
        "raspberry-pi",
        "raspberrypi",
        "self-hosted",
        "self-hosting",
        "selfhosted"
      ],
      "created_at": "2020-07-06T18:40:02Z",
      "updated_at": "2026-01-24T01:55:36Z",
      "pushed_at": "2025-11-05T11:06:25Z",
      "open_issues": 380,
      "owner": {
        "login": "getumbrel",
        "avatar_url": "https://avatars.githubusercontent.com/u/59408891?v=4"
      },
      "readme": "[![umbrelOS](https://github.com/user-attachments/assets/cabf8af7-51ce-45df-ad3a-a664cc91c610)](https://umbrel.com/umbrelos)\n\n<p align=\"center\">\n  <h1 align=\"center\">umbrelOS</h1>\n  <p align=\"center\">\n    A beautiful home server OS for self-hosting\n    <br />\n    <a href=\"https://umbrel.com\"><strong>umbrel.com ¬ª</strong></a>\n    <br />\n    <br />\n       Get an <a href=\"https://umbrel.com/umbrel-home\">Umbrel Home</a> for the full experience, or install umbrelOS on a <a href=\"https://github.com/getumbrel/umbrel/wiki/Install-umbrelOS-on-a-Raspberry-Pi-5\">Raspberry Pi 5</a> or <a href=\"https://github.com/getumbrel/umbrel/wiki/Install-umbrelOS-on-x86-systems\">any x86 system</a> for free.\n    <br />\n    <br />\n    <a href=\"https://x.com/umbrel\">\n      <img src=\"https://img.shields.io/twitter/follow/umbrel?style=social\" />\n    </a>\n    <a href=\"https://discord.gg/efNtFzqtdx\">\n      <img src=\"https://img.shields.io/discord/936694604231766046?logo=discord&logoColor=5351FB&label=Discord&labelColor=white&color=5351FB&cacheSeconds=60\">\n    </a>\n    <a href=\"https://reddit.com/r/getumbrel\">\n      <img src=\"https://img.shields.io/reddit/subreddit-subscribers/getumbrel?style=social\">\n    </a>\n    <a href=\"https://community.umbrel.com\">\n      <img src=\"https://img.shields.io/discourse/users?server=https%3A%2F%2Fcommunity.umbrel.com&style=flat&label=Community%20Forum&color=5351FB&cacheSeconds=60\">\n    </a>\n  </p>\n</p>\n\n<br />\n\n<p align=\"center\">\nAt Umbrel, we believe that everyone should be able to enjoy the convenience and benefits of the cloud, without giving up ownership and control of their data.\n</p>\n\n<p align=\"center\">\nTo achieve our vision, we're building a new kind of a home server OS. Instead of paying ransoms for storing your data on someone else's computer while they auction it off to advertisers ‚Äî you can now easily spin up a server and self-host your data and services at home.\n</p>\n\n<p align=\"center\">\nJust like the cloud, but one that you own and control.\n</p>\n\n<br />\n\n## Installing umbrelOS\n\numbrelOS is designed for the [Umbrel Home](https://umbrel.com/umbrel-home), where it includes first-class support for all features. On other devices (like Raspberry Pi or x86 systems), it‚Äôs freely available with core functionality, but support and feature availability are best-effort due to hardware differences.\n\nFor a detailed feature breakdown, see our [comparison guide](https://github.com/getumbrel/umbrel/wiki/umbrelOS-on-Umbrel-Home-vs.-DIY).\n\n### Installation guides\n- [Install umbrelOS on a Raspberry Pi 5](https://github.com/getumbrel/umbrel/wiki/Install-umbrelOS-on-a-Raspberry-Pi-5)\n- [Install umbrelOS on any x86 system](https://github.com/getumbrel/umbrel/wiki/Install-umbrelOS-on-x86-Systems)\n- [Install umbrelOS in a VM](https://github.com/getumbrel/umbrel/wiki/Install-umbrelOS-on-a-Linux-VM)\n\n[![umbrelOS use cases](https://github.com/user-attachments/assets/284feee7-15a1-48f2-a694-c968f1cc702f)](https://umbrel.com/umbrelos)\n[![Umbrel App Store](https://github.com/user-attachments/assets/3d7846c7-d896-48f5-8a30-3578554702fa)](https://apps.umbrel.com)\n[![Files on umbrelOS](https://github.com/user-attachments/assets/6c501256-47a0-4ce1-89ad-4ba02f4c9f2d)](https://umbrel.com/umbrelos)\n[![umbrelOS Features](https://github.com/user-attachments/assets/6828da74-2b64-4b56-a7b7-5db603d023c8)](https://umbrel.com/umbrelos)\n[![Backups in umbrelOS](https://github.com/user-attachments/assets/39778824-ed18-4f6f-a865-1d77bbfce833)](https://umbrel.com/umbrelos)\n[![External Storage & NAS in umbrelOS](https://github.com/user-attachments/assets/4841c2dc-4ba4-4d47-bf0a-0e342bf60166)](https://umbrel.com/umbrelos)\n\n## Building apps for umbrelOS\n\nIf you're interested in building an app for umbrelOS or packaging an existing one, please refer to the [Umbrel App Framework documentation](https://github.com/getumbrel/umbrel-apps/blob/master/README.md).\n\n## License\n\numbrelOS is licensed under the PolyForm Noncommercial 1.0.0 license. TL;DR ‚Äî You're free to use, fork, modify, and redistribute Umbrel for personal and nonprofit use under the same license. If you're interested in using umbrelOS for commercial purposes, such as selling plug-and-play home servers with umbrelOS, etc ‚Äî please reach out to us at partner@umbrel.com.\n\n[![License](https://img.shields.io/badge/license-PolyForm%20Noncommercial%201.0.0-%235351FB)](https://github.com/getumbrel/umbrel/blob/master/LICENSE.md)\n\n[umbrel.com](https://umbrel.com)\n",
      "stars_today": 32
    },
    {
      "id": 825187044,
      "name": "ab-download-manager",
      "full_name": "amir1376/ab-download-manager",
      "description": "A Download Manager that speeds up your downloads",
      "html_url": "https://github.com/amir1376/ab-download-manager",
      "stars": 13002,
      "forks": 680,
      "language": "Kotlin",
      "topics": [
        "chrome",
        "compose",
        "compose-desktop",
        "compose-multiplatform",
        "desktop",
        "desktop-app",
        "download",
        "download-manager",
        "downloader",
        "downloadmanager",
        "firefox",
        "kotlin",
        "kotlin-multiplatform",
        "linux",
        "windows"
      ],
      "created_at": "2024-07-07T03:56:25Z",
      "updated_at": "2026-01-24T02:03:42Z",
      "pushed_at": "2026-01-20T02:24:31Z",
      "open_issues": 343,
      "owner": {
        "login": "amir1376",
        "avatar_url": "https://avatars.githubusercontent.com/u/38394888?v=4"
      },
      "readme": "<div align=\"center\">\n  <a href=\"https://abdownloadmanager.com\" target=\"_blank\">\n    <img width=\"180\" src=\"assets/logo/app_logo_with_background.svg\" alt=\"AB Download Manager Logo\">\n  </a>\n</div>\n<h1 align=\"center\">AB Download Manager</h1>\n<p align=\"center\">\n    <a href=\"https://github.com/amir1376/ab-download-manager/releases/latest\"><img alt=\"GitHub Release\" src=\"https://img.shields.io/github/v/release/amir1376/ab-download-manager?color=greenlight&label=latest%20release\"></a>\n    <a href=\"https://abdownloadmanager.com\"><img alt=\"AB Download Manager Website\" src=\"https://img.shields.io/badge/project-website-purple?&labelColor=gray\"></a>\n    <a href=\"https://t.me/abdownloadmanager_discussion\"><img alt=\"Telegram Group\" src=\"https://img.shields.io/badge/Telegram-Group-blue?logo=telegram&labelColor=gray\"></a>\n    <a href=\"https://t.me/abdownloadmanager\"><img alt=\"Telegram Channel\" src=\"https://img.shields.io/badge/Telegram-Channel-blue?logo=telegram&labelColor=gray\"></a>\n    <a href=\"https://crowdin.com/project/ab-download-manager\"><img alt=\"Crowdin\" src=\"https://badges.crowdin.net/ab-download-manager/localized.svg\"></a>\n</p>\n\n<a href=\"https://abdownloadmanager.com\" target=\"_blank\">\n    <img alt=\"AB Download Manager Banner\" src=\"assets/banners/app_banner.png\"/>\n</a>\n\n\n## Description\n\n[AB Download Manager](https://abdownloadmanager.com) is a desktop app that helps you manage and organize your downloads more efficiently than ever before.\n\n## Features\n\n- ‚ö°Ô∏è Faster Download Speed\n- ‚è∞ Queues and Schedulers\n- üåê Browser Extensions\n- üíª Multiplatform (Android / Windows / Linux / Mac)\n- üåô Multiple Themes (Dark/Light/Black and more) with modern UI\n- ‚ù§Ô∏è Free and Open Source\n\nPlease visit [Project Website](https://abdownloadmanager.com) for more info.\n\n## Installation\n\n### Download and Install the App\n\n<a href=\"https://abdownloadmanager.com\"><img src=\"https://img.shields.io/badge/Official%20Website-897BFF?logo=abdownloadmanager&logoColor=fff&style=flat-square\" alt=\"Official Website\" height=\"32\" /></a>\n<a href=\"https://github.com/amir1376/ab-download-manager/releases/latest\"><img src=\"https://img.shields.io/badge/GitHub%20Releases-2a2f36?logo=github&logoColor=fff&style=flat-square\" alt=\"GitHub Releases\" height=\"32\" /></a>\n\n#### Installation script (Linux)\n\n```bash\nbash <(curl -fsSL https://raw.githubusercontent.com/amir1376/ab-download-manager/master/scripts/install.sh)\n```\n\n#### Winget or Scoop (for Windows)\n\n**winget**:\n\n```bash\nwinget install amir1376.ABDownloadManager\n```\n\n**scoop**:\n\n```bash\nscoop install extras/abdownloadmanager\n```\n\n#### Homebrew (for macOS & Linux)\n\n```bash\nbrew tap amir1376/tap && brew install --cask ab-download-manager\n```\n\n> ‚ö†Ô∏è **Warning:** This software is NOT on Google Play or other app stores unless listed here. Any version **claiming to be or related to this project** should be considered SCAM and UNSAFE.\n\nFor alternative installation methods, uninstallation instructions, and more details, please refer to the [wiki](https://github.com/amir1376/ab-download-manager/wiki/) page.\n\n### Browser Extensions\n\nYou can download the browser extension to integrate the app with your browser.\n\n<p align=\"left\">\n<a href=\"https://addons.mozilla.org/firefox/addon/ab-download-manager/\">\n    <picture>\n        <img alt=\"Chrome Extension\" src=\"./assets/banners/firefox-extension.png\" height=\"48\">\n    </picture>\n</a>\n<a href=\"https://chromewebstore.google.com/detail/bbobopahenonfdgjgaleledndnnfhooj\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/banners/chrome-extension_dark.png\" height=\"48\">\n        <source media=\"(prefers-color-scheme: light)\" srcset=\"./assets/banners/chrome-extension_light.png\" height=\"48\">\n        <img alt=\"Chrome Extension\" src=\"./assets/banners/chrome-extension_light.png\" height=\"48\">\n    </picture>\n</a>\n</p>\n\n## Screenshots\n\n<div align=\"center\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/screenshots/app-home_dark.png\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"./assets/screenshots/app-home_light.png\">\n  <img alt=\"App Home Section\" src=\"./assets/screenshots/app-home_dark.png\">\n</picture>\n\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/screenshots/app-download_dark.png\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"./assets/screenshots/app-download_light.png\">\n  <img alt=\"App Download Section\" src=\"./assets/screenshots/app-download_dark.png\">\n</picture>\n</div>\n\n## Project Status & Feedback\n\nPlease keep in mind that this project is in the beginning of its journey.\n**Lots of features** are on the way!\n\n**But**, in the meantime you may face **Bugs or Problems**. If you do, please report them to me via the [Community chat](#community) or through `GitHub Issues`, and I'll do my best to fix them ASAP.\n\n## Community\n\nYou can join our [Telegram Group](https://t.me/abdownloadmanager_discussion) to:\n\n- Report problems\n- Suggest features\n- Get help with the app\n\n## Repositories And Source Code\n\nThere are multiple repositories related to the **AB Download Manager** project:\n\n| Repository                                                                                 | Description                                                                   |\n|--------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------|\n| [Main Application](https://github.com/amir1376/ab-download-manager) (You are here)         | Contains the  **Application** that runs on your  **device**                   |\n| [Browser Integration](https://github.com/amir1376/ab-download-manager-browser-integration) | Contains the **Browser Extension** to be installed on your  **browser**       |\n| [Website](https://github.com/amir1376/ab-download-manager-website)                         | Contains the **AB Download Manager** [website](https://abdownloadmanager.com) |\n\nI've spent a lot of time to create this project.\n\nIf you like my work, please consider giving it a ‚≠ê ‚Äî thanks! ‚ù§Ô∏è\n\n## Bug Report\n\nIf you notice any bugs in the source code, please report them via the `GitHub Issues` section.\n\n## Build From Source\n\nTo compile and test the desktop app on your local machine,\nfollow these steps:\n\n1. Clone the project.\n2. Download and extract the [JBR](https://github.com/JetBrains/JetBrainsRuntime/releases), and make it available by either:\n    \n    - Adding it to your `PATH`, or\n    - Setting the `JAVA_HOME` environment variable to its installation path.\n  \n3. Navigate to the project directory, open your terminal and execute the following command:\n\n    ```bash\n    ./gradlew createReleaseFolderForCi\n    ```\n\n4. The output will be available at:\n\n    ```\n    <project_dir>/build/ci-release\n    ```\n\n> **Note**. This project is compiled and published by GitHub actions [here](./.github/workflows/publish.yml), so if you\n> faced any problem you can check that too.\n\n## Translations\n\nIf you‚Äôd like to help translate AB Download Manager into another language, or improve existing translations, you can do\nso on Crowdin. Here‚Äôs how:\n\n- Visit the project in [Crowdin](https://crowdin.com/project/ab-download-manager)\n- Please DO NOT submit translations via pull requests.\n- If you want to add a new language, please see [this](https://github.com/amir1376/ab-download-manager/issues/144).\n\n## Contribution\n\nIf you want to contribute to this project, please read [Contributing Guide](CONTRIBUTING.md) first.\n\n## Support the Project\n\nIf you'd like to support the project, you can find details on how to donate in the [DONATE.md](DONATE.md) file.\n",
      "stars_today": 31
    },
    {
      "id": 628160489,
      "name": "SimpMusic",
      "full_name": "maxrave-dev/SimpMusic",
      "description": "A cross-platform music app using YouTube Music for backend",
      "html_url": "https://github.com/maxrave-dev/SimpMusic",
      "stars": 7275,
      "forks": 332,
      "language": "Kotlin",
      "topics": [
        "android",
        "android-16",
        "android-app",
        "android-application",
        "android-auto",
        "compose-multiplatform",
        "exoplayer",
        "kotlin",
        "linux",
        "macos",
        "media3",
        "mp3",
        "music",
        "spotify",
        "video-streaming",
        "windows",
        "youtube",
        "youtube-music"
      ],
      "created_at": "2023-04-15T04:53:33Z",
      "updated_at": "2026-01-24T01:16:49Z",
      "pushed_at": "2026-01-20T17:48:43Z",
      "open_issues": 365,
      "owner": {
        "login": "maxrave-dev",
        "avatar_url": "https://avatars.githubusercontent.com/u/113747128?v=4"
      },
      "readme": "<div align=\"center\"> <img src=\"https://raw.githubusercontent.com/maxrave-dev/SimpMusic/main/fastlane/metadata/android/en-US/images/featureGraphic.png\"> <h1>SimpMusic</h1>  \nA FOSS YouTube Music client for Android and Desktop with many features from<br>Spotify, SponsorBlock, ReturnYouTubeDislike using Compose Multiplatform to develop.\n<br> \n<br>\n<a href=\"https://github.com/maxrave-dev/SimpMusic/releases\"><img src=\"https://img.shields.io/github/v/release/maxrave-dev/SimpMusic\"></a> <a href=\"https://github.com/maxrave-dev/SimpMusic/releases\"><img src=\"https://img.shields.io/github/downloads/maxrave-dev/SimpMusic/total\"></a> <br> <br> <a href=\"https://trendshift.io/repositories/13482\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/13482\" alt=\"maxrave-dev%2FSimpMusic | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n<br>\n<br>\n<a href=\"https://www.producthunt.com/products/simpmusic/reviews?utm_source=badge-product_rating&utm_medium=badge&utm_source=badge-simpmusic\" target=\"_blank\"><img src=\"https://api.producthunt.com/widgets/embed-image/v1/product_rating.svg?product_id=903836&theme=dark\" alt=\"SimpMusic - A&#0032;FOSS&#0032;YouTube&#0032;Music&#0032;client&#0032;for&#0032;Android&#0032;with&#0032;many&#0032;features | Product Hunt\" style=\"width: 242px; height: 108px;\" width=\"242\" height=\"108\" /></a>\n<br> \n<h4>Download</h4>  \n<a href=\"https://apt.izzysoft.de/packages/com.maxrave.simpmusic/\"><img src=\"https://gitlab.com/IzzyOnDroid/repo/-/raw/master/assets/IzzyOnDroid.png\" width=\"200\"></a> \n<a href=\"https://f-droid.org/en/packages/com.maxrave.simpmusic/\"><img src=\"https://fdroid.gitlab.io/artwork/badge/get-it-on.png\" width=\"200\"></a> \n<a href=\"https://www.openapk.net/simpmusic/com.maxrave.simpmusic/\"><img src=\"https://www.openapk.net/images/openapk-badge.png\" width=\"200\"></a> \n<a href=\"https://github.com/maxrave-dev/SimpMusic/releases\"><img src=\"https://raw.githubusercontent.com/NeoApplications/Neo-Backup/034b226cea5c1b30eb4f6a6f313e4dadcbb0ece4/badge_github.png\" width=\"200\"></a> \n<h4>Nightly Build</h4>  \n<a href=\"https://simpmusic.org/nightly-download\"><img src=\"https://github.com/maxrave-dev/SimpMusic/actions/workflows/android.yml/badge.svg\"></a><br/> <a href=\"https://simpmusic.org/nightly-download\"><img src=\"https://raw.githubusercontent.com/NeoApplications/Neo-Backup/034b226cea5c1b30eb4f6a6f313e4dadcbb0ece4/badge_github.png\" width=\"200\"></a> \n</div>  \n\n> SimpMusic is available on Desktop now!\n  \n## Features ‚ú®Ô∏è    \n- Play music from YouTube Music or YouTube for free, without ads and in the background    \n- Browsing Home, Charts, Podcast, Moods & Genre with YouTube Music data at high speed    \n- Search everything on YouTube    \n- Analyze your playing data, create custom playlists, and sync with YouTube Music...    \n- Spotify Canvas supported    \n- Play 1080p video option with subtitle    \n- AI song suggestions    \n- Customize your playlist, synced with YouTube Music\n- Notifications from followed artists    \n- Caching and offline playback support    \n- Synced lyrics from SimpMusic Lyrics, LRCLIB, Spotify (require login) and YouTube Transcript - AI lyrics translation (BETA) (\\*)  \n- Personalize data (\\**) and multi-YouTube-account support    \n- Supports SponsorBlock and Return YouTube Dislike\n- Sleep Timer    \n- Android Auto with online content\n- Discord Rich Presence support\n- And many more!    \n  \n> (\\*) Use your OpenAI or Gemini API key    \n> (\\**) For users who chose \"Send back to Google\" feature    \n    \n> **Warning**    \n > This app is in the beta stage, so it may have many bugs and make it crash. If you find any bugs,      \n> please create an issue or contact me via email or Discord server.   \n> Because of depending on YouTube Music, the player error will happen and it's normally, please don't ask me about the stable state of this app.\n    \n## Screenshots    \n <p align=\"center\">          \n <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/01.png?raw=true\" width=\"200\" />          \n  <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/02.png?raw=true\" width=\"200\" />          \n   <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/03.png?raw=true\" width=\"200\" />          \n   <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/04.png?raw=true\" width=\"200\" /> </p> <p align=\"center\">          \n <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/05.png?raw=true\" width=\"200\" />          \n <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/17.png?raw=true\" width=\"200\" />  \n   <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/07.png?raw=true\" width=\"200\" />          \n   <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/08.png?raw=true\" width=\"200\" /> </p> <p align=\"center\">          \n <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/09.png?raw=true\" width=\"200\" />          \n  <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/10.png?raw=true\" width=\"200\" />         \n  <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/11.png?raw=true\" width=\"200\" /> \n     <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/12.png?raw=true\" width=\"200\" /> </p> <p align=\"center\">    \n <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/13.png?raw=true\" width=\"200\" />          \n  <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/14.png?raw=true\" width=\"200\" />         \n  <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/15.png?raw=true\" width=\"200\" /> \n     <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/16.png?raw=true\" width=\"200\" /> </p> <p align=\"center\">  \n   <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/06.png?raw=true\" width=\"800\" />  \n</p>\n\n #### More [screenshots](https://photos.app.goo.gl/AbieoXG5ctDrpwzp7) here.\n \n ## Data    \n- This app uses hidden API from YouTube Music with some tricks to get data from YouTube Music.    \n- Use Spotify Web API and some tricks to get Spotify Canvas and Lyrics    \n- Thanks to [InnerTune](https://github.com/z-huang/InnerTune/) for the idea to get data from YouTube Music. This repo is my inspiration to create this app.    \n- Special thanks to [SmartTube](https://github.com/yuliskov/SmartTube). This repo help me to extract the streaming URL of YouTube Music.    \n- My app is using [SponsorBlock](https://sponsor.ajay.app/) to skip sponsor in YouTube videos.    \n- ReturnYouTubeDislike for getting information on votes \n- Main lyrics data from SimpMusic Lyrics\n- Alternative lyrics data from LRCLIB. More information [LRCLIB](https://lrclib.net/)    \n \n ## Privacy    \n SimpMusic doesn't have any tracker or third-party server for collecting user data in FOSS version. If YouTube      \nlogged-in users enable \"Send back to Google\" feature, SimpMusic only uses YouTube Music Tracking API to send listening history and listening record of video to Google for better recommendations and      \nsupporting artist or YouTube Creator (For API reference,      \nsee [this](https://github.com/maxrave-dev/SimpMusic/blob/13f7ab6e5fa521b62a9fd31a1cefdc2787a1a8af/kotlinYtmusicScraper/src/main/java/com/maxrave/kotlinytmusicscraper/Ytmusic.kt#L639C4-L666C1)).\n\nWe collect crash data in the Full version to improve the app.\n   \n## Full or FOSS version\nI use [Sentry](http://sentry.io) crashlytics to catch all crashes in the Full version. [Sentry](https://github.com/getsentry/sentry) is the open-source project.\n If you don't want to be collected crash data, you must use FOSS version.\n \n## Desktop app\n\n### Before downloading the Desktop app, make sure your system installed 3 applications below:\n- [Gstreamer](https://gstreamer.freedesktop.org/download/): Required for playback audio.\n- [Yt-dlp](https://github.com/yt-dlp/yt-dlp): Required for getting streaming URL from YouTube (when using 256kps or higher quality).\n\n### Which file should I download?\n- For Windows: Download the file with extension `.msi`.\n- For macOS: Download the file with extension `.dmg`.\n- For Linux: Download the file with extension `.deb` (Debian based), `.rpm` (Red-hat based), `.AppImage` (all Linux distributions) .\n\n### Log in guide: https://www.simpmusic.org/blogs/en/how-to-log-in-on-desktop-app\n\n### Some limitations on Desktop app:\n- No offline playback support.\n- No video playback support.\n- Very buggy on some Linux distributions (because of Jetbrains not fix).\n\nPlease report issues on our Discord server if you find any bugs.\n \n## Translation    \n[![Crowdin](https://badges.crowdin.net/simpmusic/localized.svg)](https://crowdin.com/project/simpmusic)\n<br/>\nYou can help me translate this app into your language by using Crowdin [SimpMusic on Crowdin](https://crowdin.com/project/simpmusic)    \n #### Special thanks to all translators on Crowdin ‚ù§Ô∏è    \n ## FAQ    \n #### 1. Wrong Lyrics?    \n Lyrics are provided by LRCLIB and other sources. Sometimes lyrics may not match perfectly with YouTube\"      \nvideoId\" parameter. So I need to use some \"String Matcher\" and \"Duration\" for search lyrics. So      \nsometimes, some songs or videos get the wrong lyrics    \n    \n#### 2. Why the name or brand is \"SimpMusic\"?    \n Simply, because I love the name. It's a combination of 'Simple' and 'Music'. But SimpMusic is not a simple app, it's all you need for a powerful music streaming app.    \n  \n#### More FAQ, join [my Discord channel](https://discord.com/channels/1136988323819298856/1349800418745778196)  \n  ## Developer/Team    \n- [maxrave-dev](https://github.com/maxrave-dev/SimpMusic): Founder/Developer/Designer    \n- [Owen Connor](https://github.com/owencz1998): Discord Server Admin.    \n- [ilianoKokoro](https://github.com/ilianoKokoro): Discord Server Admin.\n- [CrazyWolf13](https://github.com/CrazyWolf13): Issues organizer/planner.\n\nWe're looking for more contributors, all contributions are welcome!\nSee our [CODE OF CONDUCT](https://github.com/maxrave-dev/SimpMusic/blob/main/CODE_OF_CONDUCT.md)\n\nThanks for all my contributors:\n\n<a href=\"https://github.com/maxrave-dev/SimpMusic/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=maxrave-dev/SimpMusic\" />\n</a>\n\n ## Showcase\nThis project is following clean architecture and MVVM pattern (in UI, app module).\n\n ### Dependencies graph\n  <p float=\"left\">        \n  <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/dependencies_graph.svg?raw=true\" width=\"800\"> \n  </p>\n\n ## Support & Donations \n #### Special thanks to all supporter ‚ù§Ô∏è    \n <div align=\"left\"> \n <a href=\"https://simpmusic.org/\"><img alt=\"Visit the website\" height=\"50\" src=\"https://cdn.jsdelivr.net/npm/@intergrav/devins-badges@3/assets/cozy/documentation/website_vector.svg\"></a> &nbsp;        \n<a href=\"https://discord.gg/Rq5tWVM9Hg\"><img alt=\"Discord Server\" height=\"50\" src=\"https://cdn.jsdelivr.net/npm/@intergrav/devins-badges@3/assets/cozy/social/discord-plural_vector.svg\"></a> &nbsp;        \n<br> <a href=\"https://www.buymeacoffee.com/maxrave\"><img alt=\"Buy me a Coffee\" height=\"50\" src=\"https://cdn.jsdelivr.net/npm/@intergrav/devins-badges@3/assets/cozy/donate/buymeacoffee-singular_vector.svg\"></a> &nbsp;        \n<a href=\"https://liberapay.com/maxrave/\"><img alt=\"liberapay\" height=\"50\"        \nsrc=\"https://raw.githubusercontent.com/liberapay/liberapay.com/master/www/assets/liberapay/logo-v2_black-on-yellow.svg\"></a> \n</div>\n    \n ### MOMO or Vietnamese banking    \n <p float=\"left\">        \n <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/dev/asset/52770992.jpg?raw=true\" width=\"300\"> \n </p>\n\n## SimpMusic is sponsored by:\n<br />\n<a href=\"https://vercel.com/oss\">\n  <img alt=\"Vercel OSS Program\" src=\"https://vercel.com/oss/program-badge.svg\" />\n</a>\n<br />\n<br />\n<a href=\"https://www.digitalocean.com/?refcode=d7f6eedfb9a9&utm_campaign=Referral_Invite&utm_medium=Referral_Program&utm_source=badge\"><img src=\"https://web-platforms.sfo2.cdn.digitaloceanspaces.com/WWW/Badge%201.svg\" width=\"300\" alt=\"DigitalOcean Referral Badge\" /></a>\n<br>\n<br>\n<a href=\"https://crowdin.com\">\n<img src=\"https://support.crowdin.com/assets/logos/plate/png/crowdin-logo-with-plate.png\" width=\"300\"/>\n</a>\n<br>\n<a href=\"https://sentry.io\">\n<img src=\"https://github.com/maxrave-dev/SimpMusic/blob/dev/asset/sentry.svg?raw=true\" width=\"300\"/>\n</a>\n<br>\n<br>\n\nGet a free $200 credit over 60 days on DigitalOcean: [GET NOW](https://www.digitalocean.com/?refcode=d7f6eedfb9a9&utm_campaign=Referral_Invite&utm_medium=Referral_Program&utm_source=badge)\n\nCrowdin and Sentry both have a free enterprise plan for Open-source projects. Follow the URLs: \n- [Open Source License Request Form | Crowdin](https://crowdin.com/page/open-source-project-setup-request)\n- [Sentry for Open Source | Sentry](https://sentry.io/for/open-source/)\n\nCheck out the Vercel open-source program:\n- https://vercel.com/open-source-program\n\n*This project is a part of SimpMusic.org Open-source project by me [maxrave-dev](https://github.com/maxrave-dev)*\n",
      "stars_today": 29
    },
    {
      "id": 220497210,
      "name": "Watchy",
      "full_name": "sqfmi/Watchy",
      "description": "Watchy - An Open Source E-Ink Smartwatch",
      "html_url": "https://github.com/sqfmi/Watchy",
      "stars": 2648,
      "forks": 406,
      "language": "C",
      "topics": [
        "arduino",
        "arduino-library",
        "bluetooth-low-energy",
        "e-ink",
        "esp32",
        "iot",
        "smartwatch"
      ],
      "created_at": "2019-11-08T15:41:00Z",
      "updated_at": "2026-01-23T20:28:21Z",
      "pushed_at": "2025-08-19T01:19:38Z",
      "open_issues": 87,
      "owner": {
        "login": "sqfmi",
        "avatar_url": "https://avatars.githubusercontent.com/u/28943617?v=4"
      },
      "readme": "# Watchy - Fully Open Source E-Paper Watch\n\n![Watchy](https://watchy.sqfmi.com/img/watchy_render.png)\n\n**Buy Watchy from [Mouser](https://www.mouser.com/ProductDetail/SQFMI/SQFMI-WATCHY-10?qs=DRkmTr78QARN9VSJRzqRxw%3D%3D), [The Pi Hut](https://thepihut.com/collections/sqfmi), and [Crowd Supply](https://www.crowdsupply.com/sqfmi/watchy)**\n\n[**Watchy Case & Accessories**](https://shop.sqfmi.com)\n\n## Getting Started Guide\nFollow the instructions here https://watchy.sqfmi.com/docs/getting-started\n\n### Have Fun! :)\n\n### Got Questions?\n\nJoin our [Discord](https://discord.gg/ZXDegGV8E7)\n\n\n",
      "stars_today": 29
    },
    {
      "id": 599431918,
      "name": "oxc",
      "full_name": "oxc-project/oxc",
      "description": "‚öì A collection of high-performance JavaScript tools.",
      "html_url": "https://github.com/oxc-project/oxc",
      "stars": 18556,
      "forks": 796,
      "language": "Rust",
      "topics": [
        "compiler",
        "javascript",
        "linter",
        "minifier",
        "parser",
        "transpiler",
        "typescript"
      ],
      "created_at": "2023-02-09T05:46:51Z",
      "updated_at": "2026-01-23T22:33:31Z",
      "pushed_at": "2026-01-23T19:33:36Z",
      "open_issues": 454,
      "owner": {
        "login": "oxc-project",
        "avatar_url": "https://avatars.githubusercontent.com/u/149946238?v=4"
      },
      "readme": "<p align=\"center\">\n  <br>\n  <br>\n  <a href=\"https://oxc.rs\" target=\"_blank\" rel=\"noopener noreferrer\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://oxc.rs/oxc-light.svg\">\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"https://oxc.rs/oxc-dark.svg\">\n      <img alt=\"Oxc logo\" src=\"https://oxc.rs/oxc-dark.svg\" height=\"60\">\n    </picture>\n  </a>\n  <br>\n  <br>\n  <br>\n</p>\n\n<div align=\"center\">\n\n[![MIT licensed][license-badge]][license-url]\n[![Build Status][ci-badge]][ci-url]\n[![Code Coverage][code-coverage-badge]][code-coverage-url]\n[![CodSpeed Badge](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json)](https://codspeed.io/oxc-project/oxc)\n[![Sponsors][sponsors-badge]][sponsors-url]\n\n[![Discord chat][discord-badge]][discord-url]\n[![Playground][playground-badge]][playground-url]\n[![Website][website-badge]][website-url]\n\n</div>\n\n## ‚öì Oxc\n\n_/o ä …õks siÀê/_\n\nThe Oxidation Compiler is a collection of high-performance tools for JavaScript and TypeScript written in Rust.\n\nOxc is part of [VoidZero](https://voidzero.dev/)'s vision for a unified, high-performance toolchain for JavaScript. It powers [Rolldown](https://rolldown.rs) ([Vite]'s future bundler) and enables the next generation of ultra-fast development tools that work seamlessly together.\n\nFor more information, check out our website at [oxc.rs](https://oxc.rs).\n\n<sub>\\* Oxidation is the chemical process that creates rust</sub>\n\n## üèóÔ∏è Design Principles\n\n- **Performance**: Through rigorous performance engineering.\n- **Correctness**: Through conformance testing to standards and similar projects.\n- **Developer Experience**: Clear APIs, comprehensive documentation, and sensible configuration.\n- **Modular composability**: Use individual components independently or compose them into complete toolchains.\n\nRead more about our [architecture](https://oxc.rs/docs/learn/architecture/parser.html) and [performance philosophy](https://oxc.rs/docs/learn/performance).\n\n## üì¶ Tools & Packages\n\n| Tool        | npm                                                          | crates.io                                                   |\n| ----------- | ------------------------------------------------------------ | ----------------------------------------------------------- |\n| Linter      | [oxlint](https://www.npmjs.com/package/oxlint)               | -                                                           |\n| Formatter   | [oxfmt](https://www.npmjs.com/package/oxfmt)                 | -                                                           |\n| Parser      | [oxc-parser](https://www.npmjs.com/package/oxc-parser)       | [oxc_parser](https://crates.io/crates/oxc_parser)           |\n| Transformer | [oxc-transform](https://www.npmjs.com/package/oxc-transform) | [oxc_transformer](https://crates.io/crates/oxc_transformer) |\n| Minifier    | [oxc-minify](https://www.npmjs.com/package/oxc-minify)       | [oxc_minifier](https://crates.io/crates/oxc_minifier)       |\n| Resolver    | [oxc-resolver](https://www.npmjs.com/package/oxc-resolver)   | [oxc_resolver](https://crates.io/crates/oxc_resolver)       |\n\nSee [documentation](https://oxc.rs/) for detailed usage guides for each tool.\n\n## ‚ö°Ô∏è Quick Start\n\n### Linter\n\nThe production-ready linter catches mistakes for you with sensible defaults and optional configuration:\n\n```bash\nnpx oxlint@latest\n```\n\nTo give you an idea of its capabilities, here is an example from the [vscode] repository, which finishes linting 4800+ files in 0.7 seconds:\n\n<p float=\"left\" align=\"left\">\n  <img src=\"https://cdn.jsdelivr.net/gh/oxc-project/oxc-assets/linter-screenshot.png\" width=\"60%\">\n</p>\n\n‚Üí [oxlint documentation](https://oxc.rs/docs/guide/usage/linter/cli.html)\n\n### Formatter\n\nFast, opinionated code formatter compatible with [Prettier]:\n\n```bash\nnpx oxfmt@latest\n```\n\n‚Üí [Formatter documentation](https://oxc.rs/docs/guide/usage/formatter)\n\n### Parser (Node.js)\n\nThe fastest JavaScript/TypeScript parser written in Rust:\n\n```bash\nnpm install oxc-parser\n```\n\n```js\nimport { parseSync } from \"oxc-parser\";\nconst result = parseSync(\"const x = 1;\");\n```\n\n‚Üí [Parser documentation](https://oxc.rs/docs/guide/usage/parser)\n\n### Transformer (Node.js)\n\nTypeScript, React, and modern JavaScript transformation:\n\n```bash\nnpm install oxc-transform\n```\n\n```js\nimport { transform } from \"oxc-transform\";\nconst result = transform(\"source.tsx\", code, { typescript: true });\n```\n\n‚Üí [Transformer documentation](https://oxc.rs/docs/guide/usage/transformer)\n\n### Minifier (Node.js)\n\nHigh-performance JavaScript minifier:\n\n```bash\nnpm install oxc-minify\n```\n\n```js\nimport { minify } from \"oxc-minify\";\nconst result = minify(code, { mangle: true });\n```\n\n‚Üí [Minifier documentation](https://oxc.rs/docs/guide/usage/minifier)\n\n### Rust\n\nIndividual crates are published for building your own JavaScript tools:\n\n```toml\n[dependencies]\noxc = \"0.x\"\n```\n\n‚Üí [Rust documentation](https://docs.rs/oxc)\n\n## VoidZero Inc.\n\nOxc is a project of [VoidZero](https://voidzero.dev/), see our announcement [Announcing VoidZero - Next Generation Toolchain for JavaScript](https://voidzero.dev/blog).\n\nIf you have requirements for JavaScript tools at scale, please [get in touch](https://forms.gle/WQgjyzYJpwurpxWKA)!\n\n## üôã Who's using Oxc?\n\n[Rolldown] and [Nuxt] use Oxc for parsing. [Rolldown] also uses Oxc for transformation and minification. [Nova], [swc-node], and [knip] use [oxc_resolver][docs-resolver-url] for module resolution. [Preact], [Shopify], [ByteDance], and [Shopee] use oxlint for linting.\n\n[See more projects using Oxc ‚Üí](https://oxc.rs/docs/guide/projects.html)\n\n## ‚úçÔ∏è Contribute\n\nCheck out some of the [good first issues](https://github.com/oxc-project/oxc/contribute) or ask us on [Discord][discord-url].\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md) for guidance, or read the complete [contributing guide on our website ‚Üí](https://oxc.rs/docs/contribute/introduction.html)\n\nIf you are unable to contribute by code, you can still participate by:\n\n- Add a [GitHub Star](https://github.com/oxc-project/oxc/stargazers) to the project\n- Join us on [Discord][discord-url]\n- [Follow me on X](https://x.com/boshen_c) and post about this project\n\n## ü§ù Credits\n\nThis project was incubated with the assistance of these exceptional mentors and their projects:\n\n- [Biome][biome] - [@ematipico](https://github.com/ematipico)\n- [Ruff][ruff] - [@charliermarsh](https://github.com/charliermarsh), [@MichaReiser](https://github.com/MichaReiser)\n- [quick-lint-js](https://github.com/quick-lint/quick-lint-js) - [@strager](https://github.com/strager)\n- [elm-review](https://package.elm-lang.org/packages/jfmengels/elm-review/latest) - [@jfmengels](https://github.com/jfmengels)\n\nSpecial thanks go to:\n\n- [@domonji](https://github.com/domonji) for bootstrapping this project together and also completing the TypeScript parser\n- [@tongtong-lu](https://github.com/tongtong-lu) and [@guan-wy](https://github.com/guan-wy) for designing the [project logo](https://github.com/oxc-project/oxc-assets)\n\n## ‚ù§ Who's [Sponsoring Oxc](https://github.com/sponsors/Boshen)?\n\n<p align=\"center\">\n  <a href=\"https://github.com/sponsors/Boshen\">\n    <img src=\"https://raw.githubusercontent.com/Boshen/sponsors/main/sponsors.svg\" alt=\"My sponsors\" />\n  </a>\n</p>\n\n## üìñ License\n\nOxc is free and open-source software licensed under the [MIT License](./LICENSE).\n\nOxc ports or copies code from other open source projects, their licenses are listed in [**Third-party library licenses**](./THIRD-PARTY-LICENSE).\n\n[discord-badge]: https://img.shields.io/discord/1079625926024900739?logo=discord&label=Discord\n[discord-url]: https://discord.gg/9uXCAwqQZW\n[license-badge]: https://img.shields.io/badge/license-MIT-blue.svg\n[license-url]: https://github.com/oxc-project/oxc/blob/main/LICENSE\n[ci-badge]: https://github.com/oxc-project/oxc/actions/workflows/ci.yml/badge.svg?event=push&branch=main\n[ci-url]: https://github.com/oxc-project/oxc/actions/workflows/ci.yml?query=event%3Apush+branch%3Amain\n[code-coverage-badge]: https://codecov.io/gh/oxc-project/oxc/graph/badge.svg?token=FVHEH0BQLJ\n[code-coverage-url]: https://codecov.io/gh/oxc-project/oxc\n[sponsors-badge]: https://img.shields.io/github/sponsors/Boshen\n[sponsors-url]: https://github.com/sponsors/Boshen\n[playground-badge]: https://img.shields.io/badge/Playground-blue?color=9BE4E0\n[playground-url]: https://playground.oxc.rs/\n[website-badge]: https://img.shields.io/badge/Website-blue\n[website-url]: https://oxc.rs\n[docs-resolver-url]: https://docs.rs/oxc_resolver\n[biome]: https://biomejs.dev/\n[ruff]: https://beta.ruff.rs\n[vscode]: https://github.com/microsoft/vscode\n[rolldown]: https://rolldown.rs\n[vite]: https://vitejs.dev/\n[nuxt]: https://nuxt.com/\n[nova]: https://trynova.dev/\n[swc-node]: https://github.com/swc-project/swc-node\n[knip]: https://github.com/webpro/knip\n[preact]: https://preactjs.com/\n[shopify]: https://shopify.com/\n[bytedance]: https://www.bytedance.com/\n[shopee]: https://shopee.com/\n[prettier]: https://prettier.io/\n",
      "stars_today": 28
    },
    {
      "id": 59929513,
      "name": "skim",
      "full_name": "skim-rs/skim",
      "description": "Fuzzy Finder in rust!",
      "html_url": "https://github.com/skim-rs/skim",
      "stars": 6427,
      "forks": 235,
      "language": "Rust",
      "topics": [
        "fuzzyfinder",
        "rust",
        "skim"
      ],
      "created_at": "2016-05-29T06:24:46Z",
      "updated_at": "2026-01-23T23:57:38Z",
      "pushed_at": "2026-01-23T18:51:27Z",
      "open_issues": 39,
      "owner": {
        "login": "skim-rs",
        "avatar_url": "https://avatars.githubusercontent.com/u/187454154?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://crates.io/crates/skim\">\n    <img src=\"https://img.shields.io/crates/v/skim.svg\" alt=\"Crates.io\" />\n  </a>\n  <a href=\"https://github.com/skim-rs/skim/actions?query=workflow%3A%22Build+%26+Test%22+event%3Apush\">\n    <img src=\"https://github.com/skim-rs/skim/actions/workflows/test.yml/badge.svg?event=push\" alt=\"Build & Test\" />\n  </a>\n  <a href=\"https://repology.org/project/skim-fuzzy-finder/versions\">\n    <img src=\"https://repology.org/badge/tiny-repos/skim-fuzzy-finder.svg\" alt=\"Packaging status\" />\n  </a>\n  <a href=\"https://discord.gg/23PuxttufP\">\n    <img alt=\"Skim Discord\" src=\"https://img.shields.io/discord/1031830957432504361?label=&color=7389d8&labelColor=6a7ec2&logoColor=ffffff&logo=discord\" />\n  </a>\n  <a href=\"https://ratatui.rs\">\n    <img alt=\"Built with Ratatui\" src=\"https://ratatui.rs/built-with-ratatui/badge.svg\" />\n  </a>\n</p>\n\n> Life is short, skim!\n\nWe spend so much of our time navigating through files, lines, and commands. That's where Skim comes in!\nIt's a powerful fuzzy finder designed to make your workflow faster and more efficient.\n\n[![skim demo](https://asciinema.org/a/pIfwazaM0mTHA8F7qRbjrqOnm.svg)](https://asciinema.org/a/pIfwazaM0mTHA8F7qRbjrqOnm)\n\nSkim provides a single executable called `sk`. Think of it as a smarter alternative to tools like\n`grep` - once you try it, you'll wonder how you ever lived without it!\n\n# Table of contents\n\n- [Installation](#installation)\n   * [Package Managers](#package-managers)\n   * [Manually](#manually)\n- [Usage](#usage)\n   * [As Vim plugin](#as-vim-plugin)\n   * [As filter](#as-filter)\n   * [As Interactive Interface](#as-interactive-interface)\n   * [Shell Bindings](#shell-bindings)\n   * [Key Bindings](#key-bindings)\n   * [Search Syntax](#search-syntax)\n   * [exit code](#exit-code)\n- [Tools compatible with `skim`](#tools-compatible-with-skim)\n   * [fzf-lua neovim plugin](#fzf-lua-neovim-plugin)\n   * [nu_plugin_skim](#nu_plugin_skim)\n- [Customization](#customization)\n   * [Keymap](#keymap)\n   * [Sort Criteria](#sort-criteria)\n   * [Color Scheme](#color-scheme)\n   * [Misc](#misc)\n- [Advanced Topics](#advanced-topics)\n   * [Interactive mode](#interactive-mode)\n      + [How does it work?](#how-does-it-work)\n   * [Executing external programs](#executing-external-programs)\n   * [Preview Window](#preview-window)\n      + [How does it work?](#how-does-it-work-1)\n   * [Fields support](#fields-support)\n   * [Use as a library](#use-as-a-library)\n- [FAQ](#faq)\n   * [How to ignore files?](#how-to-ignore-files)\n   * [Some files are not shown in Vim plugin](#some-files-are-not-shown-in-vim-plugin)\n- [Differences from fzf](#differences-from-fzf)\n- [How to contribute](#how-to-contribute)\n- [Troubleshooting](#troubleshooting)\n   * [No line feed issues with nix, FreeBSD, termux](#no-line-feed-issues-with-nix-freebsd-termux)\n\n# Installation\n\nThe skim project contains several components:\n\n1. `sk` executable - the core program\n2. Vim/Nvim plugin - to call `sk` inside Vim/Nvim. Check [skim.vim](https://github.com/skim-rs/skim/blob/master/plugin/skim.vim) for Vim support.\n\n## Package Managers\n\n| OS             | Package Manager   | Command                      |\n| -------------- | ----------------- | ---------------------------- |\n| macOS          | Homebrew          | `brew install sk`            |\n| macOS          | MacPorts          | `sudo port install skim`     |\n| Alpine         | apk               | `apk add skim`               |\n| Arch           | pacman            | `pacman -S skim`             |\n| Gentoo         | Portage           | `emerge --ask app-misc/skim` |\n| Guix           | guix              | `guix install skim`          |\n| Void           | XBPS              | `xbps-install -S skim`       |\n\n<a href=\"https://repology.org/project/skim-fuzzy-finder/versions\">\n    <img src=\"https://repology.org/badge/vertical-allrepos/skim-fuzzy-finder.svg?columns=4\" alt=\"Packaging status\">\n</a>\n\n## Manually\n\nAny of the following applies:\n\n- Using the install script:\n    ```sh\n    # Always check the content of the script before running it !\n    $ curl --proto '=https' --tlsv1.2 -LsSf https://github.com/skim-rs/skim/releases/latest/download/skim-installer.sh | sh\n    ```\n- Using Binary: Simply [download the sk executable](https://github.com/skim-rs/skim/releases) directly.\n- Install from [crates.io](https://crates.io/): Run `cargo +nightly install skim` (or `cargo install skim --no-default-features --features cli` if you don't like using nightly rust, which will make you lose the `frizbee` typo-resistant matcher)\n- Build Manually:\n    ```sh\n    $ git clone --depth 1 git@github.com:skim-rs/skim.git ~/.skim\n    $ cd ~/.skim\n    $ cargo +nightly install\n    $ cargo +nightly build --release\n    $ # Add the resulting `target/release/sk` executable to your PATH\n    ```\n\nYou will then have access to:\n\n- The man page, which you can either write to the correct path or run `man --local-file <(sk --man)`\n- The shell completions (and optional keybinds), using `source <(sk --shell \\<shell> \\[--shell-bindings])`, see below for details\n\n# Usage\n\nSkim can be used either as a general filter (similar to `grep`) or as an interactive\ninterface for running commands.\n\n## As Vim plugin (on neovim, checkout [fzf-lua](https://github.com/ibhagwan/fzf-lua) with the skim profile)\n\nVia vim-plug (recommended):\n\nInstall skim, then :\n\n```vim\nPlug 'skim-rs/skim'\n```\n\n\n## As filter\n\nHere are some examples to get you started:\n\n```bash\n# directly invoke skim\nsk\n\n# Or pipe some input to it (press TAB key to select multiple items when -m is enabled)\nvim $(find . -name \"*.rs\" | sk -m)\n```\nThis last command lets you select files with the \".rs\" extension and opens\nyour selections in Vim - a great time-saver for developers!\n\n## As Interactive Interface\n\n`skim` can invoke other commands dynamically. Normally you would want to\nintegrate it with [grep](https://www.gnu.org/software/grep/),\n[ack](https://github.com/petdance/ack2),\n[ag](https://github.com/ggreer/the_silver_searcher), or\n[rg](https://github.com/BurntSushi/ripgrep) for searching contents in a\nproject directory:\n\n```sh\n# works with grep\nsk --ansi -i -c 'grep -rI --color=always --line-number \"{}\" .'\n# works with ack\nsk --ansi -i -c 'ack --color \"{}\"'\n# works with ag\nsk --ansi -i -c 'ag --color \"{}\"'\n# works with rg\nsk --ansi -i -c 'rg --color=always --line-number \"{}\"'\n```\n\n> **Note**: In these examples, `{}` will be literally expanded to the current input query.\n> This means these examples will search for the exact query string, not fuzzily.\n> For fuzzy searching, pipe the command output into `sk` without using interactive mode.\n\n![interactive mode demo](https://cloud.githubusercontent.com/assets/1527040/21603930/655d859a-d1db-11e6-9fec-c25099d30a12.gif)\n\n## Shell Bindings\n\nBindings for Fish, Bash and Zsh are available in the `shell` directory:\n- `completion.{shell}` contains the completion scripts for `sk` cli usage\n- `key-bindings.{shell}` contains key-binds and shell integrations:\n    - `ctrl-t` to select a file through `sk`\n    - `ctrl-r` to select an history entry through `sk`\n    - `alt-c`  to `cd` into a directory selected through `sk`\n    - (not available in `fish`) `**` to complete file paths, for example `ls **<tab>` will show a `sk` widget to select a folder\n\nTo enable these features, source the `key-bindings.{shell}` file and set up completions according to your shell's documentation or see below.\n\n### Shell Completions\n\nYou can generate shell completions for your preferred shell using the `--shell` flag with one of the supported shells: `bash`, `zsh`, `fish`, `powershell`, or `elvish`:\n\n> **Note:** While PowerShell completions are supported, Windows is not supported for now.\n\n#### Option 1: Source directly in your current shell session\n\n```sh\n# For bash\nsource <(sk --shell bash)\n\n# For zsh\nsource <(sk --shell zsh)\n\n# For fish\nsk --shell fish | source\n```\n\n#### Option 2: Save to a file to be loaded automatically on shell startup\n\n```sh\n# For bash, add to ~/.bashrc\necho 'source <(sk --shell bash)' >> ~/.bashrc  # Or save to ~/.bash_completion\n\n# For zsh, add to ~/.zshrc\nsk --shell zsh > ~/.zfunc/_sk  # Create ~/.zfunc directory and add to fpath in ~/.zshrc\n\n# For fish, add to ~/.config/fish/completions/\nsk --shell fish > ~/.config/fish/completions/sk.fish\n```\n\n## Key Bindings\n\nSome commonly used key bindings:\n\n| Key               | Action                                     |\n|------------------:|--------------------------------------------|\n| Enter             | Accept (select current one and quit)       |\n| ESC/Ctrl-G        | Abort                                      |\n| Ctrl-P/Up         | Move cursor up                             |\n| Ctrl-N/Down       | Move cursor Down                           |\n| TAB               | Toggle selection and move down (with `-m`) |\n| Shift-TAB         | Toggle selection and move up (with `-m`)   |\n\nFor a complete list of key bindings, refer to the [man\npage](https://github.com/skim-rs/skim/blob/master/man/man1/sk.1) (`man sk`).\n\n## Search Syntax\n\n`skim` borrows `fzf`'s syntax for matching items:\n\n| Token    | Match type                 | Description                       |\n|----------|----------------------------|-----------------------------------|\n| `text`   | fuzzy-match                | items that match `text`           |\n| `^music` | prefix-exact-match         | items that start with `music`     |\n| `.mp3$`  | suffix-exact-match         | items that end with `.mp3`        |\n| `'wild`  | exact-match (quoted)       | items that include `wild`         |\n| `!fire`  | inverse-exact-match        | items that do not include `fire`  |\n| `!.mp3$` | inverse-suffix-exact-match | items that do not end with `.mp3` |\n\n`skim` also supports the combination of tokens.\n\n- Whitespace has the meaning of `AND`. With the term `src main`, `skim` will search\n    for items that match **both** `src` and `main`.\n- ` | ` means `OR` (note the spaces around `|`). With the term `.md$ |\n    .markdown$`, `skim` will search for items ends with either `.md` or\n    `.markdown`.\n- `OR` has higher precedence. For example, `readme .md$ | .markdown$` is interpreted as\n    `readme AND (.md$ OR .markdown$)`.\n\n- When using the `--split-match` option, each part around spaces or `|` will be matched in a split way:\n    - If the option's value (defaulting to `:`) is absent from the query, do a normal match\n    - If it is present, match everything before to everything before it in the items, and everything after it (including potential other occurences of the delimiter) to the part after it in the items. This is particularly useful when piping in input from `rg` to match on both file name and content.\n\nIf you prefer using regular expressions, `skim` offers a `regex` mode:\n\n```sh\nsk --regex\n```\n\nYou can switch to `regex` mode dynamically by pressing `Ctrl-R` (Rotate Mode).\n\n## exit code\n\n| Exit Code | Meaning                             |\n|-----------|-------------------------------------|\n| 0         | Exited normally                     |\n| 1         | No Match found                      |\n| 130       | Aborted by Ctrl-C/Ctrl-G/ESC/etc... |\n\n# Tools compatible with `skim`\n\nThese tools are or aim to be compatible with `skim`:\n\n## [fzf-lua neovim plugin](https://github.com/ibhagwan/fzf-lua)\n\nA [neovim](https://neovim.io) plugin allowing fzf and skim to be used in a to navigate your code.\n\nInstall it with your package manager, following the README. For instance, with `lazy.nvim`:\n\n```lua\n{\n  \"ibhagwan/fzf-lua\",\n  -- enable `sk` support instead of the default `fzf`\n  opts = {'skim'}\n}\n```\n\n## [nu_plugin_skim](https://github.com/idanarye/nu_plugin_skim)\n\nA [nushell](https://www.nushell.sh/) plugin to allow for better interaction between skim and nushell.\n\nFollowing the instruction in the plugin's README, you can install it with cargo:\n```nu\ncargo install nu_plugin_skim\nplugin add ~/.cargo/bin/nu_plugin_skim\n```\n\n# Customization\n\nThe doc here is only a preview, please check the man page (`man sk`) for a full\nlist of options.\n\n## Keymap\n\nSpecify the bindings with comma separated pairs (no space allowed). For example:\n\n```sh\nsk --bind 'alt-a:select-all,alt-d:deselect-all'\n```\n\nAdditionally, use `+` to concatenate actions, such as `execute-silent(echo {} | pbcopy)+abort`.\n\nSee the _KEY BINDINGS_ section of the man page for details.\n\n## Sort Criteria\n\nThere are five sort keys for results: `score, index, begin, end, length`. You can\nspecify how the records are sorted by `sk --tiebreak score,index,-begin` or any\nother order you want.\n\n## Color Scheme\n\nYou probably have your own aesthetic preferences! Fortunately, you aren't\nlimited to the default appearance - Skim supports comprehensive customization of its color scheme.\n\n```sh\n--color=[BASE_SCHEME][,COLOR:ANSI]\n```\n\nSkim also respects the `NO_COLOR` environment variable. Set it to anything and `sk` (and many other terminal apps) will disable all colored output. See [no-color.org](https://no-color.org/) for more details.\n\n### Available Base Color Schemes\n\nSkim comes with several built-in color schemes that you can use as a starting point:\n\n```sh\nsk --color=dark      # Default dark theme (256 colors)\nsk --color=light     # Light theme (256 colors)\nsk --color=16        # Simple 16-color theme\nsk --color=bw        # Minimal black & white theme (no colors, just styles)\nsk --color=none      # Minimal black & white theme (no colors, no styles)\nsk --color=molokai   # Molokai-inspired theme (256 colors)\n```\n\n### Customizing Colors\n\nYou can customize individual UI elements by specifying color values after the base scheme:\n\n```sh\nsk --color=light,fg:232,bg:255,current_bg:116,info:27\n```\n\nColors can be specified in several ways:\n\n- ANSI colors (0-255): `sk --color=fg:232,bg:255`\n- RGB hex values: `sk --color=fg:#FF0000` (red text)\n\n### Available Color Customization Options\n\nThe following UI elements can be customized:\n\n| Element            | Description                                 | Example                        |\n|--------------------|---------------------------------------------|--------------------------------|\n| `fg`               | Normal text foreground color                | `--color=fg:232`               |\n| `bg`               | Normal text background color                | `--color=bg:255`               |\n| `matched`          | Matched text in search results              | `--color=matched:108`          |\n| `matched_bg`       | Background of matched text                  | `--color=matched_bg:0`         |\n| `current`          | Current line foreground color               | `--color=current:254`          |\n| `current_bg`       | Current line background color               | `--color=current_bg:236`       |\n| `current_match`    | Matched text in current line                | `--color=current_match:151`    |\n| `current_match_bg` | Background of matched text in current line  | `--color=current_match_bg:236` |\n| `spinner`          | Progress indicator color                    | `--color=spinner:148`          |\n| `info`             | Information line color                      | `--color=info:144`             |\n| `prompt`           | Prompt color                                | `--color=prompt:110`           |\n| `cursor`           | Cursor color                                | `--color=cursor:161`           |\n| `selected`         | Selected item marker color                  | `--color=selected:168`         |\n| `header`           | Header text color                           | `--color=header:109`           |\n| `border`           | Border color for preview/layout             | `--color=border:59`            |\n\n### Examples\n\n```sh\n# Use light theme but change the current line background\nsk --color=light,current_bg:24\n\n# Custom theme with multiple colors\nsk --color=dark,matched:#00FF00,current:#FFFFFF,current_bg:#000080\n\n# High contrast theme\nsk --color=fg:232,bg:255,matched:160,current:255,current_bg:20\n```\n\nFor more details, check the man page (`man sk`).\n\n## Misc\n\n- `--ansi`: to parse ANSI color codes (e.g., `\\e[32mABC`) of the data source\n- `--regex`: use the query as regular expression to match the data source\n\n# Advanced Topics\n\n## Interactive mode\n\nIn **interactive mode**, you can invoke a command dynamically. Try it out:\n\n```sh\nsk --ansi -i -c 'rg --color=always --line-number \"{}\"'\n```\n\n### How does it work?\n\n![How Skim's interactive mode works](https://user-images.githubusercontent.com/1527040/53381293-461ce380-39ab-11e9-8e86-7c3bbfd557bc.png)\n\n- Skim  accepts two kinds of sources: Command output or piped input\n- Skim has two kinds of prompts: A query prompt to specify the query pattern and a\n    command prompt to specify the \"arguments\" of the command\n- `-c` is used to specify the command to execute and defaults to `SKIM_DEFAULT_COMMAND`\n- `-i` tells skim to open command prompt on startup, which will show `c>` by default.\n\nTo further narrow down the results returned by the command, press\n`Ctrl-Q` to toggle interactive mode.\n\n## Executing external programs\n\nYou can configure key bindings to start external processes without leaving Skim (`execute`, `execute-silent`).\n\n```sh\n# Press F1 to open the file with less without leaving skim\n# Press CTRL-Y to copy the line to clipboard and aborts skim (requires pbcopy)\nsk --bind 'f1:execute(less -f {}),ctrl-y:execute-silent(echo {} | pbcopy)+abort'\n```\n\n## Preview Window\n\nThis is a great feature of fzf that skim borrows. For example, we use 'ag' to\nfind the matched lines, and once we narrow down to the target lines, we want to\nfinally decide which lines to pick by checking the context around the line.\n`grep` and `ag` have the option `--context`, and skim can make use of `--context` for\na better preview window. For example:\n\n```sh\nsk --ansi -i -c 'ag --color \"{}\"' --preview \"preview.sh {}\"\n```\n\n(Note that [preview.sh](https://github.com/junegunn/fzf.vim/blob/master/bin/preview.sh) is a script to print the context given filename:lines:columns)\n\nYou get things like this:\n\n![preview demo](https://user-images.githubusercontent.com/1527040/30677573-0cee622e-9ebf-11e7-8316-c741324ecb3a.png)\n\n### How does it work?\n\nIf the preview command is given by the `--preview` option, skim will replace the\n`{}` with the current highlighted line surrounded by single quotes, call the\ncommand to get the output, and print the output on the preview window.\n\nSometimes you don't need the whole line for invoking the command. In this case\nyou can use `{}`, `{1..}`, `{..3}` or `{1..5}` to select the fields. The\nsyntax is explained in the section [Fields Support](#filds-support).\n\nLastly, you might want to configure the position of preview window with `--preview-window`:\n- `--preview-window up:30%` to put the window in the up position with height\n    30% of the total height of skim.\n- `--preview-window left:10:wrap` to specify the `wrap` allows the preview\n    window to wrap the output of the preview command.\n- `--preview-window wrap:hidden` to hide the preview window at startup, later\n    it can be shown by the action `toggle-preview`.\n\n## Fields support\n\nNormally only plugin users need to understand this.\n\nFor example, you have the data source with the format:\n\n```sh\n<filename>:<line number>:<column number>\n```\n\nHowever, you want to search `<filename>` only when typing in queries. That\nmeans when you type `21`, you want to find a `<filename>` that contains `21`,\nbut not matching line number or column number.\n\nYou can use `sk --delimiter ':' --nth 1` to achieve this.\n\nYou can also use `--with-nth` to re-arrange the order of fields.\n\n**Range Syntax**\n\n- `<num>` -- to specify the `num`-th fields, starting with 1.\n- `start..` -- starting from the `start`-th fields and the rest.\n- `..end` -- starting from the `0`-th field, all the way to `end`-th field,\n    including `end`.\n- `start..end` -- starting from `start`-th field, all the way to `end`-th\n    field, including `end`.\n\n## Use as a library\n\nSkim can be used as a library in your Rust crates.\n\nFirst, add skim into your `Cargo.toml`:\n\n```toml\n[dependencies]\nskim = { version = \"<version>\", default-features = false, features = [..] }\n```\n\n_Note on features_:\n    - the `cli` feature is required to use skim as a cli, it *should* not be needed when using it as a library.\n    - the `nightly-frizbee` feature adds the frizbee algorithm, but requires cargo nigthly.\n\nThen try to run this simple example:\n\n```rust\nextern crate skim;\nuse skim::prelude::*;\nuse std::io::Cursor;\n\npub fn main() {\n    let options = SkimOptionsBuilder::default()\n        .height(String::from(\"50%\"))\n        .multi(true)\n        .build()\n        .unwrap();\n\n    let input = \"aaaaa\\nbbbb\\nccc\".to_string();\n\n    // `SkimItemReader` is a helper to turn any `BufRead` into a stream of `SkimItem`\n    // `SkimItem` was implemented for `AsRef<str>` by default\n    let item_reader = SkimItemReader::default();\n    let items = item_reader.of_bufread(Cursor::new(input));\n\n    // `run_with` would read and show items from the stream\n    let selected_items = Skim::run_with(&options, Some(items))\n        .map(|out| out.selected_items)\n        .unwrap_or_else(|| Vec::new());\n\n    for item in selected_items.iter() {\n        println!(\"{}\", item.output());\n    }\n}\n```\n\nGiven an `Option<SkimItemReceiver>`, skim will read items accordingly, do its\njob and bring us back the user selection including the selected items, the\nquery, etc. Note that:\n\n- `SkimItemReceiver` is `crossbeam::channel::Receiver<Arc<dyn SkimItem>>`\n- If it is none, it will invoke the given command and read items from command output\n- Otherwise, it will read the items from the (crossbeam) channel.\n\nTrait `SkimItem` is provided to customize how a line could be displayed,\ncompared and previewed. It is implemented by default for `AsRef<str>`\n\nPlus, `SkimItemReader` is a helper to convert a `BufRead` into\n`SkimItemReceiver` (we can easily turn a `File` or `String` into `BufRead`),\nso that you could deal with strings or files easily.\n\nCheck out more examples under the [examples/](https://github.com/skim-rs/skim/tree/master/skim/examples) directory.\n\n# FAQ\n\n## How to ignore files?\n\nSkim invokes `find .` to fetch a list of files for filtering. You can override\nthis by setting the environment variable `SKIM_DEFAULT_COMMAND`. For example:\n\n```sh\n$ SKIM_DEFAULT_COMMAND=\"fd --type f || git ls-tree -r --name-only HEAD || rg --files || find .\"\n$ sk\n```\n\nYou could put it in your `.bashrc` or `.zshrc` if you like it to be default.\n\n## Some files are not shown in Vim plugin\n\nIf you use the Vim plugin and execute the `:SK` command, you may find some\nof your files not shown.\n\nAs described in [#3](https://github.com/skim-rs/skim/issues/3), in the Vim\nplugin, `SKIM_DEFAULT_COMMAND` is set to the command by default:\n\n```vim\nlet $SKIM_DEFAULT_COMMAND = \"git ls-tree -r --name-only HEAD || rg --files || ag -l -g \\\"\\\" || find .\"\n```\n\nThis means files not recognized by git won't be shown. You can either override the\ndefault with `let $SKIM_DEFAULT_COMMAND = ''` or locate the missing files by\nyourself.\n\n# Differences from fzf\n\n[fzf](https://github.com/junegunn/fzf) is a command-line fuzzy finder written\nin Go and [skim](https://github.com/skim-rs/skim) tries to implement a new one\nin Rust!\n\nThis project is written from scratch. Some decisions of implementation are\ndifferent from fzf. For example:\n\n1. `skim` has an interactive mode.\n2. `skim` supports pre-selection.\n3. The fuzzy search algorithm is different.\n\nMore generally, `skim`'s maintainers allow themselves some freedom of implementation.\nThe goal is to keep `skim` as feature-full as `fzf` is, but the command flags might differ.\n\n# How to contribute\n\n[Create new issues](https://github.com/skim-rs/skim/issues/new) if you encounter any bugs\nor have any ideas. Pull requests are warmly welcomed.\n\n# Troubleshooting\n\nTo troubleshoot what's happening, you can set the environment variable `RUST_LOG` to either `debug` or even `trace`, and set `--log-file` to a path. You can then read those logs during or after the execution to better understand what's happening. Don't hesitate to add those logs to an issue if you need help.\n\n## No line feed issues with nix, FreeBSD, termux\n\nIf you encounter display issues like:\n\n```bash\n$ for n in {1..10}; do echo \"$n\"; done | sk\n  0/10 0/0.> 10/10  10  9  8  7  6  5  4  3  2> 1\n```\n\nFor example\n\n- https://github.com/skim-rs/skim/issues/412\n- https://github.com/skim-rs/skim/issues/455\n\nYou need to set TERMINFO or TERMINFO_DIRS to the path of a correct terminfo database path\n\nFor example, with termux, you can add this in your bashrc:\n\n```\nexport TERMINFO=/data/data/com.termux/files/usr/share/terminfo\n```\n\n# Benchmarks\n\nThe `bench.sh` script is available to benchmark the code.\n\nYou can use it directly using `./bench.sh <binary> -n <number of items> -r <number of runs>`, or generate the data using `./bench.sh -g <output file> -n <number of items>`, then `./bench.sh <binary> -f <file> -r <number of runs>`\n",
      "stars_today": 26
    },
    {
      "id": 523043277,
      "name": "ruff",
      "full_name": "astral-sh/ruff",
      "description": "An extremely fast Python linter and code formatter, written in Rust.",
      "html_url": "https://github.com/astral-sh/ruff",
      "stars": 45339,
      "forks": 1714,
      "language": "Rust",
      "topics": [
        "linter",
        "pep8",
        "python",
        "python3",
        "ruff",
        "rust",
        "rustpython",
        "static-analysis",
        "static-code-analysis",
        "style-guide",
        "styleguide"
      ],
      "created_at": "2022-08-09T17:17:44Z",
      "updated_at": "2026-01-24T01:21:31Z",
      "pushed_at": "2026-01-23T23:24:08Z",
      "open_issues": 1889,
      "owner": {
        "login": "astral-sh",
        "avatar_url": "https://avatars.githubusercontent.com/u/115962839?v=4"
      },
      "readme": "<!-- Begin section: Overview -->\n\n# Ruff\n\n[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)\n[![image](https://img.shields.io/pypi/v/ruff.svg)](https://pypi.python.org/pypi/ruff)\n[![image](https://img.shields.io/pypi/l/ruff.svg)](https://github.com/astral-sh/ruff/blob/main/LICENSE)\n[![image](https://img.shields.io/pypi/pyversions/ruff.svg)](https://pypi.python.org/pypi/ruff)\n[![Actions status](https://github.com/astral-sh/ruff/workflows/CI/badge.svg)](https://github.com/astral-sh/ruff/actions)\n[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.com/invite/astral-sh)\n\n[**Docs**](https://docs.astral.sh/ruff/) | [**Playground**](https://play.ruff.rs/)\n\nAn extremely fast Python linter and code formatter, written in Rust.\n\n<p align=\"center\">\n  <picture align=\"center\">\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://user-images.githubusercontent.com/1309177/232603514-c95e9b0f-6b31-43de-9a80-9e844173fd6a.svg\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://user-images.githubusercontent.com/1309177/232603516-4fb4892d-585c-4b20-b810-3db9161831e4.svg\">\n    <img alt=\"Shows a bar chart with benchmark results.\" src=\"https://user-images.githubusercontent.com/1309177/232603516-4fb4892d-585c-4b20-b810-3db9161831e4.svg\">\n  </picture>\n</p>\n\n<p align=\"center\">\n  <i>Linting the CPython codebase from scratch.</i>\n</p>\n\n- ‚ö°Ô∏è 10-100x faster than existing linters (like Flake8) and formatters (like Black)\n- üêç Installable via `pip`\n- üõ†Ô∏è `pyproject.toml` support\n- ü§ù Python 3.14 compatibility\n- ‚öñÔ∏è Drop-in parity with [Flake8](https://docs.astral.sh/ruff/faq/#how-does-ruffs-linter-compare-to-flake8), isort, and [Black](https://docs.astral.sh/ruff/faq/#how-does-ruffs-formatter-compare-to-black)\n- üì¶ Built-in caching, to avoid re-analyzing unchanged files\n- üîß Fix support, for automatic error correction (e.g., automatically remove unused imports)\n- üìè Over [800 built-in rules](https://docs.astral.sh/ruff/rules/), with native re-implementations\n    of popular Flake8 plugins, like flake8-bugbear\n- ‚å®Ô∏è First-party [editor integrations](https://docs.astral.sh/ruff/editors) for [VS Code](https://github.com/astral-sh/ruff-vscode) and [more](https://docs.astral.sh/ruff/editors/setup)\n- üåé Monorepo-friendly, with [hierarchical and cascading configuration](https://docs.astral.sh/ruff/configuration/#config-file-discovery)\n\nRuff aims to be orders of magnitude faster than alternative tools while integrating more\nfunctionality behind a single, common interface.\n\nRuff can be used to replace [Flake8](https://pypi.org/project/flake8/) (plus dozens of plugins),\n[Black](https://github.com/psf/black), [isort](https://pypi.org/project/isort/),\n[pydocstyle](https://pypi.org/project/pydocstyle/), [pyupgrade](https://pypi.org/project/pyupgrade/),\n[autoflake](https://pypi.org/project/autoflake/), and more, all while executing tens or hundreds of\ntimes faster than any individual tool.\n\nRuff is extremely actively developed and used in major open-source projects like:\n\n- [Apache Airflow](https://github.com/apache/airflow)\n- [Apache Superset](https://github.com/apache/superset)\n- [FastAPI](https://github.com/tiangolo/fastapi)\n- [Hugging Face](https://github.com/huggingface/transformers)\n- [Pandas](https://github.com/pandas-dev/pandas)\n- [SciPy](https://github.com/scipy/scipy)\n\n...and [many more](#whos-using-ruff).\n\nRuff is backed by [Astral](https://astral.sh), the creators of\n[uv](https://github.com/astral-sh/uv) and [ty](https://github.com/astral-sh/ty).\n\nRead the [launch post](https://astral.sh/blog/announcing-astral-the-company-behind-ruff), or the\noriginal [project announcement](https://notes.crmarsh.com/python-tooling-could-be-much-much-faster).\n\n## Testimonials\n\n[**Sebasti√°n Ram√≠rez**](https://twitter.com/tiangolo/status/1591912354882764802), creator\nof [FastAPI](https://github.com/tiangolo/fastapi):\n\n> Ruff is so fast that sometimes I add an intentional bug in the code just to confirm it's actually\n> running and checking the code.\n\n[**Nick Schrock**](https://twitter.com/schrockn/status/1612615862904827904), founder of [Elementl](https://www.elementl.com/),\nco-creator of [GraphQL](https://graphql.org/):\n\n> Why is Ruff a gamechanger? Primarily because it is nearly 1000x faster. Literally. Not a typo. On\n> our largest module (dagster itself, 250k LOC) pylint takes about 2.5 minutes, parallelized across 4\n> cores on my M1. Running ruff against our _entire_ codebase takes .4 seconds.\n\n[**Bryan Van de Ven**](https://github.com/bokeh/bokeh/pull/12605), co-creator\nof [Bokeh](https://github.com/bokeh/bokeh/), original author\nof [Conda](https://docs.conda.io/en/latest/):\n\n> Ruff is ~150-200x faster than flake8 on my machine, scanning the whole repo takes ~0.2s instead of\n> ~20s. This is an enormous quality of life improvement for local dev. It's fast enough that I added\n> it as an actual commit hook, which is terrific.\n\n[**Timothy Crosley**](https://twitter.com/timothycrosley/status/1606420868514877440),\ncreator of [isort](https://github.com/PyCQA/isort):\n\n> Just switched my first project to Ruff. Only one downside so far: it's so fast I couldn't believe\n> it was working till I intentionally introduced some errors.\n\n[**Tim Abbott**](https://github.com/zulip/zulip/pull/23431#issuecomment-1302557034), lead developer of [Zulip](https://github.com/zulip/zulip) (also [here](https://github.com/astral-sh/ruff/issues/465#issuecomment-1317400028)):\n\n> This is just ridiculously fast... `ruff` is amazing.\n\n<!-- End section: Overview -->\n\n## Table of Contents\n\nFor more, see the [documentation](https://docs.astral.sh/ruff/).\n\n1. [Getting Started](#getting-started)\n1. [Configuration](#configuration)\n1. [Rules](#rules)\n1. [Contributing](#contributing)\n1. [Support](#support)\n1. [Acknowledgements](#acknowledgements)\n1. [Who's Using Ruff?](#whos-using-ruff)\n1. [License](#license)\n\n## Getting Started<a id=\"getting-started\"></a>\n\nFor more, see the [documentation](https://docs.astral.sh/ruff/).\n\n### Installation\n\nRuff is available as [`ruff`](https://pypi.org/project/ruff/) on PyPI.\n\nInvoke Ruff directly with [`uvx`](https://docs.astral.sh/uv/):\n\n```shell\nuvx ruff check   # Lint all files in the current directory.\nuvx ruff format  # Format all files in the current directory.\n```\n\nOr install Ruff with `uv` (recommended), `pip`, or `pipx`:\n\n```shell\n# With uv.\nuv tool install ruff@latest  # Install Ruff globally.\nuv add --dev ruff            # Or add Ruff to your project.\n\n# With pip.\npip install ruff\n\n# With pipx.\npipx install ruff\n```\n\nStarting with version `0.5.0`, Ruff can be installed with our standalone installers:\n\n```shell\n# On macOS and Linux.\ncurl -LsSf https://astral.sh/ruff/install.sh | sh\n\n# On Windows.\npowershell -c \"irm https://astral.sh/ruff/install.ps1 | iex\"\n\n# For a specific version.\ncurl -LsSf https://astral.sh/ruff/0.14.14/install.sh | sh\npowershell -c \"irm https://astral.sh/ruff/0.14.14/install.ps1 | iex\"\n```\n\nYou can also install Ruff via [Homebrew](https://formulae.brew.sh/formula/ruff), [Conda](https://anaconda.org/conda-forge/ruff),\nand with [a variety of other package managers](https://docs.astral.sh/ruff/installation/).\n\n### Usage\n\nTo run Ruff as a linter, try any of the following:\n\n```shell\nruff check                          # Lint all files in the current directory (and any subdirectories).\nruff check path/to/code/            # Lint all files in `/path/to/code` (and any subdirectories).\nruff check path/to/code/*.py        # Lint all `.py` files in `/path/to/code`.\nruff check path/to/code/to/file.py  # Lint `file.py`.\nruff check @arguments.txt           # Lint using an input file, treating its contents as newline-delimited command-line arguments.\n```\n\nOr, to run Ruff as a formatter:\n\n```shell\nruff format                          # Format all files in the current directory (and any subdirectories).\nruff format path/to/code/            # Format all files in `/path/to/code` (and any subdirectories).\nruff format path/to/code/*.py        # Format all `.py` files in `/path/to/code`.\nruff format path/to/code/to/file.py  # Format `file.py`.\nruff format @arguments.txt           # Format using an input file, treating its contents as newline-delimited command-line arguments.\n```\n\nRuff can also be used as a [pre-commit](https://pre-commit.com/) hook via [`ruff-pre-commit`](https://github.com/astral-sh/ruff-pre-commit):\n\n```yaml\n- repo: https://github.com/astral-sh/ruff-pre-commit\n  # Ruff version.\n  rev: v0.14.14\n  hooks:\n    # Run the linter.\n    - id: ruff-check\n      args: [ --fix ]\n    # Run the formatter.\n    - id: ruff-format\n```\n\nRuff can also be used as a [VS Code extension](https://github.com/astral-sh/ruff-vscode) or with [various other editors](https://docs.astral.sh/ruff/editors/setup).\n\nRuff can also be used as a [GitHub Action](https://github.com/features/actions) via\n[`ruff-action`](https://github.com/astral-sh/ruff-action):\n\n```yaml\nname: Ruff\non: [ push, pull_request ]\njobs:\n  ruff:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: astral-sh/ruff-action@v3\n```\n\n### Configuration<a id=\"configuration\"></a>\n\nRuff can be configured through a `pyproject.toml`, `ruff.toml`, or `.ruff.toml` file (see:\n[_Configuration_](https://docs.astral.sh/ruff/configuration/), or [_Settings_](https://docs.astral.sh/ruff/settings/)\nfor a complete list of all configuration options).\n\nIf left unspecified, Ruff's default configuration is equivalent to the following `ruff.toml` file:\n\n```toml\n# Exclude a variety of commonly ignored directories.\nexclude = [\n    \".bzr\",\n    \".direnv\",\n    \".eggs\",\n    \".git\",\n    \".git-rewrite\",\n    \".hg\",\n    \".ipynb_checkpoints\",\n    \".mypy_cache\",\n    \".nox\",\n    \".pants.d\",\n    \".pyenv\",\n    \".pytest_cache\",\n    \".pytype\",\n    \".ruff_cache\",\n    \".svn\",\n    \".tox\",\n    \".venv\",\n    \".vscode\",\n    \"__pypackages__\",\n    \"_build\",\n    \"buck-out\",\n    \"build\",\n    \"dist\",\n    \"node_modules\",\n    \"site-packages\",\n    \"venv\",\n]\n\n# Same as Black.\nline-length = 88\nindent-width = 4\n\n# Assume Python 3.9\ntarget-version = \"py39\"\n\n[lint]\n# Enable Pyflakes (`F`) and a subset of the pycodestyle (`E`) codes by default.\nselect = [\"E4\", \"E7\", \"E9\", \"F\"]\nignore = []\n\n# Allow fix for all enabled rules (when `--fix`) is provided.\nfixable = [\"ALL\"]\nunfixable = []\n\n# Allow unused variables when underscore-prefixed.\ndummy-variable-rgx = \"^(_+|(_+[a-zA-Z0-9_]*[a-zA-Z0-9]+?))$\"\n\n[format]\n# Like Black, use double quotes for strings.\nquote-style = \"double\"\n\n# Like Black, indent with spaces, rather than tabs.\nindent-style = \"space\"\n\n# Like Black, respect magic trailing commas.\nskip-magic-trailing-comma = false\n\n# Like Black, automatically detect the appropriate line ending.\nline-ending = \"auto\"\n```\n\nNote that, in a `pyproject.toml`, each section header should be prefixed with `tool.ruff`. For\nexample, `[lint]` should be replaced with `[tool.ruff.lint]`.\n\nSome configuration options can be provided via dedicated command-line arguments, such as those\nrelated to rule enablement and disablement, file discovery, and logging level:\n\n```shell\nruff check --select F401 --select F403 --quiet\n```\n\nThe remaining configuration options can be provided through a catch-all `--config` argument:\n\n```shell\nruff check --config \"lint.per-file-ignores = {'some_file.py' = ['F841']}\"\n```\n\nTo opt in to the latest lint rules, formatter style changes, interface updates, and more, enable\n[preview mode](https://docs.astral.sh/ruff/rules/) by setting `preview = true` in your configuration\nfile or passing `--preview` on the command line. Preview mode enables a collection of unstable\nfeatures that may change prior to stabilization.\n\nSee `ruff help` for more on Ruff's top-level commands, or `ruff help check` and `ruff help format`\nfor more on the linting and formatting commands, respectively.\n\n## Rules<a id=\"rules\"></a>\n\n<!-- Begin section: Rules -->\n\n**Ruff supports over 800 lint rules**, many of which are inspired by popular tools like Flake8,\nisort, pyupgrade, and others. Regardless of the rule's origin, Ruff re-implements every rule in\nRust as a first-party feature.\n\nBy default, Ruff enables Flake8's `F` rules, along with a subset of the `E` rules, omitting any\nstylistic rules that overlap with the use of a formatter, like `ruff format` or\n[Black](https://github.com/psf/black).\n\nIf you're just getting started with Ruff, **the default rule set is a great place to start**: it\ncatches a wide variety of common errors (like unused imports) with zero configuration.\n\n<!-- End section: Rules -->\n\nBeyond the defaults, Ruff re-implements some of the most popular Flake8 plugins and related code\nquality tools, including:\n\n- [autoflake](https://pypi.org/project/autoflake/)\n- [eradicate](https://pypi.org/project/eradicate/)\n- [flake8-2020](https://pypi.org/project/flake8-2020/)\n- [flake8-annotations](https://pypi.org/project/flake8-annotations/)\n- [flake8-async](https://pypi.org/project/flake8-async)\n- [flake8-bandit](https://pypi.org/project/flake8-bandit/) ([#1646](https://github.com/astral-sh/ruff/issues/1646))\n- [flake8-blind-except](https://pypi.org/project/flake8-blind-except/)\n- [flake8-boolean-trap](https://pypi.org/project/flake8-boolean-trap/)\n- [flake8-bugbear](https://pypi.org/project/flake8-bugbear/)\n- [flake8-builtins](https://pypi.org/project/flake8-builtins/)\n- [flake8-commas](https://pypi.org/project/flake8-commas/)\n- [flake8-comprehensions](https://pypi.org/project/flake8-comprehensions/)\n- [flake8-copyright](https://pypi.org/project/flake8-copyright/)\n- [flake8-datetimez](https://pypi.org/project/flake8-datetimez/)\n- [flake8-debugger](https://pypi.org/project/flake8-debugger/)\n- [flake8-django](https://pypi.org/project/flake8-django/)\n- [flake8-docstrings](https://pypi.org/project/flake8-docstrings/)\n- [flake8-eradicate](https://pypi.org/project/flake8-eradicate/)\n- [flake8-errmsg](https://pypi.org/project/flake8-errmsg/)\n- [flake8-executable](https://pypi.org/project/flake8-executable/)\n- [flake8-future-annotations](https://pypi.org/project/flake8-future-annotations/)\n- [flake8-gettext](https://pypi.org/project/flake8-gettext/)\n- [flake8-implicit-str-concat](https://pypi.org/project/flake8-implicit-str-concat/)\n- [flake8-import-conventions](https://github.com/joaopalmeiro/flake8-import-conventions)\n- [flake8-logging](https://pypi.org/project/flake8-logging/)\n- [flake8-logging-format](https://pypi.org/project/flake8-logging-format/)\n- [flake8-no-pep420](https://pypi.org/project/flake8-no-pep420)\n- [flake8-pie](https://pypi.org/project/flake8-pie/)\n- [flake8-print](https://pypi.org/project/flake8-print/)\n- [flake8-pyi](https://pypi.org/project/flake8-pyi/)\n- [flake8-pytest-style](https://pypi.org/project/flake8-pytest-style/)\n- [flake8-quotes](https://pypi.org/project/flake8-quotes/)\n- [flake8-raise](https://pypi.org/project/flake8-raise/)\n- [flake8-return](https://pypi.org/project/flake8-return/)\n- [flake8-self](https://pypi.org/project/flake8-self/)\n- [flake8-simplify](https://pypi.org/project/flake8-simplify/)\n- [flake8-slots](https://pypi.org/project/flake8-slots/)\n- [flake8-super](https://pypi.org/project/flake8-super/)\n- [flake8-tidy-imports](https://pypi.org/project/flake8-tidy-imports/)\n- [flake8-todos](https://pypi.org/project/flake8-todos/)\n- [flake8-type-checking](https://pypi.org/project/flake8-type-checking/)\n- [flake8-use-pathlib](https://pypi.org/project/flake8-use-pathlib/)\n- [flynt](https://pypi.org/project/flynt/) ([#2102](https://github.com/astral-sh/ruff/issues/2102))\n- [isort](https://pypi.org/project/isort/)\n- [mccabe](https://pypi.org/project/mccabe/)\n- [pandas-vet](https://pypi.org/project/pandas-vet/)\n- [pep8-naming](https://pypi.org/project/pep8-naming/)\n- [pydocstyle](https://pypi.org/project/pydocstyle/)\n- [pygrep-hooks](https://github.com/pre-commit/pygrep-hooks)\n- [pylint-airflow](https://pypi.org/project/pylint-airflow/)\n- [pyupgrade](https://pypi.org/project/pyupgrade/)\n- [tryceratops](https://pypi.org/project/tryceratops/)\n- [yesqa](https://pypi.org/project/yesqa/)\n\nFor a complete enumeration of the supported rules, see [_Rules_](https://docs.astral.sh/ruff/rules/).\n\n## Contributing<a id=\"contributing\"></a>\n\nContributions are welcome and highly appreciated. To get started, check out the\n[**contributing guidelines**](https://docs.astral.sh/ruff/contributing/).\n\nYou can also join us on [**Discord**](https://discord.com/invite/astral-sh).\n\n## Support<a id=\"support\"></a>\n\nHaving trouble? Check out the existing issues on [**GitHub**](https://github.com/astral-sh/ruff/issues),\nor feel free to [**open a new one**](https://github.com/astral-sh/ruff/issues/new).\n\nYou can also ask for help on [**Discord**](https://discord.com/invite/astral-sh).\n\n## Acknowledgements<a id=\"acknowledgements\"></a>\n\nRuff's linter draws on both the APIs and implementation details of many other\ntools in the Python ecosystem, especially [Flake8](https://github.com/PyCQA/flake8), [Pyflakes](https://github.com/PyCQA/pyflakes),\n[pycodestyle](https://github.com/PyCQA/pycodestyle), [pydocstyle](https://github.com/PyCQA/pydocstyle),\n[pyupgrade](https://github.com/asottile/pyupgrade), and [isort](https://github.com/PyCQA/isort).\n\nIn some cases, Ruff includes a \"direct\" Rust port of the corresponding tool.\nWe're grateful to the maintainers of these tools for their work, and for all\nthe value they've provided to the Python community.\n\nRuff's formatter is built on a fork of Rome's [`rome_formatter`](https://github.com/rome/tools/tree/main/crates/rome_formatter),\nand again draws on both API and implementation details from [Rome](https://github.com/rome/tools),\n[Prettier](https://github.com/prettier/prettier), and [Black](https://github.com/psf/black).\n\nRuff's import resolver is based on the import resolution algorithm from [Pyright](https://github.com/microsoft/pyright).\n\nRuff is also influenced by a number of tools outside the Python ecosystem, like\n[Clippy](https://github.com/rust-lang/rust-clippy) and [ESLint](https://github.com/eslint/eslint).\n\nRuff is the beneficiary of a large number of [contributors](https://github.com/astral-sh/ruff/graphs/contributors).\n\nRuff is released under the MIT license.\n\n## Who's Using Ruff?<a id=\"whos-using-ruff\"></a>\n\nRuff is used by a number of major open-source projects and companies, including:\n\n- [Albumentations](https://github.com/albumentations-team/AlbumentationsX)\n- Amazon ([AWS SAM](https://github.com/aws/serverless-application-model))\n- [Anki](https://apps.ankiweb.net/)\n- Anthropic ([Python SDK](https://github.com/anthropics/anthropic-sdk-python))\n- [Apache Airflow](https://github.com/apache/airflow)\n- AstraZeneca ([Magnus](https://github.com/AstraZeneca/magnus-core))\n- [Babel](https://github.com/python-babel/babel)\n- Benchling ([Refac](https://github.com/benchling/refac))\n- [Bokeh](https://github.com/bokeh/bokeh)\n- Capital One ([datacompy](https://github.com/capitalone/datacompy))\n- CrowdCent ([NumerBlox](https://github.com/crowdcent/numerblox)) <!-- typos: ignore -->\n- [Cryptography (PyCA)](https://github.com/pyca/cryptography)\n- CERN ([Indico](https://getindico.io/))\n- [DVC](https://github.com/iterative/dvc)\n- [Dagger](https://github.com/dagger/dagger)\n- [Dagster](https://github.com/dagster-io/dagster)\n- Databricks ([MLflow](https://github.com/mlflow/mlflow))\n- [Dify](https://github.com/langgenius/dify)\n- [FastAPI](https://github.com/tiangolo/fastapi)\n- [Godot](https://github.com/godotengine/godot)\n- [Gradio](https://github.com/gradio-app/gradio)\n- [Great Expectations](https://github.com/great-expectations/great_expectations)\n- [HTTPX](https://github.com/encode/httpx)\n- [Hatch](https://github.com/pypa/hatch)\n- [Home Assistant](https://github.com/home-assistant/core)\n- Hugging Face ([Transformers](https://github.com/huggingface/transformers),\n    [Datasets](https://github.com/huggingface/datasets),\n    [Diffusers](https://github.com/huggingface/diffusers))\n- IBM ([Qiskit](https://github.com/Qiskit/qiskit))\n- ING Bank ([popmon](https://github.com/ing-bank/popmon), [probatus](https://github.com/ing-bank/probatus))\n- [Ibis](https://github.com/ibis-project/ibis)\n- [ivy](https://github.com/unifyai/ivy)\n- [JAX](https://github.com/jax-ml/jax)\n- [Jupyter](https://github.com/jupyter-server/jupyter_server)\n- [Kraken Tech](https://kraken.tech/)\n- [LangChain](https://github.com/hwchase17/langchain)\n- [Litestar](https://litestar.dev/)\n- [LlamaIndex](https://github.com/jerryjliu/llama_index)\n- Matrix ([Synapse](https://github.com/matrix-org/synapse))\n- [MegaLinter](https://github.com/oxsecurity/megalinter)\n- Meltano ([Meltano CLI](https://github.com/meltano/meltano), [Singer SDK](https://github.com/meltano/sdk))\n- Microsoft ([Semantic Kernel](https://github.com/microsoft/semantic-kernel),\n    [ONNX Runtime](https://github.com/microsoft/onnxruntime),\n    [LightGBM](https://github.com/microsoft/LightGBM))\n- Modern Treasury ([Python SDK](https://github.com/Modern-Treasury/modern-treasury-python))\n- Mozilla ([Firefox](https://github.com/mozilla/gecko-dev))\n- [Mypy](https://github.com/python/mypy)\n- [Nautobot](https://github.com/nautobot/nautobot)\n- Netflix ([Dispatch](https://github.com/Netflix/dispatch))\n- [Neon](https://github.com/neondatabase/neon)\n- [Nokia](https://nokia.com/)\n- [NoneBot](https://github.com/nonebot/nonebot2)\n- [NumPyro](https://github.com/pyro-ppl/numpyro)\n- [ONNX](https://github.com/onnx/onnx)\n- [OpenBB](https://github.com/OpenBB-finance/OpenBBTerminal)\n- [Open Wine Components](https://github.com/Open-Wine-Components/umu-launcher)\n- [PDM](https://github.com/pdm-project/pdm)\n- [PaddlePaddle](https://github.com/PaddlePaddle/Paddle)\n- [Pandas](https://github.com/pandas-dev/pandas)\n- [Pillow](https://github.com/python-pillow/Pillow)\n- [Poetry](https://github.com/python-poetry/poetry)\n- [Polars](https://github.com/pola-rs/polars)\n- [PostHog](https://github.com/PostHog/posthog)\n- Prefect ([Python SDK](https://github.com/PrefectHQ/prefect), [Marvin](https://github.com/PrefectHQ/marvin))\n- [PyInstaller](https://github.com/pyinstaller/pyinstaller)\n- [PyMC](https://github.com/pymc-devs/pymc/)\n- [PyMC-Marketing](https://github.com/pymc-labs/pymc-marketing)\n- [pytest](https://github.com/pytest-dev/pytest)\n- [PyTorch](https://github.com/pytorch/pytorch)\n- [Pydantic](https://github.com/pydantic/pydantic)\n- [Pylint](https://github.com/PyCQA/pylint)\n- [PyScripter](https://github.com/pyscripter/pyscripter)\n- [PyVista](https://github.com/pyvista/pyvista)\n- [Reflex](https://github.com/reflex-dev/reflex)\n- [River](https://github.com/online-ml/river)\n- [Rippling](https://rippling.com)\n- [Robyn](https://github.com/sansyrox/robyn)\n- [Saleor](https://github.com/saleor/saleor)\n- Scale AI ([Launch SDK](https://github.com/scaleapi/launch-python-client))\n- [SciPy](https://github.com/scipy/scipy)\n- Snowflake ([SnowCLI](https://github.com/Snowflake-Labs/snowcli))\n- [Sphinx](https://github.com/sphinx-doc/sphinx)\n- [Stable Baselines3](https://github.com/DLR-RM/stable-baselines3)\n- [Starlette](https://github.com/encode/starlette)\n- [Streamlit](https://github.com/streamlit/streamlit)\n- [The Algorithms](https://github.com/TheAlgorithms/Python)\n- [Vega-Altair](https://github.com/altair-viz/altair)\n- [Weblate](https://weblate.org/)\n- WordPress ([Openverse](https://github.com/WordPress/openverse))\n- [ZenML](https://github.com/zenml-io/zenml)\n- [Zulip](https://github.com/zulip/zulip)\n- [build (PyPA)](https://github.com/pypa/build)\n- [cibuildwheel (PyPA)](https://github.com/pypa/cibuildwheel)\n- [delta-rs](https://github.com/delta-io/delta-rs)\n- [featuretools](https://github.com/alteryx/featuretools)\n- [meson-python](https://github.com/mesonbuild/meson-python)\n- [nox](https://github.com/wntrblm/nox)\n- [pip](https://github.com/pypa/pip)\n\n### Show Your Support\n\nIf you're using Ruff, consider adding the Ruff badge to your project's `README.md`:\n\n```md\n[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)\n```\n\n...or `README.rst`:\n\n```rst\n.. image:: https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json\n    :target: https://github.com/astral-sh/ruff\n    :alt: Ruff\n```\n\n...or, as HTML:\n\n```html\n<a href=\"https://github.com/astral-sh/ruff\"><img src=\"https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json\" alt=\"Ruff\" style=\"max-width:100%;\"></a>\n```\n\n## License<a id=\"license\"></a>\n\nThis repository is licensed under the [MIT License](https://github.com/astral-sh/ruff/blob/main/LICENSE)\n\n<div align=\"center\">\n  <a target=\"_blank\" href=\"https://astral.sh\" style=\"background:none\">\n    <img src=\"https://raw.githubusercontent.com/astral-sh/ruff/main/assets/svg/Astral.svg\" alt=\"Made by Astral\">\n  </a>\n</div>\n",
      "stars_today": 25
    },
    {
      "id": 268163609,
      "name": "qdrant",
      "full_name": "qdrant/qdrant",
      "description": "Qdrant - High-performance, massive-scale Vector Database and Vector Search Engine for the next generation of AI. Also available in the cloud https://cloud.qdrant.io/",
      "html_url": "https://github.com/qdrant/qdrant",
      "stars": 28370,
      "forks": 2011,
      "language": "Rust",
      "topics": [
        "ai-search",
        "ai-search-engine",
        "embeddings-similarity",
        "hnsw",
        "image-search",
        "knn-algorithm",
        "machine-learning",
        "mlops",
        "nearest-neighbor-search",
        "neural-network",
        "neural-search",
        "recommender-system",
        "search",
        "search-engine",
        "search-engines",
        "similarity-search",
        "vector-database",
        "vector-search",
        "vector-search-engine"
      ],
      "created_at": "2020-05-30T21:37:01Z",
      "updated_at": "2026-01-23T20:54:23Z",
      "pushed_at": "2026-01-23T21:35:20Z",
      "open_issues": 460,
      "owner": {
        "login": "qdrant",
        "avatar_url": "https://avatars.githubusercontent.com/u/73504361?v=4"
      },
      "readme": "<p align=\"center\">\n  <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/qdrant/qdrant/raw/master/docs/logo-dark.svg\">\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"https://github.com/qdrant/qdrant/raw/master/docs/logo-light.svg\">\n      <img height=\"100\" alt=\"Qdrant\" src=\"https://github.com/qdrant/qdrant/raw/master/docs/logo.svg\">\n  </picture>\n</p>\n\n<p align=\"center\">\n    <b>Vector Search Engine for the next generation of AI applications</b>\n</p>\n\n<p align=center>\n    <a href=\"https://github.com/qdrant/qdrant/actions/workflows/rust.yml\"><img src=\"https://img.shields.io/github/actions/workflow/status/qdrant/qdrant/rust.yml?style=flat-square\" alt=\"Tests status\"></a>\n    <a href=\"https://api.qdrant.tech/\"><img src=\"https://img.shields.io/badge/Docs-OpenAPI%203.0-success?style=flat-square\" alt=\"OpenAPI Docs\"></a>\n    <a href=\"https://github.com/qdrant/qdrant/blob/master/LICENSE\"><img src=\"https://img.shields.io/github/license/qdrant/qdrant?style=flat-square\" alt=\"Apache 2.0 License\"></a>\n    <a href=\"https://qdrant.to/discord\"><img src=\"https://img.shields.io/discord/907569970500743200?logo=Discord&style=flat-square&color=7289da\" alt=\"Discord\"></a>\n    <a href=\"https://qdrant.to/roadmap\"><img src=\"https://img.shields.io/badge/Roadmap-2025-bc1439.svg?style=flat-square\" alt=\"Roadmap 2025\"></a>\n    <a href=\"https://cloud.qdrant.io/\"><img src=\"https://img.shields.io/badge/Qdrant-Cloud-24386C.svg?logo=cloud&style=flat-square\" alt=\"Qdrant Cloud\"></a>\n</p>\n\n**Qdrant** (read: _quadrant_) is a vector similarity search engine and vector database.\nIt provides a production-ready service with a convenient API to store, search, and manage points‚Äîvectors with an additional payload\nQdrant is tailored to extended filtering support. It makes it useful for all sorts of neural-network or semantic-based matching, faceted search, and other applications.\n\nQdrant is written in Rust ü¶Ä, which makes it fast and reliable even under high load. See [benchmarks](https://qdrant.tech/benchmarks/).\n\nWith Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!\n\nQdrant is also available as a fully managed **[Qdrant Cloud](https://cloud.qdrant.io/)** ‚õÖ including a **free tier**.\n\n<p align=\"center\">\n<strong><a href=\"docs/QUICK_START.md\">Quick Start</a> ‚Ä¢ <a href=\"#clients\">Client Libraries</a> ‚Ä¢ <a href=\"#demo-projects\">Demo Projects</a> ‚Ä¢ <a href=\"#integrations\">Integrations</a> ‚Ä¢ <a href=\"#contacts\">Contact</a>\n\n</strong>\n</p>\n\n## Getting Started\n\n### Python\n\n```\npip install qdrant-client\n```\n\nThe python client offers a convenient way to start with Qdrant locally:\n\n```python\nfrom qdrant_client import QdrantClient\nqdrant = QdrantClient(\":memory:\") # Create in-memory Qdrant instance, for testing, CI/CD\n# OR\nclient = QdrantClient(path=\"path/to/db\")  # Persists changes to disk, fast prototyping\n```\n\n### Client-Server\n\nTo experience the full power of Qdrant locally, run the container with this command:\n\n```bash\ndocker run -p 6333:6333 qdrant/qdrant\n```\n\n> [!CAUTION]\n> Starts an insecure deployment without authentication open to all network interfaces. Please refer to [secure your instance](https://qdrant.tech/documentation/guides/security/#secure-your-instance).\n\nNow you can connect to this with any client, including Python:\n\n```python\nqdrant = QdrantClient(\"http://localhost:6333\") # Connect to existing Qdrant instance\n```\n\nBefore deploying Qdrant to production, be sure to read our [installation](https://qdrant.tech/documentation/guides/installation/) and [security](https://qdrant.tech/documentation/guides/security/) guides.\n\n### Clients\n\nQdrant offers the following client libraries to help you integrate it into your application stack with ease:\n\n- Official:\n  - [Go client](https://github.com/qdrant/go-client)\n  - [Rust client](https://github.com/qdrant/rust-client)\n  - [JavaScript/TypeScript client](https://github.com/qdrant/qdrant-js)\n  - [Python client](https://github.com/qdrant/qdrant-client)\n  - [.NET/C# client](https://github.com/qdrant/qdrant-dotnet)\n  - [Java client](https://github.com/qdrant/java-client)\n- Community:\n  - [Elixir](https://hexdocs.pm/qdrant/readme.html)\n  - [PHP](https://github.com/hkulekci/qdrant-php)\n  - [Ruby](https://github.com/andreibondarev/qdrant-ruby)\n  - [Java](https://github.com/metaloom/qdrant-java-client)\n\n### Where do I go from here?\n\n- [Quick Start Guide](docs/QUICK_START.md)\n- End to End [Colab Notebook](https://colab.research.google.com/drive/1Bz8RSVHwnNDaNtDwotfPj0w7AYzsdXZ-?usp=sharing) demo with SentenceBERT and Qdrant\n- Detailed [Documentation](https://qdrant.tech/documentation/) are great starting points\n- [Step-by-Step Tutorial](https://qdrant.to/qdrant-tutorial) to create your first neural network project with Qdrant\n\n## Demo Projects<a href=\"https://replit.com/@qdrant\"><img align=\"right\" src=\"https://replit.com/badge/github/qdrant/qdrant\" alt=\"Run on Repl.it\"></a>\n\n### Discover Semantic Text Search üîç\n\nUnlock the power of semantic embeddings with Qdrant, transcending keyword-based search to find meaningful connections in short texts. Deploy a neural search in minutes using a pre-trained neural network, and experience the future of text search. [Try it online!](https://qdrant.to/semantic-search-demo)\n\n### Explore Similar Image Search - Food Discovery üçï\n\nThere's more to discovery than text search, especially when it comes to food. People often choose meals based on appearance rather than descriptions and ingredients. Let Qdrant help your users find their next delicious meal using visual search, even if they don't know the dish's name. [Check it out!](https://qdrant.to/food-discovery)\n\n### Master Extreme Classification - E-commerce Product Categorization üì∫\n\nEnter the cutting-edge realm of extreme classification, an emerging machine learning field tackling multi-class and multi-label problems with millions of labels. Harness the potential of similarity learning models, and see how a pre-trained transformer model and Qdrant can revolutionize e-commerce product categorization. [Play with it online!](https://qdrant.to/extreme-classification-demo)\n\n<details>\n<summary> More solutions </summary>\n\n<table>\n    <tr>\n        <td width=\"30%\">\n            <img src=\"https://qdrant.tech/content/images/text_search.png\">\n        </td>\n        <td width=\"30%\">\n            <img src=\"https://qdrant.tech/content/images/image_search.png\">\n        </td>\n        <td width=\"30%\">\n            <img src=\"https://qdrant.tech/content/images/recommendations.png\">\n        </td>\n    </tr>\n    <tr>\n        <td>\n            Semantic Text Search\n        </td>\n        <td>\n            Similar Image Search\n        </td>\n        <td>\n            Recommendations\n        </td>\n    </tr>\n</table>\n\n<table>\n    <tr>\n        <td>\n            <img width=\"300px\" src=\"https://qdrant.tech/content/images/chat_bots.png\">\n        </td>\n        <td>\n            <img width=\"300px\" src=\"https://qdrant.tech/content/images/matching_engines.png\">\n        </td>\n        <td>\n            <img width=\"300px\" src=\"https://qdrant.tech/content/images/anomalies_detection.png\">\n        </td>\n    </tr>\n    <tr>\n        <td>\n            Chat Bots\n        </td>\n        <td>\n            Matching Engines\n        </td>\n        <td>\n            Anomaly Detection\n        </td>\n    </tr>\n</table>\n\n</details>\n\n## API\n\n### REST\n\nOnline OpenAPI 3.0 documentation is available [here](https://api.qdrant.tech/).\nOpenAPI makes it easy to generate a client for virtually any framework or programming language.\n\nYou can also download raw OpenAPI [definitions](https://github.com/qdrant/qdrant/blob/master/docs/redoc/master/openapi.json).\n\n### gRPC\n\nFor faster production-tier searches, Qdrant also provides a gRPC interface. You can find gRPC documentation [here](https://qdrant.tech/documentation/interfaces/#grpc-interface).\n\n## Features\n\n### Filtering and Payload\n\nQdrant can attach any JSON payloads to vectors, allowing for both the storage and filtering of data based on the values in these payloads.\nPayload supports a wide range of data types and query conditions, including keyword matching, full-text filtering, numerical ranges, geo-locations, and more.\n\nFiltering conditions can be combined in various ways, including `should`, `must`, and `must_not` clauses,\nensuring that you can implement any desired business logic on top of similarity matching.\n\n\n### Hybrid Search with Sparse Vectors\n\nTo address the limitations of vector embeddings when searching for specific keywords, Qdrant introduces support for sparse vectors in addition to the regular dense ones.\n\nSparse vectors can be viewed as an generalization of BM25 or TF-IDF ranking. They enable you to harness the capabilities of transformer-based neural networks to weigh individual tokens effectively.\n\n\n### Vector Quantization and On-Disk Storage\n\nQdrant provides multiple options to make vector search cheaper and more resource-efficient.\nBuilt-in vector quantization reduces RAM usage by up to 97% and dynamically manages the trade-off between search speed and precision.\n\n\n### Distributed Deployment\n\nQdrant offers comprehensive horizontal scaling support through two key mechanisms:\n1. Size expansion via sharding and throughput enhancement via replication\n2. Zero-downtime rolling updates and seamless dynamic scaling of the collections\n\n\n### Highlighted Features\n\n* **Query Planning and Payload Indexes** - leverages stored payload information to optimize query execution strategy.\n* **SIMD Hardware Acceleration** - utilizes modern CPU x86-x64 and Neon architectures to deliver better performance.\n* **Async I/O** - uses `io_uring` to maximize disk throughput utilization even on a network-attached storage.\n* **Write-Ahead Logging** - ensures data persistence with update confirmation, even during power outages.\n\n\n# Integrations\n\nExamples and/or documentation of Qdrant integrations:\n\n- [Cohere](https://docs.cohere.com/docs/qdrant-and-cohere) ([blogpost on building a QA app with Cohere and Qdrant](https://qdrant.tech/articles/qa-with-cohere-and-qdrant/)) - Use Cohere embeddings with Qdrant\n- [DocArray](https://docs.docarray.org/user_guide/storing/index_qdrant/) - Use Qdrant as a document store in DocArray\n- [Haystack](https://haystack.deepset.ai/integrations/qdrant-document-store) - Use Qdrant as a document store with Haystack ([blogpost](https://haystack.deepset.ai/blog/qdrant-integration)).\n- [LangChain](https://python.langchain.com/docs/integrations/providers/qdrant/) ([blogpost](https://qdrant.tech/articles/langchain-integration/)) - Use Qdrant as a memory backend for LangChain.\n- [LlamaIndex](https://gpt-index.readthedocs.io/en/latest/examples/vector_stores/QdrantIndexDemo.html) - Use Qdrant as a Vector Store with LlamaIndex.\n- [OpenAI - ChatGPT retrieval plugin](https://github.com/openai/chatgpt-retrieval-plugin/blob/main/docs/providers/qdrant/setup.md) - Use Qdrant as a memory backend for ChatGPT\n- [Microsoft Semantic Kernel](https://devblogs.microsoft.com/semantic-kernel/the-power-of-persistent-memory-with-semantic-kernel-and-qdrant-vector-database/) - Use Qdrant as persistent memory with Semantic Kernel\n\n## Contacts\n\n- Have questions? Join our [Discord channel](https://qdrant.to/discord) or mention [@qdrant_engine on Twitter](https://qdrant.to/twitter)\n- Want to stay in touch with latest releases? Subscribe to our [Newsletters](https://qdrant.tech/subscribe/)\n- Looking for a managed cloud? Check [pricing](https://qdrant.tech/pricing/), need something personalised? We're at [info@qdrant.tech](mailto:info@qdrant.tech)\n\n## License\n\nQdrant is licensed under the Apache License, Version 2.0. View a copy of the [License file](https://github.com/qdrant/qdrant/blob/master/LICENSE).\n",
      "stars_today": 25
    },
    {
      "id": 626896474,
      "name": "SafeLine",
      "full_name": "chaitin/SafeLine",
      "description": "SafeLine is a self-hosted WAF(Web Application Firewall) / reverse proxy to protect your web apps from attacks and exploits.",
      "html_url": "https://github.com/chaitin/SafeLine",
      "stars": 20234,
      "forks": 1298,
      "language": "Go",
      "topics": [
        "api-gateway",
        "application-security",
        "appsec",
        "blueteam",
        "bruteforce",
        "captcha",
        "cve",
        "cybersecurity",
        "firewall",
        "hackers",
        "http-flood",
        "security",
        "self-hosted",
        "sql-injection",
        "vulnerability",
        "waf",
        "web-application-firewall",
        "web-security",
        "websecurity",
        "xss"
      ],
      "created_at": "2023-04-12T11:30:14Z",
      "updated_at": "2026-01-23T22:30:15Z",
      "pushed_at": "2025-11-05T08:13:12Z",
      "open_issues": 63,
      "owner": {
        "login": "chaitin",
        "avatar_url": "https://avatars.githubusercontent.com/u/7302766?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"/images/banner.png\" width=\"400\" />\n</p>\n\n<h4 align=\"center\">\n  SafeLine - Make your web apps secure\n</h4>\n\n<p align=\"center\">\n  <a target=\"_blank\" href=\"https://ly.safepoint.cloud/laA8asp\">üè† Website</a> &nbsp; | &nbsp;\n  <a target=\"_blank\" href=\"https://ly.safepoint.cloud/w2AeHhb\">üìñ Docs</a> &nbsp; | &nbsp;\n  <a target=\"_blank\" href=\"https://ly.safepoint.cloud/hSMd4SH\">üîç Live Demo</a> &nbsp; | &nbsp;\n  <a target=\"_blank\" href=\"https://discord.gg/SVnZGzHFvn\">üôã‚Äç‚ôÇÔ∏è Discord</a> &nbsp; | &nbsp;\n  <a target=\"_blank\" href=\"/README_CN.md\">‰∏≠ÊñáÁâà</a>\n</p>\n\n## üëã INTRODUCTION\n\nSafeLine is a self-hosted **`WAF(Web Application Firewall)`** to protect your web apps from attacks and exploits.\n\nA web application firewall helps protect web apps by filtering and monitoring HTTP traffic between a web application and the Internet. It typically protects web apps from attacks such as `SQL injection`, `XSS`, `code injection`, `os command injection`, `CRLF injection`, `ldap injection`, `xpath injection`, `RCE`, `XXE`, `SSRF`, `path traversal`, `backdoor`, `bruteforce`, `http-flood`, `bot abused`, among others.\n\n#### üí° How It Works\n\n<img src=\"/images/how-it-works.png\" width=\"800\" />\n\nBy deploying a WAF in front of a web application, a shield is placed between the web application and the Internet. While a proxy server protects a client machine‚Äôs identity by using an intermediary, a WAF is a type of reverse-proxy, protecting the server from exposure by having clients pass through the WAF before reaching the server.\n\nA WAF protects your web apps by filtering, monitoring, and blocking any malicious HTTP/S traffic traveling to the web application, and prevents any unauthorized data from leaving the app. It does this by adhering to a set of policies that help determine what traffic is malicious and what traffic is safe. Just as a proxy server acts as an intermediary to protect the identity of a client, a WAF operates in similar fashion but acting as a reverse proxy intermediary that protects the web app server from a potentially malicious client.\n\nits core capabilities include:\n\n- Defenses for web attacks\n- Proactive bot abused defense \n- HTML & JS code encryption\n- IP-based rate limiting\n- Web Access Control List\n\n#### ‚ö°Ô∏è Screenshots\n\n| <img src=\"./images/screenshot-1.png\" width=370 /> | <img src=\"./images/screenshot-2.png\" width=370 /> |\n| ------------------------------------------------- | ------------------------------------------------- | \n| <img src=\"./images/screenshot-3.png\" width=370 /> | <img src=\"./images/screenshot-4.png\" width=370 /> | \n\nGet [Live Demo](https://demo.waf.chaitin.com:9443/)\n\n## üî• FEATURES\n\nList of the main features as follows:\n\n- **`Block Web Attacks`**\n  - It defenses for all of web attacks, such as `SQL injection`, `XSS`, `code injection`, `os command injection`, `CRLF injection`, `XXE`, `SSRF`, `path traversal` and so on.\n- **`Rate Limiting`**\n  - Defend your web apps against `DoS attacks`, `bruteforce attempts`, `traffic surges`, and other types of abuse by throttling traffic that exceeds defined limits.\n- **`Anti-Bot Challenge`**\n  - Anti-Bot challenges to protect your website from `bot attacks`, humen users will be allowed, crawlers and bots will be blocked.\n- **`Authentication Challenge`**\n  - When authentication challenge turned on, visitors need to enter the password, otherwise they will be blocked.\n- **`Dynamic Protection`**\n  - When dynamic protection turned on, html and js codes in your web server will be dynamically encrypted by each time you visit.\n\n#### üß© Showcases\n\n|                               | Legitimate User                                     | Malicious User                                                   |\n| ----------------------------- | --------------------------------------------------- | ---------------------------------------------------------------- | \n| **`Block Web Attacks`**       | <img src=\"./images/skeleton.png\" width=270 />       | <img src=\"./images/blocked-for-attack-detected.png\" width=270 /> |\n| **`Rate Limiting`**           | <img src=\"./images/skeleton.png\" width=270 />       | <img src=\"./images/blocked-for-access-too-fast.png\" width=270 /> |\n| **`Anti-Bot Challenge`**       | <img src=\"./images/captcha-1.gif\" width=270 />      | <img src=\"./images/captcha-2.gif\" width=270 />                     |\n| **`Auth Challenge`**          | <img src=\"./images/auth-1.gif\" width=270 />         | <img src=\"./images/auth-2.gif\" width=270 />                        |\n| **`HTML Dynamic Protection`** | <img src=\"./images/dynamic-html-1.png\" width=270 /> | <img src=\"./images/dynamic-html-2.png\" width=270 />              |\n| **`JS Dynamic Protection`**   | <img src=\"./images/dynamic-js-1.png\" width=270 />   | <img src=\"./images/dynamic-js-2.png\" width=270 />                | \n\n## üöÄ Quickstart\n\n> [!WARNING]\n> ‰∏≠ÂõΩÂ§ßÈôÜÁî®Êà∑ÂÆâË£ÖÂõΩÈôÖÁâàÂèØËÉΩ‰ºöÂØºËá¥Êó†Ê≥ïËøûÊé•‰∫ëÊúçÂä°ÔºåËØ∑Êü•Áúã [‰∏≠ÊñáÁâàÂÆâË£ÖÊñáÊ°£](https://docs.waf-ce.chaitin.cn/zh/%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/%E5%AE%89%E8%A3%85%E9%9B%B7%E6%B1%A0)\n\n#### üì¶ Installing\n\nInformation on how to install SafeLine can be found in the [Install Guide](https://docs.waf.chaitin.com/en/GetStarted/Deploy)\n\n#### ‚öôÔ∏è Protecting Web Apps\n\nto see [Configuration](https://docs.waf.chaitin.com/en/GetStarted/AddApplication)\n\n## üìã More Informations\n\n#### Effect Evaluation\n\n| Metric            | ModSecurity, Level 1 | CloudFlare, Free     | SafeLine, Balance      | SafeLine, Strict      |\n| ----------------- | -------------------- | -------------------- | ---------------------- | --------------------- |\n| Total Samples     | 33669                | 33669                | 33669                  | 33669                 |\n| **Detection**     | 69.74%               | 10.70%               | 71.65%                 | **76.17%**            |\n| **False Positive**| 17.58%               | 0.07%                | **0.07%**              | 0.22%                 |\n| **Accuracy**      | 82.20%               | 98.40%               | **99.45%**             | 99.38%                |\n\n\n#### Is SafeLine Production-Ready?\n\nYes, SafeLine is production-ready.\n\n- Over 180,000 installations worldwide\n- Protecting over 1,000,000 Websites\n- Handling over 30,000,000,000 HTTP Requests Daily\n\n#### üôã‚Äç‚ôÇÔ∏è Community\n\nJoin our [Discord](https://discord.gg/SVnZGzHFvn) to get community support, the core team members are identified by the STAFF role in Discord.\n\n- channel [#feedback](https://discord.com/channels/1243085666485534830/1243120292822253598): for new features discussion.\n- channel [#FAQ](https://discord.com/channels/1243085666485534830/1263761679619981413): for FAQ.\n- channel [#general](https://discord.com/channels/1243085666485534830/1243115843919806486): for any other questions.\n\nSeveral contact options exist for our community, the primary one being Discord. These are in addition to GitHub issues for creating a new issue.\n\n<p align=\"left\">\n  <a target=\"_blank\" href=\"https://discord.gg/SVnZGzHFvn\"><img src=\"https://img.shields.io/badge/Discord-5865F2?style=flat&logo=discord&logoColor=white\"></a> &nbsp;\n  <a target=\"_blank\" href=\"https://x.com/safeline_waf\"><img src=\"https://img.shields.io/badge/X.com-000000?style=flat&logo=x&logoColor=white\"></a> &nbsp;\n  <a target=\"_blank\" href=\"/images/wechat.png\"><img src=\"https://img.shields.io/badge/WeChat-07C160?style=flat&logo=wechat&logoColor=white\"></a>\n</p>\n\n#### üí™ PRO Edition\n\nComing soon!\n\n#### üìù License\n\nSee [LICENSE](/LICENSE.md) for details.\n",
      "stars_today": 25
    },
    {
      "id": 593867048,
      "name": "xpipe",
      "full_name": "xpipe-io/xpipe",
      "description": "Access your entire server infrastructure from your local desktop",
      "html_url": "https://github.com/xpipe-io/xpipe",
      "stars": 13590,
      "forks": 522,
      "language": "Java",
      "topics": [
        "bash",
        "docker",
        "filemanager",
        "files",
        "incus",
        "java",
        "javafx",
        "k8s",
        "kubernetes",
        "lxd",
        "networking",
        "podman",
        "sftp",
        "ssh",
        "tailscale",
        "wsl"
      ],
      "created_at": "2023-01-27T02:25:38Z",
      "updated_at": "2026-01-23T23:03:28Z",
      "pushed_at": "2026-01-23T16:41:15Z",
      "open_issues": 48,
      "owner": {
        "login": "xpipe-io",
        "avatar_url": "https://avatars.githubusercontent.com/u/93734037?v=4"
      },
      "readme": "<p align=\"center\">\n    <a href=\"https://xpipe.io\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/img/banner.png\" alt=\"XPipe Banner\" />\n    </a>\n</p>\n\n<h1></h1>\n\n## About\n\nXPipe is a connection hub that allows you to access your entire server infrastructure from your local desktop. It works on top of your installed command-line programs like SSH, docker, or others, and does not require any setup on your remote systems. It integrates with your favourite text editors, terminals, shells, VNC/RDP clients, password managers, and command-line tools. The platform is designed to be extensible, allowing anyone to add easily support for more tools or to implement custom functionality through a modular extension system.\n\nIt currently supports:\n\n- [SSH](https://docs.xpipe.io/guide/ssh) connections, config files, and tunnels\n- [Docker](https://docs.xpipe.io/guide/docker) + compose, [Podman](https://docs.xpipe.io/guide/podman), [LXD](https://docs.xpipe.io/guide/lxc), and [incus](https://docs.xpipe.io/guide/lxc) containers\n- [Proxmox PVE](https://docs.xpipe.io/guide/proxmox), [Hyper-V](https://docs.xpipe.io/guide/hyperv), [KVM](https://docs.xpipe.io/guide/kvm), and [VMware Player/Workstation/Fusion](https://docs.xpipe.io/guide/vmware) virtual machines\n- [Tailscale](https://docs.xpipe.io/guide/tailscale), [Netbird](https://docs.xpipe.io/guide/netbird), and [Teleport](https://docs.xpipe.io/guide/teleport) connections\n- [AWS](https://docs.xpipe.io/guide/aws) and [Hetzner Cloud](https://docs.xpipe.io/guide/hcloud) servers\n- [RDP](https://docs.xpipe.io/guide/rdp) and [VNC](https://docs.xpipe.io/guide/vnc) connections\n- Windows Subsystem for Linux, Cygwin, and MSYS2 environments\n- [Kubernetes](https://docs.xpipe.io/guide/kubernetes) clusters, pods, and containers\n- [Powershell Remote Sessions](https://docs.xpipe.io/guide/pssession)\n\n---\n\n<div align=\"center\">\n    <a href=\"https://docs.xpipe.io/guide/ssh\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/ssh.svg\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/docker\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/docker.svg\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/docker#compose\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/compose.png\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/lxc\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/lxd.svg\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/podman\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/podman.svg\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/aws\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/aws.svg\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/kubernetes\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/k8s.svg\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/proxmox\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/proxmox.svg\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/vmware\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/vmware.svg\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/kvm\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/virsh.png\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/tailscale\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/tailscale.svg\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/netbird\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/netbird.svg\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/hcloud\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/hetzner.svg\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/teleport\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/teleport.png\" width=40 height=40 />\n    </a>\n</div>\n\n## Connection hub\n\n- Easily establish and manage connections to remote systems from a central hub interface\n- Organize all your connections in hierarchical categories to maintain an overview over hundreds of connections.\n- Create custom shell login environments to instantly jump into a properly set up shell for every use case\n- Quickly perform various commonly used actions like starting/stopping systems, establishing tunnels, and more\n- Create desktop shortcuts and macros that automatically open remote connections in your terminal without having to open any GUI\n\n![Connection hub](https://github.com/xpipe-io/.github/raw/main/img/hub_shadow.png)\n\n## File browser\n\n- Interact with the file system of any remote system using a workflow optimized for professionals\n- Utilize your entire arsenal of locally installed programs to open and edit remote files\n- Dynamically elevate sessions with sudo when required without having to restart the session\n- Seamlessly transfer files from and to your system desktop environment\n- Work and perform transfers on multiple systems at the same time with the built-in tabbed multitasking\n- Quickly open a terminal session into any directory in your favourite terminal emulator\n- Customize every action through the scripting system\n\n![Browser](https://github.com/xpipe-io/.github/raw/main/img/browser_shadow.png)\n\n## Terminal launcher\n\n- Launches you into a shell session in your favourite terminal with one click. Automatically fills password prompts and more\n- Comes with support for all commonly used terminal emulators across all operating systems\n- Supports opening custom terminal emulators as well via a custom command-line spec\n- Works with all command shells such as bash, zsh, fish, cmd, PowerShell, and more, locally and remote\n- Integrates with multiplexers like tmux and zellij, plus prompts like starship and oh-my-zsh\n- Supports opening multiple sessions in split terminal pane views\n- Connects to a system while the terminal is still starting up, allowing for faster connections than otherwise possible\n\n![Terminal](https://github.com/xpipe-io/.github/raw/main/img/terminal_shadow.png)\n\n## Versatile scripting system\n\n- Create reusable simple shell scripts, templates, and groups to run on connected remote systems\n- Automatically make your scripts available in the PATH on any remote system without any setup\n- Setup shell init environments for connections to fully customize your work environment for every purpose\n- Open custom shells and custom remote connections by providing your own commands\n- Use custom scripts in the file browser \n\n![scripts](https://github.com/xpipe-io/.github/raw/main/img/scripts_shadow.png)\n\n## And much more\n\n- You can synchronize your vault across multiple systems and share it with other team members via your own self-hosted git repository\n- All data is stored exclusively on your systems in a cryptographically secure vault. You can also choose to increase security by using a custom master passphrase for further encryption\n- XPipe is able to retrieve secrets automatically from your installed password manager and doesn't have store secrets itself\n- There are no servers involved, all your information stays on your systems. The XPipe application does not send any personal or sensitive information to outside services\n- XPipe has an integrated MCP server that you can enable. This allows you to easily use all of XPipe's features from an AI agent\n- Run coherent desktop applications remotely via the uniform desktop application system in XPipe for RDP, VNC, and X11 forwards\n- Securely tunnel and automatically open remote services with one click with the services integration\n\n# Downloads\n\nNote that this is a desktop application that should be run on your local desktop workstation, not on any server or containers. It will be able to connect to your server infrastructure from there.\n\nFor a full reference and instructions, see the [installation docs](https://docs.xpipe.io/guide/installation) and [managed installation docs](https://docs.xpipe.io/guide/managed-installation).\n\n## Windows\n\nInstallers are the easiest way to get started and come with an optional automatic update functionality:\n\n- [Windows .msi Installer (x86-64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-windows-x86_64.msi)\n- [Windows .msi Installer (ARM 64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-windows-arm64.msi)\n\nIf you don't like installers, you can also use a portable version that is packaged as an archive:\n\n- [Windows .zip Portable (x86-64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-windows-x86_64.zip)\n- [Windows .zip Portable (ARM 64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-windows-arm64.zip)\n\nAlternatively, you can also use the following package managers:\n- [choco](https://community.chocolatey.org/packages/xpipe) to install it with `choco install xpipe`.\n- [winget](https://github.com/microsoft/winget-cli) to install it with `winget install xpipe-io.xpipe --source winget`.\n- [scoop](https://github.com/microsoft/winget-cli) to install it with `scoop install extras/xpipe`.\n\n## macOS\n\nInstallers are the easiest way to get started and come with an optional automatic update functionality:\n\n- [MacOS .pkg Installer (x86-64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-macos-x86_64.pkg)\n- [MacOS .pkg Installer (ARM 64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-macos-arm64.pkg)\n\nIf you don't like installers, you can also use a portable version that is packaged as an archive:\n\n- [MacOS .dmg Portable (x86-64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-macos-x86_64.dmg)\n- [MacOS .dmg Portable (ARM 64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-macos-arm64.dmg)\n\nAlternatively, you can also use [Homebrew](https://github.com/xpipe-io/homebrew-tap) to install XPipe with `brew install --cask xpipe-io/tap/xpipe`.\n\n## Linux\n\nYou can install XPipe the fastest by pasting the installation command into your terminal. This will perform the setup automatically.\nThe script supports installation via `apt`, `dnf`, `yum`, `zypper`, `rpm`, and `pacman` on Linux:\n\n```\nbash <(curl -sL https://github.com/xpipe-io/xpipe/raw/master/get-xpipe.sh)\n```\n\nOf course, there are also other installation methods available.\n\n### Debian-based distros\n\nThe following debian installers are available:\n\n- [Linux .deb Installer (x86-64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-linux-x86_64.deb)\n- [Linux .deb Installer (ARM 64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-linux-arm64.deb)\n\nNote that you should use apt to install the package with `sudo apt install <file>` as other package managers, for example dpkg,\nare not able to resolve and install any dependency packages.\n\n### RHEL-based distros\n\nThe rpm releases are signed with the GPG key https://xpipe.io/signatures/crschnick.asc.\nYou can import it via `rpm --import https://xpipe.io/signatures/crschnick.asc` to allow your rpm-based package manager to verify the release signature. \n\nThe following rpm installers are available:\n\n- [Linux .rpm Installer (x86-64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-linux-x86_64.rpm)\n- [Linux .rpm Installer (ARM 64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-linux-arm64.rpm)\n\n### Arch\n\nThere is an official [AUR package](https://aur.archlinux.org/packages/xpipe) available that you can either install manually or via an AUR helper such as with `yay -S xpipe`.\n\n### AppImages\n\nAlternatively, there are also AppImages available. These can be useful if you are using an immutable distro.\n\n- [Linux .AppImage Portable (x86-64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-linux-x86_64.AppImage)\n- [Linux .AppImage Portable (ARM 64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-linux-arm64.AppImage)\n\n### NixOS\n\nThere's an official [xpipe nixpkg](https://search.nixos.org/packages?channel=unstable&show=xpipe&from=0&size=50&sort=relevance&type=packages&query=xpipe) available that you can install with `nix-env -iA nixos.xpipe` on x86_64 Linux systems. This package is however usually not up to date.\n\nThere is also a custom repository that contains the latest up-to-date release flakes for Linux and macOS systems: https://github.com/xpipe-io/nixpkg.\n\n### Tarball\n\nIn case you prefer to use an archive version that you can extract anywhere, you can use these:\n\n- [Linux .tar.gz Portable (x86-64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-linux-x86_64.tar.gz)\n- [Linux .tar.gz Portable (ARM 64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-linux-arm64.tar.gz)\n\n### Docker container\n\nXPipe is a desktop application first and foremost. It requires a full desktop environment to function with various installed applications such as terminals, editors, shells, CLI tools, and more. So there is no true web-based interface for XPipe.\n\nSince it might make sense however to access your XPipe environment from the web, there is also a so-called webtop docker container image for XPipe. [XPipe Webtop](https://github.com/xpipe-io/xpipe-webtop) is a web-based desktop environment that can be run in a container and accessed from a browser via KasmVNC. The desktop environment comes with XPipe and various terminals and editors preinstalled and configured. This image is also available for Kasm Workspaces in the [XPipe Kasm Registry](https://github.com/xpipe-io/kasm-registry).\n\n# Further information\n\n## Contributing\n\nSee [CONTRIBUTING.md](/CONTRIBUTING.md) for details.\n\n<img src=\"https://contrib.rocks/image?repo=xpipe-io/xpipe\" alt=\"contrib.rocks image\" />\n\n## Open source model\n\nXPipe follows an open core model, which essentially means that the main application is open source while certain other components are not. This mainly concerns the features only available in the homelab/professional plan and the shell handling library implementation. Furthermore, some CI pipelines and tests that run on private servers are also not included in the open repository.\n\nThe distributed XPipe application consists out of two parts:\n- The open-source core that you can find this repository. It is licensed under the [Apache License 2.0](/LICENSE.md).\n- The closed-source extensions, mostly for homelab/professional plan features, which are not included in this repository\n\nAdditional features are available in the homelab/professional plan. For more details see https://xpipe.io/pricing.\nIf your enterprise puts great emphasis on having access to the full source code, there are also full source-available enterprise options available.\n\n## Documentation\n\nYou can find the documentation at https://docs.xpipe.io.\n\n## Discord\n\n[![Discord](https://discordapp.com/api/guilds/979695018782646285/widget.png?style=banner2)](https://discord.gg/8y89vS8cRb)\n",
      "stars_today": 24
    },
    {
      "id": 1078137951,
      "name": "alt-sendme",
      "full_name": "tonyantony300/alt-sendme",
      "description": "Send files and folders anywhere in the world without storing in cloud - any size, any format, no accounts, no restrictions.",
      "html_url": "https://github.com/tonyantony300/alt-sendme",
      "stars": 4991,
      "forks": 273,
      "language": "TypeScript",
      "topics": [
        "blake3",
        "blip",
        "blip-alternative",
        "de-google",
        "dropbox-alternative",
        "encryption",
        "file-transfer",
        "hole-punching",
        "open-source",
        "p2p",
        "privacy",
        "quic",
        "resumable"
      ],
      "created_at": "2025-10-17T09:08:25Z",
      "updated_at": "2026-01-24T01:36:26Z",
      "pushed_at": "2026-01-22T16:54:44Z",
      "open_issues": 19,
      "owner": {
        "login": "tonyantony300",
        "avatar_url": "https://avatars.githubusercontent.com/u/54979586?v=4"
      },
      "readme": "<div align=\"center\">\n\n# File transfer doesn't need to be complicated\n\n</div>\n\n\n![AltSendme Header](assets/header.png)\n\n<div align=\"center\">\n\n![AltSendme working demo](assets/animation.gif)\n\n</div>\n\n<div align=\"center\">\n\n![Version][badge-version]\n![Website][badge-website]\n![Platforms][badge-platforms]\n[![Sponsor][badge-sponsor]](https://github.com/sponsors/tonyantony300)\n\n\n</div>\n\n\n\nA free and open-source file transfer tool that harnesses the power of [cutting-edge peer-to-peer networking](https://www.iroh.computer), letting you transfer files directly without storing them on cloud servers.\n\nWhy rely on WeTransfer, Dropbox, or Google Drive when you can reliably and easily transfer files directly, end-to-end encrypted and without revealing any personal information?\n\n\n## Features\n\n- **Send anywhere** ‚Äì Works seamlessly on local networks or across continents.\n- **Peer-to-peer direct transfer** ‚Äì Send files straight between devices, with no cloud storage in between.\n- **End-to-end encryption** ‚Äì Always-on protection with QUIC + TLS 1.3 for forward and backward secrecy.\n- **No accounts or personal info** ‚Äì Transfer files without sign-ups or exposing private data.\n- [**Transfer anything**](https://www.iroh.computer/proto/iroh-blobs) ‚Äì Send files or directories of any size or any format, verified with BLAKE3-based integrity checks.\n- **Resumable transfers** ‚Äì Interrupted downloads automatically resume where they left off.\n- **Fast & reliable** ‚Äì Capable of saturating multi-gigabit connections for lightning-fast transfers.\n- [**NAT traversal via QUIC**](https://www.iroh.computer/docs/faq#does-iroh-use-relay-servers) ‚Äì Secure, low-latency connections using QUIC hole punching with encrypted relay fallback.\n- **CLI integration** ‚Äì Interoperable with the [Sendme CLI](https://www.iroh.computer/sendme).\n- **Mobile & web** ‚Äì Coming soon.\n- **Free & open source** ‚Äì No upload costs, no size limits, and fully community-driven.\n\n\n\n## Installation\n\nThe easiest way to get started is by downloading one of the following versions for your respective operating system:\n\n<table>\n  <tr>\n    <td><b>Platform</b></td>\n    <td><b>Download</b></td>\n  </tr>\n  <tr>\n    <td><b>Windows</b></td>\n    <td><a href='https://github.com/tonyantony300/alt-sendme/releases/download/v0.2.4/AltSendme_0.2.4_x64-setup.exe'>AltSendme.exe</a></td>\n  </tr>\n  <tr>\n    <td><b>macOS</b></td>\n    <td><a href='https://github.com/tonyantony300/alt-sendme/releases/download/v0.2.4/AltSendme_0.2.4_universal.dmg'>AltSendme.dmg</a></td>\n  <tr>\n    <td><b>Linux </b></td>\n    <td><a href='https://github.com/tonyantony300/alt-sendme/releases/download/v0.2.4/AltSendme_0.2.4_amd64.deb'>AltSendme.deb</a></td>\n  </tr>\n</table>\n\n\nMore download options in [GitHub Releases](https://github.com/tonyantony300/alt-sendme/releases).\n\n\n## How it works \n\n1. Drop your file or folder - AltSendme creates a one-time share code (called a \"ticket\").\n2. ¬†Share the ticket via chat, email, or text.\n3. Your friend pastes the ticket in their app, and the transfer begins.\n\n\n## Under the hood ‚öôÔ∏èüõ†Ô∏è\n\nAltSendme uses [Iroh](https://www.iroh.computer) under the hood to enable peer-to-peer file transfer. It is a modern modular alternative to technologies like WebRTC and libp2p.\n\n### Important concepts \n\n- *Blobs*\n- *Tickets*\n- *Peer Discovery*\n- *Hole-punching* & *NAT traversal*\n- *QUIC* & *End-to-end encryption*\n- *Fallback Relays*\n\n\n### 1. Blobs\n\nContent-addressed blob storage and transfer. `iroh-blobs` implements request/response and streaming transfers of arbitrary-sized byte blobs, using BLAKE3-verified streams and content-addressed links.\n\n- Blob: an opaque sequence of bytes (no embedded metadata).\n- Link: a 32-byte BLAKE3 hash that identifies a blob.\n- HashSeq: a blob that contains a sequence of links (useful for chunking/trees).\n- Provider / Requester: provider serves data; requester fetches it. An endpoint can be both.\n\n### 2. Tickets\n\nTickets are a way to share dialing information between iroh endpoints. They're a single token that contains everything needed to connect to another endpoint, or to fetch a blob in this case. Contains Ed25519 NodeIds: Your device's cryptographic identity for authentication.They're also very powerful. It's worth pointing out this setup is considerably better than full peer-2-peer systems, which broadcast your IP to peers. Instead in iroh, tickets are used to form a \"cozy network\" between peers you explicitly want to connect with. It's possible to go \"full p2p\" & configure your app to broadcast dialing details, but tickets represent a better middle-ground default.\n\n\n### 3. Peer Discovery, NAT Traversal & Hole Punching\n\nPeers register with an open-source public relay servers at startup to help traverse firewalls and NATs, enabling connection setup. Once connected, Iroh uses QUIC hole punching to try and establish a direct peer-to-peer connection, bypassing the relay. If direct connection is possible, communication happens directly between peers with end-to-end encryption; otherwise, the relay operates only temporarily as a fallback. This enables smooth reliable connections between peers within local-network and across the internet.\n\n###  4. QUIC & Encryption\n\nQUIC is a modern transport protocol built on UDP, designed to reduce latency and improve web performance over TCP. Developed originally by Google and now standardized by the IETF as HTTP/3's foundation, it integrates TLS 1.3 encryption directly into the protocol.\n\nQUIC allows following super-powers:\n* encryption & authentication\n* stream multiplexing\n    * no head-of-line blocking issues\n    * stream priorities\n    * one shared congestion controller\n* an encrypted, unreliable datagram transport\n* zero round trip time connection establishment if you've connected to another endpoint before\n\n\n### 5. Relays\n\nAltSendme uses open-source public relay servers to support establishing direct connections, to speed up initial connection times, and to provide a fallback should direct connections between two endpoints fail or be impossible otherwise. All connections are end-to-end encrypted. The relay is ‚Äújust another UDP socket‚Äù for sending encrypted packets around.[Read more.](https://docs.iroh.computer/about/faq)\n\n\n## Contributing & Community ‚ù§Ô∏è\n\nWe‚Äôd love to meet you! Before diving into code or opening a PR, join our [Discord](https://discord.gg/xwb7z22Eve) to hang out, ask questions, and discuss ideas.\n\nIt‚Äôs the best place to get context, align on direction, and collaborate with the community.\n\n\n<!-- \n## Roadmap\n\n\nCheck out our [roadmap](https://github.com/users/tonyantony300/projects/4) to stay updated on recently released features and learn about what's coming next. -->\n\n\n\n\n## Supported Languages\n üá∫üá∏ üá∑üá∫ üá∑üá∏ üá´üá∑ üá®üá≥ üáπüáº üá©üá™ üáØüáµ üáπüá≠ üáÆüáπ üá®üáø üá™üá∏ üáßüá∑ üá∏üá¶ üáÆüá∑ üá∞üá∑ üáÆüá≥ üáµüá± üá∫üá¶ üáπüá∑ üá≥üá¥ üáßüá© üá™üáπ\n\n\n## Development Setup\n\n### Prerequisites\n\n- Rust 1.81+\n- Node.js 18+\n- npm or yarn\n\n### Getting Started\n\n1. **Fork and clone the repository**:\n   ```bash\n   git clone https://github.com/your-username/alt-sendme.git\n   cd alt-sendme\n   ```\n\n2. **Install frontend dependencies**:\n   ```bash\n   npm install\n   ```\n\n3. **Run in development mode**:\n   ```bash\n   npm run app:dev\n   ```\n\n4. **Build for production** (optional):\n   ```bash\n   npm run app:build --no-bundle\n   ```\n\n\n## License\n\nAGPL-3.0\n\n## Privacy Policy\n\nSee [PRIVACY.md](PRIVACY.md) for information about how AltSendme handles your data and privacy.\n\n[![Sponsor](https://img.shields.io/badge/sponsor-30363D?style=for-the-badge&logo=GitHub-Sponsors&logoColor=#EA4AAA)](https://github.com/sponsors/tonyantony300) [![Buy Me Coffee](https://img.shields.io/badge/Buy%20Me%20Coffee-FF5A5F?style=for-the-badge&logo=coffee&logoColor=FFFFFF)](https://buymeacoffee.com/tny_antny)\n\n\n## Contributors\n\n<a href=\"https://github.com/tonyantony300/alt-sendme/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=tonyantony300/alt-sendme\" />\n</a>\n\n\n## Acknowledgements\n\n\n- [Iroh](https://www.iroh.computer)\n- [Tauri](https://v2.tauri.app)\n\n\n## Contact\n\nReach me [here](https://www.altsendme.com/en/contact) for suggestions, feedback or media related communication.\n\n\nThank you for checking out this project! If you find it useful, consider giving it a star and helping spread the word.\n\n\n\n\n<!-- <div align=\"center\" style=\"color: gray;\"></div> -->\n\n[badge-website]: https://img.shields.io/badge/website-altsendme.com-orange\n[badge-version]: https://img.shields.io/badge/version-0.2.4-blue\n[badge-platforms]: https://img.shields.io/badge/platforms-macOS%2C%20Windows%2C%20Linux%2C%20-green\n[badge-sponsor]: https://img.shields.io/badge/sponsor-ff69b4\n\n\n",
      "stars_today": 24
    },
    {
      "id": 120425779,
      "name": "lapce",
      "full_name": "lapce/lapce",
      "description": "Lightning-fast and Powerful Code Editor written in Rust",
      "html_url": "https://github.com/lapce/lapce",
      "stars": 37958,
      "forks": 1223,
      "language": "Rust",
      "topics": [
        "code-editor",
        "developer-tools",
        "rust",
        "text-editor",
        "vim"
      ],
      "created_at": "2018-02-06T08:41:06Z",
      "updated_at": "2026-01-24T01:41:22Z",
      "pushed_at": "2026-01-24T00:49:15Z",
      "open_issues": 870,
      "owner": {
        "login": "lapce",
        "avatar_url": "https://avatars.githubusercontent.com/u/43668847?v=4"
      },
      "readme": "<h1 align=\"center\">\n  <a href=\"https://lapce.dev\" target=\"_blank\">\n  <img src=\"extra/images/logo.png\" width=200 height=200/><br>\n  Lapce\n  </a>\n</h1>\n\n<h4 align=\"center\">Lightning-fast And Powerful Code Editor</h4>\n\n<div align=\"center\">\n  <a href=\"https://github.com/lapce/lapce/actions/workflows/ci.yml\" target=\"_blank\">\n    <img src=\"https://github.com/lapce/lapce/actions/workflows/ci.yml/badge.svg\" />\n  </a>\n  <a href=\"https://discord.gg/n8tGJ6Rn6D\" target=\"_blank\">\n    <img src=\"https://img.shields.io/discord/946858761413328946?logo=discord\" />\n  </a>\n  <a href=\"https://docs.lapce.dev\" target=\"_blank\">\n      <img src=\"https://img.shields.io/static/v1?label=Docs&message=docs.lapce.dev&color=blue\" alt=\"Lapce Docs\">\n  </a>\n</div>\n<br/>\n\n\nLapce (IPA: /l√¶ps/) is written in pure Rust, with a UI in [Floem](https://github.com/lapce/floem). It is designed with [Rope Science](https://xi-editor.io/docs/rope_science_00.html) from the [Xi-Editor](https://github.com/xi-editor/xi-editor), enabling lightning-fast computation, and leverages [wgpu](https://github.com/gfx-rs/wgpu) for rendering. More information about the features of Lapce can be found on the [main website](https://lapce.dev) and user documentation can be found on [GitBook](https://docs.lapce.dev/).\n\n![](https://github.com/lapce/lapce/blob/master/extra/images/screenshot.png?raw=true)\n\n## Features\n\n* Built-in LSP ([Language Server Protocol](https://microsoft.github.io/language-server-protocol/)) support to give you intelligent code features such as: completion, diagnostics and code actions\n* Modal editing support as first class citizen (Vim-like, and toggleable)\n* Built-in remote development support inspired by [VSCode Remote Development](https://code.visualstudio.com/docs/remote/remote-overview). Enjoy the benefits of a \"local\" experience, and seamlessly gain the full power of a remote system. We also have [Lapdev](https://lap.dev/) which can help manage your remote dev environments. \n* Plugins can be written in programming languages that can compile to the [WASI](https://wasi.dev/) format (C, Rust, [AssemblyScript](https://www.assemblyscript.org/))\n* Built-in terminal, so you can execute commands in your workspace, without leaving Lapce.\n\n## Installation\n\nYou can find pre-built releases for Windows, Linux and macOS [here](https://github.com/lapce/lapce/releases), or [installing with a package manager](docs/installing-with-package-manager.md).\nIf you'd like to compile from source, you can find the [guide](docs/building-from-source.md).\n\n## Contributing\n\n<a href=\"https://ws.lap.dev/#https://github.com/lapce/lapce\" target=\"_blank\">\n      <img src=\"https://lap.dev/images/open-in-lapdev.svg?version=8\" alt=\"Open in Lapdev\">\n</a>\n\n[Lapdev](https://lap.dev/), developed by the Lapce team, is a cloud dev env service similar to GitHub Codespaces. By clicking the button above, you'll be taken to a fully set up Lapce dev env where you can browse the code and start developing. All dependencies are pre-installed, so you can get straight to code.\n\nGuidelines for contributing to Lapce can be found in [`CONTRIBUTING.md`](CONTRIBUTING.md).\n\n## Feedback & Contact\n\nThe most popular place for Lapce developers and users is on the [Discord server](https://discord.gg/n8tGJ6Rn6D).\n\nOr, join the discussion on [Reddit](https://www.reddit.com/r/lapce/) where we are just getting started.\n\nThere is also a [Matrix Space](https://matrix.to/#/#lapce-editor:matrix.org), which is linked to the content from the Discord server.\n\n## License\n\nLapce is released under the Apache License Version 2, which is an open source license. You may contribute to this project, or use the code as you please as long as you adhere to its conditions. You can find a copy of the license text here: [`LICENSE`](LICENSE).\n",
      "stars_today": 23
    },
    {
      "id": 671654508,
      "name": "biome",
      "full_name": "biomejs/biome",
      "description": "A toolchain for web projects, aimed to provide functionalities to maintain them. Biome offers formatter and linter, usable via CLI and LSP.",
      "html_url": "https://github.com/biomejs/biome",
      "stars": 23283,
      "forks": 827,
      "language": "Rust",
      "topics": [
        "css",
        "formatter",
        "javascript",
        "json",
        "jsx",
        "linter",
        "static-code-analysis",
        "typescript",
        "web"
      ],
      "created_at": "2023-07-27T20:30:22Z",
      "updated_at": "2026-01-23T23:08:40Z",
      "pushed_at": "2026-01-23T22:40:17Z",
      "open_issues": 498,
      "owner": {
        "login": "biomejs",
        "avatar_url": "https://avatars.githubusercontent.com/u/140182603?v=4"
      },
      "readme": "<div align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/biomejs/resources/main/svg/slogan-dark-transparent.svg\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://raw.githubusercontent.com/biomejs/resources/main/svg/slogan-light-transparent.svg\">\n    <img alt=\"Shows the banner of Biome, with its logo and the phrase 'Biome - Toolchain of the web'.\" src=\"https://raw.githubusercontent.com/biomejs/resources/main/svg/slogan-light-transparent.svg\" width=\"700\">\n  </picture>\n\n  <br>\n  <br>\n\n  [![CI on main][ci-badge]][ci-url]\n  [![Discord chat][discord-badge]][discord-url]\n  [![npm version][npm-badge]][npm-url]\n  [![VSCode version][vscode-badge]][vscode-url]\n  [![Open VSX version][open-vsx-badge]][open-vsx-url]\n\n  [ci-badge]: https://github.com/biomejs/biome/actions/workflows/main.yml/badge.svg\n  [ci-url]: https://github.com/biomejs/biome/actions/workflows/main.yml\n  [discord-badge]: https://badgen.net/discord/online-members/BypW39g6Yc?icon=discord&label=discord&color=60a5fa\n  [discord-url]: https://biomejs.dev/chat\n  [npm-badge]: https://badgen.net/npm/v/@biomejs/biome?icon=npm&color=60a5fa&label=%40biomejs%2Fbiome\n  [npm-url]: https://www.npmjs.com/package/@biomejs/biome/v/latest\n  [vscode-badge]: https://img.shields.io/visual-studio-marketplace/v/biomejs.biome?label=Visual%20Studio%20Marketplace&labelColor=374151&color=60a5fa\n  [vscode-url]: https://marketplace.visualstudio.com/items?itemName=biomejs.biome\n  [open-vsx-badge]: https://img.shields.io/visual-studio-marketplace/v/biomejs.biome?label=Open%20VSX%20Registry&logo=data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4KPHN2ZyB2aWV3Qm94PSI0LjYgNSA5Ni4yIDEyMi43IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogIDxwYXRoIGQ9Ik0zMCA0NC4yTDUyLjYgNUg3LjN6TTQuNiA4OC41aDQ1LjNMMjcuMiA0OS40em01MSAwbDIyLjYgMzkuMiAyMi42LTM5LjJ6IiBmaWxsPSIjYzE2MGVmIi8+CiAgPHBhdGggZD0iTTUyLjYgNUwzMCA0NC4yaDQ1LjJ6TTI3LjIgNDkuNGwyMi43IDM5LjEgMjIuNi0zOS4xem01MSAwTDU1LjYgODguNWg0NS4yeiIgZmlsbD0iI2E2MGVlNSIvPgo8L3N2Zz4=&labelColor=374151&color=60a5fa\n  [open-vsx-url]: https://open-vsx.org/extension/biomejs/biome\n\n<!-- Insert new entries lexicographically by language code.\n     For example given below is the same order as these files appear on page:\n     https://github.com/biomejs/biome/tree/main/packages/@biomejs/biome -->\n\n  [‡§π‡§ø‡§®‡•ç‡§¶‡•Ä](https://github.com/biomejs/biome/blob/main/packages/%40biomejs/biome/README.hi.md) | English | [Espa√±ol](https://github.com/biomejs/biome/blob/main/packages/%40biomejs/biome/README.es.md) | [Fran√ßais](https://github.com/biomejs/biome/blob/main/packages/%40biomejs/biome/README.fr.md) | [ÁπÅÈ´î‰∏≠Êñá](https://github.com/biomejs/biome/blob/main/packages/%40biomejs/biome/README.zh-TW.md) | [ÁÆÄ‰Ωì‰∏≠Êñá](https://github.com/biomejs/biome/blob/main/packages/%40biomejs/biome/README.zh-CN.md) | [Êó•Êú¨Ë™û](https://github.com/biomejs/biome/blob/main/packages/%40biomejs/biome/README.ja.md) | [Polski](https://github.com/biomejs/biome/blob/main/packages/%40biomejs/biome/README.pl.md) | [Portugu√™s do Brasil](https://github.com/biomejs/biome/blob/main/packages/%40biomejs/biome/README.pt-BR.md) | [ÌïúÍµ≠Ïñ¥](https://github.com/biomejs/biome/blob/main/packages/%40biomejs/biome/README.kr.md) | [–†—É—Å—Å–∫–∏–π](https://github.com/biomejs/biome/blob/main/packages/%40biomejs/biome/README.ru.md) | [–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞](https://github.com/biomejs/biome/blob/main/packages/%40biomejs/biome/README.uk.md)\n</div>\n\n<br>\n\n**Biome** is a performant toolchain for web projects, it aims to provide developer tools to maintain the health of said projects.\n\n**Biome is a [fast formatter](./benchmark#formatting)** for _JavaScript_, _TypeScript_, _JSX_, _JSON_, _CSS_ and _GraphQL_ that scores **[97% compatibility with _Prettier_](https://console.algora.io/challenges/prettier)**.\n\n**Biome is a [performant linter](https://github.com/biomejs/biome/tree/main/benchmark#linting)** for _JavaScript_, _TypeScript_, _JSX_, _JSON_, _CSS_, and _GraphQL_ that features **[more than 340 rules](https://biomejs.dev/linter/javascript/rules/)** from ESLint, typescript-eslint, and [other sources](https://github.com/biomejs/biome/discussions/3).\nIt **outputs detailed and contextualized diagnostics** that help you to improve your code and become a better programmer!\n\n**Biome** is designed from the start to be used [interactively within an editor](https://biomejs.dev/guides/editors/first-party-extensions/).\nIt can format and lint malformed code as you are writing it.\n\n### Installation\n\n```shell\nnpm install --save-dev --save-exact @biomejs/biome\n```\n\n### Usage\n\n```shell\n# format files\nnpx @biomejs/biome format --write\n\n# lint files and apply the safe fixes\nnpx @biomejs/biome lint --write\n\n# run format, lint, etc. and apply the safe fixes\nnpx @biomejs/biome check --write\n\n# check all files against format, lint, etc. in CI environments\nnpx @biomejs/biome ci\n```\n\nIf you want to give Biome a run without installing it, use the [online playground](https://biomejs.dev/playground/), compiled to WebAssembly.\n\n## Documentation\n\nCheck out our [homepage][biomejs] to learn more about Biome,\nor directly head to the [Getting Started guide][getting-started] to start using Biome.\n\n## More about Biome\n\n**Biome** has sane defaults and it doesn't require configuration.\n\n**Biome** aims to support [all main languages][language-support] of modern web development.\n\n**Biome** [doesn't require Node.js](https://biomejs.dev/guides/manual-installation/) to function.\n\n**Biome** has first-class LSP support, with a sophisticated parser that represents the source text in full fidelity and top-notch error recovery.\n\n**Biome** wants to offer a high-quality *Developer Experience*, with descriptive diagnostics and great performance.\n\n**Biome** unifies functionalities that have previously been separate tools. Building upon a shared base allows us to provide a cohesive experience for processing code, displaying errors, parallelize work, caching, and configuration.\n\nRead more about our [project philosophy][biome-philosophy].\n\n**Biome** is [MIT licensed](https://github.com/biomejs/biome/tree/main/LICENSE-MIT) or [Apache 2.0 licensed](https://github.com/biomejs/biome/tree/main/LICENSE-APACHE) and moderated under the [Contributor Covenant Code of Conduct](https://github.com/biomejs/biome/tree/main/CODE_OF_CONDUCT.md).\n\n## Funding\n\nYou can fund the project in different ways\n\n### Project sponsorship and funding\n\nYou can sponsor or fund the project via [Open collective](https://opencollective.com/biome) or [GitHub sponsors](https://github.com/sponsors/biomejs)\n\nBiome offers a simple sponsorship program that allows companies to get visibility and recognition among various developers.\n\nBiome offers [enterprise support](https://biomejs.dev/enterprise), where Core Contributors can be employed to work on company-focused projects.\n\n## Sponsors\n\n### Platinum Sponsors\n\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://depot.dev/?utm_source=biome&utm_medium=readme\" target=\"_blank\">\n          <picture>\n            <source media=\"(prefers-color-scheme: light)\" srcset=\"https://depot.dev/assets/brand/1693758816/depot-logo-horizontal-on-light@3x.png\" />\n            <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://depot.dev/assets/brand/1693758816/depot-logo-horizontal-on-dark@3x.png\" />\n            <img src=\"https://depot.dev/assets/brand/1693758816/depot-logo-horizontal-on-light@3x.png\" width=\"600\" alt=\"Depot logo\" />\n          </picture>\n        </a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n### Silver Sponsors\n\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://l2beat.com/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://images.opencollective.com/l2beat/c2b2a27/logo/256.png\" height=\"100\" alt=\"L2BEAT logo\"></a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://lokalise.com/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/14294501?s=200&v=4\" height=\"100\" alt=\"Lokalise logo\"></a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n### Bronze Sponsors\n\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://vital.io/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/25357309?s=200\" width=\"80\" alt=\"Vital logo\"></a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://coderabbit.ai/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/132028505?s=200&v=4\" width=\"80\" alt=\"CodeRabbit logo\"></a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://forge42.dev/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/161314831?s=200&v=4\" width=\"80\" alt=\"Forge42 logo\"></a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"http://rstudio.org/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/513560?s=200&v=4\" width=\"80\" alt=\"RStudio logo\"></a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://pennylane.com/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/57875210?s=200&v=4\" width=\"80\" alt=\"Pennylane logo\"></a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://jetbrains.com/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.png\" width=\"100\" alt=\"JetBrains logo\"></a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.egstock.co.jp/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://images.opencollective.com/egstock/b18c836/logo/256.png?height=256\" width=\"80\" alt=\"EGSTOCK, Inc. logo\"></a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.convex.dev/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/81530787?s=200&v=4\" width=\"80\" alt=\"Convex logo\"></a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://graphite.dev/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/61942612?s=200&v=4\" width=\"80\" alt=\"Graphite logo\"></a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://kraken.tech/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/105941848?s=200&v=4\" width=\"80\" alt=\"Kraken Tech logo\"></a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n[biomejs]: https://biomejs.dev/\n[biome-philosophy]: https://biomejs.dev/internals/philosophy/\n[language-support]: https://biomejs.dev/internals/language-support/\n[getting-started]: https://biomejs.dev/guides/getting-started/\n",
      "stars_today": 23
    },
    {
      "id": 130464961,
      "name": "bat",
      "full_name": "sharkdp/bat",
      "description": "A cat(1) clone with wings.",
      "html_url": "https://github.com/sharkdp/bat",
      "stars": 56781,
      "forks": 1441,
      "language": "Rust",
      "topics": [
        "cli",
        "command-line",
        "git",
        "hacktoberfest",
        "rust",
        "syntax-highlighting",
        "terminal",
        "tool"
      ],
      "created_at": "2018-04-21T10:52:23Z",
      "updated_at": "2026-01-23T23:54:37Z",
      "pushed_at": "2026-01-15T20:13:42Z",
      "open_issues": 339,
      "owner": {
        "login": "sharkdp",
        "avatar_url": "https://avatars.githubusercontent.com/u/4209276?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"doc/logo-header.svg\" alt=\"bat - a cat clone with wings\"><br>\n  <a href=\"https://github.com/sharkdp/bat/actions?query=workflow%3ACICD\"><img src=\"https://github.com/sharkdp/bat/workflows/CICD/badge.svg\" alt=\"Build Status\"></a>\n  <img src=\"https://img.shields.io/crates/l/bat.svg\" alt=\"license\">\n  <a href=\"https://crates.io/crates/bat\"><img src=\"https://img.shields.io/crates/v/bat.svg?colorB=319e8c\" alt=\"Version info\"></a><br>\n  A <i>cat(1)</i> clone with syntax highlighting and Git integration.\n</p>\n\n<p align=\"center\">\n  <a href=\"#syntax-highlighting\">Key Features</a> ‚Ä¢\n  <a href=\"#how-to-use\">How To Use</a> ‚Ä¢\n  <a href=\"#installation\">Installation</a> ‚Ä¢\n  <a href=\"#customization\">Customization</a> ‚Ä¢\n  <a href=\"#project-goals-and-alternatives\">Project goals, alternatives</a><br>\n  [English]\n  [<a href=\"doc/README-zh.md\">‰∏≠Êñá</a>]\n  [<a href=\"doc/README-ja.md\">Êó•Êú¨Ë™û</a>]\n  [<a href=\"doc/README-ko.md\">ÌïúÍµ≠Ïñ¥</a>]\n  [<a href=\"doc/README-ru.md\">–†—É—Å—Å–∫–∏–π</a>]\n</p>\n\n### Sponsors\n\nA special *thank you* goes to our biggest <a href=\"doc/sponsors.md\">sponsors</a>:<br>\n\n<p>\n<a href=\"https://www.warp.dev/bat\">\n  <img src=\"doc/sponsors/warp-logo.png\" width=\"200\" alt=\"Warp\">\n  <br>\n  <strong>Warp, the intelligent terminal</strong>\n  <br>\n  <sub>Available on MacOS, Linux, Windows</sub>\n</a>\n</p>\n\n### Syntax highlighting\n\n`bat` supports syntax highlighting for a large number of programming and markup\nlanguages:\n\n![Syntax highlighting example](https://imgur.com/rGsdnDe.png)\n\n### Git integration\n\n`bat` communicates with `git` to show modifications with respect to the index\n(see left side bar):\n\n![Git integration example](https://i.imgur.com/2lSW4RE.png)\n\n### Show non-printable characters\n\nYou can use the `-A`/`--show-all` option to show and highlight non-printable\ncharacters:\n\n![Non-printable character example](https://i.imgur.com/WndGp9H.png)\n\n### Automatic paging\n\nBy default, `bat` pipes its own output to a pager (e.g. `less`) if the output is too large for one screen.\nIf you would rather `bat` work like `cat` all the time (never page output), you can set `--paging=never` as an option, either on the command line or in your configuration file.\nIf you intend to alias `cat` to `bat` in your shell configuration, you can use `alias cat='bat --paging=never'` to preserve the default behavior.\n\n#### File concatenation\n\nEven with a pager set, you can still use `bat` to concatenate files :wink:.\nWhenever `bat` detects a non-interactive terminal (i.e. when you pipe into another process or into a file), `bat` will act as a drop-in replacement for `cat` and fall back to printing the plain file contents, regardless of the `--pager` option's value.\n\n## How to use\n\nDisplay a single file on the terminal\n\n```bash\nbat README.md\n```\n\nDisplay multiple files at once\n\n```bash\nbat src/*.rs\n```\n\nRead from stdin, determine the syntax automatically (note, highlighting will\nonly work if the syntax can be determined from the first line of the file,\nusually through a shebang such as `#!/bin/sh`)\n\n```bash\ncurl -s https://sh.rustup.rs | bat\n```\n\nRead from stdin, specify the language explicitly\n\n```bash\nyaml2json .travis.yml | json_pp | bat -l json\n```\n\nShow and highlight non-printable characters:\n```bash\nbat -A /etc/hosts\n```\n\nUse it as a `cat` replacement:\n\n```bash\nbat > note.md  # quickly create a new file\n\nbat header.md content.md footer.md > document.md\n\nbat -n main.rs  # show line numbers (only)\n\nbat f - g  # output 'f', then stdin, then 'g'.\n```\n\n### Integration with other tools\n\n#### `fzf`\n\nYou can use `bat` as a previewer for [`fzf`](https://github.com/junegunn/fzf). To do this,\nuse `bat`'s `--color=always` option to force colorized output. You can also use `--line-range`\noption to restrict the load times for long files:\n\n```bash\nfzf --preview \"bat --color=always --style=numbers --line-range=:500 {}\"\n```\n\nFor more information, see [`fzf`'s `README`](https://github.com/junegunn/fzf#preview-window).\n\n#### `find` or `fd`\n\nYou can use the `-exec` option of `find` to preview all search results with `bat`:\n\n```bash\nfind ‚Ä¶ -exec bat {} +\n```\n\nIf you happen to use [`fd`](https://github.com/sharkdp/fd), you can use the `-X`/`--exec-batch` option to do the same:\n\n```bash\nfd ‚Ä¶ -X bat\n```\n\n#### `ripgrep`\n\nWith [`batgrep`](https://github.com/eth-p/bat-extras/blob/master/doc/batgrep.md), `bat` can be used as the printer for [`ripgrep`](https://github.com/BurntSushi/ripgrep) search results.\n\n```bash\nbatgrep needle src/\n```\n\n#### `tail -f`\n\n`bat` can be combined with `tail -f` to continuously monitor a given file with syntax highlighting.\n\n```bash\ntail -f /var/log/pacman.log | bat --paging=never -l log\n```\n\nNote that we have to switch off paging in order for this to work. We have also specified the syntax\nexplicitly (`-l log`), as it can not be auto-detected in this case.\n\n#### `git`\n\nYou can combine `bat` with `git show` to view an older version of a given file with proper syntax\nhighlighting:\n\n```bash\ngit show v0.6.0:src/main.rs | bat -l rs\n```\n\n#### `git diff`\n\nYou can combine `bat` with `git diff` to view lines around code changes with proper syntax\nhighlighting:\n```bash\nbatdiff() {\n    git diff --name-only --relative --diff-filter=d -z | xargs -0 bat --diff\n}\n```\nIf you prefer to use this as a separate tool, check out `batdiff` in [`bat-extras`](https://github.com/eth-p/bat-extras).\n\nIf you are looking for more support for git and diff operations, check out [`delta`](https://github.com/dandavison/delta).\n\n#### `xclip`\n\nThe line numbers and Git modification markers in the output of `bat` can make it hard to copy\nthe contents of a file. To prevent this, you can call `bat` with the `-p`/`--plain` option or\nsimply pipe the output into `xclip`:\n```bash\nbat main.cpp | xclip\n```\n`bat` will detect that the output is being redirected and print the plain file contents.\n\n#### `man`\n\n`bat` can be used as a colorizing pager for `man`, by setting the\n`MANPAGER` environment variable:\n\n```bash\nexport MANPAGER=\"bat -plman\"\nman 2 select\n```\n(replace `bat` with `batcat` if you are on Debian or Ubuntu)\n\nIf you prefer to have this bundled in a new command, you can also use [`batman`](https://github.com/eth-p/bat-extras/blob/master/doc/batman.md).\n\nNote that the [Manpage syntax](assets/syntaxes/02_Extra/Manpage.sublime-syntax) is developed in this repository and still needs some work.\n\n#### `prettier` / `shfmt` / `rustfmt`\n\nThe [`prettybat`](https://github.com/eth-p/bat-extras/blob/master/doc/prettybat.md) script is a wrapper that will format code and print it with `bat`.\n\n#### `Warp`\n\n<a href=\"https://app.warp.dev/drive/folder/-Bat-Warp-Pack-lxhe7HrEwgwpG17mvrFSz1\">\n  <img src=\"doc/sponsors/warp-pack-header.png\" alt=\"Warp\">\n</a>\n\n#### Highlighting `--help` messages\n\nYou can use `bat` to colorize help text: `$ cp --help | bat -plhelp`\n\nYou can also use a wrapper around this:\n\n```bash\n# in your .bashrc/.zshrc/*rc\nalias bathelp='bat --plain --language=help'\nhelp() {\n    \"$@\" --help 2>&1 | bathelp\n}\n```\n\nThen you can do `$ help cp` or `$ help git commit`.\n\nWhen you are using `zsh`, you can also use global aliases to override `-h` and `--help` entirely:\n\n```bash\nalias -g -- -h='-h 2>&1 | bat --language=help --style=plain'\nalias -g -- --help='--help 2>&1 | bat --language=help --style=plain'\n```\n\nFor `fish`, you can use abbreviations:\n\n```fish\nabbr -a --position anywhere -- --help '--help | bat -plhelp'\nabbr -a --position anywhere -- -h '-h | bat -plhelp'\n```\n\nThis way, you can keep on using `cp --help`, but get colorized help pages.\n\nBe aware that in some cases, `-h` may not be a shorthand of `--help` (for example with `ls`). In cases where you need to use `-h` \nas a command argument you can prepend `\\` to the argument (eg. `ls \\-h`) to escape the aliasing defined above. \n\nPlease report any issues with the help syntax in [this repository](https://github.com/victor-gp/cmd-help-sublime-syntax).\n\n\n## Installation\n\n<!--\n\nInstallation instructions need to:\n* be for widely used systems\n* be non-obvious\n* be from somewhat official sources\n\n-->\n\n[![Packaging status](https://repology.org/badge/vertical-allrepos/bat-cat.svg?columns=3&exclude_unsupported=1)](https://repology.org/project/bat-cat/versions)\n\n### On Ubuntu (using `apt`)\n*... and other Debian-based Linux distributions.*\n\n`bat` is available on [Ubuntu since 20.04 (\"Focal\")](https://packages.ubuntu.com/search?keywords=bat&exact=1) and [Debian since August 2021 (Debian 11 - \"Bullseye\")](https://packages.debian.org/bullseye/bat).\n\nIf your Ubuntu/Debian installation is new enough you can simply run:\n\n```bash\nsudo apt install bat\n```\n\n**Important**: If you install `bat` this way, please note that the executable may be installed as `batcat` instead of `bat` (due to [a name\nclash with another package](https://github.com/sharkdp/bat/issues/982)). You can set up a `bat -> batcat` symlink or alias to prevent any issues that may come up because of this and to be consistent with other distributions:\n``` bash\nmkdir -p ~/.local/bin\nln -s /usr/bin/batcat ~/.local/bin/bat\n```\n\nan example alias for `batcat` as `bat`:\n```bash\nalias bat=\"batcat\"\n```\n\n### On Ubuntu (using most recent `.deb` packages)\n*... and other Debian-based Linux distributions.*\n\nIf the package has not yet been promoted to your Ubuntu/Debian installation, or you want\nthe most recent release of `bat`, download the latest `.deb` package from the\n[release page](https://github.com/sharkdp/bat/releases) and install it via:\n\n```bash\nsudo dpkg -i bat_0.18.3_amd64.deb  # adapt version number and architecture\n```\n\n### On Alpine Linux\n\nYou can install [the `bat` package](https://pkgs.alpinelinux.org/packages?name=bat)\nfrom the official sources, provided you have the appropriate repository enabled:\n\n```bash\napk add bat\n```\n\n### On Arch Linux\n\nYou can install [the `bat` package](https://www.archlinux.org/packages/extra/x86_64/bat/)\nfrom the official sources:\n\n```bash\npacman -S bat\n```\n\n### On Fedora\n\nYou can install [the `bat` package](https://koji.fedoraproject.org/koji/packageinfo?packageID=27506) from the official [Fedora Modular](https://docs.fedoraproject.org/en-US/modularity/using-modules/) repository.\n\n```bash\ndnf install bat\n```\n\n### On Gentoo Linux\n\nYou can install [the `bat` package](https://packages.gentoo.org/packages/sys-apps/bat)\nfrom the official sources:\n\n```bash\nemerge sys-apps/bat\n```\n\n### On FreeBSD\n\nYou can install a precompiled [`bat` package](https://www.freshports.org/textproc/bat) with pkg:\n\n```bash\npkg install bat\n```\n\nor build it on your own from the FreeBSD ports:\n\n```bash\ncd /usr/ports/textproc/bat\nmake install\n```\n\n### On OpenBSD\n\nYou can install `bat` package using [`pkg_add(1)`](https://man.openbsd.org/pkg_add.1):\n\n```bash\npkg_add bat\n```\n\n### Via nix\n\nYou can install `bat` using the [nix package manager](https://nixos.org/nix):\n\n```bash\nnix-env -i bat\n```\n\n### On openSUSE\n\nYou can install `bat` with zypper:\n\n```bash\nzypper install bat\n```\n\n### Via snap package\n\nThere is currently no recommended snap package available.\nExisting packages may be available, but are not officially supported and may contain [issues](https://github.com/sharkdp/bat/issues/1519).\n\n### On macOS (or Linux) via Homebrew\n\nYou can install `bat` with [Homebrew](https://formulae.brew.sh/formula/bat):\n\n```bash\nbrew install bat\n```\n\n### On macOS via MacPorts\n\nOr install `bat` with [MacPorts](https://ports.macports.org/port/bat/summary):\n\n```bash\nport install bat\n```\n\n### On Windows\n\nThere are a few options to install `bat` on Windows. Once you have installed `bat`,\ntake a look at the [\"Using `bat` on Windows\"](#using-bat-on-windows) section.\n\n#### Prerequisites\n\nYou will need to install the [Visual C++ Redistributable](https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist#latest-microsoft-visual-c-redistributable-version)\n\n#### With WinGet\n\nYou can install `bat` via [WinGet](https://learn.microsoft.com/en-us/windows/package-manager/winget):\n\n```bash\nwinget install sharkdp.bat\n```\n\n#### With Chocolatey\n\nYou can install `bat` via [Chocolatey](https://chocolatey.org/packages/Bat):\n```bash\nchoco install bat\n```\n\n#### With Scoop\n\nYou can install `bat` via [scoop](https://scoop.sh/):\n```bash\nscoop install bat\n```\n\n#### From prebuilt binaries:\n\nYou can download prebuilt binaries from the [Release page](https://github.com/sharkdp/bat/releases),\n\nYou will need to install the [Visual C++ Redistributable](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads) package.\n\n### From binaries\n\nCheck out the [Release page](https://github.com/sharkdp/bat/releases) for\nprebuilt versions of `bat` for many different architectures. Statically-linked\nbinaries are also available: look for archives with `musl` in the file name.\n\n### From source\n\nIf you want to build `bat` from source, you need Rust 1.79.0 or\nhigher. You can then use `cargo` to build everything:\n\n#### From local source\n```bash\ncargo install --path . --locked\n```\n> [!NOTE]\n> The `--path .` above specifies the directory of the source code and NOT where `bat` will be installed.\n> For more information see the docs for [`cargo install`](https://doc.rust-lang.org/cargo/commands/cargo-install.html).\n\n#### From `crates.io`\n```bash\ncargo install --locked bat\n```\n\nNote that additional files like the man page or shell completion\nfiles can not be installed automatically in both these ways.\nIf installing from a local source, they will be generated by `cargo`\nand should be available in the cargo target folder under `build`.\n\nFurthermore, shell completions are also available by running:\n```bash\nbat --completion <shell>\n# see --help for supported shells\n```\n\n## Customization\n\n### Highlighting theme\n\nUse `bat --list-themes` to get a list of all available themes for syntax\nhighlighting. By default, `bat` uses `Monokai Extended` or `Monokai Extended Light`\nfor dark and light themes respectively. To select the `TwoDark` theme, call `bat`\nwith the `--theme=TwoDark` option or set the `BAT_THEME` environment variable to\n`TwoDark`. Use `export BAT_THEME=\"TwoDark\"` in your shell's startup file to\nmake the change permanent. Alternatively, use `bat`'s\n[configuration file](#configuration-file).\n\nIf you want to preview the different themes on a custom file, you can use\nthe following command (you need [`fzf`](https://github.com/junegunn/fzf) for this):\n```bash\nbat --list-themes | fzf --preview=\"bat --theme={} --color=always /path/to/file\"\n```\n\n`bat` automatically picks a fitting theme depending on your terminal's background color.\nYou can use the `--theme-dark` / `--theme-light` options or the `BAT_THEME_DARK` / `BAT_THEME_LIGHT` environment variables\nto customize the themes used. This is especially useful if you frequently switch between dark and light mode.\n\nYou can also use a custom theme by following the\n['Adding new themes' section below](#adding-new-themes).\n\n### 8-bit themes\n\n`bat` has three themes that always use [8-bit colors](https://en.wikipedia.org/wiki/ANSI_escape_code#Colors),\neven when truecolor support is available:\n\n- `ansi` looks decent on any terminal. It uses 3-bit colors: black, red, green,\n  yellow, blue, magenta, cyan, and white.\n- `base16` is designed for [base16](https://github.com/tinted-theming/home) terminal themes. It uses\n  4-bit colors (3-bit colors plus bright variants) in accordance with the\n  [base16 styling guidelines](https://github.com/tinted-theming/home/blob/main/styling.md).\n- `base16-256` is designed for [tinted-shell](https://github.com/tinted-theming/tinted-shell).\n  It replaces certain bright colors with 8-bit colors from 16 to 21. **Do not** use this simply\n  because you have a 256-color terminal but are not using tinted-shell.\n\nAlthough these themes are more restricted, they have three advantages over truecolor themes. They:\n\n- Enjoy maximum compatibility. Some terminal utilities do not support more than 3-bit colors.\n- Adapt to terminal theme changes. Even for already printed output.\n- Visually harmonize better with other terminal software.\n\n### Output style\n\nYou can use the `--style` option to control the appearance of `bat`'s output.\nYou can use `--style=numbers,changes`, for example, to show only Git changes\nand line numbers but no grid and no file header. Set the `BAT_STYLE` environment\nvariable to make these changes permanent or use `bat`'s\n[configuration file](#configuration-file).\n\n>[!tip]\n> If you specify a default style in `bat`'s config file, you can change which components\n> are displayed during a single run of `bat` using the `--style` command-line argument.\n> By prefixing a component with `+` or `-`, it can be added or removed from the current style.\n>\n> For example, if your config contains `--style=full,-snip`, you can run bat with\n> `--style=-grid,+snip` to remove the grid and add back the `snip` component.\n> Or, if you want to override the styles completely, you use `--style=numbers` to\n> only show the line numbers.\n\n### Decorations\n\nBy default, `bat` only shows decorations (such as line numbers, file headers, grid borders, etc.) when outputting to an interactive terminal. You can control this behavior with the `--decorations` option. Use `--decorations=always` to show decorations even when piping output to another command, or `--decorations=never` to disable them entirely. Possible values are `auto` (default), `never`, and `always`.\n\nThere is also the `--force-colorization` option, which is an alias for `--decorations=always --color=always`. This is useful if you want to keep colorization and decorations when piping `bat`'s output to another program.\n\n### Adding new syntaxes / language definitions\n\nShould you find that a particular syntax is not available within `bat`, you can follow these\ninstructions to easily add new syntaxes to your current `bat` installation.\n\n`bat` uses the excellent [`syntect`](https://github.com/trishume/syntect/)\nlibrary for syntax highlighting. `syntect` can read any\n[Sublime Text `.sublime-syntax` file](https://www.sublimetext.com/docs/3/syntax.html)\nand theme.\n\nA good resource for finding Sublime Syntax packages is [Package Control](https://packagecontrol.io/). Once you found a\nsyntax:\n\n1. Create a folder with syntax definition files:\n\n   ```bash\n   mkdir -p \"$(bat --config-dir)/syntaxes\"\n   cd \"$(bat --config-dir)/syntaxes\"\n\n   # Put new '.sublime-syntax' language definition files\n   # in this folder (or its subdirectories), for example:\n   git clone https://github.com/tellnobody1/sublime-purescript-syntax\n   ```\n\n2. Now use the following command to parse these files into a binary cache:\n\n   ```bash\n   bat cache --build\n   ```\n\n3. Finally, use `bat --list-languages` to check if the new languages are available.\n\n   If you ever want to go back to the default settings, call:\n\n   ```bash\n   bat cache --clear\n   ```\n\n4. If you think that a specific syntax should be included in `bat` by default, please\n   consider opening a \"syntax request\" ticket after reading the policies and\n   instructions [here](doc/assets.md): [Open Syntax Request](https://github.com/sharkdp/bat/issues/new?labels=syntax-request&template=syntax_request.md).\n\n### Adding new themes\n\nThis works very similar to how we add new syntax definitions.\n> [!NOTE]\n> Themes are stored in [`.tmTheme` files](https://www.sublimetext.com/docs/color_schemes_tmtheme.html).\n\nFirst, create a folder with the new syntax highlighting themes:\n```bash\nmkdir -p \"$(bat --config-dir)/themes\"\ncd \"$(bat --config-dir)/themes\"\n\n# Download a theme in '.tmTheme' format, for example:\ngit clone https://github.com/greggb/sublime-snazzy\n\n# Update the binary cache\nbat cache --build\n```\n\nFinally, use `bat --list-themes` to check if the new themes are available.\n> [!NOTE]\n> `bat` uses the name of the `.tmTheme` file for the theme's name. \n\n### Adding or changing file type associations\n\nYou can add new (or change existing) file name patterns using the `--map-syntax`\ncommand line option. The option takes an argument of the form `pattern:syntax` where\n`pattern` is a glob pattern that is matched against the file name and\nthe absolute file path. The `syntax` part is the full name of a supported language\n(use `bat --list-languages` for an overview).\n\n**Note:** You probably want to use this option as [an entry in `bat`'s configuration file](#configuration-file)\nfor persistence instead of passing it on the command line as a one-off. Generally\nyou'd just use `-l` if you want to manually specify a language for a file.\n\nExample: To use \"INI\" syntax highlighting for all files with a `.conf` file extension, use\n```bash\n--map-syntax='*.conf:INI'\n```\n\nExample: To open all files called `.ignore` (exact match) with the \"Git Ignore\" syntax, use:\n```bash\n--map-syntax='.ignore:Git Ignore'\n```\n\nExample: To open all `.conf` files in subfolders of `/etc/apache2` with the \"Apache Conf\"\nsyntax, use (this mapping is already built in):\n```bash\n--map-syntax='/etc/apache2/**/*.conf:Apache Conf'\n```\n\n### Using a different pager\n\n`bat` uses the pager that is specified in the `PAGER` environment variable. If this variable is not\nset, `less` is used by default. You can also use bat's built-in pager with `--pager=builtin` or\nby setting the `BAT_PAGER` environment variable to \"builtin\".\n\nIf you want to use a different pager, you can either modify the `PAGER` variable or set the\n`BAT_PAGER` environment variable to override what is specified in `PAGER`.\n\n>[!NOTE]\n> If `PAGER` is `more` or `most`, `bat` will silently use `less` instead to ensure support for colors.\n\nIf you want to pass command-line arguments to the pager, you can also set them via the\n`PAGER`/`BAT_PAGER` variables:\n\n```bash\nexport BAT_PAGER=\"less -RFK\"\n```\n\nInstead of using environment variables, you can also use `bat`'s [configuration file](#configuration-file) to configure the pager (`--pager` option).\n\n\n### Using `less` as a pager\n\nWhen using `less` as a pager, `bat` will automatically pass extra options along to `less`\nto improve the experience. Specifically, `-R`/`--RAW-CONTROL-CHARS`, `-F`/`--quit-if-one-screen`,\n`-K`/`--quit-on-intr` and under certain conditions, `-X`/`--no-init` and/or `-S`/`--chop-long-lines`.\n\n>[!IMPORTANT]\n> These options will not be added if:\n> - The pager is not named `less`.\n> - The `--pager` argument contains any command-line arguments (e.g. `--pager=\"less -R\"`).\n> - The `BAT_PAGER` environment variable contains any command-line arguments (e.g. `export BAT_PAGER=\"less -R\"`)\n>\n> The `--quit-if-one-screen` option will not be added when:\n> - The `--paging=always` argument is used.\n> - The `BAT_PAGING` environment is set to `always`.\n\nThe `-R`/`--RAW-CONTROL-CHARS` option is needed to interpret ANSI colors correctly.\n\nThe `-F`/`--quit-if-one-screen` option instructs `less` to exit immediately if the output size is smaller than\nthe vertical size of the terminal. This is convenient for small files because you do not\nhave to press `q` to quit the pager.\n\nThe `-K`/`--quit-on-intr` option instructs `less` to exit immediately when an interrupt signal is received.\nThis is useful to ensure that `less` quits together with `bat` on SIGINT.\n\nThe `-X`/`--no-init` option is added to versions of `less` older than version 530 (older than 558 on Windows) to\nfix a bug with the `-F`/`--quit-if-one-screen` feature. Unfortunately, it also breaks mouse-wheel support in `less`.\nIf you want to enable mouse-wheel scrolling on older versions of `less` and do not mind losing\nthe quit-if-one-screen feature, you can set the pager (via `--pager` or `BAT_PAGER`) to `less -R`.\nFor `less` 530 or newer, it should work out of the box.\n\nThe `-S`/`--chop-long-lines` option is added when `bat`'s `-S`/`--chop-long-lines` option is used. This tells `less`\nto truncate any lines larger than the terminal width.\n\n### Indentation\n\n`bat` expands tabs to 4 spaces by itself, not relying on the pager. To change this, simply add the\n`--tabs` argument with the number of spaces you want to be displayed.\n\n**Note**: Defining tab stops for the pager (via the `--pager` argument by `bat`, or via the `LESS`\nenvironment variable for `less`) won't be taken into account because the pager will already get\nexpanded spaces instead of tabs. This behaviour is added to avoid indentation issues caused by the\nsidebar. Calling `bat` with `--tabs=0` will override it and let tabs be consumed by the pager.\n\n### Dark mode\n\nIf you make use of the dark mode feature in **macOS**, you might want to configure `bat` to use a different\ntheme based on the OS theme. The following snippet uses the `default` theme when in the _dark mode_\nand the `GitHub` theme when in the _light mode_.\n\n```bash\nalias cat=\"bat --theme auto:system --theme-dark default --theme-light GitHub\"\n```\n\nThe same dark mode feature is now available in **GNOME** and affects the `org.gnome.desktop.interface color-scheme` setting. The following code converts the above to use said setting.\n\n```bash\n# .bashrc\nsys_color_scheme_is_dark() {\n    condition=$(gsettings get org.gnome.desktop.interface color-scheme)\n    condition=$(echo \"$condition\" | tr -d \"[:space:]'\")\n    if [ $condition == \"prefer-dark\" ]; then\n        return 0\n    else\n        return 1\n    fi\n}\n\nbat_alias_wrapper() {\n    #get color scheme\n    sys_color_scheme_is_dark\n    if [[ $? -eq 0 ]]; then\n        # bat command with dark color scheme\n        bat --theme=default \"$@\"\n    else\n        # bat command with light color scheme\n        bat --theme=GitHub \"$@\"\n    fi\n}\nalias cat='bat_alias_wrapper'\n```\n\n\n## Configuration file\n\n`bat` can also be customized with a configuration file. The location of the file is dependent\non your operating system. To get the default path for your system, call\n```bash\nbat --config-file\n```\n\nAlternatively, you can use `BAT_CONFIG_PATH` or `BAT_CONFIG_DIR` environment variables to point `bat`\nto a non-default location of the configuration file or the configuration directory respectively:\n```bash\nexport BAT_CONFIG_PATH=\"/path/to/bat/bat.conf\"\nexport BAT_CONFIG_DIR=\"/path/to/bat\"\n```\n\nA default configuration file can be created with the `--generate-config-file` option.\n```bash\nbat --generate-config-file\n```\n\nThere is also now a systemwide configuration file, which is located under `/etc/bat/config` on\nLinux and Mac OS and `C:\\ProgramData\\bat\\config` on windows. If the system wide configuration\nfile is present, the content of the user configuration will simply be appended to it.\n\n### Format\n\nThe configuration file is a simple list of command line arguments. Use `bat --help` to see a full list of possible options and values. In addition, you can add comments by prepending a line with the `#` character.\n\nExample configuration file:\n```bash\n# Set the theme to \"TwoDark\"\n--theme=\"TwoDark\"\n\n# Show line numbers, Git modifications and file header (but no grid)\n--style=\"numbers,changes,header\"\n\n# Use italic text on the terminal (not supported on all terminals)\n--italic-text=always\n\n# Use C++ syntax for Arduino .ino files\n--map-syntax \"*.ino:C++\"\n```\n\n## Using `bat` on Windows\n\n`bat` mostly works out-of-the-box on Windows, but a few features may need extra configuration.\n\n### Prerequisites\n\nYou will need to install the [Visual C++ Redistributable](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads) package.\n\n### Paging\n\nWindows only includes a very limited pager in the form of `more`. You can download a Windows binary\nfor `less` [from its homepage](http://www.greenwoodsoftware.com/less/download.html) or [through\nChocolatey](https://chocolatey.org/packages/Less). To use it, place the binary in a directory in\nyour `PATH` or [define an environment variable](#using-a-different-pager). The [Chocolatey package](#on-windows) installs `less` automatically.\n\n### Colors\n\nWindows 10 natively supports colors in both `conhost.exe` (Command Prompt) and PowerShell since\n[v1511](https://en.wikipedia.org/wiki/Windows_10_version_history#Version_1511_(November_Update)), as\nwell as in newer versions of bash. On earlier versions of Windows, you can use\n[Cmder](http://cmder.app/), which includes [ConEmu](https://conemu.github.io/).\n\n**Note:** Old versions of `less` do not correctly interpret colors on Windows. To fix this, you can add the optional Unix tools to your PATH when installing Git. If you don‚Äôt have any other pagers installed, you can disable paging entirely by passing `--paging=never` or by setting `BAT_PAGER` to an empty string.\n\n### Cygwin\n\n`bat` on Windows does not natively support Cygwin's unix-style paths (`/cygdrive/*`). When passed an absolute cygwin path as an argument, `bat` will encounter the following error: `The system cannot find the path specified. (os error 3)`\n\nThis can be solved by creating a wrapper or adding the following function to your `.bash_profile` file:\n\n```bash\nbat() {\n    local index\n    local args=(\"$@\")\n    for index in $(seq 0 ${#args[@]}) ; do\n        case \"${args[index]}\" in\n        -*) continue;;\n        *)  [ -e \"${args[index]}\" ] && args[index]=\"$(cygpath --windows \"${args[index]}\")\";;\n        esac\n    done\n    command bat \"${args[@]}\"\n}\n```\n\n## Troubleshooting\n\n### Garbled output\n\nIf an input file contains color codes or other ANSI escape sequences or control characters, `bat` will have problems\nperforming syntax highlighting and text wrapping, and thus the output can become garbled.\n\nIf your version of `bat` supports the `--strip-ansi=auto` option, it can be used to remove such sequences\nbefore syntax highlighting. Alternatively, you may disable both syntax highlighting and wrapping by\npassing the `--color=never --wrap=never` options to `bat`.\n\n> [!NOTE]\n> The `auto` option of `--strip-ansi` avoids removing escape sequences when the syntax is plain text.\n\n### Terminals & colors\n\n`bat` handles terminals *with* and *without* truecolor support. However, the colors in most syntax\nhighlighting themes are not optimized for 8-bit colors. It is therefore strongly recommended\nthat you use a terminal with 24-bit truecolor support (`terminator`, `konsole`, `iTerm2`, ...),\nor use one of the basic [8-bit themes](#8-bit-themes) designed for a restricted set of colors.\nSee [this article](https://gist.github.com/XVilka/8346728) for more details and a full list of\nterminals with truecolor support.\n\nMake sure that your truecolor terminal sets the `COLORTERM` variable to either `truecolor` or\n`24bit`. Otherwise, `bat` will not be able to determine whether or not 24-bit escape sequences\nare supported (and fall back to 8-bit colors).\n\n### Line numbers and grid are hardly visible\n\nPlease try a different theme (see `bat --list-themes` for a list). The `OneHalfDark` and\n`OneHalfLight` themes provide grid and line colors that are brighter.\n\n### File encodings\n\n`bat` natively supports UTF-8 as well as UTF-16. For every other file encoding, you may need to\nconvert to UTF-8 first because the encodings can typically not be auto-detected. You can `iconv`\nto do so.\nExample: if you have a PHP file in Latin-1 (ISO-8859-1) encoding, you can call:\n``` bash\niconv -f ISO-8859-1 -t UTF-8 my-file.php | bat\n```\nNote: you might have to use the `-l`/`--language` option if the syntax can not be auto-detected\nby `bat`.\n\n## Development\n\n```bash\n# Recursive clone to retrieve all submodules\ngit clone --recursive https://github.com/sharkdp/bat\n\n# Build (debug version)\ncd bat\ncargo build --bins\n\n# Run unit tests and integration tests\ncargo test\n\n# Install (release version)\ncargo install --path . --locked\n\n# Build a bat binary with modified syntaxes and themes\nbash assets/create.sh\ncargo install --path . --locked --force\n```\n\nIf you want to build an application that uses `bat`'s pretty-printing\nfeatures as a library, check out the [the API documentation](https://docs.rs/bat/).\nNote that you have to use either `regex-onig` or `regex-fancy` as a feature\nwhen you depend on `bat` as a library.\n\n## Contributing\n\nTake a look at the [`CONTRIBUTING.md`](CONTRIBUTING.md) guide.\n\n## Maintainers\n\n- [sharkdp](https://github.com/sharkdp)\n- [eth-p](https://github.com/eth-p)\n- [keith-hall](https://github.com/keith-hall)\n- [Enselic](https://github.com/Enselic)\n\n## Security vulnerabilities\n\nSee [`SECURITY.md`](SECURITY.md).\n\n## Project goals and alternatives\n\n`bat` tries to achieve the following goals:\n\n- Provide beautiful, advanced syntax highlighting\n- Integrate with Git to show file modifications\n- Be a drop-in replacement for (POSIX) `cat`\n- Offer a user-friendly command-line interface\n\nThere are a lot of alternatives, if you are looking for similar programs. See\n[this document](doc/alternatives.md) for a comparison.\n\n## License\nCopyright (c) 2018-2025 [bat-developers](https://github.com/sharkdp/bat).\n\n`bat` is made available under the terms of either the MIT License or the Apache License 2.0, at your option.\n\nSee the [LICENSE-APACHE](LICENSE-APACHE) and [LICENSE-MIT](LICENSE-MIT) files for license details.\n",
      "stars_today": 22
    },
    {
      "id": 748528018,
      "name": "WhisperKit",
      "full_name": "argmaxinc/WhisperKit",
      "description": "On-device Speech Recognition for Apple Silicon",
      "html_url": "https://github.com/argmaxinc/WhisperKit",
      "stars": 5506,
      "forks": 492,
      "language": "Swift",
      "topics": [
        "inference",
        "ios",
        "macos",
        "speech-recognition",
        "swift",
        "transformers",
        "visionos",
        "watchos",
        "whisper"
      ],
      "created_at": "2024-01-26T07:11:52Z",
      "updated_at": "2026-01-23T18:58:41Z",
      "pushed_at": "2026-01-22T19:43:45Z",
      "open_issues": 93,
      "owner": {
        "login": "argmaxinc",
        "avatar_url": "https://avatars.githubusercontent.com/u/150409474?v=4"
      },
      "readme": "\n<div align=\"center\">\n  \n<a href=\"https://github.com/argmaxinc/WhisperKit#gh-light-mode-only\">\n  <img src=\"https://github.com/user-attachments/assets/f0699c07-c29f-45b6-a9c6-f6d491b8f791\" alt=\"WhisperKit\" width=\"20%\" />\n</a>\n\n<a href=\"https://github.com/argmaxinc/WhisperKit#gh-dark-mode-only\">\n  <img src=\"https://github.com/user-attachments/assets/1be5e31c-de42-40ab-9b85-790cb911ed47\" alt=\"WhisperKit\" width=\"20%\" />\n</a>\n\n# WhisperKit\n\n[![Tests](https://github.com/argmaxinc/whisperkit/actions/workflows/release-tests.yml/badge.svg)](https://github.com/argmaxinc/whisperkit/actions/workflows/release-tests.yml)\n[![License](https://img.shields.io/github/license/argmaxinc/whisperkit?logo=github&logoColor=969da4&label=License&labelColor=353a41&color=32d058)](LICENSE.md)\n[![Supported Swift Version](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fargmaxinc%2FWhisperKit%2Fbadge%3Ftype%3Dswift-versions&labelColor=353a41&color=32d058)](https://swiftpackageindex.com/argmaxinc/WhisperKit) [![Supported Platforms](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fargmaxinc%2FWhisperKit%2Fbadge%3Ftype%3Dplatforms&labelColor=353a41&color=32d058)](https://swiftpackageindex.com/argmaxinc/WhisperKit)\n[![Discord](https://img.shields.io/discord/1171912382512115722?style=flat&logo=discord&logoColor=969da4&label=Discord&labelColor=353a41&color=32d058&link=https%3A%2F%2Fdiscord.gg%2FG5F5GZGecC)](https://discord.gg/G5F5GZGecC)\n\n\n</div>\n\nWhisperKit is an [Argmax](https://www.takeargmax.com) framework for deploying state-of-the-art speech-to-text systems (e.g. [Whisper](https://github.com/openai/whisper)) on device with advanced features such as real-time streaming, word timestamps, voice activity detection, and more.\n\n[[TestFlight Demo App]](https://testflight.apple.com/join/Q1cywTJw) [[Python Tools]](https://github.com/argmaxinc/whisperkittools) [[Benchmarks & Device Support]](https://huggingface.co/spaces/argmaxinc/whisperkit-benchmarks) [[WhisperKit Android]](https://github.com/argmaxinc/WhisperKitAndroid)\n\n> [!IMPORTANT]\n> WhisperKit is ideal for getting started with on-device speech-to-text. When you are ready to scale your on-device deployment with real-time transcription and speaker diarization, start your [14-day trial](https://app.argmaxinc.com) for [Argmax Pro SDK](https://www.argmaxinc.com/#SDK) with 9x faster and higher accuracy models such as Nvidia Parakeet V3, [pyannoteAI's flagship](https://www.argmaxinc.com/blog/pyannote-argmax) speaker diarization model, and a Deepgram-compatible WebSocket [local server](https://www.argmaxinc.com/blog/argmax-local-server) for easy integration into non-Swift projects.\n\n## Table of Contents\n\n- [Installation](#installation)\n  - [Swift Package Manager](#swift-package-manager)\n  - [Prerequisites](#prerequisites)\n  - [Xcode Steps](#xcode-steps)\n  - [Package.swift](#packageswift)\n  - [Homebrew](#homebrew)\n- [Getting Started](#getting-started)\n  - [Quick Example](#quick-example)\n  - [Model Selection](#model-selection)\n  - [Generating Models](#generating-models)\n  - [Swift CLI](#swift-cli)\n- [WhisperKit Local Server](#whisperkit-local-server)\n- [Contributing \\& Roadmap](#contributing--roadmap)\n- [License](#license)\n- [Citation](#citation)\n\n## Installation\n\n### Swift Package Manager\n\nWhisperKit can be integrated into your Swift project using the Swift Package Manager.\n\n### Prerequisites\n\n- macOS 14.0 or later.\n- Xcode 15.0 or later.\n\n### Xcode Steps\n\n1. Open your Swift project in Xcode.\n2. Navigate to `File` > `Add Package Dependencies...`.\n3. Enter the package repository URL: `https://github.com/argmaxinc/whisperkit`.\n4. Choose the version range or specific version.\n5. Click `Finish` to add WhisperKit to your project.\n\n### Package.swift\n\nIf you're using WhisperKit as part of a swift package, you can include it in your Package.swift dependencies as follows:\n\n```swift\ndependencies: [\n    .package(url: \"https://github.com/argmaxinc/WhisperKit.git\", from: \"0.9.0\"),\n],\n```\n\nThen add `WhisperKit` as a dependency for your target:\n\n```swift\n.target(\n    name: \"YourApp\",\n    dependencies: [\"WhisperKit\"]\n),\n```\n\n### Homebrew\n\nYou can install `WhisperKit` command line app using [Homebrew](https://brew.sh) by running the following command:\n\n```bash\nbrew install whisperkit-cli\n```  \n\n## Getting Started\n\nTo get started with WhisperKit, you need to initialize it in your project.\n\n### Quick Example\n\nThis example demonstrates how to transcribe a local audio file:\n\n```swift\nimport WhisperKit\n\n// Initialize WhisperKit with default settings\nTask {\n   let pipe = try? await WhisperKit()\n   let transcription = try? await pipe!.transcribe(audioPath: \"path/to/your/audio.{wav,mp3,m4a,flac}\")?.text\n    print(transcription)\n}\n```\n\n### Model Selection\n\nWhisperKit automatically downloads the recommended model for the device if not specified. You can also select a specific model by passing in the model name:\n\n```swift\nlet pipe = try? await WhisperKit(WhisperKitConfig(model: \"large-v3\"))\n```\n\nThis method also supports glob search, so you can use wildcards to select a model:\n\n```swift\nlet pipe = try? await WhisperKit(WhisperKitConfig(model: \"distil*large-v3\"))\n```\n\nNote that the model search must return a single model from the source repo, otherwise an error will be thrown.\n\nFor a list of available models, see our [HuggingFace repo](https://huggingface.co/argmaxinc/whisperkit-coreml).\n\n### Generating Models\n\nWhisperKit also comes with the supporting repo [`whisperkittools`](https://github.com/argmaxinc/whisperkittools) which lets you create and deploy your own fine tuned versions of Whisper in CoreML format to HuggingFace. Once generated, they can be loaded by simply changing the repo name to the one used to upload the model:\n\n```swift\nlet config = WhisperKitConfig(model: \"large-v3\", modelRepo: \"username/your-model-repo\")\nlet pipe = try? await WhisperKit(config)\n```\n\n### Swift CLI\n\nThe Swift CLI allows for quick testing and debugging outside of an Xcode project. To install it, run the following:\n\n```bash\ngit clone https://github.com/argmaxinc/whisperkit.git\ncd whisperkit\n```\n\nThen, setup the environment and download your desired model.\n\n```bash\nmake setup\nmake download-model MODEL=large-v3\n```\n\n**Note**:\n\n1. This will download only the model specified by `MODEL` (see what's available in our [HuggingFace repo](https://huggingface.co/argmaxinc/whisperkit-coreml), where we use the prefix `openai_whisper-{MODEL}`)\n2. Before running `download-model`, make sure [git-lfs](https://git-lfs.com) is installed\n\nIf you would like download all available models to your local folder, use this command instead:\n\n```bash\nmake download-models\n```\n\nYou can then run them via the CLI with:\n\n```bash\nswift run whisperkit-cli transcribe --model-path \"Models/whisperkit-coreml/openai_whisper-large-v3\" --audio-path \"path/to/your/audio.{wav,mp3,m4a,flac}\" \n```\n\nWhich should print a transcription of the audio file. If you would like to stream the audio directly from a microphone, use:\n\n```bash\nswift run whisperkit-cli transcribe --model-path \"Models/whisperkit-coreml/openai_whisper-large-v3\" --stream\n```\n\n### WhisperKit Local Server\n\nWhisperKit includes a local server that implements the OpenAI Audio API, allowing you to use existing OpenAI SDK clients or generate new ones. The server supports transcription and translation with **output streaming** capabilities (real-time transcription results as they're generated).\n\n> [!NOTE]\n> **For real-time transcription server with full-duplex streaming capabilities**, check out [WhisperKit Pro Local Server](https://www.argmaxinc.com/blog/argmax-local-server) which provides live audio streaming and real-time transcription for applications requiring continuous audio processing.\n\n#### Building the Server\n\n```bash\n# Build with server support\nmake build-local-server\n\n# Or manually with the build flag\nBUILD_ALL=1 swift build --product whisperkit-cli\n```\n\n#### Starting the Server\n\n```bash\n# Start server with default settings\nBUILD_ALL=1 swift run whisperkit-cli serve\n\n# Custom host and port\nBUILD_ALL=1 swift run whisperkit-cli serve --host 0.0.0.0 --port 8080\n\n# With specific model and verbose logging\nBUILD_ALL=1 swift run whisperkit-cli serve --model tiny --verbose\n\n# See all configurable parameters\nBUILD_ALL=1 swift run whisperkit-cli serve --help\n```\n\n#### API Endpoints\n\n- **POST** `/v1/audio/transcriptions` - Transcribe audio to text\n- **POST** `/v1/audio/translations` - Translate audio to English\n\n#### Supported Parameters\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `file` | Audio file (wav, mp3, m4a, flac) | Required |\n| `model` | Model identifier | Server default |\n| `language` | Source language code | Auto-detect |\n| `prompt` | Text to guide transcription | None |\n| `response_format` | Output format (json, verbose_json) | verbose_json |\n| `temperature` | Sampling temperature (0.0-1.0) | 0.0 |\n| `timestamp_granularities[]` | Timing detail (word, segment) | segment |\n| `stream` | Enable streaming | false |\n\n#### Client Examples\n\n**Python Client (OpenAI SDK)**\n```bash\ncd Examples/ServeCLIClient/Python\nuv sync\npython whisperkit_client.py transcribe --file audio.wav --language en\npython whisperkit_client.py translate --file audio.wav\n```\n\nQuick Python example:\n```python\nfrom openai import OpenAI\nclient = OpenAI(base_url=\"http://localhost:50060/v1\")\nresult = client.audio.transcriptions.create(\n    file=open(\"audio.wav\", \"rb\"),\n    model=\"tiny\"  # Model parameter is required\n)\nprint(result.text)\n```\n\n**Swift Client (Generated from OpenAPI Spec, see ServeCLIClient/Swift/updateClient.sh)**\n```bash\ncd Examples/ServeCLIClient/Swift\nswift run whisperkit-client transcribe audio.wav --language en\nswift run whisperkit-client translate audio.wav\n```\n\n**CurlClient (Shell Scripts)**\n```bash\ncd Examples/ServeCLIClient/Curl\nchmod +x *.sh\n./transcribe.sh audio.wav --language en\n./translate.sh audio.wav --language es\n./test.sh  # Run comprehensive test suite\n```\n\n#### Generating the API Specification\n\nThe server's OpenAPI specification and code are generated from the official OpenAI API:\n\n```bash\n# Generate latest spec and server code\nmake generate-server\n```\n\n#### Client Generation\n\nYou can generate clients for any language using the OpenAPI specification, for example:\n\n```bash\n# Generate Python client\nswift run swift-openapi-generator generate scripts/specs/localserver_openapi.yaml \\\n  --output-directory python-client \\\n  --mode client \\\n  --mode types\n\n# Generate TypeScript client\nnpx @openapitools/openapi-generator-cli generate \\\n  -i scripts/specs/localserver_openapi.yaml \\\n  -g typescript-fetch \\\n  -o typescript-client\n```\n\n#### API Limitations\n\nCompared to the official OpenAI API, the local server has these limitations:\n\n- **Response formats**: Only `json` and `verbose_json` supported (no plain text, SRT, VTT formats)\n- **Model selection**: Client must launch server with desired model via `--model` flag\n\n#### Fully Supported Features\n\nThe local server fully supports these OpenAI API features:\n\n- **Include parameters**: `logprobs` parameter for detailed token-level log probabilities\n- **Streaming responses**: Server-Sent Events (SSE) for real-time transcription\n- **Timestamp granularities**: Both `word` and `segment` level timing\n- **Language detection**: Automatic language detection or manual specification\n- **Temperature control**: Sampling temperature for transcription randomness\n- **Prompt text**: Text guidance for transcription style and context\n\n## Contributing & Roadmap\n\nOur goal is to make WhisperKit better and better over time and we'd love your help! Just search the code for \"TODO\" for a variety of features that are yet to be built. Please refer to our [contribution guidelines](CONTRIBUTING.md) for submitting issues, pull requests, and coding standards, where we also have a public roadmap of features we are looking forward to building in the future.\n\n## License\n\nWhisperKit is released under the MIT License. See [LICENSE](LICENSE) for more details.\n\n## Citation\n\nIf you use WhisperKit for something cool or just find it useful, please drop us a note at [info@argmaxinc.com](mailto:info@argmaxinc.com)!\n\nIf you use WhisperKit for academic work, here is the BibTeX:\n\n```bibtex\n@misc{whisperkit-argmax,\n   title = {WhisperKit},\n   author = {Argmax, Inc.},\n   year = {2024},\n   URL = {https://github.com/argmaxinc/WhisperKit}\n}\n```\n",
      "stars_today": 19
    },
    {
      "id": 966768509,
      "name": "ygege",
      "full_name": "UwUDev/ygege",
      "description": "High-performance indexer for YGG Torrent written in Rust",
      "html_url": "https://github.com/UwUDev/ygege",
      "stars": 430,
      "forks": 27,
      "language": "Rust",
      "topics": [
        "prowlarr",
        "ygg",
        "yggtorrent"
      ],
      "created_at": "2025-04-15T12:30:39Z",
      "updated_at": "2026-01-24T01:16:50Z",
      "pushed_at": "2026-01-23T17:37:40Z",
      "open_issues": 11,
      "owner": {
        "login": "UwUDev",
        "avatar_url": "https://avatars.githubusercontent.com/u/61664271?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"website/img/ygege-logo-text.png\" alt=\"Logo Yg√©g√©\" width=\"400\"/>\n</p>\n\n<div align=\"right\">\n  <details>\n    <summary>üåê Language</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"README.md\">Fran√ßais</a>\n        | <a href=\"README-en.md\">English</a>\n      </div>\n    </div>\n  </details>\n</div>\n\nIndexeur haute performance pour YGG Torrent √©crit en Rust \n\n## https://discord.gg/rcsgdzNrvJ\n\n<!--\n> [!CAUTION]\n> Suite a la nouvelle mise en place de la limite de 5 torrents gratuits par jour sur YGG Torrent, Yg√©g√© n'est plus en mesure de fonctionner correctement. Je travaille actuellement sur une solution pour contourner cette limitation. Votre aide est possible meme si vous ne savez pas coder en Rust ni coder du tout. N'hesitez pas a aller voir le discord pour plus d'infos: https://discord.gg/rcsgdzNrvJ\n>\n> Edit: Ils ont patch√©s les 2 bypass et forcent le captcha turnstile... Merci de ne plus cr√©er d'isssues a ce sujet (erreur 403)\n-->\n\n**Caract√©ristiques principales** :\n- R√©solution automatique du domaine actuel de YGG Torrent\n- Bypass Cloudflare automatis√© (sans r√©solution manuelle)\n- Recherche quasi instantan√©e\n- Reconnexion transparente aux sessions expir√©es\n- Caching des sessions\n- Contournement des DNS menteurs\n- Consommation m√©moire faible (14.7Mo en mode release sur Linux)\n- Recherche de torrents tr√®s modulaire (par nom, seed, leech, commentaires, date de publication, etc.)\n- Recuperation des informations compl√©mentaires sur les torrents (description, taille, nombre de seeders, leechers, etc.)\n- Pas de d√©pendances externes\n- Pas de drivers de navigateur\n\n## Pr√©requis pour la compilation\n- Rust 1.85.0+\n- OpenSSL 3+\n- Toutes les d√©pendances requises pour la compilation de [wreq](https://crates.io/crates/wreq)\n\n# Installation\n\nUne image Docker pr√™te √† l'emploi est disponible pour Yg√©g√©.\nPour commencer le d√©ploiement et la configuration de Docker, consultez le [Guide d√©di√© √† Docker](https://ygege.lila.ws/installation/docker-guide).\n\n## Docker\n\nPour cr√©er une image Docker personnalis√©e avec vos propres optimisations, consultez le [Guide de cr√©ation Docker](https://ygege.lila.ws/installation/docker-guide).\n\n## Installation manuelle\n\nPour compiler l'application √† partir des sources, suivez le [Guide d'installation manuel](https://ygege.lila.ws/installation/source-guide).\n\nPour les fans de Docker, n'h√©sitez pas √† contribuer au projet en m'aidant √† cr√©er une image Docker.\n\n## Configuration IMDB et TMDB\n\nPour activer la r√©cup√©ration des m√©tadonn√©es IMDB et TMDB, veuillez suivre les instructions du [guide d'assistance TMDB et IMDB](https://ygege.lila.ws/tmdb-imdb).\n\n## Int√©gration √† Prowlarr\n\nYg√©g√© peut √™tre utilis√© comme indexeur personnalis√© pour Prowlarr. Pour le mettre en place, trouvez votre r√©pertoire AppData (situ√© dans la page `/system/status` de Prowlarr) et copiez le fichier `ygege.yml` du repo dans le dossier `{votre chemin appdata prowlarr}/Definitions/Custom`, vous aurez probablement besoin de cr√©er le dossier `Custom`.\n\nUne fois que c'est fait, red√©marrez Prowlarr et allez dans les param√®tres des indexeurs, vous devriez voir Yg√©g√© dans la liste des indexeurs disponibles.\n\n> [!NOTE]\n> Prowlarr ne permet pas de personnaliser le \"Base URL\". Par d√©faut, utilisez `http://localhost:8715/`. Pour les configurations Docker Compose, utilisez `http://ygege:8715/`. Alternativement, utilisez ygege-dns-redirect.local avec un DNS personnalis√© ou en √©ditant le fichier hosts.\n\n## Int√©gration √† Jackett\n\nYg√©g√© peut √™tre utilis√© comme indexeur personnalis√© pour Jackett. Pour le mettre en place, localisez votre r√©pertoire AppData Jackett et copiez le fichier `ygege.yml` du d√©p√¥t dans le dossier `{votre chemin appdata jackett}/cardigann/definitions/`. Vous devrez peut-√™tre cr√©er le sous-dossier `cardigann/definitions/` s'il n'existe pas.\n\n> [!NOTE]\n> L'image Docker LinuxServer Jackett fournit une structure de dossiers bien organis√©e. Si vous utilisez une autre image Docker, adaptez les chemins en cons√©quence.\n\nUne fois termin√©, red√©marrez Jackett et acc√©dez aux param√®tres des indexeurs. Vous devriez voir Yg√©g√© dans la liste des indexeurs disponibles.\n\n## Contournement Cloudflare\nPour contourner le d√©fi de Cloudflare, Yg√©g√© n'utilise pas de navigateur ni de services tiers.\n\nUne r√®gle Cloudflare est appliqu√©e sur le site YGG Torrent pour emp√™cher l'apparition du challenge Cloudflare via le cookie `account_created=true` cens√© garantir que l'utilisateur a un compte valide et est connect√©.\n\nMais ce n'est pas si simple, Cloudflare vous surveille toujours et d√©tecte les faux clients HTTPS et les faux navigateurs.\n\nPour contourner cela, Yg√©g√© utilise la librairie [wreq](https://crates.io/crates/wreq) qui est un client HTTP bas√© sur `reqwest` et `tokio` permettant de reproduire 1:1 l'√©change TLS et HTTP/2 avec le serveur afin de simuler un vrai navigateur.\n\nJ'ai aussi remarqu√© que cela ne passait plus √† partir de Chrome 133, s√ªrement √† cause de l'integration de HTTP/3 dans Chrome qui n'est pas encore simul√©e par `wreq`.\n\nJe recommande aux curieux [cet article](https://fingerprint.com/blog/what-is-tls-fingerprinting-transport-layer-security/) qui explique comment fonctionne le fingerprinting TLS et [cet autre article](https://www.trickster.dev/post/understanding-http2-fingerprinting/) qui explique comment fonctionne le fingerprinting HTTP/2 et comment il est possible de le contourner.\n\n## Test de performance\n\nQuery pour la recherche:\n- Nom: `Vaiana 2`\n- Tri: `seeders`\n- Ordre: `descendant`\n\n|                                     | Nombre de tests | Temps total de tous les tests | Temps moyen par test |\n|-------------------------------------|-----------------|-------------------------------|----------------------|\n| R√©solution du domaine actuel de YGG |        25       |           3220,378ms          |      128,81512ms     |\n| Nouvelle connection YGG             |        10       |          4881.71361ms         |     488.1713616ms    |\n| Restoration de session YGG          |        10       |         2064.672142ms         |     206.4672142ms    |\n| Recherche                           |       100       |         17621.045874ms        |    176,21045874ms    |\n\n# Documentation\n\n## Documentation utilisateur\n\nLa documentation compl√®te est disponible sur [ygege.lila.ws](https://ygege.lila.ws) :\n- [Guide de d√©marrage](https://ygege.lila.ws/getting-started)\n- [Installation](https://ygege.lila.ws/installation/docker-guide)\n- [Configuration](https://ygege.lila.ws/configuration)\n- [Int√©grations (Prowlarr/Jackett)](https://ygege.lila.ws/integrations/prowlarr)\n- [Documentation de l'API](https://ygege.lila.ws/api)\n- [FAQ](https://ygege.lila.ws/faq)\n\n## Documentation d√©veloppeur\n\nPour contribuer au projet ou comprendre le fonctionnement interne :\n- [Guide de contribution](docs/contribution-fr.md)\n- [Pipeline CI/CD](docs/ci_implementation-fr.md)\n- [Workflow de preview des PRs](docs/preview_workflow-fr.md)\n- [Workflow de release](docs/release_workflow-fr.md)\n",
      "stars_today": 19
    },
    {
      "id": 220546758,
      "name": "headlamp",
      "full_name": "kubernetes-sigs/headlamp",
      "description": "A Kubernetes web UI that is fully-featured, user-friendly and extensible",
      "html_url": "https://github.com/kubernetes-sigs/headlamp",
      "stars": 5471,
      "forks": 537,
      "language": "TypeScript",
      "topics": [
        "cloud-native",
        "dashboard",
        "debugging",
        "devops",
        "headlamp",
        "k8s",
        "kinvolk",
        "kubernetes",
        "kubernetes-dashboard",
        "kubernetes-debugging",
        "kubernetes-monitoring",
        "kubernetes-ui",
        "orchestration",
        "plugins"
      ],
      "created_at": "2019-11-08T21:00:03Z",
      "updated_at": "2026-01-24T01:17:52Z",
      "pushed_at": "2026-01-22T17:01:01Z",
      "open_issues": 311,
      "owner": {
        "login": "kubernetes-sigs",
        "avatar_url": "https://avatars.githubusercontent.com/u/36015203?v=4"
      },
      "readme": "<h1>\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"frontend/src/resources/logo-light.svg\">\n    <img src=\"frontend/src/resources/logo-dark.svg\" alt=\"Headlamp\">\n  </picture>\n</h1>\n\n> **NOTICE:** We have recently moved the project under the Kubernetes SIG UI (and the repo under the _kubernetes-sigs_ org). Container images are still at [ghcr.io](https://github.com/orgs/headlamp-k8s/packages). Please bear with us while we may experience some broken links.\n\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/7551/badge)](https://www.bestpractices.dev/projects/7551)\n[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/kubernetes-sigs/headlamp/badge)](https://scorecard.dev/viewer/?uri=github.com/kubernetes-sigs/headlamp)\n[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fheadlamp-k8s%2Fheadlamp.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fheadlamp-k8s%2Fheadlamp?ref=badge_shield)\n\nHeadlamp is an easy-to-use and extensible Kubernetes web UI.\n\nHeadlamp was created to blend the traditional feature set of other web UIs/dashboards\n(i.e., to list and view resources) with added functionality.\n\n<div align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/kubernetes-sigs/headlamp/screenshots/videos/headlamp_quick_run.gif\" width=\"80%\">\n</div>\n\n## Features\n\n- Vendor-independent / generic Kubernetes UI\n- Works in-cluster, or locally as a desktop app\n- Multi-cluster\n- Extensible through [plugins](https://github.com/headlamp-k8s/plugins)\n- UI controls reflecting user roles (no deletion/update if not allowed)\n- Clean & modern UI\n- Cancellable creation/update/deletion operations\n- Logs, exec, and resource editor with documentation\n- Read-write / interactive (actions based on permissions)\n\n## Screenshots\n\n<table>\n    <tr>\n        <td width=\"33%\"><img src=\"https://raw.githubusercontent.com/kubernetes-sigs/headlamp/screenshots/screenshots/home.png\"></td>\n        <td width=\"33%\"><img src=\"https://raw.githubusercontent.com/kubernetes-sigs/headlamp/screenshots/screenshots/cluster_chooser.png\"></td>\n    </tr>\n    <tr>\n        <td width=\"33%\"><img src=\"https://raw.githubusercontent.com/kubernetes-sigs/headlamp/screenshots/screenshots/workloads.png\"></td>\n        <td width=\"33%\"><img src=\"https://raw.githubusercontent.com/kubernetes-sigs/headlamp/screenshots/screenshots/resource_edition.png\"></td>\n    </tr>\n    <tr>\n        <td width=\"33%\"><img src=\"https://raw.githubusercontent.com/kubernetes-sigs/headlamp/screenshots/screenshots/logs.png\"></td>\n        <td width=\"33%\"><img src=\"https://raw.githubusercontent.com/kubernetes-sigs/headlamp/screenshots/screenshots/terminal.png\"></td>\n    </tr>\n</table>\n\n## Quickstart\n\nIf you want to deploy Headlamp in your cluster, check out the instructions on running it [in-cluster](https://headlamp.dev/docs/latest/installation/in-cluster/).\n\nIf you have a kubeconfig already, you can quickly try Headlamp locally as a\n[desktop application](https://headlamp.dev/docs/latest/installation/desktop/)\nfor [Linux](https://headlamp.dev/docs/latest/installation/desktop/linux-installation),\n[Mac](https://headlamp.dev/docs/latest/installation/desktop/mac-installation),\nor [Windows](https://headlamp.dev/docs/latest/installation/desktop/win-installation).\n**Make sure** you have a kubeconfig file set up with your favorite clusters and\nin the default path so Headlamp can use it.\n\n### Accessing\n\nHeadlamp uses [RBAC](https://kubernetes.io/docs/reference/access-authn-authz/rbac) for checking\nusers' access to resources. If you try Headlamp with a token that has very limited\npermissions, you may not be able to view your cluster resources correctly.\n\nSee the documentation on [how to easily get a Service Account token](https://headlamp.dev/docs/latest/installation#create-a-service-account-token) for your cluster.\n\n## Tested platforms\n\nWe maintain a list of the [Kubernetes platforms](./docs/platforms.md) we have\ntested Headlamp with. We invite you to add any missing platforms you have\ntested, or comment if there are any regressions in the existing ones.\n\n## Extensions / Plugins\n\nPlease see [headlamp plugins on Artifact Hub](https://artifacthub.io/packages/search?kind=21&sort=relevance&page=1) for a list of plugins published.\n\nSee the [plugins repo](https://github.com/headlamp-k8s/plugins) for some official plugins.\n\n### Plugin development\n\nIf you are interested in tweaking Headlamp to fit your use-cases, you can check out\nour [plugin development guide](https://headlamp.dev/docs/latest/development/plugins/).\n\n\n## Get involved\n\nCheck out our: \n- [Guidelines](https://headlamp.dev/docs/latest/contributing/)\n- [Code of Conduct](./code-of-conduct.md),\n- [#headlamp](https://kubernetes.slack.com/messages/headlamp) slack channel in the Kubernetes Slack \n- [Monthly Community Meeting](https://zoom-lfx.platform.linuxfoundation.org/meetings/headlamp)\n\n## Roadmap / Release Planning\n\nIf you are interested in the direction of the project, we maintain a\n[Roadmap](https://github.com/orgs/headlamp-k8s/projects/1/views/1). It has the\nbiggest changes planned so far, as well as a [board](https://github.com/orgs/headlamp-k8s/projects/1/) tracking each release.\n\n## License\n\nHeadlamp is released under the terms of the [Apache 2.0](./LICENSE) license.\n\n## Frequently Asked Questions\n\nFor more information about Headlamp, see the [Headlamp FAQ](https://headlamp.dev/docs/latest/faq/).\n",
      "stars_today": 18
    },
    {
      "id": 11171548,
      "name": "json",
      "full_name": "nlohmann/json",
      "description": "JSON for Modern C++",
      "html_url": "https://github.com/nlohmann/json",
      "stars": 48646,
      "forks": 7301,
      "language": "C++",
      "topics": [
        "bson",
        "cbor",
        "header-only",
        "json",
        "json-diff",
        "json-merge-patch",
        "json-parser",
        "json-patch",
        "json-pointer",
        "json-serialization",
        "messagepack",
        "msgpack",
        "rfc-6901",
        "rfc-6902",
        "rfc-7049",
        "rfc-7159",
        "rfc-8259",
        "stl-containers",
        "ubjson"
      ],
      "created_at": "2013-07-04T08:47:49Z",
      "updated_at": "2026-01-24T01:14:31Z",
      "pushed_at": "2026-01-23T15:52:41Z",
      "open_issues": 99,
      "owner": {
        "login": "nlohmann",
        "avatar_url": "https://avatars.githubusercontent.com/u/159488?v=4"
      },
      "readme": "[![JSON for Modern C++](docs/mkdocs/docs/images/json.gif)](https://github.com/nlohmann/json/releases)\n\n[![Build Status](https://ci.appveyor.com/api/projects/status/1acb366xfyg3qybk/branch/develop?svg=true)](https://ci.appveyor.com/project/nlohmann/json)\n[![Ubuntu](https://github.com/nlohmann/json/workflows/Ubuntu/badge.svg)](https://github.com/nlohmann/json/actions?query=workflow%3AUbuntu)\n[![macOS](https://github.com/nlohmann/json/workflows/macOS/badge.svg)](https://github.com/nlohmann/json/actions?query=workflow%3AmacOS)\n[![Windows](https://github.com/nlohmann/json/workflows/Windows/badge.svg)](https://github.com/nlohmann/json/actions?query=workflow%3AWindows)\n[![Coverage Status](https://coveralls.io/repos/github/nlohmann/json/badge.svg?branch=develop)](https://coveralls.io/github/nlohmann/json?branch=develop)\n[![Coverity Scan Build Status](https://scan.coverity.com/projects/5550/badge.svg)](https://scan.coverity.com/projects/nlohmann-json)\n[![Codacy Badge](https://app.codacy.com/project/badge/Grade/e0d1a9d5d6fd46fcb655c4cb930bb3e8)](https://app.codacy.com/gh/nlohmann/json/dashboard?utm_source=gh&utm_medium=referral&utm_content=&utm_campaign=Badge_grade)\n[![Cirrus CI](https://api.cirrus-ci.com/github/nlohmann/json.svg)](https://cirrus-ci.com/github/nlohmann/json)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/json.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:json)\n[![Try online](https://img.shields.io/badge/try-online-blue.svg)](https://wandbox.org/permlink/1mp10JbaANo6FUc7)\n[![Documentation](https://img.shields.io/badge/docs-mkdocs-blue.svg)](https://json.nlohmann.me)\n[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://raw.githubusercontent.com/nlohmann/json/master/LICENSE.MIT)\n[![GitHub Releases](https://img.shields.io/github/release/nlohmann/json.svg)](https://github.com/nlohmann/json/releases)\n[![Packaging status](https://repology.org/badge/tiny-repos/nlohmann-json.svg)](https://repology.org/project/nlohmann-json/versions)\n[![GitHub Downloads](https://img.shields.io/github/downloads/nlohmann/json/total)](https://github.com/nlohmann/json/releases)\n[![GitHub Issues](https://img.shields.io/github/issues/nlohmann/json.svg)](https://github.com/nlohmann/json/issues)\n[![Average time to resolve an issue](https://isitmaintained.com/badge/resolution/nlohmann/json.svg)](https://isitmaintained.com/project/nlohmann/json \"Average time to resolve an issue\")\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/289/badge)](https://bestpractices.coreinfrastructure.org/projects/289)\n[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/nlohmann/json/badge)](https://scorecard.dev/viewer/?uri=github.com/nlohmann/json)\n[![Backup Status](https://app.cloudback.it/badge/nlohmann/json)](https://cloudback.it)\n[![GitHub Sponsors](https://img.shields.io/badge/GitHub-Sponsors-ff69b4)](https://github.com/sponsors/nlohmann)\n[![REUSE status](https://api.reuse.software/badge/github.com/nlohmann/json)](https://api.reuse.software/info/github.com/nlohmann/json)\n[![Discord](https://img.shields.io/discord/1003743314341793913)](https://discord.gg/6mrGXKvX7y)\n\n- [Design goals](#design-goals)\n- [Sponsors](#sponsors)\n- [Support](#support) ([documentation](https://json.nlohmann.me), [FAQ](https://json.nlohmann.me/home/faq/), [discussions](https://github.com/nlohmann/json/discussions), [API](https://json.nlohmann.me/api/basic_json/), [bug issues](https://github.com/nlohmann/json/issues))\n- [Quick reference](#quick-reference)\n- [Examples](#examples)\n  - [Read JSON from a file](#read-json-from-a-file)\n  - [Creating `json` objects from JSON literals](#creating-json-objects-from-json-literals)\n  - [JSON as a first-class data type](#json-as-a-first-class-data-type)\n  - [Serialization / Deserialization](#serialization--deserialization)\n  - [STL-like access](#stl-like-access)\n  - [Conversion from STL containers](#conversion-from-stl-containers)\n  - [JSON Pointer and JSON Patch](#json-pointer-and-json-patch)\n  - [JSON Merge Patch](#json-merge-patch)\n  - [Implicit conversions](#implicit-conversions)\n  - [Conversions to/from arbitrary types](#arbitrary-types-conversions)\n  - [Specializing enum conversion](#specializing-enum-conversion)\n  - [Binary formats (BSON, CBOR, MessagePack, UBJSON, and BJData)](#binary-formats-bson-cbor-messagepack-ubjson-and-bjdata)\n- [Customers](#customers)\n- [Supported compilers](#supported-compilers)\n- [Integration](#integration)\n  - [CMake](#cmake)\n  - [Package Managers](#package-managers)\n  - [Pkg-config](#pkg-config)\n- [License](#license)\n- [Contact](#contact)\n- [Thanks](#thanks)\n- [Used third-party tools](#used-third-party-tools)\n- [Notes](#notes)\n- [Execute unit tests](#execute-unit-tests)\n\n## Design goals\n\nThere are myriads of [JSON](https://json.org) libraries out there, and each may even have its reason to exist. Our class had these design goals:\n\n- **Intuitive syntax**. In languages such as Python, JSON feels like a first-class data type. We used all the operator magic of modern C++ to achieve the same feeling in your code. Check out the [examples below](#examples) and you'll know what I mean.\n\n- **Trivial integration**. Our whole code consists of a single header file [`json.hpp`](https://github.com/nlohmann/json/blob/develop/single_include/nlohmann/json.hpp). That's it. No library, no subproject, no dependencies, no complex build system. The class is written in vanilla C++11. All in all, everything should require no adjustment of your compiler flags or project settings. The library is also included in all popular [package managers](https://json.nlohmann.me/integration/package_managers/).\n\n- **Serious testing**. Our code is heavily [unit-tested](https://github.com/nlohmann/json/tree/develop/tests/src) and covers [100%](https://coveralls.io/r/nlohmann/json) of the code, including all exceptional behavior. Furthermore, we checked with [Valgrind](https://valgrind.org) and the [Clang Sanitizers](https://clang.llvm.org/docs/index.html) that there are no memory leaks. [Google OSS-Fuzz](https://github.com/google/oss-fuzz/tree/master/projects/json) additionally runs fuzz tests against all parsers 24/7, effectively executing billions of tests so far. To maintain high quality, the project is following the [Core Infrastructure Initiative (CII) best practices](https://bestpractices.coreinfrastructure.org/projects/289). See the [quality assurance](https://json.nlohmann.me/community/quality_assurance) overview documentation.\n\nOther aspects were not so important to us:\n\n- **Memory efficiency**. Each JSON object has an overhead of one pointer (the maximal size of a union) and one enumeration element (1 byte). The default generalization uses the following C++ data types: `std::string` for strings, `int64_t`, `uint64_t` or `double` for numbers, `std::map` for objects, `std::vector` for arrays, and `bool` for Booleans. However, you can template the generalized class `basic_json` to your needs.\n\n- **Speed**. There are certainly [faster JSON libraries](https://github.com/miloyip/nativejson-benchmark#parsing-time) out there. However, if your goal is to speed up your development by adding JSON support with a single header, then this library is the way to go. If you know how to use a `std::vector` or `std::map`, you are already set.\n\nSee the [contribution guidelines](https://github.com/nlohmann/json/blob/master/.github/CONTRIBUTING.md#please-dont) for more information.\n\n## Sponsors\n\nYou can sponsor this library at [GitHub Sponsors](https://github.com/sponsors/nlohmann).\n\n### :raising_hand: Priority Sponsor\n\n- [Martti Laine](https://github.com/codeclown)\n- [Paul Harrington](https://github.com/phrrngtn)\n\n### :label: Named Sponsors\n\n- [Michael Hartmann](https://github.com/reFX-Mike)\n- [Stefan Hagen](https://github.com/sthagen)\n- [Steve Sperandeo](https://github.com/homer6)\n- [Robert Jefe Lindst√§dt](https://github.com/eljefedelrodeodeljefe)\n- [Steve Wagner](https://github.com/ciroque)\n- [Lion Yang](https://github.com/LionNatsu)\n\n### Further support\n\nThe development of the library is further supported by JetBrains by providing free access to their IDE tools.\n\n[![JetBrains logo.](https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.svg)](https://jb.gg/OpenSourceSupport)\n\nThanks everyone!\n\n## Support\n\n:question: If you have a **question**, please check if it is already answered in the [**FAQ**](https://json.nlohmann.me/home/faq/) or the [**Q&A**](https://github.com/nlohmann/json/discussions/categories/q-a) section. If not, please [**ask a new question**](https://github.com/nlohmann/json/discussions/new) there.\n\n:books: If you want to **learn more** about how to use the library, check out the rest of the [**README**](#examples), have a look at [**code examples**](https://github.com/nlohmann/json/tree/develop/docs/mkdocs/docs/examples), or browse through the [**help pages**](https://json.nlohmann.me).\n\n:construction: If you want to understand the **API** better, check out the [**API Reference**](https://json.nlohmann.me/api/basic_json/) or have a look at the [quick reference](#quick-reference) below.\n\n:bug: If you found a **bug**, please check the [**FAQ**](https://json.nlohmann.me/home/faq/) if it is a known issue or the result of a design decision. Please also have a look at the [**issue list**](https://github.com/nlohmann/json/issues) before you [**create a new issue**](https://github.com/nlohmann/json/issues/new/choose). Please provide as much information as possible to help us understand and reproduce your issue.\n\nThere is also a [**docset**](https://github.com/Kapeli/Dash-User-Contributions/tree/master/docsets/JSON_for_Modern_C%2B%2B) for the documentation browsers [Dash](https://kapeli.com/dash), [Velocity](https://velocity.silverlakesoftware.com), and [Zeal](https://zealdocs.org) that contains the full [documentation](https://json.nlohmann.me) as an offline resource.\n\n## Quick reference\n\n- **Constructors** [basic_json](https://json.nlohmann.me/api/basic_json/basic_json), [array](https://json.nlohmann.me/api/basic_json/array), [binary](https://json.nlohmann.me/api/basic_json/binary), [object](https://json.nlohmann.me/api/basic_json/object)\n- **Object inspection**: [type](https://json.nlohmann.me/api/basic_json/type), [operator value_t](https://json.nlohmann.me/api/basic_json/operator_value_t), [type_name](https://json.nlohmann.me/api/basic_json/type_name), [is_primitive](https://json.nlohmann.me/api/basic_json/is_primitive), [is_structured](https://json.nlohmann.me/api/basic_json/is_structured), [is_null](https://json.nlohmann.me/api/basic_json/is_null), [is_boolean](https://json.nlohmann.me/api/basic_json/is_boolean), [is_number](https://json.nlohmann.me/api/basic_json/is_number), [is_number_integer](https://json.nlohmann.me/api/basic_json/is_number_integer), [is_number_unsigned](https://json.nlohmann.me/api/basic_json/is_number_unsigned), [is_number_float](https://json.nlohmann.me/api/basic_json/is_number_float), [is_object](https://json.nlohmann.me/api/basic_json/is_object), [is_array](https://json.nlohmann.me/api/basic_json/is_array), [is_string](https://json.nlohmann.me/api/basic_json/is_string), [is_binary](https://json.nlohmann.me/api/basic_json/is_binary), [is_discarded](https://json.nlohmann.me/api/basic_json/is_discarded)\n- **Value access**; [get](https://json.nlohmann.me/api/basic_json/get), [get_to](https://json.nlohmann.me/api/basic_json/get_to), [get_ptr](https://json.nlohmann.me/api/basic_json/get_ptr), [get_ref](https://json.nlohmann.me/api/basic_json/get_ref), [operator ValueType](https://json.nlohmann.me/api/basic_json/operator_ValueType), [get_binary](https://json.nlohmann.me/api/basic_json/get_binary)\n- **Element access**: [at](https://json.nlohmann.me/api/basic_json/at), [operator[]](https://json.nlohmann.me/api/basic_json/operator[]), [value](https://json.nlohmann.me/api/basic_json/value), [front](https://json.nlohmann.me/api/basic_json/front), [back](https://json.nlohmann.me/api/basic_json/back)\n- **Lookup**: [find](https://json.nlohmann.me/api/basic_json/find), [count](https://json.nlohmann.me/api/basic_json/count), [contains](https://json.nlohmann.me/api/basic_json/contains)\n- **Iterators**: [begin](https://json.nlohmann.me/api/basic_json/begin), [cbegin](https://json.nlohmann.me/api/basic_json/cbegin), [end](https://json.nlohmann.me/api/basic_json/end), [cend](https://json.nlohmann.me/api/basic_json/cend), [rbegin](https://json.nlohmann.me/api/basic_json/rbegin), [rend](https://json.nlohmann.me/api/basic_json/rend), [crbegin](https://json.nlohmann.me/api/basic_json/crbegin), [crend](https://json.nlohmann.me/api/basic_json/crend), [items](https://json.nlohmann.me/api/basic_json/items)\n- **Capacity**: [empty](https://json.nlohmann.me/api/basic_json/empty), [size](https://json.nlohmann.me/api/basic_json/size), [max_size](https://json.nlohmann.me/api/basic_json/max_size)\n- **Modifiers**: [clear](https://json.nlohmann.me/api/basic_json/clear), [push_back](https://json.nlohmann.me/api/basic_json/push_back), [operator+=](https://json.nlohmann.me/api/basic_json/operator+=), [emplace_back](https://json.nlohmann.me/api/basic_json/emplace_back), [emplace](https://json.nlohmann.me/api/basic_json/emplace), [erase](https://json.nlohmann.me/api/basic_json/erase), [insert](https://json.nlohmann.me/api/basic_json/insert), [update](https://json.nlohmann.me/api/basic_json/update), [swap](https://json.nlohmann.me/api/basic_json/swap)\n- **Lexicographical comparison operators**: [operator==](https://json.nlohmann.me/api/basic_json/operator_eq), [operator!=](https://json.nlohmann.me/api/basic_json/operator_ne), [operator<](https://json.nlohmann.me/api/basic_json/operator_lt), [operator>](https://json.nlohmann.me/api/basic_json/operator_gt), [operator<=](https://json.nlohmann.me/api/basic_json/operator_le), [operator>=](https://json.nlohmann.me/api/basic_json/operator_ge), [operator<=>](https://json.nlohmann.me/api/basic_json/operator_spaceship)\n- **Serialization / Dumping**: [dump](https://json.nlohmann.me/api/basic_json/dump)\n- **Deserialization / Parsing**: [parse](https://json.nlohmann.me/api/basic_json/parse), [accept](https://json.nlohmann.me/api/basic_json/accept), [sax_parse](https://json.nlohmann.me/api/basic_json/sax_parse)\n- **JSON Pointer functions**: [flatten](https://json.nlohmann.me/api/basic_json/flatten), [unflatten](https://json.nlohmann.me/api/basic_json/unflatten)\n- **JSON Patch functions**: [patch](https://json.nlohmann.me/api/basic_json/patch), [patch_inplace](https://json.nlohmann.me/api/basic_json/patch_inplace), [diff](https://json.nlohmann.me/api/basic_json/diff), [merge_patch](https://json.nlohmann.me/api/basic_json/merge_patch)\n- **Static functions**: [meta](https://json.nlohmann.me/api/basic_json/meta), [get_allocator](https://json.nlohmann.me/api/basic_json/get_allocator)\n- **Binary formats**: [from_bjdata](https://json.nlohmann.me/api/basic_json/from_bjdata), [from_bson](https://json.nlohmann.me/api/basic_json/from_bson), [from_cbor](https://json.nlohmann.me/api/basic_json/from_cbor), [from_msgpack](https://json.nlohmann.me/api/basic_json/from_msgpack), [from_ubjson](https://json.nlohmann.me/api/basic_json/from_ubjson), [to_bjdata](https://json.nlohmann.me/api/basic_json/to_bjdata), [to_bson](https://json.nlohmann.me/api/basic_json/to_bson), [to_cbor](https://json.nlohmann.me/api/basic_json/to_cbor), [to_msgpack](https://json.nlohmann.me/api/basic_json/to_msgpack), [to_ubjson](https://json.nlohmann.me/api/basic_json/to_ubjson)\n- **Non-member functions**: [operator<<](https://json.nlohmann.me/api/operator_ltlt/), [operator>>](https://json.nlohmann.me/api/operator_gtgt/), [to_string](https://json.nlohmann.me/api/basic_json/to_string)\n- **Literals**: [operator\"\"_json](https://json.nlohmann.me/api/operator_literal_json)\n- **Helper classes**: [std::hash&lt;basic_json&gt;](https://json.nlohmann.me/api/basic_json/std_hash), [std::swap&lt;basic_json&gt;](https://json.nlohmann.me/api/basic_json/std_swap)\n\n[**Full API documentation**](https://json.nlohmann.me/api/basic_json/)\n\n## Examples\n\nHere are some examples to give you an idea how to use the class.\n\nBesides the examples below, you may want to:\n\n‚Üí Check the [documentation](https://json.nlohmann.me/)\\\n‚Üí Browse the [standalone example files](https://github.com/nlohmann/json/tree/develop/docs/mkdocs/docs/examples)\\\n‚Üí Read the full [API Documentation](https://json.nlohmann.me/api/basic_json/) with self-contained examples for every function\n\n### Read JSON from a file\n\nThe `json` class provides an API for manipulating a JSON value. To create a `json` object by reading a JSON file:\n\n```cpp\n#include <fstream>\n#include <nlohmann/json.hpp>\nusing json = nlohmann::json;\n\n// ...\n\nstd::ifstream f(\"example.json\");\njson data = json::parse(f);\n```\n\nIf using modules (enabled with `NLOHMANN_JSON_BUILD_MODULES`), this example becomes:\n```cpp\nimport std;\nimport nlohmann.json;\n\nusing json = nlohmann::json;\n\n// ...\n\nstd::ifstream f(\"example.json\");\njson data = json::parse(f);\n```\n\n### Creating `json` objects from JSON literals\n\nAssume you want to create hard-code this literal JSON value in a file, as a `json` object:\n\n```json\n{\n  \"pi\": 3.141,\n  \"happy\": true\n}\n```\n\nThere are various options:\n\n```cpp\n// Using (raw) string literals and json::parse\njson ex1 = json::parse(R\"(\n  {\n    \"pi\": 3.141,\n    \"happy\": true\n  }\n)\");\n\n// Using user-defined (raw) string literals\nusing namespace nlohmann::literals;\njson ex2 = R\"(\n  {\n    \"pi\": 3.141,\n    \"happy\": true\n  }\n)\"_json;\n\n// Using initializer lists\njson ex3 = {\n  {\"happy\", true},\n  {\"pi\", 3.141},\n};\n```\n\n### JSON as a first-class data type\n\nHere are some examples to give you an idea how to use the class.\n\nAssume you want to create the JSON object\n\n```json\n{\n  \"pi\": 3.141,\n  \"happy\": true,\n  \"name\": \"Niels\",\n  \"nothing\": null,\n  \"answer\": {\n    \"everything\": 42\n  },\n  \"list\": [1, 0, 2],\n  \"object\": {\n    \"currency\": \"USD\",\n    \"value\": 42.99\n  }\n}\n```\n\nWith this library, you could write:\n\n```cpp\n// create an empty structure (null)\njson j;\n\n// add a number stored as double (note the implicit conversion of j to an object)\nj[\"pi\"] = 3.141;\n\n// add a Boolean stored as bool\nj[\"happy\"] = true;\n\n// add a string stored as std::string\nj[\"name\"] = \"Niels\";\n\n// add another null object by passing nullptr\nj[\"nothing\"] = nullptr;\n\n// add an object inside the object\nj[\"answer\"][\"everything\"] = 42;\n\n// add an array stored as std::vector (using an initializer list)\nj[\"list\"] = { 1, 0, 2 };\n\n// add another object (using an initializer list of pairs)\nj[\"object\"] = { {\"currency\", \"USD\"}, {\"value\", 42.99} };\n\n// instead, you could also write (which looks very similar to the JSON above)\njson j2 = {\n  {\"pi\", 3.141},\n  {\"happy\", true},\n  {\"name\", \"Niels\"},\n  {\"nothing\", nullptr},\n  {\"answer\", {\n    {\"everything\", 42}\n  }},\n  {\"list\", {1, 0, 2}},\n  {\"object\", {\n    {\"currency\", \"USD\"},\n    {\"value\", 42.99}\n  }}\n};\n```\n\nNote that in all these cases, you never need to \"tell\" the compiler which JSON value type you want to use. If you want to be explicit or express some edge cases, the functions [`json::array()`](https://json.nlohmann.me/api/basic_json/array/) and [`json::object()`](https://json.nlohmann.me/api/basic_json/object/) will help:\n\n```cpp\n// a way to express the empty array []\njson empty_array_explicit = json::array();\n\n// ways to express the empty object {}\njson empty_object_implicit = json({});\njson empty_object_explicit = json::object();\n\n// a way to express an _array_ of key/value pairs [[\"currency\", \"USD\"], [\"value\", 42.99]]\njson array_not_object = json::array({ {\"currency\", \"USD\"}, {\"value\", 42.99} });\n```\n\n### Serialization / Deserialization\n\n#### To/from strings\n\nYou can create a JSON value (deserialization) by appending `_json` to a string literal:\n\n```cpp\n// create object from string literal\njson j = \"{ \\\"happy\\\": true, \\\"pi\\\": 3.141 }\"_json;\n\n// or even nicer with a raw string literal\nauto j2 = R\"(\n  {\n    \"happy\": true,\n    \"pi\": 3.141\n  }\n)\"_json;\n```\n\nNote that without appending the `_json` suffix, the passed string literal is not parsed, but just used as JSON string\nvalue. That is, `json j = \"{ \\\"happy\\\": true, \\\"pi\\\": 3.141 }\"` would just store the string\n`\"{ \"happy\": true, \"pi\": 3.141 }\"` rather than parsing the actual object.\n\nThe string literal should be brought into scope with `using namespace nlohmann::literals;`\n(see [`json::parse()`](https://json.nlohmann.me/api/operator_literal_json/)).\n\nThe above example can also be expressed explicitly using [`json::parse()`](https://json.nlohmann.me/api/basic_json/parse/):\n\n```cpp\n// parse explicitly\nauto j3 = json::parse(R\"({\"happy\": true, \"pi\": 3.141})\");\n```\n\nYou can also get a string representation of a JSON value (serialize):\n\n```cpp\n// explicit conversion to string\nstd::string s = j.dump();    // {\"happy\":true,\"pi\":3.141}\n\n// serialization with pretty printing\n// pass in the amount of spaces to indent\nstd::cout << j.dump(4) << std::endl;\n// {\n//     \"happy\": true,\n//     \"pi\": 3.141\n// }\n```\n\nNote the difference between serialization and assignment:\n\n```cpp\n// store a string in a JSON value\njson j_string = \"this is a string\";\n\n// retrieve the string value\nauto cpp_string = j_string.get<std::string>();\n// retrieve the string value (alternative when a variable already exists)\nstd::string cpp_string2;\nj_string.get_to(cpp_string2);\n\n// retrieve the serialized value (explicit JSON serialization)\nstd::string serialized_string = j_string.dump();\n\n// output of original string\nstd::cout << cpp_string << \" == \" << cpp_string2 << \" == \" << j_string.get<std::string>() << '\\n';\n// output of serialized value\nstd::cout << j_string << \" == \" << serialized_string << std::endl;\n```\n\n[`.dump()`](https://json.nlohmann.me/api/basic_json/dump/) returns the originally stored string value.\n\nNote the library only supports UTF-8. When you store strings with different encodings in the library, calling [`dump()`](https://json.nlohmann.me/api/basic_json/dump/) may throw an exception unless `json::error_handler_t::replace` or `json::error_handler_t::ignore` are used as error handlers.\n\n#### To/from streams (e.g., files, string streams)\n\nYou can also use streams to serialize and deserialize:\n\n```cpp\n// deserialize from standard input\njson j;\nstd::cin >> j;\n\n// serialize to standard output\nstd::cout << j;\n\n// the setw manipulator was overloaded to set the indentation for pretty printing\nstd::cout << std::setw(4) << j << std::endl;\n```\n\nThese operators work for any subclasses of `std::istream` or `std::ostream`. Here is the same example with files:\n\n```cpp\n// read a JSON file\nstd::ifstream i(\"file.json\");\njson j;\ni >> j;\n\n// write prettified JSON to another file\nstd::ofstream o(\"pretty.json\");\no << std::setw(4) << j << std::endl;\n```\n\nPlease note that setting the exception bit for `failbit` is inappropriate for this use case. It will result in program termination due to the `noexcept` specifier in use.\n\n#### Read from iterator range\n\nYou can also parse JSON from an iterator range; that is, from any container accessible by iterators whose `value_type` is an integral type of 1, 2, or 4 bytes, which will be interpreted as UTF-8, UTF-16, and UTF-32 respectively. For instance, a `std::vector<std::uint8_t>`, or a `std::list<std::uint16_t>`:\n\n```cpp\nstd::vector<std::uint8_t> v = {'t', 'r', 'u', 'e'};\njson j = json::parse(v.begin(), v.end());\n```\n\nYou may leave the iterators for the range [begin, end):\n\n```cpp\nstd::vector<std::uint8_t> v = {'t', 'r', 'u', 'e'};\njson j = json::parse(v);\n```\n\n#### Custom data source\n\nSince the parse function accepts arbitrary iterator ranges, you can provide your own data sources by implementing the `LegacyInputIterator` concept.\n\n```cpp\nstruct MyContainer {\n  void advance();\n  const char& get_current();\n};\n\nstruct MyIterator {\n    using difference_type = std::ptrdiff_t;\n    using value_type = char;\n    using pointer = const char*;\n    using reference = const char&;\n    using iterator_category = std::input_iterator_tag;\n\n    MyIterator& operator++() {\n        target->advance();\n        return *this;\n    }\n\n    bool operator!=(const MyIterator& rhs) const {\n        return rhs.target != target;\n    }\n\n    reference operator*() const {\n        return target->get_current();\n    }\n\n    MyContainer* target = nullptr;\n};\n\nMyIterator begin(MyContainer& tgt) {\n    return MyIterator{&tgt};\n}\n\nMyIterator end(const MyContainer&) {\n    return {};\n}\n\nvoid foo() {\n    MyContainer c;\n    json j = json::parse(c);\n}\n```\n\n#### SAX interface\n\nThe library uses a SAX-like interface with the following functions:\n\n```cpp\n// called when null is parsed\nbool null();\n\n// called when a boolean is parsed; value is passed\nbool boolean(bool val);\n\n// called when a signed or unsigned integer number is parsed; value is passed\nbool number_integer(number_integer_t val);\nbool number_unsigned(number_unsigned_t val);\n\n// called when a floating-point number is parsed; value and original string is passed\nbool number_float(number_float_t val, const string_t& s);\n\n// called when a string is parsed; value is passed and can be safely moved away\nbool string(string_t& val);\n// called when a binary value is parsed; value is passed and can be safely moved away\nbool binary(binary_t& val);\n\n// called when an object or array begins or ends, resp. The number of elements is passed (or -1 if not known)\nbool start_object(std::size_t elements);\nbool end_object();\nbool start_array(std::size_t elements);\nbool end_array();\n// called when an object key is parsed; value is passed and can be safely moved away\nbool key(string_t& val);\n\n// called when a parse error occurs; byte position, the last token, and an exception is passed\nbool parse_error(std::size_t position, const std::string& last_token, const detail::exception& ex);\n```\n\nThe return value of each function determines whether parsing should proceed.\n\nTo implement your own SAX handler, proceed as follows:\n\n1. Implement the SAX interface in a class. You can use class `nlohmann::json_sax<json>` as base class, but you can also use any class where the functions described above are implemented and public.\n2. Create an object of your SAX interface class, e.g. `my_sax`.\n3. Call `bool json::sax_parse(input, &my_sax)`; where the first parameter can be any input like a string or an input stream and the second parameter is a pointer to your SAX interface.\n\nNote the `sax_parse` function only returns a `bool` indicating the result of the last executed SAX event. It does not return a  `json` value - it is up to you to decide what to do with the SAX events. Furthermore, no exceptions are thrown in case of a parse error -- it is up to you what to do with the exception object passed to your `parse_error` implementation. Internally, the SAX interface is used for the DOM parser (class `json_sax_dom_parser`) as well as the acceptor (`json_sax_acceptor`), see file [`json_sax.hpp`](https://github.com/nlohmann/json/blob/develop/include/nlohmann/detail/input/json_sax.hpp).\n\n### STL-like access\n\nWe designed the JSON class to behave just like an STL container. In fact, it satisfies the [**ReversibleContainer**](https://en.cppreference.com/w/cpp/named_req/ReversibleContainer) requirement.\n\n```cpp\n// create an array using push_back\njson j;\nj.push_back(\"foo\");\nj.push_back(1);\nj.push_back(true);\n\n// also use emplace_back\nj.emplace_back(1.78);\n\n// iterate the array\nfor (json::iterator it = j.begin(); it != j.end(); ++it) {\n  std::cout << *it << '\\n';\n}\n\n// range-based for\nfor (auto& element : j) {\n  std::cout << element << '\\n';\n}\n\n// getter/setter\nconst auto tmp = j[0].get<std::string>();\nj[1] = 42;\nbool foo = j.at(2);\n\n// comparison\nj == R\"([\"foo\", 1, true, 1.78])\"_json;  // true\n\n// other stuff\nj.size();     // 4 entries\nj.empty();    // false\nj.type();     // json::value_t::array\nj.clear();    // the array is empty again\n\n// convenience type checkers\nj.is_null();\nj.is_boolean();\nj.is_number();\nj.is_object();\nj.is_array();\nj.is_string();\n\n// create an object\njson o;\no[\"foo\"] = 23;\no[\"bar\"] = false;\no[\"baz\"] = 3.141;\n\n// also use emplace\no.emplace(\"weather\", \"sunny\");\n\n// special iterator member functions for objects\nfor (json::iterator it = o.begin(); it != o.end(); ++it) {\n  std::cout << it.key() << \" : \" << it.value() << \"\\n\";\n}\n\n// the same code as range for\nfor (auto& el : o.items()) {\n  std::cout << el.key() << \" : \" << el.value() << \"\\n\";\n}\n\n// even easier with structured bindings (C++17)\nfor (auto& [key, value] : o.items()) {\n  std::cout << key << \" : \" << value << \"\\n\";\n}\n\n// find an entry\nif (o.contains(\"foo\")) {\n  // there is an entry with key \"foo\"\n}\n\n// or via find and an iterator\nif (o.find(\"foo\") != o.end()) {\n  // there is an entry with key \"foo\"\n}\n\n// or simpler using count()\nint foo_present = o.count(\"foo\"); // 1\nint fob_present = o.count(\"fob\"); // 0\n\n// delete an entry\no.erase(\"foo\");\n```\n\n### Conversion from STL containers\n\nAny sequence container (`std::array`, `std::vector`, `std::deque`, `std::forward_list`, `std::list`) whose values can be used to construct JSON values (e.g., integers, floating point numbers, Booleans, string types, or again STL containers described in this section) can be used to create a JSON array. The same holds for similar associative containers (`std::set`, `std::multiset`, `std::unordered_set`, `std::unordered_multiset`), but in these cases the order of the elements of the array depends on how the elements are ordered in the respective STL container.\n\n```cpp\nstd::vector<int> c_vector {1, 2, 3, 4};\njson j_vec(c_vector);\n// [1, 2, 3, 4]\n\nstd::deque<double> c_deque {1.2, 2.3, 3.4, 5.6};\njson j_deque(c_deque);\n// [1.2, 2.3, 3.4, 5.6]\n\nstd::list<bool> c_list {true, true, false, true};\njson j_list(c_list);\n// [true, true, false, true]\n\nstd::forward_list<int64_t> c_flist {12345678909876, 23456789098765, 34567890987654, 45678909876543};\njson j_flist(c_flist);\n// [12345678909876, 23456789098765, 34567890987654, 45678909876543]\n\nstd::array<unsigned long, 4> c_array {{1, 2, 3, 4}};\njson j_array(c_array);\n// [1, 2, 3, 4]\n\nstd::set<std::string> c_set {\"one\", \"two\", \"three\", \"four\", \"one\"};\njson j_set(c_set); // only one entry for \"one\" is used\n// [\"four\", \"one\", \"three\", \"two\"]\n\nstd::unordered_set<std::string> c_uset {\"one\", \"two\", \"three\", \"four\", \"one\"};\njson j_uset(c_uset); // only one entry for \"one\" is used\n// maybe [\"two\", \"three\", \"four\", \"one\"]\n\nstd::multiset<std::string> c_mset {\"one\", \"two\", \"one\", \"four\"};\njson j_mset(c_mset); // both entries for \"one\" are used\n// maybe [\"one\", \"two\", \"one\", \"four\"]\n\nstd::unordered_multiset<std::string> c_umset {\"one\", \"two\", \"one\", \"four\"};\njson j_umset(c_umset); // both entries for \"one\" are used\n// maybe [\"one\", \"two\", \"one\", \"four\"]\n```\n\nLikewise, any associative key-value containers (`std::map`, `std::multimap`, `std::unordered_map`, `std::unordered_multimap`) whose keys can construct an `std::string` and whose values can be used to construct JSON values (see examples above) can be used to create a JSON object. Note that in case of multimaps, only one key is used in the JSON object and the value depends on the internal order of the STL container.\n\n```cpp\nstd::map<std::string, int> c_map { {\"one\", 1}, {\"two\", 2}, {\"three\", 3} };\njson j_map(c_map);\n// {\"one\": 1, \"three\": 3, \"two\": 2 }\n\nstd::unordered_map<const char*, double> c_umap { {\"one\", 1.2}, {\"two\", 2.3}, {\"three\", 3.4} };\njson j_umap(c_umap);\n// {\"one\": 1.2, \"two\": 2.3, \"three\": 3.4}\n\nstd::multimap<std::string, bool> c_mmap { {\"one\", true}, {\"two\", true}, {\"three\", false}, {\"three\", true} };\njson j_mmap(c_mmap); // only one entry for key \"three\" is used\n// maybe {\"one\": true, \"two\": true, \"three\": true}\n\nstd::unordered_multimap<std::string, bool> c_ummap { {\"one\", true}, {\"two\", true}, {\"three\", false}, {\"three\", true} };\njson j_ummap(c_ummap); // only one entry for key \"three\" is used\n// maybe {\"one\": true, \"two\": true, \"three\": true}\n```\n\n### JSON Pointer and JSON Patch\n\nThe library supports **JSON Pointer** ([RFC 6901](https://tools.ietf.org/html/rfc6901)) as an alternative means to address structured values. On top of this, **JSON Patch** ([RFC 6902](https://tools.ietf.org/html/rfc6902)) allows describing differences between two JSON values -- effectively allowing patch and diff operations known from Unix.\n\n```cpp\n// a JSON value\njson j_original = R\"({\n  \"baz\": [\"one\", \"two\", \"three\"],\n  \"foo\": \"bar\"\n})\"_json;\n\n// access members with a JSON pointer (RFC 6901)\nj_original[\"/baz/1\"_json_pointer];\n// \"two\"\n\n// a JSON patch (RFC 6902)\njson j_patch = R\"([\n  { \"op\": \"replace\", \"path\": \"/baz\", \"value\": \"boo\" },\n  { \"op\": \"add\", \"path\": \"/hello\", \"value\": [\"world\"] },\n  { \"op\": \"remove\", \"path\": \"/foo\"}\n])\"_json;\n\n// apply the patch\njson j_result = j_original.patch(j_patch);\n// {\n//    \"baz\": \"boo\",\n//    \"hello\": [\"world\"]\n// }\n\n// calculate a JSON patch from two JSON values\njson::diff(j_result, j_original);\n// [\n//   { \"op\":\" replace\", \"path\": \"/baz\", \"value\": [\"one\", \"two\", \"three\"] },\n//   { \"op\": \"remove\",\"path\": \"/hello\" },\n//   { \"op\": \"add\", \"path\": \"/foo\", \"value\": \"bar\" }\n// ]\n```\n\n### JSON Merge Patch\n\nThe library supports **JSON Merge Patch** ([RFC 7386](https://tools.ietf.org/html/rfc7386)) as a patch format. Instead of using JSON Pointer (see above) to specify values to be manipulated, it describes the changes using a syntax that closely mimics the document being modified.\n\n```cpp\n// a JSON value\njson j_document = R\"({\n  \"a\": \"b\",\n  \"c\": {\n    \"d\": \"e\",\n    \"f\": \"g\"\n  }\n})\"_json;\n\n// a patch\njson j_patch = R\"({\n  \"a\":\"z\",\n  \"c\": {\n    \"f\": null\n  }\n})\"_json;\n\n// apply the patch\nj_document.merge_patch(j_patch);\n// {\n//  \"a\": \"z\",\n//  \"c\": {\n//    \"d\": \"e\"\n//  }\n// }\n```\n\n### Implicit conversions\n\nSupported types can be implicitly converted to JSON values.\n\nIt is recommended to **NOT USE** implicit conversions **FROM** a JSON value.\nYou can find more details about this recommendation [here](https://www.github.com/nlohmann/json/issues/958).\nYou can switch off implicit conversions by defining `JSON_USE_IMPLICIT_CONVERSIONS` to `0` before including the `json.hpp` header. When using CMake, you can also achieve this by setting the option `JSON_ImplicitConversions` to `OFF`.\n\n```cpp\n// strings\nstd::string s1 = \"Hello, world!\";\njson js = s1;\nauto s2 = js.get<std::string>();\n// NOT RECOMMENDED\nstd::string s3 = js;\nstd::string s4;\ns4 = js;\n\n// Booleans\nbool b1 = true;\njson jb = b1;\nauto b2 = jb.get<bool>();\n// NOT RECOMMENDED\nbool b3 = jb;\nbool b4;\nb4 = jb;\n\n// numbers\nint i = 42;\njson jn = i;\nauto f = jn.get<double>();\n// NOT RECOMMENDED\ndouble f2 = jb;\ndouble f3;\nf3 = jb;\n\n// etc.\n```\n\nNote that `char` types are not automatically converted to JSON strings, but to integer numbers. A conversion to a string must be specified explicitly:\n\n```cpp\nchar ch = 'A';                       // ASCII value 65\njson j_default = ch;                 // stores integer number 65\njson j_string = std::string(1, ch);  // stores string \"A\"\n```\n\n### Arbitrary types conversions\n\nEvery type can be serialized in JSON, not just STL containers and scalar types. Usually, you would do something along those lines:\n\n```cpp\nnamespace ns {\n    // a simple struct to model a person\n    struct person {\n        std::string name;\n        std::string address;\n        int age;\n    };\n}\n\nns::person p = {\"Ned Flanders\", \"744 Evergreen Terrace\", 60};\n\n// convert to JSON: copy each value into the JSON object\njson j;\nj[\"name\"] = p.name;\nj[\"address\"] = p.address;\nj[\"age\"] = p.age;\n\n// ...\n\n// convert from JSON: copy each value from the JSON object\nns::person p {\n    j[\"name\"].get<std::string>(),\n    j[\"address\"].get<std::string>(),\n    j[\"age\"].get<int>()\n};\n```\n\nIt works, but that's quite a lot of boilerplate... Fortunately, there's a better way:\n\n```cpp\n// create a person\nns::person p {\"Ned Flanders\", \"744 Evergreen Terrace\", 60};\n\n// conversion: person -> json\njson j = p;\n\nstd::cout << j << std::endl;\n// {\"address\":\"744 Evergreen Terrace\",\"age\":60,\"name\":\"Ned Flanders\"}\n\n// conversion: json -> person\nauto p2 = j.get<ns::person>();\n\n// that's it\nassert(p == p2);\n```\n\n#### Basic usage\n\nTo make this work with one of your types, you only need to provide two functions:\n\n```cpp\nusing json = nlohmann::json;\n\nnamespace ns {\n    void to_json(json& j, const person& p) {\n        j = json{{\"name\", p.name}, {\"address\", p.address}, {\"age\", p.age}};\n    }\n\n    void from_json(const json& j, person& p) {\n        j.at(\"name\").get_to(p.name);\n        j.at(\"address\").get_to(p.address);\n        j.at(\"age\").get_to(p.age);\n    }\n} // namespace ns\n```\n\nThat's all! When calling the `json` constructor with your type, your custom `to_json` method will be automatically called.\nLikewise, when calling `get<your_type>()` or `get_to(your_type&)`, the `from_json` method will be called.\n\nSome important things:\n\n- Those methods **MUST** be in your type's namespace (which can be the global namespace), or the library will not be able to locate them (in this example, they are in namespace `ns`, where `person` is defined).\n- Those methods **MUST** be available (e.g., proper headers must be included) everywhere you use these conversions. Look at [issue 1108](https://github.com/nlohmann/json/issues/1108) for errors that may occur otherwise.\n- When using `get<your_type>()`, `your_type` **MUST** be [DefaultConstructible](https://en.cppreference.com/w/cpp/named_req/DefaultConstructible). (There is a way to bypass this requirement described later.)\n- In function `from_json`, use function [`at()`](https://json.nlohmann.me/api/basic_json/at/) to access the object values rather than `operator[]`. In case a key does not exist, `at` throws an exception that you can handle, whereas `operator[]` exhibits undefined behavior.\n- You do not need to add serializers or deserializers for STL types like `std::vector`: the library already implements these.\n\n#### Simplify your life with macros\n\nIf you just want to serialize/deserialize some structs, the `to_json`/`from_json` functions can be a lot of boilerplate. There are [**several macros**](https://json.nlohmann.me/features/arbitrary_types/#simplify-your-life-with-macros) to make your life easier as long as you (1) want to use a JSON object as serialization and (2) want to use the member variable names as object keys in that object.\n\nWhich macro to choose depends on whether private member variables need to be accessed, a deserialization is needed, missing values should yield an error or should be replaced by default values, and if derived classes are used. See [this overview to choose the right one for your use case](https://json.nlohmann.me/api/macros/#serializationdeserialization-macros).\n\n##### Example usage of macros\n\nThe `to_json`/`from_json` functions for the `person` struct above can be created with [`NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE`](https://json.nlohmann.me/api/macros/nlohmann_define_type_non_intrusive/). In all macros, the first parameter is the name of the class/struct, and all remaining parameters name the members.\n\n```cpp\nnamespace ns {\n    NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE(person, name, address, age)\n}\n```\n\nHere is another example with private members, where [`NLOHMANN_DEFINE_TYPE_INTRUSIVE`](https://json.nlohmann.me/api/macros/nlohmann_define_type_intrusive/) is needed:\n\n```cpp\nnamespace ns {\n    class address {\n      private:\n        std::string street;\n        int housenumber;\n        int postcode;\n  \n      public:\n        NLOHMANN_DEFINE_TYPE_INTRUSIVE(address, street, housenumber, postcode)\n    };\n}\n```\n\n#### How do I convert third-party types?\n\nThis requires a bit more advanced technique. But first, let's see how this conversion mechanism works:\n\nThe library uses **JSON Serializers** to convert types to JSON.\nThe default serializer for `nlohmann::json` is `nlohmann::adl_serializer` (ADL means [Argument-Dependent Lookup](https://en.cppreference.com/w/cpp/language/adl)).\n\nIt is implemented like this (simplified):\n\n```cpp\ntemplate <typename T>\nstruct adl_serializer {\n    static void to_json(json& j, const T& value) {\n        // calls the \"to_json\" method in T's namespace\n    }\n\n    static void from_json(const json& j, T& value) {\n        // same thing, but with the \"from_json\" method\n    }\n};\n```\n\nThis serializer works fine when you have control over the type's namespace. However, what about `boost::optional` or `std::filesystem::path` (C++17)? Hijacking the `boost` namespace is pretty bad, and it's illegal to add something other than template specializations to `std`...\n\nTo solve this, you need to add a specialization of `adl_serializer` to the `nlohmann` namespace, here's an example:\n\n```cpp\n// partial specialization (full specialization works too)\nnamespace nlohmann {\n    template <typename T>\n    struct adl_serializer<boost::optional<T>> {\n        static void to_json(json& j, const boost::optional<T>& opt) {\n            if (opt == boost::none) {\n                j = nullptr;\n            } else {\n              j = *opt; // this will call adl_serializer<T>::to_json which will\n                        // find the free function to_json in T's namespace!\n            }\n        }\n\n        static void from_json(const json& j, boost::optional<T>& opt) {\n            if (j.is_null()) {\n                opt = boost::none;\n            } else {\n                opt = j.get<T>(); // same as above, but with\n                                  // adl_serializer<T>::from_json\n            }\n        }\n    };\n}\n```\n\n#### How can I use `get()` for non-default constructible/non-copyable types?\n\nThere is a way if your type is [MoveConstructible](https://en.cppreference.com/w/cpp/named_req/MoveConstructible). You will need to specialize the `adl_serializer` as well, but with a special `from_json` overload:\n\n```cpp\nstruct move_only_type {\n    move_only_type() = delete;\n    move_only_type(int ii): i(ii) {}\n    move_only_type(const move_only_type&) = delete;\n    move_only_type(move_only_type&&) = default;\n\n    int i;\n};\n\nnamespace nlohmann {\n    template <>\n    struct adl_serializer<move_only_type> {\n        // note: the return type is no longer 'void', and the method only takes\n        // one argument\n        static move_only_type from_json(const json& j) {\n            return {j.get<int>()};\n        }\n\n        // Here's the catch! You must provide a to_json method! Otherwise, you\n        // will not be able to convert move_only_type to json, since you fully\n        // specialized adl_serializer on that type\n        static void to_json(json& j, move_only_type t) {\n            j = t.i;\n        }\n    };\n}\n```\n\n#### Can I write my own serializer? (Advanced use)\n\nYes. You might want to take a look at [`unit-udt.cpp`](https://github.com/nlohmann/json/blob/develop/tests/src/unit-udt.cpp) in the test suite, to see a few examples.\n\nIf you write your own serializer, you'll need to do a few things:\n\n- use a different `basic_json` alias than `nlohmann::json` (the last template parameter of `basic_json` is the `JSONSerializer`)\n- use your `basic_json` alias (or a template parameter) in all your `to_json`/`from_json` methods\n- use `nlohmann::to_json` and `nlohmann::from_json` when you need ADL\n\nHere is an example, without simplifications, that only accepts types with a size <= 32, and uses ADL.\n\n```cpp\n// You should use void as a second template argument\n// if you don't need compile-time checks on T\ntemplate<typename T, typename SFINAE = typename std::enable_if<sizeof(T) <= 32>::type>\nstruct less_than_32_serializer {\n    template <typename BasicJsonType>\n    static void to_json(BasicJsonType& j, T value) {\n        // we want to use ADL, and call the correct to_json overload\n        using nlohmann::to_json; // this method is called by adl_serializer,\n                                 // this is where the magic happens\n        to_json(j, value);\n    }\n\n    template <typename BasicJsonType>\n    static void from_json(const BasicJsonType& j, T& value) {\n        // same thing here\n        using nlohmann::from_json;\n        from_json(j, value);\n    }\n};\n```\n\nBe **very** careful when reimplementing your serializer, you can stack overflow if you don't pay attention:\n\n```cpp\ntemplate <typename T, void>\nstruct bad_serializer\n{\n    template <typename BasicJsonType>\n    static void to_json(BasicJsonType& j, const T& value) {\n      // this calls BasicJsonType::json_serializer<T>::to_json(j, value)\n      // if BasicJsonType::json_serializer == bad_serializer ... oops!\n      j = value;\n    }\n\n    template <typename BasicJsonType>\n    static void to_json(const BasicJsonType& j, T& value) {\n      // this calls BasicJsonType::json_serializer<T>::from_json(j, value)\n      // if BasicJsonType::json_serializer == bad_serializer ... oops!\n      value = j.get<T>(); // oops!\n    }\n};\n```\n\n### Specializing enum conversion\n\nBy default, enum values are serialized to JSON as integers. In some cases, this could result in undesired behavior. If an enum is modified or re-ordered after data has been serialized to JSON, the later deserialized JSON data may be undefined or a different enum value than was originally intended.\n\nIt is possible to more precisely specify how a given enum is mapped to and from JSON as shown below:\n\n```cpp\n// example enum type declaration\nenum TaskState {\n    TS_STOPPED,\n    TS_RUNNING,\n    TS_COMPLETED,\n    TS_INVALID=-1,\n};\n\n// map TaskState values to JSON as strings\nNLOHMANN_JSON_SERIALIZE_ENUM( TaskState, {\n    {TS_INVALID, nullptr},\n    {TS_STOPPED, \"stopped\"},\n    {TS_RUNNING, \"running\"},\n    {TS_COMPLETED, \"completed\"},\n})\n```\n\nThe `NLOHMANN_JSON_SERIALIZE_ENUM()` macro declares a set of `to_json()` / `from_json()` functions for type `TaskState` while avoiding repetition and boilerplate serialization code.\n\n**Usage:**\n\n```cpp\n// enum to JSON as string\njson j = TS_STOPPED;\nassert(j == \"stopped\");\n\n// json string to enum\njson j3 = \"running\";\nassert(j3.get<TaskState>() == TS_RUNNING);\n\n// undefined json value to enum (where the first map entry above is the default)\njson jPi = 3.14;\nassert(jPi.get<TaskState>() == TS_INVALID);\n```\n\nJust as in [Arbitrary Type Conversions](#arbitrary-types-conversions) above,\n\n- `NLOHMANN_JSON_SERIALIZE_ENUM()` MUST be declared in your enum type's namespace (which can be the global namespace), or the library will not be able to locate it, and it will default to integer serialization.\n- It MUST be available (e.g., proper headers must be included) everywhere you use the conversions.\n\nOther Important points:\n\n- When using `get<ENUM_TYPE>()`, undefined JSON values will default to the first pair specified in your map. Select this default pair carefully.\n- If an enum or JSON value is specified more than once in your map, the first matching occurrence from the top of the map will be returned when converting to or from JSON.\n\n### Binary formats (BSON, CBOR, MessagePack, UBJSON, and BJData)\n\nThough JSON is a ubiquitous data format, it is not a very compact format suitable for data exchange, for instance over a network. Hence, the library supports [BSON](https://bsonspec.org) (Binary JSON), [CBOR](https://cbor.io) (Concise Binary Object Representation), [MessagePack](https://msgpack.org), [UBJSON](https://ubjson.org) (Universal Binary JSON Specification) and [BJData](https://neurojson.org/bjdata) (Binary JData) to efficiently encode JSON values to byte vectors and to decode such vectors.\n\n```cpp\n// create a JSON value\njson j = R\"({\"compact\": true, \"schema\": 0})\"_json;\n\n// serialize to BSON\nstd::vector<std::uint8_t> v_bson = json::to_bson(j);\n\n// 0x1B, 0x00, 0x00, 0x00, 0x08, 0x63, 0x6F, 0x6D, 0x70, 0x61, 0x63, 0x74, 0x00, 0x01, 0x10, 0x73, 0x63, 0x68, 0x65, 0x6D, 0x61, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00\n\n// roundtrip\njson j_from_bson = json::from_bson(v_bson);\n\n// serialize to CBOR\nstd::vector<std::uint8_t> v_cbor = json::to_cbor(j);\n\n// 0xA2, 0x67, 0x63, 0x6F, 0x6D, 0x70, 0x61, 0x63, 0x74, 0xF5, 0x66, 0x73, 0x63, 0x68, 0x65, 0x6D, 0x61, 0x00\n\n// roundtrip\njson j_from_cbor = json::from_cbor(v_cbor);\n\n// serialize to MessagePack\nstd::vector<std::uint8_t> v_msgpack = json::to_msgpack(j);\n\n// 0x82, 0xA7, 0x63, 0x6F, 0x6D, 0x70, 0x61, 0x63, 0x74, 0xC3, 0xA6, 0x73, 0x63, 0x68, 0x65, 0x6D, 0x61, 0x00\n\n// roundtrip\njson j_from_msgpack = json::from_msgpack(v_msgpack);\n\n// serialize to UBJSON\nstd::vector<std::uint8_t> v_ubjson = json::to_ubjson(j);\n\n// 0x7B, 0x69, 0x07, 0x63, 0x6F, 0x6D, 0x70, 0x61, 0x63, 0x74, 0x54, 0x69, 0x06, 0x73, 0x63, 0x68, 0x65, 0x6D, 0x61, 0x69, 0x00, 0x7D\n\n// roundtrip\njson j_from_ubjson = json::from_ubjson(v_ubjson);\n```\n\nThe library also supports binary types from BSON, CBOR (byte strings), and MessagePack (bin, ext, fixext). They are stored by default as `std::vector<std::uint8_t>` to be processed outside the library.\n\n```cpp\n// CBOR byte string with payload 0xCAFE\nstd::vector<std::uint8_t> v = {0x42, 0xCA, 0xFE};\n\n// read value\njson j = json::from_cbor(v);\n\n// the JSON value has type binary\nj.is_binary(); // true\n\n// get reference to stored binary value\nauto& binary = j.get_binary();\n\n// the binary value has no subtype (CBOR has no binary subtypes)\nbinary.has_subtype(); // false\n\n// access std::vector<std::uint8_t> member functions\nbinary.size(); // 2\nbinary[0]; // 0xCA\nbinary[1]; // 0xFE\n\n// set subtype to 0x10\nbinary.set_subtype(0x10);\n\n// serialize to MessagePack\nauto cbor = json::to_msgpack(j); // 0xD5 (fixext2), 0x10, 0xCA, 0xFE\n```\n\n## Customers\n\nThe library is used in multiple projects, applications, operating systems, etc. The list below is not exhaustive, but the result of an internet search. If you know further customers of the library, please let me know, see [contact](#contact).\n\n[![logos of customers using the library](docs/mkdocs/docs/images/customers.png)](https://json.nlohmann.me/home/customers/)\n\n## Supported compilers\n\nThough it's 2026 already, the support for C++11 is still a bit sparse. Currently, the following compilers are known to work:\n\n- GCC 4.8 - 14.2 (and possibly later)\n- Clang 3.4 - 21.0 (and possibly later)\n- Apple Clang 9.1 - 16.0 (and possibly later)\n- Intel C++ Compiler 17.0.2 (and possibly later)\n- Nvidia CUDA Compiler 11.0.221 (and possibly later)\n- Microsoft Visual C++ 2015 / Build Tools 14.0.25123.0 (and possibly later)\n- Microsoft Visual C++ 2017 / Build Tools 15.5.180.51428 (and possibly later)\n- Microsoft Visual C++ 2019 / Build Tools 16.3.1+1def00d3d (and possibly later)\n- Microsoft Visual C++ 2022 / Build Tools 19.30.30709.0 (and possibly later)\n\nI would be happy to learn about other compilers/versions.\n\nPlease note:\n\n- GCC 4.8 has a bug [57824](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=57824): multiline raw strings cannot be the arguments to macros. Don't use multiline raw strings directly in macros with this compiler.\n- Android defaults to using very old compilers and C++ libraries. To fix this, add the following to your `Application.mk`. This will switch to the LLVM C++ library, the Clang compiler, and enable C++11 and other features disabled by default.\n\n    ```makefile\n    APP_STL := c++_shared\n    NDK_TOOLCHAIN_VERSION := clang3.6\n    APP_CPPFLAGS += -frtti -fexceptions\n    ```\n\n    The code compiles successfully with [Android NDK](https://developer.android.com/ndk/index.html?hl=ml), Revision 9 - 11 (and possibly later) and [CrystaX's Android NDK](https://www.crystax.net/en/android/ndk) version 10.\n\n- For GCC running on MinGW or Android SDK, the error `'to_string' is not a member of 'std'` (or similarly, for `strtod` or `strtof`) may occur. Note this is not an issue with the code, but rather with the compiler itself. On Android, see above to build with a newer environment.  For MinGW, please refer to [this site](https://tehsausage.com/mingw-to-string) and [this discussion](https://github.com/nlohmann/json/issues/136) for information on how to fix this bug. For Android NDK using `APP_STL := gnustl_static`, please refer to [this discussion](https://github.com/nlohmann/json/issues/219).\n\n- Unsupported versions of GCC and Clang are rejected by `#error` directives. This can be switched off by defining `JSON_SKIP_UNSUPPORTED_COMPILER_CHECK`. Note that you can expect no support in this case.\n\nSee the page [quality assurance](https://json.nlohmann.me/community/quality_assurance) on the compilers used to check the library in the CI.\n\n## Integration\n\n[`json.hpp`](https://github.com/nlohmann/json/blob/develop/single_include/nlohmann/json.hpp) is the single required file in `single_include/nlohmann` or [released here](https://github.com/nlohmann/json/releases). You need to add\n\n```cpp\n#include <nlohmann/json.hpp>\n\n// for convenience\nusing json = nlohmann::json;\n```\n\nto the files you want to process JSON and set the necessary switches to enable C++11 (e.g., `-std=c++11` for GCC and Clang).\n\nYou can further use file [`include/nlohmann/json_fwd.hpp`](https://github.com/nlohmann/json/blob/develop/include/nlohmann/json_fwd.hpp) for forward-declarations. The installation of `json_fwd.hpp` (as part of cmake's install step) can be achieved by setting `-DJSON_MultipleHeaders=ON`.\n\n### CMake\n\nYou can also use the `nlohmann_json::nlohmann_json` interface target in CMake.  This target populates the appropriate usage requirements for `INTERFACE_INCLUDE_DIRECTORIES` to point to the appropriate include directories and `INTERFACE_COMPILE_FEATURES` for the necessary C++11 flags.\n\n#### External\n\nTo use this library from a CMake project, you can locate it directly with `find_package()` and use the namespaced imported target from the generated package configuration:\n\n```cmake\n# CMakeLists.txt\nfind_package(nlohmann_json 3.12.0 REQUIRED)\n...\nadd_library(foo ...)\n...\ntarget_link_libraries(foo PRIVATE nlohmann_json::nlohmann_json)\n```\n\nThe package configuration file, `nlohmann_jsonConfig.cmake`, can be used either from an install tree or directly out of the build tree.\n\n#### Embedded\n\nTo embed the library directly into an existing CMake project, place the entire source tree in a subdirectory and call `add_subdirectory()` in your `CMakeLists.txt` file:\n\n```cmake\n# Typically you don't care so much for a third party library's tests to be\n# run from your own project's code.\nset(JSON_BuildTests OFF CACHE INTERNAL \"\")\n\n# If you only include this third party in PRIVATE source files, you do not\n# need to install it when your main project gets installed.\n# set(JSON_Install OFF CACHE INTERNAL \"\")\n\n# Don't use include(nlohmann_json/CMakeLists.txt) since that carries with it\n# unintended consequences that will break the build.  It's generally\n# discouraged (although not necessarily well documented as such) to use\n# include(...) for pulling in other CMake projects anyways.\nadd_subdirectory(nlohmann_json)\n...\nadd_library(foo ...)\n...\ntarget_link_libraries(foo PRIVATE nlohmann_json::nlohmann_json)\n```\n\n##### Embedded (FetchContent)\n\nSince CMake v3.11,\n[FetchContent](https://cmake.org/cmake/help/v3.11/module/FetchContent.html) can\nbe used to automatically download a release as a dependency at configure time.\n\nExample:\n\n```cmake\ninclude(FetchContent)\n\nFetchContent_Declare(json URL https://github.com/nlohmann/json/releases/download/v3.12.0/json.tar.xz)\nFetchContent_MakeAvailable(json)\n\ntarget_link_libraries(foo PRIVATE nlohmann_json::nlohmann_json)\n```\n\n**Note**: It is recommended to use the URL approach described above, which is supported as of version 3.10.0. See\n<https://json.nlohmann.me/integration/cmake/#fetchcontent> for more information.\n\n#### Supporting Both\n\nTo allow your project to support either an externally supplied or an embedded JSON library, you can use a pattern akin to the following:\n\n``` cmake\n# Top level CMakeLists.txt\nproject(FOO)\n...\noption(FOO_USE_EXTERNAL_JSON \"Use an external JSON library\" OFF)\n...\nadd_subdirectory(thirdparty)\n...\nadd_library(foo ...)\n...\n# Note that the namespaced target will always be available regardless of the\n# import method\ntarget_link_libraries(foo PRIVATE nlohmann_json::nlohmann_json)\n```\n\n```cmake\n# thirdparty/CMakeLists.txt\n...\nif(FOO_USE_EXTERNAL_JSON)\n  find_package(nlohmann_json 3.12.0 REQUIRED)\nelse()\n  set(JSON_BuildTests OFF CACHE INTERNAL \"\")\n  add_subdirectory(nlohmann_json)\nendif()\n...\n```\n\n`thirdparty/nlohmann_json` is then a complete copy of this source tree.\n\n### Package Managers\n\nUse your favorite [**package manager**](https://json.nlohmann.me/integration/package_managers/) to use the library.\n\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/homebrew.svg\" height=\"20\">&nbsp;[**Homebrew**](https://json.nlohmann.me/integration/package_managers/#homebrew) `nlohmann-json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/meson.svg\" height=\"20\">&nbsp;[**Meson**](https://json.nlohmann.me/integration/package_managers/#meson) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/bazel.svg\" height=\"20\">&nbsp;[**Bazel**](https://json.nlohmann.me/integration/package_managers/#bazel) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/conan.svg\" height=\"20\">&nbsp;[**Conan**](https://json.nlohmann.me/integration/package_managers/#conan) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/spack.svg\" height=\"20\">&nbsp;[**Spack**](https://json.nlohmann.me/integration/package_managers/#spack) `nlohmann-json`\n- [**Hunter**](https://json.nlohmann.me/integration/package_managers/#hunter) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/vcpkg.png\" height=\"20\">&nbsp;[**vcpkg**](https://json.nlohmann.me/integration/package_managers/#vcpkg) `nlohmann-json`\n- [**cget**](https://json.nlohmann.me/integration/package_managers/#cget) `nlohmann/json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/swift.svg\" height=\"20\">&nbsp;[**Swift Package Manager**](https://json.nlohmann.me/integration/package_managers/#swift-package-manager) `nlohmann/json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/nuget.svg\" height=\"20\">&nbsp;[**Nuget**](https://json.nlohmann.me/integration/package_managers/#nuget) `nlohmann.json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/conda.svg\" height=\"20\">&nbsp;[**Conda**](https://json.nlohmann.me/integration/package_managers/#conda) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/macports.svg\" height=\"20\">&nbsp;[**MacPorts**](https://json.nlohmann.me/integration/package_managers/#macports) `nlohmann-json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/CPM.png\" height=\"20\">&nbsp;[**cpm.cmake**](https://json.nlohmann.me/integration/package_managers/#cpmcmake) `gh:nlohmann/json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/xmake.svg\" height=\"20\">&nbsp;[**xmake**](https://json.nlohmann.me/integration/package_managers/#xmake) `nlohmann_json`\n\nThe library is part of many package managers. See the [**documentation**](https://json.nlohmann.me/integration/package_managers/) for detailed descriptions and examples.\n\n### Pkg-config\n\nIf you are using bare Makefiles, you can use `pkg-config` to generate the include flags that point to where the library is installed:\n\n```sh\npkg-config nlohmann_json --cflags\n```\n\n## License\n\n<img align=\"right\" src=\"https://149753425.v2.pressablecdn.com/wp-content/uploads/2009/06/OSIApproved_100X125.png\" alt=\"OSI approved license\">\n\nThe class is licensed under the [MIT License](https://opensource.org/licenses/MIT):\n\nCopyright &copy; 2013-2026 [Niels Lohmann](https://nlohmann.me)\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ‚ÄúSoftware‚Äù), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ‚ÄúAS IS‚Äù, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n* * *\n\n- The class contains the UTF-8 Decoder from Bjoern Hoehrmann which is licensed under the [MIT License](https://opensource.org/licenses/MIT) (see above). Copyright &copy; 2008-2009 [Bj√∂rn Hoehrmann](https://bjoern.hoehrmann.de/) <bjoern@hoehrmann.de>\n- The class contains a slightly modified version of the Grisu2 algorithm from Florian Loitsch which is licensed under the [MIT License](https://opensource.org/licenses/MIT) (see above). Copyright &copy; 2009 [Florian Loitsch](https://florian.loitsch.com/)\n- The class contains a copy of [Hedley](https://nemequ.github.io/hedley/) from Evan Nemerson which is licensed as [CC0-1.0](https://creativecommons.org/publicdomain/zero/1.0/).\n- The class contains parts of [Google Abseil](https://github.com/abseil/abseil-cpp) which is licensed under the [Apache 2.0 License](https://opensource.org/licenses/Apache-2.0).\n\n<img align=\"right\" src=\"https://git.fsfe.org/reuse/reuse-ci/raw/branch/master/reuse-horizontal.png\" alt=\"REUSE Software\">\n\nThe library is compliant to version 3.3 of the [**REUSE specification**](https://reuse.software):\n\n- Every source file contains an SPDX copyright header.\n- The full text of all licenses used in the repository can be found in the `LICENSES` folder.\n- File `.reuse/dep5` contains an overview of all files' copyrights and licenses.\n- Run `pipx run reuse lint` to verify the project's REUSE compliance and `pipx run reuse spdx` to generate a SPDX SBOM.\n\n## Contact\n\nIf you have questions regarding the library, I would like to invite you to [open an issue at GitHub](https://github.com/nlohmann/json/issues/new/choose). Please describe your request, problem, or question as detailed as possible, and also mention the version of the library you are using as well as the version of your compiler and operating system. Opening an issue at GitHub allows other users and contributors to this library to collaborate. For instance, I have little experience with MSVC, and most issues in this regard have been solved by a growing community. If you have a look at the [closed issues](https://github.com/nlohmann/json/issues?q=is%3Aissue+is%3Aclosed), you will see that we react quite timely in most cases.\n\nOnly if your request would contain confidential information, please [send me an email](mailto:mail@nlohmann.me). For encrypted messages, please use [this key](https://keybase.io/nlohmann/pgp_keys.asc).\n\n## Security\n\n[Commits by Niels Lohmann](https://github.com/nlohmann/json/commits) and [releases](https://github.com/nlohmann/json/releases) are signed with this [PGP Key](https://keybase.io/nlohmann/pgp_keys.asc?fingerprint=797167ae41c0a6d9232e48457f3cea63ae251b69).\n\n## Thanks\n\nI deeply appreciate the help of the following people.\n\n<img src=\"https://raw.githubusercontent.com/nlohmann/json/develop/docs/avatars.png\" align=\"right\" alt=\"GitHub avatars of the contributors\">\n\n1. [Teemperor](https://github.com/Teemperor) implemented CMake support and lcov integration, realized escape and Unicode handling in the string parser, and fixed the JSON serialization.\n2. [elliotgoodrich](https://github.com/elliotgoodrich) fixed an issue with double deletion in the iterator classes.\n3. [kirkshoop](https://github.com/kirkshoop) made the iterators of the class composable to other libraries.\n4. [wancw](https://github.com/wanwc) fixed a bug that hindered the class to compile with Clang.\n5. Tomas √Öblad found a bug in the iterator implementation.\n6. [Joshua C. Randall](https://github.com/jrandall) fixed a bug in the floating-point serialization.\n7. [Aaron Burghardt](https://github.com/aburgh) implemented code to parse streams incrementally. Furthermore, he greatly improved the parser class by allowing the definition of a filter function to discard undesired elements while parsing.\n8. [Daniel Kopeƒçek](https://github.com/dkopecek) fixed a bug in the compilation with GCC 5.0.\n9. [Florian Weber](https://github.com/Florianjw) fixed a bug in and improved the performance of the comparison operators.\n10. [Eric Cornelius](https://github.com/EricMCornelius) pointed out a bug in the handling with NaN and infinity values. He also improved the performance of the string escaping.\n11. [ÊòìÊÄùÈæô](https://github.com/likebeta) implemented a conversion from anonymous enums.\n12. [kepkin](https://github.com/kepkin) patiently pushed forward the support for Microsoft Visual Studio.\n13. [gregmarr](https://github.com/gregmarr) simplified the implementation of reverse iterators and helped with numerous hints and improvements. In particular, he pushed forward the implementation of user-defined types.\n14. [Caio Luppi](https://github.com/caiovlp) fixed a bug in the Unicode handling.\n15. [dariomt](https://github.com/dariomt) fixed some typos in the examples.\n16. [Daniel Frey](https://github.com/d-frey) cleaned up some pointers and implemented exception-safe memory allocation.\n17. [Colin Hirsch](https://github.com/ColinH) took care of a small namespace issue.\n18. [Huu Nguyen](https://github.com/whoshuu) corrected a variable name in the documentation.\n19. [Silverweed](https://github.com/silverweed) overloaded `parse()` to accept an rvalue reference.\n20. [dariomt](https://github.com/dariomt) fixed a subtlety in MSVC type support and implemented the `get_ref()` function to get a reference to stored values.\n21. [ZahlGraf](https://github.com/ZahlGraf) added a workaround that allows compilation using Android NDK.\n22. [whackashoe](https://github.com/whackashoe) replaced a function that was marked as unsafe by Visual Studio.\n23. [406345](https://github.com/406345) fixed two small warnings.\n24. [Glen Fernandes](https://github.com/glenfe) noted a potential portability problem in the `has_mapped_type` function.\n25. [Corbin Hughes](https://github.com/nibroc) fixed some typos in the contribution guidelines.\n26. [twelsby](https://github.com/twelsby) fixed the array subscript operator, an issue that failed the MSVC build, and floating-point parsing/dumping. He further added support for unsigned integer numbers and implemented better roundtrip support for parsed numbers.\n27. [Volker Diels-Grabsch](https://github.com/vog) fixed a link in the README file.\n28. [msm-](https://github.com/msm-) added support for American Fuzzy Lop.\n29. [Annihil](https://github.com/Annihil) fixed an example in the README file.\n30. [Themercee](https://github.com/Themercee) noted a wrong URL in the README file.\n31. [Lv Zheng](https://github.com/lv-zheng) fixed a namespace issue with `int64_t` and `uint64_t`.\n32. [abc100m](https://github.com/abc100m) analyzed the issues with GCC 4.8 and proposed a [partial solution](https://github.com/nlohmann/json/pull/212).\n33. [zewt](https://github.com/zewt) added useful notes to the README file about Android.\n34. [R√≥bert M√°rki](https://github.com/robertmrk) added a fix to use move iterators and improved the integration via CMake.\n35. [Chris Kitching](https://github.com/ChrisKitching) cleaned up the CMake files.\n36. [Tom Needham](https://github.com/06needhamt) fixed a subtle bug with MSVC 2015 which was also proposed by [Michael K.](https://github.com/Epidal).\n37. [M√°rio Feroldi](https://github.com/thelostt) fixed a small typo.\n38. [duncanwerner](https://github.com/duncanwerner) found a really embarrassing performance regression in the 2.0.0 release.\n39. [Damien](https://github.com/dtoma) fixed one of the last conversion warnings.\n40. [Thomas Braun](https://github.com/t-b) fixed a warning in a test case and adjusted MSVC calls in the CI.\n41. [Th√©o DELRIEU](https://github.com/theodelrieu) patiently and constructively oversaw the long way toward [iterator-range parsing](https://github.com/nlohmann/json/issues/290). He also implemented the magic behind the serialization/deserialization of user-defined types and split the single header file into smaller chunks.\n42. [Stefan](https://github.com/5tefan) fixed a minor issue in the documentation.\n43. [Vasil Dimov](https://github.com/vasild) fixed the documentation regarding conversions from `std::multiset`.\n44. [ChristophJud](https://github.com/ChristophJud) overworked the CMake files to ease project inclusion.\n45. [Vladimir Petrigo](https://github.com/vpetrigo) made a SFINAE hack more readable and added Visual Studio 17 to the build matrix.\n46. [Denis Andrejew](https://github.com/seeekr) fixed a grammar issue in the README file.\n47. [Pierre-Antoine Lacaze](https://github.com/palacaze) found a subtle bug in the `dump()` function.\n48. [TurpentineDistillery](https://github.com/TurpentineDistillery) pointed to [`std::locale::classic()`](https://en.cppreference.com/w/cpp/locale/locale/classic) to avoid too much locale joggling, found some nice performance improvements in the parser, improved the benchmarking code, and realized locale-independent number parsing and printing.\n49. [cgzones](https://github.com/cgzones) had an idea how to fix the Coverity scan.\n50. [Jared Grubb](https://github.com/jaredgrubb) silenced a nasty documentation warning.\n51. [Yixin Zhang](https://github.com/qwename) fixed an integer overflow check.\n52. [Bosswestfalen](https://github.com/Bosswestfalen) merged two iterator classes into a smaller one.\n53. [Daniel599](https://github.com/Daniel599) helped to get Travis to execute the tests with Clang's sanitizers.\n54. [Jonathan Lee](https://github.com/vjon) fixed an example in the README file.\n55. [gnzlbg](https://github.com/gnzlbg) supported the implementation of user-defined types.\n56. [Alexej Harm](https://github.com/qis) helped to get the user-defined types working with Visual Studio.\n57. [Jared Grubb](https://github.com/jaredgrubb) supported the implementation of user-defined types.\n58. [EnricoBilla](https://github.com/EnricoBilla) noted a typo in an example.\n59. [Martin Ho≈ôe≈àovsk√Ω](https://github.com/horenmar) found a way for a 2x speedup for the compilation time of the test suite.\n60. [ukhegg](https://github.com/ukhegg) found proposed an improvement for the examples section.\n61. [rswanson-ihi](https://github.com/rswanson-ihi) noted a typo in the README.\n62. [Mihai Stan](https://github.com/stanmihai4) fixed a bug in the comparison with `nullptr`s.\n63. [Tushar Maheshwari](https://github.com/tusharpm) added [cotire](https://github.com/sakra/cotire) support to speed up the compilation.\n64. [TedLyngmo](https://github.com/TedLyngmo) noted a typo in the README, removed unnecessary bit arithmetic, and fixed some `-Weffc++` warnings.\n65. [Krzysztof Wo≈õ](https://github.com/krzysztofwos) made exceptions more visible.\n66. [ftillier](https://github.com/ftillier) fixed a compiler warning.\n67. [tinloaf](https://github.com/tinloaf) made sure all pushed warnings are properly popped.\n68. [Fytch](https://github.com/Fytch) found a bug in the documentation.\n69. [Jay Sistar](https://github.com/Type1J) implemented a Meson build description.\n70. [Henry Lee](https://github.com/HenryRLee) fixed a warning in ICC and improved the iterator implementation.\n71. [Vincent Thiery](https://github.com/vthiery) maintains a package for the Conan package manager.\n72. [Steffen](https://github.com/koemeet) fixed a potential issue with MSVC and `std::min`.\n73. [Mike Tzou](https://github.com/Chocobo1) fixed some typos.\n74. [amrcode](https://github.com/amrcode) noted misleading documentation about comparison of floats.\n75. [Oleg Endo](https://github.com/olegendo) reduced the memory consumption by replacing `<iostream>` with `<iosfwd>`.\n76. [dan-42](https://github.com/dan-42) cleaned up the CMake files to simplify including/reusing of the library.\n77. [Nikita Ofitserov](https://github.com/himikof) allowed for moving values from initializer lists.\n78. [Greg Hurrell](https://github.com/wincent) fixed a typo.\n79. [Dmitry Kukovinets](https://github.com/DmitryKuk) fixed a typo.\n80. [kbthomp1](https://github.com/kbthomp1) fixed an issue related to the Intel OSX compiler.\n81. [Markus Werle](https://github.com/daixtrose) fixed a typo.\n82. [WebProdPP](https://github.com/WebProdPP) fixed a subtle error in a precondition check.\n83. [Alex](https://github.com/leha-bot) noted an error in a code sample.\n84. [Tom de Geus](https://github.com/tdegeus) reported some warnings with ICC and helped to fix them.\n85. [Perry Kundert](https://github.com/pjkundert) simplified reading from input streams.\n86. [Sonu Lohani](https://github.com/sonulohani) fixed a small compilation error.\n87. [Jamie Seward](https://github.com/jseward) fixed all MSVC warnings.\n88. [Nate Vargas](https://github.com/eld00d) added a Doxygen tag file.\n89. [pvleuven](https://github.com/pvleuven) helped to fix a warning in ICC.\n90. [Pavel](https://github.com/crea7or) helped to fix some warnings in MSVC.\n91. [Jamie Seward](https://github.com/jseward) avoided unnecessary string copies in `find()` and `count()`.\n92. [Mitja](https://github.com/Itja) fixed some typos.\n93. [Jorrit Wronski](https://github.com/jowr) updated the Hunter package links.\n94. [Matthias M√∂ller](https://github.com/TinyTinni) added a `.natvis` for the MSVC debug view.\n95. [bogemic](https://github.com/bogemic) fixed some C++17 deprecation warnings.\n96. [Eren Okka](https://github.com/erengy) fixed some MSVC warnings.\n97. [abolz](https://github.com/abolz) integrated the Grisu2 algorithm for proper floating-point formatting, allowing more roundtrip checks to succeed.\n98. [Vadim Evard](https://github.com/Pipeliner) fixed a Markdown issue in the README.\n99. [zerodefect](https://github.com/zerodefect) fixed a compiler warning.\n100. [Kert](https://github.com/kaidokert) allowed to template the string type in the serialization and added the possibility to override the exceptional behavior.\n101. [mark-99](https://github.com/mark-99) helped fix an ICC error.\n102. [Patrik Huber](https://github.com/patrikhuber) fixed links in the README file.\n103. [johnfb](https://github.com/johnfb) found a bug in the implementation of CBOR's indefinite length strings.\n104. [Paul Fultz II](https://github.com/pfultz2) added a note on the cget package manager.\n105. [Wilson Lin](https://github.com/wla80) made the integration section of the README more concise.\n106. [RalfBielig](https://github.com/ralfbielig) detected and fixed a memory leak in the parser callback.\n107. [agrianius](https://github.com/agrianius) allowed dumping JSON to an alternative string type.\n108. [Kevin Tonon](https://github.com/ktonon) overworked the C++11 compiler checks in CMake.\n109. [Axel Huebl](https://github.com/ax3l) simplified a CMake check and added support for the [Spack package manager](https://spack.io).\n110. [Carlos O'Ryan](https://github.com/coryan) fixed a typo.\n111. [James Upjohn](https://github.com/jammehcow) fixed a version number in the compilers section.\n112. [Chuck Atkins](https://github.com/chuckatkins) adjusted the CMake files to the CMake packaging guidelines and provided documentation for the CMake integration.\n113. [Jan Sch√∂ppach](https://github.com/dns13) fixed a typo.\n114. [martin-mfg](https://github.com/martin-mfg) fixed a typo.\n115. [Matthias M√∂ller](https://github.com/TinyTinni) removed the dependency from `std::stringstream`.\n116. [agrianius](https://github.com/agrianius) added code to use alternative string implementations.\n117. [Daniel599](https://github.com/Daniel599) allowed to use more algorithms with the `items()` function.\n118. [Julius Rakow](https://github.com/jrakow) fixed the Meson include directory and fixed the links to [cppreference.com](https://cppreference.com).\n119. [Sonu Lohani](https://github.com/sonulohani) fixed the compilation with MSVC 2015 in debug mode.\n120. [grembo](https://github.com/grembo) fixed the test suite and re-enabled several test cases.\n121. [Hyeon Kim](https://github.com/simnalamburt) introduced the macro `JSON_INTERNAL_CATCH` to control the exception handling inside the library.\n122. [thyu](https://github.com/thyu) fixed a compiler warning.\n123. [David Guthrie](https://github.com/LEgregius) fixed a subtle compilation error with Clang 3.4.2.\n124. [Dennis Fischer](https://github.com/dennisfischer) allowed to call `find_package` without installing the library.\n125. [Hyeon Kim](https://github.com/simnalamburt) fixed an issue with a double macro definition.\n126. [Ben Berman](https://github.com/rivertam) made some error messages more understandable.\n127. [zakalibit](https://github.com/zakalibit) fixed a compilation problem with the Intel C++ compiler.\n128. [mandreyel](https://github.com/mandreyel) fixed a compilation problem.\n129. [Kostiantyn Ponomarenko](https://github.com/koponomarenko) added version and license information to the Meson build file.\n130. [Henry Schreiner](https://github.com/henryiii) added support for GCC 4.8.\n131. [knilch](https://github.com/knilch0r) made sure the test suite does not stall when run in the wrong directory.\n132. [Antonio Borondo](https://github.com/antonioborondo) fixed an MSVC 2017 warning.\n133. [Dan Gendreau](https://github.com/dgendreau) implemented the `NLOHMANN_JSON_SERIALIZE_ENUM` macro to quickly define an enum/JSON mapping.\n134. [efp](https://github.com/efp) added line and column information to parse errors.\n135. [julian-becker](https://github.com/julian-becker) added BSON support.\n136. [Pratik Chowdhury](https://github.com/pratikpc) added support for structured bindings.\n137. [David Avedissian](https://github.com/davedissian) added support for Clang 5.0.1 (PS4 version).\n138. [Jonathan Dumaresq](https://github.com/dumarjo) implemented an input adapter to read from `FILE*`.\n139. [kjpus](https://github.com/kjpus) fixed a link in the documentation.\n140. [Manvendra Singh](https://github.com/manu-chroma) fixed a typo in the documentation.\n141. [ziggurat29](https://github.com/ziggurat29) fixed an MSVC warning.\n142. [Sylvain Corlay](https://github.com/SylvainCorlay) added code to avoid an issue with MSVC.\n143. [mefyl](https://github.com/mefyl) fixed a bug when JSON was parsed from an input stream.\n144. [Millian Poquet](https://github.com/mpoquet) allowed to install the library via Meson.\n145. [Michael Behrns-Miller](https://github.com/moodboom) found an issue with a missing namespace.\n146. [Nasztanovics Ferenc](https://github.com/naszta) fixed a compilation issue with libc 2.12.\n147. [Andreas Schwab](https://github.com/andreas-schwab) fixed the endian conversion.\n148. [Mark-Dunning](https://github.com/Mark-Dunning) fixed a warning in MSVC.\n149. [Gareth Sylvester-Bradley](https://github.com/garethsb-sony) added `operator/` for JSON Pointers.\n150. [John-Mark](https://github.com/johnmarkwayve) noted a missing header.\n151. [Vitaly Zaitsev](https://github.com/xvitaly) fixed compilation with GCC 9.0.\n152. [Laurent Stacul](https://github.com/stac47) fixed compilation with GCC 9.0.\n153. [Ivor Wanders](https://github.com/iwanders) helped to reduce the CMake requirement to version 3.1.\n154. [njlr](https://github.com/njlr) updated the Buckaroo instructions.\n155. [Lion](https://github.com/lieff) fixed a compilation issue with GCC 7 on CentOS.\n156. [Isaac Nickaein](https://github.com/nickaein) improved the integer serialization performance and implemented the `contains()` function.\n157. [past-due](https://github.com/past-due) suppressed an unfixable warning.\n158. [Elvis Oric](https://github.com/elvisoric) improved Meson support.\n159. [Matƒõj Plch](https://github.com/Afforix) fixed an example in the README.\n160. [Mark Beckwith](https://github.com/wythe) fixed a typo.\n161. [scinart](https://github.com/scinart) fixed a bug in the serializer.\n162. [Patrick Boettcher](https://github.com/pboettch) implemented `push_back()` and `pop_back()` for JSON Pointers.\n163. [Bruno Oliveira](https://github.com/nicoddemus) added support for Conda.\n164. [Michele Caini](https://github.com/skypjack) fixed links in the README.\n165. [Hani](https://github.com/hnkb) documented how to install the library with NuGet.\n166. [Mark Beckwith](https://github.com/wythe) fixed a typo.\n167. [yann-morin-1998](https://github.com/yann-morin-1998) helped to reduce the CMake requirement to version 3.1.\n168. [Konstantin Podsvirov](https://github.com/podsvirov) maintains a package for the MSYS2 software distro.\n169. [remyabel](https://github.com/remyabel) added GNUInstallDirs to the CMake files.\n170. [Taylor Howard](https://github.com/taylorhoward92) fixed a unit test.\n171. [Gabe Ron](https://github.com/Macr0Nerd) implemented the `to_string` method.\n172. [Watal M. Iwasaki](https://github.com/heavywatal) fixed a Clang warning.\n173. [Viktor Kirilov](https://github.com/onqtam) switched the unit tests from [Catch](https://github.com/philsquared/Catch) to [doctest](https://github.com/onqtam/doctest)\n174. [Juncheng E](https://github.com/ejcjason) fixed a typo.\n175. [tete17](https://github.com/tete17) fixed a bug in the `contains` function.\n176. [Xav83](https://github.com/Xav83) fixed some cppcheck warnings.\n177. [0xflotus](https://github.com/0xflotus) fixed some typos.\n178. [Christian Deneke](https://github.com/chris0x44) added a const version of `json_pointer::back`.\n179. [Julien Hamaide](https://github.com/crazyjul) made the `items()` function work with custom string types.\n180. [Evan Nemerson](https://github.com/nemequ) updated fixed a bug in Hedley and updated this library accordingly.\n181. [Florian Pigorsch](https://github.com/flopp) fixed a lot of typos.\n182. [Camille B√©gu√©](https://github.com/cbegue) fixed an issue in the conversion from  `std::pair` and `std::tuple` to `json`.\n183. [Anthony VH](https://github.com/AnthonyVH) fixed a compile error in an enum deserialization.\n184. [Yuriy Vountesmery](https://github.com/ua-code-dragon) noted a subtle bug in a preprocessor check.\n185. [Chen](https://github.com/dota17) fixed numerous issues in the library.\n186. [Antony Kellermann](https://github.com/aokellermann) added a CI step for GCC 10.1.\n187. [Alex](https://github.com/gistrec) fixed an MSVC warning.\n188. [Rainer](https://github.com/rvjr) proposed an improvement in the floating-point serialization in CBOR.\n189. [Francois Chabot](https://github.com/FrancoisChabot) made performance improvements in the input adapters.\n190. [Arthur Sonzogni](https://github.com/ArthurSonzogni) documented how the library can be included via `FetchContent`.\n191. [Rimas Miseviƒçius](https://github.com/rmisev) fixed an error message.\n192. [Alexander Myasnikov](https://github.com/alexandermyasnikov) fixed some examples and a link in the README.\n193. [Hubert Chathi](https://github.com/uhoreg) made CMake's version config file architecture-independent.\n194. [OmnipotentEntity](https://github.com/OmnipotentEntity) implemented the binary values for CBOR, MessagePack, BSON, and UBJSON.\n195. [ArtemSarmini](https://github.com/ArtemSarmini) fixed a compilation issue with GCC 10 and fixed a leak.\n196. [Evgenii Sopov](https://github.com/sea-kg) integrated the library to the wsjcpp package manager.\n197. [Sergey Linev](https://github.com/linev) fixed a compiler warning.\n198. [Miguel Magalh√£es](https://github.com/magamig) fixed the year in the copyright.\n199. [Gareth Sylvester-Bradley](https://github.com/garethsb-sony) fixed a compilation issue with MSVC.\n200. [Alexander ‚Äúweej‚Äù Jones](https://github.com/alex-weej) fixed an example in the README.\n201. [Antoine C≈ìur](https://github.com/Coeur) fixed some typos in the documentation.\n202. [jothepro](https://github.com/jothepro) updated links to the Hunter package.\n203. [Dave Lee](https://github.com/kastiglione) fixed a link in the README.\n204. [Jo√´l Lamotte](https://github.com/Klaim) added instruction for using Build2's package manager.\n205. [Paul Jurczak](https://github.com/pauljurczak) fixed an example in the README.\n206. [Sonu Lohani](https://github.com/sonulohani) fixed a warning.\n207. [Carlos Gomes Martinho](https://github.com/gocarlos) updated the Conan package source.\n208. [Konstantin Podsvirov](https://github.com/podsvirov) fixed the MSYS2 package documentation.\n209. [Tridacnid](https://github.com/Tridacnid) improved the CMake tests.\n210. [Michael](https://github.com/MBalszun) fixed MSVC warnings.\n211. [Quentin Barbarat](https://github.com/quentin-dev) fixed an example in the documentation.\n212. [XyFreak](https://github.com/XyFreak) fixed a compiler warning.\n213. [TotalCaesar659](https://github.com/TotalCaesar659) fixed links in the README.\n214. [Tanuj Garg](https://github.com/tanuj208) improved the fuzzer coverage for UBSAN input.\n215. [AODQ](https://github.com/AODQ) fixed a compiler warning.\n216. [jwittbrodt](https://github.com/jwittbrodt) made `NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE` inline.\n217. [pfeatherstone](https://github.com/pfeatherstone) improved the upper bound of arguments of the `NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE`/`NLOHMANN_DEFINE_TYPE_INTRUSIVE` macros.\n218. [Jan Proch√°zka](https://github.com/jprochazk) fixed a bug in the CBOR parser for binary and string values.\n219. [T0b1-iOS](https://github.com/T0b1-iOS) fixed a bug in the new hash implementation.\n220. [Matthew Bauer](https://github.com/matthewbauer) adjusted the CBOR writer to create tags for binary subtypes.\n221. [gatopeich](https://github.com/gatopeich) implemented an ordered map container for `nlohmann::ordered_json`.\n222. [√ârico Nogueira Rolim](https://github.com/ericonr) added support for pkg-config.\n223. [KonanM](https://github.com/KonanM) proposed an implementation for the `NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE`/`NLOHMANN_DEFINE_TYPE_INTRUSIVE` macros.\n224. [Guillaume Racicot](https://github.com/gracicot) implemented `string_view` support and allowed C++20 support.\n225. [Alex Reinking](https://github.com/alexreinking) improved CMake support for `FetchContent`.\n226. [Hannes Domani](https://github.com/ssbssa) provided a GDB pretty printer.\n227. Lars Wirzenius reviewed the README file.\n228. [Jun Jie](https://github.com/ongjunjie) fixed a compiler path in the CMake scripts.\n229. [Ronak Buch](https://github.com/rbuch) fixed typos in the documentation.\n230. [Alexander Karzhenkov](https://github.com/karzhenkov) fixed a move constructor and the Travis builds.\n231. [Leonardo Lima](https://github.com/leozz37) added CPM.Cmake support.\n232. [Joseph Blackman](https://github.com/jbzdarkid) fixed a warning.\n233. [Yaroslav](https://github.com/YarikTH) updated doctest and implemented unit tests.\n234. [Martin Stump](https://github.com/globberwops) fixed a bug in the CMake files.\n235. [Jaakko Moisio](https://github.com/jasujm) fixed a bug in the input adapters.\n236. [bl-ue](https://github.com/bl-ue) fixed some Markdown issues in the README file.\n237. [William A. Wieselquist](https://github.com/wawiesel) fixed an example from the README.\n238. [abbaswasim](https://github.com/abbaswasim) fixed an example from the README.\n239. [Remy Jette](https://github.com/remyjette) fixed a warning.\n240. [Fraser](https://github.com/frasermarlow) fixed the documentation.\n241. [Ben Beasley](https://github.com/musicinmybrain) updated doctest.\n242. [Doron Behar](https://github.com/doronbehar) fixed pkg-config.pc.\n243. [raduteo](https://github.com/raduteo) fixed a warning.\n244. [David Pfahler](https://github.com/theShmoo) added the possibility to compile the library without I/O support.\n245. [Morten Fyhn Amundsen](https://github.com/mortenfyhn) fixed a typo.\n246. [jpl-mac](https://github.com/jpl-mac) allowed treating the library as a system header in CMake.\n247. [Jason Dsouza](https://github.com/jasmcaus) fixed the indentation of the CMake file.\n248. [offa](https://github.com/offa) added a link to Conan Center to the documentation.\n249. [TotalCaesar659](https://github.com/TotalCaesar659) updated the links in the documentation to use HTTPS.\n250. [Rafail Giavrimis](https://github.com/grafail) fixed the Google Benchmark default branch.\n251. [Louis Dionne](https://github.com/ldionne) fixed a conversion operator.\n252. [justanotheranonymoususer](https://github.com/justanotheranonymoususer) made the examples in the README more consistent.\n253. [Finkman](https://github.com/Finkman) suppressed some `-Wfloat-equal` warnings.\n254. [Ferry Huberts](https://github.com/fhuberts) fixed `-Wswitch-enum` warnings.\n255. [Arseniy Terekhin](https://github.com/senyai) made the GDB pretty-printer robust against unset variable names.\n256. [Amir Masoud Abdol](https://github.com/amirmasoudabdol) updated the Homebrew command as nlohmann/json is now in homebrew-core.\n257. [Hallot](https://github.com/Hallot) fixed some `-Wextra-semi-stmt warnings`.\n258. [Giovanni Cerretani](https://github.com/gcerretani) fixed `-Wunused` warnings on `JSON_DIAGNOSTICS`.\n259. [Bogdan Popescu](https://github.com/Kapeli) hosts the [docset](https://github.com/Kapeli/Dash-User-Contributions/tree/master/docsets/JSON_for_Modern_C%2B%2B) for offline documentation viewers.\n260. [Carl Smedstad](https://github.com/carlsmedstad) fixed an assertion error when using `JSON_DIAGNOSTICS`.\n261. [miikka75](https://github.com/miikka75) provided an important fix to compile C++17 code with Clang 9.\n262. [Maarten Becker](https://github.com/kernie) fixed a warning for shadowed variables.\n263. [Cristi V√Æjdea](https://github.com/axnsan12) fixed typos in the `operator[]` documentation.\n264. [Alex Beregszaszi](https://github.com/axic) fixed spelling mistakes in comments.\n265. [Dirk Stolle](https://github.com/striezel) fixed typos in documentation.\n266. [Daniel Albuschat](https://github.com/daniel-kun) corrected the parameter name in the `parse` documentation.\n267. [Prince Mendiratta](https://github.com/Prince-Mendiratta) fixed a link to the FAQ.\n268. [Florian Albrechtskirchinger](https://github.com/falbrechtskirchinger) implemented `std::string_view` support for object keys and made dozens of other improvements.\n269. [Qianqian Fang](https://github.com/fangq) implemented the Binary JData (BJData) format.\n270. [pketelsen](https://github.com/pketelsen) added macros `NLOHMANN_DEFINE_TYPE_INTRUSIVE_WITH_DEFAULT` and `NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE_WITH_DEFAULT`.\n271. [DarkZeros](https://github.com/DarkZeros) adjusted to code to not clash with Arduino defines.\n272. [flagarde](https://github.com/flagarde) fixed the output of `meta()` for MSVC.\n273. [Giovanni Cerretani](https://github.com/gcerretani) fixed a check for `std::filesystem`.\n274. [Dimitris Apostolou](https://github.com/rex4539) fixed a typo.\n275. [Ferry Huberts](https://github.com/fhuberts) fixed a typo.\n276. [Michael Nosthoff](https://github.com/heinemml) fixed a typo.\n277. [JungHoon Lee](https://github.com/jhnlee) fixed a typo.\n278. [Faruk D.](https://github.com/fdiblen) fixed the CITATION.CFF file.\n279. [Andrea Cocito](https://github.com/puffetto) added a clarification on macro usage to the documentation.\n280. [Krzysiek Karbowiak](https://github.com/kkarbowiak) refactored the tests to use `CHECK_THROWS_WITH_AS`.\n281. [Chaoqi Zhang](https://github.com/prncoprs) fixed a typo.\n282. [ivanovmp](https://github.com/ivanovmp) fixed a whitespace error.\n283. [KsaNL](https://github.com/KsaNL) fixed a build error when including `<windows.h>`.\n284. [Andrea Pappacoda](https://github.com/Tachi107) moved `.pc` and `.cmake` files to `share` directory.\n285. [Wolf Vollprecht](https://github.com/wolfv) added the `patch_inplace` function.\n286. [Jake Zimmerman](https://github.com/jez) highlighted common usage patterns in the README file.\n287. [NN](https://github.com/NN---) added the Visual Studio output directory to `.gitignore`.\n288. [Romain Reignier](https://github.com/romainreignier) improved the performance of the vector output adapter.\n289. [Mike](https://github.com/Mike-Leo-Smith) fixed the `std::iterator_traits`.\n290. [Richard Hoz√°k](https://github.com/zxey) added macro `JSON_NO_ENUM` to disable default enum conversions.\n291. [vakokako](https://github.com/vakokako) fixed tests when compiling with C++20.\n292. [Alexander ‚Äúweej‚Äù Jones](https://github.com/alexweej) fixed an example in the README.\n293. [Eli Schwartz](https://github.com/eli-schwartz) added more files to the `include.zip` archive.\n294. [Kevin Lu](https://github.com/kevinlul) fixed a compilation issue when typedefs with certain names were present.\n295. [Trevor Hickey](https://github.com/luxe) improved the description of an example.\n296. [Jef LeCompte](https://github.com/jef) updated the year in the README file.\n297. [Alexandre Hamez](https://github.com/ahamez) fixed a warning.\n298. [Maninderpal Badhan](https://github.com/mbadhan) fixed a typo.\n299. [kevin--](https://github.com/kevin--) added a note to an example in the README file.\n300. [I](https://github.com/wx257osn2) fixed a typo.\n301. [Gregorio Litenstein](https://github.com/Lord-Kamina) fixed the Clang detection.\n302. [Andreas Smas](https://github.com/andoma) added a Doozer badge.\n303. [WanCW](https://github.com/wancw) fixed the string conversion with Clang.\n304. [zhaohuaxishi](https://github.com/zhaohuaxishi) fixed a Doxygen error.\n305. [emvivre](https://github.com/emvivre) removed an invalid parameter from CMake.\n306. [Tobias Hermann](https://github.com/Dobiasd) fixed a link in the README file.\n307. [Michael](https://github.com/traits) fixed a warning.\n308. [Ryan Mulder](https://github.com/ryanjmulder) added `ensure_ascii` to the `dump` function.\n309. [Muri Nicanor](https://github.com/murinicanor) fixed the `sed` discovery in the Makefile.\n310. [David Avedissian](https://github.com/dgavedissian) implemented SFINAE-friendly `iterator_traits`.\n311. [AQNOUCH Mohammed](https://github.com/aqnouch) fixed a typo in the README.\n312. [Gareth Sylvester-Bradley](https://github.com/garethsb) added `operator/=` and `operator/` to construct JSON pointers.\n313. [Michael Macnair](https://github.com/mykter) added support for afl-fuzz testing.\n314. [Berkus Decker](https://github.com/berkus) fixed a typo in the README.\n315. [Illia Polishchuk](https://github.com/effolkronium) improved the CMake testing.\n316. [Ikko Ashimine](https://github.com/eltociear) fixed a typo.\n317. [Raphael Grimm](https://github.com/barcode) added the possibility to define a custom base class.\n318. [tocic](https://github.com/tocic) fixed typos in the documentation.\n319. [Vertexwahn](https://github.com/Vertexwahn) added Bazel build support.\n320. [Dirk Stolle](https://github.com/striezel) fixed typos in the documentation.\n321. [DavidKorczynski](https://github.com/DavidKorczynski) added a CIFuzz CI GitHub action.\n322. [Finkman](https://github.com/Finkman) fixed the debug pretty-printer.\n323. [Florian Segginger](https://github.com/floriansegginger) bumped the years in the README.\n324. [haadfida](https://github.com/haadfida) cleaned up the badges of used services.\n325. [Arsen Arsenoviƒá](https://github.com/ArsenArsen) fixed a build error.\n326. [theevilone45](https://github.com/theevilone45) fixed a typo in a CMake file.\n327. [Sergei Trofimovich](https://github.com/trofi) fixed the custom allocator support.\n328. [Joyce](https://github.com/joycebrum) fixed some security issues in the GitHub workflows.\n329. [Nicolas Jakob](https://github.com/njakob) add vcpkg version badge.\n330. [Tomerkm](https://github.com/Tomerkm) added tests.\n331. [No.](https://github.com/tusooa) fixed the use of `get<>` calls.\n332. [taro](https://github.com/tarolling) fixed a typo in the `CODEOWNERS` file.\n333. [Ikko Eltociear Ashimine](https://github.com/eltociear) fixed a typo.\n334. [Felix Yan](https://github.com/felixonmars) fixed a typo in the README.\n335. [HO-COOH](https://github.com/HO-COOH) fixed a parenthesis in the documentation.\n336. [Ivor Wanders](https://github.com/iwanders) fixed the examples to catch exception by `const&`.\n337. [miny1233](https://github.com/miny1233) fixed a parenthesis in the documentation.\n338. [tomalakgeretkal](https://github.com/tomalakgeretkal) fixed a compilation error.\n339. [alferov](https://github.com/ALF-ONE) fixed a compilation error.\n340. [Craig Scott](https://github.com/craigscott-crascit) fixed a deprecation warning in CMake.\n341. [Vyacheslav Zhdanovskiy](https://github.com/ZeronSix) added macros for serialization-only types.\n342. [Mathieu Westphal](https://github.com/mwestphal) fixed typos.\n343. [scribam](https://github.com/scribam) fixed the MinGW workflow.\n344. [Aleksei Sapitskii](https://github.com/aleksproger) added support for Apple's Swift Package Manager.\n345. [Benjamin Buch](https://github.com/bebuch) fixed the installation path in CMake.\n346. [Colby Haskell](https://github.com/colbychaskell) clarified the parse error message in case a file cannot be opened.\n347. [Juan Carlos Arevalo Baeza](https://github.com/TheJCAB) fixed the enum conversion.\n348. [alferov](https://github.com/ALF-ONE) fixed a version in the documentation.\n349. [ss](https://github.com/serge-s) fixed the amalgamation call.\n350. [AniketDhemare](https://github.com/AniketDhemare) fixed a version in the documentation.\n351. [Philip M√ºller](https://github.com/philip-paul-mueller) fixed an example.\n352. [Leila Shcheglova](https://github.com/LeilaShcheglova) fixed a warning in a test.\n353. [Alex Prabhat Bara](https://github.com/alexprabhat99) fixed a function name in the documentation.\n354. [laterlaugh](https://github.com/laterlaugh) fixed some typos.\n355. [Yuanhao Jia](https://github.com/MrJia1997) fixed the GDB pretty printer.\n356. [Fallen_Breath](https://github.com/Fallen-Breath) fixed an example for JSON Pointer.\n357. [Nikhil Idiculla](https://github.com/tsnl) fixed some typos.\n358. [Griffin Myers](https://github.com/gmyers18) updated the Natvis file.\n359. [thetimr](https://github.com/thetimr) fixed a typo in the documentation.\n360. [Balazs Erseki](https://github.com/zerocukor287) fixed a URL in the contribution guidelines.\n361. [Niccol√≤ Iardella](https://github.com/rotolof) added `NLOHMANN_DEFINE_DERIVED_TYPE_*` macros.\n362. [Borislav Stanimirov](https://github.com/iboB) allowed overriding the CMake target name.\n363. [Captain Crutches](https://github.com/captaincrutches) made `iterator_proxy_value` a `std::forward_iterator`.\n364. [Fredrik Sandhei](https://github.com/fsandhei) added type conversion support for `std::optional`.\n365. [jh96](https://github.com/jordan-hoang) added exceptions when `nullptr` is passed to `parse`.\n366. [Stuart Gorman](https://github.com/StuartGorman) fixed number parsing when `EINTR` set in `errno`.\n367. [Dylan Baker](https://github.com/dcbaker) generated a pkg-config file that follows the pkg-config conventions.\n368. [Tianyi Chen](https://github.com/TianyiChen) optimized the binary `get_number` implementation.\n369. [peng-wang-cn](https://github.com/peng-wang-cn) added type conversion support for multidimensional arrays.\n370. [Einars Netlis-Galejs](https://github.com/EinarsNG) added `ONLY_SERIALIZE` for `NLOHMANN_DEFINE_DERIVED_TYPE_*` macros.\n371. [Marcel](https://github.com/mering) removed `alwayslink=True` Bazel flag.\n372. [Harinath Nampally](https://github.com/hnampally) added diagnostic positions to exceptions.\n373. [Nissim Armand Ben Danan](https://github.com/NissimBendanan) fixed `NLOHMANN_DEFINE_TYPE_INTRUSIVE_WITH_DEFAULT` with an empty JSON instance.\n374. [Michael Valladolid](https://github.com/codenut) added support for BSON uint64 serialization/deserialization.\n375. [Nikhil](https://github.com/nikhilreddydev) updated the documentation.\n376. [Neboj≈°a Cvetkoviƒá](https://github.com/nebkat) added support for BJDATA optimized binary array type.\n377. [Sushrut Shringarputale](https://github.com/sushshring) added support for diagnostic positions. \n378. [kimci86](https://github.com/kimci86) templated to `NLOHMANN_DEFINE_TYPE` macros to also support `ordered_json`.\n379. [Richard Topchii](https://github.com/richardtop) added support for VisionOS in the Swift Package Manager.\n380. [Robert Chisholm](https://github.com/Robadob) fixed a typo.\n381. [zjyhjqs](https://github.com/zjyhjqs) added CPack support.\n382. [bitFiedler](https://github.com/bitFiedler) made GDB pretty printer work with Python 3.8.\n383. [Gianfranco Costamagna](https://github.com/LocutusOfBorg) fixed a compiler warning.\n384. [risa2000](https://github.com/risa2000) made `std::filesystem::path` conversion to/from UTF-8 encoded string explicit.\n\nThanks a lot for helping out! Please [let me know](mailto:mail@nlohmann.me) if I forgot someone.\n\n## Used third-party tools\n\nThe library itself consists of a single header file licensed under the MIT license. However, it is built, tested, documented, and whatnot using a lot of third-party tools and services. Thanks a lot!\n\n- [**amalgamate.py - Amalgamate C source and header files**](https://github.com/edlund/amalgamate) to create a single header file\n- [**American fuzzy lop**](https://lcamtuf.coredump.cx/afl/) for fuzz testing\n- [**AppVeyor**](https://www.appveyor.com) for [continuous integration](https://ci.appveyor.com/project/nlohmann/json) on Windows\n- [**Artistic Style**](http://astyle.sourceforge.net) for automatic source code indentation\n- [**Clang**](https://clang.llvm.org) for compilation with code sanitizers\n- [**CMake**](https://cmake.org) for build automation\n- [**Codacy**](https://www.codacy.com) for further [code analysis](https://app.codacy.com/gh/nlohmann/json/dashboard)\n- [**Coveralls**](https://coveralls.io) to measure [code coverage](https://coveralls.io/github/nlohmann/json)\n- [**Coverity Scan**](https://scan.coverity.com) for [static analysis](https://scan.coverity.com/projects/nlohmann-json)\n- [**cppcheck**](http://cppcheck.sourceforge.net) for static analysis\n- [**doctest**](https://github.com/onqtam/doctest) for the unit tests\n- [**GitHub Changelog Generator**](https://github.com/skywinder/github-changelog-generator) to generate the [ChangeLog](https://github.com/nlohmann/json/blob/develop/ChangeLog.md)\n- [**Google Benchmark**](https://github.com/google/benchmark) to implement the benchmarks\n- [**Hedley**](https://nemequ.github.io/hedley/) to avoid re-inventing several compiler-agnostic feature macros\n- [**lcov**](https://github.com/linux-test-project/lcov) to process coverage information and create an HTML view\n- [**libFuzzer**](https://llvm.org/docs/LibFuzzer.html) to implement fuzz testing for OSS-Fuzz\n- [**Material for MkDocs**](https://squidfunk.github.io/mkdocs-material/) for the style of the documentation site\n- [**MkDocs**](https://www.mkdocs.org) for the documentation site\n- [**OSS-Fuzz**](https://github.com/google/oss-fuzz) for continuous fuzz testing of the library ([project repository](https://github.com/google/oss-fuzz/tree/master/projects/json))\n- [**Probot**](https://probot.github.io) for automating maintainer tasks such as closing stale issues, requesting missing information, or detecting toxic comments.\n- [**Valgrind**](https://valgrind.org) to check for correct memory management\n\n## Notes\n\n### Character encoding\n\nThe library supports **Unicode input** as follows:\n\n- Only **UTF-8** encoded input is supported, which is the default encoding for JSON according to [RFC 8259](https://tools.ietf.org/html/rfc8259.html#section-8.1).\n- `std::u16string` and `std::u32string` can be parsed, assuming UTF-16 and UTF-32 encoding, respectively. These encodings are not supported when reading from files or other input containers.\n- Other encodings such as Latin-1 or ISO 8859-1 are **not** supported and will yield parse or serialization errors.\n- [Unicode noncharacters](https://www.unicode.org/faq/private_use.html#nonchar1) will not be replaced by the library.\n- Invalid surrogates (e.g., incomplete pairs such as `\\uDEAD`) will yield parse errors.\n- The strings stored in the library are UTF-8 encoded. When using the default string type (`std::string`), note that its length/size functions return the number of stored bytes rather than the number of characters or glyphs.\n- When you store strings with different encodings in the library, calling [`dump()`](https://json.nlohmann.me/api/basic_json/dump/) may throw an exception unless `json::error_handler_t::replace` or `json::error_handler_t::ignore` are used as error handlers.\n- To store wide strings (e.g., `std::wstring`), you need to convert them to a UTF-8 encoded `std::string` before, see [an example](https://json.nlohmann.me/home/faq/#wide-string-handling).\n\n### Comments in JSON\n\nThis library does not support comments by default. It does so for three reasons:\n\n1. Comments are not part of the [JSON specification](https://tools.ietf.org/html/rfc8259). You may argue that `//` or `/* */` are allowed in JavaScript, but JSON is not JavaScript.\n2. This was not an oversight: Douglas Crockford [wrote on this](https://plus.google.com/118095276221607585885/posts/RK8qyGVaGSr) in May 2012:\n  \n    > I removed comments from JSON because I saw people were using them to hold parsing directives, a practice which would have destroyed interoperability.  I know that the lack of comments makes some people sad, but it shouldn't.\n    >\n    > Suppose you are using JSON to keep configuration files, which you would like to annotate. Go ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser.\n  \n3. It is dangerous for interoperability if some libraries would add comment support while others don't. Please check [The Harmful Consequences of the Robustness Principle](https://tools.ietf.org/html/draft-iab-protocol-maintenance-01) on this.\n\nHowever, you can set set parameter `ignore_comments` to true in the `parse` function to ignore `//` or `/* */` comments. Comments will then be treated as whitespace.\n\n### Trailing commas\n\nThe JSON specification does not allow trailing commas in arrays and objects, and hence this library is treating them as parsing errors by default.\n\nLike comments, you can set parameter `ignore_trailing_commas` to true in the `parse` function to ignore trailing commas in arrays and objects. Note that a single comma as the only content of the array or object (`[,]` or `{,}`) is not allowed, and multiple trailing commas (`[1,,]`) are not allowed either.\n\nThis library does not add trailing commas when serializing JSON data.\n\nFor more information, see [JSON With Commas and Comments (JWCC)](https://nigeltao.github.io/blog/2021/json-with-commas-comments.html).\n\n### Order of object keys\n\nBy default, the library does not preserve the **insertion order of object elements**. This is standards-compliant, as the [JSON standard](https://tools.ietf.org/html/rfc8259.html) defines objects as \"an unordered collection of zero or more name/value pairs\".\n\nIf you do want to preserve the insertion order, you can try the type [`nlohmann::ordered_json`](https://github.com/nlohmann/json/issues/2179). Alternatively, you can use a more sophisticated ordered map like [`tsl::ordered_map`](https://github.com/Tessil/ordered-map) ([integration](https://github.com/nlohmann/json/issues/546#issuecomment-304447518)) or [`nlohmann::fifo_map`](https://github.com/nlohmann/fifo_map) ([integration](https://github.com/nlohmann/json/issues/485#issuecomment-333652309)).\n\nSee the [**documentation on object order**](https://json.nlohmann.me/features/object_order/) for more information.\n\n### Memory Release\n\nWe checked with Valgrind and the Address Sanitizer (ASAN) that there are no memory leaks.\n\nIf you find that a parsing program with this library does not release memory, please consider the following case, and it may be unrelated to this library.\n\n**Your program is compiled with glibc.** There is a tunable threshold that glibc uses to decide whether to actually return memory to the system or whether to cache it for later reuse. If in your program you make lots of small allocations and those small allocations are not a contiguous block and are presumably below the threshold, then they will not get returned to the OS.\nHere is a related issue [#1924](https://github.com/nlohmann/json/issues/1924).\n\n### Further notes\n\n- The code contains numerous debug **assertions** which can be switched off by defining the preprocessor macro `NDEBUG`, see the [documentation of `assert`](https://en.cppreference.com/w/cpp/error/assert). In particular, note [`operator[]`](https://json.nlohmann.me/api/basic_json/operator%5B%5D/) implements **unchecked access** for const objects: If the given key is not present, the behavior is undefined (think of a dereferenced null pointer) and yields an [assertion failure](https://github.com/nlohmann/json/issues/289) if assertions are switched on. If you are not sure whether an element in an object exists, use checked access with the [`at()` function](https://json.nlohmann.me/api/basic_json/at/). Furthermore, you can define `JSON_ASSERT(x)` to replace calls to `assert(x)`. See the [**documentation on runtime assertions**](https://json.nlohmann.me/features/assertions/) for more information.\n- As the exact number type is not defined in the [JSON specification](https://tools.ietf.org/html/rfc8259.html), this library tries to choose the best fitting C++ number type automatically. As a result, the type `double` may be used to store numbers which may yield [**floating-point exceptions**](https://github.com/nlohmann/json/issues/181) in certain rare situations if floating-point exceptions have been unmasked in the calling code. These exceptions are not caused by the library and need to be fixed in the calling code, such as by re-masking the exceptions prior to calling library functions.\n- The code can be compiled without C++ **runtime type identification** features; that is, you can use the `-fno-rtti` compiler flag.\n- **Exceptions** are used widely within the library. They can, however, be switched off with either using the compiler flag `-fno-exceptions` or by defining the symbol `JSON_NOEXCEPTION`. In this case, exceptions are replaced by `abort()` calls. You can further control this behavior by defining `JSON_THROW_USER` (overriding `throw`), `JSON_TRY_USER` (overriding `try`), and `JSON_CATCH_USER` (overriding `catch`). Note that `JSON_THROW_USER` should leave the current scope (e.g., by throwing or aborting), as continuing after it may yield undefined behavior. Note the explanatory [`what()`](https://en.cppreference.com/w/cpp/error/exception/what) string of exceptions is not available for MSVC if exceptions are disabled, see [#2824](https://github.com/nlohmann/json/discussions/2824). See the [**documentation of exceptions**](https://json.nlohmann.me/home/exceptions/) for more information.\n\n## Execute unit tests\n\nTo compile and run the tests, you need to execute\n\n```shell\nmkdir build\ncd build\ncmake .. -DJSON_BuildTests=On\ncmake --build .\nctest --output-on-failure\n```\n\nNote that during the `ctest` stage, several JSON test files are downloaded from an [external repository](https://github.com/nlohmann/json_test_data). If policies forbid downloading artifacts during testing, you can download the files yourself and pass the directory with the test files via `-DJSON_TestDataDirectory=path` to CMake. Then, no Internet connectivity is required. See [issue #2189](https://github.com/nlohmann/json/issues/2189) for more information.\n\nIf the testdata is not found, several test suites will fail like this:\n\n```\n===============================================================================\njson/tests/src/make_test_data_available.hpp:21:\nTEST CASE:  check test suite is downloaded\n\njson/tests/src/make_test_data_available.hpp:23: FATAL ERROR: REQUIRE( utils::check_testsuite_downloaded() ) is NOT correct!\n  values: REQUIRE( false )\n  logged: Test data not found in 'json/cmake-build-debug/json_test_data'.\n          Please execute target 'download_test_data' before running this test suite.\n          See <https://github.com/nlohmann/json#execute-unit-tests> for more information.\n\n===============================================================================\n```\n\nIn case you have downloaded the library rather than checked out the code via Git, test `cmake_fetch_content_configure` will fail. Please execute `ctest -LE git_required` to skip these tests. See [issue #2189](https://github.com/nlohmann/json/issues/2189) for more information.\n\nSome tests are requiring network to be properly execute. They are labeled as `git_required`. Please execute `ctest -LE git_required` to skip these tests. See [issue #4851](https://github.com/nlohmann/json/issues/4851) for more information.\n\nSome tests change the installed files and hence make the whole process not reproducible. Please execute `ctest -LE not_reproducible` to skip these tests. See [issue #2324](https://github.com/nlohmann/json/issues/2324) for more information. Furthermore, assertions must be switched off to ensure reproducible builds (see [discussion 4494](https://github.com/nlohmann/json/discussions/4494)).\n\nNote you need to call `cmake -LE \"not_reproducible|git_required\"` to exclude both labels. See [issue #2596](https://github.com/nlohmann/json/issues/2596) for more information.\n\nAs Intel compilers use unsafe floating point optimization by default, the unit tests may fail. Use flag [`/fp:precise`](https://www.intel.com/content/www/us/en/docs/cpp-compiler/developer-guide-reference/2021-8/fp-model-fp.html) then.\n",
      "stars_today": 17
    },
    {
      "id": 521189491,
      "name": "cloudstream",
      "full_name": "recloudstream/cloudstream",
      "description": "Android app for streaming and downloading media.",
      "html_url": "https://github.com/recloudstream/cloudstream",
      "stars": 8679,
      "forks": 758,
      "language": "Kotlin",
      "topics": [
        "android",
        "good-first-issue",
        "home-theater",
        "media-center",
        "multimedia",
        "video-streaming"
      ],
      "created_at": "2022-08-04T08:42:38Z",
      "updated_at": "2026-01-23T20:11:46Z",
      "pushed_at": "2026-01-23T19:56:27Z",
      "open_issues": 448,
      "owner": {
        "login": "recloudstream",
        "avatar_url": "https://avatars.githubusercontent.com/u/110591699?v=4"
      },
      "readme": "# CloudStream\n\n**‚ö†Ô∏è Warning: By default, this app doesn't provide any video sources; you have to install extensions to add functionality to the app.**\n\n[![Discord](https://invidget.switchblade.xyz/5Hus6fM)](https://discord.gg/5Hus6fM)\n\n\n## Table of Contents: \n+ [About Us:](#about_us)\n+ [Installation Steps:](#install_rules)\n+ [Contributing:](#contributing)\n+ [Issues:](#issues)\n  + [Bugs Reports:](#bug_report)\n  + [Enhancement:](#enhancment)\n+ [Extension Development:](#extensions)\n+ [Language Support:](#languages)\n+ [Further Sources](#contact_and_sources)\n\n\n<a id=\"about_us\"></a>\n\n## About us: \n\n**CloudStream is a media center that prioritizes and emphasizes complete freedom and flexibility for users and developers.** \n\nCloudStream is an extension-based multimedia player with tracking support. There are extensions to view videos from: \n\n+ [Librevox (audio-books)](https://librivox.org/) \n+ [Youtube](https://www.youtube.com/)\n+ [Twitch](https://www.twitch.tv/)\n+ [iptv-org (A collection of publicly available IPTV (Internet Protocol television) channels from all over the world.)](https://github.com/iptv-org/iptv) \n+ [nginx](https://nginx.org/)\n+ And more... \n\n\n**Please don't create illegal extensions or use any that host any copyrighted media.** For more details about our stance on the DMCA and EUCD, you can read about it on our organization: [reCloudStream](https://github.com/recloudstream)\n\n#### Important Copyright Note: \n\nOur documentation is unmaintained and open to contributions; therefore, apps and sources, extensions in recommended sources, and recommended apps are not officially moderated or endorsed by CloudStream; if you or another copyright owner identify an extension that breaches your copyright, please let us know. \n\n\n#### Features:\n+ **AdFree**, No ads whatsoever\n+ No tracking/analytics\n+ Bookmarks\n+ Phone and TV support\n+ Chromecast\n+ Extension system for personal customization\n\n\n<a id=\"install_rules\"></a>\n\n## Installation: \n\nOur documentation provides the steps to install and configure CloudStream for your streaming needs.\n\n[Getting Started With CloudStream:](https://recloudstream.github.io/csdocs/)\n\n<a id=\"contributing\"></a>\n\n## Contributing:\nWe **happily** accept any contributions to our project. To find out where you can start contributing towards the project, please look [at our issues tab](/cloudstream/issues)\n\n\n\n<a id=\"issues\"></a> \n \n### Issues: \nWhile we **actively** accept issues and pull requests, we do require you fill out an [template](https://github.com/recloudstream/cloudstream/issues/new/choose) for issues. These include the following:\n\n<a id=\"bug_report\"></a>\n\n- [Bug Report Template: ](https://github.com/recloudstream/cloudstream/issues/new?assignees=&labels=bug&projects=&template=application-bug.yml)\n  - For bug reports, we want as much info as possible, including your downloaded version of CloudeStream, device and updated version (if possible, current API),\n    expected behavior of the program, and the actual behavior that the program did, most importantly we require clear, reproducible steps of the bug. If your bug can't be       reproduced, it is unlikely we'll work on your issue.\n    \n<a id=\"enhancment\"></a>\n  \n- [Feature Request Template: ](https://github.com/recloudstream/cloudstream/issues/new?assignees=&labels=enhancement&projects=&template=feature-request.yml)\n  - Before adding a feature request, please check to see if a feature request already has been requested.  \n\n\n### Extensions:\n \n**Further details on creating extensions for CloudStream are found in our documentation.**\n\n[Guide: For Extension Developers](https://recloudstream.github.io/csdocs/devs/gettingstarted/) \n\n<a id=\"contact_and_sources\"></a>\n\n## Further Sources: \n\nAs well as providing clear install steps, our [website](https://dweb.link/ipns/cloudstream.on.fleek.co/) includes a wide variety of other tools, such as: \n- [Troubleshooting](https://recloudstream.github.io/csdocs/troubleshooting/)\n- [Further CloudStream Repositories](https://recloudstream.github.io/csdocs/repositories/) \n- Set-Up for other devices, such as:\n  - [Android TV](https://recloudstream.github.io/csdocs/other-devices/tv/)\n  - [Windows](https://recloudstream.github.io/csdocs/other-devices/windows/)\n  - [Linux](https://recloudstream.github.io/csdocs/other-devices/linux/)\n- And more...\n\n<a id=\"languages\"> </a>  \n\n### Supported languages:\n\nEven if you can't contribute to the code or documentation, we always look for those who can contribute to translation and language support. Your contribution is exceptionally appreciated; you can check our translation from the figure below. \n\n<a href=\"https://hosted.weblate.org/engage/cloudstream/\">\n  <img src=\"https://hosted.weblate.org/widgets/cloudstream/-/app/multi-auto.svg\" alt=\"Translation status\" />\n</a>\n",
      "stars_today": 16
    },
    {
      "id": 2489216,
      "name": "intellij-community",
      "full_name": "JetBrains/intellij-community",
      "description": "IntelliJ IDEA & IntelliJ Platform",
      "html_url": "https://github.com/JetBrains/intellij-community",
      "stars": 19582,
      "forks": 5668,
      "language": "Java",
      "topics": [
        "code-editor",
        "ide",
        "intellij",
        "intellij-community",
        "intellij-platform"
      ],
      "created_at": "2011-09-30T13:33:05Z",
      "updated_at": "2026-01-24T01:34:10Z",
      "pushed_at": "2026-01-22T13:05:00Z",
      "open_issues": 150,
      "owner": {
        "login": "JetBrains",
        "avatar_url": "https://avatars.githubusercontent.com/u/878437?v=4"
      },
      "readme": "[![official JetBrains project](http://jb.gg/badges/official.svg)](https://github.com/JetBrains/.github/blob/main/profile/README.md) [![IntelliJ IDEA build status](https://github.com/JetBrains/intellij-community/workflows/IntelliJ%20IDEA/badge.svg)](https://github.com/JetBrains/intellij-community/actions/workflows/IntelliJ_IDEA.yml) [![PyCharm build status](https://github.com/JetBrains/intellij-community/workflows/PyCharm/badge.svg)](https://github.com/JetBrains/intellij-community/actions/workflows/PyCharm.yml)\n\n# IntelliJ Open Source Repository\n\nThis repository is the open-source part of the JetBrains IDEs codebase.\nIt also serves as the basis for¬†[IntelliJ Platform development](https://www.jetbrains.com/opensource/idea). \n\nThese instructions will help you build and run open source parts of IntelliJ Platform / IntelliJ IDEA / PyCharm.\n\nIf you are new to the community and would like to contribute code or help others learn, see¬†[CONTRIBUTING.md](https://github.com/JetBrains/intellij-community/blob/master/CONTRIBUTING.md)¬†to get started.\n\nThe following conventions will be used to refer to directories on your machine:\n* `<USER_HOME>` is your OS user's home directory.\n* `<IDEA_HOME>` is the root directory for the **IntelliJ source code**.\n\n___\n## Getting the Source Code\n\nThis section will guide you through getting the project sources and help avoid common issues in git config and other steps before opening it in the IDE.\n\n#### Prerequisites\n- [Git](https://git-scm.com/) installed\n- ~2GB free disk space\n- Install [IntelliJ IDEA 2023.2](https://www.jetbrains.com/idea/download) or higher.\n- For **Windows** set these git config to avoid common issues during cloning:\n  ```\n  git config --global core.longpaths true\n  git config --global core.autocrlf input\n  ```\n\n#### Clone Main Repository\n\nIntelliJ open source repository is available from the [GitHub repository](https://github.com/JetBrains/intellij-community), which can be cloned or downloaded as a zip file (based on a branch) into `<IDEA_HOME>`. \nThe **master** (_default_) branch contains the source code which will be used to create the next major version of all JetBrains IDEs. \nThe branch names and build numbers for older releases of JetBrains IDEs can be found on the\n[Build Number Ranges](https://plugins.jetbrains.com/docs/intellij/build-number-ranges.html) page.\n\nYou can [clone this project](https://www.jetbrains.com/help/idea/manage-projects-hosted-on-github.html#clone-from-GitHub) directly using IntelliJ IDEA. \n\nAlternatively, follow the steps below in a terminal:\n\n   ```\n   git clone https://github.com/JetBrains/intellij-community.git\n   cd intellij-community\n   ```\n\n> [!TIP]\n> - **For faster download**: If the complete repository history isn't needed, create [shallow clone](https://git-scm.com/docs/git-clone#Documentation/git-clone.txt---depthdepth)\n> To download only the latest revision of the repository,  add `--depth 1` option after `clone`.\n> - Cloning in IntelliJ IDEA also supports creating shallow clone.\n\n#### Get Android Modules\nIntelliJ IDEA requires additional Android modules from separate Git repositories.\n\nRun the following script from project root `<IDEA_HOME>` to get the required modules:\n- Linux/macOS: `./getPlugins.sh`\n- Windows: `getPlugins.bat`\n\n> [!IMPORTANT]\n>\n>  Always `git checkout` the `intellij-community` and `android` Git repositories to the same branches/tags.\n\n\n---\n## Building IntelliJ IDEA\n\n> [Standard GitHub runners](https://docs.github.com/en/actions/concepts/runners/github-hosted-runners) can no longer be used to build the project due to the disk size limitation.\n> Now we use [larger runners](https://docs.github.com/en/enterprise-cloud@latest/actions/concepts/runners/larger-runners) which are only available for organizations and enterprises using the GitHub Team or GitHub Enterprise Cloud plans.\n> Users of personal GitHub accounts can use [the prebuilt binaries](https://github.com/JetBrains/intellij-community/releases), \n> or build IntelliJ IDEA from source code locally.\n\nThese instructions will help you build IntelliJ IDEA from source code, which is the basis for IntelliJ Platform development.\nIntelliJ IDEA '**2023.2**' or newer is required.\n\n### Opening the IntelliJ IDEA Source Code in the IDE\nUsing the latest IntelliJ IDEA, click '**File | Open**', select the `<IDEA_HOME>` directory.\nIf IntelliJ IDEA displays a message about a missing or out-of-date required plugin (e.g. Kotlin),\n[enable, upgrade, or install that plugin](https://www.jetbrains.com/help/idea/managing-plugins.html) and restart IntelliJ IDEA.\n\n\n### Build Configuration Steps\n1. **JDK Setup**\n\n- Use JetBrains Runtime 21 (without JCEF) to compile\n  - IDE will prompt to download it on the first build\n> [!IMPORTANT]\n>\n> JetBrains Runtime **without** JCEF is required. If `jbr-21` SDK points to JCEF version, change it to the non-JCEF version:\n> - Add `idea.is.internal=true` to `idea.properties` and restart the IDE.\n> - Go to '**Project Structure | SDKs**'\n> - Click 'Browse' ‚Üí 'Download...'\n> - Select version 21 and vendor 'JetBrains Runtime'\n> - To confirm if the JDK is correct, navigate to the SDK page with jbr-21 selected. Search for `jcef`, it should **_NOT_** yield a result.\n\n2. **Maven Configuration** : If the¬†**Maven**¬†plugin is disabled,¬†[add the path variable](https://www.jetbrains.com/help/idea/absolute-path-variables.html)¬†\"**MAVEN_REPOSITORY**\" pointing to¬†`<USER_HOME>/.m2/repository`¬†directory.\n\n3. **Memory Settings**\n  - Ensure a minimum **8GB** RAM on your computer.\n  - With the minimum RAM, disable \"**Compile independent modules in parallel**\" in '**Settings | Build, Execution, Deployment | Compiler**'.\n  - With notably higher available RAM, Increase \"**User-local heap size**\" to `3000`.\n\n\n### Building the IntelliJ IDEA Application from Source\n\n**To build IntelliJ IDEA from source**, choose '**Build | Build Project**' from the main menu.\n\n**To build installation packages**, run the [installers.cmd](installers.cmd) script in `<IDEA_HOME>` directory. `installers.cmd` will work on both Windows and Unix systems.\nOptions to build installers are passed as system properties to `installers.cmd` command.\nYou may find the list of available properties in [BuildOptions.kt](platform/build-scripts/src/org/jetbrains/intellij/build/BuildOptions.kt)\n\nPass --debug to suspend and wait for debugger at port 5005\n\nInstaller build examples:\n```bash\n# Build installers only for current operating system:\n./installers.cmd -Dintellij.build.target.os=current\n```\n\n> [!TIP]\n> \n> The `installers.cmd` is used to run [OpenSourceCommunityInstallersBuildTarget](build/src/OpenSourceCommunityInstallersBuildTarget.kt) from the command line.\n> You can also call it directly from IDEA, using run configuration `Build IntelliJ IDEA Installers (current OS)`.\n\n\n#### Dockerized Build Environment\nTo build installation packages inside a Docker container with preinstalled dependencies and tools, run the following command in `<IDEA_HOME>` directory (on Windows, use PowerShell):\n```bash\ndocker build . --target intellij_idea --tag intellij_idea_env\ndocker run --rm --user \"$(id -u)\" --volume \"${PWD}:/community\" intellij_idea_env\n```\n> [!NOTE]\n> \n> Please remember to specify the `--user \"$(id -u)\"` argument for the container's user to match the host's user.\n> This prevents issues with permissions for the checked-out repository, the build output, if any.\n\n---\n## Running IntelliJ IDEA\nTo run the IntelliJ IDEA that was built from source, choose '**Run | Run**' from the main menu. This will use the preconfigured run configuration `IDEA`.\n\nTo run tests on the build, apply these settings to the '**Run | Edit Configurations... | Templates | JUnit**' configuration tab:\n* Working dir: `<IDEA_HOME>/bin`\n* VM options:  `-ea`\n\n\n#### Running IntelliJ IDEA in CI/CD environment\n\nTo run tests outside of IntelliJ IDEA, run the `tests.cmd` command in `<IDEA_HOME>` directory.`tests.cmd` can be used in both Windows and Unix systems.\nOptions to run tests are passed as system properties to `tests.cmd` command.\nYou may find the list of available properties in [TestingOptions.kt](platform/build-scripts/src/org/jetbrains/intellij/build/TestingOptions.kt)\n\n```bash\n# Run specific run configuration:\n./tests.cmd -Dintellij.build.test.configurations=ApiCheckTest\n```\n```bash\n# Run a specific test: \n./tests.cmd -Dintellij.build.test.patterns=com.intellij.util.ArrayUtilTest\n```\n\nto debug tests use: `-Dintellij.build.test.debug.suspend=true -Dintellij.build.test.debug.port=5005`\n\n`tests.cmd` is used just to run [CommunityRunTestsBuildTarget](build/src/CommunityRunTestsBuildTarget.kt) from the command line.\nYou can also call it directly from IDEA, see run configuration `tests` for an example.",
      "stars_today": 15
    },
    {
      "id": 860100131,
      "name": "typescript-go",
      "full_name": "microsoft/typescript-go",
      "description": "Staging repo for development of native port of TypeScript",
      "html_url": "https://github.com/microsoft/typescript-go",
      "stars": 23839,
      "forks": 805,
      "language": "Go",
      "topics": [],
      "created_at": "2024-09-19T20:25:12Z",
      "updated_at": "2026-01-23T21:35:31Z",
      "pushed_at": "2026-01-23T23:04:32Z",
      "open_issues": 258,
      "owner": {
        "login": "microsoft",
        "avatar_url": "https://avatars.githubusercontent.com/u/6154722?v=4"
      },
      "readme": "# TypeScript 7\n\n[Not sure what this is? Read the announcement post!](https://devblogs.microsoft.com/typescript/typescript-native-port/)\n\n## Preview\n\nA preview build is available on npm as [`@typescript/native-preview`](https://www.npmjs.com/package/@typescript/native-preview).\n\n```sh\nnpm install @typescript/native-preview\nnpx tsgo # Use this as you would tsc.\n```\n\nA preview VS Code extension is [available on the VS Code marketplace](https://marketplace.visualstudio.com/items?itemName=TypeScriptTeam.native-preview).\n\nTo use this, set this in your VS Code settings:\n\n```json\n{\n    \"typescript.experimental.useTsgo\": true\n}\n```\n\n## What Works So Far?\n\nThis is still a work in progress and is not yet at full feature parity with TypeScript. Bugs may exist. Please check this list carefully before logging a new issue or assuming an intentional change.\n\n| Feature | Status | Notes |\n|---------|--------|-------|\n| Program creation | done | Same files and module resolution as TS 5.9. Not all resolution modes supported yet. |\n| Parsing/scanning | done | Exact same syntax errors as TS 5.9 |\n| Commandline and `tsconfig.json` parsing | done | Done, though `tsconfig` errors may not be as helpful. |\n| Type resolution | done | Same types as TS 5.9. |\n| Type checking | done | Same errors, locations, and messages as TS 5.9. Types printback in errors may display differently. |\n| JavaScript-specific inference and JSDoc | in progress | Mostly complete, but intentionally lacking some features. Declaration emit not complete. |\n| JSX | done | - |\n| Declaration emit | in progress | Most common features are in place, but some edge cases and feature flags are still unhandled. |\n| Emit (JS output) | in progress | `target: esnext` well-supported, other targets may have gaps. |\n| Watch mode | prototype | Watches files and rebuilds, but no incremental rechecking. Not optimized. |\n| Build mode / project references | done | - |\n| Incremental build | done | - |\n| Language service (LSP) | in progress | Most functionality. More features coming soon. |\n| API | not ready | - |\n\nDefinitions:\n\n * **done** aka \"believed done\": We're not currently aware of any deficits or major left work to do. OK to log bugs\n * **in progress**: currently being worked on; some features may work and some might not. OK to log panics, but nothing else please\n * **prototype**: proof-of-concept only; do not log bugs\n * **not ready**: either haven't even started yet, or far enough from ready that you shouldn't bother messing with it yet\n\n## Other Notes\n\nLong-term, we expect that this repo and its contents will be merged into `microsoft/TypeScript`.\nAs a result, the repo and issue tracker for typescript-go will eventually be closed, so treat discussions/issues accordingly.\n\nFor a list of intentional changes with respect to TypeScript 5.9, see CHANGES.md.\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit [Contributor License Agreements](https://cla.opensource.microsoft.com).\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft\ntrademarks or logos is subject to and must follow\n[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general).\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\nAny use of third-party trademarks or logos are subject to those third-party's policies.\n",
      "stars_today": 15
    },
    {
      "id": 81975372,
      "name": "interviews",
      "full_name": "kdn251/interviews",
      "description": "Everything you need to know to get the job.",
      "html_url": "https://github.com/kdn251/interviews",
      "stars": 64810,
      "forks": 12933,
      "language": "Java",
      "topics": [
        "algorithm",
        "algorithm-challenges",
        "algorithm-competitions",
        "algorithms",
        "coding-challenge",
        "coding-challenges",
        "coding-interview",
        "coding-interviews",
        "interview",
        "interview-practice",
        "interview-prep",
        "interview-preparation",
        "interview-questions",
        "interviews",
        "java",
        "leetcode",
        "leetcode-java",
        "leetcode-questions",
        "leetcode-solutions",
        "technical-coding-interview"
      ],
      "created_at": "2017-02-14T18:19:25Z",
      "updated_at": "2026-01-24T01:44:57Z",
      "pushed_at": "2025-05-12T12:56:04Z",
      "open_issues": 118,
      "owner": {
        "login": "kdn251",
        "avatar_url": "https://avatars.githubusercontent.com/u/16903644?v=4"
      },
      "readme": "# Interviews\n> Pass your coding interviews with [The Daily Byte](https://thedailybyte.dev/?ref=kevin)  \n> [30,000+ Software Engineers have trusted us with their interview prep](https://thedailybyte.dev/?ref=kevin).\n<a href=\"\" style=\"display:block;\"><img src=\"/images/the-daily-byte.png?raw=true\"></a>\n>\n> Maintainer - [Kevin Naughton Jr.](https://github.com/kdn251)\n\n## Translations\n\n- [ÁÆÄ‰Ωì‰∏≠Êñá](./README-zh-cn.md)\n\n## Table of Contents\n- [YouTube](#youtube)\n- [The Daily Byte](#the-daily-byte)\n- [Instagram](#instagram)\n- [Articles](#articles)\n- [Online Judges](#online-judges)\n- [Live Coding Practice](#live-coding-practice)\n- [Data Structures](#data-structures)\n- [Algorithms](#algorithms)\n- [Greedy Algorithms](#greedy-algorithms)\n- [Bitmasks](#bitmasks)\n- [Runtime Analysis](#runtime-analysis)\n- [Video Lectures](#video-lectures)\n- [Interview Books](#interview-books)\n- [Computer Science News](#computer-science-news)\n- [Directory Tree](#directory-tree)\n\n## YouTube\n* [Kevin Naughton Jr.](https://www.youtube.com/channel/UCKvwPt6BifPP54yzH99ff1g)\n\n## The Daily Byte\n* [FAANG Interview Prep](https://thedailybyte.dev/?ref=kevin)\n\n## Instagram \n* [Kevin Naughton Jr.](https://www.instagram.com/kevinnaughtonjr)\n\n## Online Judges\n* [LeetCode](https://leetcode.com/)\n* [Virtual Judge](https://vjudge.net/)\n* [CareerCup](https://www.careercup.com/)\n* [HackerRank](https://www.hackerrank.com/)\n* [CodeFights](https://codefights.com/)\n* [Kattis](https://open.kattis.com/)\n* [HackerEarth](https://www.hackerearth.com)\n* [Codility](https://codility.com/programmers/lessons/1-iterations/)\n* [Code Forces](http://codeforces.com/)\n* [Code Chef](https://www.codechef.com/)\n* [Sphere Online Judge - SPOJ](http://www.spoj.com/)\n* [InterviewBit](https://www.interviewbit.com/)\n\n## Live Mock Interviews\n* [The Daily Byte](https://thedailybyte.dev/mock-interview)\n\n## Live Coding Practice\n* [The Daily Byte](https://thedailybyte.dev/?ref=kevin)\n* [Pramp](https://www.pramp.com/ref/gt4)\n* [Gainlo](http://www.gainlo.co/#!/)\n* [Refdash](https://refdash.com/)\n* [Interviewing.io](https://www.interviewing.io/)\n\n## Data Structures\n### Linked List\n * A *Linked List* is a linear collection of data elements, called nodes, each\n   pointing to the next node by means of a pointer. It is a data structure\n   consisting of a group of nodes which together represent a sequence.\n * **Singly-linked list**: linked list in which each node points to the next node and the last node points to null\n * **Doubly-linked list**: linked list in which each node has two pointers, p and n, such that p points to the previous node and n points to the next node; the last node's n pointer points to null\n * **Circular-linked list**: linked list in which each node points to the next node and the last node points back to the first node\n * Time Complexity:\n   * Access: `O(n)`\n   * Search: `O(n)`\n   * Insert: `O(1)`\n   * Remove: `O(1)`\n\n### Stack\n * A *Stack* is a collection of elements, with two principle operations: *push*, which adds to the collection, and\n   *pop*, which removes the most recently added element\n * **Last in, first out data structure (LIFO)**: the most recently added object is the first to be removed\n * Time Complexity:\n   * Access: `O(n)`\n   * Search: `O(n)`\n   * Insert: `O(1)`\n   * Remove: `O(1)`\n\n### Queue\n * A *Queue* is a collection of elements, supporting two principle operations: *enqueue*, which inserts an element\n   into the queue, and *dequeue*, which removes an element from the queue\n * **First in, first out data structure (FIFO)**: the oldest added object is the first to be removed\n * Time Complexity:\n   * Access: `O(n)`\n   * Search: `O(n)`\n   * Insert: `O(1)`\n   * Remove: `O(1)`\n\n### Tree\n * A *Tree* is an undirected, connected, acyclic graph\n\n### Binary Tree\n * A *Binary Tree* is a tree data structure in which each node has at most two children, which are referred to as\n   the *left child* and *right child*\n * **Full Tree**: a tree in which every node has either 0 or 2 children\n * **Perfect Binary Tree**: a binary tree in which all interior nodes have two children and all leave have the same depth\n * **Complete Tree**: a binary tree in which every level *except possibly the last* is full and all nodes in the last\n   level are as far left as possible\n\n### Binary Search Tree\n * A binary search tree, sometimes called BST, is a type of binary tree which maintains the property that the value in each\n   node must be greater than or equal to any value stored in the left sub-tree, and less than or equal to any value stored\n   in the right sub-tree\n * Time Complexity:\n   * Access: `O(log(n))`\n   * Search: `O(log(n))`\n   * Insert: `O(log(n))`\n   * Remove: `O(log(n))`\n\n<img src=\"/images/BST.png?raw=true\" alt=\"Binary Search Tree\" width=\"400\" height=\"500\">\n\n### Trie\n* A trie, sometimes called a radix or prefix tree, is a kind of search tree that is used to store a dynamic set or associative\n  array where the keys are usually Strings. No node in the tree stores the key associated with that node; instead, its position \n  in the tree defines the key with which it is associated. All the descendants of a node have a common prefix of the String associated \n  with that node, and the root is associated with the empty String.\n\n![Alt text](/images/trie.png?raw=true \"Trie\")\n\n### Fenwick Tree\n* A Fenwick tree, sometimes called a binary indexed tree, is a tree in concept, but in practice is implemented as an implicit data\n  structure using an array. Given an index in the array representing a vertex, the index of a vertex's parent or child is calculated\n  through bitwise operations on the binary representation of its index. Each element of the array contains the pre-calculated sum of\n  a range of values, and by combining that sum with additional ranges encountered during an upward traversal to the root, the prefix\n  sum is calculated\n* Time Complexity:\n  * Range Sum: `O(log(n))`\n  * Update: `O(log(n))`\n\n![Alt text](/images/fenwickTree.png?raw=true \"Fenwick Tree\")\n\n### Segment Tree\n* A Segment tree, is a tree data structure for storing intervals, or segments. It allows querying which of the stored segments contain\n  a given point\n* Time Complexity:\n  * Range Query: `O(log(n))`\n  * Update: `O(log(n))`\n\n![Alt text](/images/segmentTree.png?raw=true \"Segment Tree\")\n\n### Heap\n* A *Heap* is a specialized tree based structure data structure that satisfies the *heap* property: if A is a parent node of\nB, then the key (the value) of node A is ordered with respect to the key of node B with the same ordering applying across the entire heap.\nA heap can be classified further as either a \"max heap\" or a \"min heap\". In a max heap, the keys of parent nodes are always greater\nthan or equal to those of the children and the highest key is in the root node. In a min heap, the keys of parent nodes are less than\nor equal to those of the children and the lowest key is in the root node\n* Time Complexity:\n  * Access Max / Min: `O(1)`\n  * Insert: `O(log(n))`\n  * Remove Max / Min: `O(log(n))`\n\n<img src=\"/images/heap.png?raw=true\" alt=\"Max Heap\" width=\"400\" height=\"500\">\n\n\n### Hashing\n* *Hashing* is used to map data of an arbitrary size to data of a fixed size. The values returned by a hash\n  function are called hash values, hash codes, or simply hashes. If two keys map to the same value, a collision occurs\n* **Hash Map**: a *hash map* is a structure that can map keys to values. A hash map uses a hash function to compute\n  an index into an array of buckets or slots, from which the desired value can be found.\n* Collision Resolution\n * **Separate Chaining**: in *separate chaining*, each bucket is independent, and contains a list of entries for each index. The\n time for hash map operations is the time to find the bucket (constant time), plus the time to iterate through the list\n * **Open Addressing**: in *open addressing*, when a new entry is inserted, the buckets are examined, starting with the\n hashed-to-slot and proceeding in some sequence, until an unoccupied slot is found. The name open addressing refers to\n the fact that the location of an item is not always determined by its hash value\n\n\n![Alt text](/images/hash.png?raw=true \"Hashing\")\n\n### Graph\n* A *Graph* is an ordered pair of G = (V, E) comprising a set V of vertices or nodes together with a set E of edges or arcs,\n  which are 2-element subsets of V (i.e. an edge is associated with two vertices, and that association takes the form of the\n  unordered pair comprising those two vertices)\n * **Undirected Graph**: a graph in which the adjacency relation is symmetric. So if there exists an edge from node u to node\n v (u -> v), then it is also the case that there exists an edge from node v to node u (v -> u)\n * **Directed Graph**: a graph in which the adjacency relation is not symmetric. So if there exists an edge from node u to node v\n (u -> v), this does *not* imply that there exists an edge from node v to node u (v -> u)\n\n\n<img src=\"/images/graph.png?raw=true\" alt=\"Graph\" width=\"400\" height=\"500\">\n\n## Algorithms\n\n### Sorting\n\n#### Quicksort\n* Stable: `No`\n* Time Complexity:\n  * Best Case: `O(nlog(n))`\n  * Worst Case: `O(n^2)`\n  * Average Case: `O(nlog(n))`\n\n![Alt text](/images/quicksort.gif?raw=true \"Quicksort\")\n\n#### Mergesort\n* *Mergesort* is also a divide and conquer algorithm. It continuously divides an array into two halves, recurses on both the\n  left subarray and right subarray and then merges the two sorted halves\n* Stable: `Yes`\n* Time Complexity:\n  * Best Case: `O(nlog(n))`\n  * Worst Case: `O(nlog(n))`\n  * Average Case: `O(nlog(n))`\n\n![Alt text](/images/mergesort.gif?raw=true \"Mergesort\")\n\n#### Bucket Sort\n* *Bucket Sort* is a sorting algorithm that works by distributing the elements of an array into a number of buckets. Each bucket\n  is then sorted individually, either using a different sorting algorithm, or by recursively applying the bucket sorting algorithm\n* Time Complexity:\n  * Best Case: `Œ©(n + k)`\n  * Worst Case: `O(n^2)`\n  * Average Case:`Œò(n + k)`\n\n![Alt text](/images/bucketsort.png?raw=true \"Bucket Sort\")\n\n#### Radix Sort\n* *Radix Sort* is a sorting algorithm that like bucket sort, distributes elements of an array into a number of buckets. However, radix\n  sort differs from bucket sort by 're-bucketing' the array after the initial pass as opposed to sorting each bucket and merging\n* Time Complexity:\n  * Best Case: `Œ©(nk)`\n  * Worst Case: `O(nk)`\n  * Average Case: `Œò(nk)`\n\n### Graph Algorithms\n\n#### Depth First Search\n* *Depth First Search* is a graph traversal algorithm which explores as far as possible along each branch before backtracking\n* Time Complexity: `O(|V| + |E|)`\n\n![Alt text](/images/dfsbfs.gif?raw=true \"DFS / BFS Traversal\")\n\n#### Breadth First Search\n* *Breadth First Search* is a graph traversal algorithm which explores the neighbor nodes first, before moving to the next\n  level neighbors\n* Time Complexity: `O(|V| + |E|)`\n\n![Alt text](/images/dfsbfs.gif?raw=true \"DFS / BFS Traversal\")\n\n#### Topological Sort\n* *Topological Sort* is the linear ordering of a directed graph's nodes such that for every edge from node u to node v, u\n  comes before v in the ordering\n* Time Complexity: `O(|V| + |E|)`\n\n#### Dijkstra's Algorithm\n* *Dijkstra's Algorithm* is an algorithm for finding the shortest path between nodes in a graph\n* Time Complexity: `O(|V|^2)`\n\n![Alt text](/images/dijkstra.gif?raw=true \"Dijkstra's\")\n\n#### Bellman-Ford Algorithm\n* *Bellman-Ford Algorithm* is an algorithm that computes the shortest paths from a single source node to all other nodes in a weighted graph\n* Although it is slower than Dijkstra's, it is more versatile, as it is capable of handling graphs in which some of the edge weights are\n  negative numbers\n* Time Complexity:\n  * Best Case: `O(|E|)`\n  * Worst Case: `O(|V||E|)`\n\n![Alt text](/images/bellman-ford.gif?raw=true \"Bellman-Ford\")\n\n#### Floyd-Warshall Algorithm\n* *Floyd-Warshall Algorithm* is an algorithm for finding the shortest paths in a weighted graph with positive or negative edge weights, but\n  no negative cycles\n* A single execution of the algorithm will find the lengths (summed weights) of the shortest paths between *all* pairs of nodes\n* Time Complexity:\n  * Best Case: `O(|V|^3)`\n  * Worst Case: `O(|V|^3)`\n  * Average Case: `O(|V|^3)`\n\n#### Prim's Algorithm\n* *Prim's Algorithm* is a greedy algorithm that finds a minimum spanning tree for a weighted undirected graph. In other words, Prim's find a\n  subset of edges that forms a tree that includes every node in the graph\n* Time Complexity: `O(|V|^2)`\n\n![Alt text](/images/prim.gif?raw=true \"Prim's Algorithm\")\n\n#### Kruskal's Algorithm\n* *Kruskal's Algorithm* is also a greedy algorithm that finds a minimum spanning tree in a graph. However, in Kruskal's, the graph does not\n  have to be connected\n* Time Complexity: `O(|E|log|V|)`\n\n![Alt text](/images/kruskal.gif?raw=true \"Kruskal's Algorithm\")\n\n## Greedy Algorithms\n* *Greedy Algorithms* are algorithms that make locally optimal choices at each step in the hope of eventually reaching the globally optimal solution\n* Problems must exhibit two properties in order to implement a Greedy solution:\n * Optimal Substructure\n    * An optimal solution to the problem contains optimal solutions to the given problem's subproblems\n * The Greedy Property\n    * An optimal solution is reached by \"greedily\" choosing the locally optimal choice without ever reconsidering previous choices\n* Example - Coin Change\n    * Given a target amount V cents and a list of denominations of n coins, i.e. we have coinValue[i] (in cents) for coin types i from [0...n - 1],\n      what is the minimum number of coins that we must use to represent amount V? Assume that we have an unlimited supply of coins of any type\n    * Coins - Penny (1 cent), Nickel (5 cents), Dime (10 cents), Quarter (25 cents)\n    * Assume V = 41. We can use the Greedy algorithm of continuously selecting the largest coin denomination less than or equal to V, subtract that\n      coin's value from V, and repeat.\n    * V = 41 | 0 coins used\n    * V = 16 | 1 coin used (41 - 25 = 16)\n    * V = 6  | 2 coins used (16 - 10 = 6)\n    * V = 1  | 3 coins used (6 - 5 = 1)\n    * V = 0  | 4 coins used (1 - 1 = 0)\n    * Using this algorithm, we arrive at a total of 4 coins which is optimal\n\n## Bitmasks\n* Bitmasking is a technique used to perform operations at the bit level. Leveraging bitmasks often leads to faster runtime complexity and\n  helps limit memory usage\n* Test kth bit: `s & (1 << k);`\n* Set kth bit: `s |= (1 << k);`\n* Turn off kth bit: `s &= ~(1 << k);`\n* Toggle kth bit: `s ^= (1 << k);`\n* Multiple by 2<sup>n</sup>: `s << n;`\n* Divide by 2<sup>n</sup>: `s >> n;`\n* Intersection: `s & t;`\n* Union: `s | t;`\n* Set Subtraction: `s & ~t;`\n* Extract lowest set bit: `s & (-s);`\n* Extract lowest unset bit: `~s & (s + 1);`\n* Swap Values:\n             ```\n                x ^= y;\n                y ^= x;\n                x ^= y;\n             ```\n\n## Runtime Analysis\n\n#### Big O Notation\n* *Big O Notation* is used to describe the upper bound of a particular algorithm. Big O is used to describe worst case scenarios\n\n![Alt text](/images/bigO.png?raw=true \"Theta Notation\")\n\n#### Little O Notation\n* *Little O Notation* is also used to describe an upper bound of a particular algorithm; however, Little O provides a bound\n  that is not asymptotically tight\n\n#### Big Œ© Omega Notation\n* *Big Omega Notation* is used to provide an asymptotic lower bound on a particular algorithm\n\n![Alt text](/images/bigOmega.png?raw=true \"Theta Notation\")\n\n#### Little œâ Omega Notation\n* *Little Omega Notation* is used to provide a lower bound on a particular algorithm that is not asymptotically tight\n\n#### Theta Œò Notation\n* *Theta Notation* is used to provide a bound on a particular algorithm such that it can be \"sandwiched\" between\n  two constants (one for an upper limit and one for a lower limit) for sufficiently large values\n\n![Alt text](/images/theta.png?raw=true \"Theta Notation\")\n\n## Video Lectures\n* Data Structures\n    * [UC Berkeley Data Structures](https://archive.org/details/ucberkeley-webcast?&and[]=subject%3A%22Computer%20Science%22&and[]=subject%3A%22CS%22)\n    * [MIT Advanced Data Structures](https://www.youtube.com/watch?v=T0yzrZL1py0&list=PLUl4u3cNGP61hsJNdULdudlRL493b-XZf&index=1)\n* Algorithms\n    * [MIT Introduction to Algorithms](https://www.youtube.com/watch?v=HtSuA80QTyo&list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb&index=1)\n    * [MIT Advanced Algorithms](https://www.youtube.com/playlist?list=PL6ogFv-ieghdoGKGg2Bik3Gl1glBTEu8c)\n    * [UC Berkeley Algorithms](https://archive.org/details/ucberkeley-webcast?&and[]=subject%3A%22Computer%20Science%22&and[]=subject%3A%22CS%22)\n\n## Interview Books\n* [Competitive Programming 3 - Steven Halim & Felix Halim](https://www.amazon.com/Competitive-Programming-3rd-Steven-Halim/dp/B00FG8MNN8) \n* [Cracking The Coding Interview - Gayle Laakmann McDowell](https://www.amazon.com/Cracking-Coding-Interview-Programming-Questions/dp/0984782850/ref=sr_1_1?s=books&ie=UTF8)\n* [Cracking The PM Interview - Gayle Laakmann McDowell & Jackie Bavaro](https://www.amazon.com/Cracking-PM-Interview-Product-Technology-ebook/dp/B00ISYMUR6/ref=sr_1_1?s=books&ie=UTF8)\n* [Introduction to Algorithms -  Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest & Clifford Stein](https://www.amazon.com/Introduction-Algorithms-3rd-MIT-Press/dp/0262033844/ref=sr_1_1?ie=UTF8&qid=1490295989&sr=8-1&keywords=Introduction+to+Algorithms)\n\n## Computer Science News\n* [Hacker News](https://news.ycombinator.com/)\n* [Lobsters](https://lobste.rs/)\n\n## Directory Tree\n\n```\n.\n‚îú‚îÄ‚îÄ Array\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ bestTimeToBuyAndSellStock.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ findTheCelebrity.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ gameOfLife.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ increasingTripletSubsequence.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ insertInterval.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ longestConsecutiveSequence.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ maximumProductSubarray.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ maximumSubarray.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ mergeIntervals.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ missingRanges.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ productOfArrayExceptSelf.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ rotateImage.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ searchInRotatedSortedArray.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ spiralMatrixII.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ subsetsII.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ subsets.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ summaryRanges.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ wiggleSort.java\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ wordSearch.java\n‚îú‚îÄ‚îÄ Backtracking\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ androidUnlockPatterns.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ generalizedAbbreviation.java\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ letterCombinationsOfAPhoneNumber.java\n‚îú‚îÄ‚îÄ BinarySearch\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ closestBinarySearchTreeValue.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ firstBadVersion.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ guessNumberHigherOrLower.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ pow(x,n).java\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ sqrt(x).java\n‚îú‚îÄ‚îÄ BitManipulation\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ binaryWatch.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ countingBits.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hammingDistance.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ maximumProductOfWordLengths.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ numberOf1Bits.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sumOfTwoIntegers.java\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ utf-8Validation.java\n‚îú‚îÄ‚îÄ BreadthFirstSearch\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ binaryTreeLevelOrderTraversal.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ cloneGraph.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ pacificAtlanticWaterFlow.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ removeInvalidParentheses.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ shortestDistanceFromAllBuildings.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ symmetricTree.java\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ wallsAndGates.java\n‚îú‚îÄ‚îÄ DepthFirstSearch\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ balancedBinaryTree.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ battleshipsInABoard.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ convertSortedArrayToBinarySearchTree.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ maximumDepthOfABinaryTree.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ numberOfIslands.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ populatingNextRightPointersInEachNode.java\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ sameTree.java\n‚îú‚îÄ‚îÄ Design\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ zigzagIterator.java\n‚îú‚îÄ‚îÄ DivideAndConquer\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ expressionAddOperators.java\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ kthLargestElementInAnArray.java\n‚îú‚îÄ‚îÄ DynamicProgramming\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ bombEnemy.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ climbingStairs.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ combinationSumIV.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ countingBits.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ editDistance.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ houseRobber.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ paintFence.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ paintHouseII.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ regularExpressionMatching.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sentenceScreenFitting.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ uniqueBinarySearchTrees.java\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ wordBreak.java\n‚îú‚îÄ‚îÄ HashTable\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ binaryTreeVerticalOrderTraversal.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ findTheDifference.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ groupAnagrams.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ groupShiftedStrings.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ islandPerimeter.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ loggerRateLimiter.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ maximumSizeSubarraySumEqualsK.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ minimumWindowSubstring.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sparseMatrixMultiplication.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ strobogrammaticNumber.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ twoSum.java\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ uniqueWordAbbreviation.java\n‚îú‚îÄ‚îÄ LinkedList\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ addTwoNumbers.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ deleteNodeInALinkedList.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ mergeKSortedLists.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ palindromeLinkedList.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ plusOneLinkedList.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ README.md\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ reverseLinkedList.java\n‚îú‚îÄ‚îÄ Queue\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ movingAverageFromDataStream.java\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ Sort\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ meetingRoomsII.java\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ meetingRooms.java\n‚îú‚îÄ‚îÄ Stack\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ binarySearchTreeIterator.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ decodeString.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ flattenNestedListIterator.java\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ trappingRainWater.java\n‚îú‚îÄ‚îÄ String\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ addBinary.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ countAndSay.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ decodeWays.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ editDistance.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ integerToEnglishWords.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ longestPalindrome.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ longestSubstringWithAtMostKDistinctCharacters.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ minimumWindowSubstring.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ multiplyString.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ oneEditDistance.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ palindromePermutation.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ README.md\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ reverseVowelsOfAString.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ romanToInteger.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ validPalindrome.java\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ validParentheses.java\n‚îú‚îÄ‚îÄ Tree\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ binaryTreeMaximumPathSum.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ binaryTreePaths.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ inorderSuccessorInBST.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ invertBinaryTree.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ lowestCommonAncestorOfABinaryTree.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sumOfLeftLeaves.java\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ validateBinarySearchTree.java\n‚îú‚îÄ‚îÄ Trie\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ addAndSearchWordDataStructureDesign.java\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ implementTrie.java\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ wordSquares.java\n‚îî‚îÄ‚îÄ TwoPointers\n    ‚îú‚îÄ‚îÄ 3Sum.java\n    ‚îú‚îÄ‚îÄ 3SumSmaller.java\n    ‚îú‚îÄ‚îÄ mergeSortedArray.java\n    ‚îú‚îÄ‚îÄ minimumSizeSubarraySum.java\n    ‚îú‚îÄ‚îÄ moveZeros.java\n    ‚îú‚îÄ‚îÄ removeDuplicatesFromSortedArray.java\n    ‚îú‚îÄ‚îÄ reverseString.java\n    ‚îî‚îÄ‚îÄ sortColors.java\n\n18 directories, 124 files\n```\n",
      "stars_today": 14
    },
    {
      "id": 133134007,
      "name": "openapi-generator",
      "full_name": "OpenAPITools/openapi-generator",
      "description": "OpenAPI Generator allows generation of API client libraries (SDK generation), server stubs, documentation and configuration automatically given an OpenAPI Spec (v2, v3)",
      "html_url": "https://github.com/OpenAPITools/openapi-generator",
      "stars": 25667,
      "forks": 7364,
      "language": "Java",
      "topics": [
        "api",
        "api-client",
        "api-server",
        "generator",
        "hacktoberfest",
        "openapi",
        "openapi-generator",
        "openapi3",
        "rest",
        "rest-api",
        "rest-client",
        "restful-api",
        "sdk"
      ],
      "created_at": "2018-05-12T09:57:56Z",
      "updated_at": "2026-01-24T00:05:47Z",
      "pushed_at": "2026-01-23T17:02:26Z",
      "open_issues": 5577,
      "owner": {
        "login": "OpenAPITools",
        "avatar_url": "https://avatars.githubusercontent.com/u/37325267?v=4"
      },
      "readme": "<h1 align=\"center\">OpenAPI Generator</h1>\n\n\n<div align=\"center\">\n\n[![Stable releases in Maven Central](https://img.shields.io/maven-metadata/v/https/repo1.maven.org/maven2/org/openapitools/openapi-generator/maven-metadata.xml.svg)](http://search.maven.org/#search%7Cgav%7C1%7Cg%3A%22org.openapitools%22%20AND%20a%3A%22openapi-generator%22)\n[![Apache 2.0 License](https://img.shields.io/badge/License-Apache%202.0-orange)](./LICENSE)\n[![Open Collective backers](https://img.shields.io/opencollective/backers/openapi_generator?color=orange&label=OpenCollective%20Backers)](https://opencollective.com/openapi_generator)\n[![Join the Slack chat room](https://img.shields.io/badge/Slack-Join%20the%20chat%20room-orange)](https://join.slack.com/t/openapi-generator/shared_invite/zt-36ucx4ybl-jYrN6euoYn6zxXNZdldoZA)\n[![Follow OpenAPI Generator Twitter account to get the latest update](https://img.shields.io/twitter/follow/oas_generator.svg?style=social&label=Follow)](https://twitter.com/oas_generator)\n[![Contribute with Gitpod](https://img.shields.io/badge/Contribute%20with-Gitpod-908a85?logo=gitpod)](https://gitpod.io/#https://github.com/OpenAPITools/openapi-generator)\n[![Conan Center](https://shields.io/conan/v/openapi-generator)](https://conan.io/center/recipes/openapi-generator)\n[![Revved up by Develocity](https://img.shields.io/badge/Revved%20up%20by-Develocity-06A0CE?logo=Gradle&labelColor=02303A)](https://ge.openapi-generator.tech/scans)\n</div>\n\n<div align=\"center\">\n\n[Master](https://github.com/OpenAPITools/openapi-generator/tree/master) (`7.20.0`):\n[![Integration Test2](https://circleci.com/gh/OpenAPITools/openapi-generator.svg?style=shield)](https://circleci.com/gh/OpenAPITools/openapi-generator)\n[![Bitrise](https://img.shields.io/bitrise/4a2b10a819d12b67/master?label=bitrise%3A%20Swift+4,5&token=859FMDR8QHwabCzwvZK6vQ)](https://app.bitrise.io/app/4a2b10a819d12b67)\n\n</div>\n\n<div align=\"center\">\n\n:star::star::star: If you would like to contribute, please refer to [guidelines](CONTRIBUTING.md) and a list of [open tasks](https://github.com/openapitools/openapi-generator/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22). :star::star::star:\n\n:bangbang: To migrate from Swagger Codegen to OpenAPI Generator, please refer to the [migration guide](docs/migration-from-swagger-codegen.md) :bangbang:\n\n:notebook_with_decorative_cover: For more information, please refer to the [Wiki page](https://github.com/openapitools/openapi-generator/wiki) and [FAQ](https://github.com/openapitools/openapi-generator/wiki/FAQ) :notebook_with_decorative_cover:\n\n:notebook_with_decorative_cover: The eBook [A Beginner's Guide to Code Generation for REST APIs](https://gum.co/openapi_generator_ebook) is a good starting point for beginners :notebook_with_decorative_cover:\n\n:warning: If the OpenAPI spec, templates or any input (e.g. options, environment variables) is obtained from an untrusted source or environment, please make sure you've reviewed these inputs before using OpenAPI Generator to generate the API client, server stub or documentation to avoid potential security issues (e.g. [code injection](https://en.wikipedia.org/wiki/Code_injection)). For security vulnerabilities, please contact [team@openapitools.org](mailto:team@openapitools.org). :warning:\n\n:bangbang: Both \"OpenAPI Tools\" (https://OpenAPITools.org - the parent organization of OpenAPI Generator) and \"OpenAPI Generator\" are not affiliated with OpenAPI Initiative (OAI) :bangbang:\n\n</div>\n\n## Sponsors\n\nIf you find OpenAPI Generator useful for work, please consider asking your company to support this Open Source project by [becoming a sponsor](https://opencollective.com/openapi_generator). You can also individually sponsor the project by [becoming a backer](https://opencollective.com/openapi_generator).\n\n#### Thank you to our bronze sponsors!\n\n[![NamSor](https://openapi-generator.tech/img/companies/namsor.png)](https://www.namsor.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[![LightBow](https://openapi-generator.tech/img/companies/lightbow.png)](https://www.lightbow.net/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/docspring.png\" width=\"128\" height=\"128\">](https://docspring.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/datadog.png\" width=\"128\" height=\"128\">](https://datadoghq.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/thales.jpg\" width=\"128\" height=\"128\">](https://cpl.thalesgroup.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/apideck.jpg\" width=\"128\" height=\"128\">](https://www.apideck.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/pexa.png\" width=\"128\" height=\"128\">](https://www.pexa.com.au/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/numary.png\" width=\"128\" height=\"128\">](https://www.numary.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/onesignal.png\" width=\"128\" height=\"128\">](https://www.onesignal.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/virtualansoftware.png\" width=\"128\" height=\"128\">](https://www.virtualansoftware.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/mergedev.jpeg\" width=\"128\" height=\"128\">](https://www.merge.dev/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/burkert.jpg\" width=\"128\" height=\"128\">](https://www.burkert.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/finbourne.png\" width=\"128\" height=\"128\">](https://www.finbourne.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/bumpsh.png\" width=\"128\" height=\"128\">](https://bump.sh/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/bileto.png\" width=\"128\" height=\"128\">](https://www.bileto.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/bairesdev.png\" width=\"128\" height=\"128\">](https://www.bairesdev.com/sponsoring-open-source-projects/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/dmtech.jpeg\" width=\"128\" height=\"128\">](https://www.dmtech.de/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/adyen.png\" width=\"128\" height=\"128\">](https://adyen.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/fornex.png\" width=\"128\" height=\"128\">](https://fornex.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/alloyautomation.png\" width=\"128\" height=\"128\">](https://runalloy.com/signup?utm_source=github&utm_medium=referral&utm_campaign=1524_openapigenerator)\n[<img src=\"https://openapi-generator.tech/img/companies/ssstwitter.png\" width=\"128\" height=\"128\">](https://ssstwitter.com/?utm_source=github&utm_medium=referral&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/svix.png\" width=\"128\" height=\"128\">](https://www.svix.com/?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/litslink.png\" width=\"128\" height=\"128\">](https://litslink.com/services/artificial-intelligence?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/designli.jpg\" width=\"128\" height=\"128\">](https://designli.co?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/itm.png\" width=\"128\" height=\"128\">](https://opensource.muenchen.de?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/kong.png\" width=\"128\" height=\"128\">](https://konghq.com/products/kong-konnect?utm_medium=referral&utm_source=github&utm_campaign=platform&utm_content=openapi-generator)\n[<img src=\"https://openapi-generator.tech/img/companies/route4me.png\" width=\"128\" height=\"128\">](https://route4me.com/?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/dm.png\" width=\"128\" height=\"128\">](https://www.dotcom-monitor.com/sponsoring-open-source-projects/?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/clickit.jpg\" width=\"128\" height=\"128\">](https://www.clickittech.com/?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/unified_to.jpg\" width=\"128\" height=\"128\">](https://unified.to/?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/savetwt.jpg\" width=\"128\" height=\"128\">](https://savetwt.com/?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/serpapi.png\" width=\"128\" height=\"128\">](https://serpapi.com/?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n\n#### Thank you GoDaddy for sponsoring the domain names, Linode for sponsoring the VPS, Checkly for sponsoring the API monitoring and Gradle for sponsoring Develocity\n\n[<img src=\"https://openapi-generator.tech/img/companies/godaddy.png\" width=\"150\">](https://www.godaddy.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[![Linode](https://www.linode.com/media/images/logos/standard/light/linode-logo_standard_light_small.png)](https://www.linode.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRAhEYadUyZYzGUotZiSdXkVMqqLGuohyixLl4eUpUV6pAbUULL\" width=\"150\">](https://checklyhq.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/cb/Gradle_logo.png/320px-Gradle_logo.png\" width=\"150\">](https://gradle.org?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n\n## Overview\n\nOpenAPI Generator allows generation of API client libraries (SDK generation), server stubs,  documentation and configuration automatically given an [OpenAPI Spec](https://github.com/OAI/OpenAPI-Specification) (both 2.0 and 3.0 are supported). Currently, the following languages/frameworks are supported:\n\n|                                  | Languages/Frameworks                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n| -------------------------------- |--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| **API clients**                  | **ActionScript**, **Ada**, **Apex**, **Bash**, **C**, **C#** (.net 2.0, 3.5 or later, .NET Standard 1.3 - 2.1, .NET Core 3.1, .NET 5.0. Libraries: RestSharp, GenericHost, HttpClient), **C++** (Arduino, cpp-restsdk, Qt5, Tizen, Unreal Engine 4), **Clojure**, **Crystal**, **Dart**, **Elixir**, **Elm**, **Eiffel**, **Erlang**, **Go**, **Groovy**, **Haskell** (http-client, Servant), **Java** (Apache HttpClient 4.x, Apache HttpClient 5.x, Jersey2.x, OkHttp, Retrofit1.x, Retrofit2.x, Feign, RestTemplate, RESTEasy, Vertx, Google API Client Library for Java, Rest-assured, Spring 5 Web Client, Spring 6 RestClient, MicroProfile Rest Client, Helidon), **Jetbrains HTTP Client**, **Julia**, **k6**, **Kotlin**, **Lua**, **N4JS**, **Nim**, **Node.js/JavaScript** (ES5, ES6, AngularJS with Google Closure Compiler annotations, Flow types, Apollo GraphQL DataStore), **Objective-C**, **OCaml**, **Perl**, **PHP**, **PowerShell**, **Python**, **R**, **Ruby**, **Rust** (hyper, reqwest, rust-server), **Scala** (akka, http4s, scalaz, sttp, swagger-async-httpclient, pekko), **Swift** (2.x, 3.x, 4.x, 5.x, 6.x), **Typescript** (AngularJS, Angular (9.x - 19.x), Aurelia, Axios, Fetch, Inversify, jQuery, Nestjs, Node, redux-query, Rxjs), **XoJo**, **Zapier** |\n| **Server stubs**                 | **Ada**, **C#** (ASP.NET Core, Azure Functions), **C++** (Oat++, Pistache, Restbed, Qt5 QHTTPEngine), **Erlang**, **F#** (Giraffe), **Go** (net/http, Gin, Echo), **Haskell** (Servant, Yesod), **Java** (MSF4J, Spring, Undertow, JAX-RS: CDI, CXF, Inflector, Jersey, RestEasy, Play Framework, [PKMST](https://github.com/ProKarma-Inc/pkmst-getting-started-examples), [Vert.x](https://vertx.io/), [Apache Camel](https://camel.apache.org/), [Helidon](https://helidon.io/)), **Julia**, **Kotlin** (Spring Boot, [Ktor](https://github.com/ktorio/ktor), [Vert.x](https://vertx.io/)), **PHP** ([Flight](https://docs.flightphp.com/), Laravel, Lumen, [Mezzio (fka Zend Expressive)](https://github.com/mezzio/mezzio), Slim, Silex, [Symfony](https://symfony.com/)), **Python** (FastAPI, Flask), **NodeJS**, **Ruby** (Sinatra, Rails5), **Rust** ([rust-server](https://openapi-generator.tech/docs/generators/rust-server/)), **Scala** (Akka, [Finch](https://github.com/finagle/finch), [Lagom](https://github.com/lagom/lagom), [Play](https://www.playframework.com/), [Cask](https://github.com/com-lihaoyi/cask), Scalatra)                                                                                                                                                    |\n| **API documentation generators** | **HTML**, **Confluence Wiki**, **Asciidoc**, **Markdown**, **PlantUML**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n| **Configuration files**          | [**Apache2**](https://httpd.apache.org/)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n| **Others**                       | **GraphQL**, **JMeter**, **Ktorm**, **MySQL Schema**, **Postman Collection**, **Protocol Buffer**, **WSDL**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n\n## Table of contents\n\n- [Sponsors](#sponsors)\n    - [Thank you to our bronze sponsors!](#thank-you-to-our-bronze-sponsors)\n    - [Thank you GoDaddy for sponsoring the domain names, Linode for sponsoring the VPS, Checkly for sponsoring the API monitoring and Gradle for sponsoring Develocity](#thank-you-godaddy-for-sponsoring-the-domain-names-linode-for-sponsoring-the-vps-checkly-for-sponsoring-the-api-monitoring-and-gradle-for-sponsoring-develocity)\n- [Overview](#overview)\n- [Table of contents](#table-of-contents)\n- [1 - Installation](#1---installation)\n  - [1.1 - Compatibility](#11---compatibility)\n- [1.2 - Artifacts on Maven Central](#12---artifacts-on-maven-central)\n  - [1.3 - Download JAR](#13---download-jar)\n  - [Launcher Script](#launcher-script)\n  - [1.4 - Build Projects](#14---build-projects)\n    - [Nix users](#nix-users)\n  - [1.5 - Homebrew](#15---homebrew)\n  - [1.6 - Docker](#16---docker)\n    - [Public Pre-built Docker images](#public-pre-built-docker-images)\n    - [OpenAPI Generator CLI Docker Image](#openapi-generator-cli-docker-image)\n    - [OpenAPI Generator Online Docker Image](#openapi-generator-online-docker-image)\n    - [Development in docker](#development-in-docker)\n      - [Troubleshooting](#troubleshooting)\n    - [Run Docker in Vagrant](#run-docker-in-vagrant)\n  - [1.7 - NPM](#17---npm)\n  - [1.8 - pip](#18---pip)\n- [2 - Getting Started](#2---getting-started)\n- [3 - Usage](#3---usage)\n  - [To generate a sample client library](#to-generate-a-sample-client-library)\n  - [3.1 - Customization](#31---customization)\n  - [3.2 - Workflow Integration (Maven, Gradle, Github, CI/CD)](#32---workflow-integration-maven-gradle-github-cicd)\n  - [3.3 - Online OpenAPI generator](#33---online-openapi-generator)\n  - [3.4 - License information on Generated Code](#34---license-information-on-generated-code)\n  - [3.5 - IDE Integration](#35---ide-integration)\n- [4 - Companies/Projects using OpenAPI Generator](#4---companiesprojects-using-openapi-generator)\n- [5 - Presentations/Videos/Tutorials/Books](#5---presentationsvideostutorialsbooks)\n- [6 - About Us](#6---about-us)\n  - [6.1 - OpenAPI Generator Core Team](#61---openapi-generator-core-team)\n    - [Core Team Members](#core-team-members)\n    - [Template Creator](#template-creator)\n    - [How to join the core team](#how-to-join-the-core-team)\n  - [6.2 - OpenAPI Generator Technical Committee](#62---openapi-generator-technical-committee)\n    - [Members of Technical Committee](#members-of-technical-committee)\n  - [6.3 - History of OpenAPI Generator](#63---history-of-openapi-generator)\n    - [Founding Members (alphabetical order):](#founding-members-alphabetical-order)\n- [7 - License](#7---license)\n\n## [1 - Installation](#table-of-contents)\n\n### [1.1 - Compatibility](#table-of-contents)\n\nThe OpenAPI Specification has undergone 3 revisions since initial creation in 2010.  The openapi-generator project has the following compatibilities with the OpenAPI Specification:\n\n| OpenAPI Generator Version                                                                                                                                 | Release Date | Notes                                             |\n| --------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------ | ------------------------------------------------- |\n| 7.20.0 (upcoming minor release) [SNAPSHOT](https://github.com/OpenAPITools/openapi-generator/wiki/FAQ#how-to-test-with-the-latest-master-of-openapi-generator) | 20.02.2026   | Minor release with breaking changes (with fallback) |\n| [7.19.0](https://github.com/OpenAPITools/openapi-generator/releases/tag/v7.19.0) (latest stable release)                                                    | 20.01.2026   | Minor release with breaking changes (with fallback) |\n| [6.6.0](https://github.com/OpenAPITools/openapi-generator/releases/tag/v6.6.0)                                                    | 11.05.2023   | Minor release with breaking changes (with fallback) |\n| [5.4.0](https://github.com/OpenAPITools/openapi-generator/releases/tag/v5.4.0)                                                    | 31.01.2022   | Minor release with breaking changes (with fallback) |\n| [4.3.1](https://github.com/OpenAPITools/openapi-generator/releases/tag/v4.3.1)                                                    | 06.05.2020   | Patch release (enhancements, bug fixes, etc)                       |\n\nOpenAPI Spec compatibility: 1.0, 1.1, 1.2, 2.0, 3.0, 3.1 (beta support)\n\n(We do not publish daily/nightly build. Please use SNAPSHOT instead)\n\nFor old releases, please refer to the [**Release**](https://github.com/OpenAPITools/openapi-generator/releases) page.\n\nFor decommissioned generators/libraries/frameworks, please refer to [the \"Decommission\" label](https://github.com/OpenAPITools/openapi-generator/issues?q=label%3ADecommission+is%3Amerged+) in the pull request page.\n\n## [1.2 - Artifacts on Maven Central](#table-of-contents)\n\nYou can find our released artifacts on maven central:\n\n**Core:**\n```xml\n<dependency>\n    <groupId>org.openapitools</groupId>\n    <artifactId>openapi-generator</artifactId>\n    <version>${openapi-generator-version}</version>\n</dependency>\n```\nSee the different versions of the [openapi-generator](https://search.maven.org/artifact/org.openapitools/openapi-generator) artifact available on maven central.\n\n**Cli:**\n```xml\n<dependency>\n    <groupId>org.openapitools</groupId>\n    <artifactId>openapi-generator-cli</artifactId>\n    <version>${openapi-generator-version}</version>\n</dependency>\n```\nSee the different versions of the [openapi-generator-cli](https://search.maven.org/artifact/org.openapitools/openapi-generator-cli) artifact available on maven central.\n\n**Maven plugin:**\n```xml\n<dependency>\n    <groupId>org.openapitools</groupId>\n    <artifactId>openapi-generator-maven-plugin</artifactId>\n    <version>${openapi-generator-version}</version>\n</dependency>\n```\n* See the different versions of the [openapi-generator-maven-plugin](https://search.maven.org/artifact/org.openapitools/openapi-generator-maven-plugin) artifact available on maven central.\n* [Readme](https://github.com/OpenAPITools/openapi-generator/blob/master/modules/openapi-generator-maven-plugin/README.md)\n\n**Gradle plugin:**\n```xml\n<dependency>\n    <groupId>org.openapitools</groupId>\n    <artifactId>openapi-generator-gradle-plugin</artifactId>\n    <version>${openapi-generator-version}</version>\n</dependency>\n```\n* See the different versions of the [openapi-generator-gradle-plugin](https://search.maven.org/artifact/org.openapitools/openapi-generator-gradle-plugin) artifact available on maven central.\n* [Readme](https://github.com/OpenAPITools/openapi-generator/blob/master/modules/openapi-generator-gradle-plugin/README.adoc)\n\n### [1.3 - Download JAR](#table-of-contents)\n<!-- RELEASE_VERSION -->\nIf you're looking for the latest stable version, you can grab it directly from Maven.org (Java 11 runtime at a minimum):\n\nJAR location: `https://repo1.maven.org/maven2/org/openapitools/openapi-generator-cli/7.19.0/openapi-generator-cli-7.19.0.jar`\n\nFor **Mac/Linux** users:\n```sh\nwget https://repo1.maven.org/maven2/org/openapitools/openapi-generator-cli/7.19.0/openapi-generator-cli-7.19.0.jar -O openapi-generator-cli.jar\n```\n\nFor **Windows** users, you will need to install [wget](http://gnuwin32.sourceforge.net/packages/wget.htm) or you can use Invoke-WebRequest in PowerShell (3.0+), e.g.\n```\nInvoke-WebRequest -OutFile openapi-generator-cli.jar https://repo1.maven.org/maven2/org/openapitools/openapi-generator-cli/7.19.0/openapi-generator-cli-7.19.0.jar\n```\n\nAfter downloading the JAR, run `java -jar openapi-generator-cli.jar help` to show the usage.\n\nFor Mac users, please make sure Java 11 is installed (Tips: run `java -version` to check the version), and export `JAVA_HOME` in order to use the supported Java version:\n```sh\nexport JAVA_HOME=`/usr/libexec/java_home -v 1.11`\nexport PATH=${JAVA_HOME}/bin:$PATH\n```\n\n<!-- /RELEASE_VERSION -->\n### Launcher Script\n\nOne downside to manual jar downloads is that you don't keep up-to-date with the latest released version. We have a Bash launcher script at [bin/utils/openapi-generator.cli.sh](./bin/utils/openapi-generator-cli.sh) which resolves this issue.\n\nTo install the launcher script, copy the contents of the script to a location on your path and make the script executable.\n\nAn example of setting this up (NOTE: Always evaluate scripts curled from external systems before executing them).\n\n```\nmkdir -p ~/bin/openapitools\ncurl https://raw.githubusercontent.com/OpenAPITools/openapi-generator/master/bin/utils/openapi-generator-cli.sh > ~/bin/openapitools/openapi-generator-cli\nchmod u+x ~/bin/openapitools/openapi-generator-cli\nexport PATH=$PATH:~/bin/openapitools/\n```\n\nNow, `openapi-generator-cli` is \"installed\". On invocation, it will query the GitHub repository for the most recently released version. If this matches the last downloaded jar,\nit will execute as normal. If a newer version is found, the script will download the latest release and execute it.\n\nIf you need to invoke an older version of the generator, you can define the variable `OPENAPI_GENERATOR_VERSION` either ad hoc or globally. You can export this variable if you'd like to persist a specific release version.\n\nExamples:\n\n```\n# Execute latest released openapi-generator-cli\nopenapi-generator-cli version\n\n# Execute version 4.1.0 for the current invocation, regardless of the latest released version\nOPENAPI_GENERATOR_VERSION=4.1.0 openapi-generator-cli version\n\n# Execute version 4.1.0-SNAPSHOT for the current invocation\nOPENAPI_GENERATOR_VERSION=4.1.0-SNAPSHOT openapi-generator-cli version\n\n# Execute version 4.0.2 for every invocation in the current shell session\nexport OPENAPI_GENERATOR_VERSION=4.0.2\nopenapi-generator-cli version # is 4.0.2\nopenapi-generator-cli version # is also 4.0.2\n\n# To \"install\" a specific version, set the variable in .bashrc/.bash_profile\necho \"export OPENAPI_GENERATOR_VERSION=4.0.2\" >> ~/.bashrc\nsource ~/.bashrc\nopenapi-generator-cli version # is always 4.0.2, unless any of the above overrides are done ad hoc\n```\n\n### [1.4 - Build Projects](#table-of-contents)\n\nTo build from source, you need the following installed and available in your `$PATH:`\n\n* [Java 11](https://adoptium.net/)\n\n* [Apache Maven 3.8.8 or greater](https://maven.apache.org/) (optional)\n\nAfter cloning the project, you can build it from source using [maven wrapper](https://maven.apache.org/wrapper/):\n\n- Linux: `./mvnw clean install`\n- Windows: `mvnw.cmd clean install`\n\n#### Nix users\n\nIf you're a nix user, you can enter OpenAPI Generator shell, by typing:\n```sh\nnix develop\n```\nIt will enter a shell with Java 11 installed.\n\nDirenv supports automatically loading of the nix developer shell, so if you're using direnv too, type:\n```sh\ndirenv allow\n```\nand have `java` and `mvn` set up with correct versions each time you enter project directory.\n\nThe default build contains minimal static analysis (via CheckStyle). To run your build with PMD and Spotbugs, use the `static-analysis` profile:\n\n- Linux: `./mvnw -Pstatic-analysis clean install`\n- Windows: `mvnw.cmd -Pstatic-analysis clean install`\n\n### [1.5 - Homebrew](#table-of-contents)\n\nTo install, run `brew install openapi-generator`\n\nHere is an example usage to generate a Ruby client:\n```sh\nopenapi-generator generate -i https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml -g ruby -o /tmp/test/\n```\n\nTo reinstall with the latest master, run `brew uninstall openapi-generator && brew install --HEAD openapi-generator`\n\nTo install OpenJDK (pre-requisites), please run\n```sh\nbrew tap AdoptOpenJDK/openjdk\nbrew install --cask adoptopenjdk11\nexport JAVA_HOME=`/usr/libexec/java_home -v 1.11`\n```\n\nor download installer via https://adoptium.net/\n\nTo install Maven (optional), please run\n```sh\nbrew install maven\n```\n\n### [1.6 - Docker](#table-of-contents)\n\n#### Public Pre-built Docker images\n\n - [https://hub.docker.com/r/openapitools/openapi-generator-cli/](https://hub.docker.com/r/openapitools/openapi-generator-cli/) (official CLI)\n - [https://hub.docker.com/r/openapitools/openapi-generator-online/](https://hub.docker.com/r/openapitools/openapi-generator-online/) (official web service)\n\n\n#### OpenAPI Generator CLI Docker Image\n\nThe OpenAPI Generator image acts as a standalone executable. It can be used as an alternative to installing via homebrew, or for developers who are unable to install Java or upgrade the installed version.\n\nTo generate code with this image, you'll need to mount a local location as a volume.\n\nExample:\n\n```sh\ndocker run --rm -v \"${PWD}:/local\" openapitools/openapi-generator-cli generate \\\n    -i https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml \\\n    -g go \\\n    -o /local/out/go\n```\n\nThe generated code will be located under `./out/go` in the current directory.\n\n#### OpenAPI Generator Online Docker Image\n\nThe openapi-generator-online image can act as a self-hosted web application and API for generating code. This container can be incorporated into a CI pipeline, and requires at least two HTTP requests and some docker orchestration to access generated code.\n\nExample usage:\n\n```sh\n# Start container at port 8888 and save the container id\n> CID=$(docker run -d -p 8888:8080 openapitools/openapi-generator-online)\n\n# allow for startup\n> sleep 10\n\n# Get the IP of the running container (optional)\nGEN_IP=$(docker inspect --format '{{.NetworkSettings.IPAddress}}'  $CID)\n\n# Execute an HTTP request to generate a Ruby client\n> curl -X POST --header 'Content-Type: application/json' --header 'Accept: application/json' \\\n-d '{\"openAPIUrl\": \"https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml\"}' \\\n'http://localhost:8888/api/gen/clients/ruby'\n\n{\"code\":\"c2d483.3.4672-40e9-91df-b9ffd18d22b8\",\"link\":\"http://localhost:8888/api/gen/download/c2d483.3.4672-40e9-91df-b9ffd18d22b8\"}\n\n# Download the generated zip file\n> wget http://localhost:8888/api/gen/download/c2d483.3.4672-40e9-91df-b9ffd18d22b8\n\n# Unzip the file\n> unzip c2d483.3.4672-40e9-91df-b9ffd18d22b8\n\n# Shutdown the openapi generator image\n> docker stop $CID && docker rm $CID\n```\n\n#### Development in docker\n\nYou can use `run-in-docker.sh` to do all development. This script maps your local repository to `/gen`\nin the docker container. It also maps `~/.m2/repository` to the appropriate container location.\n\nTo execute `mvn package`:\n\n```sh\ngit clone https://github.com/openapitools/openapi-generator\ncd openapi-generator\n./run-in-docker.sh mvn package\n```\n\nBuild artifacts are now accessible in your working directory.\n\nOnce built, `run-in-docker.sh` will act as an executable for openapi-generator-cli. To generate code, you'll need to output to a directory under `/gen` (e.g. `/gen/out`). For example:\n\n```sh\n./run-in-docker.sh help # Executes 'help' command for openapi-generator-cli\n./run-in-docker.sh list # Executes 'list' command for openapi-generator-cli\n./run-in-docker.sh generate -i modules/openapi-generator/src/test/resources/3_0/petstore.yaml \\\n    -g go -o /gen/out/go-petstore -p packageName=petstore # generates go client, outputs locally to ./out/go-petstore\n```\n\n##### Troubleshooting\n\nIf an error like this occurs, just execute the **./mvnw clean install -U** command:\n\n> org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project openapi-generator: A type incompatibility occurred while executing org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test: java.lang.ExceptionInInitializerError cannot be cast to java.io.IOException\n\n```sh\n./run-in-docker.sh ./mvnw clean install -U\n```\n\n> Failed to execute goal org.fortasoft:gradle-maven-plugin:1.0.8:invoke (default) on project openapi-generator-gradle-plugin-mvn-wrapper: org.gradle.tooling.BuildException: Could not execute build using Gradle distribution 'https://services.gradle.org/distributions/gradle-4.7-bin.zip'\n\nRight now: no solution for this one :|\n\n#### Run Docker in Vagrant\nPrerequisite: install [Vagrant](https://www.vagrantup.com/downloads.html) and [VirtualBox](https://www.virtualbox.org/wiki/Downloads).\n ```sh\ngit clone https://github.com/openapitools/openapi-generator.git\ncd openapi-generator\nvagrant up\nvagrant ssh\ncd /vagrant\n./run-in-docker.sh ./mvnw package\n```\n\n### [1.7 - NPM](#table-of-contents)\n\nThere is also an [NPM package wrapper](https://www.npmjs.com/package/@openapitools/openapi-generator-cli) available for different platforms (e.g. Linux, Mac, Windows). (JVM is still required)\nPlease see the [project's README](https://github.com/openapitools/openapi-generator-cli) there for more information.\n\nInstall it globally to get the CLI available on the command line:\n\n```sh\nnpm install @openapitools/openapi-generator-cli -g\nopenapi-generator-cli version\n```\n\n<!-- RELEASE_VERSION -->\nTo use a specific version of \"openapi-generator-cli\"\n\n```sh\nopenapi-generator-cli version-manager set 7.19.0\n```\n\nOr install it as dev-dependency:\n\n```sh\nnpm install @openapitools/openapi-generator-cli -D\n```\n<!-- /RELEASE_VERSION -->\n\nYou can use [locally built JARs](https://github.com/OpenAPITools/openapi-generator-cli?tab=readme-ov-file#use-locally-built-jar) or [`SNAPSHOT` versions](https://github.com/OpenAPITools/openapi-generator-cli?tab=readme-ov-file#use-nightly-snapshot-build) as well.\n\n### [1.8 - pip](#table-of-contents)\n\n\n> **Platform(s)**: Linux, macOS, Windows\n**Install** via [PyPI](https://pypi.org/) (`java` executable is needed to run):\n\n```\npip install openapi-generator-cli\n```\n\nTo install a specific version\n```\npip install openapi-generator-cli==7.19.0\n```\n\nYou can also install with [jdk4py](https://github.com/activeviam/jdk4py) instead of java binary. (python>=3.10 is required)\n\n```\npip install openapi-generator-cli[jdk4py]\n```\n\nRef: https://github.com/openAPITools/openapi-generator-pip\n\n## [2 - Getting Started](#table-of-contents)\n\nTo generate a PHP client for [petstore.yaml](https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml), please run the following\n```sh\ngit clone https://github.com/openapitools/openapi-generator\ncd openapi-generator\n./mvnw clean package\njava -jar modules/openapi-generator-cli/target/openapi-generator-cli.jar generate \\\n   -i https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml \\\n   -g php \\\n   -o /var/tmp/php_api_client\n```\n(if you're on Windows, replace the last command with `java -jar modules\\openapi-generator-cli\\target\\openapi-generator-cli.jar generate -i https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml -g php -o c:\\temp\\php_api_client`)\n\n<!-- RELEASE_VERSION -->\nYou can also download the JAR (latest release) directly from [maven.org](https://repo1.maven.org/maven2/org/openapitools/openapi-generator-cli/7.19.0/openapi-generator-cli-7.19.0.jar)\n<!-- /RELEASE_VERSION -->\n\nTo get a list of **general** options available, please run `java -jar modules/openapi-generator-cli/target/openapi-generator-cli.jar help generate`\n\nTo get a list of PHP specified options (which can be passed to the generator with a config file via the `-c` option), please run `java -jar modules/openapi-generator-cli/target/openapi-generator-cli.jar config-help -g php`\n\n## [3 - Usage](#table-of-contents)\n\n### To generate a sample client library\nYou can build a client against the [Petstore API](https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml) as follows:\n\n```sh\n./bin/generate-samples.sh ./bin/configs/java-okhttp-gson.yaml\n```\n\n(On Windows, please install [GIT Bash for Windows](https://gitforwindows.org/) to run the command above)\n\nThis script uses the default library, which is `okhttp-gson`. It will run the generator with this command:\n\n```sh\njava -jar modules/openapi-generator-cli/target/openapi-generator-cli.jar generate \\\n  -i https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml \\\n  -g java \\\n  -t modules/openapi-generator/src/main/resources/Java \\\n  --additional-properties artifactId=petstore-okhttp-gson,hideGenerationTimestamp=true \\\n  -o samples/client/petstore/java/okhttp-gson\n```\n\nwith a number of options. [The java options are documented here.](docs/generators/java.md)\n\nYou can also get the options with the `help generate` command (below only shows partial results):\n\n```\nNAME\n        openapi-generator-cli generate - Generate code with the specified\n        generator.\n\nSYNOPSIS\n        openapi-generator-cli generate\n                [(-a <authorization> | --auth <authorization>)]\n                [--api-name-suffix <api name suffix>] [--api-package <api package>]\n                [--artifact-id <artifact id>] [--artifact-version <artifact version>]\n                [(-c <configuration file> | --config <configuration file>)] [--dry-run]\n                [(-e <templating engine> | --engine <templating engine>)]\n                [--enable-post-process-file]\n                [(-g <generator name> | --generator-name <generator name>)]\n                [--generate-alias-as-model] [--git-host <git host>]\n                [--git-repo-id <git repo id>] [--git-user-id <git user id>]\n                [--global-property <global properties>...] [--group-id <group id>]\n                [--http-user-agent <http user agent>]\n                [(-i <spec file> | --input-spec <spec file>)]\n                [--ignore-file-override <ignore file override location>]\n                [--import-mappings <import mappings>...]\n                [--instantiation-types <instantiation types>...]\n                [--invoker-package <invoker package>]\n                [--language-specific-primitives <language specific primitives>...]\n                [--legacy-discriminator-behavior] [--library <library>]\n                [--log-to-stderr] [--minimal-update]\n                [--model-name-prefix <model name prefix>]\n                [--model-name-suffix <model name suffix>]\n                [--model-package <model package>]\n                [(-o <output directory> | --output <output directory>)] [(-p <additional properties> | --additional-properties <additional properties>)...]\n                [--package-name <package name>] [--release-note <release note>]\n                [--remove-operation-id-prefix]\n                [--reserved-words-mappings <reserved word mappings>...]\n                [(-s | --skip-overwrite)] [--server-variables <server variables>...]\n                [--skip-validate-spec] [--strict-spec <true/false strict behavior>]\n                [(-t <template directory> | --template-dir <template directory>)]\n                [--type-mappings <type mappings>...] [(-v | --verbose)]\n\nOPTIONS\n        -a <authorization>, --auth <authorization>\n            adds authorization headers when fetching the OpenAPI definitions\n            remotely. Pass in a URL-encoded string of name:header with a comma\n            separating multiple values\n\n...... (results omitted)\n\n        -v, --verbose\n            verbose mode\n\n```\n\nYou can then compile and run the client, as well as unit tests against it:\n\n```sh\ncd samples/client/petstore/java/okhttp-gson\nmvn package\n```\n\nOther generators have [samples](https://github.com/OpenAPITools/openapi-generator/tree/master/samples) too.\n\n### [3.1 - Customization](#table-of-contents)\n\nPlease refer to [customization.md](docs/customization.md) on how to customize the output (e.g. package name, version)\n\n### [3.2 - Workflow Integration (Maven, Gradle, Github, CI/CD)](#table-of-contents)\n\nPlease refer to [integration.md](docs/integration.md) on how to integrate OpenAPI generator with Maven, Gradle, sbt, Bazel, Github and CI/CD.\n\n### [3.3 - Online OpenAPI generator](#table-of-contents)\n\nHere are the public online services:\n\n- latest stable version: https://api.openapi-generator.tech\n- latest master: https://api-latest-master.openapi-generator.tech (updated with latest master every hour)\n\nThe server is sponsored by [Linode](https://www.linode.com/) [![Linode Logo](https://www.linode.com/media/images/logos/standard/light/linode-logo_standard_light_small.png)](https://www.linode.com/)\n\n(These services are beta and do not have any guarantee on service level)\n\nPlease refer to [online.md](docs/online.md) on how to run and use the `openapi-generator-online` - a web service for `openapi-generator`.\n\n### [3.4 - License information on Generated Code](#table-of-contents)\n\nThe OpenAPI Generator project is intended as a benefit for users of the Open API Specification.  The project itself has the [License](#7---license) as specified. In addition, please understand the following points:\n\n* The templates included with this project are subject to the [License](#7---license).\n* Generated code is intentionally _not_ subject to the parent project license\n\nWhen code is generated from this project, it shall be considered **AS IS** and owned by the user of the software.  There are no warranties--expressed or implied--for generated code.  You can do what you wish with it, and once generated, the code is your responsibility and subject to the licensing terms that you deem appropriate.\n\n### [3.5 - IDE Integration](#table-of-contents)\n\nHere is a list of community-contributed IDE plug-ins that integrate with OpenAPI Generator:\n\n- Eclipse: [Codewind OpenAPI Tools for Eclipse](https://www.eclipse.org/codewind/open-api-tools-for-eclipse.html) by [IBM](https://www.ibm.com)\n- IntelliJ IDEA: [OpenAPI Generator](https://plugins.jetbrains.com/plugin/8433-openapi-generator) by [Jim Schubert](https://jimschubert.us/#/)\n- IntelliJ IDEA: [Senya Editor](https://plugins.jetbrains.com/plugin/10690-senya-editor) by [senya.io](https://senya.io)\n- [RepreZen API Studio](https://www.reprezen.com/)\n- Visual Studio: [REST API Client Code Generator](https://marketplace.visualstudio.com/items?itemName=ChristianResmaHelle.ApiClientCodeGenerator) by [Christian Resma Helle](https://christian-helle.blogspot.com/)\n- Visual Studio Code: [Codewind OpenAPI Tools](https://marketplace.visualstudio.com/items?itemName=IBM.codewind-openapi-tools) by [IBM](https://marketplace.visualstudio.com/publishers/IBM)\n\n\n## [4 - Companies/Projects using OpenAPI Generator](#table-of-contents)\nHere are some companies/projects (alphabetical order) using OpenAPI Generator in production. To add your company/project to the list, please visit [README.md](README.md) and click on the icon to edit the page.\n\n- [Aalborg University](https://www.aau.dk)\n- [act coding](https://github.com/actcoding)\n- [Adaptant Solutions AG](https://www.adaptant.io/)\n- [adesso SE](https://www.adesso.de/)\n- [adorsys GmbH & Co.KG](https://adorsys.com/)\n- [Adyen](https://www.adyen.com/)\n- [Agoda](https://www.agoda.com/)\n- [Airthings](https://www.airthings.com/)\n- [Aleri Solutions Gmbh](https://www.aleri.de/)\n- [Allianz](https://www.allianz.com)\n- [Angular.Schule](https://angular.schule/)\n- [Aqovia](https://aqovia.com/)\n- [Australia and New Zealand Banking Group (ANZ)](http://www.anz.com/)\n- [Arduino](https://www.arduino.cc/)\n- [ASKUL](https://www.askul.co.jp)\n- [Amazon Web Services (AWS)](https://aws.amazon.com/)\n- [b<>com](https://b-com.com/en)\n- [ÁôæÂ∫¶Ëê•ÈîÄ](https://e.baidu.com)\n- [Bandwidth](https://dev.bandwidth.com)\n- [Banzai Cloud](https://banzaicloud.com)\n- [BIMData.io](https://bimdata.io)\n- [Bithost GmbH](https://www.bithost.ch)\n- [Bosch Connected Industry](https://www.bosch-connected-industry.com)\n- [Boxever](https://www.boxever.com/)\n- [Brevy](https://www.brevy.com)\n- [Bunker Holding Group](https://www.bunker-holding.com/)\n- [California State University, Northridge](https://www.csun.edu)\n- [CAM](https://www.cam-inc.co.jp/)\n- [Camptocamp](https://www.camptocamp.com/en)\n- [Carlsberg Group](https://www.carlsberggroup.com/)\n- [CERN](https://home.cern/)\n- [Christopher Queen Consulting](https://www.christopherqueenconsulting.com/)\n- [Cisco](https://www.cisco.com/)\n- [codecentric AG](https://www.codecentric.de/)\n- [CoinAPI](https://www.coinapi.io/)\n- [Commencis](https://www.commencis.com/)\n- [ConfigCat](https://configcat.com/)\n- [cronn GmbH](https://www.cronn.de/)\n- [Crossover Health](https://crossoverhealth.com/)\n- [Cupix](https://www.cupix.com/)\n- [Datadog](https://www.datadoghq.com)\n- [DB Systel](https://www.dbsystel.de)\n- [Deeporute.ai](https://www.deeproute.ai/)\n- [Devsupply](https://www.devsupply.com/)\n- [dmTECH GmbH](https://www.dmTECH.de)\n- [DocSpring](https://docspring.com/)\n- [dwango](https://dwango.co.jp/)\n- [Edge Impulse](https://www.edgeimpulse.com/)\n- [Element AI](https://www.elementai.com/)\n- [Embotics](https://www.embotics.com/)\n- [emineo](https://www.emineo.ch)\n- [fastly](https://www.fastly.com/)\n- [Fenergo](https://www.fenergo.com/)\n- [freee](https://corp.freee.co.jp/en/)\n- [FreshCells](https://www.freshcells.de/)\n- [Fuse](https://www.fuse.no/)\n- [Gantner](https://www.gantner.com)\n- [GenFlow](https://github.com/RepreZen/GenFlow)\n- [GetYourGuide](https://www.getyourguide.com/)\n- [Glovo](https://glovoapp.com/)\n- [GMO Pepabo](https://pepabo.com/en/)\n- [GoDaddy](https://godaddy.com)\n- [Gumtree](https://gumtree.com)\n- [Here](https://developer.here.com/)\n- [IBM](https://www.ibm.com/)\n- [Instana](https://www.instana.com)\n- [Interxion](https://www.interxion.com)\n- [Inquisico](https://inquisico.com)\n- [JustStar](https://www.juststarinfo.com)\n- [k6.io](https://k6.io/)\n- [Klarna](https://www.klarna.com/)\n- [Kronsoft Development](https://www.kronsoft.ro/home/)\n- [Kubernetes](https://kubernetes.io)\n- [Landeshauptstadt M√ºnchen - it@M](https://muenchen.digital/it-at-m/)\n- [Linode](https://www.linode.com/)\n- [Logicdrop](https://www.logicdrop.com)\n- [Lumeris](https://www.lumeris.com)\n- [LVM Versicherungen](https://www.lvm.de)\n- [MailSlurp](https://www.mailslurp.com)\n- [Manticore Search](https://manticoresearch.com)\n- [Mastercard](https://developers.mastercard.com)\n- [M√©diavision](https://www.mediavision.fr/)\n- [Metaswitch](https://www.metaswitch.com/)\n- [MoonVision](https://www.moonvision.io/)\n- [Myworkout](https://myworkout.com)\n- [NamSor](https://www.namsor.com/)\n- [Neverfail](https://www.neverfail.com/)\n- [NeuerEnergy](https://neuerenergy.com)\n- [Nokia](https://www.nokia.com/)\n- [OneSignal](https://www.onesignal.com/)\n- [Options Clearing Corporation (OCC)](https://www.theocc.com/)\n- [Openet](https://www.openet.com/)\n- [openVALIDATION](https://openvalidation.io/)\n- [Oracle](https://www.oracle.com/)\n- [Paxos](https://www.paxos.com)\n- [Plaid](https://plaid.com)\n- [PLAID, Inc.](https://plaid.co.jp/)\n- [Pinterest](https://www.pinterest.com)\n- [Ponicode](https://ponicode.dev/)\n- [Pricefx](https://www.pricefx.com/)\n- [PrintNanny](https://www.print-nanny.com/)\n- [Prometheus/Alertmanager](https://github.com/prometheus/alertmanager)\n- [Qavar](https://www.qavar.com)\n- [QEDIT](https://qed-it.com)\n- [Qovery](https://qovery.com)\n- [Qulix Systems](https://www.qulix.com)\n- [Raksul](https://corp.raksul.com)\n- [Raiffeisen Schweiz Genossenschaft](https://www.raiffeisen.ch)\n- [RedHat](https://www.redhat.com)\n- [RepreZen API Studio](https://www.reprezen.com/swagger-openapi-code-generation-api-first-microservices-enterprise-development)\n- [REST United](https://restunited.com)\n- [Robocorp](https://www.robocorp.com)\n- [Robotinfra](https://www.robotinfra.com)\n- [Sarvika Technologies Pvt. Ltd.](https://www.sarvika.com)\n- [SearchApi](https://www.searchapi.io/)\n- [SmartHR](https://smarthr.co.jp/)\n- [Sony Interactive Entertainment](https://www.sie.com/en/index.html)\n- [Splitit](https://www.splitit.com/)\n- [Stingray](http://www.stingray.com)\n- [Suva](https://www.suva.ch/)\n- [Svix](https://www.svix.com/)\n- [Telstra](https://dev.telstra.com)\n- [Tencent](https://www.tencent.com)\n- [The University of Aizu](https://www.u-aizu.ac.jp/en/)\n- [TINQIN](https://www.tinqin.com/)\n- [Translucent ApS](https://www.translucent.dk)\n- [TravelTime platform](https://www.traveltimeplatform.com/)\n- [TribalScale](https://www.tribalscale.com)\n- [Trifork](https://trifork.com)\n- [TUI InfoTec GmbH](http://www.tui-infotec.com/)\n- [Twilio](https://www.twilio.com/)\n- [Twitter](https://twitter.com)\n- [unblu inc.](https://www.unblu.com/)\n- [Veamly](https://www.veamly.com/)\n- [VMWare](https://www.vmware.com/)\n- [wbt-solutions](https://www.wbt-solutions.de/)\n- [Woleet](https://www.woleet.io/)\n- [WSO2](https://wso2.com/)\n- [Vouchery.io](https://vouchery.io)\n- [Xero](https://www.xero.com/)\n- [Yahoo Japan](https://www.yahoo.co.jp/)\n- [viadee](https://www.viadee.de/)\n- [Vonage](https://vonage.com)\n- [YITU Technology](https://www.yitutech.com/)\n- [Yelp](https://www.yelp.com/)\n- [Zalando](https://www.zalando.com)\n- [3DS Outscale](https://www.outscale.com/)\n\n## [5 - Presentations/Videos/Tutorials/Books](#table-of-contents)\n\n- 2018/05/12 - [OpenAPI Generator - community driven„ÅßÊàêÈï∑„Åô„Çã„Ç≥„Éº„Éâ„Ç∏„Çß„Éç„É¨„Éº„Çø](https://ackintosh.github.io/blog/2018/05/12/openapi-generator/) by [‰∏≠ÈáéÊöÅ‰∫∫](https://github.com/ackintosh)\n- 2018/05/15 - [Starting a new open-source project](http://jmini.github.io/blog/2018/2018-05-15_new-open-source-project.html) by [Jeremie Bresson](https://github.com/jmini)\n- 2018/05/15 - [REST API‰ªïÊßò„Åã„ÇâAPI„ÇØ„É©„Ç§„Ç¢„É≥„Éà„ÇÑ„Çπ„Çø„Éñ„Çµ„Éº„Éê„ÇíËá™ÂãïÁîüÊàê„Åô„Çã„ÄåOpenAPI Generator„Äç„Ç™„Éº„Éó„É≥„ÇΩ„Éº„Çπ„ÅßÂÖ¨Èñã„ÄÇSwagger Codegen„Åã„Çâ„ÅÆ„Éï„Ç©„Éº„ÇØ](https://www.publickey1.jp/blog/18/rest_apiapiopenapi_generatorswagger_generator.html) by [Publickey](https://www.publickey1.jp)\n- 2018/06/08 - [Swagger Codegen is now OpenAPI Generator](https://angular.schule/blog/2018-06-swagger-codegen-is-now-openapi-generator) by [JohannesHoppe](https://github.com/JohannesHoppe)\n- 2018/06/21 - [Connect your JHipster apps to the world of APIs with OpenAPI and gRPC](https://fr.slideshare.net/chbornet/jhipster-conf-2018-connect-your-jhipster-apps-to-the-world-of-apis-with-openapi-and-grpc) by [Christophe Bornet](https://github.com/cbornet) at [JHipster Conf 2018](https://jhipster-conf.github.io/)\n- 2018/06/22 - [OpenAPI Generator „Åß Gatling Client „ÇíÁîüÊàê„Åó„Å¶„Åø„Åü](https://rohki.hatenablog.com/entry/2018/06/22/073000) at [„ÇΩ„É¢„Çµ„É≥](https://rohki.hatenablog.com/)\n- 2018/06/27 - [Lessons Learned from Leading an Open-Source Project Supporting 30+ Programming Languages](https://speakerdeck.com/wing328/lessons-learned-from-leading-an-open-source-project-supporting-30-plus-programming-languages) - [William Cheng](https://github.com/wing328) at [LinuxCon + ContainerCon + CloudOpen China 2018](http://bit.ly/2waDKKX)\n- 2018/07/19 - [OpenAPI Generator Contribution Quickstart - RingCentral Go SDK](https://medium.com/ringcentral-developers/openapi-generator-for-go-contribution-quickstart-8cc72bf37b53) by [John Wang](https://github.com/grokify)\n- 2018/08/22 - [OpenAPI Generator„ÅÆ„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÊßãÊàê„Å™„Å©„ÅÆ„É°„É¢](https://yinm.info/20180822/) by [Yusuke Iinuma](https://github.com/yinm)\n- 2018/09/12 - [RepreZen and OpenAPI 3.0: Now is the Time](https://www.reprezen.com/blog/reprezen-openapi-3.0-upgrade-now-is-the-time) by [Miles Daffin](https://www.reprezen.com/blog/author/miles-daffin)\n- 2018/10/31 - [A node package wrapper for openapi-generator](https://github.com/HarmoWatch/openapi-generator-cli)\n- 2018/11/03 - [OpenAPI Generator + golang + Flutter „Åß„Ç¢„Éó„É™ÈñãÁô∫](http://ryuichi111std.hatenablog.com/entry/2018/11/03/214005) by [Ryuichi Daigo](https://github.com/ryuichi111)\n- 2018/11/15 - [Âü∫‰∫éopenapi3.0ÁöÑyamlÊñá‰ª∂ÁîüÊàêjava‰ª£Á†ÅÁöÑ‰∏ÄÊ¨°ÂÆûË∑µ](https://blog.csdn.net/yzy199391/article/details/84023982) by [ÁÑ±È≠îÁéã](https://me.csdn.net/yzy199391)\n- 2018/11/18 - [Generating PHP library code from OpenAPI](https://lornajane.net/posts/2018/generating-php-library-code-from-openapi) by [Lorna Jane](https://lornajane.net/) at [LORNAJANE Blog](https://lornajane.net/blog)\n- 2018/11/19 - [OpenAPIs are everywhere](https://youtu.be/-lDot4Yn7Dg) by [Jeremie Bresson (Unblu)](https://github.com/jmini) at [EclipseCon Europe 2018](https://www.eclipsecon.org/europe2018)\n- 2018/12/09 - [openapi-generator „Çí„Ç´„Çπ„Çø„Éû„Ç§„Ç∫„Åô„ÇãÊñπÊ≥ï](https://qiita.com/watiko/items/0961287c02eac9211572) by [@watiko](https://qiita.com/watiko)\n- 2019/01/03 - [Calling a Swagger service from Apex using openapi-generator](https://lekkimworld.com/2019/01/03/calling-a-swagger-service-from-apex-using-openapi-generator/) by [Mikkel Flindt Heisterberg](https://lekkimworld.com)\n- 2019/01/13 - [OpenAPI Generator„ÅßRESTful API„ÅÆÂÆöÁæ©Êõ∏„Åã„ÇâËâ≤„ÄÖËá™ÂãïÁîüÊàê„Åô„Çã](https://ky-yk-d.hatenablog.com/entry/2019/01/13/234108) by [@ky_yk_d](https://twitter.com/ky_yk_d)\n- 2019/01/20 - [Contract-First API Development with OpenAPI Generator and Connexion](https://medium.com/commencis/contract-first-api-development-with-openapi-generator-and-connexion-b21bbf2f9244) by [Anil Can Aydin](https://github.com/anlcnydn)\n- 2019/01/30 - [Rapid Application Development With API First Approach Using Open-API Generator](https://dzone.com/articles/rapid-api-development-using-open-api-generator) by [Milan Sonkar](https://dzone.com/users/828329/milan_sonkar.html)\n- 2019/02/02 - [Âπ≥Èùô„Çí‰øù„Å°„ÄÅ„Ç≥„Éº„Éâ„ÇíÁîüÊàê„Åõ„Çà „Äú OpenAPI GeneratorË™ïÁîü„ÅÆËÉåÊôØ„Å®ËªåË∑° „Äú](https://speakerdeck.com/akihito_nakano/gunmaweb34) by [‰∏≠ÈáéÊöÅ‰∫∫](https://github.com/ackintosh) at [Gunma.web #34 „Çπ„Ç≠„Éº„ÉûÈßÜÂãïÈñãÁô∫](https://gunmaweb.connpass.com/event/113974/)\n- 2019/02/20 - [An adventure in OpenAPI V3 code generation](https://mux.com/blog/an-adventure-in-openapi-v3-api-code-generation/) by [Phil Cluff](https://mux.com/blog/author/philc/)\n- 2019/02/26 - [Building API Services: A Beginner‚Äôs Guide](https://medium.com/google-cloud/building-api-services-a-beginners-guide-7274ae4c547f) by [Ratros Y.](https://medium.com/@ratrosy) in [Google Cloud Platform Blog](https://medium.com/google-cloud)\n- 2019/02/26 - [Building APIs with OpenAPI: Continued](https://medium.com/@ratrosy/building-apis-with-openapi-continued-5d0faaed32eb) by [Ratros Y.](https://medium.com/@ratrosy) in [Google Cloud Platform Blog](https://medium.com/google-cloud)\n- 2019-03-07 - [OpenAPI Generator „Åß Spring Boot „Å® Angular „Çí„Çø„Ç§„Éó„Çª„Éº„Éï„Å´Áπã„Åê](https://qiita.com/chibato/items/e4a748db12409b40c02f) by [Tomofumi Chiba](https://github.com/chibat)\n- 2019-03-16 - [A Quick introduction to manual OpenAPI V3](https://vadosware.io/post/quick-intro-to-manual-openapi-v3/) by [vados](https://github.com/t3hmrman) at [VADOSWARE](https://vadosware.io)\n- 2019-03-25 - [Access any REST service with the SAP S/4HANA Cloud SDK](https://blogs.sap.com/2019/03/25/integrate-sap-s4hana-cloud-sdk-with-open-api/) by [Alexander Duemont](https://people.sap.com/alexander.duemont)\n- 2019-03-25 - [OpenAPI generator„ÇíË©¶„Åó„Å¶„Åø„Çã](https://qiita.com/amuyikam/items/e8a45daae59c68be0fc8) by [@amuyikam](https://twitter.com/amuyikam)\n- 2019-03-27 - [OpenAPI3„Çí‰Ωø„Å£„Å¶„Åø„Çà„ÅÜÔºÅGoË®ÄË™û„Åß„ÇØ„É©„Ç§„Ç¢„É≥„Éà„Å®„Çπ„Çø„Éñ„ÅÆËá™ÂãïÁîüÊàê„Åæ„ÅßÔºÅ](https://techblog.zozo.com/entry/openapi3/go) by [@gold_kou](https://twitter.com/gold_kou)\n- 2019-04-17 - [OpenAPI„Å´„Çà„Çã„Çπ„Ç≠„Éº„Éû„Éï„Ç°„Éº„Çπ„ÉàÈñãÁô∫„ÅÆÂÆüÊñΩ„Çµ„É≥„Éó„É´„Å®Cloud Run„Å´„Å§„ÅÑ„Å¶](https://tech-blog.optim.co.jp/entry/2019/04/17/174000) by [@yukey1031](https://twitter.com/yukey1031)\n- 2019-04-18 - [How to use OpenAPI3 for API developer (RubyKaigi 2019)](https://speakerdeck.com/ota42y/how-to-use-openapi3-for-api-developer) by [@ota42y](https://twitter.com/ota42y) at [RubyKaigi 2019](https://rubykaigi.org/2019)\n- 2019-04-29 - [A Beginner's Guide to Code Generation for REST APIs (OpenAPI Generator)](https://gum.co/openapi_generator_ebook) by [William Cheng](https://twitter.com/wing328)\n- 2019-05-01 - [Design and generate a REST API from Swagger / OpenAPI in Java, Python, C# and more](https://simply-how.com/design-and-generate-api-code-from-openapi) by [Simply How](https://simply-how.com/)\n- 2019-05-17 - [Generate Spring Boot REST API using Swagger/OpenAPI](https://www.47northlabs.com/knowledge-base/generate-spring-boot-rest-api-using-swagger-openapi/) by [Antonie Zafirov](https://www.47northlabs.com/author/antonie-zafirov/)\n- 2019-05-22 - [REST APIs‰ª£Á†ÅÁîüÊàêÊåáÂçó(OpenAPI Generator)](https://gum.co/openapi_generator_ebook_gb) by [William Cheng](https://twitter.com/wing328), [Xin Meng](https://github.com/xmeng1)\n- 2019-05-24 - [REST API ‰ª£Á¢ºÁîüÊàêÊåáÂçó (OpenAPI Generator)](https://gum.co/openapi_generator_ebook_big5) by [William Cheng](https://twitter.com/wing328)\n- 2019-06-24 - [Kubernetes Clients and OpenAPI Generator](https://speakerdeck.com/wing328/kubernetes-clients-and-openapi-generator) by [William Cheng](https://twitter.com/wing328) at [Kubernetes Contributor Summits Shanghai 2019](https://www.lfasiallc.com/events/contributors-summit-china-2019/)\n- 2019-06-28 [Codewind OpenAPI Tools](https://marketplace.eclipse.org/content/codewind-openapi-tools) in [Eclipse Marketplace](https://marketplace.eclipse.org/) by IBM\n- 2019-06-29 [Codewind OpenAPI Tools](https://marketplace.visualstudio.com/items?itemName=IBM.codewind-openapi-tools) in [Visual Studio Marketplace](https://marketplace.visualstudio.com/) by IBM\n- 2019-07-04 - [REST API „ÅÆ„Åü„ÇÅ„ÅÆ„Ç≥„Éº„Éà„ÇôÁîüÊàêÂÖ•ÈñÄ (OpenAPI Generator)](https://gum.co/openapi_generator_ebook_big5) by [William Cheng](https://twitter.com/wing328), [‰∏≠ÈáéÊöÅ‰∫∫](https://github.com/ackintosh), [ÂíåÁî∞ÊãìÊúó](https://github.com/taxpon)\n- 2019-07-08 - [OpenAPI Generator „Å´„Ç≥„É≥„Éà„É™„Éì„É•„Éº„Éà„Åó„Åü„ÇâÁ§æÂêç„ÅåËºâ„Å£„ÅüË©±„ÄÇ(CAM) - CAM TECH BLOG](https://tech.cam-inc.co.jp/entry/2019/07/08/140000) by [CAM, Inc.](https://www.cam-inc.co.jp/)\n- 2019-07-14 - [OpenAPI Generator„ÅßPython„ÅÆ„ÇØ„É©„Ç§„Ç¢„É≥„Éà„É©„Ç§„Éñ„É©„É™„Çí‰ΩúÊàê„Åó„Åü](https://qiita.com/yuji38kwmt/items/dfb929316a1335a161c0) by [yuji38kwmt](https://qiita.com/yuji38kwmt)\n- 2019-07-19 - [Developer Experience (DX) for Open-Source Projects: How to Engage Developers and Build a Growing Developer Community](https://speakerdeck.com/wing328/developer-experience-dx-for-open-source-projects-english-japanese) by [William Cheng](https://twitter.com/wing328), [‰∏≠ÈáéÊöÅ‰∫∫](https://github.com/ackintosh) at [Open Source Summit Japan 2019](https://events.linuxfoundation.org/events/open-source-summit-japan-2019/)\n- 2019-08-14 - [Our OpenAPI journey with Standardizing SDKs](https://bitmovin.com/our-openapi-journey-with-standardizing-sdks/) by [Sebastian Burgstaller](https://bitmovin.com/author/sburgstaller/) at [Bitmovin](https://www.bitmovin.com)\n- 2019-08-15 - [API„ÅÆ„Ç≥„Éº„Éâ„ÇíËá™ÂãïÁîüÊàê„Åï„Åõ„Åü„ÅÑ„Å†„Åë„Å™„ÇâgRPC„Åß„Å™„Åè„Å¶„ÇÇ„Çà„Åè„Å™„ÅÑ?](https://www.m3tech.blog/entry/2019/08/15/110000) by [M3, Inc.](https://corporate.m3.com/)\n- 2019-08-22 - [„Éû„Ç§„ÇØ„É≠„Çµ„Éº„Éì„Çπ„Å´„Åä„Åë„ÇãWeb API„Çπ„Ç≠„Éº„Éû„ÅÆÁÆ°ÁêÜ‚îÄ GraphQL„ÄÅgRPC„ÄÅOpenAPI„ÅÆÁâπÂæ¥„Å®‰Ωø„ÅÑ„Å©„Åì„Çç](https://employment.en-japan.com/engineerhub/entry/2019/08/22/103000) by [@ota42y](https://twitter.com/ota42y)\n- 2019-08-24 - [Swagger„Éâ„Ç≠„É•„É°„É≥„Éà„Åã„ÇâOpenAPI Generator„Çí‰Ωø„Å£„Å¶„É¢„ÉÉ„ÇØ„Çµ„Éº„Éê„Éº‰ΩúÊàê](https://qiita.com/masayoshi0222/items/4845e4c715d04587c104) by [ÂùÇÊú¨Ê≠£Áæ©](https://qiita.com/masayoshi0222)\n- 2019-08-29 - [OpenAPIÂàùÊé¢](https://cloud.tencent.com/developer/article/1495986) by [peakxie](https://cloud.tencent.com/developer/user/1113152) at [ËÖæËÆØ‰∫ëÁ§æÂå∫](https://cloud.tencent.com/developer)\n- 2019-08-29 - [ÂÖ®Èù¢ËøõÂåñÔºöKubernetes CRD 1.16 GAÂâçÁûª](https://www.servicemesher.com/blog/kubernetes-1.16-crd-ga-preview/) by [Min Kim](https://github.com/yue9944882) at [ServiceMesher Blog](https://www.servicemesher.com/blog/)\n- 2019-09-01 - [Creating a PHP-Slim server using OpenAPI (Youtube video)](https://www.youtube.com/watch?v=5cJtbIrsYkg) by [Daniel Persson](https://www.youtube.com/channel/UCnG-TN23lswO6QbvWhMtxpA)\n- 2019-09-06 - [Vert.x and OpenAPI](https://wissel.net/blog/2019/09/vertx-and-openapi.html) by [Stephan H Wissel](https://twitter.com/notessensei) at [wissel.net blog](https://wissel.net)\n- 2019-09-09 - [Cloud-native development - Creating RESTful microservices](https://cloud.ibm.com/docs/cloud-native?topic=cloud-native-rest-api) in [IBM Cloud Docs](https://cloud.ibm.com/docs)\n- 2019-09-14 - [Generating and Configuring a Mastercard API Client](https://developer.mastercard.com/platform/documentation/generating-and-configuring-a-mastercard-api-client/) at [Mastercard Developers Platform](https://developer.mastercard.com/platform/documentation/)\n- 2019-09-15 - [OpenAPI(Swagger)Â∞éÂÖ•‰∏ãË™ø„Åπ](https://qiita.com/ShoichiKuraoka/items/f1f7a3c2376f7cd9c56a) by [Shoichi Kuraoka](https://qiita.com/ShoichiKuraoka)\n- 2019-09-17 - [Tutorial: Documenting http4k APIs with OpenApi3](https://www.http4k.org/tutorials/documenting_apis_with_openapi/) by [http4k](https://www.http4k.org/)\n- 2019-09-22 - [OpenAPI 3„ÇíÂÆåÂÖ®„Å´ÁêÜËß£„Åß„Åç„ÇãÊú¨](https://booth.pm/ja/items/1571902) by [@ota42y](https://twitter.com/ota42y)\n- 2019-09-22 - [RESTful APIs: Tutorial of OpenAPI Specification](https://medium.com/@amirm.lavasani/restful-apis-tutorial-of-openapi-specification-eeada0e3901d) by [Amir Lavasani](https://medium.com/@amirm.lavasani)\n- 2019-09-22 - [Redefining SDKs as software diversity kits](https://devrel.net/dev-rel/redefining-sdks-as-software-diversity-kits) by [Sid Maestre (Xero)](https://twitter.com/sidneyallen) at [DevRelCon San Francisco 2019](https://sf2019.devrel.net/)\n- 2019-09-23 - [swagger„Åã„ÇâOpenApi Generator„ÅßSpring„ÅÆ„Ç≥„Éº„Éâ„ÇíËá™ÂãïÁîüÊàê](https://qiita.com/littleFeet/items/492df2ad68a0799a5e5e) by [@littleFeet](https://qiita.com/littleFeet) at [Qiita](https://qiita.com/)\n- 2019-09-24 - [Eine Stunde was mit Api First!](https://www.slideshare.net/JanWeinschenker/eine-stunde-was-mit-api-first) by [@janweinschenker](https://twitter.com/janweinschenker) at [Java Forum Nord](https://javaforumnord.de/)\n- 2019-10-09 - [openapi-generator „ÅßÁîüÊàê„Åó„Åü Go „ÇØ„É©„Ç§„Ç¢„É≥„Éà„Åß Bearer Ë™çË®º„Çí„Åô„Çã](https://autopp-tech.hatenablog.com/entry/2019/10/09/222039) by [Akira Tanimura](https://github.com/autopp)\n- 2019-10-10 - [Automatic Generation of REST Clients](https://www.meetup.com/fr-FR/Criteo-Labs-Tech-Talks/events/264775768/) by Thomas Peyrard, Senior Software Engineer at Criteo in [Full-Stack Tech Talks (Meetup)](https://www.meetup.com/fr-FR/Criteo-Labs-Tech-Talks/events/264775768/)\n- 2019-10-12 - [OpenApiËá™Âä®ÁîüÊàêclient](https://blog.csdn.net/wxid2798226/article/details/102527467) by [ÈÉëÊ≥ΩÊ¥≤](https://me.csdn.net/wxid2798226)\n- 2019-10-16 - [How to ship APIs faster?](https://medium.com/@accounts_76224/how-to-ship-apis-faster-cabef2f819e4) by [Simon Guilliams @ PoniCode](https://ponicode.dev)\n- 2019-10-22 - [OpenAPI + Spring Boot(Kotlin)„Åß„Éï„Ç°„Ç§„É´„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâAPI„Çí‰ΩúÊàê„Åô„Çã](https://qiita.com/boronngo/items/4b78b92526209daeaee9) by [Yuki Furukawa](https://twitter.com/yuki_furukawa5)\n- 2019-10-24 - [Microprofile OpenAPI - Code First or Design First?](https://github.com/pe-st/apidocs/blob/master/MicroProfile-OpenAPI-all-slides.pdf) by [Peter [p…õ É…ô] Steiner](https://twitter.com/pesche) at [eclipsecon Europe 2019](https://www.eclipsecon.org/europe2019/sessions/microprofile-openapi-code-first-or-design-first)\n- 2019-11-06 - [Generating API clients based on OpenAPI v3 specifications](https://98elements.com/blog/generating-api-clients-based-on-openapi-v3-specifications) by [Dominik Jastrzƒôbski @ 98elements](https://98elements.com)\n- 2019-11-06 - [OpenAPI„ÇíÂà©Áî®„Åó„Å¶Ëá™Ââç„ÅÆAPI„Çµ„Éº„Éê„Éº(Sinatra)„ÇíÁßªÊ§ç„Åó„ÅüÊôÇ„ÅÆ„É°„É¢](https://qiita.com/YasuhiroABE/items/c73920eab2d9d6e97fd9) by [Yasuhiro ABE](https://twitter.com/YasuhiroABE)\n- 2019-11-07 - [API First development with OpenAPI - You should you practise it !?](https://www.youtube.com/watch?v=F9iF3a1Z8Y8) by [Nick Van Hoof](https://www.nickvanhoof.com/) at [Devoxx Belgium 2019](https://devoxx.be/)\n- 2019-11-08 - [JHipster beyond CRUD - API-First for Enterprises by Enrico Costanzi](https://www.youtube.com/watch?v=m28JFovKQ20) by [Enrico Costanzi](https://twitter.com/enricocostanzi) at [JHipster Conf 2019 in Paris](https://jhipster-conf.github.io/)\n- 2019-11-11 - [TypeScript REST API„ÇØ„É©„Ç§„Ç¢„É≥„Éà](https://qiita.com/unhurried/items/7b74f7d3c43545dadd2b) by [@unhurried](https://qiita.com/unhurried)\n- 2019-11-11 - [One Spec to Rule them all - OpenAPI in Action](https://www.youtube.com/watch?v=MMay_nht8ec) by [Andreas Litt](https://github.com/littldr) at [code.talks 2019](https://www.codetalks.com/)\n- 2019-11-13 - [OpenAPI 3.0 Editor And Generator With A Spring Boot Example](https://simply-how.com/design-and-generate-api-code-from-openapi) at [Simply How](https://simply-how.com/)\n- 2019-11-17 - [OpenAPI Generator YouTube playlist](https://www.youtube.com/playlist?list=PLtJyHVMdzfF6fBkOUV5VDVErP23CGgHIy) at [YouTube](https://www.youtube.com)\n- 2019-11-20 - [Introduction to OpenAPI](https://noti.st/lornajane/HvDH7U/introduction-to-openapi) by [Lorna Mitchell](https://twitter.com/lornajane) at [GOTO Copenhagen 2019](https://gotocph.com/2019/)\n- 2019-11-20 - [How to Generate Angular code from OpenAPI specifications](https://dotnetthoughts.net/how-to-generate-angular-code-from-openapi-specifications/) by Anuraj\n- 2019-11-23 - [Swagger „Åß„ÅØ„Å™„ÅÑ OpenAPI Specification 3.0 „Å´„Çà„Çã API „Çµ„Éº„Éê„ÉºÈñãÁô∫](https://www.slideshare.net/techblogyahoo/swagger-openapi-specification-30-api) by [Tetsuya Morimoto](https://github.com/t2y) at [JJUG CCC 2019 Fall](https://ccc2019fall.java-users.jp/)\n- 2019-11-24 - [Accelerate Flutter development with OpenAPI and Dart code generation](https://medium.com/@irinasouthwell_220/accelerate-flutter-development-with-openapi-and-dart-code-generation-1f16f8329a6a) by [Irina Southwell](https://medium.com/@irinasouthwell_220)\n- 2019-11-25 - [openapi-generator„ÅßÊâãËªΩ„Å´„Çπ„Çø„Éñ„Çµ„Éº„Éê„Å®„ÇØ„É©„Ç§„Ç¢„É≥„Éà„ÅÆÁîüÊàê](https://qiita.com/pochopocho13/items/8db662e1934fb2b408b8) by [@pochopocho13](https://twitter.com/pochopocho13)\n- 2019-11-26 - [CordaCon 2019 Highlights: Braid Server and OpenAPI Generator for Corda Client API‚Äôs](https://blog.b9lab.com/cordacon-2019-highlights-braid-server-and-openapi-generator-for-corda-flows-api-s-d24179ccb27c) by [Adel Rustum](https://blog.b9lab.com/@adelrestom) at [B9lab](https://blog.b9lab.com/)\n- 2019-12-03 - [A Road to Less Coding: Auto-Generate APILibrary](https://www.corda.net/blog/a-road-to-less-coding-auto-generate-apilibrary/) at [Corda Blog](https://www.corda.net/blog/)\n- 2019-12-04 - [AngularÔºãNestJSÔºãOpenAPIÔºàSwaggerÔºâ„Åß„Éû„Ç§„ÇØ„É≠„Çµ„Éº„Éì„Çπ„ÇíË¶ñÈáé„Å´ÂÖ•„Çå„ÅüÁí∞Â¢É„ÇíËÄÉ„Åà„Çã](https://qiita.com/teracy55/items/0327c7a170ec772970c6) by [„Å¶„Çâ„Åó„Éº](https://twitter.com/teracy55)\n- 2019-12-05 - [Code generation on the Java VM](https://speakerdeck.com/sullis/code-generation-on-the-java-vm-2019-12-05) by [Sean Sullivan](https://speakerdeck.com/sullis)\n- 2019-12-17 - [OpenAPI Generator „Åß OAuth2 „Ç¢„ÇØ„Çª„Çπ„Éà„Éº„ÇØ„É≥Áô∫Ë°å„ÅÆ„Ç≥„Éº„Éâ„Åæ„ÅßÁîüÊàê„Åó„Å¶„Åø„Çã](https://www.techscore.com/blog/2019/12/17/openapi-generator-oauth2-accesstoken/) by [TECHSCORE](https://www.techscore.com/blog/)\n- 2019-12-23 - [Use Ada for Your Web Development](https://www.electronicdesign.com/technologies/embedded-revolution/article/21119177/use-ada-for-your-web-development) by [Stephane Carrez](https://github.com/stcarrez)\n- 2019-12-23 - [OpenAPI„ÅÆ„Çπ„Ç≠„Éº„Éû„ÇíÂàÜÂâ≤„ÉªÊßãÈÄ†Âåñ„Åó„Å¶„ÅÑ„ÅèÊñπÊ≥ï](https://gift-tech.co.jp/articles/structured-openapi-schema) by [Â∞èÈ£ØÂ°öÈÅî‰πü](https://github.com/t2h5) at [GiFT, Inc](https://gift-tech.co.jp/)\n- 2020-01-17 - [OpenAPI demo for Pulp 3.0 GA](https://www.youtube.com/watch?v=mFBP-M0ZPfw&t=178s) by [Pulp](https://www.youtube.com/channel/UCI43Ffs4VPDv7awXvvBJfRQ) at [Youtube](https://www.youtube.com/)\n- 2020-01-19 - [Why document a REST API as code?](https://dev.to/rolfstreefkerk/why-document-a-rest-api-as-code-5e7p) by [Rolf Streefkerk](https://github.com/rpstreef) at [DEV Community](https://dev.to)\n- 2020-01-28 - [Get Your Serverless Swagger Back with OpenAPI](https://dev.to/matttyler/get-your-serverless-swagger-back-with-openapi-48gc) by [Matt Tyler](https://dev.to/matttyler)\n- 2020-01-30 - [OpenAPI Generator„Å∏„ÅÆ„Ç≥„É≥„Éà„É™„Éì„É•„Éº„Éà](https://www.yutaka0m.work/entry/2020/01/30/163905) by [yutaka0m](https://github.com/yutaka0m)\n- 2020-02-01 - [Using OpenAPI to Maximise Your Pulp 3 Experience](https://fosdem.org/2020/schedule/event/openapi/) by [Dennis Kliban](https://github.com/dkliban/) at [FOSDEM](https://fosdem.org/)\n- 2020-02-07 - [Why you should use OpenAPI for your API design](https://www.youtube.com/watch?v=zhb7vUApLW8&t=927s) by [Nick Van Hoof](https://apiconference.net/speaker/nick-van-hoof/) at [API Conference](https://apiconference.net/)\n- 2020-02-17 - [Rubynetes: using OpenAPI to validate Kubernetes configs](https://www.brightbox.com/blog/2020/02/17/using-openapi-to-validate-kubernetes-configs/) by Neil Wilson at [Brightbox](https://www.brightbox.com/)\n- 2020-02-20 - [Building SDKs for the future](https://devblog.xero.com/building-sdks-for-the-future-b79ff726dfd6) by [Sid Maestre (Xero)](https://twitter.com/sidneyallen)\n- 2020-02-27 - [NuxtÂà©Áî®„Éó„É≠„ÉÄ„ÇØ„Éà„ÅßIE11„Å®‰ª≤ËâØ„Åè„Åô„Çã„Åü„ÇÅ„ÅÆE2E](https://tech.medpeer.co.jp/entry/e2e-ie11) at [Medpeer.co.jp Tech Blog](https://tech.medpeer.co.jp/)\n- 2020-02-29 - [Providing Support to IoT Devices Deployed in Disconnected Rural Environment (Conference paper)](https://link.springer.com/chapter/10.1007/978-3-030-41494-8_14) by Sergio Laso, Daniel Flores-Mart√≠n, Juan Luis HerreraCarlos, CanalJuan Manuel, MurilloJavier Berrocal\n- 2020-03-02 - [How To Generate Angular & Spring Code From OpenAPI Specification](https://www.mokkapps.de/blog/how-to-generate-angular-and-spring-code-from-open-api-specification/) by [Michael Hoffmann](https://www.mokkapps.de/)\n- 2020-03-02 - [OpenAPI Generator + TypeScript „ÅßÂßã„ÇÅ„ÇãËá™ÂãïÁîüÊàê„ÅÆÂûã„Å´ÂÆà„Çâ„Çå„ÅüË±ä„Åã„Å™„ÇØ„É©„Ç§„Ç¢„É≥„ÉàÁîüÊ¥ª](https://gift-tech.co.jp/articles/openapi-generator-typescript) by [‰∫îÁôæËîµ Áõ¥Ê®π](https://gift-tech.co.jp/members/naokiioroi) at [GiFTÊ†™Âºè‰ºöÁ§æ](https://gift-tech.co.jp/)\n- 2020-03-10 - [OpenAPI Generator Meetup #1](https://speakerdeck.com/akihito_nakano/openapi-generator-meetup-number-1) by [‰∏≠ÈáéÊöÅ‰∫∫](https://github.com/ackintosh) at [OpenAPI Generator Meetup #1](https://openapi-generator-meetup.connpass.com/event/168187/)\n- 2020-03-15 - [Load Testing Your API with Swagger/OpenAPI and k6](https://k6.io/blog/load-testing-your-api-with-swagger-openapi-and-k6)\n- 2020-04-13 - [‰ø∫ÁöÑ„ÄêOAS„Äë„Å®„ÅÆÂêë„ÅçÂêà„ÅÑÊñπ (ÁàÜÈÄü„ÅßOpenAPI„Å®ÂèãÈÅî„Å´„Å™„Çç„ÅÜ)](https://tech-blog.optim.co.jp/entry/2020/04/13/100000) in [OPTim Blog](https://tech-blog.optim.co.jp/)\n- 2020-04-22 - [Introduction to OpenAPI Generator](https://nordicapis.com/introduction-to-openapi-generator/) by [Kristopher Sandoval](https://nordicapis.com/author/sandovaleffect/) in [Nordic APIs](https://nordicapis.com/)\n- 2020-04-27 - [How we use Open API v3 specification to auto-generate API documentation, code-snippets and clients](https://medium.com/pdf-generator-api/how-we-use-open-api-v3-specification-to-auto-generate-api-documentation-code-snippets-and-clients-d127a3cea784) by [Tanel T√§hep√µld](https://medium.com/@tanel.tahepold)\n- 2020-05-09 - [OpenAPI„Åß„ÅäÊâãËªΩ„Å´„É¢„ÉÉ„ÇØAPI„Çµ„Éº„Éê„Éº„ÇíÂãï„Åã„Åô](https://qiita.com/kasa_le/items/97ca6a8dd4605695c25c) by [Sachie Kamba](https://qiita.com/kasa_le)\n- 2020-05-18 - [Spring Boot REST with OpenAPI 3](https://dev.to/alfonzjanfrithz/spring-boot-rest-with-openapi-3-59jm) by [Alfonz Jan Frithz](https://dev.to/alfonzjanfrithz)\n- 2020-05-19 - [Dead Simple APIs with Open API](https://www.youtube.com/watch?v=sIaXmR6xRAw) by [Chris Tankersley](https://github.com/dragonmantank) at [Nexmo](https://developer.nexmo.com/)\n- 2020-05-22 - [TypeScript REST API Client](https://dev.to/unhurried/typescript-rest-api-client-4in3) by [\"unhurried\"](https://dev.to/unhurried)\n- 2020-05-28 - [„Äê‰ΩøÁî® lotify + Swagger Âª∫ÁΩÆÂèØÂÖ±Áî®ÁöÑ LINE Notify bot„Äë - #NiJia @ Chatbot Developer Taiwan Á¨¨ #19 Â∞èËÅö](https://www.youtube.com/watch?v=agYVz6dzh1I) by [Chatbot Developer Taiwan](https://www.youtube.com/channel/UCxeYUyZNnHmpX23YNF-ewvw)\n- 2020-05-28 - [Building APIs with Laravel using OpenAPI](https://www.youtube.com/watch?v=xexLvQqAhiA) by [Chris Tankersley](https://github.com/dragonmantank) at [Laracon EU](https://laracon.eu/)\n- 2020-06-12 - [Interoperability by construction: code generation for Arrowhead Clients](https://ieeexplore.ieee.org/document/9274746) by Michele Albano, Brian Nielsen at [2020 IEEE Conference on Industrial Cyberphysical Systems (ICPS)](https://ieeexplore.ieee.org/xpl/conhome/9274544/proceeding)\n- 2020-06-23 - [Êñ∞Ë¶è„Çµ„Éº„Éê„Éº„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„Å´TypeScript„ÇíÊé°Áî®„Åó„Å¶„Åø„Åü](https://www.cam-inc.co.jp/news/20200623) at [CAM Tech Blog](https://www.cam-inc.co.jp/news/tech-blog/)\n- 2020-06-29 - [Artifact Abstract: Deployment of APIs on Android Mobile Devices and Microcontrollers](https://ieeexplore.ieee.org/document/9127353) by [Sergio Laso ; Marino Linaje ; Jose Garcia-Alonso ; Juan M. Murillo ; Javier Berrocal](https://ieeexplore.ieee.org/document/9127353/authors#authors) at [2020 IEEE International Conference on Pervasive Computing and Communications (PerCom)](https://ieeexplore.ieee.org/xpl/conhome/9125449/proceeding)\n- 2020-07-07 - [5 Best API Documentation Tools](https://blog.dreamfactory.com/5-best-api-documentation-tools/) by Susanna Bouse at [DreamFactory Blog](https://blog.dreamfactory.com/)\n- 2020-07-12 - [Open API 3.0„ÅÆÂÆöÁæ©„Åã„Çâgolang„ÅÆ„Çµ„Éº„Éê„Ç≥„Éº„Éâ„ÅÆ„Çπ„Ç±„É´„Éà„É≥„Çí‰ΩúÊàê„Åô„Çã](https://qiita.com/professor/items/4cbd04ec084d13057bc2) by [@professor (Qiita Blog)](https://qiita.com/professor)\n- 2020-07-20 - [Datadog API client libraries now available for Java and Go](https://www.datadoghq.com/blog/java-go-libraries/) by Jordan Obey at [Datadog Blog](https://www.datadoghq.com/blog)\n- 2020-07-23 - [Generate Client SDK for .NET Core using Open Api](https://dev.to/no0law1/generate-client-sdk-for-net-core-using-open-api-2dgh) by [Nuno Reis](https://dev.to/no0law1)\n- 2020-07-26 - [Dart„ÅÆhttp_interceptor„É©„Ç§„Éñ„É©„É™„Çí‰Ωø„ÅÜ„Å®ÈÖçÂàó„ÅÆ„ÇØ„Ç®„É™„Éë„É©„É°„Éº„Çø„ÅåÊ∂à„Åà„Å¶„Åó„Åæ„ÅÜ‰ª∂„ÅÆÂøúÊÄ•Âá¶ÁΩÆ](https://qiita.com/gyamoto/items/eeeff81b6770487319ed) by [@gyamoto](https://qiita.com/gyamoto)\n- 2020-08-01 - [Generate Angular ReactiveForms from Swagger/OpenAPI](https://dev.to/martinmcwhorter/generate-angular-reactiveforms-from-swagger-openapi-35h9) by [Martin McWhorter](https://dev.to/martinmcwhorter)\n- 2020-08-03 - [Criando Bibliotecas para APIs RESTful com OpenAPI, Swagger Editor e OpenAPI Generator](https://medium.com/@everisBrasil/criando-bibliotecas-para-apis-restful-com-openapi-swagger-editor-e-openapi-generator-75349a6420fd) by [everis Brasil (an NTT DATA Company)](https://medium.com/@everisBrasil)\n- 2020-08-19 - [„Éû„Ç§„ÇØ„É≠„Çµ„Éº„Éì„Çπ„ÇíÈÄ£Êê∫„Åó„Å¶„Åø„Çà„ÅÜ](https://thinkit.co.jp/article/17704) by [Â≤°‰∫ï Ë£ïÁü¢(„Åä„Åã„ÅÑ „ÇÜ„ÅÜ„ÇÑ)](https://thinkit.co.jp/author/17588), [Ê≥â Âãù(„ÅÑ„Åö„Åø „Åæ„Åï„Çã)](https://thinkit.co.jp/author/17705) at [Think ITÔºà„Ç∑„É≥„ÇØ„Ç§„ÉÉ„ÉàÔºâ](https://thinkit.co.jp/)\n- 2020-08-25 - [OpenAPI Generator „Å® TypeScript „ÅßÂûãÂÆâÂÖ®„Å´„Éï„É≠„É≥„Éà„Ç®„É≥„ÉâÈñãÁô∫„Çí„Åó„Å¶„ÅÑ„ÇãË©±](https://tech.smarthr.jp/entry/2020/08/25/135631) at [SmartHR Tech Blog](https://tech.smarthr.jp/)\n- 2020-09-10 - [Introduction to OpenAPI with Instana](https://www.instana.com/blog/introduction-to-openapi-with-instana/) by [Cedric Ziel](https://www.instana.com/blog/author/cedricziel/) at [Instana Blog](https://www.instana.com/blog/)\n- 2020-09-17 - [Generate PowerShellSDK using openapi-generator](https://medium.com/@ghufz.learn/generate-powershellsdk-using-openapi-generator-33b700891e33) by [Ghufran Zahidi](https://medium.com/@ghufz.learn)\n- 2020-09-24 - [How to automate API code generation (OpenAPI/Swagger) and boost productivity - Tutorial with React Native featuring TypeScript](https://medium.com/@sceleski/how-to-automate-api-code-generation-openapi-swagger-and-boost-productivity-1176a0056d8a) by [Sanjin Celeski](https://medium.com/@sceleski)\n- 2020-09-25 - [Generate OpenAPI Angular Client](https://medium.com/@pguso/generate-openapi-angular-client-8c9288e8bbd4) by [Patric](https://medium.com/@pguso)\n- 2020-10-24 - [Working with Microsoft Identity - React Native Client](https://www.josephguadagno.net/2020/10/24/working-with-microsoft-identity-react-native-client) by [Joseph Guadagno](https://www.josephguadagno.net/)\n- 2020-10-31 - [[B2] OpenAPI SpecificationÏúºÎ°ú ÌÉÄÏûÖ-ÏÑ∏Ïù¥ÌîÑÌïòÍ≤å API Í∞úÎ∞úÌïòÍ∏∞: Ìù¨ÎßùÌé∏ VS Ï†àÎßùÌé∏](https://www.youtube.com/watch?v=J4JHLESAiFk) by ÏµúÌÉúÍ±¥ at [FEConf 2020](https://2020.feconf.kr/)\n- 2020-11-05 - [Automated REST-Api Code Generation: Wie IT-Systeme miteinander sprechen](https://www.massiveart.com/blog/automated-rest-api-code-generation-wie-it-systeme-miteinander-sprechen) by Stefan Rottensteiner at [MASSIVE ART Blog](https://www.massiveart.com/blog)\n- 2020-12-01 - [OpenAPI Generator„ÅßGo„ÅÆAPI„Çµ„Éº„Éê„Éº/„ÇØ„É©„Ç§„Ç¢„É≥„Éà„Ç≥„Éº„Éâ„ÇíËá™ÂãïÁîüÊàê„Åô„Çã](https://qiita.com/saki-engineering/items/b20d8b6074c4da9664a5) by [@saki-engineering](https://qiita.com/saki-engineering)\n- 2020-12-04 - [Scaling the Test Coverage of OpenAPI Generator for 30+ Programming Languages](https://www.youtube.com/watch?v=7Lke9dHRqT0) by [William Cheng](https://github.com/wing328) at [Open Source Summit Japan + Automotive Linux Summit 2020](https://events.linuxfoundation.org/archive/2020/open-source-summit-japan/) ([Slides](https://speakerdeck.com/wing328/scaling-the-test-coverage-of-openapi-generator-for-30-plus-programming-languages))\n- 2020-12-09 - [„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Å´OpenAPI Generator„ÅßËá™ÂãïÁîüÊàê„Åï„Çå„ÅüÂûã‰ªò„ÅçAPI Client„ÇíÂ∞éÂÖ•„Åó„ÅüË©±](https://qiita.com/yoshifujiT/items/905c18700ede23f40840) by [@yoshifujiT](https://github.com/yoshifujiT)\n- 2020-12-15 - [Next.js + NestJS + GraphQL„ÅßÂ§âÂåñ„Å´ËøΩÂæì„Åô„Çã„Éï„É≠„É≥„Éà„Ç®„É≥„Éâ„Å∏ „Äú „Ç∑„Éß„ÉÉ„Éî„É≥„Ç∞„ÇØ„Éº„Éù„É≥„ÅÆ‰∫ã‰æãÁ¥π‰ªã](https://techblog.yahoo.co.jp/entry/2020121530052952/) by [Â∞èÂÄâ Èô∏](https://github.com/ogugu9) at [Yahoo! JAPAN Tech Blog](https://techblog.yahoo.co.jp/)\n- 2021-01-08 - [Hello, New API ‚Äì Part 1](https://www.nginx.com/blog/hello-new-api-part-1/) by [Jeremy Schulman](https://www.nginx.com/people/jeremy-schulman/) at [Major League Baseball](https://www.mlb.com)\n- 2021-01-18 - [„Äå„Ç¢„Éó„É™ÈñãÁô∫„ÅÇ„Çã„ÅÇ„Çã„Äç„ÇíÁñë„ÅÜ„Åì„Å®„Åã„ÇâÂßã„Åæ„Å£„Åü„ÄÅAPI Client„Ç≥„Éº„Éâ„ÅÆËá™ÂãïÁîüÊàê„Äê„Éá„Éñ„Çπ„Éà2020„Äë](https://codezine.jp/article/detail/13406?p=2) by [CodeZineÁ∑®ÈõÜÈÉ®](https://codezine.jp/author/1)\n- 2021-02-05 - [REST-API-Roundtrip with SpringDoc and OpenAPI Generator](https://blog.viadee.de/en/rest-api-roundtrip) by [Benjamin Klatt](https://twitter.com/benklatt) at [viadee](https://www.viadee.de/en/)\n- 2021-02-17 - [REST-API-Roundtrip with SpringDoc and OpenAPI Generator](https://medium.com/nerd-for-tech/rest-api-roundtrip-with-springdoc-and-openapi-generator-30bd27ccf698) by [cloud @viadee](https://cloud-viadee.medium.com/)\n- 2021-03-08 - [OpenAPI Generator Â∑•ÂÖ∑ÁöÑË∫∫ÂùëÂ∞ùËØï](https://blog.csdn.net/u013019701/article/details/114531975) by [Áã¨ÂÆ∂Èõ®Â§©](https://blog.csdn.net/u013019701) at [CSDNÂÆòÊñπÂçöÂÆ¢](https://blog.csdn.net/)\n- 2021-03-16 - [Â¶Ç‰ΩïÂü∫‰∫é Swagger ‰ΩøÁî® OpenAPI Generator ÁîüÊàê JMeter ËÑöÊú¨Ôºü](https://cloud.tencent.com/developer/article/1802704) by [È´òÊ•ºZee](https://cloud.tencent.com/developer/user/5836255) at [ËÖæËÆØ‰∫ë‰∏ìÊ†è](https://cloud.tencent.com/developer/column)\n- 2021-03-24 - [openapi-generator-cli „Å´„Çà„Çã TypeScript ÂûãÂÆöÁæ©](https://zenn.dev/takepepe/articles/openapi-generator-cli-ts) by [Takefumi Yoshii](https://zenn.dev/takepepe)\n- 2021-03-28 - [Trying out NestJS part 4: Generate Typescript clients from OpenAPI documents](https://dev.to/arnaudcortisse/trying-out-nestjs-part-4-generate-typescript-clients-from-openapi-documents-28mk) by [Arnaud Cortisse](https://dev.to/arnaudcortisse)\n- 2021-03-31 - [Open API Server Implementation Using OpenAPI Generator](https://www.baeldung.com/java-openapi-generator-server) at [Baeldung](https://www.baeldung.com/)\n- 2021-03-31 - [‰ΩøÁî®OpenAPI GeneratorÂØ¶ÁèæOpen API Server](https://www.1ju.org/article/java-openapi-generator-server) at [ÂÑÑËÅöÁ∂≤](https://www.1ju.org/)\n- 2021-04-19 - [Introducing Twilio‚Äôs OpenAPI Specification Beta](https://www.twilio.com/blog/introducing-twilio-open-api-specification-beta) by [GARETH PAUL JONES](https://www.twilio.com/blog/author/gpj) at [Twilio Blog](https://www.twilio.com/blog)\n- 2021-04-22 - [Leveraging OpenApi strengths in a Micro-Service environment](https://medium.com/unibuddy-technology-blog/leveraging-openapi-strengths-in-a-micro-service-environment-3d7f9e7c26ff) by Nicolas Jellab at [Unibuddy Technology Blog](https://medium.com/unibuddy-technology-blog)\n- 2021-04-27 - [From zero to publishing PowerShell API clients in PowerShell Gallery within minutes](https://speakerdeck.com/wing328/from-zero-to-publishing-powershell-api-clients-in-powershell-gallery-within-minutes) by [William Cheng](https://github.com/wing328) at [PowerShell + DevOps Global Summit 2021](https://events.devopscollective.org/event/powershell-devops-global-summit-2021/)\n- 2021-05-31 - [Flutter„ÅßOpen Api Generator(Swagger)„Çí‰Ωø„ÅÜ](https://aakira.app/blog/2021/05/flutter-open-api/) by [AAkira](https://twitter.com/_a_akira)\n- 2021-06-22 - [Rest API Documentation and Client Generation With OpenAPI](https://dzone.com/articles/rest-api-documentation-and-client-generation-with) by [Prasanth Gullapalli](https://dzone.com/users/1011797/prasanthnath.g@gmail.com.html)\n- 2021-07-16 - [ÈäÄË°å‰∫ãÊ•≠„ÅÆ„Çµ„Éº„Éê„Éº„Çµ„Ç§„ÉâÈñãÁô∫„Å´„Å§„ÅÑ„Å¶ / LINE ‰∫¨ÈÉΩÈñãÁô∫ÂÆ§ „Ç®„É≥„Ç∏„Éã„Ç¢Êé°Áî®Ë™¨Êòé‰ºö](https://www.youtube.com/watch?v=YrrKQHxLPpQ) by ÈáéÁî∞Ë™†‰∫∫, Robert Mitchell\n- 2021-07-19 - [OpenAPI code generation with kotlin](https://sylhare.github.io/2021/07/19/Openapi-swagger-codegen-with-kotlin.html) by [sylhare](https://github.com/sylhare)\n- 2021-07-29 - [How To Rewrite a Huge Codebase](https://dzone.com/articles/how-to-rewrite-a-huge-code-base) by [Curtis Poe](https://dzone.com/users/4565446/publiusovidius.html)\n- 2021-08-21 - [Generating Client APIs using Swagger Part 1](https://medium.com/@flowsquad/generating-client-apis-using-swagger-part-1-2d46f13f5e92) by [FlowSquad.io](https://medium.com/@flowsquad)\n- 2021-09-11 - [Invoking AWS ParallelCluster API](https://docs.aws.amazon.com/parallelcluster/latest/ug/api-reference-v3.html) at [AWS ParallelCluster API official documentation](https://docs.aws.amazon.com/parallelcluster/latest/ug/api-reference-v3.html)\n- 2021-09-20 - [OpenAPI Generator - The Babel Fish of the API World](https://www.youtube.com/watch?v=s2zMtwd5klg) by [Cliffano Subagio (Principal Engineer at Shine Solutions)](https://github.com/cliffano) at [Apidays LIVE Australia 2021](https://www.apidays.global/australia2021/)\n- 2021-10-02 - [How to Write Fewer Lines of Code with the OpenAPI Generator](https://hackernoon.com/how-to-write-fewer-lines-of-code-with-the-openapi-generator) by [Mikhail Alfa](https://hackernoon.com/u/alphamikle)\n- 2021-10-12 - [OpenAPI Generator : 4000 √©toiles sur GitHub et des spaghettis](https://www.youtube.com/watch?v=9hEsNBSqTFk) by [J√©r√©mie Bresson](https://github.com/jmini) at [Devoxx FR 2021](https://cfp.devoxx.fr/2021/speaker/jeremie_bresson)\n- 2021-10-17 - [Generate a TypeScript HTTP Client From An OpenAPI Spec In DotNET 5](https://richardwillis.info/blog/generate-a-type-script-http-client-from-an-open-api-spec-in-dot-net-5) by [Richard Willis](https://github.com/badsyntax)\n- 2021-11-06 - [„Çπ„Çø„Éº„Éà„Ç¢„ÉÉ„Éó„ÅÆÈñãÁô∫„ÅßÊÑèË≠ò„Åó„Åü„Åì„Å®](https://zenn.dev/woo_noo/articles/5cb09f8e2899ae782ad1) by [woo-noo](https://zenn.dev/woo_noo)\n- 2021-11-09 - [Effective Software Development using OpenAPI Generator](https://apexlabs.ai/post/effective-software-development-using-openapi-generator) by Ajil Oomme\n- 2021-12-07 - [An Introduction to OpenAPI](https://betterprogramming.pub/4-use-cases-of-openapi-which-are-good-to-know-1a041f4ad71e) by [Na'aman Hirschfeld](https://naamanhirschfeld.medium.com/)\n- 2022-01-02 - [Towards a secure API client generator for IoT devices](https://arxiv.org/abs/2201.00270) by Anders Aaen Springborg, Martin Kaldahl Andersen, Kaare Holland Hattel, Michele Albano\n- 2022-02-02 - [Use OpenApi generator to share your models between Flutter and your backend](https://www.youtube.com/watch?v=kPW7ccu9Yvk) by [Guillaume Bernos](https://feb2022.fluttervikings.com/speakers/guillaume_bernos) at [Flutter Vikings Conference 2022 (Hybrid)](https://feb2022.fluttervikings.com/)\n- 2022-03-15 - [OpenAPI Spec„Åß„Éè„Ç§„Éï„É≥Âå∫Âàá„Çä„ÅÆEnumÂÄ§„ÇíOpenAPI Generator„ÅßÂá∫Âäõ„Åô„Çã„Å®„ÄÅ„Éè„Ç§„Éï„É≥Âå∫Âàá„Çä„ÅÆ„Åæ„ÅæÂá∫Âäõ„Åï„Çå„Çã](https://qiita.com/yuji38kwmt/items/824d74d4889055ab37d8) by [yuji38kwmt](https://qiita.com/yuji38kwmt)\n- 2022-04-01 - [OpenAPI Generator„ÅÆ„Ç≥„Éº„ÉâÁîüÊàê„Å®Spring Framework„ÅÆ„Ç´„Çπ„Çø„É†„Éá„Éº„Çø„Éê„Ç§„É≥„Éá„Ç£„É≥„Ç∞„ÇíÂÖ±Â≠ò„Åï„Åõ„Çã](https://techblog.zozo.com/entry/coexistence-of-openapi-and-spring) in [ZOZO Tech Blog](https://techblog.zozo.com/)\n- 2022-04-06 - [Effective Software Development using OpenAPI Generator](https://apexlabs.ai/post/openapi-generator) by Ajil Oommen (Senior Flutter Developer)\n- 2022-05-13 - [A Path From an API To Client Libraries](https://www.youtube.com/watch?v=XC8oVn_efTw) by [Filip Srnec](https://www.devoxx.co.uk/talk/?id=11211) at Infobip\n- 2022-06-01 - [API First, using OpenAPI and Spring Boot](https://medium.com/xgeeks/api-first-using-openapi-and-spring-boot-2602c04bb0d3) by [Micael Estr√°zulas Vianna](https://estrazulas.medium.com/)\n- 2022-06-10 - [Autogenerating Clients with FastAPI and Github Actions](https://www.propelauth.com/post/autogenerating-clients-with-fastapi-and-github-actions) by [Andrew Israel](https://www.propelauth.com/author/andrew)\n- 2022-06-12 - [Mustache templates with OpenAPI specs](https://medium.com/geekculture/mustache-templates-with-openapi-specs-f24711c67dec) by [Beppe Catanese](https://github.com/gcatanese)\n- 2022-07-01 - [Generate API contract using OpenAPI Generator Maven plugin](https://huongdanjava.com/generate-api-contract-using-openapi-generator-maven-plugin.html) by [Khanh Nguyen](https://huongdanjava.com/)\n- 2022-07-22 - [‰ΩøÁî®OpenAPI Generator Maven pluginÂºÄÂèëapi‰ºòÂÖàÁöÑjavaÂÆ¢Êà∑Á´ØÂíåÊúçÂä°Á´Ø‰ª£Á†Å](https://blog.roccoshi.top/2022/java/openapi-generator%E7%9A%84%E4%BD%BF%E7%94%A8/) by [Lincest](https://github.com/Lincest)\n- 2022-08-01 - [Tutorial: Etsy Open API v3 (ruby)](https://blog.tjoyal.dev/etsy-open-api-v3/) by [Thierry Joyal](https://github.com/tjoyal)\n- 2022-09-03 - [OpenAPI Generator For Go Web Development](https://blog.kevinhu.me/2022/09/03/03-openapi-generator/) by [Kevin Hu](https://twitter.com/Oldgunix)\n- 2022-10-01 - [OpenAPI Generator„Çí„Ç´„Çπ„Çø„Éû„Ç§„Ç∫„Åó„Åü„Ç≥„Éº„Éâ„ÇíÁîüÊàê„Åô„ÇãÔºàSwagger Codegen„Å®„Åª„ÅºÂêå„ÅòÔºâ](https://nainaistar.hatenablog.com/entry/2022/10/03/120000) by [„Åç„Çä‰∏∏](https://twitter.com/nainaistar)\n- 2022-10-21 - [KotlinÔºàSpring BootÔºâ„ÅÆ API „Çí OpenAPI Generator „ÅßËá™ÂãïÁîüÊàê](https://zenn.dev/msksgm/articles/20221021-kotlin-spring-openapi-generator) by [msksgm](https://zenn.dev/msksgm)\n- 2022-10-26 - [Quarkus Insights #106: Quarkiverse Extension Spotlight: OpenApi Generator](https://www.youtube.com/watch?v=_s_if69t2iQ) by [Quarkusio](https://www.youtube.com/c/Quarkusio)\n- 2022-11-28 - [The REST API implementation flow](https://tmsvr.com/openapi-code-generation-for-rest-apis/) by [Imre T√∂m√∂sv√°ri](https://tmsvr.com/author/imre/)\n- 2022-12-13 - [API-First with Spring WebFlux and OpenAPI Generator](https://boottechnologies-ci.medium.com/api-first-with-spring-webflux-and-openapi-generator-38b7804c4ed4) by [Eric Anicet](https://boottechnologies-ci.medium.com/)\n- 2023-01-06 - [Major Improvements with Helidon and OpenAPI](https://medium.com/helidon/major-improvements-with-helidon-and-openapi-f76a0951508e) by [Tim Quinn](https://medium.com/@tquinno600)\n- 2023-02-02 - [Replacing Postman with the Jetbrains HTTP Client](https://lengrand.fr/replacing-postman-in-seconds-with-the-jetbrains-http-client/) by [julien Lengrand-Lambert](https://github.com/jlengrand)\n- 2023-03-15 - [OpenAPI Generator„Å´ÈÅ©„Åó„ÅüOpenAPI„ÅÆÊõ∏„ÅçÊñπ](https://techblog.zozo.com/entry/how-to-write-openapi-for-openapi-generator) by [ZOZO Tech Blog](https://techblog.zozo.com/)\n- 2023-03-19 - [EXOGEM: Extending OpenAPI Generator for Monitoring of RESTful APIs](https://link.springer.com/chapter/10.1007/978-3-031-26507-5_10) by Daniel Friis Holtebo, Jannik Lucas Sommer, Magnus M√∏lgaard Lund, Alessandro Tibo, Junior Dongo & Michele Albano at \"ICSOC 2022: Service-Oriented Computing ‚Äì ICSOC 2022 Workshops\"\n- 2023-03-28 - [API-First Design with OpenAPI Generator](https://www.linkedin.com/pulse/api-first-design-openapi-generator-jonathan-manera/) by [Jonathan Manera](https://www.linkedin.com/in/manerajona/)\n- 2023-03-28 - [„Éè„É≥„Ç∫„Ç™„É≥„ÅßÂ≠¶„Å∂„Çµ„Éº„Éê„Éº„Çµ„Ç§„Éâ KotlinÔºàSpring Boot&Arrow&OpenAPI GeneratorÔºâv1.0.1](https://zenn.dev/msksgm/books/implementing-server-side-kotlin-development) by [msk](https://zenn.dev/msksgm)\n- 2023-04-01 - [OpenAPI Client Code Generation](https://testingboss.com/blog/openapi-client-generation/) by Kwo Ding\n- 2023-04-27 - [Create an Angular Client using OpenAPI Specifications](Create an Angular Client using OpenAPI Specifications) by [Patric](https://pguso.medium.com/)\n- 2023-05-16 - [Adyen for Java developers](https://www.adyen.com/blog/adyen-java-library) by [Beppe Catanese, Developer Advocate, Adyen](https://github.com/gcatanese)\n- 2023-05-18 - [Â¶Ç‰ΩïÂü∫‰∫é Swagger ‰ΩøÁî® OpenAPI Generator ÁîüÊàê JMeter ËÑöÊú¨Ôºü](https://blog.51cto.com/u_15181572/6294974) by [È´òÊ•ºÔºàZee)](https://blog.51cto.com/u_15181572)\n- 2023-06-28 - [Generate API contract using OpenAPI Generator Maven plugin](https://huongdanjava.com/generate-api-contract-using-openapi-generator-maven-plugin.html) by [Khanh Nguyen](https://huongdanjava.com/)\n- 2023-06-30 - [Generate Client SDKs with OpenApi Generator in Springboot](https://medium.com/@ramavathvinayak/generate-client-sdks-with-openapi-generator-in-springboot-f9f012e73c0b) by [Vinayak Ramavath](https://medium.com/@ramavathvinayak)\n- 2023-12-10 - [Unity„ÅßOpenAPI Generator„Çí‰Ωø„ÅÜ](https://www.youtube.com/watch?v=CbNwKVV5LRM) by [Soup Tori](https://www.youtube.com/@souptori8417)\n- 2024-01-24 - [Comment g√©n√©rer des stubs wiremock avec openapi generator](https://www.youtube.com/watch?v=0jhONfBrcKw) by [Alexis Couvreur](https://github.com/acouvreur)\n- 2024-03-04 - [Generating TypeScript Types with OpenAPI for REST API Consumption](https://www.pullrequest.com/blog/generating-typescript-types-with-openapi-for-rest-api-consumption/) by [PullRequest](https://www.pullrequest.com/)\n- 2024-03-07 - [Fully typed Web Apps with OpenAPI (Part 1)](https://medium.com/@gfox1984/fully-typed-web-apps-with-openapi-part-1-595d55766670) by [Guillaume Renard](https://medium.com/@gfox1984)\n- 2024-03-08 - [Laravel OpenAPI„Å´„Çà„Çã \"Ëæõ„Åè„Å™„ÅÑ\" „Çπ„Ç≠„Éº„ÉûÈßÜÂãïÈñãÁô∫](https://fortee.jp/phperkaigi-2024/proposal/9e2e6c38-d078-4efa-99b4-83ebf9033b34) by [KentarouTakeda](https://twitter.com/KentarouTakeda)\n- 2024-04-04 - [Working with OpenAPI using Rust](https://www.shuttle.dev/blog/2024/04/04/using-openapi-rust) by [Joshua Mo](https://twitter.com/joshmo_dev)\n- 2024-04-08 - [Implement API first strategy with OpenAPI generator plugin](https://medium.com/javarevisited/implement-api-first-strategy-with-openapi-generator-plugin-e4bbe7f0d778) by [Rui Zhou](https://medium.com/@wirelesser)\n- 2024-05-06 - [OpenAPI Generator Custom Templates](https://www.javacodegeeks.com/openapi-generator-custom-templates.html) by [Mary Zheng](https://www.javacodegeeks.com/author/mary-zheng)\n- 2025-02-09 - [Custom validation with OpenApiGenerator and Spring Boot 3](https://medium.com/@jugurtha.aitoufella/custom-validation-with-openapigenerator-and-spring-boot-3-34a656e815c8) by [Jugurtha Aitoufella](https://medium.com/@jugurtha.aitoufella)\n- 2025-02-20 - [Optimizing API Integration in a Large React Application Using OpenAPI Generator](https://www.youtube.com/watch?v=-B33pQnGQUI) by Stefano Marzo\n\n\n## [6 - About Us](#table-of-contents)\n\nWhat's the design philosophy or principle behind OpenAPI Generator?\n\nWe focus on developer experience. The generators should produce code, config, documentation, and more that are easily understandable and consumable by users. We focused on simple use cases to start with (bottom-up approach). Since then the project and the community have grown a lot: 600k weekly downloads via NPM CLI wrapper, 30M downloads via openapi-generator-cli docker image just to highlight a few. We've gradually supported more features (e.g. oneOf, anyOf introduced in OpenAPI 3.0) in various generators and we will continue this approach to deliver something based on our understanding of user demand and what they want, and continue to add support of new features introduced in OpenAPI specification (such as v3.1 and future versions of the OpenAPI specification).\n\n### [6.1 - OpenAPI Generator Core Team](#table-of-contents)\n\nOpenAPI Generator core team members are contributors who have been making significant contributions (review issues, fix bugs, make enhancements, etc) to the project on a regular basis.\n\n#### Core Team Members\n* [@wing328](https://github.com/wing328) (2015/07) [:heart:](https://www.patreon.com/wing328)\n* [@jimschubert](https://github.com/jimschubert) (2016/05) [:heart:](https://www.patreon.com/jimschubert)\n* [@cbornet](https://github.com/cbornet) (2016/05)\n* [@jmini](https://github.com/jmini) (2018/04)  [:heart:](https://www.patreon.com/jmini)\n* [@etherealjoy](https://github.com/etherealjoy) (2019/06)\n\n:heart: = Link to support the contributor directly\n\n#### Template Creator\n\n**NOTE**: Embedded templates are only supported in _Mustache_ format. Support for all other formats is experimental and subject to change at any time.\n\nHere is a list of template creators:\n * API Clients:\n   * Ada: @stcarrez\n   * Apex: @asnelling\n   * Bash: @bkryza\n   * C: @PowerOfCreation @zhemant [:heart:](https://www.patreon.com/zhemant)\n   * C++ Oat++: @Kraust\n   * C++ REST: @Danielku15\n   * C++ Tiny: @AndersSpringborg @kaareHH @michelealbano @mkakbas\n   * C++ UE4: @Kahncode\n   * C# (.NET 2.0): @who\n   * C# (.NET Standard 1.3 ): @Gronsak\n   * C# (.NET 4.5 refactored): @jimschubert [:heart:](https://www.patreon.com/jimschubert)\n   * C# (GenericHost): @devhl-labs\n   * C# (HttpClient): @Blackclaws\n   * Clojure: @xhh\n   * Crystal: @wing328\n   * Dart: @yissachar\n   * Dart (refactor): @joernahrens\n   * Dart 2: @swipesight\n   * Dart (Jaguar): @jaumard\n   * Dart (Dio): @josh-burton\n   * Elixir: @niku\n   * Elm: @eriktim\n   * Eiffel: @jvelilla\n   * Erlang: @tsloughter\n   * Erlang (PropEr): @jfacorro @robertoaloi\n   * Groovy: @victorgit\n   * Go: @wing328 [:heart:](https://www.patreon.com/wing328)\n   * Go (rewritten in 2.3.0): @antihax\n   * Godot (GDScript): @Goutte [:heart:](https://liberapay.com/Goutte)\n   * Haskell (http-client): @jonschoning\n   * Java (Feign): @davidkiss\n   * Java (Retrofit): @0legg\n   * Java (Retrofit2): @emilianobonassi\n   * Java (Jersey2): @xhh\n   * Java (okhttp-gson): @xhh\n   * Java (RestTemplate): @nbruno\n   * Java (Spring 5 WebClient): @daonomic\n   * Java (Spring 6 RestClient): @nicklas2751\n   * Java (RESTEasy): @gayathrigs\n   * Java (Vertx): @lopesmcc\n   * Java (Google APIs Client Library): @charlescapps\n   * Java (Rest-assured): @viclovsky\n   * Java (Java 11 Native HTTP client): @bbdouglas\n   * Java (Apache HttpClient 5.x): @harrywhite4 @andrevegas\n   * Java (Helidon): @spericas @tjquinno @tvallin\n   * Javascript/NodeJS: @jfiala\n   * JavaScript (Apollo DataSource): @erithmetic\n   * JavaScript (Closure-annotated Angular) @achew22\n   * JavaScript (Flow types) @jaypea\n   * Jetbrains HTTP Client : @jlengrand\n   * JMeter: @davidkiss\n   * Julia: @tanmaykm\n   * Kotlin: @jimschubert [:heart:](https://www.patreon.com/jimschubert)\n   * Kotlin (MultiPlatform): @andrewemery\n   * Kotlin (Volley): @alisters\n   * Kotlin (jvm-spring-webclient): @stefankoppier\n   * Kotlin (jvm-spring-restclient): @stefankoppier\n   * Lua: @daurnimator\n   * N4JS: @mmews-n4\n   * Nim: @hokamoto\n   * OCaml: @cgensoul\n   * Perl: @wing328 [:heart:](https://www.patreon.com/wing328)\n   * PHP (Guzzle): @baartosz\n   * PHP (with Data Transfer): @Articus\n   * PowerShell: @beatcracker\n   * PowerShell (refactored in 5.0.0): @wing328\n   * Python: @spacether [:heart:][spacether sponsorship]\n   * Python-Experimental: @spacether [:heart:][spacether sponsorship]\n   * Python (refactored in 7.0.0): @wing328\n   * R: @ramnov\n   * Ruby (Faraday): @meganemura @dkliban\n   * Ruby (HTTPX): @honeyryderchuck\n   * Rust: @farcaller\n   * Rust (rust-server): @metaswitch\n   * Scala (scalaz & http4s): @tbrown1979\n   * Scala (Akka): @cchafer\n   * Scala (sttp): @chameleon82\n   * Scala (sttp4): @flsh86\n   * Scala (scala-sttp4-jsoniter): @lbialy\n   * Scala (Pekko): @mickaelmagniez\n   * Scala (http4s): @JennyLeahy\n   * Swift: @tkqubo\n   * Swift 3: @hexelon\n   * Swift 4: @ehyche\n   * Swift 5: @4brunu\n   * Swift 6: @4brunu\n   * Swift Combine: @dydus0x14\n   * TypeScript (Angular1): @mhardorf\n   * TypeScript (Angular2): @roni-frantchi\n   * TypeScript (Angular6): @akehir\n   * TypeScript (Angular7): @topce\n   * TypeScript (Axios): @nicokoenig\n   * TypeScript (Fetch): @leonyu\n   * TypeScript (Inversify): @gualtierim\n   * TypeScript (jQuery): @bherila\n   * TypeScript (Nestjs): @vfrank66\n   * TypeScript (Node):  @mhardorf\n   * TypeScript (Rxjs): @denyo\n   * TypeScript (redux-query): @petejohansonxo\n   * Xojo: @Topheee\n   * Zapier: @valmoz, @emajo\n * Server Stubs\n   * Ada: @stcarrez\n   * C# ASP.NET 5: @jimschubert [:heart:](https://www.patreon.com/jimschubert)\n   * C# ASP.NET Core 3.0: @A-Joshi\n   * C# APS.NET Core 3.1: @phatcher\n   * C# Azure functions: @Abrhm7786\n   * C# NancyFX: @mstefaniuk\n   * C++ (Qt5 QHttpEngine): @etherealjoy\n   * C++ Oat++: @Kraust\n   * C++ Pistache: @sebymiano\n   * C++ Restbed: @stkrwork\n   * Erlang Server: @galaxie @nelsonvides\n   * F# (Giraffe) Server: @nmfisher\n   * Go Server: @guohuang\n   * Go Server (refactored in 7.0.0): @lwj5\n   * Go (Echo) Server: @ph4r5h4d\n   * Go (Gin) Server: @kemokemo\n   * GraphQL Express Server: @renepardon\n   * Haskell Servant: @algas\n   * Haskell Yesod: @yotsuya\n   * Java Camel: @carnevalegiacomo\n   * Java Dubbo: @redoom\n   * Java MSF4J: @sanjeewa-malalgoda\n   * Java Spring Boot: @diyfr\n   * Java Undertow: @stevehu\n   * Java Play Framework: @JFCote\n   * Java PKMST: @anshu2185 @sanshuman @rkumar-pk @ninodpillai\n   * Java Vert.x: @lwlee2608\n   * Java Micronaut: @andriy-dmytruk\n   * Java Helidon: @spericas @tjquinno @tvallin\n   * Java WireMock: [@acouvreur](https://github.com/acouvreur)\n   * JAX-RS RestEasy: @chameleon82\n   * JAX-RS CXF: @hiveship\n   * JAX-RS CXF (CDI): @nickcmaynard\n   * JAX-RS RestEasy (JBoss EAP): @jfiala\n   * Julia: @tanmaykm\n   * Kotlin: @jimschubert [:heart:](https://www.patreon.com/jimschubert)\n   * Kotlin (Spring Boot): @dr4ke616\n   * Kotlin (Vertx): @Wooyme\n   * Kotlin (JAX-RS): @anttileppa\n   * Kotlin Misk: @andrewwilsonnew @guiarn\n   * Kotlin WireMock: @stefankoppier\n   * NodeJS Express: @YishTish\n   * PHP Flight: @daniel-sc\n   * PHP Laravel: @renepardon\n   * PHP Laravel (refactor in 7.12.0): @gijs-blanken\n   * PHP Lumen: @abcsun\n   * PHP Mezzio (with Path Handler): @Articus\n   * PHP Slim: @jfastnacht\n   * PHP Slim4: [@ybelenko](https://github.com/ybelenko)\n   * PHP Symfony: @ksm2\n   * PHP Symfony6: @BenjaminHae\n   * Python FastAPI: @krjakbrjak\n   * Python AIOHTTP:\n   * Ruby on Rails 5: @zlx\n   * Rust (rust-server): @metaswitch\n   * Rust (rust-axum): @linxGnu\n   * Scala Akka: @Bouillie\n   * Scala Cask: @aaronp\n   * Scala Finch: @jimschubert [:heart:](https://www.patreon.com/jimschubert)\n   * Scala Lagom: @gmkumar2005\n   * Scala Play: @adigerber\n   * TypeScript NestJS: @aryobenholzner\n * Documentation\n   * AsciiDoc: @man-at-home\n   * HTML Doc 2: @jhitchcock\n   * Confluence Wiki: @jhitchcock\n   * PlantUML: @pburls\n * Configuration\n   * Apache2: @stkrwork\n   * k6: @mostafa\n * Schema\n   * Avro: @sgadouar\n   * GraphQL: @wing328 [:heart:](https://www.patreon.com/wing328)\n   * Ktorm: @Luiz-Monad\n   * MySQL: [@ybelenko](https://github.com/ybelenko)\n   * PostgreSQL: [@iri](https://github.com/iri)\n   * Postman Collection: @gcatanese\n   * Protocol Buffer: @wing328\n   * WSDL: @adessoDpd\n\n:heart: = Link to support the contributor directly\n\n#### How to join the core team\n\nHere are the requirements to become a core team member:\n- rank within top 50 in https://github.com/openapitools/openapi-generator/graphs/contributors\n  - to contribute, here are some good [starting points](https://github.com/openapitools/openapi-generator/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22)\n- regular contributions to the project\n  - about 3 hours per week\n  - for contribution, it can be addressing issues, reviewing PRs submitted by others, submitting PR to fix bugs or make enhancements, etc\n  - must be active in the past 3 months at the time of application\n\n To join the core team, please reach out to team@openapitools.org for more information.\n\n To become a Template Creator, simply submit a PR for new API client (e.g. Rust, Elixir) or server stub (e.g. Ruby Grape) generator.\n\n### [6.2 - OpenAPI Generator Technical Committee](#table-of-contents)\n\nMembers of the OpenAPI Generator technical committee shoulder the following responsibilities:\n\n- Provides guidance and direction to other users\n- Reviews pull requests and issues\n- Improves the generator by making enhancements, fixing bugs or updating documentations\n- Sets the technical direction of the generator\n\nWho is eligible? Those who want to join must have at least 3 PRs merged into a generator. (Exceptions can be granted to template creators or contributors who have made a lot of code changes with less than 3 merged PRs)\n\nIf you want to join the committee, please kindly apply by sending an email to team@openapitools.org with your Github ID.\n\n#### Members of Technical Committee\n\n| Languages/Generators  | Member (join date)                                                                                                                                                                                                                                    |\n|:----------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| ActionScript          |                                                                                                                                                                                                                                                       |\n| Ada                   | @stcarrez (2018/02) @michelealbano (2018/02)                                                                                                                                                                                                          |\n| Android               | @jaz-ah (2017/09)                                                                                                                                                                                                                                     |\n| Apex                  |                                                                                                                                                                                                                                                       |\n| Bash                  | @frol (2017/07) @bkryza (2017/08) @kenjones-cisco (2017/09)                                                                                                                                                                                           |\n| C                     | @zhemant (2018/11) @ityuhui (2019/12) @michelealbano (2020/03) @eafer (2024/12)                                                                                                                                                                                        |\n| C++                   | @ravinikam (2017/07) @stkrwork (2017/07) @etherealjoy (2018/02) @martindelille (2018/03) @muttleyxd (2019/08) @aminya (2025/05)                                                                                                                                         |\n| C#                    | @mandrean (2017/08) @shibayan (2020/02) @Blackclaws (2021/03) @lucamazzanti (2021/05) @iBicha (2023/07)                                                                                                                                          |\n| Clojure               |                                                                                                                                                                                                                                                       |\n| Crystal               | @cyangle (2021/01)                                                                                                                                                                                                                                    |\n| Dart                  | @jaumard (2018/09) @josh-burton (2019/12) @amondnet (2019/12) @sbu-WBT (2020/12) @kuhnroyal (2020/12) @agilob (2020/12) @ahmednfwela (2021/08)                                                                                                        |\n| Eiffel                | @jvelilla (2017/09)                                                                                                                                                                                                                                   |\n| Elixir                | @mrmstn (2018/12)                                                                                                                                                                                                                                     |\n| Elm                   | @eriktim (2018/09)                                                                                                                                                                                                                                    |\n| Erlang                | @tsloughter (2017/11) @jfacorro (2018/10) @robertoaloi (2018/10) @nelsonvides (2024/09)                                                                                                                                                               |\n| F#                    | @nmfisher (2019/05)                                                                                                                                                                                                                                   |\n| Go                    | @antihax (2017/11) @grokify (2018/07) @kemokemo (2018/09) @jirikuncar (2021/01) @ph4r5h4d (2021/04) @lwj5 (2023/04)                                                                                                                                                   |\n| GraphQL               | @renepardon (2018/12)                                                                                                                                                                                                                                 |\n| Groovy                |                                                                                                                                                                                                                                                       |\n| Haskell               |                                                                                                                                                                                                                                                       |\n| Java                  | @bbdouglas (2017/07) @sreeshas (2017/08) @jfiala (2017/08) @lukoyanov (2017/09) @cbornet (2017/09) @jeff9finger (2018/01) @karismann (2019/03) @Zomzog (2019/04) @lwlee2608 (2019/10) @martin-mfg (2023/08)                                                                 |\n| Java Spring           | @cachescrubber (2022/02) @welshm (2022/02) @MelleD (2022/02) @atextor (2022/02) @manedev79 (2022/02) @javisst (2022/02) @borsch (2022/02) @banlevente (2022/02) @Zomzog (2022/09) @martin-mfg (2023/08)                                                                     |\n| JMeter                | @kannkyo (2021/01)                                                                                                                                                                                                                                    |\n| Jetbrains HTTP Client | @jlengrand (2023/01)                                                                                                                                                                                                                                  |\n| Julia                 | @tanmaykm (2023/01)                                                                                                                                                                                                                                   |\n| Kotlin                | @karismann (2019/03) @Zomzog (2019/04) @andrewemery (2019/10) @4brunu (2019/11) @yutaka0m (2020/03) @stefankoppier (2022/06) @e5l (2024/10)                                          |\n| Lua                   | @daurnimator (2017/08)                                                                                                                                                                                                                                |\n| N4JS                  | @mmews-n4 (2023/03)                                                                                                                                                                                      |\n| Nim                   |                                                                                                                                                                                                                                                       |\n| NodeJS/Javascript     | @CodeNinjai (2017/07) @frol (2017/07) @cliffano (2017/07)                                                                                                                                                                                             |\n| ObjC                  |                                                                                                                                                                                                                                                       |\n| OCaml                 | @cgensoul (2019/08), @sir4ur0n (2025/08)                                                                                                                                                                                                              |\n| Perl                  | @wing328 (2017/07) [:heart:](https://www.patreon.com/wing328) @yue9944882 (2019/06)                                                                                                                                                                   |\n| PHP                   | @jebentier (2017/07), @dkarlovi (2017/07), @mandrean (2017/08), @jfastnacht (2017/09), [@ybelenko](https://github.com/ybelenko) (2018/07), @renepardon (2018/12)                                                                                      |\n| PowerShell            | @wing328 (2020/05)                                                                                                                                                                                                                                    |\n| Python                | @cbornet (2017/09) @tomplus (2018/10) @krjakbrjak (2023/02) @fa0311 (2023/10) @multani (2023/10) |\n| R                     | @Ramanth (2019/07) @saigiridhar21 (2019/07)                                                                                                                                                                                                           |\n| Ruby                  | @cliffano (2017/07) @zlx (2017/09) @autopp (2019/02)                                                                                                                                                                                                  |\n| Rust                  | @frol (2017/07) @farcaller (2017/08) @richardwhiuk (2019/07) @paladinzh (2020/05) @jacob-pro (2022/10) @dsteeley (2025/07)                                                                                                                                               |\n| Scala                 | @clasnake (2017/07), @shijinkui  (2018/01), @ramzimaalej (2018/03), @chameleon82 (2020/03), @Bouillie (2020/04) @fish86 (2023/06)                                                               |\n| Swift                 | @jgavris (2017/07) @ehyche (2017/08) @Edubits (2017/09) @jaz-ah (2017/09) @4brunu (2019/11) @dydus0x14 (2023/06)                                                                                                                                                           |\n| TypeScript            | @TiFu (2017/07) @taxpon (2017/07) @sebastianhaas (2017/07) @kenisteward (2017/07) @Vrolijkx (2017/09) @macjohnny (2018/01) @topce (2018/10) @akehir (2019/07) @petejohansonxo (2019/11) @amakhrov (2020/02) @davidgamero (2022/03) @mkusaka (2022/04) @joscha (2024/10)    |\n| Xojo                  | @Topheee (2023/04)                                                                                                                                                                                                                                    |\n\n\nPast Members of Technical Committee:\n| Languages/Generators         | Member (join date)                                                                                                                                                                                                                |\n| :---------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Python            | @taxpon (2017/07) @frol (2017/07) @mbohlool (2017/07) @cbornet (2017/09) @kenjones-cisco (2017/11) @tomplus (2018/10) @arun-nalla (2019/11)  |\n\n\n:heart: = Link to support the contributor directly\n\n### [6.3 - History of OpenAPI Generator](#table-of-contents)\n\nOpenAPI Generator is a fork of [Swagger Codegen](https://github.com/swagger-api/swagger-codegen). In view of the issues with the Swagger Codegen 3.0.0 (beta) release and the disagreement on the project's direction, more than 40 top contributors and template creators of Swagger Codegen decided to fork Swagger Codegen and maintain a community-driven version called \"OpenAPI Generator\". Please refer to the [Q&A](docs/qna.md) for more information.\n\n#### Founding Members (alphabetical order):\n\n- [Akihito Nakano](https://github.com/ackintosh)\n- [Artem Ocheredko](https://github.com/galaxie)\n- [Arthur Mogliev](https://github.com/Articus)\n- [Bartek Kryza](https://github.com/bkryza)\n- [Ben Wells](https://github.com/bvwells)\n- [Benjamin Gill](https://github.com/bjgill)\n- [Christophe Bornet](https://github.com/cbornet)\n- [Cliffano Subagio](https://github.com/cliffano)\n- [Daiki Matsudate](https://github.com/d-date)\n- [Daniel](https://github.com/Danielku15)\n- [Emiliano Bonassi](https://github.com/emilianobonassi)\n- [Erik Timmers](https://github.com/eriktim)\n- [Esteban Gehring](https://github.com/macjohnny)\n- [Gustavo Paz](https://github.com/gustavoapaz)\n- [Javier Velilla](https://github.com/jvelilla)\n- [Jean-Fran√ßois C√¥t√©](https://github.com/JFCote)\n- [Jim Schubert](https://github.com/jimschubert)\n- [Jon Schoning](https://github.com/jonschoning)\n- [J√©r√©mie Bresson](https://github.com/jmini) [:heart:](https://www.patreon.com/jmini)\n- [J√∂rn Ahrens](https://github.com/jayearn)\n- [Keni Steward](https://github.com/kenisteward)\n- [Marcin Stefaniuk](https://github.com/mstefaniuk)\n- [Martin Delille](https://github.com/MartinDelille)\n- [Masahiro Yamauchi](https://github.com/algas)\n- [Michele Albano](https://github.com/michelealbano)\n- [Ramzi Maalej](https://github.com/ramzimaalej)\n- [Ravindra Nikam](https://github.com/ravinikam)\n- [Ricardo Cardona](https://github.com/ricardona)\n- [Sebastian Haas](https://github.com/sebastianhaas)\n- [Sebastian Mandrean](https://github.com/mandrean)\n- [Sreenidhi Sreesha](https://github.com/sreeshas)\n- [Stefan Krismann](https://github.com/stkrwork)\n- [Stephane Carrez](https://github.com/stcarrez)\n- [Takuro Wada](https://github.com/taxpon)\n- [Tomasz Prus](https://github.com/tomplus)\n- [Tristan Sloughter](https://github.com/tsloughter)\n- [Victor Orlovsky](https://github.com/viclovsky)\n- [Victor Trakhtenberg](https://github.com/victorgit)\n- [Vlad Frolov](https://github.com/frol)\n- [Vladimir Pouzanov](https://github.com/farcaller)\n- [William Cheng](https://github.com/wing328)\n- [Xin Meng](https://github.com/xmeng1) [:heart:](https://www.patreon.com/user/overview?u=16435385)\n- [Xu Hui Hui](https://github.com/xhh)\n- [antihax](https://github.com/antihax)\n- [beatcracker](https://github.com/beatcracker)\n- [daurnimator](https:/github.com/daurnimator)\n- [etherealjoy](https://github.com/etherealjoy)\n- [jfiala](https://github.com/jfiala)\n- [lukoyanov](https://github.com/lukoyanov)\n\n:heart: = Link to support the contributor directly\n\n## [7 - License](#table-of-contents)\n-------\n\nCopyright 2018 OpenAPI-Generator Contributors (https://openapi-generator.tech)\nCopyright 2018 SmartBear Software\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at [apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0)\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n---\n",
      "stars_today": 14
    },
    {
      "id": 66190491,
      "name": "apkupdater",
      "full_name": "rumboalla/apkupdater",
      "description": "APKUpdater is an open source tool that simplifies the process of finding updates for your installed apps.",
      "html_url": "https://github.com/rumboalla/apkupdater",
      "stars": 3557,
      "forks": 257,
      "language": "Kotlin",
      "topics": [
        "android",
        "apk",
        "apkmirror",
        "aptoide",
        "f-droid",
        "flow",
        "google",
        "gplv3",
        "installer",
        "java",
        "jetpack-compose",
        "kotlin",
        "material-design-3",
        "open-source",
        "play",
        "play-store",
        "updater",
        "workmanager"
      ],
      "created_at": "2016-08-21T09:18:13Z",
      "updated_at": "2026-01-24T00:56:54Z",
      "pushed_at": "2025-07-16T07:25:56Z",
      "open_issues": 29,
      "owner": {
        "login": "rumboalla",
        "avatar_url": "https://avatars.githubusercontent.com/u/21153554?v=4"
      },
      "readme": "# APKUpdater [![](https://github.com/rumboalla/apkupdater/workflows/Android%20Build/badge.svg)](https://github.com/rumboalla/apkupdater/actions?query=workflow%3A%22Android+Build%22)\n**APKUpdater** is an open source tool that simplifies the process of **finding updates** for your installed apps.  \nIt provides similar functionality to an app store, but instead of depending on a single source, it aggregates the results from **APKMirror**, **Aptoide**, **F-Droid**, **IzzyOnDroid**, **APKPure**, **GitLab** and **GitHub**.\n\nThe 3.x branch is a full rewrite using modern technologies like **Jetpack Compose**, **Flow** and **WorkManager**.\n\n# Features\n* **Update Sources**: Find updates from **APKMirror**, **Aptoide**, **F-Droid**, **IzzyOnDroid**, **APKPure**, **GitLab**, **GitHub** and **Google Play**.\n* **Search Sources**: Find new apps to install from **APKMirror**, **Aptoide**, **F-Droid**, **IzzyOnDroid**, **APKPure**, **GitLab**, **GitHub** and **Google Play**.\n* Schedule **background update checks** and receive a **notification** when updates are found.\n* Supports **Android 5** (**21**) to **Android 14** (**34**).\n* Supports **Android TV**.\n* **Material Design 3** with **Dark**, **Light** and **System** theme support.\n* Supports **Material You** on Android 12+.\n* **Direct install** of updates for sources that support it.\n* Supports **installs without user interaction** on Android 12+.\n* **Root install** of updates.\n* No ads. No tracking.\n* **Languages**: Albanian, Arabic, Burmese, Dutch, English, German, Hebrew, Hungarian, Indonesian, Italian, Korean, Malay, Portuguese, Romanian, Russian, Simplified Chinese, Spanish, Traditional Chinese, Turkish.\n\n# Download\n* [Stable Release (3.0.3)](https://github.com/rumboalla/apkupdater/releases/latest/download/com.apkupdater-release.apk)\n* [CI Pre-release Builds](https://github.com/rumboalla/apkupdater/releases?q=CI&expanded=true)\n* [Older releases](https://github.com/rumboalla/apkupdater/releases)\n\n# Translations\nIf you want to help with translations, open a [Pull Request](https://github.com/rumboalla/apkupdater/pulls) or an [Issue](https://github.com/rumboalla/apkupdater/issues) with the translated [strings.xml](https://github.com/rumboalla/apkupdater/blob/3.x/app/src/main/res/values/strings.xml).\n\n* Albanian by [Jvr2022](https://github.com/Jvr2022)\n* Arabic by [Muhammadbahaa2001](https://github.com/Muhammadbahaa2001)\n* Burmese by [kyawlinnthant](https://github.com/kyawlinnthant)\n* Dutch by [AnonymousWP](https://github.com/AnonymousWP)\n* German by [peat80](https://github.com/peat80)\n* Hebrew by [electriquo](https://github.com/electriquo)\n* Hungarian by [gidano](https://github.com/gidano)\n* Indonesian by [HazakuraID](https://github.com/HazakuraID)\n* Italian by [NicKoehler](https://github.com/NicKoehler)\n* Korean by [Apious](https://github.com/Apious)\n* Malay by [HazakuraID](https://github.com/HazakuraID)\n* Portuguese by [zekabra](https://github.com/zekabra)\n* Romanian by [StormProductionsMusic](https://github.com/StormProductionsMusic)\n* Russian by [Xenorant](https://github.com/Xenorant)\n* Simplified Chinese by [Nriver](https://github.com/Nriver)\n* Traditional Chinese by [abc0922001](https://github.com/abc0922001)\n* Turkish by [kyoyacchi](https://github.com/kyoyacchi)\n* Japanese by [anonym499](https://github.com/anonym499)\n\n# Feedback\n- To give feedback and request new features go to [Discussions](https://github.com/rumboalla/apkupdater/discussions).\n- To report bugs, crashes, typos and translations go to [Issues](https://github.com/rumboalla/apkupdater/issues).\n\n# Screenshots\n\n| ![1](https://github.com/rumboalla/apkupdater/assets/21153554/b5b4943b-e12a-43e2-a056-26d6f06f9bc4) | ![2](https://github.com/rumboalla/apkupdater/assets/21153554/c4679c1b-09d4-429d-9160-77d4d33b0a0f) | ![3](https://github.com/rumboalla/apkupdater/assets/21153554/7b89c5a6-672c-44e4-836e-e01f51f33591) | ![4](https://github.com/rumboalla/apkupdater/assets/21153554/7ec15783-e719-4feb-9e07-a14c0f1defcc) |\n|----------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|\n\n| ![5](https://github.com/rumboalla/apkupdater/assets/21153554/bbf1132a-b0b6-4890-aed7-8fe95c0da11b) | ![6](https://github.com/rumboalla/apkupdater/assets/21153554/32236bfb-b53e-4999-8363-e957fa8f77a9) |\n|----------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|\n\n# Other Projects\n* [CoolRs](https://github.com/rumboalla/coolrs): A collection of Android RenderScript effects. \n* [KryptoPrefs](https://github.com/rumboalla/KryptoPrefs): Kotlin library for handling encrypted SharedPreferences.\n* [KryptoStore](https://github.com/rumboalla/kryptostore): A thin wrapper around Jetpack Datastore Preferences that provides useful features.\n\n# License\nCopyright &copy; 2016-2024 rumboalla.  \nLicensed under the [GNU General Public License v3](https://www.gnu.org/licenses/gpl-3.0.en.html).\n",
      "stars_today": 14
    },
    {
      "id": 192640529,
      "name": "label-studio",
      "full_name": "HumanSignal/label-studio",
      "description": "Label Studio is a multi-type data labeling and annotation tool with standardized output format",
      "html_url": "https://github.com/HumanSignal/label-studio",
      "stars": 26248,
      "forks": 3343,
      "language": "TypeScript",
      "topics": [
        "annotation",
        "annotation-tool",
        "annotations",
        "boundingbox",
        "computer-vision",
        "data-labeling",
        "dataset",
        "datasets",
        "deep-learning",
        "image-annotation",
        "image-classification",
        "image-labeling",
        "image-labelling-tool",
        "label-studio",
        "labeling",
        "labeling-tool",
        "mlops",
        "semantic-segmentation",
        "text-annotation",
        "yolo"
      ],
      "created_at": "2019-06-19T02:00:44Z",
      "updated_at": "2026-01-24T00:33:00Z",
      "pushed_at": "2026-01-24T00:33:04Z",
      "open_issues": 993,
      "owner": {
        "login": "HumanSignal",
        "avatar_url": "https://avatars.githubusercontent.com/u/48309720?v=4"
      },
      "readme": "<img src=\"https://user-images.githubusercontent.com/12534576/192582340-4c9e4401-1fe6-4dbb-95bb-fdbba5493f61.png\"/>\n\n![GitHub](https://img.shields.io/github/license/heartexlabs/label-studio?logo=heartex) ![label-studio:build](https://github.com/HumanSignal/label-studio/workflows/label-studio:build/badge.svg) ![GitHub release](https://img.shields.io/github/v/release/heartexlabs/label-studio?include_prereleases)\n\n[Website](https://labelstud.io/) ‚Ä¢ [Docs](https://labelstud.io/guide/) ‚Ä¢ [Join Slack Community <img src=\"https://app.heartex.ai/docs/images/slack-mini.png\" width=\"18px\"/>](https://slack.labelstud.io/?source=github-1)\n\n\n## What is Label Studio?\n\n<!-- <a href=\"https://labelstud.io/blog/release-130.html\"><img src=\"https://github.com/HumanSignal/label-studio/raw/master/docs/themes/htx/source/images/release-130/LS-Hits-v1.3.png\" align=\"right\" /></a> -->\n\nLabel Studio is an open source data labeling tool. It lets you label data types like audio, text, images, videos, and time series with a simple and straightforward UI and export to various model formats. It can be used to prepare raw data or improve existing training data to get more accurate ML models.\n\n- [Try out Label Studio](#try-out-label-studio)\n- [What you get from Label Studio](#what-you-get-from-label-studio)\n- [Included templates for labeling data in Label Studio](#included-templates-for-labeling-data-in-label-studio)\n- [Set up machine learning models with Label Studio](#set-up-machine-learning-models-with-Label-Studio)\n- [Integrate Label Studio with your existing tools](#integrate-label-studio-with-your-existing-tools)\n\n![Gif of Label Studio annotating different types of data](/images/annotation_examples.gif)\n\nHave a custom dataset? You can customize Label Studio to fit your needs. Read an [introductory blog post](https://towardsdatascience.com/introducing-label-studio-a-swiss-army-knife-of-data-labeling-140c1be92881) to learn more. \n\n## Try out Label Studio\n\nInstall Label Studio locally or deploy it in a cloud instance. [Or sign up for a free trial of our Starter Cloud edition!](https://humansignal.com/platform/starter-cloud/) You can learn more about what each edition offers [here](https://labelstud.io/guide/label_studio_compare). \n\n- [Install locally with Docker](#install-locally-with-docker)\n- [Run with Docker Compose (Label Studio + Nginx + PostgreSQL)](#run-with-docker-compose)\n- [Install locally with pip](#install-locally-with-pip)\n- [Install locally with poetry](#install-locally-with-poetry)\n- [Install locally with Anaconda](#install-locally-with-anaconda)\n- [Install for local development](#install-for-local-development)\n- [Deploy in a cloud instance](#deploy-in-a-cloud-instance)\n\n### Install locally with Docker\nOfficial Label Studio docker image is [here](https://hub.docker.com/r/heartexlabs/label-studio) and it can be downloaded with `docker pull`. \nRun Label Studio in a Docker container and access it at `http://localhost:8080`.\n\n\n```bash\ndocker pull heartexlabs/label-studio:latest\ndocker run -it -p 8080:8080 -v $(pwd)/mydata:/label-studio/data heartexlabs/label-studio:latest\n```\nYou can find all the generated assets, including SQLite3 database storage `label_studio.sqlite3` and uploaded files, in the `./mydata` directory.\n\n#### Override default Docker install\nYou can override the default launch command by appending the new arguments:\n```bash\ndocker run -it -p 8080:8080 -v $(pwd)/mydata:/label-studio/data heartexlabs/label-studio:latest label-studio --log-level DEBUG\n```\n\n#### Build a local image with Docker\nIf you want to build a local image, run:\n```bash\ndocker build -t heartexlabs/label-studio:latest .\n```\n\n### Run with Docker Compose\nDocker Compose script provides production-ready stack consisting of the following components:\n\n- Label Studio\n- [Nginx](https://www.nginx.com/) - proxy web server used to load various static data, including uploaded audio, images, etc.\n- [PostgreSQL](https://www.postgresql.org/) - production-ready database that replaces less performant SQLite3.\n\nTo start using the app from `http://localhost` run this command:\n```bash\ndocker-compose up\n```\n\n### Run with Docker Compose + MinIO\nYou can also run it with an additional MinIO server for local S3 storage. This is particularly useful when you want to \ntest the behavior with S3 storage on your local system. To start Label Studio in this way, you need to run the following command:\n````bash\n# Add sudo on Linux if you are not a member of the docker group\ndocker compose -f docker-compose.yml -f docker-compose.minio.yml up -d\n````\nIf you do not have a static IP address, you must create an entry in your hosts file so that both Label Studio and your \nbrowser can access the MinIO server. For more detailed instructions, please refer to [our guide on storing data](docs/source/guide/storedata.md).\n\n\n### Install locally with pip\n\n```bash\n# Requires Python >=3.10\npip install label-studio\n\n# Start the server at http://localhost:8080\nlabel-studio\n```\n\n### Install locally with poetry\n\n```bash\n### install poetry\npip install poetry\n\n### set poetry environment\npoetry new my-label-studio\ncd my-label-studio\npoetry add label-studio\n\n### activate poetry environment\npoetry shell\n\n### Start the server at http://localhost:8080\nlabel-studio\n```\n\n### Install locally with Anaconda\n\n```bash\nconda create --name label-studio\nconda activate label-studio\nconda install psycopg2\npip install label-studio\n```\n\n### Install for local development\n\nYou can run the latest Label Studio version locally without installing the package from pypi. \n\n```bash\n# Install all package dependencies\npip install poetry\npoetry install\n# Run database migrations\npython label_studio/manage.py migrate\npython label_studio/manage.py collectstatic\n# Start the server in development mode at http://localhost:8080\npython label_studio/manage.py runserver\n```\n\n### Deploy in a cloud instance\n\nYou can deploy Label Studio with one click in Heroku, Microsoft Azure, or Google Cloud Platform: \n\n<a href=\"https://www.heroku.com/deploy?template=https://github.com/HumanSignal/label-studio/tree/heroku-persistent-pg\"><img src=\"https://www.herokucdn.com/deploy/button.svg\" alt=\"Deploy\" height=\"30px\"></a>\n[<img src=\"https://aka.ms/deploytoazurebutton\" height=\"30px\">](https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2Fhumansignal%2Flabel-studio%2Fdevelop%2Fazuredeploy.json)\n[<img src=\"https://deploy.cloud.run/button.svg\" height=\"30px\">](https://deploy.cloud.run)\n\n\n#### Apply frontend changes\n\nFor information about updating the frontend, see [label-studio/web/README.md](https://github.com/HumanSignal/label-studio/blob/develop/web/README.md#installation-instructions).\n\n\n#### Install dependencies on Windows \nTo run Label Studio on Windows, download and install the following wheel packages from [Gohlke builds](https://www.lfd.uci.edu/~gohlke/pythonlibs) to ensure you're using the correct version of Python:\n- [lxml](https://www.lfd.uci.edu/~gohlke/pythonlibs/#lxml)\n\n```bash\n# Upgrade pip \npip install -U pip\n\n# If you're running Win64 with Python 3.8, install the packages downloaded from Gohlke:\npip install lxml‚Äë4.5.0‚Äëcp38‚Äëcp38‚Äëwin_amd64.whl\n\n# Install label studio\npip install label-studio\n```\n\n### Run test suite\nTo add the tests' dependencies to your local install:\n\n```bash\npoetry install --with test\n```\n\nAlternatively, it is possible to run the unit tests from a Docker container in which the test dependencies are installed:\n\n\n```bash\nmake build-testing-image\nmake docker-testing-shell\n```\n\nIn either case, to run the unit tests:\n\n```bash\ncd label_studio\n\n# sqlite3\nDJANGO_DB=sqlite DJANGO_SETTINGS_MODULE=core.settings.label_studio pytest -vv\n\n# postgres (assumes default postgres user,db,pass. Will not work in Docker\n# testing container without additional configuration)\nDJANGO_DB=default DJANGO_SETTINGS_MODULE=core.settings.label_studio pytest -vv\n```\n \n## What you get from Label Studio\n\nhttps://github.com/user-attachments/assets/525ad5ff-6904-4398-b507-7e8954268d69\n\n- **Multi-user labeling** sign up and login, when you create an annotation it's tied to your account.\n- **Multiple projects** to work on all your datasets in one instance.\n- **Streamlined design** helps you focus on your task, not how to use the software.\n- **Configurable label formats** let you customize the visual interface to meet your specific labeling needs.\n- **Support for multiple data types** including images, audio, text, HTML, time-series, and video. \n- **Import from files or from cloud storage** in Amazon AWS S3, Google Cloud Storage, or JSON, CSV, TSV, RAR, and ZIP archives. \n- **Integration with machine learning models** so that you can visualize and compare predictions from different models and perform pre-labeling.\n- **Embed it in your data pipeline** REST API makes it easy to make it a part of your pipeline\n\n## Included templates for labeling data in Label Studio \n\nLabel Studio includes a variety of templates to help you label your data, or you can create your own using specifically designed configuration language. The most common templates and use cases for labeling include the following cases:\n\n<img src=\"/images/template-types.png\" />\n\n## Set up machine learning models with Label Studio\n\nConnect your favorite machine learning model using the Label Studio Machine Learning SDK. Follow these steps:\n\n1. Start your own machine learning backend server. See [more detailed instructions](https://github.com/HumanSignal/label-studio-ml-backend).\n2. Connect Label Studio to the server on the model page found in project settings.\n\nThis lets you:\n\n- **Pre-label** your data using model predictions. \n- Do **online learning** and retrain your model while new annotations are being created. \n- Do **active learning** by labeling only the most complex examples in your data.\n\n## Integrate Label Studio with your existing tools\n\nYou can use Label Studio as an independent part of your machine learning workflow or integrate the frontend or backend into your existing tools.  \n\n## Ecosystem\n\n| Project | Description |\n|-|-|\n| label-studio | Server, distributed as a pip package |\n| [Frontend library](web/libs/editor/) | The Label Studio frontend library. This uses React to build the UI and mobx-state-tree for state management. |  \n| [Data Manager library](web/libs/datamanager/) | A library for the Data Manager, our data exploration tool. | \n| [label-studio-converter](https://github.com/HumanSignal/label-studio-sdk/tree/master/src/label_studio_sdk/converter) | Encode labels in the format of your favorite machine learning library |\n| [label-studio-transformers](https://github.com/HumanSignal/label-studio-transformers) | Transformers library connected and configured for use with Label Studio |\n\n## Citation\n\nInclude a citation for Label Studio in the **References** section of your articles:\n\n```tex\n@misc{Label Studio,\n  title={{Label Studio}: Data labeling software},\n  url={https://github.com/HumanSignal/label-studio},\n  note={Open source software available from https://github.com/HumanSignal/label-studio},\n  author={\n    Maxim Tkachenko and\n    Mikhail Malyuk and\n    Andrey Holmanyuk and\n    Nikolai Liubimov},\n  year={2020-2025},\n}\n```\n\n## License\n\nThis software is licensed under the [Apache 2.0 LICENSE](/LICENSE) ¬© [Heartex](https://www.heartex.com/). 2020-2025\n\n<img src=\"https://user-images.githubusercontent.com/12534576/192582529-cf628f58-abc5-479b-a0d4-8a3542a4b35e.png\" title=\"Hey everyone!\" width=\"180\" />\n",
      "stars_today": 13
    },
    {
      "id": 775743011,
      "name": "valkey",
      "full_name": "valkey-io/valkey",
      "description": "A flexible distributed key-value database that is optimized for caching and other realtime workloads.",
      "html_url": "https://github.com/valkey-io/valkey",
      "stars": 24574,
      "forks": 1010,
      "language": "C",
      "topics": [
        "cache",
        "database",
        "key-value",
        "key-value-store",
        "nosql",
        "redis",
        "valkey",
        "valkey-client"
      ],
      "created_at": "2024-03-22T00:42:17Z",
      "updated_at": "2026-01-24T01:24:04Z",
      "pushed_at": "2026-01-23T20:30:41Z",
      "open_issues": 590,
      "owner": {
        "login": "valkey-io",
        "avatar_url": "https://avatars.githubusercontent.com/u/164458127?v=4"
      },
      "readme": "[![codecov](https://codecov.io/gh/valkey-io/valkey/graph/badge.svg?token=KYYSJAYC5F)](https://codecov.io/gh/valkey-io/valkey)\n\nThis project was forked from the open source Redis project right before the transition to their new source available licenses.\n\nThis README is just a fast *quick start* document. More details can be found under [valkey.io](https://valkey.io/)\n\n# What is Valkey?\n\nValkey is a high-performance data structure server that primarily serves key/value workloads.\nIt supports a wide range of native structures and an extensible plugin system for adding new data structures and access patterns.\n\n# Building Valkey using `Makefile`\n\nValkey can be compiled and used on Linux, macOS, OpenBSD, NetBSD, FreeBSD.\nWe support big endian and little endian architectures, and both 32 bit\nand 64 bit systems.\n\nIt may compile on Solaris derived systems (for instance SmartOS) but our\nsupport for this platform is *best effort* and Valkey is not guaranteed to\nwork as well as in Linux, macOS, and \\*BSD.\n\nIt is as simple as:\n\n    % make\n\nTo build with TLS support, you'll need OpenSSL development libraries (e.g.\nlibssl-dev on Debian/Ubuntu).\n\nTo build TLS support as Valkey built-in:\n\n    % make BUILD_TLS=yes\n\nTo build TLS as Valkey module:\n\n    % make BUILD_TLS=module\n\nNote that sentinel mode does not support TLS module.\n\nTo build with experimental RDMA support you'll need RDMA development libraries\n(e.g. librdmacm-dev and libibverbs-dev on Debian/Ubuntu).\n\nTo build RDMA support as Valkey built-in:\n\n    % make BUILD_RDMA=yes\n\nTo build RDMA as Valkey module:\n\n    % make BUILD_RDMA=module\n\nTo build with systemd support, you'll need systemd development libraries (such\nas libsystemd-dev on Debian/Ubuntu or systemd-devel on CentOS) and run:\n\n    % make USE_SYSTEMD=yes\n\nSince Valkey version 8.1, `fast_float` has been introduced as an optional\ndependency, which can speed up sorted sets and other commands that use\nthe double datatype. To build with `fast_float` support, you'll need a\nC++ compiler and run:\n\n    % make USE_FAST_FLOAT=yes\n\nTo build Valkey without the Lua engine:\n\n    % make BUILD_LUA=no\n\nTo append a suffix to Valkey program names, use:\n\n    % make PROG_SUFFIX=\"-alt\"\n\nYou can build a 32 bit Valkey binary using:\n\n    % make 32bit\n\nAfter building Valkey, it is a good idea to test it using:\n\n    % make test\n\nThe above runs the main integration tests. Additional tests are started using:\n\n    % make test-unit     # Unit tests\n    % make test-modules  # Tests of the module API\n    % make test-sentinel # Valkey Sentinel integration tests\n    % make test-cluster  # Valkey Cluster integration tests\n\nMore about running the integration tests can be found in\n[tests/README.md](tests/README.md) and for unit tests, see\n[src/unit/README.md](src/unit/README.md).\n\n## Performance monitoring\n\nValkey Performance Dashboards provide a consolidated view of throughput trends across versions, helping contributors validate improvements and identify regressions quickly.\n\n- [Performance Overview](https://valkey.io/performance/) - Compare throughput across Valkey versions\n- [Unstable Branch Dashboard](https://perf-dashboard.valkey.io/public-dashboards/3e45bf8ded3043edaa941331cd1a94e2) - Track performance of all commits in the unstable branch\n\n## Fixing build problems with dependencies or cached build options\n\nValkey has some dependencies which are included in the `deps` directory.\n`make` does not automatically rebuild dependencies even if something in\nthe source code of dependencies changes.\n\nWhen you update the source code with `git pull` or when code inside the\ndependencies tree is modified in any other way, make sure to use the following\ncommand in order to really clean everything and rebuild from scratch:\n\n    % make distclean\n\nThis will clean: jemalloc, lua, libvalkey, linenoise and other dependencies.\n\nAlso if you force certain build options like 32bit target, no C compiler\noptimizations (for debugging purposes), and other similar build time options,\nthose options are cached indefinitely until you issue a `make distclean`\ncommand.\n\n## Fixing problems building 32 bit binaries\n\nIf after building Valkey with a 32 bit target you need to rebuild it\nwith a 64 bit target, or the other way around, you need to perform a\n`make distclean` in the root directory of the Valkey distribution.\n\nIn case of build errors when trying to build a 32 bit binary of Valkey, try\nthe following steps:\n\n* Install the package libc6-dev-i386 (also try g++-multilib).\n* Try using the following command line instead of `make 32bit`:\n  `make CFLAGS=\"-m32 -march=native\" LDFLAGS=\"-m32\"`\n\n## Allocator\n\nSelecting a non-default memory allocator when building Valkey is done by setting\nthe `MALLOC` environment variable. Valkey is compiled and linked against libc\nmalloc by default, with the exception of jemalloc being the default on Linux\nsystems. This default was picked because jemalloc has proven to have fewer\nfragmentation problems than libc malloc.\n\nTo force compiling against libc malloc, use:\n\n    % make MALLOC=libc\n\nTo compile against jemalloc on Mac OS X systems, use:\n\n    % make MALLOC=jemalloc\n\n## Monotonic clock\n\nBy default, Valkey will build using the POSIX clock_gettime function as the\nmonotonic clock source.  On most modern systems, the internal processor clock\ncan be used to improve performance.  Cautions can be found here:\n    http://oliveryang.net/2015/09/pitfalls-of-TSC-usage/\n\nTo build with support for the processor's internal instruction clock, use:\n\n    % make CFLAGS=\"-DUSE_PROCESSOR_CLOCK\"\n\n## Verbose build\n\nValkey will build with a user-friendly colorized output by default.\nIf you want to see a more verbose output, use the following:\n\n    % make V=1\n\n# Running Valkey\n\nTo run Valkey with the default configuration, just type:\n\n    % cd src\n    % ./valkey-server\n\nIf you want to provide your valkey.conf, you have to run it using an additional\nparameter (the path of the configuration file):\n\n    % cd src\n    % ./valkey-server /path/to/valkey.conf\n\nIt is possible to alter the Valkey configuration by passing parameters directly\nas options using the command line. Examples:\n\n    % ./valkey-server --port 9999 --replicaof 127.0.0.1 6379\n    % ./valkey-server /etc/valkey/6379.conf --loglevel debug\n\nAll the options in valkey.conf are also supported as options using the command\nline, with exactly the same name.\n\n# Running Valkey with TLS:\n\n## Running manually\n\nTo manually run a Valkey server with TLS mode (assuming `./utils/gen-test-certs.sh`\nwas invoked so sample certificates/keys are available):\n\n* TLS built-in mode:\n    ```\n    ./src/valkey-server --tls-port 6379 --port 0 \\\n        --tls-cert-file ./tests/tls/valkey.crt \\\n        --tls-key-file ./tests/tls/valkey.key \\\n        --tls-ca-cert-file ./tests/tls/ca.crt\n    ```\n\n* TLS module mode:\n    ```\n    ./src/valkey-server --tls-port 6379 --port 0 \\\n        --tls-cert-file ./tests/tls/valkey.crt \\\n        --tls-key-file ./tests/tls/valkey.key \\\n        --tls-ca-cert-file ./tests/tls/ca.crt \\\n        --loadmodule src/valkey-tls.so\n    ```\n\nNote that you can disable TCP by specifying `--port 0` explicitly.\nIt's also possible to have both TCP and TLS available at the same time,\nbut you'll have to assign different ports.\n\nUse `valkey-cli` to connect to the Valkey server:\n```\n./src/valkey-cli --tls \\\n    --cert ./tests/tls/valkey.crt \\\n    --key ./tests/tls/valkey.key \\\n    --cacert ./tests/tls/ca.crt\n```\n\nSpecifying `--tls-replication yes` makes a replica connect to the primary.\n\nUsing `--tls-cluster yes` makes Valkey Cluster use TLS across nodes.\n\n# Running Valkey with RDMA:\n\nNote that Valkey Over RDMA is an experimental feature.\nIt may be changed or removed in any minor or major version.\nCurrently, it is only supported on Linux.\n\n* RDMA built-in mode:\n    ```\n    ./src/valkey-server --protected-mode no \\\n         --rdma-bind 192.168.122.100 --rdma-port 6379\n    ```\n\n* RDMA module mode:\n    ```\n    ./src/valkey-server --protected-mode no \\\n         --loadmodule src/valkey-rdma.so --rdma-bind 192.168.122.100 --rdma-port 6379\n    ```\n\nIt's possible to change bind address/port of RDMA by runtime command:\n\n    192.168.122.100:6379> CONFIG SET rdma-port 6380\n\nIt's also possible to have both RDMA and TCP available, and there is no\nconflict of TCP(6379) and RDMA(6379), Ex:\n\n    % ./src/valkey-server --protected-mode no \\\n         --loadmodule src/valkey-rdma.so --rdma-bind 192.168.122.100 --rdma-port 6379 \\\n         --port 6379\n\nNote that the network card (192.168.122.100 of this example) should support\nRDMA. To test a server supports RDMA or not:\n\n    % rdma res show (a new version iproute2 package)\nOr:\n\n    % ibv_devices\n\n\n# Playing with Valkey\n\nYou can use valkey-cli to play with Valkey. Start a valkey-server instance,\nthen in another terminal try the following:\n\n    % cd src\n    % ./valkey-cli\n    valkey> ping\n    PONG\n    valkey> set foo bar\n    OK\n    valkey> get foo\n    \"bar\"\n    valkey> incr mycounter\n    (integer) 1\n    valkey> incr mycounter\n    (integer) 2\n    valkey>\n\n# Installing Valkey\n\nIn order to install Valkey binaries into /usr/local/bin, just use:\n\n    % make install\n\nYou can use `make PREFIX=/some/other/directory install` if you wish to use a\ndifferent destination.\n\n_Note_: For compatibility with Redis, we create symlinks from the Redis names (`redis-server`, `redis-cli`, etc.) to the Valkey binaries installed by `make install`.\nThe symlinks are created in same directory as the Valkey binaries.\nThe symlinks are removed when using `make uninstall`.\nThe creation of the symlinks can be skipped by setting the makefile variable `USE_REDIS_SYMLINKS=no`.\n\n`make install` will just install binaries in your system, but will not configure\ninit scripts and configuration files in the appropriate place. This is not\nneeded if you just want to play a bit with Valkey, but if you are installing\nit the proper way for a production system, we have a script that does this\nfor Ubuntu and Debian systems:\n\n    % cd utils\n    % ./install_server.sh\n\n_Note_: `install_server.sh` will not work on macOS; it is built for Linux only.\n\nThe script will ask you a few questions and will setup everything you need\nto run Valkey properly as a background daemon that will start again on\nsystem reboots.\n\nYou'll be able to stop and start Valkey using the script named\n`/etc/init.d/valkey_<portnumber>`, for instance `/etc/init.d/valkey_6379`.\n\n# Building using `CMake`\n\nIn addition to the traditional `Makefile` build, Valkey supports an alternative, **experimental**, build system using `CMake`.\n\nTo build and install `Valkey`, in `Release` mode (an optimized build), type this into your terminal:\n\n```bash\nmkdir build-release\ncd $_\ncmake .. -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/opt/valkey\nsudo make install\n# Valkey is now installed under /opt/valkey\n```\n\nOther options supported by Valkey's `CMake` build system:\n\n## Special build flags\n\n- `-DBUILD_TLS=<yes|no>` enable TLS build for Valkey. Default: `no`\n- `-DBUILD_RDMA=<no|module>` enable RDMA module build (only module mode supported). Default: `no`\n- `-DBUILD_MALLOC=<libc|jemalloc|tcmalloc|tcmalloc_minimal>` choose the allocator to use. Default on Linux: `jemalloc`, for other OS: `libc`\n- `-DBUILD_SANITIZER=<address|thread|undefined>` build with address sanitizer enabled. Default: disabled (no sanitizer)\n- `-DBUILD_UNIT_TESTS=[yes|no]`  when set, the build will produce the executable `valkey-unit-tests`. Default: `no`\n- `-DBUILD_TEST_MODULES=[yes|no]`  when set, the build will include the modules located under the `tests/modules` folder. Default: `no`\n- `-DBUILD_EXAMPLE_MODULES=[yes|no]`  when set, the build will include the example modules located under the `src/modules` folder. Default: `no`\n\n## Common flags\n\n- `-DCMAKE_BUILD_TYPE=<Debug|Release...>` define the build type, see CMake manual for more details\n- `-DCMAKE_INSTALL_PREFIX=/installation/path` override this value to define a custom install prefix. Default: `/usr/local`\n- `-G\"<Generator Name>\"` generate build files for \"Generator Name\". By default, CMake will generate `Makefile`s.\n\n## Verbose build\n\n`CMake` generates a user-friendly colorized output by default.\nIf you want to see a more verbose output, use the following:\n\n```bash\nmake VERBOSE=1\n```\n\n## Troubleshooting\n\nDuring the `CMake` stage, `CMake` caches variables in a local file named `CMakeCache.txt`. All variables generated by Valkey\nare removed from the cache once consumed (this is done by calling to `unset(VAR-NAME CACHE)`). However, some variables,\nlike the compiler path, are kept in cache. To start a fresh build either remove the cache file `CMakeCache.txt` from the\nbuild folder, or delete the build folder completely.\n\n**It is important to re-run `CMake` when adding new source files.**\n\n## Integration with IDE\n\nDuring the `CMake` stage of the build, `CMake` generates a JSON file named `compile_commands.json` and places it under the\nbuild folder. This file is used by many IDEs and text editors for providing code completion (via `clangd`).\n\nA small caveat is that these tools will look for `compile_commands.json` under the Valkey's top folder.\nA common workaround is to create a symbolic link to it:\n\n```bash\ncd /path/to/valkey/\n# We assume here that your build folder is `build-release`\nln -sf $(pwd)/build-release/compile_commands.json $(pwd)/compile_commands.json\n```\n\nRestart your IDE and voila\n\n# Code contributions\n\nPlease see the [CONTRIBUTING.md][2]. For security bugs and vulnerabilities, please see [SECURITY.md][3].\n\n# Valkey is an open community project under LF Projects\n\nValkey a Series of LF Projects, LLC\n2810 N Church St, PMB 57274\nWilmington, Delaware 19802-4447\n\n[1]: https://github.com/valkey-io/valkey/blob/unstable/COPYING\n[2]: https://github.com/valkey-io/valkey/blob/unstable/CONTRIBUTING.md\n[3]: https://github.com/valkey-io/valkey/blob/unstable/SECURITY.md\n",
      "stars_today": 13
    },
    {
      "id": 119637215,
      "name": "Maccy",
      "full_name": "p0deje/Maccy",
      "description": "Lightweight clipboard manager for macOS",
      "html_url": "https://github.com/p0deje/Maccy",
      "stars": 18355,
      "forks": 831,
      "language": "Swift",
      "topics": [
        "clipboard-manager",
        "maccy",
        "macos"
      ],
      "created_at": "2018-01-31T05:01:53Z",
      "updated_at": "2026-01-24T00:31:39Z",
      "pushed_at": "2025-12-19T20:08:30Z",
      "open_issues": 119,
      "owner": {
        "login": "p0deje",
        "avatar_url": "https://avatars.githubusercontent.com/u/665846?v=4"
      },
      "readme": "\n<img width=\"128px\" src=\"https://maccy.app/img/maccy/Logo.png\" alt=\"Logo\" align=\"left\" />\n\n# [Maccy](https://maccy.app)\n\n[![Downloads](https://img.shields.io/github/downloads/p0deje/Maccy/total.svg)](https://github.com/p0deje/Maccy/releases/latest)\n[![Build Status](https://img.shields.io/bitrise/716921b669780314/master?token=3pMiCb5dpFzlO-7jTYtO3Q)](https://app.bitrise.io/app/716921b669780314)\n\nMaccy is a lightweight clipboard manager for macOS. It keeps the history of what you copy\nand lets you quickly navigate, search, and use previous clipboard contents.\n\nMaccy works on macOS Sonoma 14 or higher.\n\n<!-- vim-markdown-toc GFM -->\n\n* [Features](#features)\n* [Install](#install)\n* [Usage](#usage)\n* [Advanced](#advanced)\n  * [Ignore Copied Items](#ignore-copied-items)\n  * [Ignore Custom Copy Types](#ignore-custom-copy-types)\n  * [Speed up Clipboard Check Interval](#speed-up-clipboard-check-interval)\n* [FAQ](#faq)\n  * [Why doesn't it paste when I select an item in history?](#why-doesnt-it-paste-when-i-select-an-item-in-history)\n  * [When assigning a hotkey to open Maccy, it says that this hotkey is already used in some system setting.](#when-assigning-a-hotkey-to-open-maccy-it-says-that-this-hotkey-is-already-used-in-some-system-setting)\n  * [How to restore hidden footer?](#how-to-restore-hidden-footer)\n  * [How to ignore copies from Universal Clipboard?](#how-to-ignore-copies-from-universal-clipboard)\n  * [My keyboard shortcut stopped working in password fields. How do I fix this?](#my-keyboard-shortcut-stopped-working-in-password-fields-how-do-i-fix-this)\n* [Translations](#translations)\n* [Motivation](#motivation)\n* [License](#license)\n\n<!-- vim-markdown-toc -->\n\n## Features\n\n* Lightweight and fast\n* Keyboard-first\n* Secure and private\n* Native UI\n* Open source and free\n\n## Install\n\nDownload the latest version from the [releases](https://github.com/p0deje/Maccy/releases/latest) page, or use [Homebrew](https://brew.sh/):\n\n```sh\nbrew install maccy\n```\n\n## Usage\n\n1. <kbd>SHIFT (‚áß)</kbd> + <kbd>COMMAND (‚åò)</kbd> + <kbd>C</kbd> to popup Maccy or click on its icon in the menu bar.\n2. Type what you want to find.\n3. To select the history item you wish to copy, press <kbd>ENTER</kbd>, or click the item, or use <kbd>COMMAND (‚åò)</kbd> + `n` shortcut.\n4. To choose the history item and paste, press <kbd>OPTION (‚å•)</kbd> + <kbd>ENTER</kbd>, or <kbd>OPTION (‚å•)</kbd> + <kbd>CLICK</kbd> the item, or use <kbd>OPTION (‚å•)</kbd> + `n` shortcut.\n5. To choose the history item and paste without formatting, press <kbd>OPTION (‚å•)</kbd> + <kbd>SHIFT (‚áß)</kbd> + <kbd>ENTER</kbd>, or <kbd>OPTION (‚å•)</kbd> + <kbd>SHIFT (‚áß)</kbd> + <kbd>CLICK</kbd> the item, or use <kbd>OPTION (‚å•)</kbd> + <kbd>SHIFT (‚áß)</kbd> + `n` shortcut.\n6. To delete the history item, press <kbd>OPTION (‚å•)</kbd> + <kbd>DELETE (‚å´)</kbd>.\n7. To see the full text of the history item, wait a couple of seconds for tooltip.\n8. To pin the history item so that it remains on top of the list, press <kbd>OPTION (‚å•)</kbd> + <kbd>P</kbd>. The item will be moved to the top with a random but permanent keyboard shortcut. To unpin it, press <kbd>OPTION (‚å•)</kbd> + <kbd>P</kbd> again.\n9. To clear all unpinned items, select _Clear_ in the menu, or press <kbd>OPTION (‚å•)</kbd> + <kbd>COMMAND (‚åò)</kbd> + <kbd>DELETE (‚å´)</kbd>. To clear all items including pinned, select _Clear_ in the menu with  <kbd>OPTION (‚å•)</kbd> pressed, or press <kbd>SHIFT (‚áß)</kbd> + <kbd>OPTION (‚å•)</kbd> + <kbd>COMMAND (‚åò)</kbd> + <kbd>DELETE (‚å´)</kbd>.\n10. To disable Maccy and ignore new copies, click on the menu icon with <kbd>OPTION (‚å•)</kbd> pressed.\n11. To ignore only the next copy, click on the menu icon with <kbd>OPTION (‚å•)</kbd> + <kbd>SHIFT (‚áß)</kbd> pressed.\n12. To customize the behavior, check \"Preferences‚Ä¶\" window, or press <kbd>COMMAND (‚åò)</kbd> + <kbd>,</kbd>.\n\n## Advanced\n\n### Ignore Copied Items\n\nYou can tell Maccy to ignore all copied items:\n\n```sh\ndefaults write org.p0deje.Maccy ignoreEvents true # default is false\n```\n\nThis is useful if you have some workflow for copying sensitive data. You can set `ignoreEvents` to true, copy the data and set `ignoreEvents` back to false.\n\nYou can also click the menu icon with <kbd>OPTION (‚å•)</kbd> pressed. To ignore only the next copy, click with <kbd>OPTION (‚å•)</kbd> + <kbd>SHIFT (‚áß)</kbd> pressed.\n\n### Ignore Custom Copy Types\n\nBy default Maccy will ignore certain copy types that are considered to be confidential\nor temporary. The default list always include the following types:\n\n* `org.nspasteboard.TransientType`\n* `org.nspasteboard.ConcealedType`\n* `org.nspasteboard.AutoGeneratedType`\n\nAlso, default configuration includes the following types but they can be removed\nor overwritten:\n\n* `com.agilebits.onepassword`\n* `com.typeit4me.clipping`\n* `de.petermaurer.TransientPasteboardType`\n* `Pasteboard generator type`\n* `net.antelle.keeweb`\n\nYou can add additional custom types using settings.\nTo find what custom types are used by an application, you can use\nfree application [Pasteboard-Viewer](https://github.com/sindresorhus/Pasteboard-Viewer).\nSimply download the application, open it, copy something from the application you\nwant to ignore and look for any custom types in the left sidebar. [Here is an example\nof using this approach to ignore Adobe InDesign](https://github.com/p0deje/Maccy/issues/125).\n\n### Speed up Clipboard Check Interval\n\nBy default, Maccy checks clipboard every 500 ms, which should be enough for most users. If you want\nto speed it up, you can change it with `defaults`:\n\n```sh\ndefaults write org.p0deje.Maccy clipboardCheckInterval 0.1 # 100 ms\n```\n\n## FAQ\n\n### Why doesn't it paste when I select an item in history?\n\n1. Make sure you have \"Paste automatically\" enabled in Preferences.\n2. Make sure \"Maccy\" is added to System Settings -> Privacy & Security -> Accessibility.\n\n### When assigning a hotkey to open Maccy, it says that this hotkey is already used in some system setting.\n\n1. Open System settings -> Keyboard -> Keyboard Shortcuts.\n2. Find where that hotkey is used. For example, \"Convert text to simplified Chinese\" is under Services -> Text.\n3. Disable that hotkey or remove assigned combination ([screenshot](https://github.com/p0deje/Maccy/assets/576152/446719e6-c3e5-4eb0-95fb-5a811066487f)).\n4. Restart Maccy.\n5. Assign hotkey in Maccy settings.\n\n### How to restore hidden footer?\n\n1. Open Maccy window.\n2. Press <kbd>COMMAND (‚åò)</kbd> + <kbd>,</kbd> to open preferences.\n3. Enable footer in Appearance section.\n\nIf for some reason it doesn't work, run the following command in Terminal.app:\n\n```sh\ndefaults write org.p0deje.Maccy showFooter 1\n```\n\n### How to ignore copies from [Universal Clipboard](https://support.apple.com/en-us/102430)?\n\n1. Open Preferences -> Ignore -> Pasteboard Types.\n2. Add `com.apple.is-remote-clipboard`.\n\n### My keyboard shortcut stopped working in password fields. How do I fix this?\n\nIf your shortcut produces a character (like `Option+C` ‚Üí \"√ß\"), macOS security may block it in password fields. Use [Karabiner-Elements](https://karabiner-elements.pqrs.org/) to remap your shortcut to a different combination like `Cmd+Shift+C`. [See detailed solution](docs/keyboard-shortcut-password-fields.md).\n\n## Translations\n\nThe translations are hosted in [Weblate](https://hosted.weblate.org/engage/maccy/).\nYou can use it to suggest changes in translations and localize the application to a new language.\n\n[![Translation status](https://hosted.weblate.org/widget/maccy/multi-auto.svg)](https://hosted.weblate.org/engage/maccy/)\n\n## Motivation\n\nThere are dozens of similar applications out there, so why build another?\nOver the past years since I moved from Linux to macOS, I struggled to find\na clipboard manager that is as free and simple as [Parcellite](http://parcellite.sourceforge.net),\nbut I couldn't. So I've decided to build one.\n\nAlso, I wanted to learn Swift and get acquainted with macOS application development.\n\n\n## License\n\n[MIT](./LICENSE)\n",
      "stars_today": 13
    },
    {
      "id": 656264456,
      "name": "langchain4j",
      "full_name": "langchain4j/langchain4j",
      "description": "LangChain4j is an open-source Java library that simplifies the integration of LLMs into Java applications through a unified API, providing access to popular LLMs and vector databases. It makes implementing RAG, tool calling (including support for MCP), and agents easy. LangChain4j integrates seamlessly with various enterprise Java frameworks.",
      "html_url": "https://github.com/langchain4j/langchain4j",
      "stars": 10494,
      "forks": 1919,
      "language": "Java",
      "topics": [
        "anthropic",
        "chatgpt",
        "chroma",
        "embeddings",
        "gemini",
        "gpt",
        "huggingface",
        "java",
        "langchain",
        "llama",
        "llm",
        "llms",
        "milvus",
        "ollama",
        "onnx",
        "openai",
        "openai-api",
        "pgvector",
        "pinecone",
        "vector-database"
      ],
      "created_at": "2023-06-20T15:30:29Z",
      "updated_at": "2026-01-23T16:29:30Z",
      "pushed_at": "2026-01-22T13:42:55Z",
      "open_issues": 676,
      "owner": {
        "login": "langchain4j",
        "avatar_url": "https://avatars.githubusercontent.com/u/132277850?v=4"
      },
      "readme": "# LangChain for Java: Supercharge your Java application with the power of LLMs\n\n[![Build Status](https://img.shields.io/github/actions/workflow/status/langchain4j/langchain4j/main.yaml?branch=main&style=for-the-badge&label=CI%20BUILD&logo=github)](https://github.com/langchain4j/langchain4j/actions/workflows/main.yaml)\n[![Nightly Build](https://img.shields.io/github/actions/workflow/status/langchain4j/langchain4j/nightly_jdk17.yaml?branch=main&style=for-the-badge&label=NIGHTLY%20BUILD&logo=github)](https://github.com/langchain4j/langchain4j/actions/workflows/nightly_jdk17.yaml)\n[![CODACY](https://img.shields.io/badge/Codacy-Dashboard-blue?style=for-the-badge&logo=codacy)](https://app.codacy.com/gh/langchain4j/langchain4j/dashboard)\n\n[![Discord](https://img.shields.io/discord/1156626270772269217?logo=discord&style=for-the-badge)](https://discord.gg/JzTFvyjG6R)\n[![BlueSky](https://img.shields.io/badge/@langchain4j-follow-blue?logo=bluesky&style=for-the-badge)](https://bsky.app/profile/langchain4j.dev)\n[![X](https://img.shields.io/badge/@langchain4j-follow-blue?logo=x&style=for-the-badge)](https://x.com/langchain4j)\n[![Maven Version](https://img.shields.io/maven-central/v/dev.langchain4j/langchain4j?logo=apachemaven&style=for-the-badge)](https://search.maven.org/#search|gav|1|g:\"dev.langchain4j\"%20AND%20a:\"langchain4j\")\n\n\n## Introduction\n\nWelcome!\n\nThe goal of LangChain4j is to simplify integrating LLMs into Java applications.\n\nHere's how:\n1. **Unified APIs:**\n   LLM providers (like OpenAI or Google Vertex AI) and embedding (vector) stores (such as Pinecone or Milvus)\n   use proprietary APIs. LangChain4j offers a unified API to avoid the need for learning and implementing specific APIs for each of them.\n   To experiment with different LLMs or embedding stores, you can easily switch between them without the need to rewrite your code.\n   LangChain4j currently supports [20+ popular LLM providers](https://docs.langchain4j.dev/integrations/language-models/)\n   and [30+ embedding stores](https://docs.langchain4j.dev/integrations/embedding-stores/).\n2. **Comprehensive Toolbox:**\n   Since early 2023, the community has been building numerous LLM-powered applications,\n   identifying common abstractions, patterns, and techniques. LangChain4j has refined these into practical code.\n   Our toolbox includes tools ranging from low-level prompt templating, chat memory management, and function calling\n   to high-level patterns like Agents and RAG.\n   For each abstraction, we provide an interface along with multiple ready-to-use implementations based on common techniques.\n   Whether you're building a chatbot or developing a RAG with a complete pipeline from data ingestion to retrieval,\n   LangChain4j offers a wide variety of options.\n3. **Numerous Examples:**\n   These [examples](https://github.com/langchain4j/langchain4j-examples) showcase how to begin creating various LLM-powered applications,\n   providing inspiration and enabling you to start building quickly.\n\nLangChain4j began development in early 2023 amid the ChatGPT hype.\nWe noticed a lack of Java counterparts to the numerous Python and JavaScript LLM libraries and frameworks,\nand we had to fix that!\nAlthough \"LangChain\" is in our name, the project is a fusion of ideas and concepts from LangChain, Haystack,\nLlamaIndex, and the broader community, spiced up with a touch of our own innovation.\n\nWe actively monitor community developments, aiming to quickly incorporate new techniques and integrations,\nensuring you stay up-to-date.\nThe library is under active development. While some features are still being worked on,\nthe core functionality is in place, allowing you to start building LLM-powered apps now!\n\n\n## Documentation\nDocumentation can be found [here](https://docs.langchain4j.dev).\n\nThe documentation chatbot (experimental) can be found [here](https://chat.langchain4j.dev/).\n\n\n## Getting Started\nGetting started guide can be found [here](https://docs.langchain4j.dev/get-started).\n\n\n## Code Examples\nPlease see examples of how LangChain4j can be used in [langchain4j-examples](https://github.com/langchain4j/langchain4j-examples) repo:\n- [Examples in plain Java](https://github.com/langchain4j/langchain4j-examples/tree/main/other-examples/src/main/java)\n- [Examples with Quarkus](https://github.com/quarkiverse/quarkus-langchain4j/tree/main/samples) (uses [quarkus-langchain4j](https://github.com/quarkiverse/quarkus-langchain4j) dependency)\n- [Example with Spring Boot](https://github.com/langchain4j/langchain4j-examples/tree/main/spring-boot-example/src/main/java/dev/langchain4j/example)\n- [Examples with Helidon](https://github.com/helidon-io/helidon-examples/tree/helidon-4.x/examples/integrations/langchain4j) (uses [io.helidon.integrations.langchain4j](https://mvnrepository.com/artifact/io.helidon.integrations.langchain4j) dependency)\n- [Examples with Micronaut](https://github.com/micronaut-projects/micronaut-langchain4j/tree/0.3.x/doc-examples/example-openai-java) (uses [micronaut-langchain4j](https://micronaut-projects.github.io/micronaut-langchain4j/latest/guide/) dependency)\n\n## Useful Materials\nUseful materials can be found [here](https://docs.langchain4j.dev/useful-materials).\n\n\n## Get Help\nPlease use [Discord](https://discord.gg/JzTFvyjG6R) or [GitHub discussions](https://github.com/langchain4j/langchain4j/discussions)\nto get help.\n\n\n## Request Features\nPlease let us know what features you need by [opening an issue](https://github.com/langchain4j/langchain4j/issues/new/choose).\n\n\n## Contribute\nContribution guidelines can be found [here](https://github.com/langchain4j/langchain4j/blob/main/CONTRIBUTING.md).\n",
      "stars_today": 13
    },
    {
      "id": 1055223285,
      "name": "claudesidian",
      "full_name": "heyitsnoah/claudesidian",
      "description": null,
      "html_url": "https://github.com/heyitsnoah/claudesidian",
      "stars": 1589,
      "forks": 129,
      "language": "JavaScript",
      "topics": [],
      "created_at": "2025-09-12T00:40:48Z",
      "updated_at": "2026-01-23T22:17:23Z",
      "pushed_at": "2026-01-13T22:48:29Z",
      "open_issues": 12,
      "owner": {
        "login": "heyitsnoah",
        "avatar_url": "https://avatars.githubusercontent.com/u/144188?v=4"
      },
      "readme": "# Claudesidian: Claude Code + Obsidian Starter Kit\n\nTurn your Obsidian vault into an AI-powered second brain using Claude Code.\n\n## What is this?\n\nThis is a pre-configured Obsidian vault structure designed to work seamlessly\nwith Claude Code, enabling you to:\n\n- Use AI as a thinking partner, not just a writing assistant\n- Organize knowledge using the PARA method\n- Maintain version control with Git\n- Access your vault from anywhere (including mobile)\n\n## Quick Start\n\n### 1. Get the Starter Kit\n\n**Option A: Clone with Git**\n\n```bash\n# Clone with your preferred folder name (replace 'my-vault' with any name you like)\ngit clone https://github.com/heyitsnoah/claudesidian.git my-vault\ncd my-vault\n\n# Examples:\n# git clone https://github.com/heyitsnoah/claudesidian.git obsidian-notes\n# git clone https://github.com/heyitsnoah/claudesidian.git knowledge-base\n# git clone https://github.com/heyitsnoah/claudesidian.git second-brain\n```\n\n**Option B: Download ZIP (no Git required)**\n\n1. Click \"Code\" ‚Üí \"Download ZIP\" on GitHub\n2. Extract to your desired location\n3. Open the folder in Claude Code\n\n### 2. Run the Setup Wizard\n\n```bash\n# Start Claude Code in the directory\nclaude\n\n# Run the interactive setup wizard (in Claude Code)\n/init-bootstrap\n```\n\nThis will:\n\n- Install dependencies automatically\n- Disconnect from the original claudesidian repository\n- **Intelligently analyze** your existing vault structure and patterns\n- **Import your existing Obsidian vault** safely to OLD_VAULT/ (if you have one)\n- **Research your public work** for personalized context (with your permission)\n- Ask you about your workflow preferences\n- Create a personalized CLAUDE.md configuration\n- Set up your folder structure\n- Optionally configure Gemini Vision for image/video analysis\n- Optionally configure Firecrawl for web research\n- Initialize Git for version control\n\n### 3. Open in Obsidian (Optional but Recommended)\n\n- Download [Obsidian](https://obsidian.md)\n- Open vault from the claudesidian folder\n- This gives you a visual interface alongside Claude Code\n\n### 4. Your First Session\n\nTell Claude Code:\n\n```\nI'm starting a new project about [topic].\nI'm in thinking mode, not writing mode.\nPlease search my vault for any relevant existing notes,\nthen help me explore this topic by asking questions.\n```\n\nOr use one of the pre-configured commands (in Claude Code):\n\n```\n/thinking-partner   # For collaborative exploration\n/daily-review       # For end-of-day reflection\n/research-assistant # For deep dives into topics\n```\n\n## Folder Structure\n\n```\nclaudesidian/\n‚îú‚îÄ‚îÄ 00_Inbox/           # Temporary capture point for new ideas\n‚îú‚îÄ‚îÄ 01_Projects/        # Active, time-bound initiatives\n‚îú‚îÄ‚îÄ 02_Areas/           # Ongoing responsibilities\n‚îú‚îÄ‚îÄ 03_Resources/       # Reference materials and knowledge base\n‚îú‚îÄ‚îÄ 04_Archive/         # Completed projects and inactive items\n‚îú‚îÄ‚îÄ 05_Attachments/     # Images, PDFs, and other files\n‚îú‚îÄ‚îÄ 06_Metadata/        # Vault configuration and templates\n‚îÇ   ‚îú‚îÄ‚îÄ Reference/      # Documentation and guides\n‚îÇ   ‚îî‚îÄ‚îÄ Templates/      # Reusable note templates\n‚îî‚îÄ‚îÄ .scripts/           # Helper scripts for automation\n```\n\n## Key Concepts\n\n### Thinking Mode vs Writing Mode\n\n**Thinking Mode** (Research & Exploration):\n\n- Claude asks questions to understand your goals\n- Searches existing notes for relevant content\n- Helps make connections between ideas\n- Maintains a log of insights and progress\n\n**Writing Mode** (Content Creation):\n\n- Generates drafts based on your research\n- Helps structure and edit content\n- Creates final deliverables\n\n### The PARA Method\n\n**Projects**: Have a deadline and specific outcome\n\n- Example: \"Q4 2025 Marketing Strategy\"\n- Create a folder in `01_Projects/`\n\n**Areas**: Ongoing without an end date\n\n- Example: \"Health\", \"Finances\", \"Team Management\"\n- Lives in `02_Areas/`\n\n**Resources**: Topics of ongoing interest\n\n- Example: \"AI Research\", \"Writing Tips\"\n- Store in `03_Resources/`\n\n**Archive**: Inactive items\n\n- Completed projects with their outputs\n- Old notes no longer relevant\n\n## Claude Code Commands\n\nPre-configured AI assistants ready to use:\n\n- `thinking-partner` - Explore ideas through questions\n- `inbox-processor` - Organize your captures\n- `research-assistant` - Deep dive into topics\n- `daily-review` - End of day reflection\n- `weekly-synthesis` - Find patterns in your week\n- `create-command` - Build new custom commands\n- `de-ai-ify` - Remove AI writing patterns from text\n- `upgrade` - Update to the latest claudesidian version\n- `init-bootstrap` - Re-run the setup wizard\n- `install-claudesidian-command` - Install shell command to launch vault from\n  anywhere\n\nRun with: `/[command-name]` in Claude Code\n\n### Staying Updated with `/upgrade`\n\nClaudesidian automatically checks for updates when you start Claude Code and\nwill remind you to run `/upgrade` when new features are available.\n\nThe upgrade command intelligently merges new features while preserving your\ncustomizations:\n\n```bash\n# Preview what would be updated (recommended first)\n/upgrade check\n\n# Run the interactive upgrade\n/upgrade\n\n# Skip confirmations for safe updates (advanced)\n/upgrade force\n```\n\n**What the upgrade does:**\n\n- Creates a timestamped backup before making any changes\n- Shows you diffs for each file before updating\n- Preserves your personal notes and customizations\n- Only updates system files (commands, agents, scripts)\n- Never touches your content folders (00_Inbox, 01_Projects, etc.)\n- Provides rollback capability if needed\n\n**Safety features:**\n\n- All your personal content is protected\n- Complete backup created in `.backup/upgrade-[timestamp]/`\n- File-by-file review and confirmation\n- Progress tracked in `.upgrade-checklist.md`\n- Can be stopped and resumed at any time\n\n## Vision & Document Analysis (Optional)\n\nWith [Google Gemini](https://ai.google.dev/) MCP configured, Claude Code can\nprocess your attachments directly without having to describe them. This means:\n\n- **Direct image analysis**: Claude sees the actual image, not your description\n- **PDF text extraction**: Full document text without copy-pasting\n- **Bulk processing**: Analyze multiple screenshots or documents at once\n- **Smart organization**: Auto-generate filenames based on image content\n- **Comparison tasks**: Compare before/after screenshots, designs, etc.\n\n**Why this matters**: Instead of describing \"a screenshot showing an error\nmessage\", Claude Code directly sees and reads the error. Perfect for debugging\nUI issues, analyzing charts, or processing scanned documents.\n\n**Getting a Gemini API key:**\n\n1. Visit [Google AI Studio](https://aistudio.google.com)\n2. Sign in with your Google account\n3. Click \"Get API key\" in the left sidebar\n4. Create a new API key (it's free!)\n5. Set it in your environment: `export GEMINI_API_KEY=\"your-key-here\"`\n\nSee `.claude/mcp-servers/README.md` for full setup instructions\n\n## Web Research (Optional)\n\nWith [Firecrawl](https://www.firecrawl.dev/) configured, our helper scripts\nfetch and save full web content directly to your vault. This means:\n\n- **Full text capture**: Scripts pipe complete article text to files, not\n  summaries\n- **Context preservation**: Claude doesn't need to hold web content in memory\n- **Batch processing**: Save multiple articles at once with `firecrawl-batch.sh`\n- **Clean markdown**: Web pages converted to readable, searchable markdown\n- **Permanent archive**: Your research stays in your vault forever\n\n**Why this matters**: Instead of Claude reading a webpage and summarizing it\n(losing detail), the scripts save the FULL text. Claude can then search and\nanalyze thousands of saved articles without hitting context limits. Perfect for\nresearch projects, documentation archives, or building a knowledge base.\n\n**Example workflow:**\n\n```bash\n# Save a single article\nnpm run firecrawl:scrape -- \"https://example.com/article\" \"03_Resources/Articles\"\n\n# Batch save multiple URLs\nnpm run firecrawl:batch -- urls.txt \"03_Resources/Research\"\n```\n\n**Getting a Firecrawl API key:**\n\n1. Visit [Firecrawl](https://www.firecrawl.dev) and sign up\n2. Get 300 free credits to start (open-source, can self-host)\n3. Go to your dashboard to find your API key\n4. Copy the key (format: `fc-xxxxx...`)\n5. Set it in your environment: `export FIRECRAWL_API_KEY=\"fc-your-key-here\"`\n\n## Helper Scripts\n\nRun these with `pnpm`:\n\n- `attachments:list` - Show unprocessed attachments\n- `attachments:organized` - Count organized files\n- `attachments:sizes` - Find large files\n- `attachments:orphans` - Find unreferenced attachments\n- `vault:stats` - Show vault statistics\n\n## Advanced Setup\n\n### Quick Launch from Anywhere\n\nInstall a shell command to launch your vault from any directory:\n\n```bash\n# In Claude Code, run:\n/install-claudesidian-command\n```\n\nThis creates a `claudesidian` alias that:\n\n- Changes to your vault directory automatically\n- Tries to resume your existing session (if one exists)\n- Falls back to starting a new session\n- Returns to your original directory when done\n\n**Usage:**\n\n```bash\n# From anywhere in your terminal:\nclaudesidian\n\n# It will automatically resume your last session or start a new one\n```\n\nThe command is added to your shell config (~/.zshrc, ~/.bashrc, etc.) so it\npersists across terminal sessions.\n\n### Git Integration\n\nInitialize Git for version control:\n\n```bash\ngit init\ngit add .\ngit commit -m \"Initial vault setup\"\ngit remote add origin your-repo-url\ngit push -u origin main\n```\n\nBest practices:\n\n- Commit after each work session\n- Use descriptive commit messages\n- Pull before starting work\n\n### Mobile Access\n\n1. Set up a small server (mini PC, cloud VPS, or home server)\n2. Install Tailscale for secure VPN access\n3. Clone your vault to the server\n4. Use Termius or similar SSH client on mobile\n5. Run Claude Code remotely\n\n### Custom Commands\n\nCreate specialized commands by saving instructions in `.claude/commands/`:\n\n**Research Assistant** (`06_Metadata/Agents/research-assistant.md`):\n\n```markdown\nYou are a research assistant.\n\n- Search the vault for relevant information\n- Synthesize findings from multiple sources\n- Identify gaps in knowledge\n- Suggest areas for further exploration\n```\n\n## Tips & Best Practices\n\n### From Experience\n\n1. **Start in thinking mode**: Resist the urge to generate content immediately\n2. **Be a token maximalist**: More context = better results\n3. **Save everything**: Capture chats, fragments, partial thoughts\n4. **Trust but verify**: Always read AI-generated content\n5. **Break your flow**: AI helps you resume easily\n\n## Troubleshooting\n\n### Claude Code can't find my notes\n\n- Make sure you're running Claude Code from the vault root directory\n- Check file permissions\n- Verify markdown files have `.md` extension\n\n### Git conflicts\n\n- Always pull before starting work\n- Commit frequently with clear messages\n- Use branches for experimental changes\n\n### Attachment management\n\n- Run `npm run attachments:create-organized` to set up folders\n- Use helper scripts to find orphaned files\n- Keep attachments under 10MB for Git\n\n## Philosophy\n\nThis setup is based on key principles:\n\n1. **AI amplifies thinking, not just writing**\n2. **Local files = full control**\n3. **Structure enables creativity**\n4. **Iteration beats perfection**\n5. **The goal is insight, not just information**\n\n## Contributing\n\nWe welcome contributions from the community! This is a living template that gets\nbetter with everyone's input.\n\n### How to Contribute\n\n1. **Fork the repository** on GitHub\n2. **Create a feature branch** (`git checkout -b feature/amazing-feature`)\n3. **Make your changes**\n4. **Test your changes** to ensure everything works\n5. **Commit your changes** (`git commit -m 'Add amazing feature'`)\n6. **Push to the branch** (`git push origin feature/amazing-feature`)\n7. **Open a Pull Request** with a clear description of what you've done\n\n### What We're Looking For\n\n- **New commands**: Useful Claude Code commands for common workflows\n- **New agents**: Specialized agents for specific tasks\n- **Documentation improvements**: Better explanations, examples, or guides\n- **Bug fixes**: Found something broken? Fix it!\n- **Workflow templates**: Share your productive workflows\n- **Helper scripts**: Automation tools that make vault management easier\n- **Integration guides**: Connect Claudesidian with other tools\n- **Core updates**: Improvements to the upgrade system, setup wizard, or other\n  core features\n\n### Guidelines\n\n- Keep commands focused and single-purpose\n- Write clear documentation with examples\n- Test thoroughly before submitting\n- Follow existing code style and structure\n- Update the CHANGELOG.md with your changes\n- **AI-generated content is welcome, but you MUST carefully read and review\n  everything before submitting** - never submit code you don't understand\n\n### Getting Updates\n\nWhen new features are contributed and merged, users can easily get them with:\n\n```bash\n/upgrade\n```\n\nThe upgrade command intelligently merges new features while preserving your\npersonal customizations, making it easy to benefit from community contributions\nwithout losing your work.\n\n### Questions or Ideas?\n\n- Open an issue to discuss major changes before starting work\n- Join discussions in existing issues\n- Share your use cases - they help us understand needs better\n\nRemember: best practices emerge from use, not theory. Your real-world experience\nmakes this better for everyone!\n\n## Resources\n\n- [Obsidian Documentation](https://help.obsidian.md)\n- [PARA Method](https://fortelabs.com/blog/para/)\n- [Claude Code Documentation](https://claude.ai/docs)\n\n## Inspiration\n\nThis starter kit was inspired by the workflows discussed in:\n\n- [How to Use Claude Code as a Second Brain](https://every.to/podcast/how-to-use-claude-code-as-a-thinking-partner) -\n  Noah Brier's interview with Dan Shipper\n- Built by the team at [Alephic](https://alephic.com) - an AI-first strategy and\n  software partner that helps organizations solve complex challenges through\n  custom AI systems\n\n## License\n\nMIT - Use this however you want. Make it your own.\n\n---\n\n_Remember: The bicycle feels wobbly at first, then you forget it was ever hard._\n",
      "stars_today": 13
    },
    {
      "id": 156939672,
      "name": "onnxruntime",
      "full_name": "microsoft/onnxruntime",
      "description": "ONNX Runtime: cross-platform, high performance ML inferencing and training accelerator",
      "html_url": "https://github.com/microsoft/onnxruntime",
      "stars": 19066,
      "forks": 3665,
      "language": "C++",
      "topics": [
        "ai-framework",
        "deep-learning",
        "hardware-acceleration",
        "machine-learning",
        "neural-networks",
        "onnx",
        "pytorch",
        "scikit-learn",
        "tensorflow"
      ],
      "created_at": "2018-11-10T02:22:53Z",
      "updated_at": "2026-01-24T01:38:39Z",
      "pushed_at": "2026-01-24T02:04:51Z",
      "open_issues": 1227,
      "owner": {
        "login": "microsoft",
        "avatar_url": "https://avatars.githubusercontent.com/u/6154722?v=4"
      },
      "readme": "<p align=\"center\"><img width=\"50%\" src=\"docs/images/ONNX_Runtime_logo_dark.png\" /></p>\n\n**ONNX Runtime is a cross-platform inference and training machine-learning accelerator**.\n\n**ONNX Runtime inference** can enable faster customer experiences and lower costs, supporting models from deep learning frameworks such as PyTorch and TensorFlow/Keras as well as classical machine learning libraries such as scikit-learn, LightGBM, XGBoost, etc. ONNX Runtime is compatible with different hardware, drivers, and operating systems, and provides optimal performance by leveraging hardware accelerators where applicable alongside graph optimizations and transforms. [Learn more &rarr;](https://www.onnxruntime.ai/docs/#onnx-runtime-for-inferencing)\n\n**ONNX Runtime training** can accelerate the model training time on multi-node NVIDIA GPUs for transformer models with a one-line addition for existing PyTorch training scripts. [Learn more &rarr;](https://www.onnxruntime.ai/docs/#onnx-runtime-for-training)\n\n## Get Started & Resources\n\n* **General Information**: [onnxruntime.ai](https://onnxruntime.ai)\n\n* **Usage documentation and tutorials**: [onnxruntime.ai/docs](https://onnxruntime.ai/docs)\n\n* **YouTube video tutorials**: [youtube.com/@ONNXRuntime](https://www.youtube.com/@ONNXRuntime)\n\n* [**Upcoming Release Roadmap**](https://onnxruntime.ai/roadmap)\n\n* **Companion sample repositories**:\n  - ONNX Runtime Inferencing: [microsoft/onnxruntime-inference-examples](https://github.com/microsoft/onnxruntime-inference-examples)\n  - ONNX Runtime Training: [microsoft/onnxruntime-training-examples](https://github.com/microsoft/onnxruntime-training-examples)\n\n## Releases\n\nThe current release and past releases can be found here: https://github.com/microsoft/onnxruntime/releases.\n\nFor details on the upcoming release, including release dates, announcements, features, and guidance on submitting feature requests, please visit the release roadmap: https://onnxruntime.ai/roadmap.\n\n## Data/Telemetry\n\nWindows distributions of this project may collect usage data and send it to Microsoft to help improve our products and services. See the [privacy statement](docs/Privacy.md) for more details.\n\n## Contributions and Feedback\n\nWe welcome contributions! Please see the [contribution guidelines](CONTRIBUTING.md).\n\nFor feature requests or bug reports, please file a [GitHub Issue](https://github.com/Microsoft/onnxruntime/issues).\n\nFor general discussion or questions, please use [GitHub Discussions](https://github.com/microsoft/onnxruntime/discussions).\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)\nor contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## License\n\nThis project is licensed under the [MIT License](LICENSE).\n",
      "stars_today": 12
    },
    {
      "id": 94173064,
      "name": "filestash",
      "full_name": "mickael-kerjean/filestash",
      "description": ":file_folder: File Management Platform / Universal Data Access Gateway (without FUSE)",
      "html_url": "https://github.com/mickael-kerjean/filestash",
      "stars": 13481,
      "forks": 953,
      "language": "JavaScript",
      "topics": [
        "archiving",
        "azure",
        "dms",
        "dropbox",
        "edrms",
        "ftp",
        "ged",
        "git",
        "ipfs",
        "mft",
        "nfs",
        "s3",
        "sae",
        "seda",
        "sftp",
        "sharepoint",
        "smb",
        "vfs",
        "webdav"
      ],
      "created_at": "2017-06-13T05:34:14Z",
      "updated_at": "2026-01-23T22:23:10Z",
      "pushed_at": "2026-01-23T03:54:00Z",
      "open_issues": 67,
      "owner": {
        "login": "mickael-kerjean",
        "avatar_url": "https://avatars.githubusercontent.com/u/13233076?v=4"
      },
      "readme": "![screenshot](https://raw.githubusercontent.com/mickael-kerjean/filestash_images/master/.assets/photo.jpg)\n\n# What is this?\n\n<p>\n    It started as a storage agnostic Dropbox-like file manager that works with every storage protocol: <a href=\"https://www.filestash.app/ftp-client.html\">FTP</a>, <a href=\"https://www.filestash.app/ssh-file-transfer.html\">SFTP</a>, <a href=\"https://www.filestash.app/s3-browser.html\">S3</a>, <a href=\"https://www.filestash.app/smb-client.html\">SMB</a>, <a href=\"https://www.filestash.app/webdav-client.html\">WebDAV</a>, IPFS, and <a href=\"https://www.filestash.app/docs/plugin/#storage\">about 20 more</a>.\n</p>\n<p>\n    It grew into a universal data access platform with <a href=\"https://www.filestash.app/docs/guide/virtual-filesystem.html?origin=github\">virtual filesystem capabilities</a>, <a href=\"https://www.filestash.app/docs/api/?origin=github#api\">APIs</a>, and Gateways to expose your data over <a href=\"https://www.filestash.app/docs/guide/sftp-gateway.html?origin=github\">SFTP</a>, S3, and <a href=\"https://www.filestash.app/docs/guide/mcp-gateway.html?origin=github\">MCP</a> to give LLMs a limited view of your data:\n</p>\n\n<a href=\"http://demo.filestash.app\">\n    <img src=\"https://www.filestash.app/img/illustration/filestash-integrations.png\" alt=\"storage + auth architecture\" />\n</a>\n\n\n# Key Features\n\n<ul>\n    <li>A plugin based architecture with a minimal core that can be extended and customized through a rich <a href=\"https://www.filestash.app/docs/plugin/\">ecosystem of plugins</a>.</li>\n    <li>An awesome web client to access your data, built in vanilla JS, sleek, speedy, snappy, and infinitely customizable through our <a href=\"https://www.filestash.app/docs/guide/plugin-development.html#patch-plugins-in-depth\">dynamic patch plugins</a>.</li>\n    <li>A Workflow engine to enable automation and tons of integrations capabilities</li>\n    <li>Integrations with almost every storage system and authentication provider, with the explicit goal of supporting 100% of storage and auth technologies on the market (including unconventional ones like using <a href=\"https://github.com/mickael-kerjean/filestash/tree/master/server/plugin/plg_authenticate_wordpress\">WordPress as an IdP</a>).</li>\n    <li>The frontend can open virtually any file format using <a href=\"https://www.filestash.app/docs/guide/plugin-development.html#xdg-open-plugins-in-depth\">xdg-open plugins</a> that add renderers and additional buttons for formats not natively supported by browsers, from astronomy to embroidery and everything in between like:\n        <ul>\n            <li><a href=\"https://demo.filestash.app/assets/plugin/application_photography.zip\">photography</a>: heif, nef, raf, <a href=\"https://www.filestash.app/tools/tiff-viewer.html\">tiff</a>, raw, arw, sr2, srf, nrw, cr2, crw, x3f, pef, rw2, orf, mrw, mdc, mef, mos, dcr, kdc, 3fr, erf and srw</li>\n            <li><a href=\"https://demo.filestash.app/assets/plugin/application_photography.zip\">astronomy</a>: <a href=\"https://www.filestash.app/tools/fits-viewer.html\">fits</a>, <a href=\"https://www.filestash.app/tools/xisf-viewer.html\">xisf</a></li>\n            <li><a href=\"https://demo.filestash.app/assets/plugin/application_science.zip\">science</a>: with latex, plantuml & pandoc compilers</li>\n            <li><a href=\"https://demo.filestash.app/assets/plugin/application_musician.zip\">music</a>: mid, midi, gp4 and gp5</li>\n            <li><a href=\"https://demo.filestash.app/assets/plugin/application_gis.zip\">GIS</a>: <a href=\"https://www.filestash.app/tools/geojson-viewer.html\">geojson</a>, <a href=\"https://www.filestash.app/tools/shp-viewer.html\">shp</a>, gpx, wms and <a href=\"https://www.filestash.app/tools/dbf-viewer.html\">dbf</a></li>\n            <li><a href=\"https://demo.filestash.app/assets/plugin/application_engineering.zip\">data engineering</a>: <a href=\"https://www.filestash.app/tools/parquet-viewer.html\">parquet</a>, <a href=\"https://www.filestash.app/tools/arrow-viewer.html\">arrow</a>, <a href=\"https://www.filestash.app/tools/feather-viewer.html\">feather</a>, <a href=\"https://www.filestash.app/tools/avro-viewer.html\">avro</a>, <a href=\"https://www.filestash.app/tools/orc-viewer.html\">orc</a>, <a href=\"https://www.filestash.app/tools/hdf5-viewer.html\">hdf5</a>, <a href=\"https://www.filestash.app/tools/hdf5-viewer.html\">h5</a>, <a href=\"https://www.filestash.app/tools/netcdf-viewer.html\">netcdf</a>, <a href=\"https://www.filestash.app/tools/netcdf-viewer.html\">nc</a>, rds, rda and rdata</li>\n            <li><a href=\"https://demo.filestash.app/assets/plugin/application_dev.zip\">dev</a>: a, so, o, dylib, dll, tar, tgz, zip, har, cap, pcap, pcapng and <a href=\"https://www.filestash.app/tools/sqlite-viewer.html\">sqlite</a></li>\n            <li><a href=\"https://demo.filestash.app/assets/plugin/application_creative.zip\">creative work</a>: svg, <a href=\"https://www.filestash.app/tools/psd-viewer.html\">psd</a>, ai, <a href=\"https://www.filestash.app/tools/sketch-viewer.html\">sketch</a>, <a href=\"https://www.filestash.app/tools/cdr-viewer.html\">cdr</a>, woff, woff2, ttf, otf, eot, exr, tga, pgm, ppm, dds, ktx, dpx, pcx, xpm, pnm, xbm, aai, xwd, cin, pbm, pcd, sgi, wbmp and rgb</li>\n            <li><a href=\"https://demo.filestash.app/assets/plugin/application_biomed.zip\">biomedical</a>: dicom, sam, bam, cif, pdb, xyz, sdf, mol, mol2 and mmtf</li>\n            <li><a href=\"https://demo.filestash.app/assets/plugin/application_autodesk.zip\">autodesk</a>: <a href=\"https://www.filestash.app/tools/dwg-viewer.html\">dwg</a> and <a href=\"https://www.filestash.app/tools/dxf-viewer.html\">dxf</a></li>\n            <li><a href=\"https://demo.filestash.app/assets/plugin/application_adobe.zip\">adobe</a>: <a href=\"https://www.filestash.app/tools/psd-viewer.html\">psd</a>, ai, <a href=\"https://www.filestash.app/tools/xd-viewer.html\">xd</a>, <a href=\"https://www.filestash.app/tools/dng-viewer.html\">dng</a>, <a href=\"https://www.filestash.app/tools/eps-viewer.html\">postscript</a>, aco, ase, swf</li>\n            <li><a href=\"https://demo.filestash.app/assets/plugin/application_3d.zip\">3d</a>: fbx, gltf, obj, stl, step, mesh, ifc, dae</li>\n            <li><a href=\"https://demo.filestash.app/assets/plugin/application_embroidery.zip\">embroidery</a>: dgt, dst, dsb, dsz, edr, exp, 10o, col, hus, inf, jef, ksm, pcm, pcs, pes, sew, shv, sst, tap, u01, vip, vp3 and xxx</li>\n        </ul>\n    </li>\n    <li>Themes: <br>\n        <img src=\"https://www.filestash.app/img/screenshots/theme_github.png\" height=\"150\" />\n        <img src=\"https://www.filestash.app/img/screenshots/theme_apple.png\" height=\"150\" />\n        <img src=\"https://www.filestash.app/img/screenshots/theme_dropbox.png\" height=\"150\" />\n        <img src=\"https://www.filestash.app/img/screenshots/theme_ibm.png\" height=\"150\" />\n    </li>\n    <li>... and much <sub>much <sub>more (chromecast support, on demand video transcoding, mounting shared links as network drive, public site, antivirus, versioning, audit, quota, ....)</sub></sub><br> As a rule of thumb, if your problem involves files, we either already <a href=\"https://www.filestash.app/docs/plugin/\">have a plugin</a> for it or can make a plugin for it\n</ul>\n\n\n# Getting Started\n\nTo install Filestash, head to the [Getting started](https://www.filestash.app/docs/?origin=github) guide.\n\nIf you want to leverage plugins, head over to the [inventory](https://www.filestash.app/docs/plugin/?origin=github), or learn about [developing your own plugins](https://www.filestash.app/docs/guide/plugin-development.html?origin=github)\n\n\n# Vision & Philosophy\n\nOur goal is simple: **to build the best file management platform ever made. Period.** But \"best\" means different things to different people, and making Filestash modular is the only sane model to accomplish that. Anything that isn't a fundamental truth of the universe and might spark a debate belongs in a plugin. Literally every piece listed in the key features is a plugin you can swap for another implementation or remove entirely.\n\nThis modularity is made possible by the magic of programming interfaces. For example, if you want a [Dropbox-like frontend for FTP](https://news.ycombinator.com/item?id=9224), you will find out the [FTP plugin](https://github.com/mickael-kerjean/filestash/tree/master/server/plugin/plg_backend_ftp) simply implements this interface:\n```go\ntype IBackend interface {\n\tLs(path string) ([]os.FileInfo, error)           // list files in a folder\n\tStat(path string) (os.FileInfo, error)           // file stat\n\tCat(path string) (io.ReadCloser, error)          // download a file\n\tMkdir(path string) error                         // create a folder\n\tRm(path string) error                            // remove something\n\tMv(from string, to string) error                 // rename something\n\tSave(path string, file io.Reader) error          // save a file\n\tTouch(path string) error                         // create a file\n\n\t// I have omitted 2 other methods, a first one to enable connections reuse and\n\t// another one to declare what should the login form be like.\n}\n```\n\nThere are interfaces you can implement for every key component of Filestash: from storage, to authentication, authorisation, custom apps, search, thumbnailing, frontend patches, middleware, endpoint creation and a few others documented in the [plugin development guide](https://www.filestash.app/docs/guide/plugin-development.html).\n\nTo see what's currently installed in your instance, head over to [/about](https://demo.filestash.app/about). The inventory of plugins is [documented here](https://www.filestash.app/docs/plugin/)\n\n\n# Support\n\n- Commercial Users ‚Üí [support contract](https://www.filestash.app/pricing/?origin=github)\n- For individuals ‚Üí [#filestash](https://kiwiirc.com/nextclient/#irc://irc.libera.chat/#filestash?nick=guest??) on IRC (libera.chat).\n\nWant to help us sprinkle some toppings on our noodle cups?\n- Bitcoin: `3LX5KGmSmHDj5EuXrmUvcg77EJxCxmdsgW`\n- [Open Collective](https://opencollective.com/filestash)\n\n\n# Credits\n\nFilestash stands on the shoulder of: [contributors](https://github.com/mickael-kerjean/filestash/graphs/contributors), folks developing [awesome libraries](https://github.com/mickael-kerjean/filestash/blob/master/go.mod), a whole bunch of C stuff (the [C standard library](https://imgs.xkcd.com/comics/dependency.png), [libjpeg](https://libjpeg-turbo.org/), [libpng](https://www.libpng.org/pub/png/libpng.html), [libgif](https://giflib.sourceforge.net/), [libraw](https://www.libraw.org/about) and many more), [fontawesome](https://fontawesome.com), [material](https://material.io/icons/), [Browser stack](https://www.browserstack.com/) to let us test on real devices, and the many guys from Nebraska and elsewhere who have been thanklessly maintaining the critical pieces that Filestash sits on top:\n\n<img src=\"https://imgs.xkcd.com/comics/dependency.png\" alt=\"credit to the nebraska guy on xkcd\" />\n",
      "stars_today": 12
    },
    {
      "id": 370467085,
      "name": "AndroidMic",
      "full_name": "teamclouday/AndroidMic",
      "description": "Use your Android phone as a microphone for your PC",
      "html_url": "https://github.com/teamclouday/AndroidMic",
      "stars": 869,
      "forks": 55,
      "language": "Rust",
      "topics": [
        "android-application",
        "audio-streaming",
        "microphone",
        "rnnoise",
        "tcp-socket",
        "udp-socket",
        "usb-serial"
      ],
      "created_at": "2021-05-24T19:44:17Z",
      "updated_at": "2026-01-24T02:04:26Z",
      "pushed_at": "2025-12-27T23:55:28Z",
      "open_issues": 47,
      "owner": {
        "login": "teamclouday",
        "avatar_url": "https://avatars.githubusercontent.com/u/22620163?v=4"
      },
      "readme": "<p align=\"center\">\n  <img align=\"center\" src=\"./Assets/app_icon.svg\" alt=\"app icon\" width=\"80px\" />\n  <h1 align=\"center\" style=\"display: inline-block; margin-left: 12px; vertical-align: middle;\">AndroidMic</h1>\n</p>\n\n<h3 align=\"center\">Use your Android phone as a microphone for your PC</h3>\n\n<!-- <a href=\"https://flathub.org/apps/io.github.teamclouday.AndroidMic\"><img align=center height=\"40\" src=\"https://flathub.org/assets/badges/flathub-badge-en.svg\"  alt=\"Download on Flathub\"/></a> -->\n[![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/teamclouday/AndroidMic.svg?logo=github&label=GitHub&cacheSeconds=3600)](https://github.com/teamclouday/AndroidMic/releases/latest)\n[![F-Droid](https://img.shields.io/f-droid/v/io.github.teamclouday.AndroidMic?logo=f-droid&label=F-Droid&cacheSeconds=3600)](https://f-droid.org/packages/io.github.teamclouday.AndroidMic)\n\n---\n\n<p  style=\"text-align: center;\">\n  <img src=\"./Assets/pc_screenshot_main_dark.png\" width=\"65%\"  alt=\"main window pc\"/>\n  <img src=\"./Assets/android_screenshot_main_dark.png\" width=\"25%\"  alt=\"main window android\"/>\n</p>\n\n# Features\n\n- Multiplatform (Linux, Windows, MacOs)\n- Wifi and USB support\n- Noise Cancellation\n- Audio wave visualization\n- Advanced Audio Options\n\n# How to Use\n\n## PC Side\n\n- **1. Start the app**: Download and install the latest release. Then start the app.\n    <details>\n    <summary>\n    More about installation\n    </summary>\n\n  On macOS, you will need to run the following command to allow the app to run. For more details, refer to this [link](https://discussions.apple.com/thread/253714860?sortBy=best):\n\n  ```sh\n  xattr -c /Applications/AndroidMic.app\n  ```\n\n    </details>\n\n- **2. Pick an output audio device**: You will see a list of audio player devices from the dropdown list. Here you want to choose a device that is wired to the virtual mic device on your system that you will be using.\n\n    <details>\n    <summary>\n    More about output device\n    </summary>\n\n  The step is system independent.\n\n  On Windows you can use [Virtual Audio Cable](https://vac.muzychenko.net/en/download.htm) or [VB Cable](https://vb-audio.com/Cable/). Both software will install virtual input and output audio devices on your system. After that map the output player device to the input mic device so any audio our app played to the device is transferred to the virtual mic device.\n\n  On Linux you can use pulseaudio to create a virtual mic device.\n\n    </details>\n\n- **3. Choose a connection method**: This is how your phone will be connected to your PC and stream audio from the mic.\n\n  For TCP & UDP, connect your phone and PC to the same internet.\n\n  For USB serial, connect your phone to PC with a cable.\n\n    <details>\n    <summary>\n    More about USB serial\n    </summary>\n\n  This option also requires configurations that are system independent.\n\n  On Windows, make sure the adb process is shutdown and android studio is closed.\n\n  On MacOS, it should just work.\n\n  On Linux, you will need to configure [udev](https://github.com/libusb/libusb/wiki/FAQ#can-i-run-libusb-applications-on-linux-without-root-privilege) so that the app has permission to use USB.\n\n  Samsung phone users may need to use [zadig](https://zadig.akeo.ie/) to change the USB driver to WinUSB. This is because by default Samsung phones use its proprietary USB driver which is not compatible with the app.\n\n    </details>\n\n  For USB adb, make sure the system has installed [adb](https://developer.android.com/tools/adb). The connect your phone to PC.\n\n- **4. Configure advanced settings**: Click to open the advanced settings window, and pick an audio format the output audio device supports. Usually sample rate of 44.1k or 48k, mono channel, and i16 or i24 are supported.\n\n## Android Side\n\n- **1. Start the app**: Download and install the apk file from release page. Then open the app.\n\n- **2. Configure the app**: Open the side drawer menu, configure the connection method according to the option on PC app. Then pick the **same audio settings** as the ones in PC app advanced settings.\n\n- **3. Connect**: First start recording and give sufficient permissions. Recording permission for accessing your phone's mic. Notification permission so the app can let you know if it is still recording in the background. Then connect to the PC app.\n\n    <details>\n    <summary>More about connection configurations</summary>\n\n  For TCP/UDP, you will need to enter the PC address and port. You can find that information from the log area on PC app.\n\n  For USB adb, set your phone to developer mode and enable USB debugging.\n\n  For USB serial, make sure your phone's USB setting is charging only. With this option, the app will ask your permission to launch the app in accessory mode.\n\n    </details>\n\n---\n\nFor more question / feature request / bug report, please [submit an issues](https://github.com/teamclouday/AndroidMic/issues).\n\n---\n\n## Some Notes\n\nThe PC app started as a WPF app written in C# and was only supported on Windows. Now most of the features are recreated in Rust app thanks to @wiiznokes and it's cross platform supported. But here's the [link to the WPF app branch](https://github.com/teamclouday/AndroidMic/tree/wpf-app-backup) in case you are interested.\n\nBluetooth is no longer supported because USB serial is made possible.\n\nWindows defender will very often identify the app as a virus, with their ML algorithm. If that happens, please [report to Microsoft](https://www.microsoft.com/en-us/wdsi/filesubmission) to get it fixed.",
      "stars_today": 12
    },
    {
      "id": 105262714,
      "name": "oauth2-proxy",
      "full_name": "oauth2-proxy/oauth2-proxy",
      "description": "A reverse proxy that provides authentication with Google, Azure, OpenID Connect and many more identity providers.",
      "html_url": "https://github.com/oauth2-proxy/oauth2-proxy",
      "stars": 13704,
      "forks": 1990,
      "language": "Go",
      "topics": [
        "cloud-infrastructure",
        "hacktoberfest",
        "oauth2-proxy",
        "ssl",
        "sso"
      ],
      "created_at": "2017-09-29T10:59:10Z",
      "updated_at": "2026-01-24T01:34:58Z",
      "pushed_at": "2026-01-18T00:26:09Z",
      "open_issues": 249,
      "owner": {
        "login": "oauth2-proxy",
        "avatar_url": "https://avatars.githubusercontent.com/u/62798169?v=4"
      },
      "readme": "[![Continuous Integration](https://github.com/oauth2-proxy/oauth2-proxy/actions/workflows/ci.yml/badge.svg)](https://github.com/oauth2-proxy/oauth2-proxy/actions/workflows/ci.yml)\n[![Go Report Card](https://goreportcard.com/badge/github.com/oauth2-proxy/oauth2-proxy)](https://goreportcard.com/report/github.com/oauth2-proxy/oauth2-proxy/v7)\n[![GoDoc](https://godoc.org/github.com/oauth2-proxy/oauth2-proxy?status.svg)](https://godoc.org/github.com/oauth2-proxy/oauth2-proxy/v7)\n[![MIT licensed](https://img.shields.io/badge/license-MIT-blue.svg)](./LICENSE)\n[![Maintainability](https://qlty.sh/gh/oauth2-proxy/projects/oauth2-proxy/maintainability.svg)](https://qlty.sh/gh/oauth2-proxy/projects/oauth2-proxy)\n[![Code Coverage](https://qlty.sh/gh/oauth2-proxy/projects/oauth2-proxy/coverage.svg)](https://qlty.sh/gh/oauth2-proxy/projects/oauth2-proxy)\n[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/oauth2-proxy/oauth2-proxy/badge)](https://scorecard.dev/viewer/?uri=github.com/oauth2-proxy/oauth2-proxy)\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/11223/badge)](https://www.bestpractices.dev/projects/11223)\n[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Foauth2-proxy%2Foauth2-proxy.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Foauth2-proxy%2Foauth2-proxy?ref=badge_shield)\n\n![OAuth2 Proxy](docs/static/img/logos/OAuth2_Proxy_horizontal.svg)\n\nOAuth2 Proxy is a flexible, open-source tool that can act as either a standalone reverse proxy or a middleware component integrated into existing reverse proxy or load balancer setups. It provides a simple and secure way to protect your web applications with OAuth2 / OIDC authentication. As a reverse proxy, it intercepts requests to your application and redirects users to an OAuth2 provider for authentication. As a middleware, it can be seamlessly integrated into your existing infrastructure to handle authentication for multiple applications.\n\nOAuth2 Proxy supports a lot of OAuth2 as well as OIDC providers. Either through a generic OIDC client or a specific implementation for Google, Microsoft Entra ID, GitHub, login.gov and others. Through specialised provider implementations oauth2-proxy can extract more details about the user like preferred usernames and groups. Those details can then be forwarded as HTTP headers to your upstream applications.\n\n![Simplified Architecture](docs/static/img/simplified-architecture.svg)\n\n## Get Started\n\nOAuth2 Proxy's [Installation Docs](https://oauth2-proxy.github.io/oauth2-proxy/installation) cover how to install and configure your setup. Additionally you can take a further look at the [example setup files](https://github.com/oauth2-proxy/oauth2-proxy/tree/master/contrib/local-environment).\n\n## Releases\n\n### Binaries\nWe publish oauth2-proxy as compiled binaries on GitHub for all major architectures as well as more exotic ones like `ppc64le` as well as `s390x`.\n\nCheck out the [latest release](https://github.com/oauth2-proxy/oauth2-proxy/releases/latest).\n\n### Images\n\nFrom `v7.6.0` and up the base image has been changed from Alpine to [GoogleContainerTools/distroless](https://github.com/GoogleContainerTools/distroless).\nThis image comes with even fewer installed dependencies and thus should improve security. The image therefore is also slightly smaller than Alpine.\nFor debugging purposes (and those who really need it. e.g. `armv6`) we still provide images based on Alpine. The tags of these images are suffixed with `-alpine`.\n\nSince 2023-11-18 we build nightly images directly from the `master` branch and provide them at `quay.io/oauth2-proxy/oauth2-proxy-nightly`.\nThese images are considered unstable and therefore should **NOT** be used for production purposes unless you know what you're doing.\n\n## Sponsors\nWould you like to sponsor the project then please contact us at [sponsors@oauth2-proxy.dev](mailto:sponsors@oauth2-proxy.dev)\n\n![SAP](https://avatars.githubusercontent.com/u/2531208?s=300&v=4)\n\nSAP Open Source Program\n\n## Former Sponsors\n![Microsoft](https://avatars.githubusercontent.com/u/6154722?s=100&v=4)\n\nMicrosoft Azure credits for open source projects\n\n## Getting Involved\n[![Slack](https://img.shields.io/badge/slack-Gopher_%23oauth2--proxy-red?logo=slack)](https://gophers.slack.com/archives/CM2RSS25N)\n\nJoin the #oauth2-proxy [Slack channel](https://gophers.slack.com/archives/CM2RSS25N) to chat with other users of oauth2-proxy or reach out to the maintainers directly. Use the [public invite link](https://invite.slack.golangbridge.org/) to get an invite for the Gopher Slack space.\n\nOAuth2 Proxy is a community-driven project. We rely on the contributÔ∏èions of our users to continually improve it. While review times can vary, we appreciate your patience and understanding. As a volunteer-driven project, we strive to keep this project stable and might take longer to merge changes.\n\nIf you want to contribute to the project. Please see our [Contributing](https://oauth2-proxy.github.io/oauth2-proxy/community/contribution) guide.\n\nThanks to all the people who already contributed ‚ù§\n\n<a href=\"https://github.com/oauth2-proxy/oauth2-proxy/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=oauth2-proxy/oauth2-proxy&columns=15&max=75\" />\n  <img src=\"https://img.shields.io/github/contributors/oauth2-proxy/oauth2-proxy\" />\n</a>\n\nMade with [contrib.rocks](https://contrib.rocks).\n\n## Security\n\nIf you believe you have found a vulnerability within OAuth2 Proxy or any of its dependencies, please do **NOT** open an issue or PR on GitHub, please do **NOT** post any details publicly.\n\nSecurity disclosures **MUST** be done in private. If you have found an issue that you would like to bring to the attention of the maintainers, please compose an email and send it to the list of people listed in our [MAINTAINERS.md](MAINTAINERS.md) file.\n\nFor more details read our full [Security Docs](https://oauth2-proxy.github.io/oauth2-proxy/community/security#security-disclosures)\n\n### Security Notice for v6.0.0 and older\n\nIf you are running a version older than v6.0.0 we **strongly recommend** to the current version.\n\nSee [open redirect vulnerability](https://github.com/oauth2-proxy/oauth2-proxy/security/advisories/GHSA-5m6c-jp6f-2vcv) for details.\n\n## Repository History\n\n**2018-11-27:** This repository was forked from [bitly/OAuth2_Proxy](https://github.com/bitly/oauth2_proxy). Versions v3.0.0 and up are from this fork and will have diverged from any changes in the original fork. A list of changes can be seen in the [CHANGELOG](CHANGELOG.md).\n\n**2020-03-29:** This project was formerly hosted as `pusher/oauth2_proxy` but has been renamed to `oauth2-proxy/oauth2-proxy`. Going forward, all images shall be available at `quay.io/oauth2-proxy/oauth2-proxy` and binaries will be named `oauth2-proxy`.\n\n## Code of Conduct\nParticipation in the OAuth2 Proxy project is governed by the [CNCF Code of Conduct](CODE_OF_CONDUCT.md).\n\n## License\n\nOAuth2 Proxy is distributed under [The MIT License](LICENSE).\n\n\n[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Foauth2-proxy%2Foauth2-proxy.svg?type=large)](https://app.fossa.com/projects/git%2Bgithub.com%2Foauth2-proxy%2Foauth2-proxy?ref=badge_large)\n\n## Trademarks\n\nOAuth2 Proxy is a [Cloud Native Computing Foundation](https://cncf.io) Sandbox project.\n\n![CNCF](https://www.cncf.io/wp-content/uploads/2023/04/cncf-main-site-logo.svg)\n\nThe Linux Foundation¬Æ (TLF) has registered trademarks and uses trademarks. For a list of TLF trademarks, see [Trademark Usage](https://www.linuxfoundation.org/legal/trademark-usage).\n",
      "stars_today": 11
    },
    {
      "id": 999686447,
      "name": "vscode-copilot-chat",
      "full_name": "microsoft/vscode-copilot-chat",
      "description": "Copilot Chat extension for VS Code",
      "html_url": "https://github.com/microsoft/vscode-copilot-chat",
      "stars": 9321,
      "forks": 1598,
      "language": "TypeScript",
      "topics": [],
      "created_at": "2025-06-10T16:21:19Z",
      "updated_at": "2026-01-24T01:48:51Z",
      "pushed_at": "2026-01-24T01:44:27Z",
      "open_issues": 135,
      "owner": {
        "login": "microsoft",
        "avatar_url": "https://avatars.githubusercontent.com/u/6154722?v=4"
      },
      "readme": "# GitHub Copilot - Your AI peer programmer\n\n**[GitHub Copilot](https://code.visualstudio.com/docs/copilot/overview)** is an AI peer programming tool that helps you write code faster and smarter.\n\nGitHub Copilot adapts to your unique needs allowing you to select the best model for your project, customize chat responses with custom instructions, and utilize agent mode for AI-powered, seamlessly integrated peer programming sessions.\n\n**Sign up for [GitHub Copilot Free](https://github.com/settings/copilot?utm_source=vscode-chat-readme&utm_medium=first&utm_campaign=2025mar-em-MSFT-signup)!**\n\n![Working with GitHub Copilot agent mode to make edits to code in your workspace](https://github.com/microsoft/vscode-copilot-release/blob/main/images/hero-dark.png?raw=true)\n\nWhen you install Copilot in Visual Studio Code, you get two extensions:\n* **[GitHub Copilot](https://marketplace.visualstudio.com/items?itemName=GitHub.copilot)** - Provides inline coding suggestions as you type.\n* **[GitHub Copilot Chat](https://marketplace.visualstudio.com/items?itemName=GitHub.copilot-chat)** (this extension) - A companion extension that provides conversational AI assistance.\n\n## Getting access to GitHub Copilot\n\nSign up for [GitHub Copilot Free](https://github.com/settings/copilot?utm_source=vscode-chat-readme&utm_medium=second&utm_campaign=2025mar-em-MSFT-signup), or request access from your enterprise admin.\n\nTo access GitHub Copilot, an active GitHub Copilot subscription is required. You can read more about our business and individual offerings at [github.com/features/copilot](https://github.com/features/copilot?utm_source=vscode-chat&utm_medium=readme&utm_campaign=2025mar-em-MSFT-signup).\n\n## AI-powered coding sessions\n\n**Start an AI-powered coding session tailored to your workflow**. Copilot Edits allows you to quickly iterate on code changes directly in the editor, across multiple files using natural language. For a more autonomous peer programmer experience,\n[agent mode](https://aka.ms/vscode-copilot-agent) performs multi-step coding tasks at your command. It automatically handles compile and lint errors, monitors terminal and test output, and iterates until the task is complete. [Edit mode](https://aka.ms/vscode-copilot-edit) offers a conversational, step-by-step coding experience. Engage in multi-turn chat conversations while Copilot applies edits directly to your codebase, allowing you to review changes in context and maintain full control.\n\n![Agent mode in Copilot Chat creating a new Vue application](https://github.com/microsoft/vscode-copilot-release/blob/main/images/agent-mode-readme.gif?raw=true)\n\n## Inline suggestions in the editor\n\n**Automatically receive inline suggestions in the editor** from [ghost text suggestions](https://aka.ms/vscode-completions) and [next edit suggestions](https://aka.ms/vscode-nes) to help you write code faster. Ghost text suggestions provide suggestions at the current location, tailored to your coding style and your existing code. Copilot next edit suggestions (Copilot NES) takes it a step further and predicts what and where your next logical code change will be. Use the Tab key to navigate and accept changes in quick succession.\n\n![Copilot next edit suggestions](https://code.visualstudio.com/assets/docs/copilot/inline-suggestions/nes-point.gif)\n\n## Ask and learn about your code with chat\n\n**Ask Copilot for help with any task or question** in the [Chat view](https://aka.ms/vscode-chat), bringing in code from your current files. Rather than giving you a generic answer, it can give answers that are relevant for your codebase using information provided by [participants](https://aka.ms/vscode-chat-participants), [variables](https://aka.ms/vscode-chat-variables), and [slash commands](https://aka.ms/vscode-chat-commands).\n\n![Using the workspace chat participant](https://github.com/microsoft/vscode-copilot-release/blob/main/images/participants-workspace.gif?raw=true)\n\n**Apply Copilot's AI suggestions directly to your code** using [Inline chat](https://aka.ms/vscode-inline-chat), staying in the flow. Need help with refactoring a method, adding error handling, or explaining a complex algorithm - just launch Copilot in the editor!\n\n![Inline chat in VS Code](https://code.visualstudio.com/assets/docs/copilot/copilot-chat/inline-chat-question-example.png)\n\n### Supported languages and frameworks\n\nGitHub Copilot works on any language, including Java, PHP, Python, JavaScript, Ruby, Go, C#, or C++. Because it‚Äôs been trained on languages in public repositories, it works for most popular languages, libraries and frameworks.\n\n### Version compatibility\n\nAs Copilot Chat releases in lockstep with VS Code due to its deep UI integration, every new version of Copilot Chat is only compatible with the latest and newest release of VS Code. This means that if you are using an older version of VS Code, you will not be able to use the latest Copilot Chat.\n\nOnly the latest Copilot Chat versions will use the latest models provided by the Copilot service, as even minor model upgrades require prompt changes and fixes in the extension.\n\n### Privacy and preview terms\n\nBy using Copilot Chat you agree to [GitHub Copilot chat preview terms](https://docs.github.com/en/early-access/copilot/github-copilot-chat-technical-preview-license-terms). Review the [transparency note](https://aka.ms/CopilotChatTransparencyNote) to understand about usage, limitations and ways to improve Copilot Chat during the technical preview.\n\nYour code is yours. We follow responsible practices in accordance with our [Privacy Statement](https://docs.github.com/en/site-policy/privacy-policies/github-privacy-statement) to ensure that your code snippets will not be used as suggested code for other users of GitHub Copilot.\n\nTo get the latest security fixes, please use the latest version of the Copilot extension and VS Code.\n\n### Resources & next steps\n* **Sign up for [GitHub Copilot Free](https://github.com/settings/copilot?utm_source=vscode-chat-readme&utm_medium=third&utm_campaign=2025mar-em-MSFT-signup)**\n    * If you're using Copilot for your business, check out [Copilot Business](https://docs.github.com/en/copilot/copilot-business/about-github-copilot-business) and [Copilot Enterprise](https://docs.github.com/en/copilot/github-copilot-enterprise/overview/about-github-copilot-enterprise)\n* **[Get started with Copilot in VS Code tutorial](https://code.visualstudio.com/docs/copilot/getting-started)**\n* **[Copilot Chat quickstart video](https://www.youtube.com/watch?v=3surPGP7_4o)** to learn Copilot Chat in less than 4 minutes\n* **[VS Code Copilot Series on YouTube](https://www.youtube.com/playlist?list=PLj6YeMhvp2S5_hvBl2SE-7YCHYlLQ0bPt)**\n* **[FAQ](https://code.visualstudio.com/docs/copilot/faq)**\n* **[Feedback](https://github.com/microsoft/vscode-copilot-release/issues)**: We'd love to get your help in making GitHub Copilot better!\n\n## Data and telemetry\n\nThe GitHub Copilot Extension for Visual Studio Code collects usage data and sends it to Microsoft to help improve our products and services. Read our [privacy statement](https://privacy.microsoft.com/privacystatement) to learn more. This extension respects the `telemetry.telemetryLevel` setting which you can learn more about at https://code.visualstudio.com/docs/supporting/faq#_how-to-disable-telemetry-reporting.\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark & Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.\n\n## License\n\nCopyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the [MIT](LICENSE.txt) license.\n",
      "stars_today": 11
    },
    {
      "id": 910702543,
      "name": "Nrfr",
      "full_name": "Ackites/Nrfr",
      "description": "üåç ÂÖç Root ÁöÑ SIM Âç°ÂõΩÂÆ∂Á†Å‰øÆÊîπÂ∑•ÂÖ∑ | Ëß£ÂÜ≥ÂõΩÈôÖÊº´Ê∏∏Êó∂ÁöÑÂÖºÂÆπÊÄßÈóÆÈ¢òÔºåÂ∏ÆÂä©‰ΩøÁî®Êµ∑Â§ñ SIM Âç°Ëé∑ÂæóÊõ¥Â•ΩÁöÑÊú¨Âú∞Âåñ‰ΩìÈ™åÔºåËß£ÈîÅËøêËê•ÂïÜÈôêÂà∂ÔºåÁ™ÅÁ†¥Âå∫ÂüüÈôêÂà∂",
      "html_url": "https://github.com/Ackites/Nrfr",
      "stars": 6085,
      "forks": 514,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2025-01-01T05:57:30Z",
      "updated_at": "2026-01-24T01:08:42Z",
      "pushed_at": "2025-07-16T01:08:53Z",
      "open_issues": 69,
      "owner": {
        "login": "Ackites",
        "avatar_url": "https://avatars.githubusercontent.com/u/91859281?v=4"
      },
      "readme": "<div align=\"center\">\n  <h1>Nrfr</h1>\n  <p>üåç ÂÖç Root ÁöÑ SIM Âç°ÂõΩÂÆ∂Á†Å‰øÆÊîπÂ∑•ÂÖ∑ÔºåËÆ©‰Ω†ÁöÑÁΩëÁªúÊõ¥Ëá™Áî±</p>\n\n  <p>\n    <img src=\"https://img.shields.io/badge/platform-Android-3DDC84?logo=android\" alt=\"Platform\">\n    <img src=\"https://img.shields.io/badge/Android-8+-3DDC84?logo=android\" alt=\"Android Version\">\n    <img src=\"https://img.shields.io/badge/Go-1.21+-00ADD8?logo=go\" alt=\"Go Version\">\n    <img src=\"https://img.shields.io/badge/React-19-61DAFB?logo=react\" alt=\"React Version\">\n    <img src=\"https://img.shields.io/badge/TypeScript-5-3178C6?logo=typescript\" alt=\"TypeScript Version\">\n    <img src=\"https://img.shields.io/badge/Tailwind-3-38B2AC?logo=tailwind-css\" alt=\"Tailwind Version\">\n    <img src=\"https://img.shields.io/badge/Wails-2-000000?logo=wails\" alt=\"Wails Version\">\n  </p>\n\n  <p>\n      <img src=\"https://img.shields.io/github/stars/Ackites/Nrfr?style=flat\" alt=\"Stars\">\n      <img src=\"https://img.shields.io/github/forks/Ackites/Nrfr?style=flat\" alt=\"Forks\">\n      <img src=\"https://img.shields.io/github/issues/Ackites/Nrfr?style=flat\" alt=\"Issues\">\n      <img src=\"https://img.shields.io/github/last-commit/Ackites/Nrfr?style=flat\" alt=\"Last Commit\">\n      <img src=\"https://img.shields.io/github/release/Ackites/Nrfr?style=flat\" alt=\"Release\">\n      <img src=\"https://img.shields.io/github/downloads/Ackites/Nrfr/total?style=flat\" alt=\"Downloads\">\n      <img src=\"https://img.shields.io/github/license/Ackites/Nrfr?style=flat\" alt=\"License\">\n      <img src=\"https://img.shields.io/badge/Follow-@actkites-1DA1F2?logo=x&style=flat\" alt=\"Follow on X\">\n  </p>\n\n  <div style=\"display: flex; justify-content: center; align-items: center; gap: 20px; margin: 20px 0;\">\n    <img src=\"docs/images/client.png\" alt=\"Âø´ÈÄüÂêØÂä®Â∑•ÂÖ∑ÁïåÈù¢\" width=\"500\">\n    <img src=\"docs/images/app.png\" alt=\"Android Â∫îÁî®ÁïåÈù¢\" width=\"220\">\n  </div>\n   <br>\n</div>\n\nNrfr ÊòØ‰∏ÄÊ¨æÂº∫Â§ßÁöÑ SIM Âç°ÂõΩÂÆ∂Á†Å‰øÆÊîπÂ∑•ÂÖ∑ÔºåÊó†ÈúÄ Root ÊùÉÈôêÂç≥ÂèØ‰øÆÊîπ SIM Âç°ÂõΩÂÆ∂Á†Å„ÄÇÊú¨È°πÁõÆÂÆåÂÖ®Âü∫‰∫é Android Á≥ªÁªüÂéüÁîü API ÂÆûÁé∞Ôºå‰∏ç‰æùËµñ\nXposed„ÄÅMagisk Á≠â‰ªª‰ΩïÁ¨¨‰∏âÊñπÊ°ÜÊû∂Ôºå‰ªÖÈÄöËøáË∞ÉÁî®Á≥ªÁªüÁ∫ßÊé•Âè£ÂÆûÁé∞ÂäüËÉΩ„ÄÇÈÄöËøá‰øÆÊîπÂõΩÂÆ∂Á†ÅÔºå‰Ω†ÂèØ‰ª•Ôºö\n\n- üåè Ëß£ÈîÅËøêËê•ÂïÜÈôêÂà∂Ôºå‰ΩøÁî®Êõ¥Â§öÊú¨Âú∞ÂäüËÉΩ\n- üîì Á™ÅÁ†¥Êüê‰∫õÂå∫ÂüüÈôêÂà∂ÁöÑÂ∫îÁî®ÂíåÊúçÂä°\n- üõ†Ô∏è Ëß£ÂÜ≥ÂõΩÈôÖÊº´Ê∏∏Êó∂ÁöÑÂÖºÂÆπÊÄßÈóÆÈ¢ò\n- üåê Â∏ÆÂä©‰ΩøÁî®Êµ∑Â§ñ SIM Âç°Ëé∑ÂæóÊõ¥Â•ΩÁöÑÊú¨Âú∞Âåñ‰ΩìÈ™å\n- ‚öôÔ∏è Ëß£ÂÜ≥ÈÉ®ÂàÜÂ∫îÁî®ËØÜÂà´ SIM Âç°Âú∞Âå∫ÈîôËØØÁöÑÈóÆÈ¢ò\n\n## üì± ‰ΩøÁî®Ê°à‰æã\n\n### ËøêËê•ÂïÜÈÖçÁΩÆ‰ºòÂåñ\n\n- ÊâãÊú∫Êó†Ê≥ïÊ≠£Á°ÆËØÜÂà´ËøêËê•ÂïÜÈÖçÁΩÆ\n- Êüê‰∫õËøêËê•ÂïÜÁâπÂÆöÂäüËÉΩÊó†Ê≥ï‰ΩøÁî®\n- ÁΩëÁªúÈÖçÁΩÆ‰∏éÂΩìÂú∞ËøêËê•ÂïÜ‰∏çÂåπÈÖç\n\n### ËøêËê•ÂïÜÂèÇÊï∞ÈÄÇÈÖç\n\n- ËøêËê•ÂïÜÂäüËÉΩÈÖçÁΩÆ‰∏çÂÆåÊï¥\n- ÁΩëÁªúÂèÇÊï∞‰∏éËøêËê•ÂïÜÈªòËÆ§ÈÖçÁΩÆ‰∏çÂåπÈÖç\n- ËøêËê•ÂïÜÁâπÂÆöÊúçÂä°Êó†Ê≥ïÊ≠£Â∏∏ÂêØÁî®\n\n### Êº´Ê∏∏ÁΩëÁªúËØÜÂà´\n\n- Êº´Ê∏∏Êó∂ËøêËê•ÂïÜÂêçÁß∞ÊòæÁ§∫ÂºÇÂ∏∏\n- ÁΩëÁªúÈÖçÁΩÆ‰∏éÊº´Ê∏∏Âú∞ËøêËê•ÂïÜ‰∏çÂåπÈÖç\n- ËøêËê•ÂïÜÁâπÂÆöÂäüËÉΩÊó†Ê≥ï‰ΩøÁî®\n\n### TikTok Âå∫ÂüüÈôêÂà∂Ëß£Èô§\n\n- TikTok ÁΩëÁªúÈîôËØØ\n- Êó†Ê≥ïÊ≠£Â∏∏‰ΩøÁî® TikTok ÁöÑÂÆåÊï¥ÂäüËÉΩ\n\n### Samsung Health Âå∫ÂüüÈôêÂà∂Ëß£Èô§\n\n- Êó†Ê≥ïÈÄöËøá Samsung Health ÁöÑÈ¶ñÊ¨° SIM Âç°Ê£ÄÊµã\n- Êó†Ê≥ïÂêåÊ≠•ÂÅ•Â∫∑Êï∞ÊçÆ\n- Êó†Ê≥ïÊ≠£Â∏∏‰ΩøÁî® Samsung Health ÁöÑÂÆåÊï¥ÂäüËÉΩ\n\n‰Ω†ÂèØ‰ª•Ôºö\n\n1. ‰ΩøÁî® Nrfr ‰øÆÊîπ SIM Âç°ÂõΩÂÆ∂Á†Å‰∏∫ÊîØÊåÅÁöÑÂú∞Âå∫ÔºàÂ¶Ç JP„ÄÅUS Á≠âÔºâ\n2. ÈáçÊñ∞ÊâìÂºÄ TikTokÔºåÂ∞±ÂèØ‰ª•Ê≠£Â∏∏‰ΩøÁî®‰∫Ü\n\n## üí° ÂÆûÁé∞ÂéüÁêÜ\n\nNrfr ÈÄöËøáË∞ÉÁî® Android Á≥ªÁªüÁ∫ß APIÔºàCarrierConfigLoaderÔºâ‰øÆÊîπÁ≥ªÁªüÂÜÖÁöÑËøêËê•ÂïÜÈÖçÁΩÆÂèÇÊï∞ÔºåËÄå**‰∏çÊòØÁõ¥Êé•‰øÆÊîπ SIM Âç°**„ÄÇËøôÁßçÂÆûÁé∞ÊñπÂºèÔºö\n\n- ÂÆåÂÖ®Âú®Á≥ªÁªüÂ±ÇÈù¢Â∑•‰ΩúÔºå‰∏ç‰ºöÂØπ SIM Âç°Êú¨Ë∫´ËøõË°å‰ªª‰Ωï‰øÆÊîπÊàñÈÄ†ÊàêÊçüÂùè\n- ‰ªÖÊîπÂèòÁ≥ªÁªüÂØπ SIM Âç°‰ø°ÊÅØÁöÑËØªÂèñÊñπÂºè\n- Âü∫‰∫é Android ÂéüÁîü API ÂÆûÁé∞Ôºå‰∏ç‰æùËµñ‰ªª‰ΩïÁ¨¨‰∏âÊñπÊ°ÜÊû∂ÔºàÂ¶Ç Xposed„ÄÅMagisk Á≠âÔºâ\n- ÈÄöËøá Shizuku ‰ªÖÊèê‰æõÂøÖË¶ÅÁöÑÊùÉÈôêÊîØÊåÅ\n- ÊâÄÊúâ‰øÆÊîπÈÉΩÊòØÂèØÈÄÜÁöÑÔºåÈöèÊó∂ÂèØ‰ª•ËøòÂéü\n\n## ‚ú® ÁâπÊÄß\n\n- üîí ÂÆâÂÖ®ÂèØÈù†\n   - Êó†ÈúÄ Root ÊùÉÈôê\n   - ‰∏ç‰øÆÊîπÁ≥ªÁªüÊñá‰ª∂\n   - ‰∏çÂΩ±ÂìçÁ≥ªÁªüÁ®≥ÂÆöÊÄß\n   - ‰∏ç‰ºöÂØπ SIM Âç°ÈÄ†Êàê‰ªª‰ΩïÂΩ±Âìç\n- üîÑ ÂäüËÉΩÂÆåÂñÑ\n   - ÊîØÊåÅÈöèÊó∂ËøòÂéü‰øÆÊîπ\n   - ÊîØÊåÅÂèåÂç°ËÆæÂ§áÔºåÂèØÂàÜÂà´ÈÖçÁΩÆ\n   - ‰∏ÄÊ¨°‰øÆÊîπÊ∞∏‰πÖÁîüÊïàÔºåÈáçÂêØÂêé‰øùÊåÅ\n- üöÄ ÁÆÄÂçïÊòìÁî®\n   - ‰∏ÄÈîÆÂêØÂä®Â∑•ÂÖ∑\n   - Êô∫ËÉΩÊ£ÄÊµãËÆæÂ§áÂíå SIM Âç°Áä∂ÊÄÅ\n   - Ëá™Âä®ÂÆâË£ÖÊâÄÈúÄÂ∫îÁî®\n   - ÁÆÄÊ¥Å‰ºòÈõÖÁöÑÁî®Êà∑ÁïåÈù¢\n   - ËΩªÈáè‰∏îÈ´òÊïàÔºåÂÆâË£ÖÂåÖ‰ΩìÁßØÂ∞è\n\n## ‚ö†Ô∏è Ê≥®ÊÑè‰∫ãÈ°π\n\n- ÈúÄË¶ÅÂÆâË£ÖÂπ∂ÂêØÁî® Shizuku\n- ‰øÆÊîπÂõΩÂÆ∂Á†ÅÂèØËÉΩ‰ºöÂΩ±ÂìçËøêËê•ÂïÜÊúçÂä°ÔºåËØ∑Ë∞®ÊÖéÊìç‰Ωú\n- ÈÉ®ÂàÜËÆæÂ§áÂèØËÉΩ‰∏çÊîØÊåÅ‰øÆÊîπÂõΩÂÆ∂Á†Å\n- Â¶ÇÈúÄËøòÂéüËÆæÁΩÆÔºåËØ∑‰ΩøÁî®Â∫îÁî®ÂÜÖÁöÑËøòÂéüÂäüËÉΩ\n\n## üöÄ Âø´ÈÄüÂºÄÂßã\n\n‰∏ãËΩΩÈ°µÈù¢Êúâ‰∏§‰∏™Êñá‰ª∂Ôºå‰∏Ä‰∏™ÊòØÂê´Âø´ÈÄüÂêØÂä®Â∑•ÂÖ∑ÁöÑÂéãÁº©ÂåÖÔºåÂè¶‰∏Ä‰∏™Â∞±Âè™ÊòØ APK ÂÆâË£ÖÂåÖ„ÄÇ**Êé®Ëçê‰ΩøÁî®Âø´ÈÄüÂêØÂä®Â∑•ÂÖ∑**ÔºåËØ∑ÊåâÁÖß‰ª•‰∏ãÊ≠•È™§Êìç‰ΩúÔºö\n\n1. ÂáÜÂ§áÊâãÊú∫\n    - ÂêØÁî®ÂºÄÂèëËÄÖÈÄâÈ°πÔºàÂÖ∑‰ΩìÁöÑËá™Â∑±Êü•‰∏Ä‰∏ãÔºâ\n    - ËøõÂÖ•ÂºÄÂèëËÄÖÈÄâÈ°πÔºåÂºÄÂêØ USB Ë∞ÉËØï\n    - ÂºÄÂêØ USB Ë∞ÉËØïÔºàÂÆâÂÖ®ËÆæÁΩÆÔºâÔºåÂ¶ÇÊûúÊúâÂ∞±ÂºÄÂêØ\n    - ÂºÄÂêØ USB ÂÆâË£ÖÔºàÂÖÅËÆ∏ÈÄöËøá USB ÂÆâË£ÖÂ∫îÁî®Ôºâ\n    - Â¶ÇÊûúÊèêÁ§∫Êú™Áü•Êù•Ê∫êÂ∫îÁî®ÂÆâË£ÖÔºåËØ∑ÂÖÅËÆ∏‰ªéÊ≠§Êù•Ê∫êÂÆâË£Ö\n\n2. ËøûÊé•ÊâãÊú∫Âà∞ÁîµËÑë\n    - ‰ΩøÁî®Êï∞ÊçÆÁ∫øÂ∞ÜÊâãÊú∫ËøûÊé•Âà∞ÁîµËÑë\n    - Âú®ÊâãÊú∫‰∏äÂÖÅËÆ∏ USB Ë∞ÉËØïÊéàÊùÉ\n\n3. ‰∏ãËΩΩÂπ∂ÂêØÂä® Nrfr Âø´ÈÄüÂêØÂä®Â∑•ÂÖ∑\n    - ‰ªé Release È°µÈù¢‰∏ãËΩΩÊúÄÊñ∞ÁâàÊú¨ÁöÑÂø´ÈÄüÂêØÂä®Â∑•ÂÖ∑\n    - Ëß£ÂéãÂπ∂ËøêË°å Nrfr Âø´ÈÄüÂêØÂä®Â∑•ÂÖ∑\n    - Â∑•ÂÖ∑‰ºöËá™Âä®Ê£ÄÊµãÂ∑≤ËøûÊé•ÁöÑËÆæÂ§á\n\n4. ÂÆâË£ÖÂøÖË¶ÅÁªÑ‰ª∂\n    - Â∑•ÂÖ∑‰ºöËá™Âä®ÂÆâË£Ö Shizuku Âà∞ÊâãÊú∫\n    - ÊåâÁÖßÊèêÁ§∫ÂêØÁî® Shizuku\n    - Á≠âÂæÖÂ∑•ÂÖ∑Ëá™Âä®ÂÆâË£Ö Nrfr Â∫îÁî®\n\n5. ‰øÆÊîπÂõΩÂÆ∂Á†Å\n    - Âú®ÊâãÊú∫‰∏äÊâìÂºÄ Nrfr Â∫îÁî®\n    - ÈÄâÊã©ÈúÄË¶Å‰øÆÊîπÁöÑ SIM Âç°\n    - ËÆæÁΩÆÁõÆÊ†áÂõΩÂÆ∂Á†Å\n    - Â∫îÁî®‰øÆÊîπ\n\n‰øÆÊîπÂÆåÊàêÂêéÊó†ÈúÄÈáçÂêØËÆæÂ§áÔºåËÆæÁΩÆ‰ºöÁ´ãÂç≥ÁîüÊïàÂπ∂Ê∞∏‰πÖ‰øùÊåÅ„ÄÇÂ¶ÇÈúÄËøòÂéüÔºåËØ∑‰ΩøÁî®Â∫îÁî®ÂÜÖÁöÑËøòÂéüÂäüËÉΩ„ÄÇ\n\n## üì¶ ÊûÑÂª∫\n\nÈ°πÁõÆÂåÖÂê´‰∏§‰∏™ÈÉ®ÂàÜÔºöÂø´ÈÄüÂêØÂä®Â∑•ÂÖ∑ÔºàÊ°åÈù¢Á´ØÔºâÂíåÊâãÊú∫Â∫îÁî®ÔºàAndroidÔºâ„ÄÇ\n\n### Âø´ÈÄüÂêØÂä®Â∑•ÂÖ∑ (nrfr-client)\n\n```bash\n# ËøõÂÖ•ÂÆ¢Êà∑Á´ØÁõÆÂΩï\ncd nrfr-client\n\n# ÂÆâË£Ö‰æùËµñ\nnpm install\n\n# ÂºÄÂèëÊ®°Âºè\nwails dev\n\n# ÊûÑÂª∫ÂèëÂ∏ÉÁâàÊú¨\nwails build\n```\n\n### Android Â∫îÁî® (app)\n\n```bash\n# ËøõÂÖ• Android Â∫îÁî®ÁõÆÂΩï\ncd app\n\n# ‰ΩøÁî® Gradle ÊûÑÂª∫ Debug ÁâàÊú¨\n./gradlew assembleDebug\n```\n\nÊûÑÂª∫ÂÆåÊàêÂêéÔºåÂèØ‰ª•Âú®‰ª•‰∏ã‰ΩçÁΩÆÊâæÂà∞ÁîüÊàêÁöÑÊñá‰ª∂Ôºö\n\n- Âø´ÈÄüÂêØÂä®Â∑•ÂÖ∑: `nrfr-client/build/bin/`\n- Android Â∫îÁî®: `app/build/outputs/apk/`\n\n## üìù ‰æùËµñÈ°π\n\n- [Shizuku](https://shizuku.rikka.app/) - Áî®‰∫éÊèê‰æõÁâπÊùÉÊúçÂä°\n- [ADB](https://developer.android.com/tools/adb) - Android Ë∞ÉËØïÊ°•Êé•\n\n## ü§ù Ë¥°ÁåÆ\n\nÊ¨¢ËøéÊèê‰∫§ Pull Request Âíå IssueÔºÅÂú®Êèê‰∫§‰πãÂâçÔºåËØ∑Á°Æ‰øùÔºö\n\n- ‰ª£Á†ÅÁªèËøáÊµãËØï\n- ÈÅµÂæ™Áé∞ÊúâÁöÑ‰ª£Á†ÅÈ£éÊ†º\n- Êõ¥Êñ∞Áõ∏ÂÖ≥ÊñáÊ°£\n- ÊèèËø∞Ê∏ÖÊ•öÊîπÂä®ÁöÑÁõÆÁöÑÂíåÂΩ±Âìç\n\n## üìÑ ËÆ∏ÂèØËØÅ\n\nÊú¨È°πÁõÆÈááÁî® [Apache-2.0](LICENSE) ËÆ∏ÂèØËØÅ„ÄÇ\n\n## ‚ö†Ô∏è ÂÖçË¥£Â£∞Êòé\n\nÊú¨Â∑•ÂÖ∑‰ªÖ‰æõÂ≠¶‰π†ÂíåÁ†îÁ©∂‰ΩøÁî®„ÄÇ‰ΩøÁî®Êú¨Â∑•ÂÖ∑‰øÆÊîπÁ≥ªÁªüËÆæÁΩÆÂèØËÉΩ‰ºöÂΩ±ÂìçËÆæÂ§áÁöÑÊ≠£Â∏∏‰ΩøÁî®ÔºåËØ∑Ëá™Ë°åÊâøÊãÖÈ£éÈô©„ÄÇ‰ΩúËÄÖ‰∏çÂØπ‰ªª‰ΩïÂèØËÉΩÁöÑÊçüÂ§±Ë¥üË¥£„ÄÇ\n\n## üíñ ÊîØÊåÅ\n\nÂ¶ÇÊûú‰Ω†ËßâÂæóËøô‰∏™È°πÁõÆÊúâÂ∏ÆÂä©Ôºö\n\n- Âú® X ‰∏äÂÖ≥Ê≥® [@actkites](https://x.com/intent/follow?screen_name=actkites)\n- ÁªôÈ°πÁõÆÁÇπ‰∏™ Star ‚≠ê\n- ÂàÜ‰∫´ÁªôÊõ¥Â§öÁöÑ‰∫∫\n\n## ‚≠ê Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=Ackites/Nrfr&type=Date)](https://star-history.com/#Ackites/Nrfr&Date)\n\n## üôè È∏£Ë∞¢\n\n- [Shizuku](https://shizuku.rikka.app/) - ÊÑüË∞¢ Shizuku Êèê‰æõÁöÑÁâπÊùÉÊúçÂä°ÊîØÊåÅ\n\n## üöÄ ËµûÂä©ÂïÜ\n\n<div>\n  <p><strong>Êú¨È°πÁõÆ CDN Âä†ÈÄüÂèäÂÆâÂÖ®Èò≤Êä§Áî± Tencent EdgeOne ËµûÂä©</strong></p>\n  <a href=\"https://edgeone.ai/zh?from=github\" target=\"_blank\">\n    <img src=\"https://edgeone.ai/media/34fe3a45-492d-4ea4-ae5d-ea1087ca7b4b.png\" alt=\"Tencent EdgeOne\" width=\"200\">\n  </a>\n  <p><a href=\"https://edgeone.ai/zh?from=github\" target=\"_blank\">‰∫öÊ¥≤ÊúÄ‰Ω≥CDN„ÄÅËæπÁºòÂíåÂÆâÂÖ®Ëß£ÂÜ≥ÊñπÊ°à - Tencent EdgeOne</a></p>\n</div>\n\n[![Powered by DartNode](https://dartnode.com/branding/DN-Open-Source-sm.png)](https://dartnode.com \"Powered by DartNode - Free VPS for Open Source\")\n",
      "stars_today": 11
    },
    {
      "id": 925684065,
      "name": "xserver",
      "full_name": "X11Libre/xserver",
      "description": "XLibre Xserver",
      "html_url": "https://github.com/X11Libre/xserver",
      "stars": 4119,
      "forks": 212,
      "language": "C",
      "topics": [
        "glamor",
        "glx",
        "linux",
        "macos",
        "opengl",
        "windows",
        "x",
        "x11",
        "xauth",
        "xdmcp",
        "xephyr",
        "xinerama",
        "xlibre",
        "xnest",
        "xorg",
        "xquartz",
        "xserver",
        "xvfb",
        "xvmc",
        "xwin"
      ],
      "created_at": "2025-02-01T13:41:59Z",
      "updated_at": "2026-01-24T00:32:59Z",
      "pushed_at": "2026-01-23T19:38:09Z",
      "open_issues": 217,
      "owner": {
        "login": "X11Libre",
        "avatar_url": "https://avatars.githubusercontent.com/u/196180733?v=4"
      },
      "readme": "# XLibre Xserver\n\n<p>\n    <figure><a href=\"https://github.com/orgs/X11Libre/discussions/211#discussioncomment-13796738\"><img src=\"https://github.com/X11Libre/website/blob/1d16316c0dbcfa5d09531136fb52ed7ad037c9b6/readme/img/xlibre-freebsd.png\" alt=\"XLibre running on FreeBSD\"></a><figcaption>XLibre running on FreeBSD. See more <a href=\"https://github.com/orgs/X11Libre/discussions/211\">liberated screens here</a>.</figcaption>\n    </figure>\n</p>\n\nXLibre is a display server implementation of the [X Window System Protocol Version 11 (Wikipedia)](https://en.wikipedia.org/wiki/X_Window_System_core_protocol), in short X11. It has been forked from the [X.Org Server (Wikipedia)](https://en.wikipedia.org/wiki/X.Org_Server). For the reasons for the fork, please see the [HISTORY.md](HISTORY.md).\n\n\n## Our mission\n\nThe XLibre contributors strive to clean up and strengthen the existing code base while maintaining backward compatibility to make X11 a viable choice for the future. Another goal is to actively enhance the functionality of the Xserver and its drivers. We also take care of the improvements to the X.Org Server that have been unreleased for several years or were made to Xwayland only. Our decision-making is based on merit and our active community keen to bring X forward.\n\n\n## Our achievements\n\nSince the fork on June 5, 2025, our by now more than 30 contributors have, e.g., released numerous code cleanups, the [Xnamespace extension](https://github.com/X11Libre/xserver/blob/master/doc/Xnamespace.md) for separating X clients, and backported the June 2025 [X](https://github.com/X11Libre/xserver/commit/c430c829d58a79a5d75ce43547fb649126baed01)[.](https://github.com/X11Libre/xserver/commit/899afa4c1097ed99858754677c37e1792ed3338f)[O](https://github.com/X11Libre/xserver/commit/3151e489e4754c0b426e7a771075d8f5d1b09144)[r](https://github.com/X11Libre/xserver/commit/a1e44d3c4ff997772c695c578286e2735e17f445)[g](https://github.com/X11Libre/xserver/commit/0d6af5a5429c2df1e5d7dff85d4a62599eb05504) [C](https://github.com/X11Libre/xserver/commit/da5f8d197fc25d898212714c653d66a91cbae7ab)[V](https://github.com/X11Libre/xserver/commit/948630fa428d8e0111c29a882c45b4c8bee5a796)[E](https://github.com/X11Libre/xserver/commit/923837e2c92c226ab9d4c57b94ac80fbe98bdf08) fixes. Together we integrated [TearFree by default](https://github.com/X11Libre/xserver/commit/0dacee6c5149b63a563e9bed63502da2e9f1ac1f) and [allowed enabling atomic modesetting](https://github.com/X11Libre/xserver/commit/461411c798c263f70daa96f7136614dfefda6adc). Xnest was ported to xcb, [per-ABI driver directories](https://github.com/X11Libre/xserver/commit/49c6431695f817845d921f74bf24e9e30ddd89a5) were introduced, and [XQuartz has been added to our build jobs](https://github.com/X11Libre/xserver/commit/f40afc89832d1faf19beb4d394956208a98462cc). We have fought through [all](https://github.com/X11Libre/xserver/pulls?q=is%3Apr) [the](https://github.com/X11Libre/misc/issues?q=is%3Aissue) [issues](https://github.com/X11Libre/xserver/issues?q=is%3Aissue) that have been thrown at us, reached the first stage of the associated workflow, and established our support for [packaging XLibre by volunteers](https://github.com/X11Libre/packaging). We have also made a [first release announcement](https://www.freelists.org/post/xlibre/Xlibre-250-summer-solstice-release) and created the [NEWS](NEWS).\n\nA side note: If your XLibre Xserver is already set up and running, you may want to skip to [our roadmap](#our-roadmap).\n\n<p>\n    <figure><a href=\"https://github.com/orgs/X11Libre/discussions/211#discussioncomment-13768576\"><img src=\"https://github.com/X11Libre/website/blob/1d16316c0dbcfa5d09531136fb52ed7ad037c9b6/readme/img/xlibre-rk3588.png\" alt=\"XLibre running accelerated on RK3588\"></a><figcaption>XLibre running accelerated on <a href=\"https://github.com/choushunn/awesome-RK3588\">RK3588</a>. See more <a href=\"https://github.com/orgs/X11Libre/discussions/211\">liberated screens here</a>.</figcaption>\n    </figure>\n</p>\n\n\n## Switching to XLibre\n\nThe easiest way to install and run XLibre is to use your distribution's provided packages. Please see the [Are We XLibre Yet? - (X11Libre/xserver Wiki)](https://github.com/X11Libre/xserver/wiki/Are-We-XLibre-Yet%3F) page for a list of the available options. If there is no option, then go on with building and installing XLibre from source.\n\n\n### Building XLibre\n\nAfter cloning the [Xserver repository](https://github.com/X11Libre/xserver.git) or unpacking the sources and installing the dependencies, change into the source directory and run the [Meson](https://mesonbuild.com) build tool:\n\n```shell\ncd \"<source dir of xserver>\"\nmeson setup <prefix> build <meson_options>\nninja -C build install\n```\n\nYou may specify the install `<prefix>` with, for example, `--prefix=\"$(pwd)/image\"` and add build time [`<meson_options>`](https://github.com/X11Libre/xserver/blob/master/meson_options.txt) like so: `-Dxnest=false`. You may also want to build and install some graphics and input drivers. Please refer to the [Building XLibre (X11Libre/xserver Wiki)](https://github.com/X11Libre/xserver/wiki/Building-XLibre) page for more details.\n\n\n### Configuring XLibre\n\nTo enable loading of the **proprietary Nvidia driver** in the XLibre Xserver up to version 25.0.0.15, please add the following to your X configuration, e.g., `/etc/X11/xorg.conf`:\n\n```\nSection \"ServerFlags\"\n  Option \"IgnoreABI\" \"1\"\nEndSection\n```\n\nStarting with version 25.0.0.16, the proprietary Nvidia driver is autodetected and handled internally without any special configuration. Please see the [Compatibility of XLibre (X11Libre/xserver Wiki)](https://github.com/X11Libre/xserver/wiki/Compatibility-of-XLibre) page for [more details on the Nvidia driver](https://github.com/X11Libre/xserver/wiki/Compatibility-of-XLibre#nvidia-proprietary-driver) and compatibility in general.\n\nUntil XLibre releases its own, you can find a detailed description of the configuration on the [Configuration - Xorg (ArchWiki)](https://wiki.archlinux.org/title/Xorg#Configuration) page. If you have built and installed XLibre yourself, then change into the `<prefix>` directory with `cd <prefix>` and create a directory `etc/X11` with a file `xorg.conf` and adjust it accordingly.\n\n\n### Running XLibre\n\nIf you installed XLibre using your distribution's provided packages, then the Xserver is usually started by [init (Wikipedia)](https://en.wikipedia.org/wiki/Init) on system start. On other systems it should be possible to manually start XLibre with user permissions by invoking `startx`. Please refer to [`man startx`](https://linux.die.net/man/1/startx) for how to use it.\n\nIf you have built and installed XLibre yourself, then you may want to shutdown other Xservers, change into the `<prefix>` directory, and create a simple `testx.sh` file with the following contents:\n\n```shell\n#!/bin/sh\n./bin/X :1 vt8 &\n_pid=$!\nsleep 10 && kill $_pid\n```\n\nYou can adjust the `:1 vt8` and other options in the `testx.sh` file as detailed in [`man Xorg`](https://linux.die.net/man/1/xorg). Make the `testx.sh` executable and run it:\n\n```shell\nchmod 0770 testx.sh\n./testx.sh\n```\n\nThis should give you 10 glorious seconds of a black and beautiful and empty screen. Afterwards the Xserver complains about being killed, but there should be no other critical errors for a \"test passed.\" For more details, please see [Building XLibre (X11Libre/xserver Wiki)](https://github.com/X11Libre/xserver/wiki/Building-XLibre).\n\n\n## Our roadmap\n\nRoughly speaking, we will continue to clean up and modernize the codebase, enhance our continuous integration, add static code analysis, and improve manual and automated testing. Therefore, we will consolidate our build infrastructure and release process and also add more platforms to the test cycle. We will also further look into separating X clients by the Xnamespace extension and providing practical examples of how to use it.\n\nSome of the many ideas and feature requests we received will be refined and prepared for implementation, and we will go on to integrate relevant but unreleased Xorg and Xwayland features as well. Our documentation will see improvements on how to build, configure, and switch to XLibre. A revamp of our website, the creation of a logo, and more rebranding to XLibre are also on the map. End of roughly speaking.\n\nOne of the very next steps is to concretize our roadmap by using the GitHub Projects feature to arrange and prioritize bug reports, feature requests, and other issues. This will give anybody a clear picture of what is next. All in the open so you can follow along and, more so, participate.\n\n\n## I want to help!\n\nThat's great; there's enough to do for everyone. You may consider [one](https://github.com/orgs/X11Libre/discussions/categories/1-new-ideas) of the [many](https://github.com/orgs/X11Libre/discussions/categories/2-rfcs-of-the-core-team) [ideas](https://github.com/orgs/X11Libre/discussions/categories/3-ideas-soon-to-be-addressed) and [feature requests](https://github.com/X11Libre/xserver/issues?q=is%3Aissue%20state%3Aopen%20label%3Aenhancement) out there, like [adding static code analysis/coverage](https://github.com/orgs/X11Libre/discussions/239), [creating a logo for XLibre](https://github.com/X11Libre/xserver/issues/112) or becoming an [XLibre Test Driver](https://github.com/X11Libre/xserver/wiki/XLibre-Test-Drivers).\n\nThere is also a good chance to [enhance the documentation of Xnamespace](https://github.com/X11Libre/xserver/issues/458) and add more details to the [Building XLibre](https://github.com/X11Libre/xserver/wiki/Building-XLibre) and [Graphics devices & drivers](https://github.com/X11Libre/xserver/wiki/Graphics-devices-&-drivers) wiki pages. Or to update the [desktop environments](https://github.com/X11Libre/xserver/wiki/Are-We-XLibre-Yet%3F#desktop-environments) and [display managers](https://github.com/X11Libre/xserver/wiki/Are-We-XLibre-Yet%3F#display-managers) lists as things work for you.\n\nTo wrap things up, please have a look at the [XLibre On Other Distributions discussion](https://github.com/X11Libre/packaging/discussions/categories/xlibre-on-other-distributions). There is already some nice work going on, and also some more could be done, like [creating XLibre packages in OpenSuse Build Service (OBS)](https://github.com/X11Libre/packaging/discussions/19). Or create a [platform cheat sheet](https://github.com/orgs/X11Libre/discussions/241) in general.\n\nThat's not enough? Then have a glance at the [good first](https://github.com/X11Libre/xserver/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22good%20first%20issue%22) and [help wanted](https://github.com/X11Libre/xserver/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22help%20wanted%22) issues. There are more to come, especially for code cleanups. If you want to work on anything, just let us know. If you have any questions, [just ask](https://github.com/orgs/X11Libre/discussions/categories/q-a). We thank you!\n\n\n## You're welcome!\n\n<p>\n    <figure><a href=\"https://github.com/orgs/X11Libre/discussions/211#discussioncomment-13818114\"><img src=\"https://github.com/X11Libre/website/blob/1d16316c0dbcfa5d09531136fb52ed7ad037c9b6/readme/img/xlibre-nixos.jpg\" alt=\"XLibre running on NixOS\"></a><figcaption>XLibre running on NixOS. See more <a href=\"https://github.com/orgs/X11Libre/discussions/211\">liberated screens here</a>.</figcaption>\n    </figure>\n</p>\n\nThis is an independent project, not at all affiliated with BigTech or any of their subsidiaries or tax evasion tools, nor any political activist groups, state actors, etc. It's explicitly free of any \"DEI\" or similar discriminatory policies. Anybody who's treating others nicely is welcome.\n\nIt doesn't matter which country you're coming from, your political views, your race, your sex, your age, your food menu, whether you wear boots or heels, whether you're furry or fairy, Conan or McKay, a comic character, a small furry creature from Alpha Centauri, or just a boring average person. Anybody who's interested in bringing X forward is welcome.\n\nTogether we'll make X great again!\n\n\n## Contact\n\n[XLibre Discussions at GitHub](https://github.com/orgs/X11Libre/discussions) | [XLibre mailing list at FreeLists](https://www.freelists.org/list/xlibre) | [@x11dev channel at Telegram](https://t.me/x11dev) | [#xlibre room at Matrix](https://matrix.to/#/#xlibre:matrix.org) | [XLibre security contact at GitHub](https://github.com/X11Libre/xserver/security/policy)\n\n[Interview: Meet Enrico Weigelt, the maintainer of the new XLibre fork - Felipe Contreras](https://felipec.wordpress.com/2025/06/11/enrico-weigelt/)\n\n",
      "stars_today": 10
    },
    {
      "id": 3432266,
      "name": "kotlin",
      "full_name": "JetBrains/kotlin",
      "description": "The Kotlin Programming Language. ",
      "html_url": "https://github.com/JetBrains/kotlin",
      "stars": 52212,
      "forks": 6186,
      "language": "Kotlin",
      "topics": [
        "compiler",
        "gradle-plugin",
        "intellij-plugin",
        "kotlin",
        "kotlin-library",
        "maven-plugin",
        "programming-language",
        "wasm",
        "webassembly"
      ],
      "created_at": "2012-02-13T17:29:58Z",
      "updated_at": "2026-01-23T21:27:39Z",
      "pushed_at": "2026-01-24T01:03:17Z",
      "open_issues": 211,
      "owner": {
        "login": "JetBrains",
        "avatar_url": "https://avatars.githubusercontent.com/u/878437?v=4"
      },
      "readme": "[![official project](https://jb.gg/badges/official.svg)](https://confluence.jetbrains.com/display/ALL/JetBrains+on+GitHub)\n[![TeamCity (simple build status)](https://img.shields.io/teamcity/http/teamcity.jetbrains.com/s/Kotlin_KotlinPublic_Compiler.svg)](https://teamcity.jetbrains.com/buildConfiguration/Kotlin_KotlinPublic_Compiler?branch=%3Cdefault%3E&buildTypeTab=overview&mode=builds)\n[![Maven Central](https://img.shields.io/maven-central/v/org.jetbrains.kotlin/kotlin-maven-plugin.svg)](https://search.maven.org/#search%7Cga%7C1%7Cg%3A%22org.jetbrains.kotlin%22)\n[![GitHub license](https://img.shields.io/badge/license-Apache%20License%202.0-blue.svg?style=flat)](https://www.apache.org/licenses/LICENSE-2.0)\n[![Revved up by Develocity](https://img.shields.io/badge/Revved%20up%20by-Develocity-06A0CE?logo=Gradle&labelColor=02303A)](https://ge.jetbrains.com/scans?search.rootProjectNames=Kotlin)\n\n# Kotlin Programming Language\n\nWelcome to [Kotlin](https://kotlinlang.org/)!   \nKotlin is a concise multiplatform language developed by [JetBrains](https://www.jetbrains.com/) and [contributors](https://kotlinlang.org/docs/contribute.html).\n\nSome handy links:\n\n * [Kotlin Site](https://kotlinlang.org/)\n * [Getting Started Guide](https://kotlinlang.org/docs/tutorials/getting-started.html)\n * [Try Kotlin](https://play.kotlinlang.org/)\n * [Kotlin Standard Library](https://kotlinlang.org/api/latest/jvm/stdlib/index.html)\n * [Issue Tracker](https://youtrack.jetbrains.com/issues/KT)\n * [Kotlin YouTube Channel](https://www.youtube.com/channel/UCP7uiEZIqci43m22KDl0sNw)\n * [Forum](https://discuss.kotlinlang.org/)\n * [Kotlin Blog](https://blog.jetbrains.com/kotlin/)\n * [Subscribe to Kotlin YouTube channel](https://www.youtube.com/channel/UCP7uiEZIqci43m22KDl0sNw)\n * [Follow Kotlin on Twitter](https://twitter.com/kotlin)\n * [Public Slack channel](https://slack.kotlinlang.org/)\n * [TeamCity CI build](https://teamcity.jetbrains.com/project.html?tab=projectOverview&projectId=Kotlin)\n * [Kotlin Foundation](https://kotlinfoundation.org/)\n\n## Kotlin Multiplatform capabilities\n\nSupport for multiplatform programming is one of Kotlin‚Äôs key benefits. It reduces time spent writing and maintaining the same code for [different platforms](https://kotlinlang.org/docs/reference/mpp-supported-platforms.html) while retaining the flexibility and benefits of native programming.\n\n * [Kotlin Multiplatform](https://www.jetbrains.com/kotlin-multiplatform/) and [Compose Multiplatform](https://www.jetbrains.com/compose-multiplatform/) for sharing business logic and UI between Android, iOS, desktop, and web.\n * [Get started with Kotlin Multiplatform](https://www.jetbrains.com/help/kotlin-multiplatform-dev/get-started.html)\n * [Kotlin Multiplatform Benefits](https://kotlinlang.org/docs/reference/multiplatform.html)\n * [Share code on all platforms](https://kotlinlang.org/docs/reference/mpp-share-on-platforms.html#share-code-on-all-platforms)\n * [Share code on similar platforms](https://kotlinlang.org/docs/reference/mpp-share-on-platforms.html#share-code-on-similar-platforms)\n\n## Editing Kotlin\n\n * [Kotlin IntelliJ IDEA Plugin](https://kotlinlang.org/docs/tutorials/getting-started.html) ([source code](https://github.com/JetBrains/intellij-community/tree/master/plugins/kotlin))\n * [Kotlin Eclipse Plugin](https://kotlinlang.org/docs/tutorials/getting-started-eclipse.html)\n * [Kotlin Sublime Text Package](https://github.com/vkostyukov/kotlin-sublime-package)\n\n## Build environment requirements\n\nThis repository is using [Gradle toolchains](https://docs.gradle.org/current/userguide/toolchains.html) feature\nto select and auto-provision required JDKs from [Eclipse Adoptium](https://adoptium.net) project.\n\nAlternatively, it is still possible to only provide required JDKs via environment variables \n(see [gradle.properties](./gradle.properties#L5) for supported variable names). To ensure Gradle uses only JDKs \nfrom environmental variables - disable Gradle toolchain auto-detection by passing `-Porg.gradle.java.installations.auto-detect=false` option\n(or put it into `$GRADLE_USER_HOME/gradle.properties`).\n\nOn Windows you might need to add long paths setting to the repo:\n\n    git config core.longpaths true \n\n## Building\n\nThe project is built with Gradle. Run Gradle to build the project and to run the tests \nusing the following command on Unix/macOS:\n\n    ./gradlew <tasks-and-options>\n    \nor the following command on Windows:\n\n    gradlew <tasks-and-options>\n\nOn the first project configuration gradle will download and setup the dependencies on:\n\n* `intellij-core` is a part of command line compiler and contains only necessary APIs.\n* `idea-full` is a full blown IntelliJ IDEA Community Edition to be used in the plugin module.\n\nThese dependencies are quite large, so depending on the quality of your internet connection \nyou might face timeouts getting them. In this case, you can increase timeout by specifying the following \ncommand line parameters on the first run: \n    \n    ./gradlew -Dhttp.socketTimeout=60000 -Dhttp.connectionTimeout=60000\n\n## Important gradle tasks\n\n- `clean` - clean build results\n- `dist` - assembles the compiler distribution into `dist/kotlinc/` folder\n- `install` - build and install all public artifacts into local maven repository\n- `coreLibsTest` - build and run stdlib, reflect and kotlin-test tests\n- `gradlePluginTest` - build and run gradle plugin tests\n- `compilerTest` - build and run all compiler tests\n\nTo reproduce TeamCity build use `-Pteamcity=true` flag. Local builds don't run proguard and have jar compression disabled by default.\n\n**OPTIONAL:** Some artifacts, mainly Maven plugin ones, are built separately with Maven.\nRefer to [libraries/ReadMe.md](libraries/ReadMe.md) for details.\n\nTo build Kotlin/Native, see\n[kotlin-native/README.md](kotlin-native/README.md#building-from-source).\n\n## <a name=\"working-in-idea\"></a> Working with the project in IntelliJ IDEA\n\nIt is recommended to use the latest released version of Intellij IDEA (Community or Ultimate Edition). You can download IntelliJ IDEA [here](https://www.jetbrains.com/idea/download).\n\nAfter cloning the project, import the project in IntelliJ by choosing the project directory in the Open project dialog.\n\nFor handy work with compiler tests it's recommended to use [Kotlin Compiler Test Helper](https://github.com/demiurg906/test-data-helper-plugin).\n\n### Dependency verification\n\nWe have a [dependencies verification](https://docs.gradle.org/current/userguide/dependency_verification.html) feature enabled in the\nrepository for all Gradle builds. Gradle will check hashes (md5 and sha256) of used dependencies and will fail builds with\n`Dependency verification failed` errors when local artifacts are absent or have different hashes listed in the\n[verification-metadata.xml](https://github.com/JetBrains/kotlin/blob/master/gradle/verification-metadata.xml) file.\n\nIt's expected that `verification-metadata.xml` should only be updated with the commits that modify the build. There are some tips how\nto perform such updates:\n\n- Delete `components` section of `verification-metadata.xml` to avoid stockpiling of old unused dependencies. You may use the following command:\n```bash\n#macOS\nsed -i '' -e '/<components>/,/<\\/components>/d' gradle/verification-metadata.xml\n#Linux & Git for Windows\nsed -i -e '/<components>/,/<\\/components>/d' gradle/verification-metadata.xml\n```\n- Re-generate dependencies with Gradle's `--write-verification-metadata` command (verify update relates to your changes)\n\n```bash\n./gradlew --write-verification-metadata sha256,md5 -Pkotlin.native.enabled=true resolveDependencies\n```\n\n*`resolveDependencies` task resolves dependencies for all platforms including dependencies downloaded by plugins.*\n\nYou can also use `./scripts/update-verification-metadata.sh` script which includes both of these steps\n\nKeep in mind:\n\n- If you‚Äôre adding a dependency with OS mentioned in an artifact name (`darwin`, `mac`, `osx`, `linux`, `windows`), remember to add them to \n  `implicitDependencies` configuration or update `resolveDependencies` task if needed. `resolveDependencies` should resolve all dependencies\n  including dependencies for different platforms.\n- If you have a `local.properties` file in your Kotlin project folder, make sure that it doesn't contain `kotlin.native.enabled=false`.\n  Otherwise, native-only dependencies may not be added to the verification metadata. This is because `local.properties` has higher \n  precedence than the `-Pkotlin.native.enabled=true` specified in the Gradle command.\n\n## Using -dev versions\n\nWe publish `-dev` versions frequently.\n\nFor `-dev` versions you can use the [list of available versions](https://redirector.kotlinlang.org/maven/bootstrap/org/jetbrains/kotlin/kotlin-compiler/maven-metadata.xml) and include this maven repository:\n\n```kotlin\nmaven(\"https://redirector.kotlinlang.org/maven/bootstrap\")\n```\n\n# License\nKotlin is distributed under the terms of the Apache License (Version 2.0). See [license folder](license/README.md) for details.\n\n# Contributing\n\nPlease be sure to review Kotlin's [contributing guidelines](docs/contributing.md) to learn how to help the project.\n\n# Kotlin Foundation\n\nThe Kotlin Foundation is a non-profit organization whose mission is to promote and advance the Kotlin ecosystem. You can learn more about the structure and goals of the Kotlin Foundation on its [official website](https://kotlinfoundation.org/).\n",
      "stars_today": 9
    },
    {
      "id": 301216792,
      "name": "register",
      "full_name": "is-a-dev/register",
      "description": "Grab your own sweet-looking '.is-a.dev' subdomain.",
      "html_url": "https://github.com/is-a-dev/register",
      "stars": 9457,
      "forks": 17663,
      "language": "JavaScript",
      "topics": [
        "cloudflare",
        "dev",
        "developer",
        "dns",
        "domain",
        "foss",
        "free",
        "free-domain",
        "free-for-dev",
        "free-for-developers",
        "github-pages",
        "oss",
        "subdomain",
        "website"
      ],
      "created_at": "2020-10-04T20:05:28Z",
      "updated_at": "2026-01-23T23:43:04Z",
      "pushed_at": "2026-01-23T15:01:02Z",
      "open_issues": 32,
      "owner": {
        "login": "is-a-dev",
        "avatar_url": "https://avatars.githubusercontent.com/u/72358814?v=4"
      },
      "readme": "<!-- <p align=\"center\">\n   <img alt=\"is-a.dev Banner\" src=\"https://raw.githubusercontent.com/is-a-dev/register/main/media/banner.png\">\n</p> -->\n\n<p align=\"center\">\n   <img height=\"350\" alt=\"is-a.dev Octoverse 2025 Banner\" src=\"https://raw.githubusercontent.com/is-a-dev/register/main/media/octoverse-2025/is-a-dev_register_1200x630.jpg\">\n</p>\n\n<p align=\"center\">\n   <img alt=\"Domains\" src=\"https://img.shields.io/github/directory-file-count/is-a-dev/register/domains?color=5c46eb&label=domains&style=for-the-badge\">\n   <img alt=\"Open Pull Requests\" src=\"https://img.shields.io/github/issues-raw/is-a-dev/register?color=5c46eb&label=issues&style=for-the-badge\">\n   <img alt=\"Open Issues\" src=\"https://img.shields.io/github/issues-pr-raw/is-a-dev/register?color=5c46eb&label=pull%20requests&style=for-the-badge\">\n   <br>\n</p>\n\n<h1 align=\"center\">is-a.dev</h1>\n\n<p align=\"center\"><strong>is-a.dev</strong> is a service that allows developers to get a sweet-looking <code>.is-a.dev</code> subdomain for their personal websites.</p>\n\n---\n\n## Announcements\nPlease join our [Discord server](https://discord.gg/is-a-dev-830872854677422150) for announcements, service updates, and downtime notifications regarding the service.\n\nNot all announcements are posted on GitHub[^1], however they will always be posted in our Discord server.\n\n[^1]: We only post announcements on GitHub in the case of a serious incident, which you'll see at the top of this README.\n\n# Register\n> If you want a visual guide, check out [this blog post](https://blog.wharrison.com.au/2024/07/is-a-dev/).\n\n- [Fork](https://github.com/is-a-dev/register/fork) the repository.\n- Follow the instructions on our [documentation](https://docs.is-a.dev).\n- Once you open your pull request (PR), it will be reviewed. *Keep an eye on it in case changes are needed!*\n   - If changes have been requested, please make the specified changes otherwise **you will be rejected**.\n- Once your PR is merged, your DNS records should be published with-in a few minutes.\n- Enjoy your new `.is-a.dev` subdomain! Please consider leaving a star ‚≠êÔ∏è to help support us!\n\n## Report Abuse\nIf you find any subdomains being abused or breaking our TOS, please report them by [creating an issue](https://github.com/is-a-dev/register/issues/new?assignees=&labels=report-abuse&projects=&template=report-abuse.md&title=Report+abuse) with relevant evidence.\n\n---\n\nWe are supported by Cloudflare's [Project Alexandria](https://www.cloudflare.com/lp/project-alexandria) sponsorship program, we would not be able to operate without their help!\n\n<a href=\"https://www.cloudflare.com\">\n   <img alt=\"Cloudflare Logo\" src=\"https://raw.githubusercontent.com/is-a-dev/register/main/media/cloudflare.png\" height=\"48\">\n</a>\n",
      "stars_today": 9
    },
    {
      "id": 5179099,
      "name": "go-redis",
      "full_name": "redis/go-redis",
      "description": "Redis Go client",
      "html_url": "https://github.com/redis/go-redis",
      "stars": 21853,
      "forks": 2527,
      "language": "Go",
      "topics": [
        "go",
        "golang",
        "redis",
        "redis-client",
        "redis-cluster"
      ],
      "created_at": "2012-07-25T13:01:39Z",
      "updated_at": "2026-01-24T01:35:29Z",
      "pushed_at": "2026-01-23T12:36:31Z",
      "open_issues": 66,
      "owner": {
        "login": "redis",
        "avatar_url": "https://avatars.githubusercontent.com/u/1529926?v=4"
      },
      "readme": "# Redis client for Go\n\n[![build workflow](https://github.com/redis/go-redis/actions/workflows/build.yml/badge.svg)](https://github.com/redis/go-redis/actions)\n[![PkgGoDev](https://pkg.go.dev/badge/github.com/redis/go-redis/v9)](https://pkg.go.dev/github.com/redis/go-redis/v9?tab=doc)\n[![Documentation](https://img.shields.io/badge/redis-documentation-informational)](https://redis.io/docs/latest/develop/clients/go/)\n[![Go Report Card](https://goreportcard.com/badge/github.com/redis/go-redis/v9)](https://goreportcard.com/report/github.com/redis/go-redis/v9)\n[![codecov](https://codecov.io/github/redis/go-redis/graph/badge.svg?token=tsrCZKuSSw)](https://codecov.io/github/redis/go-redis)\n\n[![Discord](https://img.shields.io/discord/697882427875393627.svg?style=social&logo=discord)](https://discord.gg/W4txy5AeKM)\n[![Twitch](https://img.shields.io/twitch/status/redisinc?style=social)](https://www.twitch.tv/redisinc)\n[![YouTube](https://img.shields.io/youtube/channel/views/UCD78lHSwYqMlyetR0_P4Vig?style=social)](https://www.youtube.com/redisinc)\n[![Twitter](https://img.shields.io/twitter/follow/redisinc?style=social)](https://twitter.com/redisinc)\n[![Stack Exchange questions](https://img.shields.io/stackexchange/stackoverflow/t/go-redis?style=social&logo=stackoverflow&label=Stackoverflow)](https://stackoverflow.com/questions/tagged/go-redis)\n\n> go-redis is the official Redis client library for the Go programming language. It offers a straightforward interface for interacting with Redis servers. \n\n## Supported versions\n\nIn `go-redis` we are aiming to support the last three releases of Redis. Currently, this means we do support:\n- [Redis 8.0](https://raw.githubusercontent.com/redis/redis/8.0/00-RELEASENOTES) - using Redis CE 8.0\n- [Redis 8.2](https://raw.githubusercontent.com/redis/redis/8.2/00-RELEASENOTES) - using Redis CE 8.2 \n- [Redis 8.4](https://raw.githubusercontent.com/redis/redis/8.4/00-RELEASENOTES) - using Redis CE 8.4\n\nAlthough the `go.mod` states it requires at minimum `go 1.21`, our CI is configured to run the tests against all three\nversions of Redis and multiple versions of Go ([1.21](https://go.dev/doc/devel/release#go1.21.0),\n[1.23](https://go.dev/doc/devel/release#go1.23.0), oldstable, and stable). We observe that some modules related test may not pass with\nRedis Stack 7.2 and some commands are changed with Redis CE 8.0.\nAlthough it is not officially supported, `go-redis/v9`  should be able to work with any Redis 7.0+.\nPlease do refer to the documentation and the tests if you experience any issues.\n\n## How do I Redis?\n\n[Learn for free at Redis University](https://university.redis.com/)\n\n[Build faster with the Redis Launchpad](https://launchpad.redis.com/)\n\n[Try the Redis Cloud](https://redis.com/try-free/)\n\n[Dive in developer tutorials](https://developer.redis.com/)\n\n[Join the Redis community](https://redis.com/community/)\n\n[Work at Redis](https://redis.com/company/careers/jobs/)\n\n\n## Resources\n\n- [Discussions](https://github.com/redis/go-redis/discussions)\n- [Chat](https://discord.gg/W4txy5AeKM)\n- [Reference](https://pkg.go.dev/github.com/redis/go-redis/v9)\n- [Examples](https://pkg.go.dev/github.com/redis/go-redis/v9#pkg-examples)\n\n## old documentation\n\n- [English](https://redis.uptrace.dev)\n- [ÁÆÄ‰Ωì‰∏≠Êñá](https://redis.uptrace.dev/zh/)\n\n## Ecosystem\n\n- [Entra ID (Azure AD)](https://github.com/redis/go-redis-entraid)\n- [Distributed Locks](https://github.com/bsm/redislock)\n- [Redis Cache](https://github.com/go-redis/cache)\n- [Rate limiting](https://github.com/go-redis/redis_rate)\n\n## Features\n\n- Redis commands except QUIT and SYNC.\n- Automatic connection pooling.\n- [StreamingCredentialsProvider (e.g. entra id, oauth)](#1-streaming-credentials-provider-highest-priority) (experimental)\n- [Pub/Sub](https://redis.uptrace.dev/guide/go-redis-pubsub.html).\n- [Pipelines and transactions](https://redis.uptrace.dev/guide/go-redis-pipelines.html).\n- [Scripting](https://redis.uptrace.dev/guide/lua-scripting.html).\n- [Redis Sentinel](https://redis.uptrace.dev/guide/go-redis-sentinel.html).\n- [Redis Cluster](https://redis.uptrace.dev/guide/go-redis-cluster.html).\n- [Redis Performance Monitoring](https://redis.uptrace.dev/guide/redis-performance-monitoring.html).\n- [Redis Probabilistic [RedisStack]](https://redis.io/docs/data-types/probabilistic/)\n- [Customizable read and write buffers size.](#custom-buffer-sizes)\n\n## Installation\n\ngo-redis supports 2 last Go versions and requires a Go version with\n[modules](https://github.com/golang/go/wiki/Modules) support. So make sure to initialize a Go\nmodule:\n\n```shell\ngo mod init github.com/my/repo\n```\n\nThen install go-redis/**v9**:\n\n```shell\ngo get github.com/redis/go-redis/v9\n```\n\n## Quickstart\n\n```go\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/redis/go-redis/v9\"\n)\n\nvar ctx = context.Background()\n\nfunc ExampleClient() {\n    rdb := redis.NewClient(&redis.Options{\n        Addr:     \"localhost:6379\",\n        Password: \"\", // no password set\n        DB:       0,  // use default DB\n    })\n    defer rdb.Close()\n\n    err := rdb.Set(ctx, \"key\", \"value\", 0).Err()\n    if err != nil {\n        panic(err)\n    }\n\n    val, err := rdb.Get(ctx, \"key\").Result()\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(\"key\", val)\n\n    val2, err := rdb.Get(ctx, \"key2\").Result()\n    if err == redis.Nil {\n        fmt.Println(\"key2 does not exist\")\n    } else if err != nil {\n        panic(err)\n    } else {\n        fmt.Println(\"key2\", val2)\n    }\n    // Output: key value\n    // key2 does not exist\n}\n```\n\n### Authentication\n\nThe Redis client supports multiple ways to provide authentication credentials, with a clear priority order. Here are the available options:\n\n#### 1. Streaming Credentials Provider (Highest Priority) - Experimental feature\n\nThe streaming credentials provider allows for dynamic credential updates during the connection lifetime. This is particularly useful for managed identity services and token-based authentication.\n\n```go\ntype StreamingCredentialsProvider interface {\n    Subscribe(listener CredentialsListener) (Credentials, UnsubscribeFunc, error)\n}\n\ntype CredentialsListener interface {\n    OnNext(credentials Credentials)  // Called when credentials are updated\n    OnError(err error)              // Called when an error occurs\n}\n\ntype Credentials interface {\n    BasicAuth() (username string, password string)\n    RawCredentials() string\n}\n```\n\nExample usage:\n```go\nrdb := redis.NewClient(&redis.Options{\n    Addr: \"localhost:6379\",\n    StreamingCredentialsProvider: &MyCredentialsProvider{},\n})\n```\n\n**Note:** The streaming credentials provider can be used with [go-redis-entraid](https://github.com/redis/go-redis-entraid) to enable Entra ID (formerly Azure AD) authentication. This allows for seamless integration with Azure's managed identity services and token-based authentication.\n\nExample with Entra ID:\n```go\nimport (\n    \"github.com/redis/go-redis/v9\"\n    \"github.com/redis/go-redis-entraid\"\n)\n\n// Create an Entra ID credentials provider\nprovider := entraid.NewDefaultAzureIdentityProvider()\n\n// Configure Redis client with Entra ID authentication\nrdb := redis.NewClient(&redis.Options{\n    Addr: \"your-redis-server.redis.cache.windows.net:6380\",\n    StreamingCredentialsProvider: provider,\n    TLSConfig: &tls.Config{\n        MinVersion: tls.VersionTLS12,\n    },\n})\n```\n\n#### 2. Context-based Credentials Provider\n\nThe context-based provider allows credentials to be determined at the time of each operation, using the context.\n\n```go\nrdb := redis.NewClient(&redis.Options{\n    Addr: \"localhost:6379\",\n    CredentialsProviderContext: func(ctx context.Context) (string, string, error) {\n        // Return username, password, and any error\n        return \"user\", \"pass\", nil\n    },\n})\n```\n\n#### 3. Regular Credentials Provider\n\nA simple function-based provider that returns static credentials.\n\n```go\nrdb := redis.NewClient(&redis.Options{\n    Addr: \"localhost:6379\",\n    CredentialsProvider: func() (string, string) {\n        // Return username and password\n        return \"user\", \"pass\"\n    },\n})\n```\n\n#### 4. Username/Password Fields (Lowest Priority)\n\nThe most basic way to provide credentials is through the `Username` and `Password` fields in the options.\n\n```go\nrdb := redis.NewClient(&redis.Options{\n    Addr:     \"localhost:6379\",\n    Username: \"user\",\n    Password: \"pass\",\n})\n```\n\n#### Priority Order\n\nThe client will use credentials in the following priority order:\n1. Streaming Credentials Provider (if set)\n2. Context-based Credentials Provider (if set)\n3. Regular Credentials Provider (if set)\n4. Username/Password fields (if set)\n\nIf none of these are set, the client will attempt to connect without authentication.\n\n### Protocol Version\n\nThe client supports both RESP2 and RESP3 protocols. You can specify the protocol version in the options:\n\n```go\nrdb := redis.NewClient(&redis.Options{\n    Addr:     \"localhost:6379\",\n    Password: \"\", // no password set\n    DB:       0,  // use default DB\n    Protocol: 3,  // specify 2 for RESP 2 or 3 for RESP 3\n})\n```\n\n### Connecting via a redis url\n\ngo-redis also supports connecting via the\n[redis uri specification](https://github.com/redis/redis-specifications/tree/master/uri/redis.txt).\nThe example below demonstrates how the connection can easily be configured using a string, adhering\nto this specification.\n\n```go\nimport (\n    \"github.com/redis/go-redis/v9\"\n)\n\nfunc ExampleClient() *redis.Client {\n    url := \"redis://user:password@localhost:6379/0?protocol=3\"\n    opts, err := redis.ParseURL(url)\n    if err != nil {\n        panic(err)\n    }\n\n    return redis.NewClient(opts)\n}\n\n```\n\n### Instrument with OpenTelemetry\n\n```go\nimport (\n    \"github.com/redis/go-redis/v9\"\n    \"github.com/redis/go-redis/extra/redisotel/v9\"\n    \"errors\"\n)\n\nfunc main() {\n    ...\n    rdb := redis.NewClient(&redis.Options{...})\n\n    if err := errors.Join(redisotel.InstrumentTracing(rdb), redisotel.InstrumentMetrics(rdb)); err != nil {\n        log.Fatal(err)\n    }\n```\n\n\n### Buffer Size Configuration\n\ngo-redis uses 32KiB read and write buffers by default for optimal performance. For high-throughput applications or large pipelines, you can customize buffer sizes:\n\n```go\nrdb := redis.NewClient(&redis.Options{\n    Addr:            \"localhost:6379\",\n    ReadBufferSize:  1024 * 1024, // 1MiB read buffer\n    WriteBufferSize: 1024 * 1024, // 1MiB write buffer\n})\n```\n\n### Advanced Configuration\n\ngo-redis supports extending the client identification phase to allow projects to send their own custom client identification.\n\n#### Default Client Identification\n\nBy default, go-redis automatically sends the client library name and version during the connection process. This feature is available in redis-server as of version 7.2. As a result, the command is \"fire and forget\", meaning it should fail silently, in the case that the redis server does not support this feature.\n\n#### Disabling Identity Verification\n\nWhen connection identity verification is not required or needs to be explicitly disabled, a `DisableIdentity` configuration option exists.\nInitially there was a typo and the option was named `DisableIndentity` instead of `DisableIdentity`. The misspelled option is marked as Deprecated and will be removed in V10 of this library.\nAlthough both options will work at the moment, the correct option is `DisableIdentity`. The deprecated option will be removed in V10 of this library, so please use the correct option name to avoid any issues.\n\nTo disable verification, set the `DisableIdentity` option to `true` in the Redis client options:\n\n```go\nrdb := redis.NewClient(&redis.Options{\n    Addr:            \"localhost:6379\",\n    Password:        \"\",\n    DB:              0,\n    DisableIdentity: true, // Disable set-info on connect\n})\n```\n\n#### Unstable RESP3 Structures for RediSearch Commands\nWhen integrating Redis with application functionalities using RESP3, it's important to note that some response structures aren't final yet. This is especially true for more complex structures like search and query results. We recommend using RESP2 when using the search and query capabilities, but we plan to stabilize the RESP3-based API-s in the coming versions. You can find more guidance in the upcoming release notes.\n\nTo enable unstable RESP3, set the option in your client configuration:\n\n```go\nredis.NewClient(&redis.Options{\n\t\t\tUnstableResp3: true,\n\t\t})\n```\n**Note:** When UnstableResp3 mode is enabled, it's necessary to use RawResult() and RawVal() to retrieve a raw data.\n          Since, raw response is the only option for unstable search commands Val() and Result() calls wouldn't have any affect on them:\n\n```go\nres1, err := client.FTSearchWithArgs(ctx, \"txt\", \"foo bar\", &redis.FTSearchOptions{}).RawResult()\nval1 := client.FTSearchWithArgs(ctx, \"txt\", \"foo bar\", &redis.FTSearchOptions{}).RawVal()\n```\n\n#### Redis-Search Default Dialect\n\nIn the Redis-Search module, **the default dialect is 2**. If needed, you can explicitly specify a different dialect using the appropriate configuration in your queries.\n\n**Important**: Be aware that the query dialect may impact the results returned. If needed, you can revert to a different dialect version by passing the desired dialect in the arguments of the command you want to execute.\nFor example:\n```\n\tres2, err := rdb.FTSearchWithArgs(ctx,\n\t\t\"idx:bicycle\",\n\t\t\"@pickup_zone:[CONTAINS $bike]\",\n\t\t&redis.FTSearchOptions{\n\t\t\tParams: map[string]interface{}{\n\t\t\t\t\"bike\": \"POINT(-0.1278 51.5074)\",\n\t\t\t},\n\t\t\tDialectVersion: 3,\n\t\t},\n\t).Result()\n```\nYou can find further details in the [query dialect documentation](https://redis.io/docs/latest/develop/interact/search-and-query/advanced-concepts/dialects/).\n\n#### Custom buffer sizes\nPrior to v9.12, the buffer size was the default go value of 4096 bytes. Starting from v9.12, \ngo-redis uses 32KiB read and write buffers by default for optimal performance.\nFor high-throughput applications or large pipelines, you can customize buffer sizes:\n\n```go\nrdb := redis.NewClient(&redis.Options{\n    Addr:            \"localhost:6379\",\n    ReadBufferSize:  1024 * 1024, // 1MiB read buffer\n    WriteBufferSize: 1024 * 1024, // 1MiB write buffer\n})\n```\n\n**Important**: If you experience any issues with the default buffer sizes, please try setting them to the go default of 4096 bytes.\n\n## Contributing\nWe welcome contributions to the go-redis library! If you have a bug fix, feature request, or improvement, please open an issue or pull request on GitHub.\nWe appreciate your help in making go-redis better for everyone.\nIf you are interested in contributing to the go-redis library, please check out our [contributing guidelines](CONTRIBUTING.md) for more information on how to get started.\n\n## Look and feel\n\nSome corner cases:\n\n```go\n// SET key value EX 10 NX\nset, err := rdb.SetNX(ctx, \"key\", \"value\", 10*time.Second).Result()\n\n// SET key value keepttl NX\nset, err := rdb.SetNX(ctx, \"key\", \"value\", redis.KeepTTL).Result()\n\n// SORT list LIMIT 0 2 ASC\nvals, err := rdb.Sort(ctx, \"list\", &redis.Sort{Offset: 0, Count: 2, Order: \"ASC\"}).Result()\n\n// ZRANGEBYSCORE zset -inf +inf WITHSCORES LIMIT 0 2\nvals, err := rdb.ZRangeByScoreWithScores(ctx, \"zset\", &redis.ZRangeBy{\n    Min: \"-inf\",\n    Max: \"+inf\",\n    Offset: 0,\n    Count: 2,\n}).Result()\n\n// ZINTERSTORE out 2 zset1 zset2 WEIGHTS 2 3 AGGREGATE SUM\nvals, err := rdb.ZInterStore(ctx, \"out\", &redis.ZStore{\n    Keys: []string{\"zset1\", \"zset2\"},\n    Weights: []int64{2, 3}\n}).Result()\n\n// EVAL \"return {KEYS[1],ARGV[1]}\" 1 \"key\" \"hello\"\nvals, err := rdb.Eval(ctx, \"return {KEYS[1],ARGV[1]}\", []string{\"key\"}, \"hello\").Result()\n\n// custom command\nres, err := rdb.Do(ctx, \"set\", \"key\", \"value\").Result()\n```\n\n## Typed Errors\n\ngo-redis provides typed error checking functions for common Redis errors:\n\n```go\n// Cluster and replication errors\nredis.IsLoadingError(err)        // Redis is loading the dataset\nredis.IsReadOnlyError(err)       // Write to read-only replica\nredis.IsClusterDownError(err)    // Cluster is down\nredis.IsTryAgainError(err)       // Command should be retried\nredis.IsMasterDownError(err)     // Master is down\nredis.IsMovedError(err)          // Returns (address, true) if key moved\nredis.IsAskError(err)            // Returns (address, true) if key being migrated\n\n// Connection and resource errors\nredis.IsMaxClientsError(err)     // Maximum clients reached\nredis.IsAuthError(err)           // Authentication failed (NOAUTH, WRONGPASS, unauthenticated)\nredis.IsPermissionError(err)     // Permission denied (NOPERM)\nredis.IsOOMError(err)            // Out of memory (OOM)\n\n// Transaction errors\nredis.IsExecAbortError(err)      // Transaction aborted (EXECABORT)\n```\n\n### Error Wrapping in Hooks\n\nWhen wrapping errors in hooks, use custom error types with `Unwrap()` method (preferred) or `fmt.Errorf` with `%w`. Always call `cmd.SetErr()` to preserve error type information:\n\n```go\n// Custom error type (preferred)\ntype AppError struct {\n    Code      string\n    RequestID string\n    Err       error\n}\n\nfunc (e *AppError) Error() string {\n    return fmt.Sprintf(\"[%s] request_id=%s: %v\", e.Code, e.RequestID, e.Err)\n}\n\nfunc (e *AppError) Unwrap() error {\n    return e.Err\n}\n\n// Hook implementation\nfunc (h MyHook) ProcessHook(next redis.ProcessHook) redis.ProcessHook {\n    return func(ctx context.Context, cmd redis.Cmder) error {\n        err := next(ctx, cmd)\n        if err != nil {\n            // Wrap with custom error type\n            wrappedErr := &AppError{\n                Code:      \"REDIS_ERROR\",\n                RequestID: getRequestID(ctx),\n                Err:       err,\n            }\n            cmd.SetErr(wrappedErr)\n            return wrappedErr  // Return wrapped error to preserve it\n        }\n        return nil\n    }\n}\n\n// Typed error detection works through wrappers\nif redis.IsLoadingError(err) {\n    // Retry logic\n}\n\n// Extract custom error if needed\nvar appErr *AppError\nif errors.As(err, &appErr) {\n    log.Printf(\"Request: %s\", appErr.RequestID)\n}\n```\n\nAlternatively, use `fmt.Errorf` with `%w`:\n```go\nwrappedErr := fmt.Errorf(\"context: %w\", err)\ncmd.SetErr(wrappedErr)\n```\n\n### Pipeline Hook Example\n\nFor pipeline operations, use `ProcessPipelineHook`:\n\n```go\ntype PipelineLoggingHook struct{}\n\nfunc (h PipelineLoggingHook) DialHook(next redis.DialHook) redis.DialHook {\n    return next\n}\n\nfunc (h PipelineLoggingHook) ProcessHook(next redis.ProcessHook) redis.ProcessHook {\n    return next\n}\n\nfunc (h PipelineLoggingHook) ProcessPipelineHook(next redis.ProcessPipelineHook) redis.ProcessPipelineHook {\n    return func(ctx context.Context, cmds []redis.Cmder) error {\n        start := time.Now()\n\n        // Execute the pipeline\n        err := next(ctx, cmds)\n\n        duration := time.Since(start)\n        log.Printf(\"Pipeline executed %d commands in %v\", len(cmds), duration)\n\n        // Process individual command errors\n        // Note: Individual command errors are already set on each cmd by the pipeline execution\n        for _, cmd := range cmds {\n            if cmdErr := cmd.Err(); cmdErr != nil {\n                // Check for specific error types using typed error functions\n                if redis.IsAuthError(cmdErr) {\n                    log.Printf(\"Auth error in pipeline command %s: %v\", cmd.Name(), cmdErr)\n                } else if redis.IsPermissionError(cmdErr) {\n                    log.Printf(\"Permission error in pipeline command %s: %v\", cmd.Name(), cmdErr)\n                }\n\n                // Optionally wrap individual command errors to add context\n                // The wrapped error preserves type information through errors.As()\n                wrappedErr := fmt.Errorf(\"pipeline cmd %s failed: %w\", cmd.Name(), cmdErr)\n                cmd.SetErr(wrappedErr)\n            }\n        }\n\n        // Return the pipeline-level error (connection errors, etc.)\n        // You can wrap it if needed, or return it as-is\n        return err\n    }\n}\n\n// Register the hook\nrdb.AddHook(PipelineLoggingHook{})\n\n// Use pipeline - errors are still properly typed\npipe := rdb.Pipeline()\npipe.Set(ctx, \"key1\", \"value1\", 0)\npipe.Get(ctx, \"key2\")\n_, err := pipe.Exec(ctx)\n```\n\n## Run the test\n\nRecommended to use Docker, just need to run:\n```shell\nmake test\n```\n\n## See also\n\n- [Golang ORM](https://bun.uptrace.dev) for PostgreSQL, MySQL, MSSQL, and SQLite\n- [Golang PostgreSQL](https://bun.uptrace.dev/postgres/)\n- [Golang HTTP router](https://bunrouter.uptrace.dev/)\n- [Golang ClickHouse ORM](https://github.com/uptrace/go-clickhouse)\n\n## Contributors\n\n> The go-redis project was originally initiated by :star: [**uptrace/uptrace**](https://github.com/uptrace/uptrace).\n> Uptrace is an open-source APM tool that supports distributed tracing, metrics, and logs. You can\n> use it to monitor applications and set up automatic alerts to receive notifications via email,\n> Slack, Telegram, and others.\n>\n> See [OpenTelemetry](https://github.com/redis/go-redis/tree/master/example/otel) example which\n> demonstrates how you can use Uptrace to monitor go-redis.\n\nThanks to all the people who already contributed!\n\n<a href=\"https://github.com/redis/go-redis/graphs/contributors\">\n  <img src=\"https://contributors-img.web.app/image?repo=redis/go-redis\" />\n</a>\n",
      "stars_today": 9
    },
    {
      "id": 3199002,
      "name": "linux",
      "full_name": "raspberrypi/linux",
      "description": "Kernel source tree for Raspberry Pi-provided kernel builds. Issues unrelated to the linux kernel should be posted on the community forum at https://forums.raspberrypi.com/",
      "html_url": "https://github.com/raspberrypi/linux",
      "stars": 12445,
      "forks": 5350,
      "language": "C",
      "topics": [],
      "created_at": "2012-01-17T12:10:20Z",
      "updated_at": "2026-01-24T00:02:56Z",
      "pushed_at": "2026-01-23T15:55:18Z",
      "open_issues": 1052,
      "owner": {
        "login": "raspberrypi",
        "avatar_url": "https://avatars.githubusercontent.com/u/1294177?v=4"
      },
      "readme": "Linux kernel\n============\n\nThere are several guides for kernel developers and users. These guides can\nbe rendered in a number of formats, like HTML and PDF. Please read\nDocumentation/admin-guide/README.rst first.\n\nIn order to build the documentation, use ``make htmldocs`` or\n``make pdfdocs``.  The formatted documentation can also be read online at:\n\n    https://www.kernel.org/doc/html/latest/\n\nThere are various text files in the Documentation/ subdirectory,\nseveral of them using the Restructured Text markup notation.\n\nPlease read the Documentation/process/changes.rst file, as it contains the\nrequirements for building and running the kernel, and information about\nthe problems which may result by upgrading your kernel.\n\nBuild status for rpi-6.1.y:\n[![Pi kernel build tests](https://github.com/raspberrypi/linux/actions/workflows/kernel-build.yml/badge.svg?branch=rpi-6.1.y)](https://github.com/raspberrypi/linux/actions/workflows/kernel-build.yml)\n[![dtoverlaycheck](https://github.com/raspberrypi/linux/actions/workflows/dtoverlaycheck.yml/badge.svg?branch=rpi-6.1.y)](https://github.com/raspberrypi/linux/actions/workflows/dtoverlaycheck.yml)\n\nBuild status for rpi-6.6.y:\n[![Pi kernel build tests](https://github.com/raspberrypi/linux/actions/workflows/kernel-build.yml/badge.svg?branch=rpi-6.6.y)](https://github.com/raspberrypi/linux/actions/workflows/kernel-build.yml)\n[![dtoverlaycheck](https://github.com/raspberrypi/linux/actions/workflows/dtoverlaycheck.yml/badge.svg?branch=rpi-6.6.y)](https://github.com/raspberrypi/linux/actions/workflows/dtoverlaycheck.yml)\n\nBuild status for rpi-6.12.y:\n[![Pi kernel build tests](https://github.com/raspberrypi/linux/actions/workflows/kernel-build.yml/badge.svg?branch=rpi-6.12.y)](https://github.com/raspberrypi/linux/actions/workflows/kernel-build.yml)\n[![dtoverlaycheck](https://github.com/raspberrypi/linux/actions/workflows/dtoverlaycheck.yml/badge.svg?branch=rpi-6.12.y)](https://github.com/raspberrypi/linux/actions/workflows/dtoverlaycheck.yml)\n",
      "stars_today": 9
    },
    {
      "id": 1060901286,
      "name": "Wholphin",
      "full_name": "damontecres/Wholphin",
      "description": "An OSS Android TV client for Jellyfin",
      "html_url": "https://github.com/damontecres/Wholphin",
      "stars": 1034,
      "forks": 31,
      "language": "Kotlin",
      "topics": [
        "android-tv",
        "fire-tv",
        "jellyfin",
        "jellyfin-client"
      ],
      "created_at": "2025-09-20T20:31:30Z",
      "updated_at": "2026-01-23T22:00:39Z",
      "pushed_at": "2026-01-23T14:20:57Z",
      "open_issues": 185,
      "owner": {
        "login": "damontecres",
        "avatar_url": "https://avatars.githubusercontent.com/u/154766448?v=4"
      },
      "readme": "# Wholphin - an OSS Android TV client for Jellyfin\n\n> \"Never half-phin two jellies. Always wholphin one jelly.\"\n\nWholphin is an open-source Android TV client for Jellyfin. It aims to provide a different app UI that's inspired by Plex for users interested in migrating to Jellyfin.\n\nThis is not a fork of the [official client](https://github.com/jellyfin/jellyfin-androidtv). Wholphin's user interface and controls have been written completely from scratch. Wholphin `v0.3.0+` supports playing media using either ExoPlayer/Media3 or MPV (experimental).\n\n<p align=\"center\">\n<a href=\"https://github.com/damontecres/Wholphin/releases\">\n<img alt=\"Current Release\" src=\"https://img.shields.io/github/release/damontecres/wholphin.svg\"/>\n</a>\n<a href=\"https://translate.codeberg.org/engage/wholphin/\">\n<img src=\"https://translate.codeberg.org/widget/wholphin/wholphin/svg-badge.svg\" alt=\"Translation status\" />\n</a>\n<br/>\n<a href=\"https://play.google.com/store/apps/details?id=com.github.damontecres.wholphin\">\n<img width=\"180\" alt=\"Get Wholphin on Google Play\" src=\"https://github.com/user-attachments/assets/2550a4cb-ce46-47a1-ae24-f33a169234b7\"/>\n</a>\n<a href=\"https://www.amazon.com/gp/product/B0G8RQQR9T/ref=mas_pm_wholphin\">\n<img width=\"180\" alt=\"Get Wholphin on Amazon AppStore\" src=\"https://github.com/user-attachments/assets/1f3a3b26-4b4f-44b1-9741-f4c895c8a53b\"/>\n</a>\n\n\n</p>\n\n<img width=\"1280\" height=\"720\" alt=\"0_3_5_home\" src=\"https://github.com/user-attachments/assets/a485c015-ec21-442d-a757-1f18381bf799\" />\n\n## Features\n\n### User interface\n\n- A navigation drawer for quick access to libraries, favorites, search, and settings from almost anywhere in the app\n- Integration with [Seerr](https://github.com/seerr-team/seerr) to discover new movies and TV shows\n- Option to combine Continue Watching & Next Up rows\n- Show Movie/TV Show titles when browsing libraries\n- Play theme music, if available\n- Customize subtitle style for plain text subtitles\n- Search & download subtitles (requires compatible server plugin such as [OpenSubtitles](https://github.com/jellyfin/jellyfin-plugin-opensubtitles))\n- Customize layout grids for libraries\n- Multiple app color themes\n- Protect user profile switches with PIN code\n\n### Playback\n\n- Different media playback engines:\n  - **ExoPlayer** w/ optional extra audio & AV1 software decoding\n  - **MPV** for direct playing anything plus ASS subtitle support\n- Plex inspired playback controls:\n  - Using D-Pad left/right for seeking during playback\n  - Quickly access video chapters & queue during playback\n  - Optionally skip back a few seconds when resuming playback\n- Live TV & DVR support\n- Auto play next episodes with pass out protection\n- Option for automatic refresh rate & resolution switching on supported displays\n- Trickplay support\n- Subtly show playback position along the bottom of the screen while seeking w/ D-Pad\n\n\n### Roadmap\n\nSee [here for the roadmap](https://github.com/damontecres/Wholphin/wiki#roadmap)\n\n## Installation\n\nUsing [Google Play](https://play.google.com/store/apps/details?id=com.github.damontecres.wholphin) or [Amazon appstore](https://www.amazon.com/gp/product/B0G8RQQR9T/ref=mas_pm_wholphin) are the fastest way to install. But you can follow these instructions to install without needing an app store\n\nDownloader Code: `8668671`\n\n1. Enable side-loading \"unknown\" apps\n    - https://androidtvnews.com/unknown-sources-chromecast-google-tv/\n    - https://www.xda-developers.com/how-to-sideload-apps-android-tv/\n    - https://developer.android.com/distribute/marketing-tools/alternative-distribution#unknown-sources\n    - https://www.aftvnews.com/how-to-enable-apps-from-unknown-sources-on-an-amazon-fire-tv-or-fire-tv-stick/\n2. Install the APK on your Android TV device with one of these options:\n    - Install a browser program such as [Downloader](https://www.aftvnews.com/downloader/), use it to get the latest apk with short code `8668671` or URL: http://aftv.news/8668671\n    - Download the latest APK release from the [releases page](https://github.com/damontecres/Wholphin/releases/latest) or http://aftv.news/8668671\n        - Put the APK on an SD Card/USB stick/network share and use a file manager app from the Google Play Store / Amazon AppStore (e.g. `FX File Explorer`). Android's preinstalled file manager probably will not work!\n        - Use `Send files to TV` from the Google Play Store on your phone & TV\n        - (Expert) Use [ADB](https://developer.android.com/studio/command-line/adb) to install the APK from your computer ([guide](https://fossbytes.com/side-load-apps-android-tv/#h-how-to-sideload-apps-on-your-android-tv-using-adb))\n\n### Upgrading the app\n\nAfter the initial install above, the app will automatically check for updates. The updates can be installed in settings.\n\nThe first time you attempt an update, the OS should guide you through enabling the required additional permissions for the app to install updates.\n\nNote: if installed via an app store, the app store will handle updates.\n\n## Compatibility\n\nRequires Android 6+ (or Fire TV OS 6+) and Jellyfin server `10.10.x` or `10.11.x` (tested on primarily `10.11`).\n\nThe app is tested on a variety of Android TV/Fire TV OS devices, but if you encounter issues, please file an issue!\n\n## Contributions\n\nIssues and pull requests are always welcome! Please check before submitting that your issue or pull request is not a duplicate.\n\nIf you plan to contribute, please read the [contributing guide](CONTRIBUTING.md)!\n\nYou can [help translate Wholphin](https://translate.codeberg.org/engage/wholphin/)!\n\n## Acknowledgements\n\n- Thanks to the Jellyfin team for creating and maintaining such a great open-source media server\n- Thanks to the official Jellyfin Android TV client developers, some code for creating the device direct play profile is adapted from there\n- Thanks to the Jellyfin Kotlin SDK developers for making it easier to interact with the Jellyfin server API\n- Thanks to numerous other libraries that make app development even possible\n\n## Additional screenshots\n\n### Movie library browsing\n<img width=\"1280\" height=\"771\" alt=\"0 3 0_movies\" src=\"https://github.com/user-attachments/assets/a49829b5-bc2c-4af9-8d5d-2f7d0973ce01\" />\n\n### Movie page\n<img width=\"1280\" height=\"720\" alt=\"0_3_5_movie\" src=\"https://github.com/user-attachments/assets/86af5889-6761-426a-8649-422f9d0a1dc0\" />\n\n### Series page\n<img width=\"1280\" height=\"720\" alt=\"0_3_5_series\" src=\"https://github.com/user-attachments/assets/2dcb2260-53ce-49d6-9088-72cbd4563c48\" />\n\n### Playlist\n<img width=\"1280\" height=\"771\" alt=\"0 3 0_playlist\" src=\"https://github.com/user-attachments/assets/7ca589ab-9c88-483a-b769-35ffb5663d9e\" />\n",
      "stars_today": 9
    },
    {
      "id": 39840932,
      "name": "googletest",
      "full_name": "google/googletest",
      "description": "GoogleTest - Google Testing and Mocking Framework",
      "html_url": "https://github.com/google/googletest",
      "stars": 38124,
      "forks": 10677,
      "language": "C++",
      "topics": [],
      "created_at": "2015-07-28T15:07:53Z",
      "updated_at": "2026-01-23T23:09:45Z",
      "pushed_at": "2026-01-17T05:52:03Z",
      "open_issues": 506,
      "owner": {
        "login": "google",
        "avatar_url": "https://avatars.githubusercontent.com/u/1342004?v=4"
      },
      "readme": "# GoogleTest\n\n### Announcements\n\n#### Documentation Updates\n\nOur documentation is now live on GitHub Pages at\nhttps://google.github.io/googletest/. We recommend browsing the documentation on\nGitHub Pages rather than directly in the repository.\n\n#### Release 1.17.0\n\n[Release 1.17.0](https://github.com/google/googletest/releases/tag/v1.17.0) is\nnow available.\n\nThe 1.17.x branch\n[requires at least C++17](https://opensource.google/documentation/policies/cplusplus-support#c_language_standard).\n\n#### Continuous Integration\n\nWe use Google's internal systems for continuous integration.\n\n#### Coming Soon\n\n*   We are planning to take a dependency on\n    [Abseil](https://github.com/abseil/abseil-cpp).\n\n## Welcome to **GoogleTest**, Google's C++ test framework!\n\nThis repository is a merger of the formerly separate GoogleTest and GoogleMock\nprojects. These were so closely related that it makes sense to maintain and\nrelease them together.\n\n### Getting Started\n\nSee the [GoogleTest User's Guide](https://google.github.io/googletest/) for\ndocumentation. We recommend starting with the\n[GoogleTest Primer](https://google.github.io/googletest/primer.html).\n\nMore information about building GoogleTest can be found at\n[googletest/README.md](googletest/README.md).\n\n## Features\n\n*   xUnit test framework: \\\n    Googletest is based on the [xUnit](https://en.wikipedia.org/wiki/XUnit)\n    testing framework, a popular architecture for unit testing\n*   Test discovery: \\\n    Googletest automatically discovers and runs your tests, eliminating the need\n    to manually register your tests\n*   Rich set of assertions: \\\n    Googletest provides a variety of assertions, such as equality, inequality,\n    exceptions, and more, making it easy to test your code\n*   User-defined assertions: \\\n    You can define your own assertions with Googletest, making it simple to\n    write tests that are specific to your code\n*   Death tests: \\\n    Googletest supports death tests, which verify that your code exits in a\n    certain way, making it useful for testing error-handling code\n*   Fatal and non-fatal failures: \\\n    You can specify whether a test failure should be treated as fatal or\n    non-fatal with Googletest, allowing tests to continue running even if a\n    failure occurs\n*   Value-parameterized tests: \\\n    Googletest supports value-parameterized tests, which run multiple times with\n    different input values, making it useful for testing functions that take\n    different inputs\n*   Type-parameterized tests: \\\n    Googletest also supports type-parameterized tests, which run with different\n    data types, making it useful for testing functions that work with different\n    data types\n*   Various options for running tests: \\\n    Googletest provides many options for running tests including running\n    individual tests, running tests in a specific order and running tests in\n    parallel\n\n## Supported Platforms\n\nGoogleTest follows Google's\n[Foundational C++ Support Policy](https://opensource.google/documentation/policies/cplusplus-support).\nSee\n[this table](https://github.com/google/oss-policies-info/blob/main/foundational-cxx-support-matrix.md)\nfor a list of currently supported versions of compilers, platforms, and build\ntools.\n\n## Who Is Using GoogleTest?\n\nIn addition to many internal projects at Google, GoogleTest is also used by the\nfollowing notable projects:\n\n*   The [Chromium projects](https://www.chromium.org/) (behind the Chrome\n    browser and Chrome OS).\n*   The [LLVM](https://llvm.org/) compiler.\n*   [Protocol Buffers](https://github.com/google/protobuf), Google's data\n    interchange format.\n*   The [OpenCV](https://opencv.org/) computer vision library.\n\n## Related Open Source Projects\n\n[GTest Runner](https://github.com/nholthaus/gtest-runner) is a Qt5 based\nautomated test-runner and Graphical User Interface with powerful features for\nWindows and Linux platforms.\n\n[GoogleTest UI](https://github.com/ospector/gtest-gbar) is a test runner that\nruns your test binary, allows you to track its progress via a progress bar, and\ndisplays a list of test failures. Clicking on one shows failure text. GoogleTest\nUI is written in C#.\n\n[GTest TAP Listener](https://github.com/kinow/gtest-tap-listener) is an event\nlistener for GoogleTest that implements the\n[TAP protocol](https://en.wikipedia.org/wiki/Test_Anything_Protocol) for test\nresult output. If your test runner understands TAP, you may find it useful.\n\n[gtest-parallel](https://github.com/google/gtest-parallel) is a test runner that\nruns tests from your binary in parallel to provide significant speed-up.\n\n[GoogleTest Adapter](https://marketplace.visualstudio.com/items?itemName=DavidSchuldenfrei.gtest-adapter)\nis a VS Code extension allowing to view GoogleTest in a tree view and run/debug\nyour tests.\n\n[C++ TestMate](https://github.com/matepek/vscode-catch2-test-adapter) is a VS\nCode extension allowing to view GoogleTest in a tree view and run/debug your\ntests.\n\n[Cornichon](https://pypi.org/project/cornichon/) is a small Gherkin DSL parser\nthat generates stub code for GoogleTest.\n\n## Contributing Changes\n\nPlease read\n[`CONTRIBUTING.md`](https://github.com/google/googletest/blob/main/CONTRIBUTING.md)\nfor details on how to contribute to this project.\n\nHappy testing!\n",
      "stars_today": 8
    },
    {
      "id": 5298790,
      "name": "PX4-Autopilot",
      "full_name": "PX4/PX4-Autopilot",
      "description": "PX4 Autopilot Software",
      "html_url": "https://github.com/PX4/PX4-Autopilot",
      "stars": 10942,
      "forks": 14951,
      "language": "C++",
      "topics": [
        "autonomous",
        "autopilot",
        "avoidance",
        "dds",
        "drone",
        "dronecode",
        "drones",
        "fixed-wing",
        "mavlink",
        "mavros",
        "multicopter",
        "pixhawk",
        "px4",
        "qgroundcontrol",
        "ros",
        "ros2",
        "uas",
        "uav",
        "ugv"
      ],
      "created_at": "2012-08-04T21:19:36Z",
      "updated_at": "2026-01-24T00:47:34Z",
      "pushed_at": "2026-01-24T00:47:28Z",
      "open_issues": 1802,
      "owner": {
        "login": "PX4",
        "avatar_url": "https://avatars.githubusercontent.com/u/2096014?v=4"
      },
      "readme": "# PX4 Drone Autopilot\n\n[![Releases](https://img.shields.io/github/release/PX4/PX4-Autopilot.svg)](https://github.com/PX4/PX4-Autopilot/releases) [![DOI](https://zenodo.org/badge/22634/PX4/PX4-Autopilot.svg)](https://zenodo.org/badge/latestdoi/22634/PX4/PX4-Autopilot)\n\n[![Build Targets](https://github.com/PX4/PX4-Autopilot/actions/workflows/build_all_targets.yml/badge.svg?branch=main)](https://github.com/PX4/PX4-Autopilot/actions/workflows/build_all_targets.yml) [![SITL Tests](https://github.com/PX4/PX4-Autopilot/workflows/SITL%20Tests/badge.svg?branch=master)](https://github.com/PX4/PX4-Autopilot/actions?query=workflow%3A%22SITL+Tests%22)\n\n[![Discord Shield](https://discordapp.com/api/guilds/1022170275984457759/widget.png?style=shield)](https://discord.gg/dronecode)\n\nThis repository holds the [PX4](http://px4.io) flight control solution for drones, with the main applications located in the [src/modules](https://github.com/PX4/PX4-Autopilot/tree/main/src/modules) directory. It also contains the PX4 Drone Middleware Platform, which provides drivers and middleware to run drones.\n\nPX4 is highly portable, OS-independent and supports Linux, NuttX and MacOS out of the box.\n\n* Official Website: http://px4.io (License: BSD 3-clause, [LICENSE](https://github.com/PX4/PX4-Autopilot/blob/main/LICENSE))\n* [Supported airframes](https://docs.px4.io/main/en/airframes/airframe_reference.html) ([portfolio](https://px4.io/ecosystem/commercial-systems/)):\n  * [Multicopters](https://docs.px4.io/main/en/frames_multicopter/)\n  * [Fixed wing](https://docs.px4.io/main/en/frames_plane/)\n  * [VTOL](https://docs.px4.io/main/en/frames_vtol/)\n  * [Autogyro](https://docs.px4.io/main/en/frames_autogyro/)\n  * [Rover](https://docs.px4.io/main/en/frames_rover/)\n  * many more experimental types (Blimps, Boats, Submarines, High Altitude Balloons, Spacecraft, etc)\n* Releases: [Downloads](https://github.com/PX4/PX4-Autopilot/releases)\n\n## Releases\n\nRelease notes and supporting information for PX4 releases can be found on the [Developer Guide](https://docs.px4.io/main/en/releases/).\n\n## Building a PX4 based drone, rover, boat or robot\n\nThe [PX4 User Guide](https://docs.px4.io/main/en/) explains how to assemble [supported vehicles](https://docs.px4.io/main/en/airframes/airframe_reference.html) and fly drones with PX4. See the [forum and chat](https://docs.px4.io/main/en/#getting-help) if you need help!\n\n\n## Changing Code and Contributing\n\nThis [Developer Guide](https://docs.px4.io/main/en/development/development.html) is for software developers who want to modify the flight stack and middleware (e.g. to add new flight modes), hardware integrators who want to support new flight controller boards and peripherals, and anyone who wants to get PX4 working on a new (unsupported) airframe/vehicle.\n\nDevelopers should read the [Guide for Contributions](https://docs.px4.io/main/en/contribute/).\nSee the [forum and chat](https://docs.px4.io/main/en/#getting-help) if you need help!\n\n\n## Weekly Dev Call\n\nThe PX4 Dev Team syncs up on a [weekly dev call](https://docs.px4.io/main/en/contribute/).\n\n> **Note** The dev call is open to all interested developers (not just the core dev team). This is a great opportunity to meet the team and contribute to the ongoing development of the platform. It includes a QA session for newcomers. All regular calls are listed in the [Dronecode calendar](https://www.dronecode.org/calendar/).\n\n\n## Maintenance Team\n\nSee the latest list of maintainers on [MAINTAINERS](MAINTAINERS.md) file at the root of the project.\n\nFor the latest stats on contributors please see the latest stats for the Dronecode ecosystem in our project dashboard under [LFX Insights](https://insights.lfx.linuxfoundation.org/foundation/dronecode). For information on how to update your profile and affiliations please see the following support link on how to [Complete Your LFX Profile](https://docs.linuxfoundation.org/lfx/my-profile/complete-your-lfx-profile). Dronecode publishes a yearly snapshot of contributions and achievements on its [website under the Reports section](https://dronecode.org).\n\n## Supported Hardware\n\nFor the most up to date information, please visit [PX4 User Guide > Autopilot Hardware](https://docs.px4.io/main/en/flight_controller/).\n\n## Project Governance\n\nThe PX4 Autopilot project including all of its trademarks is hosted under [Dronecode](https://www.dronecode.org/), part of the Linux Foundation.\n\n<a href=\"https://www.dronecode.org/\" style=\"padding:20px\" ><img src=\"https://dronecode.org/wp-content/uploads/sites/24/2020/08/dronecode_logo_default-1.png\" alt=\"Dronecode Logo\" width=\"110px\"/></a>\n<div style=\"padding:10px\">&nbsp;</div>\n",
      "stars_today": 8
    },
    {
      "id": 12226786,
      "name": "sharp",
      "full_name": "lovell/sharp",
      "description": "High performance Node.js image processing, the fastest module to resize JPEG, PNG, WebP, AVIF and TIFF images. Uses the libvips library.",
      "html_url": "https://github.com/lovell/sharp",
      "stars": 31784,
      "forks": 1380,
      "language": "JavaScript",
      "topics": [
        "avif",
        "crop",
        "exif",
        "icc",
        "image",
        "image-processing",
        "javascript",
        "jpeg",
        "libvips",
        "nodejs",
        "performance",
        "png",
        "resize",
        "sharp",
        "svg",
        "tiff",
        "webp"
      ],
      "created_at": "2013-08-19T20:24:24Z",
      "updated_at": "2026-01-23T12:27:34Z",
      "pushed_at": "2026-01-23T22:46:54Z",
      "open_issues": 115,
      "owner": {
        "login": "lovell",
        "avatar_url": "https://avatars.githubusercontent.com/u/210965?v=4"
      },
      "readme": "# sharp\n\n<img src=\"https://sharp.pixelplumbing.com/sharp-logo.svg\" width=\"160\" height=\"160\" alt=\"sharp logo\" align=\"right\">\n\nThe typical use case for this high speed Node-API module\nis to convert large images in common formats to\nsmaller, web-friendly JPEG, PNG, WebP, GIF and AVIF images of varying dimensions.\n\nIt can be used with all JavaScript runtimes\nthat provide support for Node-API v9, including\nNode.js (^18.17.0 or >= 20.3.0), Deno and Bun.\n\nResizing an image is typically 4x-5x faster than using the\nquickest ImageMagick and GraphicsMagick settings\ndue to its use of [libvips](https://github.com/libvips/libvips).\n\nColour spaces, embedded ICC profiles and alpha transparency channels are all handled correctly.\nLanczos resampling ensures quality is not sacrificed for speed.\n\nAs well as image resizing, operations such as\nrotation, extraction, compositing and gamma correction are available.\n\nMost modern macOS, Windows and Linux systems\ndo not require any additional install or runtime dependencies.\n\n## Documentation\n\nVisit [sharp.pixelplumbing.com](https://sharp.pixelplumbing.com/) for complete\n[installation instructions](https://sharp.pixelplumbing.com/install),\n[API documentation](https://sharp.pixelplumbing.com/api-constructor),\n[benchmark tests](https://sharp.pixelplumbing.com/performance) and\n[changelog](https://sharp.pixelplumbing.com/changelog).\n\n## Examples\n\n```sh\nnpm install sharp\n```\n\n```javascript\nconst sharp = require('sharp');\n```\n\n### Callback\n\n```javascript\nsharp(inputBuffer)\n  .resize(320, 240)\n  .toFile('output.webp', (err, info) => { ... });\n```\n\n### Promise\n\n```javascript\nsharp('input.jpg')\n  .rotate()\n  .resize(200)\n  .jpeg({ mozjpeg: true })\n  .toBuffer()\n  .then( data => { ... })\n  .catch( err => { ... });\n```\n\n### Async/await\n\n```javascript\nconst semiTransparentRedPng = await sharp({\n  create: {\n    width: 48,\n    height: 48,\n    channels: 4,\n    background: { r: 255, g: 0, b: 0, alpha: 0.5 }\n  }\n})\n  .png()\n  .toBuffer();\n```\n\n### Stream\n\n```javascript\nconst roundedCorners = Buffer.from(\n  '<svg><rect x=\"0\" y=\"0\" width=\"200\" height=\"200\" rx=\"50\" ry=\"50\"/></svg>'\n);\n\nconst roundedCornerResizer =\n  sharp()\n    .resize(200, 200)\n    .composite([{\n      input: roundedCorners,\n      blend: 'dest-in'\n    }])\n    .png();\n\nreadableStream\n  .pipe(roundedCornerResizer)\n  .pipe(writableStream);\n```\n\n## Contributing\n\nA [guide for contributors](https://github.com/lovell/sharp/blob/main/.github/CONTRIBUTING.md)\ncovers reporting bugs, requesting features and submitting code changes.\n\n## Licensing\n\nCopyright 2013 Lovell Fuller and others.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n[https://www.apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0)\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n",
      "stars_today": 8
    },
    {
      "id": 253044228,
      "name": "nuclei-templates",
      "full_name": "projectdiscovery/nuclei-templates",
      "description": "Community curated list of templates for the nuclei engine to find security vulnerabilities.",
      "html_url": "https://github.com/projectdiscovery/nuclei-templates",
      "stars": 11833,
      "forks": 3322,
      "language": "JavaScript",
      "topics": [
        "bugbounty",
        "exploit-development",
        "exploits",
        "fingerprint",
        "hacktoberfest",
        "nuclei",
        "nuclei-checks",
        "nuclei-templates",
        "security",
        "vulnerability-detection"
      ],
      "created_at": "2020-04-04T16:21:34Z",
      "updated_at": "2026-01-24T01:15:15Z",
      "pushed_at": "2026-01-23T12:15:15Z",
      "open_issues": 159,
      "owner": {
        "login": "projectdiscovery",
        "avatar_url": "https://avatars.githubusercontent.com/u/50994705?v=4"
      },
      "readme": "\n\n<h1 align=\"center\">\nNuclei Templates\n</h1>\n<h4 align=\"center\">Community curated list of templates for the nuclei engine to find security vulnerabilities in applications.</h4>\n\n\n<p align=\"center\">\n<a href=\"https://github.com/projectdiscovery/nuclei-templates/issues\"><img src=\"https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat\"></a>\n<a href=\"https://github.com/projectdiscovery/nuclei-templates/releases\"><img src=\"https://img.shields.io/github/release/projectdiscovery/nuclei-templates\"></a>\n<a href=\"https://twitter.com/pdnuclei\"><img src=\"https://img.shields.io/twitter/follow/pdnuclei.svg?logo=twitter\"></a>\n<a href=\"https://discord.gg/projectdiscovery\"><img src=\"https://img.shields.io/discord/695645237418131507.svg?logo=discord\"></a>\n</p>\n      \n<p align=\"center\">\n  <a href=\"https://docs.projectdiscovery.io/templates/introduction\">Documentation</a> ‚Ä¢\n  <a href=\"#-contributions\">Contributions</a> ‚Ä¢\n  <a href=\"#-discussion\">Discussion</a> ‚Ä¢\n  <a href=\"#-community\">Community</a> ‚Ä¢\n  <a href=\"https://docs.projectdiscovery.io/templates/faq\">FAQs</a> ‚Ä¢\n  <a href=\"https://discord.gg/projectdiscovery\">Join Discord</a>\n</p>\n\n----\n\nTemplates are the core of the [nuclei scanner](https://github.com/projectdiscovery/nuclei) which powers the actual scanning engine.\nThis repository stores and houses various templates for the scanner provided by our team, as well as contributed by the community.\nWe hope that you also contribute by sending templates via **pull requests** or [Github issues](https://github.com/projectdiscovery/nuclei-templates/issues/new?assignees=&labels=&template=submit-template.md&title=%5Bnuclei-template%5D+) to grow the list.\n\n\n## Nuclei Templates overview\n\n\nAn overview of the nuclei template project, including statistics on unique tags, author, directory, severity, and type of templates. The table below contains the top ten statistics for each matrix; an expanded version of this is [available here](TEMPLATES-STATS.md), and also available in [JSON](TEMPLATES-STATS.json) format for integration.\n\n<table>\n<tr>\n<td>\n\n### üö® Known Exploited Vulnerabilities (KEV) Coverage\n\nNuclei templates provide coverage for vulnerabilities actively exploited in the wild:\n\n| **KEV Source** | **Templates** | **Description** |\n|----------------|---------------|-----------------|\n| üî¥ **CISA KEV** | **454** | [CISA Known Exploited Vulnerabilities Catalog](https://www.cisa.gov/known-exploited-vulnerabilities-catalog) |\n| üü† **VulnCheck KEV** | **1449** | [VulnCheck KEV](https://vulncheck.com/kev) - Enhanced vulnerability intelligence |\n| üü¢ **Both Sources** | **407** | Templates covering vulnerabilities in both catalogs |\n\n> üí° **Total unique KEV templates: 1496** - Use `nuclei -tags kev,vkev` to scan for actively exploited vulnerabilities\n\n---\n\n## Nuclei Templates Top 10 statistics\n\n|    TAG    | COUNT |    AUTHOR     | COUNT | DIRECTORY  | COUNT | SEVERITY | COUNT | TYPE | COUNT |\n|-----------|-------|---------------|-------|------------|-------|----------|-------|------|-------|\n| vuln      |  6468 | dhiyaneshdk   |  1894 | http       |  9281 | info     |  4353 | file |   436 |\n| cve       |  3587 | daffainfo     |   905 | cloud      |   659 | high     |  2552 | dns  |    26 |\n| discovery |  3265 | princechaddha |   854 | file       |   436 | medium   |  2457 |      |       |\n| vkev      |  1394 | dwisiswant0   |   805 | network    |   259 | critical |  1555 |      |       |\n| panel     |  1365 | ritikchaddha  |   678 | code       |   251 | low      |   330 |      |       |\n| xss       |  1269 | pussycat0x    |   675 | dast       |   240 | unknown  |    54 |      |       |\n| wordpress |  1261 | pikpikcu      |   353 | workflows  |   205 |          |       |      |       |\n| exposure  |  1141 | pdteam        |   314 | javascript |    92 |          |       |      |       |\n| wp-plugin |  1103 | pdresearch    |   275 | ssl        |    38 |          |       |      |       |\n| osint     |   848 | iamnoooob     |   263 | dns        |    23 |          |       |      |       |\n\n**873 directories, 11997 files**.\n\n</td>\n</tr>\n</table>\n\nüìñ Documentation\n-----\n\nPlease navigate to https://nuclei.projectdiscovery.io for detailed documentation to **build** new or your own **custom** templates.\nWe have also added a set of templates to help you understand how things work.\n\nüí™ Contributions\n-----\n\nNuclei-templates is powered by major contributions from the community.\n[Template contributions ](https://github.com/projectdiscovery/nuclei-templates/issues/new?assignees=&labels=&template=submit-template.md&title=%5Bnuclei-template%5D+), [Feature Requests](https://github.com/projectdiscovery/nuclei-templates/issues/new?assignees=&labels=&template=feature_request.md&title=%5BFeature%5D+) and [Bug Reports](https://github.com/projectdiscovery/nuclei-templates/issues/new?assignees=&labels=&template=bug_report.md&title=%5BBug%5D+) are more than welcome.\n\n![Alt](https://repobeats.axiom.co/api/embed/55ee65543bb9a0f9c797626c4e66d472a517d17c.svg \"Repobeats analytics image\")\n\nüí¨ Discussion\n-----\n\nHave questions / doubts / ideas to discuss?\nFeel free to open a discussion on [Github discussions](https://github.com/projectdiscovery/nuclei-templates/discussions) board.\n\nüë®‚Äçüíª Community\n-----\n\nYou are welcome to join the active [Discord Community](https://discord.gg/projectdiscovery) to discuss directly with project maintainers and share things with others around security and automation.\nAdditionally, you may follow us on [Twitter](https://twitter.com/pdnuclei) to be updated on all the things about Nuclei.\n\n\n<p align=\"center\">\n<a href=\"https://github.com/projectdiscovery/nuclei-templates/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=projectdiscovery/nuclei-templates&max=300\">\n</a>\n</p>\n\n\nThanks again for your contribution and keeping this community vibrant. :heart:\n",
      "stars_today": 8
    },
    {
      "id": 227091502,
      "name": "perfetto",
      "full_name": "google/perfetto",
      "description": "Production-grade client-side tracing, profiling, and analysis for complex software systems.",
      "html_url": "https://github.com/google/perfetto",
      "stars": 5445,
      "forks": 669,
      "language": "C++",
      "topics": [],
      "created_at": "2019-12-10T10:32:44Z",
      "updated_at": "2026-01-23T22:22:35Z",
      "pushed_at": "2026-01-24T02:04:37Z",
      "open_issues": 200,
      "owner": {
        "login": "google",
        "avatar_url": "https://avatars.githubusercontent.com/u/1342004?v=4"
      },
      "readme": "# Perfetto - System profiling, app tracing and trace analysis\n\nPerfetto is an open-source suite of SDKs, daemons and tools which use\n**tracing** to help developers understand the behaviour of complex systems and\nroot-cause functional and performance issues on client and embedded systems.\n\nIt is a production-grade tool that is the default tracing system for the\n**Android operating system** and the **Chromium browser**.\n\n![](docs/images/perfetto-stack.svg)\n\n## Core Components\n\nPerfetto is not a single tool, but a collection of components that work\ntogether:\n\n- **High-performance tracing daemons:** For capturing tracing information from\n  many processes on a single machine into a unified trace file.\n- **Low-overhead tracing SDK:** A C++17 library for direct\n  userspace-to-userspace tracing of timings and state changes in your\n  application.\n- **Extensive OS-level probes:** For capturing system-wide context on Android\n  and Linux (e.g. scheduling states, CPU frequencies, memory profiling,\n  callstack sampling).\n- **Browser-based UI:** A powerful, fully local UI for visualizing and exploring\n  large, multi-GB traces on a timeline. It works in all major browsers, requires\n  no installation, and can open traces from other tools.\n- **SQL-based analysis library:** A powerful engine that allows you to\n  programmatically query traces using SQL to automate analysis and extract\n  custom metrics.\n\n## Why Use Perfetto?\n\nPerfetto was designed to be a versatile and powerful tracing system for a wide\nrange of use cases.\n\n- **For Android App & Platform Developers:** Debug and root-cause functional and\n  performance issues like slow startups, dropped frames (jank), animation\n  glitches, low memory kills, and ANRs. Profile both Java/Kotlin and native C++\n  memory usage with heap dumps and profiles.\n- **For C/C++ Developers (Linux, macOS, Windows):** Use the\n  [Tracing SDK](docs/instrumentation/tracing-sdk.md) to instrument your\n  application with custom trace points to understand its execution flow, find\n  performance bottlenecks, and debug complex behavior. On Linux, you can also\n  perform detailed CPU and native heap profiling.\n- **For Linux Kernel & System Developers:** Get deep insights into kernel\n  behavior. Perfetto acts as an efficient userspace daemon for `ftrace`,\n  allowing you to visualize scheduling, syscalls, interrupts, and custom kernel\n  tracepoints on a timeline.\n- **For Chromium Developers:** Perfetto is the tracing backend for\n  `chrome://tracing`. Use it to debug and root-cause issues in the browser, V8,\n  and Blink.\n- **For Performance Engineers & SREs:** Analyze and visualize a wide range of\n  profiling and tracing formats, not just Perfetto's. Use the powerful SQL\n  interface to programmatically analyze traces from tools like **Linux perf**,\n  **macOS Instruments**, **Chrome JSON traces**, and more.\n\n## Getting Started\n\nWe've designed our documentation to guide you to the right information as\nquickly as possible, whether you're a newcomer to performance analysis or an\nexperienced developer.\n\n1.  **New to tracing?** If you're unfamiliar with concepts like tracing and\n    profiling, start here:\n\n    - [**What is Tracing?**](https://perfetto.dev/docs/tracing-101) - A gentle\n      introduction to the world of performance analysis.\n\n2.  **Ready to dive in?** Our \"Getting Started\" guide is the main entry point\n    for all users. It will help you find the right tutorials and documentation\n    for your specific needs:\n\n    - [**How do I start using Perfetto?**](https://perfetto.dev/docs/getting-started/start-using-perfetto) -\n      Find your path based on your role and goals (e.g., Android App Developer,\n      C/C++ Developer, etc.).\n\n3.  **Want the full overview?** For a comprehensive look at what Perfetto is,\n    why it's useful, and who uses it, see our main documentation page:\n    - [**Perfetto Documentation Home**](https://perfetto.dev/docs/)\n\n## Debian Distribution\n\nFor users interested in the Debian distribution of Perfetto, the official source\nof truth and packaging efforts are maintained at\n[Debian Perfetto Salsa Repository](https://salsa.debian.org/debian/perfetto)\n\n## Community & Support\n\nHave questions? Need help?\n\n- **[GitHub Discussions](https://github.com/google/perfetto/discussions/categories/q-a):**\n  For Q&A and general discussions.\n- **[GitHub Issues](https://github.com/google/perfetto/issues):** For bug\n  reports.\n- **[Discord](https://discord.gg/35ShE3A):** For live chat with the community\n  and developers.\n\nWe follow\n[Google's Open Source Community Guidelines](https://opensource.google/conduct/).\n",
      "stars_today": 8
    },
    {
      "id": 681022285,
      "name": "smallweb",
      "full_name": "kagisearch/smallweb",
      "description": "Kagi Small Web",
      "html_url": "https://github.com/kagisearch/smallweb",
      "stars": 1120,
      "forks": 479,
      "language": "JavaScript",
      "topics": [],
      "created_at": "2023-08-21T05:15:13Z",
      "updated_at": "2026-01-23T20:13:07Z",
      "pushed_at": "2026-01-23T20:13:02Z",
      "open_issues": 11,
      "owner": {
        "login": "kagisearch",
        "avatar_url": "https://avatars.githubusercontent.com/u/92134518?v=4"
      },
      "readme": "# Kagi Small Web\n\nKagi Small Web is an initiative by [Kagi](https://kagi.com).\n\nKagi's mission is to humanize the web and this project is built to help surface recent results from the small web - people and stories that typically zip by in legacy search engines. Read more about it in the announcement [blog post](https://blog.kagi.com/small-web).\n\nFew things to note:\n\n- [Kagi search engine](https://kagi.com) surfaces posts from the small web for relevant queries in its search results. \n\n- Try the [Kagi Small Web](https://kagi.com/smallweb) website.\n\n- You can also use the [RSS feed](https://kagi.com/api/v1/smallweb/feed) or access these results as a part of a broader [Kagi News Enrichment API](https://help.kagi.com/kagi/api/enrich.html). \n\n- There is an [OPML file](https://kagi.com/smallweb/opml) of the sites which make up the above RSS feed\n\n## Criteria for posts to show on the website\n\nIf the blog is included in small web feed list (which means it has content in English, it is informational/educational by nature and it is not trying to sell anything) we check for these two things to show it on the site:\n\n- Blog has recent posts (<7 days old)\n- The website can appear in an iframe\n  \n## ‚ö†Ô∏è Guidelines for adding a site or channel to the list ‚ö†Ô∏è\n\nAdd a new personal blog RSS feed to the list. Rules:\n\n- **Do not submit your own website unless you submit 2 other sites that are not yours (and are not in list).**\n- Locate and submit the RSS feed of the website. Place in the file so that it remains sorted.\n- Content must be in English (currently, other languages are not accepted).\n- No illegal or NSFW content.\n- No auto generated, LLM generated or spam content.\n- Only personal blogs may be submitted. \n- The blog must have a recent post, no older than 12 months, to meet the recency criteria for inclusion.\n- The site must not contain any forms of advertisements or undisclosed affiliate links\n- Site should not have newsletter signup popups (substack sites are not accepted too)\n- A YT channel must not post more than twice a week.\n- A YT channel must have fewer than 400,000 subscribers.\n\nFor comics:\n- Must be independently created art (no AI generated content)\n- RSS feed must show the full comic in the feed\n- No commercial syndicated comics\n\n[Add website RSS\nfeed](https://github.com/kagisearch/smallweb/edit/main/smallweb.txt)\n\nHint: To extract the RSS link from a YouTube channel, you can use [this tool](https://youtube-rss-nu.vercel.app/).\n\n[Add YouTube channel RSS\nfeed](https://github.com/kagisearch/smallweb/edit/main/smallyt.txt)\n\n[Add Comic RSS\nfeed](https://github.com/kagisearch/smallweb/edit/main/smallcomic.txt)\n\n## Remove a site or a channel\n\nRemove a website if :\n\n- It does not adhere to the above guidelines\n- In the removal request, state which guideline does it break\n\nClicking \"Remove website\" will edit small web list in new tab, where you can locate and remove the website feed in question. Make sure to add in comments the reason for removal.\n\n[Remove website](https://github.com/kagisearch/smallweb/edit/main/smallweb.txt)\n\n[Remove channel](https://github.com/kagisearch/smallweb/edit/main/smallt.txt)\n\n## The Small Web seal: badge of authentic creation\nSmall Web initiative members can display badges on their websites to identify themselves as part of a community committed to authentic, human-centered content.\n\n![Small Web Seal](https://kagifeedback.org/assets/files/2025-11-27/1764250797-487602-80x15-1.png)\n\n![Small Web Seal](https://kagifeedback.org/assets/files/2025-11-27/1764250950-635837-80x15-2.png)\n\n![Small Web Seal](https://kagifeedback.org/assets/files/2025-11-27/1764250973-708369-88x31-2.gif)\n\n![Small Web Seal](https://kagifeedback.org/assets/files/2025-11-27/1764250993-634450-88x31-2.png)\n\n![Small Web Seal](https://kagifeedback.org/assets/files/2025-11-27/1764251011-383809-88x31-3.jpg)\n\n![Small Web Seal](https://kagifeedback.org/assets/files/2025-11-27/1764251027-352511-88x31-4.gif)\n\n![Small Web Seal](https://kagifeedback.org/assets/files/2025-11-27/1764251045-794944-88x31-4.png)\n\n## Small web is beautiful\n\nWhat is Small Web exactly? Recommend reading:\n\n- https://neustadt.fr/essays/the-small-web/\n- https://benhoyt.com/writings/the-small-web-is-beautiful/\n- https://smallweb.page/why\n- https://ar.al/2020/08/07/what-is-the-small-web/\n- https://news.ycombinator.com/item?id=29768197\n\n\n\n## Info\n\n[smallweb.txt](https://github.com/kagisearch/smallweb/blob/main/smallweb.txt) - Contains the feeds of indexed blogs\n\n[smallyt.txt](https://github.com/kagisearch/smallweb/blob/main/smallyt.txt) - Contains the feeds of indexed YouTube channels\n\n[smallcomic.txt](https://github.com/kagisearch/smallweb/blob/main/smallcomic.txt) - Contains the feeds of indexed independent comics\n\n[yt_rejected.txt](https://github.com/kagisearch/smallweb/blob/main/yt_rejected.txt) - Contains the list of YouTube channels that were reviewed (in an automated way) and rejected \n\napp/ - App powering the Kagi Small Web website\n\n\n\n## Sources\n### Small web \n\nThe original list of small web blogs has been assembled from various\nsources including:\n\n- https://github.com/outcoldman/hackernews-personal-blogs\n- https://news.ycombinator.com/item?id=22273224\n- https://news.ycombinator.com/item?id=15154903\n- https://news.ycombinator.com/item?id=30245247\n- https://news.ycombinator.com/item?id=29758396\n- https://news.ycombinator.com/item?id=27302195\n- https://github.com/rushter/data-science-blogs\n- https://github.com/kilimchoi/engineering-blogs#-individuals\n- https://github.com/ysfelouardi/awesome-personal-blogs?search=1\n- https://ooh.directory/blogs/personal/\n- https://indieblog.page/all\n- https://biglist.terraaeon.com\n- https://tech-blogs.dev\n- https://hn-blogs.kronis.dev/all-blogs.html\n- https://dm.hn\n- https://uses.tech\n- https://nownownow.com\n- https://personalsit.es\n\n\n\n\n### YouTube channels\n\nThe seed list for YouTube channels has been assembled from these HN discussions.\n\n- https://news.ycombinator.com/item?id=32220192\n- https://news.ycombinator.com/item?id=25647657\n- https://news.ycombinator.com/item?id=32378309\n- https://news.ycombinator.com/item?id=20385679\n- https://news.ycombinator.com/item?id=24374979\n- https://news.ycombinator.com/item?id=24589474\n- https://news.ycombinator.com/item?id=24671019\n- https://news.ycombinator.com/item?id=35120777\n- https://news.ycombinator.com/item?id=12702651\n- https://news.ycombinator.com/item?id=17202615\n- https://news.ycombinator.com/item?id=29666539\n\n\n\n### Useful commands\n\nShow duplicate domains:\n```\nawk -F/ '{print $3}' smallweb.txt | sort | uniq -d | while read domain; do echo \"$domain\"; grep \"$domain\" smallweb.txt; echo \"\"; done\n```\n",
      "stars_today": 8
    },
    {
      "id": 14812739,
      "name": "libuv",
      "full_name": "libuv/libuv",
      "description": "Cross-platform asynchronous I/O",
      "html_url": "https://github.com/libuv/libuv",
      "stars": 26502,
      "forks": 3826,
      "language": "C",
      "topics": [
        "asynchronous",
        "deep-io",
        "io",
        "networking",
        "unicorns",
        "unix",
        "velociraptors",
        "windows"
      ],
      "created_at": "2013-11-30T00:29:56Z",
      "updated_at": "2026-01-23T18:10:36Z",
      "pushed_at": "2026-01-23T10:07:16Z",
      "open_issues": 209,
      "owner": {
        "login": "libuv",
        "avatar_url": "https://avatars.githubusercontent.com/u/4030929?v=4"
      },
      "readme": "![libuv][libuv_banner]\n\n## Overview\n\nlibuv is a multi-platform support library with a focus on asynchronous I/O. It\nwas primarily developed for use by [Node.js][], but it's also\nused by [Luvit](http://luvit.io/), [Julia](http://julialang.org/),\n[uvloop](https://github.com/MagicStack/uvloop), and [others](https://github.com/libuv/libuv/blob/v1.x/LINKS.md).\n\n## Feature highlights\n\n * Full-featured event loop backed by epoll, kqueue, IOCP, event ports.\n\n * Asynchronous TCP and UDP sockets\n\n * Asynchronous DNS resolution\n\n * Asynchronous file and file system operations\n\n * File system events\n\n * ANSI escape code controlled TTY\n\n * IPC with socket sharing, using Unix domain sockets or named pipes (Windows)\n\n * Child processes\n\n * Thread pool\n\n * Signal handling\n\n * High resolution clock\n\n * Threading and synchronization primitives\n\n## Versioning\n\nStarting with version 1.0.0 libuv follows the [semantic versioning](http://semver.org/)\nscheme. The API change and backwards compatibility rules are those indicated by\nSemVer. libuv will keep a stable ABI across major releases.\n\nThe ABI/API changes can be tracked [here](http://abi-laboratory.pro/tracker/timeline/libuv/).\n\n## Licensing\n\nlibuv is licensed under the MIT license. Check the [LICENSE](LICENSE) and\n[LICENSE-extra](LICENSE-extra) files.\n\nThe documentation is licensed under the CC BY 4.0 license. Check the\n[LICENSE-docs file](LICENSE-docs).\n\n## Community\n\n * [Support](https://github.com/libuv/libuv/discussions)\n * [Mailing list](http://groups.google.com/group/libuv)\n\n## Documentation\n\n### Official documentation\n\nLocated in the docs/ subdirectory. It uses the [Sphinx](http://sphinx-doc.org/)\nframework, which makes it possible to build the documentation in multiple\nformats.\n\nShow different supported building options:\n\n```bash\n$ make help\n```\n\nBuild documentation as HTML:\n\n```bash\n$ make html\n```\n\nBuild documentation as HTML and live reload it when it changes (this requires\nsphinx-autobuild to be installed and is only supported on Unix):\n\n```bash\n$ make livehtml\n```\n\nBuild documentation as man pages:\n\n```bash\n$ make man\n```\n\nBuild documentation as ePub:\n\n```bash\n$ make epub\n```\n\nNOTE: Windows users need to use make.bat instead of plain 'make'.\n\nDocumentation can be browsed online [here](http://docs.libuv.org).\n\nThe [tests and benchmarks](https://github.com/libuv/libuv/tree/master/test)\nalso serve as API specification and usage examples.\n\n### Other resources\n\n * [LXJS 2012 talk](http://www.youtube.com/watch?v=nGn60vDSxQ4)\n   &mdash; High-level introductory talk about libuv.\n * [libuv-dox](https://github.com/thlorenz/libuv-dox)\n   &mdash; Documenting types and methods of libuv, mostly by reading uv.h.\n * [learnuv](https://github.com/thlorenz/learnuv)\n   &mdash; Learn uv for fun and profit, a self guided workshop to libuv.\n\nThese resources are not handled by libuv maintainers and might be out of\ndate. Please verify it before opening new issues.\n\n## Downloading\n\nlibuv can be downloaded either from the\n[GitHub repository](https://github.com/libuv/libuv)\nor from the [downloads site](http://dist.libuv.org/dist/).\n\nBefore verifying the git tags or signature files, importing the relevant keys\nis necessary. Key IDs are listed in the\n[MAINTAINERS](https://github.com/libuv/libuv/blob/master/MAINTAINERS.md)\nfile, but are also available as git blob objects for easier use.\n\nImporting a key the usual way:\n\n```bash\n$ gpg --keyserver pool.sks-keyservers.net --recv-keys AE9BC059\n```\n\nImporting a key from a git blob object:\n\n```bash\n$ git show pubkey-saghul | gpg --import\n```\n\n### Verifying releases\n\nGit tags are signed with the developer's key, they can be verified as follows:\n\n```bash\n$ git verify-tag v1.6.1\n```\n\nStarting with libuv 1.7.0, the tarballs stored in the\n[downloads site](http://dist.libuv.org/dist/) are signed and an accompanying\nsignature file sit alongside each. Once both the release tarball and the\nsignature file are downloaded, the file can be verified as follows:\n\n```bash\n$ gpg --verify libuv-1.7.0.tar.gz.sign\n```\n\n## Build Instructions\n\nFor UNIX-like platforms, including macOS, there are two build methods:\nautotools or [CMake][].\n\nFor Windows, [CMake][] is the only supported build method and has the\nfollowing prerequisites:\n\n<details>\n\n* One of:\n  * [Visual C++ Build Tools][]\n  * [Visual Studio 2015 Update 3][], all editions\n    including the Community edition (remember to select\n    \"Common Tools for Visual C++ 2015\" feature during installation).\n  * [Visual Studio 2017][], any edition (including the Build Tools SKU).\n    **Required Components:** \"MSbuild\", \"VC++ 2017 v141 toolset\" and one of the\n    Windows SDKs (10 or 8.1).\n* Basic Unix tools required for some tests,\n  [Git for Windows][] includes Git Bash\n  and tools which can be included in the global `PATH`.\n\n</details>\n\nTo build with autotools:\n\n```bash\n$ sh autogen.sh\n$ ./configure\n$ make\n$ make check\n$ make install\n```\n\nTo build with [CMake][]:\n\n```bash\n$ cmake -B build -DBUILD_TESTING=ON         # generate project with tests\n$ cmake --build build                       # add `-j <n>` with cmake >= 3.12\n\n# Run tests:\n$ (cd build && ctest -C Debug --output-on-failure)\n\n# Or manually run tests:\n$ build/uv_run_tests                        # shared library build\n$ build/uv_run_tests_a                      # static library build\n```\n\nTo cross-compile with [CMake][] (unsupported but generally works):\n\n```bash\n$ cmake ../..                 \\\n  -DCMAKE_SYSTEM_NAME=Windows \\\n  -DCMAKE_SYSTEM_VERSION=6.1  \\\n  -DCMAKE_C_COMPILER=i686-w64-mingw32-gcc\n```\n\n### Install with Homebrew\n\n```bash\n$ brew install --HEAD libuv\n```\n\nNote to macOS users:\n\nMake sure that you specify the architecture you wish to build for in the\n\"ARCHS\" flag. You can specify more than one by delimiting with a space\n(e.g. \"x86_64 i386\").\n\n### Install with vcpkg\n\n```bash\n$ git clone https://github.com/microsoft/vcpkg.git\n$ ./bootstrap-vcpkg.bat # for powershell\n$ ./bootstrap-vcpkg.sh # for bash\n$ ./vcpkg install libuv\n```\n\n### Install with Conan\n\nYou can install pre-built binaries for libuv or build it from source using [Conan](https://conan.io/). Use the following command:\n\n```bash\nconan install --requires=\"libuv/[*]\" --build=missing\n```\n\nThe libuv Conan recipe is kept up to date by Conan maintainers and community contributors.\nIf the version is out of date, please [create an issue or pull request](https://github.com/conan-io/conan-center-index) on the ConanCenterIndex repository.\n\n\n### Running tests\n\nSome tests are timing sensitive. Relaxing test timeouts may be necessary\non slow or overloaded machines:\n\n```bash\n$ env UV_TEST_TIMEOUT_MULTIPLIER=2 build/uv_run_tests # 10s instead of 5s\n```\n\n#### Run one test\n\nThe list of all tests is in `test/test-list.h`.\n\nThis invocation will cause the test driver to fork and execute `TEST_NAME` in\na child process:\n\n```bash\n$ build/uv_run_tests_a TEST_NAME\n```\n\nThis invocation will cause the test driver to execute the test in\nthe same process:\n\n```bash\n$ build/uv_run_tests_a TEST_NAME TEST_NAME\n```\n\n#### Debugging tools\n\nWhen running the test from within the test driver process\n(`build/uv_run_tests_a TEST_NAME TEST_NAME`), tools like gdb and valgrind\nwork normally.\n\nWhen running the test from a child of the test driver process\n(`build/uv_run_tests_a TEST_NAME`), use these tools in a fork-aware manner.\n\n##### Fork-aware gdb\n\nUse the [follow-fork-mode](https://sourceware.org/gdb/onlinedocs/gdb/Forks.html) setting:\n\n```\n$ gdb --args build/uv_run_tests_a TEST_NAME\n\n(gdb) set follow-fork-mode child\n...\n```\n\n##### Fork-aware valgrind\n\nUse the `--trace-children=yes` parameter:\n\n```bash\n$ valgrind --trace-children=yes -v --tool=memcheck --leak-check=full --track-origins=yes --leak-resolution=high --show-reachable=yes --log-file=memcheck-%p.log build/uv_run_tests_a TEST_NAME\n```\n\n### Running benchmarks\n\nSee the section on running tests.\nThe benchmark driver is `./uv_run_benchmarks_a` and the benchmarks are\nlisted in `test/benchmark-list.h`.\n\n## Supported Platforms\n\nCheck the [SUPPORTED_PLATFORMS file](SUPPORTED_PLATFORMS.md).\n\n### `-fno-strict-aliasing`\n\nIt is recommended to turn on the `-fno-strict-aliasing` compiler flag in\nprojects that use libuv. The use of ad hoc \"inheritance\" in the libuv API\nmay not be safe in the presence of compiler optimizations that depend on\nstrict aliasing.\n\nMSVC does not have an equivalent flag but it also does not appear to need it\nat the time of writing (December 2019.)\n\n### AIX Notes\n\nAIX compilation using IBM XL C/C++ requires version 12.1 or greater.\n\nAIX support for filesystem events requires the non-default IBM `bos.ahafs`\npackage to be installed.  This package provides the AIX Event Infrastructure\nthat is detected by `autoconf`.\n[IBM documentation](http://www.ibm.com/developerworks/aix/library/au-aix_event_infrastructure/)\ndescribes the package in more detail.\n\n### z/OS Notes\n\nz/OS compilation requires [ZOSLIB](https://github.com/ibmruntimes/zoslib) to be installed. When building with [CMake][], use the flag `-DZOSLIB_DIR` to specify the path to [ZOSLIB](https://github.com/ibmruntimes/zoslib):\n\n```bash\n$ (cd build && cmake .. -DBUILD_TESTING=ON -DZOSLIB_DIR=/path/to/zoslib)\n$ cmake --build build\n```\n\nz/OS creates System V semaphores and message queues. These persist on the system\nafter the process terminates unless the event loop is closed.\n\nUse the `ipcrm` command to manually clear up System V resources.\n\n## Patches\n\nSee the [guidelines for contributing][].\n\n[CMake]: https://cmake.org/\n[node.js]: http://nodejs.org/\n[guidelines for contributing]: https://github.com/libuv/libuv/blob/master/CONTRIBUTING.md\n[libuv_banner]: https://raw.githubusercontent.com/libuv/libuv/master/img/banner.png\n[Visual C++ Build Tools]: https://visualstudio.microsoft.com/visual-cpp-build-tools/\n[Visual Studio 2015 Update 3]: https://www.visualstudio.com/vs/older-downloads/\n[Visual Studio 2017]: https://www.visualstudio.com/downloads/\n[Git for Windows]: http://git-scm.com/download/win\n",
      "stars_today": 7
    },
    {
      "id": 86897963,
      "name": "ZLMediaKit",
      "full_name": "ZLMediaKit/ZLMediaKit",
      "description": "WebRTC/RTSP/RTMP/HTTP/HLS/HTTP-FLV/WebSocket-FLV/HTTP-TS/HTTP-fMP4/WebSocket-TS/WebSocket-fMP4/GB28181/SRT/STUN/TURN server and client framework based on C++11",
      "html_url": "https://github.com/ZLMediaKit/ZLMediaKit",
      "stars": 16554,
      "forks": 3936,
      "language": "C++",
      "topics": [
        "flv",
        "gb28181",
        "hls",
        "http",
        "http-flv",
        "http-fmp4",
        "http-ts",
        "live",
        "media-server",
        "mp4",
        "rtmp",
        "rtp",
        "rtsp",
        "srt",
        "stun",
        "ts",
        "turn",
        "webrtc",
        "websocket",
        "websocket-flv"
      ],
      "created_at": "2017-04-01T08:30:25Z",
      "updated_at": "2026-01-24T01:31:32Z",
      "pushed_at": "2026-01-22T08:31:05Z",
      "open_issues": 110,
      "owner": {
        "login": "ZLMediaKit",
        "avatar_url": "https://avatars.githubusercontent.com/u/84565724?v=4"
      },
      "readme": "![logo](https://raw.githubusercontent.com/ZLMediaKit/ZLMediaKit/master/www/logo.png)\n\nÁÆÄ‰Ωì‰∏≠Êñá | [English](./README_en.md)\n\n# ‰∏Ä‰∏™Âü∫‰∫éC++11ÁöÑÈ´òÊÄßËÉΩËøêËê•Á∫ßÊµÅÂ™í‰ΩìÊúçÂä°Ê°ÜÊû∂\n\n[![](https://img.shields.io/badge/license-MIT-green.svg)](https://github.com/ZLMediaKit/ZLMediaKit/blob/master/LICENSE)\n[![](https://img.shields.io/badge/language-c++-red.svg)](https://en.cppreference.com/)\n[![](https://img.shields.io/badge/platform-linux%20|%20macos%20|%20windows-blue.svg)](https://github.com/ZLMediaKit/ZLMediaKit)\n[![](https://img.shields.io/badge/PRs-welcome-yellow.svg)](https://github.com/ZLMediaKit/ZLMediaKit/pulls)\n\n[![](https://github.com/ZLMediaKit/ZLMediaKit/actions/workflows/android.yml/badge.svg)](https://github.com/ZLMediaKit/ZLMediaKit)\n[![](https://github.com/ZLMediaKit/ZLMediaKit/actions/workflows/linux.yml/badge.svg)](https://github.com/ZLMediaKit/ZLMediaKit)\n[![](https://github.com/ZLMediaKit/ZLMediaKit/actions/workflows/macos.yml/badge.svg)](https://github.com/ZLMediaKit/ZLMediaKit)\n[![](https://github.com/ZLMediaKit/ZLMediaKit/actions/workflows/windows.yml/badge.svg)](https://github.com/ZLMediaKit/ZLMediaKit)\n\n[![](https://github.com/ZLMediaKit/ZLMediaKit/actions/workflows/docker.yml/badge.svg)](https://hub.docker.com/r/zlmediakit/zlmediakit/tags)\n[![](https://img.shields.io/docker/pulls/zlmediakit/zlmediakit)](https://hub.docker.com/r/zlmediakit/zlmediakit/tags)\n\n## È°πÁõÆÁâπÁÇπ\n\n- Âü∫‰∫éC++11ÂºÄÂèëÔºåÈÅøÂÖç‰ΩøÁî®Ë£∏ÊåáÈíàÔºå‰ª£Á†ÅÁ®≥ÂÆöÂèØÈù†ÔºåÊÄßËÉΩ‰ºòË∂ä„ÄÇ\n- ÊîØÊåÅÂ§öÁßçÂçèËÆÆ(RTSP/RTMP/HLS/HTTP-FLV/WebSocket-FLV/GB28181/HTTP-TS/WebSocket-TS/HTTP-fMP4/WebSocket-fMP4/MP4/WebRTC),ÊîØÊåÅÂçèËÆÆ‰∫íËΩ¨„ÄÇ\n- ‰ΩøÁî®Â§öË∑ØÂ§çÁî®/Â§öÁ∫øÁ®ã/ÂºÇÊ≠•ÁΩëÁªúIOÊ®°ÂºèÂºÄÂèëÔºåÂπ∂ÂèëÊÄßËÉΩ‰ºòË∂äÔºåÊîØÊåÅÊµ∑ÈáèÂÆ¢Êà∑Á´ØËøûÊé•„ÄÇ\n- ‰ª£Á†ÅÁªèËøáÈïøÊúüÂ§ßÈáèÁöÑÁ®≥ÂÆöÊÄß„ÄÅÊÄßËÉΩÊµãËØïÔºåÂ∑≤ÁªèÂú®Á∫ø‰∏äÂïÜÁî®È™åËØÅÂ∑≤‰πÖ„ÄÇ\n- ÊîØÊåÅlinux„ÄÅmacos„ÄÅios„ÄÅandroid„ÄÅwindowsÂÖ®Âπ≥Âè∞„ÄÇ\n- ÊîØÊåÅx86„ÄÅarm„ÄÅrisc-v„ÄÅmips„ÄÅÈæôËäØ„ÄÅÁî≥Â®ÅÁ≠âÊåá‰ª§ÈõÜÂπ≥Âè∞„ÄÇ\n- ÊîØÊåÅÁîªÈù¢ÁßíÂºÄ„ÄÅÊûÅ‰ΩéÂª∂Êó∂([500ÊØ´ÁßíÂÜÖÔºåÊúÄ‰ΩéÂèØËææ100ÊØ´Áßí](https://github.com/ZLMediaKit/ZLMediaKit/wiki/%E5%BB%B6%E6%97%B6%E6%B5%8B%E8%AF%95))„ÄÇ\n- Êèê‰æõÂÆåÂñÑÁöÑÊ†áÂáÜ[C API](https://github.com/ZLMediaKit/ZLMediaKit/tree/master/api/include),ÂèØ‰ª•‰ΩúSDKÁî®ÔºåÊàñ‰æõÂÖ∂‰ªñËØ≠Ë®ÄË∞ÉÁî®„ÄÇ\n- Êèê‰æõÂÆåÊï¥ÁöÑ[MediaServer](https://github.com/ZLMediaKit/ZLMediaKit/tree/master/server)ÊúçÂä°Âô®ÔºåÂèØ‰ª•ÂÖçÂºÄÂèëÁõ¥Êé•ÈÉ®ÁΩ≤‰∏∫ÂïÜÁî®ÊúçÂä°Âô®„ÄÇ\n- Êèê‰æõÂÆåÂñÑÁöÑ[restful api](https://github.com/ZLMediaKit/ZLMediaKit/wiki/MediaServer%E6%94%AF%E6%8C%81%E7%9A%84HTTP-API)‰ª•Âèä[web hook](https://github.com/ZLMediaKit/ZLMediaKit/wiki/MediaServer%E6%94%AF%E6%8C%81%E7%9A%84HTTP-HOOK-API)ÔºåÊîØÊåÅ‰∏∞ÂØåÁöÑ‰∏öÂä°ÈÄªËæë„ÄÇ\n- ÊâìÈÄö‰∫ÜËßÜÈ¢ëÁõëÊéßÂçèËÆÆÊ†à‰∏éÁõ¥Êí≠ÂçèËÆÆÊ†àÔºåÂØπRTSP/RTMPÊîØÊåÅÈÉΩÂæàÂÆåÂñÑ„ÄÇ\n- ÂäüËÉΩÂÆåÂñÑÔºåÊîØÊåÅÈõÜÁæ§„ÄÅÊåâÈúÄËΩ¨ÂçèËÆÆ„ÄÅÊåâÈúÄÊé®ÊãâÊµÅ„ÄÅÂÖàÊí≠ÂêéÊé®„ÄÅÊñ≠ËøûÁª≠Êé®Á≠âÂäüËÉΩ„ÄÇ\n- ÊûÅËá¥ÊÄßËÉΩÔºåÂçïÊú∫10WÁ∫ßÂà´Êí≠ÊîæÂô®Ôºå100Gb/sÁ∫ßÂà´ioÂ∏¶ÂÆΩËÉΩÂäõ„ÄÇ\n- ÊûÅËá¥‰ΩìÈ™åÔºå[Áã¨ÂÆ∂ÁâπÊÄß](https://github.com/ZLMediaKit/ZLMediaKit/wiki/ZLMediakit%E7%8B%AC%E5%AE%B6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D)\n- [Ë∞ÅÂú®‰ΩøÁî®zlmediakit?](https://github.com/ZLMediaKit/ZLMediaKit/issues/511)\n- ÂÖ®Èù¢ÊîØÊåÅipv6ÁΩëÁªú\n- ÊîØÊåÅÂ§öËΩ®ÈÅìÊ®°Âºè(‰∏Ä‰∏™ÊµÅ‰∏≠Â§ö‰∏™ËßÜÈ¢ë/Èü≥È¢ë)\n- ÂÖ®ÂçèËÆÆÊîØÊåÅH264/H265/AAC/G711/OPUS/MP3/VP8/VP9/AV1ÔºåÈÉ®ÂàÜÊîØÊåÅJPEG/H266/ADPCM/SVAC/G722/G723/G729\n\n## È°πÁõÆÂÆö‰Ωç\n\n- ÁßªÂä®ÂµåÂÖ•ÂºèË∑®Âπ≥Âè∞ÊµÅÂ™í‰ΩìËß£ÂÜ≥ÊñπÊ°à„ÄÇ\n- ÂïÜÁî®Á∫ßÊµÅÂ™í‰ΩìÊúçÂä°Âô®„ÄÇ\n- ÁΩëÁªúÁºñÁ®ã‰∫åÊ¨°ÂºÄÂèëSDK„ÄÇ\n\n\n## ÂäüËÉΩÊ∏ÖÂçï\n### ÂäüËÉΩ‰∏ÄËßà\n<img width=\"749\" alt=\"ÂäüËÉΩÈ¢ÑËßà\" src=\"https://github.com/user-attachments/assets/7072fe1c-e2b3-47e9-bd50-e5266523edf1\">\n\n- RTSP[S]\n  - RTSP[S] ÊúçÂä°Âô®ÔºåÊîØÊåÅRTMP/MP4/HLSËΩ¨RTSP[S],ÊîØÊåÅ‰∫öÈ©¨ÈÄäecho showËøôÊ†∑ÁöÑËÆæÂ§á\n  - RTSP[S] Êí≠ÊîæÂô®ÔºåÊîØÊåÅRTSP‰ª£ÁêÜÔºåÊîØÊåÅÁîüÊàêÈùôÈü≥Èü≥È¢ë\n  - RTSP[S] Êé®ÊµÅÂÆ¢Êà∑Á´Ø‰∏éÊúçÂä°Âô®\n  - ÊîØÊåÅ `rtp over udp` `rtp over tcp` `rtp over http` `rtpÁªÑÊí≠`  ÂõõÁßçRTP‰º†ËæìÊñπÂºè \n  - ÊúçÂä°Âô®/ÂÆ¢Êà∑Á´ØÂÆåÊï¥ÊîØÊåÅBasic/DigestÊñπÂºèÁöÑÁôªÂΩïÈâ¥ÊùÉÔºåÂÖ®ÂºÇÊ≠•ÂèØÈÖçÁΩÆÂåñÁöÑÈâ¥ÊùÉÊé•Âè£\n  - ÊîØÊåÅH265ÁºñÁ†Å\n  - ÊúçÂä°Âô®ÊîØÊåÅRTSPÊé®ÊµÅ(ÂåÖÊã¨`rtp over udp` `rtp over tcp`ÊñπÂºè)\n  - ÊîØÊåÅH264/H265/AAC/G711/OPUS/MJPEG/MP3/VP8/VP9/AV1ÁºñÁ†ÅÔºåÂÖ∂‰ªñÁºñÁ†ÅËÉΩËΩ¨Âèë‰ΩÜ‰∏çËÉΩËΩ¨ÂçèËÆÆ\n\n- RTMP[S]\n  - RTMP[S] Êí≠ÊîæÊúçÂä°Âô®ÔºåÊîØÊåÅRTSP/MP4/HLSËΩ¨RTMP\n  - RTMP[S] ÂèëÂ∏ÉÊúçÂä°Âô®ÔºåÊîØÊåÅÂΩïÂà∂ÂèëÂ∏ÉÊµÅ\n  - RTMP[S] Êí≠ÊîæÂô®ÔºåÊîØÊåÅRTMP‰ª£ÁêÜÔºåÊîØÊåÅÁîüÊàêÈùôÈü≥Èü≥È¢ë\n  - RTMP[S] Êé®ÊµÅÂÆ¢Êà∑Á´Ø\n  - ÊîØÊåÅhttp[s]-flvÁõ¥Êí≠ÊúçÂä°Âô®\n  - ÊîØÊåÅhttp[s]-flvÁõ¥Êí≠Êí≠ÊîæÂô®\n  - ÊîØÊåÅwebsocket-flvÁõ¥Êí≠\n  - ÊîØÊåÅH264/H265/AAC/G711/OPUS/MP3ÁºñÁ†ÅÔºåÂÖ∂‰ªñÁºñÁ†ÅËÉΩËΩ¨Âèë‰ΩÜ‰∏çËÉΩËΩ¨ÂçèËÆÆ\n  - ÊîØÊåÅ[RTMP-H265](https://github.com/ksvc/FFmpeg/wiki)\n  - ÊîØÊåÅ[RTMP-OPUS](https://github.com/ZLMediaKit/ZLMediaKit/wiki/RTMP%E5%AF%B9H265%E5%92%8COPUS%E7%9A%84%E6%94%AF%E6%8C%81)\n  - ÊîØÊåÅ[enhanced-rtmp(H265/VP8/VP9/AV1/OPUS)](https://github.com/veovera/enhanced-rtmp)\n\n- HLS\n  - ÊîØÊåÅHLSÊñá‰ª∂(mpegts/fmp4)ÁîüÊàêÔºåËá™Â∏¶HTTPÊñá‰ª∂ÊúçÂä°Âô®\n  - ÈÄöËøácookieËøΩË∏™ÊäÄÊúØÔºåÂèØ‰ª•Ê®°ÊãüHLSÊí≠Êîæ‰∏∫ÈïøËøûÊé•ÔºåÂèØ‰ª•ÂÆûÁé∞HLSÊåâÈúÄÊãâÊµÅ„ÄÅÊí≠ÊîæÁªüËÆ°Á≠â‰∏öÂä°\n  - ÊîØÊåÅHLSÊí≠ÂèëÂô®ÔºåÊîØÊåÅÊãâÊµÅHLSËΩ¨rtsp/rtmp/mp4\n  - ÊîØÊåÅH264/H265/AAC/G711/OPUS/MP3/VP8/VP9/AV1ÁºñÁ†Å\n  - ÊîØÊåÅÂ§öËΩ®ÈÅìÊ®°Âºè\n  \n- TS\n  - ÊîØÊåÅhttp[s]-tsÁõ¥Êí≠\n  - ÊîØÊåÅws[s]-tsÁõ¥Êí≠\n  - ÊîØÊåÅH264/H265/AAC/G711/OPUS/MP3/VP8/VP9/AV1ÁºñÁ†Å\n  - ÊîØÊåÅÂ§öËΩ®ÈÅìÊ®°Âºè\n  \n- fMP4\n  - ÊîØÊåÅhttp[s]-fmp4Áõ¥Êí≠\n  - ÊîØÊåÅws[s]-fmp4Áõ¥Êí≠\n  - ÊîØÊåÅH264/H265/AAC/G711/OPUS/MJPEG/MP3/VP8/VP9/AV1ÁºñÁ†Å\n  - ÊîØÊåÅÂ§öËΩ®ÈÅìÊ®°Âºè\n\n- HTTP[S]‰∏éWebSocket\n  - ÊúçÂä°Âô®ÊîØÊåÅ`ÁõÆÂΩïÁ¥¢ÂºïÁîüÊàê`,`Êñá‰ª∂‰∏ãËΩΩ`,`Ë°®ÂçïÊèê‰∫§ËØ∑Ê±Ç`\n  - ÂÆ¢Êà∑Á´ØÊèê‰æõ`Êñá‰ª∂‰∏ãËΩΩÂô®(ÊîØÊåÅÊñ≠ÁÇπÁª≠‰º†)`,`Êé•Âè£ËØ∑Ê±ÇÂô®`,`Êñá‰ª∂‰∏ä‰º†Âô®`\n  - ÂÆåÊï¥HTTP APIÊúçÂä°Âô®ÔºåÂèØ‰ª•‰Ωú‰∏∫webÂêéÂè∞ÂºÄÂèëÊ°ÜÊû∂\n  - ÊîØÊåÅË∑®ÂüüËÆøÈóÆ\n  - ÊîØÊåÅhttpÂÆ¢Êà∑Á´Ø„ÄÅÊúçÂä°Âô®cookie\n  - ÊîØÊåÅWebSocketÊúçÂä°Âô®ÂíåÂÆ¢Êà∑Á´Ø\n  - ÊîØÊåÅhttpÊñá‰ª∂ËÆøÈóÆÈâ¥ÊùÉ\n\n- GB28181‰∏éRTPÊé®ÊµÅ\n  - ÊîØÊåÅUDP/TCP RTP(PS/TS/ES)Êé®ÊµÅÊúçÂä°Âô®ÔºåÂèØ‰ª•ËΩ¨Êç¢ÊàêRTSP/RTMP/HLSÁ≠âÂçèËÆÆ\n  - ÊîØÊåÅRTSP/RTMP/HLSÁ≠âÂçèËÆÆËΩ¨rtpÊé®ÊµÅÂÆ¢Êà∑Á´ØÔºåÊîØÊåÅTCP/UDPÊ®°ÂºèÔºåÊèê‰æõÁõ∏Â∫îrestful apiÔºåÊîØÊåÅ‰∏ªÂä®Ë¢´Âä®ÊñπÂºè\n  - ÊîØÊåÅH264/H265/AAC/G711/OPUS/MP3/VP8/VP9/AV1ÁºñÁ†Å\n  - ÊîØÊåÅes/ps/ts/ehome rtpÊé®ÊµÅ\n  - ÊîØÊåÅes/ps rtpËΩ¨Êé®\n  - ÊîØÊåÅGB28181‰∏ªÂä®ÊãâÊµÅÊ®°Âºè\n  - ÊîØÊåÅÂèåÂêëËØ≠Èü≥ÂØπËÆ≤\n  - ÊîØÊåÅÂ§öËΩ®ÈÅìÊ®°Âºè\n\n- MP4ÁÇπÊí≠‰∏éÂΩïÂà∂\n  - ÊîØÊåÅÂΩïÂà∂‰∏∫FLV/HLS/MP4\n  - RTSP/RTMP/HTTP-FLV/WS-FLVÊîØÊåÅMP4Êñá‰ª∂ÁÇπÊí≠ÔºåÊîØÊåÅseek\n  - ÊîØÊåÅH264/H265/AAC/G711/OPUS/MP3/VP8/VP9/AV1ÁºñÁ†Å\n  - ÊîØÊåÅÂ§öËΩ®ÈÅìÊ®°Âºè\n  \n- WebRTC\n  - ÊîØÊåÅWebRTCÊé®ÊµÅÔºåÊîØÊåÅËΩ¨ÂÖ∂‰ªñÂçèËÆÆ\n  - ÊîØÊåÅWebRTCÊí≠ÊîæÔºåÊîØÊåÅÂÖ∂‰ªñÂçèËÆÆËΩ¨WebRTC\n  - ÊîØÊåÅÂèåÂêëecho test     \n  - ÊîØÊåÅsimulcastÊé®ÊµÅ\n  - ÊîØÊåÅ‰∏ä‰∏ãË°årtx/nack‰∏¢ÂåÖÈáç‰º†\n  - **ÊîØÊåÅÂçïÁ´ØÂè£„ÄÅÂ§öÁ∫øÁ®ã„ÄÅÂÆ¢Êà∑Á´ØÁΩëÁªúËøûÊé•ËøÅÁßª(ÂºÄÊ∫êÁïåÂîØ‰∏Ä)**„ÄÇ\n  - ÊîØÊåÅTWCC rtcpÂä®ÊÄÅË∞ÉÊï¥Á†ÅÁéá\n  - ÊîØÊåÅremb/pli/sr/rr rtcp\n  - ÊîØÊåÅrtpÊâ©Â±ïËß£Êûê\n  - ÊîØÊåÅGOPÁºìÂÜ≤ÔºåwebrtcÊí≠ÊîæÁßíÂºÄ\n  - ÊîØÊåÅdatachannel\n  - ÊîØÊåÅwebrtc over tcpÊ®°Âºè\n  - ‰ºòÁßÄÁöÑnack„ÄÅjitter bufferÁÆóÊ≥ï, Êäó‰∏¢ÂåÖËÉΩÂäõÂçìË∂ä\n  - ÊîØÊåÅwhip/whepÂçèËÆÆ\n  - ÊîØÊåÅÁºñÁ†ÅÊ†ºÂºè‰∏értspÂçèËÆÆ‰∏ÄËá¥\n  - [ÊîØÊåÅice-full,ÊîØÊåÅ‰Ωú‰∏∫webrtcÂÆ¢Êà∑Á´ØÊãâÊµÅ„ÄÅÊé®ÊµÅ‰ª•Âèäp2pÊ®°Âºè](./webrtc/USAGE.md)\n  \n- [SRTÊîØÊåÅ](./srt/srt.md)\n- ÂÖ∂‰ªñ\n  - ÊîØÊåÅ‰∏∞ÂØåÁöÑrestful api‰ª•Âèäweb hook‰∫ã‰ª∂ \n  - ÊîØÊåÅÈÖçÁΩÆÊñá‰ª∂„ÄÅsslËØÅ‰π¶ÁÉ≠Âä†ËΩΩ\n  - ÊîØÊåÅÊµÅÈáèÁªüËÆ°„ÄÅÊé®ÊãâÊµÅÈâ¥ÊùÉÁ≠â‰∫ã‰ª∂\n  - ÊîØÊåÅËôöÊãü‰∏ªÊú∫,ÂèØ‰ª•ÈöîÁ¶ª‰∏çÂêåÂüüÂêç\n  - ÊîØÊåÅÊåâÈúÄÊãâÊµÅÔºåÊó†‰∫∫ËßÇÁúãËá™Âä®ÂÖ≥Êñ≠ÊãâÊµÅ\n  - ÊîØÊåÅÂÖàÊí≠ÊîæÂêéÊé®ÊµÅÔºåÊèêÈ´òÂèäÊó∂Êé®ÊµÅÁîªÈù¢ÊâìÂºÄÁéá\n  - Êèê‰æõÂÆåÊï¥Âº∫Â§ßÁöÑc api sdk\n  - ÊîØÊåÅFFmpegÊãâÊµÅ‰ª£ÁêÜ‰ªªÊÑèÊ†ºÂºèÁöÑÊµÅ\n  - ÊîØÊåÅhttp apiÁîüÊàêÂπ∂ËøîÂõûÂÆûÊó∂Êà™Âõæ\n  - ÊîØÊåÅÊåâÈúÄËß£Â§çÁî®„ÄÅËΩ¨ÂçèËÆÆÔºåÂΩìÊúâ‰∫∫ËßÇÁúãÊó∂ÊâçÂºÄÂêØËΩ¨ÂçèËÆÆÔºåÈôç‰ΩécpuÂç†Áî®Áéá\n  - ÊîØÊåÅÊ∫ØÊ∫êÊ®°ÂºèÁöÑÈõÜÁæ§ÈÉ®ÁΩ≤ÔºåÊ∫ØÊ∫êÊñπÂºèÊîØÊåÅrtsp/rtmp/hls/http-ts, ËæπÊ≤øÁ´ôÊîØÊåÅhls, Ê∫êÁ´ôÊîØÊåÅÂ§ö‰∏™(ÈááÁî®round robinÊñπÂºèÊ∫ØÊ∫ê)\n  - rtsp/rtmp/webrtcÊé®ÊµÅÂºÇÂ∏∏Êñ≠ÂºÄÂêéÔºåÂèØ‰ª•Âú®Ë∂ÖÊó∂Êó∂Èó¥ÂÜÖÈáçËøûÊé®ÊµÅÔºåÊí≠ÊîæÂô®Êó†ÊÑüÁü•\n \n## Èó≠Ê∫ê‰∏ì‰∏öÁâà\nÂú®ÊúÄÊñ∞ÂºÄÊ∫ê‰ª£Á†ÅÁöÑÂü∫Á°ÄÔºåÊñ∞Â¢û‰ª•‰∏ã[Èó≠Ê∫ê‰∏ì‰∏öÁâà](https://github.com/xia-chu/zlmediakit-pro)\n- Èü≥ËßÜÈ¢ëËΩ¨Á†ÅÂäüËÉΩ\n  - 1„ÄÅÈü≥ËßÜÈ¢ëÈó¥‰ªªÊÑèËΩ¨Á†Å(ÂåÖÊã¨h265/h264/opus/g711/aac/g722/g722.1/mp3/svac/vp8/vp9/av1Á≠â„ÄÇ\n  - 2„ÄÅÂü∫‰∫éÈÖçÁΩÆÊñá‰ª∂ÁöÑËΩ¨Á†ÅÔºåÊîØÊåÅËÆæÁΩÆÊØîÁâπÁéáÔºåcodecÁ±ªÂûãÁ≠âÂèÇÊï∞„ÄÇ\n  - 3„ÄÅÂü∫‰∫éhttp apiÁöÑÂä®ÊÄÅÂ¢ûÂáèËΩ¨Á†ÅÔºåÊîØÊåÅËÆæÁΩÆÊØîÁâπÁéáÔºåÂàÜËæ®ÁéáÂÄçÊï∞ÔºåcodecÁ±ªÂûã„ÄÅÊª§ÈïúÁ≠âÂèÇÊï∞„ÄÇ\n  - 4„ÄÅÊîØÊåÅÁ°¨‰ª∂„ÄÅËΩØ‰ª∂Ëá™ÈÄÇÂ∫îËΩ¨Á†Å„ÄÇ\n  - 5„ÄÅÊîØÊåÅÊåâÈúÄËΩ¨Á†ÅÔºåÊúâ‰∫∫ËßÇÁúãÊâçËΩ¨Á†ÅÔºåÊîØÊåÅÈÄèÊòéËΩ¨Á†ÅÊ®°ÂºèÔºå‰∏öÂä°Êó†ÈúÄÊÑüÁü•ËΩ¨Á†ÅÁöÑÂ≠òÂú®Ôºå‰∏öÂä°‰ª£Á†ÅÊó†ÈúÄÂÅö‰ªª‰ΩïË∞ÉÊï¥„ÄÇ\n  - 6„ÄÅÊîØÊåÅË¥üËΩΩËøáÈ´òÊó∂ÔºåËΩ¨Á†Å‰∏ªÂä®Èôç‰ΩéÂ∏ßÁéá‰∏î‰∏çËä±Â±è„ÄÇ\n  - 7„ÄÅÊîØÊåÅÊª§ÈïúÔºåÊîØÊåÅÊ∑ªÂä†osdÊñáÊú¨‰ª•ÂèälogoËßíÊ†áÁ≠âËÉΩÂäõ„ÄÇ\n  - 8„ÄÅÊîØÊåÅÂÖ®GPUÁ°¨‰ª∂ÁºñËß£Á†Å‰∏éÊª§ÈïúÔºåÈò≤Ê≠¢ÊòæÂ≠ò‰∏éÂÜÖÂ≠òÈ¢ëÁπÅÊã∑Ë¥ù„ÄÇ\n    \n- JT1078ÈÉ®Ê†áÁâàÊú¨\n  - 1„ÄÅÊîØÊåÅÊé•Êî∂jt1078Êé®ÊµÅËΩ¨ÂÖ∂‰ªñÂçèËÆÆÔºõËá™ÈÄÇÂ∫îÈü≥ËßÜÈ¢ëÂÖ±‰∫´seqÂíåÂçïÁã¨seqÊ®°Âºè„ÄÇ\n  - 2„ÄÅÊîØÊåÅjt1078Á∫ßËÅîÔºåÊîØÊåÅjt1078ÂØπËÆ≤„ÄÇ\n  - 3„ÄÅjt1078Áõ∏ÂÖ≥Êé•Âè£„ÄÅÁ´ØÂè£ÂíåÁî®Ê≥ï‰∏éGB28181Áî®Ê≥ï‰∏ÄËá¥Ôºå‰øùÊåÅÂÖºÂÆπ„ÄÇ\n  - 4„ÄÅÊîØÊåÅh264/h265/g711/aac/mp3/g721/g722/g723/g729/g726/adpcmÁ≠âÁºñÁ†Å„ÄÇ\n\n- IPTVÁâàÊú¨\n  - 1„ÄÅÊîØÊåÅrtsp-ts/hls/http-ts/rtpÁªÑÊí≠/udpÁªÑÊí≠ÊãâÊµÅËΩ¨ÂçèËÆÆÔºåÊîØÊåÅtsÈÄè‰º†Ê®°ÂºèÔºåÊó†ÈúÄËß£Â§çÁî®ËΩ¨rtsp-ts/hls/http-ts/srtÂçèËÆÆ„ÄÇ\n  - 2„ÄÅÊîØÊåÅÊé•Êî∂rtsp-ts/srt/rtp-tsÊé®ÊµÅÔºåÊîØÊåÅtsÈÄè‰º†Ê®°ÂºèÔºåÊó†ÈúÄËß£Â§çÁî®ËΩ¨rtsp-ts/hls/http-ts/srtÂçèËÆÆ„ÄÇ\n  - 3„ÄÅ‰∏äËø∞ÂäüËÉΩÂêåÊó∂ÊîØÊåÅËß£Â§çÁî®ts‰∏∫esÊµÅÂÜçËΩ¨rtsp/rtmp/flv/http-ts/hls/hls-fmp4/mp4/fmp4/webrtcÁ≠âÂçèËÆÆ„ÄÇ\n\n- S3‰∫ëÂ≠òÂÇ®\n  - ÊîØÊåÅs3/minio‰∫ëÂ≠òÂÇ®ÂÜÖÂ≠òÊµÅÁõ¥Êé•ÂÜôÂÖ•ÔºåËß£ÂÜ≥ÂΩïÂÉèÊñá‰ª∂ioÁ≥ªÁªüÁì∂È¢àÈóÆÈ¢ò\n  - ÊîØÊåÅÁõ¥Êé•ÈÄöËøázlmediakitÁöÑhttpÊúçÂä°‰∏ãËΩΩÂíåÁÇπÊí≠‰∫ëÂ≠òÂÇ®Êñá‰ª∂„ÄÇ\n  - ÊîØÊåÅÈÅçÂéÜ‰∫ëÂ≠òÂÇ®Êñá‰ª∂Âπ∂ÁîüÊàêhttpËèúÂçïÁΩëÈ°µ„ÄÇ\n \n- WebRTCÈõÜÁæ§\n  - ÊîØÊåÅrtcÊµÅÈáè‰ª£ÁêÜÔºåËß£ÂÜ≥k8sÈÉ®ÁΩ≤zlmediakit webrtcÊúçÂä°Êó∂Ôºåhttp‰ø°‰ª§‰∫§‰∫í‰∏értcÊµÅÈáèÊâì‰∏çÂà∞Âêå‰∏Ä‰∏™podÂÆû‰æãÁöÑÈóÆÈ¢ò„ÄÇ\n \n- AIÊé®ÁêÜ\n  - ÊîØÊåÅyoloÊé®ÁêÜÊèí‰ª∂ÔºåÊîØÊåÅ‰∫∫Âëò„ÄÅËΩ¶ËæÜÁ≠âÁõÆÊ†áAIËØÜÂà´ÔºåÊîØÊåÅÁõÆÊ†áË∑üË∏™ÔºåÊîØÊåÅÂ§öËæπÂΩ¢Â∏ÉÈò≤ÔºåÊîØÊåÅocrÔºåÊîØÊåÅc++/pythonÊèí‰ª∂Âø´ÈÄüÊ∑∑ÂêàÂºÄÂèë„ÄÇ\n  - ÊîØÊåÅtensorRT ÂÖ®cudaÂä†ÈÄüÊé®ÁêÜ„ÄÇ\n  - ÊîØÊåÅonnxruntime(cpu/gpu) Êé®ÁêÜ„ÄÇ\n  - ÊîØÊåÅascend cannÂä†ÈÄüÊé®ÁêÜ„ÄÇ\n  - pythonÊèí‰ª∂ÊîØÊåÅË∞ÉÁî®c++Êé•Âè£Êìç‰ΩúÊµÅÂ™í‰Ωì‰∏éÁªòÂà∂ÂΩìÂâçËßÜÈ¢ëÁîªÈù¢„ÄÇ\n\n## ÁºñËØë‰ª•ÂèäÊµãËØï\n**ÁºñËØëÂâçÂä°ÂøÖ‰ªîÁªÜÂèÇËÄÉwiki:[Âø´ÈÄüÂºÄÂßã](https://github.com/ZLMediaKit/ZLMediaKit/wiki/%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B)Êìç‰Ωú!!!**\n\n## ÊÄé‰πà‰ΩøÁî®\n\n ‰Ω†Êúâ‰∏âÁßçÊñπÊ≥ï‰ΩøÁî®ZLMediaKitÔºåÂàÜÂà´ÊòØÔºö\n\n - 1„ÄÅ‰ΩøÁî®c apiÔºå‰Ωú‰∏∫sdk‰ΩøÁî®ÔºåËØ∑ÂèÇËÄÉ[ËøôÈáå](https://github.com/ZLMediaKit/ZLMediaKit/tree/master/api/include).\n - 2„ÄÅ‰Ωú‰∏∫Áã¨Á´ãÁöÑÊµÅÂ™í‰ΩìÊúçÂä°Âô®‰ΩøÁî®Ôºå‰∏çÊÉ≥ÂÅöc/c++ÂºÄÂèëÁöÑÔºåÂèØ‰ª•ÂèÇËÄÉ [restful api](https://github.com/ZLMediaKit/ZLMediaKit/wiki/MediaServerÊîØÊåÅÁöÑHTTP-API) Âíå [web hook](https://github.com/ZLMediaKit/ZLMediaKit/wiki/MediaServerÊîØÊåÅÁöÑHTTP-HOOK-API ).\n - 3„ÄÅÂ¶ÇÊûúÊÉ≥ÂÅöc/c++ÂºÄÂèëÔºåÊ∑ªÂä†‰∏öÂä°ÈÄªËæëÂ¢ûÂä†ÂäüËÉΩÔºåÂèØ‰ª•ÂèÇËÄÉËøôÈáåÁöÑ[ÊµãËØïÁ®ãÂ∫è](https://github.com/ZLMediaKit/ZLMediaKit/tree/master/tests).\n\n## ‰∫åËøõÂà∂Êñá‰ª∂‰∏ãËΩΩ\nzlmediakitÈááÁî® github action ÊåÅÁª≠ÈõÜÊàêËá™Âä®ÁºñËØëÊâìÂåÖ‰∏ä‰º†ÁºñËØë‰∫ßÂá∫ÂåÖÔºåËØ∑Âú®[issueÂàóË°®](https://github.com/ZLMediaKit/ZLMediaKit/issues/483)‰∏ãËΩΩÊúÄÊñ∞sdkÂ∫ìÊñá‰ª∂‰ª•ÂèäÂèØÊâßË°åÊñá‰ª∂„ÄÇ\n\n## Docker ÈïúÂÉè\n\n‰Ω†ÂèØ‰ª•‰ªéDocker Hub‰∏ãËΩΩÂ∑≤ÁªèÁºñËØëÂ•ΩÁöÑÈïúÂÉèÂπ∂ÂêØÂä®ÂÆÉÔºö\n\n```bash\n#Ê≠§ÈïúÂÉè‰∏∫github action ÊåÅÁª≠ÈõÜÊàêËá™Âä®ÁºñËØëÊé®ÈÄÅÔºåË∑ü‰ª£Á†Å(masterÂàÜÊîØ)‰øùÊåÅÊúÄÊñ∞Áä∂ÊÄÅ\ndocker run -id -p 1935:1935 -p 8080:80 -p 8443:443 -p 8554:554 -p 10000:10000 -p 10000:10000/udp -p 8000:8000/udp -p 9000:9000/udp zlmediakit/zlmediakit:master\n```\n\n‰Ω†‰πüÂèØ‰ª•Ê†πÊçÆDockerfileÁºñËØëÈïúÂÉèÔºö\n\n```bash\nbash build_docker_images.sh\n```\n\n## Âêà‰ΩúÈ°πÁõÆ\n   \n - ËßÜÈ¢ëÁÆ°ÁêÜÂπ≥Âè∞\n   - [wvp-GB28181-pro](https://github.com/648540858/wvp-GB28181-pro) javaÂÆûÁé∞ÁöÑÂºÄÁÆ±Âç≥Áî®ÁöÑGB28181ÂçèËÆÆËßÜÈ¢ëÂπ≥Âè∞\n   - [AKStream](https://github.com/chatop2020/AKStream) c#ÂÆûÁé∞ÁöÑÂÖ®ÂäüËÉΩÁöÑËΩØNVRÊé•Âè£/GB28181Âπ≥Âè∞\n   - [BXC_SipServer](https://github.com/any12345com/BXC_SipServer) c++ÂÆûÁé∞ÁöÑÂõΩÊ†áGB28181ÊµÅÂ™í‰Ωì‰ø°‰ª§ÊúçÂä°Âô®\n   - [gosip](https://github.com/panjjo/gosip) golangÂÆûÁé∞ÁöÑGB28181ÊúçÂä°Âô®\n   - [FreeEhome](https://github.com/tsingeye/FreeEhome) golangÂÆûÁé∞ÁöÑÊµ∑Â∫∑ehomeÊúçÂä°Âô®\n  \n - Êí≠ÊîæÂô®\n   - [h265web.js](https://github.com/numberwolf/h265web.js) Âü∫‰∫éwasmÊîØÊåÅH265ÁöÑÊí≠ÊîæÂô®ÔºåÊîØÊåÅÊú¨È°πÁõÆÂ§öÁßç‰∏ìÂ±ûÂçèËÆÆ\n   - [jessibuca](https://github.com/langhuihui/jessibuca) Âü∫‰∫éwasmÊîØÊåÅH265ÁöÑÊí≠ÊîæÂô®\n   - [wsPlayer](https://github.com/v354412101/wsPlayer) Âü∫‰∫éMSEÁöÑwebsocket-fmp4Êí≠ÊîæÂô®\n   - [BXC_gb28181Player](https://github.com/any12345com/BXC_gb28181Player) C++ÂºÄÂèëÁöÑÊîØÊåÅÂõΩÊ†áGB28181ÂçèËÆÆÁöÑËßÜÈ¢ëÊµÅÊí≠ÊîæÂô®\n   - [WebRTC-Vue-Demo](https://github.com/Heartbreaker16/ZLMediaKit-WebRTC-Vue-Demo) zlmediakit webrtcÊí≠ÊîæÂô®vueÁâàÊú¨\n\n- WEBÁÆ°ÁêÜÁΩëÁ´ô\n   - [zlm_webassist](https://github.com/1002victor/zlm_webassist) Êú¨È°πÁõÆÈÖçÂ•óÁöÑÂâçÂêéÁ´ØÂàÜÁ¶ªwebÁÆ°ÁêÜÈ°πÁõÆ\n   - [AKStreamNVR](https://github.com/langmansh/AKStreamNVR) ÂâçÂêéÁ´ØÂàÜÁ¶ªwebÈ°πÁõÆ,ÊîØÊåÅwebrtcÊí≠Êîæ\n   - [StreamUI](https://github.com/lmk123568/StreamUI) ‰∏Ä‰∏™ÊûÅÁÆÄ„ÄÅËΩª‰æøÁöÑËßÜÈ¢ëÊµÅÂ™í‰ΩìÁÆ°ÁêÜÂπ≥Âè∞\n   \n - SDK\n   - [spring-boot-starter](https://github.com/lunasaw/zlm-spring-boot-starter) Êú¨È°πÁõÆhookÂíårestÊé•Âè£starter\n   - [java sdk](https://github.com/lidaofu-hub/j_zlm_sdk) Êú¨È°πÁõÆc sdkÂÆåÊï¥javaÂåÖË£ÖÂ∫ì\n   - [c# sdk](https://github.com/malegend/ZLMediaKit.Autogen) Êú¨È°πÁõÆc sdkÂÆåÊï¥c#ÂåÖË£ÖÂ∫ì\n   - [metaRTC](https://github.com/metartc/metaRTC) ÂÖ®ÂõΩ‰∫ßÁ∫Øc webrtc sdk\n\n- ÁõëÊéß‰∏éËøêÁª¥\n   - [ZLMediaKit_exporter](https://github.com/guohuachan/ZLMediaKit_exporter) ‰∏Ä‰∏™Áî®‰∫éÈááÈõÜ ZLMediaKit Ê†∏ÂøÉÊåáÊ†áÁöÑ Prometheus ExporterÔºåÊê≠ÈÖç Grafana Âç≥ÂèØÂø´ÈÄüÊûÑÂª∫ÂÆûÊó∂ÁõëÊéßÈù¢Êùø\n   \n - ÂÖ∂‰ªñÈ°πÁõÆ(Â∑≤ÂÅúÊ≠¢Êõ¥Êñ∞)\n   - [NodeJSÂÆûÁé∞ÁöÑGB28181Âπ≥Âè∞](https://gitee.com/hfwudao/GB28181_Node_Http)\n   - [Âü∫‰∫éZLMediaKit‰∏ªÁ∫øÁöÑÁÆ°ÁêÜWEBÁΩëÁ´ô ](https://gitee.com/kkkkk5G/MediaServerUI)\n   - [Âü∫‰∫éZLMediaKitÂàÜÊîØÁöÑÁÆ°ÁêÜWEBÁΩëÁ´ô](https://github.com/chenxiaolei/ZLMediaKit_NVR_UI)\n   - [‰∏Ä‰∏™ÈùûÂ∏∏ÊºÇ‰∫ÆÁöÑÂèØËßÜÂåñÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªü](https://github.com/MingZhuLiu/ZLMediaServerManagent)\n   - [Âü∫‰∫éC SDKÂÆûÁé∞ÁöÑÊé®ÊµÅÂÆ¢Êà∑Á´Ø](https://github.com/hctym1995/ZLM_ApiDemo)\n   - [C#ÁâàÊú¨ÁöÑHttp API‰∏éHook](https://github.com/chengxiaosheng/ZLMediaKit.HttpApi)\n   - [DotNetCoreÁöÑRESTfulÂÆ¢Êà∑Á´Ø](https://github.com/MingZhuLiu/ZLMediaKit.DotNetCore.Sdk)\n   \n   \n## ÊéàÊùÉÂçèËÆÆ\n\nÊú¨È°πÁõÆËá™Êúâ‰ª£Á†Å‰ΩøÁî®ÂÆΩÊùæÁöÑMITÂçèËÆÆÔºåÂú®‰øùÁïôÁâàÊùÉ‰ø°ÊÅØÁöÑÊÉÖÂÜµ‰∏ãÂèØ‰ª•Ëá™Áî±Â∫îÁî®‰∫éÂêÑËá™ÂïÜÁî®„ÄÅÈùûÂïÜ‰∏öÁöÑÈ°πÁõÆ„ÄÇ\n‰ΩÜÊòØÊú¨È°πÁõÆ‰πüÈõ∂Á¢éÁöÑ‰ΩøÁî®‰∫Ü‰∏Ä‰∫õÂÖ∂‰ªñÁöÑ[ÂºÄÊ∫ê‰ª£Á†Å](https://github.com/ZLMediaKit/ZLMediaKit/wiki/%E4%BB%A3%E7%A0%81%E4%BE%9D%E8%B5%96%E4%B8%8E%E7%89%88%E6%9D%83%E5%A3%B0%E6%98%8E)ÔºåÂú®ÂïÜÁî®ÁöÑÊÉÖÂÜµ‰∏ãËØ∑Ëá™Ë°åÊõø‰ª£ÊàñÂâîÈô§Ôºõ\nÁî±‰∫é‰ΩøÁî®Êú¨È°πÁõÆËÄå‰∫ßÁîüÁöÑÂïÜ‰∏öÁ∫†Á∫∑Êàñ‰æµÊùÉË°å‰∏∫‰∏ÄÊ¶Ç‰∏éÊú¨È°πÁõÆÂèäÂºÄÂèëËÄÖÊó†ÂÖ≥ÔºåËØ∑Ëá™Ë°åÊâøÊãÖÊ≥ïÂæãÈ£éÈô©„ÄÇ\nÂú®‰ΩøÁî®Êú¨È°πÁõÆ‰ª£Á†ÅÊó∂Ôºå‰πüÂ∫îËØ•Âú®ÊéàÊùÉÂçèËÆÆ‰∏≠ÂêåÊó∂Ë°®ÊòéÊú¨È°πÁõÆ‰æùËµñÁöÑÁ¨¨‰∏âÊñπÂ∫ìÁöÑÂçèËÆÆ„ÄÇ\n\n## ËÅîÁ≥ªÊñπÂºè\n\n - ÈÇÆÁÆ±Ôºö<1213642868@qq.com>(Êú¨È°πÁõÆÁõ∏ÂÖ≥ÊàñÊµÅÂ™í‰ΩìÁõ∏ÂÖ≥ÈóÆÈ¢òËØ∑Ëµ∞issueÊµÅÁ®ãÔºåÂê¶ÂàôÊÅï‰∏çÈÇÆ‰ª∂Á≠îÂ§ç)\n - ËØ∑ÂÖ≥Ê≥®ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑Ëé∑ÂèñÊúÄÊñ∞Ê∂àÊÅØÊé®ÈÄÅÔºö\n <img src=https://user-images.githubusercontent.com/11495632/232451702-4c50bc72-84d8-4c94-af2b-57290088ba7a.png width=15% />\n \n - ‰πüÂèØ‰ª•Ëá™ÊÑøÊúâÂÅøÂä†ÂÖ•Áü•ËØÜÊòüÁêÉÂí®ËØ¢„ÄÅËé∑ÂèñËµÑÊñô‰ª•ÂèäÂä†ÂÖ•ÂæÆ‰ø°ÊäÄÊúØÁæ§Ôºö\n <img src= https://user-images.githubusercontent.com/11495632/231946329-aa8517b0-3cf5-49cf-8c75-a93ed58cb9d2.png width=30% />\n  \n\n## ÊÄé‰πàÊèêÈóÆÔºü\n\nÂ¶ÇÊûúË¶ÅÂØπÈ°πÁõÆÊúâÁõ∏ÂÖ≥ÁñëÈóÆÔºåÂª∫ËÆÆÊÇ®Ëøô‰πàÂÅöÔºö\n\n - 1„ÄÅ‰ªîÁªÜÁúã‰∏ãreadme„ÄÅwikiÔºåÂ¶ÇÊûúÊúâÂøÖË¶ÅÂèØ‰ª•Êü•Áúã‰∏ãissue.\n - 2„ÄÅÂ¶ÇÊûúÊÇ®ÁöÑÈóÆÈ¢òËøòÊ≤°Ëß£ÂÜ≥ÔºåÂèØ‰ª•Êèêissue.\n - 3„ÄÅÂ¶ÇÊûúÈúÄË¶ÅËé∑ÂèñÊõ¥ÂèäÊó∂Ë¥¥ÂøÉÁöÑÊäÄÊúØÊîØÊåÅÔºåÂèØ‰ª•ÊúâÂÅøÂä†ÂÖ•[Áü•ËØÜÊòüÁêÉ](https://github.com/ZLMediaKit/ZLMediaKit/issues/2364).\n\n## ÁâπÂà´ÊÑüË∞¢\n\nÊú¨È°πÁõÆÈááÁî®‰∫Ü[ËÄÅÈôà](https://github.com/ireader) ÁöÑ [media-server](https://github.com/ireader/media-server) Â∫ìÔºå\nÊú¨È°πÁõÆÁöÑ ts/fmp4/mp4/ps ÂÆπÂô®Ê†ºÂºèÁöÑÂ§çÁî®Ëß£Â§çÁî®ÈÉΩ‰æùËµñmedia-serverÂ∫ì„ÄÇÂú®ÂÆûÁé∞Êú¨È°πÁõÆËØ∏Â§öÂäüËÉΩÊó∂ÔºåËÄÅÈôàÂ§öÊ¨°Áªô‰∫à‰∫ÜÊó†ÁßÅÁÉ≠ÊÉÖÂÖ≥ÈîÆÁöÑÂ∏ÆÂä©Ôºå\nÁâπÊ≠§ÂØπ‰ªñË°®Á§∫ËØöÊåöÁöÑÊÑüË∞¢ÔºÅ\n\n## Ëá¥Ë∞¢\n\nÊÑüË∞¢‰ª•‰∏ãÂêÑ‰ΩçÂØπÊú¨È°πÁõÆÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫é‰ª£Á†ÅË¥°ÁåÆ„ÄÅÈóÆÈ¢òÂèçÈ¶à„ÄÅËµÑÈáëÊçêËµ†Á≠âÂêÑÁßçÊñπÂºèÁöÑÊîØÊåÅÔºÅ‰ª•‰∏ãÊéíÂêç‰∏çÂàÜÂÖàÂêéÔºö\n\n[ËÄÅÈôà](https://github.com/ireader)\n[Gemfield](https://github.com/gemfield)\n[ÂçóÂÜ†ÂΩ§](https://github.com/nanguantong2)\n[ÂáπÂá∏ÊÖ¢](https://github.com/tsingeye)\n[chenxiaolei](https://github.com/chenxiaolei)\n[Âè≤ÂâçÂ∞èËô´](https://github.com/zqsong)\n[Ê∏ÖÊ∂©ÁªøËå∂](https://github.com/baiyfcu)\n[3503207480](https://github.com/3503207480)\n[DroidChow](https://github.com/DroidChow)\n[ÈòøÂ°û](https://github.com/HuoQiShuai)\n[ÁÅ´ÂÆ£](https://github.com/ChinaCCF)\n[Œ≥ÁëûŒ≥„Éü](https://github.com/JerryLinGd)\n[linkingvision](https://www.linkingvision.com/)\n[ËåÑÂ≠ê](https://github.com/taotaobujue2008)\n[Â•ΩÂøÉÊÉÖ](mailto:409257224@qq.com)\n[ÊµÆÊ≤â](https://github.com/MingZhuLiu)\n[Xiaofeng Wang](https://github.com/wasphin)\n[doodoocoder](https://github.com/doodoocoder)\n[qingci](https://github.com/Colibrow)\n[swwheihei](https://github.com/swwheihei)\n[KKKKK5G](https://gitee.com/kkkkk5G)\n[Zhou Weimin](mailto:zhouweimin@supremind.com)\n[Jim Jin](https://github.com/jim-king-2000)\n[Ë•øÁìú‰∏∂](mailto:392293307@qq.com)\n[MingZhuLiu](https://github.com/MingZhuLiu)\n[chengxiaosheng](https://github.com/chengxiaosheng)\n[big panda](mailto:2381267071@qq.com)\n[tanningzhong](https://github.com/tanningzhong)\n[hctym1995](https://github.com/hctym1995)\n[hewenyuan](https://gitee.com/kingyuanyuan)\n[sunhui](mailto:sunhui200475@163.com)\n[mirs](mailto:fangpengcheng@bilibili.com)\n[Kevin Cheng](mailto:kevin__cheng@outlook.com)\n[Liu Jiang](mailto:root@oopy.org)\n[along](https://github.com/alongl)\n[qingci](mailto:xpy66swsry@gmail.com)\n[lyg1949](mailto:zh.ghlong@qq.com)\n[zhlong](mailto:zh.ghlong@qq.com)\n[Â§ßË£§Ë°©](mailto:3503207480@qq.com)\n[droid.chow](mailto:droid.chow@gmail.com)\n[ÈôàÊôìÊûó](https://github.com/musicwood)\n[CharleyWangHZ](https://github.com/CharleyWangHZ)\n[Johnny](https://github.com/johzzy)\n[DoubleX69](https://github.com/DoubleX69)\n[lawrencehj](https://github.com/lawrencehj)\n[yangkun](mailto:xyyangkun@163.com)\n[Xinghua Zhao](mailto:holychaossword@hotmail.com)\n[hejilin](https://github.com/brokensword2018)\n[rqb500](https://github.com/rqb500)\n[Alex](https://github.com/alexliyu7352)\n[Dw9](https://github.com/Dw9)\n[ÊòéÊúàÊÉäÈπä](mailto:mingyuejingque@gmail.com)\n[cgm](mailto:2958580318@qq.com)\n[hejilin](mailto:1724010622@qq.com)\n[alexliyu7352](mailto:liyu7352@gmail.com)\n[cgm](mailto:2958580318@qq.com)\n[haorui wang](https://github.com/HaoruiWang)\n[joshuafc](mailto:joshuafc@foxmail.com)\n[JayChen0519](https://github.com/JayChen0519)\n[zx](mailto:zuoxue@qq.com)\n[wangcker](mailto:wangcker@163.com)\n[WuPeng](mailto:wp@zafu.edu.cn)\n[starry](https://github.com/starry)\n[mtdxc](https://github.com/mtdxc)\n[ËÉ°ÂàöÈ£é](https://github.com/hugangfeng333)\n[zhao85](https://github.com/zhao85)\n[dreamisdream](https://github.com/dreamisdream)\n[dingcan](https://github.com/dcan123)\n[Haibo Chen](https://github.com/duiniuluantanqin)\n[Leon](https://gitee.com/leon14631)\n[custompal](https://github.com/custompal)\n[PioLing](https://github.com/PioLing)\n[KevinZang](https://github.com/ZSC714725)\n[gongluck](https://github.com/gongluck)\n[a-ucontrol](https://github.com/a-ucontrol)\n[TalusL](https://github.com/TalusL)\n[ahaooahaz](https://github.com/AHAOAHA)\n[TempoTian](https://github.com/TempoTian)\n[Derek Liu](https://github.com/yjkhtddx)\n[ljx0305](https://github.com/ljx0305)\n[Êú±Â¶ÇÊ¥™ ](https://github.com/zhu410289616)\n[lijin](https://github.com/1461521844lijin)\n[PioLing](https://github.com/PioLing)\n[BackT0TheFuture](https://github.com/BackT0TheFuture)\n[perara](https://github.com/perara)\n[codeRATny](https://github.com/codeRATny)\n[dengjfzh](https://github.com/dengjfzh)\n[ÁôæÈ∏£](https://github.com/ixingqiao)\n[fruit Juice](https://github.com/xuandu)\n[tbago](https://github.com/tbago)\n[Luosh](https://github.com/Luosh)\n[linxiaoyan87](https://github.com/linxiaoyan)\n[waken](https://github.com/mc373906408)\n[Deepslient](https://github.com/Deepslient)\n[imp_rayjay](https://github.com/rayjay214)\n[ArmstrongCN](https://github.com/ArmstrongCN)\n[leibnewton](https://github.com/leibnewton)\n[1002victor](https://github.com/1002victor)\n[Grin](https://github.com/xyyangkun)\n[xbpeng121](https://github.com/xbpeng121)\n[lvchenyun](https://github.com/lvchenyun)\n[Fummowo](https://github.com/Fummowo)\n[Jovial Young ](https://github.com/JHYoung1034)\n[yujitai](https://github.com/yujitai)\n[KisChang](https://github.com/kisChang)\n[zjx94](https://github.com/zjx94)\n[LeiZhi.Mai ](https://github.com/blueskiner)\n[JiaHao](https://github.com/nashiracn)\n[chdahuzi](https://github.com/chdahuzi)\n[snysmtx](https://github.com/snysmtx)\n[SetoKaiba](https://github.com/SetoKaiba)\n[sandro-qiang](https://github.com/sandro-qiang)\n[Paul Philippov](https://github.com/themactep)\n[Âº†‰º†Â≥∞](https://github.com/zhang-chuanfeng)\n[lidaofu-hub](https://github.com/lidaofu-hub)\n[huangcaichun](https://github.com/huangcaichun)\n[jamesZHANG500](https://github.com/jamesZHANG500)\n[weidelong](https://github.com/wdl1697454803)\n[Â∞èÂº∫ÂÖàÁîü](https://github.com/linshangqiang)\n[Êùé‰πãÈò≥](https://github.com/leo94666)\n[sgzed](https://github.com/sgzed)\n[gaoshan](https://github.com/foobra)\n[zhang2349](https://github.com/zhang2349)\n[benshi](https://github.com/BenLocal)\n[autoantwort](https://github.com/autoantwort)\n[u7ko4](https://github.com/u7ko4)\n[WengQiang](https://github.com/Tsubaki-01)\n[wEnchanters](https://github.com/wEnchanters)\n[sbkyy](https://github.com/sbkyy)\n[wuxingzhong](https://github.com/wuxingzhong)\n[286897655](https://github.com/286897655)\n[ss002012](https://github.com/ss002012)\n[a839419160](https://github.com/a839419160)\n[oldma3095](https://github.com/oldma3095)\n[Dary](https://github.com/watersounds)\n[N.z](https://github.com/neesonqk)\n[yanggs](https://github.com/callinglove)\n\nÂêåÊó∂ÊÑüË∞¢JetBrainsÂØπÂºÄÊ∫êÈ°πÁõÆÁöÑÊîØÊåÅÔºåÊú¨È°πÁõÆ‰ΩøÁî®CLionÂºÄÂèë‰∏éË∞ÉËØïÔºö\n\n[![JetBrains](https://resources.jetbrains.com/storage/products/company/brand/logos/CLion.svg)](https://jb.gg/OpenSourceSupport)\n\n## ‰ΩøÁî®Ê°à‰æã\n\nÊú¨È°πÁõÆÂ∑≤ÁªèÂæóÂà∞‰∏çÂ∞ëÂÖ¨Âè∏Âíå‰∏™‰∫∫ÂºÄÂèëËÄÖÁöÑËÆ§ÂèØÔºåÊçÆ‰ΩúËÄÖ‰∏çÂÆåÂÖ®ÁªüËÆ°Ôºå\n‰ΩøÁî®Êú¨È°πÁõÆÁöÑÂÖ¨Âè∏ÂåÖÊã¨Áü•ÂêçÁöÑ‰∫íËÅîÁΩëÂ∑®Â§¥„ÄÅÂõΩÂÜÖÊéíÂêçÂâçÂàóÁöÑ‰∫ëÊúçÂä°ÂÖ¨Âè∏„ÄÅÂ§öÂÆ∂Áü•ÂêçÁöÑAIÁã¨ËßíÂÖΩÂÖ¨Âè∏Ôºå\n‰ª•Âèä‰∏ÄÁ≥ªÂàó‰∏≠Â∞èÂûãÂÖ¨Âè∏„ÄÇ‰ΩøÁî®ËÄÖÂèØ‰ª•ÈÄöËøáÂú® [issue](https://github.com/ZLMediaKit/ZLMediaKit/issues/511) ‰∏äÁ≤òË¥¥ÂÖ¨Âè∏ÁöÑÂ§ßÂêçÂíåÁõ∏ÂÖ≥È°πÁõÆ‰ªãÁªç‰∏∫Êú¨È°πÁõÆËÉå‰π¶ÔºåÊÑüË∞¢ÊîØÊåÅÔºÅ\n",
      "stars_today": 7
    },
    {
      "id": 402945349,
      "name": "starrocks",
      "full_name": "StarRocks/starrocks",
      "description": "The world's fastest open query engine for sub-second analytics both on and off the data lakehouse. With the flexibility to support nearly any scenario, StarRocks provides best-in-class performance for multi-dimensional analytics, real-time analytics, and ad-hoc queries. A Linux Foundation project.",
      "html_url": "https://github.com/StarRocks/starrocks",
      "stars": 11305,
      "forks": 2275,
      "language": "Java",
      "topics": [
        "analytics",
        "big-data",
        "cloudnative",
        "database",
        "datalake",
        "delta-lake",
        "distributed-database",
        "hudi",
        "iceberg",
        "join",
        "lakehouse",
        "lakehouse-platform",
        "mpp",
        "olap",
        "real-time-analytics",
        "real-time-updates",
        "realtime-database",
        "sql",
        "star-schema",
        "vectorized"
      ],
      "created_at": "2021-09-04T02:29:35Z",
      "updated_at": "2026-01-23T21:39:09Z",
      "pushed_at": "2026-01-24T01:28:37Z",
      "open_issues": 958,
      "owner": {
        "login": "StarRocks",
        "avatar_url": "https://avatars.githubusercontent.com/u/88238841?v=4"
      },
      "readme": "\n <img referrerpolicy=\"no-referrer-when-downgrade\" src=\"https://static.scarf.sh/a.png?x-pxid=e8355b6b-a9fc-4d4e-8ed8-b3157aa1827d\" />\n <p align=\"center\">\n <a href=\"https://starrocks.io/index\">\n    <img  width=\"900\" src=\"https://cdn.starrocks.io/static/github/starrocks.png?t=12234\">\n   </a>\n</p>\n<p align=\"center\">\n  <a href=\"https://starrocks.io/download/community\">Download</a> | <a href=\"https://docs.starrocks.io/\">Docs</a> | <a href=\"https://starrocks.io/blog/benchmark-test\">Benchmarks</a> | <a href=\"https://github.com/StarRocks/demo\">Demo</a>\n</p>\n<p align=\"center\">\n\n <img src=\"https://img.shields.io/badge/Made%20with-JAVA%20%26%20C%2B%2B-red\" alt=\"JAVA&C++\">\n    </a>\n    <img src=\"https://img.shields.io/github/commit-activity/m/StarRocks/starrocks\" alt=\"Commit Activities\">\n    </a>\n   <a href=\"https://github.com/StarRocks/starrocks/issues\">\n    <img src=\"https://img.shields.io/github/issues-raw/StarRocks/starrocks\" alt=\"Open Issues\">\n  </a>\n  </a>\n   <a href=\"https://starrocks.io/index\">\n    <img src=\"https://img.shields.io/badge/Visit%20StarRocks-Website-green\" alt=\"Website\">\n  </a>\n  </a>\n   <a href=\"https://try.starrocks.com/join-starrocks-on-slack\">\n    <img src=\"https://img.shields.io/badge/Join-Slack-ff69b4\" alt=\"Slack\">\n  </a>\n  </a>\n   <a href=\"https://twitter.com/StarRocksLabs\">\n    <img src=\"https://img.shields.io/twitter/follow/StarRocksLabs?style=social\" alt=\"Twitter\">\n  </a>\n  <a href=\"https://gurubase.io/g/starrocks\">\n    <img src=\"https://img.shields.io/badge/Gurubase-Ask%20StarRocks%20Guru-006BFF\" alt=\"Gurubase\">\n  </a>\n </p>\n\n<div align=\"center\"> \n\n</div>\nStarRocks is the world's fastest open query engine for sub-second, ad-hoc analytics both on and off the data lakehouse. With average query performance 3x faster than other popular alternatives, StarRocks is a query engine that eliminates the need for denormalization and adapts to your use cases, without having to move your data or rewrite SQL. A Linux Foundation project. <br></br>\n\nLearn more üëâüèª [What Is StarRocks: Features and Use Cases](https://www.youtube.com/watch?v=RfXO5GOnbW4&ab_channel=CelerData), \nJoin [StarRocks Summit 2025](https://summit.starrocks.io/2025)!\n\n<br>\n <p align=\"center\">\n    <img src=\"https://cdn.starrocks.io/static/github/community.gif\">\n   </a>\n</p>\n</br>\n\n## Features\n\n* **üöÄ Native vectorized SQL engine:** StarRocks adopts vectorization technology to make full use of the parallel computing power of CPU, achieving sub-second query returns in multi-dimensional analyses, which is 5 to 10 times faster than previous systems.\n* **üìä Standard SQL:** StarRocks supports ANSI SQL syntax (fully supported TPC-H and TPC-DS). It is also compatible with the MySQL protocol. Various clients and BI software can be used to access StarRocks.\n* **üí° Smart query optimization:** StarRocks can optimize complex queries through CBO (Cost Based Optimizer). With a better execution plan, the data analysis efficiency will be greatly improved.\n* **‚ö° Real-time update:** The updated model of StarRocks can perform upsert/delete operations according to the primary key, and achieve efficient query while concurrent updates.\n* **ü™ü Intelligent materialized view:** The materialized view of StarRocks can be automatically updated during the data import and automatically selected when the query is executed.\n* **‚ú® Querying data in data lakes directly**: StarRocks allows direct access to data from Apache Hive‚Ñ¢, Apache Iceberg‚Ñ¢, Delta Lake‚Ñ¢ and Apache Hudi‚Ñ¢ without importing.\n* **üéõÔ∏è Resource management**: This feature allows StarRocks to limit resource consumption for queries and implement isolation and efficient use of resources among tenants in the same cluster.\n* **üí† Easy to maintain**: Simple architecture makes StarRocks easy to deploy, maintain and scale out. StarRocks tunes its query plan agilely, balances the resources when the cluster is scaled in or out, and recovers the data replica under node failure automatically.\n\n\n\n<br>\n  \n## Architecture Overview\n\n <p align=\"center\">\n    <img src=\"images/arch.png\">\n   </a>\n</p>\n\n\nStarRocks‚Äôs streamlined architecture is mainly composed of two modules: Frontend (FE) and Backend (BE).  The entire system eliminates single points of failure through seamless and horizontal scaling of FE and BE, as well as replication of metadata and data.\n\nStarting from version 3.0, StarRocks supports a new shared-data architecture, which can provide better scalability and lower costs.\n\n <p align=\"center\">\n    <img src=\"docs/en/_assets/shared-data.png\" width=\"55%\" height=\"55%\">\n   </a>\n</p>\n\n\n<br>\n\n## Resources\n\n### üìö Read the docs\n\n| Section | Description |\n|-|-|\n| [Quick Starts](https://docs.starrocks.io/docs/quick_start/)| How-tos and Tutorials. |\n| [Deploy](https://docs.starrocks.io/docs/deployment/deployment_overview/) | Learn how to run and configure StarRocks.|\n| [Docs](https://docs.starrocks.io/)| Full documentation. |\n| [Blogs](https://www.starrocks.io/blog) | StarRocks deep dive and user stories.  |\n\n### ‚ùì Get support  \n[<img align=\"right\" width=\"150\" src=\"https://firstcontributions.github.io/assets/Readme/join-slack-team.png\">](https://try.starrocks.com/join-starrocks-on-slack)\n-  [Slack community: ](https://try.starrocks.com/join-starrocks-on-slack) join technical discussions, ask questions, and meet other users!\n-  [YouTube channel:](https://www.youtube.com/channel/UC38wR-ogamk4naaWNQ45y7Q/featured) subscribe to the latest video tutorials and webcasts.\n-  [GitHub issues:](https://github.com/StarRocks/starrocks/issues) report an issue with StarRocks.\n\n\n<br>  \n  \n## Contributing to StarRocks\n\nWe welcome all kinds of contributions from the community, individuals and partners. We owe our success to your active involvement.\n\n1. See [Contributing.md](https://github.com/StarRocks/starrocks/blob/main/CONTRIBUTING.md) to get started.\n2. Set up StarRocks development environment:\n* [IDE Setup](https://docs.starrocks.io/docs/developers/development-environment/ide-setup/) \n* [Compile StarRocks with Docker](https://docs.starrocks.io/docs/developers/build-starrocks/Build_in_docker/) \n* [Deploy StarRocks manually](https://docs.starrocks.io/docs/deployment/deploy_manually/) \n3. Understand our [GitHub workflow](https://github.com/StarRocks/community/blob/main/Contributors/guide/workflow.md) for opening a pull request; use this [PR Template](https://github.com/StarRocks/starrocks/blob/main/.github/PULL_REQUEST_TEMPLATE.md) when submitting a pull request.\n4. Pick a [good first issue](https://github.com/StarRocks/starrocks/labels/good%20first%20issue) and start contributing. \n\n**üìù License:** StarRocks is licensed under [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0).\n\n**üë• Community Membership:** Learn more about different [contributor roles](community/membership.md) in StarRocks community.\n\n**üí¨ Developer GroupÔºö** Please join our [Google Groups](https://groups.google.com/g/starrocks-dev) to discuss StarRocks features, project directions, issues, pull requests, or share suggestions.\n  \n<br>\n  \n## Used By\n\nThis project is used by the following companies. Learn more about their use cases:\n\n- [Airbnb](https://www.youtube.com/watch?v=AzDxEZuMBwM&ab_channel=StarRocks_labs)\n- [Airtable](https://medium.com/airtable-eng/live-shard-data-archive-export-and-ingestion-to-starrocks-for-validation-6af555e8b3fe)\n- [Alibaba](https://www.youtube.com/watch?v=7N34q65mthk)\n- [Celonis](https://www.youtube.com/watch?v=Jm-D0xvOtek)\n- [Cisco](https://www.starrocks.io/blog/how-cisco-webex-unified-real-time-analytics-with-starrocks)\n- [Coinbase](https://www.youtube.com/watch?v=3Z9jSCaHnYg&list=PL0eWwaesODdhBhKSnvpfIEAB9sgk8rKmy)\n- [Demandbase](https://starrocks.medium.com/demandbase-ditches-denormalization-by-switching-off-clickhouse-44195d795a83)\n- [Didi](https://www.starrocks.io/blog/reduced-80-cost-didis-journey-from-multiple-olap-engines-to-starrocks)\n- [Eightfold.ai](https://www.youtube.com/watch?v=qNk_-QTZk3E)\n- [Fanatics](https://www.youtube.com/watch?v=hbXovqR6tOc)\n- [Fresha](https://medium.com/fresha-data-engineering/how-we-accidentally-became-one-of-uks-first-starrocks-production-pioneers-7db249f10010)\n- [Grab](https://engineering.grab.com/building-a-spark-observability)\n- [Haezoom](https://www.starrocks.io/blog/haezoom-and-cloudshift-overcome-apache-druids-limits-with-starrocks)\n- [HerdWatch](https://medium.com/p/a7916a7e87bf)\n- [Intuit](https://www.youtube.com/watch?v=tUC3FS3ki10)\n- [iQiyi](https://medium.com/starrocks-engineering/real-time-analytics-at-scale-why-we-use-starrocks-0aa3c859cbeb)\n- [Naver](https://starrocks.medium.com/how-join-changed-how-we-approach-data-infra-at-naver-3a5bb1dac49f)\n- [Pinterest](https://medium.com/pinterest-engineering/delivering-faster-analytics-at-pinterest-a639cdfad374)\n- [PlaySimple Games](https://medium.com/@sukkhjot/querying-billions-of-user-events-in-seconds-our-journey-with-starrocks-ecc29ac6c756)\n- [Shopee](https://celerdata.com/blog/how-shopee-3xed-their-query-performance-with-starrocks)\n- [Splitmetrics](https://celerdata.com/blog/how-splitmetrics-replaced-postgresql-with-starrocks-for-customer-facing-analytics)\n- [Tencent(Games)](https://www.starrocks.io/blog/tencent-unifies-their-gaming-analytics-with-starrocks)\n- [Tencent(LLM)](https://www.youtube.com/watch?v=WVHXFks9EQk)\n- [Trip.com](https://starrocks.medium.com/trip-com-starrocks-efficiently-supports-high-concurrent-queries-dramatically-reduces-labor-and-1e1921dd6bf8)\n- [TRM Labs](https://www.trmlabs.com/post/from-bigquery-to-lakehouse-how-we-built-a-petabyte-scale-data-analytics-platform-part-1)\n- [Verisoul](https://celerdata.com/blog/verisoul-enables-real-time-analytics-by-transitioning-off-bigquery)\n- [Vivo](https://medium.com/starrocks-engineering/vivos-journey-to-a-high-performance-lakehouse-with-starrocks-56a502a0fde8) \n- [Xiaohongshu/RedNote](https://www.youtube.com/watch?v=2cvIZY4EDak&list=PL0eWwaesODdiJ0aXLzSTyNfkjjIFYpOTf)\n- [Yuno](https://celerdata.com/blog/from-hours-to-seconds-how-yuno-accelerated-customer-facing-analytics-by-switching-off-snowflake-and-athena)\n- [Zepto](https://blog.zeptonow.com/data-that-delivers-real-time-insights-for-brand-success-in-quick-commerce-b8b9e994d20b)\n\n",
      "stars_today": 7
    },
    {
      "id": 320636477,
      "name": "WebKit",
      "full_name": "WebKit/WebKit",
      "description": "Home of the WebKit project, the browser engine used by Safari, Mail, App Store and many other applications on macOS, iOS and Linux.",
      "html_url": "https://github.com/WebKit/WebKit",
      "stars": 9551,
      "forks": 1817,
      "language": "JavaScript",
      "topics": [
        "browser",
        "gtk",
        "ios",
        "javascript",
        "macos",
        "web",
        "webkit"
      ],
      "created_at": "2020-12-11T17:11:43Z",
      "updated_at": "2026-01-24T00:50:14Z",
      "pushed_at": "2026-01-24T00:50:07Z",
      "open_issues": 1782,
      "owner": {
        "login": "WebKit",
        "avatar_url": "https://avatars.githubusercontent.com/u/6458?v=4"
      },
      "readme": "# WebKit\n\nWebKit is a cross-platform web browser engine. On iOS and macOS, it powers Safari, Mail, Apple Books, and many other applications. For more information about WebKit, see the [WebKit project website](https://webkit.org/).\n\n## Trying the Latest\n\nOn macOS, [download Safari Technology Preview](https://webkit.org/downloads/) to test the latest version of WebKit. On Linux, download [Epiphany Technology Preview](https://webkitgtk.org/epiphany-tech-preview). On Windows, you'll have to build it yourself.\n\n## Reporting Bugs\n\n1. [Search WebKit Bugzilla](https://bugs.webkit.org/query.cgi?format=specific&product=WebKit) to see if there is an existing report for the bug you've encountered.\n2. [Create a Bugzilla account](https://bugs.webkit.org/createaccount.cgi) to report bugs (and comment on them) if you haven't done so already.\n3. File a bug in accordance with [our guidelines](https://webkit.org/bug-report-guidelines/).\n\nOnce your bug is filed, you will receive email when it is updated at each stage in the [bug life cycle](https://webkit.org/bug-life-cycle). After the bug is considered fixed, you may be asked to download the [latest nightly](https://webkit.org/nightly) and confirm that the fix works for you.\n\n## Getting the Code\n\nRun the following command to clone WebKit's Git repository:\n\n```\ngit clone https://github.com/WebKit/WebKit.git WebKit\n```\n\nYou can enable [git fsmonitor](https://git-scm.com/docs/git-config#Documentation/git-config.txt-corefsmonitor) to make many git commands faster (such as `git status`) with `git config core.fsmonitor true`\n\n## Building WebKit\n\n### Building for Apple platforms\n\nInstall Xcode and its command line tools if you haven't done so already:\n\n1. **Install Xcode** Get Xcode from https://developer.apple.com/downloads. To build WebKit for OS X, Xcode 5.1.1 or later is required. To build WebKit for iOS Simulator, Xcode 7 or later is required.\n2. **Install the Xcode Command Line Tools** In Terminal, run the command: `xcode-select --install`\n\nRun the following command to build a macOS debug build with debugging symbols and assertions:\n\n```\nTools/Scripts/build-webkit --debug\n```\n\nFor performance testing, and other purposes, use `--release` instead. If you\nalso need debug symbols (dSYMs), run:\n\n```\nTools/Scripts/build-webkit --release DEBUG_INFORMATION_FORMAT=dwarf-with-dsym \n```\n\n#### Embedded Builds\n\nTo build for an embedded platform like iOS, tvOS, or watchOS, pass a platform\nargument to `build-webkit`.\n\nFor example, to build a debug build with debugging symbols and assertions for\nembedded simulators:\n\n```\nTools/Scripts/build-webkit --debug --<platform>-simulator\n```\n\nor embedded devices:\n```\nTools/Scripts/build-webkit --debug --<platform>-device\n```\n\nwhere `platform` is `ios`, `tvos` or `watchos`.\n\n#### Using Xcode\n\nYou can open `WebKit.xcworkspace` to build and debug WebKit within Xcode.\nSelect the \"Everything up to WebKit + Tools\" scheme to build the entire\nproject.\n\nIf you don't use a custom build location in Xcode preferences, you have to\nupdate the workspace settings to use `WebKitBuild` directory.  In menu bar,\nchoose File > Workspace Settings, then click the Advanced button, select\n\"Custom\", \"Relative to Workspace\", and enter `WebKitBuild` for both Products\nand Intermediates.\n\n### Building the GTK Port\n\nFor production builds:\n\n```\ncmake -DPORT=GTK -DCMAKE_BUILD_TYPE=RelWithDebInfo -GNinja\nninja\nsudo ninja install\n```\n\nFor development builds:\n\n```\nTools/gtk/install-dependencies\nTools/Scripts/update-webkitgtk-libs\nTools/Scripts/build-webkit --gtk --debug\n```\n\nFor more information on building WebKitGTK, see the [wiki page](https://trac.webkit.org/wiki/BuildingGtk).\n\n### Building the WPE Port\n\nFor production builds:\n\n```\ncmake -DPORT=WPE -DCMAKE_BUILD_TYPE=RelWithDebInfo -GNinja\nninja\nsudo ninja install\n```\n\nFor development builds:\n\n```\nTools/wpe/install-dependencies\nTools/Scripts/update-webkitwpe-libs\nTools/Scripts/build-webkit --wpe --debug\n```\n\n### Building Windows Port\n\nFor building WebKit on Windows, see the [WebKit on Windows page](https://docs.webkit.org/Ports/WindowsPort.html).\n\n## Running WebKit\n\n### With Safari and Other macOS Applications\n\nRun the following command to launch Safari with your local build of WebKit:\n\n```\nTools/Scripts/run-safari --debug\n```\n\nThe `run-safari` script sets the `DYLD_FRAMEWORK_PATH` environment variable to point to your build products, and then launches `/Applications/Safari.app`. `DYLD_FRAMEWORK_PATH` tells the system loader to prefer your build products over the frameworks installed in `/System/Library/Frameworks`.\n\nTo run other applications with your local build of WebKit, run the following command:\n\n```\nTools/Scripts/run-webkit-app <application-path>\n```\n\n### iOS Simulator\n\nRun the following command to launch iOS simulator with your local build of WebKit:\n\n```\nrun-safari --debug --ios-simulator\n```\n\nIn both cases, if you have built release builds instead, use `--release` instead of `--debug`.\n\nTo run other applications, for example MobileMiniBrowser, with your local build of WebKit, run the following command:\n\n``` shell\nTools/Scripts/run-webkit-app --debug --iphone-simulator <application-path>\n```\n\n#### Using Xcode\n\nOpen `WebKit.xcworkspace`, select intended scheme such as MobileMiniBrowser and an iOS simulator as target, click run.\n\n### Linux Ports\n\nIf you have a development build, you can use the `run-minibrowser` script, e.g.:\n\n```\nrun-minibrowser --debug --wpe\n```\n\nPass one of `--gtk`, `--jsc-only`, or `--wpe` to indicate the port to use.\n\n## Contribute\n\nCongratulations! You‚Äôre up and running. Now you can begin coding in WebKit and contribute your fixes and new features to the project. For details on submitting your code to the project, read [Contributing Code](https://webkit.org/contributing-code/).\n",
      "stars_today": 7
    },
    {
      "id": 248400799,
      "name": "LibChecker",
      "full_name": "LibChecker/LibChecker",
      "description": "An app to view libraries used in apps in your device.",
      "html_url": "https://github.com/LibChecker/LibChecker",
      "stars": 6487,
      "forks": 407,
      "language": "Kotlin",
      "topics": [
        "android",
        "f-droid",
        "fdroid",
        "kotlin"
      ],
      "created_at": "2020-03-19T03:21:14Z",
      "updated_at": "2026-01-24T01:09:43Z",
      "pushed_at": "2026-01-21T11:23:25Z",
      "open_issues": 26,
      "owner": {
        "login": "LibChecker",
        "avatar_url": "https://avatars.githubusercontent.com/u/116417672?v=4"
      },
      "readme": "# LibChecker\n\n[![Android CI](https://github.com/LibChecker/LibChecker/actions/workflows/android.yml/badge.svg)](https://github.com/LibChecker/LibChecker/actions/workflows/android.yml)\n[![License](https://img.shields.io/github/license/LibChecker/LibChecker?label=License)](https://choosealicense.com/licenses/apache-2.0/)\n[![Discussion](https://img.shields.io/badge/Telegram-Group-blue.svg?logo=telegram)](https://t.me/libcheckerr)\n[![Crowdin](https://badges.crowdin.net/libchecker/localized.svg)](https://crowdin.com/project/libchecker)\n\n![Header](./source/header.png)\n\n## What's this?\nThis app is used to view the third-party libraries used by applications in your device. It can view the ABI architecture of the application's native library (in general, whether the application is 64-bit or 32-bit). It can also view well-known libraries marked by the rules repository on [GitHub](https://github.com/LibChecker/LibChecker-Rules) or [GitLab](https://gitlab.com/zhaobozhen/LibChecker-Rules), and can even sort and view them according to the number of libraries references.\n\n## Supported versions\nAndroid 7.0 ~ 16\n\nAndroid 6 [Marshmallow](https://github.com/LibChecker/LibChecker/tree/marshmallow)\n\n## Document\n[LibChecker-Docs](https://github.com/LibChecker/LibChecker-Docs)\n\n## Download\n<!-- [<img src=\"./source/coolapk-badge.png\" width=\"323\" height=\"125\" />](https://www.coolapk.com/apk/com.absinthe.libchecker) -->\n[<img src=\"https://play.google.com/intl/en_us/badges/static/images/badges/en_badge_web_generic.png\" width=\"323\" height=\"125\" />](https://play.google.com/store/apps/details?id=com.absinthe.libchecker)\n[<img src=\"https://fdroid.gitlab.io/artwork/badge/get-it-on.png\" width=\"323\" height=\"125\" />](https://f-droid.org/packages/com.absinthe.libchecker/)\n[<img src=\"https://gitlab.com/IzzyOnDroid/repo/-/raw/master/assets/IzzyOnDroid.png\" width=\"323\" height=\"125\" />](https://apt.izzysoft.de/fdroid/index/apk/com.absinthe.libchecker)\n\n## Discussions\n[Github Discussions](https://github.com/LibChecker/LibChecker/discussions)\n\n### Telegram Group\n<img src=\"./source/tg_group_dark.png#gh-dark-mode-only\" width=\"240\" height=\"240\" />\n<img src=\"./source/tg_group_light.png#gh-light-mode-only\" width=\"240\" height=\"240\" />\n",
      "stars_today": 7
    },
    {
      "id": 467381275,
      "name": "esp32-weather-epd",
      "full_name": "lmarzen/esp32-weather-epd",
      "description": "A low-power E-Paper weather display powered by an ESP32 microcontroller. Utilizes the OpenWeatherMap API.",
      "html_url": "https://github.com/lmarzen/esp32-weather-epd",
      "stars": 5873,
      "forks": 430,
      "language": "C",
      "topics": [
        "display",
        "eink",
        "embedded",
        "epaper",
        "esp32",
        "weather"
      ],
      "created_at": "2022-03-08T05:50:33Z",
      "updated_at": "2026-01-24T01:48:07Z",
      "pushed_at": "2026-01-08T05:20:16Z",
      "open_issues": 28,
      "owner": {
        "login": "lmarzen",
        "avatar_url": "https://avatars.githubusercontent.com/u/98473324?v=4"
      },
      "readme": "# ESP32 E-Paper Weather Display\n\nA low-power weather display using a wifi-enabled ESP32 microcontroller and a 7.5\" E-Paper display. Weather data is fetched from the OpenWeatherMap API, and an onboard sensor provides indoor temperature and humidity.\n\n<p float=\"left\">\n  <img src=\"showcase/assembled-demo-raleigh-front.jpg\" />\n  <img src=\"showcase/assembled-demo-raleigh-side.jpg\" width=\"49%\" />\n  <img src=\"showcase/assembled-demo-raleigh-back.jpg\" width=\"49%\" />\n  <img src=\"showcase/assembled-demo-bottom-cover.jpg\" width=\"49%\" />\n  <img src=\"showcase/assembled-demo-bottom-cover-removed.jpg\" width=\"49%\" />\n</p>\n\n## Features\n\n- Ultra-low power consumption: ~14ŒºA in sleep, ~83mA during refresh (~15s).\n\n- Long battery life: 6-12 months on a 5000mAh battery with 30-minute update frequency.\n\n- Customizable display: Supports multiple languages, units, time/date formats, AQI scales, personalization options, and much more.\n\n- Easy recharging: USB-C charging with battery monitoring.\n\nThe hourly outlook graph (bottom right) shows a line indicating temperature and shaded bars indicating probability of precipitation (or optionally volume of precipitation).\n\nHere are two (slightly outdated) examples utilizing various configuration options:\n\n<p float=\"left\">\n  <img src=\"showcase/demo-new-york.jpg\" width=\"49%\" />\n  <img src=\"showcase/demo-london.jpg\" width=\"49%\" />\n</p>\n\n## Contents\n\n- [Required Components](#required-components)\n  - [Panel Support](#panel-support)\n  - [Enclosure Options](#enclosure-options)\n  - [Solder-Free Component Selection](#solder-free-component-selection-optional)\n- [Setup Guide](#setup-guide)\n  - [Wiring](#wiring)\n  - [Configuration, Compilation, and Upload](#configuration-compilation-and-upload)\n  - [OpenWeatherMap API Key](#openweathermap-api-key)\n- [Error Messages and Troubleshooting](#error-messages-and-troubleshooting)\n  - [Low Battery](#low-battery)\n  - [WiFi Connection](#wifi-connection)\n  - [API Error](#api-error)\n  - [Time Server Error](#time-server-error)\n- [Licensing](#licensing)\n\n\n## Required Components\n\n  Some links below are affiliate links. Using them helps support the project at no extra cost to you‚Äîthanks for your support!\n\n  | Component Type  | Component                                    | Notes                                                     | Link                                                                         |\n  |-----------------|----------------------------------------------|-----------------------------------------------------------|------------------------------------------------------------------------------|\n  | ESP32           | FireBeetle 2 ESP32-E                         | Features low-power design, USB-C, and battery management. | Available [here](https://www.dfrobot.com/product-2195.html?tracking=PfSxQ8). |\n  | E-Paper Display | See [Panel Support](#panel-support).         | See [Panel Support](#panel-support).                      | See [Panel Support](#panel-support).                                         |\n  | Adapter Board   | DESPI-C02                                    | Waveshare HATs (rev 2.2/2.3) are not recommended.         | Available [here](https://www.aliexpress.us/item/3256804446769469.html).      |\n  | Sensor          | BME280                                       | Temperature, humidity, and pressure. 3.3V/5V compatible.  | Available from multiple vendors.                                             |\n  | Battery         | 3.7V LiPo w/ JST-PH2.0 connector             | Any capacity (e.g., 5000mAh for 6+ months runtime)        | Available from multiple vendors.                                             |\n  | Enclosure       | See [Enclosure Options](#enclosure-options). | See [Enclosure Options](#enclosure-options).              | See [Enclosure Options](#enclosure-options).                                 |\n\nOther items needed:\n- Wires (\"Jumper Wires\" if looking to minimize/avoid soldering).\n- Solder Iron + Solder (unless following [Solder-Free Component Selection](#solder-free-component-selection-optional)).\n- Linux, Windows, or MacOS computer (used to configure and install ESP32 firmware).\n- Push Button (optional, if you want a reset button mounted on your enslosure, else you can use the on-board reset button).\n\n### Panel Support\n\n  Waveshare and Good Display make equivalent panels. Either variant will work.\n\n  | Panel                                   | Resolution | Colors          | Notes                                                                                                                 |\n  |-----------------------------------------|------------|-----------------|-----------------------------------------------------------------------------------------------------------------------|\n  | Waveshare 7.5in e-paper (v2)            | 800x480px  | Black/White     | Available [here](https://www.waveshare.com/product/7.5inch-e-paper.htm). (recommended)                                |\n  | Good Display 7.5in e-paper (GDEY075T7)  | 800x480px  | Black/White     | [Temporarily Unavailable](https://www.aliexpress.com/item/3256802683908868.html)? (wrong product listed?)             |\n  | Waveshare 7.5in e-Paper (B)             | 800x480px  | Red/Black/White | Available [here](https://www.waveshare.com/product/7.5inch-e-paper-b.htm).                                            |\n  | Good Display 7.5in e-paper (GDEY075Z08) | 800x480px  | Red/Black/White | Available [here](https://www.aliexpress.com/item/3256803540460035.html).                                              |\n  | Waveshare 7.3in ACeP e-Paper (F)        | 800x480px  | 7-Color         | Available [here](https://www.waveshare.com/product/displays/e-paper/epaper-1/7.3inch-e-paper-f.htm).                  |\n  | Good Display 7.3in e-paper (GDEY073D46) | 800x480px  | 7-Color         | Available [here](https://www.aliexpress.com/item/3256805485098421.html).                                              |\n  | Waveshare 7.5in e-paper (v1)            | 640x384px  | Black/White     | Limited support. Some information not displayed, see [image](showcase/demo-waveshare75-version1.jpg).                 |\n  | Good Display 7.5in e-paper (GDEW075T8)  | 640x384px  | Black/White     | Limited support. Some information not displayed, see [image](showcase/demo-waveshare75-version1.jpg).                 |\n\n  This software has limited support for accent colors. E-paper panels with additional colors tend to have longer refresh times, which will reduce battery life.\n\n### Enclosure Options\n\nYou'll want a nice way to show off your project. Here are a few popular choices.\n\n- DIY Wooden\n  - I made a small stand by hollowing out a piece of wood from the bottom. On the back, I used a short USB extension cable so that I can charge the battery without needing to remove the components from the stand. I also wired a small reset button to refresh the display manually. Additionally, I 3d printed a cover for the bottom, which is held on by magnets. The E-paper screen is very thin, so I used a thin piece of acrylic to support it.\n  - Measurements:\n    - depth = 63mm <br>\n      height = 49mm <br>\n      width = 170.2mm (= width of the screen) <br>\n      screen angle = 80deg <br>\n      screen is 15mm from the front\n- 3D Printable\n  - Here is a list of community designs.\n  \n    | Contributor                                                          | Link                                                                                                      |\n    |----------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------|\n    | [Kingfisher](https://www.printables.com/@Kingfisher_32821)           | [Printables](https://www.printables.com/model/1139047-weather-station-e-ink-frame)                        |\n    | [Francois Allard](https://www.printables.com/@FrAllard_1585397)      | [Printables](https://www.printables.com/model/791477-weather-station-using-a-esp32)                       |\n    | [3D Nate](https://www.printables.com/@3DNate_451157)                 | [Printables](https://www.printables.com/model/661183-e-ink-weather-station-frame)                         |\n    | [Sven F.](https://github.com/Spanholz)                               | [Printables](https://www.printables.com/model/657756-case-for-esp32-weather-station)                      |\n    | [Layers Studio](https://www.printables.com/@LayersStudio)            | [Printables](https://www.printables.com/model/655768-esp32-e-paper-weather-display-stand)                 |\n    | [PJ Veltri](https://www.printables.com/@PJVeltri_1590999)            | [Printables](https://www.printables.com/model/692944-base-and-display-holder-for-esp-32-e-paper-weather)  |\n    | [TheMeanCanEHdian](https://www.printables.com/@TheMeanCanEH_1207348) | [Printables](https://www.printables.com/model/841458-weather-display-enclosure)                           |\n    | [MPHarms](https://www.thingiverse.com/mpharms/designs)               | [Thingiverse](https://www.thingiverse.com/thing:6666148)                                                  |\n    | [Plaste-Metz](https://www.printables.com/@PlasteMetz_576567)         | [Printables](https://www.printables.com/model/1160924-weather-station-case)                               |\n    | [kenwch92](https://github.com/kenwch92)                              | [Printables](https://www.printables.com/model/1505838-over-engineered-display-stand-for-esp32-e-paper-we) |\n    | [Eckerput](https://github.com/Eckerput)                              | [Thingiverse](https://www.thingiverse.com/thing:7112836)                                                  |\n\n  - If you want to share your own 3D printable designs, your contributions are highly encouraged and welcome!\n- Picture Frame\n\n### Solder-Free Component Selection (Optional)\n\nThis project can be completed without any soldering, if you choose your component selection carefully.\n- Buy \"Jumper Wires\" to connect your components.\n- Buy the [FireBeetle 2 ESP32-E w/ Headers](https://www.dfrobot.com/product-2231.html?tracking=PfSxQ8).\n- Buy a BME280 with headers soldered from the factory.\n- Buy a reset switch that is compatible with jumper wires.\n\n\n## Setup Guide\n\n### Wiring\n\nThe battery can be charged by plugging the FireBeetle ESP32 into the wall via the USB-C connector while the battery is plugged into the ESP32's JST connector.\n\n  > **Warning**\n  > The polarity of JST-PH2.0 connectors is not standardized! You may need to swap the order of the wires in the connector.\n\nNOTE: Waveshare now ships revision 2.3 of their e-paper HAT (no longer rev 2.2 ). Rev 2.3 has an additional `PWR` pin (not depicted in the wiring diagrams below); connect this pin to 3.3V.\n\nIMPORTANT: The DESPI-C02 adapter has one physical switch that MUST be set correctly for the display to work.\n\n- RESE: Set switch to position 0.47.\n\nIMPORTANT: The Waveshare E-Paper Driver HAT has two physical switches that MUST be set correctly for the display to work.\n\n- Display Config: Set switch to position B.\n\n- Interface Config: Set switch to position 0.\n\nCut the low power pad for even longer battery life.\n\n- From <https://wiki.dfrobot.com/FireBeetle_Board_ESP32_E_SKU_DFR0654>\n\n  > Low Power Pad: This pad is specially designed for low power consumption. It is connected by default. You can cut off the thin wire in the middle with a knife to disconnect it. After disconnection, the static power consumption can be reduced by 500 ŒºA. The power consumption can be reduced to 13 ŒºA after controlling the maincontroller enter the sleep mode through the program. Note: when the pad is disconnected, you can only drive RGB LED light via the USB Power supply.\n\n![Wiring diagram with DESPI-C02 driver board.](showcase/wiring_diagram_despi-c02.png)\n\n\n### Configuration, Compilation, and Upload\n\nPlatformIO for VSCode is used for managing dependencies, code compilation, and uploading to ESP32.\n\n1. Clone this repository or download and extract the .zip.\n\n2. Install VSCode.\n\n3. Follow these instructions to install the PlatformIO extension for VSCode: <https://platformio.org/install/ide?install=vscode>\n\n4. Open the project in VSCode.\n\n   a. File > Open Folder...\n\n   b. Navigate to this project and select the folder called \"platformio\".\n\n5. Configure Options.\n\n   - Most configuration options are located in [config.cpp](platformio/src/config.cpp), with a few  in [config.h](platformio/include/config.h).\n\n   - Important settings to configure in config.cpp:\n\n     - WiFi credentials (ssid, password).\n\n     - Open Weather Map API key (it's free, see next section for important notes about obtaining an API key).\n\n     - Latitude and longitude.\n\n     - Time and date formats.\n\n     - Sleep duration.\n\n   - Important settings to configure in config.h:\n\n     - Units (Metric or Imperial).\n\n   - Comments explain each option in detail.\n\n6. Build and Upload Code.\n\n   a. Connect ESP32 to your computer via USB.\n\n   b. Click the upload arrow along the bottom of the VSCode window. (Should say \"PlatformIO: Upload\" if you hover over it.)\n\n      - PlatformIO will automatically download the required third-party libraries, compile, and upload the code. :)\n\n      - You will only see this if you have the PlatformIO extension installed.\n\n      - If using a FireBeetle 2 ESP32-E and you receive the error `Wrong boot mode detected (0x13)! The chip needs to be in download mode.` unplug the power from the board, connect GPIO0 ([labeled 0/D5](https://wiki.dfrobot.com/FireBeetle_Board_ESP32_E_SKU_DFR0654#target_5)) to GND, and power it back up to put the board in download mode.\n\n      - If you are getting other errors during the upload process, you may need to install drivers to allow you to upload code to the ESP32.\n\n### OpenWeatherMap API Key\n\nSign up here to get an API key; it's free. <https://openweathermap.org/api>\n\nThis project will make calls to 2 different APIs (\"One Call\" and \"Air Pollution\").\n\n- The One Call API 3.0 is only included in the \"One Call by Call\" subscription. This separate subscription includes 1,000 calls/day for free and allows you to pay only for the number of API calls made to this product.\n\nHere's how to subscribe and avoid any credit card changes:\n   - Go to <https://home.openweathermap.org/subscriptions/billing_info/onecall_30/base?key=base&service=onecall_30>\n   - Follow the instructions to complete the subscription.\n   - Go to <https://home.openweathermap.org/subscriptions> and set the \"Calls per day (no more than)\" to 1,000. This ensures you will never overrun the free calls.\n\n## Error Messages and Troubleshooting\n\n### Low Battery\n<img src=\"showcase/demo-error-low-battery.jpg\" align=\"left\" width=\"25%\" />\nThis error screen appears once the battery voltage has fallen below LOW_BATTERY_VOLTAGE (default = 3.20v). The display will not refresh again until it detects battery voltage above LOW_BATTERY_VOLTAGE. When battery voltage is between LOW_BATTERY_VOLTAGE and VERY_LOW_BATTERY_VOLTAGE (default = 3.10v) the esp32 will deep-sleep for periods of LOW_BATTERY_SLEEP_INTERVAL (default = 30min) before checking battery voltage again. If the battery voltage falls between LOW_BATTERY_SLEEP_INTERVAL and CRIT_LOW_BATTERY_VOLTAGE (default = 3.00v), then the display will deep-sleep for periods VERY_LOW_BATTERY_SLEEP_INTERVAL (default = 120min). If battery voltage falls below CRIT_LOW_BATTERY_VOLTAGE, then the esp32 will enter hibernate mode and will require a manual push of the reset (RST) button to begin updating again.\n\n<br clear=\"left\"/>\n\n### WiFi Connection\n<img src=\"showcase/demo-error-wifi.jpg\" align=\"left\" width=\"25%\" />\nThis error screen appears when the ESP32 fails to connect to WiFi. If the message reads \"WiFi Connection Failed\" this might indicate an incorrect password. If the message reads \"SSID Not Available\" this might indicate that you mistyped the SSID or that the esp32 is out of the range of the access point. The esp32 will retry once every SLEEP_DURATION (default = 30min).\n\n<br clear=\"left\"/>\n\n### API Error\n<img src=\"showcase/demo-error-api.jpg\" align=\"left\" width=\"25%\" />\nThis error screen appears if an error (client or server) occurs when making an API request to OpenWeatherMap. The second line will give the error code followed by a descriptor phrase. Positive error codes correspond to HTTP response status codes, while error codes <= 0 indicate a client(esp32) error. The esp32 will retry once every SLEEP_DURATION (default = 30min).\n<br/><br/>\nIn the example shown to the left, \"401: Unauthorized\" may be the result of an incorrect API key or that you are attempting to use the One Call v3 API without the proper account setup.\n\n<br clear=\"left\"/>\n\n### Time Server Error\n<img src=\"showcase/demo-error-time.jpg\" align=\"left\" width=\"25%\" />\nThis error screen appears when the esp32 fails to fetch the time from NTP_SERVER_1/NTP_SERVER_2. This error sometimes occurs immediately after uploading to the esp32; in this case, just hit the reset button or wait for SLEEP_DURATION (default = 30min) and the esp32 to automatically retry. If the error persists, try selecting closer/lower latency time servers or increasing NTP_TIMEOUT.\n\n<br clear=\"left\"/>\n\n## Licensing\n\nesp32-weather-epd is licensed under the [GNU General Public License v3.0](LICENSE) with tools, fonts, and icons whose licenses are as follows:\n\n| Name | License | Description |\n|---------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------|------------------------------------------------------------------------------------|\n| [Adafruit-GFX-Library: fontconvert](https://github.com/adafruit/Adafruit-GFX-Library/tree/master/fontconvert) | [BSD License](fonts/fontconvert/license.txt) | CLI tool for preprocessing fonts to be used with the Adafruit_GFX Arduino library. |\n| [pollutant-concentration-to-aqi](https://github.com/lmarzen/pollutant-concentration-to-aqi) | [GNU Lesser General Public License v2.1](platformio/lib/pollutant-concentration-to-aqi/LICENSE) | C library that converts pollutant concentrations to Air Quality Index(AQI). |\n| [GNU FreeFont](https://www.gnu.org/software/freefont/) | [GNU General Public License v3.0](https://www.gnu.org/software/freefont/license.html) | Font Family |\n| [Lato](https://fonts.google.com/specimen/Lato) | [SIL OFL v1.1](http://scripts.sil.org/OFL) | Font Family |\n| [Montserrat](https://fonts.google.com/specimen/Montserrat) | [SIL OFL v1.1](http://scripts.sil.org/OFL) | Font Family |\n| [Open Sans](https://fonts.google.com/specimen/Open+Sans) | [SIL OFL v1.1](http://scripts.sil.org/OFL) | Font Family |\n| [Poppins](https://fonts.google.com/specimen/Poppins) | [SIL OFL v1.1](http://scripts.sil.org/OFL) | Font Family |\n| [Quicksand](https://fonts.google.com/specimen/Quicksand) | [SIL OFL v1.1](http://scripts.sil.org/OFL) | Font Family |\n| [Raleway](https://fonts.google.com/specimen/Raleway) | [SIL OFL v1.1](http://scripts.sil.org/OFL) | Font Family |\n| [Roboto](https://fonts.google.com/specimen/Roboto) | [Apache License v2.0](https://www.apache.org/licenses/LICENSE-2.0) | Font Family |\n| [Roboto Mono](https://fonts.google.com/specimen/Roboto+Mono) | [Apache License v2.0](https://www.apache.org/licenses/LICENSE-2.0) | Font Family |\n| [Roboto Slab](https://fonts.google.com/specimen/Roboto+Slab) | [Apache License v2.0](https://www.apache.org/licenses/LICENSE-2.0) | Font Family |\n| [Ubuntu font](https://design.ubuntu.com/font) | [Ubuntu Font Licence v1.0](https://ubuntu.com/legal/font-licence) | Font Family |\n| [Weather Themed Icons](https://github.com/erikflowers/weather-icons) | [SIL OFL v1.1](http://scripts.sil.org/OFL) | (wi-**.svg) Weather icon family by Lukas Bischoff/Erik Flowers. |\n| [Google Icons](https://fonts.google.com/icons) | [Apache License v2.0](https://www.apache.org/licenses/LICENSE-2.0) | (battery**.svg, visibility_icon.svg) Battery and visibility icons from Google Icons. |\n| [Biological Hazard Symbol](https://svgsilh.com/image/37775.html) | [CC0 v1.0](https://en.wikipedia.org/wiki/Public_domain) | (biological_hazard_symbol.svg) Biohazard icon. |\n| [House Icon](https://seekicon.com/free-icon/house_16) | [MIT License](http://opensource.org/licenses/mit-license.html) | (house.svg) House icon. |\n| [Indoor Temerature/Humidity Icons](icons/svg) | [SIL OFL v1.1](http://scripts.sil.org/OFL) | (house_**.svg) Indoor temerature/humidity icons. |\n| [Ionizing Radiation Symbol](https://svgsilh.com/image/309911.html) | [CC0 v1.0](https://creativecommons.org/publicdomain/zero/1.0/) | (ionizing_radiation_symbol.svg) Ionizing radiation icons. |\n| [Phosphor Icons](https://github.com/phosphor-icons/homepage) | [MIT License](http://opensource.org/licenses/mit-license.html) | (wifi**.svg, warning_icon.svg, error_icon.svg) WiFi, Warning, and Error icons from Phosphor Icons. |\n| [Wind Direction Icon](https://www.onlinewebfonts.com/icon/251550) | [CC BY v3.0](http://creativecommons.org/licenses/by/3.0) | (meteorological_wind_direction_**deg.svg) Meteorological wind direction icon from Online Web Fonts. |\n\n",
      "stars_today": 7
    },
    {
      "id": 510342492,
      "name": "client",
      "full_name": "Droid-ify/client",
      "description": "Clutterfree F-Droid client",
      "html_url": "https://github.com/Droid-ify/client",
      "stars": 6235,
      "forks": 161,
      "language": "Kotlin",
      "topics": [
        "android",
        "android-application",
        "fdroid",
        "kotlin",
        "kotlin-android",
        "kotlin-flow"
      ],
      "created_at": "2022-07-04T12:03:15Z",
      "updated_at": "2026-01-23T22:48:22Z",
      "pushed_at": "2026-01-23T19:45:02Z",
      "open_issues": 203,
      "owner": {
        "login": "Droid-ify",
        "avatar_url": "https://avatars.githubusercontent.com/u/123971387?v=4"
      },
      "readme": "<div align=\"center\">\n\n<img width=\"\" src=\"metadata/en-US/images/featureGraphic.png\" alt=\"Droid-ify\" align=\"center\">\n\n> **Clutterfree F-Droid client**\n\n[![GitHub stars](https://img.shields.io/github/stars/Iamlooker/Droid-ify?color=%2359a14f&style=for-the-badge)](https://github.com/Iamlooker/Droid-ify/stargazers)\n[![GitHub downloads](https://img.shields.io/github/downloads/Iamlooker/Droid-ify/total.svg?color=%236f9645&style=for-the-badge)](https://github.com/Iamlooker/Droid-ify/releases/)\n[![GitHub latest release](https://img.shields.io/github/v/release/Iamlooker/Droid-ify?display_name=tag&color=%23d97706&style=for-the-badge)](https://github.com/Iamlooker/Droid-ify/releases/latest)\n[![F-Droid latest release](https://img.shields.io/f-droid/v/com.looker.droidify?color=%23ea9010&style=for-the-badge)](https://f-droid.org/packages/com.looker.droidify)\n</div>\n<div align=\"left\">\n\n<img src=\"metadata/en-US/images/phoneScreenshots/1.png\" width=\"25%\" /><img src=\"metadata/en-US/images/phoneScreenshots/2.png\" width=\"25%\" /><img src=\"metadata/en-US/images/phoneScreenshots/3.png\" width=\"25%\" /><img src=\"metadata/en-US/images/phoneScreenshots/4.png\" width=\"25%\" />\n\n* Browse and install apps from F-Droid repositories\n* Automatic app updates in the background\n* Multiple installation methods (Session, Root, Shizuku)\n* Add custom repositories with one tap\n* Works completely offline after initial sync\n\n### Get Started\n\n**Download**: [GitHub Releases](https://github.com/Iamlooker/Droid-ify/releases/latest) ‚Ä¢ [F-Droid](https://f-droid.org/packages/com.looker.droidify)\n\n**Signature:**\n```\nED:88:59:C5:5A:F3:11:16:26:58:B9:4A:F9:82:B9:F0:91:DC:D2:76:28:D4:DE:34:86:D1:21:7E:BF:3C:99:35\n```\n\n> [!IMPORTANT]\n> Signature for older versions on F-Droid might be different\n\n**Build**: See [Building Guide](docs/building.md) for development setup\n\n### Contributing\n\n**Want to help?** Check out our [Contributing Guide](CONTRIBUTING.md)\n\n### Translations\n\n[![Translation status](https://hosted.weblate.org/widgets/droidify/-/horizontal-auto.svg)](https://hosted.weblate.org/engage/droidify/?utm_source=widget)\n\n### License\n\n```\nDroid-ify\n\nCopyright (C) 2025 LooKeR\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n```\n\n</div>\n",
      "stars_today": 7
    },
    {
      "id": 930678258,
      "name": "kubernetes-mcp-server",
      "full_name": "containers/kubernetes-mcp-server",
      "description": "Model Context Protocol (MCP) server for Kubernetes and OpenShift",
      "html_url": "https://github.com/containers/kubernetes-mcp-server",
      "stars": 1029,
      "forks": 231,
      "language": "Go",
      "topics": [
        "containers",
        "context",
        "kubernetes",
        "kubernetes-mcp",
        "mcp",
        "model",
        "modelcontextprotocol",
        "openshift",
        "protocol"
      ],
      "created_at": "2025-02-11T02:57:36Z",
      "updated_at": "2026-01-23T16:18:05Z",
      "pushed_at": "2026-01-23T16:18:01Z",
      "open_issues": 59,
      "owner": {
        "login": "containers",
        "avatar_url": "https://avatars.githubusercontent.com/u/5874934?v=4"
      },
      "readme": "# Kubernetes MCP Server\n\n[![GitHub License](https://img.shields.io/github/license/containers/kubernetes-mcp-server)](https://github.com/containers/kubernetes-mcp-server/blob/main/LICENSE)\n[![npm](https://img.shields.io/npm/v/kubernetes-mcp-server)](https://www.npmjs.com/package/kubernetes-mcp-server)\n[![PyPI - Version](https://img.shields.io/pypi/v/kubernetes-mcp-server)](https://pypi.org/project/kubernetes-mcp-server/)\n[![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/containers/kubernetes-mcp-server?sort=semver)](https://github.com/containers/kubernetes-mcp-server/releases/latest)\n[![Build](https://github.com/containers/kubernetes-mcp-server/actions/workflows/build.yaml/badge.svg)](https://github.com/containers/kubernetes-mcp-server/actions/workflows/build.yaml)\n\n[‚ú® Features](#features) | [üöÄ Getting Started](#getting-started) | [üé• Demos](#demos) | [‚öôÔ∏è Configuration](#configuration) | [üõ†Ô∏è Tools](#tools-and-functionalities) | [üßë‚Äçüíª Development](#development)\n\nhttps://github.com/user-attachments/assets/be2b67b3-fc1c-4d11-ae46-93deba8ed98e\n\n## ‚ú® Features <a id=\"features\"></a>\n\nA powerful and flexible Kubernetes [Model Context Protocol (MCP)](https://blog.marcnuri.com/model-context-protocol-mcp-introduction) server implementation with support for **Kubernetes** and **OpenShift**.\n\n- **‚úÖ Configuration**:\n  - Automatically detect changes in the Kubernetes configuration and update the MCP server.\n  - **View** and manage the current [Kubernetes `.kube/config`](https://blog.marcnuri.com/where-is-my-default-kubeconfig-file) or in-cluster configuration.\n- **‚úÖ Generic Kubernetes Resources**: Perform operations on **any** Kubernetes or OpenShift resource.\n  - Any CRUD operation (Create or Update, Get, List, Delete).\n- **‚úÖ Pods**: Perform Pod-specific operations.\n  - **List** pods in all namespaces or in a specific namespace.\n  - **Get** a pod by name from the specified namespace.\n  - **Delete** a pod by name from the specified namespace.\n  - **Show logs** for a pod by name from the specified namespace.\n  - **Top** gets resource usage metrics for all pods or a specific pod in the specified namespace.\n  - **Exec** into a pod and run a command.\n  - **Run** a container image in a pod and optionally expose it.\n- **‚úÖ Namespaces**: List Kubernetes Namespaces.\n- **‚úÖ Events**: View Kubernetes events in all namespaces or in a specific namespace.\n- **‚úÖ Projects**: List OpenShift Projects.\n- **‚ò∏Ô∏è Helm**:\n  - **Install** a Helm chart in the current or provided namespace.\n  - **List** Helm releases in all namespaces or in a specific namespace.\n  - **Uninstall** a Helm release in the current or provided namespace.\n- **üî≠ Observability**: Optional OpenTelemetry distributed tracing and metrics with custom sampling rates. Includes `/stats` endpoint for real-time statistics. See [OTEL.md](docs/OTEL.md).\n\nUnlike other Kubernetes MCP server implementations, this **IS NOT** just a wrapper around `kubectl` or `helm` command-line tools.\nIt is a **Go-based native implementation** that interacts directly with the Kubernetes API server.\n\nThere is **NO NEED** for external dependencies or tools to be installed on the system.\nIf you're using the native binaries you don't need to have Node or Python installed on your system.\n\n- **‚úÖ Lightweight**: The server is distributed as a single native binary for Linux, macOS, and Windows.\n- **‚úÖ High-Performance / Low-Latency**: Directly interacts with the Kubernetes API server without the overhead of calling and waiting for external commands.\n- **‚úÖ Multi-Cluster**: Can interact with multiple Kubernetes clusters simultaneously (as defined in your kubeconfig files).\n- **‚úÖ Cross-Platform**: Available as a native binary for Linux, macOS, and Windows, as well as an npm package, a Python package, and container/Docker image.\n- **‚úÖ Configurable**: Supports [command-line arguments](#configuration)  to configure the server behavior.\n- **‚úÖ Well tested**: The server has an extensive test suite to ensure its reliability and correctness across different Kubernetes environments.\n\n## üöÄ Getting Started <a id=\"getting-started\"></a>\n\n### Requirements\n\n- Access to a Kubernetes cluster.\n\n<details>\n<summary><b>Claude Code</b></summary>\n\nFollow the [dedicated Claude Code getting started guide](docs/GETTING_STARTED_CLAUDE_CODE.md) in our [user documentation](docs/).\n\nFor a secure production setup with dedicated ServiceAccount and read-only access, also review the [Kubernetes setup guide](docs/GETTING_STARTED_KUBERNETES.md).\n\n</details>\n\n### Claude Desktop\n\n#### Using npx\n\nIf you have npm installed, this is the fastest way to get started with `kubernetes-mcp-server` on Claude Desktop.\n\nOpen your `claude_desktop_config.json` and add the mcp server to the list of `mcpServers`:\n``` json\n{\n  \"mcpServers\": {\n    \"kubernetes\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"kubernetes-mcp-server@latest\"\n      ]\n    }\n  }\n}\n```\n\n### VS Code / VS Code Insiders\n\nInstall the Kubernetes MCP server extension in VS Code Insiders by pressing the following link:\n\n[<img src=\"https://img.shields.io/badge/VS_Code-VS_Code?style=flat-square&label=Install%20Server&color=0098FF\" alt=\"Install in VS Code\">](https://insiders.vscode.dev/redirect?url=vscode%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522kubernetes%2522%252C%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522-y%2522%252C%2522kubernetes-mcp-server%2540latest%2522%255D%257D)\n[<img alt=\"Install in VS Code Insiders\" src=\"https://img.shields.io/badge/VS_Code_Insiders-VS_Code_Insiders?style=flat-square&label=Install%20Server&color=24bfa5\">](https://insiders.vscode.dev/redirect?url=vscode-insiders%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522kubernetes%2522%252C%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522-y%2522%252C%2522kubernetes-mcp-server%2540latest%2522%255D%257D)\n\nAlternatively, you can install the extension manually by running the following command:\n\n```shell\n# For VS Code\ncode --add-mcp '{\"name\":\"kubernetes\",\"command\":\"npx\",\"args\":[\"kubernetes-mcp-server@latest\"]}'\n# For VS Code Insiders\ncode-insiders --add-mcp '{\"name\":\"kubernetes\",\"command\":\"npx\",\"args\":[\"kubernetes-mcp-server@latest\"]}'\n```\n\n### Cursor\n\nInstall the Kubernetes MCP server extension in Cursor by pressing the following link:\n\n[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/en/install-mcp?name=kubernetes-mcp-server&config=eyJjb21tYW5kIjoibnB4IC15IGt1YmVybmV0ZXMtbWNwLXNlcnZlckBsYXRlc3QifQ%3D%3D)\n\nAlternatively, you can install the extension manually by editing the `mcp.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"kubernetes-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"kubernetes-mcp-server@latest\"]\n    }\n  }\n}\n```\n\n### Goose CLI\n\n[Goose CLI](https://blog.marcnuri.com/goose-on-machine-ai-agent-cli-introduction) is the easiest (and cheapest) way to get rolling with artificial intelligence (AI) agents.\n\n#### Using npm\n\nIf you have npm installed, this is the fastest way to get started with `kubernetes-mcp-server`.\n\nOpen your goose `config.yaml` and add the mcp server to the list of `mcpServers`:\n```yaml\nextensions:\n  kubernetes:\n    command: npx\n    args:\n      - -y\n      - kubernetes-mcp-server@latest\n\n```\n\n## üé• Demos <a id=\"demos\"></a>\n\n### Diagnosing and automatically fixing an OpenShift Deployment\n\nDemo showcasing how Kubernetes MCP server is leveraged by Claude Desktop to automatically diagnose and fix a deployment in OpenShift without any user assistance.\n\nhttps://github.com/user-attachments/assets/a576176d-a142-4c19-b9aa-a83dc4b8d941\n\n### _Vibe Coding_ a simple game and deploying it to OpenShift\n\nIn this demo, I walk you through the process of _Vibe Coding_ a simple game using VS Code and how to leverage [Podman MCP server](https://github.com/manusa/podman-mcp-server) and Kubernetes MCP server to deploy it to OpenShift.\n\n<a href=\"https://www.youtube.com/watch?v=l05jQDSrzVI\" target=\"_blank\">\n <img src=\"docs/images/vibe-coding.jpg\" alt=\"Vibe Coding: Build & Deploy a Game on Kubernetes\" width=\"240\"  />\n</a>\n\n### Supercharge GitHub Copilot with Kubernetes MCP Server in VS Code - One-Click Setup!\n\nIn this demo, I'll show you how to set up Kubernetes MCP server in VS code just by clicking a link.\n\n<a href=\"https://youtu.be/AI4ljYMkgtA\" target=\"_blank\">\n <img src=\"docs/images/kubernetes-mcp-server-github-copilot.jpg\" alt=\"Supercharge GitHub Copilot with Kubernetes MCP Server in VS Code - One-Click Setup!\" width=\"240\"  />\n</a>\n\n## ‚öôÔ∏è Configuration <a id=\"configuration\"></a>\n\nThe Kubernetes MCP server can be configured using command line (CLI) arguments.\n\nYou can run the CLI executable either by using `npx`, `uvx`, or by downloading the [latest release binary](https://github.com/containers/kubernetes-mcp-server/releases/latest).\n\n```shell\n# Run the Kubernetes MCP server using npx (in case you have npm and node installed)\nnpx kubernetes-mcp-server@latest --help\n```\n\n```shell\n# Run the Kubernetes MCP server using uvx (in case you have uv and python installed)\nuvx kubernetes-mcp-server@latest --help\n```\n\n```shell\n# Run the Kubernetes MCP server using the latest release binary\n./kubernetes-mcp-server --help\n```\n\n### Configuration Options\n\n| Option                    | Description                                                                                                                                                                                                                                                                                   |\n|---------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `--port`                  | Starts the MCP server in Streamable HTTP mode (path /mcp) and Server-Sent Event (SSE) (path /sse) mode and listens on the specified port .                                                                                                                                                    |\n| `--log-level`             | Sets the logging level (values [from 0-9](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-instrumentation/logging.md)). Similar to [kubectl logging levels](https://kubernetes.io/docs/reference/kubectl/quick-reference/#kubectl-output-verbosity-and-debugging). |\n| `--config`                | (Optional) Path to the main TOML configuration file. See [Drop-in Configuration](#drop-in-configuration) section below for details.                                                                                                                                                           |\n| `--config-dir`            | (Optional) Path to drop-in configuration directory. Files are loaded in lexical (alphabetical) order. Defaults to `conf.d` relative to the main config file if `--config` is specified. See [Drop-in Configuration](#drop-in-configuration) section below for details.                        |\n| `--kubeconfig`            | Path to the Kubernetes configuration file. If not provided, it will try to resolve the configuration (in-cluster, default location, etc.).                                                                                                                                                    |\n| `--list-output`           | Output format for resource list operations (one of: yaml, table) (default \"table\")                                                                                                                                                                                                            |\n| `--read-only`             | If set, the MCP server will run in read-only mode, meaning it will not allow any write operations (create, update, delete) on the Kubernetes cluster. This is useful for debugging or inspecting the cluster without making changes.                                                          |\n| `--disable-destructive`   | If set, the MCP server will disable all destructive operations (delete, update, etc.) on the Kubernetes cluster. This is useful for debugging or inspecting the cluster without accidentally making changes. This option has no effect when `--read-only` is used.                            |\n| `--stateless`             | If set, the MCP server will run in stateless mode, disabling tool and prompt change notifications. This is useful for container deployments, load balancing, and serverless environments where maintaining client state is not desired.                                                       |\n| `--toolsets`              | Comma-separated list of toolsets to enable. Check the [üõ†Ô∏è Tools and Functionalities](#tools-and-functionalities) section for more information.                                                                                                                                                |\n| `--disable-multi-cluster` | If set, the MCP server will disable multi-cluster support and will only use the current context from the kubeconfig file. This is useful if you want to restrict the MCP server to a single cluster.                                                                                          |\n| `--cluster-provider`.     | Cluster provider strategy to use (one of: kubeconfig, in-cluster, kcp, disabled). If not set, the server will auto-detect based on the environment.                                                                                                                                           |\n\n### Drop-in Configuration <a id=\"drop-in-configuration\"></a>\n\nThe Kubernetes MCP server supports flexible configuration through both a main config file and drop-in files. **Both are optional** - you can use either, both, or neither (server will use built-in defaults).\n\n#### Configuration Loading Order\n\nConfiguration values are loaded and merged in the following order (later sources override earlier ones):\n\n1. **Internal Defaults** - Always loaded (hardcoded default values)\n2. **Main Configuration File** - Optional, loaded via `--config` flag\n3. **Drop-in Files** - Optional, loaded from `--config-dir` in **lexical (alphabetical) order**\n\n#### How Drop-in Files Work\n\n- **Default Directory**: If `--config-dir` is not specified, the server looks for drop-in files in `conf.d/` relative to the main config file's directory (when `--config` is provided)\n- **File Naming**: Use numeric prefixes to control loading order (e.g., `00-base.toml`, `10-cluster.toml`, `99-override.toml`)\n- **File Extension**: Only `.toml` files are processed; dotfiles (starting with `.`) are ignored\n- **Partial Configuration**: Drop-in files can contain only a subset of configuration options\n- **Merge Behavior**: Values present in a drop-in file override previous values; missing values are preserved\n\n#### Dynamic Configuration Reload\n\nTo reload configuration after modifying config files, send a `SIGHUP` signal to the running server process.\n\n**Prerequisite**: SIGHUP reload requires the server to be started with either the `--config` flag or `--config-dir` flag (or both). If neither is specified, SIGHUP signals will be ignored.\n\n**How to reload:**\n\n```shell\n# Find the process ID\nps aux | grep kubernetes-mcp-server\n\n# Send SIGHUP to reload configuration\nkill -HUP <pid>\n\n# Or use pkill\npkill -HUP kubernetes-mcp-server\n```\n\nThe server will:\n- Reload the main config file and all drop-in files\n- Update configuration values (log level, output format, etc.)\n- Rebuild the toolset registry with new tool configurations\n- Log the reload status\n\n**Note**: Changing `kubeconfig` or cluster-related settings requires a server restart. Only tool configurations, log levels, and output formats can be reloaded dynamically.\n\n**Note**: SIGHUP reload is not available on Windows. On Windows, restart the server to reload configuration.\n\n#### Example: Using Both Config Methods\n\n**Command (using default `conf.d` directory):**\n```shell\nkubernetes-mcp-server --config /etc/kubernetes-mcp-server/config.toml\n```\n\n**Directory structure:**\n```\n/etc/kubernetes-mcp-server/\n‚îú‚îÄ‚îÄ config.toml              # Main configuration\n‚îî‚îÄ‚îÄ conf.d/                  # Default drop-in directory (automatically loaded)\n    ‚îú‚îÄ‚îÄ 00-base.toml         # Base overrides\n    ‚îú‚îÄ‚îÄ 10-toolsets.toml     # Toolset-specific config\n    ‚îî‚îÄ‚îÄ 99-local.toml        # Local overrides\n```\n\n**Command (with explicit `--config-dir`):**\n```shell\nkubernetes-mcp-server --config /etc/kubernetes-mcp-server/config.toml \\\n                      --config-dir /etc/kubernetes-mcp-server/config.d/\n```\n\n**Example drop-in file** (`10-toolsets.toml`):\n```toml\n# Override only the toolsets - all other config preserved\ntoolsets = [\"core\", \"config\", \"helm\", \"logs\"]\n```\n\n**Example drop-in file** (`99-local.toml`):\n```toml\n# Local development overrides\nlog_level = 9\nread_only = true\n```\n\n**To apply changes:**\n```shell\n# Edit config files\nvim /etc/kubernetes-mcp-server/conf.d/99-local.toml\n\n# Reload without restarting\npkill -HUP kubernetes-mcp-server\n```\n\n### MCP Prompts\n\n1. The server supports MCP prompts for workflow templates. Define custom prompts in `config.toml`:\n\n```toml\n[[prompts]]\nname = \"my-workflow\"\ntitle = \"my workflow\"\ndescription = \"Custom workflow\"\n\n[[prompts.arguments]]\nname = \"resource_name\"\nrequired = true\n\n[[prompts.messages]]\nrole = \"user\"\ncontent = \"Help me with {{resource_name}}\"\n```\n\n2. Toolset prompts implemented by toolset developers\n\nSee docs/PROMPTS.md for detailed documentation.\n\n## üìä MCP Logging <a id=\"mcp-logging\"></a>\n\nThe server supports the MCP logging capability, allowing clients to receive debugging information via structured log messages.\n\n### For Clients\n\nClients can control log verbosity by sending a `logging/setLevel` request:\n\n```json\n{\n  \"method\": \"logging/setLevel\",\n  \"params\": { \"level\": \"info\" }\n}\n```\n\n**Available log levels** (in order of increasing severity):\n- `debug` - Detailed debugging information\n- `info` - General informational messages (default)\n- `notice` - Normal but significant events\n- `warning` - Warning messages\n- `error` - Error conditions\n- `critical` - Critical conditions\n- `alert` - Action must be taken immediately\n- `emergency` - System is unusable\n\n### For Developers\n\nToolsets can optionally send debug information to clients using helper functions from the `mcplog` package:\n\n**Recommended approach for Kubernetes errors** (automatically categorizes errors and sends appropriate messages):\n\n```go\nimport \"github.com/containers/kubernetes-mcp-server/pkg/mcplog\"\n\n// In your tool handler:\nret, err := client.CoreV1().Pods(namespace).Get(ctx, name, metav1.GetOptions{})\nif err != nil {\n    mcplog.HandleK8sError(ctx, err, \"pod access\")\n    return api.NewToolCallResult(\"\", fmt.Errorf(\"failed to get pod: %v\", err)), nil\n}\n```\n\n**Manual logging** (for custom messages):\n\n```go\nimport \"github.com/containers/kubernetes-mcp-server/pkg/mcplog\"\n\n// In your tool handler:\nif err != nil {\n    mcplog.SendMCPLog(ctx, \"error\", \"Operation failed - check permissions\")\n    return api.NewToolCallResult(\"\", err)\n}\n```\n\n**Key Points:**\n- Logging is **optional** - toolsets work fine without sending MCP logs\n- Uses a dedicated named logger (`logger=\"mcp\"`) for complete separation from server logs\n- Server logs (klog) remain detailed and unaffected\n- Client logs are high-level, helpful hints for debugging\n- Authentication failures send generic messages to clients (no security info leaked)\n- Sensitive data is automatically redacted with 28 pattern types:\n  - Generic fields (password, token, secret, api_key, etc.)\n  - Authorization headers (Bearer, Basic)\n  - Cloud credentials (AWS, GCP, Azure)\n  - API tokens (GitHub, GitLab, OpenAI, Anthropic)\n  - Cryptographic keys (JWT, SSH, PGP, RSA)\n  - Database connection strings (PostgreSQL, MySQL, MongoDB)\n\n## üõ†Ô∏è Tools and Functionalities <a id=\"tools-and-functionalities\"></a>\n\nThe Kubernetes MCP server supports enabling or disabling specific groups of tools and functionalities (tools, resources, prompts, and so on) via the `--toolsets` command-line flag or `toolsets` configuration option.\nThis allows you to control which Kubernetes functionalities are available to your AI tools.\nEnabling only the toolsets you need can help reduce the context size and improve the LLM's tool selection accuracy.\n\n### Available Toolsets\n\nThe following sets of tools are available (toolsets marked with ‚úì in the Default column are enabled by default):\n\n<!-- AVAILABLE-TOOLSETS-START -->\n\n| Toolset  | Description                                                                                                                                                          | Default |\n|----------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------|\n| config   | View and manage the current local Kubernetes configuration (kubeconfig)                                                                                              | ‚úì       |\n| core     | Most common tools for Kubernetes management (Pods, Generic Resources, Events, etc.)                                                                                  | ‚úì       |\n| kcp      | Manage kcp workspaces and multi-tenancy features                                                                                                                     |         |\n| kiali    | Most common tools for managing Kiali, check the [Kiali documentation](https://github.com/containers/kubernetes-mcp-server/blob/main/docs/KIALI.md) for more details. |         |\n| kubevirt | KubeVirt virtual machine management tools                                                                                                                            |         |\n| helm     | Tools for managing Helm charts and releases                                                                                                                          | ‚úì       |\n\n<!-- AVAILABLE-TOOLSETS-END -->\n\n### Tools\n\nIn case multi-cluster support is enabled (default) and you have access to multiple clusters, all applicable tools will include an additional `context` argument to specify the Kubernetes context (cluster) to use for that operation.\n\n<!-- AVAILABLE-TOOLSETS-TOOLS-START -->\n\n<details>\n\n<summary>config</summary>\n\n- **configuration_contexts_list** - List all available context names and associated server urls from the kubeconfig file\n\n- **targets_list** - List all available targets\n\n- **configuration_view** - Get the current Kubernetes configuration content as a kubeconfig YAML\n  - `minified` (`boolean`) - Return a minified version of the configuration. If set to true, keeps only the current-context and the relevant pieces of the configuration for that context. If set to false, all contexts, clusters, auth-infos, and users are returned in the configuration. (Optional, default true)\n\n</details>\n\n<details>\n\n<summary>core</summary>\n\n- **events_list** - List all the Kubernetes events in the current cluster from all namespaces\n  - `namespace` (`string`) - Optional Namespace to retrieve the events from. If not provided, will list events from all namespaces\n\n- **namespaces_list** - List all the Kubernetes namespaces in the current cluster\n\n- **projects_list** - List all the OpenShift projects in the current cluster\n\n- **nodes_log** - Get logs from a Kubernetes node (kubelet, kube-proxy, or other system logs). This accesses node logs through the Kubernetes API proxy to the kubelet\n  - `name` (`string`) **(required)** - Name of the node to get logs from\n  - `query` (`string`) **(required)** - query specifies services(s) or files from which to return logs (required). Example: \"kubelet\" to fetch kubelet logs, \"/<log-file-name>\" to fetch a specific log file from the node (e.g., \"/var/log/kubelet.log\" or \"/var/log/kube-proxy.log\")\n  - `tailLines` (`integer`) - Number of lines to retrieve from the end of the logs (Optional, 0 means all logs)\n\n- **nodes_stats_summary** - Get detailed resource usage statistics from a Kubernetes node via the kubelet's Summary API. Provides comprehensive metrics including CPU, memory, filesystem, and network usage at the node, pod, and container levels. On systems with cgroup v2 and kernel 4.20+, also includes PSI (Pressure Stall Information) metrics that show resource pressure for CPU, memory, and I/O. See https://kubernetes.io/docs/reference/instrumentation/understand-psi-metrics/ for details on PSI metrics\n  - `name` (`string`) **(required)** - Name of the node to get stats from\n\n- **nodes_top** - List the resource consumption (CPU and memory) as recorded by the Kubernetes Metrics Server for the specified Kubernetes Nodes or all nodes in the cluster\n  - `label_selector` (`string`) - Kubernetes label selector (e.g. 'node-role.kubernetes.io/worker=') to filter nodes by label (Optional, only applicable when name is not provided)\n  - `name` (`string`) - Name of the Node to get the resource consumption from (Optional, all Nodes if not provided)\n\n- **pods_list** - List all the Kubernetes pods in the current cluster from all namespaces\n  - `fieldSelector` (`string`) - Optional Kubernetes field selector to filter pods by field values (e.g. 'status.phase=Running', 'spec.nodeName=node1'). Supported fields: metadata.name, metadata.namespace, spec.nodeName, spec.restartPolicy, spec.schedulerName, spec.serviceAccountName, status.phase (Pending/Running/Succeeded/Failed/Unknown), status.podIP, status.nominatedNodeName. Note: CrashLoopBackOff is a container state, not a pod phase, so it cannot be filtered directly. See https://kubernetes.io/docs/concepts/overview/working-with-objects/field-selectors/\n  - `labelSelector` (`string`) - Optional Kubernetes label selector (e.g. 'app=myapp,env=prod' or 'app in (myapp,yourapp)'), use this option when you want to filter the pods by label\n\n- **pods_list_in_namespace** - List all the Kubernetes pods in the specified namespace in the current cluster\n  - `fieldSelector` (`string`) - Optional Kubernetes field selector to filter pods by field values (e.g. 'status.phase=Running', 'spec.nodeName=node1'). Supported fields: metadata.name, metadata.namespace, spec.nodeName, spec.restartPolicy, spec.schedulerName, spec.serviceAccountName, status.phase (Pending/Running/Succeeded/Failed/Unknown), status.podIP, status.nominatedNodeName. Note: CrashLoopBackOff is a container state, not a pod phase, so it cannot be filtered directly. See https://kubernetes.io/docs/concepts/overview/working-with-objects/field-selectors/\n  - `labelSelector` (`string`) - Optional Kubernetes label selector (e.g. 'app=myapp,env=prod' or 'app in (myapp,yourapp)'), use this option when you want to filter the pods by label\n  - `namespace` (`string`) **(required)** - Namespace to list pods from\n\n- **pods_get** - Get a Kubernetes Pod in the current or provided namespace with the provided name\n  - `name` (`string`) **(required)** - Name of the Pod\n  - `namespace` (`string`) - Namespace to get the Pod from\n\n- **pods_delete** - Delete a Kubernetes Pod in the current or provided namespace with the provided name\n  - `name` (`string`) **(required)** - Name of the Pod to delete\n  - `namespace` (`string`) - Namespace to delete the Pod from\n\n- **pods_top** - List the resource consumption (CPU and memory) as recorded by the Kubernetes Metrics Server for the specified Kubernetes Pods in the all namespaces, the provided namespace, or the current namespace\n  - `all_namespaces` (`boolean`) - If true, list the resource consumption for all Pods in all namespaces. If false, list the resource consumption for Pods in the provided namespace or the current namespace\n  - `label_selector` (`string`) - Kubernetes label selector (e.g. 'app=myapp,env=prod' or 'app in (myapp,yourapp)'), use this option when you want to filter the pods by label (Optional, only applicable when name is not provided)\n  - `name` (`string`) - Name of the Pod to get the resource consumption from (Optional, all Pods in the namespace if not provided)\n  - `namespace` (`string`) - Namespace to get the Pods resource consumption from (Optional, current namespace if not provided and all_namespaces is false)\n\n- **pods_exec** - Execute a command in a Kubernetes Pod in the current or provided namespace with the provided name and command\n  - `command` (`array`) **(required)** - Command to execute in the Pod container. The first item is the command to be run, and the rest are the arguments to that command. Example: [\"ls\", \"-l\", \"/tmp\"]\n  - `container` (`string`) - Name of the Pod container where the command will be executed (Optional)\n  - `name` (`string`) **(required)** - Name of the Pod where the command will be executed\n  - `namespace` (`string`) - Namespace of the Pod where the command will be executed\n\n- **pods_log** - Get the logs of a Kubernetes Pod in the current or provided namespace with the provided name\n  - `container` (`string`) - Name of the Pod container to get the logs from (Optional)\n  - `name` (`string`) **(required)** - Name of the Pod to get the logs from\n  - `namespace` (`string`) - Namespace to get the Pod logs from\n  - `previous` (`boolean`) - Return previous terminated container logs (Optional)\n  - `tail` (`integer`) - Number of lines to retrieve from the end of the logs (Optional, default: 100)\n\n- **pods_run** - Run a Kubernetes Pod in the current or provided namespace with the provided container image and optional name\n  - `image` (`string`) **(required)** - Container Image to run in the Pod\n  - `name` (`string`) - Name of the Pod (Optional, random name if not provided)\n  - `namespace` (`string`) - Namespace to run the Pod in\n  - `port` (`number`) - TCP/IP port to expose from the Pod container (Optional, no port exposed if not provided)\n\n- **resources_list** - List Kubernetes resources and objects in the current cluster by providing their apiVersion and kind and optionally the namespace and label selector\n(common apiVersion and kind include: v1 Pod, v1 Service, v1 Node, apps/v1 Deployment, networking.k8s.io/v1 Ingress, route.openshift.io/v1 Route)\n  - `apiVersion` (`string`) **(required)** - apiVersion of the resources (examples of valid apiVersion are: v1, apps/v1, networking.k8s.io/v1)\n  - `fieldSelector` (`string`) - Optional Kubernetes field selector to filter resources by field values (e.g. 'status.phase=Running', 'metadata.name=myresource'). Supported fields vary by resource type. For Pods: metadata.name, metadata.namespace, spec.nodeName, spec.restartPolicy, spec.schedulerName, spec.serviceAccountName, status.phase (Pending/Running/Succeeded/Failed/Unknown), status.podIP, status.nominatedNodeName. See https://kubernetes.io/docs/concepts/overview/working-with-objects/field-selectors/\n  - `kind` (`string`) **(required)** - kind of the resources (examples of valid kind are: Pod, Service, Deployment, Ingress)\n  - `labelSelector` (`string`) - Optional Kubernetes label selector (e.g. 'app=myapp,env=prod' or 'app in (myapp,yourapp)'), use this option when you want to filter the resources by label\n  - `namespace` (`string`) - Optional Namespace to retrieve the namespaced resources from (ignored in case of cluster scoped resources). If not provided, will list resources from all namespaces\n\n- **resources_get** - Get a Kubernetes resource in the current cluster by providing its apiVersion, kind, optionally the namespace, and its name\n(common apiVersion and kind include: v1 Pod, v1 Service, v1 Node, apps/v1 Deployment, networking.k8s.io/v1 Ingress, route.openshift.io/v1 Route)\n  - `apiVersion` (`string`) **(required)** - apiVersion of the resource (examples of valid apiVersion are: v1, apps/v1, networking.k8s.io/v1)\n  - `kind` (`string`) **(required)** - kind of the resource (examples of valid kind are: Pod, Service, Deployment, Ingress)\n  - `name` (`string`) **(required)** - Name of the resource\n  - `namespace` (`string`) - Optional Namespace to retrieve the namespaced resource from (ignored in case of cluster scoped resources). If not provided, will get resource from configured namespace\n\n- **resources_create_or_update** - Create or update a Kubernetes resource in the current cluster by providing a YAML or JSON representation of the resource\n(common apiVersion and kind include: v1 Pod, v1 Service, v1 Node, apps/v1 Deployment, networking.k8s.io/v1 Ingress, route.openshift.io/v1 Route)\n  - `resource` (`string`) **(required)** - A JSON or YAML containing a representation of the Kubernetes resource. Should include top-level fields such as apiVersion,kind,metadata, and spec\n\n- **resources_delete** - Delete a Kubernetes resource in the current cluster by providing its apiVersion, kind, optionally the namespace, and its name\n(common apiVersion and kind include: v1 Pod, v1 Service, v1 Node, apps/v1 Deployment, networking.k8s.io/v1 Ingress, route.openshift.io/v1 Route)\n  - `apiVersion` (`string`) **(required)** - apiVersion of the resource (examples of valid apiVersion are: v1, apps/v1, networking.k8s.io/v1)\n  - `kind` (`string`) **(required)** - kind of the resource (examples of valid kind are: Pod, Service, Deployment, Ingress)\n  - `name` (`string`) **(required)** - Name of the resource\n  - `namespace` (`string`) - Optional Namespace to delete the namespaced resource from (ignored in case of cluster scoped resources). If not provided, will delete resource from configured namespace\n\n- **resources_scale** - Get or update the scale of a Kubernetes resource in the current cluster by providing its apiVersion, kind, name, and optionally the namespace. If the scale is set in the tool call, the scale will be updated to that value. Always returns the current scale of the resource\n  - `apiVersion` (`string`) **(required)** - apiVersion of the resource (examples of valid apiVersion are apps/v1)\n  - `kind` (`string`) **(required)** - kind of the resource (examples of valid kind are: StatefulSet, Deployment)\n  - `name` (`string`) **(required)** - Name of the resource\n  - `namespace` (`string`) - Optional Namespace to get/update the namespaced resource scale from (ignored in case of cluster scoped resources). If not provided, will get/update resource scale from configured namespace\n  - `scale` (`integer`) - Optional scale to update the resources scale to. If not provided, will return the current scale of the resource, and not update it\n\n</details>\n\n<details>\n\n<summary>kcp</summary>\n\n- **kcp_workspaces_list** - List all available kcp workspaces in the current cluster\n\n- **kcp_workspace_describe** - Get detailed information about a specific kcp workspace\n  - `workspace` (`string`) **(required)** - Name or path of the workspace to describe\n\n</details>\n\n<details>\n\n<summary>kiali</summary>\n\n- **kiali_mesh_graph** - Returns the topology of a specific namespaces, health, status of the mesh and namespaces. Includes a mesh health summary overview with aggregated counts of healthy, degraded, and failing apps, workloads, and services. Use this for high-level overviews\n  - `graphType` (`string`) - Optional type of graph to return: 'versionedApp', 'app', 'service', 'workload', 'mesh'\n  - `namespace` (`string`) - Optional single namespace to include in the graph (alternative to namespaces)\n  - `namespaces` (`string`) - Optional comma-separated list of namespaces to include in the graph\n  - `rateInterval` (`string`) - Optional rate interval for fetching (e.g., '10m', '5m', '1h').\n\n- **kiali_manage_istio_config** - Manages Istio configuration objects (Gateways, VirtualServices, etc.). Can list (objects and validations), get, create, patch, or delete objects\n  - `action` (`string`) **(required)** - Action to perform: list, get, create, patch, or delete\n  - `group` (`string`) - API group of the Istio object (e.g., 'networking.istio.io', 'gateway.networking.k8s.io')\n  - `json_data` (`string`) - JSON data to apply or create the object\n  - `kind` (`string`) - Kind of the Istio object (e.g., 'DestinationRule', 'VirtualService', 'HTTPRoute', 'Gateway')\n  - `name` (`string`) - Name of the Istio object\n  - `namespace` (`string`) - Namespace containing the Istio object\n  - `version` (`string`) - API version of the Istio object (e.g., 'v1', 'v1beta1')\n\n- **kiali_get_resource_details** - Gets lists or detailed info for Kubernetes resources (services, workloads) within the mesh\n  - `namespaces` (`string`) - Comma-separated list of namespaces to get services from (e.g. 'bookinfo' or 'bookinfo,default'). If not provided, will list services from all accessible namespaces\n  - `resource_name` (`string`) - Name of the resource to get details for (optional string - if provided, gets details; if empty, lists all).\n  - `resource_type` (`string`) - Type of resource to get details for (service, workload)\n\n- **kiali_get_metrics** - Gets lists or detailed info for Kubernetes resources (services, workloads) within the mesh\n  - `byLabels` (`string`) - Comma-separated list of labels to group metrics by (e.g., 'source_workload,destination_service'). Optional\n  - `direction` (`string`) - Traffic direction: 'inbound' or 'outbound'. Optional, defaults to 'outbound'\n  - `duration` (`string`) - Time range to get metrics for (optional string - if provided, gets metrics (e.g., '1m', '5m', '1h'); if empty, get default 30m).\n  - `namespace` (`string`) **(required)** - Namespace to get resources from\n  - `quantiles` (`string`) - Comma-separated list of quantiles for histogram metrics (e.g., '0.5,0.95,0.99'). Optional\n  - `rateInterval` (`string`) - Rate interval for metrics (e.g., '1m', '5m'). Optional, defaults to '10m'\n  - `reporter` (`string`) - Metrics reporter: 'source', 'destination', or 'both'. Optional, defaults to 'source'\n  - `requestProtocol` (`string`) - Filter by request protocol (e.g., 'http', 'grpc', 'tcp'). Optional\n  - `resource_name` (`string`) **(required)** - Name of the resource to get details for (optional string - if provided, gets details; if empty, lists all).\n  - `resource_type` (`string`) **(required)** - Type of resource to get details for (service, workload)\n  - `step` (`string`) - Step between data points in seconds (e.g., '15'). Optional, defaults to 15 seconds\n\n- **kiali_workload_logs** - Get logs for a specific workload's pods in a namespace. Only requires namespace and workload name - automatically discovers pods and containers. Optionally filter by container name, time range, and other parameters. Container is auto-detected if not specified.\n  - `container` (`string`) - Optional container name to filter logs. If not provided, automatically detects and uses the main application container (excludes istio-proxy and istio-init)\n  - `namespace` (`string`) **(required)** - Namespace containing the workload\n  - `since` (`string`) - Time duration to fetch logs from (e.g., '5m', '1h', '30s'). If not provided, returns recent logs\n  - `tail` (`integer`) - Number of lines to retrieve from the end of logs (default: 100)\n  - `workload` (`string`) **(required)** - Name of the workload to get logs for\n\n- **kiali_get_traces** - Gets traces for a specific resource (app, service, workload) in a namespace, or gets detailed information for a specific trace by its ID. If traceId is provided, it returns detailed trace information and other parameters are not required.\n  - `clusterName` (`string`) - Cluster name for multi-cluster environments (optional, only used when traceId is not provided)\n  - `endMicros` (`string`) - End time for traces in microseconds since epoch (optional, defaults to 10 minutes after startMicros if not provided, only used when traceId is not provided)\n  - `limit` (`integer`) - Maximum number of traces to return (default: 100, only used when traceId is not provided)\n  - `minDuration` (`integer`) - Minimum trace duration in microseconds (optional, only used when traceId is not provided)\n  - `namespace` (`string`) - Namespace to get resources from. Required if traceId is not provided.\n  - `resource_name` (`string`) - Name of the resource to get traces for. Required if traceId is not provided.\n  - `resource_type` (`string`) - Type of resource to get traces for (app, service, workload). Required if traceId is not provided.\n  - `startMicros` (`string`) - Start time for traces in microseconds since epoch (optional, defaults to 10 minutes before current time if not provided, only used when traceId is not provided)\n  - `tags` (`string`) - JSON string of tags to filter traces (optional, only used when traceId is not provided)\n  - `traceId` (`string`) - Unique identifier of the trace to retrieve detailed information for. If provided, this will return detailed trace information and other parameters (resource_type, namespace, resource_name) are not required.\n\n</details>\n\n<details>\n\n<summary>kubevirt</summary>\n\n- **vm_create** - Create a VirtualMachine in the cluster with the specified configuration, automatically resolving instance types, preferences, and container disk images. VM will be created in Halted state by default; use autostart parameter to start it immediately.\n  - `autostart` (`boolean`) - Optional flag to automatically start the VM after creation (sets runStrategy to Always instead of Halted). Defaults to false.\n  - `instancetype` (`string`) - Optional instance type name for the VM (e.g., 'u1.small', 'u1.medium', 'u1.large')\n  - `name` (`string`) **(required)** - The name of the virtual machine\n  - `namespace` (`string`) **(required)** - The namespace for the virtual machine\n  - `performance` (`string`) - Optional performance family hint for the VM instance type (e.g., 'u1' for general-purpose, 'o1' for overcommitted, 'c1' for compute-optimized, 'm1' for memory-optimized). Defaults to 'u1' (general-purpose) if not specified.\n  - `preference` (`string`) - Optional preference name for the VM\n  - `size` (`string`) - Optional workload size hint for the VM (e.g., 'small', 'medium', 'large', 'xlarge'). Used to auto-select an appropriate instance type if not explicitly specified.\n  - `storage` (`string`) - Optional storage size for the VM's root disk when using DataSources (e.g., '30Gi', '50Gi', '100Gi'). Defaults to 30Gi. Ignored when using container disks.\n  - `workload` (`string`) - The workload for the VM. Accepts OS names (e.g., 'fedora' (default), 'ubuntu', 'centos', 'centos-stream', 'debian', 'rhel', 'opensuse', 'opensuse-tumbleweed', 'opensuse-leap') or full container disk image URLs\n\n- **vm_lifecycle** - Manage VirtualMachine lifecycle: start, stop, or restart a VM\n  - `action` (`string`) **(required)** - The lifecycle action to perform: 'start' (changes runStrategy to Always), 'stop' (changes runStrategy to Halted), or 'restart' (stops then starts the VM)\n  - `name` (`string`) **(required)** - The name of the virtual machine\n  - `namespace` (`string`) **(required)** - The namespace of the virtual machine\n\n</details>\n\n<details>\n\n<summary>helm</summary>\n\n- **helm_install** - Install a Helm chart in the current or provided namespace\n  - `chart` (`string`) **(required)** - Chart reference to install (for example: stable/grafana, oci://ghcr.io/nginxinc/charts/nginx-ingress)\n  - `name` (`string`) - Name of the Helm release (Optional, random name if not provided)\n  - `namespace` (`string`) - Namespace to install the Helm chart in (Optional, current namespace if not provided)\n  - `values` (`object`) - Values to pass to the Helm chart (Optional)\n\n- **helm_list** - List all the Helm releases in the current or provided namespace (or in all namespaces if specified)\n  - `all_namespaces` (`boolean`) - If true, lists all Helm releases in all namespaces ignoring the namespace argument (Optional)\n  - `namespace` (`string`) - Namespace to list Helm releases from (Optional, all namespaces if not provided)\n\n- **helm_uninstall** - Uninstall a Helm release in the current or provided namespace\n  - `name` (`string`) **(required)** - Name of the Helm release to uninstall\n  - `namespace` (`string`) - Namespace to uninstall the Helm release from (Optional, current namespace if not provided)\n\n</details>\n\n\n<!-- AVAILABLE-TOOLSETS-TOOLS-END -->\n\n## Helm Chart\n\nA [Helm Chart](https://helm.sh) is available to simplify the deployment of the Kubernetes MCP server. Additional details can be found in the [chart README](./charts/kubernetes-mcp-server/README.md).\n\n## üßë‚Äçüíª Development <a id=\"development\"></a>\n\n### Running with mcp-inspector\n\nCompile the project and run the Kubernetes MCP server with [mcp-inspector](https://modelcontextprotocol.io/docs/tools/inspector) to inspect the MCP server.\n\n```shell\n# Compile the project\nmake build\n# Run the Kubernetes MCP server with mcp-inspector\nnpx @modelcontextprotocol/inspector@latest $(pwd)/kubernetes-mcp-server\n```\n\n---\n\nmcp-name: io.github.containers/kubernetes-mcp-server",
      "stars_today": 7
    },
    {
      "id": 943421085,
      "name": "nixl",
      "full_name": "ai-dynamo/nixl",
      "description": "NVIDIA Inference Xfer Library (NIXL)",
      "html_url": "https://github.com/ai-dynamo/nixl",
      "stars": 843,
      "forks": 228,
      "language": "C++",
      "topics": [],
      "created_at": "2025-03-05T17:20:28Z",
      "updated_at": "2026-01-24T01:08:31Z",
      "pushed_at": "2026-01-23T20:02:28Z",
      "open_issues": 127,
      "owner": {
        "login": "ai-dynamo",
        "avatar_url": "https://avatars.githubusercontent.com/u/201626793?v=4"
      },
      "readme": "<!--\nSPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\nSPDX-License-Identifier: Apache-2.0\n-->\n\n# NVIDIA Inference Xfer Library (NIXL)\n\nNVIDIA Inference Xfer Library (NIXL) is targeted for accelerating point to point communications in AI inference frameworks such as NVIDIA Dynamo, while providing an abstraction over various types of memory (e.g., CPU and GPU) and storage (e.g., file, block and object store) through a modular plug-in architecture.\n\n[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n[![GitHub Release](https://img.shields.io/github/v/release/ai-dynamo/nixl)](https://github.com/ai-dynamo/nixl/releases/latest)\n\n## Documentation and Resources\n\n* [NIXL overview](https://github.com/ai-dynamo/nixl/blob/main/docs/nixl.md) - Core concepts/architecture overview (`docs/nixl.md`)\n\n* [Python API](https://github.com/ai-dynamo/nixl/blob/main/docs/python_api.md) - Python API usage and examples (`docs/python_api.md`)\n\n* [Backend guide](https://github.com/ai-dynamo/nixl/blob/main/docs/BackendGuide.md) - Backend/plugin development guide (`docs/BackendGuide.md`)\n\n* [Telemetry](https://github.com/ai-dynamo/nixl/blob/main/docs/telemetry.md) - Observability and telemetry details (`docs/telemetry.md`)\n\n* [Doxygen guide](https://github.com/ai-dynamo/nixl/blob/main/docs/doxygen/nixl_doxygen.md) - API/class diagrams overview (`docs/doxygen/nixl_doxygen.md`)\n\n* [Doxygen images](https://github.com/ai-dynamo/nixl/tree/main/docs/doxygen) - Diagram assets (`docs/doxygen/`)\n\n* [NIXLBench docs](https://github.com/ai-dynamo/nixl/blob/main/benchmark/nixlbench/README.md) - Benchmark usage guide (`benchmark/nixlbench/README.md`)\n\n* [KVBench docs](https://github.com/ai-dynamo/nixl/tree/main/benchmark/kvbench/docs) - KVBench workflows and tutorials (`benchmark/kvbench/docs/`)\n\n## Supported Platforms\nNIXL is supported on a Linux environment only. It is tested on Ubuntu (22.04/24.04) and Fedora. macOS and Windows are not currently supported; use a Linux host or container/VM.\n\n## Pre-build Distributions\n### PyPI Wheel\n\nThe nixl python API and libraries, including UCX, are available directly through PyPI.\nFor example, if you have a GPU running on a Linux host, container, or VM, you can do the following install:\n\nIt can be installed for CUDA 12 with:\n\n```\npip install nixl[cu12]\n```\n\nFor CUDA 13 with:\n\n```\npip install nixl[cu13]\n```\n\nFor backwards compatibility, `pip install nixl` installs automatically `nixl[cu12]`, continuing to work seamlessly for CUDA 12 users without requiring changes to downstream project dependencies.\n\nIf both `nixl-cu12` and `nixl-cu13` are installed at the same time in an environment, `nixl-cu13` takes precedence.\n\n## Prerequisites for source build (Linux)\n### Ubuntu:\n\n`$ sudo apt install build-essential cmake pkg-config`\n\n### Fedora:\n\n`$ sudo dnf install gcc-c++ cmake pkg-config`\n\n### Python\n\n`$ pip3 install meson ninja pybind11 tomlkit`\n\n### UCX\n\nNIXL was tested with UCX version 1.20.x.\n\n[GDRCopy](https://github.com/NVIDIA/gdrcopy) is available on Github and is necessary for maximum performance, but UCX and NIXL will work without it.\n\n```\n$ git clone https://github.com/openucx/ucx.git\n$ cd ucx\n$ git checkout v1.20.x\n$ ./autogen.sh\n$ ./contrib/configure-release-mt       \\\n    --enable-shared                    \\\n    --disable-static                   \\\n    --disable-doxygen-doc              \\\n    --enable-optimizations             \\\n    --enable-cma                       \\\n    --enable-devel-headers             \\\n    --with-cuda=<cuda install>         \\\n    --with-verbs                       \\\n    --with-dm                          \\\n    --with-gdrcopy=<gdrcopy install>\n$ make -j\n$ make -j install-strip\n$ ldconfig\n```\n\n### ETCD (Optional)\nNIXL can use ETCD for metadata distribution and coordination between nodes in distributed environments. To use ETCD with NIXL:\n#### ETCD Server and Client\n ```\n$ sudo apt install etcd etcd-server etcd-client\n\n# Or use Docker\n$ docker run -d -p 2379:2379 quay.io/coreos/etcd:v3.5.1\n```\n\n#### ETCD CPP API\nInstalled from https://github.com/etcd-cpp-apiv3/etcd-cpp-apiv3\n\n```\n$ sudo apt install libgrpc-dev libgrpc++-dev libprotobuf-dev protobuf-compiler-grpc\n$ sudo apt install libcpprest-dev\n$ git clone https://github.com/etcd-cpp-apiv3/etcd-cpp-apiv3.git\n$ cd etcd-cpp-apiv3\n$ mkdir build && cd build\n$ cmake ..\n$ make -j$(nproc) && make install\n```\n\n### Additional plugins\n\nSome plugins may have additional build requirements, see them here:\n\n- [Mooncake](src/plugins/mooncake/README.md)\n- [POSIX](src/plugins/posix/README.md)\n- [GDS](src/plugins/cuda_gds/README.md)\n\n## Getting started\n### Build & install\n\n```\n$ meson setup <name_of_build_dir>\n$ cd <name_of_build_dir>\n$ ninja\n$ ninja install\n```\n\n### Build Options\n\n#### Release build (default)\n\n```bash\n$ meson setup <name_of_build_dir>\n```\n\n#### Debug build\n\n```bash\n$ meson setup <name_of_build_dir> --buildtype=debug\n```\n\n#### NIXL-specific build options\n\n```bash\n# Example with custom options\n$ meson setup <name_of_build_dir> \\\n    -Dbuild_docs=true \\           # Build Doxygen documentation\n    -Ducx_path=/path/to/ucx \\     # Custom UCX installation path\n    -Dinstall_headers=true \\      # Install development headers\n    -Ddisable_gds_backend=false   # Enable GDS backend\n```\n\nCommon build options:\n- `build_docs`: Build Doxygen documentation (default: false)\n- `ucx_path`: Path to UCX installation (default: system path)\n- `install_headers`: Install development headers (default: true)\n- `disable_gds_backend`: Disable GDS backend (default: false)\n- `cudapath_inc`, `cudapath_lib`: Custom CUDA paths\n- `static_plugins`: Comma-separated list of plugins to build statically\n- `enable_plugins`: Comma-separated list of plugins to build (e.g. `-Denable_plugins=UCX,POSIX`). Cannot be used with `disable_plugins`.\n- `disable_plugins`: Comma-separated list of plugins to exclude (e.g. `-Ddisable_plugins=GDS`). Cannot be used with `enable_plugins`.\n\n#### Environment Variables\n\nThere are a few environment variables that can be set to configure the build:\n- `NIXL_NO_STUBS_FALLBACK`: If not set or 0, build NIXL stub library if the library build fails\n\n### Building Documentation\n\nIf you have Doxygen installed, you can build the documentation:\n\n```bash\n# Configure with documentation enabled\n$ meson setup <name_of_build_dir> -Dbuild_docs=true\n$ cd <name_of_build_dir>\n$ ninja\n\n# Documentation will be generated in <name_of_build_dir>/html\n# After installation (ninja install), documentation will be available in <prefix>/share/doc/nixl/\n```\n\n### Python Interface\n\nNIXL provides Python bindings through pybind11. For detailed Python API documentation, see [docs/python_api.md](docs/python_api.md).\n\nThe preferred way to install the Python bindings is through pip from PyPI:\n\n```bash\npip install nixl[cu12]\n```\n\nOr for CUDA 13 with:\n\n```bash\npip install nixl[cu13]\n```\n\nTo build and install the Python bindings from source, you have to build and install separately the platform-specific package and the `nixl` meta-package:\n\nOn CUDA 12:\n\n```\npip install .\nmeson setup build\nninja -C build\npip install build/src/bindings/python/nixl-meta/nixl-*-py3-none-any.whl\n```\n\nOn CUDA 13:\n\n```\npip install .\n./contrib/tomlutil.py --wheel-name nixl-cu13 pyproject.toml\nmeson setup build\nninja -C build\npip install build/src/bindings/python/nixl-meta/nixl-*-py3-none-any.whl\n```\n\nFor Python examples, see [examples/python/](examples/python/).\n\n### Rust Bindings\n#### Build\n- Use `-Drust=true` meson option to build rust bindings.\n- Use `--buildtype=debug` for a debug build (default is release).\n- Or build manually:\n    ```bash\n    $ cargo build --release\n    ```\n#### Install\nThe bindings will be installed under `nixl-sys` in the configured installation prefix.\nCan be done using ninja, from project build directory:\n```bash\n$ ninja install\n```\n\n#### Test\n```\n# Rust bindings tests\n$ cargo test\n```\n\nUse in your project by adding to `Cargo.toml`:\n```toml\n[dependencies]\nnixl-sys = { path = \"path/to/nixl/bindings/rust\" }\n```\n\n### Other build options\nSee [contrib/README.md](contrib/README.md) for more build options.\n\n### Building Docker container\nTo build the docker container, first clone the current repository. Also make sure you are able to pull docker images to your machine before attempting to build the container.\n\nRun the following from the root folder of the cloned NIXL repository:\n```\n$ ./contrib/build-container.sh\n```\n\nBy default, the container is built with Ubuntu 24.04. To build a container for Ubuntu 22.04 use the --os option as follows:\n```\n$ ./contrib/build-container.sh --os ubuntu22\n```\n\nTo see all the options supported by the container use:\n```\n$ ./contrib/build-container.sh -h\n```\n\nThe container also includes a prebuilt python wheel in /workspace/dist if required for installing/distributing. Also, the wheel can be built with a separate script (see below).\n\n### Building the python wheel\nThe contrib folder also includes a script to build the python wheel with the UCX dependencies. Note, that UCX and other NIXL dependencies are required to be installed.\n```\n$ ./contrib/build-wheel.sh\n```\n\n## Running with ETCD\nNIXL can use ETCD for metadata exchange between distributed nodes. This is especially useful in containerized or cloud-native environments.\n\n### Environment Setup\nTo use ETCD with NIXL, set the following environment variables:\n\n```bash\n# Set ETCD endpoints (required) - replace localhost with the hostname of the etcd server\nexport NIXL_ETCD_ENDPOINTS=\"http://localhost:2379\"\n\n# Set ETCD namespace (optional, defaults to /nixl/agents)\nexport NIXL_ETCD_NAMESPACE=\"/nixl/agents\"\n```\n\n### Running the ETCD Example\nNIXL includes an example demonstrating metadata exchange and data transfer using ETCD:\n\n```bash\n# Start an ETCD server if not already running\n# For example:\n# docker run -d -p 2379:2379 quay.io/coreos/etcd:v3.5.1\n\n# Set the ETCD env variables as above\n\n# Run the example. The two agents in the example will exchange metadata through ETCD\n# and perform data transfers\n./<nixl_build_path>/examples/nixl_etcd_example\n```\n\n### nixlbench Benchmark\nFor more comprehensive testing, the nixlbench benchmarking tool supports ETCD for worker coordination:\n\n```bash\n# Build nixlbench (see benchmark/nixlbench/README.md for details)\ncd benchmark/nixlbench\nmeson setup build && cd build && ninja\n\n# Run benchmark with ETCD\n./nixlbench --etcd-endpoints http://localhost:2379 --backend UCX --initiator_seg_type VRAM\n```\n\n## Code Examples\n\n* [C++ examples](https://github.com/ai-dynamo/nixl/tree/main/examples/cpp)\n\n* [Python examples](https://github.com/ai-dynamo/nixl/tree/main/examples/python)\n\n## Contributing\n\nFor contribution guidelines, see [CONTRIBUTING.md](https://github.com/ai-dynamo/nixl/blob/main/CONTRIBUTING.md) (`CONTRIBUTING.md`).\n\n## Third-Party Components\n\nThis project will download and install additional third-party open source software projects. Review the license terms of these open source projects before use.\n",
      "stars_today": 7
    },
    {
      "id": 1663468,
      "name": "pdf.js",
      "full_name": "mozilla/pdf.js",
      "description": "PDF Reader in JavaScript",
      "html_url": "https://github.com/mozilla/pdf.js",
      "stars": 52713,
      "forks": 10570,
      "language": "JavaScript",
      "topics": [],
      "created_at": "2011-04-26T06:32:03Z",
      "updated_at": "2026-01-23T20:09:16Z",
      "pushed_at": "2026-01-23T19:49:20Z",
      "open_issues": 504,
      "owner": {
        "login": "mozilla",
        "avatar_url": "https://avatars.githubusercontent.com/u/131524?v=4"
      },
      "readme": "# PDF.js [![CI](https://github.com/mozilla/pdf.js/actions/workflows/ci.yml/badge.svg?query=branch%3Amaster)](https://github.com/mozilla/pdf.js/actions/workflows/ci.yml?query=branch%3Amaster)\n\n[PDF.js](https://mozilla.github.io/pdf.js/) is a Portable Document Format (PDF) viewer that is built with HTML5.\n\nPDF.js is community-driven and supported by Mozilla. Our goal is to\ncreate a general-purpose, web standards-based platform for parsing and\nrendering PDFs.\n\n## Contributing\n\nPDF.js is an open source project and always looking for more contributors. To\nget involved, visit:\n\n+ [Issue Reporting Guide](https://github.com/mozilla/pdf.js/blob/master/.github/CONTRIBUTING.md)\n+ [Code Contribution Guide](https://github.com/mozilla/pdf.js/wiki/Contributing)\n+ [Frequently Asked Questions](https://github.com/mozilla/pdf.js/wiki/Frequently-Asked-Questions)\n+ [Good Beginner Bugs](https://github.com/mozilla/pdf.js/issues?q=is%3Aissue%20state%3Aopen%20label%3Agood-beginner-bug)\n+ [Projects](https://github.com/mozilla/pdf.js/projects)\n\nFeel free to stop by our [Matrix room](https://chat.mozilla.org/#/room/#pdfjs:mozilla.org) for questions or guidance.\n\n## Getting Started\n\n### Online demo\n\nPlease note that the \"Modern browsers\" version assumes native support for the\nlatest JavaScript features; please also see [this wiki page](https://github.com/mozilla/pdf.js/wiki/Frequently-Asked-Questions#faq-support).\n\n+ Modern browsers: https://mozilla.github.io/pdf.js/web/viewer.html\n\n+ Older browsers: https://mozilla.github.io/pdf.js/legacy/web/viewer.html\n\n### Browser Extensions\n\n#### Firefox\n\nPDF.js is built into version 19+ of Firefox.\n\n#### Chrome\n\n+ The official extension for Chrome can be installed from the [Chrome Web Store](https://chrome.google.com/webstore/detail/pdf-viewer/oemmndcbldboiebfnladdacbdfmadadm).\n*This extension is maintained by [@Rob--W](https://github.com/Rob--W).*\n+ Build Your Own - Get the code as explained below and issue `npx gulp chromium`. Then open\nChrome, go to `Tools > Extension` and load the (unpackaged) extension from the\ndirectory `build/chromium`.\n\n## Getting the Code\n\nTo get a local copy of the current code, clone it using git:\n\n    $ git clone https://github.com/mozilla/pdf.js.git\n    $ cd pdf.js\n\nNext, install Node.js via the [official package](https://nodejs.org) or via\n[nvm](https://github.com/creationix/nvm). If everything worked out, install\nall dependencies for PDF.js:\n\n    $ npm install\n\nFinally, you need to start a local web server as some browsers do not allow opening\nPDF files using a `file://` URL. Run:\n\n    $ npx gulp server\n\nand then you can open:\n\n+ http://localhost:8888/web/viewer.html\n\nPlease keep in mind that this assumes the latest version of Mozilla Firefox; refer to [Building PDF.js](https://github.com/mozilla/pdf.js/blob/master/README.md#building-pdfjs) for non-development usage of the PDF.js library.\n\nIt is also possible to view all test PDF files on the right side by opening:\n\n+ http://localhost:8888/test/pdfs/?frame\n\n## Building PDF.js\n\nIn order to bundle all `src/` files into two production scripts and build the generic\nviewer, run:\n\n    $ npx gulp generic\n\nIf you need to support older browsers, run:\n\n    $ npx gulp generic-legacy\n\nThis will generate `pdf.js` and `pdf.worker.js` in the `build/generic/build/` directory (respectively `build/generic-legacy/build/`).\nBoth scripts are needed but only `pdf.js` needs to be included since `pdf.worker.js` will\nbe loaded by `pdf.js`. The PDF.js files are large and should be minified for production.\n\n## Using PDF.js in a web application\n\nTo use PDF.js in a web application you can choose to use a pre-built version of the library\nor to build it from source. We supply pre-built versions for usage with NPM under\nthe `pdfjs-dist` name. For more information and examples please refer to the\n[wiki page](https://github.com/mozilla/pdf.js/wiki/Setup-pdf.js-in-a-website) on this subject.\n\n## Including via a CDN\n\nPDF.js is hosted on several free CDNs:\n - https://www.jsdelivr.com/package/npm/pdfjs-dist\n - https://cdnjs.com/libraries/pdf.js\n - https://unpkg.com/pdfjs-dist/\n\n## Learning\n\nYou can play with the PDF.js API directly from your browser using the live demos below:\n\n+ [Interactive examples](https://mozilla.github.io/pdf.js/examples/index.html#interactive-examples)\n\nMore examples can be found in the [examples folder](https://github.com/mozilla/pdf.js/tree/master/examples/). Some of them are using the pdfjs-dist package, which can be built and installed in this repo directory via `npx gulp dist-install` command.\n\nFor an introduction to the PDF.js code, check out the presentation by our\ncontributor Julian Viereck:\n\n+ https://www.youtube.com/watch?v=Iv15UY-4Fg8\n\nMore learning resources can be found at:\n\n+ https://github.com/mozilla/pdf.js/wiki/Additional-Learning-Resources\n\nThe API documentation can be found at:\n\n+ https://mozilla.github.io/pdf.js/api/\n\n## Questions\n\nCheck out our FAQs and get answers to common questions:\n\n+ https://github.com/mozilla/pdf.js/wiki/Frequently-Asked-Questions\n\nTalk to us on Matrix:\n\n+ https://chat.mozilla.org/#/room/#pdfjs:mozilla.org\n\nFile an issue:\n\n+ https://github.com/mozilla/pdf.js/issues/new/choose\n",
      "stars_today": 6
    },
    {
      "id": 16587283,
      "name": "xgboost",
      "full_name": "dmlc/xgboost",
      "description": "Scalable, Portable and Distributed Gradient Boosting (GBDT, GBRT or GBM) Library,  for Python, R, Java, Scala, C++ and more. Runs on single machine, Hadoop, Spark, Dask, Flink and DataFlow",
      "html_url": "https://github.com/dmlc/xgboost",
      "stars": 27898,
      "forks": 8833,
      "language": "C++",
      "topics": [
        "distributed-systems",
        "gbdt",
        "gbm",
        "gbrt",
        "machine-learning",
        "xgboost"
      ],
      "created_at": "2014-02-06T17:28:03Z",
      "updated_at": "2026-01-23T22:36:04Z",
      "pushed_at": "2026-01-23T17:26:32Z",
      "open_issues": 497,
      "owner": {
        "login": "dmlc",
        "avatar_url": "https://avatars.githubusercontent.com/u/11508361?v=4"
      },
      "readme": "<img src=\"https://xgboost.ai/images/logo/xgboost-logo-trimmed.png\" width=200/> eXtreme Gradient Boosting\n===========\n\n[![XGBoost-CI](https://github.com/dmlc/xgboost/workflows/XGBoost%20CI/badge.svg?branch=master)](https://github.com/dmlc/xgboost/actions)\n[![Documentation Status](https://readthedocs.org/projects/xgboost/badge/?version=latest)](https://xgboost.readthedocs.org)\n[![GitHub license](https://dmlc.github.io/img/apache2.svg)](./LICENSE)\n[![CRAN Status Badge](https://www.r-pkg.org/badges/version/xgboost)](https://cran.r-project.org/web/packages/xgboost)\n[![PyPI version](https://badge.fury.io/py/xgboost.svg)](https://pypi.python.org/pypi/xgboost/)\n[![Conda version](https://img.shields.io/conda/vn/conda-forge/py-xgboost.svg)](https://anaconda.org/conda-forge/py-xgboost)\n[![Optuna](https://img.shields.io/badge/Optuna-integrated-blue)](https://optuna.org)\n[![Twitter](https://img.shields.io/badge/@XGBoostProject--_.svg?style=social&logo=twitter)](https://twitter.com/XGBoostProject)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/dmlc/xgboost/badge)](https://api.securityscorecards.dev/projects/github.com/dmlc/xgboost)\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/comet-examples/blob/master/integrations/model-training/xgboost/notebooks/how_to_use_comet_with_xgboost_tutorial.ipynb)\n\n[Community](https://xgboost.ai/community) |\n[Documentation](https://xgboost.readthedocs.org) |\n[Resources](demo/README.md) |\n[Contributors](CONTRIBUTORS.md) |\n[Release Notes](https://xgboost.readthedocs.io/en/latest/changes/index.html)\n\nXGBoost is an optimized distributed gradient boosting library designed to be highly ***efficient***, ***flexible*** and ***portable***.\nIt implements machine learning algorithms under the [Gradient Boosting](https://en.wikipedia.org/wiki/Gradient_boosting) framework.\nXGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way.\nThe same code runs on major distributed environment (Kubernetes, Hadoop, SGE, Dask, Spark, PySpark) and can solve problems beyond billions of examples.\n\nLicense\n-------\n¬© Contributors, 2021. Licensed under an [Apache-2](https://github.com/dmlc/xgboost/blob/master/LICENSE) license.\n\nContribute to XGBoost\n---------------------\nXGBoost has been developed and used by a group of active community members. Your help is very valuable to make the package better for everyone.\nCheckout the [Community Page](https://xgboost.ai/community).\n\nReference\n---------\n- Tianqi Chen and Carlos Guestrin. [XGBoost: A Scalable Tree Boosting System](https://arxiv.org/abs/1603.02754). In 22nd SIGKDD Conference on Knowledge Discovery and Data Mining, 2016\n- XGBoost originates from research project at University of Washington.\n\nSponsors\n--------\nBecome a sponsor and get a logo here. See details at [Sponsoring the XGBoost Project](https://xgboost.ai/sponsors). The funds are used to defray the cost of continuous integration and testing infrastructure (https://xgboost-ci.net).\n\n## Open Source Collective sponsors\n[![Backers on Open Collective](https://opencollective.com/xgboost/backers/badge.svg)](#backers) [![Sponsors on Open Collective](https://opencollective.com/xgboost/sponsors/badge.svg)](#sponsors)\n\n### Sponsors\n[[Become a sponsor](https://opencollective.com/xgboost#sponsor)]\n\n<a href=\"https://www.nvidia.com/en-us/\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/xgboost-ai/xgboost-ai.github.io/master/images/sponsors/nvidia.jpg\" alt=\"NVIDIA\" width=\"72\" height=\"72\"></a>\n<a href=\"https://www.comet.com/site/?utm_source=xgboost&utm_medium=github&utm_content=readme\" target=\"_blank\"><img src=\"https://cdn.comet.ml/img/notebook_logo.png\" height=\"72\"></a>\n<a href=\"https://opencollective.com/tomislav1\" target=\"_blank\"><img src=\"https://images.opencollective.com/tomislav1/avatar/256.png\" height=\"72\"></a>\n<a href=\"https://databento.com/?utm_source=xgboost&utm_medium=sponsor&utm_content=display\"><img src=\"https://raw.githubusercontent.com/xgboost-ai/xgboost-ai.github.io/refs/heads/master/images/sponsors/databento.png\" height=\"72\"></a>\n<a href=\"https://www.intel.com/\" target=\"_blank\"><img src=\"https://images.opencollective.com/intel-corporation/2fa85c1/logo/256.png\" width=\"72\" height=\"72\"></a>\n\n### Backers\n[[Become a backer](https://opencollective.com/xgboost#backer)]\n\n<a href=\"https://opencollective.com/xgboost#backers\" target=\"_blank\"><img src=\"https://opencollective.com/xgboost/backers.svg?width=890\"></a>\n",
      "stars_today": 6
    },
    {
      "id": 75277003,
      "name": "thingsboard",
      "full_name": "thingsboard/thingsboard",
      "description": "Open-source IoT Platform - Device management, data collection, processing and visualization.",
      "html_url": "https://github.com/thingsboard/thingsboard",
      "stars": 20980,
      "forks": 6057,
      "language": "Java",
      "topics": [
        "cloud",
        "coap",
        "dashboard",
        "iot",
        "iot-analytics",
        "iot-platform",
        "iot-solutions",
        "java",
        "kafka",
        "lwm2m",
        "microservices",
        "middleware",
        "mqtt",
        "netty",
        "platform",
        "snmp",
        "thingsboard",
        "visualization",
        "websockets",
        "widgets"
      ],
      "created_at": "2016-12-01T09:33:30Z",
      "updated_at": "2026-01-23T22:06:15Z",
      "pushed_at": "2026-01-23T14:38:23Z",
      "open_issues": 167,
      "owner": {
        "login": "thingsboard",
        "avatar_url": "https://avatars.githubusercontent.com/u/24291394?v=4"
      },
      "readme": "![banner](https://github.com/user-attachments/assets/3584b592-33dd-4fb4-91d4-47b62b34806c)\n\n<div align=\"center\">\n\n# Open-source IoT platform for data collection, processing, visualization, and device management.\n\n</div>\n<br>\n<div align=\"center\">\n \nüí° [Get started](https://thingsboard.io/docs/getting-started-guides/helloworld/)&ensp;‚Ä¢&ensp;üåê [Website](https://thingsboard.io/)&ensp;‚Ä¢&ensp;üìö [Documentation](https://thingsboard.io/docs/)&ensp;‚Ä¢&ensp;üìî [Blog](https://thingsboard.io/blog/)&ensp;‚Ä¢&ensp;‚ñ∂Ô∏è [Live demo](https://demo.thingsboard.io/signup)&ensp;‚Ä¢&ensp;üîó [LinkedIn](https://www.linkedin.com/company/thingsboard/posts/?feedView=all)\n\n</div>\n\n## üöÄ Installation options\n\n* Install ThingsBoard [On-premise](https://thingsboard.io/docs/user-guide/install/installation-options/?ceInstallType=onPremise)\n* Try [ThingsBoard Cloud](https://thingsboard.io/installations/)\n* or [Use our Live demo](https://demo.thingsboard.io/signup)\n\n## üí° Getting started with ThingsBoard\n\nCheck out our [Getting Started guide](https://thingsboard.io/docs/getting-started-guides/helloworld/) or [watch the video](https://www.youtube.com/watch?v=80L0ubQLXsc) to learn the basics of ThingsBoard and create your first dashboard! You will learn to:\n\n* Connect devices to ThingsBoard\n* Push data from devices to ThingsBoard\n* Build real-time dashboards\n* Create a Customer and assign the dashboard with them.\n* Define thresholds and trigger alarms\n* Set up notifications via email, SMS, mobile apps, or integrate with third-party services.\n\n## ‚ú® Features\n\n<table>\n  <tr>\n    <td width=\"50%\" valign=\"top\">\n      <br>\n      <div align=\"center\">\n        <img src=\"https://github.com/user-attachments/assets/255cca4f-b111-44e8-99ea-0af55f8e3681\" alt=\"Provision and manage devices and assets\" width=\"378\" />\n        <h3>Provision and manage <br> devices and assets</h3>\n      </div>\n      <div align=\"center\">\n        <p>Provision, monitor and control your IoT entities in secure way using rich server-side APIs. Define relations between your devices, assets, customers or any other entities.</p>\n      </div>\n      <br>\n      <div align=\"center\">\n        <a href=\"https://thingsboard.io/docs/user-guide/entities-and-relations/\">Read more ‚ûú</a>\n      </div>\n      <br>\n    </td>\n    <td width=\"50%\" valign=\"top\">\n      <br>\n      <div align=\"center\">\n        <img src=\"https://github.com/user-attachments/assets/24b41d10-150a-42dd-ab1a-32ac9b5978c1\" alt=\"Collect and visualize your data\" width=\"378\" />\n        <h3>Collect and visualize <br> your data</h3>\n      </div>\n      <div align=\"center\">\n        <p>Collect and store telemetry data in scalable and fault-tolerant way. Visualize your data with built-in or custom widgets and flexible dashboards. Share dashboards with your customers.</p>\n      </div>\n      <br>\n      <div align=\"center\">\n        <a href=\"https://thingsboard.io/iot-data-visualization/\">Read more ‚ûú</a>\n      </div>\n      <br>\n    </td>\n  </tr>\n  <tr>\n    <td width=\"50%\" valign=\"top\">\n      <br>\n      <div align=\"center\">\n        <img src=\"https://github.com/user-attachments/assets/6f2a6dd2-7b33-4d17-8b92-d1f995adda2c\" alt=\"SCADA Dashboards\" width=\"378\" />\n        <h3>SCADA Dashboards</h3>\n      </div>\n      <div align=\"center\">\n        <p>Monitor and control your industrial processes in real time with SCADA. Use SCADA symbols on dashboards to create and manage any workflow, offering full flexibility to design and oversee operations according to your requirements.</p>\n      </div>\n      <br>\n      <div align=\"center\">\n        <a href=\"https://thingsboard.io/use-cases/scada/\">Read more ‚ûú</a>\n      </div>\n      <br>\n    </td>\n    <td width=\"50%\" valign=\"top\">\n      <br>\n      <div align=\"center\">\n        <img src=\"https://github.com/user-attachments/assets/c23dcc9b-aeba-40ef-9973-49b953fc1257\" alt=\"Process and React\" width=\"378\" />\n        <h3>Process and React</h3>\n      </div>\n      <div align=\"center\">\n        <p>Define data processing rule chains. Transform and normalize your device data. Raise alarms on incoming telemetry events, attribute updates, device inactivity and user actions.<br></p>\n      </div>\n      <br>\n      <br>\n      <div align=\"center\">\n        <a href=\"https://thingsboard.io/docs/user-guide/rule-engine-2-0/re-getting-started/\">Read more ‚ûú</a>\n      </div>\n      <br>\n    </td>\n  </tr>\n</table>\n\n## ‚öôÔ∏è Powerful IoT Rule Engine\n\nThingsBoard allows you to create complex [Rule Chains](https://thingsboard.io/docs/user-guide/rule-engine-2-0/re-getting-started/) to process data from your devices and match your application specific use cases.\n\n[![IoT Rule Engine](https://github.com/user-attachments/assets/43d21dc9-0e18-4f1b-8f9a-b72004e12f07 \"IoT Rule Engine\")](https://thingsboard.io/docs/user-guide/rule-engine-2-0/re-getting-started/)\n\n<div align=\"center\">\n\n[**Read more about Rule Engine ‚ûú**](https://thingsboard.io/docs/user-guide/rule-engine-2-0/re-getting-started/)\n\n</div>\n\n## üì¶ Real-Time IoT Dashboards\n\nThingsBoard is a scalable, user-friendly, and device-agnostic IoT platform that speeds up time-to-market with powerful built-in solution templates. It enables data collection and analysis from any devices, saving resources on routine tasks and letting you focus on your solution‚Äôs unique aspects. See more our Use Cases [here](https://thingsboard.io/iot-use-cases/).\n\n[**Smart energy**](https://thingsboard.io/use-cases/smart-energy/)\n\n[![Smart energy](https://github.com/user-attachments/assets/2a0abf13-6dc5-4f5e-9c30-1aea1d39af1e \"Smart energy\")](https://thingsboard.io/use-cases/smart-energy/)\n\n[**SCADA swimming pool**](https://thingsboard.io/use-cases/scada/)\n\n[![SCADA Swimming pool](https://github.com/user-attachments/assets/68fd9e29-99f1-4c16-8c4c-476f4ccb20c0 \"SCADA Swimming pool\")](https://thingsboard.io/use-cases/scada/)\n\n[**Site fleet tracking**](https://thingsboard.io/use-cases/site-fleet-tracking/)\n\n[![Site fleet tracking](https://github.com/user-attachments/assets/d6ce0766-b138-4a42-86aa-7112a543026c \"Site fleet tracking\")](https://thingsboard.io/use-cases/site-fleet-tracking/)\n\n[**Smart farming**](https://thingsboard.io/use-cases/smart-farming/)\n\n[![Smart farming](https://github.com/user-attachments/assets/56b84c99-ef24-44e5-a903-b925b7f9d142 \"Smart farming\")](https://thingsboard.io/use-cases/smart-farming/)\n\n[**Smart metering**](https://thingsboard.io/smart-metering/)\n\n[![Smart metering](https://github.com/user-attachments/assets/adc05e3d-397c-48ef-bed6-535bbd698455 \"Smart metering\")](https://thingsboard.io/smart-metering/)\n\n<div align=\"center\">\n\n[**Check more of our use cases ‚ûú**](https://thingsboard.io/iot-use-cases/)\n\n</div>\n\n## ü´∂ Support\n\nTo get support, please visit our [GitHub issues page](https://github.com/thingsboard/thingsboard/issues)\n\n## üìÑ Licenses\n\nThis project is released under [Apache 2.0 License](./LICENSE)\n",
      "stars_today": 6
    },
    {
      "id": 924551,
      "name": "rabbitmq-server",
      "full_name": "rabbitmq/rabbitmq-server",
      "description": "Open source RabbitMQ: core server and tier 1 (built-in) plugins",
      "html_url": "https://github.com/rabbitmq/rabbitmq-server",
      "stars": 13420,
      "forks": 3987,
      "language": "JavaScript",
      "topics": [
        "amqp",
        "amqp-0-9-1",
        "amqp1-0",
        "message-broker",
        "messaging",
        "mqtt",
        "rabbitmq",
        "stomp",
        "streaming",
        "streams"
      ],
      "created_at": "2010-09-20T10:29:16Z",
      "updated_at": "2026-01-23T19:03:07Z",
      "pushed_at": "2026-01-23T14:59:07Z",
      "open_issues": 261,
      "owner": {
        "login": "rabbitmq",
        "avatar_url": "https://avatars.githubusercontent.com/u/96669?v=4"
      },
      "readme": "# RabbitMQ Server\n\n[![CI](https://github.com/rabbitmq/rabbitmq-server/actions/workflows/test-make.yaml/badge.svg)](https://github.com/rabbitmq/rabbitmq-server/actions/workflows/test-make.yaml)\n\n[RabbitMQ](https://rabbitmq.com) is a [feature rich](https://www.rabbitmq.com/docs),\nmulti-protocol messaging and streaming broker. It supports:\n\n * AMQP 1.0\n * AMQP 0-9-1\n * [RabbitMQ Stream Protocol](https://www.rabbitmq.com/docs/streams)\n * MQTT 3.1, 3.1.1, and 5.0\n * STOMP 1.0 through 1.2\n * [MQTT over WebSocket](https://www.rabbitmq.com/docs/web-mqtt)\n * [STOMP over WebSocket](https://www.rabbitmq.com/docs/web-stomp)\n * AMQP 1.0 over WebSocket (supported in [VMware Tanzu RabbitMQ](https://www.vmware.com/products/app-platform/tanzu-rabbitmq))\n\n\n## Installation\n\n * [Currently supported](https://www.rabbitmq.com/release-information) released series\n * [Installation guides](https://www.rabbitmq.com/docs/download) for various platforms\n * [Kubernetes Cluster Operator](https://www.rabbitmq.com/kubernetes/operator/operator-overview)\n * [Changelog](https://www.rabbitmq.com/release-information)\n * [Releases](https://github.com/rabbitmq/rabbitmq-server/releases) on GitHub\n * [Community Support Eligibility Policy](https://github.com/rabbitmq/rabbitmq-server/blob/main/COMMUNITY_SUPPORT.md)\n * [Supported Erlang versions](https://www.rabbitmq.com/docs/which-erlang)\n\n\n## Tutorials and Documentation\n\n * [RabbitMQ tutorials](https://www.rabbitmq.com/tutorials) and their [executable versions on GitHub](https://github.com/rabbitmq/rabbitmq-tutorials)\n * [Documentation guides](https://rabbitmq.com/docs/)\n * [RabbitMQ blog](https://blog.rabbitmq.com/)\n\nSome key doc guides include\n\n * [CLI tools guide](https://www.rabbitmq.com/docs/cli)\n * [Clustering](https://www.rabbitmq.com/docs/clustering) and [Cluster Formation](https://www.rabbitmq.com/docs/cluster-formation)\n * [Configuration guide](https://www.rabbitmq.com/docs/configure)\n * [Client libraries and tools](https://www.rabbitmq.com/client-libraries/devtools)\n * [Monitoring](https://www.rabbitmq.com/docs/monitoring) and [Prometheus/Grafana](https://www.rabbitmq.com/docs/prometheus)\n * [Upgrading](https://www.rabbitmq.com/docs/upgrade)\n * [Kubernetes Cluster Operator](https://www.rabbitmq.com/kubernetes/operator/operator-overview)\n * [Production checklist](https://www.rabbitmq.com/docs/production-checklist)\n * [Quorum queues](https://www.rabbitmq.com/docs/quorum-queues): a replicated, data safety- and consistency-oriented queue type\n * [Streams](https://www.rabbitmq.com/docs/streams): a persistent and replicated append-only log with non-destructive consumer semantics\n * [Runtime Parameters and Policies](https://www.rabbitmq.com/docs/parameters)\n * [Runnable tutorials](https://github.com/rabbitmq/rabbitmq-tutorials/)\n\nRabbitMQ documentation is also [developed on GitHub](https://github.com/rabbitmq/rabbitmq-website/).\n\n## Commercial Features and Support\n\n * [Commercial editions of RabbitMQ](https://tanzu.vmware.com/rabbitmq)\n * [Commercial edition for Kubernetes](https://docs.vmware.com/en/VMware-RabbitMQ-for-Kubernetes/1/rmq/installation.html)\n * [Commercial support](https://tanzu.vmware.com/rabbitmq/oss) from [Broadcom](https://vmware.com) for open source RabbitMQ\n\n## Getting Help from the Community\n\nPlease read the [Community Support Eligibility Policy](https://github.com/rabbitmq/rabbitmq-server/blob/main/COMMUNITY_SUPPORT.md) document\nfirst.\n\nThe recommended community forums are\n\n * [GitHub Discussions](https://github.com/rabbitmq/rabbitmq-server/discussions/)\n * [Community Discord server](https://rabbitmq.com/discord/)\n * `#rabbitmq` on [Libera Chat](https://libera.chat/)\n\n\n## Contributing\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md) and our [development process overview](https://www.rabbitmq.com/github).\n\nQuestions about contributing, internals and so on are very welcome in [GitHub Discussions](https://github.com/rabbitmq/rabbitmq-server/discussions)\nor [community Discord server](https://www.rabbitmq.com/discord/) in the `contributors` channel.\n\n\n## Licensing\n\nRabbitMQ server is [licensed under the MPL 2.0](LICENSE-MPL-RabbitMQ).\n\n[Community Support Eligibility Policy](https://github.com/rabbitmq/rabbitmq-server/blob/main/COMMUNITY_SUPPORT.md)\ndocument explains the open source RabbitMQ support policy adopted by the RabbitMQ Core Team.\n\n\n## AI Agent Instructions\n\nSee `AGENTS.md`.\n\n\n## Building From Source and Packaging\n\n * [Contributor resources](https://github.com/rabbitmq/contribute)\n * [Building RabbitMQ from Source](https://www.rabbitmq.com/docs/build-server)\n * [Building RabbitMQ Distribution Packages](https://www.rabbitmq.com/docs/build-server)\n\n\n## Copyright\n\n(c) 2007-2026 Broadcom. All Rights Reserved. The term ‚ÄúBroadcom‚Äù refers to Broadcom Inc. and/or its subsidiaries.\n",
      "stars_today": 6
    },
    {
      "id": 27911088,
      "name": "nifi",
      "full_name": "apache/nifi",
      "description": "Apache NiFi",
      "html_url": "https://github.com/apache/nifi",
      "stars": 5928,
      "forks": 2926,
      "language": "Java",
      "topics": [
        "apache",
        "hacktoberfest",
        "java",
        "nifi"
      ],
      "created_at": "2014-12-12T08:00:05Z",
      "updated_at": "2026-01-23T21:55:11Z",
      "pushed_at": "2026-01-23T21:55:05Z",
      "open_issues": 26,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "<!--\n  Licensed to the Apache Software Foundation (ASF) under one or more\n  contributor license agreements.  See the NOTICE file distributed with\n  this work for additional information regarding copyright ownership.\n  The ASF licenses this file to You under the Apache License, Version 2.0\n  (the \"License\"); you may not use this file except in compliance with\n  the License.  You may obtain a copy of the License at\n      http://www.apache.org/licenses/LICENSE-2.0\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License.\n-->\n\n# Apache NiFi\n\n<img src=\"https://nifi.apache.org/images/apache-nifi-logo.svg\" width=\"300\" alt=\"Apache NiFi\"/>\n\n### Status\n\n[![ci-workflow](https://github.com/apache/nifi/workflows/ci-workflow/badge.svg)](https://github.com/apache/nifi/actions/workflows/ci-workflow.yml)\n[![system-tests](https://github.com/apache/nifi/workflows/system-tests/badge.svg)](https://github.com/apache/nifi/actions/workflows/system-tests.yml)\n[![integration-tests](https://github.com/apache/nifi/actions/workflows/integration-tests.yml/badge.svg)](https://github.com/apache/nifi/actions/workflows/integration-tests.yml)\n[![docker-tests](https://github.com/apache/nifi/actions/workflows/docker-tests.yml/badge.svg)](https://github.com/apache/nifi/actions/workflows/docker-tests.yml)\n[![code-compliance](https://github.com/apache/nifi/actions/workflows/code-compliance.yml/badge.svg)](https://github.com/apache/nifi/actions/workflows/code-compliance.yml)\n[![code-coverage](https://github.com/apache/nifi/actions/workflows/code-coverage.yml/badge.svg)](https://github.com/apache/nifi/actions/workflows/code-coverage.yml)\n[![codecov](https://codecov.io/gh/apache/nifi/branch/main/graph/badge.svg)](https://codecov.io/gh/apache/nifi)\n\n### Resources\n\n[![NiFi API](https://img.shields.io/maven-central/v/org.apache.nifi/nifi-api.svg?label=nifi-api&logo=apachenifi&logoColor=ffffff&color=728e9b)](https://central.sonatype.com/artifact/org.apache.nifi/nifi-api)\n[![NiFi NAR Maven Plugin](https://img.shields.io/maven-central/v/org.apache.nifi/nifi-nar-maven-plugin.svg?label=nifi-nar-maven-plugin&logo=apachenifi&logoColor=ffffff&color=728e9b)](https://central.sonatype.com/artifact/org.apache.nifi/nifi-nar-maven-plugin)\n[![NiFi Framework](https://img.shields.io/maven-central/v/org.apache.nifi/nifi.svg?label=nifi-framework&logo=apachenifi&logoColor=ffffff&color=728e9b)](https://nifi.apache.org/download/)\n[![NiFI Docker Pulls](https://img.shields.io/docker/pulls/apache/nifi.svg?logo=docker&logoColor=ffffff)](https://hub.docker.com/r/apache/nifi/)\n[![License](https://img.shields.io/github/license/apache/nifi)](https://github.com/apache/nifi/blob/main/LICENSE)\n[![NiFi API Javadoc](https://javadoc.io/badge2/org.apache.nifi/nifi-api/javadoc.svg)](https://javadoc.io/doc/org.apache.nifi/nifi-api)\n\n### Contacts\n\n[![Track Issues](https://img.shields.io/badge/track-Issues-728e9b.svg?logo=jirasoftware)](https://issues.apache.org/jira/browse/NIFI)\n[![Chat on Slack](https://img.shields.io/badge/chat-Slack-728e9b.svg?logo=slack)](https://s.apache.org/nifi-community-slack)\n[![Contact Developers](https://img.shields.io/badge/contact-Developers-728e9b.svg?logo=apache)](https://lists.apache.org/list.html?dev@nifi.apache.org)\n[![Contact Users](https://img.shields.io/badge/contact-Users-728e9b.svg?logo=apache)](https://lists.apache.org/list.html?users@nifi.apache.org)\n\n### Community\n\n[![Join Slack Community](https://img.shields.io/badge/join-Slack-728e9b.svg?logo=slack)](https://join.slack.com/t/apachenifi/shared_invite/zt-11njbtkdx-ZRU8FKYSWoEHRJetidy0zA)\n[![Follow on LinkedIn](https://img.shields.io/badge/follow-Apache%20NiFi-728e9b.svg?logo=linkedin)](https://www.linkedin.com/company/apache-nifi/)\n[![Follow on X](https://img.shields.io/badge/follow-apachenifi-728e9b.svg?logo=x)](https://x.com/apachenifi)\n\n## Features\n\n[Apache NiFi](https://nifi.apache.org/) is an easy to use, powerful, and reliable system to process and distribute data.\n\nNiFi automates cybersecurity, observability, event streams, and generative AI data pipelines and distribution\nfor thousands of companies worldwide across every industry.\n\n- Browser User Interface\n  - Seamless experience for design, control, and monitoring\n  - Runtime management and versioned pipelines\n  - Secure by default with HTTPS\n- Scalable Processing\n  - Configurable prioritization for throughput and latency\n  - Guaranteed delivery with retry and backoff strategies\n  - Horizontal scaling with clustering\n- Provenance Tracking \n  - Searchable history with configurable attributes\n  - Graph data lineage from source to destination\n  - Metadata and content for each processing decision\n- Extensible Design\n  - Plugin interface for Processors and Controller Services\n  - Support for Processors in native Python\n  - REST API for orchestration and monitoring\n- Secure Configuration\n  - Single sign-on with OpenID Connect or SAML 2\n  - Flexible authorization policies for role-based access\n  - Encrypted communication with TLS and SFTP\n\n## Requirements\n\nNiFi supports modern operating systems and requires recent language versions for developing and running the application.\n\n### Platform Requirements\n\n- Java 21\n\n### Optional Dependencies\n\n- Python 3.10 or higher\n\n## Projects\n\nThe source repository includes several component projects.\n\nPlease review individual project documentation for additional details.\n\n- [Apache NiFi](https://nifi.apache.org/documentation/)\n- [Apache NiFi Registry](https://github.com/apache/nifi/blob/main/nifi-registry/nifi-registry-assembly/README.md)\n- [Apache NiFi MiNiFi](https://github.com/apache/nifi/blob/main/minifi/minifi-assembly/README.md)\n\n## Getting Started\n\nProject guides provide extensive documentation for installing and extending the application.\n\n- [Getting Started](https://nifi.apache.org/documentation/nifi-latest/html/getting-started.html)\n- [User Guide](https://nifi.apache.org/documentation/nifi-latest/html/user-guide.html)\n- [Administrator Guide](https://nifi.apache.org/documentation/nifi-latest/html/administration-guide.html)\n- [Developer Guide](https://nifi.apache.org/documentation/nifi-latest/html/developer-guide.html)\n\n## Developing\n\nNiFi uses the [Maven Wrapper](https://maven.apache.org/wrapper/) for project development. The Maven Wrapper provides\nshell scripts that download and cache a selected version of [Apache Maven](https://maven.apache.org/) for running build\ncommands.\n\nDeveloping on Microsoft Windows requires using `mvnw.cmd` instead of `mvnw` to run Maven commands.\n\n### Building\n\nRun the following command to build project modules using parallel execution:\n\n```shell\n./mvnw install -T1C\n```\n\nRun the following command to build project modules using parallel execution with static analysis to confirm compliance\nwith code and licensing requirements:\n\n```shell\n./mvnw install -T1C -P contrib-check\n```\n\nRun the following command to build the application binaries without building other optional modules:\n\n```shell\n./mvnw install -T1C -am -pl :nifi-assembly\n```\n\n### Binaries\n\nThe `nifi-assembly` module contains the binary distribution.\n\n```shell\nls nifi-assembly/target/nifi-*-bin.zip\n```\n\nThe `nifi-assembly` module includes the binary distribution in a directory for local development and testing.\n\n```shell\ncd nifi-assembly/target/nifi-*-bin/nifi-*/\n```\n\n## Running\n\nNiFi provides shell scripts for starting and stopping the system.\n\nRunning on Microsoft Windows requires using `nifi.cmd` instead of `nifi.sh` for system commands.\n\n### Starting\n\nRun the following command to start NiFi from the distribution directory:\n\n```shell\n./bin/nifi.sh start\n```\n\n### Accessing\n\nThe default configuration generates a random username and password on startup. NiFi writes the generated credentials\nto the application log located in `logs/nifi-app.log` under the NiFi installation directory.\n\nThe following command can be used to find the generated credentials on operating systems with `grep` installed:\n\n```shell\ngrep Generated logs/nifi-app*log\n```\n\nNiFi logs the generated credentials as follows:\n\n```shell\nGenerated Username [USERNAME]\nGenerated Password [PASSWORD]\n```\n\nThe `USERNAME` will be a random UUID composed of 36 characters. The `PASSWORD` will be a random string.\n\nThe username and password can be replaced with custom credentials using the following command:\n\n```shell\n./bin/nifi.sh set-single-user-credentials <username> <password>\n```\n\nNiFi defaults to running on the `localhost` address with HTTPS on port `8443` at the following URL:\n\n```\nhttps://localhost:8443/nifi\n```\n\nBrowsers will display a warning message indicating a potential security risk due to the self-signed certificate\ngenerated during initialization. Production deployments should provision a certificate from a trusted certificate\nauthority and update the NiFi keystore and truststore configuration.\n\n## License\n\nExcept as otherwise noted this software is licensed under the\n[Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0.html)\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n  https://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n## Export Control\n\nThis distribution includes cryptographic software. The country in which you\ncurrently reside may have restrictions on the import, possession, use, and/or\nre-export to another country, of encryption software. BEFORE using any\nencryption software, please check your country's laws, regulations and\npolicies concerning the import, possession, or use, and re-export of encryption\nsoftware, to see if this is permitted. See https://www.wassenaar.org for more\ninformation.\n\nThe U.S. Government Department of Commerce, Bureau of Industry and Security\n(BIS), has classified this software as Export Commodity Control Number (ECCN)\n5D002.C.1, which includes information security software using or performing\ncryptographic functions with asymmetric algorithms. The form and manner of this\nApache Software Foundation distribution makes it eligible for export under the\nLicense Exception ENC Technology Software Unrestricted (TSU) exception (see the\nBIS Export Administration Regulations, Section 740.13) for both object code and\nsource code.\n\nThe following provides more details on the included cryptographic software:\n\nApache NiFi uses the following libraries and frameworks for encrypted\ncommunication and storage of sensitive information:\n\n- [Apache MINA SSHD](https://mina.apache.org/sshd-project/)\n- [Bouncy Castle](https://www.bouncycastle.org)\n- [Jagged](https://github.com/exceptionfactory/jagged)\n- [Java Cryptography Architecture](https://docs.oracle.com/en/java/javase/21/security/java-cryptography-architecture-jca-reference-guide.html)\n",
      "stars_today": 6
    },
    {
      "id": 120498971,
      "name": "swift-nio",
      "full_name": "apple/swift-nio",
      "description": "Event-driven network application framework for high performance protocol servers & clients, non-blocking.",
      "html_url": "https://github.com/apple/swift-nio",
      "stars": 8387,
      "forks": 724,
      "language": "Swift",
      "topics": [
        "asynchronous-io",
        "event-driven",
        "high-performance",
        "networking",
        "non-blocking",
        "non-blocking-io",
        "swift",
        "swift-server",
        "swift5",
        "swiftnio"
      ],
      "created_at": "2018-02-06T17:47:31Z",
      "updated_at": "2026-01-23T16:39:37Z",
      "pushed_at": "2026-01-23T16:39:32Z",
      "open_issues": 252,
      "owner": {
        "login": "apple",
        "avatar_url": "https://avatars.githubusercontent.com/u/10639145?v=4"
      },
      "readme": "[![sswg:graduated|104x20](https://img.shields.io/badge/sswg-graduated-green.svg)](https://github.com/swift-server/sswg/blob/main/process/incubation.md#graduated-level)\n\n# SwiftNIO\n\nSwiftNIO is a cross-platform asynchronous event-driven network application framework\nfor rapid development of maintainable high performance protocol servers & clients.\n\nIt's like [Netty](https://netty.io), but written for Swift.\n\n### Repository organization\n\nThe SwiftNIO project is split across multiple repositories:\n\nRepository | NIO 2\n--- | ---\n[https://github.com/apple/swift-nio][repo-nio] <br> SwiftNIO core | `from: \"2.0.0\"`\n[https://github.com/apple/swift-nio-ssl][repo-nio-ssl] <br> TLS (SSL) support | `from: \"2.0.0\"`\n[https://github.com/apple/swift-nio-http2][repo-nio-http2]<br> HTTP/2 support | `from: \"1.0.0\"`\n[https://github.com/apple/swift-nio-extras][repo-nio-extras] <br>useful additions around SwiftNIO | `from: \"1.0.0\"`\n[https://github.com/apple/swift-nio-transport-services][repo-nio-transport-services] <br> first-class support for macOS, iOS, tvOS, and watchOS | `from: \"1.0.0\"`\n[https://github.com/apple/swift-nio-ssh][repo-nio-ssh] <br> SSH support | `.upToNextMinor(from: \"0.2.0\")`\n\nWithin this repository we have a number of products that provide different functionality. This package contains the following products:\n\n- `NIO`. This is an umbrella module exporting `NIOCore`, `NIOEmbedded` and `NIOPosix`.\n- `NIOCore`. This provides the core abstractions and types for using SwiftNIO (see [\"Conceptual Overview\"](#conceptual-overview) for more details). Most NIO extension projects that provide things like new [`EventLoop`s][el] and [`Channel`s][c] or new protocol implementations should only need to depend on `NIOCore`.\n- `NIOPosix`. This provides the primary [`EventLoopGroup`], [`EventLoop`][el], and [`Channel`s][c] for use on POSIX-based systems. This is our high performance core I/O layer. In general, this should only be imported by projects that plan to do some actual I/O, such as high-level protocol implementations or applications.\n- `NIOEmbedded`. This provides [`EmbeddedChannel`][ec] and [`EmbeddedEventLoop`][eel], implementations of the `NIOCore` abstractions that provide fine-grained control over their execution. These are most often used for testing, but can also be used to drive protocol implementations in a way that is decoupled from networking altogether.\n- `NIOConcurrencyHelpers`. This provides a few low-level concurrency primitives that are used by NIO implementations, such as locks and atomics.\n- `NIOFoundationCompat`. This extends a number of NIO types for better interoperation with Foundation data types. If you are working with Foundation data types such as `Data`, you should import this.\n- `NIOTLS`. This provides a few common abstraction types for working with multiple TLS implementations. Note that this doesn't provide TLS itself: please investigate [swift-nio-ssl][repo-nio-ssl] and [swift-nio-transport-services][repo-nio-transport-services] for concrete implementations.\n- `NIOHTTP1`. This provides a low-level HTTP/1.1 protocol implementation.\n- `NIOWebSocket`. This provides a low-level WebSocket protocol implementation.\n- `NIOTestUtils`. This provides a number of helpers for testing projects that use SwiftNIO.\n- `NIOFileSystem`. This provides `async` APIs for interacting with the file system.\n\n### Protocol Implementations\n\nBelow you can find a list of a few protocol implementations that are done with SwiftNIO. This is a non-exhaustive list of protocols that are either part of the SwiftNIO project or are accepted into the [SSWG](https://swift.org/server)'s incubation process. All of the libraries listed below do all of their I/O in a non-blocking fashion using SwiftNIO.\n\n#### Low-level protocol implementations\n\nLow-level protocol implementations are often a collection of [`ChannelHandler`][ch]s that implement a protocol but still require the user to have a good understanding of SwiftNIO. Often, low-level protocol implementations will then be wrapped in high-level libraries with a nicer, more user-friendly API.\n\nProtocol | Client<br />(Sends requests) | Server<br />(Responds to requests) | Repository | Module | Comment\n--- |  --- | --- | --- | --- | ---\nHTTP/1 | ‚úÖ| ‚úÖ | [apple/swift-nio](https://github.com/apple/swift-nio) | [`NIOHTTP1`][nioh1] | official NIO project\nHTTP/2 | ‚úÖ| ‚úÖ | [apple/swift-nio-http2](https://github.com/apple/swift-nio-http2) | [`NIOHTTP2`][nioh2] | official NIO project\nWebSocket | ‚úÖ| ‚úÖ | [apple/swift-nio](https://github.com/apple/swift-nio) | [`NIOWebSocket`][niows] | official NIO project\nTLS | ‚úÖ | ‚úÖ | [apple/swift-nio-ssl](https://github.com/apple/swift-nio-ssl) | [`NIOSSL`][niossl] | official NIO project\nSSH | ‚úÖ | ‚úÖ | [apple/swift-nio-ssh][repo-nio-ssh] | [`NIOSSH`][niossh] | official NIO project\n\n\n#### High-level implementations\n\nHigh-level implementations are usually libraries that come with an API that doesn't expose SwiftNIO's [`ChannelPipeline`][cp] and can therefore be used with very little (or no) SwiftNIO-specific knowledge. The implementations listed below do still do all of their I/O in SwiftNIO and integrate really well with the SwiftNIO ecosystem.\n\nProtocol | Client<br />(Sends requests) | Server<br />(Responds to requests) | Repository | Module | Comment\n--- |  --- | --- | --- | --- | ---\nHTTP | ‚úÖ| ‚ùå | [swift-server/async-http-client](https://github.com/swift-server/async-http-client) | `AsyncHTTPClient` | SSWG community project\ngRPC | ‚úÖ| ‚úÖ | [grpc/grpc-swift](https://github.com/grpc/grpc-swift) | `GRPC` | also offers a low-level API; SSWG community project\nAPNS | ‚úÖ | ‚ùå | [swift-server-community/APNSwift](https://github.com/swift-server-community/APNSwift) | `APNSwift` | SSWG community project\nPostgreSQL | ‚úÖ | ‚ùå | [vapor/postgres-nio](https://github.com/vapor/postgres-nio) | `PostgresNIO` | SSWG community project\nRedis | ‚úÖ | ‚ùå | [swift-server/RediStack](https://github.com/swift-server/RediStack) | `RediStack` | SSWG community project\n\n### Supported Versions\n\n### SwiftNIO 2\n\nThis is the current version of SwiftNIO and will be supported for the foreseeable future.\n\n### Swift Versions\n\nWe commit to support the most recently released Swift version and the last two minor releases before that unless this is impossible to do in one codebase.\nIn addition checks are run against the latest beta release (if any) as well as the nightly Swift builds and the intent is that these should pass.\n\nThe minimum Swift version supported by SwiftNIO releases are detailed below:\n\nSwiftNIO            | Minimum Swift Version\n--------------------|----------------------\n`2.0.0 ..< 2.30.0`  | 5.0\n`2.30.0 ..< 2.40.0` | 5.2\n`2.40.0 ..< 2.43.0` | 5.4\n`2.43.0 ..< 2.51.0` | 5.5.2\n`2.51.0 ..< 2.60.0` | 5.6\n`2.60.0 ..< 2.65.0` | 5.7\n`2.65.0 ..< 2.76.0` | 5.8\n`2.76.0 ..< 2.83.0` | 5.9\n`2.83.0 ..< 2.87.0` | 5.10\n`2.87.0 ...       ` | 6.0\n\n### SwiftNIO 1\nSwiftNIO 1 is considered end of life - it is strongly recommended that you move to a newer version.  The Core NIO team does not actively work on this version.  No new features will be added to this version but PRs which fix bugs or security vulnerabilities will be accepted until the end of May 2022.\n\nIf you have a SwiftNIO 1 application or library that you would like to migrate to SwiftNIO 2, please check out the [migration guide](docs/migration-guide-NIO1-to-NIO2.md) we prepared for you.\n\nThe latest released SwiftNIO 1 version¬†supports Swift 4.0, 4.1, 4.2, and 5.0.\n\n### Supported Platforms\n\nSwiftNIO aims to support all of the platforms where Swift is supported. Currently, it is developed and tested on macOS and Linux, and is known to support the following operating system versions:\n\n* Ubuntu 18.04+\n* macOS 10.9+, iOS 7+; (macOS 10.14+, iOS 12+, tvOS 12+ or watchOS 6+ with [swift-nio-transport-services][repo-nio-transport-services])\n\nSwiftNIO has experimental support on OpenBSD for all SwiftNIO libraries _except_ for NIOFileSystem, which is not yet supported. You can use all other SwiftNIO libraries on OpenBSD by adding them as dependencies in `Package.swift`.\n\n### Compatibility\n\nSwiftNIO follows [SemVer 2.0.0](https://semver.org/#semantic-versioning-200) with a separate document declaring [SwiftNIO's Public API](docs/public-api.md).\n\nWhat this means for you is that you should depend on SwiftNIO with a version range that covers everything from the minimum SwiftNIO version you require up to the next major version.\nIn SwiftPM that can be easily done specifying for example `from: \"2.0.0\"` meaning that you support SwiftNIO in every version starting from 2.0.0 up to (excluding) 3.0.0.\nSemVer and SwiftNIO's Public API guarantees should result in a working program without having to worry about testing every single version for compatibility.\n\n\n## Conceptual Overview\n\nSwiftNIO is fundamentally a low-level tool for building high-performance networking applications in Swift. It particularly targets those use-cases where using a \"thread-per-connection\" model of concurrency is inefficient or untenable. This is a common limitation when building servers that use a large number of relatively low-utilization connections, such as HTTP servers.\n\nTo achieve its goals, SwiftNIO extensively uses \"non-blocking I/O\": hence the name! Non-blocking I/O differs from the more common blocking I/O model because the application does not wait for data to be sent to or received from the network: instead, SwiftNIO asks for the kernel to notify it when I/O operations can be performed without waiting.\n\nSwiftNIO does not aim to provide high-level solutions like, for example, web frameworks do. Instead, SwiftNIO is focused on providing the low-level building blocks for these higher-level applications. When it comes to building a web application, most users will not want to use SwiftNIO directly: instead, they'll want to use one of the many great web frameworks available in the Swift ecosystem. Those web frameworks, however, may choose to use SwiftNIO under the covers to provide their networking support.\n\nThe following sections will describe the low-level tools that SwiftNIO provides, and provide a quick overview of how to work with them. If you feel comfortable with these concepts, then you can skip right ahead to the other sections of this README.\n\n### Basic Architecture\n\nThe basic building blocks of SwiftNIO are the following 8 types of objects:\n\n- [`EventLoopGroup`][elg], a protocol, provided by `NIOCore`.\n- [`EventLoop`][el], a protocol, provided by `NIOCore`.\n- [`Channel`][c], a protocol, provided by `NIOCore`.\n- [`ChannelHandler`][ch], a protocol, provided by `NIOCore`.\n- `Bootstrap`, several related structures, provided by `NIOCore`.\n- [`ByteBuffer`][bb], a struct, provided by `NIOCore`.\n- [`EventLoopFuture`][elf], a generic class, provided by `NIOCore`.\n- [`EventLoopPromise`][elp], a generic struct, provided by `NIOCore`.\n\nAll SwiftNIO applications are ultimately constructed of these various components.\n\n#### EventLoops and EventLoopGroups\n\nThe basic I/O primitive of SwiftNIO is the event loop. The event loop is an object that waits for events (usually I/O related events, such as \"data received\") to happen and then fires some kind of callback when they do. In almost all SwiftNIO applications there will be relatively few event loops: usually only one or two per CPU core the application wants to use. Generally speaking, event loops run for the entire lifetime of your application, spinning in an endless loop dispatching events.\n\nEvent loops are gathered together into event loop *groups*. These groups provide a mechanism to distribute work around the event loops. For example, when listening for inbound connections the listening socket will be registered on one event loop. However, we don't want all connections that are accepted on that listening socket to be registered with the same event loop, as that would potentially overload one event loop while leaving the others empty. For that reason, the event loop group provides the ability to spread load across multiple event loops.\n\nIn SwiftNIO today there is one [`EventLoopGroup`][elg] implementation, and two [`EventLoop`][el] implementations. For production applications there is the [`MultiThreadedEventLoopGroup`][mtelg], an [`EventLoopGroup`][elg] that creates a number of threads (using the POSIX [`pthreads`][pthreads] library) and places one `SelectableEventLoop` on each one. The `SelectableEventLoop` is an event loop that uses a selector (either [`kqueue`][kqueue] or [`epoll`][epoll] depending on the target system) to manage I/O events from file descriptors and to dispatch work. These [`EventLoop`s][el] and [`EventLoopGroup`s][elg] are provided by the `NIOPosix` module. Additionally, there is the [`EmbeddedEventLoop`][eel], which is a dummy event loop that is used primarily for testing purposes, provided by the `NIOEmbedded` module.\n\n[`EventLoop`][el]s have a number of important properties. Most vitally, they are the way all work gets done in SwiftNIO applications. In order to ensure thread-safety, any work that wants to be done on almost any of the other objects in SwiftNIO must be dispatched via an [`EventLoop`][el]. [`EventLoop`][el] objects own almost all the other objects in a SwiftNIO application, and understanding their execution model is critical for building high-performance SwiftNIO applications.\n\n#### Channels, Channel Handlers, Channel Pipelines, and Channel Contexts\n\nWhile [`EventLoop`][el]s are critical to the way SwiftNIO works, most users will not interact with them substantially beyond asking them to create [`EventLoopPromise`][elp]s and to schedule work. The parts of a SwiftNIO application most users will spend the most time interacting with are [`Channel`][c]s and [`ChannelHandler`][ch]s.\n\nAlmost every file descriptor that a user interacts with in a SwiftNIO program is associated with a single [`Channel`][c]. The [`Channel`][c] owns this file descriptor, and is responsible for managing its lifetime. It is also responsible for processing inbound and outbound events on that file descriptor: whenever the event loop has an event that corresponds to a file descriptor, it will notify the [`Channel`][c] that owns that file descriptor.\n\n[`Channel`][c]s by themselves, however, are not useful. After all, it is a rare application that doesn't want to do anything with the data it sends or receives on a socket! So the other important part of the [`Channel`][c] is the [`ChannelPipeline`][cp].\n\nA [`ChannelPipeline`][cp] is a sequence of objects, called [`ChannelHandler`][ch]s, that process events on a [`Channel`][c]. The [`ChannelHandler`][ch]s process these events one after another, in order, mutating and transforming events as they go. This can be thought of as a data processing pipeline; hence the name [`ChannelPipeline`][cp].\n\nAll [`ChannelHandler`][ch]s are either Inbound or Outbound handlers, or both. Inbound handlers process \"inbound\" events: events like reading data from a socket, reading socket close, or other kinds of events initiated by remote peers. Outbound handlers process \"outbound\" events, such as writes, connection attempts, and local socket closes.\n\nEach handler processes the events in order. For example, read events are passed from the front of the pipeline to the back, one handler at a time, while write events are passed from the back of the pipeline to the front. Each handler may, at any time, generate either inbound or outbound events that will be sent to the next handler in whichever direction is appropriate. This allows handlers to split up reads, coalesce writes, delay connection attempts, and generally perform arbitrary transformations of events.\n\nIn general, [`ChannelHandler`][ch]s are designed to be highly re-usable components. This means they tend to be designed to be as small as possible, performing one specific data transformation. This allows handlers to be composed together in novel and flexible ways, which helps with code reuse and encapsulation.\n\n[`ChannelHandler`][ch]s are able to keep track of where they are in a [`ChannelPipeline`][cp] by using a [`ChannelHandlerContext`][chc]. These objects contain references to the previous and next channel handler in the pipeline, ensuring that it is always possible for a [`ChannelHandler`][ch] to emit events while it remains in a pipeline.\n\nSwiftNIO ships with many [`ChannelHandler`][ch]s built in that provide useful functionality, such as HTTP parsing. In addition, high-performance applications will want to provide as much of their logic as possible in [`ChannelHandler`][ch]s, as it helps avoid problems with context switching.\n\nAdditionally, SwiftNIO ships with a few [`Channel`][c] implementations. In particular, it ships with `ServerSocketChannel`, a [`Channel`][c] for sockets that accept inbound connections; `SocketChannel`, a [`Channel`][c] for TCP connections; and `DatagramChannel`, a [`Channel`][c] for UDP sockets. All of these are provided by the `NIOPosix` module. It also provides [`EmbeddedChannel`][ec], a [`Channel`][c] primarily used for testing, provided by the `NIOEmbedded` module.\n\n##### A Note on Blocking\n\nOne of the important notes about [`ChannelPipeline`][cp]s is that they are thread-safe. This is very important for writing SwiftNIO applications, as it allows you to write much simpler [`ChannelHandler`][ch]s in the knowledge that they will not require synchronization.\n\nHowever, this is achieved by dispatching all code on the [`ChannelPipeline`][cp] on the same thread as the [`EventLoop`][el]. This means that, as a general rule, [`ChannelHandler`][ch]s **must not** call blocking code without dispatching it to a background thread. If a [`ChannelHandler`][ch] blocks for any reason, all [`Channel`][c]s attached to the parent [`EventLoop`][el] will be unable to progress until the blocking call completes.\n\nThis is a common concern while writing SwiftNIO applications. If it is useful to write code in a blocking style, it is highly recommended that you dispatch work to a different thread when you're done with it in your pipeline.\n\n#### Bootstrap\n\nWhile it is possible to configure and register [`Channel`][c]s with [`EventLoop`][el]s directly, it is generally more useful to have a higher-level abstraction to handle this work.\n\nFor this reason, SwiftNIO ships a number of `Bootstrap` objects whose purpose is to streamline the creation of channels. Some `Bootstrap` objects also provide other functionality, such as support for Happy Eyeballs for making TCP connection attempts.\n\nCurrently SwiftNIO ships with three `Bootstrap` objects in the `NIOPosix` module: [`ServerBootstrap`][sbootstrap], for bootstrapping listening channels; [`ClientBootstrap`][cbootstrap], for bootstrapping client TCP channels; and [`DatagramBootstrap`][dbootstrap] for bootstrapping UDP channels.\n\n#### ByteBuffer\n\nThe majority of the work in a SwiftNIO application involves shuffling buffers of bytes around. At the very least, data is sent and received to and from the network in the form of buffers of bytes. For this reason it's very important to have a high-performance data structure that is optimized for the kind of work SwiftNIO applications perform.\n\nFor this reason, SwiftNIO provides [`ByteBuffer`][bb], a fast copy-on-write byte buffer that forms a key building block of most SwiftNIO applications. This type is provided by the `NIOCore` module.\n\n[`ByteBuffer`][bb] provides a number of useful features, and in addition provides a number of hooks to use it in an \"unsafe\" mode. This turns off bounds checking for improved performance, at the cost of potentially opening your application up to memory correctness problems.\n\nIn general, it is highly recommended that you use the [`ByteBuffer`][bb] in its safe mode at all times.\n\nFor more details on the API of [`ByteBuffer`][bb], please see our API documentation, linked below.\n\n#### Promises and Futures\n\nOne major difference between writing concurrent code and writing synchronous code is that not all actions will complete immediately. For example, when you write data on a channel, it is possible that the event loop will not be able to immediately flush that write out to the network. For this reason, SwiftNIO provides [`EventLoopPromise<T>`][elp] and [`EventLoopFuture<T>`][elf] to manage operations that complete *asynchronously*. These types are provided by the `NIOCore` module.\n\nAn [`EventLoopFuture<T>`][elf] is essentially a container for the return value of a function that will be populated *at some time in the future*. Each [`EventLoopFuture<T>`][elf] has a corresponding [`EventLoopPromise<T>`][elp], which is the object that the result will be put into. When the promise is succeeded, the future will be fulfilled.\n\nIf you had to poll the future to detect when it completed that would be quite inefficient, so [`EventLoopFuture<T>`][elf] is designed to have managed callbacks. Essentially, you can chain callbacks off the future that will be executed when a result is available. The [`EventLoopFuture<T>`][elf] will even carefully arrange the scheduling to ensure that these callbacks always execute on the event loop that initially created the promise, which helps ensure that you don't need too much synchronization around [`EventLoopFuture<T>`][elf] callbacks.\n\nAnother important topic for consideration is the difference between how the promise passed to `close` works as opposed to `closeFuture` on a [`Channel`][c]. For example, the promise passed into `close` will succeed after the [`Channel`][c] is closed down but before the [`ChannelPipeline`][cp] is completely cleared out. This will allow you to take action on the [`ChannelPipeline`][cp] before it is completely cleared out, if needed. If it is desired to wait for the [`Channel`][c] to close down and the [`ChannelPipeline`][cp] to be cleared out without any further action, then the better option would be to wait for the `closeFuture` to succeed.\n\nThere are several functions for applying callbacks to [`EventLoopFuture<T>`][elf], depending on how and when you want them to execute. Details of these functions is left to the API documentation.\n\n### Design Philosophy\n\nSwiftNIO is designed to be a powerful tool for building networked applications and frameworks, but it is not intended to be the perfect solution for all levels of abstraction. SwiftNIO is tightly focused on providing the basic I/O primitives and protocol implementations at low levels of abstraction, leaving more expressive but slower abstractions to the wider community to build. The intention is that SwiftNIO will be a building block for server-side applications, not necessarily the framework those applications will use directly.\n\nApplications that need extremely high performance from their networking stack may choose to use SwiftNIO directly in order to reduce the overhead of their abstractions. These applications should be able to maintain extremely high performance with relatively little maintenance cost. SwiftNIO also focuses on providing useful abstractions for this use-case, such that extremely high performance network servers can be built directly.\n\nThe core SwiftNIO repository will contain a few extremely important protocol implementations, such as HTTP, directly in tree. However, we believe that most protocol implementations should be decoupled from the release cycle of the underlying networking stack, as the release cadence is likely to be very different (either much faster or much slower). For this reason, we actively encourage the community to develop and maintain their protocol implementations out-of-tree. Indeed, some first-party SwiftNIO protocol implementations, including our TLS and HTTP/2 bindings, are developed out-of-tree!\n\n## Documentation\n\n - [API documentation](https://swiftpackageindex.com/apple/swift-nio/documentation/nio)\n\n## Example Usage\n\nThere are currently several example projects that demonstrate how to use SwiftNIO.\n\n- **chat client** https://github.com/apple/swift-nio/tree/main/Sources/NIOChatClient\n- **chat server** https://github.com/apple/swift-nio/tree/main/Sources/NIOChatServer\n- **echo client** https://github.com/apple/swift-nio/tree/main/Sources/NIOEchoClient\n- **echo server** https://github.com/apple/swift-nio/tree/main/Sources/NIOEchoServer\n- **UDP echo client** https://github.com/apple/swift-nio/tree/main/Sources/NIOUDPEchoClient\n- **UDP echo server** https://github.com/apple/swift-nio/tree/main/Sources/NIOUDPEchoServer\n- **HTTP client** https://github.com/apple/swift-nio/tree/main/Sources/NIOHTTP1Client\n- **HTTP server** https://github.com/apple/swift-nio/tree/main/Sources/NIOHTTP1Server\n- **WebSocket client** https://github.com/apple/swift-nio/tree/main/Sources/NIOWebSocketClient\n- **WebSocket server** https://github.com/apple/swift-nio/tree/main/Sources/NIOWebSocketServer\n\nTo build & run them, run following command, replace TARGET_NAME with the folder name under `./Sources`\n\n```bash\nswift run TARGET_NAME\n```\n\nFor example, to run NIOHTTP1Server, run following command:\n\n```bash\nswift run NIOHTTP1Server\n```\n\n## Getting Started\n\nSwiftNIO primarily uses [SwiftPM](https://swift.org/package-manager/) as its build tool, so we recommend using that as well. If you want to depend on SwiftNIO in your own project, it's as simple as adding a `dependencies` clause to your `Package.swift`:\n\n```swift\ndependencies: [\n    .package(url: \"https://github.com/apple/swift-nio.git\", from: \"2.0.0\")\n]\n```\n\nand then adding the appropriate SwiftNIO module(s) to your target dependencies.\nThe syntax for adding target dependencies differs slightly between Swift\nversions. For example, if you want to depend on the `NIOCore`, `NIOPosix` and\n`NIOHTTP1` modules, specify the following dependencies:\n\n#### Swift 5.4 and newer (`swift-tools-version:5.4`)\n\n    dependencies: [.product(name: \"NIOCore\", package: \"swift-nio\"),\n                   .product(name: \"NIOPosix\", package: \"swift-nio\"),\n                   .product(name: \"NIOHTTP1\", package: \"swift-nio\")]\n\n### Using Xcode Package support\n\nIf your project is set up as an Xcode project and you're using Xcode 11+, you can add SwiftNIO as a dependency to your\nXcode project by clicking File -> Swift Packages -> Add Package Dependency. In the upcoming dialog, please enter\n`https://github.com/apple/swift-nio.git` and click Next twice. Finally, select the targets you are planning to use (for\nexample `NIOCore`, `NIOHTTP1`, and `NIOFoundationCompat`) and click finish. Now will be able to `import NIOCore` (as well as all\nthe other targets you have selected) in your project.\n\nTo work on SwiftNIO itself, or to investigate some of the demonstration applications, you can clone the repository directly and use SwiftPM to help build it. For example, you can run the following commands to compile and run the example echo server:\n\n```bash\nswift build\nswift test\nswift run NIOEchoServer\n```\n\nTo verify that it is working, you can use another shell to attempt to connect to it:\n\n```bash\necho \"Hello SwiftNIO\" | nc localhost 9999\n```\n\nIf all goes well, you'll see the message echoed back to you.\n\nTo work on SwiftNIO in Xcode, you can just open the `Package.swift`\nfile in Xcode and use Xcode's support for SwiftPM Packages.\n\n## Developing SwiftNIO\n\n*Note*: This section is only relevant if you would like to develop SwiftNIO yourself. You can ignore the information here if you just want to use SwiftNIO as a SwiftPM package.\n\nFor the most part, SwiftNIO development is as straightforward as any other SwiftPM project. With that said, we do have a few processes that are worth understanding before you contribute. For details, please see `CONTRIBUTING.md` in this repository.\n\n### Prerequisites\n\nSwiftNIO's `main` branch is the development branch for the next releases of SwiftNIO 2, it's Swift 5-only.\n\nTo be able to compile and run SwiftNIO and the integration tests, you need to\nhave a few prerequisites installed on your system.\n\n#### macOS\n\n- Xcode 11.4 or newer, Xcode 12 recommended.\n\n### Linux\n\n- Swift 5.7 or newer from [swift.org/download](https://swift.org/download/#releases). We always recommend to use the latest released version.\n- netcat (for integration tests only)\n- lsof (for integration tests only)\n- shasum (for integration tests only)\n\n#### Ubuntu 18.04\n\n```\n# install swift tarball from https://swift.org/downloads\napt-get install -y git curl libatomic1 libxml2 netcat-openbsd lsof perl\n```\n\n\n### Fedora 28+\n\n```\ndnf install swift-lang /usr/bin/nc /usr/bin/lsof /usr/bin/shasum\n```\n\n[ch]: https://swiftpackageindex.com/apple/swift-nio/documentation/niocore/channelhandler\n[c]: https://swiftpackageindex.com/apple/swift-nio/documentation/niocore/channel\n[chc]: https://swiftpackageindex.com/apple/swift-nio/documentation/niocore/channelhandlercontext\n[ec]: https://swiftpackageindex.com/apple/swift-nio/documentation/nioembedded/embeddedchannel\n[el]: https://swiftpackageindex.com/apple/swift-nio/documentation/niocore/eventloop\n[eel]: https://swiftpackageindex.com/apple/swift-nio/documentation/nioembedded/embeddedeventloop\n[elg]: https://swiftpackageindex.com/apple/swift-nio/documentation/niocore/eventloopgroup\n[bb]: https://swiftpackageindex.com/apple/swift-nio/documentation/niocore/bytebuffer\n[elf]: https://swiftpackageindex.com/apple/swift-nio/documentation/niocore/eventloopfuture\n[elp]: https://swiftpackageindex.com/apple/swift-nio/documentation/niocore/eventlooppromise\n[cp]: https://swiftpackageindex.com/apple/swift-nio/documentation/niocore/channelpipeline\n[sbootstrap]: https://swiftpackageindex.com/apple/swift-nio/documentation/nioposix/serverbootstrap\n[cbootstrap]: https://swiftpackageindex.com/apple/swift-nio/documentation/nioposix/clientbootstrap\n[dbootstrap]: https://swiftpackageindex.com/apple/swift-nio/documentation/nioposix/datagrambootstrap\n[mtelg]: https://swiftpackageindex.com/apple/swift-nio/documentation/nioposix/multithreadedeventloopgroup\n[nioh1]: https://swiftpackageindex.com/apple/swift-nio/documentation/niohttp1\n[nioh2]: https://swiftpackageindex.com/apple/swift-nio-http2/documentation/niohttp2\n[niows]: https://swiftpackageindex.com/apple/swift-nio/documentation/niowebsocket\n[niossl]: https://swiftpackageindex.com/apple/swift-nio-ssl/documentation/niossl\n[niossh]: https://swiftpackageindex.com/apple/swift-nio-ssh/documentation/niossh\n[pthreads]: https://en.wikipedia.org/wiki/POSIX_Threads\n[kqueue]: https://en.wikipedia.org/wiki/Kqueue\n[epoll]: https://en.wikipedia.org/wiki/Epoll\n[repo-nio]: https://github.com/apple/swift-nio\n[repo-nio-extras]: https://github.com/apple/swift-nio-extras\n[repo-nio-http2]: https://github.com/apple/swift-nio-http2\n[repo-nio-ssl]: https://github.com/apple/swift-nio-ssl\n[repo-nio-transport-services]: https://github.com/apple/swift-nio-transport-services\n[repo-nio-ssh]: https://github.com/apple/swift-nio-ssh\n",
      "stars_today": 6
    },
    {
      "id": 168259404,
      "name": "lottery",
      "full_name": "moshang-ax/lottery",
      "description": "üéâüåü‚ú®üéàÂπ¥‰ºöÊäΩÂ•ñÁ®ãÂ∫èÔºåÂü∫‰∫é Express + Three.jsÁöÑ 3D ÁêÉ‰ΩìÊäΩÂ•ñÁ®ãÂ∫èÔºåÂ•ñÂìÅüßßüéÅÔºåÊñáÂ≠óÔºåÂõæÁâáÔºåÊäΩÂ•ñËßÑÂàôÂùáÂèØÈÖçÁΩÆÔºåüòúÊäΩÂ•ñ‰∫∫Âëò‰ø°ÊÅØExcel‰∏ÄÈîÆÂØºÂÖ•üòçÔºåÊäΩÂ•ñÁªìÊûúExcelÂØºÂá∫üòéÔºåÁªô‰Ω†ÁöÑÊäΩÂ•ñÊ¥ªÂä®Â∏¶Êù•ÂÖ®Êñ∞ÈÖ∑ÁÇ´‰ΩìÈ™åüöÄüöÄüöÄ",
      "html_url": "https://github.com/moshang-ax/lottery",
      "stars": 4446,
      "forks": 1056,
      "language": "JavaScript",
      "topics": [
        "lottery",
        "lucky",
        "lucky-wheel",
        "luckydraw",
        "nodejs",
        "prizes",
        "threejs"
      ],
      "created_at": "2019-01-30T01:38:03Z",
      "updated_at": "2026-01-24T01:33:08Z",
      "pushed_at": "2025-03-02T03:21:12Z",
      "open_issues": 28,
      "owner": {
        "login": "moshang-ax",
        "avatar_url": "https://avatars.githubusercontent.com/u/29499430?v=4"
      },
      "readme": "# Lottery program\n\nAnnual dinner lottery program, 3D sphere raffle, support for configuration of prize information, import participants information by `Excel`, and export lottery results by `Excel`\nIf programm is helpful for youüòéüòéüòé, it will be greatful to comment us with‚≠ê**star**‚≠ê üòòüòòüòòüòçü•∞üéâüéàüéÉ\n\n[ÁÇπÂáªË∑≥ËΩ¨Ëá≥‰∏≠Êñá‰ΩøÁî®ÊñáÊ°£](https://github.com/moshang-xc/lottery/blob/master/README-ZH_CN.MD)\n\n> Try it now:  [https://moshang-ax.github.io/lottery/](https://moshang-ax.github.io/lottery/)\n\n## Technology Stack\n\nTechnology stack: Node + Express + Three.js\n\nServer: Express + Node\n\nWeb Page: Three.js, References to the official 3D example of `Three.js`\n\n## Function Description:\n\n1. The result can ben save and downloaded to excel synchronouslyüéâ\n2. The winner will not participate in the drawing, and the drawing person can be drawn again if he/she not on siteüéÅ\n3. Refresh or trun off the server will save the winner data and will not resrt the lottery data, only by click the reset button on the page can the  lottery data be resetüßß\n4. The number of prizes is able to configureüéà\n5. After all the prizes have been drawn, you can continue to draw special prizes(For example:Red pockets, additional prizes, etc). By default, one is extracted at onceüß®\n\n## Preview\n\n> Try it now:  [https://moshang-ax.github.io/lottery/](https://moshang-ax.github.io/lottery/)\n\n![lottery.gif](https://raw.githubusercontent.com/moshang-xc/blog/master/share/lottery.gif)\n\n![index.jpg](https://raw.githubusercontent.com/moshang-xc/blog/master/share/index.jpg)\n\n![start.jpg](https://raw.githubusercontent.com/moshang-xc/blog/master/share/start.jpg)\n\n![end.jpg](https://raw.githubusercontent.com/moshang-xc/blog/master/share/end.jpg)\n\n## Install\n```\ngit clone https://github.com/moshang-xc/lottery.git\n\ncd lottery\n\n# Server plugin installation\ncd server\nnpm install\n\n# Front-end plugin installation\ncd ../product\nnpm install\n\n# Package\nnpm run build\n\n# Running\nnpm run serve\n\n# Developing & debugging\nnpm run dev\n\n```\n\n## Directory Structure\n```\nLottery\n‚îú‚îÄ‚îÄ product\n‚îÇ   ‚îú‚îÄ‚îÄ src\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lottery\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.js\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lib\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ img\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ css\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data\n‚îÇ   ‚îú‚îÄ‚îÄ package.json\n‚îÇ   ‚îî‚îÄ‚îÄ webpack.config.js\n‚îú‚îÄ‚îÄ server\n‚îÇ   ‚îú‚îÄ‚îÄ config.js\n‚îÇ   ‚îú‚îÄ‚îÄ server.js\n‚îÇ   ‚îî‚îÄ‚îÄ package.js\n```\n\n> 1. product is Front-end page directory\n> 4. server is Server directory\n> 5. config is Profile for prize information\n\n## Configuration Information\n### Lottery personnel list information configuration\nThe lottery list information is in the **`server/data/user.xlsx`** file, information could only fill in base on the format, file name and title are not able to revise\n\n### Prize information configuration\nPrize information is filled in the **server/config.js** file, and the file name cannot be modified.\n\n**The configuration of the prizes is described as follows:**\n\n| Parameter | Value Type | Description                                                  |\n| --------- | ---------- | ------------------------------------------------------------ |\n| type      | Number     | Type of prize, unique identifier, 0 is the placeholder for the default special prize, other prizes cannot be used |\n| count | Number | Prizes amount                                                 |\n| text  | String |  Prizes name                                     |\n| title | String | Prizes description                                              |\n| img   | String | Image URL of the prize, image is under**img** catalog                |\n\n\n```js\n// Prize information, the first item is reserved and cannot be modified. Other items can be modified as required\n// Prize in\nlet prizes = [{\n        type: 0,\n        count: 1000,\n        title: \"\",\n        text: \"Special Price\"\n    },\n    {\n        type: 1,\n        count: 2,\n        text: \"Special Price\"\n        title: \"Mystery jackpot\"\n        img: \"../img/secrit.jpg\"\n    },\n    {\n        type: 2,\n        count: 5,\n        text: \"First prize\"\n        title: \"Mac Pro\",\n        img: \"../img/mbp.jpg\"\n    }\n    ...\n];\n```\n\n### The configuration of the number of prizes drawn each time\n\n**EACH_COUNT**It is used to configure the number of lottery draws each time, which corresponds to the prizes one by one. For example, the number of lottery draws corresponding to the above prize configuration is as followsÔºö\n\n```js\nconst EACH_COUNT = [1, 1, 5];\n```\n\nConfiguration above means the order of the number of prizes to be drawn at one time isÔºöone special prize per time, one grand prize per time and 5 first prize per time.\n\n### Enterprise Identity Configuration\n\nThis identification is used to display on the lottery card. \n\n```js\nconst COMPANY = \"MoShang\";\n```\n\n\n## Docker Deployment plan\n\n### Summary\n\nThis project is support to deploy by Docker. Docker is a platform with lightweight containerization, allows you to quickly deploy, test and run the applications. This text will introduce how to deploy the project by Docker.\n\n### System Requirement\n\nBefore you use the Docker to deploy the project, you need to ensure you have download below software:\n\n- Docker (Please refer Docker official file to get the installation instructions)\n- Docker Compose\n\n### Installation\n\n1. Download and unzip the source code for the project\n\n2. Access the project directory after unzipped the file\n\n3. Execute the following command to build the Docker mirror image:\n\n   ```\n   ./build.sh [TAG]\n   ```\n\n   It will use Dockerfile to set up the Docker mirror image named `lottery:[TAG]`. If no tag is specified, the 'latest' tag is used by default\n   \n4. Execute the following command to run the local container:\n\n   ```\n   ./dev.sh [TAG]\n   ```\n\n   This will start the container and deploy the application in the Docker container. You can test loacally to ensure all running fulently.  \nPlease be pay attention that all applicaiton in the container will monitor port 8888 and port 443.\n\n5. Execute the following command to tag the Docker mirror image and push it to the remote Docker repository\n\n   ```\n   ./tagpush.sh [TAG]\n   ```\n\n   It will tag the Docker mirror image and push it to the remote Docker repository, please build up your repo at https://hub.docker.com/ if you want to us Docker official hub.\n\n6. Ensure it has a file named `docker-compose.yml` and add below information:\n\n   ```\n   version: '3.8'\n   \n   volumes:\n     lottery_log:\n   \n   services:\n     lottery:\n       container_name: lottery\n       expose:\n         - 8888\n       ports:\n         - \"28458:8888\"\n         - \"443:443\"\n       volumes:\n         - \"lottery_log:/var/log\"\n       image: \"panda1024/lottery:[TAG]\" \n       restart: always\n   ```\n\n  Kindly take note that `[TAG]` should be replaced with the name of the mirror image you pushed to the Docker repository\n\n7. Run the following command in the project directory on the server to deploy the application using Docker Compose:\n\n```\ndocker-compose up -d\n```\n\nThis will start a Docker Compose stack and deploy the project into it. Note that port 8888 and port 443 of the container are mapped to port 8888 and port 443 on the server. If you wish to use a different port, please change the `docker-compose.yml` file accordingly.\n\n\n## License\n\nMIT\n",
      "stars_today": 6
    },
    {
      "id": 20008432,
      "name": "orbot-android",
      "full_name": "guardianproject/orbot-android",
      "description": "The Github home of Orbot: Tor on Android (Also available on gitlab!)",
      "html_url": "https://github.com/guardianproject/orbot-android",
      "stars": 2958,
      "forks": 422,
      "language": "Kotlin",
      "topics": [
        "anonymity",
        "anticensorship",
        "censorship-circumvention",
        "security",
        "tor"
      ],
      "created_at": "2014-05-21T05:03:06Z",
      "updated_at": "2026-01-23T17:41:50Z",
      "pushed_at": "2026-01-23T14:45:28Z",
      "open_issues": 169,
      "owner": {
        "login": "guardianproject",
        "avatar_url": "https://avatars.githubusercontent.com/u/218109?v=4"
      },
      "readme": "<div align=\"center\">\n\n# [Orbot](https://orbot.app)\n\n### *Android Onion Routing Robot*\n\n[![Weblate Status](https://hosted.weblate.org/widget/guardianproject/orbot/svg-badge.svg)](https://hosted.weblate.org/engage/guardianproject/)\n[![Play Downloads](https://img.shields.io/github/downloads/guardianproject/orbot/total)](https://play.google.com/store/apps/details?id=org.torproject.android)\n[![Bitrise Status](https://img.shields.io/bitrise/0e76c31b8e7e1801?token=S2weJXueO3AvrDUrrd85SA&logo=bitrise&color=blue)](https://app.bitrise.io/app/0e76c31b8e7e1801) ([CI docs](./docs/info/CI.md))\n\nOrbot is a free VPN and proxy app that empowers other apps to use the internet more securely. Orbot uses Tor to encrypt your Internet traffic and then hides it by bouncing through a series of computers around the world. Tor is free software and an open network that helps you defend against a form of network surveillance that threatens personal freedom and privacy, confidential business activities and relationships, and state security known as traffic analysis.\n\n<img src=./fastlane/metadata/android/en-US/images/phoneScreenshots/A-orbot_connected.png width=\"19%%\"> <img src=./fastlane/metadata/android/en-US/images/phoneScreenshots/B-choose-how.png width=\"20%\">\n<img src=./fastlane/metadata/android/en-US/images/phoneScreenshots/C-Choose_Apps.png width=\"19%\">\n<img src=./fastlane/metadata/android/en-US/images/phoneScreenshots/D-kindness_mode_screen.png width=\"19%\">\n<img src=./fastlane/metadata/android/en-US/images/phoneScreenshots/E-more_screen.png width=\"19%\">\n\n</div>\n\nOrbot is a crucial component of the Guardian Project, an initiative  that leads an effort\nto develop a secure and anonymous smartphone. This platform is designed for use by human rights\nactivists, journalists and others around the world. Learn more: <https://guardianproject.info/>\n\n\nTor protects your privacy on the internet by hiding the connection\nbetween your Internet address and the services you use. We believe that Tor\nis reasonably secure, but please ensure you read the usage instructions and\nlearn to configure it properly. Learn more: <https://torproject.org/>\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <td><a href=\"https://github.com/guardianproject/orbot/releases/latest\">Download the Latest Orbot Release</a></td>\n    </tr>\n    <tr>\n      <td><a href=\"https://support.torproject.org/faq/\">Tor FAQ (Frequently Asked Questions)</a></td>\n    </tr>\n    <tr>\n      <td><a href=\"https://hosted.weblate.org/engage/guardianproject/\">Please Contribute Your Translations</a></td>\n    </tr>\n  </table>\n</div>\n\n### Build Instructions\n\nOrbot is built with [hev-socks5-tunnel](https://github.com/heiher/hev-socks5-tunnel). Before you can build Orbot, you'll need to clone the submodule\nfor this dependency. Once cloned, Android Studio + Gradle will take care of building the C code.\n\n```bash\ngit clone --recursive https://github.com/guardianproject/orbot-android\n```\n\nOr, if you already cloned the repo:\n\n```bash\ncd orbot-android\ngit pull\ngit submodule update --init --recursive\n```\n\nIf you pull and see that there are changes to `app/src/main/jni/hev-socks5-tunnel` that means that `hev-socks5-tunnel` was updated. You need to re-run `git submodule update --init --recursive` to fetch the latest changes and then rebuild Orbot.\n\n### Viewing Logs \n\nRecently `tor` was added to be its own Linux process on Android instead of having it run within the primary app process. That measn that you will no longer see logs from `tor`, `OrbotService`, `OrbotVPNManager` etc within Android Studio. In order to see these logs you can use:\n\n\n`adb logcat  --pid=$(adb shell pidof -s \"org.torproject.android.debug\") -v color` to see the app logs in your terminal\n\n`adb logcat  --pid=$(adb shell pidof -s \"org.torproject.android.debug:tor\") -v color` and to see the `tor` process logs.\n\n**There is a helper script to get both of these logs printed side-by-side with `tmux`. From the root directory run:\n\n```bash\n./scripts/view_logs_tmux.sh\n```\n\nYou may need to initially do some configuration to obtain `tmux` and add `adb` to your `PATH`:\n\n```bash\n# on Mac OS \nbrew install tmux \n\n\n# on debian + friends:\nsudo apt intstall tmux \n\n# then make sure adb is in your path in your .bashrc or similar file:\nexport ANDROID_HOME=~/Android/Sdk\nexport PATH=$PATH:$ANDROID_HOME/platform-tools\n\n\n# on mac you do the above or instead get an adb instance from brew...\nbrew install android-platform-tools\n```\n\n**Copyright &#169; 2009-2026, Nathan Freitas, The Guardian Project**\n",
      "stars_today": 6
    },
    {
      "id": 761046569,
      "name": "Xed-Editor",
      "full_name": "Xed-Editor/Xed-Editor",
      "description": "Advanced Text Editor for Android ",
      "html_url": "https://github.com/Xed-Editor/Xed-Editor",
      "stars": 1605,
      "forks": 99,
      "language": "Java",
      "topics": [
        "android",
        "android-app",
        "android-application",
        "android-studio",
        "code",
        "code-editor",
        "code-editor-mobile",
        "codeeditor",
        "fileviewer",
        "mobile-ide",
        "note-taking",
        "notes-app",
        "text-editing",
        "text-editor",
        "todo-app",
        "todoapp",
        "todolist"
      ],
      "created_at": "2024-02-21T06:15:55Z",
      "updated_at": "2026-01-23T17:03:58Z",
      "pushed_at": "2026-01-22T10:01:58Z",
      "open_issues": 38,
      "owner": {
        "login": "Xed-Editor",
        "avatar_url": "https://avatars.githubusercontent.com/u/184326269?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"/fastlane/metadata/android/en-US/images/icon.png\" alt=\"Xed-Editor Icon\" width=\"90\" height=\"90\"/>\n</p>\n\n<h2 align=\"center\"><b>Xed-Editor</b></h2>\n\n<div align=\"center\">\n  <img src=\"https://img.shields.io/github/downloads/Xed-Editor/Xed-Editor/total?label=Downloads\" alt=\"Download Count\">\n  <img src=\"https://github.com/Rohitkushvaha01/Xed-Editor/actions/workflows/android.yml/badge.svg?event=push\" alt=\"CI\">\n</div>\n\n**Xed-Editor** is a versatile text editor for Android, offering advanced functionality such as\nsyntax highlighting, extensive customization options, and a streamlined interface for efficient\nediting.\n\n> **We are looking for contributors/maintainers to help keep the project alive and speed up the\ndevelopment. You can help by fixing bugs, implementing & improving features, etc.**\n\n---\n\n## üìñ Documentation\n\nTo learn more about Xed-Editor‚Äòs features and usage, visit the official\ndocumentation: https://xed-editor.github.io/Xed-Docs/\n\n---\n\n## üåç Community\n\n> [!TIP]\n> Join the Xed-Editor community to stay updated and engage with other users:\n\n- [Telegram](https://t.me/XedEditor)\n- [Discord](https://discord.gg/6bKzcQRuef)\n\n---\n\n## ‚¨áÔ∏è Download\n\n<div>\n  <a href=\"https://android.izzysoft.de/repo/apk/com.rk.xededitor\">\n    <img src=\"https://img.shields.io/endpoint?url=https://apt.izzysoft.de/fdroid/api/v1/shield/com.rk.xededitor&label=IzzyOnDroid&cacheSeconds=33000\">\n  </a>\n  <a href=\"https://f-droid.org/packages/com.rk.xededitor\">\n    <img src=\"https://img.shields.io/f-droid/v/com.rk.xededitor\">\n  </a>\n</div>\n\n- **Latest Alpha Build**: Download from [Actions](https://github.com/Xed-Editor/Xed-Editor/actions/)\n- **Latest Stable Build**: Download\n  from [Releases](https://github.com/Xed-Editor/Xed-Editor/releases)\n\n[<img src=\"https://fdroid.gitlab.io/artwork/badge/get-it-on.png\" alt=\"Get it on F-Droid\" height=\"80\">](https://f-droid.org/packages/com.rk.xededitor)\n[<img src=\"https://gitlab.com/IzzyOnDroid/repo/-/raw/master/assets/IzzyOnDroid.png?ref_type=heads\" alt=\"Get it on IzzyOnDroid\" height=\"80\">](https://apt.izzysoft.de/fdroid/index/apk/com.rk.xededitor)\n[<img src=\"https://raw.githubusercontent.com/Kunzisoft/Github-badge/main/get-it-on-github.png\" alt=\"Get it on GitHub\" height=\"80\">](https://github.com/Xed-Editor/Xed-Editor/releases/latest)\n\n---\n\n## üì∑ Screenshots\n\n<div>\n  <img src=\"/fastlane/metadata/android/en-US/images/phoneScreenshots/01.jpg\" width=\"32%\" />\n  <img src=\"/fastlane/metadata/android/en-US/images/phoneScreenshots/02.jpg\" width=\"32%\" />\n  <img src=\"/fastlane/metadata/android/en-US/images/phoneScreenshots/03.jpg\" width=\"32%\" />\n</div>\n<div>\n  <img src=\"/fastlane/metadata/android/en-US/images/phoneScreenshots/04.jpg\" width=\"32%\" />\n  <img src=\"/fastlane/metadata/android/en-US/images/phoneScreenshots/05.jpg\" width=\"32%\" />\n  <img src=\"/fastlane/metadata/android/en-US/images/phoneScreenshots/06.jpg\" width=\"32%\" />\n</div>\n\n---\n\n## ü§ù Contributing\n\nWe welcome contributions! Please read the [CONTRIBUTING.md](/docs/CONTRIBUTING.md) file to learn how\nyou can get involved.\n\n---\n\n## üåê Translations\n\nTranslate Xed-Editor! Visit [Weblate](https://hosted.weblate.org/engage/xed-editor/) to get\ninvolved:\n\n<a href=\"https://hosted.weblate.org/engage/xed-editor/\">\n    <img src=\"https://hosted.weblate.org/widgets/xed-editor/-/multi-auto.svg\" alt=\"Translation Status\">\n</a>\n\n---\n\n## :heart: Find this app useful?\n\nSupport it by giving a star :star: <br>\nAlso, **__[follow](https://github.com/Rohitkushvaha01)__** me for my next creations!\n\n---\n\n## üë• Contributors\n\n<a href=\"https://github.com/Xed-Editor/Xed-Editor/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=Xed-Editor/Xed-Editor\" />\n</a>\n",
      "stars_today": 6
    },
    {
      "id": 1048623630,
      "name": "ArchiveTune",
      "full_name": "koiverse/ArchiveTune",
      "description": "The cutest Material 3 Expressive music streaming client for Android, built for performance and extensibility.",
      "html_url": "https://github.com/koiverse/ArchiveTune",
      "stars": 409,
      "forks": 14,
      "language": "Kotlin",
      "topics": [
        "android-application",
        "android-studio",
        "foss",
        "jetpack-compose",
        "kotlin",
        "material3",
        "music-player-foss",
        "nvvm",
        "streaming-apps",
        "youtube-music-client"
      ],
      "created_at": "2025-09-01T18:42:42Z",
      "updated_at": "2026-01-24T00:40:54Z",
      "pushed_at": "2026-01-23T23:52:32Z",
      "open_issues": 14,
      "owner": {
        "login": "koiverse",
        "avatar_url": "https://avatars.githubusercontent.com/u/107134739?v=4"
      },
      "readme": "<div align=\"center\">\n\n  <img src=\"https://github.com/koiverse/ArchiveTune/blob/main/fastlane/metadata/android/en-US/images/icon.png\" width=\"160\" height=\"160\" alt=\"ArchiveTune Logo\" style=\"border-radius: 22%\">\n\n  <h1>ArchiveTune</h1>\n\n  <p align=\"center\">\n    <strong>Redefining the YouTube Music Experience on Android.</strong>\n    <br />\n    <em>High-performance. Privacy-centric. Audiophile-grade features.</em>\n  </p>\n\n  <p align=\"center\">\n    <a href=\"https://archivetune.koiiverse.cloud\"><b>Official Website</b></a> ‚Ä¢\n    <a href=\"#-key-highlights\"><b>Features</b></a> ‚Ä¢\n    <a href=\"#-installation\"><b>Download</b></a> ‚Ä¢\n    <a href=\"#-showcase\"><b>Showcase</b></a> ‚Ä¢\n    <a href=\"https://github.com/koiverse/ArchiveTune/issues/new/choose\"><b>Support</b></a>\n  </p>\n\n  <div align=\"center\">\n    <img src=\"https://img.shields.io/github/v/release/koiverse/ArchiveTune?style=for-the-badge&color=6366f1&labelColor=1e1e2e&logo=github\" alt=\"Latest Version\" />\n    <img src=\"https://img.shields.io/github/downloads/koiverse/ArchiveTune/total?style=for-the-badge&color=6366f1&labelColor=1e1e2e&logo=github\" alt=\"Downloads\" />\n    <img src=\"https://img.shields.io/github/stars/koiverse/ArchiveTune?style=for-the-badge&color=6366f1&labelColor=1e1e2e&logo=github\" alt=\"Stars\" />\n    <img src=\"https://img.shields.io/github/license/koiverse/ArchiveTune?style=for-the-badge&color=6366f1&labelColor=1e1e2e\" alt=\"License\" />\n    <img src=\"https://img.shields.io/badge/Architecture-MVVM-6366f1?style=for-the-badge&labelColor=1e1e2e&logo=kotlin\" alt=\"MVVM Architecture\" />\n    <img src=\"https://img.shields.io/badge/Language-Kotlin-7f52ff?style=for-the-badge&logo=kotlin&color=6366f1&labelColor=1e1e2e\" alt=\"Kotlin Language\" />\n    <img src=\"https://img.shields.io/badge/Toolkit-Jetpack_Compose-4285f4?style=for-the-badge&logo=jetpack-compose&color=6366f1&labelColor=1e1e2e\" alt=\"Jetpack Compose Toolkit\" />\n    <img src=\"https://img.shields.io/badge/Design-Material_3-000000?style=for-the-badge&logo=material-design&color=6366f1&labelColor=1e1e2e\" alt=\"Material Design 3\" />\n  </div>\n  \n  <br />\n\n  <a href=\"https://trendshift.io/repositories/17521\" target=\"_blank\">\n    <img src=\"https://trendshift.io/api/badge/repositories/17521\" alt=\"ArchiveTune | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/>\n  </a>\n</div>\n\n<hr />\n\n**ArchiveTune** isn't just a wrapper‚Äîit's a precision-engineered music ecosystem. We believe your music library should be private, beautiful, and powerful. Designed for power users who refuse to compromise on audio quality or UI aesthetics.\n\n---\n\n### üöÄ Core Experience\n* **Ad-Free Core:** A pure, uninterrupted listening experience.\n* **Deep Library Sync:** Instant access to your Liked Songs, Playlists, and Subscriptions.\n* **Smart Caching:** High-speed playback with intelligent data management.\n* **Background Mastery:** Optimized background playback that respects your battery.\n\n### üéöÔ∏è Professional Audio Suite\n* **Loudness Normalization:** Industry-standard volume leveling (EBU R128).\n* **Precision Control:** On-the-fly **Tempo & Pitch** manipulation for musicians and DJs.\n* **The \"Gapless\" Flow:** Integrated **Crossfade** and **Silence Skipping**.\n* **System EQ Bridge:** Seamlessly integrates with system-level equalizers and spatial audio.\n\n### üé® Visual & Identity\n* **Material You (MD3E):** The UI breathes through your wallpaper‚Äôs color palette.\n* **Synced Lyrics:** Beautiful, word-by-word playback with translation & romanization.\n* **Music Insights:** Native \"Year in Review\" and real-time listening statistics.\n* **Discord RPC:** Show the world your vibe with high-quality Rich Presence.\n\n---\n\n## üì∏ Showcase\n\n<div align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/koiverse/ArchiveTune/refs/heads/dev/fastlane/metadata/android/en-US/images/ArchiveTuneBanner.png\" alt=\"ArchiveTune Banner\" style=\"width: 100%; max-width: 400px; border-radius: 12px;\">\n  <table border=\"0\">\n    <tr>\n      <td><img src=\"https://github.com/koiverse/ArchiveTune/blob/main/fastlane/metadata/android/en-US/images/phoneScreenshots/screenshot_1.jpg\" width=\"180\" style=\"border-radius: 12px;\"></td>\n      <td><img src=\"https://github.com/koiverse/ArchiveTune/blob/main/fastlane/metadata/android/en-US/images/phoneScreenshots/screenshot_2.jpg\" width=\"180\" style=\"border-radius: 12px;\"></td>\n      <td><img src=\"https://github.com/koiverse/ArchiveTune/blob/main/fastlane/metadata/android/en-US/images/phoneScreenshots/screenshot_3.jpg\" width=\"180\" style=\"border-radius: 12px;\"></td>\n      <td><img src=\"https://github.com/koiverse/ArchiveTune/blob/main/fastlane/metadata/android/en-US/images/phoneScreenshots/screenshot_4.jpg\" width=\"180\" style=\"border-radius: 12px;\"></td>\n      <td><img src=\"https://github.com/koiverse/ArchiveTune/blob/main/fastlane/metadata/android/en-US/images/phoneScreenshots/screenshot_5.jpg\" width=\"180\" style=\"border-radius: 12px;\"></td>\n      <td><img src=\"https://github.com/koiverse/ArchiveTune/blob/main/fastlane/metadata/android/en-US/images/phoneScreenshots/screenshot_6.jpg\" width=\"180\" style=\"border-radius: 12px;\"></td>\n    </tr>\n    <tr align=\"center\">\n      <td><sub>Player</sub></td>\n      <td><sub>Live Lyrics</sub></td>\n      <td><sub>Theme Customization</sub></td>\n      <td><sub>Live Statistics</sub></td>\n      <td><sub>Artist UI</sub></td>\n      <td><sub>Album UI</sub></td>\n    </tr>\n  </table>\n</div>\n\n---\n\n## üì• Installation\n\n<table>\n  <tr>\n    <td align=\"center\">\n      <a href=\"https://github.com/koiverse/ArchiveTune/releases/latest\">\n        <img src=\"https://raw.githubusercontent.com/koiverse/ArchiveTune/refs/heads/main/assets/badge_github.png\" height=\"40\" alt=\"Get it on GitHub\">\n      </a>\n    </td>\n    <td align=\"center\">\n      <a href=\"https://apt.izzysoft.de/fdroid/index/apk/moe.koiverse.archivetune\">\n        <img src=\"https://raw.githubusercontent.com/koiverse/ArchiveTune/757d5932832e1da27ced56de98c5ad1275cf0db1/assets/IzzyOnDroidButtonBorder.svg\" height=\"40\" alt=\"Get it on IzzyOnDroid\">\n      </a>\n    </td>\n    <td align=\"center\">\n      <a href=\"https://www.openapk.net/archivetune/moe.koiverse.archivetune/\">\n        <img src=\"https://www.openapk.net/images/openapk-badge.png\" height=\"60\" alt=\"Get it on OpenAPK\">\n      </a>\n    </td>\n  </tr>\n</table>\n\n\n\n> [!IMPORTANT]  \n> **Geographic Availability:** If YouTube Music is not supported in your region, a VPN or Proxy set to a supported region is required for initial data fetching.\n\n---\n\n## üåç Globalization\n\nArchiveTune belongs to everyone. Help us localize the experience for your region.\n\n<div align=\"center\">\n  <a href=\"https://translate.codeberg.org/engage/archivetune/\">\n    <img src=\"https://translate.codeberg.org/widget/archivetune/horizontal-blue.svg\" alt=\"Translation status\" />\n  </a>\n</div>\n\n### ‚ú® Project Contributors\n<a href=\"https://github.com/koiverse/ArchiveTune/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=koiverse/ArchiveTune\" />\n</a>\n\n### üõ†Ô∏è Development & Engineering\nInterested in building the project or contributing? ArchiveTune is built on a high-performance Kotlin stack.\n<a href=\"BUILDING.md\"><b>Read the Build & Contribution Guide ‚Üí</b></a>\n\n---\n\n## ü§ù Acknowledgments\n\nWe stand on the shoulders of open-source giants:\n- **Metrolist** by [Mostafa Alagamy](https://github.com/mostafaalagamy/Metrolist) For Base framework.\n- **Kizzy** by [dead8309](https://github.com/dead8309/Kizzy) For Discord Integration.\n- **SimpMusic** by [maxrave-dev](https://github.com/maxrave-dev/SimpMusic) For Lyrics API Provider.\n- [BetterLyrics](https://better-lyrics.boidu.dev/) For word-by-word Lyrics API Provider.\n- [Material Color Utilities](https://github.com/material-foundation/material-color-utilities)\n- [Read You](https://github.com/Ashinch/ReadYou) and [Seal](https://github.com/JunkFood02/Seal) for Ui Components.\n- The global community of translators and beta testers.\n\n---\n\n## ‚öñÔ∏è Legal Disclaimer\n\nArchiveTune is an independent third-party client.\n- Not affiliated with Google LLC or YouTube.\n- Does not bypass YouTube's technical protections.\n- Users are encouraged to support artists by purchasing music via official channels.\n\n---\n\n<div align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/koiverse/ArchiveTune/refs/heads/dev/fastlane/metadata/android/en-US/images/ArchiveTuneFull.png\" alt=\"ArchiveTune Banner\" style=\"width: 100%; max-width: 500px;\">\n  <p><b>If ArchiveTune elevated your music experience, please consider giving us a ‚≠ê</b></p>\n  <br />\n  Made with üíú by <strong>Koiverse</strong>\n</div>",
      "stars_today": 6
    },
    {
      "id": 12574344,
      "name": "cobra",
      "full_name": "spf13/cobra",
      "description": "A Commander for modern Go CLI interactions",
      "html_url": "https://github.com/spf13/cobra",
      "stars": 42963,
      "forks": 3043,
      "language": "Go",
      "topics": [
        "cli",
        "cli-app",
        "cobra",
        "cobra-generator",
        "cobra-library",
        "command",
        "command-cobra",
        "command-line",
        "commandline",
        "go",
        "golang",
        "golang-application",
        "golang-library",
        "posix",
        "posix-compliant-flags",
        "subcommands"
      ],
      "created_at": "2013-09-03T20:40:26Z",
      "updated_at": "2026-01-24T00:31:40Z",
      "pushed_at": "2025-12-10T02:18:50Z",
      "open_issues": 342,
      "owner": {
        "login": "spf13",
        "avatar_url": "https://avatars.githubusercontent.com/u/173412?v=4"
      },
      "readme": "<div align=\"center\">\n<a href=\"https://cobra.dev\">\n<img width=\"512\" height=\"535\" alt=\"cobra-logo\" src=\"https://github.com/user-attachments/assets/c8bf9aad-b5ae-41d3-8899-d83baec10af8\" />\n</a>\n</div>\n\nCobra is a library for creating powerful modern CLI applications.\n\n<a href=\"https://cobra.dev\">Visit Cobra.dev for extensive documentation</a> \n\n\nCobra is used in many Go projects such as [Kubernetes](https://kubernetes.io/),\n[Hugo](https://gohugo.io), and [GitHub CLI](https://github.com/cli/cli) to\nname a few. [This list](site/content/projects_using_cobra.md) contains a more extensive list of projects using Cobra.\n\n[![](https://img.shields.io/github/actions/workflow/status/spf13/cobra/test.yml?branch=main&longCache=true&label=Test&logo=github%20actions&logoColor=fff)](https://github.com/spf13/cobra/actions?query=workflow%3ATest)\n[![Go Reference](https://pkg.go.dev/badge/github.com/spf13/cobra.svg)](https://pkg.go.dev/github.com/spf13/cobra)\n[![Go Report Card](https://goreportcard.com/badge/github.com/spf13/cobra)](https://goreportcard.com/report/github.com/spf13/cobra)\n[![Slack](https://img.shields.io/badge/Slack-cobra-brightgreen)](https://gophers.slack.com/archives/CD3LP1199)\n<hr>\n<div align=\"center\" markdown=\"1\">\n   <sup>Supported by:</sup>\n   <br>\n   <br>\n   <a href=\"https://www.warp.dev/cobra\">\n      <img alt=\"Warp sponsorship\" width=\"400\" src=\"https://github.com/user-attachments/assets/ab8dd143-b0fd-4904-bdc5-dd7ecac94eae\">\n   </a>\n\n### [Warp, the AI terminal for devs](https://www.warp.dev/cobra)\n[Try Cobra in Warp today](https://www.warp.dev/cobra)<br>\n\n</div>\n<hr>\n\n# Overview\n\nCobra is a library providing a simple interface to create powerful modern CLI\ninterfaces similar to git & go tools.\n\nCobra provides:\n* Easy subcommand-based CLIs: `app server`, `app fetch`, etc.\n* Fully POSIX-compliant flags (including short & long versions)\n* Nested subcommands\n* Global, local and cascading flags\n* Intelligent suggestions (`app srver`... did you mean `app server`?)\n* Automatic help generation for commands and flags\n* Grouping help for subcommands\n* Automatic help flag recognition of `-h`, `--help`, etc.\n* Automatically generated shell autocomplete for your application (bash, zsh, fish, powershell)\n* Automatically generated man pages for your application\n* Command aliases so you can change things without breaking them\n* The flexibility to define your own help, usage, etc.\n* Optional seamless integration with [viper](https://github.com/spf13/viper) for 12-factor apps\n\n# Concepts\n\nCobra is built on a structure of commands, arguments & flags.\n\n**Commands** represent actions, **Args** are things and **Flags** are modifiers for those actions.\n\nThe best applications read like sentences when used, and as a result, users\nintuitively know how to interact with them.\n\nThe pattern to follow is\n`APPNAME VERB NOUN --ADJECTIVE`\n    or\n`APPNAME COMMAND ARG --FLAG`.\n\nA few good real world examples may better illustrate this point.\n\nIn the following example, 'server' is a command, and 'port' is a flag:\n\n    hugo server --port=1313\n\nIn this command we are telling Git to clone the url bare.\n\n    git clone URL --bare\n\n## Commands\n\nCommand is the central point of the application. Each interaction that\nthe application supports will be contained in a Command. A command can\nhave children commands and optionally run an action.\n\nIn the example above, 'server' is the command.\n\n[More about cobra.Command](https://pkg.go.dev/github.com/spf13/cobra#Command)\n\n## Flags\n\nA flag is a way to modify the behavior of a command. Cobra supports\nfully POSIX-compliant flags as well as the Go [flag package](https://golang.org/pkg/flag/).\nA Cobra command can define flags that persist through to children commands\nand flags that are only available to that command.\n\nIn the example above, 'port' is the flag.\n\nFlag functionality is provided by the [pflag\nlibrary](https://github.com/spf13/pflag), a fork of the flag standard library\nwhich maintains the same interface while adding POSIX compliance.\n\n# Installing\nUsing Cobra is easy. First, use `go get` to install the latest version\nof the library.\n\n```\ngo get -u github.com/spf13/cobra@latest\n```\n\nNext, include Cobra in your application:\n\n```go\nimport \"github.com/spf13/cobra\"\n```\n\n# Usage\n`cobra-cli` is a command line program to generate cobra applications and command files.\nIt will bootstrap your application scaffolding to rapidly\ndevelop a Cobra-based application. It is the easiest way to incorporate Cobra into your application.\n\nIt can be installed by running:\n\n```\ngo install github.com/spf13/cobra-cli@latest\n```\n\nFor complete details on using the Cobra-CLI generator, please read [The Cobra Generator README](https://github.com/spf13/cobra-cli/blob/main/README.md)\n\nFor complete details on using the Cobra library, please read [The Cobra User Guide](site/content/user_guide.md).\n\n# License\n\nCobra is released under the Apache 2.0 license. See [LICENSE.txt](LICENSE.txt)\n",
      "stars_today": 5
    },
    {
      "id": 7056202,
      "name": "fmt",
      "full_name": "fmtlib/fmt",
      "description": "A modern formatting library",
      "html_url": "https://github.com/fmtlib/fmt",
      "stars": 23190,
      "forks": 2813,
      "language": "C++",
      "topics": [
        "c-plus-plus",
        "chrono",
        "cpp",
        "cross-platform",
        "floating-point",
        "formatting",
        "multiplatform",
        "output",
        "performance",
        "printf",
        "ranges",
        "unicode"
      ],
      "created_at": "2012-12-07T16:26:46Z",
      "updated_at": "2026-01-24T01:16:09Z",
      "pushed_at": "2026-01-22T19:24:11Z",
      "open_issues": 11,
      "owner": {
        "login": "fmtlib",
        "avatar_url": "https://avatars.githubusercontent.com/u/7280830?v=4"
      },
      "readme": "<img src=\"https://user-images.githubusercontent.com/576385/156254208-f5b743a9-88cf-439d-b0c0-923d53e8d551.png\" alt=\"{fmt}\" width=\"25%\"/>\n\n[![image](https://github.com/fmtlib/fmt/workflows/linux/badge.svg)](https://github.com/fmtlib/fmt/actions?query=workflow%3Alinux)\n[![image](https://github.com/fmtlib/fmt/workflows/macos/badge.svg)](https://github.com/fmtlib/fmt/actions?query=workflow%3Amacos)\n[![image](https://github.com/fmtlib/fmt/workflows/windows/badge.svg)](https://github.com/fmtlib/fmt/actions?query=workflow%3Awindows)\n[![fmt is continuously fuzzed at oss-fuzz](https://oss-fuzz-build-logs.storage.googleapis.com/badges/fmt.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?\\%0Acolspec=ID%20Type%20Component%20Status%20Proj%20Reported%20Owner%20\\%0ASummary&q=proj%3Dfmt&can=1)\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/8880/badge)](https://www.bestpractices.dev/projects/8880)\n[![image](https://api.securityscorecards.dev/projects/github.com/fmtlib/fmt/badge)](https://securityscorecards.dev/viewer/?uri=github.com/fmtlib/fmt)\n[![Ask questions at StackOverflow with the tag fmt](https://img.shields.io/badge/stackoverflow-fmt-blue.svg)](https://stackoverflow.com/questions/tagged/fmt)\n\n**{fmt}** is an open-source formatting library providing a fast and safe\nalternative to C stdio and C++ iostreams.\n\nIf you like this project, please consider donating to one of the funds\nthat help victims of the war in Ukraine: <https://u24.gov.ua/>.\n\n[Documentation](https://fmt.dev)\n\n[Cheat Sheets](https://hackingcpp.com/cpp/libs/fmt.html)\n\nQ&A: ask questions on [StackOverflow with the tag\nfmt](https://stackoverflow.com/questions/tagged/fmt).\n\nTry {fmt} in [Compiler Explorer](https://godbolt.org/z/8Mx1EW73v).\n\n# Features\n\n- Simple [format API](https://fmt.dev/latest/api/) with positional\n  arguments for localization\n- Implementation of [C++20\n  std::format](https://en.cppreference.com/w/cpp/utility/format) and\n  [C++23 std::print](https://en.cppreference.com/w/cpp/io/print)\n- [Format string syntax](https://fmt.dev/latest/syntax/) similar\n  to Python\\'s\n  [format](https://docs.python.org/3/library/stdtypes.html#str.format)\n- Fast IEEE 754 floating-point formatter with correct rounding,\n  shortness and round-trip guarantees using the\n  [Dragonbox](https://github.com/jk-jeon/dragonbox) algorithm\n- Portable Unicode support\n- Safe [printf\n  implementation](https://fmt.dev/latest/api/#printf-formatting)\n  including the POSIX extension for positional arguments\n- Extensibility: [support for user-defined\n  types](https://fmt.dev/latest/api/#formatting-user-defined-types)\n- High performance: faster than common standard library\n  implementations of `(s)printf`, iostreams, `to_string` and\n  `to_chars`, see [Speed tests](#speed-tests) and [Converting a\n  hundred million integers to strings per\n  second](http://www.zverovich.net/2020/06/13/fast-int-to-string-revisited.html)\n- Small code size both in terms of source code with the minimum\n  configuration consisting of just three files, `base.h`, `format.h`\n  and `format-inl.h`, and compiled code; see [Compile time and code\n  bloat](#compile-time-and-code-bloat)\n- Reliability: the library has an extensive set of\n  [tests](https://github.com/fmtlib/fmt/tree/master/test) and is\n  [continuously fuzzed](https://bugs.chromium.org/p/oss-fuzz/issues/list?colspec=ID%20Type%20Component%20Status%20Proj%20Reported%20Owner%20Summary&q=proj%3Dfmt&can=1)\n- Safety: the library is fully type-safe, errors in format strings can\n  be reported at compile time, automatic memory management prevents\n  buffer overflow errors\n- Ease of use: small self-contained code base, no external\n  dependencies, permissive MIT\n  [license](https://github.com/fmtlib/fmt/blob/master/LICENSE)\n- [Portability](https://fmt.dev/latest/#portability) with\n  consistent output across platforms and support for older compilers\n- Clean warning-free codebase even on high warning levels such as\n  `-Wall -Wextra -pedantic`\n- Locale independence by default\n- Optional header-only configuration enabled with the\n  `FMT_HEADER_ONLY` macro\n\nSee the [documentation](https://fmt.dev) for more details.\n\n# Examples\n\n**Print to stdout** ([run](https://godbolt.org/z/Tevcjh))\n\n``` c++\n#include <fmt/base.h>\n\nint main() {\n  fmt::print(\"Hello, world!\\n\");\n}\n```\n\n**Format a string** ([run](https://godbolt.org/z/oK8h33))\n\n``` c++\nstd::string s = fmt::format(\"The answer is {}.\", 42);\n// s == \"The answer is 42.\"\n```\n\n**Format a string using positional arguments**\n([run](https://godbolt.org/z/Yn7Txe))\n\n``` c++\nstd::string s = fmt::format(\"I'd rather be {1} than {0}.\", \"right\", \"happy\");\n// s == \"I'd rather be happy than right.\"\n```\n\n**Print dates and times** ([run](https://godbolt.org/z/c31ExdY3W))\n\n``` c++\n#include <fmt/chrono.h>\n\nint main() {\n  auto now = std::chrono::system_clock::now();\n  fmt::print(\"Date and time: {}\\n\", now);\n  fmt::print(\"Time: {:%H:%M}\\n\", now);\n}\n```\n\nOutput:\n\n    Date and time: 2023-12-26 19:10:31.557195597\n    Time: 19:10\n\n**Print a container** ([run](https://godbolt.org/z/MxM1YqjE7))\n\n``` c++\n#include <vector>\n#include <fmt/ranges.h>\n\nint main() {\n  std::vector<int> v = {1, 2, 3};\n  fmt::print(\"{}\\n\", v);\n}\n```\n\nOutput:\n\n    [1, 2, 3]\n\n**Check a format string at compile time**\n\n``` c++\nstd::string s = fmt::format(\"{:d}\", \"I am not a number\");\n```\n\nThis gives a compile-time error in C++20 because `d` is an invalid\nformat specifier for a string.\n\n**Write a file from a single thread**\n\n``` c++\n#include <fmt/os.h>\n\nint main() {\n  auto out = fmt::output_file(\"guide.txt\");\n  out.print(\"Don't {}\", \"Panic\");\n}\n```\n\nThis can be [up to 9 times faster than `fprintf`](\nhttp://www.zverovich.net/2020/08/04/optimal-file-buffer-size.html).\n\n**Print with colors and text styles**\n\n``` c++\n#include <fmt/color.h>\n\nint main() {\n  fmt::print(fg(fmt::color::crimson) | fmt::emphasis::bold,\n             \"Hello, {}!\\n\", \"world\");\n  fmt::print(fg(fmt::color::floral_white) | bg(fmt::color::slate_gray) |\n             fmt::emphasis::underline, \"Ol√°, {}!\\n\", \"Mundo\");\n  fmt::print(fg(fmt::color::steel_blue) | fmt::emphasis::italic,\n             \"‰Ω†Â•Ω{}ÔºÅ\\n\", \"‰∏ñÁïå\");\n}\n```\n\nOutput on a modern terminal with Unicode support:\n\n![image](https://github.com/fmtlib/fmt/assets/%0A576385/2a93c904-d6fa-4aa6-b453-2618e1c327d7)\n\n# Benchmarks\n\n## Speed tests\n\n| Library           | Method        | Run Time, s |\n|-------------------|---------------|-------------|\n| libc              | printf        |   0.66      |\n| libc++            | std::ostream  |   1.63      |\n| {fmt} 12.1        | fmt::print    |   0.44      |\n| Boost Format 1.88 | boost::format |   3.89      |\n| Folly Format      | folly::format |   1.28      |\n\n{fmt} is the fastest of the benchmarked methods, \\~50% faster than\n`printf`.\n\nThe above results were generated by building `tinyformat_test.cpp` on\nmacOS 15.6.1 with `clang++ -O3 -DNDEBUG -DSPEED_TEST -DHAVE_FORMAT`, and\ntaking the best of three runs. In the test, the format string\n`\"%0.10f:%04d:%+g:%s:%p:%c:%%\\n\"` or equivalent is filled 2,000,000\ntimes with output sent to `/dev/null`; for further details refer to the\n[source](https://github.com/fmtlib/format-benchmark/blob/master/src/tinyformat-test.cc).\n\n{fmt} is up to 20-30x faster than `std::ostringstream` and `sprintf` on\nIEEE754 `float` and `double` formatting\n([dtoa-benchmark](https://github.com/fmtlib/dtoa-benchmark)) and faster\nthan [double-conversion](https://github.com/google/double-conversion)\nand [ryu](https://github.com/ulfjack/ryu):\n\n[![image](https://user-images.githubusercontent.com/576385/95684665-11719600-0ba8-11eb-8e5b-972ff4e49428.png)](https://fmt.dev/unknown_mac64_clang12.0.html)\n\n## Compile time and code bloat\n\nThe script [bloat-test.py][test] from [format-benchmark][bench] tests compile\ntime and code bloat for nontrivial projects. It generates 100 translation units\nand uses `printf()` or its alternative five times in each to simulate a\nmedium-sized project. The resulting executable size and compile time (Apple\nclang version 15.0.0 (clang-1500.1.0.2.5), macOS Sonoma, best of three) is shown\nin the following tables.\n\n[test]: https://github.com/fmtlib/format-benchmark/blob/master/bloat-test.py\n[bench]: https://github.com/fmtlib/format-benchmark\n\n**Optimized build (-O3)**\n\n| Method          | Compile Time, s | Executable size, KiB | Stripped size, KiB |\n|-----------------|-----------------|----------------------|--------------------|\n| printf          |             1.6 |                   54 |                 50 |\n| IOStreams       |            28.4 |                   98 |                 84 |\n| {fmt} `1122268` |             5.0 |                   54 |                 50 |\n| tinyformat      |            32.6 |                  164 |                136 |\n| Boost Format    |            55.0 |                  530 |                317 |\n\n{fmt} is fast to compile and is comparable to `printf` in terms of per-call\nbinary size (within a rounding error on this system).\n\n**Non-optimized build**\n\n| Method          | Compile Time, s | Executable size, KiB | Stripped size, KiB |\n|-----------------|-----------------|----------------------|--------------------|\n| printf          |             1.4 |                   54 |                 50 |\n| IOStreams       |            27.0 |                   88 |                 68 |\n| {fmt} `1122268` |             4.7 |                   87 |                 84 |\n| tinyformat      |            28.1 |                  185 |                145 |\n| Boost Format    |            38.9 |                  678 |                381 |\n\n`libc`, `lib(std)c++`, and `libfmt` are all linked as shared libraries\nto compare formatting function overhead only. Boost Format is a\nheader-only library so it doesn\\'t provide any linkage options.\n\n## Running the tests\n\nPlease refer to [Building the\nlibrary](https://fmt.dev/latest/get-started/#building-from-source) for\ninstructions on how to build the library and run the unit tests.\n\nBenchmarks reside in a separate repository,\n[format-benchmarks](https://github.com/fmtlib/format-benchmark), so to\nrun the benchmarks you first need to clone this repository and generate\nMakefiles with CMake:\n\n    $ git clone --recursive https://github.com/fmtlib/format-benchmark.git\n    $ cd format-benchmark\n    $ cmake .\n\nThen you can run the speed test:\n\n    $ make speed-test\n\nor the bloat test:\n\n    $ make bloat-test\n\n# Migrating code\n\n[clang-tidy](https://clang.llvm.org/extra/clang-tidy/) v18 provides the\n[modernize-use-std-print](https://clang.llvm.org/extra/clang-tidy/checks/modernize/use-std-print.html)\ncheck that is capable of converting occurrences of `printf` and\n`fprintf` to `fmt::print` if configured to do so. (By default it\nconverts to `std::print`.)\n\n# Notable projects using this library\n\n- [0 A.D.](https://play0ad.com/): a free, open-source, cross-platform\n  real-time strategy game\n- [AMPL/MP](https://github.com/ampl/mp): an open-source library for\n  mathematical programming\n- [Apple's FoundationDB](https://github.com/apple/foundationdb): an open-source,\n  distributed, transactional key-value store\n- [Aseprite](https://github.com/aseprite/aseprite): animated sprite\n  editor & pixel art tool\n- [AvioBook](https://www.aviobook.aero/en): a comprehensive aircraft\n  operations suite\n- [Blizzard Battle.net](https://battle.net/): an online gaming\n  platform\n- [Celestia](https://celestia.space/): real-time 3D visualization of\n  space\n- [Ceph](https://ceph.com/): a scalable distributed storage system\n- [ccache](https://ccache.dev/): a compiler cache\n- [ClickHouse](https://github.com/ClickHouse/ClickHouse): an\n  analytical database management system\n- [ContextVision](https://www.contextvision.com/): medical imaging software\n- [Contour](https://github.com/contour-terminal/contour/): a modern\n  terminal emulator\n- [CUAUV](https://cuauv.org/): Cornell University\\'s autonomous\n  underwater vehicle\n- [Drake](https://drake.mit.edu/): a planning, control, and analysis\n  toolbox for nonlinear dynamical systems (MIT)\n- [Envoy](https://github.com/envoyproxy/envoy): C++ L7 proxy and\n  communication bus (Lyft)\n- [FiveM](https://fivem.net/): a modification framework for GTA V\n- [fmtlog](https://github.com/MengRao/fmtlog): a performant\n  fmtlib-style logging library with latency in nanoseconds\n- [Folly](https://github.com/facebook/folly): Facebook open-source\n  library\n- [GemRB](https://gemrb.org/): a portable open-source implementation\n  of Bioware's Infinity Engine\n- [Grand Mountain\n  Adventure](https://store.steampowered.com/app/1247360/Grand_Mountain_Adventure/):\n  a beautiful open-world ski & snowboarding game\n- [HarpyWar/pvpgn](https://github.com/pvpgn/pvpgn-server): Player vs\n  Player Gaming Network with tweaks\n- [KBEngine](https://github.com/kbengine/kbengine): an open-source\n  MMOG server engine\n- [Keypirinha](https://keypirinha.com/): a semantic launcher for\n  Windows\n- [Kodi](https://kodi.tv/) (formerly xbmc): home theater software\n- [Knuth](https://kth.cash/): high-performance Bitcoin full-node\n- [libunicode](https://github.com/contour-terminal/libunicode/): a\n  modern C++17 Unicode library\n- [MariaDB](https://mariadb.org/): relational database management\n  system\n- [Microsoft Verona](https://github.com/microsoft/verona): research\n  programming language for concurrent ownership\n- [MongoDB](https://mongodb.com/): distributed document database\n- [MongoDB Smasher](https://github.com/duckie/mongo_smasher): a small\n  tool to generate randomized datasets\n- [OpenSpace](https://openspaceproject.com/): an open-source\n  astrovisualization framework\n- [PenUltima Online (POL)](https://www.polserver.com/): an MMO server,\n  compatible with most Ultima Online clients\n- [PyTorch](https://github.com/pytorch/pytorch): an open-source\n  machine learning library\n- [quasardb](https://www.quasardb.net/): a distributed,\n  high-performance, associative database\n- [Quill](https://github.com/odygrd/quill): asynchronous low-latency\n  logging library\n- [QKW](https://github.com/ravijanjam/qkw): generalizing aliasing to\n  simplify navigation, and execute complex multi-line terminal\n  command sequences\n- [redis-cerberus](https://github.com/HunanTV/redis-cerberus): a Redis\n  cluster proxy\n- [redpanda](https://vectorized.io/redpanda): a 10x faster Kafka¬Æ\n  replacement for mission-critical systems written in C++\n- [rpclib](http://rpclib.net/): a modern C++ msgpack-RPC server and\n  client library\n- [Salesforce Analytics\n  Cloud](https://www.salesforce.com/analytics-cloud/overview/):\n  business intelligence software\n- [Scylla](https://www.scylladb.com/): a Cassandra-compatible NoSQL\n  data store that can handle 1 million transactions per second on a\n  single server\n- [Seastar](http://www.seastar-project.org/): an advanced, open-source\n  C++ framework for high-performance server applications on modern\n  hardware\n- [spdlog](https://github.com/gabime/spdlog): super fast C++ logging\n  library\n- [Stellar](https://www.stellar.org/): financial platform\n- [Touch Surgery](https://www.touchsurgery.com/): surgery simulator\n- [TrinityCore](https://github.com/TrinityCore/TrinityCore):\n  open-source MMORPG framework\n- [üêô userver framework](https://userver.tech/): open-source\n  asynchronous framework with a rich set of abstractions and database\n  drivers\n- [Windows Terminal](https://github.com/microsoft/terminal): the new\n  Windows terminal\n\n[More\\...](https://github.com/search?q=fmtlib&type=Code)\n\nIf you are aware of other projects using this library, please let me\nknow by [email](mailto:victor.zverovich@gmail.com) or by submitting an\n[issue](https://github.com/fmtlib/fmt/issues).\n\n# Motivation\n\nSo why yet another formatting library?\n\nThere are plenty of methods for doing this task, from standard ones like\nthe printf family of function and iostreams to Boost Format and\nFastFormat libraries. The reason for creating a new library is that\nevery existing solution that I found either had serious issues or\ndidn\\'t provide all the features I needed.\n\n## printf\n\nThe good thing about `printf` is that it is pretty fast and readily\navailable being a part of the C standard library. The main drawback is\nthat it doesn\\'t support user-defined types. `printf` also has safety\nissues although they are somewhat mitigated with [\\_\\_attribute\\_\\_\n((format (printf,\n\\...))](https://gcc.gnu.org/onlinedocs/gcc/Function-Attributes.html) in\nGCC. There is a POSIX extension that adds positional arguments required\nfor\n[i18n](https://en.wikipedia.org/wiki/Internationalization_and_localization)\nto `printf` but it is not a part of C99 and may not be available on some\nplatforms.\n\n## iostreams\n\nThe main issue with iostreams is best illustrated with an example:\n\n``` c++\nstd::cout << std::setprecision(2) << std::fixed << 1.23456 << \"\\n\";\n```\n\nwhich is a lot of typing compared to printf:\n\n``` c++\nprintf(\"%.2f\\n\", 1.23456);\n```\n\nMatthew Wilson, the author of FastFormat, called this \\\"chevron hell\\\".\niostreams don\\'t support positional arguments by design.\n\nThe good part is that iostreams support user-defined types and are safe\nalthough error handling is awkward.\n\n## Boost Format\n\nThis is a very powerful library that supports both `printf`-like format\nstrings and positional arguments. Its main drawback is performance.\nAccording to various benchmarks, it is much slower than other methods\nconsidered here. Boost Format also has excessive build times and severe\ncode bloat issues (see [Benchmarks](#benchmarks)).\n\n## FastFormat\n\nThis is an interesting library that is fast, safe and has positional\narguments. However, it has significant limitations, citing its author:\n\n> Three features that have no hope of being accommodated within the\n> current design are:\n>\n> - Leading zeros (or any other non-space padding)\n> - Octal/hexadecimal encoding\n> - Runtime width/alignment specification\n\nIt is also quite big and has a heavy dependency, on STLSoft, which might be\ntoo restrictive for use in some projects.\n\n## Boost Spirit.Karma\n\nThis is not a formatting library but I decided to include it here for\ncompleteness. As iostreams, it suffers from the problem of mixing\nverbatim text with arguments. The library is pretty fast, but slower on\ninteger formatting than `fmt::format_to` with format string compilation\non Karma\\'s own benchmark, see [Converting a hundred million integers to\nstrings per\nsecond](http://www.zverovich.net/2020/06/13/fast-int-to-string-revisited.html).\n\n# License\n\n{fmt} is distributed under the MIT\n[license](https://github.com/fmtlib/fmt/blob/master/LICENSE).\n\n# Documentation License\n\nThe [Format String Syntax](https://fmt.dev/latest/syntax/) section\nin the documentation is based on the one from Python [string module\ndocumentation](https://docs.python.org/3/library/string.html#module-string).\nFor this reason, the documentation is distributed under the Python\nSoftware Foundation license available in\n[doc/python-license.txt](https://raw.github.com/fmtlib/fmt/master/doc/python-license.txt).\nIt only applies if you distribute the documentation of {fmt}.\n\n# Maintainers\n\nThe {fmt} library is maintained by Victor Zverovich\n([vitaut](https://github.com/vitaut)) with contributions from many other\npeople. See\n[Contributors](https://github.com/fmtlib/fmt/graphs/contributors) and\n[Releases](https://github.com/fmtlib/fmt/releases) for some of the\nnames. Let us know if your contribution is not listed or mentioned\nincorrectly and we\\'ll make it right.\n\n# Security Policy\n\nTo report a security issue, please disclose it at [security\nadvisory](https://github.com/fmtlib/fmt/security/advisories/new).\n\nThis project is maintained by a team of volunteers on a\nreasonable-effort basis. As such, please give us at least *90* days to\nwork on a fix before public exposure.\n",
      "stars_today": 5
    },
    {
      "id": 51905353,
      "name": "arrow",
      "full_name": "apache/arrow",
      "description": "Apache Arrow is the universal columnar format and multi-language toolbox for fast data interchange and in-memory analytics",
      "html_url": "https://github.com/apache/arrow",
      "stars": 16428,
      "forks": 3992,
      "language": "C++",
      "topics": [
        "arrow",
        "parquet"
      ],
      "created_at": "2016-02-17T08:00:23Z",
      "updated_at": "2026-01-23T22:21:20Z",
      "pushed_at": "2026-01-23T22:21:11Z",
      "open_issues": 4065,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "<!---\n  Licensed to the Apache Software Foundation (ASF) under one\n  or more contributor license agreements.  See the NOTICE file\n  distributed with this work for additional information\n  regarding copyright ownership.  The ASF licenses this file\n  to you under the Apache License, Version 2.0 (the\n  \"License\"); you may not use this file except in compliance\n  with the License.  You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing,\n  software distributed under the License is distributed on an\n  \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n  KIND, either express or implied.  See the License for the\n  specific language governing permissions and limitations\n  under the License.\n-->\n\n# Apache Arrow\n\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/arrow.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:arrow)\n[![License](https://img.shields.io/:license-Apache%202-blue.svg)](https://github.com/apache/arrow/blob/main/LICENSE.txt)\n[![BlueSky Follow](https://img.shields.io/badge/bluesky-Follow-blue?logo=bluesky)](https://bsky.app/profile/arrow.apache.org)\n\n## Powering In-Memory Analytics\n\nApache Arrow is a universal columnar format and multi-language toolbox for fast\ndata interchange and in-memory analytics. It contains a set of technologies that\nenable data systems to efficiently store, process, and move data.\n\nMajor components of the project include:\n\n - [The Arrow Columnar Format](https://arrow.apache.org/docs/dev/format/Columnar.html):\n   a standard and efficient in-memory representation of various datatypes, plain or nested\n - [The Arrow IPC Format](https://arrow.apache.org/docs/dev/format/Columnar.html#serialization-and-interprocess-communication-ipc):\n   an efficient serialization of the Arrow format and associated metadata,\n   for communication between processes and heterogeneous environments\n - [ADBC (Arrow Database Connectivity)](https://github.com/apache/arrow-adbc/) `‚Üó`: Arrow-powered API,\n   drivers, and libraries for access to databases and query engines\n - [The Arrow Flight RPC protocol](https://github.com/apache/arrow/tree/main/format/Flight.proto):\n   based on the Arrow IPC format, a building block for remote services exchanging\n   Arrow data with application-defined semantics (for example a storage server or a database)\n - [C++ libraries](https://github.com/apache/arrow/tree/main/cpp)\n - [C bindings using GLib](https://github.com/apache/arrow/tree/main/c_glib)\n - [.NET libraries](https://github.com/apache/arrow-dotnet) `‚Üó`\n - [Gandiva](https://github.com/apache/arrow/tree/main/cpp/src/gandiva):\n   an [LLVM](https://llvm.org)-based Arrow expression compiler, part of the C++ codebase\n - [Go libraries](https://github.com/apache/arrow-go) `‚Üó`\n - [Java libraries](https://github.com/apache/arrow-java) `‚Üó`\n - [JavaScript libraries](https://github.com/apache/arrow-js) `‚Üó`\n - [Julia implementation](https://github.com/apache/arrow-julia) `‚Üó`\n - [Python libraries](https://github.com/apache/arrow/tree/main/python)\n - [R libraries](https://github.com/apache/arrow/tree/main/r)\n - [Ruby libraries](https://github.com/apache/arrow/tree/main/ruby)\n - [Rust libraries](https://github.com/apache/arrow-rs) `‚Üó`\n - [Swift libraries](https://github.com/apache/arrow-swift) `‚Üó`\n\nThe `‚Üó` icon denotes that this component of the project is maintained in a separate\nrepository.\n\nArrow is an [Apache Software Foundation](https://www.apache.org) project. Learn more at\n[arrow.apache.org](https://arrow.apache.org).\n\n## What's in the Arrow libraries?\n\nThe reference Arrow libraries contain many distinct software components:\n\n- Columnar vector and table-like containers (similar to data frames) supporting\n  flat or nested types\n- Fast, language agnostic metadata messaging layer (using Google's FlatBuffers\n  library)\n- Reference-counted off-heap buffer memory management, for zero-copy memory\n  sharing and handling memory-mapped files\n- IO interfaces to local and remote filesystems\n- Self-describing binary wire formats (streaming and batch/file-like) for\n  remote procedure calls (RPC) and interprocess communication (IPC)\n- Integration tests for verifying binary compatibility between the\n  implementations (e.g. sending data from Java to C++)\n- Conversions to and from other in-memory data structures\n- Readers and writers for various widely-used file formats (such as Parquet, CSV)\n\n## Implementation status\n\nThe official Arrow libraries in this repository are in different stages of\nimplementing the Arrow format and related features.  See our current\n[feature matrix](https://arrow.apache.org/docs/dev/status.html)\non git main.\n\n## How to Contribute\n\nPlease read our latest [project contribution guide][4].\n\n## Getting involved\n\nEven if you do not plan to contribute to Apache Arrow itself or Arrow\nintegrations in other projects, we'd be happy to have you involved:\n\n- Join the mailing list: send an email to\n  [dev-subscribe@arrow.apache.org][1]. Share your ideas and use cases for the\n  project.\n- Follow our activity on [GitHub issues][3]\n- [Learn the format][2]\n- Contribute code to one of the reference implementations\n\n## Continuous Integration Sponsors\n\nWe use [runs-on][5] for managing the project self-hosted runners.\nWe use [AWS][6] for some of the required infrastructure for the project.\n\n[1]: mailto:dev-subscribe@arrow.apache.org\n[2]: https://github.com/apache/arrow/tree/main/format\n[3]: https://github.com/apache/arrow/issues\n[4]: https://arrow.apache.org/docs/dev/developers/index.html\n[5]: https://runs-on.com/\n[6]: https://aws.amazon.com/\n",
      "stars_today": 5
    },
    {
      "id": 46374199,
      "name": "librealsense",
      "full_name": "realsenseai/librealsense",
      "description": "RealSense SDK",
      "html_url": "https://github.com/realsenseai/librealsense",
      "stars": 8490,
      "forks": 4975,
      "language": "C++",
      "topics": [
        "camera-api",
        "computer-vision",
        "developer-kits",
        "hardware",
        "library",
        "librealsense",
        "sdk"
      ],
      "created_at": "2015-11-17T20:42:18Z",
      "updated_at": "2026-01-23T15:18:41Z",
      "pushed_at": "2026-01-22T14:59:19Z",
      "open_issues": 431,
      "owner": {
        "login": "realsenseai",
        "avatar_url": "https://avatars.githubusercontent.com/u/204379195?v=4"
      },
      "readme": "<p align=\"center\">\n<!-- Light mode -->\n<img src=\"doc/img/realsense-logo-light-mode.png#gh-light-mode-only\" alt=\"Logo for light mode\" width=\"30%\"/>\n\n<!-- Dark mode -->\n<img src=\"doc/img/realsense-logo-dark-mode.png#gh-dark-mode-only\" alt=\"Logo for dark mode\" width=\"30%\"/>\n<br><br>\n</p>\n\n<p align=\"center\">RealSense SDK 2.0 is a cross-platform library for RealSense depth cameras.\nThe SDK allows depth and color streaming, and provides intrinsic and extrinsic calibration information.</p>\n\n\n<p align=\"center\">\n  <a href=\"https://www.apache.org/licenses/LICENSE-2.0\"><img src=\"https://img.shields.io/github/license/realsenseai/librealsense.svg\" alt=\"License\"></a>\n  <a href=\"https://github.com/realsenseai/librealsense/releases/latest\"><img src=\"https://img.shields.io/github/v/release/realsenseai/librealsense?sort=semver\" alt=\"Latest release\"></a>\n  <a href=\"https://github.com/realsenseai/librealsense/compare/master...development\"><img src=\"https://img.shields.io/github/commits-since/realsenseai/librealsense/master/development?label=commits%20since\" alt=\"Commits since\"></a>\n  <a href=\"https://github.com/realsenseai/librealsense/issues\"><img src=\"https://img.shields.io/github/issues/realsenseai/librealsense.svg\" alt=\"Issues\"></a>\n  <a href=\"https://github.com/realsenseai/librealsense/actions/workflows/buildsCI.yaml?query=branch%3Adevelopment\"><img src=\"https://github.com/realsenseai/librealsense/actions/workflows/buildsCI.yaml/badge.svg?branch=development\" alt=\"GitHub CI\"></a>\n  <a href=\"https://github.com/realsenseai/librealsense/network/members\"><img src=\"https://img.shields.io/github/forks/realsenseai/librealsense.svg\" alt=\"Forks\"></a>\n</p>\n\n## Important Notice\n\nWe are happy to announce that the RealSense GitHub repositories have been successfully migrated to the RealSenseAI organization.\nPlease make sure to update your links to the new RealSenseAI organization for both cloning the repositories and accessing specific files within them.\n\n[https://github.com/**IntelRealSense**/librealsense](https://github.com/IntelRealSense/librealsense) --> [https://github.com/**realsenseai**/librealsense](https://github.com/realsenseai/librealsense)\n\nNote: A redirection from the previous name IntelRealSense is currently in place, but we cannot guarantee how long it will remain active. We recommend that all users update their references to point to the new GitHub location.\n\n#### Branch Policy\nWe have updated our branch policy:\nFrom now on, we will also push beta releases to the master branch, so users can access up-to-date code and features.\nIn the near future, beta binaries will also be pushed to public distribution servers (e.g., APT).\nThe last validated official release can be found on our Releases page on GitHub.\n\n## Use Cases\n\nBelow are some of the many real-world applications powered by RealSense technology:\n\nRobotics | Depth Sensing | 3D Scanning |\n:------------: | :----------: | :-------------: |\n<a href=\"https://realsenseai.com/case-studies/?capability_application=autonomous-mobile-robots\"><img src=\"https://librealsense.realsenseai.com/readme-media/realsense_examplerealsense_example.gif\" width=\"240\"/></a> |<a href=\"https://realsenseai.com/case-studies/?q=/case-studies&\"><img src=\"https://librealsense.realsenseai.com/readme-media/align-expectede.gif\" width=\"240\"/></a> | <a href=\"https://realsenseai.com/case-studies/?capability_application=autonomous-mobile-robots\"><img src=\"https://librealsense.realsenseai.com/readme-media/realsense_dynamic_example.gif\" width=\"240\"/></a>\n\nDrones | Skeletal and People Tracking | Facial Authentication |\n:--------------------------: | :-----: | :----------------------: |\n<a href=\"https://realsenseai.com/case-studies/?q=/case-studies&\"><img src=\"https://librealsense.realsenseai.com/readme-media/drone-demo.gif\" width=\"240\"/></a> |<a href=\"https://realsenseai.com/case-studies/?capability_application=monitoring-and-tracking\"><img src=\"https://librealsense.realsenseai.com/readme-media/SkeletalTracking.gif\" width=\"240\"/></a> | <a href=\"https://realsenseai.com/case-studies/?capability_application=biometrics\"><img src=\"https://librealsense.realsenseai.com/readme-media/face-demo.gif\" width=\"240\"/></a>\n\n\n\n## Why RealSense?\n\n- **High-resolution color and depth** at close and long ranges\n- **Open source SDK** with rich examples and wrappers (Python, ROS, C#, Unity and [more...](https://github.com/realsenseai/librealsense/tree/master/wrappers))\n- **Active developer community and defacto-standard 3D stereo camera for robotics**\n- **Cross-platform** support: Windows, Linux, macOS, Android, and Docker\n\n## Product Line\n\nRealSense stereo depth products use stereo vision to calculate depth, providing high-quality performance in various lighting and environmental conditions.\n\nHere are some examples of the supported models:\n\n| Product | Image | Description |\n|---------|-------|-------------|\n| [**D555 PoE**](https://realsenseai.com/ruggedized-industrial-stereo-depth/d555-poe/) | <img src=\"https://realsenseai.com/wp-content/uploads/2025/07/D555.png\" width=\"1000\"> | The RealSense‚Ñ¢ Depth Camera D555 introduces Power over Ethernet (PoE) interface on chip, expanding our portfolio of USB and GMSL/FAKRA products. |\n| [**D457 GMSL/FAKRA**](https://realsenseai.com/ruggedized-industrial-stereo-depth/d457-gmsl-fakra/) | <img src=\"https://realsenseai.com/wp-content/uploads/2025/07/D457.png\" width=\"1000\"> | The RealSense‚Ñ¢ Depth Camera D457 is our first GMSL/FAKRA high bandwidth stereo camera. The D457 has an IP65 grade enclosure protecting it from dust ingress and projected water. |\n| [**D455**](https://realsenseai.com/stereo-depth-cameras/real-sense-depth-camera-d455/) | <img src=\"https://www.realsenseai.com/wp-content/uploads/2021/11/455.png\" width=\"1000\"> | The RealSense D455 is a long-range stereo depth camera with a 95 mm baseline, global-shutter depth sensors, an RGB sensor, and a built-in IMU, delivering accurate depth at distances up to 10 m.. |\n| [**D435if**](https://realsenseai.com/stereo-depth-cameras/depth-camera-d435i/) | <img src=\"https://realsenseai.com/wp-content/uploads/2025/06/D435if-a.png\" width=\"1000\"> | The D435if is one of [RealSense‚Ñ¢ Depth Camera with IR pass filter family](https://realsenseai.com/stereo-depth-with-ir-pass-filter/) expanding our portfolio targeting the growing robotic market. The D400f family utilizes an IR pass filter to enhance depth quality and performance range in many robotic environments.|\n| [**D405**](https://realsenseai.com/stereo-depth-cameras/stereo-depth-camera-d405/) | <img src=\"https://realsenseai.com/wp-content/uploads/2025/07/D-405.png\" width=\"1000\"> | The RealSense‚Ñ¢ Depth Camera D405 is a short-range stereo camera providing sub-millimeter accuracy for your close-range computer vision needs. |\n\n\n> üõçÔ∏è [Explore more stereo products](https://store.realsenseai.com/)\n\n## Getting Started\n\nStart developing with RealSense in minutes using either method below.\n\n### 1Ô∏è. Precompiled SDK\n\nThis is the best option if you want to plug in your camera and get started right away.\n1. Download the latest SDK bundle from the [Releases page](https://github.com/realsenseai/librealsense/releases).\n2. Connect your RealSense camera.\n3. Run the included tools:\n    - [RealSense Viewer](./tools/realsense-viewer/): View streams, tune settings, record and playback.\n    - [Depth Quality Tool](./tools/depth-quality/): Measure accuracy and fill rate.\n\n### Setup Guides - precompiled SDK\n\n<a href=\"./doc/distribution_linux.md\"><img src=\"https://img.shields.io/badge/Ubuntu_Guide-333?style=flat&logo=ubuntu&logoColor=white\" style=\"margin: 5px;\" alt=\"Linux\\Jetson Guide\"/></a>\n<a href=\"./doc/distribution_windows.md\"><img src=\"https://custom-icon-badges.demolab.com/badge/Windows_Guide-333?logo=windows11&logoColor=white\" style=\"margin: 5px;\" alt=\"Windows Guide\"/></a>\n\n> **Note:** For **minor releases**, we publish Debian packages as release artifacts that you can download and install directly.\n\n### 2Ô∏è. Build from Source\nFor a more custom installation, follow these steps to build the SDK from source.\n1. Clone the repository and create a build directory:\n   ```bash\n   git clone https://github.com/realsenseai/librealsense.git\n   cd librealsense\n   mkdir build && cd build\n   ```\n2. Run CMake to configure the build:\n    ```bash\n    cmake ..\n    ```\n3. Build the project:\n    ```bash\n    cmake --build .\n    ```\n\n### Setup Guides - build from source\n\n<a href=\"./doc/installation.md\"><img src=\"https://img.shields.io/badge/Ubuntu_Guide-333?style=flat&logo=ubuntu&logoColor=white\" style=\"margin: 5px;\" alt=\"Linux Guide\"/></a>\n<a href=\"./doc/installation_jetson.md\"><img src=\"https://img.shields.io/badge/Jetson_Guide-333?style=flat&logo=nvidia&logoColor=white\" style=\"margin: 5px;\" alt=\"Jetson Guide\"/></a>\n<a href=\"./doc/installation_windows.md\"><img src=\"https://custom-icon-badges.demolab.com/badge/Windows_Guide-333?logo=windows11&logoColor=white\" style=\"margin: 5px;\" alt=\"Windows Guide\"/></a>\n<a href=\"./doc/installation_osx.md\"><img src=\"https://img.shields.io/badge/macOS_Guide-333?style=flat&logo=apple&logoColor=white\" style=\"margin: 5px;\" alt=\"macOS Guide\"/></a>\n\n\n## Python Packages\n[![pyrealsense2](https://img.shields.io/pypi/v/pyrealsense2.svg?label=pyrealsense2&logo=pypi)](https://pypi.org/project/pyrealsense2/)\n[![PyPI - pyrealsense2-beta](https://img.shields.io/pypi/v/pyrealsense2-beta.svg?label=pyrealsense2-beta&logo=pypi)](https://pypi.org/project/pyrealsense2-beta/)\n\n**Which should I use?**\n- **Stable:** `pyrealsense2` ‚Äî validated releases aligned with SDK tags (Recommended for most users).  \n- **Beta:** `pyrealsense2-beta` ‚Äî fresher builds for early access and testing. Expect faster updates.  \n\n### Install\n```bash\npip install pyrealsense2 # Stable\npip install pyrealsense2-beta # Beta\n```\n> Both packages import as `pyrealsense2`. Install **only one** at a time.\n\n## Ready to Hack!\n\nOur library offers a high level API for using RealSense depth cameras (in addition to lower level ones).\nThe following snippets show how to start streaming frames and extracting the depth value of a pixel:\n\n**C++**\n```cpp\n#include <librealsense2/rs.hpp>\n#include <iostream>\n\nint main() {\n    rs2::pipeline p;                 // Top-level API for streaming & processing frames\n    p.start();                       // Configure and start the pipeline\n\n    while (true) {\n        rs2::frameset frames = p.wait_for_frames();        // Block until frames arrive\n        rs2::depth_frame depth = frames.get_depth_frame(); // Get depth frame\n        if (!depth) continue;\n\n        int w = depth.get_width(), h = depth.get_height();\n        float dist = depth.get_distance(w/2, h/2);         // Distance to center pixel\n        std::cout << \"The camera is facing an object \" << dist << \" meters away\\r\";\n    }\n}\n```\n\n**Python**\n```python\nimport pyrealsense2 as rs\n\npipeline = rs.pipeline() # Create a pipeline\npipeline.start() # Start streaming\n\ntry:\n    while True:\n        frames = pipeline.wait_for_frames()\n        depth_frame = frames.get_depth_frame()\n        if not depth_frame:\n            continue\n\n        width, height = depth_frame.get_width(), depth_frame.get_height()\n        dist = depth_frame.get_distance(width // 2, height // 2)\n        print(f\"The camera is facing an object {dist:.3f} meters away\", end=\"\\r\")\n\nfinally:\n    pipeline.stop() # Stop streaming\n```\n\nFor more information on the library, please follow our [examples](./examples) or [tools](./tools/), and read the [documentation](./doc) to learn more.\n\n## Supported Platforms\n\n### Operating Systems and Platforms\n\n| Ubuntu | Windows | macOS High Sierra | Jetson | Raspberry Pi |\n|--------|---------|-------|--------|----------------|\n| <div align=\"center\"><a href=\"https://dev.realsenseai.com/docs/compiling-librealsense-for-linux-ubuntu-guide\"><img src=\"https://librealsense.realsenseai.com/readme-media/ubuntu.png\" width=\"40%\" alt=\"Ubuntu\" /></a></div> | <div align=\"center\"><a href=\"https://dev.realsenseai.com/docs/compiling-librealsense-for-windows-guide\"><img src=\"https://librealsense.realsenseai.com/readme-media/Windows_logo.png\" width=\"40%\" alt=\"Windows\" /></a></div> | <div align=\"center\"><a href=\"https://dev.realsenseai.com/docs/macos-installation-for-intel-realsense-sdk\"><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"https://librealsense.realsenseai.com/readme-media/apple-dark.png\"><img src=\"https://librealsense.realsenseai.com/readme-media/apple-light.png\" width=\"40%\" alt=\"macOS\" /></picture></a></div> | <div align=\"center\"><a href=\"https://dev.realsenseai.com/docs/nvidia-jetson-tx2-installation\"><img src=\"https://librealsense.realsenseai.com/readme-media/nvidia.png\" width=\"40%\" alt=\"\" /></a></div> | <div align=\"center\"><a href=\"https://dev.realsenseai.com/docs/using-depth-camera-with-raspberry-pi-3\"><img src=\"https://librealsense.realsenseai.com/readme-media/raspberry-pi.png\" width=\"40%\" alt=\"\" /></a></div> \n\n\n\n### Programming Languages and Wrappers\n\n| C++ | C | C# | Python | ROS 2 |Rest API |\n|-----|---|----|--------|-------|---------|\n| <div align=\"center\"><a href=\"https://dev.realsenseai.com/docs/code-samples\"><img src=\"https://librealsense.realsenseai.com/readme-media/cpp.png\" width=\"50%\" alt=\"\" /></a></div> | <div align=\"center\"><a href=\"https://dev.realsenseai.com/docs/code-samples\"><img src=\"https://librealsense.realsenseai.com/readme-media/c.png\" width=\"55%\" alt=\"\" /></a></div> | <div align=\"center\"><a href=\"https://dev.realsenseai.com/docs/csharp-wrapper\"><img src=\"https://librealsense.realsenseai.com/readme-media/c-sharp.png\" width=\"50%\" alt=\"\" /></a></div> | <div align=\"center\"><a href=\"https://dev.realsenseai.com/docs/python2\"><img src=\"https://librealsense.realsenseai.com/readme-media/python.png\" width=\"30%\" alt=\"\" /></a></div> | <div align=\"center\"><a href=\"https://dev.realsenseai.com/docs/ros2-wrapper\"><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"https://librealsense.realsenseai.com/readme-media/ros2-dark.png\"><img src=\"https://librealsense.realsenseai.com/readme-media/ROS2-light.png\" width=\"80%\" alt=\"ROS 2\" /></picture></a></div> | <div align=\"center\"><a href=\"https://github.com/realsenseai/librealsense/blob/development/wrappers/rest-api/README.md\"><img src=\"https://librealsense.realsenseai.com/readme-media/REST_API.png\" width=\"50%\" alt=\"Rest API\" /></a></div>|\n\nFor more platforms and wrappers look over [here](https://dev.realsenseai.com/docs/docs-get-started).\n> Full feature support varies by platform ‚Äì refer to the [release notes](https://github.com/realsenseai/librealsense/wiki/Release-Notes) for details.\n\n## Community & Support\n\n- [üìö Wiki & Docs](https://github.com/realsenseai/librealsense/wiki)\n- [üêû Report Issues](https://github.com/realsenseai/librealsense/issues)- Found a bug or want to contribute? Read our [contribution guidelines](./CONTRIBUTING.md).\n\n> üîé Looking for legacy devices (F200, R200, LR200, ZR300)? Visit the [legacy release](https://github.com/realsenseai/librealsense/tree/v1.12.1).\n\n---\n<p align=\"center\">\nYou can find us at\n</p>\n<p align=\"center\">\n  <a href=\"https://github.com/realsenseai\" target=\"_blank\" aria-label=\"GitHub\"><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"https://librealsense.realsenseai.com/readme-media/github_light.PNG\"><img src=\"https://librealsense.realsenseai.com/readme-media/github.png\" width=\"32\" alt=\"GitHub\"></picture></a>\n  &nbsp;&nbsp;&nbsp;\n  <a href=\"https://x.com/RealSenseai\" target=\"_blank\" aria-label=\"X (Twitter)\"><img src=\"https://librealsense.realsenseai.com/readme-media/twitter.png\" width=\"32\" alt=\"X (Twitter)\" /></a>\n  &nbsp;&nbsp;&nbsp;\n  <a href=\"https://www.youtube.com/@RealSenseai\" target=\"_blank\" aria-label=\"YouTube\"><img src=\"https://librealsense.realsenseai.com/readme-media/social.png\" width=\"32\" alt=\"YouTube\" /></a>\n  &nbsp;&nbsp;&nbsp;\n  <a href=\"https://www.linkedin.com/company/realsenseai?trk=similar-pages\" target=\"_blank\" aria-label=\"LinkedIn\"><img src=\"https://librealsense.realsenseai.com/readme-media/linkedin.png\" width=\"32\" alt=\"LinkedIn\" /></a>\n  &nbsp;&nbsp;&nbsp;\n  <a href=\"https://realsenseai.com/\" target=\"_blank\" aria-label=\"Community\"><img src=\"https://librealsense.realsenseai.com/readme-media/Real-sense-badge-rgb-c.png\" width=\"32\" alt=\"Community\" /></a>\n</p>\n\n\n\n",
      "stars_today": 5
    },
    {
      "id": 129990396,
      "name": "rust-by-practice",
      "full_name": "sunface/rust-by-practice",
      "description": "Learning Rust By Practice,  narrowing the gap between beginner and skilled-dev through challenging examples, exercises and projects.",
      "html_url": "https://github.com/sunface/rust-by-practice",
      "stars": 13923,
      "forks": 1139,
      "language": "Rust",
      "topics": [
        "example",
        "examples",
        "exercise",
        "exercises",
        "learning",
        "practice",
        "rust",
        "study"
      ],
      "created_at": "2018-04-18T02:13:19Z",
      "updated_at": "2026-01-24T02:04:16Z",
      "pushed_at": "2025-11-26T04:06:45Z",
      "open_issues": 64,
      "owner": {
        "login": "sunface",
        "avatar_url": "https://avatars.githubusercontent.com/u/7036754?v=4"
      },
      "readme": "<div align=\"center\">\n    <img src=\"https://github.com/sunface/rust-by-practice/blob/master/en/assets/header.jpg?raw=true\">\n</div>\n\n<p align=\"center\">\n    <span>English</span>\n    <span> | </span>\n    <a href=\"https://github.com/sunface/rust-by-practice/blob/master/zh-CN/src/why-exercise.md\">‰∏≠Êñá</a>\n</p>\n    \n<p align=\"center\">Practice Rust with challenging examples, exercises and projects</p>\n    \n<div align=\"center\">\n\n[![Stars Count](https://img.shields.io/github/stars/sunface/rust-by-practice?style=flat)](https://github.com/sunface/rust-by-practice/stargazers) \n[![studyrut](https://img.shields.io/badge/RustCn-orange)](https://hirust.cn) \n[![LICENSE](https://img.shields.io/badge/license-CC_BY_4.0-green?style=flat)](https://github.com/sunface/rust-by-practice/blob/master/LICENSE)\n</div>\n\nThis book was designed for easily diving into and getting skilled with Rust It's very easy to use. All you need to do is to make each exercise compile without ERRORS and Panics!\n\n\n## Reading online\n\n- [https://practice.rs](https://practice.rs)\n\n## Features\n\nPart of our examples and exercises are borrowed from [Rust By Example](https://github.com/rust-lang/rust-by-example), thanks for your great works!\n\nAlthough they are so awesome, we have our own secret weapons :)\n\n- There are three parts in each chapter: examples, exercises and practices\n\n- Besides examples, we have `a lot of exercises`, you can Read, Edit and Run them ONLINE\n\n- Covering nearly all aspects of Rust, such as async/await, threads, sync primitives, optimizing, standard libraries, tool chain, data structures and algorithms etc.\n\n- Every exercise has its own solutions\n\n- The overall difficulties are a bit higher and from easy to super hard: easy üåü medium üåüüåü hard üåüüåüüåü super hard üåüüåüüåüüåü\n\n**What we want to do is fill in the gap between learning and getting started with real projects.**\n\n## üèÖ Contributors\n\nThanks to all of our [contributors](https://github.com/sunface/rust-by-practice/graphs/contributors)!\n\n<br />\n\n**üèÜ Special thanks to our English editor:**\n<table>\n    <tr>\n        <td align=\"center\">\n            <a href=\"https://github.com/Tanish-Eagle\">\n                <img src=\"https://avatars.githubusercontent.com/u/71984506?v=4?s=100\" width=\"160px\"   alt=\"\"/>\n                <br />\n                <sub><b>Tanish-Eagle</b></sub>\n            </a>\n        </td>\n    </tr>\n</table>\n\n<br />\n\n## Running locally\n\nWe use [mdbook](https://rust-lang.github.io/mdBook/) building our exercises. You can run locally with below steps:\n\n- Clone the repo\n```shell\n$ git clone https://github.com/sunface/rust-by-practice\n```\n- Install mdbook using Cargo\n```shell\n$ cargo install mdbook\n```\n\n- For Book in English\n```shell\n$ cd rust-by-practice && mdbook serve en/\n```\n\n- For Book in Chinese\n```shell\n$ cd rust-by-practice && mdbook serve zh-CN/\n```\n\n## Some of our exercises\n\nüåüüåüüåü Tuple struct looks similar to tuples, it has added meaning the struct name provides but has no named fields. It's useful when you want give the whole tuple a name, but don't care the fields's names.\n\n```rust\n\n// fix the error and fill the blanks\nstruct Color(i32, i32, i32);\nstruct Point(i32, i32, i32);\nfn main() {\n    let v = Point(___, ___, ___);\n    check_color(v);\n}\n\nfn check_color(p: Color) {\n    let (x, _, _) = p;\n    assert_eq!(x, 0);\n    assert_eq!(p.1, 127);\n    assert_eq!(___, 255);\n }\n```\n\nüåüüåü Within the destructuring of a single variable, both by-move and by-reference pattern bindings can be used at the same time. Doing this will result in a partial move of the variable, which means that parts of the variable will be moved while other parts stay. In such a case, the parent variable cannot be used afterwards as a whole, however the parts that are only referenced (and not moved) can still be used.\n```rust\n\n// fix errors to make it work\n#[derive(Debug)]\nstruct File {\n    name: String,\n    data: String,\n}\nfn main() {\n    let f = File {\n        name: String::from(\"readme.md\"),\n        data: \"Rust By Practice\".to_string()\n    };\n\n    let _name = f.name;\n\n    // ONLY modify this line\n    println!(\"{}, {}, {:?}\",f.name, f.data, f);\n}\n```\n\nüåüüåü A match guard is an additional if condition specified after the pattern in a match arm that must also match, along with the pattern matching, for that arm to be chosen.\n```rust,editable\n\n// fill in the blank to make the code work, `split` MUST be used\nfn main() {\n    let num = Some(4);\n    let split = 5;\n    match num {\n        Some(x) __ => assert!(x < split),\n        Some(x) => assert!(x >= split),\n        None => (),\n    }\n}\n```\n",
      "stars_today": 5
    },
    {
      "id": 130578889,
      "name": "smartdns",
      "full_name": "pymumu/smartdns",
      "description": "A local DNS server to obtain the fastest website IP for the best Internet experience, support DoT, DoH, DoQ. ‰∏Ä‰∏™Êú¨Âú∞DNSÊúçÂä°Âô®ÔºåËé∑ÂèñÊúÄÂø´ÁöÑÁΩëÁ´ôIPÔºåËé∑ÂæóÊúÄ‰Ω≥‰∏äÁΩë‰ΩìÈ™åÔºåÊîØÊåÅDoHÔºåDoTÔºåDoQ„ÄÇ",
      "html_url": "https://github.com/pymumu/smartdns",
      "stars": 10491,
      "forks": 1215,
      "language": "C",
      "topics": [
        "c",
        "dns",
        "dns-over-https",
        "dns-over-tls",
        "dns-server",
        "dns64",
        "doh",
        "doh3",
        "doq",
        "dot",
        "nftables",
        "nftables-sets",
        "openwrt",
        "openwrt-package",
        "smartdns",
        "stubby"
      ],
      "created_at": "2018-04-22T15:09:47Z",
      "updated_at": "2026-01-23T17:31:19Z",
      "pushed_at": "2026-01-23T14:34:15Z",
      "open_issues": 255,
      "owner": {
        "login": "pymumu",
        "avatar_url": "https://avatars.githubusercontent.com/u/3275997?v=4"
      },
      "readme": "# SmartDNS\n\n**[English](ReadMe_en.md)**\n\n![SmartDNS](doc/smartdns-banner.png)\nSmartDNS ÊòØ‰∏Ä‰∏™ËøêË°åÂú®Êú¨Âú∞ÁöÑ DNS ÊúçÂä°Âô®ÔºåÂÆÉÊé•ÂèóÊù•Ëá™Êú¨Âú∞ÂÆ¢Êà∑Á´ØÁöÑ DNS Êü•ËØ¢ËØ∑Ê±ÇÔºåÁÑ∂Âêé‰ªéÂ§ö‰∏™‰∏äÊ∏∏ DNS ÊúçÂä°Âô®Ëé∑Âèñ DNS Êü•ËØ¢ÁªìÊûúÔºåÂπ∂Â∞ÜËÆøÈóÆÈÄüÂ∫¶ÊúÄÂø´ÁöÑÁªìÊûúËøîÂõûÁªôÂÆ¢Êà∑Á´ØÔºå‰ª•Ê≠§ÊèêÈ´òÁΩëÁªúËÆøÈóÆÈÄüÂ∫¶„ÄÇ\nSmartDNS ÂêåÊó∂ÊîØÊåÅÊåáÂÆöÁâπÂÆöÂüüÂêç IP Âú∞ÂùÄÔºåÂπ∂È´òÊÄßÂåπÈÖçÔºåÂèØËææÂà∞ËøáÊª§ÂπøÂëäÁöÑÊïàÊûú; ÊîØÊåÅDOTÔºåDOHÔºåDOQÔºåDOH3ÔºåÊõ¥Â•ΩÁöÑ‰øùÊä§ÈöêÁßÅ„ÄÇ  \n\n‰∏é DNSmasq ÁöÑ all-servers ‰∏çÂêåÔºåSmartDNS ËøîÂõûÁöÑÊòØËÆøÈóÆÈÄüÂ∫¶ÊúÄÂø´ÁöÑËß£ÊûêÁªìÊûú„ÄÇ\n\nÊîØÊåÅÊ†ëËéìÊ¥æ„ÄÅOpenWrt„ÄÅÂçéÁ°ïË∑ØÁî±Âô®ÂéüÁîüÂõ∫‰ª∂Âíå Windows Á≥ªÁªüÁ≠â„ÄÇ\n\n## ‰ΩøÁî®ÊåáÂØº\n\nSmartDNSÂÆòÁΩëÔºö[https://pymumu.github.io/smartdns](https://pymumu.github.io/smartdns)\n\n## ËΩØ‰ª∂ÊïàÊûúÂ±ïÁ§∫\n\n### ‰ª™Ë°®Áõò\n\n![SmartDNS-WebUI](doc/smartdns-webui.png)\n\n### ÈÄüÂ∫¶ÂØπÊØî\n\n**ÈòøÈáå DNS**  \n‰ΩøÁî®ÈòøÈáå DNS Êü•ËØ¢ÁôæÂ∫¶IPÔºåÂπ∂Ê£ÄÊµãÁªìÊûú„ÄÇ  \n\n```shell\n$ nslookup www.baidu.com 223.5.5.5\nServer:         223.5.5.5\nAddress:        223.5.5.5#53\n\nNon-authoritative answer:\nwww.baidu.com   canonical name = www.a.shifen.com.\nName:   www.a.shifen.com\nAddress: 180.97.33.108\nName:   www.a.shifen.com\nAddress: 180.97.33.107\n\n$ ping 180.97.33.107 -c 2\nPING 180.97.33.107 (180.97.33.107) 56(84) bytes of data.\n64 bytes from 180.97.33.107: icmp_seq=1 ttl=55 time=24.3 ms\n64 bytes from 180.97.33.107: icmp_seq=2 ttl=55 time=24.2 ms\n\n--- 180.97.33.107 ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 1001ms\nrtt min/avg/max/mdev = 24.275/24.327/24.380/0.164 ms\npi@raspberrypi:~/code/smartdns_build $ ping 180.97.33.108 -c 2\nPING 180.97.33.108 (180.97.33.108) 56(84) bytes of data.\n64 bytes from 180.97.33.108: icmp_seq=1 ttl=55 time=31.1 ms\n64 bytes from 180.97.33.108: icmp_seq=2 ttl=55 time=31.0 ms\n\n--- 180.97.33.108 ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 1001ms\nrtt min/avg/max/mdev = 31.014/31.094/31.175/0.193 ms\n```\n\n**SmartDNS**  \n‰ΩøÁî® SmartDNS Êü•ËØ¢ÁôæÂ∫¶ IPÔºåÂπ∂Ê£ÄÊµãÁªìÊûú„ÄÇ\n\n```shell\n$ nslookup www.baidu.com\nServer:         192.168.1.1\nAddress:        192.168.1.1#53\n\nNon-authoritative answer:\nwww.baidu.com   canonical name = www.a.shifen.com.\nName:   www.a.shifen.com\nAddress: 14.215.177.39\n\n$ ping 14.215.177.39 -c 2\nPING 14.215.177.39 (14.215.177.39) 56(84) bytes of data.\n64 bytes from 14.215.177.39: icmp_seq=1 ttl=56 time=6.31 ms\n64 bytes from 14.215.177.39: icmp_seq=2 ttl=56 time=5.95 ms\n\n--- 14.215.177.39 ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 1001ms\nrtt min/avg/max/mdev = 5.954/6.133/6.313/0.195 ms\n```\n\n‰ªéÂØπÊØîÁúãÂá∫ÔºåSmartDNS ÊâæÂà∞‰∫ÜËÆøÈóÆ `www.baidu.com` ÊúÄÂø´ÁöÑ IP Âú∞ÂùÄÔºåÊØîÈòøÈáå DNS ÈÄüÂ∫¶Âø´‰∫Ü 5 ÂÄç„ÄÇ\n\n## ÁâπÊÄß\n\n1. **Â§öËôöÊãüDNSÊúçÂä°Âô®**  \n   ÊîØÊåÅÂ§ö‰∏™ËôöÊãüDNSÊúçÂä°Âô®Ôºå‰∏çÂêåËôöÊãüDNSÊúçÂä°Âô®‰∏çÂêåÁöÑÁ´ØÂè£ÔºåËßÑÂàôÔºåÂÆ¢Êà∑Á´Ø„ÄÇ\n\n1. **Â§ö DNS ‰∏äÊ∏∏ÊúçÂä°Âô®**  \n   ÊîØÊåÅÈÖçÁΩÆÂ§ö‰∏™‰∏äÊ∏∏ DNS ÊúçÂä°Âô®ÔºåÂπ∂ÂêåÊó∂ËøõË°åÊü•ËØ¢ÔºåÂç≥‰ΩøÂÖ∂‰∏≠Êúâ DNS ÊúçÂä°Âô®ÂºÇÂ∏∏Ôºå‰πü‰∏ç‰ºöÂΩ±ÂìçÊü•ËØ¢„ÄÇ  \n\n1. **ÊîØÊåÅÊØè‰∏™ÂÆ¢Êà∑Á´ØÁã¨Á´ãÊéßÂà∂**  \n   ÊîØÊåÅÂü∫‰∫éMACÔºåIPÂú∞ÂùÄÊéßÂà∂ÂÆ¢Êà∑Á´Ø‰ΩøÁî®‰∏çÂêåÊü•ËØ¢ËßÑÂàôÔºåÂèØÂÆûÁé∞ÂÆ∂ÈïøÊéßÂà∂Á≠âÂäüËÉΩ„ÄÇ  \n\n1. **ËøîÂõûÊúÄÂø´ IP Âú∞ÂùÄ**  \n   ÊîØÊåÅ‰ªéÂüüÂêçÊâÄÂ±û IP Âú∞ÂùÄÂàóË°®‰∏≠Êü•ÊâæÂà∞ËÆøÈóÆÈÄüÂ∫¶ÊúÄÂø´ÁöÑ IP Âú∞ÂùÄÔºåÂπ∂ËøîÂõûÁªôÂÆ¢Êà∑Á´ØÔºåÊèêÈ´òÁΩëÁªúËÆøÈóÆÈÄüÂ∫¶„ÄÇ\n\n1. **ÊîØÊåÅÂ§öÁßçÊü•ËØ¢ÂçèËÆÆ**  \n   ÊîØÊåÅ UDP„ÄÅTCP„ÄÅDOT„ÄÅDOH„ÄÅDOQ Âíå DOH3 Êü•ËØ¢ÂèäÊúçÂä°Ôºå‰ª•ÂèäÈùû 53 Á´ØÂè£Êü•ËØ¢ÔºõÊîØÊåÅÈÄöËøásocks5ÔºåHTTP‰ª£ÁêÜÊü•ËØ¢;\n\n1. **ÁâπÂÆöÂüüÂêç IP Âú∞ÂùÄÊåáÂÆö**  \n   ÊîØÊåÅÊåáÂÆöÂüüÂêçÁöÑ IP Âú∞ÂùÄÔºåËææÂà∞ÂπøÂëäËøáÊª§ÊïàÊûú„ÄÅÈÅøÂÖçÊÅ∂ÊÑèÁΩëÁ´ôÁöÑÊïàÊûú„ÄÇ\n\n1. **ÂüüÂêçÈ´òÊÄßËÉΩÂêéÁºÄÂåπÈÖç**  \n   ÊîØÊåÅÂüüÂêçÂêéÁºÄÂåπÈÖçÊ®°ÂºèÔºåÁÆÄÂåñËøáÊª§ÈÖçÁΩÆÔºåËøáÊª§ 20 ‰∏áÊù°ËÆ∞ÂΩïÊó∂Èó¥ < 1ms„ÄÇ\n\n1. **ÂüüÂêçÂàÜÊµÅ**  \n   ÊîØÊåÅÂüüÂêçÂàÜÊµÅÔºå‰∏çÂêåÁ±ªÂûãÁöÑÂüüÂêçÂêë‰∏çÂêåÁöÑ DNS ÊúçÂä°Âô®Êü•ËØ¢ÔºåÊîØÊåÅiptableÂíånftableÊõ¥Â•ΩÁöÑÂàÜÊµÅÔºõÊîØÊåÅÊµãÈÄüÂ§±Ë¥•ÁöÑÊÉÖÂÜµ‰∏ãËÆæÁΩÆÂüüÂêçÁªìÊûúÂà∞ÂØπÂ∫îipsetÂíånftsetÈõÜÂêà„ÄÇ\n\n1. **Windows / Linux Â§öÂπ≥Âè∞ÊîØÊåÅ**  \n   ÊîØÊåÅÊ†áÂáÜ Linux Á≥ªÁªüÔºàÊ†ëËéìÊ¥æÔºâ„ÄÅOpenWrt Á≥ªÁªüÂêÑÁßçÂõ∫‰ª∂ÂíåÂçéÁ°ïË∑ØÁî±Âô®ÂéüÁîüÂõ∫‰ª∂„ÄÇÂêåÊó∂ËøòÊîØÊåÅ WSLÔºàWindows Subsystem for LinuxÔºåÈÄÇÁî®‰∫é Linux ÁöÑ Windows Â≠êÁ≥ªÁªüÔºâ„ÄÇ\n\n1. **ÊîØÊåÅ IPv4„ÄÅIPv6 ÂèåÊ†à**  \n   ÊîØÊåÅ IPv4 Âíå IPV 6ÁΩëÁªúÔºåÊîØÊåÅÊü•ËØ¢ A Âíå AAAA ËÆ∞ÂΩïÔºåÊîØÊåÅÂèåÊ†à IP ÈÄüÂ∫¶‰ºòÂåñÔºåÂπ∂ÊîØÊåÅÂÆåÂÖ®Á¶ÅÁî® IPv6 AAAA Ëß£Êûê„ÄÇ\n\n1. **ÊîØÊåÅDNS64**  \n   ÊîØÊåÅDNS64ËΩ¨Êç¢„ÄÇ\n\n1. **È´òÊÄßËÉΩ„ÄÅÂç†Áî®ËµÑÊ∫êÂ∞ë**  \n   Â§öÁ∫øÁ®ãÂºÇÊ≠• IO Ê®°ÂºèÔºåcache ÁºìÂ≠òÊü•ËØ¢ÁªìÊûú„ÄÇ\n\n1. **‰∏ªÊµÅÁ≥ªÁªüÂÆòÊñπÊîØÊåÅ**  \n   ‰∏ªÊµÅË∑ØÁî±Á≥ªÁªüÂÆòÊñπËΩØ‰ª∂Ê∫êÂÆâË£Ösmartdns„ÄÇ\n\n## Êû∂ÊûÑ\n\n![Architecture](https://github.com/pymumu/test/releases/download/blob/architecture.png)\n\n1. SmartDNS Êé•Êî∂Êú¨Âú∞ÁΩëÁªúËÆæÂ§áÁöÑDNS Êü•ËØ¢ËØ∑Ê±ÇÔºåÂ¶Ç PC„ÄÅÊâãÊú∫ÁöÑÊü•ËØ¢ËØ∑Ê±ÇÔºõ\n1. ÁÑ∂ÂêéÂ∞ÜÊü•ËØ¢ËØ∑Ê±ÇÂèëÈÄÅÂà∞Â§ö‰∏™‰∏äÊ∏∏ DNS ÊúçÂä°Âô®ÔºåÂèØÊîØÊåÅ UDP Ê†áÂáÜÁ´ØÂè£ÊàñÈùûÊ†áÂáÜÁ´ØÂè£Êü•ËØ¢Ôºå‰ª•Âèä TCP Êü•ËØ¢Ôºõ\n1. ‰∏äÊ∏∏ DNS ÊúçÂä°Âô®ËøîÂõûÂüüÂêçÂØπÂ∫îÁöÑÊúçÂä°Âô® IP Âú∞ÂùÄÂàóË°®ÔºåSmartDNS Âàô‰ºöÊ£ÄÊµã‰ªéÊú¨Âú∞ÁΩëÁªúËÆøÈóÆÈÄüÂ∫¶ÊúÄÂø´ÁöÑÊúçÂä°Âô® IPÔºõ\n1. ÊúÄÂêéÂ∞ÜËÆøÈóÆÈÄüÂ∫¶ÊúÄÂø´ÁöÑÊúçÂä°Âô® IP ËøîÂõûÁªôÊú¨Âú∞ÂÆ¢Êà∑Á´Ø„ÄÇ\n\n## ÁºñËØë\n\n- ‰ª£Á†ÅÁºñËØëÔºö\n\n  SmartDNS Êèê‰æõ‰∫ÜÁºñËØëËΩØ‰ª∂ÂåÖÁöÑËÑöÊú¨Ôºà`package/build-pkg.sh`ÔºâÔºåÊîØÊåÅÁºñËØë LuCI„ÄÅDebian„ÄÅOpenWrt Âíå Optware ÂÆâË£ÖÂåÖ„ÄÇ\n\n- ÊñáÊ°£ÁºñËØëÔºö\n\n  ÊñáÊ°£ÂàÜÊîØ‰∏∫`doc`ÔºåÂÆâË£Ö`mkdocs`Â∑•ÂÖ∑ÂêéÔºåÊâßË°å`mkdocs build`ÁºñËØë„ÄÇ\n\n## ÊçêËµ†\n\nÂ¶ÇÊûú‰Ω†ËßâÂæóÊ≠§È°πÁõÆÂØπ‰Ω†ÊúâÂ∏ÆÂä©ÔºåËØ∑ÊçêÂä©Êàë‰ª¨Ôºå‰ΩøÈ°πÁõÆËÉΩÊåÅÁª≠ÂèëÂ±ïÂíåÊõ¥Âä†ÂÆåÂñÑ„ÄÇ\n\n### PayPal Ë¥ùÂÆù\n\n[![Support via PayPal](https://cdn.rawgit.com/twolfson/paypal-github-button/1.0.0/dist/button.svg)](https://paypal.me/PengNick/)\n\n### AliPay ÊîØ‰ªòÂÆù\n\n![alipay](doc/alipay_donate.jpg)\n\n### WeChat Pay ÂæÆ‰ø°ÊîØ‰ªò\n\n![wechat](doc/wechat_donate.jpg)\n\n## ÂºÄÊ∫êÂ£∞Êòé\n\nSmartDNS Âü∫‰∫é GPL V3 ÂçèËÆÆÂºÄÊ∫ê„ÄÇ\n",
      "stars_today": 5
    },
    {
      "id": 2755696,
      "name": "go-sqlite3",
      "full_name": "mattn/go-sqlite3",
      "description": "sqlite3 driver for go using database/sql",
      "html_url": "https://github.com/mattn/go-sqlite3",
      "stars": 8933,
      "forks": 1155,
      "language": "C",
      "topics": [
        "go",
        "sqlite",
        "sqlite3-driver"
      ],
      "created_at": "2011-11-11T12:36:50Z",
      "updated_at": "2026-01-23T22:25:42Z",
      "pushed_at": "2026-01-16T08:19:54Z",
      "open_issues": 211,
      "owner": {
        "login": "mattn",
        "avatar_url": "https://avatars.githubusercontent.com/u/10111?v=4"
      },
      "readme": "go-sqlite3\n==========\n\n[![Go Reference](https://pkg.go.dev/badge/github.com/mattn/go-sqlite3.svg)](https://pkg.go.dev/github.com/mattn/go-sqlite3)\n[![GitHub Actions](https://github.com/mattn/go-sqlite3/workflows/Go/badge.svg)](https://github.com/mattn/go-sqlite3/actions?query=workflow%3AGo)\n[![Financial Contributors on Open Collective](https://opencollective.com/mattn-go-sqlite3/all/badge.svg?label=financial+contributors)](https://opencollective.com/mattn-go-sqlite3) \n[![codecov](https://codecov.io/gh/mattn/go-sqlite3/branch/master/graph/badge.svg)](https://codecov.io/gh/mattn/go-sqlite3)\n[![Go Report Card](https://goreportcard.com/badge/github.com/mattn/go-sqlite3)](https://goreportcard.com/report/github.com/mattn/go-sqlite3)\n\nLatest stable version is v1.14 or later, not v2.\n\n~~**NOTE:** The increase to v2 was an accident. There were no major changes or features.~~\n\n# Description\n\nA sqlite3 driver that conforms to the built-in database/sql interface.\n\nSupported Golang version: See [.github/workflows/go.yaml](./.github/workflows/go.yaml).\n\nThis package follows the official [Golang Release Policy](https://golang.org/doc/devel/release.html#policy).\n\n### Overview\n\n- [go-sqlite3](#go-sqlite3)\n- [Description](#description)\n    - [Overview](#overview)\n- [Installation](#installation)\n- [API Reference](#api-reference)\n- [Connection String](#connection-string)\n  - [DSN Examples](#dsn-examples)\n- [Features](#features)\n    - [Usage](#usage)\n    - [Feature / Extension List](#feature--extension-list)\n- [Compilation](#compilation)\n  - [Android](#android)\n- [ARM](#arm)\n- [Cross Compile](#cross-compile)\n- [Compiling](#compiling)\n  - [Linux](#linux)\n    - [Alpine](#alpine)\n    - [Fedora](#fedora)\n    - [Ubuntu](#ubuntu)\n  - [macOS](#mac-osx)\n  - [Windows](#windows)\n  - [Errors](#errors)\n- [User Authentication](#user-authentication)\n  - [Compile](#compile)\n  - [Usage](#usage-1)\n    - [Create protected database](#create-protected-database)\n    - [Password Encoding](#password-encoding)\n      - [Available Encoders](#available-encoders)\n    - [Restrictions](#restrictions)\n    - [Support](#support)\n    - [User Management](#user-management)\n      - [SQL](#sql)\n        - [Examples](#examples)\n      - [*SQLiteConn](#sqliteconn)\n    - [Attached database](#attached-database)\n- [Extensions](#extensions)\n  - [Spatialite](#spatialite)\n- [FAQ](#faq)\n- [License](#license)\n- [Author](#author)\n\n# Installation\n\nThis package can be installed with the `go get` command:\n\n    go get github.com/mattn/go-sqlite3\n\n_go-sqlite3_ is *cgo* package.\nIf you want to build your app using go-sqlite3, you need gcc.\n\n***Important: because this is a `CGO` enabled package, you are required to set the environment variable `CGO_ENABLED=1` and have a `gcc` compiler present within your path.***\n\n# API Reference\n\nAPI documentation can be found [here](http://godoc.org/github.com/mattn/go-sqlite3).\n\nExamples can be found under the [examples](./_example) directory.\n\n# Connection String\n\nWhen creating a new SQLite database or connection to an existing one, with the file name additional options can be given.\nThis is also known as a DSN (Data Source Name) string.\n\nOptions are append after the filename of the SQLite database.\nThe database filename and options are separated by an `?` (Question Mark).\nOptions should be URL-encoded (see [url.QueryEscape](https://golang.org/pkg/net/url/#QueryEscape)).\n\nThis also applies when using an in-memory database instead of a file.\n\nOptions can be given using the following format: `KEYWORD=VALUE` and multiple options can be combined with the `&` ampersand.\n\nThis library supports DSN options of SQLite itself and provides additional options.\n\nBoolean values can be one of:\n* `0` `no` `false` `off`\n* `1` `yes` `true` `on`\n\n| Name | Key | Value(s) | Description |\n|------|-----|----------|-------------|\n| UA - Create | `_auth` | - | Create User Authentication, for more information see [User Authentication](#user-authentication) |\n| UA - Username | `_auth_user` | `string` | Username for User Authentication, for more information see [User Authentication](#user-authentication) |\n| UA - Password | `_auth_pass` | `string` | Password for User Authentication, for more information see [User Authentication](#user-authentication) |\n| UA - Crypt | `_auth_crypt` | <ul><li>SHA1</li><li>SSHA1</li><li>SHA256</li><li>SSHA256</li><li>SHA384</li><li>SSHA384</li><li>SHA512</li><li>SSHA512</li></ul> | Password encoder to use for User Authentication, for more information see [User Authentication](#user-authentication) |\n| UA - Salt | `_auth_salt` | `string` | Salt to use if the configure password encoder requires a salt, for User Authentication, for more information see [User Authentication](#user-authentication) |\n| Auto Vacuum | `_auto_vacuum` \\| `_vacuum` | <ul><li>`0` \\| `none`</li><li>`1` \\| `full`</li><li>`2` \\| `incremental`</li></ul> | For more information see [PRAGMA auto_vacuum](https://www.sqlite.org/pragma.html#pragma_auto_vacuum) |\n| Busy Timeout | `_busy_timeout` \\| `_timeout` | `int` | Specify value for sqlite3_busy_timeout. For more information see [PRAGMA busy_timeout](https://www.sqlite.org/pragma.html#pragma_busy_timeout) |\n| Case Sensitive LIKE | `_case_sensitive_like` \\| `_cslike` | `boolean` | For more information see [PRAGMA case_sensitive_like](https://www.sqlite.org/pragma.html#pragma_case_sensitive_like) |\n| Defer Foreign Keys | `_defer_foreign_keys` \\| `_defer_fk` | `boolean` | For more information see [PRAGMA defer_foreign_keys](https://www.sqlite.org/pragma.html#pragma_defer_foreign_keys) |\n| Foreign Keys | `_foreign_keys` \\| `_fk` | `boolean` | For more information see [PRAGMA foreign_keys](https://www.sqlite.org/pragma.html#pragma_foreign_keys) |\n| Ignore CHECK Constraints | `_ignore_check_constraints` | `boolean` | For more information see [PRAGMA ignore_check_constraints](https://www.sqlite.org/pragma.html#pragma_ignore_check_constraints) |\n| Immutable | `immutable` | `boolean` | For more information see [Immutable](https://www.sqlite.org/c3ref/open.html) |\n| Journal Mode | `_journal_mode` \\| `_journal` | <ul><li>DELETE</li><li>TRUNCATE</li><li>PERSIST</li><li>MEMORY</li><li>WAL</li><li>OFF</li></ul> | For more information see [PRAGMA journal_mode](https://www.sqlite.org/pragma.html#pragma_journal_mode) |\n| Locking Mode | `_locking_mode` \\| `_locking` | <ul><li>NORMAL</li><li>EXCLUSIVE</li></ul> | For more information see [PRAGMA locking_mode](https://www.sqlite.org/pragma.html#pragma_locking_mode) |\n| Mode | `mode` | <ul><li>ro</li><li>rw</li><li>rwc</li><li>memory</li></ul> | Access Mode of the database. For more information see [SQLite Open](https://www.sqlite.org/c3ref/open.html) |\n| Mutex Locking | `_mutex` | <ul><li>no</li><li>full</li></ul> | Specify mutex mode. |\n| Query Only | `_query_only` | `boolean` | For more information see [PRAGMA query_only](https://www.sqlite.org/pragma.html#pragma_query_only) |\n| Recursive Triggers | `_recursive_triggers` \\| `_rt` | `boolean` | For more information see [PRAGMA recursive_triggers](https://www.sqlite.org/pragma.html#pragma_recursive_triggers) |\n| Secure Delete | `_secure_delete` | `boolean` \\| `FAST` | For more information see [PRAGMA secure_delete](https://www.sqlite.org/pragma.html#pragma_secure_delete) |\n| Shared-Cache Mode | `cache` | <ul><li>shared</li><li>private</li></ul> | Set cache mode for more information see [sqlite.org](https://www.sqlite.org/sharedcache.html) |\n| Synchronous | `_synchronous` \\| `_sync` | <ul><li>0 \\| OFF</li><li>1 \\| NORMAL</li><li>2 \\| FULL</li><li>3 \\| EXTRA</li></ul> | For more information see [PRAGMA synchronous](https://www.sqlite.org/pragma.html#pragma_synchronous) |\n| Time Zone Location | `_loc` | auto | Specify location of time format. |\n| Transaction Lock | `_txlock` | <ul><li>immediate</li><li>deferred</li><li>exclusive</li></ul> | Specify locking behavior for transactions. |\n| Writable Schema | `_writable_schema` | `Boolean` | When this pragma is on, the SQLITE_MASTER tables in which database can be changed using ordinary UPDATE, INSERT, and DELETE statements. Warning: misuse of this pragma can easily result in a corrupt database file. |\n| Cache Size | `_cache_size` | `int` | Maximum cache size; default is 2000K (2M). See [PRAGMA cache_size](https://sqlite.org/pragma.html#pragma_cache_size) |\n\n\n## DSN Examples\n\n```\nfile:test.db?cache=shared&mode=memory\n```\n\n# Features\n\nThis package allows additional configuration of features available within SQLite3 to be enabled or disabled by golang build constraints also known as build `tags`.\n\nClick [here](https://golang.org/pkg/go/build/#hdr-Build_Constraints) for more information about build tags / constraints.\n\n### Usage\n\nIf you wish to build this library with additional extensions / features, use the following command:\n\n```bash\ngo build -tags \"<FEATURE>\"\n```\n\nFor available features, see the extension list.\nWhen using multiple build tags, all the different tags should be space delimited.\n\nExample:\n\n```bash\ngo build -tags \"icu json1 fts5 secure_delete\"\n```\n\n### Feature / Extension List\n\n| Extension | Build Tag | Description |\n|-----------|-----------|-------------|\n| Additional Statistics | sqlite_stat4 | This option adds additional logic to the ANALYZE command and to the query planner that can help SQLite to chose a better query plan under certain situations. The ANALYZE command is enhanced to collect histogram data from all columns of every index and store that data in the sqlite_stat4 table.<br><br>The query planner will then use the histogram data to help it make better index choices. The downside of this compile-time option is that it violates the query planner stability guarantee making it more difficult to ensure consistent performance in mass-produced applications.<br><br>SQLITE_ENABLE_STAT4 is an enhancement of SQLITE_ENABLE_STAT3. STAT3 only recorded histogram data for the left-most column of each index whereas the STAT4 enhancement records histogram data from all columns of each index.<br><br>The SQLITE_ENABLE_STAT3 compile-time option is a no-op and is ignored if the SQLITE_ENABLE_STAT4 compile-time option is used |\n| Allow URI Authority | sqlite_allow_uri_authority | URI filenames normally throws an error if the authority section is not either empty or \"localhost\".<br><br>However, if SQLite is compiled with the SQLITE_ALLOW_URI_AUTHORITY compile-time option, then the URI is converted into a Uniform Naming Convention (UNC) filename and passed down to the underlying operating system that way |\n| App Armor | sqlite_app_armor | When defined, this C-preprocessor macro activates extra code that attempts to detect misuse of the SQLite API, such as passing in NULL pointers to required parameters or using objects after they have been destroyed. <br><br>App Armor is not available under `Windows`. |\n| Disable Load Extensions | sqlite_omit_load_extension | Loading of external extensions is enabled by default.<br><br>To disable extension loading add the build tag `sqlite_omit_load_extension`. |\n| Enable Serialization with `libsqlite3` | sqlite_serialize | Serialization and deserialization of a SQLite database is available by default, unless the build tag `libsqlite3` is set.<br><br>To enable this functionality even if `libsqlite3` is set, add the build tag `sqlite_serialize`. |\n| Foreign Keys | sqlite_foreign_keys | This macro determines whether enforcement of foreign key constraints is enabled or disabled by default for new database connections.<br><br>Each database connection can always turn enforcement of foreign key constraints on and off and run-time using the foreign_keys pragma.<br><br>Enforcement of foreign key constraints is normally off by default, but if this compile-time parameter is set to 1, enforcement of foreign key constraints will be on by default | \n| Full Auto Vacuum | sqlite_vacuum_full | Set the default auto vacuum to full |\n| Incremental Auto Vacuum | sqlite_vacuum_incr | Set the default auto vacuum to incremental |\n| Full Text Search Engine | sqlite_fts5 | When this option is defined in the amalgamation, versions 5 of the full-text search engine (fts5) is added to the build automatically |\n|  International Components for Unicode | sqlite_icu | This option causes the International Components for Unicode or \"ICU\" extension to SQLite to be added to the build |\n| Introspect PRAGMAS | sqlite_introspect | This option adds some extra PRAGMA statements. <ul><li>PRAGMA function_list</li><li>PRAGMA module_list</li><li>PRAGMA pragma_list</li></ul> |\n| JSON SQL Functions | sqlite_json | When this option is defined in the amalgamation, the JSON SQL functions are added to the build automatically |\n| Math Functions | sqlite_math_functions | This compile-time option enables built-in scalar math functions. For more information see [Built-In Mathematical SQL Functions](https://www.sqlite.org/lang_mathfunc.html) |\n| OS Trace | sqlite_os_trace | This option enables OSTRACE() debug logging. This can be verbose and should not be used in production. |\n| Percentile | sqlite_percentile | This option enables [The Percentile Extension](sqlite.org/percentile.html). |\n| Pre Update Hook | sqlite_preupdate_hook | Registers a callback function that is invoked prior to each INSERT, UPDATE, and DELETE operation on a database table. |\n| Secure Delete | sqlite_secure_delete | This compile-time option changes the default setting of the secure_delete pragma.<br><br>When this option is not used, secure_delete defaults to off. When this option is present, secure_delete defaults to on.<br><br>The secure_delete setting causes deleted content to be overwritten with zeros. There is a small performance penalty since additional I/O must occur.<br><br>On the other hand, secure_delete can prevent fragments of sensitive information from lingering in unused parts of the database file after it has been deleted. See the documentation on the secure_delete pragma for additional information |\n| Secure Delete (FAST) | sqlite_secure_delete_fast | For more information see [PRAGMA secure_delete](https://www.sqlite.org/pragma.html#pragma_secure_delete) |\n| Tracing / Debug | sqlite_trace | Activate trace functions |\n| User Authentication | sqlite_userauth | SQLite User Authentication see [User Authentication](#user-authentication) for more information. |\n| Virtual Tables | sqlite_vtable | SQLite Virtual Tables see [SQLite Official VTABLE Documentation](https://www.sqlite.org/vtab.html) for more information, and a [full example here](https://github.com/mattn/go-sqlite3/tree/master/_example/vtable) |\n\n# Compilation\n\nThis package requires the `CGO_ENABLED=1` environment variable if not set by default, and the presence of the `gcc` compiler.\n\nIf you need to add additional CFLAGS or LDFLAGS to the build command, and do not want to modify this package, then this can be achieved by using the `CGO_CFLAGS` and `CGO_LDFLAGS` environment variables.\n\n## Android\n\nThis package can be compiled for android.\nCompile with:\n\n```bash\ngo build -tags \"android\"\n```\n\nFor more information see [#201](https://github.com/mattn/go-sqlite3/issues/201)\n\n# ARM\n\nTo compile for `ARM` use the following environment:\n\n```bash\nenv CC=arm-linux-gnueabihf-gcc CXX=arm-linux-gnueabihf-g++ \\\n    CGO_ENABLED=1 GOOS=linux GOARCH=arm GOARM=7 \\\n    go build -v \n```\n\nAdditional information:\n- [#242](https://github.com/mattn/go-sqlite3/issues/242)\n- [#504](https://github.com/mattn/go-sqlite3/issues/504)\n\n# Cross Compile\n\nThis library can be cross-compiled.\n\nIn some cases you are required to the `CC` environment variable with the cross compiler.\n\n## Cross Compiling from macOS\nThe simplest way to cross compile from macOS is to use [xgo](https://github.com/karalabe/xgo).\n\nSteps:\n- Install [musl-cross](https://github.com/FiloSottile/homebrew-musl-cross) (`brew install FiloSottile/musl-cross/musl-cross`).\n- Run `CC=x86_64-linux-musl-gcc CXX=x86_64-linux-musl-g++ GOARCH=amd64 GOOS=linux CGO_ENABLED=1 go build -ldflags \"-linkmode external -extldflags -static\"`.\n\nPlease refer to the project's [README](https://github.com/FiloSottile/homebrew-musl-cross#readme) for further information.\n\n# Compiling\n\n## Linux\n\nTo compile this package on Linux, you must install the development tools for your linux distribution.\n\nTo compile under linux use the build tag `linux`.\n\n```bash\ngo build -tags \"linux\"\n```\n\nIf you wish to link directly to libsqlite3 then you can use the `libsqlite3` build tag.\n\n```\ngo build -tags \"libsqlite3 linux\"\n```\n\n### Alpine\n\nWhen building in an `alpine` container  run the following command before building:\n\n```\napk add --update gcc musl-dev\n```\n\n### Fedora\n\n```bash\nsudo yum groupinstall \"Development Tools\" \"Development Libraries\"\n```\n\n### Ubuntu\n\n```bash\nsudo apt-get install build-essential\n```\n\n## macOS\n\nmacOS should have all the tools present to compile this package. If not, install XCode to add all the developers tools.\n\nRequired dependency:\n\n```bash\nbrew install sqlite3\n```\n\nFor macOS, there is an additional package to install which is required if you wish to build the `icu` extension.\n\nThis additional package can be installed with `homebrew`:\n\n```bash\nbrew upgrade icu4c\n```\n\nTo compile for macOS on x86:\n\n```bash\ngo build -tags \"darwin amd64\"\n```\n\nTo compile for macOS on ARM chips:\n\n```bash\ngo build -tags \"darwin arm64\"\n```\n\nIf you wish to link directly to libsqlite3, use the `libsqlite3` build tag:\n\n```\n# x86 \ngo build -tags \"libsqlite3 darwin amd64\"\n# ARM\ngo build -tags \"libsqlite3 darwin arm64\"\n```\n\nAdditional information:\n- [#206](https://github.com/mattn/go-sqlite3/issues/206)\n- [#404](https://github.com/mattn/go-sqlite3/issues/404)\n\n## Windows\n\nTo compile this package on Windows, you must have the `gcc` compiler installed.\n\n1) Install a Windows `gcc` toolchain.\n2) Add the `bin` folder to the Windows path, if the installer did not do this by default.\n3) Open a terminal for the TDM-GCC toolchain, which can be found in the Windows Start menu.\n4) Navigate to your project folder and run the `go build ...` command for this package.\n\nFor example the TDM-GCC Toolchain can be found [here](https://jmeubank.github.io/tdm-gcc/).\n\n## Errors\n\n- Compile error: `can not be used when making a shared object; recompile with -fPIC`\n\n    When receiving a compile time error referencing recompile with `-FPIC` then you\n    are probably using a hardend system.\n\n    You can compile the library on a hardend system with the following command.\n\n    ```bash\n    go build -ldflags '-extldflags=-fno-PIC'\n    ```\n\n    More details see [#120](https://github.com/mattn/go-sqlite3/issues/120)\n\n- Can't build go-sqlite3 on windows 64bit.\n\n    > Probably, you are using go 1.0, go1.0 has a problem when it comes to compiling/linking on windows 64bit.\n    > See: [#27](https://github.com/mattn/go-sqlite3/issues/27)\n\n- `go get github.com/mattn/go-sqlite3` throws compilation error.\n\n    `gcc` throws: `internal compiler error`\n\n    Remove the download repository from your disk and try re-install with:\n\n    ```bash\n    go install github.com/mattn/go-sqlite3\n    ```\n\n# User Authentication\n\n***This is deprecated***\n\nThis package supports the SQLite User Authentication module.\n\n## Compile\n\nTo use the User authentication module, the package has to be compiled with the tag `sqlite_userauth`. See [Features](#features).\n\n## Usage\n\n### Create protected database\n\nTo create a database protected by user authentication, provide the following argument to the connection string `_auth`.\nThis will enable user authentication within the database. This option however requires two additional arguments:\n\n- `_auth_user`\n- `_auth_pass`\n\nWhen `_auth` is present in the connection string user authentication will be enabled and the provided user will be created\nas an `admin` user. After initial creation, the parameter `_auth` has no effect anymore and can be omitted from the connection string.\n\nExample connection strings:\n\nCreate an user authentication database with user `admin` and password `admin`:\n\n`file:test.s3db?_auth&_auth_user=admin&_auth_pass=admin`\n\nCreate an user authentication database with user `admin` and password `admin` and use `SHA1` for the password encoding:\n\n`file:test.s3db?_auth&_auth_user=admin&_auth_pass=admin&_auth_crypt=sha1`\n\n### Password Encoding\n\nThe passwords within the user authentication module of SQLite are encoded with the SQLite function `sqlite_cryp`.\nThis function uses a ceasar-cypher which is quite insecure.\nThis library provides several additional password encoders which can be configured through the connection string.\n\nThe password cypher can be configured with the key `_auth_crypt`. And if the configured password encoder also requires an\nsalt this can be configured with `_auth_salt`.\n\n#### Available Encoders\n\n- SHA1\n- SSHA1 (Salted SHA1)\n- SHA256\n- SSHA256 (salted SHA256)\n- SHA384\n- SSHA384 (salted SHA384)\n- SHA512\n- SSHA512 (salted SHA512)\n\n### Restrictions\n\nOperations on the database regarding user management can only be preformed by an administrator user.\n\n### Support\n\nThe user authentication supports two kinds of users:\n\n- administrators\n- regular users\n\n### User Management\n\nUser management can be done by directly using the `*SQLiteConn` or by SQL.\n\n#### SQL\n\nThe following sql functions are available for user management:\n\n| Function | Arguments | Description |\n|----------|-----------|-------------|\n| `authenticate` | username `string`, password `string` | Will authenticate an user, this is done by the connection; and should not be used manually. |\n| `auth_user_add` | username `string`, password `string`, admin `int` | This function will add an user to the database.<br>if the database is not protected by user authentication it will enable it. Argument `admin` is an integer identifying if the added user should be an administrator. Only Administrators can add administrators. |\n| `auth_user_change` | username `string`, password `string`, admin `int` | Function to modify an user. Users can change their own password, but only an administrator can change the administrator flag. |\n| `authUserDelete` | username `string` | Delete an user from the database. Can only be used by an administrator. The current logged in administrator cannot be deleted. This is to make sure their is always an administrator remaining. |\n\nThese functions will return an integer:\n\n- 0 (SQLITE_OK)\n- 23 (SQLITE_AUTH) Failed to perform due to authentication or insufficient privileges\n\n##### Examples\n\n```sql\n// Autheticate user\n// Create Admin User\nSELECT auth_user_add('admin2', 'admin2', 1);\n\n// Change password for user\nSELECT auth_user_change('user', 'userpassword', 0);\n\n// Delete user\nSELECT user_delete('user');\n```\n\n#### *SQLiteConn\n\nThe following functions are available for User authentication from the `*SQLiteConn`:\n\n| Function | Description |\n|----------|-------------|\n| `Authenticate(username, password string) error` | Authenticate user |\n| `AuthUserAdd(username, password string, admin bool) error` | Add user |\n| `AuthUserChange(username, password string, admin bool) error` | Modify user |\n| `AuthUserDelete(username string) error` | Delete user |\n\n### Attached database\n\nWhen using attached databases, SQLite will use the authentication from the `main` database for the attached database(s).\n\n# Extensions\n\nIf you want your own extension to be listed here, or you want to add a reference to an extension; please submit an Issue for this.\n\n## Spatialite\n\nSpatialite is available as an extension to SQLite, and can be used in combination with this repository.\nFor an example, see [shaxbee/go-spatialite](https://github.com/shaxbee/go-spatialite).\n\n## extension-functions.c from SQLite3 Contrib\n\nextension-functions.c is available as an extension to SQLite, and provides the following functions:\n\n- Math: acos, asin, atan, atn2, atan2, acosh, asinh, atanh, difference, degrees, radians, cos, sin, tan, cot, cosh, sinh, tanh, coth, exp, log, log10, power, sign, sqrt, square, ceil, floor, pi.\n- String: replicate, charindex, leftstr, rightstr, ltrim, rtrim, trim, replace, reverse, proper, padl, padr, padc, strfilter.\n- Aggregate: stdev, variance, mode, median, lower_quartile, upper_quartile\n\nFor an example, see [dinedal/go-sqlite3-extension-functions](https://github.com/dinedal/go-sqlite3-extension-functions).\n\n# FAQ\n\n- Getting insert error while query is opened.\n\n    > You can pass some arguments into the connection string, for example, a URI.\n    > See: [#39](https://github.com/mattn/go-sqlite3/issues/39)\n\n- Do you want to cross compile? mingw on Linux or Mac?\n\n    > See: [#106](https://github.com/mattn/go-sqlite3/issues/106)\n    > See also: http://www.limitlessfx.com/cross-compile-golang-app-for-windows-from-linux.html\n\n- Want to get time.Time with current locale\n\n    Use `_loc=auto` in SQLite3 filename schema like `file:foo.db?_loc=auto`.\n\n- Can I use this in multiple routines concurrently?\n\n    Yes for readonly. But not for writable. See [#50](https://github.com/mattn/go-sqlite3/issues/50), [#51](https://github.com/mattn/go-sqlite3/issues/51), [#209](https://github.com/mattn/go-sqlite3/issues/209), [#274](https://github.com/mattn/go-sqlite3/issues/274).\n\n- Why I'm getting `no such table` error?\n\n    Why is it racy if I use a `sql.Open(\"sqlite3\", \":memory:\")` database?\n\n    Each connection to `\":memory:\"` opens a brand new in-memory sql database, so if\n    the stdlib's sql engine happens to open another connection and you've only\n    specified `\":memory:\"`, that connection will see a brand new database. A\n    workaround is to use `\"file::memory:?cache=shared\"` (or `\"file:foobar?mode=memory&cache=shared\"`). Every\n    connection to this string will point to the same in-memory database.\n    \n    Note that if the last database connection in the pool closes, the in-memory database is deleted. Make sure the [max idle connection limit](https://golang.org/pkg/database/sql/#DB.SetMaxIdleConns) is > 0, and the [connection lifetime](https://golang.org/pkg/database/sql/#DB.SetConnMaxLifetime) is infinite.\n    \n    For more information see:\n    * [#204](https://github.com/mattn/go-sqlite3/issues/204)\n    * [#511](https://github.com/mattn/go-sqlite3/issues/511)\n    * https://www.sqlite.org/sharedcache.html#shared_cache_and_in_memory_databases\n    * https://www.sqlite.org/inmemorydb.html#sharedmemdb\n\n- Reading from database with large amount of goroutines fails on OSX.\n\n    OS X limits OS-wide to not have more than 1000 files open simultaneously by default.\n\n    For more information, see [#289](https://github.com/mattn/go-sqlite3/issues/289)\n\n- Trying to execute a `.` (dot) command throws an error.\n\n    Error: `Error: near \".\": syntax error`\n    Dot command are part of SQLite3 CLI, not of this library.\n\n    You need to implement the feature or call the sqlite3 cli.\n\n    More information see [#305](https://github.com/mattn/go-sqlite3/issues/305).\n\n- Error: `database is locked`\n\n    When you get a database is locked, please use the following options.\n\n    Add to DSN: `cache=shared`\n\n    Example:\n    ```go\n    db, err := sql.Open(\"sqlite3\", \"file:locked.sqlite?cache=shared\")\n    ```\n\n    Next, please set the database connections of the SQL package to 1:\n    \n    ```go\n    db.SetMaxOpenConns(1)\n    ```\n\n    For more information, see [#209](https://github.com/mattn/go-sqlite3/issues/209).\n\n## Contributors\n\n### Code Contributors\n\nThis project exists thanks to all the people who [[contribute](CONTRIBUTING.md)].\n<a href=\"https://github.com/mattn/go-sqlite3/graphs/contributors\"><img src=\"https://opencollective.com/mattn-go-sqlite3/contributors.svg?width=890&button=false\" /></a>\n\n### Financial Contributors\n\nBecome a financial contributor and help us sustain our community. [[Contribute here](https://opencollective.com/mattn-go-sqlite3/contribute)].\n\n#### Individuals\n\n<a href=\"https://opencollective.com/mattn-go-sqlite3\"><img src=\"https://opencollective.com/mattn-go-sqlite3/individuals.svg?width=890\"></a>\n\n#### Organizations\n\nSupport this project with your organization. Your logo will show up here with a link to your website. [[Contribute](https://opencollective.com/mattn-go-sqlite3/contribute)]\n\n<a href=\"https://opencollective.com/mattn-go-sqlite3/organization/0/website\"><img src=\"https://opencollective.com/mattn-go-sqlite3/organization/0/avatar.svg\"></a>\n<a href=\"https://opencollective.com/mattn-go-sqlite3/organization/1/website\"><img src=\"https://opencollective.com/mattn-go-sqlite3/organization/1/avatar.svg\"></a>\n<a href=\"https://opencollective.com/mattn-go-sqlite3/organization/2/website\"><img src=\"https://opencollective.com/mattn-go-sqlite3/organization/2/avatar.svg\"></a>\n<a href=\"https://opencollective.com/mattn-go-sqlite3/organization/3/website\"><img src=\"https://opencollective.com/mattn-go-sqlite3/organization/3/avatar.svg\"></a>\n<a href=\"https://opencollective.com/mattn-go-sqlite3/organization/4/website\"><img src=\"https://opencollective.com/mattn-go-sqlite3/organization/4/avatar.svg\"></a>\n<a href=\"https://opencollective.com/mattn-go-sqlite3/organization/5/website\"><img src=\"https://opencollective.com/mattn-go-sqlite3/organization/5/avatar.svg\"></a>\n<a href=\"https://opencollective.com/mattn-go-sqlite3/organization/6/website\"><img src=\"https://opencollective.com/mattn-go-sqlite3/organization/6/avatar.svg\"></a>\n<a href=\"https://opencollective.com/mattn-go-sqlite3/organization/7/website\"><img src=\"https://opencollective.com/mattn-go-sqlite3/organization/7/avatar.svg\"></a>\n<a href=\"https://opencollective.com/mattn-go-sqlite3/organization/8/website\"><img src=\"https://opencollective.com/mattn-go-sqlite3/organization/8/avatar.svg\"></a>\n<a href=\"https://opencollective.com/mattn-go-sqlite3/organization/9/website\"><img src=\"https://opencollective.com/mattn-go-sqlite3/organization/9/avatar.svg\"></a>\n\n# License\n\nMIT: http://mattn.mit-license.org/2018\n\nsqlite3-binding.c, sqlite3-binding.h, sqlite3ext.h\n\nThe -binding suffix was added to avoid build failures under gccgo.\n\nIn this repository, those files are an amalgamation of code that was copied from SQLite3. The license of that code is the same as the license of SQLite3.\n\n# Author\n\nYasuhiro Matsumoto (a.k.a mattn)\n\nG.J.R. Timmer\n",
      "stars_today": 5
    },
    {
      "id": 211381955,
      "name": "uPlot",
      "full_name": "leeoniya/uPlot",
      "description": "üìà A small, fast chart for time series, lines, areas, ohlc & bars",
      "html_url": "https://github.com/leeoniya/uPlot",
      "stars": 9802,
      "forks": 438,
      "language": "JavaScript",
      "topics": [
        "analytics",
        "chart",
        "charts",
        "data-visualization",
        "graph",
        "graphs",
        "lightweight",
        "line-chart",
        "ohlc",
        "performance",
        "plot",
        "plotting",
        "streaming",
        "time-series",
        "timeseries",
        "trend-analysis"
      ],
      "created_at": "2019-09-27T18:45:21Z",
      "updated_at": "2026-01-24T01:26:49Z",
      "pushed_at": "2026-01-22T15:22:49Z",
      "open_issues": 139,
      "owner": {
        "login": "leeoniya",
        "avatar_url": "https://avatars.githubusercontent.com/u/43234?v=4"
      },
      "readme": "<h2><img src=\"uPlot.svg\" alt=\"uPlot logo\" height=\"36\" align=\"top\"> ŒºPlot</h2>\n\nA small ([~50 KB min](https://github.com/leeoniya/uPlot/tree/master/dist/uPlot.iife.min.js)), [fast](#performance) chart for time series, lines, areas, ohlc & bars _(MIT Licensed)_\n\n---\n### Introduction\n\nuPlot is a [fast, memory-efficient](#performance) [Canvas 2D](https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D)-based chart for plotting [time series](https://en.wikipedia.org/wiki/Time_series), lines, areas, ohlc & bars. From a cold start it can create an [interactive chart containing 166,650 data points](https://leeoniya.github.io/uPlot/bench/uPlot.html) in 25ms, scaling linearly at [~100,000 pts/ms](https://leeoniya.github.io/uPlot/bench/uPlot-10M.html) afterwards. In addition to fast initial render, the zooming and cursor performance is by far the best of any similar charting lib; at ~50 KB, it's likely the smallest and fastest time series plotter that doesn't make use of [context-limited](https://bugs.chromium.org/p/chromium/issues/detail?id=771792) WebGL shaders or WASM, both of which have much higher startup cost and code size.\n\nIn most sane cases, you can live-stream data with uPlot at 60fps, though it may begin to struggle beyond 100k in-view points.\nWhen [updating 3,600 points at 60fps](https://leeoniya.github.io/uPlot/demos/sine-stream.html), uPlot uses 10% CPU and 12.3MB RAM.\nThe next fastest Canvas-based libs (Chart.js and ECharts) use [40% / 77MB](https://leeoniya.github.io/uPlot/bench/Chart.js4-sine-stream.html) and [70% / 85MB](https://leeoniya.github.io/uPlot/bench/ECharts5-sine-stream.html), respectively.\nIf you need to stream, give [unclog your rendering pipeline](#unclog-your-rendering-pipeline) a try.\nIf that does not help, consider reducing the update frequency or switch to a WebGL/WebGPU solution, like [danchitnis/webgl-plot](https://github.com/danchitnis/webgl-plot), [huww98/TimeChart](https://github.com/huww98/TimeChart), [epezent/implot](https://github.com/epezent/implot).\n\n---\n![uPlot Chart](uPlot.png \"uPlot Chart\")\n\n---\n### Features\n\n- Multiple series w/toggle\n- Multiple y-axes, scales & grids\n- Temporal or numeric x-axis\n- Linear, uniform or [logarithmic](https://leeoniya.github.io/uPlot/demos/log-scales.html) scales\n- Line & Area styles (stroke, fill, width, dash)\n- Pluggable path renderers [linear, spline, stepped, bars](https://leeoniya.github.io/uPlot/demos/line-paths.html)\n- Zoom with auto-rescale\n- Legend with live values\n- Support for [IANA Time Zone Names](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones) & DST\n- [Support for missing data](https://leeoniya.github.io/uPlot/demos/missing-data.html)\n- [Cursor sync for multiple charts](https://leeoniya.github.io/uPlot/demos/sync-cursor.html)\n- [Focus closest series](https://leeoniya.github.io/uPlot/demos/focus-cursor.html)\n- [Data streaming (live update)](https://leeoniya.github.io/uPlot/demos/stream-data.html)\n- [High / Low bands](https://leeoniya.github.io/uPlot/demos/high-low-bands.html)\n- A lean, consistent, and powerful API with hooks & plugins\n\n---\n### Non-Features\n\nIn order to stay lean, fast and focused the following features will not be added:\n\n- No data parsing, aggregation, summation or statistical processing - just do it in advance. e.g. [simples-statistics](https://simple-statistics.github.io/), https://github.com/leeoniya/uDSV\n- No transitions or animations - they're always pure distractions.\n- No collision avoidance for axis tick labels, so may require manual tweaking of spacing metrics if label customization significiantly increases default label widths.\n- No stacked series: see [\"Stacked Area Graphs Are Not Your Friend\"](https://web.archive.org/web/20221208193656/https://everydayanalytics.ca/2014/08/stacked-area-graphs-are-not-your-friend.html) and a [horrific demo](https://leeoniya.github.io/uPlot/demos/stacked-series.html). While smooth spline interpolation is available, its use is strongly discouraged: [Your data is misrepresented!](http://www.vizwiz.com/2011/12/when-you-use-smoothed-line-chart-your.html). Both visualizations are terrible at accurately communicating information.\n- No built-in drag scrolling/panning due to ambiguous native zoom/selection behavior. However, this can be added externally via the plugin/hooks API: [zoom-wheel](https://leeoniya.github.io/uPlot/demos/zoom-wheel.html), [zoom-touch](https://leeoniya.github.io/uPlot/demos/zoom-touch.html).\n\n---\n### Documentation (WIP)\n\nThe docs are a perpetual work in progress, it seems.\nStart with [/docs/README.md](https://github.com/leeoniya/uPlot/tree/master/docs) for a conceptual overview.\nThe full API is further documented via comments in [/dist/uPlot.d.ts](https://github.com/leeoniya/uPlot/blob/master/dist/uPlot.d.ts).\nAdditionally, an ever-expanding collection of runnable [/demos](https://leeoniya.github.io/uPlot/demos/index.html) covers the vast majority of uPlot's API.\n\n---\n### Third-party Integrations\n\n- [React, Vue.js and Svelte](https://github.com/skalinichev/uplot-wrappers) (Sergey Kalinichev)\n- [Python](https://github.com/stephane-caron/uplot-python) (St√©phane Caron)\n\n---\n### Performance\n\nBenchmarks done on this hardware:\n\n- Date: 2023-03-11\n- AMD Ryzen 7 PRO 5850U @ 1.9GHz, 32GB RAM\n- EndeavourOS/Arch (KDE/Plasma), Chrome 113.0.5638.0 (64-bit)\n- 4K display scaled to 1440p (1.5 devicePixelRatio)\n\n![uPlot Performance](perf.png \"uPlot Performance\")\n\nFull size: https://leeoniya.github.io/uPlot/demos/multi-bars.html\n\nRaw data: https://github.com/leeoniya/uPlot/blob/master/bench/results.json\n\n<pre>\n| lib                    | size    | done    | js,rend,paint,sys | heap peak,final | mousemove (10s)     |\n| ---------------------- | ------- | ------- | ----------------- | --------------- | ------------------- |\n| <a href=\"https://leeoniya.github.io/uPlot/bench/uPlot.html\">uPlot v1.6.24</a>          | 47.9 KB |   34 ms |   51   2   1   34 |  21 MB   3 MB   |  218  360  146  196 |\n| <a href=\"https://leeoniya.github.io/uPlot/bench/Chart.js4.html\">Chart.js v4.2.1</a>        |  254 KB |   38 ms |   90   2   1   40 |  29 MB  10 MB   | 1154   46  165  235 |\n| <a href=\"https://leeoniya.github.io/uPlot/bench/Flot.html\">Flot v3.0.0</a>            |  494 KB |   60 ms |  105   5   1   52 |  41 MB  21 MB   | ---                 |\n| <a href=\"https://leeoniya.github.io/uPlot/bench/ECharts5.html\">ECharts v5.4.1</a>         | 1000 KB |   55 ms |  148   3   1   35 |  17 MB   3 MB   | 1943  444  203  208 |\n| <a href=\"https://leeoniya.github.io/uPlot/bench/dygraphs.html\">dygraphs v2.2.1</a>        |  132 KB |   90 ms |  163   2   1   33 |  88 MB  42 MB   | 1438  371  174  268 |\n| <a href=\"https://leeoniya.github.io/uPlot/bench/LightningChart.html\">LightningChart¬Æ v4.0.2</a> | 1300 KB |  --- ms |  250   2   1   33 |  33 MB  13 MB   | 5390  120  128  325 |\n| <a href=\"https://leeoniya.github.io/uPlot/bench/CanvasJS.html\">CanvasJS v3.7.5</a>        |  489 KB |  130 ms |  266   4   1   35 |  98 MB  69 MB   | 1030  445   90  246 |\n| <a href=\"https://leeoniya.github.io/uPlot/bench/dvxCharts.html\">dvxCharts v5.1.0</a>       |  373 KB |  160 ms |  264  23   1   62 | 100 MB  61 MB   |  687  779  206  197 |\n| <a href=\"https://leeoniya.github.io/uPlot/bench/Highcharts.html\">Highcharts v10.3.3</a>     |  413 KB |  --- ms |  416   7   1   38 |  97 MB  55 MB   | 1286  824  205  242 |\n| <a href=\"https://leeoniya.github.io/uPlot/bench/Plotly.js.html\">Plotly.js v2.18.2</a>      | 3600 KB |  310 ms |  655  14   1   40 | 104 MB  70 MB   | 1814  163   25  208 |\n| <a href=\"https://leeoniya.github.io/uPlot/bench/ApexCharts.html\">ApexCharts v3.37.1</a>     |  503 KB |  685 ms |  694   9   1   33 | 175 MB  46 MB   | 1708  421  106  207 |\n| <a href=\"https://leeoniya.github.io/uPlot/bench/ZingChart.html\">ZingChart v2.9.10</a>      |  871 KB |  681 ms |  717   7   1  105 | 290 MB 195 MB   | 9021  305   41   71 |\n| <a href=\"https://leeoniya.github.io/uPlot/bench/amCharts5.html\">amCharts v5.3.7</a>        |  625 KB |  --- ms | 1601   3   3   46 | 147 MB 121 MB   | 9171   71  460  167 |\n</pre>\n\n- libs are sorted by their initial, cold-start, render performance (excluding network transfer time to download the lib)\n- `size` includes the lib itself plus any dependencies required to render the benchmark, e.g. Moment, jQuery, etc.\n- Flot does not make available any minified assets and all their examples use the uncompressed sources; they also use an uncompressed version of jQuery :/\n\nSome libraries provide their own performance demos:\n\n- https://echarts.apache.org/next/examples/en/index.html\n- https://github.com/sveinn-steinarsson/flot-downsample/\n- https://dygraphs.com/tests/dygraph-many-points-benchmark.html\n- https://www.chartjs.org/docs/latest/general/performance.html\n- https://dash.plotly.com/performance\n- https://www.highcharts.com/docs/advanced-chart-features/boost-module\n- https://danchitnis.github.io/webgl-plot-examples/vanilla/\n- https://huww98.github.io/TimeChart/docs/performance\n- https://www.arction.com/lightningchart-js-performance/\n\nTODO (all of these use SVG, so performance should be similar to Highcharts):\n\n- Chartist.js\n- d3-based\n  - C3.js\n  - dc.js\n  - MetricsGraphics\n  - rickshaw\n\n---\n### Unclog your rendering pipeline\n\nYour browser's performance is highly dependent on your hardware, operating system, and GPU drivers.\n\nIf you're using a Chromium-based browser, there are some hidden settings that can unlock significant performance improvements for Canvas2D rendering.\nMost of these have to do with where and how the rasterization is performed.\n\nHead over to https://leeoniya.github.io/uPlot/demos/sine-stream.html and open up Chrome's DevTools (F12), then toggle the Performance Monitor.\n\n![Chrome DevTools Peformance Monitor](img/chrome-perf-monitor.png \"Chrome DevTools Peformance Monitor\")\n\nFor me:\n\n- On Windows 10 Desktop, Core i7-8700, 16GB RAM, AMD RX480 GPU, 2048 x 1080 resolution = 57% CPU usage\n- On Manjaro Laptop (Arch Linux), AMD Ryzen 7 PRO 5850U, 48GB RAM, AMD Radeon RX Vega 8 (integrated GPU), 4K resolution = **99% CPU usage**\n\nIf your CPU is close to 100%, it may be rasterizing everything in the same CPU process.\n\nPop open `chrome://gpu` and see what's orange or red.\n\n![Chrome gpu](img/chrome-gpu.png \"Chrome gpu\")\n\nThen open `chrome://flags` and search for \"raster\" to see what can be force-enabled.\n\n![Chrome flags](img/chrome-flags.png \"Chrome flags\")\n\n- On my Manjaro/Ryzen/Integrated GPU setup, force-enabling `Canvas out-of-process rasterization` resulted in a dramatic framerate improvement.\n- On my Windows/i7/Dedicated GPU setup, toggling the same flags moved the work to another process (still good), but did not have a significant framerate impact.\n\nYMMV!\n\n---\n### Acknowledgements\n\n- Dan Vanderkam's [dygraphs](https://github.com/danvk/dygraphs) was a big inspiration; in fact, my stale [pull request #948](https://github.com/danvk/dygraphs/pull/948) was a primary motivator for ŒºPlot's inception.\n- Adam Pearce for [#15 - remove redundant lineTo commands](https://github.com/leeoniya/uPlot/issues/15).\n",
      "stars_today": 5
    },
    {
      "id": 135348215,
      "name": "MTProxy",
      "full_name": "TelegramMessenger/MTProxy",
      "description": null,
      "html_url": "https://github.com/TelegramMessenger/MTProxy",
      "stars": 5609,
      "forks": 981,
      "language": "C",
      "topics": [],
      "created_at": "2018-05-29T20:15:11Z",
      "updated_at": "2026-01-24T01:55:10Z",
      "pushed_at": "2025-11-04T11:03:19Z",
      "open_issues": 315,
      "owner": {
        "login": "TelegramMessenger",
        "avatar_url": "https://avatars.githubusercontent.com/u/22377696?v=4"
      },
      "readme": "# MTProxy\nSimple MT-Proto proxy\n\n## Building\nInstall dependencies, you would need common set of tools for building from source, and development packages for `openssl` and `zlib`.\n\nOn Debian/Ubuntu:\n```bash\napt install git curl build-essential libssl-dev zlib1g-dev\n```\nOn CentOS/RHEL:\n```bash\nyum install openssl-devel zlib-devel\nyum groupinstall \"Development Tools\"\n```\n\nClone the repo:\n```bash\ngit clone https://github.com/TelegramMessenger/MTProxy\ncd MTProxy\n```\n\nTo build, simply run `make`, the binary will be in `objs/bin/mtproto-proxy`:\n\n```bash\nmake && cd objs/bin\n```\n\nIf the build has failed, you should run `make clean` before building it again.\n\n## Running\n1. Obtain a secret, used to connect to telegram servers.\n```bash\ncurl -s https://core.telegram.org/getProxySecret -o proxy-secret\n```\n2. Obtain current telegram configuration. It can change (occasionally), so we encourage you to update it once per day.\n```bash\ncurl -s https://core.telegram.org/getProxyConfig -o proxy-multi.conf\n```\n3. Generate a secret to be used by users to connect to your proxy.\n```bash\nhead -c 16 /dev/urandom | xxd -ps\n```\n4. Run `mtproto-proxy`:\n```bash\n./mtproto-proxy -u nobody -p 8888 -H 443 -S <secret> --aes-pwd proxy-secret proxy-multi.conf -M 1\n```\n... where:\n- `nobody` is the username. `mtproto-proxy` calls `setuid()` to drop privileges.\n- `443` is the port, used by clients to connect to the proxy.\n- `8888` is the local port. You can use it to get statistics from `mtproto-proxy`. Like `wget localhost:8888/stats`. You can only get this stat via loopback.\n- `<secret>` is the secret generated at step 3. Also you can set multiple secrets: `-S <secret1> -S <secret2>`.\n- `proxy-secret` and `proxy-multi.conf` are obtained at steps 1 and 2.\n- `1` is the number of workers. You can increase the number of workers, if you have a powerful server.\n\nAlso feel free to check out other options using `mtproto-proxy --help`.\n\n5. Generate the link with following schema: `tg://proxy?server=SERVER_NAME&port=PORT&secret=SECRET` (or let the official bot generate it for you).\n6. Register your proxy with [@MTProxybot](https://t.me/MTProxybot) on Telegram.\n7. Set received tag with arguments: `-P <proxy tag>`\n8. Enjoy.\n\n## Random padding\nDue to some ISPs detecting MTProxy by packet sizes, random padding is\nadded to packets if such mode is enabled.\n\nIt's only enabled for clients which request it.\n\nAdd `dd` prefix to secret (`cafe...babe` => `ddcafe...babe`) to enable\nthis mode on client side.\n\n## Systemd example configuration\n1. Create systemd service file (it's standard path for the most Linux distros, but you should check it before):\n```bash\nnano /etc/systemd/system/MTProxy.service\n```\n2. Edit this basic service (especially paths and params):\n```bash\n[Unit]\nDescription=MTProxy\nAfter=network.target\n\n[Service]\nType=simple\nWorkingDirectory=/opt/MTProxy\nExecStart=/opt/MTProxy/mtproto-proxy -u nobody -p 8888 -H 443 -S <secret> -P <proxy tag> <other params>\nRestart=on-failure\n\n[Install]\nWantedBy=multi-user.target\n```\n3. Reload daemons:\n```bash\nsystemctl daemon-reload\n```\n4. Test fresh MTProxy service:\n```bash\nsystemctl restart MTProxy.service\n# Check status, it should be active\nsystemctl status MTProxy.service\n```\n5. Enable it, to autostart service after reboot:\n```bash\nsystemctl enable MTProxy.service\n```\n\n## Docker image\nTelegram is also providing [official Docker image](https://hub.docker.com/r/telegrammessenger/proxy/).\nNote: the image is outdated.\n",
      "stars_today": 5
    },
    {
      "id": 23690226,
      "name": "xray-16",
      "full_name": "OpenXRay/xray-16",
      "description": "Improved version of the X-Ray Engine, the game engine used in the world-famous S.T.A.L.K.E.R. game series by GSC Game World. Join OpenXRay! ;)",
      "html_url": "https://github.com/OpenXRay/xray-16",
      "stars": 3403,
      "forks": 500,
      "language": "C++",
      "topics": [
        "3d-engine",
        "arm64",
        "cmake",
        "cplusplus",
        "cpp17",
        "d3d11",
        "directx",
        "directx11",
        "engine",
        "game",
        "game-engine",
        "gamedev",
        "mod",
        "opengl",
        "opensource",
        "sdl",
        "sdl2",
        "stalker",
        "x64",
        "xray-engine"
      ],
      "created_at": "2014-09-05T04:28:23Z",
      "updated_at": "2026-01-24T00:27:16Z",
      "pushed_at": "2026-01-19T14:37:01Z",
      "open_issues": 259,
      "owner": {
        "login": "OpenXRay",
        "avatar_url": "https://avatars.githubusercontent.com/u/8896523?v=4"
      },
      "readme": "<div align=\"center\">\n  <p>\n    <a href=\"https://github.com/OpenXRay\">\n      <img src=\"misc/media/OpenXRayCover.png\" alt=\"Open for everyone\" />\n    </a>\n  </p>\n</div>\n\n<h1 align=\"center\">\n  OpenXRay\n</h1>\n\n**OpenXRay** is an improved version of the X-Ray Engine, the game engine used in the world-famous S.T.A.L.K.E.R. game series by GSC Game World.\n\nThis is a fan-made project not affiliated with GSC Game World in any way.\nHowever, they know about many community projects, including this, and support S.T.A.L.K.E.R. community efforts to make the game better.\n\nInstallation instructions are on the [How to install and play](https://github.com/OpenXRay/xray-16/wiki/[EN]-How-to-install-and-play) page.\n\n## Supported game platforms\n- Call of Chernobyl 1.4.22.\n- Call of Pripyat 1.6.02.\n- Clear Sky 1.5.10. (minor bugs are possible, but the game is stable finishable. See [#382](https://github.com/OpenXRay/xray-16/issues/382))\n\nShadow of Chernobyl is **not supported** yet. (see [#392](https://github.com/OpenXRay/xray-16/issues/392)) <br>\nLegends of the Zone/Enhanced Edition is not supported and won't ever be likely. (see [#1865](https://github.com/OpenXRay/xray-16/issues/1865))\n\n## Main differences from the original X-Ray\n- Support for 64-bit.\n- Improved performance, better FPS.\n- Original bugs fixes.\n- New features for modmakers.\n- Works on Linux, macOS, *BSDs and supports ARM, ARM64, E2K (Elbrus 2000), PPC64LE architectures.\n\nYou can see the detailed differences table [here](https://github.com/OpenXRay/xray-16/wiki/%5BEN%5D-Differences-from-original-X‚ÄêRay).\n\n## Goals\n1. Clean up engine code, boost performance, and fix original X-Ray Engine bugs that were polluting S.T.A.L.K.E.R. series.\n2. Make it a drop-in replacement for original engine.\n    1. Aim at 99% compatibility and same behaviour, where possible.\n3. Support all three games in the series: SOC/CS/COP.\n4. Introduce a solid platform for modmakers:\n    1. Add frame/render graph for those who want to add new graphics features.\n    2. Add new scripting, development and debugging features.\n    3. New game SDK with new features.\n5. Enhance player's experience with new graphics, gameplay and other features that can be enabled optionally. (by default, we stay close to vanilla)\n\n## Contributing\nAll contributions are more than welcomed. There are several ways how you can contribute:\n\n### Community\n[![Discord](https://img.shields.io/discord/410170555619082240?label=Discord)](https://discord.gg/sjRMQwv)\n\nPlay and enjoy the game, [file an Issue](https://github.com/OpenXRay/xray-16/issues/new/choose) when you encounter any bugs, or you have an enhancement request.\n\nJoin us on our [Discord](https://discord.gg/sjRMQwv), subscribe to our [YouTube channel](https://www.youtube.com/OpenXRay), join our [VK group](https://vk.com/openxray), leave a comment, put a like and communicate there! <br>\nAlso you can put a star on this repository or boost our Discord server :)\n\n### Modding\n\nUse OpenXRay as a platform for your work!\n\nMake sure to follow the official EULA and Fan Content Creation Guidelines when making modifications for S.T.A.L.K.E.R. games: <br>\nhttps://www.gsc-game.com/eula/ <br>\nhttps://www.gsc-game.com/guidelines/\n\n### Development\n[![GitHub Actions Build Status](https://github.com/OpenXRay/xray-16/actions/workflows/cibuild.yml/badge.svg)](https://github.com/OpenXRay/xray-16/actions/workflows/cibuild.yml)\n[![Contributors](https://img.shields.io/github/contributors/OpenXRay/xray-16.svg?label=Contributors)](https://github.com/OpenXRay/xray-16/graphs/contributors)\n\nJoin our efforts in making our beloved game better, send pull requests, participate in discussions and code reviews!\n\nIt is a place to share ideas on what to implement, gather people that want to work on the engine, and work on the source code. However, the following things should be taken into consideration:\n* We want to keep the game close to the vanilla, so if you want to introduce new gameplay features, make sure it is optional, and doesn't break compatibility with original game resources (i.e. everything in `gamedata` folder and `.db*`/`.xdb` archives). You also may want to add non-gameplay features, fix bugs, or improve engine performance and code quality.\n* Major changes should be discussed before implementation.\n\nTake a look at our [Issues](https://github.com/openxray/xray-16/issues) page:\n* See issues labeled as [good first issue](https://github.com/OpenXRay/xray-16/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc+label%3A%22Good+first+issue%22) to get familiar with the engine code in practice.\n* You may also want to look at issues labeled as [help wanted](https://github.com/OpenXRay/xray-16/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc+label%3A%22Help+wanted%22). Some of them are difficult ones, though.\n\nMake sure to visit our [wiki](https://github.com/OpenXRay/xray-16/wiki):\n* [Build instructions for Windows](https://github.com/OpenXRay/xray-16/wiki/[EN]-How-to-build-and-setup-on-Windows).\n* [Build instructions for Linux and other platforms](https://github.com/OpenXRay/xray-16/wiki/%5BEN%5D-How-to-build-and-setup-on-Linux-and-MacOS).\n\nThe `dev` branch is the default and base branch for the project. It is used for development, and all pull requests should go there. But be aware that this branch sometimes may be broken, and we can only rarely do force pushes to this branch.\n\nThe code base is based on X-Ray 1.6.02 that is used in S.T.A.L.K.E.R.: Call of Pripyat and it was greatly refactored.\n\n### Funding\n[![Financial Contributors](https://opencollective.com/openxray/tiers/badge.svg?label=Financial%20contributors)](https://opencollective.com/openxray) [![Sponsors](https://img.shields.io/github/sponsors/openxray?color=brightgreen&label=Sponsors)](https://github.com/sponsors/OpenXRay) [![Patreon](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fwww.patreon.com%2Fapi%2Fcampaigns%2F5950725&query=data.attributes.patron_count&suffix=%20Patrons&color=success&label=Patreon&style=flat)](https://patreon.com/openxray)\n\nYou may provide financial support for this project by donating via different ways:\n* [Boosty](https://boosty.to/openxray) ‚Äì a large part of the team is located in Russia, if you have an ability to donate through Boosty, please use it, since we don't have an ability to withdraw funds from services like Patreon, etc. to our local Russian banking cards/accounts.\n* [GitHub Sponsors](https://github.com/sponsors/OpenXRay), [Patreon](https://patreon.com/openxray), [Open Collective](https://opencollective.com/openxray) ‚Äì funds raised from these services will be used to support our developers outside of Russia, and also we may use them to pay for paid services on GitHub, AppVeyor, etc.\n* BTC: 363ZUoWcQe9fDvRPK9Kee2YuPdyhSFQpr2\n* ETH: 0x45a4fe8566e76946591e1eeabf190aa09b1cdb66\n* TRX: TGx7QAhTPsRcwnb4mwCtNDU7NF6kuoACpt\n* Please, contact @1yohji in [our Discord](discord.gg/sjRMQwv) if you would like to use another cryptocurrency.\n\nThank you for your support!\n\n## Thanks\n* [GSC Game World](https://gsc-game.com/) ‚Äì for creating S.T.A.L.K.E.R. and supporting the community.\n* Loxotron ‚Äì for making the engine sources available.\n* [All the OpenXRay contributors](https://github.com/OpenXRay/xray-16/graphs/contributors) ‚Äì for making the project what it is:\n  * The OpenXRay team:\n    * [nitrocaster](https://github.com/nitrocaster) ‚Äì original project founder.\n    * [Kaffeine](https://github.com/Kaffeine) ‚Äì initial work on the Linux port, refactoring, polishing.\n    * [CrossVR](https://github.com/CrossVR) (Armada651) ‚Äì creation of the OpenGL renderer, work on the build system, other project maintenance work.\n    * [andrew-boyarshin](https://github.com/andrew-boyarshin) ‚Äì work on the build system.\n    * [CasualDev242](https://github.com/CasualDev242) (Swartz27) ‚Äì work on renderer features.\n    * [awdavies](https://github.com/awdavies) ‚Äì project maintenance work.\n    * [Xottab_DUTY](https://github.com/Xottab-DUTY) ‚Äì former project leader (2018-2026), gathering a new team, creation of the community (GitHub, Discord, VK), defining project guiding principles and goals, working on many areas of tasks (core, renderering, AI, gameplay, UI), SOC/CS/COC support.\n    * [intorr](https://github.com/intorr) ‚Äì work on the project quality, memory leaks, refactoring and optimizations.\n    * [eagleivg](https://github.com/eagleivg) ‚Äì main part of the work on Linux port.\n    * [q4a](https://github.com/q4a) ‚Äì main part of the work on Linux port.\n    * [SkyLoader](https://github.com/SkyLoaderr) ‚Äì OpenGL renderer improvements, stabilization and polishing, other project work.\n    * [qweasdd136963](https://github.com/qweasdd136963) ‚Äì supporting the [OXR_COC](https://github.com/qweasdd136963/OXR_CoC) project (Call of Chernobyl port to latest OpenXRay), other project work on new features, refactoring and bug fixing.\n    * [JohnDoe_71Rus](https://github.com/johndoe71rus) ‚Äì our regular tester.\n    * [Chip_exe](https://github.com/007exe) ‚Äì work on Linux port, maintaining AUR package, our regular tester.\n    * [a1batross](https://github.com/a1batross) ‚Äì work on Linux port.\n    * [The Sin!](https://github.com/FreeZoneMods) ‚Äì new features, refactoring, bug fixing polishing.\n    * [Zegeri](https://github.com/Zegeri) ‚Äì work on Linux port, code quality, fixes, polishing.\n    * [drug007](https://github.com/drug007) ‚Äì work on Linux port.\n    * [vTurbine](https://github.com/vTurbine) ‚Äì work on renderer multithreading, improvements and refactoring.\n    * [Zigatun](https://github.com/Zigatun) ‚Äì work on ARM port.\n    * [Masterkatze](https://github.com/Masterkatze) ‚Äì work on the build system, bug fixing.\n    * [Chugunov Roman](https://github.com/ChugunovRoman) ‚Äì work on [porting Call of Chernobyl to latest OpenXRay](https://github.com/ChugunovRoman/xray-16), extending functionality for modmakers.\n    * [yohjimane](https://github.com/yohjimane) ‚Äì lead developer (2026-current), work on introducing many new features, fixing original engine bugs\n  * Other contributors:\n    * [alexgdi](https://github.com/alexgdi) ‚Äì work on organizing project infrastructure, external dependencies.\n    * [Shoker](https://github.com/ShokerStlk) ‚Äì contributing new features, bug fixing.\n    * [Alundaio](https://github.com/revolucas) ‚Äì useful new features, bug fixes and optimizations.\n    * [NeoAnomaly](https://github.com/NeoAnomaly) ‚Äì help with debug functionality on Windows.\n    * [RainbowZerg](https://github.com/RainbowZerg) ‚Äì work on the renderer features, bug fixing.\n    * [FozeSt](https://github.com/FozeSt) ‚Äì help with some fixes and features.\n    * [justtails](https://github.com/justtails) (mrnotbadguy) ‚Äì work on gamepads support and bug fixing.\n    * [devnexen](https://github.com/devnexen) ‚Äì work on FreeBSD support and portability.\n    * [vamit611](https://github.com/vamit611) ‚Äì work on code quality and bug fixes.\n    * [ZeeWanderer](https://github.com/ZeeWanderer) ‚Äì work on the build system.\n    * [GeorgeIvlev](https://github.com/GeorgeIvlev) ‚Äì work on the build system, bug fixing.\n    * [r-a-sattarov](https://github.com/r-a-sattarov) ‚Äì work on portability and E2K support.\n    * [TmLev](https://github.com/TmLev) ‚Äì work on code quality and Docker support.\n    * [Plotja](https://github.com/Plotja) ‚Äì work on new gameplay features, bug fixes, portability, polishing.\n    * [jjdredd](https://github.com/jjdredd) ‚Äì work on various useful features.\n    * [dimhotepus](https://github.com/dimhotepus) ‚Äì work on code quality.\n    * [HeapRaid](https://github.com/HeapRaid) ‚Äì work on renderer cleanup, code quality, portability.\n    * [OPNA2608](https://github.com/OPNA2608) ‚Äì maintaining NixOS package, work on portability.\n    * [kosumosu](https://github.com/kosumosu) ‚Äì work on portability, including E2K support, and renderer features.\n    * [Graff46](https://github.com/Graff46) ‚Äì work on various scripting features.\n    * [vertver](https://github.com/vertver) ‚Äì work on macOS support.\n    * [Lnd-stoL](https://github.com/Lnd-stoL) ‚Äì work on macOS support.\n    * [GermanAizek](https://github.com/GermanAizek) ‚Äì work on code quality, finding and fixing vanilla bugs.\n    * [dasehak](https://github.com/dasehak) ‚Äì work on FreeBSD support, finding and fixing vanilla bugs.\n    * [Hrust](https://github.com/Hrusteckiy) ‚Äì work various features, including UI, CS/SOC support and bug fixes.\n    * [johncurley](https://github.com/johncurley) ‚Äì work on EFX, bugs and portability.\n    * [v2v3v4](https://github.com/v2v3v4) ‚Äì work on physics, useful help with the engine and showing sexy screenshots and videos about his X-Ray fork, but refusing to send pull requests :D\n    * [Neloreck](https://github.com/Neloreck) ‚Äì work on extending Lua scripting features.\n    * [sobkas](https://github.com/sobkas) ‚Äì work on code quality and bug fixing.\n    * [AMS21](https://github.com/AMS21) ‚Äì work on CMake, code quality, and project standards and infrastructure.\n    * [olefirenque](https://github.com/olefirenque) ‚Äì work on multithreading and code optimization.\n    * [tsmp](https://github.com/tsmp) ‚Äì work on performance and code optimization.\n  * Individuals, whose work was used, merged or imported:\n    * [Im-Dex](https://github.com/Im-dex/xray-162) ‚Äì x64 support, work on the engine.\n    * [tamlin-mike](https://github.com/tamlin-mike) ‚Äì work on the build system.\n    * [Vincent](https://github.com/0xBADEAFFE) ‚Äì work on the Linux port.\n    * [abramcumner](https://github.com/abramcumner) ‚Äì useful fixes and additions.\n    * [Morrey](https://github.com/morrey) (nouverbe, [viventaje](https://github.com/viventaje)) ‚Äì work on DX12 renderer, Clear Sky support and his Return to Clear Sky mod.\n    * [avoitishin](https://github.com/avoitishin) ‚Äì work on scripting features expansion, other improvements and fixes.\n  * Financial supporters:\n    * [nitrocaster](https://github.com/nitrocaster), Lukas Friedrich, Luke Jones, NekoIt, Igor Polyakov,\n    * Incognito, PJ, RazDva, astral jellybean, Kirill Reprintsev,\n    * [John Curley](https://github.com/johncurley), The ParaziT, [clayne](https://github.com/clayne), [sobkas](https://github.com/sobkas), MANfromMOON,\n    * Valevicor, Nac, Midiy, Vadim Balashov, Jacob Arms,\n    * CatWMuttonChops, Reed777, Interpreter_, nexusasx10, [Egor Olefirenko](https://github.com/olefirenque),\n    * Igor Zharenko, SLF, Dmitriy Terletskiy, Alex Brodskiy, Neizvestniy Chelovek,\n    * LinuxNerd, [tyabus](https://github.com/tyabus), [Sevenfortyseven](https://github.com/Sevenfortyseven), 777yur0k, ItzVladik,\n    * @psistore, @forealdo25, Tech Racoon\n* Particular projects and their contributors:\n  * [Oxygen](https://github.com/xrOxygen) ‚Äì for being our friends and giving tips and help with new features, optimizations, bug fixes, etc.\n  * [Shoker Weapon Mod](https://github.com/ShokerStlk/xray-16-SWM) ‚Äì for first introducing 3D (PiP) scopes and implementing new features to overall improve the weaponry of the game.\n  * [OGSR](https://github.com/OGSR/OGSR-Engine) ‚Äì for amazing work on Shadow of Chernobyl.\n  * [Call of Chernobyl](https://github.com/revolucas/CoC-Xray) ‚Äì for useful new features, bug fixes and optimizations.\n    * [Anomaly](https://www.moddb.com/mods/stalker-anomaly) ‚Äì for pushing the boundaries, adding new features and enhancing player experience.\n  * [Lost Alpha](https://www.moddb.com/mods/lost-alpha) ‚Äì for their effort on restoring the old game concept.\n    * Lost Alpha DC ‚Äì for continuing work on Lost Alpha and mastering it.\n  * [Living Zone](https://vk.com/projektx) ‚Äì for pushing the limits of our engine past the edge.\n  * [OpenXRay Gunslinger](https://www.moddb.com/mods/openxray-gunslinger) ‚Äì for introducing new fascinating features and enhancing the game experience with players-approved weapon pack on top of OpenXRay.\n  * [IX-Ray](https://github.com/ixray-team) ‚Äì for being at the edge of technology.\n* Companies:\n  * [CoderGears](https://www.cppdepend.com) ‚Äì thanks for providing a [free Pro Licence for CppDepend](https://www.cppdepend.com/cppdependfoross), an amazing and powerful tool for C and C++. <br>\n    [![CppDepend logo](https://www.cppdepend.com/images/cppdependlogo.png)](https://www.cppdepend.com)\n  * [PVS-Studio LLC](https://pvs-studio.com/pvs-studio/?utm_source=website&utm_medium=github&utm_campaign=open_source) ‚Äì thanks for proving us a [free licence](https://pvs-studio.ru/ru/order/open-source-license/?utm_source=website&utm_medium=github&utm_campaign=open_source) for PVS-Studio, a static analyzer for C, C++, C#, and Java code.\n\nIf your work is being used in our project and you are not mentioned here or in the [contributors page](https://github.com/OpenXRay/xray-16/graphs/contributors), please, write to us and we will add you. Or send us a pull request with you added to this list ;)\n",
      "stars_today": 5
    },
    {
      "id": 870686739,
      "name": "podkop",
      "full_name": "itdoginfo/podkop",
      "description": "Dev podkop",
      "html_url": "https://github.com/itdoginfo/podkop",
      "stars": 1282,
      "forks": 105,
      "language": "JavaScript",
      "topics": [],
      "created_at": "2024-10-10T13:40:31Z",
      "updated_at": "2026-01-23T18:17:57Z",
      "pushed_at": "2026-01-23T14:06:58Z",
      "open_issues": 35,
      "owner": {
        "login": "itdoginfo",
        "avatar_url": "https://avatars.githubusercontent.com/u/11143109?v=4"
      },
      "readme": "# –í–µ—â–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤–∞–º –Ω—É–∂–Ω–æ –∑–Ω–∞—Ç—å –ø–µ—Ä–µ–¥ —É—Å—Ç–∞–Ω–æ–≤–∫–æ–π\n\n- –≠—Ç–æ –±–µ—Ç–∞-–≤–µ—Ä—Å–∏—è, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –∞–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ. –ò–∑ –≤–µ—Ä—Å–∏–∏ –≤ –≤–µ—Ä—Å–∏—é —á—Ç–æ-—Ç–æ –º–æ–∂–µ—Ç –º–µ–Ω—è—Ç—å—Å—è.\n- –ü—Ä–∏ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏ –ø—Ä–æ–±–ª–µ–º, –Ω—É–∂–µ–Ω —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏ –≥—Ä–∞–º–æ—Ç–Ω—ã–π —Ñ–∏–¥–±—ç–∫ –≤ —á–∞—Ç. –û–∑–Ω–∞–∫–æ–º—å—Ç–µ—Å—å —Å –∑–∞–∫—Ä–µ–ø–æ–º –≤ —Ç–æ–ø–∏–∫–µ.\n- –ü—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ **–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ** [—Å–±—Ä–∞—Å—ã–≤–∞–π—Ç–µ –∫—ç—à LuCI](https://podkop.net/docs/clear-browser-cache/).\n- –¢–∞–∫–∂–µ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –≤—Å–µ–≥–¥–∞ –∑–∞—Ö–æ–¥–∏—Ç–µ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏ –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ —Å–≤–æ–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–∂–µ—Ç –∏–∑–º–µ–Ω–∏—Ç—å—Å—è.\n- –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –º–∏–Ω–∏–º—É–º 25–ú–ë —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞ –Ω–∞ —Ä–æ—É—Ç–µ—Ä–µ. –†–æ—É—Ç–µ—Ä—ã —Å —Ñ–ª–µ—à–∫–∞–º–∏ –Ω–∞ 16–ú–ë —Å—Ä–∞–∑—É –º–∏–º–æ.\n- –ü—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ—Ç—Å—è –∫–æ–Ω—Ñ–∏–≥ Dnsmasq.\n- Podkop —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ—Ç –∫–æ–Ω—Ñ–∏–≥ sing-box. –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ –≤–∞—à –∫–æ–Ω—Ñ–∏–≥ sing-box –ø–µ—Ä–µ–¥ —É—Å—Ç–∞–Ω–æ–≤–∫–æ–π, –µ—Å–ª–∏ –æ–Ω –≤–∞–º –Ω—É–∂–µ–Ω.\n- –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–¥–µ—Å—å –º–æ–∂–µ—Ç –±—ã—Ç—å —É—Å—Ç–∞—Ä–µ–≤—à–µ–π. –í—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ñ–∏–∫—Å–∏—Ä—É—é—Ç—Å—è –≤ [—Ç–µ–ª–µ–≥—Ä–∞–º-—á–∞—Ç–µ](https://t.me/itdogchat/81758/420321).\n- [–ï—Å–ª–∏ —É –≤–∞—Å —á—Ç–æ-—Ç–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç.](https://podkop.net/docs/diagnostics/)\n- –ï—Å–ª–∏ —É –≤–∞—Å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω Getdomains, [–µ–≥–æ —Å–ª–µ–¥—É–µ—Ç —É–¥–∞–ª–∏—Ç—å](https://github.com/itdoginfo/domain-routing-openwrt?tab=readme-ov-file#%D1%81%D0%BA%D1%80%D0%B8%D0%BF%D1%82-%D0%B4%D0%BB%D1%8F-%D1%83%D0%B4%D0%B0%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F).\n- –¢—Ä–µ–±—É–µ—Ç—Å—è –≤–µ—Ä—Å–∏—è OpenWrt 24.10.\n- Dashboard –¥–æ—Å—Ç—É–ø–µ–Ω, –µ—Å–ª–∏ –≤—ã –∑–∞—Ö–æ–¥–∏—Ç–µ –ø–æ http (–∏–∑-–∑–∞ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–µ–π clash api). –ò –Ω–µ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å, –µ—Å–ª–∏ –≤—ã –∑–∞—Ö–æ–¥–∏—Ç–µ –ø–æ https –∏/–∏–ª–∏ –¥–æ–º–µ–Ω—É.\n\n# –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è\nhttps://podkop.net/\n\n# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Podkop\n–ü–æ–ª–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤ [–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏](https://podkop.net/docs/install/)\n\n–í–∫—Ä–∞—Ç—Ü–µ, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–¥–Ω–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞ –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è:\n```\nsh <(wget -O - https://raw.githubusercontent.com/itdoginfo/podkop/refs/heads/main/install.sh)\n```\n\n## –ò–∑–º–µ–Ω–µ–Ω–∏—è 0.7.0\n–ù–∞—á–∏–Ω–∞—è —Å –≤–µ—Ä—Å–∏–∏ 0.7.0 –∏–∑–º–µ–Ω–µ–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–æ–Ω—Ñ–∏–≥–∞ `/etc/config/podkop`. –°—Ç–∞—Ä—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º—ã —Å –Ω–æ–≤—ã–º–∏. –ù—É–∂–Ω–æ –∑–∞–Ω–æ–≤–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å Podkop.\n\n–°–∫—Ä–∏–ø—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ–±–Ω–∞—Ä—É–∂–∏—Ç —Å—Ç–∞—Ä—É—é –≤–µ—Ä—Å–∏—é –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–¥–∏—Ç –≤–∞—Å –æ–± —ç—Ç–æ–º. –ï—Å–ª–∏ –≤—ã —Å–æ–≥–ª–∞—Å–∏—Ç–µ—Å—å, —Ç–æ –æ–Ω —Å–¥–µ–ª–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–ø–∏—Å–∞–Ω–Ω–æ–µ –Ω–∏–∂–µ.\n\n–ü—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –≤—Ä—É—á–Ω—É—é –Ω—É–∂–Ω–æ:\n\n0. –ù–µ –Ω—ã—Ç—å –≤ issue –∏ —á–∞—Ç–∏–∫.\n1. –ó–∞–±—ç–∫–∞–ø–∏—Ç—å —Å—Ç–∞—Ä—ã–π –∫–æ–Ω—Ñ–∏–≥:\n```\nmv /etc/config/podkop /etc/config/podkop-070\n```\n2. –°—Ç—è–Ω—É—Ç—å –Ω–æ–≤—ã–π –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥:\n```\nwget -O /etc/config/podkop https://raw.githubusercontent.com/itdoginfo/podkop/refs/heads/main/podkop/files/etc/config/podkop\n```\n3. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –∑–∞–Ω–æ–≤–æ –≤–∞—à Podkop —á–µ—Ä–µ–∑ Luci –∏–ª–∏ UCI.\n\n# ToDo\n\n> [!IMPORTANT]  \n> PR –ø—Ä–∏–Ω–∏–º–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–æ issues, —É –∫–æ—Ç–æ—Ä—ã—Ö —Å—Ç–æ–∏—Ç label \"enhancement\". –õ–∏–±–æ –ø–æ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—é —Å –∞–≤—Ç–æ—Ä–∞–º–∏ –≤ –¢–ì-—á–∞—Ç–µ. –û—Å—Ç–∞–ª—å–Ω—ã–µ PR –Ω–∞ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç –Ω–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç—Å—è.\n\n## –ë—É–¥—É—â–µ–µ\n- [ ] [–ü–æ–¥–ø–∏—Å–∫–∞](https://github.com/itdoginfo/podkop/issues/118). –ó–¥–µ—Å—å –Ω—É–∂–Ω–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è, —á—Ç–æ–± –¥–ª—è –∫–∞–∂–¥–æ–π —Å–µ–∫—Ü–∏–∏ –ø–æ–º–∏–º–æ —Ä—É—á–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞, –±—ã–ª –≤—ã–±–æ—Ä —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ —Ç–µ–≥—É. –ù–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è main –≤—ã–±–∏—Ä–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ NL, DE, FI. –ê –¥–ª—è extra —Å–µ–∫—Ü–∏–∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ RU. –ò —Å–æ–∑–¥–∞—ë—Ç—Å—è outbound c urltest –≤ –∫–æ—Ç–æ—Ä—ã—Ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω—ã outbound –∏–∑ —Ñ–∏–ª—å—Ç—Ä–æ–≤.\n- [ ] –í–µ—Å—å —Ç—Ä–∞—Ñ–∏–∫ –≤ sing-box –∏ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–∞ –µ–≥–æ —É—Ä–æ–≤–Ω–µ.\n- [ ] –ü—Ä–∏ —É—Å–ø–µ—à–Ω–æ–º –∑–∞–ø—É—Å–∫–µ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç –≤ —Ñ–æ–Ω–æ–≤—ã–π —Ä–µ–∂–∏–º –∏ —Å–ª–µ–¥–∏—Ç –∑–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º sing-box. –ï—Å–ª–∏ –≤–¥—Ä—É–≥ –∏–¥—ë—Ç exit 1, –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è dnsmasq restore –∏ —Å–Ω–æ–≤–∞ —Å–ª–µ–¥–∏—Ç –∑–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º. –í–æ–ø—Ä–æ—Å –≤ —Ç–æ–º, –∫–∞–∫ —ç—Ç–æ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ –ø—Ä–æ–≤–µ—Ä–Ω—É—Ç—å. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ø–æ–ª–æ–∂–∏—Ç—å –ø—Ä–æ–∫—Å–∏ –∏ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å, –æ—Å—Ç–∞–Ω–µ—Ç—Å—è –ª–∏ —Ä–∞–±–æ—Ç–∞—Ç—å DNS –≤ —ç—Ç–æ–º —Å–ª—É—á–∞–µ. –ò –∑–¥–µ—Å—å, –≤–µ—Ä–æ—è—Ç–Ω–æ, –º–æ–∂–Ω–æ –æ–±–æ–π—Ç–∏—Å—å —Ç—Ä–∏–≥–≥–µ—Ä–æ–º –≤ init.d. [Issue](https://github.com/itdoginfo/podkop/issues/111)\n- [ ] –ì–∞–ª–æ—á–∫–∞, –∫–æ—Ç–æ—Ä–∞—è —Ä–µ–∂–µ—Ç –¥–æ—Å—Ç—É–ø –∫ doh —Å–µ—Ä–≤–µ—Ä–∞–º.\n- [ ] IPv6. –¢–æ–ª—å–∫–æ –ø–æ—Å–ª–µ –Ω–∞–ø–æ–ª–Ω–µ–Ω–∏—è Wiki.\n\n## –¢–µ—Å—Ç—ã\n- [ ] Unit —Ç–µ—Å—Ç—ã (BATS)\n- [ ] –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –±–µ–∫–µ–Ω–¥–∞ (OpenWrt rootfs + BATS)\n\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/itdoginfo/podkop)",
      "stars_today": 5
    },
    {
      "id": 43723161,
      "name": "helm",
      "full_name": "helm/helm",
      "description": "The Kubernetes Package Manager",
      "html_url": "https://github.com/helm/helm",
      "stars": 29333,
      "forks": 7466,
      "language": "Go",
      "topics": [
        "chart",
        "charts",
        "cncf",
        "helm",
        "kubernetes"
      ],
      "created_at": "2015-10-06T01:07:32Z",
      "updated_at": "2026-01-23T23:15:29Z",
      "pushed_at": "2026-01-23T00:18:15Z",
      "open_issues": 408,
      "owner": {
        "login": "helm",
        "avatar_url": "https://avatars.githubusercontent.com/u/15859888?v=4"
      },
      "readme": "# Helm\n\n[![Build Status](https://github.com/helm/helm/workflows/release/badge.svg)](https://github.com/helm/helm/actions?workflow=release)\n[![Go Report Card](https://goreportcard.com/badge/helm.sh/helm/v4)](https://goreportcard.com/report/helm.sh/helm/v4)\n[![GoDoc](https://img.shields.io/static/v1?label=godoc&message=reference&color=blue)](https://pkg.go.dev/helm.sh/helm/v4)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/3131/badge)](https://bestpractices.coreinfrastructure.org/projects/3131)\n[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/helm/helm/badge)](https://scorecard.dev/viewer/?uri=github.com/helm/helm)\n[![LFX Health Score](https://insights.linuxfoundation.org/api/badge/health-score?project=helm)](https://insights.linuxfoundation.org/project/helm)\n\nHelm is a tool for managing Charts. Charts are packages of pre-configured Kubernetes resources.\n\nUse Helm to:\n\n- Find and use [popular software packaged as Helm Charts](https://artifacthub.io/packages/search?kind=0) to run in Kubernetes\n- Share your own applications as Helm Charts\n- Create reproducible builds of your Kubernetes applications\n- Intelligently manage your Kubernetes manifest files\n- Manage releases of Helm packages\n\n## Helm in a Handbasket\n\nHelm is a tool that streamlines installing and managing Kubernetes applications.\nThink of it like apt/yum/homebrew for Kubernetes.\n\n- Helm renders your templates and communicates with the Kubernetes API\n- Helm runs on your laptop, CI/CD, or wherever you want it to run.\n- Charts are Helm packages that contain at least two things:\n  - A description of the package (`Chart.yaml`)\n  - One or more templates, which contain Kubernetes manifest files\n- Charts can be stored on disk, or fetched from remote chart repositories\n  (like Debian or RedHat packages)\n\n## Helm Development and Stable Versions\n\nHelm v4 is currently under development on the `main` branch. This is unstable and the APIs within the Go SDK and at the command line are changing.\nHelm v3 (current stable) is maintained on the `dev-v3` branch. APIs there follow semantic versioning.\n\n## Install\n\nBinary downloads of the Helm client can be found on [the Releases page](https://github.com/helm/helm/releases/latest).\n\nUnpack the `helm` binary and add it to your PATH and you are good to go!\n\nIf you want to use a package manager:\n\n- [Homebrew](https://brew.sh/) users can use `brew install helm`.\n- [Chocolatey](https://chocolatey.org/) users can use `choco install kubernetes-helm`.\n- [Winget](https://learn.microsoft.com/en-us/windows/package-manager/) users can use `winget install Helm.Helm`.\n- [Scoop](https://scoop.sh/) users can use `scoop install helm`.\n- [Snapcraft](https://snapcraft.io/) users can use `snap install helm --classic`.\n- [Flox](https://flox.dev) users can use `flox install kubernetes-helm`.\n- [Mise-en-place](https://mise.jdx.dev/) users can use `mise use -g helm@latest`\n\nTo rapidly get Helm up and running, start with the [Quick Start Guide](https://helm.sh/docs/intro/quickstart/).\n\nSee the [installation guide](https://helm.sh/docs/intro/install/) for more options,\nincluding installing pre-releases.\n\n## Docs\n\nGet started with the [Quick Start guide](https://helm.sh/docs/intro/quickstart/) or plunge into the [complete documentation](https://helm.sh/docs).\n\n## Roadmap\n\nThe [Helm roadmap uses GitHub milestones](https://github.com/helm/helm/milestones) to track the progress of the project.\n\nThe development of Helm v4 is currently happening on the `main` branch while the development of Helm v3, the stable branch, is happening on the `dev-v3` branch. Changes should be made to the `main` branch prior to being added to the `dev-v3` branch so that all changes are carried along to Helm v4.\n\n## Community, discussion, contribution, and support\n\nYou can reach the Helm community and developers via the following channels:\n\n- [Kubernetes Slack](https://kubernetes.slack.com):\n  - [#helm-users](https://kubernetes.slack.com/messages/helm-users)\n  - [#helm-dev](https://kubernetes.slack.com/messages/helm-dev)\n  - [#charts](https://kubernetes.slack.com/messages/charts)\n- Mailing List:\n  - [Helm Mailing List](https://lists.cncf.io/g/cncf-helm)\n- Developer Call: Thursdays at 9:30-10:00 Pacific ([meeting details](https://github.com/helm/community/blob/master/communication.md#meetings))\n\n### Contribution\n\nIf you're interested in contributing, please refer to the [Contributing Guide](CONTRIBUTING.md) **before submitting a pull request**.\n\n### Code of conduct\n\nParticipation in the Helm community is governed by the [Code of Conduct](code-of-conduct.md).\n",
      "stars_today": 4
    },
    {
      "id": 1103607,
      "name": "jenkins",
      "full_name": "jenkinsci/jenkins",
      "description": "Jenkins automation server",
      "html_url": "https://github.com/jenkinsci/jenkins",
      "stars": 24944,
      "forks": 9334,
      "language": "Java",
      "topics": [
        "cicd",
        "continuous-delivery",
        "continuous-deployment",
        "continuous-integration",
        "devops",
        "groovy",
        "hacktoberfest",
        "java",
        "jenkins",
        "pipelines-as-code"
      ],
      "created_at": "2010-11-22T21:21:23Z",
      "updated_at": "2026-01-23T16:55:54Z",
      "pushed_at": "2026-01-23T16:42:47Z",
      "open_issues": 3545,
      "owner": {
        "login": "jenkinsci",
        "avatar_url": "https://avatars.githubusercontent.com/u/107424?v=4"
      },
      "readme": "<a href=\"https://jenkins.io\">\n    <img width=\"400\" src=\"https://www.jenkins.io/images/jenkins-logo-title-dark.svg\" alt=\"Jenkins logo\"> \n</a>\n\n[![Jenkins Regular Release](https://img.shields.io/endpoint?url=https%3A%2F%2Fwww.jenkins.io%2Fchangelog%2Fbadge.json)](https://www.jenkins.io/changelog)\n[![Jenkins LTS Release](https://img.shields.io/endpoint?url=https%3A%2F%2Fwww.jenkins.io%2Fchangelog-stable%2Fbadge.json)](https://www.jenkins.io/changelog-stable)\n[![Docker Pulls](https://img.shields.io/docker/pulls/jenkins/jenkins.svg)](https://hub.docker.com/r/jenkins/jenkins/)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/3538/badge)](https://bestpractices.coreinfrastructure.org/projects/3538)\n[![Reproducible Builds](https://img.shields.io/badge/Reproducible_Builds-ok-green)](https://maven.apache.org/guides/mini/guide-reproducible-builds.html)\n[![Gitter](https://img.shields.io/gitter/room/jenkinsci/jenkins)](https://app.gitter.im/#/room/#jenkinsci_jenkins:gitter.im)\n\n---\n\n# Table of Contents\n\n- [About](#about)\n- [What to Use Jenkins for and When to Use It](#what-to-use-jenkins-for-and-when-to-use-it)\n- [Downloads](#downloads)\n- [Getting Started (Development)](#getting-started-development)\n- [Source](#source)\n- [Contributing to Jenkins](#contributing-to-jenkins)\n- [News and Website](#news-and-website)\n- [Governance](#governance)\n- [Adopters](#adopters)\n- [License](#license)\n\n---\n\n# About\n\nIn a nutshell, Jenkins is the leading open-source automation server.\nBuilt with Java, it provides over 2,000 [plugins](https://plugins.jenkins.io/) to support automating virtually anything,\nso that humans can spend their time doing things machines cannot.\n\n# What to Use Jenkins for and When to Use It\n\nUse Jenkins to automate your development workflow, so you can focus on work that matters most. Jenkins is commonly used for:\n\n- Building projects\n- Running tests to detect bugs and other issues as soon as they are introduced\n- Static code analysis\n- Deployment\n\nExecute repetitive tasks, save time, and optimize your development process with Jenkins.\n\n# Downloads\n\nThe Jenkins project provides official distributions as WAR files, Docker images, native packages and installers for platforms including several Linux distributions and Windows.\nSee the [Downloads](https://www.jenkins.io/download) page for references.\n\nFor all distributions Jenkins offers two release lines:\n\n- [Weekly](https://www.jenkins.io/download/weekly/) -\n  Frequent releases which include all new features, improvements, and bug fixes.\n- [Long-Term Support (LTS)](https://www.jenkins.io/download/lts/) -\n  Older release line which gets periodically updated via bug fix backports.\n\nLatest releases:\n\n[![Jenkins Regular Release](https://img.shields.io/endpoint?url=https%3A%2F%2Fwww.jenkins.io%2Fchangelog%2Fbadge.json)](https://www.jenkins.io/changelog)\n[![Jenkins LTS Release](https://img.shields.io/endpoint?url=https%3A%2F%2Fwww.jenkins.io%2Fchangelog-stable%2Fbadge.json)](https://www.jenkins.io/changelog-stable)\n\n# Getting Started (Development)\n\nFor more information on setting up your development environment, contributing, and working with Jenkins internals, check the [contributing guide](CONTRIBUTING.md) and the [Jenkins Developer Documentation](https://www.jenkins.io/doc/developer/).\n\n# Source\n\nOur latest and greatest source of Jenkins can be found on [GitHub](https://github.com/jenkinsci/jenkins). Fork us!\n\n# Contributing to Jenkins\n\nNew to open source or Jenkins? Here‚Äôs how to get started:\n\n- Read the [Contribution Guidelines](CONTRIBUTING.md)\n- Check our [good first issues](https://github.com/jenkinsci/jenkins/issues?q=is%3Aissue%20is%3Aopen%20label%3A%22good%20first%20issue%22)\n- Join our [Gitter chat](https://app.gitter.im/#/room/#jenkinsci_newcomer-contributors:gitter.im) for questions and help\n\nFor more information about participating in the community and contributing to the Jenkins project,\nsee [this page](https://www.jenkins.io/participate/).\n\nDocumentation for Jenkins core maintainers is in the [maintainers guidelines](docs/MAINTAINERS.adoc).\n\n# News and Website\n\nAll information about Jenkins can be found on our [official website](https://www.jenkins.io/), including documentation, blog posts, plugin listings, community updates, and more.\n\nStay up-to-date with the latest Jenkins news, tutorials, and release notes:\n\n- [Jenkins Blog](https://www.jenkins.io/blog/)\n- [Documentation](https://www.jenkins.io/doc/)\n- [Plugins Index](https://plugins.jenkins.io/)\n- [Events](https://www.jenkins.io/events/)\n\nFollow Jenkins on social media to stay connected with the community:\n\n- [Twitter / X](https://x.com/jenkinsci)\n- [YouTube](https://www.youtube.com/@jenkinscicd)\n- [LinkedIn](https://www.linkedin.com/company/jenkins-project/)\n\n# Governance\n\nThe Jenkins project is governed by an open source community.\nTo learn more about the governance structure, project leadership, and how decisions are made, visit the [Governance Page](https://www.jenkins.io/project/governance/).\n\n# Adopters\n\nJenkins is trusted by **millions of users** and adopted by **thousands of companies** around the world ‚Äî from startups to enterprises ‚Äî to automate their software delivery pipelines.\n\nExplore the [Adopters Page](https://www.jenkins.io/project/adopters/) and https://stories.jenkins.io to see:\n\n- Companies and organizations using Jenkins\n- Success stories and case studies\n- How Jenkins is used in different industries\n\n> If your company uses Jenkins and you'd like to be featured, feel free to [submit your story](https://www.jenkins.io/project/adopters/contributing/#share-your-story)!\n\n# License\n\nJenkins is **licensed** under the **[MIT License](LICENSE.txt)**.\n",
      "stars_today": 4
    },
    {
      "id": 190964861,
      "name": "tech-interview-for-developer",
      "full_name": "gyoogle/tech-interview-for-developer",
      "description": "üë∂üèª Ïã†ÏûÖ Í∞úÎ∞úÏûê Ï†ÑÍ≥µ ÏßÄÏãù & Í∏∞Ïà† Î©¥Ï†ë Î∞±Í≥ºÏÇ¨Ï†Ñ üìñ",
      "html_url": "https://github.com/gyoogle/tech-interview-for-developer",
      "stars": 17050,
      "forks": 3726,
      "language": "Java",
      "topics": [
        "algorithm",
        "computer-science",
        "cs",
        "data-structures",
        "database",
        "developer",
        "interview",
        "it",
        "java",
        "javascript",
        "language",
        "seminar",
        "sql",
        "tech",
        "web"
      ],
      "created_at": "2019-06-09T04:42:57Z",
      "updated_at": "2026-01-23T10:39:58Z",
      "pushed_at": "2025-06-04T08:16:06Z",
      "open_issues": 19,
      "owner": {
        "login": "gyoogle",
        "avatar_url": "https://avatars.githubusercontent.com/u/34904741?v=4"
      },
      "readme": "# tech-interview-for-developer\n\n[![Since](https://img.shields.io/badge/since-2019.03.01-333333.svg?style=flat-square)](https://gyoogle.github.io)\n[![author](https://img.shields.io/badge/author-gyoogle-0066FF.svg?style=flat-square)](https://gyoogle.github.io)\n[![LICENSE](https://img.shields.io/dub/l/vibe-d.svg?style=flat-square)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/LICENSE)\n[![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2Fgyoogle%2Fhit-counter&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false)](https://hits.seeyoufarm.com)\n[![All Contributors](https://img.shields.io/badge/all_contributors-58-orange.svg?style=flat-square)](#contributors)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-FF66FF.svg?style=flat-square)](http://makeapullrequest.com)\n\n[![Watch on GitHub](https://img.shields.io/github/watchers/gyoogle/tech-interview-for-developer.svg?style=social)](https://github.com/gyoogle/tech-interview-for-developer/watchers)\n[![Star on GitHub](https://img.shields.io/github/stars/gyoogle/tech-interview-for-developer.svg?style=social)](https://github.com/gyoogle/tech-interview-for-developer/stargazers)\n[![Fork on GitHub](https://img.shields.io/github/forks/gyoogle/tech-interview-for-developer.svg?style=social)](https://github.com/gyoogle/tech-interview-for-developer/network/members)\n\n<br>\n\n<br>\n\n### üë∂üèª Ïã†ÏûÖ Í∞úÎ∞úÏûê Ï†ÑÍ≥µ ÏßÄÏãù & Í∏∞Ïà† Î©¥Ï†ë Î∞±Í≥ºÏÇ¨Ï†Ñ üìñ\n\n<br> \n\n**Collaborator**\n\n| [<img src=\"https://avatars3.githubusercontent.com/u/34904741?s=460&u=c8b8b7954518e26abbcf5d29c69c5df0b5c53c1b&v=4\" width=\"100\">](https://github.com/gyoogle)| [<img src=\"https://avatars2.githubusercontent.com/u/46181475?s=460&u=16d868ed1e357e51e8ba9f6dbb77df53a8fbb945&v=4\" width=\"100\">](https://github.com/GimunLee) | [<img src=\"https://avatars2.githubusercontent.com/u/37679254?s=460&u=1a7ccc7bf9926d6ea1cc455d04dfb63e4ebceaec&v=4\" width=\"100\">](https://github.com/b2narae) |\n| :-----------------------------------: | :---------------------------------------: | :-------------------------------------: |\n\n<br>\n\n**Commit convention rule** : ÎÇ†Ïßú-[Ï£ºÏ†ú]-ÎÇ¥Ïö©-ÏÉÅÌÉú\n\n`ex) 2019-10-14 [Algorithm] Sort Add/Update/Delete`\n\n<br>\n\nÏûòÎ™ªÎêú ÎÇ¥Ïö©ÏùÄ [Ïù¥Ïäà](https://github.com/gyoogle/tech-interview-for-developer/issues)ÏôÄ [PR](https://github.com/gyoogle/tech-interview-for-developer/pulls)Î°ú ÏïåÎ†§Ï£ºÏÑ∏Ïöî üí°\n\n<br>\n\n\n\n<center>üôèÎèÑÏõÄÏùÑ Ï£ºÏã† Î∂ÑÎì§üôè</center>\n\n<br>\n<br>\n\n<a href=\"https://github.com/gyoogle/tech-interview-for-developer/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=gyoogle/tech-interview-for-developer\" />\n</a>\n\n<br>\n\n#### [üíñÌõÑÏõêÌïòÍ∏∞üíù](https://github.com/sponsors/gyoogle)\n\n<br>\n<br>\n\n## ‚è© ‚è© ‚è©  [Ïõπ ÏÇ¨Ïù¥Ìä∏ÏóêÏÑú Ìé∏ÌïòÍ≤å Í≥µÎ∂ÄÌïòÏÑ∏Ïöî! Click!](https://gyoogle.dev/)  ‚è™ ‚è™ ‚è™\n\n<br>\n<br>\n\n<br>\n\n### üë®üèª‚Äçüè´ [Í∏∞Ïà† Î©¥Ï†ë Í∞ê Ïû°Í∏∞](<https://github.com/gyoogle/tech-interview-for-developer/tree/master/Interview#%EA%B8%B0%EC%88%A0-%EB%A9%B4%EC%A0%91-%EC%A4%80%EB%B9%84%ED%95%98%EA%B8%B0>) üë©üèª‚Äçüè´\n\n------\n\n<br>\n\n## üìå Computer Science\n\n- ### Computer Architecture\n\n  - [Ïª¥Ìì®ÌÑ∞ Íµ¨Ï°∞ Í∏∞Ï¥à](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Computer%20Architecture/%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B5%AC%EC%A1%B0%20%EA%B8%B0%EC%B4%88.pdf)\n  - [Ïª¥Ìì®ÌÑ∞Ïùò Íµ¨ÏÑ±](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Computer%20Architecture/%EC%BB%B4%ED%93%A8%ED%84%B0%EC%9D%98%20%EA%B5%AC%EC%84%B1.md)\n  - [Ï§ëÏïôÏ≤òÎ¶¨Ïû•Ïπò(CPU) ÏûëÎèô ÏõêÎ¶¨](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Computer%20Architecture/%EC%A4%91%EC%95%99%EC%B2%98%EB%A6%AC%EC%9E%A5%EC%B9%98(CPU)%20%EC%9E%91%EB%8F%99%20%EC%9B%90%EB%A6%AC.md)\n  - [Ï∫êÏãú Î©îÎ™®Î¶¨](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Computer%20Architecture/Ï∫êÏãú%20Î©îÎ™®Î¶¨(Cache%20Memory).md)\n  - [Í≥†Ï†ï ÏÜåÏàòÏ†ê & Î∂ÄÎèô ÏÜåÏàòÏ†ê](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Computer%20Architecture/%EA%B3%A0%EC%A0%95%20%EC%86%8C%EC%88%98%EC%A0%90%20%26%20%EB%B6%80%EB%8F%99%20%EC%86%8C%EC%88%98%EC%A0%90.md)\n  - [Ìå®Î¶¨Ìã∞ ÎπÑÌä∏ & Ìï¥Î∞ç ÏΩîÎìú](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Computer%20Architecture/%ED%8C%A8%EB%A6%AC%ED%8B%B0%20%EB%B9%84%ED%8A%B8%20%26%20%ED%95%B4%EB%B0%8D%20%EC%BD%94%EB%93%9C.md)\n  - [ARM ÌîÑÎ°úÏÑ∏ÏÑú](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Computer%20Architecture/ARM%20%ED%94%84%EB%A1%9C%EC%84%B8%EC%84%9C.md)\n\n  <br>\n\n- ### Data Structure\n\n  - [Array](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Data%20Structure/Array.md)\n  - [LinkedList](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Data%20Structure/Linked%20List.md)\n  - [Array & ArrayList & LinkedList](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Data%20Structure/Array%20vs%20ArrayList%20vs%20LinkedList.md)\n  - [Ïä§ÌÉù(Stack) & ÌÅê(Queue)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Data%20Structure/Stack%20%26%20Queue.md)\n  - [Ìûô(Heap)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Data%20Structure/Heap.md)\n  - [Ìä∏Î¶¨(Tree)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Data%20Structure/Tree.md)\n  - [Ïù¥ÏßÑÌÉêÏÉâÌä∏Î¶¨(Binary Search Tree)](<https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Data%20Structure/Binary%20Search%20Tree.md>)\n  - [Ìï¥Ïãú(Hash)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Data%20Structure/Hash.md)\n  - [Ìä∏ÎùºÏù¥(Trie)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Data%20Structure/Trie.md)\n  - [B-Tree & B+Tree](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Data%20Structure/B%20Tree%20%26%20B%2B%20Tree.md)\n\n  <br>\n\n- ### Database\n\n  - [ÌÇ§(Key) Ï†ïÎ¶¨](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Database/%5BDB%5D%20Key.md)\n  - [SQL - JOIN](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Database/%5BDatabase%20SQL%5D%20JOIN.md)\n  - [SQL Injection](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Database/SQL%20Injection.md)\n  - [SQL vs NoSQL](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Database/SQL%EA%B3%BC%20NOSQL%EC%9D%98%20%EC%B0%A8%EC%9D%B4.md)\n  - [Ï†ïÍ∑úÌôî(Normalization)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Database/%EC%A0%95%EA%B7%9C%ED%99%94(Normalization).md)\n  - [Ïù¥ÏÉÅ(Anomaly)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Database/%5BDB%5D%20Anomaly.md)\n  - [Ïù∏Îç±Ïä§(INDEX)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Database/%5BDB%5D%20Index.md)\n  - [Ìä∏ÎûúÏû≠ÏÖò(Transaction)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Database/Transaction.md)\n  - [Ìä∏ÎûúÏû≠ÏÖò Í≤©Î¶¨ ÏàòÏ§Ä(Transaction Isolation Level)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Database/Transaction%20Isolation%20Level.md)\n  - [Ï†ÄÏû• ÌîÑÎ°úÏãúÏ†Ä(Stored PROCEDURE)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Database/%EC%A0%80%EC%9E%A5%20%ED%94%84%EB%A1%9C%EC%8B%9C%EC%A0%80(Stored%20PROCEDURE).md)\n  - [Î†àÎîîÏä§(Redis)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Database/Redis.md)\n\n  <br>\n\n- ### Network\n\n  - [OSI 7 Í≥ÑÏ∏µ](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Network/OSI%207%20Í≥ÑÏ∏µ.md)\n  - [TCP 3 way handshake & 4 way handshake](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Network/TCP%203%20way%20handshake%20%26%204%20way%20handshake.md)\n  - [TCP/IP ÌùêÎ¶ÑÏ†úÏñ¥ & ÌòºÏû°Ï†úÏñ¥](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Network/TCP%20(%ED%9D%90%EB%A6%84%EC%A0%9C%EC%96%B4%ED%98%BC%EC%9E%A1%EC%A0%9C%EC%96%B4).md#tcp-%ED%9D%90%EB%A6%84%EC%A0%9C%EC%96%B4%ED%98%BC%EC%9E%A1%EC%A0%9C%EC%96%B4)\n  - [UDP](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Network/UDP.md#20190826%EC%9B%94-bym-udp%EB%9E%80)\n  - [ÎåÄÏπ≠ÌÇ§ & Í≥µÍ∞úÌÇ§](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Network/%EB%8C%80%EC%B9%AD%ED%82%A4%20%26%20%EA%B3%B5%EA%B0%9C%ED%82%A4.md)\n  - [HTTP & HTTPS](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Network/HTTP%20%26%20HTTPS.md)\n  - [TLS/SSL handshake](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Network/TLS%20HandShake.md)\n  - [Î°úÎìú Î∞∏Îü∞Ïã±(Load Balancing)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Network/%EB%A1%9C%EB%93%9C%20%EB%B0%B8%EB%9F%B0%EC%8B%B1(Load%20Balancing).md)\n  - [Blocking,Non-blocking & Synchronous,Asynchronous](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Network/%5BNetwork%5D%20Blocking%2CNon-blocking%20%26%20Synchronous%2CAsynchronous.md)\n  - [Blocking & Non-Blocking I/O](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Network/%5BNetwork%5D%20Blocking%20Non-Blocking%20IO.md)\n\n  <br>\n\n- ### Operating System\n\n  - [Ïö¥ÏòÅÏ≤¥Ï†úÎûÄ](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Operating%20System/Operation%20System.md)\n  - [ÌîÑÎ°úÏÑ∏Ïä§ vs Ïä§Î†àÎìú](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Operating%20System/Process%20vs%20Thread.md)\n  - [ÌîÑÎ°úÏÑ∏Ïä§ Ï£ºÏÜå Í≥µÍ∞Ñ](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Operating%20System/Process%20Address%20Space.md)\n  - [Ïù∏ÌÑ∞ÎüΩÌä∏(Interrupt)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Operating%20System/Interrupt.md)\n  - [ÏãúÏä§ÌÖú ÏΩú(System Call)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Operating%20System/%5BOS%5D%20System%20Call%20(Fork%20Wait%20Exec).md)\n  - [PCBÏôÄ Context Switching](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Operating%20System/PCB%20%26%20Context%20Switcing.md)\n  - [IPC(Inter Process Communication)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Operating%20System/IPC(Inter%20Process%20Communication).md)\n  - [CPU Ïä§ÏºÄÏ§ÑÎßÅ](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Operating%20System/CPU%20Scheduling.md)\n  - [Îç∞ÎìúÎùΩ(DeadLock)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Operating%20System/DeadLock.md)\n  - [Race Condition]( https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Operating%20System/Race%20Condition.md)\n  - [ÏÑ∏ÎßàÌè¨Ïñ¥(Semaphore) & ÎÆ§ÌÖçÏä§(Mutex)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Operating%20System/Semaphore%20%26%20Mutex.md)\n  - [ÌéòÏù¥Ïßï & ÏÑ∏Í∑∏Î®ºÌÖåÏù¥ÏÖò](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Operating%20System/Paging%20and%20Segmentation.md) ([PDF](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Operating%20System/Paging%20and%20Segmentation.pdf))\n  - [ÌéòÏù¥ÏßÄ ÍµêÏ≤¥ ÏïåÍ≥†Î¶¨Ï¶ò](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Operating%20System/Page%20Replacement%20Algorithm.md)\n  - [Î©îÎ™®Î¶¨(Memory)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Operating%20System/Memory.md)\n  - [ÌååÏùº ÏãúÏä§ÌÖú](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Operating%20System/File%20System.md)\n\n  <br>\n\n- ### Software Engineering\n\n  - [ÌÅ¥Î¶∞ÏΩîÎìú & Î¶¨Ìå©ÌÜ†ÎßÅ](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Software%20Engineering/Clean%20Code%20%26%20Refactoring.md) / [ÌÅ¥Î¶∞ÏΩîÎìú & ÏãúÌÅêÏñ¥ÏΩîÎî©](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Software%20Engineering/%ED%81%B4%EB%A6%B0%EC%BD%94%EB%93%9C(Clean%20Code)%20%26%20%EC%8B%9C%ED%81%90%EC%96%B4%EC%BD%94%EB%94%A9(Secure%20Coding).md)\n  - [TDD(Test Driven Development)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Software%20Engineering/TDD(Test%20Driven%20Development).md)\n  - [Ïï†ÏûêÏùº(Agile) Ï†ïÎ¶¨1](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Software%20Engineering/%EC%95%A0%EC%9E%90%EC%9D%BC(Agile).md) / [Ïï†ÏûêÏùº(Agile) Ï†ïÎ¶¨2](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Software%20Engineering/%EC%95%A0%EC%9E%90%EC%9D%BC(Agile)2.md)\n  - [Í∞ùÏ≤¥ ÏßÄÌñ• ÌîÑÎ°úÍ∑∏ÎûòÎ∞ç(Object-Oriented Programming)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Software%20Engineering/Object-Oriented%20Programming.md)\n  - [Ìï®ÏàòÌòï ÌîÑÎ°úÍ∑∏ÎûòÎ∞ç(Fuctional Programming)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Software%20Engineering/Fuctional%20Programming.md)\n  - [Îç∞Î∏åÏòµÏä§(DevOps)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Software%20Engineering/%EB%8D%B0%EB%B8%8C%EC%98%B5%EC%8A%A4(DevOps).md)\n  - [ÏÑúÎìú ÌååÌã∞(3rd party)ÎûÄ?](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Software%20Engineering/%EC%8D%A8%EB%93%9C%ED%8C%8C%ED%8B%B0(3rd%20party)%EB%9E%80.md)\n  - [ÎßàÏù¥ÌÅ¨Î°úÏÑúÎπÑÏä§ ÏïÑÌÇ§ÌÖçÏ≤ò(MSA)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Software%20Engineering/%EB%A7%88%EC%9D%B4%ED%81%AC%EB%A1%9C%EC%84%9C%EB%B9%84%EC%8A%A4%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98(MSA).md)\n  \n\n<br>\n\n<br>\n\n## üìå Algorithm\n\n- [Í±∞Ìíà Ï†ïÎ†¨(Bubble Sort)](https://github.com/GimunLee/tech-refrigerator/blob/master/Algorithm/%EA%B1%B0%ED%92%88%20%EC%A0%95%EB%A0%AC%20(Bubble%20Sort).md#%EA%B1%B0%ED%92%88-%EC%A0%95%EB%A0%AC-bubble-sort)\n- [ÏÑ†ÌÉù Ï†ïÎ†¨(Selection Sort)](https://github.com/GimunLee/tech-refrigerator/blob/master/Algorithm/%EC%84%A0%ED%83%9D%20%EC%A0%95%EB%A0%AC%20(Selection%20Sort).md#%EC%84%A0%ED%83%9D-%EC%A0%95%EB%A0%AC-selection-sort) \n- [ÏÇΩÏûÖ Ï†ïÎ†¨(Insertion Sort)](https://github.com/GimunLee/tech-refrigerator/blob/master/Algorithm/%EC%82%BD%EC%9E%85%20%EC%A0%95%EB%A0%AC%20(Insertion%20Sort).md#%EC%82%BD%EC%9E%85-%EC%A0%95%EB%A0%AC-insertion-sort)\n- [ÌÄµ Ï†ïÎ†¨(Quick Sort)](<https://github.com/gyoogle/tech-interview-for-developer/blob/master/Algorithm/QuickSort.md>)\n- [Î≥ëÌï© Ï†ïÎ†¨(Merge Sort)](<https://github.com/gyoogle/tech-interview-for-developer/blob/master/Algorithm/MergeSort.md>)\n- [Ìûô Ï†ïÎ†¨(Heap Sort)](<https://github.com/gyoogle/tech-interview-for-developer/blob/master/Algorithm/HeapSort.md>)\n- [Í∏∞Ïàò Ï†ïÎ†¨(Radix Sort)](<https://github.com/gyoogle/tech-interview-for-developer/blob/master/Algorithm/Sort_Radix.md>)\n- [Í≥ÑÏàò Ï†ïÎ†¨(Count Sort)](<https://github.com/gyoogle/tech-interview-for-developer/blob/master/Algorithm/Sort_Counting.md>)\n- [Ïù¥Î∂Ñ ÌÉêÏÉâ(Binary Search)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Algorithm/Binary%20Search.md)\n- [Ìï¥Ïãú ÌÖåÏù¥Î∏î Íµ¨ÌòÑ](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Algorithm/Hash%20Table%20%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0.md)\n- [DFS & BFS](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Algorithm/DFS%20%26%20BFS.md)\n- [ÏµúÏû• Ï¶ùÍ∞Ä ÏàòÏó¥(LIS)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Algorithm/LIS%20(Longest%20Increasing%20Sequence).md)\n- [ÏµúÏÜå Í≥µÌÜµ Ï°∞ÏÉÅ(LCA)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Algorithm/LCA(Lowest%20Common%20Ancestor).md)\n- [ÎèôÏ†Å Í≥ÑÌöçÎ≤ï(Dynamic Programming)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Algorithm/%EB%8F%99%EC%A0%81%20%EA%B3%84%ED%9A%8D%EB%B2%95%20(Dynamic%20Programming).md)\n- [Îã§ÏùµÏä§Ìä∏Îùº(Dijkstra) ÏïåÍ≥†Î¶¨Ï¶ò](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Algorithm/%EB%8B%A4%EC%9D%B5%EC%8A%A4%ED%8A%B8%EB%9D%BC(Dijkstra).md)\n- [ÎπÑÌä∏ÎßàÏä§ÌÅ¨(BitMask)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Algorithm/%EB%B9%84%ED%8A%B8%EB%A7%88%EC%8A%A4%ED%81%AC(BitMask).md)\n\n<br>\n\n- ##### ‚úèÔ∏è TEST\n\n  - [ÏÇºÏÑ± ÏÜåÌîÑÌä∏Ïõ®Ïñ¥ Ïó≠ÎüâÌÖåÏä§Ìä∏ PRO Îì±Í∏â Ï§ÄÎπÑ](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Algorithm/SAMSUNG%20Software%20PRO%EB%93%B1%EA%B8%89%20%EC%A4%80%EB%B9%84.md)\n\n<br>\n\n## üìå Design Pattern\n\n- [ÎîîÏûêÏù∏Ìå®ÌÑ¥ Í∞úÏöî(Overview)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Design%20Pattern/%5BDesign%20Pattern%5D%20Overview.md)\n- [Ïñ¥ÎåëÌÑ∞ Ìå®ÌÑ¥](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Design%20Pattern/Adapter%20Pattern.md)\n- [Ïã±Í∏ÄÌÜ§ Ìå®ÌÑ¥](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Design%20Pattern/Singleton%20Pattern.md)\n- [ÌÉ¨ÌîåÎ¶ø Î©îÏÜåÎìú Ìå®ÌÑ¥](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Design%20Pattern/Design%20Pattern_Template%20Method.md)\n- [Ìå©ÌÜ†Î¶¨ Î©îÏÜåÎìú Ìå®ÌÑ¥](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Design%20Pattern/Design%20Pattern_Factory%20Method.md)\n- [ÏòµÏ†ÄÎ≤Ñ Ìå®ÌÑ¥](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Design%20Pattern/Observer%20pattern.md)\n- [Ïä§Ìä∏Î†àÌã∞ÏßÄ Ìå®ÌÑ¥](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Design%20Pattern/Strategy%20Pattern.md)\n- [Ïª¥Ìè¨ÏßÄÌä∏ Ìå®ÌÑ¥](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Design%20Pattern/Composite%20Pattern.md)\n- [SOLID](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Design%20Pattern/SOLID.md)\n\n<br>\n\n## üìå Interview\n\n- [Ïñ∏Ïñ¥(Java, C++ ... )](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Interview/Interview%20List.md#Ïñ∏Ïñ¥)\n- [Ïö¥ÏòÅÏ≤¥Ï†ú](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Interview/Interview%20List.md#Ïö¥ÏòÅÏ≤¥Ï†ú)\n- [Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§](<https://github.com/gyoogle/tech-interview-for-developer/blob/master/Interview/Interview%20List.md#Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§>)\n- [ÎÑ§Ìä∏ÏõåÌÅ¨](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Interview/Interview%20List.md#ÎÑ§Ìä∏ÏõåÌÅ¨)\n- [Ïõπ(Ïä§ÌîÑÎßÅ)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Interview/Interview%20List.md#Ïä§ÌîÑÎßÅ)\n\n<br>\n\n## üìå Language\n\n- ### C\n\n  - [[C] CÏñ∏Ïñ¥ Ïª¥ÌååÏùº Í≥ºÏ†ï](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5Bc%5D%20C%EC%96%B8%EC%96%B4%20%EC%BB%B4%ED%8C%8C%EC%9D%BC%20%EA%B3%BC%EC%A0%95.md)\n  - [[C] Íµ¨Ï°∞Ï≤¥ Î©îÎ™®Î¶¨ ÌÅ¨Í∏∞ Í≥ÑÏÇ∞](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5BC%5D%20%EA%B5%AC%EC%A1%B0%EC%B2%B4%20%EB%A9%94%EB%AA%A8%EB%A6%AC%20%ED%81%AC%EA%B8%B0%20%EA%B3%84%EC%82%B0.md)\n  - [[C] Ìè¨Ïù∏ÌÑ∞(Pointer)](<https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5BC%5D%20%ED%8F%AC%EC%9D%B8%ED%84%B0(Pointer).md>)\n  - [[C] ÎèôÏ†ÅÌï†Îãπ](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5BC%5D%20%EB%8F%99%EC%A0%81%ED%95%A0%EB%8B%B9.md)\n\n- ### C++\n\n  - [[C++] ÏñïÏùÄ Î≥µÏÇ¨ vs ÍπäÏùÄ Î≥µÏÇ¨](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5BCpp%5D%20shallow%20copy%20vs%20deep%20copy.md)\n  - [[C++] Í∞ÄÏÉÅ Ìï®Ïàò(Virtual Function)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5BC%2B%2B%5D%20%EA%B0%80%EC%83%81%20%ED%95%A8%EC%88%98(virtual%20function).md)\n  - [[C++] ÏûÖÏ∂úÎ†• ÏµúÏ†ÅÌôîÌïòÍ∏∞](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5BC%2B%2B%5D%20%EC%9E%85%EC%B6%9C%EB%A0%A5%20%EC%8B%A4%ED%96%89%EC%86%8D%EB%8F%84%20%EC%A4%84%EC%9D%B4%EB%8A%94%20%EB%B2%95.md)\n  - [[C++] Vector Container](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5BC%2B%2B%5D%20Vector%20Container.md)\n\n- ### Java\n\n  - [[Java] Java Ïª¥ÌååÏùº Í≥ºÏ†ï](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5Bjava%5D%20%EC%9E%90%EB%B0%94%20%EC%BB%B4%ED%8C%8C%EC%9D%BC%20%EA%B3%BC%EC%A0%95.md)\n  - [[Java] Call by Value vs Call by Reference](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5Bjava%5D%20Call%20by%20value%EC%99%80%20Call%20by%20reference.md)\n  - [[Java] String & StringBuffer & StringBuilder](<https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5Bjava%5D%20String%20StringBuilder%20StringBuffer%20%EC%B0%A8%EC%9D%B4.md>)\n  - [[Java] ÏûêÎ∞î Í∞ÄÏÉÅ Î®∏Ïã†(Java Virtual Machine)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5Bjava%5D%20%EC%9E%90%EB%B0%94%20%EA%B0%80%EC%83%81%20%EB%A8%B8%EC%8B%A0(Java%20Virtual%20Machine).md)\n  - [[Java] Casting(ÏóÖÏ∫êÏä§ÌåÖ & Îã§Ïö¥Ï∫êÏä§ÌåÖ)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5Bjava%5D%20Casting(%EC%97%85%EC%BA%90%EC%8A%A4%ED%8C%85%20%26%20%EB%8B%A4%EC%9A%B4%EC%BA%90%EC%8A%A4%ED%8C%85).md)\n  - [[Java] Ïò§ÌÜ† Î∞ïÏã± & Ïò§ÌÜ†Ïñ∏Î∞ïÏã±](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5BJava%5D%20Auto%20Boxing%20%26%20Unboxing.md)\n  - [[Java] Thread ÌôúÏö©](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5Bjava%5D%20Java%EC%97%90%EC%84%9C%EC%9D%98%20Thread.md)\n  - [[Java] Í≥†Ïú† ÎùΩ(Intrinsic Lock)](<https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5BJava%5D%20Intrinsic%20Lock.md>)\n  - [[Java] Î¨∏ÏûêÏó¥ ÌÅ¥ÎûòÏä§](https://github.com/GimunLee/tech-refrigerator/blob/master/Language/JAVA/%EB%AC%B8%EC%9E%90%EC%97%B4%20%ED%81%B4%EB%9E%98%EC%8A%A4.md#%EB%AC%B8%EC%9E%90%EC%97%B4-%ED%81%B4%EB%9E%98%EC%8A%A4) \n  - [[Java] Garbage Collection](https://github.com/GimunLee/tech-refrigerator/blob/master/Language/JAVA/Garbage%20Collection.md#garbage-collection) \n  - [[Java] Promotion & Casting](https://github.com/GimunLee/tech-refrigerator/blob/master/Language/JAVA/Promotion%20%26%20Casting.md#promotion--casting)\n  - [[Java] Primitive type & Reference type](https://github.com/GimunLee/tech-refrigerator/blob/master/Language/JAVA/Primitive%20type%20%26%20Reference%20type.md#primitive-type--reference-type)\n  - [[Java] ÏßÅÎ†¨Ìôî(Serialization)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5BJava%5D%20%EC%A7%81%EB%A0%AC%ED%99%94(Serialization).md)\n  - [[Java] Error & Exception](https://github.com/GimunLee/tech-refrigerator/blob/master/Language/JAVA/Error%20%26%20Exception.md#error--exception)\n  - [[Java] Stream API](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5Bjava%5D%20Stream.md)\n  - [[Java] Record](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5Bjava%5D%20Record.md)\n  - [[Java] Interend String in Java](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5BJava%5D%20Interned%20String%20in%20JAVA.md)\n  - [[Java] Composition](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5BJava%5D%20%EC%BB%B4%ED%8F%AC%EC%A7%80%EC%85%98(Composition).md)\n  \n- ### Javascript\n\n  - [[Javascript] ES2015+ ÏöîÏïΩ Ï†ïÎ¶¨](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5BJavascript%5D%20ES2015%2B%20%EC%9A%94%EC%95%BD%20%EC%A0%95%EB%A6%AC.md)\n  - [[Javascript] Object Prototype](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5BJavasript%5D%20Object%20Prototype.md)\n  - [[Javascript] Closure](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5BJavascript%5D%20Closure.md)\n\n- ### Python\n\n  - [[Python] Îß§ÌÅ¨Î°ú ÏÇ¨Ïö©Î≤ï](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Language/%5BPython%5D%20%EB%A7%A4%ED%81%AC%EB%A1%9C%20%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC.md)\n\n<br>\n\n## üìå Web\n\n- [Î∏åÎùºÏö∞Ï†Ä ÎèôÏûë Î∞©Î≤ï](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/%EB%B8%8C%EB%9D%BC%EC%9A%B0%EC%A0%80%20%EB%8F%99%EC%9E%91%20%EB%B0%A9%EB%B2%95.md)\n\n- [Ïø†ÌÇ§(Cookie) & ÏÑ∏ÏÖò(Session)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/Cookie%20%26%20Session.md)\n\n- [HTTP Request Methods](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/HTTP%20Request%20Methods.md)\n\n- [HTTP Status Code](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/HTTP%20status%20code.md)\n\n- [REST API](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/%5BWeb%5D%20REST%20API.md)\n\n- [Ïõπ ÏÑúÎ≤ÑÏôÄ WASÏùò Ï∞®Ïù¥Ï†ê](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/Web%20Server%EC%99%80%20WAS%EC%9D%98%20%EC%B0%A8%EC%9D%B4.md)\n\n- [OAuth](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/OAuth.md)\n\n- [JWT(JSON Web Token)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/JWT(JSON%20Web%20Token).md)\n\n- [Authentication and Authorization](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/%EC%9D%B8%EC%A6%9D%EB%B0%A9%EC%8B%9D.md)\n\n- [Î°úÍ∑∏ Î†àÎ≤®](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/Logging%20Level.md)\n\n- [UIÏôÄ UX](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/UI%EC%99%80%20UX.md)\n\n- [CSR & SSR](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/CSR%20%26%20SSR.md)\n\n- [Vue.js vs React](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/Vue.js%EC%99%80%20React%EC%9D%98%20%EC%B0%A8%EC%9D%B4.md)\n\n- [ÎÑ§Ïù¥Ìã∞Î∏å Ïï± & Ïõπ Ïï± & ÌïòÏù¥Î∏åÎ¶¨Îìú Ïï±](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/%EB%84%A4%EC%9D%B4%ED%8B%B0%EB%B8%8C%20%EC%95%B1%20%26%20%EC%9B%B9%20%EC%95%B1%20%26%20%ED%95%98%EC%9D%B4%EB%B8%8C%EB%A6%AC%EB%93%9C%20%EC%95%B1.md)\n\n- [PWA(Progressive Web App)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/PWA%20(Progressive%20Web%20App).md)\n\n- [CSRF & XSS](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/CSRF%20%26%20XSS.md)\n\n- ##### Spring\n\n  - [[Spring] Bean Scope](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/Spring/%5BSpring%5D%20Bean%20Scope.md)\n  - [[Spring] MVC Framework](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/Spring/Spring%20MVC.md)\n  - [[Spring Boot] SpringApplication](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/Spring/%5BSpring%20Boot%5D%20SpringApplication.md)\n  - [[Spring Boot] Test Code](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/Spring/%5BSpring%20Boot%5D%20Test%20Code.md)\n  - [JPA](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/Spring/JPA.md)\n  - [[Spring Data JPA] ÎçîÌã∞ Ï≤¥ÌÇπ(Dirty Checking)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/Spring/%5BSpring%20Data%20JPA%5D%20%EB%8D%94%ED%8B%B0%20%EC%B2%B4%ED%82%B9%20(Dirty%20Checking).md)\n  - [Spring Security - Ïù∏Ï¶ù Î∞è Í∂åÌïú Î∂ÄÏó¨](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/Spring/Spring%20Security%20-%20Authentication%20and%20Authorization.md)\n\n- ##### Vue.js\n  \n  - [Vue.js ÎùºÏù¥ÌîÑÏÇ¨Ïù¥ÌÅ¥](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/Vue/Vue.js%20%EB%9D%BC%EC%9D%B4%ED%94%84%EC%82%AC%EC%9D%B4%ED%81%B4%20%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0.md)\n  - [Vue CLI + Spring Boot Ïó∞ÎèôÌïòÏó¨ ÌôòÍ≤Ω Íµ¨Ï∂ïÌïòÍ∏∞](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/Vue/Vue%20CLI%20%2B%20Spring%20Boot%20%EC%97%B0%EB%8F%99%ED%95%98%EC%97%AC%20%ED%99%98%EA%B2%BD%20%EA%B5%AC%EC%B6%95%ED%95%98%EA%B8%B0.md)\n  - [Vue.js + FirebaseÎ°ú Ïù¥Î©îÏùº ÌöåÏõêÍ∞ÄÏûÖ&Î°úÍ∑∏Ïù∏ Íµ¨ÌòÑÌïòÍ∏∞](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/Vue/Vue.js%20%2B%20Firebase%EB%A1%9C%20%EC%9D%B4%EB%A9%94%EC%9D%BC%20%ED%9A%8C%EC%9B%90%EA%B0%80%EC%9E%85%EB%A1%9C%EA%B7%B8%EC%9D%B8%20%EA%B5%AC%ED%98%84.md)\n  - [Vue.js + FirebaseÎ°ú Facebook Î°úÍ∑∏Ïù∏ Ïó∞ÎèôÌïòÍ∏∞](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/Vue/Vue.js%20%2B%20Firebase%EB%A1%9C%20%ED%8E%98%EC%9D%B4%EC%8A%A4%EB%B6%81(facebook)%20%EB%A1%9C%EA%B7%B8%EC%9D%B8%20%EC%97%B0%EB%8F%99%ED%95%98%EA%B8%B0.md)\n  - [Nuxt.jsÎûÄ](<https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/Nuxt.js.md>)\n  \n- ##### React\n  \n  - [React Fragment](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/React/React%20Fragment.md)\n  - [React Hook](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/React/React%20Hook.md)\n  - [React + Spring Boot Ïó∞ÎèôÌïòÏó¨ ÌôòÍ≤Ω Íµ¨Ï∂ïÌïòÍ∏∞](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/React/React%20%26%20Spring%20Boot%20%EC%97%B0%EB%8F%99%ED%95%98%EC%97%AC%20%ED%99%98%EA%B2%BD%20%EA%B5%AC%EC%B6%95%ED%95%98%EA%B8%B0.md)\n  \n- ##### DevOps\n\n  - [[AWS] Spring Boot Î∞∞Ìè¨ Ïä§ÌÅ¨Î¶ΩÌä∏ ÏÉùÏÑ±](https://github.com/gyoogle/tech-interview-for-developer/tree/master/Web/DevOps)\n  - [[Travis CI] ÌîÑÎ°úÏ†ùÌä∏ Ïó∞ÎèôÌïòÍ∏∞](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/DevOps/%5BTravis%20CI%5D%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%20%EC%97%B0%EB%8F%99%ED%95%98%EA%B8%B0.md)\n  - [ÏãúÏä§ÌÖú Í∑úÎ™® ÌôïÏû•](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Web/DevOps/%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EA%B7%9C%EB%AA%A8%20%ED%99%95%EC%9E%A5.md)\n\n\n<br>\n\n## üìå Linux\n\n- [Î¶¨ÎàÖÏä§ Í∏∞Î≥∏ Î™ÖÎ†πÏñ¥](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Linux/Linux%20Basic%20Command.md)\n- [Ìè∞ ÎÖ∏Ïù¥Îßå Íµ¨Ï°∞](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Linux/Von%20Neumann%20Architecture.md)\n- [ÌçºÎØ∏ÏÖò ÌôúÏö©](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Linux/Permission.md)\n\n<br>\n\n## üìå New Technology\n\n- #### AI \n  - [Ïö©Ïñ¥ Ï†ïÎ¶¨](https://github.com/gyoogle/tech-interview-for-developer/blob/master/New%20Technology/AI/README.md)\n  - [TensorflowÎ°ú Linear Regression ÏïåÍ≥†Î¶¨Ï¶ò Íµ¨ÌòÑ](https://github.com/gyoogle/tech-interview-for-developer/blob/master/New%20Technology/AI/Linear%20regression%20%EC%8B%A4%EC%8A%B5.md)\n  \n- #### Big Data\n  - [Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù](https://github.com/gyoogle/tech-interview-for-developer/blob/master/New%20Technology/Big%20Data/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.md)\n  - [DBSCAN ÌÅ¥Îü¨Ïä§ÌÑ∞ÎßÅ ÏïåÍ≥†Î¶¨Ï¶ò](https://github.com/gyoogle/tech-interview-for-developer/blob/master/New%20Technology/Big%20Data/DBSCAN%20%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0%EB%A7%81%20%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98.md)\n  \n- #### IT Issues\n  - [Ïù¥Î©îÏùº Í≥µÍ≤© Ï¶ùÍ∞ÄÎ°ú Î≥¥ÏïàÏóÖÍ≥Ñ ÎåÄÏùë ÎπÑÏÉÅ(19.08.07)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/New%20Technology/IT%20Issues/%5B2019.08.07%5D%20%EC%9D%B4%EB%A9%94%EC%9D%BC%20%EA%B3%B5%EA%B2%A9%20%EC%A6%9D%EA%B0%80%EB%A1%9C%20%EB%B3%B4%EC%95%88%EC%97%85%EA%B3%84%20%EB%8C%80%EC%9D%91%20%EB%B9%84%EC%83%81.md)\n  - [Ïø†Ìå° ÏÑúÎπÑÏä§ Ïò§Î•ò(19.08.08)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/New%20Technology/IT%20Issues/%5B2019.08.08%5D%20IT%20%EC%88%98%EB%8B%A4%20%EC%A0%95%EB%A6%AC.md)\n  - [GraphQL(19.08.08)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/New%20Technology/IT%20Issues/%5B2019.08.08%5D%20IT%20%EC%88%98%EB%8B%A4%20%EC%A0%95%EB%A6%AC.md)\n  - [SK ÌïòÏù¥ÎãâÏä§Ïùò ÌÉÑÏÉùÏùÄ?(19.08.08)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/New%20Technology/IT%20Issues/%5B2019.08.08%5D%20IT%20%EC%88%98%EB%8B%A4%20%EC%A0%95%EB%A6%AC.md)\n  - [Íµ¨Í∏Ä, ÌÅ¨Î°¨ Î∏åÎùºÏö∞Ï†ÄÏóêÏÑú FTP ÏßÄÏõê Ï§ëÎã® ÌôïÏ†ï(19.08.20)](https://github.com/gyoogle/tech-interview-for-developer/blob/master/New%20Technology/IT%20Issues/%5B2019.08.20%5D%20Google%2C%20%ED%81%AC%EB%A1%AC%20%EB%B8%8C%EB%9D%BC%EC%9A%B0%EC%A0%80%EC%97%90%EC%84%9C%20FTP%20%EC%A7%80%EC%9B%90%20%EC%A4%91%EB%8B%A8%20%ED%99%95%EC%A0%95.md)\n  - [2020 ICT Ïù¥Ïäà](https://github.com/gyoogle/tech-interview-for-developer/blob/master/New%20Technology/IT%20Issues/2020%20ICT%20%EC%9D%B4%EC%8A%88.md)\n  - [AMDÏôÄ IntelÏùò Î∞òÎ∞±ÎÖÑ Ï†ÑÏüÅ, Í∑∏Î¶¨Í≥† 2020ÎÖÑÏùò 'Î∞òÎèÑÏ≤¥'](https://github.com/gyoogle/tech-interview-for-developer/blob/master/New%20Technology/IT%20Issues/AMD%20vs%20Intel.md)\n\n<br>\n\n## üìå Seminar\n\n- [2019 NHN OPEN TALK DAY](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Seminar/NHN%202019%20OPEN%20TALK%20DAY.md)\n- [2019 ÏÇºÏÑ±Ï†ÑÏûê ÎπÑÏ†ÑÏ∫†ÌîÑ](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Seminar/2019%20%EC%82%BC%EC%84%B1%EC%A0%84%EC%9E%90%20%EB%B9%84%EC%A0%84%EC%BA%A0%ED%94%84.md)\n- [2019 NCSOFT JOB Cafe](https://github.com/GimunLee/tech-interview-for-developer/blob/master/Seminar/NCSOFT%202019%20JOB%20Cafe.md#2019-10-02-ncsoft-job-cafe)\n- [2019 ÏÇºÏÑ±Ï†ÑÏûê Ïò§ÌîàÏÜåÏä§ Ïª®ÌçºÎü∞Ïä§](<https://github.com/gyoogle/tech-interview-for-developer/blob/master/Seminar/2019%20%EC%82%BC%EC%84%B1%EC%A0%84%EC%9E%90%20%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4%20%EC%BB%A8%ED%8D%BC%EB%9F%B0%EC%8A%A4(SOSCON).md>)\n\n<br>\n\n## üìå ETC\n\n- [Git Commit Message Convention](https://github.com/gyoogle/tech-interview-for-developer/blob/master/ETC/Git%20Commit%20Message%20Convention.md)\n- [GitHub ForkÎ°ú ÌòëÏóÖÌïòÍ∏∞](https://github.com/gyoogle/tech-interview-for-developer/blob/master/ETC/GitHub%20Fork%EB%A1%9C%20%ED%98%91%EC%97%85%ED%95%98%EA%B8%B0.md#github-fork%EB%A1%9C-%ED%98%91%EC%97%85%ED%95%98%EA%B8%B0)\n- [GitHub Ï†ÄÏû•ÏÜå(repository) ÎØ∏Îü¨ÎßÅ](https://github.com/gyoogle/tech-interview-for-developer/blob/master/ETC/GitHub%20%EC%A0%80%EC%9E%A5%EC%86%8C(repository)%20%EB%AF%B8%EB%9F%AC%EB%A7%81.md#github-%EC%A0%80%EC%9E%A5%EC%86%8Crepository-%EB%AF%B8%EB%9F%AC%EB%A7%81)\n- [Git & GitHub & GitLab Flow](https://github.com/gyoogle/tech-interview-for-developer/blob/master/ETC/Git%20vs%20GitHub%20vs%20GitLab%20Flow.md)\n- [JavascriptÏôÄ Node.jsÎ°ú GitÏùÑ ÌÜµÌï¥ ÌòëÏóÖÌïòÍ∏∞](https://github.com/gyoogle/tech-interview-for-developer/blob/master/ETC/Collaborate%20with%20Git%20on%20Javascript%20and%20Node.js.md) \n\n<br>\n\n## License\n[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fgyoogle%2Ftech-interview-for-developer.svg?type=small)](https://app.fossa.com/projects/git%2Bgithub.com%2Fgyoogle%2Ftech-interview-for-developer?ref=badge_small)\n\n<br>\n\n[<img src=\"https://github.com/gyoogle/blog/blob/master/docs/.vuepress/public/images/BMC.png?raw=true\" width=\"150px\" height=\"30px\">](https://www.buymeacoffee.com/gyoogle)\n\n\n",
      "stars_today": 4
    },
    {
      "id": 261039251,
      "name": "swift-composable-architecture",
      "full_name": "pointfreeco/swift-composable-architecture",
      "description": "A library for building applications in a consistent and understandable way, with composition, testing, and ergonomics in mind.",
      "html_url": "https://github.com/pointfreeco/swift-composable-architecture",
      "stars": 14273,
      "forks": 1628,
      "language": "Swift",
      "topics": [
        "architecture",
        "composition",
        "modularity",
        "swiftui",
        "testability",
        "uikit"
      ],
      "created_at": "2020-05-03T23:18:40Z",
      "updated_at": "2026-01-24T00:47:31Z",
      "pushed_at": "2025-12-30T21:38:44Z",
      "open_issues": 24,
      "owner": {
        "login": "pointfreeco",
        "avatar_url": "https://avatars.githubusercontent.com/u/29466629?v=4"
      },
      "readme": "# The Composable Architecture\n\n[![CI](https://github.com/pointfreeco/swift-composable-architecture/actions/workflows/ci.yml/badge.svg)](https://github.com/pointfreeco/swift-composable-architecture/actions/workflows/ci.yml)\n[![Slack](https://img.shields.io/badge/slack-chat-informational.svg?label=Slack&logo=slack)](https://www.pointfree.co/slack-invite)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-composable-architecture%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-composable-architecture%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture)\n\nThe Composable Architecture (TCA, for short) is a library for building applications in a consistent \nand understandable way, with composition, testing, and ergonomics in mind. It can be used in \nSwiftUI, UIKit, and more, and on any Apple platform (iOS, macOS, iPadOS, visionOS, tvOS, and watchOS).\n\n* [What is the Composable Architecture?](#what-is-the-composable-architecture)\n* [Learn more](#learn-more)\n* [Examples](#examples)\n* [Basic usage](#basic-usage)\n* [Documentation](#documentation)\n* [FAQ](#faq)\n* [Community](#community)\n* [Installation](#installation)\n* [Translations](#translations)\n\n## What is the Composable Architecture?\n\nThis library provides a few core tools that can be used to build applications of varying purpose and \ncomplexity. It provides compelling stories that you can follow to solve many problems you encounter \nday-to-day when building applications, such as:\n\n* **State management**\n  <br> How to manage the state of your application using simple value types, and share state across \n  many screens so that mutations in one screen can be immediately observed in another screen.\n\n* **Composition**\n  <br> How to break down large features into smaller components that can be extracted to their own, \n  isolated modules and be easily glued back together to form the feature.\n\n* **Side effects**\n  <br> How to let certain parts of the application talk to the outside world in the most testable \n  and understandable way possible.\n\n* **Testing**\n  <br> How to not only test a feature built in the architecture, but also write integration tests \n  for features that have been composed of many parts, and write end-to-end tests to understand how \n  side effects influence your application. This allows you to make strong guarantees that your \n  business logic is running in the way you expect.\n\n* **Ergonomics**\n  <br> How to accomplish all of the above in a simple API with as few concepts and moving parts as \n  possible.\n\n## Learn More\n\nThe Composable Architecture was designed over the course of many episodes on \n[Point-Free][pointfreeco], a video series exploring advanced programming topics in the Swift language, \nhosted by [Brandon Williams][mbrandonw] and [Stephen Celis][stephencelis].\n\nYou can watch all of the episodes [here][tca-episode-collection], as well as a dedicated, [multipart\ntour][tca-tour] of the architecture from scratch.\n\n<a href=\"https://www.pointfree.co/collections/tours/composable-architecture-1-0\">\n  <img alt=\"video poster image\" src=\"https://d3rccdn33rt8ze.cloudfront.net/episodes/0243.jpeg\" width=\"600\">\n</a>\n\n## Examples\n\n[![Screen shots of example applications](https://d3rccdn33rt8ze.cloudfront.net/composable-architecture/demos.png)](./Examples)\n\nThis repo comes with _lots_ of examples to demonstrate how to solve common and complex problems with \nthe Composable Architecture. Check out [this](./Examples) directory to see them all, including:\n\n* [Case Studies](./Examples/CaseStudies)\n  * Getting started\n  * Effects\n  * Navigation\n  * Higher-order reducers\n  * Reusable components\n* [Location manager](https://github.com/pointfreeco/composable-core-location/tree/main/Examples/LocationManager)\n* [Motion manager](https://github.com/pointfreeco/composable-core-motion/tree/main/Examples/MotionManager)\n* [Search](./Examples/Search)\n* [Speech Recognition](./Examples/SpeechRecognition)\n* [SyncUps app](./Examples/SyncUps)\n* [Tic-Tac-Toe](./Examples/TicTacToe)\n* [Todos](./Examples/Todos)\n* [Voice memos](./Examples/VoiceMemos)\n\nLooking for something more substantial? Check out the source code for [isowords][gh-isowords], an \niOS word search game built in SwiftUI and the Composable Architecture.\n\n## Basic Usage\n\n> [!Note] \n> For a step-by-step interactive tutorial, be sure to check out [Meet the Composable\n> Architecture][meet-tca].\n\nTo build a feature using the Composable Architecture you define some types and values that model \nyour domain:\n\n* **State**: A type that describes the data your feature needs to perform its logic and render its \nUI.\n* **Action**: A type that represents all of the actions that can happen in your feature, such as \nuser actions, notifications, event sources and more.\n* **Reducer**: A function that describes how to evolve the current state of the app to the next \nstate given an action. The reducer is also responsible for returning any effects that should be \nrun, such as API requests, which can be done by returning an `Effect` value.\n* **Store**: The runtime that actually drives your feature. You send all user actions to the store \nso that the store can run the reducer and effects, and you can observe state changes in the store \nso that you can update UI.\n\nThe benefits of doing this are that you will instantly unlock testability of your feature, and you \nwill be able to break large, complex features into smaller domains that can be glued together.\n\nAs a basic example, consider a UI that shows a number along with \"+\" and \"‚àí\" buttons that increment \nand decrement the number. To make things interesting, suppose there is also a button that when \ntapped makes an API request to fetch a random fact about that number and displays it in the view.\n\nTo implement this feature we create a new type that will house the domain and behavior of the \nfeature, and it will be annotated with the `@Reducer` macro:\n\n```swift\nimport ComposableArchitecture\n\n@Reducer\nstruct Feature {\n}\n```\n\nIn here we need to define a type for the feature's state, which consists of an integer for the \ncurrent count, as well as an optional string that represents the fact being presented:\n\n```swift\n@Reducer\nstruct Feature {\n  @ObservableState\n  struct State: Equatable {\n    var count = 0\n    var numberFact: String?\n  }\n}\n```\n\n> [!Note] \n> We've applied the `@ObservableState` macro to `State` in order to take advantage of the\n> observation tools in the library.\n\nWe also need to define a type for the feature's actions. There are the obvious actions, such as \ntapping the decrement button, increment button, or fact button. But there are also some slightly \nnon-obvious ones, such as the action that occurs when we receive a response from the fact API \nrequest:\n\n```swift\n@Reducer\nstruct Feature {\n  @ObservableState\n  struct State: Equatable { /* ... */ }\n  enum Action {\n    case decrementButtonTapped\n    case incrementButtonTapped\n    case numberFactButtonTapped\n    case numberFactResponse(String)\n  }\n}\n```\n\nAnd then we implement the `body` property, which is responsible for composing the actual logic and \nbehavior for the feature. In it we can use the `Reduce` reducer to describe how to change the\ncurrent state to the next state, and what effects need to be executed. Some actions don't need to\nexecute effects, and they can return `.none` to represent that:\n\n```swift\n@Reducer\nstruct Feature {\n  @ObservableState\n  struct State: Equatable { /* ... */ }\n  enum Action { /* ... */ }\n\n  var body: some Reducer<State, Action> {\n    Reduce { state, action in\n      switch action {\n      case .decrementButtonTapped:\n        state.count -= 1\n        return .none\n\n      case .incrementButtonTapped:\n        state.count += 1\n        return .none\n\n      case .numberFactButtonTapped:\n        return .run { [count = state.count] send in\n          let (data, _) = try await URLSession.shared.data(\n            from: URL(string: \"http://numbersapi.com/\\(count)/trivia\")!\n          )\n          await send(\n            .numberFactResponse(String(decoding: data, as: UTF8.self))\n          )\n        }\n\n      case let .numberFactResponse(fact):\n        state.numberFact = fact\n        return .none\n      }\n    }\n  }\n}\n```\n\nAnd then finally we define the view that displays the feature. It holds onto a `StoreOf<Feature>` \nso that it can observe all changes to the state and re-render, and we can send all user actions to \nthe store so that state changes:\n\n```swift\nstruct FeatureView: View {\n  let store: StoreOf<Feature>\n\n  var body: some View {\n    Form {\n      Section {\n        Text(\"\\(store.count)\")\n        Button(\"Decrement\") { store.send(.decrementButtonTapped) }\n        Button(\"Increment\") { store.send(.incrementButtonTapped) }\n      }\n\n      Section {\n        Button(\"Number fact\") { store.send(.numberFactButtonTapped) }\n      }\n      \n      if let fact = store.numberFact {\n        Text(fact)\n      }\n    }\n  }\n}\n```\n\nIt is also straightforward to have a UIKit controller driven off of this store. You can observe\nstate changes in the store in `viewDidLoad`, and then populate the UI components with data from\nthe store. The code is a bit longer than the SwiftUI version, so we have collapsed it here:\n\n<details>\n  <summary>Click to expand!</summary>\n\n  ```swift\n  class FeatureViewController: UIViewController {\n    let store: StoreOf<Feature>\n\n    init(store: StoreOf<Feature>) {\n      self.store = store\n      super.init(nibName: nil, bundle: nil)\n    }\n\n    required init?(coder: NSCoder) {\n      fatalError(\"init(coder:) has not been implemented\")\n    }\n\n    override func viewDidLoad() {\n      super.viewDidLoad()\n\n      let countLabel = UILabel()\n      let decrementButton = UIButton()\n      let incrementButton = UIButton()\n      let factLabel = UILabel()\n      \n      // Omitted: Add subviews and set up constraints...\n      \n      observe { [weak self] in\n        guard let self \n        else { return }\n        \n        countLabel.text = \"\\(self.store.count)\"\n        factLabel.text = self.store.numberFact\n      }\n    }\n\n    @objc private func incrementButtonTapped() {\n      self.store.send(.incrementButtonTapped)\n    }\n    @objc private func decrementButtonTapped() {\n      self.store.send(.decrementButtonTapped)\n    }\n    @objc private func factButtonTapped() {\n      self.store.send(.numberFactButtonTapped)\n    }\n  }\n  ```\n</details>\n\nOnce we are ready to display this view, for example in the app's entry point, we can construct a \nstore. This can be done by specifying the initial state to start the application in, as well as \nthe reducer that will power the application:\n\n```swift\nimport ComposableArchitecture\n\n@main\nstruct MyApp: App {\n  var body: some Scene {\n    WindowGroup {\n      FeatureView(\n        store: Store(initialState: Feature.State()) {\n          Feature()\n        }\n      )\n    }\n  }\n}\n```\n\nAnd that is enough to get something on the screen to play around with. It's definitely a few more \nsteps than if you were to do this in a vanilla SwiftUI way, but there are a few benefits. It gives \nus a consistent manner to apply state mutations, instead of scattering logic in some observable \nobjects and in various action closures of UI components. It also gives us a concise way of \nexpressing side effects. And we can immediately test this logic, including the effects, without \ndoing much additional work.\n\n### Testing\n\n> [!Note] \n> For more in-depth information on testing, see the dedicated [testing][testing-article] article. \n\nTo test use a `TestStore`, which can be created with the same information as the `Store`, but it \ndoes extra work to allow you to assert how your feature evolves as actions are sent:\n\n```swift\n@Test\nfunc basics() async {\n  let store = TestStore(initialState: Feature.State()) {\n    Feature()\n  }\n}\n```\n\nOnce the test store is created we can use it to make an assertion of an entire user flow of steps. \nEach step of the way we need to prove that state changed how we expect. For example, we can \nsimulate the user flow of tapping on the increment and decrement buttons:\n\n```swift\n// Test that tapping on the increment/decrement buttons changes the count\nawait store.send(.incrementButtonTapped) {\n  $0.count = 1\n}\nawait store.send(.decrementButtonTapped) {\n  $0.count = 0\n}\n```\n\nFurther, if a step causes an effect to be executed, which feeds data back into the store, we must \nassert on that. For example, if we simulate the user tapping on the fact button we expect to \nreceive a fact response back with the fact, which then causes the `numberFact` state to be \npopulated:\n\n```swift\nawait store.send(.numberFactButtonTapped)\n\nawait store.receive(\\.numberFactResponse) {\n  $0.numberFact = ???\n}\n```\n\nHowever, how do we know what fact is going to be sent back to us?\n\nCurrently our reducer is using an effect that reaches out into the real world to hit an API server, \nand that means we have no way to control its behavior. We are at the whims of our internet \nconnectivity and the availability of the API server in order to write this test.\n\nIt would be better for this dependency to be passed to the reducer so that we can use a live \ndependency when running the application on a device, but use a mocked dependency for tests. We can \ndo this by adding a property to the `Feature` reducer:\n\n```swift\n@Reducer\nstruct Feature {\n  let numberFact: (Int) async throws -> String\n  // ...\n}\n```\n\nThen we can use it in the `reduce` implementation:\n\n```swift\ncase .numberFactButtonTapped:\n  return .run { [count = state.count] send in \n    let fact = try await self.numberFact(count)\n    await send(.numberFactResponse(fact))\n  }\n```\n\nAnd in the entry point of the application we can provide a version of the dependency that actually \ninteracts with the real world API server:\n\n```swift\n@main\nstruct MyApp: App {\n  var body: some Scene {\n    WindowGroup {\n      FeatureView(\n        store: Store(initialState: Feature.State()) {\n          Feature(\n            numberFact: { number in\n              let (data, _) = try await URLSession.shared.data(\n                from: URL(string: \"http://numbersapi.com/\\(number)\")!\n              )\n              return String(decoding: data, as: UTF8.self)\n            }\n          )\n        }\n      )\n    }\n  }\n}\n```\n\nBut in tests we can use a mock dependency that immediately returns a deterministic, predictable \nfact: \n\n```swift\n@Test\nfunc basics() async {\n  let store = TestStore(initialState: Feature.State()) {\n    Feature(numberFact: { \"\\($0) is a good number Brent\" })\n  }\n}\n```\n\nWith that little bit of upfront work we can finish the test by simulating the user tapping on the \nfact button, and then receiving the response from the dependency to present the fact:\n\n```swift\nawait store.send(.numberFactButtonTapped)\n\nawait store.receive(\\.numberFactResponse) {\n  $0.numberFact = \"0 is a good number Brent\"\n}\n```\n\nWe can also improve the ergonomics of using the `numberFact` dependency in our application. Over \ntime the application may evolve into many features, and some of those features may also want access \nto `numberFact`, and explicitly passing it through all layers can get annoying. There is a process \nyou can follow to ‚Äúregister‚Äù dependencies with the library, making them instantly available to any \nlayer in the application.\n\n> [!Note] \n> For more in-depth information on dependency management, see the dedicated\n> [dependencies][dependencies-article] article. \n\nWe can start by wrapping the number fact functionality in a new type:\n\n```swift\nstruct NumberFactClient {\n  var fetch: (Int) async throws -> String\n}\n```\n\nAnd then registering that type with the dependency management system by conforming the client to\nthe `DependencyKey` protocol, which requires you to specify the live value to use when running the\napplication in simulators or devices:\n\n```swift\nextension NumberFactClient: DependencyKey {\n  static let liveValue = Self(\n    fetch: { number in\n      let (data, _) = try await URLSession.shared\n        .data(from: URL(string: \"http://numbersapi.com/\\(number)\")!\n      )\n      return String(decoding: data, as: UTF8.self)\n    }\n  )\n}\n\nextension DependencyValues {\n  var numberFact: NumberFactClient {\n    get { self[NumberFactClient.self] }\n    set { self[NumberFactClient.self] = newValue }\n  }\n}\n```\n\nWith that little bit of upfront work done you can instantly start making use of the dependency in \nany feature by using the `@Dependency` property wrapper:\n\n```diff\n @Reducer\n struct Feature {\n-  let numberFact: (Int) async throws -> String\n+  @Dependency(\\.numberFact) var numberFact\n   \n   ‚Ä¶\n\n-  try await self.numberFact(count)\n+  try await self.numberFact.fetch(count)\n }\n```\n\nThis code works exactly as it did before, but you no longer have to explicitly pass the dependency \nwhen constructing the feature's reducer. When running the app in previews, the simulator or on a \ndevice, the live dependency will be provided to the reducer, and in tests the test dependency will \nbe provided.\n\nThis means the entry point to the application no longer needs to construct dependencies:\n\n```swift\n@main\nstruct MyApp: App {\n  var body: some Scene {\n    WindowGroup {\n      FeatureView(\n        store: Store(initialState: Feature.State()) {\n          Feature()\n        }\n      )\n    }\n  }\n}\n```\n\nAnd the test store can be constructed without specifying any dependencies, but you can still \noverride any dependency you need to for the purpose of the test:\n\n```swift\nlet store = TestStore(initialState: Feature.State()) {\n  Feature()\n} withDependencies: {\n  $0.numberFact.fetch = { \"\\($0) is a good number Brent\" }\n}\n\n// ...\n```\n\nThat is the basics of building and testing a feature in the Composable Architecture. There are \n_a lot_ more things to be explored, such as composition, modularity, adaptability, and complex \neffects. The [Examples](./Examples) directory has a bunch of projects to explore to see more \nadvanced usages.\n\n## Documentation\n\nThe documentation for releases and `main` are available here:\n\n* [`main`](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture)\n* [1.x.x](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/~/documentation/composablearchitecture)\n\nThere are a number of articles in the documentation that you may find helpful as you become more \ncomfortable with the library:\n\n* [Getting started][getting-started-article]\n* [Dependencies][dependencies-article]\n* [Testing][testing-article]\n* [Navigation][navigation-article]\n* [Sharing state][sharing-state-article]\n* [Performance][performance-article]\n* [Concurrency][concurrency-article]\n* [Bindings][bindings-article]\n\n## FAQ\n\nWe have a [dedicated article][faq-article] for all of the most frequently asked questions and\ncomments people have concerning the library.\n\n## Community\n\nIf you want to discuss the Composable Architecture or have a question about how to use it to solve \na particular problem, there are a number of places you can discuss with fellow \n[Point-Free](http://www.pointfree.co) enthusiasts:\n\n* For long-form discussions, we recommend the [discussions][gh-discussions] tab of this repo.\n* For casual chat, we recommend the [Point-Free Community slack](http://pointfree.co/slack-invite).\n\n## Installation\n\nYou can add ComposableArchitecture to an Xcode project by adding it as a package dependency.\n\n  1. From the **File** menu, select **Add Package Dependencies...**\n  2. Enter \"https://github.com/pointfreeco/swift-composable-architecture\" into the package \n     repository URL text field\n  3. Depending on how your project is structured:\n      - If you have a single application target that needs access to the library, then add \n        **ComposableArchitecture** directly to your application.\n      - If you want to use this library from multiple Xcode targets, or mix Xcode targets and SPM \n        targets, you must create a shared framework that depends on **ComposableArchitecture** and \n        then depend on that framework in all of your targets. For an example of this, check out the \n        [Tic-Tac-Toe](./Examples/TicTacToe) demo application, which splits lots of features into \n        modules and consumes the static library in this fashion using the **tic-tac-toe** Swift \n        package.\n\n## Companion libraries\n\nThe Composable Architecture is built with extensibility in mind, and there are a number of\ncommunity-supported libraries available to enhance your applications:\n\n* [Composable Architecture Extras](https://github.com/Ryu0118/swift-composable-architecture-extras):\n  A companion library to the Composable Architecture.\n* [TCAComposer](https://github.com/mentalflux/tca-composer): A macro framework for generating\n  boiler-plate code in the Composable Architecture.\n* [TCACoordinators](https://github.com/johnpatrickmorgan/TCACoordinators): The coordinator pattern\n  in the Composable Architecture.\n\nIf you'd like to contribute a library, please [open a\nPR](https://github.com/pointfreeco/swift-composable-architecture/edit/main/README.md) with a link\nto it!\n\n## Translations\n\nThe following translations of this README have been contributed by members of the community:\n\n* [Arabic](https://gist.github.com/NorhanBoghdadi/1b98d55c02b683ddef7e05c2ebcccd47)\n* [French](https://gist.github.com/nikitamounier/0e93eb832cf389db12f9a69da030a2dc)\n* [Hindi](https://gist.github.com/akashsoni01/b358ee0b3b747167964ef6946123c88d)\n* [Indonesian](https://gist.github.com/wendyliga/792ea9ac5cc887f59de70a9e39cc7343)\n* [Italian](https://gist.github.com/Bellaposa/5114e6d4d55fdb1388e8186886d48958)\n* [Japanese](https://gist.github.com/Achoo-kr/2d0712deb77f78b3379551ac7baea3e4)\n* [Korean](https://gist.github.com/Achoo-kr/5d8936d12e71028fcc4a7c5e078ca038)\n* [Polish](https://gist.github.com/MarcelStarczyk/6b6153051f46912a665c32199f0d1d54)\n* [Portuguese](https://gist.github.com/SevioCorrea/2bbf337cd084a58c89f2f7f370626dc8)\n* [Russian](https://gist.github.com/SubvertDev/3317d0c3b35ed601be330d6fc0df5aba)\n* [Simplified Chinese](https://gist.github.com/sh3l6orrr/10c8f7c634a892a9c37214f3211242ad)\n* [Spanish](https://gist.github.com/pitt500/f5e32fccb575ce112ffea2827c7bf942)\n* [Turkish](https://gist.github.com/gokhanamal/93001244ef0c1cec58abeb1afc0de37c)\n* [Ukrainian](https://gist.github.com/barabashd/33b64676195ce41f4bb73c327ea512a8)\n\nIf you'd like to contribute a translation, please [open a\nPR](https://github.com/pointfreeco/swift-composable-architecture/edit/main/README.md) with a link \nto a [Gist](https://gist.github.com)!\n\n## Credits and thanks\n\nThe following people gave feedback on the library at its early stages and helped make the library \nwhat it is today:\n\nPaul Colton, Kaan Dedeoglu, Matt Diephouse, Josef Dole≈æal, Eimantas, Matthew Johnson, George \nKaimakas, Nikita Leonov, Christopher Liscio, Jeffrey Macko, Alejandro Martinez, Shai Mishali, Willis \nPlummer, Simon-Pierre Roy, Justin Price, Sven A. Schmidt, Kyle Sherman, Petr ≈†√≠ma, Jasdev Singh, \nMaxim Smirnov, Ryan Stone, Daniel Hollis Tavares, and all of the [Point-Free][pointfreeco] \nsubscribers üòÅ.\n\nSpecial thanks to [Chris Liscio](https://twitter.com/liscio) who helped us work through many strange \nSwiftUI quirks and helped refine the final API.\n\nAnd thanks to [Shai Mishali](https://github.com/freak4pc) and the\n[CombineCommunity](https://github.com/CombineCommunity/CombineExt/) project, from which we took \ntheir implementation of `Publishers.Create`, which we use in `Effect` to help bridge delegate and \ncallback-based APIs, making it much easier to interface with 3rd party frameworks.\n\n## Other libraries\n\nThe Composable Architecture was built on a foundation of ideas started by other libraries, in \nparticular [Elm](https://elm-lang.org) and [Redux](https://redux.js.org/).\n\nThere are also many architecture libraries in the Swift and iOS community. Each one of these has \ntheir own set of priorities and trade-offs that differ from the Composable Architecture.\n\n* [RIBs](https://github.com/uber/RIBs)\n* [Loop](https://github.com/ReactiveCocoa/Loop)\n* [ReSwift](https://github.com/ReSwift/ReSwift)\n* [Workflow](https://github.com/square/workflow)\n* [ReactorKit](https://github.com/ReactorKit/ReactorKit)\n* [RxFeedback](https://github.com/NoTests/RxFeedback.swift)\n* [Mobius.swift](https://github.com/spotify/mobius.swift)\n* <details>\n  <summary>And more</summary>\n\n  * [Fluxor](https://github.com/FluxorOrg/Fluxor)\n  * [PromisedArchitectureKit](https://github.com/RPallas92/PromisedArchitectureKit)\n  </details>\n\n## License\n\nThis library is released under the MIT license. See [LICENSE](LICENSE) for details.\n\n[pointfreeco]: https://www.pointfree.co\n[mbrandonw]: https://twitter.com/mbrandonw\n[stephencelis]: https://twitter.com/stephencelis\n[tca-episode-collection]: https://www.pointfree.co/collections/composable-architecture\n[tca-tour]: https://www.pointfree.co/collections/tours/composable-architecture-1-0\n[gh-isowords]: https://github.com/pointfreeco/isowords\n[gh-discussions]: https://github.com/pointfreeco/swift-composable-architecture/discussions\n[swift-forum]: https://forums.swift.org/c/related-projects/swift-composable-architecture\n[testing-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/testingtca\n[faq-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/faq\n[dependencies-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/dependencymanagement\n[getting-started-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/gettingstarted\n[navigation-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/navigation\n[performance-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/performance\n[concurrency-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/swiftconcurrency\n[bindings-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/bindings\n[sharing-state-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/sharingstate\n[meet-tca]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/tutorials/meetcomposablearchitecture\n",
      "stars_today": 4
    },
    {
      "id": 511961615,
      "name": "PlayCover",
      "full_name": "PlayCover/PlayCover",
      "description": "Community fork of PlayCover",
      "html_url": "https://github.com/PlayCover/PlayCover",
      "stars": 10644,
      "forks": 869,
      "language": "Swift",
      "topics": [],
      "created_at": "2022-07-08T16:38:11Z",
      "updated_at": "2026-01-24T01:33:08Z",
      "pushed_at": "2026-01-23T17:03:29Z",
      "open_issues": 500,
      "owner": {
        "login": "PlayCover",
        "avatar_url": "https://avatars.githubusercontent.com/u/108947908?v=4"
      },
      "readme": "<div id=\"top\"></div>\n\n‚Äé<h1 align=\"center\">[![Contributors][contributors-shield]][contributors-url]\n[![Forks][forks-shield]][forks-url]\n[![Stargazers][stars-shield]][stars-url]\n[![Issues][issues-shield]][issues-url]\n[![GPLv3 License][license-shield]][license-url]\n[![Weblate](https://img.shields.io/weblate/progress/playcover?style=for-the-badge)](https://hosted.weblate.org/projects/playcover/playcover/)\n</h1>\n\n\n\n<!-- PROJECT LOGO -->\n<br />\n<div align=\"center\">\n  <a href=\"https://github.com/PlayCover/PlayCover\">\n    <img src=\"images/logo.png\" alt=\"Logo\" width=\"80\" height=\"80\">\n  </a>\n\n  <h3 align=\"center\">PlayCover</h3>\n\n  <p align=\"center\">\n    Run iOS apps and games on Apple Silicon Macs with mouse, keyboard and controller support.\n    <br />\n    <br />\n    <a href=\"https://playcover.github.io/PlayBook\">Documentation</a>\n    ¬∑\n    <a href=\"https://discord.gg/RNCHsQHr3S\">Discord</a>\n    ¬∑\n    <a href=\"https://playcover.io/\">Website</a>\n  </p>\n</div>\n\n<!-- ABOUT THE PROJECT -->\n## About The Project\n\nWelcome to PlayCover! This software is all about allowing you to run iOS apps and games on Apple Silicon devices running macOS 12.0 or newer.\n\nPlayCover works by putting applications through a wrapper which imitates an iPad. This allows the apps to run natively and perform very well.\n\nPlayCover also allows you to map custom touch controls to keyboard, which is not possible in alternative sideloading methods such as Sideloadly. \n\nThese controls include all the essentials, from WASD, camera movement, left and right clicks, and individual keymapping, similar to a popular Android emulator‚Äôs keymapping system called Bluestacks.\n\nThis software was originally designed to run Genshin Impact on your Apple Silicon device, but it can now run a wide range of applications. Unfortunately, not all games are supported, and some may have bugs.\n\nLocalisations handled in [Weblate](https://hosted.weblate.org/projects/playcover/).\n\n![Fancy logo](./images/dark.png#gh-dark-mode-only)\n![Fancy logo](./images/light.png#gh-light-mode-only)\n\n<p align=\"right\"><a href=\"#top\">‚¨ÜÔ∏è Back to topÔ∏è</a></p>\n\n<!-- GETTING STARTED -->\n## Getting Started\n\nFollow the instructions below to get Genshin Impact, and many other games, up and running in no time.\n\n### Prerequisites\n\nAt the moment, PlayCover can only run on Apple Silicon Macs. This means that only devices with M-series SoCs (eg. M1) are supported.\n\nIf you have an Intel Mac, you can explore alternatives like Bootcamp or emulators.\n\n### Download\n\nYou can download stable releases [here](https://github.com/PlayCover/PlayCover/releases), or build from source by following the instructions in the Documentation.\n\n### Documentation\n\nTo learn how to setup and use PlayCover, visit the documentation [here](https://playcover.github.io/PlayBook).\n\n### Homebrew Cask\nWe host a [Homebrew](https://brew.sh) tap with the [PlayCover cask](https://github.com/PlayCover/homebrew-playcover/blob/master/Casks/playcover-community.rb). To install from it run:\n\n```sh\nbrew install --cask PlayCover/playcover/playcover-community\n```\n\nTo uninstall:\n1. Remove PlayCover using `brew uninstall --cask playcover-community`;\n2. Untap `PlayCover/playcover` with `brew untap PlayCover/playcover`.\n\n<p align=\"right\"><a href=\"#top\">‚¨ÜÔ∏è Back to topÔ∏è</a></p>\n\n\n\n<!-- LICENSE -->\n## License\n\nDistributed under the GPLv3 License. See `LICENSE` for more information.\n\n\n\n<!-- CONTACT -->\n## Contact\n\nLucas Lee - playcover@lucas.icu\n\nDepal - depal@playcover.io\n\n\n\n\n<!-- ACKNOWLEDGMENTS -->\n## Libraries Used\n\nThese open source libraries were used to create this project.\n\n* [inject](https://github.com/paradiseduo/inject)\n* [PTFakeTouch](https://github.com/Ret70/PTFakeTouch)\n* [DownloadManager](https://github.com/shapedbyiris/download-manager)\n* [DataCache](https://github.com/huynguyencong/DataCache)\n* [SwiftUI CachedAsyncImage](https://github.com/bullinnyc/CachedAsyncImage)\n\n* Thanks to @iVoider for creating such a great project!\n\n<p align=\"right\"><a href=\"#top\">‚¨ÜÔ∏è Back to topÔ∏è</a></p>\n\n\n\n<!-- MARKDOWN LINKS & IMAGES -->\n[contributors-shield]: https://img.shields.io/github/contributors/PlayCover/PlayCover.svg?style=for-the-badge\n[contributors-url]: https://github.com/PlayCover/PlayCover/graphs/contributors\n[forks-shield]: https://img.shields.io/github/forks/PlayCover/PlayCover.svg?style=for-the-badge\n[forks-url]: https://github.com/PlayCover/PlayCover/network/members\n[stars-shield]: https://img.shields.io/github/stars/PlayCover/PlayCover.svg?style=for-the-badge\n[stars-url]: https://github.com/PlayCover/PlayCover/stargazers\n[issues-shield]: https://img.shields.io/github/issues/PlayCover/PlayCover.svg?style=for-the-badge\n[issues-url]: https://github.com/PlayCover/PlayCover/issues\n[license-shield]: https://img.shields.io/github/license/PlayCover/PlayCover.svg?style=for-the-badge\n[license-url]: https://github.com/PlayCover/PlayCover/blob/master/LICENSE\n",
      "stars_today": 4
    },
    {
      "id": 50629145,
      "name": "pprof",
      "full_name": "google/pprof",
      "description": "pprof is a tool for visualization and analysis of profiling data",
      "html_url": "https://github.com/google/pprof",
      "stars": 9022,
      "forks": 649,
      "language": "Go",
      "topics": [
        "performance",
        "performance-analysis",
        "pprof",
        "profiler"
      ],
      "created_at": "2016-01-29T01:52:07Z",
      "updated_at": "2026-01-23T21:00:08Z",
      "pushed_at": "2026-01-15T05:41:56Z",
      "open_issues": 54,
      "owner": {
        "login": "google",
        "avatar_url": "https://avatars.githubusercontent.com/u/1342004?v=4"
      },
      "readme": "[![Github Action CI](https://github.com/google/pprof/workflows/ci/badge.svg)](https://github.com/google/pprof/actions)\n[![Codecov](https://codecov.io/gh/google/pprof/graph/badge.svg)](https://codecov.io/gh/google/pprof)\n[![Go Reference](https://pkg.go.dev/badge/github.com/google/pprof/profile.svg)](https://pkg.go.dev/github.com/google/pprof/profile)\n\n# Introduction\n\npprof is a tool for visualization and analysis of profiling data.\n\npprof reads a collection of profiling samples in profile.proto format and\ngenerates reports to visualize and help analyze the data. It can generate both\ntext and graphical reports (through the use of the dot visualization package).\n\nprofile.proto is a protocol buffer that describes a set of callstacks\nand symbolization information. A common usage is to represent a set of\nsampled callstacks from statistical profiling. The format is\ndescribed on the [proto/profile.proto](./proto/profile.proto) file. For details on protocol\nbuffers, see https://developers.google.com/protocol-buffers\n\nProfiles can be read from a local file, or over http. Multiple\nprofiles of the same type can be aggregated or compared.\n\nIf the profile samples contain machine addresses, pprof can symbolize\nthem through the use of the native binutils tools (addr2line and nm).\n\n**This is not an official Google product.**\n\n# Building pprof\n\nPrerequisites:\n\n- Go development kit of a [supported version](https://golang.org/doc/devel/release.html#policy).\n  Follow [these instructions](http://golang.org/doc/code.html) to prepare\n  the environment.\n\n- Graphviz: http://www.graphviz.org/\n  Optional, used to generate graphic visualizations of profiles\n\nTo build and install it:\n\n    go install github.com/google/pprof@latest\n\nThe binary will be installed `$GOPATH/bin` (`$HOME/go/bin` by default).\n\n# Basic usage\n\npprof can read a profile from a file or directly from a server via http.\nSpecify the profile input(s) in the command line, and use options to\nindicate how to format the report.\n\n## Generate a text report of the profile, sorted by hotness:\n\n```\n% pprof -top [main_binary] profile.pb.gz\nWhere\n    main_binary:  Local path to the main program binary, to enable symbolization\n    profile.pb.gz: Local path to the profile in a compressed protobuf, or\n                   URL to the http service that serves a profile.\n```\n\n## Generate a graph in an SVG file, and open it with a web browser:\n\n```\npprof -web [main_binary] profile.pb.gz\n```\n\n## Run pprof on interactive mode:\n\nIf no output formatting option is specified, pprof runs on interactive mode,\nwhere reads the profile and accepts interactive commands for visualization and\nrefinement of the profile.\n\n```\npprof [main_binary] profile.pb.gz\n\nThis will open a simple shell that takes pprof commands to generate reports.\nType 'help' for available commands/options.\n```\n\n## Run pprof via a web interface\n\nIf the `-http` flag is specified, pprof starts a web server at\nthe specified host:port that provides an interactive web-based interface to pprof.\nHost is optional, and is \"localhost\" by default. Port is optional, and is a\nrandom available port by default. `-http=\":\"` starts a server locally at\na random port.\n\n```\npprof -http=[host]:[port] [main_binary] profile.pb.gz\n```\n\nThe preceding command should automatically open your web browser at\nthe right page; if not, you can manually visit the specified port in\nyour web browser.\n\n## Using pprof with Linux Perf\n\npprof can read `perf.data` files generated by the\n[Linux perf](https://perf.wiki.kernel.org/index.php/Main_Page) tool by using the\n`perf_to_profile` program from the\n[perf_data_converter](https://github.com/google/perf_data_converter) package.\n\n## Viewing disassembly on Windows\n\nTo view disassembly of profiles collected from Go programs compiled as Windows executables,\nthe executable must be built with `go build -buildmode=exe`. LLVM or GCC must be installed,\nso required tools like `addr2line` and `nm` are available to `pprof`.\n\n## Further documentation\n\nSee [doc/README.md](doc/README.md) for more detailed end-user documentation.\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for contribution documentation.\n\nSee [proto/README.md](proto/README.md) for a description of the profile.proto format.\n",
      "stars_today": 4
    },
    {
      "id": 37778564,
      "name": "Clipy",
      "full_name": "Clipy/Clipy",
      "description": "Clipboard extension app for macOS.",
      "html_url": "https://github.com/Clipy/Clipy",
      "stars": 8365,
      "forks": 716,
      "language": "Swift",
      "topics": [
        "clipboard",
        "clipboard-extension",
        "clipmenu",
        "macos",
        "swift",
        "xcode"
      ],
      "created_at": "2015-06-20T17:21:24Z",
      "updated_at": "2026-01-23T15:54:05Z",
      "pushed_at": "2024-06-29T14:02:13Z",
      "open_issues": 256,
      "owner": {
        "login": "Clipy",
        "avatar_url": "https://avatars.githubusercontent.com/u/12979368?v=4"
      },
      "readme": "<div align=\"center\">\n  <img src=\"./Resources/clipy_logo.png\" width=\"400\">\n</div>\n\n<br>\n\n![CI](https://github.com/Clipy/Clipy/workflows/CI/badge.svg)\n[![Release version](https://img.shields.io/github/release/Clipy/Clipy.svg)](https://github.com/Clipy/Clipy/releases/latest)\n[![OpenCollective](https://opencollective.com/clipy/backers/badge.svg)](#backers)\n[![OpenCollective](https://opencollective.com/clipy/sponsors/badge.svg)](#sponsors)\n\nClipy is a Clipboard extension app for macOS.\n\n---\n\n__Requirement__: macOS 10.10 Yosemite or higher\n\n__Distribution Site__ : <https://clipy-app.com>\n\n<img src=\"http://clipy-app.com/img/screenshot1.png\" width=\"400\">\n\n### Development Environment\n* macOS 10.15 Catalina\n* Xcode 12.2\n* Swift 5.3\n\n### How to Build\n0. Move to the project root directory\n1. `bundle install --path=vendor/bundle && bundle exec pod install`\n2. Open `Clipy.xcworkspace` on Xcode.\n3. build.\n\n### Contributing\n1. Fork it ( https://github.com/Clipy/Clipy/fork )\n2. Create your feature branch (`git checkout -b my-new-feature`)\n3. Commit your changes (`git commit -am 'Add some feature'`)\n4. Push to the branch (`git push origin my-new-feature`)\n5. Create a new Pull Request\n\n### Localization Contributors\nClipy is looking for localization contributors.  \nIf you can contribute, please see [CONTRIBUTING.md](https://github.com/Clipy/Clipy/blob/master/.github/CONTRIBUTING.md)\n\n### Distribution\nIf you distribute derived work, especially in the Mac App Store, I ask you to follow two rules:\n\n1. Don't use `Clipy` and `ClipMenu` as your product name.\n2. Follow the MIT license terms.\n\nThank you for your cooperation.\n\n### Backers\n\nSupport us with a monthly donation and help us continue our activities. [[Become a backer](https://opencollective.com/clipy#backer)]\n\n<a href=\"https://opencollective.com/clipy/backer/0/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/0/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/1/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/1/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/2/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/2/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/3/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/3/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/4/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/4/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/5/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/5/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/6/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/6/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/7/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/7/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/8/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/8/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/9/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/9/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/10/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/10/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/11/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/11/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/12/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/12/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/13/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/13/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/14/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/14/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/15/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/15/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/16/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/16/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/17/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/17/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/18/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/18/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/19/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/19/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/20/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/20/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/21/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/21/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/22/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/22/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/23/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/23/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/24/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/24/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/25/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/25/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/26/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/26/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/27/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/27/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/28/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/28/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/29/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/29/avatar.svg\"></a>\n\n### Sponsors\n\nBecome a sponsor and get your logo on our README on Github with a link to your site. [[Become a sponsor](https://opencollective.com/clipy#sponsor)]\n\n<a href=\"https://opencollective.com/clipy/sponsor/0/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/0/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/1/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/1/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/2/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/2/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/3/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/3/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/4/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/4/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/5/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/5/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/6/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/6/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/7/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/7/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/8/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/8/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/9/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/9/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/10/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/10/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/11/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/11/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/12/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/12/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/13/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/13/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/14/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/14/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/15/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/15/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/16/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/16/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/17/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/17/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/18/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/18/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/19/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/19/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/20/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/20/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/21/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/21/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/22/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/22/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/23/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/23/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/24/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/24/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/25/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/25/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/26/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/26/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/27/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/27/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/28/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/28/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/29/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/29/avatar.svg\"></a>\n\n### Licence\nClipy is available under the MIT license. See the LICENSE file for more info.\n\nIcons are copyrighted by their respective authors.\n\n### Special Thanks\n__Thank you for [@naotaka](https://github.com/naotaka) who have published [ClipMenu](https://github.com/naotaka/ClipMenu) as OSS.__\n",
      "stars_today": 4
    },
    {
      "id": 9982112,
      "name": "minhook",
      "full_name": "TsudaKageyu/minhook",
      "description": "The Minimalistic x86/x64 API Hooking Library for Windows",
      "html_url": "https://github.com/TsudaKageyu/minhook",
      "stars": 5478,
      "forks": 1029,
      "language": "C",
      "topics": [],
      "created_at": "2013-05-10T13:36:41Z",
      "updated_at": "2026-01-23T12:08:41Z",
      "pushed_at": "2025-11-03T08:09:42Z",
      "open_issues": 54,
      "owner": {
        "login": "TsudaKageyu",
        "avatar_url": "https://avatars.githubusercontent.com/u/2161941?v=4"
      },
      "readme": "# MinHook\n\n[![License](https://img.shields.io/badge/License-BSD%202--Clause-orange.svg)](https://opensource.org/licenses/BSD-2-Clause)\n\nThe Minimalistic x86/x64 API Hooking Library for Windows\n\nhttps://www.codeproject.com/articles/MinHook-The-Minimalistic-x-x-API-Hooking-Libra\n\n### Version history\n\n- **v1.3.4 - 28 Mar 2025**\n  * Improved error handling for enumerating and suspending threads.\n  * Visual Studio 2022 support.\n  * CMake support.\n  * Fixed compilation with Clang.\n  * Fixed compilation as C++ code.\n\n- **v1.3.3 - 8 Jan 2017**\n  * Added a helper function ```MH_CreateHookApiEx```. (Thanks to asm256)\n  * Support Visual Studio 2017 RC.\n\n- **v1.3.2.1 - 9 Nov 2015**  (Nuget package only)\n  * Fixed an insufficient support for Visual Studio 2015.\n\n- **v1.3.2 - 1 Nov 2015**\n  * Support Visual Studio 2015.\n  * Support MinGW.\n\n- **v1.3.2-beta3 - 21 Jul 2015**  (Nuget package only)\n  * Support MinGW. (Experimental)\n\n- **v1.3.2-beta2 - 18 May 2015**\n  * Fixed some subtle bugs. (Thanks to RaMMicHaeL)\n  * Added a helper function ```MH_StatusToString```. (Thanks to Jan Klass)\n\n- **v1.3.2-beta - 12 May 2015**\n  * Fixed a possible thread deadlock in x64 mode. (Thanks to Aleh Kazakevich)\n  * Reduced the footprint a little more.\n  * Support Visual Studio 2015 RC. (Experimental)\n\n- **v1.3.1.1 - 7 Apr 2015**  (Nuget package only)\n  * Support for WDK8.0 and 8.1.\n\n- **v1.3.1 - 19 Mar 2015**\n  * No major changes from v1.3.1-beta.\n\n- **v1.3.1-beta - 11 Mar 2015**\n  * Added a helper function ```MH_CreateHookApi```. (Thanks to uniskz).\n  * Fixed a false memory leak reported by some tools.\n  * Fixed a degradated compatibility issue.\n\n- **v1.3 - 13 Sep 2014**\n  * No major changes from v1.3-beta3.\n\n- **v1.3-beta3 - 31 Jul 2014**\n  * Fixed some small bugs.\n  * Improved the memory management.\n\n- **v1.3-beta2 - 21 Jul 2014**\n  * Changed the parameters to Windows-friendly types. (void* to LPVOID)\n  * Fixed some small bugs.\n  * Reorganized the source files.\n  * Reduced the footprint a little more.\n\n- **v1.3-beta - 17 Jul 2014**\n  * Rewrote in plain C to reduce the footprint and memory usage. (suggested by Andrey Unis)\n  * Simplified the overall code base to make it more readable and maintainable.\n  * Changed the license from 3-clause to 2-clause BSD License.\n\n- **v1.2 - 28 Sep 2013**\n  * Removed boost dependency ([jarredholman](https://github.com/jarredholman/minhook)).\n  * Fixed a small bug in the GetRelativeBranchDestination function ([pillbug99](http://www.codeproject.com/Messages/4058892/Small-Bug-Found.aspx)).\n  * Added the ```MH_RemoveHook``` function, which removes a hook created with the ```MH_CreateHook``` function.\n  * Added the following functions to enable or disable multiple hooks in one go: ```MH_QueueEnableHook```, ```MH_QueueDisableHook```, ```MH_ApplyQueued```. This is the preferred way of handling multiple hooks as every call to `MH_EnableHook` or `MH_DisableHook` suspends and resumes all threads.\n  * Made the functions ```MH_EnableHook``` and ```MH_DisableHook``` enable/disable all created hooks when the ```MH_ALL_HOOKS``` parameter is passed. This, too, is an efficient way of handling multiple hooks.\n  * If the target function is too small to be patched with a jump, MinHook tries to place the jump above the function. If that fails as well, the ```MH_CreateHook``` function returns ```MH_ERROR_UNSUPPORTED_FUNCTION```. This fixes an issue of hooking the LoadLibraryExW function on Windows 7 x64 ([reported by Obble](http://www.codeproject.com/Messages/4578613/Re-Bug-LoadLibraryExW-hook-fails-on-windows-2008-r.aspx)).\n\n- **v1.1 - 26 Nov 2009**\n  * Changed the interface to create a hook and a trampoline function in one go to prevent the detour function from being called before the trampoline function is created. ([reported by xliqz](http://www.codeproject.com/Messages/3280374/Unsafe.aspx))\n  * Shortened the function names from ```MinHook_*``` to ```MH_*``` to make them handier.\n\n- **v1.0 - 22 Nov 2009**\n  * Initial release.\n\n### Building MinHook - Using vcpkg\n\nYou can download and install MinHook using the [vcpkg](https://github.com/Microsoft/vcpkg) dependency manager:\n\n    git clone https://github.com/microsoft/vcpkg\n    .\\vcpkg\\bootstrap-vcpkg.bat\n    .\\vcpkg\\vcpkg integrate install\n    .\\vcpkg\\vcpkg install minhook\n\nThe MinHook port in vcpkg is kept up to date by Microsoft team members and community contributors. If the version is out of date, please [create an issue or pull request](https://github.com/Microsoft/vcpkg) on the vcpkg repository.\n",
      "stars_today": 4
    },
    {
      "id": 105010691,
      "name": "desktop",
      "full_name": "nextcloud/desktop",
      "description": "üíª Desktop sync client for Nextcloud",
      "html_url": "https://github.com/nextcloud/desktop",
      "stars": 3586,
      "forks": 912,
      "language": "C++",
      "topics": [
        "c-plus-plus",
        "cpp",
        "desktop",
        "hacktoberfest",
        "nextcloud",
        "nextcloud-desktop-client"
      ],
      "created_at": "2017-09-27T11:38:04Z",
      "updated_at": "2026-01-23T19:05:28Z",
      "pushed_at": "2026-01-23T19:44:11Z",
      "open_issues": 737,
      "owner": {
        "login": "nextcloud",
        "avatar_url": "https://avatars.githubusercontent.com/u/19211038?v=4"
      },
      "readme": "<!--\n  - SPDX-FileCopyrightText: 2017 Nextcloud GmbH and Nextcloud contributors\n  - SPDX-FileCopyrightText: 2011 Nextcloud GmbH and Nextcloud contributors\n  - SPDX-License-Identifier: GPL-2.0-or-later\n-->\n# Nextcloud Desktop Client\n\n[![REUSE status](https://api.reuse.software/badge/github.com/nextcloud/desktop)](https://api.reuse.software/info/github.com/nextcloud/desktop)\n\nThe Nextcloud Desktop Client is a tool to synchronize files from Nextcloud Server with your computer.\n\n<p align=\"center\">\n    <img src=\"doc/images/main_dialog_christine.png\" alt=\"Desktop Client on Windows\" width=\"450\">\n</p>\n\n## :rocket: Releases\nFor the latest stable recommended version, please refer to the [download page https://nextcloud.com/install/#install-clients](https://nextcloud.com/install/#install-clients)\n\n## Contributing to the desktop client\n:v: Please read the [Code of Conduct](https://nextcloud.com/community/code-of-conduct/). This document offers some guidance to ensure Nextcloud participants can cooperate effectively in a positive and inspiring atmosphere and to explain how together we can strengthen and support each other.\n\n### üë™ Join the team\nThere are many ways to contribute, of which development is only one! Find out [how to get involved](https://nextcloud.com/contribute/), including as a translator, designer, tester, helping others, and much more! üòç\n\n### Help testing\nDownload and install the client:<br>\n[üîΩ All releases](https://github.com/nextcloud-releases/desktop/releases)<br>\n[üîΩ Daily master builds](https://download.nextcloud.com/desktop/daily)\n\n### Reporting issues\nIf you find any bugs or have any suggestion for improvement, please\n[open an issue in this repository](https://github.com/nextcloud/desktop/issues).\n\n### Bug fixing and development\n\n> [!TIP]\n> For building the client on macOS we have a tool called `mac-crafter`.\n> You will find more information about it in [its dedicated README](admin/osx/mac-crafter/README.md).\n> Also, please note the [README in the NextcloudIntegration project](shell_integration/MacOSX/NextcloudIntegration/README.md) which provides an even more convenient way to work on and build the desktop client on macOS by using Xcode.\n\n#### 1. üöÄ Set up your local development environment\n\n> [!NOTE]  \n> Find the system requirements and instructions on [how to work on Windows with KDE Craft](https://github.com/nextcloud/desktop-client-blueprints/) on our [desktop client blueprints repository](https://github.com/nextcloud/desktop-client-blueprints/).\n\n1.1 System requirements\n- [Windows 10, Windows 11](https://github.com/nextcloud/desktop-client-blueprints/), macOS 10.14 Mojave (or newer) or Linux\n- [üîΩ Inkscape (to generate icons)](https://inkscape.org/release/)\n- Developer tools: cmake, clang/gcc/g++:\n- Qt6 since 3.14, Qt5 for earlier versions\n- OpenSSL\n- [üîΩ QtKeychain](https://github.com/frankosterfeld/qtkeychain)\n- SQLite\n\n1.2 Optional\n- [Qt Creator IDE](https://www.qt.io/product/development-tools)\n- [delta: A viewer for git and diff output](https://github.com/dandavison/delta)\n\n> [!TIP]\n> We highly recommend [Nextcloud development environment on Docker Compose](https://juliusknorr.github.io/nextcloud-docker-dev/) for testing/bug fixing/development.<br>\n> ‚ñ∂Ô∏è https://juliusknorr.github.io/nextcloud-docker-dev/\n\n1.3 Step by step instructions on how to build the client to contribute\n1. Clone the Github repository:\n```\ngit clone https://github.com/nextcloud/desktop.git\n```\n2. Create <build directory>:\n```\nmkdir <build directory>\n```\n3. Compile:\n```\ncd <build directory>\ncmake -S <cloned desktop repo> -B build -DCMAKE_PREFIX_PATH=<dependencies> -DCMAKE_BUILD_TYPE=Debug -DCMAKE_INSTALL_PREFIX=. -DNEXTCLOUD_DEV=ON\n```\n\n> [!TIP]\n> The cmake variable NEXTCLOUD_DEV allows you to run your own build of the client while developing in parallel with an installed version of the client.\n\n4. Build it:\n- Windows:\n```\ncmake --build .\n```\n- Other platforms:\n```\nmake\n```\n\n5. üêõ [Pick a good first issue](https://github.com/nextcloud/desktop/labels/good%20first%20issue)\n6. üë©‚Äçüîß Create a branch and make your changes. Remember to sign off your commits using `git commit -sm \"Your commit message\"`\n7. ‚¨Ü Create a [pull request](https://opensource.guide/how-to-contribute/#opening-a-pull-request) and `@mention` the people from the issue to review\n8. üëç Fix things that come up during a review\n9. üéâ Wait for it to get merged!\n\n## Get in touch üí¨\n* [üìã Forum](https://help.nextcloud.com)\n* [üë• Facebook](https://www.facebook.com/nextclouders)\n* [üê£ Twitter](https://twitter.com/Nextclouders)\n* [üêò Mastodon](https://mastodon.xyz/@nextcloud)\n\nYou can also [get support for Nextcloud](https://nextcloud.com/support)!\n\n## :scroll: License\n\n    This program is free software; you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation; either version 2 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful, but\n    WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY\n    or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License\n    for more details.\n",
      "stars_today": 4
    },
    {
      "id": 976095156,
      "name": "koog",
      "full_name": "JetBrains/koog",
      "description": "Koog is the official Kotlin framework for building predictable, fault-tolerant and enterprise-ready AI agents across all platforms ‚Äì from backend services to Android and iOS, JVM, and even in-browser environments. Koog is based on our AI products expertise and provides proven solutions for complex LLM and AI problems",
      "html_url": "https://github.com/JetBrains/koog",
      "stars": 3650,
      "forks": 303,
      "language": "Kotlin",
      "topics": [
        "agentframework",
        "agentic-ai",
        "agents",
        "ai",
        "ai-agents-framework",
        "aiagentframework",
        "android-ai",
        "anthropic",
        "genai",
        "generative-ai",
        "java",
        "jvm",
        "kotlin",
        "ktor",
        "llm",
        "mcp",
        "multi-agent-systems",
        "ollama",
        "openai",
        "spring"
      ],
      "created_at": "2025-05-01T13:38:01Z",
      "updated_at": "2026-01-23T18:22:05Z",
      "pushed_at": "2026-01-23T23:23:09Z",
      "open_issues": 206,
      "owner": {
        "login": "JetBrains",
        "avatar_url": "https://avatars.githubusercontent.com/u/878437?v=4"
      },
      "readme": "# Koog\n\n[![Kotlin Alpha](https://kotl.in/badges/alpha.svg)](https://kotlinlang.org/docs/components-stability.html)\n[![Maven Central](https://img.shields.io/maven-central/v/ai.koog/koog-agents)](https://search.maven.org/artifact/ai.koog/koog-agents)\n[![JetBrains incubator project](https://jb.gg/badges/incubator.svg)](https://github.com/JetBrains#jetbrains-on-github)\n[![Kotlin](https://img.shields.io/badge/kotlin-2.2-blue.svg?logo=kotlin)](http://kotlinlang.org)\n[![CI status](https://img.shields.io/github/checks-status/JetBrains/koog/main)](https://github.com/JetBrains/koog/actions?query=branch%3Amain)\n[![GitHub license](https://img.shields.io/github/license/JetBrains/koog)](LICENSE.txt)\n\nBuild status:\n\n[![Checks](https://github.com/JetBrains/koog/actions/workflows/checks.yml/badge.svg?branch=develop)](https://github.com/JetBrains/koog/actions/workflows/checks.yml?query=branch%3Adevelop)\n[![Heavy Tests](https://github.com/JetBrains/koog/actions/workflows/heavy-tests.yml/badge.svg?branch=develop)](https://github.com/JetBrains/koog/actions/workflows/heavy-tests.yml?query=branch%3Adevelop)\n[![Ollama Tests](https://github.com/JetBrains/koog/actions/workflows/ollama-tests.yml/badge.svg?branch=develop)](https://github.com/JetBrains/koog/actions/workflows/ollama-tests.yml?query=branch%3Adevelop)\n\nUseful links:\n\n* [Documentation](https://docs.koog.ai/)\n* [API reference](https://api.koog.ai/)\n* [Slack channel](https://docs.koog.ai/koog-slack-channel/)\n* [Issue tracker](https://youtrack.jetbrains.com/issues/KG)\n\n## Overview\n\nKoog is a Kotlin-based framework designed to build and run AI agents entirely in idiomatic Kotlin. It lets you create agents that can interact with tools, handle complex workflows, and communicate with users.\n\n### Key features\n\nKey features of Koog include:\n\n- **Multiplatform development**: Deploy agents across JVM, JS, WasmJS, Android, and iOS targets using Kotlin Multiplatform.\n- **Reliability and fault-tolerance**: Handle failures with built-in retries and restore the agent state at specific points during execution with the agent persistence feature.\n- **Intelligent history compression**: Optimize token usage while maintaining context in long-running conversations using advanced built-in history compression techniques.\n- **Enterprise-ready integrations**: Utilize integration with popular JVM frameworks such as Spring Boot and Ktor to embed Koog into your applications.\n- **Observability with OpenTelemetry exporters**: Monitor and debug applications with built-in support for popular observability providers (W&B Weave, Langfuse).\n- **LLM switching and seamless history adaptation**: Switch to a different LLM at any point without losing the existing conversation history, or reroute between multiple LLM providers.\n- **Integration with JVM and Kotlin applications**: Build AI agents with an idiomatic, type-safe Kotlin DSL designed specifically for JVM and Kotlin developers.\n- **Model Context Protocol integration**: Use Model Context Protocol (MCP) tools in AI agents.\n- **Agent Client Protocol integration**: Build ACP-compliant agents that can communicate with standardized client applications using the Agent Client Protocol (ACP).\n- **Knowledge retrieval and memory**: Retain and retrieve knowledge across conversations using vector embeddings, ranked document storage, and shared agent memory.\n- **Powerful Streaming API**: Process responses in real-time with streaming support and parallel tool calls.\n- **Modular feature system**: Customize agent capabilities through a composable architecture.\n- **Flexible graph workflows**: Design complex agent behaviors using intuitive graph-based workflows.\n- **Custom tool creation**: Enhance your agents with tools that access external systems and APIs.\n- **Comprehensive tracing**: Debug and monitor agent execution with detailed, configurable tracing.\n\n### Available LLM providers and platforms\n\nThe LLM providers and platforms whose LLMs you can use to power your agent capabilities:\n\n- Google\n- OpenAI\n- Anthropic\n- DeepSeek\n- OpenRouter\n- Ollama\n- Bedrock\n\n### Quickstart example\n\nTo help you get started with AI agents, here is a quick example:\n\n```kotlin\nfun main() = runBlocking {\n    // Before you run the example, assign a corresponding API key as an environment variable.\n   val apiKey = System.getenv(\"OPENAI_API_KEY\") // or Anthropic, Google, OpenRouter, etc.\n\n   val agent = AIAgent(\n      promptExecutor = simpleOpenAIExecutor(apiKey), // or Anthropic, Google, OpenRouter, etc.\n      systemPrompt = \"You are a helpful assistant. Answer user questions concisely.\",\n      llmModel = OpenAIModels.Chat.GPT4o\n   )\n\n   val result = agent.run(\"Hello! How can you help me?\")\n   println(result)\n}\n```\n\n## Using in your projects\n\n### Supported targets\n\nCurrently, the framework supports the JVM, JS, WasmJS and iOS targets.\n\n### Requirements\n\n- JDK 17 or higher is required to use the framework on JVM.\n- kotlinx-coroutines 1.10.2 and kotlinx-serialization 1.8.1 versions should be set explicitly in existing projects. Please check the [libs.versions.toml](gradle/libs.versions.toml) to know more about the Koog dependencies.\n\n### Gradle (Kotlin DSL)\n\n1. Add dependencies to the `build.gradle.kts` file:\n\n    ```\n    dependencies {\n        implementation(\"ai.koog:koog-agents:0.6.0\")\n    }\n    ```\n2. Make sure that you have `mavenCentral()` in the list of repositories.\n### Gradle (Groovy)\n\n1. Add dependencies to the `build.gradle` file:\n\n    ```\n    dependencies {\n        implementation 'ai.koog:koog-agents:0.6.0'\n    }\n    ```\n2. Make sure that you have `mavenCentral()` in the list of repositories.\n### Maven\n\n1. Add dependencies to the `pom.xml` file:\n\n    ```\n    <dependency>\n        <groupId>ai.koog</groupId>\n        <artifactId>koog-agents-jvm</artifactId>\n        <version>0.6.0</version>\n    </dependency>\n    ```\n2. Make sure that you have `mavenCentral` in the list of repositories.\n## Contributing\nRead the [Contributing Guidelines](CONTRIBUTING.md).\n\n## Code of Conduct\nThis project and the corresponding community are governed by the [JetBrains Open Source and Community Code of Conduct](https://github.com/jetbrains#code-of-conduct). Please make sure you read it.\n\n## License\nKoog is licensed under the [Apache 2.0 License](LICENSE.txt).\n\n## Support\n\nPlease feel free to ask any questions in our [official Slack\nchannel](https://docs.koog.ai/koog-slack-channel/) and to\nuse [Koog official YouTrack project](https://youtrack.jetbrains.com/issues/KG)\nfor filing feature requests and bug reports.\n\n\n",
      "stars_today": 4
    },
    {
      "id": 984809295,
      "name": "virtualbox",
      "full_name": "VirtualBox/virtualbox",
      "description": "Source code for Oracle VirtualBox",
      "html_url": "https://github.com/VirtualBox/virtualbox",
      "stars": 930,
      "forks": 110,
      "language": "C",
      "topics": [
        "emulation",
        "networking",
        "virtual-machine",
        "virtualbox",
        "virtualization",
        "vm"
      ],
      "created_at": "2025-05-16T14:41:57Z",
      "updated_at": "2026-01-23T09:44:59Z",
      "pushed_at": "2026-01-12T18:21:57Z",
      "open_issues": 267,
      "owner": {
        "login": "VirtualBox",
        "avatar_url": "https://avatars.githubusercontent.com/u/207759635?v=4"
      },
      "readme": "# Oracle VirtualBox\n\nVirtualBox is a general-purpose full virtualization software for x86_64\nhardware (with version 7.1 additionally for macOS/Arm), targeted at laptop,\ndesktop, server and embedded use.\n\nIt features a very user friendly graphical user interface and is available for\nmany popular operating systems (Linux, Windows, macOS and Solaris). Flexible\nnetworking setup and interactive performance are the strong points.\n\nAnyone with the need to run multiple operating systems simultaneously with some\nbasic knowledge about PCs and operating system installation can use it to\nreduce effort with a large number of tasks including software testing.\n\n## Getting started\n\nVirtualBox is a complex product with multiple dependencies, some of them\nspecific to the operating system on which you want to run it.\n\nThe basics for building VirtualBox are described on the [build\ninstructions](https://www.virtualbox.org/wiki/Build_instructions) page.\n\n## Documentation\n\nThe [VirtualBox User\nGuide](https://docs.oracle.com/en/virtualization/virtualbox/index.html)\ncontains all information relevant for users, including the product features and\ntheir configuration.\n\nFor developers it is recommended to start with the [technical\ndocumentation](https://www.virtualbox.org/wiki/Technical_documentation) which\ncontains links to a broad collection of pages related to development, covering\nmany aspects of the project and its features.\n\n## Examples\n\nTutorials on how to install and use Oracle VirtualBox are available at\n[Learn to Install Oracle VirtualBox and Run Virtual Machines](https://blogs.oracle.com/linux/post/learn-to-install-oracle-virtualbox-and-run-virtual-machines)\nand [Use Oracle VirtualBox on Oracle Linux](https://docs.oracle.com/en/learn/ol-vbox/index.html).\n\n## Help\n\nOracle customers with a support contract covering Oracle VirtualBox should\nreach out to [Oracle Support](https://www.oracle.com/support/).\n\nEveryone can use the [VirtualBox Forums](https://forums.virtualbox.org/)\nfor questions about the product or discussing its functionality. Open an [issue](https://github.com/VirtualBox/virtualbox/issues)\nfor bug reports or request for enhancements. Report a security vulnerability\naccording to the [Reporting Vulnerabilities Guide](https://www.oracle.com/corporate/security-practices/assurance/vulnerability/reporting.html).\n\n## Contributing\n\nThis project welcomes contributions from the community. Before submitting a\npull request, please [review our contribution guide](./CONTRIBUTING.md)\n\n## Security\n\nPlease consult the [security guide](./SECURITY.md) for our responsible security vulnerability disclosure process.\n\n## License\n\nThe correct copyright notice format for both documentation and software is\n\n    Copyright (C) [year-]year Oracle and/or its affiliates.\n\n    This file is part of VirtualBox base platform packages, as\n    available from https://www.virtualbox.org.\n\n    This program is free software; you can redistribute it and/or\n    modify it under the terms of the GNU General Public License\n    as published by the Free Software Foundation, in version 3 of the\n    License.\n\n    This program is distributed in the hope that it will be useful, but\n    WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n    General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program; if not, see <https://www.gnu.org/licenses>.\n\nYou must include the year the content was first released (on any platform) and\nthe most recent year in which it was revised:\n\n    Copyright (C) 2025 Oracle and/or its affiliates.\n\nReleased under the GNU General Public License v3.0 as shown at\n[COPYING](./COPYING) which contains clarifications regarding allowed licenses\nfor other code using parts of the project which are covered by multiple\nlicenses.\n\n",
      "stars_today": 4
    },
    {
      "id": 32538871,
      "name": "gson",
      "full_name": "google/gson",
      "description": "A Java serialization/deserialization library to convert Java Objects into JSON and back",
      "html_url": "https://github.com/google/gson",
      "stars": 24326,
      "forks": 4379,
      "language": "Java",
      "topics": [],
      "created_at": "2015-03-19T18:21:20Z",
      "updated_at": "2026-01-23T22:55:04Z",
      "pushed_at": "2026-01-12T14:45:55Z",
      "open_issues": 334,
      "owner": {
        "login": "google",
        "avatar_url": "https://avatars.githubusercontent.com/u/1342004?v=4"
      },
      "readme": "# Gson\n\nGson is a Java library that can be used to convert Java Objects into their JSON representation. It can also be used to convert a JSON string to an equivalent Java object.\nGson can work with arbitrary Java objects including pre-existing objects that you do not have source-code of.\n\nThere are a few open-source projects that can convert Java objects to JSON. However, most of them require that you place Java annotations in your classes; something that you can not do if you do not have access to the source-code. Most also do not fully support the use of Java Generics. Gson considers both of these as very important design goals.\n\n> [!NOTE]\\\n> Gson is currently in maintenance mode; existing bugs will be fixed, but large new features will likely not be added. If you want to add a new feature, please first search for existing GitHub issues, or create a new one to discuss the feature and get feedback.\n\n> [!IMPORTANT]\\\n> Gson's main focus is on Java. Using it with other JVM languages such as Kotlin or Scala might work fine in many cases, but language-specific features such as Kotlin's non-`null` types or constructors with default arguments are not supported. This can lead to confusing and incorrect behavior.\\\n> When using languages other than Java, prefer a JSON library with explicit support for that language.\n\n> [!IMPORTANT]\\\n> Gson is not a recommended library for interacting with JSON on Android. The open-ended reflection in the Gson runtime doesn't play nicely with shrinking/optimization/obfuscation passes that Android release apps should perform.\\\n> If your app or library may be running on Android, consider using [Kotlin Serialization](https://github.com/Kotlin/kotlinx.serialization/blob/master/docs/basic-serialization.md#basics) or [Moshi's Codegen](https://github.com/square/moshi?tab=readme-ov-file#codegen),\n> which use code generation instead of reflection. This avoids Gson's runtime crashes when optimizations are applied (usually due to the fields missing or being obfuscated), and results in faster performance on Android devices.\n> The Moshi APIs may be more familiar to users who already know Gson.\n> If you still want to use Gson and attempt to avoid these crashes, you can see how to do so [here](Troubleshooting.md#proguard-r8).\n\n### Goals\n  * Provide simple `toJson()` and `fromJson()` methods to convert Java objects to JSON and vice-versa\n  * Allow pre-existing unmodifiable objects to be converted to and from JSON\n  * Extensive support of Java Generics\n  * Allow custom representations for objects\n  * Support arbitrarily complex objects (with deep inheritance hierarchies and extensive use of generic types)\n\n### Download\n\nGradle:\n```gradle\ndependencies {\n  implementation 'com.google.code.gson:gson:2.13.2'\n}\n```\n\nMaven:\n```xml\n<dependency>\n  <groupId>com.google.code.gson</groupId>\n  <artifactId>gson</artifactId>\n  <version>2.13.2</version>\n</dependency>\n```\n\n[Gson jar downloads](https://maven-badges.herokuapp.com/maven-central/com.google.code.gson/gson) are available from Maven Central.\n\n![Build Status](https://github.com/google/gson/actions/workflows/build.yml/badge.svg)\n\n### Requirements\n#### Minimum Java version\n- Gson 2.12.0 and newer: Java 8\n- Gson 2.9.0 to 2.11.0: Java 7\n- Gson 2.8.9 and older: Java 6\n\nDespite supporting older Java versions, Gson also provides a JPMS module descriptor (module name `com.google.gson`) for users of Java 9 or newer.\n\n#### JPMS dependencies (Java 9+)\nThese are the optional Java Platform Module System (JPMS) JDK modules which Gson depends on.\nThis only applies when running Java 9 or newer.\n\n- `java.sql` (optional since Gson 2.8.9)\\\nWhen this module is present, Gson provides default adapters for some SQL date and time classes.\n\n- `jdk.unsupported`, respectively class `sun.misc.Unsafe` (optional)\\\nWhen this module is present, Gson can use the `Unsafe` class to create instances of classes without no-args constructor.\nHowever, care should be taken when relying on this. `Unsafe` is not available in all environments and its usage has some pitfalls,\nsee [`GsonBuilder.disableJdkUnsafe()`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#disableJdkUnsafe()).\n\n#### Minimum Android API level\n\n- Gson 2.11.0 and newer: API level 21\n- Gson 2.10.1 and older: API level 19\n\nOlder Gson versions may also support lower API levels, however this has not been verified.\n\n### Documentation\n  * [API Javadoc](https://www.javadoc.io/doc/com.google.code.gson/gson): Documentation for the current release\n  * [User guide](UserGuide.md): This guide contains examples on how to use Gson in your code\n  * [Troubleshooting guide](Troubleshooting.md): Describes how to solve common issues when using Gson\n  * [Releases and change log](https://github.com/google/gson/releases): Latest releases and changes in these versions; for older releases see [`CHANGELOG.md`](CHANGELOG.md)\n  * [Design document](GsonDesignDocument.md): This document discusses issues we faced while designing Gson. It also includes a comparison of Gson with other Java libraries that can be used for Json conversion\n\nPlease use the ['gson' tag on StackOverflow](https://stackoverflow.com/questions/tagged/gson), [GitHub Discussions](https://github.com/google/gson/discussions) or the [google-gson Google group](https://groups.google.com/group/google-gson) to discuss Gson or to post questions.\n\n### ProGuard / R8\n\nSee the details in the related section in the [Troubleshooting guide](Troubleshooting.md#proguard-r8).\n\n### Related Content Created by Third Parties\n  * [Gson Tutorial](https://www.studytrails.com/java/json/java-google-json-introduction/) by `StudyTrails`\n  * [Gson Tutorial Series](https://futurestud.io/tutorials/gson-getting-started-with-java-json-serialization-deserialization) by `Future Studio`\n  * [Gson API Report](https://abi-laboratory.pro/java/tracker/timeline/gson/)\n\n### Building\n\nGson uses Maven to build the project:\n```\nmvn clean verify\n```\n\nJDK 17 or newer is required for building, JDK 21 is recommended. Newer JDKs are currently not supported for building (but are supported when _using_ Gson).\n\n### Contributing\n\nSee the [contributing guide](https://github.com/google/.github/blob/master/CONTRIBUTING.md).\\\nPlease perform a quick search to check if there are already existing issues or pull requests related to your contribution.\n\nKeep in mind that Gson is in maintenance mode. If you want to add a new feature, please first search for existing GitHub issues, or create a new one to discuss the feature and get feedback.\n\n### License\n\nGson is released under the [Apache 2.0 license](LICENSE).\n\n```\nCopyright 2008 Google Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n### Disclaimer\n\nThis is not an officially supported Google product.\n",
      "stars_today": 3
    },
    {
      "id": 19438,
      "name": "ggplot2",
      "full_name": "tidyverse/ggplot2",
      "description": "An implementation of the Grammar of Graphics in R",
      "html_url": "https://github.com/tidyverse/ggplot2",
      "stars": 6868,
      "forks": 2116,
      "language": "R",
      "topics": [
        "data-visualisation",
        "r",
        "visualisation"
      ],
      "created_at": "2008-05-25T01:21:32Z",
      "updated_at": "2026-01-23T13:48:18Z",
      "pushed_at": "2025-12-18T13:22:01Z",
      "open_issues": 95,
      "owner": {
        "login": "tidyverse",
        "avatar_url": "https://avatars.githubusercontent.com/u/22032646?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# ggplot2 <a href=\"https://ggplot2.tidyverse.org\"><img src=\"man/figures/logo.png\" align=\"right\" height=\"138\" alt=\"ggplot2 website\" /></a>\n\n<!-- badges: start -->\n\n[![R-CMD-check](https://github.com/tidyverse/ggplot2/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/tidyverse/ggplot2/actions/workflows/R-CMD-check.yaml)\n[![CRAN_Status_Badge](https://www.r-pkg.org/badges/version/ggplot2)](https://cran.r-project.org/package=ggplot2)\n[![Codecov test\ncoverage](https://codecov.io/gh/tidyverse/ggplot2/graph/badge.svg)](https://app.codecov.io/gh/tidyverse/ggplot2)\n<!-- badges: end -->\n\n## Overview\n\nggplot2 is a system for declaratively creating graphics, based on [The\nGrammar of\nGraphics](https://link.springer.com/book/10.1007/0-387-28695-0). You\nprovide the data, tell ggplot2 how to map variables to aesthetics, what\ngraphical primitives to use, and it takes care of the details.\n\n## Installation\n\n``` r\n# The easiest way to get ggplot2 is to install the whole tidyverse:\ninstall.packages(\"tidyverse\")\n\n# Alternatively, install just ggplot2:\ninstall.packages(\"ggplot2\")\n\n# Or the development version from GitHub:\n# install.packages(\"pak\")\npak::pak(\"tidyverse/ggplot2\")\n```\n\n## Cheatsheet\n\n<a href=\"https://github.com/rstudio/cheatsheets/blob/main/data-visualization.pdf\"><img src=\"https://raw.githubusercontent.com/rstudio/cheatsheets/main/pngs/thumbnails/data-visualization-cheatsheet-thumbs.png\" width=\"630\" height=\"252\" alt=\"ggplot2 cheatsheet\" /></a>\n\n## Usage\n\nIt‚Äôs hard to succinctly describe how ggplot2 works because it embodies a\ndeep philosophy of visualisation. However, in most cases you start with\n`ggplot()`, supply a dataset and aesthetic mapping (with `aes()`). You\nthen add on layers (like `geom_point()` or `geom_histogram()`), scales\n(like `scale_colour_brewer()`), faceting specifications (like\n`facet_wrap()`) and coordinate systems (like `coord_flip()`).\n\n``` r\nlibrary(ggplot2)\n\nggplot(mpg, aes(displ, hwy, colour = class)) +\n  geom_point()\n```\n\n<img src=\"man/figures/README-example-1.png\" alt=\"Scatterplot of engine displacement versus highway miles per gallon, for 234 cars coloured by 7 'types' of car. The displacement and miles per gallon are inversely correlated.\"  />\n\n## Lifecycle\n\n[![lifecycle](https://img.shields.io/badge/lifecycle-stable-brightgreen.svg)](https://lifecycle.r-lib.org/articles/stages.html)\n\nggplot2 is now 18 years old and is used by hundreds of thousands of\npeople to make millions of plots. That means, by-and-large, ggplot2\nitself changes relatively little. When we do make changes, they will be\ngenerally to add new functions or arguments rather than changing the\nbehaviour of existing functions, and if we do make changes to existing\nbehaviour we will do them for compelling reasons.\n\nIf you are looking for innovation, look to ggplot2‚Äôs rich ecosystem of\nextensions. See a community maintained list at\n<https://exts.ggplot2.tidyverse.org/gallery/>.\n\n## Learning ggplot2\n\nIf you are new to ggplot2 you are better off starting with a systematic\nintroduction, rather than trying to learn from reading individual\ndocumentation pages. Currently, there are several good places to start:\n\n1.  The [Data Visualization](https://r4ds.hadley.nz/data-visualize) and\n    [Communication](https://r4ds.hadley.nz/communication) chapters in [R\n    for Data Science](https://r4ds.hadley.nz). R for Data Science is\n    designed to give you a comprehensive introduction to the\n    [tidyverse](https://tidyverse.org/), and these two chapters will get\n    you up to speed with the essentials of ggplot2 as quickly as\n    possible.\n\n2.  If you‚Äôd like to take an online course, try [Data Visualization in R\n    With\n    ggplot2](https://learning.oreilly.com/videos/data-visualization-in/9781491963661/)\n    by Kara Woo.\n\n3.  If you‚Äôd like to follow a webinar, try [Plotting Anything with\n    ggplot2](https://youtu.be/h29g21z0a68) by Thomas Lin Pedersen.\n\n4.  If you want to dive into making common graphics as quickly as\n    possible, I recommend [The R Graphics\n    Cookbook](https://r-graphics.org) by Winston Chang. It provides a\n    set of recipes to solve common graphics problems.\n\n5.  If you‚Äôve mastered the basics and want to learn more, read [ggplot2:\n    Elegant Graphics for Data Analysis](https://ggplot2-book.org). It\n    describes the theoretical underpinnings of ggplot2 and shows you how\n    all the pieces fit together. This book helps you understand the\n    theory that underpins ggplot2, and will help you create new types of\n    graphics specifically tailored to your needs.\n\n6.  For articles about announcements and deep-dives you can visit the\n    [tidyverse blog](https://tidyverse.org/tags/ggplot2/).\n\n## Getting help\n\nThere are two main places to get help with ggplot2:\n\n1.  The [Posit Community](https://forum.posit.co/) (formerly RStudio\n    Community) is a friendly place to ask any questions about ggplot2.\n\n2.  [Stack\n    Overflow](https://stackoverflow.com/questions/tagged/ggplot2?sort=frequent&pageSize=50)\n    is a great source of answers to common ggplot2 questions. It is also\n    a great place to get help, once you have created a reproducible\n    example that illustrates your problem.\n",
      "stars_today": 3
    },
    {
      "id": 4729944,
      "name": "shiny",
      "full_name": "rstudio/shiny",
      "description": "Easy interactive web applications with R",
      "html_url": "https://github.com/rstudio/shiny",
      "stars": 5593,
      "forks": 1881,
      "language": "R",
      "topics": [
        "r",
        "reactive",
        "rstudio",
        "shiny",
        "web-app",
        "web-development"
      ],
      "created_at": "2012-06-20T18:45:11Z",
      "updated_at": "2026-01-23T15:48:17Z",
      "pushed_at": "2026-01-12T16:26:11Z",
      "open_issues": 870,
      "owner": {
        "login": "rstudio",
        "avatar_url": "https://avatars.githubusercontent.com/u/513560?v=4"
      },
      "readme": "# shiny <img src=\"man/figures/logo.png\" align=\"right\" width=120 height=139 alt=\"\" />\n\n<!-- badges: start -->\n[![CRAN](https://www.r-pkg.org/badges/version/shiny)](https://CRAN.R-project.org/package=shiny)\n[![R build status](https://github.com/rstudio/shiny/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/rstudio/shiny/actions)\n[![RStudio community](https://img.shields.io/badge/community-shiny-blue?style=social&logo=rstudio&logoColor=75AADB)](https://forum.posit.co/new-topic?category=shiny&tags=shiny)\n\n<!-- badges: end -->\n\nEasily build rich and productive interactive web apps in R &mdash; no HTML/CSS/JavaScript required.\n\n## Features\n\n* An intuitive and extensible [reactive programming](https://en.wikipedia.org/wiki/Reactive_programming) model which makes it easy to transform existing R code into a \"live app\" where outputs automatically react to new user input.\n  * Compared to event-based programming, reactivity allows Shiny to do the minimum amount of work when input(s) change, and allows humans to more easily reason about complex [MVC logic](https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller).\n* A prebuilt set of highly sophisticated, customizable, and easy-to-use widgets (e.g., plots, tables, sliders, dropdowns, date pickers, and more).\n* An attractive default look based on [Bootstrap](https://getbootstrap.com/) which can also be easily customized with the [bslib](https://github.com/rstudio/bslib) package or avoided entirely with more direct R bindings to HTML/CSS/JavaScript.\n* Seamless integration with [R Markdown](https://shiny.rstudio.com/articles/interactive-docs.html), making it easy to embed numerous applications natively within a larger dynamic document.\n* Tools for improving and monitoring performance, including native support for [async programming](https://posit.co/blog/shiny-1-1-0/), [caching](https://talks.cpsievert.me/20201117), [load testing](https://rstudio.github.io/shinyloadtest/), and more.\n* [Modules](https://shiny.rstudio.com/articles/modules.html): a framework for reducing code duplication and complexity.\n* An ability to [bookmark application state](https://shiny.rstudio.com/articles/bookmarking-state.html) and/or [generate code to reproduce output(s)](https://github.com/rstudio/shinymeta).\n* A rich ecosystem of extension packages for more [custom widgets](http://www.htmlwidgets.org/), [input validation](https://github.com/rstudio/shinyvalidate), [unit testing](https://github.com/rstudio/shinytest), and more.\n\n## Installation\n\nTo install the stable version from CRAN:\n\n```r\ninstall.packages(\"shiny\")\n```\n\n## Getting Started\n\nOnce installed, load the library and run an example:\n\n```r\nlibrary(shiny)\n# Launches an app, with the app's source code included\nrunExample(\"06_tabsets\")\n# Lists more prepackaged examples\nrunExample()\n```\n\nFor more examples and inspiration, check out the [Shiny User Gallery](https://shiny.rstudio.com/gallery/).\n\nFor help with learning fundamental Shiny programming concepts, check out the [Mastering Shiny](https://mastering-shiny.org/) book and the [Shiny Tutorial](https://shiny.rstudio.com/tutorial/). The former is currently more up-to-date with modern Shiny features, whereas the latter takes a deeper, more visual, dive into fundamental concepts.\n\n## Join the conversation\n\nIf you want to chat about Shiny, meet other developers, or help us decide what to work on next, [join us on Discord](https://discord.com/invite/yMGCamUMnS).\n\n## Getting Help\n\nTo ask a question about Shiny, please use the [RStudio Community website](https://forum.posit.co/new-topic?category=shiny&tags=shiny).\n\nFor bug reports, please use the [issue tracker](https://github.com/rstudio/shiny/issues) and also keep in mind that by [writing a good bug report](https://github.com/rstudio/shiny/wiki/Writing-Good-Bug-Reports), you're more likely to get help with your problem.\n\n## Contributing\n\nWe welcome contributions to the **shiny** package. Please see our [CONTRIBUTING.md](https://github.com/rstudio/shiny/blob/main/.github/CONTRIBUTING.md) file for detailed guidelines of how to contribute.\n\n## License\n\nThe shiny package as a whole is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.\n\n## R version support\n\nShiny is supported on the latest release version of R, as well as the previous four minor release versions of R. For example, if the latest release R version is 4.3, then that version is supported, as well as 4.2, 4.1, 4.0, 3.6.\n",
      "stars_today": 3
    },
    {
      "id": 28463126,
      "name": "KeychainAccess",
      "full_name": "kishikawakatsumi/KeychainAccess",
      "description": "Simple Swift wrapper for Keychain that works on iOS, watchOS, tvOS and macOS.",
      "html_url": "https://github.com/kishikawakatsumi/KeychainAccess",
      "stars": 8230,
      "forks": 830,
      "language": "Swift",
      "topics": [
        "keychain",
        "security",
        "touch-id"
      ],
      "created_at": "2014-12-24T22:04:11Z",
      "updated_at": "2026-01-24T01:40:56Z",
      "pushed_at": "2024-05-31T12:29:46Z",
      "open_issues": 54,
      "owner": {
        "login": "kishikawakatsumi",
        "avatar_url": "https://avatars.githubusercontent.com/u/40610?v=4"
      },
      "readme": "# KeychainAccess\n\n[![Build Status](https://travis-ci.com/kishikawakatsumi/KeychainAccess.svg?branch=master)](https://travis-ci.com/kishikawakatsumi/KeychainAccess)\n[![Carthage compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat)](https://github.com/Carthage/Carthage)\n[![SPM supported](https://img.shields.io/badge/SPM-supported-DE5C43.svg?style=flat)](https://swift.org/package-manager)\n[![Version](https://img.shields.io/cocoapods/v/KeychainAccess.svg)](http://cocoadocs.org/docsets/KeychainAccess)\n[![Platform](https://img.shields.io/cocoapods/p/KeychainAccess.svg)](http://cocoadocs.org/docsets/KeychainAccess)\n\nKeychainAccess is a simple Swift wrapper for Keychain that works on iOS and macOS. Makes using Keychain APIs extremely easy and much more palatable to use in Swift.\n\n<img src=\"https://github.com/kishikawakatsumi/KeychainAccess/assets/40610/4de4aae1-6fc1-4477-af6d-afbe6d164da0\" width=\"320px\" /> <img src=\"https://github.com/kishikawakatsumi/KeychainAccess/assets/40610/2980ea84-862b-4067-b9b7-90de629171b9\" width=\"320px\" />\n<img src=\"https://github.com/kishikawakatsumi/KeychainAccess/assets/40610/3299347d-eb1b-446c-921c-778fa493f818\" width=\"320px\" />\n\n## :bulb: Features\n\n- Simple interface\n- Support access group\n- [Support accessibility](#accessibility)\n- [Support iCloud sharing](#icloud_sharing)\n- **[Support TouchID and Keychain integration (iOS 8+)](#touch_id_integration)**\n- **[Support Shared Web Credentials (iOS 8+)](#shared_web_credentials)**\n- [Works on both iOS & macOS](#requirements)\n- [watchOS and tvOS are supported](#requirements)\n- **[Mac Catalyst is supported](#requirements)**\n- **[Swift 3, 4 and 5 compatible](#requirements)**\n\n## :book: Usage\n\n##### :eyes: See also:\n\n- [:link: iOS Example Project](https://github.com/kishikawakatsumi/KeychainAccess/tree/master/Examples/Example-iOS)\n\n### :key: Basics\n\n#### Saving Application Password\n\n```swift\nlet keychain = Keychain(service: \"com.example.github-token\")\nkeychain[\"kishikawakatsumi\"] = \"01234567-89ab-cdef-0123-456789abcdef\"\n```\n\n#### Saving Internet Password\n\n```swift\nlet keychain = Keychain(server: \"https://github.com\", protocolType: .https)\nkeychain[\"kishikawakatsumi\"] = \"01234567-89ab-cdef-0123-456789abcdef\"\n```\n\n### :key: Instantiation\n\n#### Create Keychain for Application Password\n\n```swift\nlet keychain = Keychain(service: \"com.example.github-token\")\n```\n\n```swift\nlet keychain = Keychain(service: \"com.example.github-token\", accessGroup: \"12ABCD3E4F.shared\")\n```\n\n#### Create Keychain for Internet Password\n\n```swift\nlet keychain = Keychain(server: \"https://github.com\", protocolType: .https)\n```\n\n```swift\nlet keychain = Keychain(server: \"https://github.com\", protocolType: .https, authenticationType: .htmlForm)\n```\n\n### :key: Adding an item\n\n#### subscripting\n\n##### for String\n\n```swift\nkeychain[\"kishikawakatsumi\"] = \"01234567-89ab-cdef-0123-456789abcdef\"\n```\n\n```swift\nkeychain[string: \"kishikawakatsumi\"] = \"01234567-89ab-cdef-0123-456789abcdef\"\n```\n\n##### for NSData\n\n```swift\nkeychain[data: \"secret\"] = NSData(contentsOfFile: \"secret.bin\")\n```\n\n#### set method\n\n```swift\nkeychain.set(\"01234567-89ab-cdef-0123-456789abcdef\", key: \"kishikawakatsumi\")\n```\n\n#### error handling\n\n```swift\ndo {\n    try keychain.set(\"01234567-89ab-cdef-0123-456789abcdef\", key: \"kishikawakatsumi\")\n}\ncatch let error {\n    print(error)\n}\n```\n\n### :key: Obtaining an item\n\n#### subscripting\n\n##### for String (If the value is NSData, attempt to convert to String)\n\n```swift\nlet token = keychain[\"kishikawakatsumi\"]\n```\n\n```swift\nlet token = keychain[string: \"kishikawakatsumi\"]\n```\n\n##### for NSData\n\n```swift\nlet secretData = keychain[data: \"secret\"]\n```\n\n#### get methods\n\n##### as String\n\n```swift\nlet token = try? keychain.get(\"kishikawakatsumi\")\n```\n\n```swift\nlet token = try? keychain.getString(\"kishikawakatsumi\")\n```\n\n##### as NSData\n\n```swift\nlet data = try? keychain.getData(\"kishikawakatsumi\")\n```\n\n### :key: Removing an item\n\n#### subscripting\n\n```swift\nkeychain[\"kishikawakatsumi\"] = nil\n```\n\n#### remove method\n\n```swift\ndo {\n    try keychain.remove(\"kishikawakatsumi\")\n} catch let error {\n    print(\"error: \\(error)\")\n}\n```\n\n### :key: Set Label and Comment\n\n```swift\nlet keychain = Keychain(server: \"https://github.com\", protocolType: .https)\ndo {\n    try keychain\n        .label(\"github.com (kishikawakatsumi)\")\n        .comment(\"github access token\")\n        .set(\"01234567-89ab-cdef-0123-456789abcdef\", key: \"kishikawakatsumi\")\n} catch let error {\n    print(\"error: \\(error)\")\n}\n```\n\n### :key: Obtaining Other Attributes\n\n#### PersistentRef\n\n```swift\nlet keychain = Keychain()\nlet persistentRef = keychain[attributes: \"kishikawakatsumi\"]?.persistentRef\n...\n```\n\n#### Creation Date\n\n```swift\nlet keychain = Keychain()\nlet creationDate = keychain[attributes: \"kishikawakatsumi\"]?.creationDate\n...\n```\n\n#### All Attributes\n\n```swift\nlet keychain = Keychain()\ndo {\n    let attributes = try keychain.get(\"kishikawakatsumi\") { $0 }\n    print(attributes?.comment)\n    print(attributes?.label)\n    print(attributes?.creator)\n    ...\n} catch let error {\n    print(\"error: \\(error)\")\n}\n```\n\n##### subscripting\n\n```swift\nlet keychain = Keychain()\nif let attributes = keychain[attributes: \"kishikawakatsumi\"] {\n    print(attributes.comment)\n    print(attributes.label)\n    print(attributes.creator)\n}\n```\n\n### :key: Configuration (Accessibility, Sharing, iCloud Sync)\n\n**Provides fluent interfaces**\n\n```swift\nlet keychain = Keychain(service: \"com.example.github-token\")\n    .label(\"github.com (kishikawakatsumi)\")\n    .synchronizable(true)\n    .accessibility(.afterFirstUnlock)\n```\n\n#### <a name=\"accessibility\"> Accessibility\n\n##### Default accessibility matches background application (=kSecAttrAccessibleAfterFirstUnlock)\n\n```swift\nlet keychain = Keychain(service: \"com.example.github-token\")\n```\n\n##### For background application\n\n###### Creating instance\n\n```swift\nlet keychain = Keychain(service: \"com.example.github-token\")\n    .accessibility(.afterFirstUnlock)\n\nkeychain[\"kishikawakatsumi\"] = \"01234567-89ab-cdef-0123-456789abcdef\"\n```\n\n###### One-shot\n\n```swift\nlet keychain = Keychain(service: \"com.example.github-token\")\n\ndo {\n    try keychain\n        .accessibility(.afterFirstUnlock)\n        .set(\"01234567-89ab-cdef-0123-456789abcdef\", key: \"kishikawakatsumi\")\n} catch let error {\n    print(\"error: \\(error)\")\n}\n```\n\n##### For foreground application\n\n###### Creating instance\n\n```swift\nlet keychain = Keychain(service: \"com.example.github-token\")\n    .accessibility(.whenUnlocked)\n\nkeychain[\"kishikawakatsumi\"] = \"01234567-89ab-cdef-0123-456789abcdef\"\n```\n\n###### One-shot\n\n```swift\nlet keychain = Keychain(service: \"com.example.github-token\")\n\ndo {\n    try keychain\n        .accessibility(.whenUnlocked)\n        .set(\"01234567-89ab-cdef-0123-456789abcdef\", key: \"kishikawakatsumi\")\n} catch let error {\n    print(\"error: \\(error)\")\n}\n```\n\n#### :couple: Sharing Keychain items\n\n```swift\nlet keychain = Keychain(service: \"com.example.github-token\", accessGroup: \"12ABCD3E4F.shared\")\n```\n\n#### <a name=\"icloud_sharing\"> :arrows_counterclockwise: Synchronizing Keychain items with iCloud\n\n###### Creating instance\n\n```swift\nlet keychain = Keychain(service: \"com.example.github-token\")\n    .synchronizable(true)\n\nkeychain[\"kishikawakatsumi\"] = \"01234567-89ab-cdef-0123-456789abcdef\"\n```\n\n###### One-shot\n\n```swift\nlet keychain = Keychain(service: \"com.example.github-token\")\n\ndo {\n    try keychain\n        .synchronizable(true)\n        .set(\"01234567-89ab-cdef-0123-456789abcdef\", key: \"kishikawakatsumi\")\n} catch let error {\n    print(\"error: \\(error)\")\n}\n```\n\n### <a name=\"touch_id_integration\"> :cyclone: Touch ID (Face ID) integration\n\n**Any Operation that require authentication must be run in the background thread.**  \n**If you run in the main thread, UI thread will lock for the system to try to display the authentication dialog.**\n\n**To use Face ID, add `NSFaceIDUsageDescription` key to your `Info.plist`**\n\n#### :closed_lock_with_key: Adding a Touch ID (Face ID) protected item\n\nIf you want to store the Touch ID protected Keychain item, specify `accessibility` and `authenticationPolicy` attributes.\n\n```swift\nlet keychain = Keychain(service: \"com.example.github-token\")\n\nDispatchQueue.global().async {\n    do {\n        // Should be the secret invalidated when passcode is removed? If not then use `.WhenUnlocked`\n        try keychain\n            .accessibility(.whenPasscodeSetThisDeviceOnly, authenticationPolicy: [.biometryAny])\n            .set(\"01234567-89ab-cdef-0123-456789abcdef\", key: \"kishikawakatsumi\")\n    } catch let error {\n        // Error handling if needed...\n    }\n}\n```\n\n#### :closed_lock_with_key: Updating a Touch ID (Face ID) protected item\n\nThe same way as when adding.\n\n**Do not run in the main thread if there is a possibility that the item you are trying to add already exists, and protected.**\n**Because updating protected items requires authentication.**\n\nAdditionally, you want to show custom authentication prompt message when updating, specify an `authenticationPrompt` attribute.\nIf the item not protected, the `authenticationPrompt` parameter just be ignored.\n\n```swift\nlet keychain = Keychain(service: \"com.example.github-token\")\n\nDispatchQueue.global().async {\n    do {\n        // Should be the secret invalidated when passcode is removed? If not then use `.WhenUnlocked`\n        try keychain\n            .accessibility(.whenPasscodeSetThisDeviceOnly, authenticationPolicy: [.biometryAny])\n            .authenticationPrompt(\"Authenticate to update your access token\")\n            .set(\"01234567-89ab-cdef-0123-456789abcdef\", key: \"kishikawakatsumi\")\n    } catch let error {\n        // Error handling if needed...\n    }\n}\n```\n\n#### :closed_lock_with_key: Obtaining a Touch ID (Face ID) protected item\n\nThe same way as when you get a normal item. It will be displayed automatically Touch ID or passcode authentication If the item you try to get is protected.  \nIf you want to show custom authentication prompt message, specify an `authenticationPrompt` attribute.\nIf the item not protected, the `authenticationPrompt` parameter just be ignored.\n\n```swift\nlet keychain = Keychain(service: \"com.example.github-token\")\n\nDispatchQueue.global().async {\n    do {\n        let password = try keychain\n            .authenticationPrompt(\"Authenticate to login to server\")\n            .get(\"kishikawakatsumi\")\n\n        print(\"password: \\(password)\")\n    } catch let error {\n        // Error handling if needed...\n    }\n}\n```\n\n#### :closed_lock_with_key: Removing a Touch ID (Face ID) protected item\n\nThe same way as when you remove a normal item.\nThere is no way to show Touch ID or passcode authentication when removing Keychain items.\n\n```swift\nlet keychain = Keychain(service: \"com.example.github-token\")\n\ndo {\n    try keychain.remove(\"kishikawakatsumi\")\n} catch let error {\n    // Error handling if needed...\n}\n```\n\n### <a name=\"shared_web_credentials\"> :key: Shared Web Credentials\n\n> Shared web credentials is a programming interface that enables native iOS apps to share credentials with their website counterparts. For example, a user may log in to a website in Safari, entering a user name and password, and save those credentials using the iCloud Keychain. Later, the user may run a native app from the same developer, and instead of the app requiring the user to reenter a user name and password, shared web credentials gives it access to the credentials that were entered earlier in Safari. The user can also create new accounts, update passwords, or delete her account from within the app. These changes are then saved and used by Safari.  \n> <https://developer.apple.com/library/ios/documentation/Security/Reference/SharedWebCredentialsRef/>\n\n```swift\nlet keychain = Keychain(server: \"https://www.kishikawakatsumi.com\", protocolType: .HTTPS)\n\nlet username = \"kishikawakatsumi@mac.com\"\n\n// First, check the credential in the app's Keychain\nif let password = try? keychain.get(username) {\n    // If found password in the Keychain,\n    // then log into the server\n} else {\n    // If not found password in the Keychain,\n    // try to read from Shared Web Credentials\n    keychain.getSharedPassword(username) { (password, error) -> () in\n        if password != nil {\n            // If found password in the Shared Web Credentials,\n            // then log into the server\n            // and save the password to the Keychain\n\n            keychain[username] = password\n        } else {\n            // If not found password either in the Keychain also Shared Web Credentials,\n            // prompt for username and password\n\n            // Log into server\n\n            // If the login is successful,\n            // save the credentials to both the Keychain and the Shared Web Credentials.\n\n            keychain[username] = inputPassword\n            keychain.setSharedPassword(inputPassword, account: username)\n        }\n    }\n}\n```\n\n#### Request all associated domain's credentials\n\n```swift\nKeychain.requestSharedWebCredential { (credentials, error) -> () in\n\n}\n```\n\n#### Generate strong random password\n\nGenerate strong random password that is in the same format used by Safari autofill (xxx-xxx-xxx-xxx).\n\n```swift\nlet password = Keychain.generatePassword() // => Nhu-GKm-s3n-pMx\n```\n\n#### How to set up Shared Web Credentials\n\n> 1. Add a com.apple.developer.associated-domains entitlement to your app. This entitlement must include all the domains with which you want to share credentials.\n>\n> 2. Add an apple-app-site-association file to your website. This file must include application identifiers for all the apps with which the site wants to share credentials, and it must be properly signed.\n>\n> 3. When the app is installed, the system downloads and verifies the site association file for each of its associated domains. If the verification is successful, the app is associated with the domain.\n\n**More details:**  \n<https://developer.apple.com/library/ios/documentation/Security/Reference/SharedWebCredentialsRef/>\n\n### :mag: Debugging\n\n#### Display all stored items if print keychain object\n\n```swift\nlet keychain = Keychain(server: \"https://github.com\", protocolType: .https)\nprint(\"\\(keychain)\")\n```\n\n```\n=>\n[\n  [authenticationType: default, key: kishikawakatsumi, server: github.com, class: internetPassword, protocol: https]\n  [authenticationType: default, key: hirohamada, server: github.com, class: internetPassword, protocol: https]\n  [authenticationType: default, key: honeylemon, server: github.com, class: internetPassword, protocol: https]\n]\n```\n\n#### Obtaining all stored keys\n\n```swift\nlet keychain = Keychain(server: \"https://github.com\", protocolType: .https)\n\nlet keys = keychain.allKeys()\nfor key in keys {\n  print(\"key: \\(key)\")\n}\n```\n\n```\n=>\nkey: kishikawakatsumi\nkey: hirohamada\nkey: honeylemon\n```\n\n#### Obtaining all stored items\n\n```swift\nlet keychain = Keychain(server: \"https://github.com\", protocolType: .https)\n\nlet items = keychain.allItems()\nfor item in items {\n  print(\"item: \\(item)\")\n}\n```\n\n```\n=>\nitem: [authenticationType: Default, key: kishikawakatsumi, server: github.com, class: InternetPassword, protocol: https]\nitem: [authenticationType: Default, key: hirohamada, server: github.com, class: InternetPassword, protocol: https]\nitem: [authenticationType: Default, key: honeylemon, server: github.com, class: InternetPassword, protocol: https]\n```\n\n## Keychain sharing capability\n\nIf you encounter the error below, you need to add an `Keychain.entitlements`.\n\n```\nOSStatus error:[-34018] Internal error when a required entitlement isn't present, client has neither application-identifier nor keychain-access-groups entitlements.\n```\n\n<img alt=\"Screen Shot 2019-10-27 at 8 08 50\" src=\"https://user-images.githubusercontent.com/40610/67627108-1a7f2f80-f891-11e9-97bc-7f7313cb63d1.png\" width=\"500\">\n\n<img src=\"https://user-images.githubusercontent.com/40610/67627072-333b1580-f890-11e9-9feb-bf507abc2724.png\" width=\"500\" />\n\n## Requirements\n\n|            | OS                                                         | Swift              |\n| ---------- | ---------------------------------------------------------- | ------------------ |\n| **v1.1.x** | iOS 7+, macOS 10.9+                                        | 1.1                |\n| **v1.2.x** | iOS 7+, macOS 10.9+                                        | 1.2                |\n| **v2.0.x** | iOS 7+, macOS 10.9+, watchOS 2+                            | 2.0                |\n| **v2.1.x** | iOS 7+, macOS 10.9+, watchOS 2+                            | 2.0                |\n| **v2.2.x** | iOS 8+, macOS 10.9+, watchOS 2+, tvOS 9+                   | 2.0, 2.1           |\n| **v2.3.x** | iOS 8+, macOS 10.9+, watchOS 2+, tvOS 9+                   | 2.0, 2.1, 2.2      |\n| **v2.4.x** | iOS 8+, macOS 10.9+, watchOS 2+, tvOS 9+                   | 2.2, 2.3           |\n| **v3.0.x** | iOS 8+, macOS 10.9+, watchOS 2+, tvOS 9+                   | 3.x                |\n| **v3.1.x** | iOS 8+, macOS 10.9+, watchOS 2+, tvOS 9+                   | 4.0, 4.1, 4.2      |\n| **v3.2.x** | iOS 8+, macOS 10.9+, watchOS 2+, tvOS 9+                   | 4.0, 4.1, 4.2, 5.0 |\n| **v4.0.x** | iOS 8+, macOS 10.9+, watchOS 2+, tvOS 9+                   | 4.0, 4.1, 4.2, 5.1 |\n| **v4.1.x** | iOS 8+, macOS 10.9+, watchOS 3+, tvOS 9+, Mac Catalyst 13+ | 4.0, 4.1, 4.2, 5.1 |\n\n## Installation\n\n### CocoaPods\n\nKeychainAccess is available through [CocoaPods](http://cocoapods.org). To install\nit, simply add the following lines to your Podfile:\n\n```ruby\nuse_frameworks!\npod 'KeychainAccess'\n```\n\n### Carthage\n\nKeychainAccess is available through [Carthage](https://github.com/Carthage/Carthage). To install\nit, simply add the following line to your Cartfile:\n\n`github \"kishikawakatsumi/KeychainAccess\"`\n\n### Swift Package Manager\n\nKeychainAccess is also available through [Swift Package Manager](https://github.com/apple/swift-package-manager/).\n\n#### Xcode\n\nSelect `File > Add Packages... > Add Package Dependency...`,\n\n<img src=\"https://user-images.githubusercontent.com/40610/67627000-2833b580-f88f-11e9-89ef-18819b1a6c67.png\" width=\"800px\" />\n\n#### CLI\n\nFirst, create `Package.swift` that its package declaration includes:\n\n```swift\n// swift-tools-version:5.0\nimport PackageDescription\n\nlet package = Package(\n    name: \"MyLibrary\",\n    products: [\n        .library(name: \"MyLibrary\", targets: [\"MyLibrary\"]),\n    ],\n    dependencies: [\n        .package(url: \"https://github.com/kishikawakatsumi/KeychainAccess.git\", from: \"3.0.0\"),\n    ],\n    targets: [\n        .target(name: \"MyLibrary\", dependencies: [\"KeychainAccess\"]),\n    ]\n)\n```\n\nThen, type\n\n```shell\n$ swift build\n```\n\n### To manually add to your project\n\n1. Add `Lib/KeychainAccess.xcodeproj` to your project\n2. Link `KeychainAccess.framework` with your target\n3. Add `Copy Files Build Phase` to include the framework to your application bundle\n\n_See [iOS Example Project](https://github.com/kishikawakatsumi/KeychainAccess/tree/master/Examples/Example-iOS) as reference._\n\n<img src=\"https://github.com/kishikawakatsumi/KeychainAccess/assets/40610/b7a46cfb-714d-47d5-84ea-6a80f640e03d\" width=\"800px\" />\n\n## Author\n\nkishikawa katsumi, kishikawakatsumi@mac.com\n\n## License\n\nKeychainAccess is available under the MIT license. See the LICENSE file for more info.\n",
      "stars_today": 3
    },
    {
      "id": 6427813,
      "name": "dplyr",
      "full_name": "tidyverse/dplyr",
      "description": "dplyr: A grammar of data manipulation",
      "html_url": "https://github.com/tidyverse/dplyr",
      "stars": 4988,
      "forks": 2130,
      "language": "R",
      "topics": [
        "data-manipulation",
        "grammar",
        "r"
      ],
      "created_at": "2012-10-28T13:39:17Z",
      "updated_at": "2026-01-23T19:34:00Z",
      "pushed_at": "2026-01-23T19:33:54Z",
      "open_issues": 76,
      "owner": {
        "login": "tidyverse",
        "avatar_url": "https://avatars.githubusercontent.com/u/22032646?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# dplyr <a href=\"https://dplyr.tidyverse.org\"><img src=\"man/figures/logo.png\" align=\"right\" height=\"138\" /></a>\n\n<!-- badges: start -->\n\n[![CRAN\nstatus](https://www.r-pkg.org/badges/version/dplyr)](https://cran.r-project.org/package=dplyr)\n[![R-CMD-check](https://github.com/tidyverse/dplyr/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/tidyverse/dplyr/actions/workflows/R-CMD-check.yaml)\n[![Codecov test\ncoverage](https://codecov.io/gh/tidyverse/dplyr/graph/badge.svg)](https://app.codecov.io/gh/tidyverse/dplyr)\n<!-- badges: end -->\n\n## Overview\n\ndplyr is a grammar of data manipulation, providing a consistent set of\nverbs that help you solve the most common data manipulation challenges:\n\n- `mutate()` adds new variables that are functions of existing variables\n- `select()` picks variables based on their names.\n- `filter()` picks cases based on their values.\n- `summarise()` reduces multiple values down to a single summary.\n- `arrange()` changes the ordering of the rows.\n\nThese all combine naturally with `group_by()` which allows you to\nperform any operation ‚Äúby group‚Äù. You can learn more about them in\n`vignette(\"dplyr\")`. As well as these single-table verbs, dplyr also\nprovides a variety of two-table verbs, which you can learn about in\n`vignette(\"two-table\")`.\n\nIf you are new to dplyr, the best place to start is the [data\ntransformation chapter](https://r4ds.hadley.nz/data-transform) in R for\nData Science.\n\n## Backends\n\nIn addition to data frames/tibbles, dplyr makes working with other\ncomputational backends accessible and efficient. Below is a list of\nalternative backends:\n\n- [arrow](https://arrow.apache.org/docs/r/) for larger-than-memory\n  datasets, including on remote cloud storage like AWS S3, using the\n  Apache Arrow C++ engine,\n  [Acero](https://arrow.apache.org/docs/cpp/acero/overview.html).\n\n- [dbplyr](https://dbplyr.tidyverse.org/) for data stored in a\n  relational database. Translates your dplyr code to SQL.\n\n- [dtplyr](https://dtplyr.tidyverse.org/) for large, in-memory datasets.\n  Translates your dplyr code to high performance\n  [data.table](https://rdatatable.gitlab.io/data.table/) code.\n\n- [duckplyr](https://duckplyr.tidyverse.org/) for large, in-memory\n  datasets. Translates your dplyr code to high performance\n  [duckdb](https://duckdb.org) queries with zero extra copies and an\n  automatic R fallback when translation isn‚Äôt possible.\n\n- [sparklyr](https://spark.posit.co/) for very large datasets stored in\n  [Apache Spark](https://spark.apache.org).\n\n## Installation\n\n``` r\n# The easiest way to get dplyr is to install the whole tidyverse:\ninstall.packages(\"tidyverse\")\n\n# Alternatively, install just dplyr:\ninstall.packages(\"dplyr\")\n```\n\n### Development version\n\nTo get a bug fix or to use a feature from the development version, you\ncan install the development version of dplyr from GitHub.\n\n``` r\n# install.packages(\"pak\")\npak::pak(\"tidyverse/dplyr\")\n```\n\n## Cheat Sheet\n\n<a href=\"https://github.com/rstudio/cheatsheets/blob/main/data-transformation.pdf\"><img src=\"https://raw.githubusercontent.com/rstudio/cheatsheets/main/pngs/thumbnails/data-transformation-cheatsheet-thumbs.png\" width=\"630\" height=\"252\"/></a>\n\n## Usage\n\n``` r\nlibrary(dplyr)\n\nstarwars |>\n  filter(species == \"Droid\")\n#> # A tibble: 6 √ó 14\n#>   name   height  mass hair_color skin_color  eye_color birth_year sex   gender  \n#>   <chr>   <int> <dbl> <chr>      <chr>       <chr>          <dbl> <chr> <chr>   \n#> 1 C-3PO     167    75 <NA>       gold        yellow           112 none  masculi‚Ä¶\n#> 2 R2-D2      96    32 <NA>       white, blue red               33 none  masculi‚Ä¶\n#> 3 R5-D4      97    32 <NA>       white, red  red               NA none  masculi‚Ä¶\n#> 4 IG-88     200   140 none       metal       red               15 none  masculi‚Ä¶\n#> 5 R4-P17     96    NA none       silver, red red, blue         NA none  feminine\n#> # ‚Ñπ 1 more row\n#> # ‚Ñπ 5 more variables: homeworld <chr>, species <chr>, films <list>,\n#> #   vehicles <list>, starships <list>\n\nstarwars |>\n  select(name, ends_with(\"color\"))\n#> # A tibble: 87 √ó 4\n#>   name           hair_color skin_color  eye_color\n#>   <chr>          <chr>      <chr>       <chr>    \n#> 1 Luke Skywalker blond      fair        blue     \n#> 2 C-3PO          <NA>       gold        yellow   \n#> 3 R2-D2          <NA>       white, blue red      \n#> 4 Darth Vader    none       white       yellow   \n#> 5 Leia Organa    brown      light       brown    \n#> # ‚Ñπ 82 more rows\n\nstarwars |>\n  mutate(name, bmi = mass / ((height / 100)^2)) |>\n  select(name:mass, bmi)\n#> # A tibble: 87 √ó 4\n#>   name           height  mass   bmi\n#>   <chr>           <int> <dbl> <dbl>\n#> 1 Luke Skywalker    172    77  26.0\n#> 2 C-3PO             167    75  26.9\n#> 3 R2-D2              96    32  34.7\n#> 4 Darth Vader       202   136  33.3\n#> 5 Leia Organa       150    49  21.8\n#> # ‚Ñπ 82 more rows\n\nstarwars |>\n  arrange(desc(mass))\n#> # A tibble: 87 √ó 14\n#>   name      height  mass hair_color skin_color eye_color birth_year sex   gender\n#>   <chr>      <int> <dbl> <chr>      <chr>      <chr>          <dbl> <chr> <chr> \n#> 1 Jabba De‚Ä¶    175  1358 <NA>       green-tan‚Ä¶ orange         600   herm‚Ä¶ mascu‚Ä¶\n#> 2 Grievous     216   159 none       brown, wh‚Ä¶ green, y‚Ä¶       NA   male  mascu‚Ä¶\n#> 3 IG-88        200   140 none       metal      red             15   none  mascu‚Ä¶\n#> 4 Darth Va‚Ä¶    202   136 none       white      yellow          41.9 male  mascu‚Ä¶\n#> 5 Tarfful      234   136 brown      brown      blue            NA   male  mascu‚Ä¶\n#> # ‚Ñπ 82 more rows\n#> # ‚Ñπ 5 more variables: homeworld <chr>, species <chr>, films <list>,\n#> #   vehicles <list>, starships <list>\n\nstarwars |>\n  group_by(species) |>\n  summarise(\n    n = n(),\n    mass = mean(mass, na.rm = TRUE)\n  ) |>\n  filter(\n    n > 1,\n    mass > 50\n  )\n#> # A tibble: 9 √ó 3\n#>   species      n  mass\n#>   <chr>    <int> <dbl>\n#> 1 Droid        6  69.8\n#> 2 Gungan       3  74  \n#> 3 Human       35  81.3\n#> 4 Kaminoan     2  88  \n#> 5 Mirialan     2  53.1\n#> # ‚Ñπ 4 more rows\n```\n\n## Getting help\n\nIf you encounter a clear bug, please file an issue with a minimal\nreproducible example on\n[GitHub](https://github.com/tidyverse/dplyr/issues). For questions and\nother discussion, please use [forum.posit.co](https://forum.posit.co/).\n\n## Code of conduct\n\nPlease note that this project is released with a [Contributor Code of\nConduct](https://dplyr.tidyverse.org/CODE_OF_CONDUCT). By participating\nin this project you agree to abide by its terms.\n",
      "stars_today": 3
    },
    {
      "id": 135363400,
      "name": "navigation2",
      "full_name": "ros-navigation/navigation2",
      "description": "ROS 2 Navigation Framework and System",
      "html_url": "https://github.com/ros-navigation/navigation2",
      "stars": 3859,
      "forks": 1702,
      "language": "C++",
      "topics": [
        "navigation",
        "robotics",
        "ros2"
      ],
      "created_at": "2018-05-29T23:35:08Z",
      "updated_at": "2026-01-23T19:41:05Z",
      "pushed_at": "2026-01-23T19:40:57Z",
      "open_issues": 130,
      "owner": {
        "login": "ros-navigation",
        "avatar_url": "https://avatars.githubusercontent.com/u/150733807?v=4"
      },
      "readme": "# Nav2\n[![GitHub Workflow Status](https://github.com/ros-navigation/navigation2/actions/workflows/update_ci_image.yaml/badge.svg)](https://github.com/ros-navigation/navigation2/actions/workflows/update_ci_image.yaml)\n[![codecov](https://codecov.io/gh/ros-navigation/navigation2/branch/main/graph/badge.svg?token=S3iRmypwlg)](https://codecov.io/gh/ros-navigation/navigation2)\n[![Build Status](https://circleci.com/gh/ros-navigation/navigation2/tree/main.svg?style=svg)](https://circleci.com/gh/ros-navigation/navigation2/tree/main)\n\n<p align=\"center\">\n  <img height=\"300\" src=\"doc/nav2_logo.png\" />\n</p>\n\nFor detailed instructions on how to:\n- [Concepts](https://docs.nav2.org/concepts/index.html) and [Getting Started](https://docs.nav2.org/getting_started/index.html)\n- [First Time Setup Guide](https://docs.nav2.org/setup_guides/index.html)\n- [ROS Distribution Statuses](https://docs.nav2.org/#distributions)\n- [Build & Install](https://docs.nav2.org/development_guides/build_docs/index.html#build) and [Docker Containers](https://github.com/orgs/ros-navigation/packages/container/package/navigation2)\n- [General Tutorials](https://docs.nav2.org/tutorials/index.html) and [Algorithm Developer Tutorials](https://docs.nav2.org/plugin_tutorials/index.html)\n- [Configuration Guide](https://docs.nav2.org/configuration/index.html)\n- [Navigation Plugins](https://docs.nav2.org/plugins/index.html)\n- [API Docs](https://api.nav2.org/)\n- [ROSCon Talks](https://docs.nav2.org/about/roscon.html) and [Citations](https://docs.nav2.org/citations.html)\n- [Migration Guides](https://docs.nav2.org/migration/index.html)\n- [Contribute](https://docs.nav2.org/development_guides/involvement_docs/index.html)\n\nPlease visit our [documentation site](https://docs.nav2.org/). [Please visit our community Slack here](https://join.slack.com/t/navigation2/shared_invite/zt-uj428p0x-jKx8U7OzK1IOWp5TnDS2rA) (if this link does not work, please contact maintainers to reactivate).\n\n**‚ö†Ô∏è If you need professional services related to Nav2, please contact [Open Navigation](https://www.opennav.org/) at info@opennav.org.**\n\n## Our Sponsors\n\nPlease thank our amazing sponsors for their generous support of Nav2 on behalf of the community to allow the project to continue to be professionally maintained, developed, and supported for the long-haul! [Open Navigation LLC](https://www.opennav.org/) provides project leadership, maintenance, development, and support services to the Nav2 & ROS community.\n\n<p align=\"center\">\n  <img src=\"doc/sponsors_oct_2025.png\" />\n</p>\n\n### [Dexory](https://www.dexory.com/) develops robotics and AI logistics solutions to drive better business decisions using a digital twin of warehouses to provide inventory insights.\n\n### [Nvidia](https://www.nvidia.com/en-us/deep-learning-ai/industries/robotics/) develops GPU and AI technologies that power modern robotics, autonomous driving, data centers, gaming, and more.\n\n### [AMD](https://www.amd.com/en/solutions/industrial/robotics.html) provides high-performance and adaptive computing solutions that empower robotics and autonomous systems with embedded SoCs, FPGAs, and Ryzen CPUs, and Radeon GPUs.\n\n### [Polymath Robotics](https://www.polymathrobotics.com/) creates safety-critical navigation systems for industrial vehicles that are radically simple to enable and deploy.\n\n### [Stereolabs](https://www.stereolabs.com/) produces the high-quality ZED stereo cameras with a complete vision pipeline from neural depth to SLAM, 3D object tracking, AI and more.\n\n### [3Laws Robotics](https://3laws.io/) provide Supervisor ROS and Pro, easy-to-use dynamic collision avoidance solutions to improve safety and application throughput.\n\n### [Staer](https://staer.ai/) makes mobile robots truly autonomous and gives them the ability to map new environments, understand space, plan their movements, and continuously improve.\n\n## Citation\n\nIf you use the navigation framework, an algorithm from this repository, or ideas from it\nplease cite this work in your papers!\n\n- S. Macenski, F. Mart√≠n, R. White, J. Clavero. [**The Marathon 2: A Navigation System**](https://arxiv.org/abs/2003.00368). IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2020.\n\n  ```bibtex\n  @inproceedings{macenski2020marathon2,\n    title     = {The Marathon 2: A Navigation System},\n    author    = {Macenski, Steve and Mart√≠n, Francisco and White, Ruffin and Gin√©s Clavero, Jonatan},\n    year      = {2020},\n    booktitle = {2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},\n    url       = {https://github.com/ros-planning/navigation2},\n    pdf       = {https://arxiv.org/abs/2003.00368}\n  }\n  ```\n\nIf you use **any** of the algorithms in Nav2 or the analysis of the algorithms in your work, please cite this work in your papers!\n\n- S. Macenski, T. Moore, DV Lu, A. Merzlyakov, M. Ferguson, [**From the desks of ROS maintainers: A survey of modern & capable mobile robotics algorithms in the robot operating system 2**](https://arxiv.org/pdf/2307.15236.pdf), Robotics and Autonomous Systems, 2023.\n\n  ```bibtex\n  @article{macenski2023survey,\n    title   = {From the desks of ROS maintainers: A survey of modern & capable mobile robotics algorithms in the robot operating system 2},\n    author  = {S. Macenski, T. Moore, DV Lu, A. Merzlyakov, M. Ferguson},\n    year    = {2023},\n    journal = {Robotics and Autonomous Systems}\n  }\n  ```\n\nIf you use the Smac Planner (Hybrid A*, State Lattice, 2D), please cite this work in your papers!\n\n- S. Macenski, M. Booker, J. Wallace, [**Open-Source, Cost-Aware Kinematically Feasible Planning for Mobile and Surface Robotics**](https://arxiv.org/abs/2401.13078). 2024.\n\n  ```bibtex\n  @article{macenski2024smac,\n    title   = {Open-Source, Cost-Aware Kinematically Feasible Planning for Mobile and Surface Robotics},\n    author  = {Steve Macenski and Matthew Booker and Josh Wallace},\n    year    = {2024},\n    journal = {Arxiv}\n  }\n  ```\n\nIf you use the Regulated Pure Pursuit Controller algorithm or software from this repository, please cite this work in your papers!\n\n- S. Macenski, S. Singh, F. Martin, J. Gines, [**Regulated Pure Pursuit for Robot Path Tracking**](https://arxiv.org/abs/2305.20026). Autonomous Robots, 2023.\n\n  ```bibtex\n  @article{macenski2023regulated,\n    title   = {Regulated Pure Pursuit for Robot Path Tracking},\n    author  = {Steve Macenski and Shrijit Singh and Francisco Martin and Jonatan Gines},\n    year    = {2023},\n    journal = {Autonomous Robots}\n  }\n  ```\n\nIf you use our work on VSLAM and formal comparisons for service robot needs, please cite the paper:\n\n- A. Merzlyakov, S. Macenski. [**A Comparison of Modern General-Purpose Visual SLAM Approaches**](https://arxiv.org/abs/2107.07589). IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2021.\n\n  ```bibtex\n  @inproceedings{vslamComparison2021,\n    title     = {A Comparison of Modern General-Purpose Visual SLAM Approaches},\n    author    = {Merzlyakov, Alexey and Macenski, Steven},\n    year      = {2021},\n    booktitle = {2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},\n    pdf       = {https://arxiv.org/abs/2107.07589}\n  }\n  ```\n\n## Build Status\n\n| Package | humble Source | humble Debian | jazzy Source | jazzy Debian | kilted Source | kilted Debian |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| navigation2 | [![Build Status](https://build.ros2.org/job/Hsrc_uj__navigation2__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__navigation2__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__navigation2__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__navigation2__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__navigation2__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__navigation2__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__navigation2__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__navigation2__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__navigation2__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__navigation2__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__navigation2__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__navigation2__ubuntu_noble_amd64__binary/) |\n| nav2_amcl | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_amcl__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_amcl__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_amcl__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_amcl__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_amcl__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_amcl__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_amcl__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_amcl__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_amcl__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_amcl__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_amcl__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_amcl__ubuntu_noble_amd64__binary/) |\n| nav2_behavior_tree | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_behavior_tree__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_behavior_tree__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_behavior_tree__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_behavior_tree__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_behavior_tree__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_behavior_tree__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_behavior_tree__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_behavior_tree__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_behavior_tree__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_behavior_tree__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_behavior_tree__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_behavior_tree__ubuntu_noble_amd64__binary/) |\n| nav2_behaviors | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_behaviors__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_behaviors__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_behaviors__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_behaviors__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_behaviors__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_behaviors__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_behaviors__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_behaviors__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_behaviors__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_behaviors__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_behaviors__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_behaviors__ubuntu_noble_amd64__binary/) |\n| nav2_bringup | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_bringup__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_bringup__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_bringup__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_bringup__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_bringup__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_bringup__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_bringup__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_bringup__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_bringup__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_bringup__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_bringup__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_bringup__ubuntu_noble_amd64__binary/) |\n| nav2_bt_navigator | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_bt_navigator__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_bt_navigator__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_bt_navigator__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_bt_navigator__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_bt_navigator__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_bt_navigator__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_bt_navigator__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_bt_navigator__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_bt_navigator__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_bt_navigator__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_bt_navigator__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_bt_navigator__ubuntu_noble_amd64__binary/) |\n| nav2_collision_monitor | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_collision_monitor__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_collision_monitor__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_collision_monitor__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_collision_monitor__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_collision_monitor__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_collision_monitor__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_collision_monitor__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_collision_monitor__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_collision_monitor__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_collision_monitor__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_collision_monitor__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_collision_monitor__ubuntu_noble_amd64__binary/) |\n| nav2_common | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_common__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_common__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_common__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_common__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_common__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_common__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_common__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_common__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_common__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_common__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_common__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_common__ubuntu_noble_amd64__binary/) |\n| nav2_constrained_smoother | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_constrained_smoother__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_constrained_smoother__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_constrained_smoother__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_constrained_smoother__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_constrained_smoother__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_constrained_smoother__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_constrained_smoother__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_constrained_smoother__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_constrained_smoother__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_constrained_smoother__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_constrained_smoother__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_constrained_smoother__ubuntu_noble_amd64__binary/) |\n| nav2_controller | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_controller__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_controller__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_controller__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_controller__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_controller__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_controller__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_controller__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_controller__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_controller__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_controller__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_controller__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_controller__ubuntu_noble_amd64__binary/) |\n| nav2_core | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_core__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_core__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_core__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_core__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_core__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_core__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_core__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_core__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_core__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_core__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_core__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_core__ubuntu_noble_amd64__binary/) |\n| nav2_costmap_2d | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_costmap_2d__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_costmap_2d__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_costmap_2d__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_costmap_2d__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_costmap_2d__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_costmap_2d__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_costmap_2d__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_costmap_2d__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_costmap_2d__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_costmap_2d__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_costmap_2d__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_costmap_2d__ubuntu_noble_amd64__binary/) |\n| nav2_docking | [![Build Status](https://build.ros2.org/job/Hsrc_uj__opennav_docking__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__opennav_docking__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__opennav_docking__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__opennav_docking__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__opennav_docking__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__opennav_docking__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__opennav_docking__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__opennav_docking__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__opennav_docking__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__opennav_docking__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__opennav_docking__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__opennav_docking__ubuntu_noble_amd64__binary/) |\n| nav2_dwb_controller | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_dwb_controller__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_dwb_controller__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_dwb_controller__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_dwb_controller__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_dwb_controller__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_dwb_controller__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_dwb_controller__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_dwb_controller__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_dwb_controller__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_dwb_controller__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_dwb_controller__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_dwb_controller__ubuntu_noble_amd64__binary/) |\n| nav2_graceful_controller | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_graceful_controller__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_graceful_controller__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_graceful_controller__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_graceful_controller__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_graceful_controller__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_graceful_controller__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_graceful_controller__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_graceful_controller__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_graceful_controller__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_graceful_controller__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_graceful_controller__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_graceful_controller__ubuntu_noble_amd64__binary/) |\n| nav2_lifecycle_manager | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_lifecycle_manager__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_lifecycle_manager__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_lifecycle_manager__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_lifecycle_manager__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_lifecycle_manager__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_lifecycle_manager__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_lifecycle_manager__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_lifecycle_manager__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_lifecycle_manager__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_lifecycle_manager__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_lifecycle_manager__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_lifecycle_manager__ubuntu_noble_amd64__binary/) |\n| nav2_loopback_sim | N/A | N/A | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_loopback_sim__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_loopback_sim__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_loopback_sim__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_loopback_sim__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_loopback_sim__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_loopback_sim__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_loopback_sim__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_loopback_sim__ubuntu_noble_amd64__binary/) |\n| nav2_map_server | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_map_server__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_map_server__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_map_server__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_map_server__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_map_server__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_map_server__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_map_server__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_map_server__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_map_server__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_map_server__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_map_server__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_map_server__ubuntu_noble_amd64__binary/) |\n| nav2_mppi_controller | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_mppi_controller__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_mppi_controller__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_mppi_controller__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_mppi_controller__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_mppi_controller__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_mppi_controller__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_mppi_controller__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_mppi_controller__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_mppi_controller__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_mppi_controller__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_mppi_controller__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_mppi_controller__ubuntu_noble_amd64__binary/) |\n| nav2_msgs | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_msgs__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_msgs__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_msgs__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_msgs__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_msgs__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_msgs__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_msgs__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_msgs__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_msgs__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_msgs__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_msgs__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_msgs__ubuntu_noble_amd64__binary/) |\n| nav2_navfn_planner | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_navfn_planner__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_navfn_planner__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_navfn_planner__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_navfn_planner__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_navfn_planner__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_navfn_planner__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_navfn_planner__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_navfn_planner__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_navfn_planner__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_navfn_planner__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_navfn_planner__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_navfn_planner__ubuntu_noble_amd64__binary/) |\n| nav2_planner | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_planner__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_planner__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_planner__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_planner__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_planner__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_planner__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_planner__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_planner__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_planner__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_planner__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_planner__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_planner__ubuntu_noble_amd64__binary/) |\n| nav2_regulated_pure_pursuit | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_regulated_pure_pursuit_controller__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_regulated_pure_pursuit_controller__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_regulated_pure_pursuit_controller__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_regulated_pure_pursuit_controller__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_regulated_pure_pursuit_controller__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_regulated_pure_pursuit_controller__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_regulated_pure_pursuit_controller__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_regulated_pure_pursuit_controller__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_regulated_pure_pursuit_controller__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_regulated_pure_pursuit_controller__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_regulated_pure_pursuit_controller__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_regulated_pure_pursuit_controller__ubuntu_noble_amd64__binary/) |\n| nav2_rotation_shim_controller | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_rotation_shim_controller__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_rotation_shim_controller__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_rotation_shim_controller__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_rotation_shim_controller__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_rotation_shim_controller__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_rotation_shim_controller__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_rotation_shim_controller__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_rotation_shim_controller__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_rotation_shim_controller__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_rotation_shim_controller__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_rotation_shim_controller__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_rotation_shim_controller__ubuntu_noble_amd64__binary/) |\n| nav2_route | N/A | N/A | N/A | N/A | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_route__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_route__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_route__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_route__ubuntu_noble_amd64__binary/) |\n| nav2_rviz_plugins | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_rviz_plugins__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_rviz_plugins__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_rviz_plugins__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_rviz_plugins__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_rviz_plugins__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_rviz_plugins__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_rviz_plugins__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_rviz_plugins__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_rviz_plugins__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_rviz_plugins__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_rviz_plugins__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_rviz_plugins__ubuntu_noble_amd64__binary/) |\n| nav2_simple_commander | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_simple_commander__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_simple_commander__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_simple_commander__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_simple_commander__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_simple_commander__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_simple_commander__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_simple_commander__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_simple_commander__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_simple_commander__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_simple_commander__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_simple_commander__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_simple_commander__ubuntu_noble_amd64__binary/) |\n| nav2_smac_planner | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_smac_planner__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_smac_planner__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_smac_planner__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_smac_planner__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_smac_planner__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_smac_planner__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_smac_planner__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_smac_planner__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_smac_planner__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_smac_planner__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_smac_planner__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_smac_planner__ubuntu_noble_amd64__binary/) |\n| nav2_smoother | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_smoother__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_smoother__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_smoother__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_smoother__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_smoother__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_smoother__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_smoother__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_smoother__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_smoother__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_smoother__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_smoother__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_smoother__ubuntu_noble_amd64__binary/) |\n| nav2_system_tests | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_system_tests__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_system_tests__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_system_tests__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_system_tests__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_system_tests__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_system_tests__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_system_tests__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_system_tests__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_system_tests__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_system_tests__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_system_tests__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_system_tests__ubuntu_noble_amd64__binary/) |\n| nav2_theta_star_planner | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_theta_star_planner__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_theta_star_planner__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_theta_star_planner__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_theta_star_planner__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_theta_star_planner__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_theta_star_planner__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_theta_star_planner__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_theta_star_planner__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_theta_star_planner__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_theta_star_planner__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_theta_star_planner__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_theta_star_planner__ubuntu_noble_amd64__binary/) |\n| nav2_util | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_util__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_util__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_util__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_util__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_util__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_util__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_util__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_util__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_util__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_util__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_util__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_util__ubuntu_noble_amd64__binary/) |\n| nav2_velocity_smoother | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_velocity_smoother__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_velocity_smoother__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_velocity_smoother__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_velocity_smoother__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_velocity_smoother__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_velocity_smoother__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_velocity_smoother__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_velocity_smoother__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_velocity_smoother__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_velocity_smoother__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_velocity_smoother__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_velocity_smoother__ubuntu_noble_amd64__binary/) |\n| nav2_voxel_grid | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_voxel_grid__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_voxel_grid__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_voxel_grid__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_voxel_grid__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_voxel_grid__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_voxel_grid__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_voxel_grid__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_voxel_grid__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_voxel_grid__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_voxel_grid__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_voxel_grid__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_voxel_grid__ubuntu_noble_amd64__binary/) |\n| nav2_waypoint_follower | [![Build Status](https://build.ros2.org/job/Hsrc_uj__nav2_waypoint_follower__ubuntu_jammy__source/badge/icon)](https://build.ros2.org/job/Hsrc_uj__nav2_waypoint_follower__ubuntu_jammy__source/) | [![Build Status](https://build.ros2.org/job/Hbin_uj64__nav2_waypoint_follower__ubuntu_jammy_amd64__binary/badge/icon)](https://build.ros2.org/job/Hbin_uj64__nav2_waypoint_follower__ubuntu_jammy_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Jsrc_un__nav2_waypoint_follower__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Jsrc_un__nav2_waypoint_follower__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Jbin_un64__nav2_waypoint_follower__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Jbin_un64__nav2_waypoint_follower__ubuntu_noble_amd64__binary/) | [![Build Status](https://build.ros2.org/job/Ksrc_un__nav2_waypoint_follower__ubuntu_noble__source/badge/icon)](https://build.ros2.org/job/Ksrc_un__nav2_waypoint_follower__ubuntu_noble__source/) | [![Build Status](https://build.ros2.org/job/Kbin_un64__nav2_waypoint_follower__ubuntu_noble_amd64__binary/badge/icon)](https://build.ros2.org/job/Kbin_un64__nav2_waypoint_follower__ubuntu_noble_amd64__binary/) |\n",
      "stars_today": 3
    },
    {
      "id": 23780138,
      "name": "riscv-gnu-toolchain",
      "full_name": "riscv-collab/riscv-gnu-toolchain",
      "description": "GNU toolchain for RISC-V, including GCC",
      "html_url": "https://github.com/riscv-collab/riscv-gnu-toolchain",
      "stars": 4337,
      "forks": 1342,
      "language": "C",
      "topics": [],
      "created_at": "2014-09-08T05:22:03Z",
      "updated_at": "2026-01-23T23:54:19Z",
      "pushed_at": "2026-01-23T03:42:26Z",
      "open_issues": 37,
      "owner": {
        "login": "riscv-collab",
        "avatar_url": "https://avatars.githubusercontent.com/u/89536104?v=4"
      },
      "readme": "RISC-V GNU Compiler Toolchain\n=============================\n\nThis is the RISC-V C and C++ cross-compiler. It supports two build modes:\na generic ELF/Newlib toolchain and a more sophisticated Linux-ELF/glibc\ntoolchain.\n\n###  Getting the sources\n\nThis repository uses submodules, but submodules will fetch automatically on demand,\nso `--recursive` or `git submodule update --init --recursive` is not needed.\n\n    $ git clone https://github.com/riscv/riscv-gnu-toolchain\n\n**Warning: git clone takes around 6.65 GB of disk and download size**\n\n### Prerequisites\n\nSeveral standard packages are needed to build the toolchain.\n\nOn Ubuntu, executing the following command should suffice:\n\n    $ sudo apt-get install autoconf automake autotools-dev curl python3 python3-pip python3-tomli libmpc-dev libmpfr-dev libgmp-dev gawk build-essential bison flex texinfo gperf libtool patchutils bc zlib1g-dev libexpat-dev ninja-build git cmake libglib2.0-dev libslirp-dev libncurses-dev\n\nOn Fedora/CentOS/RHEL OS, executing the following command should suffice:\n\n    $ sudo yum install autoconf automake python3 libmpc-devel mpfr-devel gmp-devel gawk  bison flex texinfo patchutils gcc gcc-c++ zlib-devel expat-devel libslirp-devel ncurses-devel\n\nOn Arch Linux, executing the following command should suffice:\n\n    $ sudo pacman -Syu curl python3 libmpc mpfr gmp base-devel texinfo gperf patchutils bc zlib expat libslirp ncurses\n\nAlso available for Arch users on the AUR: [https://aur.archlinux.org/packages/riscv-gnu-toolchain-bin](https://aur.archlinux.org/packages/riscv-gnu-toolchain-bin)\n\nOn macOS, you can use [Homebrew](http://brew.sh) to install the dependencies:\n\n    $ brew install python3 gawk gnu-sed make gmp mpfr libmpc isl zlib expat texinfo flock libslirp ncurses ninja bison m4 wget\n\nWhen executing the instructions in this README, please use `gmake` instead of `make` to use the newly installed version of make.\nTo build the glibc (Linux) on macOS, you will need to build within a case-sensitive file\nsystem.  The simplest approach is to create and mount a new disk image with\na case sensitive format.  Make sure that the mount point does not contain spaces. This is not necessary to build newlib or gcc itself on macOS.\n\nThis process will start by downloading about 200 MiB of upstream sources, then\nwill patch, build, and install the toolchain.  If a local cache of the\nupstream sources exists in $(DISTDIR), it will be used; the default location\nis /var/cache/distfiles.  Your computer will need about 8 GiB of disk space to\ncomplete the process.\n\n### Installation (Newlib)\n\nTo build the Newlib cross-compiler, pick an install path (that is writeable).\nIf you choose, say, `/opt/riscv`, then add `/opt/riscv/bin` to your `PATH`.\nThen, simply run the following command:\n\n    ./configure --prefix=/opt/riscv\n    make\n\nYou should now be able to use riscv64-unknown-elf-gcc and its cousins.\n\nNote: If you're planning to use an external library that replaces part of newlib (for example `libgloss-htif`), [read the FAQ](#ensuring-code-model-consistency).\n\n### Installation (Linux)\n\nTo build the Linux cross-compiler, pick an install path (that is writeable).\nIf you choose, say, `/opt/riscv`, then add `/opt/riscv/bin` to your `PATH`.\nThen, simply run the following command:\n\n    ./configure --prefix=/opt/riscv\n    make linux\n\nThe build defaults to targeting RV64GC (64-bit) with glibc, even on a 32-bit\nbuild environment. To build the 32-bit RV32GC toolchain, use:\n\n    ./configure --prefix=/opt/riscv --with-arch=rv32gc --with-abi=ilp32d\n    make linux\n\nIn case you prefer musl libc over glibc, configure just like above and opt for\n`make musl` instead of `make linux`.\n\nSupported architectures are rv32i or rv64i plus standard extensions (a)tomics,\n(m)ultiplication and division, (f)loat, (d)ouble, or (g)eneral for MAFD.\n\nSupported ABIs are ilp32 (32-bit soft-float), ilp32d (32-bit hard-float),\nilp32f (32-bit with single-precision in registers and double in memory, niche\nuse only), lp64 lp64f lp64d (same but with 64-bit long and pointers).\n\n### Installation (Newlib/Linux multilib)\n\nTo build either cross-compiler with support for both 32-bit and\n64-bit, run the following command:\n\n    ./configure --prefix=/opt/riscv --enable-multilib\n\nAnd then either `make`, `make linux` or `make musl` for the Newlib, Linux\nglibc-based or Linux musl libc-based cross-compiler, respectively.\n\nThe multilib compiler will have the prefix riscv64-unknown-elf- or\nriscv64-unknown-linux-gnu- but will be able to target both 32-bit and 64-bit\nsystems.\nIt will support the most common `-march`/`-mabi` options, which can be seen by\nusing the `--print-multi-lib` flag on either cross-compiler.\n\nLinux toolchain has an additional option `--enable-default-pie` to control the\ndefault PIE enablement for GCC, which is disable by default.\n\nTo customize the enabled languages, use option `--with-languages=`. For example,\nif you want to enable `c,c++,fortran`, use `./configure --with-languages=c,c++,fortran`.\nThis option only takes effect for the GNU toolchain.\n\nThe toolchain has an option `--enable-strip` to control strip of host binaries,\nstrip is disabled by default.\n\n### Installation (MacOS ARM)\n\nFirst, ensure you have cloned the toolchain repository in a case-sensitive volume. \n\nNow source `macos.zsh` to setup the PATH variable so that the build scripts can use the tools from homebrew, which are needed to build the GNU toolchain.\n\nThen, run configure with your desired flags - For example:\n```\n./configure --prefix=/Volumes/case-sensitive/opt/riscv --with-arch=rv64gc_zifencei --with-abi=lp64d --enable-linux --disable-gdb\n```\n\nThen, raise the limit of open files. Run: `ulimit -n 65536`\n\nBuilds on MacOS are highly specific to OS versions and the versions of the developer tools installed. We recommend running `make check-binutils` first, which will help surface a some of the more frequent build errors we've seen without having to start a full build.\n\nIf `make check-binutils` errors, check the [following documentation](./macos-build.md) for a list of common errors when building on MacOS and their solutions.\n\nWhen `make check-binutils` finishes successfully, you run the build normally with `make` or `make linux`.\n\n### Troubleshooting Build Problems\n\nBuilds work best if installing into an empty directory.  If you build a\nhard-float toolchain and then try to build a soft-float toolchain with\nthe same --prefix directory, then the build scripts may get confused\nand exit with a linker error complaining that hard float code can't be\nlinked with soft float code.  Removing the existing toolchain first, or\nusing a different prefix for the second build, avoids the problem.  It\nis OK to build one newlib and one linux toolchain with the same prefix.\nBut you should avoid building two newlib or two linux toolchains with\nthe same prefix.\n\nIf building a linux toolchain on a MacOS system, or on a Windows system\nusing the Linux subsystem or cygwin, you must ensure that the filesystem\nis case-sensitive.  A build on a case-insensitive filesystem will fail when\nbuilding glibc because \\*.os and \\*.oS files will clobber each other during\nthe build eventually resulting in confusing link errors.\n\nCentOS (and RHEL) provide old GNU tools versions that may be too old to build\na RISC-V toolchain.  There is an alternate toolset provided that includes\ncurrent versions of the GNU tools.  This is the devtoolset provided as part\nof the Software Collection service.  For more info, see the\n[devtoolset-7](https://www.softwarecollections.org/en/scls/rhscl/devtoolset-7/)\nURL.  There are various versions of the devtoolset that are available, so you\ncan also try other versions of it, but we have at least one report that\ndevtoolset-7 works.\n\n### Advanced Options\n\nThere are a number of additional options that may be passed to\nconfigure.  See './configure --help' for more details.\n\nAlso you can define extra flags to pass to specific projects: ```BINUTILS_NATIVE_FLAGS_EXTRA,\nBINUTILS_TARGET_FLAGS_EXTRA, GCC_EXTRA_CONFIGURE_FLAGS, GDB_NATIVE_FLAGS_EXTRA,\nGDB_TARGET_FLAGS_EXTRA, GLIBC_TARGET_FLAGS_EXTRA, NEWLIB_TARGET_FLAGS_EXTRA,\nLLVM_EXTRA_CONFIGURE_FLAGS, QEMU_EXTRA_CONFIGURE_FLAGS```.\nExample: ```GCC_EXTRA_CONFIGURE_FLAGS=--with-gmp=/opt/gmp make linux```\n\n#### Set default ISA spec version\n\n`--with-isa-spec=` can specify the default version of the RISC-V Unprivileged\n(formerly User-Level) ISA specification.\n\nPossible options are: `2.2`, `20190608` and `20191213`.\n\nThe default version is `20191213`.\n\nMore details about this option you can refer this post [RISC-V GNU toolchain bumping default ISA spec to 20191213](https://groups.google.com/a/groups.riscv.org/g/sw-dev/c/aE1ZeHHCYf4).\n\n#### Build with customized multi-lib configure.\n\n`--with-multilib-generator=` can specify what multilibs to build.  The argument\nis a semicolon separated list of values, possibly consisting of a single value.\nCurrently only supported for riscv*-*-elf*.  The accepted values and meanings\nare given below.\n\nEvery config is constructed with four components: architecture string, ABI,\nreuse rule with architecture string and reuse rule with sub-extension.\n\nRe-use part support expansion operator (*) to simplify the combination of\ndifferent sub-extensions, example 4 demonstrate how it uses and works.\n\nExample 1: Add multi-lib support for rv32i with ilp32.\n```\n./configure --with-multilib-generator=\"rv32i-ilp32--\"\n```\n\nExample 2: Add multi-lib support for rv32i with ilp32 and rv32imafd with ilp32.\n\n```\n./configure --with-multilib-generator=\"rv32i-ilp32--;rv32imafd-ilp32--\"\n```\n\nExample 3: Add multi-lib support for rv32i with ilp32; rv32im with ilp32 and\nrv32ic with ilp32 will reuse this multi-lib set.\n```\n./configure --with-multilib-generator=\"rv32i-ilp32-rv32im-c\"\n```\n\nExample 4: Add multi-lib support for rv64ima with lp64; rv64imaf with lp64,\nrv64imac with lp64 and rv64imafc with lp64 will reuse this multi-lib set.\n```\n./configure --with-multilib-generator=\"rv64ima-lp64--f*c\"\n```\n\n#### Enabling QEMU System Targets\n\nThe `--enable-qemu-system` configuration flag allows you to include QEMU system emulation targets in addition to the default user-mode emulation.\n\n- **Enabled targets**:\n  - `riscv64-linux-user`\n  - `riscv32-linux-user`\n  - `riscv64-softmmu`\n  - `riscv32-softmmu`\n\n- **Default targets** (without this flag):\n  - `riscv64-linux-user`\n  - `riscv32-linux-user`\n\nUse this option if you need full system emulation for RISC-V. Example configuration:\n\n```bash\n./configure --enable-qemu-system --prefix=/opt/riscv\nmake build-sim SIM=qemu\n```\n\nThis flag is particularly useful for developers testing and emulating full RISC-V systems rather than just user-space applications.\n\n### Test Suite\n\nThe Dejagnu test suite has been ported to RISC-V. This can be run with a\nsimulator for the elf and linux toolchains. The simulator can be selected\nby the SIM variable in the Makefile, e.g. SIM=qemu, SIM=gdb, or SIM=spike\n(experimental).In addition, the simulator can also be selected with the\nconfigure time option `--with-sim=`.However, the testsuite allowlist is\nonly maintained for qemu.Other simulators might get extra failures.\n\n#### Additional Prerequisite\n\nA helper script to setup testing environment requires\n[pyelftools](https://github.com/eliben/pyelftools).\n\nOn newer versions of Ubuntu, executing the following command\nshould suffice:\n\n    $ sudo apt-get install python3-pyelftools\n\nOn newer versions of Fedora and CentOS/RHEL OS (9 or later), executing\nthe following command should suffice:\n\n    $ sudo yum install python3-pyelftools\n\nOn Arch Linux, executing the following command should suffice:\n\n    $ sudo pacman -Syyu python-pyelftools python-sphinx python-sphinx_rtd_theme ninja\n\nIf your distribution/OS does not have pyelftools package, you can install\nit using PIP.\n\n    # Assuming that PIP is installed\n    $ pip3 install --user pyelftools\n\n#### Testing GCC\n\nTo test GCC, run the following commands:\n\n    ./configure --prefix=$RISCV --disable-linux --with-arch=rv64ima # or --with-arch=rv32ima\n    make newlib\n    make report-newlib SIM=gdb # Run with gdb simulator\n\n    ./configure --prefix=$RISCV\n    make linux\n    make report-linux SIM=qemu # Run with qemu\n\n    ./configure --prefix=$RISCV --with-sim=spike\n    make linux\n    make report               # Run with spike\n\nNote:\n- spike only support rv64* bare-metal/elf toolchain.\n- gdb simulator only support bare-metal/elf toolchain.\n\n#### Selecting the tests to run in GCC's regression test suite\n\nBy default GCC will execute all tests of its regression test suite.\nWhile running them in parallel (e.g. `make -j$(nproc) report`) will\nsignificantly speed up the execution time on multi-processor systems,\nthe required time for executing all tests is usually too high for\ntypical development cycles. Therefore GCC allows to select the tests\nthat are being executed using the environment variable `RUNTESTFLAGS`.\n\nTo restrict a test run to only RISC-V specific tests\nthe following command can be used:\n\n    RUNTESTFLAGS=\"riscv.exp\" make report\n\nTo restrict a test run to only RISC-V specific tests with match the\npattern \"zb*.c\" and \"sm*.c\" the following command can be used:\n\n    RUNTESTFLAGS=\"riscv.exp=zb*.c\\ sm*.c\" make report\n\n#### Testing GCC, Binutils, and glibc of a Linux toolchain\n\nThe default Makefile target to run toolchain tests is `report`.\nThis will run all tests of the GCC regression test suite.\nAlternatively, the following command can be used to do the same:\n\n    make check-gcc\n\nThe following command can be used to run the Binutils tests:\n\n    make check-binutils\n\nThe command below can be used to run the glibc tests:\n\n    make check-glibc-linux\n\n##### Adding more arch/abi combination for testing without introducing multilib\n\n`--with-extra-multilib-test` can be used when you want to test more combination\nof arch/ABI, for example: built a linux toolchain with multilib with\n`rv64gc/lp64d` and `rv64imac/lp64`, but you want to test more configuration like\n`rv64gcv/lp64d` or `rv64gcv_zba/lp64d`, then you can use --with-extra-multilib-test\nto specify that via `--with-extra-multilib-test=\"rv64gcv-lp64d;rv64gcv_zba-lp64d\"`,\nthen the testing will run for `rv64gc/lp64d`, `rv64imac/lp64`, `rv64gcv/lp64d`\nand `rv64gcv_zba/lp64d`.\n\n`--with-extra-multilib-test` support bare-metal and linux toolchain and support\neven multilib is disable, but the user must ensure extra multilib test\nconfiguration can be work with existing lib/multilib, e.g. rv32gcv/ilp32 test\ncan't work if multilib didn't have any rv32 multilib.\n\n`--with-extra-multilib-test` also support more complicated format to fit the\nrequirements of end-users. First of all, the argument is a list of test\nconfigurations. Each test configuration are separated by `;`. For example:\n\n  `rv64gcv-lp64d;rv64_zvl256b_zvfh-lp64d`\n\nFor each test configuration, it has two parts, aka required arch-abi part and\noptional build flags. We leverage `:` to separate them with some restrictions.\n\n  * arch-abi should be required and there must be only one at the begining of\n    the test configuration.\n  * build flags is a array-like flags after the arch-abi, there will be two\n    ways to arrange them, aka AND, OR operation.\n  * If you would like the flags in build flags array acts on arch-abi\n    __simultaneously__, you can use `:` to separate them. For example:\n\n   ```\n   rv64gcv-lp64d:--param=riscv-autovec-lmul=dynamic:--param=riscv-autovec-preference=fixed-vlmax\n   ```\n\n   will be consider as one target board same as below:\n\n   ```\n   riscv-sim/-march=rv64gcv/-mabi=lp64d/-mcmodel=medlow/--param=riscv-autovec-lmul=dynamic/--param=riscv-autovec-preference=fixed-vlmax\n   ```\n\n  * If you would like the flags in build flags array acts on arch-abi\n    __respectively__, you can use ',' to separate them. For example:\n\n   ```\n   rv64gcv-lp64d:--param=riscv-autovec-lmul=dynamic,--param=riscv-autovec-preference=fixed-vlmax\n   ```\n\n   will be consider as two target boards same as below:\n\n   ```\n   riscv-sim/-march=rv64gcv/-mabi=lp64d/-mcmodel=medlow/--param=riscv-autovec-preference=fixed-vlmax\n   riscv-sim/-march=rv64gcv/-mabi=lp64d/-mcmodel=medlow/--param=riscv-autovec-lmul=dynamic\n   ```\n\n  * However, you can also leverage AND(`:`), OR(`,`) operator together but the\n    OR(`,`) will always have the higher priority. For example:\n\n   ```\n   rv64gcv-lp64d:--param=riscv-autovec-lmul=dynamic:--param=riscv-autovec-preference=fixed-vlmax,--param=riscv-autovec-lmul=m2\n   ```\n\n   will be consider as tow target boars same as below:\n\n   ```\n   riscv-sim/-march=rv64gcv/-mabi=lp64d/-mcmodel=medlow/--param=riscv-autovec-lmul=dynamic/--param=riscv-autovec-preference=fixed-vlmax\n   riscv-sim/-march=rv64gcv/-mabi=lp64d/-mcmodel=medlow/--param=riscv-autovec-lmul=m2\n   ```\n\n### LLVM / clang\n\nLLVM can be used in combination with the RISC-V GNU Compiler Toolchain\nto build RISC-V applications. To build LLVM with C and C++ support the\nconfigure flag `--enable-llvm` can be used.\n\nE.g. to build LLVM on top of a RV64 Linux toolchain the following commands\ncan be used:\n\n  ./configure --prefix=$RISCV --enable-llvm --enable-linux\n  make\n\nNote, that a combination of `--enable-llvm` and multilib configuration flags\nis not supported.\n\nBelow are examples how to build a rv64gc Linux/newlib toolchain with LLVM support,\nhow to use it to build a C and a C++ application using clang, and how to\nexecute the generated binaries using QEMU.\n\nBuild Linux toolchain and run examples:\n\n    # Build rv64gc toolchain with LLVM\n    ./configure --prefix=$RISCV --enable-llvm --enable-linux --with-arch=rv64gc --with-abi=lp64d\n    make -j$(nproc) all build-sim SIM=qemu\n    # Build C application with clang\n    $RISCV/bin/clang -march=rv64imafdc -o hello_world hello_world.c\n    $RISCV/bin/qemu-riscv64 -L $RISCV/sysroot ./hello_world\n    # Build C++ application with clang\n    $RISCV/bin/clang++ -march=rv64imafdc -stdlib=libc++ -o hello_world_cpp hello_world_cpp.cxx\n    $RISCV/bin/qemu-riscv64 -L $RISCV/sysroot ./hello_world_cpp\n\nBuild newlib toolchain and run examples (don't work with `--with-multilib-generator=`):\n\n    # Build rv64gc bare-metal toolchain with LLVM\n    ./configure --prefix=$RISCV --enable-llvm --disable-linux --with-arch=rv64gc --with-abi=lp64d\n    make -j$(nproc) all build-sim SIM=qemu\n    # Build C application with clang\n    $RISCV/bin/clang -march=rv64imafdc -o hello_world hello_world.c\n    $RISCV/bin/qemu-riscv64 -L $RISCV/sysroot ./hello_world\n    # Build C++ application with clang using static link\n    $RISCV/bin/clang++ -march=rv64imafdc -static -o hello_world_cpp hello_world_cpp.cxx\n    $RISCV/bin/qemu-riscv64 -L $RISCV/sysroot ./hello_world_cpp\n\n### Development\n\nThis section is only for developer or advanced user, or you want to build\ntoolchain with your own source tree.\n\n#### Update Source Tree\n\n`riscv-gnu-toolchain` contain stable but not latest source for each submodule,\nin case you want to using latest development tree, you can use following command\nto upgrade all submodule.\n\n    git submodule update --remote\n\nOr you can upgrade specific submodule only.\n\n    git submodule update --remote <component>\n\nFor example, upgrade gcc only, you can using following command:\n\n    git submodule update --remote gcc\n\n#### How to Check Which Branch are Used for Specific submodule\n\nThe branch info has recorded in `.gitmodules` file, which can set or update via\n`git submodule add -b` or `git submodule set-branch`.\n\nHowever the only way to check which branch are using is to check `.gitmodules`\nfile, here is the example for `gcc`, it's using releases/gcc-12 branch, so\nit will has a section named `gcc` and has a field `branch` is\n`releases/gcc-12`.\n\n```\n[submodule \"gcc\"]\n        path = gcc\n        url = ../gcc.git\n        branch = releases/gcc-12\n```\n\n#### Use Source Tree Other Than `riscv-gnu-toolchain`\n\n`riscv-gnu-toolchain` also supports using out-of-tree source to build the toolchain.\nThere are several configure options for specifying the source tree of each\nsubmodule/component.\n\nFor example, if you have GCC sources in `$HOME/gcc`, use `--with-gcc-src` to build the toolchain using those sources:\n\n    ./configure ... --with-gcc-src=$HOME/gcc\n\nHere is the list of configure options for specifying alternative sources for the various submodules/components:\n\n    --with-binutils-src\n    --with-dejagnu-src\n    --with-gcc-src\n    --with-gdb-src\n    --with-glibc-src\n    --with-linux-headers-src\n    --with-llvm-src\n    --with-musl-src\n    --with-newlib-src\n    --with-pk-src\n    --with-qemu-src\n    --with-spike-src\n    --with-uclibc-src\n\n#### Build host GCC to check for compiler warnings\n\nGCC contributions have to meet several requirements to qualify for upstream\ninclusion.  Warning free compilation with a compiler build from the same\nsources is among them.  The flag `--enable-host-gcc` does exaclty that:\n\n* Initially a host GCC will be built\n* This host GCC is then used to build the cross compiler\n* The cross compiler will be built with `-Werror` to identify code issues\n\n### FAQ\n#### Ensuring Code Model Consistency\nIf parts of newlib are going to be replaced with an external library (such as with [libgloss-htif](https://github.com/ucb-bar/libgloss-htif) for Berkeley Host-Target Interface),\nyou should take care to ensure that both newlib and the external library are built using the same code model. For more information about RISC-V code models,\n[read this SiFive blog article](https://www.sifive.com/blog/all-aboard-part-4-risc-v-code-models).\n\nErrors that indicate a code model mismatch include \"relocation overflow\" or \"relocation truncated\" errors from the linker being unable to successfully relocate symbols in the executable.\n\nBy default, `riscv-gnu-toolchain` builds newlib with `-mcmodel=medlow`. You can use the alternative `medany` code model (as used in libgloss-htif) by passing `--with-cmodel=medany` to the configure script.\n",
      "stars_today": 3
    },
    {
      "id": 129699403,
      "name": "tuist",
      "full_name": "tuist/tuist",
      "description": "A virtual platform team for mobile devs who ship ",
      "html_url": "https://github.com/tuist/tuist",
      "stars": 5484,
      "forks": 690,
      "language": "Swift",
      "topics": [
        "ios",
        "objective-c",
        "productivity",
        "scalability",
        "swift",
        "xcode"
      ],
      "created_at": "2018-04-16T07:02:54Z",
      "updated_at": "2026-01-23T18:03:33Z",
      "pushed_at": "2026-01-23T18:34:41Z",
      "open_issues": 255,
      "owner": {
        "login": "tuist",
        "avatar_url": "https://avatars.githubusercontent.com/u/38419084?v=4"
      },
      "readme": "<div align=\"center\">\n  <div>\n    <a href=\"https://tuist.dev\" target=\"_blank\"><img src=\"assets/header.png\" alt=\"header\"/></a>\n  </div>\n  <img src=\"https://img.shields.io/github/commit-activity/w/tuist/tuist?style=flat-square&label=commits\" alt=\"Commit Activity\">\n  <a href=\"https://fosstodon.org/@tuist\"><img src=\"https://img.shields.io/badge/tuist-gray.svg?logo=mastodon&logoColor=f5f5f5\" alt=\"Mastodon badge\"></a>\n  <a href=\"https://bsky.app/profile/tuist.dev\"><img src=\"https://img.shields.io/badge/tuist-gray.svg?logo=bluesky\" alt=\"Bluesky badge\"></a>\n  <a href=\"https://join.slack.com/t/tuistapp/shared_invite/zt-1lqw355mp-zElRwLeoZ2EQsgGEkyaFgg\"><img src=\"https://img.shields.io/badge/tuist-gray.svg?logo=slack\" alt=\"Slack Workspace\"></a>\n  <a href=\"https://t.me/tuist\"><img src=\"https://img.shields.io/badge/tuist-gray.svg?logo=telegram\" alt=\"Slack Workspace\"></a>\n  <div>\n    <a href=\"https://cal.com/team/tuist/cloud?utm_source=banner&utm_campaign=oss\" target=\"_blank\"><img alt=\"Book us with Cal.com\" src=\"https://cal.com/book-with-cal-dark.svg\" width=\"150\"/></a>\n  </div>\n  <a href=\"https://translate.tuist.dev/engage/tuist/\">\n  <img src=\"https://translate.tuist.dev/widget/tuist/svg-badge.svg\" alt=\"Translation status\" />\n  </a>\n</div>\n\n# Tuist\n\nTuist is a virtual platform team for Swift app devs who ship. Through an integrated platform that integrates with your toolchain and projects, we help you stay focused and productive while building apps.\n\nThe following solutions are part of Tuist:\n\n- [üóÇÔ∏è **Generated projects**](https://docs.tuist.dev/en/guides/develop/projects): A solution for more accessible and easier-to-manage Xcode projects.\n- [üöù **Cache**](https://docs.tuist.dev/en/guides/develop/cache): Speed up builds across environments with a content-addressable store.\n- [‚úÖ **Selective testing**](https://docs.tuist.dev/en/guides/develop/selective-testing): Run tests faster by selecting them based on the file changes.\n- [üì¶ **Registry**](https://docs.tuist.dev/en/guides/develop/registry): Speed up the resolution of [Swift Package Index](https://swiftpackageindex.com/)-indexed packages.\n- [üìà **Build insights**](https://docs.tuist.dev/en/guides/develop/insights): Get actionable insights from your projects, builds, and test runs to make informed decisions.\n- [üì± **Bundle insights**](https://docs.tuist.dev/en/guides/develop/bundle-size): Analyze your built apps and get suggestions to improve them.\n- [üì± **Previews**](https://docs.tuist.dev/en/guides/features/previews): Sharing apps (previews) as easy as sharing a link.\n- [‚úÖ **QA**](https://docs.tuist.dev/en/guides/features/qa): QA your app using LLM-based agents.\n\nOpenness and community are cornerstones in shaping Tuist, as we believe they are the key to building the best solution. We recommend checking out the following resources:\n\n- [üìë **Documentation**](https://docs.tuist.dev)\n- [üìö **Handbook**](https://handbook.tuist.dev)\n- [üí¨ **Community forum**](https://community.tuist.dev)\n\n> [!NOTE]\n> Even though our current focus is on the development phase of Apple native apps, we'll gradually expand our focus to include other ecosystems (e.g., Android, RN, and Flutter), and expand beyond just development.\n\n## Get started\n\nYou can run the following command to get started with [Mise] (check out [this page](https://docs.tuist.dev/en/guides/quick-start/get-started) for other methods):\n\n```bash\nmise x tuist@latest -- tuist init\n```\n\n> [!IMPORTANT]\n> The `init` workflow is designed to integrate with an existing Xcode project or create [a generated project](https://docs.tuist.dev/en/guides/features/projects). If you are migrating an existing Xcode project to a generated project, we recommend [checking out these docs](https://docs.tuist.dev/en/guides/features/projects/adoption/migrate/xcode-project).\n\n## Documentation\n\nDo you want to know more about what Tuist can offer you? Or perhaps want to contribute to the project and you need a starting point?\n\nYou can check out [the project documentation](https://docs.tuist.dev).\n\n### Sample projects\n\nYou can find some sample projects in the [examples folder](examples/xcode) or the [awesome Tuist repo](https://github.com/tuist/awesome-tuist)! üéâ\n\n## Development\n\nThis repository represents a monorepo with the following projects:\n\n| Project | Description |\n| ------ | -------  |\n| [cli](/cli) | The command line interface for Tuist |\n| [app](/app) | The Swift-powered iOS and macOS app |\n| [docs](/docs) | The documentation for Tuist |\n| [handbook](/handbook) | The company's handbook |\n\n## Sponsors\n\nSome companies support our community and open source efforts with contributions through [GitHub Sponsors](https://github.com/sponsors/tuist) and [Open Collective Backers](https://opencollective.com/tuistapp). We'd like to give a special mention to the following sponsors:\n\n<table>\n  <tbody>\n    <tr>\n      <td width=\"30%\" align=\"center\">\n        <a href=\"https://monday.com?utm_source=Github&utm_medium=Github_Repo_Content_Ad&utm_content=Developer&&utm_term=tuist\" target=\"_blank\">\n          <img width=\"300\" src=\"assets/companies/monday.com.svg\" alt=\"mondaycom_logo\"/>\n        </a>\n      </td>\n      <td><a href=\"https://monday.com?utm_source=Github&utm_medium=Github_Repo_Content_Ad&utm_content=Developer&&utm_term=tuist\">Monday.com</a> is a cloud-based work operating system (Work OS) that empowers teams to run projects and workflows with confidence. It's a versatile platform that combines features of project management, workflow automation, and team collaboration to streamline the way teams work together.</td>\n    </tr>\n    <tr>\n      <td width=\"30%\" align=\"center\">\n        <a href=\"https://lapse.com?utm_source=Github&utm_medium=Github_Repo_Content_Ad&utm_content=Developer&&utm_term=tuist\" target=\"_blank\">\n          <img width=\"200\" src=\"assets/companies/lapse.svg\" alt=\"lapse_logo\"/>\n        </a>\n      </td>\n      <td><a href=\"https://lapse.com?utm_source=Github&utm_medium=Github_Repo_Content_Ad&utm_content=Developer&&utm_term=tuist\">Lapse</a> is an app designed to reclaim how we take and share memories. A camera for living in the moment and a private photo journal for friends, not followers.</td>\n    </tr>\n  </tbody>\n</table>\n\n## Companies using Tuist\n\n<table>\n  <tbody>\n    <tr>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://play.tv2.no\" target=\"_blank\">\n          <img src=\"assets/companies/tv2.svg\" alt=\"tv2_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.depop.com\" target=\"_blank\">\n          <img src=\"assets/companies/depop.svg\" alt=\"depop_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://bendingspoons.com\" target=\"_blank\">\n          <picture>\n            <source\n              srcset=\"assets/companies/bendingspoons-darkmode.png\"\n              media=\"(prefers-color-scheme: dark)\">\n            <img src=\"assets/companies/bendingspoons.png\" alt=\"bendingspoons_logo\"/>\n          </picture>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://globekeeper.com\" target=\"_blank\">\n          <img src=\"assets/companies/globekeeper.png\" alt=\"globekeeper_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://getyourguide.com\" target=\"_blank\">\n          <img src=\"assets/companies/getyourguide.png\" alt=\"getyourguide_logo\" height=\"75\"/>\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://emplate.it\" target=\"_blank\">\n          <img src=\"assets/companies/emplate.svg\" alt=\"emplate_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.trendyol.com\" target=\"_blank\">\n          <img src=\"assets/companies/Trendyol.png\" alt=\"trendyol_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://angrynerds.co\" target=\"_blank\">\n          <img src=\"assets/companies/angrynerds.svg\" alt=\"angrynerds_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.compass.com\" target=\"_blank\">\n          <img src=\"assets/companies/compass.png\" alt=\"compass_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.wefox.com\" target=\"_blank\">\n          <img src=\"assets/companies/wefox.png\" alt=\"wefox_logo\"/>\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.hedvig.com\" target=\"_blank\">\n            <img src=\"assets/companies/hedvig.svg\" alt=\"hedvig_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.takeoutcentral.com\" target=\"_blank\">\n          <img src=\"assets/companies/takeoutcentral.svg\" alt=\"takeoutcentral_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.olx.com.br\" target=\"_blank\">\n          <img src=\"assets/companies/olx.png\" alt=\"olx_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.justeattakeaway.com\" target=\"_blank\">\n          <img src=\"assets/companies/justeattakeaway.svg\" alt=\"justeattakeaway_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://qnips.io\" target=\"_blank\">\n          <img src=\"assets/companies/qnips.svg\" alt=\"qnips_logo\"/>\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.telepass.com\" target=\"_blank\">\n          <img src=\"assets/companies/telepass.svg\" alt=\"telepass_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.crunchyroll.com\" target=\"_blank\">\n          <img src=\"assets/companies/crunchyroll.svg\" alt=\"crunchyroll_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://altel.kz\" target=\"_blank\">\n          <img src=\"assets/companies/altel.svg\" alt=\"altel_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://tele2.kz\" target=\"_blank\">\n          <img src=\"assets/companies/tele2.svg\" alt=\"altel_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://izi.me/kz\" target=\"_blank\">\n          <img src=\"assets/companies/izi.svg\" alt=\"izi_logo\" height=\"75\"/>\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://wise.com\" target=\"_blank\">\n          <img src=\"assets/companies/wise.png\" alt=\"wise_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://zapis.kz/\" target=\"_blank\">\n          <img src=\"assets/companies/zapis.svg\" alt=\"wise_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://apps.apple.com/kz/app/rbk-business/id1466194695\" target=\"_blank\">\n          <img src=\"assets/companies/rbkbusiness.svg\" alt=\"rbkbusiness_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://snoonu.com/\" target=\"_blank\">\n          <img src=\"assets/companies/snoonu.svg\" alt=\"rbkbusiness_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://get.sajda.app\" target=\"_blank\">\n          <img src=\"assets/companies/sajda_app.svg\" alt=\"sajda_logo\" height=\"75\"/>\n        </a>\n      </td>\n    </tr>\n    <tr>\n     <td width=\"20%\" align=\"center\">\n        <a href=\"https://abb-bank.az\" target=\"_blank\">\n          <img src=\"assets/companies/abb-logo-slogan.png\" alt=\"abb_mobile_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\"></td>\n      <td width=\"20%\"></td>\n      <td width=\"20%\"></td>\n      <td width=\"20%\"></td>\n    </tr>\n  </tbody>\n</table>\n\n## Want to contribute?\n\nYou can use our [contribution docs](https://docs.tuist.dev/en/contributors/code) to get started. You can find good issues for first-time contributors [here](https://github.com/tuist/tuist/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22).\n\n## Core Alumni\n\nThe following people were once core contributors helping steer the project in the right direction and ensuring we have a reliable foundation we can build new features upon:\n\n<table>\n  <tr>\n    <td align=\"center\"><a href=\"http://www.matrixprojects.net\"><img src=\"https://avatars3.githubusercontent.com/u/11914919?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kas</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/danyf90\"><img src=\"https://avatars.githubusercontent.com/u/2794031?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Daniele Formichelli</b></sub></a><br /></td>\n    <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/waltflanagan\"><img src=\"https://avatars.githubusercontent.com/u/398293?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mike Simons</b></sub></a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"http://natanrolnik.me\"><img src=\"https://avatars3.githubusercontent.com/u/1164565?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Natan Rolnik</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/andreacipriani\"><img src=\"https://avatars3.githubusercontent.com/u/536929?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andrea Cipriani</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/ollieatkinson\"><img src=\"https://avatars1.githubusercontent.com/u/1382565?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Oliver Atkinson</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/RomainBoulay\"><img src=\"https://avatars1.githubusercontent.com/u/169323?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Romain Boulay</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/laxmorek\"><img src=\"https://avatars1.githubusercontent.com/u/4774319?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kamil Harasimowicz</b></sub></a><br /></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"http://www.luispadron.com\"><img src=\"https://avatars3.githubusercontent.com/u/13840545?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Luis Padron</b></sub></a></td>\n    <td align=\"center\"><a href=\"https://github.com/adellibovi\"><img src=\"https://avatars3.githubusercontent.com/u/67916?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alfredo Delli Bovi</b></sub></a><br /></td>\n  </tr>\n</table>\n\n## Contributors\n\nThanks goes to these wonderful people:\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kalkwarf\"><img src=\"https://avatars1.githubusercontent.com/u/1033839?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kalkwarf</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/fortmarek\"><img src=\"https://avatars0.githubusercontent.com/u/9371695?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Marek Fo≈ôt</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.matrixprojects.net\"><img src=\"https://avatars3.githubusercontent.com/u/11914919?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kas</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://natanrolnik.me\"><img src=\"https://avatars3.githubusercontent.com/u/1164565?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Natan Rolnik</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/svastven\"><img src=\"https://avatars0.githubusercontent.com/u/42235915?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>svastven</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://bhuemer.github.io\"><img src=\"https://avatars2.githubusercontent.com/u/1212480?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Bernhard Huemer</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://djankowski.dev\"><img src=\"https://avatars0.githubusercontent.com/u/10795657?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Daniel Jankowski</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/facumenzella\"><img src=\"https://avatars1.githubusercontent.com/u/1125252?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Facundo Menzella</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/eito\"><img src=\"https://avatars3.githubusercontent.com/u/775643?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Eric Ito</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/laxmorek\"><img src=\"https://avatars2.githubusercontent.com/u/4774319?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kamil Harasimowicz</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/olejnjak\"><img src=\"https://avatars1.githubusercontent.com/u/3148214?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jakub Olejn√≠k</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lakpa\"><img src=\"https://avatars0.githubusercontent.com/u/389328?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ldindu</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/gtsifrikas\"><img src=\"https://avatars2.githubusercontent.com/u/8904378?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>George Tsifrikas</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/yurapriv\"><img src=\"https://avatars2.githubusercontent.com/u/7814127?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Privezentsev Yura</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://ferologics.github.io\"><img src=\"https://avatars2.githubusercontent.com/u/5576161?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Fero</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://heberti.com\"><img src=\"https://avatars0.githubusercontent.com/u/103670?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Heberti Almeida</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://benscheirman.com\"><img src=\"https://avatars0.githubusercontent.com/u/59140?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ben Scheirman</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://jsorge.net\"><img src=\"https://avatars3.githubusercontent.com/u/2585841?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jared Sorge</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://joeblau.com\"><img src=\"https://avatars1.githubusercontent.com/u/1218847?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Joe Blau</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/dchavezlive\"><img src=\"https://avatars0.githubusercontent.com/u/2475932?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>David Chavez</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/—Ä–æ–º–∞–Ω-–ø–æ–¥—ã–º–æ–≤-72338ab0/\"><img src=\"https://avatars3.githubusercontent.com/u/10789692?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Roman Podymov</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/marcinreliga-fn\"><img src=\"https://avatars0.githubusercontent.com/u/76949651?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Marcin Religa</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/adellibovi\"><img src=\"https://avatars3.githubusercontent.com/u/67916?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alfredo Delli Bovi</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Jake-Prickett\"><img src=\"https://avatars1.githubusercontent.com/u/26095410?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jake Prickett</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/danyf90\"><img src=\"https://avatars.githubusercontent.com/u/2794031?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Daniele Formichelli</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.facebook.com/PetrachkovSergey\"><img src=\"https://avatars.githubusercontent.com/u/7995896?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sergey Petrachkov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://jinuman.github.io/resume\"><img src=\"https://avatars.githubusercontent.com/u/26243835?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jinwoo, Kim</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/thedavidharris\"><img src=\"https://avatars.githubusercontent.com/u/5666250?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>David Harris</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/DimaMishchenko\"><img src=\"https://avatars.githubusercontent.com/u/25247301?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dmytro Mishchenko</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.sampettersson.com\"><img src=\"https://avatars.githubusercontent.com/u/5459507?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sam Pettersson</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.joshholtz.com\"><img src=\"https://avatars.githubusercontent.com/u/401294?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Josh Holtz</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://jierong.dev\"><img src=\"https://avatars.githubusercontent.com/u/7414906?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jierong Li</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/freak4pc\"><img src=\"https://avatars.githubusercontent.com/u/605076?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Shai Mishali</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/FranzJBusch\"><img src=\"https://avatars.githubusercontent.com/u/3491887?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Franz Busch</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tiarnann\"><img src=\"https://avatars.githubusercontent.com/u/10522081?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>T√≠arn√°n McGrath</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/softmaxsg\"><img src=\"https://avatars.githubusercontent.com/u/3723817?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vitaly Chupryk</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rmnblm\"><img src=\"https://avatars.githubusercontent.com/u/5942764?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Roman Blum</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://nanotek.me\"><img src=\"https://avatars.githubusercontent.com/u/7265334?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Giovanni Filaferro</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://twitter.com/tovkal\"><img src=\"https://avatars.githubusercontent.com/u/5960675?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andr√©s Piz√° B√ºckmann</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://coutinho.dev\"><img src=\"https://avatars.githubusercontent.com/u/17842860?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Gabriel Coutinho</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://medium.com/@riccardocipolleschi\"><img src=\"https://avatars.githubusercontent.com/u/11162307?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Riccardo</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/bolismauro\"><img src=\"https://avatars.githubusercontent.com/u/771999?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mauro Bolis</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/iteractive_man\"><img src=\"https://avatars.githubusercontent.com/u/461805?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Peter Weishapl</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://stackoverflow.com/users/1878594/swiftycruz\"><img src=\"https://avatars.githubusercontent.com/u/2609775?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Cruz</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/svenmuennich\"><img src=\"https://avatars.githubusercontent.com/u/1932115?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sven M√ºnnich</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/santi-d\"><img src=\"https://avatars.githubusercontent.com/u/993826?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Santiago A. Delgado</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://wojciechkulik.pl\"><img src=\"https://avatars.githubusercontent.com/u/3128467?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Wojciech Kulik</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/iainsmith\"><img src=\"https://avatars.githubusercontent.com/u/993745?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Iain Smith</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/havebeenfitz\"><img src=\"https://avatars.githubusercontent.com/u/31866271?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Max Kraev</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mstfy\"><img src=\"https://avatars.githubusercontent.com/u/5105861?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mustafa Yusuf</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://twitter.com/danielbarden\"><img src=\"https://avatars.githubusercontent.com/u/104456?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Daniel Barden</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/zzzkk\"><img src=\"https://avatars.githubusercontent.com/u/12541603?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Zofia Kulus</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://randombits.org/\"><img src=\"https://avatars.githubusercontent.com/u/3589315?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>David Peterson</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://bandism.net/\"><img src=\"https://avatars.githubusercontent.com/u/22633385?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ikko Ashimine</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/setoelkahfi\"><img src=\"https://avatars.githubusercontent.com/u/1797197?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Seto Elkahfi / Â°ûÊâò¬∑ÂüÉÂ∞îÂç°Ëè≤</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://apps4everyone.at\"><img src=\"https://avatars.githubusercontent.com/u/1915802?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>apps4everyone</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/LorDisturbia\"><img src=\"https://avatars.githubusercontent.com/u/12445776?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Lorenzo</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/DarkoDamjanovic\"><img src=\"https://avatars.githubusercontent.com/u/11902775?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Darko Damjanovic</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/MarvinNazari\"><img src=\"https://avatars.githubusercontent.com/u/926772?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Marvin Nazari</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://twitter.com/codeOfRobin\"><img src=\"https://avatars.githubusercontent.com/u/5009041?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Robin Malhotra</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/astromonkee\"><img src=\"https://avatars.githubusercontent.com/u/44421303?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Astromonkee</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ezraberch\"><img src=\"https://avatars.githubusercontent.com/u/49635435?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ezraberch</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/cconstable\"><img src=\"https://avatars.githubusercontent.com/u/564781?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Christopher Constable</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/neakor\"><img src=\"https://avatars.githubusercontent.com/u/1827517?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Yi Wang</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.mustafadur.com\"><img src=\"https://avatars.githubusercontent.com/u/971530?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mustafa Dur</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lucabartoletti\"><img src=\"https://avatars.githubusercontent.com/u/838925?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Luca Bartoletti</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sujata23\"><img src=\"https://avatars.githubusercontent.com/u/1849089?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sujata Chakraborty</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.viber.com\"><img src=\"https://avatars.githubusercontent.com/u/5096762?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Pavel Trafimuk</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://alexsilva.dev/\"><img src=\"https://avatars.githubusercontent.com/u/633535?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alejandro Silva Fern√°ndez</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.jakeadams.co\"><img src=\"https://avatars.githubusercontent.com/u/3605966?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jake Adams</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/wattson12\"><img src=\"https://avatars.githubusercontent.com/u/1217873?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sam Watts</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://erkekin.com\"><img src=\"https://avatars.githubusercontent.com/u/701481?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Erk Ekin</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/morozkin\"><img src=\"https://avatars.githubusercontent.com/u/16591888?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Denis Morozov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/orbitekk\"><img src=\"https://avatars.githubusercontent.com/u/4222449?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>orbitekk</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://blog.naver.com/wogus3602\"><img src=\"https://avatars.githubusercontent.com/u/46857148?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Park Jae Hyun</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/regularberry\"><img src=\"https://avatars.githubusercontent.com/u/565192?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sean Berry</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://hisaac.net\"><img src=\"https://avatars.githubusercontent.com/u/923876?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Isaac Halvorson</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mohitsaxenaknoldus\"><img src=\"https://avatars.githubusercontent.com/u/76725454?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mohit Saxena</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mikchmie\"><img src=\"https://avatars.githubusercontent.com/u/15248837?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Miko≈Çaj Chmielewski</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/takinwande\"><img src=\"https://avatars.githubusercontent.com/u/4744429?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Tope Akinwande</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.theinkedengineer.com\"><img src=\"https://avatars.githubusercontent.com/u/13349066?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>TheInkedEngineer</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://alexanderweiss.dev\"><img src=\"https://avatars.githubusercontent.com/u/12934015?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alexander Wei√ü</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kyungpyoda\"><img src=\"https://avatars.githubusercontent.com/u/44656036?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kyungpyoda</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.villewitt.net\"><img src=\"https://avatars.githubusercontent.com/u/522544?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ville Witt</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/paulsamuels\"><img src=\"https://avatars.githubusercontent.com/u/527091?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>paul.s</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/aniltaskiran\"><img src=\"https://avatars.githubusercontent.com/u/16738729?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>aniltaskiran</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/unxavi\"><img src=\"https://avatars.githubusercontent.com/u/3817679?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Javier Vieira</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/a-sarris\"><img src=\"https://avatars.githubusercontent.com/u/78614622?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Aris Sarris</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://xxw9999.notion.site/xxw9999/iOS-8585a34b2886419586960c5c02b9d845\"><img src=\"https://avatars.githubusercontent.com/u/67373938?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kimxwan0319</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://florian.codes\"><img src=\"https://avatars.githubusercontent.com/u/7734806?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Florian Fittschen</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jesus-mg-ios\"><img src=\"https://avatars.githubusercontent.com/u/85997060?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jesus (iOS)</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nicholaskim94\"><img src=\"https://avatars.githubusercontent.com/u/7912759?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Nicholas Kim</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Smponias\"><img src=\"https://avatars.githubusercontent.com/u/14213855?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alexandros Smponias</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mangofever\"><img src=\"https://avatars.githubusercontent.com/u/724343?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Go</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/AlbGarciam\"><img src=\"https://avatars.githubusercontent.com/u/45308839?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alberto Garcia</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/andreascuderi/\"><img src=\"https://avatars.githubusercontent.com/u/8319309?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andrea Scuderi</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://dogoautilio.wordpress.com/\"><img src=\"https://avatars.githubusercontent.com/u/1487375?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Diogo Autilio</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/shahzadmajeed\"><img src=\"https://avatars.githubusercontent.com/u/1209459?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Shahzad Majeed</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/danrevah\"><img src=\"https://avatars.githubusercontent.com/u/7808742?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dan</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nivanchikov\"><img src=\"https://avatars.githubusercontent.com/u/1830010?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Nikita Ivanchikov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/xoxo-anastasi-xoxo\"><img src=\"https://avatars.githubusercontent.com/u/28875920?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Anastasia Kazantseva</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/MonocularVision\"><img src=\"https://avatars.githubusercontent.com/u/429790?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Michael McGuire</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.michaelfcollins3.me\"><img src=\"https://avatars.githubusercontent.com/u/104274?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Michael Collins</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/devyhan\"><img src=\"https://avatars.githubusercontent.com/u/45344633?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>YoHan Cho</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/euriasb\"><img src=\"https://avatars.githubusercontent.com/u/3721257?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>euriasb</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/MontakOleg\"><img src=\"https://avatars.githubusercontent.com/u/1800899?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>MontakOleg</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/oozoofrog\"><img src=\"https://avatars.githubusercontent.com/u/3011832?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>oozoofrog</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/MartinStrambach\"><img src=\"https://avatars.githubusercontent.com/u/11178869?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Martin Strambach</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sh-a-n\"><img src=\"https://avatars.githubusercontent.com/u/2219548?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>sh-a-n</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://linkedin.com/in/batuhansaka\"><img src=\"https://avatars.githubusercontent.com/u/9626765?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Batuhan Saka</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://jcsoohwancho.github.io\"><img src=\"https://avatars.githubusercontent.com/u/51935215?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>SooHwanCho</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.bouncingball.mobi\"><img src=\"https://avatars.githubusercontent.com/u/798117?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Gary Riches</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://mustiikhalil.github.io/mustiikhalil/\"><img src=\"https://avatars.githubusercontent.com/u/26250654?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>mustiikhalil</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/serejahh\"><img src=\"https://avatars.githubusercontent.com/u/2575555?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Serhii Butenko</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/petrukha-ivan\"><img src=\"https://avatars.githubusercontent.com/u/93926277?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Petrukha Ivan</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lo1tuma\"><img src=\"https://avatars.githubusercontent.com/u/169170?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mathias Schreck</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Buju77\"><img src=\"https://avatars.githubusercontent.com/u/266349?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Yen-Chia Lin</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://coolmathgames.tech\"><img src=\"https://avatars.githubusercontent.com/u/6877780?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mary </b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/woohyunjin06\"><img src=\"https://avatars.githubusercontent.com/u/30452977?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Hyunjin</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kevin58332\"><img src=\"https://avatars.githubusercontent.com/u/47673410?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kevin Aguilar</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://andrewroan.com\"><img src=\"https://avatars.githubusercontent.com/u/9873566?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andrew Roan</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/ibrahim-oktay-518b4939/\"><img src=\"https://avatars.githubusercontent.com/u/36792481?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ibrahim oktay</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/navartis\"><img src=\"https://avatars.githubusercontent.com/u/7813723?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dmitriy Kulakov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/woin2ee\"><img src=\"https://avatars.githubusercontent.com/u/81426024?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jaewon-Yun</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tatagrigory\"><img src=\"https://avatars.githubusercontent.com/u/5187973?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>tatagrigory</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://linkedin.com/in/denilchungath\"><img src=\"https://avatars.githubusercontent.com/u/95201442?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Denil Chungath</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/victor-sarda/\"><img src=\"https://avatars.githubusercontent.com/u/6460866?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Victor Sarda</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tzxdtc\"><img src=\"https://avatars.githubusercontent.com/u/19767846?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>tzxdtc10</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ThiemeFM\"><img src=\"https://avatars.githubusercontent.com/u/143395823?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Thieme</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Lilfaen\"><img src=\"https://avatars.githubusercontent.com/u/39119695?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Clemens Beck</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://macpaw.com/\"><img src=\"https://avatars.githubusercontent.com/u/119268?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Paul Taykalo</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/in4lio\"><img src=\"https://avatars.githubusercontent.com/u/976061?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vitaly Kravtsov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://dc.wtf\"><img src=\"https://avatars.githubusercontent.com/u/643865?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>dc</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/baekteun\"><img src=\"https://avatars.githubusercontent.com/u/74440939?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>baegteun</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://vcoutasso.com\"><img src=\"https://avatars.githubusercontent.com/u/44986513?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vin√≠cius Couto Tasso</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://blog.jihoon.me\"><img src=\"https://avatars.githubusercontent.com/u/68891494?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ÏïàÏßÄÌõà</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dxmvsh\"><img src=\"https://avatars.githubusercontent.com/u/44325936?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dimash</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/danibachar\"><img src=\"https://avatars.githubusercontent.com/u/6380777?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>danibachar</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dp221125\"><img src=\"https://avatars.githubusercontent.com/u/10572119?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ÌïúÏÑùÌò∏(MilKyo)</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://medium.com/@haifengkaohaifengkao&usg=AOvVaw2_xG-ZLdBawBIyS7m-99RQ\"><img src=\"https://avatars.githubusercontent.com/u/4080524?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Hai Feng Kao</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/anlaital-oura\"><img src=\"https://avatars.githubusercontent.com/u/133648611?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Antti Laitala</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/PushedCrayon\"><img src=\"https://avatars.githubusercontent.com/u/37077444?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>PushedCrayon</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://stefanomondino.com\"><img src=\"https://avatars.githubusercontent.com/u/1691903?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Stefano Mondino</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/leszko11\"><img src=\"https://avatars.githubusercontent.com/u/23533452?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>≈Åukasz Lech</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/costapombo\"><img src=\"https://avatars.githubusercontent.com/u/31352351?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>costapombo</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/isavynskyi\"><img src=\"https://avatars.githubusercontent.com/u/18377497?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ihor Savynskyi</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kapitoshka438\"><img src=\"https://avatars.githubusercontent.com/u/3232401?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Eduard Miniakhmetov</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/alexfilimon\"><img src=\"https://avatars.githubusercontent.com/u/19904867?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alexander Filimonov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rofle100lvl\"><img src=\"https://avatars.githubusercontent.com/u/45801227?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Gorbenko Roman</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/lucas-paim/\"><img src=\"https://avatars.githubusercontent.com/u/7849484?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Lucas Mrowskovsky Paim</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://actuallytaylor.com\"><img src=\"https://avatars.githubusercontent.com/u/32944568?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Taylor Lineman</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nandodelauni\"><img src=\"https://avatars.githubusercontent.com/u/1938501?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Miguel Ferrando</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/barredewe\"><img src=\"https://avatars.githubusercontent.com/u/19188911?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>BarredEwe</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/chris-livefront\"><img src=\"https://avatars.githubusercontent.com/u/126101032?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Chris Sessions</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ajkolean\"><img src=\"https://avatars.githubusercontent.com/u/5394701?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andy Kolean</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Binlogo\"><img src=\"https://avatars.githubusercontent.com/u/7845507?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Binlogo</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/DevilDimon\"><img src=\"https://avatars.githubusercontent.com/u/10220441?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dmitry Serov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://darrarski.pl\"><img src=\"https://avatars.githubusercontent.com/u/1384684?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dariusz Rybicki</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dansinclair25\"><img src=\"https://avatars.githubusercontent.com/u/2573447?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dan Sinclair</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.kaioelfke.de\"><img src=\"https://avatars.githubusercontent.com/u/1190948?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kai Oelfke</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://stackoverflow.com/users/468724/inder-kumar-rathore\"><img src=\"https://avatars.githubusercontent.com/u/352443?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Inder</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kyounh12\"><img src=\"https://avatars.githubusercontent.com/u/25301615?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kyounh12</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/alvar-bolt\"><img src=\"https://avatars.githubusercontent.com/u/72379847?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alvar Hansen</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/barakwei\"><img src=\"https://avatars.githubusercontent.com/u/5232161?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Barak Weiss</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/hiltonc\"><img src=\"https://avatars.githubusercontent.com/u/470753?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Hilton Campbell</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rgnns\"><img src=\"https://avatars.githubusercontent.com/u/811827?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Gabriel Li√©vano</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/vijaytholpadi\"><img src=\"https://avatars.githubusercontent.com/u/1171868?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vijay Tholpadi</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://withiosdeveloper.blogspot.com/\"><img src=\"https://avatars.githubusercontent.com/u/27220138?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Minhoi Goo</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sphanley\"><img src=\"https://avatars.githubusercontent.com/u/1323769?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sam Hanley</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ahmdyasser\"><img src=\"https://avatars.githubusercontent.com/u/42544598?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ahmdyasser</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/minhaaan\"><img src=\"https://avatars.githubusercontent.com/u/87178301?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>minhaaan</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/TamarMilchtaich\"><img src=\"https://avatars.githubusercontent.com/u/49520876?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Tamar Milchtaich Lavi</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rock88\"><img src=\"https://avatars.githubusercontent.com/u/323908?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andrey K</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://2stable.com\"><img src=\"https://avatars.githubusercontent.com/u/69604865?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alex Vera</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.annalisemariottini.com\"><img src=\"https://avatars.githubusercontent.com/u/14299642?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Annalise Mariottini</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/gustn3965\"><img src=\"https://avatars.githubusercontent.com/u/48749182?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>HyunSu Park</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/vldalx\"><img src=\"https://avatars.githubusercontent.com/u/13873200?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vladimir</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://rhysmorgan.co\"><img src=\"https://avatars.githubusercontent.com/u/11096937?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Rhys Morgan</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pierrerodgers\"><img src=\"https://avatars.githubusercontent.com/u/48193278?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>pierrerodgers</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/honghoker\"><img src=\"https://avatars.githubusercontent.com/u/50417461?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>eunpyo hong</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://medium.com/@dbstj169\"><img src=\"https://avatars.githubusercontent.com/u/65678579?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Yunseo Kang</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ilia3546\"><img src=\"https://avatars.githubusercontent.com/u/4445510?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ilya Kharlamov</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/brianvar\"><img src=\"https://avatars.githubusercontent.com/u/115399684?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>brianvar</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/HossamYoussof\"><img src=\"https://avatars.githubusercontent.com/u/6381926?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Hossam Youssof</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/devMinseok\"><img src=\"https://avatars.githubusercontent.com/u/51021614?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Minseok Kang</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/alpanyukov\"><img src=\"https://avatars.githubusercontent.com/u/36258478?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alexander</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sanghyeok-kim\"><img src=\"https://avatars.githubusercontent.com/u/57667738?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Loyle</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/vvisionnn\"><img src=\"https://avatars.githubusercontent.com/u/24761186?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ydna</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://brucemcrooster.dev\"><img src=\"https://avatars.githubusercontent.com/u/53529192?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Evan</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.snipnotes.de\"><img src=\"https://avatars.githubusercontent.com/u/5102728?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Felix Lisczyk</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lukaswuerzburger\"><img src=\"https://avatars.githubusercontent.com/u/10812458?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Lukas W√ºrzburger</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/GetToSet\"><img src=\"https://avatars.githubusercontent.com/u/8158163?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ethan Wong</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://tdkn.dev\"><img src=\"https://avatars.githubusercontent.com/u/1296540?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Shun Tedokon</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://connorricks.com\"><img src=\"https://avatars.githubusercontent.com/u/13373737?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Connor Ricks</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://franciscodiaz.cl\"><img src=\"https://avatars.githubusercontent.com/u/530662?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Francisco Diaz</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Ethan-IS\"><img src=\"https://avatars.githubusercontent.com/u/140235921?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ethan Parker</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lukevanin\"><img src=\"https://avatars.githubusercontent.com/u/550579?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Luke Van In</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://mustafataibah.vercel.app/\"><img src=\"https://avatars.githubusercontent.com/u/83141712?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mustafa Taibah</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/vkondrashkov\"><img src=\"https://avatars.githubusercontent.com/u/16046780?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vladislav Kondrashkov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/chrisjrex\"><img src=\"https://avatars.githubusercontent.com/u/4457170?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Christopher Rex</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/bahattinkoc\"><img src=\"https://avatars.githubusercontent.com/u/61124759?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>baaddin</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mattjung\"><img src=\"https://avatars.githubusercontent.com/u/19891158?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Matt Jung</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://imaginativeworld.org\"><img src=\"https://avatars.githubusercontent.com/u/1952630?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Md. Mahmudul Hasan Shohag</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://ma.tyas.cz\"><img src=\"https://avatars.githubusercontent.com/u/6033733?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Matty Cross</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/YIshihara11201\"><img src=\"https://avatars.githubusercontent.com/u/98417271?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>YIshihara11201</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/PhilippeWeidmann\"><img src=\"https://avatars.githubusercontent.com/u/5843044?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Philippe Weidmann</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Zentaur0\"><img src=\"https://avatars.githubusercontent.com/u/75909658?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Anton SVTSV</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://johannes.plunien.com\"><img src=\"https://avatars.githubusercontent.com/u/31597?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Johannes Plunien</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://emirhankarahan.com\"><img src=\"https://avatars.githubusercontent.com/u/48404459?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Emirhan KARAHAN</b></sub></a></td>\n    </tr>\n  </tbody>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n",
      "stars_today": 3
    },
    {
      "id": 11457947,
      "name": "dependency-track",
      "full_name": "DependencyTrack/dependency-track",
      "description": "Dependency-Track is an intelligent Component Analysis platform that allows organizations to identify and reduce risk in the software supply chain.",
      "html_url": "https://github.com/DependencyTrack/dependency-track",
      "stars": 3537,
      "forks": 707,
      "language": "Java",
      "topics": [
        "appsec",
        "bill-of-materials",
        "bom",
        "component-analysis",
        "cyclonedx",
        "devsecops",
        "hacktoberfest",
        "nvd",
        "ossindex",
        "owasp",
        "package-url",
        "purl",
        "sbom",
        "sca",
        "security",
        "security-automation",
        "software-composition-analysis",
        "software-security",
        "vulnerabilities",
        "vulnerability-detection"
      ],
      "created_at": "2013-07-16T19:16:43Z",
      "updated_at": "2026-01-24T00:20:31Z",
      "pushed_at": "2026-01-22T10:52:58Z",
      "open_issues": 1024,
      "owner": {
        "login": "DependencyTrack",
        "avatar_url": "https://avatars.githubusercontent.com/u/40258585?v=4"
      },
      "readme": "[![Build Status](https://github.com/DependencyTrack/dependency-track/actions/workflows/ci-build.yaml/badge.svg)](https://github.com/DependencyTrack/dependency-track/actions?workflow=CI+Build)\n[![Codacy Badge](https://app.codacy.com/project/badge/Grade/b2ecd06dab57438a9a55bc4a71c5a8ce)](https://www.codacy.com/gh/DependencyTrack/dependency-track/dashboard?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=DependencyTrack/dependency-track&amp;utm_campaign=Badge_Grade)\n[![Alpine](https://img.shields.io/badge/built%20on-Alpine-blue.svg)](https://github.com/stevespringett/Alpine)\n[![License][license-image]][Apache License 2.0]\n[![OWASP Flagship](https://img.shields.io/badge/owasp-flagship%20project-orange.svg)](https://www.owasp.org/index.php/OWASP_Dependency_Track_Project)\n[![Website](https://img.shields.io/badge/https://-dependencytrack.org-blue.svg)](https://dependencytrack.org/)\n[![Documentation](https://img.shields.io/badge/read-documentation-blue.svg)](https://docs.dependencytrack.org/)\n[![Slack](https://img.shields.io/badge/chat%20on-slack-46BC99.svg)](https://dependencytrack.org/slack)\n[![Group Discussion](https://img.shields.io/badge/discussion-groups.io-blue.svg)](https://dependencytrack.org/discussion)\n[![YouTube Subscribe](https://img.shields.io/badge/youtube-subscribe-%23c4302b.svg)](https://dependencytrack.org/youtube)\n[![Twitter](https://img.shields.io/twitter/follow/dependencytrack.svg?label=Follow&style=social)](https://twitter.com/dependencytrack)\n[![Downloads](https://img.shields.io/github/downloads/DependencyTrack/dependency-track/total.svg)](https://github.com/DependencyTrack/dependency-track/releases)\n[![Latest](https://img.shields.io/github/release/DependencyTrack/dependency-track.svg)](https://github.com/DependencyTrack/dependency-track/releases)\n[![Pulls - API Server](https://img.shields.io/docker/pulls/dependencytrack/apiserver.svg?label=Docker%20Pulls%20%28API%20Server%29)](https://hub.docker.com/r/dependencytrack/apiserver/)\n[![Pulls - Frontend](https://img.shields.io/docker/pulls/dependencytrack/frontend.svg?label=Docker%20Pulls%20%28Frontend%29)](https://hub.docker.com/r/dependencytrack/frontend/)\n[![Pulls - Bundled](https://img.shields.io/docker/pulls/dependencytrack/bundled.svg?label=Docker%20Pulls%20%28Bundled%29)](https://hub.docker.com/r/dependencytrack/bundled/)\n[![Pulls - Legacy](https://img.shields.io/docker/pulls/owasp/dependency-track.svg?label=Docker%20Pulls%20%28OWASP%20Legacy%29)](https://hub.docker.com/r/owasp/dependency-track/)\n\n![logo preview](https://raw.githubusercontent.com/DependencyTrack/branding/master/dt-logo.svg?sanitize=true)\n\n\nDependency-Track is an intelligent [Component Analysis] platform that allows organizations to\nidentify and reduce risk in the software supply chain. Dependency-Track takes a unique\nand highly beneficial approach by leveraging the capabilities of [Software Bill of Materials] (SBOM). This approach\nprovides capabilities that traditional Software Composition Analysis (SCA) solutions cannot achieve.\n\nDependency-Track monitors component usage across all versions of every application in its portfolio in order to\nproactively identify risk across an organization. The platform has an API-first design and is ideal for use in\nCI/CD environments.\n\n## Ecosystem Overview\n![alt text](./docs/images/integrations.png)\n\n## Features\n* Consumes and produces [CycloneDX] Software Bill of Materials (SBOM)\n* Consumes and produces [CycloneDX Vulnerability Exploitability Exchange (VEX)](https://cyclonedx.org/capabilities/vex/)\n* Component support for:\n  * Applications\n  * Libraries\n  * Frameworks\n  * Operating systems\n  * Containers\n  * Firmware\n  * Files\n  * Hardware\n  * Services\n* Tracks component usage across every application in an organizations portfolio\n* Quickly identify what is affected, and where\n* Identifies multiple forms of risk including\n  * Components with known vulnerabilities\n  * Out-of-date components\n  * Modified components\n  * License risk\n  * More coming soon...\n* Integrates with multiple sources of vulnerability intelligence including:\n  * [National Vulnerability Database] (NVD)\n  * [GitHub Advisories]\n  * [Sonatype OSS Index]\n  * [Snyk]\n  * [Trivy]\n  * [OSV]\n  * [VulnDB] from [Risk Based Security]\n  * More coming soon.\n* Helps to prioritize mitigation by incorporating support for the [Exploit Prediction Scoring System (EPSS)](https://www.first.org/epss/)\n* Maintain a private vulnerability database of vulnerability components\n* Robust policy engine with support for global and per-project policies\n  * Security risk and compliance\n  * License risk and compliance\n  * Operational risk and compliance\n* Ecosystem agnostic with built-in repository support for:\n  * Cargo (Rust)\n  * Composer (PHP)\n  * Gems (Ruby)\n  * Hex (Erlang/Elixir)\n  * Maven (Java)\n  * NPM (Javascript)\n  * CPAN (Perl)\n  * NuGet (.NET)\n  * PyPI (Python)\n  * More coming soon.\n* Identifies APIs and external service components including:\n  * Service provider\n  * Endpoint URIs\n  * Data classification\n  * Directional flow of data\n  * Trust boundary traversal\n  * Authentication requirements\n* Includes a comprehensive auditing workflow for triaging results\n* Configurable notifications supporting Slack, Microsoft Teams, Mattermost, Webhooks, Webex, Email and Jira\n* Supports standardized SPDX license ID‚Äôs and tracks license use by component\n* Easy to read metrics for components, projects, and portfolio\n* Native support for Kenna Security, Fortify SSC, ThreadFix, and DefectDojo\n* API-first design facilitates easy integration with other systems\n* API documentation available in OpenAPI format\n* OAuth 2.0 + OpenID Connect (OIDC) support for single sign-on (authN/authZ)\n* Supports internally managed users, Active Directory/LDAP, and API Keys\n* Simple to install and configure. Get up and running in just a few minutes\n\n\n<hr>\n\n![alt text](./docs/images/screenshots/dashboard.png)\n\n### Quickstart (Docker Compose)\n\n```bash\n# Downloads the latest Docker Compose file\ncurl -LO https://dependencytrack.org/docker-compose.yml\n\n# Starts the stack using Docker Compose\ndocker compose up -d\n```\n\n### Quickstart (Docker Swarm)\n\n```bash\n# Downloads the latest Docker Compose file\ncurl -LO https://dependencytrack.org/docker-compose.yml\n\n# Initializes Docker Swarm (if not previously initialized)\ndocker swarm init\n\n# Starts the stack using Docker Swarm\ndocker stack deploy -c docker-compose.yml dtrack\n```\n\n### Quickstart (Manual Execution)\n\n```bash\n# Pull the image from the Docker Hub OWASP repo\ndocker pull dependencytrack/bundled\n\n# Creates a dedicated volume where data can be stored outside the container\ndocker volume create --name dependency-track\n\n# Run the bundled container with 8GB RAM on port 8080\ndocker run -d -m 8192m -p 8080:8080 --name dependency-track -v dependency-track:/data dependencytrack/bundled\n```\n\n**NOTICE: Always use official binary releases in production.**\n\n## Distributions\n\nDependency-Track has three distribution variants. They are:\n\n| Package    | Package Format          | Recommended | Supported | Docker | Download |\n|:-----------|:------------------------|:-----------:|:---------:|:------:|:--------:|\n| API Server | Executable WAR          |      ‚úÖ      |     ‚úÖ     |   ‚úÖ    |    ‚úÖ     |\n| Frontend   | Single Page Application |      ‚úÖ      |     ‚úÖ     |   ‚úÖ    |    ‚úÖ     |\n| Bundled    | Executable WAR          |      ‚ùå      |    ‚òëÔ∏è     |   ‚úÖ    |    ‚úÖ     |\n\n#### API Server\n\nThe API Server contains an embedded Jetty server and all server-side functionality, but excludes the frontend user\ninterface. This variant is new as of Dependency-Track v4.0.\n\n#### Frontend\n\nThe [Frontend](https://github.com/DependencyTrack/frontend) is the user interface that is accessible in a web browser. The Frontend is a Single Page Application (SPA)\nthat can be deployed independently of the Dependency-Track API Server. This variant is new as of Dependency-Track v3.8.\n\n#### Bundled\n\nThe Bundled variant combines the API Server and the Frontend user interface. This variant was previously referred to as\nthe executable war and was the preferred distribution from Dependency-Track v3.0 - v3.8. This variant is supported but\ndeprecated and will be discontinued in a future release.\n\n#### Traditional\n\nThe Traditional variant combines the API Server and the Frontend user interface and must be deployed to a Servlet\ncontainer. This variant is not supported, deprecated, and will be discontinued in a future release.\n\n## Deploying on Kubernetes with Helm\n\nRefer to https://github.com/DependencyTrack/helm-charts.\n\n## Contributing\n\nInterested in contributing to Dependency-Track? Please check [`CONTRIBUTING.md`](./CONTRIBUTING.md) to see how you can help!\n\n## Resources\n\n* Website: <https://dependencytrack.org/>\n* Documentation: <https://docs.dependencytrack.org/>\n* Component Analysis: <https://owasp.org/www-community/Component_Analysis>\n\n## Community\n\n* Twitter: <https://dependencytrack.org/twitter>\n* YouTube: <https://dependencytrack.org/youtube>\n* Slack: <https://dependencytrack.org/slack> (Invite:  <https://dependencytrack.org/slack/invite>)\n* Discussion (Groups.io): <https://dependencytrack.org/discussion>\n\n## Copyright & License\nDependency-Track is Copyright (c) OWASP Foundation. All Rights Reserved.\n\nPermission to modify and redistribute is granted under the terms of the\n[Apache License 2.0].\n\nDependency-Track makes use of several other open source libraries. Please see\nthe [notices] file for more information.\n\n  [National Vulnerability Database]: https://nvd.nist.gov\n  [GitHub Advisories]: https://www.github.com/advisories\n  [Sonatype OSS Index]: https://ossindex.sonatype.org\n  [Snyk]: https://snyk.io\n  [Trivy]: https://www.aquasec.com/products/trivy/\n  [OSV]: https://osv.dev\n  [VulnDB]: https://vulndb.cyberriskanalytics.com\n  [Risk Based Security]: https://www.riskbasedsecurity.com\n  [Component Analysis]: https://owasp.org/www-community/Component_Analysis\n  [Software Bill of Materials]: https://owasp.org/www-community/Component_Analysis#software-bill-of-materials-sbom\n  [CycloneDX]: https://cyclonedx.org\n  [license-image]: https://img.shields.io/badge/license-apache%20v2-brightgreen.svg\n  [Apache License 2.0]: https://github.com/DependencyTrack/dependency-track/blob/master/LICENSE.txt\n  [notices]: https://github.com/DependencyTrack/dependency-track/blob/master/NOTICES.txt\n  [Alpine]: https://github.com/stevespringett/Alpine\n",
      "stars_today": 3
    },
    {
      "id": 962090208,
      "name": "rocm-systems",
      "full_name": "ROCm/rocm-systems",
      "description": "super repo for rocm systems projects",
      "html_url": "https://github.com/ROCm/rocm-systems",
      "stars": 219,
      "forks": 111,
      "language": "C++",
      "topics": [],
      "created_at": "2025-04-07T16:23:38Z",
      "updated_at": "2026-01-23T20:56:34Z",
      "pushed_at": "2026-01-24T02:02:37Z",
      "open_issues": 917,
      "owner": {
        "login": "ROCm",
        "avatar_url": "https://avatars.githubusercontent.com/u/21157610?v=4"
      },
      "readme": "# ROCm Systems\n\nWelcome to the ROCm Systems super-repo. This repository consolidates multiple ROCm systems projects into a single repository to streamline development, CI, and integration. The first set of projects focuses on requirements for building PyTorch.\n\n# Super-repo Status and CI Health\n\nThis table provides the current status of the migration of specific ROCm systems projects as well as a pointer to their current CI health.\n\n**Key:**\n- **Completed**: Fully migrated and integrated. This super-repo should be considered the source of truth for this project. The old repo may still be used for release activities.\n- **In Progress**: Ongoing migration, tests, or integration. Please refrain from submitting new pull requests on the individual repo of the project, and develop on the super-repo.\n- **Pending**: Not yet started or in the early planning stages. The individual repo should be considered the source of truth for this project.\n\n| Component              | Source of Truth | Migration Status | Azure CI Status                       | Component CI Status                   |\n|------------------------|-----------------|------------------|---------------------------------------|---------------------------------------|\n| `amdsmi`               | EMU             | Pending          |                                       |                                       |\n| `aqlprofile`           | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Faqlprofile?repoName=ROCm%2Frocm-systems&branchName=refs%2Fpull%2F368%2Fmerge)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=365&repoName=ROCm%2Frocm-systems&branchName=refs%2Fpull%2F368%2Fmerge) | [![CodeQL](https://github.com/ROCm/rocm-systems/actions/workflows/aqlprofile-codeql.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/aqlprofile-codeql.yml) <br> [![Continuous Integration](https://github.com/ROCm/rocm-systems/actions/workflows/aqlprofile-continuous_integration.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/aqlprofile-continuous_integration.yml) |\n| `clr`                  | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Fhip-clr?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=335&repoName=ROCm%2Frocm-systems&branchName=develop) |                                       |\n| `hip`                  | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Fhip-clr?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=335&repoName=ROCm%2Frocm-systems&branchName=develop) |                                       |\n| `hipother`             | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Fhip-clr?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=335&repoName=ROCm%2Frocm-systems&branchName=develop) |                                       |\n| `hip-tests`            | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Fhip-tests?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=362&repoName=ROCm%2Frocm-systems&branchName=develop) |                                       |\n| `rdc`                  | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Frdc?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=360&repoName=ROCm%2Frocm-systems&branchName=develop) |                                       |\n| `rocm-core`            | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Frocm-core?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=349&repoName=ROCm%2Frocm-systems&branchName=develop) |                                       |\n| `rocminfo`             | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Frocminfo?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=356&repoName=ROCm%2Frocm-systems&branchName=develop) |                                       |\n| `rocm-smi-lib`         | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Frocm-smi-lib?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=358&repoName=ROCm%2Frocm-systems&branchName=develop) |                                       |\n| `rocprofiler`          | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Frocprofiler?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=329&repoName=ROCm%2Frocm-systems&branchName=develop) |                                       |\n| `rocprofiler-compute`  | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Frocprofiler-compute?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=344&repoName=ROCm%2Frocm-systems&branchName=develop) | [![Formatting](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-compute-formatting.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-compute-formatting.yml) <br> [![ rhel-8](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-compute-rhel-8.yml/badge.svg)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-compute-rhel-8.yml) <br> [![tarball](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-compute-tarball.yml/badge.svg)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-compute-tarball.yml) <br> [![ubuntu jammy](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-compute-ubuntu-jammy.yml/badge.svg)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-compute-ubuntu-jammy.yml) |\n| `rocprofiler-register` | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Frocprofiler-register?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=327&repoName=ROCm%2Frocm-systems&branchName=develop) | [![Continuous Integration](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-register-continuous-integration.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-register-continuous-integration.yml) |\n| `rocprofiler-sdk`      | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Frocprofiler-sdk?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=347&repoName=ROCm%2Frocm-systems&branchName=develop) | [![Code Coverage Integration](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-code_coverage.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-code_coverage.yml) <br> [![CodeQL](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-codeql.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-codeql.yml) <br> [![Continuous Integration](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-continuous_integration.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-continuous_integration.yml) <br> [![Documentation](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-docs.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-docs.yml) <br> [![Formatting](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-formatting.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-formatting.yml) <br> [![Python Linting](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-python.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-python.yml) <br> [![Restrictions](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-restrictions.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-restrictions.yml) <br> [![Release Compatibility](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-rocm_release_compatibility.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-rocm_release_compatibility.yml) |\n| `rocprofiler-systems`  | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Frocprofiler-systems?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=345&repoName=ROCm%2Frocm-systems&branchName=develop) | [![Containers](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-containers.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-containers.yml) <br> [![rocprofiler-systems GHCR Packages for CI Images](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-ghcr.yml/badge.svg)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-ghcr.yml) <br> [![CPack](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-cpack.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-cpack.yml) <br> [![Formatting](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-formatting.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-formatting.yml) <br> [![OpenSUSE](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-opensuse.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-opensuse.yml) <br> [![Python Linting](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-python.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-python.yml) <br> [![RedHat Linux](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-redhat.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-redhat.yml) <br> [![Ubuntu Jammy](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-ubuntu-jammy.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-ubuntu-jammy.yml) <br> [![Ubuntu Noble](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-ubuntu-noble.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-ubuntu-noble.yml) |\n| `rocr-runtime`         | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Frocr-runtime?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=354&repoName=ROCm%2Frocm-systems&branchName=develop) |                                       |\n| `roctracer`            | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Froctracer?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=331&repoName=ROCm%2Frocm-systems&branchName=develop) |                                       |\n\n\n## Tentative migration schedule\n\n| Component              | Tentative Date |\n|------------------------|----------------|\n\n\n*Remaining schedule to be determined.\n\n# TheRock CI Status\n\nNote TheRock CI performs multi-component testing on top of builds leveraging [TheRock](https://github.com/ROCm/TheRock) build system.\n\n[![The Rock CI](https://github.com/ROCm/rocm-systems/actions/workflows/therock-ci.yml/badge.svg?branch%3Adevelop+event%3Apush)](https://github.com/ROCm/rocm-systems/actions/workflows/therock-ci.yml?query=branch%3Adevelop+event%3Apush)\n\n---\n\n## Nomenclature\n\nProject names have been standardized to match the casing and punctuation of released packages. This removes inconsistent camel-casing and underscores used in legacy repositories.\n\n## Structure\n\nThe repository is organized as follows:\n\n```\nprojects/\n  amdsmi/\n  aqlprofile/\n  clr/\n  hip/\n  hipother/\n  hip-tests/\n  rccl/\n  rdc/\n  rocm-core\n  rocminfo/\n  rocmsmilib/\n  rocprofiler/\n  rocprofiler-compute/\n  rocprofiler-register/\n  rocprofiler-sdk/\n  rocprofiler-systems/\n  rocrruntime/\n  rocshmem/\n  roctracer/\n```\n\n- Each folder under `projects/` corresponds to a ROCm systems project that was previously maintained in a standalone GitHub repository and released as distinct packages.\n- Each folder under `shared/` contains code that existed in its own repository and is used as a dependency by multiple projects, but does not produce its own distinct packages in previous ROCm releases.\n\n## Goals\n\n- Enable unified build and test workflows across ROCm libraries.\n- Facilitate shared tooling, CI, and contributor experience.\n- Improve integration, visibility, and collaboration across ROCm library teams.\n\n## Getting Started\n\nTo begin contributing or building, see the [CONTRIBUTING.md](./CONTRIBUTING.md) guide. It includes setup instructions, sparse-checkout configuration, development workflow, and pull request guidelines.\n\n## License\n\nThis super-repo contains multiple subprojects, each of which retains the license under which it was originally published.\n\nüìÅ Refer to the `LICENSE`, `LICENSE.md`, or `LICENSE.txt` file within each `projects/` or `shared/` directory for specific license terms.\nüìÑ Refer to the header notice in individual files outside `projects/` or `shared/` folders for their specific license terms.\n\n> **Note**: The root of this repository does not define a unified license across all components.\n\n## Questions or Feedback?\n\n- üí¨ [Start a discussion](https://github.com/ROCm/rocm-systems/discussions)\n- üêû [Open an issue](https://github.com/ROCm/rocm-systems/issues)\n\nWe're happy to help!\n",
      "stars_today": 3
    },
    {
      "id": 51148780,
      "name": "architecture-samples",
      "full_name": "android/architecture-samples",
      "description": "A collection of samples to discuss and showcase different architectural tools and patterns for Android apps.",
      "html_url": "https://github.com/android/architecture-samples",
      "stars": 45528,
      "forks": 11848,
      "language": "Kotlin",
      "topics": [
        "android",
        "android-architecture",
        "samples"
      ],
      "created_at": "2016-02-05T13:42:07Z",
      "updated_at": "2026-01-23T16:41:44Z",
      "pushed_at": "2026-01-23T01:33:44Z",
      "open_issues": 216,
      "owner": {
        "login": "android",
        "avatar_url": "https://avatars.githubusercontent.com/u/32689599?v=4"
      },
      "readme": "# Android Architecture Samples\n\nThese samples showcase different architectural approaches to developing Android apps. In its different branches you'll find the same app (a TODO app) implemented with small differences.\n\nIn this branch you'll find:\n*   User Interface built with **[Jetpack Compose](https://developer.android.com/jetpack/compose)** \n*   A single-activity architecture, using **[Navigation Compose](https://developer.android.com/jetpack/compose/navigation)**.\n*   A presentation layer that contains a Compose screen (View) and a **ViewModel** per screen (or feature).\n*   Reactive UIs using **[Flow](https://developer.android.com/kotlin/flow)** and **[coroutines](https://kotlinlang.org/docs/coroutines-overview.html)** for asynchronous operations.\n*   A **data layer** with a repository and two data sources (local using Room and a fake remote).\n*   Two **product flavors**, `mock` and `prod`, [to ease development and testing](https://android-developers.googleblog.com/2015/12/leveraging-product-flavors-in-android.html).\n*   A collection of unit, integration and e2e **tests**, including \"shared\" tests that can be run on emulator/device.\n*   Dependency injection using [Hilt](https://developer.android.com/training/dependency-injection/hilt-android).\n\n## Screenshots\n\n<img src=\"screenshots/screenshots.png\" alt=\"Screenshot\">\n\n## Why a to-do app?\n\nThe app in this project aims to be simple enough that you can understand it quickly, but complex enough to showcase difficult design decisions and testing scenarios. For more information, see the [app's specification](https://github.com/googlesamples/android-architecture/wiki/To-do-app-specification).\n\n## What is it not?\n*   A template. Check out the [Architecture Templates](https://github.com/android/architecture-templates) instead.\n*   A UI/Material Design sample. The interface of the app is deliberately kept simple to focus on architecture. Check out the [Compose Samples](https://github.com/android/compose-samples) instead.\n*   A real production app with network access, user authentication, etc. Check out the [Now in Android app](https://github.com/android/nowinandroid) instead.\n\n## Who is it for?\n\n*   Intermediate developers and beginners looking for a way to structure their app in a testable and maintainable way.\n*   Advanced developers looking for quick reference.\n\n## Opening a sample in Android Studio\n\nTo open one of the samples in Android Studio, begin by checking out one of the sample branches, and then open the root directory in Android Studio. The following series of steps illustrate how to open the sample.\n\nClone the repository:\n\n```\ngit clone git@github.com:android/architecture-samples.git\n```\n\nFinally open the `architecture-samples/` directory in Android Studio.\n\n### License\n\n\n```\nCopyright 2024 Google, Inc.\n\nLicensed to the Apache Software Foundation (ASF) under one or more contributor\nlicense agreements. See the NOTICE file distributed with this work for\nadditional information regarding copyright ownership. The ASF licenses this\nfile to you under the Apache License, Version 2.0 (the \"License\"); you may not\nuse this file except in compliance with the License. You may obtain a copy of\nthe License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\nWARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\nLicense for the specific language governing permissions and limitations under\nthe License.\n```\n",
      "stars_today": 2
    },
    {
      "id": 75164823,
      "name": "rocketmq",
      "full_name": "apache/rocketmq",
      "description": "Apache RocketMQ is a cloud native messaging and streaming platform, making it simple to build event-driven applications.",
      "html_url": "https://github.com/apache/rocketmq",
      "stars": 22309,
      "forks": 12008,
      "language": "Java",
      "topics": [
        "cloud-native",
        "eventing",
        "hacktoberfest",
        "java",
        "messaging",
        "rocketmq",
        "streaming"
      ],
      "created_at": "2016-11-30T08:00:08Z",
      "updated_at": "2026-01-23T20:54:28Z",
      "pushed_at": "2026-01-22T03:55:56Z",
      "open_issues": 293,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "## Apache RocketMQ\n\n[![Build Status][maven-build-image]][maven-build-url]\n[![CodeCov][codecov-image]][codecov-url]\n[![Maven Central][maven-central-image]][maven-central-url]\n[![Release][release-image]][release-url]\n[![License][license-image]][license-url]\n[![Average Time to Resolve An Issue][average-time-to-resolve-an-issue-image]][average-time-to-resolve-an-issue-url]\n[![Percentage of Issues Still Open][percentage-of-issues-still-open-image]][percentage-of-issues-still-open-url]\n[![Twitter Follow][twitter-follow-image]][twitter-follow-url]\n\n**[Apache RocketMQ](https://rocketmq.apache.org) is a distributed messaging and streaming platform with low latency, high performance and reliability, trillion-level capacity and flexible scalability.**\n\n\nIt offers a variety of features:\n\n* Messaging patterns including publish/subscribe, request/reply and streaming\n* Financial grade transactional message\n* Built-in fault tolerance and high availability configuration options based on [DLedger Controller](docs/en/controller/quick_start.md)\n* Built-in message tracing capability, also supports opentracing\n* Versatile big-data and streaming ecosystem integration\n* Message retroactivity by time or offset\n* Reliable FIFO and strict ordered messaging in the same queue\n* Efficient pull and push consumption model\n* Million-level message accumulation capacity in a single queue\n* Multiple messaging protocols like gRPC, MQTT, JMS and OpenMessaging\n* Flexible distributed scale-out deployment architecture\n* Lightning-fast batch message exchange system\n* Various message filter mechanics such as SQL and Tag\n* Docker images for isolated testing and cloud isolated clusters\n* Feature-rich administrative dashboard for configuration, metrics and monitoring\n* Authentication and authorization\n* Free open source connectors, for both sources and sinks\n* Lightweight real-time computing\n----------\n\n\n## Quick Start\n\nThis paragraph guides you through steps of installing RocketMQ in different ways.\nFor local development and testing, only one instance will be created for each component.\n\n### Run RocketMQ locally\n\nRocketMQ runs on all major operating systems and requires only a Java JDK version 8 or higher to be installed.\nTo check, run `java -version`:\n```shell\n$ java -version\njava version \"1.8.0_121\"\n```\n\nFor Windows users, click [here](https://dist.apache.org/repos/dist/release/rocketmq/5.4.0/rocketmq-all-5.4.0-bin-release.zip) to download the 5.4.0 RocketMQ binary release,\nunpack it to your local disk, such as `D:\\rocketmq`.\nFor macOS and Linux users, execute following commands:\n\n```shell\n# Download release from the Apache mirror\n$ wget https://dist.apache.org/repos/dist/release/rocketmq/5.4.0/rocketmq-all-5.4.0-bin-release.zip\n\n# Unpack the release\n$ unzip rocketmq-all-5.4.0-bin-release.zip\n```\n\nPrepare a terminal and change to the extracted `bin` directory:\n```shell\n$ cd rocketmq-all-5.4.0-bin-release/bin\n```\n\n**1) Start NameServer**\n\nNameServer will be listening at `0.0.0.0:9876`, make sure that the port is not used by others on the local machine, and then do as follows.\n\nFor macOS and Linux users:\n```shell\n### start Name Server\n$ nohup sh mqnamesrv &\n\n### check whether Name Server is successfully started\n$ tail -f ~/logs/rocketmqlogs/namesrv.log\nThe Name Server boot success...\n```\n\nFor Windows users, you need to set environment variables first:\n- From the desktop, right click the Computer icon.\n- Choose Properties from the context menu.\n- Click the Advanced system settings link.\n- Click Environment Variables.\n- Add Environment `ROCKETMQ_HOME=\"D:\\rocketmq\"`. \n\nThen change directory to rocketmq, type and run:\n```shell\n$ mqnamesrv.cmd\nThe Name Server boot success...\n```\n\n**2) Start Broker**\n\nFor macOS and Linux users:\n```shell\n### start Broker\n$ nohup sh mqbroker -n localhost:9876 &\n\n### check whether Broker is successfully started, eg: Broker's IP is 192.168.1.2, Broker's name is broker-a\n$ tail -f ~/logs/rocketmqlogs/broker.log\nThe broker[broker-a, 192.168.1.2:10911] boot success...\n```\n\nFor Windows users:\n```shell\n$ mqbroker.cmd -n localhost:9876\nThe broker[broker-a, 192.168.1.2:10911] boot success...\n```\n\n### Run RocketMQ in Docker\n\nYou can run RocketMQ on your own machine within Docker containers,\n`host` network will be used to expose listening port in the container.\n\n**1) Start NameServer**\n\n```shell\n$ docker run -it --net=host apache/rocketmq ./mqnamesrv\n```\n\n**2) Start Broker**\n\n```shell\n$ docker run -it --net=host --mount type=bind,source=/tmp/store,target=/home/rocketmq/store apache/rocketmq ./mqbroker -n localhost:9876\n```\n\n### Run RocketMQ in Kubernetes\n\nYou can also run a RocketMQ cluster within a Kubernetes cluster using [RocketMQ Operator](https://github.com/apache/rocketmq-operator).\nBefore your operations, make sure that `kubectl` and related kubeconfig file installed on your machine.\n\n**1) Install CRDs**\n```shell\n### install CRDs\n$ git clone https://github.com/apache/rocketmq-operator\n$ cd rocketmq-operator && make deploy\n\n### check whether CRDs are successfully installed\n$ kubectl get crd | grep rocketmq.apache.org\nbrokers.rocketmq.apache.org                 2022-05-12T09:23:18Z\nconsoles.rocketmq.apache.org                2022-05-12T09:23:19Z\nnameservices.rocketmq.apache.org            2022-05-12T09:23:18Z\ntopictransfers.rocketmq.apache.org          2022-05-12T09:23:19Z\n\n### check whether operator is running\n$ kubectl get pods | grep rocketmq-operator\nrocketmq-operator-6f65c77c49-8hwmj   1/1     Running   0          93s\n```\n\n**2) Create Cluster Instance**\n```shell\n### create RocketMQ cluster resource\n$ cd example && kubectl create -f rocketmq_v1alpha1_rocketmq_cluster.yaml\n\n### check whether cluster resources are running\n$ kubectl get sts\nNAME                 READY   AGE\nbroker-0-master      1/1     107m\nbroker-0-replica-1   1/1     107m\nname-service         1/1     107m\n```\n\n---\n## Apache RocketMQ Community\n* [RocketMQ Streams](https://github.com/apache/rocketmq-streams): A lightweight stream computing engine based on Apache RocketMQ.\n* [RocketMQ Flink](https://github.com/apache/rocketmq-flink): The Apache RocketMQ connector of Apache Flink that supports source and sink connector in data stream and Table.\n* [RocketMQ APIs](https://github.com/apache/rocketmq-apis): RocketMQ protobuf protocol.\n* [RocketMQ Clients](https://github.com/apache/rocketmq-clients): gRPC/protobuf-based RocketMQ clients.\n* RocketMQ Remoting-based Clients\n\t - [RocketMQ Client CPP](https://github.com/apache/rocketmq-client-cpp)\n\t - [RocketMQ Client Go](https://github.com/apache/rocketmq-client-go)\n\t - [RocketMQ Client Python](https://github.com/apache/rocketmq-client-python)\n\t - [RocketMQ Client Nodejs](https://github.com/apache/rocketmq-client-nodejs)\n* [RocketMQ Spring](https://github.com/apache/rocketmq-spring): A project which helps developers quickly integrate Apache RocketMQ with Spring Boot.\n* [RocketMQ Exporter](https://github.com/apache/rocketmq-exporter): An Apache RocketMQ exporter for Prometheus.\n* [RocketMQ Operator](https://github.com/apache/rocketmq-operator): Providing a way to run an Apache RocketMQ cluster on Kubernetes.\n* [RocketMQ Docker](https://github.com/apache/rocketmq-docker): The Git repo of the Docker Image for Apache RocketMQ.\n* [RocketMQ Dashboard](https://github.com/apache/rocketmq-dashboard): Operation and maintenance console of Apache RocketMQ.\n* [RocketMQ Connect](https://github.com/apache/rocketmq-connect): A tool for scalably and reliably streaming data between Apache RocketMQ and other systems.\n* [RocketMQ MQTT](https://github.com/apache/rocketmq-mqtt): A new MQTT protocol architecture model, based on which Apache RocketMQ can better support messages from terminals such as IoT devices and Mobile APP.\n* [RocketMQ EventBridge](https://github.com/apache/rocketmq-eventbridge): EventBridge makes it easier to build an event-driven application.\n* [RocketMQ Incubating Community Projects](https://github.com/apache/rocketmq-externals): Incubator community projects of Apache RocketMQ, including [logappender](https://github.com/apache/rocketmq-externals/tree/master/logappender), [rocketmq-ansible](https://github.com/apache/rocketmq-externals/tree/master/rocketmq-ansible), [rocketmq-beats-integration](https://github.com/apache/rocketmq-externals/tree/master/rocketmq-beats-integration), [rocketmq-cloudevents-binding](https://github.com/apache/rocketmq-externals/tree/master/rocketmq-cloudevents-binding), etc.\n* [RocketMQ Site](https://github.com/apache/rocketmq-site): The repository for Apache RocketMQ website.\n* [RocketMQ E2E](https://github.com/apache/rocketmq-e2e): A project for testing Apache RocketMQ, including end-to-end, performance, compatibility tests.\n\n\n----------\n## Learn it & Contact us\n* Mailing Lists: <https://rocketmq.apache.org/about/contact/>\n* Home: <https://rocketmq.apache.org>\n* Docs: <https://rocketmq.apache.org/docs/quick-start/>\n* Issues: <https://github.com/apache/rocketmq/issues>\n* Rips: <https://github.com/apache/rocketmq/wiki/RocketMQ-Improvement-Proposal>\n* Ask: <https://stackoverflow.com/questions/tagged/rocketmq>\n* Slack: <https://rocketmq-invite-automation.herokuapp.com/>\n\n\n----------\n\n\n\n## Contributing\nWe always welcome new contributions, whether for trivial cleanups, [big new features](https://github.com/apache/rocketmq/wiki/RocketMQ-Improvement-Proposal) or other material rewards, more details see [here](http://rocketmq.apache.org/docs/how-to-contribute/).\n\n----------\n## License\n[Apache License, Version 2.0](http://www.apache.org/licenses/LICENSE-2.0.html) Copyright (C) Apache Software Foundation\n\n\n----------\n## Export Control Notice\nThis distribution includes cryptographic software. The country in which you currently reside may have\nrestrictions on the import, possession, use, and/or re-export to another country, of encryption software.\nBEFORE using any encryption software, please check your country's laws, regulations and policies concerning\nthe import, possession, or use, and re-export of encryption software, to see if this is permitted. See\n<http://www.wassenaar.org/> for more information.\n\nThe U.S. Government Department of Commerce, Bureau of Industry and Security (BIS), has classified this\nsoftware as Export Commodity Control Number (ECCN) 5D002.C.1, which includes information security software\nusing or performing cryptographic functions with asymmetric algorithms. The form and manner of this Apache\nSoftware Foundation distribution makes it eligible for export under the License Exception ENC Technology\nSoftware Unrestricted (TSU) exception (see the BIS Export Administration Regulations, Section 740.13) for\nboth object code and source code.\n\nThe following provides more details on the included cryptographic software:\n\nThis software uses Apache Commons Crypto (https://commons.apache.org/proper/commons-crypto/) to\nsupport authentication, and encryption and decryption of data sent across the network between\nservices.\n\n[maven-build-image]: https://github.com/apache/rocketmq/actions/workflows/maven.yaml/badge.svg\n[maven-build-url]: https://github.com/apache/rocketmq/actions/workflows/maven.yaml\n[codecov-image]: https://codecov.io/gh/apache/rocketmq/branch/master/graph/badge.svg\n[codecov-url]: https://codecov.io/gh/apache/rocketmq\n[maven-central-image]: https://maven-badges.herokuapp.com/maven-central/org.apache.rocketmq/rocketmq-all/badge.svg\n[maven-central-url]: http://search.maven.org/#search%7Cga%7C1%7Corg.apache.rocketmq\n[release-image]: https://img.shields.io/badge/release-download-orange.svg\n[release-url]: https://rocketmq.apache.org/download/\n[license-image]: https://img.shields.io/badge/license-Apache%202-4EB1BA.svg\n[license-url]: https://www.apache.org/licenses/LICENSE-2.0.html\n[average-time-to-resolve-an-issue-image]: http://isitmaintained.com/badge/resolution/apache/rocketmq.svg\n[average-time-to-resolve-an-issue-url]: http://isitmaintained.com/project/apache/rocketmq\n[percentage-of-issues-still-open-image]: http://isitmaintained.com/badge/open/apache/rocketmq.svg\n[percentage-of-issues-still-open-url]: http://isitmaintained.com/project/apache/rocketmq\n[twitter-follow-image]: https://img.shields.io/twitter/follow/ApacheRocketMQ?style=social\n[twitter-follow-url]: https://twitter.com/intent/follow?screen_name=ApacheRocketMQ\n",
      "stars_today": 2
    },
    {
      "id": 196353673,
      "name": "TDengine",
      "full_name": "taosdata/TDengine",
      "description": "High-performance, scalable time-series database designed for Industrial IoT (IIoT) scenarios",
      "html_url": "https://github.com/taosdata/TDengine",
      "stars": 24690,
      "forks": 4989,
      "language": "C",
      "topics": [
        "bigdata",
        "cloud-native",
        "cluster",
        "connected-vehicles",
        "database",
        "distributed",
        "financial-analysis",
        "industrial-iot",
        "iot",
        "metrics",
        "monitoring",
        "scalability",
        "sql",
        "tdengine",
        "time-series",
        "time-series-database",
        "tsdb"
      ],
      "created_at": "2019-07-11T08:33:48Z",
      "updated_at": "2026-01-23T10:25:10Z",
      "pushed_at": "2026-01-23T13:51:31Z",
      "open_issues": 478,
      "owner": {
        "login": "taosdata",
        "avatar_url": "https://avatars.githubusercontent.com/u/48876650?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://tdengine.com\" target=\"_blank\">\n  <img\n    src=\"docs/assets/tdengine.svg\"\n    alt=\"TDengine\"\n    width=\"500\"\n  />\n  </a>\n</p>\n\n[![TDengine Release Build](https://github.com/taosdata/TDengine/actions/workflows/tdengine-release-build.yml/badge.svg)](https://github.com/taosdata/TDengine/actions/workflows/tdengine-release-build.yml)\n[![Coverage Status](https://coveralls.io/repos/github/taosdata/TDengine/badge.svg?branch=3.0)](https://coveralls.io/github/taosdata/TDengine?branch=3.0)\n[![GitHub commit activity](https://img.shields.io/github/commit-activity/m/taosdata/tdengine)](https://github.com/feici02/TDengine/commits/main/)\n<br />\n[![GitHub Release](https://img.shields.io/github/v/release/taosdata/tdengine)](https://github.com/taosdata/TDengine/releases)\n[![GitHub License](https://img.shields.io/github/license/taosdata/tdengine)](https://github.com/taosdata/TDengine/blob/main/LICENSE)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/4201/badge)](https://bestpractices.coreinfrastructure.org/projects/4201)\n<br />\n[![Twitter Follow](https://img.shields.io/twitter/follow/tdenginedb?label=TDengine&style=social)](https://twitter.com/tdenginedb)\n[![YouTube Channel](https://img.shields.io/badge/Subscribe_@tdengine--white?logo=youtube&style=social)](https://www.youtube.com/@tdengine)\n[![Discord Community](https://img.shields.io/badge/Join_Discord--white?logo=discord&style=social)](https://discord.com/invite/VZdSuUg4pS)\n[![LinkedIn](https://img.shields.io/badge/Follow_LinkedIn--white?logo=linkedin&style=social)](https://www.linkedin.com/company/tdengine)\n[![StackOverflow](https://img.shields.io/badge/Ask_StackOverflow--white?logo=stackoverflow&style=social&logoColor=orange)](https://stackoverflow.com/questions/tagged/tdengine)\n[![DeepWiki](https://img.shields.io/badge/Ask%20DeepWiki-white.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAyCAYAAAAnWDnqAAAAAXNSR0IArs4c6QAAA05JREFUaEPtmUtyEzEQhtWTQyQLHNak2AB7ZnyXZMEjXMGeK/AIi+QuHrMnbChYY7MIh8g01fJoopFb0uhhEqqcbWTp06/uv1saEDv4O3n3dV60RfP947Mm9/SQc0ICFQgzfc4CYZoTPAswgSJCCUJUnAAoRHOAUOcATwbmVLWdGoH//PB8mnKqScAhsD0kYP3j/Yt5LPQe2KvcXmGvRHcDnpxfL2zOYJ1mFwrryWTz0advv1Ut4CJgf5uhDuDj5eUcAUoahrdY/56ebRWeraTjMt/00Sh3UDtjgHtQNHwcRGOC98BJEAEymycmYcWwOprTgcB6VZ5JK5TAJ+fXGLBm3FDAmn6oPPjR4rKCAoJCal2eAiQp2x0vxTPB3ALO2CRkwmDy5WohzBDwSEFKRwPbknEggCPB/imwrycgxX2NzoMCHhPkDwqYMr9tRcP5qNrMZHkVnOjRMWwLCcr8ohBVb1OMjxLwGCvjTikrsBOiA6fNyCrm8V1rP93iVPpwaE+gO0SsWmPiXB+jikdf6SizrT5qKasx5j8ABbHpFTx+vFXp9EnYQmLx02h1QTTrl6eDqxLnGjporxl3NL3agEvXdT0WmEost648sQOYAeJS9Q7bfUVoMGnjo4AZdUMQku50McDcMWcBPvr0SzbTAFDfvJqwLzgxwATnCgnp4wDl6Aa+Ax283gghmj+vj7feE2KBBRMW3FzOpLOADl0Isb5587h/U4gGvkt5v60Z1VLG8BhYjbzRwyQZemwAd6cCR5/XFWLYZRIMpX39AR0tjaGGiGzLVyhse5C9RKC6ai42ppWPKiBagOvaYk8lO7DajerabOZP46Lby5wKjw1HCRx7p9sVMOWGzb/vA1hwiWc6jm3MvQDTogQkiqIhJV0nBQBTU+3okKCFDy9WwferkHjtxib7t3xIUQtHxnIwtx4mpg26/HfwVNVDb4oI9RHmx5WGelRVlrtiw43zboCLaxv46AZeB3IlTkwouebTr1y2NjSpHz68WNFjHvupy3q8TFn3Hos2IAk4Ju5dCo8B3wP7VPr/FGaKiG+T+v+TQqIrOqMTL1VdWV1DdmcbO8KXBz6esmYWYKPwDL5b5FA1a0hwapHiom0r/cKaoqr+27/XcrS5UwSMbQAAAABJRU5ErkJggg==)](https://deepwiki.com/taosdata/TDengine)\n\nEnglish | [ÁÆÄ‰Ωì‰∏≠Êñá](README-CN.md) | [TDengine Cloud](https://cloud.tdengine.com) | [Learn more about TSDB](https://tdengine.com/time-series-database/)\n\n# Table of Contents\n\n- [1. Introduction](#1-introduction)\n- [2. Documentation](#2-documentation)\n- [3. Prerequisites](#3-prerequisites)\n  - [3.1 Prerequisites on Linux](#31-prerequisites-on-linux)\n    - [3.1.1 For Ubuntu](#311-for-ubuntu)\n    - [3.1.2 For CentOS](#312-for-centos)\n  - [3.2 Prerequisites on macOS](#32-prerequisites-on-macos)\n  - [3.3 Prerequisites on Windows](#33-prerequisites-on-windows)\n  - [3.4 Clone the repo](#34-clone-the-repo)\n- [4. Building](#4-building)\n  - [4.1 Build on Linux](#41-build-on-linux)\n  - [4.2 Build on macOS](#42-build-on-macos)\n  - [4.3 Build on Windows](#43-build-on-windows)\n- [5. Packaging](#5-packaging)\n- [6. Installation](#6-installation)\n  - [6.1 Install on Linux](#61-install-on-linux)\n  - [6.2 Install on macOS](#62-install-on-macos)\n  - [6.3 Install on Windows](#63-install-on-windows)\n- [7. Running](#7-running)\n  - [7.1 Run TDengine on Linux](#71-run-tdengine-on-linux)\n  - [7.2 Run TDengine on macOS](#72-run-tdengine-on-macos)\n  - [7.3 Run TDengine on Windows](#73-run-tdengine-on-windows)\n- [8. Testing](#8-testing)\n- [9. Releasing](#9-releasing)\n- [10. Workflow](#10-workflow)\n- [11. Coverage](#11-coverage)\n- [12. Contributing](#12-contributing)\n\n# 1. Introduction\n\nTDengine is an open source, high-performance, cloud native and AI powered [time-series database](https://tdengine.com/tsdb/) designed for Internet of Things (IoT), Connected Cars, and Industrial IoT. It enables efficient, real-time data ingestion, processing, and analysis of TB and even PB scale data per day, generated by billions of sensors and data collectors. TDengine differentiates itself from other time-series databases with the following advantages:\n\n- **[High Performance](https://tdengine.com/tdengine/high-performance-time-series-database/)**: TDengine is the only time-series database to solve the high cardinality issue to support billions of data collection points while out performing other time-series databases for data ingestion, querying and data compression.\n\n- **[Simplified Solution](https://tdengine.com/tdengine/simplified-time-series-data-solution/)**: Through built-in caching, stream processing, data subscription and AI agent features, TDengine provides a simplified solution for time-series data processing. It reduces system design complexity and operation costs significantly.\n\n- **[Cloud Native](https://tdengine.com/tdengine/cloud-native-time-series-database/)**: Through native distributed design, sharding and partitioning, separation of compute and storage, RAFT, support for kubernetes deployment and full observability, TDengine is a cloud native Time-Series Database and can be deployed on public, private or hybrid clouds.\n\n- **[AI Powered](https://tdengine.com/tdengine/tdgpt/)**: Through the built in AI agent TDgpt, TDengine can connect to a variety of time series foundation model, large language model, machine learning and traditional algorithms to provide time series data forecasting, anomly detection, imputation and classification.\n\n- **[Ease of Use](https://tdengine.com/tdengine/easy-time-series-data-platform/)**: For administrators, TDengine significantly reduces the effort to deploy and maintain. For developers, it provides a simple interface, simplified solution and seamless integrations for third party tools. For data users, it gives easy data access.\n\n- **[Easy Data Analytics](https://tdengine.com/tdengine/time-series-data-analytics-made-easy/)**: Through super tables, storage and compute separation, data partitioning by time interval, pre-computation and AI agent, TDengine makes it easy to explore, format, and get access to data in a highly efficient way.\n\n- **[Open Source](https://tdengine.com/tdengine/open-source-time-series-database/)**: TDengine‚Äôs core modules, including cluster feature and AI agent, are all available under open source licenses. It has gathered 23.7k stars on GitHub. There is an active developer community, and over 730k running instances worldwide.\n\nFor a full list of TDengine competitive advantages, please [check here](https://tdengine.com/tdengine/). The easiest way to experience TDengine is through [TDengine Cloud](https://cloud.tdengine.com). For the latest TDengine component TDgpt, please refer to [TDgpt README](./tools/tdgpt/README.md) for details.\n\n# 2. Documentation\n\nFor user manual, system design and architecture, please refer to [TDengine Documentation](https://docs.tdengine.com) ([TDengine ÊñáÊ°£](https://docs.taosdata.com))\n\nYou can choose to install TDengine via [container](https://docs.tdengine.com/get-started/deploy-in-docker/), [installation package](https://docs.tdengine.com/get-started/deploy-from-package/), [Kubernetes](https://docs.tdengine.com/operations-and-maintenance/deploy-your-cluster/#kubernetes-deployment) or try [fully managed service](https://cloud.tdengine.com/) without installation. This quick guide is for developers who want to contribute, build, release and test TDengine by themselves.\n\nFor contributing/building/testing TDengine Connectors, please check the following repositories: [JDBC Connector](https://github.com/taosdata/taos-connector-jdbc), [Go Connector](https://github.com/taosdata/driver-go), [Python Connector](https://github.com/taosdata/taos-connector-python), [Node.js Connector](https://github.com/taosdata/taos-connector-node), [C# Connector](https://github.com/taosdata/taos-connector-dotnet), [Rust Connector](https://github.com/taosdata/taos-connector-rust).\n\n# 3. Prerequisites\n\nAt the moment, TDengine server supports running on Linux/MacOS systems. Any application can also choose the RESTful interface provided by taosAdapter to connect the taosd service. TDengine supports X64/ARM64 CPU, and it will support MIPS64, Alpha64, ARM32, RISC-V and other CPU architectures in the future. Right now we don't support build with cross-compiling environment.\n\nStarting from version 3.1.0.0, TDengine supports the Windows system exclusively in its TSDB-Enterprise edition.\n\nIf you want to compile taosAdapter or taosKeeper, you need to install Go 1.23 or above.\n\n## 3.1 Prerequisites on Linux\n\n<details>\n\n<summary>Install required tools on Linux</summary>\n\n### 3.1.1 For Ubuntu\n\nVerified on Ubuntu 18.04, 20.04, 22.04.\n\n```bash\nsudo apt-get update\nsudo apt-get install -y gcc cmake build-essential git libjansson-dev \\\n  libsnappy-dev liblzma-dev zlib1g-dev pkg-config libtool autoconf automake groff\n```\n\n### 3.1.2 For CentOS\n\nVerified on CentOS 8.\n\n```bash\nsudo yum update\nyum install -y epel-release gcc gcc-c++ make cmake git perl dnf-plugins-core autoconf automake libtool groff\nyum config-manager --set-enabled powertools\nyum install -y zlib-static xz-devel snappy-devel jansson-devel pkgconfig libatomic-static libstdc++-static \n```\n\n</details>\n\n## 3.2 Prerequisites on macOS\n\n<details>\n\n<summary>Install required tools on macOS</summary>\n\nPlease install the dependencies with [brew](https://brew.sh/).\n\n```bash\nbrew install argp-standalone gflags pkgconfig\n```\n\n</details>\n\n## 3.3 Prerequisites on Windows\n\nNot available for TDengine TSDB-OSS.\n\n## 3.4 Clone the repo\n\nClone the repository to the target machine:\n\n```bash\ngit clone https://github.com/taosdata/TDengine.git\ncd TDengine\n```\n\n</details>\n\n# 4. Building\n\nTDengine provide a few useful tools such as taosBenchmark (was named taosdemo) and taosdump. They were part of TDengine. By default, TDengine compiling does not include taosTools. You can use `cmake .. -DBUILD_TOOLS=true` to make them be compiled with TDengine.\n\nTDengine requires [GCC](https://gcc.gnu.org/) 9.3.1 or higher and [CMake](https://cmake.org/) 3.18.0 or higher for building.\n\n## 4.1 Build on Linux\n\n<details>\n\n<summary>Detailed steps to build on Linux</summary>\n\nYou can run the bash script `build.sh` to build both TDengine and taosTools including taosBenchmark and taosdump as below:\n\n```bash\n./build.sh\n```\n\nIt equals to execute following commands:\n\n```bash\nmkdir debug && cd debug\ncmake .. -DBUILD_TOOLS=true -DBUILD_CONTRIB=true\nmake\n```\n\nIf you want to compile taosAdapter, you need to add the `-DBUILD_HTTP=false` option.\n\nIf you want to compile taosKeeper, you need to add the `-DBUILD_KEEPER=true` option.\n\nYou can use Jemalloc as memory allocator instead of glibc:\n\n```bash\ncmake .. -DJEMALLOC_ENABLED=ON\n```\n\nTDengine build script can auto-detect the host machine's architecture on x86, x86-64, arm64 platform.\nYou can also specify architecture manually by CPUTYPE option:\n\n```bash\ncmake .. -DCPUTYPE=aarch64 && cmake --build .\n```\n\n</details>\n\n## 4.2 Build on macOS\n\n<details>\n\n<summary>Detailed steps to build on macOS</summary>\n\nPlease install XCode command line tools and cmake. Verified with XCode 11.4+ on Catalina and Big Sur.\n\n```shell\nmkdir debug && cd debug\ncmake .. && cmake --build .\n```\n\nIf you want to compile taosAdapter, you need to add the `-DBUILD_HTTP=false` option.\n\nIf you want to compile taosKeeper, you need to add the `-DBUILD_KEEPER=true` option.\n\n</details>\n\n## 4.3 Build on Windows\n\nNot available for TDengine TSDB-OSS.\n\n# 5. Packaging\n\nThe TDengine TSDB-OSS installer can NOT be created by this repository only, due to some component dependencies. We are still working on this improvement.\n\n# 6. Installation\n\n## 6.1 Install on Linux\n\n<details>\n\n<summary>Detailed steps to install on Linux</summary>\n\nAfter building successfully, TDengine can be installed by:\n\n```bash\nsudo make install\n```\n\nInstalling from source code will also configure service management for TDengine. Users can also choose to [install from packages](https://docs.tdengine.com/get-started/deploy-from-package/) for it.\n\n</details>\n\n## 6.2 Install on macOS\n\n<details>\n\n<summary>Detailed steps to install on macOS</summary>\n\nAfter building successfully, TDengine can be installed by:\n\n```bash\nsudo make install\n```\n\n</details>\n\n## 6.3 Install on Windows\n\nNot available for TDengine TSDB-OSS.\n\n# 7. Running\n\n## 7.1 Run TDengine on Linux\n\n<details>\n\n<summary>Detailed steps to run on Linux</summary>\n\nTo start the service after installation on linux, in a terminal, use:\n\n```bash\nsudo systemctl start taosd\n```\n\nThen users can use the TDengine CLI to connect the TDengine server. In a terminal, use:\n\n```bash\ntaos\n```\n\nIf TDengine CLI connects the server successfully, welcome messages and version info are printed. Otherwise, an error message is shown.\n\nIf you don't want to run TDengine as a service, you can run it in current shell. For example, to quickly start a TDengine server after building, run the command below in terminal: (We take Linux as an example, command on Windows will be `taosd.exe`)\n\n```bash\n./build/bin/taosd -c test/cfg\n```\n\nIn another terminal, use the TDengine CLI to connect the server:\n\n```bash\n./build/bin/taos -c test/cfg\n```\n\nOption `-c test/cfg` specifies the system configuration file directory.\n\n</details>\n\n## 7.2 Run TDengine on macOS\n\n<details>\n\n<summary>Detailed steps to run on macOS</summary>\n\nTo start the service after installation on macOS, double-click the /applications/TDengine to start the program, or in a terminal, use:\n\n```bash\nsudo launchctl start com.tdengine.taosd\n```\n\nThen users can use the TDengine CLI to connect the TDengine server. In a terminal, use:\n\n```bash\ntaos\n```\n\nIf TDengine CLI connects the server successfully, welcome messages and version info are printed. Otherwise, an error message is shown.\n\n</details>\n\n## 7.3 Run TDengine on Windows\n\nNot available for TDengine TSDB-OSS.\n\n# 8. Testing\n\nFor how to run different types of tests on TDengine, please see [Testing TDengine](./tests/README.md).\n\n# 9. Releasing\n\nFor the complete list of TDengine Releases, please see [Releases](https://github.com/taosdata/TDengine/releases).\n\n# 10. Workflow\n\nTDengine build check workflow can be found in this [Github Action](https://github.com/taosdata/TDengine/actions/workflows/taosd-ci-build.yml). More workflows will be available soon.\n\n# 11. Coverage\n\nLatest TDengine test coverage report can be found on [coveralls.io](https://coveralls.io/github/taosdata/TDengine)\n\n<details>\n\n<summary>How to run the coverage report locally?</summary>\nTo create the test coverage report (in HTML format) locally, please run following commands:\n\n```bash\ncd tests\nbash setup-lcov.sh -v 1.16 && ./run_local_coverage.sh -b main -c task \n# on main branch and run cases in longtimeruning_cases.task \n# for more information about options please refer to ./run_local_coverage.sh -h\n```\n\n> **NOTE**:\n> Please note that the -b and -i options will recompile TDengine with the -DCOVER=true option, which may take a amount of time.\n\n</details>\n\n# 12. Contributing\n\nPlease follow the [contribution guidelines](CONTRIBUTING.md) to contribute to TDengine.\n",
      "stars_today": 2
    },
    {
      "id": 49876476,
      "name": "shardingsphere",
      "full_name": "apache/shardingsphere",
      "description": "Empowering Data Intelligence with Distributed SQL for Sharding, Scalability, and Security Across All Databases.",
      "html_url": "https://github.com/apache/shardingsphere",
      "stars": 20648,
      "forks": 6914,
      "language": "Java",
      "topics": [
        "bigdata",
        "data-encryption",
        "data-pipeline",
        "database",
        "database-cluster",
        "database-gateway",
        "database-middleware",
        "distributed-database",
        "distributed-sql-database",
        "distributed-transaction",
        "encrypt",
        "mysql",
        "postgresql",
        "read-write-splitting",
        "shard",
        "sql"
      ],
      "created_at": "2016-01-18T12:49:26Z",
      "updated_at": "2026-01-23T16:28:31Z",
      "pushed_at": "2026-01-23T16:28:25Z",
      "open_issues": 379,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "## [Apache ShardingSphere - Enterprise Distributed Database Ecosystem](https://shardingsphere.apache.org/)\n\nBuilding the standards and ecosystem on top of heterogeneous databases, empowering enterprise data architecture transformation\n\n**Official Website:** [https://shardingsphere.apache.org/](https://shardingsphere.apache.org/)\n\n[![GitHub Release](https://img.shields.io/github/release/apache/shardingsphere.svg)](https://github.com/apache/shardingsphere/releases)\n[![Lines of Code](https://sonarcloud.io/api/project_badges/measure?project=apache_shardingsphere&metric=ncloc)](https://sonarcloud.io/summary/new_code?id=apache_shardingsphere)\n\n[![CI](https://github.com/apache/shardingsphere/actions/workflows/ci.yml/badge.svg)](https://github.com/apache/shardingsphere/actions/workflows/ci.yml)\n[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=apache_shardingsphere&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=apache_shardingsphere)\n[![Technical Debt](https://sonarcloud.io/api/project_badges/measure?project=apache_shardingsphere&metric=sqale_index)](https://sonarcloud.io/summary/new_code?id=apache_shardingsphere)\n[![Maintainability Rating](https://sonarcloud.io/api/project_badges/measure?project=apache_shardingsphere&metric=sqale_rating)](https://sonarcloud.io/summary/new_code?id=apache_shardingsphere)\n[![Security Rating](https://sonarcloud.io/api/project_badges/measure?project=apache_shardingsphere&metric=security_rating)](https://sonarcloud.io/summary/new_code?id=apache_shardingsphere)\n[![codecov](https://codecov.io/gh/apache/shardingsphere/branch/master/graph/badge.svg)](https://codecov.io/gh/apache/shardingsphere)\n\n[![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/5394/badge)](https://bestpractices.coreinfrastructure.org/projects/5394)\n\n[![Slack](https://img.shields.io/badge/%20Slack-ShardingSphere%20Channel-blueviolet)](https://join.slack.com/t/apacheshardingsphere/shared_invite/zt-sbdde7ie-SjDqo9~I4rYcR18bq0SYTg)\n[![Gitter](https://badges.gitter.im/shardingsphere/shardingsphere.svg)](https://gitter.im/shardingsphere/Lobby)\n\n[![X](https://img.shields.io/twitter/url/https/twitter.com/ShardingSphere.svg?style=social&label=Follow%20%40ShardingSphere)](https://x.com/ShardingSphere)\n\n<table style=\"width:100%\">\n    <tr>\n        <th>\n            <a href=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map?activity=stars&repo_id=49876476\" target=\"_blank\" style=\"display: block\" align=\"center\">\n                <picture>\n                    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map/thumbnail.png?activity=stars&repo_id=49876476&image_size=auto&color_scheme=dark\" width=\"721\" height=\"auto\">\n                    <img alt=\"Star Geographical Distribution of apache/shardingsphere\" src=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map/thumbnail.png?activity=stars&repo_id=49876476&image_size=auto&color_scheme=light\" width=\"721\" height=\"auto\">\n                </picture>\n            </a>\n        </th>\n        <th>\n            <a href=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map?activity=pull-request-creators&repo_id=49876476\" target=\"_blank\" style=\"display: block\" align=\"center\">\n                <picture>\n                    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map/thumbnail.png?activity=pull-request-creators&repo_id=49876476&image_size=auto&color_scheme=dark\" width=\"721\" height=\"auto\">\n                    <img alt=\"Pull Request Creator Geographical Distribution of apache/shardingsphere\" src=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map/thumbnail.png?activity=pull-request-creators&repo_id=49876476&image_size=auto&color_scheme=light\" width=\"721\" height=\"auto\">\n                </picture>\n            </a>\n        </th>\n        <th>\n            <a href=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map?activity=issue-creators&repo_id=49876476\" target=\"_blank\" style=\"display: block\" align=\"center\">\n                <picture>\n                    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map/thumbnail.png?activity=issue-creators&repo_id=49876476&image_size=auto&color_scheme=dark\" width=\"721\" height=\"auto\">\n                    <img alt=\"Issue Creator Geographical Distribution of apache/shardingsphere\" src=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map/thumbnail.png?activity=issue-creators&repo_id=49876476&image_size=auto&color_scheme=light\" width=\"721\" height=\"auto\">\n                </picture>\n            </a>\n        </th>\n    </tr>\n</table>\n\n### OVERVIEW\n\n<hr>\n\nApache ShardingSphere is positioned as **Database Plus**, a standard and ecosystem built on top of heterogeneous databases. As an operating system layer above databases, ShardingSphere does not create new databases but focuses on maximizing the computing capabilities of existing databases, providing unified data access and enhanced computing capabilities.\n\n**Database Plus Core Concept**: By building a standardized and scalable enhancement layer above databases, it makes heterogeneous databases as simple to use as a single database, providing unified governance capabilities and distributed computing capabilities for enterprise data architectures.\n\n**Connect, Enhance, and Pluggable** are the three core pillars of Apache ShardingSphere:\n\n- **Connect:** Building database upper-layer standards, quickly connecting applications with multi-modal heterogeneous databases through flexible adaptation of database protocols, SQL dialects, and storage formats, providing unified data access experience;\n\n- **Enhance:** As a database computing enhancement engine, transparently providing enterprise-grade capabilities including distributed computing (data sharding, readwrite-splitting, SQL federation), data security (encryption, masking, audit), traffic control (circuit breaker, rate limiting), and observability (monitoring, tracing, analysis);\n\n- **Pluggable:** Adopting a micro-kernel + 3-layer pluggable architecture to achieve complete decoupling of kernel, functional components, and ecosystem integration. Developers can flexibly customize unique data architecture solutions that meet enterprise needs, just like building with LEGO blocks.\n\n**Differentiation Advantages**:\n- **vs Distributed Databases**: More lightweight, protecting existing investments, avoiding vendor lock-in\n- **vs Traditional Middleware**: Richer features, more complete ecosystem, more flexible architecture\n- **vs Cloud Vendor Solutions**: Support multi-cloud deployment, avoid technology binding, autonomous and controllable\n\nShardingSphere became an [Apache](https://apache.org/index.html#projects-list) Top-Level Project on April 16, 2020, and has been adopted by [19,000+ projects](https://github.com/search?l=Maven+POM&q=shardingsphere+language%3A%22Maven+POM%22&type=Code) worldwide.\n\n### DUAL-ACCESS ARCHITECTURE DESIGN\n\n<hr>\n\nShardingSphere adopts a unique dual-access architecture design, providing two access ends - JDBC and Proxy - that can be deployed independently or in hybrid deployment, meeting diverse requirements for different scenarios.\n\n#### ShardingSphere-JDBC: Lightweight Access End\n\n**Positioning**: Lightweight Java framework, enhanced JDBC driver\n\n**Core Features**:\n- **Client-side direct connection**: Shares resources with applications, decentralized architecture\n- **High performance, low overhead**: Direct database connection with minimal performance loss\n- **Complete compatibility**: Compatible with all ORM frameworks (MyBatis, JPA, Hibernate, etc.)\n- **Zero additional deployment**: Provided as JAR package, no independent deployment and dependencies required\n\n**Use Cases**: High-performance Java applications, integrated deployment with business applications, pursuing ultimate performance\n\n#### ShardingSphere-Proxy: Enterprise Access End\n\n**Positioning**: Transparent database proxy, independently deployed server-side\n\n**Core Features**:\n- **Static entry point**: Independent deployment from applications, providing stable database access entry\n- **Heterogeneous language support**: Supports any MySQL/PostgreSQL protocol compatible client\n- **DBA friendly**: Database operation and maintenance management interface, convenient for O&M personnel\n- **Enterprise-grade features**: Supports cluster deployment, load balancing, failover\n\n**Use Cases**: Heterogeneous language environments, database operation and maintenance management, enterprise applications requiring unified access entry\n\n#### Hybrid Architecture Advantages\n\nBy hybridizing ShardingSphere-JDBC and ShardingSphere-Proxy with unified configuration through the same registry center, you can flexibly build application systems suitable for various scenarios:\n\n- **Architectural flexibility**: Architects can freely adjust the optimal system architecture\n- **Scenario adaptability**: Select the most suitable access method according to different business scenarios\n- **Unified management**: Single configuration, multi-end collaboration, simplifying O&M complexity\n- **Progressive evolution**: Support smooth evolution path from JDBC to Proxy\n\n### AI ABSTRACTION\n\n[![DeepWiki](https://img.shields.io/badge/DeepWiki-apache%2Fshardingsphere-blue.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAyCAYAAAAnWDnqAAAAAXNSR0IArs4c6QAAA05JREFUaEPtmUtyEzEQhtWTQyQLHNak2AB7ZnyXZMEjXMGeK/AIi+QuHrMnbChYY7MIh8g01fJoopFb0uhhEqqcbWTp06/uv1saEDv4O3n3dV60RfP947Mm9/SQc0ICFQgzfc4CYZoTPAswgSJCCUJUnAAoRHOAUOcATwbmVLWdGoH//PB8mnKqScAhsD0kYP3j/Yt5LPQe2KvcXmGvRHcDnpxfL2zOYJ1mFwrryWTz0advv1Ut4CJgf5uhDuDj5eUcAUoahrdY/56ebRWeraTjMt/00Sh3UDtjgHtQNHwcRGOC98BJEAEymycmYcWwOprTgcB6VZ5JK5TAJ+fXGLBm3FDAmn6oPPjR4rKCAoJCal2eAiQp2x0vxTPB3ALO2CRkwmDy5WohzBDwSEFKRwPbknEggCPB/imwrycgxX2NzoMCHhPkDwqYMr9tRcP5qNrMZHkVnOjRMWwLCcr8ohBVb1OMjxLwGCvjTikrsBOiA6fNyCrm8V1rP93iVPpwaE+gO0SsWmPiXB+jikdf6SizrT5qKasx5j8ABbHpFTx+vFXp9EnYQmLx02h1QTTrl6eDqxLnGjporxl3NL3agEvXdT0WmEost648sQOYAeJS9Q7bfUVoMGnjo4AZdUMQku50McDcMWcBPvr0SzbTAFDfvJqwLzgxwATnCgnp4wDl6Aa+Ax283gghmj+vj7feE2KBBRMW3FzOpLOADl0Isb5587h/U4gGvkt5v60Z1VLG8BhYjbzRwyQZemwAd6cCR5/XFWLYZRIMpX39AR0tjaGGiGzLVyhse5C9RKC6ai42ppWPKiBagOvaYk8lO7DajerabOZP46Lby5wKjw1HCRx7p9sVMOWGzb/vA1hwiWc6jm3MvQDTogQkiqIhJV0nBQBTU+3okKCFDy9WwferkHjtxib7t3xIUQtHxnIwtx4mpg26/HfwVNVDb4oI9RHmx5WGelRVlrtiw43zboCLaxv46AZeB3IlTkwouebTr1y2NjSpHz68WNFjHvupy3q8TFn3Hos2IAk4Ju5dCo8B3wP7VPr/FGaKiG+T+v+TQqIrOqMTL1VdWV1DdmcbO8KXBz6esmYWYKPwDL5b5FA1a0hwapHiom0r/cKaoqr+27/XcrS5UwSMbQAAAABJRU5ErkJggg==)](https://deepwiki.com/apache/shardingsphere)\n[![zread](https://img.shields.io/badge/Ask_Zread-_.svg?style=flat&color=00b0aa&labelColor=000000&logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTQuOTYxNTYgMS42MDAxSDIuMjQxNTZDMS44ODgxIDEuNjAwMSAxLjYwMTU2IDEuODg2NjQgMS42MDE1NiAyLjI0MDFWNC45NjAxQzEuNjAxNTYgNS4zMTM1NiAxLjg4ODEgNS42MDAxIDIuMjQxNTYgNS42MDAxSDQuOTYxNTZDNS4zMTUwMiA1LjYwMDEgNS42MDE1NiA1LjMxMzU2IDUuNjAxNTYgNC45NjAxVjIuMjQwMUM1LjYwMTU2IDEuODg2NjQgNS4zMTUwMiAxLjYwMDEgNC45NjE1NiAxLjYwMDFaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00Ljk2MTU2IDEwLjM5OTlIMi4yNDE1NkMxLjg4ODEgMTAuMzk5OSAxLjYwMTU2IDEwLjY4NjQgMS42MDE1NiAxMS4wMzk5VjEzLjc1OTlDMS42MDE1NiAxNC4xMTM0IDEuODg4MSAxNC4zOTk5IDIuMjQxNTYgMTQuMzk5OUg0Ljk2MTU2QzUuMzE1MDIgMTQuMzk5OSA1LjYwMTU2IDE0LjExMzQgNS42MDE1NiAxMy43NTk5VjExLjAzOTlDNS42MDE1NiAxMC42ODY0IDUuMzE1MDIgMTAuMzk5OSA0Ljk2MTU2IDEwLjM5OTlaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik0xMy43NTg0IDEuNjAwMUgxMS4wMzg0QzEwLjY4NSAxLjYwMDEgMTAuMzk4NCAxLjg4NjY0IDEwLjM5ODQgMi4yNDAxVjQuOTYwMUMxMC4zOTg0IDUuMzEzNTYgMTAuNjg1IDUuNjAwMSAxMS4wMzg0IDUuNjAwMUgxMy43NTg0QzE0LjExMTkgNS42MDAxIDE0LjM5ODQgNS4zMTM1NiAxNC4zOTg0IDQuOTYwMVYyLjI0MDFDMTQuMzk4NCAxLjg4NjY0IDE0LjExMTkgMS42MDAxIDEzLjc1ODQgMS42MDAxWiIgZmlsbD0iI2ZmZiIvPgo8cGF0aCBkPSJNNCAxMkwxMiA0TDQgMTJaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00IDEyTDEyIDQiIHN0cm9rZT0iI2ZmZiIgc3Ryb2tlLXdpZHRoPSIxLjUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIvPgo8L3N2Zz4K&logoColor=ffffff)](https://zread.ai/apache/shardingsphere)\n\n### DOCUMENTATIONüìú\n\n<hr>\n\n[![EN doc](https://img.shields.io/badge/document-English-blue.svg)](https://shardingsphere.apache.org/document/current/en/overview/)\n[![CN doc](https://img.shields.io/badge/ÊñáÊ°£-‰∏≠ÊñáÁâà-blue.svg)](https://shardingsphere.apache.org/document/current/cn/overview/)\n\nFor full documentation & more details, visit: [Docs](https://shardingsphere.apache.org/document/current/en/overview/)\n\n### CONTRIBUTIONüöÄüßëüíª\n\n<hr>\n\nFor guides on how to get started and setup your environment, contributor & committer guides, visit: [Contribution Guidelines](https://shardingsphere.apache.org/community/en/involved/)\n\n### Team\n\n<hr>\n\nWe deeply appreciate [community contributors](https://shardingsphere.apache.org/community/en/team) for their dedication to Apache ShardingSphere.\n\n##\n\n### COMMUNITY & SUPPORTüíùüñ§\n\n<hr>\n\n:link: [Mailing List](https://shardingsphere.apache.org/community/en/involved/subscribe/). Best for: Apache community updates, releases, changes.\n\n:link: [GitHub Issues](https://github.com/apache/shardingsphere/issues). Best for: design discussions, bug reports, or anything development related.\n\n:link: [Slack channel](https://join.slack.com/t/apacheshardingsphere/shared_invite/zt-sbdde7ie-SjDqo9~I4rYcR18bq0SYTg). Best for: instant communications and online meetings, sharing your applications.\n\n:link: [X](https://x.com/ShardingSphere). Best for: keeping up to date on everything ShardingSphere.\n\n:link: [LinkedIn](https://www.linkedin.com/showcase/apache-shardingsphere/e). Best for: professional networking and career development with other ShardingSphere contributors.\n\n##\n\n### PROJECT STATUS\n\n<hr>\n\n:white_check_mark: **Version 5.5.3-SNAPSHOT**: Actively under development :tada:\n\nüîó For the release notes, follow this link to the relevant [GitHub page](https://github.com/apache/shardingsphere/blob/master/RELEASE-NOTES.md).\n\n:soon: **Version 5.5.3**\n\nWe are currently developing version 5.5.3, which includes multiple security enhancements and performance optimizations.\nKeep an eye on the [milestones page](https://github.com/apache/shardingsphere/milestones) of this repo for the latest development progress.\n\n[comment]: <> (##)\n\n[comment]: <> (### NIGHTLY BUILDS:)\n\n[comment]: <> (<hr>)\n\n[comment]: <> (A nightly build of ShardingSphere from the latest master branch is available. )\n\n[comment]: <> (The package is updated daily and is available [here]&#40;http://117.48.121.24:8080&#41;.)\n\n[comment]: <> (##)\n\n[comment]: <> (**‚ÄºÔ∏è Notice:**)\n\n[comment]: <> (<hr>)\n\n[comment]: <> (Use this nightly build at your own risk! )\n\n[comment]: <> (The branch is not always fully tested. )\n\n[comment]: <> (The nightly build may contain bugs, and there may be new features added which may cause problems with your environment. )\n\n##\n\n### TECHNICAL ARCHITECTURE EVOLUTION\n\n<hr>\n\nApache ShardingSphere adopts a micro-kernel + 3-layer pluggable architecture, achieving complete decoupling of the kernel, functional components, and ecosystem integration, providing developers with ultimate flexibility and extensibility.\n\n#### Micro-Kernel + 3-Layer Pluggable Model\n\n**Core Layer**:\n- Query optimizer: Intelligent SQL routing and execution plan optimization\n- Distributed transaction: ACID transaction guarantees and consistency coordination\n- Execution engine: Efficient distributed execution and result aggregation\n\n**Feature Layer**:\n- Data sharding, readwrite-splitting, federation query\n- Data encryption, data masking, SQL audit\n- Shadow database, observability, traffic control\n\n**Ecosystem Layer**:\n- Database protocol adaptation (MySQL, PostgreSQL, Oracle, etc.)\n- Registry center integration (ZooKeeper, ETCD, etc.)\n- Configuration management, service discovery, monitoring integration\n\n#### Technical Innovation Highlights\n\n**Complete Decoupling Architecture**:\n- Database types completely decoupled, supporting rapid integration of new databases\n- Functional modules completely decoupled, supporting on-demand feature combination\n\nApache ShardingSphere consists of two access ends - JDBC and Proxy - that can be deployed independently or in hybrid deployment, providing unified distributed database solutions for diverse application scenarios including Java isomorphism, heterogeneous languages, and cloud-native environments.\n\n### ShardingSphere-JDBC\n\n<hr>\n\n[![Maven Status](https://img.shields.io/maven-central/v/org.apache.shardingsphere/shardingsphere-jdbc.svg?color=green)](https://mvnrepository.com/artifact/org.apache.shardingsphere/shardingsphere-jdbc)\n\nA lightweight Java framework providing extra services at the Java JDBC layer. \nWith the client end connecting directly to the database, it provides services in the form of a jar and requires no extra deployment and dependence.\n\n:link: For more details, follow this [link to the official website](https://shardingsphere.apache.org/document/current/en/overview/#shardingsphere-jdbc).\n\n> **Note**: When using ShardingSphere-JDBC adapter, pay attention to your application's memory configuration. Antlr uses an internal cache to improve performance during SQL parsing. If your application has too many SQL templates, the cache will continue to grow, occupying a large amount of heap memory.\nAccording to feedback from the ANTLR official [issue#4232](https://github.com/antlr/antlr4/issues/4232), this issue has not yet been optimized. When connecting your application to ShardingSphere-JDBC, it is recommended to set a reasonable heap memory size using the `-Xmx` parameter to avoid OOM errors caused by insufficient memory.\n\n### ShardingSphere-Proxy\n\n<hr>\n\n[![Nightly-Download](https://img.shields.io/static/v1?label=nightly-builds&message=download&color=orange)](https://nightlies.apache.org/shardingsphere/)\n[![Download](https://img.shields.io/badge/release-download-orange.svg)](https://www.apache.org/dyn/closer.lua/shardingsphere/5.3.2/apache-shardingsphere-5.3.2-shardingsphere-proxy-bin.tar.gz)\n[![Docker Pulls](https://img.shields.io/docker/pulls/apache/shardingsphere-proxy.svg)](https://store.docker.com/community/images/apache/shardingsphere-proxy)\n\nA transparent database proxy, providing a database server that encapsulates the database binary protocol to support heterogeneous languages. \nFriendlier to DBAs, the MariaDB, MySQL and PostgreSQL version now provided can use any kind of terminal.\n\n:link: For more details, follow this [link to the official website](https://shardingsphere.apache.org/document/current/en/overview/#shardingsphere-proxy).\n\n### Hybrid Architecture\n\n<hr>\n\nShardingSphere-JDBC adopts a decentralized architecture, applicable to high-performance light-weight OLTP applications developed with Java. \nShardingSphere-Proxy provides static entry and all languages support, suitable for an OLAP application and sharding databases management and operation.\n\nThrough the combination of ShardingSphere-JDBC & ShardingSphere-Proxy together with a unified sharding strategy by the same registry center, the ShardingSphere ecosystem can build an application system suitable to all kinds of scenarios.\n\n:link: More details can be found following this [link to the official website](https://shardingsphere.apache.org/document/current/en/overview/#hybrid-architecture).\n\n##\n\n### CORE FEATURE MATRIX\n\n<hr>\n\n#### Distributed Database Core Capabilities\n- **Data Sharding**: Horizontal sharding, vertical sharding, custom sharding strategies, automatic sharding routing\n- **Read/Write Splitting**: Master-slave replication, load balancing, failover, read weight configuration\n- **Distributed Transaction**: XA transactions, BASE transactions, transaction propagation\n\n#### Data Security & Governance\n- **Data Encryption**: Field-level encryption, transparent encryption, key management, encryption algorithm support\n- **Data Masking**: Sensitive data protection, masking strategy customization, dynamic masking rules\n- **Access Control**: Fine-grained permissions, access control, SQL firewall, security policies\n\n#### Database Gateway Capabilities\n- **Heterogeneous Databases**: MySQL, PostgreSQL, Oracle, SQL Server, Firebird, etc.\n- **SQL Dialect Translation**: Cross-database SQL compatibility, dialect adaptation, syntax conversion\n- **Protocol Adaptation**: Database protocol conversion, multi-protocol support, communication optimization\n\n#### Full-link Stress Testing & Observability\n- **Shadow Database**: Stress testing data isolation, environment separation, real data simulation\n- **Observability**: Performance monitoring, distributed tracing, QoS analysis, metrics collection\n- **Traffic Analysis**: SQL performance analysis, traffic statistics, bottleneck identification\n\n#### Enterprise-grade Features\n- **High Availability**: Cluster deployment, fault recovery, service discovery, health checks\n- **Cloud Native**: Containerized deployment, Kubernetes integration, native image support\n- **Monitoring & Alerting**: Real-time monitoring, alert notifications, performance metrics, O&M dashboard\n\n##\n\n### Roadmap\n\n<hr>\n\n![Roadmap](https://shardingsphere.apache.org/document/current/img/roadmap_en.png)\n\n##\n\n### How to Build Apache ShardingSphere\n\n<hr>\n\nCheck out [Wiki](https://github.com/apache/shardingsphere/wiki) section for details on how to build Apache ShardingSphere and a full guide on how to get started and setup your local dev environment.\n\n##\n\n### Landscapes\n\n<hr>\n\n<p align=\"center\">\n<br/><br/>\n<img src=\"https://landscape.cncf.io/images/cncf-landscape-horizontal-color.svg\" width=\"165\"/>&nbsp;&nbsp;<img src=\"https://www.cncf.io/wp-content/uploads/2023/04/cncf-main-site-logo.svg\" width=\"200\"/>\n<br/><br/>\nApache ShardingSphere enriches the <a href=\"https://landscape.cncf.io/?category=app-definition-and-development&grouping=category\">CNCF CLOUD NATIVE Landscape</a>.\n</p>\n\n##\n",
      "stars_today": 2
    },
    {
      "id": 70198664,
      "name": "lottie-ios",
      "full_name": "airbnb/lottie-ios",
      "description": "An iOS library to natively render After Effects vector animations",
      "html_url": "https://github.com/airbnb/lottie-ios",
      "stars": 26632,
      "forks": 3828,
      "language": "Swift",
      "topics": [
        "animation",
        "bodymovin",
        "custom-transitions",
        "ios",
        "ios-animation",
        "ios-transition",
        "keyframes",
        "swift",
        "transition-animation"
      ],
      "created_at": "2016-10-06T22:38:38Z",
      "updated_at": "2026-01-24T00:48:43Z",
      "pushed_at": "2026-01-13T14:44:25Z",
      "open_issues": 45,
      "owner": {
        "login": "airbnb",
        "avatar_url": "https://avatars.githubusercontent.com/u/698437?v=4"
      },
      "readme": "# Lottie for iOS\n [![Version](https://img.shields.io/cocoapods/v/lottie-ios.svg?style=flat)](https://cocoapods.org/pods/lottie-ios) [![Carthage Compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat)](https://github.com/Carthage/Carthage) [![SwiftPM](https://img.shields.io/badge/SPM-supported-DE5C43.svg?style=flat)](https://swift.org/package-manager/) [![License](https://img.shields.io/cocoapods/l/lottie-ios.svg?style=flat)](https://cocoapods.org/pods/lottie-ios) [![Platform](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fairbnb%2Flottie-ios%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/airbnb/lottie-ios) [![Swift Versions](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fairbnb%2Flottie-ios%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/airbnb/lottie-ios)\n\n**View documentation, FAQ, help, examples, and more at [airbnb.io/lottie](https://airbnb.io/lottie/)**\n\nLottie is a cross-platform library for iOS, macOS, tvOS, visionOS, [Android](https://github.com/airbnb/lottie-android), and [Web](https://github.com/airbnb/lottie-web) that natively renders vector-based animations and art in realtime with minimal code.\n\nLottie loads and renders animations and vectors exported in the bodymovin JSON format. Bodymovin JSON can be created and exported from After Effects with [bodymovin](https://github.com/bodymovin/bodymovin), Sketch with [Lottie Sketch Export](https://github.com/buba447/Lottie-Sketch-Export), and from [Haiku](https://www.haikuanimator.com).\n\nDesigners can create **and ship** beautiful animations without an engineer painstakingly recreating them by hand.\nSince the animations are backed by JSON, they are extremely small in size but can be large in complexity!\nAnimations can be played, resized, looped, sped up, slowed down, reversed, and even interactively scrubbed.\nLottie can play or loop just a portion of the animation as well, the possibilities are endless!\nAnimations can even be ***changed at runtime*** in various ways! Change the color, position, or any keyframable value!\n\nHere is just a small sampling of the power of Lottie\n\n![Example1](_Gifs/Examples1.gif)\n![Example2](_Gifs/Examples2.gif)\n\n<img src=\"_Gifs/Community 2_3.gif\" />\n\n![Example3](_Gifs/Examples3.gif)\n\n![Abcs](_Gifs/Examples4.gif)\n\n## Installing Lottie\nLottie supports [Swift Package Manager](https://www.swift.org/package-manager/), [CocoaPods](https://cocoapods.org/), and [Carthage](https://github.com/Carthage/Carthage) (Both dynamic and static).\n\n### Github Repo\n\nYou can pull the [Lottie Github Repo](https://github.com/airbnb/lottie-ios/) and include the `Lottie.xcodeproj` to build a dynamic or static library.\n\n### Swift Package Manager\n\nTo install Lottie using [Swift Package Manager](https://github.com/swiftlang/swift-package-manager) you can follow the [tutorial published by Apple](https://developer.apple.com/documentation/xcode/adding_package_dependencies_to_your_app) using the URL for the Lottie repo with the current version:\n\n1. In Xcode, select ‚ÄúFile‚Äù ‚Üí ‚ÄúAdd Packages...‚Äù\n1. Enter https://github.com/airbnb/lottie-spm.git\n\nor you can add the following dependency to your `Package.swift`:\n\n```swift\n.package(url: \"https://github.com/airbnb/lottie-spm.git\", from: \"4.5.2\")\n```\n\nWhen using Swift Package Manager we recommend using the [lottie-spm](https://github.com/airbnb/lottie-spm) repo instead of the main lottie-ios repo.  The main git repository for [lottie-ios](https://github.com/airbnb/lottie-ios) is somewhat large (300+ MB), and Swift Package Manager always downloads the full repository with all git history. The [lottie-spm](https://github.com/airbnb/lottie-spm) repo is much smaller (less than 500kb), so can be downloaded much more quickly. \n\nInstead of downloading the full git history of Lottie and building it from source, the lottie-spm repo just contains a pointer to the precompiled XCFramework included in the [latest lottie-ios release](https://github.com/airbnb/lottie-ios/releases/latest) (typically ~8MB). If you prefer to include Lottie source directly your project, you can directly depend on the main lottie-ios repo by referencing `https://github.com/airbnb/lottie-ios.git` instead.\n\n### CocoaPods\nAdd the pod to your Podfile:\n```ruby\npod 'lottie-ios'\n```\n\nAnd then run:\n```ruby\npod install\n```\nAfter installing the cocoapod into your project import Lottie with\n```swift\nimport Lottie\n```\n\n### Carthage\nAdd Lottie to your Cartfile:\n```\ngithub \"airbnb/lottie-ios\" \"master\"\n```\n\nAnd then run:\n```\ncarthage update\n```\nIn your application targets ‚ÄúGeneral‚Äù tab under the ‚ÄúLinked Frameworks and Libraries‚Äù section, drag and drop lottie-ios.framework from the Carthage/Build/iOS directory that `carthage update` produced.\n\n## Swift Version Support\n\nLottie supports Swift / Xcode versions back to the minimum version that is permitted by Apple for submissions to the App Store. You can see the most up-to-date information for which Swift versions Lottie supports on [Swift Package Index](https://swiftpackageindex.com/airbnb/lottie-ios):\n\n[![Swift Versions](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fairbnb%2Flottie-ios%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/airbnb/lottie-ios)\n\n## Privacy\n\nLottie does not collect any data. We provide this notice to help you fill out [App Privacy Details](https://developer.apple.com/app-store/app-privacy-details/). We additionally provide a [privacy manifest](https://github.com/airbnb/lottie-ios/blob/master/Sources/PrivacyInfo.xcprivacy) which can be included in your app.\n\n## Security\n\nWe distribute XCFramework bundles for each release on [GitHub](https://github.com/airbnb/lottie-ios/releases/latest). In Lottie 4.4.0 and later, these XCFramework bundles include a [code signature](https://developer.apple.com/documentation/xcode/verifying-the-origin-of-your-xcframeworks). These bundles are self-signed under the name \"Lottie iOS\" and have the following fingerprint:\n\n```\n89 2F 1B 43 04 7B 50 53 8F 2F 46 EA D9 29 00 DD 3D 48 11 F358 21 78 C0 61 A5 FB 20 F1 11 CB 26\n```\n\nIn Xcode you can verify this by selecting `Lottie.xcframework` and confirming that it shows the following information:\n\n![Code Signature in Xcode](_Gifs/code_signature.png)\n\n## Contributing\n\nWe always appreciate contributions from the community. To make changes to the project, you can clone the repo and open `Lottie.xcworkspace`. This workspace includes:\n - the Lottie framework (for iOS, macOS, and tvOS)\n - unit tests and snapshot tests (for iOS, must be run on an iPhone 8 simulator)\n - an Example iOS app that lets you browse and test over 100 sample animations included in the repo\n\nAll pull requests with new features or bug fixes that affect how animations render should include snapshot test cases that validate the included changes. \n  - To add a new sample animation to the snapshot testing suite, you can add the `.json` file to `Tests/Samples`. Re-run the snapshot tests to generate the new snapshot image files.\n  - To update existing snapshots after making changes, you can set `isRecording = true` in `SnapshotTests.swift` `setUp()` method and then re-run the snapshot tests.\n\nThe project also includes several helpful commands defined in our [Rakefile](https://github.com/airbnb/lottie-ios/blob/master/Rakefile). To use these, you need to install [Bundler](https://bundler.io/):\n\n```bash\n$ sudo gem install bundle\n$ bundle install\n```\n\nFor example, all Swift code should be formatted according to the [Airbnb Swift Style Guide](https://github.com/airbnb/swift). After making changes, you can reformat the code automatically using [SwiftFormat](https://github.com/nicklockwood/SwiftFormat) and [SwiftLint](https://github.com/realm/SwiftLint) by running `bundle exec rake format:swift`. Other helpful commands include:\n\n```bash\n$ bundle exec rake build:all # builds all targets for all platforms\n$ bundle exec rake build:package:iOS # builds the Lottie package for iOS\n$ bundle exec rake test:package # tests the Lottie package\n$ bundle exec rake format:swift # reformat Swift code based on the Airbnb Swift Style Guide\n```\n",
      "stars_today": 2
    },
    {
      "id": 27729907,
      "name": "grpc-go",
      "full_name": "grpc/grpc-go",
      "description": "The Go language implementation of gRPC. HTTP/2 based RPC",
      "html_url": "https://github.com/grpc/grpc-go",
      "stars": 22730,
      "forks": 4635,
      "language": "Go",
      "topics": [
        "dogs-over-cats",
        "giant-robots",
        "go",
        "golang",
        "grpc",
        "hacktoberfest",
        "microservices",
        "not-nanoservices",
        "proto",
        "rpc"
      ],
      "created_at": "2014-12-08T18:59:34Z",
      "updated_at": "2026-01-23T22:39:30Z",
      "pushed_at": "2026-01-22T06:17:01Z",
      "open_issues": 134,
      "owner": {
        "login": "grpc",
        "avatar_url": "https://avatars.githubusercontent.com/u/7802525?v=4"
      },
      "readme": "# gRPC-Go\n\n[![GoDoc](https://pkg.go.dev/badge/google.golang.org/grpc)][API]\n[![GoReportCard](https://goreportcard.com/badge/grpc/grpc-go)](https://goreportcard.com/report/github.com/grpc/grpc-go)\n[![codecov](https://codecov.io/gh/grpc/grpc-go/graph/badge.svg)](https://codecov.io/gh/grpc/grpc-go)\n\nThe [Go][] implementation of [gRPC][]: A high performance, open source, general\nRPC framework that puts mobile and HTTP/2 first. For more information see the\n[Go gRPC docs][], or jump directly into the [quick start][].\n\n## Prerequisites\n\n- **[Go][]**: any one of the **two latest major** [releases][go-releases].\n\n## Installation\n\nSimply add the following import to your code, and then `go [build|run|test]`\nwill automatically fetch the necessary dependencies:\n\n\n```go\nimport \"google.golang.org/grpc\"\n```\n\n> **Note:** If you are trying to access `grpc-go` from **China**, see the\n> [FAQ](#FAQ) below.\n\n## Learn more\n\n- [Go gRPC docs][], which include a [quick start][] and [API\n  reference][API] among other resources\n- [Low-level technical docs](Documentation) from this repository\n- [Performance benchmark][]\n- [Examples](examples)\n- [Contribution guidelines](CONTRIBUTING.md)\n\n## FAQ\n\n### I/O Timeout Errors\n\nThe `golang.org` domain may be blocked from some countries. `go get` usually\nproduces an error like the following when this happens:\n\n```console\n$ go get -u google.golang.org/grpc\npackage google.golang.org/grpc: unrecognized import path \"google.golang.org/grpc\" (https fetch: Get https://google.golang.org/grpc?go-get=1: dial tcp 216.239.37.1:443: i/o timeout)\n```\n\nTo build Go code, there are several options:\n\n- Set up a VPN and access google.golang.org through that.\n\n- With Go module support: it is possible to use the `replace` feature of `go\n  mod` to create aliases for golang.org packages.  In your project's directory:\n\n  ```sh\n  go mod edit -replace=google.golang.org/grpc=github.com/grpc/grpc-go@latest\n  go mod tidy\n  go mod vendor\n  go build -mod=vendor\n  ```\n\n  Again, this will need to be done for all transitive dependencies hosted on\n  golang.org as well. For details, refer to [golang/go issue\n  #28652](https://github.com/golang/go/issues/28652).\n\n### Compiling error, undefined: grpc.SupportPackageIsVersion\n\nPlease update to the latest version of gRPC-Go using\n`go get google.golang.org/grpc`.\n\n### How to turn on logging\n\nThe default logger is controlled by environment variables. Turn everything on\nlike this:\n\n```console\n$ export GRPC_GO_LOG_VERBOSITY_LEVEL=99\n$ export GRPC_GO_LOG_SEVERITY_LEVEL=info\n```\n\n### The RPC failed with error `\"code = Unavailable desc = transport is closing\"`\n\nThis error means the connection the RPC is using was closed, and there are many\npossible reasons, including:\n 1. mis-configured transport credentials, connection failed on handshaking\n 1. bytes disrupted, possibly by a proxy in between\n 1. server shutdown\n 1. Keepalive parameters caused connection shutdown, for example if you have\n    configured your server to terminate connections regularly to [trigger DNS\n    lookups](https://github.com/grpc/grpc-go/issues/3170#issuecomment-552517779).\n    If this is the case, you may want to increase your\n    [MaxConnectionAgeGrace](https://pkg.go.dev/google.golang.org/grpc/keepalive?tab=doc#ServerParameters),\n    to allow longer RPC calls to finish.\n\nIt can be tricky to debug this because the error happens on the client side but\nthe root cause of the connection being closed is on the server side. Turn on\nlogging on __both client and server__, and see if there are any transport\nerrors.\n\n[API]: https://pkg.go.dev/google.golang.org/grpc\n[Go]: https://golang.org\n[Go module]: https://github.com/golang/go/wiki/Modules\n[gRPC]: https://grpc.io\n[Go gRPC docs]: https://grpc.io/docs/languages/go\n[Performance benchmark]: https://performance-dot-grpc-testing.appspot.com/explore?dashboard=5180705743044608\n[quick start]: https://grpc.io/docs/languages/go/quickstart\n[go-releases]: https://golang.org/doc/devel/release.html\n",
      "stars_today": 2
    },
    {
      "id": 117965972,
      "name": "DataX",
      "full_name": "alibaba/DataX",
      "description": "DataXÊòØÈòøÈáå‰∫ëDataWorksÊï∞ÊçÆÈõÜÊàêÁöÑÂºÄÊ∫êÁâàÊú¨„ÄÇ",
      "html_url": "https://github.com/alibaba/DataX",
      "stars": 17088,
      "forks": 5659,
      "language": "Java",
      "topics": [],
      "created_at": "2018-01-18T10:09:47Z",
      "updated_at": "2026-01-23T07:09:41Z",
      "pushed_at": "2025-07-01T01:42:28Z",
      "open_issues": 1349,
      "owner": {
        "login": "alibaba",
        "avatar_url": "https://avatars.githubusercontent.com/u/1961952?v=4"
      },
      "readme": "![Datax-logo](https://github.com/alibaba/DataX/blob/master/images/DataX-logo.jpg)\n\n# DataX\n\n[![Leaderboard](https://img.shields.io/badge/DataX-%E6%9F%A5%E7%9C%8B%E8%B4%A1%E7%8C%AE%E6%8E%92%E8%A1%8C%E6%A6%9C-orange)](https://opensource.alibaba.com/contribution_leaderboard/details?projectValue=datax)\n\nDataX ÊòØÈòøÈáå‰∫ë [DataWorksÊï∞ÊçÆÈõÜÊàê](https://www.aliyun.com/product/bigdata/ide) ÁöÑÂºÄÊ∫êÁâàÊú¨ÔºåÂú®ÈòøÈáåÂ∑¥Â∑¥ÈõÜÂõ¢ÂÜÖË¢´ÂπøÊ≥õ‰ΩøÁî®ÁöÑÁ¶ªÁ∫øÊï∞ÊçÆÂêåÊ≠•Â∑•ÂÖ∑/Âπ≥Âè∞„ÄÇDataX ÂÆûÁé∞‰∫ÜÂåÖÊã¨ MySQL„ÄÅOracle„ÄÅOceanBase„ÄÅSqlServer„ÄÅPostgre„ÄÅHDFS„ÄÅHive„ÄÅADS„ÄÅHBase„ÄÅTableStore(OTS)„ÄÅMaxCompute(ODPS)„ÄÅHologres„ÄÅDRDS, databend Á≠âÂêÑÁßçÂºÇÊûÑÊï∞ÊçÆÊ∫ê‰πãÈó¥È´òÊïàÁöÑÊï∞ÊçÆÂêåÊ≠•ÂäüËÉΩ„ÄÇ\n\n# DataX ÂïÜ‰∏öÁâàÊú¨\nÈòøÈáå‰∫ëDataWorksÊï∞ÊçÆÈõÜÊàêÊòØDataXÂõ¢ÈòüÂú®ÈòøÈáå‰∫ë‰∏äÁöÑÂïÜ‰∏öÂåñ‰∫ßÂìÅÔºåËá¥Âäõ‰∫éÊèê‰æõÂ§çÊùÇÁΩëÁªúÁéØÂ¢É‰∏ã„ÄÅ‰∏∞ÂØåÁöÑÂºÇÊûÑÊï∞ÊçÆÊ∫ê‰πãÈó¥È´òÈÄüÁ®≥ÂÆöÁöÑÊï∞ÊçÆÁßªÂä®ËÉΩÂäõÔºå‰ª•ÂèäÁπÅÊùÇ‰∏öÂä°ËÉåÊôØ‰∏ãÁöÑÊï∞ÊçÆÂêåÊ≠•Ëß£ÂÜ≥ÊñπÊ°à„ÄÇÁõÆÂâçÂ∑≤ÁªèÊîØÊåÅ‰∫ë‰∏äËøë3000ÂÆ∂ÂÆ¢Êà∑ÔºåÂçïÊó•ÂêåÊ≠•Êï∞ÊçÆË∂ÖËøá3‰∏á‰∫øÊù°„ÄÇDataWorksÊï∞ÊçÆÈõÜÊàêÁõÆÂâçÊîØÊåÅÁ¶ªÁ∫ø50+ÁßçÊï∞ÊçÆÊ∫êÔºåÂèØ‰ª•ËøõË°åÊï¥Â∫ìËøÅÁßª„ÄÅÊâπÈáè‰∏ä‰∫ë„ÄÅÂ¢ûÈáèÂêåÊ≠•„ÄÅÂàÜÂ∫ìÂàÜË°®Á≠âÂêÑÁ±ªÂêåÊ≠•Ëß£ÂÜ≥ÊñπÊ°à„ÄÇ2020Âπ¥Êõ¥Êñ∞ÂÆûÊó∂ÂêåÊ≠•ËÉΩÂäõÔºåÊîØÊåÅ10+ÁßçÊï∞ÊçÆÊ∫êÁöÑËØªÂÜô‰ªªÊÑèÁªÑÂêà„ÄÇÊèê‰æõMySQLÔºåOracleÁ≠âÂ§öÁßçÊï∞ÊçÆÊ∫êÂà∞ÈòøÈáå‰∫ëMaxComputeÔºåHologresÁ≠âÂ§ßÊï∞ÊçÆÂºïÊìéÁöÑ‰∏ÄÈîÆÂÖ®Â¢ûÈáèÂêåÊ≠•Ëß£ÂÜ≥ÊñπÊ°à„ÄÇ\n\nÂïÜ‰∏öÁâàÊú¨ÂèÇËßÅÔºö  https://www.aliyun.com/product/bigdata/ide\n\n\n# Features\n\nDataXÊú¨Ë∫´‰Ωú‰∏∫Êï∞ÊçÆÂêåÊ≠•Ê°ÜÊû∂ÔºåÂ∞Ü‰∏çÂêåÊï∞ÊçÆÊ∫êÁöÑÂêåÊ≠•ÊäΩË±°‰∏∫‰ªéÊ∫êÂ§¥Êï∞ÊçÆÊ∫êËØªÂèñÊï∞ÊçÆÁöÑReaderÊèí‰ª∂Ôºå‰ª•ÂèäÂêëÁõÆÊ†áÁ´ØÂÜôÂÖ•Êï∞ÊçÆÁöÑWriterÊèí‰ª∂ÔºåÁêÜËÆ∫‰∏äDataXÊ°ÜÊû∂ÂèØ‰ª•ÊîØÊåÅ‰ªªÊÑèÊï∞ÊçÆÊ∫êÁ±ªÂûãÁöÑÊï∞ÊçÆÂêåÊ≠•Â∑•‰Ωú„ÄÇÂêåÊó∂DataXÊèí‰ª∂‰ΩìÁ≥ª‰Ωú‰∏∫‰∏ÄÂ•óÁîüÊÄÅÁ≥ªÁªü, ÊØèÊé•ÂÖ•‰∏ÄÂ•óÊñ∞Êï∞ÊçÆÊ∫êËØ•Êñ∞Âä†ÂÖ•ÁöÑÊï∞ÊçÆÊ∫êÂç≥ÂèØÂÆûÁé∞ÂíåÁé∞ÊúâÁöÑÊï∞ÊçÆÊ∫ê‰∫íÈÄö„ÄÇ\n\n\n\n# DataXËØ¶ÁªÜ‰ªãÁªç\n\n##### ËØ∑ÂèÇËÄÉÔºö[DataX-Introduction](https://github.com/alibaba/DataX/blob/master/introduction.md)\n\n\n\n# Quick Start\n\n##### Download [DataX‰∏ãËΩΩÂú∞ÂùÄ](https://datax-opensource.oss-cn-hangzhou.aliyuncs.com/202308/datax.tar.gz)\n\n\n##### ËØ∑ÁÇπÂáªÔºö[Quick Start](https://github.com/alibaba/DataX/blob/master/userGuid.md)\n\n\n\n# Support Data Channels \n\nDataXÁõÆÂâçÂ∑≤ÁªèÊúâ‰∫ÜÊØîËæÉÂÖ®Èù¢ÁöÑÊèí‰ª∂‰ΩìÁ≥ªÔºå‰∏ªÊµÅÁöÑRDBMSÊï∞ÊçÆÂ∫ì„ÄÅNOSQL„ÄÅÂ§ßÊï∞ÊçÆËÆ°ÁÆóÁ≥ªÁªüÈÉΩÂ∑≤ÁªèÊé•ÂÖ•ÔºåÁõÆÂâçÊîØÊåÅÊï∞ÊçÆÂ¶Ç‰∏ãÂõæÔºåËØ¶ÊÉÖËØ∑ÁÇπÂáªÔºö[DataXÊï∞ÊçÆÊ∫êÂèÇËÄÉÊåáÂçó](https://github.com/alibaba/DataX/wiki/DataX-all-data-channels)\n\n| Á±ªÂûã               | Êï∞ÊçÆÊ∫ê                          | Reader(ËØª) | Writer(ÂÜô) |                                                                                                                       ÊñáÊ°£                                                                                                                       |\n|--------------|---------------------------|:---------:|:---------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|\n| RDBMS ÂÖ≥Á≥ªÂûãÊï∞ÊçÆÂ∫ì | MySQL                           |     ‚àö      |     ‚àö      |                                       [ËØª](https://github.com/alibaba/DataX/blob/master/mysqlreader/doc/mysqlreader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/mysqlwriter/doc/mysqlwriter.md)                                       |\n|                    | Oracle                          |     ‚àö      |     ‚àö      |                                     [ËØª](https://github.com/alibaba/DataX/blob/master/oraclereader/doc/oraclereader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/oraclewriter/doc/oraclewriter.md)                                     |\n|                    | OceanBase                       |     ‚àö      |     ‚àö      | [ËØª](https://github.com/alibaba/DataX/blob/master/oceanbasev10reader/doc/oceanbasev10reader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/oceanbasev10writer/doc/oceanbasev10writer.md) |\n|                    | SQLServer                       |     ‚àö      |     ‚àö      |                               [ËØª](https://github.com/alibaba/DataX/blob/master/sqlserverreader/doc/sqlserverreader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/sqlserverwriter/doc/sqlserverwriter.md)                               |\n|                    | PostgreSQL                      |     ‚àö      |     ‚àö      |                             [ËØª](https://github.com/alibaba/DataX/blob/master/postgresqlreader/doc/postgresqlreader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/postgresqlwriter/doc/postgresqlwriter.md)                             |\n|                    | DRDS                            |     ‚àö      |     ‚àö      |                                         [ËØª](https://github.com/alibaba/DataX/blob/master/drdsreader/doc/drdsreader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/drdswriter/doc/drdswriter.md)                                         |\n|                    | Kingbase                        |     ‚àö      |     ‚àö      |                                         [ËØª](https://github.com/alibaba/DataX/blob/master/drdsreader/doc/drdsreader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/drdswriter/doc/drdswriter.md)                                         |\n|                    | ÈÄöÁî®RDBMS(ÊîØÊåÅÊâÄÊúâÂÖ≥Á≥ªÂûãÊï∞ÊçÆÂ∫ì) |     ‚àö      |     ‚àö      |                                       [ËØª](https://github.com/alibaba/DataX/blob/master/rdbmsreader/doc/rdbmsreader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/rdbmswriter/doc/rdbmswriter.md)                                       |\n| ÈòøÈáå‰∫ëÊï∞‰ªìÊï∞ÊçÆÂ≠òÂÇ® | ODPS                            |     ‚àö      |     ‚àö      |                                         [ËØª](https://github.com/alibaba/DataX/blob/master/odpsreader/doc/odpsreader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/odpswriter/doc/odpswriter.md)                                         |\n|                    | ADB                             |            |     ‚àö      |                                                                             [ÂÜô](https://github.com/alibaba/DataX/blob/master/adbmysqlwriter/doc/adbmysqlwriter.md)                                                                             |\n|                    | ADS                             |            |     ‚àö      |                                                                                  [ÂÜô](https://github.com/alibaba/DataX/blob/master/adswriter/doc/adswriter.md)                                                                                  |\n|                    | OSS                             |     ‚àö      |     ‚àö      |                                           [ËØª](https://github.com/alibaba/DataX/blob/master/ossreader/doc/ossreader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/osswriter/doc/osswriter.md)                                           |\n|                    | OCS                             |            |     ‚àö      |                                                                                  [ÂÜô](https://github.com/alibaba/DataX/blob/master/ocswriter/doc/ocswriter.md)                                                                                  |\n|                    | Hologres                        |            |     ‚àö      |                                                                         [ÂÜô](https://github.com/alibaba/DataX/blob/master/hologresjdbcwriter/doc/hologresjdbcwriter.md)                                                                         |\n|                    | AnalyticDB For PostgreSQL       |            |     ‚àö      |                                                                                                                       ÂÜô                                                                                                                        |\n| ÈòøÈáå‰∫ë‰∏≠Èó¥‰ª∂       | datahub                         |     ‚àö      |     ‚àö      |                                                                                                                      ËØª „ÄÅÂÜô                                                                                                                      |\n|                    | SLS                             |     ‚àö      |     ‚àö      |                                                                                                                      ËØª „ÄÅÂÜô                                                                                                                      |\n| ÂõæÊï∞ÊçÆÂ∫ì           | ÈòøÈáå‰∫ë GDB                      |     ‚àö      |     ‚àö      |                                           [ËØª](https://github.com/alibaba/DataX/blob/master/gdbreader/doc/gdbreader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/gdbwriter/doc/gdbwriter.md)                                           |\n|                    | Neo4j                           |            |     ‚àö      |                                                                                [ÂÜô](https://github.com/alibaba/DataX/blob/master/neo4jwriter/doc/neo4jwriter.md)                                                                                |\n| NoSQLÊï∞ÊçÆÂ≠òÂÇ®      | OTS                             |     ‚àö      |     ‚àö      |                                           [ËØª](https://github.com/alibaba/DataX/blob/master/otsreader/doc/otsreader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/otswriter/doc/otswriter.md)                                           |\n|                    | Hbase0.94                       |     ‚àö      |     ‚àö      |                               [ËØª](https://github.com/alibaba/DataX/blob/master/hbase094xreader/doc/hbase094xreader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/hbase094xwriter/doc/hbase094xwriter.md)                               |\n|                    | Hbase1.1                        |     ‚àö      |     ‚àö      |                                 [ËØª](https://github.com/alibaba/DataX/blob/master/hbase11xreader/doc/hbase11xreader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/hbase11xwriter/doc/hbase11xwriter.md)                                 |\n|                    | Phoenix4.x                      |     ‚àö      |     ‚àö      |                           [ËØª](https://github.com/alibaba/DataX/blob/master/hbase11xsqlreader/doc/hbase11xsqlreader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/hbase11xsqlwriter/doc/hbase11xsqlwriter.md)                           |\n|                    | Phoenix5.x                      |     ‚àö      |     ‚àö      |                           [ËØª](https://github.com/alibaba/DataX/blob/master/hbase20xsqlreader/doc/hbase20xsqlreader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/hbase20xsqlwriter/doc/hbase20xsqlwriter.md)                           |\n|                    | MongoDB                         |     ‚àö      |     ‚àö      |                                   [ËØª](https://github.com/alibaba/DataX/blob/master/mongodbreader/doc/mongodbreader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/mongodbwriter/doc/mongodbwriter.md)                                   |\n|                    | Cassandra                       |     ‚àö      |     ‚àö      |                               [ËØª](https://github.com/alibaba/DataX/blob/master/cassandrareader/doc/cassandrareader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/cassandrawriter/doc/cassandrawriter.md)                               |\n| Êï∞‰ªìÊï∞ÊçÆÂ≠òÂÇ®       | StarRocks                       |     ‚àö      |     ‚àö      |                                                                          ËØª „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/starrockswriter/doc/starrockswriter.md)                                                                           |\n|                    | ApacheDoris                     |            |     ‚àö      |                                                                                [ÂÜô](https://github.com/alibaba/DataX/blob/master/doriswriter/doc/doriswriter.md)                                                                                |\n|                    | ClickHouse                      |     ‚àö      |     ‚àö      |                              [ËØª](https://github.com/alibaba/DataX/blob/master/clickhousereader/doc/clickhousereader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/clickhousewriter/doc/clickhousewriter.md)                               |\n|                    | Databend                        |            |     ‚àö      |                                                                             [ÂÜô](https://github.com/alibaba/DataX/blob/master/databendwriter/doc/databendwriter.md)                                                                             |\n|                    | Hive                            |     ‚àö      |     ‚àö      |                                         [ËØª](https://github.com/alibaba/DataX/blob/master/hdfsreader/doc/hdfsreader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/hdfswriter/doc/hdfswriter.md)                                         |\n|                    | kudu                            |            |     ‚àö      |                                                                                 [ÂÜô](https://github.com/alibaba/DataX/blob/master/hdfswriter/doc/hdfswriter.md)                                                                                 |\n|                    | selectdb                        |            |     ‚àö      |                                                                             [ÂÜô](https://github.com/alibaba/DataX/blob/master/selectdbwriter/doc/selectdbwriter.md)                                                                             |\n| Êó†ÁªìÊûÑÂåñÊï∞ÊçÆÂ≠òÂÇ®   | TxtFile                         |     ‚àö      |     ‚àö      |                                   [ËØª](https://github.com/alibaba/DataX/blob/master/txtfilereader/doc/txtfilereader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/txtfilewriter/doc/txtfilewriter.md)                                   |\n|                    | FTP                             |     ‚àö      |     ‚àö      |                                           [ËØª](https://github.com/alibaba/DataX/blob/master/ftpreader/doc/ftpreader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/ftpwriter/doc/ftpwriter.md)                                           |\n|                    | HDFS                            |     ‚àö      |     ‚àö      |                                         [ËØª](https://github.com/alibaba/DataX/blob/master/hdfsreader/doc/hdfsreader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/hdfswriter/doc/hdfswriter.md)                                         |\n|                    | Elasticsearch                   |            |     ‚àö      |                                                                        [ÂÜô](https://github.com/alibaba/DataX/blob/master/elasticsearchwriter/doc/elasticsearchwriter.md)                                                                        |\n| Êó∂Èó¥Â∫èÂàóÊï∞ÊçÆÂ∫ì     | OpenTSDB                        |     ‚àö      |            |                                                                             [ËØª](https://github.com/alibaba/DataX/blob/master/opentsdbreader/doc/opentsdbreader.md)                                                                             |\n|                    | TSDB                            |     ‚àö      |     ‚àö      |                                       [ËØª](https://github.com/alibaba/DataX/blob/master/tsdbreader/doc/tsdbreader.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/tsdbwriter/doc/tsdbhttpwriter.md)                                       |\n|                    | TDengine                        |     ‚àö      |     ‚àö      |                              [ËØª](https://github.com/alibaba/DataX/blob/master/tdenginereader/doc/tdenginereader-CN.md) „ÄÅ[ÂÜô](https://github.com/alibaba/DataX/blob/master/tdenginewriter/doc/tdenginewriter-CN.md)                              |\n\n# ÈòøÈáå‰∫ëDataWorksÊï∞ÊçÆÈõÜÊàê\n\nÁõÆÂâçDataXÁöÑÂ∑≤ÊúâËÉΩÂäõÂ∑≤ÁªèÂÖ®ÈÉ®ËûçÂíåËøõÈòøÈáå‰∫ëÁöÑÊï∞ÊçÆÈõÜÊàêÔºåÂπ∂‰∏îÊØîDataXÊõ¥Âä†È´òÊïà„ÄÅÂÆâÂÖ®ÔºåÂêåÊó∂Êï∞ÊçÆÈõÜÊàêÂÖ∑Â§áDataX‰∏çÂÖ∑Â§áÁöÑÂÖ∂ÂÆÉÈ´òÁ∫ßÁâπÊÄßÂíåÂäüËÉΩ„ÄÇÂèØ‰ª•ÁêÜËß£‰∏∫Êï∞ÊçÆÈõÜÊàêÊòØDataXÁöÑÂÖ®Èù¢ÂçáÁ∫ßÁöÑÂïÜ‰∏öÂåñÁî®ÁâàÊú¨Ôºå‰∏∫‰ºÅ‰∏öÂèØ‰ª•Êèê‰æõÁ®≥ÂÆö„ÄÅÂèØÈù†„ÄÅÂÆâÂÖ®ÁöÑÊï∞ÊçÆ‰º†ËæìÊúçÂä°„ÄÇ‰∏éDataXÁõ∏ÊØîÔºåÊï∞ÊçÆÈõÜÊàê‰∏ªË¶ÅÊúâ‰ª•‰∏ãÂá†Â§ßÁ™ÅÂá∫ÁâπÁÇπÔºö\n\nÊîØÊåÅÂÆûÊó∂ÂêåÊ≠•Ôºö\n\n- ÂäüËÉΩÁÆÄ‰ªãÔºöhttps://help.aliyun.com/document_detail/181912.html\n- ÊîØÊåÅÁöÑÊï∞ÊçÆÊ∫êÔºöhttps://help.aliyun.com/document_detail/146778.html\n- ÊîØÊåÅÊï∞ÊçÆÂ§ÑÁêÜÔºöhttps://help.aliyun.com/document_detail/146777.html\n\nÁ¶ªÁ∫øÂêåÊ≠•Êï∞ÊçÆÊ∫êÁßçÁ±ªÂ§ßÂπÖÂ∫¶Êâ©ÂÖÖÔºö\n\n- Êñ∞Â¢ûÊØîÂ¶ÇÔºöDB2„ÄÅKafka„ÄÅHologres„ÄÅMetaQ„ÄÅSAPHANA„ÄÅËææÊ¢¶Á≠âÁ≠âÔºåÊåÅÁª≠Êâ©ÂÖÖ‰∏≠\n- Á¶ªÁ∫øÂêåÊ≠•ÊîØÊåÅÁöÑÊï∞ÊçÆÊ∫êÔºöhttps://help.aliyun.com/document_detail/137670.html\n- ÂÖ∑Â§áÂêåÊ≠•Ëß£ÂÜ≥ÊñπÊ°àÔºö\n    - Ëß£ÂÜ≥ÊñπÊ°àÁ≥ªÁªüÔºöhttps://help.aliyun.com/document_detail/171765.html\n    - ‰∏ÄÈîÆÂÖ®Â¢ûÈáèÔºöhttps://help.aliyun.com/document_detail/175676.html\n    - Êï¥Â∫ìËøÅÁßªÔºöhttps://help.aliyun.com/document_detail/137809.html\n    - ÊâπÈáè‰∏ä‰∫ëÔºöhttps://help.aliyun.com/document_detail/146671.html\n    - Êõ¥Êñ∞Êõ¥Â§öËÉΩÂäõËØ∑ËÆøÈóÆÔºöhttps://help.aliyun.com/document_detail/137663.html\n    -\n\n# ÊàëË¶ÅÂºÄÂèëÊñ∞ÁöÑÊèí‰ª∂\n\nËØ∑ÁÇπÂáªÔºö[DataXÊèí‰ª∂ÂºÄÂèëÂÆùÂÖ∏](https://github.com/alibaba/DataX/blob/master/dataxPluginDev.md)\n\n# ÈáçË¶ÅÁâàÊú¨Êõ¥Êñ∞ËØ¥Êòé\n\nDataX ÂêéÁª≠ËÆ°ÂàíÊúàÂ∫¶Ëø≠‰ª£Êõ¥Êñ∞Ôºå‰πüÊ¨¢ËøéÊÑüÂÖ¥Ë∂£ÁöÑÂêåÂ≠¶Êèê‰∫§ Pull requestsÔºåÊúàÂ∫¶Êõ¥Êñ∞ÂÜÖÂÆπÂ¶Ç‰∏ã„ÄÇ\n\n- [datax_v202309]Ôºàhttps://github.com/alibaba/DataX/releases/tag/datax_v202309)\n  - ÊîØÊåÅPhoenix ÂêåÊ≠•Êï∞ÊçÆÊ∑ªÂä† whereÊù°‰ª∂\n  - ÊîØÊåÅÂçé‰∏∫ GuassDBËØªÂÜôÊèí‰ª∂\n  - ‰øÆÂ§çClickReader Êèí‰ª∂ËøêË°åÊä•Èîô Can't find bundle for base name\n  - Â¢ûÂä† DataXË∞ÉËØïÊ®°Âùó\n  - ‰øÆÂ§ç orcÁ©∫Êñá‰ª∂Êä•ÈîôÈóÆÈ¢ò\n  - ‰ºòÂåñobwriterÊÄßËÉΩ\n  - txtfilewriter Â¢ûÂä†ÂØºÂá∫‰∏∫insertËØ≠Âè•ÂäüËÉΩÊîØÊåÅ\n  - HdfsReader/HdfsWriter ÊîØÊåÅparquetËØªÂÜôËÉΩÂäõ\n  \n- [datax_v202308]Ôºàhttps://github.com/alibaba/DataX/releases/tag/datax_v202308)\n  - OTS Êèí‰ª∂Êõ¥Êñ∞\n  - databend Êèí‰ª∂Êõ¥Êñ∞\n  - OceanbaseÈ©±Âä®‰øÆÂ§ç\n\n\n- [datax_v202306]Ôºàhttps://github.com/alibaba/DataX/releases/tag/datax_v202306)\n  - Á≤æÁÆÄ‰ª£Á†Å\n  - Êñ∞Â¢ûÊèí‰ª∂Ôºàneo4jwriter„ÄÅclickhousewriterÔºâ\n  - ‰ºòÂåñÊèí‰ª∂„ÄÅ‰øÆÂ§çÈóÆÈ¢òÔºàoceanbase„ÄÅhdfs„ÄÅdatabend„ÄÅtxtfileÔºâ\n\n\n- [datax_v202303]Ôºàhttps://github.com/alibaba/DataX/releases/tag/datax_v202303)\n  - Á≤æÁÆÄ‰ª£Á†Å\n  - Êñ∞Â¢ûÊèí‰ª∂Ôºàadbmysqlwriter„ÄÅdatabendwriter„ÄÅselectdbwriterÔºâ\n  - ‰ºòÂåñÊèí‰ª∂„ÄÅ‰øÆÂ§çÈóÆÈ¢òÔºàsqlserver„ÄÅhdfs„ÄÅcassandra„ÄÅkudu„ÄÅossÔºâ\n  - fastjson ÂçáÁ∫ßÂà∞ fastjson2\n\n- [datax_v202210]Ôºàhttps://github.com/alibaba/DataX/releases/tag/datax_v202210)\n  - Ê∂âÂèäÈÄöÈÅìËÉΩÂäõÊõ¥Êñ∞ÔºàOceanBase„ÄÅTdengine„ÄÅDorisÁ≠âÔºâ\n\n- [datax_v202209]Ôºàhttps://github.com/alibaba/DataX/releases/tag/datax_v202209)\n    - Ê∂âÂèäÈÄöÈÅìËÉΩÂäõÊõ¥Êñ∞ÔºàMaxCompute„ÄÅDatahub„ÄÅSLSÁ≠âÔºâ„ÄÅÂÆâÂÖ®ÊºèÊ¥ûÊõ¥Êñ∞„ÄÅÈÄöÁî®ÊâìÂåÖÊõ¥Êñ∞Á≠â\n\n- [datax_v202205]Ôºàhttps://github.com/alibaba/DataX/releases/tag/datax_v202205)\n    - Ê∂âÂèäÈÄöÈÅìËÉΩÂäõÊõ¥Êñ∞ÔºàMaxCompute„ÄÅHologres„ÄÅOSS„ÄÅTdengineÁ≠âÔºâ„ÄÅÂÆâÂÖ®ÊºèÊ¥ûÊõ¥Êñ∞„ÄÅÈÄöÁî®ÊâìÂåÖÊõ¥Êñ∞Á≠â\n\n\n# È°πÁõÆÊàêÂëò\n\nÊ†∏ÂøÉContributions: Ë®ÄÊüè „ÄÅÊûïÊ∞¥„ÄÅÁßãÂ•á„ÄÅÈùíÁ†æ„ÄÅ‰∏ÄÊñÖ„ÄÅ‰∫ëÊó∂\n\nÊÑüË∞¢Â§©ÁÉ¨„ÄÅÂÖâÊàà„ÄÅÁ•ÅÁÑ∂„ÄÅÂ∑¥Áúü„ÄÅÈùôË°åÂØπDataXÂÅöÂá∫ÁöÑË¥°ÁåÆ„ÄÇ\n\n# License\n\nThis software is free to use under the Apache License [Apache license](https://github.com/alibaba/DataX/blob/master/license.txt).\n\n# \nËØ∑ÂèäÊó∂ÊèêÂá∫issueÁªôÊàë‰ª¨„ÄÇËØ∑ÂâçÂæÄÔºö[DataxIssue](https://github.com/alibaba/DataX/issues)\n\n# ÂºÄÊ∫êÁâàDataX‰ºÅ‰∏öÁî®Êà∑\n\n![Datax-logo](https://github.com/alibaba/DataX/blob/master/images/datax-enterprise-users.jpg)\n\n```\nÈïøÊúüÊãõËÅò ËÅîÁ≥ªÈÇÆÁÆ±Ôºödatax@alibabacloud.com\n„ÄêJAVAÂºÄÂèëËÅå‰Ωç„Äë\nËÅå‰ΩçÂêçÁß∞ÔºöJAVAËµÑÊ∑±ÂºÄÂèëÂ∑•Á®ãÂ∏à/‰∏ìÂÆ∂/È´òÁ∫ß‰∏ìÂÆ∂\nÂ∑•‰ΩúÂπ¥Èôê : 2Âπ¥‰ª•‰∏ä\nÂ≠¶ÂéÜË¶ÅÊ±Ç : Êú¨ÁßëÔºàÂ¶ÇÊûúËÉΩÂäõÈù†Ë∞±ÔºåËøô‰∫õÈÉΩ‰∏çÊòØÊù°‰ª∂Ôºâ\nÊúüÊúõÂ±ÇÁ∫ß : P6/P7/P8\n\nÂ≤ó‰ΩçÊèèËø∞Ôºö\n    1. Ë¥üË¥£ÈòøÈáå‰∫ëÂ§ßÊï∞ÊçÆÂπ≥Âè∞ÔºàÊï∞Âä†ÔºâÁöÑÂºÄÂèëËÆæËÆ°„ÄÇ \n    2. Ë¥üË¥£Èù¢ÂêëÊîø‰ºÅÂÆ¢Êà∑ÁöÑÂ§ßÊï∞ÊçÆÁõ∏ÂÖ≥‰∫ßÂìÅÂºÄÂèëÔºõ\n    3. Âà©Áî®Â§ßËßÑÊ®°Êú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÊåñÊéòÊï∞ÊçÆ‰πãÈó¥ÁöÑËÅîÁ≥ªÔºåÊé¢Á¥¢Êï∞ÊçÆÊåñÊéòÊäÄÊúØÂú®ÂÆûÈôÖÂú∫ÊôØ‰∏≠ÁöÑ‰∫ßÂìÅÂ∫îÁî® Ôºõ\n    4. ‰∏ÄÁ´ôÂºèÂ§ßÊï∞ÊçÆÂºÄÂèëÂπ≥Âè∞\n    5. Â§ßÊï∞ÊçÆ‰ªªÂä°Ë∞ÉÂ∫¶ÂºïÊìé\n    6. ‰ªªÂä°ÊâßË°åÂºïÊìé\n    7. ‰ªªÂä°ÁõëÊéßÂëäË≠¶\n    8. Êµ∑ÈáèÂºÇÊûÑÊï∞ÊçÆÂêåÊ≠•\n\nÂ≤ó‰ΩçË¶ÅÊ±ÇÔºö\n    1. Êã•Êúâ3Âπ¥‰ª•‰∏äJAVA WebÂºÄÂèëÁªèÈ™åÔºõ\n    2. ÁÜüÊÇâJavaÁöÑÂü∫Á°ÄÊäÄÊúØ‰ΩìÁ≥ª„ÄÇÂåÖÊã¨JVM„ÄÅÁ±ªË£ÖËΩΩ„ÄÅÁ∫øÁ®ã„ÄÅÂπ∂Âèë„ÄÅIOËµÑÊ∫êÁÆ°ÁêÜ„ÄÅÁΩëÁªúÔºõ\n    3. ÁÜüÁªÉ‰ΩøÁî®Â∏∏Áî®JavaÊäÄÊúØÊ°ÜÊû∂„ÄÅÂØπÊñ∞ÊäÄÊúØÊ°ÜÊû∂ÊúâÊïèÈîêÊÑüÁü•ËÉΩÂäõÔºõÊ∑±ÂàªÁêÜËß£Èù¢ÂêëÂØπË±°„ÄÅËÆæËÆ°ÂéüÂàô„ÄÅÂ∞ÅË£ÖÊäΩË±°Ôºõ\n    4. ÁÜüÊÇâHTML/HTML5ÂíåJavaScriptÔºõÁÜüÊÇâSQLËØ≠Ë®ÄÔºõ\n    5. ÊâßË°åÂäõÂº∫ÔºåÂÖ∑Êúâ‰ºòÁßÄÁöÑÂõ¢ÈòüÂêà‰ΩúÁ≤æÁ•û„ÄÅÊï¨‰∏öÁ≤æÁ•ûÔºõ\n    6. Ê∑±ÂàªÁêÜËß£ËÆæËÆ°Ê®°ÂºèÂèäÂ∫îÁî®Âú∫ÊôØËÄÖÂä†ÂàÜÔºõ\n    7. ÂÖ∑ÊúâËæÉÂº∫ÁöÑÈóÆÈ¢òÂàÜÊûêÂíåÂ§ÑÁêÜËÉΩÂäõ„ÄÅÊØîËæÉÂº∫ÁöÑÂä®ÊâãËÉΩÂäõÔºåÂØπÊäÄÊúØÊúâÂº∫ÁÉàËøΩÊ±ÇËÄÖ‰ºòÂÖàËÄÉËôëÔºõ\n    8. ÂØπÈ´òÂπ∂Âèë„ÄÅÈ´òÁ®≥ÂÆöÂèØÁî®ÊÄß„ÄÅÈ´òÊÄßËÉΩ„ÄÅÂ§ßÊï∞ÊçÆÂ§ÑÁêÜÊúâËøáÂÆûÈôÖÈ°πÁõÆÂèä‰∫ßÂìÅÁªèÈ™åËÄÖ‰ºòÂÖàËÄÉËôëÔºõ\n    9. ÊúâÂ§ßÊï∞ÊçÆ‰∫ßÂìÅ„ÄÅ‰∫ë‰∫ßÂìÅ„ÄÅ‰∏≠Èó¥‰ª∂ÊäÄÊúØËß£ÂÜ≥ÊñπÊ°àËÄÖ‰ºòÂÖàËÄÉËôë„ÄÇ\n````\n\nÁî®Êà∑Âí®ËØ¢ÊîØÊåÅÔºö\n\nÈíâÈíâÁæ§ÁõÆÂâçÊöÇÊó∂ÂèóÂà∞‰∫Ü‰∏Ä‰∫õÁÆ°ÊéßÁ≠ñÁï•ÂΩ±ÂìçÔºåÂª∫ËÆÆÂ§ßÂÆ∂ÊúâÈóÆÈ¢ò‰ºòÂÖàÂú®ËøôÈáåÊèê‰∫§ÈóÆÈ¢ò IssueÔºåDataXÁ†îÂèëÂíåÁ§æÂå∫‰ºöÂÆöÊúüÂõûÁ≠îIssue‰∏≠ÁöÑÈóÆÈ¢òÔºåÁü•ËØÜÂ∫ì‰∏∞ÂØåÂêé‰πüËÉΩÂ∏ÆÂä©Âà∞ÂêéÊù•ÁöÑ‰ΩøÁî®ËÄÖ„ÄÇ\n\n\n\n",
      "stars_today": 2
    },
    {
      "id": 49910095,
      "name": "vapor",
      "full_name": "vapor/vapor",
      "description": "üíß A server-side Swift HTTP web framework.",
      "html_url": "https://github.com/vapor/vapor",
      "stars": 25918,
      "forks": 1522,
      "language": "Swift",
      "topics": [
        "framework",
        "http",
        "http2",
        "server",
        "server-side-swift",
        "swift",
        "vapor",
        "web-framework"
      ],
      "created_at": "2016-01-18T22:37:52Z",
      "updated_at": "2026-01-23T19:08:22Z",
      "pushed_at": "2026-01-22T17:44:23Z",
      "open_issues": 112,
      "owner": {
        "login": "vapor",
        "avatar_url": "https://avatars.githubusercontent.com/u/17364220?v=4"
      },
      "readme": "<a href=\"https://discord.gg/vapor\">\n\n![Vapor](https://user-images.githubusercontent.com/1342803/75634175-4876d680-5bd9-11ea-90d6-12c7b6a9ee3f.png)\n\n</a>\n\n<p align=\"center\">\n    <a href=\"https://docs.vapor.codes/4.0/\">\n        <img src=\"https://design.vapor.codes/images/readthedocs.svg\" alt=\"Documentation\">\n    </a>\n    <a href=\"https://discord.gg/vapor\">\n        <img src=\"https://design.vapor.codes/images/discordchat.svg\" alt=\"Team Chat\">\n    </a>\n    <a href=\"LICENSE\">\n        <img src=\"https://design.vapor.codes/images/mitlicense.svg\" alt=\"MIT License\">\n    </a>\n    <a href=\"https://github.com/vapor/vapor/actions/workflows/test.yml\">\n        <img src=\"https://img.shields.io/github/actions/workflow/status/vapor/vapor/test.yml?event=push&style=plastic&logo=github&label=tests&logoColor=%23ccc\" alt=\"Continuous Integration\">\n    </a>\n    <a href=\"https://codecov.io/gh/vapor/vapor\">\n        <img src=\"https://img.shields.io/codecov/c/github/vapor/vapor?style=plastic&logo=codecov&label=codecov\" alt=\"Code Coverage\">\n    </a>\n    <a href=\"https://swift.org\">\n        <img src=\"https://design.vapor.codes/images/swift60up.svg\" alt=\"Swift 6.0+\">\n    </a>\n    <a href=\"https://hachyderm.io/@codevapor\">\n        <img src=\"https://img.shields.io/badge/%20-@codevapor-6364f6.svg?style=plastic&logo=mastodon&labelColor=gray&logoColor=%239394ff\" alt=\"Mastodon\">\n    </a>\n</p>\n\n<br>\n\nVapor is an HTTP web framework for Swift. It provides a beautifully expressive and easy-to-use foundation for your next website, API, or cloud project.\n\nTake a look at some of the [awesome stuff](https://github.com/vapor-community/awesome-vapor) created with Vapor.\n\n### üíß Community\n\nJoin the welcoming community of fellow Vapor developers on [Discord](https://vapor.team).\n\n### üöÄ Contributing\n\nTo contribute a **feature or idea** to Vapor, [create an issue](https://github.com/vapor/vapor/issues/new) explaining your idea or bring it up on [Discord](https://vapor.team).\n\nIf you find a **bug**, please [create an issue](https://github.com/vapor/vapor/issues/new). \n\nIf you find a **security vulnerability**, please contact [security@vapor.codes](mailto:security@vapor.codes) as soon as possible.\n\n### üíõ Sponsors\n\nSupport Vapor's development by [becoming a sponsor](https://github.com/sponsors/vapor).\n\n<a href=\"https://www.brokenhands.io\">\n    <img src=\"https://user-images.githubusercontent.com/9938337/137103192-21f99099-6aaa-4cc1-a1a7-21ee767a72d1.png\" height=\"100px\" alt=\"Broken Hands\">\n</a>\n<a href=\"https://www.emergetools.com\">\n    <img src=\"https://user-images.githubusercontent.com/9938337/265658253-cb37d2fa-3251-497f-8eeb-ba7c95af373b.svg\" height=\"100px\" alt=\"Emerge Tools\">\n</a>\n<a href=\"https://github.com/MrLotU\">\n    <img src=\"https://user-images.githubusercontent.com/1342803/79599312-426a8580-80b3-11ea-89b3-8b2722485e37.png\" height=\"100px\" alt=\"Jari\">\n</a>\n<a href=\"https://github.com/DonutDane\">\n    <img src=\"https://user-images.githubusercontent.com/9938337/265657642-6b6b1705-9611-4547-8e2f-a3773fda87c6.png\" height=\"100px\" alt=\"Donut Dane\">\n</a>\n<a href=\"https://macstadium.com\">\n    <img src=\"https://uploads-ssl.webflow.com/5ac3c046c82724970fc60918/5c019d917bba312af7553b49_MacStadium-developerlogo.png\" height=\"100px\" alt=\"MacStadium\">\n</a>\n\n\n\n### üíö Backers\nSupport Vapor's development by [becoming a backer](https://github.com/sponsors/vapor).\n\n<!-- backers --><a href=\"https://github.com/slashmo\"><img src=\"https://github.com/slashmo.png\" width=\"60px\" alt=\"Moritz Lang\" /></a><a href=\"https://github.com/maartene\"><img src=\"https://github.com/maartene.png\" width=\"60px\" alt=\"Maarten Engels\" /></a><a href=\"https://github.com/tkrajacic\"><img src=\"https://github.com/tkrajacic.png\" width=\"60px\" alt=\"Thomas Krajacic\" /></a><a href=\"https://github.com/jessetipton\"><img src=\"https://github.com/jessetipton.png\" width=\"60px\" alt=\"Jesse Tipton\" /></a><a href=\"https://github.com/steve-h\"><img src=\"https://github.com/steve-h.png\" width=\"60px\" alt=\"Steve Hume\" /></a><a href=\"https://github.com/mikkelu\"><img src=\"https://github.com/mikkelu.png\" width=\"60px\" alt=\"Mikkel Ulstrup\" /></a><a href=\"https://github.com/g-Off\"><img src=\"https://github.com/g-Off.png\" width=\"60px\" alt=\"Geoffrey Foster\" /></a><a href=\"https://github.com/PSchmiedmayer\"><img src=\"https://github.com/PSchmiedmayer.png\" width=\"60px\" alt=\"Paul Schmiedmayer\" /></a><a href=\"https://github.com/ScottRobbins\"><img src=\"https://github.com/ScottRobbins.png\" width=\"60px\" alt=\"Scott Robbins\" /></a><a href=\"https://github.com/finestructure\"><img src=\"https://github.com/finestructure.png\" width=\"60px\" alt=\"Sven A. Schmidt\" /></a><a href=\"https://github.com/SpencerCurtis\"><img src=\"https://github.com/SpencerCurtis.png\" width=\"60px\" alt=\"Spencer Curtis\" /></a><a href=\"https://github.com/rausnitz\"><img src=\"https://github.com/rausnitz.png\" width=\"60px\" alt=\"Zach Rausnitz\" /></a><a href=\"https://github.com/masterofinsanity\"><img src=\"https://github.com/masterofinsanity.png\" width=\"60px\" alt=\"Tim ‚ÄûTiminator‚Äú Kretzschmar\" /></a><a href=\"https://github.com/klaas\"><img src=\"https://github.com/klaas.png\" width=\"60px\" alt=\"Klaas\" /></a><a href=\"https://github.com/Andrewangeta\"><img src=\"https://github.com/Andrewangeta.png\" width=\"60px\" alt=\"Andrew Edwards\" /></a><a href=\"https://github.com/addli\"><img src=\"https://github.com/addli.png\" width=\"60px\" alt=\"+Li, Inc.\" /></a><a href=\"https://github.com/doozMen\"><img src=\"https://github.com/doozMen.png\" width=\"60px\" alt=\"Stijn Willems\" /></a><a href=\"https://github.com/bitwit\"><img src=\"https://github.com/bitwit.png\" width=\"60px\" alt=\"Kyle Newsome\" /></a><a href=\"https://github.com/viaaurelia\"><img src=\"https://github.com/viaaurelia.png\" width=\"60px\" alt=\"Via Aurelia Solutions\" /></a><a href=\"https://github.com/kkiermasz\"><img src=\"https://github.com/kkiermasz.png\" width=\"60px\" alt=\"Jakub Kiermasz\" /></a><a href=\"https://github.com/bdrelling\"><img src=\"https://github.com/bdrelling.png\" width=\"60px\" alt=\"Brian Drelling\" /></a><a href=\"https://github.com/mayondigital\"><img src=\"https://github.com/mayondigital.png\" width=\"60px\" alt=\"\" /></a><a href=\"https://github.com/mattesmohr\"><img src=\"https://github.com/mattesmohr.png\" width=\"60px\" alt=\"Mattes Mohr\" /></a><a href=\"https://github.com/scibidoo\"><img src=\"https://github.com/scibidoo.png\" width=\"60px\" alt=\"Jamie\" /></a><a href=\"https://github.com/GalenRhodes\"><img src=\"https://github.com/GalenRhodes.png\" width=\"60px\" alt=\"Galen Rhodes\" /></a><a href=\"https://github.com/litmaps\"><img src=\"https://github.com/litmaps.png\" width=\"60px\" alt=\"Litmaps\" /></a><a href=\"https://github.com/davdroman\"><img src=\"https://github.com/davdroman.png\" width=\"60px\" alt=\"David Roman\" /></a><a href=\"https://github.com/Strobocop\"><img src=\"https://github.com/Strobocop.png\" width=\"60px\" alt=\"Brian Strobach\" /></a><a href=\"https://github.com/kishikawakatsumi\"><img src=\"https://github.com/kishikawakatsumi.png\" width=\"60px\" alt=\"Kishikawa Katsumi\" /></a><a href=\"https://github.com/mkll\"><img src=\"https://github.com/mkll.png\" width=\"60px\" alt=\"Alex Sherbakov\" /></a><a href=\"https://github.com/getsidetrack\"><img src=\"https://github.com/getsidetrack.png\" width=\"60px\" alt=\"Sidetrack\" /></a><a href=\"https://github.com/GregKarpati\"><img src=\"https://github.com/GregKarpati.png\" width=\"60px\" alt=\"Greg Karpati\" /></a><a href=\"https://github.com/fananek\"><img src=\"https://github.com/fananek.png\" width=\"60px\" alt=\"Franti≈°ek Mik≈°\" /></a><a href=\"https://github.com/jagreenwood\"><img src=\"https://github.com/jagreenwood.png\" width=\"60px\" alt=\"Jeremy Greenwood\" /></a><a href=\"https://github.com/rayfix\"><img src=\"https://github.com/rayfix.png\" width=\"60px\" alt=\"Ray Fix\" /></a><a href=\"https://github.com/micomiloloza\"><img src=\"https://github.com/micomiloloza.png\" width=\"60px\" alt=\"Miƒáo Milolo≈æa\" /></a><a href=\"https://github.com/awamser\"><img src=\"https://github.com/awamser.png\" width=\"60px\" alt=\"Alan\" /></a><a href=\"https://github.com/Suboptimierer\"><img src=\"https://github.com/Suboptimierer.png\" width=\"60px\" alt=\"Jonas Sannewald\" /></a><a href=\"https://github.com/TapEnvy-us-LLC\"><img src=\"https://github.com/TapEnvy-us-LLC.png\" width=\"60px\" alt=\"TapEnvy.us, LLC\" /></a><a href=\"https://github.com/JawadHF\"><img src=\"https://github.com/JawadHF.png\" width=\"60px\" alt=\"Jawad\" /></a><a href=\"https://github.com/PARAIPAN9\"><img src=\"https://github.com/PARAIPAN9.png\" width=\"60px\" alt=\"PARAIPAN SORIN\" /></a><a href=\"https://github.com/KalynDavis\"><img src=\"https://github.com/KalynDavis.png\" width=\"60px\" alt=\"Kalyn Davis\" /></a><a href=\"https://github.com/stevapple\"><img src=\"https://github.com/stevapple.png\" width=\"60px\" alt=\"YR Chen\" /></a><a href=\"https://github.com/roncuevas\"><img src=\"https://github.com/roncuevas.png\" width=\"60px\" alt=\"Aar√≥n Mart√≠nez Cuevas\" /></a><!-- backers -->\n\n<a href=\"https://opencollective.com/vapor/backer/0/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/0/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/1/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/1/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/2/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/2/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/3/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/3/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/4/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/4/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/5/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/5/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/6/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/6/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/7/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/7/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/8/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/8/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/9/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/9/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/10/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/10/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/11/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/11/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/12/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/12/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/13/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/13/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/14/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/14/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/15/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/15/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/16/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/16/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/17/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/17/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/18/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/18/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/19/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/19/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/20/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/20/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/21/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/21/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/22/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/22/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/23/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/23/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/24/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/24/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/25/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/25/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/26/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/26/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/27/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/27/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/28/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/28/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/29/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/29/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/30/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/30/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/31/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/31/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/32/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/32/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/33/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/33/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/34/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/34/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/35/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/35/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/36/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/36/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/37/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/37/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/38/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/38/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/39/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/39/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/40/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/40/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/41/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/41/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/42/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/42/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/43/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/43/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/44/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/44/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/45/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/45/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/46/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/46/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/47/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/47/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/48/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/48/avatar.svg\"></a>\n",
      "stars_today": 2
    },
    {
      "id": 199488860,
      "name": "starter-workflows",
      "full_name": "actions/starter-workflows",
      "description": "Accelerating new GitHub Actions workflows ",
      "html_url": "https://github.com/actions/starter-workflows",
      "stars": 11175,
      "forks": 6743,
      "language": "TypeScript",
      "topics": [
        "actions"
      ],
      "created_at": "2019-07-29T16:26:51Z",
      "updated_at": "2026-01-24T01:40:29Z",
      "pushed_at": "2025-12-04T18:30:49Z",
      "open_issues": 386,
      "owner": {
        "login": "actions",
        "avatar_url": "https://avatars.githubusercontent.com/u/44036562?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"https://avatars0.githubusercontent.com/u/44036562?s=100&v=4\"/> \n</p>\n\n## Starter Workflows\n\nThese are the workflow files for helping people get started with GitHub Actions.  They're presented whenever you start to create a new GitHub Actions workflow.\n\n**If you want to get started with GitHub Actions, you can use these starter workflows by clicking the \"Actions\" tab in the repository where you want to create a workflow.**\n\n<img src=\"https://d3vv6lp55qjaqc.cloudfront.net/items/353A3p3Y2x3c2t2N0c01/Image%202019-08-27%20at%203.25.07%20PM.png\" max-width=\"75%\"/>\n\n### Note\n\nThank you for your interest in this GitHub repo, however, right now we are not taking contributions. \n\nWe continue to focus our resources on strategic areas that help our customers be successful while making developers' lives easier. While GitHub Actions remains a key part of this vision, we are allocating resources towards other areas of Actions and are not taking contributions to this repository at this time. The GitHub public roadmap is the best place to follow along for any updates on features we‚Äôre working on and what stage they‚Äôre in.\n\nWe are taking the following steps to better direct requests related to GitHub Actions, including:\n\n1. We will be directing questions and support requests to our [Community Discussions area](https://github.com/orgs/community/discussions/categories/actions)\n\n2. High Priority bugs can be reported through Community Discussions or you can report these to our support team https://support.github.com/contact/bug-report.\n\n3. Security Issues should be handled as per our [security.md](security.md)\n\nWe will still provide security updates for this project and fix major breaking changes during this time.\n\nYou are welcome to still raise bugs in this repo.\n\n### Directory structure\n\n* [ci](ci): solutions for Continuous Integration workflows\n* [deployments](deployments): solutions for Deployment workflows\n* [automation](automation): solutions for automating workflows\n* [code-scanning](code-scanning): solutions for [Code Scanning](https://github.com/features/security)\n* [pages](pages): solutions for Pages workflows\n* [icons](icons): svg icons for the relevant template\n\nEach workflow must be written in YAML and have a `.yml` extension. They also need a corresponding `.properties.json` file that contains extra metadata about the workflow (this is displayed in the GitHub.com UI).\n\nFor example: `ci/django.yml` and `ci/properties/django.properties.json`.\n\n### Valid properties\n\n* `name`: the name shown in onboarding. This property is unique within the repository.\n* `description`: the description shown in onboarding\n* `iconName`: the icon name in the relevant folder, for example, `django` should have an icon `icons/django.svg`. Only SVG is supported at this time. Another option is to use [octicon](https://primer.style/octicons/). The format to use an octicon is `octicon <<icon name>>`. Example: `octicon person`\n* `creator`: creator of the template shown in onboarding. All the workflow templates from an author will have the same `creator` field.\n* `categories`: the categories that it will be shown under. Choose at least one category from the list [here](#categories). Further, choose the categories from the list of languages available [here](https://github.com/github/linguist/blob/master/lib/linguist/languages.yml) and the list of tech stacks available [here](https://github.com/github-starter-workflows/repo-analysis-partner/blob/main/tech_stacks.yml). When a user views the available templates, those templates that match the language and tech stacks will feature more prominently.\n\n### Categories\n* continuous-integration\n* deployment\n* testing\n* code-quality\n* code-review\n* dependency-management\n* monitoring\n* Automation\n* utilities\n* Pages\n* Hugo\n\n### Variables\nThese variables can be placed in the starter workflow and will be substituted as detailed below:\n\n* `$default-branch`: will substitute the branch from the repository, for example `main` and `master`\n* `$protected-branches`: will substitute any protected branches from the repository\n* `$cron-daily`: will substitute a valid but random time within the day\n\n## How to test templates before publishing\n\n### Disable template for public\nThe template author adds a `labels` array in the template's `properties.json` file with a label `preview`. This will hide the template from users, unless user uses query parameter `preview=true` in the URL.\nExample `properties.json` file:\n```json\n{\n    \"name\": \"Node.js\",\n    \"description\": \"Build and test a Node.js project with npm.\",\n    \"iconName\": \"nodejs\",\n    \"categories\": [\"Continuous integration\", \"JavaScript\", \"npm\", \"React\", \"Angular\", \"Vue\"],\n    \"labels\": [\"preview\"]\n}\n```\n\nFor viewing the templates with `preview` label, provide query parameter `preview=true` to the  `new workflow` page URL. Eg. `https://github.com/<owner>/<repo_name>/actions/new?preview=true`.\n\n### Enable template for public\nRemove the `labels` array from `properties.json` file to publish the template to public\n",
      "stars_today": 2
    },
    {
      "id": 147886080,
      "name": "crossplane",
      "full_name": "crossplane/crossplane",
      "description": "The Cloud Native Control Plane",
      "html_url": "https://github.com/crossplane/crossplane",
      "stars": 11324,
      "forks": 1122,
      "language": "Go",
      "topics": [
        "cloud-computing",
        "cloud-management",
        "cloud-native",
        "cncf",
        "containers",
        "control-plane",
        "infrastructure",
        "infrastructure-as-code",
        "kubernetes",
        "multicloud",
        "serverless"
      ],
      "created_at": "2018-09-08T00:10:35Z",
      "updated_at": "2026-01-23T20:19:06Z",
      "pushed_at": "2026-01-23T08:24:00Z",
      "open_issues": 197,
      "owner": {
        "login": "crossplane",
        "avatar_url": "https://avatars.githubusercontent.com/u/45158470?v=4"
      },
      "readme": "[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/3260/badge)](https://www.bestpractices.dev/projects/3260) ![CI](https://github.com/crossplane/crossplane/workflows/CI/badge.svg) [![Go Report Card](https://goreportcard.com/badge/github.com/crossplane/crossplane)](https://goreportcard.com/report/github.com/crossplane/crossplane)\n\n![Crossplane](banner.png)\n\nCrossplane is a framework for building cloud native control planes without\nneeding to write code. It has a highly extensible backend that enables you to\nbuild a control plane that can orchestrate applications and infrastructure no\nmatter where they run, and a highly configurable frontend that puts you in\ncontrol of the schema of the declarative API it offers.\n\nCrossplane is a [Cloud Native Computing Foundation][cncf] project.\n\n## Get Started\n\nCrossplane's [Get Started Docs] covers install and resource quickstarts.\n\n## Releases\n\n[![GitHub release](https://img.shields.io/github/release/crossplane/crossplane/all.svg)](https://github.com/crossplane/crossplane/releases) [![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/crossplane)](https://artifacthub.io/packages/helm/crossplane/crossplane)\n\nCurrently maintained releases, as well as the next few upcoming releases are\nlisted below. For more information take a look at the Crossplane [release cycle\ndocumentation].\n\n| Release | Release Date  |   EOL    |\n|:-------:|:-------------:|:--------:|\n|  v1.20  | May 21, 2025  | Feb 2026 |\n|  v2.0   |  Aug 8, 2025  | May 2026 |\n|  v2.1   |  Nov 5, 2025  | Aug 2026 |\n|  v2.2   | Early Feb '26 | Nov 2026 |\n|  v2.3   | Early May '26 | Feb 2027 |\n|  v2.4   | Early Aug '26 | May 2027 |\n\nYou can subscribe to the [community calendar] to track all release dates, and\nfind the most recent releases on the [releases] page.\n\nThe release process is fully documented in the [`crossplane/release`] repo.\n\n## Roadmap\n\nThe public roadmap for Crossplane is published as a GitHub project board. Issues\nadded to the roadmap have been triaged and identified as valuable to the\ncommunity, and therefore a priority for the project that we expect to invest in.\n\nThe maintainer team regularly triages requests from the community to identify\nfeatures and issues of suitable scope and impact to include in this roadmap. The\ncommunity is encouraged to show their support for potential roadmap issues by\nadding a :+1: reaction, leaving descriptive comments, and attending the\n[regular community meetings] to discuss their requirements and use cases.\n\nThe maintainer team updates the roadmap on an as needed basis, in response to\ndemand, priority, and available resources. The public roadmap can be updated at\nany time.\n\nMilestones assigned to any issues in the roadmap are intended to give a sense of\noverall priority and the expected order of delivery. They should be considered\napproximate estimations and are **not** a strict commitment to a specific\ndelivery timeline.\n\n[Crossplane Roadmap]\n\n## Get Involved\n\n[![Slack](https://img.shields.io/badge/slack-crossplane-red?logo=slack)](https://slack.crossplane.io) [![Bluesky Follow](https://img.shields.io/badge/bluesky-Follow-blue?logo=bluesky)](https://bsky.app/profile/crossplane.io) [![Twitter Follow](https://img.shields.io/twitter/follow/crossplane_io?logo=X&label=Follow&style=flat)](https://twitter.com/intent/follow?screen_name=crossplane_io&user_id=788180534543339520) [![YouTube Channel Subscribers](https://img.shields.io/youtube/channel/subscribers/UC19FgzMBMqBro361HbE46Fw)](https://www.youtube.com/@Crossplane)\n\nCrossplane is a community driven project; we welcome your contribution. To file\na bug, suggest an improvement, or request a new feature please open an [issue\nagainst Crossplane] or the relevant provider. Refer to our [contributing guide]\nfor more information on how you can help.\n\n* Discuss Crossplane on [Slack].\n* Follow us on [Bluesky], [Twitter], or [LinkedIn].\n* Contact us via [Email].\n* Join our regular community meetings.\n* Provide feedback on our [roadmap and releases board].\n\nThe Crossplane community meeting takes place every 4 weeks on [Thursday at\n10:00am Pacific Time][community meeting time]. You can find the up to date\nmeeting schedule on the [Community Calendar][community calendar].\n\nAnyone who wants to discuss the direction of the project, design and\nimplementation reviews, or raise general questions with the broader community is\nencouraged to join.\n\n* Meeting link: <https://zoom-lfx.platform.linuxfoundation.org/meeting/98901510164?password=c60c41ae-1e1e-42d0-9a74-16de2fbb66f9>\n* [Current agenda and past meeting notes]\n* [Past meeting recordings]\n* [Community Calendar][community calendar]\n\n### Special Interest Groups (SIG)\n\nThe Crossplane project supports SIGs as discussion groups that bring together\ncommunity members with shared interests. SIGs have no decision making authority\nor ownership responsibilities. They serve purely as collaborative forums for\ncommunity discussion.\n\nIf you're interested in any of the areas below, consider joining the discussion\nin their Slack channels. To propose a new SIG that isn't represented, reach out\nthrough any of the contact methods in the [get involved] section.\n\nEach SIG collaborates primarily in Slack, and some groups hold regular meetings\nthat you can find in the [Community Calendar][community calendar].\n\n- [#sig-cli][sig-cli]\n- [#sig-composition-environments][sig-composition-environments-slack]\n- [#sig-composition-functions][sig-composition-functions-slack]\n- [#sig-deletion-ordering][sig-deletion-ordering-slack]\n- [#sig-devex][sig-devex-slack]\n- [#sig-docs][sig-docs-slack]\n- [#sig-e2e-testing][sig-e2e-testing-slack]\n- [#sig-observability][sig-observability-slack]\n- [#sig-observe-only][sig-observe-only-slack]\n- [#sig-provider-families][sig-provider-families-slack]\n- [#sig-secret-stores][sig-secret-stores-slack]\n- [#sig-upjet][sig-upjet-slack]\n\n## Adopters\n\nA list of publicly known users of the Crossplane project can be found in [ADOPTERS.md].  We\nencourage all users of Crossplane to add themselves to this list - we want to see the community's\ngrowing success!\n\n## License\n\nCrossplane is under the Apache 2.0 license.\n\n[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bgithub.com%2Fcrossplane%2Fcrossplane.svg?type=large)](https://app.fossa.io/projects/git%2Bgithub.com%2Fcrossplane%2Fcrossplane?ref=badge_large)\n\n<!-- Named links -->\n\n[Crossplane]: https://crossplane.io\n[release cycle documentation]: https://docs.crossplane.io/knowledge-base/guides/release-cycle\n[install]: https://crossplane.io/docs/latest\n[Slack]: https://slack.crossplane.io\n[Bluesky]: https://bsky.app/profile/crossplane.io\n[Twitter]: https://twitter.com/crossplane_io\n[LinkedIn]: https://www.linkedin.com/company/crossplane/\n[Email]: mailto:crossplane-info@lists.cncf.io\n[issue against Crossplane]: https://github.com/crossplane/crossplane/issues\n[contributing guide]: contributing/README.md\n[community meeting time]: https://www.thetimezoneconverter.com/?t=10:00&tz=PT%20%28Pacific%20Time%29\n[Current agenda and past meeting notes]: https://docs.google.com/document/d/1q_sp2jLQsDEOX7Yug6TPOv7Fwrys6EwcF5Itxjkno7Y/edit?usp=sharing\n[Past meeting recordings]: https://www.youtube.com/playlist?list=PL510POnNVaaYYYDSICFSNWFqNbx1EMr-M\n[roadmap and releases board]: https://github.com/orgs/crossplane/projects/20/views/9?pane=info\n[cncf]: https://www.cncf.io/\n[Get Started Docs]: https://docs.crossplane.io/latest/get-started/get-started-with-composition\n[community calendar]: https://zoom-lfx.platform.linuxfoundation.org/meetings/crossplane?view=month\n[releases]: https://github.com/crossplane/crossplane/releases\n[`crossplane/release`]: https://github.com/crossplane/release\n[ADOPTERS.md]: ADOPTERS.md\n[regular community meetings]: https://github.com/crossplane/crossplane/blob/main/README.md#get-involved\n[Crossplane Roadmap]: https://github.com/orgs/crossplane/projects/20/views/9?pane=info\n[get involved]: https://github.com/crossplane/crossplane/blob/main/README.md#get-involved\n[sig-cli]: https://crossplane.slack.com/archives/C08V9PMLRQA\n[sig-composition-environments-slack]: https://crossplane.slack.com/archives/C05BP6QFLUW\n[sig-composition-functions-slack]: https://crossplane.slack.com/archives/C031Y29CSAE\n[sig-deletion-ordering-slack]: https://crossplane.slack.com/archives/C05BP8W5ALW\n[sig-devex-slack]: https://crossplane.slack.com/archives/C05U1LLM3B2\n[sig-docs-slack]: https://crossplane.slack.com/archives/C02CAQ52DPU\n[sig-e2e-testing-slack]: https://crossplane.slack.com/archives/C05C8CCTVNV\n[sig-observability-slack]: https://crossplane.slack.com/archives/C061GNH3LA0\n[sig-observe-only-slack]: https://crossplane.slack.com/archives/C04D5988QEA\n[sig-provider-families-slack]: https://crossplane.slack.com/archives/C056YAQRV16\n[sig-secret-stores-slack]: https://crossplane.slack.com/archives/C05BY7DKFV2\n[sig-upjet-slack]: https://crossplane.slack.com/archives/C05T19TB729\n",
      "stars_today": 2
    },
    {
      "id": 6687936,
      "name": "mbedtls",
      "full_name": "Mbed-TLS/mbedtls",
      "description": "An open source, portable, easy to use, readable and flexible TLS library, and reference implementation of the PSA Cryptography API. Releases are on a varying cadence, typically around 3 - 6 months between releases.",
      "html_url": "https://github.com/Mbed-TLS/mbedtls",
      "stars": 6412,
      "forks": 2832,
      "language": "C",
      "topics": [
        "crypto",
        "cryptography-library",
        "psa",
        "ssl",
        "tls"
      ],
      "created_at": "2012-11-14T13:13:13Z",
      "updated_at": "2026-01-23T17:08:07Z",
      "pushed_at": "2026-01-22T16:28:25Z",
      "open_issues": 1561,
      "owner": {
        "login": "Mbed-TLS",
        "avatar_url": "https://avatars.githubusercontent.com/u/97226525?v=4"
      },
      "readme": "README for Mbed TLS\n===================\n\nMbed TLS is a C library that implements X.509 certificate manipulation and the TLS and DTLS protocols. Its small code footprint makes it suitable for embedded systems.\nMbed TLS includes the [TF-PSA-Crypto repository](https://github.com/Mbed-TLS/TF-PSA-Crypto) that provides an implementation of the [PSA Cryptography API](https://arm-software.github.io/psa-api).\n\nConfiguration\n-------------\nConfiguration options related to X.509 and TLS are available in `include/mbedtls/mbedtls_config.h`, while cryptography and platform options are located in the TF-PSA-Crypto configuration file `tf-psa-crypto/include/psa/crypto_config.h`.\n\nWith the default platform options, Mbed TLS should build out of the box on most systems.\n\nThese configuration files can be edited manually, or programmatically using the Python script `scripts/config.py` (run with --help for usage instructions).\n\nWe provide some non-standard configurations focused on specific use cases in the `configs/` directory. You can read more about those in `configs/README.txt`.\n\nDocumentation\n-------------\n\nThe main Mbed TLS documentation is available via [ReadTheDocs](https://mbed-tls.readthedocs.io/).\n\nTo generate a local copy of the library documentation in HTML format, tailored to your compile-time configuration:\n\n1. Make sure that [Doxygen](http://www.doxygen.nl/) is installed.\n1. Run `cmake -B /path/to/build_dir /path/to/mbedtls/source`\n1. Run `cmake --build /path/to/build_dir --target mbedtls-apidoc`\n1. Open one of the main generated HTML files:\n   * `apidoc/index.html`\n   * `apidoc/modules.html` or `apidoc/topics.html`\n\nFor other sources of documentation, see the [SUPPORT](SUPPORT.md) document.\n\nCompiling\n---------\n\nWe use CMake to configure and drive our build process. Three libraries are built: `libtfpsacrypto`, `libmbedx509`, and `libmbedtls`. Note that `libmbedtls` depends on `libmbedx509` and `libtfpsacrypto`, and `libmbedx509` depends on `libtfpsacrypto`. As a result, some linkers will expect flags to be in a specific order, for example the GNU linker wants `-lmbedtls -lmbedx509 -ltfpsacrypto`. The cryptographic library `libtfpsacrypto` is also provided under its legacy name, `libmbedcrypto`.\n\n### Tool versions\n\nYou need the following tools to build the library from the main branch with the provided CMake files. Mbed TLS minimum tool version requirements are set based on the versions shipped in the latest or penultimate (depending on the release cadence) long-term support releases of major Linux distributions, namely at time of writing: Ubuntu 22.04, RHEL 9, and SLES 15 SP4.\n\n* CMake 3.20.2 or later.\n* A build system like Make or Ninja for which CMake can generate build files.\n* A C99 toolchain (compiler, linker, archiver). We actively test with GCC 5.4, Clang 3.8, Arm Compiler 6, and Visual Studio 2017 Compiler. More recent versions should work. Slightly older versions may work.\n* Python 3.8 or later to generate the test code. Python is also needed to build the development branch (see next section).\n* Perl to run the tests, and to generate some source files in the development branch.\n* Doxygen 1.8.14 or later (if building the documentation; slightly older versions should work).\n\n### Git usage\n\nThe supported branches (see [`BRANCHES.md`](BRANCHES.md)) use [Git submodules](https://git-scm.com/book/en/v2/Git-Tools-Submodules#_cloning_submodules). They contain two submodules: the [framework](https://github.com/Mbed-TLS/mbedtls-framework) submodule and the [tf-psa-crypto](https://github.com/Mbed-TLS/TF-PSA-Crypto) submodule, except for the 3.6 LTS branch, which contains only the framework submodule. Release tags also use Git submodules.\n\nAfter cloning or checking out a branch or tag, run:\n    ```\n    git submodule update --init --recursive\n    ```\n to initialize and update the submodules before building.\n\nHowever, the official source release tarballs (e.g. [mbedtls-4.0.0.tar.bz2](https://github.com/Mbed-TLS/mbedtls/releases/download/mbedtls-4.0.0/mbedtls-4.0.0.tar.bz2)) include the contents of the submodules.\n\n### Generated source files in the development branch\n\nThe source code of Mbed TLS includes some files that are automatically generated by scripts and whose content depends only on the Mbed TLS source, not on the platform or on the library configuration. These files are not included in the development branch of Mbed TLS, but the generated files are included in official releases. This section explains how to generate the missing files in the development branch.\n\nThe following tools are required:\n\n* Perl, for some library source files.\n* Python 3 and some Python packages, for some library source files, sample programs and test data. To install the necessary packages, run:\n    ```\n    python3 -m pip install --user -r scripts/basic.requirements.txt\n    ```\n    Depending on your Python installation, you may need to invoke `python` instead of `python3`. To install the packages system-wide or in a virtual environment, omit the `--user` option.\n* A C compiler for the host platform, for some test data.\n\nThe scripts that generate the configuration-independent files will look for a host C compiler in the following places (in order of preference):\n\n1. The `HOSTCC` environment variable. This can be used if `CC` is pointing to a cross-compiler.\n2. The `CC` environment variable.\n3. An executable called `cc` in the current path.\n\nNote: If you have multiple toolchains installed, it is recommended to set `CC` or `HOSTCC` to the intended host compiler before generating the files.\n\nAny of the following methods are available to generate the configuration-independent files:\n\n* On non-Windows systems, when not cross-compiling, CMake generates the required files automatically.\n* Run `framework/scripts/make_generated_files.py` to generate all the configuration-independent files.\n\n### CMake\n\nIn order to build the libraries using CMake in a separate directory (recommended), just enter at the command line:\n\n    mkdir /path/to/build_dir && cd /path/to/build_dir\n    cmake /path/to/mbedtls_source\n    cmake --build .\n\nIn order to run the tests, enter:\n\n    ctest\n\nThe test suites need Python to be built. If you don't have Python installed, you'll want to disable the test suites with:\n\n    cmake -DENABLE_TESTING=Off /path/to/mbedtls_source\n\nTo configure CMake for building shared libraries, use:\n\n    cmake -DUSE_SHARED_MBEDTLS_LIBRARY=On /path/to/mbedtls_source\n\nThere are many different build types available with CMake. Most of them are available for gcc and clang, though some are compiler-specific:\n\n-   `Release`. This generates the default code without any unnecessary information in the binary files.\n-   `Debug`. This generates debug information and disables optimization of the code.\n-   `Coverage`. This generates code coverage information in addition to debug information.\n-   `ASan`. This instruments the code with AddressSanitizer to check for memory errors. (This includes LeakSanitizer, with recent version of gcc and clang.) (With recent version of clang, this mode also instruments the code with UndefinedSanitizer to check for undefined behaviour.)\n-   `ASanDbg`. Same as ASan but slower, with debug information and better stack traces.\n-   `MemSan`. This instruments the code with MemorySanitizer to check for uninitialised memory reads.\n-   `MemSanDbg`. Same as MemSan but slower, with debug information, better stack traces and origin tracking.\n-   `Check`. This activates the compiler warnings that depend on optimization and treats all warnings as errors.\n-   `TSan`. This instruments the code with ThreadSanitizer to detect data races and other threading-related concurrency issues at runtime.\n-   `TSanDbg`. Same as TSan but slower, with debug information, better stack traces and origin tracking.\n\nSwitching build types in CMake is simple. For debug mode, enter at the command line:\n\n    cmake -D CMAKE_BUILD_TYPE=Debug /path/to/mbedtls_source\n\nTo list other available CMake options, use:\n\n    cmake -LH\n\nNote that, with CMake, you can't adjust the compiler or its flags after the\ninitial invocation of cmake. This means that `CC=your_cc make` and `make\nCC=your_cc` will *not* work (similarly with `CFLAGS` and other variables).\nThese variables need to be adjusted when invoking cmake for the first time,\nfor example:\n\n    CC=your_cc cmake /path/to/mbedtls_source\n\nIf you already invoked cmake and want to change those settings, you need to\ninvoke the configuration phase of CMake again with the new settings.\n\nNote that it is possible to build in-place; this will however overwrite the\nlegacy Makefiles still used for testing purposes (see\n`scripts/tmp_ignore_makefiles.sh` if you want to prevent `git status` from\nshowing them as modified). In order to do so, from the Mbed TLS source\ndirectory, use:\n\n    cmake .\n    cmake --build .\n\nIf you want to change `CC` or `CFLAGS` afterwards, you will need to remove the\nCMake cache. This can be done with the following command using GNU find:\n\n    find . -iname '*cmake*' -not -name CMakeLists.txt -exec rm -rf {} +\n\nYou can now make the desired change:\n\n    CC=your_cc cmake .\n    cmake --build .\n\nRegarding variables, also note that if you set CFLAGS when invoking cmake,\nyour value of CFLAGS doesn't override the content provided by CMake (depending\non the build mode as seen above), it's merely prepended to it.\n\n#### Consuming Mbed TLS\n\nMbed TLS provides a CMake package configuration file for consumption as a\ndependency in other CMake projects. You can load its CMake targets with:\n\n    find_package(MbedTLS REQUIRED)\n\nYou can help CMake find the package:\n\n- By setting the variable `MbedTLS_DIR` to `${YOUR_MBEDTLS_BUILD_DIR}/cmake`,\n  as shown in `programs/test/cmake_package/CMakeLists.txt`, or\n- By adding the Mbed TLS installation prefix to `CMAKE_PREFIX_PATH`,\n  as shown in `programs/test/cmake_package_install/CMakeLists.txt`.\n\nAfter a successful `find_package(MbedTLS)`, the following imported targets are available:\n\n- `MbedTLS::tfpsacrypto`, the crypto library\n- `MbedTLS::mbedtls`, the TLS library\n- `MbedTLS::mbedx509`, the X.509 library\n\nYou can then use these directly through `target_link_libraries()`:\n\n    add_executable(xyz)\n\n    target_link_libraries(xyz\n        PUBLIC MbedTLS::mbedtls\n               MbedTLS::tfpsacrypto\n               MbedTLS::mbedx509)\n\nThis will link the Mbed TLS libraries to your library or application, and add\nits include directories to your target (transitively, in the case of `PUBLIC` or\n`INTERFACE` link libraries).\n\n#### Mbed TLS as a subproject\n\nMbed TLS supports being built as a CMake subproject. One can\nuse `add_subdirectory()` from a parent CMake project to include Mbed TLS as a\nsubproject.\n\nExample programs\n----------------\n\nWe've included example programs for a lot of different features and uses in [`programs/`](programs/README.md).\nPlease note that the goal of these sample programs is to demonstrate specific features of the library, and the code may need to be adapted to build a real-world application.\n\nTests\n-----\n\nMbed TLS includes an elaborate test suite in `tests/` that initially requires Python to generate the tests files (e.g. `test_suite_ssl.c`). These files are generated from a `function file` (e.g. `suites/test_suite_ssl.function`) and a `data file` (e.g. `suites/test_suite_ssl.data`). The `function file` contains the test functions. The `data file` contains the test cases, specified as parameters that will be passed to the test function.\n\nFor machines with a Unix shell and OpenSSL (and optionally GnuTLS) installed, additional test scripts are available:\n\n-   `tests/ssl-opt.sh` runs integration tests for various TLS options (renegotiation, resumption, etc.) and tests interoperability of these options with other implementations.\n-   `tests/compat.sh` tests interoperability of every ciphersuite with other implementations.\n-   `tests/scripts/depends.py` tests builds in configurations with a single curve, key exchange, hash, cipher, or pkalg on.\n-   `tests/scripts/all.sh` runs a combination of the above tests, plus some more, with various build options (such as ASan, full `mbedtls_config.h`, etc).\n\nInstead of manually installing the required versions of all tools required for testing, it is possible to use the Docker images from our CI systems, as explained in [our testing infrastructure repository](https://github.com/Mbed-TLS/mbedtls-test/blob/main/README.md#quick-start).\n\nPorting Mbed TLS\n----------------\n\nMbed TLS can be ported to many different architectures, OS's and platforms. Before starting a port, you may find the following Knowledge Base articles useful:\n\n-   [Porting Mbed TLS to a new environment or OS](https://mbed-tls.readthedocs.io/en/latest/kb/how-to/how-do-i-port-mbed-tls-to-a-new-environment-OS/)\n-   [What external dependencies does Mbed TLS rely on?](https://mbed-tls.readthedocs.io/en/latest/kb/development/what-external-dependencies-does-mbedtls-rely-on/)\n-   [How do I configure Mbed TLS](https://mbed-tls.readthedocs.io/en/latest/kb/compiling-and-building/how-do-i-configure-mbedtls/)\n\nMbed TLS is mostly written in portable C99; however, it has a few platform requirements that go beyond the standard, but are met by most modern architectures:\n\n- Bytes must be 8 bits.\n- All-bits-zero must be a valid representation of a null pointer.\n- Signed integers must be represented using two's complement.\n- `int` and `size_t` must be at least 32 bits wide.\n- The types `uint8_t`, `uint16_t`, `uint32_t` and their signed equivalents must be available.\n- Mixed-endian platforms are not supported.\n- SIZE_MAX must be at least as big as INT_MAX and UINT_MAX.\n\nLicense\n-------\n\nUnless specifically indicated otherwise in a file, Mbed TLS files are provided under a dual [Apache-2.0](https://spdx.org/licenses/Apache-2.0.html) OR [GPL-2.0-or-later](https://spdx.org/licenses/GPL-2.0-or-later.html) license. See the [LICENSE](LICENSE) file for the full text of these licenses, and [the 'License and Copyright' section in the contributing guidelines](CONTRIBUTING.md#License-and-Copyright) for more information.\n\nContributing\n------------\n\nWe gratefully accept bug reports and contributions from the community. Please see the [contributing guidelines](CONTRIBUTING.md) for details on how to do this.\n\nContact\n-------\n\n* To report a security vulnerability in Mbed TLS, please email <mbed-tls-security@lists.trustedfirmware.org>. For more information, see [`SECURITY.md`](SECURITY.md).\n* To report a bug or request a feature in Mbed TLS, please [file an issue on GitHub](https://github.com/Mbed-TLS/mbedtls/issues/new/choose).\n* Please see [`SUPPORT.md`](SUPPORT.md) for other channels for discussion and support about Mbed TLS.\n",
      "stars_today": 2
    },
    {
      "id": 39799721,
      "name": "r4ds",
      "full_name": "hadley/r4ds",
      "description": "R for data science: a book",
      "html_url": "https://github.com/hadley/r4ds",
      "stars": 4979,
      "forks": 4408,
      "language": "R",
      "topics": [
        "book",
        "bookdown",
        "data-science",
        "r"
      ],
      "created_at": "2015-07-27T21:52:44Z",
      "updated_at": "2026-01-23T16:59:54Z",
      "pushed_at": "2026-01-16T04:04:49Z",
      "open_issues": 21,
      "owner": {
        "login": "hadley",
        "avatar_url": "https://avatars.githubusercontent.com/u/4196?v=4"
      },
      "readme": "# R for Data Science\n\n<!-- badges: start -->\n\n[![Render and deploy Book to Netlify](https://github.com/hadley/r4ds/actions/workflows/build_book.yaml/badge.svg)](https://github.com/hadley/r4ds/actions/workflows/build_book.yaml)\n\n<!-- badges: end -->\n\nThis repository contains the source of [R for Data Science](http://r4ds.hadley.nz) book.\nThe book is built using [Quarto](https://quarto.org/).\n\n## Images\n\n### Omnigraffle drawings\n\n-   Font: 12pt Guardian Sans Condensed / Ubuntu mono\n\n-   Export as 300 dpi png.\n\n-   Website font is 18 px = 13.5 pt, so scale dpi to match font sizes: 270 = 300 \\* 12 / 13.5.\n    (I also verified this empirically by screenshotting.)\n\n    ``` r\n    #| echo: FALSE\n    #| out.width: NULL\n    knitr::include_graphics(\"diagrams/transform.png\", dpi = 270)\n    ```\n\n### Screenshots\n\n-   Make sure you're using a light theme.\n    For small interface elements (eg. toolbars), zoom in twice.\n\n-   Screenshot with Cmd + Shift + 4.\n\n-   Don't need to set dpi:\n\n    ``` r\n    #| echo: FALSE\n    #| out.width: NULL\n    knitr::include_graphics(\"screenshots/rstudio-wg.png\")\n    ```\n\n### O'Reilly\n\nTo generate book for O'Reilly, build the book then:\n\n```{r}\n# pak::pak(\"hadley/htmlbook\")\nhtmlbook::convert_book()\n\nhtml <- list.files(\"oreilly\", pattern = \"[.]html$\", full.names = TRUE)\nfile.copy(html, \"../r-for-data-science-2e/\", overwrite = TRUE)\n\npngs <- list.files(\"oreilly\", pattern = \"[.]png$\", full.names = TRUE, recursive = TRUE)\ndest <- gsub(\"oreilly\", \"../r-for-data-science-2e/\", pngs)\nfs::dir_create(unique(dirname(dest)))\nfile.copy(pngs, dest, overwrite = TRUE)\n```\n\nThen commit and push to atlas.\n\n## Code of Conduct\n\nPlease note that r4ds uses a [Contributor Code of Conduct](https://contributor-covenant.org/version/2/0/CODE_OF_CONDUCT.html).\nBy contributing to this book, you agree to abide by its terms.\n",
      "stars_today": 2
    },
    {
      "id": 1368195,
      "name": "asio",
      "full_name": "chriskohlhoff/asio",
      "description": "Asio C++ Library",
      "html_url": "https://github.com/chriskohlhoff/asio",
      "stars": 5721,
      "forks": 1341,
      "language": "C++",
      "topics": [],
      "created_at": "2011-02-15T05:18:45Z",
      "updated_at": "2026-01-23T21:07:09Z",
      "pushed_at": "2025-11-30T09:48:48Z",
      "open_issues": 1045,
      "owner": {
        "login": "chriskohlhoff",
        "avatar_url": "https://avatars.githubusercontent.com/u/462538?v=4"
      },
      "readme": "asio version 1.36.0\nReleased Saturday, 16 August 2025.\n\nVisit https://think-async.com/ or see packaged doc/index.html for API\ndocumentation and a tutorial.\n",
      "stars_today": 2
    },
    {
      "id": 83160811,
      "name": "littlefs",
      "full_name": "littlefs-project/littlefs",
      "description": "A little fail-safe filesystem designed for microcontrollers",
      "html_url": "https://github.com/littlefs-project/littlefs",
      "stars": 6381,
      "forks": 961,
      "language": "C",
      "topics": [
        "embedded",
        "filesystem",
        "microcontroller"
      ],
      "created_at": "2017-02-25T20:33:13Z",
      "updated_at": "2026-01-23T20:34:34Z",
      "pushed_at": "2026-01-09T06:51:19Z",
      "open_issues": 603,
      "owner": {
        "login": "littlefs-project",
        "avatar_url": "https://avatars.githubusercontent.com/u/60944974?v=4"
      },
      "readme": "## littlefs\n\nA little fail-safe filesystem designed for microcontrollers.\n\n```\n   | | |     .---._____\n  .-----.   |          |\n--|o    |---| littlefs |\n--|     |---|          |\n  '-----'   '----------'\n   | | |\n```\n\n**Power-loss resilience** - littlefs is designed to handle random power\nfailures. All file operations have strong copy-on-write guarantees and if\npower is lost the filesystem will fall back to the last known good state.\n\n**Dynamic wear leveling** - littlefs is designed with flash in mind, and\nprovides wear leveling over dynamic blocks. Additionally, littlefs can\ndetect bad blocks and work around them.\n\n**Bounded RAM/ROM** - littlefs is designed to work with a small amount of\nmemory. RAM usage is strictly bounded, which means RAM consumption does not\nchange as the filesystem grows. The filesystem contains no unbounded\nrecursion and dynamic memory is limited to configurable buffers that can be\nprovided statically.\n\n## Example\n\nHere's a simple example that updates a file named `boot_count` every time\nmain runs. The program can be interrupted at any time without losing track\nof how many times it has been booted and without corrupting the filesystem:\n\n``` c\n#include \"lfs.h\"\n\n// variables used by the filesystem\nlfs_t lfs;\nlfs_file_t file;\n\n// configuration of the filesystem is provided by this struct\nconst struct lfs_config cfg = {\n    // block device operations\n    .read  = user_provided_block_device_read,\n    .prog  = user_provided_block_device_prog,\n    .erase = user_provided_block_device_erase,\n    .sync  = user_provided_block_device_sync,\n\n    // block device configuration\n    .read_size = 16,\n    .prog_size = 16,\n    .block_size = 4096,\n    .block_count = 128,\n    .cache_size = 16,\n    .lookahead_size = 16,\n    .block_cycles = 500,\n};\n\n// entry point\nint main(void) {\n    // mount the filesystem\n    int err = lfs_mount(&lfs, &cfg);\n\n    // reformat if we can't mount the filesystem\n    // this should only happen on the first boot\n    if (err) {\n        lfs_format(&lfs, &cfg);\n        lfs_mount(&lfs, &cfg);\n    }\n\n    // read current count\n    uint32_t boot_count = 0;\n    lfs_file_open(&lfs, &file, \"boot_count\", LFS_O_RDWR | LFS_O_CREAT);\n    lfs_file_read(&lfs, &file, &boot_count, sizeof(boot_count));\n\n    // update boot count\n    boot_count += 1;\n    lfs_file_rewind(&lfs, &file);\n    lfs_file_write(&lfs, &file, &boot_count, sizeof(boot_count));\n\n    // remember the storage is not updated until the file is closed successfully\n    lfs_file_close(&lfs, &file);\n\n    // release any resources we were using\n    lfs_unmount(&lfs);\n\n    // print the boot count\n    printf(\"boot_count: %d\\n\", boot_count);\n}\n```\n\n## Usage\n\nDetailed documentation (or at least as much detail as is currently available)\ncan be found in the comments in [lfs.h](lfs.h).\n\nlittlefs takes in a configuration structure that defines how the filesystem\noperates. The configuration struct provides the filesystem with the block\ndevice operations and dimensions, tweakable parameters that tradeoff memory\nusage for performance, and optional static buffers if the user wants to avoid\ndynamic memory.\n\nThe state of the littlefs is stored in the `lfs_t` type which is left up\nto the user to allocate, allowing multiple filesystems to be in use\nsimultaneously. With the `lfs_t` and configuration struct, a user can\nformat a block device or mount the filesystem.\n\nOnce mounted, the littlefs provides a full set of POSIX-like file and\ndirectory functions, with the deviation that the allocation of filesystem\nstructures must be provided by the user.\n\nAll POSIX operations, such as remove and rename, are atomic, even in event\nof power-loss. Additionally, file updates are not actually committed to\nthe filesystem until sync or close is called on the file.\n\n## Other notes\n\nLittlefs is written in C, and specifically should compile with any compiler\nthat conforms to the `C99` standard.\n\nAll littlefs calls have the potential to return a negative error code. The\nerrors can be either one of those found in the `enum lfs_error` in\n[lfs.h](lfs.h), or an error returned by the user's block device operations.\n\nIn the configuration struct, the `prog` and `erase` function provided by the\nuser may return a `LFS_ERR_CORRUPT` error if the implementation already can\ndetect corrupt blocks. However, the wear leveling does not depend on the return\ncode of these functions, instead all data is read back and checked for\nintegrity.\n\nIf your storage caches writes, make sure that the provided `sync` function\nflushes all the data to memory and ensures that the next read fetches the data\nfrom memory, otherwise data integrity can not be guaranteed. If the `write`\nfunction does not perform caching, and therefore each `read` or `write` call\nhits the memory, the `sync` function can simply return 0.\n\n## Design\n\nAt a high level, littlefs is a block based filesystem that uses small logs to\nstore metadata and larger copy-on-write (COW) structures to store file data.\n\nIn littlefs, these ingredients form a sort of two-layered cake, with the small\nlogs (called metadata pairs) providing fast updates to metadata anywhere on\nstorage, while the COW structures store file data compactly and without any\nwear amplification cost.\n\nBoth of these data structures are built out of blocks, which are fed by a\ncommon block allocator. By limiting the number of erases allowed on a block\nper allocation, the allocator provides dynamic wear leveling over the entire\nfilesystem.\n\n```\n                    root\n                   .--------.--------.\n                   | A'| B'|         |\n                   |   |   |->       |\n                   |   |   |         |\n                   '--------'--------'\n                .----'   '--------------.\n       A       v                 B       v\n      .--------.--------.       .--------.--------.\n      | C'| D'|         |       | E'|new|         |\n      |   |   |->       |       |   | E'|->       |\n      |   |   |         |       |   |   |         |\n      '--------'--------'       '--------'--------'\n      .-'   '--.                  |   '------------------.\n     v          v              .-'                        v\n.--------.  .--------.        v                       .--------.\n|   C    |  |   D    |   .--------.       write       | new E  |\n|        |  |        |   |   E    |        ==>        |        |\n|        |  |        |   |        |                   |        |\n'--------'  '--------'   |        |                   '--------'\n                         '--------'                   .-'    |\n                         .-'    '-.    .-------------|------'\n                        v          v  v              v\n                   .--------.  .--------.       .--------.\n                   |   F    |  |   G    |       | new F  |\n                   |        |  |        |       |        |\n                   |        |  |        |       |        |\n                   '--------'  '--------'       '--------'\n```\n\nMore details on how littlefs works can be found in [DESIGN.md](DESIGN.md) and\n[SPEC.md](SPEC.md).\n\n- [DESIGN.md](DESIGN.md) - A fully detailed dive into how littlefs works.\n  I would suggest reading it as the tradeoffs at work are quite interesting.\n\n- [SPEC.md](SPEC.md) - The on-disk specification of littlefs with all the\n  nitty-gritty details. May be useful for tooling development.\n\n## Testing\n\nThe littlefs comes with a test suite designed to run on a PC using the\n[emulated block device](bd/lfs_testbd.h) found in the `bd` directory.\nThe tests assume a Linux environment and can be started with make:\n\n``` bash\nmake test\n```\n\nTests are implemented in C in the .toml files found in the `tests` directory.\nWhen developing a feature or fixing a bug, it is frequently useful to run a\nsingle test case or suite of tests:\n\n``` bash\n./scripts/test.py -l runners/test_runner  # list available test suites\n./scripts/test.py -L runners/test_runner test_dirs  # list available test cases\n./scripts/test.py runners/test_runner test_dirs  # run a specific test suite\n```\n\nIf an assert fails in a test, test.py will try to print information about the\nfailure:\n\n``` bash\ntests/test_dirs.toml:1:failure: test_dirs_root:1g12gg2 (PROG_SIZE=16, ERASE_SIZE=512) failed\ntests/test_dirs.toml:5:assert: assert failed with 0, expected eq 42\n    lfs_mount(&lfs, cfg) => 42;\n```\n\nThis includes the test id, which can be passed to test.py to run only that\nspecific test permutation:\n\n``` bash\n./scripts/test.py runners/test_runner test_dirs_root:1g12gg2  # run a specific test permutation\n./scripts/test.py runners/test_runner test_dirs_root:1g12gg2 --gdb  # drop into gdb on failure\n```\n\nSome other flags that may be useful:\n\n```bash\n./scripts/test.py runners/test_runner -b -j  # run tests in parallel\n./scripts/test.py runners/test_runner -v -O-  # redirect stdout to stdout\n./scripts/test.py runners/test_runner -ddisk  # capture resulting disk image\n```\n\nSee `-h/--help` for a full list of available flags:\n\n``` bash\n./scripts/test.py --help\n```\n\n## License\n\nThe littlefs is provided under the [BSD-3-Clause] license. See\n[LICENSE.md](LICENSE.md) for more information. Contributions to this project\nare accepted under the same license.\n\nIndividual files contain the following tag instead of the full license text.\n\n    SPDX-License-Identifier:    BSD-3-Clause\n\nThis enables machine processing of license information based on the SPDX\nLicense Identifiers that are here available: http://spdx.org/licenses/\n\n## Related projects\n\n- [littlefs-fuse] - A [FUSE] wrapper for littlefs. The project allows you to\n  mount littlefs directly on a Linux machine. Can be useful for debugging\n  littlefs if you have an SD card handy.\n\n- [littlefs-js] - A javascript wrapper for littlefs. I'm not sure why you would\n  want this, but it is handy for demos.  You can see it in action\n  [here][littlefs-js-demo].\n  \n- [littlefs-python] - A Python wrapper for littlefs. The project allows you\n  to create images of the filesystem on your PC. Check if littlefs will fit\n  your needs, create images for a later download to the target memory or\n  inspect the content of a binary image of the target memory.\n\n- [littlefs-toy] - A command-line tool for creating and working with littlefs\n  images. Uses syntax similar to tar command for ease of use. Supports working\n  on littlefs images embedded inside another file (firmware image, etc).\n\n- [littlefs2-rust] - A Rust wrapper for littlefs. This project allows you\n  to use littlefs in a Rust-friendly API, reaping the benefits of Rust's memory\n  safety and other guarantees.\n\n- [nim-littlefs] - A Nim wrapper and API for littlefs. Includes a fuse\n  implementation based on [littlefs-fuse]\n\n- [chamelon] - A pure-OCaml implementation of (most of) littlefs, designed for\n  use with the MirageOS library operating system project. It is interoperable\n  with the reference implementation, with some caveats.\n\n- [littlefs-disk-img-viewer] - A memory-efficient web application for viewing\n  littlefs disk images in your web browser.\n\n- [mklfs] - A command line tool for creating littlefs images. Used in the Lua\n  RTOS ecosystem.\n\n- [mklittlefs] - A command line tool for creating littlefs images. Used in the\n  ESP8266 and RP2040 ecosystem.\n\n- [pico-littlefs-usb] - An interface for littlefs that emulates a FAT12\n  filesystem over USB. Allows mounting littlefs on a host PC without additional\n  drivers.\n\n- [ramcrc32bd] - An example block device using littlefs's 32-bit CRC for\n  error-correction.\n\n- [ramrsbd] - An example block device using Reed-Solomon codes for\n  error-correction.\n\n- [Mbed OS] - The easiest way to get started with littlefs is to jump into Mbed\n  which already has block device drivers for most forms of embedded storage.\n  littlefs is available in Mbed OS as the [LittleFileSystem] class.\n\n- [SPIFFS] - Another excellent embedded filesystem for NOR flash. As a more\n  traditional logging filesystem with full static wear-leveling, SPIFFS will\n  likely outperform littlefs on small memories such as the internal flash on\n  microcontrollers.\n\n- [Dhara] - An interesting NAND flash translation layer designed for small\n  MCUs. It offers static wear-leveling and power-resilience with only a fixed\n  _O(|address|)_ pointer structure stored on each block and in RAM.\n\n- [ChaN's FatFs] - A lightweight reimplementation of the infamous FAT filesystem\n  for microcontroller-scale devices. Due to limitations of FAT it can't provide\n  power-loss resilience, but it does allow easy interop with PCs.\n\n[BSD-3-Clause]: https://spdx.org/licenses/BSD-3-Clause.html\n[littlefs-fuse]: https://github.com/geky/littlefs-fuse\n[FUSE]: https://github.com/libfuse/libfuse\n[littlefs-js]: https://github.com/geky/littlefs-js\n[littlefs-js-demo]:http://littlefs.geky.net/demo.html\n[littlefs-python]: https://pypi.org/project/littlefs-python/\n[littlefs-toy]: https://github.com/tjko/littlefs-toy\n[littlefs2-rust]: https://crates.io/crates/littlefs2\n[nim-littlefs]: https://github.com/Graveflo/nim-littlefs\n[chamelon]: https://github.com/yomimono/chamelon\n[littlefs-disk-img-viewer]: https://github.com/tniessen/littlefs-disk-img-viewer\n[mklfs]: https://github.com/whitecatboard/Lua-RTOS-ESP32/tree/master/components/mklfs/src\n[mklittlefs]: https://github.com/earlephilhower/mklittlefs\n[pico-littlefs-usb]: https://github.com/oyama/pico-littlefs-usb\n[ramcrc32bd]: https://github.com/geky/ramcrc32bd\n[ramrsbd]: https://github.com/geky/ramrsbd\n[Mbed OS]: https://github.com/armmbed/mbed-os\n[LittleFileSystem]: https://os.mbed.com/docs/mbed-os/latest/apis/littlefilesystem.html\n[SPIFFS]: https://github.com/pellepl/spiffs\n[Dhara]: https://github.com/dlbeer/dhara\n[ChaN's FatFs]: http://elm-chan.org/fsw/ff/00index_e.html\n",
      "stars_today": 2
    },
    {
      "id": 198232685,
      "name": "open_spiel",
      "full_name": "google-deepmind/open_spiel",
      "description": "OpenSpiel is a collection of environments and algorithms for research in general reinforcement learning and search/planning in games.",
      "html_url": "https://github.com/google-deepmind/open_spiel",
      "stars": 4997,
      "forks": 1080,
      "language": "C++",
      "topics": [
        "cpp",
        "games",
        "multiagent",
        "python",
        "reinforcement-learning"
      ],
      "created_at": "2019-07-22T13:50:21Z",
      "updated_at": "2026-01-24T02:05:07Z",
      "pushed_at": "2026-01-22T16:53:14Z",
      "open_issues": 26,
      "owner": {
        "login": "google-deepmind",
        "avatar_url": "https://avatars.githubusercontent.com/u/8596759?v=4"
      },
      "readme": "\n<!-- disableFinding(IMAGE_ALT_TEXT_INACCESSIBLE) -->\n<!-- disableFinding(HEADING_REPEAT_H1) -->\n<!-- disableFinding(SNIPPET_INVALID_LANGUAGE) -->\n<!-- disableFinding(\"github\") -->\n<!-- disableFinding(LINK_CL_HEAD) -->\n\n# OpenSpiel: A Framework for Reinforcement Learning in Games\n\n[![Documentation Status](https://readthedocs.org/projects/openspiel/badge/?version=latest)](https://openspiel.readthedocs.io/en/latest/?badge=latest)\n![build_and_test](https://github.com/deepmind/open_spiel/workflows/build_and_test/badge.svg)\n\nOpenSpiel is a collection of environments and algorithms for research in general\nreinforcement learning and search/planning in games. OpenSpiel supports n-player\n(single- and multi- agent) zero-sum, cooperative and general-sum, one-shot and\nsequential, strictly turn-taking and simultaneous-move, perfect and imperfect\ninformation games, as well as traditional multiagent environments such as\n(partially- and fully- observable) grid worlds and social dilemmas. OpenSpiel\nalso includes tools to analyze learning dynamics and other common evaluation\nmetrics. Games are represented as procedural extensive-form games, with some\nnatural extensions. The core API and games are implemented in C++ and exposed to\nPython. Algorithms and tools are written both in C++ and Python.\n\nTo try OpenSpiel in Google Colaboratory, please refer to `open_spiel/colabs` subdirectory or start [here](https://colab.research.google.com/github/deepmind/open_spiel/blob/master/open_spiel/colabs/install_open_spiel.ipynb).\n\n<p align=\"center\">\n  <img src=\"docs/_static/OpenSpielB.png\" alt=\"OpenSpiel visual asset\">\n</p>\n\n# Index\n\nPlease choose among the following options:\n\n*   [Installing OpenSpiel](docs/install.md)\n*   [Introduction to OpenSpiel](docs/intro.md)\n*   [API Overview and First Example](docs/concepts.md)\n*   [API Reference](docs/api_reference.md)\n*   [Overview of Implemented Games](docs/games.md)\n*   [Overview of Implemented Algorithms](docs/algorithms.md)\n*   [Developer Guide](docs/developer_guide.md)\n*   [Using OpenSpiel as a C++ Library](docs/library.md)\n*   [Guidelines and Contributing](docs/contributing.md)\n*   [Authors](docs/authors.md)\n\nFor a longer introduction to the core concepts, formalisms, and terminology,\nincluding an overview of the algorithms and some results, please see\n[OpenSpiel: A Framework for Reinforcement Learning in Games](https://arxiv.org/abs/1908.09453).\n\nFor an overview of OpenSpiel and example uses of the core API, please check out\nour tutorials:\n\n*   [Motivation, Core API, Brief Intro to Replictor Dynamics and Imperfect\n    Information Games](https://www.youtube.com/watch?v=8NCPqtPwlFQ) by Marc\n    Lanctot.\n    [(slides)](http://mlanctot.info/files/OpenSpiel_Tutorial_KU_Leuven_2022.pdf)\n    [(colab)](https://colab.research.google.com/github/deepmind/open_spiel/blob/master/open_spiel/colabs/OpenSpielTutorial.ipynb)\n*   [Motivation, Core API, Implementing CFR and REINFORCE on Kuhn poker, Leduc\n    poker, and Goofspiel](https://www.youtube.com/watch?v=o6JNHoGUXCo) by Edward\n    Lockhart.\n    [(slides)](http://mlanctot.info/files/open_spiel_tutorial-mar2021-comarl.pdf)\n    [(colab)](https://colab.research.google.com/github/deepmind/open_spiel/blob/master/open_spiel/colabs/CFR_and_REINFORCE.ipynb)\n\nIf you use OpenSpiel in your research, please cite the paper using the following\nBibTeX:\n\n```bibtex\n@article{LanctotEtAl2019OpenSpiel,\n  title     = {{OpenSpiel}: A Framework for Reinforcement Learning in Games},\n  author    = {Marc Lanctot and Edward Lockhart and Jean-Baptiste Lespiau and\n               Vinicius Zambaldi and Satyaki Upadhyay and Julien P\\'{e}rolat and\n               Sriram Srinivasan and Finbarr Timbers and Karl Tuyls and\n               Shayegan Omidshafiei and Daniel Hennes and Dustin Morrill and\n               Paul Muller and Timo Ewalds and Ryan Faulkner and J\\'{a}nos Kram\\'{a}r\n               and Bart De Vylder and Brennan Saeta and James Bradbury and David Ding\n               and Sebastian Borgeaud and Matthew Lai and Julian Schrittwieser and\n               Thomas Anthony and Edward Hughes and Ivo Danihelka and Jonah Ryan-Davis},\n  year      = {2019},\n  eprint    = {1908.09453},\n  archivePrefix = {arXiv},\n  primaryClass = {cs.LG},\n  journal   = {CoRR},\n  volume    = {abs/1908.09453},\n  url       = {http://arxiv.org/abs/1908.09453},\n}\n```\n\n## Versioning\n\nWe use [Semantic Versioning](https://semver.org/).\n\n",
      "stars_today": 2
    },
    {
      "id": 39042157,
      "name": "spdk",
      "full_name": "spdk/spdk",
      "description": "Storage Performance Development Kit",
      "html_url": "https://github.com/spdk/spdk",
      "stars": 3469,
      "forks": 1311,
      "language": "C",
      "topics": [],
      "created_at": "2015-07-13T23:15:15Z",
      "updated_at": "2026-01-23T19:51:25Z",
      "pushed_at": "2026-01-23T19:51:19Z",
      "open_issues": 223,
      "owner": {
        "login": "spdk",
        "avatar_url": "https://avatars.githubusercontent.com/u/13323228?v=4"
      },
      "readme": "# Storage Performance Development Kit\n\n[![Go Doc](https://img.shields.io/badge/godoc-reference-blue.svg)](http://godoc.org/github.com/spdk/spdk/go/rpc)\n[![Go Report Card](https://goreportcard.com/badge/github.com/spdk/spdk/go/rpc)](https://goreportcard.com/report/github.com/spdk/spdk/go/rpc)\n[![PyPI Latest Release](https://img.shields.io/pypi/v/spdk.svg)](https://pypi.org/project/spdk/)\n[![PyPI Downloads](https://img.shields.io/pypi/dm/spdk.svg?label=PyPI%20downloads)](https://pypi.org/project/spdk/)\n\nNOTE: The SPDK mailing list has moved to a new location. Please visit\n[this URL](https://lists.linuxfoundation.org/mailman/listinfo/spdk) to subscribe\nat the new location. Subscribers from the old location will not be automatically\nmigrated to the new location.\n\nThe Storage Performance Development Kit ([SPDK](http://www.spdk.io)) provides a set of tools\nand libraries for writing high performance, scalable, user-mode storage\napplications. It achieves high performance by moving all of the necessary\ndrivers into userspace and operating in a polled mode instead of relying on\ninterrupts, which avoids kernel context switches and eliminates interrupt\nhandling overhead.\n\nThe development kit currently includes:\n\n* [NVMe driver](http://www.spdk.io/doc/nvme.html)\n* [I/OAT (DMA engine) driver](http://www.spdk.io/doc/ioat.html)\n* [NVMe over Fabrics target](http://www.spdk.io/doc/nvmf.html)\n* [iSCSI target](http://www.spdk.io/doc/iscsi.html)\n* [vhost target](http://www.spdk.io/doc/vhost.html)\n* [Virtio-SCSI driver](http://www.spdk.io/doc/virtio.html)\n\n## In this readme\n\n* [Documentation](#documentation)\n* [Prerequisites](#prerequisites)\n* [Source Code](#source)\n* [Build](#libraries)\n* [Unit Tests](#tests)\n* [Vagrant](#vagrant)\n* [AWS](#aws)\n* [Advanced Build Options](#advanced)\n* [Shared libraries](#shared)\n* [Hugepages and Device Binding](#huge)\n* [Example Code](#examples)\n* [Contributing](#contributing)\n\n<a id=\"documentation\"></a>\n## Documentation\n\n[Doxygen API documentation](http://www.spdk.io/doc/) is available, as\nwell as a [Porting Guide](http://www.spdk.io/doc/porting.html) for porting SPDK to different frameworks\nand operating systems.\n\n<a id=\"source\"></a>\n## Source Code\n\n~~~{.sh}\ngit clone https://github.com/spdk/spdk\ncd spdk\ngit submodule update --init\n~~~\n\n<a id=\"prerequisites\"></a>\n## Prerequisites\n\nThe dependencies can be installed automatically by `scripts/pkgdep.sh`.\nThe `scripts/pkgdep.sh` script will automatically install the bare minimum\ndependencies required to build SPDK.\nUse `--help` to see information on installing dependencies for optional components\n\n~~~{.sh}\n./scripts/pkgdep.sh\n~~~\n\n<a id=\"libraries\"></a>\n## Build\n\nLinux:\n\n~~~{.sh}\n./configure\nmake\n~~~\n\nFreeBSD:\nNote: Make sure you have the matching kernel source in /usr/src/ and\nalso note that CONFIG_COVERAGE option is not available right now\nfor FreeBSD builds.\n\n~~~{.sh}\n./configure\ngmake\n~~~\n\n<a id=\"tests\"></a>\n## Unit Tests\n\n~~~{.sh}\n./test/unit/unittest.sh\n~~~\n\nYou will see several error messages when running the unit tests, but they are\npart of the test suite. The final message at the end of the script indicates\nsuccess or failure.\n\n<a id=\"vagrant\"></a>\n## Vagrant\n\nA [Vagrant](https://www.vagrantup.com/downloads.html) setup is also provided\nto create a Linux VM with a virtual NVMe controller to get up and running\nquickly.  Currently this has been tested on MacOS, Ubuntu 16.04.2 LTS and\nUbuntu 18.04.3 LTS with the VirtualBox and Libvirt provider.\nThe [VirtualBox Extension Pack](https://www.virtualbox.org/wiki/Downloads)\nor [Vagrant Libvirt] (https://github.com/vagrant-libvirt/vagrant-libvirt) must\nalso be installed in order to get the required NVMe support.\n\nDetails on the Vagrant setup can be found in the\n[SPDK Vagrant documentation](http://spdk.io/doc/vagrant.html).\n\n<a id=\"aws\"></a>\n## AWS\n\nThe following setup is known to work on AWS:\nImage: Ubuntu 18.04\nBefore running  `setup.sh`, run `modprobe vfio-pci`\nthen: `DRIVER_OVERRIDE=vfio-pci ./setup.sh`\n\n<a id=\"advanced\"></a>\n## Advanced Build Options\n\nOptional components and other build-time configuration are controlled by\nsettings in the Makefile configuration file in the root of the repository. `CONFIG`\ncontains the base settings for the `configure` script. This script generates a new\nfile, `mk/config.mk`, that contains final build settings. For advanced configuration,\nthere are a number of additional options to `configure` that may be used, or\n`mk/config.mk` can simply be created and edited by hand. A description of all\npossible options is located in `CONFIG`.\n\nBoolean (on/off) options are configured with a 'y' (yes) or 'n' (no). For\nexample, this line of `CONFIG` controls whether the optional RDMA (libibverbs)\nsupport is enabled:\n\n~~~{.sh}\nCONFIG_RDMA?=n\n~~~\n\nTo enable RDMA, this line may be added to `mk/config.mk` with a 'y' instead of\n'n'. For the majority of options this can be done using the `configure` script.\nFor example:\n\n~~~{.sh}\n./configure --with-rdma\n~~~\n\nAdditionally, `CONFIG` options may also be overridden on the `make` command\nline:\n\n~~~{.sh}\nmake CONFIG_RDMA=y\n~~~\n\nUsers may wish to use a version of DPDK different from the submodule included\nin the SPDK repository.  Note, this includes the ability to build not only\nfrom DPDK sources, but also just with the includes and libraries\ninstalled via the dpdk and dpdk-devel packages.  To specify an alternate DPDK\ninstallation, run configure with the --with-dpdk option.  For example:\n\nLinux:\n\n~~~{.sh}\n./configure --with-dpdk=/path/to/dpdk/x86_64-native-linuxapp-gcc\nmake\n~~~\n\nFreeBSD:\n\n~~~{.sh}\n./configure --with-dpdk=/path/to/dpdk/x86_64-native-bsdapp-clang\ngmake\n~~~\n\nThe options specified on the `make` command line take precedence over the\nvalues in `mk/config.mk`. This can be useful if you, for example, generate\na `mk/config.mk` using the `configure` script and then have one or two\noptions (i.e. debug builds) that you wish to turn on and off frequently.\n\n<a id=\"shared\"></a>\n## Shared libraries\n\nBy default, the build of the SPDK yields static libraries against which\nthe SPDK applications and examples are linked.\nConfigure option `--with-shared` provides the ability to produce SPDK shared\nlibraries, in addition to the default static ones.  Use of this flag also\nresults in the SPDK executables linked to the shared versions of libraries.\nSPDK shared libraries by default, are located in `./build/lib`.  This includes\nthe single SPDK shared lib encompassing all of the SPDK static libs\n(`libspdk.so`) as well as individual SPDK shared libs corresponding to each\nof the SPDK static ones.\n\nIn order to start a SPDK app linked with SPDK shared libraries, make sure\nto do the following steps:\n\n- run ldconfig specifying the directory containing SPDK shared libraries\n- provide proper `LD_LIBRARY_PATH`\n\nIf DPDK shared libraries are used, you may also need to add DPDK shared\nlibraries to `LD_LIBRARY_PATH`\n\nLinux:\n\n~~~{.sh}\n./configure --with-shared\nmake\nldconfig -v -n ./build/lib\nLD_LIBRARY_PATH=./build/lib/:./dpdk/build/lib/ ./build/bin/spdk_tgt\n~~~\n\n<a id=\"huge\"></a>\n## Hugepages and Device Binding\n\nBefore running an SPDK application, some hugepages must be allocated and\nany NVMe and I/OAT devices must be unbound from the native kernel drivers.\nSPDK includes a script to automate this process on both Linux and FreeBSD.\nThis script should be run as root.\n\n~~~{.sh}\nsudo scripts/setup.sh\n~~~\n\nUsers may wish to configure a specific memory size. Below is an example of\nconfiguring 8192MB memory.\n\n~~~{.sh}\nsudo HUGEMEM=8192 scripts/setup.sh\n~~~\n\nThere are a lot of other environment variables that can be set to configure\nsetup.sh for advanced users. To see the full list, run:\n\n~~~{.sh}\nscripts/setup.sh --help\n~~~\n\n<a id=\"targets\"></a>\n## Target applications\n\nAfter completing the build process, SPDK target applications can be found in\n`spdk/build/bin` directory:\n\n* [nvmf_tgt](https://spdk.io/doc/nvmf.html) - SPDK NVMe over Fabrics target\n  presents block devices over a fabrics,\n* [iscsi_tgt](https://spdk.io/doc/iscsi.html) - SPDK iSCSI target runs I/O\n  operations remotely with TCP/IP protocol,\n* [vhost](https://spdk.io/doc/vhost.html) - A vhost target provides a local\n  storage service as a process running on a local machine,\n* spdk_tgt - combines capabilities of all three applications.\n\nSPDK runs in a polled mode, which means it continuously checks for operation completions.\nThis approach assures faster response than interrupt mode, but also lessens usefulness\nof tools like `top`, which only shows 100% CPU usage for SPDK assigned cores.\n[spdk_top](https://spdk.io/doc/spdk_top.html) is a program which simulates `top` application\nand uses SPDK's [JSON RPC](https://spdk.io/doc/jsonrpc.html) interface to present statistics\nabout SPDK threads, pollers and CPU cores as an interactive list.\n\n<a id=\"examples\"></a>\n## Example Code\n\nExample code is located in the examples directory. The examples are compiled\nautomatically as part of the build process. Simply call any of the examples\nwith no arguments to see the help output. You'll likely need to run the examples\nas a privileged user (root) unless you've done additional configuration\nto grant your user permission to allocate huge pages and map devices through\nvfio.\n\n<a id=\"python\"></a>\n## Python bindings\n\nSPDK python bindings and scripts are located in [python](./python) folder. Python code is\nautomatically built as part of the build process. Python package is also published\nto <https://pypi.org/project/spdk/> every release for ease of consumption. For more\ndetails, check the [README](./python/README.md).\n\n<a id=\"contributing\"></a>\n## Contributing\n\nFor additional details on how to get more involved in the community, including\n[contributing code](http://www.spdk.io/development) and participating in discussions and other activities, please\nrefer to [spdk.io](http://www.spdk.io/community)\n",
      "stars_today": 2
    },
    {
      "id": 33784533,
      "name": "asterisk",
      "full_name": "asterisk/asterisk",
      "description": "The official Asterisk Project repository.",
      "html_url": "https://github.com/asterisk/asterisk",
      "stars": 3018,
      "forks": 1178,
      "language": "C",
      "topics": [
        "asterisk",
        "c",
        "pbx",
        "sip",
        "voip"
      ],
      "created_at": "2015-04-11T17:07:55Z",
      "updated_at": "2026-01-23T16:30:44Z",
      "pushed_at": "2026-01-23T15:25:44Z",
      "open_issues": 188,
      "owner": {
        "login": "asterisk",
        "avatar_url": "https://avatars.githubusercontent.com/u/2914369?v=4"
      },
      "readme": "# The Asterisk(R) Open Source PBX\n\n```\nBy Mark Spencer <markster@digium.com> and the Asterisk.org developer community.\nCopyright (C) 2001-2025 Sangoma Technologies Corporation and other copyright holders.\n```\n\n## SECURITY\n\nIt is imperative that you read and fully understand the contents of\nthe security information document before you attempt to configure and run\nan Asterisk server.\n\nSee [Important Security Considerations](https://docs.asterisk.org/Deployment/Important-Security-Considerations) for more information.\n\n## WHAT IS ASTERISK ?\n\nAsterisk is an Open Source PBX and telephony toolkit.  It is, in a\nsense, middleware between Internet and telephony channels on the bottom,\nand Internet and telephony applications at the top.  However, Asterisk supports\nmore telephony interfaces than just Internet telephony.  Asterisk also has a\nvast amount of support for traditional PSTN telephony, as well.\n\nFor more information on the project itself, please visit the [Asterisk\nHome Page](https://www.asterisk.org) and the official\n[Asterisk Documentation](https://docs.asterisk.org).\n\n## SUPPORTED OPERATING SYSTEMS\n\n### Linux\n\nThe Asterisk Open Source PBX is developed and tested primarily on the\nGNU/Linux operating system, and is supported on every major GNU/Linux\ndistribution.\n\n### Others\n\nAsterisk has also been 'ported' and reportedly runs properly on other\noperating systems as well, Apple's Mac OS X, and the BSD variants.\n\n## GETTING STARTED\n\nMost users are using VoIP/SIP exclusively these days but if you need to\ninterface to TDM or analog services or devices, be sure you've got supported\nhardware.\n\nSupported telephony hardware includes:\n* All Analog and Digital Interface cards from Sangoma\n* Any full duplex sound card supported by PortAudio\n* The Xorcom Astribank channel bank\n\n### UPGRADING FROM AN EARLIER VERSION\n\nIf you are updating from a previous version of Asterisk, make sure you\nread the Change Logs.\n\n<!-- CHANGELOGS (the URL will change based on the location of this README) -->\n[Change Logs](https://downloads.asterisk.org/pub/telephony/asterisk)\n<!-- END-CHANGELOGS -->\n\n### NEW INSTALLATIONS\n\nEnsure that your system contains a compatible compiler and development\nlibraries.  Asterisk requires either the GNU Compiler Collection (GCC) version\n4.1 or higher, or a compiler that supports the C99 specification and some of\nthe gcc language extensions.  In addition, your system needs to have the C\nlibrary headers available, and the headers and libraries for ncurses.\n\nThere are many modules that have additional dependencies.  To see what\nlibraries are being looked for, see `./configure --help`, or run\n`make menuselect` to view the dependencies for specific modules.\n\nOn many distributions, these dependencies are installed by packages with names\nlike 'glibc-devel', 'ncurses-devel', 'openssl-devel' and 'zlib-devel'\nor similar.  The `contrib/scripts/install_prereq` script can be used to install\nthe dependencies for most Debian and Redhat based Linux distributions.\nThe script also handles SUSE, Arch, Gentoo, FreeBSD, NetBSD and OpenBSD but\nthose distributions mightnoit have complete support or they might be out of date.\n\nSo, let's proceed:\n\n1. Read the documentation.<br>\nThe [Asterisk Documentation](https://docs.asterisk.org) website has full\ninformation for building, installing, configuring and running Asterisk.\n\n2. Run `./configure`<br>\nExecute the configure script to guess values for system-dependent\nvariables used during compilation. If the script indicates that some required\ncomponents are missing, you can run `./contrib/scripts/install_prereq install`\nto install the necessary components. Note that this will install all dependencies\nfor every functionality of Asterisk. After running the script, you will need\nto rerun `./configure`.\n\n3. Run `make menuselect`<br>\nThis is needed if you want to select the modules that will be compiled and to\ncheck dependencies for various optional modules.\n\n4. Run `make`<br>\nAssuming the build completes successfully:\n\n5. Run `make install`<br>\nIf this is your first time working with Asterisk, you may wish to install\nthe sample PBX, with demonstration extensions, etc.  If so, run:\n\n6. Run `make samples`<br>\nDoing so will overwrite any existing configuration files you have installed.\n\n7. Finally, you can launch Asterisk in the foreground mode (not a daemon) with\n`asterisk -vvvc`<br>\nYou'll see a bunch of verbose messages fly by your screen as Asterisk\ninitializes (that's the \"very very verbose\" mode).  When it's ready, if\nyou specified the \"c\" then you'll get a command line console, that looks\nlike this:<br>\n`*CLI>`<br>\nYou can type `core show help` at any time to get help with the system.  For help\nwith a specific command, type `core show help <command>`.\n\n`man asterisk` at the Unix/Linux command prompt will give you detailed\ninformation on how to start and stop Asterisk, as well as all the command\nline options for starting Asterisk.\n\n### ABOUT CONFIGURATION FILES\n\nAll Asterisk configuration files share a common format.  Comments are\ndelimited by `;` (since `#` of course, being a DTMF digit, may occur in\nmany places).  A configuration file is divided into sections whose names\nappear in `[]`'s.  Each section typically contains statements in the form\n`variable = value` although you may see `variable => value` in older samples.\n\n### SPECIAL NOTE ON TIME\n\nThose using SIP phones should be aware that Asterisk is sensitive to\nlarge jumps in time.  Manually changing the system time using date(1)\n(or other similar commands) may cause SIP registrations and other\ninternal processes to fail.  For this reason, you should always use\na time synchronization package to keep your system time accurate.\nAll OS/distributions make one or more of the following packages\navailable:\n\n* ntpd/ntpsec\n* chronyd\n* systemd-timesyncd\n\nBe sure to install and configure one (and only one) of them.\n\n### FILE DESCRIPTORS\n\nDepending on the size of your system and your configuration,\nAsterisk can consume a large number of file descriptors.  In UNIX,\nfile descriptors are used for more than just files on disk.  File\ndescriptors are also used for handling network communication\n(e.g. SIP, IAX2, or H.323 calls) and hardware access (e.g. analog and\ndigital trunk hardware).  Asterisk accesses many on-disk files for\neverything from configuration information to voicemail storage.\n\nMost systems limit the number of file descriptors that Asterisk can\nhave open at one time.  This can limit the number of simultaneous\ncalls that your system can handle.  For example, if the limit is set\nat 1024 (a common default value) Asterisk can handle approximately 150\nSIP calls simultaneously.  To change the number of file descriptors\nfollow the instructions for your system below:\n\n#### PAM-BASED LINUX SYSTEM\n\nIf your system uses PAM (Pluggable Authentication Modules) edit\n`/etc/security/limits.conf`.  Add these lines to the bottom of the file:\n\n```text\nroot            soft    nofile          4096\nroot            hard    nofile          8196\nasterisk        soft    nofile          4096\nasterisk        hard    nofile          8196\n```\n\n(adjust the numbers to taste).  You may need to reboot the system for\nthese changes to take effect.\n\n#### GENERIC UNIX SYSTEM\n\nIf there are no instructions specifically adapted to your system\nabove you can try adding the command `ulimit -n 8192` to the script\nthat starts Asterisk.\n\n## MORE INFORMATION\n\nVisit the [Asterisk Documentation](https://docs.asterisk.org) website\nfor more documentation on various features and please read all the\nconfiguration samples that include documentation on the configuration options.\n\nFinally, you may wish to join the\n[Asterisk Community Forums](https://community.asterisk.org)\n\n\nWelcome to the growing worldwide community of Asterisk users!\n\n```\n        Mark Spencer, and the Asterisk.org development community\n```\n\n---\n\nAsterisk is a trademark of Sangoma Technologies Corporation\n\n\\[[Sangoma](https://www.sangoma.com/)\\] \n\\[[Home Page](https://www.asterisk.org)\\] \n\\[[Support](https://www.asterisk.org/support)\\] \n\\[[Documentation](https://docs.asterisk.org)\\] \n\\[[Community Forums](https://community.asterisk.org)\\] \n\\[[Release Notes](https://github.com/asterisk/asterisk/releases)\\] \n\\[[Security](https://docs.asterisk.org/Deployment/Important-Security-Considerations/)\\] \n\\[[Mailing List Archive](https://lists.digium.com)\\] \n\n",
      "stars_today": 2
    },
    {
      "id": 221058575,
      "name": "opentelemetry-rust",
      "full_name": "open-telemetry/opentelemetry-rust",
      "description": "The Rust OpenTelemetry implementation",
      "html_url": "https://github.com/open-telemetry/opentelemetry-rust",
      "stars": 2427,
      "forks": 622,
      "language": "Rust",
      "topics": [
        "jaeger",
        "logging",
        "metrics",
        "opentelemetry",
        "prometheus",
        "tracing",
        "zipkin"
      ],
      "created_at": "2019-11-11T19:53:32Z",
      "updated_at": "2026-01-23T22:22:42Z",
      "pushed_at": "2026-01-23T22:22:40Z",
      "open_issues": 294,
      "owner": {
        "login": "open-telemetry",
        "avatar_url": "https://avatars.githubusercontent.com/u/49998002?v=4"
      },
      "readme": "# OpenTelemetry Rust\n\nThe Rust [OpenTelemetry](https://opentelemetry.io/) implementation.\n\n[![Crates.io: opentelemetry](https://img.shields.io/crates/v/opentelemetry.svg)](https://crates.io/crates/opentelemetry)\n[![LICENSE](https://img.shields.io/crates/l/opentelemetry)](./LICENSE)\n[![FOSSA Status](https://app.fossa.com/api/projects/custom%2B162%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-rust.svg?type=shield&issueType=license)](https://app.fossa.com/projects/custom%2B162%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-rust?ref=badge_shield&issueType=license)\n[![FOSSA Status](https://app.fossa.com/api/projects/custom%2B162%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-rust.svg?type=shield&issueType=security)](https://app.fossa.com/projects/custom%2B162%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-rust?ref=badge_shield&issueType=security)\n[![GitHub Actions CI](https://github.com/open-telemetry/opentelemetry-rust/workflows/CI/badge.svg)](https://github.com/open-telemetry/opentelemetry-rust/actions?query=workflow%3ACI+branch%3Amain)\n[![Documentation](https://docs.rs/opentelemetry/badge.svg)](https://docs.rs/opentelemetry)\n[![codecov](https://codecov.io/gh/open-telemetry/opentelemetry-rust/branch/main/graph/badge.svg)](https://codecov.io/gh/open-telemetry/opentelemetry-rust)\n[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/open-telemetry/opentelemetry-rust/badge)](https://scorecard.dev/viewer/?uri=github.com/open-telemetry/opentelemetry-rust)\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10394/badge)](https://www.bestpractices.dev/projects/10394)\n[![Slack](https://img.shields.io/badge/slack-@cncf/otel/rust-brightgreen.svg?logo=slack)](https://cloud-native.slack.com/archives/C03GDP0H023)\n\n## Overview\n\nOpenTelemetry is a collection of tools, APIs, and SDKs used to instrument,\ngenerate, collect, and export telemetry data (metrics, logs, and traces) for\nanalysis in order to understand your software's performance and behavior. You\ncan export and analyze them using [Prometheus], [Jaeger], and other\nobservability tools.\n\n*[Supported Rust Versions](#supported-rust-versions)*\n\n[Prometheus]: https://prometheus.io\n[Jaeger]: https://www.jaegertracing.io\n\n## Project Status\n\nThe table below summarizes the overall status of each component. Some components\ninclude unstable features, which are documented in their respective crate\ndocumentation.\n\n| Signal/Component      | Overall Status     |\n| --------------------  | ------------------ |\n| Context               | Beta               |\n| Baggage               | RC                 |\n| Propagators           | Beta               |\n| Logs-API              | Stable*            |\n| Logs-SDK              | Stable             |\n| Logs-OTLP Exporter    | RC                 |\n| Logs-Appender-Tracing | Stable             |\n| Metrics-API           | Stable             |\n| Metrics-SDK           | Stable             |\n| Metrics-OTLP Exporter | RC                 |\n| Traces-API            | Beta               |\n| Traces-SDK            | Beta               |\n| Traces-OTLP Exporter  | Beta               |\n\n*OpenTelemetry Rust is not introducing a new end user callable Logging API.\nInstead, it provides [Logs Bridge\nAPI](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/logs/api.md),\nthat allows one to write log appenders that can bridge existing logging\nlibraries to the OpenTelemetry log data model. The following log appenders are\navailable:\n\n* [opentelemetry-appender-log](opentelemetry-appender-log/README.md)\n* [opentelemetry-appender-tracing](opentelemetry-appender-tracing/README.md)\n\nIf you already use the logging APIs from above, continue to use them, and use\nthe appenders above to bridge the logs to OpenTelemetry. If you are using a\nlibrary not listed here, feel free to contribute a new appender for the same.\n\nIf you are starting fresh, we recommend using\n[tracing](https://github.com/tokio-rs/tracing) as your logging API. It supports\nstructured logging and is actively maintained. `OpenTelemetry` itself uses\n`tracing` for its internal logging.\n\nProject versioning information and stability guarantees can be found\n[here](VERSIONING.md).\n\n## Getting Started\n\nIf you are new to OpenTelemetry, start with the [Stdout\nExample](./opentelemetry-stdout/examples/basic.rs). This example demonstrates\nhow to use OpenTelemetry for logs, metrics, and traces, and display\ntelemetry data on your console.\n\nFor those using OTLP, the recommended OpenTelemetry Exporter for production\nscenarios, refer to the [OTLP Example -\nHTTP](./opentelemetry-otlp/examples/basic-otlp-http/README.md) and the [OTLP\nExample - gRPC](./opentelemetry-otlp/examples/basic-otlp/README.md).\n\nAdditional examples for various integration patterns can be found in the\n[examples](./examples) directory.\n\n## Overview of crates\n\nThe following crates are maintained in this repo:\n\n* [`opentelemetry`] This is the OpenTelemetry API crate, and is the crate\n  required to instrument libraries and applications. It contains Context API,\n  Baggage API, Propagators API, Logging Bridge API, Metrics API, and Tracing\n  API.\n* [`opentelemetry-sdk`] This is the OpenTelemetry SDK crate, and contains the\n  official OpenTelemetry SDK implementation. It contains Logging SDK, Metrics\n  SDK, and Tracing SDK. It also contains propagator implementations.\n* [`opentelemetry-otlp`] - exporter to send telemetry (logs, metrics and traces)\n  in the [OTLP\n  format](https://github.com/open-telemetry/opentelemetry-specification/tree/main/specification/protocol)\n  to an endpoint accepting OTLP. This could be the [OTel\n  Collector](https://github.com/open-telemetry/opentelemetry-collector),\n  telemetry backends like [Jaeger](https://www.jaegertracing.io/),\n  [Prometheus](https://prometheus.io/docs/prometheus/latest/feature_flags/#otlp-receiver)\n  or [vendor specific endpoints](https://opentelemetry.io/ecosystem/vendors/).\n* [`opentelemetry-stdout`] exporter for sending logs, metrics and traces to\n  stdout, for learning/debugging purposes.  \n* [`opentelemetry-http`] This crate contains utility functions to help with\n  exporting telemetry, propagation, over [`http`].\n* [`opentelemetry-appender-log`] This crate provides logging appender to route\n  logs emitted using the [log](https://docs.rs/log/latest/log/) crate to\n  opentelemetry.\n* [`opentelemetry-appender-tracing`] This crate provides logging appender to\n  route logs emitted using the [tracing](https://crates.io/crates/tracing) crate\n  to opentelemetry.  \n* [`opentelemetry-jaeger-propagator`] provides context propagation using [jaeger\n  propagation\n  format](https://www.jaegertracing.io/docs/1.18/client-libraries/#propagation-format).\n* [`opentelemetry-prometheus`] provides a pipeline and exporter for sending\n  metrics to [`Prometheus`].\n* [`opentelemetry-semantic-conventions`] provides standard names and semantic\n  otel conventions.\n* [`opentelemetry-zipkin`] provides a pipeline and exporter for sending traces\n  to [`Zipkin`].\n\nIn addition, there are several other useful crates in the [OTel Rust Contrib\nrepo](https://github.com/open-telemetry/opentelemetry-rust-contrib). A lot of\ncrates maintained outside OpenTelemetry owned repos can be found in the\n[OpenTelemetry\nRegistry](https://opentelemetry.io/ecosystem/registry/?language=rust).\n\n[`opentelemetry`]: https://crates.io/crates/opentelemetry\n[`opentelemetry-sdk`]: https://crates.io/crates/opentelemetry-sdk\n[`opentelemetry-appender-log`]: https://crates.io/crates/opentelemetry-appender-log\n[`opentelemetry-appender-tracing`]: https://crates.io/crates/opentelemetry-appender-tracing\n[`opentelemetry-http`]: https://crates.io/crates/opentelemetry-http\n[`opentelemetry-otlp`]: https://crates.io/crates/opentelemetry-otlp\n[`opentelemetry-stdout`]: https://crates.io/crates/opentelemetry-stdout\n[`opentelemetry-jaeger-propagator`]: https://crates.io/crates/opentelemetry-jaeger-propagator\n[`opentelemetry-prometheus`]: https://crates.io/crates/opentelemetry-prometheus\n[`Prometheus`]: https://prometheus.io\n[`opentelemetry-zipkin`]: https://crates.io/crates/opentelemetry-zipkin\n[`Zipkin`]: https://zipkin.io\n[`opentelemetry-semantic-conventions`]: https://crates.io/crates/opentelemetry-semantic-conventions\n[`http`]: https://crates.io/crates/http\n\n## Supported Rust Versions\n\nOpenTelemetry is built against the latest stable release. The minimum supported\nversion is 1.75. The current OpenTelemetry version is not guaranteed to build\non Rust versions earlier than the minimum supported version.\n\nThe current stable Rust compiler and the three most recent minor versions\nbefore it will always be supported. For example, if the current stable compiler\nversion is 1.49, the minimum supported version will not be increased past 1.46,\nthree minor versions prior. Increasing the minimum supported compiler version\nis not considered a semver breaking change as long as doing so complies with\nthis policy.\n\n## Contributing\n\nSee the [contributing file](CONTRIBUTING.md).\n\nThe Rust special interest group (SIG) meets on alternating weeks between Tuesday\nat 9:00 AM PT and Wednesday at 8:00 AM PT.\nThe meeting is subject to change depending on contributors' availability.\nCheck the [OpenTelemetry community\ncalendar](https://github.com/open-telemetry/community?tab=readme-ov-file#calendar)\nfor specific dates and for Zoom meeting links. \"OTel Rust SIG\" is the name of\nmeeting for this group.\n\nMeeting notes are available as a public [Google\ndoc](https://docs.google.com/document/d/12upOzNk8c3SFTjsL6IRohCWMgzLKoknSCOOdMakbWo4/edit).\nIf you have trouble accessing the doc, please get in touch on\n[Slack](https://cloud-native.slack.com/archives/C03GDP0H023).\n\nThe meeting is open for all to join. We invite everyone to join our meeting,\nregardless of your experience level. Whether you're a seasoned OpenTelemetry\ndeveloper, just starting your journey, or simply curious about the work we do,\nyou're more than welcome to participate!\n\n## Approvers and Maintainers\n\n### Maintainers\n\n* [Cijo Thomas](https://github.com/cijothomas), Microsoft\n* [Harold Dost](https://github.com/hdost)\n* [Lalit Kumar Bhasin](https://github.com/lalitb), Microsoft\n* [Utkarsh Umesan Pillai](https://github.com/utpilla), Microsoft\n* [Zhongyang Wu](https://github.com/TommyCpp)\n\nFor more information about the maintainer role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#maintainer).\n\n### Approvers\n\n* [Anton Gr√ºbel](https://github.com/gruebel), Baz\n* [Bj√∂rn Antonsson](https://github.com/bantonsson), Datadog\n* [Scott Gerring](https://github.com/scottgerring), Datadog\n* [Shaun Cox](https://github.com/shaun-cox), Microsoft\n\nFor more information about the approver role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#approver).\n\n### Emeritus\n\n* [Dirkjan Ochtman](https://github.com/djc)\n* [Isobel Redelmeier](https://github.com/iredelmeier)\n* [Jan K√ºhle](https://github.com/frigus02)\n* [Julian Tescher](https://github.com/jtescher)\n* [Mike Goldsmith](https://github.com/MikeGoldsmith)\n\nFor more information about the emeritus role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager).\n\n### Thanks to all the people who have contributed\n\n[![contributors](https://contributors-img.web.app/image?repo=open-telemetry/opentelemetry-rust)](https://github.com/open-telemetry/opentelemetry-rust/graphs/contributors)\n",
      "stars_today": 2
    },
    {
      "id": 190275430,
      "name": "hidapi",
      "full_name": "libusb/hidapi",
      "description": "A Simple cross-platform library for communicating with HID devices",
      "html_url": "https://github.com/libusb/hidapi",
      "stars": 2104,
      "forks": 453,
      "language": "C",
      "topics": [
        "android",
        "bluetooth",
        "bsd",
        "c",
        "hid",
        "hidapi",
        "hidapi-library",
        "hidraw",
        "i2c",
        "linux",
        "macos",
        "spi",
        "usb",
        "usb-hid",
        "windows"
      ],
      "created_at": "2019-06-04T20:36:19Z",
      "updated_at": "2026-01-23T19:39:53Z",
      "pushed_at": "2026-01-15T14:17:10Z",
      "open_issues": 59,
      "owner": {
        "login": "libusb",
        "avatar_url": "https://avatars.githubusercontent.com/u/4439549?v=4"
      },
      "readme": "## HIDAPI library for Windows, Linux, FreeBSD and macOS\n\n| CI instance          | Status |\n|----------------------|--------|\n| `Linux/macOS/Windows (master)` | [![GitHub Builds](https://github.com/libusb/hidapi/actions/workflows/builds.yml/badge.svg?branch=master)](https://github.com/libusb/hidapi/actions/workflows/builds.yml?query=branch%3Amaster) |\n| `Windows (master)` | [![Build status](https://ci.appveyor.com/api/projects/status/xfmr5fo8w0re8ded/branch/master?svg=true)](https://ci.appveyor.com/project/libusb/hidapi/branch/master) |\n| `BSD, last build (branch/PR)` | [![builds.sr.ht status](https://builds.sr.ht/~z3ntu/hidapi.svg)](https://builds.sr.ht/~z3ntu/hidapi) |\n| `Coverity Scan (last)` | [![Coverity Scan](https://scan.coverity.com/projects/583/badge.svg)](https://scan.coverity.com/projects/hidapi) |\n\nHIDAPI is a multi-platform library which allows an application to interface\nwith USB and Bluetooth HID-Class devices on Windows, Linux, FreeBSD, and macOS.\nHIDAPI can be either built as a shared library (`.so`, `.dll` or `.dylib`) or\ncan be embedded directly into a target application by adding a _single source_\nfile (per platform) and a single header.<br>\nSee [remarks](BUILD.md#embedding-hidapi-directly-into-your-source-tree) on embedding _directly_ into your build system.\n\nHIDAPI library was originally developed by Alan Ott ([signal11](https://github.com/signal11)).\n\nIt was moved to [libusb/hidapi](https://github.com/libusb/hidapi) on June 4th, 2019, in order to merge important bugfixes and continue development of the library.\n\n## Table of Contents\n\n* [About](#about)\n    * [Test GUI](#test-gui)\n    * [Console Test App](#console-test-app)\n* [What Does the API Look Like?](#what-does-the-api-look-like)\n* [License](#license)\n* [Installing HIDAPI](#installing-hidapi)\n* [Build from Source](#build-from-source)\n\n\n## About\n\n### HIDAPI has four back-ends:\n* Windows (using `hid.dll`)\n* Linux/hidraw (using the Kernel's hidraw driver)\n* libusb (using libusb-1.0 - Linux/BSD/other UNIX-like systems)\n* macOS (using IOHidManager)\n\nOn Linux, either the hidraw or the libusb back-end can be used. There are\ntradeoffs, and the functionality supported is slightly different. Both are\nbuilt by default. It is up to the application linking to hidapi to choose\nthe backend at link time by linking to either `libhidapi-libusb` or\n`libhidapi-hidraw`.\n\nNote that you will need to install an udev rule file with your application\nfor unprivileged users to be able to access HID devices with hidapi. Refer\nto the [69-hid.rules](udev/69-hid.rules) file in the `udev` directory\nfor an example.\n\n#### __Linux/hidraw__ (`linux/hid.c`):\n\nThis back-end uses the hidraw interface in the Linux kernel, and supports\nboth USB and Bluetooth HID devices. It requires kernel version at least 2.6.39\nto build. In addition, it will only communicate with devices which have hidraw\nnodes associated with them.\nKeyboards, mice, and some other devices which are blacklisted from having\nhidraw nodes will not work. Fortunately, for nearly all the uses of hidraw,\nthis is not a problem.\n\n#### __Linux/FreeBSD/libusb__ (`libusb/hid.c`):\n\nThis back-end uses libusb-1.0 to communicate directly to a USB device. This\nback-end will of course not work with Bluetooth devices.\n\n### Test GUI\n\nHIDAPI also comes with a Test GUI. The Test GUI is cross-platform and uses\nFox Toolkit <http://www.fox-toolkit.org>.  It will build on every platform\nwhich HIDAPI supports.  Since it relies on a 3rd party library, building it\nis optional but it is useful when debugging hardware.\n\nNOTE: Test GUI based on Fox Toolkit is not actively developed nor supported\nby HIDAPI team. It is kept as a historical artifact. It may even work sometime\nor on some platforms, but it is not going to get any new features or bugfixes.\n\nInstructions for installing Fox-Toolkit on each platform is not provided.\nMake sure to use Fox-Toolkit v1.6 if you choose to use it.\n\n### Console Test App\n\nIf you want to play around with your HID device before starting\nany development with HIDAPI and using a GUI app is not an option for you, you may try [`hidapitester`](https://github.com/todbot/hidapitester).\n\nThis app has a console interface for most of the features supported\nby HIDAPI library.\n\n## What Does the API Look Like?\n\nThe API provides the most commonly used HID functions including sending\nand receiving of input, output, and feature reports. The sample program,\nwhich communicates with a heavily hacked up version of the Microchip USB\nGeneric HID sample looks like this (with error checking removed for\nsimplicity):\n\n**Warning: Only run the code you understand, and only when it conforms to the\ndevice spec. Writing data (`hid_write`) at random to your HID devices can break them.**\n\n```c\n#include <stdio.h> // printf\n#include <wchar.h> // wchar_t\n\n#include <hidapi.h>\n\n#define MAX_STR 255\n\nint main(int argc, char* argv[])\n{\n\tint res;\n\tunsigned char buf[65];\n\twchar_t wstr[MAX_STR];\n\thid_device *handle;\n\tint i;\n\n\t// Initialize the hidapi library\n\tres = hid_init();\n\n\t// Open the device using the VID, PID,\n\t// and optionally the Serial number.\n\thandle = hid_open(0x4d8, 0x3f, NULL);\n\tif (!handle) {\n\t\tprintf(\"Unable to open device\\n\");\n\t\thid_exit();\n \t\treturn 1;\n\t}\n\n\t// Read the Manufacturer String\n\tres = hid_get_manufacturer_string(handle, wstr, MAX_STR);\n\tprintf(\"Manufacturer String: %ls\\n\", wstr);\n\n\t// Read the Product String\n\tres = hid_get_product_string(handle, wstr, MAX_STR);\n\tprintf(\"Product String: %ls\\n\", wstr);\n\n\t// Read the Serial Number String\n\tres = hid_get_serial_number_string(handle, wstr, MAX_STR);\n\tprintf(\"Serial Number String: (%d) %ls\\n\", wstr[0], wstr);\n\n\t// Read Indexed String 1\n\tres = hid_get_indexed_string(handle, 1, wstr, MAX_STR);\n\tprintf(\"Indexed String 1: %ls\\n\", wstr);\n\n\t// Toggle LED (cmd 0x80). The first byte is the report number (0x0).\n\tbuf[0] = 0x0;\n\tbuf[1] = 0x80;\n\tres = hid_write(handle, buf, 65);\n\n\t// Request state (cmd 0x81). The first byte is the report number (0x0).\n\tbuf[0] = 0x0;\n\tbuf[1] = 0x81;\n\tres = hid_write(handle, buf, 65);\n\n\t// Read requested state\n\tres = hid_read(handle, buf, 65);\n\n\t// Print out the returned buffer.\n\tfor (i = 0; i < 4; i++)\n\t\tprintf(\"buf[%d]: %d\\n\", i, buf[i]);\n\n\t// Close the device\n\thid_close(handle);\n\n\t// Finalize the hidapi library\n\tres = hid_exit();\n\n\treturn 0;\n}\n```\n\nYou can also use [hidtest/test.c](hidtest/test.c)\nas a starting point for your applications.\n\n\n## License\n\nHIDAPI may be used by one of three licenses as outlined in [LICENSE.txt](LICENSE.txt).\n\n## Installing HIDAPI\n\nIf you want to build your own application that uses HID devices with HIDAPI,\nyou need to get HIDAPI development package.\n\nDepending on what your development environment is, HIDAPI likely to be provided\nby your package manager.\n\nFor instance on Ubuntu, HIDAPI is available via APT:\n```sh\nsudo apt install libhidapi-dev\n```\n\nHIDAPI package name for other systems/package managers may differ.\nCheck the documentation/package list of your package manager.\n\n## Build from Source\n\nCheck [BUILD.md](BUILD.md) for details.\n",
      "stars_today": 2
    },
    {
      "id": 107540288,
      "name": "ort",
      "full_name": "oss-review-toolkit/ort",
      "description": "A suite of tools to automate software compliance checks.",
      "html_url": "https://github.com/oss-review-toolkit/ort",
      "stars": 1914,
      "forks": 371,
      "language": "Kotlin",
      "topics": [
        "compliance",
        "copyright",
        "cra",
        "cyclonedx",
        "dependencies",
        "dependency-graph",
        "dora",
        "hacktoberfest",
        "license",
        "license-management",
        "open-source-licensing",
        "ospo",
        "oss-compliance",
        "package-manager",
        "sbom",
        "sbom-generator",
        "sca",
        "spdx"
      ],
      "created_at": "2017-10-19T11:59:49Z",
      "updated_at": "2026-01-23T21:59:18Z",
      "pushed_at": "2026-01-23T21:59:14Z",
      "open_issues": 323,
      "owner": {
        "login": "oss-review-toolkit",
        "avatar_url": "https://avatars.githubusercontent.com/u/48252958?v=4"
      },
      "readme": "![OSS Review Toolkit Logo](./logos/ort.png)\n\n&nbsp;\n\n[![Slack][1]][2]\n\n[![Static Analysis][3]][4] [![Build and Test][5]][6] [![Code coverage][7]][8]\n\n[![REUSE status][9]][10] [![OpenSSF Best Practices][11]][12] [![OpenSSF Scorecard][13]][14]\n\n[1]: https://img.shields.io/badge/Join_us_on_Slack!-ort--talk-blue.svg?longCache=true&logo=slack\n[2]: http://slack.oss-review-toolkit.org\n[3]: https://github.com/oss-review-toolkit/ort/actions/workflows/static-analysis.yml/badge.svg\n[4]: https://github.com/oss-review-toolkit/ort/actions/workflows/static-analysis.yml\n[5]: https://github.com/oss-review-toolkit/ort/actions/workflows/build-and-test.yml/badge.svg\n[6]: https://github.com/oss-review-toolkit/ort/actions/workflows/build-and-test.yml\n[7]: https://codecov.io/gh/oss-review-toolkit/ort/branch/main/graph/badge.svg?token=QD2tCSUTVN\n[8]: https://app.codecov.io/gh/oss-review-toolkit/ort\n[9]: https://api.reuse.software/badge/github.com/oss-review-toolkit/ort\n[10]: https://api.reuse.software/info/github.com/oss-review-toolkit/ort\n[11]: https://www.bestpractices.dev/projects/4618/badge\n[12]: https://www.bestpractices.dev/projects/4618\n[13]: https://api.scorecard.dev/projects/github.com/oss-review-toolkit/ort/badge\n[14]: https://scorecard.dev/viewer/?uri=github.com/oss-review-toolkit/ort\n\n# Introduction\n\nThe OSS Review Toolkit (ORT) is a FOSS policy automation and orchestration toolkit that you can use to manage your (open source) software dependencies in a strategic, safe and efficient manner.\n\nYou can use it to:\n\n* Generate CycloneDX, SPDX SBOMs, or custom FOSS attribution documentation for your software project\n* Automate your FOSS policy using risk-based Policy as Code to do licensing, security vulnerability, InnerSource and engineering standards checks for your software project and its dependencies\n* Create a source code archive for your software project and its dependencies to comply with certain licenses or have your own copy as nothing on the internet is forever\n* Correct package metadata or licensing findings yourself, using InnerSource or with the help of the FOSS community\n\nORT can be used as a library (for programmatic use), via a command line interface (for scripted use), or via its CI integrations.\nIt consists of the following tools which can be combined into a *highly customizable* pipeline:\n\n* [*Analyzer*](https://oss-review-toolkit.org/ort/docs/tools/analyzer):\n  Determines the dependencies of projects and their metadata, abstracting which package managers or build systems are actually being used.\n* [*Downloader*](https://oss-review-toolkit.org/ort/docs/tools/downloader):\n  Fetches all source code of the projects and their dependencies, abstracting which Version Control System (VCS) or other means are used to retrieve the source code.\n* [*Scanner*](https://oss-review-toolkit.org/ort/docs/tools/scanner):\n  Uses configured source code scanners to detect license / copyright findings, abstracting the type of scanner.\n* [*Advisor*](https://oss-review-toolkit.org/ort/docs/tools/advisor):\n  Retrieves security advisories for used dependencies from configured vulnerability data services.\n* [*Evaluator*](https://oss-review-toolkit.org/ort/docs/tools/evaluator):\n  Evaluates custom policy rules along with custom license classifications against the data gathered in preceding stages and returns a list of policy violations, e.g. to flag license findings.\n* [*Reporter*](https://oss-review-toolkit.org/ort/docs/tools/reporter):\n  Presents results in various formats such as visual reports, Open Source notices or Bill-Of-Materials (BOMs) to easily identify dependencies, licenses, copyrights or policy rule violations.\n* *Notifier*:\n  Sends result notifications via different channels (like [emails](./examples/example.notifications.kts) and / or JIRA tickets).\n\nAlso see the [list of related tools](https://oss-review-toolkit.org/ort/docs/related-tools) that help with running ORT.\n\n## Documentation\n\nFor detailed information, see the documentation on the [ORT Website](https://oss-review-toolkit.org/ort/).\n\n# Installation\n\n## System requirements\n\nORT is being continuously used on Linux, Windows and macOS by the [core development team](https://github.com/orgs/oss-review-toolkit/people), so these operating systems are considered to be well-supported.\n\nTo run the ORT binaries (also see [Installation from binaries](#from-binaries)) at least Java 21 is required.\nMemory and CPU requirements vary depending on the size and type of project(s) to analyze / scan, but the general recommendation is to configure Java with 8 GiB of memory and to use a CPU with at least 4 cores.\n\n```shell\n# This will give the Java Virtual Machine 8GB Memory.\nexport JAVA_OPTS=\"$JAVA_OPTS -Xmx8g\"\n```\n\nIf ORT requires external tools to analyze a project, these tools are listed by the `ort requirements` command.\nIf a package manager is not listed there, support for it is integrated directly into ORT and does not require any external tools to be installed.\n\n## From binaries\n\n### CLI distribution\n\nHead over to the [releases](https://github.com/oss-review-toolkit/ort/releases) page.\nFrom the \"Assets\" section of your chosen release, download the distribution archive of the desired type.\nTypically that is `.zip` for Windows and `.tgz` otherwise; but the contents of the archives are the same.\nThe `ort-*` archives contain the [ORT main](./cli/) distribution, while the `orth-*` archives contain the [ORT helper](./cli-helper/) distribution.\nUnpack the archive to an installation directory.\nThe scripts to run ORT are located at `bin/ort` and `bin\\ort.bat`, or `bin/orth` and `bin\\orth.bat`, respectively.\n\n### Docker distribution\n\nIn addition to the CLI, ORT is also distributed as a Docker image that contains all tools required by ORT (see the `ort requirements` command).\nTo run ORT from the latest version of that image (which will be downloaded if needed) use:\n\n```shell\ndocker run ghcr.io/oss-review-toolkit/ort --help\n```\n\n## From sources\n\nInstall the following basic prerequisites:\n\n* Git (any recent version will do).\n\nThen clone this repository.\n\n```shell\ngit clone https://github.com/oss-review-toolkit/ort\n# If you intend to run tests, you have to clone the submodules too.\ncd ort\ngit submodule update --init --recursive\n```\n\n### Build using Docker\n\nInstall the following basic prerequisites:\n\n* Docker 18.09 or later (and ensure its daemon is running).\n* Enable [BuildKit](https://docs.docker.com/develop/develop-images/build_enhancements/#to-enable-buildkit-builds) for Docker.\n\nChange into the directory with ORT's source code and run `docker build -t ort .`.\nAlternatively, use the script at `scripts/docker_build.sh` which also sets the ORT version from the Git revision.\n\n### Build natively\n\nInstall these additional prerequisites:\n\n* Java Development Kit (JDK) version 21 or later; also remember to set the `JAVA_HOME` environment variable accordingly.\n\nChange into the directory with ORT's source code and run `./gradlew installDist` (on the first run this will bootstrap Gradle and download all required dependencies).\n\n## Basic usage\n\nDepending on how ORT was installed, it can be run in the following ways:\n\n* If the Docker image was built locally as described above, use\n\n  ```shell\n  docker run ort --help\n  ```\n\n  You can find further hints for using ORT with Docker in the [documentation](./website/docs/guides/docker.md).\n\n* If the ORT distribution was built from sources, use\n\n  ```shell\n  ./cli/build/install/ort/bin/ort --help\n  ```\n\n* If running directly from sources via Gradle, use\n\n  ```shell\n  ./gradlew cli:run --args=\"--help\"\n  ```\n\n  Note that in this case the working directory used by ORT is that of the `cli` project, not the directory `gradlew` is located in (see https://github.com/gradle/gradle/issues/6074).\n\n# Contributing\n\nAll contributions are welcome.\nIf you are interested in contributing code, please read our [contributing guide](https://github.com/oss-review-toolkit/.github/blob/main/CONTRIBUTING.md).\nFor everything from reporting bugs to asking questions, please go through the [issue workflow](https://github.com/oss-review-toolkit/ort/issues/new/choose).\n\n## Statistics\n\n![Alt](https://repobeats.axiom.co/api/embed/39cfad4ac09c3b4a361a1365ccf1a65c612a8ed0.svg \"Repobeats analytics image\")\n\n# License\n\nCopyright (C) 2017-2026 [The ORT Project Copyright Holders](./NOTICE).\n\nSee the [LICENSE](./LICENSE) file in the root of this project for license details.\n\nOSS Review Toolkit (ORT) is a [Linux Foundation project](https://www.linuxfoundation.org/) and part of [ACT](https://automatecompliance.org/).\nTo learn more on how the project is governed, including its charter, see the [ort-governance](https://github.com/oss-review-toolkit/ort-governance) repository.\n",
      "stars_today": 2
    },
    {
      "id": 452908115,
      "name": "nflverse-data",
      "full_name": "nflverse/nflverse-data",
      "description": "Automated nflverse data repository",
      "html_url": "https://github.com/nflverse/nflverse-data",
      "stars": 331,
      "forks": 34,
      "language": "R",
      "topics": [],
      "created_at": "2022-01-28T02:01:18Z",
      "updated_at": "2026-01-23T16:05:09Z",
      "pushed_at": "2026-01-18T10:33:20Z",
      "open_issues": 6,
      "owner": {
        "login": "nflverse",
        "avatar_url": "https://avatars.githubusercontent.com/u/79467114?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# nflverse-data\n\n<!-- badges: start -->\n<!-- badges: end -->\n\nThis repository holds automated data releases for nflverse projects\n(i.e.¬†all of the data powered/scraped via GitHub Actions).\n\n## Usage\n\nYou can download data hosted here with the `{nflreadr}` package, or\nmanually download and access the\n[releases](https://github.com/nflverse/nflverse-data/releases) page.\nReleases are roughly organized along the [main\nfunctions](https://nflreadr.nflverse.com/reference/) of nflreadr.\n\n## Automation Status\n\nPlease see https://nflreadr.nflverse.com/articles/nflverse_data_schedule.html#automation-status for the status table. \n",
      "stars_today": 2
    },
    {
      "id": 293498508,
      "name": "compose-multiplatform",
      "full_name": "JetBrains/compose-multiplatform",
      "description": "Compose Multiplatform, a modern UI framework for Kotlin that makes building performant and beautiful user interfaces easy and enjoyable.",
      "html_url": "https://github.com/JetBrains/compose-multiplatform",
      "stars": 18738,
      "forks": 1378,
      "language": "Kotlin",
      "topics": [
        "android",
        "awt",
        "compose",
        "declarative-ui",
        "desktop",
        "gui",
        "ios",
        "javascript",
        "kotlin",
        "multiplatform",
        "reactive",
        "swing",
        "ui",
        "wasm",
        "web",
        "webassembly"
      ],
      "created_at": "2020-09-07T10:40:49Z",
      "updated_at": "2026-01-24T00:04:03Z",
      "pushed_at": "2026-01-23T10:25:39Z",
      "open_issues": 70,
      "owner": {
        "login": "JetBrains",
        "avatar_url": "https://avatars.githubusercontent.com/u/878437?v=4"
      },
      "readme": "[![official project](http://jb.gg/badges/official.svg)](https://confluence.jetbrains.com/display/ALL/JetBrains+on+GitHub)\n[![stable](https://img.shields.io/github/v/release/JetBrains/compose-multiplatform?sort=semver&display_name=release&label=stable&color=brightgreen)](https://github.com/JetBrains/compose-multiplatform/releases/latest)\n[![prerelease](https://img.shields.io/github/v/release/JetBrains/compose-multiplatform?include_prereleases&sort=semver&filter=*-*&display_name=release&label=prerelease&color=blue)](https://github.com/JetBrains/compose-multiplatform/releases)\n[![dev](https://img.shields.io/github/v/tag/JetBrains/compose-multiplatform?include_prereleases&sort=semver&filter=v*%2Bdev*&label=dev&color=orange)](https://github.com/JetBrains/compose-multiplatform/tags)\n\n<a href=\"https://jb.gg/cmp\">\n    <picture>\n        <source srcset=\"artwork/compose-logo-name-white.svg\"  width=\"400\" media=\"(prefers-color-scheme: dark)\">\n        <img src=\"artwork/compose-logo-name-black.svg\" alt=\"Compose Multiplatform logo and name\" width=\"400\">\n    </picture>\n</a>\n\n[Compose Multiplatform](https://jb.gg/cmp) is a declarative framework for sharing UI code across multiple platforms with Kotlin. \nIt is based on [Jetpack Compose](https://developer.android.com/jetpack/compose) and developed by [JetBrains](https://www.jetbrains.com/) and open-source contributors.\n\nYou can choose the platforms across which to share your UI code using Compose Multiplatform:\n\n* [iOS](https://jb.gg/start-cmp)\n* [Android](https://jb.gg/start-cmp) \n* [Desktop](https://jb.gg/start-cmp) (Windows, MacOS, and Linux)\n* [Web](https://jb.gg/start-cmp) (Beta)\n\nFor example, you can share UIs between iOS and Android or Windows and MacOS.\n\n![Shared UIs of the iOS, Android, desktop, and web apps](artwork/readme/apps.png)\n\n## iOS\n\nCompose Multiplatform shares most of its API with Jetpack Compose, the Android UI framework developed by Google. \nYou can use the same APIs to build user interfaces for both Android and iOS.\n\nSince Compose is built on top of [Kotlin Multiplatform](https://jb.gg/kmp), \nyou can easily access native APIs, such as the [Camera API](https://developer.apple.com/documentation/avfoundation/capture_setup/avcam_building_a_camera_app), \nand embed complex native UI views, such as [MKMapView](https://developer.apple.com/documentation/mapkit/mkmapview).\n\n**[Get started with Compose Multiplatform](https://jb.gg/start-cmp)**\n\n## Android\n\nWhen Android is one of your targets, you get the same experience for Android as if you were developing an Android app \nusing [Jetpack Compose](https://developer.android.com/jetpack/compose).\n\n**[Get started with Compose Multiplatform](https://jb.gg/start-cmp)**\n\n## Desktop\n\nCompose Multiplatform targets the JVM and supports high-performance hardware-accelerated UI rendering on all major desktop\nplatforms ‚Äì macOS, Windows, and Linux.\n\nIt has desktop extensions for menus, keyboard shortcuts, window manipulation, and notification management.\n\n**[Get started with Compose Multiplatform](https://jb.gg/start-cmp)**\n\n## Web\n\n> Web support is in Beta, making it a great time to give it a try. Check out our [blog post](https://blog.jetbrains.com/kotlin/2025/09/compose-multiplatform-1-9-0-compose-for-web-beta/) to learn more about the progress made to reach this milestone.\n> We would appreciate your feedback on it in the public Slack channel [#compose-web](https://kotlinlang.slack.com/archives/C01F2HV7868/p1678887590205449). \n> If you face any issues, please report them on [YouTrack](https://youtrack.jetbrains.com/newIssue?project=CMP).\n\nYou can experiment with sharing your mobile or desktop UIs with the web. Compose Multiplatform for web is based on [Kotlin/Wasm](https://kotl.in/wasm), \nthe newest target for Kotlin Multiplatform projects. It allows Kotlin developers to run their code in the browser with \nall the benefits that WebAssembly has to offer, such as good and predictable performance for your applications.\n\n**[Get started with Compose Multiplatform for web](https://jb.gg/start-cmp)**\n\n## Libraries\n\n### Compose HTML\n\nCompose HTML is a library targeting [Kotlin/JS](https://kotlinlang.org/docs/js-overview.html) that provides Composable building blocks \nfor creating web user interfaces with HTML and CSS.    \n\n> Note that Compose HTML is not a multiplatform library. It can be used only with Kotlin/JS.\n\n## Learn more\n\n* [FAQ](https://jb.gg/cmp-faq)\n* [Samples](https://jb.gg/cmp-samples)\n* [Tutorials](tutorials/README.md)\n* [Compatibility and versioning](https://jb.gg/cmp-versioning)\n* [Changelog](CHANGELOG.md)\n* [Contibution guide](CONTRIBUTING.md)\n\n## Get help\n\nThere are dedicated public Slack channels for [#compose-ios](https://kotlinlang.slack.com/archives/C0346LWVBJ4/p1678888063176359), [#compose-desktop](https://kotlinlang.slack.com/archives/C01D6HTPATV) and [#compose-web](https://kotlinlang.slack.com/archives/C01F2HV7868/p1678887590205449), as well as the general [#compose](https://kotlinlang.slack.com/archives/CJLTWPH7S) channel.\n\nIf you encounter any issues, please report them on [YouTrack](https://youtrack.jetbrains.com/newIssue?project=CMP).\n\n",
      "stars_today": 1
    },
    {
      "id": 53614190,
      "name": "mosquitto",
      "full_name": "eclipse-mosquitto/mosquitto",
      "description": "Eclipse Mosquitto - An open source MQTT broker",
      "html_url": "https://github.com/eclipse-mosquitto/mosquitto",
      "stars": 10540,
      "forks": 2574,
      "language": "C",
      "topics": [
        "broker",
        "eclipse-iot",
        "mosquitto",
        "mqtt"
      ],
      "created_at": "2016-03-10T20:19:09Z",
      "updated_at": "2026-01-24T01:23:29Z",
      "pushed_at": "2026-01-23T09:26:12Z",
      "open_issues": 812,
      "owner": {
        "login": "eclipse-mosquitto",
        "avatar_url": "https://avatars.githubusercontent.com/u/185921483?v=4"
      },
      "readme": "Eclipse Mosquitto\n=================\n\nMosquitto is an open source implementation of a server for version 5.0, 3.1.1,\nand 3.1 of the MQTT protocol. It also includes a C and C++ client library, and\nthe `mosquitto_pub` and `mosquitto_sub` utilities for publishing and\nsubscribing.\n\n## Links\n\nSee the following links for more information on MQTT:\n\n- Community page: <http://mqtt.org/>\n- MQTT v3.1.1 standard: <https://docs.oasis-open.org/mqtt/mqtt/v3.1.1/mqtt-v3.1.1.html>\n- MQTT v5.0 standard: <https://docs.oasis-open.org/mqtt/mqtt/v5.0/mqtt-v5.0.html>\n\nMosquitto project information is available at the following locations:\n\n- Main homepage: <https://mosquitto.org/>\n- Find existing bugs or submit a new bug: <https://github.com/eclipse/mosquitto/issues>\n- Source code repository: <https://github.com/eclipse/mosquitto>\n\nThere is also a public test server available at <https://test.mosquitto.org/>\n\n## Installing\n\nSee <https://mosquitto.org/download/> for details on installing binaries for\nvarious platforms.\n\n## Quick start\n\nIf you have installed a binary package the broker should have been started\nautomatically. If not, it can be started with a very basic configuration:\n\n    mosquitto\n\nThen use `mosquitto_sub` to subscribe to a topic:\n\n    mosquitto_sub -t 'test/topic' -v\n\nAnd to publish a message:\n\n    mosquitto_pub -t 'test/topic' -m 'hello world'\n\nNote that starting the broker like this allows anonymous/unauthenticated access\nbut only from the local computer, so it's only really useful for initial testing.\n\nIf you want to have clients from another computer connect, you will need to\nprovide a configuration file. If you have installed from a binary package, you\nwill probably already have a configuration file at somewhere like\n`/etc/mosquitto/mosquitto.conf`. If you've compiled from source, you can write\nyour config file then run as `mosquitto -c /path/to/mosquitto.conf`.\n\nTo start your config file you define a listener and you will need to think\nabout what authentication you require. It is not advised to run your broker\nwith anonymous access when it is publically available.\n\nFor details on how to do this, look at the\n[authentication methods](https://mosquitto.org/documentation/authentication-methods/)\navailable and the [dynamic security plugin](https://mosquitto.org/documentation/dynamic-security/).\n\n## Documentation\n\nDocumentation for the broker, clients and client library API can be found in\nthe man pages, which are available online at <https://mosquitto.org/man/>. There\nare also pages with an introduction to the features of MQTT, the\n`mosquitto_passwd` utility for dealing with username/passwords, and a\ndescription of the configuration file options available for the broker.\n\nDetailed client library API documentation can be found at <https://mosquitto.org/api/>\n\n## Building from source\n\nTo build from source the recommended route for end users is to download the\narchive from <https://mosquitto.org/download/>.\n\nOn Windows and Mac, use `cmake` to build. On other platforms, just run `make`\nto build. For Windows, see also `README-windows.md`.\n\nIf you are building from the git repository then the documentation will not\nalready be built. Use `make binary` to skip building the man pages, or install\n`docbook-xsl` on Debian/Ubuntu systems.\n\n### Build Dependencies\n\n* c-ares (libc-ares-dev on Debian based systems) - only when compiled with `make WITH_SRV=yes`\n* cJSON - for client JSON output support. Disable with `make WITH_CJSON=no` Auto detected with CMake.\n* libwebsockets (libwebsockets-dev) - enable with `make WITH_WEBSOCKETS=yes`\n* openssl (libssl-dev on Debian based systems) - disable with `make WITH_TLS=no`\n* pthreads - for client library thread support. This is required to support the\n  `mosquitto_loop_start()` and `mosquitto_loop_stop()` functions. If compiled\n  without pthread support, the library isn't guaranteed to be thread safe.\n* uthash / utlist - bundled versions of these headers are provided, disable their use with `make WITH_BUNDLED_DEPS=no`\n* xsltproc (xsltproc and docbook-xsl on Debian based systems) - only needed when building from git sources - disable with `make WITH_DOCS=no`\n\nEquivalent options for enabling/disabling features are available when using the CMake build.\n\n\n## Credits\n\nMosquitto was written by Roger Light <roger@atchoo.org>\n",
      "stars_today": 1
    },
    {
      "id": 10270722,
      "name": "go-github",
      "full_name": "google/go-github",
      "description": "Go library for accessing the GitHub v3 API",
      "html_url": "https://github.com/google/go-github",
      "stars": 11089,
      "forks": 2208,
      "language": "Go",
      "topics": [
        "github",
        "github-api",
        "go",
        "golang",
        "hacktoberfest"
      ],
      "created_at": "2013-05-24T16:42:58Z",
      "updated_at": "2026-01-24T01:35:04Z",
      "pushed_at": "2026-01-24T00:53:57Z",
      "open_issues": 58,
      "owner": {
        "login": "google",
        "avatar_url": "https://avatars.githubusercontent.com/u/1342004?v=4"
      },
      "readme": "# go-github #\n\n[![go-github release (latest SemVer)](https://img.shields.io/github/v/release/google/go-github?sort=semver)](https://github.com/google/go-github/releases)\n[![Go Reference](https://img.shields.io/static/v1?label=godoc&message=reference&color=blue)](https://pkg.go.dev/github.com/google/go-github/v81/github)\n[![Test Status](https://github.com/google/go-github/actions/workflows/tests.yml/badge.svg?branch=master)](https://github.com/google/go-github/actions/workflows/tests.yml)\n[![Test Coverage](https://codecov.io/gh/google/go-github/branch/master/graph/badge.svg)](https://codecov.io/gh/google/go-github)\n[![Discuss at go-github@googlegroups.com](https://img.shields.io/badge/discuss-go--github%40googlegroups.com-blue.svg)](https://groups.google.com/group/go-github)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/796/badge)](https://bestpractices.coreinfrastructure.org/projects/796)\n\ngo-github is a Go client library for accessing the [GitHub API v3][].\n\ngo-github tracks [Go's version support policy][support-policy] supporting any\nminor version of the latest two major releases of Go and the go directive in\ngo.mod reflects that.\nWe do our best not to break older versions of Go if we don't have to, but we\ndon't explicitly test older versions and as of Go 1.23 the go directive in\ngo.mod declares a hard required _minimum_ version of Go to use with this module\nand this _must_ be greater than or equal to the go line of all dependencies so\ngo-github will require the N-1 major release of Go by default.\n\n[support-policy]: https://golang.org/doc/devel/release.html#policy\n\n## Development\n\nIf you're interested in using the [GraphQL API v4][], the recommended library is\n[shurcooL/githubv4][].\n\n## Installation ##\n\ngo-github is compatible with modern Go releases in module mode, with Go installed:\n\n```bash\ngo get github.com/google/go-github/v81\n```\n\nwill resolve and add the package to the current development module, along with its dependencies.\n\nAlternatively the same can be achieved if you use import in a package:\n\n```go\nimport \"github.com/google/go-github/v81/github\"\n```\n\nand run `go get` without parameters.\n\nFinally, to use the top-of-trunk version of this repo, use the following command:\n\n```bash\ngo get github.com/google/go-github/v81@master\n```\n\n## Usage ##\n\n```go\nimport \"github.com/google/go-github/v81/github\"\t// with go modules enabled (GO111MODULE=on or outside GOPATH)\nimport \"github.com/google/go-github/github\" // with go modules disabled\n```\n\nConstruct a new GitHub client, then use the various services on the client to\naccess different parts of the GitHub API. For example:\n\n```go\nclient := github.NewClient(nil)\n\n// list all organizations for user \"willnorris\"\norgs, _, err := client.Organizations.List(context.Background(), \"willnorris\", nil)\n```\n\nSome API methods have optional parameters that can be passed. For example:\n\n```go\nclient := github.NewClient(nil)\n\n// list public repositories for org \"github\"\nopt := &github.RepositoryListByOrgOptions{Type: \"public\"}\nrepos, _, err := client.Repositories.ListByOrg(context.Background(), \"github\", opt)\n```\n\nThe services of a client divide the API into logical chunks and correspond to\nthe structure of the [GitHub API documentation](https://docs.github.com/en/rest).\n\nNOTE: Using the [context](https://pkg.go.dev/context) package, one can easily\npass cancellation signals and deadlines to various services of the client for\nhandling a request. In case there is no context available, then `context.Background()`\ncan be used as a starting point.\n\nFor more sample code snippets, head over to the\n[example](https://github.com/google/go-github/tree/master/example) directory.\n\n### Authentication ###\n\nUse the `WithAuthToken` method to configure your client to authenticate using an\nOAuth token (for example, a [personal access token][]). This is what is needed\nfor a majority of use cases aside from GitHub Apps.\n\n```go\nclient := github.NewClient(nil).WithAuthToken(\"... your access token ...\")\n```\n\nNote that when using an authenticated Client, all calls made by the client will\ninclude the specified OAuth token. Therefore, authenticated clients should\nalmost never be shared between different users.\n\nFor API methods that require HTTP Basic Authentication, use the\n[`BasicAuthTransport`](https://pkg.go.dev/github.com/google/go-github/v81/github#BasicAuthTransport).\n\n#### As a GitHub App ####\n\nGitHub Apps authentication can be provided by different pkgs like [bradleyfalzon/ghinstallation](https://github.com/bradleyfalzon/ghinstallation)\nor [jferrl/go-githubauth](https://github.com/jferrl/go-githubauth).\n\n> **Note**: Most endpoints (ex. [`GET /rate_limit`]) require access token authentication\n> while a few others (ex. [`GET /app/hook/deliveries`]) require [JWT] authentication.\n\n[`GET /rate_limit`]: https://docs.github.com/en/rest/rate-limit#get-rate-limit-status-for-the-authenticated-user\n[`GET /app/hook/deliveries`]: https://docs.github.com/en/rest/apps/webhooks#list-deliveries-for-an-app-webhook\n[JWT]: https://docs.github.com/en/developers/apps/building-github-apps/authenticating-with-github-apps#authenticating-as-a-github-app\n\n`ghinstallation` provides `Transport`, which implements `http.RoundTripper` to provide authentication as an installation for GitHub Apps.\n\nHere is an example of how to authenticate as a GitHub App using the `ghinstallation` package:\n\n```go\nimport (\n\t\"net/http\"\n\n\t\"github.com/bradleyfalzon/ghinstallation/v2\"\n\t\"github.com/google/go-github/v81/github\"\n)\n\nfunc main() {\n\t// Wrap the shared transport for use with the integration ID 1 authenticating with installation ID 99.\n\titr, err := ghinstallation.NewKeyFromFile(http.DefaultTransport, 1, 99, \"2016-10-19.private-key.pem\")\n\n\t// Or for endpoints that require JWT authentication\n\t// itr, err := ghinstallation.NewAppsTransportKeyFromFile(http.DefaultTransport, 1, \"2016-10-19.private-key.pem\")\n\n\tif err != nil {\n\t\t// Handle error.\n\t}\n\n\t// Use installation transport with client.\n\tclient := github.NewClient(&http.Client{Transport: itr})\n\n\t// Use client...\n}\n```\n\n`go-githubauth` implements a set of `oauth2.TokenSource` to be used with `oauth2.Client`. An `oauth2.Client` can be injected into the `github.Client` to authenticate requests.\n\nOther example using `go-githubauth`:\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"strconv\"\n\n\t\"github.com/google/go-github/v81/github\"\n\t\"github.com/jferrl/go-githubauth\"\n\t\"golang.org/x/oauth2\"\n)\n\nfunc main() {\n\tprivateKey := []byte(os.Getenv(\"GITHUB_APP_PRIVATE_KEY\"))\n\n\tappTokenSource, err := githubauth.NewApplicationTokenSource(1112, privateKey)\n\tif err != nil {\n\t\tfmt.Println(\"Error creating application token source:\", err)\n\t\treturn\n\t }\n\n\tinstallationTokenSource := githubauth.NewInstallationTokenSource(1113, appTokenSource)\n\n\t// oauth2.NewClient uses oauth2.ReuseTokenSource to reuse the token until it expires.\n\t// The token will be automatically refreshed when it expires.\n\t// InstallationTokenSource has the mechanism to refresh the token when it expires.\n\thttpClient := oauth2.NewClient(context.Background(), installationTokenSource)\n\n\tclient := github.NewClient(httpClient)\n}\n```\n\n*Note*: In order to interact with certain APIs, for example writing a file to a repo, one must generate an installation token\nusing the installation ID of the GitHub app and authenticate with the OAuth method mentioned above. See the examples.\n\n### Rate Limiting ###\n\nGitHub imposes rate limits on all API clients. The [primary rate limit](https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api#about-primary-rate-limits)\nis the limit to the number of REST API requests that a client can make within a\nspecific amount of time. This limit helps prevent abuse and denial-of-service\nattacks, and ensures that the API remains available for all users. Some\nendpoints, like the search endpoints, have more restrictive limits.\nUnauthenticated clients may request public data but have a low rate limit,\nwhile authenticated clients have rate limits based on the client\nidentity.\n\nIn addition to primary rate limits, GitHub enforces [secondary rate limits](https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api#about-secondary-rate-limits)\nin order to prevent abuse and keep the API available for all users.\nSecondary rate limits generally limit the number of concurrent requests that a\nclient can make.\n\nThe client returned `Response.Rate` value contains the rate limit information\nfrom the most recent API call. If a recent enough response isn't\navailable, you can use the client `RateLimits` service to fetch the most\nup-to-date rate limit data for the client.\n\nTo detect a primary API rate limit error, you can check if the error is a\n`RateLimitError`.\n\n```go\nrepos, _, err := client.Repositories.List(ctx, \"\", nil)\nvar rateErr *github.RateLimitError\nif errors.As(err, &rateErr) {\n\tlog.Printf(\"hit primary rate limit, used %v of %v\\n\", rateErr.Rate.Used, rateErr.Rate.Limit)\n}\n```\n\nTo detect an API secondary rate limit error, you can check if the error is an\n`AbuseRateLimitError`.\n\n```go\nrepos, _, err := client.Repositories.List(ctx, \"\", nil)\nvar rateErr *github.AbuseRateLimitError\nif errors.As(err, &rateErr) {\n\tlog.Printf(\"hit secondary rate limit, retry after %v\\n\", rateErr.RetryAfter)\n}\n```\n\nIf you hit the primary rate limit, you can use the `SleepUntilPrimaryRateLimitResetWhenRateLimited`\nmethod to block until the rate limit is reset.\n\n```go\nrepos, _, err := client.Repositories.List(context.WithValue(ctx, github.SleepUntilPrimaryRateLimitResetWhenRateLimited, true), \"\", nil)\n```\n\nIf you need to make a request even if the rate limit has been hit you can use\nthe `BypassRateLimitCheck` method to bypass the rate limit check and make the\nrequest anyway.\n\n```go\nrepos, _, err := client.Repositories.List(context.WithValue(ctx, github.BypassRateLimitCheck, true), \"\", nil)\n```\n\nFor more advanced use cases, you can use [gofri/go-github-ratelimit](https://github.com/gofri/go-github-ratelimit)\nwhich provides a middleware (`http.RoundTripper`) that handles both the primary\nrate limit and secondary rate limit for the GitHub API. In this case you can\nset the client `DisableRateLimitCheck` to `true` so the client doesn't track the rate limit usage.\n\nIf the client is an [OAuth app](https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api#primary-rate-limit-for-oauth-apps)\nyou can use the apps higher rate limit to request public data by using the\n`UnauthenticatedRateLimitedTransport` to make calls as the app instead of as\nthe user.\n\n### Accepted Status ###\n\nSome endpoints may return a 202 Accepted status code, meaning that the\ninformation required is not yet ready and was scheduled to be gathered on\nthe GitHub side. Methods known to behave like this are documented specifying\nthis behavior.\n\nTo detect this condition of error, you can check if its type is\n`*github.AcceptedError`:\n\n```go\nstats, _, err := client.Repositories.ListContributorsStats(ctx, org, repo)\nif errors.As(err, new(*github.AcceptedError)) {\n\tlog.Println(\"scheduled on GitHub side\")\n}\n```\n\n### Conditional Requests ###\n\nThe GitHub REST API has good support for [conditional HTTP requests](https://docs.github.com/en/rest/using-the-rest-api/best-practices-for-using-the-rest-api?apiVersion=2022-11-28#use-conditional-requests-if-appropriate)\nvia the `ETag` header which will help prevent you from burning through your\nrate limit, as well as help speed up your application. `go-github` does not\nhandle conditional requests directly, but is instead designed to work with a\ncaching `http.Transport`.\n\nTypically, an [RFC 9111](https://datatracker.ietf.org/doc/html/rfc9111)\ncompliant HTTP cache such as [bartventer/httpcache](https://github.com/bartventer/httpcache)\nis recommended, ex:\n\n```go\nimport (\n\t\"github.com/bartventer/httpcache\"\n\t_ \"github.com/bartventer/httpcache/store/memcache\" //  Register the in-memory backend\n)\n\nclient := github.NewClient(\n\thttpcache.NewClient(\"memcache://\"),\n).WithAuthToken(os.Getenv(\"GITHUB_TOKEN\"))\n```\n\nAlternatively, the [bored-engineer/github-conditional-http-transport](https://github.com/bored-engineer/github-conditional-http-transport)\npackage relies on (undocumented) GitHub specific cache logic and is\nrecommended when making requests using short-lived credentials such as a \n[GitHub App installation token](https://docs.github.com/en/apps/creating-github-apps/authenticating-with-a-github-app/authenticating-as-a-github-app-installation).\n\n### Creating and Updating Resources ###\n\nAll structs for GitHub resources use pointer values for all non-repeated fields.\nThis allows distinguishing between unset fields and those set to a zero-value.\nHelper functions have been provided to easily create these pointers for string,\nbool, and int values. For example:\n\n```go\n// create a new private repository named \"foo\"\nrepo := &github.Repository{\n\tName:    github.Ptr(\"foo\"),\n\tPrivate: github.Ptr(true),\n}\nclient.Repositories.Create(ctx, \"\", repo)\n```\n\nUsers who have worked with protocol buffers should find this pattern familiar.\n\n### Pagination ###\n\nAll requests for resource collections (repos, pull requests, issues, etc.)\nsupport pagination. Pagination options are described in the\n`github.ListOptions` struct and passed to the list methods directly or as an\nembedded type of a more specific list options struct (for example\n`github.PullRequestListOptions`). Pages information is available via the\n`github.Response` struct.\n\n```go\nclient := github.NewClient(nil)\n\nopt := &github.RepositoryListByOrgOptions{\n\tListOptions: github.ListOptions{PerPage: 10},\n}\n// get all pages of results\nvar allRepos []*github.Repository\nfor {\n\trepos, resp, err := client.Repositories.ListByOrg(ctx, \"github\", opt)\n\tif err != nil {\n\t\treturn err\n\t}\n\tallRepos = append(allRepos, repos...)\n\tif resp.NextPage == 0 {\n\t\tbreak\n\t}\n\topt.Page = resp.NextPage\n}\n```\n\n#### Iterators (**experimental**) ####\n\nGo v1.23 introduces the new `iter` package.  \n\nWith the `enrichman/gh-iter` package, it is possible to create iterators for `go-github`. The iterator will handle pagination for you, looping through all the available results.\n\n```go\nclient := github.NewClient(nil)\nvar allRepos []*github.Repository\n\n// create an iterator and start looping through all the results\nrepos := ghiter.NewFromFn1(client.Repositories.ListByOrg, \"github\")\nfor repo := range repos.All() {\n\tallRepos = append(allRepos, repo)\n}\n```\n\nFor complete usage of `enrichman/gh-iter`, see the full [package docs](https://github.com/enrichman/gh-iter).\n\n#### Middleware ####\n\nYou can use [gofri/go-github-pagination](https://github.com/gofri/go-github-pagination) to handle\npagination for you. It supports both sync and async modes, as well as customizations.  \nBy default, the middleware automatically paginates through all pages, aggregates results, and returns them as an array.  \nSee `example/ratelimit/main.go` for usage.\n\n### Webhooks ###\n\n`go-github` provides structs for almost all [GitHub webhook events][] as well as functions to validate them and unmarshal JSON payloads from `http.Request` structs.\n\n```go\nfunc (s *GitHubEventMonitor) ServeHTTP(w http.ResponseWriter, r *http.Request) {\n\tpayload, err := github.ValidatePayload(r, s.webhookSecretKey)\n\tif err != nil { ... }\n\tevent, err := github.ParseWebHook(github.WebHookType(r), payload)\n\tif err != nil { ... }\n\tswitch event := event.(type) {\n\tcase *github.CommitCommentEvent:\n\t\tprocessCommitCommentEvent(event)\n\tcase *github.CreateEvent:\n\t\tprocessCreateEvent(event)\n\t...\n\t}\n}\n```\n\nFurthermore, there are libraries like [cbrgm/githubevents][] that build upon the example above and provide functions to subscribe callbacks to specific events.\n\nFor complete usage of go-github, see the full [package docs][].\n\n[GitHub API v3]: https://docs.github.com/en/rest\n[personal access token]: https://github.com/blog/1509-personal-api-tokens\n[package docs]: https://pkg.go.dev/github.com/google/go-github/v81/github\n[GraphQL API v4]: https://developer.github.com/v4/\n[shurcooL/githubv4]: https://github.com/shurcooL/githubv4\n[GitHub webhook events]: https://docs.github.com/en/developers/webhooks-and-events/webhooks/webhook-events-and-payloads\n[cbrgm/githubevents]: https://github.com/cbrgm/githubevents\n\n### Testing code that uses `go-github` ###\n\nThe repo [migueleliasweb/go-github-mock](https://github.com/migueleliasweb/go-github-mock) provides a way to mock responses. Check the repo for more details.\n\n### Integration Tests ###\n\nYou can run integration tests from the `test` directory. See the integration tests [README](test/README.md).\n\n## Contributing ##\n\nI would like to cover the entire GitHub API and contributions are of course always welcome. The\ncalling pattern is pretty well established, so adding new methods is relatively\nstraightforward. See [`CONTRIBUTING.md`](CONTRIBUTING.md) for details.\n\n## Versioning ##\n\nIn general, go-github follows [semver](https://semver.org/) as closely as we\ncan for tagging releases of the package. For self-contained libraries, the\napplication of semantic versioning is relatively straightforward and generally\nunderstood. But because go-github is a client library for the GitHub API, which\nitself changes behavior, and because we are typically pretty aggressive about\nimplementing preview features of the GitHub API, we've adopted the following\nversioning policy:\n\n* We increment the **major version** with any incompatible change to\n\tnon-preview functionality, including changes to the exported Go API surface\n\tor behavior of the API.\n* We increment the **minor version** with any backwards-compatible changes to\n\tfunctionality, as well as any changes to preview functionality in the GitHub\n\tAPI. GitHub makes no guarantee about the stability of preview functionality,\n\tso neither do we consider it a stable part of the go-github API.\n* We increment the **patch version** with any backwards-compatible bug fixes.\n\nPreview functionality may take the form of entire methods or simply additional\ndata returned from an otherwise non-preview method. Refer to the GitHub API\ndocumentation for details on preview functionality.\n\n### Calendar Versioning ###\n\nAs of 2022-11-28, GitHub [has announced](https://github.blog/2022-11-28-to-infinity-and-beyond-enabling-the-future-of-githubs-rest-api-with-api-versioning/)\nthat they are starting to version their v3 API based on \"calendar-versioning\".\n\nIn practice, our goal is to make per-method version overrides (at\nleast in the core library) rare and temporary.\n\nOur understanding of the GitHub docs is that they will be revving the\nentire API to each new date-based version, even if only a few methods\nhave breaking changes. Other methods will accept the new version with\ntheir existing functionality. So when a new date-based version of the\nGitHub API is released, we (the repo maintainers) plan to:\n\n* update each method that had breaking changes, overriding their\n  per-method API version header. This may happen in one or multiple\n  commits and PRs, and is all done in the main branch.\n\n* once all of the methods with breaking changes have been updated,\n  have a final commit that bumps the default API version, and remove\n  all of the per-method overrides. That would now get a major version\n  bump when the next go-github release is made.\n\n### Version Compatibility Table ###\n\nThe following table identifies which version of the GitHub API is\nsupported by this (and past) versions of this repo (go-github).\nVersions prior to 48.2.0 are not listed.\n\n| go-github Version | GitHub v3 API Version |\n| ----------------- | --------------------- |\n| 81.0.0            | 2022-11-28            |\n| ...               | 2022-11-28            |\n| 48.2.0            | 2022-11-28            |\n\n## License ##\n\nThis library is distributed under the BSD-style license found in the [LICENSE](./LICENSE)\nfile.\n",
      "stars_today": 1
    },
    {
      "id": 33166041,
      "name": "react-native-video",
      "full_name": "TheWidlarzGroup/react-native-video",
      "description": "A <Video /> component for react-native",
      "html_url": "https://github.com/TheWidlarzGroup/react-native-video",
      "stars": 7621,
      "forks": 3024,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2015-03-31T05:08:38Z",
      "updated_at": "2026-01-22T23:33:47Z",
      "pushed_at": "2026-01-22T11:14:54Z",
      "open_issues": 201,
      "owner": {
        "login": "TheWidlarzGroup",
        "avatar_url": "https://avatars.githubusercontent.com/u/60334373?v=4"
      },
      "readme": "[![React Native Video Component](./docs/static/baners/rnv-banner.png)](https://thewidlarzgroup.com/?utm_source=rnv&utm_medium=readme&utm_id=banner)\n\nThe most battle-tested open-source video player component for React Native with support for DRM, offline playback, HLS/DASH streaming, and more.\n\n> [!IMPORTANT]\n> This is a new version (v7) of `react-native-video` that is currently in active development.\n> You can expect breaking changes and missing features.\n> \n> If you have any questions, please contact us at [hi@thewidlarzgroup.com](mailto:hi@thewidlarzgroup.com).\n\n## üîç Features\n\n| Feature | Status |\n|---------|--------|\n| üì± Plays all video formats natively supported by iOS/Android | ‚úÖ Available |\n| ‚ñ∂Ô∏è Local and remote playback | ‚úÖ Available |\n| üîÅ Streaming: HLS ‚Ä¢ DASH ‚Ä¢ SmoothStreaming | ‚úÖ Available |\n| üß© Expo plugin support | ‚úÖ Available |\n| üì¥ Offline playback, video download, support for side-tracks and side-captions (via [optional SDK](https://docs.thewidlarzgroup.com/offline-video-sdk?utm_source=rnv&utm_medium=readme&utm_id=features-text)) | ‚úÖ Available |\n| üì± Picture in Picture | ‚úÖ Available |\n| üéöÔ∏è Fine-grained control over tracks, buffering & events | üèóÔ∏è In Development |\n| üß† Advanced control over playback and buffering | ‚úÖ Available |\n| üîê DRM: Widevine & FairPlay ([See free DRM stream example](https://www.thewidlarzgroup.com/services/free-drm-token-generator-for-video?utm_source=rnv&utm_medium=readme&utm_id=free-drm)) | ‚úÖ Available |\n| üåê Basic Web Support | üìù [TODO](https://github.com/TheWidlarzGroup/react-native-video/issues/4605) |\n| üì∫ TV Support | üìù [TODO](https://github.com/TheWidlarzGroup/react-native-video/issues/4607) |\n| ü•Ω VisionOS Support | üìù [TODO](https://github.com/TheWidlarzGroup/react-native-video/issues/4608) |\n\n\n\n## ‚ú® Project Status\n\n| Version | State | Architecture |\n|---------|-------|--------------|\n| **v5 and lower** | ‚ùå End-of-life [Commercial Support Available](https://www.thewidlarzgroup.com/blog/react-native-video-upgrade-challenges-custom-maintenance-support#how-we-can-help?utm_source=rnv&utm_medium=readme&utm_id=upgradev5) | Old Architecture |\n| **v6** | üõ† Maintained (community + TWG) | Old + New (Interop Layer) |\n| **v7** | üöÄ Active Development | Old + New (Full Support) |\n\n`react-native-video` v7 introduces full support for the new React Native architecture, unlocking better performance, improved consistency, and modern native modules.\n\n---\n\n## üìö Documentation & Examples\n\n- üìñ [Documentation](https://docs.thewidlarzgroup.com/react-native-video/docs/v7/intro)\n- üì¶ [Example: Basic Usage](https://github.com/TheWidlarzGroup/react-native-video/tree/v7/example)\n- üì¶ [Example: Free DRM Stream](https://www.thewidlarzgroup.com/services/free-drm-token-generator-for-video?utm_source=rnv&utm_medium=readme&utm_id=free-drm)\n\n## üöÄ Quick Start\n\n### Requirements\n\n- React Native 0.75 or higher\n- `react-native-nitro-modules` (>=0.31.10) - Please see [nitro requirements](https://nitro.margelo.com/docs/minimum-requirements)\n\n### Install\n\n`react-native-video` requires `react-native-nitro-modules` (>=0.31.10) in your project.\n```bash\nnpm install react-native-nitro-modules\n```\n\nThen install `react-native-video`\n\n```bash\n# Install the beta version of react-native-video v7\nnpm install react-native-video@beta\n\n# Install pods\ncd ios && pod install\n```\n\n<details>\n<summary>For react-native < 0.80</summary>\n`react-native` < 0.80 have bug that prevents to properly handle errors by nitro modules on Android.\nWe highly recommend to apply bellow patch for `react-native-nitro-modules` to fix this issue.\nYou can apply it using `patch-package`.\n\nWithout this patch you won't be able \"recognize\" errors, all will be thrown as unknown errors.\n\nsee [installation guide](https://docs.thewidlarzgroup.com/react-native-video/docs/v7/installation#patch-for-react-native--080)\n</details>\n\n### Usage\n```tsx\nimport { useVideoPlayer, VideoView } from 'react-native-video';\n\nexport default () => (\n  const player = useVideoPlayer(\n    'https://www.w3schools.com/html/mov_bbb.mp4',\n    (_player) => {\n      _player.play();\n    }\n  );\n\n  <VideoView\n    player={player}\n    style={{ width: '100%', aspectRatio: 16 / 9 }}\n    controls\n  />\n);\n```\n\n---\n\n## :inbox_tray: We're building a Pro Player!\n\n<a href=\"https://sdk.thewidlarzgroup.com\">\n  <img src=\"./docs/static/baners/rnv-pro-player-banner.png\" alt=\"Offline SDK Preview\" width=\"40%\" align=\"right\" />\n</a>\n\nWe see the need for a more feature-rich video player. There is a gap between open source and commercial players, and we want to fill that gap with plugins.\n\n**Are you using a commercial player just for 1-2 features?** Maybe you are paying for a license just to get **Caching**, **Ads**, or **Analytics**? Let us know. We want to identify these missing pieces and build them, so you can switch back to open source.\n\n**This is what we have already. Check out!**\n\n* [Offline Video](https://sdk.thewidlarzgroup.com/offline-video): Logic for downloading streams (HLS/DASH) and standard video files to enable offline playback.\n* [Background Uploader](https://sdk.thewidlarzgroup.com/background-uploader): Handles uploads even if the app is minimized (not strictly a player plugin, but super useful).\n* [Chapter Markers](https://sdk.thewidlarzgroup.com/chapters): Visual markers on the timeline to navigate content.\n\n<br/>\n<br/>\n\n[-> Tell us what to build next ‚Üê](https://sdk.thewidlarzgroup.com/ask-for-plugin) or reach out to us sdk@thewidlarzgroup.com\n\n<br/>\n\n---\n\n## üíº TWG Services & Products\n\n| Offering | Description |\n|----------|-------------|\n| [**Professional Support Packages**](https://www.thewidlarzgroup.com/issue-boost?utm_source=rnv&utm_medium=readme&utm_campaign=professional-support-packages#Contact) | Priority bug-fixes, guaranteed SLAs, [roadmap influence](https://github.com/orgs/TheWidlarzGroup/projects/6) |\n| [**Issue Booster**](https://www.thewidlarzgroup.com/issue-boost?utm_source=rnv&utm_medium=readme) | Fast-track urgent fixes with a pay‚Äëper‚Äëissue model |\n| [**Offline Video SDK**](https://www.thewidlarzgroup.com/offline-video-sdk/?utm_source=rnv&utm_medium=readme&utm_campaign=downloading&utm_id=offline-video-sdk-link) | Plug‚Äëand‚Äëplay secure download solution for iOS & Android |\n| [**Integration Support**](https://www.thewidlarzgroup.com/?utm_source=rnv&utm_medium=readme&utm_campaign=integration-support#Contact) | Hands‚Äëon help integrating video, DRM & offline into your app |\n| [**Free DRM Token Generator**](https://www.thewidlarzgroup.com/services/free-drm-token-generator-for-video?utm_source=rnv&utm_medium=readme&utm_id=free-drm) | Generate Widevine / FairPlay tokens for testing |\n| [**Ready Boilerplates**](https://www.thewidlarzgroup.com/showcases?utm_source=rnv&utm_medium=readme) | Ready-to-use apps with offline HLS/DASH DRM, video frame scrubbing, TikTok-style video feed, background uploads, Skia-based frame processor (R&D phase), and more |\n| [**React Native Video Upgrade Guide**](https://www.thewidlarzgroup.com/blog/react-native-video-upgrade-challenges-custom-maintenance-support?utm_source=rnv&utm_medium=readme&utm_id=upgrade-blog&utm_campaign=v7) | Common upgrade pitfalls & how to solve them |\n\n*See how [TWG](https://www.thewidlarzgroup.com/?utm_source=rnv&utm_medium=readme&utm_id=services-text) helped **Learnn** ship a world‚Äëclass player in record time -  [case study](https://gitnation.com/contents/a-4-year-retrospective-lessons-learned-from-building-a-video-player-from-scratch-with-react-native).*\n\nContact us at [hi@thewidlarzgroup.com](mailto:hi@thewidlarzgroup.com)\n\n## üåç Social\n\n- üê¶ **X / Twitter** - [follow product & release updates](https://x.com/TheWidlarzGroup)\n- üí¨ **Discord** - [talk to the community and us](https://discord.gg/9WPq6Yx)\n- üíº **LinkedIn** - [see TWG flexing](https://linkedin.com/company/the-widlarz-group)\n\n## üì∞ Community & Media\n\n- üóΩ **React Summit US** ‚Äì How TWG helped Learnn boost video performance on React Native.  \n[Watch the talk ¬ª](https://gitnation.com/contents/a-4-year-retrospective-lessons-learned-from-building-a-video-player-from-scratch-with-react-native)\n\n- üß® **v7 deep dive** ‚Äì Why we‚Äôre building v7 with Nitro Modules\n[Watch on X ¬ª](https://x.com/krzysztof_moch/status/1854162551946478051)\n\n- üõ†Ô∏è **Well-maintained open-source library** - What does it truly mean? - Bart's talk for React Native Warsaw\n[Watch here ¬ª](https://www.youtube.com/watch?v=RAQQwGCQNqY)\n\n- üì∫ **‚ÄúOver the Top‚Äù Panel** - Building Streaming Apps for Mobile, Web, and Smart TVs - Bart giving his insights on the industry\n[Watch here ¬ª](https://youtu.be/j2b_bG-32JI)\n",
      "stars_today": 1
    },
    {
      "id": 17101828,
      "name": "swirl_courses",
      "full_name": "swirldev/swirl_courses",
      "description": ":mortar_board: A collection of interactive courses for the swirl R package.",
      "html_url": "https://github.com/swirldev/swirl_courses",
      "stars": 4523,
      "forks": 7241,
      "language": "R",
      "topics": [],
      "created_at": "2014-02-23T04:48:04Z",
      "updated_at": "2026-01-23T10:12:20Z",
      "pushed_at": "2024-01-10T17:38:19Z",
      "open_issues": 206,
      "owner": {
        "login": "swirldev",
        "avatar_url": "https://avatars.githubusercontent.com/u/5671732?v=4"
      },
      "readme": "# swirl courses\n\nThis is a collection of interactive courses for use with the [swirl R package](http://swirlstats.com). You'll find instructions for installing courses further down on this page. Some courses are still in development and we'd love to hear any [suggestions](https://github.com/swirldev/swirl_courses/issues/new) you have as you work through them.\n\nFor more information regarding swirl, visit [swirlstats.com](http://swirlstats.com) or the [swirl GitHub repository](https://github.com/swirldev/swirl). If you'd like to write your own interactive content, please visit the [Instructors page](http://swirlstats.com/instructors.html) of our website.\n\nHere are our current offerings, organized by level of difficulty:\n\n#### Beginner\n\n- **R Programming**: The basics of programming in R\n- [**R Programming E**](https://github.com/swirldev/R_Programming_E): Same as the original, but modified slightly for in-class use (see below ***)\n- [**The R Programming Environment**](https://swirlstats.com/scn/rpe.html)\n<!-- - **Data Analysis**: Basic ideas in statistics and data visualization -->\n<!-- - **Mathematical Biostatistics Boot Camp**: One- and two-sample t-tests, power, and sample size -->\n<!-- - **Open Intro**: A very basic introduction to statistics, data analysis, and data visualization -->\n\n\\*\\*\\* *R Programming E is identical to R Programming, except we've eliminated the prompts for Coursera credentials at the end of each lesson and instead give students the option to send an email to their instructor notifying them of completion. Admittedly, it's sort of a hack until we come up with a more robust solution for in-class use (i.e. an instructor \"dashboard\").*\n\n#### Intermediate\n\n- **Regression Models**: The basics of regression modeling in R\n- **Getting and Cleaning Data**: dplyr, tidyr, lubridate, oh my!\n\n#### Advanced\n\n- **Statistical Inference**: This intermediate to advanced level course closely follows the\n[Statistical Inference course](https://www.coursera.org/course/statinference) of the Johns Hopkins \n[Data Science Specialization](https://www.coursera.org/specialization/jhudatascience/1) on Coursera. It\nintroduces the student to basic concepts of statistical inference\nincluding probability, hypothesis testing, confidence intervals and\np-values. It concludes with an initiation to topics of particular\nrelevance to big data, issues of multiple testing and resampling.\n- [**Advanced R Programming**](https://swirlstats.com/scn/arp.html)\n\nSince our users come from a variety backgrounds, it's very hard to label material as **Beginner**, **Intermediate**, or **Advanced**. If you find something that is labelled **Beginner** to be challenging, please don't be discouraged. The first step of learning anything is to acknowledge that you are capable of understanding it. True understanding will come with time and practice.\n\n#### Course Authors\n\n- **Writing swirl Courses**: An interactive guides and example \n  for swirl course authors. The first group of lessons cover basics. The rest cover \n  special topics useful primarily as samples--points of departure for one's own material.\n  For more comprehensive documentation about writing your own swirl courses see http://swirlstats.com/swirlify/.\n\n## Install and run a course automatically from swirl\n\n**This is the preferred method of installing courses.** It automates the process by allowing you to do everything right from the R console.\n\n1) Make sure you have a recent version version of swirl:\n\n```\ninstall.packages(\"swirl\")\n```\n\n2) Enter the following from the R console, **substituting the name of the course** that you wish to install:\n\n```\nlibrary(swirl)\ninstall_course(\"Course Name Here\")\nswirl()\n```\n\nFor example, `install_course(\"R Programming\")` will install the R Programming course. **Please note that course names are case sensitive!**\n\nIf that doesn't work for you...\n\n## Install and run a course manually\n\nIf the automatic course installation method outlined above does not work for you, then there's a simple alternative.\n\n1. Find the course you want to install on the [Swirl Course network website](https://swirlstats.com/scn/title.html).\n2. Follow the manual installation instructions on the course page.\n\nIf that does not work for you, consider taking a look at the \n[legacy manual install instructions](https://github.com/swirldev/swirl_courses/wiki/Legacy-Manual-Install-Instructions-for-Swirl-Courses).\n\n## Uninstall a course\n\nIf you'd like to remove a course at any time, you can use `uninstall_course(\"Course Name Here\")`.\n\n## Using swirl in the classroom\n\nInstructors around the world are using swirl in their classrooms. We think this is awesome. If you're an instructor, please feel free to do the same -- free of charge. While your students may be paying to take your course or attend your institution, we simply ask that you don't charge people *directly* for the use of our software or instructional content.\n\nIf you are not sure about a particular use case, don't hesitate to post a\nquestion to our [Google Group](https://groups.google.com/forum/#!forum/swirl-discuss).\n",
      "stars_today": 1
    },
    {
      "id": 26537135,
      "name": "u-boot",
      "full_name": "u-boot/u-boot",
      "description": "\"Das U-Boot\" Source Tree",
      "html_url": "https://github.com/u-boot/u-boot",
      "stars": 4892,
      "forks": 4252,
      "language": "C",
      "topics": [],
      "created_at": "2014-11-12T13:29:02Z",
      "updated_at": "2026-01-23T22:33:49Z",
      "pushed_at": "2026-01-23T22:33:38Z",
      "open_issues": 229,
      "owner": {
        "login": "u-boot",
        "avatar_url": "https://avatars.githubusercontent.com/u/9681997?v=4"
      },
      "readme": " # SPDX-License-Identifier: GPL-2.0+\n#\n# (C) Copyright 2000 - 2013\n# Wolfgang Denk, DENX Software Engineering, wd@denx.de.\n\nSummary:\n========\n\nThis directory contains the source code for U-Boot, a boot loader for\nEmbedded boards based on PowerPC, ARM, MIPS and several other\nprocessors, which can be installed in a boot ROM and used to\ninitialize and test the hardware or to download and run application\ncode.\n\nThe development of U-Boot is closely related to Linux: some parts of\nthe source code originate in the Linux source tree, we have some\nheader files in common, and special provision has been made to\nsupport booting of Linux images.\n\nSome attention has been paid to make this software easily\nconfigurable and extendable. For instance, all monitor commands are\nimplemented with the same call interface, so that it's very easy to\nadd new commands. Also, instead of permanently adding rarely used\ncode (for instance hardware test utilities) to the monitor, you can\nload and run it dynamically.\n\n\nStatus:\n=======\n\nIn general, all boards for which a default configuration file exists in the\nconfigs/ directory have been tested to some extent and can be considered\n\"working\". In fact, many of them are used in production systems.\n\nIn case of problems you can use\n\n     scripts/get_maintainer.pl <path>\n\nto identify the people or companies responsible for various boards and\nsubsystems. Or have a look at the git log.\n\n\nWhere to get help:\n==================\n\nIn case you have questions about, problems with or contributions for\nU-Boot, you should send a message to the U-Boot mailing list at\n<u-boot@lists.denx.de>. There is also an archive of previous traffic\non the mailing list - please search the archive before asking FAQ's.\nPlease see https://lists.denx.de/pipermail/u-boot and\nhttps://marc.info/?l=u-boot\n\nWhere to get source code:\n=========================\n\nThe U-Boot source code is maintained in the Git repository at\nhttps://source.denx.de/u-boot/u-boot.git ; you can browse it online at\nhttps://source.denx.de/u-boot/u-boot\n\nThe \"Tags\" links on this page allow you to download tarballs of\nany version you might be interested in. Official releases are also\navailable from the DENX file server through HTTPS or FTP.\nhttps://ftp.denx.de/pub/u-boot/\nftp://ftp.denx.de/pub/u-boot/\n\n\nWhere we come from:\n===================\n\n- start from 8xxrom sources\n- create PPCBoot project (https://sourceforge.net/projects/ppcboot)\n- clean up code\n- make it easier to add custom boards\n- make it possible to add other [PowerPC] CPUs\n- extend functions, especially:\n  * Provide extended interface to Linux boot loader\n  * S-Record download\n  * network boot\n  * ATA disk / SCSI ... boot\n- create ARMBoot project (https://sourceforge.net/projects/armboot)\n- add other CPU families (starting with ARM)\n- create U-Boot project (https://sourceforge.net/projects/u-boot)\n- current project page: see https://www.denx.de/wiki/U-Boot\n\n\nNames and Spelling:\n===================\n\nThe \"official\" name of this project is \"Das U-Boot\". The spelling\n\"U-Boot\" shall be used in all written text (documentation, comments\nin source files etc.). Example:\n\n\tThis is the README file for the U-Boot project.\n\nFile names etc. shall be based on the string \"u-boot\". Examples:\n\n\tinclude/asm-ppc/u-boot.h\n\n\t#include <asm/u-boot.h>\n\nVariable names, preprocessor constants etc. shall be either based on\nthe string \"u_boot\" or on \"U_BOOT\". Example:\n\n\tU_BOOT_VERSION\t\tu_boot_logo\n\tIH_OS_U_BOOT\t\tu_boot_hush_start\n\n\nSoftware Configuration:\n=======================\n\nSelection of Processor Architecture and Board Type:\n---------------------------------------------------\n\nFor all supported boards there are ready-to-use default\nconfigurations available; just type \"make <board_name>_defconfig\".\n\nExample: For a TQM823L module type:\n\n\tcd u-boot\n\tmake TQM823L_defconfig\n\nNote: If you're looking for the default configuration file for a board\nyou're sure used to be there but is now missing, check the file\ndoc/README.scrapyard for a list of no longer supported boards.\n\nSandbox Environment:\n--------------------\n\nU-Boot can be built natively to run on a Linux host using the 'sandbox'\nboard. This allows feature development which is not board- or architecture-\nspecific to be undertaken on a native platform. The sandbox is also used to\nrun some of U-Boot's tests.\n\nSee doc/arch/sandbox/sandbox.rst for more details.\n\nThe following options need to be configured:\n\n- CPU Type:\tDefine exactly one, e.g. CONFIG_MPC85XX.\n\n- Board Type:\tDefine exactly one, e.g. CONFIG_MPC8540ADS.\n\n- 85xx CPU Options:\n\t\tCONFIG_SYS_PPC64\n\n\t\tSpecifies that the core is a 64-bit PowerPC implementation (implements\n\t\tthe \"64\" category of the Power ISA). This is necessary for ePAPR\n\t\tcompliance, among other possible reasons.\n\n\t\tCONFIG_SYS_FSL_ERRATUM_A004510\n\n\t\tEnables a workaround for erratum A004510.  If set,\n\t\tthen CONFIG_SYS_FSL_ERRATUM_A004510_SVR_REV and\n\t\tCFG_SYS_FSL_CORENET_SNOOPVEC_COREONLY must be set.\n\n\t\tCONFIG_SYS_FSL_ERRATUM_A004510_SVR_REV\n\t\tCONFIG_SYS_FSL_ERRATUM_A004510_SVR_REV2 (optional)\n\n\t\tDefines one or two SoC revisions (low 8 bits of SVR)\n\t\tfor which the A004510 workaround should be applied.\n\n\t\tThe rest of SVR is either not relevant to the decision\n\t\tof whether the erratum is present (e.g. p2040 versus\n\t\tp2041) or is implied by the build target, which controls\n\t\twhether CONFIG_SYS_FSL_ERRATUM_A004510 is set.\n\n\t\tSee Freescale App Note 4493 for more information about\n\t\tthis erratum.\n\n\t\tCFG_SYS_FSL_CORENET_SNOOPVEC_COREONLY\n\n\t\tThis is the value to write into CCSR offset 0x18600\n\t\taccording to the A004510 workaround.\n\n\t\tCONFIG_SYS_FSL_SINGLE_SOURCE_CLK\n\t\tSingle Source Clock is clocking mode present in some of FSL SoC's.\n\t\tIn this mode, a single differential clock is used to supply\n\t\tclocks to the sysclock, ddrclock and usbclock.\n\n- Generic CPU options:\n\n\t\tCONFIG_SYS_FSL_DDR\n\t\tFreescale DDR driver in use. This type of DDR controller is\n\t\tfound in mpc83xx, mpc85xx as well as some ARM core SoCs.\n\n\t\tCFG_SYS_FSL_DDR_ADDR\n\t\tFreescale DDR memory-mapped register base.\n\n\t\tCONFIG_SYS_FSL_IFC_CLK_DIV\n\t\tDefines divider of platform clock(clock input to IFC controller).\n\n\t\tCONFIG_SYS_FSL_LBC_CLK_DIV\n\t\tDefines divider of platform clock(clock input to eLBC controller).\n\n\t\tCFG_SYS_FSL_DDR_SDRAM_BASE_PHY\n\t\tPhysical address from the view of DDR controllers. It is the\n\t\tsame as CFG_SYS_DDR_SDRAM_BASE for  all Power SoCs. But\n\t\tit could be different for ARM SoCs.\n\n- ARM options:\n\t\tCFG_SYS_EXCEPTION_VECTORS_HIGH\n\n\t\tSelect high exception vectors of the ARM core, e.g., do not\n\t\tclear the V bit of the c1 register of CP15.\n\n\t\tCOUNTER_FREQUENCY\n\t\tGeneric timer clock source frequency.\n\n\t\tCOUNTER_FREQUENCY_REAL\n\t\tGeneric timer clock source frequency if the real clock is\n\t\tdifferent from COUNTER_FREQUENCY, and can only be determined\n\t\tat run time.\n\n- Linux Kernel Interface:\n\t\tCONFIG_OF_LIBFDT\n\n\t\tNew kernel versions are expecting firmware settings to be\n\t\tpassed using flattened device trees (based on open firmware\n\t\tconcepts).\n\n\t\tCONFIG_OF_LIBFDT\n\t\t * New libfdt-based support\n\t\t * Adds the \"fdt\" command\n\t\t * The bootm command automatically updates the fdt\n\n\t\tOF_TBCLK - The timebase frequency.\n\n\t\tboards with QUICC Engines require OF_QE to set UCC MAC\n\t\taddresses\n\n\t\tCONFIG_OF_IDE_FIXUP\n\n\t\tU-Boot can detect if an IDE device is present or not.\n\t\tIf not, and this new config option is activated, U-Boot\n\t\tremoves the ATA node from the DTS before booting Linux,\n\t\tso the Linux IDE driver does not probe the device and\n\t\tcrash. This is needed for buggy hardware (uc101) where\n\t\tno pull down resistor is connected to the signal IDE5V_DD7.\n\n- vxWorks boot parameters:\n\n\t\tbootvx constructs a valid bootline using the following\n\t\tenvironments variables: bootdev, bootfile, ipaddr, netmask,\n\t\tserverip, gatewayip, hostname, othbootargs.\n\t\tIt loads the vxWorks image pointed bootfile.\n\n\t\tNote: If a \"bootargs\" environment is defined, it will override\n\t\tthe defaults discussed just above.\n\n- Cache Configuration for ARM:\n\t\tCFG_SYS_PL310_BASE - Physical base address of PL310\n\t\t\t\t\tcontroller register space\n\n- Serial Ports:\n\t\tCFG_PL011_CLOCK\n\n\t\tIf you have Amba PrimeCell PL011 UARTs, set this variable to\n\t\tthe clock speed of the UARTs.\n\n\t\tCFG_PL01x_PORTS\n\n\t\tIf you have Amba PrimeCell PL010 or PL011 UARTs on your board,\n\t\tdefine this to a list of base addresses for each (supported)\n\t\tport. See e.g. include/configs/versatile.h\n\n\t\tCONFIG_SERIAL_HW_FLOW_CONTROL\n\n\t\tDefine this variable to enable hw flow control in serial driver.\n\t\tCurrent user of this option is drivers/serial/nsl16550.c driver\n\n- Removal of commands\n\t\tIf no commands are needed to boot, you can disable\n\t\tCONFIG_CMDLINE to remove them. In this case, the command line\n\t\twill not be available, and when U-Boot wants to execute the\n\t\tboot command (on start-up) it will call board_run_command()\n\t\tinstead. This can reduce image size significantly for very\n\t\tsimple boot procedures.\n\n- Regular expression support:\n\t\tCONFIG_REGEX\n\t\tIf this variable is defined, U-Boot is linked against\n\t\tthe SLRE (Super Light Regular Expression) library,\n\t\twhich adds regex support to some commands, as for\n\t\texample \"env grep\" and \"setexpr\".\n\n- Watchdog:\n\t\tCFG_SYS_WATCHDOG_FREQ\n\t\tSome platforms automatically call WATCHDOG_RESET()\n\t\tfrom the timer interrupt handler every\n\t\tCFG_SYS_WATCHDOG_FREQ interrupts. If not set by the\n\t\tboard configuration file, a default of CONFIG_SYS_HZ/2\n\t\t(i.e. 500) is used. Setting CFG_SYS_WATCHDOG_FREQ\n\t\tto 0 disables calling WATCHDOG_RESET() from the timer\n\t\tinterrupt.\n\n- GPIO Support:\n\t\tThe CFG_SYS_I2C_PCA953X_WIDTH option specifies a list of\n\t\tchip-ngpio pairs that tell the PCA953X driver the number of\n\t\tpins supported by a particular chip.\n\n\t\tNote that if the GPIO device uses I2C, then the I2C interface\n\t\tmust also be configured. See I2C Support, below.\n\n- Timestamp Support:\n\n\t\tWhen CONFIG_TIMESTAMP is selected, the timestamp\n\t\t(date and time) of an image is printed by image\n\t\tcommands like bootm or iminfo. This option is\n\t\tautomatically enabled when you select CONFIG_CMD_DATE .\n\n- Partition Labels (disklabels) Supported:\n\t\tZero or more of the following:\n\t\tCONFIG_MAC_PARTITION   Apple's MacOS partition table.\n\t\tCONFIG_ISO_PARTITION   ISO partition table, used on CDROM etc.\n\t\tCONFIG_EFI_PARTITION   GPT partition table, common when EFI is the\n\t\t\t\t       bootloader.  Note 2TB partition limit; see\n\t\t\t\t       disk/part_efi.c\n\t\tCONFIG_SCSI) you must configure support for at\n\t\tleast one non-MTD partition type as well.\n\n- NETWORK Support (PCI):\n\t\tCONFIG_E1000_SPI\n\t\tUtility code for direct access to the SPI bus on Intel 8257x.\n\t\tThis does not do anything useful unless you set at least one\n\t\tof CONFIG_CMD_E1000 or CONFIG_E1000_SPI_GENERIC.\n\n\t\tCONFIG_NATSEMI\n\t\tSupport for National dp83815 chips.\n\n\t\tCONFIG_NS8382X\n\t\tSupport for National dp8382[01] gigabit chips.\n\n- NETWORK Support (other):\n\t\tCONFIG_CALXEDA_XGMAC\n\t\tSupport for the Calxeda XGMAC device\n\n\t\tCONFIG_LAN91C96\n\t\tSupport for SMSC's LAN91C96 chips.\n\n\t\t\tCONFIG_LAN91C96_USE_32_BIT\n\t\t\tDefine this to enable 32 bit addressing\n\n\t\t\tCFG_SYS_DAVINCI_EMAC_PHY_COUNT\n\t\t\tDefine this if you have more then 3 PHYs.\n\n\t\tCONFIG_FTGMAC100\n\t\tSupport for Faraday's FTGMAC100 Gigabit SoC Ethernet\n\n\t\t\tCONFIG_FTGMAC100_EGIGA\n\t\t\tDefine this to use GE link update with gigabit PHY.\n\t\t\tDefine this if FTGMAC100 is connected to gigabit PHY.\n\t\t\tIf your system has 10/100 PHY only, it might not occur\n\t\t\twrong behavior. Because PHY usually return timeout or\n\t\t\tuseless data when polling gigabit status and gigabit\n\t\t\tcontrol registers. This behavior won't affect the\n\t\t\tcorrectnessof 10/100 link speed update.\n\n\t\tCONFIG_SH_ETHER\n\t\tSupport for Renesas on-chip Ethernet controller\n\n- TPM Support:\n\t\tCONFIG_TPM\n\t\tSupport TPM devices.\n\n\t\tCONFIG_TPM_TIS_INFINEON\n\t\tSupport for Infineon i2c bus TPM devices. Only one device\n\t\tper system is supported at this time.\n\n\t\t\tCONFIG_TPM_TIS_I2C_BURST_LIMITATION\n\t\t\tDefine the burst count bytes upper limit\n\n\t\tCONFIG_TPM_ATMEL_TWI\n\t\tSupport for Atmel TWI TPM device. Requires I2C support.\n\n\t\tCONFIG_TPM_TIS_LPC\n\t\tSupport for generic parallel port TPM devices. Only one device\n\t\tper system is supported at this time.\n\n\t\tCONFIG_TPM\n\t\tDefine this to enable the TPM support library which provides\n\t\tfunctional interfaces to some TPM commands.\n\t\tRequires support for a TPM device.\n\n\t\tCONFIG_TPM_AUTH_SESSIONS\n\t\tDefine this to enable authorized functions in the TPM library.\n\t\tRequires CONFIG_TPM and CONFIG_SHA1.\n\n- USB Support:\n\t\tAt the moment only the UHCI host controller is\n\t\tsupported (PIP405, MIP405); define\n\t\tCONFIG_USB_UHCI to enable it.\n\t\tdefine CONFIG_USB_KEYBOARD to enable the USB Keyboard\n\t\tand define CONFIG_USB_STORAGE to enable the USB\n\t\tstorage devices.\n\t\tNote:\n\t\tSupported are USB Keyboards and USB Floppy drives\n\t\t(TEAC FD-05PUB).\n\n\t\tCONFIG_USB_DWC2_REG_ADDR the physical CPU address of the DWC2\n\t\tHW module registers.\n\n- USB Device:\n\t\tDefine the below if you wish to use the USB console.\n\t\tOnce firmware is rebuilt from a serial console issue the\n\t\tcommand \"setenv stdin usbtty; setenv stdout usbtty\" and\n\t\tattach your USB cable. The Unix command \"dmesg\" should print\n\t\tit has found a new device. The environment variable usbtty\n\t\tcan be set to gserial or cdc_acm to enable your device to\n\t\tappear to a USB host as a Linux gserial device or a\n\t\tCommon Device Class Abstract Control Model serial device.\n\t\tIf you select usbtty = gserial you should be able to enumerate\n\t\ta Linux host by\n\t\t# modprobe usbserial vendor=0xVendorID product=0xProductID\n\t\telse if using cdc_acm, simply setting the environment\n\t\tvariable usbtty to be cdc_acm should suffice. The following\n\t\tmight be defined in YourBoardName.h\n\n\t\tIf you have a USB-IF assigned VendorID then you may wish to\n\t\tdefine your own vendor specific values either in BoardName.h\n\t\tor directly in usbd_vendor_info.h. If you don't define\n\t\tCONFIG_USBD_MANUFACTURER, CONFIG_USBD_PRODUCT_NAME,\n\t\tCONFIG_USBD_VENDORID and CONFIG_USBD_PRODUCTID, then U-Boot\n\t\tshould pretend to be a Linux device to it's target host.\n\n\t\t\tCONFIG_USBD_MANUFACTURER\n\t\t\tDefine this string as the name of your company for\n\t\t\t- CONFIG_USBD_MANUFACTURER \"my company\"\n\n\t\t\tCONFIG_USBD_PRODUCT_NAME\n\t\t\tDefine this string as the name of your product\n\t\t\t- CONFIG_USBD_PRODUCT_NAME \"acme usb device\"\n\n\t\t\tCONFIG_USBD_VENDORID\n\t\t\tDefine this as your assigned Vendor ID from the USB\n\t\t\tImplementors Forum. This *must* be a genuine Vendor ID\n\t\t\tto avoid polluting the USB namespace.\n\t\t\t- CONFIG_USBD_VENDORID 0xFFFF\n\n\t\t\tCONFIG_USBD_PRODUCTID\n\t\t\tDefine this as the unique Product ID\n\t\t\tfor your device\n\t\t\t- CONFIG_USBD_PRODUCTID 0xFFFF\n\n- MMC Support:\n\t\tCONFIG_SH_MMCIF\n\t\tSupport for Renesas on-chip MMCIF controller\n\n\t\t\tCONFIG_SH_MMCIF_ADDR\n\t\t\tDefine the base address of MMCIF registers\n\n\t\t\tCONFIG_SH_MMCIF_CLK\n\t\t\tDefine the clock frequency for MMCIF\n\n- USB Device Firmware Update (DFU) class support:\n\t\tCONFIG_DFU_OVER_USB\n\t\tThis enables the USB portion of the DFU USB class\n\n\t\tCONFIG_DFU_NAND\n\t\tThis enables support for exposing NAND devices via DFU.\n\n\t\tCONFIG_DFU_RAM\n\t\tThis enables support for exposing RAM via DFU.\n\t\tNote: DFU spec refer to non-volatile memory usage, but\n\t\tallow usages beyond the scope of spec - here RAM usage,\n\t\tone that would help mostly the developer.\n\n\t\tCONFIG_SYS_DFU_DATA_BUF_SIZE\n\t\tDfu transfer uses a buffer before writing data to the\n\t\traw storage device. Make the size (in bytes) of this buffer\n\t\tconfigurable. The size of this buffer is also configurable\n\t\tthrough the \"dfu_bufsiz\" environment variable.\n\n\t\tCONFIG_SYS_DFU_MAX_FILE_SIZE\n\t\tWhen updating files rather than the raw storage device,\n\t\twe use a static buffer to copy the file into and then write\n\t\tthe buffer once we've been given the whole file.  Define\n\t\tthis to the maximum filesize (in bytes) for the buffer.\n\t\tDefault is 4 MiB if undefined.\n\n\t\tDFU_DEFAULT_POLL_TIMEOUT\n\t\tPoll timeout [ms], is the timeout a device can send to the\n\t\thost. The host must wait for this timeout before sending\n\t\ta subsequent DFU_GET_STATUS request to the device.\n\n\t\tDFU_MANIFEST_POLL_TIMEOUT\n\t\tPoll timeout [ms], which the device sends to the host when\n\t\tentering dfuMANIFEST state. Host waits this timeout, before\n\t\tsending again an USB request to the device.\n\n- Keyboard Support:\n\t\tSee Kconfig help for available keyboard drivers.\n\n- MII/PHY support:\n\t\tCONFIG_PHY_CLOCK_FREQ (ppc4xx)\n\n\t\tThe clock frequency of the MII bus\n\n\t\tCONFIG_PHY_CMD_DELAY (ppc4xx)\n\n\t\tSome PHY like Intel LXT971A need extra delay after\n\t\tcommand issued before MII status register can be read\n\n- BOOTP Recovery Mode:\n\t\tCONFIG_BOOTP_RANDOM_DELAY\n\n\t\tIf you have many targets in a network that try to\n\t\tboot using BOOTP, you may want to avoid that all\n\t\tsystems send out BOOTP requests at precisely the same\n\t\tmoment (which would happen for instance at recovery\n\t\tfrom a power failure, when all systems will try to\n\t\tboot, thus flooding the BOOTP server. Defining\n\t\tCONFIG_BOOTP_RANDOM_DELAY causes a random delay to be\n\t\tinserted before sending out BOOTP requests. The\n\t\tfollowing delays are inserted then:\n\n\t\t1st BOOTP request:\tdelay 0 ... 1 sec\n\t\t2nd BOOTP request:\tdelay 0 ... 2 sec\n\t\t3rd BOOTP request:\tdelay 0 ... 4 sec\n\t\t4th and following\n\t\tBOOTP requests:\t\tdelay 0 ... 8 sec\n\n\t\tCFG_BOOTP_ID_CACHE_SIZE\n\n\t\tBOOTP packets are uniquely identified using a 32-bit ID. The\n\t\tserver will copy the ID from client requests to responses and\n\t\tU-Boot will use this to determine if it is the destination of\n\t\tan incoming response. Some servers will check that addresses\n\t\taren't in use before handing them out (usually using an ARP\n\t\tping) and therefore take up to a few hundred milliseconds to\n\t\trespond. Network congestion may also influence the time it\n\t\ttakes for a response to make it back to the client. If that\n\t\ttime is too long, U-Boot will retransmit requests. In order\n\t\tto allow earlier responses to still be accepted after these\n\t\tretransmissions, U-Boot's BOOTP client keeps a small cache of\n\t\tIDs. The CFG_BOOTP_ID_CACHE_SIZE controls the size of this\n\t\tcache. The default is to keep IDs for up to four outstanding\n\t\trequests. Increasing this will allow U-Boot to accept offers\n\t\tfrom a BOOTP client in networks with unusually high latency.\n\n- DHCP Advanced Options:\n\n - Link-local IP address negotiation:\n\t\tNegotiate with other link-local clients on the local network\n\t\tfor an address that doesn't require explicit configuration.\n\t\tThis is especially useful if a DHCP server cannot be guaranteed\n\t\tto exist in all environments that the device must operate.\n\n\t\tSee doc/README.link-local for more information.\n\n - MAC address from environment variables\n\n\t\tFDT_SEQ_MACADDR_FROM_ENV\n\n\t\tFix-up device tree with MAC addresses fetched sequentially from\n\t\tenvironment variables. This config work on assumption that\n\t\tnon-usable ethernet node of device-tree are either not present\n\t\tor their status has been marked as \"disabled\".\n\n - CDP Options:\n\t\tCONFIG_CDP_DEVICE_ID\n\n\t\tThe device id used in CDP trigger frames.\n\n\t\tCONFIG_CDP_DEVICE_ID_PREFIX\n\n\t\tA two character string which is prefixed to the MAC address\n\t\tof the device.\n\n\t\tCONFIG_CDP_PORT_ID\n\n\t\tA printf format string which contains the ascii name of\n\t\tthe port. Normally is set to \"eth%d\" which sets\n\t\teth0 for the first Ethernet, eth1 for the second etc.\n\n\t\tCONFIG_CDP_CAPABILITIES\n\n\t\tA 32bit integer which indicates the device capabilities;\n\t\t0x00000010 for a normal host which does not forwards.\n\n\t\tCONFIG_CDP_VERSION\n\n\t\tAn ascii string containing the version of the software.\n\n\t\tCONFIG_CDP_PLATFORM\n\n\t\tAn ascii string containing the name of the platform.\n\n\t\tCONFIG_CDP_TRIGGER\n\n\t\tA 32bit integer sent on the trigger.\n\n\t\tCONFIG_CDP_POWER_CONSUMPTION\n\n\t\tA 16bit integer containing the power consumption of the\n\t\tdevice in .1 of milliwatts.\n\n\t\tCONFIG_CDP_APPLIANCE_VLAN_TYPE\n\n\t\tA byte containing the id of the VLAN.\n\n- Status LED:\tCONFIG_LED_STATUS\n\n\t\tSeveral configurations allow to display the current\n\t\tstatus using a LED. For instance, the LED will blink\n\t\tfast while running U-Boot code, stop blinking as\n\t\tsoon as a reply to a BOOTP request was received, and\n\t\tstart blinking slow once the Linux kernel is running\n\t\t(supported by a status LED driver in the Linux\n\t\tkernel). Defining CONFIG_LED_STATUS enables this\n\t\tfeature in U-Boot.\n\n\t\tAdditional options:\n\n\t\tCONFIG_LED_STATUS_GPIO\n\t\tThe status LED can be connected to a GPIO pin.\n\t\tIn such cases, the gpio_led driver can be used as a\n\t\tstatus LED backend implementation. Define CONFIG_LED_STATUS_GPIO\n\t\tto include the gpio_led driver in the U-Boot binary.\n\n\t\tCFG_GPIO_LED_INVERTED_TABLE\n\t\tSome GPIO connected LEDs may have inverted polarity in which\n\t\tcase the GPIO high value corresponds to LED off state and\n\t\tGPIO low value corresponds to LED on state.\n\t\tIn such cases CFG_GPIO_LED_INVERTED_TABLE may be defined\n\t\twith a list of GPIO LEDs that have inverted polarity.\n\n- I2C Support:\n\t\tCFG_SYS_NUM_I2C_BUSES\n\t\tHold the number of i2c buses you want to use.\n\n\t\tCFG_SYS_I2C_BUSES\n\t\thold a list of buses you want to use\n\n\t\t CFG_SYS_I2C_BUSES\t{{0, {I2C_NULL_HOP}}, \\\n\t\t\t\t\t{0, {{I2C_MUX_PCA9547, 0x70, 1}}}, \\\n\t\t\t\t\t{0, {{I2C_MUX_PCA9547, 0x70, 2}}}, \\\n\t\t\t\t\t{0, {{I2C_MUX_PCA9547, 0x70, 3}}}, \\\n\t\t\t\t\t{0, {{I2C_MUX_PCA9547, 0x70, 4}}}, \\\n\t\t\t\t\t{0, {{I2C_MUX_PCA9547, 0x70, 5}}}, \\\n\t\t\t\t\t{1, {I2C_NULL_HOP}}, \\\n\t\t\t\t\t{1, {{I2C_MUX_PCA9544, 0x72, 1}}}, \\\n\t\t\t\t\t{1, {{I2C_MUX_PCA9544, 0x72, 2}}}, \\\n\t\t\t\t\t}\n\n\t\twhich defines\n\t\t\tbus 0 on adapter 0 without a mux\n\t\t\tbus 1 on adapter 0 with a PCA9547 on address 0x70 port 1\n\t\t\tbus 2 on adapter 0 with a PCA9547 on address 0x70 port 2\n\t\t\tbus 3 on adapter 0 with a PCA9547 on address 0x70 port 3\n\t\t\tbus 4 on adapter 0 with a PCA9547 on address 0x70 port 4\n\t\t\tbus 5 on adapter 0 with a PCA9547 on address 0x70 port 5\n\t\t\tbus 6 on adapter 1 without a mux\n\t\t\tbus 7 on adapter 1 with a PCA9544 on address 0x72 port 1\n\t\t\tbus 8 on adapter 1 with a PCA9544 on address 0x72 port 2\n\n\t\tIf you do not have i2c muxes on your board, omit this define.\n\n- Legacy I2C Support:\n\t\tIf you use the software i2c interface (CONFIG_SYS_I2C_SOFT)\n\t\tthen the following macros need to be defined (examples are\n\t\tfrom include/configs/lwmon.h):\n\n\t\tI2C_INIT\n\n\t\t(Optional). Any commands necessary to enable the I2C\n\t\tcontroller or configure ports.\n\n\t\teg: #define I2C_INIT (immr->im_cpm.cp_pbdir |=\tPB_SCL)\n\n\t\tI2C_ACTIVE\n\n\t\tThe code necessary to make the I2C data line active\n\t\t(driven).  If the data line is open collector, this\n\t\tdefine can be null.\n\n\t\teg: #define I2C_ACTIVE (immr->im_cpm.cp_pbdir |=  PB_SDA)\n\n\t\tI2C_TRISTATE\n\n\t\tThe code necessary to make the I2C data line tri-stated\n\t\t(inactive).  If the data line is open collector, this\n\t\tdefine can be null.\n\n\t\teg: #define I2C_TRISTATE (immr->im_cpm.cp_pbdir &= ~PB_SDA)\n\n\t\tI2C_READ\n\n\t\tCode that returns true if the I2C data line is high,\n\t\tfalse if it is low.\n\n\t\teg: #define I2C_READ ((immr->im_cpm.cp_pbdat & PB_SDA) != 0)\n\n\t\tI2C_SDA(bit)\n\n\t\tIf <bit> is true, sets the I2C data line high. If it\n\t\tis false, it clears it (low).\n\n\t\teg: #define I2C_SDA(bit) \\\n\t\t\tif(bit) immr->im_cpm.cp_pbdat |=  PB_SDA; \\\n\t\t\telse\timmr->im_cpm.cp_pbdat &= ~PB_SDA\n\n\t\tI2C_SCL(bit)\n\n\t\tIf <bit> is true, sets the I2C clock line high. If it\n\t\tis false, it clears it (low).\n\n\t\teg: #define I2C_SCL(bit) \\\n\t\t\tif(bit) immr->im_cpm.cp_pbdat |=  PB_SCL; \\\n\t\t\telse\timmr->im_cpm.cp_pbdat &= ~PB_SCL\n\n\t\tI2C_DELAY\n\n\t\tThis delay is invoked four times per clock cycle so this\n\t\tcontrols the rate of data transfer.  The data rate thus\n\t\tis 1 / (I2C_DELAY * 4). Often defined to be something\n\t\tlike:\n\n\t\t#define I2C_DELAY  udelay(2)\n\n\t\tCONFIG_SOFT_I2C_GPIO_SCL / CONFIG_SOFT_I2C_GPIO_SDA\n\n\t\tIf your arch supports the generic GPIO framework (asm/gpio.h),\n\t\tthen you may alternatively define the two GPIOs that are to be\n\t\tused as SCL / SDA.  Any of the previous I2C_xxx macros will\n\t\thave GPIO-based defaults assigned to them as appropriate.\n\n\t\tYou should define these to the GPIO value as given directly to\n\t\tthe generic GPIO functions.\n\n\t\tCFG_SYS_I2C_NOPROBES\n\n\t\tThis option specifies a list of I2C devices that will be skipped\n\t\twhen the 'i2c probe' command is issued.\n\n\t\te.g.\n\t\t\t#define CFG_SYS_I2C_NOPROBES {0x50,0x68}\n\n\t\twill skip addresses 0x50 and 0x68 on a board with one I2C bus\n\n\t\tCONFIG_SOFT_I2C_READ_REPEATED_START\n\n\t\tdefining this will force the i2c_read() function in\n\t\tthe soft_i2c driver to perform an I2C repeated start\n\t\tbetween writing the address pointer and reading the\n\t\tdata.  If this define is omitted the default behaviour\n\t\tof doing a stop-start sequence will be used.  Most I2C\n\t\tdevices can use either method, but some require one or\n\t\tthe other.\n\n- SPI Support:\tCONFIG_SPI\n\n\t\tEnables SPI driver (so far only tested with\n\t\tSPI EEPROM, also an instance works with Crystal A/D and\n\t\tD/As on the SACSng board)\n\n\t\tCFG_SYS_SPI_MXC_WAIT\n\t\tTimeout for waiting until spi transfer completed.\n\t\tdefault: (CONFIG_SYS_HZ/100)     /* 10 ms */\n\n- FPGA Support: CONFIG_FPGA\n\n\t\tEnables FPGA subsystem.\n\n\t\tCONFIG_FPGA_<vendor>\n\n\t\tEnables support for specific chip vendors.\n\t\t(ALTERA, XILINX)\n\n\t\tCONFIG_FPGA_<family>\n\n\t\tEnables support for FPGA family.\n\t\t(SPARTAN2, SPARTAN3, VIRTEX2, CYCLONE2, ACEX1K, ACEX)\n\n\t\tCONFIG_SYS_FPGA_CHECK_BUSY\n\n\t\tEnable checks on FPGA configuration interface busy\n\t\tstatus by the configuration function. This option\n\t\twill require a board or device specific function to\n\t\tbe written.\n\n\t\tCFG_FPGA_DELAY\n\n\t\tIf defined, a function that provides delays in the FPGA\n\t\tconfiguration driver.\n\n\t\tCFG_SYS_FPGA_CHECK_ERROR\n\n\t\tCheck for configuration errors during FPGA bitfile\n\t\tloading. For example, abort during Virtex II\n\t\tconfiguration if the INIT_B line goes low (which\n\t\tindicated a CRC error).\n\n\t\tCFG_SYS_FPGA_WAIT_INIT\n\n\t\tMaximum time to wait for the INIT_B line to de-assert\n\t\tafter PROB_B has been de-asserted during a Virtex II\n\t\tFPGA configuration sequence. The default time is 500\n\t\tms.\n\n\t\tCFG_SYS_FPGA_WAIT_BUSY\n\n\t\tMaximum time to wait for BUSY to de-assert during\n\t\tVirtex II FPGA configuration. The default is 5 ms.\n\n\t\tCFG_SYS_FPGA_WAIT_CONFIG\n\n\t\tTime to wait after FPGA configuration. The default is\n\t\t200 ms.\n\n- Vendor Parameter Protection:\n\n\t\tU-Boot considers the values of the environment\n\t\tvariables \"serial#\" (Board Serial Number) and\n\t\t\"ethaddr\" (Ethernet Address) to be parameters that\n\t\tare set once by the board vendor / manufacturer, and\n\t\tprotects these variables from casual modification by\n\t\tthe user. Once set, these variables are read-only,\n\t\tand write or delete attempts are rejected. You can\n\t\tchange this behaviour:\n\n\t\tIf CONFIG_ENV_OVERWRITE is #defined in your config\n\t\tfile, the write protection for vendor parameters is\n\t\tcompletely disabled. Anybody can change or delete\n\t\tthese parameters.\n\n\t\tThe same can be accomplished in a more flexible way\n\t\tfor any variable by configuring the type of access\n\t\tto allow for those variables in the \".flags\" variable\n\t\tor define CFG_ENV_FLAGS_LIST_STATIC.\n\n- Protected RAM:\n\t\tCFG_PRAM\n\n\t\tDefine this variable to enable the reservation of\n\t\t\"protected RAM\", i. e. RAM which is not overwritten\n\t\tby U-Boot. Define CFG_PRAM to hold the number of\n\t\tkB you want to reserve for pRAM. You can overwrite\n\t\tthis default value by defining an environment\n\t\tvariable \"pram\" to the number of kB you want to\n\t\treserve. Note that the board info structure will\n\t\tstill show the full amount of RAM. If pRAM is\n\t\treserved, a new environment variable \"mem\" will\n\t\tautomatically be defined to hold the amount of\n\t\tremaining RAM in a form that can be passed as boot\n\t\targument to Linux, for instance like that:\n\n\t\t\tsetenv bootargs ... mem=\\${mem}\n\t\t\tsaveenv\n\n\t\tThis way you can tell Linux not to use this memory,\n\t\teither, which results in a memory region that will\n\t\tnot be affected by reboots.\n\n\t\t*WARNING* If your board configuration uses automatic\n\t\tdetection of the RAM size, you must make sure that\n\t\tthis memory test is non-destructive. So far, the\n\t\tfollowing board configurations are known to be\n\t\t\"pRAM-clean\":\n\n\t\t\tIVMS8, IVML24, SPD8xx,\n\t\t\tHERMES, IP860, RPXlite, LWMON,\n\t\t\tFLAGADM\n\n- Error Recovery:\n\tNote:\n\n\t\tIn the current implementation, the local variables\n\t\tspace and global environment variables space are\n\t\tseparated. Local variables are those you define by\n\t\tsimply typing `name=value'. To access a local\n\t\tvariable later on, you have write `$name' or\n\t\t`${name}'; to execute the contents of a variable\n\t\tdirectly type `$name' at the command prompt.\n\n\t\tGlobal environment variables are those you use\n\t\tsetenv/printenv to work with. To run a command stored\n\t\tin such a variable, you need to use the run command,\n\t\tand you must not use the '$' sign to access them.\n\n\t\tTo store commands and special characters in a\n\t\tvariable, please use double quotation marks\n\t\tsurrounding the whole text of the variable, instead\n\t\tof the backslashes before semicolons and special\n\t\tsymbols.\n\n- Default Environment:\n\t\tCFG_EXTRA_ENV_SETTINGS\n\n\t\tDefine this to contain any number of null terminated\n\t\tstrings (variable = value pairs) that will be part of\n\t\tthe default environment compiled into the boot image.\n\n\t\tFor example, place something like this in your\n\t\tboard's config file:\n\n\t\t#define CFG_EXTRA_ENV_SETTINGS \\\n\t\t\t\"myvar1=value1\\0\" \\\n\t\t\t\"myvar2=value2\\0\"\n\n\t\tWarning: This method is based on knowledge about the\n\t\tinternal format how the environment is stored by the\n\t\tU-Boot code. This is NOT an official, exported\n\t\tinterface! Although it is unlikely that this format\n\t\twill change soon, there is no guarantee either.\n\t\tYou better know what you are doing here.\n\n\t\tNote: overly (ab)use of the default environment is\n\t\tdiscouraged. Make sure to check other ways to preset\n\t\tthe environment like the \"source\" command or the\n\t\tboot command first.\n\n- Automatic software updates via TFTP server\n\t\tCONFIG_UPDATE_TFTP\n\t\tCONFIG_UPDATE_TFTP_CNT_MAX\n\t\tCONFIG_UPDATE_TFTP_MSEC_MAX\n\n\t\tThese options enable and control the auto-update feature;\n\t\tfor a more detailed description refer to doc/README.update.\n\n- MTD Support (mtdparts command, UBI support)\n\t\tCONFIG_MTD_UBI_WL_THRESHOLD\n\t\tThis parameter defines the maximum difference between the highest\n\t\terase counter value and the lowest erase counter value of eraseblocks\n\t\tof UBI devices. When this threshold is exceeded, UBI starts performing\n\t\twear leveling by means of moving data from eraseblock with low erase\n\t\tcounter to eraseblocks with high erase counter.\n\n\t\tThe default value should be OK for SLC NAND flashes, NOR flashes and\n\t\tother flashes which have eraseblock life-cycle 100000 or more.\n\t\tHowever, in case of MLC NAND flashes which typically have eraseblock\n\t\tlife-cycle less than 10000, the threshold should be lessened (e.g.,\n\t\tto 128 or 256, although it does not have to be power of 2).\n\n\t\tdefault: 4096\n\n\t\tCONFIG_MTD_UBI_BEB_LIMIT\n\t\tThis option specifies the maximum bad physical eraseblocks UBI\n\t\texpects on the MTD device (per 1024 eraseblocks). If the\n\t\tunderlying flash does not admit of bad eraseblocks (e.g. NOR\n\t\tflash), this value is ignored.\n\n\t\tNAND datasheets often specify the minimum and maximum NVM\n\t\t(Number of Valid Blocks) for the flashes' endurance lifetime.\n\t\tThe maximum expected bad eraseblocks per 1024 eraseblocks\n\t\tthen can be calculated as \"1024 * (1 - MinNVB / MaxNVB)\",\n\t\twhich gives 20 for most NANDs (MaxNVB is basically the total\n\t\tcount of eraseblocks on the chip).\n\n\t\tTo put it differently, if this value is 20, UBI will try to\n\t\treserve about 1.9% of physical eraseblocks for bad blocks\n\t\thandling. And that will be 1.9% of eraseblocks on the entire\n\t\tNAND chip, not just the MTD partition UBI attaches. This means\n\t\tthat if you have, say, a NAND flash chip admits maximum 40 bad\n\t\teraseblocks, and it is split on two MTD partitions of the same\n\t\tsize, UBI will reserve 40 eraseblocks when attaching a\n\t\tpartition.\n\n\t\tdefault: 20\n\n\t\tCONFIG_MTD_UBI_FASTMAP\n\t\tFastmap is a mechanism which allows attaching an UBI device\n\t\tin nearly constant time. Instead of scanning the whole MTD device it\n\t\tonly has to locate a checkpoint (called fastmap) on the device.\n\t\tThe on-flash fastmap contains all information needed to attach\n\t\tthe device. Using fastmap makes only sense on large devices where\n\t\tattaching by scanning takes long. UBI will not automatically install\n\t\ta fastmap on old images, but you can set the UBI parameter\n\t\tCONFIG_MTD_UBI_FASTMAP_AUTOCONVERT to 1 if you want so. Please note\n\t\tthat fastmap-enabled images are still usable with UBI implementations\n\t\twithout\tfastmap support. On typical flash devices the whole fastmap\n\t\tfits into one PEB. UBI will reserve PEBs to hold two fastmaps.\n\n\t\tCONFIG_MTD_UBI_FASTMAP_AUTOCONVERT\n\t\tSet this parameter to enable fastmap automatically on images\n\t\twithout a fastmap.\n\t\tdefault: 0\n\n\t\tCONFIG_MTD_UBI_FM_DEBUG\n\t\tEnable UBI fastmap debug\n\t\tdefault: 0\n\n- SPL framework\n\t\tCONFIG_SPL\n\t\tEnable building of SPL globally.\n\n\t\tCONFIG_SPL_PANIC_ON_RAW_IMAGE\n\t\tWhen defined, SPL will panic() if the image it has\n\t\tloaded does not have a signature.\n\t\tDefining this is useful when code which loads images\n\t\tin SPL cannot guarantee that absolutely all read errors\n\t\twill be caught.\n\t\tAn example is the LPC32XX MLC NAND driver, which will\n\t\tconsider that a completely unreadable NAND block is bad,\n\t\tand thus should be skipped silently.\n\n\t\tCONFIG_SPL_DISPLAY_PRINT\n\t\tFor ARM, enable an optional function to print more information\n\t\tabout the running system.\n\n\t\tCONFIG_SPL_MPC83XX_WAIT_FOR_NAND\n\t\tSet this for NAND SPL on PPC mpc83xx targets, so that\n\t\tstart.S waits for the rest of the SPL to load before\n\t\tcontinuing (the hardware starts execution after just\n\t\tloading the first page rather than the full 4K).\n\n\t\tCONFIG_SPL_UBI\n\t\tSupport for a lightweight UBI (fastmap) scanner and\n\t\tloader\n\n\t\tCONFIG_SYS_NAND_5_ADDR_CYCLE, CONFIG_SYS_NAND_PAGE_SIZE,\n\t\tCONFIG_SYS_NAND_OOBSIZE, CONFIG_SYS_NAND_BLOCK_SIZE,\n\t\tCONFIG_SYS_NAND_BAD_BLOCK_POS, CFG_SYS_NAND_ECCPOS,\n\t\tCFG_SYS_NAND_ECCSIZE, CFG_SYS_NAND_ECCBYTES\n\t\tDefines the size and behavior of the NAND that SPL uses\n\t\tto read U-Boot\n\n\t\tCFG_SYS_NAND_U_BOOT_DST\n\t\tLocation in memory to load U-Boot to\n\n\t\tCFG_SYS_NAND_U_BOOT_SIZE\n\t\tSize of image to load\n\n\t\tCFG_SYS_NAND_U_BOOT_START\n\t\tEntry point in loaded image to jump to\n\n\t\tCONFIG_SPL_RAM_DEVICE\n\t\tSupport for running image already present in ram, in SPL binary\n\n\t\tCONFIG_SPL_FIT_PRINT\n\t\tPrinting information about a FIT image adds quite a bit of\n\t\tcode to SPL. So this is normally disabled in SPL. Use this\n\t\toption to re-enable it. This will affect the output of the\n\t\tbootm command when booting a FIT image.\n\n- Interrupt support (PPC):\n\n\t\tThere are common interrupt_init() and timer_interrupt()\n\t\tfor all PPC archs. interrupt_init() calls interrupt_init_cpu()\n\t\tfor CPU specific initialization. interrupt_init_cpu()\n\t\tshould set decrementer_count to appropriate value. If\n\t\tCPU resets decrementer automatically after interrupt\n\t\t(ppc4xx) it should set decrementer_count to zero.\n\t\ttimer_interrupt() calls timer_interrupt_cpu() for CPU\n\t\tspecific handling. If board has watchdog / status_led\n\t\t/ other_activity_monitor it works automatically from\n\t\tgeneral timer_interrupt().\n\n\nBoard initialization settings:\n------------------------------\n\nDuring Initialization u-boot calls a number of board specific functions\nto allow the preparation of board specific prerequisites, e.g. pin setup\nbefore drivers are initialized. To enable these callbacks the\nfollowing configuration macros have to be defined. Currently this is\narchitecture specific, so please check arch/your_architecture/lib/board.c\ntypically in board_init_f() and board_init_r().\n\n- CONFIG_BOARD_EARLY_INIT_F: Call board_early_init_f()\n- CONFIG_BOARD_EARLY_INIT_R: Call board_early_init_r()\n- CONFIG_BOARD_LATE_INIT: Call board_late_init()\n\nConfiguration Settings:\n-----------------------\n\n- CONFIG_SYS_LONGHELP: Defined when you want long help messages included;\n\t\tundefine this when you're short of memory.\n\n- CFG_SYS_HELP_CMD_WIDTH: Defined when you want to override the default\n\t\twidth of the commands listed in the 'help' command output.\n\n- CONFIG_SYS_PROMPT:\tThis is what U-Boot prints on the console to\n\t\tprompt for user input.\n\n- CFG_SYS_BAUDRATE_TABLE:\n\t\tList of legal baudrate settings for this board.\n\n- CFG_SYS_MEM_RESERVE_SECURE\n\t\tOnly implemented for ARMv8 for now.\n\t\tIf defined, the size of CFG_SYS_MEM_RESERVE_SECURE memory\n\t\tis substracted from total RAM and won't be reported to OS.\n\t\tThis memory can be used as secure memory. A variable\n\t\tgd->arch.secure_ram is used to track the location. In systems\n\t\tthe RAM base is not zero, or RAM is divided into banks,\n\t\tthis variable needs to be recalcuated to get the address.\n\n- CFG_SYS_SDRAM_BASE:\n\t\tPhysical start address of SDRAM. _Must_ be 0 here.\n\n- CFG_SYS_FLASH_BASE:\n\t\tPhysical start address of Flash memory.\n\n- CONFIG_SYS_MALLOC_LEN:\n\t\tSize of DRAM reserved for malloc() use.\n\n- CFG_SYS_BOOTMAPSZ:\n\t\tMaximum size of memory mapped by the startup code of\n\t\tthe Linux kernel; all data that must be processed by\n\t\tthe Linux kernel (bd_info, boot arguments, FDT blob if\n\t\tused) must be put below this limit, unless \"bootm_low\"\n\t\tenvironment variable is defined and non-zero. In such case\n\t\tall data for the Linux kernel must be between \"bootm_low\"\n\t\tand \"bootm_low\" + CFG_SYS_BOOTMAPSZ.\t The environment\n\t\tvariable \"bootm_mapsize\" will override the value of\n\t\tCFG_SYS_BOOTMAPSZ.  If CFG_SYS_BOOTMAPSZ is undefined,\n\t\tthen the value in \"bootm_size\" will be used instead.\n\n- CONFIG_SYS_BOOT_GET_CMDLINE:\n\t\tEnables allocating and saving kernel cmdline in space between\n\t\t\"bootm_low\" and \"bootm_low\" + BOOTMAPSZ.\n\n- CONFIG_SYS_BOOT_GET_KBD:\n\t\tEnables allocating and saving a kernel copy of the bd_info in\n\t\tspace between \"bootm_low\" and \"bootm_low\" + BOOTMAPSZ.\n\n- CONFIG_SYS_FLASH_PROTECTION\n\t\tIf defined, hardware flash sectors protection is used\n\t\tinstead of U-Boot software protection.\n\n- CONFIG_SYS_FLASH_CFI:\n\t\tDefine if the flash driver uses extra elements in the\n\t\tcommon flash structure for storing flash geometry.\n\n- CONFIG_FLASH_CFI_DRIVER\n\t\tThis option also enables the building of the cfi_flash driver\n\t\tin the drivers directory\n\n- CONFIG_FLASH_CFI_MTD\n\t\tThis option enables the building of the cfi_mtd driver\n\t\tin the drivers directory. The driver exports CFI flash\n\t\tto the MTD layer.\n\n- CONFIG_SYS_FLASH_USE_BUFFER_WRITE\n\t\tUse buffered writes to flash.\n\n- CONFIG_ENV_FLAGS_LIST_DEFAULT\n- CFG_ENV_FLAGS_LIST_STATIC\n\tEnable validation of the values given to environment variables when\n\tcalling env set.  Variables can be restricted to only decimal,\n\thexadecimal, or boolean.  If CONFIG_CMD_NET is also defined,\n\tthe variables can also be restricted to IP address or MAC address.\n\n\tThe format of the list is:\n\t\ttype_attribute = [s|d|x|b|i|m]\n\t\taccess_attribute = [a|r|o|c]\n\t\tattributes = type_attribute[access_attribute]\n\t\tentry = variable_name[:attributes]\n\t\tlist = entry[,list]\n\n\tThe type attributes are:\n\t\ts - String (default)\n\t\td - Decimal\n\t\tx - Hexadecimal\n\t\tb - Boolean ([1yYtT|0nNfF])\n\t\ti - IP address\n\t\tm - MAC address\n\n\tThe access attributes are:\n\t\ta - Any (default)\n\t\tr - Read-only\n\t\to - Write-once\n\t\tc - Change-default\n\n\t- CONFIG_ENV_FLAGS_LIST_DEFAULT\n\t\tDefine this to a list (string) to define the \".flags\"\n\t\tenvironment variable in the default or embedded environment.\n\n\t- CFG_ENV_FLAGS_LIST_STATIC\n\t\tDefine this to a list (string) to define validation that\n\t\tshould be done if an entry is not found in the \".flags\"\n\t\tenvironment variable.  To override a setting in the static\n\t\tlist, simply add an entry for the same variable name to the\n\t\t\".flags\" variable.\n\n\tIf CONFIG_REGEX is defined, the variable_name above is evaluated as a\n\tregular expression. This allows multiple variables to define the same\n\tflags without explicitly listing them for each variable.\n\nThe following definitions that deal with the placement and management\nof environment data (variable area); in general, we support the\nfollowing configurations:\n\nBE CAREFUL! The first access to the environment happens quite early\nin U-Boot initialization (when we try to get the setting of for the\nconsole baudrate). You *MUST* have mapped your NVRAM area then, or\nU-Boot will hang.\n\nPlease note that even with NVRAM we still use a copy of the\nenvironment in RAM: we could work on NVRAM directly, but we want to\nkeep settings there always unmodified except somebody uses \"saveenv\"\nto save the current settings.\n\nBE CAREFUL! For some special cases, the local device can not use\n\"saveenv\" command. For example, the local device will get the\nenvironment stored in a remote NOR flash by SRIO or PCIE link,\nbut it can not erase, write this NOR flash by SRIO or PCIE interface.\n\n- CONFIG_NAND_ENV_DST\n\n\tDefines address in RAM to which the nand_spl code should copy the\n\tenvironment. If redundant environment is used, it will be copied to\n\tCONFIG_NAND_ENV_DST + CONFIG_ENV_SIZE.\n\nPlease note that the environment is read-only until the monitor\nhas been relocated to RAM and a RAM copy of the environment has been\ncreated; also, when using EEPROM you will have to use env_get_f()\nuntil then to read environment variables.\n\nThe environment is protected by a CRC32 checksum. Before the monitor\nis relocated into RAM, as a result of a bad CRC you will be working\nwith the compiled-in default environment - *silently*!!! [This is\nnecessary, because the first environment variable we need is the\n\"baudrate\" setting for the console - if we have a bad CRC, we don't\nhave any device yet where we could complain.]\n\nNote: once the monitor has been relocated, then it will complain if\nthe default environment is used; a new CRC is computed as soon as you\nuse the \"saveenv\" command to store a valid environment.\n\n- CONFIG_DISPLAY_BOARDINFO\n\t\tDisplay information about the board that U-Boot is running on\n\t\twhen U-Boot starts up. The board function checkboard() is called\n\t\tto do this.\n\n- CONFIG_DISPLAY_BOARDINFO_LATE\n\t\tSimilar to the previous option, but display this information\n\t\tlater, once stdio is running and output goes to the LCD, if\n\t\tpresent.\n\nLow Level (hardware related) configuration options:\n---------------------------------------------------\n\n- CONFIG_SYS_CACHELINE_SIZE:\n\t\tCache Line Size of the CPU.\n\n- CONFIG_SYS_CCSRBAR_DEFAULT:\n\t\tDefault (power-on reset) physical address of CCSR on Freescale\n\t\tPowerPC SOCs.\n\n- CFG_SYS_CCSRBAR:\n\t\tVirtual address of CCSR.  On a 32-bit build, this is typically\n\t\tthe same value as CONFIG_SYS_CCSRBAR_DEFAULT.\n\n- CFG_SYS_CCSRBAR_PHYS:\n\t\tPhysical address of CCSR.  CCSR can be relocated to a new\n\t\tphysical address, if desired.  In this case, this macro should\n\t\tbe set to that address.\t Otherwise, it should be set to the\n\t\tsame value as CONFIG_SYS_CCSRBAR_DEFAULT.  For example, CCSR\n\t\tis typically relocated on 36-bit builds.  It is recommended\n\t\tthat this macro be defined via the _HIGH and _LOW macros:\n\n\t\t#define CFG_SYS_CCSRBAR_PHYS ((CFG_SYS_CCSRBAR_PHYS_HIGH\n\t\t\t* 1ull) << 32 | CFG_SYS_CCSRBAR_PHYS_LOW)\n\n- CFG_SYS_CCSRBAR_PHYS_HIGH:\n\t\tBits 33-36 of CFG_SYS_CCSRBAR_PHYS.\tThis value is typically\n\t\teither 0 (32-bit build) or 0xF (36-bit build).\tThis macro is\n\t\tused in assembly code, so it must not contain typecasts or\n\t\tinteger size suffixes (e.g. \"ULL\").\n\n- CFG_SYS_CCSRBAR_PHYS_LOW:\n\t\tLower 32-bits of CFG_SYS_CCSRBAR_PHYS.  This macro is\n\t\tused in assembly code, so it must not contain typecasts or\n\t\tinteger size suffixes (e.g. \"ULL\").\n\n- CONFIG_SYS_IMMR:\tPhysical address of the Internal Memory.\n\t\tDO NOT CHANGE unless you know exactly what you're\n\t\tdoing! (11-4) [MPC8xx systems only]\n\n- CFG_SYS_INIT_RAM_ADDR:\n\n\t\tStart address of memory area that can be used for\n\t\tinitial data and stack; please note that this must be\n\t\twritable memory that is working WITHOUT special\n\t\tinitialization, i. e. you CANNOT use normal RAM which\n\t\twill become available only after programming the\n\t\tmemory controller and running certain initialization\n\t\tsequences.\n\n\t\tU-Boot uses the following memory types:\n\t\t- MPC8xx: IMMR (internal memory of the CPU)\n\n- CONFIG_SYS_SCCR:\tSystem Clock and reset Control Register (15-27)\n\n- CONFIG_SYS_OR_TIMING_SDRAM:\n\t\tSDRAM timing\n\n- CONFIG_SYS_SRIOn_MEM_VIRT:\n\t\tVirtual Address of SRIO port 'n' memory region\n\n- CONFIG_SYS_SRIOn_MEM_PHYxS:\n\t\tPhysical Address of SRIO port 'n' memory region\n\n- CONFIG_SYS_SRIOn_MEM_SIZE:\n\t\tSize of SRIO port 'n' memory region\n\n- CONFIG_SYS_NAND_BUSWIDTH_16BIT\n\t\tDefined to tell the NAND controller that the NAND chip is using\n\t\ta 16 bit bus.\n\t\tNot all NAND drivers use this symbol.\n\t\tExample of drivers that use it:\n\t\t- drivers/mtd/nand/raw/ndfc.c\n\t\t- drivers/mtd/nand/raw/mxc_nand.c\n\n- CONFIG_SYS_NDFC_EBC0_CFG\n\t\tSets the EBC0_CFG register for the NDFC. If not defined\n\t\ta default value will be used.\n\n- CONFIG_SYS_SPD_BUS_NUM\n\t\tIf SPD EEPROM is on an I2C bus other than the first\n\t\tone, specify here. Note that the value must resolve\n\t\tto something your driver can deal with.\n\n- CONFIG_FSL_DDR_INTERACTIVE\n\t\tEnable interactive DDR debugging. See doc/README.fsl-ddr.\n\n- CONFIG_FSL_DDR_SYNC_REFRESH\n\t\tEnable sync of refresh for multiple controllers.\n\n- CONFIG_FSL_DDR_BIST\n\t\tEnable built-in memory test for Freescale DDR controllers.\n\n- CONFIG_RMII\n\t\tEnable RMII mode for all FECs.\n\t\tNote that this is a global option, we can't\n\t\thave one FEC in standard MII mode and another in RMII mode.\n\n- CONFIG_CRC32_VERIFY\n\t\tAdd a verify option to the crc32 command.\n\t\tThe syntax is:\n\n\t\t=> crc32 -v <address> <count> <crc32>\n\n\t\tWhere address/count indicate a memory area\n\t\tand crc32 is the correct crc32 which the\n\t\tarea should have.\n\n- CONFIG_LOOPW\n\t\tAdd the \"loopw\" memory command. This only takes effect if\n\t\tthe memory commands are activated globally (CONFIG_CMD_MEMORY).\n\n- CONFIG_CMD_MX_CYCLIC\n\t\tAdd the \"mdc\" and \"mwc\" memory commands. These are cyclic\n\t\t\"md/mw\" commands.\n\t\tExamples:\n\n\t\t=> mdc.b 10 4 500\n\t\tThis command will print 4 bytes (10,11,12,13) each 500 ms.\n\n\t\t=> mwc.l 100 12345678 10\n\t\tThis command will write 12345678 to address 100 all 10 ms.\n\n\t\tThis only takes effect if the memory commands are activated\n\t\tglobally (CONFIG_CMD_MEMORY).\n\n- CONFIG_XPL_BUILD\n\t\tSet when the currently running compilation is for an artifact\n\t\tthat will end up in one of the 'xPL' builds, i.e. SPL, TPL or\n\t\tVPL. Code that needs phase-specific behaviour can check this,\n\t\tor (where possible) use xpl_phase() instead.\n\n- CONFIG_TPL_BUILD\n\t\tSet when the currently running compilation is for an artifact\n\t\tthat will end up in the TPL build (as opposed to SPL, VPL or\n\t\tU-Boot proper). Code that needs phase-specific behaviour can\n\t\tcheck this, or (where possible) use xpl_phase() instead.\n\n- CONFIG_VPL_BUILD\n\t\tSet when the currently running compilation is for an artifact\n\t\tthat will end up in the VPL build (as opposed to the SPL, TPL\n\t\tor U-Boot proper). Code that needs phase-specific behaviour can\n\t\tcheck this, or (where possible) use xpl_phase() instead.\n\n- CONFIG_ARCH_MAP_SYSMEM\n\t\tGenerally U-Boot (and in particular the md command) uses\n\t\teffective address. It is therefore not necessary to regard\n\t\tU-Boot address as virtual addresses that need to be translated\n\t\tto physical addresses. However, sandbox requires this, since\n\t\tit maintains its own little RAM buffer which contains all\n\t\taddressable memory. This option causes some memory accesses\n\t\tto be mapped through map_sysmem() / unmap_sysmem().\n\n- CONFIG_X86_RESET_VECTOR\n\t\tIf defined, the x86 reset vector code is included. This is not\n\t\tneeded when U-Boot is running from Coreboot.\n\nFreescale QE/FMAN Firmware Support:\n-----------------------------------\n\nThe Freescale QUICCEngine (QE) and Frame Manager (FMAN) both support the\nloading of \"firmware\", which is encoded in the QE firmware binary format.\nThis firmware often needs to be loaded during U-Boot booting, so macros\nare used to identify the storage device (NOR flash, SPI, etc) and the address\nwithin that device.\n\n- CONFIG_SYS_FMAN_FW_ADDR\n\tThe address in the storage device where the FMAN microcode is located.  The\n\tmeaning of this address depends on which CONFIG_SYS_QE_FMAN_FW_IN_xxx macro\n\tis also specified.\n\n- CONFIG_SYS_QE_FW_ADDR\n\tThe address in the storage device where the QE microcode is located.  The\n\tmeaning of this address depends on which CONFIG_SYS_QE_FMAN_FW_IN_xxx macro\n\tis also specified.\n\n- CONFIG_SYS_QE_FMAN_FW_LENGTH\n\tThe maximum possible size of the firmware.  The firmware binary format\n\thas a field that specifies the actual size of the firmware, but it\n\tmight not be possible to read any part of the firmware unless some\n\tlocal storage is allocated to hold the entire firmware first.\n\n- CONFIG_SYS_QE_FMAN_FW_IN_NOR\n\tSpecifies that QE/FMAN firmware is located in NOR flash, mapped as\n\tnormal addressable memory via the LBC.  CONFIG_SYS_FMAN_FW_ADDR is the\n\tvirtual address in NOR flash.\n\n- CONFIG_SYS_QE_FMAN_FW_IN_NAND\n\tSpecifies that QE/FMAN firmware is located in NAND flash.\n\tCONFIG_SYS_FMAN_FW_ADDR is the offset within NAND flash.\n\n- CONFIG_SYS_QE_FMAN_FW_IN_MMC\n\tSpecifies that QE/FMAN firmware is located on the primary SD/MMC\n\tdevice.  CONFIG_SYS_FMAN_FW_ADDR is the byte offset on that device.\n\n- CONFIG_SYS_QE_FMAN_FW_IN_REMOTE\n\tSpecifies that QE/FMAN firmware is located in the remote (master)\n\tmemory space.\tCONFIG_SYS_FMAN_FW_ADDR is a virtual address which\n\tcan be mapped from slave TLB->slave LAW->slave SRIO or PCIE outbound\n\twindow->master inbound window->master LAW->the ucode address in\n\tmaster's memory space.\n\nFreescale Layerscape Management Complex Firmware Support:\n---------------------------------------------------------\nThe Freescale Layerscape Management Complex (MC) supports the loading of\n\"firmware\".\nThis firmware often needs to be loaded during U-Boot booting, so macros\nare used to identify the storage device (NOR flash, SPI, etc) and the address\nwithin that device.\n\n- CONFIG_FSL_MC_ENET\n\tEnable the MC driver for Layerscape SoCs.\n\nFreescale Layerscape Debug Server Support:\n-------------------------------------------\nThe Freescale Layerscape Debug Server Support supports the loading of\n\"Debug Server firmware\" and triggering SP boot-rom.\nThis firmware often needs to be loaded during U-Boot booting.\n\n- CONFIG_SYS_MC_RSV_MEM_ALIGN\n\tDefine alignment of reserved memory MC requires\n\n\nBuilding the Software:\n======================\n\nBuilding U-Boot has been tested in several native build environments\nand in many different cross environments. Of course we cannot support\nall possibly existing versions of cross development tools in all\n(potentially obsolete) versions. In case of tool chain problems we\nrecommend to use the ELDK (see https://www.denx.de/wiki/DULG/ELDK)\nwhich is extensively used to build and test U-Boot.\n\nIf you are not using a native environment, it is assumed that you\nhave GNU cross compiling tools available in your path. In this case,\nyou must set the environment variable CROSS_COMPILE in your shell.\nNote that no changes to the Makefile or any other source files are\nnecessary. For example using the ELDK on a 4xx CPU, please enter:\n\n\t$ CROSS_COMPILE=ppc_4xx-\n\t$ export CROSS_COMPILE\n\nU-Boot is intended to be simple to build. After installing the\nsources you must configure U-Boot for one specific board type. This\nis done by typing:\n\n\tmake NAME_defconfig\n\nwhere \"NAME_defconfig\" is the name of one of the existing configu-\nrations; see configs/*_defconfig for supported names.\n\nNote: for some boards special configuration names may exist; check if\n      additional information is available from the board vendor; for\n      instance, the TQM823L systems are available without (standard)\n      or with LCD support. You can select such additional \"features\"\n      when choosing the configuration, i. e.\n\n      make TQM823L_defconfig\n\t- will configure for a plain TQM823L, i. e. no LCD support\n\n      make TQM823L_LCD_defconfig\n\t- will configure for a TQM823L with U-Boot console on LCD\n\n      etc.\n\n\nFinally, type \"make all\", and you should get some working U-Boot\nimages ready for download to / installation on your system:\n\n- \"u-boot.bin\" is a raw binary image\n- \"u-boot\" is an image in ELF binary format\n- \"u-boot.srec\" is in Motorola S-Record format\n\nUser specific CPPFLAGS, AFLAGS and CFLAGS can be passed to the compiler by\nsetting the according environment variables KCPPFLAGS, KAFLAGS and KCFLAGS.\nFor example to treat all compiler warnings as errors:\n\n\tmake KCFLAGS=-Werror\n\nPlease be aware that the Makefiles assume you are using GNU make, so\nfor instance on NetBSD you might need to use \"gmake\" instead of\nnative \"make\".\n\n\nIf the system board that you have is not listed, then you will need\nto port U-Boot to your hardware platform. To do this, follow these\nsteps:\n\n1.  Create a new directory to hold your board specific code. Add any\n    files you need. In your board directory, you will need at least\n    the \"Makefile\" and a \"<board>.c\".\n2.  Create a new configuration file \"include/configs/<board>.h\" for\n    your board.\n3.  If you're porting U-Boot to a new CPU, then also create a new\n    directory to hold your CPU specific code. Add any files you need.\n4.  Run \"make <board>_defconfig\" with your new name.\n5.  Type \"make\", and you should get a working \"u-boot.srec\" file\n    to be installed on your target system.\n6.  Debug and solve any problems that might arise.\n    [Of course, this last step is much harder than it sounds.]\n\n\nTesting of U-Boot Modifications, Ports to New Hardware, etc.:\n==============================================================\n\nIf you have modified U-Boot sources (for instance added a new board\nor support for new devices, a new CPU, etc.) you are expected to\nprovide feedback to the other developers. The feedback normally takes\nthe form of a \"patch\", i.e. a context diff against a certain (latest\nofficial or latest in the git repository) version of U-Boot sources.\n\nBut before you submit such a patch, please verify that your modifi-\ncation did not break existing code. At least make sure that *ALL* of\nthe supported boards compile WITHOUT ANY compiler warnings. To do so,\njust run the buildman script (tools/buildman/buildman), which will\nconfigure and build U-Boot for ALL supported system. Be warned, this\nwill take a while. Please see the buildman README, or run 'buildman -H'\nfor documentation.\n\n\nSee also \"U-Boot Porting Guide\" below.\n\n\nMonitor Commands - Overview:\n============================\n\ngo\t- start application at address 'addr'\nrun\t- run commands in an environment variable\nbootm\t- boot application image from memory\nbootp\t- boot image via network using BootP/TFTP protocol\nbootz   - boot zImage from memory\ntftpboot- boot image via network using TFTP protocol\n\t       and env variables \"ipaddr\" and \"serverip\"\n\t       (and eventually \"gatewayip\")\ntftpput - upload a file via network using TFTP protocol\nrarpboot- boot image via network using RARP/TFTP protocol\ndiskboot- boot from IDE devicebootd   - boot default, i.e., run 'bootcmd'\nloads\t- load S-Record file over serial line\nloadb\t- load binary file over serial line (kermit mode)\nloadm   - load binary blob from source address to destination address\nmd\t- memory display\nmm\t- memory modify (auto-incrementing)\nnm\t- memory modify (constant address)\nmw\t- memory write (fill)\nms\t- memory search\ncp\t- memory copy\ncmp\t- memory compare\ncrc32\t- checksum calculation\ni2c\t- I2C sub-system\nsspi\t- SPI utility commands\nbase\t- print or set address offset\nprintenv- print environment variables\npwm\t- control pwm channels\nseama   - load SEAMA NAND image\nsetenv\t- set environment variables\nsaveenv - save environment variables to persistent storage\nprotect - enable or disable FLASH write protection\nerase\t- erase FLASH memory\nflinfo\t- print FLASH memory information\nnand\t- NAND memory operations (see doc/README.nand)\nbdinfo\t- print Board Info structure\niminfo\t- print header information for application image\nconinfo - print console devices and informations\nide\t- IDE sub-system\nloop\t- infinite loop on address range\nloopw\t- infinite write loop on address range\nmtest\t- simple RAM test\nicache\t- enable or disable instruction cache\ndcache\t- enable or disable data cache\nreset\t- Perform RESET of the CPU\necho\t- echo args to console\nversion - print monitor version\nhelp\t- print online help\n?\t- alias for 'help'\n\n\nMonitor Commands - Detailed Description:\n========================================\n\nTODO.\n\nFor now: just type \"help <command>\".\n\n\nNote for Redundant Ethernet Interfaces:\n=======================================\n\nSome boards come with redundant Ethernet interfaces; U-Boot supports\nsuch configurations and is capable of automatic selection of a\n\"working\" interface when needed. MAC assignment works as follows:\n\nNetwork interfaces are numbered eth0, eth1, eth2, ... Corresponding\nMAC addresses can be stored in the environment as \"ethaddr\" (=>eth0),\n\"eth1addr\" (=>eth1), \"eth2addr\", ...\n\nIf the network interface stores some valid MAC address (for instance\nin SROM), this is used as default address if there is NO correspon-\nding setting in the environment; if the corresponding environment\nvariable is set, this overrides the settings in the card; that means:\n\no If the SROM has a valid MAC address, and there is no address in the\n  environment, the SROM's address is used.\n\no If there is no valid address in the SROM, and a definition in the\n  environment exists, then the value from the environment variable is\n  used.\n\no If both the SROM and the environment contain a MAC address, and\n  both addresses are the same, this MAC address is used.\n\no If both the SROM and the environment contain a MAC address, and the\n  addresses differ, the value from the environment is used and a\n  warning is printed.\n\no If neither SROM nor the environment contain a MAC address, an error\n  is raised. If CONFIG_NET_RANDOM_ETHADDR is defined, then in this case\n  a random, locally-assigned MAC is used.\n\nIf Ethernet drivers implement the 'write_hwaddr' function, valid MAC addresses\nwill be programmed into hardware as part of the initialization process.\t This\nmay be skipped by setting the appropriate 'ethmacskip' environment variable.\nThe naming convention is as follows:\n\"ethmacskip\" (=>eth0), \"eth1macskip\" (=>eth1) etc.\n\nImage Formats:\n==============\n\nU-Boot is capable of booting (and performing other auxiliary operations on)\nimages in two formats:\n\nNew uImage format (FIT)\n-----------------------\n\nFlexible and powerful format based on Flattened Image Tree -- FIT (similar\nto Flattened Device Tree). It allows the use of images with multiple\ncomponents (several kernels, ramdisks, etc.), with contents protected by\nSHA1, MD5 or CRC32. More details are found in the doc/uImage.FIT directory.\n\n\nOld uImage format\n-----------------\n\nOld image format is based on binary files which can be basically anything,\npreceded by a special header; see the definitions in include/image.h for\ndetails; basically, the header defines the following image properties:\n\n* Target Operating System (Provisions for OpenBSD, NetBSD, FreeBSD,\n  4.4BSD, Linux, SVR4, Esix, Solaris, Irix, SCO, Dell, NCR, VxWorks,\n  LynxOS, pSOS, QNX, RTEMS, INTEGRITY;\n  Currently supported: Linux, NetBSD, VxWorks, QNX, RTEMS, INTEGRITY).\n* Target CPU Architecture (Provisions for Alpha, ARM, Intel x86,\n  IA64, MIPS, Nios II, PowerPC, IBM S390, SuperH, Sparc, Sparc 64 Bit;\n  Currently supported: ARM, Intel x86, MIPS, Nios II, PowerPC).\n* Compression Type (uncompressed, gzip, bzip2)\n* Load Address\n* Entry Point\n* Image Name\n* Image Timestamp\n\nThe header is marked by a special Magic Number, and both the header\nand the data portions of the image are secured against corruption by\nCRC32 checksums.\n\n\nLinux Support:\n==============\n\nAlthough U-Boot should support any OS or standalone application\neasily, the main focus has always been on Linux during the design of\nU-Boot.\n\nU-Boot includes many features that so far have been part of some\nspecial \"boot loader\" code within the Linux kernel. Also, any\n\"initrd\" images to be used are no longer part of one big Linux image;\ninstead, kernel and \"initrd\" are separate images. This implementation\nserves several purposes:\n\n- the same features can be used for other OS or standalone\n  applications (for instance: using compressed images to reduce the\n  Flash memory footprint)\n\n- it becomes much easier to port new Linux kernel versions because\n  lots of low-level, hardware dependent stuff are done by U-Boot\n\n- the same Linux kernel image can now be used with different \"initrd\"\n  images; of course this also means that different kernel images can\n  be run with the same \"initrd\". This makes testing easier (you don't\n  have to build a new \"zImage.initrd\" Linux image when you just\n  change a file in your \"initrd\"). Also, a field-upgrade of the\n  software is easier now.\n\n\nLinux HOWTO:\n============\n\nPorting Linux to U-Boot based systems:\n---------------------------------------\n\nU-Boot cannot save you from doing all the necessary modifications to\nconfigure the Linux device drivers for use with your target hardware\n(no, we don't intend to provide a full virtual machine interface to\nLinux :-).\n\nBut now you can ignore ALL boot loader code (in arch/powerpc/mbxboot).\n\nJust make sure your machine specific header file (for instance\ninclude/asm-ppc/tqm8xx.h) includes the same definition of the Board\nInformation structure as we define in include/asm-<arch>/u-boot.h,\nand make sure that your definition of IMAP_ADDR uses the same value\nas your U-Boot configuration in CONFIG_SYS_IMMR.\n\nNote that U-Boot now has a driver model, a unified model for drivers.\nIf you are adding a new driver, plumb it into driver model. If there\nis no uclass available, you are encouraged to create one. See\ndoc/driver-model.\n\n\nConfiguring the Linux kernel:\n-----------------------------\n\nNo specific requirements for U-Boot. Make sure you have some root\ndevice (initial ramdisk, NFS) for your target system.\n\n\nBuilding a Linux Image:\n-----------------------\n\nWith U-Boot, \"normal\" build targets like \"zImage\" or \"bzImage\" are\nnot used. If you use recent kernel source, a new build target\n\"uImage\" will exist which automatically builds an image usable by\nU-Boot. Most older kernels also have support for a \"pImage\" target,\nwhich was introduced for our predecessor project PPCBoot and uses a\n100% compatible format.\n\nExample:\n\n\tmake TQM850L_defconfig\n\tmake oldconfig\n\tmake dep\n\tmake uImage\n\nThe \"uImage\" build target uses a special tool (in 'tools/mkimage') to\nencapsulate a compressed Linux kernel image with header\t information,\nCRC32 checksum etc. for use with U-Boot. This is what we are doing:\n\n* build a standard \"vmlinux\" kernel image (in ELF binary format):\n\n* convert the kernel into a raw binary image:\n\n\t${CROSS_COMPILE}-objcopy -O binary \\\n\t\t\t\t -R .note -R .comment \\\n\t\t\t\t -S vmlinux linux.bin\n\n* compress the binary image:\n\n\tgzip -9 linux.bin\n\n* package compressed binary image for U-Boot:\n\n\tmkimage -A ppc -O linux -T kernel -C gzip \\\n\t\t-a 0 -e 0 -n \"Linux Kernel Image\" \\\n\t\t-d linux.bin.gz uImage\n\n\nThe \"mkimage\" tool can also be used to create ramdisk images for use\nwith U-Boot, either separated from the Linux kernel image, or\ncombined into one file. \"mkimage\" encapsulates the images with a 64\nbyte header containing information about target architecture,\noperating system, image type, compression method, entry points, time\nstamp, CRC32 checksums, etc.\n\n\"mkimage\" can be called in two ways: to verify existing images and\nprint the header information, or to build new images.\n\nIn the first form (with \"-l\" option) mkimage lists the information\ncontained in the header of an existing U-Boot image; this includes\nchecksum verification:\n\n\ttools/mkimage -l image\n\t  -l ==> list image header information\n\nThe second form (with \"-d\" option) is used to build a U-Boot image\nfrom a \"data file\" which is used as image payload:\n\n\ttools/mkimage -A arch -O os -T type -C comp -a addr -e ep \\\n\t\t      -n name -d data_file image\n\t  -A ==> set architecture to 'arch'\n\t  -O ==> set operating system to 'os'\n\t  -T ==> set image type to 'type'\n\t  -C ==> set compression type 'comp'\n\t  -a ==> set load address to 'addr' (hex)\n\t  -e ==> set entry point to 'ep' (hex)\n\t  -n ==> set image name to 'name'\n\t  -d ==> use image data from 'datafile'\n\nRight now, all Linux kernels for PowerPC systems use the same load\naddress (0x00000000), but the entry point address depends on the\nkernel version:\n\n- 2.2.x kernels have the entry point at 0x0000000C,\n- 2.3.x and later kernels have the entry point at 0x00000000.\n\nSo a typical call to build a U-Boot image would read:\n\n\t-> tools/mkimage -n '2.4.4 kernel for TQM850L' \\\n\t> -A ppc -O linux -T kernel -C gzip -a 0 -e 0 \\\n\t> -d /opt/elsk/ppc_8xx/usr/src/linux-2.4.4/arch/powerpc/coffboot/vmlinux.gz \\\n\t> examples/uImage.TQM850L\n\tImage Name:   2.4.4 kernel for TQM850L\n\tCreated:      Wed Jul 19 02:34:59 2000\n\tImage Type:   PowerPC Linux Kernel Image (gzip compressed)\n\tData Size:    335725 Bytes = 327.86 kB = 0.32 MB\n\tLoad Address: 0x00000000\n\tEntry Point:  0x00000000\n\nTo verify the contents of the image (or check for corruption):\n\n\t-> tools/mkimage -l examples/uImage.TQM850L\n\tImage Name:   2.4.4 kernel for TQM850L\n\tCreated:      Wed Jul 19 02:34:59 2000\n\tImage Type:   PowerPC Linux Kernel Image (gzip compressed)\n\tData Size:    335725 Bytes = 327.86 kB = 0.32 MB\n\tLoad Address: 0x00000000\n\tEntry Point:  0x00000000\n\nNOTE: for embedded systems where boot time is critical you can trade\nspeed for memory and install an UNCOMPRESSED image instead: this\nneeds more space in Flash, but boots much faster since it does not\nneed to be uncompressed:\n\n\t-> gunzip /opt/elsk/ppc_8xx/usr/src/linux-2.4.4/arch/powerpc/coffboot/vmlinux.gz\n\t-> tools/mkimage -n '2.4.4 kernel for TQM850L' \\\n\t> -A ppc -O linux -T kernel -C none -a 0 -e 0 \\\n\t> -d /opt/elsk/ppc_8xx/usr/src/linux-2.4.4/arch/powerpc/coffboot/vmlinux \\\n\t> examples/uImage.TQM850L-uncompressed\n\tImage Name:   2.4.4 kernel for TQM850L\n\tCreated:      Wed Jul 19 02:34:59 2000\n\tImage Type:   PowerPC Linux Kernel Image (uncompressed)\n\tData Size:    792160 Bytes = 773.59 kB = 0.76 MB\n\tLoad Address: 0x00000000\n\tEntry Point:  0x00000000\n\n\nSimilar you can build U-Boot images from a 'ramdisk.image.gz' file\nwhen your kernel is intended to use an initial ramdisk:\n\n\t-> tools/mkimage -n 'Simple Ramdisk Image' \\\n\t> -A ppc -O linux -T ramdisk -C gzip \\\n\t> -d /LinuxPPC/images/SIMPLE-ramdisk.image.gz examples/simple-initrd\n\tImage Name:   Simple Ramdisk Image\n\tCreated:      Wed Jan 12 14:01:50 2000\n\tImage Type:   PowerPC Linux RAMDisk Image (gzip compressed)\n\tData Size:    566530 Bytes = 553.25 kB = 0.54 MB\n\tLoad Address: 0x00000000\n\tEntry Point:  0x00000000\n\nThe \"dumpimage\" tool can be used to disassemble or list the contents of images\nbuilt by mkimage. See dumpimage's help output (-h) for details.\n\nInstalling a Linux Image:\n-------------------------\n\nTo downloading a U-Boot image over the serial (console) interface,\nyou must convert the image to S-Record format:\n\n\tobjcopy -I binary -O srec examples/image examples/image.srec\n\nThe 'objcopy' does not understand the information in the U-Boot\nimage header, so the resulting S-Record file will be relative to\naddress 0x00000000. To load it to a given address, you need to\nspecify the target address as 'offset' parameter with the 'loads'\ncommand.\n\nExample: install the image to address 0x40100000 (which on the\nTQM8xxL is in the first Flash bank):\n\n\t=> erase 40100000 401FFFFF\n\n\t.......... done\n\tErased 8 sectors\n\n\t=> loads 40100000\n\t## Ready for S-Record download ...\n\t~>examples/image.srec\n\t1 2 3 4 5 6 7 8 9 10 11 12 13 ...\n\t...\n\t15989 15990 15991 15992\n\t[file transfer complete]\n\t[connected]\n\t## Start Addr = 0x00000000\n\n\nYou can check the success of the download using the 'iminfo' command;\nthis includes a checksum verification so you can be sure no data\ncorruption happened:\n\n\t=> imi 40100000\n\n\t## Checking Image at 40100000 ...\n\t   Image Name:\t 2.2.13 for initrd on TQM850L\n\t   Image Type:\t PowerPC Linux Kernel Image (gzip compressed)\n\t   Data Size:\t 335725 Bytes = 327 kB = 0 MB\n\t   Load Address: 00000000\n\t   Entry Point:\t 0000000c\n\t   Verifying Checksum ... OK\n\n\nBoot Linux:\n-----------\n\nThe \"bootm\" command is used to boot an application that is stored in\nmemory (RAM or Flash). In case of a Linux kernel image, the contents\nof the \"bootargs\" environment variable is passed to the kernel as\nparameters. You can check and modify this variable using the\n\"printenv\" and \"setenv\" commands:\n\n\n\t=> printenv bootargs\n\tbootargs=root=/dev/ram\n\n\t=> setenv bootargs root=/dev/nfs rw nfsroot=10.0.0.2:/LinuxPPC nfsaddrs=10.0.0.99:10.0.0.2\n\n\t=> printenv bootargs\n\tbootargs=root=/dev/nfs rw nfsroot=10.0.0.2:/LinuxPPC nfsaddrs=10.0.0.99:10.0.0.2\n\n\t=> bootm 40020000\n\t## Booting Linux kernel at 40020000 ...\n\t   Image Name:\t 2.2.13 for NFS on TQM850L\n\t   Image Type:\t PowerPC Linux Kernel Image (gzip compressed)\n\t   Data Size:\t 381681 Bytes = 372 kB = 0 MB\n\t   Load Address: 00000000\n\t   Entry Point:\t 0000000c\n\t   Verifying Checksum ... OK\n\t   Uncompressing Kernel Image ... OK\n\tLinux version 2.2.13 (wd@denx.local.net) (gcc version 2.95.2 19991024 (release)) #1 Wed Jul 19 02:35:17 MEST 2000\n\tBoot arguments: root=/dev/nfs rw nfsroot=10.0.0.2:/LinuxPPC nfsaddrs=10.0.0.99:10.0.0.2\n\ttime_init: decrementer frequency = 187500000/60\n\tCalibrating delay loop... 49.77 BogoMIPS\n\tMemory: 15208k available (700k kernel code, 444k data, 32k init) [c0000000,c1000000]\n\t...\n\nIf you want to boot a Linux kernel with initial RAM disk, you pass\nthe memory addresses of both the kernel and the initrd image (PPBCOOT\nformat!) to the \"bootm\" command:\n\n\t=> imi 40100000 40200000\n\n\t## Checking Image at 40100000 ...\n\t   Image Name:\t 2.2.13 for initrd on TQM850L\n\t   Image Type:\t PowerPC Linux Kernel Image (gzip compressed)\n\t   Data Size:\t 335725 Bytes = 327 kB = 0 MB\n\t   Load Address: 00000000\n\t   Entry Point:\t 0000000c\n\t   Verifying Checksum ... OK\n\n\t## Checking Image at 40200000 ...\n\t   Image Name:\t Simple Ramdisk Image\n\t   Image Type:\t PowerPC Linux RAMDisk Image (gzip compressed)\n\t   Data Size:\t 566530 Bytes = 553 kB = 0 MB\n\t   Load Address: 00000000\n\t   Entry Point:\t 00000000\n\t   Verifying Checksum ... OK\n\n\t=> bootm 40100000 40200000\n\t## Booting Linux kernel at 40100000 ...\n\t   Image Name:\t 2.2.13 for initrd on TQM850L\n\t   Image Type:\t PowerPC Linux Kernel Image (gzip compressed)\n\t   Data Size:\t 335725 Bytes = 327 kB = 0 MB\n\t   Load Address: 00000000\n\t   Entry Point:\t 0000000c\n\t   Verifying Checksum ... OK\n\t   Uncompressing Kernel Image ... OK\n\t## Loading RAMDisk Image at 40200000 ...\n\t   Image Name:\t Simple Ramdisk Image\n\t   Image Type:\t PowerPC Linux RAMDisk Image (gzip compressed)\n\t   Data Size:\t 566530 Bytes = 553 kB = 0 MB\n\t   Load Address: 00000000\n\t   Entry Point:\t 00000000\n\t   Verifying Checksum ... OK\n\t   Loading Ramdisk ... OK\n\tLinux version 2.2.13 (wd@denx.local.net) (gcc version 2.95.2 19991024 (release)) #1 Wed Jul 19 02:32:08 MEST 2000\n\tBoot arguments: root=/dev/ram\n\ttime_init: decrementer frequency = 187500000/60\n\tCalibrating delay loop... 49.77 BogoMIPS\n\t...\n\tRAMDISK: Compressed image found at block 0\n\tVFS: Mounted root (ext2 filesystem).\n\n\tbash#\n\nBoot Linux and pass a flat device tree:\n-----------\n\nFirst, U-Boot must be compiled with the appropriate defines. See the section\ntitled \"Linux Kernel Interface\" above for a more in depth explanation. The\nfollowing is an example of how to start a kernel and pass an updated\nflat device tree:\n\n=> print oftaddr\noftaddr=0x300000\n=> print oft\noft=oftrees/mpc8540ads.dtb\n=> tftp $oftaddr $oft\nSpeed: 1000, full duplex\nUsing TSEC0 device\nTFTP from server 192.168.1.1; our IP address is 192.168.1.101\nFilename 'oftrees/mpc8540ads.dtb'.\nLoad address: 0x300000\nLoading: #\ndone\nBytes transferred = 4106 (100a hex)\n=> tftp $loadaddr $bootfile\nSpeed: 1000, full duplex\nUsing TSEC0 device\nTFTP from server 192.168.1.1; our IP address is 192.168.1.2\nFilename 'uImage'.\nLoad address: 0x200000\nLoading:############\ndone\nBytes transferred = 1029407 (fb51f hex)\n=> print loadaddr\nloadaddr=200000\n=> print oftaddr\noftaddr=0x300000\n=> bootm $loadaddr - $oftaddr\n## Booting image at 00200000 ...\n   Image Name:\t Linux-2.6.17-dirty\n   Image Type:\t PowerPC Linux Kernel Image (gzip compressed)\n   Data Size:\t 1029343 Bytes = 1005.2 kB\n   Load Address: 00000000\n   Entry Point:\t 00000000\n   Verifying Checksum ... OK\n   Uncompressing Kernel Image ... OK\nBooting using flat device tree at 0x300000\nUsing MPC85xx ADS machine description\nMemory CAM mapping: CAM0=256Mb, CAM1=256Mb, CAM2=0Mb residual: 0Mb\n[snip]\n\n\nMore About U-Boot Image Types:\n------------------------------\n\nU-Boot supports the following image types:\n\n   \"Standalone Programs\" are directly runnable in the environment\n\tprovided by U-Boot; it is expected that (if they behave\n\twell) you can continue to work in U-Boot after return from\n\tthe Standalone Program.\n   \"OS Kernel Images\" are usually images of some Embedded OS which\n\twill take over control completely. Usually these programs\n\twill install their own set of exception handlers, device\n\tdrivers, set up the MMU, etc. - this means, that you cannot\n\texpect to re-enter U-Boot except by resetting the CPU.\n   \"RAMDisk Images\" are more or less just data blocks, and their\n\tparameters (address, size) are passed to an OS kernel that is\n\tbeing started.\n   \"Multi-File Images\" contain several images, typically an OS\n\t(Linux) kernel image and one or more data images like\n\tRAMDisks. This construct is useful for instance when you want\n\tto boot over the network using BOOTP etc., where the boot\n\tserver provides just a single image file, but you want to get\n\tfor instance an OS kernel and a RAMDisk image.\n\n\t\"Multi-File Images\" start with a list of image sizes, each\n\timage size (in bytes) specified by an \"uint32_t\" in network\n\tbyte order. This list is terminated by an \"(uint32_t)0\".\n\tImmediately after the terminating 0 follow the images, one by\n\tone, all aligned on \"uint32_t\" boundaries (size rounded up to\n\ta multiple of 4 bytes).\n\n   \"Firmware Images\" are binary images containing firmware (like\n\tU-Boot or FPGA images) which usually will be programmed to\n\tflash memory.\n\n   \"Script files\" are command sequences that will be executed by\n\tU-Boot's command interpreter; this feature is especially\n\tuseful when you configure U-Boot to use a real shell (hush)\n\tas command interpreter.\n\nBooting the Linux zImage:\n-------------------------\n\nOn some platforms, it's possible to boot Linux zImage. This is done\nusing the \"bootz\" command. The syntax of \"bootz\" command is the same\nas the syntax of \"bootm\" command.\n\nNote, defining the CONFIG_SUPPORT_RAW_INITRD allows user to supply\nkernel with raw initrd images. The syntax is slightly different, the\naddress of the initrd must be augmented by it's size, in the following\nformat: \"<initrd addres>:<initrd size>\".\n\n\nStandalone HOWTO:\n=================\n\nOne of the features of U-Boot is that you can dynamically load and\nrun \"standalone\" applications, which can use some resources of\nU-Boot like console I/O functions or interrupt services.\n\nTwo simple examples are included with the sources:\n\n\"Hello World\" Demo:\n-------------------\n\n'examples/hello_world.c' contains a small \"Hello World\" Demo\napplication; it is automatically compiled when you build U-Boot.\nIt's configured to run at address 0x00040004, so you can play with it\nlike that:\n\n\t=> loads\n\t## Ready for S-Record download ...\n\t~>examples/hello_world.srec\n\t1 2 3 4 5 6 7 8 9 10 11 ...\n\t[file transfer complete]\n\t[connected]\n\t## Start Addr = 0x00040004\n\n\t=> go 40004 Hello World! This is a test.\n\t## Starting application at 0x00040004 ...\n\tHello World\n\targc = 7\n\targv[0] = \"40004\"\n\targv[1] = \"Hello\"\n\targv[2] = \"World!\"\n\targv[3] = \"This\"\n\targv[4] = \"is\"\n\targv[5] = \"a\"\n\targv[6] = \"test.\"\n\targv[7] = \"<NULL>\"\n\tHit any key to exit ...\n\n\t## Application terminated, rc = 0x0\n\nAnother example, which demonstrates how to register a CPM interrupt\nhandler with the U-Boot code, can be found in 'examples/timer.c'.\nHere, a CPM timer is set up to generate an interrupt every second.\nThe interrupt service routine is trivial, just printing a '.'\ncharacter, but this is just a demo program. The application can be\ncontrolled by the following keys:\n\n\t? - print current values og the CPM Timer registers\n\tb - enable interrupts and start timer\n\te - stop timer and disable interrupts\n\tq - quit application\n\n\t=> loads\n\t## Ready for S-Record download ...\n\t~>examples/timer.srec\n\t1 2 3 4 5 6 7 8 9 10 11 ...\n\t[file transfer complete]\n\t[connected]\n\t## Start Addr = 0x00040004\n\n\t=> go 40004\n\t## Starting application at 0x00040004 ...\n\tTIMERS=0xfff00980\n\tUsing timer 1\n\t  tgcr @ 0xfff00980, tmr @ 0xfff00990, trr @ 0xfff00994, tcr @ 0xfff00998, tcn @ 0xfff0099c, ter @ 0xfff009b0\n\nHit 'b':\n\t[q, b, e, ?] Set interval 1000000 us\n\tEnabling timer\nHit '?':\n\t[q, b, e, ?] ........\n\ttgcr=0x1, tmr=0xff1c, trr=0x3d09, tcr=0x0, tcn=0xef6, ter=0x0\nHit '?':\n\t[q, b, e, ?] .\n\ttgcr=0x1, tmr=0xff1c, trr=0x3d09, tcr=0x0, tcn=0x2ad4, ter=0x0\nHit '?':\n\t[q, b, e, ?] .\n\ttgcr=0x1, tmr=0xff1c, trr=0x3d09, tcr=0x0, tcn=0x1efc, ter=0x0\nHit '?':\n\t[q, b, e, ?] .\n\ttgcr=0x1, tmr=0xff1c, trr=0x3d09, tcr=0x0, tcn=0x169d, ter=0x0\nHit 'e':\n\t[q, b, e, ?] ...Stopping timer\nHit 'q':\n\t[q, b, e, ?] ## Application terminated, rc = 0x0\n\n\nImplementation Internals:\n=========================\n\nThe following is not intended to be a complete description of every\nimplementation detail. However, it should help to understand the\ninner workings of U-Boot and make it easier to port it to custom\nhardware.\n\n\nInitial Stack, Global Data:\n---------------------------\n\nThe implementation of U-Boot is complicated by the fact that U-Boot\nstarts running out of ROM (flash memory), usually without access to\nsystem RAM (because the memory controller is not initialized yet).\nThis means that we don't have writable Data or BSS segments, and BSS\nis not initialized as zero. To be able to get a C environment working\nat all, we have to allocate at least a minimal stack. Implementation\noptions for this are defined and restricted by the CPU used: Some CPU\nmodels provide on-chip memory (like the IMMR area on MPC8xx and\nMPC826x processors), on others (parts of) the data cache can be\nlocked as (mis-) used as memory, etc.\n\n\tChris Hallinan posted a good summary of these issues to the\n\tU-Boot mailing list:\n\n\tSubject: RE: [U-Boot-Users] RE: More On Memory Bank x (nothingness)?\n\tFrom: \"Chris Hallinan\" <clh@net1plus.com>\n\tDate: Mon, 10 Feb 2003 16:43:46 -0500 (22:43 MET)\n\t...\n\n\tCorrect me if I'm wrong, folks, but the way I understand it\n\tis this: Using DCACHE as initial RAM for Stack, etc, does not\n\trequire any physical RAM backing up the cache. The cleverness\n\tis that the cache is being used as a temporary supply of\n\tnecessary storage before the SDRAM controller is setup. It's\n\tbeyond the scope of this list to explain the details, but you\n\tcan see how this works by studying the cache architecture and\n\toperation in the architecture and processor-specific manuals.\n\n\tOCM is On Chip Memory, which I believe the 405GP has 4K. It\n\tis another option for the system designer to use as an\n\tinitial stack/RAM area prior to SDRAM being available. Either\n\toption should work for you. Using CS 4 should be fine if your\n\tboard designers haven't used it for something that would\n\tcause you grief during the initial boot! It is frequently not\n\tused.\n\n\tCFG_SYS_INIT_RAM_ADDR should be somewhere that won't interfere\n\twith your processor/board/system design. The default value\n\tyou will find in any recent u-boot distribution in\n\twalnut.h should work for you. I'd set it to a value larger\n\tthan your SDRAM module. If you have a 64MB SDRAM module, set\n\tit above 400_0000. Just make sure your board has no resources\n\tthat are supposed to respond to that address! That code in\n\tstart.S has been around a while and should work as is when\n\tyou get the config right.\n\n\t-Chris Hallinan\n\tDS4.COM, Inc.\n\nIt is essential to remember this, since it has some impact on the C\ncode for the initialization procedures:\n\n* Initialized global data (data segment) is read-only. Do not attempt\n  to write it.\n\n* Do not use any uninitialized global data (or implicitly initialized\n  as zero data - BSS segment) at all - this is undefined, initiali-\n  zation is performed later (when relocating to RAM).\n\n* Stack space is very limited. Avoid big data buffers or things like\n  that.\n\nHaving only the stack as writable memory limits means we cannot use\nnormal global data to share information between the code. But it\nturned out that the implementation of U-Boot can be greatly\nsimplified by making a global data structure (gd_t) available to all\nfunctions. We could pass a pointer to this data as argument to _all_\nfunctions, but this would bloat the code. Instead we use a feature of\nthe GCC compiler (Global Register Variables) to share the data: we\nplace a pointer (gd) to the global data into a register which we\nreserve for this purpose.\n\nWhen choosing a register for such a purpose we are restricted by the\nrelevant  (E)ABI  specifications for the current architecture, and by\nGCC's implementation.\n\nFor PowerPC, the following registers have specific use:\n\tR1:\tstack pointer\n\tR2:\treserved for system use\n\tR3-R4:\tparameter passing and return values\n\tR5-R10: parameter passing\n\tR13:\tsmall data area pointer\n\tR30:\tGOT pointer\n\tR31:\tframe pointer\n\n\t(U-Boot also uses R12 as internal GOT pointer. r12\n\tis a volatile register so r12 needs to be reset when\n\tgoing back and forth between asm and C)\n\n    ==> U-Boot will use R2 to hold a pointer to the global data\n\n    Note: on PPC, we could use a static initializer (since the\n    address of the global data structure is known at compile time),\n    but it turned out that reserving a register results in somewhat\n    smaller code - although the code savings are not that big (on\n    average for all boards 752 bytes for the whole U-Boot image,\n    624 text + 127 data).\n\nOn ARM, the following registers are used:\n\n\tR0:\tfunction argument word/integer result\n\tR1-R3:\tfunction argument word\n\tR9:\tplatform specific\n\tR10:\tstack limit (used only if stack checking is enabled)\n\tR11:\targument (frame) pointer\n\tR12:\ttemporary workspace\n\tR13:\tstack pointer\n\tR14:\tlink register\n\tR15:\tprogram counter\n\n    ==> U-Boot will use R9 to hold a pointer to the global data\n\n    Note: on ARM, only R_ARM_RELATIVE relocations are supported.\n\nOn Nios II, the ABI is documented here:\n\thttps://www.altera.com/literature/hb/nios2/n2cpu_nii51016.pdf\n\n    ==> U-Boot will use gp to hold a pointer to the global data\n\n    Note: on Nios II, we give \"-G0\" option to gcc and don't use gp\n    to access small data sections, so gp is free.\n\nOn RISC-V, the following registers are used:\n\n\tx0: hard-wired zero (zero)\n\tx1: return address (ra)\n\tx2:\tstack pointer (sp)\n\tx3:\tglobal pointer (gp)\n\tx4:\tthread pointer (tp)\n\tx5:\tlink register (t0)\n\tx8:\tframe pointer (fp)\n\tx10-x11:\targuments/return values (a0-1)\n\tx12-x17:\targuments (a2-7)\n\tx28-31:\t temporaries (t3-6)\n\tpc:\tprogram counter (pc)\n\n    ==> U-Boot will use gp to hold a pointer to the global data\n\nSystem Initialization:\n----------------------\n\nIn the reset configuration, U-Boot starts at the reset entry point\n(on most PowerPC systems at address 0x00000100). Because of the reset\nconfiguration for CS0# this is a mirror of the on board Flash memory.\nTo be able to re-map memory U-Boot then jumps to its link address.\nTo be able to implement the initialization code in C, a (small!)\ninitial stack is set up in the internal Dual Ported RAM (in case CPUs\nwhich provide such a feature like), or in a locked part of the data\ncache. After that, U-Boot initializes the CPU core, the caches and\nthe SIU.\n\nNext, all (potentially) available memory banks are mapped using a\npreliminary mapping. For example, we put them on 512 MB boundaries\n(multiples of 0x20000000: SDRAM on 0x00000000 and 0x20000000, Flash\non 0x40000000 and 0x60000000, SRAM on 0x80000000). Then UPM A is\nprogrammed for SDRAM access. Using the temporary configuration, a\nsimple memory test is run that determines the size of the SDRAM\nbanks.\n\nWhen there is more than one SDRAM bank, and the banks are of\ndifferent size, the largest is mapped first. For equal size, the first\nbank (CS2#) is mapped first. The first mapping is always for address\n0x00000000, with any additional banks following immediately to create\ncontiguous memory starting from 0.\n\nThen, the monitor installs itself at the upper end of the SDRAM area\nand allocates memory for use by malloc() and for the global Board\nInfo data; also, the exception vector code is copied to the low RAM\npages, and the final stack is set up.\n\nOnly after this relocation will you have a \"normal\" C environment;\nuntil that you are restricted in several ways, mostly because you are\nrunning from ROM, and because the code will have to be relocated to a\nnew address in RAM.\n\n\nContributing\n============\n\nThe U-Boot projects depends on contributions from the user community.\nIf you want to participate, please, have a look at the 'General'\nsection of https://docs.u-boot.org/en/latest/develop/index.html\nwhere we describe coding standards and the patch submission process.\n",
      "stars_today": 1
    },
    {
      "id": 189044704,
      "name": "AFLplusplus",
      "full_name": "AFLplusplus/AFLplusplus",
      "description": "The fuzzer afl++ is afl with community patches, qemu 5.1 upgrade, collision-free coverage, enhanced laf-intel & redqueen, AFLfast++ power schedules, MOpt mutators, unicorn_mode, and a lot more!",
      "html_url": "https://github.com/AFLplusplus/AFLplusplus",
      "stars": 6256,
      "forks": 1243,
      "language": "C",
      "topics": [
        "afl",
        "afl-compiler",
        "afl-fuzz",
        "afl-fuzzer",
        "afl-gcc",
        "fuzz-testing",
        "fuzzer",
        "fuzzer-afl",
        "fuzzing",
        "instrumentation",
        "qemu",
        "security",
        "testing",
        "unicorn-emulator",
        "unicorn-mode"
      ],
      "created_at": "2019-05-28T14:29:06Z",
      "updated_at": "2026-01-23T21:49:46Z",
      "pushed_at": "2026-01-23T20:59:15Z",
      "open_issues": 30,
      "owner": {
        "login": "AFLplusplus",
        "avatar_url": "https://avatars.githubusercontent.com/u/62360046?v=4"
      },
      "readme": "# American Fuzzy Lop plus plus (AFL++)\n\n<img align=\"right\" src=\"https://raw.githubusercontent.com/AFLplusplus/Website/main/static/aflpp_bg.svg\" alt=\"AFL++ logo\" width=\"250\" height=\"250\">\n\nRelease version: [4.35c](https://github.com/AFLplusplus/AFLplusplus/releases)\n\nGitHub version: 4.36a\n\nRepository:\n[https://github.com/AFLplusplus/AFLplusplus](https://github.com/AFLplusplus/AFLplusplus)\n\nAFL++ is maintained by:\n\n* Marc \"van Hauser\" Heuse <mh@mh-sec.de>\n* Dominik Maier <mail@dmnk.co>\n* Andrea Fioraldi <andreafioraldi@gmail.com>\n* Heiko \"hexcoder-\" Eissfeldt <heiko.eissfeldt@hexco.de>\n* frida_mode is maintained by @Worksbutnottested\n\nOriginally developed by Michal \"lcamtuf\" Zalewski.\n\nAFL++ is a superior fork to Google's AFL - more speed, more and better\nmutations, more and better instrumentation, custom module support, etc.\n\nYou are free to copy, modify, and distribute AFL++ with attribution under the\nterms of the Apache-2.0 License. See the [LICENSE](LICENSE) for details.\n\n## Getting started\n\nHere is some information to get you started:\n\n* For an overview of the AFL++ documentation and a very helpful graphical guide,\n  please visit [docs/README.md](docs/README.md).\n* To get you started with tutorials, go to\n  [docs/tutorials.md](docs/tutorials.md).\n* For releases, see the\n  [Releases tab](https://github.com/AFLplusplus/AFLplusplus/releases) and\n  [branches](#branches). The best branches to use are, however, `stable` or\n  `dev` - depending on your risk appetite. Also take a look at the list of\n  [important changes in AFL++](docs/important_changes.md) and the list of\n  [features](docs/features.md).\n* If you want to use AFL++ for your academic work, check the\n  [papers page](https://aflplus.plus/papers/) on the website.\n* To cite our work, look at the [Cite](#cite) section.\n* For comparisons, use the fuzzbench `aflplusplus` setup, or use\n  `afl-clang-fast` with `AFL_LLVM_CMPLOG=1`. You can find the `aflplusplus`\n  default configuration on Google's\n  [fuzzbench](https://github.com/google/fuzzbench/tree/master/fuzzers/aflplusplus).\n\n## Building and installing AFL++\n\nTo have AFL++ easily available with everything compiled, pull the image directly\nfrom the Docker Hub (available for both x86_64 and arm64):\n\n```shell\ndocker pull aflplusplus/aflplusplus\ndocker run -ti -v /location/of/your/target:/src aflplusplus/aflplusplus\n```\n\nThis image is automatically published when a push to the stable branch happens\n(see [branches](#branches)). If you use the command above, you will find your\ntarget source code in `/src` in the container.\n\nNote: you can also pull `aflplusplus/aflplusplus:dev` which is the most current\ndevelopment state of AFL++.\n\nTo build AFL++ yourself - *which we recommend* - continue at\n[docs/INSTALL.md](docs/INSTALL.md).\n\n## Quick start: Fuzzing with AFL++\n\n*NOTE: Before you start, please read about the\n[common sense risks of fuzzing](docs/fuzzing_in_depth.md#0-common-sense-risks).*\n\nThis is a quick start for fuzzing targets with the source code available. To\nread about the process in detail, see\n[docs/fuzzing_in_depth.md](docs/fuzzing_in_depth.md).\n\nTo learn about fuzzing other targets, see:\n* Binary-only targets:\n  [docs/fuzzing_binary-only_targets.md](docs/fuzzing_binary-only_targets.md)\n* Network services:\n  [docs/best_practices.md#fuzzing-a-network-service](docs/best_practices.md#fuzzing-a-network-service)\n* GUI programs:\n  [docs/best_practices.md#fuzzing-a-gui-program](docs/best_practices.md#fuzzing-a-gui-program)\n\nStep-by-step quick start:\n\n1. Compile the program or library to be fuzzed using `afl-cc`. A common way to\n   do this would be:\n\n   ```\n   CC=/path/to/afl-cc CXX=/path/to/afl-c++ ./configure --disable-shared\n   make clean all\n   ```\n\n2. Get a small but valid input file that makes sense to the program. When\n   fuzzing verbose syntax (SQL, HTTP, etc.), create a dictionary as described in\n   [dictionaries/README.md](dictionaries/README.md), too.\n\n3. If the program reads from stdin, run `afl-fuzz` like so:\n\n   ```\n   ./afl-fuzz -i seeds_dir -o output_dir -- \\\n   /path/to/tested/program [...program's cmdline...]\n   ```\n\n   To add a dictionary, add `-x /path/to/dictionary.txt` to afl-fuzz.\n\n   If the program takes input from a file, you can put `@@` in the program's\n   command line; AFL++ will put an auto-generated file name in there for you.\n\n4. Investigate anything shown in red in the fuzzer UI by promptly consulting\n   [docs/afl-fuzz_approach.md#understanding-the-status-screen](docs/afl-fuzz_approach.md#understanding-the-status-screen).\n\n5. You will find found crashes and hangs in the subdirectories `crashes/` and\n   `hangs/` in the `-o output_dir` directory. You can replay the crashes by\n   feeding them to the target, e.g. if your target is using stdin:\n\n   ```\n   cat output_dir/crashes/id:000000,* | /path/to/tested/program [...program's cmdline...]\n   ```\n\n   You can generate cores or use gdb directly to follow up the crashes.\n\n6. We cannot stress this enough - if you want to fuzz effectively, read the\n   [docs/fuzzing_in_depth.md](docs/fuzzing_in_depth.md) document!\n\n## Contact\n\nQuestions? Concerns? Bug reports?\n\n* The contributors can be reached via (e.g., by creating an issue):\n  [https://github.com/AFLplusplus/AFLplusplus](https://github.com/AFLplusplus/AFLplusplus).\n* Take a look at our [FAQ](docs/FAQ.md). If you find an interesting or important\n  question missing, submit it via\n  [https://github.com/AFLplusplus/AFLplusplus/discussions](https://github.com/AFLplusplus/AFLplusplus/discussions).\n* Best: join the [Awesome Fuzzing](https://discord.gg/gCraWct) Discord server.\n* There is a (not really used) mailing list for the AFL/AFL++ project\n  ([browse archive](https://groups.google.com/group/afl-users)). To compare\n  notes with other users or to get notified about major new features, send an\n  email to <afl-users+subscribe@googlegroups.com>, but note that this is not\n  managed by us.\n\n## Branches\n\nThe following branches exist:\n\n* [release](https://github.com/AFLplusplus/AFLplusplus/tree/release): the latest\n  release\n* [stable/trunk](https://github.com/AFLplusplus/AFLplusplus/): stable state of\n  AFL++ - it is synced from dev from time to time when we are satisfied with its\n  stability\n* [dev](https://github.com/AFLplusplus/AFLplusplus/tree/dev): development state\n  of AFL++ - bleeding edge and you might catch a checkout which does not compile\n  or has a bug. **We only accept PRs (pull requests) for the 'dev' branch!**\n* (any other): experimental branches to work on specific features or testing new\n  functionality or changes.\n\n## Help wanted\n\nWe have several [ideas](docs/ideas.md) we would like to see in AFL++ to make it\neven better. However, we already work on so many things that we do not have the\ntime for all the big ideas.\n\nThis can be your way to support and contribute to AFL++ - extend it to do\nsomething cool.\n\nFor everyone who wants to contribute (and send pull requests), please read our\n[contributing guidelines](CONTRIBUTING.md) before you submit.\n\n## Special thanks\n\nMany of the improvements to the original AFL and AFL++ wouldn't be possible\nwithout feedback, bug reports, or patches from our contributors.\n\nThank you! (For people sending pull requests - please add yourself to this list\n:-)\n\n<details>\n\n  <summary>List of contributors</summary>\n\n  ```\n    Jann Horn                             Hanno Boeck\n    Felix Groebert                        Jakub Wilk\n    Richard W. M. Jones                   Alexander Cherepanov\n    Tom Ritter                            Hovik Manucharyan\n    Sebastian Roschke                     Eberhard Mattes\n    Padraig Brady                         Ben Laurie\n    @dronesec                             Luca Barbato\n    Tobias Ospelt                         Thomas Jarosch\n    Martin Carpenter                      Mudge Zatko\n    Joe Zbiciak                           Ryan Govostes\n    Michael Rash                          William Robinet\n    Jonathan Gray                         Filipe Cabecinhas\n    Nico Weber                            Jodie Cunningham\n    Andrew Griffiths                      Parker Thompson\n    Jonathan Neuschaefer                  Tyler Nighswander\n    Ben Nagy                              Samir Aguiar\n    Aidan Thornton                        Aleksandar Nikolich\n    Sam Hakim                             Laszlo Szekeres\n    David A. Wheeler                      Turo Lamminen\n    Andreas Stieger                       Richard Godbee\n    Louis Dassy                           teor2345\n    Alex Moneger                          Dmitry Vyukov\n    Keegan McAllister                     Kostya Serebryany\n    Richo Healey                          Martijn Bogaard\n    rc0r                                  Jonathan Foote\n    Christian Holler                      Dominique Pelle\n    Jacek Wielemborek                     Leo Barnes\n    Jeremy Barnes                         Jeff Trull\n    Guillaume Endignoux                   ilovezfs\n    Daniel Godas-Lopez                    Franjo Ivancic\n    Austin Seipp                          Daniel Komaromy\n    Daniel Binderman                      Jonathan Metzman\n    Vegard Nossum                         Jan Kneschke\n    Kurt Roeckx                           Marcel Boehme\n    Van-Thuan Pham                        Abhik Roychoudhury\n    Joshua J. Drake                       Toby Hutton\n    Rene Freingruber                      Sergey Davidoff\n    Sami Liedes                           Craig Young\n    Andrzej Jackowski                     Daniel Hodson\n    Nathan Voss                           Dominik Maier\n    Andrea Biondo                         Vincent Le Garrec\n    Khaled Yakdan                         Kuang-che Wu\n    Josephine Calliotte                   Konrad Welc\n    Thomas Rooijakkers                    David Carlier\n    Ruben ten Hove                        Joey Jiao\n    fuzzah                                @intrigus-lgtm\n    Yaakov Saxon                          Sergej Schumilo\n    Ziqiao Kong                           Ryan Berger\n    Sangjun Park                          Scott Guest\n    Fabian Keil\n  ```\n\n</details>\n\n## Cite\n\nIf you use AFL++ in scientific work, consider citing\n[our paper](https://www.usenix.org/conference/woot20/presentation/fioraldi)\npresented at WOOT'20:\n\n    Andrea Fioraldi, Dominik Maier, Heiko Ei√üfeldt, and Marc Heuse. ‚ÄúAFL++: Combining incremental steps of fuzzing research‚Äù. In 14th USENIX Workshop on Offensive Technologies (WOOT 20). USENIX Association, Aug. 2020.\n\n<details>\n\n<summary>BibTeX</summary>\n\n  ```bibtex\n  @inproceedings {AFLplusplus-Woot20,\n  author = {Andrea Fioraldi and Dominik Maier and Heiko Ei{\\ss}feldt and Marc Heuse},\n  title = {{AFL++}: Combining Incremental Steps of Fuzzing Research},\n  booktitle = {14th {USENIX} Workshop on Offensive Technologies ({WOOT} 20)},\n  year = {2020},\n  publisher = {{USENIX} Association},\n  month = aug,\n  }\n  ```\n\n</details>\n\n[![zread](https://img.shields.io/badge/Ask_Zread-_.svg?style=flat&color=00b0aa&labelColor=000000&logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTQuOTYxNTYgMS42MDAxSDIuMjQxNTZDMS44ODgxIDEuNjAwMSAxLjYwMTU2IDEuODg2NjQgMS42MDE1NiAyLjI0MDFWNC45NjAxQzEuNjAxNTYgNS4zMTM1NiAxLjg4ODEgNS42MDAxIDIuMjQxNTYgNS42MDAxSDQuOTYxNTZDNS4zMTUwMiA1LjYwMDEgNS42MDE1NiA1LjMxMzU2IDUuNjAxNTYgNC45NjAxVjIuMjQwMUM1LjYwMTU2IDEuODg2NjQgNS4zMTUwMiAxLjYwMDEgNC45NjE1NiAxLjYwMDFaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00Ljk2MTU2IDEwLjM5OTlIMi4yNDE1NkMxLjg4ODEgMTAuMzk5OSAxLjYwMTU2IDEwLjY4NjQgMS42MDE1NiAxMS4wMzk5VjEzLjc1OTlDMS42MDE1NiAxNC4xMTM0IDEuODg4MSAxNC4zOTk5IDIuMjQxNTYgMTQuMzk5OUg0Ljk2MTU2QzUuMzE1MDIgMTQuMzk5OSA1LjYwMTU2IDE0LjExMzQgNS42MDE1NiAxMy43NTk5VjExLjAzOTlDNS42MDE1NiAxMC42ODY0IDUuMzE1MDIgMTAuMzk5OSA0Ljk2MTU2IDEwLjM5OTlaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik0xMy43NTg0IDEuNjAwMUgxMS4wMzg0QzEwLjY4NSAxLjYwMDEgMTAuMzk4NCAxLjg4NjY0IDEwLjM5ODQgMi4yNDAxVjQuOTYwMUMxMC4zOTg0IDUuMzEzNTYgMTAuNjg1IDUuNjAwMSAxMS4wMzg0IDUuNjAwMUgxMy43NTg0QzE0LjExMTkgNS42MDAxIDE0LjM5ODQgNS4zMTM1NiAxNC4zOTg0IDQuOTYwMVYyLjI0MDFDMTQuMzk4NCAxLjg4NjY0IDE0LjExMTkgMS42MDAxIDEzLjc1ODQgMS42MDAxWiIgZmlsbD0iI2ZmZiIvPgo8cGF0aCBkPSJNNCAxMkwxMiA0TDQgMTJaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00IDEyTDEyIDQiIHN0cm9rZT0iI2ZmZiIgc3Ryb2tlLXdpZHRoPSIxLjUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIvPgo8L3N2Zz4K&logoColor=ffffff)](https://zread.ai/AFLplusplus/AFLplusplus)\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/AFLplusplus/AFLplusplus)\n",
      "stars_today": 1
    },
    {
      "id": 19608522,
      "name": "google-cloud-go",
      "full_name": "googleapis/google-cloud-go",
      "description": "Google Cloud Client Libraries for Go.",
      "html_url": "https://github.com/googleapis/google-cloud-go",
      "stars": 4399,
      "forks": 1509,
      "language": "Go",
      "topics": [
        "cloud-bigquery",
        "cloud-datastore",
        "cloud-pubsub",
        "cloud-storage",
        "go",
        "golang",
        "google-cloud"
      ],
      "created_at": "2014-05-09T11:11:58Z",
      "updated_at": "2026-01-23T22:42:26Z",
      "pushed_at": "2026-01-23T22:42:07Z",
      "open_issues": 489,
      "owner": {
        "login": "googleapis",
        "avatar_url": "https://avatars.githubusercontent.com/u/16785467?v=4"
      },
      "readme": "# Google Cloud Client Libraries for Go\n\n[![Go Reference](https://pkg.go.dev/badge/cloud.google.com/go.svg)](https://pkg.go.dev/cloud.google.com/go)\n\nGo packages for [Google Cloud Platform](https://cloud.google.com) services.\n\n## Installation\n\n```bash\ngo get cloud.google.com/go/firestore@latest # Replace firestore with the package you want to use.\n```\n\n**NOTE:** Some of these packages are under development, and may occasionally\nmake backwards-incompatible changes.\n\n## Supported APIs\n\nFor an updated list of all of our released APIs please see our\n[reference docs](https://cloud.google.com/go/docs/reference).\n\n## [Go Versions Supported](#supported-versions)\n\nOur libraries are compatible with the two most recent major Go\nreleases, the same [policy](https://go.dev/doc/devel/release#policy) the Go\nprogramming language follows. This means the currently supported versions are:\n\n- Go 1.24\n- Go 1.25\n\n## Authentication\n\nBy default, each client library will use [Application Default Credentials](https://developers.google.com/identity/protocols/application-default-credentials)\n(ADC) to automatically configure the credentials used in calling the API endpoint.\nWhen using the libraries in a Google Cloud Platform environment such as Compute\nEngine, Kubernetes Engine, or App Engine, no additional authentication steps are\nnecessary. See [Authentication methods at Google](https://cloud.google.com/docs/authentication)\nand [Authenticate for using client libraries](https://cloud.google.com/docs/authentication/client-libraries)\nfor more information.\n\n```go\nclient, err := storage.NewClient(ctx)\n```\n\nFor applications running elsewhere, such as your local development environment,\nyou can use the `gcloud auth application-default login` command from the\n[Google Cloud CLI](https://cloud.google.com/cli) to set user credentials in\nyour local filesystem. Application Default Credentials will automatically detect\nthese credentials. See [Set up ADC for a local development\nenvironment](https://cloud.google.com/docs/authentication/set-up-adc-local-dev-environment)\nfor more information.\n\nAlternately, you may need to provide an explicit path to your credentials. To authenticate\nusing a [service account](https://cloud.google.com/docs/authentication#service-accounts)\nkey file, either set the `GOOGLE_APPLICATION_CREDENTIALS` environment variable to the path\nto your key file, or programmatically pass\n[`option.WithCredentialsFile`](https://pkg.go.dev/google.golang.org/api/option#WithCredentialsFile)\nto the `NewClient` function of the desired package. For example:\n\n```go\nclient, err := storage.NewClient(ctx, option.WithCredentialsFile(\"path/to/keyfile.json\"))\n```\n\nYou can exert even more control over authentication by using the\n[credentials](https://pkg.go.dev/cloud.google.com/go/auth/credentials) package to\ncreate an [auth.Credentials](https://pkg.go.dev/cloud.google.com/go/auth#Credentials).\nThen pass [`option.WithAuthCredentials`](https://pkg.go.dev/google.golang.org/api/option#WithAuthCredentials)\nto the `NewClient` function:\n\n```go\ncreds, err := credentials.DetectDefault(&credentials.DetectOptions{...})\n...\nclient, err := storage.NewClient(ctx, option.WithAuthCredentials(creds))\n```\n\n## Contributing\n\nContributions are welcome. Please, see the\n[CONTRIBUTING](https://github.com/GoogleCloudPlatform/google-cloud-go/blob/main/CONTRIBUTING.md)\ndocument for details.\n\nPlease note that this project is released with a Contributor Code of Conduct.\nBy participating in this project you agree to abide by its terms.\nSee [Contributor Code of Conduct](https://github.com/GoogleCloudPlatform/google-cloud-go/blob/main/CONTRIBUTING.md#contributor-code-of-conduct)\nfor more information.\n\n## Links\n\n- [Go on Google Cloud](https://cloud.google.com/go/home)\n- [Getting started with Go on Google Cloud](https://cloud.google.com/go/getting-started)\n- [App Engine Quickstart](https://cloud.google.com/appengine/docs/standard/go/quickstart)\n- [Cloud Functions Quickstart](https://cloud.google.com/functions/docs/quickstart-go)\n- [Cloud Run Quickstart](https://cloud.google.com/run/docs/quickstarts/build-and-deploy#go)\n",
      "stars_today": 1
    },
    {
      "id": 96496250,
      "name": "swift-snapshot-testing",
      "full_name": "pointfreeco/swift-snapshot-testing",
      "description": "üì∏ Delightful Swift snapshot testing.",
      "html_url": "https://github.com/pointfreeco/swift-snapshot-testing",
      "stars": 4114,
      "forks": 643,
      "language": "Swift",
      "topics": [
        "screenshot-testing",
        "snapshot-testing",
        "swift",
        "testing"
      ],
      "created_at": "2017-07-07T03:38:51Z",
      "updated_at": "2026-01-23T02:27:33Z",
      "pushed_at": "2025-11-17T17:51:33Z",
      "open_issues": 195,
      "owner": {
        "login": "pointfreeco",
        "avatar_url": "https://avatars.githubusercontent.com/u/29466629?v=4"
      },
      "readme": "# üì∏ SnapshotTesting\n\n[![CI](https://github.com/pointfreeco/swift-snapshot-testing/workflows/CI/badge.svg)](https://actions-badge.atrox.dev/pointfreeco/swift-snapshot-testing/goto)\n[![Slack](https://img.shields.io/badge/slack-chat-informational.svg?label=Slack&logo=slack)](http://pointfree.co/slack-invite)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-snapshot-testing%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-snapshot-testing%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing)\n\nDelightful Swift snapshot testing.\n\n## Usage\n\nOnce [installed](#installation), _no additional configuration is required_. You can import the\n`SnapshotTesting` module and call the `assertSnapshot` function.\n\n``` swift\nimport SnapshotTesting\nimport Testing\n\n@MainActor\nstruct MyViewControllerTests {\n  @Test func myViewController() {\n    let vc = MyViewController()\n\n    assertSnapshot(of: vc, as: .image)\n  }\n}\n```\n\nWhen an assertion first runs, a snapshot is automatically recorded to disk and the test will fail,\nprinting out the file path of any newly-recorded reference.\n\n> ‚ùå failed - No reference was found on disk. Automatically recorded snapshot: ‚Ä¶\n>\n> open \"‚Ä¶/MyAppTests/\\_\\_Snapshots\\_\\_/MyViewControllerTests/testMyViewController.png\"\n>\n> Re-run \"testMyViewController\" to test against the newly-recorded snapshot.\n\nRepeat test runs will load this reference and compare it with the runtime value. If they don't\nmatch, the test will fail and describe the difference. Failures can be inspected from Xcode's Report\nNavigator or by inspecting the file URLs of the failure.\n\nYou can record a new reference by customizing snapshots inline with the assertion, or using the\n`withSnapshotTesting` tool:\n\n```swift\n// Record just this one snapshot\nassertSnapshot(of: vc, as: .image, record: .all)\n\n// Record all snapshots in a scope:\nwithSnapshotTesting(record: .all) {\n  assertSnapshot(of: vc1, as: .image)\n  assertSnapshot(of: vc2, as: .image)\n  assertSnapshot(of: vc3, as: .image)\n}\n\n// Record all snapshot failures in a Swift Testing suite:\n@Suite(.snapshots(record: .failed))\nstruct FeatureTests {}\n\n// Record all snapshot failures in an 'XCTestCase' subclass:\nclass FeatureTests: XCTestCase {\n  override func invokeTest() {\n    withSnapshotTesting(record: .failed) {\n      super.invokeTest()\n    }\n  }\n}\n```\n\n## Snapshot Anything\n\nWhile most snapshot testing libraries in the Swift community are limited to `UIImage`s of `UIView`s,\nSnapshotTesting can work with _any_ format of _any_ value on _any_ Swift platform!\n\nThe `assertSnapshot` function accepts a value and any snapshot strategy that value supports. This\nmeans that a view or view controller can be tested against an image representation _and_ against a\ntextual representation of its properties and subview hierarchy.\n\n``` swift\nassertSnapshot(of: vc, as: .image)\nassertSnapshot(of: vc, as: .recursiveDescription)\n```\n\nView testing is highly configurable. You can override trait collections (for specific size classes\nand content size categories) and generate device-agnostic snapshots, all from a single simulator.\n\n``` swift\nassertSnapshot(of: vc, as: .image(on: .iPhoneSe))\nassertSnapshot(of: vc, as: .recursiveDescription(on: .iPhoneSe))\n\nassertSnapshot(of: vc, as: .image(on: .iPhoneSe(.landscape)))\nassertSnapshot(of: vc, as: .recursiveDescription(on: .iPhoneSe(.landscape)))\n\nassertSnapshot(of: vc, as: .image(on: .iPhoneX))\nassertSnapshot(of: vc, as: .recursiveDescription(on: .iPhoneX))\n\nassertSnapshot(of: vc, as: .image(on: .iPadMini(.portrait)))\nassertSnapshot(of: vc, as: .recursiveDescription(on: .iPadMini(.portrait)))\n```\n\n> **Warning**\n> Snapshots must be compared using the exact same simulator that originally took the reference to\n> avoid discrepancies between images.\n\nBetter yet, SnapshotTesting isn't limited to views and view controllers! There are a number of\navailable snapshot strategies to choose from.\n\nFor example, you can snapshot test URL requests (_e.g._, those that your API client prepares).\n\n``` swift\nassertSnapshot(of: urlRequest, as: .raw)\n// POST http://localhost:8080/account\n// Cookie: pf_session={\"userId\":\"1\"}\n//\n// email=blob%40pointfree.co&name=Blob\n```\n\nAnd you can snapshot test `Encodable` values against their JSON _and_ property list representations.\n\n``` swift\nassertSnapshot(of: user, as: .json)\n// {\n//   \"bio\" : \"Blobbed around the world.\",\n//   \"id\" : 1,\n//   \"name\" : \"Blobby\"\n// }\n\nassertSnapshot(of: user, as: .plist)\n// <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n// <!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\"\n//  \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n// <plist version=\"1.0\">\n// <dict>\n//   <key>bio</key>\n//   <string>Blobbed around the world.</string>\n//   <key>id</key>\n//   <integer>1</integer>\n//   <key>name</key>\n//   <string>Blobby</string>\n// </dict>\n// </plist>\n```\n\nIn fact, _any_ value can be snapshot-tested by default using its\n[mirror](https://developer.apple.com/documentation/swift/mirror)!\n\n``` swift\nassertSnapshot(of: user, as: .dump)\n// ‚ñø User\n//   - bio: \"Blobbed around the world.\"\n//   - id: 1\n//   - name: \"Blobby\"\n```\n\nIf your data can be represented as an image, text, or data, you can write a snapshot test for it!\n\n## Documentation\n\nThe latest documentation is available\n[here](https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing/main/documentation/snapshottesting).\n\n## Installation\n\n### Xcode\n\n> **Warning**\n> By default, Xcode will try to add the SnapshotTesting package to your project's main\n> application/framework target. Please ensure that SnapshotTesting is added to a _test_ target\n> instead, as documented in the last step, below.\n\n 1. From the **File** menu, navigate through **Swift Packages** and select\n    **Add Package Dependency‚Ä¶**.\n 2. Enter package repository URL: `https://github.com/pointfreeco/swift-snapshot-testing`.\n 3. Confirm the version and let Xcode resolve the package.\n 4. On the final dialog, update SnapshotTesting's **Add to Target** column to a test target that\n    will contain snapshot tests (if you have more than one test target, you can later add\n    SnapshotTesting to them by manually linking the library in its build phase).\n\n### Swift Package Manager\n\nIf you want to use SnapshotTesting in any other project that uses\n[SwiftPM](https://swift.org/package-manager/), add the package as a dependency in `Package.swift`:\n\n```swift\ndependencies: [\n  .package(\n    url: \"https://github.com/pointfreeco/swift-snapshot-testing\",\n    from: \"1.12.0\"\n  ),\n]\n```\n\nNext, add `SnapshotTesting` as a dependency of your test target:\n\n```swift\ntargets: [\n  .target(name: \"MyApp\"),\n  .testTarget(\n    name: \"MyAppTests\",\n    dependencies: [\n      \"MyApp\",\n      .product(name: \"SnapshotTesting\", package: \"swift-snapshot-testing\"),\n    ]\n  )\n]\n```\n\n## Features\n\n  - [**Dozens of snapshot strategies**][available-strategies]. Snapshot\n    testing isn't just for `UIView`s and `CALayer`s. Write snapshots against _any_ value.\n  - [**Write your own snapshot strategies**][defining-strategies].\n    If you can convert it to an image, string, data, or your own diffable format, you can snapshot\n    test it! Build your own snapshot strategies from scratch or transform existing ones.\n  - **No configuration required.** Don't fuss with scheme settings and environment variables.\n    Snapshots are automatically saved alongside your tests.\n  - **More hands-off.** New snapshots are recorded whether `isRecording` mode is `true` or not.\n  - **Subclass-free.** Assert from any XCTest case or Quick spec.\n  - **Device-agnostic snapshots.** Render views and view controllers for specific devices and trait\n    collections from a single simulator.\n  - **First-class Xcode support.** Image differences are captured as XCTest attachments. Text\n    differences are rendered in inline error messages.\n  - **Supports any platform that supports Swift.** Write snapshot tests for iOS, Linux, macOS, and\n    tvOS.\n  - **SceneKit, SpriteKit, and WebKit support.** Most snapshot testing libraries don't support these\n    view subclasses.\n  - **`Codable` support**. Snapshot encodable data structures into their JSON and property list\n    representations.\n  - **Custom diff tool integration**. Configure failure messages to print diff commands for\n    [Kaleidoscope](https://kaleidoscope.app) or your diff tool of choice.\n    ``` swift\n    SnapshotTesting.diffToolCommand = { \"ksdiff \\($0) \\($1)\" }\n    ```\n\n[available-strategies]: https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing/main/documentation/snapshottesting/snapshotting\n[defining-strategies]: https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing/main/documentation/snapshottesting/customstrategies\n\n## Plug-ins\n\n  - [AccessibilitySnapshot](https://github.com/cashapp/AccessibilitySnapshot) adds easy regression\n    testing for iOS accessibility.\n    \n  - [AccessibilitySnapshotColorBlindness](https://github.com/Sherlouk/AccessibilitySnapshotColorBlindness)\n    adds snapshot strategies for color blindness simulation on iOS views, view controllers and images.\n\n  - [GRDBSnapshotTesting](https://github.com/SebastianOsinski/GRDBSnapshotTesting) adds snapshot\n    strategy for testing SQLite database migrations made with [GRDB](https://github.com/groue/GRDB.swift).\n\n  - [Nimble-SnapshotTesting](https://github.com/tahirmt/Nimble-SnapshotTesting) adds \n    [Nimble](https://github.com/Quick/Nimble) matchers for SnapshotTesting to be used by Swift\n    Package Manager.\n\n  - [Prefire](https://github.com/BarredEwe/Prefire) generating Snapshot Tests via\n    [Swift Package Plugins](https://github.com/apple/swift-package-manager/blob/main/Documentation/Plugins.md)\n    using SwiftUI `Preview`\n  \n  - [PreviewSnapshots](https://github.com/doordash-oss/swiftui-preview-snapshots) share `View`\n    configurations between SwiftUI Previews and snapshot tests and generate several snapshots with a\n    single test assertion.\n\n  - [swift-html](https://github.com/pointfreeco/swift-html) is a Swift DSL for type-safe,\n    extensible, and transformable HTML documents and includes an `HtmlSnapshotTesting` module to\n    snapshot test its HTML documents.\n\n  - [swift-snapshot-testing-nimble](https://github.com/Killectro/swift-snapshot-testing-nimble) adds\n    [Nimble](https://github.com/Quick/Nimble) matchers for SnapshotTesting.\n\n  - [swift-snapshot-testing-stitch](https://github.com/Sherlouk/swift-snapshot-testing-stitch/) adds\n    the ability to stitch multiple UIView's or UIViewController's together in a single test.\n\n  - [SnapshotTestingDump](https://github.com/tahirmt/swift-snapshot-testing-dump) Adds support to\n    use [swift-custom-dump](https://github.com/pointfreeco/swift-custom-dump/) by using `customDump`\n    strategy for `Any`\n\n  - [SnapshotTestingHEIC](https://github.com/alexey1312/SnapshotTestingHEIC) adds image support\n  using the HEIC storage format which reduces file sizes in comparison to PNG.\n\n  - [SnapshotVision](https://github.com/gregersson/swift-snapshot-testing-vision) adds snapshot\n    strategy for text recognition on views and images. Uses Apples Vision framework.\n\nHave you written your own SnapshotTesting plug-in?\n[Add it here](https://github.com/pointfreeco/swift-snapshot-testing/edit/master/README.md) and\nsubmit a pull request!\n\n## Related Tools\n\n  - [`iOSSnapshotTestCase`](https://github.com/uber/ios-snapshot-test-case/) helped introduce screen\n    shot testing to a broad audience in the iOS community. Experience with it inspired the creation\n    of this library.\n\n  - [Jest](https://jestjs.io) brought generalized snapshot testing to the JavaScript community with\n    a polished user experience. Several features of this library (diffing, automatically capturing\n    new snapshots) were directly influenced.\n\n## Learn More\n\nSnapshotTesting was designed with [witness-oriented programming](https://www.pointfree.co/episodes/ep39-witness-oriented-library-design).\n\nThis concept (and more) are explored thoroughly in a series of episodes on\n[Point-Free](https://www.pointfree.co), a video series exploring functional programming and Swift\nhosted by [Brandon Williams](https://twitter.com/mbrandonw) and\n[Stephen Celis](https://twitter.com/stephencelis).\n\nWitness-oriented programming and the design of this library was explored in the following\n[Point-Free](https://www.pointfree.co) episodes:\n\n  - [Episode 33](https://www.pointfree.co/episodes/ep33-protocol-witnesses-part-1): Protocol Witnesses: Part 1\n  - [Episode 34](https://www.pointfree.co/episodes/ep34-protocol-witnesses-part-1): Protocol Witnesses: Part 2\n  - [Episode 35](https://www.pointfree.co/episodes/ep35-advanced-protocol-witnesses-part-1): Advanced Protocol Witnesses: Part 1\n  - [Episode 36](https://www.pointfree.co/episodes/ep36-advanced-protocol-witnesses-part-2): Advanced Protocol Witnesses: Part 2\n  - [Episode 37](https://www.pointfree.co/episodes/ep37-protocol-oriented-library-design-part-1): Protocol-Oriented Library Design: Part 1\n  - [Episode 38](https://www.pointfree.co/episodes/ep38-protocol-oriented-library-design-part-2): Protocol-Oriented Library Design: Part 2\n  - [Episode 39](https://www.pointfree.co/episodes/ep39-witness-oriented-library-design): Witness-Oriented Library Design\n  - [Episode 40](https://www.pointfree.co/episodes/ep40-async-functional-refactoring): Async Functional Refactoring\n  - [Episode 41](https://www.pointfree.co/episodes/ep41-a-tour-of-snapshot-testing): A Tour of Snapshot Testing üÜì\n\n<a href=\"https://www.pointfree.co/episodes/ep41-a-tour-of-snapshot-testing\">\n  <img alt=\"video poster image\" src=\"https://d3rccdn33rt8ze.cloudfront.net/episodes/0041.jpeg\" width=\"480\">\n</a>\n\n## License\n\nThis library is released under the MIT license. See [LICENSE](LICENSE) for details.\n",
      "stars_today": 1
    },
    {
      "id": 35927665,
      "name": "seurat",
      "full_name": "satijalab/seurat",
      "description": "R toolkit for single cell genomics",
      "html_url": "https://github.com/satijalab/seurat",
      "stars": 2620,
      "forks": 977,
      "language": "R",
      "topics": [
        "cran",
        "human-cell-atlas",
        "single-cell-genomics",
        "single-cell-rna-seq"
      ],
      "created_at": "2015-05-20T05:23:02Z",
      "updated_at": "2026-01-23T15:32:24Z",
      "pushed_at": "2026-01-21T19:54:02Z",
      "open_issues": 313,
      "owner": {
        "login": "satijalab",
        "avatar_url": "https://avatars.githubusercontent.com/u/8411851?v=4"
      },
      "readme": "[![CRAN Version](https://www.r-pkg.org/badges/version/Seurat)](https://cran.r-project.org/package=Seurat)\n[![CRAN Downloads](https://cranlogs.r-pkg.org/badges/Seurat)](https://cran.r-project.org/package=Seurat)\n\n\n# Seurat v5\n\nSeurat is an R toolkit for single cell genomics, developed and maintained by the Satija Lab at NYGC.\n\nWe are excited to release Seurat v5! This updates introduces new functionality for spatial, multimodal, and scalable single-cell analysis.\n\nSeurat v5 is backwards-compatible with previous versions, so that users will continue to be able to re-run existing workflows. \n\nInstructions, documentation, and tutorials can be found at:\n\n* https://satijalab.org/seurat\n\nSeurat is also hosted on GitHub, you can view and clone the repository at\n\n* https://github.com/satijalab/seurat\n\nSeurat has been successfully installed on Mac OS X, Linux, and Windows, using the devtools package to install directly from GitHub\n\nImprovements and new features will be added on a regular basis, please post on the [github page](https://github.com/satijalab/seurat) with any questions or if you would like to contribute\n\nFor a version history/changelog, please see the [NEWS file](https://github.com/satijalab/seurat/blob/master/NEWS.md).\n",
      "stars_today": 1
    },
    {
      "id": 143079594,
      "name": "swift-syntax",
      "full_name": "swiftlang/swift-syntax",
      "description": "A set of Swift libraries for parsing, inspecting, generating, and transforming Swift source code.",
      "html_url": "https://github.com/swiftlang/swift-syntax",
      "stars": 3602,
      "forks": 485,
      "language": "Swift",
      "topics": [],
      "created_at": "2018-07-31T23:19:58Z",
      "updated_at": "2026-01-23T12:56:31Z",
      "pushed_at": "2026-01-22T06:08:27Z",
      "open_issues": 152,
      "owner": {
        "login": "swiftlang",
        "avatar_url": "https://avatars.githubusercontent.com/u/42816656?v=4"
      },
      "readme": "# Swift Syntax\n\nThe swift-syntax package is a set of libraries that work on a source-accurate tree representation of Swift source code, called the SwiftSyntax tree. The SwiftSyntax tree forms the backbone of Swift‚Äôs macro system ‚Äì the macro expansion nodes are represented as SwiftSyntax nodes and a macro generates a SwiftSyntax tree to be inserted into the source file.\n\n## Documentation\n\nYou can read SwiftSyntax‚Äôs documentation on [swiftpackageindex.com](https://swiftpackageindex.com/swiftlang/swift-syntax/documentation).\n\nA great way to interactively explore the SwiftSyntax tree of a source file is https://swift-ast-explorer.com, developed by [@kishikawakatsumi](https://github.com/kishikawakatsumi).\n\nA set of example usages of swift-syntax can be found in [Examples](Examples).\n\n## Releases\n\nReleases of SwiftSyntax are aligned with corresponding language and tooling releases, for example the major version 509 of swift-syntax is aligned with Swift 5.9. \n \nTo depend on swift-syntax in a SwiftPM package, add the following to your `Package.swift`.\n\n\n```swift\ndependencies: [\n  .package(url: \"https://github.com/swiftlang/swift-syntax.git\", from: \"<#latest swift-syntax tag#>\"),\n],\n```\n \nTo add swift-syntax as a dependency of your Xcode project, go to the *Package Dependencies* tab of your Xcode project, click the plus button and search for https://github.com/swiftlang/swift-syntax.git.\n\n## Reporting Issues\n\nIf you should hit any issues while using SwiftSyntax, we appreciate bug reports on [GitHub Issue](https://github.com/swiftlang/swift-syntax/issues).\n\n## Contributing\n\nStart contributing to SwiftSyntax see [this guide](CONTRIBUTING.md) for more information.\n\n## Bazel\n\nSwiftSyntax provides an experimental [Bazel](https://bazel.build) build configuration, maintained by Keith Smiley. \nTo use it, you can pull the source archive from the relevant release tag\ninto your `MODULE.bazel` file (preferred and recommended) with `bazel_dep`. Bzlmod support was added starting release of `509.0.0` and above. All available versions can be found in the [Bazel Central Registry](https://registry.bazel.build/modules/swift-syntax)\n\n```python3\nbazel_dep(name = \"swift-syntax\", version = \"600.0.1\")\n```\n\nYou can also pull source archive with `WORKSPACE` but note that it is preferred to use `MODULE.bazel`. To use `WORKSPACE` and swift-syntax, you can use `http_archive` as such\n\n```python3\nhttp_archive(\n    name = \"SwiftSyntax\",\n    sha256 = \"f070fd44db9b33f430fd5b5d2700f1e2001c0028711859600e80cc975074fab0\",\n    strip_prefix = \"swift-syntax-509.1.0\",\n    url = \"https://github.com/apple/swift-syntax/archive/refs/tags/509.1.0.tar.gz\",\n)\n```\n\nand depend on the libraries you need from the\n[`BUILD.bazel`](BUILD.bazel) file. Each library also has an associated\n`Library_opt` target (such as `SwiftSyntax_opt`) which forces\nSwiftSyntax to always build with optimizations enabled. This may help\nlocal runtime performance at the cost of debuggability, and initial\nbuild time. Please tag any [issues](https://github.com/swiftlang/swift-syntax/issues) related to the Bazel configuration with the label \"Bazel\".\n\n## License\n\nPlease see [LICENSE](LICENSE.txt) for more information.\n",
      "stars_today": 1
    },
    {
      "id": 546522002,
      "name": "element-x-android",
      "full_name": "element-hq/element-x-android",
      "description": "Android Matrix messenger application using the Matrix Rust Sdk and Jetpack Compose",
      "html_url": "https://github.com/element-hq/element-x-android",
      "stars": 1786,
      "forks": 382,
      "language": "Kotlin",
      "topics": [
        "hacktoberfest",
        "matrix"
      ],
      "created_at": "2022-10-06T07:59:24Z",
      "updated_at": "2026-01-23T20:07:51Z",
      "pushed_at": "2026-01-23T22:44:56Z",
      "open_issues": 560,
      "owner": {
        "login": "element-hq",
        "avatar_url": "https://avatars.githubusercontent.com/u/13446337?v=4"
      },
      "readme": "[![Latest build](https://github.com/element-hq/element-x-android/actions/workflows/build.yml/badge.svg?query=branch%3Adevelop)](https://github.com/element-hq/element-x-android/actions/workflows/build.yml?query=branch%3Adevelop)\n[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=element-x-android&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=element-x-android)\n[![Vulnerabilities](https://sonarcloud.io/api/project_badges/measure?project=element-x-android&metric=vulnerabilities)](https://sonarcloud.io/summary/new_code?id=element-x-android)\n[![Bugs](https://sonarcloud.io/api/project_badges/measure?project=element-x-android&metric=bugs)](https://sonarcloud.io/summary/new_code?id=element-x-android)\n[![codecov](https://codecov.io/github/element-hq/element-x-android/branch/develop/graph/badge.svg?token=ecwvia7amV)](https://codecov.io/github/element-hq/element-x-android)\n[![Element X Android Matrix room #element-x-android:matrix.org](https://img.shields.io/matrix/element-x-android:matrix.org.svg?label=%23element-x-android:matrix.org&logo=matrix&server_fqdn=matrix.org)](https://matrix.to/#/#element-x-android:matrix.org)\n[![Localazy](https://img.shields.io/endpoint?url=https%3A%2F%2Fconnect.localazy.com%2Fstatus%2Felement%2Fdata%3Fcontent%3Dall%26title%3Dlocalazy%26logo%3Dtrue)](https://localazy.com/p/element)\n\n# Element X Android\n\nElement X Android is the next-generation [Matrix](https://matrix.org/) client provided by [Element](https://element.io/).\n\nCompared to the previous-generation [Element Classic](https://github.com/element-hq/element-android), the application is a total rewrite, using the [Matrix Rust SDK](https://github.com/matrix-org/matrix-rust-sdk) underneath and targeting devices running Android 7+. The UI layer is written using [Jetpack Compose](https://developer.android.com/jetpack/compose), and the navigation is managed using [Appyx](https://github.com/bumble-tech/appyx).\n\n[<img src=\"https://play.google.com/intl/en_us/badges/static/images/badges/en_badge_web_generic.png\" alt=\"Get it on Google Play\" height=\"80\">](https://play.google.com/store/apps/details?id=io.element.android.x)[<img src=\"https://fdroid.gitlab.io/artwork/badge/get-it-on.png\" alt=\"Get it on F-Droid\" height=\"80\">](https://f-droid.org/packages/io.element.android.x)\n\n## Table of contents\n\n<!--- TOC -->\n\n* [Screenshots](#screenshots)\n* [Translations](#translations)\n* [Rust SDK](#rust-sdk)\n* [Status](#status)\n* [Minimum SDK version](#minimum-sdk-version)\n* [Contributing](#contributing)\n* [Build instructions](#build-instructions)\n* [Support](#support)\n* [Copyright and License](#copyright-and-license)\n\n<!--- END -->\n\n## Screenshots\n\nHere are some screenshots of the application:\n\n<!--\nCommands run before taking the screenshots:\nadb shell settings put system time_12_24 24\nadb shell am broadcast -a com.android.systemui.demo -e command enter\nadb shell am broadcast -a com.android.systemui.demo -e command clock -e hhmm 1337\nadb shell am broadcast -a com.android.systemui.demo -e command network -e mobile show -e level 4\nadb shell am broadcast -a com.android.systemui.demo -e command network -e wifi show -e level 4\nadb shell am broadcast -a com.android.systemui.demo -e command notifications -e visible false\nadb shell am broadcast -a com.android.systemui.demo -e command battery -e plugged false -e level 100\n\nAnd to exit demo mode:\nadb shell am broadcast -a com.android.systemui.demo -e command exit\n-->\n\n|<img src=\"./docs/images-lfs/screen_1_light.png\" width=\"280\" />|<img src=\"./docs/images-lfs/screen_2_light.png\" width=\"280\" />|<img src=\"./docs/images-lfs/screen_3_light.png\" width=\"280\" />|<img src=\"./docs/images-lfs/screen_4_light.png\" width=\"280\" />|\n|-|-|-|-|\n|<img src=\"./docs/images-lfs/screen_1_dark.png\" width=\"280\" />|<img src=\"./docs/images-lfs/screen_2_dark.png\" width=\"280\" />|<img src=\"./docs/images-lfs/screen_3_dark.png\" width=\"280\" />|<img src=\"./docs/images-lfs/screen_4_dark.png\" width=\"280\" />|\n\n## Translations\n\nElement X Android supports many languages. You can help us to translate the app in your language by joining our [Localazy project](https://localazy.com/p/element). You can also help us to improve the existing translations.\n\nNote that for now, we keep control on the French and German translations.\n\nTranslations can be checked screen per screen using our tool Element X Android Gallery, available at https://element-hq.github.io/element-x-android/. Note that this page is updated every Tuesday.\n\nMore instructions about translating the application can be found at [CONTRIBUTING.md](CONTRIBUTING.md#strings).\n\n## Rust SDK\n\nElement X leverages the [Matrix Rust SDK](https://github.com/matrix-org/matrix-rust-sdk) through an FFI layer that the final client can directly import and use.\n\nWe're doing this as a way to share code between platforms and while we've seen promising results it's still in the experimental stage and bound to change.\n\n## Status\n\nThis project is actively developed and supported. New users are recommended to use Element X instead of the previous-generation app.\n\n## Minimum SDK version\n\nElement X Android requires a minimum SDK version of 24 (Android 7.0, Nougat). We aim to support devices running Android 7.0 and above, which covers a wide range of devices still in use today.\n\nElement Android Enterprise requires a minimum SDK version of 33 (Android 13, Tiramisu). For Element Enterprise, we support only devices that still receive security updates, which means devices running Android 13 and above. Android does not have a documented support policy, but some information can be found at [https://endoflife.date/android](https://endoflife.date/android).\n\n## Contributing\n\nWant to get actively involved in the project? You're more than welcome! A good way to start is to check the issues that are labelled with the [good first issue](https://github.com/element-hq/element-x-android/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) label. Let us know by commenting the issue that you're starting working on it.\n\nBut first make sure to read our [contribution guide](CONTRIBUTING.md) first.\n\nYou can also come chat with the community in the Matrix [room](https://matrix.to/#/#element-x-android:matrix.org) dedicated to the project.\n\n## Build instructions\n\nJust clone the project and open it in Android Studio. Make sure to select the\n`app` configuration when building (as we also have sample apps in the project).\n\nTo build against a local copy of the Rust SDK, see the [Developer\nonboarding](docs/_developer_onboarding.md#building-the-sdk-locally) instructions.\n\n## Support\n\nWhen you are experiencing an issue on Element X Android, please first search in [GitHub issues](https://github.com/element-hq/element-x-android/issues)\nand then in [#element-x-android:matrix.org](https://matrix.to/#/#element-x-android:matrix.org).\nIf after your research you still have a question, ask at [#element-x-android:matrix.org](https://matrix.to/#/#element-x-android:matrix.org). Otherwise feel free to create a GitHub issue if you encounter a bug or a crash, by explaining clearly in detail what happened. You can also perform bug reporting from the application settings. This is especially recommended when you encounter a crash.\n\n## Copyright and License\n\nCopyright (c) 2025 Element Creations Ltd.\nCopyright (c) 2022 - 2025 New Vector Ltd.\n\nThis software is dual licensed by Element Creations Ltd (Element). It can be used either:\n\n(1) for free under the terms of the GNU Affero General Public License (as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version); OR\n\n(2) under the terms of a paid-for Element Commercial License agreement between you and Element (the terms of which may vary depending on what you and Element have agreed to).\n\nUnless required by applicable law or agreed to in writing, software distributed under the Licenses is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the Licenses for the specific language governing permissions and limitations under the Licenses.\n",
      "stars_today": 1
    },
    {
      "id": 730759265,
      "name": "iceoryx2",
      "full_name": "eclipse-iceoryx/iceoryx2",
      "description": "Eclipse iceoryx2‚Ñ¢ - true zero-copy inter-process-communication with a Rust core",
      "html_url": "https://github.com/eclipse-iceoryx/iceoryx2",
      "stars": 2002,
      "forks": 113,
      "language": "Rust",
      "topics": [
        "eclipse",
        "iceoryx",
        "inter-process-communication",
        "ipc",
        "middleware",
        "publish-subscribe",
        "pubsub",
        "request-response",
        "rpc",
        "rust",
        "shared-memory",
        "zero-copy"
      ],
      "created_at": "2023-12-12T16:00:07Z",
      "updated_at": "2026-01-24T00:06:19Z",
      "pushed_at": "2026-01-23T18:13:38Z",
      "open_issues": 187,
      "owner": {
        "login": "eclipse-iceoryx",
        "avatar_url": "https://avatars.githubusercontent.com/u/69006087?v=4"
      },
      "readme": "<!-- markdownlint-disable -->\n\n[![CI](https://github.com/eclipse-iceoryx/iceoryx2/workflows/CI/badge.svg)](https://github.com/eclipse-iceoryx/iceoryx2/actions/workflows/build-test.yml?query=branch%3Amain++)\n[![Codecov](https://codecov.io/gh/eclipse-iceoryx/iceoryx2/branch/main/graph/badge.svg?branch=main)](https://codecov.io/gh/eclipse-iceoryx/iceoryx2?branch=main)\n[![Examples](https://img.shields.io/badge/Examples-gray)](examples/)\n[![FAQ](https://img.shields.io/badge/FAQ-gray)](FAQ.md)\n[![Gitter](https://badges.gitter.im/eclipse-iceoryx/iceoryx.svg)](https://gitter.im/eclipse/iceoryx)\n[![Developer Meetup](https://img.shields.io/badge/Developer_Meetup-gray?style=social)](https://github.com/eclipse-iceoryx/iceoryx2/wiki/Developer-Meetup)\n[![Roadmap](https://img.shields.io/badge/Roadmap-gray)](ROADMAP.md)\n\n<p align=\"center\">\n<img src=\"https://github.com/eclipse-iceoryx/iceoryx2/assets/56729169/3230a125-19e5-4e98-a752-da026a086782\" width=\"50%\">\n</p>\n\n<!-- markdownlint-enable -->\n\n# iceoryx2 - Zero-Copy Lock-Free IPC with a Rust Core\n\n* [Introduction](#introduction)\n* [Performance](#performance)\n    * [Comparision Of Mechanisms](#comparision-of-mechanisms)\n        * [Benchmark-System](#benchmark-system)\n    * [Comparision Of Architectures](#comparision-of-architectures)\n* [Documentation](#documentation)\n    * [User Documentation](#user-documentation)\n    * [Contributor Documentation](#contributor-documentation)\n    * [API References](#api-references)\n* [Supported Platforms](#supported-platforms)\n* [Language Bindings](#language-bindings)\n* [Commercial Support](#commercial-support)\n* [Thanks To All Contributors](#thanks-to-all-contributors)\n\n## Introduction\n\nWelcome to iceoryx2, the efficient, and ultra-low latency inter-process\ncommunication middleware. This library is designed to provide you with fast and\nreliable zero-copy and lock-free inter-process communication mechanisms.\n\nSo if you want to communicate efficiently between multiple processes or\napplications iceoryx2 is for you. With iceoryx2, you can:\n\n* Send huge amounts of data using a publish/subscribe, request/response,\n  pipeline (planned) or blackboard pattern (planned), making it ideal\n  for scenarios where large datasets need to be shared.\n* Exchange signals through events, enabling quick and reliable signaling between\n  processes.\n\niceoryx2 is based on a service-oriented architecture (SOA) and facilitates\nseamless inter-process communication (IPC).\n\nIt is all about providing a seamless experience for inter-process communication,\nfeaturing versatile messaging patterns. Whether you're diving into\npublish-subscribe, events, request-response, or the promise of upcoming features\nlike pipelines, and blackboard, iceoryx2 has you covered.\n\nOne of the features of iceoryx2 is its consistently low transmission latency\nregardless of payload size, ensuring a predictable and reliable communication\nexperience.\n\niceoryx2's origins can be traced back to\n[iceoryx](https://github.com/eclipse-iceoryx/iceoryx). By overcoming past\ntechnical debts and refining the architecture, iceoryx2 enables the modularity\nwe've always desired.\n\nIn the near future, iceoryx2 is poised to support at least the same feature set\nand platforms as [iceoryx](https://github.com/eclipse-iceoryx/iceoryx), ensuring\na seamless transition and offering enhanced capabilities for your inter-process\ncommunication needs. So, if you're looking for lightning-fast, cross-platform\ncommunication that doesn't compromise on performance or modularity, iceoryx2 is\nyour answer.\n\nFeel free to join the [Gitter Chat](https://gitter.im/eclipse/iceoryx) or\nthe [Developer Meetup](https://github.com/eclipse-iceoryx/iceoryx2/wiki/Developer-Meetup)\nif you want to have a chat with the developers of iceoryx.\n\n## Performance\n\n### Comparision Of Mechanisms\n\n![benchmark of different mechanism](https://raw.githubusercontent.com/eclipse-iceoryx/iceoryx2/refs/heads/main/internal/plots/benchmark_mechanism.svg)\n\n#### Benchmark-System\n\n* **CPU:** Intel i7 13700h\n* **OS:** Linux 6.10.10-arch1-1 #1 SMP PREEMPT_DYNAMIC\n* **Compiler:**\n    * rustc 1.81.0\n    * gcc 14.2.1 20240910\n\n### Comparision Of Architectures\n\n![benchmark on different systems](https://raw.githubusercontent.com/eclipse-iceoryx/iceoryx2/refs/heads/main/internal/plots/benchmark_architecture.svg)\n\n## Documentation\n\n### User Documentation\n\n* [The iceoryx2 Book](https://ekxide.github.io/iceoryx2-book) (by [ekxide](https://ekxide.io))\n* [Examples](examples)\n* [Release Notes](doc/release-notes)\n* [User FAQ](FAQ.md)\n\n### Contributor Documentation\n\n* [Contributor FAQ](FAQ_ICEORYX_DEVS.md)\n\n### API References\n\n* [Rust API Reference](https://docs.rs/iceoryx2/latest/iceoryx2/)\n* [Python API Reference](https://eclipse-iceoryx.github.io/iceoryx2/python/latest/)\n* [C++ API Reference](https://eclipse-iceoryx.github.io/iceoryx2/cxx/latest/)\n* [C API Reference](https://eclipse-iceoryx.github.io/iceoryx2/c/latest/)\n\n## Supported Platforms\n\nThe support levels can be adjusted when required.\n\n| Operating System | State                    | Current Support Level | Target Support Level |\n| ---------------- | :----------------------- | :-------------------: | -------------------: |\n| Android          | proof-of-concept[^1]     |           -           |               tier 1 |\n| Bare Metal       | proof-of-concept[^2]     |           -           |               tier 1 |\n| FreeBSD          | done                     |        tier 2         |               tier 1 |\n| FreeRTOS         | planned                  |           -           |               tier 2 |\n| ThreadX          | planned                  |           -           |               tier 2 |\n| iOS              | planned                  |           -           |               tier 2 |\n| Linux (x86_64)   | done                     |        tier 2         |               tier 1 |\n| Linux (aarch64)  | done                     |        tier 2         |               tier 1 |\n| Linux (32-bit)   | done                     |        tier 2         |               tier 1 |\n| Mac OS           | done                     |        tier 2         |               tier 2 |\n| QNX 7.1          | done                     |        tier 3         |               tier 1 |\n| QNX 8.0          | done                     |        tier 3         |               tier 1 |\n| VxWorks          | proof-of-concept[^3]     |           -           |               tier 1 |\n| WatchOS          | planned                  |           -           |               tier 2 |\n| Windows          | done                     |        tier 2         |               tier 2 |\n\n[^1]: A proof-of-concept for Android platform support is available. Currently\n      only local, inter-thread communication works.\n[^2]: A proof-of-concept with `no_std` bare-metal support is available. The event\n      messaging-pattern does not yet work and the memory usage is not yet optimized.\n[^3]: A proof-of-concept for VxWorks platform support is available on [this\n      branch](https://github.com/ekxide/iceoryx2/blob/vxworks-mvp/doc/development-setup/vxworks.md)\n      on the [ekxide](https://ekxide.io) fork\n\n* **tier 1** - All safety and security features are working.\n* **tier 2** - Works with a restricted security and safety feature set.\n* **tier 3** - Not tested in our CI, so may or may not compile and run.\n\n<!-- markdownlint-disable MD027 -->\n> [!NOTE]\n> Some commercial operating systems require expensive licenses and the support\n> for these platforms relies on funding for the license costs.\n<!-- markdownlint-enable MD027 -->\n\n<!-- markdownlint-disable MD027 -->\n> [!NOTE]\n> Yocto recipes are available at [meta-iceoryx2](https://github.com/eclipse-iceoryx/meta-iceoryx2)\n<!-- markdownlint-enable MD027 -->\n\n## Language Bindings\n\n| Language |     State                                                         |\n| :------- | ----------------------------------------------------------------: |\n| C / C++  |     done                                                          |\n| Python   |     done                                                          |\n| Go       |  planned                                                          |\n| C#       |    [done](https://github.com/eclipse-iceoryx/iceoryx2-csharp)[^4] |\n| Java     |  planned                                                          |\n| Kotlin   |  planned                                                          |\n| Lua      |  planned                                                          |\n| Swift    |  planned                                                          |\n| Zig      |  planned                                                          |\n\n[^4]: C# bindings are available in a separate repository. May not be up to date\n      with `main`.\n\n## Commercial Support\n\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n\n<table width=\"100%\">\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"33%\">\n        <a href=\"https://ekxide.io\">\n        <img src=\"https://github.com/eclipse-iceoryx/iceoryx2/assets/56729169/c3ce8370-6cef-4c31-8259-93ddaa61c43e\" alt=\"ekxide IO GmbH\"/><br />\n        </a>\n        <a href=\"mailto:info@ekxide.io\">info@ekxide.io</a>\n      </td>\n      <td>\n        <ul>\n          <li>commercial extensions and tooling</li>\n          <li>custom feature development</li>\n          <li>training and consulting</li>\n          <li>integration support</li>\n          <li>engineering services around the iceoryx ecosystem</li>\n        </ul>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n## Thanks To All Contributors\n\nThanks to everyone who has contributed to iceoryx2. Without their passion and\ndedication, the project wouldn't thrive. A list of people who have committed\ncode can be found on [github](https://github.com/eclipse-iceoryx/iceoryx2/graphs/contributors).\nHowever, contributions are not limited to code - testing the software, reporting\nbugs, and spreading the word about iceoryx2 are all equally valuable. A big\nthank you as well to those 'invisible' contributors who play a crucial role\nbehind the scenes.\n",
      "stars_today": 1
    },
    {
      "id": 159560389,
      "name": "renv",
      "full_name": "rstudio/renv",
      "description": "renv: Project environments for R.",
      "html_url": "https://github.com/rstudio/renv",
      "stars": 1126,
      "forks": 162,
      "language": "R",
      "topics": [],
      "created_at": "2018-11-28T20:25:39Z",
      "updated_at": "2026-01-23T01:23:09Z",
      "pushed_at": "2026-01-22T07:14:26Z",
      "open_issues": 213,
      "owner": {
        "login": "rstudio",
        "avatar_url": "https://avatars.githubusercontent.com/u/513560?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# renv <img src=\"man/figures/logo.svg\" align=\"right\" height=\"115\"/>\n\n<!-- badges: start -->\n\n[![Lifecycle:\nstable](https://img.shields.io/badge/lifecycle-stable-brightgreen.svg)](https://lifecycle.r-lib.org/articles/stages.html)\n[![CRAN\nstatus](https://www.r-pkg.org/badges/version/renv)](https://CRAN.R-project.org/package=renv)\n[![R-CMD-check](https://github.com/rstudio/renv/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/rstudio/renv/actions/workflows/R-CMD-check.yaml)\n\n<!-- badges: end -->\n\n## Overview\n\nThe renv package[^1] helps you create **r**eproducible **env**ironments\nfor your R projects. Use renv to make your R projects more isolated,\nportable and reproducible.\n\n- **Isolated**: Installing a new or updated package for one project\n  won‚Äôt break your other projects, and vice versa. That‚Äôs because renv\n  gives each project its own private library.\n- **Portable**: Easily transport your projects from one computer to\n  another, even across different platforms. renv makes it easy to\n  install the packages your project depends on.\n- **Reproducible**: renv records the exact package versions you depend\n  on, and ensures those exact versions are the ones that get installed\n  wherever you go.\n\n## Installation\n\nInstall the latest version of renv from CRAN with:\n\n``` r\ninstall.packages(\"renv\")\n```\n\nAlternatively, install the development version from\n[r-universe](https://rstudio.r-universe.dev/renv) with:\n\n``` r\ninstall.packages(\"renv\", repos = \"https://rstudio.r-universe.dev\")\n```\n\n## Workflow\n\n<img src=\"vignettes/renv.png\" alt=\"A diagram showing the most important verbs and nouns of renv. Projects start with init(), which creates a project library using packages from the system library. snapshot() updates the lockfile using the packages installed in the project library, where restore() installs packages into the project library using the metadata from the lockfile, and status() compares the lockfile to the project library. You install and update packages from CRAN and GitHub using install() and update(), but because you'll need to do this for multiple projects, renv uses cache to make this fast.\" width=\"408\" style=\"display: block; margin: auto;\" />\n\nUse `renv::init()` to initialize renv in a new or existing project. This\nwill set up a **project library**, containing all the packages you‚Äôre\ncurrently using. The packages (and all the metadata needed to reinstall\nthem) are recorded into a **lockfile**, `renv.lock`, and a `.Rprofile`\nensures that the library is used every time you open that project.\n\nAs you continue to work on your project, you will install and upgrade\npackages, either using `install.packages()` and `update.packages()` or\n`renv::install()` and `renv::update()`. After you‚Äôve confirmed your code\nworks as expected, use `renv::snapshot()` to record the packages and\ntheir sources in the lockfile.\n\nLater, if you need to share your code with someone else or run your code\non new machine, your collaborator (or you) can call `renv::restore()` to\nreinstall the specific package versions recorded in the lockfile.\n\n## Learning more\n\nIf this is your first time using renv, we strongly recommend starting\nwith the [Introduction to\nrenv](https://rstudio.github.io/renv/articles/renv.html) vignette: this\nwill help you understand the most important verbs and nouns of renv.\n\nIf you have a question about renv, please first check the\n[FAQ](https://rstudio.github.io/renv/articles/faq.html) to see whether\nyour question has already been addressed. If it hasn‚Äôt, please feel free\nto ask on the [Posit Forum](https://forum.posit.co).\n\nIf you believe you‚Äôve found a bug in renv, please file a bug (and, if\npossible, a [reproducible example](https://reprex.tidyverse.org)) at\n<https://github.com/rstudio/renv/issues>.\n\n[^1]: Pronounced ‚ÄúR‚Äù ‚Äúenv‚Äù\n",
      "stars_today": 1
    },
    {
      "id": 259225467,
      "name": "CellChat",
      "full_name": "sqjin/CellChat",
      "description": "R toolkit for inference, visualization and analysis of cell-cell communication from single-cell data",
      "html_url": "https://github.com/sqjin/CellChat",
      "stars": 760,
      "forks": 167,
      "language": "R",
      "topics": [
        "cell-cell-communication",
        "cell-cell-interaction",
        "microenvironment",
        "single-cell-analysis"
      ],
      "created_at": "2020-04-27T06:28:33Z",
      "updated_at": "2026-01-23T21:19:32Z",
      "pushed_at": "2024-01-06T18:23:14Z",
      "open_issues": 455,
      "owner": {
        "login": "sqjin",
        "avatar_url": "https://avatars.githubusercontent.com/u/32399212?v=4"
      },
      "readme": "\n<p align=\"center\">\n  <img width=\"200\"  src=\"https://github.com/sqjin/CellChat/blob/master/CellChat_Logo.png\">\n</p>\n\n# CAUTION\nWe have updated CellChat to v2 and migrated CellChat to a new repository. This repository will be NOT updated and maintained any more. Please check the new repository [jinworks/CellChat](https://github.com/jinworks/CellChat) for the new updates, and the [CellChat v2 paper](https://biorxiv.org/cgi/content/short/2023.11.05.565674v1) for a comprehensive protocol of CellChat.  \n\n# About CellChat and CellChatDB\nCellChat is an R package designed for inference, analysis, and visualization of cell-cell communication from single-cell data. CellChat aims to enable users to identify and interpret cell-cell communication within an easily interpretable framework, with the emphasis of clear, attractive, and interpretable visualizations.  \n\nCellChatDB is a manually curated database of literature-supported ligand-receptor interactions in mutiple species, leading to a comprehensive recapitulation of known molecular interaction mechanisms including multi-subunit structure of ligand-receptor complexes and co-factors.\n\nIf you use CellChat in your research, please considering citing our papers: \n- [Suoqin Jin et al., CellChat for systematic analysis of cell-cell communication from single-cell and spatially resolved transcriptomics, bioRxiv 2023](https://biorxiv.org/cgi/content/short/2023.11.05.565674v1) [CellChat v2]\n- [Suoqin Jin et al., Inference and analysis of cell-cell communication using CellChat, Nature Communications 2021](https://www.nature.com/articles/s41467-021-21246-9) [CellChat v1]\n\n# Capabilities\nIn addition to infer the intercellular communication from any given single-cell data, CellChat provides functionality for further data exploration, analysis, and visualization. \n\n- It can quantitatively characterize and compare the inferred cell-cell communication networks using a systems approach by combining social network analysis, pattern recognition, and manifold learning approaches.\n- It provides an easy-to-use tool for extracting and visualizing high-order information of the inferred networks. For example, it allows ready prediction of major signaling inputs and outputs for all cell populations and how these populations and signals coordinate together for functions.\n- It enables comparative analysis of cell-cell communication across different conditions and identification of altered signaling and cell populations. \n- It provides several visualization outputs to facilitate intuitive user-guided data interpretation.\n\n<p align=\"center\">\n  <img width=\"700\"  src=\"https://github.com/sqjin/CellChat/blob/master/overview_CellChat.png\">\n</p>\n\n\n<p align=\"center\">\n  <a href=\"https://clustrmaps.com/site/1bpq2\">\n     <img width=\"200\"  src=\"https://clustrmaps.com/map_v2.png?cl=ffffff&w=a&t=n&d=42WqeykSXznN_NSaBlpf6CtSXQxhqmIs6QusUsguFdY\" />\n   </a>\n</p>\n<p align=\"center\">\n  <a href=\"#\">\n     <img src=\"https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fsqjin%2FCellChat&labelColor=%233499cc&countColor=%2370c168\" />\n   </a>\n</p>\n\n\n\n\n\n",
      "stars_today": 1
    },
    {
      "id": 567482582,
      "name": "swift-http-types",
      "full_name": "apple/swift-http-types",
      "description": "Version-independent HTTP currency types for Swift",
      "html_url": "https://github.com/apple/swift-http-types",
      "stars": 1001,
      "forks": 68,
      "language": "Swift",
      "topics": [],
      "created_at": "2022-11-17T22:14:21Z",
      "updated_at": "2026-01-23T23:55:35Z",
      "pushed_at": "2025-11-24T10:24:28Z",
      "open_issues": 16,
      "owner": {
        "login": "apple",
        "avatar_url": "https://avatars.githubusercontent.com/u/10639145?v=4"
      },
      "readme": "# Swift HTTP Types\n\nSwift HTTP Types are version-independent HTTP currency types designed for both clients and servers. They provide a common set of representations for HTTP requests and responses, focusing on modern HTTP features.\n\n## Getting Started\n\nAdd the following dependency clause to your Package.swift:\n\n```swift\ndependencies: [\n    .package(url: \"https://github.com/apple/swift-http-types.git\", from: \"1.0.0\")\n]\n```\n\nThe `HTTPTypes` library exposes the core HTTP currency types, including `HTTPRequest`, `HTTPResponse`, and `HTTPFields`.\n\nThe `HTTPTypesFoundation` library provides conveniences for using new HTTP types with Foundation, including bidirectional convertors between the new types and Foundation URL types, and URLSession convenience methods with the new types.\n\nThe `NIOHTTPTypes`, `NIOHTTPTypesHTTP1`, and `NIOHTTPTypesHTTP2` libraries provide channel handlers for translating the version-specific NIO HTTP types with the new HTTP types. They can be found in [`swift-nio-extras`](https://github.com/apple/swift-nio-extras).\n\n## Usage\n\n#### Create a request\n\n```swift\nlet request = HTTPRequest(method: .get, scheme: \"https\", authority: \"www.example.com\", path: \"/\")\n```\n\n#### Create a request from a Foundation URL\n\n```swift\nvar request = HTTPRequest(method: .get, url: URL(string: \"https://www.example.com/\")!)\nrequest.method = .post\nrequest.path = \"/upload\"\n```\n\n#### Create a response\n\n```swift\nlet response = HTTPResponse(status: .ok)\n```\n\n#### Access and modify header fields\n\n```swift\nextension HTTPField.Name {\n    static let myCustomHeader = Self(\"My-Custom-Header\")!\n}\n\n// Set\nrequest.headerFields[.userAgent] = \"MyApp/1.0\"\nrequest.headerFields[.myCustomHeader] = \"custom-value\"\nrequest.headerFields[values: .acceptLanguage] = [\"en-US\", \"zh-Hans-CN\"]\n\n// Get\nrequest.headerFields[.userAgent] // \"MyApp/1.0\"\nrequest.headerFields[.myCustomHeader] // \"custom-value\"\nrequest.headerFields[.acceptLanguage] // \"en-US, zh-Hans-CN\"\nrequest.headerFields[values: .acceptLanguage] // [\"en-US\", \"zh-Hans-CN\"]\n```\n\n#### Use with URLSession\n\n```swift\nvar request = HTTPRequest(method: .post, url: URL(string: \"https://www.example.com/upload\")!)\nrequest.headerFields[.userAgent] = \"MyApp/1.0\"\nlet (responseBody, response) = try await URLSession.shared.upload(for: request, from: requestBody)\nguard response.status == .created else {\n    // Handle error\n}\n```\n\n#### Use with SwiftNIO\n\n```swift\nchannel.configureHTTP2Pipeline(mode: .server) { channel in\n    channel.pipeline.addHandlers([\n        HTTP2FramePayloadToHTTPServerCodec(),\n        ExampleChannelHandler()\n    ])\n}.map { _ in () }\n```\n\n```swift\nfinal class ExampleChannelHandler: ChannelDuplexHandler {\n    typealias InboundIn = HTTPTypeServerRequestPart\n    typealias OutboundOut = HTTPTypeServerResponsePart\n\n    func channelRead(context: ChannelHandlerContext, data: NIOAny) {\n        switch unwrapInboundIn(data) {\n        case .head(let request):\n            // Handle request headers\n        case .body(let body):\n            // Handle request body\n        case .end(let trailers):\n            // Handle complete request\n            let response = HTTPResponse(status: .ok)\n            context.write(wrapOutboundOut(.head(response)), promise: nil)\n            context.writeAndFlush(wrapOutboundOut(.end(nil)), promise: nil)\n        }\n    }\n}\n```\n\n## Developing HTTP Types\n\nFor the most part, HTTP Types development is as straightforward as any other SwiftPM project. With that said, we do have a few processes that are worth understanding before you contribute. For details, please see `CONTRIBUTING.md` in this repository.\n\nPlease note that all work on HTTP Types is covered by the [Swift HTTP Types Code of Conduct](https://github.com/apple/swift-http-types/blob/main/CODE_OF_CONDUCT.md).\n",
      "stars_today": 1
    },
    {
      "id": 28114218,
      "name": "dada2",
      "full_name": "benjjneb/dada2",
      "description": "Accurate sample inference from amplicon data with single nucleotide resolution",
      "html_url": "https://github.com/benjjneb/dada2",
      "stars": 534,
      "forks": 162,
      "language": "R",
      "topics": [
        "amplicon",
        "bioconductor",
        "bioinformatics",
        "metabarcoding",
        "metagenomics",
        "microbiome",
        "taxonomy"
      ],
      "created_at": "2014-12-17T00:53:58Z",
      "updated_at": "2026-01-23T20:51:05Z",
      "pushed_at": "2025-12-15T19:22:15Z",
      "open_issues": 193,
      "owner": {
        "login": "benjjneb",
        "avatar_url": "https://avatars.githubusercontent.com/u/5797204?v=4"
      },
      "readme": "\n[![Build Status](https://app.travis-ci.com/benjjneb/dada2.svg?branch=master)](https://app.travis-ci.com/benjjneb/dada2)\n\n# dada2\n\nExact sample inference from high-throughput amplicon data. Resolves real variants differing by as little as one nucleotide. Visit [the DADA2 website](https://benjjneb.github.io/dada2/index.html) for the most detailed and up-to-date documentation.\n\n### Installation\n\nThe dada2 package binaries are available through Bioconductor:\n\n```S\n## try http:// if https:// URLs are not supported\nif (!requireNamespace(\"BiocManager\", quietly=TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"dada2\")\n```\n\nIn order to install dada2 from source (and get the latest and greatest new features) see our [installation from source instructions](https://benjjneb.github.io/dada2/dada-installation.html).\n\n### Documentation\n\nThe [tutorial walkthrough of the DADA2 pipeline on paired end Illumina Miseq data](https://benjjneb.github.io/dada2/tutorial.html). \n\nThe [dada2 R package manual](https://www.bioconductor.org/packages/3.6/bioc/manuals/dada2/man/dada2.pdf).\n\nFurther documentation is available on [the DADA2 front page](http://benjjneb.github.io/dada2/). \n\n### DADA2 Articles\n\n[DADA2: High resolution sample inference from Illumina amplicon data. Nature Methods, 2016.](http://dx.doi.org/10.1038/nmeth.3869) [(Open Access link.)](http://rdcu.be/ipGh)\n\n[Bioconductor workflow for microbiome data analysis: from raw reads to community analyses. F1000 Research, 2016.](https://f1000research.com/articles/5-1492)\n\n[Exact sequence variants should replace operational taxonomic units in marker-gene data analysis. ISMEJ, 2017.](http://dx.doi.org/10.1038/ismej.2017.119)\n\n[High-throughput amplicon sequencing of the full-length 16S rRNA gene with single-nucleotide resolution. Nucleic Acids Research, 2019.](http://dx.doi.org/10.1093/nar/gkz569)\n\n### Other Resources\n\nPlanned feature improvements are publicly catalogued at the main DADA2 development site on github, specifically on the \"Issues\" page for DADA2:\n\nhttps://github.com/benjjneb/dada2/issues\n\nIf the feature you are hoping for is not listed, you are welcome to add it as a feature request \"issue\" on this page. This request will be publicly available and listed on the page.\n\nBugs and difficulties in using DADA2 are also welcome on [the issue tracker](https://github.com/benjjneb/dada2/issues).\n",
      "stars_today": 1
    },
    {
      "id": 480989366,
      "name": "privacy-sandbox-samples",
      "full_name": "android/privacy-sandbox-samples",
      "description": null,
      "html_url": "https://github.com/android/privacy-sandbox-samples",
      "stars": 194,
      "forks": 117,
      "language": "Kotlin",
      "topics": [
        "samples"
      ],
      "created_at": "2022-04-12T22:16:49Z",
      "updated_at": "2026-01-22T20:06:55Z",
      "pushed_at": "2025-05-07T17:30:14Z",
      "open_issues": 20,
      "owner": {
        "login": "android",
        "avatar_url": "https://avatars.githubusercontent.com/u/32689599?v=4"
      },
      "readme": "SDK Runtime and Privacy Preserving APIs Repository\n==================================================\n\nThis repository contains a set of individual Android Studio projects to help you get started writing apps using the SDK Runtime and Privacy Preserving APIs (PPAPIs).\n\nBranches\n-----------\nDue to the dynamic nature of this project, there are three branches provided.\nPlease ensure you are using the correct branch for your needs.\n\n* [main](https://github.com/android/privacy-sandbox-samples) - contains sample\n  applications targeting Beta releases.\n* [dev-preview-main](https://github.com/android/privacy-sandbox-samples/tree/dev-preview-main) - contains\nsample applications targeting Developer Preview releases. This provides early access to new features for early testing.\n* [jetpack-main](https://github.com/android/privacy-sandbox-samples/tree/jetpack-main) - contains\nversions of the sample applications that utilize Jetpack libraries to interface with the Privacy Sandbox.\n\nThe Privacy Sandbox on Android is currently in Alpha and it is not recommended to deploy or use these samples other than to test your own infrastructure.\n\nNote: It is recommended to use [Android Studio\nCanary](https://developer.android.com/studio/preview). As we work to support the\nlatest features for Privacy Sandbox, there may be some issues using Stable\nreleases.\n\nRead below for a description of each sample.\n\n\nSamples\n----------\n\n* **[TopicsKotlin](TopicsKotlin)** (Kotlin) - Demonstrates how to initialize and call the Topics API. \n\n* **[TopicsJava](TopicsJava)** (Java) - Demonstrates how to initialize and call the Topics API. \n\n* **[Fledge](Fledge)** - Contains components for demonstrating FLEDGE APIs.\n  * **[FledgeKotlin](Fledge/FledgeKotlin)** (Kotlin) - Demonstrates how to initialize and call the FLEDGE APIs. \n\n  * **[FledgeJava](Fledge/FledgeJava)** (Java) - Demonstrates how to initialize and call the FLEDGE API. \n\n  * **[FledgeServerSpec](Fledge/FledgeServerSpec)** (OpenApi 3.1) - Sample FLEDGE server specs that can be used generate mock servers for delivering Javascript files to FLEDGE and receiving impression reports.  \n\n* **[PrivacySandboxKotlin](PrivacySandboxKotlin)** (Kotlin) - Demonstrates how to create an SDK that will run in a separate process. This sample contains both an app, and an SDK to show the interaction between them.\n\n* **[AttributionReporting](AttributionReporting)** - Contains components for demonstrating Attribution Reporting API.\n   * **[MeasurementAdTechServer](AttributionReporting/MeasurementAdTechServer)** (Kotlin) - Sample AdTech server to facilitate demonstration of Measurement APIs by the measurement sample app.\n\n   * **[MeasurementAdTechServerSpec](AttributionReporting/MeasurementAdTechServerSpec)** (OpenApi 3.1) - Sample AdTech server spec that can be used generate a mock server for interaction with measurement sample app.\n\n   * **[MeasurementSampleApp](AttributionReporting/MeasurementSampleApp)** (Kotlin) - Demonstrates how to initialize and use Attribution Reporting API\n\n",
      "stars_today": 1
    },
    {
      "id": 33569135,
      "name": "RxSwift",
      "full_name": "ReactiveX/RxSwift",
      "description": "Reactive Programming in Swift",
      "html_url": "https://github.com/ReactiveX/RxSwift",
      "stars": 24686,
      "forks": 4174,
      "language": "Swift",
      "topics": [
        "functional",
        "ios",
        "observer",
        "reactive",
        "reactivex",
        "rxswift",
        "swift",
        "unidirectional"
      ],
      "created_at": "2015-04-07T21:25:17Z",
      "updated_at": "2026-01-23T09:47:30Z",
      "pushed_at": "2026-01-22T08:14:18Z",
      "open_issues": 6,
      "owner": {
        "login": "ReactiveX",
        "avatar_url": "https://avatars.githubusercontent.com/u/6407041?v=4"
      },
      "readme": "<p align=\"center\">\n<img src=\"https://github.com/ReactiveX/RxSwift/blob/main/assets/RxSwift_Logo.png?raw=true\" width=\"35%\" alt=\"RxSwift Logo\" />\n<br />\n<a href=\"https://github.com/ReactiveX/RxSwift/actions/workflows/tests.yml\" target=\"_blank\"><img src=\"https://github.com/ReactiveX/RxSwift/actions/workflows/tests.yml/badge.svg\" alt=\"Build Status\" /></a>\n<img src=\"https://img.shields.io/badge/platforms-iOS%20%7C%20macOS%20%7C%20tvOS%20%7C%20watchOS%20%7C%20Linux-333333.svg\" alt=\"Supported Platforms: iOS, macOS, tvOS, watchOS & Linux\" />\n<br />\n<a href=\"https://github.com/Carthage/Carthage\" alt=\"RxSwift on Carthage\" title=\"RxSwift on Carthage\"><img src=\"https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat\" /></a>\n<a href=\"https://github.com/swiftlang/swift-package-manager\" alt=\"RxSwift on Swift Package Manager\" title=\"RxSwift on Swift Package Manager\"><img src=\"https://img.shields.io/badge/Swift%20Package%20Manager-compatible-brightgreen.svg\" /></a>\n</p>\n\nRx is a [generic abstraction of computation](https://youtu.be/looJcaeboBY) expressed through `Observable<Element>` interface, which lets you broadcast and subscribe to values and other events from an `Observable` stream.\n\nRxSwift is the Swift-specific implementation of the [Reactive Extensions](http://reactivex.io) standard.\n\n<p align=\"center\"><img src=\"https://github.com/ReactiveX/RxSwift/blob/main/assets/example.png?raw=true\" width=\"55%\" alt=\"RxSwift Observable Example of a price constantly changing and updating the app's UI\" /></p>\n\nWhile this version aims to stay true to the original spirit and naming conventions of Rx, this project also aims to provide a true Swift-first API for Rx APIs.\n\nCross platform documentation can be found on [ReactiveX.io](http://reactivex.io/).\n\nLike other Rx implementations, RxSwift's intention is to enable easy composition of asynchronous operations and streams of data in the form of `Observable` objects and a suite of methods to transform and compose these pieces of asynchronous work.\n\nKVO observation, async operations, UI Events and other streams of data are all unified under [abstraction of sequence](Documentation/GettingStarted.md#observables-aka-sequences). This is the reason why Rx is so simple, elegant and powerful.\n\n## I came here because I want to ...\n\n###### ... understand\n\n* [why use rx?](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/Why.md)\n* [the basics, getting started with RxSwift](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/GettingStarted.md)\n* [traits](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/Traits.md) - what are `Single`, `Completable`, `Maybe`, `Driver`, and `ControlProperty` ... and why do they exist?\n* [testing](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/UnitTests.md)\n* [tips and common errors](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/Tips.md)\n* [debugging](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/GettingStarted.md#debugging)\n* [the math behind Rx](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/MathBehindRx.md)\n* [what are hot and cold observable sequences?](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/HotAndColdObservables.md)\n\n###### ... install\n\n* Integrate RxSwift/RxCocoa with my app. [Installation Guide](#installation)\n\n###### ... hack around\n\n* with the example app. [Running Example App](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/ExampleApp.md)\n* with operators in playgrounds. [Playgrounds](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/Playgrounds.md)\n\n###### ... interact\n\n* All of this is great, but it would be nice to talk with other people using RxSwift and exchange experiences. <br />[Join Slack Channel](http://slack.rxswift.org)\n* Report a problem using the library. [Open an Issue With Bug Template](https://github.com/ReactiveX/RxSwift/blob/main/.github/ISSUE_TEMPLATE.md)\n* Request a new feature. [Open an Issue With Feature Request Template](Documentation/NewFeatureRequestTemplate.md)\n* Help out [Check out contribution guide](https://github.com/ReactiveX/RxSwift/blob/main/CONTRIBUTING.md)\n\n###### ... compare\n\n* [with Combine and ReactiveSwift](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/ComparisonWithOtherLibraries.md).\n\n###### ... understand the structure\n\nRxSwift is as compositional as the asynchronous work it drives. The core unit is RxSwift itself, while other dependencies can be added for UI Work, testing, and more.\n\nIt comprises five separate components depending on each other in the following way:\n\n```none\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ   RxCocoa    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂   RxRelay    ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n        ‚îÇ                  ‚îÇ\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ             RxSwift              ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n        ‚îÇ                  ‚îÇ\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ    RxTest    ‚îÇ    ‚îÇ  RxBlocking  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n* **RxSwift**: The core of RxSwift, providing the Rx standard as (mostly) defined by [ReactiveX](https://reactivex.io). It has no other dependencies.\n* **RxCocoa**: Provides Cocoa-specific capabilities for general iOS/macOS/watchOS & tvOS app development, such as Shared Sequences, Traits, and much more. It depends on both `RxSwift` and `RxRelay`.\n* **RxRelay**: Provides `PublishRelay`, `BehaviorRelay` and `ReplayRelay`, three [simple wrappers around Subjects](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/Subjects.md#relays). It depends on `RxSwift`.\n* **RxTest** and **RxBlocking**: Provides testing capabilities for Rx-based systems. It depends on `RxSwift`.\n\n## Usage\n\n<table>\n  <tr>\n    <th width=\"30%\">Here's an example</th>\n    <th width=\"30%\">In Action</th>\n  </tr>\n  <tr>\n    <td>Define search for GitHub repositories ...</td>\n    <th rowspan=\"9\"><img src=\"https://raw.githubusercontent.com/kzaher/rxswiftcontent/master/GithubSearch.gif\"></th>\n  </tr>\n  <tr>\n    <td><div class=\"highlight highlight-source-swift\"><pre>\nlet searchResults = searchBar.rx.text.orEmpty\n    .throttle(.milliseconds(300), scheduler: MainScheduler.instance)\n    .distinctUntilChanged()\n    .flatMapLatest { query -> Observable&lt;[Repository]&gt; in\n        if query.isEmpty {\n            return .just([])\n        }\n        return searchGitHub(query)\n            .catchAndReturn([])\n    }\n    .observe(on: MainScheduler.instance)</pre></div></td>\n  </tr>\n  <tr>\n    <td>... then bind the results to your tableview</td>\n  </tr>\n  <tr>\n    <td width=\"30%\"><div class=\"highlight highlight-source-swift\"><pre>\nsearchResults\n    .bind(to: tableView.rx.items(cellIdentifier: \"Cell\")) {\n        (index, repository: Repository, cell) in\n        cell.textLabel?.text = repository.name\n        cell.detailTextLabel?.text = repository.url\n    }\n    .disposed(by: disposeBag)</pre></div></td>\n  </tr>\n</table>\n\n## Installation\n\nRxSwift doesn't contain any external dependencies.\n\nThese are currently the supported installation options:\n\n### Manual\n\nOpen Rx.xcworkspace, choose `RxExample` and hit run. This method will build everything and run the sample app\n\n### XCFrameworks\n\nEach release starting with RxSwift 6 includes `*.xcframework` framework binaries.\n\nSimply drag the needed framework binaries to your **Frameworks, Libraries, and Embedded Content** section under your target's **General** tab.\n\n<img src=\"https://raw.githubusercontent.com/ReactiveX/RxSwift/main/assets/xcframeworks.png\" alt=\"XCFrameworks instructions\" width=\"65%\">\n\n> [!TIP]\n> RxSwift's xcframework(s) are signed with an Apple Developer account, and you can always verify the Team Name: Shai Mishali\n>\n> <img src=\"https://raw.githubusercontent.com/ReactiveX/RxSwift/main/assets/xcframeworks_signing.png\" alt=\"XCFrameworks Signing Team Name Validation\" width=\"65%\">\n\n### [Carthage](https://github.com/Carthage/Carthage)\n\nAdd this to `Cartfile`\n\n```\ngithub \"ReactiveX/RxSwift\" \"6.10.0\"\n```\n\n```bash\n$ carthage update\n```\n\n#### Carthage as a Static Library\n\nCarthage defaults to building RxSwift as a Dynamic Library.\n\nIf you wish to build RxSwift as a Static Library using Carthage you may use the script below to manually modify the framework type before building with Carthage:\n\n```bash\ncarthage update RxSwift --platform iOS --no-build\nsed -i -e 's/MACH_O_TYPE = mh_dylib/MACH_O_TYPE = staticlib/g' Carthage/Checkouts/RxSwift/Rx.xcodeproj/project.pbxproj\ncarthage build RxSwift --platform iOS\n```\n\n### [Swift Package Manager](https://github.com/swiftlang/swift-package-manager)\n\n> **Note**: There is a critical cross-dependency bug affecting many projects including RxSwift in Swift Package Manager. We've [filed a bug (SR-12303)](https://bugs.swift.org/browse/SR-12303) in early 2020 but have no answer yet. Your mileage may vary. A partial workaround can be found [here](https://github.com/ReactiveX/RxSwift/issues/2127#issuecomment-717830502).\n\nCreate a `Package.swift` file.\n\n```swift\n// swift-tools-version:5.0\n\nimport PackageDescription\n\nlet package = Package(\n  name: \"RxProject\",\n  dependencies: [\n    .package(url: \"https://github.com/ReactiveX/RxSwift.git\", .upToNextMajor(from: \"6.0.0\"))\n  ],\n  targets: [\n    .target(name: \"RxProject\", dependencies: [\"RxSwift\", .product(name: \"RxCocoa\", package: \"RxSwift\")]),\n  ]\n)\n```\n\n```bash\n$ swift build\n```\n\nTo build or test a module with RxTest dependency, set `TEST=1`.\n\n```bash\n$ TEST=1 swift test\n```\n\n### Manually using git submodules\n\n* Add RxSwift as a submodule\n\n```bash\n$ git submodule add git@github.com:ReactiveX/RxSwift.git\n```\n\n* Drag `Rx.xcodeproj` into Project Navigator\n* Go to `Project > Targets > Build Phases > Link Binary With Libraries`, click `+` and select `RxSwift`, `RxCocoa` and `RxRelay` targets\n\n## References\n\n* [http://reactivex.io/](http://reactivex.io/)\n* [Reactive Extensions GitHub (GitHub)](https://github.com/Reactive-Extensions)\n* [RxSwift RayWenderlich.com Book](https://store.raywenderlich.com/products/rxswift-reactive-programming-with-swift)\n* [RxSwift: Debunking the myth of hard (YouTube)](https://www.youtube.com/watch?v=GdvLP0ZAhhc)\n* [Boxue.io RxSwift Online Course](https://boxueio.com/series/rxswift-101) (Chinese üá®üá≥)\n* [Expert to Expert: Brian Beckman and Erik Meijer - Inside the .NET Reactive Framework (Rx) (video)](https://youtu.be/looJcaeboBY)\n* [Reactive Programming Overview (Jafar Husain from Netflix)](https://youtu.be/-8Y1-lE6NSA)\n* [Subject/Observer is Dual to Iterator (paper)](http://csl.stanford.edu/~christos/pldi2010.fit/meijer.duality.pdf)\n* [Rx standard sequence operators visualized (visualization tool)](http://rxmarbles.com/)\n* [Haskell](https://www.haskell.org/)\n",
      "stars_today": 0
    },
    {
      "id": 33486016,
      "name": "Kingfisher",
      "full_name": "onevcat/Kingfisher",
      "description": "A lightweight, pure-Swift library for downloading and caching images from the web.",
      "html_url": "https://github.com/onevcat/Kingfisher",
      "stars": 24243,
      "forks": 2747,
      "language": "Swift",
      "topics": [
        "cache",
        "filters",
        "image",
        "image-processor",
        "ios",
        "kingfisher",
        "macos",
        "swift",
        "xcode"
      ],
      "created_at": "2015-04-06T14:26:21Z",
      "updated_at": "2026-01-24T01:50:14Z",
      "pushed_at": "2026-01-05T14:19:51Z",
      "open_issues": 174,
      "owner": {
        "login": "onevcat",
        "avatar_url": "https://avatars.githubusercontent.com/u/1019875?v=4"
      },
      "readme": "<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/onevcat/Kingfisher/master/images/logo.png\" alt=\"Kingfisher\" title=\"Kingfisher\" width=\"557\"/>\n</p>\n\n<p align=\"center\">\n<a href=\"https://github.com/onevcat/Kingfisher/actions?query=workflow%3Abuild\"><img src=\"https://github.com/onevcat/kingfisher/workflows/build/badge.svg?branch=master\"></a>\n<a href=\"https://swiftpackageindex.com/onevcat/Kingfisher/master/documentation/kingfisher\"><img src=\"https://img.shields.io/badge/Swift-Doc-DE5C43.svg?style=flat\"></a>\n<a href=\"https://cocoapods.org/pods/Kingfisher\"><img src=\"https://img.shields.io/github/v/tag/onevcat/Kingfisher.svg?color=blue&include_prereleases=&sort=semver\"></a>\n<a href=\"https://swift.org/package-manager/\"><img src=\"https://img.shields.io/badge/SPM-supported-DE5C43.svg?style=flat\"></a>\n<a href=\"https://raw.githubusercontent.com/onevcat/Kingfisher/master/LICENSE\"><img src=\"https://img.shields.io/badge/license-MIT-black\"></a>\n</p>\n\nKingfisher is a powerful, pure-Swift library for downloading and caching images from the web. It provides you a chance to use a pure-Swift way to work with remote images in your next app.\n\n## Features\n\n- [x] Asynchronous image downloading and caching.\n- [x] Loading image from either `URLSession`-based networking or local provided data.\n- [x] Useful image processors and filters provided.\n- [x] Multiple-layer hybrid cache for both memory and disk.\n- [x] Fine control on cache behavior. Customizable expiration date and size limit.\n- [x] Cancelable downloading and auto-reusing previous downloaded content to improve performance.\n- [x] Independent components. Use the downloader, caching system, and image processors separately as you need.\n- [x] Prefetching images and showing them from the cache to boost your app.\n- [x] Extensions for `UIImageView`, `NSImageView`, `NSButton`, `UIButton`, `NSTextAttachment`, `WKInterfaceImage`, `TVMonogramView` and `CPListItem` to directly set an image from a URL.\n- [x] Built-in transition animation when setting images.\n- [x] Customizable placeholder and indicator while loading images.\n- [x] Extensible image processing and image format easily.\n- [x] Low Data Mode support.\n- [x] SwiftUI support.\n- [x] Swift 6 & Swift Concurrency (strict mode) prepared.\n- [x] Load & cache for Live Photo.\n\n### Kingfisher 101\n\nThe simplest use-case is setting an image to an image view with the `UIImageView` extension:\n\n```swift\nimport Kingfisher\n\nlet url = URL(string: \"https://example.com/image.png\")\nimageView.kf.setImage(with: url)\n```\n\nKingfisher will download the image from `url`, send it to both memory cache and disk cache, and display it in `imageView`. \nWhen you set it with the same URL later, the image will be retrieved from the cache and shown immediately.\n\nIt also works if you use SwiftUI:\n\n```swift\nvar body: some View {\n    KFImage(URL(string: \"https://example.com/image.png\")!)\n}\n```\n\n### A More Advanced Example\n\nWith the powerful options, you can do hard tasks with Kingfisher in a simple way. For example, the code below: \n\n1. Downloads a high-resolution image.\n2. Downsamples it to match the image view size.\n3. Makes it round cornered with a given radius.\n4. Shows a system indicator and a placeholder image while downloading.\n5. When prepared, it animates the small thumbnail image with a \"fade in\" effect. \n6. The original large image is also cached to disk for later use, to get rid of downloading it again in a detail view.\n7. A console log is printed when the task finishes, either for success or failure.\n\n```swift\nlet url = URL(string: \"https://example.com/high_resolution_image.png\")\nlet processor = DownsamplingImageProcessor(size: imageView.bounds.size)\n             |> RoundCornerImageProcessor(cornerRadius: 20)\nimageView.kf.indicatorType = .activity\nimageView.kf.setImage(\n    with: url,\n    placeholder: UIImage(named: \"placeholderImage\"),\n    options: [\n        .processor(processor),\n        .scaleFactor(UIScreen.main.scale),\n        .transition(.fade(1)),\n        .cacheOriginalImage\n    ])\n{\n    result in\n    switch result {\n    case .success(let value):\n        print(\"Task done for: \\(value.source.url?.absoluteString ?? \"\")\")\n    case .failure(let error):\n        print(\"Job failed: \\(error.localizedDescription)\")\n    }\n}\n```\n\nIt is a common situation I can meet in my daily work. Think about how many lines you need to write without\nKingfisher!\n\n### Method Chaining\n\nIf you are not a fan of the `kf` extension, you can also prefer to use the `KF` builder and chained the method \ninvocations. The code below is doing the same thing:\n\n```swift\n// Use `kf` extension\nimageView.kf.setImage(\n    with: url,\n    placeholder: placeholderImage,\n    options: [\n        .processor(processor),\n        .loadDiskFileSynchronously,\n        .cacheOriginalImage,\n        .transition(.fade(0.25)),\n        .lowDataMode(.network(lowResolutionURL))\n    ],\n    progressBlock: { receivedSize, totalSize in\n        // Progress updated\n    },\n    completionHandler: { result in\n        // Done\n    }\n)\n\n// Use `KF` builder\nKF.url(url)\n  .placeholder(placeholderImage)\n  .setProcessor(processor)\n  .loadDiskFileSynchronously()\n  .cacheMemoryOnly()\n  .fade(duration: 0.25)\n  .lowDataModeSource(.network(lowResolutionURL))\n  .onProgress { receivedSize, totalSize in  }\n  .onSuccess { result in  }\n  .onFailure { error in }\n  .set(to: imageView)\n```\n\nAnd even better, if later you want to switch to SwiftUI, just change the `KF` above to `KFImage`, and you've done:\n\n```swift\nstruct ContentView: View {\n    var body: some View {\n        KFImage.url(url)\n          .placeholder(placeholderImage)\n          .setProcessor(processor)\n          .loadDiskFileSynchronously()\n          .cacheMemoryOnly()\n          .fade(duration: 0.25)\n          .lowDataModeSource(.network(lowResolutionURL))\n          .onProgress { receivedSize, totalSize in  }\n          .onSuccess { result in  }\n          .onFailure { error in }\n    }\n}\n```\n\n## Requirements\n\n### Kingfisher 8.0\n\n- (UIKit/AppKit) iOS 13.0+ / macOS 10.15+ / tvOS 13.0+ / watchOS 6.0+ / visionOS 1.0+\n- (SwiftUI) iOS 14.0+ / macOS 11.0+ / tvOS 14.0+ / watchOS 7.0+ / visionOS 1.0+\n- Swift 5.9+\n\n### Kingfisher 7.0\n\n- (UIKit/AppKit) iOS 12.0+ / macOS 10.14+ / tvOS 12.0+ / watchOS 5.0+ / visionOS 1.0+\n- (SwiftUI) iOS 14.0+ / macOS 11.0+ / tvOS 14.0+ / watchOS 7.0+ / visionOS 1.0+\n- Swift 5.0+\n\n### Installation\n\nRefer to one of the following tutorials to install and use the framework:\n\n- [UIKit Tutorial](https://swiftpackageindex.com/onevcat/kingfisher/master/tutorials/kingfisher/gettingstarteduikit)\n- [SwiftUI Tutorial](https://swiftpackageindex.com/onevcat/kingfisher/master/tutorials/kingfisher/gettingstartedswiftui)\n\nAlternatively, you can follow either of the methods below.\n\n#### Swift Package Manager\n\n- File > Swift Packages > Add Package Dependency\n- Add `https://github.com/onevcat/Kingfisher.git`\n- Select \"Up to Next Major\" with \"8.0.0\"\n\n#### CocoaPods\n\n```ruby\nsource 'https://github.com/CocoaPods/Specs.git'\nplatform :ios, '13.0'\nuse_frameworks!\n\ntarget 'MyApp' do\n  pod 'Kingfisher', '~> 8.0'\nend\n```\n\n#### Pre-built Framework\n\n1. Open the release page, download the latest version of Kingfisher from the assets section. \n2. Drag the `Kingfisher.xcframework` into your project and add it to the target (usually the app target).\n3. Select your target, in the \"General\" Tab, find the \"Frameworks, Libraries, and Embedded Content\" section, set the `Embed Without Signing` to Kingfisher.\n\n## Documentation\n\nCheck the documentation and tutorials:\n\n- [Documentation Home](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher)\n- [Getting Started](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/gettingstarted)\n    - [UIKit Tutorial](https://swiftpackageindex.com/onevcat/kingfisher/master/tutorials/kingfisher/gettingstarteduikit)\n    - [SwiftUI Tutorial](https://swiftpackageindex.com/onevcat/kingfisher/master/tutorials/kingfisher/gettingstartedswiftui)\n- [Common Tasks - General](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/commontasks)\n    - [Common Tasks - Cache](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/commontasks_cache)\n    - [Common Tasks - Downloader](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/commontasks_downloader)\n    - [Common tasks - Processor](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/commontasks_processor)\n\n### Migrating\n\n- [Kingfisher 8.0 Migration](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/migration-to-8)\n- [Kingfisher 7.0 Migration](https://github.com/onevcat/Kingfisher/wiki/Kingfisher-7.0-Migration-Guide)\n\nIf you are using an even earlier version, see the guides below to know the steps for migrating.\n\n## Other\n\n### Future of Kingfisher\n\nI want to keep Kingfisher lightweight. This framework focuses on providing a simple solution for downloading and caching images. This doesn‚Äôt mean the framework can‚Äôt be improved. Kingfisher is far from perfect, so necessary and useful updates will be made to make it better.\n\n### Developments and Tests\n\nAny contributing and pull requests are warmly welcome. However, before you plan to implement some features or try to fix an uncertain issue, it is recommended to open a discussion first. It would be appreciated if your pull requests could build with all tests green. :)\n\n### About the logo\n\nThe logo of Kingfisher is inspired by [Tangram (‰∏ÉÂ∑ßÊùø)](http://en.wikipedia.org/wiki/Tangram), a dissection puzzle consisting of seven flat shapes from China. I believe she's a kingfisher bird instead of a swift, but someone insists that she is a pigeon. I guess I should give her a name. Hi, guys, do you have any suggestions?\n\n### Contact\n\nFollow and contact me on [Twitter](http://twitter.com/onevcat) or [Sina Weibo](http://weibo.com/onevcat). If you find an issue, [open a ticket](https://github.com/onevcat/Kingfisher/issues/new). Pull requests are warmly welcome as well.\n\n## Backers & Sponsors\n\nOpen-source projects cannot live long without your help. If you find Kingfisher to be useful, please consider supporting this \nproject by becoming a sponsor. Your user icon or company logo shows up [on my blog](https://onevcat.com/tabs/about/) with a link to your home page. \n\nBecome a sponsor through [GitHub Sponsors](https://github.com/sponsors/onevcat). :heart:\n\nSpecial thanks to:\n\n[![imgly](https://user-images.githubusercontent.com/1812216/106253726-271ed000-6218-11eb-98e0-c9c681925770.png)](https://img.ly/)\n\n[![emergetools](https://github-production-user-asset-6210df.s3.amazonaws.com/1019875/254794187-d44f6f50-993f-42e3-b79c-960f69c4adc1.png)](https://www.emergetools.com)\n\n\n\n### License\n\nKingfisher is released under the MIT license. See LICENSE for details.\n",
      "stars_today": 0
    },
    {
      "id": 139914932,
      "name": "quarkus",
      "full_name": "quarkusio/quarkus",
      "description": "Quarkus: Supersonic Subatomic Java. ",
      "html_url": "https://github.com/quarkusio/quarkus",
      "stars": 15421,
      "forks": 3059,
      "language": "Java",
      "topics": [
        "cloud-native",
        "hacktoberfest",
        "java",
        "kubernetes",
        "reactive"
      ],
      "created_at": "2018-07-06T00:44:20Z",
      "updated_at": "2026-01-23T18:34:58Z",
      "pushed_at": "2026-01-23T22:21:41Z",
      "open_issues": 2669,
      "owner": {
        "login": "quarkusio",
        "avatar_url": "https://avatars.githubusercontent.com/u/47638783?v=4"
      },
      "readme": "[![Quarkus](https://design.jboss.org/quarkus/logo/final/PNG/quarkus_logo_horizontal_rgb_1280px_default.png#gh-light-mode-only)](https://quarkus.io/#gh-light-mode-only)\n[![Quarkus](https://design.jboss.org/quarkus/logo/final/PNG/quarkus_logo_horizontal_rgb_1280px_reverse.png#gh-dark-mode-only)](https://quarkus.io/#gh-dark-mode-only)\n\n[![Version](https://img.shields.io/maven-central/v/io.quarkus/quarkus-bom?logo=apache-maven&style=for-the-badge)](https://search.maven.org/artifact/io.quarkus/quarkus-bom)\n[![GitHub Actions Status](<https://img.shields.io/github/actions/workflow/status/QuarkusIO/quarkus/ci-actions-incremental.yml?branch=main&logo=GitHub&style=for-the-badge>)](https://github.com/quarkusio/quarkus/actions?query=workflow%3A%22Quarkus+CI%22)\n[![Commits](https://img.shields.io/github/commit-activity/m/quarkusio/quarkus.svg?label=commits&style=for-the-badge&logo=git&logoColor=white)](https://github.com/quarkusio/quarkus/pulse)\n[![License](https://img.shields.io/github/license/quarkusio/quarkus?style=for-the-badge&logo=apache&color=brightgreen)](https://www.apache.org/licenses/LICENSE-2.0)\n[![Project Chat](https://img.shields.io/badge/zulip-join_chat-brightgreen.svg?style=for-the-badge&logo=zulip)](https://quarkusio.zulipchat.com/)\n[![Gitpod Ready-to-Code](https://img.shields.io/badge/Gitpod-Ready--to--Code-blue?style=for-the-badge&logo=gitpod&logoColor=white)](https://gitpod.io/#https://github.com/quarkusio/quarkus/-/tree/main/)\n[![Supported JVM Versions](https://img.shields.io/badge/JVM-17--21-brightgreen.svg?style=for-the-badge&logo=openjdk)](https://github.com/quarkusio/quarkus/actions/runs/113853915/)\n[![Develocity](https://img.shields.io/badge/Revved%20up%20by-Develocity-007EC5?style=for-the-badge&logo=gradle)](https://ge.quarkus.io/scans)\n[![GitHub Repo stars](https://img.shields.io/github/stars/quarkusio/quarkus?style=for-the-badge)](https://github.com/quarkusio/quarkus/stargazers)\n[![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20Quarkus%20Guru-007EC5?style=for-the-badge)](https://gurubase.io/g/quarkus)\n\n# Quarkus - Supersonic Subatomic Java\n\nQuarkus is a Cloud Native, (Linux) Container First framework for writing Java applications.\n\n* **Container First**:\nMinimal footprint Java applications optimal for running in containers.\n* **Cloud Native**:\nEmbraces [12 factor architecture](https://12factor.net) in environments like Kubernetes.\n* **Unify imperative and reactive**:\nBrings under one programming model non-blocking and imperative styles of development.\n* **Standards-based**:\nBased on the standards and frameworks you love and use (RESTEasy and JAX-RS, Hibernate ORM and JPA, Netty, Eclipse Vert.x, Eclipse MicroProfile, Apache Camel...).\n* **Microservice First**:\nBrings lightning fast startup time and code turnaround to Java apps.\n* **Developer Joy**:\nDevelopment centric experience without compromise to bring your amazing apps to life in no time.\n\n_All under ONE framework._\n\n## Getting Started\n\n* [Documentation](https://quarkus.io)\n* [Wiki](https://github.com/quarkusio/quarkus/wiki)\n\n## Migration Guides\n\nWe collect all the migration notes in our [migration guides](https://github.com/quarkusio/quarkus/wiki/Migration-Guides).\n\n## Release Planning\n\nInterested in when the next release is coming? Check our [release planning](https://github.com/quarkusio/quarkus/wiki/Release-Planning) document for details.\n\n## How to build Quarkus\n\nThe build instructions are available in the [contribution guide](CONTRIBUTING.md).\n",
      "stars_today": 0
    },
    {
      "id": 70780002,
      "name": "flowable-engine",
      "full_name": "flowable/flowable-engine",
      "description": "A compact and highly efficient workflow and Business Process Management (BPM) platform for developers, system admins and business users.",
      "html_url": "https://github.com/flowable/flowable-engine",
      "stars": 9040,
      "forks": 2801,
      "language": "Java",
      "topics": [
        "bpmn",
        "java",
        "workflow",
        "workflow-engine"
      ],
      "created_at": "2016-10-13T07:21:43Z",
      "updated_at": "2026-01-23T12:56:10Z",
      "pushed_at": "2026-01-13T12:04:45Z",
      "open_issues": 380,
      "owner": {
        "login": "flowable",
        "avatar_url": "https://avatars.githubusercontent.com/u/22557067?v=4"
      },
      "readme": "Flowable (V7)\n========\n\n[![Maven Central](https://img.shields.io/maven-central/v/org.flowable/flowable-engine?label=Maven%20Central)](https://central.sonatype.com/search?q=g:org.flowable%20%26%26%20%28a:flowable-engine%20a:flowable-cmmn-engine%20a:flowable-dmn-engine%29)\n[![Docker](https://shields.io/docker/pulls/flowable/flowable-rest)](https://hub.docker.com/r/flowable/flowable-rest)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://github.com/flowable/flowable-engine/blob/main/LICENSE)\n\n![Flowable Actions CI](https://github.com/flowable/flowable-engine/actions/workflows/main.yml/badge.svg?branch=main)\n\nHomepage: https://www.flowable.org/\n\n## flowable / flow…ôb(…ô)l /\n* a compact and highly efficient workflow and Business Process Management (BPM) platform for developers, system admins and business users.\n* a lightning fast, tried and tested BPMN 2 process engine written in Java.  It is Apache 2.0 licensed open source, with a committed community.\n* can run embedded in a Java application, or as a service on a server, a cluster, and in the cloud.  It integrates perfectly with Spring.  With a rich Java and REST API, it is the ideal engine for orchestrating human or system activities.\n\n## Introduction\n\n### License\n\nFlowable is distributed under the Apache V2 license (http://www.apache.org/licenses/LICENSE-2.0.html).\n\n### Download\n\nThe Flowable downloads can be found on https://www.flowable.org/downloads.html.\n\n### Sources\n\nThe distribution contains most of the sources as jar files. The source code of Flowable can be found on https://github.com/flowable/flowable-engine.\n\n### JDK 17+\n\nFlowable V7 runs on a Java higher than or equal to version 17. Use the JDK packaged with your Linux distribution or go to [adoptium.net](https://adoptium.net/) and click on the *Latest LTS Release* button. There are installation instructions on that page as well. To verify that your installation was successful, run `java -version` on the command line. That should print the installed version of your JDK.\n\n[Flowable V6](https://github.com/flowable/flowable-engine/tree/flowable6.x) is still maintained and supports Java 8+.\n\n### Flowable Design\n\nFlowable offers a free to use Flowable Cloud Design application, which you can use to model CMMN, BPMN, DMN and other model types. You can register via the Flowable account registration page to get started https://www.flowable.com/account/open-source.\n\n### Contributing\n\nContributing to Flowable: https://github.com/flowable/flowable-engine/wiki.\n\n### Reporting problems\n\nEvery self-respecting developer should have read this link on how to ask smart questions: http://www.catb.org/~esr/faqs/smart-questions.html.\n\nAfter you've done that you can post questions and comments on https://forum.flowable.org and create issues in https://github.com/flowable/flowable-engine/issues.\n",
      "stars_today": 0
    },
    {
      "id": 20597509,
      "name": "data.table",
      "full_name": "Rdatatable/data.table",
      "description": "R's data.table package extends data.frame:",
      "html_url": "https://github.com/Rdatatable/data.table",
      "stars": 3843,
      "forks": 1025,
      "language": "R",
      "topics": [],
      "created_at": "2014-06-07T16:38:05Z",
      "updated_at": "2026-01-23T22:34:11Z",
      "pushed_at": "2026-01-23T22:34:08Z",
      "open_issues": 962,
      "owner": {
        "login": "Rdatatable",
        "avatar_url": "https://avatars.githubusercontent.com/u/7824179?v=4"
      },
      "readme": "\n# data.table <a href=\"https://r-datatable.com\"><img src=\"https://raw.githubusercontent.com/Rdatatable/data.table/master/.graphics/logo.png\" align=\"right\" height=\"140\" /></a>\n\n<!-- badges: start -->\n[![CRAN status](https://badges.cranchecks.info/flavor/release/data.table.svg)](https://cran.r-project.org/web/checks/check_results_data.table.html)\n[![R-CMD-check](https://github.com/Rdatatable/data.table/actions/workflows/R-CMD-check.yaml/badge.svg?branch=master)](https://github.com/Rdatatable/data.table/actions)\n[![Codecov test coverage](https://codecov.io/github/Rdatatable/data.table/coverage.svg?branch=master)](https://app.codecov.io/github/Rdatatable/data.table?branch=master)\n[![GitLab CI build status](https://gitlab.com/Rdatatable/data.table/badges/master/pipeline.svg)](https://rdatatable.gitlab.io/data.table/web/checks/check_results_data.table.html)\n[![downloads](https://cranlogs.r-pkg.org/badges/data.table)](https://www.rdocumentation.org/trends)\n[![CRAN usage](https://jangorecki.gitlab.io/rdeps/data.table/CRAN_usage.svg?sanitize=true)](https://gitlab.com/jangorecki/rdeps)\n[![BioC usage](https://jangorecki.gitlab.io/rdeps/data.table/BioC_usage.svg?sanitize=true)](https://gitlab.com/jangorecki/rdeps)\n[![indirect usage](https://jangorecki.gitlab.io/rdeps/data.table/indirect_usage.svg?sanitize=true)](https://gitlab.com/jangorecki/rdeps)\n[![Powered by NumFOCUS](https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A )](https://numfocus.org)\n<!-- badges: end -->\n\n`data.table` provides a high-performance version of [base R](https://www.r-project.org/about.html)'s `data.frame` with syntax and feature enhancements for ease of use, convenience and programming speed.\n\n[//]: # (numfocus-fiscal-sponsor-attribution)\n\nThe `data.table` project uses a [custom governance agreement](https://rdatatable.gitlab.io/data.table/GOVERNANCE.html) \nand is fiscally sponsored by [NumFOCUS](https://numfocus.org/). Consider making \na [tax-deductible donation](https://numfocus.org/project/data-table) to help the project \npay for developer time, professional services, travel, workshops, and a variety of other needs.\n\n<div align=\"center\">\n  <a href=\"https://numfocus.org/project/data-table\">\n    <img width=\"25%\" \n         src=\"https://raw.githubusercontent.com/numfocus/templates/master/images/numfocus-logo.png\" \n         align=\"center\">\n  </a>\n</div>\n<br>\n\n## Why `data.table`?\n\n* concise syntax: fast to type, fast to read\n* fast speed\n* memory efficient\n* careful API lifecycle management\n* community\n* feature rich\n\n## Features\n\n* fast and friendly delimited **file reader**: **[`?fread`](https://rdatatable.gitlab.io/data.table/reference/fread.html)**, see also [convenience features for _small_ data](https://github.com/Rdatatable/data.table/wiki/Convenience-features-of-fread)\n* fast and feature rich delimited **file writer**: **[`?fwrite`](https://rdatatable.gitlab.io/data.table/reference/fwrite.html)**\n* low-level **parallelism**: many common operations are internally parallelized to use multiple CPU threads\n* fast and scalable aggregations; e.g. 100GB in RAM (see [benchmarks](https://duckdblabs.github.io/db-benchmark/) on up to **two billion rows**)\n* fast and feature rich joins: **ordered joins** (e.g. rolling forwards, backwards, nearest and limited staleness), **[overlapping range joins](https://github.com/Rdatatable/data.table/wiki/talks/EARL2014_OverlapRangeJoin_Arun.pdf)** (similar to `IRanges::findOverlaps`), **[non-equi joins](https://github.com/Rdatatable/data.table/wiki/talks/ArunSrinivasanUseR2016.pdf)** (i.e. joins using operators `>, >=, <, <=`), **aggregate on join** (`by=.EACHI`), **update on join**\n* fast add/update/delete columns **by reference** by group using no copies at all\n* fast and feature rich **reshaping** data: **[`?dcast`](https://rdatatable.gitlab.io/data.table/reference/dcast.data.table.html)** (_pivot/wider/spread_) and **[`?melt`](https://rdatatable.gitlab.io/data.table/reference/melt.data.table.html)** (_unpivot/longer/gather_)\n* **any R function from any R package** can be used in queries not just the subset of functions made available by a database backend, also columns of type `list` are supported\n* has **[no dependencies](https://en.wikipedia.org/wiki/Dependency_hell)** at all other than base R itself, for simpler production/maintenance\n* the R dependency is **as old as possible for as long as possible**, currently R 3.5.0 (2018), and we continuously test against that version\n\n## Installation\n\n```r\ninstall.packages(\"data.table\")\n\n# latest development version (only if newer available)\ndata.table::update_dev_pkg()\n\n# latest development version (force install)\ninstall.packages(\"data.table\", repos=\"https://rdatatable.gitlab.io/data.table\")\n```\n\nSee [the Installation wiki](https://github.com/Rdatatable/data.table/wiki/Installation) for more details.\n\n## Usage\n\nUse `data.table` subset `[` operator the same way you would use `data.frame` one, but...\n\n* no need to prefix each column with `DT$` (like `subset()` and `with()` but built-in)\n* any R expression using any package is allowed in `j` argument, not just list of columns\n* extra argument `by` to compute `j` expression by group\n\n```r\nlibrary(data.table)\nDT = as.data.table(iris)\n\n# FROM[WHERE, SELECT, GROUP BY]\n# DT  [i,     j,      by]\n\nDT[Petal.Width > 1.0, mean(Petal.Length), by = Species]\n#      Species       V1\n#1: versicolor 4.362791\n#2:  virginica 5.552000\n```\n\n### Getting started\n\n* [Introduction to data.table](https://cran.r-project.org/package=data.table/vignettes/datatable-intro.html) vignette\n* [Getting started](https://github.com/Rdatatable/data.table/wiki/Getting-started) wiki page\n* [Examples](https://rdatatable.gitlab.io/data.table/reference/data.table.html#examples) produced by `example(data.table)`\n\n### Cheatsheets\n\n<a href=\"https://raw.githubusercontent.com/rstudio/cheatsheets/master/datatable.pdf\"><img src=\"https://raw.githubusercontent.com/rstudio/cheatsheets/master/pngs/datatable.png\" width=\"615\" height=\"242\"/></a>\n\n## Community\n\n`data.table` is widely used by the R community. It is being directly used by hundreds of CRAN and Bioconductor packages, and indirectly by thousands. It is one of the [top most starred](https://medium.datadriveninvestor.com/most-starred-and-forked-github-repos-for-r-in-data-science-fb87a54d2a6a) R packages on GitHub, and was highly rated by the [Depsy project](http://depsy.org/package/r/data.table). If you need help, the `data.table` community is active on [StackOverflow](https://stackoverflow.com/questions/tagged/data.table).\n\nA list of packages that significantly support, extend, or make use of `data.table` can be found in the [Seal of Approval](https://github.com/Rdatatable/data.table/blob/master/Seal_of_Approval.md) document.\n\n### Stay up-to-date\n\n- click the **Watch** button at the top and right of GitHub project page\n- read [NEWS file](https://github.com/Rdatatable/data.table/blob/master/NEWS.md)\n- follow [#rdatatable](https://x.com/hashtag/rdatatable) and the [r_data_table](https://x.com/r_data_table) account on X/Twitter\n- follow [#rdatatable](https://fosstodon.org/tags/rdatatable) and the [r_data_table account](https://fosstodon.org/@r_data_table) on fosstodon\n- follow the [data.table community page](https://www.linkedin.com/company/data-table-community) on LinkedIn\n- watch recent [Presentations](https://github.com/Rdatatable/data.table/wiki/Presentations)\n- read recent [Articles](https://github.com/Rdatatable/data.table/wiki/Articles)\n- read posts on [The Raft](https://rdatatable-community.github.io/The-Raft/)\n\n### Contributing\n\nGuidelines for filing issues / pull requests: [Contribution Guidelines](https://github.com/Rdatatable/data.table/blob/master/.github/CONTRIBUTING.md).\n",
      "stars_today": 0
    },
    {
      "id": 16146440,
      "name": "rmarkdown",
      "full_name": "rstudio/rmarkdown",
      "description": "Dynamic Documents for R",
      "html_url": "https://github.com/rstudio/rmarkdown",
      "stars": 3013,
      "forks": 996,
      "language": "R",
      "topics": [
        "literate-programming",
        "markdown",
        "pandoc",
        "r",
        "r-package",
        "rmarkdown"
      ],
      "created_at": "2014-01-22T17:25:19Z",
      "updated_at": "2026-01-21T15:22:20Z",
      "pushed_at": "2025-11-26T19:36:51Z",
      "open_issues": 264,
      "owner": {
        "login": "rstudio",
        "avatar_url": "https://avatars.githubusercontent.com/u/513560?v=4"
      },
      "readme": "# rmarkdown <a href=\"https://pkgs.rstudio.com/rmarkdown/\"><img src=\"man/figures/logo.png\" align=\"right\" height=\"138\" /></a>\n\n\n<!-- badges: start -->\n[![R-CMD-check](https://github.com/rstudio/rmarkdown/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/rstudio/rmarkdown/actions/workflows/R-CMD-check.yaml)\n[![CRAN release](https://www.r-pkg.org/badges/version/rmarkdown)](https://cran.r-project.org/package=rmarkdown)\n[![Codecov test coverage](https://codecov.io/gh/rstudio/rmarkdown/branch/main/graph/badge.svg)](https://app.codecov.io/gh/rstudio/rmarkdown?branch=main)\n<!-- badges: end -->\n\n\nThe **rmarkdown** package helps you create dynamic analysis documents that combine code, rendered output (such as figures), and prose. You bring your data, code, and ideas, and R Markdown renders your content into a polished document that can be used to:\n\n- Do data science interactively within the RStudio IDE,\n\n- Reproduce your analyses,\n\n- Collaborate and share code with others, and\n\n- Communicate your results with others.\n\nR Markdown documents can be rendered to many output formats including HTML documents, PDFs, Word files, slideshows, and more, allowing you to focus on the content while R Markdown takes care of your presentation. \n\n## Books\n\n<a href=\"https://bookdown.org/yihui/rmarkdown/\"><img class=\"book\" src=\"https://bookdown.org/yihui/rmarkdown/images/cover.png\" alt=\"R Markdown: The Definitive Guide\" height=\"400\"></a>\n<a href=\"https://bookdown.org/yihui/rmarkdown-cookbook/\"><img class=\"book\" src=\"https://bookdown.org/yihui/rmarkdown-cookbook/images/cover.png\" alt=\"R Markdown Cookbook\" height=\"400\"></a>\n\nSee more about them in [Get Started](https://pkgs.rstudio.com/rmarkdown/articles/rmarkdown.html).\n\n## Installation\n\nThe easiest way to install the **rmarkdown** package is from within the [RStudio IDE](https://posit.co/download/rstudio-desktop/), but you don't need to explicitly install it or load it, as RStudio automatically does both when needed. A recent version of Pandoc (>= 1.12.3) is also required; RStudio also automatically includes this too so you do not need to download Pandoc if you plan to use rmarkdown from the RStudio IDE.\n\nIf you want to use the rmarkdown package outside of RStudio, you can install the package from CRAN as follows:\n\n```r\ninstall.packages(\"rmarkdown\")\n```\n\nIf you want to use the development version of the rmarkdown package (either with or without RStudio), you can install the package from GitHub via the [**pak** package](https://pak.r-lib.org):\n\n```r\n# install.packages(\"pak\")\npak::pak('rstudio/rmarkdown')\n```\n\nIf not using the RStudio IDE, you'll need to install a recent version of Pandoc (>= 1.12.3); see the [Pandoc installation instructions](https://pandoc.org/installing.html) for help.\n\n## Usage\n\nThe easiest way to make a new R Markdown document is from within RStudio. Go to _File > New File > R Markdown_. From the new file wizard, you may:\n\n+ Provide a document title (_optional but recommended_),\n+ Provide an author name (_optional but recommended_),\n+ Select a default output format- HTML is the recommended format for authoring, and you can switch the output format anytime (_required_), \n+ Click **OK** (_required_).\n\nOnce inside your new `.Rmd` file, you should see some boilerplate text that includes code chunks. Use the \"Knit\" button in the RStudio IDE to render the file and preview the output with a single click or use the keyboard shortcut Cmd/Ctrl + Shift + K. \n\nYou can also delete all the text below the YAML frontmatter and fill in your own `.Rmd` by:\n\n+ Adding code chunks (keyboard shortcut: `Ctrl + Alt + I`; OS X: `Cmd + Option + I`),\n+ Writing prose with [Markdown formatting](https://www.markdowntutorial.com/), and\n+ Running each code chunk interactively by clicking the ![The run button](https://rmarkdown.rstudio.com/images/notebook-run-chunk.png) icon within RStudio. \n\nYou can also click \"Knit to HTML\" again to render the full document with all code chunks. For more help getting started in R Markdown, please see the [R Markdown website](https://rmarkdown.rstudio.com/lesson-1.html) or use the **\"Get Started\"** links at the top of this page.\n\n## Getting help\n\nThere are two main places to get help:\n\n1. The [Posit community](https://forum.posit.co/c/quarto-r-markdown/10) is a friendly place to ask any questions about rmarkdown and the R Markdown family of packages.\n\n1. [Stack Overflow](https://stackoverflow.com/questions/tagged/r-markdown) is a great source of answers to common rmarkdown questions. It is also a great place to get help, once you have created a reproducible example that illustrates your problem.\n\n## Code of Conduct\n\nPlease note that the **rmarkdown** project is released with a [Contributor Code of Conduct](https://pkgs.rstudio.com/rmarkdown/CODE_OF_CONDUCT.html). By contributing to this project, you agree to abide by its terms.\n",
      "stars_today": 0
    },
    {
      "id": 643909,
      "name": "devtools",
      "full_name": "r-lib/devtools",
      "description": "Tools to make an R developer's life easier",
      "html_url": "https://github.com/r-lib/devtools",
      "stars": 2491,
      "forks": 763,
      "language": "R",
      "topics": [
        "package-creation",
        "r"
      ],
      "created_at": "2010-05-03T04:08:49Z",
      "updated_at": "2026-01-22T13:57:49Z",
      "pushed_at": "2026-01-22T20:36:08Z",
      "open_issues": 36,
      "owner": {
        "login": "r-lib",
        "avatar_url": "https://avatars.githubusercontent.com/u/22618716?v=4"
      },
      "readme": "# devtools <a href=\"https://devtools.r-lib.org/\"><img src=\"man/figures/logo.png\" align=\"right\" height=\"138\" alt=\"\"/></a>\n\n<!-- badges: start -->\n[![R-CMD-check](https://github.com/r-lib/devtools/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/r-lib/devtools/actions/workflows/R-CMD-check.yaml)\n[![CRAN_Status_Badge](https://www.r-pkg.org/badges/version/devtools)](https://cran.r-project.org/package=devtools)\n[![Codecov test coverage](https://codecov.io/gh/r-lib/devtools/graph/badge.svg)](https://app.codecov.io/gh/r-lib/devtools)\n<!-- badges: end -->\n\nThe aim of devtools is to make package development easier by providing R\nfunctions that simplify and expedite common tasks. [R\nPackages](https://r-pkgs.org/) is a book based around this workflow.\n\n## Installation\n\n```r\n# Install devtools from CRAN\ninstall.packages(\"devtools\")\n\n# Or the development version from GitHub:\n# install.packages(\"pak\")\npak::pak(\"r-lib/devtools\")\n```\n\n## Cheatsheet\n\n<a href=\"https://raw.githubusercontent.com/rstudio/cheatsheets/main/package-development.pdf\"><img src=\"https://github.com/rstudio/cheatsheets/raw/main/pngs/thumbnails/package-development-thumbs.png\" height=\"252\" alt=\"thumbnail of package development cheatsheet\"/></a>\n\n\n## Usage\n\nAll devtools functions accept a path as an argument, e.g.\n`load_all(\"path/to/mypkg\")`. If you don't specify a path, devtools will\nlook in the current working directory - this is a recommended practice.\n\n### Frequent development tasks:\n\n* `load_all()` simulates installing and reloading your package, loading R code\n  in `R/`, compiled shared objects in `src/` and data files in `data/`. During\n  development you would usually want to access all functions (even un-exported\n  internal ones) so `load_all()` works as if all functions were exported in the\n  package `NAMESPACE`.\n\n* `document()` updates generated documentation in `man/`, file collation and\n  `NAMESPACE`.\n\n* `test()` reloads your code with `load_all()`, then runs all `testthat` tests.\n\n* `test_coverage()` runs test coverage on your package with\n  [covr](https://github.com/r-lib/covr). This makes it easy to see what parts of your\n  package could use more tests!\n\n### Building and installing:\n\n* `install()` reinstalls the package, detaches the currently loaded version\n  then reloads the new version with `library()`. Reloading a package is not\n  guaranteed to work: see the documentation for `unload()` for caveats.\n\n* `build()` builds a package file from package sources. You can use it to build\n  a binary version of your package.\n\n* `install_*` functions install an R package:\n   * `install_github()` from GitHub\n   * `install_gitlab()` from GitLab\n   * `install_bitbucket()` from Bitbucket\n   * `install_url()` from an arbitrary url\n   * `install_git()` and `install_svn()` from an arbitrary git or SVN repository\n   * `install_local()` from a local file on disk\n   * `install_version()` from a specific version on CRAN\n\n* `update_packages()` updates a package to the latest version. This works\n  both on packages installed from CRAN as well as those installed from any of\n  the `install_*` functions.\n\n### Check and release:\n\n* `check()` updates the documentation, then builds and checks the package locally.\n* `check_win_release()`, `check_win_devel()`, and `check_mac_release()` check\n  a package using [win-builder](https://win-builder.r-project.org/) or\n  <https://mac.r-project.org/macbuilder/submit.html>.\n* `release()` and `submit_cran()` handle the mechanics of CRAN submission with\n  or without, respectively, (re)-running lots of local checks.\n\n## Learning more\n\nR package development can be intimidating, however there are now a number of\nvaluable resources to help!\n\n<a href=\"https://r-pkgs.org\"><img src=\"http://r-pkgs.org/images/cover-2e-small.png\" height=\"252\" align = \"right\" alt=\"Cover image of R Packages book\"/></a>\n\n1. R Packages is a book that gives a comprehensive treatment of all common parts\n   of package development and uses devtools throughout.\n    * The first edition is no longer available online, but it is still in print. Note that it has grown somewhat out of sync with the current version of devtools.\n    * A second edition that reflects the current state of devtools, plus new topics such as package websites and GitHub Actions, is available at <https://r-pkgs.org> and in paperback format.\n    * The [Whole Game](https://r-pkgs.org/whole-game.html) and\n      [Package structure](https://r-pkgs.org/package-structure-state.html) chapters\n      make great places to start.\n\n2. [Posit Community - package\n   development](https://forum.posit.co/c/package-development/11)\n   is a great place to ask specific questions related to package development.\n\n3. [rOpenSci packages](https://devguide.ropensci.org/) has\n   extensive documentation on best practices for R packages looking to be\n   contributed to rOpenSci, but also very useful general recommendations\n   for package authors.\n\n4. There are a number of fantastic blog posts on writing your first package, including\n   - [Writing an R package from scratch - Hilary Parker](https://hilaryparker.com/2014/04/29/writing-an-r-package-from-scratch/)\n   - [How to develop good R packages - Ma√´lle Salmon](https://masalmon.eu/2017/12/11/goodrpackages/)\n   - [Making your first R package - Fong Chun Chan](https://tinyheero.github.io/jekyll/update/2015/07/26/making-your-first-R-package.html)\n   - [Writing an R package from scratch - Tomas Westlake](https://r-mageddon.netlify.app/post/writing-an-r-package-from-scratch/)\n\n5. [Writing R\n   Extensions](https://cran.r-project.org/doc/manuals/r-release/R-exts.html) is\n   the exhaustive, canonical reference for writing R packages, maintained by\n   the R core developers.\n\n## Conscious uncoupling\n\ndevtools started off as a lean-and-mean package to facilitate local package\ndevelopment, but over the years it accumulated more and more functionality.\ndevtools has undergone a [conscious\nuncoupling](https://web.archive.org/web/20140326060230/https://www.goop.com/journal/be/conscious-uncoupling)\nto split out functionality into smaller, more tightly focussed packages. This\nincludes:\n\n* [testthat](https://github.com/r-lib/testthat): Writing and running tests\n  (i.e. `test()`).\n\n* [roxygen2](https://github.com/r-lib/roxygen2): Function and package documentation\n  (i.e. `document()`).\n\n* [remotes](https://github.com/r-lib/remotes): Installing packages (i.e.\n  `install_github()`).\n\n* [pkgbuild](https://github.com/r-lib/pkgbuild): Building binary packages\n  (including checking if build tools are available) (i.e. `build()`).\n\n* [pkgload](https://github.com/r-lib/pkgload): Simulating package loading (i.e.\n  `load_all()`).\n\n* [rcmdcheck](https://github.com/r-lib/rcmdcheck): Running R CMD check and\n  reporting the results (i.e. `check()`).\n\n* [revdepcheck](https://github.com/r-lib/revdepcheck): Running R CMD check on\n  all reverse dependencies, and figuring out what's changed since the last CRAN\n  release (i.e. `revdep_check()`).\n\n* [sessioninfo](https://github.com/r-lib/sessioninfo): R session info (i.e.\n  `session_info()`).\n\n* [usethis](https://github.com/r-lib/usethis): Automating package setup (i.e.\n  `use_test()`).\n\nGenerally, you would not need to worry about these different packages, because\ndevtools installs all of them automatically. You will need to care, however, if\nyou're filing a bug because reporting it at the correct place will lead to a\nspeedier resolution.\n\nYou may also need to care if you are trying to use some devtools functionality\nin your own package or deployed application. Generally in these cases it\nis better to depend on the particular package directly rather than depend on devtools,\ne.g. use `sessioninfo::session_info()` rather than `devtools::session_info()`,\nor `remotes::install_github()` vs `devtools::install_github()`.\n\nHowever for day to day development we recommend you continue to use\n`library(devtools)` to quickly load all needed development tools, just like\n`library(tidyverse)` quickly loads all the tools necessary for data exploration\nand visualization.\n\n## Code of conduct\n\nPlease note that the devtools project is released with a [Contributor Code of Conduct](https://github.com/r-lib/devtools/blob/main/.github/CODE_OF_CONDUCT.md). By contributing to this project, you agree to abide by its terms.\n",
      "stars_today": 0
    },
    {
      "id": 387532152,
      "name": "swift-markdown",
      "full_name": "swiftlang/swift-markdown",
      "description": "A Swift package for parsing, building, editing, and analyzing Markdown documents.",
      "html_url": "https://github.com/swiftlang/swift-markdown",
      "stars": 3214,
      "forks": 250,
      "language": "Swift",
      "topics": [],
      "created_at": "2021-07-19T16:42:24Z",
      "updated_at": "2026-01-24T01:32:31Z",
      "pushed_at": "2026-01-21T16:24:56Z",
      "open_issues": 58,
      "owner": {
        "login": "swiftlang",
        "avatar_url": "https://avatars.githubusercontent.com/u/42816656?v=4"
      },
      "readme": "# Swift Markdown\n\nSwift `Markdown` is a Swift package for parsing, building, editing, and analyzing Markdown documents.\n\nThe parser is powered by GitHub-flavored Markdown's [cmark-gfm](https://github.com/github/cmark-gfm) implementation, so it follows the spec closely. As the needs of the community change, the effective dialect implemented by this library may change.\n\nThe markup tree provided by this package is comprised of immutable/persistent, thread-safe, copy-on-write value types that only copy substructure that has changed. Other examples of the main strategy behind this library can be seen in [SwiftSyntax](https://github.com/swiftlang/swift-syntax).\n\n## Getting Started Using Markup\n\nIn your `Package.swift` Swift Package Manager manifest, add the following dependency to your `dependencies` argument:\n\n```swift\n.package(url: \"https://github.com/swiftlang/swift-markdown.git\", branch: \"main\"),\n```\n\nAdd the dependency to any targets you've declared in your manifest:\n\n```swift\n.target(\n    name: \"MyTarget\", \n    dependencies: [\n        .product(name: \"Markdown\", package: \"swift-markdown\"),\n    ]\n),\n```\n\nTo parse a document, use `Document(parsing:)`, supplying a `String` or `URL`:\n\n```swift\nimport Markdown\n\nlet source = \"This is a markup *document*.\"\nlet document = Document(parsing: source)\nprint(document.debugDescription())\n// Document\n// ‚îî‚îÄ Paragraph\n//    ‚îú‚îÄ Text \"This is a markup \"\n//    ‚îú‚îÄ Emphasis\n//    ‚îÇ  ‚îî‚îÄ Text \"document\"\n//    ‚îî‚îÄ Text \".\"\n```\n\nPlease see Swift `Markdown`'s [documentation site](https://swiftlang.github.io/swift-markdown/documentation/markdown/)\nfor more detailed information about the library.\n\n## Contributing to Swift Markdown\n\nPlease see the [contributing guide](https://swift.org/contributing/#contributing-code) for more information.\n\n### Submitting a Bug Report\n\nSwift Markdown tracks all bug reports with [GitHub Issues](https://github.com/swiftlang/swift-markdown/issues).\nYou can use the \"Swift-Markdown\" component for issues and feature requests specific to Swift Markdown.\nWhen you submit a bug report we ask that you follow the\nSwift [Bug Reporting](https://swift.org/contributing/#reporting-bugs) guidelines\nand provide as many details as possible.\n\n### Submitting a Feature Request\n\nFor feature requests, please feel free to file a [GitHub issue](https://github.com/swiftlang/swift-markdown/issues/new)\nor start a discussion on the [Swift Forums](https://forums.swift.org/c/development/swift-docc).\n\nDon't hesitate to submit a feature request if you see a way\nSwift Markdown can be improved to better meet your needs.\n\n\n\n<!-- Copyright (c) 2021-2023 Apple Inc and the Swift Project authors. All Rights Reserved. -->\n",
      "stars_today": 0
    },
    {
      "id": 242202166,
      "name": "opentelemetry-go-contrib",
      "full_name": "open-telemetry/opentelemetry-go-contrib",
      "description": "Collection of extensions for OpenTelemetry-Go.",
      "html_url": "https://github.com/open-telemetry/opentelemetry-go-contrib",
      "stars": 1584,
      "forks": 737,
      "language": "Go",
      "topics": [],
      "created_at": "2020-02-21T18:12:36Z",
      "updated_at": "2026-01-23T17:23:02Z",
      "pushed_at": "2026-01-23T17:22:59Z",
      "open_issues": 203,
      "owner": {
        "login": "open-telemetry",
        "avatar_url": "https://avatars.githubusercontent.com/u/49998002?v=4"
      },
      "readme": "# OpenTelemetry-Go Contrib\n\n[![build_and_test](https://github.com/open-telemetry/opentelemetry-go-contrib/workflows/build_and_test/badge.svg)](https://github.com/open-telemetry/opentelemetry-go-contrib/actions?query=workflow%3Abuild_and_test+branch%3Amain)\n[![codecov.io](https://codecov.io/gh/open-telemetry/opentelemetry-go-contrib/coverage.svg?branch=main)](https://app.codecov.io/gh/open-telemetry/opentelemetry-go-contrib?branch=main)\n[![Docs](https://godoc.org/go.opentelemetry.io/contrib?status.svg)](https://pkg.go.dev/go.opentelemetry.io/contrib)\n[![Go Report Card](https://goreportcard.com/badge/go.opentelemetry.io/contrib)](https://goreportcard.com/report/go.opentelemetry.io/contrib)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/opentelemetry-go-contrib.svg)](https://issues.oss-fuzz.com/issues?q=project:opentelemetry-go-contrib)\n[![Slack](https://img.shields.io/badge/slack-@cncf/otel--go-brightgreen.svg?logo=slack)](https://cloud-native.slack.com/archives/C01NPAXACKT)\n\nCollection of 3rd-party packages for [OpenTelemetry-Go](https://github.com/open-telemetry/opentelemetry-go).\n\n## Contents\n\n- [Examples](./examples/): Examples of OpenTelemetry libraries usage.\n- [Instrumentation](./instrumentation/): Packages providing OpenTelemetry instrumentation for 3rd-party libraries.\n- [Propagators](./propagators/): Packages providing OpenTelemetry context propagators for 3rd-party propagation formats.\n- [Detectors](./detectors/): Packages providing OpenTelemetry resource detectors for 3rd-party cloud computing environments.\n- [Exporters](./exporters/): Packages providing OpenTelemetry exporters for 3rd-party export formats.\n- [Samplers](./samplers/): Packages providing additional implementations of OpenTelemetry samplers.\n- [Bridges](./bridges/): Packages providing adapters for 3rd-party instrumentation frameworks.\n- [Processors](./processors/): Packages providing additional implementations of OpenTelemetry processors.\n\n## Project Status\n\nThis project contains both stable and unstable modules.\nRefer to the module for its version or our [versioning manifest](./versions.yaml).\n\nProject versioning information and stability guarantees can be found in the [versioning documentation](https://github.com/open-telemetry/opentelemetry-go/blob/a724cf884287e04785eaa91513d26a6ef9699288/VERSIONING.md).\n\nProgress and status specific to this repository is tracked in our local [project boards](https://github.com/open-telemetry/opentelemetry-go-contrib/projects?query=is%3Aopen) and [milestones](https://github.com/open-telemetry/opentelemetry-go-contrib/milestones).\n\n### Compatibility\n\nOpenTelemetry-Go Contrib ensures compatibility with the current supported\nversions of\nthe [Go language](https://golang.org/doc/devel/release#policy):\n\n> Each major Go release is supported until there are two newer major releases.\n> For example, Go 1.5 was supported until the Go 1.7 release, and Go 1.6 was supported until the Go 1.8 release.\n\nFor versions of Go that are no longer supported upstream, opentelemetry-go-contrib will\nstop ensuring compatibility with these versions in the following manner:\n\n- A minor release of opentelemetry-go-contrib will be made to add support for the new\n  supported release of Go.\n- The following minor release of opentelemetry-go-contrib will remove compatibility\n  testing for the oldest (now archived upstream) version of Go. This, and\n  future, releases of opentelemetry-go-contrib may include features only supported by\n  the currently supported versions of Go.\n\nThis project is tested on the following systems.\n\n| OS       | Go Version | Architecture |\n| -------- | ---------- | ------------ |\n| Ubuntu   | 1.25       | amd64        |\n| Ubuntu   | 1.24       | amd64        |\n| Ubuntu   | 1.25       | 386          |\n| Ubuntu   | 1.24       | 386          |\n| macOS    | 1.25       | amd64        |\n| macOS    | 1.24       | amd64        |\n| macOS    | 1.25       | arm64        |\n| macOS    | 1.24       | arm64        |\n| Windows  | 1.25       | amd64        |\n| Windows  | 1.24       | amd64        |\n| Windows  | 1.25       | 386          |\n| Windows  | 1.24       | 386          |\n\nWhile this project should work for other systems, no compatibility guarantees\nare made for those systems currently.\n\n## Contributing\n\nFor information on how to contribute, consult [the contributing guidelines](./CONTRIBUTING.md)\n",
      "stars_today": 0
    },
    {
      "id": 55534429,
      "name": "sentry-cocoa",
      "full_name": "getsentry/sentry-cocoa",
      "description": "The official Sentry SDK for iOS, tvOS, macOS, watchOS, iPadOS and visionOS.",
      "html_url": "https://github.com/getsentry/sentry-cocoa",
      "stars": 1009,
      "forks": 376,
      "language": "Swift",
      "topics": [
        "cocoa",
        "crash",
        "crash-reporting",
        "crash-reports",
        "error-handler",
        "error-monitoring",
        "ios",
        "ipados",
        "macos",
        "objective-c",
        "sdk",
        "sentry",
        "swift",
        "tag-production",
        "team-mobile",
        "tvos",
        "visionos",
        "watchos"
      ],
      "created_at": "2016-04-05T18:55:09Z",
      "updated_at": "2026-01-23T21:20:43Z",
      "pushed_at": "2026-01-23T22:38:09Z",
      "open_issues": 343,
      "owner": {
        "login": "getsentry",
        "avatar_url": "https://avatars.githubusercontent.com/u/1396951?v=4"
      },
      "readme": "<div align=\"center\">\n    <a href=\"https://sentry.io/?utm_source=github&utm_medium=logo\" target=\"_blank\">\n        <img src=\"https://sentry-brand.storage.googleapis.com/github-banners/github-sdk-cocoa.jpg\" alt=\"Sentry for Apple\">\n    </a>\n</div>\n\n_Bad software is everywhere, and we're tired of it. Sentry is on a mission to help developers write better software faster, so we can get back to enjoying technology. If you want to join us [<kbd>**Check out our open positions**</kbd>](https://sentry.io/careers/)_\n\n> [!NOTE]\n> You are currently viewing the **`main`** branch which contains the upcoming **v9** release with breaking changes.\n>\n> For the stable **v8** release, please switch to the [`v8.x` branch](https://github.com/getsentry/sentry-cocoa/tree/v8.x) and refer to the [v8 CHANGELOG](https://github.com/getsentry/sentry-cocoa/blob/v8.x/CHANGELOG.md).\n\n# Official Sentry SDK for iOS / tvOS / macOS / watchOS <sup>(1)</sup>\n\n[![Build](https://img.shields.io/github/actions/workflow/status/getsentry/sentry-cocoa/build.yml?branch=main)](https://github.com/getsentry/sentry-cocoa/actions/workflows/build.yml?query=branch%3Amain)\n[![codecov.io](https://codecov.io/gh/getsentry/sentry-cocoa/branch/master/graph/badge.svg)](https://codecov.io/gh/getsentry/sentry-cocoa)\n[![CocoaPods compatible](https://img.shields.io/cocoapods/v/Sentry.svg)](https://cocoapods.org/pods/Sentry)\n[![SwiftPM compatible](https://img.shields.io/badge/spm-compatible-brightgreen.svg?style=flat)](https://swift.org/package-manager)\n![platforms](https://img.shields.io/cocoapods/p/Sentry.svg?style=flat)\n[![Swift Package Index](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fgetsentry%2Fsentry-cocoa%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/getsentry/sentry-cocoa)\n[![X Follow](https://img.shields.io/twitter/follow/sentry?label=sentry&style=social)](https://x.com/intent/follow?screen_name=sentry)\n[![Discord Chat](https://img.shields.io/discord/621778831602221064?logo=discord&logoColor=ffffff&color=7389D8)](https://discord.com/invite/sentry)\n\n# Installation\n\nSPM is the recommended way to include Sentry into your project, but we also support [CocoaPods](https://cocoapods.org/pods/Sentry), and provide pre-built XCFrameworks on [our GitHub Releases page](https://github.com/getsentry/sentry-cocoa/releases).\n\n# Initialization\n\n_Remember to call this as early in your application life cycle as possible_\nIdeally in `applicationDidFinishLaunching` in `AppDelegate`\n\n```swift\nimport Sentry\n\n// ....\n\nSentrySDK.start { options in\n    options.dsn = \"___PUBLIC_DSN___\"\n    options.debug = true // Helpful to see what's going on\n}\n```\n\n```objc\n@import Sentry;\n\n// ....\n\n[SentrySDK startWithConfigureOptions:^(SentryOptions *options) {\n    options.dsn = @\"___PUBLIC_DSN___\";\n    options.debug = @YES; // Helpful to see what's going on\n}];\n```\n\nFor more information checkout the [docs](https://docs.sentry.io/platforms/apple).\n\n<sup>(1)</sup>limited symbolication support and no crash handling.\n\n# Blog posts\n\n[Mobile Vitals - Four Metrics Every Mobile Developer Should Care About](https://blog.sentry.io/2021/08/23/mobile-vitals-four-metrics-every-mobile-developer-should-care-about/).\n\n[How to use Sentry Attachments with Mobile Applications](https://blog.sentry.io/2021/02/03/how-to-use-sentry-attachments-with-mobile-applications/?utm_source=github&utm_medium=readme&utm_campaign=sentry-cocoa).\n\n[Close the Loop with User Feedback](https://blog.sentry.io/2021/02/16/close-the-loop-with-user-feedback/?utm_source=github&utm_medium=readme&utm_campaign=sentry-cocoa).\n\n[A Sanity Listicle for Mobile Developers](https://blog.sentry.io/2021/03/30/a-sanity-listicle-for-mobile-developers/?utm_source=github&utm_medium=readme&utm_campaign=sentry-cocoa).\n\n# Resources\n\n- [![Documentation](https://img.shields.io/badge/documentation-sentry.io-green.svg)](https://docs.sentry.io/platforms/apple/)\n- [![Discussions](https://img.shields.io/github/discussions/getsentry/sentry-cocoa.svg)](https://github.com/getsentry/sentry-cocoa/discussions)\n- [![Discord Chat](https://img.shields.io/discord/621778831602221064?logo=discord&logoColor=ffffff&color=7389D8)](https://discord.com/invite/sentry)\n- [![Stack Overflow](https://img.shields.io/badge/stack%20overflow-sentry-green.svg)](http://stackoverflow.com/questions/tagged/sentry)\n- [![Code of Conduct](https://img.shields.io/badge/code%20of%20conduct-sentry-green.svg)](https://github.com/getsentry/.github/blob/master/CODE_OF_CONDUCT.md)\n- [![Twitter Follow](https://img.shields.io/twitter/follow/getsentry?label=getsentry&style=social)](https://twitter.com/intent/follow?screen_name=getsentry)\n",
      "stars_today": 0
    },
    {
      "id": 20360040,
      "name": "clusterProfiler",
      "full_name": "YuLab-SMU/clusterProfiler",
      "description": ":bar_chart: A universal enrichment tool for interpreting omics data",
      "html_url": "https://github.com/YuLab-SMU/clusterProfiler",
      "stars": 1156,
      "forks": 263,
      "language": "R",
      "topics": [
        "enrichment-analysis",
        "go",
        "gsea",
        "kegg",
        "rstats",
        "visualization"
      ],
      "created_at": "2014-05-31T16:34:32Z",
      "updated_at": "2026-01-22T06:05:51Z",
      "pushed_at": "2026-01-22T06:05:47Z",
      "open_issues": 362,
      "owner": {
        "login": "YuLab-SMU",
        "avatar_url": "https://avatars.githubusercontent.com/u/40430016?v=4"
      },
      "readme": "# clusterProfiler\n\n<img src=\"inst/sticker/clusterProfiler_hex.png\" height=\"200\" align=\"right\" />\n\n[![Project Status: Active - The project has reached a stable, usable\nstate and is being actively\ndeveloped.](http://www.repostatus.org/badges/latest/active.svg)](http://www.repostatus.org/#active)\n[![](https://img.shields.io/badge/release%20version-4.18.4-green.svg)](https://www.bioconductor.org/packages/clusterProfiler)\n[![](https://img.shields.io/badge/devel%20version-4.19.4.006-green.svg)](https://github.com/guangchuangyu/clusterProfiler)\n[![Bioc](http://www.bioconductor.org/shields/years-in-bioc/clusterProfiler.svg)](https://www.bioconductor.org/packages/devel/bioc/html/clusterProfiler.html#since)\n\n[![platform](http://www.bioconductor.org/shields/availability/devel/clusterProfiler.svg)](https://www.bioconductor.org/packages/devel/bioc/html/clusterProfiler.html#archives)\n[![Build\nStatus](http://www.bioconductor.org/shields/build/devel/bioc/clusterProfiler.svg)](https://bioconductor.org/checkResults/devel/bioc-LATEST/clusterProfiler/)\n[![codecov](https://codecov.io/gh/GuangchuangYu/clusterProfiler/branch/master/graph/badge.svg)](https://codecov.io/gh/GuangchuangYu/clusterProfiler/)\n\n<!--\n[![Last-changedate](https://img.shields.io/badge/last%20change-2026--01--21-green.svg)](https://github.com/GuangchuangYu/clusterProfiler/commits/master)\n-->\n\n- [clusterProfiler](http://bioconductor.org/packages/clusterProfiler)\n  supports exploring functional characteristics of both coding and\n  non-coding genomics data for thousands of species with up-to-date gene\n  annotation.\n- It provides a universal interface for gene functional annotation from\n  a variety of sources and thus can be applied in diverse scenarios.\n- It provides a tidy interface to access, manipulate, and visualize\n  enrichment results to help users achieve efficient data interpretation\n- Datasets obtained from multiple treatments and time points can be\n  analyzed and compared in a single run, easily revealing functional\n  consensus and differences among distinct conditions\n\nFor details, please visit:\n\n- <https://yulab-smu.top/contribution-knowledge-mining/>\n- <https://yulab-smu.top/biomedical-knowledge-mining-book/>\n\n<img src=\"graphic-abstract-The-Innovation-2021.jpg\" width=\"890\"/>\n\n## :writing_hand: Authors\n\nGuangchuang YU <https://yulab-smu.top>\n\nSchool of Basic Medical Sciences, Southern Medical University\n\n------------------------------------------------------------------------\n\nIf you use\n[clusterProfiler](http://bioconductor.org/packages/clusterProfiler) in\npublished research, please cite the most appropriate paper(s) from this\nlist:\n\n1.  S Xu<sup>\\#</sup>, E Hu<sup>\\#</sup>, Y Cai<sup>\\#</sup>, Z\n    Xie<sup>\\#</sup>, X Luo<sup>\\#</sup>, L Zhan, W Tang, Q Wang, B Liu,\n    R Wang, W Xie, T Wu, L Xie, **G Yu**<sup>\\*</sup>. Using\n    clusterProfiler to characterise Multi-Omics Data. ***Nature\n    Protocols***. 2024, accepted. doi:\n    [10.1038/s41596-024-01020-z](https://doi.org/10.1038/s41596-024-01020-z)\n2.  T Wu<sup>\\#</sup>, E Hu<sup>\\#</sup>, S Xu, M Chen, P Guo, Z Dai, T\n    Feng, L Zhou, W Tang, L Zhan, X Fu, S Liu, X Bo<sup>\\*</sup>, **G\n    Yu**<sup>\\*</sup>. clusterProfiler 4.0: A universal enrichment tool\n    for interpreting omics data. ***The Innovation***. 2021,\n    2(3):100141. doi:\n    [10.1016/j.xinn.2021.100141](https://doi.org/10.1016/j.xinn.2021.100141)\n3.  **G Yu**<sup>\\*</sup>. Gene Ontology Semantic Similarity Analysis\n    Using GOSemSim. In: Kidder B. (eds) Stem Cell Transcriptional\n    Networks. ***Methods in Molecular Biology***. 2020, 2117:207-215.\n    Humana, New York, NY. doi:\n    [10.1007/978-1-0716-0301-7_11](https://doi.org/10.1007/978-1-0716-0301-7_11)\n4.  **G Yu**<sup>\\*</sup>. Using meshes for MeSH term enrichment and\n    semantic analyses. ***Bioinformatics***. 2018, 34(21):3766‚Äì3767.\n    doi:\n    [10.1093/bioinformatics/bty410](https://doi.org/10.1093/bioinformatics/bty410)\n5.  **G Yu**, QY He<sup>\\*</sup>. ReactomePA: an R/Bioconductor package\n    for reactome pathway analysis and visualization. ***Molecular\n    BioSystems***. 2016, 12(2):477-479. doi:\n    [10.1039/C5MB00663E](https://doi.org/10.1039/C5MB00663E)\n6.  **G Yu**<sup>\\*</sup>, LG Wang, and QY He<sup>\\*</sup>. ChIPseeker:\n    an R/Bioconductor package for ChIP peak annotation, comparison and\n    visualization. ***Bioinformatics***. 2015, 31(14):2382-2383. doi:\n    [10.1093/bioinformatics/btv145](https://doi.org/10.1093/bioinformatics/btv145)\n7.  **G Yu**<sup>\\*</sup>, LG Wang, GR Yan, QY He<sup>\\*</sup>. DOSE: an\n    R/Bioconductor package for Disease Ontology Semantic and Enrichment\n    analysis. ***Bioinformatics***. 2015, 31(4):608-609. doi:\n    [10.1093/bioinformatics/btu684](https://doi.org/10.1093/bioinformatics/btu684)\n8.  **G Yu**, LG Wang, Y Han and QY He<sup>\\*</sup>. clusterProfiler: an\n    R package for comparing biological themes among gene clusters.\n    ***OMICS: A Journal of Integrative Biology***. 2012, 16(5):284-287.\n    doi: [10.1089/omi.2011.0118](https://doi.org/10.1089/omi.2011.0118)\n9.  **G Yu**, F Li, Y Qin, X Bo<sup>\\*</sup>, Y Wu, S Wang<sup>\\*</sup>.\n    GOSemSim: an R package for measuring semantic similarity among GO\n    terms and gene products. ***Bioinformatics***. 2010, 26(7):976-978.\n    doi:\n    [10.1093/bioinformatics/btq064](https://doi.org/10.1093/bioinformatics/btq064)\n\n<!--\n&#10;\n&#10; r badge_custom(\"1st most cited paper\", \"in OMICS\", \"green\",\n  \"http://online.liebertpub.com/action/showMostCitedArticles?journalCode=omi\")`\n r badge_custom(\"ESI\", \"Highly Cited Paper\", \"green\")`\n r badge_doi(\"10.1089/omi.2011.0118\", \"green\")`\n&#10;\n------------------------------------------------------------------------\n&#10;### Citation\n&#10;\n&#10;\n<img src=\"https://guangchuangyu.github.io/software/citation_trend/clusterProfiler.png\" width=\"890\"/>\n&#10;\n### Download stats\n&#10;r badge_download_bioc(\"clusterProfiler\")\nr badge_bioc_download(\"clusterProfiler\", \"total\", \"blue\")\nr badge_bioc_download(\"clusterProfiler\", \"month\", \"blue\")\n&#10;\n<img src=\"https://guangchuangyu.github.io/software/dlstats/clusterProfiler.png\" width=\"890\"/>\n&#10;-->\n",
      "stars_today": 0
    },
    {
      "id": 2188402,
      "name": "phyloseq",
      "full_name": "joey711/phyloseq",
      "description": "phyloseq is a set of classes, wrappers, and tools (in R) to make it easier to import, store, and analyze phylogenetic sequencing data; and to reproducibly share that data and analysis with others. See the phyloseq front page:",
      "html_url": "https://github.com/joey711/phyloseq",
      "stars": 635,
      "forks": 193,
      "language": "R",
      "topics": [],
      "created_at": "2011-08-11T00:16:34Z",
      "updated_at": "2026-01-12T16:12:10Z",
      "pushed_at": "2024-04-29T20:03:19Z",
      "open_issues": 765,
      "owner": {
        "login": "joey711",
        "avatar_url": "https://avatars.githubusercontent.com/u/841437?v=4"
      },
      "readme": "<link href=\"http://joey711.github.com/phyloseq/markdown.css\" rel=\"stylesheet\"></link>\n\n# [phyloseq](http://joey711.github.com/phyloseq/)\n\n[![Travis-CI Build Status](https://travis-ci.org/joey711/phyloseq.svg?branch=master)](https://travis-ci.org/joey711/phyloseq)\n\n![phyloseq](inst/extdata/phyloseq.png)\n\n## Quick Install\n\nIn R terminal:\n\n```\nif(!requireNamespace(\"BiocManager\")){\n  install.packages(\"BiocManager\")\n}\nBiocManager::install(\"phyloseq\")\n```\n\nSee [the phyloseq installation page](http://joey711.github.io/phyloseq/install.html)\nfor further details, examples.\n\n## Article on Improved Microbiome Analysis\n\nMcMurdie and Holmes (2014)\n[Waste Not, Want Not: Why Rarefying Microbiome Data is Statistically Inadmissible](http://dx.plos.org/10.1371/journal.pcbi.1003531)\n*PLoS Computational Biology*\n10(4): e1003531\n\nPresubmission versions ahead of acceptance (2013):\n[PDF version 2](http://arxiv.org/pdf/1310.0424v2.pdf),\n[PDF version 1](http://arxiv.org/pdf/1310.0424v1.pdf)\n\n\n## Peer-reviewed articles about phyloseq\n\nMcMurdie and Holmes (2014) [Shiny-phyloseq: Web Application for Interactive Microbiome Analysis with Provenance Tracking](http://bioinformatics.oxfordjournals.org/content/early/2014/10/02/bioinformatics.btu616).\n*Bioinformatics (Oxford, England)*\n31(2), 282‚Äì283.\n\nMcMurdie and Holmes (2013)\n[phyloseq: An R package for reproducible interactive analysis and graphics of microbiome census data](http://dx.plos.org/10.1371/journal.pone.0061217)\n*PLoS ONE* \n8(4):e61217\n\n## Other resources\n\nThe phyloseq project also has a number of supporting online resources,\nincluding (but probably not limited to)\n\n### [the phyloseq home page](http://joey711.github.com/phyloseq/)\n\n### [the phyloseq FAQ](https://www.bioconductor.org/packages/release/bioc/vignettes/phyloseq/inst/doc/phyloseq-FAQ.html)\nI recommend checking this page, and the issues tracker,\nbefore posting new issues.\n\n### [Bioconductor stable release](http://bioconductor.org/packages/release/bioc/html/phyloseq.html).\n\n### [the phyloseq Issue Tracker](https://github.com/joey711/phyloseq/issues)\nThis is the recommended location to post\n\n(1) feature requests\n(2) bug reports\n(3) theoretical considerations\n(4) other issues, feedback\n(5) ask for help\n\nSearch previous posts,\nand check [the phyloseq FAQ](https://www.bioconductor.org/packages/release/bioc/vignettes/phyloseq/inst/doc/phyloseq-FAQ.html)\nbefore posting a new issue.\n",
      "stars_today": 0
    },
    {
      "id": 53894616,
      "name": "infercnv",
      "full_name": "broadinstitute/infercnv",
      "description": "Inferring CNV from Single-Cell RNA-Seq",
      "html_url": "https://github.com/broadinstitute/infercnv",
      "stars": 650,
      "forks": 177,
      "language": "R",
      "topics": [],
      "created_at": "2016-03-14T21:53:54Z",
      "updated_at": "2026-01-20T07:04:11Z",
      "pushed_at": "2025-11-14T17:35:17Z",
      "open_issues": 236,
      "owner": {
        "login": "broadinstitute",
        "avatar_url": "https://avatars.githubusercontent.com/u/393552?v=4"
      },
      "readme": "\n***********************************************\n>InferCNV is no longer supported. Please explore alternatives such as InferCNA (https://jlaffy.github.io/infercna/)[https://jlaffy.github.io/infercna/], CopyKAT (https://github.com/navinlabcode/copykat)[https://github.com/navinlabcode/copykat], and Numbat (https://github.com/kharchenkolab/numbat)[https://github.com/kharchenkolab/numbat]\n***********************************************\n\n# Subclustering\n\nSubclustering resolution is one of the primary settings that will need to be adjusted in most runs to avoid oversplitting. The tutorial below explains how it works and details about it can also be found on the [wiki](https://github.com/broadinstitute/infercnv/wiki/infercnv-tumor-subclusters#tumor-subclustering-by-leiden-clustering-preferred).\n\n# Documentation\n### Full documentation\n\nVisit project [wiki](https://github.com/broadinstitute/inferCNV/wiki) for InferCNV documentation.\n\n\n### Infercnv video tutorial\n\nA **video** tutorial giving on overview of infercnv features and how to run an analysis can be found below **(click on the image)**:\n\n[![Tutorial: Running infercnv](http://img.youtube.com/vi/-qOcHAavZT8/0.jpg)](http://www.youtube.com/watch?v=-qOcHAavZT8 \"Tutorial: Running infercnv\")\n\n\n\n",
      "stars_today": 0
    },
    {
      "id": 120286519,
      "name": "nichenetr",
      "full_name": "saeyslab/nichenetr",
      "description": "NicheNet: predict active ligand-target links between interacting cells",
      "html_url": "https://github.com/saeyslab/nichenetr",
      "stars": 609,
      "forks": 134,
      "language": "R",
      "topics": [
        "cell-cell-communication",
        "data-integration",
        "gene-expression",
        "intercellular-communication",
        "ligand-receptor",
        "ligand-target",
        "network-inference",
        "rna-seq",
        "single-cell-omics",
        "single-cell-rna-seq"
      ],
      "created_at": "2018-02-05T09:58:45Z",
      "updated_at": "2026-01-22T23:45:57Z",
      "pushed_at": "2025-11-12T09:07:45Z",
      "open_issues": 25,
      "owner": {
        "login": "saeyslab",
        "avatar_url": "https://avatars.githubusercontent.com/u/18485264?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n<!-- github markdown built using\nrmarkdown::render(\"README.Rmd\",output_format = \"md_document\")\n-->\n\n# nichenetr\n\n<!-- badges: start -->\n\n[![R build\nstatus](https://github.com/saeyslab/nichenetr/workflows/R-CMD-check-bioc/badge.svg)](https://github.com/saeyslab/nichenetr/actions)\n[![Coverage\nStatus](https://codecov.io/gh/saeyslab/nichenetr/branch/master/graph/badge.svg)](https://codecov.io/gh/saeyslab/nichenetr)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3260758.svg)](https://doi.org/10.5281/zenodo.3260758)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7074291.svg)](https://doi.org/10.5281/zenodo.7074291)\n<!-- badges: end -->\n\n**nichenetr: the R implementation of the NicheNet method.** The goal of\nNicheNet is to study intercellular communication from a computational\nperspective. NicheNet uses human or mouse gene expression data of\ninteracting cells as input and combines this with a prior model that\nintegrates existing knowledge on ligand-to-target signaling paths. This\nallows to predict ligand-receptor interactions that might drive gene\nexpression changes in cells of interest.\n\nWe describe the NicheNet algorithm in the following paper: [NicheNet:\nmodeling intercellular communication by linking ligands to target\ngenes](https://www.nature.com/articles/s41592-019-0667-5).\n\nTo help users **customize NicheNet** to their specific biological use-case, we have recently published a **best practices workflow** cultivated over four years of experience and user feedback  \n[Unraveling cell-cell communication with NicheNet by inferring active\nligands from transcriptomics\ndata](https://www.nature.com/articles/s41596-024-01121-9). In the\nstep-by-step protocol, we describe both a ‚Äòsender-agnostic‚Äô approach\nthat considers ligands from the entire microenvironment and a\n‚Äòsender-focused‚Äô approach that only considers ligands from cell\npopulations of interest. We also include a new downstream procedure for\nprioritizing cell type-specific ligand-receptor pairs. The code to\nreproduce this protocol and the resulting figures can be found on\n<https://github.com/saeyslab/nichenet_protocol>.\n\n## Installation of nichenetr\n\nInstallation typically takes a few minutes, depending on the number of\ndependencies that has already been installed on your PC. You can install\nnichenetr (and required dependencies) from github with:\n\n``` r\nif(!requireNamespace(\"devtools\", quietly = TRUE)) {\n  install.packages(\"devtools\") \n}\n\ndevtools::install_github(\"saeyslab/nichenetr\")\n```\n\nnichenetr was tested on both Windows and Linux (most recently tested R\nversion: R 4.3.2)\n\n## Overview of NicheNet\n\n<details>\n<summary>\n<h3>\nBackground\n</h3>\n</summary>\n\nNicheNet strongly differs from most computational approaches to study\ncell-cell communication (CCC), as summarized conceptually by the figure\nbelow (**top panel:** current ligand-receptor inference approaches;\n**bottom panel:** NicheNet). Many approaches to study CCC from\nexpression data involve linking ligands expressed by sender cells to\ntheir corresponding receptors expressed by receiver cells. However,\nfunctional understanding of a CCC process also requires knowing how\nthese inferred ligand-receptor interactions result in changes in the\nexpression of downstream target genes within the receiver cells.\nTherefore, we developed NicheNet to consider the gene regulatory effects\nof ligands. <br><br>\n<img src=\"vignettes/images/comparison_other_approaches_2.jpg\"\nwidth=\"450\" /> <br><br>\n\nAt the core of NicheNet is a prior knowledge model, created by\nintegrating three types of databases‚Äîligand-receptor interactions,\nsignaling pathways, and transcription factor (TF) regulation‚Äîto form a\ncomplete communication network spanning from ligands to their downstream\ntarget genes (see figure below). Therefore, this model goes beyond\nligand-receptor interactions and incorporates intracellular signaling\nand transcriptional regulation as well. As a result, NicheNet is able to\npredict which ligands influence the expression in another cell, which\ntarget genes are affected by each ligand, and which signaling mediators\nmay be involved. By generating these novel types of hypotheses, NicheNet\ncan drive an improved functional understanding of a CCC process of\ninterest. Note that although we provide a pre-built prior model, it is\nalso possible to construct your own model (see vignettes below).\n\n<img src=\"vignettes/images/nichenet_prior_model.png\"\nstyle=\"width:70.0%\" />\n</details>\n<details>\n<summary>\n<h3>\nMain functionalities of nichenetr\n</h3>\n</summary>\n\n- Assessing how well ligands expressed by a sender cell can predict\n  changes in gene expression in the receiver cell\n- Prioritizing ligands based on their effect on gene expression\n- Inferring putative ligand-target links active in the system under\n  study\n- Inferring potential signaling paths between ligands and target genes\n  of interest: to generate causal hypotheses and check which data\n  sources support the predictions\n- Validation of the prior ligand-target model\n- Construction of user-defined prior ligand-target models\n\nMoreover, we provide instructions on how to make intuitive\nvisualizations of the main predictions (e.g., via circos plots as shown\nhere below).\n\n<br><br>\n<img src=\"vignettes/images/circos_plot_adapted.jpg\" width=\"600\" />\n\n</details>\n\nAs input to NicheNet, users must provide cell type-annotated expression\ndata that reflects a cell-cell communication (CCC) event. The input can\nbe single-cell or sorted bulk data from human or mouse. As output,\nNicheNet returns the ranking of ligands that best explain the CCC event\nof interest, as well as candidate target genes with high potential to be\nregulated by these ligands. As an intermediate step, we extract the\nthree features required for the analysis: a list of potential ligands, a\ngene set that captures the downstream effects of the CCC event of\ninterest, and a background set of genes. Further explanation on each\nfeature can be found in the introductory vignette.\n\n![](vignettes/images/figure1.svg) <br><br>\n\n## Learning to use nichenetr\n\nThe following vignettes contain the explanation on how to perform a\nbasic NicheNet analysis on a Seurat object. This includes prioritizing\nligands and predicting target genes of prioritized ligands. We recommend\nstarting with the step-by-step analysis, but we also demonstrate the use\nof a single wrapper function. This demo analysis takes only a few\nminutes to run.\n\n- [Perform NicheNet analysis starting from a Seurat object: step-by-step\n  analysis](vignettes/seurat_steps.md):`vignette(\"seurat_steps\", package=\"nichenetr\")`\n- [Perform NicheNet analysis starting from a Seurat\n  object](vignettes/seurat_wrapper.md):`vignette(\"seurat_wrapper\", package=\"nichenetr\")`\n\nCase study on HNSCC tumor which demonstrates the flexibility of\nNicheNet. Here, the gene set of interest was determined by the original\nauthors, and the expression data is a matrix rather than a Seurat\nobject.\n\n- [NicheNet‚Äôs ligand activity analysis on a gene set of\n  interest](vignettes/ligand_activity_geneset.md):\n  `vignette(\"ligand_activity_geneset\", package=\"nichenetr\")`\n\nThe following vignettes contain explanation on how to do some follow-up\nanalyses after performing the most basic analysis:\n\n- [Prioritization of ligands based on expression\n  values](vignettes/seurat_steps_prioritization.md):\n  `vignette(\"seurat_steps_prioritization\", package=\"nichenetr\")`\n- [Inferring ligand-to-target signaling\n  paths](vignettes/ligand_target_signaling_path.md):\n  `vignette(\"ligand_target_signaling_path\", package=\"nichenetr\")`\n- [Assess how well top-ranked ligands can predict a gene set of\n  interest](vignettes/target_prediction_evaluation_geneset.md):\n  `vignette(\"target_prediction_evaluation_geneset\", package=\"nichenetr\")`\n- [Single-cell NicheNet‚Äôs ligand activity\n  analysis](vignettes/ligand_activity_single_cell.md):\n  `vignette(\"ligand_activity_single_cell\", package=\"nichenetr\")`\n\nIf you want to make a circos plot visualization of the NicheNet output\nto show active ligand-target links between interacting cells, you can\ncheck following vignettes:\n\n- [Seurat Wrapper + circos\n  visualization](vignettes/seurat_wrapper_circos.md):`vignette(\"seurat_wrapper_circos\", package=\"nichenetr\")`.\n- [HNSCC case study + double circos\n  visualization](vignettes/circos.md):`vignette(\"circos\", package=\"nichenetr\")`.\n\nPeople interested in building their own models or benchmarking their own\nmodels against NicheNet can read one of the following vignettes:\n\n- [Model construction](vignettes/model_construction.md):\n  `vignette(\"model_construction\", package=\"nichenetr\")`\n- [Using LIANA ligand-receptor databases to construct the ligand-target\n  model](vignettes/model_construction_with_liana.md):\n  `vignette(\"model_construction_with_liana\", package=\"nichenetr\")`\n- [Model evaluation: target gene and ligand activity\n  prediction](vignettes/model_evaluation.md):\n  `vignette(\"model_evaluation\", package=\"nichenetr\")`\n- [Parameter optimization via\n  NSGAII-R](vignettes/parameter_optimization.md):\n  `vignette(\"parameter_optimization\", package=\"nichenetr\")`\n\n## FAQ\n\nCheck the FAQ page at [FAQ NicheNet](vignettes/faq.md):\n`vignette(\"faq\", package=\"nichenetr\")`\n\n<details>\n<summary>\n<h2>\nPrevious updates\n</h2>\n</summary>\n\n**20-06-2023:**\n\n- MultiNicheNet - a multi-sample, multi-condition extension of\n  NicheNet - is now available on\n  [biorxiv](https://www.biorxiv.org/content/10.1101/2023.06.13.544751v1)\n  and [Github](https://github.com/saeyslab/multinichenetr).\n- MultiNicheNet uses an [updated prior model\n  (v2)](https://zenodo.org/record/7074291/) consisting of additional\n  ligand-receptor interactions from the [Omnipath\n  database](https://omnipathdb.org/) and from [Verschueren et\n  al.¬†(2020)](https://www.sciencedirect.com/science/article/pii/S0092867420306942?via%3Dihub).\n  We have now also updated the vignettes of NicheNet to use the new\n  model instead.\n- **New functionality:** we have included additional functions to\n  prioritize ligands not only based on the ligand activity, but also on\n  the ligand and receptor expression, cell type specificity, and\n  condition specificity. This is similar to the criteria used in\n  Differential NicheNet and MultiNicheNet. See the [Prioritizing ligands\n  based on expression values](vignettes/seurat_steps_prioritization.md)\n  vignette for more information.\n- Due to this more generalizable prioritization scheme, we will no\n  longer provide support for Differential NicheNet.\n- We included code for making a ligand-receptor-target circos plot in\n  the [Circos plot visualization](vignettes/circos.md) vignette.\n\n<h5>\nDeprecated vignettes\n</h5>\n\nDifferential NicheNet has been deprecated: we will not longer provide\nsupport or code fixes on Differential NicheNet and its vignettes. You\nmay want to consider using the [general prioritization\nscheme](vignettes/seurat_steps_prioritization.md) instead.\n\n- [Differential NicheNet analysis between niches of\n  interest](vignettes/differential_nichenet.md):`vignette(\"differential_nichenet\", package=\"nichenetr\")`\n- [Differential NicheNet analysis between conditions of\n  interest](vignettes/differential_nichenet_pEMT.md):`vignette(\"differential_nichenet_pEMT\", package=\"nichenetr\")`\n\nIn NicheNet v2, the mouse and human ligand-target models are uploaded\nseparately so symbol conversion is not necessary. If you are still using\nthe NicheNet v1 model, you can check the following vignette on how to\nconvert the model (given in human symbols) to mouse symbols:\n\n- [Converting NicheNet‚Äôs model from human to mouse\n  symbols](vignettes/symbol_conversion.md):\n  `vignette(\"symbol_conversion\", package=\"nichenetr\")`\n\n**12-01-2022:** In the Liver Atlas paper from Guilliams et al.: [Spatial\nproteogenomics reveals distinct and evolutionarily conserved hepatic\nmacrophage\nniches](https://www.sciencedirect.com/science/article/pii/S0092867421014811),\nwe used Differential NicheNet, an extension to the default NicheNet\nalgorithm. **Differential NicheNet** can be used to compare cell-cell\ninteractions between different niches and better predict niche-specific\nligand-receptor (L-R) pairs. It was used in that paper to predict\nligand-receptor pairs specific for the Kupffer cell niche in mouse and\nhuman.\n\nThe main difference between the classic NicheNet pipeline and the\nDifferential NicheNet pipeline is that Differential NicheNet also uses\nthe differential expression between the conditions/niches of the\nligand-receptor pairs for prioritization in addition to the ligand\nactivities. The classic NicheNet pipeline on the contrary uses only\nligand acivity for prioritization (and shows differential expression\nonly in visualizations).\n\nSo if you have data of multiple conditions or niches, and you want to\ninclude differential expression of the ligand-receptor pairs in the\nprioritization, we recommend you check out Differential NicheNet (update\nnichenetr to the 1.1.0 version). At the bottom of this page, you can\nfind the links to two vignettes illustrating a Differential NicheNet\nanalysis. We recommend these vignettes if you want to apply Differential\nNicheNet on your own data. If you want to see the code used for the\nanalyses used in the Guilliams et al.¬†paper, see\n<https://github.com/saeyslab/NicheNet_LiverCellAtlas>.\n\n**15-10-2019:** Bonnardel, T‚ÄôJonck et al.¬†used NicheNet to predict\nupstream niche signals driving Kupffer cell differentiation [Stellate\nCells, Hepatocytes, and Endothelial Cells Imprint the Kupffer Cell\nIdentity on Monocytes Colonizing the Liver Macrophage\nNiche](https://www.cell.com/immunity/fulltext/S1074-7613(19)30368-1).\n\n</details>\n\n## References\n\nBrowaeys, R., Saelens, W. & Saeys, Y. NicheNet: modeling intercellular\ncommunication by linking ligands to target genes. Nat Methods (2019)\n<doi:10.1038/s41592-019-0667-5>\n\nBonnardel et al.¬†Stellate Cells, Hepatocytes, and Endothelial Cells\nImprint the Kupffer Cell Identity on Monocytes Colonizing the Liver\nMacrophage Niche. Immunity (2019) <doi:10.1016/j.immuni.2019.08.017>\n\nGuilliams et al.¬†Spatial proteogenomics reveals distinct and\nevolutionarily conserved hepatic macrophage niches. Cell (2022)\n<doi:10.1016/j.cell.2021.12.018>\n",
      "stars_today": 0
    },
    {
      "id": 167440342,
      "name": "monocle3",
      "full_name": "cole-trapnell-lab/monocle3",
      "description": null,
      "html_url": "https://github.com/cole-trapnell-lab/monocle3",
      "stars": 433,
      "forks": 115,
      "language": "R",
      "topics": [
        "single-cell-rna-seq"
      ],
      "created_at": "2019-01-24T21:26:18Z",
      "updated_at": "2026-01-20T19:15:46Z",
      "pushed_at": "2026-01-08T18:32:17Z",
      "open_issues": 260,
      "owner": {
        "login": "cole-trapnell-lab",
        "avatar_url": "https://avatars.githubusercontent.com/u/8060918?v=4"
      },
      "readme": "MONOCLE 3\n=======================\n\nMonocle 3 is an analysis toolkit for single-cell RNA-Seq experiments.  To use this package, you will need the R statistical computing environment (version 3.0 or later) and several packages available through Bioconductor and CRAN.\n\nDetails on how to install and use Monocle 3 are available on our website:\n\nhttp://cole-trapnell-lab.github.io/monocle3/\n\n## Monocle3 with BPCells counts matrix support\n\nThis development branch version of Monocle3 adds the ability to store the counts matrix on-disk using the BPCells package. By default, Monocle3 stores the counts matrix in-memory as a sparse matrix, as in previous versions. In order to store the matrix on-disk, you must set the matrix_control list value `matrix_class=\"BPCells\"` in the affected commands. For example, to load a MatrixMarket file as an on-disk matrix, use the command\n\n```\ncds <- load_mm_data(mat_path=<path_to_mtx_file>,\n                    feature_anno_path=<path_to_feature_anno_file>,\n                    cell_anno_path=<path_to_cell_anno_file>,\n                    matrix_control=list(matrix_class='BPCells'))\n```\n\n### Install Monocle3 with BPCells\n\nYou must install BPCells from Github before you can install this Monocle3 version, and BPCells requires an HDF5 object library for installation. After installing the HDF5 library, you install BPCells using the command\n\n```\nremotes::install_github(\"bnprks/BPCells/r\")\n```\n\nThe [BPCells Github site](https://github.com/bnprks/BPCells)  has additional information.\n\nSome Linux distributions provide the HDF5 library as an option. The\nBPCells site has information about installing the HDF5 library on various operating systems.\n\nI used Homebrew to install an HDF5 library on MacOS. I seemed to need to install the pkg-config package as well, and add a pkg-config configuration file for HDF5. Homebrew installed pkg-config in '/opt/homebrew' so I added the hdf5.pc file in\n\n> /opt/homebrew/lib/pkgconfig/hdf5.pc\n\nwith the contents\n\n```\nprefix=/opt/homebrew/Cellar/hdf5/1.12.2_2\nexec_prefix=${prefix}\nincludedir=${prefix}/include\nlibdir=/opt/homebrew/Cellar/hdf5/1.12.2_2/lib\n  \nName: hdf5\nDescription: HDF5\nURL: xx\nVersion: 1.12.2_2\nCflags: -I${includedir}\nLibs: -L${libdir} -lhdf5\n```\n\nYou may need to update the version strings in your hdf5.pc file.\n\nMonocle3 no longer uses the terra package, so it does not need to be installed.\n\n### Notes\n\n- Monocle3 can use the BPCells package to store the feature-cell counts matrix on-disk rather than in-memory, which enables analysis of considerably larger data sets than before. By default, Monocle3 stores the counts matrix in-memory as a sparse matrix, as it has in the past. To store the counts matrix on-disk, use the parameter `matrix_control=list(matrix_class=\"BPCells\")` when you make the CDS or convert the counts matrix using one of the functions\n  - `load_mm_data()`\n  - `load_mtx_data()`\n  - `load_cellranger_data()`\n  - `load_a549()`\n  - `load_worm_embryo()`\n  - `load_worm_l2()`\n  - `convert_counts_matrix()`\n\n  For example, to convert a dgCMatrix counts matrix to a BPCells on-disk matrix in an existing CDS, use the command `cds <- convert_counts_matrix(cds, matrix_control=list(matrix_class=\"BPCells\"))`.\n- BPCells stores the count matrix information in directories with names similar to `monocle.bpcells.20230830.4c4b1bebe4b4.tmp`. Monocle3 tries to remove those directories when you quit R. Please do not remove them while Monocle3 is running because doing so eliminates the count matrix data. You *can* remove them after quitting R if Monocle3 fails to remove them.\n- The method `new_cell_data_set()` accepts a BPCells on-disk counts matrix.\n- The functions `save_monocle_objects()` and `load_monocle_objects()` store and load BPCells on-disk matrices when the CDS counts matrix is an on-disk BPCells matrix.\n- The Monocle3 `saveRDS()` function warns the user to use `save_monocle_objects()` when saving a CDS with a BPCells on-disk counts matrix. If you insist on using the `saveRDS()` function, the BPCells on-disk matrix directory will not be stored and you will be unable to load it with the `readRDS()` function.\n- The function `combine_cds()` combines CDSes with mixes of dgCMatrix and BPCells on-disk counts matrices into a BPCells on-disk counts matrix. When called with the `matrix_control=list(matrix_class=\"BPCells\")` parameter, `combine_cds()` combines CDSes with all dgCMatrix counts matrices into a BPCells on-disk counts matrix.\n- Note that when the counts matrix is stored as a BPCells on-disk matrix, the `new_cell_data_set()` method stores a second BPCells on-disk copy of the matrix in the CDS assays slot with the name `counts_row_order`. The `counts_row_order` matrix is used by Monocle3 when the counts matrix is accessed intensively by row. The reason is that, by default, BPCells stores the matrix as a one-dimensional vector in column-major order, as does R. As a result, column access is fast and row access is slow. We use BPCell's ability to also store and access matrices in row-major order, which gives fast row access. However, this means that the two copies of the counts matrix must have the same count values. If you replace or change the CDS's counts matrix, you must also update the `counts_row_order` matrix, which you can do using the function `set_cds_row_order_matrix()`.\n  - The CDS assays slot is a named list where the standard, column-major order, matrix is called `counts` and the BPCells row-major order matrix is called `counts_row_order`.\n  - The `counts` matrix getter and setter methods are `counts(cds)` and `counts(cds)<-`.\n  - The Monocle3 setter warns about re-setting the BPCells `counts_row_order` matrix, unless called with the parameter `bpcells_warn=FALSE`.\n  - The `counts_row_order` getter method is called `counts_row_order`.\n  - There is no corresponding `counts_row_order` setter method\n- By default, the BPCells on-disk matrix is stored in a directory that is created where R is started. You can change the directory location using the `matrix_path` value in the `matrix_control` parameter.\n- For more information about the `matrix_control` values, see the help document for the function `set_matrix_control()`.\n- I tested this version using BPCells counts matrices on the examples in the Monocle3 documentation although I did not try all of the plotting functions.\n\n",
      "stars_today": 0
    },
    {
      "id": 248836530,
      "name": "scTenifoldKnk",
      "full_name": "cailab-tamu/scTenifoldKnk",
      "description": " R/MATLAB package to perform virtual knockout experiments on single-cell gene regulatory networks.",
      "html_url": "https://github.com/cailab-tamu/scTenifoldKnk",
      "stars": 138,
      "forks": 13,
      "language": "R",
      "topics": [
        "functional-genomics",
        "gene-function",
        "gene-knockout",
        "gene-regulatory-network",
        "virtual-knockout-experiments"
      ],
      "created_at": "2020-03-20T19:31:03Z",
      "updated_at": "2026-01-24T01:44:09Z",
      "pushed_at": "2026-01-23T22:21:05Z",
      "open_issues": 21,
      "owner": {
        "login": "cailab-tamu",
        "avatar_url": "https://avatars.githubusercontent.com/u/31963060?v=4"
      },
      "readme": "scTenifoldKnk\n=============\n\nA R/MATLAB/Python package to perform virtual knockout experiments on single-cell gene regulatory networks. **scTenifoldKnk** is a machine learning workflow that performs virtual knockout experiments using single-cell RNA sequencing (scRNAseq) data from wild-type (WT) control samples as input. Constructs a single-cell gene regulatory network (scGRN) and knocks out a target gene from the adjacency matrix of the WT scGRN by setting the gene‚Äôs outdegree edges to zero. **scTenifoldKnk** then compares the knocked out scGRN with the WT scGRN to identify differentially regulated genes, called virtual-knockout perturbed genes, which are used to assess the impact of the gene knockout and reveal the gene‚Äôs function in the analyzed cells.\n\nPython version of scTenifoldKnk is available at: https://github.com/qwerty239qwe/scTenifoldpy\n\nMATLAB version is available at: https://github.com/jamesjcai/scGEAToolbox\n\nInstall:\n-------\nYou can install **scTenifoldKnk/R** using the following command:\n\n```{R}\nlibrary(remotes)\ninstall_github('cailab-tamu/scTenifoldKnk')\nlibrary(scTenifoldKnk)\n```\n\nAvailable functions:\n--------------------\n\n|Code| Function |\n|:-|:-|\n|scTenifoldKnk|Perform virtual knockout experiments on single-cell gene regulatory networks|\n\nInput:\n--------\nThe required input for **scTenifoldKnk** is an expression matrix with genes in the rows and cells (barcodes) in the columns. Data is expected to be previously normalized or _not normalized_ if `QC = TRUE`.\n\nRunning time:\n--------\nThe running time of scTenifoldKnk is largely dependent on how long it takes to construct scGRNs from subsampled expression matrices. Time increases proportional to the number of cells and genes in the dataset used as input. Below is a table of running times under different scenarios:\n\n| Number of Cells | Number of Genes | Running Time |\n|-----------------|-----------------|--------------|\n| 300             | 1000            | 3.45 min     |\n| 1000            | 1000            | 4.25 min     |\n| 1000            | 5000            | 171.88 min (2 h 51.6 min) |\n| 2500            | 5000            | 175.29 min (2 h 55.3 min) |\n| 5000            | 5000            | 188.88 min (3 h 8.9 min) |\n| 5000            | 7500            | 189.51 min (3 h 9.5 min)  |\n| 7500            | 5000            | 615.45 min (10 h 15.5 min) |\n| 7500            | 7500            | 616.12 min (10 h 16.1 min)  |\n\n\nOutput:\n--------\nThe output of **scTenifoldKnk** is a list with 3 slots as follows: \n  * **tensorNetworks**: The computed weight-averaged denoised gene regulatory networks after CANDECOMP/PARAFAC (CP) tensor decomposition. It includes two slots with:\n    * **X**: The constructed network for the _X_ sample.\n    * **Y**: The constructed network for the _Y_ sample.\n  * **manifoldAlignment**: The generated low-dimensional features result of the non-linear manifold alignment. It is a data frame with _2 times the number of genes_ in the rows and _d_ (default= 2) dimensions in the columns\n  * **diffRegulation**: The results of the differential regulation analysis. It is a data frame with 6 columns as follows:\n    * **gene**: A character vector with the gene id identified from the manifoldAlignment output.\n    * **distance**: A numeric vector of the Euclidean distance computed between the coordinates of the same gene in both conditions.\n    * **Z**: A numeric vector of the Z-scores computed after Box-Cox power transformation.\n    * **FC**: A numeric vector of the FC computed with respect to the expectation.\n    * **p.value**: A numeric vector of the p-values associated to the fold-changes, probabilities are asigned as P[X > x] using the Chi-square distribution with one degree of freedom.\n    * **p.adj**: A numeric vector of adjusted p-values using Benjamini & Hochberg (1995) FDR correction.\n\n---\nThe function to plot the egocentric KO, the code is available at [https://github.com/dosorio/utilities/blob/master/singleCell/plotKO.R](https://github.com/dosorio/utilities/blob/master/singleCell/plotKO.R), it requires: The object out of Knk (as X), the gene to knockout (gKO).\n\n\n¬©Ô∏è The Texas A & M University System. All rights reserved.\n",
      "stars_today": 0
    }
  ],
  "created_at": "2026-01-24T02:07:46.261820083Z"
}