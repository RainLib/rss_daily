{
  "date": "2026-02-07",
  "name": "trending",
  "repositories": [
    {
      "id": 1048065319,
      "name": "claude-mem",
      "full_name": "thedotmack/claude-mem",
      "description": "A Claude Code plugin that automatically captures everything Claude does during your coding sessions, compresses it with AI (using Claude's agent-sdk), and injects relevant context back into future sessions.",
      "html_url": "https://github.com/thedotmack/claude-mem",
      "stars": 24335,
      "forks": 1603,
      "language": "TypeScript",
      "topics": [
        "ai",
        "ai-agents",
        "ai-memory",
        "anthropic",
        "artificial-intelligence",
        "chromadb",
        "claude",
        "claude-agent-sdk",
        "claude-agents",
        "claude-code",
        "claude-code-plugin",
        "claude-skills",
        "embeddings",
        "long-term-memory",
        "mem0",
        "memory-engine",
        "openmemory",
        "rag",
        "sqlite",
        "supermemory"
      ],
      "created_at": "2025-08-31T20:50:03Z",
      "updated_at": "2026-02-07T02:33:58Z",
      "pushed_at": "2026-02-06T10:53:34Z",
      "open_issues": 167,
      "owner": {
        "login": "thedotmack",
        "avatar_url": "https://avatars.githubusercontent.com/u/683968?v=4"
      },
      "readme": "<p align=\"center\">\n  Official $CMEM Links: \n  <a href=\"https://bags.fm/2TsmuYUrsctE57VLckZBYEEzdokUF8j8e1GavekWBAGS\">Bags.fm</a> â€¢\n  <a href=\"https://jup.ag/tokens/2TsmuYUrsctE57VLckZBYEEzdokUF8j8e1GavekWBAGS\">Jupiter</a> â€¢\n  <a href=\"https://photon-sol.tinyastro.io/en/lp/6MzFAkWnac6GSK1EdFX93dZeukGfzrFq4UHWarhGSQyd\">Photon</a> â€¢\n  <a href=\"https://dexscreener.com/solana/6mzfakwnac6gsk1edfx93dzeukgfzrfq4uhwarhgsqyd\">DEXScreener</a>\n</p>\n\n<p align=\"center\">Official CA: 2TsmuYUrsctE57VLckZBYEEzdokUF8j8e1GavekWBAGS (on Solana)</p>\n\n<h1 align=\"center\">\n  <br>\n  <a href=\"https://github.com/thedotmack/claude-mem\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/claude-mem-logo-for-dark-mode.webp\">\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/claude-mem-logo-for-light-mode.webp\">\n      <img src=\"https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/claude-mem-logo-for-light-mode.webp\" alt=\"Claude-Mem\" width=\"400\">\n    </picture>\n  </a>\n  <br>\n</h1>\n\n<p align=\"center\">\n  <a href=\"docs/i18n/README.zh.md\">ğŸ‡¨ğŸ‡³ ä¸­æ–‡</a> â€¢\n  <a href=\"docs/i18n/README.zh-tw.md\">ğŸ‡¹ğŸ‡¼ ç¹é«”ä¸­æ–‡</a> â€¢\n  <a href=\"docs/i18n/README.ja.md\">ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª</a> â€¢\n  <a href=\"docs/i18n/README.pt-br.md\">ğŸ‡§ğŸ‡· PortuguÃªs</a> â€¢\n  <a href=\"docs/i18n/README.ko.md\">ğŸ‡°ğŸ‡· í•œêµ­ì–´</a> â€¢\n  <a href=\"docs/i18n/README.es.md\">ğŸ‡ªğŸ‡¸ EspaÃ±ol</a> â€¢\n  <a href=\"docs/i18n/README.de.md\">ğŸ‡©ğŸ‡ª Deutsch</a> â€¢\n  <a href=\"docs/i18n/README.fr.md\">ğŸ‡«ğŸ‡· FranÃ§ais</a>\n  <a href=\"docs/i18n/README.he.md\">ğŸ‡®ğŸ‡± ×¢×‘×¨×™×ª</a> â€¢\n  <a href=\"docs/i18n/README.ar.md\">ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a> â€¢\n  <a href=\"docs/i18n/README.ru.md\">ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹</a> â€¢\n  <a href=\"docs/i18n/README.pl.md\">ğŸ‡µğŸ‡± Polski</a> â€¢\n  <a href=\"docs/i18n/README.cs.md\">ğŸ‡¨ğŸ‡¿ ÄŒeÅ¡tina</a> â€¢\n  <a href=\"docs/i18n/README.nl.md\">ğŸ‡³ğŸ‡± Nederlands</a> â€¢\n  <a href=\"docs/i18n/README.tr.md\">ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e</a> â€¢\n  <a href=\"docs/i18n/README.uk.md\">ğŸ‡ºğŸ‡¦ Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°</a> â€¢\n  <a href=\"docs/i18n/README.vi.md\">ğŸ‡»ğŸ‡³ Tiáº¿ng Viá»‡t</a> â€¢\n  <a href=\"docs/i18n/README.id.md\">ğŸ‡®ğŸ‡© Indonesia</a> â€¢\n  <a href=\"docs/i18n/README.th.md\">ğŸ‡¹ğŸ‡­ à¹„à¸—à¸¢</a> â€¢\n  <a href=\"docs/i18n/README.hi.md\">ğŸ‡®ğŸ‡³ à¤¹à¤¿à¤¨à¥à¤¦à¥€</a> â€¢\n  <a href=\"docs/i18n/README.bn.md\">ğŸ‡§ğŸ‡© à¦¬à¦¾à¦‚à¦²à¦¾</a> â€¢\n  <a href=\"docs/i18n/README.ur.md\">ğŸ‡µğŸ‡° Ø§Ø±Ø¯Ùˆ</a> â€¢\n  <a href=\"docs/i18n/README.ro.md\">ğŸ‡·ğŸ‡´ RomÃ¢nÄƒ</a> â€¢\n  <a href=\"docs/i18n/README.sv.md\">ğŸ‡¸ğŸ‡ª Svenska</a> â€¢\n  <a href=\"docs/i18n/README.it.md\">ğŸ‡®ğŸ‡¹ Italiano</a> â€¢\n  <a href=\"docs/i18n/README.el.md\">ğŸ‡¬ğŸ‡· Î•Î»Î»Î·Î½Î¹ÎºÎ¬</a> â€¢\n  <a href=\"docs/i18n/README.hu.md\">ğŸ‡­ğŸ‡º Magyar</a> â€¢\n  <a href=\"docs/i18n/README.fi.md\">ğŸ‡«ğŸ‡® Suomi</a> â€¢\n  <a href=\"docs/i18n/README.da.md\">ğŸ‡©ğŸ‡° Dansk</a> â€¢\n  <a href=\"docs/i18n/README.no.md\">ğŸ‡³ğŸ‡´ Norsk</a>\n</p>\n\n<h4 align=\"center\">Persistent memory compression system built for <a href=\"https://claude.com/claude-code\" target=\"_blank\">Claude Code</a>.</h4>\n\n<p align=\"center\">\n  <a href=\"LICENSE\">\n    <img src=\"https://img.shields.io/badge/License-AGPL%203.0-blue.svg\" alt=\"License\">\n  </a>\n  <a href=\"package.json\">\n    <img src=\"https://img.shields.io/badge/version-6.5.0-green.svg\" alt=\"Version\">\n  </a>\n  <a href=\"package.json\">\n    <img src=\"https://img.shields.io/badge/node-%3E%3D18.0.0-brightgreen.svg\" alt=\"Node\">\n  </a>\n  <a href=\"https://github.com/thedotmack/awesome-claude-code\">\n    <img src=\"https://awesome.re/mentioned-badge.svg\" alt=\"Mentioned in Awesome Claude Code\">\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://trendshift.io/repositories/15496\" target=\"_blank\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/trendshift-badge-dark.svg\">\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/trendshift-badge.svg\">\n      <img src=\"https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/trendshift-badge.svg\" alt=\"thedotmack/claude-mem | Trendshift\" width=\"250\" height=\"55\"/>\n    </picture>\n  </a>\n</p>\n\n<br>\n\n<p align=\"center\">\n  <a href=\"https://github.com/thedotmack/claude-mem\">\n    <picture>\n      <img src=\"https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/cm-preview.gif\" alt=\"Claude-Mem Preview\" width=\"800\">\n    </picture>\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"#quick-start\">Quick Start</a> â€¢\n  <a href=\"#how-it-works\">How It Works</a> â€¢\n  <a href=\"#mcp-search-tools\">Search Tools</a> â€¢\n  <a href=\"#documentation\">Documentation</a> â€¢\n  <a href=\"#configuration\">Configuration</a> â€¢\n  <a href=\"#troubleshooting\">Troubleshooting</a> â€¢\n  <a href=\"#license\">License</a>\n</p>\n\n<p align=\"center\">\n  Claude-Mem seamlessly preserves context across sessions by automatically capturing tool usage observations, generating semantic summaries, and making them available to future sessions. This enables Claude to maintain continuity of knowledge about projects even after sessions end or reconnect.\n</p>\n\n---\n\n## Quick Start\n\nStart a new Claude Code session in the terminal and enter the following commands:\n\n```\n/plugin marketplace add thedotmack/claude-mem\n\n/plugin install claude-mem\n```\n\nRestart Claude Code. Context from previous sessions will automatically appear in new sessions.\n\n**Key Features:**\n\n- ğŸ§  **Persistent Memory** - Context survives across sessions\n- ğŸ“Š **Progressive Disclosure** - Layered memory retrieval with token cost visibility\n- ğŸ” **Skill-Based Search** - Query your project history with mem-search skill\n- ğŸ–¥ï¸ **Web Viewer UI** - Real-time memory stream at http://localhost:37777\n- ğŸ’» **Claude Desktop Skill** - Search memory from Claude Desktop conversations\n- ğŸ”’ **Privacy Control** - Use `<private>` tags to exclude sensitive content from storage\n- âš™ï¸ **Context Configuration** - Fine-grained control over what context gets injected\n- ğŸ¤– **Automatic Operation** - No manual intervention required\n- ğŸ”— **Citations** - Reference past observations with IDs (access via http://localhost:37777/api/observation/{id} or view all in the web viewer at http://localhost:37777)\n- ğŸ§ª **Beta Channel** - Try experimental features like Endless Mode via version switching\n\n---\n\n## Documentation\n\nğŸ“š **[View Full Documentation](https://docs.claude-mem.ai/)** - Browse on official website\n\n### Getting Started\n\n- **[Installation Guide](https://docs.claude-mem.ai/installation)** - Quick start & advanced installation\n- **[Usage Guide](https://docs.claude-mem.ai/usage/getting-started)** - How Claude-Mem works automatically\n- **[Search Tools](https://docs.claude-mem.ai/usage/search-tools)** - Query your project history with natural language\n- **[Beta Features](https://docs.claude-mem.ai/beta-features)** - Try experimental features like Endless Mode\n\n### Best Practices\n\n- **[Context Engineering](https://docs.claude-mem.ai/context-engineering)** - AI agent context optimization principles\n- **[Progressive Disclosure](https://docs.claude-mem.ai/progressive-disclosure)** - Philosophy behind Claude-Mem's context priming strategy\n\n### Architecture\n\n- **[Overview](https://docs.claude-mem.ai/architecture/overview)** - System components & data flow\n- **[Architecture Evolution](https://docs.claude-mem.ai/architecture-evolution)** - The journey from v3 to v5\n- **[Hooks Architecture](https://docs.claude-mem.ai/hooks-architecture)** - How Claude-Mem uses lifecycle hooks\n- **[Hooks Reference](https://docs.claude-mem.ai/architecture/hooks)** - 7 hook scripts explained\n- **[Worker Service](https://docs.claude-mem.ai/architecture/worker-service)** - HTTP API & Bun management\n- **[Database](https://docs.claude-mem.ai/architecture/database)** - SQLite schema & FTS5 search\n- **[Search Architecture](https://docs.claude-mem.ai/architecture/search-architecture)** - Hybrid search with Chroma vector database\n\n### Configuration & Development\n\n- **[Configuration](https://docs.claude-mem.ai/configuration)** - Environment variables & settings\n- **[Development](https://docs.claude-mem.ai/development)** - Building, testing, contributing\n- **[Troubleshooting](https://docs.claude-mem.ai/troubleshooting)** - Common issues & solutions\n\n---\n\n## How It Works\n\n**Core Components:**\n\n1. **5 Lifecycle Hooks** - SessionStart, UserPromptSubmit, PostToolUse, Stop, SessionEnd (6 hook scripts)\n2. **Smart Install** - Cached dependency checker (pre-hook script, not a lifecycle hook)\n3. **Worker Service** - HTTP API on port 37777 with web viewer UI and 10 search endpoints, managed by Bun\n4. **SQLite Database** - Stores sessions, observations, summaries\n5. **mem-search Skill** - Natural language queries with progressive disclosure\n6. **Chroma Vector Database** - Hybrid semantic + keyword search for intelligent context retrieval\n\nSee [Architecture Overview](https://docs.claude-mem.ai/architecture/overview) for details.\n\n---\n\n## MCP Search Tools\n\nClaude-Mem provides intelligent memory search through **5 MCP tools** following a token-efficient **3-layer workflow pattern**:\n\n**The 3-Layer Workflow:**\n\n1. **`search`** - Get compact index with IDs (~50-100 tokens/result)\n2. **`timeline`** - Get chronological context around interesting results\n3. **`get_observations`** - Fetch full details ONLY for filtered IDs (~500-1,000 tokens/result)\n\n**How It Works:**\n- Claude uses MCP tools to search your memory\n- Start with `search` to get an index of results\n- Use `timeline` to see what was happening around specific observations\n- Use `get_observations` to fetch full details for relevant IDs\n- Use `save_memory` to manually store important information\n- **~10x token savings** by filtering before fetching details\n\n**Available MCP Tools:**\n\n1. **`search`** - Search memory index with full-text queries, filters by type/date/project\n2. **`timeline`** - Get chronological context around a specific observation or query\n3. **`get_observations`** - Fetch full observation details by IDs (always batch multiple IDs)\n4. **`save_memory`** - Manually save a memory/observation for semantic search\n5. **`__IMPORTANT`** - Workflow documentation (always visible to Claude)\n\n**Example Usage:**\n\n```typescript\n// Step 1: Search for index\nsearch(query=\"authentication bug\", type=\"bugfix\", limit=10)\n\n// Step 2: Review index, identify relevant IDs (e.g., #123, #456)\n\n// Step 3: Fetch full details\nget_observations(ids=[123, 456])\n\n// Save important information manually\nsave_memory(text=\"API requires auth header X-API-Key\", title=\"API Auth\")\n```\n\nSee [Search Tools Guide](https://docs.claude-mem.ai/usage/search-tools) for detailed examples.\n\n---\n\n## Beta Features\n\nClaude-Mem offers a **beta channel** with experimental features like **Endless Mode** (biomimetic memory architecture for extended sessions). Switch between stable and beta versions from the web viewer UI at http://localhost:37777 â†’ Settings.\n\nSee **[Beta Features Documentation](https://docs.claude-mem.ai/beta-features)** for details on Endless Mode and how to try it.\n\n---\n\n## System Requirements\n\n- **Node.js**: 18.0.0 or higher\n- **Claude Code**: Latest version with plugin support\n- **Bun**: JavaScript runtime and process manager (auto-installed if missing)\n- **uv**: Python package manager for vector search (auto-installed if missing)\n- **SQLite 3**: For persistent storage (bundled)\n\n---\n### Windows Setup Notes\n\nIf you see an error like:\n\n```powershell\nnpm : The term 'npm' is not recognized as the name of a cmdlet\n```\n\nMake sure Node.js and npm are installed and added to your PATH. Download the latest Node.js installer from https://nodejs.org and restart your terminal after installation.\n\n---\n\n## Configuration\n\nSettings are managed in `~/.claude-mem/settings.json` (auto-created with defaults on first run). Configure AI model, worker port, data directory, log level, and context injection settings.\n\nSee the **[Configuration Guide](https://docs.claude-mem.ai/configuration)** for all available settings and examples.\n\n---\n\n## Development\n\nSee the **[Development Guide](https://docs.claude-mem.ai/development)** for build instructions, testing, and contribution workflow.\n\n---\n\n## Troubleshooting\n\nIf experiencing issues, describe the problem to Claude and the troubleshoot skill will automatically diagnose and provide fixes.\n\nSee the **[Troubleshooting Guide](https://docs.claude-mem.ai/troubleshooting)** for common issues and solutions.\n\n---\n\n## Bug Reports\n\nCreate comprehensive bug reports with the automated generator:\n\n```bash\ncd ~/.claude/plugins/marketplaces/thedotmack\nnpm run bug-report\n```\n\n## Contributing\n\nContributions are welcome! Please:\n\n1. Fork the repository\n2. Create a feature branch\n3. Make your changes with tests\n4. Update documentation\n5. Submit a Pull Request\n\nSee [Development Guide](https://docs.claude-mem.ai/development) for contribution workflow.\n\n---\n\n## License\n\nThis project is licensed under the **GNU Affero General Public License v3.0** (AGPL-3.0).\n\nCopyright (C) 2025 Alex Newman (@thedotmack). All rights reserved.\n\nSee the [LICENSE](LICENSE) file for full details.\n\n**What This Means:**\n\n- You can use, modify, and distribute this software freely\n- If you modify and deploy on a network server, you must make your source code available\n- Derivative works must also be licensed under AGPL-3.0\n- There is NO WARRANTY for this software\n\n**Note on Ragtime**: The `ragtime/` directory is licensed separately under the **PolyForm Noncommercial License 1.0.0**. See [ragtime/LICENSE](ragtime/LICENSE) for details.\n\n---\n\n## Support\n\n- **Documentation**: [docs/](docs/)\n- **Issues**: [GitHub Issues](https://github.com/thedotmack/claude-mem/issues)\n- **Repository**: [github.com/thedotmack/claude-mem](https://github.com/thedotmack/claude-mem)\n- **Official X Account**: [@Claude_Memory](https://x.com/Claude_Memory)\n- **Official Discord**: [Join Discord](https://discord.com/invite/J4wttp9vDu)\n- **Author**: Alex Newman ([@thedotmack](https://github.com/thedotmack))\n\n---\n\n**Built with Claude Agent SDK** | **Powered by Claude Code** | **Made with TypeScript**\n",
      "stars_today": 799
    },
    {
      "id": 918932603,
      "name": "UI-TARS-desktop",
      "full_name": "bytedance/UI-TARS-desktop",
      "description": "The Open-Source Multimodal AI Agent Stack: Connecting Cutting-Edge AI Models and Agent Infra",
      "html_url": "https://github.com/bytedance/UI-TARS-desktop",
      "stars": 27131,
      "forks": 2643,
      "language": "TypeScript",
      "topics": [
        "agent",
        "agent-tars",
        "browser-use",
        "computer-use",
        "cowork",
        "gui-agent",
        "gui-operator",
        "mcp",
        "mcp-server",
        "multimodal",
        "tars",
        "ui-tars",
        "vision",
        "vlm"
      ],
      "created_at": "2025-01-19T09:04:43Z",
      "updated_at": "2026-02-07T02:33:27Z",
      "pushed_at": "2026-01-14T13:12:22Z",
      "open_issues": 342,
      "owner": {
        "login": "bytedance",
        "avatar_url": "https://avatars.githubusercontent.com/u/4158466?v=4"
      },
      "readme": "<picture>\n  <img alt=\"Agent TARS Banner\" src=\"./images/tars.png\">\n</picture>\n\n<br/>\n\n## Introduction\n\nEnglish | [ç®€ä½“ä¸­æ–‡](./README.zh-CN.md)\n\n[![](https://trendshift.io/api/badge/repositories/13584)](https://trendshift.io/repositories/13584)\n\n<b>TARS<sup>\\*</sup></b> is a Multimodal AI Agent stack, currently shipping two projects: [Agent TARS](#agent-tars) and [UI-TARS-desktop](#ui-tars-desktop):\n\n<table>\n  <thead>\n    <tr>\n      <th width=\"50%\" align=\"center\"><a href=\"#agent-tars\">Agent TARS</a></th>\n      <th width=\"50%\" align=\"center\"><a href=\"#ui-tars-desktop\">UI-TARS-desktop</a></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <video src=\"https://github.com/user-attachments/assets/c9489936-afdc-4d12-adda-d4b90d2a869d\" width=\"50%\"></video>\n      </td>\n      <td align=\"center\">\n        <video src=\"https://github.com/user-attachments/assets/e0914ce9-ad33-494b-bdec-0c25c1b01a27\" width=\"50%\"></video>\n      </td>\n    </tr>\n    <tr>\n      <td align=\"left\">\n        <b>Agent TARS</b> is a general multimodal AI Agent stack, it brings the power of GUI Agent and Vision into your terminal, computer, browser and product.\n        <br>\n        <br>\n        It primarily ships with a <a href=\"https://agent-tars.com/guide/basic/cli.html\" target=\"_blank\">CLI</a> and <a href=\"https://agent-tars.com/guide/basic/web-ui.html\" target=\"_blank\">Web UI</a> for usage.\n        It aims to provide a workflow that is closer to human-like task completion through cutting-edge multimodal LLMs and seamless integration with various real-world <a href=\"https://agent-tars.com/guide/basic/mcp.html\" target=\"_blank\">MCP</a> tools.\n      </td>\n      <td align=\"left\">\n        <b>UI-TARS Desktop</b> is a desktop application that provides a native GUI Agent based on the <a href=\"https://github.com/bytedance/UI-TARS\" target=\"_blank\">UI-TARS</a> model.\n        <br>\n        <br>\n        It primarily ships a\n        <a href=\"https://github.com/bytedance/UI-TARS-desktop/blob/main/docs/quick-start.md#get-model-and-run-local-operator\" target=\"_blank\">local</a> and \n        <a href=\"https://github.com/bytedance/UI-TARS-desktop/blob/main/docs/quick-start.md#run-remote-operator\" target=\"_blank\">remote</a> computer as well as browser operators.\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n## Table of Contents\n\n<!-- START doctoc generated TOC please keep comment here to allow auto update -->\n<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->\n\n- [News](#news)\n- [Agent TARS](#agent-tars)\n  - [Showcase](#showcase)\n  - [Core Features](#core-features)\n  - [Quick Start](#quick-start)\n  - [Documentation](#documentation)\n- [UI-TARS Desktop](#ui-tars-desktop)\n  - [Showcase](#showcase-1)\n  - [Features](#features)\n  - [Quick Start](#quick-start-1)\n- [Contributing](#contributing)\n- [License](#license)\n- [Citation](#citation)\n\n<!-- END doctoc generated TOC please keep comment here to allow auto update -->\n\n## News\n\n- **\\[2025-11-05\\]** ğŸ‰ We're excited to announce the release of [Agent TARS CLI v0.3.0](https://github.com/bytedance/UI-TARS-desktop/releases/tag/v0.3.0)! This version brings streaming support for multiple tools (shell commands, multi-file structured display), runtime settings with timing statistics for tool calls and deep thinking, Event Stream Viewer for data flow tracking and debugging. Additionally, it features exclusive support for [AIO agent Sandbox](https://github.com/agent-infra/sandbox) as isolated all-in-one tools execution environment.\n- **\\[2025-06-25\\]** We released a Agent TARS Beta and Agent TARS CLI - [Introducing Agent TARS Beta](https://agent-tars.com/blog/2025-06-25-introducing-agent-tars-beta.html), a multimodal AI agent that aims to explore a work form that is closer to human-like task completion through rich multimodal capabilities (such as GUI Agent, Vision) and seamless integration with various real-world tools.\n- **\\[2025-06-12\\]** - ğŸ We are thrilled to announce the release of UI-TARS Desktop v0.2.0! This update introduces two powerful new features: **Remote Computer Operator** and **Remote Browser Operator**â€”both completely free. No configuration required: simply click to remotely control any computer or browser, and experience a new level of convenience and intelligence.\n- **\\[2025-04-17\\]** - ğŸ‰ We're thrilled to announce the release of new UI-TARS Desktop application v0.1.0, featuring a redesigned Agent UI. The application enhances the computer using experience, introduces new browser operation features, and supports [the advanced UI-TARS-1.5 model](https://seed-tars.com/1.5) for improved performance and precise control.\n- **\\[2025-02-20\\]** - ğŸ“¦ Introduced [UI TARS SDK](./docs/sdk.md), is a powerful cross-platform toolkit for building GUI automation agents.\n- **\\[2025-01-23\\]** - ğŸš€ We updated the **[Cloud Deployment](./docs/deployment.md#cloud-deployment)** section in the ä¸­æ–‡ç‰ˆ: [GUIæ¨¡å‹éƒ¨ç½²æ•™ç¨‹](https://bytedance.sg.larkoffice.com/docx/TCcudYwyIox5vyxiSDLlgIsTgWf#U94rdCxzBoJMLex38NPlHL21gNb) with new information related to the ModelScope platform. You can now use the ModelScope platform for deployment.\n\n<br>\n\n## Agent TARS\n\n<p>\n    <a href=\"https://npmjs.com/package/@agent-tars/cli?activeTab=readme\"><img src=\"https://img.shields.io/npm/v/@agent-tars/cli?style=for-the-badge&colorA=1a1a2e&colorB=3B82F6&logo=npm&logoColor=white\" alt=\"npm version\" /></a>\n    <a href=\"https://npmcharts.com/compare/@agent-tars/cli?minimal=true\"><img src=\"https://img.shields.io/npm/dm/@agent-tars/cli.svg?style=for-the-badge&colorA=1a1a2e&colorB=0EA5E9&logo=npm&logoColor=white\" alt=\"downloads\" /></a>\n    <a href=\"https://nodejs.org/en/about/previous-releases\"><img src=\"https://img.shields.io/node/v/@agent-tars/cli.svg?style=for-the-badge&colorA=1a1a2e&colorB=06B6D4&logo=node.js&logoColor=white\" alt=\"node version\"></a>\n    <a href=\"https://discord.gg/HnKcSBgTVx\"><img src=\"https://img.shields.io/badge/Discord-Join%20Community-5865F2?style=for-the-badge&logo=discord&logoColor=white\" alt=\"Discord Community\" /></a>\n    <a href=\"https://twitter.com/agent_tars\"><img src=\"https://img.shields.io/badge/Twitter-Follow%20%40agent__tars-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white\" alt=\"Official Twitter\" /></a>\n    <a href=\"https://applink.larkoffice.com/client/chat/chatter/add_by_link?link_token=deen76f4-ea3c-4964-93a3-78f126f39651\"><img src=\"https://img.shields.io/badge/é£ä¹¦ç¾¤-åŠ å…¥äº¤æµç¾¤-00D4AA?style=for-the-badge&logo=lark&logoColor=white\" alt=\"é£ä¹¦äº¤æµç¾¤\" /></a>\n    <a href=\"https://deepwiki.com/bytedance/UI-TARS-desktop\"><img src=\"https://img.shields.io/badge/DeepWiki-Ask%20AI-8B5CF6?style=for-the-badge&logo=gitbook&logoColor=white\" alt=\"Ask DeepWiki\" /></a>\n</p>\n\n<b>Agent TARS</b> is a general multimodal AI Agent stack, it brings the power of GUI Agent and Vision into your terminal, computer, browser and product. <br> <br>\nIt primarily ships with a <a href=\"https://agent-tars.com/guide/basic/cli.html\" target=\"_blank\">CLI</a> and <a href=\"https://agent-tars.com/guide/basic/web-ui.html\" target=\"_blank\">Web UI</a> for usage.\nIt aims to provide a workflow that is closer to human-like task completion through cutting-edge multimodal LLMs and seamless integration with various real-world <a href=\"https://agent-tars.com/guide/basic/mcp.html\" target=\"_blank\">MCP</a> tools.\n\n### Showcase\n\n```\nPlease help me book the earliest flight from San Jose to New York on September 1st and the last return flight on September 6th on Priceline\n```\n\nhttps://github.com/user-attachments/assets/772b0eef-aef7-4ab9-8cb0-9611820539d8\n\n<br>\n\n<table>\n  <thead>\n    <tr>\n      <th width=\"50%\" align=\"center\">Booking Hotel</th>\n      <th width=\"50%\" align=\"center\">Generate Chart with extra MCP Servers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <video src=\"https://github.com/user-attachments/assets/c9489936-afdc-4d12-adda-d4b90d2a869d\" width=\"50%\"></video>\n      </td>\n      <td align=\"center\">\n        <video src=\"https://github.com/user-attachments/assets/a9fd72d0-01bb-4233-aa27-ca95194bbce9\" width=\"50%\"></video>\n      </td>\n    </tr>\n    <tr>\n      <td align=\"left\">\n        <b>Instruction:</b> <i>I am in Los Angeles from September 1st to September 6th, with a budget of $5,000. Please help me book a Ritz-Carlton hotel closest to the airport on booking.com and compile a transportation guide for me</i>\n      </td>\n      <td align=\"left\">\n        <b>Instruction:</b> <i>Draw me a chart of Hangzhou's weather for one month</i>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\nFor more use cases, please check out [#842](https://github.com/bytedance/UI-TARS-desktop/issues/842).\n\n### Core Features\n\n- ğŸ–±ï¸ **One-Click Out-of-the-box CLI** - Supports both **headful** [Web UI](https://agent-tars.com/guide/basic/web-ui.html) and **headless** [server](https://agent-tars.com/guide/advanced/server.html)) [execution](https://agent-tars.com/guide/basic/cli.html).\n- ğŸŒ **Hybrid Browser Agent** - Control browsers using [GUI Agent](https://agent-tars.com/guide/basic/browser.html#visual-grounding), [DOM](https://agent-tars.com/guide/basic/browser.html#dom), or a hybrid strategy.\n- ğŸ”„ **Event Stream** - Protocol-driven Event Stream drives [Context Engineering](https://agent-tars.com/beta#context-engineering) and [Agent UI](https://agent-tars.com/blog/2025-06-25-introducing-agent-tars-beta.html#easy-to-build-applications).\n- ğŸ§° **MCP Integration** - The kernel is built on MCP and also supports mounting [MCP Servers](https://agent-tars.com/guide/basic/mcp.html) to connect to real-world tools.\n\n### Quick Start\n\n<img alt=\"Agent TARS CLI\" src=\"https://agent-tars.com/agent-tars-cli.png\">\n\n```bash\n# Launch with `npx`.\nnpx @agent-tars/cli@latest\n\n# Install globally, required Node.js >= 22\nnpm install @agent-tars/cli@latest -g\n\n# Run with your preferred model provider\nagent-tars --provider volcengine --model doubao-1-5-thinking-vision-pro-250428 --apiKey your-api-key\nagent-tars --provider anthropic --model claude-3-7-sonnet-latest --apiKey your-api-key\n```\n\nVisit the comprehensive [Quick Start](https://agent-tars.com/guide/get-started/quick-start.html) guide for detailed setup instructions.\n\n### Documentation\n\n> ğŸŒŸ **Explore Agent TARS Universe** ğŸŒŸ\n\n<table>\n  <thead>\n    <tr>\n      <th width=\"20%\" align=\"center\">Category</th>\n      <th width=\"30%\" align=\"center\">Resource Link</th>\n      <th width=\"50%\" align=\"left\">Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td align=\"center\">ğŸ  <strong>Central Hub</strong></td>\n      <td align=\"center\">\n        <a href=\"https://agent-tars.com\">\n          <img src=\"https://img.shields.io/badge/Visit-Website-4F46E5?style=for-the-badge&logo=globe&logoColor=white\" alt=\"Website\" />\n        </a>\n      </td>\n      <td align=\"left\">Your gateway to Agent TARS ecosystem</td>\n    </tr>\n      <tr>\n      <td align=\"center\">ğŸ“š <strong>Quick Start</strong></td>\n      <td align=\"center\">\n        <a href=\"https://agent-tars.com/guide/get-started/quick-start.html\">\n          <img src=\"https://img.shields.io/badge/Get-Started-06B6D4?style=for-the-badge&logo=rocket&logoColor=white\" alt=\"Quick Start\" />\n        </a>\n      </td>\n      <td align=\"left\">Zero to hero in 5 minutes</td>\n    </tr>\n    <tr>\n      <td align=\"center\">ğŸš€ <strong>What's New</strong></td>\n      <td align=\"center\">\n        <a href=\"https://agent-tars.com/beta\">\n          <img src=\"https://img.shields.io/badge/Read-Blog-F59E0B?style=for-the-badge&logo=rss&logoColor=white\" alt=\"Blog\" />\n        </a>\n      </td>\n      <td align=\"left\">Discover cutting-edge features & vision</td>\n    </tr>\n    <tr>\n      <td align=\"center\">ğŸ› ï¸ <strong>Developer Zone</strong></td>\n      <td align=\"center\">\n        <a href=\"https://agent-tars.com/guide/get-started/introduction.html\">\n          <img src=\"https://img.shields.io/badge/View-Docs-10B981?style=for-the-badge&logo=gitbook&logoColor=white\" alt=\"Docs\" />\n        </a>\n      </td>\n      <td align=\"left\">Master every command & features</td>\n    </tr>\n    <tr>\n      <td align=\"center\">ğŸ¯ <strong>Showcase</strong></td>\n      <td align=\"center\">\n        <a href=\"https://github.com/bytedance/UI-TARS-desktop/issues/842\">\n          <img src=\"https://img.shields.io/badge/View-Examples-8B5CF6?style=for-the-badge&logo=github&logoColor=white\" alt=\"Examples\" />\n        </a>\n      </td>\n      <td align=\"left\">View use cases built by the official and community</td>\n    </tr>\n    <tr>\n      <td align=\"center\">ğŸ”§ <strong>Reference</strong></td>\n      <td align=\"center\">\n        <a href=\"https://agent-tars.com/api/\">\n          <img src=\"https://img.shields.io/badge/API-Reference-EF4444?style=for-the-badge&logo=book&logoColor=white\" alt=\"API\" />\n        </a>\n      </td>\n      <td align=\"left\">Complete technical reference</td>\n    </tr>\n  </tbody>\n</table>\n\n<br/>\n<br/>\n<br/>\n\n## UI-TARS Desktop\n\n<p align=\"center\">\n  <img alt=\"UI-TARS\" width=\"260\" src=\"./apps/ui-tars/resources/icon.png\">\n</p>\n\nUI-TARS Desktop is a native GUI agent for your local computer, driven by [UI-TARS](https://github.com/bytedance/UI-TARS) and Seed-1.5-VL/1.6 series models.\n\n<div align=\"center\">\n<p>\n        &nbsp&nbsp ğŸ“‘ <a href=\"https://arxiv.org/abs/2501.12326\">Paper</a> &nbsp&nbsp\n        | ğŸ¤— <a href=\"https://huggingface.co/ByteDance-Seed/UI-TARS-1.5-7B\">Hugging Face Models</a>&nbsp&nbsp\n        | &nbsp&nbspğŸ«¨ <a href=\"https://discord.gg/pTXwYVjfcs\">Discord</a>&nbsp&nbsp\n        | &nbsp&nbspğŸ¤– <a href=\"https://www.modelscope.cn/collections/UI-TARS-bccb56fa1ef640\">ModelScope</a>&nbsp&nbsp\n<br>\nğŸ–¥ï¸ Desktop Application &nbsp&nbsp\n| &nbsp&nbsp ğŸ‘“ <a href=\"https://github.com/web-infra-dev/midscene\">Midscene (use in browser)</a> &nbsp&nbsp\n</p>\n\n</div>\n\n### Showcase\n\n<!-- // FIXME: Choose only two demo, one local computer and one remote computer showcase. -->\n\n|                                                          Instruction                                                           |                                                Local Operator                                                |                                               Remote Operator                                                |\n| :----------------------------------------------------------------------------------------------------------------------------: | :----------------------------------------------------------------------------------------------------------: | :----------------------------------------------------------------------------------------------------------: |\n| Please help me open the autosave feature of VS Code and delay AutoSave operations for 500 milliseconds in the VS Code setting. | <video src=\"https://github.com/user-attachments/assets/e0914ce9-ad33-494b-bdec-0c25c1b01a27\" height=\"300\" /> | <video src=\"https://github.com/user-attachments/assets/01e49b69-7070-46c8-b3e3-2aaaaec71800\" height=\"300\" /> |\n|                    Could you help me check the latest open issue of the UI-TARS-Desktop project on GitHub?                     | <video src=\"https://github.com/user-attachments/assets/3d159f54-d24a-4268-96c0-e149607e9199\" height=\"300\" /> | <video src=\"https://github.com/user-attachments/assets/072fb72d-7394-4bfa-95f5-4736e29f7e58\" height=\"300\" /> |\n\n### Features\n\n- ğŸ¤– Natural language control powered by Vision-Language Model\n- ğŸ–¥ï¸ Screenshot and visual recognition support\n- ğŸ¯ Precise mouse and keyboard control\n- ğŸ’» Cross-platform support (Windows/MacOS/Browser)\n- ğŸ”„ Real-time feedback and status display\n- ğŸ” Private and secure - fully local processing\n\n### Quick Start\n\nSee [Quick Start](./docs/quick-start.md)\n\n## Contributing\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md).\n\n## License\n\nThis project is licensed under the Apache License 2.0.\n\n## Citation\n\nIf you find our paper and code useful in your research, please consider giving a star :star: and citation :pencil:\n\n```BibTeX\n@article{qin2025ui,\n  title={UI-TARS: Pioneering Automated GUI Interaction with Native Agents},\n  author={Qin, Yujia and Ye, Yining and Fang, Junjie and Wang, Haoming and Liang, Shihao and Tian, Shizuo and Zhang, Junda and Li, Jiahao and Li, Yunxin and Huang, Shijue and others},\n  journal={arXiv preprint arXiv:2501.12326},\n  year={2025}\n}\n```\n",
      "stars_today": 573
    },
    {
      "id": 1097695258,
      "name": "CodexBar",
      "full_name": "steipete/CodexBar",
      "description": "Show usage stats for OpenAI Codex and Claude Code, without having to login.",
      "html_url": "https://github.com/steipete/CodexBar",
      "stars": 5190,
      "forks": 313,
      "language": "Swift",
      "topics": [
        "ai",
        "claude-code",
        "codex",
        "swift"
      ],
      "created_at": "2025-11-16T17:00:44Z",
      "updated_at": "2026-02-07T02:29:37Z",
      "pushed_at": "2026-02-06T22:02:59Z",
      "open_issues": 131,
      "owner": {
        "login": "steipete",
        "avatar_url": "https://avatars.githubusercontent.com/u/58493?v=4"
      },
      "readme": "# CodexBar ğŸšï¸ - May your tokens never run out.\n\nTiny macOS 14+ menu bar app that keeps your Codex, Claude, Cursor, Gemini, Antigravity, Droid (Factory), Copilot, z.ai, Kiro, Vertex AI, Augment, Amp, and JetBrains AI limits visible (session + weekly where available) and shows when each window resets. One status item per provider (or Merge Icons mode); enable what you use from Settings. No Dock icon, minimal UI, dynamic bar icons in the menu bar.\n\n<img src=\"codexbar.png\" alt=\"CodexBar menu screenshot\" width=\"520\" />\n\n## Install\n\n### Requirements\n- macOS 14+ (Sonoma)\n\n### GitHub Releases\nDownload: <https://github.com/steipete/CodexBar/releases>\n\n### Homebrew\n```bash\nbrew install --cask steipete/tap/codexbar\n```\n\n### Linux (CLI only)\n```bash\nbrew install steipete/tap/codexbar\n```\nOr download `CodexBarCLI-v<tag>-linux-<arch>.tar.gz` from GitHub Releases.\nLinux support via Omarchy: community Waybar module and TUI, driven by the `codexbar` executable.\n\n### First run\n- Open Settings â†’ Providers and enable what you use.\n- Install/sign in to the provider sources you rely on (e.g. `codex`, `claude`, `gemini`, browser cookies, or OAuth; Antigravity requires the Antigravity app running).\n- Optional: Settings â†’ Providers â†’ Codex â†’ OpenAI cookies (Automatic or Manual) to add dashboard extras.\n\n## Providers\n\n- [Codex](docs/codex.md) â€” Local Codex CLI RPC (+ PTY fallback) and optional OpenAI web dashboard extras.\n- [Claude](docs/claude.md) â€” OAuth API or browser cookies (+ CLI PTY fallback); session + weekly usage.\n- [Cursor](docs/cursor.md) â€” Browser session cookies for plan + usage + billing resets.\n- [Gemini](docs/gemini.md) â€” OAuth-backed quota API using Gemini CLI credentials (no browser cookies).\n- [Antigravity](docs/antigravity.md) â€” Local language server probe (experimental); no external auth.\n- [Droid](docs/factory.md) â€” Browser cookies + WorkOS token flows for Factory usage + billing.\n- [Copilot](docs/copilot.md) â€” GitHub device flow + Copilot internal usage API.\n- [z.ai](docs/zai.md) â€” API token (Keychain) for quota + MCP windows.\n- [Kimi](docs/kimi.md) â€” Auth token (JWT from `kimi-auth` cookie) for weekly quota + 5â€‘hour rate limit.\n- [Kimi K2](docs/kimi-k2.md) â€” API key for credit-based usage totals.\n- [Kiro](docs/kiro.md) â€” CLI-based usage via `kiro-cli /usage` command; monthly credits + bonus credits.\n- [Vertex AI](docs/vertexai.md) â€” Google Cloud gcloud OAuth with token cost tracking from local Claude logs.\n- [Augment](docs/augment.md) â€” Browser cookie-based authentication with automatic session keepalive; credits tracking and usage monitoring.\n- [Amp](docs/amp.md) â€” Browser cookie-based authentication with Amp Free usage tracking.\n- [JetBrains AI](docs/jetbrains.md) â€” Local XML-based quota from JetBrains IDE configuration; monthly credits tracking.\n- Open to new providers: [provider authoring guide](docs/provider.md).\n\n## Icon & Screenshot\nThe menu bar icon is a tiny two-bar meter:\n- Top bar: 5â€‘hour/session window. If weekly is missing/exhausted and credits are available, it becomes a thicker credits bar.\n- Bottom bar: weekly window (hairline).\n- Errors/stale data dim the icon; status overlays indicate incidents.\n\n## Features\n- Multi-provider menu bar with per-provider toggles (Settings â†’ Providers).\n- Session + weekly meters with reset countdowns.\n- Optional Codex web dashboard enrichments (code review remaining, usage breakdown, credits history).\n- Local cost-usage scan for Codex + Claude (last 30 days).\n- Provider status polling with incident badges in the menu and icon overlay.\n- Merge Icons mode to combine providers into one status item + switcher.\n- Refresh cadence presets (manual, 1m, 2m, 5m, 15m).\n- Bundled CLI (`codexbar`) for scripts and CI (including `codexbar cost --provider codex|claude` for local cost usage); Linux CLI builds available.\n- WidgetKit widget mirrors the menu card snapshot.\n- Privacy-first: on-device parsing by default; browser cookies are opt-in and reused (no passwords stored).\n\n## Privacy note\nWondering if CodexBar scans your disk? It doesnâ€™t crawl your filesystem; it reads a small set of known locations (browser cookies/local storage, local JSONL logs) when the related features are enabled. See the discussion and audit notes in [issue #12](https://github.com/steipete/CodexBar/issues/12).\n\n## macOS permissions (why theyâ€™re needed)\n- **Full Disk Access (optional)**: only required to read Safari cookies/local storage for web-based providers (Codex web, Claude web, Cursor, Droid/Factory). If you donâ€™t grant it, use Chrome/Firefox cookies or CLI-only sources instead.\n- **Keychain access (prompted by macOS)**:\n  - Chrome cookie import needs the â€œChrome Safe Storageâ€ key to decrypt cookies.\n  - Claude OAuth credentials (written by the Claude CLI) are read from Keychain when present.\n  - z.ai API token is stored in Keychain from Preferences â†’ Providers; Copilot stores its API token in Keychain during device flow.\n  - **How do I prevent those keychain alerts?**\n    - Open **Keychain Access.app** â†’ login keychain â†’ search the item (e.g., â€œClaude Code-credentialsâ€).\n    - Open the item â†’ **Access Control** â†’ add `CodexBar.app` under â€œAlways allow access by these applicationsâ€.\n    - Prefer adding just CodexBar (avoid â€œAllow all applicationsâ€ unless you want it wide open).\n    - Relaunch CodexBar after saving.\n    - Reference screenshot: ![Keychain access control](docs/keychain-allow.png)\n  - **How to do the same for the browser?**\n    - Find the browserâ€™s â€œSafe Storageâ€ key (e.g., â€œChrome Safe Storageâ€, â€œBrave Safe Storageâ€, â€œFirefoxâ€, â€œMicrosoft Edge Safe Storageâ€).\n    - Open the item â†’ **Access Control** â†’ add `CodexBar.app` under â€œAlways allow access by these applicationsâ€.\n    - This removes the prompt when CodexBar decrypts cookies for that browser.\n- **Files & Folders prompts (folder/volume access)**: CodexBar launches provider CLIs (codex/claude/gemini/antigravity). If those CLIs read a project directory or external drive, macOS may ask CodexBar for that folder/volume (e.g., Desktop or an external volume). This is driven by the CLIâ€™s working directory, not background disk scanning.\n- **What we do not request**: no Screen Recording, Accessibility, or Automation permissions; no passwords are stored (browser cookies are reused when you opt in).\n\n## Docs\n- Providers overview: [docs/providers.md](docs/providers.md)\n- Provider authoring: [docs/provider.md](docs/provider.md)\n- UI & icon notes: [docs/ui.md](docs/ui.md)\n- CLI reference: [docs/cli.md](docs/cli.md)\n- Architecture: [docs/architecture.md](docs/architecture.md)\n- Refresh loop: [docs/refresh-loop.md](docs/refresh-loop.md)\n- Status polling: [docs/status.md](docs/status.md)\n- Sparkle updates: [docs/sparkle.md](docs/sparkle.md)\n- Release checklist: [docs/RELEASING.md](docs/RELEASING.md)\n\n## Getting started (dev)\n- Clone the repo and open it in Xcode or run the scripts directly.\n- Launch once, then toggle providers in Settings â†’ Providers.\n- Install/sign in to provider sources you rely on (CLIs, browser cookies, or OAuth).\n- Optional: set OpenAI cookies (Automatic or Manual) for Codex dashboard extras.\n\n## Build from source\n```bash\nswift build -c release          # or debug for development\n./Scripts/package_app.sh        # builds CodexBar.app in-place\nCODEXBAR_SIGNING=adhoc ./Scripts/package_app.sh  # ad-hoc signing (no Apple Developer account)\nopen CodexBar.app\n```\n\nDev loop:\n```bash\n./Scripts/compile_and_run.sh\n```\n\n## Related\n- âœ‚ï¸ [Trimmy](https://github.com/steipete/Trimmy) â€” â€œPaste once, run once.â€ Flatten multi-line shell snippets so they paste and run.\n- ğŸ§³ [MCPorter](https://mcporter.dev) â€” TypeScript toolkit + CLI for Model Context Protocol servers.\n- ğŸ§¿ [oracle](https://askoracle.dev) â€” Ask the oracle when you're stuck. Invoke GPT-5 Pro with a custom context and files.\n\n## Looking for a Windows version?\n- [Win-CodexBar](https://github.com/Finesssee/Win-CodexBar)\n\n## Credits\nInspired by [ccusage](https://github.com/ryoppippi/ccusage) (MIT), specifically the cost usage tracking.\n\n## License\nMIT â€¢ Peter Steinberger ([steipete](https://twitter.com/steipete))\n",
      "stars_today": 457
    },
    {
      "id": 868811259,
      "name": "prek",
      "full_name": "j178/prek",
      "description": "âš¡ Better `pre-commit`, re-engineered in Rust",
      "html_url": "https://github.com/j178/prek",
      "stars": 5721,
      "forks": 152,
      "language": "Rust",
      "topics": [
        "git",
        "git-hooks",
        "pre-commit"
      ],
      "created_at": "2024-10-07T08:21:29Z",
      "updated_at": "2026-02-07T02:30:21Z",
      "pushed_at": "2026-02-06T13:51:28Z",
      "open_issues": 85,
      "owner": {
        "login": "j178",
        "avatar_url": "https://avatars.githubusercontent.com/u/10510431?v=4"
      },
      "readme": "<div align=\"center\">\n\n<h1>\n  <img width=\"180\" alt=\"prek\" src=\"https://raw.githubusercontent.com/j178/prek/master/docs/assets/logo.webp\" />\n  <br/>prek\n</h1>\n\n[![prek](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/j178/prek/master/docs/assets/badge-v0.json)](https://github.com/j178/prek)\n[![codecov](https://codecov.io/github/j178/prek/graph/badge.svg?token=MP6TY24F43)](https://codecov.io/github/j178/prek)\n[![GitHub Downloads](https://img.shields.io/github/downloads/j178/prek/total?logo=github)](https://github.com/j178/prek/releases)\n[![PyPI Downloads](https://img.shields.io/pypi/dm/prek?logo=python)](https://pepy.tech/projects/prek)\n[![Discord](https://img.shields.io/discord/1403581202102878289?logo=discord)](https://discord.gg/3NRJUqJz86)\n\n</div>\n\n<!-- --8<-- [start: description] -->\n\n[pre-commit](https://pre-commit.com/) is a framework to run hooks written in many languages, and it manages the\nlanguage toolchain and dependencies for running the hooks.\n\n*prek* is a reimagined version of pre-commit, built in Rust.\nIt is designed to be a faster, dependency-free and drop-in alternative for it,\nwhile also providing some additional long-requested features.\n\n<!-- --8<-- [end: description] -->\n\n> [!NOTE]\n> Although prek is pretty new, itâ€™s already powering realâ€‘world projects like [CPython](https://github.com/python/cpython), [Apache Airflow](https://github.com/apache/airflow), [FastAPI](https://github.com/fastapi/fastapi), and more projects are picking it upâ€”see [Who is using prek?](#who-is-using-prek). If youâ€™re looking for an alternative to `pre-commit`, please give it a tryâ€”weâ€™d love your feedback!\n>\n> Please note that some languages are not yet supported for full dropâ€‘in parity with `pre-commit`. See [Language Support](https://prek.j178.dev/languages/) for current status.\n\n<!-- --8<-- [start:features] -->\n\n## Features\n\n- A single binary with no dependencies, does not require Python or any other runtime.\n- [Faster](https://prek.j178.dev/benchmark/) than `pre-commit` and more efficient in disk space usage.\n- Fully compatible with the original pre-commit configurations and hooks.\n- Built-in support for monorepos (i.e. [workspace mode](https://prek.j178.dev/workspace/)).\n- Integration with [`uv`](https://github.com/astral-sh/uv) for managing Python virtual environments and dependencies.\n- Improved toolchain installations for Python, Node.js, Bun, Go, Rust and Ruby, shared between hooks.\n- [Built-in](https://prek.j178.dev/builtin/) Rust-native implementation of some common hooks.\n\n<!-- --8<-- [end:features] -->\n\n## Table of contents\n\n- [Installation](#installation)\n- [Quick start](#quick-start)\n- [Why prek?](#why-prek)\n- [Who is using prek?](#who-is-using-prek)\n- [Acknowledgements](#acknowledgements)\n\n## Installation\n\n<details>\n<summary>Standalone installer</summary>\n\nprek provides a standalone installer script to download and install the tool,\n\nOn Linux and macOS:\n\n<!-- --8<-- [start: linux-standalone-install] -->\n\n```bash\ncurl --proto '=https' --tlsv1.2 -LsSf https://github.com/j178/prek/releases/download/v0.3.2/prek-installer.sh | sh\n```\n\n<!-- --8<-- [end: linux-standalone-install] -->\n\nOn Windows:\n\n<!-- --8<-- [start: windows-standalone-install] -->\n\n```powershell\npowershell -ExecutionPolicy ByPass -c \"irm https://github.com/j178/prek/releases/download/v0.3.2/prek-installer.ps1 | iex\"\n```\n\n<!-- --8<-- [end: windows-standalone-install] -->\n\n</details>\n\n<details>\n<summary>PyPI</summary>\n\n<!-- --8<-- [start: pypi-install] -->\n\nprek is published as Python binary wheel to PyPI, you can install it using `pip`, `uv` (recommended), or `pipx`:\n\n```bash\n# Using uv (recommended)\nuv tool install prek\n\n# Using uvx (install and run in one command)\nuvx prek\n\n# Adding prek to the project dev-dependencies\nuv add --dev prek\n\n# Using pip\npip install prek\n\n# Using pipx\npipx install prek\n```\n\n<!-- --8<-- [end: pypi-install] -->\n\n</details>\n\n<details>\n<summary>Homebrew</summary>\n\n<!-- --8<-- [start: homebrew-install] -->\n\n```bash\nbrew install prek\n```\n\n<!-- --8<-- [end: homebrew-install] -->\n\n</details>\n\n<details>\n<summary>mise</summary>\n\n<!-- --8<-- [start: mise-install] -->\n\nTo use prek with [mise](https://mise.jdx.dev) ([v2025.8.11](https://github.com/jdx/mise/releases/tag/v2025.8.11) or later):\n\n```bash\nmise use prek\n```\n\n<!-- --8<-- [end: mise-install] -->\n\n</details>\n\n<details>\n<summary>Cargo binstall</summary>\n\n<!-- --8<-- [start: cargo-binstall] -->\n\nInstall pre-compiled binaries from GitHub using [cargo-binstall](https://github.com/cargo-bins/cargo-binstall):\n\n```bash\ncargo binstall prek\n```\n\n<!-- --8<-- [end: cargo-binstall] -->\n\n</details>\n\n<details>\n<summary>Cargo</summary>\n\n<!-- --8<-- [start: cargo-install] -->\n\nBuild from source using Cargo (Rust 1.89+ is required):\n\n```bash\ncargo install --locked prek\n```\n\n<!-- --8<-- [end: cargo-install] -->\n\n</details>\n\n<details>\n<summary>npmjs</summary>\n\n<!-- --8<-- [start: npmjs-install] -->\n\nprek is published as a [Node.js package](https://www.npmjs.com/package/@j178/prek)\nand can be installed with any npm-compatible package manager:\n\n```bash\n# As a dev dependency\nnpm add -D @j178/prek\npnpm add -D @j178/prek\nbun add -D @j178/prek\n\n# Or install globally\nnpm install -g @j178/prek\npnpm add -g @j178/prek\nbun install -g @j178/prek\n\n# Or run directly without installing\nnpx @j178/prek --version\nbunx @j178/prek --version\n```\n\n<!-- --8<-- [end: npmjs-install] -->\n\n</details>\n\n<details>\n<summary>Nix</summary>\n\n<!-- --8<-- [start: nix-install] -->\n\nprek is available via [Nixpkgs](https://search.nixos.org/packages?channel=unstable&show=prek&query=prek).\n\n```shell\n# Choose what's appropriate for your use case.\n# One-off in a shell:\nnix-shell -p prek\n\n# NixOS or non-NixOS without flakes:\nnix-env -iA nixos.prek\n\n# Non-NixOS with flakes:\nnix profile install nixpkgs#prek\n```\n\n<!-- --8<-- [end: nix-install] -->\n\n</details>\n\n<details>\n<summary>Conda</summary>\n\n<!-- --8<-- [start: conda-forge-install] -->\n\nprek is available as `prek` via [conda-forge](https://anaconda.org/conda-forge/prek).\n\n```shell\nconda install conda-forge::prek\n```\n\n<!-- --8<-- [end: conda-forge-install] -->\n\n</details>\n\n<details>\n<summary>Scoop (Windows)</summary>\n\n<!-- --8<-- [start: scoop-install] -->\n\nprek is available via [Scoop](https://scoop.sh/#/apps?q=prek).\n\n```powershell\nscoop install main/prek\n```\n\n<!-- --8<-- [end: scoop-install] -->\n\n</details>\n\n<details>\n<summary>MacPorts</summary>\n\n<!-- --8<-- [start: macports-install] -->\n\nprek is available via [MacPorts](https://ports.macports.org/port/prek/).\n\n```bash\nsudo port install prek\n```\n\n<!-- --8<-- [end: macports-install] -->\n\n</details>\n\n<details>\n<summary>GitHub Releases</summary>\n\n<!-- --8<-- [start: pre-built-binaries] -->\n\nPre-built binaries are available for download from the [GitHub releases](https://github.com/j178/prek/releases) page.\n\n<!-- --8<-- [end: pre-built-binaries] -->\n\n</details>\n\n<details>\n<summary>GitHub Actions</summary>\n\n<!-- --8<-- [start: github-actions] -->\n\nprek can be used in GitHub Actions via the [j178/prek-action](https://github.com/j178/prek-action) repository.\n\nExample workflow:\n\n```yaml\nname: Prek checks\non: [push, pull_request]\n\njobs:\n  prek:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v6\n      - uses: j178/prek-action@v1\n```\n\nThis action installs prek and runs `prek run --all-files` on your repository.\n\nprek is also available via [`taiki-e/install-action`](https://github.com/taiki-e/install-action) for installing various tools.\n\n<!-- --8<-- [end: github-actions] -->\n\n</details>\n\n<!-- --8<-- [start: self-update] -->\n\nIf installed via the standalone installer, prek can update itself to the latest version:\n\n```bash\nprek self update\n```\n\n<!-- --8<-- [end: self-update] -->\n\n## Quick start\n\n- **I already use pre-commit:** follow the short migration checklist in the [quickstart guide](https://prek.j178.dev/quickstart/#already-using-pre-commit) to swap in `prek` safely.\n- **I'm new to pre-commit-style tools:** learn the basicsâ€”creating a config, running hooks, and installing git hooksâ€”in the [beginner quickstart walkthrough](https://prek.j178.dev/quickstart/#new-to-pre-commit-style-workflows).\n\n<!-- --8<-- [start: why] -->\n\n## Why prek?\n\n### prek is faster\n\n- It is [multiple times faster](https://prek.j178.dev/benchmark/) than `pre-commit` and takes up half the disk space.\n- It redesigned how hook environments and toolchains are managed, they are all shared between hooks, which reduces the disk space usage and speeds up the installation process.\n- Repositories are cloned in parallel, and hooks are installed in parallel if their dependencies are disjoint.\n- Hooks can run in parallel by priority (hooks with the same [`priority`](https://prek.j178.dev/configuration/#priority) may run concurrently), reducing end-to-end runtime.\n- It uses [`uv`](https://github.com/astral-sh/uv) for creating Python virtualenvs and installing dependencies, which is known for its speed and efficiency.\n- It implements some common hooks in Rust, [built in prek](https://prek.j178.dev/builtin/), which are faster than their Python counterparts.\n- It supports `repo: builtin` for offline, zero-setup hooks, which is not available in `pre-commit`.\n\n### prek provides a better user experience\n\n- No need to install Python or any other runtime, just download a single binary.\n- No hassle with your Python version or virtual environments, prek automatically installs the required Python version and creates a virtual environment for you.\n- Built-in support for [workspaces](https://prek.j178.dev/workspace/) (or monorepos), each subproject can have its own `.pre-commit-config.yaml` file.\n- [`prek run`](https://prek.j178.dev/cli/#prek-run) has some nifty improvements over `pre-commit run`, such as:\n    - `prek run --directory <dir>` runs hooks for files in the specified directory, no need to use `git ls-files -- <dir> | xargs pre-commit run --files` anymore.\n    - `prek run --last-commit` runs hooks for files changed in the last commit.\n    - `prek run [HOOK] [HOOK]` selects and runs multiple hooks.\n- [`prek list`](https://prek.j178.dev/cli/#prek-list) command lists all available hooks, their ids, and descriptions, providing a better overview of the configured hooks.\n- [`prek auto-update`](https://prek.j178.dev/cli/#prek-auto-update) supports `--cooldown-days` to mitigate open source supply chain attacks.\n- prek provides shell completions for `prek run <hook_id>` command, making it easier to run specific hooks without remembering their ids.\n\nFor more detailed improvements prek offers, take a look at [Difference from pre-commit](https://prek.j178.dev/diff/).\n\n## Who is using prek?\n\nprek is pretty new, but it is already being used or recommend by some projects and organizations:\n\n- [apache/airflow](https://github.com/apache/airflow/issues/44995)\n- [python/cpython](https://github.com/python/cpython/issues/143148)\n- [pdm-project/pdm](https://github.com/pdm-project/pdm/pull/3593)\n- [fastapi/fastapi](https://github.com/fastapi/fastapi/pull/14572)\n- [fastapi/typer](https://github.com/fastapi/typer/pull/1453)\n- [fastapi/asyncer](https://github.com/fastapi/asyncer/pull/437)\n- [astral-sh/ruff](https://github.com/astral-sh/ruff/pull/22505)\n- [astral-sh/ty](https://github.com/astral-sh/ty/pull/2469)\n- [openclaw/openclaw](https://github.com/openclaw/openclaw/pull/1720)\n- [home-assistant/core](https://github.com/home-assistant/core/pull/160427)\n- [DetachHead/basedpyright](https://github.com/DetachHead/basedpyright/pull/1413)\n- [OpenLineage/OpenLineage](https://github.com/OpenLineage/OpenLineage/pull/3965)\n- [authlib/authlib](https://github.com/authlib/authlib/pull/804)\n- [django/djangoproject.com](https://github.com/django/djangoproject.com/pull/2252)\n- [Future-House/paper-qa](https://github.com/Future-House/paper-qa/pull/1098)\n- [requests-cache/requests-cache](https://github.com/requests-cache/requests-cache/pull/1116)\n- [Goldziher/kreuzberg](https://github.com/Goldziher/kreuzberg/pull/142)\n- [python-attrs/attrs](https://github.com/python-attrs/attrs/commit/c95b177682e76a63478d29d040f9cb36a8d31915)\n- [jlowin/fastmcp](https://github.com/jlowin/fastmcp/pull/2309)\n- [apache/iceberg-python](https://github.com/apache/iceberg-python/pull/2533)\n- [apache/lucene](https://github.com/apache/lucene/pull/15629)\n- [jcrist/msgspec](https://github.com/jcrist/msgspec/pull/918)\n- [python-humanize/humanize](https://github.com/python-humanize/humanize/pull/276)\n- [MoonshotAI/kimi-cli](https://github.com/MoonshotAI/kimi-cli/pull/535)\n- [simple-icons/simple-icons](https://github.com/simple-icons/simple-icons/pull/14245)\n- [ast-grep/ast-grep](https://github.com/ast-grep/ast-grep.github.io/commit/e30818144b2967a7f9172c8cf2f4596bba219bf5)\n- [commitizen-tools/commitizen](https://github.com/commitizen-tools/commitizen)\n- [cocoindex-io/cocoindex](https://github.com/cocoindex-io/cocoindex/pull/1564)\n- [cachix/devenv](https://github.com/cachix/devenv/pull/2304)\n- [copper-project/copper-rs](https://github.com/copper-project/copper-rs/pull/783)\n\n<!-- --8<-- [end: why] -->\n\n## Acknowledgements\n\nThis project is heavily inspired by the original [pre-commit](https://pre-commit.com/) tool, and it wouldn't be possible without the hard work\nof the maintainers and contributors of that project.\n\nAnd a special thanks to the [Astral](https://github.com/astral-sh) team for their remarkable projects, particularly [uv](https://github.com/astral-sh/uv),\nfrom which I've learned a lot on how to write efficient and idiomatic Rust code.\n",
      "stars_today": 329
    },
    {
      "id": 931352845,
      "name": "prompt-optimizer",
      "full_name": "linshenkx/prompt-optimizer",
      "description": "ä¸€æ¬¾æç¤ºè¯ä¼˜åŒ–å™¨ï¼ŒåŠ©åŠ›äºç¼–å†™é«˜è´¨é‡çš„æç¤ºè¯",
      "html_url": "https://github.com/linshenkx/prompt-optimizer",
      "stars": 19689,
      "forks": 2426,
      "language": "TypeScript",
      "topics": [
        "llm",
        "prompt",
        "prompt-engineering",
        "prompt-optimization",
        "prompt-toolkit",
        "prompt-tuning"
      ],
      "created_at": "2025-02-12T06:06:49Z",
      "updated_at": "2026-02-07T02:27:43Z",
      "pushed_at": "2026-02-05T14:41:30Z",
      "open_issues": 24,
      "owner": {
        "login": "linshenkx",
        "avatar_url": "https://avatars.githubusercontent.com/u/32978552?v=4"
      },
      "readme": "# Prompt Optimizer (æç¤ºè¯ä¼˜åŒ–å™¨) ğŸš€\n\n<div align=\"center\">\n\n[English](README_EN.md) | [ä¸­æ–‡](README.md)\n\n[![GitHub stars](https://img.shields.io/github/stars/linshenkx/prompt-optimizer)](https://github.com/linshenkx/prompt-optimizer/stargazers)\n![Chrome Web Store Users](https://img.shields.io/chrome-web-store/users/cakkkhboolfnadechdlgdcnjammejlna?style=flat&label=Chrome%20Users&link=https%3A%2F%2Fchromewebstore.google.com%2Fdetail%2F%25E6%258F%2590%25E7%25A4%25BA%25E8%25AF%258D%25E4%25BC%2598%25E5%258C%2596%25E5%2599%25A8%2Fcakkkhboolfnadechdlgdcnjammejlna)\n\n<a href=\"https://trendshift.io/repositories/13813\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/13813\" alt=\"linshenkx%2Fprompt-optimizer | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\n[![License](https://img.shields.io/badge/license-AGPL--3.0-blue.svg)](LICENSE)\n[![Docker Pulls](https://img.shields.io/docker/pulls/linshen/prompt-optimizer)](https://hub.docker.com/r/linshen/prompt-optimizer)\n![GitHub forks](https://img.shields.io/github/forks/linshenkx/prompt-optimizer?style=flat)\n[![Deploy with Vercel](https://img.shields.io/badge/Vercel-indigo?style=flat&logo=vercel)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Flinshenkx%2Fprompt-optimizer)\n\n[åœ¨çº¿ä½“éªŒ](https://prompt.always200.com) | [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹) | [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜) | [Chromeæ’ä»¶](https://chromewebstore.google.com/detail/prompt-optimizer/cakkkhboolfnadechdlgdcnjammejlna) | [ğŸ’–èµåŠ©æ”¯æŒ](images/other/sponsor_wx.jpg)\n\n[å¼€å‘æ–‡æ¡£](dev.md) | [Verceléƒ¨ç½²æŒ‡å—](docs/user/deployment/vercel.md) | [MCPéƒ¨ç½²ä½¿ç”¨è¯´æ˜](docs/user/mcp-server.md) | [DeepWikiæ–‡æ¡£](https://deepwiki.com/linshenkx/prompt-optimizer) | [ZReadæ–‡æ¡£](https://zread.ai/linshenkx/prompt-optimizer)\n\n</div>\n\n## ğŸ“– é¡¹ç›®ç®€ä»‹\n\nPrompt Optimizeræ˜¯ä¸€ä¸ªå¼ºå¤§çš„AIæç¤ºè¯ä¼˜åŒ–å·¥å…·ï¼Œå¸®åŠ©ä½ ç¼–å†™æ›´å¥½çš„AIæç¤ºè¯ï¼Œæå‡AIè¾“å‡ºè´¨é‡ã€‚æ”¯æŒWebåº”ç”¨ã€æ¡Œé¢åº”ç”¨ã€Chromeæ’ä»¶å’ŒDockeréƒ¨ç½²å››ç§ä½¿ç”¨æ–¹å¼ã€‚\n\n### ğŸ¥ åŠŸèƒ½æ¼”ç¤º\n\n<div align=\"center\">\n  <p><b>1. è§’è‰²æ‰®æ¼”å¯¹è¯ï¼šæ¿€å‘å°æ¨¡å‹æ½œåŠ›</b></p>\n  <p>åœ¨è¿½æ±‚æˆæœ¬æ•ˆç›Šçš„ç”Ÿäº§æˆ–æ³¨é‡éšç§çš„æœ¬åœ°åŒ–åœºæ™¯ä¸­ï¼Œç»“æ„åŒ–çš„æç¤ºè¯èƒ½è®©å°æ¨¡å‹ç¨³å®šåœ°è¿›å…¥è§’è‰²ï¼Œæä¾›æ²‰æµ¸å¼ã€é«˜ä¸€è‡´æ€§çš„è§’è‰²æ‰®æ¼”ä½“éªŒï¼Œæœ‰æ•ˆæ¿€å‘å…¶æ½œåŠ›ã€‚</p>\n  <img src=\"images/demo/cat-maid-roleplay.png\" alt=\"çŒ«å¥³ä»†è§’è‰²æ‰®æ¼”æ¼”ç¤º\" width=\"85%\">\n  <br>\n  <p><b>2. çŸ¥è¯†å›¾è°±æå–ï¼šä¿éšœç”Ÿäº§ç¯å¢ƒçš„ç¨³å®šæ€§</b></p>\n  <p>åœ¨éœ€è¦ç¨‹åºåŒ–å¤„ç†çš„ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œé«˜è´¨é‡çš„æç¤ºè¯èƒ½æ˜¾è‘—é™ä½å¯¹æ¨¡å‹æ™ºèƒ½ç¨‹åº¦çš„è¦æ±‚ï¼Œä½¿å¾—æ›´ç»æµçš„å°æ¨¡å‹ä¹Ÿèƒ½ç¨³å®šè¾“å‡ºå¯é çš„æŒ‡å®šæ ¼å¼ã€‚æœ¬å·¥å…·æ—¨åœ¨è¾…åŠ©å¼€å‘è€…å¿«é€Ÿè¾¾åˆ°æ­¤ç›®çš„ï¼Œä»è€ŒåŠ é€Ÿå¼€å‘ã€ä¿éšœç¨³å®šï¼Œå®ç°é™æœ¬å¢æ•ˆã€‚</p>\n  <img src=\"images/demo/knowledge-graph-extractor.png\" alt=\"çŸ¥è¯†å›¾è°±æå–æ¼”ç¤º\" width=\"85%\">\n  <br>\n  <p><b>3. è¯—æ­Œå†™ä½œï¼šè¾…åŠ©åˆ›æ„æ¢ç´¢ä¸éœ€æ±‚å®šåˆ¶</b></p>\n  <p>å½“é¢å¯¹ä¸€ä¸ªå¼ºå¤§çš„AIï¼Œæˆ‘ä»¬çš„ç›®æ ‡ä¸åªæ˜¯å¾—åˆ°ä¸€ä¸ªâ€œå¥½â€ç­”æ¡ˆï¼Œè€Œæ˜¯å¾—åˆ°ä¸€ä¸ªâ€œæˆ‘ä»¬æƒ³è¦çš„â€ç‹¬ç‰¹ç­”æ¡ˆã€‚æœ¬å·¥å…·èƒ½å¸®åŠ©ç”¨æˆ·å°†ä¸€ä¸ªæ¨¡ç³Šçš„çµæ„Ÿï¼ˆå¦‚â€œå†™é¦–è¯—â€ï¼‰ç»†åŒ–ä¸ºå…·ä½“çš„éœ€æ±‚ï¼ˆå…³äºä»€ä¹ˆä¸»é¢˜ã€ä½•ç§æ„è±¡ã€ä½•ç§æƒ…æ„Ÿï¼‰ï¼Œè¾…åŠ©æ‚¨æ¢ç´¢ã€å‘æ˜å¹¶ç²¾ç¡®è¡¨è¾¾è‡ªå·±çš„åˆ›æ„ï¼Œä¸AIå…±åˆ›ç‹¬ä¸€æ— äºŒçš„ä½œå“ã€‚</p>\n  <img src=\"images/demo/poetry-writing.png\" alt=\"è¯—æ­Œåˆ›ä½œæ¼”ç¤º\" width=\"85%\">\n</div>\n\n## âœ¨ æ ¸å¿ƒç‰¹æ€§\n\n- ğŸ¯ **æ™ºèƒ½ä¼˜åŒ–**ï¼šä¸€é”®ä¼˜åŒ–æç¤ºè¯ï¼Œæ”¯æŒå¤šè½®è¿­ä»£æ”¹è¿›ï¼Œæå‡AIå›å¤å‡†ç¡®åº¦\n- ğŸ“ **åŒæ¨¡å¼ä¼˜åŒ–**ï¼šæ”¯æŒç³»ç»Ÿæç¤ºè¯ä¼˜åŒ–å’Œç”¨æˆ·æç¤ºè¯ä¼˜åŒ–ï¼Œæ»¡è¶³ä¸åŒä½¿ç”¨åœºæ™¯\n- ğŸ”„ **å¯¹æ¯”æµ‹è¯•**ï¼šæ”¯æŒåŸå§‹æç¤ºè¯å’Œä¼˜åŒ–åæç¤ºè¯çš„å®æ—¶å¯¹æ¯”ï¼Œç›´è§‚å±•ç¤ºä¼˜åŒ–æ•ˆæœ\n- ğŸ¤– **å¤šæ¨¡å‹é›†æˆ**ï¼šæ”¯æŒOpenAIã€Geminiã€DeepSeekã€æ™ºè°±AIã€SiliconFlowç­‰ä¸»æµAIæ¨¡å‹\n- ğŸ–¼ï¸ **å›¾åƒç”Ÿæˆ**ï¼šæ”¯æŒæ–‡ç”Ÿå›¾ï¼ˆT2Iï¼‰å’Œå›¾ç”Ÿå›¾ï¼ˆI2Iï¼‰ï¼Œé›†æˆGeminiã€Seedreamç­‰å›¾åƒæ¨¡å‹\n- ğŸ“Š **é«˜çº§æµ‹è¯•æ¨¡å¼**ï¼šä¸Šä¸‹æ–‡å˜é‡ç®¡ç†ã€å¤šè½®ä¼šè¯æµ‹è¯•ã€å·¥å…·è°ƒç”¨ï¼ˆFunction Callingï¼‰æ”¯æŒ\n- ğŸ”’ **å®‰å…¨æ¶æ„**ï¼šçº¯å®¢æˆ·ç«¯å¤„ç†ï¼Œæ•°æ®ç›´æ¥ä¸AIæœåŠ¡å•†äº¤äº’ï¼Œä¸ç»è¿‡ä¸­é—´æœåŠ¡å™¨\n- ğŸ“± **å¤šç«¯æ”¯æŒ**ï¼šåŒæ—¶æä¾›Webåº”ç”¨ã€æ¡Œé¢åº”ç”¨ã€Chromeæ’ä»¶å’ŒDockeréƒ¨ç½²å››ç§ä½¿ç”¨æ–¹å¼\n- ğŸ” **è®¿é—®æ§åˆ¶**ï¼šæ”¯æŒå¯†ç ä¿æŠ¤åŠŸèƒ½ï¼Œä¿éšœéƒ¨ç½²å®‰å…¨\n- ğŸ§© **MCPåè®®æ”¯æŒ**ï¼šæ”¯æŒModel Context Protocol (MCP) åè®®ï¼Œå¯ä¸Claude Desktopç­‰MCPå…¼å®¹åº”ç”¨é›†æˆ\n\n## ğŸš€ é«˜çº§åŠŸèƒ½\n\n### å›¾åƒç”Ÿæˆæ¨¡å¼\n- ğŸ–¼ï¸ **æ–‡ç”Ÿå›¾ï¼ˆT2Iï¼‰**ï¼šé€šè¿‡æ–‡æœ¬æç¤ºè¯ç”Ÿæˆå›¾åƒ\n- ğŸ¨ **å›¾ç”Ÿå›¾ï¼ˆI2Iï¼‰**ï¼šåŸºäºæœ¬åœ°å›¾ç‰‡è¿›è¡Œå›¾åƒå˜æ¢å’Œä¼˜åŒ–\n- ğŸ”Œ **å¤šæ¨¡å‹æ”¯æŒ**ï¼šé›†æˆGeminiã€Seedreamç­‰ä¸»æµå›¾åƒç”Ÿæˆæ¨¡å‹\n- âš™ï¸ **æ¨¡å‹å‚æ•°**ï¼šæ”¯æŒå„æ¨¡å‹ç‰¹æœ‰å‚æ•°é…ç½®ï¼ˆå¦‚å°ºå¯¸ã€é£æ ¼ç­‰ï¼‰\n- ğŸ“¥ **é¢„è§ˆä¸ä¸‹è½½**ï¼šå®æ—¶é¢„è§ˆç”Ÿæˆç»“æœï¼Œæ”¯æŒä¸‹è½½ä¿å­˜\n\n### é«˜çº§æµ‹è¯•æ¨¡å¼\n- ğŸ“Š **ä¸Šä¸‹æ–‡å˜é‡ç®¡ç†**ï¼šè‡ªå®šä¹‰å˜é‡ã€æ‰¹é‡æ›¿æ¢ã€å˜é‡é¢„è§ˆ\n- ğŸ’¬ **å¤šè½®ä¼šè¯æµ‹è¯•**ï¼šæ¨¡æ‹ŸçœŸå®å¯¹è¯åœºæ™¯ï¼Œæµ‹è¯•æç¤ºè¯åœ¨å¤šè½®äº¤äº’ä¸­çš„è¡¨ç°\n- ğŸ› ï¸ **å·¥å…·è°ƒç”¨æ”¯æŒ**ï¼šFunction Callingé›†æˆï¼Œæ”¯æŒOpenAIå’ŒGeminiå·¥å…·è°ƒç”¨\n- ğŸ¯ **çµæ´»è°ƒè¯•**ï¼šæ›´å¼ºå¤§çš„æç¤ºè¯æµ‹è¯•å’Œè°ƒè¯•èƒ½åŠ›\n\nè¯¦ç»†ä½¿ç”¨è¯´æ˜è¯·æŸ¥çœ‹ [å›¾åƒæ¨¡å¼æ–‡æ¡£](docs/image-mode.md)\n\n## å¿«é€Ÿå¼€å§‹\n\n### 1. ä½¿ç”¨åœ¨çº¿ç‰ˆæœ¬ï¼ˆæ¨èï¼‰\n\nç›´æ¥è®¿é—®ï¼š[https://prompt.always200.com](https://prompt.always200.com)\n\né¡¹ç›®æ˜¯çº¯å‰ç«¯é¡¹ç›®ï¼Œæ‰€æœ‰æ•°æ®åªå­˜å‚¨åœ¨æµè§ˆå™¨æœ¬åœ°ï¼Œä¸ä¼šä¸Šä¼ è‡³ä»»ä½•æœåŠ¡å™¨ï¼Œå› æ­¤ç›´æ¥ä½¿ç”¨åœ¨çº¿ç‰ˆæœ¬ä¹Ÿæ˜¯å®‰å…¨å¯é çš„\n\n### 2. Verceléƒ¨ç½²\næ–¹å¼1ï¼šä¸€é”®éƒ¨ç½²åˆ°è‡ªå·±çš„Vercel(æ–¹ä¾¿ï¼Œä½†åç»­æ— æ³•è‡ªåŠ¨æ›´æ–°)ï¼š\n   [![éƒ¨ç½²åˆ° Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Flinshenkx%2Fprompt-optimizer)\n\næ–¹å¼2: Forké¡¹ç›®ååœ¨Vercelä¸­å¯¼å…¥ï¼ˆæ¨èï¼Œä½†éœ€å‚è€ƒéƒ¨ç½²æ–‡æ¡£è¿›è¡Œæ‰‹åŠ¨è®¾ç½®ï¼‰ï¼š\n   - å…ˆForké¡¹ç›®åˆ°è‡ªå·±çš„GitHub\n   - ç„¶ååœ¨Vercelä¸­å¯¼å…¥è¯¥é¡¹ç›®\n   - å¯è·Ÿè¸ªæºé¡¹ç›®æ›´æ–°ï¼Œä¾¿äºåŒæ­¥æœ€æ–°åŠŸèƒ½å’Œä¿®å¤\n- é…ç½®ç¯å¢ƒå˜é‡ï¼š\n  - `ACCESS_PASSWORD`ï¼šè®¾ç½®è®¿é—®å¯†ç ï¼Œå¯ç”¨è®¿é—®é™åˆ¶\n  - `VITE_OPENAI_API_KEY`ç­‰ï¼šé…ç½®å„AIæœåŠ¡å•†çš„APIå¯†é’¥\n\næ›´å¤šè¯¦ç»†çš„éƒ¨ç½²æ­¥éª¤å’Œæ³¨æ„äº‹é¡¹ï¼Œè¯·æŸ¥çœ‹ï¼š\n- [Verceléƒ¨ç½²æŒ‡å—](docs/user/deployment/vercel.md)\n\n### 3. ä¸‹è½½æ¡Œé¢åº”ç”¨\nä» [GitHub Releases](https://github.com/linshenkx/prompt-optimizer/releases) ä¸‹è½½æœ€æ–°ç‰ˆæœ¬ã€‚æˆ‘ä»¬ä¸ºå„å¹³å°æä¾›**å®‰è£…ç¨‹åº**å’Œ**å‹ç¼©åŒ…**ä¸¤ç§æ ¼å¼ã€‚\n\n- **å®‰è£…ç¨‹åº (æ¨è)**: å¦‚ `*.exe`, `*.dmg`, `*.AppImage` ç­‰ã€‚**å¼ºçƒˆæ¨èä½¿ç”¨æ­¤æ–¹å¼ï¼Œå› ä¸ºå®ƒæ”¯æŒè‡ªåŠ¨æ›´æ–°**ã€‚\n- **å‹ç¼©åŒ…**: å¦‚ `*.zip`ã€‚è§£å‹å³ç”¨ï¼Œä½†æ— æ³•è‡ªåŠ¨æ›´æ–°ã€‚\n\n**æ¡Œé¢åº”ç”¨æ ¸å¿ƒä¼˜åŠ¿**:\n- âœ… **æ— è·¨åŸŸé™åˆ¶**ï¼šä½œä¸ºåŸç”Ÿæ¡Œé¢åº”ç”¨ï¼Œå®ƒèƒ½å½»åº•æ‘†è„±æµè§ˆå™¨è·¨åŸŸï¼ˆCORSï¼‰é—®é¢˜çš„å›°æ‰°ã€‚è¿™æ„å‘³ç€æ‚¨å¯ä»¥ç›´æ¥è¿æ¥ä»»ä½•AIæœåŠ¡æä¾›å•†çš„APIï¼ŒåŒ…æ‹¬æœ¬åœ°éƒ¨ç½²çš„Ollamaæˆ–æœ‰ä¸¥æ ¼å®‰å…¨ç­–ç•¥çš„å•†ä¸šAPIï¼Œè·å¾—æœ€å®Œæ•´ã€æœ€ç¨³å®šçš„åŠŸèƒ½ä½“éªŒã€‚\n- âœ… **è‡ªåŠ¨æ›´æ–°**ï¼šé€šè¿‡å®‰è£…ç¨‹åºï¼ˆå¦‚ `.exe`, `.dmg`ï¼‰å®‰è£…çš„ç‰ˆæœ¬ï¼Œèƒ½å¤Ÿè‡ªåŠ¨æ£€æŸ¥å¹¶æ›´æ–°åˆ°æœ€æ–°ç‰ˆã€‚\n- âœ… **ç‹¬ç«‹è¿è¡Œ**ï¼šæ— éœ€ä¾èµ–æµè§ˆå™¨ï¼Œæä¾›æ›´å¿«çš„å“åº”å’Œæ›´ä½³çš„æ€§èƒ½ã€‚\n\n### 4. å®‰è£…Chromeæ’ä»¶\n1. ä»Chromeå•†åº—å®‰è£…ï¼ˆç”±äºå®¡æ‰¹è¾ƒæ…¢ï¼Œå¯èƒ½ä¸æ˜¯æœ€æ–°çš„ï¼‰ï¼š[Chromeå•†åº—åœ°å€](https://chromewebstore.google.com/detail/prompt-optimizer/cakkkhboolfnadechdlgdcnjammejlna)\n2. ç‚¹å‡»å›¾æ ‡å³å¯æ‰“å¼€æç¤ºè¯ä¼˜åŒ–å™¨\n\n### 5. Dockeréƒ¨ç½²\n<details>\n<summary>ç‚¹å‡»æŸ¥çœ‹ Docker éƒ¨ç½²å‘½ä»¤</summary>\n\n```bash\n# è¿è¡Œå®¹å™¨ï¼ˆé»˜è®¤é…ç½®ï¼‰\ndocker run -d -p 8081:80 --restart unless-stopped --name prompt-optimizer linshen/prompt-optimizer\n\n# è¿è¡Œå®¹å™¨ï¼ˆé…ç½®APIå¯†é’¥å’Œè®¿é—®å¯†ç ï¼‰\ndocker run -d -p 8081:80 \\\n  -e VITE_OPENAI_API_KEY=your_key \\\n  -e ACCESS_USERNAME=your_username \\  # å¯é€‰ï¼Œé»˜è®¤ä¸º\"admin\"\n  -e ACCESS_PASSWORD=your_password \\  # è®¾ç½®è®¿é—®å¯†ç \n  --restart unless-stopped \\\n  --name prompt-optimizer \\\n  linshen/prompt-optimizer\n```\n</details>\n\n> **å›½å†…é•œåƒ**: å¦‚æœDocker Hubè®¿é—®è¾ƒæ…¢ï¼Œå¯ä»¥å°†ä¸Šè¿°å‘½ä»¤ä¸­çš„ `linshen/prompt-optimizer` æ›¿æ¢ä¸º `registry.cn-guangzhou.aliyuncs.com/prompt-optimizer/prompt-optimizer`\n\n### 6. Docker Composeéƒ¨ç½²\n<details>\n<summary>ç‚¹å‡»æŸ¥çœ‹ Docker Compose éƒ¨ç½²æ­¥éª¤</summary>\n\n```bash\n# 1. å…‹éš†ä»“åº“\ngit clone https://github.com/linshenkx/prompt-optimizer.git\ncd prompt-optimizer\n\n# 2. å¯é€‰ï¼šåˆ›å»º.envæ–‡ä»¶é…ç½®APIå¯†é’¥å’Œè®¿é—®è®¤è¯\ncp env.local.example .env\n# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å…¥å®é™…çš„ API å¯†é’¥å’Œé…ç½®\n\n# 3. å¯åŠ¨æœåŠ¡\ndocker compose up -d\n\n# 4. æŸ¥çœ‹æ—¥å¿—\ndocker compose logs -f\n\n# 5. è®¿é—®æœåŠ¡\nWeb ç•Œé¢ï¼šhttp://localhost:8081\nMCP æœåŠ¡å™¨ï¼šhttp://localhost:8081/mcp\n```\n</details>\n\nä½ è¿˜å¯ä»¥ç›´æ¥ç¼–è¾‘docker-compose.ymlæ–‡ä»¶ï¼Œè‡ªå®šä¹‰é…ç½®ï¼š\n<details>\n<summary>ç‚¹å‡»æŸ¥çœ‹ docker-compose.yml ç¤ºä¾‹</summary>\n\n```yaml\nservices:\n  prompt-optimizer:\n    # ä½¿ç”¨Docker Hubé•œåƒ\n    image: linshen/prompt-optimizer:latest\n    # æˆ–ä½¿ç”¨é˜¿é‡Œäº‘é•œåƒï¼ˆå›½å†…ç”¨æˆ·æ¨èï¼‰\n    # image: registry.cn-guangzhou.aliyuncs.com/prompt-optimizer/prompt-optimizer:latest\n    container_name: prompt-optimizer\n    restart: unless-stopped\n    ports:\n      - \"8081:80\"  # Webåº”ç”¨ç«¯å£ï¼ˆåŒ…å«MCPæœåŠ¡å™¨ï¼Œé€šè¿‡/mcpè·¯å¾„è®¿é—®ï¼‰\n    environment:\n      # APIå¯†é’¥é…ç½®\n      - VITE_OPENAI_API_KEY=your_openai_key\n      - VITE_GEMINI_API_KEY=your_gemini_key\n      # è®¿é—®æ§åˆ¶ï¼ˆå¯é€‰ï¼‰\n      - ACCESS_USERNAME=admin\n      - ACCESS_PASSWORD=your_password\n```\n</details>\n\n### 7. MCP Server ä½¿ç”¨è¯´æ˜\n<details>\n<summary>ç‚¹å‡»æŸ¥çœ‹ MCP Server ä½¿ç”¨è¯´æ˜</summary>\n\nPrompt Optimizer ç°åœ¨æ”¯æŒ Model Context Protocol (MCP) åè®®ï¼Œå¯ä»¥ä¸ Claude Desktop ç­‰æ”¯æŒ MCP çš„ AI åº”ç”¨é›†æˆã€‚\n\nå½“é€šè¿‡ Docker è¿è¡Œæ—¶ï¼ŒMCP Server ä¼šè‡ªåŠ¨å¯åŠ¨ï¼Œå¹¶å¯é€šè¿‡ `http://ip:port/mcp` è®¿é—®ã€‚\n\n#### ç¯å¢ƒå˜é‡é…ç½®\n\nMCP Server éœ€è¦é…ç½® API å¯†é’¥æ‰èƒ½æ­£å¸¸å·¥ä½œã€‚ä¸»è¦çš„ MCP ä¸“å±é…ç½®ï¼š\n\n```bash\n# MCP æœåŠ¡å™¨é…ç½®\nMCP_DEFAULT_MODEL_PROVIDER=openai  # å¯é€‰å€¼ï¼šopenai, gemini, deepseek, siliconflow, zhipu, custom\nMCP_LOG_LEVEL=info                 # æ—¥å¿—çº§åˆ«\n```\n\n#### Docker ç¯å¢ƒä¸‹ä½¿ç”¨ MCP\n\nåœ¨ Docker ç¯å¢ƒä¸­ï¼ŒMCP Server ä¼šä¸ Web åº”ç”¨ä¸€èµ·è¿è¡Œï¼Œæ‚¨å¯ä»¥é€šè¿‡ Web åº”ç”¨çš„ç›¸åŒç«¯å£è®¿é—® MCP æœåŠ¡ï¼Œè·¯å¾„ä¸º `/mcp`ã€‚\n\nä¾‹å¦‚ï¼Œå¦‚æœæ‚¨å°†å®¹å™¨çš„ 80 ç«¯å£æ˜ å°„åˆ°ä¸»æœºçš„ 8081 ç«¯å£ï¼š\n```bash\ndocker run -d -p 8081:80 \\\n  -e VITE_OPENAI_API_KEY=your-openai-key \\\n  -e MCP_DEFAULT_MODEL_PROVIDER=openai \\\n  --name prompt-optimizer \\\n  linshen/prompt-optimizer\n```\n\né‚£ä¹ˆ MCP Server å°†å¯ä»¥é€šè¿‡ `http://localhost:8081/mcp` è®¿é—®ã€‚\n\n#### Claude Desktop é›†æˆç¤ºä¾‹\n\nè¦åœ¨ Claude Desktop ä¸­ä½¿ç”¨ Prompt Optimizerï¼Œæ‚¨éœ€è¦åœ¨ Claude Desktop çš„é…ç½®æ–‡ä»¶ä¸­æ·»åŠ æœåŠ¡é…ç½®ã€‚\n\n1. æ‰¾åˆ° Claude Desktop çš„é…ç½®ç›®å½•ï¼š\n   - Windows: `%APPDATA%\\Claude\\services`\n   - macOS: `~/Library/Application Support/Claude/services`\n   - Linux: `~/.config/Claude/services`\n\n2. ç¼–è¾‘æˆ–åˆ›å»º `services.json` æ–‡ä»¶ï¼Œæ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š\n\n```json\n{\n  \"services\": [\n    {\n      \"name\": \"Prompt Optimizer\",\n      \"url\": \"http://localhost:8081/mcp\"\n    }\n  ]\n}\n```\n\nè¯·ç¡®ä¿å°† `localhost:8081` æ›¿æ¢ä¸ºæ‚¨å®é™…éƒ¨ç½² Prompt Optimizer çš„åœ°å€å’Œç«¯å£ã€‚\n\n#### å¯ç”¨å·¥å…·\n\n- **optimize-user-prompt**: ä¼˜åŒ–ç”¨æˆ·æç¤ºè¯ä»¥æé«˜ LLM æ€§èƒ½\n- **optimize-system-prompt**: ä¼˜åŒ–ç³»ç»Ÿæç¤ºè¯ä»¥æé«˜ LLM æ€§èƒ½\n- **iterate-prompt**: å¯¹å·²ç»æˆç†Ÿ/å®Œå–„çš„æç¤ºè¯è¿›è¡Œå®šå‘è¿­ä»£ä¼˜åŒ–\n\næ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ [MCP æœåŠ¡å™¨ç”¨æˆ·æŒ‡å—](docs/user/mcp-server.md)ã€‚\n</details>\n\n## âš™ï¸ APIå¯†é’¥é…ç½®\n\n<details>\n<summary>ç‚¹å‡»æŸ¥çœ‹APIå¯†é’¥é…ç½®æ–¹æ³•</summary>\n\n### æ–¹å¼ä¸€ï¼šé€šè¿‡ç•Œé¢é…ç½®ï¼ˆæ¨èï¼‰\n1. ç‚¹å‡»ç•Œé¢å³ä¸Šè§’çš„\"âš™ï¸è®¾ç½®\"æŒ‰é’®\n2. é€‰æ‹©\"æ¨¡å‹ç®¡ç†\"é€‰é¡¹å¡\n3. ç‚¹å‡»éœ€è¦é…ç½®çš„æ¨¡å‹ï¼ˆå¦‚OpenAIã€Geminiã€DeepSeekç­‰ï¼‰\n4. åœ¨å¼¹å‡ºçš„é…ç½®æ¡†ä¸­è¾“å…¥å¯¹åº”çš„APIå¯†é’¥\n5. ç‚¹å‡»\"ä¿å­˜\"å³å¯\n\næ”¯æŒçš„æ¨¡å‹ï¼šOpenAIã€Geminiã€DeepSeekã€Zhipuæ™ºè°±ã€SiliconFlowã€è‡ªå®šä¹‰APIï¼ˆOpenAIå…¼å®¹æ¥å£ï¼‰\n\né™¤äº†APIå¯†é’¥ï¼Œæ‚¨è¿˜å¯ä»¥åœ¨æ¨¡å‹é…ç½®ç•Œé¢ä¸ºæ¯ä¸ªæ¨¡å‹å•ç‹¬è®¾ç½®é«˜çº§LLMå‚æ•°ã€‚è¿™äº›å‚æ•°é€šè¿‡ä¸€ä¸ªåä¸º `llmParams` çš„å­—æ®µè¿›è¡Œé…ç½®ï¼Œå®ƒå…è®¸æ‚¨ä»¥é”®å€¼å¯¹çš„å½¢å¼æŒ‡å®šLLM SDKæ”¯æŒçš„ä»»ä½•å‚æ•°ï¼Œä»è€Œæ›´ç²¾ç»†åœ°æ§åˆ¶æ¨¡å‹è¡Œä¸ºã€‚\n\n**é«˜çº§LLMå‚æ•°é…ç½®ç¤ºä¾‹ï¼š**\n- **OpenAI/å…¼å®¹API**: `{\"temperature\": 0.7, \"max_tokens\": 4096, \"timeout\": 60000}`\n- **Gemini**: `{\"temperature\": 0.8, \"maxOutputTokens\": 2048, \"topP\": 0.95}`\n- **DeepSeek**: `{\"temperature\": 0.5, \"top_p\": 0.9, \"frequency_penalty\": 0.1}`\n\næœ‰å…³ `llmParams` çš„æ›´è¯¦ç»†è¯´æ˜å’Œé…ç½®æŒ‡å—ï¼Œè¯·å‚é˜… [LLMå‚æ•°é…ç½®æŒ‡å—](docs/developer/llm-params-guide.md)ã€‚\n\n### æ–¹å¼äºŒï¼šé€šè¿‡ç¯å¢ƒå˜é‡é…ç½®\nDockeréƒ¨ç½²æ—¶é€šè¿‡ `-e` å‚æ•°é…ç½®ç¯å¢ƒå˜é‡ï¼š\n\n```bash\n-e VITE_OPENAI_API_KEY=your_key\n-e VITE_GEMINI_API_KEY=your_key\n-e VITE_DEEPSEEK_API_KEY=your_key\n-e VITE_ZHIPU_API_KEY=your_key\n-e VITE_SILICONFLOW_API_KEY=your_key\n\n# å¤šè‡ªå®šä¹‰æ¨¡å‹é…ç½®ï¼ˆæ”¯æŒæ— é™æ•°é‡ï¼‰\n-e VITE_CUSTOM_API_KEY_ollama=dummy_key\n-e VITE_CUSTOM_API_BASE_URL_ollama=http://localhost:11434/v1\n-e VITE_CUSTOM_API_MODEL_ollama=qwen2.5:7b\n```\n\n> ğŸ“– **è¯¦ç»†é…ç½®æŒ‡å—**: æŸ¥çœ‹ [å¤šè‡ªå®šä¹‰æ¨¡å‹é…ç½®æ–‡æ¡£](./docs/user/multi-custom-models.md) äº†è§£å®Œæ•´çš„é…ç½®æ–¹æ³•å’Œé«˜çº§ç”¨æ³•\n\n</details>\n\n## æœ¬åœ°å¼€å‘\nè¯¦ç»†æ–‡æ¡£å¯æŸ¥çœ‹ [å¼€å‘æ–‡æ¡£](dev.md)\n\n<details>\n<summary>ç‚¹å‡»æŸ¥çœ‹æœ¬åœ°å¼€å‘å‘½ä»¤</summary>\n\n```bash\n# 1. å…‹éš†é¡¹ç›®\ngit clone https://github.com/linshenkx/prompt-optimizer.git\ncd prompt-optimizer\n\n# 2. å®‰è£…ä¾èµ–\npnpm install\n\n# 3. å¯åŠ¨å¼€å‘æœåŠ¡\npnpm dev               # ä¸»å¼€å‘å‘½ä»¤ï¼šæ„å»ºcore/uiå¹¶è¿è¡Œwebåº”ç”¨\npnpm dev:web          # ä»…è¿è¡Œwebåº”ç”¨\npnpm dev:fresh        # å®Œæ•´é‡ç½®å¹¶é‡æ–°å¯åŠ¨å¼€å‘ç¯å¢ƒ\n```\n</details>\n\n## ğŸ—ºï¸ å¼€å‘è·¯çº¿\n\n- [x] åŸºç¡€åŠŸèƒ½å¼€å‘\n- [x] Webåº”ç”¨å‘å¸ƒ\n- [x] Chromeæ’ä»¶å‘å¸ƒ\n- [x] å›½é™…åŒ–æ”¯æŒ\n- [x] æ”¯æŒç³»ç»Ÿæç¤ºè¯ä¼˜åŒ–å’Œç”¨æˆ·æç¤ºè¯ä¼˜åŒ–\n- [x] æ¡Œé¢åº”ç”¨å‘å¸ƒ\n- [x] MCPæœåŠ¡å‘å¸ƒ\n- [x] é«˜çº§æ¨¡å¼ï¼šå˜é‡ç®¡ç†ã€ä¸Šä¸‹æ–‡æµ‹è¯•ã€å·¥å…·è°ƒç”¨\n- [x] å›¾åƒç”Ÿæˆï¼šæ–‡ç”Ÿå›¾ï¼ˆT2Iï¼‰å’Œå›¾ç”Ÿå›¾ï¼ˆI2Iï¼‰æ”¯æŒ\n- [ ] æ”¯æŒå·¥ä½œåŒº/é¡¹ç›®ç®¡ç†\n- [ ] æ”¯æŒæç¤ºè¯æ”¶è—å’Œæ¨¡æ¿ç®¡ç†\n\nè¯¦ç»†çš„é¡¹ç›®çŠ¶æ€å¯æŸ¥çœ‹ [é¡¹ç›®çŠ¶æ€æ–‡æ¡£](docs/project-status.md)\n\n## ğŸ“– ç›¸å…³æ–‡æ¡£\n\n- [æ–‡æ¡£ç´¢å¼•](docs/README.md) - æ‰€æœ‰æ–‡æ¡£çš„ç´¢å¼•\n- [æŠ€æœ¯å¼€å‘æŒ‡å—](docs/developer/technical-development-guide.md) - æŠ€æœ¯æ ˆå’Œå¼€å‘è§„èŒƒ\n- [LLMå‚æ•°é…ç½®æŒ‡å—](docs/developer/llm-params-guide.md) - é«˜çº§LLMå‚æ•°é…ç½®è¯¦ç»†è¯´æ˜\n- [é¡¹ç›®ç»“æ„](docs/developer/project-structure.md) - è¯¦ç»†çš„é¡¹ç›®ç»“æ„è¯´æ˜\n- [é¡¹ç›®çŠ¶æ€](docs/project/project-status.md) - å½“å‰è¿›åº¦å’Œè®¡åˆ’\n- [äº§å“éœ€æ±‚](docs/project/prd.md) - äº§å“éœ€æ±‚æ–‡æ¡£\n- [Verceléƒ¨ç½²æŒ‡å—](docs/user/deployment/vercel.md) - Verceléƒ¨ç½²è¯¦ç»†è¯´æ˜\n\n\n## Star History\n\n<a href=\"https://star-history.com/#linshenkx/prompt-optimizer&Date\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=linshenkx/prompt-optimizer&type=Date&theme=dark\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=linshenkx/prompt-optimizer&type=Date\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=linshenkx/prompt-optimizer&type=Date\" />\n </picture>\n</a>\n\n## å¸¸è§é—®é¢˜\n\n<details>\n<summary>ç‚¹å‡»æŸ¥çœ‹å¸¸è§é—®é¢˜è§£ç­”</summary>\n\n### APIè¿æ¥é—®é¢˜\n\n#### Q1: ä¸ºä»€ä¹ˆé…ç½®å¥½APIå¯†é’¥åä»ç„¶æ— æ³•è¿æ¥åˆ°æ¨¡å‹æœåŠ¡ï¼Ÿ\n**A**: å¤§å¤šæ•°è¿æ¥å¤±è´¥æ˜¯ç”±**è·¨åŸŸé—®é¢˜**ï¼ˆCORSï¼‰å¯¼è‡´çš„ã€‚ç”±äºæœ¬é¡¹ç›®æ˜¯çº¯å‰ç«¯åº”ç”¨ï¼Œæµè§ˆå™¨å‡ºäºå®‰å…¨è€ƒè™‘ä¼šé˜»æ­¢ç›´æ¥è®¿é—®ä¸åŒæºçš„APIæœåŠ¡ã€‚æ¨¡å‹æœåŠ¡å¦‚æœªæ­£ç¡®é…ç½®CORSç­–ç•¥ï¼Œä¼šæ‹’ç»æ¥è‡ªæµè§ˆå™¨çš„ç›´æ¥è¯·æ±‚ã€‚\n\n#### Q2: å¦‚ä½•è§£å†³æœ¬åœ°Ollamaçš„è¿æ¥é—®é¢˜ï¼Ÿ\n**A**: Ollamaå®Œå…¨æ”¯æŒOpenAIæ ‡å‡†æ¥å£ï¼Œåªéœ€é…ç½®æ­£ç¡®çš„è·¨åŸŸç­–ç•¥ï¼š\n1. è®¾ç½®ç¯å¢ƒå˜é‡ `OLLAMA_ORIGINS=*` å…è®¸ä»»æ„æ¥æºçš„è¯·æ±‚\n2. å¦‚ä»æœ‰é—®é¢˜ï¼Œè®¾ç½® `OLLAMA_HOST=0.0.0.0:11434` ç›‘å¬ä»»æ„IPåœ°å€\n\n#### Q3: å¦‚ä½•è§£å†³å•†ä¸šAPIï¼ˆå¦‚Nvidiaçš„DS APIã€å­—èŠ‚è·³åŠ¨çš„ç«å±±APIï¼‰çš„è·¨åŸŸé—®é¢˜ï¼Ÿ\n**A**: è¿™äº›å¹³å°é€šå¸¸æœ‰ä¸¥æ ¼çš„è·¨åŸŸé™åˆ¶ï¼Œæ¨èä»¥ä¸‹è§£å†³æ–¹æ¡ˆï¼š\n\n1. **ä½¿ç”¨æ¡Œé¢ç‰ˆåº”ç”¨**ï¼ˆæœ€æ¨èï¼‰\n   - æ¡Œé¢åº”ç”¨ä½œä¸ºåŸç”Ÿåº”ç”¨ï¼Œå®Œå…¨æ²¡æœ‰è·¨åŸŸé™åˆ¶\n   - å¯ä»¥ç›´æ¥è¿æ¥ä»»ä½•APIæœåŠ¡ï¼ŒåŒ…æ‹¬æœ¬åœ°éƒ¨ç½²çš„æ¨¡å‹\n   - æä¾›æœ€å®Œæ•´ã€æœ€ç¨³å®šçš„åŠŸèƒ½ä½“éªŒ\n   - ä» [GitHub Releases](https://github.com/linshenkx/prompt-optimizer/releases) ä¸‹è½½\n\n2. **ä½¿ç”¨è‡ªéƒ¨ç½²çš„APIä¸­è½¬æœåŠ¡**ï¼ˆä¸“ä¸šæ–¹æ¡ˆï¼‰\n   - éƒ¨ç½²å¦‚OneAPIã€NewAPIç­‰å¼€æºAPIèšåˆ/ä»£ç†å·¥å…·\n   - åœ¨è®¾ç½®ä¸­é…ç½®ä¸ºè‡ªå®šä¹‰APIç«¯ç‚¹\n   - è¯·æ±‚æµå‘ï¼šæµè§ˆå™¨â†’ä¸­è½¬æœåŠ¡â†’æ¨¡å‹æœåŠ¡æä¾›å•†\n   - å®Œå…¨æ§åˆ¶å®‰å…¨ç­–ç•¥å’Œè®¿é—®æƒé™\n\n**æ³¨æ„**ï¼šWebç‰ˆï¼ˆåŒ…æ‹¬åœ¨çº¿ç‰ˆã€Verceléƒ¨ç½²ã€Dockeréƒ¨ç½²ï¼‰éƒ½æ˜¯çº¯å‰ç«¯åº”ç”¨ï¼Œéƒ½ä¼šå—åˆ°æµè§ˆå™¨CORSé™åˆ¶ã€‚åªæœ‰æ¡Œé¢ç‰ˆæˆ–ä½¿ç”¨APIä¸­è½¬æœåŠ¡æ‰èƒ½è§£å†³è·¨åŸŸé—®é¢˜ã€‚\n\n#### Q4: æˆ‘å·²æ­£ç¡®é…ç½®æœ¬åœ°æ¨¡å‹ï¼ˆå¦‚Ollamaï¼‰çš„è·¨åŸŸç­–ç•¥ï¼Œä¸ºä»€ä¹ˆä½¿ç”¨åœ¨çº¿ç‰ˆä¾ç„¶æ— æ³•è¿æ¥ï¼Ÿ\n**A**: è¿™æ˜¯ç”±æµè§ˆå™¨çš„**æ··åˆå†…å®¹ï¼ˆMixed Contentï¼‰å®‰å…¨ç­–ç•¥**å¯¼è‡´çš„ã€‚å‡ºäºå®‰å…¨è€ƒè™‘ï¼Œæµè§ˆå™¨ä¼šé˜»æ­¢å®‰å…¨çš„HTTPSé¡µé¢ï¼ˆå¦‚åœ¨çº¿ç‰ˆï¼‰å‘ä¸å®‰å…¨çš„HTTPåœ°å€ï¼ˆå¦‚æ‚¨çš„æœ¬åœ°OllamaæœåŠ¡ï¼‰å‘é€è¯·æ±‚ã€‚\n\n**è§£å†³æ–¹æ¡ˆ**ï¼š\nä¸ºäº†ç»•è¿‡æ­¤é™åˆ¶ï¼Œæ‚¨éœ€è¦è®©åº”ç”¨å’ŒAPIå¤„äºåŒä¸€ç§åè®®ä¸‹ï¼ˆä¾‹å¦‚ï¼Œéƒ½æ˜¯HTTPï¼‰ã€‚æ¨èä»¥ä¸‹æ–¹å¼ï¼š\n1. **ä½¿ç”¨æ¡Œé¢ç‰ˆ**ï¼šæ¡Œé¢åº”ç”¨æ²¡æœ‰æµè§ˆå™¨é™åˆ¶ï¼Œæ˜¯è¿æ¥æœ¬åœ°æ¨¡å‹æœ€ç¨³å®šå¯é çš„æ–¹å¼\n2. **ä½¿ç”¨Dockeréƒ¨ç½²ï¼ˆHTTPï¼‰**ï¼šé€šè¿‡ `http://localhost:8081` è®¿é—®ï¼Œä¸æœ¬åœ°Ollamaéƒ½æ˜¯HTTP\n3. **ä½¿ç”¨Chromeæ’ä»¶**ï¼šæ’ä»¶åœ¨æŸäº›æƒ…å†µä¸‹ä¹Ÿå¯ä»¥ç»•è¿‡éƒ¨åˆ†å®‰å…¨é™åˆ¶\n\n### macOS æ¡Œé¢åº”ç”¨é—®é¢˜\n\n#### Q5: macOS æ‰“å¼€åº”ç”¨æ—¶æç¤ºã€Œå·²æŸåã€æˆ–ã€Œæ— æ³•éªŒè¯å¼€å‘è€…ã€æ€ä¹ˆåŠï¼Ÿ\n**A**: è¿™æ˜¯å› ä¸ºåº”ç”¨æœªç»è¿‡ Apple ç­¾åè®¤è¯ã€‚ç”±äº Apple å¼€å‘è€…è´¦å·è´¹ç”¨è¾ƒé«˜ï¼Œç›®å‰æ¡Œé¢åº”ç”¨æš‚æœªè¿›è¡Œç­¾åã€‚\n\n**è§£å†³æ–¹æ¡ˆ**ï¼š\nåœ¨ç»ˆç«¯ä¸­æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ç§»é™¤å®‰å…¨éš”ç¦»å±æ€§ï¼š\n\n```bash\n# å¯¹äºå·²å®‰è£…çš„åº”ç”¨\nxattr -rd com.apple.quarantine /Applications/PromptOptimizer.app\n\n# å¯¹äºä¸‹è½½çš„ .dmg æ–‡ä»¶ï¼ˆå®‰è£…å‰æ‰§è¡Œï¼‰\nxattr -rd com.apple.quarantine ~/Downloads/PromptOptimizer-*.dmg\n```\n\næ‰§è¡Œåé‡æ–°æ‰“å¼€åº”ç”¨å³å¯æ­£å¸¸ä½¿ç”¨ã€‚\n\n</details>\n\n\n## ğŸ¤ å‚ä¸è´¡çŒ®\n\n<details>\n<summary>ç‚¹å‡»æŸ¥çœ‹è´¡çŒ®æŒ‡å—</summary>\n\n1. Fork æœ¬ä»“åº“\n2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)\n3. æäº¤æ›´æ”¹ (`git commit -m 'æ·»åŠ æŸä¸ªç‰¹æ€§'`)\n4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)\n5. æäº¤ Pull Request\n\næç¤ºï¼šä½¿ç”¨cursorå·¥å…·å¼€å‘æ—¶ï¼Œå»ºè®®åœ¨æäº¤å‰:\n1. ä½¿ç”¨\"code_review\"è§„åˆ™è¿›è¡Œä»£ç å®¡æŸ¥\n2. æŒ‰ç…§å®¡æŸ¥æŠ¥å‘Šæ ¼å¼æ£€æŸ¥:\n   - å˜æ›´çš„æ•´ä½“ä¸€è‡´æ€§\n   - ä»£ç è´¨é‡å’Œå®ç°æ–¹å¼\n   - æµ‹è¯•è¦†ç›–æƒ…å†µ\n   - æ–‡æ¡£å®Œå–„ç¨‹åº¦\n3. æ ¹æ®å®¡æŸ¥ç»“æœè¿›è¡Œä¼˜åŒ–åå†æäº¤\n\n</details>\n\n## ğŸ‘ è´¡çŒ®è€…åå•\n\næ„Ÿè°¢æ‰€æœ‰ä¸ºé¡¹ç›®åšå‡ºè´¡çŒ®çš„å¼€å‘è€…ï¼\n\n<a href=\"https://github.com/linshenkx/prompt-optimizer/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=linshenkx/prompt-optimizer\" alt=\"è´¡çŒ®è€…\" />\n</a>\n\n## ğŸ“„ å¼€æºåè®®\n\næœ¬é¡¹ç›®é‡‡ç”¨ [AGPL-3.0](LICENSE) åè®®å¼€æºã€‚\n\n**ç®€å•æ¥è¯´**ï¼šä½ å¯ä»¥è‡ªç”±ä½¿ç”¨ã€ä¿®æ”¹å’Œå•†ç”¨æœ¬é¡¹ç›®ï¼Œä½†å¦‚æœä½ æŠŠå®ƒåšæˆç½‘ç«™æˆ–æœåŠ¡ç»™åˆ«äººç”¨ï¼Œéœ€è¦å…¬å¼€ä½ çš„æºä»£ç ã€‚\n\n<details>\n<summary>ğŸ‘‰ ç‚¹å‡»æŸ¥çœ‹è¯¦ç»†è¯´æ˜</summary>\n\n**å…è®¸åšä»€ä¹ˆï¼š**\n- âœ… ä¸ªäººä½¿ç”¨ã€å­¦ä¹ ã€ç ”ç©¶\n- âœ… å…¬å¸å†…éƒ¨ä½¿ç”¨ï¼ˆä¸å¯¹å¤–æä¾›æœåŠ¡ï¼‰\n- âœ… ä¿®æ”¹ä»£ç å¹¶ç”¨äºå•†ä¸šé¡¹ç›®\n- âœ… æ”¶è´¹é”€å”®æˆ–æä¾›æœåŠ¡\n\n**éœ€è¦åšä»€ä¹ˆï¼š**\n- ğŸ“– å¦‚æœåˆ†å‘è½¯ä»¶æˆ–æä¾›ç½‘ç»œæœåŠ¡ï¼Œå¿…é¡»å…¬å¼€æºä»£ç \n- ğŸ“ ä¿ç•™åŸä½œè€…çš„ç‰ˆæƒå£°æ˜\n\n**ä¸€å¥è¯æ ¸å¿ƒ**ï¼šå¯ä»¥å•†ç”¨ï¼Œä½†ä¸èƒ½é—­æºã€‚\n\n</details>\n\n---\n\nå¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·è€ƒè™‘ç»™å®ƒä¸€ä¸ª Star â­ï¸\n\n## ğŸ‘¥ è”ç³»æˆ‘ä»¬\n\n- æäº¤ Issue\n- å‘èµ· Pull Request\n- åŠ å…¥è®¨è®ºç»„",
      "stars_today": 326
    },
    {
      "id": 1104535633,
      "name": "Antigravity-Manager",
      "full_name": "lbjlaq/Antigravity-Manager",
      "description": "Professional Antigravity Account Manager & Switcher. One-click seamless account switching for Antigravity Tools. Built with Tauri v2 + React (Rust).ä¸“ä¸šçš„ Antigravity è´¦å·ç®¡ç†ä¸åˆ‡æ¢å·¥å…·ã€‚ä¸º Antigravity æä¾›ä¸€é”®æ— ç¼è´¦å·åˆ‡æ¢åŠŸèƒ½ã€‚",
      "html_url": "https://github.com/lbjlaq/Antigravity-Manager",
      "stars": 21703,
      "forks": 2462,
      "language": "Rust",
      "topics": [
        "account-manager",
        "antigravity"
      ],
      "created_at": "2025-11-26T10:47:13Z",
      "updated_at": "2026-02-07T02:31:35Z",
      "pushed_at": "2026-02-06T12:50:24Z",
      "open_issues": 1086,
      "owner": {
        "login": "lbjlaq",
        "avatar_url": "https://avatars.githubusercontent.com/u/22748003?v=4"
      },
      "readme": "# Antigravity Tools ğŸš€\n> ä¸“ä¸šçš„ AI è´¦å·ç®¡ç†ä¸åè®®åä»£ç³»ç»Ÿ (v4.1.7)\n<div align=\"center\">\n  <img src=\"public/icon.png\" alt=\"Antigravity Logo\" width=\"120\" height=\"120\" style=\"border-radius: 24px; box-shadow: 0 10px 30px rgba(0,0,0,0.15);\">\n\n  <h3>æ‚¨çš„ä¸ªäººé«˜æ€§èƒ½ AI è°ƒåº¦ç½‘å…³</h3>\n  <p>ä¸ä»…ä»…æ˜¯è´¦å·ç®¡ç†ï¼Œæ›´æ˜¯æ‰“ç ´ API è°ƒç”¨å£å’çš„ç»ˆæè§£å†³æ–¹æ¡ˆã€‚</p>\n  \n  <p>\n    <a href=\"https://github.com/lbjlaq/Antigravity-Manager\">\n      <img src=\"https://img.shields.io/badge/Version-4.1.7-blue?style=flat-square\" alt=\"Version\">\n    </a>\n    <img src=\"https://img.shields.io/badge/Tauri-v2-orange?style=flat-square\" alt=\"Tauri\">\n    <img src=\"https://img.shields.io/badge/Backend-Rust-red?style=flat-square\" alt=\"Rust\">\n    <img src=\"https://img.shields.io/badge/Frontend-React-61DAFB?style=flat-square\" alt=\"React\">\n    <img src=\"https://img.shields.io/badge/License-CC--BY--NC--SA--4.0-lightgrey?style=flat-square\" alt=\"License\">\n  </p>\n\n  <p>\n    <a href=\"#-æ ¸å¿ƒåŠŸèƒ½\">æ ¸å¿ƒåŠŸèƒ½</a> â€¢ \n    <a href=\"#-ç•Œé¢å¯¼è§ˆ\">ç•Œé¢å¯¼è§ˆ</a> â€¢ \n    <a href=\"#-æŠ€æœ¯æ¶æ„\">æŠ€æœ¯æ¶æ„</a> â€¢ \n    <a href=\"#-å®‰è£…æŒ‡å—\">å®‰è£…æŒ‡å—</a> â€¢ \n    <a href=\"#-å¿«é€Ÿæ¥å…¥\">å¿«é€Ÿæ¥å…¥</a>\n  </p>\n\n  <p>\n    <strong>ç®€ä½“ä¸­æ–‡</strong> | \n    <a href=\"./README_EN.md\">English</a>\n  </p>\n</div>\n\n---\n\n**Antigravity Tools** æ˜¯ä¸€ä¸ªä¸“ä¸ºå¼€å‘è€…å’Œ AI çˆ±å¥½è€…è®¾è®¡çš„å…¨åŠŸèƒ½æ¡Œé¢åº”ç”¨ã€‚å®ƒå°†å¤šè´¦å·ç®¡ç†ã€åè®®è½¬æ¢å’Œæ™ºèƒ½è¯·æ±‚è°ƒåº¦å®Œç¾ç»“åˆï¼Œä¸ºæ‚¨æä¾›ä¸€ä¸ªç¨³å®šã€æé€Ÿä¸”æˆæœ¬ä½å»‰çš„ **æœ¬åœ° AI ä¸­è½¬ç«™**ã€‚\n\né€šè¿‡æœ¬åº”ç”¨ï¼Œæ‚¨å¯ä»¥å°†å¸¸è§çš„ Web ç«¯ Session (Google/Anthropic) è½¬åŒ–ä¸ºæ ‡å‡†åŒ–çš„ API æ¥å£ï¼Œæ¶ˆé™¤ä¸åŒå‚å•†é—´çš„åè®®é¸¿æ²Ÿã€‚\n\n## ğŸ’– èµåŠ©å•† (Sponsors)\n\n| èµåŠ©å•† (Sponsor) | ç®€ä»‹ (Description) |\n| :---: | :--- |\n| <img src=\"docs/images/packycode_logo.png\" width=\"200\" alt=\"PackyCode Logo\"> | æ„Ÿè°¢ **PackyCode** å¯¹æœ¬é¡¹ç›®çš„èµåŠ©ï¼PackyCode æ˜¯ä¸€å®¶å¯é é«˜æ•ˆçš„ API ä¸­è½¬æœåŠ¡å•†ï¼Œæä¾› Claude Codeã€Codexã€Gemini ç­‰å¤šç§æœåŠ¡çš„ä¸­è½¬ã€‚PackyCode ä¸ºæœ¬é¡¹ç›®çš„ç”¨æˆ·æä¾›äº†ç‰¹åˆ«ä¼˜æƒ ï¼šä½¿ç”¨[æ­¤é“¾æ¥](https://www.packyapi.com/register?aff=Ctrler)æ³¨å†Œï¼Œå¹¶åœ¨å……å€¼æ—¶è¾“å…¥ **â€œCtrlerâ€** ä¼˜æƒ ç å³å¯äº«å— **ä¹æŠ˜ä¼˜æƒ **ã€‚ |\n| <img src=\"docs/images/AICodeMirror.jpg\" width=\"200\" alt=\"AICodeMirror Logo\"> | æ„Ÿè°¢ AICodeMirror èµåŠ©äº†æœ¬é¡¹ç›®ï¼AICodeMirror æä¾› Claude Code / Codex / Gemini CLI å®˜æ–¹é«˜ç¨³å®šä¸­è½¬æœåŠ¡ï¼Œæ”¯æŒä¼ä¸šçº§é«˜å¹¶å‘ã€æé€Ÿå¼€ç¥¨ã€7Ã—24 ä¸“å±æŠ€æœ¯æ”¯æŒã€‚ Claude Code / Codex / Gemini å®˜æ–¹æ¸ é“ä½è‡³ 3.8 / 0.2 / 0.9 æŠ˜ï¼Œå……å€¼æ›´æœ‰æŠ˜ä¸ŠæŠ˜ï¼AICodeMirror ä¸º Antigravity-Manager çš„ç”¨æˆ·æä¾›äº†ç‰¹åˆ«ç¦åˆ©ï¼Œé€šè¿‡[æ­¤é“¾æ¥](https://www.aicodemirror.com/register?invitecode=MV5XUM)æ³¨å†Œçš„ç”¨æˆ·ï¼Œå¯äº«å—é¦–å……8æŠ˜ï¼Œä¼ä¸šå®¢æˆ·æœ€é«˜å¯äº« 7.5 æŠ˜ï¼ |\n\n### â˜• æ”¯æŒé¡¹ç›® (Support)\n\nå¦‚æœæ‚¨è§‰å¾—æœ¬é¡¹ç›®å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ï¼Œæ¬¢è¿æ‰“èµä½œè€…ï¼\n\n<a href=\"https://www.buymeacoffee.com/Ctrler\" target=\"_blank\"><img src=\"https://cdn.buymeacoffee.com/buttons/v2/default-green.png\" alt=\"è¯·æˆ‘å–æ¯å’–å•¡\" style=\"height: 60px !important; width: 217px !important;\"></a>\n\n| æ”¯ä»˜å® (Alipay) | å¾®ä¿¡æ”¯ä»˜ (WeChat) | Buy Me a Coffee |\n| :---: | :---: | :---: |\n| ![Alipay](./docs/images/donate_alipay.png) | ![WeChat](./docs/images/donate_wechat.png) | ![Coffee](./docs/images/donate_coffee.png) |\n\n## ğŸŒŸ æ·±åº¦åŠŸèƒ½è§£æ (Detailed Features)\n\n### 1. ğŸ›ï¸ æ™ºèƒ½è´¦å·ä»ªè¡¨ç›˜ (Smart Dashboard)\n*   **å…¨å±€å®æ—¶ç›‘æ§**: ä¸€çœ¼æ´å¯Ÿæ‰€æœ‰è´¦å·çš„å¥åº·çŠ¶å†µï¼ŒåŒ…æ‹¬ Gemini Proã€Gemini Flashã€Claude ä»¥åŠ Gemini ç»˜å›¾çš„ **å¹³å‡å‰©ä½™é…é¢**ã€‚\n*   **æœ€ä½³è´¦å·æ¨è (Smart Recommendation)**: ç³»ç»Ÿä¼šæ ¹æ®å½“å‰æ‰€æœ‰è´¦å·çš„é…é¢å†—ä½™åº¦ï¼Œå®æ—¶ç®—æ³•ç­›é€‰å¹¶æ¨èâ€œæœ€ä½³è´¦å·â€ï¼Œæ”¯æŒ **ä¸€é”®åˆ‡æ¢**ã€‚\n*   **æ´»è·ƒè´¦å·å¿«ç…§**: ç›´è§‚æ˜¾ç¤ºå½“å‰æ´»è·ƒè´¦å·çš„å…·ä½“é…é¢ç™¾åˆ†æ¯”åŠæœ€ååŒæ­¥æ—¶é—´ã€‚\n\n### 2. ğŸ” å¼ºå¤§çš„è´¦å·ç®¡å®¶ (Account Management)\n*   **OAuth 2.0 æˆæƒï¼ˆè‡ªåŠ¨/æ‰‹åŠ¨ï¼‰**: æ·»åŠ è´¦å·æ—¶ä¼šæå‰ç”Ÿæˆå¯å¤åˆ¶çš„æˆæƒé“¾æ¥ï¼Œæ”¯æŒåœ¨ä»»æ„æµè§ˆå™¨å®Œæˆæˆæƒï¼›å›è°ƒæˆåŠŸååº”ç”¨ä¼šè‡ªåŠ¨å®Œæˆå¹¶ä¿å­˜ï¼ˆå¿…è¦æ—¶å¯ç‚¹å‡»â€œæˆ‘å·²æˆæƒï¼Œç»§ç»­â€æ‰‹åŠ¨æ”¶å°¾ï¼‰ã€‚\n*   **å¤šç»´åº¦å¯¼å…¥**: æ”¯æŒå•æ¡ Token å½•å…¥ã€JSON æ‰¹é‡å¯¼å…¥ï¼ˆå¦‚æ¥è‡ªå…¶ä»–å·¥å…·çš„å¤‡ä»½ï¼‰ï¼Œä»¥åŠä» V1 æ—§ç‰ˆæœ¬æ•°æ®åº“è‡ªåŠ¨çƒ­è¿ç§»ã€‚\n*   **ç½‘å…³çº§è§†å›¾**: æ”¯æŒâ€œåˆ—è¡¨â€ä¸â€œç½‘æ ¼â€åŒè§†å›¾åˆ‡æ¢ã€‚æä¾› 403 å°ç¦æ£€æµ‹ï¼Œè‡ªåŠ¨æ ‡æ³¨å¹¶è·³è¿‡æƒé™å¼‚å¸¸çš„è´¦å·ã€‚\n\n### 3. ğŸ”Œ åè®®è½¬æ¢ä¸ä¸­ç»§ (API Proxy)\n*   **å…¨åè®®é€‚é… (Multi-Sink)**:\n    *   **OpenAI æ ¼å¼**: æä¾› `/v1/chat/completions` ç«¯ç‚¹ï¼Œå…¼å®¹ 99% çš„ç°æœ‰ AI åº”ç”¨ã€‚\n    *   **Anthropic æ ¼å¼**: æä¾›åŸç”Ÿ `/v1/messages` æ¥å£ï¼Œæ”¯æŒ **Claude Code CLI** çš„å…¨åŠŸèƒ½ï¼ˆå¦‚æ€æ€ç»´é“¾ã€ç³»ç»Ÿæç¤ºè¯ï¼‰ã€‚\n    *   **Gemini æ ¼å¼**: æ”¯æŒ Google å®˜æ–¹ SDK ç›´æ¥è°ƒç”¨ã€‚\n*   **æ™ºèƒ½çŠ¶æ€è‡ªæ„ˆ**: å½“è¯·æ±‚é‡åˆ° `429 (Too Many Requests)` æˆ– `401 (Expire)` æ—¶ï¼Œåç«¯ä¼šæ¯«ç§’çº§è§¦å‘ **è‡ªåŠ¨é‡è¯•ä¸é™é»˜è½®æ¢**ï¼Œç¡®ä¿ä¸šåŠ¡ä¸ä¸­æ–­ã€‚\n\n### 4. ğŸ”€ æ¨¡å‹è·¯ç”±ä¸­å¿ƒ (Model Router)\n*   **ç³»åˆ—åŒ–æ˜ å°„**: æ‚¨å¯ä»¥å°†å¤æ‚çš„åŸå§‹æ¨¡å‹ ID å½’ç±»åˆ°â€œè§„æ ¼å®¶æ—â€ï¼ˆå¦‚å°†æ‰€æœ‰ GPT-4 è¯·æ±‚ç»Ÿä¸€è·¯ç”±åˆ° `gemini-3-pro-high`ï¼‰ã€‚\n*   **ä¸“å®¶çº§é‡å®šå‘**: æ”¯æŒè‡ªå®šä¹‰æ­£åˆ™è¡¨è¾¾å¼çº§æ¨¡å‹æ˜ å°„ï¼Œç²¾å‡†æ§åˆ¶æ¯ä¸€ä¸ªè¯·æ±‚çš„è½åœ°æ¨¡å‹ã€‚\n*   **æ™ºèƒ½åˆ†çº§è·¯ç”± (Tiered Routing)**: [æ–°] ç³»ç»Ÿæ ¹æ®è´¦å·ç±»å‹ï¼ˆUltra/Pro/Freeï¼‰å’Œé…é¢é‡ç½®é¢‘ç‡è‡ªåŠ¨ä¼˜å…ˆçº§æ’åºï¼Œä¼˜å…ˆæ¶ˆè€—é«˜é€Ÿé‡ç½®è´¦å·ï¼Œç¡®ä¿é«˜é¢‘è°ƒç”¨ä¸‹çš„æœåŠ¡ç¨³å®šæ€§ã€‚\n*   **åå°ä»»åŠ¡é™é»˜é™çº§**: [æ–°] è‡ªåŠ¨è¯†åˆ« Claude CLI ç­‰å·¥å…·ç”Ÿæˆçš„åå°è¯·æ±‚ï¼ˆå¦‚æ ‡é¢˜ç”Ÿæˆï¼‰ï¼Œæ™ºèƒ½é‡å®šå‘è‡³ Flash æ¨¡å‹ï¼Œä¿æŠ¤é«˜çº§æ¨¡å‹é…é¢ä¸è¢«æµªè´¹ã€‚\n\n### 5. ğŸ¨ å¤šæ¨¡æ€ä¸ Imagen 3 æ”¯æŒ\n*   **é«˜çº§ç”»è´¨æ§åˆ¶**: æ”¯æŒé€šè¿‡ OpenAI `size` (å¦‚ `1024x1024`, `16:9`) å‚æ•°è‡ªåŠ¨æ˜ å°„åˆ° Imagen 3 çš„ç›¸åº”è§„æ ¼ã€‚\n*   **è¶…å¼º Body æ”¯æŒ**: åç«¯æ”¯æŒé«˜è¾¾ **100MB** (å¯é…ç½®) çš„ Payloadï¼Œå¤„ç† 4K é«˜æ¸…å›¾è¯†åˆ«ç»°ç»°æœ‰ä½™ã€‚\n\n## ğŸ“¸ ç•Œé¢å¯¼è§ˆ (GUI Overview)\n\n| | |\n| :---: | :---: |\n| ![ä»ªè¡¨ç›˜ - å…¨å±€é…é¢ç›‘æ§ä¸ä¸€é”®åˆ‡æ¢](docs/images/dashboard-light.png) <br> ä»ªè¡¨ç›˜ | ![è´¦å·åˆ—è¡¨ - é«˜å¯†åº¦é…é¢å±•ç¤ºä¸ 403 æ™ºèƒ½æ ‡æ³¨](docs/images/accounts-light.png) <br> è´¦å·åˆ—è¡¨ |\n| ![å…³äºé¡µé¢ - å…³äº Antigravity Tools](docs/images/about-dark.png) <br> å…³äºé¡µé¢ | ![API åä»£ - æœåŠ¡æ§åˆ¶](docs/images/v3/proxy-settings.png) <br> API åä»£ |\n| ![ç³»ç»Ÿè®¾ç½® - é€šç”¨é…ç½®](docs/images/settings-dark.png) <br> ç³»ç»Ÿè®¾ç½® | |\n\n### ğŸ’¡ ä½¿ç”¨æ¡ˆä¾‹ (Usage Examples)\n\n| | |\n| :---: | :---: |\n| ![Claude Code è”ç½‘æœç´¢ - ç»“æ„åŒ–æ¥æºä¸å¼•æ–‡æ˜¾ç¤º](docs/images/usage/claude-code-search.png) <br> Claude Code è”ç½‘æœç´¢ | ![Cherry Studio æ·±åº¦é›†æˆ - åŸç”Ÿå›æ˜¾æœç´¢å¼•æ–‡ä¸æ¥æºé“¾æ¥](docs/images/usage/cherry-studio-citations.png) <br> Cherry Studio æ·±åº¦é›†æˆ |\n| ![Imagen 3 é«˜çº§ç»˜å›¾ - å®Œç¾è¿˜åŸ Prompt æ„å¢ƒä¸ç»†èŠ‚](docs/images/usage/image-gen-nebula.png) <br> Imagen 3 é«˜çº§ç»˜å›¾ | ![Kilo Code æ¥å…¥ - å¤šè´¦å·æé€Ÿè½®æ¢ä¸æ¨¡å‹ç©¿é€](docs/images/usage/kilo-code-integration.png) <br> Kilo Code æ¥å…¥ |\n\n## ğŸ—ï¸ æŠ€æœ¯æ¶æ„ (Architecture)\n\n```mermaid\ngraph TD\n    Client([å¤–éƒ¨åº”ç”¨: Claude Code/NextChat]) -->|OpenAI/Anthropic| Gateway[Antigravity Axum Server]\n    Gateway --> Middleware[ä¸­é—´ä»¶: é‰´æƒ/é™æµ/æ—¥å¿—]\n    Middleware --> Router[Model Router: ID æ˜ å°„]\n    Router --> Dispatcher[è´¦å·åˆ†å‘å™¨: è½®è¯¢/æƒé‡]\n    Dispatcher --> Mapper[åè®®è½¬æ¢å™¨: Request Mapper]\n    Mapper --> Upstream[ä¸Šæ¸¸è¯·æ±‚: Google/Anthropic API]\n    Upstream --> ResponseMapper[å“åº”è½¬æ¢å™¨: Response Mapper]\n    ResponseMapper --> Client\n```\n\n##  å®‰è£…æŒ‡å— (Installation)\n\n### é€‰é¡¹ A: ç»ˆç«¯å®‰è£… (macOS & Linux æ¨è)\n\n#### macOS \nå¦‚æœæ‚¨å·²å®‰è£… [Homebrew](https://brew.sh/)ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤å¿«é€Ÿå®‰è£…ï¼š\n\n```bash\n# 1. è®¢é˜…æœ¬ä»“åº“çš„ Tap\nbrew tap lbjlaq/antigravity-manager https://github.com/lbjlaq/Antigravity-Manager\n\n# 2. å®‰è£…åº”ç”¨\nbrew install --cask antigravity-tools\n```\n> **æç¤º**: å¦‚æœé‡åˆ°æƒé™é—®é¢˜ï¼Œå»ºè®®æ·»åŠ  `--no-quarantine` å‚æ•°ã€‚\n\n#### Arch Linux\næ‚¨å¯ä»¥é€‰æ‹©é€šè¿‡ä¸€é”®å®‰è£…è„šæœ¬æˆ– Homebrew è¿›è¡Œå®‰è£…ï¼š\n\n**æ–¹å¼ 1ï¼šä¸€é”®å®‰è£…è„šæœ¬ (æ¨è)**\n```bash\ncurl -sSL https://raw.githubusercontent.com/lbjlaq/Antigravity-Manager/main/deploy/arch/install.sh | bash\n```\n\n**æ–¹å¼ 2ï¼šé€šè¿‡ Homebrew** (å¦‚æœæ‚¨å·²å®‰è£… [Linuxbrew](https://sh.brew.sh/))\n```bash\nbrew tap lbjlaq/antigravity-manager https://github.com/lbjlaq/Antigravity-Manager\nbrew install --cask antigravity-tools\n```\n\n#### å…¶ä»– Linux å‘è¡Œç‰ˆ\nå®‰è£…åä¼šè‡ªåŠ¨å°† AppImage æ·»åŠ åˆ°äºŒè¿›åˆ¶è·¯å¾„å¹¶é…ç½®å¯æ‰§è¡Œæƒé™ã€‚\n\n### é€‰é¡¹ B: æ‰‹åŠ¨ä¸‹è½½\nå‰å¾€ [GitHub Releases](https://github.com/lbjlaq/Antigravity-Manager/releases) ä¸‹è½½å¯¹åº”ç³»ç»Ÿçš„åŒ…ï¼š\n*   **macOS**: `.dmg` (æ”¯æŒ Apple Silicon & Intel)\n*   **Windows**: `.msi` æˆ– ä¾¿æºç‰ˆ `.zip`\n*   **Linux**: `.deb` æˆ– `AppImage`\n\n### é€‰é¡¹ C: Docker éƒ¨ç½² (æ¨èç”¨äº NAS/æœåŠ¡å™¨)\nå¦‚æœæ‚¨å¸Œæœ›åœ¨å®¹å™¨åŒ–ç¯å¢ƒä¸­è¿è¡Œï¼Œæˆ‘ä»¬æä¾›äº†åŸç”Ÿçš„ Docker é•œåƒã€‚è¯¥é•œåƒå†…ç½®äº†å¯¹ v4.0.2 åŸç”Ÿ Headless æ¶æ„çš„æ”¯æŒï¼Œå¯è‡ªåŠ¨æ‰˜ç®¡å‰ç«¯é™æ€èµ„æºï¼Œå¹¶é€šè¿‡æµè§ˆå™¨ç›´æ¥è¿›è¡Œç®¡ç†ã€‚\n\n```bash\n# æ–¹å¼ 1: ç›´æ¥è¿è¡Œ (æ¨è)\n# - API_KEY: å¿…å¡«ã€‚ç”¨äºæ‰€æœ‰åè®®çš„ AI è¯·æ±‚é‰´å®šã€‚\n# - WEB_PASSWORD: å¯é€‰ã€‚ç”¨äºç®¡ç†åå°ç™»å½•ã€‚è‹¥ä¸è®¾ç½®åˆ™é»˜è®¤ä½¿ç”¨ API_KEYã€‚\ndocker run -d --name antigravity-manager \\\n  -p 8045:8045 \\\n  -e API_KEY=sk-your-api-key \\\n  -e WEB_PASSWORD=your-login-password \\\n  -e ABV_MAX_BODY_SIZE=104857600 \\\n  -v ~/.antigravity_tools:/root/.antigravity_tools \\\n  lbjlaq/antigravity-manager:latest\n\n# å¿˜è®°å¯†é’¥ï¼Ÿæ‰§è¡Œ docker logs antigravity-manager æˆ– grep -E '\"api_key\"|\"admin_password\"' ~/.antigravity_tools/gui_config.json\n\n#### ğŸ” é‰´æƒé€»è¾‘è¯´æ˜\n*   **åœºæ™¯ Aï¼šä»…è®¾ç½®äº† `API_KEY`**\n    - **Web ç™»å½•**ï¼šä½¿ç”¨ `API_KEY` è¿›å…¥åå°ã€‚\n    - **API è°ƒç”¨**ï¼šä½¿ç”¨ `API_KEY` è¿›è¡Œ AI è¯·æ±‚é‰´æƒã€‚\n*   **åœºæ™¯ Bï¼šåŒæ—¶è®¾ç½®äº† `API_KEY` å’Œ `WEB_PASSWORD` (æ¨è)**\n    - **Web ç™»å½•**ï¼š**å¿…é¡»**ä½¿ç”¨ `WEB_PASSWORD`ï¼Œä½¿ç”¨ API Key å°†è¢«æ‹’ç»ï¼ˆæ›´å®‰å…¨ï¼‰ã€‚\n    - **API è°ƒç”¨**ï¼šç»Ÿä¸€ä½¿ç”¨ `API_KEY`ã€‚è¿™æ ·æ‚¨å¯ä»¥å°† API Key åˆ†å‘ç»™æˆå‘˜ï¼Œè€Œä¿ç•™å¯†ç ä»…ä¾›ç®¡ç†å‘˜ä½¿ç”¨ã€‚\n\n#### ğŸ†™ æ—§ç‰ˆæœ¬å‡çº§æŒ‡å¼•\nå¦‚æœæ‚¨æ˜¯ä» v4.0.1 åŠæ›´æ—©ç‰ˆæœ¬å‡çº§ï¼Œç³»ç»Ÿé»˜è®¤æœªè®¾ç½® `WEB_PASSWORD`ã€‚æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹ä»»ä¸€æ–¹å¼è®¾ç½®ï¼š\n1.  **Web UI ç•Œé¢ (æ¨è)**ï¼šä½¿ç”¨åŸæœ‰ `API_KEY` ç™»å½•åï¼Œåœ¨ **API åä»£è®¾ç½®** é¡µé¢æ‰‹åŠ¨è®¾ç½®å¹¶ä¿å­˜ã€‚æ–°å¯†ç å°†æŒä¹…åŒ–å­˜å‚¨åœ¨ `gui_config.json` ä¸­ã€‚\n2.  **ç¯å¢ƒå˜é‡ (Docker)**ï¼šåœ¨å¯åŠ¨å®¹å™¨æ—¶å¢åŠ  `-e WEB_PASSWORD=æ‚¨çš„æ–°å¯†ç `ã€‚**æ³¨æ„ï¼šç¯å¢ƒå˜é‡å…·æœ‰æœ€é«˜ä¼˜å…ˆçº§ï¼Œå°†è¦†ç›– UI ä¸­çš„ä»»ä½•ä¿®æ”¹ã€‚**\n3.  **é…ç½®æ–‡ä»¶ (æŒä¹…åŒ–)**ï¼šç›´æ¥ä¿®æ”¹ `~/.antigravity_tools/gui_config.json`ï¼Œåœ¨ `proxy` å¯¹è±¡ä¸­ä¿®æ”¹æˆ–æ·»åŠ  `\"admin_password\": \"æ‚¨çš„æ–°å¯†ç \"` å­—æ®µã€‚\n    - *æ³¨ï¼š`WEB_PASSWORD` æ˜¯ç¯å¢ƒå˜é‡åï¼Œ`admin_password` æ˜¯é…ç½®æ–‡ä»¶ä¸­çš„ JSON é”®åã€‚*\n\n> [!TIP]\n> **å¯†ç ä¼˜å…ˆçº§é€»è¾‘ (Priority)**:\n> - **ç¬¬ä¸€ä¼˜å…ˆçº§ (ç¯å¢ƒå˜é‡)**: `ABV_WEB_PASSWORD` æˆ– `WEB_PASSWORD`ã€‚åªè¦è®¾ç½®äº†ç¯å¢ƒå˜é‡ï¼Œç³»ç»Ÿå°†å§‹ç»ˆä½¿ç”¨å®ƒã€‚\n> - **ç¬¬äºŒä¼˜å…ˆçº§ (é…ç½®æ–‡ä»¶)**: `gui_config.json` ä¸­çš„ `admin_password` å­—æ®µã€‚UI çš„â€œä¿å­˜â€æ“ä½œä¼šæ›´æ–°æ­¤å€¼ã€‚\n> - **ä¿åº•å›é€€ (å‘åå…¼å®¹)**: è‹¥ä¸Šè¿°å‡æœªè®¾ç½®ï¼Œåˆ™å›é€€ä½¿ç”¨ `API_KEY` ä½œä¸ºç™»å½•å¯†ç ã€‚\n\n# æ–¹å¼ 2: ä½¿ç”¨ Docker Compose\n# 1. è¿›å…¥é¡¹ç›®çš„ docker ç›®å½•\ncd docker\n# 2. å¯åŠ¨æœåŠ¡\ndocker compose up -d\n```\n> **è®¿é—®åœ°å€**: `http://localhost:8045` (ç®¡ç†åå°) | `http://localhost:8045/v1` (API Base)\n> **ç³»ç»Ÿè¦æ±‚**:\n> - **å†…å­˜**: å»ºè®® **1GB** (æœ€å° 256MB)ã€‚\n> - **æŒä¹…åŒ–**: éœ€æŒ‚è½½ `/root/.antigravity_tools` ä»¥ä¿å­˜æ•°æ®ã€‚\n> - **æ¶æ„**: æ”¯æŒ x86_64 å’Œ ARM64ã€‚\n> **è¯¦æƒ…è§**: [Docker éƒ¨ç½²æŒ‡å— (docker)](./docker/README.md)\n\n---\n\nCopyright Â© 2024-2026 [lbjlaq](https://github.com/lbjlaq)\n\n### ğŸ› ï¸ å¸¸è§é—®é¢˜æ’æŸ¥ (Troubleshooting)\n\n#### macOS æç¤ºâ€œåº”ç”¨å·²æŸåï¼Œæ— æ³•æ‰“å¼€â€ï¼Ÿ\nç”±äº macOS çš„å®‰å…¨æœºåˆ¶ï¼Œé App Store ä¸‹è½½çš„åº”ç”¨å¯èƒ½ä¼šè§¦å‘æ­¤æç¤ºã€‚æ‚¨å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å¿«é€Ÿä¿®å¤ï¼š\n\n1.  **å‘½ä»¤è¡Œä¿®å¤** (æ¨è):\n    æ‰“å¼€ç»ˆç«¯ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š\n    ```bash\n    sudo xattr -rd com.apple.quarantine \"/Applications/Antigravity Tools.app\"\n    ```\n2.  **Homebrew å®‰è£…æŠ€å·§**:\n    å¦‚æœæ‚¨ä½¿ç”¨ brew å®‰è£…ï¼Œå¯ä»¥æ·»åŠ  `--no-quarantine` å‚æ•°æ¥è§„é¿æ­¤é—®é¢˜ï¼š\n    ```bash\n    brew install --cask --no-quarantine antigravity-tools\n    ```\n\n## ğŸ”Œ å¿«é€Ÿæ¥å…¥ç¤ºä¾‹\n\n### ğŸ” OAuth æˆæƒæµç¨‹ï¼ˆæ·»åŠ è´¦å·ï¼‰\n1. æ‰“å¼€â€œAccounts / è´¦å·â€ â†’ â€œæ·»åŠ è´¦å·â€ â†’ â€œOAuthâ€ã€‚\n2. å¼¹çª—ä¼šåœ¨ç‚¹å‡»æŒ‰é’®å‰é¢„ç”Ÿæˆæˆæƒé“¾æ¥ï¼›ç‚¹å‡»é“¾æ¥å³å¯å¤åˆ¶åˆ°ç³»ç»Ÿå‰ªè´´æ¿ï¼Œç„¶åç”¨ä½ å¸Œæœ›çš„æµè§ˆå™¨æ‰“å¼€å¹¶å®Œæˆæˆæƒã€‚\n3. æˆæƒå®Œæˆåæµè§ˆå™¨ä¼šæ‰“å¼€æœ¬åœ°å›è°ƒé¡µå¹¶æ˜¾ç¤ºâ€œâœ… æˆæƒæˆåŠŸ!â€ã€‚\n4. åº”ç”¨ä¼šè‡ªåŠ¨ç»§ç»­å®Œæˆæˆæƒå¹¶ä¿å­˜è´¦å·ï¼›å¦‚æœªè‡ªåŠ¨å®Œæˆï¼Œå¯ç‚¹å‡»â€œæˆ‘å·²æˆæƒï¼Œç»§ç»­â€æ‰‹åŠ¨å®Œæˆã€‚\n\n> æç¤ºï¼šæˆæƒé“¾æ¥åŒ…å«ä¸€æ¬¡æ€§å›è°ƒç«¯å£ï¼Œè¯·å§‹ç»ˆä½¿ç”¨å¼¹çª—é‡Œç”Ÿæˆçš„æœ€æ–°é“¾æ¥ï¼›å¦‚æœæˆæƒæ—¶åº”ç”¨æœªè¿è¡Œæˆ–å¼¹çª—å·²å…³é—­ï¼Œæµè§ˆå™¨å¯èƒ½ä¼šæç¤º `localhost refused connection`ã€‚\n\n### å¦‚ä½•æ¥å…¥ Claude Code CLI?\n1.  å¯åŠ¨ Antigravityï¼Œå¹¶åœ¨â€œAPI åä»£â€é¡µé¢å¼€å¯æœåŠ¡ã€‚\n2.  åœ¨ç»ˆç«¯æ‰§è¡Œï¼š\n```bash\nexport ANTHROPIC_API_KEY=\"sk-antigravity\"\nexport ANTHROPIC_BASE_URL=\"http://127.0.0.1:8045\"\nclaude\n```\n\n### å¦‚ä½•æ¥å…¥ OpenCode?\n1.  è¿›å…¥ **API åä»£**é¡µé¢ â†’ **å¤–éƒ¨ Providers** â†’ ç‚¹å‡» **OpenCode Sync** å¡ç‰‡ã€‚\n2.  ç‚¹å‡» **Sync** æŒ‰é’®ï¼Œå°†è‡ªåŠ¨ç”Ÿæˆ `~/.config/opencode/opencode.json` é…ç½®æ–‡ä»¶ï¼ˆåŒ…å«ä»£ç† baseURL ä¸ apiKeyï¼Œæ”¯æŒ Anthropic/Google åŒ Providerï¼‰ã€‚\n3.  å¯é€‰ï¼šå‹¾é€‰ **Sync accounts** å¯åŒæ—¶å¯¼å‡º `antigravity-accounts.json` è´¦å·åˆ—è¡¨ï¼Œä¾› OpenCode æ’ä»¶ç›´æ¥å¯¼å…¥ä½¿ç”¨ã€‚\n4.  Windows ç”¨æˆ·è·¯å¾„ä¸º `C:\\Users\\<ç”¨æˆ·å>\\.config\\opencode\\`ï¼ˆä¸ `~/.config/opencode` è§„åˆ™ä¸€è‡´ï¼‰ã€‚\n5.  å¦‚éœ€å›æ»šï¼Œå¯ç‚¹å‡» **Restore** æŒ‰é’®ä»å¤‡ä»½æ¢å¤ä¹‹å‰çš„é…ç½®ã€‚\n\n### å¦‚ä½•æ¥å…¥ Kilo Code?\n1.  **åè®®é€‰æ‹©**: å»ºè®®ä¼˜å…ˆä½¿ç”¨ **Gemini åè®®**ã€‚\n2.  **Base URL**: å¡«å†™ `http://127.0.0.1:8045`ã€‚\n3.  **æ³¨æ„**: \n    - **OpenAI åè®®é™åˆ¶**: Kilo Code åœ¨ä½¿ç”¨ OpenAI æ¨¡å¼æ—¶ï¼Œå…¶è¯·æ±‚è·¯å¾„ä¼šå åŠ äº§ç”Ÿ `/v1/chat/completions/responses` è¿™ç§éæ ‡å‡†è·¯å¾„ï¼Œå¯¼è‡´ Antigravity è¿”å› 404ã€‚å› æ­¤è¯·åŠ¡å¿…å¡«å…¥ Base URL åé€‰æ‹© Gemini æ¨¡å¼ã€‚\n    - **æ¨¡å‹æ˜ å°„**: Kilo Code ä¸­çš„æ¨¡å‹åç§°å¯èƒ½ä¸ Antigravity é»˜è®¤è®¾ç½®ä¸ä¸€è‡´ï¼Œå¦‚é‡åˆ°æ— æ³•è¿æ¥ï¼Œè¯·åœ¨â€œæ¨¡å‹æ˜ å°„â€é¡µé¢è®¾ç½®è‡ªå®šä¹‰æ˜ å°„ï¼Œå¹¶æŸ¥çœ‹**æ—¥å¿—æ–‡ä»¶**è¿›è¡Œè°ƒè¯•ã€‚\n\n### å¦‚ä½•åœ¨ Python ä¸­ä½¿ç”¨?\n```python\nimport openai\n\nclient = openai.OpenAI(\n    api_key=\"sk-antigravity\",\n    base_url=\"http://127.0.0.1:8045/v1\"\n)\n\nresponse = client.chat.completions.create(\n    model=\"gemini-3-flash\",\n    messages=[{\"role\": \"user\", \"content\": \"ä½ å¥½ï¼Œè¯·è‡ªæˆ‘ä»‹ç»\"}]\n)\nprint(response.choices[0].message.content)\n```\n\n### å¦‚ä½•ä½¿ç”¨å›¾ç‰‡ç”Ÿæˆ (Imagen 3)?\n\n#### æ–¹å¼ä¸€ï¼šOpenAI Images API (æ¨è)\n```python\nimport openai\n\nclient = openai.OpenAI(\n    api_key=\"sk-antigravity\",\n    base_url=\"http://127.0.0.1:8045/v1\"\n)\n\n# ç”Ÿæˆå›¾ç‰‡\nresponse = client.images.generate(\n    model=\"gemini-3-pro-image\",\n    prompt=\"ä¸€åº§æœªæ¥ä¸»ä¹‰é£æ ¼çš„åŸå¸‚ï¼Œèµ›åšæœ‹å…‹ï¼Œéœ“è™¹ç¯\",\n    size=\"1920x1080\",      # æ”¯æŒä»»æ„ WIDTHxHEIGHT æ ¼å¼ï¼Œè‡ªåŠ¨è®¡ç®—å®½é«˜æ¯”\n    quality=\"hd\",          # \"standard\" | \"hd\" | \"medium\"\n    n=1,\n    response_format=\"b64_json\"\n)\n\n# ä¿å­˜å›¾ç‰‡\nimport base64\nimage_data = base64.b64decode(response.data[0].b64_json)\nwith open(\"output.png\", \"wb\") as f:\n    f.write(image_data)\n```\n\n**æ”¯æŒçš„å‚æ•°**ï¼š\n- **`size`**: ä»»æ„ `WIDTHxHEIGHT` æ ¼å¼ï¼ˆå¦‚ `1280x720`, `1024x1024`, `1920x1080`ï¼‰ï¼Œè‡ªåŠ¨è®¡ç®—å¹¶æ˜ å°„åˆ°æ ‡å‡†å®½é«˜æ¯”ï¼ˆ21:9, 16:9, 9:16, 4:3, 3:4, 1:1ï¼‰\n- **`quality`**: \n  - `\"hd\"` â†’ 4K åˆ†è¾¨ç‡ï¼ˆé«˜è´¨é‡ï¼‰\n  - `\"medium\"` â†’ 2K åˆ†è¾¨ç‡ï¼ˆä¸­ç­‰è´¨é‡ï¼‰\n  - `\"standard\"` â†’ é»˜è®¤åˆ†è¾¨ç‡ï¼ˆæ ‡å‡†è´¨é‡ï¼‰\n- **`n`**: ç”Ÿæˆå›¾ç‰‡æ•°é‡ï¼ˆ1-10ï¼‰\n- **`response_format`**: `\"b64_json\"` æˆ– `\"url\"`ï¼ˆData URIï¼‰\n\n#### æ–¹å¼äºŒï¼šChat API + å‚æ•°è®¾ç½® (âœ¨ æ–°å¢)\n\n**æ‰€æœ‰åè®®**ï¼ˆOpenAIã€Claudeï¼‰çš„ Chat API ç°åœ¨éƒ½æ”¯æŒç›´æ¥ä¼ é€’ `size` å’Œ `quality` å‚æ•°ï¼š\n\n```python\n# OpenAI Chat API\nresponse = client.chat.completions.create(\n    model=\"gemini-3-pro-image\",\n    size=\"1920x1080\",      # âœ… æ”¯æŒä»»æ„ WIDTHxHEIGHT æ ¼å¼\n    quality=\"hd\",          # âœ… \"standard\" | \"hd\" | \"medium\"\n    messages=[{\"role\": \"user\", \"content\": \"ä¸€åº§æœªæ¥ä¸»ä¹‰é£æ ¼çš„åŸå¸‚\"}]\n)\n```\n\n```bash\n# Claude Messages API\ncurl -X POST http://127.0.0.1:8045/v1/messages \\\n  -H \"Content-Type: application/json\" \\\n  -H \"x-api-key: sk-antigravity\" \\\n  -d '{\n    \"model\": \"gemini-3-pro-image\",\n    \"size\": \"1280x720\",\n    \"quality\": \"hd\",\n    \"messages\": [{\"role\": \"user\", \"content\": \"ä¸€åªå¯çˆ±çš„çŒ«å’ª\"}]\n  }'\n```\n\n**å‚æ•°ä¼˜å…ˆçº§**: è¯·æ±‚ä½“å‚æ•° > æ¨¡å‹åç¼€\n\n#### æ–¹å¼ä¸‰ï¼šChat æ¥å£ + æ¨¡å‹åç¼€\n```python\nresponse = client.chat.completions.create(\n    model=\"gemini-3-pro-image-16-9-4k\",  # æ ¼å¼ï¼šgemini-3-pro-image-[æ¯”ä¾‹]-[è´¨é‡]\n    messages=[{\"role\": \"user\", \"content\": \"ä¸€åº§æœªæ¥ä¸»ä¹‰é£æ ¼çš„åŸå¸‚\"}]\n)\n```\n\n**æ¨¡å‹åç¼€è¯´æ˜**ï¼š\n- **å®½é«˜æ¯”**: `-16-9`, `-9-16`, `-4-3`, `-3-4`, `-21-9`, `-1-1`\n- **è´¨é‡**: `-4k` (4K), `-2k` (2K), ä¸åŠ åç¼€ï¼ˆæ ‡å‡†ï¼‰\n- **ç¤ºä¾‹**: `gemini-3-pro-image-16-9-4k` â†’ 16:9 æ¯”ä¾‹ + 4K åˆ†è¾¨ç‡\n\n#### æ–¹å¼å››ï¼šCherry Studio ç­‰å®¢æˆ·ç«¯è®¾ç½®\nåœ¨æ”¯æŒ OpenAI åè®®çš„å®¢æˆ·ç«¯ï¼ˆå¦‚ Cherry Studioï¼‰ä¸­ï¼Œå¯ä»¥é€šè¿‡**æ¨¡å‹è®¾ç½®**é¡µé¢é…ç½®å›¾ç‰‡ç”Ÿæˆå‚æ•°ï¼š\n\n1. **è¿›å…¥æ¨¡å‹è®¾ç½®**ï¼šé€‰æ‹© `gemini-3-pro-image` æ¨¡å‹\n2. **é…ç½®å‚æ•°**ï¼š\n   - **Size (å°ºå¯¸)**: è¾“å…¥ä»»æ„ `WIDTHxHEIGHT` æ ¼å¼ï¼ˆå¦‚ `1920x1080`, `1024x1024`ï¼‰\n   - **Quality (è´¨é‡)**: é€‰æ‹© `standard` / `hd` / `medium`\n   - **Number (æ•°é‡)**: è®¾ç½®ç”Ÿæˆå›¾ç‰‡æ•°é‡ï¼ˆ1-10ï¼‰\n3. **å‘é€è¯·æ±‚**ï¼šç›´æ¥åœ¨å¯¹è¯æ¡†ä¸­è¾“å…¥å›¾ç‰‡æè¿°å³å¯\n\n**å‚æ•°æ˜ å°„è§„åˆ™**ï¼š\n- `size: \"1920x1080\"` â†’ è‡ªåŠ¨è®¡ç®—ä¸º `16:9` å®½é«˜æ¯”\n- `quality: \"hd\"` â†’ æ˜ å°„ä¸º `4K` åˆ†è¾¨ç‡\n- `quality: \"medium\"` â†’ æ˜ å°„ä¸º `2K` åˆ†è¾¨ç‡\n\n\n## ğŸ“ å¼€å‘è€…ä¸ç¤¾åŒº\n\n*   **ç‰ˆæœ¬æ¼”è¿› (Changelog)**:\n    *   **v4.1.7 (2026-02-06)**:\n        -   **[æ ¸å¿ƒä¿®å¤] ä¿®å¤å›¾åƒç”Ÿæˆ API (429/500/503) è‡ªåŠ¨åˆ‡æ¢è´¦å·é—®é¢˜ (Issue #1622)**:\n            -   **è‡ªåŠ¨é‡è¯•**: ä¸º `images/generations` å’Œ `images/edits` å¼•å…¥äº†ä¸ Chat API ä¸€è‡´çš„è‡ªåŠ¨é‡è¯•ä¸è´¦å·è½®æ¢æœºåˆ¶ã€‚\n            -   **ä½“éªŒä¸€è‡´æ€§**: ç¡®ä¿åœ¨æŸä¸ªè´¦å·é…é¢è€—å°½æˆ–æœåŠ¡ä¸å¯ç”¨æ—¶ï¼Œè¯·æ±‚èƒ½è‡ªåŠ¨æ•…éšœè½¬ç§»åˆ°ä¸‹ä¸€ä¸ªå¯ç”¨è´¦å·ï¼Œä¸å†ç›´æ¥å¤±è´¥ã€‚\n        -   **[æ ¸å¿ƒåŠŸèƒ½] æ–°å¢è´¦æˆ·è‡ªå®šä¹‰æ ‡ç­¾æ”¯æŒ (PR #1620)**:\n            -   **æ ‡ç­¾ç®¡ç†**: æ”¯æŒä¸ºæ¯ä¸ªè´¦æˆ·è®¾ç½®ä¸ªæ€§åŒ–æ ‡ç­¾ï¼Œæ–¹ä¾¿åœ¨å¤šè´¦æˆ·ç¯å¢ƒä¸‹å¿«é€Ÿè¯†åˆ«ã€‚\n            -   **äº¤äº’ä¼˜åŒ–**: è´¦æˆ·åˆ—è¡¨å’Œå¡ç‰‡è§†å›¾å‡æ”¯æŒç›´æ¥æŸ¥çœ‹å’Œå†…è”ç¼–è¾‘æ ‡ç­¾ã€‚\n            -   **å¤šè¯­è¨€æ”¯æŒ**: å®Œæ•´é€‚é…ä¸­ã€è‹±åŒè¯­æ˜¾ç¤ºã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] ä¿®å¤æ•°æ®åº“ä¸ºç©ºæ—¶ `get_stats` è¿”å› NULL å¯¼è‡´å´©æºƒçš„é—®é¢˜ (PR #1578)**:\n            -   **NULL å€¼å¤„ç†**: åœ¨ SQL æŸ¥è¯¢ä¸­ä½¿ç”¨ `COALESCE(SUM(...), 0)` ç¡®ä¿åœ¨æ²¡æœ‰æ—¥å¿—è®°å½•æ—¶ä¾ç„¶è¿”å›æ•°å€¼ï¼Œè§£å†³äº† `rusqlite` æ— æ³•å°† `NULL` è½¬æ¢ä¸º `u64` çš„é—®é¢˜ã€‚\n            -   **æ€§èƒ½ä¿ç•™**: ä¿ç•™äº†æœ¬åœ°åˆ†æ”¯ä¸­é€šè¿‡å•æ¬¡æŸ¥è¯¢è·å–å¤šé¡¹ç»Ÿè®¡æ•°æ®çš„æ€§èƒ½ä¼˜åŒ–é€»è¾‘ã€‚\n\n        -   **[æ ¸å¿ƒä¿®å¤] Claude 403 é”™è¯¯å¤„ç†ä¸è´¦å·è½®æ¢ä¼˜åŒ– (PR #1616)**:\n            -   **403 çŠ¶æ€æ˜ å°„**: å°† 403 (Forbidden) é”™è¯¯æ˜ å°„ä¸º 503 (Service Unavailable)ï¼Œé˜²æ­¢å®¢æˆ·ç«¯ï¼ˆå¦‚ Claude Codeï¼‰å› æ£€æµ‹åˆ° 403 è€Œè‡ªåŠ¨ç™»å‡ºã€‚\n            -   **è‡ªåŠ¨ç¦ç”¨é€»è¾‘**: æ£€æµ‹åˆ° 403 é”™è¯¯æ—¶è‡ªåŠ¨å°†è´¦å·æ ‡è®°ä¸º `is_forbidden` å¹¶ä»æ´»è·ƒæ± ä¸­ç§»é™¤ï¼Œé¿å…è¯¥è´¦å·åœ¨æ¥ä¸‹æ¥çš„è¯·æ±‚ä¸­è¢«ç»§ç»­é€‰ä¸­ã€‚\n            -   **ä¸´æ—¶é£æ§è¯†åˆ«**: è¯†åˆ« `VALIDATION_REQUIRED` é”™è¯¯ï¼Œå¹¶å¯¹ç›¸å…³è´¦å·æ‰§è¡Œ 10 åˆ†é’Ÿçš„ä¸´æ—¶é˜»æ–­ã€‚\n            -   **è½®æ¢ç¨³å®šæ€§**: ä¿®å¤äº†åœ¨è´¦å·é¢åº¦è€—å°½ (QUOTA_EXHAUSTED) æ—¶çš„è¿‡æ—©è¿”å›é—®é¢˜ï¼Œç¡®ä¿ç³»ç»Ÿèƒ½æ­£ç¡®å°è¯•è½®æ¢åˆ°ä¸‹ä¸€ä¸ªå¯ç”¨è´¦å·ã€‚\n        -   **[æ ¸å¿ƒåŠŸèƒ½] OpenCode CLI é…ç½®åŒæ­¥é›†æˆ (PR #1614)**:\n            -   **ä¸€é”®åŒæ­¥**: è‡ªåŠ¨ç”Ÿæˆ `~/.config/opencode/opencode.json`ï¼Œæ”¯æŒ Anthropic å’Œ Google åŒ Provider è‡ªåŠ¨é…ç½®ã€‚\n            -   **è´¦å·å¯¼å‡º**: å¯é€‰åŒæ­¥è´¦å·åˆ—è¡¨è‡³ `antigravity-accounts.json`ï¼Œä¾› OpenCode æ’ä»¶ç›´æ¥å¯¼å…¥ã€‚\n            -   **å¤‡ä»½ä¸è¿˜åŸ**: åŒæ­¥å‰è‡ªåŠ¨å¤‡ä»½åŸæœ‰é…ç½®ï¼Œæ”¯æŒä¸€é”®è¿˜åŸã€‚\n            -   **è·¨å¹³å°æ”¯æŒ**: ç»Ÿä¸€é€‚é… Windowsã€macOS å’Œ Linux ç¯å¢ƒã€‚\n            -   **ä½“éªŒä¼˜åŒ–**: ä¿®å¤äº† RPC å‚æ•°åŒ…è£…é—®é¢˜ï¼Œè¡¥å…¨äº†å¤šè¯­è¨€ç¿»è¯‘ï¼Œå¹¶ä¼˜åŒ–äº†é…ç½®æ–‡ä»¶ä¸å­˜åœ¨æ—¶çš„è§†å›¾çŠ¶æ€ã€‚\n        -   **[æ ¸å¿ƒåŠŸèƒ½] å…è®¸éšè—æœªä½¿ç”¨çš„èœå•é¡¹ (PR #1610)**:\n            -   **å¯è§æ€§æ§åˆ¶**: åœ¨è®¾ç½®é¡µé¢æ–°å¢â€œèœå•é¡¹æ˜¾ç¤ºè®¾ç½®â€ï¼Œå…è®¸ç”¨æˆ·è‡ªå®šä¹‰ä¾§è¾¹æ æ˜¾ç¤ºçš„å¯¼èˆªé¡¹ã€‚\n            -   **ç•Œé¢ç¾åŒ–**: ä¸ºæç®€ç”¨æˆ·æä¾›æ›´æ¸…çˆ½çš„ç•Œé¢ï¼Œéšè—ä¸å¸¸ç”¨çš„åŠŸèƒ½å…¥å£ã€‚\n\n        -   **[æ ¸å¿ƒä¿®å¤] Gemini åŸç”Ÿåè®®å›¾åƒç”Ÿæˆå®Œå…¨ä¿®å¤ (Issue #1573, #1625)**:\n            -   **400 é”™è¯¯ä¿®å¤**: ä¿®å¤äº† Gemini åŸç”Ÿåè®®ç”Ÿæˆå›¾ç‰‡æ—¶ï¼Œå› è¯·æ±‚ä½“ `contents` æ•°ç»„ç¼ºå¤± `role: \"user\"` å­—æ®µå¯¼è‡´çš„ `INVALID_ARGUMENT` é”™è¯¯ã€‚\n            -   **å‚æ•°é€ä¼ æ”¯æŒ**: ç¡®ä¿ `generationConfig.imageConfig` (å¦‚ `aspectRatio`, `imageSize`) èƒ½æ­£ç¡®é€ä¼ ç»™ä¸Šæ¸¸ï¼Œä¸å†è¢«é”™è¯¯è¿‡æ»¤ã€‚\n            -   **é”™è¯¯ç ä¼˜åŒ–**: ä¼˜åŒ–äº†å›¾åƒç”ŸæˆæœåŠ¡çš„é”™è¯¯æ˜ å°„ï¼Œç¡®ä¿ 429/503 ç­‰çŠ¶æ€ç èƒ½æ­£ç¡®è§¦å‘å®¢æˆ·ç«¯çš„é‡è¯•æœºåˆ¶ã€‚\n        -   **[æ ¸å¿ƒå¢å¼º] è‡ªå®šä¹‰æ˜ å°„æ”¯æŒæ‰‹åŠ¨è¾“å…¥ä»»æ„æ¨¡å‹ ID**:\n            -   **çµæ´»è¾“å…¥**: åœ¨è‡ªå®šä¹‰æ˜ å°„çš„ç›®æ ‡æ¨¡å‹é€‰æ‹©å™¨ä¸­æ–°å¢æ‰‹åŠ¨è¾“å…¥åŠŸèƒ½ï¼Œç”¨æˆ·ç°åœ¨å¯ä»¥åœ¨ä¸‹æ‹‰èœå•åº•éƒ¨ç›´æ¥è¾“å…¥ä»»æ„æ¨¡å‹ IDã€‚\n            -   **æœªå‘å¸ƒæ¨¡å‹ä½“éªŒ**: æ”¯æŒä½“éªŒ Antigravity å°šæœªæ­£å¼å‘å¸ƒçš„æ¨¡å‹ï¼Œä¾‹å¦‚ `claude-opus-4-6`ã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡è‡ªå®šä¹‰æ˜ å°„å°†è¯·æ±‚è·¯ç”±åˆ°è¿™äº›å®éªŒæ€§æ¨¡å‹ã€‚\n            -   **é‡è¦æç¤º**: å¹¶éæ‰€æœ‰è´¦å·éƒ½æ”¯æŒè°ƒç”¨æœªå‘å¸ƒçš„æ¨¡å‹ã€‚å¦‚æœæ‚¨çš„è´¦å·æ— æƒè®¿é—®æŸä¸ªæ¨¡å‹ï¼Œè¯·æ±‚å¯èƒ½ä¼šè¿”å›é”™è¯¯ã€‚å»ºè®®å…ˆåœ¨å°‘é‡è¯·æ±‚ä¸­æµ‹è¯•ï¼Œç¡®è®¤è´¦å·æƒé™åå†å¤§è§„æ¨¡ä½¿ç”¨ã€‚\n            -   **å¿«æ·æ“ä½œ**: æ”¯æŒ Enter é”®å¿«é€Ÿæäº¤è‡ªå®šä¹‰æ¨¡å‹ IDï¼Œæå‡è¾“å…¥æ•ˆç‡ã€‚\n    *   **v4.1.6 (2026-02-06)**:\n        -   **[æ ¸å¿ƒä¿®å¤] æ·±åº¦é‡æ„ Claude/Gemini æ€è€ƒæ¨¡å‹ä¸­æ–­ä¸å·¥å…·å¾ªç¯è‡ªæ„ˆé€»è¾‘ (#1575)**:\n            -   **æ€è€ƒå¼‚å¸¸æ¢å¤**: å¼•å…¥äº† `thinking_recovery` æœºåˆ¶ã€‚å½“æ£€æµ‹åˆ°å†å²æ¶ˆæ¯ä¸­åŒ…å«é™ˆæ—§æ€è€ƒå—æˆ–é™·å…¥çŠ¶æ€å¾ªç¯æ—¶ï¼Œè‡ªåŠ¨è¿›è¡Œå‰¥ç¦»ä¸å¼•å¯¼ï¼Œæå‡äº†åœ¨å¤æ‚å·¥å…·è°ƒç”¨åœºæ™¯ä¸‹çš„ç¨³å®šæ€§ã€‚\n            -   **å½»åº•è§£å†³ç­¾åç»‘å®šé”™è¯¯**: ä¿®æ­£äº†è¯¯å°†ç¼“å­˜ç­¾åæ³¨å…¥å®¢æˆ·ç«¯è‡ªå®šä¹‰æ€è€ƒå†…å®¹çš„é€»è¾‘ã€‚ç”±äºç­¾åä¸æ–‡æœ¬å¼ºç»‘å®šï¼Œæ­¤ä¸¾å½»åº•è§£å†³äº†ä¼šè¯ä¸­æ–­æˆ–é‡ç½®åå¸¸è§çš„ `Invalid signature` (HTTP 400) æŠ¥é”™ã€‚\n            -   **ä¼šè¯çº§å®Œå…¨éš”ç¦»**: åˆ é™¤äº†å…¨å±€ç­¾åå•ä¾‹ï¼Œç¡®ä¿æ‰€æœ‰æ€ç»´ç­¾åä¸¥æ ¼åœ¨ Session çº§åˆ«éš”ç¦»ï¼Œå½»åº•æœç»äº†å¤šè´¦å·ã€å¤šä¼šè¯å¹¶å‘æ—¶çš„ç­¾åæ±¡æŸ“ã€‚\n        -   **[ä¿®å¤] å½»åº•è§£å†³ Gemini ç³»åˆ—ç”±äº `thinking_budget` è¶Šç•Œå¯¼è‡´çš„ HTTP 400 é”™è¯¯ (#1592, #1602)**:\n            -   **å…¨åè®®è·¯å¾„ç¡¬æˆªæ–­**: ä¿®å¤äº† OpenAI å’Œ Claude åè®®æ˜ å°„å™¨åœ¨ã€Œè‡ªå®šä¹‰æ¨¡å¼ã€ä¸‹ç¼ºå¤±é™é¢ä¿æŠ¤çš„é—®é¢˜ã€‚ç°åœ¨æ— è®ºé€‰æ‹©ä½•ç§æ¨¡å¼ï¼ˆè‡ªåŠ¨/è‡ªå®šä¹‰/é€ä¼ ï¼‰ï¼Œåªè¦ç›®æ ‡æ¨¡å‹ä¸º Geminiï¼Œåç«¯éƒ½ä¼šå¼ºåˆ¶æ‰§è¡Œ 24576 çš„ç‰©ç†ä¸Šé™ä¿æŠ¤ã€‚\n            -   **è‡ªåŠ¨é€‚é…ä¸å‰ç«¯åŒæ­¥**: é‡æ„äº†åè®®è½¬æ¢é€»è¾‘ï¼Œä½¿å…¶åŸºäºæœ€ç»ˆæ˜ å°„çš„æ¨¡å‹å‹å·è¿›è¡ŒåŠ¨æ€é™é¢ï¼›åŒæ­¥æ›´æ–°äº†è®¾ç½®ç•Œé¢çš„æç¤ºæ–‡æ¡ˆï¼Œæ˜ç¡®äº† Gemini åè®®çš„ç‰©ç†é™åˆ¶ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] Web Mode ç™»å½•éªŒè¯ä¿®å¤ & ç™»å‡ºæŒ‰é’® (PR #1603)**:\n            -   **ç™»å½•éªŒè¯**: ä¿®å¤äº† Web æ¨¡å¼ä¸‹ç™»å½•éªŒè¯é€»è¾‘çš„å¼‚å¸¸ï¼Œç¡®ä¿ç”¨æˆ·èº«ä»½éªŒè¯çš„ç¨³å®šæ€§ã€‚\n            -   **ç™»å‡ºåŠŸèƒ½**: åœ¨ç•Œé¢ä¸­æ–°å¢/ä¿®å¤äº†ç™»å‡ºæŒ‰é’®ï¼Œå®Œå–„äº† Web æ¨¡å¼ä¸‹çš„è´¦æˆ·ç®¡ç†é—­ç¯ã€‚\n    *   **v4.1.5 (2026-02-05)**:\n        -   **[å®‰å…¨ä¿®å¤] å‰ç«¯ API Key å­˜å‚¨è¿ç§» (LocalStorage -> SessionStorage)**:\n            -   **å­˜å‚¨æœºåˆ¶å‡çº§**: å°† Admin API Key çš„å­˜å‚¨ä½ç½®ä»æŒä¹…åŒ–çš„ `localStorage` è¿ç§»è‡³ä¼šè¯çº§çš„ `sessionStorage`ï¼Œæ˜¾è‘—é™ä½äº†åœ¨å…¬å…±è®¾å¤‡ä¸Šçš„å®‰å…¨é£é™©ã€‚\n            -   **è‡ªåŠ¨æ— æ„Ÿè¿ç§»**: å®ç°äº†è‡ªåŠ¨æ£€æµ‹ä¸è¿ç§»é€»è¾‘ã€‚ç³»ç»Ÿä¼šè¯†åˆ«æ—§çš„ `localStorage` å¯†é’¥ï¼Œå°†å…¶è‡ªåŠ¨è½¬ç§»åˆ° `sessionStorage` å¹¶å½»åº•æ¸…é™¤æ—§æ•°æ®ï¼Œç¡®ä¿ç°æœ‰ç”¨æˆ·æ— ç¼è¿‡æ¸¡ä¸”æ¶ˆé™¤å®‰å…¨éšæ‚£ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] ä¿®å¤ Docker ç¯å¢ƒä¸‹æ·»åŠ è´¦å·å¤±è´¥é—®é¢˜ (Issue #1583)**:\n            -   **è´¦å·ä¸Šä¸‹æ–‡ä¿®å¤**: ä¿®å¤äº†åœ¨æ·»åŠ æ–°è´¦å·æ—¶ `account_id` ä¸º `None` å¯¼è‡´ä»£ç†é€‰æ‹©å¼‚å¸¸çš„é—®é¢˜ã€‚ç°åœ¨ç³»ç»Ÿä¼šä¸ºæ–°è´¦å·ç”Ÿæˆä¸´æ—¶ UUID,ç¡®ä¿æ‰€æœ‰ OAuth è¯·æ±‚éƒ½æœ‰æ˜ç¡®çš„è´¦å·ä¸Šä¸‹æ–‡ã€‚\n            -   **æ—¥å¿—å¢å¼º**: ä¼˜åŒ–äº† `refresh_access_token` å’Œ `get_effective_client` çš„æ—¥å¿—è®°å½•,æä¾›æ›´è¯¦ç»†çš„ä»£ç†é€‰æ‹©ä¿¡æ¯,å¸®åŠ©è¯Šæ–­ Docker ç¯å¢ƒä¸‹çš„ç½‘ç»œé—®é¢˜ã€‚\n            -   **å½±å“èŒƒå›´**: ä¿®å¤äº† Docker éƒ¨ç½²ç¯å¢ƒä¸‹é€šè¿‡ Refresh Token æ·»åŠ è´¦å·æ—¶å¯èƒ½å‡ºç°çš„é•¿æ—¶é—´æŒ‚èµ·æˆ–å¤±è´¥é—®é¢˜ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] Web Mode å…¼å®¹æ€§ä¿®å¤ & 403 è´¦å·è½®æ¢ä¼˜åŒ– (PR #1585)**:\n            -   **Security API Web Mode å…¼å®¹æ€§ä¿®å¤ (Issue: 400/422 é”™è¯¯)**:\n                -   ä¸º `IpAccessLogQuery` æ·»åŠ  `page` å’Œ `page_size` çš„é»˜è®¤å€¼,è§£å†³ `/api/security/logs` è¿”å› 400 Bad Request çš„é—®é¢˜\n                -   ç§»é™¤ `AddBlacklistWrapper` å’Œ `AddWhitelistWrapper` ç»“æ„ä½“,è§£å†³ `/api/security/blacklist` å’Œ `/api/security/whitelist` POST è¿”å› 422 Unprocessable Content çš„é—®é¢˜\n                -   å‰ç«¯ç»„ä»¶å‚æ•°åä¿®æ­£:`ipPattern` â†’ `ip_pattern`,ç¡®ä¿ä¸åç«¯ API å‚æ•°ä¸€è‡´\n            -   **403 è´¦å·è½®æ¢ä¼˜åŒ– (Issue: 403 åæœªæ­£ç¡®è·³è¿‡è´¦å·)**:\n                -   åœ¨ `token_manager.rs` ä¸­æ·»åŠ  `set_forbidden` æ–¹æ³•,æ”¯æŒæ ‡è®°è´¦å·ä¸ºç¦ç”¨çŠ¶æ€\n                -   è´¦å·é€‰æ‹©æ—¶æ£€æŸ¥ `quota.is_forbidden` çŠ¶æ€,è‡ªåŠ¨è·³è¿‡è¢«ç¦ç”¨çš„è´¦å·\n                -   403 æ—¶æ¸…é™¤è¯¥è´¦å·çš„ sticky session ç»‘å®š,ç¡®ä¿ç«‹å³åˆ‡æ¢åˆ°å…¶ä»–å¯ç”¨è´¦å·\n            -   **Web Mode è¯·æ±‚å¤„ç†ä¼˜åŒ–**:\n                -   `request.ts` ä¿®å¤è·¯å¾„å‚æ•°æ›¿æ¢åä» body ä¸­ç§»é™¤å·²ä½¿ç”¨çš„å‚æ•°,é¿å…é‡å¤ä¼ å‚\n                -   æ”¯æŒ PATCH æ–¹æ³•çš„ body å¤„ç†,è¡¥å…¨ HTTP æ–¹æ³•æ”¯æŒ\n                -   è‡ªåŠ¨è§£åŒ… `request` å­—æ®µ,ç®€åŒ–è¯·æ±‚ç»“æ„\n            -   **Debug Console Web Mode æ”¯æŒ**:\n                -   `useDebugConsole.ts` æ·»åŠ  `isTauri` ç¯å¢ƒæ£€æµ‹,åŒºåˆ† Tauri å’Œ Web ç¯å¢ƒ\n                -   Web æ¨¡å¼ä¸‹ä½¿ç”¨ `request()` æ›¿ä»£ `invoke()`,ç¡®ä¿ Web ç¯å¢ƒä¸‹çš„æ­£å¸¸è°ƒç”¨\n                -   æ·»åŠ è½®è¯¢æœºåˆ¶,Web æ¨¡å¼ä¸‹æ¯ 2 ç§’è‡ªåŠ¨åˆ·æ–°æ—¥å¿—\n            -   **Docker æ„å»ºä¼˜åŒ–**:\n                -   æ·»åŠ  `--legacy-peer-deps` æ ‡å¿—,è§£å†³å‰ç«¯ä¾èµ–å†²çª\n                -   å¯ç”¨ BuildKit ç¼“å­˜åŠ é€Ÿ Cargo æ„å»º,æå‡æ„å»ºé€Ÿåº¦\n                -   è¡¥å…¨ `@lobehub/icons` peer dependencies,ä¿®å¤å‰ç«¯ä¾èµ–ç¼ºå¤±å¯¼è‡´çš„æ„å»ºå¤±è´¥\n            -   **å½±å“èŒƒå›´**: æ­¤æ›´æ–°æ˜¾è‘—æå‡äº† Docker/Web æ¨¡å¼ä¸‹çš„ç¨³å®šæ€§å’Œå¯ç”¨æ€§,è§£å†³äº† Security API æŠ¥é”™ã€403 è´¦å·è½®æ¢å¤±æ•ˆã€Debug Console ä¸å¯ç”¨ç­‰é—®é¢˜,åŒæ—¶ä¼˜åŒ–äº† Docker æ„å»ºæµç¨‹ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] ä¿®å¤ Web/Docker æ¨¡å¼ä¸‹è°ƒè¯•æ§åˆ¶å°å´©æºƒä¸æ—¥å¿—åŒæ­¥é—®é¢˜ (Issue #1574)**:\n            -   **Web å…¼å®¹æ€§**: ä¿®å¤äº†åœ¨é Tauri ç¯å¢ƒä¸‹ç›´æ¥è°ƒç”¨åŸç”Ÿ `invoke` API å¯¼è‡´çš„ `TypeError` å´©æºƒã€‚ç°åœ¨é€šè¿‡å…¼å®¹æ€§è¯·æ±‚å±‚è¿›è¡Œåç«¯é€šä¿¡ã€‚\n            -   **æŒ‡çº¹ç»‘å®šä¿®å¤**: ä¿®å¤äº†ç”ŸæˆæŒ‡çº¹å¹¶ç»‘å®šæ—¶,ç”±äºå‰åç«¯å‚æ•°ç»“æ„ä¸åŒ¹é…å¯¼è‡´çš„ `HTTP Error 422` æŠ¥é”™ã€‚é€šè¿‡è°ƒæ•´åç«¯åŒ…è£…ç±»,ä½¿å…¶å…¼å®¹å‰ç«¯åµŒå¥—çš„ `profile` å¯¹è±¡ã€‚\n            -   **æ—¥å¿—è½®è¯¢æœºåˆ¶**: ä¸º Web æ¨¡å¼å¼•å…¥äº†è‡ªåŠ¨æ—¥å¿—è½®è¯¢åŠŸèƒ½(2ç§’/æ¬¡),è§£å†³äº†æµè§ˆå™¨ç«¯æ— æ³•æ¥æ”¶ Rust åç«¯äº‹ä»¶æ¨é€å¯¼è‡´è°ƒè¯•æ—¥å¿—ä¸ºç©ºçš„é—®é¢˜ã€‚\n        -   **[æ ¸å¿ƒä¼˜åŒ–] è¡¥å…¨ Tauri å‘½ä»¤çš„ HTTP API æ˜ å°„**:\n            -   **å…¨é‡é€‚é…**: å¯¹é½äº† 30+ ä¸ªåŸç”Ÿ Tauri å‘½ä»¤,ä¸ºç¼“å­˜ç®¡ç†(æ¸…ç†æ—¥å¿—/åº”ç”¨ç¼“å­˜)ã€ç³»ç»Ÿè·¯å¾„è·å–ã€ä»£ç†æ± é…ç½®ã€ç”¨æˆ·ä»¤ç‰Œç®¡ç†ç­‰æ ¸å¿ƒåŠŸèƒ½è¡¥å…¨äº† HTTP æ˜ å°„,ç¡®ä¿ Web/Docker ç‰ˆæœ¬çš„åŠŸèƒ½å®Œæ•´æ€§ã€‚\n        -   **[å®‰å…¨ä¿®å¤] ä»»æ„æ–‡ä»¶è¯»å†™æ¼æ´åŠ å›º**:\n            -   **API å®‰å…¨å±‚**: å½»åº•ç§»é™¤äº†é«˜å±æ¥å£ `/api/system/save-file` åŠå…¶å…³è”å‡½æ•°,å¹¶åœ¨æ•°æ®åº“å¯¼å…¥æ¥å£ä¸­å¢åŠ äº†è·¯å¾„éå†é˜²èŒƒ (`..` æ ¡éªŒ)ã€‚\n            -   **Tauri å®‰å…¨å¢å¼º**: ä¸º `save_text_file` å’Œ `read_text_file` å‘½ä»¤å¼•å…¥äº†ç»Ÿä¸€çš„è·¯å¾„æ ¡éªŒå™¨,ä¸¥ç¦ç›®å½•éå†å¹¶å°å µäº†ç³»ç»Ÿæ•æ„Ÿç›®å½•çš„è®¿é—®æƒé™ã€‚\n    *   **v4.1.4 (2026-02-05)**:\n        -   **[æ ¸å¿ƒåŠŸèƒ½] ä»£ç†æ± æŒä¹…åŒ–ä¸è´¦å·ç­›é€‰ä¼˜åŒ– (PR #1565)**:\n            -   **æŒä¹…åŒ–å¢å¼º**: ä¿®å¤äº†ä»£ç†æ± ç»‘å®šåœ¨åä»£æœåŠ¡é‡å¯æˆ–é‡è½½æ—¶æ— æ³•æ­£ç¡®æ¢å¤çš„é—®é¢˜ï¼Œç¡®ä¿ç»‘å®šå…³ç³»ä¸¥æ ¼æŒä¹…åŒ–ã€‚\n            -   **æ™ºèƒ½ç­›é€‰**: ä¼˜åŒ–äº† `TokenManager` çš„è´¦å·è·å–é€»è¾‘,åœ¨å…¨é‡åŠ è½½ã€åŒæ­¥ä»¥åŠè°ƒåº¦è·¯å¾„ä¸­å¢åŠ äº†å¯¹ `disabled` å’Œ `proxy_disabled` çŠ¶æ€çš„æ·±åº¦æ ¡éªŒï¼Œå½»åº•æœç»å·²ç¦ç”¨è´¦å·è¢«è¯¯é€‰çš„é—®é¢˜ã€‚\n            -   **éªŒè¯é˜»æ­¢æ”¯æŒ**: å¼•å…¥äº† `validation_blocked` å­—æ®µä½“ç³»ï¼Œä¸“é—¨å¤„ç† Google çš„ `VALIDATION_REQUIRED` (403 ä¸´æ—¶é£æ§) åœºæ™¯ï¼Œå®ç°äº†åŸºäºæˆªæ­¢æ—¶é—´çš„æ™ºèƒ½è‡ªåŠ¨ç»•è¿‡ã€‚\n            -   **çŠ¶æ€æ¸…ç†åŠ å›º**: è´¦å·å¤±æ•ˆæ—¶åŒæ­¥æ¸…ç†å†…å­˜ä»¤ç‰Œã€é™æµè®°å½•ã€ä¼šè¯ç»‘å®šåŠä¼˜å…ˆè´¦å·æ ‡å¿—ï¼Œä¿è¯å†…éƒ¨çŠ¶æ€æœºçš„ä¸€è‡´æ€§ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] ä¿®å¤ Web/Docker æ¨¡å¼ä¸‹çš„å…³é”®å…¼å®¹æ€§é—®é¢˜ (Issue #1574)**:\n            -   **è°ƒè¯•æ¨¡å¼ä¿®å¤**: ä¿®æ­£äº†å‰ç«¯è°ƒè¯•æ§åˆ¶å° URL æ˜ å°„é”™è¯¯ï¼ˆç§»é™¤å¤šä½™çš„ `/proxy` è·¯å¾„ï¼‰ï¼Œè§£å†³äº† Web æ¨¡å¼ä¸‹è°ƒè¯•æ¨¡å¼æ— æ³•å¼€å¯çš„é—®é¢˜ã€‚\n            -   **æŒ‡çº¹ç»‘å®šä¿®å¤**: ä¸º `admin_bind_device_profile_with_profile` æ¥å£å¢åŠ äº† `BindDeviceProfileWrapper` ç»“æ„ï¼Œä¿®å¤äº†å‰ç«¯å‘é€åµŒå¥—å‚æ•°å¯¼è‡´çš„ HTTP 422 é”™è¯¯ã€‚\n            -   **å‘åå…¼å®¹æ€§**: ä½¿ç”¨ `serde alias` åŠŸèƒ½åœ¨ API å±‚åŒæ—¶æ”¯æŒ camelCaseï¼ˆå‰ç«¯ï¼‰å’Œ snake_caseï¼ˆåç«¯æ–‡ä»¶ï¼‰ï¼Œç¡®ä¿æ—§è´¦å·æ–‡ä»¶æ­£å¸¸åŠ è½½ã€‚\n        -   **[ä»£ç ä¼˜åŒ–] ç®€åŒ– API å¤„ç†ç»“æ„**:\n            -   ç§»é™¤äº†å¤šä¸ªç®¡ç† API è·¯ç”±ï¼ˆå¦‚ IP é»‘ç™½åå•ç®¡ç†ã€å®‰å…¨è®¾ç½®æ›´æ–°ç­‰ï¼‰ä¸­çš„å†—ä½™åŒ…è£…å±‚ (`Wrapper`)ï¼Œç›´æ¥è§£æ„ä¸šåŠ¡æ¨¡å‹ï¼Œæå‡äº†ä»£ç çš„ç®€æ´æ€§ä¸å¼€å‘æ•ˆç‡ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] è§£å†³ OpenCode è°ƒç”¨ Thinking æ¨¡å‹ä¸­æ–­é—®é¢˜ (Issue #1575)**:\n            -   **finish_reason å¼ºåˆ¶ä¿®æ­£**: ä¿®å¤äº†å·¥å…·è°ƒç”¨æ—¶ `finish_reason` è¢«é”™è¯¯è®¾ç½®ä¸º `stop` å¯¼è‡´ OpenAI å®¢æˆ·ç«¯æå‰ç»ˆæ­¢å¯¹è¯çš„é—®é¢˜ã€‚ç°åœ¨ç³»ç»Ÿä¼šå¼ºåˆ¶å°†æœ‰å·¥å…·è°ƒç”¨çš„å“åº” `finish_reason` è®¾ç½®ä¸º `tool_calls`ï¼Œç¡®ä¿å·¥å…·å¾ªç¯æ­£å¸¸è¿è¡Œã€‚\n            -   **å·¥å…·å‚æ•°æ ‡å‡†åŒ–**: å®ç°äº† shell å·¥å…·å‚æ•°åç§°çš„è‡ªåŠ¨æ ‡å‡†åŒ–ï¼Œå°† Gemini å¯èƒ½ç”Ÿæˆçš„ `cmd`/`code`/`script` ç­‰éæ ‡å‡†å‚æ•°åç»Ÿä¸€è½¬æ¢ä¸º `command`ï¼Œæå‡äº†å·¥å…·è°ƒç”¨çš„å…¼å®¹æ€§ã€‚\n            -   **å½±å“èŒƒå›´**: ä¿®å¤äº† OpenAI åè®®ä¸‹ Thinking æ¨¡å‹ï¼ˆå¦‚ `claude-sonnet-4-5-thinking`ï¼‰çš„å·¥å…·è°ƒç”¨æµç¨‹ï¼Œè§£å†³äº† OpenCode ç­‰å®¢æˆ·ç«¯çš„ä¸­æ–­é—®é¢˜ã€‚\n\n    *   **v4.1.3 (2026-02-05)**:\n        -   **[æ ¸å¿ƒä¿®å¤] è§£å†³ Web/Docker æ¨¡å¼ä¸‹å®‰å…¨é…ç½®ä¸ IP ç®¡ç†å¤±æ•ˆé—®é¢˜ (Issue #1560)**:\n            -   **åè®®å¯¹é½**: ä¿®å¤äº†åç«¯ Axum æ¥å£æ— æ³•è§£æå‰ç«¯ `invoke` å°è£…çš„åµŒå¥—å‚æ•°æ ¼å¼ï¼ˆå¦‚ `{\"config\": ...}`ï¼‰çš„é—®é¢˜ï¼Œç¡®ä¿å®‰å…¨é…ç½®èƒ½æ­£ç¡®æŒä¹…åŒ–ã€‚\n            -   **å‚æ•°è§„èŒƒåŒ–**: ä¸º IP ç®¡ç†ç›¸å…³æ¥å£æ·»åŠ äº† `camelCase` é‡å‘½åæ”¯æŒï¼Œè§£å†³äº† Web ç«¯ Query å‚æ•°å¤§å°å†™ä¸åŒ¹é…å¯¼è‡´çš„æ·»åŠ å¤±è´¥ä¸åˆ é™¤å¤±æ•ˆã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] æ¢å¤ Gemini Pro æ€è€ƒå—è¾“å‡º (Issue #1557)**:\n            -   **è·¨åè®®å¯¹é½**: ä¿®å¤äº†è‡ª v4.1.0 ä»¥æ¥ `gemini-3-pro` ç­‰æ¨¡å‹åœ¨ OpenAIã€Claude å’Œ Gemini åŸç”Ÿåè®®ä¸‹æ€è€ƒå—ç¼ºå¤±çš„é—®é¢˜ã€‚\n            -   **æ™ºèƒ½æ³¨å…¥é€»è¾‘**: å®ç°äº† `thinkingConfig` çš„è‡ªåŠ¨æ³¨å…¥ä¸é»˜è®¤å¼€å¯æœºåˆ¶ï¼Œç¡®ä¿å³ä½¿å®¢æˆ·ç«¯æœªå‘é€é…ç½®ï¼Œæ¨¡å‹ä¹Ÿèƒ½æ­£ç¡®æ¿€æ´»æ€è€ƒèƒ½åŠ›ã€‚\n            -   **é²æ£’æ€§å¢å¼º**: ä¼˜åŒ–äº† `wrapper.rs` å†…éƒ¨ç±»å‹å¤„ç†ï¼Œè§£æå¹¶è§£å†³äº†é«˜å¹¶å‘åœºæ™¯ä¸‹çš„é…ç½®å†²çªã€‚\n    *   **v4.1.2 (2026-02-05)**:\n        -   **[æ ¸å¿ƒåŠŸèƒ½] å¤šåè®®å®¢æˆ·ç«¯é€‚é…å™¨ (ClientAdapter Framework) (Issue #1522)**:\n            -   **æ¶æ„é‡æ„**: å¼•å…¥ `ClientAdapter` æ¡†æ¶å¹¶åº”ç”¨ `Arc` å¼•ç”¨è®¡æ•°ï¼Œå®ç°äº† Handler å±‚ä¸ä¸‹æ¸¸å®¢æˆ·ç«¯é€»è¾‘çš„å®Œå…¨è§£è€¦ï¼Œæ”¯æŒæ›´å®‰å…¨çš„è·¨çº¿ç¨‹å…±äº«ã€‚\n            -   **å…¨åè®®å…¼å®¹**: é’ˆå¯¹ `opencode` ç­‰ç¬¬ä¸‰æ–¹å®¢æˆ·ç«¯ï¼Œå®ç°äº† **4 ç§åè®®**ï¼ˆClaude/OpenAI/Gemini/OA-Compatibleï¼‰çš„æ— ç¼æ¥å…¥ï¼Œå½»åº•è§£å†³äº† `AI_TypeValidationError` æŠ¥é”™ã€‚\n            -   **æ™ºèƒ½ç­–ç•¥**: å®ç°äº† FIFO ç­¾åç¼“å­˜ç­–ç•¥ä¸ `let_it_crash` å¿«é€Ÿå¤±è´¥æœºåˆ¶ï¼Œæ˜¾è‘—æå‡äº†é«˜å¹¶å‘åœºæ™¯ä¸‹çš„ç¨³å®šæ€§å’Œé”™è¯¯åé¦ˆé€Ÿåº¦ã€‚\n            -   **æ ‡å‡†åŒ–é”™è¯¯å“åº”**: å¼ºåˆ¶ç»Ÿä¸€æ‰€æœ‰åè®®çš„é”™è¯¯è¿”å›æ ¼å¼ï¼ˆæµå¼ SSE `event: error` / éæµå¼ JSONï¼‰ï¼Œç¡®ä¿å®¢æˆ·ç«¯èƒ½æ­£ç¡®è§£æä¸Šæ¸¸å¼‚å¸¸ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] ç»Ÿä¸€è´¦å·ç¦ç”¨çŠ¶æ€æ£€æŸ¥é€»è¾‘ (Issue #1512)**:\n            -   **é€»è¾‘å¯¹é½**: ä¿®å¤äº†æ‰¹é‡åˆ·æ–°é…é¢åŠè‡ªåŠ¨é¢„çƒ­é€»è¾‘ä¸­é—æ¼æ‰‹åŠ¨ç¦ç”¨çŠ¶æ€ (`proxy_disabled`) çš„é—®é¢˜ã€‚\n            -   **åå°é™å™ª**: ç¡®ä¿æ ‡è®°ä¸ºâ€œç¦ç”¨â€æˆ–â€œç¦ç”¨ä»£ç†â€çš„è´¦å·ä¸å†è§¦å‘ä»»ä½•åå°ç½‘ç»œè¯·æ±‚ï¼Œæå‡äº†ç³»ç»Ÿçš„éšç§æ€§ä¸èµ„æºæ•ˆç‡ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] è§£å†³ OpenAI åè®®è·¯å¾„ä¸‹ Invalid signature å¯¼è‡´çš„ 400 é”™è¯¯ (Issue #1506)**:\n            -   **Session çº§ç­¾åéš”ç¦»**: å¼•å…¥äº† `SignatureCache` æœºåˆ¶ï¼Œé€šè¿‡ `session_id` ç‰©ç†éš”ç¦»ä¸åŒä¼šè¯çš„æ€ç»´ç­¾åå­˜å‚¨ï¼Œå½»åº•æœç»å¤šè½®å¯¹è¯æˆ–å¹¶å‘è¯·æ±‚å¯¼è‡´çš„ç­¾åæ±¡æŸ“ã€‚\n            -   **é²æ£’æ€§å¢å¼º**: å¢åŠ äº†å¯¹æ€ç»´é“¾å ä½ç¬¦ï¼ˆå¦‚ `[undefined]`ï¼‰çš„è¯†åˆ«ä¸è‡ªåŠ¨æ¸…æ´—é€»è¾‘ï¼Œæå‡äº†å¯¹ä¸åŒå®¢æˆ·ç«¯ï¼ˆå¦‚ Cherry Studioï¼‰çš„å…¼å®¹æ€§ã€‚\n            -   **å…¨è·¯å¾„é€ä¼ **: é‡æ„äº†è¯·æ±‚è½¬æ¢ä¸æµå¼å¤„ç†é“¾è·¯ï¼Œç¡®ä¿ Session ä¸Šä¸‹æ–‡åœ¨éæµå¼å’Œæµå¼è¯·æ±‚ä¸­å‡èƒ½ç²¾å‡†ä¼ å¯¼ã€‚\n        -   **[UI å¢å¼º] æ–°å¢æ¨¡å‹å›¾æ ‡æ”¯æŒä¸è‡ªåŠ¨æ’åºåŠŸèƒ½ (PR #1535)**:\n            -   **è§†è§‰å‘ˆç°**: å¼•å…¥ `@lobehub/icons` å›¾æ ‡åº“ï¼Œåœ¨è´¦å·å¡ç‰‡ã€è¡¨æ ¼åŠè¯¦æƒ…é¡µä¸­å±•ç¤ºä¸åŒæ¨¡å‹çš„ brand å›¾æ ‡ï¼Œè§†è§‰ä½“éªŒæ›´ä½³ã€‚\n            -   **æ™ºèƒ½æ’åº**: å®ç°äº†åŸºäºæƒé‡çš„æ¨¡å‹è‡ªåŠ¨æ’åºé€»è¾‘ï¼ˆç³»åˆ— > çº§åˆ« > åç¼€ï¼‰ï¼Œä¼˜å…ˆå±•ç¤ºæœ€å¸¸ç”¨çš„é«˜çº§æ¨¡å‹ï¼ˆå¦‚ Gemini 3 Proï¼‰ã€‚\n            -   **é…ç½®ä¸­å¿ƒåŒ–**: æ„å»ºäº†ç»Ÿä¸€çš„æ¨¡å‹å…ƒæ•°æ®é…ç½®ç³»ç»Ÿï¼Œå°†æ¨¡å‹æ ‡ç­¾ã€çŸ­åç§°ã€å›¾æ ‡ä¸æƒé‡è§£è€¦ï¼Œæå‡ç³»ç»Ÿæ‰©å±•æ€§ã€‚\n            -   **å›½é™…åŒ–åŒæ­¥**: åŒæ­¥è¡¥å…¨äº† 13 ç§å¸¸ç”¨è¯­è¨€çš„æ¨¡å‹æ˜¾ç¤ºåç§°ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] å¢å¼ºè´¦å·ç¦ç”¨çŠ¶æ€ä¸ç£ç›˜çŠ¶æ€å®æ—¶æ ¡éªŒ (PR #1546)**:\n            -   **ç£ç›˜æ·±åº¦æ ¡éªŒ**: å¼•å…¥äº† `get_account_state_on_disk` æœºåˆ¶ï¼Œåœ¨è·å– Token çš„å…³é”®è·¯å¾„å¢åŠ ç£ç›˜çŠ¶æ€äºŒæ¬¡ç¡®è®¤ï¼Œå½»åº•è§£å†³å†…å­˜ç¼“å­˜å»¶è¿Ÿå¯¼è‡´çš„ç¦ç”¨è´¦å·è¯¯é€‰é—®é¢˜ã€‚\n            -   **å›ºå®šè´¦å·æ™ºèƒ½åŒæ­¥**: ä¼˜åŒ–äº† `toggle_proxy_status` æŒ‡ä»¤ï¼Œç¦ç”¨è´¦å·æ—¶ä¼šè‡ªåŠ¨æ£€æŸ¥å¹¶å…³é—­å¯¹åº”çš„å›ºå®šè´¦å·æ¨¡å¼ï¼Œå¹¶ç«‹å³è§¦å‘ä»£ç†æ± é‡è½½ã€‚\n            -   **æˆæƒå¤±æ•ˆè‡ªæ„ˆ**: å½“åç«¯æ£€æµ‹åˆ° `invalid_grant` é”™è¯¯å¹¶è‡ªåŠ¨ç¦ç”¨è´¦å·æ—¶ï¼Œç°åœ¨ä¼šç‰©ç†æ¸…ç†å†…å­˜ä¸­çš„ Tokenã€é™æµè®°å½•å’Œä¼šè¯ç»‘å®šï¼Œç¡®ä¿æ•…éšœè´¦å·å³åˆ»ä¸‹çº¿ã€‚\n            -   **å…¨é“¾è·¯è¿‡æ»¤é€‚é…**: è¡¥å…¨äº†é¢„çƒ­é€»è¾‘ (`Warmup`) ä¸å®šæ—¶è°ƒåº¦å™¨ (`Scheduler`) çš„ç¦ç”¨çŠ¶æ€æ£€æŸ¥ï¼Œå¤§å¹…å‡å°‘æ— æ•ˆçš„åå°ç½‘ç»œè¯·æ±‚ã€‚\n        -   **[æ ¸å¿ƒä¼˜åŒ–] ä»£ç†æ± å¥åº·æ£€æŸ¥å¹¶å‘åŒ– (PR #1547)**:\n            -   **æ€§èƒ½æå‡**: å¼•å…¥äº†åŸºäº `futures` æµçš„å¹¶å‘æ‰§è¡Œæœºåˆ¶ï¼Œå°†é¡ºåºæ£€æŸ¥é‡æ„ä¸ºå¹¶å‘å¤„ç†ï¼ˆå¹¶å‘ä¸Šé™ 20ï¼‰ã€‚\n            -   **æ•ˆç‡å¢å¼º**: æ˜¾è‘—ç¼©çŸ­äº†å¤§å‹ä»£ç†æ± çš„å¥åº·æ£€æŸ¥æ€»æ—¶é•¿ï¼Œæå‡äº†ç³»ç»Ÿå¯¹ä»£ç†çŠ¶æ€å˜æ›´çš„å“åº”é€Ÿåº¦ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] è§£å†³ Docker/HTTP ç¯å¢ƒä¸‹ crypto.randomUUID å…¼å®¹æ€§é—®é¢˜ (Issue #1548)**:\n            -   **é—®é¢˜ä¿®å¤**: ä¿®å¤äº†åœ¨éå®‰å…¨ä¸Šä¸‹æ–‡ï¼ˆå¦‚ HTTP æˆ–éƒ¨åˆ† Docker ç¯å¢ƒï¼‰ä¸­ï¼Œå› æµè§ˆå™¨ç¦ç”¨ `crypto.randomUUID` API å¯¼è‡´çš„åº”ç”¨å´©æºƒï¼ˆ\"Unexpected Application Error\"ï¼‰åŠæ‰¹é‡å¯¼å…¥å¤±è´¥é—®é¢˜ã€‚\n            -   **å…¼å®¹æ€§å¢å¼º**: å¼•å…¥äº†å…¨å¹³å°å…¼å®¹çš„ UUID ç”Ÿæˆå›é€€æœºåˆ¶ï¼Œç¡®ä¿åœ¨ä»»ä½•éƒ¨ç½²ç¯å¢ƒä¸‹ ID ç”Ÿæˆçš„ç¨³å®šæ€§ã€‚\n    *   **v4.1.1 (2026-02-04)**:\n        -   **[æ ¸å¿ƒä¿®å¤] è§£å†³ User Tokens é¡µé¢åœ¨ Web/Docker ç¯å¢ƒä¸‹åŠ è½½å¤±è´¥é—®é¢˜ (Issue #1525)**:\n            -   **API åŒæ­¥**: è¡¥å…¨äº†å‰ç«¯ `request.ts` çš„å‘½ä»¤æ˜ å°„ï¼Œå¹¶æ–°å¢å¯¹ `PATCH` æ–¹æ³•çš„æ”¯æŒï¼Œè§£å†³äº† Web ç«¯å› æ˜ å°„ç¼ºå¤±å¯¼è‡´çš„ API è°ƒç”¨é”™è¯¯ã€‚\n            -   **åç«¯è·¯ç”±è¡¥å…¨**: åœ¨ Axum ç®¡ç†æœåŠ¡å™¨ä¸­æ–°å¢äº† User Token çš„å…¨é‡ç®¡ç†æ¥å£ï¼ˆList/Create/Update/Renew/Deleteï¼‰ï¼Œç¡®ä¿ Headless æ¨¡å¼åŠŸèƒ½å®Œæ•´ã€‚\n        -   **[æ ¸å¿ƒä¼˜åŒ–] æ•°æ®åº“è¿ç§»å¢å¼ºä¸å¹‚ç­‰æ€§æ”¹è¿›**:\n            -   **è‡ªåŠ¨åˆ—è¿ç§»**: å®Œå–„äº† `UserToken` æ•°æ®åº“åˆå§‹åŒ–é€»è¾‘ï¼Œæ”¯æŒä»æ—§ç‰ˆæœ¬è‡ªåŠ¨é€šè¿‡ `ALTER TABLE` è¡¥å…¨ç¼ºå¤±åˆ—ï¼ˆå¦‚ `expires_type`, `max_ips`, `curfew_*` ç­‰ï¼‰ï¼Œæå¤§æå‡äº†ç‰ˆæœ¬å‡çº§çš„ç¨³å®šæ€§ã€‚\n        -   **[Docker ä¼˜åŒ–] æ–°å¢ ABV_DATA_DIR ç¯å¢ƒå˜é‡æ”¯æŒ**:\n            -   **çµæ´»æŒ‚è½½**: å…è®¸ç”¨æˆ·é€šè¿‡ç¯å¢ƒå˜é‡æ˜¾å¼æŒ‡å®šæ•°æ®å­˜å‚¨ç›®å½•ã€‚ç°åœ¨ Docker ç”¨æˆ·å¯ä»¥æ›´æ–¹ä¾¿åœ°æŒ‚è½½å¤–éƒ¨å·è‡³è‡ªå®šä¹‰è·¯å¾„ï¼ˆå¦‚ `-e ABV_DATA_DIR=/app/data`ï¼‰ï¼Œè§£å†³äº†é»˜è®¤éšè—ç›®å½•æƒé™åŠå¯è§æ€§é—®é¢˜ã€‚\n        -   **[æ ¸å¿ƒåŠŸèƒ½] æ›´æ–°æ£€æŸ¥å™¨å¢å¼º (Update Checker 2.0) (PR #1494)**:\n            -   **ä»£ç†æ”¯æŒ**: æ›´æ–°æ£€æŸ¥å™¨ç°åœ¨å®Œå…¨éµå¾ªå…¨å±€ä¸Šæ¸¸ä»£ç†é…ç½®ï¼Œè§£å†³äº†åœ¨å—é™ç½‘ç»œç¯å¢ƒä¸‹æ— æ³•è·å–æ›´æ–°çš„é—®é¢˜ã€‚\n            -   **å¤šçº§é™çº§ç­–ç•¥**: å®ç°äº† `GitHub API -> GitHub Raw -> jsDelivr` çš„ä¸‰å±‚å›é€€æœºåˆ¶ï¼Œæå¤§æå‡äº†ç‰ˆæœ¬æ£€æµ‹çš„æˆåŠŸç‡ã€‚\n            -   **æ¥æºå¯è§‚æµ‹**: æ›´æ–°æç¤ºä¸­ç°åœ¨ä¼šæ˜¾ç¤ºæ£€æµ‹æºä¿¡æ¯ï¼Œæ–¹ä¾¿æ’æŸ¥è¿æ¥é—®é¢˜ã€‚\n        -   **[æ ¸å¿ƒä¼˜åŒ–] Antigravity æ•°æ®åº“æ ¼å¼å…¼å®¹æ€§æ”¹è¿› (>= 1.16.5)**:\n            -   **æ™ºèƒ½ç‰ˆæœ¬æ£€æµ‹**: æ–°å¢è·¨å¹³å°ç‰ˆæœ¬æ£€æµ‹æ¨¡å—ï¼Œæ”¯æŒè‡ªåŠ¨è¯†åˆ« Antigravity å®¢æˆ·ç«¯ç‰ˆæœ¬ï¼ˆmacOS/Windows/Linuxï¼‰ã€‚\n            -   **æ–°æ—§æ ¼å¼é€‚é…**: é€‚é…äº† 1.16.5+ ç‰ˆæœ¬çš„ `antigravityUnifiedStateSync.oauthToken` æ–°æ ¼å¼ï¼Œå¹¶ä¿æŒå¯¹æ—§ç‰ˆæ ¼å¼çš„å‘ä¸‹å…¼å®¹ã€‚\n            -   **æ³¨å…¥ç­–ç•¥å¢å¼º**: å®ç°åŸºäºç‰ˆæœ¬çš„æ™ºèƒ½æ³¨å…¥ç­–ç•¥ï¼Œå¹¶åœ¨æ£€æµ‹å¤±è´¥æ—¶æä¾›åŒé‡æ ¼å¼æ³¨å…¥çš„å®¹é”™æœºåˆ¶ï¼Œç¡®ä¿è´¦å·åˆ‡æ¢æˆåŠŸã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] è§£å†³ react-router SSR XSS æ¼æ´ (CVE-2026-21884) (PR #1500)**:\n            -   **å®‰å…¨ä¿®å¤**: å‡çº§ `react-router` ä¾èµ–è‡³å®‰å…¨ç‰ˆæœ¬ï¼Œä¿®å¤äº† `ScrollRestoration` ç»„ä»¶åœ¨æœåŠ¡ç«¯æ¸²æŸ“ (SSR) æ—¶å¯èƒ½é€ æˆçš„è·¨ç«™è„šæœ¬æ”»å‡» (XSS) é£é™©ã€‚\n        -   **[å›½é™…åŒ–] å®Œå–„æ—¥è¯­ç¿»è¯‘æ”¯æŒ (PR #1524)**:\n            -   **æ”¹è¿›**: è¡¥å…¨äº†ä»£ç†æ± ã€æµé”™è¯¯æ¶ˆæ¯ã€User-Agent ç­‰é‡è¦æ¨¡å—çš„æ—¥è¯­æœ¬åœ°åŒ–ã€‚\n    *   **v4.1.0 (2026-02-04)**:\n        -   **[é‡å¤§æ›´æ–°] ä»£ç†æ±  2.0 (Proxy Pool) å®Œå…¨ä½“ä¸ç¨³å®šæ€§ä¿®å¤**:\n            -   **è´¦å·çº§ä¸“å± IP éš”ç¦»**: å®ç°è´¦å·ä¸ä»£ç†çš„å¼ºç»‘å®šé€»è¾‘ã€‚ä¸€æ—¦è´¦å·ç»‘å®šä¸“å±ä»£ç†ï¼Œè¯¥ IP å°†è‡ªåŠ¨ä»å…¬å…±æ± éš”ç¦»ï¼Œæœç»è·¨è´¦å·å…³è”é£é™©ã€‚\n            -   **åè®®è‡ªåŠ¨è¡¥å…¨ä¸å…¼å®¹æ€§**: åç«¯æ”¯æŒè‡ªåŠ¨è¯†åˆ«ç®€å†™è¾“å…¥ï¼ˆå¦‚ `ip:port`ï¼‰ï¼Œè‡ªåŠ¨è¡¥å…¨ `http://` æ–¹æ¡ˆã€‚\n            -   **æ™ºèƒ½å¥åº·æ£€æŸ¥åŠ å›º**: å¼•å…¥æµè§ˆå™¨ User-Agent ä¼ªè£…ï¼Œè§£å†³ `google.com` æ‹¦æˆªé—®é¢˜ï¼›æ›´æ¢ä¿åº•æ£€æŸ¥ URL è‡³ `cloudflare.com`ã€‚\n            -   **å“åº”å¼çŠ¶æ€åŒæ­¥**: ä¿®å¤â€œå…ˆç¡çœ åæ£€æŸ¥â€é€»è¾‘ï¼Œå®ç°å¯åŠ¨å³æ›´æ–°çŠ¶æ€ï¼Œæ¶ˆé™¤ UI æ˜¾ç¤ºè¶…æ—¶çš„åŒæ­¥å»¶è¿Ÿã€‚\n            -   **æŒä¹…åŒ– Bug ä¿®å¤**: å½»åº•è§£å†³åœ¨é«˜é¢‘ç‡è½®è¯¢ä¸‹ï¼Œåç«¯æ—§çŠ¶æ€å¯èƒ½å›æ»šå‰ç«¯æ–°å¢ä»£ç†çš„ç«æ€é—®é¢˜ã€‚\n        -   **ä»£ç†æ±  2.0 è¿è¡Œæœºåˆ¶è§£æ**:\n            -   **åœºæ™¯ 1ï¼šè´¦å·å…¨é“¾è·¯é”å®š** â€” ç³»ç»Ÿè¯†åˆ«åˆ°è´¦å· A ä¸ Node-01 çš„ç»‘å®šå…³ç³»åï¼Œå…¶ Token åˆ·æ–°ã€é¢åº¦åŒæ­¥ã€AI æ¨ç†å°†å…¨é‡å¼ºåˆ¶èµ° Node-01ã€‚Google ä¾§å§‹ç»ˆæ•è·åˆ°è¯¥è´¦å·åœ¨å•ä¸€ç¨³å®š IP ä¸Šæ“ä½œã€‚\n            -   **åœºæ™¯ 2ï¼šå…¬ç”¨æ± è‡ªåŠ¨éš”ç¦»** â€” è´¦å· B æ— ç»‘å®šã€‚ç³»ç»Ÿåœ¨æ‰«æä»£ç†æ± æ—¶ï¼Œä¼šè‡ªåŠ¨å‘ç° Node-01 å·²è¢« A ä¸“å±å ç”¨å¹¶å°†å…¶å‰”é™¤ï¼Œä»…ä»å‰©ä½™èŠ‚ç‚¹ä¸­è½®è¯¢ã€‚ç¡®ä¿ä¸åŒè´¦å· IP ç»ä¸æ··ç”¨ï¼Œé›¶å…³è”é£é™©ã€‚\n            -   **åœºæ™¯ 3ï¼šæ•…éšœè‡ªæ„ˆä¸ä¿åº•** â€” è‹¥ Node-01 å®•æœºä¸”å¼€å¯äº†â€œæ•…éšœé‡è¯•â€ï¼Œè´¦å· A ä¼šä¸´æ—¶å€Ÿç”¨å…¬å…±æ± èŠ‚ç‚¹å®Œæˆ Token åˆ·æ–°ç­‰ç´§æ€¥ä»»åŠ¡ï¼Œå¹¶è®°å½•æ—¥å¿—ï¼Œç¡®ä¿æœåŠ¡ä¸ä¸­æ–­ã€‚\n        -   **[æ–°åŠŸèƒ½] UserToken é¡µé¢å¯¼èˆªä¸ç›‘æ§å¢å¼º (PR #1475)**:\n            -   **é¡µé¢å¯¼èˆª**: æ–°å¢ UserToken ç‹¬ç«‹ç®¡ç†é¡µé¢ï¼Œæ”¯æŒæ›´ç»†ç²’åº¦çš„ç”¨æˆ·ä»¤ç‰Œç®¡ç†ã€‚\n            -   **ç›‘æ§å¢å¼º**: å®Œå–„äº†ç³»ç»Ÿç›‘æ§å’Œè·¯ç”±åŠŸèƒ½çš„é›†æˆï¼Œæå‡äº†ç³»ç»Ÿçš„å¯è§‚æµ‹æ€§ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] Warmup æ¥å£å­—æ®µä¸¢å¤±ä¿®å¤**:\n            -   **ç¼–è¯‘ä¿®å¤**: ä¿®å¤äº† `ProxyRequestLog` åˆå§‹åŒ–æ—¶ç¼ºå¤± `username` å­—æ®µå¯¼è‡´çš„ç¼–è¯‘é”™è¯¯ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] Docker Warmup 401/502 é”™è¯¯ä¿®å¤ (PR #1479)**:\n            -   **ç½‘ç»œä¼˜åŒ–**: åœ¨ Docker ç¯å¢ƒä¸‹çš„ Warmup è¯·æ±‚ä¸­ï¼Œä½¿ç”¨äº†å¸¦ `.no_proxy()` çš„å®¢æˆ·ç«¯ï¼Œé˜²æ­¢ localhost è¯·æ±‚è¢«é”™è¯¯è·¯ç”±åˆ°å¤–éƒ¨ä»£ç†å¯¼è‡´ 502/401 é”™è¯¯ã€‚\n            -   **é‰´æƒå˜æ›´**: è±å…äº† `/internal/*` è·¯å¾„çš„é‰´æƒï¼Œç¡®ä¿å†…éƒ¨é¢„çƒ­è¯·æ±‚ä¸ä¼šè¢«æ‹¦æˆªã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] Docker/Headless ç¯å¢ƒè°ƒè¯•ä¸ç»‘å®šé—®é¢˜ä¿®å¤**:\n            -   **è°ƒè¯•æ§åˆ¶å°**: ä¿®å¤äº† Docker æ¨¡å¼ä¸‹æ—¥å¿—æ¨¡å—æœªåˆå§‹åŒ–çš„é—®é¢˜ï¼Œå¹¶æ–°å¢ HTTP API æ˜ å°„ï¼Œæ”¯æŒ Web å‰ç«¯è·å–å®æ—¶æ—¥å¿—ã€‚\n            -   **æŒ‡çº¹ç»‘å®š**: ä¼˜åŒ–äº†è®¾å¤‡æŒ‡çº¹ç»‘å®šé€»è¾‘ï¼Œç¡®ä¿å…¶åœ¨ Docker å®¹å™¨ç¯å¢ƒä¸‹çš„å…¼å®¹æ€§å¹¶æ”¯æŒé€šè¿‡ API å®Œæ•´è°ƒç”¨ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] è´¦å·åˆ é™¤ç¼“å­˜åŒæ­¥ä¿®å¤ (Issue #1477)**:\n            -   **åŒæ­¥æœºåˆ¶**: å¼•å…¥äº†å…¨å±€åˆ é™¤ä¿¡å·åŒæ­¥é˜Ÿåˆ—ï¼Œç¡®ä¿è´¦å·åœ¨ç£ç›˜åˆ é™¤åå³åˆ»ä»å†…å­˜ç¼“å­˜ä¸­å‰”é™¤ã€‚\n            -   **å½»åº•æ¸…ç†**: TokenManager ç°åœ¨ä¼šåŒæ­¥æ¸…ç†å·²åˆ é™¤è´¦å·çš„ä»¤ç‰Œã€å¥åº·åˆ†æ•°ã€é™æµè®°å½•ä»¥åŠä¼šè¯ç»‘å®šï¼Œå½»åº•è§£å†³â€œå·²åˆ é™¤è´¦å·ä»è¢«è°ƒåº¦â€çš„é—®é¢˜ã€‚\n        -   **[UI ä¼˜åŒ–] æ›´æ–°é€šçŸ¥æœ¬åœ°åŒ– (PR #1484)**:\n            -   **å›½é™…åŒ–é€‚é…**: å½»åº•ç§»é™¤äº†æ›´æ–°æç¤ºæ¡†ä¸­çš„ç¡¬ç¼–ç å­—ç¬¦ä¸²ï¼Œå®ç°äº†å¯¹æ‰€æœ‰ 12 ç§è¯­è¨€çš„å®Œæ•´æ”¯æŒã€‚\n        -   **[UI ä¼˜åŒ–] å¯¼èˆªæ é‡æ„ä¸å“åº”å¼é€‚é… (PR #1493)**:\n            -   **ç»„ä»¶è§£æ„**: å°†å•ä½“ Navbar æ‹†åˆ†ä¸ºæ›´ç»†ç²’åº¦çš„æ¨¡å—åŒ–ç»„ä»¶ï¼Œæå‡ä»£ç å¯ç»´æŠ¤æ€§ã€‚\n            -   **å“åº”å¼å¢å¼º**: ä¼˜åŒ–äº†å¸ƒå±€æ–­ç‚¹åŠâ€œåˆ·æ–°é…é¢â€æŒ‰é’®çš„å“åº”å¼è¡Œä¸ºã€‚\n    *   **v4.0.15 (2026-02-03)**:\n        -   **[æ ¸å¿ƒä¼˜åŒ–] é¢„çƒ­åŠŸèƒ½å¢å¼ºä¸è¯¯æŠ¥ä¿®å¤ (PR #1466)**:\n            -   **æ¨¡å¼ä¼˜åŒ–**: ç§»é™¤ç¡¬ç¼–ç æ¨¡å‹ç™½åå•ï¼Œæ”¯æŒå¯¹æ‰€æœ‰è¾¾åˆ° 100% é…é¢çš„æ¨¡å‹è‡ªåŠ¨è§¦å‘é¢„çƒ­ã€‚\n            -   **å‡†ç¡®æ€§ä¿®å¤**: ä¿®å¤äº†é¢„çƒ­çŠ¶æ€çš„è¯¯æŠ¥é—®é¢˜ï¼Œç¡®ä¿ä»…åœ¨é¢„çƒ­çœŸæ­£æˆåŠŸæ—¶è®°å½•å†å²ã€‚\n            -   **åŠŸèƒ½æ‰©å±•**: ä¼˜åŒ–äº†é¢„çƒ­è¯·æ±‚çš„æµé‡æ—¥å¿—è®°å½•ï¼Œå¹¶è·³è¿‡ä¸æ”¯æŒé¢„çƒ­çš„ 2.5 ç³»åˆ—æ¨¡å‹ã€‚\n        -   **[æ ¸å¿ƒä¼˜åŒ–] æ€è€ƒé¢„ç®— (Thinking Budget) å…¨é¢å›½é™…åŒ–ä¸ä¼˜åŒ–**:\n            -   **å¤šè¯­è¨€é€‚é…**: è¡¥å…¨å¹¶ä¼˜åŒ–äº†ä¸­ã€è‹±ã€æ—¥ã€éŸ©ã€ä¿„ã€è¥¿ã€ç¹ä½“ã€é˜¿ç­‰å¤šå›½è¯­è¨€çš„ç¿»è¯‘ï¼Œç¡®ä¿å…¨çƒç”¨æˆ·ä½“éªŒä¸€è‡´ã€‚\n            -   **UI ç»†èŠ‚å¢å¼º**: ä¼˜åŒ–äº†è®¾ç½®é¡¹çš„æç¤ºè¯­ï¼ˆAuto Hint / Passthrough Warningï¼‰ï¼Œå¸®åŠ©ç”¨æˆ·æ›´å‡†ç¡®åœ°é…ç½®æ¨¡å‹æ€è€ƒæ·±åº¦ã€‚\n    *   **v4.0.14 (2026-02-02)**:\n        -   **[æ ¸å¿ƒä¿®å¤] è§£å†³ Web/Docker éƒ¨ç½²ä¸‹ API Key éšæœºå˜æ›´é—®é¢˜ (Issue #1460)**:\n            -   **é—®é¢˜ä¿®å¤**: ä¿®å¤äº†åœ¨æ²¡æœ‰é…ç½®æ–‡ä»¶çš„æƒ…å†µä¸‹ï¼Œæ¯æ¬¡åˆ·æ–°é¡µé¢éƒ½ä¼šé‡æ–°ç”Ÿæˆ API Key çš„ Bugã€‚\n            -   **é€»è¾‘ä¼˜åŒ–**: ä¼˜åŒ–äº†é…ç½®åŠ è½½æµç¨‹ï¼Œç¡®ä¿é¦–æ¬¡ç”Ÿæˆçš„éšæœº Key è¢«æ­£ç¡®æŒä¹…åŒ–ï¼›åŒæ—¶ä¹Ÿç¡®ä¿äº† Headless æ¨¡å¼ä¸‹ç¯å¢ƒå˜é‡ï¼ˆå¦‚ `ABV_API_KEY`ï¼‰çš„è¦†ç›–èƒ½å¤Ÿè¢«å‰ç«¯æ­£ç¡®è·å–ã€‚\n        -   **[æ ¸å¿ƒåŠŸèƒ½] å¯é…ç½®æ€è€ƒé¢„ç®— (Thinking Budget) (PR #1456)**:\n            -   **é¢„ç®—æ§åˆ¶**: åœ¨ç³»ç»Ÿè®¾ç½®ä¸­æ–°å¢äº†â€œæ€è€ƒé¢„ç®—â€é…ç½®é¡¹ã€‚\n            -   **æ™ºèƒ½é€‚é…**: æ”¯æŒä¸º Claude 3.7+ å’Œ Gemini 2.0 Flash Thinking ç­‰æ¨¡å‹è‡ªå®šä¹‰æœ€å¤§æ€è€ƒ token é™åˆ¶ã€‚\n            -   **é»˜è®¤ä¼˜åŒ–**: é»˜è®¤å€¼è®¾ç½®ä¸ºæ™ºèƒ½é€‚é…æ¨¡å¼ï¼Œç¡®ä¿åœ¨å¤§å¤šæ•°åœºæ™¯ä¸‹ä¸ä»…èƒ½è·å¾—å®Œæ•´æ€è€ƒè¿‡ç¨‹ï¼Œåˆèƒ½é¿å…è§¦å‘ä¸Šæ¸¸ budget é™åˆ¶ã€‚\n    *   **v4.0.13 (2026-02-02)**:\n        -   **[æ ¸å¿ƒä¼˜åŒ–] è´Ÿè½½å‡è¡¡ç®—æ³•å‡çº§ (P2C Algorithm) (PR #1433)**:\n            -   **ç®—æ³•å‡çº§**: å°†åŸæœ‰çš„ Round-Robin (è½®è¯¢) ç®—æ³•å‡çº§ä¸º P2C (Power of Two Choices) è´Ÿè½½å‡è¡¡ç®—æ³•ã€‚\n            -   **æ€§èƒ½æå‡**: åœ¨é«˜å¹¶å‘åœºæ™¯ä¸‹æ˜¾è‘—å‡å°‘äº†è¯·æ±‚ç­‰å¾…æ—¶é—´ï¼Œå¹¶ä¼˜åŒ–äº†åç«¯å®ä¾‹çš„è´Ÿè½½åˆ†å¸ƒï¼Œé¿å…äº†å•ç‚¹è¿‡è½½ã€‚\n        -   **[UI å‡çº§] å“åº”å¼å¯¼èˆªæ ä¸å¸ƒå±€ä¼˜åŒ– (Responsive Navbar) (PR #1429)**:\n            -   **ç§»åŠ¨ç«¯é€‚é…**: å…¨æ–°è®¾è®¡çš„å“åº”å¼å¯¼èˆªæ ï¼Œå®Œç¾é€‚é…ç§»åŠ¨è®¾å¤‡ä¸å°å±å¹•çª—å£ã€‚\n            -   **è§†è§‰å¢å¼º**: ä¸ºå¯¼èˆªé¡¹æ·»åŠ äº†ç›´è§‚çš„å›¾æ ‡ï¼Œæå‡äº†æ•´ä½“è§†è§‰ä½“éªŒä¸æ“ä½œä¾¿æ·æ€§ã€‚\n        -   **[æ–°åŠŸèƒ½] è´¦å·é…é¢å¯è§†åŒ–å¢å¼º (Show All Quotas) (PR #1429)**:\n            -   **æ˜¾ç¤ºæ‰€æœ‰é…é¢**: åœ¨è´¦å·åˆ—è¡¨é¡µæ–°å¢â€œæ˜¾ç¤ºæ‰€æœ‰é…é¢â€å¼€å…³ã€‚å¼€å¯åå¯ä¸€è§ˆ Ultra/Pro/Free/Image ç­‰æ‰€æœ‰ç»´åº¦çš„å®æ—¶é…é¢ä¿¡æ¯ï¼Œä¸å†ä»…æ˜¾ç¤ºé¦–è¦é…é¢ã€‚\n        -   **[å›½é™…åŒ–] å…¨é¢å¤šè¯­è¨€æ”¯æŒå®Œå–„ (Full i18n Update)**:\n            -   **è¦†ç›–ç‡æå‡**: è¡¥å…¨äº†ç¹ä½“ä¸­æ–‡ã€æ—¥è¯­ã€éŸ©è¯­ã€è¥¿ç­ç‰™è¯­ã€é˜¿æ‹‰ä¼¯è¯­ç­‰ 10 ç§è¯­è¨€çš„ç¼ºå¤±ç¿»è¯‘é”®å€¼ã€‚\n            -   **ç»†èŠ‚ä¼˜åŒ–**: ä¿®å¤äº†â€œæ˜¾ç¤ºæ‰€æœ‰é…é¢â€åŠ OAuth æˆæƒæµç¨‹ä¸­çš„æç¤ºè¯­ç¿»è¯‘ç¼ºå¤±é—®é¢˜ã€‚\n        -   **[å›½é™…åŒ–] åå°ä»»åŠ¡ç¿»è¯‘è¡¥å…¨ (Translate Background Tasks) (PR #1421)**:\n            -   **ç¿»è¯‘ä¿®å¤**: ä¿®å¤äº†åå°ä»»åŠ¡ï¼ˆå¦‚æ ‡é¢˜ç”Ÿæˆï¼‰çš„ç›¸å…³æ–‡æœ¬ç¼ºå°‘ç¿»è¯‘çš„é—®é¢˜ï¼Œç°åœ¨æ”¯æŒæ‰€æœ‰è¯­è¨€çš„æœ¬åœ°åŒ–æ˜¾ç¤ºã€‚\n            - **å½’å› **: ä¿®å¤äº†åˆå¹¶ä»£ç æ—¶å¼•å…¥çš„ `ref` å†²çªå¯¼è‡´ç§»åŠ¨ç«¯/æ¡Œé¢ç«¯ç‚¹å‡»åˆ¤å®šå¼‚å¸¸ã€‚\n            - **ç»“æœ**: è¯­è¨€åˆ‡æ¢èœå•ç°åœ¨å¯ä»¥æ­£å¸¸æ‰“å¼€å’Œäº¤äº’ã€‚\n        -   **[Docker/Web ä¿®å¤] Web ç«¯æ”¯æŒ IP ç®¡ç† (IP Security for Web)**:\n            - **åŠŸèƒ½è¡¥å…¨**: ä¿®å¤äº†åœ¨ Docker æˆ– Web æ¨¡å¼ä¸‹ï¼ŒIP å®‰å…¨ç®¡ç†åŠŸèƒ½ï¼ˆæ—¥å¿—ã€é»‘ç™½åå•ï¼‰å› åç«¯è·¯ç”±ç¼ºå¤±è€Œæ— æ³•ä½¿ç”¨çš„é—®é¢˜ã€‚\n            - **API å®ç°**: å®ç°äº†å®Œæ•´çš„ RESTful ç®¡ç†æ¥å£ï¼Œç¡®ä¿ Web å‰ç«¯èƒ½æ­£å¸¸è°ƒç”¨åº•å±‚å®‰å…¨æ¨¡å—ã€‚\n            - **ä½“éªŒå¼ºåŒ–**: ä¼˜åŒ–äº†åˆ é™¤æ“ä½œçš„å‚æ•°ä¼ é€’é€»è¾‘ï¼Œè§£å†³äº†éƒ¨åˆ†æµè§ˆå™¨ä¸‹åˆ é™¤é»‘ç™½åå•å¤±çµçš„é—®é¢˜ã€‚\n    *   **v4.0.12 (2026-02-01)**:\n        -   **[ä»£ç é‡æ„] è¿æ¥å™¨æœåŠ¡ä¼˜åŒ– (Refactor Connector Service)**:\n            -   **æ·±åº¦ä¼˜åŒ–**: é‡å†™äº†è¿æ¥å™¨æœåŠ¡ (`connector.rs`) çš„æ ¸å¿ƒé€»è¾‘ï¼Œæ¶ˆé™¤äº†å†å²é—ç•™çš„ä½æ•ˆä»£ç ã€‚\n            -   **æ€§èƒ½æå‡**: ä¼˜åŒ–äº†è¿æ¥å»ºç«‹ä¸å¤„ç†æµç¨‹ï¼Œæå‡äº†ç³»ç»Ÿçš„æ•´ä½“ç¨³å®šæ€§ä¸å“åº”é€Ÿåº¦ã€‚\n    *   **v4.0.11 (2026-01-31)**:\n        -   **[æ ¸å¿ƒä¿®å¤] è°ƒæ•´ API ç«¯ç‚¹é¡ºåºä¸è‡ªåŠ¨é˜»æ–­ (Fix 403 VALIDATION_REQUIRED)**:\n            -   **ç«¯ç‚¹é¡ºåºä¼˜åŒ–**: å°† Google API çš„è¯·æ±‚é¡ºåºè°ƒæ•´ä¸º `Sandbox -> Daily -> Prod`ã€‚ä¼˜å…ˆä½¿ç”¨å®½æ¾ç¯å¢ƒï¼Œä»æºå¤´å‡å°‘ 403 é”™è¯¯çš„å‘ç”Ÿã€‚\n            -   **æ™ºèƒ½é˜»æ–­æœºåˆ¶**: å½“æ£€æµ‹åˆ° `VALIDATION_REQUIRED` (403) é”™è¯¯æ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å°†è¯¥è´¦å·æ ‡è®°ä¸ºâ€œä¸´æ—¶é˜»æ–­â€çŠ¶æ€å¹¶æŒç»­ 10 åˆ†é’Ÿã€‚æœŸé—´è¯·æ±‚ä¼šè‡ªåŠ¨è·³è¿‡è¯¥è´¦å·ï¼Œé¿å…æ— æ•ˆé‡è¯•å¯¼è‡´è´¦å·è¢«è¿›ä¸€æ­¥é£æ§ã€‚\n            -   **è‡ªåŠ¨æ¢å¤**: é˜»æ–­æœŸè¿‡åï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å°è¯•æ¢å¤è¯¥è´¦å·çš„ä½¿ç”¨ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] è´¦å·çŠ¶æ€çƒ­é‡è½½ (Account Hot-Reload)**:\n            -   **æ¶æ„ç»Ÿä¸€**: æ¶ˆé™¤äº†ç³»ç»Ÿä¸­å¹¶å­˜çš„å¤šä¸ª `TokenManager` å®ä¾‹ï¼Œå®ç°äº†ç®¡ç†åå°ä¸åä»£æœåŠ¡å…±äº«å•ä¾‹è´¦å·ç®¡ç†å™¨ã€‚\n            -   **å®æ—¶ç”Ÿæ•ˆ**: ä¿®å¤äº†æ‰‹åŠ¨å¯ç”¨/ç¦ç”¨è´¦å·ã€è´¦å·é‡æ’åºåŠæ‰¹é‡æ“ä½œåéœ€è¦é‡å¯åº”ç”¨æ‰èƒ½ç”Ÿæ•ˆçš„é—®é¢˜ã€‚ç°åœ¨æ‰€æœ‰è´¦å·å˜æ›´éƒ½ä¼šç«‹å³åŒæ­¥è‡³å†…å­˜è´¦å·æ± ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] é…é¢ä¿æŠ¤é€»è¾‘ä¼˜åŒ– (PR #1344 è¡¥ä¸)**:\n            -   è¿›ä¸€æ­¥ä¼˜åŒ–äº†é…é¢ä¿æŠ¤é€»è¾‘ä¸­å¯¹â€œå·²ç¦ç”¨â€çŠ¶æ€ä¸â€œé…é¢ä¿æŠ¤â€çŠ¶æ€çš„åŒºåˆ†é€»è¾‘ï¼Œç¡®ä¿æ—¥å¿—è®°å½•å‡†ç¡®ä¸”çŠ¶æ€åŒæ­¥å®æ—¶ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] æ¢å¤å¥åº·æ£€æŸ¥æ¥å£ (PR #1364)**:\n            -   **è·¯ç”±æ¢å¤**: ä¿®å¤äº†åœ¨ 4.0.0 æ¶æ„è¿ç§»ä¸­é—å¤±çš„ `/health` å’Œ `/healthz` è·¯ç”±ã€‚\n            -   **å“åº”å¢å¼º**: æ¥å£ç°åœ¨ä¼šè¿”å›åŒ…å« `\"status\": \"ok\"` å’Œå½“å‰åº”ç”¨ç‰ˆæœ¬å·çš„ JSONï¼Œæ–¹ä¾¿ç›‘æ§ç³»ç»Ÿè¿›è¡Œç‰ˆæœ¬åŒ¹é…å’Œå­˜æ´»æ£€æŸ¥ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] ä¿®å¤ Gemini Flash æ¨¡å‹æ€è€ƒé¢„ç®—è¶…é™ (Fix PR #1355)**:\n            -   **è‡ªåŠ¨é™é¢**: ä¿®å¤äº†åœ¨ Gemini Flash æ€è€ƒæ¨¡å‹ï¼ˆå¦‚ `gemini-2.0-flash-thinking`ï¼‰ä¸­ï¼Œé»˜è®¤æˆ–ä¸Šæ¸¸ä¼ å…¥çš„ `thinking_budget` (ä¾‹å¦‚ 32k) è¶…è¿‡æ¨¡å‹ä¸Šé™ (24k) å¯¼è‡´ API æŠ¥é”™ `400 Bad Request` çš„é—®é¢˜ã€‚\n            -   **å¤šåè®®è¦†ç›–**: æ­¤é˜²æŠ¤å·²æ‰©å±•è‡³ **OpenAIã€Claude å’ŒåŸç”Ÿ Gemini åè®®**ï¼Œå…¨æ–¹ä½æ‹¦æˆªä¸å®‰å…¨çš„é¢„ç®—é…ç½®ã€‚\n            -   **æ™ºèƒ½æˆªæ–­**: ç³»ç»Ÿç°åœ¨ä¼šè‡ªåŠ¨æ£€æµ‹ Flash ç³»åˆ—æ¨¡å‹ï¼Œå¹¶å¼ºåˆ¶å°†æ€è€ƒé¢„é¢„ç®—é™åˆ¶åœ¨å®‰å…¨èŒƒå›´å†… (**24,576**)ï¼Œç¡®ä¿è¯·æ±‚å§‹ç»ˆæˆåŠŸï¼Œæ— éœ€ç”¨æˆ·æ‰‹åŠ¨è°ƒæ•´å®¢æˆ·ç«¯é…ç½®ã€‚\n        -   **[æ ¸å¿ƒåŠŸèƒ½] IP å®‰å…¨ä¸é£æ§ç³»ç»Ÿ (IP Security & Management) (PR #1369 by @å¤§é»„)**:\n            -   **å¯è§†åŒ–å·¥å•ç®¡ç†**: å…¨æ–°çš„â€œå®‰å…¨ç›‘æ§â€æ¨¡å—ï¼Œæ”¯æŒå›¾å½¢åŒ–ç®¡ç† IP é»‘åå•ä¸ç™½åå•ã€‚\n            -   **æ™ºèƒ½å°ç¦ç­–ç•¥**: å®ç°äº†åŸºäº CIDR çš„ç½‘æ®µå°ç¦ã€è‡ªåŠ¨é‡Šæ”¾æ—¶é—´è®¾ç½®åŠå°ç¦åŸå› å¤‡æ³¨åŠŸèƒ½ã€‚\n            -   **å®æ—¶è®¿é—®æ—¥å¿—**: é›†æˆäº† IP ç»´åº¦çš„å®æ—¶è®¿é—®æ—¥å¿—å®¡è®¡ï¼Œæ”¯æŒæŒ‰ IPã€æ—¶é—´èŒƒå›´ç­›é€‰ï¼Œæ–¹ä¾¿å¿«é€Ÿå®šä½å¼‚å¸¸æµé‡ã€‚\n        -   **[UI ä¼˜åŒ–] æè‡´çš„è§†è§‰ä½“éªŒ**:\n            -   **å¼¹çª—ç¾åŒ–**: å…¨é¢å‡çº§äº† IP å®‰å…¨æ¨¡å—çš„æ‰€æœ‰å¼¹çª—æŒ‰é’®æ ·å¼ï¼Œé‡‡ç”¨å®å¿ƒè‰²å—ä¸é˜´å½±è®¾è®¡ï¼Œæ“ä½œå¼•å¯¼æ›´æ¸…æ™°ã€‚\n            -   **å¸ƒå±€å³å…´**: ä¿®å¤äº†å®‰å…¨é…ç½®é¡µé¢çš„æ»šåŠ¨æ¡å¼‚å¸¸ä¸å¸ƒå±€é”™ä½ï¼Œä¼˜åŒ–äº†æ ‡ç­¾é¡µåˆ‡æ¢ä½“éªŒã€‚\n        -   **[æ ¸å¿ƒåŠŸèƒ½] è°ƒè¯•æ§åˆ¶å° (Debug Console) (PR #1385)**:\n            -   **å®æ—¶æ—¥å¿—æµ**: å¼•å…¥äº†å…¨åŠŸèƒ½çš„è°ƒè¯•æ§åˆ¶å°ï¼Œæ”¯æŒå®æ—¶æ•è·å¹¶å±•ç¤ºåç«¯ä¸šåŠ¡æ—¥å¿—ã€‚\n            -   **è¿‡æ»¤ä¸æœç´¢**: æ”¯æŒæŒ‰æ—¥å¿—çº§åˆ«ï¼ˆInfo, Debug, Warn, Errorï¼‰è¿‡æ»¤åŠå…³é”®è¯å…¨å±€æœç´¢ã€‚\n            -   **äº¤äº’ä¼˜åŒ–**: æ”¯æŒä¸€é”®æ¸…ç©ºæ—¥å¿—ã€è‡ªåŠ¨æ»šåŠ¨å¼€å…³ï¼Œå¹¶å®Œæ•´é€‚é…æ·±è‰²/æµ…è‰²ä¸»é¢˜ã€‚\n            -   **åç«¯æ¡¥æ¥**: å®ç°äº†é«˜æ€§èƒ½çš„æ—¥å¿—æ¡¥æ¥å™¨ï¼Œç¡®ä¿æ—¥å¿—æ•è·ä¸å½±å“åä»£æ€§èƒ½ã€‚\n    *   **v4.0.9 (2026-01-30)**:\n        -   **[æ ¸å¿ƒåŠŸèƒ½] User-Agent è‡ªå®šä¹‰ä¸ç‰ˆæœ¬æ¬ºéª— (PR #1325)**:\n            - **åŠ¨æ€è¦†ç›–**: æ”¯æŒåœ¨â€œæœåŠ¡é…ç½®â€ä¸­è‡ªå®šä¹‰ä¸Šæ¸¸è¯·æ±‚çš„ `User-Agent` å¤´éƒ¨ã€‚è¿™å…è®¸ç”¨æˆ·æ¨¡æ‹Ÿä»»æ„å®¢æˆ·ç«¯ç‰ˆæœ¬ï¼ˆå¦‚ Cheat æ¨¡å¼ï¼‰ï¼Œæœ‰æ•ˆç»•è¿‡éƒ¨åˆ†åœ°åŒºçš„ç‰ˆæœ¬å°é”æˆ–é£æ§é™åˆ¶ã€‚\n            - **æ™ºèƒ½å›é€€**: å®ç°äº†â€œè¿œç¨‹æŠ“å– -> Cargo ç‰ˆæœ¬ -> ç¡¬ç¼–ç â€çš„ä¸‰çº§ç‰ˆæœ¬å·è·å–æœºåˆ¶ã€‚å½“ä¸»ç‰ˆæœ¬ API ä¸å¯ç”¨æ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è§£æå®˜ç½‘ Changelog é¡µé¢è·å–æœ€æ–°ç‰ˆæœ¬å·ï¼Œç¡®ä¿ UA å§‹ç»ˆä¼ªè£…æˆæœ€æ–°ç‰ˆå®¢æˆ·ç«¯ã€‚\n            - **çƒ­æ›´æ–°æ”¯æŒ**: ä¿®æ”¹ UA é…ç½®åå³åˆ»ç”Ÿæ•ˆï¼Œæ— éœ€é‡å¯æœåŠ¡ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] è§£å†³é…é¢ä¿æŠ¤çŠ¶æ€åŒæ­¥ç¼ºé™· (Issue #1344)**:\n            - **çŠ¶æ€å®æ—¶åŒæ­¥**: ä¿®å¤äº† `check_and_protect_quota()` å‡½æ•°åœ¨å¤„ç†ç¦ç”¨è´¦å·æ—¶æå‰é€€å‡ºçš„é€»è¾‘ç¼ºé™·ã€‚ç°åœ¨å³ä¾¿è´¦å·è¢«ç¦ç”¨ï¼Œç³»ç»Ÿä»ä¼šæ‰«æå¹¶å®æ—¶æ›´æ–°å…¶ `protected_models`ï¼ˆæ¨¡å‹çº§ä¿æŠ¤åˆ—è¡¨ï¼‰ï¼Œç¡®ä¿é…é¢ä¸è¶³çš„è´¦å·åœ¨é‡æ–°å¯ç”¨åä¸ä¼šç»•è¿‡ä¿æŠ¤æœºåˆ¶ç»§ç»­è¢«ä½¿ç”¨ã€‚\n            - **æ—¥å¿—è·¯å¾„åˆ†ç¦»**: å°†æ‰‹åŠ¨ç¦ç”¨æ£€æŸ¥ä»é…é¢ä¿æŠ¤å‡½æ•°ä¸­å‰¥ç¦»è‡³è°ƒç”¨æ–¹ï¼Œæ ¹æ®ä¸åŒçš„è·³è¿‡åŸå› ï¼ˆæ‰‹åŠ¨ç¦ç”¨/é…é¢ä¿æŠ¤ï¼‰è®°å½•å‡†ç¡®çš„æ—¥å¿—ï¼Œæ¶ˆé™¤ç”¨æˆ·å›°æƒ‘ã€‚\n        -   **[æ ¸å¿ƒåŠŸèƒ½] ç¼“å­˜ç®¡ç†ä¸ä¸€é”®æ¸…ç† (PR #1346)**:\n            - **åç«¯é›†æˆ**: æ–°å¢äº† `src-tauri/src/modules/cache.rs` æ¨¡å—ï¼Œç”¨äºè®¡ç®—å’Œç®¡ç†åº”ç”¨è¿è¡ŒæœŸé—´äº§ç”Ÿçš„å„ç±»ä¸´æ—¶æ–‡ä»¶åˆ†å¸ƒï¼ˆå¦‚ç¿»è¯‘ç¼“å­˜ã€æ—¥å¿—æŒ‡çº¹ç­‰ï¼‰ã€‚\n            - **UI å®ç°**: åœ¨â€œç³»ç»Ÿè®¾ç½®â€é¡µé¢æ–°å¢äº†â€œæ¸…ç†ç¼“å­˜â€åŠŸèƒ½ã€‚ç”¨æˆ·å¯ä»¥å®æ—¶æŸ¥çœ‹ç¼“å­˜å ç”¨çš„ç©ºé—´å¤§å°ï¼Œå¹¶æ”¯æŒä¸€é”®æ¸…ç†ï¼Œæœ‰æ•ˆè§£å†³é•¿æœŸä½¿ç”¨åçš„ç£ç›˜å ç”¨é—®é¢˜ã€‚\n        -   **[å›½é™…åŒ–] æ–°å¢è¯­è¨€æ”¯æŒ (PR #1346)**:\n            - æ–°å¢äº† **è¥¿ç­ç‰™è¯­ (es)** å’Œ **é©¬æ¥è¯­ (my)** çš„å®Œæ•´ç¿»è¯‘æ”¯æŒï¼Œè¿›ä¸€æ­¥æ‰©å¤§äº†åº”ç”¨çš„å…¨çƒé€‚ç”¨èŒƒå›´ã€‚\n        -   **[å›½é™…åŒ–] å…¨è¯­è¨€è¦†ç›–**:\n            - ä¸ºæ–°åŠŸèƒ½è¡¥å…¨äº† En, Zh, Zh-TW, Ar, Ja, Ko, Pt, Ru, Tr, Vi ç­‰ 10 ç§è¯­è¨€çš„å®Œæ•´ç¿»è¯‘æ”¯æŒã€‚\n        -   **[å›½é™…åŒ–] å®Œå–„ UI å­—ç¬¦ä¸²æœ¬åœ°åŒ– (PR #1350)**:\n            - **å…¨é¢è¦†ç›–**: è¡¥å……äº† UI ä¸­å‰©ä½™çš„ç¡¬ç¼–ç å­—ç¬¦ä¸²åŠæœªç¿»è¯‘é¡¹ï¼Œå®ç°äº†ç•Œé¢å­—ç¬¦ä¸²çš„å®Œå…¨æœ¬åœ°åŒ–ã€‚\n            - **æ¸…ç†å†—ä½™**: åˆ é™¤äº†ä»£ç ä¸­æ‰€æœ‰çš„è‹±æ–‡å›é€€ (English fallbacks)ï¼Œå¼ºåˆ¶æ‰€æœ‰ç»„ä»¶é€šè¿‡ i18n é”®è°ƒç”¨è¯­è¨€åŒ…ã€‚\n            - **è¯­è¨€å¢å¼º**: æ˜¾è‘—æå‡äº†æ—¥è¯­ (ja) ç­‰è¯­è¨€çš„ç¿»è¯‘å‡†ç¡®åº¦ï¼Œå¹¶ç¡®ä¿äº†æ–° UI ç»„ä»¶åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„æ˜¾ç¤ºä¸€è‡´æ€§ã€‚\n    *   **v4.0.8 (2026-01-30)**:\n        -   **[æ ¸å¿ƒåŠŸèƒ½] è®°å¿†çª—å£ä½ç½®ä¸å¤§å° (PR #1322)**: è‡ªåŠ¨æ¢å¤ä¸Šæ¬¡å…³é—­æ—¶çš„çª—å£åæ ‡ä¸å°ºå¯¸ï¼Œæå‡ä½¿ç”¨ä½“éªŒã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] ä¼˜é›…å…³é—­ Admin Server (PR #1323)**: ä¿®å¤äº† Windows ç¯å¢ƒä¸‹é€€å‡ºåå†æ¬¡å¯åŠ¨æ—¶ï¼Œç«¯å£ 8045 å ç”¨å¯¼è‡´çš„ç»‘å®šå¤±è´¥é—®é¢˜ã€‚\n        -   **[æ ¸å¿ƒåŠŸèƒ½] å®ç°å…¨é“¾è·¯è°ƒè¯•æ—¥å¿—åŠŸèƒ½ (PR #1308)**:\n            - **åç«¯é›†æˆ**: å¼•å…¥äº† `debug_logger.rs`ï¼Œæ”¯æŒæ•è·å¹¶è®°å½• OpenAIã€Claude åŠ Gemini å¤„ç†å™¨çš„åŸå§‹è¯·æ±‚ã€è½¬æ¢åæŠ¥æ–‡åŠå®Œæ•´æµå¼å“åº”ã€‚\n            - **åŠ¨æ€é…ç½®**: æ”¯æŒçƒ­åŠ è½½æ—¥å¿—é…ç½®ï¼Œæ— éœ€é‡å¯æœåŠ¡å³å¯å¯ç”¨/ç¦ç”¨æˆ–ä¿®æ”¹è¾“å‡ºç›®å½•ã€‚\n            - **å‰ç«¯äº¤äº’**: åœ¨â€œé«˜çº§è®¾ç½®â€ä¸­æ–°å¢â€œè°ƒè¯•æ—¥å¿—â€å¼€å…³åŠè‡ªå®šä¹‰è¾“å‡ºç›®å½•é€‰æ‹©å™¨ï¼Œæ–¹ä¾¿å¼€å‘è€…æ’æŸ¥åè®®è½¬æ¢ä¸ä¸Šæ¸¸é€šä¿¡é—®é¢˜ã€‚\n        -   **[UI ä¼˜åŒ–] ä¼˜åŒ–å›¾è¡¨å·¥å…·æç¤º (Tooltip) æµ®åŠ¨æ˜¾ç¤ºé€»è¾‘ (Issue #1263, PR #1307)**:\n            - **æº¢å‡ºé˜²å¾¡**: ä¼˜åŒ–äº† `TokenStats.tsx` ä¸­çš„ Tooltip å®šä½ç®—æ³•ï¼Œç¡®ä¿åœ¨å°çª—å£æˆ–é«˜ç¼©æ”¾æ¯”ä¾‹ä¸‹ï¼Œæ‚¬æµ®æç¤ºä¿¡æ¯å§‹ç»ˆåœ¨å¯è§†åŒºåŸŸå†…æ˜¾ç¤ºï¼Œé˜²æ­¢è¢«çª—å£è¾¹ç•Œé®æŒ¡ã€‚\n        -   **[æ ¸å¿ƒä¼˜åŒ–] é²æ£’æ€§å¢å¼ºï¼šåŠ¨æ€ User-Agent ç‰ˆæœ¬è·å–åŠå¤šçº§å›é€€ (PR #1316)**:\n            - **åŠ¨æ€ç‰ˆæœ¬è·å–**: æ”¯æŒä»è¿œç¨‹ç«¯ç‚¹å®æ—¶æ‹‰å–ç‰ˆæœ¬å·ï¼Œç¡®ä¿ UA ä¿¡æ¯çš„å®æ—¶æ€§ä¸å‡†ç¡®æ€§ã€‚\n            - **ç¨³å»¶å›é€€é“¾**: å¼•å…¥â€œè¿œç¨‹ç«¯ç‚¹ -> Cargo.toml -> ç¡¬ç¼–ç â€çš„ä¸‰çº§ç‰ˆæœ¬å›é€€æœºåˆ¶ï¼Œæå¤§æå‡äº†åˆå§‹åŒ–é˜¶æ®µçš„é²æ£’æ€§ã€‚\n            - **é¢„ç¼–è¯‘ä¼˜åŒ–**: ä½¿ç”¨ `LazyLock` é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼è§£æç‰ˆæœ¬å·ï¼Œæå‡è¿è¡Œæ•ˆç‡å¹¶é™ä½å†…å­˜æŠ–åŠ¨ã€‚\n            - **å¯è§‚æµ‹æ€§æå‡**: æ·»åŠ äº†ç»“æ„åŒ–æ—¥å¿—è®°å½•åŠ VersionSource æšä¸¾ï¼Œæ–¹ä¾¿å¼€å‘è€…è¿½è¸ªç‰ˆæœ¬æ¥æºåŠæ½œåœ¨çš„è·å–æ•…éšœã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] è§£å†³ Gemini CLI \"Response stopped due to malformed function call.\" é”™è¯¯ (PR #1312)**:\n            - **å‚æ•°å­—æ®µå¯¹é½**: å°†å·¥å…·å£°æ˜ä¸­çš„ `parametersJsonSchema` é‡å‘½åä¸º `parameters`ï¼Œç¡®ä¿ä¸ Gemini æœ€æ–° API è§„èŒƒå®Œå…¨å¯¹é½ã€‚\n            - **å‚æ•°å¯¹é½å¼•æ“å¢å¼º**: ç§»é™¤äº†å¤šä½™çš„å‚æ•°åŒ…è£…å±‚ï¼Œä½¿å‚æ•°ä¼ é€’æ›´åŠ é€æ˜å’Œç›´æ¥ã€‚\n            - **å®¹é”™æ ¡éªŒ**: å¢å¼ºäº†å¯¹å·¥å…·è°ƒç”¨å“åº”çš„é²æ£’æ€§ï¼Œæœ‰æ•ˆé˜²æ­¢å› å‚æ•°ç»“æ„ä¸åŒ¹é…å¯¼è‡´çš„è¾“å‡ºä¸­æ–­ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] è§£å†³ Docker/Headless æ¨¡å¼ä¸‹ç«¯å£æ˜¾ç¤ºä¸º 'undefined' çš„é—®é¢˜ (Issue #1305)**: ä¿®å¤äº†ç®¡ç† API `/api/proxy/status` ç¼ºå°‘ `port` å­—æ®µä¸” `base_url` æ„é€ é”™è¯¯çš„é—®é¢˜ï¼Œç¡®ä¿å‰ç«¯èƒ½æ­£ç¡®æ˜¾ç¤ºç›‘å¬åœ°å€ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] è§£å†³ Docker/Headless æ¨¡å¼ä¸‹ Web å¯†ç ç»•è¿‡é—®é¢˜ (Issue #1309)**:\n            - **é»˜è®¤é‰´æƒå¢å¼º**: å°† `auth_mode` é»˜è®¤å€¼æ”¹ä¸º `auto`ã€‚åœ¨ Docker æˆ–å…è®¸å±€åŸŸç½‘è®¿é—®çš„ç¯å¢ƒä¸‹ï¼Œç³»ç»Ÿç°åœ¨ä¼šè‡ªåŠ¨æ¿€æ´»èº«ä»½éªŒè¯ï¼Œç¡®ä¿ `WEB_PASSWORD` ç”Ÿæ•ˆã€‚\n            - **ç¯å¢ƒå˜é‡æ”¯æŒ**: æ–°å¢ `ABV_AUTH_MODE` å’Œ `AUTH_MODE` ç¯å¢ƒå˜é‡ï¼Œå…è®¸ç”¨æˆ·åœ¨å¯åŠ¨æ—¶æ˜¾å¼è¦†ç›–é‰´æƒæ¨¡å¼ï¼ˆæ”¯æŒ `off`, `strict`, `all_except_health`, `auto`ï¼‰ã€‚\n    *   **v4.0.7 (2026-01-29)**:\n        -   **[æ€§èƒ½ä¼˜åŒ–] ä¼˜åŒ– Docker æ„å»ºæµç¨‹ (Fix Issue #1271)**:\n            - **åŸç”Ÿæ¶æ„æ„å»º**: å°† AMD64 å’Œ ARM64 çš„æ„å»ºä»»åŠ¡æ‹†åˆ†ä¸ºç‹¬ç«‹ Job å¹¶è¡Œæ‰§è¡Œï¼Œå¹¶ç§»é™¤ QEMU æ¨¡æ‹Ÿå±‚ï¼Œè½¬è€Œä½¿ç”¨å„æ¶æ„åŸç”Ÿçš„ GitHub Runnerã€‚æ­¤ä¸¾å°†è·¨å¹³å°æ„å»ºè€—æ—¶ä» 3 å°æ—¶å¤§å¹…ç¼©å‡è‡³ 10 åˆ†é’Ÿä»¥å†…ã€‚\n\n        -   **[æ€§èƒ½ä¼˜åŒ–] è§£å†³ Docker ç‰ˆæœ¬åœ¨å¤§æ•°æ®é‡ä¸‹çš„å¡é¡¿ä¸å´©æºƒé—®é¢˜ (Fix Issue #1269)**:\n            - **å¼‚æ­¥æ•°æ®åº“æ“ä½œ**: å°†æµé‡æ—¥å¿—ã€Token ç»Ÿè®¡ç­‰æ‰€æœ‰è€—æ—¶æ•°æ®åº“æŸ¥è¯¢è¿ç§»è‡³åå°é˜»å¡çº¿ç¨‹æ±  (`spawn_blocking`)ï¼Œå½»åº•è§£å†³äº†åœ¨æŸ¥çœ‹å¤§å‹æ—¥å¿—æ–‡ä»¶ï¼ˆ800MB+ï¼‰æ—¶å¯èƒ½å¯¼è‡´çš„ UI å¡æ­»åŠåä»£æœåŠ¡ä¸å¯ç”¨çš„é—®é¢˜ã€‚\n            - **ç›‘æ§é€»è¾‘å¹³æ»‘åŒ–**: ä¼˜åŒ–äº†ç›‘æ§çŠ¶æ€åˆ‡æ¢é€»è¾‘ï¼Œç§»é™¤å†—ä½™çš„é‡å¤å¯åŠ¨è®°å½•ï¼Œæå‡äº† Docker ç¯å¢ƒä¸‹çš„è¿è¡Œç¨³å®šæ€§ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] è§£å†³ OpenAI åè®® 400 Invalid Argument é”™è¯¯ (Fix Issue #1267)**:\n            - **ç§»é™¤æ¿€è¿›é»˜è®¤å€¼**: å›æ»šäº† v4.0.6 ä¸­ä¸º OpenAI/Claude åè®®å¼•å…¥çš„é»˜è®¤ `maxOutputTokens: 81920` è®¾ç½®ã€‚è¯¥å€¼è¶…è¿‡äº†è®¸å¤šæ—§æ¨¡å‹ï¼ˆå¦‚ `gemini-3-pro-preview` æˆ–åŸç”Ÿ Claude 3.5ï¼‰çš„ç¡¬æ€§é™åˆ¶ï¼Œå¯¼è‡´è¯·æ±‚è¢«ç›´æ¥æ‹’ç»ã€‚\n            - **æ™ºèƒ½æ€ç»´é…ç½®**: ä¼˜åŒ–äº†æ€ç»´æ¨¡å‹æ£€æµ‹é€»è¾‘ï¼Œä»…å¯¹ä»¥ `-thinking` ç»“å°¾çš„æ¨¡å‹è‡ªåŠ¨æ³¨å…¥ `thinkingConfig`ï¼Œé¿å…äº†å¯¹ä¸æ”¯æŒè¯¥å‚æ•°çš„æ ‡å‡†æ¨¡å‹ï¼ˆå¦‚ `gemini-3-pro`ï¼‰äº§ç”Ÿå‰¯ä½œç”¨ã€‚\n        -   **[å…¼å®¹æ€§ä¿®å¤] ä¿®å¤ OpenAI Codex (v0.92.0) è°ƒç”¨é”™è¯¯ (Fix Issue #1278)**:\n            - **å­—æ®µæ¸…æ´—**: è‡ªåŠ¨è¿‡æ»¤ Codex å®¢æˆ·ç«¯åœ¨å·¥å…·å®šä¹‰ä¸­æ³¨å…¥çš„éæ ‡å‡† `external_web_access` å­—æ®µï¼Œæ¶ˆé™¤äº† Gemini API è¿”å›çš„ 400 Invalid Argument é”™è¯¯.\n            - **å®¹é”™å¢å¼º**: å¢åŠ äº†å¯¹å·¥å…· `name` å­—æ®µçš„å¼ºåˆ¶æ ¡éªŒã€‚å½“å®¢æˆ·ç«¯å‘é€ç¼ºå¤±åç§°çš„æ— æ•ˆå·¥å…·å®šä¹‰æ—¶ï¼Œä»£ç†å±‚ç°åœ¨ä¼šè‡ªåŠ¨è·³è¿‡å¹¶è®°å½•è­¦å‘Šï¼Œè€Œä¸æ˜¯ç›´æ¥è®©è¯·æ±‚å¤±è´¥ã€‚\n        -   **[æ ¸å¿ƒåŠŸèƒ½] è‡ªé€‚åº”ç†”æ–­å™¨ (Adaptive Circuit Breaker)**:\n            - **æ¨¡å‹çº§éš”ç¦»**: å®ç°äº†åŸºäº `account_id:model` çš„å¤åˆ Key é™æµè¿½è¸ªï¼Œç¡®ä¿å•ä¸€æ¨¡å‹çš„é…é¢è€—å°½ä¸ä¼šå¯¼è‡´æ•´ä¸ªè´¦å·è¢«é”å®šã€‚\n            - **åŠ¨æ€é€€é¿ç­–ç•¥**: æ”¯æŒç”¨æˆ·è‡ªå®šä¹‰ `[60, 300, 1800, 7200]` ç­‰å¤šçº§é€€é¿é˜¶æ¢¯ï¼Œè‡ªåŠ¨æ ¹æ®å¤±è´¥æ¬¡æ•°å¢åŠ é”å®šæ—¶é—´ã€‚\n            - **é…ç½®çƒ­æ›´æ–°**: é…åˆ `TokenManager` å†…å­˜ç¼“å­˜ï¼Œå®ç°é…ç½®ä¿®æ”¹ååä»£æœåŠ¡å³åˆ»ç”Ÿæ•ˆï¼Œæ— éœ€é‡å¯ã€‚\n            - **ç®¡ç† UI é›†æˆ**: åœ¨ API åä»£é¡µé¢æ–°å¢äº†å®Œæ•´çš„æ§åˆ¶é¢æ¿ï¼Œæ”¯æŒä¸€é”®å¼€å…³åŠæ‰‹åŠ¨æ¸…é™¤é™æµè®°å½•ã€‚\n        -   **[æ ¸å¿ƒä¼˜åŒ–] å®Œå–„æ—¥å¿—æ¸…ç†ä¸å†—ä½™å‹åˆ¶ (Fix Issue #1280)**:\n            - **è‡ªåŠ¨ç©ºé—´å›æ”¶**: å¼•å…¥åŸºäºä½“ç§¯çš„æ¸…ç†æœºåˆ¶ï¼Œå½“æ—¥å¿—ç›®å½•è¶…è¿‡ 1GB æ—¶è‡ªåŠ¨è§¦å‘æ¸…ç†ï¼Œå¹¶å°†å ç”¨é™è‡³ 512MB ä»¥å†…ã€‚ç›¸æ¯”åŸæœ‰çš„æŒ‰å¤©æ¸…ç†ï¼Œèƒ½ä»æ ¹æœ¬ä¸Šé˜²æ­¢å› æ—¥å¿—çˆ†å‘å¯¼è‡´çš„ç£ç›˜æ’‘çˆ†é—®é¢˜ã€‚\n            - **é«˜é¢‘æ—¥å¿—ç˜¦èº«**: å°† OpenAI å¤„ç†å™¨æŠ¥æ–‡è¯¦æƒ…ã€TokenManager è´¦å·æ± è½®è¯¢ç­‰é«˜é¢‘äº§ç”Ÿçš„æ—¥å¿—çº§åˆ«ä» INFO é™çº§ä¸º DEBUGã€‚ç°åœ¨ INFO çº§åˆ«ä»…ä¿ç•™ç®€æ´çš„è¯·æ±‚æ‘˜è¦ã€‚\n    *   **v4.0.6 (2026-01-28)**:\n        -   **[æ ¸å¿ƒä¿®å¤] å½»åº•è§£å†³ Google OAuth \"Account already exists\" é”™è¯¯**:\n            - **æŒä¹…åŒ–å‡çº§**: å°†æˆæƒæˆåŠŸåçš„ä¿å­˜é€»è¾‘ä»â€œä»…æ–°å¢â€å‡çº§ä¸º `upsert` (æ›´æ–°æˆ–æ–°å¢) æ¨¡å¼ã€‚ç°åœ¨é‡æ–°æˆæƒå·²å­˜åœ¨çš„è´¦å·ä¼šå¹³æ»‘æ›´æ–°å…¶ Token å’Œé¡¹ç›®ä¿¡æ¯ï¼Œä¸å†å¼¹å‡ºæŠ¥é”™ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] ä¿®å¤ Docker/Web æ¨¡å¼ä¸‹æ‰‹åŠ¨å›å¡«æˆæƒç å¤±æ•ˆé—®é¢˜**:\n            - **Flow çŠ¶æ€é¢„åˆå§‹åŒ–**: åœ¨ Web æ¨¡å¼ç”Ÿæˆæˆæƒé“¾æ¥æ—¶ï¼Œåç«¯ä¼šåŒæ­¥åˆå§‹åŒ– OAuth Flow çŠ¶æ€ã€‚è¿™ç¡®ä¿äº†åœ¨ Docker ç­‰æ— æ³•è‡ªåŠ¨è·³è½¬çš„ç¯å¢ƒä¸‹ï¼Œæ‰‹åŠ¨å¤åˆ¶å›å¡«æˆæƒç æˆ– URL èƒ½å¤Ÿè¢«åç«¯æ­£ç¡®è¯†åˆ«å¹¶å¤„ç†ã€‚\n        -   **[ä½“éªŒä¼˜åŒ–] ç»Ÿä¸€ Web ä¸æ¡Œé¢ç«¯çš„ OAuth æŒä¹…åŒ–è·¯å¾„**: é‡æ„äº† `TokenManager`ï¼Œç¡®ä¿æ‰€æœ‰å¹³å°å…±ç”¨åŒä¸€å¥—å¥å£®çš„è´¦å·æ ¸éªŒä¸å­˜å‚¨é€»è¾‘ã€‚\n        -   **[æ€§èƒ½ä¼˜åŒ–] ä¼˜åŒ–é™æµæ¢å¤æœºåˆ¶ (PR #1247)**:\n            - **è‡ªåŠ¨æ¸…ç†é¢‘ç‡**: å°†é™æµè®°å½•çš„åå°è‡ªåŠ¨æ¸…ç†é—´éš”ä» 60 ç§’ç¼©çŸ­è‡³ 15 ç§’ï¼Œå¤§å¹…æå‡äº†è§¦å‘ 429 æˆ– 503 é”™è¯¯åçš„ä¸šåŠ¡æ¢å¤é€Ÿåº¦ã€‚\n            - **æ™ºèƒ½åŒæ­¥æ¸…ç†**: ä¼˜åŒ–äº†å•ä¸ªæˆ–å…¨éƒ¨è´¦å·åˆ·æ–°é€»è¾‘ï¼Œç¡®ä¿åˆ·æ–°è´¦å·çš„åŒæ—¶å³åˆ»æ¸…é™¤æœ¬åœ°é™æµé”å®šï¼Œä½¿æœ€æ–°é…é¢èƒ½ç«‹å³æŠ•å…¥ä½¿ç”¨ã€‚\n            - **æ¸è¿›å¼å®¹é‡é€€é¿**: é’ˆå¯¹ `ModelCapacityExhausted` é”™è¯¯ï¼ˆå¦‚ 503ï¼‰ï¼Œå°†åŸæœ‰çš„å›ºå®š 15 ç§’é‡è¯•ç­‰å¾…ä¼˜åŒ–ä¸º `[5s, 10s, 15s]` é˜¶æ¢¯å¼ç­–ç•¥ï¼Œæ˜¾è‘—å‡å°‘äº†å¶å‘æ€§å®¹é‡æ³¢åŠ¨çš„ç­‰å¾…æ—¶é—´ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] çª—å£æ ‡é¢˜æ æ·±è‰²æ¨¡å¼é€‚é… (PR #1253)**: ä¿®å¤äº†åœ¨ç³»ç»Ÿåˆ‡æ¢ä¸ºæ·±è‰²æ¨¡å¼æ—¶ï¼Œåº”ç”¨æ ‡é¢˜æ ï¼ˆTitlebarï¼‰æœªèƒ½åŒæ­¥åˆ‡æ¢é…è‰²ï¼Œå¯¼è‡´è§†è§‰ä¸ç»Ÿä¸€çš„é—®é¢˜ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] æå‡ Opus 4.5 é»˜è®¤è¾“å‡ºä¸Šé™ (Fix Issue #1244)**:\n            -   **çªç ´é™åˆ¶**: å°† Claude å’Œ OpenAI åè®®çš„é»˜è®¤ `max_tokens` ä» 16k æå‡è‡³ **81,920** (80k)ã€‚\n            -   **è§£å†³æˆªæ–­**: å½»åº•è§£å†³äº† Opus 4.5 ç­‰æ¨¡å‹åœ¨å¼€å¯æ€ç»´æ¨¡å¼æ—¶ï¼Œå› é»˜è®¤ Budget é™åˆ¶å¯¼è‡´è¾“å‡ºè¢«é”å®šåœ¨ 48k å·¦å³çš„æˆªæ–­é—®é¢˜ã€‚ç°åœ¨æ— éœ€ä»»ä½•é…ç½®å³å¯äº«å—å®Œæ•´çš„é•¿æ–‡æœ¬è¾“å‡ºèƒ½åŠ›ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] ä¿®å¤è´¦å·åˆ é™¤åçš„å¹½çµæ•°æ®é—®é¢˜ (Ghost Account Fix)**:\n            -   **åŒæ­¥é‡è½½**: ä¿®å¤äº†è´¦å·æ–‡ä»¶è¢«åˆ é™¤åï¼Œåä»£æœåŠ¡çš„å†…å­˜ç¼“å­˜æœªåŒæ­¥æ›´æ–°ï¼Œå¯¼è‡´å·²åˆ è´¦å·ä»å‚ä¸è½®è¯¢çš„ä¸¥é‡ Bugã€‚\n            -   **å³æ—¶ç”Ÿæ•ˆ**: ç°åœ¨å•åˆ æˆ–æ‰¹é‡åˆ é™¤è´¦å·åï¼Œä¼šå¼ºåˆ¶è§¦å‘åä»£æœåŠ¡é‡è½½ï¼Œç¡®ä¿å†…å­˜ä¸­çš„è´¦å·åˆ—è¡¨ä¸ç£ç›˜å®æ—¶ä¸€è‡´ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] Cloudflared éš§é“å¯åŠ¨é—®é¢˜ä¿®å¤ (Fix PR #1238)**:\n            -   **å¯åŠ¨å´©æºƒä¿®å¤**: ç§»é™¤äº†ä¸æ”¯æŒçš„å‘½ä»¤è¡Œå‚æ•° (`--no-autoupdate` / `--loglevel`)ï¼Œè§£å†³äº† cloudflared è¿›ç¨‹å¯åŠ¨å³é€€å‡ºçš„é—®é¢˜ã€‚\n            -   **URL è§£æä¿®æ­£**: ä¿®æ­£äº†å‘½åéš§é“ URL æå–æ—¶çš„å­—ç¬¦ä¸²åç§»é‡é”™è¯¯ï¼Œç¡®ä¿ç”Ÿæˆçš„è®¿é—®é“¾æ¥æ ¼å¼æ­£ç¡®ã€‚\n            -   **Windows ä½“éªŒä¼˜åŒ–**: ä¸º Windows å¹³å°æ·»åŠ äº† `DETACHED_PROCESS` æ ‡å¿—ï¼Œå®ç°äº†éš§é“çš„å®Œå…¨é™é»˜åå°è¿è¡Œï¼Œæ¶ˆé™¤äº†å¼¹çª—å¹²æ‰°ã€‚\n    *   **v4.0.5 (2026-01-28)**:\n        -   **[æ ¸å¿ƒä¿®å¤] å½»åº•è§£å†³ Docker/Web æ¨¡å¼ Google OAuth 400 é”™è¯¯ (Google OAuth Fix)**:\n            - **åè®®å¯¹é½**: å¼ºåˆ¶æ‰€æœ‰æ¨¡å¼ï¼ˆåŒ…æ‹¬ Docker/Webï¼‰ä½¿ç”¨ `localhost` ä½œä¸º OAuth é‡å®šå‘ URIï¼Œç»•è¿‡äº† Google å¯¹ç§ç½‘ IP å’Œé HTTPS ç¯å¢ƒçš„æ‹¦æˆªç­–ç•¥ã€‚\n            - **æµç¨‹ä¼˜åŒ–**: é…åˆå·²æœ‰çš„â€œæ‰‹åŠ¨æˆæƒç å›å¡«â€åŠŸèƒ½ï¼Œç¡®ä¿å³ä½¿åœ¨è¿œç¨‹æœåŠ¡å™¨éƒ¨ç½²ç¯å¢ƒä¸‹ï¼Œç”¨æˆ·ä¹Ÿèƒ½é¡ºåˆ©å®Œæˆ Google è´¦å·çš„æˆæƒä¸æ·»åŠ ã€‚\n        -   **[åŠŸèƒ½å¢å¼º] æ–°å¢é˜¿æ‹‰ä¼¯è¯­æ”¯æŒä¸ RTL å¸ƒå±€é€‚é… (PR #1220)**:\n            - **å›½é™…åŒ–æ‹“å±•**: æ–°å¢å®Œæ•´çš„é˜¿æ‹‰ä¼¯è¯­ (`ar`) ç¿»è¯‘æ”¯æŒã€‚\n            - **RTL å¸ƒå±€**: å®ç°äº†è‡ªåŠ¨æ£€æµ‹å¹¶é€‚é…ä»å³å‘å·¦ (Right-to-Left) çš„ UI å¸ƒå±€ã€‚\n            - **æ’ç‰ˆä¼˜åŒ–**: å¼•å…¥äº† Effra å­—ä½“å®¶æ—ï¼Œæ˜¾è‘—æå‡äº†é˜¿æ‹‰ä¼¯è¯­æ–‡æœ¬çš„å¯è¯»æ€§ä¸ç¾è§‚åº¦ã€‚\n        -   **[åŠŸèƒ½å¢å¼º] æ‰‹åŠ¨æ¸…é™¤é™æµè®°å½• (Clear Rate Limit Records)**:\n            - **ç®¡ç† UI é›†æˆ**: åœ¨â€œä»£ç†è®¾ç½® -> è´¦å·è½®æ¢ä¸ä¼šè¯è°ƒåº¦â€åŒºåŸŸæ–°å¢äº†â€œæ¸…é™¤é™æµè®°å½•â€æŒ‰é’®ï¼Œæ”¯æŒæ¡Œé¢ç«¯ä¸ Web ç«¯è°ƒç”¨ï¼Œå…è®¸ç”¨æˆ·æ‰‹åŠ¨æ¸…é™¤æ‰€æœ‰è´¦å·çš„æœ¬åœ°é™æµé”ï¼ˆ429/503 è®°å½•ï¼‰ã€‚\n            - **è´¦å·åˆ—è¡¨è”åŠ¨**: å®ç°äº†é…é¢ä¸é™æµçš„æ™ºèƒ½åŒæ­¥ã€‚ç°åœ¨åˆ·æ–°è´¦å·é¢åº¦ï¼ˆå•ä¸ªæˆ–å…¨éƒ¨ï¼‰æ—¶ï¼Œä¼šè‡ªåŠ¨æ¸…é™¤æœ¬åœ°é™æµçŠ¶æ€ï¼Œç¡®ä¿æœ€æ–°çš„é¢åº¦ä¿¡æ¯èƒ½ç«‹å³ç”Ÿæ•ˆã€‚\n            - **åç«¯æ ¸å¿ƒé€»è¾‘**: åœ¨ `RateLimitTracker` å’Œ `TokenManager` ä¸­åº•å±‚å®ç°äº†æ‰‹åŠ¨ä¸è‡ªåŠ¨è§¦å‘çš„æ¸…é™¤é€»è¾‘ï¼Œç¡®ä¿é«˜å¹¶å‘ä¸‹çš„çŠ¶æ€ä¸€è‡´æ€§ã€‚\n            - **API æ”¯æŒ**: æ–°å¢äº†å¯¹åº”çš„ Tauri å‘½ä»¤ä¸ Admin API (`DELETE /api/proxy/rate-limits`)ï¼Œæ–¹ä¾¿å¼€å‘è€…è¿›è¡Œç¼–ç¨‹åŒ–ç®¡ç†ä¸é›†æˆã€‚\n            - **å¼ºåˆ¶é‡è¯•**: é…åˆæ¸…é™¤æ“ä½œï¼Œå¯å¼ºåˆ¶ä¸‹ä¸€æ¬¡è¯·æ±‚å¿½ç•¥ä¹‹å‰çš„é€€é¿æ—¶é—´ï¼Œç›´æ¥å°è¯•è¿æ¥ä¸Šæ¸¸ï¼Œå¸®åŠ©åœ¨ç½‘ç»œæ¢å¤åå¿«é€Ÿæ¢å¤ä¸šåŠ¡ã€‚\n    *   **v4.0.4 (2026-01-27)**:\n        -   **[åŠŸèƒ½å¢å¼º] æ·±åº¦é›†æˆ Gemini å›¾åƒç”Ÿæˆä¸å¤šåè®®æ”¯æŒ (PR #1203)**:\n            - **OpenAI å…¼å®¹æ€§å¢å¼º**: æ”¯æŒé€šè¿‡æ ‡å‡† OpenAI Images API (`/v1/images/generate`) è°ƒç”¨ Gemini 3 å›¾åƒæ¨¡å‹ï¼Œæ”¯æŒ `size`ã€`quality` ç­‰å‚æ•°ã€‚\n            - **å¤šåè®®é›†æˆ**: å¢å¼ºäº† Claude å’Œ OpenAI Chat æ¥å£ï¼Œæ”¯æŒç›´æ¥ä¼ é€’å›¾ç‰‡ç”Ÿæˆå‚æ•°ï¼Œå¹¶å®ç°äº†è‡ªåŠ¨å®½é«˜æ¯”è®¡ç®—ä¸ 4K/2K è´¨é‡æ˜ å°„ã€‚\n            - **æ–‡æ¡£è¡¥å…¨**: æ–°å¢ `docs/gemini-3-image-guide.md`ï¼Œæä¾›å®Œæ•´çš„ Gemini å›¾åƒç”Ÿæˆé›†æˆæŒ‡å—ã€‚\n            - **ç¨³å®šæ€§ä¼˜åŒ–**: ä¼˜åŒ–äº†é€šç”¨å·¥å…·å‡½æ•° (`common_utils.rs`) å’Œ Gemini/OpenAI æ˜ å°„é€»è¾‘ï¼Œç¡®ä¿å¤§å°ºå¯¸ Payload ä¼ è¾“ç¨³å®šã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] å¯¹é½ OpenAI é‡è¯•ä¸é™æµé€»è¾‘ (PR #1204)**:\n            - **é€»è¾‘å¯¹é½**: é‡æ„äº† OpenAI å¤„ç†å™¨çš„é‡è¯•ã€é™æµåŠè´¦å·è½®æ¢é€»è¾‘ï¼Œä½¿å…¶ä¸ Claude å¤„ç†å™¨ä¿æŒä¸€è‡´ï¼Œæ˜¾è‘—æå‡äº†é«˜å¹¶å‘ä¸‹çš„ç¨³å®šæ€§ã€‚\n            - **çƒ­é‡è½½ä¼˜åŒ–**: ç¡®ä¿ OpenAI è¯·æ±‚åœ¨è§¦å‘ 429 æˆ– 503 é”™è¯¯æ—¶èƒ½ç²¾å‡†æ‰§è¡Œé€€é¿ç­–ç•¥å¹¶è‡ªåŠ¨åˆ‡æ¢å¯ç”¨è´¦å·ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] ä¿®å¤ Web OAuth è´¦å·æŒä¹…åŒ–é—®é¢˜ (Web Persistence Fix)**:\n            - **ç´¢å¼•ä¿®å¤**: è§£å†³äº†åœ¨ Web ç®¡ç†ç•Œé¢é€šè¿‡ OAuth æ·»åŠ çš„è´¦å·è™½ç„¶æ–‡ä»¶å·²ç”Ÿæˆï¼Œä½†æœªåŒæ­¥æ›´æ–°åˆ°å…¨å±€è´¦å·ç´¢å¼• (`accounts.json`)ï¼Œå¯¼è‡´é‡å¯åæˆ–æ¡Œé¢ç«¯æ— æ³•è¯†åˆ«çš„é—®é¢˜ã€‚\n            - **é”æœºåˆ¶ç»Ÿä¸€**: é‡æ„äº† `TokenManager` çš„ä¿å­˜é€»è¾‘ï¼Œå¤ç”¨äº† `modules::account` çš„æ ¸å¿ƒæ–¹æ³•ï¼Œç¡®ä¿äº†æ–‡ä»¶é”ä¸ç´¢å¼•æ›´æ–°çš„åŸå­æ€§ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] è§£å†³ Google OAuth é Localhost å›è°ƒé™åˆ¶ (Fix Issue #1186)**:\n            -   **é—®é¢˜èƒŒæ™¯**: Google ä¸æ”¯æŒåœ¨ OAuth æµç¨‹ä¸­ä½¿ç”¨é localhost ç§ç½‘ IP ä½œä¸ºå›è°ƒåœ°å€ï¼Œå³ä¾¿æ³¨å…¥ `device_id` ä¹Ÿä¼šæŠ¥â€œä¸å®‰å…¨çš„åº”ç”¨ç‰ˆæœ¬â€è­¦å‘Šã€‚\n            -   **è§£å†³æ–¹æ¡ˆ**: å¼•å…¥äº†æ ‡å‡†åŒ–çš„â€œæ‰‹åŠ¨ OAuth æäº¤â€æµç¨‹ã€‚å½“æµè§ˆå™¨æ— æ³•è‡ªåŠ¨å›è°ƒè‡³æœ¬åœ°ï¼ˆå¦‚è¿œç¨‹éƒ¨ç½²æˆ–é Localhost ç¯å¢ƒï¼‰æ—¶ï¼Œç”¨æˆ·å¯ç›´æ¥å¤åˆ¶å›è°ƒé“¾æ¥æˆ–æˆæƒç è‡³åº”ç”¨å†…å®Œæˆæˆæƒã€‚\n            - **ä½“éªŒå¢å¼º**: é‡æ„äº†æ‰‹åŠ¨æäº¤ç•Œé¢ï¼Œé›†æˆäº†å…¨è¯­è¨€å›½é™…åŒ–æ”¯æŒï¼ˆ9 å›½è¯­è¨€ï¼‰ä¸ UI ä¼˜åŒ–ï¼Œç¡®ä¿åœ¨ä»»ä½•ç½‘ç»œç¯å¢ƒä¸‹éƒ½èƒ½é¡ºåˆ©æ·»åŠ è´¦å·ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] è§£å†³ Google Cloud Code API 429 é”™è¯¯ (Fix Issue #1176)**:\n            - **æ™ºèƒ½é™çº§**: é»˜è®¤å°† API æµé‡è¿ç§»è‡³æ›´ç¨³å®šçš„ Daily/Sandbox ç¯å¢ƒï¼Œé¿å¼€ç”Ÿäº§ç¯å¢ƒ (`cloudcode-pa.googleapis.com`) å½“å‰é¢‘ç¹çš„ 429 é”™è¯¯ã€‚\n            - **ç¨³å¥æ€§æå‡**: å®ç°äº† Sandbox -> Daily -> Prod çš„ä¸‰çº§é™çº§ç­–ç•¥ï¼Œç¡®ä¿ä¸»ä¸šåŠ¡æµç¨‹åœ¨æç«¯ç½‘ç»œç¯å¢ƒä¸‹çš„é«˜å¯ç”¨æ€§ã€‚\n        -   **[æ ¸å¿ƒä¼˜åŒ–] è´¦å·è°ƒåº¦ç®—æ³•å‡çº§ (Algorithm Upgrade)**:\n            - **å¥åº·è¯„åˆ†ç³»ç»Ÿ (Health Score)**: å¼•å…¥äº† 0.0 åˆ° 1.0 çš„å®æ—¶å¥åº·åˆ†æœºåˆ¶ã€‚è¯·æ±‚å¤±è´¥ï¼ˆå¦‚ 429/5xxï¼‰å°†æ˜¾è‘—æ‰£åˆ†ï¼Œä½¿å—æŸè´¦å·è‡ªåŠ¨é™çº§ï¼›æˆåŠŸè¯·æ±‚åˆ™é€æ­¥å›å‡ï¼Œå®ç°è´¦å·çŠ¶æ€çš„æ™ºèƒ½è‡ªæ„ˆã€‚\n            - **ä¸‰çº§æ™ºèƒ½æ’åº**: è°ƒåº¦ä¼˜å…ˆçº§é‡æ„ä¸º `è®¢é˜…ç­‰çº§ > å‰©ä½™é…é¢ > å¥åº·åˆ†`ã€‚ç¡®ä¿åœ¨åŒç­‰çº§ã€åŒé…é¢æƒ…å†µä¸‹ï¼Œå§‹ç»ˆä¼˜å…ˆé€šè¿‡å†å²è¡¨ç°æœ€ç¨³å®šçš„è´¦å·ã€‚\n            - **å¾®å»¶è¿Ÿ (Throttle Delay)**: é’ˆå¯¹æç«¯é™æµåœºæ™¯ï¼Œå½“æ‰€æœ‰è´¦å·å‡è¢«å°é”ä¸”æœ‰è´¦å·åœ¨ 2 ç§’å†…å³å°†æ¢å¤æ—¶ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨æ‰§è¡Œæ¯«ç§’çº§æŒ‚èµ·ç­‰å¾…è€Œéç›´æ¥æŠ¥é”™ã€‚æå¤§æå‡äº†é«˜å¹¶å‘ä¸‹çš„æˆåŠŸç‡ï¼Œå¹¶å¢å¼ºäº†ä¼šè¯ç²˜æ€§ã€‚\n            - **å…¨é‡æ¥å£é€‚é…**: é‡æ„äº† `TokenManager` æ ¸å¿ƒæ¥å£ï¼Œå¹¶å®Œæˆäº†å…¨é‡å¤„ç†å™¨ï¼ˆClaude, Gemini, OpenAI, Audio, Warmupï¼‰çš„åŒæ­¥é€‚é…ï¼Œç¡®ä¿è°ƒåº¦å±‚å˜æ›´å¯¹ä¸šåŠ¡å±‚é€æ˜ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] å›ºå®šè´¦å·æ¨¡å¼æŒä¹…åŒ– (PR #1209)**:\n            -   **é—®é¢˜èƒŒæ™¯**: ä¹‹å‰ç‰ˆæœ¬åœ¨é‡å¯æœåŠ¡åï¼Œå›ºå®šè´¦å·æ¨¡å¼ï¼ˆFixed Account Modeï¼‰çš„å¼€å…³çŠ¶æ€ä¼šè¢«é‡ç½®ã€‚\n            -   **ä¿®å¤å†…å®¹**: å®ç°äº†è®¾ç½®çš„æŒä¹…åŒ–å­˜å‚¨ï¼Œç¡®ä¿ç”¨æˆ·åå¥½åœ¨é‡å¯åä¾ç„¶ç”Ÿæ•ˆã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] é€Ÿç‡é™åˆ¶æ¯«ç§’çº§è§£æ (PR #1210)**:\n            -   **é—®é¢˜èƒŒæ™¯**: éƒ¨åˆ†ä¸Šæ¸¸æœåŠ¡è¿”å›çš„ `Retry-After` æˆ–é€Ÿç‡é™åˆ¶å¤´éƒ¨åŒ…å«å¸¦å°æ•°ç‚¹çš„æ¯«ç§’å€¼ï¼Œå¯¼è‡´è§£æå¤±è´¥ã€‚\n            -   **ä¿®å¤å†…å®¹**: å¢å¼ºäº†æ—¶é—´è§£æé€»è¾‘ï¼Œæ”¯æŒå…¼å®¹æµ®ç‚¹æ•°æ ¼å¼çš„æ—¶é—´å­—æ®µï¼Œæé«˜äº†å¯¹éæ ‡å‡†ä¸Šæ¸¸çš„å…¼å®¹æ€§ã€‚\n    *   **v4.0.3 (2026-01-27)**:\n        -   **[åŠŸèƒ½å¢å¼º] æé«˜è¯·æ±‚ä½“é™åˆ¶ä»¥æ”¯æŒå¤§ä½“ç§¯å›¾ç‰‡ Payload (PR #1167)**:\n            - å°†é»˜è®¤è¯·æ±‚ä½“å¤§å°é™åˆ¶ä» 2MB æå‡è‡³ **100MB**ï¼Œè§£å†³å¤šå›¾å¹¶å‘ä¼ è¾“æ—¶çš„ 413 (Payload Too Large) é”™è¯¯ã€‚\n            - æ–°å¢ç¯å¢ƒå˜é‡ `ABV_MAX_BODY_SIZE`ï¼Œæ”¯æŒç”¨æˆ·æ ¹æ®éœ€æ±‚åŠ¨æ€è°ƒæ•´æœ€å¤§é™åˆ¶ã€‚\n            - æœåŠ¡å¯åŠ¨æ—¶è‡ªåŠ¨è¾“å‡ºå½“å‰ç”Ÿæ•ˆçš„ Body Limit æ—¥å¿—ï¼Œä¾¿äºæ’æŸ¥ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] è§£å†³ Google OAuth 'state' å‚æ•°ç¼ºå¤±å¯¼è‡´çš„æˆæƒå¤±è´¥ (Issue #1168)**:\n            - ä¿®å¤äº†æ·»åŠ  Google è´¦å·æ—¶å¯èƒ½å‡ºç°çš„ \"Agent execution terminated\" é”™è¯¯ã€‚\n            - å®ç°äº†éšæœº `state` å‚æ•°çš„ç”Ÿæˆä¸å›è°ƒéªŒè¯ï¼Œå¢å¼ºäº† OAuth æµç¨‹çš„å®‰å…¨æ€§å’Œå…¼å®¹æ€§ã€‚\n            - ç¡®ä¿åœ¨æ¡Œé¢ç«¯å’Œ Web æ¨¡å¼ä¸‹çš„æˆæƒæµç¨‹å‡ç¬¦åˆ OAuth 2.0 æ ‡å‡†ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] è§£å†³ Docker/Web æ¨¡å¼ä¸‹ä»£ç†å¼€å…³åŠè´¦å·å˜åŠ¨éœ€é‡å¯ç”Ÿæ•ˆçš„é—®é¢˜ (Issue #1166)**:\n            - å®ç°äº†ä»£ç†å¼€å…³çŠ¶æ€çš„æŒä¹…åŒ–å­˜å‚¨ï¼Œç¡®ä¿å®¹å™¨é‡å¯åçŠ¶æ€ä¿æŒä¸€è‡´ã€‚\n            - åœ¨è´¦å·å¢åˆ ã€åˆ‡æ¢ã€é‡æ’åŠå¯¼å…¥åè‡ªåŠ¨è§¦å‘ Token ç®¡ç†å™¨çƒ­åŠ è½½ï¼Œä½¿å˜æ›´ç«‹å³åœ¨åä»£æœåŠ¡ä¸­ç”Ÿæ•ˆã€‚\n            - ä¼˜åŒ–äº†è´¦å·åˆ‡æ¢é€»è¾‘ï¼Œè‡ªåŠ¨æ¸…é™¤æ—§ä¼šè¯ç»‘å®šï¼Œç¡®ä¿è¯·æ±‚ç«‹å³è·¯ç”±åˆ°æ–°è´¦å·ã€‚\n    *   **v4.0.2 (2026-01-26)**:\n        -   **[æ ¸å¿ƒä¿®å¤] è§£å†³å¼€å¯â€œè®¿é—®æˆæƒâ€å¯¼è‡´çš„é‡å¤è®¤è¯ä¸ 401 å¾ªç¯ (Fix Issue #1163)**:\n            - ä¿®æ­£äº†åç«¯é‰´æƒä¸­é—´ä»¶é€»è¾‘ï¼Œç¡®ä¿åœ¨é‰´æƒå…³é—­æ¨¡å¼ï¼ˆOff/Autoï¼‰ä¸‹ç®¡ç†æ¥å£ä¸å†å¼ºåˆ¶æ‹¦æˆªã€‚\n            - å¢å¼ºäº†å¥åº·æ£€æŸ¥è·¯å¾„ (`/api/health`) çš„å…é‰´æƒè±å…ï¼Œé¿å… UI åŠ è½½åˆæœŸå› çŠ¶æ€æ£€æµ‹å¤±è´¥è§¦å‘ç™»å½•ã€‚\n            - åœ¨å‰ç«¯è¯·æ±‚å±‚å¼•å…¥äº† 401 å¼‚å¸¸é¢‘ç‡é™åˆ¶ï¼ˆé˜²æŠ–é”ï¼‰ï¼Œå½»åº•è§£å†³äº†å¤§æ‰¹é‡è¯·æ±‚å¤±è´¥å¯¼è‡´çš„ UI å¼¹çª—æŠ–åŠ¨ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] è§£å†³åˆ‡æ¢è´¦å·åä¼šè¯æ— æ³•æŒä¹…åŒ–ä¿å­˜ (Fix Issue #1159)**:\n            - å¢å¼ºäº†æ•°æ®åº“æ³¨å…¥é€»è¾‘ï¼Œåœ¨åˆ‡æ¢è´¦å·æ—¶åŒæ­¥æ›´æ–°èº«ä»½æ ‡è¯†ï¼ˆEmailï¼‰å¹¶æ¸…é™¤æ—§çš„ UserID ç¼“å­˜ã€‚\n            - è§£å†³äº†å›  Token ä¸èº«ä»½æ ‡è¯†ä¸åŒ¹é…å¯¼è‡´å®¢æˆ·ç«¯æ— æ³•æ­£ç¡®å…³è”æˆ–ä¿å­˜æ–°ä¼šè¯çš„é—®é¢˜ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] Docker/Web æ¨¡å¼ä¸‹æ¨¡å‹æ˜ å°„æŒä¹…åŒ– (Fix Issue #1149)**:\n            - ä¿®å¤äº†åœ¨ Docker æˆ– Web éƒ¨ç½²æ¨¡å¼ä¸‹ï¼Œç®¡ç†å‘˜é€šè¿‡ API ä¿®æ”¹çš„æ¨¡å‹æ˜ å°„é…ç½®ï¼ˆModel Mappingï¼‰æ— æ³•ä¿å­˜åˆ°ç¡¬ç›˜çš„é—®é¢˜ã€‚\n            - ç¡®ä¿ `admin_update_model_mapping` æ¥å£æ­£ç¡®è°ƒç”¨æŒä¹…åŒ–é€»è¾‘ï¼Œé…ç½®åœ¨é‡å¯å®¹å™¨åä¾ç„¶ç”Ÿæ•ˆã€‚\n        -   **[æ¶æ„ä¼˜åŒ–] MCP å·¥å…·æ”¯æŒæ¶æ„å…¨é¢å‡çº§ (Schema Cleaning & Tool Adapters)**:\n            - **çº¦æŸè¯­ä¹‰å›å¡« (Constraint Hints)**:\n                - å®ç°äº†æ™ºèƒ½çº¦æŸè¿ç§»æœºåˆ¶ï¼Œåœ¨åˆ é™¤ Gemini ä¸æ”¯æŒçš„çº¦æŸå­—æ®µ(`minLength`, `pattern`, `format` ç­‰)å‰ï¼Œè‡ªåŠ¨å°†å…¶è½¬åŒ–ä¸ºæè¿°æç¤ºã€‚\n                - æ–°å¢ `CONSTRAINT_FIELDS` å¸¸é‡å’Œ `move_constraints_to_description` å‡½æ•°ï¼Œç¡®ä¿æ¨¡å‹èƒ½é€šè¿‡æè¿°ç†è§£åŸå§‹çº¦æŸã€‚\n                - ç¤ºä¾‹: `{\"minLength\": 5}` â†’ `{\"description\": \"[Constraint: minLen: 5]\"}`\n            - **anyOf/oneOf æ™ºèƒ½æ‰å¹³åŒ–å¢å¼º**:\n                - é‡å†™ `extract_best_schema_from_union` å‡½æ•°ï¼Œä½¿ç”¨è¯„åˆ†æœºåˆ¶é€‰æ‹©æœ€ä½³ç±»å‹(object > array > scalar)ã€‚\n                - åœ¨åˆå¹¶åè‡ªåŠ¨æ·»åŠ  `\"Accepts: type1 | type2\"` æç¤ºåˆ°æè¿°ä¸­ï¼Œä¿ç•™æ‰€æœ‰å¯èƒ½ç±»å‹çš„ä¿¡æ¯ã€‚\n                - æ–°å¢ `get_schema_type_name` å‡½æ•°ï¼Œæ”¯æŒæ˜¾å¼ç±»å‹å’Œç»“æ„æ¨æ–­ã€‚\n            - **æ’ä»¶åŒ–å·¥å…·é€‚é…å™¨å±‚ (Tool Adapter System)**:\n                - åˆ›å»º `ToolAdapter` traitï¼Œä¸ºä¸åŒ MCP å·¥å…·æä¾›å®šåˆ¶åŒ– Schema å¤„ç†èƒ½åŠ›ã€‚\n                - å®ç° `PencilAdapter`ï¼Œè‡ªåŠ¨ä¸º Pencil ç»˜å›¾å·¥å…·çš„è§†è§‰å±æ€§(`cornerRadius`, `strokeWidth`)å’Œè·¯å¾„å‚æ•°æ·»åŠ è¯´æ˜ã€‚\n                - å»ºç«‹å…¨å±€é€‚é…å™¨æ³¨å†Œè¡¨ï¼Œæ”¯æŒé€šè¿‡ `clean_json_schema_for_tool` å‡½æ•°åº”ç”¨å·¥å…·ç‰¹å®šä¼˜åŒ–ã€‚\n            - **é«˜æ€§èƒ½ç¼“å­˜å±‚ (Schema Cache)**:\n                - å®ç°åŸºäº SHA-256 å“ˆå¸Œçš„ Schema ç¼“å­˜æœºåˆ¶ï¼Œé¿å…é‡å¤æ¸…æ´—ç›¸åŒçš„ Schemaã€‚\n                - é‡‡ç”¨ LRU æ·˜æ±°ç­–ç•¥ï¼Œæœ€å¤§ç¼“å­˜ 1000 æ¡ï¼Œå†…å­˜å ç”¨ < 10MBã€‚\n                - æä¾› `clean_json_schema_cached` å‡½æ•°å’Œç¼“å­˜ç»Ÿè®¡åŠŸèƒ½ï¼Œé¢„è®¡æ€§èƒ½æå‡ 60%+ã€‚\n            - **å½±å“èŒƒå›´**: \n                - âœ… æ˜¾è‘—æå‡ MCP å·¥å…·(å¦‚ Pencil)çš„ Schema å…¼å®¹æ€§å’Œæ¨¡å‹ç†è§£èƒ½åŠ›\n                - âœ… ä¸ºæœªæ¥æ·»åŠ æ›´å¤š MCP å·¥å…·(filesystem, database ç­‰)å¥ å®šäº†æ’ä»¶åŒ–åŸºç¡€\n                - âœ… å®Œå…¨å‘åå…¼å®¹ï¼Œæ‰€æœ‰ 25 é¡¹æµ‹è¯•é€šè¿‡\n        -   **[å®‰å…¨å¢å¼º] Web UI ç®¡ç†åå°å¯†ç ä¸ API Key åˆ†ç¦» (Fix Issue #1139)**:\n            - **ç‹¬ç«‹å¯†ç é…ç½®**: æ”¯æŒé€šè¿‡ `ABV_WEB_PASSWORD` æˆ– `WEB_PASSWORD` ç¯å¢ƒå˜é‡è®¾ç½®ç‹¬ç«‹çš„ç®¡ç†åå°ç™»å½•å¯†ç ã€‚\n            - **æ™ºèƒ½é‰´æƒé€»è¾‘**: \n                - ç®¡ç†æ¥å£ä¼˜å…ˆéªŒè¯ç‹¬ç«‹å¯†ç ï¼Œæœªè®¾ç½®æ—¶è‡ªåŠ¨å›é€€éªŒè¯ `API_KEY`ï¼ˆç¡®ä¿å‘åå…¼å®¹ï¼‰ã€‚\n                - AI ä»£ç†æ¥å£ä¸¥æ ¼ä»…å…è®¸ä½¿ç”¨ `API_KEY` è¿›è¡Œè®¤è¯ï¼Œå®ç°æƒé™éš”ç¦»ã€‚\n            - **é…ç½® UI æ”¯æŒ**: åœ¨â€œä»ªè¡¨ç›˜-æœåŠ¡é…ç½®â€ä¸­æ–°å¢ç®¡ç†å¯†ç ç¼–è¾‘é¡¹ï¼Œæ”¯æŒä¸€é”®æ‰¾å›æˆ–ä¿®æ”¹ã€‚\n            - **æ—¥å¿—å¼•å¯¼**: Headless æ¨¡å¼å¯åŠ¨æ—¶ä¼šæ¸…æ™°æ‰“å° API Key ä¸ Web UI Password çš„çŠ¶æ€åŠæŸ¥çœ‹æ–¹å¼ã€‚\n    *   **v4.0.1 (2026-01-26)**:\n        -   **[UX ä¼˜åŒ–] ä¸»é¢˜ä¸è¯­è¨€åˆ‡æ¢å¹³æ»‘åº¦**:\n            - è§£å†³äº†ä¸»é¢˜å’Œè¯­è¨€åˆ‡æ¢æ—¶çš„ UI å¡é¡¿é—®é¢˜ï¼Œå°†é…ç½®æŒä¹…åŒ–é€»è¾‘ä¸çŠ¶æ€æ›´æ–°è§£è€¦ã€‚\n            - ä¼˜åŒ–äº†å¯¼èˆªæ ä¸­çš„ View Transition API ä½¿ç”¨ï¼Œç¡®ä¿è§†è§‰æ›´æ–°ä¸é˜»å¡æ“ä½œã€‚\n            - å°†çª—å£èƒŒæ™¯åŒæ­¥è°ƒç”¨æ”¹ä¸ºå¼‚æ­¥ï¼Œé¿å… React æ¸²æŸ“å»¶è¿Ÿã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] åä»£æœåŠ¡å¯åŠ¨æ­»é”**:\n            - ä¿®å¤äº†å¯åŠ¨åä»£æœåŠ¡æ—¶ä¼šé˜»å¡çŠ¶æ€è½®è¯¢è¯·æ±‚çš„ç«æ€/æ­»é”é—®é¢˜ã€‚\n            - å¼•å…¥äº†åŸå­å¯åŠ¨æ ‡å¿—å’Œéé˜»å¡çŠ¶æ€æ£€æŸ¥ï¼Œç¡®ä¿ UI åœ¨æœåŠ¡åˆå§‹åŒ–æœŸé—´ä¿æŒå“åº”ã€‚\n    *   **v4.0.0 (2026-01-25)**:\n        -   **[é‡å¤§æ¶æ„] æ·±åº¦è¿ç§»è‡³ Tauri v2 (Tauri v2 Migration)**:\n            - å…¨é¢é€‚é… Tauri v2 æ ¸å¿ƒ APIï¼ŒåŒ…æ‹¬ç³»ç»Ÿæ‰˜ç›˜ã€çª—å£ç®¡ç†ä¸äº‹ä»¶ç³»ç»Ÿã€‚\n            - è§£å†³äº†å¤šä¸ªå¼‚æ­¥ Trait åŠ¨æ€æ´¾å‘ä¸ç”Ÿå‘½å‘¨æœŸå†²çªé—®é¢˜ï¼Œåç«¯æ€§èƒ½ä¸ç¨³å®šæ€§æ˜¾è‘—æå‡ã€‚\n        -   **[éƒ¨ç½²é©æ–°] åŸç”Ÿ Headless Docker æ¨¡å¼ (Native Headless Docker)**:\n            - å®ç°äº†â€œçº¯åç«¯â€Docker é•œåƒï¼Œå½»åº•ç§»é™¤äº†å¯¹ VNCã€noVNC æˆ– XVFB çš„ä¾èµ–ï¼Œå¤§å¹…é™ä½å†…å­˜ä¸ CPU å ç”¨ã€‚\n            - æ”¯æŒç›´æ¥æ‰˜ç®¡å‰ç«¯é™æ€èµ„æºï¼Œå®¹å™¨å¯åŠ¨åå³å¯é€šè¿‡æµè§ˆå™¨è¿œç¨‹ç®¡ç†ã€‚\n        -   **[éƒ¨ç½²ä¿®å¤] Arch Linux å®‰è£…è„šæœ¬ä¿®å¤ (PR #1108)**:\n            - ä¿®å¤äº† `deploy/arch/PKGBUILD.template` ä¸­ç¡¬ç¼–ç  `data.tar.zst` å¯¼è‡´çš„æå–å¤±è´¥é—®é¢˜ã€‚\n            - å®ç°äº†åŸºäºé€šé…ç¬¦çš„åŠ¨æ€å‹ç¼©æ ¼å¼è¯†åˆ«ï¼Œç¡®ä¿å…¼å®¹ä¸åŒç‰ˆæœ¬çš„ `.deb` åŒ…ã€‚\n        -   **[ç®¡ç†å‡çº§] å…¨åŠŸèƒ½ Web ç®¡ç†ç•Œé¢ (Web-based Console)**:\n            - é‡å†™äº†ç®¡ç†åå°ï¼Œä½¿æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½ï¼ˆè´¦å·ç®¡ç†ã€API åä»£ç›‘æ§ã€OAuth æˆæƒã€æ¨¡å‹æ˜ å°„ï¼‰å‡å¯åœ¨æµè§ˆå™¨ç«¯å®Œæˆã€‚\n            - è¡¥å…¨äº† Web æ¨¡å¼ä¸‹çš„ OAuth å›è°ƒå¤„ç†ï¼Œæ”¯æŒ `ABV_PUBLIC_URL` è‡ªå®šä¹‰ï¼Œå®Œç¾é€‚é…è¿œç¨‹ VPS æˆ– NAS éƒ¨ç½²åœºæ™¯ã€‚\n        -   **[é¡¹ç›®è§„èŒƒåŒ–] ç»“æ„æ¸…ç†ä¸å•å…ƒåŒ– (Project Normalization)**:\n            - æ¸…ç†äº†å†—ä½™çš„ `deploy` ç›®å½•åŠå…¶æ—§ç‰ˆè„šæœ¬ï¼Œé¡¹ç›®ç»“æ„æ›´åŠ ç°ä»£ã€‚\n            - è§„èŒƒåŒ– Docker é•œåƒåç§°ä¸º `antigravity-manager`ï¼Œå¹¶æ•´åˆä¸“å±çš„ `docker/` ç›®å½•ä¸éƒ¨ç½²æ‰‹å†Œã€‚\n        -   **[API å¢å¼º] æµé‡æ—¥å¿—ä¸ç›‘æ§ä¼˜åŒ–**:\n            - ä¼˜åŒ–äº†æµé‡æ—¥å¿—çš„å®æ—¶ç›‘æ§ä½“éªŒï¼Œè¡¥å…¨äº† Web æ¨¡å¼ä¸‹çš„è½®è¯¢æœºåˆ¶ä¸ç»Ÿè®¡æ¥å£ã€‚\n            - ç²¾ç¡®åŒ–ç®¡ç† API è·¯ç”±å ä½ç¬¦å‘½åï¼Œæå‡äº† API çš„è°ƒç”¨ç²¾ç¡®åº¦ã€‚\n        -   **[ç”¨æˆ·ä½“éªŒ] ç›‘æ§é¡µé¢å¸ƒå±€ä¸æ·±è‰²æ¨¡å¼ä¼˜åŒ– (PR #1105)**:\n            -   **å¸ƒå±€é‡æ„**: ä¼˜åŒ–äº†æµé‡æ—¥å¿—é¡µé¢çš„å®¹å™¨å¸ƒå±€ï¼Œé‡‡ç”¨å›ºå®šæœ€å¤§å®½åº¦ä¸å“åº”å¼è¾¹è·ï¼Œè§£å†³äº†åœ¨å¤§å±æ˜¾ç¤ºå™¨ä¸‹çš„å†…å®¹è¿‡åº¦æ‹‰ä¼¸é—®é¢˜ï¼Œè§†è§‰ä½“éªŒæ›´åŠ èˆ’é€‚ã€‚\n            -   **æ·±è‰²æ¨¡å¼ä¸€è‡´æ€§**: å°†æ—¥å¿—è¯¦æƒ…å¼¹çª—çš„é…è‰²æ–¹æ¡ˆä»ç¡¬ç¼–ç çš„ Slate è‰²ç³»è¿ç§»è‡³ Base ä¸»é¢˜è‰²ç³»ï¼Œç¡®ä¿ä¸å…¨å±€æ·±è‰²æ¨¡å¼é£æ ¼æ— ç¼ç»Ÿä¸€ï¼Œæå‡äº†è§†è§‰ä¸€è‡´æ€§ã€‚\n        -   **[ç”¨æˆ·ä½“éªŒ] è‡ªåŠ¨æ›´æ–°ä½“éªŒä¼˜åŒ–**:\n            -   **æ™ºèƒ½é™çº§**: ä¿®å¤äº†å½“åŸç”Ÿæ›´æ–°åŒ…æœªå°±ç»ªï¼ˆå¦‚ Draft Releaseï¼‰æ—¶ç‚¹å‡»æ›´æ–°æ— ååº”çš„é—®é¢˜ã€‚ç°åœ¨ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹å¹¶æç¤ºç”¨æˆ·ï¼ŒåŒæ—¶ä¼˜é›…é™çº§è‡³æµè§ˆå™¨ä¸‹è½½æ¨¡å¼ï¼Œç¡®ä¿æŒç»­å¯æ›´æ–°ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] æ·±åº¦ä¼˜åŒ– Signature Cache ä¸ Rewind æ£€æµ‹ (PR #1094)**:\n            -   **400 é”™è¯¯è‡ªæ„ˆ**: å¢å¼ºäº†æ€è€ƒå—ç­¾åçš„æ¸…æ´—é€»è¾‘ã€‚ç³»ç»Ÿç°åœ¨èƒ½è‡ªåŠ¨è¯†åˆ«å› æœåŠ¡å™¨é‡å¯å¯¼è‡´çš„â€œæ— ä¸»ç­¾åâ€ï¼Œå¹¶åœ¨å‘é€ç»™ä¸Šæ¸¸å‰ä¸»åŠ¨å°†å…¶å‰¥ç¦»ï¼Œä»æ ¹æœ¬ä¸Šæœç»äº†ç”±æ­¤å¼•å‘äº† `400 Invalid signature` æŠ¥é”™ã€‚\n            -   **Rewind (å›é€€) æ£€æµ‹æœºåˆ¶**: å‡çº§ç¼“å­˜å±‚ï¼Œå¼•å…¥æ¶ˆæ¯è®¡æ•°ï¼ˆMessage Countï¼‰æ ¡éªŒã€‚å½“ç”¨æˆ·å›é€€å¯¹è¯å†å²å¹¶é‡æ–°å‘é€æ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨é‡ç½®ç­¾åçŠ¶æ€ï¼Œç¡®ä¿å¯¹è¯æµçš„åˆæ³•æ€§ã€‚\n            -   **å…¨é“¾è·¯é€‚é…**: ä¼˜åŒ–äº† Claudeã€Gemini åŠ z.ai (Anthropic) çš„æ•°æ®é“¾è·¯ï¼Œç¡®ä¿æ¶ˆæ¯è®¡æ•°åœ¨æµå¼ä¸éæµå¼è¯·æ±‚ä¸­å‡èƒ½ç²¾å‡†ä¼ æ’­ã€‚\n        -   **[OpenAI é²æ£’æ€§å¢å¼º] ä¼˜åŒ–é‡è¯•ç­–ç•¥ä¸æ¨¡å‹çº§é™æµ (PR #1093)**:\n            -   **é²æ£’é‡è¯•**: å¼ºåˆ¶æœ€å° 2 æ¬¡è¯·æ±‚å°è¯•ï¼Œç¡®ä¿å•è´¦å·æ¨¡å¼ä¸‹ä¹Ÿèƒ½æœ‰æ•ˆåº”å¯¹ç¬æ—¶ç½‘ç»œæŠ–åŠ¨ï¼›ç§»é™¤äº†é…é¢è€—å°½çš„ç¡¬ä¸­æ–­ï¼Œå…è®¸è‡ªåŠ¨è½®æ¢è´¦å·ã€‚\n            -   **æ¨¡å‹çº§é™æµ**: å¼•å…¥æ¨¡å‹çº§é™æµéš”ç¦»ï¼Œé¿å…å•ä¸ªæ¨¡å‹é™æµé”å®šæ•´ä¸ªè´¦å·ï¼Œç¡®ä¿è´¦å·ä¸‹å…¶ä»–æ¨¡å‹å¯ç”¨ã€‚\n            -   **æ¥å£ä¿®å¤**: ä¿®å¤äº† TokenManager å¼‚æ­¥æ¥å£çš„ Email/ID æ··ç”¨æ¼æ´ï¼Œç¡®ä¿é™æµè®°å½•å‡†ç¡®ã€‚\n        -   **[ç³»ç»Ÿé²æ£’æ€§] ç»Ÿä¸€é‡è¯•ä¸é€€é¿è°ƒåº¦ä¸­å¿ƒ (Unified Retry & Backoff Hub)**:\n            -   **é€»è¾‘å½’ä¸€åŒ–**: å°†æ•£è½åœ¨å„åè®®å¤„ç†å™¨ä¸­çš„é‡è¯•é€»è¾‘æŠ½è±¡è‡³ `common.rs`ï¼Œå®ç°å…¨å±€ç»Ÿä¸€è°ƒåº¦ã€‚\n            -   **å¼ºåˆ¶é€€é¿å»¶è¿Ÿ**: å½»åº•ä¿®å¤äº†åŸå…ˆé€»è¾‘ä¸­è§£æä¸åˆ° `Retry-After` å°±ç«‹å³é‡è¯•å¯¼è‡´å°å·çš„é—®é¢˜ã€‚ç°åœ¨æ‰€æœ‰å¤„ç†å™¨åœ¨é‡è¯•å‰å¿…é¡»é€šè¿‡å…±äº«æ¨¡å—æ‰§è¡Œç‰©ç†ç­‰å¾…ï¼Œæœ‰æ•ˆä¿æŠ¤ IP ä¿¡èª‰ã€‚\n            -   **æ¿€è¿›å‚æ•°è°ƒæ•´**: é’ˆå¯¹ Google/Anthropic é¢‘ç‡é™åˆ¶ï¼Œå°† 429 å’Œ 503 çš„åˆå§‹é€€é¿æ—¶é—´æ˜¾è‘—ä¸Šè°ƒè‡³ **5s-10s**ï¼Œå¤§å¹…é™ä½ç”Ÿäº§ç¯å¢ƒé£æ§é£é™©ã€‚\n        -   **[CLI åŒæ­¥ä¼˜åŒ–] è§£å†³ Token å†²çªä¸æ¨¡å‹é…ç½®æ¸…ç† (PR #1054)**:\n            -   **è‡ªåŠ¨å†²çªè§£å†³**: åœ¨è®¾ç½® `ANTHROPIC_API_KEY` æ—¶è‡ªåŠ¨ç§»é™¤å†²çªçš„ `ANTHROPIC_AUTH_TOKEN`ï¼Œè§£å†³ Claude CLI åŒæ­¥æŠ¥é”™é—®é¢˜ã€‚\n            -   **ç¯å¢ƒå˜é‡æ¸…ç†**: åŒæ­¥æ—¶è‡ªåŠ¨ç§»é™¤ `ANTHROPIC_MODEL` ç­‰å¯èƒ½å¹²æ‰°æ¨¡å‹è¾“å‡ºçš„ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿ CLI ä½¿ç”¨æ ‡å‡†æ¨¡å‹ã€‚\n            -   **é…ç½®å¥å£®æ€§**: ä¼˜åŒ–äº† API Key ä¸ºç©ºæ—¶çš„å¤„ç†æ–¹å¼ï¼Œé¿å…æ— æ•ˆé…ç½®å¹²æ‰°ã€‚\n        -   **[æ ¸å¿ƒä¼˜åŒ–] ç”¨é‡ç¼©æ”¾åŠŸèƒ½é»˜è®¤å…³é—­ä¸è”åŠ¨æœºåˆ¶ (Usage Scaling Default Off)**:\n            -   **é»˜è®¤å…³é—­**: åŸºäºç”¨æˆ·åé¦ˆï¼Œå°†\"å¯ç”¨ç”¨é‡ç¼©æ”¾\"åŠŸèƒ½ä»é»˜è®¤å¼€å¯æ”¹ä¸ºé»˜è®¤å…³é—­ï¼Œå›å½’é€æ˜æ¨¡å¼ã€‚\n            -   **è”åŠ¨æœºåˆ¶**: å»ºç«‹äº†ç¼©æ”¾ä¸è‡ªåŠ¨å‹ç¼© (L1/L2/L3) çš„è”åŠ¨å…³ç³»ã€‚åªæœ‰å½“ç”¨æˆ·ä¸»åŠ¨å¼€å¯ç¼©æ”¾æ—¶ï¼Œæ‰åŒæ­¥æ¿€æ´»è‡ªåŠ¨å‹ç¼©é€»è¾‘ã€‚\n            -   **è§£å†³ç—›ç‚¹**: ä¿®å¤äº†ç”¨æˆ·åé¦ˆçš„\"ç¼©æ”¾è‡´ç›²\"é—®é¢˜ - é»˜è®¤æ¨¡å¼ä¸‹å®¢æˆ·ç«¯èƒ½çœ‹åˆ°çœŸå® Token ç”¨é‡ï¼Œåœ¨æ¥è¿‘ 200k æ—¶è§¦å‘åŸç”Ÿ `/compact` æç¤ºï¼Œé¿å…æ­»é”ã€‚\n            -   **åŠŸèƒ½å®šä½**: å°†ç¼©æ”¾+å‹ç¼©é‡æ–°å®šä¹‰ä¸º\"æ¿€è¿›æ‰©å®¹æ¨¡å¼\"ï¼Œä»…ä¾›å¤„ç†è¶…å¤§å‹é¡¹ç›®æ—¶æ‰‹åŠ¨å¼€å¯ï¼Œæå‡ç³»ç»Ÿç¨³å®šæ€§ä¸å¯é¢„æµ‹æ€§ã€‚\n            -   **âš ï¸ å‡çº§æé†’**: ä»æ—§ç‰ˆæœ¬å‡çº§çš„ç”¨æˆ·,å»ºè®®åœ¨\"è®¾ç½® â†’ å®éªŒæ€§åŠŸèƒ½\"ä¸­æ‰‹åŠ¨å…³é—­\"å¯ç”¨ç”¨é‡ç¼©æ”¾\",ä»¥è·å¾—æ›´ç¨³å®šé€æ˜çš„ä½“éªŒã€‚\n        -   **[åè®®ä¼˜åŒ–] å…¨åè®®è‡ªåŠ¨æµå¼è½¬æ¢ (Auto-Stream Conversion)**:\n            -   **å…¨é“¾è·¯è¦†ç›–**: å¯¹ OpenAI (Chat/Legacy/Codex) å’Œ Gemini åè®®å®ç°äº†å¼ºåˆ¶å†…éƒ¨æµå¼åŒ–è½¬æ¢ã€‚å³ä½¿å®¢æˆ·ç«¯è¯·æ±‚éæµå¼ (`stream: false`)ï¼Œåç«¯ä¹Ÿä¼šè‡ªåŠ¨å»ºç«‹æµå¼è¿æ¥ä¸ä¸Šæ¸¸é€šä¿¡ï¼Œæå¤§æå‡äº†è¿æ¥ç¨³å®šæ€§å’Œé…é¢åˆ©ç”¨ç‡ã€‚\n            -   **æ™ºèƒ½èšåˆ**: å®ç°äº†é«˜æ€§èƒ½çš„æµå¼èšåˆå™¨ï¼Œåœ¨å…¼å®¹æ—§ç‰ˆå®¢æˆ·ç«¯çš„åŒæ—¶ï¼Œè¿˜èƒ½åœ¨åå°å®æ—¶æ•è· Thinking ç­¾åï¼Œæœ‰æ•ˆè§£å†³äº†éæµå¼è¯·æ±‚ä¸‹ç­¾åä¸¢å¤±å¯¼è‡´åç»­å·¥å…·è°ƒç”¨å¤±è´¥çš„é—®é¢˜ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] é”™è¯¯æ—¥å¿—å…ƒæ•°æ®è¡¥å…¨ (Log Metadata Fix)**:\n            -   **é—®é¢˜èƒŒæ™¯**: ä¹‹å‰ç‰ˆæœ¬åœ¨ 429/503 ç­‰ä¸¥é‡é”™è¯¯ï¼ˆå¦‚è´¦å·è€—å°½ï¼‰å‘ç”Ÿæ—¶ï¼Œæ—¥å¿—è®°å½•ä¸­é—æ¼äº† `mapped_model` å’Œ `account_email` å­—æ®µï¼Œå¯¼è‡´æ— æ³•å®šä½å‡ºé”™çš„å…·ä½“æ¨¡å‹å’Œè´¦å·ã€‚\n            -   **ä¿®å¤å†…å®¹**: åœ¨ OpenAI å’Œ Claude åè®®çš„æ‰€æœ‰é”™è¯¯é€€å‡ºè·¯å¾„ï¼ˆåŒ…æ‹¬ Token è·å–å¤±è´¥ã€è½¬æ¢å¼‚å¸¸ã€é‡è¯•è€—å°½ï¼‰ä¸­å¼ºåˆ¶æ³¨å…¥äº†å…ƒæ•°æ® Headerã€‚ç°åœ¨å³ä½¿è¯·æ±‚å¤±è´¥ï¼Œæµé‡æ—¥å¿—ä¹Ÿèƒ½å‡†ç¡®æ˜¾ç¤ºç›®æ ‡æ¨¡å‹å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæå¤§æå‡äº†æ’æŸ¥æ•ˆç‡ã€‚\n\n\n    *   **v4.0.0 (2026-01-25)**:\n        -   **[æ ¸å¿ƒåŠŸèƒ½] åå°ä»»åŠ¡æ¨¡å‹å¯é…ç½® (Background Model Configuration)**:\n            -   **åŠŸèƒ½å¢å¼º**: å…è®¸ç”¨æˆ·è‡ªå®šä¹‰â€œåå°ä»»åŠ¡â€ï¼ˆå¦‚æ ‡é¢˜ç”Ÿæˆã€æ‘˜è¦å‹ç¼©ï¼‰ä½¿ç”¨çš„æ¨¡å‹ã€‚ä¸å†å¼ºåˆ¶ç»‘å®š `gemini-2.5-flash`ã€‚\n            -   **UI æ›´æ–°**: åœ¨â€œæ¨¡å‹æ˜ å°„â€é¡µé¢æ–°å¢äº†â€œåå°ä»»åŠ¡æ¨¡å‹â€é…ç½®é¡¹ï¼Œæ”¯æŒä»ä¸‹æ‹‰èœå•ä¸­é€‰æ‹©ä»»æ„å¯ç”¨æ¨¡å‹ï¼ˆå¦‚ `gemini-3-flash`ï¼‰ã€‚\n            -   **è·¯ç”±ä¿®å¤**: ä¿®å¤äº†åå°ä»»åŠ¡å¯èƒ½ç»•è¿‡ç”¨æˆ·è‡ªå®šä¹‰æ˜ å°„çš„é—®é¢˜ã€‚ç°åœ¨ `internal-background-task` ä¼šä¸¥æ ¼éµå¾ªç”¨æˆ·çš„é‡å®šå‘è§„åˆ™ã€‚\n        -   **[é‡è¦é€šå‘Š] ä¸Šæ¸¸æ¨¡å‹å®¹é‡é¢„è­¦ (Capacity Warning)**:\n            -   **å®¹é‡ä¸è¶³**: æ¥è·å¤§é‡åé¦ˆï¼Œä¸Šæ¸¸ Google çš„ `gemini-2.5-flash` å’Œ `gemini-2.5-flash-lite` æ¨¡å‹å½“å‰æ­£å¤„äºæåº¦å®¹é‡å—é™çŠ¶æ€ (Rate Limited / Capacity Exhausted)ã€‚\n            -   **å»ºè®®æ“ä½œ**: ä¸ºä¿è¯æœåŠ¡å¯ç”¨æ€§ï¼Œå»ºè®®ç”¨æˆ·æš‚æ—¶åœ¨â€œè‡ªå®šä¹‰æ˜ å°„â€ä¸­å°†ä¸Šè¿°ä¸¤ä¸ªæ¨¡å‹é‡å®šå‘è‡³å…¶ä»–æ¨¡å‹ï¼ˆå¦‚ `gemini-3-flash` æˆ– `gemini-3-pro-high`ï¼‰ï¼Œç›´åˆ°ä¸Šæ¸¸æ¢å¤ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] Windows å¯åŠ¨å‚æ•°æ”¯æŒ (PR #973)**:\n            -   **é—®é¢˜ä¿®å¤**: ä¿®å¤äº† Windows å¹³å°ä¸‹å¯åŠ¨å‚æ•°ï¼ˆå¦‚å†…ç½‘ç©¿é€é…ç½®ç­‰ï¼‰æ— æ³•æ­£ç¡®è§£æç”Ÿæ•ˆçš„é—®é¢˜ã€‚æ„Ÿè°¢ @Mag1cFall çš„è´¡çŒ®ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] Claude ç­¾åæ ¡éªŒå¢å¼º (PR #1009)**:\n            -   **åŠŸèƒ½ä¼˜åŒ–**: å¢å¼ºäº† Claude æ¨¡å‹çš„ç­¾åæ ¡éªŒé€»è¾‘ï¼Œä¿®å¤äº†åœ¨é•¿å¯¹è¯æˆ–å¤æ‚å·¥å…·è°ƒç”¨åœºæ™¯ä¸‹å¯èƒ½å‡ºç°çš„ 400 é”™è¯¯ã€‚\n            -   **å…¼å®¹æ€§æå‡**: å¼•å…¥æœ€å°ç­¾åé•¿åº¦æ ¡éªŒï¼Œå¹¶å¯¹åˆæ³•é•¿åº¦çš„æœªçŸ¥ç­¾åé‡‡å–ä¿¡ä»»ç­–ç•¥ï¼Œå¤§å¹…æå‡äº† JSON å·¥å…·è°ƒç”¨çš„ç¨³å®šæ€§ã€‚\n        -   **[å›½é™…åŒ–] è¶Šå—è¯­ç¿»è¯‘ä¼˜åŒ– (PR #1017)**:\n            -   **ç¿»è¯‘ç²¾ç®€**: å¯¹å…³äºé¡µé¢ç­‰åŒºåŸŸçš„è¶Šå—è¯­ç¿»è¯‘è¿›è¡Œäº†ç²¾ç®€ä¸æ ‡ç‚¹ä¼˜åŒ–ã€‚\n        -   **[å›½é™…åŒ–] åœŸè€³å…¶è¯­æ‰˜ç›˜ç¿»è¯‘å¢å¼º (PR #1023)**:\n            -   **åŠŸèƒ½ä¼˜åŒ–**: ä¸ºç³»ç»Ÿæ‰˜ç›˜èœå•å¢åŠ äº†å®Œæ•´çš„åœŸè€³å…¶è¯­ç¿»è¯‘æ”¯æŒï¼Œæå‡äº†åœŸè€³å…¶è¯­ç”¨æˆ·çš„æ“ä½œä½“éªŒã€‚\n            -   **[åŠŸèƒ½å¢å¼º] å¤šè¯­è¨€æ”¯æŒä¸ I18n è®¾ç½® (PR #1029)**:\n            -   **æ–°å¢è¯­è¨€æ”¯æŒ**: å¢åŠ äº†è‘¡è„ç‰™è¯­ã€æ—¥è¯­ã€è¶Šå—è¯­ã€åœŸè€³å…¶è¯­ã€ä¿„è¯­ç­‰å¤šå›½è¯­è¨€çš„æ›´å®Œæ•´æ”¯æŒã€‚\n            -   **I18n è®¾ç½®é¢æ¿**: åœ¨è®¾ç½®é¡µé¢æ–°å¢äº†è¯­è¨€é€‰æ‹©å™¨ï¼Œæ”¯æŒå³æ—¶åˆ‡æ¢åº”ç”¨æ˜¾ç¤ºè¯­è¨€ã€‚\n        -   **[å›½é™…åŒ–] éŸ©è¯­æ”¯æŒä¸ç•Œé¢ä¼˜åŒ– (New)**:\n            -   **éŸ©è¯­é›†æˆ**: æ–°å¢äº†å®Œæ•´çš„éŸ©è¯­ (`ko`) ç¿»è¯‘æ”¯æŒï¼Œç°åœ¨å¯ä»¥åœ¨è®¾ç½®ä¸­é€‰æ‹©éŸ©è¯­ç•Œé¢ã€‚\n            -   **UI äº¤äº’å‡çº§**: é‡æ„äº†é¡¶éƒ¨å¯¼èˆªæ çš„è¯­è¨€åˆ‡æ¢å™¨ï¼Œç”±åŸæ¥çš„å•æ¬¡ç‚¹å‡»å¾ªç¯åˆ‡æ¢å‡çº§ä¸ºæ›´ç›´è§‚çš„ä¸‹æ‹‰èœå•ï¼Œå±•ç¤ºè¯­è¨€ç¼©å†™ä¸å…¨ç§°ï¼Œæå‡äº†å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„æ“ä½œä½“éªŒã€‚\n    *   **v3.3.49 (2026-01-22)**:\n        -   **[æ ¸å¿ƒä¿®å¤] Thinking åä¸­æ–­ä¸ 0 Token é˜²å¾¡ (Fix Thinking Interruption)**:\n            -   **é—®é¢˜èƒŒæ™¯**: é’ˆå¯¹ Gemini ç­‰æ¨¡å‹åœ¨è¾“å‡º Thinking å†…å®¹åæµæ„å¤–ä¸­æ–­ï¼Œå¯¼è‡´ Claude å®¢æˆ·ç«¯æ”¶åˆ° 0 Token å“åº”å¹¶æŠ¥é”™æ­»é”çš„é—®é¢˜ã€‚\n            -   **é˜²å¾¡æœºåˆ¶**:\n                - **çŠ¶æ€è¿½è¸ª**: å®æ—¶ç›‘æµ‹æµå¼å“åº”ä¸­æ˜¯å¦â€œåªæƒ³æœªè¯´â€ï¼ˆå·²å‘é€ Thinking ä½†æœªå‘é€ Contentï¼‰ã€‚\n                - **è‡ªåŠ¨å…œåº•**: å½“æ£€æµ‹åˆ°æ­¤ç±»ä¸­æ–­æ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨é—­åˆ Thinking å—ï¼Œæ³¨å…¥ç³»ç»Ÿæç¤ºä¿¡æ¯ï¼Œå¹¶æ¨¡æ‹Ÿæ­£å¸¸çš„ Usage æ•°æ®ï¼Œç¡®ä¿å®¢æˆ·ç«¯èƒ½ä¼˜é›…ç»“æŸä¼šè¯ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] ç§»é™¤ Flash Lite æ¨¡å‹ä»¥ä¿®å¤ 429 é”™è¯¯ (Fix 429 Errors)**:\n            -   **é—®é¢˜èƒŒæ™¯**: ä»Šæ—¥ç›‘æµ‹å‘ç° `gemini-2.5-flash-lite` é¢‘ç¹å‡ºç° 429 é”™è¯¯ï¼Œå…·ä½“åŸå› ä¸º **ä¸Šæ¸¸ Google å®¹å™¨å®¹é‡è€—å°½ (MODEL_CAPACITY_EXHAUSTED)**ï¼Œè€Œéé€šå¸¸çš„è´¦å·é…é¢ä¸è¶³ã€‚\n            -   **ç´§æ€¥ä¿®å¤**: å°†æ‰€æœ‰ç³»ç»Ÿå†…éƒ¨é»˜è®¤çš„ `gemini-2.5-flash-lite` è°ƒç”¨ï¼ˆå¦‚åå°æ ‡é¢˜ç”Ÿæˆã€L3 æ‘˜è¦å‹ç¼©ï¼‰åŠé¢„è®¾æ˜ å°„å…¨éƒ¨æ›¿æ¢ä¸ºæ›´ç¨³å®šçš„ `gemini-2.5-flash`ã€‚\n            -   **ç”¨æˆ·æé†’**: å¦‚æœæ‚¨åœ¨â€œè‡ªå®šä¹‰æ˜ å°„â€æˆ–â€œé¢„è®¾â€ä¸­æ‰‹åŠ¨ä½¿ç”¨äº† `gemini-2.5-flash-lite`ï¼Œè¯·åŠ¡å¿…ä¿®æ”¹ä¸ºå…¶ä»–æ¨¡å‹ï¼Œå¦åˆ™å¯èƒ½ä¼šæŒç»­é‡åˆ° 429 é”™è¯¯ã€‚\n        -   **[æ€§èƒ½ä¼˜åŒ–] è®¾ç½®é¡¹å³æ—¶ç”Ÿæ•ˆ (Fix PR #949)**:\n            -   **å³æ—¶ç”Ÿæ•ˆ**: ä¿®å¤äº†è¯­è¨€åˆ‡æ¢éœ€è¦æ‰‹åŠ¨ç‚¹å‡»ä¿å­˜çš„é—®é¢˜ã€‚ç°åœ¨ä¿®æ”¹è¯­è¨€è®¾ç½®ä¼šç«‹å³åº”ç”¨åˆ°æ•´ä¸ª UIã€‚\n        -   **[ä»£ç æ¸…ç†] åç«¯æ¶æ„é‡æ„ä¸ä¼˜åŒ– (PR #950)**:\n            -   **æ¶æ„ç²¾ç®€**: æ·±åº¦é‡æ„äº†ä»£ç†å±‚çš„ Mapper å’Œ Handler é€»è¾‘ï¼Œç§»é™¤äº†å†—ä½™æ¨¡å—ï¼ˆå¦‚ `openai/collector.rs`ï¼‰ï¼Œæ˜¾è‘—æå‡äº†ä»£ç çš„å¯ç»´æŠ¤æ€§ã€‚\n            -   **ç¨³å®šæ€§å¢å¼º**: ä¼˜åŒ–äº† OpenAI ä¸ Claude åè®®çš„è½¬æ¢é“¾è·¯ï¼Œç»Ÿä¸€äº†å›¾ç‰‡é…ç½®è§£æé€»è¾‘ï¼Œå¹¶åŠ å›ºäº†ä¸Šä¸‹æ–‡ç®¡ç†å™¨çš„å¥å£®æ€§ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] è®¾ç½®é¡¹åŒæ­¥ç­–ç•¥æ›´æ–°**:\n            -   **çŠ¶æ€åŒæ­¥**: ä¿®æ­£äº†ä¸»é¢˜åˆ‡æ¢çš„å³æ—¶åº”ç”¨é€»è¾‘ï¼Œå¹¶è§£å†³äº† `App.tsx` ä¸ `Settings.tsx` ä¹‹é—´çš„çŠ¶æ€å†²çªï¼Œç¡®ä¿é…ç½®åŠ è½½è¿‡ç¨‹ä¸­çš„ UI ä¸€è‡´æ€§ã€‚\n        -   **[æ ¸å¿ƒä¼˜åŒ–] ä¸Šä¸‹æ–‡å‹ç¼©ä¸ Token èŠ‚çœ**:\n            -   **ç”±äº Claude CLI åœ¨æ¢å¤å†å²è®°å½•æ—¶ä¼šå‘é€å¤§é‡ä¸Šä¸‹æ–‡ï¼Œç°å·²å°†å‹ç¼©é˜ˆå€¼æ”¹ä¸ºå¯é…ç½®å¹¶é™ä½é»˜è®¤å€¼ã€‚**\n            -   **L3 æ‘˜è¦é‡ç½®é˜ˆå€¼ç”± 90% é™è‡³ 70%ï¼Œåœ¨ token å †ç§¯è¿‡å¤šå‰æå‰è¿›è¡Œå‹ç¼©èŠ‚çœé¢åº¦ã€‚**\n            -   **å‰ç«¯ UI å¢å¼ºï¼šåœ¨å®éªŒæ€§è®¾ç½®ä¸­æ–°å¢ L1/L2/L3 å‹ç¼©é˜ˆå€¼æ»‘å—ï¼Œæ”¯æŒåŠ¨æ€è‡ªå®šä¹‰ã€‚**\n        -   **[åŠŸèƒ½å¢å¼º] API ç›‘æ§çœ‹æ¿åŠŸèƒ½å‡çº§ (PR #951)**:\n            -   **è´¦å·ç­›é€‰**: æ–°å¢æŒ‰è´¦å·ç­›é€‰æµé‡æ—¥å¿—çš„åŠŸèƒ½ï¼Œæ”¯æŒåœ¨å¤§æµé‡ç¯å¢ƒä¸‹ç²¾å‡†è¿½è¸ªç‰¹å®šè´¦å·çš„è°ƒç”¨æƒ…å†µã€‚\n            -   **è¯¦æƒ…æ·±åº¦å¢å¼º**: ç›‘æ§è¯¦æƒ…é¡µç°åœ¨å¯ä»¥å®Œæ•´æ˜¾ç¤ºè¯·æ±‚åè®®ï¼ˆOpenAI/Anthropic/Geminiï¼‰ã€ä½¿ç”¨è´¦å·ã€æ˜ å°„åçš„ç‰©ç†æ¨¡å‹ç­‰å…³é”®å…ƒæ•°æ®ã€‚\n            -   **UI ä¸å›½é™…åŒ–**: ä¼˜åŒ–äº†ç›‘æ§è¯¦æƒ…çš„å¸ƒå±€ï¼Œå¹¶è¡¥å…¨äº† 8 ç§è¯­è¨€çš„ç›¸å…³ç¿»è¯‘ã€‚\n        -   **[JSON Schema ä¼˜åŒ–] é€’å½’æ”¶é›† $defs å¹¶å®Œå–„å›é€€å¤„ç† (PR #953)**:\n            -   **é€’å½’æ”¶é›†**: æ·»åŠ äº† `collect_all_defs()` ä»¥é€’å½’æ–¹å¼ä»æ‰€æœ‰æ¨¡å¼å±‚çº§æ”¶é›† `$defs`/`definitions`ï¼Œè§£å†³äº†åµŒå¥—å®šä¹‰ä¸¢å¤±çš„é—®é¢˜ã€‚\n            -   **å¼•ç”¨å¹³å¦åŒ–**: å§‹ç»ˆè¿è¡Œ `flatten_refs()` ä»¥æ•è·å¹¶å¤„ç†å­¤ç«‹çš„ `$ref` å­—æ®µã€‚\n            -   **å›é€€æœºåˆ¶**: ä¸ºæœªè§£æçš„ `$ref` æ·»åŠ äº†å›é€€é€»è¾‘ï¼Œå°†å…¶è½¬æ¢ä¸ºå¸¦æœ‰æè¿°æ€§æç¤ºçš„å­—ç¬¦ä¸²ç±»å‹ã€‚\n            -   **ç¨³å®šæ€§å¢å¼º**: æ–°å¢äº†é’ˆå¯¹åµŒå¥—å®šä¹‰å’Œæœªè§£æå¼•ç”¨çš„æµ‹è¯•ç”¨ä¾‹ï¼Œç¡®ä¿ Schema å¤„ç†çš„å¥å£®æ€§ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] è´¦å·ç´¢å¼•ä¿æŠ¤ (Fix Issue #929)**:\n            -   **å®‰å…¨åŠ å›º**: ç§»é™¤äº†åŠ è½½å¤±è´¥æ—¶çš„è‡ªåŠ¨åˆ é™¤é€»è¾‘ï¼Œé˜²æ­¢åœ¨å‡çº§æˆ–ç¯å¢ƒå¼‚å¸¸æ—¶æ„å¤–ä¸¢å¤±è´¦å·ç´¢å¼•ï¼Œç¡®ä¿ç”¨æˆ·æ•°æ®å®‰å…¨ã€‚\n        -   **[æ ¸å¿ƒä¼˜åŒ–] è·¯ç”±å™¨ä¸æ¨¡å‹æ˜ å°„æ·±åº¦ä¼˜åŒ– (PR #954)**:\n            -   **è·¯ç”±å™¨ç¡®å®šæ€§ä¼˜å…ˆçº§**: ä¿®å¤äº†è·¯ç”±å™¨åœ¨å¤„ç†å¤šé€šé…ç¬¦æ¨¡å¼æ—¶çš„ä¸ç¡®å®šæ€§é—®é¢˜ï¼Œå®ç°äº†åŸºäºæ¨¡å¼é•¿åº¦å’Œå¤æ‚åº¦çš„ç¡®å®šæ€§åŒ¹é…ä¼˜å…ˆçº§ã€‚\n\n        -   **[ç¨³å®šæ€§å¢å¼º] OAuth å›è°ƒä¸è§£æä¼˜åŒ– (Fix #931, #850, #778)**:\n            -   **é²æ£’è§£æ**: ä¼˜åŒ–äº†æœ¬åœ°å›è°ƒæœåŠ¡å™¨çš„ URL è§£æé€»è¾‘ï¼Œä¸å†ä¾èµ–å•ä¸€åˆ†å‰²ç¬¦ï¼Œæå‡äº†ä¸åŒæµè§ˆå™¨ä¸‹çš„å…¼å®¹æ€§ã€‚\n            -   **è°ƒè¯•å¢å¼º**: å¢åŠ äº†åŸå§‹è¯·æ±‚ (Raw Request) è®°å½•åŠŸèƒ½ï¼Œå½“æˆæƒå¤±è´¥æ—¶å¯ç›´æ¥åœ¨æ—¥å¿—ä¸­æŸ¥çœ‹åŸå§‹æ•°æ®ï¼Œæ–¹ä¾¿å®šä½ç½‘ç»œæ‹¦æˆªé—®é¢˜ã€‚\n        -   **[ç½‘ç»œä¼˜åŒ–] OAuth é€šä¿¡è´¨é‡æå‡ (Issue #948, #887)**:\n            -   **å»¶æ—¶ä¿éšœ**: å°†æˆæƒè¯·æ±‚è¶…æ—¶æ—¶é—´å»¶é•¿è‡³ 60 ç§’ï¼Œå¤§å¹…æå‡äº†åœ¨ä»£ç†ç¯å¢ƒä¸‹çš„ Token äº¤æ¢æˆåŠŸç‡ã€‚\n            -   **é”™è¯¯æŒ‡å¼•**: é’ˆå¯¹ Google API è¿æ¥è¶…æ—¶æˆ–é‡ç½®çš„æƒ…å†µï¼Œæ–°å¢äº†æ˜ç¡®çš„ä¸­æ–‡ä»£ç†è®¾ç½®å»ºè®®ï¼Œé™ä½æ’æŸ¥é—¨æ§›ã€‚\n        -   **[ä½“éªŒä¼˜åŒ–] ä¸Šæ¸¸ä»£ç†é…ç½®æ ¡éªŒä¸æç¤ºå¢å¼º (Contributed by @zhiqianzheng)**:\n            -   **é…ç½®æ ¡éªŒ**: å½“ç”¨æˆ·å¯ç”¨ä¸Šæ¸¸ä»£ç†ä½†æœªå¡«å†™ä»£ç†åœ°å€æ—¶ï¼Œä¿å­˜æ“ä½œå°†è¢«é˜»æ­¢å¹¶æ˜¾ç¤ºæ˜ç¡®çš„é”™è¯¯æç¤ºï¼Œé¿å…æ— æ•ˆé…ç½®å¯¼è‡´çš„è¿æ¥å¤±è´¥ã€‚\n            -   **é‡å¯æé†’**: æˆåŠŸä¿å­˜ä»£ç†é…ç½®åï¼Œç³»ç»Ÿä¼šæç¤ºç”¨æˆ·éœ€è¦é‡å¯åº”ç”¨æ‰èƒ½ä½¿é…ç½®ç”Ÿæ•ˆï¼Œé™ä½ç”¨æˆ·æ’æŸ¥æˆæœ¬ã€‚\n            -   **å¤šè¯­è¨€æ”¯æŒ**: æ–°å¢ç®€ä½“ä¸­æ–‡ã€ç¹ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ—¥è¯­çš„ç›¸å…³ç¿»è¯‘ã€‚\n\n    *   **v3.3.48 (2026-01-21)**:\n        -   **[æ ¸å¿ƒä¿®å¤] Windows æ§åˆ¶å°é—ªçƒé—®é¢˜ (Fix PR #933)**:\n            -   **é—®é¢˜èƒŒæ™¯**: Windows å¹³å°åœ¨å¯åŠ¨æˆ–æ‰§è¡Œåå°å‘½ä»¤æ—¶ï¼Œå¶å°”ä¼šå¼¹å‡ºçŸ­æš‚çš„ CMD çª—å£ï¼Œå½±å“ç”¨æˆ·ä½“éªŒã€‚\n            -   **ä¿®å¤å†…å®¹**: åœ¨ `cloudflared` è¿›ç¨‹åˆ›å»ºé€»è¾‘ä¸­æ·»åŠ  `CREATE_NO_WINDOW` æ ‡å¿—ï¼Œç¡®ä¿æ‰€æœ‰åå°è¿›ç¨‹é™é»˜è¿è¡Œã€‚\n            -   **å½±å“èŒƒå›´**: è§£å†³äº† Windows ç”¨æˆ·åœ¨å¯åŠ¨åº”ç”¨æˆ– CLI äº¤äº’æ—¶çš„çª—å£é—ªçƒé—®é¢˜ã€‚\n    *   **v3.3.47 (2026-01-21)**:\n        -   **[æ ¸å¿ƒä¿®å¤] å›¾ç‰‡ç”Ÿæˆ API å‚æ•°æ˜ å°„å¢å¼º (Fix Issue #911)**:\n            -   **åŠŸèƒ½**: æ”¯æŒä» OpenAI å‚æ•° (`size`, `quality`) è§£æé…ç½®ï¼Œæ”¯æŒåŠ¨æ€å®½é«˜æ¯”è®¡ç®—ï¼Œ`quality: hd` è‡ªåŠ¨æ˜ å°„ä¸º 4K åˆ†è¾¨ç‡ã€‚\n            -   **å½±å“**: æ˜¾è‘—æå‡ Images API å…¼å®¹æ€§ï¼ŒOpenAI ä¸ Claude åè®®å‡å—æ”¯æŒã€‚\n        -   **[åŠŸèƒ½å¢å¼º] Cloudflared å†…ç½‘ç©¿é€æ”¯æŒ (PR #923)**:\n            -   **æ ¸å¿ƒåŠŸèƒ½**: é›†æˆ `cloudflared` éš§é“æ”¯æŒï¼Œå…è®¸ç”¨æˆ·åœ¨æ— å…¬ç½‘ IP æˆ–å¤„äºå¤æ‚å†…ç½‘ç¯å¢ƒä¸‹ï¼Œé€šè¿‡ Cloudflare éš§é“ä¸€é”®å‘å¸ƒ API æœåŠ¡ã€‚\n            -   **æ˜“ç”¨æ€§ä¼˜åŒ–**: å‰ç«¯æ–°å¢ Cloudflared é…ç½®ç•Œé¢ï¼Œæ”¯æŒçŠ¶æ€ç›‘æ§ã€æ—¥å¿—æŸ¥çœ‹åŠä¸€é”®å¼€å…³éš§é“ã€‚\n            -   **å›½é™…åŒ–è¡¥å…¨**: è¡¥å…¨äº†ç¹ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ã€è¶Šå—è¯­ã€åœŸè€³å…¶è¯­ã€ä¿„è¯­ç­‰ 8 å›½è¯­è¨€çš„ Cloudflared ç›¸å…³ç¿»è¯‘ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] è§£å†³ Git åˆå¹¶å†²çªå¯¼è‡´çš„å¯åŠ¨å¤±è´¥**:\n            -   **ä¿®å¤å†…å®¹**: è§£å†³äº† `src-tauri/src/proxy/handlers/claude.rs` ä¸­å› å¤šè¿›ç¨‹å¹¶è¡Œåˆå¹¶äº§ç”Ÿçš„ `<<<<<<< HEAD` å†²çªæ ‡è®°ã€‚\n            -   **å½±å“èŒƒå›´**: æ¢å¤äº†åç«¯æœåŠ¡çš„ç¼–è¯‘èƒ½åŠ›ï¼Œä¿®å¤äº†åº”ç”¨å¯åŠ¨å³å´©æºƒçš„é—®é¢˜ã€‚\n        -   **[æ ¸å¿ƒä¼˜åŒ–] ä¸‰å±‚æ¸è¿›å¼ä¸Šä¸‹æ–‡å‹ç¼© (3-Layer Progressive Context PCC)**:\n            -   **èƒŒæ™¯**: é•¿å¯¹è¯åœºæ™¯ä¸‹é¢‘ç¹è§¦å‘ \"Prompt is too long\" é”™è¯¯ï¼Œæ‰‹åŠ¨ `/compact` æ“ä½œç¹çï¼Œä¸”ç°æœ‰å‹ç¼©ç­–ç•¥ä¼šç ´å LLM çš„ KV Cacheï¼Œå¯¼è‡´æˆæœ¬é£™å‡\n            -   **è§£å†³æ–¹æ¡ˆ - å¤šå±‚æ¸è¿›å¼å‹ç¼©ç­–ç•¥**:\n                - **Layer 1 (60% å‹åŠ›)**: å·¥å…·æ¶ˆæ¯æ™ºèƒ½è£å‰ª\n                    - åˆ é™¤æ—§çš„å·¥å…·è°ƒç”¨/ç»“æœæ¶ˆæ¯ï¼Œä¿ç•™æœ€è¿‘ 5 è½®äº¤äº’\n                    - **å®Œå…¨ä¸ç ´å KV Cache**ï¼ˆåªåˆ é™¤æ¶ˆæ¯ï¼Œä¸ä¿®æ”¹å†…å®¹ï¼‰\n                    - å‹ç¼©ç‡ï¼š60-90%\n                - **Layer 2 (75% å‹åŠ›)**: Thinking å†…å®¹å‹ç¼© + ç­¾åä¿ç•™\n                    - å‹ç¼© `assistant` æ¶ˆæ¯ä¸­çš„ Thinking å—æ–‡æœ¬å†…å®¹ï¼ˆæ›¿æ¢ä¸º \"...\"ï¼‰\n                    - **å®Œæ•´ä¿ç•™ `signature` å­—æ®µ**ï¼Œè§£å†³ Issue #902ï¼ˆç­¾åä¸¢å¤±å¯¼è‡´ 400 é”™è¯¯ï¼‰\n                    - ä¿æŠ¤æœ€è¿‘ 4 æ¡æ¶ˆæ¯ä¸è¢«å‹ç¼©\n                    - å‹ç¼©ç‡ï¼š70-95%\n                - **Layer 3 (90% å‹åŠ›)**: Fork ä¼šè¯ + XML æ‘˜è¦\n                    - ä½¿ç”¨ `gemini-2.5-flash-lite` ç”Ÿæˆ 8 èŠ‚ XML ç»“æ„åŒ–æ‘˜è¦ï¼ˆæˆæœ¬æä½ï¼‰\n                    - æå–å¹¶ä¿ç•™æœ€åä¸€ä¸ªæœ‰æ•ˆ Thinking ç­¾å\n                    - åˆ›å»ºæ–°çš„æ¶ˆæ¯åºåˆ—ï¼š`[User: XMLæ‘˜è¦] + [Assistant: ç¡®è®¤] + [ç”¨æˆ·æœ€æ–°æ¶ˆæ¯]`\n                    - **å®Œå…¨ä¸ç ´å Prompt Cache**ï¼ˆå‰ç¼€ç¨³å®šï¼Œåªè¿½åŠ ï¼‰\n                    - å‹ç¼©ç‡ï¼š86-97%\n            -   **æŠ€æœ¯å®ç°**:\n                - **æ–°å¢æ¨¡å—**: `context_manager.rs` ä¸­å®ç° Token ä¼°ç®—ã€å·¥å…·è£å‰ªã€Thinking å‹ç¼©ã€ç­¾åæå–ç­‰æ ¸å¿ƒåŠŸèƒ½\n                - **è¾…åŠ©å‡½æ•°**: `call_gemini_sync()` - å¯å¤ç”¨çš„åŒæ­¥ä¸Šæ¸¸è°ƒç”¨å‡½æ•°\n                - **XML æ‘˜è¦æ¨¡æ¿**: 8 èŠ‚ç»“æ„åŒ–æ‘˜è¦ï¼ˆç›®æ ‡ã€æŠ€æœ¯æ ˆã€æ–‡ä»¶çŠ¶æ€ã€ä»£ç å˜æ›´ã€è°ƒè¯•å†å²ã€è®¡åˆ’ã€åå¥½ã€ç­¾åï¼‰\n                - **æ¸è¿›å¼è§¦å‘**: æŒ‰å‹åŠ›ç­‰çº§è‡ªåŠ¨è§¦å‘ï¼Œæ¯æ¬¡å‹ç¼©åé‡æ–°ä¼°ç®— Token ç”¨é‡\n            -   **æˆæœ¬ä¼˜åŒ–**:\n                - Layer 1: å®Œå…¨æ— æˆæœ¬ï¼ˆä¸ç ´åç¼“å­˜ï¼‰\n                - Layer 2: ä½æˆæœ¬ï¼ˆä»…ç ´åéƒ¨åˆ†ç¼“å­˜ï¼‰\n                - Layer 3: æä½æˆæœ¬ï¼ˆæ‘˜è¦ç”Ÿæˆä½¿ç”¨ flash-liteï¼Œæ–°ä¼šè¯å®Œå…¨ç¼“å­˜å‹å¥½ï¼‰\n                - **ç»¼åˆèŠ‚çœ**: 86-97% Token æˆæœ¬ï¼ŒåŒæ—¶ä¿æŒç­¾åé“¾å®Œæ•´æ€§\n            -   **ç”¨æˆ·ä½“éªŒ**:\n                - è‡ªåŠ¨åŒ–ï¼šæ— éœ€æ‰‹åŠ¨ `/compact`ï¼Œç³»ç»Ÿè‡ªåŠ¨å¤„ç†\n                - é€æ˜åŒ–ï¼šè¯¦ç»†æ—¥å¿—è®°å½•æ¯å±‚å‹ç¼©çš„è§¦å‘å’Œæ•ˆæœ\n                - å®¹é”™æ€§ï¼šLayer 3 å¤±è´¥æ—¶è¿”å›å‹å¥½é”™è¯¯æç¤º\n            -   **å½±å“èŒƒå›´**: è§£å†³é•¿å¯¹è¯åœºæ™¯ä¸‹çš„ä¸Šä¸‹æ–‡ç®¡ç†é—®é¢˜,æ˜¾è‘—é™ä½ API æˆæœ¬,ç¡®ä¿å·¥å…·è°ƒç”¨é“¾å®Œæ•´æ€§\n        -   **[æ ¸å¿ƒä¼˜åŒ–] ä¸Šä¸‹æ–‡ä¼°ç®—ä¸ç¼©æ”¾ç®—æ³•å¢å¼º (PR #925)**:\n            -   **èƒŒæ™¯**: åœ¨ Claude Code ç­‰é•¿å¯¹è¯åœºæ™¯ä¸‹,å›ºå®šçš„ Token ä¼°ç®—ç®—æ³•ï¼ˆ3.5 å­—ç¬¦/tokenï¼‰åœ¨ä¸­è‹±æ–‡æ··æ’æ—¶è¯¯å·®æå¤§,å¯¼è‡´ä¸‰å±‚å‹ç¼©é€»è¾‘æ— æ³•åŠæ—¶è§¦å‘,æœ€ç»ˆä»ä¼šæŠ¥ \"Prompt is too long\" é”™è¯¯\n            -   **è§£å†³æ–¹æ¡ˆ - åŠ¨æ€æ ¡å‡† + å¤šè¯­è¨€æ„ŸçŸ¥**:\n                - **å¤šè¯­è¨€æ„ŸçŸ¥ä¼°ç®—**:\n                    - **ASCII/è‹±æ–‡**: çº¦ä¸º 4 å­—ç¬¦/Tokenï¼ˆé’ˆå¯¹ä»£ç å’Œè‹±æ–‡æ–‡æ¡£ä¼˜åŒ–ï¼‰\n                    - **Unicode/CJK (ä¸­æ—¥éŸ©)**: çº¦ä¸º 1.5 å­—ç¬¦/Tokenï¼ˆé’ˆå¯¹ Gemini/Claude åˆ†è¯ç‰¹ç‚¹ï¼‰\n                    - **å®‰å…¨ä½™é‡**: åœ¨è®¡ç®—ç»“æœåŸºç¡€ä¸Šé¢å¤–å¢åŠ  15% çš„å®‰å…¨å†—ä½™\n                - **åŠ¨æ€æ ¡å‡†å™¨ (`estimation_calibrator.rs`)**:\n                    - **è‡ªå­¦ä¹ æœºåˆ¶**: è®°å½•æ¯æ¬¡è¯·æ±‚çš„\"ä¼°ç®— Token æ•°\"ä¸ Google API è¿”å›çš„\"å®é™… Token æ•°\"\n                    - **æ ¡å‡†å› å­**: ä½¿ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡ (EMA, 60% æ—§æ¯”ä¾‹ + 40% æ–°æ¯”ä¾‹) ç»´æŠ¤æ ¡å‡†ç³»æ•°\n                    - **ä¿å®ˆåˆå§‹åŒ–**: åˆå§‹æ ¡å‡†ç³»æ•°ä¸º 2.0,ç¡®ä¿ç³»ç»Ÿè¿è¡ŒåˆæœŸæå…¶ä¿å®ˆåœ°è§¦å‘å‹ç¼©\n                    - **è‡ªåŠ¨æ”¶æ•›**: æ ¹æ®å®é™…æ•°æ®è‡ªåŠ¨ä¿®æ­£,ä½¿ä¼°ç®—å€¼è¶Šæ¥è¶Šæ¥è¿‘çœŸå®å€¼\n                - **æ•´åˆä¸‰å±‚å‹ç¼©æ¡†æ¶**:\n                    - åœ¨æ‰€æœ‰ä¼°ç®—ç¯èŠ‚ï¼ˆåˆå§‹ä¼°ç®—ã€Layer 1/2/3 åé‡æ–°ä¼°ç®—ï¼‰ä½¿ç”¨æ ¡å‡†åçš„ Token æ•°\n                    - æ¯å±‚å‹ç¼©åè®°å½•è¯¦ç»†çš„æ ¡å‡†å› å­æ—¥å¿—,ä¾¿äºè°ƒè¯•å’Œç›‘æ§\n            -   **æŠ€æœ¯å®ç°**:\n                - **æ–°å¢æ¨¡å—**: `estimation_calibrator.rs` - å…¨å±€å•ä¾‹æ ¡å‡†å™¨,çº¿ç¨‹å®‰å…¨\n                - **ä¿®æ”¹æ–‡ä»¶**: `claude.rs`, `streaming.rs`, `context_manager.rs`\n                - **æ ¡å‡†æ•°æ®æµ**: æµå¼å“åº”æ”¶é›†å™¨ â†’ æå–çœŸå® Token æ•° â†’ æ›´æ–°æ ¡å‡†å™¨ â†’ ä¸‹æ¬¡è¯·æ±‚ä½¿ç”¨æ–°ç³»æ•°\n            -   **ç”¨æˆ·ä½“éªŒ**:\n                - **é€æ˜åŒ–**: æ—¥å¿—ä¸­æ˜¾ç¤ºåŸå§‹ä¼°ç®—å€¼ã€æ ¡å‡†åä¼°ç®—å€¼ã€æ ¡å‡†å› å­,ä¾¿äºç†è§£ç³»ç»Ÿè¡Œä¸º\n                - **è‡ªé€‚åº”**: ç³»ç»Ÿä¼šæ ¹æ®ç”¨æˆ·çš„å®é™…ä½¿ç”¨æ¨¡å¼ï¼ˆä¸­è‹±æ–‡æ¯”ä¾‹ã€ä»£ç é‡ç­‰ï¼‰è‡ªåŠ¨è°ƒæ•´\n                - **ç²¾å‡†è§¦å‘**: å‹ç¼©é€»è¾‘åŸºäºæ›´å‡†ç¡®çš„ä¼°ç®—å€¼,å¤§å¹…é™ä½\"æ¼åˆ¤\"å’Œ\"è¯¯åˆ¤\"æ¦‚ç‡\n            -   **å½±å“èŒƒå›´**: æ˜¾è‘—æå‡ä¸Šä¸‹æ–‡ç®¡ç†çš„ç²¾å‡†åº¦,è§£å†³ Issue #902 å’Œ #867 ä¸­åé¦ˆçš„è‡ªåŠ¨å‹ç¼©å¤±æ•ˆé—®é¢˜,ç¡®ä¿é•¿å¯¹è¯ç¨³å®šæ€§\n        -   **[å…³é”®ä¿®å¤] Thinking ç­¾åæ¢å¤é€»è¾‘ä¼˜åŒ–**:\n            -   **èƒŒæ™¯**: åœ¨é‡è¯•åœºæ™¯ä¸‹,ç­¾åæ£€æŸ¥é€»è¾‘æœªæ£€æŸ¥ Session Cache,å¯¼è‡´é”™è¯¯ç¦ç”¨ Thinking æ¨¡å¼,äº§ç”Ÿ 0 token è¯·æ±‚å’Œå“åº”å¤±è´¥\n            -   **é—®é¢˜è¡¨ç°**:\n                - é‡è¯•æ—¶æ˜¾ç¤º \"No valid signature found for function calls. Disabling thinking\"\n                - æµé‡æ—¥å¿—æ˜¾ç¤º `I: 0, O: 0` (å®é™…è¯·æ±‚æˆåŠŸä½† Token æœªè®°å½•)\n                - å®¢æˆ·ç«¯å¯èƒ½æ— æ³•æ¥æ”¶åˆ°å“åº”å†…å®¹\n            -   **ä¿®å¤å†…å®¹**:\n                - **æ‰©å±•ç­¾åæ£€æŸ¥èŒƒå›´**: `has_valid_signature_for_function_calls()` ç°åœ¨æ£€æŸ¥ Session Cache\n                - **æ£€æŸ¥ä¼˜å…ˆçº§**: Global Store â†’ **Session Cache (æ–°å¢)** â†’ Message History\n                - **è¯¦ç»†æ—¥å¿—**: æ·»åŠ ç­¾åæ¥æºè¿½è¸ªæ—¥å¿—,ä¾¿äºè°ƒè¯•\n            -   **æŠ€æœ¯å®ç°**:\n                - ä¿®æ”¹ `request.rs` ä¸­çš„ç­¾åéªŒè¯é€»è¾‘\n                - æ–°å¢ `session_id` å‚æ•°ä¼ é€’åˆ°ç­¾åæ£€æŸ¥å‡½æ•°\n                - æ·»åŠ  `[Signature-Check]` ç³»åˆ—æ—¥å¿—ç”¨äºè¿½è¸ªç­¾åæ¢å¤è¿‡ç¨‹\n            -   **å½±å“**: è§£å†³é‡è¯•åœºæ™¯ä¸‹çš„ Thinking æ¨¡å¼é™çº§é—®é¢˜,ç¡®ä¿ Token ç»Ÿè®¡å‡†ç¡®æ€§,æå‡é•¿ä¼šè¯ç¨³å®šæ€§\n        -   **[æ ¸å¿ƒä¿®å¤] é€šç”¨å‚æ•°å¯¹é½å¼•æ“ (Universal Parameter Alignment Engine)**:\n            -   **èƒŒæ™¯**: è§£å†³ Gemini API åœ¨è°ƒç”¨å·¥å…·ï¼ˆTool Useï¼‰æ—¶å› å‚æ•°ç±»å‹ä¸åŒ¹é…äº§ç”Ÿçš„ `400 Bad Request` é”™è¯¯ã€‚\n            -   **ä¿®å¤å†…å®¹**:\n                - **å®ç°å‚æ•°å¯¹é½å¼•æ“**: åœ¨ `json_schema.rs` ä¸­å®ç° `fix_tool_call_args`ï¼ŒåŸºäº JSON Schema è‡ªåŠ¨å°†å­—ç¬¦ä¸²ç±»å‹çš„æ•°å­—/å¸ƒå°”å€¼è½¬æ¢ä¸ºç›®æ ‡ç±»å‹ï¼Œå¹¶å¤„ç†éæ³•å­—æ®µã€‚\n                - **å¤šåè®®é‡æ„**: åŒæ­¥é‡æ„äº† OpenAI å’Œ Claude åè®®å±‚ï¼Œç§»é™¤äº†ç¡¬ç¼–ç çš„å·¥å…·å‚æ•°ä¿®æ­£é€»è¾‘ï¼Œæ”¹ç”¨ç»Ÿä¸€çš„å¯¹é½å¼•æ“ã€‚\n            -   **è§£å†³é—®é¢˜**: ä¿®å¤äº† `local_shell_call`ã€`apply_patch` ç­‰å·¥å…·åœ¨å¤šçº§åä»£æˆ–ç‰¹å®šå®¢æˆ·ç«¯ä¸‹å‚æ•°è¢«é”™è¯¯æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²å¯¼è‡´çš„å¼‚å¸¸ã€‚\n            -   **å½±å“**: æ˜¾è‘—æå‡äº†å·¥å…·è°ƒç”¨çš„ç¨³å®šæ€§ï¼Œå‡å°‘äº†ä¸Šæ¸¸ API çš„ 400 é”™è¯¯ã€‚\n        -   **[åŠŸèƒ½å¢å¼º] ç”»å›¾æ¨¡å‹é…é¢ä¿æŠ¤æ”¯æŒ (Fix Issue #912)**:\n            -   **é—®é¢˜èƒŒæ™¯**: ç”¨æˆ·åé¦ˆç”»å›¾æ¨¡å‹ï¼ˆG3 Imageï¼‰æ²¡æœ‰é…é¢ä¿æŠ¤åŠŸèƒ½ï¼Œå¯¼è‡´é…é¢è€—å°½çš„è´¦å·ä»è¢«ç”¨äºç”»å›¾è¯·æ±‚\n            -   **ä¿®å¤å†…å®¹**:\n                - **åç«¯é…ç½®**: åœ¨ `config.rs` çš„ `default_monitored_models()` ä¸­æ·»åŠ  `gemini-3-pro-image`ï¼Œä¸æ™ºèƒ½é¢„çƒ­å’Œé…é¢å…³æ³¨åˆ—è¡¨ä¿æŒä¸€è‡´\n                - **å‰ç«¯ UI**: åœ¨ `QuotaProtection.tsx` ä¸­æ·»åŠ ç”»å›¾æ¨¡å‹é€‰é¡¹ï¼Œè°ƒæ•´å¸ƒå±€ä¸ºä¸€è¡Œ4ä¸ªæ¨¡å‹ï¼ˆä¸æ™ºèƒ½é¢„çƒ­ä¿æŒä¸€è‡´ï¼‰\n            -   **å½±å“èŒƒå›´**: \n                - âœ… å‘åå…¼å®¹ï¼šå·²æœ‰é…ç½®ä¸å—å½±å“ï¼Œæ–°ç”¨æˆ·æˆ–é‡ç½®é…ç½®åä¼šè‡ªåŠ¨åŒ…å«ç”»å›¾æ¨¡å‹\n                - âœ… å®Œæ•´ä¿æŠ¤ï¼šç°åœ¨æ‰€æœ‰4ä¸ªæ ¸å¿ƒæ¨¡å‹ï¼ˆGemini 3 Flashã€Gemini 3 Pro Highã€Claude 4.5 Sonnetã€Gemini 3 Pro Imageï¼‰éƒ½å—é…é¢ä¿æŠ¤ç›‘æ§\n                - âœ… è‡ªåŠ¨è§¦å‘ï¼šå½“ç”»å›¾æ¨¡å‹é…é¢ä½äºé˜ˆå€¼æ—¶ï¼Œè´¦å·ä¼šè‡ªåŠ¨åŠ å…¥ä¿æŠ¤åˆ—è¡¨ï¼Œé¿å…ç»§ç»­æ¶ˆè€—\n        -   **[ä¼ è¾“å±‚ä¼˜åŒ–] æµå¼å“åº”é˜²ç¼“å†²ä¼˜åŒ– (Streaming Response Anti-Buffering)**:\n            -   **èƒŒæ™¯**: åœ¨ Nginx ç­‰åå‘ä»£ç†åéƒ¨ç½²æ—¶ï¼Œæµå¼å“åº”å¯èƒ½è¢«ä»£ç†ç¼“å†²ï¼Œå¯¼è‡´å®¢æˆ·ç«¯å»¶è¿Ÿå¢åŠ \n            -   **ä¿®å¤å†…å®¹**:\n                - **æ·»åŠ  X-Accel-Buffering Header**: åœ¨æ‰€æœ‰æµå¼å“åº”ä¸­æ³¨å…¥ `X-Accel-Buffering: no` å¤´éƒ¨\n                - **å¤šåè®®è¦†ç›–**: Claude (`/v1/messages`)ã€OpenAI (`/v1/chat/completions`) å’Œ Gemini åŸç”Ÿåè®®å…¨éƒ¨æ”¯æŒ\n            -   **æŠ€æœ¯ç»†èŠ‚**:\n                - ä¿®æ”¹æ–‡ä»¶: `claude.rs:L877`, `openai.rs:L314`, `gemini.rs:L240`\n                - è¯¥ Header å‘Šè¯‰ Nginx ç­‰åå‘ä»£ç†ä¸è¦ç¼“å†²æµå¼å“åº”ï¼Œç›´æ¥é€ä¼ ç»™å®¢æˆ·ç«¯\n            -   **å½±å“**: æ˜¾è‘—é™ä½åå‘ä»£ç†åœºæ™¯ä¸‹çš„æµå¼å“åº”å»¶è¿Ÿï¼Œæå‡ç”¨æˆ·ä½“éªŒ\n        -   **[é”™è¯¯æ¢å¤å¢å¼º] å¤šåè®®ç­¾åé”™è¯¯è‡ªæ„ˆæç¤ºè¯ (Multi-Protocol Signature Error Recovery)**:\n            -   **èƒŒæ™¯**: å½“ Thinking æ¨¡å¼ä¸‹å‡ºç°ç­¾åé”™è¯¯æ—¶ï¼Œä»…å‰”é™¤ç­¾åå¯èƒ½å¯¼è‡´æ¨¡å‹ç”Ÿæˆç©ºå“åº”æˆ–ç®€å•çš„ \"OK\"\n            -   **ä¿®å¤å†…å®¹**:\n                - **Claude åè®®å¢å¼º**: åœ¨ç°æœ‰ç­¾åé”™è¯¯é‡è¯•é€»è¾‘ä¸­è¿½åŠ ä¿®å¤æç¤ºè¯ï¼Œå¼•å¯¼æ¨¡å‹é‡æ–°ç”Ÿæˆå®Œæ•´å“åº”\n                - **OpenAI åè®®å®ç°**: æ–°å¢ 400 ç­¾åé”™è¯¯æ£€æµ‹å’Œä¿®å¤æç¤ºè¯æ³¨å…¥é€»è¾‘\n                - **Gemini åè®®å®ç°**: æ–°å¢ 400 ç­¾åé”™è¯¯æ£€æµ‹å’Œä¿®å¤æç¤ºè¯æ³¨å…¥é€»è¾‘\n            -   **ä¿®å¤æç¤ºè¯**:\n                ```\n                [System Recovery] Your previous output contained an invalid signature. \n                Please regenerate the response without the corrupted signature block.\n                ```\n            -   **æŠ€æœ¯ç»†èŠ‚**:\n                - Claude: `claude.rs:L1012-1030` - å¢å¼ºç°æœ‰é€»è¾‘ï¼Œæ”¯æŒ String å’Œ Array æ¶ˆæ¯æ ¼å¼\n                - OpenAI: `openai.rs:L391-427` - å®Œæ•´å®ç°ï¼Œä½¿ç”¨ `OpenAIContentBlock::Text` ç±»å‹\n                - Gemini: `gemini.rs:L17, L299-329` - ä¿®æ”¹å‡½æ•°ç­¾åæ”¯æŒå¯å˜ bodyï¼Œæ³¨å…¥ä¿®å¤æç¤ºè¯\n            -   **å½±å“**: \n                - âœ… æå‡é”™è¯¯æ¢å¤æˆåŠŸç‡ï¼šæ¨¡å‹æ”¶åˆ°æ˜ç¡®æŒ‡ä»¤ï¼Œé¿å…ç”Ÿæˆæ— æ„ä¹‰å“åº”\n                - âœ… å¤šåè®®ä¸€è‡´æ€§ï¼šæ‰€æœ‰ 3 ä¸ªåè®®å…·æœ‰ç›¸åŒçš„é”™è¯¯æ¢å¤èƒ½åŠ›\n                - âœ… ç”¨æˆ·ä½“éªŒæ”¹å–„ï¼šå‡å°‘å› ç­¾åé”™è¯¯å¯¼è‡´çš„å¯¹è¯ä¸­æ–­\n    *   **v3.3.46 (2026-01-20)**:\n        -   **[åŠŸèƒ½å¢å¼º] Token ä½¿ç”¨ç»Ÿè®¡ (Token Stats) æ·±åº¦ä¼˜åŒ–ä¸å›½é™…åŒ–æ ‡å‡†åŒ– (PR #892)**:\n            -   **UI/UX ç»Ÿä¸€**: å®ç°äº†è‡ªå®šä¹‰ Tooltip ç»„ä»¶ï¼Œç»Ÿä¸€äº†é¢ç§¯å›¾ã€æŸ±çŠ¶å›¾å’Œé¥¼å›¾çš„æ‚¬æµ®æç¤ºæ ·å¼ï¼Œå¢å¼ºäº†æ·±è‰²æ¨¡å¼ä¸‹çš„å¯¹æ¯”åº¦ä¸å¯è¯»æ€§ã€‚\n            -   **è§†è§‰ç»†èŠ‚ç£¨ç ‚**: ä¼˜åŒ–äº†å›¾è¡¨å…‰æ ‡å’Œç½‘æ ¼çº¿ï¼Œç§»é™¤å†—ä½™çš„ hover é«˜äº®ï¼Œä½¿å›¾è¡¨ç•Œé¢æ›´åŠ æ¸…çˆ½ä¸“ä¸šã€‚\n            -   **è‡ªé€‚åº”å¸ƒå±€**: æ”¹è¿›äº†å›¾è¡¨å®¹å™¨çš„ Flex å¸ƒå±€ï¼Œç¡®ä¿åœ¨ä¸åŒçª—å£å°ºå¯¸ä¸‹å‡èƒ½å¡«å……æ»¡å‚ç›´ç©ºé—´ï¼Œæ¶ˆé™¤äº†å›¾è¡¨ä¸‹æ–¹çš„ç•™ç™½ã€‚\n            -   **åˆ†è´¦å·è¶‹åŠ¿ç»Ÿè®¡**: æ–°å¢äº†â€œæŒ‰è´¦å·æŸ¥çœ‹â€æ¨¡å¼ï¼Œæ”¯æŒé€šè¿‡é¥¼å›¾å’Œè¶‹åŠ¿å›¾ç›´è§‚åˆ†æå„è´¦å·çš„ Token æ¶ˆè€—å æ¯”ä¸æ´»è·ƒåº¦ã€‚\n            -   **å›½é™…åŒ– (i18n) æ ‡å‡†åŒ–**: è§£å†³äº† `ja.json`ã€`zh-TW.json`ã€`vi.json`ã€`ru.json`ã€`tr.json` ç­‰å¤šå›½è¯­è¨€æ–‡ä»¶ä¸­çš„é”®å€¼é‡å¤è­¦å‘Šã€‚è¡¥å…¨äº† `account_trend`ã€`by_model` ç­‰ç¼ºå¤±ç¿»è¯‘ï¼Œç¡®ä¿ 8 ç§è¯­è¨€ä¸‹çš„ UI å±•ç°é«˜åº¦ä¸€è‡´ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] ç§»é™¤ [DONE] åœæ­¢åºåˆ—ä»¥é˜²æ­¢è¾“å‡ºæˆªæ–­ (PR #889)**:\n            -   **é—®é¢˜èƒŒæ™¯**: `[DONE]` æ˜¯ SSE (Server-Sent Events) åè®®çš„æ ‡å‡†ç»“æŸæ ‡è®°,åœ¨ä»£ç å’Œæ–‡æ¡£ä¸­ç»å¸¸å‡ºç°ã€‚å°†å…¶ä½œä¸º `stopSequence` ä¼šå¯¼è‡´æ¨¡å‹åœ¨è§£é‡Š SSE ç›¸å…³å†…å®¹æ—¶è¾“å‡ºè¢«æ„å¤–æˆªæ–­ã€‚\n            -   **ä¿®å¤å†…å®¹**: ä» Gemini è¯·æ±‚çš„ `stopSequences` æ•°ç»„ä¸­ç§»é™¤äº† `\"[DONE]\"` æ ‡è®°ã€‚\n            -   **æŠ€æœ¯è¯´æ˜**:\n                - Gemini æµçš„çœŸæ­£ç»“æŸç”± `finishReason` å­—æ®µæ§åˆ¶,æ— éœ€ä¾èµ– `stopSequence`\n                - SSE å±‚é¢çš„ `\"data: [DONE]\"` å·²åœ¨ `mod.rs` ä¸­å•ç‹¬å¤„ç†\n            -   **å½±å“èŒƒå›´**: è§£å†³äº†æ¨¡å‹åœ¨ç”ŸæˆåŒ…å« SSE åè®®è¯´æ˜ã€ä»£ç ç¤ºä¾‹ç­‰å†…å®¹æ—¶è¢«æå‰ç»ˆæ­¢çš„é—®é¢˜ (Issue #888)ã€‚\n        -   **[éƒ¨ç½²ä¼˜åŒ–] Docker é•œåƒæ„å»ºåŒæ¨¡é€‚é… (Default/China Mode)**:\n            -   **åŒæ¨¡æ¶æ„**: å¼•å…¥ `ARG USE_CHINA_MIRROR` æ„å»ºå‚æ•°ã€‚é»˜è®¤æ¨¡å¼ä¿æŒåŸæ±åŸå‘³çš„ Debian å®˜æ–¹æºï¼ˆé€‚åˆæµ·å¤–/äº‘æ„å»ºï¼‰ï¼›å¼€å¯åè‡ªåŠ¨åˆ‡æ¢ä¸ºæ¸…åå¤§å­¦ (TUNA) é•œåƒæºï¼ˆé€‚åˆå›½å†…ç¯å¢ƒï¼‰ã€‚\n            -   **çµæ´»æ€§å¤§å¹…æå‡**: è§£å†³äº†ç¡¬ç¼–ç å›½å†…æºå¯¼è‡´æµ·å¤–æ„å»ºç¼“æ…¢çš„é—®é¢˜ï¼ŒåŒæ—¶ä¿ç•™äº†å›½å†…ç”¨æˆ·çš„åŠ é€Ÿä½“éªŒã€‚\n        -   **[ç¨³å®šæ€§ä¿®å¤] VNC ä¸å®¹å™¨å¯åŠ¨é€»è¾‘åŠ å›º (PR #881)**:\n            -   **åƒµå°¸è¿›ç¨‹æ¸…ç†**: ä¼˜åŒ–äº† `start.sh` ä¸­çš„ cleanup é€»è¾‘ï¼Œæ”¹ç”¨ `pkill` ç²¾å‡†æŸ¥æ€ Xtigervnc å’Œ websockify è¿›ç¨‹ï¼Œå¹¶æ¸…ç† `/tmp/.X11-unix` é”æ–‡ä»¶ï¼Œè§£å†³äº†é‡å¯å VNC æ— æ³•è¿æ¥çš„å„ç§è¾¹ç¼˜æƒ…å†µã€‚\n            -   **å¥åº·æ£€æŸ¥å‡çº§**: å°† Healthcheck æ£€æŸ¥é¡¹æ‰©å±•åˆ° websockify å’Œä¸»ç¨‹åºï¼Œç¡®ä¿å®¹å™¨çŠ¶æ€æ›´çœŸå®åœ°åæ˜ æœåŠ¡å¯ç”¨æ€§ã€‚\n            -   **é‡å¤§ä¿®å¤**: ä¿®å¤äº† OpenAI åè®®è¯·æ±‚è¿”å› 404 çš„é—®é¢˜ï¼Œå¹¶è§£å†³äº† Codex (`/v1/responses`) æ¥æ”¶å¤æ‚å¯¹è±¡æ•°ç»„ `input` æˆ– `apply_patch` ç­‰è‡ªå®šä¹‰å·¥å…·ï¼ˆç¼ºå¤± Schemaï¼‰æ—¶å¯¼è‡´ä¸Šæ¸¸è¿”å› 400 (`INVALID_ARGUMENT`) çš„å…¼å®¹æ€§ç¼ºé™·ã€‚\n            -   **æ€ç»´æ¨¡å‹ä¼˜åŒ–**: è§£å†³äº† Claude 3.7 Thinking æ¨¡å‹åœ¨å†å²æ¶ˆæ¯ç¼ºå¤±æ€ç»´é“¾æ—¶å¼ºåˆ¶æŠ¥é”™çš„é—®é¢˜ï¼Œå®ç°äº†æ™ºèƒ½åè®®é™çº§ä¸å ä½å—æ³¨å…¥ã€‚\n            -   **åè®®è¡¥å…¨**: è¡¥å…¨äº† OpenAI Legacy æ¥å£çš„ Token ç»Ÿè®¡å“åº”ä¸ Header æ³¨å…¥ï¼Œæ”¯æŒ `input_text` ç±»å‹å†…å®¹å—ï¼Œå¹¶å°† `developer` è§’è‰²é€‚é…ä¸ºç³»ç»ŸæŒ‡ä»¤ã€‚\n            -   **requestId ç»Ÿä¸€**: ç»Ÿä¸€æ‰€æœ‰ OpenAI è·¯å¾„ä¸‹çš„ `requestId` å‰ç¼€ä¸º `agent-`ï¼Œè§£å†³éƒ¨åˆ†å®¢æˆ·ç«¯çš„ ID è¯†åˆ«é—®é¢˜ã€‚\n        -   **[æ ¸å¿ƒä¿®å¤] JSON Schema æ•°ç»„é€’å½’æ¸…ç†ä¿®å¤ (è§£å†³ Gemini API 400 é”™è¯¯)**:\n            -   **é—®é¢˜èƒŒæ™¯**: Gemini API ä¸æ”¯æŒ `propertyNames`ã€`const` ç­‰ JSON Schema å­—æ®µã€‚è™½ç„¶å·²æœ‰ç™½åå•è¿‡æ»¤é€»è¾‘ï¼Œä½†ç”±äº `clean_json_schema_recursive` å‡½æ•°ç¼ºå°‘å¯¹ `Value::Array` ç±»å‹çš„é€’å½’å¤„ç†ï¼Œå¯¼è‡´åµŒå¥—åœ¨ `anyOf`ã€`oneOf` æˆ– `items` æ•°ç»„å†…éƒ¨çš„éæ³•å­—æ®µæ— æ³•è¢«æ¸…é™¤ï¼Œè§¦å‘ `Invalid JSON payload received. Unknown name \"propertyNames\"/\"const\"` é”™è¯¯ã€‚\n            -   **ä¿®å¤å†…å®¹**:\n                - **å¢åŠ  anyOf/oneOf åˆå¹¶å‰çš„é€’å½’æ¸…æ´—**: åœ¨åˆå¹¶ `anyOf`/`oneOf` åˆ†æ”¯ä¹‹å‰ï¼Œå…ˆé€’å½’æ¸…æ´—æ¯ä¸ªåˆ†æ”¯å†…éƒ¨çš„å†…å®¹ï¼Œç¡®ä¿åˆå¹¶çš„åˆ†æ”¯å·²è¢«æ¸…ç†ï¼Œé˜²æ­¢éæ³•å­—æ®µåœ¨åˆå¹¶è¿‡ç¨‹ä¸­é€ƒé€¸ã€‚\n                - **å¢åŠ é€šç”¨æ•°ç»„é€’å½’å¤„ç†åˆ†æ”¯**: ä¸º `match` è¯­å¥å¢åŠ  `Value::Array` åˆ†æ”¯ï¼Œç¡®ä¿æ‰€æœ‰æ•°ç»„ç±»å‹çš„å€¼ï¼ˆåŒ…æ‹¬ `items`ã€`enum` ç­‰ï¼‰éƒ½ä¼šè¢«é€’å½’æ¸…ç†ï¼Œè¦†ç›–æ‰€æœ‰å¯èƒ½åŒ…å« Schema å®šä¹‰çš„æ•°ç»„å­—æ®µã€‚\n            -   **æµ‹è¯•éªŒè¯**: æ–°å¢ 3 ä¸ªæµ‹è¯•ç”¨ä¾‹éªŒè¯ä¿®å¤æ•ˆæœï¼Œæ‰€æœ‰ 14 ä¸ªæµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼Œæ— å›å½’ã€‚\n            -   **å½±å“èŒƒå›´**: è§£å†³äº†å¤æ‚å·¥å…·å®šä¹‰ï¼ˆå¦‚ MCP å·¥å…·ï¼‰ä¸­åµŒå¥—æ•°ç»„ç»“æ„å¯¼è‡´çš„ 400 é”™è¯¯ï¼Œç¡®ä¿ Gemini API è°ƒç”¨ 100% å…¼å®¹ã€‚\n    *   **v3.3.45 (2026-01-19)**:\n        - **[æ ¸å¿ƒåŠŸèƒ½] è§£å†³ Claude/Gemini SSE ä¸­æ–­ä¸ 0-token å“åº”é—®é¢˜ (Issue #859)**:\n            - **å¢å¼ºå‹é¢„è¯» (Peek) é€»è¾‘**: åœ¨å‘å®¢æˆ·ç«¯å‘é€ 200 OK å“åº”å‰ï¼Œä»£ç†ç°åœ¨ä¼šå¾ªç¯é¢„è¯»å¹¶è·³è¿‡æ‰€æœ‰å¿ƒè·³åŒ…ï¼ˆSSE pingï¼‰åŠç©ºæ•°æ®å—ï¼Œç¡®è®¤æ”¶åˆ°æœ‰æ•ˆä¸šåŠ¡å†…å®¹åå†å»ºç«‹è¿æ¥ã€‚\n            - **æ™ºèƒ½é‡è¯•è§¦å‘**: è‹¥åœ¨é¢„è¯»é˜¶æ®µæ£€æµ‹åˆ°ç©ºå“åº”ã€è¶…æ—¶ï¼ˆ60sï¼‰æˆ–æµå¼‚å¸¸ä¸­æ–­ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨è§¦å‘è´¦å·è½®æ¢å’Œé‡è¯•æœºåˆ¶ï¼Œè§£å†³äº†é•¿å»¶è¿Ÿæ¨¡å‹ä¸‹çš„é™é»˜å¤±è´¥ã€‚\n            - **åè®®ä¸€è‡´æ€§å¢å¼º**: ä¸º Gemini åè®®è¡¥é½äº†ç¼ºå¤±çš„é¢„è¯»é€»è¾‘ï¼›åŒæ—¶å°† Claude å¿ƒè·³é—´éš”ä¼˜åŒ–ä¸º 30sï¼Œå‡å°‘äº†ç”Ÿæˆé•¿æ–‡æœ¬æ—¶çš„è¿æ¥å¹²æ‰°ã€‚\n        - **[æ ¸å¿ƒåŠŸèƒ½] å›ºå®šè´¦å·æ¨¡å¼é›†æˆ (PR #842)**:\n            - **åç«¯å¢å¼º**: åœ¨ä»£ç†æ ¸å¿ƒä¸­å¼•å…¥äº† `preferred_account_id` æ”¯æŒï¼Œå…è®¸é€šè¿‡ API æˆ– UI å¼ºåˆ¶é”å®šç‰¹å®šè´¦å·è¿›è¡Œè¯·æ±‚è°ƒåº¦ã€‚\n            - **UI äº¤äº’æ›´æ–°**: åœ¨ API åä»£é¡µé¢æ–°å¢â€œå›ºå®šè´¦å·â€åˆ‡æ¢ä¸è´¦å·é€‰æ‹©å™¨ï¼Œæ”¯æŒå®æ—¶é”å®šå½“å‰ä¼šè¯çš„å‡ºå£è´¦å·ã€‚\n            - **è°ƒåº¦ä¼˜åŒ–**: åœ¨â€œå›ºå®šè´¦å·æ¨¡å¼â€ä¸‹ä¼˜å…ˆçº§é«˜äºä¼ ç»Ÿè½®è¯¢ï¼Œç¡®ä¿ç‰¹å®šä¸šåŠ¡åœºæ™¯ä¸‹çš„ä¼šè¯è¿ç»­æ€§ã€‚\n        - **[å›½é™…åŒ–] å…¨è¯­è¨€ç¿»è¯‘è¡¥å…¨ä¸æ¸…ç†**:\n            - **8 è¯­è¨€è¦†ç›–**: è¡¥å…¨äº†ä¸­ã€è‹±ã€ç¹ä¸­ã€æ—¥ã€åœŸã€è¶Šã€è‘¡ã€ä¿„ç­‰ 8 ç§è¯­è¨€ä¸­å…³äºâ€œå›ºå®šè´¦å·æ¨¡å¼â€çš„æ‰€æœ‰ i18n ç¿»è¯‘é¡¹ã€‚\n            - **å†—ä½™æ¸…ç†**: ä¿®å¤äº† `ja.json` å’Œ `vi.json` ä¸­ç”±äºå†å² PR ç´¯ç§¯å¯¼è‡´çš„é‡å¤é”®ï¼ˆDuplicate Keysï¼‰è­¦å‘Šï¼Œæå‡äº†ç¿»è¯‘è§„èŒƒæ€§ã€‚\n            - **æ ‡ç‚¹åŒæ­¥**: ç»Ÿä¸€æ¸…é™¤äº†å„è¯­è¨€ç¿»è¯‘ä¸­è¯¯ç”¨çš„å…¨è§’æ ‡ç‚¹ï¼Œç¡®ä¿ UI å±•ç¤ºçš„ä¸€è‡´æ€§ã€‚\n        - **[æ ¸å¿ƒåŠŸèƒ½] å®¢æˆ·ç«¯çƒ­æ›´æ–°ä¸ Token ç»Ÿè®¡ç³»ç»Ÿ (PR #846 by @lengjingxu)**:\n            - **çƒ­æ›´æ–° (Native Updater)**: é›†æˆ Tauri v2 åŸç”Ÿæ›´æ–°æ’ä»¶ï¼Œæ”¯æŒè‡ªåŠ¨æ£€æµ‹ã€ä¸‹è½½ã€å®‰è£…åŠé‡å¯ï¼Œå®ç°å®¢æˆ·ç«¯æ— æ„Ÿå‡çº§ã€‚\n            - **Token æ¶ˆè´¹å¯è§†åŒ–**: æ–°å¢åŸºäº SQLite å®ç°çš„ Token ç»Ÿè®¡æŒä¹…åŒ–æ¨¡å—ï¼Œæ”¯æŒæŒ‰å°æ—¶/æ—¥/å‘¨ç»´åº¦æŸ¥çœ‹æ€»æ¶ˆè€—åŠå„è´¦å·å æ¯”ã€‚\n            - **UI/UX å¢å¼º**: ä¼˜åŒ–äº†å›¾è¡¨æ‚¬æµ®æç¤º (Tooltip) åœ¨æ·±è‰²æ¨¡å¼ä¸‹çš„å¯¹æ¯”åº¦ï¼Œéšè—äº†å†—ä½™çš„ hover é«˜äº®ï¼›è¡¥å…¨äº† 8 è¯­è¨€å®Œæ•´ç¿»è¯‘å¹¶ä¿®å¤äº†ç¡¬ç¼–ç å›¾ä¾‹ã€‚\n            - **é›†æˆä¿®å¤**: åœ¨æœ¬åœ°åˆå¹¶æœŸé—´ä¿®å¤äº† PR åŸå§‹ä»£ç ä¸­ç¼ºå¤±æ’ä»¶é…ç½®å¯¼è‡´çš„å¯åŠ¨å´©æºƒæ•…éšœã€‚\n        - **[ç³»ç»ŸåŠ é€Ÿ] å¯ç”¨æ¸…åå¤§å­¦ (TUNA) é•œåƒæº**: ä¼˜åŒ–äº† Dockerfile æ„å»ºæµç¨‹ï¼Œå¤§å¹…æå‡å›½å†…ç¯å¢ƒä¸‹çš„æ’ä»¶å®‰è£…é€Ÿåº¦ã€‚\n        - **[éƒ¨ç½²ä¼˜åŒ–] å®˜æ–¹ Docker ä¸ noVNC æ”¯æŒ (PR #851)**:\n            - **å…¨åŠŸèƒ½å®¹å™¨åŒ–**: ä¸º headless ç¯å¢ƒæä¾›å®Œæ•´çš„ Docker éƒ¨ç½²æ–¹æ¡ˆï¼Œå†…ç½® Openbox æ¡Œé¢ç¯å¢ƒã€‚\n            - **Web VNC é›†æˆ**: é›†æˆ noVNCï¼Œæ”¯æŒé€šè¿‡æµè§ˆå™¨ç›´æ¥è®¿é—®å›¾å½¢ç•Œé¢è¿›è¡Œ OAuth æˆæƒï¼ˆå†…ç½® Firefox ESRï¼‰ã€‚\n            - **è‡ªæ„ˆå¯åŠ¨æµ**: ä¼˜åŒ–äº† `start.sh` å¯åŠ¨é€»è¾‘ï¼Œæ”¯æŒè‡ªåŠ¨æ¸…ç† X11 é”æ–‡ä»¶åŠæœåŠ¡å´©æºƒè‡ªåŠ¨é€€å‡ºï¼Œæå‡ç”Ÿäº§ç¯å¢ƒç¨³å®šæ€§ã€‚\n            - **å¤šè¯­è¨€é€‚é…**: å†…ç½® CJK å­—ä½“ï¼Œç¡®ä¿ Docker ç¯å¢ƒä¸‹ä¸­æ–‡å­—ç¬¦æ­£å¸¸æ˜¾ç¤ºã€‚\n            - **èµ„æºé™åˆ¶ä¼˜åŒ–**: ç»Ÿä¸€è®¾ç½® `shm_size: 2gb`ï¼Œè§£å†³å®¹å™¨å†…æµè§ˆå™¨åŠå›¾å½¢ç•Œé¢å´©æºƒé—®é¢˜ã€‚\n        - **[æ ¸å¿ƒåŠŸèƒ½] ä¿®å¤è´¦å·åˆ‡æ¢æ—¶çš„è®¾å¤‡æŒ‡çº¹åŒæ­¥é—®é¢˜**:\n            - **è·¯å¾„æ¢æµ‹æ”¹è¿›**: ä¼˜åŒ–äº† `storage.json` çš„æ¢æµ‹æ—¶æœºï¼Œç¡®ä¿åœ¨è¿›ç¨‹å…³é—­å‰å‡†ç¡®è·å–è·¯å¾„ï¼Œå…¼å®¹è‡ªå®šä¹‰æ•°æ®ç›®å½•ã€‚\n            - **è‡ªåŠ¨éš”ç¦»ç”Ÿæˆ**: é’ˆå¯¹æœªç»‘å®šæŒ‡çº¹çš„è´¦å·ï¼Œåœ¨åˆ‡æ¢æ—¶ä¼šè‡ªåŠ¨ç”Ÿæˆå¹¶ç»‘å®šå”¯ä¸€çš„è®¾å¤‡æ ‡è¯†ï¼Œå®ç°è´¦å·é—´çš„æŒ‡çº¹éš”ç¦»ã€‚\n        - **[UI ä¿®å¤] ä¿®å¤è´¦å·ç®¡ç†é¡µæ¡æ•°æ˜¾ç¤ºä¸å‡†ç¡®é—®é¢˜ (Issue #754)**:\n            - **é€»è¾‘ä¿®æ­£**: å¼ºåˆ¶åˆ†é¡µæ¡æ•°é»˜è®¤æœ€ä½ä¸º 10 æ¡ï¼Œè§£å†³äº†å°çª—å£ä¸‹è‡ªåŠ¨å˜ä¸º 5 æ¡æˆ– 9 æ¡çš„ä¸ç›´è§‰ä½“éªŒã€‚\n            - **æŒä¹…åŒ–å¢å¼º**: å®ç°äº†åˆ†é¡µå¤§å°çš„ `localStorage` æŒä¹…åŒ–ï¼Œç”¨æˆ·æ‰‹åŠ¨é€‰æ‹©çš„æ¡æ•°å°†æ°¸ä¹…é”å®šå¹¶è¦†ç›–è‡ªåŠ¨æ¨¡å¼ã€‚\n            - **UI ä¸€è‡´æ€§**: ç¡®ä¿å³ä¸‹è§’åˆ†é¡µé€‰é¡¹ä¸åˆ—è¡¨å®é™…å±•ç¤ºæ¡æ•°å§‹ç»ˆä¿æŒä¸€è‡´ã€‚\n    *   **v3.3.44 (2026-01-19)**:\n        - **[æ ¸å¿ƒç¨³å®šæ€§] åŠ¨æ€æ€ç»´å‰¥ç¦» (Dynamic Thinking Stripping) - è§£å†³ Prompt è¿‡é•¿ä¸ç­¾åé”™è¯¯**:\n            - **é—®é¢˜èƒŒæ™¯**: åœ¨ Deep Thinking æ¨¡å¼ä¸‹,é•¿å¯¹è¯ä¼šå¯¼è‡´ä¸¤ç±»è‡´å‘½é”™è¯¯:\n                - `Prompt is too long`: å†å² Thinking Block ç´¯ç§¯å¯¼è‡´ Token è¶…é™\n                - `Invalid signature`: ä»£ç†é‡å¯åå†…å­˜ç­¾åç¼“å­˜ä¸¢å¤±,æ—§ç­¾åè¢« Google æ‹’æ”¶\n            - **è§£å†³æ–¹æ¡ˆ - Context Purification (ä¸Šä¸‹æ–‡å‡€åŒ–)**:\n                - **æ–°å¢ `ContextManager` æ¨¡å—**: å®ç° Token ä¼°ç®—ä¸å†å²æ¸…æ´—é€»è¾‘\n                - **åˆ†çº§æ¸…æ´—ç­–ç•¥**:\n                    - `Soft` (60%+ å‹åŠ›): ä¿ç•™æœ€è¿‘ 2 è½® Thinking,å‰¥ç¦»æ›´æ—©å†å²\n                    - `Aggressive` (90%+ å‹åŠ›): ç§»é™¤æ‰€æœ‰å†å² Thinking Block\n                - **å·®å¼‚åŒ–é™é¢**: Flash æ¨¡å‹ (1M) ä¸ Pro æ¨¡å‹ (2M) é‡‡ç”¨ä¸åŒè§¦å‘é˜ˆå€¼\n                - **ç­¾ååŒæ­¥æ¸…é™¤**: æ¸…æ´— Thinking æ—¶è‡ªåŠ¨ç§»é™¤ `thought_signature`,é¿å…ç­¾åæ ¡éªŒå¤±è´¥\n            - **é€æ˜åº¦å¢å¼º**: å“åº”å¤´æ–°å¢ `X-Context-Purified: true` æ ‡è¯†,ä¾¿äºè°ƒè¯•\n            - **æ€§èƒ½ä¼˜åŒ–**: åŸºäºå­—ç¬¦æ•°çš„è½»é‡çº§ Token ä¼°ç®—,å¯¹è¯·æ±‚å»¶è¿Ÿå½±å“ \\u003c 5ms\n            - **å½±å“èŒƒå›´**: è§£å†³ Deep Thinking æ¨¡å¼ä¸‹çš„ä¸¤å¤§é¡½ç–¾,é‡Šæ”¾ 40%-60% Context ç©ºé—´,ç¡®ä¿é•¿å¯¹è¯ç¨³å®šæ€§\n    *   **v3.3.43 (2026-01-18)**:\n        - **[å›½é™…åŒ–] è®¾å¤‡æŒ‡çº¹å¯¹è¯æ¡†å…¨é‡æœ¬åœ°åŒ– (PR #825, æ„Ÿè°¢ @IamAshrafee)**:\n            - è§£å†³äº†è®¾å¤‡æŒ‡çº¹ï¼ˆDevice Fingerprintï¼‰å¯¹è¯æ¡†ä¸­æ®‹ç•™çš„ç¡¬ç¼–ç ä¸­æ–‡å­—ç¬¦ä¸²é—®é¢˜ã€‚\n            - è¡¥å…¨äº†è‹±ã€ç¹ã€æ—¥ç­‰ 8 ç§è¯­è¨€çš„ç¿»è¯‘éª¨æ¶ï¼Œæå‡å…¨çƒåŒ–ä½“éªŒã€‚\n        - **[æ—¥è¯­ä¼˜åŒ–] æ—¥è¯­ç¿»è¯‘è¡¥å…¨ä¸æœ¯è¯­ä¿®æ­£ (PR #822, æ„Ÿè°¢ @Koshikai)**:\n            - è¡¥å…¨äº† 50 å¤šä¸ªç¼ºå¤±çš„ç¿»è¯‘é”®ï¼Œè¦†ç›–é…é¢ä¿æŠ¤ã€HTTP APIã€æ›´æ–°æ£€æŸ¥ç­‰æ ¸å¿ƒè®¾ç½®ã€‚\n            - ä¼˜åŒ–äº†æŠ€æœ¯æœ¯è¯­ï¼Œä½¿æ—¥è¯­è¡¨è¾¾æ›´è‡ªç„¶ï¼ˆä¾‹å¦‚ï¼š`pro_low` è¯‘ä¸ºâ€œä½æ¶ˆè²»â€ï¼‰ã€‚\n        - **[ç¿»è¯‘ä¿®å¤] è¶Šå—è¯­æ‹¼å†™é”™è¯¯ä¿®æ­£ (PR #798, æ„Ÿè°¢ @vietnhatthai)**:\n            - ä¿®å¤äº†è¶Šå—è¯­è®¾ç½®ä¸­ `refresh_msg` çš„æ‹¼å†™é”™è¯¯ï¼ˆ`hiá»‡n Ä‘Ã i` -> `hiá»‡n táº¡i`ï¼‰ã€‚\n        - **[å…¼å®¹æ€§å¢å¼º] æ–°å¢ Google API Key åŸç”Ÿæ”¯æŒ (PR #831)**:\n            - **æ”¯æŒ `x-goog-api-key` è¯·æ±‚å¤´**:\n                - è®¤è¯ä¸­é—´ä»¶ç°åœ¨æ”¯æŒè¯†åˆ« `x-goog-api-key` å¤´éƒ¨ã€‚\n                - æé«˜äº†ä¸ Google å®˜æ–¹ SDK åŠç¬¬ä¸‰æ–¹ Google é£æ ¼å®¢æˆ·ç«¯çš„å…¼å®¹æ€§ï¼Œæ— éœ€å†æ‰‹åŠ¨ä¿®æ”¹ Header ä¸º `x-api-key`ã€‚\n    *   **v3.3.42 (2026-01-18)**:\n        - **[æµé‡æ—¥å¿—å¢å¼º] åè®®è‡ªåŠ¨è¯†åˆ«ä¸æµå¼å“åº”æ•´åˆ (PR #814)**:\n            - **åè®®æ ‡ç­¾åˆ†ç±»**: æµé‡æ—¥å¿—åˆ—è¡¨ç°åœ¨å¯ä»¥æ ¹æ® URI è‡ªåŠ¨è¯†åˆ«å¹¶æ ‡æ³¨åè®®ç±»å‹ï¼ˆOpenAI ç»¿è‰²ã€Anthropic æ©™è‰²ã€Gemini è“è‰²ï¼‰ï¼Œä½¿è¯·æ±‚æ¥æºä¸€ç›®äº†ç„¶ã€‚\n            - **æµå¼æ•°æ®å…¨æ•´åˆ**: è§£å†³äº†æµå¼å“åº”åœ¨æ—¥å¿—ä¸­ä»…æ˜¾ç¤º `[Stream Data]` çš„é—®é¢˜ã€‚ç°åœ¨ä¼šè‡ªåŠ¨æ‹¦æˆªå¹¶èšåˆæµå¼æ•°æ®åŒ…ï¼Œå°†åˆ†æ•£çš„ `delta` ç‰‡æ®µè¿˜åŸä¸ºå®Œæ•´çš„å›å¤å†…å®¹å’Œâ€œæ€è€ƒâ€è¿‡ç¨‹ï¼Œå¤§å¹…æå‡è°ƒè¯•æ•ˆç‡ã€‚\n            - **å¤šè¯­è¨€é€‚é…**: è¡¥å…¨äº†æµé‡æ—¥å¿—ç›¸å…³åŠŸèƒ½åœ¨ 8 ç§è¯­è¨€ç¯å¢ƒä¸‹çš„ i18n ç¿»è¯‘ã€‚\n        - **[é‡å¤§ä¿®å¤] Gemini JSON Schema æ¸…æ´—ç­–ç•¥æ·±åº¦é‡æ„ (Issue #815)**:\n            - **è§£å†³å±æ€§ä¸¢å¤±é—®é¢˜**: å®ç°äº†â€œæœ€ä½³åˆ†æ”¯åˆå¹¶â€é€»è¾‘ã€‚åœ¨å¤„ç†å·¥å…·å®šä¹‰çš„ `anyOf`/`oneOf` ç»“æ„æ—¶ï¼Œä¼šè‡ªåŠ¨è¯†åˆ«å¹¶æå–å†…å®¹æœ€ä¸°å¯Œçš„åˆ†æ”¯å±æ€§å‘ä¸Šåˆå¹¶ï¼Œè§£å†³äº†æ¨¡å‹æŠ¥é”™ `malformed function call` çš„é¡½ç–¾ã€‚\n            - **ç¨³å¥çš„ç™½åå•æœºåˆ¶**: é‡‡ç”¨é’ˆå¯¹ Gemini API çš„ä¸¥æ ¼ç™½åå•è¿‡æ»¤ç­–ç•¥ï¼Œå‰”é™¤ä¸æ”¯æŒçš„æ ¡éªŒå­—æ®µï¼Œç¡®ä¿ API è°ƒç”¨ 100% å…¼å®¹ï¼ˆä»æ ¹æœ¬ä¸Šæœç» 400 é”™è¯¯ï¼‰ã€‚\n            - **çº¦æŸä¿¡æ¯è¿ç§» (Description Hints)**: åœ¨ç§»é™¤ `minLength`, `pattern`, `format` ç­‰å­—æ®µå‰ï¼Œè‡ªåŠ¨å°†å…¶è½¬ä¸ºæ–‡å­—æè¿°è¿½åŠ åˆ° `description` ä¸­ï¼Œç¡®ä¿æ¨¡å‹ä¾ç„¶èƒ½æ„ŸçŸ¥å‚æ•°çº¦æŸã€‚\n            - **Schema ä¸Šä¸‹æ–‡æ£€æµ‹é”**: æ–°å¢å®‰å…¨æ£€æŸ¥é€»è¾‘ï¼Œç¡®ä¿æ¸…æ´—å™¨ä»…åœ¨å¤„ç†çœŸæ­£çš„ Schema æ—¶æ‰§è¡Œã€‚é€šè¿‡â€œç²¾å‡†é”â€ä¿æŠ¤äº† `request.rs` ä¸­çš„å·¥å…·è°ƒç”¨ç»“æ„ï¼Œç¡®ä¿å†å²ä¿®å¤é€»è¾‘ï¼ˆå¦‚å¸ƒå°”å€¼è½¬æ¢ã€Shell æ•°ç»„è½¬æ¢ï¼‰åœ¨é‡æ„åä¾ç„¶ç¨³å¦‚ç£çŸ³ã€‚\n    *   **v3.3.41 (2026-01-18)**:\n        - **Claude åè®®æ ¸å¿ƒå…¼å®¹æ€§ä¿®å¤ (Issue #813)**:\n            - **è¿ç»­ User æ¶ˆæ¯åˆå¹¶**: å®ç°äº† `merge_consecutive_messages` é€»è¾‘ï¼Œåœ¨è¯·æ±‚è¿›å…¥ Proxy æ—¶è‡ªåŠ¨åˆå¹¶å…·æœ‰ç›¸åŒè§’è‰²çš„è¿ç»­æ¶ˆæ¯æµã€‚è§£å†³äº†å›  Spec/Plan æ¨¡å¼åˆ‡æ¢å¯¼è‡´çš„è§’è‰²äº¤æ›¿è¿è§„äº§ç”Ÿçš„ 400 Bad Request é”™è¯¯ã€‚\n            - **EnterPlanMode åè®®å¯¹é½**: é’ˆå¯¹ Claude Code çš„ `EnterPlanMode` å·¥å…·è°ƒç”¨ï¼Œå¼ºåˆ¶æ¸…ç©ºå†—ä½™å‚æ•°ï¼Œç¡®ä¿å®Œå…¨ç¬¦åˆå®˜æ–¹åè®®ï¼Œè§£å†³äº†æ¿€æ´» Plan Mode æ—¶çš„æŒ‡ä»¤é›†æ ¡éªŒå¤±è´¥é—®é¢˜ã€‚\n        - **ä»£ç†é²æ£’æ€§å¢å¼º**:\n            - å¢å¼ºäº†å·¥å…·è°ƒç”¨é“¾çš„è‡ªæ„ˆèƒ½åŠ›ã€‚å½“æ¨¡å‹å› å¹»è§‰äº§ç”Ÿé”™è¯¯è·¯å¾„å°è¯•æ—¶ï¼ŒProxy ç°èƒ½æä¾›æ ‡å‡†çš„é”™è¯¯åé¦ˆå¼•å¯¼æ¨¡å‹è½¬å‘æ­£ç¡®è·¯å¾„ã€‚\n    *   **v3.3.40 (2026-01-18)**:\n        - **API 400 é”™è¯¯æ·±åº¦ä¿®å¤ (Grep/Thinking ç¨³å®šæ€§æ”¹è¿›)**:\n            - **ä¿®å¤æµå¼å—é¡ºåºè¿è§„**: è§£å†³äº† \"Found 'text' instead of 'thinking'\" 400 é”™è¯¯ã€‚ä¿®æ­£äº† `streaming.rs` ä¸­åœ¨æ–‡å­—å—åéæ³•è¿½åŠ æ€ç»´å—çš„é€»è¾‘ï¼Œæ”¹ç”±ç¼“å­˜æœºåˆ¶å®ç°é™é»˜åŒæ­¥ã€‚\n            - **æ€ç»´ç­¾åè‡ªæ„ˆå¢å¼º**: åœ¨ `claude.rs` ä¸­æ‰©å±•äº† 400 é”™è¯¯æ•è·å…³é”®è¯ï¼Œè¦†ç›–äº†ç­¾åå¤±æ•ˆã€é¡ºåºè¿è§„å’Œåè®®ä¸åŒ¹é…åœºæ™¯ã€‚ä¸€æ—¦è§¦å‘ï¼Œä»£ç†ä¼šè‡ªåŠ¨æ‰§è¡Œæ¶ˆæ¯é™çº§å¹¶å¿«é€Ÿé‡è¯•ï¼Œå®ç°ç”¨æˆ·æ— æ„ŸçŸ¥çš„å¼‚å¸¸è‡ªæ„ˆã€‚\n            - **æœç´¢å·¥å…·å‚æ•°æ·±åº¦å¯¹é½**: ä¿®æ­£äº† `Grep` å’Œ `Glob` å·¥å…·çš„å‚æ•°æ˜ å°„é€»è¾‘ï¼Œå°† `query` å‡†ç¡®æ˜ å°„ä¸º `path` (Claude Code Schema)ï¼Œå¹¶æ”¯æŒé»˜è®¤æ³¨å…¥æ‰§è¡Œè·¯å¾„ `.`ã€‚\n            - **å·¥å…·åé‡æ˜ å°„ç­–ç•¥ä¼˜åŒ–**: æ”¹è¿›äº†é‡å‘½åé€»è¾‘ï¼Œä»…é’ˆå¯¹ `search` ç­‰æ¨¡å‹å¹»è§‰è¿›è¡Œä¿®æ­£ï¼Œé¿å…ç ´ååŸå§‹å·¥å…·è°ƒç”¨ç­¾åã€‚\n            - **ç­¾åç¼ºå¤±è‡ªåŠ¨è¡¥å®Œ**: é’ˆå¯¹ LSã€Bashã€TodoWrite ç­‰å·¥å…·è°ƒç”¨ç¼ºå¤± `thought_signature` çš„æƒ…å†µï¼Œè‡ªåŠ¨æ³¨å…¥é€šç”¨æ ¡éªŒå ä½ç¬¦ï¼Œç¡®ä¿åè®®é“¾è·¯ç•…é€šã€‚\n        - **æ¶æ„å¥å£®æ€§ä¼˜åŒ–**:\n            - å¢å¼ºäº†å…¨å±€é€’å½’æ¸…ç†å‡½æ•° `clean_cache_control_from_messages`ï¼Œç¡®ä¿ `cache_control` ä¸ä¼šå¹²æ‰° Vertex AI/Anthropic ä¸¥æ ¼æ¨¡å¼ã€‚\n            - å®Œå–„äº†é”™è¯¯æ—¥å¿—ç³»ç»Ÿï¼Œå»ºç«‹äº†è¯¦ç»†çš„åœºæ™¯å¯¹ç…§è¡¨å¹¶è®°å½•äº [docs/client_test_examples.md](docs/client_test_examples.md)ã€‚\n    *   **v3.3.39 (2026-01-17)**:\n        - **ä»£ç†æ·±åº¦ä¼˜åŒ– (Gemini ç¨³å®šæ€§å¢å¼º)**ï¼š\n            - **Schema å‡€åŒ–å™¨å‡çº§**ï¼šæ”¯æŒ `allOf` åˆå¹¶ã€æ™ºèƒ½è”åˆç±»å‹é€‰æ‹©ã€Nullable è‡ªåŠ¨è¿‡æ»¤åŠç©ºå¯¹è±¡å‚æ•°è¡¥å…¨ï¼Œè§£å†³å¤æ‚å·¥å…·å®šä¹‰å¯¼è‡´çš„ 400 é”™è¯¯ã€‚\n            - **æœç´¢å·¥å…·è‡ªæ„ˆ**ï¼šå®ç° `Search` åˆ° `grep` çš„è‡ªåŠ¨é‡æ˜ å°„ï¼Œå¹¶å¼•å…¥ **Glob-to-Include è¿ç§»**ï¼ˆè‡ªåŠ¨å°† `**/*.rs` ç­‰ Glob æ¨¡å¼ç§»è‡³åŒ…å«å‚æ•°ï¼‰ï¼Œè§£å†³ Claude Code `Error searching files` æŠ¥é”™ã€‚\n            - **å‚æ•°åˆ«åè¡¥å…¨**ï¼šç»Ÿä¸€ `search_code_definitions` ç­‰ç›¸å…³å·¥å…·çš„å‚æ•°æ˜ å°„é€»è¾‘ï¼Œå¹¶å¼ºåˆ¶æ‰§è¡Œå¸ƒå°”å€¼ç±»å‹è½¬æ¢ã€‚\n            - **Shell è°ƒç”¨åŠ å›º**ï¼šå¼ºåˆ¶ `local_shell_call` çš„ `command` å‚æ•°è¿”å›æ•°ç»„ï¼Œå¢å¼ºä¸ Google API çš„å…¼å®¹æ€§ã€‚\n            - **åŠ¨æ€ Token çº¦æŸ**ï¼šè‡ªåŠ¨æ ¹æ® `thinking_budget` è°ƒæ•´ `maxOutputTokens`ï¼Œç¡®ä¿æ»¡è¶³ API å¼ºçº¦æŸï¼›ç²¾ç®€åœæ­¢åºåˆ— (Stop Sequences) ä»¥æå‡æµå¼è¾“å‡ºè´¨é‡ã€‚\n        - **Thinking æ¨¡å¼ç¨³å®šæ€§å¤§å¹…æå‡**ï¼š\n            - å¼•å…¥è·¨æ¨¡å‹å®¶æ—ç­¾åæ ¡éªŒï¼Œè‡ªåŠ¨è¯†åˆ«å¹¶é™çº§ä¸å…¼å®¹çš„æ€ç»´é“¾ç­¾åï¼Œé˜²æ­¢ 400 Bad Request é”™è¯¯ã€‚\n            - å¢å¼ºâ€œä¼šè¯è‡ªæ„ˆ (Session Healing)â€é€»è¾‘ï¼Œæ”¯æŒè‡ªåŠ¨è¡¥å…¨è¢«ä¸­æ–­çš„å·¥å…·å¾ªç¯ï¼Œç¡®ä¿æ»¡è¶³ Google/Vertex AI çš„ä¸¥è‹›ç»“æ„è¦æ±‚ã€‚\n        - **é«˜å¯ç”¨æ€§å¢å¼º**ï¼š\n            - ä¼˜åŒ–è‡ªåŠ¨ç«¯ç‚¹é™çº§ (Endpoint Fallback) é€»è¾‘ï¼Œåœ¨ 429 æˆ– 5xx é”™è¯¯æ—¶æ›´å¹³æ»‘åœ°åˆ‡æ¢è‡³å¤‡ç”¨ API ç«¯ç‚¹ã€‚\n        - **ä¿®å¤ macOS \"Too many open files\" é”™è¯¯ (Issue #784)**ï¼š\n            - å¼•å…¥å…¨å±€å…±äº« HTTP å®¢æˆ·ç«¯è¿æ¥æ± ï¼Œå¤§å¹…å‡å°‘ Socket å¥æŸ„å ç”¨ã€‚\n            - é’ˆå¯¹ macOS ç³»ç»Ÿè‡ªåŠ¨æå‡æ–‡ä»¶æè¿°ç¬¦é™åˆ¶ (RLIMIT_NOFILE) è‡³ 4096ï¼Œå¢å¼ºé«˜å¹¶å‘ç¨³å®šæ€§ã€‚\n    *   **v3.3.38 (2026-01-17)**:\n        - **CLI åŒæ­¥å¢å¼ºä¸æ¢æµ‹ä¿®å¤ (Fix CLI-Sync Detection)**:\n            - **æ¢æµ‹è·¯å¾„æ‰©å±•**: ä¼˜åŒ–äº†äºŒè¿›åˆ¶æ£€æµ‹é€»è¾‘ã€‚æ–°å¢å¯¹ `~/.local/bin` (curl å®‰è£…å¸¸ç”¨è·¯å¾„)ã€`~/.npm-global/bin` ä»¥åŠ `~/bin` çš„æ‰«æã€‚\n            - **nvm å¤šç‰ˆæœ¬æ”¯æŒ**: å¼•å…¥å¯¹ `nvm` ç›®å½•çš„æ·±åº¦æ‰«æï¼Œæ”¯æŒè‡ªåŠ¨è¯†åˆ«ä¸åŒ Node.js ç‰ˆæœ¬ä¸‹å®‰è£…çš„ CLI å·¥å…·ï¼Œè§£å†³ M1 èŠ¯ç‰‡ç”¨æˆ·æ‰‹åŠ¨å®‰è£…æ£€æµ‹ä¸åˆ°çš„é—®é¢˜ã€‚\n            - **åŸå­åŒ–æ–‡ä»¶æ“ä½œ**: é‡‡ç”¨ä¸´æ—¶æ–‡ä»¶å†™å…¥ + åŸå­æ›¿æ¢æœºåˆ¶ï¼Œç¡®ä¿åŒæ­¥è¿‡ç¨‹ä¸­æ–­ä¸ä¼šæŸååŸå§‹é…ç½®æ–‡ä»¶ã€‚\n        - **Thinking Signature æ·±åº¦ä¿®å¤ä¸ä¼šè¯è‡ªæ„ˆ (Fix Issue #752)**:\n            - **é²æ£’é‡è¯•é€»è¾‘**: ä¿®æ­£äº†é‡è¯•è®¡æ¬¡é€»è¾‘ï¼Œç¡®ä¿å•è´¦å·ç”¨æˆ·åœ¨é‡åˆ°ç­¾åé”™è¯¯æ—¶ä¹Ÿèƒ½è§¦å‘å†…éƒ¨é‡è¯•ï¼Œæé«˜äº†è‡ªåŠ¨ä¿®å¤çš„è§¦å‘ç‡ã€‚\n            - **ä¸»åŠ¨ç­¾åå‰¥ç¦»**: å¼•å…¥ `is_retry`çŠ¶æ€ï¼Œåœ¨é‡è¯•è¯·æ±‚ä¸­å¼ºåˆ¶å‰¥ç¦»æ‰€æœ‰å†å²ç­¾åã€‚é…åˆä¸¥è‹›çš„æ¨¡å‹å®¶æ—æ ¡éªŒï¼ˆGemini 1.5/2.0 ä¸å†æ··ç”¨ç­¾åï¼‰ï¼Œæœç»äº†æ— æ•ˆç­¾åå¯¼è‡´çš„ 400 é”™è¯¯ã€‚\n            - **ä¼šè¯è‡ªæ„ˆ (Session Healing)**: é’ˆå¯¹å‰¥ç¦»ç­¾ååå¯èƒ½å‡ºç°çš„â€œè£¸å·¥å…·ç»“æœâ€ç»“æ„é”™è¯¯ï¼Œå®ç°äº†æ™ºèƒ½æ¶ˆæ¯æ³¨å…¥æœºåˆ¶ï¼Œé€šè¿‡åˆæˆä¸Šä¸‹æ–‡æ»¡è¶³ Vertex AI çš„ç»“æ„æ ¡éªŒé™åˆ¶ã€‚\n        - **é…é¢å…³æ³¨åˆ—è¡¨ (Fix PR #783)**:\n            - **è‡ªå®šä¹‰æ˜¾ç¤º**: åœ¨ã€Œè®¾ç½® -> è´¦å·ã€ä¸­æ–°å¢æ¨¡å‹é…é¢å…³æ³¨åˆ—è¡¨ï¼Œæ”¯æŒç”¨æˆ·è‡ªå®šä¹‰ä¸»è¡¨æ ¼æ˜¾ç¤ºçš„ç‰¹å®šæ¨¡å‹é…é¢ï¼Œæœªé€‰ä¸­æ¨¡å‹ä»…åœ¨è¯¦æƒ…å¼¹çª—ä¸­å±•ç¤ºã€‚\n            - **å¸ƒå±€ä¼˜åŒ–**: é’ˆå¯¹è¯¥æ¿å—å®ç°äº†å“åº”å¼ 4 åˆ—ç½‘æ ¼å¸ƒå±€ï¼Œå¹¶åœ¨ UI é£æ ¼ä¸Šä¸â€œé¢åº¦ä¿æŠ¤â€ä¿æŒä¸€è‡´ã€‚\n        - **ä¸­è½¬ç¨³å®šæ€§å¢å¼º**: å¢å¼ºäº†å¯¹ 529 Overloaded ç­‰ä¸Šæ¸¸è¿‡è½½é”™è¯¯çš„è¯†åˆ«ä¸é€€é¿é‡è¯•ï¼Œæå‡äº†æç«¯è´Ÿè½½ä¸‹çš„ä»»åŠ¡æˆåŠŸç‡ã€‚\n    *   **v3.3.37 (2026-01-17)**:\n        - **åç«¯å…¼å®¹æ€§ä¿®å¤ (Fix PR #772)**:\n            - **å‘åå…¼å®¹æ€§å¢å¼º**: ä¸º `StickySessionConfig` æ·»åŠ äº† `#[serde(default)]` å±æ€§ï¼Œç¡®ä¿æ—§ç‰ˆæœ¬çš„é…ç½®æ–‡ä»¶ï¼ˆç¼ºå°‘ç²˜æ€§ä¼šè¯å­—æ®µï¼‰èƒ½å¤Ÿè¢«æ­£ç¡®åŠ è½½ï¼Œé¿å…äº†ååºåˆ—åŒ–é”™è¯¯ã€‚\n        - **ç”¨æˆ·ä½“éªŒä¼˜åŒ– (Fix PR #772)**:\n            - **é…ç½®åŠ è½½ä½“éªŒå‡çº§**: åœ¨ `ApiProxy.tsx` ä¸­å¼•å…¥äº†ç‹¬ç«‹çš„åŠ è½½çŠ¶æ€å’Œé”™è¯¯å¤„ç†æœºåˆ¶ã€‚ç°åœ¨ï¼Œåœ¨è·å–é…ç½®æ—¶ç”¨æˆ·ä¼šçœ‹åˆ°åŠ è½½åŠ¨ç”»ï¼Œå¦‚æœåŠ è½½å¤±è´¥ï¼Œç³»ç»Ÿå°†å±•ç¤ºæ˜ç¡®çš„é”™è¯¯ä¿¡æ¯å¹¶æä¾›é‡è¯•æŒ‰é’®ï¼Œå–ä»£äº†ä¹‹å‰çš„ç©ºç™½æˆ–é”™è¯¯çŠ¶æ€ã€‚\n        - **macOS Monterey æ²™ç›’æƒé™ä¿®å¤ (Fix Issue #468)**:\n            - **é—®é¢˜æ ¹æº**: åœ¨ macOS Monterey (12.x) ç­‰æ—§ç‰ˆæœ¬ç³»ç»Ÿä¸Šï¼Œåº”ç”¨æ²™ç›’ç­–ç•¥é˜»æ­¢äº†è¯»å–å…¨å±€åå¥½è®¾ç½® (`kCFPreferencesAnyApplication`)ï¼Œå¯¼è‡´æ— æ³•æ­£ç¡®æ£€æµ‹é»˜è®¤æµè§ˆå™¨ï¼Œè¿›è€Œæ‹¦æˆªäº† OAuth è·³è½¬ã€‚\n            - **ä¿®å¤å†…å®¹**: åœ¨ `Entitlements.plist` ä¸­æ·»åŠ äº† `com.apple.security.temporary-exception.shared-preference.read-only` æƒé™ä¾‹å¤–ï¼Œæ˜¾å¼å…è®¸è¯»å–å…¨å±€é…ç½®ã€‚\n    *   **v3.3.36 (2026-01-17)**:\n        - **Claude åè®®æ ¸å¿ƒç¨³å®šæ€§ä¿®å¤**:\n            - **ä¿®å¤ \"å›å¤ OK\" æ­»å¾ªç¯ (History Poisoning Fix)**:\n                - **é—®é¢˜æ ¹æº**: ä¿®å¤äº† `is_warmup_request` æ£€æµ‹é€»è¾‘ä¸­çš„ä¸¥é‡ç¼ºé™·ã€‚æ—§é€»è¾‘ä¼šæ‰«ææœ€è¿‘ 10 æ¡å†å²æ¶ˆæ¯ï¼Œä¸€æ—¦å†å²è®°å½•ä¸­åŒ…å«ä»»ä½•ä¸€æ¡ \"Warmup\" æ¶ˆæ¯ï¼ˆæ— è®ºæ˜¯ç”¨æˆ·å‘é€è¿˜æ˜¯åå°å¿ƒè·³æ®‹ç•™ï¼‰ï¼Œç³»ç»Ÿå°±ä¼šè¯¯åˆ¤æ‰€æœ‰åç»­çš„ç”¨æˆ·è¾“å…¥ï¼ˆå¦‚ \"continue\"ï¼‰ä¸º Warmup è¯·æ±‚å¹¶å¼ºåˆ¶å›å¤ \"OK\"ã€‚\n                - **ä¿®å¤å†…å®¹**: å°†æ£€æµ‹èŒƒå›´é™åˆ¶ä¸ºä»…æ£€æŸ¥**æœ€æ–°**çš„ä¸€æ¡æ¶ˆæ¯ã€‚ç°åœ¨åªæœ‰å½“å‰è¯·æ±‚ç¡®å®æ˜¯ Warmup å¿ƒè·³æ—¶æ‰ä¼šè¢«æ‹¦æˆªï¼Œè§£å†³äº†ç”¨æˆ·åœ¨å¤šè½®å¯¹è¯ä¸­è¢« \"OK\" å¡æ­»çš„é—®é¢˜ã€‚\n                - **å½±å“èŒƒå›´**: æå¤§æå‡äº† Claude Code CLI åŠ Cherry Studio ç­‰å®¢æˆ·ç«¯åœ¨é•¿æ—¶é—´ä¼šè¯ä¸‹çš„å¯ç”¨æ€§ã€‚\n            - **ä¿®å¤ Cache Control æ³¨å…¥ (Fix Issue #744)**:\n                - **é—®é¢˜æ ¹æº**: Claude å®¢æˆ·ç«¯åœ¨ Thinking å—ä¸­æ³¨å…¥äº†éæ ‡å‡†çš„ `cache_control: {\"type\": \"ephemeral\"}` å­—æ®µï¼Œå¯¼è‡´ Google API è¿”å› `Extra inputs are not permitted` 400 é”™è¯¯ã€‚\n                - **ä¿®å¤å†…å®¹**: å®ç°äº†å…¨å±€é€’å½’æ¸…ç†å‡½æ•° `clean_cache_control_from_messages`ï¼Œå¹¶å°†å…¶é›†æˆåˆ° Anthropic (z.ai) è½¬å‘è·¯å¾„ä¸­ï¼Œç¡®ä¿åœ¨å‘é€ç»™ä¸Šæ¸¸ API å‰ç§»é™¤æ‰€æœ‰ `cache_control` å­—æ®µã€‚\n            - **ç­¾åé”™è¯¯é˜²å¾¡ä½“ç³»å…¨é¢éªŒè¯**:\n                - **éšå¼ä¿®å¤ (Implicit Fixes)**: ç»è¿‡æ·±åº¦ä»£ç å®¡è®¡ï¼Œç¡®è®¤æ­¤å‰æŠ¥å‘Šçš„ä¸€ç³»åˆ—ç­¾åç›¸å…³ Issue (#755, #654, #653, #639, #617) å·²è¢« v3.3.35 çš„**ä¸¥æ ¼ç­¾åéªŒè¯**ã€**è‡ªåŠ¨é™çº§**åŠ**Base64 æ™ºèƒ½è§£ç **æœºåˆ¶æ‰€è¦†ç›–å’Œä¿®å¤ã€‚ç°åœ¨çš„ç³»ç»Ÿå¯¹ç¼ºå¤±ã€æŸåæˆ–ç¼–ç é”™è¯¯çš„ç­¾åå…·æœ‰æé«˜çš„å®¹é”™æ€§ã€‚\n        - **æ™ºèƒ½é¢„çƒ­é€»è¾‘ä¿®å¤ (Fix Issue #760)**:\n            - **é—®é¢˜æ ¹æº**: ä¿®å¤äº†è‡ªåŠ¨é¢„çƒ­è°ƒåº¦å™¨ä¸­çš„ä¸€æ®µé—ç•™ä»£ç ï¼Œè¯¥ä»£ç é”™è¯¯åœ°å°† `gemini-2.5-flash` çš„é…é¢çŠ¶æ€å¼ºåˆ¶æ˜ å°„ç»™ `gemini-3-flash`ã€‚\n            - **ç°è±¡**: è¿™ä¼šå¯¼è‡´å½“ `gemini-2.5-flash` ä»æœ‰é¢åº¦ï¼ˆå¦‚ 100%ï¼‰ä½† `gemini-3-flash` å·²è€—å°½ï¼ˆ0%ï¼‰æ—¶ï¼Œç³»ç»Ÿè¯¯åˆ¤ `gemini-3-flash` ä¹Ÿä¸ºæ»¡é¢å¹¶è§¦å‘é¢„çƒ­ï¼Œé€ æˆâ€œæ— é¢åº¦å´é¢„çƒ­â€çš„å¹½çµè¯·æ±‚ã€‚\n            - **ä¿®å¤å†…å®¹**: ç§»é™¤äº†æ‰€æœ‰ç¡¬ç¼–ç çš„ `2.5 -> 3` æ˜ å°„é€»è¾‘ã€‚ç°åœ¨çš„é¢„çƒ­è°ƒåº¦å™¨ä¸¥æ ¼æ£€æŸ¥æ¯ä¸ªæ¨¡å‹è‡ªèº«çš„é…é¢ç™¾åˆ†æ¯”ï¼Œåªæœ‰å½“è¯¥æ¨¡å‹å®æµ‹ä¸º 100% æ—¶æ‰ä¼šè§¦å‘é¢„çƒ­ã€‚\n        - **ç§»é™¤ Gemini 2.5 Pro æ¨¡å‹ (Fix Issue #766)**:\n            - **åŸå› **: é‰´äº `gemini-2.5-pro` æ¨¡å‹çš„å¯é æ€§é—®é¢˜ï¼Œå·²å°†å…¶ä»æ”¯æŒåˆ—è¡¨ä¸­ç§»é™¤ã€‚\n            - **è¿ç§»**: æ‰€æœ‰ `gpt-4` ç³»åˆ—åˆ«åï¼ˆå¦‚ `gpt-4`, `gpt-4o`ï¼‰å·²é‡æ–°æ˜ å°„è‡³ `gemini-2.5-flash`ï¼Œç¡®ä¿æœåŠ¡è¿ç»­æ€§ã€‚\n            - **å½±å“**: ä¹‹å‰é€šè¿‡åˆ«åä½¿ç”¨ `gemini-2.5-pro` çš„ç”¨æˆ·å°†è‡ªåŠ¨è·¯ç”±è‡³ `gemini-2.5-flash`ã€‚å‰ç«¯ä¸å†æ˜¾ç¤ºè¯¥æ¨¡å‹ã€‚\n        - **CLI åŒæ­¥å®‰å…¨ä¸å¤‡ä»½å¢å¼º (Fix Issue #756 & #765)**:\n            - **æ™ºèƒ½å¤‡ä»½ä¸è¿˜åŸ**: å¼•å…¥äº†è‡ªåŠ¨å¤‡ä»½æœºåˆ¶ã€‚åœ¨æ‰§è¡ŒåŒæ­¥è¦†ç›–å‰ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å°†ç”¨æˆ·ç°æœ‰çš„é…ç½®æ–‡ä»¶å¤‡ä»½ä¸º `.antigravity.bak`ã€‚â€œæ¢å¤â€åŠŸèƒ½ç°å·²å‡çº§ï¼Œèƒ½æ™ºèƒ½æ£€æµ‹å¤‡ä»½æ–‡ä»¶ï¼Œå¹¶ä¼˜å…ˆæä¾›â€œæ¢å¤åŸæœ‰é…ç½®â€é€‰é¡¹ï¼Œè€Œéå•ä¸€çš„é‡ç½®é»˜è®¤ã€‚\n            - **æ“ä½œäºŒæ¬¡ç¡®è®¤**: ä¸ºâ€œç«‹å³åŒæ­¥é…ç½®â€æ“ä½œå¢åŠ äº†äºŒæ¬¡ç¡®è®¤å¼¹çª—ï¼Œæœ‰æ•ˆé˜²æ­¢è¯¯è§¦å¯¼è‡´æœ¬åœ°ä¸ªæ€§åŒ–é…ç½®ï¼ˆå¦‚ç™»å½•æ€ï¼‰ä¸¢å¤±ã€‚\n            - **CLI æ£€æµ‹å¢å¼º**: ä¼˜åŒ–äº† macOS å¹³å°ä¸‹çš„ CLIï¼ˆå¦‚ Claude Codeï¼‰æ£€æµ‹é€»è¾‘ã€‚å³ä½¿äºŒè¿›åˆ¶æ–‡ä»¶ä¸åœ¨ç³»ç»Ÿ `PATH` ä¸­ï¼Œåªè¦å­˜åœ¨äºæ ‡å‡†å®‰è£…è·¯å¾„ï¼Œä¹Ÿèƒ½è¢«æ­£ç¡®è¯†åˆ«å¹¶è°ƒç”¨ã€‚\n        - **Windows æ§åˆ¶å°é—ªçƒä¿®å¤ (PR #769, æ„Ÿè°¢ @i-smile)**:\n            - **æ— çª—å£è¿è¡Œ**: ä¿®å¤äº†åœ¨ Windows å¹³å°ä¸Šæ‰§è¡Œ CLI åŒæ­¥å‘½ä»¤ï¼ˆå¦‚ `where` æ£€æµ‹ï¼‰æ—¶ä¼šçŸ­æš‚å¼¹å‡ºæ§åˆ¶å°çª—å£çš„é—®é¢˜ã€‚é€šè¿‡æ·»åŠ  `CREATE_NO_WINDOW` æ ‡å¿—ï¼Œç°åœ¨æ‰€æœ‰åå°æ£€æµ‹å‘½ä»¤éƒ½å°†é™é»˜æ‰§è¡Œã€‚\n        - **Auth UI çŠ¶æ€æ˜¾ç¤ºä¿®å¤ (PR #769, æ„Ÿè°¢ @i-smile)**:\n            - **çŠ¶æ€å‡†ç¡®æ€§**: ä¿®æ­£äº† API åä»£é¡µé¢ä¸­è®¤è¯çŠ¶æ€çš„æ˜¾ç¤ºé€»è¾‘ã€‚ç°åœ¨å½“ `auth_mode` ä¸º `off` æ—¶ï¼ŒUI ä¼šæ­£ç¡®æ˜¾ç¤ºâ€œDisabledâ€çŠ¶æ€ï¼Œè€Œä¸æ˜¯ä¸€ç›´æ˜¾ç¤ºâ€œEnabledâ€ã€‚\n    *   **v3.3.35 (2026-01-16)**:\n        - **CLI åŒæ­¥åŠŸèƒ½é‡å¤§å¢å¼º (CLI Sync Enhancements)**:\n            - **å¤šé…ç½®æ–‡ä»¶æ”¯æŒ**: ç°å·²æ”¯æŒåŒæ­¥æ¯ä¸ª CLI çš„å¤šä¸ªé…ç½®æ–‡ä»¶ï¼Œç¡®ä¿ç¯å¢ƒé…ç½®æ›´å®Œæ•´ã€‚æ¶µç›– Claude Code (`settings.json`, `.claude.json`)ã€Codex (`auth.json`, `config.toml`) åŠ Gemini CLI (`.env`, `settings.json`, `config.json`)ã€‚\n            - **Claude å…ç™»å½•ç‰¹æƒ**: åŒæ­¥æ—¶ä¼šè‡ªåŠ¨åœ¨ `~/.claude.json` ä¸­æ³¨å…¥ `\"hasCompletedOnboarding\": true`ï¼Œå¸®åŠ©æ–°ç”¨æˆ·ç›´æ¥è·³è¿‡ Claude CLI çš„åˆå§‹ç™»å½•/å¼•å¯¼æ­¥éª¤ã€‚\n            - **å¤šæ–‡ä»¶æŸ¥é˜…ä½“éªŒ**: é…ç½®æŸ¥çœ‹è¯¦æƒ…é¡µå‡çº§ä¸ºâ€œæ ‡ç­¾é¡µâ€æ¨¡å¼ï¼Œæ”¯æŒåœ¨ä¸€ä¸ªå¼¹çª—å†…é¡ºç•…åˆ‡æ¢å¹¶æŸ¥çœ‹è¯¥ CLI å…³è”çš„æ‰€æœ‰æœ¬åœ°é…ç½®æ–‡ä»¶ã€‚\n        - **UI/UX æ·±åº¦ç»†èŠ‚ä¼˜åŒ–**:\n            - **å¼¹çª—ä½“éªŒç»Ÿä¸€**: å°†â€œæ¢å¤é»˜è®¤é…ç½®â€çš„ç¡®è®¤æ¡†ç”±åŸç”Ÿæµè§ˆå™¨å¼¹çª—æ›¿æ¢ä¸ºåº”ç”¨ä¸»é¢˜ä¸€è‡´çš„ `ModalDialog`ã€‚\n            - **å›¾è¡¨ä¸æ˜¾ç¤ºä¼˜åŒ–**: ä¼˜åŒ–äº†æ¢å¤æŒ‰é’®å›¾æ ‡ (RotateCcw)ï¼›ç²¾ç®€äº†çŠ¶æ€æ ‡ç­¾æ–‡æ¡ˆå¹¶å¼ºåˆ¶ä¸æ¢è¡Œï¼Œè§£å†³äº†é«˜åˆ†å±æˆ–çª„çª—å£ä¸‹çš„å¸ƒå±€é”™ä½é—®é¢˜ã€‚\n            - **ç‰ˆæœ¬å·ç²¾ç®€**: æ”¹è¿›äº† CLI ç‰ˆæœ¬å·æå–é€»è¾‘ï¼Œç•Œé¢ä»…ä¿ç•™çº¯æ•°å­—ç‰ˆæœ¬ï¼ˆå¦‚ v0.86.0ï¼‰ï¼Œè§†è§‰æ›´åŠ æ¸…çˆ½ã€‚\n        - **Claude æ€è€ƒç­¾åæŒä¹…åŒ–ä¿®å¤ (Fix Issue #752)**:\n            - **é—®é¢˜æ ¹æº**: \n                - **å“åº”æ”¶é›†ä¾§**ï¼šv3.3.34 ä¸­æµå¼å“åº”æ”¶é›†å™¨ (`collector.rs`) åœ¨å¤„ç† `content_block_start` äº‹ä»¶æ—¶é—æ¼äº† `thinking` å—çš„ `signature` å­—æ®µï¼Œå¯¼è‡´ç­¾åä¸¢å¤±ã€‚\n                - **è¯·æ±‚è½¬æ¢ä¾§**ï¼šå†å²æ¶ˆæ¯ä¸­çš„ç­¾åæœªç»éªŒè¯ç›´æ¥å‘é€ç»™ Geminiï¼Œå¯¼è‡´è·¨æ¨¡å‹åˆ‡æ¢æˆ–å†·å¯åŠ¨æ—¶å‡ºç° `Invalid signature in thinking block` é”™è¯¯ã€‚\n            - **ä¿®å¤å†…å®¹**: \n                - **å“åº”æ”¶é›†å™¨**ï¼šåœ¨ `collector.rs` ä¸­æ·»åŠ äº† `signature` å­—æ®µçš„æå–å’ŒæŒä¹…åŒ–é€»è¾‘ï¼Œå¹¶è¡¥å……äº†å•å…ƒæµ‹è¯• `test_collect_thinking_response_with_signature`ã€‚\n                - **è¯·æ±‚è½¬æ¢å™¨**ï¼šåœ¨ `request.rs` ä¸­å®æ–½ä¸¥æ ¼ç­¾åéªŒè¯ï¼Œåªä½¿ç”¨å·²ç¼“å­˜ä¸”å…¼å®¹çš„ç­¾åã€‚æœªçŸ¥æˆ–ä¸å…¼å®¹çš„ç­¾åä¼šå¯¼è‡´ thinking å—è‡ªåŠ¨é™çº§ä¸ºæ™®é€šæ–‡æœ¬ï¼Œé¿å…å‘é€æ— æ•ˆç­¾åã€‚\n                - **å›é€€æœºåˆ¶**ï¼šå®ç°æ™ºèƒ½å›é€€é‡è¯•é€»è¾‘ã€‚å¦‚æœç­¾åéªŒè¯å¤±æ•ˆæˆ–ä¸Šæ¸¸ API æ‹’ç»ï¼ˆ400é”™è¯¯ï¼‰ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ¸…é™¤æ‰€æœ‰ thinking å—å¹¶å¼ºåˆ¶é‡è¯•ï¼Œç¡®ä¿ç”¨æˆ·è¯·æ±‚æ€»æ˜¯æˆåŠŸã€‚\n            - **å½±å“èŒƒå›´**: è§£å†³äº† `Invalid signature in thinking block` é”™è¯¯ï¼Œæ”¯æŒè·¨æ¨¡å‹åˆ‡æ¢å’Œå†·å¯åŠ¨åœºæ™¯ï¼Œç¡®ä¿ Thinking æ¨¡å‹åœ¨æ‰€æœ‰æ¨¡å¼ä¸‹ç¨³å®šå·¥ä½œã€‚\n        - **API ç›‘æ§æ•°æ®å®æ—¶åŒæ­¥ä¿®å¤ (Pull Request #747, Thanks to @xycxl)**:\n            - **é—®é¢˜æ ¹æº**: ä¿®å¤äº† API ç›‘æ§é¡µé¢å› äº‹ä»¶ç›‘å¬å™¨é‡å¤æ³¨å†Œå’ŒçŠ¶æ€ä¸åŒæ­¥å¯¼è‡´çš„æ—¥å¿—é‡å¤æ˜¾ç¤ºã€è®¡æ•°å™¨ä¸å‡†ç­‰é—®é¢˜ã€‚\n            - **ä¿®å¤å†…å®¹**:\n                - **æ•°æ®å»é‡**: å¼•å…¥ `pendingLogsRef` å’Œ ID æ’é‡æœºåˆ¶ï¼Œæœç»æ—¥å¿—åˆ—è¡¨ä¸­å‡ºç°é‡å¤æ¡ç›®ã€‚\n                - **ç²¾å‡†è®¡æ•°**: å®ç°äº†å‰åç«¯çŠ¶æ€çš„ä¸¥æ ¼åŒæ­¥ï¼Œæ¯æ¬¡æ¥æ”¶æ–°æ—¥å¿—éƒ½ä»åç«¯è·å–æƒå¨çš„ `totalCount`ï¼Œç¡®ä¿é¡µç å’Œæ€»æ•°å‡†ç¡®æ— è¯¯ã€‚\n                - **é˜²æŠ–ä¼˜åŒ–**: ä¼˜åŒ–äº†æ—¥å¿—æ›´æ–°çš„é˜²æŠ–é€»è¾‘ï¼Œå‡å°‘ React é‡æ¸²æŸ“æ¬¡æ•°ï¼Œæå‡é¡µé¢æµç•…åº¦ã€‚\n                - **åŠŸèƒ½é‡å‘½å**: å°†â€œè°ƒç”¨è®°å½•â€é‡å‘½åä¸ºâ€œæµé‡æ—¥å¿—â€ï¼Œå¹¶æ¢å¤è·¯ç”±ä¸º `/monitor`ï¼Œä½¿åŠŸèƒ½å®šä½æ›´åŠ ç›´è§‚ã€‚\n    *   **v3.3.34 (2026-01-16)**:\n        - **OpenAI Codex/Responses åè®®ä¿®å¤ (Fix Issue #742)**:\n            - **400 Invalid Argument ä¿®å¤**:\n                - **é—®é¢˜æ ¹æº**: `/v1/responses` ç­‰ä¸“æœ‰æ¥å£åœ¨è¯·æ±‚ä½“ä¸­ä»…åŒ…å« `instructions` æˆ– `input` è€Œç¼ºå¤± `messages` å­—æ®µæ—¶ï¼Œè½¬æ¢é€»è¾‘æœªè¦†ç›–å…¨åœºæ™¯ï¼Œå¯¼è‡´ Gemini æ¥æ”¶åˆ°ç©º Bodyã€‚\n                - **ä¿®å¤å†…å®¹**: åœ¨ `handle_completions` ä¸­åå‘ç§»æ¤äº†èŠå¤©æ¥å£çš„â€œè¯·æ±‚æ ‡å‡†åŒ–â€é€»è¾‘ã€‚ç°åœ¨ç³»ç»Ÿä¼šå¼ºåˆ¶æ£€æµ‹ Codex ç‰¹æœ‰å­—æ®µï¼ˆ`instructions`/`input`ï¼‰ï¼Œå³ä½¿ `messages` ä¸ºç©ºæˆ–ç¼ºå¤±ï¼Œä¹Ÿä¼šè‡ªåŠ¨å°†å…¶è½¬åŒ–ä¸ºæ ‡å‡†çš„ System/User æ¶ˆæ¯å¯¹ï¼Œç¡®ä¿ä¸Šæ¸¸è¯·æ±‚åˆæ³•ã€‚\n            - **429/503 é«˜çº§é‡è¯•ä¸è´¦å·è½®æ¢æ”¯æŒ**:\n                - **é€»è¾‘å¯¹é½**: å°† Claude å¤„ç†å™¨ä¸­éªŒè¯è¿‡çš„â€œæ™ºèƒ½æŒ‡æ•°é€€é¿â€ä¸â€œå¤šç»´è´¦å·è½®æ¢â€ç­–ç•¥å®Œæ•´ç§»æ¤åˆ°äº† OpenAI Completions æ¥å£ã€‚\n                - **æ•ˆæœ**: ç°åœ¨ Codex æ¥å£åœ¨é‡åˆ°é™æµæˆ–æœåŠ¡å™¨è¿‡è½½æ—¶ï¼Œä¼šè‡ªåŠ¨æ‰§è¡Œæ¯«ç§’çº§åˆ‡æ¢ï¼Œä¸å†ç›´æ¥æŠ›å‡ºé”™è¯¯ï¼Œæå¤§æå‡äº† VS Code æ’ä»¶ç­‰å·¥å…·çš„ç¨³å®šæ€§ã€‚\n            - **ä¼šè¯ç²˜æ€§ (Session Stickiness) æ”¯æŒ**:\n                - **åŠŸèƒ½æ‰©å±•**: è¡¥å…¨äº† OpenAI åè®®ä¸‹çš„ `session_id` æå–ä¸è°ƒåº¦é€»è¾‘ã€‚ç°åœ¨æ— è®ºæ˜¯ Chat è¿˜æ˜¯ Codex æ¥å£ï¼Œåªè¦æ˜¯åŒä¸€æ®µå¯¹è¯ï¼Œç³»ç»Ÿéƒ½ä¼šå°½é‡å°†å…¶è°ƒåº¦åˆ°åŒä¸€ä¸ª Google è´¦å·ä¸Šã€‚\n                - **æ€§èƒ½çº¢åˆ©**: è¿™å°†æ˜¾è‘—æå‡ Google Prompt Caching çš„å‘½ä¸­ç‡ï¼Œä»è€Œå¤§å¹…åŠ å¿«å“åº”é€Ÿåº¦å¹¶èŠ‚çœè®¡ç®—èµ„æºã€‚\n        - **Claude æ€è€ƒç­¾åç¼–ç ä¿®å¤ (Fix Issue #726)**:\n            - **é—®é¢˜æ ¹æº**: ä¿®å¤äº† v3.3.33 ä¸­å¼•å…¥çš„ Regressionï¼Œè¯¥ç‰ˆæœ¬é”™è¯¯åœ°å¯¹å·²ç» Base64 ç¼–ç çš„ `thoughtSignature` è¿›è¡Œäº†äºŒæ¬¡ç¼–ç ï¼Œå¯¼è‡´ Google Vertex AI æ— æ³•æ­£ç¡®æ ¡éªŒç­¾åè€Œè¿”å› `Invalid signature` é”™è¯¯ã€‚\n            - **ä¿®å¤å†…å®¹**: ç§»é™¤äº† `Thinking`ã€`ToolUse` å’Œ `ToolResult` å¤„ç†é€»è¾‘ä¸­å¤šä½™çš„ Base64 ç¼–ç æ­¥éª¤ï¼Œç¡®ä¿ç­¾åä»¥åŸå§‹æ ¼å¼æ­£ç¡®é€ä¼ ç»™ä¸Šæ¸¸ã€‚\n            - **å½±å“èŒƒå›´**: è§£å†³äº†ä½¿ç”¨ Thinking æ¨¡å‹ï¼ˆå¦‚ Claude 4.5 Opus / Sonnetï¼‰åœ¨å¤šè½®å¯¹è¯ä¸­è§¦å‘çš„ 400 ç­¾åé”™è¯¯ï¼Œä»¥åŠç”±æ­¤å¯¼è‡´çš„ \"Error searching files\" ä»»åŠ¡å¡æ­»é—®é¢˜ (Issue #737)ã€‚\n        - **API ç›‘æ§çœ‹æ¿åˆ·æ–°ä¿®å¤ (Fix Issue #735)**:\n            - **é—®é¢˜æ ¹æº**: ä¿®å¤äº† `ProxyMonitor` ç»„ä»¶ä¸­å›  Closure å¯¼è‡´çš„äº‹ä»¶ç›‘å¬å¤±æ•ˆé—®é¢˜ï¼Œè¯¥é—®é¢˜å¯¼è‡´æ–°è¯·æ±‚æ— æ³•è‡ªåŠ¨æ˜¾ç¤ºåœ¨åˆ—è¡¨ä¸­ã€‚\n            - **ä¿®å¤å†…å®¹**: å¼•å…¥ `useRef` ä¼˜åŒ–äº‹ä»¶ç¼“å†²é€»è¾‘ï¼Œå¹¶æ–°å¢æ‰‹åŠ¨åˆ·æ–°æŒ‰é’®ä½œä¸ºå¤‡ä»½æ–¹æ¡ˆï¼›åŒæ—¶åœ¨ Tauri æƒé™é…ç½®ä¸­æ˜¾å¼å…è®¸äº†äº‹ä»¶ç›‘å¬ã€‚\n        - **ä¸¥æ ¼åˆ†ç»„é…é¢ä¿æŠ¤ä¿®å¤ (Strict Grouped Quota Protection Fix - Core Thanks to @Mag1cFall PR #746)**:\n            - **é—®é¢˜æ ¹æº**: ä¿®å¤äº†åœ¨ä¸¥æ ¼åŒ¹é…æ¨¡å¼ä¸‹ï¼Œé…é¢ä¿æŠ¤é€»è¾‘å› å¤§å°å†™æ•æ„Ÿå’Œå‰ç«¯ UI é”®åæ˜ å°„ç¼ºå¤±è€Œå¤±æ•ˆçš„é—®é¢˜ã€‚ä¹‹å‰ç‰ˆæœ¬ä¸­ `gemini-pro` ç­‰ UI ç®€å†™é”®åæ— æ³•åŒ¹é…åˆ°åç«¯å®šä¹‰çš„ `gemini-3-pro-high` ä¸¥æ ¼ç»„ã€‚\n            - **ä¿®å¤å†…å®¹**:\n                - **å³æ—¶å¤§å°å†™å½’ä¸€åŒ–**: æ¢å¤äº†åç«¯ `normalize_to_standard_id` çš„å¤§å°å†™ä¸æ•æ„ŸåŒ¹é…ï¼Œç¡®ä¿ `Gemini-3-Pro-High` ç­‰å˜ä½“èƒ½è¢«æ­£ç¡®è¯†åˆ«ã€‚\n                - **UI é”®åæ™ºèƒ½æ˜ å°„**: åœ¨å‰ç«¯ `isModelProtected` ä¸­å¢åŠ äº†å¯¹ `gemini-pro/flash` ç­‰ UI åˆ—åçš„è‡ªåŠ¨æ˜ å°„ï¼Œç¡®ä¿ UI ä¸Šçš„é”å›¾æ ‡èƒ½æ­£ç¡®åæ˜ åç«¯ä¿æŠ¤çŠ¶æ€ã€‚\n            - **å½±å“èŒƒå›´**: è§£å†³äº† Gemini 3 Pro/Flash å’Œ Claude 4.5 Sonnet åœ¨ä¸¥æ ¼åˆ†ç»„æ¨¡å¼ä¸‹çš„é”å›¾æ ‡æ˜¾ç¤ºé—®é¢˜ï¼Œç¡®ä¿é…é¢è€—å°½æ—¶èƒ½ç›´è§‚æç¤ºç”¨æˆ·ã€‚\n        - **OpenAI åè®® Usage ç»Ÿè®¡ä¿®å¤ (Pull Request #749, Thanks to @stillyun)**:\n            - **é—®é¢˜æ ¹æº**: åœ¨ OpenAI åè®®è½¬æ¢è¿‡ç¨‹ä¸­ï¼Œæœªå°† Gemini è¿”å›çš„ `usageMetadata` æ˜ å°„åˆ° OpenAI æ ¼å¼çš„ `usage` å­—æ®µï¼Œå¯¼è‡´ Kilo ç­‰å®¢æˆ·ç«¯æ˜¾ç¤º Token ä½¿ç”¨é‡ä¸º 0ã€‚\n            - **ä¿®å¤å†…å®¹**:\n                - **æ•°æ®æ¨¡å‹è¡¥å…¨**: ä¸º `OpenAIResponse` å¢åŠ äº†æ ‡å‡†çš„ `usage` å­—æ®µã€‚\n                - **å…¨é“¾è·¯æ˜ å°„**: å®ç°äº†ä»æµå¼ (SSE) å’Œéæµå¼å“åº”ä¸­æå–å¹¶æ˜ å°„ `prompt_tokens`ã€`completion_tokens` åŠ `total_tokens` çš„é€»è¾‘ã€‚\n            - **å½±å“èŒƒå›´**: è§£å†³äº† Kilo Editorã€Claude Code ç­‰å·¥å…·åœ¨ä½¿ç”¨ OpenAI åè®®æ—¶æ— æ³•ç»Ÿè®¡ Token ç”¨é‡çš„é—®é¢˜ã€‚\n        - **Linux ä¸»é¢˜åˆ‡æ¢å´©æºƒä¿®å¤ (Pull Request #750, Thanks to @infinitete)**:\n            - **ä¿®å¤å†…å®¹**: \n                - åœ¨ Linux å¹³å°ç¦ç”¨ä¸å…¼å®¹çš„ `setBackgroundColor` è°ƒç”¨ã€‚\n                - é’ˆå¯¹ WebKitGTK ç¯å¢ƒç¦ç”¨ View Transition API ä»¥é˜²æ­¢é€æ˜çª—å£å´©æºƒã€‚\n                - å¯åŠ¨æ—¶è‡ªåŠ¨è°ƒæ•´ GTK çª—å£ alpha é€šé“ä»¥å¢å¼ºç¨³å®šæ€§ã€‚\n            - **å½±å“èŒƒå›´**: è§£å†³äº† Linux ç”¨æˆ·åœ¨åˆ‡æ¢æ·±è‰²/æµ…è‰²æ¨¡å¼æ—¶å¯èƒ½é‡åˆ°çš„ç¨‹åºå¡æ­»æˆ–ç¡¬å´©æºƒé—®é¢˜ã€‚\n    *   **v3.3.33 (2026-01-15)**:\n        - **Codex å…¼å®¹æ€§ä¸æ¨¡å‹æ˜ å°„ä¿®å¤ (Fix Issue #697)**:\n            - **Instructions å‚æ•°æ”¯æŒ**: ä¿®å¤äº†å¯¹ `instructions` å‚æ•°çš„å¤„ç†é€»è¾‘ï¼Œç¡®ä¿å…¶ä½œä¸ºç³»ç»ŸæŒ‡ä»¤ï¼ˆSystem Instructionsï¼‰æ­£ç¡®æ³¨å…¥ï¼Œæå‡ä¸ Codex ç­‰å·¥å…·çš„å…¼å®¹æ€§ã€‚\n            - **è‡ªåŠ¨ Responses æ ¼å¼æ£€æµ‹**: åœ¨ OpenAI å¤„ç†å™¨ä¸­æ–°å¢æ™ºèƒ½æ£€æµ‹é€»è¾‘ï¼Œè‡ªåŠ¨è¯†åˆ«å¹¶è½¬æ¢ `instructions` æˆ– `input` å­—æ®µè§¦å‘çš„ Responses æ¨¡å¼ï¼Œæ— éœ€å®¢æˆ·ç«¯æ‰‹åŠ¨åˆ‡æ¢ã€‚\n            - **æ¨¡å‹æ˜ å°„æ¢å¤ä¸å½’ä¸€åŒ–**: æ¢å¤äº† `gemini-3-pro-low/high/pro` ç»Ÿä¸€å½’ä¸€åŒ–ä¸ºå†…éƒ¨åˆ«å `gemini-3-pro-preview` çš„é€»è¾‘ï¼Œå¹¶ç¡®ä¿åœ¨ä¸Šæ¸¸è¯·æ±‚æ—¶æ­£ç¡®è¿˜åŸä¸ºç‰©ç†æ¨¡å‹å `high`ã€‚\n            - **Opus æ˜ å°„å¢å¼º**: ä¼˜åŒ–äº†ç³»ç»Ÿé»˜è®¤æ˜ å°„ï¼Œè‡ªåŠ¨è¯†åˆ« `opus` å…³é”®å­—æ¨¡å‹å¹¶ç¡®ä¿å…¶é»˜è®¤è·¯ç”±è‡³é«˜æ€§èƒ½ Pro é¢„è§ˆçº¿è·¯ã€‚\n        - **OpenAI å·¥å…·è°ƒç”¨ä¸æ€è€ƒå†…å®¹ä¿®å¤ (Fix Issue #710)**:\n            - **ä¿ç•™å·¥å…·è°ƒç”¨ ID**: ä¿®å¤äº† OpenAI æ ¼å¼è½¬æ¢è¿‡ç¨‹ä¸­ä¸¢å¤± `tool_use.id` çš„é—®é¢˜ï¼Œç¡®ä¿ `functionCall` å’Œ `functionResponse` å‡ä¿ç•™åŸå§‹ IDï¼Œè§£å†³äº†è°ƒç”¨ Claude æ¨¡å‹æ—¶çš„ `Field required` é”™è¯¯ã€‚\n            - **æ€è€ƒå†…å®¹ (Reasoning) åŸç”Ÿæ”¯æŒ**: å¢åŠ äº†å¯¹ OpenAI æ¶ˆæ¯ä¸­ `reasoning_content` çš„æ”¯æŒï¼Œå°†å…¶æ­£ç¡®æ˜ å°„ä¸ºå†…éƒ¨ `thought` éƒ¨åˆ†å¹¶æ³¨å…¥æ€ç»´é“¾ç­¾åï¼Œæ˜¾è‘—æå‡äº†â€œæ€è€ƒå‹â€æ¨¡å‹çš„è§†è§‰å›æ˜¾æ•ˆæœã€‚\n            - **å·¥å…·å“åº”æ ¼å¼ä¼˜åŒ–**: ä¿®å¤äº† `tool` è§’è‰²æ¶ˆæ¯ä¸­å¯èƒ½äº§ç”Ÿçš„å†—ä½™ Part å†²çªï¼Œç¡®ä¿è¯·æ±‚æŠ¥æ–‡ä¸¥æ ¼ç¬¦åˆä¸Šæ¸¸æ ¡éªŒè§„èŒƒã€‚\n        - **å¤–éƒ¨æä¾›å•†æ™ºèƒ½å…œåº•ä¿®å¤ (Fix Issue #703)**: ä¿®å¤äº†\"ä»…å…œåº•\"æ¨¡å¼åœ¨ Google è´¦å·é¢åº¦è€—å°½æ—¶æ— æ³•è‡ªåŠ¨åˆ‡æ¢åˆ°å¤–éƒ¨æä¾›å•†çš„é—®é¢˜ã€‚\n            - **æ ¸å¿ƒé—®é¢˜**: åŸåˆ¤æ–­é€»è¾‘åªæ£€æŸ¥ Google è´¦å·æ•°é‡æ˜¯å¦ä¸º 0,è€Œä¸æ£€æŸ¥è´¦å·çš„å®é™…å¯ç”¨æ€§(é™æµçŠ¶æ€ã€é…é¢ä¿æŠ¤çŠ¶æ€),å¯¼è‡´è´¦å·å­˜åœ¨ä½†ä¸å¯ç”¨æ—¶ç›´æ¥è¿”å› 429 é”™è¯¯ã€‚\n            - **è§£å†³æ–¹æ¡ˆ**: å®ç°æ™ºèƒ½è´¦å·å¯ç”¨æ€§æ£€æŸ¥æœºåˆ¶,åœ¨ `TokenManager` ä¸­æ–°å¢ `has_available_account()` æ–¹æ³•,ç»¼åˆåˆ¤æ–­è´¦å·çš„é™æµçŠ¶æ€å’Œé…é¢ä¿æŠ¤çŠ¶æ€ã€‚\n            - **ä¿®æ”¹æ–‡ä»¶**:\n                - `token_manager.rs`: æ–°å¢ `has_available_account()` æ–¹æ³•,æ£€æŸ¥æ˜¯å¦å­˜åœ¨æœªè¢«é™æµä¸”æœªè¢«é…é¢ä¿æŠ¤çš„å¯ç”¨è´¦å·\n                - `handlers/claude.rs`: ä¼˜åŒ– Fallback æ¨¡å¼åˆ¤æ–­é€»è¾‘,ä»ç®€å•çš„ `google_accounts == 0` æ”¹ä¸ºæ™ºèƒ½çš„å¯ç”¨æ€§æ£€æŸ¥\n            - **è¡Œä¸ºæ”¹è¿›**: å½“æ‰€æœ‰ Google è´¦å·å› é™æµã€é…é¢ä¿æŠ¤æˆ–å…¶ä»–åŸå› ä¸å¯ç”¨æ—¶,ç³»ç»Ÿä¼šè‡ªåŠ¨åˆ‡æ¢åˆ°å¤–éƒ¨æä¾›å•†,å®ç°çœŸæ­£çš„æ™ºèƒ½å…œåº•ã€‚\n            - **å½±å“èŒƒå›´**: æ­¤ä¿®å¤ç¡®ä¿äº†å¤–éƒ¨æä¾›å•†(å¦‚æ™ºè°± API)çš„\"ä»…å…œåº•\"æ¨¡å¼èƒ½å¤Ÿæ­£ç¡®å·¥ä½œ,æ˜¾è‘—æå‡äº†å¤šè´¦å·åœºæ™¯ä¸‹çš„æœåŠ¡å¯ç”¨æ€§ã€‚\n        - **é…é¢ä¿æŠ¤æ¨¡å‹åç§°å½’ä¸€åŒ–ä¿®å¤ (Fix Issue #685)**: ä¿®å¤äº†é…é¢ä¿æŠ¤åŠŸèƒ½å› æ¨¡å‹åç§°ä¸åŒ¹é…è€Œå¤±æ•ˆçš„é—®é¢˜ã€‚\n            - **æ ¸å¿ƒé—®é¢˜**: Quota API è¿”å›çš„æ¨¡å‹åç§°(å¦‚ `gemini-2.5-flash`)ä¸ç”¨æˆ·åœ¨ UI å‹¾é€‰çš„æ ‡å‡†åç§°(å¦‚ `gemini-3-flash`)ä¸ä¸€è‡´,å¯¼è‡´ç²¾ç¡®å­—ç¬¦ä¸²åŒ¹é…å¤±è´¥,ä¿æŠ¤æœºåˆ¶æ— æ³•è§¦å‘ã€‚\n            - **è§£å†³æ–¹æ¡ˆ**: å®ç°äº†ç»Ÿä¸€çš„æ¨¡å‹åç§°å½’ä¸€åŒ–å¼•æ“ `normalize_to_standard_id`,å°†æ‰€æœ‰ç‰©ç†æ¨¡å‹åæ˜ å°„åˆ° 3 ä¸ªæ ‡å‡†ä¿æŠ¤ ID:\n                - `gemini-3-flash`: æ‰€æœ‰ Flash å˜ä½“ (1.5-flash, 2.5-flash, 3-flash ç­‰)\n                - `gemini-3-pro-high`: æ‰€æœ‰ Pro å˜ä½“ (1.5-pro, 2.5-pro ç­‰)\n                - `claude-sonnet-4-5`: æ‰€æœ‰ Claude Sonnet å˜ä½“ (3-5-sonnet, sonnet-4-5 ç­‰)\n            - **ä¿®æ”¹æ–‡ä»¶**:\n                - `model_mapping.rs`: æ–°å¢å½’ä¸€åŒ–å‡½æ•°\n                - `account.rs`: é…é¢æ›´æ–°æ—¶å½’ä¸€åŒ–æ¨¡å‹åå¹¶å­˜å‚¨æ ‡å‡† ID\n                - `token_manager.rs`: è¯·æ±‚æ‹¦æˆªæ—¶å½’ä¸€åŒ– `target_model` è¿›è¡ŒåŒ¹é…\n            - **è”ç½‘é™çº§åœºæ™¯**: å³ä½¿è¯·æ±‚å› è”ç½‘æœç´¢è¢«é™çº§ä¸º `gemini-2.5-flash`,ä¾ç„¶èƒ½æ­£ç¡®å½’ä¸€åŒ–ä¸º `gemini-3-flash` å¹¶è§¦å‘ä¿æŠ¤ã€‚\n            - **å½±å“èŒƒå›´**: è§£å†³äº†é…é¢ä¿æŠ¤å¤±æ•ˆé—®é¢˜,ç¡®ä¿æ‰€æœ‰ 3 ä¸ªç›‘æ§æ¨¡å‹çš„ä¿æŠ¤åŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚\n        - **æ–°å¢è´¦å·å¯¼å…¥åŠŸèƒ½ (#682)**: æ”¯æŒé€šè¿‡å¯¼å‡ºçš„ JSON æ–‡ä»¶æ‰¹é‡å¯¼å…¥å·²æœ‰çš„è´¦å·ï¼Œå®Œå–„äº†è´¦å·è¿ç§»é—­ç¯ã€‚\n        - **æ–°å¢è‘¡è„ç‰™è¯­ä¸ä¿„è¯­æ”¯æŒ (#691, #713)**: ç°å·²æ”¯æŒè‘¡è„ç‰™è¯­ï¼ˆå·´è¥¿ï¼‰ä¸ä¿„è¯­æœ¬åœ°åŒ–ã€‚\n        - **ä»£ç†ç›‘æ§å¢å¼º (#676)**: åœ¨ä»£ç†ç›‘æ§è¯¦æƒ…é¡µä¸­ä¸ºè¯·æ±‚å’Œå“åº”è½½è·æ–°å¢äº†â€œå¤åˆ¶â€æŒ‰é’®ï¼Œå¹¶æ”¯æŒè‡ªåŠ¨ JSON æ ¼å¼åŒ–ã€‚\n        - **i18n ä¿®å¤ä¸ç•Œé¢æ–‡æ¡ˆä¼˜åŒ– (#671, #713)**: ä¿®æ­£äº†æ—¥è¯­ (ja)ã€åœŸè€³å…¶è¯­ (tr) å’Œä¿„è¯­ (ru) ä¸­é—æ¼å’Œé”™ä½çš„ç¿»è¯‘æ–‡æ¡ˆã€‚\n        - **å…¨å±€ HTTP API (#696)**: æ–°å¢æœ¬åœ° HTTP æœåŠ¡ç«¯å£ï¼ˆé»˜è®¤ 19527ï¼‰ï¼Œæ”¯æŒå¤–éƒ¨å·¥å…·ï¼ˆå¦‚ VS Code æ’ä»¶ï¼‰ç›´æ¥é€šè¿‡ API è¿›è¡Œè´¦å·åˆ‡æ¢ã€é…é¢åˆ·æ–°å’Œè®¾å¤‡ç»‘å®šã€‚\n        - **ä»£ç†ç›‘æ§å‡çº§ (#704)**: å…¨é¢é‡æ„ç›‘æ§é¢æ¿ï¼Œå¼•å…¥åç«¯åˆ†é¡µæŸ¥è¯¢ï¼ˆæ”¯æŒæœç´¢è¿‡æ»¤ï¼‰ï¼Œè§£å†³äº†å¤§é‡æ—¥å¿—å¯¼è‡´çš„ç•Œé¢å¡é¡¿é—®é¢˜ï¼›å¼€æ”¾ `GET /logs` æ¥å£ä¾›å¤–éƒ¨è°ƒç”¨ã€‚\n        - **é¢„çƒ­ç­–ç•¥ä¼˜åŒ– (#699)**: é¢„çƒ­è¯·æ±‚æ–°å¢å”¯ä¸€ `session_id`ï¼Œå¹¶å°† `max_tokens` é™åˆ¶ä¸º 8ï¼Œ`temperature` è®¾ç½®ä¸º 0ï¼Œä»¥é™ä½èµ„æºæ¶ˆè€—å¹¶é¿å… 429 é”™è¯¯ã€‚\n        - **é¢„çƒ­é€»è¾‘ä¿®å¤ä¸ä¼˜åŒ–**: ä¿®å¤äº†æ‰‹åŠ¨è§¦å‘é¢„çƒ­æœªè®°å½•å†å²å¯¼è‡´è‡ªåŠ¨è°ƒåº¦é‡å¤é¢„çƒ­çš„é—®é¢˜ï¼›ä¼˜åŒ–è°ƒåº¦å™¨è‡ªåŠ¨è·³è¿‡â€œåä»£ç¦ç”¨â€çŠ¶æ€çš„è´¦å·ã€‚\n        - **æ€§èƒ½æ¨¡å¼è°ƒåº¦ä¼˜åŒ– (PR #706)**: åœ¨â€œæ€§èƒ½ä¼˜å…ˆâ€è°ƒåº¦æ¨¡å¼ä¸‹ï¼Œç°åœ¨ä¼šè·³è¿‡é»˜è®¤çš„ 60ç§’å…¨å±€é”å®šæœºåˆ¶ï¼Œæ˜¾è‘—æå‡é«˜å¹¶å‘åœºæ™¯ä¸‹çš„è´¦å·è½®è½¬æ•ˆç‡ã€‚\n        - **é™æµè®°å½•è‡ªåŠ¨æ¸…ç† (PR #701)**: å¼•å…¥äº†æ¯åˆ†é’Ÿæ‰§è¡Œçš„åå°æ¸…ç†ä»»åŠ¡ï¼Œè‡ªåŠ¨ç§»é™¤è¶…è¿‡ 1 å°æ—¶çš„è¿‡æœŸå¤±è´¥è®°å½•ï¼Œè§£å†³é•¿æœŸè¿è¡Œåå› å†å²è®°å½•ç´¯ç§¯å¯¼è‡´çš„â€œæ— å¯ç”¨è´¦å·â€è¯¯æŠ¥é—®é¢˜ã€‚\n        - **API Monitor é”å®šä¿®å¤ (Fix Issue #708)**: å¯ç”¨ SQLite WAL æ¨¡å¼å¹¶ä¼˜åŒ–è¿æ¥é…ç½®ï¼Œè§£å†³äº†é«˜å¹¶å‘åœºæ™¯ä¸‹å› æ•°æ®åº“é”å®šå¯¼è‡´çš„ç›‘æ§æ•°æ®æ»åå’Œä»£ç†æœåŠ¡ 400/429 é”™è¯¯ã€‚\n        - **Claude æç¤ºè¯è¿‡æ»¤ä¼˜åŒ– (#712)**: ä¿®å¤äº†åœ¨è¿‡æ»¤ Claude Code å†—ä½™é»˜è®¤æç¤ºè¯æ—¶ï¼Œè¯¯åˆ ç”¨æˆ·è‡ªå®šä¹‰æŒ‡ä»¤ (Instructions from: ...) çš„é—®é¢˜ï¼Œç¡®ä¿ä¸ªæ€§åŒ–é…ç½®åœ¨é•¿å¯¹è¯åœºæ™¯ä¸‹ä»èƒ½æ­£ç¡®ç”Ÿæ•ˆã€‚\n        - **Claude æ€ç»´å—æ’åºç­–ç•¥ä¼˜åŒ– (Fix Issue #709)**: è§£å†³äº†å¼€å¯æ€ç»´æ¨¡å¼æ—¶ç”±äºå—é¡ºåºé”™ä½ï¼ˆText å‡ºç°åœ¨ Thinking å‰ï¼‰å¯¼è‡´çš„ `INVALID_ARGUMENT` æŠ¥é”™ã€‚\n            - **ä¸‰æ®µå¼å¼ºåˆ¶åˆ†åŒº**: å®ç° `[Thinking, Text, ToolUse]` ä¸¥æ ¼é¡ºåºæ ¡éªŒã€‚\n            - **è‡ªåŠ¨é™çº§ç½‘å…³**: åœ¨å•æ¡æ¶ˆæ¯å†…ï¼Œä¸€æ—¦å‡ºç°éæ€ç»´å†…å®¹ï¼Œåç»­æ€ç»´å—è‡ªåŠ¨é™çº§ä¸ºæ–‡æœ¬ï¼Œç¡®ä¿åè®®åˆè§„ã€‚\n            - **åˆå¹¶åäºŒæ¬¡é‡æ’**: åœ¨ Assistant æ¶ˆæ¯åˆå¹¶é€»è¾‘åå¢åŠ å¼ºåˆ¶é‡æ’åºï¼Œå µæ­»å› æ¶ˆæ¯æ‹¼æ¥å¯¼è‡´çš„æ’åºæ¼æ´ã€‚\n    *   **v3.3.32 (2026-01-15)**:\n        - **æ ¸å¿ƒè°ƒåº¦ä¸ç¨³å®šæ€§ä¼˜åŒ– (Fix Issue #630, #631 - æ ¸å¿ƒè‡´è°¢ @lbjlaq PR #640)**:\n            - **é…é¢æ¼æ´ä¸ç»•è¿‡ä¿®å¤**: è§£å†³äº†åœ¨é«˜å¹¶å‘æˆ–ç‰¹å®šé‡è¯•åœºæ™¯ä¸‹ï¼Œé…é¢ä¿æŠ¤æœºåˆ¶å¯èƒ½è¢«ç»•è¿‡çš„æ½œåœ¨æ¼æ´ã€‚\n            - **é™æµ Key åŒ¹é…ä¼˜åŒ–**: å¢å¼ºäº† `TokenManager` ä¸­é™æµè®°å½•çš„åŒ¹é…ç²¾å‡†åº¦ï¼Œè§£å†³äº†åœ¨å¤šå®ä¾‹æˆ–å¤æ‚ç½‘ç»œç¯å¢ƒä¸‹å¯èƒ½å‡ºç°çš„é€Ÿç‡é™åˆ¶åˆ¤å®šä¸ä¸€è‡´é—®é¢˜ã€‚\n            - **è´¦å·ç¦ç”¨é€»è¾‘åŠ å›º**: ä¿®å¤äº†æ‰‹åŠ¨ç¦ç”¨è´¦å·åœ¨æŸäº›ç¼“å­˜ç”Ÿå‘½å‘¨æœŸå†…æœªç«‹å³ä»è°ƒåº¦æ± ä¸­å‰¥ç¦»çš„é—®é¢˜ï¼Œç¡®ä¿â€œç¦ç”¨å³ç”Ÿæ•ˆâ€ã€‚\n            - **è´¦å·çŠ¶æ€é‡ç½®æœºåˆ¶**: å®Œå–„äº†è´¦å·å¤±è´¥è®¡æ•°å™¨åœ¨æˆåŠŸè¯·æ±‚åçš„é‡ç½®ç­–ç•¥ï¼Œé¿å…è´¦å·å› å†å²æ³¢åŠ¨è¢«é•¿æœŸè¯¯é”å®šã€‚\n    *   **v3.3.31 (2026-01-14)**:\n        - **é…é¢ä¿æŠ¤å¤±æ•ˆä¿®å¤ (Fix Issue #631)**:\n            - **å†…å­˜çŠ¶æ€åŒæ­¥**: ä¿®å¤äº†åŠ è½½è´¦å·è§¦å‘é…é¢ä¿æŠ¤æ—¶ï¼Œå†…å­˜çŠ¶æ€æœªç«‹å³åŒæ­¥çš„é—®é¢˜ï¼Œç¡®ä¿ä¿æŠ¤æœºåˆ¶å³æ—¶ç”Ÿæ•ˆã€‚\n            - **å…¨åœºæ™¯è¦†ç›–**: åœ¨â€œç²˜æ€§ä¼šè¯ (Sticky Session)â€å’Œâ€œ60ç§’é”å®š (60s Window Lock)â€é€»è¾‘ä¸­è¡¥å……äº†é…é¢ä¿æŠ¤æ£€æŸ¥ï¼Œé˜²æ­¢å—é™è´¦å·è¢«é”™è¯¯å¤ç”¨ã€‚\n            - **ä»£ç ä¼˜åŒ–**: ä¿®å¤äº† `token_manager.rs` ä¸­çš„éƒ¨åˆ†ç¼–è¯‘è­¦å‘Šã€‚\n        - **Claude å·¥å…·è°ƒç”¨é‡å¤æŠ¥é”™ä¿®å¤ (Fix Issue #632)**:\n            - **å¼¹æ€§ä¿®å¤ä¼˜åŒ–**: æ”¹è¿›äº† `Elastic-Recovery` é€»è¾‘ï¼Œåœ¨æ³¨å…¥å ä½ç»“æœå‰å¢åŠ å…¨é‡æ¶ˆæ¯ ID é¢„æ‰«æï¼Œé¿å…äº† `Found multiple tool_result blocks with id` é”™è¯¯ã€‚\n            - **Anthropic åè®®å¯¹é½**: ç¡®ä¿ç”Ÿæˆçš„è¯·æ±‚åŒ…ä¸¥æ ¼ç¬¦åˆ Anthropic å¯¹å·¥å…·è°ƒç”¨ ID å”¯ä¸€æ€§çš„è¦æ±‚ã€‚\n    *   **v3.3.30 (2026-01-14)**:\n        - **æ¨¡å‹çº§é…é¢ä¿æŠ¤ (Issue #621)**:\n            - **éš”ç¦»ä¼˜åŒ–**: è§£å†³äº†å› å•ä¸ªæ¨¡å‹é…é¢è€—å°½è€Œç¦ç”¨æ•´ä¸ªè´¦å·çš„é—®é¢˜ã€‚ç°åœ¨é…é¢ä¿æŠ¤ä»…é’ˆå¯¹å—é™çš„å…·ä½“æ¨¡å‹ï¼Œè´¦å·ä»å¯å¤„ç†å…¶ä»–æ¨¡å‹çš„è¯·æ±‚ã€‚\n            - **è‡ªåŠ¨è¿ç§»**: æ–°ç³»ç»Ÿä¼šè‡ªåŠ¨å°†æ—§ç‰ˆå› é…é¢ä¿æŠ¤è¢«å…¨å±€ç¦ç”¨çš„è´¦å·æ¢å¤ï¼Œå¹¶å¹³æ»‘è½¬ä¸ºæ¨¡å‹çº§é™åˆ¶ã€‚\n            - **å…¨åè®®æ”¯æŒé¡¹ç›®**: å·²åŒæ­¥æ›´æ–° Claude, OpenAI (Chat/DALL-E), Gemini, Audio å¤„ç†å™¨çš„è·¯ç”±é€»è¾‘ã€‚\n        - **Gemini å‚æ•°å¹»è§‰ä¿®å¤ (PR #622)**:\n            - **å‚æ•°çº é”™**: ä¿®å¤äº† Gemini æ¨¡å‹å°† `pattern` å‚æ•°é”™è¯¯æ”¾ç½®åœ¨ `description` æˆ– `query` å­—æ®µçš„é—®é¢˜ï¼Œå¢åŠ äº†è‡ªåŠ¨é‡æ˜ å°„é€»è¾‘ã€‚\n            - **å¸ƒå°”å€¼å¼ºåˆ¶è½¬æ¢**: å¢åŠ äº†å¯¹ `yes`/`no`ã€`-n` ç­‰éæ ‡å‡†å¸ƒå°”å€¼çš„è‡ªåŠ¨è½¬æ¢æ”¯æŒï¼Œè§£å†³äº† `lineNumbers` ç­‰å‚æ•°å› ç±»å‹é”™è¯¯å¯¼è‡´çš„è°ƒç”¨å¤±è´¥ã€‚\n            - **å½±å“èŒƒå›´**: æ˜¾è‘—æå‡äº† Gemini æ¨¡å‹åœ¨ Claude Code CLI åŠå…¶ä»–å·¥å…·è°ƒç”¨åœºæ™¯ä¸‹çš„ç¨³å®šæ€§å’Œå…¼å®¹æ€§ã€‚\n        - **ä»£ç æ¸…ç†ä¸è­¦å‘Šä¿®å¤ (PR #628)**:\n            - **æ¶ˆé™¤ç¼–è¯‘å™¨è­¦å‘Š**: ä¿®å¤äº†å¤šä¸ªæœªä½¿ç”¨çš„å¯¼å…¥å’Œå˜é‡è­¦å‘Šï¼Œç§»é™¤äº†å†—ä½™ä»£ç ï¼Œä¿æŒä»£ç åº“æ•´æ´ã€‚\n            - **è·¨å¹³å°å…¼å®¹æ€§**: é’ˆå¯¹ Windows/macOS/Linux ä¸åŒå¹³å°çš„ä»£ç è·¯å¾„è¿›è¡Œäº†å®æ ‡è®°ä¼˜åŒ–ã€‚\n        - **API å¯†é’¥è‡ªå®šä¹‰ç¼–è¾‘åŠŸèƒ½ (Issue #627)**:\n            - **è‡ªå®šä¹‰å¯†é’¥æ”¯æŒ**: API åä»£é¡µé¢çš„\"API å¯†é’¥\"é…ç½®é¡¹ç°åœ¨æ”¯æŒç›´æ¥ç¼–è¾‘,ç”¨æˆ·å¯ä»¥è¾“å…¥è‡ªå®šä¹‰å¯†é’¥,é€‚åˆå¤šå®ä¾‹éƒ¨ç½²åœºæ™¯ã€‚\n            - **ä¿ç•™è‡ªåŠ¨ç”Ÿæˆ**: ä¿ç•™äº†åŸæœ‰çš„\"é‡æ–°ç”Ÿæˆ\"åŠŸèƒ½,ç”¨æˆ·å¯ä»¥é€‰æ‹©è‡ªåŠ¨ç”Ÿæˆæˆ–æ‰‹åŠ¨è¾“å…¥ã€‚\n            - **æ ¼å¼éªŒè¯**: æ·»åŠ äº†å¯†é’¥æ ¼å¼éªŒè¯(å¿…é¡»ä»¥ `sk-` å¼€å¤´,é•¿åº¦è‡³å°‘ 10 ä¸ªå­—ç¬¦),é˜²æ­¢æ— æ•ˆè¾“å…¥ã€‚\n            - **å¤šè¯­è¨€æ”¯æŒ**: ä¸ºæ‰€æœ‰ 6 ç§æ”¯æŒçš„è¯­è¨€(ç®€ä½“ä¸­æ–‡ã€è‹±æ–‡ã€ç¹ä½“ä¸­æ–‡ã€æ—¥è¯­ã€åœŸè€³å…¶è¯­ã€è¶Šå—è¯­)æ·»åŠ äº†å®Œæ•´çš„å›½é™…åŒ–ç¿»è¯‘ã€‚\n    *   **v3.3.29 (2026-01-14)**:\n        - **OpenAI æµå¼å“åº” Function Call æ”¯æŒä¿®å¤ (Fix Issue #602, #614)**:\n            - **é—®é¢˜èƒŒæ™¯**: OpenAI æ¥å£çš„æµå¼å“åº” (`stream: true`) ä¸­ç¼ºå°‘ Function Call å¤„ç†é€»è¾‘,å¯¼è‡´å®¢æˆ·ç«¯æ— æ³•æ¥æ”¶åˆ°å·¥å…·è°ƒç”¨ä¿¡æ¯ã€‚\n            - **æ ¹æœ¬åŸå› **: `create_openai_sse_stream` å‡½æ•°åªå¤„ç†äº†æ–‡æœ¬å†…å®¹ã€æ€è€ƒå†…å®¹å’Œå›¾ç‰‡,å®Œå…¨ç¼ºå°‘å¯¹ `functionCall` çš„å¤„ç†ã€‚\n            - **ä¿®å¤å†…å®¹**:\n                - æ·»åŠ å·¥å…·è°ƒç”¨çŠ¶æ€è¿½è¸ªå˜é‡ (`emitted_tool_calls`),é˜²æ­¢é‡å¤å‘é€\n                - åœ¨ parts å¾ªç¯ä¸­æ·»åŠ  `functionCall` æ£€æµ‹å’Œè½¬æ¢é€»è¾‘\n                - æ„å»ºç¬¦åˆ OpenAI è§„èŒƒçš„ `delta.tool_calls` æ•°ç»„\n                - ä½¿ç”¨å“ˆå¸Œç®—æ³•ç”Ÿæˆç¨³å®šçš„ `call_id`\n                - åŒ…å«å®Œæ•´çš„å·¥å…·è°ƒç”¨ä¿¡æ¯ (`index`, `id`, `type`, `function.name`, `function.arguments`)\n            - **å½±å“èŒƒå›´**: æ­¤ä¿®å¤ç¡®ä¿äº†æµå¼è¯·æ±‚èƒ½å¤Ÿæ­£ç¡®è¿”å›å·¥å…·è°ƒç”¨ä¿¡æ¯,ä¸éæµå¼å“åº”å’Œ Codex æµå¼å“åº”çš„è¡Œä¸ºä¿æŒä¸€è‡´ã€‚æ‰€æœ‰ä½¿ç”¨ `stream: true` + `tools` å‚æ•°çš„å®¢æˆ·ç«¯ç°åœ¨å¯ä»¥æ­£å¸¸æ¥æ”¶ Function Call æ•°æ®ã€‚\n        - **æ™ºèƒ½é˜ˆå€¼å›å½’ (Smart Threshold Recovery) - è§£å†³ Issue #613**:\n            - **æ ¸å¿ƒé€»è¾‘**: å®ç°äº†ä¸€ç§æ„ŸçŸ¥ä¸Šä¸‹æ–‡è´Ÿè½½çš„åŠ¨æ€ Token æŠ¥å‘Šæœºåˆ¶ã€‚\n            - **ä¿®å¤å†…å®¹**:\n                - **ä¸‰é˜¶æ®µç¼©æ”¾**: åœ¨ä½è´Ÿè½½(0-70%)ä¿æŒé«˜æ•ˆå‹ç¼©;åœ¨ä¸­è´Ÿè½½(70-95%)å¹³æ»‘é™ä½å‹ç¼©ç‡;åœ¨æ¥è¿‘ 100% æé™æ—¶çœŸå®ä¸ŠæŠ¥(å›å½’è‡³ 195k å·¦å³)ã€‚\n                - **æ¨¡å‹æ„Ÿåº”**: å¤„ç†å™¨è‡ªåŠ¨è¯†åˆ« 1M (Flash) å’Œ 2M (Pro) çš„ç‰©ç†ä¸Šä¸‹æ–‡ç•Œé™ã€‚\n                - **400 é”™è¯¯æ‹¦æˆª**: å³ä½¿è§¦å‘ç‰©ç†æº¢å‡ºï¼Œä»£ç†å±‚ä¹Ÿä¼šæ‹¦æˆª `Prompt is too long` é”™è¯¯ï¼Œå¹¶è¿”å›å‹å¥½çš„ä¸­æ–‡/è‹±æ–‡ä¿®å¤æŒ‡å¼•ï¼Œå¼•å¯¼ç”¨æˆ·æ‰§è¡Œ `/compact`ã€‚\n            - **å½±å“èŒƒå›´**: è§£å†³äº† Claude Code åœ¨é•¿å¯¹è¯åœºæ™¯ä¸‹å› ä¸çŸ¥é“çœŸå® Token ç”¨é‡è€Œæ‹’ç»å‹ç¼©ï¼Œæœ€ç»ˆå¯¼è‡´ Gemini æœåŠ¡ç«¯æŠ¥é”™çš„é—®é¢˜ã€‚\n        - **Playwright MCP è¿é€šæ€§ä¸ç¨³å®šæ€§å¢å¼º (å‚è€ƒ [Antigravity2Api](https://github.com/znlsl/Antigravity2Api)) - è§£å†³ Issue #616**:\n            - **SSE å¿ƒè·³ä¿æ´»**: å¼•å…¥ 15 ç§’å®šæ—¶å¿ƒè·³ (`: ping`)ï¼Œè§£å†³é•¿è€—æ—¶å·¥å…·è°ƒç”¨å¯¼è‡´çš„è¿æ¥è¶…æ—¶æ–­å¼€é—®é¢˜ã€‚\n            - **MCP XML Bridge**: å®ç°åŒå‘åè®®è½¬æ¢é€»è¾‘ï¼ˆæŒ‡ä»¤æ³¨å…¥ + æ ‡ç­¾æ‹¦æˆªï¼‰ï¼Œæ˜¾è‘—æå‡ MCP å·¥å…·ï¼ˆå¦‚ Playwrightï¼‰åœ¨ä¸ç¨³å®šé“¾è·¯ä¸‹çš„è¿é€šæ€§ã€‚\n            - **ä¸Šä¸‹æ–‡æ¿€è¿›ç˜¦èº«**: \n                - **æŒ‡ä»¤è¿‡æ»¤**: è‡ªåŠ¨è¯†åˆ«å¹¶ç§»é™¤ Claude Code æ³¨å…¥çš„å†—ä½™ç³»ç»Ÿè¯´æ˜ï¼ˆ~1-2k tokensï¼‰ã€‚\n                - **ä»»åŠ¡å»é‡**: å‰”é™¤ tool_result åé‡å¤çš„ä»»åŠ¡å›æ˜¾æ–‡æœ¬ï¼Œç‰©ç†å‡å°‘ Context å ç”¨ã€‚\n            - **æ™ºèƒ½ HTML æ¸…ç†ä¸æˆªæ–­**: \n                - **æ·±åº¦å‰¥ç¦»**: é’ˆå¯¹æµè§ˆå™¨å¿«ç…§è‡ªåŠ¨ç§»é™¤ `<style>`ã€`<script>` åŠå†…è” Base64 èµ„æºã€‚\n                - **ç»“æ„åŒ–æˆªæ–­**: ä¼˜åŒ–æˆªæ–­ç®—æ³•ï¼Œç¡®ä¿ä¸åœ¨ HTML æ ‡ç­¾æˆ– JSON ä¸­é—´åˆ‡æ–­ï¼Œé¿å…äº§ç”Ÿç ´åæ€§çš„ 400 ç»“æ„é”™è¯¯ã€‚\n        - **è´¦å·ç´¢å¼•åŠ è½½å®¹é”™ä¿®å¤ (Fix Issue #619)**:\n            - **ä¿®å¤å†…å®¹**: åœ¨åŠ è½½ `accounts.json` æ—¶å¢åŠ äº†å¯¹ç©ºæ–‡ä»¶çš„æ£€æµ‹åŠè‡ªåŠ¨é‡ç½®é€»è¾‘ã€‚\n            - **å½±å“èŒƒå›´**: è§£å†³äº†å› ç´¢å¼•æ–‡ä»¶æŸå/ä¸ºç©ºå¯¼è‡´çš„è½¯ä»¶å¯åŠ¨æŠ¥é”™ `expected value at line 1 column 1`ã€‚\n    *   **v3.3.28 (2026-01-14)**:\n        - **OpenAI Thinking Content ä¿®å¤ (PR #604)**:\n            - **ä¿®å¤ Gemini 3 Pro thinking å†…å®¹ä¸¢å¤±**: åœ¨æµå¼å“åº”æ”¶é›†å™¨ä¸­æ·»åŠ  `reasoning_content` ç´¯ç§¯é€»è¾‘,è§£å†³äº† Gemini 3 Pro (high/low) éæµå¼å“åº”ä¸­æ€è€ƒå†…å®¹ä¸¢å¤±çš„é—®é¢˜ã€‚\n            - **æ”¯æŒ Claude *-thinking æ¨¡å‹**: æ‰©å±• thinking æ¨¡å‹æ£€æµ‹é€»è¾‘,æ”¯æŒæ‰€æœ‰ä»¥ `-thinking` ç»“å°¾çš„æ¨¡å‹(å¦‚ `claude-opus-4-5-thinking`ã€`claude-sonnet-4-5-thinking`),è‡ªåŠ¨æ³¨å…¥ `thinkingConfig` ç¡®ä¿æ€è€ƒå†…å®¹æ­£å¸¸è¾“å‡ºã€‚\n            - **ç»Ÿä¸€ thinking é…ç½®**: ä¸ºæ‰€æœ‰ thinking æ¨¡å‹(Gemini 3 Pro å’Œ Claude thinking ç³»åˆ—)æ³¨å…¥ç»Ÿä¸€çš„ `thinkingBudget: 16000` é…ç½®,ç¬¦åˆ Cloud Code API è§„èŒƒã€‚\n            - **å½±å“èŒƒå›´**: æ­¤ä¿®å¤ç¡®ä¿äº† Gemini 3 Pro å’Œ Claude Thinking æ¨¡å‹åœ¨ OpenAI åè®®ä¸‹çš„ `reasoning_content` å­—æ®µæ­£å¸¸å·¥ä½œ,ä¸å½±å“ Anthropic å’Œ Gemini åŸç”Ÿåè®®ã€‚\n        - **Experimental é…ç½®çƒ­æ›´æ–° (PR #605)**:\n            - **æ–°å¢çƒ­æ›´æ–°æ”¯æŒ**: ä¸º `ExperimentalConfig` æ·»åŠ çƒ­æ›´æ–°æœºåˆ¶,ä¸å…¶ä»–é…ç½®é¡¹(mappingã€proxyã€securityã€zaiã€scheduling)ä¿æŒä¸€è‡´ã€‚\n            - **å®æ—¶ç”Ÿæ•ˆ**: ç”¨æˆ·ä¿®æ”¹å®éªŒæ€§åŠŸèƒ½å¼€å…³åæ— éœ€é‡å¯åº”ç”¨å³å¯ç”Ÿæ•ˆ,æå‡é…ç½®è°ƒæ•´çš„ä¾¿æ·æ€§ã€‚\n            - **æ¶æ„å®Œå–„**: åœ¨ `AxumServer` ä¸­æ·»åŠ  `experimental` å­—æ®µå­˜å‚¨å’Œ `update_experimental()` æ›´æ–°æ–¹æ³•,åœ¨ `save_config` ä¸­è‡ªåŠ¨è§¦å‘çƒ­æ›´æ–°ã€‚\n        - **æ™ºèƒ½é¢„çƒ­ç­–ç•¥ä¼˜åŒ– (PR #606 - æ€§èƒ½æå‡ 2.9x-5x)**:\n            - **åˆ†ç¦»åˆ·æ–°å’Œé¢„çƒ­**: ç§»é™¤é…é¢åˆ·æ–°æ—¶çš„è‡ªåŠ¨é¢„çƒ­è§¦å‘,é¢„çƒ­ä»…é€šè¿‡å®šæ—¶è°ƒåº¦å™¨(æ¯10åˆ†é’Ÿ)æˆ–æ‰‹åŠ¨æŒ‰é’®è§¦å‘,é¿å…ç”¨æˆ·åˆ·æ–°é…é¢æ—¶æ„å¤–æ¶ˆè€—é¢„çƒ­é¢åº¦ã€‚\n            - **å»¶é•¿å†·å´æœŸ**: å†·å´æœŸä»30åˆ†é’Ÿå»¶é•¿è‡³4å°æ—¶(14400ç§’),åŒ¹é… Pro è´¦å·5å°æ—¶é‡ç½®å‘¨æœŸ,è§£å†³åŒä¸€å‘¨æœŸå†…é‡å¤é¢„çƒ­é—®é¢˜ã€‚\n            - **æŒä¹…åŒ–å†å²è®°å½•**: é¢„çƒ­å†å²ä¿å­˜è‡³ `~/.antigravity_tools/warmup_history.json`,ç¨‹åºé‡å¯åå†·å´æœŸä»ç„¶æœ‰æ•ˆ,è§£å†³çŠ¶æ€ä¸¢å¤±é—®é¢˜ã€‚\n            - **å¹¶å‘æ‰§è¡Œä¼˜åŒ–**: \n                - ç­›é€‰é˜¶æ®µ: æ¯æ‰¹5ä¸ªè´¦å·å¹¶å‘è·å–é…é¢,10ä¸ªè´¦å·ä»~15ç§’é™è‡³~3ç§’ (5å€æå‡)\n                - é¢„çƒ­é˜¶æ®µ: æ¯æ‰¹3ä¸ªä»»åŠ¡å¹¶å‘æ‰§è¡Œ,æ‰¹æ¬¡é—´éš”2ç§’,40ä¸ªä»»åŠ¡ä»~80ç§’é™è‡³~28ç§’ (2.9å€æå‡)\n            - **ç™½åå•è¿‡æ»¤**: ä»…è®°å½•å’Œé¢„çƒ­4ä¸ªæ ¸å¿ƒæ¨¡å‹ç»„(`gemini-3-flash`ã€`claude-sonnet-4-5`ã€`gemini-3-pro-high`ã€`gemini-3-pro-image`),é¿å…å†å²è®°å½•è‡ƒè‚¿ã€‚\n            - **æˆåŠŸåè®°å½•**: é¢„çƒ­å¤±è´¥ä¸è®°å½•å†å²,å…è®¸ä¸‹æ¬¡é‡è¯•,æé«˜å®¹é”™æ€§ã€‚\n            - **æ‰‹åŠ¨é¢„çƒ­ä¿æŠ¤**: æ‰‹åŠ¨é¢„çƒ­ä¹Ÿéµå®ˆ4å°æ—¶å†·å´æœŸ,è¿‡æ»¤å·²é¢„çƒ­æ¨¡å‹å¹¶æ˜¾ç¤ºè·³è¿‡æ•°é‡,é˜²æ­¢ç”¨æˆ·åå¤ç‚¹å‡»æµªè´¹é…é¢ã€‚\n            - **å®Œå–„æ—¥å¿—**: æ·»åŠ è°ƒåº¦å™¨æ‰«æã€é¢„çƒ­å¯åŠ¨/å®Œæˆã€å†·å´æœŸè·³è¿‡ç­‰è¯¦ç»†æ—¥å¿—,ä¾¿äºç›‘æ§å’Œè°ƒè¯•ã€‚\n            - **å½±å“èŒƒå›´**: æ­¤ä¼˜åŒ–å¤§å¹…æå‡äº†æ™ºèƒ½é¢„çƒ­çš„æ€§èƒ½å’Œå¯é æ€§,è§£å†³äº†é‡å¤é¢„çƒ­ã€é€Ÿåº¦æ…¢ã€çŠ¶æ€ä¸¢å¤±ç­‰å¤šä¸ªé—®é¢˜,å¹¶å‘çº§åˆ«ä¸ä¼šè§¦å‘ RateLimitã€‚\n        - **ç¹ä½“ä¸­æ–‡æœ¬åœ°åŒ–ä¼˜åŒ– (PR #607)**:\n            - **æœ¯è¯­ä¼˜åŒ–**: ä¼˜åŒ–100å¤„ç¹ä½“ä¸­æ–‡ç¿»è¯‘,ä½¿å…¶æ›´ç¬¦åˆå°æ¹¾åœ°åŒºç”¨æˆ·çš„è¯­è¨€ä¹ æƒ¯å’Œè¡¨è¾¾æ–¹å¼ã€‚\n            - **ç”¨æˆ·ä½“éªŒæå‡**: æå‡ç¹ä½“ä¸­æ–‡ç•Œé¢çš„ä¸“ä¸šæ€§å’Œå¯è¯»æ€§,çº¯æ–‡æœ¬å˜æ›´æ— ä»£ç é€»è¾‘å½±å“ã€‚\n        - **API ç›‘æ§æ€§èƒ½ä¼˜åŒ– (ä¿®å¤é•¿æ—¶é—´è¿è¡Œç™½å±é—®é¢˜)**:\n            - **é—®é¢˜èƒŒæ™¯**: ä¿®å¤åå°é•¿æ—¶é—´è¿è¡Œååœç•™åœ¨ API ç›‘æ§é¡µé¢å¯¼è‡´çª—å£å¡æˆç™½å±çš„é—®é¢˜,ç¨‹åºä»åœ¨è¿è¡Œä½† UI æ— å“åº”ã€‚\n            - **å†…å­˜ä¼˜åŒ–**:\n                - å‡å°‘å†…å­˜æ—¥å¿—é™åˆ¶ä» 1000 æ¡é™è‡³ 100 æ¡,å¤§å¹…é™ä½å†…å­˜å ç”¨\n                - ç§»é™¤å®æ—¶äº‹ä»¶ä¸­çš„å®Œæ•´ request/response body å­˜å‚¨,ä»…ä¿ç•™æ‘˜è¦ä¿¡æ¯\n                - åç«¯äº‹ä»¶å‘é€ä¼˜åŒ–,ä»…ä¼ è¾“æ—¥å¿—æ‘˜è¦è€Œéå®Œæ•´æ•°æ®,å‡å°‘ IPC ä¼ è¾“é‡\n            - **æ¸²æŸ“æ€§èƒ½æå‡**:\n                - é›†æˆ `@tanstack/react-virtual` è™šæ‹Ÿæ»šåŠ¨åº“,ä»…æ¸²æŸ“å¯è§è¡Œ(çº¦ 20-30 è¡Œ)\n                - DOM èŠ‚ç‚¹æ•°é‡ä» 1000+ é™è‡³ 20-30,å‡å°‘ 97%\n                - æ»šåŠ¨å¸§ç‡ä» 20-30fps æå‡è‡³ 60fps\n            - **é˜²æŠ–æœºåˆ¶**:\n                - æ·»åŠ  500ms é˜²æŠ–æœºåˆ¶,æ‰¹é‡å¤„ç†æ—¥å¿—æ›´æ–°,é¿å…é¢‘ç¹çŠ¶æ€æ›´æ–°\n                - å‡å°‘ React re-render æ¬¡æ•°,æå‡ UI å“åº”æ€§\n            - **æ€§èƒ½æå‡**:\n                - å†…å­˜å ç”¨: ~500MB â†’ <100MB (å‡å°‘ 90%)\n                - é¦–æ¬¡æ¸²æŸ“æ—¶é—´: ~2000ms â†’ <100ms (æå‡ 20 å€)\n                - æ”¯æŒæ— é™æ—¥å¿—æ»šåŠ¨,é•¿æ—¶é—´è¿è¡Œæ— ç™½å±\n            - **å½±å“èŒƒå›´**: æ­¤ä¼˜åŒ–è§£å†³äº†é•¿æ—¶é—´è¿è¡Œå’Œå¤§é‡æ—¥å¿—åœºæ™¯ä¸‹çš„æ€§èƒ½é—®é¢˜,å³ä½¿åœç•™åœ¨ç›‘æ§é¡µé¢æ•°å°æ—¶ä¹Ÿèƒ½ä¿æŒæµç•…ã€‚\n    *   **v3.3.27 (2026-01-13)**:\n        - **å®éªŒæ€§é…ç½®ä¸ç”¨é‡ç¼©æ”¾ (PR #603 å¢å¼º)**:\n            - **æ–°å¢å®éªŒæ€§è®¾ç½®é¢æ¿**: åœ¨ API åä»£é…ç½®ä¸­å¢åŠ äº†â€œå®éªŒæ€§è®¾ç½®â€å¡ç‰‡ï¼Œç”¨äºç®¡ç†æ­£åœ¨æ¢ç´¢ä¸­çš„åŠŸèƒ½ã€‚\n            - **å¯ç”¨ç”¨é‡ç¼©æ”¾ (Usage Scaling)**: é’ˆå¯¹ Claude ç›¸å®¹åè®®å®ç°äº†æ¿€è¿›çš„è¾“å…¥ Token è‡ªåŠ¨ç¼©æ”¾é€»è¾‘ã€‚å½“æ€»è¾“å…¥è¶…è¿‡ 30k æ—¶ï¼Œè‡ªåŠ¨åº”ç”¨å¹³æ–¹æ ¹ç¼©æ”¾ï¼Œæœ‰æ•ˆé˜²æ­¢é•¿ä¸Šä¸‹æ–‡åœºæ™¯ä¸‹ï¼ˆå¦‚ Gemini 2M çª—å£ï¼‰é¢‘ç¹è§¦å‘å®¢æˆ·ç«¯ä¾§çš„å¼ºåˆ¶å‹ç¼©ã€‚\n            - **å¤šè¯­è¨€ç¿»è¯‘è¡¥å…¨**: ä¸ºå®éªŒæ€§åŠŸèƒ½åŒæ­¥è¡¥å…¨äº†ä¸­ã€è‹±ã€æ—¥ã€ç¹ã€åœŸã€è¶Š 6 ç§è¯­è¨€çš„ç¿»è¯‘ã€‚\n    *   **v3.3.26 (2026-01-13)**:\n        - **é…é¢ä¿æŠ¤ä¸è°ƒåº¦ä¼˜åŒ– (Fix Issue #595 - é›¶é…é¢è´¦æˆ·ä»è¿›å…¥é˜Ÿåˆ—)**:\n            - **é…é¢ä¿æŠ¤é€»è¾‘é‡æ„**: ä¿®å¤äº†é…é¢ä¿æŠ¤å› ä¾èµ–ä¸å­˜åœ¨çš„ `limit/remaining` å­—æ®µè€Œå¤±æ•ˆçš„é—®é¢˜ã€‚ç°åœ¨ç›´æ¥ä½¿ç”¨æ¨¡å‹æ•°æ®ä¸­å§‹ç»ˆå­˜åœ¨çš„ `percentage` å­—æ®µï¼Œç¡®ä¿ä»»ä½•å—ç›‘æ§æ¨¡å‹ï¼ˆå¦‚ Claude 4.5 Sonnetï¼‰é…é¢ä½äºé˜ˆå€¼æ—¶ï¼Œè´¦å·éƒ½èƒ½è¢«ç«‹å³ç¦ç”¨ã€‚\n            - **è´¦å·ä¼˜å…ˆçº§ç®—æ³•å‡çº§**: è´¦å·è°ƒåº¦ä¼˜å…ˆçº§ä¸å†ä»…ä¾èµ–è®¢é˜…ç­‰çº§ã€‚åœ¨åŒç­‰çº§ï¼ˆUltra/Pro/Freeï¼‰å†…ï¼Œç³»ç»Ÿç°åœ¨ä¼šä¼˜å…ˆé€‰æ‹©**æœ€å¤§æ¨¡å‹å‰©ä½™ç™¾åˆ†æ¯”**æœ€é«˜çš„è´¦å·ï¼Œé¿å…å¯¹æ¿’ä¸´è€—å°½çš„è´¦å·è¿›è¡Œâ€œå‹æ¦¨â€ï¼Œæ˜¾è‘—é™ä½ 429 é”™è¯¯ç‡ã€‚\n            - **ä¿æŠ¤æ—¥å¿—å¢å¼º**: è§¦å‘é…é¢ä¿æŠ¤æ—¶çš„æ—¥å¿—ç°åœ¨ä¼šæ˜ç¡®æŒ‡å‡ºå…·ä½“æ˜¯å“ªä¸ªæ¨¡å‹è§¦å‘äº†é˜ˆå€¼ï¼ˆä¾‹å¦‚ï¼š`quota_protection: claude-sonnet-4-5 (0% <= 10%)`ï¼‰ï¼Œä¾¿äºæ’æŸ¥ã€‚\n        - **MCP å·¥å…·å…¼å®¹æ€§å¢å¼º (Fix Issue #593)**:\n            - **æ·±åº¦ cache_control æ¸…ç†**: å®ç°äº†å¤šå±‚æ¬¡çš„ `cache_control` å­—æ®µæ¸…ç†æœºåˆ¶,è§£å†³ Chrome Dev Tools MCP ç­‰å·¥å…·åœ¨ thinking block ä¸­åŒ…å« `cache_control` å¯¼è‡´çš„ \"Extra inputs are not permitted\" é”™è¯¯ã€‚\n                - **å¢å¼ºæ—¥å¿—è¿½è¸ª**: æ·»åŠ  `[DEBUG-593]` æ—¥å¿—å‰ç¼€,è®°å½•æ¶ˆæ¯ç´¢å¼•å’Œå—ç´¢å¼•,ä¾¿äºé—®é¢˜å®šä½å’Œè°ƒè¯•ã€‚\n                - **é€’å½’æ·±åº¦æ¸…ç†**: æ–°å¢ `deep_clean_cache_control()` å‡½æ•°,é€’å½’éå†æ‰€æœ‰åµŒå¥—å¯¹è±¡å’Œæ•°ç»„,ç§»é™¤ä»»ä½•ä½ç½®çš„ `cache_control` å­—æ®µã€‚\n                - **æœ€åä¸€é“é˜²çº¿**: åœ¨æ„å»º Gemini è¯·æ±‚ä½“åã€å‘é€å‰å†æ¬¡æ‰§è¡Œæ·±åº¦æ¸…ç†,ç¡®ä¿å‘é€ç»™ Antigravity çš„è¯·æ±‚ä¸­ä¸åŒ…å«ä»»ä½• `cache_control`ã€‚\n            - **å·¥å…·è¾“å‡ºæ™ºèƒ½å‹ç¼©**: æ–°å¢ `tool_result_compressor` æ¨¡å—,å¤„ç†è¶…å¤§å·¥å…·è¾“å‡º,é™ä½ prompt è¶…é•¿å¯¼è‡´çš„ 429 é”™è¯¯æ¦‚ç‡ã€‚\n                - **æµè§ˆå™¨å¿«ç…§å‹ç¼©**: è‡ªåŠ¨æ£€æµ‹å¹¶å‹ç¼©è¶…è¿‡ 20,000 å­—ç¬¦çš„æµè§ˆå™¨å¿«ç…§,é‡‡ç”¨å¤´éƒ¨(70%) + å°¾éƒ¨(30%)ä¿ç•™ç­–ç•¥,ä¸­é—´çœç•¥ã€‚\n                - **å¤§æ–‡ä»¶æç¤ºå‹ç¼©**: æ™ºèƒ½è¯†åˆ« \"exceeds maximum allowed tokens\" æ¨¡å¼,æå–å…³é”®ä¿¡æ¯(æ–‡ä»¶è·¯å¾„ã€å­—ç¬¦æ•°ã€æ ¼å¼è¯´æ˜),å¤§å¹…å‡å°‘å†—ä½™å†…å®¹ã€‚\n                - **é€šç”¨æˆªæ–­**: å¯¹è¶…è¿‡ 200,000 å­—ç¬¦çš„å·¥å…·è¾“å‡ºè¿›è¡Œæˆªæ–­,æ·»åŠ æ¸…æ™°çš„æˆªæ–­æç¤ºã€‚\n                - **Base64 å›¾ç‰‡ç§»é™¤**: è‡ªåŠ¨ç§»é™¤å·¥å…·ç»“æœä¸­çš„ base64 ç¼–ç å›¾ç‰‡,é¿å…ä½“ç§¯è¿‡å¤§ã€‚\n            - **å®Œæ•´æµ‹è¯•è¦†ç›–**: æ–°å¢ 7 ä¸ªå•å…ƒæµ‹è¯•,è¦†ç›–æ–‡æœ¬æˆªæ–­ã€æµè§ˆå™¨å¿«ç…§å‹ç¼©ã€å¤§æ–‡ä»¶æç¤ºå‹ç¼©ã€å·¥å…·ç»“æœæ¸…ç†ç­‰æ ¸å¿ƒåŠŸèƒ½,å…¨éƒ¨é€šè¿‡éªŒè¯ã€‚\n            - **å½±å“èŒƒå›´**: æ­¤æ›´æ–°æ˜¾è‘—æå‡äº† MCP å·¥å…·(ç‰¹åˆ«æ˜¯ Chrome Dev Tools MCP)çš„ç¨³å®šæ€§,è§£å†³äº† thinking block ä¸­ `cache_control` å­—æ®µå¯¼è‡´çš„ API é”™è¯¯,åŒæ—¶é€šè¿‡æ™ºèƒ½å‹ç¼©é™ä½äº†è¶…å¤§å·¥å…·è¾“å‡ºå¯¼è‡´çš„ 429 é”™è¯¯æ¦‚ç‡ã€‚\n        - **API ç›‘æ§è´¦å·ä¿¡æ¯è®°å½•ä¿®å¤**:\n            - **ä¿®å¤å›¾ç‰‡ç”Ÿæˆç«¯ç‚¹**: ä¿®å¤äº† `/v1/images/generations` ç«¯ç‚¹ç¼ºå°‘ `X-Account-Email` å“åº”å¤´çš„é—®é¢˜,ç°åœ¨ç›‘æ§é¢æ¿èƒ½æ­£ç¡®æ˜¾ç¤ºå¤„ç†å›¾ç‰‡ç”Ÿæˆè¯·æ±‚çš„è´¦å·ä¿¡æ¯ã€‚\n            - **ä¿®å¤å›¾ç‰‡ç¼–è¾‘ç«¯ç‚¹**: ä¿®å¤äº† `/v1/images/edits` ç«¯ç‚¹ç¼ºå°‘ `X-Account-Email` å“åº”å¤´çš„é—®é¢˜,ç¡®ä¿å›¾ç‰‡ç¼–è¾‘è¯·æ±‚çš„è´¦å·ä¿¡æ¯èƒ½è¢«æ­£ç¡®è®°å½•ã€‚\n            - **ä¿®å¤éŸ³é¢‘è½¬å½•ç«¯ç‚¹**: ä¿®å¤äº† `/v1/audio/transcriptions` ç«¯ç‚¹ç¼ºå°‘ `X-Account-Email` å“åº”å¤´çš„é—®é¢˜,å®Œå–„äº†éŸ³é¢‘è½¬å½•åŠŸèƒ½çš„ç›‘æ§æ”¯æŒã€‚\n            - **å½±å“èŒƒå›´**: æ­¤ä¿®å¤ç¡®ä¿äº†æ‰€æœ‰æ¶‰åŠè´¦å·è°ƒç”¨çš„ API ç«¯ç‚¹éƒ½èƒ½åœ¨ç›‘æ§é¢æ¿ä¸­æ­£ç¡®æ˜¾ç¤ºè´¦å·ä¿¡æ¯,ä¸å†æ˜¾ç¤ºä¸º\"-\",æå‡äº† API ç›‘æ§ç³»ç»Ÿçš„å®Œæ•´æ€§å’Œå¯ç”¨æ€§ã€‚\n        - **æ— å¤´æœåŠ¡å™¨éƒ¨ç½²æ”¯æŒ (Headless Server Support)**:\n            - **ä¸€é”®éƒ¨ç½²è„šæœ¬**: æ–°å¢ `deploy/headless-xvfb/` ç›®å½•,æä¾›é’ˆå¯¹ Linux æ— ç•Œé¢æœåŠ¡å™¨çš„ä¸€é”®å®‰è£…ã€åŒæ­¥ã€å‡çº§è„šæœ¬ã€‚\n            - **Xvfb ç¯å¢ƒé€‚é…**: åˆ©ç”¨è™šæ‹Ÿæ˜¾ç¤ºå™¨æŠ€æœ¯,å…è®¸ GUI ç‰ˆæœ¬çš„ Antigravity Tools åœ¨æ— æ˜¾å¡çš„è¿œç¨‹æœåŠ¡å™¨ä¸Šè¿è¡Œ,å¹¶æä¾›äº†è¯¦ç»†çš„èµ„æºå ç”¨é¢„è­¦å’Œå±€é™æ€§è¯´æ˜ã€‚\n    *   **v3.3.25 (2026-01-13)**:\n        - **ä¼šè¯ç­¾åç¼“å­˜ç³»ç»Ÿ (Session-Based Signature Caching) - æå‡ Thinking æ¨¡å‹ç¨³å®šæ€§ (æ ¸å¿ƒè‡´è°¢ @Gok-tug PR #574)**:\n            - **ä¸‰å±‚ç­¾åç¼“å­˜æ¶æ„**: å®ç°äº† Tool Signatures (Layer 1)ã€Thinking Families (Layer 2) å’Œ Session Signatures (Layer 3) çš„å®Œæ•´ä¸‰å±‚ç¼“å­˜ä½“ç³»ã€‚\n            - **ä¼šè¯éš”ç¦»æœºåˆ¶**: åŸºäºç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯çš„ SHA256 å“ˆå¸Œç”Ÿæˆç¨³å®šçš„ session_id,ç¡®ä¿åŒä¸€å¯¹è¯çš„æ‰€æœ‰è½®æ¬¡ä½¿ç”¨ç›¸åŒçš„ä¼šè¯æ ‡è¯†ã€‚\n            - **æ™ºèƒ½ç­¾åæ¢å¤**: åœ¨å·¥å…·è°ƒç”¨å’Œå¤šè½®å¯¹è¯ä¸­è‡ªåŠ¨æ¢å¤æ€è€ƒç­¾å,æ˜¾è‘—å‡å°‘ thinking æ¨¡å‹çš„ç­¾åç›¸å…³é”™è¯¯ã€‚\n            - **ä¼˜å…ˆçº§æŸ¥æ‰¾ç­–ç•¥**: å®ç° Session Cache â†’ Tool Cache â†’ Global Store çš„ä¸‰å±‚æŸ¥æ‰¾ä¼˜å…ˆçº§,æœ€å¤§åŒ–ç­¾åæ¢å¤æˆåŠŸç‡ã€‚\n        - **Session ID ç”Ÿæˆä¼˜åŒ–**:\n            - **ç®€æ´è®¾è®¡**: åªå“ˆå¸Œç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯å†…å®¹,ä¸æ··å…¥æ¨¡å‹åç§°æˆ–æ—¶é—´æˆ³,ç¡®ä¿ä¼šè¯å»¶ç»­æ€§ã€‚\n            - **å®Œç¾å»¶ç»­æ€§**: åŒä¸€å¯¹è¯çš„æ‰€æœ‰è½®æ¬¡(æ— è®ºå¤šå°‘è½®)éƒ½ä½¿ç”¨ç›¸åŒçš„ session_id,æ— æ—¶é—´é™åˆ¶ã€‚\n            - **æ€§èƒ½æå‡**: ç›¸æ¯”ä¹‹å‰çš„æ–¹æ¡ˆ,CPU å¼€é”€é™ä½ 60%,ä»£ç è¡Œæ•°å‡å°‘ 20%ã€‚\n        - **ç¼“å­˜ç®¡ç†ä¼˜åŒ–**:\n            - **åˆ†å±‚é˜ˆå€¼**: ä¸ºä¸åŒå±‚çº§è®¾ç½®åˆç†çš„ç¼“å­˜æ¸…ç†é˜ˆå€¼ (Tool: 500, Family: 200, Session: 1000)ã€‚\n            - **æ™ºèƒ½æ¸…ç†**: æ·»åŠ è¯¦ç»†çš„ç¼“å­˜æ¸…ç†æ—¥å¿—,ä¾¿äºç›‘æ§å’Œè°ƒè¯•ã€‚\n        - **ç¼–è¯‘é”™è¯¯ä¿®å¤**:\n            - ä¿®å¤ `process.rs` ä¸­çš„å‚æ•°å‘½åå’Œå¯å˜æ€§é—®é¢˜ã€‚\n            - æ¸…ç†æœªä½¿ç”¨çš„å¯¼å…¥å’Œå˜é‡è­¦å‘Šã€‚\n        - **å›½é™…åŒ– (i18n)**:\n            - **ç¹ä½“ä¸­æ–‡æ”¯æŒ**: æ–°å¢ç¹ä½“ä¸­æ–‡ (Traditional Chinese) æœ¬åœ°åŒ–æ”¯æŒ (Thank you @audichuang PR #577)ã€‚\n        - **æµå¼å“åº”é”™è¯¯å¤„ç†æ”¹è¿› (Stream Error Handling Improvements)**:\n            - **å‹å¥½é”™è¯¯æç¤º**: ä¿®å¤äº† Issue #579 ä¸­æåˆ°çš„æµå¼é”™è¯¯å¯¼è‡´ 200 OK ä¸”æ— æç¤ºçš„é—®é¢˜ã€‚ç°åœ¨å°†æŠ€æœ¯æ€§é”™è¯¯ (Timeout, Decode, Connection) è½¬æ¢ä¸ºç”¨æˆ·å‹å¥½çš„ä¸­æ–‡æç¤ºã€‚\n            - **SSE é”™è¯¯äº‹ä»¶**: å®ç°äº†æ ‡å‡†çš„ SSE é”™è¯¯äº‹ä»¶ä¼ æ’­,å‰ç«¯å¯æ•è·å¹¶ä¼˜é›…å±•ç¤ºé”™è¯¯,åŒ…å«è¯¦ç»†çš„è§£å†³å»ºè®®(å¦‚æ£€æŸ¥ç½‘ç»œã€ä»£ç†ç­‰)ã€‚\n            - **å¤šè¯­è¨€é”™è¯¯æ¶ˆæ¯ (i18n)**: é”™è¯¯æ¶ˆæ¯å·²é›†æˆ i18n ç³»ç»Ÿ,æ”¯æŒæ‰€æœ‰ 6 ç§è¯­è¨€(zh, en, zh-TW, ja, tr, vi)ã€‚éæµè§ˆå™¨å®¢æˆ·ç«¯è‡ªåŠ¨å›é€€åˆ°è‹±æ–‡æç¤ºã€‚\n        - **å½±å“èŒƒå›´**: æ­¤æ›´æ–°æ˜¾è‘—æå‡äº† Claude 4.5 Opusã€Gemini 3 Pro ç­‰ thinking æ¨¡å‹çš„å¤šè½®å¯¹è¯ç¨³å®šæ€§,ç‰¹åˆ«æ˜¯åœ¨ä½¿ç”¨ MCP å·¥å…·å’Œé•¿ä¼šè¯åœºæ™¯ä¸‹ã€‚\n    <details>\n    <summary>æ˜¾ç¤ºæ—§ç‰ˆæœ¬æ—¥å¿— (v3.3.24 åŠæ›´æ—©)</summary>\n\n    *   **v3.3.24 (2026-01-12)**:\n        - **UI äº¤äº’æ”¹è¿› (UI Interaction Improvements)**:\n            - **å¡ç‰‡å¼æ¨¡å‹é€‰æ‹©**: è®¾ç½®é¡µé¢çš„â€œé…é¢ä¿æŠ¤â€ä¸â€œæ™ºèƒ½é¢„çƒ­â€æ¨¡å‹é€‰æ‹©å‡çº§ä¸ºå¡ç‰‡å¼è®¾è®¡ï¼Œæ”¯æŒé€‰ä¸­çŠ¶æ€å‹¾é€‰åŠæœªé€‰ä¸­çŠ¶æ€ä¸‹æ˜¾çœ¼çš„è¾¹ç¼˜æç¤ºã€‚\n            - **å¸ƒå±€ä¼˜åŒ–**: â€œæ™ºèƒ½é¢„çƒ­â€æ¨¡å‹åˆ—è¡¨ç”±å•è¡Œ 2 åˆ—è°ƒæ•´ä¸ºå•è¡Œ 4 åˆ—å¸ƒå±€ï¼Œæ›´åŠ èŠ‚çœç©ºé—´ã€‚\n            - **åç§°ä¿®æ­£**: å°† `claude-sonnet-4-5` é”™è¯¯æ˜¾ç¤ºçš„åç§°ç”± \"Claude 3.5 Sonnet\" ä¿®æ­£ä¸º \"Claude 4.5 Sonnet\"ã€‚\n        - **å›½é™…åŒ– (i18n)**:\n            - **è¶Šå—è¯­æ”¯æŒ**: æ–°å¢è¶Šå—è¯­ (Vietnamese) æœ¬åœ°åŒ–æ”¯æŒ (Thank you @ThanhNguyxn PR #570)ã€‚\n            - **ç¿»è¯‘ä¼˜åŒ–**: æ¸…ç†äº†é‡å¤çš„ç¿»è¯‘é”®å€¼ï¼Œå¹¶ä¼˜åŒ–äº†è¯­è¨€è‡ªåŠ¨æ£€æµ‹é€»è¾‘ã€‚\n    *   **v3.3.23 (2026-01-12)**:\n        - **æ›´æ–°é€šçŸ¥ UI é‡æ„ (Update Notification UI Modernization)**:\n            - **è§†è§‰å‡çº§**: é‡‡ç”¨ \"Glassmorphism\" æ¯›ç»ç’ƒé£æ ¼è®¾è®¡ï¼Œé…åˆä¼˜é›…çš„æ¸å˜èƒŒæ™¯ä¸å¾®å…‰æ•ˆæœï¼Œå¤§å¹…æå‡è§†è§‰ç²¾è‡´åº¦ã€‚\n            - **æµç•…åŠ¨æ•ˆ**: å¼•å…¥äº†æ›´å¹³æ»‘çš„å¼¹çª—å…¥åœºä¸é€€å‡ºåŠ¨ç”»ï¼Œä¼˜åŒ–äº†äº¤äº’ä½“éªŒã€‚\n            - **æ·±è‰²æ¨¡å¼é€‚é…**: å®Œç¾æ”¯æŒæ·±è‰²æ¨¡å¼ (Dark Mode)ï¼Œè‡ªåŠ¨è·Ÿéšç³»ç»Ÿä¸»é¢˜åˆ‡æ¢ï¼Œç¡®ä¿åœ¨ä»»ä½•ç¯å¢ƒä¸‹éƒ½ä¸åˆºçœ¼ã€‚\n            - **éä¾µå…¥å¼å¸ƒå±€**: ä¼˜åŒ–äº†å¼¹çª—ä½ç½®ä¸å±‚çº§ï¼Œç¡®ä¿ä¸ä¼šé®æŒ¡é¡¶éƒ¨å¯¼èˆªæ ç­‰å…³é”®æ“ä½œåŒºåŸŸã€‚\n        - **å›½é™…åŒ–æ”¯æŒ (Internationalization)**:\n            - **åŒè¯­é€‚é…**: æ›´æ–°é€šçŸ¥ç°å·²å®Œæ•´æ”¯æŒä¸­è‹±åŒè¯­ï¼Œæ ¹æ®åº”ç”¨è¯­è¨€è®¾ç½®è‡ªåŠ¨åˆ‡æ¢æ–‡æ¡ˆã€‚\n        - **æ£€æŸ¥é€»è¾‘ä¿®æ­£**: ä¿®å¤äº†æ›´æ–°æ£€æŸ¥çŠ¶æ€æ›´æ–°çš„æ—¶åºé—®é¢˜ï¼Œç¡®ä¿åœ¨å‘ç°æ–°ç‰ˆæœ¬æ—¶èƒ½ç¨³å®šå¼¹å‡ºé€šçŸ¥ã€‚\n        - **èœå•æ å›¾æ ‡é«˜æ¸…åŒ–ä¿®å¤ (Menu Bar Icon Resolution Fix)**:\n            - **Retina é€‚é…**: å°†èœå•æ æ‰˜ç›˜å›¾æ ‡ (`tray-icon.png`) åˆ†è¾¨ç‡ä» 22x22 æå‡è‡³ 44x44ï¼Œè§£å†³äº†åœ¨é«˜åˆ†å±ä¸‹æ˜¾ç¤ºæ¨¡ç³Šçš„é—®é¢˜ (Fix Issue #557)ã€‚\n        - **Claude Thinking å‹ç¼©ä¼˜åŒ– (æ ¸å¿ƒè‡´è°¢ @ThanhNguyxn PR #566)**:\n            - **ä¿®å¤æ€è€ƒå—ä¹±åº**: è§£å†³äº†åœ¨ä½¿ç”¨ Context Compression (Kilo) æ—¶ï¼Œæ€è€ƒå— (Thinking Blocks) å¯èƒ½è¢«é”™è¯¯åœ°æ’åºåˆ°æ–‡æœ¬å—ä¹‹åçš„é—®é¢˜ã€‚\n            - **å¼ºåˆ¶é¦–ä½æ’åº**: å¼•å…¥äº† `sort_thinking_blocks_first` é€»è¾‘ï¼Œç¡®ä¿åŠ©æ‰‹æ¶ˆæ¯ä¸­çš„æ€è€ƒå—å§‹ç»ˆä½äºæœ€å‰ï¼Œç¬¦åˆ Anthropic API çš„ 400 æ ¡éªŒè§„åˆ™ã€‚\n        - **è´¦å·è·¯ç”±ä¼˜å…ˆçº§å¢å¼º (æ ¸å¿ƒè‡´è°¢ @ThanhNguyxn PR #567)**:\n            - **é«˜é…é¢ä¼˜å…ˆç­–ç•¥**: åœ¨åŒç­‰çº§åˆ« (Free/Pro/Ultra) ä¸‹ï¼Œç³»ç»Ÿç°åœ¨ä¼šä¼˜å…ˆé€‰æ‹©**å‰©ä½™é…é¢æ›´å¤š**çš„è´¦å·è¿›è¡Œè°ƒåº¦ã€‚\n            - **é¿å…æœ¨æ¡¶æ•ˆåº”**: é˜²æ­¢å› éšæœºåˆ†é…å¯¼è‡´æŸäº›é•¿é…é¢è´¦å·è¢«é—²ç½®ï¼Œè€ŒçŸ­é…é¢è´¦å·è¿‡æ—©è€—å°½ã€‚\n        - **éæµå¼å“åº” Base64 ç­¾åä¿®å¤ (æ ¸å¿ƒè‡´è°¢ @ThanhNguyxn PR #568)**:\n            - **å…¨æ¨¡å¼å…¼å®¹**: å°†æµå¼å“åº”ä¸­çš„ Base64 æ€è€ƒç­¾åè§£ç é€»è¾‘åŒæ­¥åº”ç”¨åˆ°éæµå¼å“åº” (Non-streaming) ä¸­ã€‚\n            - **æ¶ˆé™¤ç­¾åé”™è¯¯**: è§£å†³äº†åœ¨éæµå¼å®¢æˆ·ç«¯ (å¦‚ Python SDK) ä¸­ä½¿ç”¨ Antigravity ä»£ç†æ—¶å› ç­¾åç¼–ç æ ¼å¼ä¸ä¸€è‡´å¯¼è‡´çš„ 400 é”™è¯¯ã€‚\n        - **å›½é™…åŒ– (i18n)**:\n            - **æ—¥è¯­æ”¯æŒ**: æ–°å¢æ—¥è¯­ (Japanese) æœ¬åœ°åŒ–æ”¯æŒ (Thank you @Koshikai PR #526)ã€‚\n            - **åœŸè€³å…¶è¯­æ”¯æŒ**: æ–°å¢åœŸè€³å…¶è¯­ (Turkish) æœ¬åœ°åŒ–æ”¯æŒ (Thank you @hakanyalitekin PR #515)ã€‚\n    *   **v3.3.22 (2026-01-12)**:\n        - **é…é¢ä¿æŠ¤ç³»ç»Ÿå‡çº§**:\n            - æ”¯æŒè‡ªå®šä¹‰ç›‘æ§æ¨¡å‹ï¼ˆ`gemini-3-flash`, `gemini-3-pro-high`, `claude-sonnet-4-5`ï¼‰ï¼Œä»…åœ¨é€‰ä¸­æ¨¡å‹é¢åº¦ä½äºé˜ˆå€¼æ—¶è§¦å‘ä¿æŠ¤\n            - ä¿æŠ¤é€»è¾‘ä¼˜åŒ–ä¸º\"å‹¾é€‰æ¨¡å‹æœ€å°é…é¢\"è§¦å‘æœºåˆ¶\n            - å¼€å¯ä¿æŠ¤æ—¶é»˜è®¤å‹¾é€‰ `claude-sonnet-4-5`ï¼ŒUI å¼ºåˆ¶è‡³å°‘ä¿ç•™ä¸€ä¸ªæ¨¡å‹\n        - **å…¨è‡ªåŠ¨é…é¢ç®¡ç†è”åŠ¨**:\n            - å¼ºåˆ¶å¼€å¯åå°è‡ªåŠ¨åˆ·æ–°ï¼Œç¡®ä¿é…é¢æ•°æ®å®æ—¶åŒæ­¥\n            - è‡ªåŠ¨æ‰§è¡Œ\"åˆ·æ–° â†’ ä¿æŠ¤ â†’ æ¢å¤ â†’ é¢„çƒ­\"å®Œæ•´ç”Ÿå‘½å‘¨æœŸç®¡ç†\n        - **æ™ºèƒ½é¢„çƒ­è‡ªå®šä¹‰å‹¾é€‰**:\n            - æ”¯æŒè‡ªå®šä¹‰é¢„çƒ­æ¨¡å‹ï¼ˆ`gemini-3-flash`, `gemini-3-pro-high`, `claude-sonnet-4-5`, `gemini-3-pro-image`ï¼‰\n            - æ–°å¢ç‹¬ç«‹ `SmartWarmup.tsx` ç»„ä»¶ï¼Œæä¾›ä¸é…é¢ä¿æŠ¤ä¸€è‡´çš„å‹¾é€‰ä½“éªŒ\n            - å¼€å¯é¢„çƒ­æ—¶é»˜è®¤å‹¾é€‰æ‰€æœ‰æ ¸å¿ƒæ¨¡å‹ï¼ŒUI å¼ºåˆ¶è‡³å°‘ä¿ç•™ä¸€ä¸ªæ¨¡å‹\n            - è°ƒåº¦å™¨å®æ—¶è¯»å–é…ç½®ï¼Œä¿®æ”¹ç«‹å³ç”Ÿæ•ˆ\n        - **æ™ºèƒ½é¢„çƒ­ç³»ç»ŸåŸºç¡€åŠŸèƒ½**:\n            - é¢åº¦æ¢å¤åˆ° 100% æ—¶è‡ªåŠ¨è§¦å‘é¢„çƒ­\n            - æ™ºèƒ½å»é‡æœºåˆ¶ï¼šåŒä¸€ 100% å‘¨æœŸä»…é¢„çƒ­ä¸€æ¬¡\n            - è°ƒåº¦å™¨æ¯ 10 åˆ†é’Ÿæ‰«æå¹¶åŒæ­¥æœ€æ–°é…é¢åˆ°å‰ç«¯\n            - è¦†ç›–æ‰€æœ‰è´¦å·ç±»å‹ï¼ˆUltra/Pro/Freeï¼‰\n        - **å›½é™…åŒ–å®Œå–„**: ä¿®å¤\"è‡ªåŠ¨æ£€æŸ¥æ›´æ–°\"å’Œ\"è®¾å¤‡æŒ‡çº¹\"ç›¸å…³ç¿»è¯‘ç¼ºå¤±ï¼ˆIssue #550ï¼‰\n        - **ç¨³å®šæ€§ä¿®å¤**: ä¿®å¤é«˜å¹¶å‘è°ƒåº¦ä¸‹çš„å˜é‡å¼•ç”¨å’Œæ‰€æœ‰æƒå†²çªé—®é¢˜\n        - **API ç›‘æ§æ€§èƒ½ä¼˜åŒ– (ä¿®å¤ Issue #560)**:\n            - **é—®é¢˜èƒŒæ™¯**: ä¿®å¤ macOS ä¸Šæ‰“å¼€ API ç›‘æ§ç•Œé¢æ—¶å‡ºç° 5-10 ç§’å“åº”å»¶è¿Ÿå’Œåº”ç”¨å´©æºƒé—®é¢˜\n            - **æ•°æ®åº“ä¼˜åŒ–**:\n                - æ–°å¢ `status` å­—æ®µç´¢å¼•ï¼Œç»Ÿè®¡æŸ¥è¯¢æ€§èƒ½æå‡ 50 å€\n                - ä¼˜åŒ– `get_stats()` æŸ¥è¯¢ï¼Œä» 3 æ¬¡å…¨è¡¨æ‰«æåˆå¹¶ä¸º 1 æ¬¡ï¼ŒæŸ¥è¯¢æ—¶é—´å‡å°‘ 66%\n            - **åˆ†é¡µåŠ è½½**:\n                - åˆ—è¡¨è§†å›¾ä¸å†æŸ¥è¯¢å¤§å‹ `request_body` å’Œ `response_body` å­—æ®µï¼Œæ•°æ®ä¼ è¾“é‡å‡å°‘ 90%+\n                - æ–°å¢ `get_proxy_logs_paginated` å‘½ä»¤ï¼Œæ”¯æŒåˆ†é¡µæŸ¥è¯¢ï¼ˆæ¯é¡µ 20 æ¡ï¼‰\n                - å‰ç«¯æ–°å¢\"åŠ è½½æ›´å¤š\"æŒ‰é’®ï¼Œæ”¯æŒæŒ‰éœ€åŠ è½½å†å²è®°å½•\n            - **æŒ‰éœ€è¯¦æƒ…æŸ¥è¯¢**:\n                - æ–°å¢ `get_proxy_log_detail` å‘½ä»¤ï¼Œç‚¹å‡»æ—¥å¿—æ—¶æ‰æŸ¥è¯¢å®Œæ•´è¯¦æƒ…\n                - è¯¦æƒ…åŠ è½½æ—¶é—´ 0.1-0.5 ç§’ï¼Œé¿å…ä¸å¿…è¦çš„æ•°æ®ä¼ è¾“\n            - **è‡ªåŠ¨æ¸…ç†åŠŸèƒ½**:\n                - åº”ç”¨å¯åŠ¨æ—¶è‡ªåŠ¨æ¸…ç† 30 å¤©å‰çš„æ—§æ—¥å¿—ï¼Œé˜²æ­¢æ•°æ®åº“æ— é™å¢é•¿\n                - æ‰§è¡Œ VACUUM é‡Šæ”¾ç£ç›˜ç©ºé—´\n            - **UI ä¼˜åŒ–**:\n                - æ–°å¢åŠ è½½çŠ¶æ€æŒ‡ç¤ºå™¨ï¼Œæä¾›æ¸…æ™°çš„è§†è§‰åé¦ˆ\n                - æ–°å¢ 10 ç§’è¶…æ—¶æ§åˆ¶ï¼Œé˜²æ­¢é•¿æ—¶é—´æ— å“åº”\n                - è¯¦æƒ…æ¨¡æ€æ¡†æ–°å¢åŠ è½½æŒ‡ç¤ºå™¨\n            - **æ€§èƒ½æå‡**:\n                - åˆå§‹åŠ è½½æ—¶é—´: 10-18 ç§’ â†’ **0.5-1 ç§’** (10-36 å€æå‡)\n                - å†…å­˜å ç”¨: 1GB â†’ **5MB** (200 å€å‡å°‘)\n                - æ•°æ®ä¼ è¾“é‡: 1-10GB â†’ **1-5MB** (200-2000 å€å‡å°‘)\n            - **å½±å“èŒƒå›´**: æ­¤ä¼˜åŒ–è§£å†³äº†å¤§æ•°æ®é‡åœºæ™¯ä¸‹çš„æ€§èƒ½é—®é¢˜ï¼Œæ”¯æŒ 10,000+ æ¡ç›‘æ§è®°å½•çš„æµç•…æŸ¥çœ‹\n        - **åä»£æ—¥å¿—å¢å¼º**: ä¿®æ­£äº†åä»£æ¸©è¡¥é€»è¾‘ä¸­è´¦å·/æ¨¡å‹æ—¥å¿—è®°å½•é—®é¢˜ï¼Œè¡¥å……äº†éƒ¨åˆ†ç¼ºå¤±çš„å›½é™…åŒ–ç¿»è¯‘é¡¹ã€‚\n    *   **v3.3.21 (2026-01-11)**:\n        - **è®¾å¤‡æŒ‡çº¹ç»‘å®šç³»ç»Ÿ (Device Fingerprint Binding) - é™ä½é£æ§æ£€æµ‹ (æ ¸å¿ƒè‡´è°¢ @jlcodes99 PR #523)**:\n            - **è´¦å·è®¾å¤‡ç»‘å®š**: å®ç°è´¦å·ä¸è®¾å¤‡ä¿¡æ¯çš„ä¸€å¯¹ä¸€ç»‘å®šå…³ç³»ï¼Œåˆ‡æ¢è´¦å·æ—¶è‡ªåŠ¨åˆ‡æ¢å¯¹åº”çš„è®¾å¤‡æŒ‡çº¹ã€‚\n            - **è®¾å¤‡æŒ‡çº¹ç®¡ç†**: æ–°å¢å®Œæ•´çš„è®¾å¤‡æŒ‡çº¹ç®¡ç†æ¨¡å— (`device.rs`)ï¼Œæ”¯æŒæŒ‡çº¹ç”Ÿæˆã€ç»‘å®šã€æ¢å¤å’Œç‰ˆæœ¬ç®¡ç†ã€‚\n            - **é£æ§ä¼˜åŒ–**: é€šè¿‡ç¡®ä¿æ¯ä¸ªè´¦å·ä½¿ç”¨ç‹¬ç«‹çš„è®¾å¤‡ä¿¡æ¯ï¼Œæ˜¾è‘—é™ä½è¢« Google é£æ§ç³»ç»Ÿæ£€æµ‹çš„æ¦‚ç‡ã€‚\n            - **UI å¢å¼º**: æ–°å¢è®¾å¤‡æŒ‡çº¹ç®¡ç†å¯¹è¯æ¡† (`DeviceFingerprintDialog.tsx`)ï¼Œæä¾›å¯è§†åŒ–çš„æŒ‡çº¹ç®¡ç†ç•Œé¢ã€‚\n            - **æ ¸å¿ƒåŠŸèƒ½**:\n                - æ”¯æŒé‡‡é›†å½“å‰è®¾å¤‡æŒ‡çº¹æˆ–ç”ŸæˆéšæœºæŒ‡çº¹\n                - è‡ªåŠ¨å¤‡ä»½å’Œç‰ˆæœ¬ç®¡ç†è®¾å¤‡æŒ‡çº¹å†å²\n                - æ”¯æŒæ¢å¤åˆ°ä»»æ„å†å²ç‰ˆæœ¬\n                - æä¾›è®¾å¤‡å­˜å‚¨ç›®å½•å¿«é€Ÿè®¿é—®\n            - **å½±å“èŒƒå›´**: æ­¤åŠŸèƒ½ä¸ºå¤šè´¦å·ç®¡ç†æä¾›äº†æ›´å¼ºçš„éšç§ä¿æŠ¤ï¼Œæœ‰æ•ˆé™ä½è´¦å·å…³è”é£é™©ã€‚\n        - **ä»£ç†æœåŠ¡æ ¸å¿ƒä¿®å¤ (Proxy Service Critical Fixes) - æå‡ç¨³å®šæ€§ (æ ¸å¿ƒè‡´è°¢ @byte-sunlight PR #532)**:\n            - **Warmup è¯·æ±‚æ‹¦æˆª**: è‡ªåŠ¨è¯†åˆ«å¹¶æ‹¦æˆª Claude Code æ¯ 10 ç§’å‘é€çš„ warmup è¯·æ±‚ï¼Œè¿”å›æ¨¡æ‹Ÿå“åº”ï¼Œé¿å…æ¶ˆè€—é…é¢ã€‚\n                - æ”¯æŒæµå¼å’Œéæµå¼ä¸¤ç§å“åº”æ¨¡å¼\n                - æ™ºèƒ½æ£€æµ‹ warmup ç‰¹å¾ï¼ˆæ–‡æœ¬å†…å®¹ã€tool_result é”™è¯¯ç­‰ï¼‰\n                - æ·»åŠ  `X-Warmup-Intercepted` å“åº”å¤´æ ‡è¯†\n            - **é™æµé€»è¾‘é‡æ„**: ä¿®å¤é™æµæ£€æŸ¥ä¸­çš„å…³é”® bugï¼Œä½¿ç”¨ `email` è€Œé `account_id` ä½œä¸ºé™æµè®°å½•çš„ keyã€‚\n                - ä¿®å¤ç»‘å®šè´¦å·é™æµæ£€æŸ¥å¤±æ•ˆçš„é—®é¢˜\n                - ä¼˜åŒ– 60s æ—¶é—´çª—å£å†…çš„è´¦å·å¤ç”¨é€»è¾‘ï¼Œé¿å…å¤ç”¨å·²é™æµè´¦å·\n                - æ”¹è¿›ä¼šè¯è§£ç»‘æœºåˆ¶ï¼Œé™æµæ—¶ç«‹å³åˆ‡æ¢è€Œéé˜»å¡ç­‰å¾…\n            - **å­—ç¬¦ä¸²å¤„ç†å®‰å…¨**: ä¿®å¤ UTF-8 å­—ç¬¦è¾¹ç•Œ panic é—®é¢˜ï¼Œä½¿ç”¨ `chars().take()` å®‰å…¨æˆªå–å­—ç¬¦ä¸²ã€‚\n            - **å½±å“èŒƒå›´**: æ­¤ä¿®å¤æ˜¾è‘—æå‡äº† Claude Code ç­‰å·¥å…·çš„ä½¿ç”¨ä½“éªŒï¼Œå‡å°‘é…é¢æµªè´¹å¹¶æé«˜è´¦å·è½®æ¢çš„å‡†ç¡®æ€§ã€‚\n        - **CI/CD æµ‹è¯•å¢å¼º (CI Testing Enhancement) - æå‡å‘å¸ƒè´¨é‡ (æ ¸å¿ƒè‡´è°¢ @Vucius PR #519)**:\n            - **å¼ºåˆ¶æµ‹è¯•**: åœ¨ GitHub Actions çš„ Release æµç¨‹ä¸­æ·»åŠ  `cargo test` æ­¥éª¤ï¼Œç¡®ä¿æ‰€æœ‰æµ‹è¯•é€šè¿‡åæ‰èƒ½æ„å»ºå‘å¸ƒç‰ˆæœ¬ã€‚\n            - **æµ‹è¯•ä¿®å¤**: ä¿®æ­£ `common_utils.rs` ä¸­è”ç½‘æœç´¢æµ‹è¯•çš„æ¨¡å‹æ˜ å°„æ–­è¨€ï¼ˆ`gemini-3-flash` â†’ `gemini-2.5-flash`ï¼‰ã€‚\n            - **æµ‹è¯•æ¸…ç†**: ç§»é™¤ `gemini/wrapper.rs` ä¸­é‡å¤çš„æµ‹è¯•æ¨¡å—å®šä¹‰ï¼Œä¼˜åŒ–æµ‹è¯•ä»£ç ç»“æ„ã€‚\n            - **æ–°å¢æµ‹è¯•æ¢é’ˆ**: æ·»åŠ  `common_utils_test_probe.rs` æ–‡ä»¶ï¼Œæä¾›è‡ªå®šä¹‰å·¥å…·æ£€æµ‹çš„æµ‹è¯•ç”¨ä¾‹ã€‚\n            - **å½±å“èŒƒå›´**: æ­¤æ”¹è¿›ç¡®ä¿äº†æ¯æ¬¡å‘å¸ƒçš„ä»£ç è´¨é‡ï¼Œå‡å°‘å› æµ‹è¯•å¤±è´¥å¯¼è‡´çš„å›å½’é—®é¢˜ã€‚\n        - **ç›‘æ§æ—¥å¿—å®¹é‡ä¼˜åŒ– (Monitor Log Capacity Enhancement) - æ”¯æŒå¤§å‹å›¾ç‰‡å“åº” (ä¿®å¤ Issue #489)**:\n            - **æå‡å“åº”æ—¥å¿—é™åˆ¶**: å°†ç›‘æ§ä¸­é—´ä»¶çš„å“åº”ä½“æ—¥å¿—é™åˆ¶ä» 10MB æå‡åˆ° **100MB**ï¼Œè§£å†³ 4K å›¾ç‰‡ç­‰å¤§å‹å“åº”è¢«æˆªæ–­çš„é—®é¢˜ã€‚\n            - **é—®é¢˜èƒŒæ™¯**: 4K å›¾ç‰‡ç»è¿‡ base64 ç¼–ç åé€šå¸¸è¶…è¿‡ 10MBï¼Œå¯¼è‡´ç›‘æ§æ—¥å¿—æ˜¾ç¤º `[Response too large (>10MB)]` è€Œæ— æ³•è®°å½•å®Œæ•´å“åº”ã€‚\n            - **ä¼˜åŒ–æ•ˆæœ**: ç°åœ¨å¯ä»¥å®Œæ•´è®°å½•åŒ…å«é«˜åˆ†è¾¨ç‡å›¾ç‰‡çš„å“åº”å†…å®¹ï¼Œä¾¿äºè°ƒè¯•å’Œç›‘æ§å›¾åƒç”Ÿæˆç­‰å¤šæ¨¡æ€åŠŸèƒ½ã€‚\n            - **æ€§èƒ½å½±å“**: æ¯ä¸ªè¯·æ±‚æœ€å¤šå ç”¨ 100MB ä¸´æ—¶å†…å­˜ï¼Œå¯¹ç°ä»£ç³»ç»Ÿï¼ˆ8GB+ RAMï¼‰å®Œå…¨å¯æ¥å—ã€‚\n            - **å†å²æ¼”è¿›**: v3.3.16 æ—¶ä» 512KB æå‡åˆ° 10MBï¼ˆ@Stranmor PR #321ï¼‰ï¼Œæœ¬æ¬¡è¿›ä¸€æ­¥æå‡åˆ° 100MBã€‚\n            - **å½±å“èŒƒå›´**: æ­¤ä¼˜åŒ–ç¡®ä¿äº†å›¾åƒç”Ÿæˆã€å¤§å‹ JSON å“åº”ç­‰åœºæ™¯çš„å®Œæ•´æ—¥å¿—è®°å½•ï¼Œæå‡äº†ç›‘æ§ç³»ç»Ÿçš„å®ç”¨æ€§ã€‚\n        - **è‡ªåŠ¨æ›´æ–°é€šçŸ¥ç³»ç»Ÿ (Automatic Update Notification System) - æå‡ç”¨æˆ·ä½“éªŒ (ä¿®å¤ Issue #484)**:\n            - **åç«¯å®ç°**: æ–°å¢ `update_checker.rs` æ¨¡å—ï¼Œé›†æˆ GitHub API è‡ªåŠ¨æ£€æµ‹æœ€æ–°ç‰ˆæœ¬ã€‚\n                - è¯­ä¹‰åŒ–ç‰ˆæœ¬æ¯”è¾ƒï¼ˆæ”¯æŒ x.y.z æ ¼å¼ï¼‰\n                - 24 å°æ—¶æ™ºèƒ½æ£€æŸ¥é—´éš”\n                - è®¾ç½®æŒä¹…åŒ–ï¼ˆ`update_settings.json`ï¼‰\n                - ç½‘ç»œé”™è¯¯å®¹é”™å¤„ç†\n            - **å‰ç«¯å®ç°**: æ–°å¢ `UpdateNotification.tsx` Toast é€šçŸ¥ç»„ä»¶ã€‚\n                - æ¸å˜ UI è®¾è®¡ï¼ˆè“ç´«è‰²æ¸å˜ï¼‰\n                - åº”ç”¨å¯åŠ¨å 2 ç§’è‡ªåŠ¨æ£€æŸ¥\n                - ä¸€é”®è·³è½¬ä¸‹è½½é¡µé¢\n                - å¯å…³é—­/å¿½ç•¥åŠŸèƒ½\n            - **ç”¨æˆ·æ§åˆ¶**: å°Šé‡ç”¨æˆ·è®¾ç½®ï¼Œæ”¯æŒè‡ªåŠ¨æ£€æŸ¥å¼€å…³å’Œæ£€æŸ¥é—´éš”é…ç½®ã€‚\n            - **è·¨å¹³å°æ”¯æŒ**: å®Œå…¨å…¼å®¹ macOSã€Windowsã€Linux ä¸‰å¤§å¹³å°ã€‚\n            - **å½±å“èŒƒå›´**: ç”¨æˆ·æ— éœ€æ‰‹åŠ¨æ£€æŸ¥å³å¯åŠæ—¶è·çŸ¥æ–°ç‰ˆæœ¬ï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°åŠŸèƒ½å’Œ bug ä¿®å¤ã€‚\n        - **å¼€æœºè‡ªåŠ¨å¯åŠ¨å…¼å®¹æ€§ä¿®å¤ (Auto-Launch Compatibility Fix) - è§£å†³ Windows åˆ‡æ¢å¼‚å¸¸ (ä¿®å¤ Issue #438, #539)**:\n            - **åç«¯å®¹é”™å¢å¼º**: ä¿®å¤äº† Windows ç¯å¢ƒä¸‹ç¦ç”¨è‡ªå¯æ—¶å› æ‰¾ä¸åˆ°æ³¨å†Œè¡¨é¡¹å¯¼è‡´çš„ `os error 2` æŠ¥é”™ã€‚ç°åœ¨å½“ç”¨æˆ·é€‰æ‹©ç¦ç”¨ä¸”å¯åŠ¨é¡¹å·²ä¸å­˜åœ¨æ—¶ï¼Œç³»ç»Ÿå°†è§†ä¸ºæ“ä½œæˆåŠŸï¼Œä¸å†é˜»æ–­åç»­é€»è¾‘ã€‚\n            - **çŠ¶æ€å®æ—¶åŒæ­¥**: å‰ç«¯è®¾ç½®é¡µé¢ç°åœ¨ä¼šåœ¨åŠ è½½æ—¶ä¸»åŠ¨æŸ¥è¯¢ç³»ç»Ÿçš„çœŸå®è‡ªå¯çŠ¶æ€ï¼Œè€Œéä»…ä»…ä¾èµ–é…ç½®æ–‡ä»¶ã€‚è¿™è§£å†³äº†ç”±äºç³»ç»Ÿæ¸…ç†è½¯ä»¶æˆ–ç§»åŠ¨åº”ç”¨ä½ç½®å¯¼è‡´çš„çŠ¶æ€ä¸ä¸€è‡´é—®é¢˜ã€‚\n            - **é€»è¾‘é—­ç¯**: ç¡®ä¿äº†å³ä½¿åœ¨å¼‚å¸¸ç³»ç»Ÿç¯å¢ƒä¸‹ï¼Œç”¨æˆ·ä¹Ÿèƒ½é€šè¿‡é‡æ–°ç‚¹å‡»â€œå¯ç”¨/ç¦ç”¨â€æ¥å¼ºåˆ¶ä¿®å¤å¹¶åŒæ­¥è‡ªå¯çŠ¶æ€ã€‚\n            - **å½±å“èŒƒå›´**: è§£å†³äº†ä» v3.2.7 ä»¥æ¥é•¿æœŸå›°æ‰° Windows ç”¨æˆ·çš„â€œæ— æ³•ç¦ç”¨/è®¾ç½®ä¸ç”Ÿæ•ˆâ€é—®é¢˜ã€‚\n        - **API ç›‘æ§çœ‹æ¿å¢å¼º (API Monitor Enhancement) - è¡¥å…¨å¤±è´¥è¯·æ±‚è®°å½•ä¸ Gemini ç»Ÿè®¡ (ä¿®å¤ Issue #504)**:\n            - **Gemini Token ç»Ÿè®¡å…¼å®¹**: å¢å¼ºäº†ç›‘æ§ä¸­é—´ä»¶å¯¹ Gemini API æ–¹è¨€çš„æ”¯æŒï¼Œèƒ½å¤Ÿè‡ªåŠ¨è¯†åˆ« `usageMetadata` èŠ‚ç‚¹å¹¶æ˜ å°„ `promptTokenCount` ç­‰åŸç”Ÿå­—æ®µã€‚\n            - **å½±å“èŒƒå›´**: æ˜¾è‘—æå‡äº†ç›‘æ§é¢æ¿åœ¨æ•…éšœæ’æŸ¥æ—¶çš„å‡†ç¡®æ€§ï¼Œç¡®ä¿äº†è·¨åè®® Token ç»Ÿè®¡çš„ä¸€è‡´æ€§ã€‚\n        - **Claude åè®®æ ¸å¿ƒå¢å¼º (Claude Protocol Enhancement)**:\n            - **å¼¹æ€§æ¢å¤å¼•æ“ (Elastic Recovery Engine)**: \n                - **ç©ºæµé‡è¯•**: æ™ºèƒ½è¯†åˆ«å¹¶è‡ªåŠ¨é‡è¯•ä¸Šæ¸¸è¿”å›çš„ç©ºæ•°æ®æµï¼Œè§£å†³ç½‘ç»œæŠ–åŠ¨å¯¼è‡´çš„è¯·æ±‚å¤±è´¥ã€‚\n                - **æ–­ç‚¹è‡ªæ„ˆ**: è‡ªåŠ¨æ£€æµ‹å·¥å…·è°ƒç”¨é“¾çš„æ–­è£‚çŠ¶æ€ï¼ˆMissing ToolResultï¼‰ï¼Œå¹¶å®æ–½ä¸»åŠ¨ä¿®å¤ï¼Œé˜²æ­¢å› å®¢æˆ·ç«¯ä¸­æ–­å¯¼è‡´çš„ä¸Šä¸‹æ–‡åŒæ­¥é”™è¯¯ (400)ã€‚\n            - **æ™ºèƒ½ä¸Šä¸‹æ–‡ä¼˜åŒ– (Smart Context Optimization)**:\n                - **èµ„æºç˜¦èº«**: è‡ªåŠ¨æ¸…æ´—å†å²è®°å½•ä¸­çš„å†—ä½™ Base64 å›¾ç‰‡æ•°æ®ä¸è¶…é•¿æ—¥å¿—ï¼Œåœ¨ä¿æŒä¸Šä¸‹æ–‡è¿è´¯çš„åŒæ—¶å¤§å¹…é™ä½ Token æ¶ˆè€—ã€‚\n                - **ç­¾åå…¼å®¹**: å®ç°äº†åŒå‘ç­¾åè½¬æ¢å±‚ï¼Œå®Œç¾é€‚é…å„ç‰ˆæœ¬ Claude å®¢æˆ·ç«¯çš„ Thinking ç­¾åæ ¡éªŒæœºåˆ¶ã€‚\n            - **ç²¾ç»†åŒ–é™æµ (Model-Level Rate Limiting)**:\n                - **æ¨¡å‹éš”ç¦»**: 429 é™æµç­–ç•¥å‡çº§ä¸ºâ€œè´¦å·+æ¨¡å‹â€åŒç»´åº¦é”å®šã€‚Gemini Flash çš„é¢‘æ§ä¸å†å½±å“ Pro/Ultra æ¨¡å‹çš„ä½¿ç”¨ï¼Œæ˜¾è‘—æå‡è´¦å·åˆ©ç”¨ç‡ã€‚\n    *   **v3.3.20 (2026-01-09)**:\n        - **è¯·æ±‚è¶…æ—¶é…ç½®ä¼˜åŒ– (Request Timeout Enhancement) - æ”¯æŒé•¿æ—¶é—´æ–‡æœ¬å¤„ç† (æ ¸å¿ƒè‡´è°¢ @xiaoyaocp Issue #473)**:\n            - **æå‡è¶…æ—¶ä¸Šé™**: å°†æœåŠ¡é…ç½®ä¸­çš„è¯·æ±‚è¶…æ—¶æœ€å¤§å€¼ä» 600 ç§’ï¼ˆ10 åˆ†é’Ÿï¼‰æå‡åˆ° 3600 ç§’ï¼ˆ1 å°æ—¶ï¼‰ã€‚\n            - **æ”¯æŒè€—æ—¶æ¥å£**: è§£å†³äº†æŸäº›æ–‡æœ¬å¤„ç†æ¥å£ï¼ˆå¦‚é•¿æ–‡æœ¬ç”Ÿæˆã€å¤æ‚æ¨ç†ç­‰ï¼‰å› è¶…æ—¶é™åˆ¶å¯¼è‡´çš„è¯·æ±‚ä¸­æ–­é—®é¢˜ã€‚\n            - **çµæ´»é…ç½®èŒƒå›´**: ä¿æŒæœ€å°å€¼ 30 ç§’ä¸å˜ï¼Œç”¨æˆ·å¯æ ¹æ®å®é™…éœ€æ±‚åœ¨ 30-3600 ç§’èŒƒå›´å†…è‡ªç”±è°ƒæ•´ã€‚\n            - **å›½é™…åŒ–æ›´æ–°**: åŒæ­¥æ›´æ–°ä¸­è‹±æ–‡æç¤ºæ–‡æœ¬ï¼Œæ¸…æ™°æ ‡æ³¨æ–°çš„é…ç½®èŒƒå›´ã€‚\n            - **å½±å“èŒƒå›´**: æ­¤ä¼˜åŒ–ä¸ºéœ€è¦é•¿æ—¶é—´å¤„ç†çš„ API è¯·æ±‚æä¾›äº†æ›´å¤§çš„çµæ´»æ€§ï¼Œç‰¹åˆ«é€‚ç”¨äºå¤æ‚æ–‡æœ¬å¤„ç†ã€é•¿æ–‡æœ¬ç”Ÿæˆç­‰åœºæ™¯ã€‚\n        - **è‡ªåŠ¨ Stream è½¬æ¢åŠŸèƒ½ (Auto-Stream Conversion) - æ¶ˆé™¤ 429 é”™è¯¯**:\n            - **æ ¸å¿ƒé—®é¢˜**: Google API å¯¹æµå¼ (`stream: true`) å’Œéæµå¼ (`stream: false`) è¯·æ±‚é‡‡ç”¨æˆªç„¶ä¸åŒçš„é…é¢é™åˆ¶ç­–ç•¥ã€‚æµå¼è¯·æ±‚é…é¢æ›´å®½æ¾ï¼Œéæµå¼è¯·æ±‚ææ˜“è§¦å‘ 429 é”™è¯¯ã€‚\n            - **è§£å†³æ–¹æ¡ˆ**: åœ¨ä»£ç†å±‚è‡ªåŠ¨å°†æ‰€æœ‰éæµå¼è¯·æ±‚è½¬æ¢ä¸ºæµå¼è¯·æ±‚å‘é€ç»™ Googleï¼Œç„¶åå°† SSE å“åº”æ”¶é›†å¹¶è½¬æ¢å› JSON æ ¼å¼è¿”å›ç»™å®¢æˆ·ç«¯ã€‚\n            - **åè®®æ”¯æŒ**:\n                - **Claude åè®®**: âœ… å®Œæ•´å®ç°å¹¶æµ‹è¯•é€šè¿‡\n                - **OpenAI åè®®**: âœ… å®Œæ•´å®ç°å¹¶æµ‹è¯•é€šè¿‡\n                - **Gemini åè®®**: âœ… åŸç”Ÿæ”¯æŒéæµå¼è¯·æ±‚ï¼Œæ— éœ€è½¬æ¢\n            - **æ ¸å¿ƒæ”¹åŠ¨**:\n                - æ–°å¢ `src-tauri/src/proxy/mappers/claude/collector.rs` - Claude SSE æ”¶é›†å™¨\n                - æ–°å¢ `src-tauri/src/proxy/mappers/openai/collector.rs` - OpenAI SSE æ”¶é›†å™¨\n                - ä¿®æ”¹ `claude.rs` å’Œ `openai.rs` handlerï¼Œå®ç°è‡ªåŠ¨è½¬æ¢é€»è¾‘\n            - **æ€§èƒ½å½±å“**:\n                - **æˆåŠŸç‡**: ä» 10-20% æå‡åˆ° **95%+**\n                - **429 é”™è¯¯**: ä»é¢‘ç¹å‡ºç°åˆ°**å‡ ä¹æ¶ˆé™¤**\n                - **å“åº”æ—¶é—´**: å¢åŠ çº¦ 100-200msï¼ˆå¯æ¥å—çš„ä»£ä»·ï¼‰\n            - **å½±å“èŒƒå›´**: æ­¤åŠŸèƒ½æ˜¾è‘—æå‡äº† Python SDKã€Claude CLI ç­‰éæµå¼å®¢æˆ·ç«¯çš„ç¨³å®šæ€§ï¼Œè§£å†³äº†é•¿æœŸå›°æ‰°ç”¨æˆ·çš„ 429 é…é¢é—®é¢˜ã€‚\n        - **macOS Dock å›¾æ ‡ä¿®å¤ (æ ¸å¿ƒè‡´è°¢ @jalen0x PR #472)**:\n            - **ä¿®å¤çª—å£æ— æ³•é‡æ–°æ‰“å¼€**: è§£å†³äº† macOS ä¸Šå…³é—­çª—å£åç‚¹å‡» Dock å›¾æ ‡æ— æ³•é‡æ–°æ‰“å¼€çª—å£çš„é—®é¢˜ï¼ˆIssue #471ï¼‰ã€‚\n            - **RunEvent::Reopen å¤„ç†**: å°† `.run()` æ”¹ä¸º `.build().run()` æ¨¡å¼ï¼Œæ·»åŠ  `RunEvent::Reopen` äº‹ä»¶å¤„ç†å™¨ã€‚\n            - **çª—å£çŠ¶æ€æ¢å¤**: å½“ç‚¹å‡» Dock å›¾æ ‡æ—¶è‡ªåŠ¨æ˜¾ç¤ºçª—å£ã€å–æ¶ˆæœ€å°åŒ–ã€è®¾ç½®ç„¦ç‚¹ï¼Œå¹¶æ¢å¤æ¿€æ´»ç­–ç•¥ä¸º `Regular`ã€‚\n            - **å½±å“èŒƒå›´**: æ­¤ä¿®å¤æå‡äº† macOS ç”¨æˆ·ä½“éªŒï¼Œç¡®ä¿åº”ç”¨çª—å£èƒ½å¤Ÿæ­£å¸¸é‡æ–°æ‰“å¼€ï¼Œç¬¦åˆ macOS åº”ç”¨çš„æ ‡å‡†è¡Œä¸ºã€‚\n    *   **v3.3.19 (2026-01-09)**:\n        - **æ¨¡å‹è·¯ç”±ç³»ç»Ÿæç®€é‡æ„ (Model Routing Refactoring)**:\n            - **é€»è¾‘ç®€åŒ–**: ç§»é™¤äº†å¤æ‚çš„â€œè§„æ ¼å®¶æ—â€åˆ†ç»„æ˜ å°„ï¼Œå¼•å…¥äº†æ›´ç›´è§‚çš„ **é€šé…ç¬¦ (*)** åŒ¹é…é€»è¾‘ã€‚\n            - **è‡ªåŠ¨é…ç½®è¿ç§»**: å¯åŠ¨æ—¶è‡ªåŠ¨å°†æ—§ç‰ˆæœ¬çš„å®¶æ—æ˜ å°„è§„åˆ™è¿ç§»è‡³è‡ªå®šä¹‰æ˜ å°„è¡¨ï¼Œç¡®ä¿æ— æŸå‡çº§ã€‚\n            - **UI å¸ƒå±€ä¼˜åŒ–**:\n                - **é«˜æ•ˆæ’ç‰ˆ**: â€œç²¾ç¡®æ˜ å°„åˆ—è¡¨â€æ”¹ä¸º 2 åˆ—å¹¶åˆ—å±•ç¤ºï¼Œå¤§å¹…æå‡ç©ºé—´åˆ©ç”¨ç‡ã€‚\n                - **äº¤äº’ä¼˜åŒ–**: å°†åˆ—è¡¨ç½®é¡¶å¹¶æ”¯æŒ Hover åˆ é™¤ï¼Œè¡¨å•å‹ç¼©ä¸ºå•è¡Œç½®åº•ï¼Œæ“ä½œæ›´åŠ èšç„¦ã€‚\n                - **æ·±è‰²æ¨¡å¼è°ƒä¼˜**: é’ˆå¯¹æš—è‰²ç¯å¢ƒè¿›è¡Œäº†ä¸“é¡¹è§†è§‰ä¼˜åŒ–ï¼Œæå‡äº†å¯¹æ¯”åº¦ä¸å±‚æ¬¡æ„Ÿã€‚\n            - **ä¸€é”®é¢„è®¾**: æ–°å¢â€œåº”ç”¨é¢„è®¾æ˜ å°„â€åŠŸèƒ½ï¼Œå†…ç½® 11 æ¡å¸¸ç”¨çš„é€šé…ç¬¦è·¯ç”±è§„åˆ™ï¼ˆå¦‚ `gpt-4*`, `o1-*` ç­‰ï¼‰ã€‚\n            - **åœ¨çº¿ç¼–è¾‘åŠŸèƒ½**: æ”¯æŒç›´æ¥åœ¨åˆ—è¡¨ä¸­ä¿®æ”¹å·²æœ‰è§„åˆ™çš„ç›®æ ‡æ¨¡å‹ï¼Œæ— éœ€åˆ é™¤é‡å»ºï¼Œæ“ä½œæ›´é¡ºæ»‘ã€‚\n            - **ç¨³å®šæ€§å¢å¼º**: æ¸…ç†äº†åºŸå¼ƒå­—æ®µçš„æ®‹ç•™å¼•ç”¨ï¼Œä¿®å¤äº†æ‰€æœ‰ç›¸å…³ç¼–è¯‘è­¦å‘Šã€‚\n        - **æ¨¡å‹çº§åˆ«é™æµé”å®š (Model-Level Rate Limiting)**:\n            - **é—®é¢˜ä¿®å¤**: è§£å†³äº†ä¸åŒæ¨¡å‹é…é¢äº’ç›¸å½±å“çš„é—®é¢˜ã€‚ä¹‹å‰å½“ Image æ¨¡å‹é…é¢è€—å°½æ—¶,ä¼šé”å®šæ•´ä¸ªè´¦å·,å¯¼è‡´ Claude ç­‰å…¶ä»–æ¨¡å‹å³ä½¿æœ‰é…é¢ä¹Ÿæ— æ³•ä½¿ç”¨ã€‚\n            - **æ¨¡å‹çº§åˆ«é”å®š**: æ–°å¢ `model` å­—æ®µåˆ° `RateLimitInfo` ç»“æ„,æ”¯æŒé’ˆå¯¹ç‰¹å®šæ¨¡å‹è¿›è¡Œé™æµé”å®šã€‚\n            - **ç²¾ç¡®é…é¢ç®¡ç†**: ä¿®æ”¹ `mark_rate_limited_async`ã€`set_lockout_until`ã€`set_lockout_until_iso` ç­‰æ–¹æ³•,æ·»åŠ å¯é€‰çš„ `model` å‚æ•°ã€‚\n            - **æ™ºèƒ½æ—¥å¿—è¾“å‡º**: åŒºåˆ†è´¦å·çº§åˆ«å’Œæ¨¡å‹çº§åˆ«çš„é™æµæ—¥å¿—,ä¾¿äºè°ƒè¯•å’Œç›‘æ§ã€‚\n            - **å‘åå…¼å®¹**: `model: None` è¡¨ç¤ºè´¦å·çº§åˆ«é™æµ(ä¿æŒåŸæœ‰è¡Œä¸º),`model: Some(...)` è¡¨ç¤ºæ¨¡å‹çº§åˆ«é™æµ(æ–°åŠŸèƒ½)ã€‚\n            - **å½±å“èŒƒå›´**: æ­¤ä¿®å¤ç¡®ä¿äº†ä¸åŒæ¨¡å‹çš„é…é¢ç‹¬ç«‹ç®¡ç†,Image æ¨¡å‹é…é¢è€—å°½ä¸å†å½±å“ Claudeã€Gemini ç­‰å…¶ä»–æ¨¡å‹çš„æ­£å¸¸ä½¿ç”¨ã€‚\n        - **ä¹è§‚é‡ç½®ç­–ç•¥é›†æˆ (Optimistic Reset Strategy)**:\n            - **åŒå±‚é˜²æŠ¤æœºåˆ¶**: ä¸º 429 é”™è¯¯å¤„ç†æ·»åŠ æœ€åä¸€é“é˜²çº¿,è§£å†³æ—¶åºç«äº‰æ¡ä»¶å¯¼è‡´çš„\"æ— å¯ç”¨è´¦å·\"è¯¯æŠ¥ã€‚\n                - **Layer 1 - ç¼“å†²å»¶è¿Ÿ**: å½“æ‰€æœ‰è´¦å·è¢«é™æµä½†æœ€çŸ­ç­‰å¾…æ—¶é—´ â‰¤ 2 ç§’æ—¶,æ‰§è¡Œ 500ms ç¼“å†²å»¶è¿Ÿ,ç­‰å¾…çŠ¶æ€åŒæ­¥ã€‚\n                - **Layer 2 - ä¹è§‚é‡ç½®**: å¦‚æœç¼“å†²åä»æ— å¯ç”¨è´¦å·,æ¸…é™¤æ‰€æœ‰é™æµè®°å½•(`clear_all`)å¹¶é‡è¯•ã€‚\n            - **ç²¾å‡†è§¦å‘æ¡ä»¶**: åªåœ¨ç­‰å¾…æ—¶é—´ â‰¤ 2 ç§’æ—¶è§¦å‘,é¿å…å¯¹çœŸå®é…é¢è€—å°½æ‰§è¡Œæ— æ•ˆé‡ç½®ã€‚\n            - **è¯¦ç»†æ—¥å¿—è¿½è¸ª**: æ‰€æœ‰å…³é”®æ­¥éª¤éƒ½æœ‰æ—¥å¿—è¾“å‡º(`[WARN]`/`[INFO]`),ä¾¿äºè°ƒè¯•å’Œç›‘æ§ã€‚\n            - **é€‚ç”¨åœºæ™¯**: è§£å†³é™æµè¿‡æœŸè¾¹ç•Œçš„æ—¶åºç«äº‰æ¡ä»¶ã€ä¸´æ—¶æ€§ API é™æµã€çŠ¶æ€åŒæ­¥å»¶è¿Ÿç­‰é—®é¢˜ã€‚\n            - **å½±å“èŒƒå›´**: æ­¤ç­–ç•¥ä½œä¸ºç°æœ‰ 429 å¤„ç†ç³»ç»Ÿ(ç²¾ç¡®è§£æã€æ™ºèƒ½é€€é¿ã€æˆåŠŸé‡ç½®)çš„è¡¥å……,æé«˜äº†ä¸´æ—¶æ€§é™æµçš„æ¢å¤èƒ½åŠ›ã€‚\n    *   **v3.3.18 (2026-01-08)**:\n        - **æ™ºèƒ½é™æµä¼˜åŒ– - å®æ—¶é…é¢åˆ·æ–°ä¸ç²¾å‡†é”å®š (æ ¸å¿ƒè‡´è°¢ @Mag1cFall PR #446)**:\n            - **æ™ºèƒ½æŒ‡æ•°é€€é¿**: æ ¹æ®è¿ç»­å¤±è´¥æ¬¡æ•°åŠ¨æ€è°ƒæ•´é”å®šæ—¶é—´,é¿å…å› ä¸´æ—¶é…é¢æ³¢åŠ¨å¯¼è‡´çš„é•¿æ—¶é—´é”å®šã€‚\n                - ç¬¬ 1 æ¬¡å¤±è´¥: 60 ç§’\n                - ç¬¬ 2 æ¬¡å¤±è´¥: 5 åˆ†é’Ÿ\n                - ç¬¬ 3 æ¬¡å¤±è´¥: 30 åˆ†é’Ÿ\n                - ç¬¬ 4 æ¬¡åŠä»¥ä¸Š: 2 å°æ—¶\n            - **å®æ—¶é…é¢åˆ·æ–°**: å½“ API è¿”å› 429 ä½†æœªæä¾› `quotaResetDelay` æ—¶,å®æ—¶è°ƒç”¨é…é¢åˆ·æ–° API è·å–æœ€æ–°çš„ `reset_time`,ç²¾ç¡®é”å®šè´¦å·åˆ°é…é¢æ¢å¤æ—¶é—´ç‚¹ã€‚\n            - **ä¸‰çº§é™çº§ç­–ç•¥**:\n                - ä¼˜å…ˆ: ä½¿ç”¨ API è¿”å›çš„ `quotaResetDelay`\n                - æ¬¡ä¼˜: å®æ—¶åˆ·æ–°é…é¢è·å– `reset_time`\n                - ä¿åº•: ä½¿ç”¨æœ¬åœ°ç¼“å­˜çš„é…é¢åˆ·æ–°æ—¶é—´\n                - å…œåº•: ä½¿ç”¨æ™ºèƒ½æŒ‡æ•°é€€é¿ç­–ç•¥\n            - **ç²¾å‡†é”å®š**: æ–°å¢ `set_lockout_until_iso` æ–¹æ³•,æ”¯æŒä½¿ç”¨ ISO 8601 æ—¶é—´å­—ç¬¦ä¸²ç²¾ç¡®é”å®šè´¦å·ã€‚\n            - **æˆåŠŸé‡ç½®**: è¯·æ±‚æˆåŠŸåè‡ªåŠ¨é‡ç½®è´¦å·çš„è¿ç»­å¤±è´¥è®¡æ•°,é¿å…è´¦å·å› å†å²å¤±è´¥è®°å½•è€Œè¢«é•¿æœŸé”å®šã€‚\n            - **æ–°å¢é”™è¯¯ç±»å‹æ”¯æŒ**: æ–°å¢ `ModelCapacityExhausted` é”™è¯¯ç±»å‹,å¤„ç†æœåŠ¡ç«¯æš‚æ—¶æ— å¯ç”¨ GPU å®ä¾‹çš„æƒ…å†µ(15 ç§’é‡è¯•)ã€‚\n            - **ä¼˜åŒ–é™æµåˆ¤æ–­**: ä¿®å¤ TPM é™æµè¢«è¯¯åˆ¤ä¸ºé…é¢è€—å°½çš„é—®é¢˜,ä¼˜å…ˆæ£€æŸ¥ \"per minute\" æˆ– \"rate limit\" å…³é”®è¯ã€‚\n            - **å½±å“èŒƒå›´**: æ­¤ä¼˜åŒ–æ˜¾è‘—æå‡äº†å¤šè½®å¯¹è¯ä¸­çš„è´¦å·å¯ç”¨æ€§å’Œç¨³å®šæ€§,è§£å†³äº†é¢‘ç¹ 429 é”™è¯¯å’Œè´¦å·é”å®šæ—¶é—´ä¸å‡†ç¡®çš„é—®é¢˜ã€‚\n        - **æ¨¡å‹è·¯ç”±ä¸­å¿ƒ BUG ä¿®å¤ (Fix Issue #434)**:\n            - **ä¿®å¤ GroupedSelect Portal äº‹ä»¶å¤„ç†**: è§£å†³äº†è‡ªå®šä¹‰ä¸‹æ‹‰é€‰æ‹©ç»„ä»¶çš„å…³é”® BUG,ä¿®å¤ç‚¹å‡»é€‰é¡¹æ—¶èœå•ç«‹å³å…³é—­å¯¼è‡´é€‰æ‹©æ— æ•ˆçš„é—®é¢˜ã€‚\n                - **æ ¹æœ¬åŸå› **: `createPortal` å°†ä¸‹æ‹‰èœå•æ¸²æŸ“åˆ° `document.body`,ä½† `handleClickOutside` åªæ£€æŸ¥ `containerRef`,å¯¼è‡´ç‚¹å‡»é€‰é¡¹æ—¶è¢«è¯¯åˆ¤ä¸º\"ç‚¹å‡»å¤–éƒ¨\"ã€‚\n                - **è§£å†³æ–¹æ¡ˆ**: æ·»åŠ  `dropdownRef` å¼•ç”¨ä¸‹æ‹‰èœå•,ä¿®æ”¹ `handleClickOutside` åŒæ—¶æ£€æŸ¥å®¹å™¨å’Œä¸‹æ‹‰èœå•,ç¡®ä¿ç‚¹å‡»é€‰é¡¹æ—¶ä¸ä¼šå…³é—­èœå•ã€‚\n                - **å½±å“èŒƒå›´**: ä¿®å¤äº†æ‰€æœ‰ 5 ä¸ªæ¨¡å‹å®¶æ—åˆ†ç»„(Claude 4.5ã€Claude 3.5ã€GPT-4ã€GPT-4oã€GPT-5)çš„ä¸‹æ‹‰é€‰æ‹©åŠŸèƒ½ã€‚\n            - **è¡¥å……ç¼ºå¤±çš„å›½é™…åŒ–ç¿»è¯‘**: æ·»åŠ ä¸“å®¶ç²¾ç¡®æ˜ å°„éƒ¨åˆ†ç¼ºå¤±çš„ç¿»è¯‘é”®,è§£å†³æç¤ºæ–‡æœ¬ä¸æ˜¾ç¤ºçš„é—®é¢˜ã€‚\n                - ä¸­æ–‡: `money_saving_tip`ã€`haiku_optimization_tip`ã€`haiku_optimization_btn`ã€`select_target_model`\n                - è‹±æ–‡: å¯¹åº”çš„è‹±æ–‡ç¿»è¯‘\n                - **å½±å“èŒƒå›´**: \"ğŸ’° çœé’±æç¤º\" å’Œ \"ä¸€é”®ä¼˜åŒ–\" æŒ‰é’®ç°åœ¨æ­£å¸¸æ˜¾ç¤ºã€‚\n            - **ç»Ÿä¸€ä¸“å®¶æ˜ å°„è¡¨å•ä¸‹æ‹‰æ¡†**: å°†æ·»åŠ æ˜ å°„è¡¨å•ä¸­çš„åŸç”Ÿ `<select>` æ›¿æ¢ä¸ºè‡ªå®šä¹‰ `GroupedSelect` ç»„ä»¶ã€‚\n                - æ·»åŠ  `customMappingValue` state ç®¡ç†é€‰ä¸­å€¼\n                - ä» `models` åŠ¨æ€ç”Ÿæˆ `customMappingOptions`\n                - æä¾›ä¸€è‡´çš„ç”¨æˆ·ä½“éªŒ,è§£å†³ Windows é€æ˜åº¦é—®é¢˜\n            - **ç”¨æˆ·ä½“éªŒå¢å¼º**:\n                - æ·»åŠ æˆåŠŸ/å¤±è´¥ Toast æç¤º,ç”¨æˆ·æ“ä½œåæœ‰æ˜ç¡®åé¦ˆ\n                - æ·»åŠ è°ƒè¯•æ—¥å¿—ä¾¿äºé—®é¢˜è¯Šæ–­\n                - æ”¹è¿›é”™è¯¯å¤„ç†,å¤±è´¥æ—¶æ˜¾ç¤ºå…·ä½“é”™è¯¯ä¿¡æ¯\n        - **macOS æ—§ç‰ˆæœ¬å…¼å®¹æ€§ä¿®å¤ (Fix Issue #219)**:\n            - **ä¿®å¤æ·»åŠ è´¦å·å¼¹çª—ä¸æ˜¾ç¤º**: å°† `AddAccountDialog` ä¸­çš„ `<dialog>` æ ‡ç­¾æ›¿æ¢ä¸º `<div>`ï¼Œè§£å†³äº† macOS 12.1 (Safari < 15.4) ç­‰æ—§ç‰ˆæœ¬ç³»ç»Ÿä¸Šç‚¹å‡»â€œæ·»åŠ è´¦å·â€æŒ‰é’®æ— ååº”çš„é—®é¢˜ã€‚\n        - **å†…ç½®ç›´é€šæ¨¡å‹è·¯ç”±ä¿®å¤ (æ ¸å¿ƒè‡´è°¢ @jalen0x PR #444)**:\n            - **ä¿®å¤ç›´é€šæ¨¡å‹è¢«é”™è¯¯æ‹¦æˆª**: è§£å†³äº† `claude-opus-4-5-thinking` ç­‰å†…ç½®ç›´é€šæ¨¡å‹åœ¨ CLI æ¨¡å¼ä¸‹è¢«é”™è¯¯åœ°åº”ç”¨å®¶æ—æ˜ å°„è§„åˆ™ï¼ˆå¦‚è¢«é‡å®šå‘åˆ° `gemini-3-pro-high`ï¼‰çš„é—®é¢˜ã€‚\n            - **é€»è¾‘ä¼˜åŒ–**: ç§»é™¤äº†é’ˆå¯¹ CLI è¯·æ±‚çš„ç›´é€šæ£€æŸ¥é™åˆ¶ï¼Œç¡®ä¿å†…ç½®è¡¨ä¸­å®šä¹‰çš„ç›´é€šæ¨¡å‹ï¼ˆkey == valueï¼‰å§‹ç»ˆæ‹¥æœ‰æœ€é«˜ä¼˜å…ˆçº§ï¼Œç»•è¿‡å®¶æ—åˆ†ç»„æ˜ å°„ã€‚\n    *   **v3.3.17 (2026-01-08)**:\n        - **OpenAI åè®® Thinking å±•ç¤ºå¢å¼º (æ ¸å¿ƒè‡´è°¢ @Mag1cFall PR #411)**:\n            - **æ–°å¢ reasoning_content å­—æ®µæ”¯æŒ**: åœ¨ OpenAI å…¼å®¹æ ¼å¼ä¸­æ·»åŠ  `reasoning_content` å­—æ®µ,ä½¿ Gemini 3 æ¨¡å‹çš„æ€è€ƒè¿‡ç¨‹èƒ½å¤Ÿè¢« Cherry Studio ç­‰å®¢æˆ·ç«¯æ­£ç¡®æŠ˜å æ˜¾ç¤ºã€‚\n            - **æ€è€ƒå†…å®¹æ™ºèƒ½åˆ†ç¦»**: æ ¹æ® `thought:true` æ ‡è®°è‡ªåŠ¨åˆ†ç¦»æ€è€ƒå†…å®¹åˆ° `reasoning_content` å­—æ®µ,æ­£å¸¸å†…å®¹ä¿ç•™åœ¨ `content` å­—æ®µ,æå‡ç”¨æˆ·ä½“éªŒã€‚\n            - **æµå¼ä¸éæµå¼å…¨é¢æ”¯æŒ**: åœ¨ `streaming.rs` å’Œ `response.rs` ä¸­åŒæ—¶å®ç° `reasoning_content` æ”¯æŒ,ç¡®ä¿æ‰€æœ‰å“åº”æ¨¡å¼ä¸‹çš„ä¸€è‡´æ€§ã€‚\n            - **ä¿®å¤ç©º Chunk è·³è¿‡é—®é¢˜**: ä¿®å¤äº†å½“ä»…æœ‰æ€è€ƒå†…å®¹æ—¶ chunk è¢«é”™è¯¯è·³è¿‡çš„ Bug,ç°åœ¨åªæœ‰å½“ `content` å’Œ `reasoning_content` éƒ½ä¸ºç©ºæ—¶æ‰è·³è¿‡ã€‚\n            - **ç»Ÿä¸€æµå¼ ID**: ä¸ºæ‰€æœ‰æµå¼ chunk ä½¿ç”¨ç»Ÿä¸€çš„ `stream_id` å’Œ `created_ts`,ç¬¦åˆ OpenAI åè®®è§„èŒƒã€‚\n            - **å½±å“èŒƒå›´**: æ­¤åŠŸèƒ½å¢å¼ºäº† Gemini 3 thinking æ¨¡å‹åœ¨ Cherry Studioã€Cursor ç­‰å®¢æˆ·ç«¯ä¸­çš„å±•ç¤ºæ•ˆæœ,æ€è€ƒè¿‡ç¨‹å¯ä»¥è¢«æ­£ç¡®æŠ˜å ,ä¸å½±å“ä»»ä½•ç°æœ‰ v3.3.16 ä¿®å¤ã€‚\n        - **FastMCP æ¡†æ¶å…¼å®¹æ€§ä¿®å¤ (æ ¸å¿ƒè‡´è°¢ @Silviovespoli PR #416)**:\n            - **ä¿®å¤ anyOf/oneOf ç±»å‹ä¸¢å¤±é—®é¢˜**: è§£å†³äº† FastMCP æ¡†æ¶ç”Ÿæˆçš„ JSON Schema ä¸­ `anyOf`/`oneOf` è¢«ç§»é™¤åå¯¼è‡´å­—æ®µç¼ºå°‘ `type` å±æ€§çš„é—®é¢˜ã€‚\n            - **æ™ºèƒ½ç±»å‹æå–**: åœ¨ç§»é™¤ `anyOf`/`oneOf` ä¹‹å‰,è‡ªåŠ¨æå–ç¬¬ä¸€ä¸ªé null ç±»å‹åˆ° `type` å­—æ®µ,ç¡®ä¿ Schema æœ‰æ•ˆæ€§ã€‚\n            - **ä¿®å¤å·¥å…·è°ƒç”¨é™é»˜å¤±è´¥**: è§£å†³äº† Claude Code ä½¿ç”¨ FastMCP å·¥å…·æ—¶è°ƒç”¨å¤±è´¥ä½†æ— é”™è¯¯æç¤ºçš„é—®é¢˜ (Issue #379, #391)ã€‚\n            - **å‘åå…¼å®¹**: ä»…åœ¨å­—æ®µç¼ºå°‘ `type` æ—¶æ‰æå–,å·²æœ‰ `type` çš„ Schema ä¸å—å½±å“,ç¡®ä¿ä¸æ ‡å‡† MCP Server çš„å…¼å®¹æ€§ã€‚\n            - **å®Œæ•´æµ‹è¯•è¦†ç›–**: æ–°å¢ 4 ä¸ªå•å…ƒæµ‹è¯•éªŒè¯ `anyOf`/`oneOf` ç±»å‹æå–ã€å·²æœ‰ç±»å‹ä¿æŠ¤ç­‰åœºæ™¯ã€‚\n            - **å½±å“èŒƒå›´**: æ­¤ä¿®å¤ä½¿ FastMCP æ¡†æ¶æ„å»ºçš„ MCP æœåŠ¡å™¨èƒ½å¤Ÿæ­£å¸¸å·¥ä½œ,ä¸å½±å“æ ‡å‡† MCP Server å’Œä»»ä½•ç°æœ‰ v3.3.16 ä¿®å¤ã€‚\n        - **å‰ç«¯ UI/UX ä¼˜åŒ– (æ ¸å¿ƒè‡´è°¢ @i-smile PR #414)**:\n            - **API ä»£ç†è·¯ç”±é‡æ„**: ä½¿ç”¨åˆ†ç»„ä¸‹æ‹‰èœå•ä¼˜åŒ–ä¸“å®¶è·¯ç”±é…ç½®ç•Œé¢,æå‡æ¨¡å‹æ˜ å°„é…ç½®çš„å¯è¯»æ€§å’Œæ˜“ç”¨æ€§ã€‚\n            - **è´¦æˆ·è§†å›¾æ¨¡å¼æŒä¹…åŒ–**: ä½¿ç”¨ localStorage è‡ªåŠ¨è®°ä½ç”¨æˆ·é€‰æ‹©çš„åˆ—è¡¨/ç½‘æ ¼è§†å›¾æ¨¡å¼,æå‡ç”¨æˆ·ä½“éªŒã€‚\n            - **è¡¨æ ¼å¸ƒå±€ä¼˜åŒ–**: ä¸ºé…é¢åˆ—è®¾ç½®æœ€å°å®½åº¦é˜²æ­¢å‹ç¼©,æ“ä½œåˆ—å›ºå®šåœ¨å³ä¾§æå‡å°å±å¹•å¯è®¿é—®æ€§ã€‚\n            - **å›½é™…åŒ–ç¿»è¯‘å®Œå–„**: æ·»åŠ ç¼ºå¤±çš„ç¿»è¯‘é”®,ç§»é™¤ç¡¬ç¼–ç å­—ç¬¦ä¸²,æå‡å¤šè¯­è¨€æ”¯æŒè´¨é‡ã€‚\n            - **å½±å“èŒƒå›´**: æ­¤æ›´æ–°ä»…æ¶‰åŠå‰ç«¯ UI æ”¹è¿›,ä¸å½±å“ä»»ä½•åç«¯é€»è¾‘å’Œç°æœ‰ v3.3.16/v3.3.17 ä¿®å¤ã€‚\n        - **è‡ªå®šä¹‰åˆ†ç»„ä¸‹æ‹‰ç»„ä»¶ (Custom Grouped Select)**:\n            - **è§£å†³ Windows é€æ˜åº¦é—®é¢˜**: åˆ›å»ºè‡ªå®šä¹‰ `GroupedSelect` ç»„ä»¶æ›¿æ¢åŸç”Ÿ `<select>`,è§£å†³ Windows ä¸‹æ‹‰èœå•è¿‡äºé€æ˜çš„é—®é¢˜ã€‚\n            - **å®Œæ•´æ·±æµ…æ¨¡å¼æ”¯æŒ**: è‡ªå®šä¹‰ç»„ä»¶å®Œç¾æ”¯æŒæ·±æµ…æ¨¡å¼åˆ‡æ¢,æä¾›ä¸€è‡´çš„è§†è§‰ä½“éªŒã€‚\n            - **React Portal æ¸²æŸ“**: ä½¿ç”¨ `createPortal` å°†ä¸‹æ‹‰èœå•æ¸²æŸ“åˆ° `document.body`,è§£å†³è¢«çˆ¶å®¹å™¨é®ç›–çš„é—®é¢˜ã€‚\n            - **åŠ¨æ€ä½ç½®è®¡ç®—**: å®æ—¶è®¡ç®—ä¸‹æ‹‰èœå•ä½ç½®,æ”¯æŒé¡µé¢æ»šåŠ¨å’Œçª—å£å¤§å°å˜åŒ–æ—¶è‡ªåŠ¨è°ƒæ•´ã€‚\n            - **ä¼˜åŒ–å­—ä½“å’Œé—´è·**: é€‰é¡¹å­—ä½“ 10px,åˆ†ç»„æ ‡é¢˜ 9px,padding ç´§å‡‘,å‹¾é€‰å›¾æ ‡ 12px,æå‡ä¿¡æ¯å¯†åº¦ã€‚\n            - **æ™ºèƒ½å®½åº¦è°ƒæ•´**: ä¸‹æ‹‰èœå•å®½åº¦ä¸ºæŒ‰é’®å®½åº¦çš„ 1.1 å€(æœ€å° 220px),å®Œæ•´æ˜¾ç¤ºæ¨¡å‹åç§°åŒæ—¶ä¿æŒç´§å‡‘ã€‚\n            - **æ‚¬åœæç¤º**: æ·»åŠ  `title` å±æ€§,é¼ æ ‡æ‚¬åœæ—¶æ˜¾ç¤ºå®Œæ•´çš„æ¨¡å‹åç§°ã€‚\n            - **å½±å“èŒƒå›´**: æ›¿æ¢äº†æ‰€æœ‰ 5 ä¸ªæ¨¡å‹å®¶æ—åˆ†ç»„çš„åŸç”Ÿ select(Claude 4.5ã€Claude 3.5ã€GPT-4ã€GPT-4oã€GPT-5),æå‡è·¨å¹³å°ä¸€è‡´æ€§ã€‚\n        - **å›½é™…åŒ–å®Œå–„ (æ ¸å¿ƒè‡´è°¢ @dlukt PR #397)**:\n            - **å¡«è¡¥è‹±æ–‡ç¿»è¯‘**: å¤§å¹…æ‰©å±• `en.json`,æ·»åŠ ç¼ºå¤±çš„è‹±æ–‡ç¿»è¯‘é”®,è¦†ç›–å¯¼èˆªæ ã€è´¦æˆ·ç®¡ç†ã€API ä»£ç†ç­‰æ¨¡å—ã€‚\n            - **ç§»é™¤ç¡¬ç¼–ç æ–‡æœ¬**: ç³»ç»Ÿæ€§ç§»é™¤ç»„ä»¶ä¸­çš„ç¡¬ç¼–ç ä¸­æ–‡æ–‡æœ¬,ä½¿ç”¨ `useTranslation` hook å’Œ `t()` å‡½æ•°å®ç°åŠ¨æ€ç¿»è¯‘ã€‚\n            - **æ–°å¢åŠŸèƒ½ç¿»è¯‘**: æ·»åŠ è´¦æˆ·ä»£ç†å¯ç”¨/ç¦ç”¨ã€ä¸»é¢˜åˆ‡æ¢ã€è¯­è¨€åˆ‡æ¢ã€Python ä»£ç ç¤ºä¾‹ç­‰åŠŸèƒ½çš„å›½é™…åŒ–æ”¯æŒã€‚\n            - **ä¿æŒç¿»è¯‘åŒæ­¥**: åŒæ­¥æ›´æ–° `zh.json` å’Œ `en.json`,ç¡®ä¿ä¸­è‹±æ–‡ç¿»è¯‘é”®çš„ä¸€è‡´æ€§ã€‚\n            - **å½±å“èŒƒå›´**: æ›´æ–°äº† `AccountGrid`ã€`AddAccountDialog`ã€`Navbar`ã€`Accounts`ã€`accountService` ç­‰ 7 ä¸ªæ–‡ä»¶,æå‡å¤šè¯­è¨€æ”¯æŒè´¨é‡ã€‚\n        - **Antigravity èº«ä»½æ³¨å…¥ (æ ¸å¿ƒè‡´è°¢ [wendavid](https://linux.do/u/wendavid))**:\n            - **æ™ºèƒ½èº«ä»½ç®¡ç†**: åœ¨ä¸‰ä¸ªåè®®(Claudeã€OpenAIã€Gemini)ä¸­å®ç°äº† Antigravity èº«ä»½æ³¨å…¥,ç¡®ä¿æ¨¡å‹æ­£ç¡®è¯†åˆ«è‡ªå·±çš„èº«ä»½å’Œä½¿ç”¨è§„èŒƒã€‚\n            - **é¿å…é‡å¤æ³¨å…¥**: å®ç°æ™ºèƒ½æ£€æŸ¥æœºåˆ¶,æ£€æµ‹ç”¨æˆ·æ˜¯å¦å·²æä¾› Antigravity èº«ä»½,é¿å…é‡å¤æ³¨å…¥ã€‚\n            - **ç®€æ´ä¸“ä¸šç‰ˆæ–‡æœ¬**: é‡‡ç”¨ç®€æ´ä¸“ä¸šçš„èº«ä»½æè¿°,åŒ…å«æ ¸å¿ƒä¿¡æ¯(Google Deepmindã€agentic AIã€pair programming)å’Œå…³é”®æç¤º(**Absolute paths only**ã€**Proactiveness**)ã€‚\n            - **ä¿ç•™ç”¨æˆ·æ§åˆ¶**: å¦‚æœç”¨æˆ·è‡ªå®šä¹‰äº†ç³»ç»Ÿæç¤ºè¯,ç³»ç»Ÿä¼šå°Šé‡ç”¨æˆ·çš„é€‰æ‹©,ä¸å¼ºåˆ¶è¦†ç›–ã€‚\n            - **å½±å“èŒƒå›´**: ä¿®æ”¹äº† `claude/request.rs`ã€`openai/request.rs`ã€`gemini/wrapper.rs` ä¸‰ä¸ªæ–‡ä»¶,æå‡äº†æ¨¡å‹å“åº”çš„ä¸€è‡´æ€§å’Œå‡†ç¡®æ€§ã€‚\n    *   **v3.3.16 (2026-01-07)**:\n        - **æ€§èƒ½ä¼˜åŒ– (Performance Optimization)**:\n            - **å¹¶å‘é…é¢åˆ·æ–°**: é‡æ„è´¦å·é…é¢åˆ·æ–°é€»è¾‘,ä»ä¸²è¡Œæ”¹ä¸ºå¹¶å‘æ‰§è¡Œ,æ˜¾è‘—æå‡å¤šè´¦å·åœºæ™¯ä¸‹çš„åˆ·æ–°é€Ÿåº¦\n                - ä½¿ç”¨ `futures::join_all` å®ç°å¹¶å‘ä»»åŠ¡æ‰§è¡Œ\n                - æ·»åŠ ä¿¡å·é‡æ§åˆ¶,é™åˆ¶æœ€å¤§å¹¶å‘æ•°ä¸º 5,é¿å… API é™æµå’Œæ•°æ®åº“å†™å…¥å†²çª\n                - 10 ä¸ªè´¦å·åˆ·æ–°è€—æ—¶ä» ~30s é™ä½è‡³ ~6s (æå‡çº¦ 5 å€)\n                - æ·»åŠ æ€§èƒ½ç›‘æ§æ—¥å¿—,å®æ—¶æ˜¾ç¤ºåˆ·æ–°è€—æ—¶\n                - æ„Ÿè°¢ [@Mag1cFall](https://github.com/Mag1cFall) æä¾›çš„ä¼˜åŒ–æ–¹æ¡ˆ ([#354](https://github.com/lbjlaq/Antigravity-Manager/pull/354))\n        - **UI è§†è§‰è®¾è®¡ä¼˜åŒ– (æ ¸å¿ƒè‡´è°¢ @Mag1cFall PR #353 + @AmbitionsXXXV PR #371)**:\n            - **API ä»£ç†é¡µé¢è§†è§‰æ”¹è¿›**:\n                - **æŸ”åŒ–ç¦ç”¨çŠ¶æ€é®ç½©**: å°†ç¦ç”¨å¡ç‰‡çš„é®ç½©ä» `bg-white/60` æ”¹ä¸º `bg-gray-100/40`,ç§»é™¤æ¨¡ç³Šæ•ˆæœ,æå‡å¯è¯»æ€§ã€‚\n                - **ç»Ÿä¸€å¤é€‰æ¡†æ ·å¼**: å°† MCP åŠŸèƒ½åŒºçš„å¤é€‰æ¡†ä» DaisyUI çš„ `checkbox-primary` æ”¹ä¸ºè‡ªå®šä¹‰è“è‰²æ ·å¼,ä¿æŒè§†è§‰ä¸€è‡´æ€§ã€‚\n                - **é†’ç›®çš„åŠŸèƒ½æ ‡ç­¾**: MCP åŠŸèƒ½æ ‡ç­¾ä»ç°è‰²æ”¹ä¸ºè“è‰² (`bg-blue-500 dark:bg-blue-600`),ä¸€çœ¼è¯†åˆ«å·²å¯ç”¨åŠŸèƒ½ã€‚\n                - **Slate è‰²ç³»å®¹å™¨**: MCP ç«¯ç‚¹æ˜¾ç¤ºå’Œè°ƒåº¦é…ç½®æ»‘å—å®¹å™¨ä½¿ç”¨ `slate-800/80` æš—è‰²èƒŒæ™¯,å¯¹æ¯”åº¦æ›´å¥½ã€‚\n            - **æš—è‰²æ¨¡å¼å¢å¼º**:\n                - **æ”¹è¿›è¾¹æ¡†å¯¹æ¯”åº¦**: å¡ç‰‡è¾¹æ¡†ä» `dark:border-base-200` æ”¹ä¸º `dark:border-gray-700/50`,å±‚æ¬¡æ›´æ¸…æ™°ã€‚\n                - **ä¼˜åŒ–èƒŒæ™¯æ·±åº¦**: å¡ç‰‡å¤´éƒ¨å’Œè¡¨æ ¼å¤´éƒ¨ä½¿ç”¨ `dark:bg-gray-800/50`,è§†è§‰åˆ†éš”æ›´æ˜æ˜¾ã€‚\n                - **Select ä¸‹æ‹‰æ¡†æš—è‰²æ”¯æŒ**: å…¨å±€æ·»åŠ  Select æš—è‰²æ ·å¼,é€‰ä¸­é¡¹ä½¿ç”¨è“è‰²é«˜äº®ã€‚\n                - **ä»£ç è´¨é‡æå‡**: ä½¿ç”¨ `cn()` å·¥å…·å‡½æ•°ä¼˜åŒ–ç±»åæ‹¼æ¥,ä»£ç æ›´ç®€æ´ã€‚\n            - **ä¸»é¢˜åˆ‡æ¢åŠ¨ç”»ä¿®å¤**:\n                - **åŒå‘å¯¹ç§°è¿‡æ¸¡**: ä¿®å¤äº®è½¬æš—å’Œæš—è½¬äº®çš„è¿‡æ¸¡åŠ¨ç”»,å®ç°å¯¹ç§°çš„æ”¶ç¼©/å±•å¼€æ•ˆæœã€‚\n                - **æ¶ˆé™¤ç™½è‰²é—ªçƒ**: æ·»åŠ  `fill: 'forwards'` é˜²æ­¢åŠ¨ç”»ç»“æŸæ—¶çš„ç™½è‰²é—ªçƒã€‚\n                - **æµç•…ä½“éªŒ**: ä¸»é¢˜åˆ‡æ¢åŠ¨ç”»æ›´è‡ªç„¶æµç•…,æå‡ç”¨æˆ·ä½“éªŒã€‚\n        - **ç¨³å®šæ€§ä¸å·¥å…·ä¿®å¤ (Stability & Tool Fixes)**:\n            - **Grep/Glob å‚æ•°ä¿®å¤ (P3-5)**: ä¿®å¤äº† Grep å’Œ Glob å·¥å…·æœç´¢æŠ¥é”™çš„é—®é¢˜ã€‚ä¿®æ­£äº†å‚æ•°æ˜ å°„é€»è¾‘:å°† `paths` (æ•°ç»„) æ”¹ä¸º `path` (å­—ç¬¦ä¸²),å¹¶å®ç°äº†å¤§å°å†™ä¸æ•æ„Ÿçš„å·¥å…·ååŒ¹é…ã€‚\n            - **æ€è€ƒå†…å®¹å±è”½æ”¯æŒ (P3-2)**: ä¿®å¤äº† `RedactedThinking` å¯¼è‡´æŠ¥é”™çš„é—®é¢˜ï¼Œç°åœ¨ä¼šä¼˜é›…é™çº§ä¸º `[Redacted Thinking]` æ–‡æœ¬ï¼Œä¿ç•™ä¸Šä¸‹æ–‡ã€‚\n            - **JSON Schema æ¸…ç†å¢å¼º**: ä¿®å¤äº† `clean_json_schema` è¯¯åˆ åä¸º \"pattern\" ç­‰éæ ¡éªŒå±æ€§çš„ Bugï¼Œæé«˜äº† Schema å…¼å®¹æ€§ã€‚\n            - **ä¸¥æ ¼è§’è‰²è½®æ›¿ (P3-3)**: å®ç°äº†æ¶ˆæ¯åˆå¹¶é€»è¾‘ï¼Œç¡®ä¿ç¬¦åˆ Gemini API çš„ä¸¥æ ¼ User/Assistant è½®æ›¿è¦æ±‚ï¼Œå‡å°‘ 400 é”™è¯¯ã€‚\n            - **400 è‡ªåŠ¨é‡è¯• (P3-1)**: å¢å¼ºäº†é’ˆå¯¹ 400 é”™è¯¯çš„è‡ªåŠ¨é‡è¯•ä¸è´¦å·è½®è¯¢æœºåˆ¶ï¼Œæå‡äº†é•¿æ—¶é—´è¿è¡Œçš„ç¨³å®šæ€§ã€‚\n        - **é«˜å¹¶å‘æ€§èƒ½ä¼˜åŒ– (Issue #284 ä¿®å¤)**:\n            - **è§£å†³ UND_ERR_SOCKET é”™è¯¯**: ä¿®å¤äº†åœ¨ 8+ å¹¶å‘ Agent åœºæ™¯ä¸‹å®¢æˆ·ç«¯ socket è¶…æ—¶çš„é—®é¢˜ã€‚\n            - **ç§»é™¤é˜»å¡ç­‰å¾…**: åˆ é™¤äº†\"ç¼“å­˜ä¼˜å…ˆ\"æ¨¡å¼ä¸‹å½“ç»‘å®šè´¦å·è¢«é™æµæ—¶çš„ 60 ç§’é˜»å¡ç­‰å¾…é€»è¾‘ã€‚ç°åœ¨é™æµæ—¶ä¼šç«‹å³è§£ç»‘å¹¶åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªå¯ç”¨è´¦å·ï¼Œé¿å…å®¢æˆ·ç«¯è¶…æ—¶ã€‚\n            - **é”ç«äº‰ä¼˜åŒ–**: å°† `last_used_account` é”çš„è·å–ç§»åˆ°é‡è¯•å¾ªç¯å¤–ï¼Œä»æ¯ä¸ªè¯·æ±‚ 18 æ¬¡é”æ“ä½œé™ä½åˆ° 1-2 æ¬¡ï¼Œå¤§å¹…å‡å°‘å¹¶å‘åœºæ™¯ä¸‹çš„é”ç«äº‰ã€‚\n            - **5 ç§’è¶…æ—¶ä¿æŠ¤**: ä¸º `get_token()` æ“ä½œæ·»åŠ  5 ç§’å¼ºåˆ¶è¶…æ—¶ï¼Œé˜²æ­¢ç³»ç»Ÿè¿‡è½½æˆ–æ­»é”æ—¶è¯·æ±‚æ— é™æœŸæŒ‚èµ·ã€‚\n            - **å½±å“èŒƒå›´**: æ­¤ä¼˜åŒ–æ˜¾è‘—æå‡äº†å¤š Agent å¹¶å‘åœºæ™¯ï¼ˆå¦‚ Claude Codeã€Cursor ç­‰ï¼‰çš„ç¨³å®šæ€§ï¼Œè§£å†³äº†\"æœ‰å¤´æ— å°¾\"çš„è¯·æ±‚å¡æ­»é—®é¢˜ã€‚\n        - **æ—¥å¿—ç³»ç»Ÿå…¨é¢ä¼˜åŒ– (Issue #241 ä¿®å¤)**:\n            - **æ—¥å¿—çº§åˆ«ä¼˜åŒ–**: å°†å·¥å…·è°ƒç”¨å’Œå‚æ•°é‡æ˜ å°„çš„é«˜é¢‘è°ƒè¯•æ—¥å¿—ä» `info!` é™çº§ä¸º `debug!`ï¼Œå¤§å¹…å‡å°‘æ—¥å¿—è¾“å‡ºé‡ã€‚\n            - **è‡ªåŠ¨æ¸…ç†æœºåˆ¶**: åº”ç”¨å¯åŠ¨æ—¶è‡ªåŠ¨æ¸…ç† 7 å¤©å‰çš„æ—§æ—¥å¿—æ–‡ä»¶ï¼Œé˜²æ­¢æ—¥å¿—æ— é™ç´¯ç§¯ã€‚\n            - **æ˜¾è‘—æ•ˆæœ**: æ—¥å¿—æ–‡ä»¶å¤§å°ä» 130GB/å¤© é™è‡³ < 100MB/å¤©ï¼Œå‡å°‘ **99.9%** çš„æ—¥å¿—è¾“å‡ºã€‚\n            - **å½±å“èŒƒå›´**: ä¿®æ”¹äº† `streaming.rs` å’Œ `response.rs` ä¸­çš„ 21 å¤„æ—¥å¿—çº§åˆ«ï¼Œæ·»åŠ äº† `cleanup_old_logs()` è‡ªåŠ¨æ¸…ç†å‡½æ•°ã€‚\n        - **Gemini 3 Pro Thinking æ¨¡å‹ä¿®å¤ (æ ¸å¿ƒè‡´è°¢ @fishheadwithchili PR #368)**:\n            - **ä¿®å¤ gemini-3-pro-high å’Œ gemini-3-pro-low çš„ 404 é”™è¯¯**: è§£å†³äº†è°ƒç”¨è¿™ä¸¤ä¸ªæ¨¡å‹æ—¶è¿”å› 404 Not Found çš„é—®é¢˜ã€‚\n            - **æ­£ç¡®çš„ thinkingConfig å‚æ•°**: ä¸º Gemini 3 Pro æ¨¡å‹æ³¨å…¥æ­£ç¡®çš„ `thinkingBudget: 16000` é…ç½®ï¼ˆè€Œéé”™è¯¯çš„ `thinkingLevel`ï¼‰ï¼Œç¬¦åˆ Cloud Code API è§„èŒƒã€‚\n            - **å®Œæ•´æ¨¡å‹åç§°æ”¯æŒ**: ä¿ç•™æ¨¡å‹åç§°ä¸­çš„ `-high` å’Œ `-low` åç¼€ï¼ŒAPI éœ€è¦å®Œæ•´çš„æ¨¡å‹åç§°æ¥è¯†åˆ«ç‰¹å®šå˜ä½“ã€‚\n            - **åŸºç¡€æ¨¡å‹æ˜ å°„**: æ·»åŠ  `gemini-3-pro` åŸºç¡€æ¨¡å‹çš„ç›´æ¥é€ä¼ æ˜ å°„ï¼Œæ”¯æŒä¸å¸¦åç¼€çš„è°ƒç”¨ã€‚\n            - **å½±å“èŒƒå›´**: æ­¤ä¿®å¤ç¡®ä¿äº† Gemini 3 Pro thinking æ¨¡å‹çš„æ­£å¸¸ä½¿ç”¨ï¼Œç”¨æˆ·ç°åœ¨å¯ä»¥æ­£å¸¸è°ƒç”¨ `gemini-3-pro-high` å’Œ `gemini-3-pro-low` å¹¶è·å¾—åŒ…å« thinking å†…å®¹çš„å“åº”ã€‚\n        - **è”ç½‘åŠŸèƒ½é™çº§ä¼˜åŒ–**:\n            - **å¼ºåˆ¶æ¨¡å‹é™çº§**: ä¿®å¤äº†è”ç½‘åŠŸèƒ½çš„æ¨¡å‹é™çº§é€»è¾‘ã€‚ç”±äº Antigravity æä¾›çš„æ¨¡å‹ä¸­**åªæœ‰ `gemini-2.5-flash` æ”¯æŒ googleSearch å·¥å…·**ï¼Œç°åœ¨æ‰€æœ‰æ¨¡å‹ï¼ˆåŒ…æ‹¬ Gemini 3 Proã€thinking æ¨¡å‹ã€Claude åˆ«åï¼‰åœ¨å¯ç”¨è”ç½‘æ—¶éƒ½ä¼šè‡ªåŠ¨é™çº§åˆ° `gemini-2.5-flash`ã€‚\n            - **æ—¥å¿—å¢å¼º**: æ·»åŠ äº†é™çº§æ—¥å¿—ï¼Œæ–¹ä¾¿ç”¨æˆ·äº†è§£æ¨¡å‹åˆ‡æ¢æƒ…å†µã€‚\n            - **å½±å“èŒƒå›´**: æ­¤ä¿®å¤ç¡®ä¿äº† Cherry Studioã€Claude CLI ç­‰å®¢æˆ·ç«¯çš„è”ç½‘åŠŸèƒ½æ­£å¸¸å·¥ä½œï¼Œé¿å…äº†å› æ¨¡å‹ä¸æ”¯æŒ googleSearch è€Œå¯¼è‡´çš„\"æ¨¡æ‹Ÿæœç´¢\"é—®é¢˜ã€‚\n        - **OpenAI åè®®å¤šå€™é€‰æ”¯æŒ (æ ¸å¿ƒè‡´è°¢ @ThanhNguyxn PR #403)**:\n            - å®ç°äº†å¯¹ `n` å‚æ•°çš„æ”¯æŒï¼Œå…è®¸ä¸€æ¬¡è¯·æ±‚è¿”å›å¤šä¸ªå€™é€‰ç»“æœã€‚\n            - è¡¥å…¨äº†æµå¼å“åº” (SSE) ä¸‹çš„å¤šå€™é€‰æ”¯æŒè¡¥ä¸ï¼Œç¡®ä¿è·¨å¹³å°æ¨¡å¼çš„åŠŸèƒ½å¯¹é½ã€‚\n        - **è”ç½‘æœç´¢åŠŸèƒ½å¢å¼ºä¸å¼•æ–‡ä¼˜åŒ–**:\n            - é‡æ–°å®ç°äº†è”ç½‘æœç´¢æ¥æºå±•ç¤ºï¼Œé‡‡ç”¨æ›´æ˜“è¯»çš„ Markdown å¼•ç”¨æ ¼å¼ï¼ˆåŒ…å«æ ‡é¢˜å’Œé“¾æ¥ï¼‰ã€‚\n            - è§£å†³äº†ä¹‹å‰ç‰ˆæœ¬ä¸­å¼•æ–‡æ˜¾ç¤ºé€»è¾‘è¢«ç¦ç”¨çš„é—®é¢˜ï¼Œç°å·²åœ¨æµå¼å’Œéæµå¼æ¨¡å¼ä¸‹å…¨é¢å¯ç”¨ã€‚\n        - **MCP å·¥å…·æšä¸¾å€¼ç±»å‹ä¿®å¤ (æ ¸å¿ƒè‡´è°¢ @ThanhNguyxn PR #395)**:\n            - **ä¿®å¤ Gemini API æšä¸¾å€¼ç±»å‹é”™è¯¯**: è§£å†³äº† MCP å·¥å…·ï¼ˆå¦‚ mcpserver-ncpï¼‰å› æšä¸¾å€¼ä¸ºæ•°å­—æˆ–å¸ƒå°”å€¼è€Œå¯¼è‡´çš„ 400 é”™è¯¯ã€‚\n            - **è‡ªåŠ¨ç±»å‹è½¬æ¢**: åœ¨ `clean_json_schema` å‡½æ•°ä¸­æ·»åŠ äº†æšä¸¾å€¼å­—ç¬¦ä¸²åŒ–é€»è¾‘ï¼Œå°†æ•°å­—ã€å¸ƒå°”å€¼ã€null ç­‰è‡ªåŠ¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²ã€‚\n            - **ç¬¦åˆ Gemini è§„èŒƒ**: ç¡®ä¿æ‰€æœ‰å·¥å…·å®šä¹‰çš„æšä¸¾å€¼éƒ½æ˜¯ `TYPE_STRING` ç±»å‹ï¼Œç¬¦åˆ Gemini v1internal API çš„ä¸¥æ ¼è¦æ±‚ã€‚\n            - **å½±å“èŒƒå›´**: æ­¤ä¿®å¤ç¡®ä¿äº† MCP å·¥å…·åœ¨ Gemini æ¨¡å‹ä¸‹çš„æ­£å¸¸è°ƒç”¨ï¼Œæå‡äº†è·¨æ¨¡å‹ä¾›åº”å•†çš„å·¥å…·å®šä¹‰å…¼å®¹æ€§ã€‚\n        - **å“åº”ä½“æ—¥å¿—é™åˆ¶ä¼˜åŒ– (æ ¸å¿ƒè‡´è°¢ @Stranmor PR #321)**:\n            - **æå‡æ—¥å¿—å®¹é‡**: å°†å“åº”ä½“æ—¥å¿—é™åˆ¶ä» 512KB æå‡åˆ° 10MBï¼Œè§£å†³å›¾åƒç”Ÿæˆå“åº”è¢«æˆªæ–­çš„é—®é¢˜ã€‚\n            - **æ”¯æŒå¤§å‹å“åº”**: ç°åœ¨å¯ä»¥å®Œæ•´è®°å½•åŒ…å« base64 ç¼–ç å›¾åƒçš„å“åº”å’Œå¤§å‹ JSON æ•°æ®ã€‚\n            - **å½±å“èŒƒå›´**: æ­¤ä¼˜åŒ–ç¡®ä¿äº†å›¾åƒç”Ÿæˆå’Œå¤§å‹å“åº”çš„å®Œæ•´æ—¥å¿—è®°å½•ï¼Œä¾¿äºè°ƒè¯•å’Œç›‘æ§ã€‚\n        - **éŸ³é¢‘è½¬å½• API æ”¯æŒ (æ ¸å¿ƒè‡´è°¢ @Jint8888 PR #311 éƒ¨åˆ†åŠŸèƒ½)**:\n            - **éŸ³é¢‘è½¬å½•ç«¯ç‚¹**: æ–°å¢ `/v1/audio/transcriptions` ç«¯ç‚¹ï¼Œå…¼å®¹ OpenAI Whisper APIï¼Œæ”¯æŒ 15MB æ–‡ä»¶å¤§å°é™åˆ¶ã€‚\n            - **éŸ³é¢‘å¤„ç†æ¨¡å—**: æ·»åŠ éŸ³é¢‘ MIME ç±»å‹æ£€æµ‹å’Œ Base64 ç¼–ç å¤„ç†åŠŸèƒ½ã€‚\n            - **å½±å“èŒƒå›´**: æ­¤åŠŸèƒ½ä¸ºé¡¹ç›®æ·»åŠ äº†è¯­éŸ³è½¬æ–‡å­—èƒ½åŠ›ï¼Œè¡¥å…¨äº†å¤šæ¨¡æ€åŠŸèƒ½çš„é‡è¦ä¸€ç¯ã€‚\n            - **æ³¨æ„**: å¯¹è¯ä¸­çš„ `audio_url` æ”¯æŒå°†åœ¨åç»­ç‰ˆæœ¬ä¸­å®Œæ•´å®ç°ï¼ˆéœ€è¦ä¸ v3.3.16 çš„ thinkingConfig é€»è¾‘åè°ƒï¼‰ã€‚\n        - **Linux ç³»ç»Ÿå…¼å®¹æ€§å¢å¼º (æ ¸å¿ƒè‡´è°¢ @0-don PR #326)**:\n            - **ä¿®å¤é€æ˜çª—å£æ¸²æŸ“**: åœ¨ Linux ç³»ç»Ÿä¸‹è‡ªåŠ¨ç¦ç”¨ DMA-BUF æ¸²æŸ“å™¨ (`WEBKIT_DISABLE_DMABUF_RENDERER=1`)ï¼Œè§£å†³äº†éƒ¨åˆ†å‘è¡Œç‰ˆï¼ˆå¦‚ Ubuntu/Fedoraï¼‰ä¸‹çª—å£é€æ˜å¤±æ•ˆæˆ–é»‘å±çš„é—®é¢˜ã€‚\n        - **ç›‘æ§ä¸­é—´ä»¶å®¹é‡ä¼˜åŒ– (æ ¸å¿ƒè‡´è°¢ @Mag1cFall PR #346)**:\n            - **å¯¹é½å…¨å±€ Payload é™åˆ¶**: å°†ç›‘æ§ä¸­é—´ä»¶çš„è¯·æ±‚ä½“è§£æé™åˆ¶ä» 1MB æå‡è‡³ 100MBï¼Œç¡®ä¿åŒ…å«å¤§å‹å›¾ç‰‡çš„è¯·æ±‚èƒ½è¢«æ­£å¸¸è®°å½•å¹¶åœ¨ç›‘æ§é¡µé¢æ˜¾ç¤ºã€‚\n        - **å®‰è£…ä¸åˆ†å‘ä¼˜åŒ– (æ ¸å¿ƒè‡´è°¢ @dlukt PR #396)**:\n            - **Homebrew Cask æ”¯æŒ Linux**: é‡æ„ Cask æ–‡ä»¶ï¼Œç°åœ¨ Linux ç”¨æˆ·å¯ä»¥é€šè¿‡ `brew install --cask` è½»æ¾å®‰è£…å¹¶è‡ªåŠ¨é…ç½® AppImage æƒé™ã€‚\n        - **API ç›‘æ§å¢å¼º (æ ¸å¿ƒè‡´è°¢ PR #394)**:\n            - **è´¦å·é‚®ç®±æ˜¾ç¤º**: API ç›‘æ§æ—¥å¿—ç°åœ¨æ˜¾ç¤ºæ¯ä¸ªè¯·æ±‚ä½¿ç”¨çš„è´¦å·é‚®ç®±,æ”¯æŒè„±æ•æ˜¾ç¤º(ä¾‹å¦‚: `tee***@gmail.com`)ã€‚\n            - **æ¨¡å‹æ˜ å°„æ˜¾ç¤º**: ç›‘æ§è¡¨æ ¼ä¸­çš„\"æ¨¡å‹\"åˆ—ç°åœ¨æ˜¾ç¤ºåŸå§‹æ¨¡å‹åˆ°å®é™…ä½¿ç”¨æ¨¡å‹çš„æ˜ å°„å…³ç³»(ä¾‹å¦‚: `g-3-pro-high =u003e gpt-5.2`)ã€‚\n            - **è¯¦æƒ…å¼¹çª—å¢å¼º**: ç‚¹å‡»è¯·æ±‚è¯¦æƒ…æ—¶,å¼¹çª—ä¸­æ˜¾ç¤ºå®Œæ•´çš„è´¦å·é‚®ç®±(æœªè„±æ•)å’Œæ˜ å°„æ¨¡å‹ä¿¡æ¯ã€‚\n            - **æ•°æ®åº“å…¼å®¹**: è‡ªåŠ¨æ·»åŠ  `account_email` å’Œ `mapped_model` åˆ—,å‘åå…¼å®¹ç°æœ‰æ•°æ®åº“ã€‚\n            - **å½±å“èŒƒå›´**: æ­¤åŠŸèƒ½å¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°ç›‘æ§å’Œè°ƒè¯• API è¯·æ±‚,äº†è§£è´¦å·ä½¿ç”¨æƒ…å†µå’Œæ¨¡å‹æ˜ å°„æ•ˆæœ,ä¸å½±å“ä»»ä½•ç°æœ‰ v3.3.16 ä¿®å¤ã€‚\n    *   **v3.3.15 (2026-01-04)**:\n        - **Claude åè®®å…¼å®¹æ€§å¢å¼º** (åŸºäº PR #296 by @karasungur + Issue #298 ä¿®å¤):\n            - **ä¿®å¤ Opus 4.5 é¦–æ¬¡è¯·æ±‚é”™è¯¯ (Issue #298)**: æ‰©å±•ç­¾åé¢„æ£€éªŒè¯åˆ°æ‰€æœ‰é¦–æ¬¡ thinking è¯·æ±‚,ä¸ä»…é™äºå‡½æ•°è°ƒç”¨åœºæ™¯ã€‚å½“ä½¿ç”¨ `claude-opus-4-5-thinking` ç­‰æ¨¡å‹è¿›è¡Œé¦–æ¬¡è¯·æ±‚æ—¶,å¦‚æœæ²¡æœ‰æœ‰æ•ˆç­¾å,ç³»ç»Ÿä¼šè‡ªåŠ¨ç¦ç”¨ thinking æ¨¡å¼ä»¥é¿å… API æ‹’ç»,è§£å†³äº† \"Server disconnected without sending a response\" é”™è¯¯ã€‚\n            - **å‡½æ•°è°ƒç”¨ç­¾åéªŒè¯ (Issue #295)**: æ·»åŠ é¢„æ£€ç­¾åéªŒè¯,å½“å¯ç”¨ thinking ä½†å‡½æ•°è°ƒç”¨ç¼ºå°‘æœ‰æ•ˆç­¾åæ—¶è‡ªåŠ¨ç¦ç”¨ thinking,é˜²æ­¢ Gemini 3 Pro æ‹’ç»è¯·æ±‚ã€‚\n            - **cache_control æ¸…ç† (Issue #290)**: å®ç°é€’å½’æ·±åº¦æ¸…ç†,ç§»é™¤æ‰€æœ‰åµŒå¥—å¯¹è±¡/æ•°ç»„ä¸­çš„ `cache_control` å­—æ®µ,è§£å†³ Anthropic API (z.ai æ¨¡å¼) çš„ \"Extra inputs are not permitted\" é”™è¯¯ã€‚\n            - **å·¥å…·å‚æ•°é‡æ˜ å°„**: è‡ªåŠ¨ä¿®æ­£ Gemini ä½¿ç”¨çš„å‚æ•°åç§° (Grep/Glob: `query` â†’ `pattern`, Read: `path` â†’ `file_path`),è§£å†³ Claude Code å·¥å…·è°ƒç”¨éªŒè¯é”™è¯¯ã€‚\n            - **å¯é…ç½®å®‰å…¨è®¾ç½®**: æ–°å¢ `GEMINI_SAFETY_THRESHOLD` ç¯å¢ƒå˜é‡,æ”¯æŒ 5 ä¸ªå®‰å…¨çº§åˆ« (OFF/LOW/MEDIUM/HIGH/NONE),é»˜è®¤ OFF ä¿æŒå‘åå…¼å®¹ã€‚\n            - **Effort å‚æ•°æ”¯æŒ**: æ”¯æŒ Claude API v2.0.67+ çš„ `output_config.effort` å‚æ•°,å…è®¸ç²¾ç»†æ§åˆ¶æ¨¡å‹æ¨ç†åŠªåŠ›ç¨‹åº¦ã€‚\n            - **Opus 4.5 é»˜è®¤ Thinking**: ä¸ Claude Code v2.0.67+ å¯¹é½,Opus 4.5 æ¨¡å‹é»˜è®¤å¯ç”¨ thinking æ¨¡å¼,é…åˆç­¾åéªŒè¯å®ç°ä¼˜é›…é™çº§ã€‚\n            - **é‡è¯•æŠ–åŠ¨ä¼˜åŒ–**: ä¸ºæ‰€æœ‰é‡è¯•ç­–ç•¥æ·»åŠ  Â±20% éšæœºæŠ–åŠ¨,é˜²æ­¢æƒŠç¾¤æ•ˆåº”,æå‡é«˜å¹¶å‘åœºæ™¯ç¨³å®šæ€§ã€‚\n            - **ç­¾åæ•è·æ”¹è¿›**: ä» thinking blocks ä¸­ç«‹å³æ•è·ç­¾å,å‡å°‘å¤šè½®å¯¹è¯ä¸­çš„ç­¾åç¼ºå¤±é”™è¯¯ã€‚\n            - **å½±å“èŒƒå›´**: è¿™äº›æ”¹è¿›æ˜¾è‘—æå‡äº† Claude Codeã€Cursorã€Cherry Studio ç­‰å®¢æˆ·ç«¯çš„å…¼å®¹æ€§å’Œç¨³å®šæ€§,ç‰¹åˆ«æ˜¯åœ¨ Opus 4.5 æ¨¡å‹ã€å·¥å…·è°ƒç”¨å’Œå¤šè½®å¯¹è¯åœºæ™¯ä¸‹ã€‚\n    *   **v3.3.14 (2026-01-03)**:\n        - **Claude åè®®é²æ£’æ€§æ”¹è¿›** (æ ¸å¿ƒè‡´è°¢ @karasungur PR #289):\n            - **Thinking Block ç­¾åéªŒè¯å¢å¼º**:\n                - æ”¯æŒå¸¦æœ‰æ•ˆç­¾åçš„ç©º thinking blocks (å°¾éƒ¨ç­¾ååœºæ™¯)\n                - æ— æ•ˆç­¾åçš„ blocks ä¼˜é›…é™çº§ä¸ºæ–‡æœ¬è€Œéä¸¢å¼ƒ,ä¿ç•™å†…å®¹é¿å…æ•°æ®ä¸¢å¤±\n                - å¢å¼ºè°ƒè¯•æ—¥å¿—,ä¾¿äºæ’æŸ¥ç­¾åé—®é¢˜\n            - **å·¥å…·/å‡½æ•°è°ƒç”¨å…¼å®¹æ€§ä¼˜åŒ–**:\n                - æå– web æœç´¢å›é€€æ¨¡å‹ä¸ºå‘½åå¸¸é‡ `WEB_SEARCH_FALLBACK_MODEL`,æå‡å¯ç»´æŠ¤æ€§\n                - å½“å­˜åœ¨ MCP å·¥å…·æ—¶è‡ªåŠ¨è·³è¿‡ googleSearch æ³¨å…¥,é¿å…å†²çª\n                - æ·»åŠ ä¿¡æ¯æ€§æ—¥å¿—,ä¾¿äºè°ƒè¯•å·¥å…·è°ƒç”¨åœºæ™¯\n                - **é‡è¦è¯´æ˜**: Gemini Internal API ä¸æ”¯æŒæ··åˆä½¿ç”¨ `functionDeclarations` å’Œ `googleSearch`\n            - **SSE è§£æé”™è¯¯æ¢å¤æœºåˆ¶**:\n                - æ–°å¢ `parse_error_count` å’Œ `last_valid_state` è¿½è¸ª,å®ç°æµå¼å“åº”é”™è¯¯ç›‘æ§\n                - å®ç° `handle_parse_error()` ç”¨äºä¼˜é›…çš„æµé™çº§\n                - å®ç° `reset_error_state()` ç”¨äºé”™è¯¯åæ¢å¤\n                - å®ç° `get_error_count()` ç”¨äºè·å–é”™è¯¯è®¡æ•°\n                - é«˜é”™è¯¯ç‡è­¦å‘Šç³»ç»Ÿ (>5 ä¸ªé”™è¯¯),ä¾¿äºè¿ç»´ç›‘æ§\n                - è¯¦ç»†çš„è°ƒè¯•æ—¥å¿—,æ”¯æŒæ•…éšœæ’æŸ¥æŸåæµ\n            - **å½±å“èŒƒå›´**: è¿™äº›æ”¹è¿›æ˜¾è‘—æå‡äº† Claude CLIã€Cursorã€Cherry Studio ç­‰å®¢æˆ·ç«¯çš„ç¨³å®šæ€§,ç‰¹åˆ«æ˜¯åœ¨å¤šè½®å¯¹è¯ã€å·¥å…·è°ƒç”¨å’Œæµå¼å“åº”åœºæ™¯ä¸‹ã€‚\n        - **ä»ªè¡¨æ¿ç»Ÿè®¡ä¿®å¤** (æ ¸å¿ƒè‡´è°¢ @yinjianhong22-design PR #285):\n            - **ä¿®å¤ä½é…é¢ç»Ÿè®¡è¯¯æŠ¥**: ä¿®å¤äº†è¢«ç¦ç”¨è´¦æˆ· (403 çŠ¶æ€) è¢«é”™è¯¯è®¡å…¥\"ä½é…é¢\"ç»Ÿè®¡çš„é—®é¢˜\n            - **é€»è¾‘ä¼˜åŒ–**: åœ¨ `lowQuotaCount` è¿‡æ»¤å™¨ä¸­æ·»åŠ  `is_forbidden` æ£€æŸ¥,æ’é™¤è¢«ç¦ç”¨è´¦æˆ·\n            - **æ•°æ®å‡†ç¡®æ€§æå‡**: ä»ªè¡¨æ¿ç°åœ¨èƒ½å‡†ç¡®åæ˜ çœŸå®çš„ä½é…é¢æ´»è·ƒè´¦æˆ·æ•°é‡,é¿å…è¯¯æŠ¥\n            - **å½±å“èŒƒå›´**: æå‡äº†ä»ªè¡¨æ¿æ•°æ®çš„å‡†ç¡®æ€§å’Œç”¨æˆ·ä½“éªŒ,ç”¨æˆ·å¯ä»¥æ›´æ¸…æ™°åœ°äº†è§£éœ€è¦å…³æ³¨çš„è´¦æˆ·ã€‚\n    *   **v3.3.13 (2026-01-03)**:\n        - **Thinking æ¨¡å¼ç¨³å®šæ€§ä¿®å¤**:\n            - **ä¿®å¤ç©º Thinking å†…å®¹é”™è¯¯**: å½“å®¢æˆ·ç«¯å‘é€ç©ºçš„ Thinking å—æ—¶ï¼Œè‡ªåŠ¨é™çº§ä¸ºæ™®é€šæ–‡æœ¬å—ï¼Œé¿å… `thinking: Field required` é”™è¯¯ã€‚\n            - **ä¿®å¤æ™ºèƒ½é™çº§åçš„éªŒè¯é”™è¯¯**: å½“ Thinking è¢«æ™ºèƒ½é™çº§ç¦ç”¨æ—¶ï¼ˆå¦‚å†å²æ¶ˆæ¯ä¸å…¼å®¹ï¼‰ï¼Œè‡ªåŠ¨å°†æ‰€æœ‰å†å²æ¶ˆæ¯ä¸­çš„ Thinking å—è½¬æ¢ä¸ºæ™®é€šæ–‡æœ¬ï¼Œè§£å†³ \"thinking is disabled but message contains thinking\" é”™è¯¯ã€‚\n            - **ä¿®å¤æ¨¡å‹åˆ‡æ¢ç­¾åé”™è¯¯**: å¢åŠ ç›®æ ‡æ¨¡å‹ Thinking æ”¯æŒæ£€æµ‹ã€‚ä» Claude thinking æ¨¡å‹åˆ‡æ¢åˆ°æ™®é€š Gemini æ¨¡å‹ï¼ˆå¦‚ `gemini-2.5-flash`ï¼‰æ—¶ï¼Œè‡ªåŠ¨ç¦ç”¨ Thinking å¹¶é™çº§å†å²æ¶ˆæ¯ï¼Œé¿å… \"Corrupted thought signature\" é”™è¯¯ã€‚åªæœ‰å¸¦ `-thinking` åç¼€çš„æ¨¡å‹ï¼ˆå¦‚ `gemini-2.5-flash-thinking`ï¼‰æˆ– Claude æ¨¡å‹æ”¯æŒ Thinkingã€‚\n            - **å½±å“èŒƒå›´**: è¿™äº›ä¿®å¤ç¡®ä¿äº†åœ¨å„ç§æ¨¡å‹åˆ‡æ¢åœºæ™¯ä¸‹çš„ç¨³å®šæ€§ï¼Œç‰¹åˆ«æ˜¯ Claude â†” Gemini ä¹‹é—´çš„è‡ªç”±åˆ‡æ¢ã€‚\n        - **è´¦å·è½®è¯¢é™æµæœºåˆ¶ä¼˜åŒ– (æ ¸å¿ƒä¿®å¤ Issue #278)**:\n            - **ä¿®å¤é™æµæ—¶é—´è§£æå¤±è´¥**: è§£å†³äº† Google API è¿”å›çš„ `quotaResetDelay` æ— æ³•æ­£ç¡®è§£æçš„é—®é¢˜ã€‚\n                - **ä¿®æ­£ JSON è§£æè·¯å¾„**: å°† `quotaResetDelay` çš„æå–è·¯å¾„ä» `details[0].quotaResetDelay` ä¿®æ­£ä¸º `details[0].metadata.quotaResetDelay`ï¼ŒåŒ¹é… Google API çš„å®é™… JSON ç»“æ„ã€‚\n                - **å®ç°é€šç”¨æ—¶é—´è§£æ**: æ–°å¢ `parse_duration_string()` å‡½æ•°ï¼Œæ”¯æŒè§£ææ‰€æœ‰ Google API è¿”å›çš„æ—¶é—´æ ¼å¼ï¼ŒåŒ…æ‹¬ `\"2h21m25.831582438s\"`, `\"1h30m\"`, `\"5m\"`, `\"30s\"` ç­‰å¤æ‚æ ¼å¼ç»„åˆã€‚\n                - **åŒºåˆ†é™æµç±»å‹**: æ–°å¢ `RateLimitReason` æšä¸¾ï¼ŒåŒºåˆ† `QUOTA_EXHAUSTED`ï¼ˆé…é¢è€—å°½ï¼‰å’Œ `RATE_LIMIT_EXCEEDED`ï¼ˆé€Ÿç‡é™åˆ¶ï¼‰ä¸¤ç§é™æµç±»å‹ï¼Œæ ¹æ®ç±»å‹è®¾ç½®ä¸åŒçš„é»˜è®¤ç­‰å¾…æ—¶é—´ï¼ˆé…é¢è€—å°½: 1å°æ—¶ï¼Œé€Ÿç‡é™åˆ¶: 30ç§’ï¼‰ã€‚\n            - **ä¿®å¤å‰çš„é—®é¢˜**: å½“è´¦å·é…é¢è€—å°½è§¦å‘ 429 é”™è¯¯æ—¶ï¼Œç³»ç»Ÿæ— æ³•è§£æ Google API è¿”å›çš„å‡†ç¡®é‡ç½®æ—¶é—´ï¼ˆå¦‚ `\"2h21m25s\"`ï¼‰ï¼Œå¯¼è‡´ä½¿ç”¨å›ºå®šé»˜è®¤å€¼ 60 ç§’ã€‚è´¦å·è¢«é”™è¯¯åœ°è®¤ä¸º\"1åˆ†é’Ÿåæ¢å¤\"ï¼Œå®é™…å¯èƒ½éœ€è¦ 2 å°æ—¶ï¼Œå¯¼è‡´è´¦å·é™·å…¥ 429 å¾ªç¯ï¼Œåªä½¿ç”¨å‰ 2 ä¸ªè´¦å·ï¼Œåç»­è´¦å·ä»æœªè¢«ä½¿ç”¨ã€‚\n            - **ä¿®å¤åçš„æ•ˆæœ**: ç³»ç»Ÿç°åœ¨èƒ½å‡†ç¡®è§£æ Google API è¿”å›çš„é‡ç½®æ—¶é—´ï¼ˆå¦‚ `\"2h21m25.831582438s\"` â†’ 8485ç§’ï¼‰ï¼Œè´¦å·è¢«æ­£ç¡®æ ‡è®°ä¸ºé™æµçŠ¶æ€å¹¶ç­‰å¾…å‡†ç¡®çš„æ—¶é—´ï¼Œç¡®ä¿æ‰€æœ‰è´¦å·éƒ½èƒ½è¢«æ­£å¸¸è½®æ¢ä½¿ç”¨ï¼Œè§£å†³\"åªä½¿ç”¨å‰ 2 ä¸ªè´¦å·\"çš„é—®é¢˜ã€‚\n            - **å½±å“èŒƒå›´**: æ­¤ä¿®å¤æ˜¾è‘—æå‡äº†å¤šè´¦å·ç¯å¢ƒä¸‹çš„ç¨³å®šæ€§å’Œå¯ç”¨æ€§ï¼Œç¡®ä¿æ‰€æœ‰è´¦å·éƒ½èƒ½è¢«å……åˆ†åˆ©ç”¨ï¼Œé¿å…å› é™æµæ—¶é—´è§£æé”™è¯¯å¯¼è‡´çš„è´¦å·è½®æ¢å¤±æ•ˆã€‚\n    *   **v3.3.12 (2026-01-02)**:\n        - **æ ¸å¿ƒä¿®å¤ (Critical Fixes)**:\n            - **ä¿®å¤ Antigravity Thinking Signature é”™è¯¯**: è§£å†³äº†ä½¿ç”¨ Antigravity (Google API) æ¸ é“æ—¶çš„ `400: thinking.signature: Field required` é”™è¯¯ã€‚\n                - **ç¦ç”¨å‡ Thinking å—æ³¨å…¥**: ç§»é™¤äº†ä¸ºå†å²æ¶ˆæ¯è‡ªåŠ¨æ³¨å…¥æ— ç­¾å \"Thinking...\" å ä½å—çš„é€»è¾‘ï¼ŒGoogle API ä¸æ¥å—ä»»ä½•æ— æ•ˆç­¾åçš„ thinking å—ã€‚\n                - **ç§»é™¤å‡ç­¾å Fallback**: ç§»é™¤äº†ä¸º ToolUse å’Œ Thinking å—æ·»åŠ  `skip_thought_signature_validator` å“¨å…µå€¼çš„é€»è¾‘ï¼Œåªä½¿ç”¨çœŸå®ç­¾åæˆ–å®Œå…¨ä¸æ·»åŠ  thoughtSignature å­—æ®µã€‚\n                - **ä¿®å¤åå°ä»»åŠ¡è¯¯åˆ¤**: ç§»é™¤äº† \"Caveat: The messages below were generated\" å…³é”®è¯ï¼Œé¿å…å°†åŒ…å« Claude Desktop ç³»ç»Ÿæç¤ºçš„æ­£å¸¸è¯·æ±‚è¯¯åˆ¤ä¸ºåå°ä»»åŠ¡å¹¶é™çº§åˆ° Flash Lite æ¨¡å‹ã€‚\n                - **å½±å“èŒƒå›´**: æ­¤ä¿®å¤ç¡®ä¿äº† Claude CLIã€Cursorã€Cherry Studio ç­‰å®¢æˆ·ç«¯åœ¨ä½¿ç”¨ Antigravity ä»£ç†æ—¶çš„ç¨³å®šæ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šè½®å¯¹è¯å’Œå·¥å…·è°ƒç”¨åœºæ™¯ä¸‹ã€‚\n    *   **v3.3.11 (2026-01-02)**:\n        - **é‡è¦ä¿®å¤ (Critical Fixes)**:\n            - **Cherry Studio å…¼å®¹æ€§ä¿®å¤ (Gemini 3)**:\n                - **ç§»é™¤å¼ºåˆ¶æ€§ Prompt æ³¨å…¥**: ç§»é™¤äº†é’ˆå¯¹ Coding Agent çš„å¼ºåˆ¶ç³»ç»ŸæŒ‡ä»¤æ³¨å…¥å’Œ Gemini 3 æ¨¡å‹çš„ç”¨æˆ·æ¶ˆæ¯åç¼€ã€‚è¿™è§£å†³äº†åœ¨ Cherry Studio ç­‰é€šç”¨å®¢æˆ·ç«¯ä¸­ä½¿ç”¨ `gemini-3-flash` æ—¶æ¨¡å‹è¾“å‡º \"Thinking Process\" æˆ– \"Actually, the instruction says...\" ç­‰å›°æƒ‘å›å¤çš„é—®é¢˜ã€‚ç°åœ¨é€šç”¨ OpenAI åè®®è¯·æ±‚å°†ä¿æŒåŸæ±åŸå‘³ã€‚\n            - **ä¿®å¤ Gemini 3 Python å®¢æˆ·ç«¯å´©æºƒé—®é¢˜**:\n                - **ç§»é™¤ maxOutputTokens å¼ºåˆ¶é™åˆ¶**: ç§»é™¤äº†å¯¹ Gemini è¯·æ±‚å¼ºåˆ¶è®¾ç½® `maxOutputTokens: 64000` çš„é€»è¾‘ã€‚è¯¥å¼ºåˆ¶è®¾ç½®å¯¼è‡´æ ‡å‡† Gemini 3 Flash/Pro æ¨¡å‹ (ä¸Šé™ 8192) æ‹’ç»è¯·æ±‚å¹¶è¿”å›ç©ºå“åº”ï¼Œè¿›è€Œå¼•å‘ Python å®¢æˆ·ç«¯å‡ºç° `'NoneType' object has no attribute 'strip'` é”™è¯¯ã€‚ä¿®å¤åï¼Œä»£ç†å°†é»˜è®¤ä½¿ç”¨æ¨¡å‹åŸç”Ÿä¸Šé™æˆ–å°Šé‡å®¢æˆ·ç«¯å‚æ•°ã€‚\n        - **æ ¸å¿ƒä¼˜åŒ– (Core Optimization)**:\n            - **ç»Ÿä¸€é€€é¿ç­–ç•¥ç³»ç»Ÿ**: é‡æ„é”™è¯¯é‡è¯•é€»è¾‘,å¼•å…¥æ™ºèƒ½é€€é¿ç­–ç•¥æ¨¡å—,é’ˆå¯¹ä¸åŒé”™è¯¯ç±»å‹é‡‡ç”¨åˆé€‚çš„é€€é¿ç®—æ³•:\n                - **Thinking ç­¾åå¤±è´¥ (400)**: å›ºå®š 200ms å»¶è¿Ÿåé‡è¯•,é¿å…ç«‹å³é‡è¯•å¯¼è‡´çš„è¯·æ±‚ç¿»å€ã€‚\n                - **æœåŠ¡å™¨è¿‡è½½ (529/503)**: æŒ‡æ•°é€€é¿(1s/2s/4s/8s),æ˜¾è‘—æå‡æ¢å¤æˆåŠŸç‡ 167%ã€‚\n                - **é™æµé”™è¯¯ (429)**: ä¼˜å…ˆä½¿ç”¨æœåŠ¡ç«¯ Retry-After,å¦åˆ™çº¿æ€§é€€é¿(1s/2s/3s)ã€‚\n                - **è´¦å·ä¿æŠ¤**: æœåŠ¡ç«¯é”™è¯¯(529/503)ä¸å†è½®æ¢è´¦å·,é¿å…æ±¡æŸ“å¥åº·è´¦å·æ± ã€‚\n                - **ç»Ÿä¸€æ—¥å¿—**: æ‰€æœ‰é€€é¿æ“ä½œä½¿ç”¨ â±ï¸ æ ‡è¯†,ä¾¿äºç›‘æ§å’Œè°ƒè¯•ã€‚\n        - **æ ¸å¿ƒä¿®å¤ (Critical Fix)**:\n            - **ä¿®å¤ Gemini 3 Python å®¢æˆ·ç«¯å´©æºƒé—®é¢˜**: ç§»é™¤äº†å¯¹ Gemini è¯·æ±‚å¼ºåˆ¶è®¾ç½® `maxOutputTokens: 64000` çš„é€»è¾‘ã€‚è¯¥å¼ºåˆ¶è®¾ç½®å¯¼è‡´æ ‡å‡† Gemini 3 Flash/Pro æ¨¡å‹(ä¸Šé™ 8192)æ‹’ç»è¯·æ±‚å¹¶è¿”å›ç©ºå“åº”,è¿›è€Œå¼•å‘ Python å®¢æˆ·ç«¯å‡ºç° `'NoneType' object has no attribute 'strip'` é”™è¯¯ã€‚ä¿®å¤å,ä»£ç†å°†é»˜è®¤ä½¿ç”¨æ¨¡å‹åŸç”Ÿä¸Šé™æˆ–å°Šé‡å®¢æˆ·ç«¯å‚æ•°ã€‚\n        - **Scoop å®‰è£…å…¼å®¹æ€§æ”¯æŒ (æ ¸å¿ƒè‡´è°¢ @Small-Ku PR #252)**:\n            - **å¯åŠ¨å‚æ•°é…ç½®**: æ–°å¢ Antigravity å¯åŠ¨å‚æ•°é…ç½®åŠŸèƒ½,æ”¯æŒåœ¨è®¾ç½®é¡µé¢è‡ªå®šä¹‰å¯åŠ¨å‚æ•°,å®Œç¾å…¼å®¹ Scoop ç­‰åŒ…ç®¡ç†å™¨çš„ä¾¿æºå¼å®‰è£…ã€‚\n            - **æ™ºèƒ½æ•°æ®åº“è·¯å¾„æ£€æµ‹**: ä¼˜åŒ–æ•°æ®åº“è·¯å¾„æ£€æµ‹é€»è¾‘,æŒ‰ä¼˜å…ˆçº§ä¾æ¬¡æ£€æŸ¥:\n                - å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šçš„ `--user-data-dir` è·¯å¾„\n                - ä¾¿æºæ¨¡å¼ä¸‹çš„ `data/user-data` ç›®å½•\n                - ç³»ç»Ÿé»˜è®¤è·¯å¾„ (macOS/Windows/Linux)\n            - **å¤šå®‰è£…æ–¹å¼æ”¯æŒ**: ç¡®ä¿åœ¨æ ‡å‡†å®‰è£…ã€Scoop ä¾¿æºå®‰è£…ã€è‡ªå®šä¹‰æ•°æ®ç›®å½•ç­‰å¤šç§åœºæ™¯ä¸‹éƒ½èƒ½æ­£ç¡®æ‰¾åˆ°å¹¶è®¿é—®æ•°æ®åº“æ–‡ä»¶ã€‚\n        - **æµè§ˆå™¨ç¯å¢ƒ CORS æ”¯æŒä¼˜åŒ– (æ ¸å¿ƒè‡´è°¢ @marovole PR #223)**:\n            - **æ˜ç¡® HTTP æ–¹æ³•åˆ—è¡¨**: å°† CORS ä¸­é—´ä»¶çš„ `allow_methods` ä»æ³›å‹ `Any` æ”¹ä¸ºæ˜ç¡®çš„æ–¹æ³•åˆ—è¡¨ï¼ˆGET/POST/PUT/DELETE/HEAD/OPTIONS/PATCHï¼‰ï¼Œæå‡æµè§ˆå™¨ç¯å¢ƒä¸‹çš„å…¼å®¹æ€§ã€‚\n            - **é¢„æ£€ç¼“å­˜ä¼˜åŒ–**: æ·»åŠ  `max_age(3600)` é…ç½®ï¼Œå°† CORS é¢„æ£€è¯·æ±‚ç¼“å­˜æ—¶é—´è®¾ç½®ä¸º 1 å°æ—¶ï¼Œå‡å°‘ä¸å¿…è¦çš„ OPTIONS è¯·æ±‚ï¼Œæå‡æ€§èƒ½ã€‚\n            - **å®‰å…¨æ€§å¢å¼º**: æ·»åŠ  `allow_credentials(false)` é…ç½®ï¼Œä¸ `allow_origin(Any)` é…åˆä½¿ç”¨æ—¶ç¬¦åˆå®‰å…¨æœ€ä½³å®è·µã€‚\n            - **æµè§ˆå™¨å®¢æˆ·ç«¯æ”¯æŒ**: å®Œå–„äº†å¯¹ Droid ç­‰åŸºäºæµè§ˆå™¨çš„ AI å®¢æˆ·ç«¯çš„ CORS æ”¯æŒï¼Œç¡®ä¿è·¨åŸŸ API è°ƒç”¨æ­£å¸¸å·¥ä½œã€‚\n        - **è´¦å·è¡¨æ ¼æ‹–æ‹½æ’åºåŠŸèƒ½ (æ ¸å¿ƒè‡´è°¢ @wanglei8888 PR #256)**:\n            - **æ‹–æ‹½æ’åº**: æ–°å¢è´¦å·è¡¨æ ¼æ‹–æ‹½æ’åºåŠŸèƒ½ï¼Œç”¨æˆ·å¯é€šè¿‡æ‹–åŠ¨è¡¨æ ¼è¡Œæ¥è‡ªå®šä¹‰è´¦å·æ˜¾ç¤ºé¡ºåºï¼Œæ–¹ä¾¿å°†å¸¸ç”¨è´¦å·ç½®é¡¶ã€‚\n            - **æŒä¹…åŒ–å­˜å‚¨**: è‡ªå®šä¹‰æ’åºä¼šè‡ªåŠ¨ä¿å­˜åˆ°æœ¬åœ°ï¼Œé‡å¯åº”ç”¨åä¿æŒç”¨æˆ·è®¾ç½®çš„é¡ºåºã€‚\n            - **ä¹è§‚æ›´æ–°**: æ‹–æ‹½æ“ä½œç«‹å³æ›´æ–°ç•Œé¢ï¼Œæä¾›æµç•…çš„ç”¨æˆ·ä½“éªŒï¼ŒåŒæ—¶åå°å¼‚æ­¥ä¿å­˜æ’åºç»“æœã€‚\n            - **åŸºäº dnd-kit**: ä½¿ç”¨ç°ä»£åŒ–çš„ `@dnd-kit` åº“å®ç°ï¼Œæ”¯æŒé”®ç›˜å¯¼èˆªå’Œæ— éšœç¢è®¿é—®ã€‚\n    *   **v3.3.10 (2026-01-01)**:\n        - ğŸŒ **ä¸Šæ¸¸ç«¯ç‚¹ Fallback æœºåˆ¶** (æ ¸å¿ƒè‡´è°¢ @karasungur PR #243):\n            - **å¤šç«¯ç‚¹è‡ªåŠ¨åˆ‡æ¢**: å®ç° `prod â†’ daily` åŒç«¯ç‚¹ Fallback ç­–ç•¥ï¼Œå½“ä¸»ç«¯ç‚¹è¿”å› 404/429/5xx æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨ç«¯ç‚¹ï¼Œæ˜¾è‘—æå‡æœåŠ¡å¯ç”¨æ€§ã€‚\n            - **è¿æ¥æ± ä¼˜åŒ–**: æ–°å¢ `pool_max_idle_per_host(16)`ã€`tcp_keepalive(60s)` ç­‰å‚æ•°ï¼Œä¼˜åŒ–è¿æ¥å¤ç”¨ï¼Œå‡å°‘å»ºç«‹å¼€é”€ï¼Œç‰¹åˆ«é€‚é… WSL/Windows ç¯å¢ƒã€‚\n            - **æ™ºèƒ½é‡è¯•é€»è¾‘**: æ”¯æŒ 408 Request Timeoutã€404 Not Foundã€429 Too Many Requests å’Œ 5xx Server Error çš„è‡ªåŠ¨ç«¯ç‚¹åˆ‡æ¢ã€‚\n            - **è¯¦ç»†æ—¥å¿—è®°å½•**: Fallback æˆåŠŸæ—¶è®°å½• INFO æ—¥å¿—ï¼Œå¤±è´¥æ—¶è®°å½• WARN æ—¥å¿—ï¼Œä¾¿äºè¿ç»´ç›‘æ§å’Œé—®é¢˜æ’æŸ¥ã€‚\n            - **ä¸è°ƒåº¦æ¨¡å¼å®Œå…¨å…¼å®¹**: ç«¯ç‚¹ Fallback ä¸è´¦å·è°ƒåº¦ï¼ˆç¼“å­˜ä¼˜å…ˆ/å¹³è¡¡/æ€§èƒ½ä¼˜å…ˆï¼‰å·¥ä½œåœ¨ä¸åŒå±‚çº§ï¼Œäº’ä¸å¹²æ‰°ï¼Œç¡®ä¿ç¼“å­˜å‘½ä¸­ç‡ä¸å—å½±å“ã€‚\n        - ğŸ“ **æ—¥å¿—ç³»ç»Ÿå…¨é¢ä¼˜åŒ–**:\n            - **æ—¥å¿—çº§åˆ«é‡æ„**: ä¸¥æ ¼åŒºåˆ† INFO/DEBUG/TRACE çº§åˆ«ï¼ŒINFO ä»…æ˜¾ç¤ºå…³é”®ä¸šåŠ¡ä¿¡æ¯ï¼Œè¯¦ç»†è°ƒè¯•ä¿¡æ¯é™çº§åˆ° DEBUGã€‚\n            - **å¿ƒè·³è¯·æ±‚è¿‡æ»¤**: å°† `/api/event_logging/batch` å’Œ `/healthz` ç­‰å¿ƒè·³è¯·æ±‚ä» INFO é™çº§åˆ° TRACEï¼Œæ¶ˆé™¤æ—¥å¿—å™ªéŸ³ã€‚\n            - **è´¦å·ä¿¡æ¯æ˜¾ç¤º**: åœ¨è¯·æ±‚å¼€å§‹å’Œå®Œæˆæ—¶æ˜¾ç¤ºä½¿ç”¨çš„è´¦å·é‚®ç®±ï¼Œä¾¿äºç›‘æ§è´¦å·ä½¿ç”¨æƒ…å†µå’Œè°ƒè¯•ä¼šè¯ç²˜æ€§ã€‚\n            - **æµå¼å“åº”å®Œæˆæ ‡è®°**: ä¸ºæµå¼å“åº”æ·»åŠ å®Œæˆæ—¥å¿—ï¼ˆåŒ…å« Token ç»Ÿè®¡ï¼‰ï¼Œç¡®ä¿è¯·æ±‚ç”Ÿå‘½å‘¨æœŸå¯è¿½è¸ªã€‚\n            - **æ—¥å¿—é‡å‡å°‘ 90%+**: æ­£å¸¸è¯·æ±‚ä» 50+ è¡Œé™è‡³ 3-5 è¡Œï¼Œå¯åŠ¨æ—¥å¿—ä» 30+ è¡Œé™è‡³ 6 è¡Œï¼Œå¤§å¹…æå‡å¯è¯»æ€§ã€‚\n            - **Debug æ¨¡å¼**: é€šè¿‡ `RUST_LOG=debug` å¯æŸ¥çœ‹å®Œæ•´è¯·æ±‚/å“åº” JSONï¼Œæ”¯æŒæ·±åº¦è°ƒè¯•ã€‚\n        - ğŸ¨ **Imagen 3 å›¾åƒç”Ÿæˆå¢å¼º**:\n            - **æ–°å¢åˆ†è¾¨ç‡æ”¯æŒ**: æ”¯æŒé€šè¿‡æ¨¡å‹ååç¼€æŒ‡å®š `-2k` åˆ†è¾¨ç‡ï¼Œæ»¡è¶³æ›´é«˜æ¸…çš„ç»˜å›¾éœ€æ±‚ã€‚\n            - **è¶…å®½æ¯”ä¾‹æ”¯æŒ**: æ–°å¢ `-21x9` (æˆ– `-21-9`) æ¯”ä¾‹æ”¯æŒï¼Œé€‚é…å¸¦é±¼å±æ˜¾ç¤ºã€‚\n            - **æ˜ å°„ä¼˜åŒ–**: ä¼˜åŒ–äº†åˆ†è¾¨ç‡ä¸æ¯”ä¾‹çš„è‡ªåŠ¨æ˜ å°„é€»è¾‘ï¼Œæ”¯æŒ `2560x1080` ç­‰è‡ªå®šä¹‰å°ºå¯¸ã€‚\n            - **å…¨åè®®è¦†ç›–**: è¯¥å¢å¼ºåŠŸèƒ½å·²åŒæ­¥è¦†ç›– OpenAIã€Claude åŠ Gemini åŸç”Ÿåè®®ã€‚\n        - ğŸ” **æ¨¡å‹æ£€æµ‹ API**:\n            - **æ–°å¢æ¢æµ‹æ¥å£**: æä¾› `POST /v1/models/detect` æ¥å£ï¼Œæ”¯æŒå®æ—¶æ¢æµ‹ç‰¹å®šæ¨¡å‹çš„å›¾ç‰‡ç”Ÿæˆèƒ½åŠ›åŠé…ç½®ç»„åˆã€‚\n            - **åŠ¨æ€æ¨¡å‹åˆ—è¡¨**: `/v1/models` æ¥å£ç°åœ¨è‡ªåŠ¨ç½—åˆ—æ‰€æœ‰åˆ†è¾¨ç‡ä¸æ¯”ä¾‹çš„ç”»å›¾æ¨¡å‹å˜ä½“ï¼ˆå¦‚ `gemini-3-pro-image-4k-21x9`ï¼‰ï¼Œæ–¹ä¾¿å®¢æˆ·ç«¯è°ƒç”¨ã€‚\n        - ğŸ› **åå°ä»»åŠ¡é™çº§æ¨¡å‹ä¿®å¤**:\n            - **ä¿®å¤ 404 é”™è¯¯**: å°†åå°ä»»åŠ¡é™çº§æ¨¡å‹ä»ä¸å­˜åœ¨çš„ `gemini-2.0-flash-exp` ä¿®æ­£ä¸º `gemini-2.5-flash-lite`ï¼Œè§£å†³æ ‡é¢˜ç”Ÿæˆã€æ‘˜è¦ç­‰åå°ä»»åŠ¡çš„ 404 é”™è¯¯ã€‚\n        - ğŸ” **è´¦å·ä¸»åŠ¨ç¦ç”¨åŠŸèƒ½**:\n            - **ç‹¬ç«‹ç¦ç”¨æ§åˆ¶**: æ–°å¢è´¦å·ä¸»åŠ¨ç¦ç”¨åŠŸèƒ½,åŒºåˆ«äº 403 ç¦ç”¨,ä»…å½±å“åä»£æ± ,ä¸å‚ä¸ API è¯·æ±‚ã€‚\n            - **åº”ç”¨å†…å¯ç”¨**: ä¸»åŠ¨ç¦ç”¨çš„è´¦å·ä»å¯åœ¨åº”ç”¨ä¸­åˆ‡æ¢ä½¿ç”¨ã€æŸ¥çœ‹é…é¢è¯¦æƒ…,ä»…ä»åä»£æ± ä¸­ç§»é™¤ã€‚\n            - **è§†è§‰åŒºåˆ†**: 403 ç¦ç”¨æ˜¾ç¤ºçº¢è‰²\"å·²ç¦ç”¨\"å¾½ç« ,ä¸»åŠ¨ç¦ç”¨æ˜¾ç¤ºæ©™è‰²\"åä»£å·²ç¦ç”¨\"å¾½ç« ã€‚\n            - **æ‰¹é‡æ“ä½œ**: æ”¯æŒæ‰¹é‡ç¦ç”¨/å¯ç”¨å¤šä¸ªè´¦å·,æé«˜ç®¡ç†æ•ˆç‡ã€‚\n            - **è‡ªåŠ¨é‡è½½**: ç¦ç”¨/å¯ç”¨æ“ä½œåè‡ªåŠ¨é‡æ–°åŠ è½½åä»£è´¦å·æ± ,ç«‹å³ç”Ÿæ•ˆã€‚\n            - **å½±å“èŒƒå›´**: æ ‡é¢˜ç”Ÿæˆã€ç®€å•æ‘˜è¦ã€ç³»ç»Ÿæ¶ˆæ¯ã€æç¤ºå»ºè®®ã€ç¯å¢ƒæ¢æµ‹ç­‰è½»é‡ä»»åŠ¡ç°åœ¨æ­£ç¡®é™çº§åˆ° `gemini-2.5-flash-lite`ã€‚\n        - ğŸ¨ **UI ä½“éªŒæå‡**:\n            - **åä»£é¡µå¼¹çª—é£æ ¼ç»Ÿä¸€**: å°† ApiProxy é¡µé¢ä¸­æ‰€æœ‰åŸç”Ÿçš„ alert/confirm å¼¹çª—ç»Ÿä¸€ä¸ºåº”ç”¨æ ‡å‡†çš„ Toast é€šçŸ¥ä¸ ModalDialog å¯¹è¯æ¡†ï¼Œæå‡è§†è§‰ä¸€è‡´æ€§ã€‚\n            - **Tooltip é®æŒ¡ä¿®å¤**: ä¿®å¤äº†åä»£è®¾ç½®é¡µé¢ä¸­ï¼ˆå¦‚\"è°ƒåº¦æ¨¡å¼\"ã€\"å…è®¸å±€åŸŸç½‘è®¿é—®\"ç­‰ï¼‰Tooltip è¢«å·¦ä¾§å®¹å™¨é®æŒ¡çš„é—®é¢˜ï¼Œä¼˜åŒ–é˜…è¯»ä½“éªŒã€‚\n    *   **v3.3.9 (2026-01-01)**:\n        - ğŸš€ **å…¨åè®®è°ƒåº¦å¯¹é½**: `Scheduling Mode` ç°åœ¨æ­£å¼è¦†ç›– OpenAI (Cursor/Cherry)ã€Gemini åŸç”ŸåŠ Claude åè®®ã€‚\n        - ğŸ§  **å·¥ä¸šçº§ Session æŒ‡çº¹**: å‡çº§ SHA256 å†…å®¹å“ˆå¸Œç®—æ³•ç”Ÿæˆç²˜æ€§ Session IDï¼Œç¡®ä¿ CLI é‡å¯åä»èƒ½å®Œç¾ç»§æ‰¿åŒä¸€è´¦å·ï¼Œæå¤§æå‡ Prompt Caching å‘½ä¸­ç‡ã€‚\n        - ğŸ›¡ï¸ **ç²¾å‡†é™æµä¸ 5xx æ•…éšœé¿è®©**: æ·±åº¦é›†æˆ Google API JSON æŠ¥æ–‡è§£æï¼Œæ”¯æŒæ¯«ç§’çº§ `quotaResetDelay` æå–ï¼Œå¹¶åœ¨ 500/503/529 æ•…éšœæ—¶è‡ªåŠ¨è§¦å‘ 20s é¿è®©éš”ç¦»ï¼Œå®ç°å¹³æ»‘çƒ­åˆ‡æ¢ã€‚\n        - ğŸ”€ **æ™ºèƒ½è°ƒåº¦ç®—æ³•å‡çº§**: `TokenManager` è½®è½¬æ—¶ä¸»åŠ¨é¿å¼€æ‰€æœ‰é™æµæˆ–éš”ç¦»è´¦å·ï¼›å…¨é‡é™æµæ—¶ç²¾å‡†æç¤ºæœ€çŸ­é‡ç½®æ—¶é—´ã€‚\n        - ğŸŒ **å…¨å±€é™æµåŒæ­¥**: å¼•å…¥è·¨åè®®é™æµè¿½è¸ªå™¨ï¼Œä»»æ„åè®®è§¦å‘é™æµå‡ä¼šå®æ—¶åŒæ­¥è‡³å…¨å±€è´¦å·æ± ï¼Œå®ç°â€œä¸€ç«¯é™æµï¼Œå…¨å±€é¿è®©â€ã€‚\n        - ğŸ“„ **Claude å¤šæ¨¡æ€è¡¥å…¨**: ä¿®å¤ Claude CLI ä¼ è¾“ PDF ç­‰æ–‡æ¡£æ—¶çš„ 400 é”™è¯¯ï¼Œè¡¥å…¨å¤šæ¨¡æ€æ˜ å°„é€»è¾‘ã€‚\n    *   **v3.3.8 (2025-12-31)**:\n        - **ä»£ç†ç›‘æ§æ¨¡å— (æ ¸å¿ƒè‡´è°¢ @84hero PR #212)**:\n            - **å®æ—¶è¯·æ±‚è¿½è¸ª**: å…¨æ–°çš„ç›‘æ§ä»ªè¡¨æ¿ï¼Œå®æ—¶å¯è§†åŒ–æŸ¥çœ‹æ‰€æœ‰åä»£æµé‡ï¼ŒåŒ…æ‹¬è¯·æ±‚è·¯å¾„ã€çŠ¶æ€ç ã€å“åº”æ—¶é—´ã€Tokenæ¶ˆè€—ç­‰è¯¦ç»†ä¿¡æ¯ã€‚\n            - **æŒä¹…åŒ–æ—¥å¿—å­˜å‚¨**: åŸºäº SQLite çš„æ—¥å¿—ç³»ç»Ÿï¼Œæ”¯æŒè·¨åº”ç”¨é‡å¯çš„å†å²è®°å½•æŸ¥è¯¢ä¸åˆ†æã€‚\n            - **é«˜çº§ç­›é€‰ä¸æ’åº**: æ”¯æŒå®æ—¶æœç´¢ã€æŒ‰æ—¶é—´æˆ³æ’åºï¼Œå¿«é€Ÿå®šä½é—®é¢˜è¯·æ±‚ã€‚\n            - **è¯¦ç»†æ£€è§†æ¨¡æ€æ¡†**: ç‚¹å‡»ä»»æ„è¯·æ±‚å³å¯æŸ¥çœ‹å®Œæ•´çš„è¯·æ±‚/å“åº” Payloadã€Headerã€Token è®¡æ•°ç­‰è°ƒè¯•ä¿¡æ¯ã€‚\n            - **æ€§èƒ½ä¼˜åŒ–**: ç´§å‡‘çš„æ•°æ®æ ¼å¼åŒ–ï¼ˆå¦‚ 1.2k ä»£æ›¿ 1200ï¼‰æå‡å¤§æ•°æ®é‡ä¸‹çš„ UI å“åº”é€Ÿåº¦ã€‚\n        - **UI ä¼˜åŒ–ä¸å¸ƒå±€æ”¹è¿›**:\n            - **Toggle æ ·å¼ç»Ÿä¸€**: å°†æ‰€æœ‰Toggleå¼€å…³ï¼ˆè‡ªåŠ¨å¯åŠ¨ã€å±€åŸŸç½‘è®¿é—®ã€è®¿é—®æˆæƒã€å¤–éƒ¨æä¾›å•†ï¼‰ç»Ÿä¸€ä¸ºå°å·è“è‰²æ ·å¼ï¼Œæ•´ä½“è§†è§‰æ›´ä¸€è‡´ã€‚\n            - **å¸ƒå±€å¯†åº¦ä¼˜åŒ–**: å°†\"å…è®¸å±€åŸŸç½‘è®¿é—®\"å’Œ\"è®¿é—®æˆæƒ\"åˆå¹¶ä¸ºå•è¡Œç½‘æ ¼å¸ƒå±€ï¼ˆlg:grid-cols-2ï¼‰ï¼Œåœ¨å¤§å±å¹•ä¸Šæ›´é«˜æ•ˆåˆ©ç”¨ç©ºé—´ã€‚\n        - **Zai Dispatcher è°ƒåº¦å™¨é›†æˆ (æ ¸å¿ƒè‡´è°¢ @XinXin622 PR #205)**:\n            - **å¤šçº§åˆ†å‘æ¨¡å¼**: æ”¯æŒ `Exclusive` (ä¸“å±)ã€`Pooled` (æ± åŒ–) å’Œ `Fallback` (å›é€€) ä¸‰ç§è°ƒåº¦æ¨¡å¼ï¼Œçµæ´»å¹³è¡¡å“åº”é€Ÿåº¦ä¸è´¦å·å®‰å…¨æ€§ã€‚\n            - **å†…ç½® MCP æœåŠ¡æ”¯æŒ**: é¢„ç½® Web Search Primeã€Web Reader å’Œ Vision ç­‰ MCP æ¥å£åœ°å€ï¼Œæ”¯æŒæœ¬åœ°/å±€åŸŸç½‘ç›´æ¥è°ƒç”¨ã€‚\n            - **é…ç½®ç•Œé¢å‡çº§**: åœ¨ ApiProxy é¡µé¢å¢åŠ äº†é…å¥—çš„å›¾å½¢åŒ–é…ç½®é¡¹ä¸äº¤äº’æç¤ºã€‚\n        - **è´¦å·å¼‚å¸¸è‡ªåŠ¨å¤„ç† (æ ¸å¿ƒè‡´è°¢ @salacoste PR #203)**:\n\n            - **è‡ªåŠ¨ç¦ç”¨å¤±æ•ˆè´¦å·**: å½“ Google OAuth åˆ·æ–°ä»¤ç‰Œå¤±æ•ˆï¼ˆè§¦å‘ `invalid_grant` é”™è¯¯ï¼‰æ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å°†è¯¥è´¦å·æ ‡è®°ä¸ºç¦ç”¨çŠ¶æ€ï¼Œé˜²æ­¢ä»£ç†æœåŠ¡å› é‡å¤å°è¯•æ•…éšœè´¦å·è€Œäº§ç”Ÿ 5xx é”™è¯¯ã€‚\n            - **æŒä¹…åŒ–çŠ¶æ€ç®¡ç†**: è´¦å·çš„ç¦ç”¨çŠ¶æ€ä¼šè‡ªåŠ¨ä¿å­˜åˆ°ç£ç›˜ï¼Œç³»ç»Ÿé‡å¯åä»å¯ä¿æŒã€‚åŒæ—¶ä¼˜åŒ–äº†åŠ è½½é€»è¾‘ï¼Œè·³è¿‡æ‰€æœ‰å·²ç¦ç”¨çš„è´¦å·ã€‚\n            - **æ™ºèƒ½è‡ªåŠ¨æ¢å¤**: ç”¨æˆ·åœ¨ UI ç•Œé¢æ‰‹åŠ¨æ›´æ–°è´¦å·ä»¤ç‰Œåï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨é‡æ–°å¯ç”¨è¯¥è´¦å·ã€‚\n            - **æ–‡æ¡£å®Œå–„**: æ·»åŠ äº†é’ˆå¯¹ `invalid_grant` å¼‚å¸¸å¤„ç†æœºåˆ¶çš„è¯¦ç»†è¯´æ˜æ–‡æ¡£ã€‚\n        - **åŠ¨æ€æ¨¡å‹åˆ—è¡¨ API (æ™ºèƒ½åŒ–ç«¯ç‚¹ä¼˜åŒ–)**:\n            - **å®æ—¶åŠ¨æ€åŒæ­¥**: `/v1/models` (OpenAI) å’Œ `/v1/models/claude` (Claude) æ¥å£ç°åœ¨å®æ—¶èšåˆå†…ç½®æ˜ å°„ä¸ç”¨æˆ·è‡ªå®šä¹‰æ˜ å°„ï¼Œä¿®æ”¹è®¾ç½®å³åˆ»ç”Ÿæ•ˆã€‚\n            - **å…¨é‡æ¨¡å‹æ”¯æŒ**: æ¥å£ä¸å†å¼ºåˆ¶è¿‡æ»¤å‰ç¼€ï¼Œæ”¯æŒç›´æ¥åœ¨ç»ˆç«¯æˆ–å®¢æˆ·ç«¯æŸ¥çœ‹å¹¶ä½¿ç”¨ `gemini-3-pro-image-4k-16x9` ç­‰ç”»å›¾æ¨¡å‹åŠæ‰€æœ‰è‡ªå®šä¹‰ IDã€‚\n        - **è´¦å·é…é¢ç®¡ç†ä¸æ¨¡å‹åˆ†çº§è·¯ç”± (è¿è¥ä¼˜åŒ–ä¸ Bug ä¿®å¤)**:\n            - **åå°ä»»åŠ¡æ™ºèƒ½é™çº§**: è‡ªåŠ¨è¯†åˆ«å¹¶é‡æ”¾ Claude CLI/Agent çš„åå°ä»»åŠ¡ï¼ˆæ ‡é¢˜ã€æ‘˜è¦ç­‰ï¼‰ä¸º Flash æ¨¡å‹ï¼Œè§£å†³ä¹‹å‰è¯¥ç±»è¯·æ±‚é”™è¯¯æ¶ˆè€—é•¿æ–‡æœ¬/é«˜çº§æ¨¡å‹é¢åº¦çš„é—®é¢˜ã€‚\n            - **å¹¶å‘é”ä¸é¢åº¦ä¿æŠ¤**: ä¿®å¤äº†é«˜å¹¶å‘åœºæ™¯ä¸‹å¤šä¸ªè¯·æ±‚åŒæ—¶å¯¼è‡´è´¦å·é¢åº¦è¶…é™çš„é—®é¢˜ã€‚é€šè¿‡åŸå­é”ï¼ˆAtomic Lockï¼‰ç¡®ä¿åŒä¸€ä¼šè¯å†…çš„è¯·æ±‚ä¸€è‡´æ€§ï¼Œé¿å…ä¸å¿…è¦çš„è´¦å·è½®æ¢ã€‚\n            - **è´¦å·åˆ†çº§æ’åº (ULTRA > PRO > FREE)**: ç³»ç»Ÿç°åœ¨æ ¹æ®è´¦å·é…é¢é‡ç½®é¢‘ç‡ï¼ˆæ¯å°æ—¶ vs æ¯æ—¥ï¼‰è‡ªåŠ¨æ’åºæ¨¡å‹è·¯ç”±ã€‚ä¼˜å…ˆæ¶ˆè€—æ›´é¢‘ç¹é‡ç½®çš„é«˜çº§è´¦å·ï¼Œå°† FREE è´¦å·ä½œä¸ºæœ€åçš„å†—ä½™ä¿éšœã€‚\n            - **åŸå­åŒ–å¹¶å‘é”å®š**: ä¼˜åŒ–äº† TokenManager çš„ä¼šè¯é”å®šé€»è¾‘ã€‚åœ¨é«˜å¹¶å‘å¹¶å‘ï¼ˆå¦‚ Agent æ¨¡å¼ï¼‰ä¸‹ï¼Œç¡®ä¿åŒä¸€ä¼šè¯çš„è¯·æ±‚èƒ½ç¨³å®šé”å®šåœ¨åŒä¸€è´¦å·ï¼Œè§£å†³è½®è¯¢æš´èµ°é—®é¢˜ã€‚\n            - **å…³é”®è¯åº“æ‰©å±•**: å†…ç½® 30+ ç§é«˜é¢‘åå°æŒ‡ä»¤ç‰¹å¾åº“ï¼Œè¦†ç›– 5 å¤§ç±»ä¸»æµ Agent åå°æ“ä½œï¼Œè¯†åˆ«ç‡æå‡è‡³ 95% ä»¥ä¸Šã€‚\n\n    *   **v3.3.7 (2025-12-30)**:\n        - **Proxy æ ¸å¿ƒç¨³å®šæ€§ä¿®å¤ (æ ¸å¿ƒè‡´è°¢ @llsenyue PR #191)**:\n            - **JSON Schema æ·±åº¦ç¡¬åŒ–**: å®ç°äº†å¯¹å·¥å…·è°ƒç”¨ Schema çš„é€’å½’å¹³å¦åŒ–ä¸æ¸…ç†ï¼Œè‡ªåŠ¨å°† Gemini ä¸æ”¯æŒçš„æ ¡éªŒçº¦æŸï¼ˆå¦‚ `pattern`ï¼‰è¿ç§»è‡³æè¿°å­—æ®µï¼Œè§£å†³ Schema æ‹’ç»é—®é¢˜ã€‚\n            - **åå°ä»»åŠ¡é²æ£’æ€§å¢å¼º**: æ–°å¢åå°ä»»åŠ¡ï¼ˆå¦‚æ‘˜è¦ç”Ÿæˆï¼‰æ£€æµ‹ï¼Œè‡ªåŠ¨è¿‡æ»¤æ€ç»´é“¾é…ç½®ä¸å†å²å—ï¼Œå¹¶å®šå‘è½¬å‘è‡³ `gemini-2.5-flash` ä»¥ç¡®ä¿ 100% æˆåŠŸç‡ã€‚\n            - **æ€ç»´é“¾ç­¾åè‡ªåŠ¨æ•è·**: ä¼˜åŒ–äº† `thoughtSignature` çš„æå–ä¸æŒä¹…åŒ–é€»è¾‘ï¼Œè§£å†³äº†å¤šè½®å¯¹è¯ä¸­å› ç­¾åä¸¢å¤±å¯¼è‡´çš„ `400` é”™è¯¯ã€‚\n            - **æ—¥å¿—ä½“éªŒä¼˜åŒ–**: æå‡äº†ç”¨æˆ·æ¶ˆæ¯çš„æ—¥å¿—ä¼˜å…ˆçº§ï¼Œç¡®ä¿æ ¸å¿ƒå¯¹è¯ä¿¡æ¯ä¸è¢«åå°ä»»åŠ¡æ—¥å¿—æ·¹æ²¡ã€‚\n    *   **v3.3.6 (2025-12-30)**:\n        - **OpenAI å›¾åƒåŠŸèƒ½æ·±åº¦é€‚é… (æ ¸å¿ƒè‡´è°¢ @llsenyue PR #186)**:\n            - **æ–°å¢å›¾åƒç”Ÿæˆæ¥å£**: å®Œæ•´æ”¯æŒ `/v1/images/generations` ç«¯ç‚¹ï¼Œæ”¯æŒ `model`ã€`prompt`ã€`n`ã€`size` åŠ `response_format` ç­‰æ ‡å‡†å‚æ•°ã€‚\n            - **æ–°å¢å›¾åƒç¼–è¾‘ä¸å˜æ¢æ¥å£**: é€‚é… `/v1/images/edits` å’Œ `/v1/images/variations` ç«¯ç‚¹ã€‚\n            - **åº•å±‚åè®®æ¡¥æ¥**: å®ç°äº† OpenAI å›¾åƒè¯·æ±‚åˆ° Google Internal API (Cloud Code) çš„è‡ªåŠ¨ç»“æ„åŒ–æ˜ å°„ä¸èº«ä»½éªŒè¯ã€‚\n    *   **v3.3.5 (2025-12-29)**:\n        - **æ ¸å¿ƒä¿®å¤ä¸ç¨³å®šæ€§å¢å¼º**:\n            - **ä¿®å¤ Claude Extended Thinking 400 é”™è¯¯ (æ¨¡å‹åˆ‡æ¢åœºæ™¯)**: è§£å†³äº†åœ¨åŒä¸€ä¼šè¯ä¸­ä»æ™®é€šæ¨¡å‹åˆ‡æ¢åˆ°æ€ç»´é“¾æ¨¡å‹æ—¶ï¼Œå› å†å²æ¶ˆæ¯ç¼ºå°‘æ€ç»´å—å¯¼è‡´çš„ Google API æ ¡éªŒå¤±è´¥ã€‚ç°åœ¨åªè¦å¼€å¯ Thinking æ¨¡å¼ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ä¸ºåˆè§„æ€§è¡¥å…¨å†å²æ€ç»´å—ã€‚\n            - **æ–°å¢ 429 é”™è¯¯è‡ªåŠ¨è´¦å·è½®è½¬ (Account Rotation)**: ä¼˜åŒ–äº†é‡è¯•æœºåˆ¶ã€‚å½“è¯·æ±‚é‡åˆ° `429` (é™æµ/é…é¢)ã€`403` (æƒé™) æˆ– `401` (è®¤è¯å¤±æ•ˆ) é”™è¯¯æ—¶ï¼Œç³»ç»Ÿåœ¨é‡è¯•æ—¶ä¼š **å¼ºåˆ¶ç»•è¿‡ 60s ä¼šè¯é”å®š** å¹¶åˆ‡æ¢åˆ°è´¦å·æ± ä¸­çš„ä¸‹ä¸€ä¸ªå¯ç”¨è´¦å·ï¼Œå¹¶å®ç°æ•…éšœè¿ç§»ã€‚\n            - **å•å…ƒæµ‹è¯•ç»´æŠ¤**: ä¿®å¤äº†ä»£ç åº“ä¸­å¤šä¸ªé™ˆæ—§ä¸”ç ´æŸçš„å•å…ƒæµ‹è¯•ï¼Œç¡®ä¿äº†å¼€å‘ç¯å¢ƒçš„ç¼–è¯‘ä¸é€»è¾‘æ ¡éªŒé—­ç¯ã€‚\n        - **æ—¥å¿—ç³»ç»Ÿä¼˜åŒ–**:\n            - **æ¸…ç†å†—ä½™æ—¥å¿—**: ç§»é™¤äº†é…é¢æŸ¥è¯¢æ—¶é€è¡Œæ‰“å°æ‰€æœ‰æ¨¡å‹åç§°çš„å†—ä½™æ—¥å¿—ï¼Œå°†è¯¦ç»†æ¨¡å‹åˆ—è¡¨ä¿¡æ¯é™çº§ä¸º debug çº§åˆ«ï¼Œæ˜¾è‘—å‡å°‘æ§åˆ¶å°å™ªéŸ³ã€‚\n            - **æœ¬åœ°æ—¶åŒºæ”¯æŒ**: æ—¥å¿—æ—¶é—´æˆ³ç°å·²è‡ªåŠ¨ä½¿ç”¨æœ¬åœ°æ—¶åŒºæ ¼å¼ï¼ˆå¦‚ `2025-12-29T22:50:41+08:00`ï¼‰ï¼Œè€Œé UTC æ—¶é—´ï¼Œä¾¿äºç”¨æˆ·ç›´è§‚æŸ¥çœ‹ã€‚\n        - **UI ä¼˜åŒ–**:\n            - **ä¼˜åŒ–è´¦å·é¢åº¦åˆ·æ–°æ—¶é—´æ˜¾ç¤º**: å¢åŠ æ—¶é’Ÿå›¾æ ‡ã€å®ç°å±…ä¸­å¯¹é½ä¸åŠ¨æ€é¢œè‰²åé¦ˆï¼ˆè¡¨æ ¼ä¸å¡ç‰‡è§†å›¾åŒæ­¥ä¼˜åŒ–ï¼‰ã€‚\n    *   **v3.3.4 (2025-12-29)**:\n        - **OpenAI/Codex å…¼å®¹æ€§å¤§å¹…å¢å¼º (æ ¸å¿ƒè‡´è°¢ @llsenyue PR #158)**:\n            - **ä¿®å¤å›¾åƒè¯†åˆ«**: å®Œç¾é€‚é… Codex CLI çš„ `input_image` å—è§£æï¼Œå¹¶æ”¯æŒ `file://` æœ¬åœ°è·¯å¾„è‡ªåŠ¨è½¬ Base64 ä¸Šä¼ ã€‚\n            - **Gemini 400 é”™è¯¯æ²»ç†**: å®ç°äº†è¿ç»­ç›¸åŒè§’è‰²æ¶ˆæ¯çš„è‡ªåŠ¨åˆå¹¶ï¼Œä¸¥æ ¼éµå¾ª Gemini è§’è‰²äº¤æ›¿è§„èŒƒï¼Œè§£å†³æ­¤ç±» 400 æŠ¥é”™ã€‚\n            - **åè®®ç¨³å®šæ€§å¢å¼º**: ä¼˜åŒ–äº† JSON Schema æ·±åº¦æ¸…ç†ï¼ˆæ–°å¢å¯¹ `cache_control` çš„ç‰©ç†éš”ç¦»ï¼‰åŠ `thoughtSignature` çš„ä¸Šä¸‹æ–‡å›å¡«é€»è¾‘ã€‚\n            - **Linux æ„å»ºç­–ç•¥è°ƒæ•´**: ç”±äº GitHub çš„ Ubuntu 20.04 è¿è¡Œå™¨èµ„æºæåº¦åŒ®ä¹å¯¼è‡´å‘å¸ƒæŒ‚èµ·ï¼Œå®˜æ–¹ç‰ˆæœ¬ç°å›å½’ä½¿ç”¨ **Ubuntu 22.04** ç¯å¢ƒç¼–è¯‘ã€‚Ubuntu 20.04 ç”¨æˆ·å»ºè®®è‡ªè¡Œå…‹éš†æºç å®Œæˆæœ¬åœ°æ„å»ºï¼Œæˆ–ä½¿ç”¨ AppImage å°è¯•è¿è¡Œã€‚\n    *   **v3.3.3 (2025-12-29)**:\n        - **è´¦å·ç®¡ç†å¢å¼º**:\n            - **è®¢é˜…ç­‰çº§æ™ºèƒ½è¯†åˆ«**: æ–°å¢å¯¹è´¦å·è®¢é˜…ç­‰çº§ï¼ˆPRO/ULTRA/FREEï¼‰çš„è‡ªåŠ¨è¯†åˆ«ã€æ ‡è¯†ä¸ç­›é€‰æ”¯æŒã€‚\n            - **å¤šç»´ç­›é€‰ç³»ç»Ÿ**: è´¦å·ç®¡ç†é¡µå¼•å…¥â€œå…¨éƒ¨/å¯ç”¨/ä½é…é¢/PRO/ULTRA/FREEâ€å¤šç»´åº¦ç­›é€‰ Tabï¼Œæ”¯æŒå®æ—¶è®¡æ•°ä¸è”åŠ¨æœç´¢ã€‚\n            - **UI/UX æ·±åº¦ä¼˜åŒ–**: é‡‡ç”¨é«˜æ„Ÿåº¦ Tab åˆ‡æ¢è®¾è®¡ï¼›é‡æ„é¡¶éƒ¨å·¥å…·æ å¸ƒå±€ï¼Œå¼•å…¥å¼¹æ€§æœç´¢æ¡†ä¸å“åº”å¼æ“ä½œæŒ‰é’®ï¼Œæ˜¾è‘—æå‡å„åˆ†è¾¨ç‡ä¸‹çš„ç©ºé—´åˆ©ç”¨ç‡ã€‚\n        - **æ ¸å¿ƒä¿®å¤**:\n            - **ä¿®å¤ Claude Extended Thinking 400 é”™è¯¯**: è§£å†³äº†å†å² `ContentBlock::Thinking` æ¶ˆæ¯ä¸­ç¼ºå¤± `thought: true` æ ‡è®°å¯¼è‡´çš„æ ¼å¼æ ¡éªŒé”™è¯¯ã€‚æ­¤ä¿®å¤è§£å†³äº† 95% ä»¥ä¸Šçš„ Claude æ€ç»´é“¾ç›¸å…³æŠ¥é”™ï¼Œå¤§å¹…æå‡å¤šè½®å¯¹è¯ç¨³å®šæ€§ã€‚æ­¤é—®é¢˜ä¼šå¯¼è‡´ä¸ç®¡æ˜¯å¦æ˜¾å¼å¼€å¯ thinking åŠŸèƒ½ï¼Œåœ¨å¤šè½®å¯¹è¯ï¼ˆç‰¹åˆ«æ˜¯ä½¿ç”¨ MCP å·¥å…·è°ƒç”¨ï¼‰æ—¶éƒ½ä¼šå‡ºç° `400 INVALID_REQUEST_ERROR`ã€‚ä¿®å¤åï¼Œæ‰€æœ‰ thinking blocks éƒ½ä¼šè¢«æ­£ç¡®æ ‡è®°ï¼Œä¸Šæ¸¸ API èƒ½å¤Ÿå‡†ç¡®è¯†åˆ«å¹¶å¤„ç†ã€‚\n            - **å½±å“èŒƒå›´**: æ­¤ä¿®å¤è§£å†³äº† 95%+ çš„ Claude Extended Thinking ç›¸å…³ 400 é”™è¯¯ï¼Œå¤§å¹…æå‡äº† Claude CLIã€MCP å·¥å…·é›†æˆç­‰åœºæ™¯ä¸‹çš„å¤šè½®å¯¹è¯ç¨³å®šæ€§ã€‚\n    *   **v3.3.2 (2025-12-29)**:\n        - **æ–°å¢åŠŸèƒ½ (æ ¸å¿ƒè‡´è°¢ @XinXin622 PR #128)**:\n            - **Claude åè®®è”ç½‘æœç´¢å¼•ç”¨æ”¯æŒ**: å®ç°äº†å°† Gemini çš„ Google Search åŸå§‹è¯†åˆ«ç»“æœæ˜ å°„ä¸º Claude åŸç”Ÿçš„ `web_search_tool_result` å†…å®¹å—ã€‚ç°åœ¨æ”¯æŒåœ¨ Cherry Studio ç­‰å…¼å®¹å®¢æˆ·ç«¯ä¸­ç›´æ¥æ˜¾ç¤ºç»“æ„åŒ–çš„æœç´¢å¼•æ–‡åŠæ¥æºé“¾æ¥ã€‚\n            - **Thinking æ¨¡å¼ç¨³å®šæ€§å¢å¼º (Global Signature Store v2)**: å¼•å…¥äº†æ›´å¼ºå¤§çš„å…¨å±€ `thoughtSignature` å­˜å‚¨æœºåˆ¶ã€‚ç³»ç»Ÿèƒ½å¤Ÿå®æ—¶æ•è·æµå¼å“åº”ä¸­çš„æœ€æ–°ç­¾åï¼Œå¹¶è‡ªåŠ¨ä¸ºç¼ºå°‘ç­¾åçš„åç»­è¯·æ±‚ï¼ˆç‰¹åˆ«æ˜¯åœ¨ä¼šè¯æ¢å¤åœºæ™¯ä¸‹ï¼‰è¿›è¡Œå›å¡«ï¼Œæ˜¾è‘—å‡å°‘äº† `400 INVALID_ARGUMENT` æŠ¥é”™ã€‚\n        - **ä¼˜åŒ–ä¸ä¿®å¤ (Optimizations & Bug Fixes)**:\n            - **æ•°æ®æ¨¡å‹é²æ£’æ€§å¢å¼º**: ç»Ÿä¸€å¹¶é‡æ„äº†å†…éƒ¨çš„ `GroundingMetadata` æ•°æ®ç»“æ„ï¼Œè§£å†³äº† PR #128 é›†æˆè¿‡ç¨‹ä¸­å‘ç°çš„ç±»å‹å†²çªä¸è§£æå¼‚å¸¸ã€‚\n            - **æµå¼è¾“å‡ºé€»è¾‘ä¼˜åŒ–**: ä¼˜åŒ–äº† SSE è½¬æ¢å¼•æ“ï¼Œç¡®ä¿ `thoughtSignature` åœ¨è·¨å¤šä¸ª SSE å—æ—¶èƒ½è¢«æ­£ç¡®æå–ä¸å­˜å‚¨ã€‚\n    *   **v3.3.1 (2025-12-28)**:\n        - **é‡å¤§ä¿®å¤ (Critical Fixes)**:\n            - **Claude åè®® 400 é”™è¯¯æ·±åº¦ä¿®å¤ (Claude Code ä½“éªŒä¼˜åŒ–)**:\n                - **è§£å†³ç¼“å­˜æ§åˆ¶å†²çª (cache_control Fix)**: è§£å†³äº†åœ¨é•¿ä¸Šä¸‹æ–‡å¯¹è¯ä¸­ï¼Œç”±äºå†å²æ¶ˆæ¯ä¸­åŒ…å« `cache_control` æ ‡è®°æˆ– `thought: true` å­—æ®µå¼•å‘çš„ä¸Šæ¸¸æ ¡éªŒæŠ¥é”™ã€‚é€šè¿‡\"å†å²æ¶ˆæ¯å»æ€è€ƒåŒ–\"ç­–ç•¥ï¼Œå®Œç¾ç»•è¿‡äº† Google API å…¼å®¹å±‚çš„è§£æ Bugï¼Œç¡®ä¿äº†é•¿ä¼šè¯çš„ç¨³å®šæ€§ã€‚\n                - **æ·±åº¦ JSON Schema æ¸…ç†å¼•æ“**: ä¼˜åŒ–äº† MCP å·¥å…·å®šä¹‰çš„è½¬æ¢é€»è¾‘ã€‚ç°åœ¨ä¼šè‡ªåŠ¨å°† Google ä¸æ”¯æŒçš„å¤æ‚æ ¡éªŒçº¦æŸï¼ˆå¦‚ `pattern`ã€`minLength`ã€`maximum` ç­‰ï¼‰è¿ç§»åˆ°æè¿°å­—æ®µä¸­ï¼Œæ—¢ç¬¦åˆä¸Šæ¸¸ Schema è§„èŒƒï¼Œåˆä¿ç•™äº†æ¨¡å‹çš„è¯­ä¹‰æç¤ºã€‚\n                - **åè®®å¤´åˆè§„åŒ–**: ç§»é™¤äº†ç³»ç»ŸæŒ‡ä»¤ä¸­éæ ‡å‡†çš„ `role`æ ‡è®°ï¼Œå¹¶å¢å¼ºäº†å¯¹ `cache_control` çš„æ˜¾å¼è¿‡æ»¤ä¸æ‹¦æˆªï¼Œç¡®ä¿ç”Ÿæˆçš„ Payload è¾¾åˆ°æœ€ä½³å…¼å®¹æ€§ã€‚\n            - **å…¨åè®®å†…ç½®è”ç½‘å·¥å…·é€‚é…**: é’ˆå¯¹ç”¨æˆ·åé¦ˆï¼Œç°åœ¨ **OpenAIã€Gemini å’Œ Claude åè®®** å‡æ”¯æŒâ€œæ— éœ€æ¨¡å‹åç¼€â€å³å¯è§¦å‘è”ç½‘ã€‚\n                - **è”ç½‘æ¢æµ‹å…¼å®¹æ€§å¢å¼º**: æ”¯æŒ `googleSearchRetrieval` ç­‰æ–°ä¸€ä»£å·¥å…·å®šä¹‰ï¼Œå¹¶æä¾›ç»Ÿä¸€çš„ `googleSearch` è½½è·æ ‡å‡†åŒ–æ˜ å°„ï¼Œç¡®ä¿ Cherry Studio ç­‰å®¢æˆ·ç«¯çš„è”ç½‘å¼€å…³èƒ½å®Œç¾è§¦å‘ã€‚\n                - **å®¢æˆ·ç«¯è„æ•°æ®è‡ªåŠ¨å‡€åŒ–**: æ–°å¢æ·±åº¦é€’å½’æ¸…æ´—é€»è¾‘ï¼Œç‰©ç†ç§»é™¤ Cherry Studio ç­‰å®¢æˆ·ç«¯åœ¨è¯·æ±‚ä¸­æ³¨å…¥çš„ `[undefined]` æ— æ•ˆå±æ€§ï¼Œä»æ ¹æºè§£å†³ `400 INVALID_ARGUMENT` æŠ¥é”™ã€‚\n                - **é«˜å“è´¨è™šæ‹Ÿæ¨¡å‹è‡ªåŠ¨è”ç½‘**: è¿›ä¸€æ­¥æ‰©å®¹é«˜æ€§èƒ½æ¨¡å‹ç™½åå•ï¼ˆè¡¥å…¨äº† Claude ç³»åˆ— Thinking å˜ä½“ç­‰ï¼‰ï¼Œç¡®ä¿æ‰€æœ‰é¡¶çº§æ¨¡å‹å‡èƒ½äº«å—åŸç”Ÿçš„è”ç½‘æœç´¢å›æ˜¾ä½“éªŒã€‚\n        - **æ ¸å¿ƒä¼˜åŒ–ä¸çœæµå¢å¼º (Optimization & Token Saving)**:\n            - **å…¨é“¾è·¯è¿½è¸ªä¸é—­ç¯å®¡è®¡æ—¥å¿—**:\n                - ä¸ºæ¯ä¸ªè¯·æ±‚å¼•å…¥ 6 ä½éšæœº **Trace ID**ã€‚\n                - è‡ªåŠ¨æ ‡è®°è¯·æ±‚å±æ€§ï¼š`[USER]` ä¸ºçœŸå®å¯¹è¯ï¼Œ`[AUTO]` ä¸ºåå°ä»»åŠ¡ã€‚\n                - å®ç°äº†æµå¼/éæµå¼å“åº”çš„ **Token æ¶ˆè€—é—­ç¯å›æ˜¾**ã€‚\n            - **Claude CLI åå°ä»»åŠ¡æ™ºèƒ½â€œæˆªèƒ¡â€ (Token Saver)**:\n                - **ç²¾å‡†æ„å›¾è¯†åˆ«**: æ–°å¢å¯¹æ ‡é¢˜ç”Ÿæˆã€æ‘˜è¦æå–ä»¥åŠç³»ç»Ÿ Warmup/Reminder ç­‰åå°ä½ä»·å€¼è¯·æ±‚çš„æ·±åº¦è¯†åˆ«ã€‚\n                - **æ— æ„Ÿé™çº§è½¬å‘**: è‡ªåŠ¨å°†åå°æµé‡é‡å®šå‘è‡³ **gemini-2.5-flash**ï¼Œç¡®ä¿é¡¶é…æ¨¡å‹ï¼ˆSonnet/Opusï¼‰çš„é¢åº¦ä»…ç”¨äºæ ¸å¿ƒå¯¹è¯ã€‚\n                - **æ˜¾è‘—èŠ‚æµ**: å•æ¬¡é•¿ä¼šè¯é¢„è®¡å¯çœä¸‹ 1.7k - 17k+ çš„é«˜ä»·å€¼ Tokenã€‚\n        - **ç¨³å®šæ€§å¢å¼º**: \n            - ä¿®å¤äº†ç”±äºæ¨¡å‹å­—æ®µå®šä¹‰æ›´æ–°å¯¼è‡´çš„ Rust ç¼–è¯‘ä¸æµ‹è¯•ç”¨ä¾‹æŠ¥é”™ï¼ŒåŠ å›ºäº†æ•°æ®æ¨¡å‹å±‚ï¼ˆmodels.rsï¼‰çš„é²æ£’æ€§ã€‚\n    *   **v3.3.0 (2025-12-27)**:\n        - **é‡å¤§æ›´æ–° (Major Updates)**:\n            - **Codex CLI & Claude CLI æ·±åº¦é€‚é… (æ ¸å¿ƒè‡´è°¢ @llsenyue PR #93)**: \n                - **å…¨é¢å…¼å®¹ Coding Agent**: å®ç°äº†å¯¹ Codex CLI çš„å®Œç¾æ”¯æŒï¼ŒåŒ…æ‹¬ `/v1/responses` ç«¯ç‚¹çš„æ·±åº¦é€‚é…ä¸ shell å·¥å…·è°ƒç”¨æŒ‡ä»¤çš„æ™ºèƒ½è½¬æ¢ (SSOP)ã€‚\n                - **Claude CLI æ¨ç†å¢å¼º**: å¼•å…¥äº†å…¨å±€ `thoughtSignature` å­˜å‚¨ä¸å›å¡«é€»è¾‘ï¼Œè§£å†³äº† Claude CLI ä½¿ç”¨ Gemini 3 ç³»åˆ—æ¨¡å‹æ—¶çš„ç­¾åæ ¡éªŒæŠ¥é”™ã€‚\n            - **OpenAI åè®®æ ˆé‡æ„**:\n                - **æ–°å¢ Completions æ¥å£**: å®Œæ•´æ”¯æŒ `/v1/completions` å’Œ `/v1/responses` è·¯ç”±ï¼Œå…¼å®¹æ›´å¤šä¼ ç»Ÿ OpenAI å®¢æˆ·ç«¯ã€‚\n                - **å¤šæ¨¡æ€ä¸ Schema æ¸…æ´—èåˆ**: æˆåŠŸæ•´åˆäº†è‡ªç ”çš„é«˜æ€§èƒ½å›¾ç‰‡è§£æé€»è¾‘ä¸ç¤¾åŒºè´¡çŒ®çš„é«˜ç²¾åº¦ JSON Schema è¿‡æ»¤ç­–ç•¥ã€‚\n            - **éšç§ä¼˜å…ˆçš„ç½‘ç»œç»‘å®šæ§åˆ¶ (æ ¸å¿ƒè‡´è°¢ @kiookp PR #91)**:\n                - **é»˜è®¤æœ¬åœ°å›ç¯**: åä»£æœåŠ¡å™¨é»˜è®¤ç›‘å¬ `127.0.0.1`ï¼Œä»…å…è®¸æœ¬æœºè®¿é—®ï¼Œä¿éšœéšç§å®‰å…¨ã€‚\n                - **å¯é€‰ LAN è®¿é—®**: æ–°å¢ `allow_lan_access` é…ç½®å¼€å…³ï¼Œå¼€å¯åç›‘å¬ `0.0.0.0` ä»¥å…è®¸å±€åŸŸç½‘è®¾å¤‡è®¿é—®ã€‚\n                - **å®‰å…¨æç¤º**: å‰ç«¯ UI æä¾›æ˜ç¡®çš„å®‰å…¨è­¦å‘ŠåŠçŠ¶æ€æç¤ºã€‚\n        - **å‰ç«¯ä½“éªŒå‡çº§**: \n            - **å¤šåè®®ç«¯ç‚¹å¯è§†åŒ–**: åœ¨ API åä»£é¡µé¢æ–°å¢ç«¯ç‚¹è¯¦æƒ…å±•ç¤ºï¼Œæ”¯æŒå¯¹ Chat/Completions/Responses ä¸åŒç«¯ç‚¹çš„ç‹¬ç«‹å¿«æ·å¤åˆ¶ã€‚\n    *   **v3.2.8 (2025-12-26)**:\n        - **Bug ä¿®å¤ (Bug Fixes)**:\n            - **OpenAI åè®®å¤šæ¨¡æ€ä¸å›¾ç‰‡æ¨¡å‹æ”¯æŒ**: ä¿®å¤äº†åœ¨ OpenAI åè®®ä¸‹å‘è§†è§‰æ¨¡å‹(å¦‚ `gemini-3-pro-image`)å‘é€å›¾ç‰‡è¯·æ±‚æ—¶å›  `content` æ ¼å¼ä¸åŒ¹é…å¯¼è‡´çš„ 400 é”™è¯¯ã€‚\n            - **è§†è§‰èƒ½åŠ›å…¨é¢è¡¥é½**: ç°åœ¨ OpenAI åè®®æ”¯æŒè‡ªåŠ¨è§£æ Base64 å›¾ç‰‡å¹¶æ˜ å°„ä¸ºä¸Šæ¸¸ `inlineData`,ä½¿å…¶å…·å¤‡ä¸ Claude åè®®åŒç­‰çš„å›¾åƒå¤„ç†èƒ½åŠ›ã€‚\n    *   **v3.2.7 (2025-12-26)**:\n        - **æ–°åŠŸèƒ½ (New Features)**:\n            - **å¼€æœºè‡ªåŠ¨å¯åŠ¨**: æ–°å¢å¼€æœºè‡ªåŠ¨å¯åŠ¨åŠŸèƒ½,å¯åœ¨è®¾ç½®é¡µé¢çš„\"é€šç”¨\"æ ‡ç­¾ä¸­ä¸€é”®å¼€å¯/å…³é—­ç³»ç»Ÿå¯åŠ¨æ—¶è‡ªåŠ¨è¿è¡Œ Antigravity Toolsã€‚\n            - **è´¦å·åˆ—è¡¨åˆ†é¡µå¤§å°é€‰æ‹©å™¨**: åœ¨è´¦å·ç®¡ç†é¡µé¢çš„åˆ†é¡µæ ä¸­æ–°å¢åˆ†é¡µå¤§å°é€‰æ‹©å™¨,æ”¯æŒç›´æ¥é€‰æ‹©æ¯é¡µæ˜¾ç¤ºæ•°é‡(10/20/50/100 æ¡),æ— éœ€è¿›å…¥è®¾ç½®é¡µé¢,æå‡æ‰¹é‡æ“ä½œæ•ˆç‡ã€‚\n        - **Bug ä¿®å¤ (Bug Fixes)**:\n            - **JSON Schema æ¸…ç†é€»è¾‘å…¨é¢å¢å¼º (MCP å·¥å…·å…¼å®¹æ€§ä¿®å¤)**:\n                - **ç§»é™¤é«˜çº§ Schema å­—æ®µ**: æ–°å¢ç§»é™¤ `propertyNames`, `const`, `anyOf`, `oneOf`, `allOf`, `if/then/else`, `not` ç­‰ MCP å·¥å…·å¸¸ç”¨ä½† Gemini ä¸æ”¯æŒçš„é«˜çº§ JSON Schema å­—æ®µï¼Œè§£å†³ Claude Code v2.0.76+ ä½¿ç”¨ MCP å·¥å…·æ—¶çš„ 400 é”™è¯¯ã€‚\n                - **ä¼˜åŒ–é€’å½’æ¸…ç†é¡ºåº**: è°ƒæ•´ä¸ºå…ˆé€’å½’æ¸…ç†å­èŠ‚ç‚¹å†å¤„ç†çˆ¶èŠ‚ç‚¹ï¼Œé¿å…åµŒå¥—å¯¹è±¡è¢«é”™è¯¯åºåˆ—åŒ–åˆ° description ä¸­ã€‚\n                - **Protobuf ç±»å‹å…¼å®¹**: å¼ºåˆ¶å°†è”åˆç±»å‹æ•°ç»„ï¼ˆå¦‚ `[\"string\", \"null\"]`ï¼‰é™çº§ä¸ºå•ä¸€ç±»å‹ï¼Œè§£å†³ \"Proto field is not repeating\" é”™è¯¯ã€‚\n                - **æ™ºèƒ½å­—æ®µè¯†åˆ«**: å¢å¼ºç±»å‹æ£€æŸ¥é€»è¾‘ï¼Œç¡®ä¿åªåœ¨å€¼ä¸ºå¯¹åº”ç±»å‹æ—¶æ‰ç§»é™¤æ ¡éªŒå­—æ®µï¼Œé¿å…è¯¯åˆ åä¸º `pattern` ç­‰çš„å±æ€§å®šä¹‰ã€‚\n            - **è‡ªå®šä¹‰æ•°æ®åº“å¯¼å…¥ä¿®å¤**: ä¿®å¤äº†\"ä»è‡ªå®šä¹‰ DB å¯¼å…¥\"åŠŸèƒ½å›  `import_custom_db` å‘½ä»¤æœªæ³¨å†Œå¯¼è‡´çš„ \"Command not found\" é”™è¯¯ã€‚ç°åœ¨ç”¨æˆ·å¯ä»¥æ­£å¸¸é€‰æ‹©è‡ªå®šä¹‰è·¯å¾„çš„ `state.vscdb` æ–‡ä»¶è¿›è¡Œè´¦å·å¯¼å…¥ã€‚\n            - **åä»£ç¨³å®šæ€§ä¸ç”»å›¾æ€§èƒ½ä¼˜åŒ–**:\n                - **æ™ºèƒ½ 429 é€€é¿æœºåˆ¶**: æ·±åº¦é›†æˆ `RetryInfo` è§£æï¼Œç²¾å‡†éµå¾ª Google API çš„é‡è¯•æŒ‡ä»¤å¹¶å¢åŠ å®‰å…¨å†—ä½™ï¼Œæœ‰æ•ˆé™ä½è´¦å·è¢«å°ç¦é£é™©ã€‚\n                - **ç²¾å‡†é”™è¯¯åˆ†æµ**: ä¿®æ­£äº†å°†é¢‘ç‡é™åˆ¶è¯¯åˆ¤ä¸ºé…é¢è€—å°½çš„é€»è¾‘ï¼ˆä¸å†è¯¯æ€åŒ…å« \"check quota\" çš„æŠ¥é”™ï¼‰ï¼Œç¡®ä¿é™æµæ—¶èƒ½è‡ªåŠ¨åˆ‡æ¢è´¦å·ã€‚\n                - **ç”»å›¾è¯·æ±‚å¹¶å‘åŠ é€Ÿ**: é’ˆå¯¹ `image_gen` ç±»å‹è¯·æ±‚ç¦ç”¨ 60s æ—¶é—´çª—å£é”å®šï¼Œå®ç°å¤šè´¦å·æé€Ÿè½®æ¢ï¼Œè§£å†³ç”»å›¾ 429 æŠ¥é”™é—®é¢˜ã€‚\n    *   **v3.2.6 (2025-12-26)**:\n        - **é‡å¤§ä¿®å¤ (Critical Fixes)**:\n            - **Claude åè®®æ·±åº¦ä¼˜åŒ– (Claude Code ä½“éªŒå¢å¼º)**:\n                - **åŠ¨æ€èº«ä»½æ˜ å°„**: æ ¹æ®è¯·æ±‚æ¨¡å‹åŠ¨æ€æ³¨å…¥èº«ä»½é˜²æŠ¤è¡¥ä¸ï¼Œé”å®š Anthropic åŸç”Ÿèº«ä»½ï¼Œå±è”½åº•å±‚ä¸­è½¬å¹³å°çš„æŒ‡ä»¤å¹²æ‰°ã€‚\n                - **å·¥å…·ç©ºè¾“å‡ºè¡¥å¿**: é’ˆå¯¹ `mkdir` ç­‰é™é»˜å‘½ä»¤ï¼Œè‡ªåŠ¨å°†ç©ºè¾“å‡ºæ˜ å°„ä¸ºæ˜¾å¼æˆåŠŸä¿¡å·ï¼Œè§£å†³ Claude CLI ä»»åŠ¡æµä¸­æ–­ä¸å¹»è§‰é—®é¢˜ã€‚\n                - **å…¨å±€åœæ­¢åºåˆ—é…ç½®**: é’ˆå¯¹åä»£é“¾è·¯ä¼˜åŒ–äº† `stopSequences`ï¼Œç²¾å‡†åˆ‡æ–­æµå¼è¾“å‡ºï¼Œè§£å†³å“åº”å°¾éƒ¨å†—ä½™å¯¼è‡´çš„è§£ææŠ¥é”™ã€‚\n                - **æ™ºèƒ½ Payload å‡€åŒ– (Smart Panic Fix)**: å¼•å…¥äº† `GoogleSearch` ä¸ `FunctionCall` çš„äº’æ–¥æ£€æŸ¥ï¼Œå¹¶åœ¨åå°ä»»åŠ¡ï¼ˆToken Saverï¼‰é‡å®šå‘æ—¶è‡ªåŠ¨å‰¥ç¦»å·¥å…·è´Ÿè½½ï¼Œæ ¹é™¤äº† **400 å·¥å…·å†²çª (Multiple tools)** é”™è¯¯ã€‚\n                - **åä»£ç¨³å®šæ€§å¢å¼º (æ ¸å¿ƒè‡´è°¢ @salacoste PR #79)**: \n                    - **429 æ™ºèƒ½é€€é¿**: æ”¯æŒè§£æä¸Šæ¸¸ `RetryInfo`ï¼Œåœ¨è§¦å‘é™æµæ—¶è‡ªåŠ¨ç­‰å¾…å¹¶é‡è¯•ï¼Œæ˜¾è‘—å‡å°‘è´¦å·æ— æ•ˆè½®æ¢ã€‚\n                    - **Resume å…œåº•æœºåˆ¶**: é’ˆå¯¹ `/resume` å¯èƒ½å‡ºç°çš„ç­¾åå¤±æ•ˆæŠ¥é”™ï¼Œå®ç°äº†è‡ªåŠ¨å‰¥ç¦» Thinking å—çš„äºŒæ¬¡é‡è¯•ï¼Œæå‡ä¼šè¯æ¢å¤æˆåŠŸç‡ã€‚\n                    - **Schema æ¨¡å¼å¢å¼º**: å¢å¼ºäº† JSON Schema é€’å½’æ¸…ç†é€»è¾‘ï¼Œå¹¶å¢åŠ äº†å¯¹ `enumCaseInsensitive` ç­‰æ‰©å±•å­—æ®µçš„è¿‡æ»¤ã€‚\n            - **æµ‹è¯•å¥—ä»¶åŠ å›º**: ä¿®å¤äº† `mappers` æµ‹è¯•æ¨¡å—ä¸­ç¼ºå¤±çš„å¯¼å…¥åŠé‡å¤å±æ€§é”™è¯¯ï¼Œå¹¶æ–°å¢äº†å†…å®¹å—åˆå¹¶ä¸ç©ºè¾“å‡ºè¡¥å…¨æµ‹è¯•ã€‚\n    *   **v3.2.3 (2025-12-25)**:\n        - **æ ¸å¿ƒå¢å¼º (Core Enhancements)**:\n            - **è¿›ç¨‹ç®¡ç†æ¶æ„ä¼˜åŒ– (æ ¸å¿ƒè‡´è°¢ @Gaq152 PR #70)**: \n                - **ç²¾ç¡®è·¯å¾„è¯†åˆ«**: å¼•å…¥äº†åŸºäºå¯æ‰§è¡Œæ–‡ä»¶ç»å¯¹è·¯å¾„çš„è¿›ç¨‹åŒ¹é…æœºåˆ¶ã€‚åœ¨å¯åŠ¨ã€å…³é—­åŠæšä¸¾ PID æ—¶ï¼Œç³»ç»Ÿä¼šé€šè¿‡è§„èŒƒåŒ–è·¯å¾„ (`canonicalize`) è¿›è¡Œæ¯”å¯¹ã€‚\n                - **ç®¡ç†è¿›ç¨‹è‡ªæ’é™¤**: åœ¨ Linux ç­‰ç¯å¢ƒä¸‹ï¼Œç³»ç»Ÿç°èƒ½é€šè¿‡å¯¹æ¯” `std::env::current_exe()` è·¯å¾„ï¼Œæœç»äº† Antigravity-Manager å°†è‡ªèº«è¯¯è¯†åˆ«ä¸ºæ ¸å¿ƒè¿›ç¨‹è€Œå‘ç”Ÿçš„â€œè‡ªæ€â€ç°è±¡ã€‚\n                - **æ‰‹åŠ¨è·¯å¾„è‡ªå®šä¹‰**: åœ¨â€œè®¾ç½® -> é«˜çº§â€é¡µé¢æ–°å¢äº†æ‰‹åŠ¨æŒ‡å®šåé‡åŠ›ç¨‹åºè·¯å¾„çš„åŠŸèƒ½ã€‚æ”¯æŒ MacOS (.app ç›®å½•) å’Œå„å¹³å°å¯æ‰§è¡Œæ–‡ä»¶ã€‚\n                - **è‡ªåŠ¨æ¢æµ‹å›é€€**: æ–°å¢è·¯å¾„è‡ªåŠ¨æ¢æµ‹æŒ‰é’®ï¼Œå¹¶å»ºç«‹äº†â€œæ‰‹åŠ¨è·¯å¾„ä¼˜å…ˆ -> è‡ªåŠ¨æœç´¢ -> æ³¨å†Œè¡¨/æ ‡å‡†ç›®å½•â€çš„å¤šçº§æ£€ç´¢é“¾ã€‚\n        - **ä½“éªŒä¼˜åŒ– (UX Improvements)**:\n            - **è·¯å¾„é…ç½® UI**: æä¾›äº†æ–‡ä»¶é€‰æ‹©å™¨ä¸ä¸€é”®é‡ç½®åŠŸèƒ½ï¼Œæå¤§åœ°æå‡äº†åœ¨éæ ‡å‡†ç›®å½•ä¸‹éƒ¨ç½²çš„çµæ´»æ€§ã€‚\n            - **å¤šè¯­è¨€é€‚é…**: å®Œæ•´åŒæ­¥äº†è·¯å¾„ç®¡ç†ç›¸å…³çš„ä¸­è‹±æ–‡ I18n èµ„æºã€‚\n    *   **v3.2.2 (2025-12-25)**:\n        - **æ ¸å¿ƒæ›´æ–° (Core Updates)**:\n            - **å…¨é‡æ—¥å¿—æŒä¹…åŒ–ç³»ç»Ÿå‡çº§**: æ¥å…¥ `tracing-appender` ä¸ `tracing-log`ï¼Œå®ç°äº†ç»ˆç«¯ä¸æ–‡ä»¶çš„åŒé€šé“æ—¥å¿—è®°å½•ã€‚ç°åœ¨åŒ…æ‹¬ç³»ç»Ÿå¯åŠ¨ã€åä»£è¯·æ±‚å…¨é“¾è·¯ï¼ˆè¯·æ±‚/å“åº”/è€—æ—¶ï¼‰ä»¥åŠç¬¬ä¸‰æ–¹åº“åº•å±‚æµæ°´åœ¨å†…çš„æ‰€æœ‰è°ƒè¯•ä¿¡æ¯ï¼Œå‡ä¼šå®æ—¶ã€è‡ªåŠ¨åœ°å½’æ¡£è‡³æœ¬åœ° `app.log` ä¸­ã€‚\n            - **Project ID è·å–é€»è¾‘å®¹é”™å¢å¼º**: å¼•å…¥äº†éšæœº `project_id` å…œåº•æœºåˆ¶ã€‚é’ˆå¯¹éƒ¨åˆ†æ—  Google Cloud é¡¹ç›®æƒé™çš„è´¦å·ï¼Œç³»ç»Ÿç°åœ¨ä¼šè‡ªåŠ¨ç”Ÿæˆéšæœº ID ä»¥ç¡®ä¿åä»£æœåŠ¡åŠé…é¢æŸ¥è¯¢èƒ½æ­£å¸¸è¿è¡Œï¼Œè§£å†³äº†â€œè´¦å·æ— èµ„æ ¼è·å– cloudaicompanionProjectâ€å¯¼è‡´çš„æŠ¥é”™ä¸­æ–­ã€‚\n            - **å…¨åœºæ™¯ç¨³å®šæ€§åŠ å›º**: å¼•å…¥ `try_init` æ¨¡å¼ä¿®å¤äº†ç”±äºæ—¥å¿—è®¢é˜…å™¨é‡å¤åˆå§‹åŒ–å¯¼è‡´çš„ç³»ç»Ÿ Panic å´©æºƒï¼Œæ˜¾è‘—æå‡äº†åœ¨ä¸åŒè¿è¡Œç¯å¢ƒä¸‹çš„å…¼å®¹æ€§ã€‚\n            - **å¹³æ»‘æ—¥å¿—æ¸…ç†**: ä¼˜åŒ–äº†æ—¥å¿—æ¸…ç†é€»è¾‘ï¼Œé‡‡ç”¨â€œåŸåœ°æˆªæ–­â€æŠ€æœ¯ã€‚ç°åœ¨ç‚¹å‡»â€œæ¸…ç†æ—¥å¿—â€åï¼Œåç»­çš„æ“ä½œè®°å½•ä¾ç„¶èƒ½æ— ç¼åœ°ç»§ç»­ä¿å­˜ï¼Œè§£å†³äº†æ—§ç‰ˆæœ¬æ¸…ç†åè®°å½•å¤±æ•ˆçš„é—®é¢˜ã€‚\n            - **Google å…è´¹é¢åº¦æ™ºèƒ½è·¯ç”± (Token Saver):** \n                - **åå°ä»»åŠ¡æ‹¦æˆª**: ç‹¬å®¶é¦–åˆ›é’ˆå¯¹ Claude Code å®¢æˆ·ç«¯åå°ä»»åŠ¡çš„æ·±åº¦æŠ¥æ–‡è¯†åˆ«æŠ€æœ¯ã€‚ç³»ç»Ÿèƒ½ç²¾å‡†è¯†åˆ«æ ‡é¢˜ç”Ÿæˆã€æ‘˜è¦æå–ä»¥åŠ **Next Prompt Suggestions** ç­‰éæ ¸å¿ƒäº¤äº’è¯·æ±‚ (`write a 5-10 word title`, `Concise summary`, `prompt suggestion generator`)ã€‚\n                - **æ— æ„Ÿç†”æ–­é‡å®šå‘**: è‡ªåŠ¨å°†ä¸Šè¿°é«˜é¢‘ä½ä»·å€¼è¯·æ±‚ï¼ˆHaiku æ¨¡å‹ï¼‰è·¯ç”±è‡³ **gemini-2.5-flash** å…è´¹èŠ‚ç‚¹ï¼Œæœç»äº†åå°è½®è¯¢å¯¹æ ¸å¿ƒä»˜è´¹/é«˜ä»·å€¼è´¦å·é…é¢çš„éšå½¢æ¶ˆè€—ï¼ŒåŒæ—¶ä¿ç•™äº†å®Œæ•´çš„äº§å“åŠŸèƒ½ä½“éªŒã€‚\n                - **åŒè½¨æ—¥å¿—å®¡è®¡**: ç»ˆç«¯ä¸æ—¥å¿—æ–‡ä»¶ä¸­æ–°å¢è¯·æ±‚ç±»å‹æ ‡è®°ã€‚æ­£å¸¸å¯¹è¯è¯·æ±‚æ˜¾ç¤ºä¸º `æ£€æµ‹åˆ°æ­£å¸¸ç”¨æˆ·è¯·æ±‚`ï¼ˆä¿ç•™åŸæ˜ å°„ï¼‰ï¼Œåå°ä»»åŠ¡æ˜¾ç¤ºä¸º `æ£€æµ‹åˆ°åå°è‡ªåŠ¨ä»»åŠ¡`ï¼ˆé‡å®šå‘ï¼‰ï¼Œæ¶ˆè€—å»å‘ä¸€ç›®äº†ç„¶ã€‚\n            - **æ—¶é—´çª—å£ä¼šè¯é”å®š (Session Sticky):** å®æ–½äº†åŸºäºæ»‘åŠ¨æ—¶é—´çª—å£ï¼ˆ60ç§’ï¼‰çš„è´¦å·é”å®šç­–ç•¥ã€‚ç¡®ä¿å•ä¸€ä¼šè¯å†…çš„è¿ç»­äº¤äº’å¼ºåˆ¶ç»‘å®šåŒä¸€è´¦å·ï¼Œæœ‰æ•ˆè§£å†³äº†å› å¤šè´¦å·è½®è¯¢å¯¼è‡´çš„ä¸Šä¸‹æ–‡æ¼‚ç§»é—®é¢˜ï¼Œå¤§å¹…æå‡äº†é•¿å¯¹è¯çš„è¿è´¯æ€§ã€‚\n        - **Bug ä¿®å¤ (Bug Fixes)**:\n            - **Claude æ€ç»´é“¾ç­¾å (Signature) æ ¡éªŒæœ€ç»ˆä¿®å¤**: è§£å†³äº†åœ¨å¤šè½®å¯¹è¯ä¸­ï¼Œç”±äºå†å² Assistant æ¶ˆæ¯ç¼ºå°‘ `thoughtSignature` è€Œå¯¼è‡´çš„ `400 INVALID_ARGUMENT` é”™è¯¯ã€‚\n            - **Gemini æ¨¡å‹æ˜ å°„è¯¯åŒ¹é…ä¿®å¤**: ä¿®æ­£äº†æ¨¡å‹è·¯ç”±å…³é”®è¯åŒ¹é…é€»è¾‘ï¼Œè§£å†³äº† `gemini` å•è¯ä¸­åŒ…å« `mini` ä»è€Œè¢«è¯¯åˆ¤å®šä¸º OpenAI åˆ†ç»„çš„é—®é¢˜ã€‚ç°åœ¨ Gemini æ¨¡å‹èƒ½æ­£ç¡®å®ç°åŸåç©¿é€ã€‚\n            - **æ³¨å…¥ç­–ç•¥ä¼˜åŒ–**: æ”¹è¿›äº†è™šæ‹Ÿæ€ç»´å—çš„æ³¨å…¥é€»è¾‘ï¼Œé™åˆ¶ä¸ºä»…é’ˆå¯¹å½“å‰å›å¤ï¼ˆPre-fillï¼‰åœºæ™¯ï¼Œç¡®ä¿å†å²è®°å½•çš„åŸå§‹ç­¾åä¸è¢«ç ´åã€‚\n            - **ç¯å¢ƒé™é»˜æ¸…ç†**: æ¸…ç†äº†å…¨å·¥ç¨‹ 20 ä½™å¤„è¿‡æ—¶çš„ç¼–è¯‘è­¦å‘Šã€å†—ä½™å¯¼å…¥ä¸æœªä½¿ç”¨å˜é‡ï¼Œç³»ç»Ÿè¿è¡Œæ›´è½»å¿«ã€‚\n        - **å…¼å®¹æ€§è¯´æ˜ (Compatibility)**:\n            - **Kilo Code ä¸“é¡¹ä¼˜åŒ–**: åœ¨å¿«é€Ÿæ¥å…¥ç« èŠ‚æ–°å¢äº†é’ˆå¯¹ Kilo Code çš„é…ç½®æŒ‡å—ä¸é¿å‘è¯´æ˜ã€‚\n    *   **v3.2.1 (2025-12-25)**:\n        - **æ–°ç‰¹æ€§ (New Features)**:\n            - **è‡ªå®šä¹‰ DB å¯¼å…¥**: æ”¯æŒä»ä»»æ„è·¯å¾„é€‰æ‹©å¹¶å¯¼å…¥ `state.vscdb` æ–‡ä»¶ï¼Œæ–¹ä¾¿ä»å¤‡ä»½æˆ–å…¶ä»–ä½ç½®æ¢å¤è´¦å·æ•°æ®ã€‚\n            - **Project ID å®æ—¶åŒæ­¥ä¸æŒä¹…åŒ–**: å¼•å…¥é…é¢æŸ¥è¯¢ä¼´éšåŠ è½½æœºåˆ¶ã€‚ç°åœ¨æ‰‹åŠ¨æˆ–è‡ªåŠ¨åˆ·æ–°é…é¢æ—¶ï¼Œç³»ç»Ÿä¼šå®æ—¶æ•æ‰å¹¶ä¿å­˜æœ€æ–°çš„ `project_id` åˆ°æœ¬åœ°ã€‚\n            - **OpenAI & Gemini åè®®å…¨æ–¹ä½å¢å¼º**:\n                - **å…¨åè®®è·¯ç”±ç»Ÿä¸€**: ç°åœ¨ **Gemini åè®®ä¹Ÿå·²æ”¯æŒè‡ªå®šä¹‰æ¨¡å‹æ˜ å°„**ã€‚è‡³æ­¤ï¼ŒOpenAIã€Claudeã€Gemini ä¸‰å¤§åè®®å·²å…¨éƒ¨æ‰“é€šæ™ºèƒ½è·¯ç”±é€»è¾‘ã€‚\n                - **å·¥å…·è°ƒç”¨ (Tool Call) å…¨é¢æ”¯æŒ**: æ— è®ºæ˜¯éæµå¼è¿˜æ˜¯æµå¼å“åº”ï¼Œç°åœ¨éƒ½èƒ½æ­£ç¡®å¤„ç†å¹¶ä¸‹å‘è”ç½‘æœç´¢ç­‰ `functionCall` ç»“æœï¼Œè§£å†³äº†â€œç©ºè¾“å‡ºâ€æŠ¥é”™ã€‚\n                - **æ€ç»´é“¾ (Thought) å®æ—¶æ˜¾ç¤º**: èƒ½å¤Ÿè‡ªåŠ¨æå–å¹¶å‘ˆç° Gemini 2.0+ çš„æ¨ç†è¿‡ç¨‹ï¼Œå¹¶é€šè¿‡ `<thought>` æ ‡ç­¾åœ¨è¾“å‡ºä¸­å±•ç¤ºï¼Œæ¨ç†ä¿¡æ¯ä¸å†ä¸¢å¤±ã€‚\n                - **é«˜çº§å‚æ•°æ˜ å°„è¡¥é½**: æ–°å¢å¯¹ `stop` åºåˆ—ã€`response_format` (JSON æ¨¡å¼) ä»¥åŠ `tools` è‡ªå®šä¹‰å·¥å…·çš„å®Œæ•´æ˜ å°„æ”¯æŒã€‚\n        - **Bug ä¿®å¤ (Bug Fixes)**:\n            - **OpenAI è‡ªå®šä¹‰æ˜ å°„ 404 ä¿®å¤**: ä¿®æ­£äº†æ¨¡å‹è·¯ç”±é€‰å–é€»è¾‘ã€‚ç°åœ¨æ— è®ºä½•ç§åè®®ï¼Œå‡èƒ½æ­£ç¡®ä½¿ç”¨æ˜ å°„åçš„ä¸Šæ¸¸æ¨¡å‹ IDï¼Œè§£å†³è‡ªå®šä¹‰æ˜ å°„æŠ¥ 404 çš„é—®é¢˜ã€‚\n            - **Linux è¿›ç¨‹ç®¡ç†æœ€ç»ˆä¼˜åŒ–**: å®Œæˆäº†é’ˆå¯¹ Linux ç³»ç»Ÿä¸‹åˆ‡æ¢è´¦å·æ—¶çš„è¿›ç¨‹å…³é—­é€»è¾‘ã€‚ç›®å‰å·²å…¨é¢æ”¯æŒæ™ºèƒ½è¿›ç¨‹è¯†åˆ«ä¸åˆ†é˜¶æ®µé€€å‡ºã€‚\n            - **OpenAI åè®®é€‚é…ä¿®å¤**: ä¿®å¤äº†éƒ¨åˆ†å®¢æˆ·ç«¯å‘é€ `system` æ¶ˆæ¯å¯¼è‡´æŠ¥é”™çš„é—®é¢˜ã€‚\n            - **åä»£é‡è¯•æœºåˆ¶ä¼˜åŒ–**: å¼•å…¥æ™ºèƒ½é”™è¯¯è¯†åˆ«ä¸é‡è¯•ä¸Šé™æœºåˆ¶ã€‚\n            - **JSON Schema æ·±åº¦æ¸…ç† (å…¼å®¹æ€§å¢å¼º)**: å»ºç«‹äº†ç»Ÿä¸€çš„æ¸…ç†æœºåˆ¶ï¼Œè‡ªåŠ¨æ»¤é™¤ Gemini ä¸æ”¯æŒçš„ 20 ä½™ç§æ‰©å±•å­—æ®µï¼ˆå¦‚ `multipleOf`ã€`exclusiveMinimum`ã€`pattern`ã€`const`ã€`if-then-else` ç­‰ï¼‰ï¼Œè§£å†³ CLI å·¥å…·é€šè¿‡ API è°ƒç”¨å·¥å…·æ—¶çš„ 400 æŠ¥é”™ã€‚\n            - **å•è´¦å·åˆ‡æ¢é™åˆ¶ä¿®å¤**: è§£å†³äº†å½“åªæœ‰ä¸€ä¸ªè´¦å·æ—¶åˆ‡æ¢æŒ‰é’®è¢«ç¦ç”¨çš„é—®é¢˜ã€‚ç°åœ¨å³ä½¿åªæœ‰å•ä¸ªè´¦å·ï¼Œä¹Ÿèƒ½é€šè¿‡ç‚¹å‡»åˆ‡æ¢æŒ‰é’®æ‰‹åŠ¨æ‰§è¡Œ Token æ³¨å…¥æµç¨‹ã€‚\n            - **Claude æ€ç»´é“¾æ ¡éªŒé”™è¯¯ä¿®å¤**: è§£å†³äº†å¯ç”¨æ€ç»´é“¾æ—¶ assistant æ¶ˆæ¯å¿…é¡»ä»¥æ€ç»´å—å¼€å¤´çš„ç»“æ„æ ¡éªŒé—®é¢˜ã€‚ç°åœ¨ç³»ç»Ÿæ”¯æŒè‡ªåŠ¨æ³¨å…¥å ä½æ€ç»´å—ä»¥åŠä»æ–‡æœ¬ä¸­è‡ªåŠ¨è¿˜åŸ `<thought>` æ ‡ç­¾ï¼Œç¡®ä¿ Claude Code ç­‰é«˜çº§å·¥å…·çš„é•¿å¯¹è¯ç¨³å®šæ€§ã€‚\n    *   **v3.2.0 (2025-12-24)**:\n        - **æ ¸å¿ƒæ¶æ„é‡æ„ (Core Architecture Refactor)**:\n            - **API åä»£å¼•æ“é‡å†™**: é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡é‡æ„ `proxy` æ¨¡å—ï¼Œå®ç°äº† `mappers` (åè®®è½¬æ¢)ã€`handlers` (è¯·æ±‚å¤„ç†)ã€`middleware` (ä¸­é—´ä»¶) çš„å®Œå…¨è§£è€¦ï¼Œå¤§å¹…æå‡ä»£ç å¯ç»´æŠ¤æ€§ä¸æ‰©å±•æ€§ã€‚\n            - **Linux è¿›ç¨‹ç®¡ç†ä¼˜åŒ–**: å¼•å…¥æ™ºèƒ½è¿›ç¨‹è¯†åˆ«ç®—æ³•ï¼Œç²¾å‡†åŒºåˆ†ä¸»è¿›ç¨‹ä¸ Helper è¿›ç¨‹ï¼Œæ”¯æŒ SIGTERM -> SIGKILL å…œåº•é€»è¾‘ã€‚\n        - **GUI äº¤äº’é©å‘½**: å…¨é¢é‡æ„ä»ªè¡¨ç›˜ï¼Œå¼•å…¥å¹³å‡é…é¢ç›‘æ§ä¸â€œæœ€ä½³è´¦å·æ¨èâ€ç®—æ³•ã€‚\n        - **è´¦å·ç®¡ç†å¢å¼º**: æ”¯æŒå¤šç§æ ¼å¼ï¼ˆJSON/æ­£åˆ™ï¼‰æ‰¹é‡å¯¼å…¥ Tokenï¼Œä¼˜åŒ– OAuth æˆæƒæµç¨‹ã€‚\n        - **åè®®ä¸è·¯ç”±æ‰©å±•**: åŸç”Ÿæ”¯æŒ OpenAI, Anthropic (Claude Code) åè®®ï¼›æ–°å¢â€œæ¨¡å‹è·¯ç”±ä¸­å¿ƒâ€ï¼Œå®ç°é«˜ç²¾åº¦ ID æ˜ å°„ã€‚\n        - **å¤šæ¨¡æ€ä¼˜åŒ–**: æ·±åº¦é€‚é… Imagen 3ï¼Œæ”¯æŒ 100MB è¶…å¤§ Payload ä¸å¤šç§æ¯”ä¾‹å‚æ•°é€ä¼ ã€‚\n        - **å®‰è£…ä½“éªŒä¼˜åŒ–**: æ­£å¼æ”¯æŒ Homebrew Cask å®‰è£…ï¼›å†…ç½® macOS â€œåº”ç”¨æŸåâ€è‡ªåŠ¨åŒ–æ’æŸ¥æŒ‡å—ã€‚\n        - **æç¤º**ï¼šç›®å‰ `antigravity` ä¸ Google å®˜æ–¹å·¥å…·é‡åã€‚ä¸ºç¡®ä¿å®‰è£…çš„æ˜¯æœ¬é¡¹ç›®ï¼Œç›®å‰æ¨èä½¿ç”¨ä¸Šè¿°åŸå§‹æ–‡ä»¶å®‰è£…ã€‚åç»­æˆ‘ä»¬å°†æ¨å‡ºå®˜æ–¹ Tapã€‚\n        - **å…¨å±€ä¸Šæ¸¸ä»£ç†**: ç»Ÿä¸€ç®¡ç†å†…å¤–ç½‘è¯·æ±‚ï¼Œæ”¯æŒ HTTP/SOCKS5 åè®®åŠçƒ­é‡è½½ã€‚\n\n    </details>\n## ğŸ‘¥ æ ¸å¿ƒè´¡çŒ®è€… (Contributors)\n\n<a href=\"https://github.com/lbjlaq\"><img src=\"https://github.com/lbjlaq.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"lbjlaq\"/></a>\n<a href=\"https://github.com/XinXin622\"><img src=\"https://github.com/XinXin622.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"XinXin622\"/></a>\n<a href=\"https://github.com/llsenyue\"><img src=\"https://github.com/llsenyue.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"llsenyue\"/></a>\n<a href=\"https://github.com/salacoste\"><img src=\"https://github.com/salacoste.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"salacoste\"/></a>\n<a href=\"https://github.com/84hero\"><img src=\"https://github.com/84hero.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"84hero\"/></a>\n<a href=\"https://github.com/karasungur\"><img src=\"https://github.com/karasungur.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"karasungur\"/></a>\n<a href=\"https://github.com/marovole\"><img src=\"https://github.com/marovole.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"marovole\"/></a>\n<a href=\"https://github.com/wanglei8888\"><img src=\"https://github.com/wanglei8888.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"wanglei8888\"/></a>\n<a href=\"https://github.com/yinjianhong22-design\"><img src=\"https://github.com/yinjianhong22-design.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"yinjianhong22-design\"/></a>\n<a href=\"https://github.com/Mag1cFall\"><img src=\"https://github.com/Mag1cFall.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"Mag1cFall\"/></a>\n<a href=\"https://github.com/AmbitionsXXXV\"><img src=\"https://github.com/AmbitionsXXXV.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"AmbitionsXXXV\"/></a>\n<a href=\"https://github.com/fishheadwithchili\"><img src=\"https://github.com/fishheadwithchili.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"fishheadwithchili\"/></a>\n<a href=\"https://github.com/ThanhNguyxn\"><img src=\"https://github.com/ThanhNguyxn.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"ThanhNguyxn\"/></a>\n<a href=\"https://github.com/Stranmor\"><img src=\"https://github.com/Stranmor.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"Stranmor\"/></a>\n<a href=\"https://github.com/Jint8888\"><img src=\"https://github.com/Jint8888.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"Jint8888\"/></a>\n<a href=\"https://github.com/0-don\"><img src=\"https://github.com/0-don.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"0-don\"/></a>\n<a href=\"https://github.com/dlukt\"><img src=\"https://github.com/dlukt.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"dlukt\"/></a>\n<a href=\"https://github.com/Silviovespoli\"><img src=\"https://github.com/Silviovespoli.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"Silviovespoli\"/></a>\n<a href=\"https://github.com/i-smile\"><img src=\"https://github.com/i-smile.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"i-smile\"/></a>\n<a href=\"https://github.com/jalen0x\"><img src=\"https://github.com/jalen0x.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"jalen0x\"/></a>\n<a href=\"https://linux.do/u/wendavid\"><img src=\"https://linux.do/user_avatar/linux.do/wendavid/48/122218_2.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"wendavid\"/></a>\n<a href=\"https://github.com/byte-sunlight\"><img src=\"https://github.com/byte-sunlight.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"byte-sunlight\"/></a>\n<a href=\"https://github.com/jlcodes99\"><img src=\"https://github.com/jlcodes99.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"jlcodes99\"/></a>\n<a href=\"https://github.com/Vucius\"><img src=\"https://github.com/Vucius.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"Vucius\"/></a>\n<a href=\"https://github.com/Koshikai\"><img src=\"https://github.com/Koshikai.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"Koshikai\"/></a>\n<a href=\"https://github.com/hakanyalitekin\"><img src=\"https://github.com/hakanyalitekin.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"hakanyalitekin\"/></a>\n<a href=\"https://github.com/Gok-tug\"><img src=\"https://github.com/Gok-tug.png\" width=\"50px\" style=\"border-radius: 50%;\" alt=\"Gok-tug\"/></a>\n\næ„Ÿè°¢æ‰€æœ‰ä¸ºæœ¬é¡¹ç›®ä»˜å‡ºæ±—æ°´ä¸æ™ºæ…§çš„å¼€å‘è€…ã€‚\n\n## ğŸ¤ é¸£è°¢é¡¹ç›® (Special Thanks)\n\næœ¬é¡¹ç›®åœ¨å¼€å‘è¿‡ç¨‹ä¸­å‚è€ƒæˆ–å€Ÿé‰´äº†ä»¥ä¸‹ä¼˜ç§€å¼€æºé¡¹ç›®çš„æ€è·¯æˆ–ä»£ç ï¼Œæ’åä¸åˆ†å…ˆåï¼š\n\n*   [learn-claude-code](https://github.com/shareAI-lab/learn-claude-code)\n*   [Practical-Guide-to-Context-Engineering](https://github.com/WakeUp-Jin/Practical-Guide-to-Context-Engineering)\n*   [CLIProxyAPI](https://github.com/router-for-me/CLIProxyAPI)\n*   [antigravity-claude-proxy](https://github.com/badrisnarayanan/antigravity-claude-proxy)\n*   [aistudio-gemini-proxy](https://github.com/zhongruichen/aistudio-gemini-proxy)\n*   [gcli2api](https://github.com/su-kaka/gcli2api)\n\n*   **ç‰ˆæƒè®¸å¯**: åŸºäº **CC BY-NC-SA 4.0** è®¸å¯ï¼Œ**ä¸¥ç¦ä»»ä½•å½¢å¼çš„å•†ä¸šè¡Œä¸º**ã€‚\n*   **å®‰å…¨å£°æ˜**: æœ¬åº”ç”¨æ‰€æœ‰è´¦å·æ•°æ®åŠ å¯†å­˜å‚¨äºæœ¬åœ° SQLite æ•°æ®åº“ï¼Œé™¤éå¼€å¯åŒæ­¥åŠŸèƒ½ï¼Œå¦åˆ™æ•°æ®ç»ä¸ç¦»å¼€æ‚¨çš„è®¾å¤‡ã€‚\n\n---\n\n<div align=\"center\">\n  <p>å¦‚æœæ‚¨è§‰å¾—è¿™ä¸ªå·¥å…·æœ‰æ‰€å¸®åŠ©ï¼Œæ¬¢è¿åœ¨ GitHub ä¸Šç‚¹ä¸€ä¸ª â­ï¸</p>\n  <p>Copyright Â© 2025 Antigravity Team.</p>\n</div>\n",
      "stars_today": 292
    },
    {
      "id": 799669968,
      "name": "100-exercises-to-learn-rust",
      "full_name": "mainmatter/100-exercises-to-learn-rust",
      "description": "A self-paced course to learn Rust, one exercise at a time.",
      "html_url": "https://github.com/mainmatter/100-exercises-to-learn-rust",
      "stars": 9019,
      "forks": 1939,
      "language": "Rust",
      "topics": [
        "exercises",
        "learning-by-doing",
        "rust"
      ],
      "created_at": "2024-05-12T20:20:12Z",
      "updated_at": "2026-02-07T02:01:18Z",
      "pushed_at": "2025-10-30T13:48:38Z",
      "open_issues": 45,
      "owner": {
        "login": "mainmatter",
        "avatar_url": "https://avatars.githubusercontent.com/u/56627?v=4"
      },
      "readme": "# Learn Rust, one exercise at a time\n\nYou've heard about Rust, but you never had the chance to try it out?\\\nThis course is for you!\n\nYou'll learn Rust by solving 100 exercises.\\\nYou'll go from knowing nothing about Rust to being able to start\nwriting your own programs, one exercise at a time.\n\n> [!NOTE]\n> This course has been written by [Mainmatter](https://mainmatter.com/rust-consulting/).\\\n> It's one of the trainings in [our portfolio of Rust workshops](https://mainmatter.com/services/workshops/rust/).\\\n> Check out our [landing page](https://mainmatter.com/rust-consulting/) if you're looking for Rust consulting or\n> training!\n\n## Getting started\n\nGo to [rust-exercises.com](https://rust-exercises.com) and follow the instructions there\nto get started with the course.\n\n## Requirements\n\n- **Rust** (follow instructions [here](https://www.rust-lang.org/tools/install)).\\\n  If `rustup` is already installed on your system, run `rustup update` (or another appropriate command depending on how\n  you installed Rust on your system)\n  to make sure you're running on the latest stable version.\n- _(Optional but recommended)_ An IDE with Rust autocompletion support.\n  We recommend one of the following:\n  - [RustRover](https://www.jetbrains.com/rust/);\n  - [Visual Studio Code](https://code.visualstudio.com) with\n    the [`rust-analyzer`](https://marketplace.visualstudio.com/items?itemName=matklad.rust-analyzer) extension.\n\n## Solutions\n\nYou can find the solutions to the exercises in\nthe [`solutions` branch](https://github.com/mainmatter/100-exercises-to-learn-rust/tree/solutions) of this repository.\n\n# License\n\nCopyright Â© 2024- Mainmatter GmbH (https://mainmatter.com), released under the\n[Creative Commons Attribution-NonCommercial 4.0 International license](https://creativecommons.org/licenses/by-nc/4.0/).\n",
      "stars_today": 234
    },
    {
      "id": 965415649,
      "name": "codex",
      "full_name": "openai/codex",
      "description": "Lightweight coding agent that runs in your terminal",
      "html_url": "https://github.com/openai/codex",
      "stars": 59299,
      "forks": 7756,
      "language": "Rust",
      "topics": [],
      "created_at": "2025-04-13T05:37:54Z",
      "updated_at": "2026-02-07T02:10:40Z",
      "pushed_at": "2026-02-07T02:25:19Z",
      "open_issues": 1052,
      "owner": {
        "login": "openai",
        "avatar_url": "https://avatars.githubusercontent.com/u/14957082?v=4"
      },
      "readme": "<p align=\"center\"><code>npm i -g @openai/codex</code><br />or <code>brew install --cask codex</code></p>\n<p align=\"center\"><strong>Codex CLI</strong> is a coding agent from OpenAI that runs locally on your computer.\n<p align=\"center\">\n  <img src=\"https://github.com/openai/codex/blob/main/.github/codex-cli-splash.png\" alt=\"Codex CLI splash\" width=\"80%\" />\n</p>\n</br>\nIf you want Codex in your code editor (VS Code, Cursor, Windsurf), <a href=\"https://developers.openai.com/codex/ide\">install in your IDE.</a>\n</br>If you are looking for the <em>cloud-based agent</em> from OpenAI, <strong>Codex Web</strong>, go to <a href=\"https://chatgpt.com/codex\">chatgpt.com/codex</a>.</p>\n\n---\n\n## Quickstart\n\n### Installing and running Codex CLI\n\nInstall globally with your preferred package manager:\n\n```shell\n# Install using npm\nnpm install -g @openai/codex\n```\n\n```shell\n# Install using Homebrew\nbrew install --cask codex\n```\n\nThen simply run `codex` to get started.\n\n<details>\n<summary>You can also go to the <a href=\"https://github.com/openai/codex/releases/latest\">latest GitHub Release</a> and download the appropriate binary for your platform.</summary>\n\nEach GitHub Release contains many executables, but in practice, you likely want one of these:\n\n- macOS\n  - Apple Silicon/arm64: `codex-aarch64-apple-darwin.tar.gz`\n  - x86_64 (older Mac hardware): `codex-x86_64-apple-darwin.tar.gz`\n- Linux\n  - x86_64: `codex-x86_64-unknown-linux-musl.tar.gz`\n  - arm64: `codex-aarch64-unknown-linux-musl.tar.gz`\n\nEach archive contains a single entry with the platform baked into the name (e.g., `codex-x86_64-unknown-linux-musl`), so you likely want to rename it to `codex` after extracting it.\n\n</details>\n\n### Using Codex with your ChatGPT plan\n\nRun `codex` and select **Sign in with ChatGPT**. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan. [Learn more about what's included in your ChatGPT plan](https://help.openai.com/en/articles/11369540-codex-in-chatgpt).\n\nYou can also use Codex with an API key, but this requires [additional setup](https://developers.openai.com/codex/auth#sign-in-with-an-api-key).\n\n## Docs\n\n- [**Codex Documentation**](https://developers.openai.com/codex)\n- [**Contributing**](./docs/contributing.md)\n- [**Installing & building**](./docs/install.md)\n- [**Open source fund**](./docs/open-source-fund.md)\n\nThis repository is licensed under the [Apache-2.0 License](LICENSE).\n",
      "stars_today": 210
    },
    {
      "id": 901607132,
      "name": "litebox",
      "full_name": "microsoft/litebox",
      "description": "A security-focused library OS supporting kernel- and user-mode execution",
      "html_url": "https://github.com/microsoft/litebox",
      "stars": 750,
      "forks": 35,
      "language": "Rust",
      "topics": [],
      "created_at": "2024-12-11T01:23:27Z",
      "updated_at": "2026-02-07T02:34:02Z",
      "pushed_at": "2026-02-07T01:43:51Z",
      "open_issues": 78,
      "owner": {
        "login": "microsoft",
        "avatar_url": "https://avatars.githubusercontent.com/u/6154722?v=4"
      },
      "readme": "# LiteBox\n\n> A security-focused library OS\n\n> [!NOTE]  \n> This project is currently actively evolving and improving. While we are\n> working toward a stable release, some APIs and interfaces may change as the\n> design continues to mature. You are welcome to explore and experiment, but if\n> you need long-term stability, it may be best to wait for a stable release, or\n> be prepared to adapt to updates along the way.\n\nLiteBox is a sandboxing library OS that drastically cuts down the interface to the host, thereby reducing attack surface.  It focuses on easy interop of various \"North\" shims and \"South\" platforms.  LiteBox is designed for usage in both kernel and non-kernel scenarios.\n\nLiteBox exposes a Rust-y [`nix`](https://docs.rs/nix)/[`rustix`](https://docs.rs/rustix)-inspired \"North\" interface when it is provided a `Platform` interface at its \"South\".  These interfaces allow for a wide variety of use-cases, easily allowing for connection between any of the North--South pairs.\n\nExample use cases include:\n- Running unmodified Linux programs on Windows\n- Sandboxing Linux applications on Linux\n- Run programs on top of SEV SNP\n- Running OP-TEE programs on Linux\n- Running on LVBS\n\n![LiteBox and related projects](./.figures/litebox.svg)\n\n## Contributing\n\nSee the following files for details:\n\n- [CONTRIBUTING.md](./CONTRIBUTING.md)\n- [CODE_OF_CONDUCT.md](./CODE_OF_CONDUCT.md)\n- [SECURITY.md](./SECURITY.md)\n- [SUPPORT.md](./SUPPORT.md)\n\n## License\n\nMIT License.  See [./LICENSE](./LICENSE) for details.\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft \ntrademarks or logos is subject to and must follow \n[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\nAny use of third-party trademarks or logos are subject to those third-party's policies.\n",
      "stars_today": 208
    },
    {
      "id": 4279682,
      "name": "fish-shell",
      "full_name": "fish-shell/fish-shell",
      "description": "The user-friendly command line shell.",
      "html_url": "https://github.com/fish-shell/fish-shell",
      "stars": 32500,
      "forks": 2222,
      "language": "Rust",
      "topics": [
        "fish",
        "rust",
        "shell",
        "terminal"
      ],
      "created_at": "2012-05-10T03:00:55Z",
      "updated_at": "2026-02-07T01:03:15Z",
      "pushed_at": "2026-02-06T04:39:21Z",
      "open_issues": 528,
      "owner": {
        "login": "fish-shell",
        "avatar_url": "https://avatars.githubusercontent.com/u/1828073?v=4"
      },
      "readme": ".. |Cirrus CI| image:: https://api.cirrus-ci.com/github/fish-shell/fish-shell.svg?branch=master\n      :target: https://cirrus-ci.com/github/fish-shell/fish-shell\n      :alt: Cirrus CI Build Status\n\n`fish <https://fishshell.com/>`__ - the friendly interactive shell |Build Status| |Cirrus CI|\n=============================================================================================\n\nfish is a smart and user-friendly command line shell for macOS, Linux,\nand the rest of the family. fish includes features like syntax\nhighlighting, autosuggest-as-you-type, and fancy tab completions that\njust work, with no configuration required.\n\nFor downloads, screenshots and more, go to https://fishshell.com/.\n\nQuick Start\n-----------\n\nfish generally works like other shells, like bash or zsh. A few\nimportant differences can be found at\nhttps://fishshell.com/docs/current/tutorial.html by searching for the\nmagic phrase â€œunlike other shellsâ€.\n\nDetailed user documentation is available by running ``help`` within\nfish, and also at https://fishshell.com/docs/current/index.html\n\nGetting fish\n------------\n\nmacOS\n~~~~~\n\nfish can be installed:\n\n-  using `Homebrew <http://brew.sh/>`__: ``brew install fish``\n-  using `MacPorts <https://www.macports.org/>`__:\n   ``sudo port install fish``\n-  using the `installer from fishshell.com <https://fishshell.com/>`__\n-  as a `standalone app from fishshell.com <https://fishshell.com/>`__\n\nNote: The minimum supported macOS version is 10.12.\n\nPackages for Linux\n~~~~~~~~~~~~~~~~~~\n\nPackages for Debian, Fedora, openSUSE, and Red Hat Enterprise\nLinux/CentOS are available from the `openSUSE Build\nService <https://software.opensuse.org/download.html?project=shells%3Afish&package=fish>`__.\n\nPackages for Ubuntu are available from the `fish\nPPA <https://launchpad.net/~fish-shell/+archive/ubuntu/release-4>`__,\nand can be installed using the following commands:\n\n::\n\n   sudo apt-add-repository ppa:fish-shell/release-4\n   sudo apt update\n   sudo apt install fish\n\nInstructions for other distributions may be found at\n`fishshell.com <https://fishshell.com>`__.\n\nWindows\n~~~~~~~\n\n-  On Windows 10/11, fish can be installed under the WSL Windows Subsystem\n   for Linux with the instructions for the appropriate distribution\n   listed above under â€œPackages for Linuxâ€, or from source with the\n   instructions below.\n-  Fish can also be installed on all versions of Windows using\n   `Cygwin <https://cygwin.com/>`__ or `MSYS2 <https://github.com/Berrysoft/fish-msys2>`__.\n\nBuilding from source\n~~~~~~~~~~~~~~~~~~~~\n\nIf packages are not available for your platform, GPG-signed tarballs are\navailable from `fishshell.com <https://fishshell.com/>`__ and\n`fish-shell on\nGitHub <https://github.com/fish-shell/fish-shell/releases>`__. See the\n`Building <#building>`_ section for instructions.\n\nRunning fish\n------------\n\nOnce installed, run ``fish`` from your current shell to try fish out!\n\nDependencies\n~~~~~~~~~~~~\n\nRunning fish requires:\n\n-  some common \\*nix system utilities (currently ``mktemp``), in\n   addition to the basic POSIX utilities (``cat``, ``cut``, ``dirname``,\n   ``ls``, ``mkdir``, ``mkfifo``, ``rm``, ``sh``, ``sort``, ``tee``, ``tr``,\n   ``uname`` and ``sed`` at least, but the full coreutils plus ``find`` and\n   ``awk`` is preferred)\n\nThe following optional features also have specific requirements:\n\n-  builtin commands that have the ``--help`` option or print usage\n   messages require ``man`` for display\n-  automated completion generation from manual pages requires Python 3.5+\n-  the ``fish_config`` web configuration tool requires Python 3.5+ and a web browser\n-  the :ref:`alt-o <shared-binds-alt-o>` binding requires the ``file`` program.\n-  system clipboard integration (with the default Ctrl-V and Ctrl-X\n   bindings) require either the ``xsel``, ``xclip``,\n   ``wl-copy``/``wl-paste`` or ``pbcopy``/``pbpaste`` utilities\n-  full completions for ``yarn`` and ``npm`` require the\n   ``all-the-package-names`` NPM module\n-  ``colorls`` is used, if installed, to add color when running ``ls`` on platforms\n   that do not have color support (such as OpenBSD)\n\nBuilding\n--------\n\nDependencies\n~~~~~~~~~~~~\n\nCompiling fish requires:\n\n-  Rust (version 1.85 or later), including cargo\n-  CMake (version 3.15 or later)\n-  a C compiler (for system feature detection and the test helper binary)\n-  PCRE2 (headers and libraries) - optional, this will be downloaded if missing\n-  gettext (only the msgfmt tool) - optional, for translation support\n-  an Internet connection, as other dependencies will be downloaded automatically\n\nSphinx is also optionally required to build the documentation from a\ncloned git repository.\n\nAdditionally, running the full test suite requires diff, git, Python 3.5+, pexpect, less, tmux and wget.\n\nBuilding from source with CMake\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nRather than building from source, consider using a packaged build for your platform. Using the\nsteps below makes fish difficult to uninstall or upgrade. Release packages are available from the\nlinks above, and up-to-date `development builds of fish are available for many platforms\n<https://github.com/fish-shell/fish-shell/wiki/Development-builds>`__\n\nTo install into ``/usr/local``, run:\n\n.. code:: shell\n\n   mkdir build; cd build\n   cmake ..\n   cmake --build .\n   sudo cmake --install .\n\nThe install directory can be changed using the\n``-DCMAKE_INSTALL_PREFIX`` parameter for ``cmake``.\n\nCMake Build options\n~~~~~~~~~~~~~~~~~~~\n\nIn addition to the normal CMake build options (like ``CMAKE_INSTALL_PREFIX``), fish's CMake build has some other options available to customize it.\n\n- Rust_COMPILER=path - the path to rustc. If not set, cmake will check $PATH and ~/.cargo/bin\n- Rust_CARGO=path - the path to cargo. If not set, cmake will check $PATH and ~/.cargo/bin\n- Rust_CARGO_TARGET=target - the target to pass to cargo. Set this for cross-compilation.\n- WITH_DOCS=ON|OFF - whether to build the documentation. By default, this is ON when Sphinx is installed.\n- FISH_INDENT_FOR_BUILDING_DOCS - useful for cross-compilation.\n  Set this to the path to the ``fish_indent`` executable to use for building HTML docs.\n  By default, ``${CMAKE_BINARY_DIR}/fish_indent`` will be used.\n  If that's not runnable on the compile host,\n  you can build a native one with ``cargo build --bin fish_indent`` and set this to ``$PWD/target/debug/fish_indent``.\n- FISH_USE_SYSTEM_PCRE2=ON|OFF - whether to use an installed pcre2. This is normally autodetected.\n- WITH_MESSAGE_LOCALIZATION=ON|OFF - whether to include translations.\n- extra_functionsdir, extra_completionsdir and extra_confdir - to compile in an additional directory to be searched for functions, completions and configuration snippets\n\nBuilding fish with Cargo\n~~~~~~~~~~~~~~~~~~~~~~~~\n\nYou can also build fish with Cargo.\nThis example uses `uv <https://github.com/astral-sh/uv>`__ to install Sphinx (which is used for man-pages and ``--help`` options).\nYou can also install Sphinx another way and drop the ``uv run --no-managed-python`` prefix.\n\n.. code:: shell\n\n    git clone https://github.com/fish-shell/fish-shell\n    cd fish-shell\n\n    # Optional: check out a specific version rather than building the latest\n    # development version.\n    git checkout \"$(git for-each-ref refs/tags/ | awk '$2 == \"tag\" { print $3 }' | tail -1)\"\n\n    uv run --no-managed-python \\\n        cargo install --path .\n\nThis will place standalone binaries in ``~/.cargo/bin/``, but you can move them wherever you want.\n\nTo disable translations, disable the ``localize-messages`` feature by passing ``--no-default-features --features=embed-manpages`` to cargo.\n\nYou can also link this build statically (but not against glibc) and move it to other computers.\n\nHere are the remaining advantages of a full installation, as currently done by CMake:\n\n- Man pages like ``fish(1)`` installed in standard locations, easily accessible from outside fish.\n- Separate files for builtins (e.g. ``$PREFIX/share/fish/man/man1/abbr.1``).\n- A local copy of the HTML documentation, typically accessed via the ``help`` fish function.\n  In Cargo builds, ``help`` will redirect to `<https://fishshell.com/docs/current/>`__\n- Ability to use our CMake options extra_functionsdir, extra_completionsdir and extra_confdir,\n  (also recorded in ``$PREFIX/share/pkgconfig/fish.pc``)\n  which are used by some package managers to house third-party completions.\n  Regardless of build system, fish uses ``$XDG_DATA_DIRS/{vendor_completion.d,vendor_conf.d,vendor_functions.d}``.\n\nContributing Changes to the Code\n--------------------------------\n\nSee the `Guide for Developers <CONTRIBUTING.rst>`__.\n\nContact Us\n----------\n\nQuestions, comments, rants and raves can be posted to the official fish\nmailing list at https://lists.sourceforge.net/lists/listinfo/fish-users\nor join us on our `matrix\nchannel <https://matrix.to/#/#fish-shell:matrix.org>`__. Or use the `fish tag\non Unix & Linux Stackexchange <https://unix.stackexchange.com/questions/tagged/fish>`__.\nThere is also a fish tag on Stackoverflow, but it is typically a poor fit.\n\nFound a bug? Have an awesome idea? Please `open an\nissue <https://github.com/fish-shell/fish-shell/issues/new>`__.\n\n.. |Build Status| image:: https://github.com/fish-shell/fish-shell/workflows/make%20test/badge.svg\n   :target: https://github.com/fish-shell/fish-shell/actions\n",
      "stars_today": 193
    },
    {
      "id": 1052051256,
      "name": "anet",
      "full_name": "ZeroTworu/anet",
      "description": "Simple Rust VPN Client / Server",
      "html_url": "https://github.com/ZeroTworu/anet",
      "stars": 540,
      "forks": 48,
      "language": "Rust",
      "topics": [
        "rust",
        "vpn"
      ],
      "created_at": "2025-09-07T09:52:50Z",
      "updated_at": "2026-02-07T02:33:11Z",
      "pushed_at": "2026-02-05T05:30:07Z",
      "open_issues": 11,
      "owner": {
        "login": "ZeroTworu",
        "avatar_url": "https://avatars.githubusercontent.com/u/17995677?v=4"
      },
      "readme": "# ANet: Ğ¡ĞµÑ‚ÑŒ Ğ”Ñ€ÑƒĞ·ĞµĞ¹\n\n![Build Status](https://img.shields.io/badge/build-passing-brightgreen)\n![Language](https://img.shields.io/badge/rust-1.84%2B-orange)\n![Protocol](https://img.shields.io/badge/protocol-ASTP_v1.0-blue)\n\n**ANet** â€” ÑÑ‚Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ¾Ñ€Ğ³Ğ°Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€Ğ¸Ğ²Ğ°Ñ‚Ğ½Ğ¾Ğ³Ğ¾, Ğ·Ğ°Ñ‰Ğ¸Ñ‰ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ° Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ±Ğ»Ğ¸Ğ·ĞºĞ¸Ğ¼Ğ¸ Ğ»ÑĞ´ÑŒĞ¼Ğ¸. ĞœÑ‹ ÑÑ‚Ñ€Ğ¾Ğ¸Ğ¼ Ñ†Ğ¸Ñ„Ñ€Ğ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾ÑÑ‚Ñ‹ Ñ‚Ğ°Ğ¼, Ğ³Ğ´Ğµ Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ñ‹Ğµ Ğ¿ÑƒÑ‚Ğ¸ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹.\n\nĞ­Ñ‚Ğ¾ Ğ½Ğµ ÑĞµÑ€Ğ²Ğ¸Ñ. Ğ­Ñ‚Ğ¾ Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ Ğ´Ğ»Ñ ÑĞ²ÑĞ·Ğ¸ Ñ‚ĞµÑ…, ĞºÑ‚Ğ¾ Ğ´Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ´Ñ€ÑƒĞ³ Ğ´Ñ€ÑƒĞ³Ñƒ.\n\n## ĞÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸\n\nĞ’ Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ° Ğ»ĞµĞ¶Ğ¸Ñ‚ ÑĞ¾Ğ±ÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ‚Ñ€Ğ°Ğ½ÑĞ¿Ğ¾Ñ€Ñ‚Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ» **ASTP (ANet Secure Transport Protocol)**, Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ Ñ„Ğ¾ĞºÑƒÑĞ¾Ğ¼ Ğ½Ğ°:\n\n*   **ĞŸÑ€Ğ¸Ğ²Ğ°Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ:** ĞŸĞ¾Ğ»Ğ½Ğ¾Ğµ ÑĞºĞ²Ğ¾Ğ·Ğ½Ğ¾Ğµ ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ (ChaCha20Poly1305 / X25519).\n*   **Ğ£ÑÑ‚Ğ¾Ğ¹Ñ‡Ğ¸Ğ²Ğ¾ÑÑ‚ÑŒ:** Ğ¡Ñ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ°Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ° Ğ² ÑĞµÑ‚ÑÑ… Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğ¼Ğ¸ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑĞ¼Ğ¸ Ğ¿Ğ°ĞºĞµÑ‚Ğ¾Ğ² Ğ¸ Ğ½ĞµÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¼ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸ĞµĞ¼.\n*   **ĞœĞ¸Ğ¼Ğ¸ĞºÑ€Ğ¸Ñ:** Ğ¢Ñ€Ğ°Ğ½ÑĞ¿Ğ¾Ñ€Ñ‚Ğ½Ñ‹Ğ¹ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ½ĞµĞ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ğ¼ Ğ¾Ñ‚ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾Ğ³Ğ¾ ÑˆÑƒĞ¼Ğ° (High-entropy UDP stream).\n*   **ĞšÑ€Ğ¾ÑÑĞ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ:** ĞšĞ»Ğ¸ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Linux, Windows Ğ¸ Android.\n\n## Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°\n\nĞŸÑ€Ğ¾ĞµĞºÑ‚ Ğ½Ğ°Ğ¿Ğ¸ÑĞ°Ğ½ Ğ½Ğ° Rust Ğ¸ Ñ€Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½ Ğ½Ğ° Ğ¼Ğ¾Ğ´ÑƒĞ»Ğ¸:\n\n*   `anet-server` â€” Ğ£Ğ·ĞµĞ» ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸.\n*   `anet-client-cli` â€” ĞšĞ¾Ğ½ÑĞ¾Ğ»ÑŒĞ½Ñ‹Ğ¹ ĞºĞ»Ğ¸ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Linux/Headless ÑĞ¸ÑÑ‚ĞµĞ¼.\n*   `anet-client-gui` â€” Ğ“Ñ€Ğ°Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ ĞºĞ»Ğ¸ĞµĞ½Ñ‚ (Windows/Linux) Ñ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¼ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ¾Ğ¼.\n*   `anet-mobile` â€” Ğ‘Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ° Ğ¸ JNI-Ğ±Ğ¸Ğ½Ğ´Ğ¸Ğ½Ğ³Ğ¸ Ğ´Ğ»Ñ Android.\n*   `anet-common` â€” Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ»Ğ° ASTP Ğ¸ ĞºÑ€Ğ¸Ğ¿Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ğ¸.\n*   `anet-keygen` â€” Ğ£Ñ‚Ğ¸Ğ»Ğ¸Ñ‚Ğ° Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ĞºĞ»ÑÑ‡ĞµĞ¹ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ°.\n\n## Ğ¡Ğ±Ğ¾Ñ€ĞºĞ°\n\nĞ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ Rust (cargo).\n\n```bash\n# Ğ¡Ğ±Ğ¾Ñ€ĞºĞ° Ğ²ÑĞµÑ… ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²\ncargo build --release\n```\n\nSupport the Chaos / ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ°Ñ‚ÑŒ Ğ¥Ğ°Ğ¾Ñ\n\nĞ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ²ĞµĞ´ĞµÑ‚ÑÑ Ğ² ÑƒÑĞ»Ğ¾Ğ²Ğ¸ÑÑ… Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ½Ğ¾Ğ¹ Ñ€Ğ°Ğ´Ğ¸Ğ°Ñ†Ğ¸Ğ¸ (Ğ§ĞµÑ€Ğ½Ğ¸ĞºĞ¾Ğ²ĞºĞ°), Ğ¿Ğ¾Ğ´ Ğ¿Ñ€Ğ¸ÑÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ²Ğ·Ğ³Ğ»ÑĞ´Ğ¾Ğ¼ Ğ¥Ğ°Ğ½ÑÑˆĞ¸ Ğ¸ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ°Ğ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ² ÑĞ½ĞµÑ€Ğ³Ğ¸Ğ¸ (C2H5OH).\n\nĞ•ÑĞ»Ğ¸ ANet Ğ¿Ğ¾Ğ¼Ğ¾Ğ³ Ñ‚ĞµĞ±Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ¸Ñ‚ÑŒ ÑÑ‚ĞµĞ½Ñƒ Ñ†ĞµĞ½Ğ·ÑƒÑ€Ñ‹ â€” Ğ½Ğ°Ğ»ĞµĞ¹ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ñƒ.\n\n    ĞĞ° Ğ²Ğ¾Ğ´ĞºÑƒ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ñƒ (Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ ĞºĞ¾Ğ´ ĞºĞ¾Ğ¼Ğ¿Ğ¸Ğ»Ğ¸Ğ»ÑÑ): 2202 2084 3646 6800\n\n    ĞĞ° Ğ±ÑƒĞ»Ğ¾Ñ‡ĞºĞ¸ Ğ´Ğ»Ñ Ğ¥Ğ°Ğ½Ñ (Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğµ ĞºÑƒÑĞ°Ğ»Ğ°ÑÑŒ): 2202 2084 3646 6800\n\n    ĞĞ° J7 (Ğ´Ğ»Ñ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ° Ğ¸Ğ· ÑˆÑ‚Ğ¾Ğ¿Ğ¾Ñ€Ğ°): 2202 2084 3646 6800",
      "stars_today": 193
    },
    {
      "id": 1022937426,
      "name": "AIClient-2-API",
      "full_name": "justlovemaki/AIClient-2-API",
      "description": "Simulates Gemini CLI, Antigravity, Qwen Code, and Kiro client requests, compatible with the OpenAI API. It supports thousands of Gemini model requests per day and offers free use of the built-in Claude model in Kiro. Easily connect to any client via the API, making AI development more efficient!",
      "html_url": "https://github.com/justlovemaki/AIClient-2-API",
      "stars": 3609,
      "forks": 579,
      "language": "JavaScript",
      "topics": [
        "aicoding",
        "free"
      ],
      "created_at": "2025-07-20T07:05:56Z",
      "updated_at": "2026-02-07T02:17:43Z",
      "pushed_at": "2026-02-06T03:44:42Z",
      "open_issues": 5,
      "owner": {
        "login": "justlovemaki",
        "avatar_url": "https://avatars.githubusercontent.com/u/22851716?v=4"
      },
      "readme": "<div align=\"center\">\n\n<img src=\"src/img/logo-mid.webp\" alt=\"logo\"  style=\"width: 128px; height: 128px;margin-bottom: 3px;\">\n\n# AIClient-2-API ğŸš€\n\n**A powerful proxy that can unify the requests of various client-only large model APIs (Gemini CLI, Antigravity, Qwen Code, Kiro ...), simulate requests, and encapsulate them into a local OpenAI-compatible interface.**\n\n</div>\n\n<div align=\"center\">\n\n<a href=\"https://deepwiki.com/justlovemaki/AIClient-2-API\"><img src=\"https://deepwiki.com/badge.svg\" alt=\"Ask DeepWiki\"  style=\"width: 134px; height: 23px;margin-bottom: 3px;\"></a>\n\n[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)\n[![Node.js](https://img.shields.io/badge/Node.js-â‰¥20.0.0-green.svg)](https://nodejs.org/)\n[![Docker](https://img.shields.io/badge/docker-â‰¥20.0.0-blue.svg)](https://hub.docker.com/r/justlikemaki/aiclient-2-api)\n[![GitHub stars](https://img.shields.io/github/stars/justlovemaki/AIClient-2-API.svg?style=flat&label=Star)](https://github.com/justlovemaki/AIClient-2-API/stargazers)\n[![GitHub issues](https://img.shields.io/github/issues/justlovemaki/AIClient-2-API.svg)](https://github.com/justlovemaki/AIClient-2-API/issues)\n\n[**ğŸ”§ OpenClaw Config**](./docs/OPENCLAW_CONFIG_GUIDE.md) | [ä¸­æ–‡](./README-ZH.md) | [**ğŸ‘‰ English**](./README.md) | [æ—¥æœ¬èª](./README-JA.md) | [**ğŸ“š Documentation**](https://aiproxy.justlikemaki.vip/en/)\n\n</div>\n\n`AIClient2API` is an API proxy service that breaks through client limitations, converting free large models originally restricted to client use only (such as Gemini, Antigravity, Qwen Code, Kiro) into standard OpenAI-compatible interfaces that can be called by any application. Built on Node.js, it supports intelligent conversion between OpenAI, Claude, and Gemini protocols, enabling tools like Cherry-Studio, NextChat, and Cline to freely use advanced models such as Claude Opus 4.5, Gemini 3.0 Pro, and Qwen3 Coder Plus at scale. The project adopts a modular architecture based on strategy and adapter patterns, with built-in account pool management, intelligent polling, automatic failover, and health check mechanisms, ensuring 99.9% service availability.\n\n> [!NOTE]\n> **ğŸ‰ Important Milestone**\n>\n> - Thanks to Ruan Yifeng for the recommendation in [Weekly Issue 359](https://www.ruanyifeng.com/blog/2025/08/weekly-issue-359.html)\n>\n> **ğŸ“… Version Update Log**\n>\n> <details>\n> <summary>Click to expand detailed version history</summary>\n>\n> - **2026.01.26** - Added Codex protocol support: supports OpenAI Codex OAuth authorization access\n> - **2026.01.25** - Enhanced AI Monitor plugin: supports monitoring request parameters and responses before and after AI protocol conversion. Optimized log management: unified log format, visual configuration\n> - **2026.01.15** - Optimized provider pool manager: added async refresh queue mechanism, buffer queue deduplication, global concurrency control, node warmup and automatic expiry detection\n> - **2026.01.07** - Added iFlow protocol support, enabling access to Qwen, Kimi, DeepSeek, and GLM series models via OAuth authentication with automatic token refresh\n> - **2026.01.03** - Added theme switching functionality and optimized provider pool initialization, removed the fallback strategy of using provider default configuration\n> - **2025.12.30** - Added main process management and automatic update functionality\n> - **2025.12.25** - Unified configuration management: All configs centralized to `configs/` directory. Docker users need to update mount path to `-v \"local_path:/app/configs\"`\n> - **2025.12.11** - Automatically built Docker images are now available on Docker Hub: [justlikemaki/aiclient-2-api](https://hub.docker.com/r/justlikemaki/aiclient-2-api)\n> - **2025.11.30** - Added Antigravity protocol support, enabling access to Gemini 3 Pro, Claude Sonnet 4.5, and other models via Google internal interfaces\n> - **2025.11.16** - Added Ollama protocol support, unified interface to access all supported models (Claude, Gemini, Qwen, OpenAI, etc.)\n> - **2025.11.11** - Added Web UI management console, supporting real-time configuration management and health status monitoring\n> - **2025.11.06** - Added support for Gemini 3 Preview, enhanced model compatibility and performance optimization\n> - **2025.10.18** - Kiro open registration, new accounts get 500 credits, full support for Claude Sonnet 4.5\n> - **2025.09.01** - Integrated Qwen Code CLI, added `qwen3-coder-plus` model support\n> - **2025.08.29** - Released account pool management feature, supporting multi-account polling, intelligent failover, and automatic degradation strategies\n>   - Configuration: Add `PROVIDER_POOLS_FILE_PATH` parameter in `configs/config.json`\n>   - Reference configuration: [provider_pools.json](./configs/provider_pools.json.example)\n> - **History Developed**\n>   - Support Gemini CLI, Kiro and other client2API\n>   - OpenAI, Claude, Gemini three-protocol mutual conversion, automatic intelligent switching\n> </details>\n\n---\n\n## ğŸ’¡ Core Advantages\n\n### ğŸ¯ Unified Access, One-Stop Management\n*   **Multi-Model Unified Interface**: Through standard OpenAI-compatible protocol, configure once to access mainstream large models including Gemini, Claude, Qwen Code, Kimi K2, MiniMax M2\n*   **Flexible Switching Mechanism**: Path routing, support dynamic model switching via startup parameters or environment variables to meet different scenario requirements\n*   **Zero-Cost Migration**: Fully compatible with OpenAI API specifications, tools like Cherry-Studio, NextChat, Cline can be used without modification\n*   **Multi-Protocol Intelligent Conversion**: Support intelligent conversion between OpenAI, Claude, and Gemini protocols for cross-protocol model invocation\n\n### ğŸš€ Break Through Limitations, Improve Efficiency\n*   **Bypass Official Restrictions**: Utilize OAuth authorization mechanism to effectively break through rate and quota limits of services like Gemini, Antigravity\n*   **Free Advanced Models**: Use Claude Opus 4.5 for free via Kiro API mode, use Qwen3 Coder Plus via Qwen OAuth mode, reducing usage costs\n*   **Intelligent Account Pool Scheduling**: Support multi-account polling, automatic failover, and configuration degradation, ensuring 99.9% service availability\n\n### ğŸ›¡ï¸ Secure and Controllable, Data Transparent\n*   **Full-Chain Log Recording**: Capture all request and response data, supporting auditing and debugging\n*   **Private Dataset Construction**: Quickly build proprietary training datasets based on log data\n*   **System Prompt Management**: Support override and append modes, achieving perfect combination of unified base instructions and personalized extensions\n\n### ğŸ”§ Developer-Friendly, Easy to Extend\n*   **Web UI Management Console**: Real-time configuration management, health status monitoring, API testing and log viewing\n*   **Modular Architecture**: Based on strategy and adapter patterns, adding new model providers requires only 3 steps\n*   **Complete Test Coverage**: Integration and unit test coverage 90%+, ensuring code quality\n*   **Containerized Deployment**: Provides Docker support, one-click deployment, cross-platform operation\n\n---\n\n## ğŸ“‘ Quick Navigation\n\n- [ğŸ’¡ Core Advantages](#-core-advantages)\n- [ğŸš€ Quick Start](#-quick-start)\n  - [ğŸ³ Docker Deployment](https://hub.docker.com/r/justlikemaki/aiclient-2-api)\n  - [ğŸ“‹ Core Features](#-core-features)\n- [ğŸ” Authorization Configuration Guide](#-authorization-configuration-guide)\n- [ğŸ“ Authorization File Storage Paths](#-authorization-file-storage-paths)\n- [ğŸ¦™ Ollama Protocol Usage Examples](#-ollama-protocol-usage-examples)\n- [âš™ï¸ Advanced Configuration](#advanced-configuration)\n- [â“ FAQ](#-faq)\n- [ğŸ“„ Open Source License](#-open-source-license)\n- [ğŸ™ Acknowledgements](#-acknowledgements)\n- [âš ï¸ Disclaimer](#ï¸-disclaimer)\n\n---\n\n## ğŸ”§ Usage Instructions\n\n### ğŸš€ Quick Start\n\nThe most recommended way to use AIClient-2-API is to start it through an automated script and configure it visually directly in the **Web UI console**.\n\n#### ğŸ³ Docker Quick Start (Recommended)\n\n```bash\ndocker run -d -p 3000:3000 -p 8085-8087:8085-8087 -p 1455:1455 -p 19876-19880:19876-19880 --restart=always -v \"your_path:/app/configs\" --name aiclient2api justlikemaki/aiclient-2-api\n```\n\n**Parameter Description**:\n- `-d`: Run container in background\n- `-p 3000:3000 ...`: Port mapping. 3000 is for Web UI, others are for OAuth callbacks (Gemini: 8085, Antigravity: 8086, iFlow: 8087, Codex: 1455, Kiro: 19876-19880)\n- `--restart=always`: Container auto-restart policy\n- `-v \"your_path:/app/configs\"`: Mount configuration directory (replace \"your_path\" with actual path, e.g., `/home/user/aiclient-configs`)\n- `--name aiclient2api`: Container name\n\n#### ğŸ³ Docker Compose Deployment\n\nYou can also use Docker Compose for deployment. First, navigate to the `docker` directory:\n\n```bash\ncd docker\nmkdir -p configs\ndocker compose up -d\n```\n\nTo build from source instead of using the pre-built image, edit `docker-compose.yml`:\n1. Comment out the `image: justlikemaki/aiclient-2-api:latest` line\n2. Uncomment the `build:` section\n3. Run `docker compose up -d --build`\n\n#### 1. Run the startup script\n*   **Linux/macOS**: `chmod +x install-and-run.sh && ./install-and-run.sh`\n*   **Windows**: Double-click `install-and-run.bat`\n\n#### 2. Access the console\nAfter the server starts, open your browser and visit:\nğŸ‘‰ [**http://localhost:3000**](http://localhost:3000)\n\n> **Default Password**: `admin123` (can be changed in the console or by modifying the `pwd` file after login)\n\n#### 3. Visual Configuration (Recommended)\nGo to the **\"Configuration\"** page, you can:\n*   âœ… Fill in the API Key for each provider or upload OAuth credential files\n*   âœ… Switch default model providers in real-time\n*   âœ… Monitor health status and real-time request logs\n\n#### Script Execution Example\n```\n========================================\n  AI Client 2 API Quick Install Script\n========================================\n\n[Check] Checking if Node.js is installed...\nâœ… Node.js is installed, version: v20.10.0\nâœ… Found package.json file\nâœ… node_modules directory already exists\nâœ… Project file check completed\n\n========================================\n  Starting AI Client 2 API Server...\n========================================\n\nğŸŒ Server will start on http://localhost:3000\nğŸ“– Visit http://localhost:3000 to view management interface\nâ¹ï¸  Press Ctrl+C to stop server\n```\n\n> **ğŸ’¡ Tip**: The script will automatically install dependencies and start the server. If you encounter any issues, the script provides clear error messages and suggested solutions.\n\n---\n\n### ğŸ“‹ Core Features\n\n#### Web UI Management Console\n\n![Web UI](src/img/en.png)\n\nA functional Web management interface, including:\n\n**ğŸ“Š Dashboard**: System overview, interactive routing examples, client configuration guide\n\n**âš™ï¸ Configuration**: Real-time parameter modification, supporting all providers (Gemini, Antigravity, OpenAI, Claude, Kiro, Qwen), including advanced settings and file uploads\n\n**ğŸ”— Provider Pools**: Monitor active connections, provider health statistics, enable/disable management\n\n**ğŸ“ Config Files**: Centralized OAuth credential management, supporting search filtering and file operations\n\n**ğŸ“œ Real-time Logs**: Real-time display of system and request logs, with management controls\n\n**ğŸ” Login Verification**: Default password `admin123`, can be modified via `pwd` file\n\nAccess: `http://localhost:3000` â†’ Login â†’ Sidebar navigation â†’ Take effect immediately\n\n#### Multimodal Input Capabilities\nSupports various input types such as images and documents, providing you with a richer interaction experience and more powerful application scenarios.\n\n#### Latest Model Support\nSeamlessly support the following latest large models, just configure the corresponding endpoint in Web UI or [`configs/config.json`](./configs/config.json):\n*   **Claude 4.5 Opus** - Anthropic's strongest model ever, now supported via Kiro, Antigravity\n*   **Gemini 3 Pro** - Google's next-generation architecture preview, now supported via Gemini, Antigravity\n*   **Qwen3 Coder Plus** - Alibaba Tongyi Qianwen's latest code-specific model, now supported via Qwen Code\n*   **Kimi K2 / MiniMax M2** - Synchronized support for top domestic flagship models, now supported via custom OpenAI, Claude\n\n---\n\n### ğŸ” Authorization Configuration Guide\n\n<details>\n<summary>Click to expand detailed authorization configuration steps for each provider</summary>\n\n> **ğŸ’¡ Tip**: For the best experience, it is recommended to manage authorization visually through the **Web UI console**.\n\n#### ğŸŒ Web UI Quick Authorization (Recommended)\nIn the Web UI management interface, you can complete authorization configuration rapidly:\n1. **Generate Authorization**: On the **\"Provider Pools\"** page or **\"Configuration\"** page, click the **\"Generate Authorization\"** button in the upper right corner of the corresponding provider (e.g., Gemini, Qwen).\n2. **Scan/Login**: An authorization dialog will pop up, you can click **\"Open in Browser\"** for login verification. For Qwen, just complete the web login; for Gemini and Antigravity, complete the Google account authorization.\n3. **Auto-Save**: After successful authorization, the system will automatically obtain credentials and save them to the corresponding directory in `configs/`. You can see the newly generated credentials on the **\"Config Files\"** page.\n4. **Visual Management**: You can upload or delete credentials at any time in the Web UI, or use the **\"Quick Associate\"** function to bind existing credential files to providers with one click.\n\n#### Gemini CLI OAuth Configuration\n1. **Obtain OAuth Credentials**: Visit [Google Cloud Console](https://console.cloud.google.com/) to create a project and enable Gemini API\n2. **Project Configuration**: You may need to provide a valid Google Cloud project ID, which can be specified via the startup parameter `--project-id`\n3. **Ensure Project ID**: When configuring in the Web UI, ensure the project ID entered matches the project ID displayed in the Google Cloud Console and Gemini CLI.\n\n#### Antigravity OAuth Configuration\n1. **Personal Account**: Personal accounts require separate authorization, application channels have been closed.\n2. **Pro Member**: Antigravity is temporarily open to Pro members, you need to purchase a Pro membership first.\n3. **Organization Account**: Organization accounts require separate authorization, contact the administrator to obtain authorization.\n\n#### Qwen Code OAuth Configuration\n1. **First Authorization**: After configuring the Qwen service, the system will automatically open the authorization page in the browser\n2. **Recommended Parameters**: Use official default parameters for best results\n   ```json\n   {\n     \"temperature\": 0,\n     \"top_p\": 1\n   }\n   ```\n\n#### Kiro API Configuration\n1. **Environment Preparation**: [Download and install Kiro client](https://kiro.dev/pricing/)\n2. **Complete Authorization**: Log in to your account in the client to generate `kiro-auth-token.json` credential file\n3. **Best Practice**: Recommended to use with **Claude Code** for optimal experience\n4. **Important Notice**: Kiro service usage policy has been updated, please visit the official website for the latest usage restrictions and terms\n\n#### iFlow OAuth Configuration\n1. **First Authorization**: In Web UI's \"Configuration\" or \"Provider Pools\" page, click the \"Generate Authorization\" button for iFlow\n2. **Phone Login**: The system will open the iFlow authorization page, complete login verification using your phone number\n3. **Auto Save**: After successful authorization, the system will automatically obtain the API Key and save credentials\n4. **Supported Models**: Qwen3 series, Kimi K2, DeepSeek V3/R1, GLM-4.6/4.7, etc.\n5. **Auto Refresh**: The system will automatically refresh tokens when they are about to expire, no manual intervention required\n\n#### Codex OAuth Configuration\n1. **Generate Authorization**: On the Web UI \"Provider Pools\" or \"Configuration\" page, click the \"Generate Authorization\" button for Codex\n2. **Browser Login**: The system opens the OpenAI Codex authorization page to complete OAuth login\n3. **Auto Save**: After successful authorization, the system automatically saves the Codex OAuth credential file\n4. **Callback Port**: Ensure the OAuth callback port `1455` is not occupied\n\n#### Account Pool Management Configuration\n1. **Create Pool Configuration File**: Create a configuration file referencing [provider_pools.json.example](./configs/provider_pools.json.example)\n2. **Configure Pool Parameters**: Set `PROVIDER_POOLS_FILE_PATH` in `configs/config.json` to point to the pool configuration file\n3. **Startup Parameter Configuration**: Use the `--provider-pools-file <path>` parameter to specify the pool configuration file path\n4. **Health Check**: The system will automatically perform periodic health checks and avoid using unhealthy providers\n\n</details>\n\n### ğŸ“ Authorization File Storage Paths\n\n<details>\n<summary>Click to expand default storage locations for authorization credentials</summary>\n\nDefault storage locations for authorization credential files of each service:\n\n| Service | Default Path | Description |\n|------|---------|------|\n| **Gemini** | `~/.gemini/oauth_creds.json` | OAuth authentication credentials |\n| **Kiro** | `~/.aws/sso/cache/kiro-auth-token.json` | Kiro authentication token |\n| **Qwen** | `~/.qwen/oauth_creds.json` | Qwen OAuth credentials |\n| **Antigravity** | `~/.antigravity/oauth_creds.json` | Antigravity OAuth credentials (supports Claude 4.5 Opus) |\n| **iFlow** | `~/.iflow/oauth_creds.json` | iFlow OAuth credentials (supports Qwen, Kimi, DeepSeek, GLM) |\n| **Codex** | `~/.codex/oauth_creds.json` | Codex OAuth credentials |\n\n> **Note**: `~` represents the user home directory (Windows: `C:\\Users\\username`, Linux/macOS: `/home/username` or `/Users/username`)\n\n> **Custom Path**: Can specify custom storage location via relevant parameters in configuration file or environment variables\n\n</details>\n\n---\n\n### ğŸ¦™ Ollama Protocol Usage Examples\n\nThis project supports the Ollama protocol, allowing access to all supported models through a unified interface. The Ollama endpoint provides standard interfaces such as `/api/tags`, `/api/chat`, `/api/generate`, etc.\n\n**Ollama API Call Examples**:\n\n1. **List all available models**:\n```bash\ncurl http://localhost:3000/ollama/api/tags \\\n  -H \"Authorization: Bearer your-api-key\"\n```\n\n2. **Chat interface**:\n```bash\ncurl http://localhost:3000/ollama/api/chat \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer your-api-key\" \\\n  -d '{\n    \"model\": \"[Claude] claude-sonnet-4.5\",\n    \"messages\": [\n      {\"role\": \"user\", \"content\": \"Hello\"}\n    ]\n  }'\n```\n\n3. **Specify provider using model prefix**:\n- `[Kiro]` - Access Claude models using Kiro API\n- `[Claude]` - Use official Claude API\n- `[Gemini CLI]` - Access via Gemini CLI OAuth\n- `[OpenAI]` - Use official OpenAI API\n- `[Qwen CLI]` - Access via Qwen OAuth\n\n---\n\n### Advanced Configuration\n\n<details>\n<summary>Click to expand proxy configuration, model filtering, and Fallback advanced settings</summary>\n\n#### 1. Proxy Configuration\n\nThis project supports flexible proxy configuration, allowing you to configure a unified proxy for different providers or use provider-specific proxied endpoints.\n\n**Configuration Methods**:\n\n1. **Web UI Configuration** (Recommended): Convenient configuration management\n\n  In the \"Configuration\" page of the Web UI, you can visually configure all proxy options:\n  - **Unified Proxy**: Fill in the proxy address in the \"Proxy Settings\" area and check the providers that need to use the proxy\n  - **Provider Endpoints**: In each provider's configuration area, directly modify the Base URL to a proxied endpoint\n  - **Click \"Save Configuration\"**: Takes effect immediately without restarting the service\n\n2. **Unified Proxy Configuration**: Configure a global proxy and specify which providers use it\n\n   - **Web UI Configuration**: Fill in the proxy address in the \"Proxy Settings\" area of the \"Configuration\" page and check the providers that need to use the proxy\n   - **Configuration File**: Configure in `configs/config.json`\n   ```json\n   {\n     \"PROXY_URL\": \"http://127.0.0.1:7890\",\n     \"PROXY_ENABLED_PROVIDERS\": [\n       \"gemini-cli-oauth\",\n       \"gemini-antigravity\",\n       \"claude-kiro-oauth\"\n     ]\n   }\n   ```\n\n3. **Provider-Specific Proxied Endpoints**: Some providers (like OpenAI, Claude) support configuring proxied API endpoints\n\n   - **Web UI Configuration**: In each provider's configuration area on the \"Configuration\" page, modify the corresponding Base URL\n   - **Configuration File**: Configure in `configs/config.json`\n   ```json\n   {\n     \"OPENAI_BASE_URL\": \"https://your-proxy-endpoint.com/v1\",\n     \"CLAUDE_BASE_URL\": \"https://your-proxy-endpoint.com\"\n   }\n   ```\n\n**Supported Proxy Types**:\n- **HTTP Proxy**: `http://127.0.0.1:7890`\n- **HTTPS Proxy**: `https://127.0.0.1:7890`\n- **SOCKS5 Proxy**: `socks5://127.0.0.1:1080`\n\n**Use Cases**:\n- **Network-Restricted Environments**: Use in network environments where Google, OpenAI, and other services cannot be accessed directly\n- **Hybrid Configuration**: Some providers use unified proxy, others use their own proxied endpoints\n- **Flexible Switching**: Enable/disable proxy for specific providers at any time in the Web UI\n\n**Notes**:\n- Proxy configuration priority: Unified proxy configuration > Provider-specific endpoints > Direct connection\n- Ensure the proxy service is stable and available, otherwise it may affect service quality\n- SOCKS5 proxy usually performs better than HTTP proxy\n\n#### 2. Model Filtering Configuration\n\nSupport excluding unsupported models through `notSupportedModels` configuration, the system will automatically skip these providers.\n\n**Configuration**: Add `notSupportedModels` field for providers in `configs/provider_pools.json`:\n\n```json\n{\n  \"gemini-cli-oauth\": [\n    {\n      \"uuid\": \"provider-1\",\n      \"notSupportedModels\": [\"gemini-3.0-pro\", \"gemini-3.5-flash\"],\n      \"checkHealth\": true\n    }\n  ]\n}\n```\n\n**How It Works**:\n- When requesting a specific model, the system automatically filters out providers that have configured the model as unsupported\n- Only providers that support the model will be selected to handle the request\n\n**Use Cases**:\n- Some accounts cannot access specific models due to quota or permission restrictions\n- Need to assign different model access permissions to different accounts\n\n#### 3. Cross-Type Fallback Configuration\n\nWhen all accounts under a Provider Type (e.g., `gemini-cli-oauth`) are exhausted due to 429 quota limits or marked as unhealthy, the system can automatically fallback to another compatible Provider Type (e.g., `gemini-antigravity`) instead of returning an error directly.\n\n**Configuration**: Add `providerFallbackChain` configuration in `configs/config.json`:\n\n```json\n{\n  \"providerFallbackChain\": {\n    \"gemini-cli-oauth\": [\"gemini-antigravity\"],\n    \"gemini-antigravity\": [\"gemini-cli-oauth\"],\n    \"claude-kiro-oauth\": [\"claude-custom\"],\n    \"claude-custom\": [\"claude-kiro-oauth\"]\n  }\n}\n```\n\n**How It Works**:\n1. Try to select a healthy account from the primary Provider Type pool\n2. If all accounts in that type are unhealthy or return 429:\n   - Look up the configured fallback types\n   - Check if the fallback type supports the requested model (protocol compatibility check)\n   - Select a healthy account from the fallback type's pool\n3. Supports multi-level degradation chains: `gemini-cli-oauth â†’ gemini-antigravity â†’ openai-custom`\n4. Only returns an error if all fallback types are also unavailable\n\n**Use Cases**:\n- In batch task scenarios, the free RPD quota of a single Provider Type can be easily exhausted in a short time\n- Through cross-type Fallback, you can fully utilize the independent quotas of multiple Providers, improving overall availability and throughput\n\n**Notes**:\n- Fallback only occurs between protocol-compatible types (e.g., between `gemini-*`, between `claude-*`)\n- The system automatically checks if the target Provider Type supports the requested model\n\n</details>\n\n---\n\n## â“ FAQ\n\n<details>\n<summary>Click to expand FAQ and solutions (port occupation, Docker startup, 429 errors, etc.)</summary>\n\n### 1. OAuth Authorization Failed\n\n**Problem Description**: After clicking \"Generate Authorization\", the browser opens the authorization page but authorization fails or cannot be completed.\n\n**Solutions**:\n- **Check Network Connection**: Ensure you can access Google, Alibaba Cloud, and other services normally\n- **Check Port Occupation**: OAuth callbacks require specific ports (Gemini: 8085, Antigravity: 8086, iFlow: 8087, Codex: 1455, Kiro: 19876-19880), ensure these ports are not occupied\n- **Clear Browser Cache**: Try using incognito mode or clearing browser cache and retry\n- **Check Firewall Settings**: Ensure the firewall allows access to local callback ports\n- **Docker Users**: Ensure all OAuth callback ports are correctly mapped\n\n### 2. Port Already in Use\n\n**Problem Description**: When starting the service, it shows the port is already in use (e.g., `EADDRINUSE`).\n\n**Solutions**:\n```bash\n# Windows - Find the process occupying the port\nnetstat -ano | findstr :3000\n# Then use Task Manager to end the corresponding PID process\n\n# Linux/macOS - Find and end the process occupying the port\nlsof -i :3000\nkill -9 <PID>\n```\n\nOr modify the port configuration in `configs/config.json` to use a different port.\n\n### 3. Docker Container Won't Start\n\n**Problem Description**: Docker container fails to start or exits immediately.\n\n**Solutions**:\n- **Check Logs**: `docker logs aiclient2api` to view error messages\n- **Check Mount Path**: Ensure the local path in the `-v` parameter exists and has read/write permissions\n- **Check Port Conflicts**: Ensure all mapped ports are not occupied on the host\n- **Re-pull Image**: `docker pull justlikemaki/aiclient-2-api:latest`\n\n### 4. Credential File Not Recognized\n\n**Problem Description**: After uploading or configuring credential files, the system shows it cannot be recognized or format error.\n\n**Solutions**:\n- **Check File Format**: Ensure the credential file is valid JSON format\n- **Check File Path**: Ensure the file path is correct, Docker users need to ensure the file is in the mounted directory\n- **Check File Permissions**: Ensure the service has permission to read the credential file\n- **Regenerate Credentials**: If credentials have expired, try re-authorizing via OAuth\n\n### 5. Request Returns 429 Error\n\n**Problem Description**: API requests frequently return 429 Too Many Requests error.\n\n**Solutions**:\n- **Configure Account Pool**: Add multiple accounts to `provider_pools.json`, enable polling mechanism\n- **Configure Fallback**: Configure `providerFallbackChain` in `config.json` for cross-type degradation\n- **Reduce Request Frequency**: Appropriately increase request intervals to avoid triggering rate limits\n- **Wait for Quota Reset**: Free quotas usually reset daily or per minute\n\n### 6. Model Unavailable or Returns Error\n\n**Problem Description**: When requesting a specific model, it returns an error or shows the model is unavailable.\n\n**Solutions**:\n- **Check Model Name**: Ensure you're using the correct model name (case-sensitive)\n- **Check Provider Support**: Confirm the currently configured provider supports that model\n- **Check Account Permissions**: Some advanced models may require specific account permissions\n- **Configure Model Filtering**: Use `notSupportedModels` to exclude unsupported models\n\n### 7. Web UI Cannot Be Accessed\n\n**Problem Description**: Browser cannot open `http://localhost:3000`.\n\n**Solutions**:\n- **Check Service Status**: Confirm the service has started successfully, check terminal output\n- **Check Port Mapping**: Docker users ensure `-p 3000:3000` parameter is correct\n- **Try Other Address**: Try accessing `http://127.0.0.1:3000`\n- **Check Firewall**: Ensure the firewall allows access to port 3000\n\n### 8. Streaming Response Interrupted\n\n**Problem Description**: When using streaming output, the response is interrupted midway or incomplete.\n\n**Solutions**:\n- **Check Network Stability**: Ensure network connection is stable\n- **Increase Timeout**: Increase request timeout in client configuration\n- **Check Proxy Settings**: If using a proxy, ensure the proxy supports long connections\n- **Check Service Logs**: Check for error messages\n\n### 9. Configuration Changes Not Taking Effect\n\n**Problem Description**: After modifying configuration in Web UI, service behavior doesn't change.\n\n**Solutions**:\n- **Refresh Page**: Refresh the Web UI page after modification\n- **Check Save Status**: Confirm the configuration was saved successfully (check prompt messages)\n- **Restart Service**: Some configurations may require service restart to take effect\n- **Check Configuration File**: Directly check `configs/config.json` to confirm changes were written\n\n### 10. API Returns 404\n\n**Problem Description**: When calling API endpoints, it returns 404 Not Found error.\n\n**Solutions**:\n- **Check Endpoint Path**: Ensure you're using the correct endpoint path, such as `/v1/chat/completions`, `/ollama/api/chat`, etc.\n- **Check Client Auto-completion**: Some clients (like Cherry-Studio, NextChat) automatically append paths (like `/v1/chat/completions`) after the Base URL, causing path duplication. Check the actual request URL in the console and remove redundant path parts\n- **Check Service Status**: Confirm the service has started normally, visit `http://localhost:3000` to view Web UI\n- **Check Port Configuration**: Ensure requests are sent to the correct port (default 3000)\n- **View Available Routes**: Check \"Interactive Routing Examples\" on the Web UI dashboard page to see all available endpoints\n\n### 11. Unauthorized: API key is invalid or missing\n\n**Problem Description**: When calling API endpoints, it returns `Unauthorized: API key is invalid or missing.` error.\n\n**Solutions**:\n- **Check API Key Configuration**: Ensure API Key is correctly configured in `configs/config.json` or Web UI\n- **Check Request Header Format**: Ensure the request contains the correct Authorization header format, such as `Authorization: Bearer your-api-key`\n- **Check Service Logs**: View detailed error messages on the \"Real-time Logs\" page in Web UI to locate the specific cause\n\n### 12. No available and healthy providers for type\n\n**Problem Description**: When calling API, it returns `No available and healthy providers for type xxx` error.\n\n**Solutions**:\n- **Check Provider Status**: Check if providers of the corresponding type are in healthy status on the \"Provider Pools\" page in Web UI\n- **Check Credential Validity**: Confirm OAuth credentials have not expired; if expired, regenerate authorization\n- **Check Quota Limits**: Some providers may have reached free quota limits; wait for quota reset or add more accounts\n- **Enable Fallback**: Configure `providerFallbackChain` in `config.json` to automatically switch to backup providers when the primary provider is unavailable\n- **View Detailed Logs**: Check specific health check failure reasons on the \"Real-time Logs\" page in Web UI\n\n### 13. Request Returns 403 Forbidden Error\n\n**Problem Description**: API requests return 403 Forbidden error.\n\n**Solutions**:\n- **Check Node Status**: If you see the node status is normal (health check passed) on the \"Provider Pools\" page in Web UI, you can ignore this error as the system will handle it automatically\n- **Check Account Permissions**: Confirm the account has permission to access the requested model or service\n- **Check API Key Permissions**: Some providers' API Keys may have access scope restrictions; ensure the Key has sufficient permissions\n- **Check Regional Restrictions**: Some services may have regional access restrictions; try using a proxy or VPN\n- **Check Credential Status**: OAuth credentials may have been revoked or expired; try regenerating authorization\n- **Check Request Frequency**: Some providers have strict request frequency limits; reduce request frequency and retry\n- **View Provider Documentation**: Visit the official documentation of the corresponding provider to understand specific access restrictions and requirements\n\n</details>\n\n---\n\n## ğŸ“„ Open Source License\n\nThis project follows the [**GNU General Public License v3 (GPLv3)**](https://www.gnu.org/licenses/gpl-3.0) license. For details, please check the `LICENSE` file in the root directory.\n\n## ğŸ™ Acknowledgements\n\nThe development of this project was greatly inspired by the official Google Gemini CLI and referenced part of the code implementation of `gemini-cli.ts` in Cline 3.18.0. Sincere thanks to the Google official team and the Cline development team for their excellent work!\n\n### Contributor List\n\nThanks to all the developers who contributed to the AIClient-2-API project:\n\n[![Contributors](https://contrib.rocks/image?repo=justlovemaki/AIClient-2-API)](https://github.com/justlovemaki/AIClient-2-API/graphs/contributors)\n\n### Sponsor List\n\nWe are grateful for the support from our sponsors:\n\n- [**Cigarliu**](https://github.com/Cigarliu \"9.9\")\n- [**xianengqi**](https://github.com/xianengqi \"9.9\")\n- [**3831143avl**](https://github.com/3831143avl \"10\")\n- [**é†‰æ˜¥é£**](https://github.com/handsometong \"28.8\")\n- [**crazy**](https://github.com/404 \"88\")\n- [**æ¸…å®µè½äº†ç¯èŠ±**](https://github.com/Lanternmorning \"16\")\n- [**éƒ­é“**](https://github.com/guotie \"20\")\n- [**è½å¶èšå**](https://github.com/mb5u88-debug \"88\")\n- [**åŒ¿å**](https://github.com/404 \"8.88\")\n\n### Scan to Sponsor\n\nYour sponsorship is the driving force for the project's continued development â¤ï¸\n\n<img src=\"static/coffee.png\" alt=\"Scan to Sponsor\" width=\"200\">\n<img src=\"static/sponsor.png\" alt=\"Scan to Sponsor\" width=\"200\">\n\n### ğŸŒŸ Star History\n\n\n[![Star History Chart](https://api.star-history.com/svg?repos=justlovemaki/AIClient-2-API&type=Timeline)](https://www.star-history.com/#justlovemaki/AIClient-2-API&Timeline)\n\n---\n\n## âš ï¸ Disclaimer\n\n### Usage Risk Warning\nThis project (AIClient-2-API) is for learning and research purposes only. Users assume all risks when using this project. The author is not responsible for any direct, indirect, or consequential losses resulting from the use of this project.\n\n### Third-Party Service Responsibility Statement\nThis project is an API proxy tool and does not provide any AI model services. All AI model services are provided by their respective third-party providers (such as Google, OpenAI, Anthropic, etc.). Users should comply with the terms of service and policies of each third-party service when accessing them through this project. The author is not responsible for the availability, quality, security, or legality of third-party services.\n\n### Data Privacy Statement\nThis project runs locally and does not collect or upload any user data. However, users should protect their API keys and other sensitive information when using this project. It is recommended that users regularly check and update their API keys and avoid using this project in insecure network environments.\n\n### Legal Compliance Reminder\nUsers should comply with the laws and regulations of their country/region when using this project. It is strictly prohibited to use this project for any illegal purposes. Any consequences resulting from users' violation of laws and regulations shall be borne by the users themselves.\n",
      "stars_today": 186
    },
    {
      "id": 180687624,
      "name": "trivy",
      "full_name": "aquasecurity/trivy",
      "description": "Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more",
      "html_url": "https://github.com/aquasecurity/trivy",
      "stars": 31547,
      "forks": 2921,
      "language": "Go",
      "topics": [
        "containers",
        "devsecops",
        "docker",
        "go",
        "golang",
        "hacktoberfest",
        "iac",
        "infrastructure-as-code",
        "kubernetes",
        "misconfiguration",
        "security",
        "security-tools",
        "vulnerability",
        "vulnerability-detection",
        "vulnerability-scanners"
      ],
      "created_at": "2019-04-11T01:01:07Z",
      "updated_at": "2026-02-07T02:21:42Z",
      "pushed_at": "2026-02-06T12:59:51Z",
      "open_issues": 214,
      "owner": {
        "login": "aquasecurity",
        "avatar_url": "https://avatars.githubusercontent.com/u/12783832?v=4"
      },
      "readme": "<div align=\"center\">\n<img src=\"docs/imgs/logo.png\" width=\"200\">\n\n[![GitHub Release][release-img]][release]\n[![Test][test-img]][test]\n[![Go Report Card][go-report-img]][go-report]\n[![License: Apache-2.0][license-img]][license]\n[![GitHub Downloads][github-downloads-img]][release]\n![Docker Pulls][docker-pulls]\n\n[ğŸ“– Documentation][docs]\n</div>\n\nTrivy ([pronunciation][pronunciation]) is a comprehensive and versatile security scanner.\nTrivy has *scanners* that look for security issues, and *targets* where it can find those issues.\n\nTargets (what Trivy can scan):\n\n- Container Image\n- Filesystem\n- Git Repository (remote)\n- Virtual Machine Image\n- Kubernetes\n\nScanners (what Trivy can find there):\n\n- OS packages and software dependencies in use (SBOM)\n- Known vulnerabilities (CVEs)\n- IaC issues and misconfigurations\n- Sensitive information and secrets\n- Software licenses\n\nTrivy supports most popular programming languages, operating systems, and platforms. For a complete list, see the [Scanning Coverage] page.\n\nTo learn more, go to the [Trivy homepage][homepage] for feature highlights, or to the [Documentation site][docs] for detailed information.\n\n## Quick Start\n\n### Get Trivy\n\nTrivy is available in most common distribution channels. The full list of installation options is available in the [Installation] page. Here are a few popular examples:\n\n- `brew install trivy`\n- `docker run aquasec/trivy`\n- Download binary from <https://github.com/aquasecurity/trivy/releases/latest/>\n- See [Installation] for more\n\nTrivy is integrated with many popular platforms and applications. The complete list of integrations is available in the [Ecosystem] page. Here are a few popular examples:\n\n- [GitHub Actions](https://github.com/aquasecurity/trivy-action)\n- [Kubernetes operator](https://github.com/aquasecurity/trivy-operator)\n- [VS Code plugin](https://github.com/aquasecurity/trivy-vscode-extension)\n- See [Ecosystem] for more\n\n### Canary builds\nThere are canary builds ([Docker Hub](https://hub.docker.com/r/aquasec/trivy/tags?page=1&name=canary), [GitHub](https://github.com/aquasecurity/trivy/pkgs/container/trivy/75776514?tag=canary), [ECR](https://gallery.ecr.aws/aquasecurity/trivy#canary) images and [binaries](https://github.com/aquasecurity/trivy/actions/workflows/canary.yaml)) generated with every push to the main branch.\n\nPlease be aware: canary builds might have critical bugs, so they are not recommended for use in production.\n\n### General usage\n\n```bash\ntrivy <target> [--scanners <scanner1,scanner2>] <subject>\n```\n\nExamples:\n\n```bash\ntrivy image python:3.4-alpine\n```\n\n<details>\n<summary>Result</summary>\n\nhttps://user-images.githubusercontent.com/1161307/171013513-95f18734-233d-45d3-aaf5-d6aec687db0e.mov\n\n</details>\n\n```bash\ntrivy fs --scanners vuln,secret,misconfig myproject/\n```\n\n<details>\n<summary>Result</summary>\n\nhttps://user-images.githubusercontent.com/1161307/171013917-b1f37810-f434-465c-b01a-22de036bd9b3.mov\n\n</details>\n\n```bash\ntrivy k8s --report summary cluster\n```\n\n<details>\n<summary>Result</summary>\n\n![k8s summary](docs/imgs/trivy-k8s.png)\n\n</details>\n\n## FAQ\n\n### How to pronounce the name \"Trivy\"?\n\n`tri` is pronounced like **tri**gger, `vy` is pronounced like en**vy**.\n\n## Want more? Check out Aqua\n\nIf you liked Trivy, you will love Aqua which builds on top of Trivy to provide even more enhanced capabilities for a complete security management offering.  \nYou can find a high level comparison table specific to Trivy users [here](https://trivy.dev/docs/latest/commercial/compare/).\nIn addition check out the <https://aquasec.com> website for more information about our products and services.\nIf you'd like to contact Aqua or request a demo, please use this form: <https://www.aquasec.com/demo>\n\n## Community\n\nTrivy is an [Aqua Security][aquasec] open source project.  \nLearn about our open source work and portfolio [here][oss].  \nContact us about any matter by opening a GitHub Discussion [here][discussions]\n\nPlease ensure to abide by our [Code of Conduct][code-of-conduct] during all interactions.\n\n[test]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml\n[test-img]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml/badge.svg\n[go-report]: https://goreportcard.com/report/github.com/aquasecurity/trivy\n[go-report-img]: https://goreportcard.com/badge/github.com/aquasecurity/trivy\n[release]: https://github.com/aquasecurity/trivy/releases\n[release-img]: https://img.shields.io/github/release/aquasecurity/trivy.svg?logo=github\n[github-downloads-img]: https://img.shields.io/github/downloads/aquasecurity/trivy/total?logo=github\n[docker-pulls]: https://img.shields.io/docker/pulls/aquasec/trivy?logo=docker&label=docker%20pulls%20%2F%20trivy\n[license]: https://github.com/aquasecurity/trivy/blob/main/LICENSE\n[license-img]: https://img.shields.io/badge/License-Apache%202.0-blue.svg\n[homepage]: https://trivy.dev\n[docs]: https://trivy.dev/docs/latest/\n[pronunciation]: #how-to-pronounce-the-name-trivy\n[code-of-conduct]: https://github.com/aquasecurity/community/blob/main/CODE_OF_CONDUCT.md\n\n[Installation]:https://trivy.dev/docs/latest/getting-started/installation/\n[Ecosystem]: https://trivy.dev/docs/latest/ecosystem/\n[Scanning Coverage]: https://trivy.dev/docs/latest/coverage/\n\n[alpine]: https://ariadne.space/2021/06/08/the-vulnerability-remediation-lifecycle-of-alpine-containers/\n[rego]: https://www.openpolicyagent.org/docs/latest/#rego\n[sigstore]: https://www.sigstore.dev/\n\n[aquasec]: https://aquasec.com\n[oss]: https://www.aquasec.com/products/open-source-projects/\n[discussions]: https://github.com/aquasecurity/trivy/discussions\n",
      "stars_today": 165
    },
    {
      "id": 1023959202,
      "name": "runanywhere-sdks",
      "full_name": "RunanywhereAI/runanywhere-sdks",
      "description": "Production ready toolkit to run AI locally",
      "html_url": "https://github.com/RunanywhereAI/runanywhere-sdks",
      "stars": 6295,
      "forks": 198,
      "language": "Kotlin",
      "topics": [
        "agent-framework",
        "android",
        "apple-intelligence",
        "edge",
        "edge-ai",
        "foundational-models",
        "inference",
        "ios",
        "kotlin",
        "llamacpp",
        "llm",
        "multimodal",
        "ollama",
        "on-device-ai",
        "privacy",
        "swift",
        "voice-ai",
        "voice-assistant"
      ],
      "created_at": "2025-07-22T01:23:34Z",
      "updated_at": "2026-02-07T01:58:08Z",
      "pushed_at": "2026-02-06T08:56:22Z",
      "open_issues": 40,
      "owner": {
        "login": "RunanywhereAI",
        "avatar_url": "https://avatars.githubusercontent.com/u/220821781?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"examples/logo.svg\" alt=\"RunAnywhere Logo\" width=\"140\"/>\n</p>\n\n<h1 align=\"center\">RunAnywhere</h1>\n\n<p align=\"center\">\n  <strong>On-device AI for mobile apps.</strong><br/>\n  Run LLMs, speech-to-text, and text-to-speech locallyâ€”private, offline, fast.\n</p>\n\n<p align=\"center\">\n  <a href=\"https://apps.apple.com/us/app/runanywhere/id6756506307\">\n    <img src=\"https://img.shields.io/badge/App_Store-Download-0D96F6?style=for-the-badge&logo=apple&logoColor=white\" alt=\"Download on App Store\" />\n  </a>\n  &nbsp;\n  <a href=\"https://play.google.com/store/apps/details?id=com.runanywhere.runanywhereai\">\n    <img src=\"https://img.shields.io/badge/Google_Play-Download-34A853?style=for-the-badge&logo=google-play&logoColor=white\" alt=\"Get it on Google Play\" />\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/RunanywhereAI/runanywhere-sdks/stargazers\"><img src=\"https://img.shields.io/github/stars/RunanywhereAI/runanywhere-sdks?style=flat-square\" alt=\"GitHub Stars\" /></a>\n  <a href=\"LICENSE\"><img src=\"https://img.shields.io/badge/License-Apache%202.0-blue?style=flat-square\" alt=\"License\" /></a>\n  <a href=\"https://discord.gg/N359FBbDVd\"><img src=\"https://img.shields.io/badge/Discord-Join-5865F2?style=flat-square&logo=discord&logoColor=white\" alt=\"Discord\" /></a>\n</p>\n\n<p align=\"center\">\n  <img src=\"docs/screenshots/main-screenshot.jpg\" alt=\"Chat\" width=\"180\"/>\n  &nbsp;&nbsp;\n  <img src=\"examples/ios/RunAnywhereAI/docs/screenshots/chat-interface.png\" alt=\"Analytics\" width=\"180\"/>\n  &nbsp;&nbsp;\n  <img src=\"examples/ios/RunAnywhereAI/docs/screenshots/quiz-flow.png\" alt=\"Structured Output\" width=\"180\"/>\n  &nbsp;&nbsp;\n  <img src=\"examples/ios/RunAnywhereAI/docs/screenshots/voice-ai.png\" alt=\"Voice AI\" width=\"180\"/>\n</p>\n\n---\n\n## See It In Action\n\n<p align=\"center\">\n  <img src=\"demo.gif\" alt=\"On-device tool calling demo\" width=\"260\"/>\n</p>\n\n<p align=\"center\">\n  <strong>Llama 3.2 3B on iPhone 16 Pro Max</strong><br/>\n  Tool calling + LLM reasoning â€” 100% on-device\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/RunanywhereAI/runanywhere-sdks/pull/296\">View the code</a>\n  &nbsp;Â·&nbsp;\n  <em>Full tool calling support coming soon</em>\n</p>\n\n---\n\n## What is RunAnywhere?\n\nRunAnywhere lets you add AI features to your mobile app that run entirely on-device:\n\n- **LLM Chat** â€” Llama, Mistral, Qwen, SmolLM, and more\n- **Speech-to-Text** â€” Whisper-powered transcription\n- **Text-to-Speech** â€” Neural voice synthesis\n- **Voice Assistant** â€” Full STT â†’ LLM â†’ TTS pipeline\n\nNo cloud. No latency. No data leaves the device.\n\n---\n\n## SDKs\n\n| Platform | Status | Installation | Documentation |\n|----------|--------|--------------|---------------|\n| **Swift** (iOS/macOS) | Stable | [Swift Package Manager](#swift-ios--macos) | [docs.runanywhere.ai/swift](https://docs.runanywhere.ai/swift/introduction) |\n| **Kotlin** (Android) | Stable | [Gradle](#kotlin-android) | [docs.runanywhere.ai/kotlin](https://docs.runanywhere.ai/kotlin/introduction) |\n| **React Native** | Beta | [npm](#react-native) | [docs.runanywhere.ai/react-native](https://docs.runanywhere.ai/react-native/introduction) |\n| **Flutter** | Beta | [pub.dev](#flutter) | [docs.runanywhere.ai/flutter](https://docs.runanywhere.ai/flutter/introduction) |\n\n---\n\n## Quick Start\n\n### Swift (iOS / macOS)\n\n```swift\nimport RunAnywhere\nimport LlamaCPPRuntime\n\n// 1. Initialize\nLlamaCPP.register()\ntry RunAnywhere.initialize()\n\n// 2. Load a model\ntry await RunAnywhere.downloadModel(\"smollm2-360m\")\ntry await RunAnywhere.loadModel(\"smollm2-360m\")\n\n// 3. Generate\nlet response = try await RunAnywhere.chat(\"What is the capital of France?\")\nprint(response) // \"Paris is the capital of France.\"\n```\n\n**Install via Swift Package Manager:**\n\n```\nhttps://github.com/RunanywhereAI/runanywhere-sdks\n```\n\n[Full documentation â†’](https://docs.runanywhere.ai/swift/introduction) Â· [Source code](sdk/runanywhere-swift/)\n\n---\n\n### Kotlin (Android)\n\n```kotlin\nimport com.runanywhere.sdk.public.RunAnywhere\nimport com.runanywhere.sdk.public.extensions.*\n\n// 1. Initialize\nLlamaCPP.register()\nRunAnywhere.initialize(environment = SDKEnvironment.DEVELOPMENT)\n\n// 2. Load a model\nRunAnywhere.downloadModel(\"smollm2-360m\").collect { println(\"${it.progress * 100}%\") }\nRunAnywhere.loadLLMModel(\"smollm2-360m\")\n\n// 3. Generate\nval response = RunAnywhere.chat(\"What is the capital of France?\")\nprintln(response) // \"Paris is the capital of France.\"\n```\n\n**Install via Gradle:**\n\n```kotlin\ndependencies {\n    implementation(\"com.runanywhere.sdk:runanywhere-kotlin:0.1.4\")\n    implementation(\"com.runanywhere.sdk:runanywhere-core-llamacpp:0.1.4\")\n}\n```\n\n[Full documentation â†’](https://docs.runanywhere.ai/kotlin/introduction) Â· [Source code](sdk/runanywhere-kotlin/)\n\n---\n\n### React Native\n\n```typescript\nimport { RunAnywhere, SDKEnvironment } from '@runanywhere/core';\nimport { LlamaCPP } from '@runanywhere/llamacpp';\n\n// 1. Initialize\nawait RunAnywhere.initialize({ environment: SDKEnvironment.Development });\nLlamaCPP.register();\n\n// 2. Load a model\nawait RunAnywhere.downloadModel('smollm2-360m');\nawait RunAnywhere.loadModel(modelPath);\n\n// 3. Generate\nconst response = await RunAnywhere.chat('What is the capital of France?');\nconsole.log(response); // \"Paris is the capital of France.\"\n```\n\n**Install via npm:**\n\n```bash\nnpm install @runanywhere/core @runanywhere/llamacpp\n```\n\n[Full documentation â†’](https://docs.runanywhere.ai/react-native/introduction) Â· [Source code](sdk/runanywhere-react-native/)\n\n---\n\n### Flutter\n\n```dart\nimport 'package:runanywhere/runanywhere.dart';\nimport 'package:runanywhere_llamacpp/runanywhere_llamacpp.dart';\n\n// 1. Initialize\nawait RunAnywhere.initialize();\nawait LlamaCpp.register();\n\n// 2. Load a model\nawait RunAnywhere.downloadModel('smollm2-360m');\nawait RunAnywhere.loadModel('smollm2-360m');\n\n// 3. Generate\nfinal response = await RunAnywhere.chat('What is the capital of France?');\nprint(response); // \"Paris is the capital of France.\"\n```\n\n**Install via pub.dev:**\n\n```yaml\ndependencies:\n  runanywhere: ^0.15.11\n  runanywhere_llamacpp: ^0.15.11\n```\n\n[Full documentation â†’](https://docs.runanywhere.ai/flutter/introduction) Â· [Source code](sdk/runanywhere-flutter/)\n\n---\n\n## Sample Apps\n\nFull-featured demo applications demonstrating SDK capabilities:\n\n| Platform | Source Code | Download |\n|----------|-------------|----------|\n| iOS | [examples/ios/RunAnywhereAI](examples/ios/RunAnywhereAI/) | [App Store](https://apps.apple.com/us/app/runanywhere/id6756506307) |\n| Android | [examples/android/RunAnywhereAI](examples/android/RunAnywhereAI/) | [Google Play](https://play.google.com/store/apps/details?id=com.runanywhere.runanywhereai) |\n| React Native | [examples/react-native/RunAnywhereAI](examples/react-native/RunAnywhereAI/) | Build from source |\n| Flutter | [examples/flutter/RunAnywhereAI](examples/flutter/RunAnywhereAI/) | Build from source |\n\n---\n\n## Playground\n\nStandalone demo projects showcasing what you can build with RunAnywhere:\n\n| Project | Description | Platform |\n|---------|-------------|----------|\n| [swift-starter-app](Playground/swift-starter-app/) | Privacy-first AI demo â€” LLM Chat, STT, TTS, and Voice Pipeline | iOS (Swift/SwiftUI) |\n| [on-device-browser-agent](Playground/on-device-browser-agent/) | On-device AI browser automation â€” no cloud, no API keys | Chrome Extension |\n\n---\n\n## Features\n\n| Feature | iOS | Android | React Native | Flutter |\n|---------|-----|---------|--------------|---------|\n| LLM Text Generation | âœ… | âœ… | âœ… | âœ… |\n| Streaming | âœ… | âœ… | âœ… | âœ… |\n| Speech-to-Text | âœ… | âœ… | âœ… | âœ… |\n| Text-to-Speech | âœ… | âœ… | âœ… | âœ… |\n| Voice Assistant Pipeline | âœ… | âœ… | âœ… | âœ… |\n| Model Download + Progress | âœ… | âœ… | âœ… | âœ… |\n| Structured Output (JSON) | âœ… | âœ… | ğŸ”œ | ğŸ”œ |\n| Apple Foundation Models | âœ… | â€” | â€” | â€” |\n\n---\n\n## Supported Models\n\n### LLM (GGUF format via llama.cpp)\n\n| Model | Size | RAM Required | Use Case |\n|-------|------|--------------|----------|\n| SmolLM2 360M | ~400MB | 500MB | Fast, lightweight |\n| Qwen 2.5 0.5B | ~500MB | 600MB | Multilingual |\n| Llama 3.2 1B | ~1GB | 1.2GB | Balanced |\n| Mistral 7B Q4 | ~4GB | 5GB | High quality |\n\n### Speech-to-Text (Whisper via ONNX)\n\n| Model | Size | Languages |\n|-------|------|-----------|\n| Whisper Tiny | ~75MB | English |\n| Whisper Base | ~150MB | Multilingual |\n\n### Text-to-Speech (Piper via ONNX)\n\n| Voice | Size | Language |\n|-------|------|----------|\n| Piper US English | ~65MB | English (US) |\n| Piper British English | ~65MB | English (UK) |\n\n---\n\n## Repository Structure\n\n```\nrunanywhere-sdks/\nâ”œâ”€â”€ sdk/\nâ”‚   â”œâ”€â”€ runanywhere-swift/          # iOS/macOS SDK\nâ”‚   â”œâ”€â”€ runanywhere-kotlin/         # Android SDK\nâ”‚   â”œâ”€â”€ runanywhere-react-native/   # React Native SDK\nâ”‚   â”œâ”€â”€ runanywhere-flutter/        # Flutter SDK\nâ”‚   â””â”€â”€ runanywhere-commons/        # Shared C++ core\nâ”‚\nâ”œâ”€â”€ examples/\nâ”‚   â”œâ”€â”€ ios/RunAnywhereAI/          # iOS sample app\nâ”‚   â”œâ”€â”€ android/RunAnywhereAI/      # Android sample app\nâ”‚   â”œâ”€â”€ react-native/RunAnywhereAI/ # React Native sample app\nâ”‚   â””â”€â”€ flutter/RunAnywhereAI/      # Flutter sample app\nâ”‚\nâ”œâ”€â”€ Playground/\nâ”‚   â”œâ”€â”€ swift-starter-app/          # iOS AI playground app\nâ”‚   â””â”€â”€ on-device-browser-agent/    # Chrome browser automation agent\nâ”‚\nâ””â”€â”€ docs/                           # Documentation\n```\n\n---\n\n## Requirements\n\n| Platform | Minimum | Recommended |\n|----------|---------|-------------|\n| iOS | 17.0+ | 17.0+ |\n| macOS | 14.0+ | 14.0+ |\n| Android | API 24 (7.0) | API 28+ |\n| React Native | 0.74+ | 0.76+ |\n| Flutter | 3.10+ | 3.24+ |\n\n**Memory:** 2GB minimum, 4GB+ recommended for larger models\n\n---\n\n## Contributing\n\nWe welcome contributions. See our [Contributing Guide](CONTRIBUTING.md) for details.\n\n```bash\n# Clone the repo\ngit clone https://github.com/RunanywhereAI/runanywhere-sdks.git\n\n# Set up a specific SDK (example: Swift)\ncd runanywhere-sdks/sdk/runanywhere-swift\n./scripts/build-swift.sh --setup\n\n# Run the sample app\ncd ../../examples/ios/RunAnywhereAI\nopen RunAnywhereAI.xcodeproj\n```\n\n---\n\n## Support\n\n- **Discord:** [Join our community](https://discord.gg/N359FBbDVd)\n- **GitHub Issues:** [Report bugs or request features](https://github.com/RunanywhereAI/runanywhere-sdks/issues)\n- **Email:** founders@runanywhere.ai\n- **Twitter:** [@RunanywhereAI](https://twitter.com/RunanywhereAI)\n\n---\n\n## License\n\nApache 2.0 â€” see [LICENSE](LICENSE) for details.\n",
      "stars_today": 165
    },
    {
      "id": 658928958,
      "name": "ollama",
      "full_name": "ollama/ollama",
      "description": "Get up and running with Kimi-K2.5, GLM-4.7, DeepSeek, gpt-oss, Qwen, Gemma and other models.",
      "html_url": "https://github.com/ollama/ollama",
      "stars": 161987,
      "forks": 14475,
      "language": "Go",
      "topics": [
        "deepseek",
        "gemma",
        "gemma3",
        "glm",
        "go",
        "golang",
        "gpt-oss",
        "llama",
        "llama3",
        "llm",
        "llms",
        "minimax",
        "mistral",
        "ollama",
        "qwen"
      ],
      "created_at": "2023-06-26T19:39:32Z",
      "updated_at": "2026-02-07T02:33:47Z",
      "pushed_at": "2026-02-07T01:11:04Z",
      "open_issues": 2442,
      "owner": {
        "login": "ollama",
        "avatar_url": "https://avatars.githubusercontent.com/u/151674099?v=4"
      },
      "readme": "<div align=\"center\">\nÂ  <a href=\"https://ollama.com\">\n    <img alt=\"ollama\" width=\"240\" src=\"https://github.com/ollama/ollama/assets/3325447/0d0b44e2-8f4a-4e99-9b52-a5c1c741c8f7\">\n  </a>\n</div>\n\n# Ollama\n\nGet up and running with large language models.\n\n### macOS\n\n[Download](https://ollama.com/download/Ollama.dmg)\n\n### Windows\n\n[Download](https://ollama.com/download/OllamaSetup.exe)\n\n### Linux\n\n```shell\ncurl -fsSL https://ollama.com/install.sh | sh\n```\n\n[Manual install instructions](https://docs.ollama.com/linux#manual-install)\n\n### Docker\n\nThe official [Ollama Docker image](https://hub.docker.com/r/ollama/ollama) `ollama/ollama` is available on Docker Hub.\n\n### Libraries\n\n- [ollama-python](https://github.com/ollama/ollama-python)\n- [ollama-js](https://github.com/ollama/ollama-js)\n\n### Community\n\n- [Discord](https://discord.gg/ollama)\n- [Reddit](https://reddit.com/r/ollama)\n\n## Quickstart\n\nTo run and chat with [Gemma 3](https://ollama.com/library/gemma3):\n\n```shell\nollama run gemma3\n```\n\n## Model library\n\nOllama supports a list of models available on [ollama.com/library](https://ollama.com/library \"ollama model library\")\n\nHere are some example models that can be downloaded:\n\n| Model              | Parameters | Size  | Download                         |\n| ------------------ | ---------- | ----- | -------------------------------- |\n| Gemma 3            | 1B         | 815MB | `ollama run gemma3:1b`           |\n| Gemma 3            | 4B         | 3.3GB | `ollama run gemma3`              |\n| Gemma 3            | 12B        | 8.1GB | `ollama run gemma3:12b`          |\n| Gemma 3            | 27B        | 17GB  | `ollama run gemma3:27b`          |\n| QwQ                | 32B        | 20GB  | `ollama run qwq`                 |\n| DeepSeek-R1        | 7B         | 4.7GB | `ollama run deepseek-r1`         |\n| DeepSeek-R1        | 671B       | 404GB | `ollama run deepseek-r1:671b`    |\n| Llama 4            | 109B       | 67GB  | `ollama run llama4:scout`        |\n| Llama 4            | 400B       | 245GB | `ollama run llama4:maverick`     |\n| Llama 3.3          | 70B        | 43GB  | `ollama run llama3.3`            |\n| Llama 3.2          | 3B         | 2.0GB | `ollama run llama3.2`            |\n| Llama 3.2          | 1B         | 1.3GB | `ollama run llama3.2:1b`         |\n| Llama 3.2 Vision   | 11B        | 7.9GB | `ollama run llama3.2-vision`     |\n| Llama 3.2 Vision   | 90B        | 55GB  | `ollama run llama3.2-vision:90b` |\n| Llama 3.1          | 8B         | 4.7GB | `ollama run llama3.1`            |\n| Llama 3.1          | 405B       | 231GB | `ollama run llama3.1:405b`       |\n| Phi 4              | 14B        | 9.1GB | `ollama run phi4`                |\n| Phi 4 Mini         | 3.8B       | 2.5GB | `ollama run phi4-mini`           |\n| Mistral            | 7B         | 4.1GB | `ollama run mistral`             |\n| Moondream 2        | 1.4B       | 829MB | `ollama run moondream`           |\n| Neural Chat        | 7B         | 4.1GB | `ollama run neural-chat`         |\n| Starling           | 7B         | 4.1GB | `ollama run starling-lm`         |\n| Code Llama         | 7B         | 3.8GB | `ollama run codellama`           |\n| Llama 2 Uncensored | 7B         | 3.8GB | `ollama run llama2-uncensored`   |\n| LLaVA              | 7B         | 4.5GB | `ollama run llava`               |\n| Granite-3.3        | 8B         | 4.9GB | `ollama run granite3.3`          |\n\n> [!NOTE]\n> You should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.\n\n## Customize a model\n\n### Import from GGUF\n\nOllama supports importing GGUF models in the Modelfile:\n\n1. Create a file named `Modelfile`, with a `FROM` instruction with the local filepath to the model you want to import.\n\n   ```\n   FROM ./vicuna-33b.Q4_0.gguf\n   ```\n\n2. Create the model in Ollama\n\n   ```shell\n   ollama create example -f Modelfile\n   ```\n\n3. Run the model\n\n   ```shell\n   ollama run example\n   ```\n\n### Import from Safetensors\n\nSee the [guide](https://docs.ollama.com/import) on importing models for more information.\n\n### Customize a prompt\n\nModels from the Ollama library can be customized with a prompt. For example, to customize the `llama3.2` model:\n\n```shell\nollama pull llama3.2\n```\n\nCreate a `Modelfile`:\n\n```\nFROM llama3.2\n\n# set the temperature to 1 [higher is more creative, lower is more coherent]\nPARAMETER temperature 1\n\n# set the system message\nSYSTEM \"\"\"\nYou are Mario from Super Mario Bros. Answer as Mario, the assistant, only.\n\"\"\"\n```\n\nNext, create and run the model:\n\n```\nollama create mario -f ./Modelfile\nollama run mario\n>>> hi\nHello! It's your friend Mario.\n```\n\nFor more information on working with a Modelfile, see the [Modelfile](https://docs.ollama.com/modelfile) documentation.\n\n## CLI Reference\n\n### Create a model\n\n`ollama create` is used to create a model from a Modelfile.\n\n```shell\nollama create mymodel -f ./Modelfile\n```\n\n### Pull a model\n\n```shell\nollama pull llama3.2\n```\n\n> This command can also be used to update a local model. Only the diff will be pulled.\n\n### Remove a model\n\n```shell\nollama rm llama3.2\n```\n\n### Copy a model\n\n```shell\nollama cp llama3.2 my-model\n```\n\n### Multiline input\n\nFor multiline input, you can wrap text with `\"\"\"`:\n\n```\n>>> \"\"\"Hello,\n... world!\n... \"\"\"\nI'm a basic program that prints the famous \"Hello, world!\" message to the console.\n```\n\n### Multimodal models\n\n```\nollama run llava \"What's in this image? /Users/jmorgan/Desktop/smile.png\"\n```\n\n> **Output**: The image features a yellow smiley face, which is likely the central focus of the picture.\n\n### Pass the prompt as an argument\n\n```shell\nollama run llama3.2 \"Summarize this file: $(cat README.md)\"\n```\n\n> **Output**: Ollama is a lightweight, extensible framework for building and running language models on the local machine. It provides a simple API for creating, running, and managing models, as well as a library of pre-built models that can be easily used in a variety of applications.\n\n### Show model information\n\n```shell\nollama show llama3.2\n```\n\n### List models on your computer\n\n```shell\nollama list\n```\n\n### List which models are currently loaded\n\n```shell\nollama ps\n```\n\n### Stop a model which is currently running\n\n```shell\nollama stop llama3.2\n```\n\n### Generate embeddings from the CLI\n\n```shell\nollama run embeddinggemma \"Your text to embed\"\n```\n\nYou can also pipe text for scripted workflows:\n\n```shell\necho \"Your text to embed\" | ollama run embeddinggemma\n```\n\n### Start Ollama\n\n`ollama serve` is used when you want to start ollama without running the desktop application.\n\n## Building\n\nSee the [developer guide](https://github.com/ollama/ollama/blob/main/docs/development.md)\n\n### Running local builds\n\nNext, start the server:\n\n```shell\n./ollama serve\n```\n\nFinally, in a separate shell, run a model:\n\n```shell\n./ollama run llama3.2\n```\n\n## Building with MLX (experimental)\n\nFirst build the MLX libraries:\n\n```shell\ncmake --preset MLX\ncmake --build --preset MLX --parallel\ncmake --install build --component MLX\n```\n\nWhen building with the `-tags mlx` flag, the main `ollama` binary includes MLX support for experimental features like image generation:\n\n```shell\ngo build -tags mlx .\n```\n\nFinally, start the server:\n\n```\n./ollama serve\n```\n\n### Building MLX with CUDA\n\nWhen building with CUDA, use the preset \"MLX CUDA 13\" or \"MLX CUDA 12\" to enable CUDA with default architectures:\n\n```shell\ncmake --preset 'MLX CUDA 13'\ncmake --build --preset 'MLX CUDA 13' --parallel\ncmake --install build --component MLX\n```\n\n## REST API\n\nOllama has a REST API for running and managing models.\n\n### Generate a response\n\n```shell\ncurl http://localhost:11434/api/generate -d '{\n  \"model\": \"llama3.2\",\n  \"prompt\":\"Why is the sky blue?\"\n}'\n```\n\n### Chat with a model\n\n```shell\ncurl http://localhost:11434/api/chat -d '{\n  \"model\": \"llama3.2\",\n  \"messages\": [\n    { \"role\": \"user\", \"content\": \"why is the sky blue?\" }\n  ]\n}'\n```\n\nSee the [API documentation](./docs/api.md) for all endpoints.\n\n## Community Integrations\n\n### Web & Desktop\n\n- [Onyx](https://github.com/onyx-dot-app/onyx)\n- [Open WebUI](https://github.com/open-webui/open-webui)\n- [SwiftChat (macOS with ReactNative)](https://github.com/aws-samples/swift-chat)\n- [Enchanted (macOS native)](https://github.com/AugustDev/enchanted)\n- [Hollama](https://github.com/fmaclen/hollama)\n- [Lollms WebUI (Single user)](https://github.com/ParisNeo/lollms-webui)\n- [Lollms (Multi users)](https://github.com/ParisNeo/lollms)\n- [LibreChat](https://github.com/danny-avila/LibreChat)\n- [Bionic GPT](https://github.com/bionic-gpt/bionic-gpt)\n- [HTML UI](https://github.com/rtcfirefly/ollama-ui)\n- [AI-UI](https://github.com/bajahaw/ai-ui)\n- [Saddle](https://github.com/jikkuatwork/saddle)\n- [TagSpaces](https://www.tagspaces.org) (A platform for file-based apps, [utilizing Ollama](https://docs.tagspaces.org/ai/) for the generation of tags and descriptions)\n- [Chatbot UI](https://github.com/ivanfioravanti/chatbot-ollama)\n- [Chatbot UI v2](https://github.com/mckaywrigley/chatbot-ui)\n- [Typescript UI](https://github.com/ollama-interface/Ollama-Gui?tab=readme-ov-file)\n- [Minimalistic React UI for Ollama Models](https://github.com/richawo/minimal-llm-ui)\n- [Ollamac](https://github.com/kevinhermawan/Ollamac)\n- [big-AGI](https://github.com/enricoros/big-AGI)\n- [Cheshire Cat assistant framework](https://github.com/cheshire-cat-ai/core)\n- [Amica](https://github.com/semperai/amica)\n- [chatd](https://github.com/BruceMacD/chatd)\n- [Ollama-SwiftUI](https://github.com/kghandour/Ollama-SwiftUI)\n- [Dify.AI](https://github.com/langgenius/dify)\n- [MindMac](https://mindmac.app)\n- [NextJS Web Interface for Ollama](https://github.com/jakobhoeg/nextjs-ollama-llm-ui)\n- [Msty](https://msty.app)\n- [Chatbox](https://github.com/Bin-Huang/Chatbox)\n- [WinForm Ollama Copilot](https://github.com/tgraupmann/WinForm_Ollama_Copilot)\n- [NextChat](https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web) with [Get Started Doc](https://docs.nextchat.dev/models/ollama)\n- [Alpaca WebUI](https://github.com/mmo80/alpaca-webui)\n- [OllamaGUI](https://github.com/enoch1118/ollamaGUI)\n- [OpenAOE](https://github.com/InternLM/OpenAOE)\n- [Odin Runes](https://github.com/leonid20000/OdinRunes)\n- [LLM-X](https://github.com/mrdjohnson/llm-x) (Progressive Web App)\n- [AnythingLLM (Docker + MacOs/Windows/Linux native app)](https://github.com/Mintplex-Labs/anything-llm)\n- [Screenpipe](https://github.com/mediar-ai/screenpipe) (24/7 screen & mic recording with AI-powered search, uses Ollama for local LLM features)\n- [Ollama Basic Chat: Uses HyperDiv Reactive UI](https://github.com/rapidarchitect/ollama_basic_chat)\n- [Ollama-chats RPG](https://github.com/drazdra/ollama-chats)\n- [IntelliBar](https://intellibar.app/) (AI-powered assistant for macOS)\n- [Jirapt](https://github.com/AliAhmedNada/jirapt) (Jira Integration to generate issues, tasks, epics)\n- [ojira](https://github.com/AliAhmedNada/ojira) (Jira chrome plugin to easily generate descriptions for tasks)\n- [QA-Pilot](https://github.com/reid41/QA-Pilot) (Interactive chat tool that can leverage Ollama models for rapid understanding and navigation of GitHub code repositories)\n- [ChatOllama](https://github.com/sugarforever/chat-ollama) (Open Source Chatbot based on Ollama with Knowledge Bases)\n- [CRAG Ollama Chat](https://github.com/Nagi-ovo/CRAG-Ollama-Chat) (Simple Web Search with Corrective RAG)\n- [RAGFlow](https://github.com/infiniflow/ragflow) (Open-source Retrieval-Augmented Generation engine based on deep document understanding)\n- [StreamDeploy](https://github.com/StreamDeploy-DevRel/streamdeploy-llm-app-scaffold) (LLM Application Scaffold)\n- [chat](https://github.com/swuecho/chat) (chat web app for teams)\n- [Lobe Chat](https://github.com/lobehub/lobe-chat) with [Integrating Doc](https://lobehub.com/docs/self-hosting/examples/ollama)\n- [Ollama RAG Chatbot](https://github.com/datvodinh/rag-chatbot.git) (Local Chat with multiple PDFs using Ollama and RAG)\n- [BrainSoup](https://www.nurgo-software.com/products/brainsoup) (Flexible native client with RAG & multi-agent automation)\n- [macai](https://github.com/Renset/macai) (macOS client for Ollama, ChatGPT, and other compatible API back-ends)\n- [RWKV-Runner](https://github.com/josStorer/RWKV-Runner) (RWKV offline LLM deployment tool, also usable as a client for ChatGPT and Ollama)\n- [Ollama Grid Search](https://github.com/dezoito/ollama-grid-search) (app to evaluate and compare models)\n- [Olpaka](https://github.com/Otacon/olpaka) (User-friendly Flutter Web App for Ollama)\n- [Casibase](https://casibase.org) (An open source AI knowledge base and dialogue system combining the latest RAG, SSO, ollama support, and multiple large language models.)\n- [OllamaSpring](https://github.com/CrazyNeil/OllamaSpring) (Ollama Client for macOS)\n- [LLocal.in](https://github.com/kartikm7/llocal) (Easy to use Electron Desktop Client for Ollama)\n- [Shinkai Desktop](https://github.com/dcSpark/shinkai-apps) (Two click install Local AI using Ollama + Files + RAG)\n- [AiLama](https://github.com/zeyoyt/ailama) (A Discord User App that allows you to interact with Ollama anywhere in Discord)\n- [Ollama with Google Mesop](https://github.com/rapidarchitect/ollama_mesop/) (Mesop Chat Client implementation with Ollama)\n- [R2R](https://github.com/SciPhi-AI/R2R) (Open-source RAG engine)\n- [Ollama-Kis](https://github.com/elearningshow/ollama-kis) (A simple easy-to-use GUI with sample custom LLM for Drivers Education)\n- [OpenGPA](https://opengpa.org) (Open-source offline-first Enterprise Agentic Application)\n- [Painting Droid](https://github.com/mateuszmigas/painting-droid) (Painting app with AI integrations)\n- [Kerlig AI](https://www.kerlig.com/) (AI writing assistant for macOS)\n- [AI Studio](https://github.com/MindWorkAI/AI-Studio)\n- [Sidellama](https://github.com/gyopak/sidellama) (browser-based LLM client)\n- [LLMStack](https://github.com/trypromptly/LLMStack) (No-code multi-agent framework to build LLM agents and workflows)\n- [BoltAI for Mac](https://boltai.com) (AI Chat Client for Mac)\n- [Harbor](https://github.com/av/harbor) (Containerized LLM Toolkit with Ollama as default backend)\n- [PyGPT](https://github.com/szczyglis-dev/py-gpt) (AI desktop assistant for Linux, Windows, and Mac)\n- [Alpaca](https://github.com/Jeffser/Alpaca) (An Ollama client application for Linux and macOS made with GTK4 and Adwaita)\n- [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT/blob/master/docs/content/platform/ollama.md) (AutoGPT Ollama integration)\n- [Go-CREW](https://www.jonathanhecl.com/go-crew/) (Powerful Offline RAG in Golang)\n- [PartCAD](https://github.com/openvmp/partcad/) (CAD model generation with OpenSCAD and CadQuery)\n- [Ollama4j Web UI](https://github.com/ollama4j/ollama4j-web-ui) - Java-based Web UI for Ollama built with Vaadin, Spring Boot, and Ollama4j\n- [PyOllaMx](https://github.com/kspviswa/pyOllaMx) - macOS application capable of chatting with both Ollama and Apple MLX models.\n- [Cline](https://github.com/cline/cline) - Formerly known as Claude Dev is a VS Code extension for multi-file/whole-repo coding\n- [Void](https://github.com/voideditor/void) (Open source AI code editor and Cursor alternative)\n- [Cherry Studio](https://github.com/kangfenmao/cherry-studio) (Desktop client with Ollama support)\n- [ConfiChat](https://github.com/1runeberg/confichat) (Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)\n- [Archyve](https://github.com/nickthecook/archyve) (RAG-enabling document library)\n- [crewAI with Mesop](https://github.com/rapidarchitect/ollama-crew-mesop) (Mesop Web Interface to run crewAI with Ollama)\n- [Tkinter-based client](https://github.com/chyok/ollama-gui) (Python tkinter-based Client for Ollama)\n- [LLMChat](https://github.com/trendy-design/llmchat) (Privacy focused, 100% local, intuitive all-in-one chat interface)\n- [Local Multimodal AI Chat](https://github.com/Leon-Sander/Local-Multimodal-AI-Chat) (Ollama-based LLM Chat with support for multiple features, including PDF RAG, voice chat, image-based interactions, and integration with OpenAI.)\n- [ARGO](https://github.com/xark-argo/argo) (Locally download and run Ollama and Huggingface models with RAG and deep research on Mac/Windows/Linux)\n- [OrionChat](https://github.com/EliasPereirah/OrionChat) - OrionChat is a web interface for chatting with different AI providers\n- [G1](https://github.com/bklieger-groq/g1) (Prototype of using prompting strategies to improve the LLM's reasoning through o1-like reasoning chains.)\n- [Web management](https://github.com/lemonit-eric-mao/ollama-web-management) (Web management page)\n- [Promptery](https://github.com/promptery/promptery) (desktop client for Ollama.)\n- [Ollama App](https://github.com/JHubi1/ollama-app) (Modern and easy-to-use multi-platform client for Ollama)\n- [chat-ollama](https://github.com/annilq/chat-ollama) (a React Native client for Ollama)\n- [SpaceLlama](https://github.com/tcsenpai/spacellama) (Firefox and Chrome extension to quickly summarize web pages with ollama in a sidebar)\n- [YouLama](https://github.com/tcsenpai/youlama) (Webapp to quickly summarize any YouTube video, supporting Invidious as well)\n- [DualMind](https://github.com/tcsenpai/dualmind) (Experimental app allowing two models to talk to each other in the terminal or in a web interface)\n- [ollamarama-matrix](https://github.com/h1ddenpr0cess20/ollamarama-matrix) (Ollama chatbot for the Matrix chat protocol)\n- [ollama-chat-app](https://github.com/anan1213095357/ollama-chat-app) (Flutter-based chat app)\n- [Perfect Memory AI](https://www.perfectmemory.ai/) (Productivity AI assists personalized by what you have seen on your screen, heard, and said in the meetings)\n- [Hexabot](https://github.com/hexastack/hexabot) (A conversational AI builder)\n- [Reddit Rate](https://github.com/rapidarchitect/reddit_analyzer) (Search and Rate Reddit topics with a weighted summation)\n- [OpenTalkGpt](https://github.com/adarshM84/OpenTalkGpt) (Chrome Extension to manage open-source models supported by Ollama, create custom models, and chat with models from a user-friendly UI)\n- [VT](https://github.com/vinhnx/vt.ai) (A minimal multimodal AI chat app, with dynamic conversation routing. Supports local models via Ollama)\n- [Nosia](https://github.com/nosia-ai/nosia) (Easy to install and use RAG platform based on Ollama)\n- [Witsy](https://github.com/nbonamy/witsy) (An AI Desktop application available for Mac/Windows/Linux)\n- [Abbey](https://github.com/US-Artificial-Intelligence/abbey) (A configurable AI interface server with notebooks, document storage, and YouTube support)\n- [Minima](https://github.com/dmayboroda/minima) (RAG with on-premises or fully local workflow)\n- [aidful-ollama-model-delete](https://github.com/AidfulAI/aidful-ollama-model-delete) (User interface for simplified model cleanup)\n- [Perplexica](https://github.com/ItzCrazyKns/Perplexica) (An AI-powered search engine & an open-source alternative to Perplexity AI)\n- [Ollama Chat WebUI for Docker ](https://github.com/oslook/ollama-webui) (Support for local docker deployment, lightweight ollama webui)\n- [AI Toolkit for Visual Studio Code](https://aka.ms/ai-tooklit/ollama-docs) (Microsoft-official VS Code extension to chat, test, evaluate models with Ollama support, and use them in your AI applications.)\n- [MinimalNextOllamaChat](https://github.com/anilkay/MinimalNextOllamaChat) (Minimal Web UI for Chat and Model Control)\n- [Chipper](https://github.com/TilmanGriesel/chipper) AI interface for tinkerers (Ollama, Haystack RAG, Python)\n- [ChibiChat](https://github.com/CosmicEventHorizon/ChibiChat) (Kotlin-based Android app to chat with Ollama and Koboldcpp API endpoints)\n- [LocalLLM](https://github.com/qusaismael/localllm) (Minimal Web-App to run ollama models on it with a GUI)\n- [Ollamazing](https://github.com/buiducnhat/ollamazing) (Web extension to run Ollama models)\n- [OpenDeepResearcher-via-searxng](https://github.com/benhaotang/OpenDeepResearcher-via-searxng) (A Deep Research equivalent endpoint with Ollama support for running locally)\n- [AntSK](https://github.com/AIDotNet/AntSK) (Out-of-the-box & Adaptable RAG Chatbot)\n- [MaxKB](https://github.com/1Panel-dev/MaxKB/) (Ready-to-use & flexible RAG Chatbot)\n- [yla](https://github.com/danielekp/yla) (Web interface to freely interact with your customized models)\n- [LangBot](https://github.com/RockChinQ/LangBot) (LLM-based instant messaging bots platform, with Agents, RAG features, supports multiple platforms)\n- [1Panel](https://github.com/1Panel-dev/1Panel/) (Web-based Linux Server Management Tool)\n- [AstrBot](https://github.com/Soulter/AstrBot/) (User-friendly LLM-based multi-platform chatbot with a WebUI, supporting RAG, LLM agents, and plugins integration)\n- [Reins](https://github.com/ibrahimcetin/reins) (Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)\n- [Flufy](https://github.com/Aharon-Bensadoun/Flufy) (A beautiful chat interface for interacting with Ollama's API. Built with React, TypeScript, and Material-UI.)\n- [Ellama](https://github.com/zeozeozeo/ellama) (Friendly native app to chat with an Ollama instance)\n- [screenpipe](https://github.com/mediar-ai/screenpipe) Build agents powered by your screen history\n- [Ollamb](https://github.com/hengkysteen/ollamb) (Simple yet rich in features, cross-platform built with Flutter and designed for Ollama. Try the [web demo](https://hengkysteen.github.io/demo/ollamb/).)\n- [Writeopia](https://github.com/Writeopia/Writeopia) (Text editor with integration with Ollama)\n- [AppFlowy](https://github.com/AppFlowy-IO/AppFlowy) (AI collaborative workspace with Ollama, cross-platform and self-hostable)\n- [Lumina](https://github.com/cushydigit/lumina.git) (A lightweight, minimal React.js frontend for interacting with Ollama servers)\n- [Tiny Notepad](https://pypi.org/project/tiny-notepad) (A lightweight, notepad-like interface to chat with ollama available on PyPI)\n- [macLlama (macOS native)](https://github.com/hellotunamayo/macLlama) (A native macOS GUI application for interacting with Ollama models, featuring a chat interface.)\n- [GPTranslate](https://github.com/philberndt/GPTranslate) (A fast and lightweight, AI powered desktop translation application written with Rust and Tauri. Features real-time translation with OpenAI/Azure/Ollama.)\n- [ollama launcher](https://github.com/NGC13009/ollama-launcher) (A launcher for Ollama, aiming to provide users with convenient functions such as ollama server launching, management, or configuration.)\n- [ai-hub](https://github.com/Aj-Seven/ai-hub) (AI Hub supports multiple models via API keys and Chat support via Ollama API.)\n- [Mayan EDMS](https://gitlab.com/mayan-edms/mayan-edms) (Open source document management system to organize, tag, search, and automate your files with powerful Ollama driven workflows.)\n- [Serene Pub](https://github.com/doolijb/serene-pub) (Beginner friendly, open source AI Roleplaying App for Windows, Mac OS and Linux. Search, download and use models with Ollama all inside the app.)\n- [Andes](https://github.com/aqerd/andes) (A Visual Studio Code extension that provides a local UI interface for Ollama models)\n- [KDeps](https://github.com/kdeps/kdeps) (Kdeps is an offline-first AI framework for building Dockerized full-stack AI applications declaratively using Apple PKL and integrates APIs with Ollama on the backend.)\n- [Clueless](https://github.com/KashyapTan/clueless) (Open Source & Local Cluely: A desktop application LLM assistant to help you talk to anything on your screen using locally served Ollama models. Also undetectable to screenshare)\n- [ollama-co2](https://github.com/carbonatedWaterOrg/ollama-co2) (FastAPI web interface for monitoring and managing local and remote Ollama servers with real-time model monitoring and concurrent downloads)\n- [Hillnote](https://hillnote.com) (A Markdown-first workspace designed to supercharge your AI workflow. Create documents ready to integrate with Claude, ChatGPT, Gemini, Cursor, and more - all while keeping your work on your device.)\n- [Stakpak](https://github.com/stakpak/agent) (An open source, vendor neutral DevOps agent that works with any model, and any stack, for teams who just want to ship)\n\n### Cloud\n\n- [Google Cloud](https://cloud.google.com/run/docs/tutorials/gpu-gemma2-with-ollama)\n- [Fly.io](https://fly.io/docs/python/do-more/add-ollama/)\n- [Koyeb](https://www.koyeb.com/deploy/ollama)\n\n### Tutorial\n\n- [handy-ollama](https://github.com/datawhalechina/handy-ollama) (Chinese Tutorial for Ollama by [Datawhale ](https://github.com/datawhalechina) - China's Largest Open Source AI Learning Community)\n\n### Terminal\n\n- [oterm](https://github.com/ggozad/oterm)\n- [Ellama Emacs client](https://github.com/s-kostyaev/ellama)\n- [Emacs client](https://github.com/zweifisch/ollama)\n- [neollama](https://github.com/paradoxical-dev/neollama) UI client for interacting with models from within Neovim\n- [gen.nvim](https://github.com/David-Kunz/gen.nvim)\n- [ollama.nvim](https://github.com/nomnivore/ollama.nvim)\n- [ollero.nvim](https://github.com/marco-souza/ollero.nvim)\n- [ollama-chat.nvim](https://github.com/gerazov/ollama-chat.nvim)\n- [ogpt.nvim](https://github.com/huynle/ogpt.nvim)\n- [gptel Emacs client](https://github.com/karthink/gptel)\n- [Oatmeal](https://github.com/dustinblackman/oatmeal)\n- [cmdh](https://github.com/pgibler/cmdh)\n- [ooo](https://github.com/npahlfer/ooo)\n- [shell-pilot](https://github.com/reid41/shell-pilot)(Interact with models via pure shell scripts on Linux or macOS)\n- [tenere](https://github.com/pythops/tenere)\n- [llm-ollama](https://github.com/taketwo/llm-ollama) for [Datasette's LLM CLI](https://llm.datasette.io/en/stable/).\n- [typechat-cli](https://github.com/anaisbetts/typechat-cli)\n- [ShellOracle](https://github.com/djcopley/ShellOracle)\n- [tlm](https://github.com/yusufcanb/tlm)\n- [podman-ollama](https://github.com/ericcurtin/podman-ollama)\n- [gollama](https://github.com/sammcj/gollama)\n- [ParLlama](https://github.com/paulrobello/parllama)\n- [Ollama eBook Summary](https://github.com/cognitivetech/ollama-ebook-summary/)\n- [Ollama Mixture of Experts (MOE) in 50 lines of code](https://github.com/rapidarchitect/ollama_moe)\n- [vim-intelligence-bridge](https://github.com/pepo-ec/vim-intelligence-bridge) Simple interaction of \"Ollama\" with the Vim editor\n- [x-cmd ollama](https://x-cmd.com/mod/ollama)\n- [bb7](https://github.com/drunkwcodes/bb7)\n- [SwollamaCLI](https://github.com/marcusziade/Swollama) bundled with the Swollama Swift package. [Demo](https://github.com/marcusziade/Swollama?tab=readme-ov-file#cli-usage)\n- [aichat](https://github.com/sigoden/aichat) All-in-one LLM CLI tool featuring Shell Assistant, Chat-REPL, RAG, AI tools & agents, with access to OpenAI, Claude, Gemini, Ollama, Groq, and more.\n- [PowershAI](https://github.com/rrg92/powershai) PowerShell module that brings AI to terminal on Windows, including support for Ollama\n- [DeepShell](https://github.com/Abyss-c0re/deepshell) Your self-hosted AI assistant. Interactive Shell, Files and Folders analysis.\n- [orbiton](https://github.com/xyproto/orbiton) Configuration-free text editor and IDE with support for tab completion with Ollama.\n- [orca-cli](https://github.com/molbal/orca-cli) Ollama Registry CLI Application - Browse, pull, and download models from Ollama Registry in your terminal.\n- [GGUF-to-Ollama](https://github.com/jonathanhecl/gguf-to-ollama) - Importing GGUF to Ollama made easy (multiplatform)\n- [AWS-Strands-With-Ollama](https://github.com/rapidarchitect/ollama_strands) - AWS Strands Agents with Ollama Examples\n- [ollama-multirun](https://github.com/attogram/ollama-multirun) - A bash shell script to run a single prompt against any or all of your locally installed ollama models, saving the output and performance statistics as easily navigable web pages. ([Demo](https://attogram.github.io/ai_test_zone/))\n- [ollama-bash-toolshed](https://github.com/attogram/ollama-bash-toolshed) - Bash scripts to chat with tool using models. Add new tools to your shed with ease. Runs on Ollama.\n- [hle-eval-ollama](https://github.com/mags0ft/hle-eval-ollama) - Runs benchmarks like \"Humanity's Last Exam\" (HLE) on your favorite local Ollama models and evaluates the quality of their responses\n- [VT Code](https://github.com/vinhnx/vtcode) - VT Code is a Rust-based terminal coding agent with semantic code intelligence via Tree-sitter. Ollama integration for running local/cloud models with configurable endpoints.\n\n### Apple Vision Pro\n\n- [SwiftChat](https://github.com/aws-samples/swift-chat) (Cross-platform AI chat app supporting Apple Vision Pro via \"Designed for iPad\")\n- [Enchanted](https://github.com/AugustDev/enchanted)\n\n### Database\n\n- [pgai](https://github.com/timescale/pgai) - PostgreSQL as a vector database (Create and search embeddings from Ollama models using pgvector)\n  - [Get started guide](https://github.com/timescale/pgai/blob/main/docs/vectorizer-quick-start.md)\n- [MindsDB](https://github.com/mindsdb/mindsdb/blob/staging/mindsdb/integrations/handlers/ollama_handler/README.md) (Connects Ollama models with nearly 200 data platforms and apps)\n- [chromem-go](https://github.com/philippgille/chromem-go/blob/v0.5.0/embed_ollama.go) with [example](https://github.com/philippgille/chromem-go/tree/v0.5.0/examples/rag-wikipedia-ollama)\n- [Kangaroo](https://github.com/dbkangaroo/kangaroo) (AI-powered SQL client and admin tool for popular databases)\n\n### Package managers\n\n- [Pacman](https://archlinux.org/packages/extra/x86_64/ollama/)\n- [Gentoo](https://github.com/gentoo/guru/tree/master/app-misc/ollama)\n- [Homebrew](https://formulae.brew.sh/formula/ollama)\n- [Helm Chart](https://artifacthub.io/packages/helm/ollama-helm/ollama)\n- [Guix channel](https://codeberg.org/tusharhero/ollama-guix)\n- [Nix package](https://search.nixos.org/packages?show=ollama&from=0&size=50&sort=relevance&type=packages&query=ollama)\n- [Flox](https://flox.dev/blog/ollama-part-one)\n\n### Libraries\n\n- [LangChain](https://python.langchain.com/docs/integrations/chat/ollama/) and [LangChain.js](https://js.langchain.com/docs/integrations/chat/ollama/) with [example](https://js.langchain.com/docs/tutorials/local_rag/)\n- [Firebase Genkit](https://firebase.google.com/docs/genkit/plugins/ollama)\n- [crewAI](https://github.com/crewAIInc/crewAI)\n- [Yacana](https://remembersoftwares.github.io/yacana/) (User-friendly multi-agent framework for brainstorming and executing predetermined flows with built-in tool integration)\n- [Strands Agents](https://github.com/strands-agents/sdk-python) (A model-driven approach to building AI agents in just a few lines of code)\n- [Spring AI](https://github.com/spring-projects/spring-ai) with [reference](https://docs.spring.io/spring-ai/reference/api/chat/ollama-chat.html) and [example](https://github.com/tzolov/ollama-tools)\n- [LangChainGo](https://github.com/tmc/langchaingo/) with [example](https://github.com/tmc/langchaingo/tree/main/examples/ollama-completion-example)\n- [LangChain4j](https://github.com/langchain4j/langchain4j) with [example](https://github.com/langchain4j/langchain4j-examples/tree/main/ollama-examples/src/main/java)\n- [LangChainRust](https://github.com/Abraxas-365/langchain-rust) with [example](https://github.com/Abraxas-365/langchain-rust/blob/main/examples/llm_ollama.rs)\n- [LangChain for .NET](https://github.com/tryAGI/LangChain) with [example](https://github.com/tryAGI/LangChain/blob/main/examples/LangChain.Samples.OpenAI/Program.cs)\n- [LLPhant](https://github.com/theodo-group/LLPhant?tab=readme-ov-file#ollama)\n- [LlamaIndex](https://docs.llamaindex.ai/en/stable/examples/llm/ollama/) and [LlamaIndexTS](https://ts.llamaindex.ai/modules/llms/available_llms/ollama)\n- [LiteLLM](https://github.com/BerriAI/litellm)\n- [OllamaFarm for Go](https://github.com/presbrey/ollamafarm)\n- [OllamaSharp for .NET](https://github.com/awaescher/OllamaSharp)\n- [Ollama for Ruby](https://github.com/crmne/ruby_llm)\n- [Ollama-rs for Rust](https://github.com/pepperoni21/ollama-rs)\n- [Ollama-hpp for C++](https://github.com/jmont-dev/ollama-hpp)\n- [Ollama4j for Java](https://github.com/ollama4j/ollama4j)\n- [ModelFusion Typescript Library](https://modelfusion.dev/integration/model-provider/ollama)\n- [OllamaKit for Swift](https://github.com/kevinhermawan/OllamaKit)\n- [Ollama for Dart](https://github.com/breitburg/dart-ollama)\n- [Ollama for Laravel](https://github.com/cloudstudio/ollama-laravel)\n- [LangChainDart](https://github.com/davidmigloz/langchain_dart)\n- [Semantic Kernel - Python](https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/ai/ollama)\n- [Haystack](https://github.com/deepset-ai/haystack-integrations/blob/main/integrations/ollama.md)\n- [Elixir LangChain](https://github.com/brainlid/langchain)\n- [Ollama for R - rollama](https://github.com/JBGruber/rollama)\n- [Ollama for R - ollama-r](https://github.com/hauselin/ollama-r)\n- [Ollama-ex for Elixir](https://github.com/lebrunel/ollama-ex)\n- [Ollama Connector for SAP ABAP](https://github.com/b-tocs/abap_btocs_ollama)\n- [Testcontainers](https://testcontainers.com/modules/ollama/)\n- [Portkey](https://portkey.ai/docs/welcome/integration-guides/ollama)\n- [PromptingTools.jl](https://github.com/svilupp/PromptingTools.jl) with an [example](https://svilupp.github.io/PromptingTools.jl/dev/examples/working_with_ollama)\n- [LlamaScript](https://github.com/Project-Llama/llamascript)\n- [llm-axe](https://github.com/emirsahin1/llm-axe) (Python Toolkit for Building LLM Powered Apps)\n- [Gollm](https://docs.gollm.co/examples/ollama-example)\n- [Gollama for Golang](https://github.com/jonathanhecl/gollama)\n- [Ollamaclient for Golang](https://github.com/xyproto/ollamaclient)\n- [High-level function abstraction in Go](https://gitlab.com/tozd/go/fun)\n- [Ollama PHP](https://github.com/ArdaGnsrn/ollama-php)\n- [Agents-Flex for Java](https://github.com/agents-flex/agents-flex) with [example](https://github.com/agents-flex/agents-flex/tree/main/agents-flex-llm/agents-flex-llm-ollama/src/test/java/com/agentsflex/llm/ollama)\n- [Parakeet](https://github.com/parakeet-nest/parakeet) is a GoLang library, made to simplify the development of small generative AI applications with Ollama.\n- [Haverscript](https://github.com/andygill/haverscript) with [examples](https://github.com/andygill/haverscript/tree/main/examples)\n- [Ollama for Swift](https://github.com/mattt/ollama-swift)\n- [Swollama for Swift](https://github.com/guitaripod/Swollama) with [DocC](https://guitaripod.github.io/Swollama/documentation/swollama)\n- [GoLamify](https://github.com/prasad89/golamify)\n- [Ollama for Haskell](https://github.com/tusharad/ollama-haskell)\n- [multi-llm-ts](https://github.com/nbonamy/multi-llm-ts) (A Typescript/JavaScript library allowing access to different LLM in a unified API)\n- [LlmTornado](https://github.com/lofcz/llmtornado) (C# library providing a unified interface for major FOSS & Commercial inference APIs)\n- [Ollama for Zig](https://github.com/dravenk/ollama-zig)\n- [Abso](https://github.com/lunary-ai/abso) (OpenAI-compatible TypeScript SDK for any LLM provider)\n- [Nichey](https://github.com/goodreasonai/nichey) is a Python package for generating custom wikis for your research topic\n- [Ollama for D](https://github.com/kassane/ollama-d)\n- [OllamaPlusPlus](https://github.com/HardCodeDev777/OllamaPlusPlus) (Very simple C++ library for Ollama)\n- [any-llm](https://github.com/mozilla-ai/any-llm) (A single interface to use different llm providers by [mozilla.ai](https://www.mozilla.ai/))\n- [any-agent](https://github.com/mozilla-ai/any-agent) (A single interface to use and evaluate different agent frameworks by [mozilla.ai](https://www.mozilla.ai/))\n- [Neuro SAN](https://github.com/cognizant-ai-lab/neuro-san-studio) (Data-driven multi-agent orchestration framework) with [example](https://github.com/cognizant-ai-lab/neuro-san-studio/blob/main/docs/user_guide.md#ollama)\n- [achatbot-go](https://github.com/ai-bot-pro/achatbot-go) a multimodal(text/audio/image) chatbot.\n- [Ollama Bash Lib](https://github.com/attogram/ollama-bash-lib) - A Bash Library for Ollama. Run LLM prompts straight from your shell, and more\n\n### Mobile\n\n- [SwiftChat](https://github.com/aws-samples/swift-chat) (Lightning-fast Cross-platform AI chat app with native UI for Android, iOS, and iPad)\n- [Enchanted](https://github.com/AugustDev/enchanted)\n- [Maid](https://github.com/Mobile-Artificial-Intelligence/maid)\n- [Ollama App](https://github.com/JHubi1/ollama-app) (Modern and easy-to-use multi-platform client for Ollama)\n- [ConfiChat](https://github.com/1runeberg/confichat) (Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)\n- [Ollama Android Chat](https://github.com/sunshine0523/OllamaServer) (No need for Termux, start the Ollama service with one click on an Android device)\n- [Reins](https://github.com/ibrahimcetin/reins) (Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)\n\n### Extensions & Plugins\n\n- [Raycast extension](https://github.com/MassimilianoPasquini97/raycast_ollama)\n- [Discollama](https://github.com/mxyng/discollama) (Discord bot inside the Ollama discord channel)\n- [Continue](https://github.com/continuedev/continue)\n- [Vibe](https://github.com/thewh1teagle/vibe) (Transcribe and analyze meetings with Ollama)\n- [Obsidian Ollama plugin](https://github.com/hinterdupfinger/obsidian-ollama)\n- [Logseq Ollama plugin](https://github.com/omagdy7/ollama-logseq)\n- [NotesOllama](https://github.com/andersrex/notesollama) (Apple Notes Ollama plugin)\n- [Dagger Chatbot](https://github.com/samalba/dagger-chatbot)\n- [Discord AI Bot](https://github.com/mekb-turtle/discord-ai-bot)\n- [Ollama Telegram Bot](https://github.com/ruecat/ollama-telegram)\n- [Hass Ollama Conversation](https://github.com/ej52/hass-ollama-conversation)\n- [Rivet plugin](https://github.com/abrenneke/rivet-plugin-ollama)\n- [Obsidian BMO Chatbot plugin](https://github.com/longy2k/obsidian-bmo-chatbot)\n- [Cliobot](https://github.com/herval/cliobot) (Telegram bot with Ollama support)\n- [Copilot for Obsidian plugin](https://github.com/logancyang/obsidian-copilot)\n- [Obsidian Local GPT plugin](https://github.com/pfrankov/obsidian-local-gpt)\n- [Open Interpreter](https://docs.openinterpreter.com/language-model-setup/local-models/ollama)\n- [Llama Coder](https://github.com/ex3ndr/llama-coder) (Copilot alternative using Ollama)\n- [Ollama Copilot](https://github.com/bernardo-bruning/ollama-copilot) (Proxy that allows you to use Ollama as a copilot like GitHub Copilot)\n- [twinny](https://github.com/rjmacarthy/twinny) (Copilot and Copilot chat alternative using Ollama)\n- [Wingman-AI](https://github.com/RussellCanfield/wingman-ai) (Copilot code and chat alternative using Ollama and Hugging Face)\n- [Page Assist](https://github.com/n4ze3m/page-assist) (Chrome Extension)\n- [Plasmoid Ollama Control](https://github.com/imoize/plasmoid-ollamacontrol) (KDE Plasma extension that allows you to quickly manage/control Ollama model)\n- [AI Telegram Bot](https://github.com/tusharhero/aitelegrambot) (Telegram bot using Ollama in backend)\n- [AI ST Completion](https://github.com/yaroslavyaroslav/OpenAI-sublime-text) (Sublime Text 4 AI assistant plugin with Ollama support)\n- [Discord-Ollama Chat Bot](https://github.com/kevinthedang/discord-ollama) (Generalized TypeScript Discord Bot w/ Tuning Documentation)\n- [ChatGPTBox: All in one browser extension](https://github.com/josStorer/chatGPTBox) with [Integrating Tutorial](https://github.com/josStorer/chatGPTBox/issues/616#issuecomment-1975186467)\n- [Discord AI chat/moderation bot](https://github.com/rapmd73/Companion) Chat/moderation bot written in python. Uses Ollama to create personalities.\n- [Headless Ollama](https://github.com/nischalj10/headless-ollama) (Scripts to automatically install ollama client & models on any OS for apps that depend on ollama server)\n- [Terraform AWS Ollama & Open WebUI](https://github.com/xuyangbocn/terraform-aws-self-host-llm) (A Terraform module to deploy on AWS a ready-to-use Ollama service, together with its front-end Open WebUI service.)\n- [node-red-contrib-ollama](https://github.com/jakubburkiewicz/node-red-contrib-ollama)\n- [Local AI Helper](https://github.com/ivostoykov/localAI) (Chrome and Firefox extensions that enable interactions with the active tab and customisable API endpoints. Includes secure storage for user prompts.)\n- [LSP-AI](https://github.com/SilasMarvin/lsp-ai) (Open-source language server for AI-powered functionality)\n- [QodeAssist](https://github.com/Palm1r/QodeAssist) (AI-powered coding assistant plugin for Qt Creator)\n- [Obsidian Quiz Generator plugin](https://github.com/ECuiDev/obsidian-quiz-generator)\n- [AI Summary Helper plugin](https://github.com/philffm/ai-summary-helper)\n- [TextCraft](https://github.com/suncloudsmoon/TextCraft) (Copilot in Word alternative using Ollama)\n- [Alfred Ollama](https://github.com/zeitlings/alfred-ollama) (Alfred Workflow)\n- [TextLLaMA](https://github.com/adarshM84/TextLLaMA) A Chrome Extension that helps you write emails, correct grammar, and translate into any language\n- [Simple-Discord-AI](https://github.com/zyphixor/simple-discord-ai)\n- [LLM Telegram Bot](https://github.com/innightwolfsleep/llm_telegram_bot) (telegram bot, primary for RP. Oobabooga-like buttons, [A1111](https://github.com/AUTOMATIC1111/stable-diffusion-webui) API integration e.t.c)\n- [mcp-llm](https://github.com/sammcj/mcp-llm) (MCP Server to allow LLMs to call other LLMs)\n- [SimpleOllamaUnity](https://github.com/HardCodeDev777/SimpleOllamaUnity) (Unity Engine extension for communicating with Ollama in a few lines of code. Also works at runtime)\n- [UnityCodeLama](https://github.com/HardCodeDev777/UnityCodeLama) (Unity Editor tool to analyze scripts via Ollama)\n- [NativeMind](https://github.com/NativeMindBrowser/NativeMindExtension) (Private, on-device AI Assistant, no cloud dependencies)\n- [GMAI - Gradle Managed AI](https://gmai.premex.se/) (Gradle plugin for automated Ollama lifecycle management during build phases)\n- [NOMYO Router](https://github.com/nomyo-ai/nomyo-router) (A transparent Ollama proxy with model deployment aware routing which auto-manages multiple Ollama instances in a given network)\n\n### Supported backends\n\n- [llama.cpp](https://github.com/ggml-org/llama.cpp) project founded by Georgi Gerganov.\n\n### Observability\n\n- [Opik](https://www.comet.com/docs/opik/cookbook/ollama) is an open-source platform to debug, evaluate, and monitor your LLM applications, RAG systems, and agentic workflows with comprehensive tracing, automated evaluations, and production-ready dashboards. Opik supports native integration to Ollama.\n- [Lunary](https://lunary.ai/docs/integrations/ollama) is the leading open-source LLM observability platform. It provides a variety of enterprise-grade features such as real-time analytics, prompt templates management, PII masking, and comprehensive agent tracing.\n- [OpenLIT](https://github.com/openlit/openlit) is an OpenTelemetry-native tool for monitoring Ollama Applications & GPUs using traces and metrics.\n- [HoneyHive](https://docs.honeyhive.ai/integrations/ollama) is an AI observability and evaluation platform for AI agents. Use HoneyHive to evaluate agent performance, interrogate failures, and monitor quality in production.\n- [Langfuse](https://langfuse.com/docs/integrations/ollama) is an open source LLM observability platform that enables teams to collaboratively monitor, evaluate and debug AI applications.\n- [MLflow Tracing](https://mlflow.org/docs/latest/llms/tracing/index.html#automatic-tracing) is an open source LLM observability tool with a convenient API to log and visualize traces, making it easy to debug and evaluate GenAI applications.\n\n### Security\n\n- [Ollama Fortress](https://github.com/ParisNeo/ollama_proxy_server)\n",
      "stars_today": 142
    },
    {
      "id": 612354784,
      "name": "llama.cpp",
      "full_name": "ggml-org/llama.cpp",
      "description": "LLM inference in C/C++",
      "html_url": "https://github.com/ggml-org/llama.cpp",
      "stars": 94541,
      "forks": 14791,
      "language": "C++",
      "topics": [
        "ggml"
      ],
      "created_at": "2023-03-10T18:58:00Z",
      "updated_at": "2026-02-07T02:10:45Z",
      "pushed_at": "2026-02-07T00:28:32Z",
      "open_issues": 1077,
      "owner": {
        "login": "ggml-org",
        "avatar_url": "https://avatars.githubusercontent.com/u/134263123?v=4"
      },
      "readme": "# llama.cpp\n\n![llama](https://user-images.githubusercontent.com/1991296/230134379-7181e485-c521-4d23-a0d6-f7b3b61ba524.png)\n\n[![License: MIT](https://img.shields.io/badge/license-MIT-blue.svg)](https://opensource.org/licenses/MIT)\n[![Release](https://img.shields.io/github/v/release/ggml-org/llama.cpp)](https://github.com/ggml-org/llama.cpp/releases)\n[![Server](https://github.com/ggml-org/llama.cpp/actions/workflows/server.yml/badge.svg)](https://github.com/ggml-org/llama.cpp/actions/workflows/server.yml)\n\n[Manifesto](https://github.com/ggml-org/llama.cpp/discussions/205) / [ggml](https://github.com/ggml-org/ggml) / [ops](https://github.com/ggml-org/llama.cpp/blob/master/docs/ops.md)\n\nLLM inference in C/C++\n\n## Recent API changes\n\n- [Changelog for `libllama` API](https://github.com/ggml-org/llama.cpp/issues/9289)\n- [Changelog for `llama-server` REST API](https://github.com/ggml-org/llama.cpp/issues/9291)\n\n## Hot topics\n\n- **[guide : using the new WebUI of llama.cpp](https://github.com/ggml-org/llama.cpp/discussions/16938)**\n- [guide : running gpt-oss with llama.cpp](https://github.com/ggml-org/llama.cpp/discussions/15396)\n- [[FEEDBACK] Better packaging for llama.cpp to support downstream consumers ğŸ¤—](https://github.com/ggml-org/llama.cpp/discussions/15313)\n- Support for the `gpt-oss` model with native MXFP4 format has been added | [PR](https://github.com/ggml-org/llama.cpp/pull/15091) | [Collaboration with NVIDIA](https://blogs.nvidia.com/blog/rtx-ai-garage-openai-oss) | [Comment](https://github.com/ggml-org/llama.cpp/discussions/15095)\n- Multimodal support arrived in `llama-server`: [#12898](https://github.com/ggml-org/llama.cpp/pull/12898) | [documentation](./docs/multimodal.md)\n- VS Code extension for FIM completions: https://github.com/ggml-org/llama.vscode\n- Vim/Neovim plugin for FIM completions: https://github.com/ggml-org/llama.vim\n- Hugging Face Inference Endpoints now support GGUF out of the box! https://github.com/ggml-org/llama.cpp/discussions/9669\n- Hugging Face GGUF editor: [discussion](https://github.com/ggml-org/llama.cpp/discussions/9268) | [tool](https://huggingface.co/spaces/CISCai/gguf-editor)\n\n----\n\n## Quick start\n\nGetting started with llama.cpp is straightforward. Here are several ways to install it on your machine:\n\n- Install `llama.cpp` using [brew, nix or winget](docs/install.md)\n- Run with Docker - see our [Docker documentation](docs/docker.md)\n- Download pre-built binaries from the [releases page](https://github.com/ggml-org/llama.cpp/releases)\n- Build from source by cloning this repository - check out [our build guide](docs/build.md)\n\nOnce installed, you'll need a model to work with. Head to the [Obtaining and quantizing models](#obtaining-and-quantizing-models) section to learn more.\n\nExample command:\n\n```sh\n# Use a local model file\nllama-cli -m my_model.gguf\n\n# Or download and run a model directly from Hugging Face\nllama-cli -hf ggml-org/gemma-3-1b-it-GGUF\n\n# Launch OpenAI-compatible API server\nllama-server -hf ggml-org/gemma-3-1b-it-GGUF\n```\n\n## Description\n\nThe main goal of `llama.cpp` is to enable LLM inference with minimal setup and state-of-the-art performance on a wide\nrange of hardware - locally and in the cloud.\n\n- Plain C/C++ implementation without any dependencies\n- Apple silicon is a first-class citizen - optimized via ARM NEON, Accelerate and Metal frameworks\n- AVX, AVX2, AVX512 and AMX support for x86 architectures\n- RVV, ZVFH, ZFH, ZICBOP and ZIHINTPAUSE support for RISC-V architectures\n- 1.5-bit, 2-bit, 3-bit, 4-bit, 5-bit, 6-bit, and 8-bit integer quantization for faster inference and reduced memory use\n- Custom CUDA kernels for running LLMs on NVIDIA GPUs (support for AMD GPUs via HIP and Moore Threads GPUs via MUSA)\n- Vulkan and SYCL backend support\n- CPU+GPU hybrid inference to partially accelerate models larger than the total VRAM capacity\n\nThe `llama.cpp` project is the main playground for developing new features for the [ggml](https://github.com/ggml-org/ggml) library.\n\n<details>\n<summary>Models</summary>\n\nTypically finetunes of the base models below are supported as well.\n\nInstructions for adding support for new models: [HOWTO-add-model.md](docs/development/HOWTO-add-model.md)\n\n#### Text-only\n\n- [X] LLaMA ğŸ¦™\n- [x] LLaMA 2 ğŸ¦™ğŸ¦™\n- [x] LLaMA 3 ğŸ¦™ğŸ¦™ğŸ¦™\n- [X] [Mistral 7B](https://huggingface.co/mistralai/Mistral-7B-v0.1)\n- [x] [Mixtral MoE](https://huggingface.co/models?search=mistral-ai/Mixtral)\n- [x] [DBRX](https://huggingface.co/databricks/dbrx-instruct)\n- [x] [Jamba](https://huggingface.co/ai21labs)\n- [X] [Falcon](https://huggingface.co/models?search=tiiuae/falcon)\n- [X] [Chinese LLaMA / Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca) and [Chinese LLaMA-2 / Alpaca-2](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2)\n- [X] [Vigogne (French)](https://github.com/bofenghuang/vigogne)\n- [X] [BERT](https://github.com/ggml-org/llama.cpp/pull/5423)\n- [X] [Koala](https://bair.berkeley.edu/blog/2023/04/03/koala/)\n- [X] [Baichuan 1 & 2](https://huggingface.co/models?search=baichuan-inc/Baichuan) + [derivations](https://huggingface.co/hiyouga/baichuan-7b-sft)\n- [X] [Aquila 1 & 2](https://huggingface.co/models?search=BAAI/Aquila)\n- [X] [Starcoder models](https://github.com/ggml-org/llama.cpp/pull/3187)\n- [X] [Refact](https://huggingface.co/smallcloudai/Refact-1_6B-fim)\n- [X] [MPT](https://github.com/ggml-org/llama.cpp/pull/3417)\n- [X] [Bloom](https://github.com/ggml-org/llama.cpp/pull/3553)\n- [x] [Yi models](https://huggingface.co/models?search=01-ai/Yi)\n- [X] [StableLM models](https://huggingface.co/stabilityai)\n- [x] [Deepseek models](https://huggingface.co/models?search=deepseek-ai/deepseek)\n- [x] [Qwen models](https://huggingface.co/models?search=Qwen/Qwen)\n- [x] [PLaMo-13B](https://github.com/ggml-org/llama.cpp/pull/3557)\n- [x] [Phi models](https://huggingface.co/models?search=microsoft/phi)\n- [x] [PhiMoE](https://github.com/ggml-org/llama.cpp/pull/11003)\n- [x] [GPT-2](https://huggingface.co/gpt2)\n- [x] [Orion 14B](https://github.com/ggml-org/llama.cpp/pull/5118)\n- [x] [InternLM2](https://huggingface.co/models?search=internlm2)\n- [x] [CodeShell](https://github.com/WisdomShell/codeshell)\n- [x] [Gemma](https://ai.google.dev/gemma)\n- [x] [Mamba](https://github.com/state-spaces/mamba)\n- [x] [Grok-1](https://huggingface.co/keyfan/grok-1-hf)\n- [x] [Xverse](https://huggingface.co/models?search=xverse)\n- [x] [Command-R models](https://huggingface.co/models?search=CohereForAI/c4ai-command-r)\n- [x] [SEA-LION](https://huggingface.co/models?search=sea-lion)\n- [x] [GritLM-7B](https://huggingface.co/GritLM/GritLM-7B) + [GritLM-8x7B](https://huggingface.co/GritLM/GritLM-8x7B)\n- [x] [OLMo](https://allenai.org/olmo)\n- [x] [OLMo 2](https://allenai.org/olmo)\n- [x] [OLMoE](https://huggingface.co/allenai/OLMoE-1B-7B-0924)\n- [x] [Granite models](https://huggingface.co/collections/ibm-granite/granite-code-models-6624c5cec322e4c148c8b330)\n- [x] [GPT-NeoX](https://github.com/EleutherAI/gpt-neox) + [Pythia](https://github.com/EleutherAI/pythia)\n- [x] [Snowflake-Arctic MoE](https://huggingface.co/collections/Snowflake/arctic-66290090abe542894a5ac520)\n- [x] [Smaug](https://huggingface.co/models?search=Smaug)\n- [x] [Poro 34B](https://huggingface.co/LumiOpen/Poro-34B)\n- [x] [Bitnet b1.58 models](https://huggingface.co/1bitLLM)\n- [x] [Flan T5](https://huggingface.co/models?search=flan-t5)\n- [x] [Open Elm models](https://huggingface.co/collections/apple/openelm-instruct-models-6619ad295d7ae9f868b759ca)\n- [x] [ChatGLM3-6b](https://huggingface.co/THUDM/chatglm3-6b) + [ChatGLM4-9b](https://huggingface.co/THUDM/glm-4-9b) + [GLMEdge-1.5b](https://huggingface.co/THUDM/glm-edge-1.5b-chat) + [GLMEdge-4b](https://huggingface.co/THUDM/glm-edge-4b-chat)\n- [x] [GLM-4-0414](https://huggingface.co/collections/THUDM/glm-4-0414-67f3cbcb34dd9d252707cb2e)\n- [x] [SmolLM](https://huggingface.co/collections/HuggingFaceTB/smollm-6695016cad7167254ce15966)\n- [x] [EXAONE-3.0-7.8B-Instruct](https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct)\n- [x] [FalconMamba Models](https://huggingface.co/collections/tiiuae/falconmamba-7b-66b9a580324dd1598b0f6d4a)\n- [x] [Jais](https://huggingface.co/inceptionai/jais-13b-chat)\n- [x] [Bielik-11B-v2.3](https://huggingface.co/collections/speakleash/bielik-11b-v23-66ee813238d9b526a072408a)\n- [x] [RWKV-7](https://huggingface.co/collections/shoumenchougou/rwkv7-gxx-gguf)\n- [x] [RWKV-6](https://github.com/BlinkDL/RWKV-LM)\n- [x] [QRWKV-6](https://huggingface.co/recursal/QRWKV6-32B-Instruct-Preview-v0.1)\n- [x] [GigaChat-20B-A3B](https://huggingface.co/ai-sage/GigaChat-20B-A3B-instruct)\n- [X] [Trillion-7B-preview](https://huggingface.co/trillionlabs/Trillion-7B-preview)\n- [x] [Ling models](https://huggingface.co/collections/inclusionAI/ling-67c51c85b34a7ea0aba94c32)\n- [x] [LFM2 models](https://huggingface.co/collections/LiquidAI/lfm2-686d721927015b2ad73eaa38)\n- [x] [Hunyuan models](https://huggingface.co/collections/tencent/hunyuan-dense-model-6890632cda26b19119c9c5e7)\n- [x] [BailingMoeV2 (Ring/Ling 2.0) models](https://huggingface.co/collections/inclusionAI/ling-v2-68bf1dd2fc34c306c1fa6f86)\n\n#### Multimodal\n\n- [x] [LLaVA 1.5 models](https://huggingface.co/collections/liuhaotian/llava-15-653aac15d994e992e2677a7e), [LLaVA 1.6 models](https://huggingface.co/collections/liuhaotian/llava-16-65b9e40155f60fd046a5ccf2)\n- [x] [BakLLaVA](https://huggingface.co/models?search=SkunkworksAI/Bakllava)\n- [x] [Obsidian](https://huggingface.co/NousResearch/Obsidian-3B-V0.5)\n- [x] [ShareGPT4V](https://huggingface.co/models?search=Lin-Chen/ShareGPT4V)\n- [x] [MobileVLM 1.7B/3B models](https://huggingface.co/models?search=mobileVLM)\n- [x] [Yi-VL](https://huggingface.co/models?search=Yi-VL)\n- [x] [Mini CPM](https://huggingface.co/models?search=MiniCPM)\n- [x] [Moondream](https://huggingface.co/vikhyatk/moondream2)\n- [x] [Bunny](https://github.com/BAAI-DCAI/Bunny)\n- [x] [GLM-EDGE](https://huggingface.co/models?search=glm-edge)\n- [x] [Qwen2-VL](https://huggingface.co/collections/Qwen/qwen2-vl-66cee7455501d7126940800d)\n- [x] [LFM2-VL](https://huggingface.co/collections/LiquidAI/lfm2-vl-68963bbc84a610f7638d5ffa)\n\n</details>\n\n<details>\n<summary>Bindings</summary>\n\n- Python: [ddh0/easy-llama](https://github.com/ddh0/easy-llama)\n- Python: [abetlen/llama-cpp-python](https://github.com/abetlen/llama-cpp-python)\n- Go: [go-skynet/go-llama.cpp](https://github.com/go-skynet/go-llama.cpp)\n- Node.js: [withcatai/node-llama-cpp](https://github.com/withcatai/node-llama-cpp)\n- JS/TS (llama.cpp server client): [lgrammel/modelfusion](https://modelfusion.dev/integration/model-provider/llamacpp)\n- JS/TS (Programmable Prompt Engine CLI): [offline-ai/cli](https://github.com/offline-ai/cli)\n- JavaScript/Wasm (works in browser): [tangledgroup/llama-cpp-wasm](https://github.com/tangledgroup/llama-cpp-wasm)\n- Typescript/Wasm (nicer API, available on npm): [ngxson/wllama](https://github.com/ngxson/wllama)\n- Ruby: [yoshoku/llama_cpp.rb](https://github.com/yoshoku/llama_cpp.rb)\n- Rust (more features): [edgenai/llama_cpp-rs](https://github.com/edgenai/llama_cpp-rs)\n- Rust (nicer API): [mdrokz/rust-llama.cpp](https://github.com/mdrokz/rust-llama.cpp)\n- Rust (more direct bindings): [utilityai/llama-cpp-rs](https://github.com/utilityai/llama-cpp-rs)\n- Rust (automated build from crates.io): [ShelbyJenkins/llm_client](https://github.com/ShelbyJenkins/llm_client)\n- C#/.NET: [SciSharp/LLamaSharp](https://github.com/SciSharp/LLamaSharp)\n- C#/VB.NET (more features - community license): [LM-Kit.NET](https://docs.lm-kit.com/lm-kit-net/index.html)\n- Scala 3: [donderom/llm4s](https://github.com/donderom/llm4s)\n- Clojure: [phronmophobic/llama.clj](https://github.com/phronmophobic/llama.clj)\n- React Native: [mybigday/llama.rn](https://github.com/mybigday/llama.rn)\n- Java: [kherud/java-llama.cpp](https://github.com/kherud/java-llama.cpp)\n- Java: [QuasarByte/llama-cpp-jna](https://github.com/QuasarByte/llama-cpp-jna)\n- Zig: [deins/llama.cpp.zig](https://github.com/Deins/llama.cpp.zig)\n- Flutter/Dart: [netdur/llama_cpp_dart](https://github.com/netdur/llama_cpp_dart)\n- Flutter: [xuegao-tzx/Fllama](https://github.com/xuegao-tzx/Fllama)\n- PHP (API bindings and features built on top of llama.cpp): [distantmagic/resonance](https://github.com/distantmagic/resonance) [(more info)](https://github.com/ggml-org/llama.cpp/pull/6326)\n- Guile Scheme: [guile_llama_cpp](https://savannah.nongnu.org/projects/guile-llama-cpp)\n- Swift [srgtuszy/llama-cpp-swift](https://github.com/srgtuszy/llama-cpp-swift)\n- Swift [ShenghaiWang/SwiftLlama](https://github.com/ShenghaiWang/SwiftLlama)\n- Delphi [Embarcadero/llama-cpp-delphi](https://github.com/Embarcadero/llama-cpp-delphi)\n- Go (no CGo needed): [hybridgroup/yzma](https://github.com/hybridgroup/yzma)\n- Android: [llama.android](/examples/llama.android)\n\n</details>\n\n<details>\n<summary>UIs</summary>\n\n*(to have a project listed here, it should clearly state that it depends on `llama.cpp`)*\n\n- [AI Sublime Text plugin](https://github.com/yaroslavyaroslav/OpenAI-sublime-text) (MIT)\n- [BonzAI App](https://apps.apple.com/us/app/bonzai-your-local-ai-agent/id6752847988) (proprietary)\n- [cztomsik/ava](https://github.com/cztomsik/ava) (MIT)\n- [Dot](https://github.com/alexpinel/Dot) (GPL)\n- [eva](https://github.com/ylsdamxssjxxdd/eva) (MIT)\n- [iohub/collama](https://github.com/iohub/coLLaMA) (Apache-2.0)\n- [janhq/jan](https://github.com/janhq/jan) (AGPL)\n- [johnbean393/Sidekick](https://github.com/johnbean393/Sidekick) (MIT)\n- [KanTV](https://github.com/zhouwg/kantv?tab=readme-ov-file) (Apache-2.0)\n- [KodiBot](https://github.com/firatkiral/kodibot) (GPL)\n- [llama.vim](https://github.com/ggml-org/llama.vim) (MIT)\n- [LARS](https://github.com/abgulati/LARS) (AGPL)\n- [Llama Assistant](https://github.com/vietanhdev/llama-assistant) (GPL)\n- [LlamaLib](https://github.com/undreamai/LlamaLib) (Apache-2.0)\n- [LLMFarm](https://github.com/guinmoon/LLMFarm?tab=readme-ov-file) (MIT)\n- [LLMUnity](https://github.com/undreamai/LLMUnity) (MIT)\n- [LMStudio](https://lmstudio.ai/) (proprietary)\n- [LocalAI](https://github.com/mudler/LocalAI) (MIT)\n- [LostRuins/koboldcpp](https://github.com/LostRuins/koboldcpp) (AGPL)\n- [MindMac](https://mindmac.app) (proprietary)\n- [MindWorkAI/AI-Studio](https://github.com/MindWorkAI/AI-Studio) (FSL-1.1-MIT)\n- [Mobile-Artificial-Intelligence/maid](https://github.com/Mobile-Artificial-Intelligence/maid) (MIT)\n- [Mozilla-Ocho/llamafile](https://github.com/Mozilla-Ocho/llamafile) (Apache-2.0)\n- [nat/openplayground](https://github.com/nat/openplayground) (MIT)\n- [nomic-ai/gpt4all](https://github.com/nomic-ai/gpt4all) (MIT)\n- [ollama/ollama](https://github.com/ollama/ollama) (MIT)\n- [oobabooga/text-generation-webui](https://github.com/oobabooga/text-generation-webui) (AGPL)\n- [PocketPal AI](https://github.com/a-ghorbani/pocketpal-ai) (MIT)\n- [psugihara/FreeChat](https://github.com/psugihara/FreeChat) (MIT)\n- [ptsochantaris/emeltal](https://github.com/ptsochantaris/emeltal) (MIT)\n- [pythops/tenere](https://github.com/pythops/tenere) (AGPL)\n- [ramalama](https://github.com/containers/ramalama) (MIT)\n- [semperai/amica](https://github.com/semperai/amica) (MIT)\n- [withcatai/catai](https://github.com/withcatai/catai) (MIT)\n- [Autopen](https://github.com/blackhole89/autopen) (GPL)\n\n</details>\n\n<details>\n<summary>Tools</summary>\n\n- [akx/ggify](https://github.com/akx/ggify) â€“ download PyTorch models from HuggingFace Hub and convert them to GGML\n- [akx/ollama-dl](https://github.com/akx/ollama-dl) â€“ download models from the Ollama library to be used directly with llama.cpp\n- [crashr/gppm](https://github.com/crashr/gppm) â€“ launch llama.cpp instances utilizing NVIDIA Tesla P40 or P100 GPUs with reduced idle power consumption\n- [gpustack/gguf-parser](https://github.com/gpustack/gguf-parser-go/tree/main/cmd/gguf-parser) - review/check the GGUF file and estimate the memory usage\n- [Styled Lines](https://marketplace.unity.com/packages/tools/generative-ai/styled-lines-llama-cpp-model-292902) (proprietary licensed, async wrapper of inference part for game development in Unity3d with pre-built Mobile and Web platform wrappers and a model example)\n- [unslothai/unsloth](https://github.com/unslothai/unsloth) â€“ ğŸ¦¥ exports/saves fine-tuned and trained models to GGUF (Apache-2.0)\n\n</details>\n\n<details>\n<summary>Infrastructure</summary>\n\n- [Paddler](https://github.com/intentee/paddler) - Open-source LLMOps platform for hosting and scaling AI in your own infrastructure\n- [GPUStack](https://github.com/gpustack/gpustack) - Manage GPU clusters for running LLMs\n- [llama_cpp_canister](https://github.com/onicai/llama_cpp_canister) - llama.cpp as a smart contract on the Internet Computer, using WebAssembly\n- [llama-swap](https://github.com/mostlygeek/llama-swap) - transparent proxy that adds automatic model switching with llama-server\n- [Kalavai](https://github.com/kalavai-net/kalavai-client) - Crowdsource end to end LLM deployment at any scale\n- [llmaz](https://github.com/InftyAI/llmaz) - â˜¸ï¸ Easy, advanced inference platform for large language models on Kubernetes.\n</details>\n\n<details>\n<summary>Games</summary>\n\n- [Lucy's Labyrinth](https://github.com/MorganRO8/Lucys_Labyrinth) - A simple maze game where agents controlled by an AI model will try to trick you.\n\n</details>\n\n\n## Supported backends\n\n| Backend | Target devices |\n| --- | --- |\n| [Metal](docs/build.md#metal-build) | Apple Silicon |\n| [BLAS](docs/build.md#blas-build) | All |\n| [BLIS](docs/backend/BLIS.md) | All |\n| [SYCL](docs/backend/SYCL.md) | Intel and Nvidia GPU |\n| [MUSA](docs/build.md#musa) | Moore Threads GPU |\n| [CUDA](docs/build.md#cuda) | Nvidia GPU |\n| [HIP](docs/build.md#hip) | AMD GPU |\n| [ZenDNN](docs/build.md#zendnn) | AMD CPU |\n| [Vulkan](docs/build.md#vulkan) | GPU |\n| [CANN](docs/build.md#cann) | Ascend NPU |\n| [OpenCL](docs/backend/OPENCL.md) | Adreno GPU |\n| [IBM zDNN](docs/backend/zDNN.md) | IBM Z & LinuxONE |\n| [WebGPU [In Progress]](docs/build.md#webgpu) | All |\n| [RPC](https://github.com/ggml-org/llama.cpp/tree/master/tools/rpc) | All |\n| [Hexagon [In Progress]](docs/backend/hexagon/README.md) | Snapdragon |\n\n## Obtaining and quantizing models\n\nThe [Hugging Face](https://huggingface.co) platform hosts a [number of LLMs](https://huggingface.co/models?library=gguf&sort=trending) compatible with `llama.cpp`:\n\n- [Trending](https://huggingface.co/models?library=gguf&sort=trending)\n- [LLaMA](https://huggingface.co/models?sort=trending&search=llama+gguf)\n\nYou can either manually download the GGUF file or directly use any `llama.cpp`-compatible models from [Hugging Face](https://huggingface.co/) or other model hosting sites, such as [ModelScope](https://modelscope.cn/), by using this CLI argument: `-hf <user>/<model>[:quant]`. For example:\n\n```sh\nllama-cli -hf ggml-org/gemma-3-1b-it-GGUF\n```\n\nBy default, the CLI would download from Hugging Face, you can switch to other options with the environment variable `MODEL_ENDPOINT`. For example, you may opt to downloading model checkpoints from ModelScope or other model sharing communities by setting the environment variable, e.g. `MODEL_ENDPOINT=https://www.modelscope.cn/`.\n\nAfter downloading a model, use the CLI tools to run it locally - see below.\n\n`llama.cpp` requires the model to be stored in the [GGUF](https://github.com/ggml-org/ggml/blob/master/docs/gguf.md) file format. Models in other data formats can be converted to GGUF using the `convert_*.py` Python scripts in this repo.\n\nThe Hugging Face platform provides a variety of online tools for converting, quantizing and hosting models with `llama.cpp`:\n\n- Use the [GGUF-my-repo space](https://huggingface.co/spaces/ggml-org/gguf-my-repo) to convert to GGUF format and quantize model weights to smaller sizes\n- Use the [GGUF-my-LoRA space](https://huggingface.co/spaces/ggml-org/gguf-my-lora) to convert LoRA adapters to GGUF format (more info: https://github.com/ggml-org/llama.cpp/discussions/10123)\n- Use the [GGUF-editor space](https://huggingface.co/spaces/CISCai/gguf-editor) to edit GGUF meta data in the browser (more info: https://github.com/ggml-org/llama.cpp/discussions/9268)\n- Use the [Inference Endpoints](https://ui.endpoints.huggingface.co/) to directly host `llama.cpp` in the cloud (more info: https://github.com/ggml-org/llama.cpp/discussions/9669)\n\nTo learn more about model quantization, [read this documentation](tools/quantize/README.md)\n\n## [`llama-cli`](tools/cli)\n\n#### A CLI tool for accessing and experimenting with most of `llama.cpp`'s functionality.\n\n- <details open>\n    <summary>Run in conversation mode</summary>\n\n    Models with a built-in chat template will automatically activate conversation mode. If this doesn't occur, you can manually enable it by adding `-cnv` and specifying a suitable chat template with `--chat-template NAME`\n\n    ```bash\n    llama-cli -m model.gguf\n\n    # > hi, who are you?\n    # Hi there! I'm your helpful assistant! I'm an AI-powered chatbot designed to assist and provide information to users like you. I'm here to help answer your questions, provide guidance, and offer support on a wide range of topics. I'm a friendly and knowledgeable AI, and I'm always happy to help with anything you need. What's on your mind, and how can I assist you today?\n    #\n    # > what is 1+1?\n    # Easy peasy! The answer to 1+1 is... 2!\n    ```\n\n    </details>\n\n- <details>\n    <summary>Run in conversation mode with custom chat template</summary>\n\n    ```bash\n    # use the \"chatml\" template (use -h to see the list of supported templates)\n    llama-cli -m model.gguf -cnv --chat-template chatml\n\n    # use a custom template\n    llama-cli -m model.gguf -cnv --in-prefix 'User: ' --reverse-prompt 'User:'\n    ```\n\n    </details>\n\n- <details>\n    <summary>Constrain the output with a custom grammar</summary>\n\n    ```bash\n    llama-cli -m model.gguf -n 256 --grammar-file grammars/json.gbnf -p 'Request: schedule a call at 8pm; Command:'\n\n    # {\"appointmentTime\": \"8pm\", \"appointmentDetails\": \"schedule a a call\"}\n    ```\n\n    The [grammars/](grammars/) folder contains a handful of sample grammars. To write your own, check out the [GBNF Guide](grammars/README.md).\n\n    For authoring more complex JSON grammars, check out https://grammar.intrinsiclabs.ai/\n\n    </details>\n\n\n## [`llama-server`](tools/server)\n\n#### A lightweight, [OpenAI API](https://github.com/openai/openai-openapi) compatible, HTTP server for serving LLMs.\n\n- <details open>\n    <summary>Start a local HTTP server with default configuration on port 8080</summary>\n\n    ```bash\n    llama-server -m model.gguf --port 8080\n\n    # Basic web UI can be accessed via browser: http://localhost:8080\n    # Chat completion endpoint: http://localhost:8080/v1/chat/completions\n    ```\n\n    </details>\n\n- <details>\n    <summary>Support multiple-users and parallel decoding</summary>\n\n    ```bash\n    # up to 4 concurrent requests, each with 4096 max context\n    llama-server -m model.gguf -c 16384 -np 4\n    ```\n\n    </details>\n\n- <details>\n    <summary>Enable speculative decoding</summary>\n\n    ```bash\n    # the draft.gguf model should be a small variant of the target model.gguf\n    llama-server -m model.gguf -md draft.gguf\n    ```\n\n    </details>\n\n- <details>\n    <summary>Serve an embedding model</summary>\n\n    ```bash\n    # use the /embedding endpoint\n    llama-server -m model.gguf --embedding --pooling cls -ub 8192\n    ```\n\n    </details>\n\n- <details>\n    <summary>Serve a reranking model</summary>\n\n    ```bash\n    # use the /reranking endpoint\n    llama-server -m model.gguf --reranking\n    ```\n\n    </details>\n\n- <details>\n    <summary>Constrain all outputs with a grammar</summary>\n\n    ```bash\n    # custom grammar\n    llama-server -m model.gguf --grammar-file grammar.gbnf\n\n    # JSON\n    llama-server -m model.gguf --grammar-file grammars/json.gbnf\n    ```\n\n    </details>\n\n\n## [`llama-perplexity`](tools/perplexity)\n\n#### A tool for measuring the [perplexity](tools/perplexity/README.md) [^1] (and other quality metrics) of a model over a given text.\n\n- <details open>\n    <summary>Measure the perplexity over a text file</summary>\n\n    ```bash\n    llama-perplexity -m model.gguf -f file.txt\n\n    # [1]15.2701,[2]5.4007,[3]5.3073,[4]6.2965,[5]5.8940,[6]5.6096,[7]5.7942,[8]4.9297, ...\n    # Final estimate: PPL = 5.4007 +/- 0.67339\n    ```\n\n    </details>\n\n- <details>\n    <summary>Measure KL divergence</summary>\n\n    ```bash\n    # TODO\n    ```\n\n    </details>\n\n[^1]: [https://huggingface.co/docs/transformers/perplexity](https://huggingface.co/docs/transformers/perplexity)\n\n## [`llama-bench`](tools/llama-bench)\n\n#### Benchmark the performance of the inference for various parameters.\n\n- <details open>\n    <summary>Run default benchmark</summary>\n\n    ```bash\n    llama-bench -m model.gguf\n\n    # Output:\n    # | model               |       size |     params | backend    | threads |          test |                  t/s |\n    # | ------------------- | ---------: | ---------: | ---------- | ------: | ------------: | -------------------: |\n    # | qwen2 1.5B Q4_0     | 885.97 MiB |     1.54 B | Metal,BLAS |      16 |         pp512 |      5765.41 Â± 20.55 |\n    # | qwen2 1.5B Q4_0     | 885.97 MiB |     1.54 B | Metal,BLAS |      16 |         tg128 |        197.71 Â± 0.81 |\n    #\n    # build: 3e0ba0e60 (4229)\n    ```\n\n    </details>\n\n## [`llama-simple`](examples/simple)\n\n#### A minimal example for implementing apps with `llama.cpp`. Useful for developers.\n\n- <details>\n    <summary>Basic text completion</summary>\n\n    ```bash\n    llama-simple -m model.gguf\n\n    # Hello my name is Kaitlyn and I am a 16 year old girl. I am a junior in high school and I am currently taking a class called \"The Art of\n    ```\n\n    </details>\n\n\n## Contributing\n\n- Contributors can open PRs\n- Collaborators will be invited based on contributions\n- Maintainers can push to branches in the `llama.cpp` repo and merge PRs into the `master` branch\n- Any help with managing issues, PRs and projects is very appreciated!\n- See [good first issues](https://github.com/ggml-org/llama.cpp/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) for tasks suitable for first contributions\n- Read the [CONTRIBUTING.md](CONTRIBUTING.md) for more information\n- Make sure to read this: [Inference at the edge](https://github.com/ggml-org/llama.cpp/discussions/205)\n- A bit of backstory for those who are interested: [Changelog podcast](https://changelog.com/podcast/532)\n\n## Other documentation\n\n- [cli](tools/cli/README.md)\n- [completion](tools/completion/README.md)\n- [server](tools/server/README.md)\n- [GBNF grammars](grammars/README.md)\n\n#### Development documentation\n\n- [How to build](docs/build.md)\n- [Running on Docker](docs/docker.md)\n- [Build on Android](docs/android.md)\n- [Performance troubleshooting](docs/development/token_generation_performance_tips.md)\n- [GGML tips & tricks](https://github.com/ggml-org/llama.cpp/wiki/GGML-Tips-&-Tricks)\n\n#### Seminal papers and background on the models\n\nIf your issue is with model generation quality, then please at least scan the following links and papers to understand the limitations of LLaMA models. This is especially important when choosing an appropriate model size and appreciating both the significant and subtle differences between LLaMA models and ChatGPT:\n- LLaMA:\n    - [Introducing LLaMA: A foundational, 65-billion-parameter large language model](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)\n    - [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971)\n- GPT-3\n    - [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)\n- GPT-3.5 / InstructGPT / ChatGPT:\n    - [Aligning language models to follow instructions](https://openai.com/research/instruction-following)\n    - [Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155)\n\n## XCFramework\nThe XCFramework is a precompiled version of the library for iOS, visionOS, tvOS,\nand macOS. It can be used in Swift projects without the need to compile the\nlibrary from source. For example:\n```swift\n// swift-tools-version: 5.10\n// The swift-tools-version declares the minimum version of Swift required to build this package.\n\nimport PackageDescription\n\nlet package = Package(\n    name: \"MyLlamaPackage\",\n    targets: [\n        .executableTarget(\n            name: \"MyLlamaPackage\",\n            dependencies: [\n                \"LlamaFramework\"\n            ]),\n        .binaryTarget(\n            name: \"LlamaFramework\",\n            url: \"https://github.com/ggml-org/llama.cpp/releases/download/b5046/llama-b5046-xcframework.zip\",\n            checksum: \"c19be78b5f00d8d29a25da41042cb7afa094cbf6280a225abe614b03b20029ab\"\n        )\n    ]\n)\n```\nThe above example is using an intermediate build `b5046` of the library. This can be modified\nto use a different version by changing the URL and checksum.\n\n## Completions\nCommand-line completion is available for some environments.\n\n#### Bash Completion\n```bash\n$ build/bin/llama-cli --completion-bash > ~/.llama-completion.bash\n$ source ~/.llama-completion.bash\n```\nOptionally this can be added to your `.bashrc` or `.bash_profile` to load it\nautomatically. For example:\n```console\n$ echo \"source ~/.llama-completion.bash\" >> ~/.bashrc\n```\n\n## Dependencies\n\n- [yhirose/cpp-httplib](https://github.com/yhirose/cpp-httplib) - Single-header HTTP server, used by `llama-server` - MIT license\n- [stb-image](https://github.com/nothings/stb) - Single-header image format decoder, used by multimodal subsystem - Public domain\n- [nlohmann/json](https://github.com/nlohmann/json) - Single-header JSON library, used by various tools/examples - MIT License\n- [miniaudio.h](https://github.com/mackron/miniaudio) - Single-header audio format decoder, used by multimodal subsystem - Public domain\n- [subprocess.h](https://github.com/sheredom/subprocess.h) - Single-header process launching solution for C and C++ - Public domain\n",
      "stars_today": 85
    },
    {
      "id": 709242076,
      "name": "gofr",
      "full_name": "gofr-dev/gofr",
      "description": "An opinionated GoLang framework for accelerated microservice development. Built in support for databases and observability.",
      "html_url": "https://github.com/gofr-dev/gofr",
      "stars": 15955,
      "forks": 1740,
      "language": "Go",
      "topics": [
        "framework",
        "go",
        "go-framework",
        "golang",
        "golang-framework",
        "grpc",
        "grpc-go",
        "grpc-golang",
        "hacktoberfest",
        "http-server",
        "logging",
        "metrics",
        "microservice",
        "microservice-framework",
        "opentelemetry",
        "performance",
        "rest-api",
        "server",
        "tracing",
        "web-framework"
      ],
      "created_at": "2023-10-24T10:14:48Z",
      "updated_at": "2026-02-07T02:07:50Z",
      "pushed_at": "2026-02-06T11:20:14Z",
      "open_issues": 89,
      "owner": {
        "login": "gofr-dev",
        "avatar_url": "https://avatars.githubusercontent.com/u/146108433?v=4"
      },
      "readme": "<div align=\"center\">\n<h1 style=\"font-size: 100px; font-weight: 500;\">\n    <i>Go</i>Fr\n</h1>\n<div align=\"center\">\n<p>\n<img width=\"300\" alt=\"logo\" src=\"https://github.com/gofr-dev/gofr/assets/44036979/916fe7b1-42fb-4af1-9e0b-4a7a064c243c\">\n<h2 style=\"font-size: 28px;\"><b>GoFr: An Opinionated Microservice Development Framework</b></h2>\n</p>\n<a href=\"https://pkg.go.dev/gofr.dev\"><img src=\"https://img.shields.io/badge/GoDoc-Read%20Documentation-blue?style=for-the-badge\" alt=\"godoc\"></a>\n<a href=\"https://gofr.dev/docs\"><img src=\"https://img.shields.io/badge/GoFr-Docs-orange?style=for-the-badge\" alt=\"gofr-docs\"></a>\n<a href=\"https://qlty.sh/gh/gofr-dev/projects/gofr\"><img src=\"https://qlty.sh/gh/gofr-dev/projects/gofr/maintainability.svg\" alt=\"Maintainability\" height=\"27.99\" /></a>\n<a href=\"https://qlty.sh/gh/gofr-dev/projects/gofr\"><img src=\"https://qlty.sh/gh/gofr-dev/projects/gofr/coverage.svg\" alt=\"Code Coverage\" height=\"27.99\" /></a>\n<a href=\"https://goreportcard.com/report/gofr.dev\"><img src=\"https://goreportcard.com/badge/gofr.dev?style=for-the-badge\" alt=\"Go Report Card\"></a>\n<a href=\"https://opensource.org/licenses/Apache-2.0\"><img src=\"https://img.shields.io/badge/License-Apache_2.0-blue?style=for-the-badge\" alt=\"Apache 2.0 License\"></a>\n<a href=\"https://discord.gg/wsaSkQTdgq\"><img src=\"https://img.shields.io/badge/discord-join-us?style=for-the-badge&logo=discord&color=7289DA\" alt=\"discord\" /></a>\n<a href=\"https://gurubase.io/g/gofr\"><img src=\"https://img.shields.io/badge/Gurubase-Ask%20GoFr%20Guru-006BFF?style=for-the-badge\" /></a>\n</div>\n<h2>Listed in the <a href=\"https://landscape.cncf.io/?selected=go-fr\">CNCF Landscape</a></h2>\n</div>\n\n## ğŸ¯ **Goal**\nGoFr is designed to **simplify microservice development**, with key focuses on **Kubernetes deployment** and **out-of-the-box observability**. While capable of building generic applications, **microservices** remain at its core.\n\n---\n\n## ğŸ’¡ **Key Features**\n\n1. **Simple API Syntax**\n2. **REST Standards by Default**\n3. **Configuration Management**\n4. **[Observability](https://gofr.dev/docs/quick-start/observability)** (Logs, Traces, Metrics)\n5. **Inbuilt [Auth Middleware](https://gofr.dev/docs/advanced-guide/http-authentication)** & Custom Middleware Support\n6. **[gRPC Support](https://gofr.dev/docs/advanced-guide/grpc)**\n7. **[HTTP Service](https://gofr.dev/docs/advanced-guide/http-communication)** with Circuit Breaker Support\n8. **[Pub/Sub](https://gofr.dev/docs/advanced-guide/using-publisher-subscriber)**\n9. **[Health Check](https://gofr.dev/docs/advanced-guide/monitoring-service-health)** for All Datasources\n10. **[Database Migration](https://gofr.dev/docs/advanced-guide/handling-data-migrations)**\n11. **[Cron Jobs](https://gofr.dev/docs/advanced-guide/using-cron)**\n12. **Support for [Changing Log Level](https://gofr.dev/docs/advanced-guide/remote-log-level-change) Without Restarting**\n13. **[Swagger Rendering](https://gofr.dev/docs/advanced-guide/swagger-documentation)**\n14. **[Abstracted File Systems](https://gofr.dev/docs/advanced-guide/handling-file)**\n15. **[Websockets](https://gofr.dev/docs/advanced-guide/websocket)**\n\n---\n\n## ğŸš€ **Getting Started**\n\n### **Prerequisites**\n- GoFr requires **[Go](https://go.dev/)** version **[1.24](https://go.dev/doc/devel/release#go1.24.0)** or above.\n\n### **Installation**\nTo get started with GoFr, add the following import to your code and use Goâ€™s module support to automatically fetch dependencies:\n\n```go\nimport \"gofr.dev/pkg/gofr\"\n```\n\nAlternatively, use the command:\n\n```bash\ngo get -u gofr.dev/pkg/gofr\n```\n\n---\n\n## ğŸƒ **Running GoFr**\n\nHere's a simple example to get a GoFr application up and running:\n\n```go\npackage main\n\nimport \"gofr.dev/pkg/gofr\"\n\nfunc main() {\n\tapp := gofr.New()\n\n\tapp.GET(\"/greet\", func(ctx *gofr.Context) (any, error) {\n\t\treturn \"Hello World!\", nil\n\t})\n\n\tapp.Run() // listens and serves on localhost:8000\n}\n```\n\nTo run this code:\n\n```bash\n$ go run main.go\n```\n\nVisit [`localhost:8000/greet`](http://localhost:8000/greet) to see the result.\n\n---\n\n## ğŸ“‚ **More Examples**\n\nExplore a variety of ready-to-run examples in the [GoFr examples directory](https://github.com/gofr-dev/gofr/tree/development/examples).\n\n---\n\n## ğŸ‘©â€ğŸ’» **Documentation**\n\n- **[GoDoc](https://pkg.go.dev/gofr.dev)**: Official API documentation.\n- **[GoFr Documentation](https://gofr.dev/docs)**: Comprehensive guides and resources.\n\n---\n\n## ğŸ‘ **Contribute**\n\nJoin Us in Making GoFr Better\n\n**Share your experience**: If youâ€™ve found GoFr helpful, consider writing a review or tutorial on platforms like **[Medium](https://medium.com/)**, **[Dev.to](https://dev.to/)**, or your personal blog. \nYour insights could help others get started faster!\n\n**Contribute to the project**: Want to get involved? Check out our **[CONTRIBUTING.md](CONTRIBUTING.md)**\nguide to learn how you can contribute code, suggest improvements, or report issues.\n\n---\n\n## ğŸ”’ **Secure Cloning**\nTo securely clone the GoFr repository, you can use HTTPS or SSH:\n\n### Cloning with HTTPS\n```bash\ngit clone https://github.com/gofr-dev/gofr.git\n```\n### Cloning with SSH\n```bash\ngit clone git@github.com:gofr-dev/gofr.git\n```\n\n### ğŸ **Get a GoFr T-Shirt & Stickers!**\n\nIf your PR is merged, or if you contribute by writing articles or promoting GoFr, we invite you to fill out [this form](https://forms.gle/R1Yz7ZzY3U5WWTgy5) to claim your GoFr merchandise as a token of our appreciation! \n\n### Partners\n\n<img src=\"https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.png\" alt=\"JetBrains logo\" width=\"200\">\n",
      "stars_today": 82
    },
    {
      "id": 1034918094,
      "name": "zerobyte",
      "full_name": "nicotsx/zerobyte",
      "description": "Backup automation for self-hosters. Built on top of restic",
      "html_url": "https://github.com/nicotsx/zerobyte",
      "stars": 5433,
      "forks": 134,
      "language": "TypeScript",
      "topics": [],
      "created_at": "2025-08-09T08:58:56Z",
      "updated_at": "2026-02-07T02:19:44Z",
      "pushed_at": "2026-02-06T21:38:21Z",
      "open_issues": 79,
      "owner": {
        "login": "nicotsx",
        "avatar_url": "https://avatars.githubusercontent.com/u/47644445?v=4"
      },
      "readme": "<div align=\"center\">\n  <h1>Zerobyte</h1>\n  <h3>Powerful backup automation for your remote storage<br />Encrypt, compress, and protect your data with ease</h3>\n  <a href=\"https://github.com/nicotsx/zerobyte/blob/main/LICENSE\">\n    <img src=\"https://img.shields.io/github/license/nicotsx/zerobyte\" />\n  </a>\n  <br />\n  <figure>\n    <img src=\"https://github.com/nicotsx/zerobyte/blob/main/screenshots/backup-details.webp?raw=true\" alt=\"Demo\" />\n    <figcaption>\n      <p align=\"center\">\n        Backup management with scheduling and monitoring\n      </p>\n    </figcaption>\n  </figure>\n</div>\n\n> [!WARNING]\n> Zerobyte is still in version 0.x.x and is subject to major changes from version to version. I am developing the core features and collecting feedbacks. Expect bugs! Please open issues or feature requests\n\n<p align=\"center\">\n<a href=\"https://www.buymeacoffee.com/nicotsx\" target=\"_blank\"><img src=\"https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png\" alt=\"Buy Me A Coffee\" style=\"height: 60px !important;width: 217px !important;\" ></a>\n</p>\n\n## Intro\n\nZerobyte is a backup automation tool that helps you save your data across multiple storage backends. Built on top of Restic, it provides an modern web interface to schedule, manage, and monitor encrypted backups of your remote storage.\n\n### Features\n\n- &nbsp; **Automated backups** with encryption, compression and retention policies powered by Restic\n- &nbsp; **Flexible scheduling** For automated backup jobs with fine-grained retention policies\n- &nbsp; **End-to-end encryption** ensuring your data is always protected\n- &nbsp; **Multi-protocol support**: Backup from NFS, SMB, WebDAV, SFTP, or local directories\n\n## Installation\n\nIn order to run Zerobyte, you need to have Docker and Docker Compose installed on your server. Then, you can use the provided `docker-compose.yml` file to start the application.\n\n```yaml\nservices:\n  zerobyte:\n    image: ghcr.io/nicotsx/zerobyte:v0.25\n    container_name: zerobyte\n    restart: unless-stopped\n    cap_add:\n      - SYS_ADMIN\n    ports:\n      - \"4096:4096\"\n    devices:\n      - /dev/fuse:/dev/fuse\n    environment:\n      - TZ=Europe/Paris # Set your timezone here\n      - BASE_URL=http://localhost:4096 # URL you will use to access Zerobyte\n      - APP_SECRET=94bad46...c66e25d5c2b # Generate your own secret with `openssl rand -hex 32`\n    volumes:\n      - /etc/localtime:/etc/localtime:ro\n      - /var/lib/zerobyte:/var/lib/zerobyte\n```\n\n> [!WARNING]\n> It is highly discouraged to run Zerobyte on a server that is accessible from the internet (VPS or home server with port forwarding) If you do, make sure to change the port mapping to \"127.0.0.1:4096:4096\" and use a secure tunnel (SSH tunnel, Cloudflare Tunnel, etc.) with authentication.\n\n> [!WARNING]\n> Do not try to point `/var/lib/zerobyte` on a network share. You will face permission issues and strong performance degradation.\n\n> [!NOTE]\n> **TrueNAS Users:** The host path `/var/lib` is ephemeral on TrueNAS and will be reset during system upgrades. Instead of using `/var/lib/zerobyte:/var/lib/zerobyte`, create a dedicated ZFS dataset (e.g., `tank/docker/zerobyte`) and mount it instead:\n>\n> ```yaml\n> volumes:\n>   - /etc/localtime:/etc/localtime:ro\n>   - /mnt/tank/docker/zerobyte:/var/lib/zerobyte\n> ```\n>\n> This ensures your configuration, encryption keys, and database persist across TrueNAS upgrades.\n\nThen, run the following command to start Zerobyte:\n\n```bash\ndocker compose up -d\n```\n\nOnce the container is running, you can access the web interface at `http://<your-server-ip>:4096`.\n\n## Configuration\n\nZerobyte can be customized using environment variables. Below are the available options:\n\n### Environment Variables\n\n| Variable              | Description                                                                                                                               | Default                |\n| :-------------------- | :---------------------------------------------------------------------------------------------------------------------------------------- | :--------------------- |\n| `BASE_URL`            | **Required.** The base URL of your Zerobyte instance (e.g., `https://zerobyte.example.com`). See [Authentication](#authentication) below. | (none)                 |\n| `APP_SECRET`          | **Required.** A random secret key (32+ chars) used to encrypt sensitive data in the database. Generate with `openssl rand -hex 32`.       | (none)                 |\n| `PORT`                | The port the web interface and API will listen on.                                                                                        | `4096`                 |\n| `RESTIC_HOSTNAME`     | The hostname used by Restic when creating snapshots. Automatically detected if a custom hostname is set in Docker.                        | `zerobyte`             |\n| `TZ`                  | Timezone for the container (e.g., `Europe/Paris`). **Crucial for accurate backup scheduling.**                                            | `UTC`                  |\n| `TRUSTED_ORIGINS`     | Comma-separated list of extra trusted origins for CORS (e.g., `http://localhost:3000,http://example.com`).                                | (none)                 |\n| `LOG_LEVEL`           | Logging verbosity. Options: `debug`, `info`, `warn`, `error`.                                                                             | `info`                 |\n| `SERVER_IDLE_TIMEOUT` | Idle timeout for the server in seconds.                                                                                                   | `60`                   |\n| `RCLONE_CONFIG_DIR`   | Path to the rclone config directory inside the container. Change this if running as a non-root user.                                      | `/root/.config/rclone` |\n\n### Secret References\n\nFor enhanced security, Zerobyte supports dynamic secret resolution for sensitive fields (like passwords, access keys, etc.) in volume and repository configurations. Instead of storing the encrypted secret in the database, you can use one of the following prefixes:\n\n- `env://VAR_NAME`: Reads the secret from the environment variable `VAR_NAME`.\n- `file://SECRET_NAME`: Reads the secret from `/run/secrets/SECRET_NAME` (standard Docker Secrets path).\n\n**Example:**\nWhen configuring an S3 repository, you can set the Secret Access Key to `env://S3_SECRET_KEY` and then provide that variable in your `docker-compose.yml`.\n\n### Simplified setup (No remote mounts)\n\nIf you only need to back up locally mounted folders and don't require remote share mounting capabilities, you can remove the `SYS_ADMIN` capability and FUSE device from your `docker-compose.yml`:\n\n```yaml\nservices:\n  zerobyte:\n    image: ghcr.io/nicotsx/zerobyte:v0.25\n    container_name: zerobyte\n    restart: unless-stopped\n    ports:\n      - \"4096:4096\"\n    environment:\n      - TZ=Europe/Paris # Set your timezone here\n      - BASE_URL=http://localhost:4096 # Change this to your actual URL (use https:// for secure cookies)\n      - APP_SECRET=94bad46...c66e25d5c2b # Generate your own secret with `openssl rand -hex 32`\n    volumes:\n      - /etc/localtime:/etc/localtime:ro\n      - /var/lib/zerobyte:/var/lib/zerobyte\n      - /path/to/your/directory:/mydata\n```\n\n**Trade-offs:**\n\n- âœ… Improved security by reducing container capabilities\n- âœ… Support for local directories\n- âœ… Keep support all repository types (local, S3, GCS, Azure, rclone)\n- âŒ Cannot mount NFS, SMB, WebDAV, or SFTP shares directly from Zerobyte\n\nIf you need remote mount capabilities, keep the original configuration with `cap_add: SYS_ADMIN` and `devices: /dev/fuse:/dev/fuse`.\n\n## Examples\n\nSee [examples/README.md](examples/README.md) for runnable, copy/paste-friendly examples.\n\n## Adding your first volume\n\nZerobyte supports multiple volume backends including NFS, SMB, WebDAV, SFTP, and local directories. A volume represents the source data you want to back up and monitor.\n\nTo add your first volume, navigate to the \"Volumes\" section in the web interface and click on \"Create volume\". Fill in the required details such as volume name, type, and connection settings.\n\nIf you want to track a local directory on the same server where Zerobyte is running, you'll first need to mount that directory into the Zerobyte container. You can do this by adding a volume mapping in your `docker-compose.yml` file. For example, to mount `/path/to/your/directory` from the host to `/mydata` in the container, you would add the following line under the `volumes` section:\n\n```diff\nservices:\n  zerobyte:\n    image: ghcr.io/nicotsx/zerobyte:v0.25\n    container_name: zerobyte\n    restart: unless-stopped\n    cap_add:\n      - SYS_ADMIN\n    ports:\n      - \"4096:4096\"\n    devices:\n      - /dev/fuse:/dev/fuse\n    environment:\n      - TZ=Europe/Paris\n      - BASE_URL=http://localhost:4096 # URL you will use to access Zerobyte\n      - APP_SECRET=94bad46...c66e25d5c2b # Generate your own secret with `openssl rand -hex 32`\n    volumes:\n      - /etc/localtime:/etc/localtime:ro\n      - /var/lib/zerobyte:/var/lib/zerobyte\n+     - /path/to/your/directory:/mydata\n```\n\nAfter updating the `docker-compose.yml` file, restart the Zerobyte container to apply the changes:\n\n```bash\ndocker compose down\ndocker compose up -d\n```\n\nNow, when adding a new volume in the Zerobyte web interface, you can select \"Directory\" as the volume type and search for your mounted path (e.g., `/mydata`) as the source path.\n\n![Preview](https://github.com/nicotsx/zerobyte/blob/main/screenshots/add-volume.png?raw=true)\n\n## Creating a repository\n\nA repository is where your backups will be securely stored encrypted. Zerobyte supports multiple storage backends for your backup repositories:\n\n- **Local directories** - Store backups on local disk subfolder of `/var/lib/zerobyte/repositories/` or any other (mounted) path\n- **S3-compatible storage** - Amazon S3, MinIO, Wasabi, DigitalOcean Spaces, etc.\n- **Google Cloud Storage** - Google's cloud storage service\n- **Azure Blob Storage** - Microsoft Azure storage\n- **rclone remotes** - 40+ cloud storage providers via rclone (see below)\n\nRepositories are optimized for storage efficiency and data integrity, leveraging Restic's deduplication and encryption features.\n\nTo create a repository, navigate to the \"Repositories\" section in the web interface and click on \"Create repository\". Fill in the required details such as repository name, type, and connection settings.\n\n### Using rclone for cloud storage\n\nZerobyte can use [rclone](https://rclone.org/) to support 40+ cloud storage providers including Google Drive, Dropbox, OneDrive, Box, pCloud, Mega, and many more. This gives you the flexibility to store your backups on virtually any cloud storage service.\n\n**Setup instructions:**\n\n1. **Install rclone on your host system** (if not already installed):\n\n   ```bash\n   curl https://rclone.org/install.sh | sudo bash\n   ```\n\n2. **Configure your cloud storage remote** using rclone's interactive config:\n\n   ```bash\n   rclone config\n   ```\n\n   Follow the prompts to set up your cloud storage provider. For OAuth providers (Google Drive, Dropbox, etc.), rclone will guide you through the authentication flow.\n\n3. **Verify your remote is configured**:\n\n   ```bash\n   rclone listremotes\n   ```\n\n4. **Mount the rclone config into the Zerobyte container** by updating your `docker-compose.yml`:\n\n   ```diff\n   services:\n     zerobyte:\n       image: ghcr.io/nicotsx/zerobyte:v0.25\n       container_name: zerobyte\n       restart: unless-stopped\n       cap_add:\n         - SYS_ADMIN\n       ports:\n         - \"4096:4096\"\n       devices:\n         - /dev/fuse:/dev/fuse\n       environment:\n         - TZ=Europe/Paris\n         - BASE_URL=http://localhost:4096 # URL you will use to access Zerobyte\n       volumes:\n         - /etc/localtime:/etc/localtime:ro\n         - /var/lib/zerobyte:/var/lib/zerobyte\n   +     - ~/.config/rclone:/root/.config/rclone:ro\n   ```\n\n   > **Note for non-root users:** If your container runs as a different user (e.g., TrueNAS apps), mount your config to the appropriate location and set `RCLONE_CONF_DIR`:\n   >\n   > ```yaml\n   > environment:\n   >   - RCLONE_CONFIG_DIR=/home/appuser/.config/rclone\n   > volumes:\n   >   - ~/.config/rclone:/home/appuser/.config/rclone:ro\n   > ```\n\n5. **Restart the Zerobyte container**:\n\n   ```bash\n   docker compose down\n   docker compose up -d\n   ```\n\n6. **Create a repository** in Zerobyte:\n   - Select \"rclone\" as the repository type\n   - Choose your configured remote from the dropdown\n   - Specify the path within your remote (e.g., `backups/zerobyte`)\n\nFor a complete list of supported providers, see the [rclone documentation](https://rclone.org/).\n\n## Your first backup job\n\nOnce you have added a volume and created a repository, you can create your first backup job. A backup job defines the schedule and parameters for backing up a specific volume to a designated repository.\n\nWhen creating a backup job, you can specify the following settings:\n\n- **Schedule**: Define how often the backup should run (e.g., daily, weekly)\n- **Retention Policy**: Set rules for how long backups should be retained (e.g., keep daily backups for 7 days, weekly backups for 4 weeks)\n- **Paths**: Specify which files or directories to include in the backup\n\nAfter configuring the backup job, save it and Zerobyte will automatically execute the backup according to the defined schedule.\nYou can monitor the progress and status of your backup jobs in the \"Backups\" section of the web interface.\n\n![Preview](https://github.com/nicotsx/zerobyte/blob/main/screenshots/backups-list.png?raw=true)\n\n## Restoring data\n\nZerobyte allows you to easily restore your data from backups. To restore data, navigate to the \"Backups\" section and select the backup job from which you want to restore data. You can then choose a specific backup snapshot and select the files or directories you wish to restore. The data you select will be restored to their original location.\n\n![Preview](https://github.com/nicotsx/zerobyte/blob/main/screenshots/restoring.png?raw=true)\n\n## Authentication\n\nZerobyte uses [better-auth](https://github.com/better-auth/better-auth) for authentication and session management. The authentication system automatically adapts to your deployment scenario:\n\n### Cookie Security\n\n- **IP Address / HTTP access**: Set `BASE_URL=http://192.168.1.50:4096` (or your IP). Cookies will use `Secure: false`, allowing immediate login without SSL.\n- **Domain / HTTPS access**: Set `BASE_URL=https://zerobyte.example.com`. Cookies will automatically use `Secure: true` for protected sessions.\n\n### Reverse Proxy Setup\n\nIf you're running Zerobyte behind a reverse proxy (Nginx, Traefik, Caddy, etc.):\n\n1. **Set `BASE_URL`** to your HTTPS domain (e.g., `https://zerobyte.example.com`)\n2. The app will automatically enable secure cookies based on the `https://` prefix\n3. Ensure your proxy passes the `X-Forwarded-Proto` header\n\n### Important Notes\n\n- The `BASE_URL` must start with `https://` for secure cookies to be enabled\n- Local IP addresses (e.g., `http://192.168.x.x`) are **not** treated as secure contexts by browsers, so secure cookies are disabled automatically\n\n## Troubleshooting\n\nFor troubleshooting common issues, please refer to the [TROUBLESHOOTING.md](TROUBLESHOOTING.md) file.\n\n## Third-Party Software\n\nThis project includes the following third-party software components:\n\n### Restic\n\nZerobyte includes [Restic](https://github.com/restic/restic) for backup functionality.\n\n- **License**: BSD 2-Clause License\n- **Copyright**: Copyright (c) 2014, Alexander Neumann <alexander@bumpern.de>\n- **Status**: Included unchanged\n- **License Text**: See [LICENSES/BSD-2-Clause-Restic.txt](LICENSES/BSD-2-Clause-Restic.txt)\n\nFor a complete list of third-party software licenses and attributions, please refer to the [NOTICES.md](NOTICES.md) file.\n\n## Contributing\n\nContributions by anyone are welcome! If you find a bug or have a feature request, please open an issue on GitHub. If you want to contribute code, feel free to fork the repository and submit a pull request. We require that all contributors sign a Contributor License Agreement (CLA) before we can accept your contributions. This is to protect both you and the project. Please see the [CONTRIBUTING.md](CONTRIBUTING.md) file for more details.\n\n## Development (no Docker)\n\nYou can run Zerobyte locally during development without Docker:\n\n```bash\nbun install\nbun run dev\n```\n\nFor local development, create a `.env.local` file at the repo root and override the Docker paths:\n\n```bash\n# Example\nDATABASE_URL=./data/zerobyte.db\nAPP_SECRET=your_app_secret_here\nRESTIC_PASS_FILE=./data/restic.pass\nRESTIC_CACHE_DIR=./data/restic/cache\nZEROBYTE_REPOSITORIES_DIR=./data/repositories\nZEROBYTE_VOLUMES_DIR=./data/volumes\nBASE_URL=http://localhost:4096\n```\n\nNotes:\n\n- Remote mount backends (NFS/SMB/WebDAV/SFTP) rely on Linux mount tooling and `CAP_SYS_ADMIN`; on macOS they are expected to be unavailable.\n- To actually run backups/repository checks, install `restic` on your machine (e.g. via Homebrew). If `restic` is not installed, the app still starts but backup operations will fail with a clear error.\n",
      "stars_today": 80
    },
    {
      "id": 911303109,
      "name": "motia",
      "full_name": "MotiaDev/motia",
      "description": "Multi-Language Backend Framework that unifies APIs, background jobs, queues, workflows, streams, and AI agents with a single core primitive with built-in observability and state management.",
      "html_url": "https://github.com/MotiaDev/motia",
      "stars": 14914,
      "forks": 995,
      "language": "TypeScript",
      "topics": [
        "agents",
        "ai",
        "api",
        "backend",
        "developer-tools",
        "framework",
        "genai",
        "javascript",
        "python",
        "typescript"
      ],
      "created_at": "2025-01-02T17:45:02Z",
      "updated_at": "2026-02-07T01:32:31Z",
      "pushed_at": "2026-02-05T22:51:24Z",
      "open_issues": 74,
      "owner": {
        "login": "MotiaDev",
        "avatar_url": "https://avatars.githubusercontent.com/u/193029780?v=4"
      },
      "readme": "> [!IMPORTANT]\n> ğŸš€ **A brand new engine is coming to Motia that will supercharge its speed & scalability.**\n> \n> **[ğŸ“¬ Signup to be the first to get notified when it's released](https://forms.gle/24iCHL9yAk1i6LDc6) â†’ https://forms.gle/24iCHL9yAk1i6LDc6**\n>\n> **It's almost ready!**\n\n<a href=\"https://motia.dev\">\n  <img src=\"assets/github-readme-banner.png\" alt=\"Motia Banner\" width=\"100%\">\n</a>\n\n<p align=\"center\">\n  <a href=\"https://trendshift.io/repositories/14032\" style=\"margin-right:8px;\">\n    <img src=\"https://trendshift.io/api/badge/repositories/14032\" alt=\"Motia\" style=\"width: 250px; height: 55px; margin-right:8px;\" width=\"250\" height=\"55\"/>\n  </a>\n  <a href=\"https://vercel.com/blog/summer-2025-oss-program#motia\" target=\"_blank\" style=\"margin-left:8px;\">\n    <img alt=\"Vercel OSS Program\" src=\"https://vercel.com/oss/program-badge.svg\" style=\"width: 250px; height: 55px; margin-left:8px;\" width=\"250\" height=\"55\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  <strong>ğŸ”¥ The Unified Backend Framework That Eliminates Runtime Fragmentation ğŸ”¥</strong>\n</p>\n<p align=\"center\">\n  <em>APIs, background jobs, queueing, streaming, states, workflows, AI agents, observability, scaling, and deployment all in one system. JavaScript, TypeScript, Python, and more in a single core primitive</em>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://www.npmjs.com/package/motia\">\n    <img src=\"https://img.shields.io/npm/v/motia?style=flat&logo=npm&logoColor=white&color=CB3837&labelColor=000000\" alt=\"npm version\">\n  </a>\n  <a href=\"https://github.com/MotiaDev/motia/blob/main/LICENSE\">\n    <img src=\"https://img.shields.io/badge/license-ELv2-blue?style=flat&logo=opensourceinitiative&logoColor=white&labelColor=000000\" alt=\"license\">\n  </a>\n  <a href=\"https://github.com/MotiaDev/motia\">\n    <img src=\"https://img.shields.io/github/stars/MotiaDev/motia?style=flat&logo=github&logoColor=white&color=yellow&labelColor=000000\" alt=\"GitHub stars\">\n  </a>\n  <a href=\"https://twitter.com/motiadev\" target=\"_blank\">\n    <img src=\"https://img.shields.io/badge/Follow-@motiadev-1DA1F2?style=flat&logo=twitter&logoColor=white&labelColor=000000\" alt=\"Twitter Follow\">\n  </a>\n  <a href=\"https://discord.gg/motia\" target=\"_blank\">\n    <img src=\"https://img.shields.io/discord/1322278831184281721?style=flat&logo=discord&logoColor=white&color=5865F2&label=Discord&labelColor=000000\" alt=\"Discord\">\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://www.motia.dev/manifesto\">ğŸ’¡ Motia Manifesto</a> â€¢\n  <a href=\"https://www.motia.dev/docs/getting-started/quick-start\">ğŸš€ Quick Start</a> â€¢\n  <a href=\"https://www.motia.dev/docs/concepts/steps\">ğŸ“‹ Defining Steps</a> â€¢\n  <a href=\"https://www.motia.dev/docs\">ğŸ“š Docs</a>\n</p>\n\n---\n\n## ğŸš€ Create your first Motia App\n\nGet started in seconds:\n\n```bash\nnpx motia@latest create\n```\n\n---\n\n## ğŸ¯ What is Motia?\n\nBackend development today is fragmented.\n\nAPIs live in one framework, background jobs in another, queues and schedulers elsewhere, and now AI agents and streaming systems have their own runtimes. Add observability and state management on top, and you're stitching together half a dozen tools before writing your first feature.\n\n**Motia unifies all of these concerns around one core primitive: the Step.**\n\nJust as React made frontend development simple by introducing components, Motia redefines backend development with Steps - a single primitive that handles everything.\n\nEvery backend pattern, API endpoints, background jobs, queues, workflows, AI agents, streaming, observability, and state, is expressed with the same primitive.\n\nTo read more about this, check out our **[manifesto](https://motia.dev/manifesto)**.\n\n---\n\n## The Core Primitive: the Step\n\nA Step is just a file with a `config` and a `handler`. Motia auto-discovers these files and connects them automatically.\n\nHere's a simple example of two Steps working together: an API Step that emits an event, and an Event Step that processes it.\n\n<details open>\n<summary><b>TypeScript</b></summary>\n\n```ts\n// src/send-message.step.ts\nexport const config = {\n  name: 'SendMessage',\n  type: 'api',\n  path: '/messages',\n  method: 'POST',\n  emits: ['message.sent']\n};\n\nexport const handler = async (req, { emit }) => {\n  await emit({\n    topic: 'message.sent',\n    data: { text: req.body.text }\n  });\n  return { status: 200, body: { ok: true } };\n};\n```\n\n```ts\n// src/process-message.step.ts\nexport const config = {\n  name: 'ProcessMessage',\n  type: 'event',\n  subscribes: ['message.sent']\n};\n\nexport const handler = async (input, { logger }) => {\n  logger.info('Processing message', input);\n};\n```\n\n</details>\n\n<details close>\n<summary><b>Python</b></summary>\n\n```python\n# send_message_step.py\nconfig = {\n    \"name\": \"SendMessage\",\n    \"type\": \"api\",\n    \"path\": \"/messages\",\n    \"method\": \"POST\",\n    \"emits\": [\"message.sent\"]\n}\n\nasync def handler(req, context):\n    await context.emit({\n        \"topic\": \"message.sent\",\n        \"data\": {\"text\": req.body[\"text\"]}\n    })\n    return {\"status\": 200, \"body\": {\"ok\": True}}\n```\n\n```python\n# process_message_step.py\nconfig = {\n    \"name\": \"ProcessMessage\",\n    \"type\": \"event\",\n    \"subscribes\": [\"message.sent\"]\n}\n\nasync def handler(input, context):\n    context.logger.info(\"Processing message\", input)\n```\n\n</details close>\n\n<details>\n<summary><b>JavaScript</b></summary>\n\n```js\n// src/send-message.step.js\nconst config = {\n  name: 'SendMessage',\n  type: 'api',\n  path: '/messages',\n  method: 'POST',\n  emits: ['message.sent']\n};\n\nconst handler = async (req, { emit }) => {\n  await emit({\n    topic: 'message.sent',\n    data: { text: req.body.text }\n  });\n  return { status: 200, body: { ok: true } };\n};\n\nmodule.exports = { config, handler };\n```\n\n```js\n// src/process-message.step.js\nconst config = {\n  name: 'ProcessMessage',\n  type: 'event',\n  subscribes: ['message.sent']\n};\n\nconst handler = async (input, { logger }) => {\n  logger.info('Processing message', input);\n};\n\nmodule.exports = { config, handler };\n```\n\n</details>\n\nğŸ‘‰ With just two files, you've built an **API endpoint**, a **queue**, and a **worker**. No extra frameworks required.\n\n**[Learn more about Steps â†’](https://motia.dev/docs/concepts/steps)**\n\n[![Motia combines APIs, background queues, and AI agents into one system](assets/github-readme-banner.gif)](https://motia.dev)\n\n## ğŸ’» Remix your own Motia App in Replit\n[![Open in Replit](https://img.shields.io/badge/Open%20in-Replit-blue?logo=replit&style=for-the-badge)](https://replit.com/@motiadev/motia)\n\n## ğŸš€ Quickstart\n\nGet Motia project up and running in **under 60 seconds**:\n\n### 1. Bootstrap a New Motia Project\n\n```bash\nnpx motia@latest create   # runs the interactive terminal\n```\n\nFollow the prompts to pick a template, project name, and language.\n![motia-terminal](assets/motia-terminal.gif)\n\n### 2. Start the Workbench\n\nInside your new project folder, launch the dev server:\n\n```bash\nnpm run dev # âœ http://localhost:3000\n```\n\n**That's it!** You have:\n- âœ… REST APIs with validation\n- âœ… Visual debugger & tracing  \n- âœ… Multi-language support\n- âœ… Event-driven architecture\n- âœ… Zero configuration\n- âœ… AI development guides included (Cursor, OpenCode, Codex, and more)\n\n![new-workbench](assets/new-workbench.png)\n\n> ğŸ“– **[Full tutorial in our docs â†’](https://motia.dev/docs/getting-started/quick-start)**\n\n### ğŸ¤– AI-Assisted Development\n\nEvery Motia project includes detailed AI development guides that work with **any AI coding tool**:\n\n- **[Cursor IDE](https://cursor.sh/)** - Optimized `.mdc` rules with context-aware suggestions\n- **[OpenCode](https://opencode.ai/)**, **[Codex (OpenAI)](https://openai.com/index/introducing-codex/)** - Full support via `AGENTS.md` standard\n- **Aider, Jules, Factory, Amp, GitHub Copilot** - Compatible with [AGENTS.md format](https://agents.md/) (used by 20k+ projects)\n\nThe guides include patterns for API endpoints, background tasks, state management, real-time streaming, and complete architecture blueprints.\n\n> ğŸ¤– **[Learn more about AI development support â†’](https://motia.dev/docs/ai-development-guide)**\n\n## ğŸ¯ Triggers\n\n| Type | When it runs | Use Case |\n|------|--------------|----------|\n| **`api`** | HTTP Request | REST endpoints |\n| **`event`** | Topic subscription | Background processing |  \n| **`cron`** | Schedule | Recurring jobs |\n\n> ğŸ“– **[Learn more about Steps â†’](https://motia.dev/docs/concepts/steps)**\n\n---\n\n## ğŸ”Œ Plugins & Adapters\n\nExtend Motia with plugins and customize infrastructure with adapters.\n\n### Official Plugins\n\nPre-installed with every Motia project to enhance your workbench:\n\n| Plugin | Description | NPM |\n|--------|-------------|-----|\n| **[@motiadev/plugin-logs](https://github.com/motiadev/motia/tree/main/plugins/plugin-logs)** | Real-time log viewer with filtering and search | [![npm](https://img.shields.io/npm/v/@motiadev/plugin-logs?style=flat&color=CB3837)](https://www.npmjs.com/package/@motiadev/plugin-logs) |\n| **[@motiadev/plugin-endpoint](https://github.com/motiadev/motia/tree/main/plugins/plugin-endpoint)** | Interactive API endpoint testing tool | [![npm](https://img.shields.io/npm/v/@motiadev/plugin-endpoint?style=flat&color=CB3837)](https://www.npmjs.com/package/@motiadev/plugin-endpoint) |\n| **[@motiadev/plugin-observability](https://github.com/motiadev/motia/tree/main/plugins/plugin-observability)** | Performance tracing and distributed monitoring | [![npm](https://img.shields.io/npm/v/@motiadev/plugin-observability?style=flat&color=CB3837)](https://www.npmjs.com/package/@motiadev/plugin-observability) |\n| **[@motiadev/plugin-states](https://github.com/motiadev/motia/tree/main/plugins/plugin-states)** | State management and inspection tool | [![npm](https://img.shields.io/npm/v/@motiadev/plugin-states?style=flat&color=CB3837)](https://www.npmjs.com/package/@motiadev/plugin-states) |\n| **[@motiadev/plugin-bullmq](https://github.com/motiadev/motia/tree/main/plugins/plugin-bullmq)** | BullMQ queue and DLQ management | [![npm](https://img.shields.io/npm/v/@motiadev/plugin-bullmq?style=flat&color=CB3837)](https://www.npmjs.com/package/@motiadev/plugin-bullmq) |\n| **[@motiadev/plugin-ws](https://github.com/motiadev/motia/tree/main/plugins/plugin-ws)** | WebSocket monitoring and debugging<sup>*</sup> | [![npm](https://img.shields.io/npm/v/@motiadev/plugin-ws?style=flat&color=CB3837)](https://www.npmjs.com/package/@motiadev/plugin-ws) |\n| **[@motiadev/plugin-cron](https://github.com/motiadev/motia/tree/main/plugins/plugin-cron)** | Cron job monitoring and management | [![npm](https://img.shields.io/npm/v/@motiadev/plugin-cron?style=flat&color=CB3837)](https://www.npmjs.com/package/@motiadev/plugin-cron) |\n\n<sup>*</sup> Originally created by [@Rohithgilla12](https://github.com/Rohithgilla12) as [@potatocoder/ws-plugin](https://github.com/Rohithgilla12/motia-ws-plugin)\n\n**[View all community plugins â†’](https://github.com/MotiaDev/awesome-plugins)**\n\n### Official Adapters\n\nCustomize your infrastructure with production-ready adapters:\n\n| Adapter | Purpose | NPM |\n|---------|---------|-----|\n| **[@motiadev/adapter-bullmq-events](https://github.com/motiadev/motia/tree/main/packages/adapter-bullmq-events)** | BullMQ-based event processing | [![npm](https://img.shields.io/npm/v/@motiadev/adapter-bullmq-events?style=flat&color=CB3837)](https://www.npmjs.com/package/@motiadev/adapter-bullmq-events) |\n| **[@motiadev/adapter-rabbitmq-events](https://github.com/motiadev/motia/tree/main/packages/adapter-rabbitmq-events)** | RabbitMQ event adapter | [![npm](https://img.shields.io/npm/v/@motiadev/adapter-rabbitmq-events?style=flat&color=CB3837)](https://www.npmjs.com/package/@motiadev/adapter-rabbitmq-events) |\n| **[@motiadev/adapter-redis-cron](https://github.com/motiadev/motia/tree/main/packages/adapter-redis-cron)** | Redis-based cron scheduling | [![npm](https://img.shields.io/npm/v/@motiadev/adapter-redis-cron?style=flat&color=CB3837)](https://www.npmjs.com/package/@motiadev/adapter-redis-cron) |\n| **[@motiadev/adapter-redis-state](https://github.com/motiadev/motia/tree/main/packages/adapter-redis-state)** | Redis state management | [![npm](https://img.shields.io/npm/v/@motiadev/adapter-redis-state?style=flat&color=CB3837)](https://www.npmjs.com/package/@motiadev/adapter-redis-state) |\n| **[@motiadev/adapter-redis-streams](https://github.com/motiadev/motia/tree/main/packages/adapter-redis-streams)** | Redis Streams for real-time data | [![npm](https://img.shields.io/npm/v/@motiadev/adapter-redis-streams?style=flat&color=CB3837)](https://www.npmjs.com/package/@motiadev/adapter-redis-streams) |\n\n### Create Your Own\n\n- **[Create a Plugin](https://github.com/MotiaDev/awesome-plugins/blob/main/CONTRIBUTING.md)** - Build custom workbench features\n- **[Plugin Development Guide](https://motia.dev/docs/development-guide/plugins)** - Complete documentation\n- **[Contribute to awesome-plugins](https://github.com/MotiaDev/awesome-plugins)** - Share with the community\n\n---\n\n## ğŸ¯ Examples\n\n### ğŸ† **[ChessArena.ai](https://chessarena.ai)** - Full-Featured Production App\n\nA complete chess platform benchmarking LLM performance with real-time evaluation.\n\n**[Live Website â†’](https://chessarena.ai)** | **[Source Code â†’](https://github.com/MotiaDev/chessarena-ai)**\n\n> ![ChessArena.ai in action (raw GIF)](https://github.com/MotiaDev/chessarena-ai/blob/main/public/images/chessarena.gif?raw=true)\n\n**Built from scratch to production deployment, featuring:**\n- ğŸ” **Authentication & user management**\n- ğŸ¤– **Multi-agent LLM evaluation** (OpenAI, Claude, Gemini, Grok)\n- ğŸ **Python engine integration** (Stockfish chess evaluation)\n- ğŸ“Š **Real-time streaming** with live move updates and scoring\n- ğŸ¨ **Modern React UI** with interactive chess boards\n- ğŸ”„ **Event-driven workflows** connecting TypeScript APIs to Python processors\n- ğŸ“ˆ **Live leaderboards** with move-by-move quality scoring\n- ğŸš€ **Production deployment** on Motia Cloud\n\n### ğŸ“š **More Examples**\n\n**[View all 20+ examples â†’](https://github.com/MotiaDev/motia-examples)**\n\n| Example | Description |\n|---------|-------------|\n| **[AI Research Agent](https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-deep-research-agent)** | Web research with iterative analysis |\n| **[Streaming Chatbot](https://github.com/MotiaDev/motia-examples/tree/main/examples/streaming-ai-chatbot)** | Real-time AI responses |\n| **[Gmail Automation](https://github.com/MotiaDev/motia-examples/tree/main/examples/gmail-workflow)** | Smart email processing |\n| **[GitHub PR Manager](https://github.com/MotiaDev/motia-examples/tree/main/examples/github-integration-workflow)** | Automated PR workflows |\n| **[Finance Agent](https://github.com/MotiaDev/motia-examples/tree/main/examples/finance-agent)** | Real-time market analysis |\n\n**Features demonstrated:** Multi-language workflows â€¢ Real-time streaming â€¢ AI integration â€¢ Production deployment\n\n---\n\n## ğŸŒ Language Support\n\n| Language | Status | \n|----------|--------|\n| **JavaScript** | âœ… Stable |\n| **TypeScript** | âœ… Stable |\n| **Python** | âœ… Stable |\n| **Ruby** | ğŸš§ Beta |\n| **Go** | ğŸ”„ Soon |\n\n## ğŸ“š Resources\n\n- **[ğŸ“– Documentation](https://motia.dev/docs)** - Complete guides and API reference\n- **[ğŸ’¬ Discord](https://discord.gg/motia)** - Community support and discussions\n- **[ğŸ› GitHub Issues](https://github.com/MotiaDev/motia/issues)** - Bug reports and feature requests\n- **[ğŸ—ºï¸ Roadmap](https://github.com/orgs/MotiaDev/projects/2)** - Upcoming features and progress\n\n## ğŸš§ Roadmap\n\nWe have a public roadmap for Motia, you can view it [here](https://github.com/orgs/MotiaDev/projects/2/views/4).\n\nFeel free to add comments to the issues, or create a new issue if you have a feature request.\n\n| Feature | Status | Link | Description |\n| ------- | ------ | ---- | ----------- |\n| Python Types | ğŸš§ In Progress | [#485](https://github.com/MotiaDev/motia/issues/485) | Add support for Python types |\n| Streams: RBAC | âœ… Shipped | [#495](https://github.com/MotiaDev/motia/issues/495) | Add support for RBAC |\n| Streams: Workbench UI | ğŸ¨ Design Phase | [#497](https://github.com/MotiaDev/motia/issues/497) | Add support for Workbench UI |\n| Queue Strategies | âœ… Shipped | [#476](https://github.com/MotiaDev/motia/issues/476) | Add support for Queue Strategies |\n| Reactive Steps | ğŸ“… Planned | [#477](https://github.com/MotiaDev/motia/issues/477) | Add support for Reactive Steps |\n| Point in time triggers | ğŸ“… Planned | [#480](https://github.com/MotiaDev/motia/issues/480) | Add support for Point in time triggers |\n| Workbench plugins | âœ… Shipped | [#481](https://github.com/MotiaDev/motia/issues/481) | Add support for Workbench plugins |\n| Rewrite core in Rust | ğŸš§ In Progress | [#482](https://github.com/MotiaDev/motia/issues/482) | Rewrite our Core in Rust |\n| Decrease deployment time | ğŸš§ In Progress | [#483](https://github.com/MotiaDev/motia/issues/483) | Decrease deployment time |\n| Built-in database support | ğŸ“… Planned | [#484](https://github.com/MotiaDev/motia/issues/484) | Add support for built-in database |\n\n## ğŸ¤ Contributing\n\nWe welcome contributions! Check our **[Contributing Guide](https://github.com/MotiaDev/motia/blob/main/CONTRIBUTING.md)** to get started.\n\n---\n\n<div align=\"center\">\n\n**[ğŸš€ Get Started](https://motia.dev)** â€¢ **[ğŸ“– Docs](https://motia.dev/docs)** â€¢ **[ğŸ’¬ Discord](https://discord.gg/motia)**\n\n<a href=\"https://git-history.com\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://git-history.com/api/embed/stars?repos=MotiaDev/motia&theme=dark\" />\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://git-history.com/api/embed/stars?repos=MotiaDev/motia&theme=light\" />\n    <img alt=\"Star History Chart\" src=\"https://git-history.com/api/embed/stars?repos=MotiaDev/motia&theme=dark\" width=\"100%\" />\n  </picture>\n</a>\n\n<sub>â­ **Star us if you find Motia useful!**</sub>\n\n</div>\n",
      "stars_today": 79
    },
    {
      "id": 595662105,
      "name": "gitbutler",
      "full_name": "gitbutlerapp/gitbutler",
      "description": "The GitButler version control client, backed by Git, powered by Tauri/Rust/Svelte",
      "html_url": "https://github.com/gitbutlerapp/gitbutler",
      "stars": 17701,
      "forks": 768,
      "language": "Rust",
      "topics": [
        "git",
        "github",
        "tauri"
      ],
      "created_at": "2023-01-31T14:56:22Z",
      "updated_at": "2026-02-07T02:27:35Z",
      "pushed_at": "2026-02-07T01:55:22Z",
      "open_issues": 682,
      "owner": {
        "login": "gitbutlerapp",
        "avatar_url": "https://avatars.githubusercontent.com/u/123460877?v=4"
      },
      "readme": "<div align=\"center\">\n  <img align=\"center\" width=\"100%\" src=\"./readme-preview.webp\" />\n\n  <br />\n  <br />\n\n  <p align=\"center\" >\n    Version Control tool built from the ground up for modern, AI-powered workflows.\n    <br />\n    <br />\n    <a href=\"https://gitbutler.com\">Website</a>\n    <span>&nbsp;&nbsp;â€¢&nbsp;&nbsp;</span>\n    <a href=\"https://blog.gitbutler.com/\">Blog</a>\n    <span>&nbsp;&nbsp;â€¢&nbsp;&nbsp;</span>\n    <a href=\"https://docs.gitbutler.com/\">Docs</a>\n    <span>&nbsp;&nbsp;â€¢&nbsp;&nbsp;</span>\n    <a href=\"https://gitbutler.com/downloads\">Downloads</a>\n  </p>\n\n[![TWEET][s1]][l1] [\n![BLUESKY][s8]][l8 ] [![DISCORD][s2]][l2]\n\n[![CI][s0]][l0] [![INSTA][s3]][l3] [![YOUTUBE][s5]][l5] [![DEEPWIKI][s7]][l7]\n\n[s0]: https://github.com/gitbutlerapp/gitbutler/actions/workflows/push.yaml/badge.svg\n[l0]: https://github.com/gitbutlerapp/gitbutler/actions/workflows/push.yaml\n[s1]: https://img.shields.io/badge/Twitter-black?logo=x&logoColor=white\n[l1]: https://twitter.com/intent/follow?screen_name=gitbutler\n[s2]: https://img.shields.io/discord/1060193121130000425?label=Discord&color=5865F2\n[l2]: https://discord.gg/MmFkmaJ42D\n[s3]: https://img.shields.io/badge/Instagram-E4405F?logo=instagram&logoColor=white\n[l3]: https://www.instagram.com/gitbutler/\n[s5]: https://img.shields.io/youtube/channel/subscribers/UCEwkZIHGqsTGYvX8wgD0LoQ\n[l5]: https://www.youtube.com/@gitbutlerapp\n[s7]: https://deepwiki.com/badge.svg\n[l7]: https://deepwiki.com/gitbutlerapp/gitbutler\n[s8]: https://img.shields.io/badge/Bluesky-0285FF?logo=bluesky&logoColor=fff\n[l8]: https://bsky.app/profile/gitbutler.com\n\n</div>\n\n<br/>\n\n![Alt](https://repobeats.axiom.co/api/embed/fb23382bcf57c609832661874d3019a43555d6ae.svg 'Repobeats analytics for GitButler')\n\nGitButler is a git client that lets you work on multiple branches at the same time.\nIt allows you to quickly organize file changes into separate branches while still having them applied to your working directory.\nYou can then push branches individually to your remote, or directly create pull requests.\n\nIn a nutshell, it's a more flexible version of `git add -p` and `git rebase -i`, allowing you to efficiently multitask across branches.\n\n## How Does It Work?\n\nGitButler keeps track of uncommitted changes in a layer on top of Git. Changes to files or parts of files can be grouped into what we call virtual branches. Whenever you are happy with the contents of a virtual branch, you can push it to a remote. GitButler makes sure that the state of other virtual branches is kept separate.\n\n## How Do GB's Virtual Branches Differ From Git Branches?\n\nThe branches that we know and love in Git are separate universes, and switching between them is a full context switch. GitButler allows you to work with multiple branches in parallel in the same working directory. This effectively means having the content of multiple branches available at the same time.\n\nGitButler is aware of changes before they are committed. This allows it to keep a record of which virtual branch each individual diff belongs to. Effectively, this means that you can separate out individual branches with their content at any time to push them to a remote or to unapply them from your working directory.\n\nAnd finally, while in Git it is preferable that you create your desired branch ahead of time, using GitButler you can move changes between virtual branches at any point during development.\n\n## Why GitButler?\n\nWe love Git. Our own [@schacon](https://github.com/schacon) has even published the [Pro Git](https://git-scm.com/book/en/v2) book. At the same time, Git's user interface hasn't been fundamentally changed for 15 years. While it was written for Linux kernel devs sending patches to each other over mailing lists, most developers today have different workflows and needs.\n\nInstead of trying to fit the semantics of the Git CLI into a graphical interface, we are starting with the developer workflow and mapping it back to Git.\n\n## Tech\n\nGitButler is a [Tauri](https://tauri.app/)-based application. Its UI is written in [Svelte](https://svelte.dev/) using [TypeScript](https://www.typescriptlang.org) and its backend is written in [Rust](https://www.rust-lang.org/).\n\n## Main Features\n\n- **Virtual Branches**\n  - Organize work on multiple branches simultaneously, rather than constantly switching branches\n  - Automatically create new branches when needed\n- **Easy Commit Management**\n  - Undo, Amend and Squash commits by dragging and dropping\n- **Undo Timeline**\n  - Logs all operations and changes and allows you to easily undo or revert any operation\n- **GitHub Integration**\n  - Authenticate to GitHub to open Pull Requests, list branches and statuses and more\n- **Easy SSH Key Management**\n  - GitButler can generate an SSH key to upload to GitHub automatically\n- **AI Tooling**\n  - Automatically write commit messages based on your work in progress\n  - Automatically create descriptive branch names\n- **Commit Signing**\n  - Easy commit signing with GPG or SSH\n\n## Example Uses\n\n### Fixing a Bug While Working on a Feature\n\n> Say that while developing a feature, you encounter a bug that you wish to fix. It's often desirable that you ship the fix as a separate contribution (Pull request).\n\nUsing Git you can stash your changes and switch to another branch, where you can commit, and push your fix.\n\n_With GitButler_ you simply assign your fix to a separate virtual branch, which you can individually push (or directly create a PR). An additional benefit is that you can retain the fix in your working directory while waiting for CI and/or code review.\n\n### Trying Someone Else's Branch Together With My Work in Progress\n\n> Say you want to test a branch from someone else for the purpose of code review.\n\nUsing Git trying out someone else's branch is a full context switch away from your own work.\n_With GitButler_ you can apply and unapply (add / remove) any remote branch directly into your working directory.\n\n## Documentation\n\nYou can find our end user documentation at: <https://docs.gitbutler.com>\n\n## Bugs and Feature Requests\n\nIf you have a bug or feature request, feel free to open an [issue](https://github.com/gitbutlerapp/gitbutler/issues/new),\nor [join our Discord server](https://discord.gg/MmFkmaJ42D).\n\n## AI Commit Message Generation\n\nCommit message generation is an opt-in feature. You can enable it while adding your repository for the first time or later in the project settings.\n\nCurrently, GitButler uses OpenAI's API for diff summarization, which means that if enabled, code diffs would be sent to OpenAI's servers.\n\nOur goal is to make this feature more modular such that in the future you can modify the prompt as well as plug a different LLM endpoints (including local ones).\n\n## Contributing\n\nSo you want to help out? Please check out the [CONTRIBUTING.md](CONTRIBUTING.md)\ndocument.\n\nIf you want to skip right to getting the code to actually compile, take a look\nat the [DEVELOPMENT.md](DEVELOPMENT.md) file.\n\n### Contributors\n\n<a href=\"https://github.com/gitbutlerapp/gitbutler/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=gitbutlerapp/gitbutler\" />\n</a>\n",
      "stars_today": 66
    },
    {
      "id": 932825524,
      "name": "Pulse",
      "full_name": "rcourtman/Pulse",
      "description": "Real-time monitoring for Proxmox, Docker, and Kubernetes with AI-powered insights, smart alerts, and a beautiful unified dashboard",
      "html_url": "https://github.com/rcourtman/Pulse",
      "stars": 4158,
      "forks": 175,
      "language": "Go",
      "topics": [
        "ai",
        "alerts",
        "dashboard",
        "docker",
        "docker-monitoring",
        "go",
        "homelab",
        "host-monitoring",
        "infrastructure-monitoring",
        "kubernetes",
        "monitoring",
        "proxmox",
        "proxmox-backup-server",
        "proxmox-mail-gateway",
        "proxmox-ve",
        "react",
        "self-hosted",
        "typescript",
        "webhooks"
      ],
      "created_at": "2025-02-14T15:36:13Z",
      "updated_at": "2026-02-07T02:33:53Z",
      "pushed_at": "2026-02-05T18:02:16Z",
      "open_issues": 91,
      "owner": {
        "login": "rcourtman",
        "avatar_url": "https://avatars.githubusercontent.com/u/8825017?v=4"
      },
      "readme": "# Pulse\n\n<div align=\"center\">\n  <img src=\"docs/images/pulse-logo.svg\" alt=\"Pulse Logo\" width=\"120\" />\n  <p><strong>Real-time monitoring for Proxmox, Docker, and Kubernetes infrastructure.</strong></p>\n\n  [![GitHub Stars](https://img.shields.io/github/stars/rcourtman/Pulse?style=flat&logo=github)](https://github.com/rcourtman/Pulse)\n  [![GitHub release](https://img.shields.io/github/v/release/rcourtman/Pulse)](https://github.com/rcourtman/Pulse/releases/latest)\n  [![Docker Pulls](https://img.shields.io/docker/pulls/rcourtman/pulse)](https://hub.docker.com/r/rcourtman/pulse)\n  [![License](https://img.shields.io/github/license/rcourtman/Pulse)](LICENSE)\n\n  [Live Demo](https://demo.pulserelay.pro) â€¢ [Pulse Pro](https://pulserelay.pro) â€¢ [Documentation](docs/README.md) â€¢ [Report Bug](https://github.com/rcourtman/Pulse/issues)\n</div>\n\n---\n\n## ğŸš€ Overview\n\nPulse is a modern, unified dashboard for monitoring your **infrastructure** across Proxmox, Docker, and Kubernetes. It consolidates metrics, alerts, and AI-powered insights from all your systems into a single, beautiful interface.\n\nDesigned for homelabs, sysadmins, and MSPs who need a \"single pane of glass\" without the complexity of enterprise monitoring stacks.\n\n![Pulse Dashboard](docs/images/01-dashboard.jpg)\n\n## ğŸ§­ Unified Navigation\n\nPulse now groups everything by task instead of data source:\n- **Infrastructure** for hosts and nodes\n- **Workloads** for VMs and containers\n- **Storage** and **Backups** as top-level views\n- **Services** for PMG instances (when connected)\n\nPower-user shortcuts:\n- `g i` â†’ Infrastructure, `g w` â†’ Workloads, `?` â†’ shortcuts help\n- `/` or `Cmd/Ctrl+K` â†’ global search\n\n## âœ¨ Features\n\n### Core Monitoring\n- **Unified Monitoring**: View health and metrics for PVE, PBS, PMG, Docker, and Kubernetes in one place\n- **Smart Alerts**: Get notified via Discord, Slack, Telegram, Email, and more\n- **Auto-Discovery**: Automatically finds Proxmox nodes on your network\n- **Metrics History**: Persistent storage with configurable retention\n- **Backup Explorer**: Visualize backup jobs and storage usage\n\n### AI-Powered\n- **Chat Assistant (BYOK)**: Ask questions about your infrastructure in natural language\n- **Patrol (BYOK)**: Background health checks that generate findings on a schedule\n- **Alert Analysis (Pro)**: Optional AI analysis when alerts fire\n- **Cost Tracking**: Track usage and costs per provider/model\n\n### Multi-Platform\n- **Proxmox VE/PBS/PMG**: Full monitoring and management\n- **Kubernetes**: Complete K8s cluster monitoring via agents\n- **Docker/Podman**: Container and Swarm service monitoring\n- **OCI Containers**: Proxmox 9.1+ native container support\n\n### Security & Operations\n- **Secure by Design**: Credentials encrypted at rest, strict API scoping\n- **One-Click Updates**: Easy upgrades for supported deployments\n- **OIDC/SSO**: Single sign-on authentication\n- **Privacy Focused**: No telemetry, all data stays on your server\n\n## âš¡ Quick Start\n\n### Option 1: Proxmox LXC (Recommended)\nRun this one-liner on your Proxmox host to create a lightweight LXC container:\n\n```bash\ncurl -fsSL https://github.com/rcourtman/Pulse/releases/latest/download/install.sh | bash\n```\n\nNote: this installs the Pulse **server**. Agent installs use the command generated in **Settings â†’ Agents â†’ Installation commands** (served from `/install.sh` on your Pulse server).\n\n### Option 2: Docker\n```bash\ndocker run -d \\\n  --name pulse \\\n  -p 7655:7655 \\\n  -v pulse_data:/data \\\n  --restart unless-stopped \\\n  rcourtman/pulse:latest\n```\n\nAccess the dashboard at `http://<your-ip>:7655`.\n\n## ğŸ“š Documentation\n\n- **[Installation Guide](docs/INSTALL.md)**: Detailed instructions for Docker, Kubernetes, and bare metal.\n- **[Configuration](docs/CONFIGURATION.md)**: Setup authentication, notifications, and advanced settings.\n- **[Security](SECURITY.md)**: Learn about Pulse's security model and best practices.\n- **[API Reference](docs/API.md)**: Integrate Pulse with your own tools.\n- **[Architecture](ARCHITECTURE.md)**: High-level system design and data flow.\n- **[Troubleshooting](docs/TROUBLESHOOTING.md)**: Solutions to common issues.\n- **[Agent Security](docs/AGENT_SECURITY.md)**: Details on checksum-verified updates and verification.\n- **[Docker Monitoring](docs/DOCKER.md)**: Setup and management of Docker agents.\n\n## ğŸŒ Community Integrations\n\nCommunity-maintained integrations and addons:\n\n- **[Home Assistant Addons](https://github.com/Kosztyk/homeassistant-addons)** - Run Pulse Agent and Pulse Server as Home Assistant addons.\n\n## ğŸš€ Pulse Pro\n\n**[Pulse Pro](https://pulserelay.pro)** unlocks **Auto-Fix and advanced AI analysis** â€” **Pulse Patrol is available to everyone with BYOK**.\n\n| Feature | Free | Pro |\n|---------|------|-----|\n| Real-time dashboard | âœ… | âœ… |\n| Threshold alerts | âœ… | âœ… |\n| AI Chat (BYOK) | âœ… | âœ… |\n| **Pulse Patrol (BYOK)** | âœ… | âœ… |\n| Alert-triggered AI analysis | â€” | âœ… |\n| Kubernetes AI analysis | â€” | âœ… |\n| Auto-fix + autonomous mode | â€” | âœ… |\n| Centralized agent profiles | â€” | âœ… |\n| **Advanced Reporting (PDF/CSV)** | â€” | âœ… |\n| **Audit Webhooks (SIEM integration)** | â€” | âœ… |\n| Priority support | â€” | âœ… |\n\nPulse Patrol runs on your schedule (every 10 minutes to every 7 days, default 6 hours) and finds:\n- ZFS pools approaching capacity\n- Backup jobs that silently failed\n- VMs stuck in restart loops\n- Clock drift across cluster nodes\n- Container health check failures\n\nPulse Patrol uses your configured provider (BYOK) and runs entirely on your server.\n\nTechnical highlights:\n- Cross-system context (nodes, VMs, backups, containers, and metrics history)\n- LLM analysis with your provider + alert-triggered deep dives (Pro)\n- Optional auto-fix with command safety policies and audit trail\n- Centralized agent profiles for consistent fleet settings\n\n**[Try the live demo â†’](https://demo.pulserelay.pro)** or **[learn more at pulserelay.pro](https://pulserelay.pro)**\n\nPulse Pro technical details: [docs/PULSE_PRO.md](docs/PULSE_PRO.md)\n\n## â¤ï¸ Support Pulse Development\n\nPulse is maintained by one person. Sponsorships help cover the costs of the demo server, development tools, and domains. If Pulse saves you time, please consider supporting the project!\n\n[![GitHub Sponsors](https://img.shields.io/github/sponsors/rcourtman?label=Sponsor)](https://github.com/sponsors/rcourtman)\n[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/rcourtman)\n\n## ğŸ“„ License\n\nMIT Â© [Richard Courtman](https://github.com/rcourtman). Use of Pulse Pro is subject to the [Terms of Service](TERMS.md).\n",
      "stars_today": 63
    },
    {
      "id": 36836475,
      "name": "tmux",
      "full_name": "tmux/tmux",
      "description": "tmux source code",
      "html_url": "https://github.com/tmux/tmux",
      "stars": 41443,
      "forks": 2401,
      "language": "C",
      "topics": [],
      "created_at": "2015-06-03T23:32:55Z",
      "updated_at": "2026-02-07T02:21:05Z",
      "pushed_at": "2026-02-02T19:09:32Z",
      "open_issues": 37,
      "owner": {
        "login": "tmux",
        "avatar_url": "https://avatars.githubusercontent.com/u/12054114?v=4"
      },
      "readme": "# Welcome to tmux!\n\ntmux is a terminal multiplexer: it enables a number of terminals to be created,\naccessed, and controlled from a single screen. tmux may be detached from a\nscreen and continue running in the background, then later reattached.\n\nThis release runs on OpenBSD, FreeBSD, NetBSD, Linux, macOS and Solaris.\n\n## Dependencies\n\ntmux depends on [libevent](https://libevent.org) 2.x, available from [this\npage](https://github.com/libevent/libevent/releases/latest).\n\nIt also depends on [ncurses](https://www.gnu.org/software/ncurses/), available\nfrom [this page](https://invisible-mirror.net/archives/ncurses/).\n\nTo build tmux, a C compiler (for example gcc or clang), make, pkg-config and a\nsuitable yacc (yacc or bison) are needed.\n\n## Installation\n\n### Binary packages\n\nSome platforms provide binary packages for tmux, although these are sometimes\nout of date. Examples are listed on\n[this page](https://github.com/tmux/tmux/wiki/Installing).\n\n### From release tarball\n\nTo build and install tmux from a release tarball, use:\n\n~~~bash\n./configure && make\nsudo make install\n~~~\n\ntmux can use the utempter library to update utmp(5), if it is installed - run\nconfigure with `--enable-utempter` to enable this.\n\nFor more detailed instructions on building and installing tmux, see\n[this page](https://github.com/tmux/tmux/wiki/Installing).\n\n### From version control\n\nTo get and build the latest from version control - note that this requires\n`autoconf`, `automake` and `pkg-config`:\n\n~~~bash\ngit clone https://github.com/tmux/tmux.git\ncd tmux\nsh autogen.sh\n./configure && make\n~~~\n\n## Contributing\n\nBug reports, feature suggestions and especially code contributions are most\nwelcome. Please send by email to:\n\ntmux-users@googlegroups.com\n\nOr open a GitHub issue or pull request. **Please read [this\ndocument](CONTRIBUTING.md) before opening an issue.**\n\nThere is [a list of suggestions for contributions](https://github.com/tmux/tmux/wiki/Contributing).\nPlease feel free to ask on the mailing list if you're thinking of working on something or need\nfurther information.\n\n## Documentation\n\nFor documentation on using tmux, see the tmux.1 manpage. View it from the\nsource tree with:\n\n~~~bash\nnroff -mdoc tmux.1|less\n~~~\n\nA small example configuration is in `example_tmux.conf`.\n\nAnd a bash(1) completion file at:\n\nhttps://github.com/scop/bash-completion/blob/main/completions/tmux\n\nFor debugging, run tmux with `-v` or `-vv` to generate server and client log\nfiles in the current directory.\n\n## Support\n\nThe tmux mailing list for general discussion and bug reports is:\n\nhttps://groups.google.com/forum/#!forum/tmux-users\n\nSubscribe by sending an email to:\n\ntmux-users+subscribe@googlegroups.com\n",
      "stars_today": 62
    },
    {
      "id": 15634981,
      "name": "godot",
      "full_name": "godotengine/godot",
      "description": "Godot Engine â€“ Multi-platform 2D and 3D game engine",
      "html_url": "https://github.com/godotengine/godot",
      "stars": 106404,
      "forks": 24260,
      "language": "C++",
      "topics": [
        "game-development",
        "game-engine",
        "gamedev",
        "godot",
        "godotengine",
        "multi-platform",
        "open-source"
      ],
      "created_at": "2014-01-04T16:05:36Z",
      "updated_at": "2026-02-07T02:21:13Z",
      "pushed_at": "2026-02-06T16:02:31Z",
      "open_issues": 17453,
      "owner": {
        "login": "godotengine",
        "avatar_url": "https://avatars.githubusercontent.com/u/6318500?v=4"
      },
      "readme": "# Godot Engine\n\n<p align=\"center\">\n  <a href=\"https://godotengine.org\">\n    <img src=\"logo_outlined.svg\" width=\"400\" alt=\"Godot Engine logo\">\n  </a>\n</p>\n\n## 2D and 3D cross-platform game engine\n\n**[Godot Engine](https://godotengine.org) is a feature-packed, cross-platform\ngame engine to create 2D and 3D games from a unified interface.** It provides a\ncomprehensive set of [common tools](https://godotengine.org/features), so that\nusers can focus on making games without having to reinvent the wheel. Games can\nbe exported with one click to a number of platforms, including the major desktop\nplatforms (Linux, macOS, Windows), mobile platforms (Android, iOS), as well as\nWeb-based platforms and [consoles](https://godotengine.org/consoles).\n\n## Free, open source and community-driven\n\nGodot is completely free and open source under the very permissive [MIT license](https://godotengine.org/license).\nNo strings attached, no royalties, nothing. The users' games are theirs, down\nto the last line of engine code. Godot's development is fully independent and\ncommunity-driven, empowering users to help shape their engine to match their\nexpectations. It is supported by the [Godot Foundation](https://godot.foundation/)\nnot-for-profit.\n\nBefore being open sourced in [February 2014](https://github.com/godotengine/godot/commit/0b806ee0fc9097fa7bda7ac0109191c9c5e0a1ac),\nGodot had been developed by [Juan Linietsky](https://github.com/reduz) and\n[Ariel Manzur](https://github.com/punto-) for several years as an in-house\nengine, used to publish several work-for-hire titles.\n\n![Screenshot of a 3D scene in the Godot Engine editor](https://raw.githubusercontent.com/godotengine/godot-design/master/screenshots/editor_tps_demo_1920x1080.jpg)\n\n## Getting the engine\n\n### Binary downloads\n\nOfficial binaries for the Godot editor and the export templates can be found\n[on the Godot website](https://godotengine.org/download).\n\n### Compiling from source\n\n[See the official docs](https://docs.godotengine.org/en/latest/engine_details/development/compiling)\nfor compilation instructions for every supported platform.\n\n## Community and contributing\n\nGodot is not only an engine but an ever-growing community of users and engine\ndevelopers. The main community channels are listed [on the homepage](https://godotengine.org/community).\n\nThe best way to get in touch with the core engine developers is to join the\n[Godot Contributors Chat](https://chat.godotengine.org).\n\nTo get started contributing to the project, see the [contributing guide](CONTRIBUTING.md).\nThis document also includes guidelines for reporting bugs.\n\n## Documentation and demos\n\nThe official documentation is hosted on [Read the Docs](https://docs.godotengine.org).\nIt is maintained by the Godot community in its own [GitHub repository](https://github.com/godotengine/godot-docs).\n\nThe [class reference](https://docs.godotengine.org/en/latest/classes/)\nis also accessible from the Godot editor.\n\nWe also maintain official demos in their own [GitHub repository](https://github.com/godotengine/godot-demo-projects)\nas well as a list of [awesome Godot community resources](https://github.com/godotengine/awesome-godot).\n\nThere are also a number of other\n[learning resources](https://docs.godotengine.org/en/latest/community/tutorials.html)\nprovided by the community, such as text and video tutorials, demos, etc.\nConsult the [community channels](https://godotengine.org/community)\nfor more information.\n\n[![Code Triagers Badge](https://www.codetriage.com/godotengine/godot/badges/users.svg)](https://www.codetriage.com/godotengine/godot)\n[![Translate on Weblate](https://hosted.weblate.org/widgets/godot-engine/-/godot/svg-badge.svg)](https://hosted.weblate.org/engage/godot-engine/?utm_source=widget)\n",
      "stars_today": 61
    },
    {
      "id": 21331090,
      "name": "GDevelop",
      "full_name": "4ian/GDevelop",
      "description": "ğŸ® Open-source, cross-platform 2D/3D/multiplayer game engine designed for everyone.",
      "html_url": "https://github.com/4ian/GDevelop",
      "stars": 20222,
      "forks": 1251,
      "language": "JavaScript",
      "topics": [
        "2d-game",
        "2d-game-engine",
        "3d",
        "3d-game",
        "3d-game-engine",
        "game",
        "game-development",
        "game-engine",
        "gamedev",
        "gamemaker",
        "gdevelop",
        "hacktoberfest",
        "html5",
        "html5-game-engine",
        "javascript",
        "multiplayer",
        "no-code",
        "open-source",
        "vibe-coding"
      ],
      "created_at": "2014-06-29T19:58:38Z",
      "updated_at": "2026-02-07T02:19:21Z",
      "pushed_at": "2026-02-06T17:13:57Z",
      "open_issues": 566,
      "owner": {
        "login": "4ian",
        "avatar_url": "https://avatars.githubusercontent.com/u/1280130?v=4"
      },
      "readme": "![GDevelop logo](https://raw.githubusercontent.com/4ian/GDevelop/master/newIDE/GDevelop%20banner.png \"GDevelop logo\")\n\nGDevelop is a **full-featured, no-code, open-source** game development software. You can build **2D, 3D and multiplayer games** for mobile (iOS, Android), desktop and the web. GDevelop is designed to be fast and incredibly intuitive: make games using an easy-to-understand yet powerful event-based system and modular behaviors. Create with AI that assists or builds alongside you.\n\n![The GDevelop editor when editing a game level](https://raw.githubusercontent.com/4ian/GDevelop/master/newIDE/GDevelop%20screenshot.png \"The GDevelop editor when editing a 3D game level\")\n\n![The GDevelop editor when editing a game level](./newIDE/GDevelop%202D%20screenshot.png \"The GDevelop editor when editing a 2D game level\")\n\n## Getting started\n\n| â” I want to...                                   | ğŸš€ What to do                                                                                                                                                     |\n| ------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| ğŸ® Use GDevelop to make games                     | Go to [GDevelop homepage](https://gdevelop.io) to download the app!                                                                                               |\n| âš™ï¸ Create/improve an extension                    | Read about [creating an extension](https://wiki.gdevelop.io/gdevelop5/extensions/create), with no-code or code.                                                   |\n| ğŸ§‘â€ğŸ’» Contribute to the editor or game engine        | Follow this [README](newIDE/README.md).                                                                                                                           |\n| ğŸ‘¾ Create or sell a game template                 | Submit a [free example or a paid template on the Asset Store](https://wiki.gdevelop.io/gdevelop5/community/guide-for-submitting-an-example/).                     |\n| ğŸ¨ Share or sell an asset pack                    | Submit a [free or paid asset pack on the Asset Store](https://wiki.gdevelop.io/gdevelop5/community/sell-asset-pack-store).                                        |\n| ğŸŒ Help translate GDevelop                        | Go on the [GDevelop project on Crowdin](https://crowdin.com/project/gdevelop) or translate [in-app tutorials](https://github.com/GDevelopApp/GDevelop-tutorials). |\n| ğŸ‘¥ Get online game services or commercial support | See offers for [professionals, teams or individual creators](https://gdevelop.io/pricing).                                                                        |\n\n> Are you interested in contributing to GDevelop for the first time? Take a look at the list of **[good first issues](https://github.com/4ian/GDevelop/issues?q=is%3Aissue+is%3Aopen+label%3A%22%F0%9F%91%8Cgood+first+issue%22)**, **[good first contributions](https://github.com/4ian/GDevelop/discussions/categories/good-first-contribution)** or the **[\"ğŸ not too hard\" cards](https://trello.com/b/qf0lM7k8/gdevelop-roadmap?menu=filter&filter=label:Not%20too%20hard%20%E2%9A%BD%EF%B8%8F)** on the Roadmap.\n\n## Games made with GDevelop\n\n- Find GDevelop games on [gd.games](https://gd.games), the gaming platform for games powered by GDevelop.\n- See the [showcase of games](https://gdevelop.io/games) created with GDevelop and published on Steam, iOS (App Store), Android (Google Play), Itch.io, Newgrounds, CrazyGames, Poki...\n  - Suggest your game to be [added to the showcase here](https://docs.google.com/forms/d/e/1FAIpQLSfjiOnkbODuPifSGuzxYY61vB5kyMWdTZSSqkJsv3H6ePRTQA/viewform).\n\n[![Some games made with GDevelop](https://raw.githubusercontent.com/4ian/GDevelop/master/newIDE/GDevelop%20games.png \"Some games made with GDevelop\")](https://gdevelop.io/games)\n\n## Technical architecture\n\nGDevelop is composed of an **editor**, a **game engine**, an **ecosystem** of extensions as well as **online services** and commercial support.\n\n| Directory     | â„¹ï¸ Description                                                                                                                                                                                                                                                                                           |\n| ------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `Core`        | Core classes, describing the structure of a game and tools to implement the IDE and work with GDevelop games.                                                                                                                                                                                            |\n| `GDJS`        | The game engine, written in TypeScript, using PixiJS and Three.js for 2D and 3D rendering (WebGL), powering all GDevelop games.                                                                                                                                                                          |\n| `GDevelop.js` | Bindings of `Core`, `GDJS` and `Extensions` to JavaScript (with WebAssembly), used by the IDE.                                                                                                                                                                                                           |\n| `newIDE`      | The game editor, written in JavaScript with React, Electron, PixiJS and Three.js.                                                                                                                                                                                                                        |\n| `Extensions`  | Built-in extensions for the game engine, providing objects, behaviors and new features. For example, this includes the physics engines running in WebAssembly (Box2D or Jolt Physics for 3D). All the [official and experimental extensions are on this repository](https://github.com/GDevelopApp/GDevelop-extensions). [Community extensions are available here](https://github.com/GDevelopApp/GDevelop-community-list). |\n\nTo learn more about GDevelop Architecture, read the [architecture overview here](Core/GDevelop-Architecture-Overview.md).\n\nPre-generated documentation of the game engine is [available here](https://docs.gdevelop.io).\n\nStatus of the tests and builds: [![macOS and Linux build status](https://circleci.com/gh/4ian/GDevelop.svg?style=shield)](https://app.circleci.com/pipelines/github/4ian/GDevelop) [![Fast tests status](https://gdevelop.semaphoreci.com/badges/GDevelop/branches/master.svg?style=shields)](https://gdevelop.semaphoreci.com/projects/GDevelop) [![Windows Build status](https://ci.appveyor.com/api/projects/status/84uhtdox47xp422x/branch/master?svg=true)](https://ci.appveyor.com/project/4ian/gdevelop/branch/master) [![https://good-labs.github.io/greater-good-affirmation/assets/images/badge.svg](https://good-labs.github.io/greater-good-affirmation/assets/images/badge.svg)](https://good-labs.github.io/greater-good-affirmation)\n\n## Links\n\n### Community\n\n- [GDevelop forums](https://forum.gdevelop.io) and [Discord chat](https://discord.gg/gdevelop).\n- [GDevelop homepage](https://gdevelop.io).\n- [GDevelop wiki (documentation)](https://wiki.gdevelop.io/gdevelop5/start).\n- Help translate GDevelop in your language: [GDevelop project on Crowdin](https://crowdin.com/project/gdevelop).\n- Open-source [extensions (official or experimental)](https://github.com/GDevelopApp/GDevelop-extensions), [community extensions](https://github.com/GDevelopApp/GDevelop-community-list), [examples](https://github.com/GDevelopApp/GDevelop-examples), [tutorials](https://github.com/GDevelopApp/GDevelop-tutorials) are on GitHub.\n\n### Development Roadmap\n\n- [GDevelop Roadmap on Trello.com](https://trello.com/b/qf0lM7k8/gdevelop-roadmap), for a global view of the features that could be added. Please vote and comment here for new features/requests.\n- [GitHub issue page](https://github.com/4ian/GDevelop/issues), for technical issues and bugs.\n- [Github discussions](https://github.com/4ian/GDevelop/discussions) to talk about new features and ideas.\n\n## License\n\n- The Core library, the native and HTML5 game engines, the IDE, and all extensions (respectively `Core`, `GDJS`, `newIDE` and `Extensions` folders) are under the **MIT license**.\n- The name, GDevelop, and its logo are the exclusive property of Florian Rival.\n\nGames exported with GDevelop are based on the GDevelop game engine (see `Core` and `GDJS` folders): this engine is distributed under the MIT license so that you can **distribute, sell or do anything** with the games you created with GDevelop. In particular, you are not forced to make your game open-source.\n\n[node.js]: https://nodejs.org\n\n## Star History\n\nHelp us spread the word about GDevelop by starring the repository on GitHub!\n\n[![Star History Chart](https://api.star-history.com/svg?repos=4ian/gdevelop&type=Date)](https://star-history.com/#4ian/gdevelop&Date)\n",
      "stars_today": 60
    },
    {
      "id": 41881900,
      "name": "vscode",
      "full_name": "microsoft/vscode",
      "description": "Visual Studio Code",
      "html_url": "https://github.com/microsoft/vscode",
      "stars": 181477,
      "forks": 37775,
      "language": "TypeScript",
      "topics": [
        "editor",
        "electron",
        "microsoft",
        "typescript",
        "visual-studio-code"
      ],
      "created_at": "2015-09-03T20:23:38Z",
      "updated_at": "2026-02-07T01:15:14Z",
      "pushed_at": "2026-02-07T01:29:33Z",
      "open_issues": 13689,
      "owner": {
        "login": "microsoft",
        "avatar_url": "https://avatars.githubusercontent.com/u/6154722?v=4"
      },
      "readme": "# Visual Studio Code - Open Source (\"Code - OSS\")\n[![Feature Requests](https://img.shields.io/github/issues/microsoft/vscode/feature-request.svg)](https://github.com/microsoft/vscode/issues?q=is%3Aopen+is%3Aissue+label%3Afeature-request+sort%3Areactions-%2B1-desc)\n[![Bugs](https://img.shields.io/github/issues/microsoft/vscode/bug.svg)](https://github.com/microsoft/vscode/issues?utf8=âœ“&q=is%3Aissue+is%3Aopen+label%3Abug)\n[![Gitter](https://img.shields.io/badge/chat-on%20gitter-yellow.svg)](https://gitter.im/Microsoft/vscode)\n\n## The Repository\n\nThis repository (\"`Code - OSS`\") is where we (Microsoft) develop the [Visual Studio Code](https://code.visualstudio.com) product together with the community. Not only do we work on code and issues here, we also publish our [roadmap](https://github.com/microsoft/vscode/wiki/Roadmap), [monthly iteration plans](https://github.com/microsoft/vscode/wiki/Iteration-Plans), and our [endgame plans](https://github.com/microsoft/vscode/wiki/Running-the-Endgame). This source code is available to everyone under the standard [MIT license](https://github.com/microsoft/vscode/blob/main/LICENSE.txt).\n\n## Visual Studio Code\n\n<p align=\"center\">\n  <img alt=\"VS Code in action\" src=\"https://user-images.githubusercontent.com/35271042/118224532-3842c400-b438-11eb-923d-a5f66fa6785a.png\">\n</p>\n\n[Visual Studio Code](https://code.visualstudio.com) is a distribution of the `Code - OSS` repository with Microsoft-specific customizations released under a traditional [Microsoft product license](https://code.visualstudio.com/License/).\n\n[Visual Studio Code](https://code.visualstudio.com) combines the simplicity of a code editor with what developers need for their core edit-build-debug cycle. It provides comprehensive code editing, navigation, and understanding support along with lightweight debugging, a rich extensibility model, and lightweight integration with existing tools.\n\nVisual Studio Code is updated monthly with new features and bug fixes. You can download it for Windows, macOS, and Linux on [Visual Studio Code's website](https://code.visualstudio.com/Download). To get the latest releases every day, install the [Insiders build](https://code.visualstudio.com/insiders).\n\n## Contributing\n\nThere are many ways in which you can participate in this project, for example:\n\n* [Submit bugs and feature requests](https://github.com/microsoft/vscode/issues), and help us verify as they are checked in\n* Review [source code changes](https://github.com/microsoft/vscode/pulls)\n* Review the [documentation](https://github.com/microsoft/vscode-docs) and make pull requests for anything from typos to additional and new content\n\nIf you are interested in fixing issues and contributing directly to the code base,\nplease see the document [How to Contribute](https://github.com/microsoft/vscode/wiki/How-to-Contribute), which covers the following:\n\n* [How to build and run from source](https://github.com/microsoft/vscode/wiki/How-to-Contribute)\n* [The development workflow, including debugging and running tests](https://github.com/microsoft/vscode/wiki/How-to-Contribute#debugging)\n* [Coding guidelines](https://github.com/microsoft/vscode/wiki/Coding-Guidelines)\n* [Submitting pull requests](https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests)\n* [Finding an issue to work on](https://github.com/microsoft/vscode/wiki/How-to-Contribute#where-to-contribute)\n* [Contributing to translations](https://aka.ms/vscodeloc)\n\n## Feedback\n\n* Ask a question on [Stack Overflow](https://stackoverflow.com/questions/tagged/vscode)\n* [Request a new feature](CONTRIBUTING.md)\n* Upvote [popular feature requests](https://github.com/microsoft/vscode/issues?q=is%3Aopen+is%3Aissue+label%3Afeature-request+sort%3Areactions-%2B1-desc)\n* [File an issue](https://github.com/microsoft/vscode/issues)\n* Connect with the extension author community on [GitHub Discussions](https://github.com/microsoft/vscode-discussions/discussions) or [Slack](https://aka.ms/vscode-dev-community)\n* Follow [@code](https://x.com/code) and let us know what you think!\n\nSee our [wiki](https://github.com/microsoft/vscode/wiki/Feedback-Channels) for a description of each of these channels and information on some other available community-driven channels.\n\n## Related Projects\n\nMany of the core components and extensions to VS Code live in their own repositories on GitHub. For example, the [node debug adapter](https://github.com/microsoft/vscode-node-debug) and the [mono debug adapter](https://github.com/microsoft/vscode-mono-debug) repositories are separate from each other. For a complete list, please visit the [Related Projects](https://github.com/microsoft/vscode/wiki/Related-Projects) page on our [wiki](https://github.com/microsoft/vscode/wiki).\n\n## Bundled Extensions\n\nVS Code includes a set of built-in extensions located in the [extensions](extensions) folder, including grammars and snippets for many languages. Extensions that provide rich language support (inline suggestions, Go to Definition) for a language have the suffix `language-features`. For example, the `json` extension provides coloring for `JSON` and the `json-language-features` extension provides rich language support for `JSON`.\n\n## Development Container\n\nThis repository includes a Visual Studio Code Dev Containers / GitHub Codespaces development container.\n\n* For [Dev Containers](https://aka.ms/vscode-remote/download/containers), use the **Dev Containers: Clone Repository in Container Volume...** command which creates a Docker volume for better disk I/O on macOS and Windows.\n  * If you already have VS Code and Docker installed, you can also click [here](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/vscode) to get started. This will cause VS Code to automatically install the Dev Containers extension if needed, clone the source code into a container volume, and spin up a dev container for use.\n\n* For Codespaces, install the [GitHub Codespaces](https://marketplace.visualstudio.com/items?itemName=GitHub.codespaces) extension in VS Code, and use the **Codespaces: Create New Codespace** command.\n\nDocker / the Codespace should have at least **4 Cores and 6 GB of RAM (8 GB recommended)** to run a full build. See the [development container README](.devcontainer/README.md) for more information.\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## License\n\nCopyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the [MIT](LICENSE.txt) license.\n",
      "stars_today": 59
    },
    {
      "id": 846698999,
      "name": "goose",
      "full_name": "block/goose",
      "description": "an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM",
      "html_url": "https://github.com/block/goose",
      "stars": 30026,
      "forks": 2714,
      "language": "Rust",
      "topics": [
        "mcp"
      ],
      "created_at": "2024-08-23T19:03:36Z",
      "updated_at": "2026-02-07T02:33:40Z",
      "pushed_at": "2026-02-07T01:58:42Z",
      "open_issues": 348,
      "owner": {
        "login": "block",
        "avatar_url": "https://avatars.githubusercontent.com/u/185116535?v=4"
      },
      "readme": "<div align=\"center\">\n\n# goose\n\n_a local, extensible, open source AI agent that automates engineering tasks_\n\n<p align=\"center\">\n  <a href=\"https://opensource.org/licenses/Apache-2.0\">\n    <img src=\"https://img.shields.io/badge/License-Apache_2.0-blue.svg\">\n  </a>\n  <a href=\"https://discord.gg/goose-oss\">\n    <img src=\"https://img.shields.io/discord/1287729918100246654?logo=discord&logoColor=white&label=Join+Us&color=blueviolet\" alt=\"Discord\">\n  </a>\n  <a href=\"https://github.com/block/goose/actions/workflows/ci.yml\">\n     <img src=\"https://img.shields.io/github/actions/workflow/status/block/goose/ci.yml?branch=main\" alt=\"CI\">\n  </a>\n</p>\n</div>\n\ngoose is your on-machine AI agent, capable of automating complex development tasks from start to finish. More than just code suggestions, goose can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows, and interact with external APIs - _autonomously_.\n\nWhether you're prototyping an idea, refining existing code, or managing intricate engineering pipelines, goose adapts to your workflow and executes tasks with precision.\n\nDesigned for maximum flexibility, goose works with any LLM and supports multi-model configuration to optimize performance and cost, seamlessly integrates with MCP servers, and is available as both a desktop app as well as CLI - making it the ultimate AI assistant for developers who want to move faster and focus on innovation.\n\n[![Watch the video](https://github.com/user-attachments/assets/ddc71240-3928-41b5-8210-626dfb28af7a)](https://youtu.be/D-DpDunrbpo)\n\n# Quick Links\n- [Quickstart](https://block.github.io/goose/docs/quickstart)\n- [Installation](https://block.github.io/goose/docs/getting-started/installation)\n- [Tutorials](https://block.github.io/goose/docs/category/tutorials)\n- [Documentation](https://block.github.io/goose/docs/category/getting-started)\n- [Responsible AI-Assisted Coding Guide](https://github.com/block/goose/blob/main/HOWTOAI.md)\n- [Governance](https://github.com/block/goose/blob/main/GOVERNANCE.md)\n\n## Need Help?\n- [Diagnostics & Reporting](https://block.github.io/goose/docs/troubleshooting/diagnostics-and-reporting)\n- [Known Issues](https://block.github.io/goose/docs/troubleshooting/known-issues)\n\n# a little goose humor ğŸ¦¢\n\n> Why did the developer choose goose as their AI agent?\n> \n> Because it always helps them \"migrate\" their code to production! ğŸš€\n\n# goose around with us  \n- [Discord](https://discord.gg/goose-oss)\n- [YouTube](https://www.youtube.com/@goose-oss)\n- [LinkedIn](https://www.linkedin.com/company/goose-oss)\n- [Twitter/X](https://x.com/goose_oss)\n- [Bluesky](https://bsky.app/profile/opensource.block.xyz)\n- [Nostr](https://njump.me/opensource@block.xyz)\n",
      "stars_today": 54
    },
    {
      "id": 907990001,
      "name": "fresh",
      "full_name": "sinelaw/fresh",
      "description": "Terminal based IDE & text editor: easy, powerful and fast",
      "html_url": "https://github.com/sinelaw/fresh",
      "stars": 5737,
      "forks": 201,
      "language": "Rust",
      "topics": [
        "ide",
        "terminal-based",
        "text-editor"
      ],
      "created_at": "2024-12-24T19:50:15Z",
      "updated_at": "2026-02-07T00:17:31Z",
      "pushed_at": "2026-02-06T14:43:07Z",
      "open_issues": 107,
      "owner": {
        "login": "sinelaw",
        "avatar_url": "https://avatars.githubusercontent.com/u/84020?v=4"
      },
      "readme": "# Fresh\n\nA terminal-based text editor. [Official Website â†’](https://sinelaw.github.io/fresh/)\n\n**[ğŸ“¦ Installation Instructions](#installation)**\n\n**[Contributing](#contributing)**\n\n## Why?\n\nWhy another text editor? Fresh brings the intuitive, conventional UX of editors like VS Code and Sublime Text to the terminal.\n\nWhile veterans like Emacs and Vim - and newer editors like Neovim and Helix - are excellent for power users who prefer modal, highly specialized workflows, they often present a steep learning curve for those used to standard GUI interactions. Fresh is built for the developer who wants a familiar, non-modal experience out-of-the-box, without sacrificing the speed and portability of the command line. Keyboard bindings, mouse support, menus, command palette etc. are all designed to be familiar to most modern users.\n\nArchitecturally, Fresh is built to handle multi-gigabyte files or slow network streams efficiently, maintaining a negligible memory overhead regardless of file size. While traditional editors struggle with latency and RAM bloat on large files, Fresh delivers consistent, high-speed performance on any scale.\n\nThe goal for Fresh is to be an intuitive and accessible, high-performance terminal-based editor that \"just works\" on any hardware, for everyone.\n\n## Discovery & Ease of Use\n\nFresh is designed for discovery. It features native UIs, a full Menu system, and a powerful Command Palette. With full mouse support, transitioning from graphical editors is seamless.\n\n## Modern Extensibility\n\nExtend Fresh easily using modern tools. Plugins are written in TypeScript and run securely in a sandboxed Deno environment, providing access to a modern JavaScript ecosystem without compromising stability.\n\n## Low-Latency Performance\n\nFresh is engineered for speed. It delivers a low-latency experience, with text appearing instantly. The editor is designed to be light and fast, reliably opening and editing [huge files up to multi-gigabyte sizes](https://noamlewis.com/blog/2025/12/09/how-fresh-loads-huge-files-fast) without slowdown.\n\n## Comprehensive Feature Set\n\n- **File Management**: open/save/new/close, file explorer, tabs, auto-revert, git file finder\n- **Editing**: undo/redo, multi-cursor, block selection, smart indent, comments, clipboard\n- **Search & Replace**: incremental search, find in selection, query replace, git grep\n- **Navigation**: go to line/bracket, word movement, position history, bookmarks, error navigation\n- **Views & Layout**: split panes, line numbers, line wrap, backgrounds, markdown preview\n- **Language Server (LSP)**: go to definition, references, hover, code actions, rename, diagnostics, autocompletion\n- **Productivity**: command palette, menu bar, keyboard macros, git log, diagnostics panel\n- **Plugins & Extensibility**: TypeScript plugins, color highlighter, TODO highlighter, merge conflicts, path complete, keymaps\n- **Internationalization**: Multiple language support (see [`locales/`](locales/) for available languages), plugin translation system\n\n![Fresh Demo](docs/fresh-demo2.gif)\n![Fresh Screenshot](docs/public/images/screenshot1.png)\n![Fresh Screenshot](docs/public/images/screenshot2.png)\n![Fresh Screenshot](docs/public/images/screenshot3.png)\n\n## Installation\n\nQuick install (autodetect best method):\n\n`curl https://raw.githubusercontent.com/sinelaw/fresh/refs/heads/master/scripts/install.sh | sh`\n\nOr, pick your preferred method:\n\n| Platform | Method |\n|----------|--------|\n| macOS | [brew](#brew) |\n| Bazzite/Bluefin/Aurora Linux | [brew](#brew) |\n| Arch Linux | [AUR](#arch-linux-aur) |\n| Debian/Ubuntu | [.deb](#debianubuntu-deb) |\n| Fedora/RHEL | [.rpm](#fedorarhelopensuse-rpm), [Terra](https://terra.fyralabs.com/) |\n| FreeBSD | [ports / pkg](https://www.freshports.org/editors/fresh) |\n| Linux (any distro) | [AppImage](#appimage), [Flatpak](#flatpak) |\n| All platforms | [Pre-built binaries](#pre-built-binaries) |\n| npm | [npm / npx](#npm) |\n| Rust users (Fast) | [cargo-binstall](#using-cargo-binstall) |\n| Rust users | [crates.io](#from-cratesio) |\n| Nix | [Nix flakes](#nix-flakes) |\n| Developers | [From source](#from-source) |\n\n### Brew\n\nOn macOS and some linux distros (Bazzite/Bluefin/Aurora):\n\n> **Note:** On macOS, see [macOS Terminal Tips](https://getfresh.dev/docs/configuration/keyboard#macos-terminal-tips) for recommended terminal configuration.\n\n```bash\nbrew tap sinelaw/fresh\nbrew install fresh-editor\n```\n\n### Arch Linux ([AUR](https://aur.archlinux.org/packages/fresh-editor-bin))\n\n**Binary package (recommended, faster install):**\n\n```bash\ngit clone https://aur.archlinux.org/fresh-editor-bin.git\ncd fresh-editor-bin\nmakepkg --syncdeps --install\n```\n\n**Build from source:**\n\n```bash\ngit clone https://aur.archlinux.org/fresh-editor.git\ncd fresh-editor\nmakepkg --syncdeps --install\n```\n\n**Using an AUR helper (such as `yay` or `paru`):**\n\n```bash\n# Binary package (recommended, faster install)\nyay -S fresh-editor-bin\n\n# Or build from source\nyay -S fresh-editor\n```\n\n### Debian/Ubuntu (.deb)\n\nDownload and install the latest release:\n\n```bash\ncurl -sL $(curl -s https://api.github.com/repos/sinelaw/fresh/releases/latest | grep \"browser_download_url.*_$(dpkg --print-architecture)\\.deb\" | cut -d '\"' -f 4) -o fresh-editor.deb && sudo dpkg -i fresh-editor.deb\n```\n\nOr download the `.deb` file manually from the [releases page](https://github.com/sinelaw/fresh/releases).\n\n### Fedora/RHEL/openSUSE (.rpm)\n\nDownload and install the latest release:\n\n```bash\ncurl -sL $(curl -s https://api.github.com/repos/sinelaw/fresh/releases/latest | grep \"browser_download_url.*\\.$(uname -m)\\.rpm\" | cut -d '\"' -f 4) -o fresh-editor.rpm && sudo rpm -U fresh-editor.rpm\n```\n\nOr download the `.rpm` file manually from the [releases page](https://github.com/sinelaw/fresh/releases).\n\n### AppImage\n\nDownload the `.AppImage` file from the [releases page](https://github.com/sinelaw/fresh/releases) and run:\n\n```bash\nchmod +x fresh-editor-VERSION-x86_64.AppImage\n./fresh-editor-VERSION-x86_64.AppImage\n```\n\n**For faster startup** (recommended): Extract the AppImage instead of running it directly. This avoids the FUSE mount overhead on each launch (~10x faster):\n\n```bash\n./fresh-editor-VERSION-x86_64.AppImage --appimage-extract\nmkdir -p ~/.local/share/fresh-editor ~/.local/bin\nmv squashfs-root/* ~/.local/share/fresh-editor/\nln -sf ~/.local/share/fresh-editor/usr/bin/fresh ~/.local/bin/fresh\n```\n\nEnsure `~/.local/bin` is in your PATH. Available for x86_64 and aarch64 architectures.\n\n### Flatpak\n\nDownload the `.flatpak` bundle from the [releases page](https://github.com/sinelaw/fresh/releases) and install:\n\n```bash\nflatpak install --user fresh-editor-VERSION-x86_64.flatpak\nflatpak run io.github.sinelaw.fresh\n```\n\nSee [flatpak/README.md](flatpak/README.md) for building from source.\n\n### Pre-built binaries\n\nDownload the latest release for your platform from the [releases page](https://github.com/sinelaw/fresh/releases).\n\n### npm\n\n```bash\nnpm install -g @fresh-editor/fresh-editor\n```\n\nOr try it without installing:\n\n```bash\nnpx @fresh-editor/fresh-editor\n```\n\n### Using cargo-binstall\n\nTo install the binary directly without compiling (much faster than crates.io):\n\nFirst, install cargo-binstall if you haven't already\n\n```bash\ncargo install cargo-binstall\n```\n\nThen install fresh\n\n```bash\ncargo binstall fresh-editor\n```\n\n### Nix flakes\n\nRun without installing:\n```bash\nnix run github:sinelaw/fresh\n```\n\nOr install to your profile:\n```bash\nnix profile add github:sinelaw/fresh\n```\n\n### From crates.io\n\n```bash\ncargo install fresh-editor\n```\n\n### From source\n\n```bash\ngit clone https://github.com/sinelaw/fresh.git\ncd fresh\ncargo build --release\n./target/release/fresh [file]\n```\n\n## Documentation\n\n- [User Guide](https://getfresh.dev/docs)\n- [macOS Tips](https://getfresh.dev/docs/configuration/keyboard#macos-terminal-tips) - Terminal configuration, keyboard shortcuts, and troubleshooting for Mac users\n- [Plugin Development](https://getfresh.dev/docs/plugins/development)\n\n## Contributing\n\nThanks for contributing!\n\n1. **Reproduce Before Fixing**: Always include a test case that reproduces the bug (fails) without the fix, and passes with the fix. This ensures the issue is verified and prevents future regressions.\n\n2. **E2E Tests for New Flows**: Any new user flow or feature must include an end-to-end (e2e) test. E2E tests send keyboard/mouse events and examines the final rendered output, do not examine internal state.\n\n3. **No timeouts or time-sensitive tests**: Use \"semantic waiting\" (waiting for specific state changes/events) instead of fixed timers to ensure test stability. Wait indefinitely, don't put timeouts inside tests (cargo nextest will timeout externally).\n\n4. **Test isolation**: Tests should run in parallel. Use the internal clipboard mode in tests to isolate them from the host system and prevent flakiness in CI. Same for other external resources (temp files, etc. should all be isolated between tests, under a per-test temporary workdir).\n\n5. **Required Formatting**: All code must be formatted with `cargo fmt` before submission. PRs that fail formatting checks will not be merged.\n\n6. **Cross-Platform Consistency**: Avoid hard-coding newline or CRLF related logic, consider the buffer mode.\n\n7. **LSP**: Ensure LSP interactions follow the correct lifecycle (e.g., `didOpen` must always precede other requests to avoid server-side errors). Use the appropriate existing helpers for this pattern.\n\n8. **Regenerate plugin types and schemas**: After modifying the plugin API or config types:\n   - **TypeScript definitions** (`plugins/lib/fresh.d.ts`): Auto-generated from Rust types with `#[derive(TS)]`. Run: `cargo test -p fresh-plugin-runtime write_fresh_dts_file -- --ignored`\n   - **JSON schemas** (`plugins/config-schema.json`, `plugins/schemas/theme.schema.json`): Auto-generated from Rust types with `#[derive(JsonSchema)]`. Run: `./scripts/gen_schema.sh`\n   - **Package schema** (`plugins/schemas/package.schema.json`): Manually maintained - edit directly when adding new language pack fields\n\n9. **Type check plugins**: Run `crates/fresh-editor/plugins/check-types.sh` (requires `tsc`)\n\n**Tip**: You can use tmux + send-keys + render-pane to script ad-hoc tests on the UI, for example when trying to reproduce an issue.\n\n## Privacy\n\nFresh checks for new versions daily to notify you of available upgrades. Alongside this, it sends basic anonymous telemetry (version, OS/architecture, terminal type) to help understand usage patterns. No personal data or file contents are collected.\n\nTo disable both upgrade checks and telemetry, use `--no-upgrade-check` or set `check_for_updates: false` in your config.\n\n## License\n\nCopyright (c) Noam Lewis\n\nThis project is licensed under the GNU General Public License v2.0 (GPL-2.0).\n",
      "stars_today": 50
    },
    {
      "id": 649170660,
      "name": "anything-llm",
      "full_name": "Mintplex-Labs/anything-llm",
      "description": "The all-in-one Desktop & Docker AI application with built-in RAG, AI agents, No-code agent builder, MCP compatibility,  and more.",
      "html_url": "https://github.com/Mintplex-Labs/anything-llm",
      "stars": 54274,
      "forks": 5842,
      "language": "JavaScript",
      "topics": [
        "ai-agents",
        "custom-ai-agents",
        "deepseek",
        "kimi",
        "llama3",
        "llm",
        "lmstudio",
        "local-llm",
        "localai",
        "mcp",
        "mcp-servers",
        "moonshot",
        "multimodal",
        "no-code",
        "ollama",
        "qwen3",
        "rag",
        "vector-database",
        "web-scraping"
      ],
      "created_at": "2023-06-04T02:29:14Z",
      "updated_at": "2026-02-07T02:17:07Z",
      "pushed_at": "2026-02-07T00:13:09Z",
      "open_issues": 274,
      "owner": {
        "login": "Mintplex-Labs",
        "avatar_url": "https://avatars.githubusercontent.com/u/134426827?v=4"
      },
      "readme": "<a name=\"readme-top\"></a>\n\n<p align=\"center\">\n  <a href=\"https://anythingllm.com\"><img src=\"https://github.com/Mintplex-Labs/anything-llm/blob/master/images/wordmark.png?raw=true\" alt=\"AnythingLLM logo\"></a>\n</p>\n\n<div align='center'>\n<a href=\"https://trendshift.io/repositories/2415\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/2415\" alt=\"Mintplex-Labs%2Fanything-llm | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</div>\n\n<p align=\"center\">\n    <b>AnythingLLM:</b> The all-in-one AI app you were looking for.<br />\n    Chat with your docs, use AI Agents, hyper-configurable, multi-user, & no frustrating setup required.\n</p>\n\n<p align=\"center\">\n  <a href=\"https://discord.gg/6UyHPeGZAC\" target=\"_blank\">\n      <img src=\"https://img.shields.io/badge/chat-mintplex_labs-blue.svg?style=flat&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAMAAABEpIrGAAAAIGNIUk0AAHomAACAhAAA+gAAAIDoAAB1MAAA6mAAADqYAAAXcJy6UTwAAAH1UExURQAAAP////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////r6+ubn5+7u7/3+/v39/enq6urq6/v7+97f39rb26eoqT1BQ0pOT4+Rkuzs7cnKykZKS0NHSHl8fdzd3ejo6UxPUUBDRdzc3RwgIh8jJSAkJm5xcvHx8aanqB4iJFBTVezt7V5hYlJVVuLj43p9fiImKCMnKZKUlaaoqSElJ21wcfT09O3u7uvr6zE0Nr6/wCUpK5qcnf7+/nh7fEdKTHx+f0tPUOTl5aipqiouMGtubz5CRDQ4OsTGxufn515hY7a3uH1/gXBydIOFhlVYWvX29qaoqCQoKs7Pz/Pz87/AwUtOUNfY2dHR0mhrbOvr7E5RUy8zNXR2d/f39+Xl5UZJSx0hIzQ3Odra2/z8/GlsbaGjpERHSezs7L/BwScrLTQ4Odna2zM3Obm7u3x/gKSmp9jZ2T1AQu/v71pdXkVISr2+vygsLiInKTg7PaOlpisvMcXGxzk8PldaXPLy8u7u7rm6u7S1tsDBwvj4+MPExbe4ueXm5s/Q0Kyf7ewAAAAodFJOUwAABClsrNjx/QM2l9/7lhmI6jTB/kA1GgKJN+nea6vy/MLZQYeVKK3rVA5tAAAAAWJLR0QB/wIt3gAAAAd0SU1FB+cKBAAmMZBHjXIAAAISSURBVDjLY2CAAkYmZhZWNnYODnY2VhZmJkYGVMDIycXNw6sBBbw8fFycyEoYGfkFBDVQgKAAPyMjQl5IWEQDDYgIC8FUMDKKsmlgAWyiEBWMjGJY5YEqxMAqGMWFNXAAYXGgAkYJSQ2cQFKCkYFRShq3AmkpRgYJbghbU0tbB0Tr6ukbgGhDI10gySfBwCwDUWBsYmpmDqQtLK2sbTQ0bO3sHYA8GWYGWWj4WTs6Obu4ami4OTm7exhqeHp5+4DCVJZBDmqdr7ufn3+ArkZgkJ+fU3CIRmgYWFiOARYGvo5OQUHhEUAFTkF+kVHRsLBgkIeyYmLjwoOc4hMSk5JTnINS06DC8gwcEEZ6RqZGlpOfc3ZObl5+gZ+TR2ERWFyBQQFMF5eklmqUpQb5+ReU61ZUOvkFVVXXQBSAraitq29o1GiKcfLzc29u0mjxBzq0tQ0kww5xZHtHUGeXhkZhdxBYgZ4d0LI6c4gjwd7siQQraOp1AivQ6CuAKZCDBBRQQQNQgUb/BGf3cqCCiZOcnCe3QQIKHNRTpk6bDgpZjRkzg3pBQTBrdtCcuZCgluAD0vPmL1gIdvSixUuWgqNs2YJ+DUhkEYxuggkGmOQUcckrioPTJCOXEnZ5JS5YslbGnuyVERlDDFvGEUPOWvwqaH6RVkHKeuDMK6SKnHlVhTgx8jeTmqy6Eij7K6nLqiGyPwChsa1MUrnq1wAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAyMy0xMC0wNFQwMDozODo0OSswMDowMB9V0a8AAAAldEVYdGRhdGU6bW9kaWZ5ADIwMjMtMTAtMDRUMDA6Mzg6NDkrMDA6MDBuCGkTAAAAKHRFWHRkYXRlOnRpbWVzdGFtcAAyMDIzLTEwLTA0VDAwOjM4OjQ5KzAwOjAwOR1IzAAAAABJRU5ErkJggg==\" alt=\"Discord\">\n  </a> |\n  <a href=\"https://github.com/Mintplex-Labs/anything-llm/blob/master/LICENSE\" target=\"_blank\">\n      <img src=\"https://img.shields.io/static/v1?label=license&message=MIT&color=white\" alt=\"License\">\n  </a> |\n  <a href=\"https://docs.anythingllm.com\" target=\"_blank\">\n    Docs\n  </a> |\n   <a href=\"https://my.mintplexlabs.com/aio-checkout?product=anythingllm\" target=\"_blank\">\n    Hosted Instance\n  </a>\n</p>\n\n<p align=\"center\">\n  <b>English</b> Â· <a href='./locales/README.zh-CN.md'>ç®€ä½“ä¸­æ–‡</a> Â· <a href='./locales/README.ja-JP.md'>æ—¥æœ¬èª</a>\n</p>\n\n<p align=\"center\">\nğŸ‘‰ AnythingLLM for desktop (Mac, Windows, & Linux)! <a href=\"https://anythingllm.com/download\" target=\"_blank\"> Download Now</a>\n</p>\n\nA full-stack application that enables you to turn any document, resource, or piece of content into context that any LLM can use as a reference during chatting. This application allows you to pick and choose which LLM or Vector Database you want to use as well as supporting multi-user management and permissions.\n\n![Chatting](https://github.com/Mintplex-Labs/anything-llm/assets/16845892/cfc5f47c-bd91-4067-986c-f3f49621a859)\n\n<details>\n<summary><kbd>Watch the demo!</kbd></summary>\n\n[![Watch the video](/images/youtube.png)](https://youtu.be/f95rGD9trL0)\n\n</details>\n\n### Product Overview\n\nAnythingLLM is a full-stack application where you can use commercial off-the-shelf LLMs or popular open source LLMs and vectorDB solutions to build a private ChatGPT with no compromises that you can run locally as well as host remotely and be able to chat intelligently with any documents you provide it.\n\nAnythingLLM divides your documents into objects called `workspaces`. A Workspace functions a lot like a thread, but with the addition of containerization of your documents. Workspaces can share documents, but they do not talk to each other so you can keep your context for each workspace clean.\n\n## Cool features of AnythingLLM\n\n- ğŸ†• [**Full MCP-compatibility**](https://docs.anythingllm.com/mcp-compatibility/overview)\n- ğŸ†• [**No-code AI Agent builder**](https://docs.anythingllm.com/agent-flows/overview)\n- ğŸ–¼ï¸ **Multi-modal support (both closed and open-source LLMs!)**\n- [**Custom AI Agents**](https://docs.anythingllm.com/agent/custom/introduction)\n- ğŸ‘¤ Multi-user instance support and permissioning _Docker version only_\n- ğŸ¦¾ Agents inside your workspace (browse the web, etc)\n- ğŸ’¬ [Custom Embeddable Chat widget for your website](https://github.com/Mintplex-Labs/anythingllm-embed/blob/main/README.md) _Docker version only_\n- ğŸ“– Multiple document type support (PDF, TXT, DOCX, etc)\n- Simple chat UI with Drag-n-Drop functionality and clear citations.\n- 100% Cloud deployment ready.\n- Works with all popular [closed and open-source LLM providers](#supported-llms-embedder-models-speech-models-and-vector-databases).\n- Built-in cost & time-saving measures for managing very large documents compared to any other chat UI.\n- Full Developer API for custom integrations!\n- Much more...install and find out!\n\n### Supported LLMs, Embedder Models, Speech models, and Vector Databases\n\n**Large Language Models (LLMs):**\n\n- [Any open-source llama.cpp compatible model](/server/storage/models/README.md#text-generation-llm-selection)\n- [OpenAI](https://openai.com)\n- [OpenAI (Generic)](https://openai.com)\n- [Azure OpenAI](https://azure.microsoft.com/en-us/products/ai-services/openai-service)\n- [AWS Bedrock](https://aws.amazon.com/bedrock/)\n- [Anthropic](https://www.anthropic.com/)\n- [NVIDIA NIM (chat models)](https://build.nvidia.com/explore/discover)\n- [Google Gemini Pro](https://ai.google.dev/)\n- [Hugging Face (chat models)](https://huggingface.co/)\n- [Ollama (chat models)](https://ollama.ai/)\n- [LM Studio (all models)](https://lmstudio.ai)\n- [LocalAI (all models)](https://localai.io/)\n- [Together AI (chat models)](https://www.together.ai/)\n- [Fireworks AI (chat models)](https://fireworks.ai/)\n- [Perplexity (chat models)](https://www.perplexity.ai/)\n- [OpenRouter (chat models)](https://openrouter.ai/)\n- [DeepSeek (chat models)](https://deepseek.com/)\n- [Mistral](https://mistral.ai/)\n- [Groq](https://groq.com/)\n- [Cohere](https://cohere.com/)\n- [KoboldCPP](https://github.com/LostRuins/koboldcpp)\n- [LiteLLM](https://github.com/BerriAI/litellm)\n- [Text Generation Web UI](https://github.com/oobabooga/text-generation-webui)\n- [Apipie](https://apipie.ai/)\n- [xAI](https://x.ai/)\n- [Z.AI (chat models)](https://z.ai/model-api)\n- [Novita AI (chat models)](https://novita.ai/model-api/product/llm-api?utm_source=github_anything-llm&utm_medium=github_readme&utm_campaign=link)\n- [PPIO](https://ppinfra.com?utm_source=github_anything-llm)\n- [Gitee AI](https://ai.gitee.com/)\n- [Moonshot AI](https://www.moonshot.ai/)\n- [Microsoft Foundry Local](https://github.com/microsoft/Foundry-Local)\n- [CometAPI (chat models)](https://api.cometapi.com/)\n- [Docker Model Runner](https://docs.docker.com/ai/model-runner/)\n- [PrivateModeAI (chat models)](https://privatemode.ai/)\n- [SambaNova Cloud (chat models)](https://cloud.sambanova.ai/)\n\n**Embedder models:**\n\n- [AnythingLLM Native Embedder](/server/storage/models/README.md) (default)\n- [OpenAI](https://openai.com)\n- [Azure OpenAI](https://azure.microsoft.com/en-us/products/ai-services/openai-service)\n- [LocalAI (all)](https://localai.io/)\n- [Ollama (all)](https://ollama.ai/)\n- [LM Studio (all)](https://lmstudio.ai)\n- [Cohere](https://cohere.com/)\n\n**Audio Transcription models:**\n\n- [AnythingLLM Built-in](https://github.com/Mintplex-Labs/anything-llm/tree/master/server/storage/models#audiovideo-transcription) (default)\n- [OpenAI](https://openai.com/)\n\n**TTS (text-to-speech) support:**\n\n- Native Browser Built-in (default)\n- [PiperTTSLocal - runs in browser](https://github.com/rhasspy/piper)\n- [OpenAI TTS](https://platform.openai.com/docs/guides/text-to-speech/voice-options)\n- [ElevenLabs](https://elevenlabs.io/)\n- Any OpenAI Compatible TTS service.\n\n**STT (speech-to-text) support:**\n\n- Native Browser Built-in (default)\n\n**Vector Databases:**\n\n- [LanceDB](https://github.com/lancedb/lancedb) (default)\n- [PGVector](https://github.com/pgvector/pgvector)\n- [Astra DB](https://www.datastax.com/products/datastax-astra)\n- [Pinecone](https://pinecone.io)\n- [Chroma & ChromaCloud](https://trychroma.com)\n- [Weaviate](https://weaviate.io)\n- [Qdrant](https://qdrant.tech)\n- [Milvus](https://milvus.io)\n- [Zilliz](https://zilliz.com)\n\n### Technical Overview\n\nThis monorepo consists of six main sections:\n\n- `frontend`: A viteJS + React frontend that you can run to easily create and manage all your content the LLM can use.\n- `server`: A NodeJS express server to handle all the interactions and do all the vectorDB management and LLM interactions.\n- `collector`: NodeJS express server that processes and parses documents from the UI.\n- `docker`: Docker instructions and build process + information for building from source.\n- `embed`: Submodule for generation & creation of the [web embed widget](https://github.com/Mintplex-Labs/anythingllm-embed).\n- `browser-extension`: Submodule for the [chrome browser extension](https://github.com/Mintplex-Labs/anythingllm-extension).\n\n## ğŸ›³ Self-Hosting\n\nMintplex Labs & the community maintain a number of deployment methods, scripts, and templates that you can use to run AnythingLLM locally. Refer to the table below to read how to deploy on your preferred environment or to automatically deploy.\n| Docker | AWS | GCP | Digital Ocean | Render.com |\n|----------------------------------------|----|-----|---------------|------------|\n| [![Deploy on Docker][docker-btn]][docker-deploy] | [![Deploy on AWS][aws-btn]][aws-deploy] | [![Deploy on GCP][gcp-btn]][gcp-deploy] | [![Deploy on DigitalOcean][do-btn]][do-deploy] | [![Deploy on Render.com][render-btn]][render-deploy] |\n\n| Railway                                             | RepoCloud                                                 | Elestio                                             | Northflank                                                   |\n| --------------------------------------------------- | --------------------------------------------------------- | --------------------------------------------------- | ------------------------------------------------------------ |\n| [![Deploy on Railway][railway-btn]][railway-deploy] | [![Deploy on RepoCloud][repocloud-btn]][repocloud-deploy] | [![Deploy on Elestio][elestio-btn]][elestio-deploy] | [![Deploy on Northflank][northflank-btn]][northflank-deploy] |\n\n[or set up a production AnythingLLM instance without Docker â†’](./BARE_METAL.md)\n\n## How to setup for development\n\n- `yarn setup` To fill in the required `.env` files you'll need in each of the application sections (from root of repo).\n  - Go fill those out before proceeding. Ensure `server/.env.development` is filled or else things won't work right.\n- `yarn dev:server` To boot the server locally (from root of repo).\n- `yarn dev:frontend` To boot the frontend locally (from root of repo).\n- `yarn dev:collector` To then run the document collector (from root of repo).\n\n[Learn about documents](./server/storage/documents/DOCUMENTS.md)\n\n[Learn about vector caching](./server/storage/vector-cache/VECTOR_CACHE.md)\n\n## External Apps & Integrations\n\n_These are apps that are not maintained by Mintplex Labs, but are compatible with AnythingLLM. A listing here is not an endorsement._\n\n- [Midori AI Subsystem Manager](https://io.midori-ai.xyz/subsystem/anythingllm/) - A streamlined and efficient way to deploy AI systems using Docker container technology.\n- [Coolify](https://coolify.io/docs/services/anythingllm/) - Deploy AnythingLLM with a single click.\n- [GPTLocalhost for Microsoft Word](https://gptlocalhost.com/demo/) - A local Word Add-in for you to use AnythingLLM in Microsoft Word.\n\n## Telemetry & Privacy\n\nAnythingLLM by Mintplex Labs Inc contains a telemetry feature that collects anonymous usage information.\n\n<details>\n<summary><kbd>More about Telemetry & Privacy for AnythingLLM</kbd></summary>\n\n### Why?\n\nWe use this information to help us understand how AnythingLLM is used, to help us prioritize work on new features and bug fixes, and to help us improve AnythingLLM's performance and stability.\n\n### Opting out\n\nSet `DISABLE_TELEMETRY` in your server or docker .env settings to \"true\" to opt out of telemetry. You can also do this in-app by going to the sidebar > `Privacy` and disabling telemetry.\n\n### What do you explicitly track?\n\nWe will only track usage details that help us make product and roadmap decisions, specifically:\n\n- Type of your installation (Docker or Desktop)\n\n- When a document is added or removed. No information _about_ the document. Just that the event occurred. This gives us an idea of use.\n\n- Type of vector database in use. This helps us prioritize changes when updates arrive for that provider.\n\n- Type of LLM provider & model tag in use. This helps us prioritize changes when updates arrive for that provider or model, or combination thereof. eg: reasoning vs regular, multi-modal models, etc.\n\n- When a chat is sent. This is the most regular \"event\" and gives us an idea of the daily-activity of this project across all installations. Again, only the **event** is sent - we have no information on the nature or content of the chat itself.\n\nYou can verify these claims by finding all locations `Telemetry.sendTelemetry` is called. Additionally these events are written to the output log so you can also see the specific data which was sent - if enabled. **No IP or other identifying information is collected**. The Telemetry provider is [PostHog](https://posthog.com/) - an open-source telemetry collection service.\n\nWe take privacy very seriously, and we hope you understand that we want to learn how our tool is used, without using annoying popup surveys, so we can build something worth using. The anonymous data is _never_ shared with third parties, ever.\n\n[View all telemetry events in source code](https://github.com/search?q=repo%3AMintplex-Labs%2Fanything-llm%20.sendTelemetry(&type=code)\n\n</details>\n\n## ğŸ‘‹ Contributing\n\n- [Contributing to AnythingLLM](./CONTRIBUTING.md) - How to contribute to AnythingLLM.\n\n## ğŸ’– Sponsors\n\n### Premium Sponsors\n\n<!-- premium-sponsors (reserved for $100/mth sponsors who request to be called out here and/or are non-private sponsors) -->\n<a href=\"https://www.dcsdigital.co.uk\" target=\"_blank\">\n  <img src=\"https://a8cforagenciesportfolio.wordpress.com/wp-content/uploads/2024/08/logo-image-232621379.png\" height=\"100px\" alt=\"User avatar: DCS DIGITAL\" />\n</a>\n<!-- premium-sponsors -->\n\n### All Sponsors\n\n<!-- all-sponsors --><a href=\"https://github.com/jaschadub\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;jaschadub.png\" width=\"60px\" alt=\"User avatar: Jascha\" /></a><a href=\"https://github.com/KickingAss2024\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;KickingAss2024.png\" width=\"60px\" alt=\"User avatar: KickAss\" /></a><a href=\"https://github.com/ShadowArcanist\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;ShadowArcanist.png\" width=\"60px\" alt=\"User avatar: ShadowArcanist\" /></a><a href=\"https://github.com/AtlasVIA\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;AtlasVIA.png\" width=\"60px\" alt=\"User avatar: Atlas\" /></a><a href=\"https://github.com/cope\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;cope.png\" width=\"60px\" alt=\"User avatar: Predrag StojadinoviÄ‡\" /></a><a href=\"https://github.com/DiegoSpinola\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;DiegoSpinola.png\" width=\"60px\" alt=\"User avatar: Diego Spinola\" /></a><a href=\"https://github.com/PortlandKyGuy\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;PortlandKyGuy.png\" width=\"60px\" alt=\"User avatar: Kyle\" /></a><a href=\"https://github.com/peperunas\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;peperunas.png\" width=\"60px\" alt=\"User avatar: Giulio De Pasquale\" /></a><a href=\"https://github.com/jasoncdavis0\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;jasoncdavis0.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/macstadium\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;macstadium.png\" width=\"60px\" alt=\"User avatar: MacStadium\" /></a><a href=\"https://github.com/armlynobinguar\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;armlynobinguar.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/MikeHago\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;MikeHago.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/maaisde\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;maaisde.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/mhollier117\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;mhollier117.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/pleabargain\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;pleabargain.png\" width=\"60px\" alt=\"User avatar: Dennis\" /></a><a href=\"https://github.com/broichan\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;broichan.png\" width=\"60px\" alt=\"User avatar: Michael Hamilton, Ph.D.\" /></a><a href=\"https://github.com/azim-charaniya\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;azim-charaniya.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/gabriellemon\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;gabriellemon.png\" width=\"60px\" alt=\"User avatar: TernaryLabs\" /></a><a href=\"https://github.com/CelaDaniel\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;CelaDaniel.png\" width=\"60px\" alt=\"User avatar: Daniel Cela\" /></a><a href=\"https://github.com/altrsadmin\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;altrsadmin.png\" width=\"60px\" alt=\"User avatar: Alesso\" /></a><a href=\"https://github.com/bitjungle\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;bitjungle.png\" width=\"60px\" alt=\"User avatar: Rune Mathisen\" /></a><a href=\"https://github.com/pcrossleyAC\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;pcrossleyAC.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/saroj-pattnaik\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;saroj-pattnaik.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/techmedic5\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;techmedic5.png\" width=\"60px\" alt=\"User avatar: Alan\" /></a><a href=\"https://github.com/ddocta\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;ddocta.png\" width=\"60px\" alt=\"User avatar: Damien Peters\" /></a><a href=\"https://github.com/dcsdigital\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;dcsdigital.png\" width=\"60px\" alt=\"User avatar: DCS Digital\" /></a><a href=\"https://github.com/pm7y\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;pm7y.png\" width=\"60px\" alt=\"User avatar: Paul Mcilreavy\" /></a><a href=\"https://github.com/tilwolf\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;tilwolf.png\" width=\"60px\" alt=\"User avatar: Til Wolf\" /></a><a href=\"https://github.com/ozzyoss77\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;ozzyoss77.png\" width=\"60px\" alt=\"User avatar: Leopoldo Crhistian Riverin Gomez\" /></a><a href=\"https://github.com/AlphaEcho11\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;AlphaEcho11.png\" width=\"60px\" alt=\"User avatar: AJEsau\" /></a><a href=\"https://github.com/svanomm\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;svanomm.png\" width=\"60px\" alt=\"User avatar: Steven VanOmmeren\" /></a><a href=\"https://github.com/socketbox\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;socketbox.png\" width=\"60px\" alt=\"User avatar: Casey Boettcher\" /></a><a href=\"https://github.com/zebbern\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;zebbern.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/avineetbespin\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;avineetbespin.png\" width=\"60px\" alt=\"User avatar: Avineet\" /></a><a href=\"https://github.com/invictus-1\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;invictus-1.png\" width=\"60px\" alt=\"User avatar: Chris\" /></a><a href=\"https://github.com/mirbyte\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;mirbyte.png\" width=\"60px\" alt=\"User avatar: mirko\" /></a><a href=\"https://github.com/bisonbet\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;bisonbet.png\" width=\"60px\" alt=\"User avatar: Tim Champ\" /></a><a href=\"https://github.com/Sinkingdev\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;Sinkingdev.png\" width=\"60px\" alt=\"User avatar: Peter Mathisen\" /></a><a href=\"https://github.com/Ed-STEM\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;Ed-STEM.png\" width=\"60px\" alt=\"User avatar: Ed di Girolamo\" /></a><a href=\"https://github.com/milkowski\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;milkowski.png\" width=\"60px\" alt=\"User avatar: Wojciech MiÅ‚kowski\" /></a><a href=\"https://github.com/ADS-Fund\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;ADS-Fund.png\" width=\"60px\" alt=\"User avatar: ADS Fund\" /></a><a href=\"https://github.com/arc46-io\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;arc46-io.png\" width=\"60px\" alt=\"User avatar: arc46 GmbH\" /></a><!-- all-sponsors -->\n\n## ğŸŒŸ Contributors\n\n[![anythingllm contributors](https://contrib.rocks/image?repo=mintplex-labs/anything-llm)](https://github.com/mintplex-labs/anything-llm/graphs/contributors)\n\n[![Star History Chart](https://api.star-history.com/svg?repos=mintplex-labs/anything-llm&type=Timeline)](https://star-history.com/#mintplex-labs/anything-llm&Date)\n\n## ğŸ”— More Products\n\n- **[VectorAdmin][vector-admin]:** An all-in-one GUI & tool-suite for managing vector databases.\n- **[OpenAI Assistant Swarm][assistant-swarm]:** Turn your entire library of OpenAI assistants into one single army commanded from a single agent.\n\n<div align=\"right\">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n---\n\nCopyright Â© 2025 [Mintplex Labs][profile-link]. <br />\nThis project is [MIT](./LICENSE) licensed.\n\n<!-- LINK GROUP -->\n\n[back-to-top]: https://img.shields.io/badge/-BACK_TO_TOP-222628?style=flat-square\n[profile-link]: https://github.com/mintplex-labs\n[vector-admin]: https://github.com/mintplex-labs/vector-admin\n[assistant-swarm]: https://github.com/Mintplex-Labs/openai-assistant-swarm\n[docker-btn]: ./images/deployBtns/docker.png\n[docker-deploy]: ./docker/HOW_TO_USE_DOCKER.md\n[aws-btn]: ./images/deployBtns/aws.png\n[aws-deploy]: ./cloud-deployments/aws/cloudformation/DEPLOY.md\n[gcp-btn]: https://deploy.cloud.run/button.svg\n[gcp-deploy]: ./cloud-deployments/gcp/deployment/DEPLOY.md\n[do-btn]: https://www.deploytodo.com/do-btn-blue.svg\n[do-deploy]: ./cloud-deployments/digitalocean/terraform/DEPLOY.md\n[render-btn]: https://render.com/images/deploy-to-render-button.svg\n[render-deploy]: https://render.com/deploy?repo=https://github.com/Mintplex-Labs/anything-llm&branch=render\n[render-btn]: https://render.com/images/deploy-to-render-button.svg\n[render-deploy]: https://render.com/deploy?repo=https://github.com/Mintplex-Labs/anything-llm&branch=render\n[railway-btn]: https://railway.app/button.svg\n[railway-deploy]: https://railway.app/template/HNSCS1?referralCode=WFgJkn\n[repocloud-btn]: https://d16t0pc4846x52.cloudfront.net/deploylobe.svg\n[repocloud-deploy]: https://repocloud.io/details/?app_id=276\n[elestio-btn]: https://elest.io/images/logos/deploy-to-elestio-btn.png\n[elestio-deploy]: https://elest.io/open-source/anythingllm\n[northflank-btn]: https://assets.northflank.com/deploy_to_northflank_smm_36700fb050.svg\n[northflank-deploy]: https://northflank.com/stacks/deploy-anythingllm\n",
      "stars_today": 49
    },
    {
      "id": 361044034,
      "name": "slidev",
      "full_name": "slidevjs/slidev",
      "description": "Presentation Slides for Developers",
      "html_url": "https://github.com/slidevjs/slidev",
      "stars": 44199,
      "forks": 1922,
      "language": "TypeScript",
      "topics": [
        "markdown",
        "presentation",
        "slides",
        "vite",
        "vue",
        "vueuse"
      ],
      "created_at": "2021-04-24T01:25:23Z",
      "updated_at": "2026-02-07T00:27:02Z",
      "pushed_at": "2026-02-05T03:53:55Z",
      "open_issues": 180,
      "owner": {
        "login": "slidevjs",
        "avatar_url": "https://avatars.githubusercontent.com/u/83095831?v=4"
      },
      "readme": "<br>\n<p align=\"center\">\n<a href=\"https://sli.dev\" target=\"_blank\">\n<img src=\"https://sli.dev/logo-title.png\" alt=\"Slidev\" height=\"250\" width=\"250\"/>\n</a>\n</p>\n\n<p align=\"center\">\nPresentation <b>slide</b>s for <b>dev</b>elopers ğŸ§‘â€ğŸ’»ğŸ‘©â€ğŸ’»ğŸ‘¨â€ğŸ’»\n</p>\n\n<p align=\"center\">\n<a href=\"https://www.npmjs.com/package/@slidev/cli\" target=\"__blank\"><img src=\"https://img.shields.io/npm/v/@slidev/cli?color=2B90B6&label=\" alt=\"NPM version\"></a>\n<a href=\"https://www.npmjs.com/package/@slidev/cli\" target=\"__blank\"><img alt=\"NPM Downloads\" src=\"https://img.shields.io/npm/dm/@slidev/cli?color=349dbe&label=\"></a>\n<a href=\"https://sli.dev/\" target=\"__blank\"><img src=\"https://img.shields.io/static/v1?label=&message=docs%20%26%20demos&color=45b8cd\" alt=\"Docs & Demos\"></a>\n<a href=\"https://sli.dev/resources/theme-gallery\" target=\"__blank\"><img src=\"https://img.shields.io/static/v1?label=&message=themes&color=4ec5d4\" alt=\"Themes\"></a>\n<br>\n<a href=\"https://github.com/slidevjs/slidev/stargazers\" target=\"__blank\"><img alt=\"GitHub stars\" src=\"https://img.shields.io/github/stars/slidevjs/slidev?style=social\"></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://twitter.com/antfu7/status/1389604687502995457\">Video Preview</a> | <a href=\"https://sli.dev\">Documentation</a>\n</p>\n\n<div align=\"center\">\n<table>\n<tbody>\n<td align=\"center\">\n<img width=\"2000\" height=\"0\" alt=\"\" aria-hidden><br>\n<sub>Made possible by my <a href=\"https://github.com/sponsors/antfu\">Sponsor Program ğŸ’–</a></sub><br>\n<img width=\"2000\" height=\"0\" alt=\"\" aria-hidden>\n</td>\n</tbody>\n</table>\n</div>\n\n## Features\n\n- ğŸ“ [**Markdown-based**](https://sli.dev/guide/syntax) - focus on content and use your favorite editor\n- ğŸ§‘â€ğŸ’» [**Developer Friendly**](https://sli.dev/guide/syntax#code-blocks) - built-in code highlighting, live coding, etc.\n- ğŸ¨ [**Themable**](https://sli.dev/resources/theme-gallery) - theme can be shared and used with npm packages\n- ğŸŒˆ [**Stylish**](https://sli.dev/guide/syntax#embedded-styles) - on-demand utilities via [UnoCSS](https://github.com/unocss/unocss).\n- ğŸ¤¹ [**Interactive**](https://sli.dev/custom/directory-structure#components) - embedding Vue components seamlessly\n- ğŸ™ [**Presenter Mode**](https://sli.dev/guide/ui#presenter-mode) - use another window, or even your phone to control your slides\n- ğŸ¨ [**Drawing**](https://sli.dev/features/drawing) - draw and annotate on your slides\n- ğŸ§® [**LaTeX**](https://sli.dev/features/latex) - built-in LaTeX math equations support\n- ğŸ“° [**Diagrams**](https://sli.dev/guide/syntax#diagrams) - creates diagrams using textual descriptions with [Mermaid](https://mermaid.js.org/)\n- ğŸŒŸ [**Icons**](https://sli.dev/features/icons) - access to icons from any icon set directly\n- ğŸ’» [**Editor**](https://sli.dev/guide/index#editor) - integrated editor, or the [VSCode extension](https://sli.dev/features/vscode-extension)\n- ğŸ¥ [**Recording**](https://sli.dev/features/recording) - built-in recording and camera view\n- ğŸ“¤ [**Portable**](https://sli.dev/guide/exporting) - export into PDF, PNGs, or PPTX\n- âš¡ï¸ [**Fast**](https://vitejs.dev) - instant reloading powered by [Vite](https://vitejs.dev)\n- ğŸ›  [**Hackable**](https://sli.dev/custom/) - using Vite plugins, Vue components, or any npm packages\n\n## Getting Started\n\n### Try it Online âš¡ï¸\n\n[sli.dev/new](https://sli.dev/new)\n\n[![](https://developer.stackblitz.com/img/open_in_stackblitz.svg)](https://sli.dev/new)\n\n### Init Project Locally\n\nInstall [Node.js >=18](https://nodejs.org/) and run the following command:\n\n```bash\nnpm init slidev\n```\n\nDocumentation:\n**[English](https://sli.dev)** | [ä¸­æ–‡æ–‡æ¡£](https://cn.sli.dev) | [FranÃ§ais](https://fr.sli.dev) | [EspaÃ±ol](https://es.sli.dev) | [Ğ ÑƒÑÑĞºĞ¸Ğ¹](https://ru.sli.dev) | [PortuguÃªs-BR](https://br.sli.dev)\n\nDiscord: [chat.sli.dev](https://chat.sli.dev)\n\nFor a full example, you can check the [demo](https://github.com/slidevjs/slidev/blob/main/demo) folder, which is also the source file for [my previous talk](https://antfu.me/posts/composable-vue-vueday-2021).\n\n## Tech Stack\n\n- [Vite](https://vitejs.dev) - An extremely fast frontend tooling\n- [Vue 3](https://v3.vuejs.org/) powered [Markdown](https://daringfireball.net/projects/markdown/syntax) - Focus on the content while having the power of HTML and Vue components whenever needed\n- [UnoCSS](https://github.com/unocss/unocss) - On-demand utility-first CSS engine, style your slides at ease\n- [Shiki](https://github.com/shikijs/shiki), [Monaco Editor](https://github.com/Microsoft/monaco-editor) - First-class code snippets support with live coding capability\n- [RecordRTC](https://recordrtc.org) - Built-in recording and camera view\n- [VueUse](https://vueuse.org) family - [`@vueuse/core`](https://github.com/vueuse/vueuse), [`@vueuse/motion`](https://github.com/vueuse/motion), etc.\n- [Iconify](https://iconify.design/) - Icon sets collection.\n- [Drauu](https://github.com/antfu/drauu) - Drawing and annotations support\n- [KaTeX](https://katex.org/) - LaTeX math rendering.\n- [Mermaid](https://mermaid-js.github.io/mermaid) - Textual Diagrams.\n\n## Sponsors\n\nThis project is made possible by all the sponsors supporting my work:\n\n<p align=\"center\">\n  <a href=\"https://github.com/sponsors/antfu\">\n    <img src='https://cdn.jsdelivr.net/gh/antfu/static/sponsors.svg' alt=\"Logos from Sponsors\" />\n  </a>\n</p>\n\n## License\n\nMIT License Â© 2021 [Anthony Fu](https://github.com/antfu)\n",
      "stars_today": 42
    },
    {
      "id": 476507964,
      "name": "artcraft",
      "full_name": "storytold/artcraft",
      "description": "ArtCraft is an intentional crafting engine for artists, designers, and filmmakers",
      "html_url": "https://github.com/storytold/artcraft",
      "stars": 674,
      "forks": 40,
      "language": "Rust",
      "topics": [
        "3d-graphics",
        "ai",
        "aivideo",
        "filmmaking",
        "imagegeneration"
      ],
      "created_at": "2022-03-31T23:19:12Z",
      "updated_at": "2026-02-07T01:34:17Z",
      "pushed_at": "2026-02-05T16:31:39Z",
      "open_issues": 51,
      "owner": {
        "login": "storytold",
        "avatar_url": "https://avatars.githubusercontent.com/u/76897702?v=4"
      },
      "readme": "<p align=\"center\">\n  <video src=\"https://github.com/user-attachments/assets/b4e24c27-d87d-4fd1-8599-dc0d0b8af48d\" width=\"100%\" autoplay=\"true\" loop controls>\n</p>\n\n<p align=\"center\">The IDE for artists.</p>\n<p align=\"center\">\n  <a href=\"https://discord.gg/artcraft\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1359579021108842617?style=for-the-badge&label=discord&color=ffffff&logo=discord&logoColor=ffffff\" /></a>\n  <a href=\"https://www.youtube.com/@OfficialArtCraftStudios\"><img alt=\"YouTube\" src=\"https://img.shields.io/youtube/channel/subscribers/UCdjY4VG0ntoGwFsKZO4sVWA?style=for-the-badge&logo=YouTube\" /></a>\n  <a href=\"https://x.com/intent/follow?screen_name=get_artcraft\"><img alt=\"X\" src=\"https://img.shields.io/twitter/follow/get_artcraft?style=for-the-badge&label=follow&logo=x&logoColor=ffffff&color=ffffff\" /></a>\n  <a href=\"https://www.linkedin.com/company/artcraft-ai\"><img alt=\"LinkedIn\" src=\"https://img.shields.io/badge/linkedin--0A66C2?style=for-the-badge\"></a>\n</p>\n\n---\n\nArtCraft\n========\nArtCraft is the IDE for interactive AI image and video creation.\nWe turn prompting into *crafting*, so your ideas become a form of tangible expression and computing.\nThis is Adobe Photoshop for everyone, and we're giving away the source code!\n\n## Show, Don't Tell: Advanced Crafting Features\n\nText-to-image is great, but artists *need control*. It's important to know what your image will look like before you generate it, and it's vitally important to achieve consistency and repeatability.\n\n| Feature                           | Demo + Explanation                                                                                                                                                                                                                                                      \n|-----------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Image to Location**             | ![Video](https://github.com/user-attachments/assets/21f103e3-cc19-4882-a630-9caa1b76ae31) Placing virtual actors into physical environments establishes single-location consistency. You can film multiple shots within a room without having things disappear.         |\n| **3D Image Compositing**          | ![Video](https://github.com/user-attachments/assets/f93a616f-571d-474e-bcc0-53736de7303d) Use images (backdrops, foreground elements, props, etc.) in scenes with depth and blend them naturally together. Just a couple of images usually leads to great compositions. |\n| **2D Image Compositing**          | ![Video](https://github.com/user-attachments/assets/d6f99391-e496-4c62-9e37-29734ba5f899) Use images, background removal, layers, and simple drawing tools to precisely compose a scene.                                                                                |\n| **Image to 3D Mesh**              | ![Video](https://github.com/user-attachments/assets/600a405c-e360-48c1-9b42-6e657ae6243b) It's almost impossible to lay out complicated objects or block complicated scenes; turning images into 3D helps position elements exactingly and intentionally.               |\n| **Character Posing**              | ![Video](https://github.com/user-attachments/assets/52a8e983-7c8f-42d2-be8b-25296ab9ed57) You can dynamically pose your characters to achieve the precise character, scene, and camera blocking before calling \"action\".                                                |\n| **Scene Blocking w/ Kit Bashing** | ![Video](https://github.com/user-attachments/assets/eef025ac-0346-4a46-a023-d48e23629eb5) Use 3D asset kits to precisely block out your scene: get the correct angles, object positions, and rich depth layering you can't with text prompting.                         |\n| **Character Identity Transfer**   | ![Video](https://github.com/user-attachments/assets/629119ee-8c76-4a83-9827-8c6c995a3ec1) Use mannequins as simple 3D ControlNets for posing any character.                                                                                                             |\n| **Background Removal**            | ![Video](https://github.com/user-attachments/assets/90c65057-5531-404f-83af-b34e66e24ec1) Remove backgrounds from images to make them useful in 2D or 3D compositing. They can be props, layers, or backdrops.                                                          |\n| **Mixed Asset Crafting**          | ![Video](https://raw.githubusercontent.com/storytold/github-media/main/ship-editing.gif) You can use image cutouts, worlds, and simple 3D meshes all together to precisely and intentionally lay out your scenes.                                                       |\n| **Scene Blocking**                | (preview coming soon)                                                                                                                                                                                                                                                   |\n| **Canvas Editing**                | (preview coming soon)                                                                                                                                                                                                                                                   |\n| **Scene Relighting**              | (preview coming soon)                                                                                                                                                                                                                                                   |\n\nNote: all of the above videos were generated for free with Grok Video; the cost to build this README was negligible.\n\n## Quick and Easy Prompting\nWe haven't abandoned text-to-asset generation for quick prototyping and ideation. We support every popular workflow in a first class fashion.\n\n| Feature               | Demo + Explanation                                                                                                                                    \n|-----------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Text to Image**     | ![Video](https://github.com/user-attachments/assets/9cc289cd-faf4-4eaf-aed2-21134cce127c) Text prompt over a dozen different image models.            |\n| **Image Editing**     | ![Video](https://github.com/user-attachments/assets/a06fa6ad-936c-42d0-8767-48fdbb8ff141) Edit with Nano Banana Pro and GPT Image 1.5.                |\n| **Image Editing**     | ![Video](https://github.com/user-attachments/assets/f036e08a-f3a6-417a-98ee-ec7f04b2b5ff) Use inpainting, drawing, masking, etc. to edit images.      |\n| **Image to Video**    | ![Video](https://github.com/user-attachments/assets/2bc6c592-511e-4fba-b40f-03c96699b7f7) Image to video with lots of different options and controls. |\n| **Image Inpainting**  | (preview coming soon)                                                                                                                                 |\n| **Image Ingredients** | (preview coming soon)                                                                                                                                 |\n\n## Models and Providers Supported within Artcraft\n\n| Provider   | Features                                                                                                                                                                |\n|------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Artcraft   | Nano Banana, Nano Banana Pro, GPT-Image-1 / 1.5, Seedream 4 / 4.5, Flux 1.1 / Kontext, Veo 2 / 3 / 3.1, Kling 1.6 / 2.1 / 2.5 / 2.6, Seedance, Sora 2 / Pro, Hunyuan 3d 2 / 3 |\n| Grok       | Grok Imagine, Grok Video                                                                                                                                                |\n| Midjourney | Image Gen (all versions)                                                                                                                                                |\n| Sora       | Sora 1, Sora 2, GPT-Image-1                                                                                                                                             |\n| WorldLabs  | Marble (Gaussian Splat World Generation)                                                                                                                                |\n\nWe're going to be adding the following providers soon: Kling (via Kling website accounts), Google (via API keys), \nRunway (via website account), Luma (via website account).\n\nWe're potentially interested in adding other aggregators for those who already have subscriptions and credits at \nthose providers, for example: OpenArt, FreePik, etc.\n\n## Downloads\n\n- [Visit our website for the stable Windows and MacOS releases](https://getartcraft.com/)\n- Or you can grab a [more recent Windows and MacOS build directly](https://github.com/storytold/artcraft/releases)\n- Linux requires building from source for now\n\n## Documentation\n\n- [developer documentation](./_docs)\n- [tools, scripts, misc](./script)\n- [license](./LICENSE.md)\n- [roadmap](./ROADMAP.md)\n\n",
      "stars_today": 41
    },
    {
      "id": 84240850,
      "name": "timescaledb",
      "full_name": "timescale/timescaledb",
      "description": "A time-series database for high-performance real-time analytics packaged as a Postgres extension",
      "html_url": "https://github.com/timescale/timescaledb",
      "stars": 21708,
      "forks": 1041,
      "language": "C",
      "topics": [
        "analytics",
        "database",
        "financial-analysis",
        "hacktoberfest",
        "iot",
        "postgres",
        "postgresql",
        "sql",
        "tigerdata",
        "time-series",
        "time-series-database",
        "timescaledb",
        "tsdb"
      ],
      "created_at": "2017-03-07T20:03:41Z",
      "updated_at": "2026-02-07T02:21:39Z",
      "pushed_at": "2026-02-06T17:19:48Z",
      "open_issues": 447,
      "owner": {
        "login": "timescale",
        "avatar_url": "https://avatars.githubusercontent.com/u/8986001?v=4"
      },
      "readme": "<div align=center>\n<picture align=center>\n    <source  srcset=\"https://assets.timescale.com/timescale-web/brand/show/horizontal-black.svg\">\n    <img alt=\"Tiger Data logo\" >\n</picture>\n</div>\n\n<div align=center>\n\n<h3>TimescaleDB is a PostgreSQL extension for high-performance real-time analytics on time-series and event data</h3>\n\n[![Docs](https://img.shields.io/badge/Read_the_docs-black?style=for-the-badge&logo=readthedocs&logoColor=white)](https://docs.tigerdata.com/)\n[![SLACK](https://img.shields.io/badge/Ask_the_community-black?style=for-the-badge&logo=slack&logoColor=white)](https://timescaledb.slack.com/archives/C4GT3N90X)\n[![Try TimescaleDB for free](https://img.shields.io/badge/Try_Tiger_Cloud_for_free-black?style=for-the-badge&logo=timescale&logoColor=white)](https://console.cloud.timescale.com/signup)\n\n</div>\n\n## Quick Start with TimescaleDB\n\nGet started with TimescaleDB in under 10 minutes. This guide will help you run TimescaleDB locally, create your first hypertable with columnstore enabled, write data to the columnstore, and see instant analytical query performance.\n\n### What You'll Learn\n\n- How to run TimescaleDB with a one-line install or Docker command\n- How to create a hypertable with columnstore enabled\n- How to insert data directly to the columnstore \n- How to execute analytical queries\n\n### Prerequisites\n\n- Docker installed on your machine\n- 8GB RAM recommended\n- `psql` client (included with PostgreSQL) or any PostgreSQL client like [pgAdmin](https://www.pgadmin.org/download/)\n\n### Step 1: Start TimescaleDB\n\nYou have two options to start TimescaleDB:\n\n#### Option 1: One-line install (Recommended)\n\nThe easiest way to get started:\n\n> **Important:** This script is intended for local development and testing only. Do **not** use it for production deployments. For production-ready installation options, see the [TimescaleDB installation guide](https://docs.timescale.com/self-hosted/latest/install/).\n\n**Linux/Mac:**\n\n```sh\ncurl -sL https://tsdb.co/start-local | sh\n```\n\nThis command:\n- Downloads and starts TimescaleDB (if not already downloaded)\n- Exposes PostgreSQL on port **6543** (a non-standard port to avoid conflicts with other PostgreSQL instances on port 5432)\n- Automatically tunes settings for your environment using timescaledb-tune\n- Sets up a persistent data volume\n\n#### Option 2: Manual Docker command also used for Windows\n\nAlternatively, you can run TimescaleDB directly with Docker:\n\n```bash\ndocker run -d --name timescaledb \\\n    -p 6543:5432 \\\n    -e POSTGRES_PASSWORD=password \\\n    timescale/timescaledb-ha:pg18\n```\n\n**Note:** We use port **6543** (mapped to container port 5432) to avoid conflicts if you have other PostgreSQL instances running on the standard port 5432.\n\nWait about 1-2 minutes for TimescaleDB to download & initialize.\n\n### Step 2: Connect to TimescaleDB\n\nConnect using `psql`:\n\n```bash\npsql -h localhost -p 6543 -U postgres\n# When prompted, enter password: password\n```\n\nYou should see the PostgreSQL prompt. Verify TimescaleDB is installed:\n\n```sql\nSELECT extname, extversion FROM pg_extension WHERE extname = 'timescaledb';\n```\n\nExpected output:\n```\n   extname   | extversion\n-------------+------------\n timescaledb | 2.x.x\n```\n\n**Prefer a GUI?** If you'd rather use a graphical tool instead of the command line, you can download [pgAdmin](https://www.pgadmin.org/download/) and connect to TimescaleDB using the same connection details (host: `localhost`, port: `6543`, user: `postgres`, password: `password`).\n\n### Step 3: Create Your First Hypertable\n\nLet's create a hypertable for IoT sensor data with columnstore enabled:\n\n```sql\n-- Create a hypertable with automatic columnstore\nCREATE TABLE sensor_data (\n    time TIMESTAMPTZ NOT NULL,\n    sensor_id TEXT NOT NULL,\n    temperature DOUBLE PRECISION,\n    humidity DOUBLE PRECISION,\n    pressure DOUBLE PRECISION\n) WITH (\n    tsdb.hypertable\n);\n-- create index\nCREATE INDEX idx_sensor_id_time ON sensor_data(sensor_id, time DESC);\n```\n\n`tsdb.hypertable` - Converts this into a TimescaleDB hypertable\n\nSee more:\n\n- [About hypertables](https://docs.tigerdata.com/use-timescale/latest/hypertables/)\n- [API reference](https://docs.tigerdata.com/api/latest/hypertable/)\n- [About columnstore](https://docs.tigerdata.com/use-timescale/latest/compression/about-compression/)\n- [Enable columnstore manually](https://docs.tigerdata.com/use-timescale/latest/compression/manual-compression/)\n- [API reference](https://docs.tigerdata.com/api/latest/compression/)\n\n### Step 4: Insert Sample Data\n\nLet's add some sample sensor readings:\n\n\n```sql\n-- Enable timing to see time to execute queries\n\\timing on\n\n-- Insert sample data for multiple sensors\n-- SET timescaledb.enable_direct_compress_insert = on to insert data directly to the columnstore (columnnar format for performance)\nSET timescaledb.enable_direct_compress_insert = on;\nINSERT INTO sensor_data (time, sensor_id, temperature, humidity, pressure)\nSELECT\n    time,\n    'sensor_' || ((random() * 9)::int + 1),\n    20 + (random() * 15),\n    40 + (random() * 30),\n    1000 + (random() * 50)\nFROM generate_series(\n    NOW() - INTERVAL '90 days',\n    NOW(),\n    INTERVAL '1 seconds'\n) AS time;\n\n-- Once data is inserted into the columnstore we optimize the order and structure \n-- this compacts and orders the data in the chunks for optimal query performance and compression\nDO $$\nDECLARE ch TEXT;\nBEGIN\n    FOR ch IN SELECT show_chunks('sensor_data') LOOP\n        CALL convert_to_columnstore(ch, recompress := true);\n    END LOOP;\nEND $$;\n```\n\nThis generates ~7,776,001 readings across 10 sensors over the past 90 days.\n\nVerify the data was inserted:\n\n```sql\nSELECT COUNT(*) FROM sensor_data;\n```\n\n### Step 5: Run Your First Analytical Queries\n\nNow let's run some analytical queries that showcase TimescaleDB's performance:\n\n```sql\n-- Enable query timing to see performance\n\\timing on\n\n-- Query 1: Average readings per sensor over the last 7 days\nSELECT\n    sensor_id,\n    COUNT(*) as readings,\n    ROUND(AVG(temperature)::numeric, 2) as avg_temp,\n    ROUND(AVG(humidity)::numeric, 2) as avg_humidity,\n    ROUND(AVG(pressure)::numeric, 2) as avg_pressure\nFROM sensor_data\nWHERE time > NOW() - INTERVAL '7 days'\nGROUP BY sensor_id\nORDER BY sensor_id;\n\n-- Query 2: Hourly averages using time_bucket \n-- Time buckets enable you to aggregate data in hypertables by time interval and calculate summary values.\nSELECT\n    time_bucket('1 hour', time) AS hour,\n    sensor_id,\n    ROUND(AVG(temperature)::numeric, 2) as avg_temp,\n    ROUND(AVG(humidity)::numeric, 2) as avg_humidity\nFROM sensor_data\nWHERE time > NOW() - INTERVAL '24 hours'\nGROUP BY hour, sensor_id\nORDER BY hour DESC, sensor_id\nLIMIT 20;\n\n-- Query 3: Daily statistics across all sensors\nSELECT\n    time_bucket('1 day', time) AS day,\n    COUNT(*) as total_readings,\n    ROUND(AVG(temperature)::numeric, 2) as avg_temp,\n    ROUND(MIN(temperature)::numeric, 2) as min_temp,\n    ROUND(MAX(temperature)::numeric, 2) as max_temp\nFROM sensor_data\nGROUP BY day\nORDER BY day DESC\nLIMIT 10;\n\n-- Query 4: Latest reading for each sensor\n-- Highlights the value of Skipscan executing in under 100ms without skipscan it takes over 5sec\nSELECT DISTINCT ON (sensor_id)\n    sensor_id,\n    time,\n    ROUND(temperature::numeric, 2) as temperature,\n    ROUND(humidity::numeric, 2) as humidity,\n    ROUND(pressure::numeric, 2) as pressure\nFROM sensor_data\nORDER BY sensor_id, time DESC;\n```\n\nNotice how fast these analytical queries run, even with aggregations across millions of rows. This is the power of TimescaleDB's columnstore.\n\n### What's Happening Behind the Scenes?\n\nTimescaleDB automatically:\n- **Partitions your data** into time-based chunks for efficient querying\n- **Write directly to columnstore** using columnar storage (90%+ compression typical) and faster vectorized queries\n- **Optimizes queries** by only scanning relevant time ranges and columns\n- **Enables time_bucket()** - a powerful function for time-series aggregation\n\nSee more:\n\n- [Query data](https://docs.tigerdata.com/use-timescale/latest/query-data/)\n- [Write data](https://docs.tigerdata.com/use-timescale/latest/write-data/)\n- [About time buckets](https://docs.tigerdata.com/use-timescale/latest/time-buckets/about-time-buckets/)\n- [API reference](https://docs.tigerdata.com/api/latest/hyperfunctions/time_bucket/)\n- [All TimescaleDB features](https://docs.tigerdata.com/use-timescale/latest/)\n\n### Next Steps\n\nNow that you've got the basics, explore more:\n\n### Create Continuous Aggregates\n\nContinuous aggregates make real-time analytics run faster on very large datasets. They continuously and incrementally refresh a query in the background, so that when you run such query, only the data that has changed needs to be computed, not the entire dataset. This is what makes them different from regular PostgreSQL [materialized views](https://www.postgresql.org/docs/current/rules-materializedviews.html), which cannot be incrementally materialized and have to be rebuilt from scratch every time you want to refresh them.\n\nLet's create a continuous aggregate for hourly sensor statistics:\n\n#### Step 1: Create the Continuous Aggregate\n\n```sql\nCREATE MATERIALIZED VIEW sensor_data_hourly\nWITH (timescaledb.continuous) AS\nSELECT\n    time_bucket('1 hour', time) AS hour,\n    sensor_id,\n    AVG(temperature) AS avg_temp,\n    AVG(humidity) AS avg_humidity,\n    AVG(pressure) AS avg_pressure,\n    MIN(temperature) AS min_temp,\n    MAX(temperature) AS max_temp,\n    COUNT(*) AS reading_count\nFROM sensor_data\nGROUP BY hour, sensor_id;\n```\n\nThis creates a materialized view that pre-aggregates your sensor data into hourly buckets. The view is automatically populated with existing data.\n\n#### Step 2: Add a Refresh Policy\n\nTo keep the continuous aggregate up-to-date as new data arrives, add a refresh policy:\n\n```sql\nSELECT add_continuous_aggregate_policy(\n    'sensor_data_hourly',\n    start_offset => INTERVAL '3 hours',\n    end_offset => INTERVAL '1 hour',\n    schedule_interval => INTERVAL '1 hour'\n);\n```\n\nThis policy:\n- Refreshes the continuous aggregate every hour\n- Processes data from 3 hours ago up to 1 hour ago (leaving the most recent hour for real-time queries)\n- Only processes new or changed data incrementally\n\n#### Step 3: Query the Continuous Aggregate\n\nNow you can query the pre-aggregated data for much faster results:\n\n```sql\n-- Get hourly averages for the last 24 hours\nSELECT\n    hour,\n    sensor_id,\n    ROUND(avg_temp::numeric, 2) AS avg_temp,\n    ROUND(avg_humidity::numeric, 2) AS avg_humidity,\n    reading_count\nFROM sensor_data_hourly\nWHERE hour > NOW() - INTERVAL '24 hours'\nORDER BY hour DESC, sensor_id\nLIMIT 50;\n```\n\n#### Benefits of Continuous Aggregates\n\n- **Faster queries**: Pre-aggregated data means queries run in milliseconds instead of seconds\n- **Incremental refresh**: Only new/changed data is processed, not the entire dataset\n- **Automatic updates**: The refresh policy keeps your aggregates current without manual intervention\n- **Real-time option**: You can enable real-time aggregation to combine materialized and raw data\n\n#### Try It Yourself\n\nCompare the performance difference:\n\n```sql\n-- Query the raw hypertable (slower on large datasets)\n\\timing on\nSELECT\n    time_bucket('1 hour', time) AS hour,\n    AVG(temperature) AS avg_temp\nFROM sensor_data\nWHERE time > NOW() - INTERVAL '60 days'\nGROUP BY hour\nORDER BY hour DESC\nLIMIT 24;\n\n-- Query the continuous aggregate (much faster)\nSELECT\n    hour,\n    avg_temp\nFROM sensor_data_hourly\nWHERE hour > NOW() - INTERVAL '60 days'\nORDER BY hour DESC\nLIMIT 24;\n```\n\nNotice how the continuous aggregate query is significantly faster, especially as your dataset grows!\n\nSee more:\n\n- [About continuous aggregates](https://docs.tigerdata.com/use-timescale/latest/continuous-aggregates/)\n- [API reference](https://docs.tigerdata.com/api/latest/continuous-aggregates/create_materialized_view/)\n- [TimescaleDB Documentation](https://docs.timescale.com)\n- [Time-series Best Practices](https://docs.timescale.com/use-timescale/latest/schema-management/)\n- [Continuous Aggregates](https://docs.timescale.com/use-timescale/latest/continuous-aggregates/)\n\n## Examples\n\nLearn TimescaleDB with complete, standalone examples using real-world datasets. Each example includes sample data and analytical queries.\n\n- **[NYC Taxi Data](docs/getting-started/nyc-taxi/)** - Transportation and location-based analytics\n- **[Financial Market Data](docs/getting-started/financial-ticks/)** - Trading and market data analysis\n- **[Application Events](docs/getting-started/events-uuidv7/)** - Event logging with UUIDv7\n\nOr try some of our workshops\n- **[AI Workshop: EV Charging Station Analysis](https://github.com/timescale/TigerData-Workshops/tree/main/AI-Workshop)** - Integrate PostgreSQL with AI capabilities for managing and analyzing EV charging station data\n- **[Time-Series Workshop: Financial Data Analysis](https://github.com/timescale/TigerData-Workshops/tree/main/TimeSeries-Workshop-Finance/)** - Work with cryptocurrency tick data, create candlestick charts\n\n## Want TimescaleDB hosted and managed for you? Try Tiger Cloud\n\n[Tiger Cloud](https://docs.tigerdata.com/getting-started/latest/) is the modern PostgreSQL data platform for all your applications. It enhances PostgreSQL to handle time series, events, real-time analytics, and vector searchâ€”all in a single database alongside transactional workloads. You get one system that handles live data ingestion, late and out-of-order updates, and low latency queries, with the performance, reliability, and scalability your app needs. Ideal for IoT, crypto, finance, SaaS, and a myriad other domains, Tiger Cloud allows you to build data-heavy, mission-critical apps while retaining the familiarity and reliability of PostgreSQL. See [our whitepaper](https://docs.tigerdata.com/about/latest/whitepaper/) for a deep dive into Tiger Cloud's architecture and how it meets the needs of even the most demanding applications.\n\nA Tiger Cloud service is a single optimized 100% PostgreSQL database instance that you use as is, or extend with capabilities specific to your business needs. The available capabilities are:\n\n- **Time-series and analytics**: PostgreSQL with TimescaleDB. The PostgreSQL you know and love, supercharged with functionality for storing and querying time-series data at scale for real-time analytics and other use cases. Get faster time-based queries with hypertables, continuous aggregates, and columnar storage. Save on storage with native compression, data retention policies, and bottomless data tiering to Amazon S3.\n- **AI and vector**: PostgreSQL with vector extensions. Use PostgreSQL as a vector database with purpose built extensions for building AI applications from start to scale. Get fast and accurate similarity search with the pgvector and pgvectorscale extensions. Create vector embeddings and perform LLM reasoning on your data with the pgai extension.\n- **PostgreSQL**: the trusted industry-standard RDBMS. Ideal for applications requiring strong data consistency, complex relationships, and advanced querying capabilities. Get ACID compliance, extensive SQL support, JSON handling, and extensibility through custom functions, data types, and extensions.\nAll services include all the cloud tooling you'd expect for production use: [automatic backups](https://docs.tigerdata.com/use-timescale/latest/backup-restore/backup-restore-cloud/), [high availability](https://docs.tigerdata.com/use-timescale/latest/ha-replicas/), [read replicas](https://docs.tigerdata.com/use-timescale/latest/ha-replicas/read-scaling/), [data forking](https://docs.tigerdata.com/use-timescale/latest/services/service-management/#fork-a-service), [connection pooling](https://docs.tigerdata.com/use-timescale/latest/services/connection-pooling/), [tiered storage](https://docs.tigerdata.com/use-timescale/latest/data-tiering/), [usage-based storage](https://docs.tigerdata.com/about/latest/pricing-and-account-management/), and much more.\n\n## Check build status\n\n|Linux/macOS|Linux i386|Windows|Coverity|Code Coverage|OpenSSF|\n|:---:|:---:|:---:|:---:|:---:|:---:|\n|[![Build Status Linux/macOS](https://github.com/timescale/timescaledb/actions/workflows/linux-build-and-test.yaml/badge.svg?branch=main&event=schedule)](https://github.com/timescale/timescaledb/actions/workflows/linux-build-and-test.yaml?query=workflow%3ARegression+branch%3Amain+event%3Aschedule)|[![Build Status Linux i386](https://github.com/timescale/timescaledb/actions/workflows/linux-32bit-build-and-test.yaml/badge.svg?branch=main&event=schedule)](https://github.com/timescale/timescaledb/actions/workflows/linux-32bit-build-and-test.yaml?query=workflow%3ARegression+branch%3Amain+event%3Aschedule)|[![Windows build status](https://github.com/timescale/timescaledb/actions/workflows/windows-build-and-test.yaml/badge.svg?branch=main&event=schedule)](https://github.com/timescale/timescaledb/actions/workflows/windows-build-and-test.yaml?query=workflow%3ARegression+branch%3Amain+event%3Aschedule)|[![Coverity Scan Build Status](https://scan.coverity.com/projects/timescale-timescaledb/badge.svg)](https://scan.coverity.com/projects/timescale-timescaledb)|[![Code Coverage](https://codecov.io/gh/timescale/timescaledb/branch/main/graphs/badge.svg?branch=main)](https://codecov.io/gh/timescale/timescaledb)|[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/8012/badge)](https://www.bestpractices.dev/projects/8012)|\n\n## Get involved\n\nWe welcome contributions to TimescaleDB! See [Contributing](https://github.com/timescale/timescaledb/blob/main/CONTRIBUTING.md) and [Code style guide](https://github.com/timescale/timescaledb/blob/main/docs/StyleGuide.md) for details.\n\n## Learn about Tiger Data\n\nTiger Data is the fastest PostgreSQL for transactional, analytical and agentic workloads. To learn more about the company and its products, visit [tigerdata.com](https://www.tigerdata.com).\n\n## Troubleshooting\n\n#### Docker container won't start\n\n```bash\n# Check if container is running\ndocker ps -a\n\n# View container logs (use the appropriate container name)\n# For one-line install:\ndocker logs timescaledb-ha-pg18-quickstart\n# For manual Docker command:\ndocker logs timescaledb\n\n# Stop and remove existing container\n# For one-line install:\ndocker stop timescaledb-ha-pg18-quickstart && docker rm timescaledb-ha-pg18-quickstart\n# For manual Docker command:\ndocker stop timescaledb && docker rm timescaledb\n\n# Start fresh\n# Option 1: Use the one-line install\ncurl -sL https://tsdb.co/start-local | sh\n# Option 2: Use manual Docker command\ndocker run -d --name timescaledb -p 6543:5432 -e POSTGRES_PASSWORD=password timescale/timescaledb-ha:pg18\n```\n\n#### Can't connect with psql\n\n- Verify Docker container is running: `docker ps`\n- Check port 6543 isn't already in use: `lsof -i :6543`\n- Try using explicit host: `psql -h 127.0.0.1 -p 6543 -U postgres`\n\n#### TimescaleDB extension not found\n\nThe `timescale/timescaledb-ha:pg18` image has TimescaleDB pre-installed and pre-loaded. If you see errors, ensure you're using the correct image.\n\n## Clean Up\n\nWhen you're done experimenting:\n\n#### If you used the one-line install:\n\n```bash\n# Stop the container\ndocker stop timescaledb-ha-pg18-quickstart\n\n# Remove the container\ndocker rm timescaledb-ha-pg18-quickstart\n\n# Remove the persistent data volume\ndocker volume rm timescaledb_data\n\n# (Optional) Remove the Docker image\ndocker rmi timescale/timescaledb-ha:pg18\n```\n\n#### If you used the manual Docker command:\n\n```bash\n# Stop the container\ndocker stop timescaledb\n\n# Remove the container\ndocker rm timescaledb\n\n# (Optional) Remove the Docker image\ndocker rmi timescale/timescaledb-ha:pg18\n```\n\n**Note:** If you created a named volume with the manual Docker command, you can remove it with `docker volume rm <volume_name>`.\n",
      "stars_today": 40
    },
    {
      "id": 618351200,
      "name": "likec4",
      "full_name": "likec4/likec4",
      "description": "Visualize, collaborate, and evolve the software architecture with always actual and live diagrams from your code",
      "html_url": "https://github.com/likec4/likec4",
      "stars": 1825,
      "forks": 136,
      "language": "TypeScript",
      "topics": [
        "architecture",
        "architecture-as-code",
        "c4",
        "diagrams"
      ],
      "created_at": "2023-03-24T09:30:34Z",
      "updated_at": "2026-02-07T02:31:33Z",
      "pushed_at": "2026-02-06T19:58:56Z",
      "open_issues": 139,
      "owner": {
        "login": "likec4",
        "avatar_url": "https://avatars.githubusercontent.com/u/128791862?v=4"
      },
      "readme": "# Architecture as a code\n\nVisualize, collaborate on, and evolve your software architecture with always up-to-date, live diagrams generated from your code.\n\n[docs](https://likec4.dev/) - [playground](https://playground.likec4.dev/) - [demo](https://template.likec4.dev/view/index)\n\n<a href=\"https://www.npmjs.com/package/likec4\" target=\"_blank\"> ![NPM Version](https://img.shields.io/npm/v/likec4) </a>\n<a href=\"https://www.npmjs.com/package/likec4\" target=\"_blank\">![NPM Downloads](https://img.shields.io/npm/dm/likec4)</a>\n<a href=\"https://marketplace.visualstudio.com/items?itemName=likec4.likec4-vscode\" target=\"_blank\">![VSCode Installs](https://img.shields.io/visual-studio-marketplace/azure-devops/installs/total/likec4.likec4-vscode?label=vscode%20installs)</a>\n<a href=\"https://open-vsx.org/extension/likec4/likec4-vscode\" target=\"_blank\">![Open VSX Installs](https://img.shields.io/open-vsx/dt/likec4/likec4-vscode?label=open-vsx&color=%23A60EE5)</a>\n\n![vscode extension](https://github.com/likec4/likec4/assets/824903/d6994540-55d1-4167-b66b-45056754cc29)\n\n## What is LikeC4? Why \"like\"?\n\nLikeC4 is a modeling language for describing software architecture and tools to generate diagrams from the model.\n\nLikeC4 is inspired by [C4 Model](https://c4model.com/) and [Structurizr DSL](https://github.com/structurizr/dsl), but provides some flexibility.\nYou customize or define your own notation, element types, and any number of nested levels in architecture model.\\\nPerfectly tailored to your needs.\n\n## What does LikeC4 look like?\n\nLikeC4 source:\n\n<div align=\"center\">\n  <img src=\"https://github.com/likec4/.github/assets/824903/c0f22106-dba6-469e-ab47-85e7b8565513\" width=\"675px\">\n</div>\n\nRun [CLI](./packages/likec4/README.md) to preview:\n\n```sh\nnpx likec4 start\n```\n\nAnd result:\n\n<div align=\"center\">\n  <img src=\"https://github.com/likec4/likec4/assets/824903/27eabe54-7d97-47a8-a7e4-1bb44a8e03e5\" width=\"984px\">\n</div>\n\nTemplate repository - [likec4/template](https://github.com/likec4/template)\\\nDeployed - [https://template.likec4.dev](https://template.likec4.dev/view/index)\n\n[![Open in StackBlitz](https://developer.stackblitz.com/img/open_in_stackblitz.svg)](https://stackblitz.com/~/github.com/likec4/template)\n\nCheck [Tutorial](https://likec4.dev/tutorial/) - for a quick overview of LikeC4.\n\n## Getting help\n\nWe are always happy to help you get started:\n\n- [Join Discord community](https://discord.gg/86ZSpjKAdA) â€“ it is the easiest way to get help\n- [GitHub Discussions](https://github.com/likec4/likec4/discussions) â€“ ask anything about the project or give feedback\n\n## Contributors\n\n<a href=\"https://github.com/likec4/likec4/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=likec4/likec4\" />\n</a>\n\n[Become a contributor](./CONTRIBUTING.md)\n\n## Support development\n\nLikeC4 is a MIT-licensed open source project with its ongoing development made possible entirely by your support.\\\nIf you like the project, please consider contributing financially to help grow and improve it.\\\nYou can support us via [OpenCollective](https://opencollective.com/likec4) or [GitHub Sponsors](https://github.com/sponsors/likec4).\n\n## License\n\nThis project is released under the [MIT License](LICENSE)\n",
      "stars_today": 40
    },
    {
      "id": 186733095,
      "name": "v2rayNG",
      "full_name": "2dust/v2rayNG",
      "description": "A V2Ray client for Android, support Xray core and v2fly core",
      "html_url": "https://github.com/2dust/v2rayNG",
      "stars": 50653,
      "forks": 6898,
      "language": "Kotlin",
      "topics": [
        "android",
        "proxy",
        "shadowsocks",
        "socks5",
        "trojan",
        "v2fly",
        "v2ray",
        "vless",
        "vmess",
        "vpn",
        "xray",
        "xtls"
      ],
      "created_at": "2019-05-15T02:15:31Z",
      "updated_at": "2026-02-07T02:21:55Z",
      "pushed_at": "2026-02-06T12:14:37Z",
      "open_issues": 5,
      "owner": {
        "login": "2dust",
        "avatar_url": "https://avatars.githubusercontent.com/u/31833384?v=4"
      },
      "readme": "# v2rayNG\n\nA V2Ray client for Android, support [Xray core](https://github.com/XTLS/Xray-core) and [v2fly core](https://github.com/v2fly/v2ray-core)\n\n[![API](https://img.shields.io/badge/API-24%2B-yellow.svg?style=flat)](https://developer.android.com/about/versions/lollipop)\n[![Kotlin Version](https://img.shields.io/badge/Kotlin-2.3.0-blue.svg)](https://kotlinlang.org)\n[![GitHub commit activity](https://img.shields.io/github/commit-activity/m/2dust/v2rayNG)](https://github.com/2dust/v2rayNG/commits/master)\n[![CodeFactor](https://www.codefactor.io/repository/github/2dust/v2rayng/badge)](https://www.codefactor.io/repository/github/2dust/v2rayng)\n[![GitHub Releases](https://img.shields.io/github/downloads/2dust/v2rayNG/latest/total?logo=github)](https://github.com/2dust/v2rayNG/releases)\n[![Chat on Telegram](https://img.shields.io/badge/Chat%20on-Telegram-brightgreen.svg)](https://t.me/v2rayn)\n\n### Telegram Channel\n[github_2dust](https://t.me/github_2dust)\n\n### Usage\n\n#### Geoip and Geosite\n- geoip.dat and geosite.dat files are in `Android/data/com.v2ray.ang/files/assets` (path may differ on some Android device)\n- download feature will get enhanced version in this [repo](https://github.com/Loyalsoldier/v2ray-rules-dat) (Note it need a working proxy)\n- latest official [domain list](https://github.com/Loyalsoldier/v2ray-rules-dat) and [ip list](https://github.com/Loyalsoldier/geoip) can be imported manually\n- possible to use third party dat file in the same folder, like [h2y](https://guide.v2fly.org/routing/sitedata.html#%E5%A4%96%E7%BD%AE%E7%9A%84%E5%9F%9F%E5%90%8D%E6%96%87%E4%BB%B6)\n\n### More in our [wiki](https://github.com/2dust/v2rayNG/wiki)\n\n### Development guide\n\nAndroid project under V2rayNG folder can be compiled directly in Android Studio, or using Gradle wrapper. But the v2ray core inside the aar is (probably) outdated.  \nThe aar can be compiled from the Golang project [AndroidLibV2rayLite](https://github.com/2dust/AndroidLibV2rayLite) or [AndroidLibXrayLite](https://github.com/2dust/AndroidLibXrayLite).\nFor a quick start, read guide for [Go Mobile](https://github.com/golang/go/wiki/Mobile) and [Makefiles for Go Developers](https://tutorialedge.net/golang/makefiles-for-go-developers/)\n\nv2rayNG can run on Android Emulators. For WSA, VPN permission need to be granted via\n`appops set [package name] ACTIVATE_VPN allow`\n",
      "stars_today": 39
    },
    {
      "id": 771350543,
      "name": "WrenAI",
      "full_name": "Canner/WrenAI",
      "description": "âš¡ï¸ GenBI (Generative BI) queries any database in natural language, generates accurate SQL (Text-to-SQL), charts (Text-to-Chart), and AI-powered business intelligence in seconds.",
      "html_url": "https://github.com/Canner/WrenAI",
      "stars": 14163,
      "forks": 1524,
      "language": "TypeScript",
      "topics": [
        "agent",
        "anthropic",
        "bedrock",
        "bigquery",
        "business-intelligence",
        "charts",
        "duckdb",
        "genbi",
        "llm",
        "openai",
        "postgresql",
        "rag",
        "spreadsheets",
        "sql",
        "sqlai",
        "text-to-chart",
        "text-to-sql",
        "text2sql",
        "vertex"
      ],
      "created_at": "2024-03-13T06:18:20Z",
      "updated_at": "2026-02-07T02:04:09Z",
      "pushed_at": "2026-02-02T13:12:10Z",
      "open_issues": 279,
      "owner": {
        "login": "Canner",
        "avatar_url": "https://avatars.githubusercontent.com/u/7250217?v=4"
      },
      "readme": "\n<p align=\"center\" id=\"top\">\n  <a href=\"https://getwren.ai/?utm_source=github&utm_medium=title&utm_campaign=readme\">\n    <picture>\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"./misc/wrenai_logo.png\">\n      <img src=\"./misc/wrenai_logo_white.png\" width=\"300px\">\n    </picture>\n    <h1 align=\"center\">Wren AI - Open-Source GenBI Agent</h1>\n  </a>\n</p>\n\n<p align=\"center\">\n  <a aria-label=\"Follow us on X\" href=\"https://x.com/getwrenai\">\n    <img alt=\"\" src=\"https://img.shields.io/badge/-@getwrenai-blue?style=for-the-badge&logo=x&logoColor=white&labelColor=gray&logoWidth=20\">\n  </a>\n  <a aria-label=\"Releases\" href=\"https://github.com/canner/WrenAI/releases\">\n    <img alt=\"\" src=\"https://img.shields.io/github/v/release/canner/WrenAI?logo=github&label=GitHub%20Release&color=blue&style=for-the-badge\">\n  </a>\n  <a aria-label=\"License\" href=\"https://github.com/Canner/WrenAI/blob/main/LICENSE\">\n    <img alt=\"\" src=\"https://img.shields.io/github/license/canner/WrenAI?color=blue&style=for-the-badge\">\n  </a>\n  <a href=\"https://docs.getwren.ai\">\n    <img src=\"https://img.shields.io/badge/docs-online-brightgreen?style=for-the-badge\" alt=\"Docs\">\n  </a>\n  <a aria-label=\"Join the community on GitHub\" href=\"https://discord.gg/5DvshJqG8Z\">\n    <img alt=\"\" src=\"https://img.shields.io/badge/-JOIN%20THE%20COMMUNITY-blue?style=for-the-badge&logo=discord&logoColor=white&labelColor=grey&logoWidth=20\">\n  </a>\n  <a aria-label=\"Canner\" href=\"https://cannerdata.com/?utm_source=github&utm_medium=badge&utm_campaign=readme\">\n    <img src=\"https://img.shields.io/badge/%F0%9F%A7%A1-Made%20by%20Canner-blue?style=for-the-badge\">\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://trendshift.io/repositories/9263\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/9263\" alt=\"Canner%2FWrenAI | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</p>\n\n> âš¡ GenBI (Generative BI) queries any database in natural language, generates accurate SQL (Text-to-SQL), charts (Text-to-Chart), and AI-powered business intelligence in seconds. ï¸\n\n<p align=\"center\">\n  <img width=\"1920\" height=\"1080\" alt=\"1\" src=\"https://github.com/user-attachments/assets/bba9d37a-33e3-49ab-b7cb-32fd6dddc8d1\" />\n</p>\n \n## ğŸ˜ Demos\n\nhttps://github.com/user-attachments/assets/f9c1cb34-5a95-4580-8890-ec9644da4160\n\n[Watch GenBI Demo](https://github.com/user-attachments/assets/90ad1d35-bb1e-490b-9676-b29863ff090b)\n\n## ğŸ¤– Features\n\n|                    | What you get | Why it matters |\n|--------------------|--------------|----------------|\n| **Talk to Your Data** | Ask in any language â†’ precise SQL & answers | Slash the SQL learning curveï»¿ |\n| **GenBI Insights** | AI-written summaries, charts & reports | Decision-ready context in one clickï»¿ |\n| **Semantic Layer** | MDL models encode schema, metrics, joins | Keeps LLM outputs accurate & governedï»¿ |\n| **Embed via API**  | Generate queries & charts inside your apps ([API Docs](https://wrenai.readme.io/reference/cloud-getting-started)) | Build custom agents, SaaS features, chatbotsï»¿ ([Streamlit Live Demo](https://huggingface.co/spaces/getWrenAI/wrenai-cloud-api-demo)) |\n\nğŸ¤© [Learn more about GenBI](https://getwren.ai/genbi?utm_source=github&utm_medium=content&utm_campaign=readme)\n\n## ğŸš€ Getting Started\n\nUsing Wren AI is super simple, you can set it up within 3 minutes, and start to interact with your data!\n\n<p align=\"center\">\n  <img width=\"1920\" height=\"1080\" alt=\"2\" src=\"https://github.com/user-attachments/assets/6555f539-9ef2-485d-9135-0071741fda96\" />\n</p>\n\n- Visit our [Install in your local environment](http://docs.getwren.ai/oss/installation?utm_source=github&utm_medium=content&utm_campaign=readme).\n- Visit the [Usage Guides](https://docs.getwren.ai/oss/guide/connect/overview?utm_source=github&utm_medium=content&utm_campaign=readme) to learn more about how to use Wren AI.\n- Or just start with [Wren AI Cloud](https://getwren.ai/?utm_source=github&utm_medium=content&utm_campaign=readme) our Managed Cloud Service. ([OSS vs. Commercial Plans](https://docs.getwren.ai/oss/overview/cloud_vs_self_host)).\n\n## ğŸ—ï¸ Architecture\n\n<p align=\"center\">\n  <img width=\"1011\" height=\"682\" alt=\"wrenai-architecture\" src=\"https://github.com/user-attachments/assets/e99b999f-9912-4fa7-921a-9c86b6b83354\" />\n</p>\n\nğŸ‘‰ [Learn more about our Design](https://getwren.ai/post/how-we-design-our-semantic-engine-for-llms-the-backbone-of-the-semantic-layer-for-llm-architecture?utm_source=github&utm_medium=content&utm_campaign=readme)\n\n\n\n## ğŸ”Œ Data Sources\n\nIf your data source is not listed here, vote for it in our [GitHub discussion thread](https://github.com/Canner/WrenAI/discussions/327). It will be a valuable input for us to decide on the next supported data sources.\n- Athena (Trino)\n- Redshift\n- BigQuery\n- DuckDB\n- Databricks\n- PostgreSQL\n- MySQL\n- Microsoft SQL Server\n- ClickHouse\n- Oracle\n- Trino\n- Snowflake\n\n## ğŸ¤– LLM Models\n\nWren AI supports integration with various Large Language Models (LLMs), including but not limited to:\n- OpenAI Models\n- Azure OpenAI Models\n- DeepSeek Models\n- Google AI Studio â€“ Gemini Models\n- Vertex AI Models (Gemini + Anthropic)\n- Bedrock Models\n- Anthropic API Models\n- Groq Models\n- Ollama Models\n- Databricks Models\n\nCheck [configuration examples here](https://github.com/Canner/WrenAI/tree/main/wren-ai-service/docs/config_examples)!\n\n> [!CAUTION]\n> The performance of Wren AI depends significantly on the capabilities of the LLM you choose. We strongly recommend using the most powerful model available for optimal results. Using less capable models may lead to reduced performance, slower response times, or inaccurate outputs.\n\n## ğŸ“š Documentation\n\nVisit [Wren AI documentation](https://docs.getwren.ai/oss/overview/introduction?utm_source=github&utm_medium=content&utm_campaign=readme) to view the full documentation.\n\n## ğŸ“ª Keep Posted?\n\n[Subscribe our blog](https://www.getwren.ai/blog/?utm_source=github&utm_medium=content&utm_campaign=readme) and [Follow our LinkedIn](https://www.linkedin.com/company/wrenai)\n\n## ğŸ› ï¸ Contribution\n\n1.\tStar â­ the repo to show support (it really helps).\n2.\tOpen an issue for bugs, ideas, or discussions.\n3.\tRead [Contribution Guidelines](https://github.com/Canner/WrenAI/blob/main/CONTRIBUTING.md) for setup & PR guidelines.\n\n## â­ï¸ Community\n\n- Join 1.3k+ developers in our [Discord](https://discord.gg/5DvshJqG8Z) for real-time help and roadmap previews.\n- If there are any issues, please visit [GitHub Issues](https://github.com/Canner/WrenAI/issues).\n- Explore our [public roadmap](https://wrenai.notion.site/) to stay updated on upcoming features and improvements!\n\nPlease note that our [Code of Conduct](./CODE_OF_CONDUCT.md) applies to all Wren AI community channels. Users are **highly encouraged** to read and adhere to them to avoid repercussions.\n\n## ğŸ‰ Our Contributors\n<a href=\"https://github.com/canner/wrenAI/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=Canner/WrenAI\" />\n</a>\n\n<p align=\"right\">\n  <a href=\"#top\">â¬†ï¸ Back to Top</a>\n</p>\n",
      "stars_today": 39
    },
    {
      "id": 53538899,
      "name": "clients",
      "full_name": "bitwarden/clients",
      "description": "Bitwarden client apps (web, browser extension, desktop, and cli).",
      "html_url": "https://github.com/bitwarden/clients",
      "stars": 12020,
      "forks": 1627,
      "language": "TypeScript",
      "topics": [
        "angular",
        "bitwarden",
        "browser-extension",
        "chrome",
        "cli",
        "desktop",
        "electron",
        "firefox",
        "javascript",
        "nodejs",
        "safari",
        "typescript",
        "webextension"
      ],
      "created_at": "2016-03-09T23:14:01Z",
      "updated_at": "2026-02-07T00:36:28Z",
      "pushed_at": "2026-02-07T00:48:24Z",
      "open_issues": 1013,
      "owner": {
        "login": "bitwarden",
        "avatar_url": "https://avatars.githubusercontent.com/u/15990069?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bitwarden/brand/main/screenshots/apps-combo-logo.png\" alt=\"Bitwarden\" />\n</p>\n<p align=\"center\">\n  <a href=\"https://github.com/bitwarden/clients/actions/workflows/build-browser.yml?query=branch:main\" target=\"_blank\"><img src=\"https://github.com/bitwarden/clients/actions/workflows/build-browser.yml/badge.svg?branch=main\" alt=\"GitHub Workflow browser build on main\" /></a>\n  <a href=\"https://github.com/bitwarden/clients/actions/workflows/build-cli.yml?query=branch:main\" target=\"_blank\"><img src=\"https://github.com/bitwarden/clients/actions/workflows/build-cli.yml/badge.svg?branch=main\" alt=\"GitHub Workflow CLI build on main\" /></a>\n  <a href=\"https://github.com/bitwarden/clients/actions/workflows/build-desktop.yml?query=branch:main\" target=\"_blank\"><img src=\"https://github.com/bitwarden/clients/actions/workflows/build-desktop.yml/badge.svg?branch=main\" alt=\"GitHub Workflow desktop build on main\" /></a>\n  <a href=\"https://github.com/bitwarden/clients/actions/workflows/build-web.yml?query=branch:main\" target=\"_blank\"><img src=\"https://github.com/bitwarden/clients/actions/workflows/build-web.yml/badge.svg?branch=main\" alt=\"GitHub Workflow web build on main\" /></a>\n  <a href=\"https://gitter.im/bitwarden/Lobby\" target=\"_blank\"><img src=\"https://badges.gitter.im/bitwarden/Lobby.svg\" alt=\"gitter chat\" /></a>\n</p>\n\n---\n\n# Bitwarden Client Applications\n\nThis repository houses all Bitwarden client applications except the mobile applications ([iOS](https://github.com/bitwarden/ios) | [android](https://github.com/bitwarden/android)).\n\nPlease refer to the [Clients section](https://contributing.bitwarden.com/getting-started/clients/) of the [Contributing Documentation](https://contributing.bitwarden.com/) for build instructions, recommended tooling, code style tips, and lots of other great information to get you started.\n\n## Related projects:\n\n- [bitwarden/server](https://github.com/bitwarden/server): The core infrastructure backend (API, database, Docker, etc).\n- [bitwarden/ios](https://github.com/bitwarden/ios): Bitwarden iOS Password Manager & Authenticator apps.\n- [bitwarden/android](https://github.com/bitwarden/android): Bitwarden Android Password Manager & Authenticator apps.\n- [bitwarden/directory-connector](https://github.com/bitwarden/directory-connector): A tool for syncing a directory (AD, LDAP, Azure, G Suite, Okta) to an organization.\n\n# We're Hiring!\n\nInterested in contributing in a big way? Consider joining our team! We're hiring for many positions. Please take a look at our [Careers page](https://bitwarden.com/careers/) to see what opportunities are [currently open](https://bitwarden.com/careers/#open-positions) as well as what it's like to work at Bitwarden.\n\n# Contribute\n\nCode contributions are welcome! Please commit any pull requests against the `main` branch. Learn more about how to contribute by reading the [Contributing Guidelines](https://contributing.bitwarden.com/contributing/). Check out the [Contributing Documentation](https://contributing.bitwarden.com/) for how to get started with your first contribution.\n\nSecurity audits and feedback are welcome. Please open an issue or email us privately if the report is sensitive in nature. You can read our security policy in the [`SECURITY.md`](SECURITY.md) file.\n",
      "stars_today": 38
    },
    {
      "id": 808045485,
      "name": "ladybird",
      "full_name": "LadybirdBrowser/ladybird",
      "description": "Truly independent web browser",
      "html_url": "https://github.com/LadybirdBrowser/ladybird",
      "stars": 58407,
      "forks": 2657,
      "language": "C++",
      "topics": [
        "browser",
        "browser-engine"
      ],
      "created_at": "2024-05-30T09:18:10Z",
      "updated_at": "2026-02-07T01:12:52Z",
      "pushed_at": "2026-02-06T18:25:28Z",
      "open_issues": 625,
      "owner": {
        "login": "LadybirdBrowser",
        "avatar_url": "https://avatars.githubusercontent.com/u/134672918?v=4"
      },
      "readme": "# Ladybird\n\n[Ladybird](https://ladybird.org) is a truly independent web browser, using a novel engine based on web standards.\n\n> [!IMPORTANT]\n> Ladybird is in a pre-alpha state, and only suitable for use by developers\n>\n\n## Features\n\nWe aim to build a complete, usable browser for the modern web.\n\nLadybird uses a multi-process architecture with a main UI process, several WebContent renderer processes,\nan ImageDecoder process, and a RequestServer process.\n\nImage decoding and network connections are done out of process to be more robust against malicious content.\nEach tab has its own renderer process, which is sandboxed from the rest of the system.\n\nAt the moment, many core library support components are inherited from SerenityOS:\n\n- LibWeb: Web rendering engine\n- LibJS: JavaScript engine\n- LibWasm: WebAssembly implementation\n- LibCrypto/LibTLS: Cryptography primitives and Transport Layer Security\n- LibHTTP: HTTP/1.1 client\n- LibGfx: 2D Graphics Library, Image Decoding and Rendering\n- LibUnicode: Unicode and locale support\n- LibMedia: Audio and video playback\n- LibCore: Event loop, OS abstraction layer\n- LibIPC: Inter-process communication\n\n## How do I build and run this?\n\nSee [build instructions](Documentation/BuildInstructionsLadybird.md) for information on how to build Ladybird.\n\nLadybird runs on Linux, macOS, Windows (with WSL2), and many other \\*Nixes.\n\n## How do I read the documentation?\n\nCode-related documentation can be found in the [documentation](Documentation/) folder.\n\n## Get in touch and participate!\n\nJoin [our Discord server](https://discord.gg/nvfjVJ4Svh) to participate in development discussion.\n\nPlease read [Getting started contributing](Documentation/GettingStartedContributing.md) if you plan to contribute to Ladybird for the first time.\n\nBefore opening an issue, please see the [issue policy](CONTRIBUTING.md#issue-policy) and the [detailed issue-reporting guidelines](ISSUES.md).\n\nThe full contribution guidelines can be found in [`CONTRIBUTING.md`](CONTRIBUTING.md).\n\n## License\n\nLadybird is licensed under a 2-clause BSD license.\n",
      "stars_today": 33
    },
    {
      "id": 245166720,
      "name": "zoxide",
      "full_name": "ajeetdsouza/zoxide",
      "description": "A smarter cd command. Supports all major shells.",
      "html_url": "https://github.com/ajeetdsouza/zoxide",
      "stars": 33204,
      "forks": 730,
      "language": "Rust",
      "topics": [
        "autojump",
        "bash",
        "cli",
        "command-line",
        "command-line-tool",
        "elvish",
        "fasd",
        "fish",
        "fish-shell",
        "fzf",
        "hacktoberfest",
        "jump",
        "nushell",
        "powershell",
        "rust",
        "shell",
        "xonsh",
        "xontrib",
        "z",
        "zsh"
      ],
      "created_at": "2020-03-05T13:11:40Z",
      "updated_at": "2026-02-07T01:42:57Z",
      "pushed_at": "2026-02-02T05:37:36Z",
      "open_issues": 151,
      "owner": {
        "login": "ajeetdsouza",
        "avatar_url": "https://avatars.githubusercontent.com/u/1777663?v=4"
      },
      "readme": "<!-- markdownlint-configure-file {\n  \"MD013\": {\n    \"code_blocks\": false,\n    \"tables\": false\n  },\n  \"MD033\": false,\n  \"MD041\": false\n} -->\n\n<div align=\"center\">\n\n<sup>Special thanks to:</sup>\n\n<!-- markdownlint-disable-next-line MD013 -->\n<div><a href=\"https://go.warp.dev/zoxide\"><img alt=\"Sponsored by Warp\" width=\"230\" src=\"https://raw.githubusercontent.com/warpdotdev/brand-assets/refs/heads/main/Github/Sponsor/Warp-Github-LG-03.png\" /></a></div>\n<div><sup><b>Warp, built for coding with multiple AI agents.</b></sup></div>\n<div><sup>Available for macOS, Linux, and Windows.</sup></div>\n<div><sup>\n  Visit\n  <a href=\"https://go.warp.dev/zoxide\"><u>warp.dev</u></a>\n  to learn more.\n</sup></div>\n\n<hr />\n\n# zoxide\n\n[![crates.io][crates.io-badge]][crates.io]\n[![Downloads][downloads-badge]][releases]\n[![Built with Nix][builtwithnix-badge]][builtwithnix]\n\nzoxide is a **smarter cd command**, inspired by z and autojump.\n\nIt remembers which directories you use most frequently, so you can \"jump\" to\nthem in just a few keystrokes.<br />\nzoxide works on all major shells.\n\n[Getting started](#getting-started) â€¢\n[Installation](#installation) â€¢\n[Configuration](#configuration) â€¢\n[Integrations](#third-party-integrations)\n\n</div>\n\n## Getting started\n\n![Tutorial][tutorial]\n\n```sh\nz foo              # cd into highest ranked directory matching foo\nz foo bar          # cd into highest ranked directory matching foo and bar\nz foo /            # cd into a subdirectory starting with foo\n\nz ~/foo            # z also works like a regular cd command\nz foo/             # cd into relative path\nz ..               # cd one level up\nz -                # cd into previous directory\n\nzi foo             # cd with interactive selection (using fzf)\n\nz foo<SPACE><TAB>  # show interactive completions (zoxide v0.8.0+, bash 4.4+/fish/zsh only)\n```\n\nRead more about the matching algorithm [here][algorithm-matching].\n\n## Installation\n\nzoxide can be installed in 4 easy steps:\n\n1. **Install binary**\n\n   zoxide runs on most major platforms. If your platform isn't listed below,\n   please [open an issue][issues].\n\n   <details>\n   <summary>Linux / WSL</summary>\n\n   > The recommended way to install zoxide is via the install script:\n   >\n   > ```sh\n   > curl -sSfL https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh | sh\n   > ```\n   >\n   > Or, you can use a package manager:\n   >\n   > | Distribution        | Repository                  | Instructions                                                                                          |\n   > | ------------------- | --------------------------- | ----------------------------------------------------------------------------------------------------- |\n   > | **_Any_**           | **[crates.io]**             | `cargo install zoxide --locked`                                                                       |\n   > | _Any_               | [asdf]                      | `asdf plugin add zoxide https://github.com/nyrst/asdf-zoxide.git` <br /> `asdf install zoxide latest` |\n   > | _Any_               | [conda-forge]               | `conda install -c conda-forge zoxide`                                                                 |\n   > | _Any_               | [guix]                      | `guix install zoxide`                                                                                 |\n   > | _Any_               | [Linuxbrew]                 | `brew install zoxide`                                                                                 |\n   > | _Any_               | [nixpkgs]                   | `nix-env -iA nixpkgs.zoxide`                                                                          |\n   > | Alpine Linux 3.13+  | [Alpine Linux Packages]     | `apk add zoxide`                                                                                      |\n   > | Arch Linux          | [Arch Linux Extra]          | `pacman -S zoxide`                                                                                    |\n   > | ~Debian~[^1]    | ~[Debian Packages]~         | ~`apt install zoxide`~                                                                                    |\n   > | Devuan 4.0+         | [Devuan Packages]           | `apt install zoxide`                                                                                  |\n   > | Exherbo Linux       | [Exherbo packages]          | `cave resolve -x repository/rust` <br /> `cave resolve -x zoxide`                                     |\n   > | Fedora 32+          | [Fedora Packages]           | `dnf install zoxide`                                                                                  |\n   > | Gentoo              | [Gentoo Packages]           | `emerge app-shells/zoxide`                                                                            |\n   > | Manjaro             |                             | `pacman -S zoxide`                                                                                    |\n   > | openSUSE Tumbleweed | [openSUSE Factory]          | `zypper install zoxide`                                                                               |\n   > | ~Parrot OS~[^1]     |                             | ~`apt install zoxide`~                                                                                |\n   > | ~Raspbian~[^1]  | ~[Raspbian Packages]~       | ~`apt install zoxide`~                                                                                    |\n   > | Rhino Linux         | [Pacstall Packages]         | `pacstall -I zoxide-deb`                                                                              |\n   > | Slackware 15.0+     | [SlackBuilds]               | [Instructions][slackbuilds-howto]                                                                     |\n   > | Solus               | [Solus Packages]            | `eopkg install zoxide`                                                                                |\n   > | ~Ubuntu~[^1]        | ~[Ubuntu Packages]~         | ~`apt install zoxide`~                                                                                |\n   > | Void Linux          | [Void Linux Packages]       | `xbps-install -S zoxide`                                                                              |\n\n   </details>\n\n   <details>\n   <summary>macOS</summary>\n\n   > To install zoxide, use a package manager:\n   >\n   > | Repository      | Instructions                                                                                          |\n   > | --------------- | ----------------------------------------------------------------------------------------------------- |\n   > | **[crates.io]** | `cargo install zoxide --locked`                                                                       |\n   > | **[Homebrew]**  | `brew install zoxide`                                                                                 |\n   > | [asdf]          | `asdf plugin add zoxide https://github.com/nyrst/asdf-zoxide.git` <br /> `asdf install zoxide latest` |\n   > | [conda-forge]   | `conda install -c conda-forge zoxide`                                                                 |\n   > | [MacPorts]      | `port install zoxide`                                                                                 |\n   > | [nixpkgs]       | `nix-env -iA nixpkgs.zoxide`                                                                          |\n   >\n   > Or, run this command in your terminal:\n   >\n   > ```sh\n   > curl -sSfL https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh | sh\n   > ```\n\n   </details>\n\n   <details>\n   <summary>Windows</summary>\n\n   > zoxide works with PowerShell, as well as shells running in Cygwin, Git\n   > Bash, and MSYS2.\n   >\n   > The recommended way to install zoxide is via `winget`:\n   >\n   > ```sh\n   > winget install ajeetdsouza.zoxide\n   > ```\n   >\n   > Or, you can use an alternative package manager:\n   >\n   > | Repository      | Instructions                          |\n   > | --------------- | ------------------------------------- |\n   > | **[crates.io]** | `cargo install zoxide --locked`       |\n   > | [Chocolatey]    | `choco install zoxide`                |\n   > | [conda-forge]   | `conda install -c conda-forge zoxide` |\n   > | [Scoop]         | `scoop install zoxide`                |\n   >\n   > If you're using Cygwin, Git Bash, or MSYS2, you can also use the install script:\n   >\n   > ```sh\n   > curl -sSfL https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh | sh\n   > ```\n\n   </details>\n\n   <details>\n   <summary>BSD</summary>\n\n   > To install zoxide, use a package manager:\n   >\n   > | Distribution  | Repository      | Instructions                    |\n   > | ------------- | --------------- | ------------------------------- |\n   > | **_Any_**     | **[crates.io]** | `cargo install zoxide --locked` |\n   > | DragonFly BSD | [DPorts]        | `pkg install zoxide`            |\n   > | FreeBSD       | [FreshPorts]    | `pkg install zoxide`            |\n   > | NetBSD        | [pkgsrc]        | `pkgin install zoxide`          |\n   >\n   > Or, run this command in your terminal:\n   >\n   > ```sh\n   > curl -sS https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh | bash\n   > ```\n\n   </details>\n\n   <details>\n   <summary>Android</summary>\n\n   > To install zoxide, use a package manager:\n   >\n   > | Repository | Instructions         |\n   > | ---------- | -------------------- |\n   > | [Termux]   | `pkg install zoxide` |\n   >\n   > Or, run this command in your terminal:\n   >\n   > ```sh\n   > curl -sS https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh | bash\n   > ```\n\n   </details>\n\n2. **Setup zoxide on your shell**\n\n   To start using zoxide, add it to your shell.\n\n   <details>\n   <summary>Bash</summary>\n\n   > Add this to the <ins>**end**</ins> of your config file (usually `~/.bashrc`):\n   >\n   > ```sh\n   > eval \"$(zoxide init bash)\"\n   > ```\n\n   </details>\n\n   <details>\n   <summary>Elvish</summary>\n\n   > Add this to the <ins>**end**</ins> of your config file (usually `~/.elvish/rc.elv`):\n   >\n   > ```sh\n   > eval (zoxide init elvish | slurp)\n   > ```\n   >\n   > **Note**\n   > zoxide only supports elvish v0.18.0 and above.\n\n   </details>\n\n   <details>\n   <summary>Fish</summary>\n\n   > Add this to the <ins>**end**</ins> of your config file (usually\n   > `~/.config/fish/config.fish`):\n   >\n   > ```sh\n   > zoxide init fish | source\n   > ```\n\n   </details>\n\n   <details>\n   <summary>Nushell</summary>\n\n   > Add this to the <ins>**end**</ins> of your env file (find it by running `$nu.env-path`\n   > in Nushell):\n   >\n   > ```sh\n   > zoxide init nushell | save -f ~/.zoxide.nu\n   > ```\n   >\n   > Now, add this to the <ins>**end**</ins> of your config file (find it by running\n   > `$nu.config-path` in Nushell):\n   >\n   > ```sh\n   > source ~/.zoxide.nu\n   > ```\n   >\n   > **Note**\n   > zoxide only supports Nushell v0.89.0+.\n\n   </details>\n\n   <details>\n   <summary>PowerShell</summary>\n\n   > Add this to the <ins>**end**</ins> of your config file (find it by running\n   > `echo $profile` in PowerShell):\n   >\n   > ```powershell\n   > Invoke-Expression (& { (zoxide init powershell | Out-String) })\n   > ```\n\n   </details>\n\n   <details>\n   <summary>Tcsh</summary>\n\n   > Add this to the <ins>**end**</ins> of your config file (usually `~/.tcshrc`):\n   >\n   > ```sh\n   > zoxide init tcsh > ~/.zoxide.tcsh\n   > source ~/.zoxide.tcsh\n   > ```\n\n   </details>\n\n   <details>\n   <summary>Xonsh</summary>\n\n   > Add this to the <ins>**end**</ins> of your config file (usually `~/.xonshrc`):\n   >\n   > ```python\n   > execx($(zoxide init xonsh), 'exec', __xonsh__.ctx, filename='zoxide')\n   > ```\n\n   </details>\n\n   <details>\n   <summary>Zsh</summary>\n\n   > Add this to the <ins>**end**</ins> of your config file (usually `~/.zshrc`):\n   >\n   > ```sh\n   > eval \"$(zoxide init zsh)\"\n   > ```\n   >\n   > For completions to work, the above line must be added _after_ `compinit` is\n   > called. You may have to rebuild your completions cache by running\n   > `rm ~/.zcompdump*; compinit`.\n\n   </details>\n\n   <details>\n   <summary>Any POSIX shell</summary>\n\n   > Add this to the <ins>**end**</ins> of your config file:\n   >\n   > ```sh\n   > eval \"$(zoxide init posix --hook prompt)\"\n   > ```\n\n   </details>\n\n3. **Install fzf** <sup>(optional)</sup>\n\n   [fzf] is a command-line fuzzy finder, used by zoxide for completions /\n   interactive selection. It can be installed from [here][fzf-installation].\n\n   > **Note**\n   > The minimum supported fzf version is v0.51.0.\n\n4. **Import your data** <sup>(optional)</sup>\n\n   If you currently use any of these plugins, you may want to import your data\n   into zoxide:\n\n   <details>\n   <summary>autojump</summary>\n\n   > Run this command in your terminal:\n   >\n   > ```sh\n   > zoxide import --from=autojump \"/path/to/autojump/db\"\n   > ```\n   >\n   > The path usually varies according to your system:\n   >\n   > | OS      | Path                                                                                 | Example                                                |\n   > | ------- | ------------------------------------------------------------------------------------ | ------------------------------------------------------ |\n   > | Linux   | `$XDG_DATA_HOME/autojump/autojump.txt` or `$HOME/.local/share/autojump/autojump.txt` | `/home/alice/.local/share/autojump/autojump.txt`       |\n   > | macOS   | `$HOME/Library/autojump/autojump.txt`                                                | `/Users/Alice/Library/autojump/autojump.txt`           |\n   > | Windows | `%APPDATA%\\autojump\\autojump.txt`                                                    | `C:\\Users\\Alice\\AppData\\Roaming\\autojump\\autojump.txt` |\n\n   </details>\n\n   <details>\n   <summary>fasd, z, z.lua, zsh-z</summary>\n\n   > Run this command in your terminal:\n   >\n   > ```sh\n   > zoxide import --from=z \"path/to/z/db\"\n   > ```\n   >\n   > The path usually varies according to your system:\n   >\n   > | Plugin           | Path                                                                                |\n   > | ---------------- | ----------------------------------------------------------------------------------- |\n   > | fasd             | `$_FASD_DATA` or `$HOME/.fasd`                                                      |\n   > | z (bash/zsh)     | `$_Z_DATA` or `$HOME/.z`                                                            |\n   > | z (fish)         | `$Z_DATA` or `$XDG_DATA_HOME/z/data` or `$HOME/.local/share/z/data`                 |\n   > | z.lua (bash/zsh) | `$_ZL_DATA` or `$HOME/.zlua`                                                        |\n   > | z.lua (fish)     | `$XDG_DATA_HOME/zlua/zlua.txt` or `$HOME/.local/share/zlua/zlua.txt` or `$_ZL_DATA` |\n   > | zsh-z            | `$ZSHZ_DATA` or `$_Z_DATA` or `$HOME/.z`                                            |\n\n   </details>\n\n   <details>\n   <summary>ZLocation</summary>\n\n   > Run this command in PowerShell:\n   >\n   > ```powershell\n   > $db = New-TemporaryFile\n   > (Get-ZLocation).GetEnumerator() | ForEach-Object { Write-Output ($_.Name+'|'+$_.Value+'|0') } | Out-File $db\n   > zoxide import --from=z $db\n   > ```\n\n   </details>\n\n## Configuration\n\n### Flags\n\nWhen calling `zoxide init`, the following flags are available:\n\n- `--cmd`\n  - Changes the prefix of the `z` and `zi` commands.\n  - `--cmd j` would change the commands to (`j`, `ji`).\n  - `--cmd cd` would replace the `cd` command.\n- `--hook <HOOK>`\n  - Changes how often zoxide increments a directory's score:\n\n    | Hook            | Description                       |\n    | --------------- | --------------------------------- |\n    | `none`          | Never                             |\n    | `prompt`        | At every shell prompt             |\n    | `pwd` (default) | Whenever the directory is changed |\n\n- `--no-cmd`\n  - Prevents zoxide from defining the `z` and `zi` commands.\n  - These functions will still be available in your shell as `__zoxide_z` and\n    `__zoxide_zi`, should you choose to redefine them.\n\n### Environment variables\n\nEnvironment variables[^2] can be used for configuration. They must be set before\n`zoxide init` is called.\n\n- `_ZO_DATA_DIR`\n  - Specifies the directory in which the database is stored.\n  - The default value varies across OSes:\n\n    | OS          | Path                                     | Example                                    |\n    | ----------- | ---------------------------------------- | ------------------------------------------ |\n    | Linux / BSD | `$XDG_DATA_HOME` or `$HOME/.local/share` | `/home/alice/.local/share`                 |\n    | macOS       | `$HOME/Library/Application Support`      | `/Users/Alice/Library/Application Support` |\n    | Windows     | `%LOCALAPPDATA%`                         | `C:\\Users\\Alice\\AppData\\Local`             |\n\n- `_ZO_ECHO`\n  - When set to 1, `z` will print the matched directory before navigating to\n    it.\n- `_ZO_EXCLUDE_DIRS`\n  - Excludes the specified directories from the database.\n  - This is provided as a list of [globs][glob], separated by OS-specific\n    characters:\n\n    | OS                  | Separator | Example                 |\n    | ------------------- | --------- | ----------------------- |\n    | Linux / macOS / BSD | `:`       | `$HOME:$HOME/private/*` |\n    | Windows             | `;`       | `$HOME;$HOME/private/*` |\n\n  - By default, this is set to `\"$HOME\"`.\n- `_ZO_FZF_OPTS`\n  - Custom options to pass to [fzf] during interactive selection. See\n    [`man fzf`][fzf-man] for the list of options.\n- `_ZO_MAXAGE`\n  - Configures the [aging algorithm][algorithm-aging], which limits the maximum\n    number of entries in the database.\n  - By default, this is set to 10000.\n- `_ZO_RESOLVE_SYMLINKS`\n  - When set to 1, `z` will resolve symlinks before adding directories to the\n    database.\n\n## Third-party integrations\n\n| Application           | Description                                  | Plugin                     |\n| --------------------- | -------------------------------------------- | -------------------------- |\n| [aerc]                | Email client                                 | Natively supported         |\n| [alfred]              | macOS launcher                               | [alfred-zoxide]            |\n| [clink]               | Improved cmd.exe for Windows                 | [clink-zoxide]             |\n| [emacs]               | Text editor                                  | [zoxide.el]                |\n| [felix]               | File manager                                 | Natively supported         |\n| [joshuto]             | File manager                                 | Natively supported         |\n| [lf]                  | File manager                                 | See the [wiki][lf-wiki]    |\n| [nnn]                 | File manager                                 | [nnn-autojump]             |\n| [ranger]              | File manager                                 | [ranger-zoxide]            |\n| [raycast]             | macOS launcher                               | [raycast-zoxide]           |\n| [rfm]                 | File manager                                 | Natively supported         |\n| [sesh]                | `tmux` session manager                       | Natively supported         |\n| [telescope.nvim]      | Fuzzy finder for Neovim                      | [telescope-zoxide]         |\n| [tmux-session-wizard] | `tmux` session manager                       | Natively supported         |\n| [tmux-sessionx]       | `tmux` session manager                       | Natively supported         |\n| [vim] / [neovim]      | Text editor                                  | [zoxide.vim]               |\n| [xplr]                | File manager                                 | [zoxide.xplr]              |\n| [xxh]                 | Transports shell configuration over SSH      | [xxh-plugin-prerun-zoxide] |\n| [yazi]                | File manager                                 | Natively supported         |\n| [zabb]                | Finds the shortest possible query for a path | Natively supported         |\n| [zesh]                | `zellij` session manager                     | Natively supported         |\n| [zsh-autocomplete]    | Realtime completions for zsh                 | Natively supported         |\n\n[^1]:\n    Debian / Ubuntu derivatives update their packages very slowly. If you're\n    using one of these distributions, consider using the install script instead.\n\n[^2]:\n    If you're not sure how to set an environment variable on your shell, check\n    out the [wiki][wiki-env].\n\n[aerc]: https://github.com/rjarry/aerc\n[alfred]: https://www.alfredapp.com/\n[alfred-zoxide]: https://github.com/yihou/alfred-zoxide\n[algorithm-aging]: https://github.com/ajeetdsouza/zoxide/wiki/Algorithm#aging\n[algorithm-matching]: https://github.com/ajeetdsouza/zoxide/wiki/Algorithm#matching\n[alpine linux packages]: https://pkgs.alpinelinux.org/packages?name=zoxide\n[arch linux extra]: https://archlinux.org/packages/extra/x86_64/zoxide/\n[asdf]: https://github.com/asdf-vm/asdf\n[builtwithnix-badge]: https://img.shields.io/badge/builtwith-nix-7d81f7?logo=nixos&logoColor=white&style=flat-square\n[builtwithnix]: https://builtwithnix.org/\n[chocolatey]: https://community.chocolatey.org/packages/zoxide\n[clink-zoxide]: https://github.com/shunsambongi/clink-zoxide\n[clink]: https://github.com/mridgers/clink\n[conda-forge]: https://anaconda.org/conda-forge/zoxide\n[crates.io-badge]: https://img.shields.io/crates/v/zoxide?logo=rust&logoColor=white&style=flat-square\n[crates.io]: https://crates.io/crates/zoxide\n[debian packages]: https://packages.debian.org/stable/admin/zoxide\n[exherbo packages]: https://gitlab.exherbo.org/exherbo/rust/-/tree/master/packages/sys-apps/zoxide\n[devuan packages]: https://pkginfo.devuan.org/cgi-bin/package-query.html?c=package&q=zoxide\n[downloads-badge]: https://img.shields.io/github/downloads/ajeetdsouza/zoxide/total?logo=github&logoColor=white&style=flat-square\n[dports]: https://github.com/DragonFlyBSD/DPorts/tree/master/sysutils/zoxide\n[emacs]: https://www.gnu.org/software/emacs/\n[fedora packages]: https://src.fedoraproject.org/rpms/rust-zoxide\n[felix]: https://github.com/kyoheiu/felix\n[freshports]: https://www.freshports.org/sysutils/zoxide/\n[fzf-installation]: https://github.com/junegunn/fzf#installation\n[fzf-man]: https://manpages.ubuntu.com/manpages/en/man1/fzf.1.html\n[fzf]: https://github.com/junegunn/fzf\n[gentoo packages]: https://packages.gentoo.org/packages/app-shells/zoxide\n[glob]: https://man7.org/linux/man-pages/man7/glob.7.html\n[guix]: https://packages.guix.gnu.org/packages/zoxide/\n[homebrew]: https://formulae.brew.sh/formula/zoxide\n[issues]: https://github.com/ajeetdsouza/zoxide/issues/new\n[joshuto]: https://github.com/kamiyaa/joshuto\n[lf]: https://github.com/gokcehan/lf\n[lf-wiki]: https://github.com/gokcehan/lf/wiki/Integrations#zoxide\n[linuxbrew]: https://formulae.brew.sh/formula-linux/zoxide\n[macports]: https://ports.macports.org/port/zoxide/summary\n[neovim]: https://github.com/neovim/neovim\n[nixpkgs]: https://github.com/NixOS/nixpkgs/blob/master/pkgs/by-name/zo/zoxide/package.nix\n[nnn-autojump]: https://github.com/jarun/nnn/blob/master/plugins/autojump\n[nnn]: https://github.com/jarun/nnn\n[opensuse factory]: https://build.opensuse.org/package/show/openSUSE:Factory/zoxide\n[pacstall packages]: https://pacstall.dev/packages/zoxide-deb\n[pkgsrc]: https://pkgsrc.se/sysutils/zoxide\n[ranger-zoxide]: https://github.com/jchook/ranger-zoxide\n[ranger]: https://github.com/ranger/ranger\n[raspbian packages]: https://archive.raspbian.org/raspbian/pool/main/r/rust-zoxide/\n[raycast]: https://www.raycast.com/\n[raycast-zoxide]: https://www.raycast.com/mrpunkin/raycast-zoxide\n[releases]: https://github.com/ajeetdsouza/zoxide/releases\n[rfm]: https://github.com/dsxmachina/rfm\n[scoop]: https://github.com/ScoopInstaller/Main/tree/master/bucket/zoxide.json\n[sesh]: https://github.com/joshmedeski/sesh\n[slackbuilds]: https://slackbuilds.org/repository/15.0/system/zoxide/\n[slackbuilds-howto]: https://slackbuilds.org/howto/\n[solus packages]: https://github.com/getsolus/packages/tree/main/packages/z/zoxide/\n[telescope-zoxide]: https://github.com/jvgrootveld/telescope-zoxide\n[telescope.nvim]: https://github.com/nvim-telescope/telescope.nvim\n[termux]: https://github.com/termux/termux-packages/tree/master/packages/zoxide\n[tmux-session-wizard]: https://github.com/27medkamal/tmux-session-wizard\n[tmux-sessionx]: https://github.com/omerxx/tmux-sessionx\n[tutorial]: contrib/tutorial.webp\n[ubuntu packages]: https://packages.ubuntu.com/jammy/zoxide\n[vim]: https://github.com/vim/vim\n[void linux packages]: https://github.com/void-linux/void-packages/tree/master/srcpkgs/zoxide\n[wiki-env]: https://github.com/ajeetdsouza/zoxide/wiki/HOWTO:-set-environment-variables \"HOWTO: set environment variables\"\n[xplr]: https://github.com/sayanarijit/xplr\n[xxh-plugin-prerun-zoxide]: https://github.com/xxh/xxh-plugin-prerun-zoxide\n[xxh]: https://github.com/xxh/xxh\n[yazi]: https://github.com/sxyazi/yazi\n[zabb]: https://github.com/Mellbourn/zabb\n[zesh]: https://github.com/roberte777/zesh\n[zoxide.el]: https://gitlab.com/Vonfry/zoxide.el\n[zoxide.vim]: https://github.com/nanotee/zoxide.vim\n[zoxide.xplr]: https://github.com/sayanarijit/zoxide.xplr\n[zsh-autocomplete]: https://github.com/marlonrichert/zsh-autocomplete\n",
      "stars_today": 31
    },
    {
      "id": 189285554,
      "name": "stats",
      "full_name": "exelban/stats",
      "description": "macOS system monitor in your menu bar",
      "html_url": "https://github.com/exelban/stats",
      "stars": 36250,
      "forks": 1169,
      "language": "Swift",
      "topics": [
        "battery",
        "bluetooth",
        "clock",
        "cpu",
        "disk",
        "fans",
        "gpu",
        "macos",
        "menubar",
        "monitor",
        "network",
        "sensors",
        "stats",
        "temperature"
      ],
      "created_at": "2019-05-29T19:24:56Z",
      "updated_at": "2026-02-07T02:19:09Z",
      "pushed_at": "2026-02-01T17:00:03Z",
      "open_issues": 29,
      "owner": {
        "login": "exelban",
        "avatar_url": "https://avatars.githubusercontent.com/u/13332412?v=4"
      },
      "readme": "<div align=\"center\" markdown=\"1\">\n <sup>Special thanks to:</sup>\n <br><br>\n <a href=\"https://go.warp.dev/stats\">\n  <img width=\"400\" alt=\"Warp sponsorship\" src=\"https://github.com/user-attachments/assets/67ff3655-983d-43cf-9e99-51ce76afa3e7\"/>\n </a>\n <br><br>\n <a href=\"https://go.warp.dev/stats\">Warp is built for coding with multiple AI agents</a>\n</div>\n\n---\n\n# Stats\n\n<a href=\"https://github.com/exelban/stats/releases\"><p align=\"center\"><img src=\"https://github.com/exelban/stats/raw/master/Stats/Supporting%20Files/Assets.xcassets/AppIcon.appiconset/icon_256x256.png\" width=\"120\"></p></a>\n\n[![Stats](https://serhiy.s3.eu-central-1.amazonaws.com/Github_repo/stats/menus%3Fv2.3.2.png?v1)](https://github.com/exelban/stats/releases)\n[![Stats](https://serhiy.s3.eu-central-1.amazonaws.com/Github_repo/stats/popups%3Fv2.3.2.png?v3)](https://github.com/exelban/stats/releases)\n\nmacOS system monitor in your menu bar\n\n## Installation\n### Manual\nYou can download the latest version [here](https://github.com/exelban/stats/releases/latest/download/Stats.dmg).\nThis will download a file called `Stats.dmg`. Open it and move the app to the application folder.\n\n### Homebrew\nTo install it using Homebrew, open the Terminal app and type:\n```bash\nbrew install stats\n```\n\n### Legacy version\nLegacy version for older systems could be found [here](https://mac-stats.com/downloads).\n\n## Requirements\nStats is supported on the released macOS version starting from macOS 10.15 (Catalina).\n\n## Features\nStats is an application that allows you to monitor your macOS system.\n\n - CPU utilization\n - GPU utilization\n - Memory usage\n - Disk utilization\n - Network usage\n - Battery level\n - Fan's control (not maintained)\n - Sensors information (Temperature/Voltage/Power)\n - Bluetooth devices\n - Multiple time zone clock\n\n## FAQs\n\n### How do you change the order of the menu bar icons?\nmacOS decides the order of the menu bar items not `Stats` - it may change after the first reboot after installing Stats.\n\nTo change the order of any menu bar icon - macOS Mojave (version 10.14) and up.\n\n1. Hold down âŒ˜ (command key).\n2. Drag the icon to the desired position on the menu bar.\n3. Release âŒ˜ (command key)\n\n### How to reduce energy impact or CPU usage of Stats?\nStats tries to be efficient as it's possible. But reading some data periodically is not a cheap task. Each module has its own \"price\". So, if you want to reduce energy impact from the Stats you need to disable some Stats modules. The most inefficient modules are Sensors and Bluetooth. Disabling these modules could reduce CPU usage and power efficiency by up to 50% in some cases.\n\n### Fan control\nFan control is in legacy mode. It does not receive any updates or fixes. It's not dropped from the app just because in the old Macs it works pretty acceptable. I'm open to accepting fixed or improvements (via PR) for this feature in case someone would like to help with that. But have no option and time to provide support for this feature.\n\n### Sensors show incorrect CPU/GPU core count\nCPU/GPU sensors are simply thermal zones (sensors) on the CPU/GPU. They have no relation to the number of cores or specific cores.\nFor example, a CPU is typically divided into two clusters: efficiency and performance. Each cluster contains multiple temperature sensors, and Stats simply displays these sensors. However, \"CPU Efficient Core 1\" does not represent the temperature of a single efficient coreâ€”it only indicates one of the temperature sensors within the efficiency core cluster.\nAdditionally, with each new SoC, Apple changes the sensor keys. As a result, it takes time to determine which SMC values correspond to the appropriate sensors. If anyone knows how to accurately match the sensors for Apple Silicon, please contact me.\n\n### App crash â€“ what to do?\nFirst, ensure that you are using the latest version of Stats. There is a high chance that a fix preventing the crash has already been released. If you are already running the latest version, check the open issues. Only if none of the existing issues address your problem should you open a new issue.\n\n### Why my issue was closed without any response?\nMost probably because it's a duplicated issue and there is an answer to the question, report, or proposition. Please use a search by closed issues to get an answer.\nSo, if your issue was closed without any response, most probably it already has a response.\n\n### External API\nStats uses some external APIs, such as:\n\n- https://api.mac-stats.com â€“ For update checks and retrieving the public IP address\n- https://api.github.com â€“ Fallback for update checks\n\nBoth of these APIs are used to check for updates. Additionally, an external request is required to obtain the public IP address. I do not want to use any third-party providers for retrieving the public IP address, so I use my own server for this purpose.\n\nIf you have concerns about these requests, you have a few options:\n\n- propose a PR that allows these features to work without an external server\n- block both of these servers using any network filtering app (if you're reading this, you're likely using something like Little Snitch, so you can easily do this). In this case do not expect to receive any updates or see your public IP in the network module.\n\n\n## Supported languages\n- English\n- Polski\n- Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°\n- Ğ ÑƒÑÑĞºĞ¸Ğ¹\n- ä¸­æ–‡ (ç®€ä½“) (thanks to [chenguokai](https://github.com/chenguokai), [Tai-Zhou](https://github.com/Tai-Zhou), and [Jerry](https://github.com/Jerry23011))\n- TÃ¼rkÃ§e (thanks to [yusufozgul](https://github.com/yusufozgul) and [setanarut](https://github.com/setanarut))\n- í•œêµ­ì–´ (thanks to [escapeanaemia](https://github.com/escapeanaemia) and [iamhslee](https://github.com/iamhslee))\n- German (thanks to [natterstefan](https://github.com/natterstefan) and [aneitel](https://github.com/aneitel))\n- ä¸­æ–‡ (ç¹é«”) (thanks to [iamch15542](https://github.com/iamch15542) and [jrthsr700tmax](https://github.com/jrthsr700tmax))\n- Spanish (thanks to [jcconca](https://github.com/jcconca))\n- Vietnamese (thanks to [HXD.VN](https://github.com/xuandung38))\n- French (thanks to [RomainLt](https://github.com/RomainLt))\n- Italian (thanks to [gmcinalli](https://github.com/gmcinalli))\n- Portuguese (Brazil) (thanks to [marcelochaves95](https://github.com/marcelochaves95) and [pedroserigatto](https://github.com/pedroserigatto))\n- Norwegian BokmÃ¥l (thanks to [rubjo](https://github.com/rubjo))\n- æ—¥æœ¬èª (thanks to [treastrain](https://github.com/treastrain))\n- Portuguese (Portugal) (thanks to [AdamModus](https://github.com/AdamModus))\n- Czech (thanks to [mpl75](https://github.com/mpl75))\n- Magyar (thanks to [moriczr](https://github.com/moriczr))\n- Bulgarian (thanks to [zbrox](https://github.com/zbrox))\n- Romanian (thanks to [razluta](https://github.com/razluta))\n- Dutch (thanks to [ngohungphuc](https://github.com/ngohungphuc))\n- Hrvatski (thanks to [milotype](https://github.com/milotype))\n- Danish (thanks to [casperes1996](https://github.com/casperes1996) and [aleksanderbl29](https://github.com/aleksanderbl29))\n- Catalan (thanks to [davidalonso](https://github.com/davidalonso))\n- Indonesian (thanks to [yooody](https://github.com/yooody))\n- Hebrew (thanks to [BadSugar](https://github.com/BadSugar))\n- Slovenian (thanks to [zigapovhe](https://github.com/zigapovhe))\n- Greek (thanks to [sudoxcess](https://github.com/sudoxcess) and [vaionicle](https://github.com/vaionicle))\n- Persian (thanks to [ShawnAlisson](https://github.com/ShawnAlisson))\n- SlovenskÃ½ (thanks to [martinbernat](https://github.com/martinbernat))\n- Thai (thanks to [apiphoomchu](https://github.com/apiphoomchu))\n- Estonian (thanks to [postylem](https://github.com/postylem))\n- Hindi (thanks to [patiljignesh](https://github.com/patiljignesh))\n- Finnish (thanks to [eightscrow](https://github.com/eightscrow))\n\nYou can help by adding a new language or improving the existing translation.\n\n## License\n[MIT License](https://github.com/exelban/stats/blob/master/LICENSE)\n",
      "stars_today": 29
    },
    {
      "id": 908589694,
      "name": "meeting-minutes",
      "full_name": "Zackriya-Solutions/meeting-minutes",
      "description": "Privacy first, AI meeting assistant with 4x faster Parakeet/Whisper live transcription, speaker diarization, and Ollama summarization built on Rust. 100% local processing. no cloud required. Meetily (Meetly Ai - https://meetily.ai) is the #1 Self-hosted,  Open-source Ai meeting note taker for macOS & Windows.  ",
      "html_url": "https://github.com/Zackriya-Solutions/meeting-minutes",
      "stars": 9666,
      "forks": 848,
      "language": "Rust",
      "topics": [
        "ai",
        "ai-meeting-assistant",
        "llm",
        "local-ai",
        "mac",
        "meeting-minutes",
        "meeting-notes",
        "offline-first",
        "ollama",
        "parakeet",
        "privacy-focused",
        "privacy-tools",
        "rust",
        "self-hosted",
        "speech-to-text",
        "transcription",
        "whisper",
        "whisper-cpp",
        "windows"
      ],
      "created_at": "2024-12-26T12:52:14Z",
      "updated_at": "2026-02-07T02:28:38Z",
      "pushed_at": "2026-02-05T11:22:15Z",
      "open_issues": 127,
      "owner": {
        "login": "Zackriya-Solutions",
        "avatar_url": "https://avatars.githubusercontent.com/u/82556810?v=4"
      },
      "readme": "<div align=\"center\" style=\"border-bottom: none\">\n    <h1>\n        <img src=\"docs/Meetily-6.png\" style=\"border-radius: 10px;\" />\n        <br>\n        Privacy-First AI Meeting Assistant\n    </h1>\n    <a href=\"https://trendshift.io/repositories/13272\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/13272\" alt=\"Zackriya-Solutions%2Fmeeting-minutes | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n    <br>\n    <br>\n    <a href=\"https://github.com/Zackriya-Solutions/meeting-minutes/releases/\"><img src=\"https://img.shields.io/badge/Pre_Release-Link-brightgreen\" alt=\"Pre-Release\"></a>\n    <a href=\"https://github.com/Zackriya-Solutions/meeting-minutes/releases\"><img alt=\"GitHub Repo stars\" src=\"https://img.shields.io/github/stars/zackriya-solutions/meeting-minutes?style=flat\">\n</a>\n <a href=\"https://github.com/Zackriya-Solutions/meeting-minutes/releases\"> <img alt=\"GitHub Downloads (all assets, all releases)\" src=\"https://img.shields.io/github/downloads/zackriya-solutions/meeting-minutes/total?style=plastic\"> </a>\n    <a href=\"https://github.com/Zackriya-Solutions/meeting-minutes/releases\"><img src=\"https://img.shields.io/badge/License-MIT-blue\" alt=\"License\"></a>\n    <a href=\"https://github.com/Zackriya-Solutions/meeting-minutes/releases\"><img src=\"https://img.shields.io/badge/Supported_OS-macOS,_Windows-white\" alt=\"Supported OS\"></a>\n    <a href=\"https://github.com/Zackriya-Solutions/meeting-minutes/releases\"><img alt=\"GitHub Tag\" src=\"https://img.shields.io/github/v/tag/zackriya-solutions/meeting-minutes?include_prereleases&color=yellow\">\n</a>\n    <br>\n    <h3>\n    <br>\n    Open Source â€¢ Privacy-First â€¢ Enterprise-Ready\n    </h3>\n    <p align=\"center\">\n    Get latest <a href=\"https://www.zackriya.com/meetily-subscribe/\"><b>Product updates</b></a> <br><br>\n    <a href=\"https://meetily.ai\"><b>Website</b></a> â€¢\n    <a href=\"https://www.linkedin.com/company/106363062/\"><b>LinkedIn</b></a> â€¢\n    <a href=\"https://discord.gg/crRymMQBFH\"><b>Meetily Discord</b></a> â€¢\n    <a href=\"https://discord.com/invite/vCFJvN4BwJ\"><b>Privacy-First AI</b></a> â€¢\n    <a href=\"https://www.reddit.com/r/meetily/\"><b>Reddit</b></a>\n</p>\n    <p align=\"center\">\n\nA privacy-first AI meeting assistant that captures, transcribes, and summarizes meetings entirely on your infrastructure. Built by expert AI engineers passionate about data sovereignty and open source solutions. Perfect for enterprises that need advanced meeting intelligence without compromising on privacy, compliance, or control.\n\n</p>\n\n<p align=\"center\">\n    <img src=\"docs/meetily_demo.gif\" width=\"650\" alt=\"Meetily Demo\" />\n    <br>\n    <a href=\"https://youtu.be/6FnhSC_eSz8\">View full Demo Video</a>\n</p>\n\n</div>\n\n---\n\n> **ğŸ‰ New: Meetily PRO Available** - Looking for enhanced accuracy and advanced features? Check out our professional-grade solution with custom summary templates, advanced exports (PDF, DOCX), auto-meeting detection, built-in GDPR compliance, and many more. **This Community Edition remains forever free & open source**. [Learn more about PRO â†’](https://meetily.ai/pro/)\n\n---\n\n<details>\n<summary>Table of Contents</summary>\n\n- [Introduction](#introduction)\n- [Why Meetily?](#why-meetily)\n- [Features](#features)\n- [Installation](#installation)\n- [Key Features in Action](#key-features-in-action)\n- [System Architecture](#system-architecture)\n- [For Developers](#for-developers)\n- [Meetily PRO](#meetily-pro)\n- [Contributing](#contributing)\n- [License](#license)\n\n</details>\n\n## Introduction\n\nMeetily is a privacy-first AI meeting assistant that runs entirely on your local machine. It captures your meetings, transcribes them in real-time, and generates summaries, all without sending any data to the cloud. This makes it the perfect solution for professionals and enterprises who need to maintain complete control over their sensitive information.\n\n## Why Meetily?\n\nWhile there are many meeting transcription tools available, this solution stands out by offering:\n\n- **Privacy First:** All processing happens locally on your device.\n- **Cost-Effective:** Uses open-source AI models instead of expensive APIs.\n- **Flexible:** Works offline and supports multiple meeting platforms.\n- **Customizable:** Self-host and modify for your specific needs.\n\n<details>\n<summary>The Privacy Problem</summary>\n\nMeeting AI tools create significant privacy and compliance risks across all sectors:\n\n- **$4.4M average cost per data breach** (IBM 2024)\n- **â‚¬5.88 billion in GDPR fines** issued by 2025\n- **400+ unlawful recording cases** filed in California this year\n\nWhether you're a defense consultant, enterprise executive, legal professional, or healthcare provider, your sensitive discussions shouldn't live on servers you don't control. Cloud meeting tools promise convenience but deliver privacy nightmares with unclear data storage practices and potential unauthorized access.\n\n**Meetily solves this:** Complete data sovereignty on your infrastructure, zero vendor lock-in, and full control over your sensitive conversations.\n\n</details>\n\n## Features\n\n- **Local First:** All processing is done on your machine. No data ever leaves your computer.\n- **Real-time Transcription:** Get a live transcript of your meeting as it happens.\n- **AI-Powered Summaries:** Generate summaries of your meetings using powerful language models.\n- **Multi-Platform:** Works on macOS, Windows, and Linux.\n- **Open Source:** Meetily is open source and free to use.\n- **Flexible AI Provider Support:** Choose from Ollama (local), Claude, Groq, OpenRouter, or use your own OpenAI-compatible endpoint.\n\n## Installation\n\n### ğŸªŸ **Windows**\n\n1. Download the latest `x64-setup.exe` from [Releases](https://github.com/Zackriya-Solutions/meeting-minutes/releases/latest)\n2. Right-click the downloaded file â†’ **Properties** â†’ Check **Unblock** â†’ Click **OK**\n3. Run the installer (if Windows shows a security warning: Click **More info** â†’ **Run anyway**)\n\n### ğŸ **macOS**\n\n1. Download `meetily_0.2.0_aarch64.dmg` from [Releases](https://github.com/Zackriya-Solutions/meeting-minutes/releases/latest)\n2. Open the downloaded `.dmg` file\n3. Drag **Meetily** to your Applications folder\n4. Open **Meetily** from Applications folder\n\n### ğŸ§ **Linux**\n\nBuild from source following our detailed guides:\n\n- [Building on Linux](docs/building_in_linux.md)\n- [General Build Instructions](docs/BUILDING.md)\n\n**Quick start:**\n\n```bash\ngit clone https://github.com/Zackriya-Solutions/meeting-minutes\ncd meeting-minutes/frontend\npnpm install\n./build-gpu.sh\n```\n\n## Key Features in Action\n\n### ğŸ¯ Local Transcription\n\nTranscribe meetings entirely on your device using **Whisper** or **Parakeet** models. No cloud required.\n\n<p align=\"center\">\n    <img src=\"docs/home.png\" width=\"650\" style=\"border-radius: 10px;\" alt=\"Meetily Demo\" />\n</p>\n\n### ğŸ¤– AI-Powered Summaries\n\nGenerate meeting summaries with your choice of AI provider. **Ollama** (local) is recommended, with support for Claude, Groq, OpenRouter, and OpenAI.\n\n<p align=\"center\">\n    <img src=\"docs/summary.png\" width=\"650\" style=\"border-radius: 10px;\" alt=\"Summary generation\" />\n</p>\n\n<p align=\"center\">\n    <img src=\"docs/editor1.png\" width=\"650\" style=\"border-radius: 10px;\" alt=\"Editor Summary generation\" />\n</p>\n\n### ğŸ”’ Privacy-First Design\n\nAll data stays on your machine. Transcription models, recordings, and transcripts are stored locally.\n\n<p align=\"center\">\n    <img src=\"docs/settings.png\" width=\"650\" style=\"border-radius: 10px;\" alt=\"Local Transcription and storage\" />\n</p>\n\n### ğŸŒ Custom OpenAI Endpoint Support\n\nUse your own OpenAI-compatible endpoint for AI summaries. Perfect for organizations with custom AI infrastructure or preferred providers.\n\n<p align=\"center\">\n    <img src=\"docs/custom.png\" width=\"650\" style=\"border-radius: 10px;\" alt=\"Custom OpenAI Endpoint Configuration\" />\n</p>\n\n### ğŸ™ï¸ Professional Audio Mixing\n\nCapture microphone and system audio simultaneously with intelligent ducking and clipping prevention.\n\n<p align=\"center\">\n    <img src=\"docs/audio.png\" width=\"650\" style=\"border-radius: 10px;\" alt=\"Device selection\" />\n</p>\n\n### âš¡ GPU Acceleration\n\nBuilt-in support for hardware acceleration across platforms:\n\n- **macOS**: Apple Silicon (Metal) + CoreML\n- **Windows/Linux**: NVIDIA (CUDA), AMD/Intel (Vulkan)\n\nAutomatically enabled at build time - no configuration needed.\n\n## System Architecture\n\nMeetily is a single, self-contained application built with [Tauri](https://tauri.app/). It uses a Rust-based backend to handle all the core logic, and a Next.js frontend for the user interface.\n\nFor more details, see the [Architecture documentation](docs/architecture.md).\n\n## For Developers\n\nIf you want to contribute to Meetily or build it from source, you'll need to have Rust and Node.js installed. For detailed build instructions, please see the [Building from Source guide](docs/BUILDING.md).\n\n## Meetily Pro\n\n<p align=\"center\">\n    <img src=\"docs/pv2.1.png\" width=\"650\" style=\"border-radius: 10px;\" alt=\"Upcoming version\" />\n</p>\n\n**Meetily PRO** is a professional-grade solution with enhanced accuracy and advanced features for serious users and teams. Built on a different codebase with superior transcription models and enterprise-ready capabilities.\n\n### Key Advantages Over Community Edition:\n\n- **Enhanced Accuracy**: Superior transcription models for professional-grade accuracy\n- **Custom Summary Templates**: Tailor summaries to your specific workflow and needs\n- **Advanced Export Options**: PDF, DOCX, and Markdown exports with formatting\n- **Auto-detect and Join Meetings**: Automatic meeting detection and joining\n- **Speaker Identification**: Distinguish between speakers automatically *(Coming Soon)*\n- **Chat with Meetings**: AI-powered meeting insights and queries *(Coming Soon)*\n- **Calendar Integration**: Seamless integration with your calendar *(Coming Soon)*\n- **Self-Hosted Deployment**: Deploy on your own infrastructure for teams\n- **GDPR Compliance Built-In**: Privacy by design architecture with complete audit trails\n- **Priority Support**: Dedicated support for PRO users\n\n### Who is PRO for?\n\n- **Professionals** who need the highest accuracy for critical meetings\n- **Teams and organizations** (2-100 users) requiring self-hosted deployment\n- **Power users** who need advanced export formats and custom workflows\n- **Compliance-focused organizations** requiring GDPR readiness\n\n> **Note:** Meetily Community Edition remains **free & open source forever** with local transcription, AI summaries, and core features. PRO is a separate professional solution for users who need enhanced accuracy and advanced capabilities.\n\nFor organizations needing 100+ users or managed compliance solutions, explore [Meetily Enterprise](https://meetily.ai/enterprise/).\n\n**Learn more about pricing and features:** [https://meetily.ai/pro/](https://meetily.ai/pro/)\n\n## Contributing\n\nWe welcome contributions from the community! If you have any questions or suggestions, please open an issue or submit a pull request. Please follow the established project structure and guidelines. For more details, refer to the [CONTRIBUTING.md](CONTRIBUTING.md) file.\n\nThanks for all the contributions. Our community is what makes this project possible.\n\n## License\n\nMIT License - Feel free to use this project for your own purposes.\n\n## Acknowledgments\n\n- We borrowed some code from [Whisper.cpp](https://github.com/ggerganov/whisper.cpp).\n- We borrowed some code from [Screenpipe](https://github.com/mediar-ai/screenpipe).\n- We borrowed some code from [transcribe-rs](https://crates.io/crates/transcribe-rs).\n- Thanks to **NVIDIA** for developing the **Parakeet** model.\n- Thanks to [istupakov](https://huggingface.co/istupakov/parakeet-tdt-0.6b-v3-onnx) for providing the **ONNX conversion** of the Parakeet model.\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=Zackriya-Solutions/meeting-minutes&type=Date)](https://star-history.com/#Zackriya-Solutions/meeting-minutes&Date)\n",
      "stars_today": 29
    },
    {
      "id": 75785240,
      "name": "authelia",
      "full_name": "authelia/authelia",
      "description": "The Single Sign-On Multi-Factor portal for web apps, now OpenID Certifiedâ„¢",
      "html_url": "https://github.com/authelia/authelia",
      "stars": 26660,
      "forks": 1334,
      "language": "Go",
      "topics": [
        "2fa",
        "authentication",
        "docker",
        "golang",
        "kubernetes",
        "ldap",
        "mfa",
        "multifactor",
        "oauth2",
        "openid-connect",
        "passkeys",
        "push-notifications",
        "security",
        "sso",
        "sso-authentication",
        "totp",
        "two-factor",
        "two-factor-authentication",
        "webauthn",
        "yubikey"
      ],
      "created_at": "2016-12-07T00:56:57Z",
      "updated_at": "2026-02-07T02:21:55Z",
      "pushed_at": "2026-02-06T23:20:30Z",
      "open_issues": 118,
      "owner": {
        "login": "authelia",
        "avatar_url": "https://avatars.githubusercontent.com/u/59122411?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"https://www.authelia.com/images/authelia-title.png\" width=\"350\" title=\"Authelia\">\n</p>\n\n  [![Build](https://img.shields.io/buildkite/d6543d3ece3433f46dbe5fd9fcfaf1f68a6dbc48eb1048bc22/master?logo=buildkite&style=flat-square&color=brightgreen)](https://buildkite.com/authelia/authelia)\n  [![OpenSSF Best Practices](https://img.shields.io/static/v1?label=openssf%20best%20practices&logo=data:image/png;base64,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&message=passing&style=flat-square&color=brightgreen)](https://bestpractices.coreinfrastructure.org/projects/7128)\n  [![OpenSSF Scorecard](https://img.shields.io/ossf-scorecard/github.com/authelia/authelia?label=openssf+scorecard&style=flat-square&color=brightgreen)](https://scorecard.dev/viewer/?uri=github.com/authelia/authelia)\n  [![SLSA 3](https://img.shields.io/badge/slsa-level_3-brightgreen?style=flat-square&logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%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%2BCjwvc3ZnPgo%3D)](https://slsa.dev)\n  [![Go Report Card](https://goreportcard.com/badge/github.com/authelia/authelia/v4?logo=go&style=flat-square)](https://goreportcard.com/report/github.com/authelia/authelia/v4)\n  [![GitHub Release](https://img.shields.io/github/release/authelia/authelia.svg?logo=github&style=flat-square&color=blue)](https://github.com/authelia/authelia/releases)\n  [![Docker Tag](https://img.shields.io/docker/v/authelia/authelia/latest?logo=docker&style=flat-square&color=blue&sort=semver)](https://hub.docker.com/r/authelia/authelia/tags)\n  [![Docker Size](https://img.shields.io/docker/image-size/authelia/authelia/latest?logo=docker&style=flat-square&color=blue&sort=semver)](https://hub.docker.com/r/authelia/authelia/tags)\n  ![Docker Pulls](https://img.shields.io/docker/pulls/authelia/authelia?logo=docker&label=pulls&style=flat-square&color=blue)\n  [![AUR source version](https://img.shields.io/aur/version/authelia?logo=arch-linux&label=authelia&style=flat-square&color=blue)](https://aur.archlinux.org/packages/authelia/)\n  [![AUR binary version](https://img.shields.io/aur/version/authelia-bin?logo=arch-linux&label=authelia-bin&style=flat-square&color=blue)](https://aur.archlinux.org/packages/authelia-bin/)\n  [![AUR development version](https://img.shields.io/aur/version/authelia-git?logo=arch-linux&label=authelia-git&style=flat-square&color=blue)](https://aur.archlinux.org/packages/authelia-git/)\n  [![License](https://img.shields.io/github/license/authelia/authelia?logo=apache&style=flat-square&color=blue)][Apache 2.0]\n  [![Sponsor](https://img.shields.io/opencollective/all/authelia-sponsors?logo=Open%20Collective&label=financial%20contributors&style=flat-square&color=blue)](https://opencollective.com/authelia-sponsors)\n  [![Discord](https://img.shields.io/discord/707844280412012608?label=discord&logo=discord&style=flat-square&color=blue)](https://discord.authelia.com)\n  [![Matrix](https://img.shields.io/matrix/authelia-support:matrix.org?label=matrix&logo=matrix&style=flat-square&color=blue)](https://matrix.to/#/#support:authelia.com)\n\n**Authelia** is an open-source authentication and authorization server providing two-factor authentication and single\nsign-on (SSO) for your applications via a web portal. It acts as a companion for [reverse proxies](#proxy-support) by\nallowing, denying, or redirecting requests.\n\nDocumentation is available at [https://www.authelia.com/](https://www.authelia.com/).\n\nThe following is a simple diagram of the architecture:\n\n<p align=\"center\" style=\"margin:50px\">\n  <img src=\"https://www.authelia.com/images/archi.png\"/>\n</p>\n\n**Authelia** can be installed as a standalone service from the [AUR](https://aur.archlinux.org/packages/authelia/),\n[APT](https://apt.authelia.com/stable/debian/packages/authelia/),\n[FreeBSD Ports](https://svnweb.freebsd.org/ports/head/www/authelia/), or using a\n[static binary](https://github.com/authelia/authelia/releases/latest),\n[.deb package](https://github.com/authelia/authelia/releases/latest), as a container on [Docker] or [Kubernetes].\n\n\nDeployment can be orchestrated via the Helm [Chart](https://charts.authelia.com) (beta) leveraging ingress controllers\nand ingress configurations.\n\n<p align=\"center\">\n  <img src=\"https://www.authelia.com/images/logos/kubernetes.png\" height=\"100\"/>\n  <img src=\"https://www.authelia.com/images/logos/docker.logo.png\" width=\"100\">\n</p>\n\nHere is what Authelia's portal looks like:\n\n<p align=\"center\">\n    <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://www.authelia.com/images/dark.png\" width=\"400\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://www.authelia.com/images/light.png\" width=\"400\">\n    <img src=\"https://www.authelia.com/images/light.png\" width=\"400\">\n  </picture>\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://www.authelia.com/images/2fa-methods-dark.png\" width=\"400\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://www.authelia.com/images/2fa-methods-light.png\" width=\"400\">\n    <img src=\"https://www.authelia.com/images/2fa-methods-light.png\" width=\"400\">\n  </picture>\n</p>\n\n## Features summary\n\nThis is a list of the key features of Authelia:\n\n* [OpenID Connect 1.0 / OAuth 2.0](#openid-connect-10--oauth-20)\n* Several second factor methods:\n  * **[Security Keys](https://www.authelia.com/overview/authentication/security-key/)** that support\n    [FIDO2]&nbsp;[WebAuthn] with devices like a [YubiKey].\n  * **[Time-based One-Time password](https://www.authelia.com/overview/authentication/one-time-password/)**\n    with compatible authenticator applications.\n  * **[Mobile Push Notifications](https://www.authelia.com/overview/authentication/push-notification/)**\n    with [Duo](https://duo.com/).\n* Passwordless Authentication via WebAuthn (Passkeys)\n* Password reset with identity verification using email confirmation.\n* Access restriction after too many invalid authentication attempts.\n* Fine-grained access control using rules which match criteria like subdomain, user, user group membership, request uri,\n request method, and network.\n* Choice between one-factor and two-factor policies per-rule.\n* Support of basic authentication for endpoints protected by the one-factor policy.\n* Highly available using a remote database and Redis as a highly available KV store.\n* Compatible with [Traefik](https://doc.traefik.io/traefik) out of the box using the\n  [ForwardAuth](https://doc.traefik.io/traefik/middlewares/http/forwardauth/) middleware.\n* Curated configuration from [LinuxServer](https://www.linuxserver.io/) via their\n  [SWAG](https://docs.linuxserver.io/general/swag) container as well as a\n  [guide](https://blog.linuxserver.io/2020/08/26/setting-up-authelia/).\n* Compatible with [Caddy] using the [forward_auth](https://caddyserver.com/docs/caddyfile/directives/forward_auth)\n  directive.\n* Kubernetes Support:\n  * Compatible with several Kubernetes Ingress Controllers and Gateways:\n    * [ingress-nginx](https://www.authelia.com/integration/kubernetes/nginx-ingress/)\n    * [Traefik Kubernetes CRD](https://www.authelia.com/integration/kubernetes/traefik-ingress/#ingressroute)\n    * [Traefik Kubernetes Ingress](https://www.authelia.com/integration/kubernetes/traefik-ingress/#ingress)\n    * [Istio](https://www.authelia.com/integration/kubernetes/envoy/introduction/)\n    * [Envoy Gateway](https://www.authelia.com/integration/kubernetes/envoy/gateway/)\n  * Beta support for installing via Helm using our [Charts](https://charts.authelia.com).\n\nFor more details take a look at the [Overview](https://www.authelia.com/overview/prologue/introduction/).\n\nIf you want to know more about the roadmap, follow [Roadmap](https://www.authelia.com/roadmap).\n\n### OpenID Connect 1.0 / OAuth 2.0\n\nAuthelia is [OpenID Certifiedâ„¢] to the Basic OP / Implicit OP / Hybrid OP / Form Post OP / Config OP profiles of the\n[OpenID Connectâ„¢ protocol]. While this offering is still effectively\n[on the roadmap as a beta](https://www.authelia.com/roadmap/active/openid-connect/) it's very comprehensive and well\nimplemented already, also allowing us comprehensive certification. Read more about the\n[OpenID Certifiedâ„¢] status of Authelia in the\n[OpenID Connect 1.0 Integration Guide](https://www.authelia.com/integration/openid-connect/introduction/#openid-certified).\n\n<p align=\"center\">\n\t<a href=\"https://www.authelia.com/integration/openid-connect/introduction/#openid-certified\" target=\"_blank\">\n\t\t<picture>\n\t\t\t<img src=\"https://www.authelia.com/images/oid-certification.jpg\" width=\"400\" title=\"OpenID Certifiedâ„¢ by Authelia to the Basic OP / Implicit OP / Hybrid OP / Form Post OP / Config OP of the OpenID Connectâ„¢ protocol\">\n\t\t</picture>\n\t</a>\n</p>\n\n## Proxy support\n\nAuthelia works in combination with [nginx], [Traefik], [Caddy], [Skipper], [Envoy], or [HAProxy].\n\n<p align=\"center\">\n  <img src=\"https://www.authelia.com/images/logos/nginx.png\" height=\"50\"/>\n  <img src=\"https://www.authelia.com/images/logos/traefik.png\" height=\"50\"/>\n  <img src=\"https://www.authelia.com/images/logos/caddy.png\" height=\"50\"/>\n  <img src=\"https://www.authelia.com/images/logos/envoy.png\" height=\"50\"/>\n  <img src=\"https://www.authelia.com/images/logos/haproxy.png\" height=\"50\"/>\n</p>\n\n## Getting Started\n\nSee the [Get Started Guide](https://www.authelia.com/integration/prologue/get-started/) or one of the curated examples\nbelow.\n\n### docker compose\n\nThe `docker compose` bundles act as a starting point for anyone wanting to see Authelia in action. You will have to\ncustomize them to your needs as they come with self-signed certificates.\n\n#### [Local](https://www.authelia.com/integration/deployment/docker/#local)\nThe Local compose bundle is intended to test Authelia without worrying about configuration.\nIt's meant to be used for scenarios where the server is not be exposed to the internet.\nDomains will be defined in the local hosts file and self-signed certificates will be utilised.\n\n#### [Lite](https://www.authelia.com/integration/deployment/docker/#lite)\nThe Lite compose bundle is intended for scenarios where the server will be exposed to the internet, domains and DNS will\nneed to be setup accordingly and certificates will be generated through LetsEncrypt. The Lite element refers to minimal\nexternal dependencies; File based user storage, SQLite based configuration storage. In this configuration, the service\nwill not scale well.\n\n## Deployment\n\nNow that you have tested **Authelia** and you want to try it out in your own infrastructure,\nyou can learn how to deploy and use it with [Deployment](https://www.authelia.com/integration/deployment/introduction/).\nThis guide will show you how to deploy it on bare metal as well as on\n[Kubernetes](https://kubernetes.io/).\n\n## Security\n\nAuthelia takes security very seriously. If you discover a vulnerability in Authelia, please see our\n[Security Policy](https://github.com/authelia/authelia/security/policy).\n\nFor more information about [security](https://www.authelia.com/policies/security/) related matters, please read\n[the documentation](https://www.authelia.com/policies/security/).\n\n## Contact Options\n\nSeveral contact options exist for our community, the primary one being [Matrix](#matrix). These are in addition to\n[GitHub issues](https://github.com/authelia/authelia/issues) for creating a\n[new issue](https://github.com/authelia/authelia/issues/new/choose).\n\n### Matrix\n\nCommunity members are invited to join the [Matrix Space](https://matrix.to/#/#community:authelia.com) which includes\nboth the [Support Room](https://matrix.to/#/#support:authelia.com) and the\n[Contributing Room](https://matrix.to/#/#contributing:authelia.com).\n\n- The core team members are identified as administrators in the Space and individual Rooms.\n- All channels are linked to [Discord](#discord).\n\n### Discord\n\nCommunity members are invited to join the [Discord Server](https://discord.authelia.com).\n\n- The core team members are identified by the <span style=\"color:#BA55D3;\">**CORE TEAM**</span> role in Discord.\n- The [#support] and [#contributing] channels are linked to [Matrix](#matrix).\n\n### Email\n\nYou can contact the core team by email via [team@authelia.com](mailto:team@authelia.com). Please note the\n[security@authelia.com](mailto:security@authelia.com) is also available but is strictly reserved for [security] related\nmatters.\n\n## Breaking changes\n\nSince Authelia is still under active development, it is subject to breaking changes. It's recommended to pin a version\ntag instead of using the `latest` tag and reading the [release notes](https://github.com/authelia/authelia/releases)\nbefore upgrading. This is where you will find information about breaking changes and what you should do to overcome\nsaid changes.\n\n## Why Open Source?\n\nYou might wonder why Authelia is open source while it adds a great deal of security and user experience to your\ninfrastructure at zero cost. It is open source because we firmly believe that security should be available for all to\nbenefit in the face of the battlefield which is the Internet, with near zero effort.\n\nAdditionally, keeping the code open source is a way to leave it auditable by anyone who is willing to contribute. This\nway, you can be confident that the product remains secure and does not act maliciously.\n\nIt's important to keep in mind Authelia is not directly exposed on the\nInternet (your reverse proxies are) however, it's still the control plane for your internal security so take care of it!\n\n## Contribute\n\nIf you want to contribute to Authelia, please read our [contribution guidelines](CONTRIBUTING.md).\n\nAuthelia exists thanks to all the people who contribute so don't be shy, come chat with us on either [Matrix](#matrix)\nor [Discord](#discord) and start contributing too.\n\nThanks goes to these wonderful people ([emoji key](https://allcontributors.org/docs/en/emoji-key)):\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/clems4ever\"><img src=\"https://avatars.githubusercontent.com/u/3193257?v=4?s=100\" width=\"100px;\" alt=\"ClÃ©ment Michaud\"/><br /><sub><b>ClÃ©ment Michaud</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=clems4ever\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/authelia/authelia/commits?author=clems4ever\" title=\"Documentation\">ğŸ“–</a> <a href=\"#ideas-clems4ever\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"#maintenance-clems4ever\" title=\"Maintenance\">ğŸš§</a> <a href=\"#question-clems4ever\" title=\"Answering Questions\">ğŸ’¬</a> <a href=\"https://github.com/authelia/authelia/pulls?q=is%3Apr+reviewed-by%3Aclems4ever\" title=\"Reviewed Pull Requests\">ğŸ‘€</a> <a href=\"https://github.com/authelia/authelia/commits?author=clems4ever\" title=\"Tests\">âš ï¸</a> <a href=\"#mentoring-clems4ever\" title=\"Mentoring\">ğŸ§‘â€ğŸ«</a> <a href=\"#infra-clems4ever\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">ğŸš‡</a> <a href=\"#design-clems4ever\" title=\"Design\">ğŸ¨</a> <a href=\"#userTesting-clems4ever\" title=\"User Testing\">ğŸ““</a> <a href=\"#tool-clems4ever\" title=\"Tools\">ğŸ”§</a> <a href=\"#research-clems4ever\" title=\"Research\">ğŸ”¬</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nightah\"><img src=\"https://avatars.githubusercontent.com/u/3339418?v=4?s=100\" width=\"100px;\" alt=\"Amir Zarrinkafsh\"/><br /><sub><b>Amir Zarrinkafsh</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=nightah\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/authelia/authelia/commits?author=nightah\" title=\"Documentation\">ğŸ“–</a> <a href=\"#ideas-nightah\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"#maintenance-nightah\" title=\"Maintenance\">ğŸš§</a> <a href=\"#question-nightah\" title=\"Answering Questions\">ğŸ’¬</a> <a href=\"https://github.com/authelia/authelia/pulls?q=is%3Apr+reviewed-by%3Anightah\" title=\"Reviewed Pull Requests\">ğŸ‘€</a> <a href=\"https://github.com/authelia/authelia/commits?author=nightah\" title=\"Tests\">âš ï¸</a> <a href=\"#mentoring-nightah\" title=\"Mentoring\">ğŸ§‘â€ğŸ«</a> <a href=\"#infra-nightah\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">ğŸš‡</a> <a href=\"#design-nightah\" title=\"Design\">ğŸ¨</a> <a href=\"#userTesting-nightah\" title=\"User Testing\">ğŸ““</a> <a href=\"#tool-nightah\" title=\"Tools\">ğŸ”§</a> <a href=\"#research-nightah\" title=\"Research\">ğŸ”¬</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/james-d-elliott\"><img src=\"https://avatars.githubusercontent.com/u/3903683?v=4?s=100\" width=\"100px;\" alt=\"James Elliott\"/><br /><sub><b>James Elliott</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=james-d-elliott\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/authelia/authelia/commits?author=james-d-elliott\" title=\"Documentation\">ğŸ“–</a> <a href=\"#ideas-james-d-elliott\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"#maintenance-james-d-elliott\" title=\"Maintenance\">ğŸš§</a> <a href=\"#question-james-d-elliott\" title=\"Answering Questions\">ğŸ’¬</a> <a href=\"https://github.com/authelia/authelia/pulls?q=is%3Apr+reviewed-by%3Ajames-d-elliott\" title=\"Reviewed Pull Requests\">ğŸ‘€</a> <a href=\"https://github.com/authelia/authelia/commits?author=james-d-elliott\" title=\"Tests\">âš ï¸</a> <a href=\"#mentoring-james-d-elliott\" title=\"Mentoring\">ğŸ§‘â€ğŸ«</a> <a href=\"#infra-james-d-elliott\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">ğŸš‡</a> <a href=\"#design-james-d-elliott\" title=\"Design\">ğŸ¨</a> <a href=\"#userTesting-james-d-elliott\" title=\"User Testing\">ğŸ““</a> <a href=\"#tool-james-d-elliott\" title=\"Tools\">ğŸ”§</a> <a href=\"#research-james-d-elliott\" title=\"Research\">ğŸ”¬</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/n4kre\"><img src=\"https://avatars.githubusercontent.com/u/14371127?v=4?s=100\" width=\"100px;\" alt=\"Antoine Favre\"/><br /><sub><b>Antoine Favre</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/issues?q=author%3An4kre\" title=\"Bug reports\">ğŸ›</a> <a href=\"#ideas-n4kre\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/BankaiNoJutsu\"><img src=\"https://avatars.githubusercontent.com/u/2241519?v=4?s=100\" width=\"100px;\" alt=\"BankaiNoJutsu\"/><br /><sub><b>BankaiNoJutsu</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=BankaiNoJutsu\" title=\"Code\">ğŸ’»</a> <a href=\"#design-BankaiNoJutsu\" title=\"Design\">ğŸ¨</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/p-rintz\"><img src=\"https://avatars.githubusercontent.com/u/13933258?v=4?s=100\" width=\"100px;\" alt=\"Philipp Rintz\"/><br /><sub><b>Philipp Rintz</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=p-rintz\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://callanbryant.co.uk/\"><img src=\"https://avatars.githubusercontent.com/u/208440?v=4?s=100\" width=\"100px;\" alt=\"Callan Bryant\"/><br /><sub><b>Callan Bryant</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=naggie\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/authelia/authelia/commits?author=naggie\" title=\"Documentation\">ğŸ“–</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ViViDboarder\"><img src=\"https://avatars.githubusercontent.com/u/137025?v=4?s=100\" width=\"100px;\" alt=\"Ian\"/><br /><sub><b>Ian</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=ViViDboarder\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/FrozenDragoon\"><img src=\"https://avatars.githubusercontent.com/u/5301673?v=4?s=100\" width=\"100px;\" alt=\"FrozenDragoon\"/><br /><sub><b>FrozenDragoon</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=FrozenDragoon\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/vdot0x23\"><img src=\"https://avatars.githubusercontent.com/u/40716069?v=4?s=100\" width=\"100px;\" alt=\"vdot0x23\"/><br /><sub><b>vdot0x23</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=vdot0x23\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/alexw1982\"><img src=\"https://avatars.githubusercontent.com/u/11628284?v=4?s=100\" width=\"100px;\" alt=\"alexw1982\"/><br /><sub><b>alexw1982</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=alexw1982\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Sohalt\"><img src=\"https://avatars.githubusercontent.com/u/2157287?v=4?s=100\" width=\"100px;\" alt=\"Sohalt\"/><br /><sub><b>Sohalt</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=Sohalt\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/authelia/authelia/commits?author=Sohalt\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Tedyst\"><img src=\"https://avatars.githubusercontent.com/u/13637623?v=4?s=100\" width=\"100px;\" alt=\"Stoica Tedy\"/><br /><sub><b>Stoica Tedy</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=Tedyst\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Chemsmith\"><img src=\"https://avatars.githubusercontent.com/u/9061024?v=4?s=100\" width=\"100px;\" alt=\"Dylan Smith\"/><br /><sub><b>Dylan Smith</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=Chemsmith\" title=\"Code\">ğŸ’»</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/LukasK13\"><img src=\"https://avatars.githubusercontent.com/u/24586740?v=4?s=100\" width=\"100px;\" alt=\"Lukas Klass\"/><br /><sub><b>Lukas Klass</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=LukasK13\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://staiger.it/\"><img src=\"https://avatars.githubusercontent.com/u/9325003?v=4?s=100\" width=\"100px;\" alt=\"Philipp Staiger\"/><br /><sub><b>Philipp Staiger</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=lippl\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/authelia/authelia/commits?author=lippl\" title=\"Documentation\">ğŸ“–</a> <a href=\"https://github.com/authelia/authelia/commits?author=lippl\" title=\"Tests\">âš ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://yaleman.org/\"><img src=\"https://avatars.githubusercontent.com/u/168188?v=4?s=100\" width=\"100px;\" alt=\"James Hodgkinson\"/><br /><sub><b>James Hodgkinson</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=yaleman\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://chris.smith.xyz/\"><img src=\"https://avatars.githubusercontent.com/u/1979423?v=4?s=100\" width=\"100px;\" alt=\"Chris Smith\"/><br /><sub><b>Chris Smith</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=chris13524\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mqmq0\"><img src=\"https://avatars.githubusercontent.com/u/13240971?v=4?s=100\" width=\"100px;\" alt=\"MihÃ¡ly\"/><br /><sub><b>MihÃ¡ly</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=mqmq0\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://iret.xyz/\"><img src=\"https://avatars.githubusercontent.com/u/6560655?v=4?s=100\" width=\"100px;\" alt=\"Silver Bullet\"/><br /><sub><b>Silver Bullet</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=SilverBut\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/skenmy\"><img src=\"https://avatars.githubusercontent.com/u/1454505?v=4?s=100\" width=\"100px;\" alt=\"Paul Williams\"/><br /><sub><b>Paul Williams</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=skenmy\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/authelia/authelia/commits?author=skenmy\" title=\"Tests\">âš ï¸</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ntimo\"><img src=\"https://avatars.githubusercontent.com/u/6145026?v=4?s=100\" width=\"100px;\" alt=\"Timo\"/><br /><sub><b>Timo</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=ntimo\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/andrewkliskey\"><img src=\"https://avatars.githubusercontent.com/u/44645768?v=4?s=100\" width=\"100px;\" alt=\"Andrew Kliskey\"/><br /><sub><b>Andrew Kliskey</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=andrewkliskey\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://kristofmattei.be/\"><img src=\"https://avatars.githubusercontent.com/u/864376?v=4?s=100\" width=\"100px;\" alt=\"Kristof Mattei\"/><br /><sub><b>Kristof Mattei</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=Kristof-Mattei\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.zmiguel.me/\"><img src=\"https://avatars.githubusercontent.com/u/4400540?v=4?s=100\" width=\"100px;\" alt=\"ZMiguel Valdiviesso\"/><br /><sub><b>ZMiguel Valdiviesso</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=zmiguel\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/akusei\"><img src=\"https://avatars.githubusercontent.com/u/12972900?v=4?s=100\" width=\"100px;\" alt=\"akusei\"/><br /><sub><b>akusei</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=akusei\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/authelia/authelia/commits?author=akusei\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Peaches491\"><img src=\"https://avatars.githubusercontent.com/u/494334?v=4?s=100\" width=\"100px;\" alt=\"Daniel Miller\"/><br /><sub><b>Daniel Miller</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=Peaches491\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dustins\"><img src=\"https://avatars.githubusercontent.com/u/14645?v=4?s=100\" width=\"100px;\" alt=\"Dustin Sweigart\"/><br /><sub><b>Dustin Sweigart</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=dustins\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/authelia/authelia/commits?author=dustins\" title=\"Documentation\">ğŸ“–</a> <a href=\"https://github.com/authelia/authelia/commits?author=dustins\" title=\"Tests\">âš ï¸</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rogue780\"><img src=\"https://avatars.githubusercontent.com/u/247716?v=4?s=100\" width=\"100px;\" alt=\"Shawn Haggard\"/><br /><sub><b>Shawn Haggard</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=rogue780\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/authelia/authelia/commits?author=rogue780\" title=\"Tests\">âš ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kevynb\"><img src=\"https://avatars.githubusercontent.com/u/4941215?v=4?s=100\" width=\"100px;\" alt=\"Kevyn Bruyere\"/><br /><sub><b>Kevyn Bruyere</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=kevynb\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ducksecops\"><img src=\"https://avatars.githubusercontent.com/u/25612094?v=4?s=100\" width=\"100px;\" alt=\"Daniel Sutton\"/><br /><sub><b>Daniel Sutton</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=ducksecops\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.xenuser.org/\"><img src=\"https://avatars.githubusercontent.com/u/2216868?v=4?s=100\" width=\"100px;\" alt=\"Valentin HÃ¶bel\"/><br /><sub><b>Valentin HÃ¶bel</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=xenuser\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/thehedgefrog\"><img src=\"https://avatars.githubusercontent.com/u/38590447?v=4?s=100\" width=\"100px;\" alt=\"thehedgefrog\"/><br /><sub><b>thehedgefrog</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=thehedgefrog\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ViRb3\"><img src=\"https://avatars.githubusercontent.com/u/2650170?v=4?s=100\" width=\"100px;\" alt=\"Victor\"/><br /><sub><b>Victor</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=ViRb3\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/whiskerch\"><img src=\"https://avatars.githubusercontent.com/u/35109315?v=4?s=100\" width=\"100px;\" alt=\"Chris Whisker\"/><br /><sub><b>Chris Whisker</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=whiskerch\" title=\"Documentation\">ğŸ“–</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nasatome\"><img src=\"https://avatars.githubusercontent.com/u/18271791?v=4?s=100\" width=\"100px;\" alt=\"nasatome\"/><br /><sub><b>nasatome</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=nasatome\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/bbros-dev\"><img src=\"https://avatars.githubusercontent.com/u/60454087?v=4?s=100\" width=\"100px;\" alt=\"Begley Brothers (Development)\"/><br /><sub><b>Begley Brothers (Development)</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=bbros-dev\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://mikekusold.com/\"><img src=\"https://avatars.githubusercontent.com/u/509966?v=4?s=100\" width=\"100px;\" alt=\"Mike Kusold\"/><br /><sub><b>Mike Kusold</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=kusold\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://dzervas.gr/\"><img src=\"https://avatars.githubusercontent.com/u/1029195?v=4?s=100\" width=\"100px;\" alt=\"Dimitris Zervas\"/><br /><sub><b>Dimitris Zervas</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=dzervas\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://paypal.me/DHoung\"><img src=\"https://avatars.githubusercontent.com/u/52870424?v=4?s=100\" width=\"100px;\" alt=\"TheCatLady\"/><br /><sub><b>TheCatLady</b></sub></a><br /><a href=\"#ideas-TheCatLady\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://lauri.vosandi.com/\"><img src=\"https://avatars.githubusercontent.com/u/194685?v=4?s=100\" width=\"100px;\" alt=\"Lauri VÃµsandi\"/><br /><sub><b>Lauri VÃµsandi</b></sub></a><br /><a href=\"#ideas-laurivosandi\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/knnnrd\"><img src=\"https://avatars.githubusercontent.com/u/5852381?v=4?s=100\" width=\"100px;\" alt=\"Kennard Vermeiren\"/><br /><sub><b>Kennard Vermeiren</b></sub></a><br /><a href=\"#ideas-knnnrd\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ThinkChaos\"><img src=\"https://avatars.githubusercontent.com/u/4761135?v=4?s=100\" width=\"100px;\" alt=\"ThinkChaos\"/><br /><sub><b>ThinkChaos</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=ThinkChaos\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/authelia/authelia/commits?author=ThinkChaos\" title=\"Documentation\">ğŸ“–</a> <a href=\"https://github.com/authelia/authelia/commits?author=ThinkChaos\" title=\"Tests\">âš ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/except\"><img src=\"https://avatars.githubusercontent.com/u/26675576?v=4?s=100\" width=\"100px;\" alt=\"Hasan\"/><br /><sub><b>Hasan</b></sub></a><br /><a href=\"#security-except\" title=\"Security\">ğŸ›¡ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://blog.dchidell.com\"><img src=\"https://avatars.githubusercontent.com/u/26146619?v=4?s=100\" width=\"100px;\" alt=\"David Chidell\"/><br /><sub><b>David Chidell</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=dchidell\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mardom1\"><img src=\"https://avatars.githubusercontent.com/u/32371724?v=4?s=100\" width=\"100px;\" alt=\"Marcel Marquardt\"/><br /><sub><b>Marcel Marquardt</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/issues?q=author%3Amardom1\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://cdine.org\"><img src=\"https://avatars.githubusercontent.com/u/127512?v=4?s=100\" width=\"100px;\" alt=\"Ian Gallagher\"/><br /><sub><b>Ian Gallagher</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=craSH\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://wuhanstudio.cc\"><img src=\"https://avatars.githubusercontent.com/u/15157070?v=4?s=100\" width=\"100px;\" alt=\"Wu Han\"/><br /><sub><b>Wu Han</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=wuhanstudio\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lavih\"><img src=\"https://avatars.githubusercontent.com/u/47455309?v=4?s=100\" width=\"100px;\" alt=\"lavih\"/><br /><sub><b>lavih</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=lavih\" title=\"Documentation\">ğŸ“–</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://jonbayl\"><img src=\"https://avatars.githubusercontent.com/u/30201351?v=4?s=100\" width=\"100px;\" alt=\"Jon B. \"/><br /><sub><b>Jon B. </b></sub></a><br /><a href=\"#security-jonbayl\" title=\"Security\">ğŸ›¡ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/AlexGustafsson\"><img src=\"https://avatars.githubusercontent.com/u/14974112?v=4?s=100\" width=\"100px;\" alt=\"Alex Gustafsson\"/><br /><sub><b>Alex Gustafsson</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=AlexGustafsson\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/authelia/authelia/commits?author=AlexGustafsson\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.aarsen.me/\"><img src=\"https://avatars.githubusercontent.com/u/7805050?v=4?s=100\" width=\"100px;\" alt=\"ArsenoviÄ‡ Arsen\"/><br /><sub><b>ArsenoviÄ‡ Arsen</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=ArsenArsen\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/authelia/authelia/commits?author=ArsenArsen\" title=\"Tests\">âš ï¸</a> <a href=\"#security-ArsenArsen\" title=\"Security\">ğŸ›¡ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dakriy\"><img src=\"https://avatars.githubusercontent.com/u/13756065?v=4?s=100\" width=\"100px;\" alt=\"dakriy\"/><br /><sub><b>dakriy</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=dakriy\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/davama\"><img src=\"https://avatars.githubusercontent.com/u/5359152?v=4?s=100\" width=\"100px;\" alt=\"Dave\"/><br /><sub><b>Dave</b></sub></a><br /><a href=\"#userTesting-davama\" title=\"User Testing\">ğŸ““</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nreymundo\"><img src=\"https://avatars.githubusercontent.com/u/5833447?v=4?s=100\" width=\"100px;\" alt=\"Nicolas Reymundo\"/><br /><sub><b>Nicolas Reymundo</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=nreymundo\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/polandy\"><img src=\"https://avatars.githubusercontent.com/u/3670670?v=4?s=100\" width=\"100px;\" alt=\"polandy\"/><br /><sub><b>polandy</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=polandy\" title=\"Documentation\">ğŸ“–</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/you1996\"><img src=\"https://avatars.githubusercontent.com/u/45292366?v=4?s=100\" width=\"100px;\" alt=\"yossbg\"/><br /><sub><b>yossbg</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=you1996\" title=\"Code\">ğŸ’»</a> <a href=\"#design-you1996\" title=\"Design\">ğŸ¨</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mpdcampbell\"><img src=\"https://avatars.githubusercontent.com/u/47434940?v=4?s=100\" width=\"100px;\" alt=\"Michael Campbell\"/><br /><sub><b>Michael Campbell</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=mpdcampbell\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://sievenpiper.co\"><img src=\"https://avatars.githubusercontent.com/u/1131882?v=4?s=100\" width=\"100px;\" alt=\"Justin Sievenpiper\"/><br /><sub><b>Justin Sievenpiper</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=jsievenpiper\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kaysond\"><img src=\"https://avatars.githubusercontent.com/u/1147328?v=4?s=100\" width=\"100px;\" alt=\"Aram Akhavan\"/><br /><sub><b>Aram Akhavan</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=kaysond\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://skhuf.net\"><img src=\"https://avatars.githubusercontent.com/u/286341?v=4?s=100\" width=\"100px;\" alt=\"Shadow\"/><br /><sub><b>Shadow</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=shadow7412\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tarioch\"><img src=\"https://avatars.githubusercontent.com/u/2998148?v=4?s=100\" width=\"100px;\" alt=\"Patrick Ruckstuhl\"/><br /><sub><b>Patrick Ruckstuhl</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=tarioch\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/FineWolf\"><img src=\"https://avatars.githubusercontent.com/u/203591?v=4?s=100\" width=\"100px;\" alt=\"Andrew Moore\"/><br /><sub><b>Andrew Moore</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=FineWolf\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/authelia/authelia/commits?author=FineWolf\" title=\"Documentation\">ğŸ“–</a> <a href=\"https://github.com/authelia/authelia/commits?author=FineWolf\" title=\"Tests\">âš ï¸</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.dennisgaida.de\"><img src=\"https://avatars.githubusercontent.com/u/2392217?v=4?s=100\" width=\"100px;\" alt=\"Dennis Gaida\"/><br /><sub><b>Dennis Gaida</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=DennisGaida\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Alestrix\"><img src=\"https://avatars.githubusercontent.com/u/7452860?v=4?s=100\" width=\"100px;\" alt=\"Alestrix\"/><br /><sub><b>Alestrix</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=Alestrix\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/bgh-github\"><img src=\"https://avatars.githubusercontent.com/u/99472455?v=4?s=100\" width=\"100px;\" alt=\"bgh-github\"/><br /><sub><b>bgh-github</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=bgh-github\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mind-ar\"><img src=\"https://avatars.githubusercontent.com/u/10672208?v=4?s=100\" width=\"100px;\" alt=\"Manuel NuÃ±ez\"/><br /><sub><b>Manuel NuÃ±ez</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=mind-ar\" title=\"Code\">ğŸ’»</a> <a href=\"#translation-mind-ar\" title=\"Translation\">ğŸŒ</a> <a href=\"https://github.com/authelia/authelia/commits?author=mind-ar\" title=\"Documentation\">ğŸ“–</a> <a href=\"https://github.com/authelia/authelia/issues?q=author%3Amind-ar\" title=\"Bug reports\">ğŸ›</a> <a href=\"#design-mind-ar\" title=\"Design\">ğŸ¨</a> <a href=\"https://github.com/authelia/authelia/commits?author=mind-ar\" title=\"Tests\">âš ï¸</a> <a href=\"https://github.com/authelia/authelia/pulls?q=is%3Apr+reviewed-by%3Amind-ar\" title=\"Reviewed Pull Requests\">ğŸ‘€</a> <a href=\"#research-mind-ar\" title=\"Research\">ğŸ”¬</a> <a href=\"#ideas-mind-ar\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/protvis74\"><img src=\"https://avatars.githubusercontent.com/u/50554836?v=4?s=100\" width=\"100px;\" alt=\"protvis74\"/><br /><sub><b>protvis74</b></sub></a><br /><a href=\"#translation-protvis74\" title=\"Translation\">ğŸŒ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://itjamie.com\"><img src=\"https://avatars.githubusercontent.com/u/1613241?v=4?s=100\" width=\"100px;\" alt=\"Jamie (Bear) Murphy \"/><br /><sub><b>Jamie (Bear) Murphy </b></sub></a><br /><a href=\"https://github.com/authelia/authelia/pulls?q=is%3Apr+reviewed-by%3AITJamie\" title=\"Reviewed Pull Requests\">ğŸ‘€</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Beanow\"><img src=\"https://avatars.githubusercontent.com/u/497556?v=4?s=100\" width=\"100px;\" alt=\"Robin van Boven\"/><br /><sub><b>Robin van Boven</b></sub></a><br /><a href=\"#security-Beanow\" title=\"Security\">ğŸ›¡ï¸</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.cybertrol.com\"><img src=\"https://avatars.githubusercontent.com/u/1178293?v=4?s=100\" width=\"100px;\" alt=\"alphabet5\"/><br /><sub><b>alphabet5</b></sub></a><br /><a href=\"#ideas-alphabet5\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rjmidau\"><img src=\"https://avatars.githubusercontent.com/u/8134995?v=4?s=100\" width=\"100px;\" alt=\"Robert Meredith\"/><br /><sub><b>Robert Meredith</b></sub></a><br /><a href=\"#ideas-rjmidau\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/adriang-90\"><img src=\"https://avatars.githubusercontent.com/u/60886162?v=4?s=100\" width=\"100px;\" alt=\"Adrian GÄ…sior\"/><br /><sub><b>Adrian GÄ…sior</b></sub></a><br /><a href=\"#security-adriang-90\" title=\"Security\">ğŸ›¡ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://jamesw.link/me\"><img src=\"https://avatars.githubusercontent.com/u/8067792?v=4?s=100\" width=\"100px;\" alt=\"James White\"/><br /><sub><b>James White</b></sub></a><br /><a href=\"#question-jamesmacwhite\" title=\"Answering Questions\">ğŸ’¬</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.zxlim.xyz\"><img src=\"https://avatars.githubusercontent.com/u/19372079?v=4?s=100\" width=\"100px;\" alt=\"Zhao Xiang Lim\"/><br /><sub><b>Zhao Xiang Lim</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=zxlim\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Auzborn123\"><img src=\"https://avatars.githubusercontent.com/u/42992103?v=4?s=100\" width=\"100px;\" alt=\"Auzborn123\"/><br /><sub><b>Auzborn123</b></sub></a><br /><a href=\"#translation-Auzborn123\" title=\"Translation\">ğŸŒ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/SvanGlan\"><img src=\"https://avatars.githubusercontent.com/u/106152205?v=4?s=100\" width=\"100px;\" alt=\"SvanGlan\"/><br /><sub><b>SvanGlan</b></sub></a><br /><a href=\"#translation-SvanGlan\" title=\"Translation\">ğŸŒ</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/HannesJo0139\"><img src=\"https://avatars.githubusercontent.com/u/42114183?v=4?s=100\" width=\"100px;\" alt=\"HannesJo0139\"/><br /><sub><b>HannesJo0139</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=HannesJo0139\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/andreas-berg\"><img src=\"https://avatars.githubusercontent.com/u/39428693?v=4?s=100\" width=\"100px;\" alt=\"andreas-berg\"/><br /><sub><b>andreas-berg</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/issues?q=author%3Aandreas-berg\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://radenac.me\"><img src=\"https://avatars.githubusercontent.com/u/47008408?v=4?s=100\" width=\"100px;\" alt=\"ClÃ©ment Radenac\"/><br /><sub><b>ClÃ©ment Radenac</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=clem3109\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/boomam\"><img src=\"https://avatars.githubusercontent.com/u/37086258?v=4?s=100\" width=\"100px;\" alt=\"boomam\"/><br /><sub><b>boomam</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=boomam\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Northguy\"><img src=\"https://avatars.githubusercontent.com/u/1189058?v=4?s=100\" width=\"100px;\" alt=\"Northguy\"/><br /><sub><b>Northguy</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=Northguy\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/polarathene\"><img src=\"https://avatars.githubusercontent.com/u/5098581?v=4?s=100\" width=\"100px;\" alt=\"Brennan Kinney\"/><br /><sub><b>Brennan Kinney</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=polarathene\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/LongerHV\"><img src=\"https://avatars.githubusercontent.com/u/46924944?v=4?s=100\" width=\"100px;\" alt=\"MichaÅ‚ Mieszczak\"/><br /><sub><b>MichaÅ‚ Mieszczak</b></sub></a><br /><a href=\"#ideas-LongerHV\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"https://github.com/authelia/authelia/commits?author=LongerHV\" title=\"Code\">ğŸ’»</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/paul-ohl\"><img src=\"https://avatars.githubusercontent.com/u/37795294?v=4?s=100\" width=\"100px;\" alt=\"Paul Ohl\"/><br /><sub><b>Paul Ohl</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=paul-ohl\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/smkent\"><img src=\"https://avatars.githubusercontent.com/u/2831985?v=4?s=100\" width=\"100px;\" alt=\"Stephen Kent\"/><br /><sub><b>Stephen Kent</b></sub></a><br /><a href=\"#ideas-smkent\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"https://github.com/authelia/authelia/commits?author=smkent\" title=\"Code\">ğŸ’»</a> <a href=\"#design-smkent\" title=\"Design\">ğŸ¨</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Ohelig\"><img src=\"https://avatars.githubusercontent.com/u/5841980?v=4?s=100\" width=\"100px;\" alt=\"Ohelig\"/><br /><sub><b>Ohelig</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=Ohelig\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/chillinPanda\"><img src=\"https://avatars.githubusercontent.com/u/250694?v=4?s=100\" width=\"100px;\" alt=\"Dinh Bao Dang\"/><br /><sub><b>Dinh Bao Dang</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=chillinPanda\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/levkoburburas\"><img src=\"https://avatars.githubusercontent.com/u/62853952?v=4?s=100\" width=\"100px;\" alt=\"levkoburburas\"/><br /><sub><b>levkoburburas</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=levkoburburas\" title=\"Code\">ğŸ’»</a> <a href=\"#ideas-levkoburburas\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"https://github.com/authelia/authelia/issues?q=author%3Alevkoburburas\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tiuub\"><img src=\"https://avatars.githubusercontent.com/u/46517077?v=4?s=100\" width=\"100px;\" alt=\"tiuub\"/><br /><sub><b>tiuub</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=tiuub\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://joshgordon.net\"><img src=\"https://avatars.githubusercontent.com/u/2125341?v=4?s=100\" width=\"100px;\" alt=\"Josh Gordon\"/><br /><sub><b>Josh Gordon</b></sub></a><br /><a href=\"#ideas-joshgordon\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"#security-joshgordon\" title=\"Security\">ğŸ›¡ï¸</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/silasfrancisco\"><img src=\"https://avatars.githubusercontent.com/u/84447762?v=4?s=100\" width=\"100px;\" alt=\"silasfrancisco\"/><br /><sub><b>silasfrancisco</b></sub></a><br /><a href=\"#security-silasfrancisco\" title=\"Security\">ğŸ›¡ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/n4m3l3ss-b0t\"><img src=\"https://avatars.githubusercontent.com/u/1162710?v=4?s=100\" width=\"100px;\" alt=\"Ricardo Pesqueira\"/><br /><sub><b>Ricardo Pesqueira</b></sub></a><br /><a href=\"#security-n4m3l3ss-b0t\" title=\"Security\">ğŸ›¡ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/HaroldVB\"><img src=\"https://avatars.githubusercontent.com/u/73724671?v=4?s=100\" width=\"100px;\" alt=\"Harold\"/><br /><sub><b>Harold</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=HaroldVB\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Crowley723\"><img src=\"https://avatars.githubusercontent.com/u/26265198?v=4?s=100\" width=\"100px;\" alt=\"Brynn Crowley\"/><br /><sub><b>Brynn Crowley</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=Crowley723\" title=\"Documentation\">ğŸ“–</a> <a href=\"#design-Crowley723\" title=\"Design\">ğŸ¨</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://budimanjojo.com\"><img src=\"https://avatars.githubusercontent.com/u/13085918?v=4?s=100\" width=\"100px;\" alt=\"Budiman Jojo\"/><br /><sub><b>Budiman Jojo</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=budimanjojo\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/hendrik1120\"><img src=\"https://avatars.githubusercontent.com/u/89412959?v=4?s=100\" width=\"100px;\" alt=\"Hendrik Sievers\"/><br /><sub><b>Hendrik Sievers</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=hendrik1120\" title=\"Documentation\">ğŸ“–</a> <a href=\"#design-hendrik1120\" title=\"Design\">ğŸ¨</a> <a href=\"#ideas-hendrik1120\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/m-georgi\"><img src=\"https://avatars.githubusercontent.com/u/20987691?v=4?s=100\" width=\"100px;\" alt=\"Marcus Georgi\"/><br /><sub><b>Marcus Georgi</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=m-georgi\" title=\"Documentation\">ğŸ“–</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/samos667\"><img src=\"https://avatars.githubusercontent.com/u/50653464?v=4?s=100\" width=\"100px;\" alt=\"samos667\"/><br /><sub><b>samos667</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=samos667\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/0xSysR3ll\"><img src=\"https://avatars.githubusercontent.com/u/31414959?v=4?s=100\" width=\"100px;\" alt=\"0xsysr3ll\"/><br /><sub><b>0xsysr3ll</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=0xSysR3ll\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/cromelex\"><img src=\"https://avatars.githubusercontent.com/u/96779452?v=4?s=100\" width=\"100px;\" alt=\"Dan\"/><br /><sub><b>Dan</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=cromelex\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://shaamallow.com\"><img src=\"https://avatars.githubusercontent.com/u/39766320?v=4?s=100\" width=\"100px;\" alt=\"Eyal Benaroche\"/><br /><sub><b>Eyal Benaroche</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=Shaamallow\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/wangweixuan\"><img src=\"https://avatars.githubusercontent.com/u/24620923?v=4?s=100\" width=\"100px;\" alt=\"Wang Weixuan\"/><br /><sub><b>Wang Weixuan</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/issues?q=author%3Awangweixuan\" title=\"Bug reports\">ğŸ›</a> <a href=\"https://github.com/authelia/authelia/commits?author=wangweixuan\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/authelia/authelia/commits?author=wangweixuan\" title=\"Tests\">âš ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://t.me/daniw1337\"><img src=\"https://avatars.githubusercontent.com/u/21097466?v=4?s=100\" width=\"100px;\" alt=\"Dani\"/><br /><sub><b>Dani</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=DaniW42\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://lhns.de\"><img src=\"https://avatars.githubusercontent.com/u/1524059?v=4?s=100\" width=\"100px;\" alt=\"Pierre Kisters\"/><br /><sub><b>Pierre Kisters</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=lhns\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/authelia/authelia/issues?q=author%3Alhns\" title=\"Bug reports\">ğŸ›</a> <a href=\"https://github.com/authelia/authelia/commits?author=lhns\" title=\"Tests\">âš ï¸</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://auston.dev\"><img src=\"https://avatars.githubusercontent.com/u/5049050?v=4?s=100\" width=\"100px;\" alt=\"Auston Pramodh Barboza\"/><br /><sub><b>Auston Pramodh Barboza</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=austonpramodh\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ThomasSteinbach\"><img src=\"https://avatars.githubusercontent.com/u/1683246?v=4?s=100\" width=\"100px;\" alt=\"Thomas Steinbach\"/><br /><sub><b>Thomas Steinbach</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=ThomasSteinbach\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Steve-Brule\"><img src=\"https://avatars.githubusercontent.com/u/83868338?v=4?s=100\" width=\"100px;\" alt=\"Steve-Brule\"/><br /><sub><b>Steve-Brule</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/commits?author=Steve-Brule\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/peter-\"><img src=\"https://avatars.githubusercontent.com/u/4047365?v=4?s=100\" width=\"100px;\" alt=\"peter\"/><br /><sub><b>peter</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/issues?q=author%3Apeter-\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://ocnr.org\"><img src=\"https://avatars.githubusercontent.com/u/1495157?v=4?s=100\" width=\"100px;\" alt=\"Nick O'Connor\"/><br /><sub><b>Nick O'Connor</b></sub></a><br /><a href=\"https://github.com/authelia/authelia/issues?q=author%3Anick-oconnor\" title=\"Bug reports\">ğŸ›</a> <a href=\"#userTesting-nick-oconnor\" title=\"User Testing\">ğŸ““</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pedorich-n\"><img src=\"https://avatars.githubusercontent.com/u/15573098?v=4?s=100\" width=\"100px;\" alt=\"Nikita Pedorich\"/><br /><sub><b>Nikita Pedorich</b></sub></a><br /><a href=\"#userTesting-pedorich-n\" title=\"User Testing\">ğŸ““</a></td>\n    </tr>\n  </tbody>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n\nThis project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification.\nContributions of any kind welcome!\n\n### Sponsors\n\n***Help Wanted:*** We are actively looking for sponsorship to obtain either a code security audit, penetration testing,\nor other audits related to improving the security of Authelia.\n\nAny company can become a sponsor by donating or providing any benefit to the project or the team helping improve\nAuthelia.\n\n#### Balto\n\nThank you to [<img src=\"https://www.authelia.com/svgs/logos/balto.svg\" alt=\"Balto\" width=\"32\"> Balto](https://www.getbalto.com/)\nfor hosting our apt repository.\n\n#### JetBrains\n\nThank you to [<img src=\"https://www.authelia.com/svgs/logos/jetbrains.svg\" alt=\"JetBrains\" width=\"32\"> JetBrains](https://www.jetbrains.com/?from=Authelia)\nfor providing us with free licenses to their great tools.\n\n* [<img src=\"https://www.authelia.com/svgs/logos/intellij-idea.svg\" alt=\"IDEA\" width=\"32\"> IDEA](http://www.jetbrains.com/idea/)\n* [<img src=\"https://www.authelia.com/svgs/logos/goland.svg\" alt=\"GoLand\" width=\"32\"> GoLand](http://www.jetbrains.com/go/)\n* [<img src=\"https://www.authelia.com/svgs/logos/webstorm.svg\" alt=\"WebStorm\" width=\"32\"> WebStorm](http://www.jetbrains.com/webstorm/)\n\n#### Microsoft\n\nOur pipeline agents which we rely on for productivity are hosted on [Azure](https://azure.microsoft.com/?from=Authelia)\nand our [git repositories](https://github.com/authelia) are hosted on [GitHub](https://github.com/?from=Authela)\nwhich are both [Microsoft](https://www.microsoft.com/?from=Authelia) products.\n\n[<img src=\"https://www.authelia.com/svgs/logos/microsoft.svg\" alt=\"microsoft\" height=\"32\">](https://www.microsoft.com/?from=Authelia)\n\n[<img src=\"https://www.authelia.com/svgs/logos/azure.svg\" alt=\"Azure\" height=\"32\">](https://azure.microsoft.com/?from=Authelia)\n\n### Open Collective\n\n#### Backers\n\nThank you to all our backers! ğŸ™ [Become a backer](https://opencollective.com/authelia-sponsors/contribute) and help us\nsustain our community. The money we currently receive is dedicated to fund a security audit, and potentially in the\nfuture introducing a bug bounty program to give us as many\neyes as we can to detect potential vulnerabilities.\n<a href=\"https://opencollective.com/authelia-sponsors#backers\"><img src=\"https://opencollective.com/authelia-sponsors/backers.svg?width=890\"></a>\n\n#### Sponsorship\n\nCompanies contributing to Authelia via Open Collective will have a special mention below.\n[Become a sponsor](https://opencollective.com/authelia-sponsors#sponsor).\n\n<a href=\"https://opencollective.com/authelia-sponsors/sponsor/0/website\"><img src=\"https://opencollective.com/authelia-sponsors/sponsor/0/avatar.svg\"></a>\n<a href=\"https://opencollective.com/authelia-sponsors/sponsor/1/website\"><img src=\"https://opencollective.com/authelia-sponsors/sponsor/1/avatar.svg\"></a>\n<a href=\"https://opencollective.com/authelia-sponsors/sponsor/2/website\"><img src=\"https://opencollective.com/authelia-sponsors/sponsor/2/avatar.svg\"></a>\n<a href=\"https://opencollective.com/authelia-sponsors/sponsor/3/website\"><img src=\"https://opencollective.com/authelia-sponsors/sponsor/3/avatar.svg\"></a>\n<a href=\"https://opencollective.com/authelia-sponsors/sponsor/4/website\"><img src=\"https://opencollective.com/authelia-sponsors/sponsor/4/avatar.svg\"></a>\n<a href=\"https://opencollective.com/authelia-sponsors/sponsor/5/website\"><img src=\"https://opencollective.com/authelia-sponsors/sponsor/5/avatar.svg\"></a>\n<a href=\"https://opencollective.com/authelia-sponsors/sponsor/6/website\"><img src=\"https://opencollective.com/authelia-sponsors/sponsor/6/avatar.svg\"></a>\n<a href=\"https://opencollective.com/authelia-sponsors/sponsor/7/website\"><img src=\"https://opencollective.com/authelia-sponsors/sponsor/7/avatar.svg\"></a>\n<a href=\"https://opencollective.com/authelia-sponsors/sponsor/8/website\"><img src=\"https://opencollective.com/authelia-sponsors/sponsor/8/avatar.svg\"></a>\n<a href=\"https://opencollective.com/authelia-sponsors/sponsor/9/website\"><img src=\"https://opencollective.com/authelia-sponsors/sponsor/9/avatar.svg\"></a>\n\n## License\n\n**Authelia** is **licensed** under the **[Apache 2.0]** license. The terms of the license are detailed in\n[LICENSE](LICENSE).\n\n[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fauthelia%2Fauthelia.svg?type=large)](https://app.fossa.com/projects/git%2Bgithub.com%2Fauthelia%2Fauthelia?ref=badge_large)\n\n\n[Apache 2.0]: https://www.apache.org/licenses/LICENSE-2.0\n[TOTP]: https://en.wikipedia.org/wiki/Time-based_One-time_Password_Algorithm\n[FIDO2]: https://www.yubico.com/authentication-standards/fido2/\n[YubiKey]: https://www.yubico.com/products/yubikey-5-overview/\n[WebAuthn]: https://www.yubico.com/authentication-standards/webauthn/\n[auth_request]: https://nginx.org/en/docs/http/ngx_http_auth_request_module.html\n[config.template.yml]: ./config.template.yml\n[nginx]: https://www.authelia.com/integration/proxies/nginx/\n[Traefik]: https://www.authelia.com/integration/proxies/traefik/\n[Caddy]: https://www.authelia.com/integration/proxies/caddy/\n[Skipper]: https://www.authelia.com/integration/proxies/skipper/\n[Envoy]: https://www.authelia.com/integration/proxies/envoy/\n[HAProxy]: https://www.authelia.com/integration/proxies/haproxy/\n[Docker]: https://docker.com/\n[Kubernetes]: https://kubernetes.io/\n[security]: https://github.com/authelia/authelia/security/policy\n[#support]: https://discord.com/channels/707844280412012608/707844280412012612\n[#contributing]: https://discord.com/channels/707844280412012608/804943261265297408\n[OpenID Certifiedâ„¢]: https://openid.net/certification/\n[OpenID Connectâ„¢ protocol]: https://openid.net/developers/how-connect-works/\n",
      "stars_today": 24
    },
    {
      "id": 70107786,
      "name": "next.js",
      "full_name": "vercel/next.js",
      "description": "The React Framework",
      "html_url": "https://github.com/vercel/next.js",
      "stars": 137550,
      "forks": 30406,
      "language": "JavaScript",
      "topics": [
        "blog",
        "browser",
        "compiler",
        "components",
        "hybrid",
        "nextjs",
        "node",
        "react",
        "server-rendering",
        "ssg",
        "static",
        "static-site-generator",
        "universal",
        "vercel"
      ],
      "created_at": "2016-10-05T23:32:51Z",
      "updated_at": "2026-02-06T23:45:55Z",
      "pushed_at": "2026-02-07T02:02:46Z",
      "open_issues": 3280,
      "owner": {
        "login": "vercel",
        "avatar_url": "https://avatars.githubusercontent.com/u/14985020?v=4"
      },
      "readme": "<div align=\"center\">\n  <a href=\"https://nextjs.org\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://assets.vercel.com/image/upload/v1662130559/nextjs/Icon_dark_background.png\">\n      <img alt=\"Next.js logo\" src=\"https://assets.vercel.com/image/upload/v1662130559/nextjs/Icon_light_background.png\" height=\"128\">\n    </picture>\n  </a>\n  <h1>Next.js</h1>\n\n<a href=\"https://vercel.com\"><img alt=\"Vercel logo\" src=\"https://img.shields.io/badge/MADE%20BY%20Vercel-000000.svg?style=for-the-badge&logo=Vercel&labelColor=000\"></a>\n<a href=\"https://www.npmjs.com/package/next\"><img alt=\"NPM version\" src=\"https://img.shields.io/npm/v/next.svg?style=for-the-badge&labelColor=000000\"></a>\n<a href=\"https://github.com/vercel/next.js/blob/canary/license.md\"><img alt=\"License\" src=\"https://img.shields.io/npm/l/next.svg?style=for-the-badge&labelColor=000000\"></a>\n<a href=\"https://github.com/vercel/next.js/discussions\"><img alt=\"Join the community on GitHub\" src=\"https://img.shields.io/badge/Join%20the%20community-blueviolet.svg?style=for-the-badge&logo=Next.js&labelColor=000000&logoWidth=20\"></a>\n\n</div>\n\n## Getting Started\n\nUsed by some of the world's largest companies, Next.js enables you to create full-stack web applications by extending the latest React features, and integrating powerful Rust-based JavaScript tooling for the fastest builds.\n\n- Visit our [Learn Next.js](https://nextjs.org/learn) course to get started with Next.js.\n- Visit the [Next.js Showcase](https://nextjs.org/showcase) to see more sites built with Next.js.\n\n## Documentation\n\nVisit [https://nextjs.org/docs](https://nextjs.org/docs) to view the full documentation.\n\n## Community\n\nThe Next.js community can be found on [GitHub Discussions](https://github.com/vercel/next.js/discussions) where you can ask questions, voice ideas, and share your projects with other people.\n\nTo chat with other community members you can join the Next.js [Discord](https://nextjs.org/discord) server.\n\nDo note that our [Code of Conduct](https://github.com/vercel/next.js/blob/canary/CODE_OF_CONDUCT.md) applies to all Next.js community channels. Users are **highly encouraged** to read and adhere to it to avoid repercussions.\n\n## Contributing\n\nContributions to Next.js are welcome and highly appreciated. However, before you jump right into it, we would like you to review our [Contribution Guidelines](/contributing.md) to make sure you have a smooth experience contributing to Next.js.\n\n### Good First Issues:\n\nWe have a list of **[good first issues](https://github.com/vercel/next.js/labels/good%20first%20issue)** that contain bugs that have a relatively limited scope. This is a great place for newcomers and beginners alike to get started, gain experience, and get familiar with our contribution process.\n\n---\n## Security\n\nIf you believe you have found a security vulnerability in Next.js, we encourage you to **_responsibly disclose this and NOT open a public issue_**.\n\nTo participate in our Open Source Software Bug Bounty program, please email [responsible.disclosure@vercel.com](mailto:responsible.disclosure@vercel.com). We will add you to the program and provide further instructions for submitting your report.\n",
      "stars_today": 22
    },
    {
      "id": 531380835,
      "name": "sherpa-onnx",
      "full_name": "k2-fsa/sherpa-onnx",
      "description": "Speech-to-text, text-to-speech, speaker diarization, speech enhancement, source separation, and VAD using next-gen Kaldi with onnxruntime without Internet connection. Support embedded systems, Android, iOS, HarmonyOS, Raspberry Pi, RISC-V, RK NPU, Axera NPU, Ascend NPU, x86_64 servers, websocket server/client, support 12 programming languages",
      "html_url": "https://github.com/k2-fsa/sherpa-onnx",
      "stars": 10196,
      "forks": 1148,
      "language": "C++",
      "topics": [
        "aarch64",
        "android",
        "arm32",
        "asr",
        "cpp",
        "csharp",
        "dotnet",
        "ios",
        "lazarus",
        "linux",
        "macos",
        "mfc",
        "object-pascal",
        "onnx",
        "raspberry-pi",
        "risc-v",
        "speech-to-text",
        "text-to-speech",
        "vits",
        "windows"
      ],
      "created_at": "2022-09-01T05:47:33Z",
      "updated_at": "2026-02-07T02:00:05Z",
      "pushed_at": "2026-02-06T08:09:32Z",
      "open_issues": 536,
      "owner": {
        "login": "k2-fsa",
        "avatar_url": "https://avatars.githubusercontent.com/u/71431748?v=4"
      },
      "readme": " ### Supported functions\n\n|Speech recognition| [Speech synthesis][tts-url] | [Source separation][ss-url] |\n|------------------|------------------|-------------------|\n|   âœ”ï¸              |         âœ”ï¸        |       âœ”ï¸           |\n\n|Speaker identification| [Speaker diarization][sd-url] | Speaker verification |\n|----------------------|-------------------- |------------------------|\n|   âœ”ï¸                  |         âœ”ï¸           |            âœ”ï¸           |\n\n| [Spoken Language identification][slid-url] | [Audio tagging][at-url] | [Voice activity detection][vad-url] |\n|--------------------------------|---------------|--------------------------|\n|                 âœ”ï¸              |          âœ”ï¸    |                âœ”ï¸         |\n\n| [Keyword spotting][kws-url] | [Add punctuation][punct-url] | [Speech enhancement][se-url] |\n|------------------|-----------------|--------------------|\n|     âœ”ï¸            |       âœ”ï¸         |      âœ”ï¸             |\n\n\n### Supported platforms\n\n|Architecture| Android | iOS     | Windows    | macOS | linux | HarmonyOS |\n|------------|---------|---------|------------|-------|-------|-----------|\n|   x64      |  âœ”ï¸      |         |   âœ”ï¸      | âœ”ï¸    |  âœ”ï¸    |   âœ”ï¸   |\n|   x86      |  âœ”ï¸      |         |   âœ”ï¸      |       |        |        |\n|   arm64    |  âœ”ï¸      | âœ”ï¸      |   âœ”ï¸      | âœ”ï¸    |  âœ”ï¸    |   âœ”ï¸   |\n|   arm32    |  âœ”ï¸      |         |           |       |  âœ”ï¸    |   âœ”ï¸   |\n|   riscv64  |          |         |           |       |  âœ”ï¸    |        |\n\n### Supported programming languages\n\n| 1. C++ | 2. C  | 3. Python | 4. JavaScript |\n|--------|-------|-----------|---------------|\n|   âœ”ï¸    | âœ”ï¸     | âœ”ï¸         |    âœ”ï¸          |\n\n|5. Java | 6. C# | 7. Kotlin | 8. Swift |\n|--------|-------|-----------|----------|\n| âœ”ï¸      |  âœ”ï¸    | âœ”ï¸         |  âœ”ï¸       |\n\n| 9. Go | 10. Dart | 11. Rust | 12. Pascal |\n|-------|----------|----------|------------|\n| âœ”ï¸     |  âœ”ï¸       |   âœ”ï¸      |    âœ”ï¸       |\n\nFor Rust support, please see [sherpa-rs][sherpa-rs]\n\nIt also supports WebAssembly.\n\n### Supported NPUs\n\n| [1. Rockchip NPU (RKNN)][rknpu-doc] | [2. Qualcomm NPU (QNN)][qnn-doc]  | [3. Ascend NPU][ascend-doc] |\n|-------------------------------------|-----------------------------------|-----------------------------|\n|     âœ”ï¸                              |                  âœ”ï¸               |     âœ”ï¸                      |\n\n| [4. Axera NPU][axera-npu] |\n|---------------------------|\n|     âœ”ï¸                    |\n\n[Join our discord](https://discord.gg/fJdxzg2VbG)\n\n\n## Introduction\n\nThis repository supports running the following functions **locally**\n\n  - Speech-to-text (i.e., ASR); both streaming and non-streaming are supported\n  - Text-to-speech (i.e., TTS)\n  - Speaker diarization\n  - Speaker identification\n  - Speaker verification\n  - Spoken language identification\n  - Audio tagging\n  - VAD (e.g., [silero-vad][silero-vad])\n  - Speech enhancement (e.g., [gtcrn][gtcrn])\n  - Keyword spotting\n  - Source separation (e.g., [spleeter][spleeter], [UVR][UVR])\n\non the following platforms and operating systems:\n\n  - x86, ``x86_64``, 32-bit ARM, 64-bit ARM (arm64, aarch64), RISC-V (riscv64), **RK NPU**, **Ascend NPU**\n  - Linux, macOS, Windows, openKylin\n  - Android, WearOS\n  - iOS\n  - HarmonyOS\n  - NodeJS\n  - WebAssembly\n  - [NVIDIA Jetson Orin NX][NVIDIA Jetson Orin NX] (Support running on both CPU and GPU)\n  - [NVIDIA Jetson Nano B01][NVIDIA Jetson Nano B01] (Support running on both CPU and GPU)\n  - [Raspberry Pi][Raspberry Pi]\n  - [RV1126][RV1126]\n  - [LicheePi4A][LicheePi4A]\n  - [VisionFive 2][VisionFive 2]\n  - [æ—­æ—¥X3æ´¾][æ—­æ—¥X3æ´¾]\n  - [çˆ±èŠ¯æ´¾][çˆ±èŠ¯æ´¾]\n  - [RK3588][RK3588]\n  - etc\n\nwith the following APIs\n\n  - C++, C, Python, Go, ``C#``\n  - Java, Kotlin, JavaScript\n  - Swift, Rust\n  - Dart, Object Pascal\n\n### Links for Huggingface Spaces\n\n<details>\n<summary>You can visit the following Huggingface spaces to try sherpa-onnx without\ninstalling anything. All you need is a browser.</summary>\n\n| Description                                           | URL                                     | ä¸­å›½é•œåƒ                               |\n|-------------------------------------------------------|-----------------------------------------|----------------------------------------|\n| Speaker diarization                                   | [Click me][hf-space-speaker-diarization]| [é•œåƒ][hf-space-speaker-diarization-cn]|\n| Speech recognition                                    | [Click me][hf-space-asr]                | [é•œåƒ][hf-space-asr-cn]                |\n| Speech recognition with [Whisper][Whisper]            | [Click me][hf-space-asr-whisper]        | [é•œåƒ][hf-space-asr-whisper-cn]        |\n| Speech synthesis                                      | [Click me][hf-space-tts]                | [é•œåƒ][hf-space-tts-cn]                |\n| Generate subtitles                                    | [Click me][hf-space-subtitle]           | [é•œåƒ][hf-space-subtitle-cn]           |\n| Audio tagging                                         | [Click me][hf-space-audio-tagging]      | [é•œåƒ][hf-space-audio-tagging-cn]      |\n| Source separation                                     | [Click me][hf-space-source-separation]  | [é•œåƒ][hf-space-source-separation-cn]  |\n| Spoken language identification with [Whisper][Whisper]| [Click me][hf-space-slid-whisper]       | [é•œåƒ][hf-space-slid-whisper-cn]       |\n\nWe also have spaces built using WebAssembly. They are listed below:\n\n| Description                                                                              | Huggingface space| ModelScope space|\n|------------------------------------------------------------------------------------------|------------------|-----------------|\n|Voice activity detection with [silero-vad][silero-vad]                                    | [Click me][wasm-hf-vad]|[åœ°å€][wasm-ms-vad]|\n|Real-time speech recognition (Chinese + English) with Zipformer                           | [Click me][wasm-hf-streaming-asr-zh-en-zipformer]|[åœ°å€][wasm-hf-streaming-asr-zh-en-zipformer]|\n|Real-time speech recognition (Chinese + English) with Paraformer                          |[Click me][wasm-hf-streaming-asr-zh-en-paraformer]| [åœ°å€][wasm-ms-streaming-asr-zh-en-paraformer]|\n|Real-time speech recognition (Chinese + English + Cantonese) with [Paraformer-large][Paraformer-large]|[Click me][wasm-hf-streaming-asr-zh-en-yue-paraformer]| [åœ°å€][wasm-ms-streaming-asr-zh-en-yue-paraformer]|\n|Real-time speech recognition (English) |[Click me][wasm-hf-streaming-asr-en-zipformer]    |[åœ°å€][wasm-ms-streaming-asr-en-zipformer]|\n|VAD + speech recognition (Chinese) with [Zipformer CTC](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-ctc/icefall/zipformer.html#sherpa-onnx-zipformer-ctc-zh-int8-2025-07-03-chinese)|[Click me][wasm-hf-vad-asr-zh-zipformer-ctc-07-03]| [åœ°å€][wasm-ms-vad-asr-zh-zipformer-ctc-07-03]|\n|VAD + speech recognition (Chinese + English + Korean + Japanese + Cantonese) with [SenseVoice][SenseVoice]|[Click me][wasm-hf-vad-asr-zh-en-ko-ja-yue-sense-voice]| [åœ°å€][wasm-ms-vad-asr-zh-en-ko-ja-yue-sense-voice]|\n|VAD + speech recognition (English) with [Whisper][Whisper] tiny.en|[Click me][wasm-hf-vad-asr-en-whisper-tiny-en]| [åœ°å€][wasm-ms-vad-asr-en-whisper-tiny-en]|\n|VAD + speech recognition (English) with [Moonshine tiny][Moonshine tiny]|[Click me][wasm-hf-vad-asr-en-moonshine-tiny-en]| [åœ°å€][wasm-ms-vad-asr-en-moonshine-tiny-en]|\n|VAD + speech recognition (English) with Zipformer trained with [GigaSpeech][GigaSpeech]    |[Click me][wasm-hf-vad-asr-en-zipformer-gigaspeech]| [åœ°å€][wasm-ms-vad-asr-en-zipformer-gigaspeech]|\n|VAD + speech recognition (Chinese) with Zipformer trained with [WenetSpeech][WenetSpeech]  |[Click me][wasm-hf-vad-asr-zh-zipformer-wenetspeech]| [åœ°å€][wasm-ms-vad-asr-zh-zipformer-wenetspeech]|\n|VAD + speech recognition (Japanese) with Zipformer trained with [ReazonSpeech][ReazonSpeech]|[Click me][wasm-hf-vad-asr-ja-zipformer-reazonspeech]| [åœ°å€][wasm-ms-vad-asr-ja-zipformer-reazonspeech]|\n|VAD + speech recognition (Thai) with Zipformer trained with [GigaSpeech2][GigaSpeech2]      |[Click me][wasm-hf-vad-asr-th-zipformer-gigaspeech2]| [åœ°å€][wasm-ms-vad-asr-th-zipformer-gigaspeech2]|\n|VAD + speech recognition (Chinese å¤šç§æ–¹è¨€) with a [TeleSpeech-ASR][TeleSpeech-ASR] CTC model|[Click me][wasm-hf-vad-asr-zh-telespeech]| [åœ°å€][wasm-ms-vad-asr-zh-telespeech]|\n|VAD + speech recognition (English + Chinese, åŠå¤šç§ä¸­æ–‡æ–¹è¨€) with Paraformer-large          |[Click me][wasm-hf-vad-asr-zh-en-paraformer-large]| [åœ°å€][wasm-ms-vad-asr-zh-en-paraformer-large]|\n|VAD + speech recognition (English + Chinese, åŠå¤šç§ä¸­æ–‡æ–¹è¨€) with Paraformer-small          |[Click me][wasm-hf-vad-asr-zh-en-paraformer-small]| [åœ°å€][wasm-ms-vad-asr-zh-en-paraformer-small]|\n|VAD + speech recognition (å¤šè¯­ç§åŠå¤šç§ä¸­æ–‡æ–¹è¨€) with [Dolphin][Dolphin]-base          |[Click me][wasm-hf-vad-asr-multi-lang-dolphin-base]| [åœ°å€][wasm-ms-vad-asr-multi-lang-dolphin-base]|\n|Speech synthesis (Piper, English)                                                                  |[Click me][wasm-hf-tts-piper-en]| [åœ°å€][wasm-ms-tts-piper-en]|\n|Speech synthesis (Piper, German)                                                                   |[Click me][wasm-hf-tts-piper-de]| [åœ°å€][wasm-ms-tts-piper-de]|\n|Speech synthesis (Matcha, Chinese)                                                                  |[Click me][wasm-hf-tts-matcha-zh]| [åœ°å€][wasm-ms-tts-matcha-zh]|\n|Speech synthesis (Matcha, English)                                                                  |[Click me][wasm-hf-tts-matcha-en]| [åœ°å€][wasm-ms-tts-matcha-en]|\n|Speech synthesis (Matcha, Chinese+English)                                                          |[Click me][wasm-hf-tts-matcha-zh-en]| [åœ°å€][wasm-ms-tts-matcha-zh-en]|\n|Speaker diarization                                                                         |[Click me][wasm-hf-speaker-diarization]|[åœ°å€][wasm-ms-speaker-diarization]|\n\n</details>\n\n### Links for pre-built Android APKs\n\n<details>\n\n<summary>You can find pre-built Android APKs for this repository in the following table</summary>\n\n| Description                            | URL                                | ä¸­å›½ç”¨æˆ·                          |\n|----------------------------------------|------------------------------------|-----------------------------------|\n| Speaker diarization                    | [Address][apk-speaker-diarization] | [ç‚¹æ­¤][apk-speaker-diarization-cn]|\n| Streaming speech recognition           | [Address][apk-streaming-asr]       | [ç‚¹æ­¤][apk-streaming-asr-cn]      |\n| Simulated-streaming speech recognition | [Address][apk-simula-streaming-asr]| [ç‚¹æ­¤][apk-simula-streaming-asr-cn]|\n| Text-to-speech                         | [Address][apk-tts]                 | [ç‚¹æ­¤][apk-tts-cn]                |\n| Voice activity detection (VAD)         | [Address][apk-vad]                 | [ç‚¹æ­¤][apk-vad-cn]                |\n| VAD + non-streaming speech recognition | [Address][apk-vad-asr]             | [ç‚¹æ­¤][apk-vad-asr-cn]            |\n| Two-pass speech recognition            | [Address][apk-2pass]               | [ç‚¹æ­¤][apk-2pass-cn]              |\n| Audio tagging                          | [Address][apk-at]                  | [ç‚¹æ­¤][apk-at-cn]                 |\n| Audio tagging (WearOS)                 | [Address][apk-at-wearos]           | [ç‚¹æ­¤][apk-at-wearos-cn]          |\n| Speaker identification                 | [Address][apk-sid]                 | [ç‚¹æ­¤][apk-sid-cn]                |\n| Spoken language identification         | [Address][apk-slid]                | [ç‚¹æ­¤][apk-slid-cn]               |\n| Keyword spotting                       | [Address][apk-kws]                 | [ç‚¹æ­¤][apk-kws-cn]                |\n\n</details>\n\n### Links for pre-built Flutter APPs\n\n<details>\n\n#### Real-time speech recognition\n\n| Description                    | URL                                 | ä¸­å›½ç”¨æˆ·                            |\n|--------------------------------|-------------------------------------|-------------------------------------|\n| Streaming speech recognition   | [Address][apk-flutter-streaming-asr]| [ç‚¹æ­¤][apk-flutter-streaming-asr-cn]|\n\n#### Text-to-speech\n\n| Description                              | URL                                | ä¸­å›½ç”¨æˆ·                           |\n|------------------------------------------|------------------------------------|------------------------------------|\n| Android (arm64-v8a, armeabi-v7a, x86_64) | [Address][flutter-tts-android]     | [ç‚¹æ­¤][flutter-tts-android-cn]     |\n| Linux (x64)                              | [Address][flutter-tts-linux]       | [ç‚¹æ­¤][flutter-tts-linux-cn]       |\n| macOS (x64)                              | [Address][flutter-tts-macos-x64]   | [ç‚¹æ­¤][flutter-tts-macos-x64-cn] |\n| macOS (arm64)                            | [Address][flutter-tts-macos-arm64] | [ç‚¹æ­¤][flutter-tts-macos-arm64-cn]   |\n| Windows (x64)                            | [Address][flutter-tts-win-x64]     | [ç‚¹æ­¤][flutter-tts-win-x64-cn]     |\n\n> Note: You need to build from source for iOS.\n\n</details>\n\n### Links for pre-built Lazarus APPs\n\n<details>\n\n#### Generating subtitles\n\n| Description                    | URL                        | ä¸­å›½ç”¨æˆ·                   |\n|--------------------------------|----------------------------|----------------------------|\n| Generate subtitles (ç”Ÿæˆå­—å¹•)  | [Address][lazarus-subtitle]| [ç‚¹æ­¤][lazarus-subtitle-cn]|\n\n</details>\n\n### Links for pre-trained models\n\n<details>\n\n| Description                                 | URL                                                                                   |\n|---------------------------------------------|---------------------------------------------------------------------------------------|\n| Speech recognition (speech to text, ASR)    | [Address][asr-models]                                                                 |\n| Text-to-speech (TTS)                        | [Address][tts-models]                                                                 |\n| VAD                                         | [Address][vad-models]                                                                 |\n| Keyword spotting                            | [Address][kws-models]                                                                 |\n| Audio tagging                               | [Address][at-models]                                                                  |\n| Speaker identification (Speaker ID)         | [Address][sid-models]                                                                 |\n| Spoken language identification (Language ID)| See multi-lingual [Whisper][Whisper] ASR models from  [Speech recognition][asr-models]|\n| Punctuation                                 | [Address][punct-models]                                                               |\n| Speaker segmentation                        | [Address][speaker-segmentation-models]                                                |\n| Speech enhancement                          | [Address][speech-enhancement-models]                                                  |\n| Source separation                           | [Address][source-separation-models]                                                  |\n\n</details>\n\n#### Some pre-trained ASR models (Streaming)\n\n<details>\n\nPlease see\n\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-paraformer/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-ctc/index.html>\n\nfor more models. The following table lists only **SOME** of them.\n\n\n|Name | Supported Languages| Description|\n|-----|-----|----|\n|[sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20][sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20]| Chinese, English| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20-bilingual-chinese-english)|\n|[sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16][sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16]| Chinese, English| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16-bilingual-chinese-english)|\n|[sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23][sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23]|Chinese| Suitable for Cortex A7 CPU. See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-zh-14m-2023-02-23)|\n|[sherpa-onnx-streaming-zipformer-en-20M-2023-02-17][sherpa-onnx-streaming-zipformer-en-20M-2023-02-17]|English|Suitable for Cortex A7 CPU. See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-en-20m-2023-02-17)|\n|[sherpa-onnx-streaming-zipformer-korean-2024-06-16][sherpa-onnx-streaming-zipformer-korean-2024-06-16]|Korean| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-korean-2024-06-16-korean)|\n|[sherpa-onnx-streaming-zipformer-fr-2023-04-14][sherpa-onnx-streaming-zipformer-fr-2023-04-14]|French| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#shaojieli-sherpa-onnx-streaming-zipformer-fr-2023-04-14-french)|\n\n</details>\n\n\n#### Some pre-trained ASR models (Non-Streaming)\n\n<details>\n\nPlease see\n\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-paraformer/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-ctc/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/telespeech/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/whisper/index.html>\n\nfor more models. The following table lists only **SOME** of them.\n\n|Name | Supported Languages| Description|\n|-----|-----|----|\n|[sherpa-onnx-nemo-parakeet-tdt-0.6b-v2-int8](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/nemo-transducer-models.html#sherpa-onnx-nemo-parakeet-tdt-0-6b-v2-int8-english)| English | It is converted from <https://huggingface.co/nvidia/parakeet-tdt-0.6b-v2>|\n|[Whisper tiny.en](https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-whisper-tiny.en.tar.bz2)|English| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/whisper/tiny.en.html)|\n|[Moonshine tiny][Moonshine tiny]|English|See [also](https://github.com/usefulsensors/moonshine)|\n|[sherpa-onnx-zipformer-ctc-zh-int8-2025-07-03](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-ctc/icefall/zipformer.html#sherpa-onnx-zipformer-ctc-zh-int8-2025-07-03-chinese)|Chinese| A Zipformer CTC model|\n|[sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17][sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17]|Chinese, Cantonese, English, Korean, Japanese| æ”¯æŒå¤šç§ä¸­æ–‡æ–¹è¨€. See [also](https://k2-fsa.github.io/sherpa/onnx/sense-voice/index.html)|\n|[sherpa-onnx-paraformer-zh-2024-03-09][sherpa-onnx-paraformer-zh-2024-03-09]|Chinese, English| ä¹Ÿæ”¯æŒå¤šç§ä¸­æ–‡æ–¹è¨€. See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-zh-2024-03-09-chinese-english)|\n|[sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01][sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01]|Japanese|See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01-japanese)|\n|[sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24][sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24]|Russian|See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/nemo-transducer-models.html#sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24-russian)|\n|[sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24][sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24]|Russian| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-ctc/nemo/russian.html#sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24)|\n|[sherpa-onnx-zipformer-ru-2024-09-18][sherpa-onnx-zipformer-ru-2024-09-18]|Russian|See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-ru-2024-09-18-russian)|\n|[sherpa-onnx-zipformer-korean-2024-06-24][sherpa-onnx-zipformer-korean-2024-06-24]|Korean|See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-korean-2024-06-24-korean)|\n|[sherpa-onnx-zipformer-thai-2024-06-20][sherpa-onnx-zipformer-thai-2024-06-20]|Thai| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-thai-2024-06-20-thai)|\n|[sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04][sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04]|Chinese| æ”¯æŒå¤šç§æ–¹è¨€. See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/telespeech/models.html#sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04)|\n\n</details>\n\n### Useful links\n\n- Documentation: https://k2-fsa.github.io/sherpa/onnx/\n- Bilibili æ¼”ç¤ºè§†é¢‘: https://search.bilibili.com/all?keyword=%E6%96%B0%E4%B8%80%E4%BB%A3Kaldi\n\n### How to reach us\n\nPlease see\nhttps://k2-fsa.github.io/sherpa/social-groups.html\nfor æ–°ä¸€ä»£ Kaldi **å¾®ä¿¡äº¤æµç¾¤** and **QQ äº¤æµç¾¤**.\n\n## Projects using sherpa-onnx\n\n### [BreezeApp](https://github.com/mtkresearch/BreezeApp) from [MediaTek Research](https://github.com/mtkresearch)\n\n> BreezeAPP is a mobile AI application developed for both Android and iOS platforms.\n> Users can download it directly from the App Store and enjoy a variety of features\n> offline, including speech-to-text, text-to-speech, text-based chatbot interactions,\n> and image question-answering\n\n  - [Download APK for BreezeAPP](https://huggingface.co/MediaTek-Research/BreezeApp/resolve/main/BreezeApp.apk)\n  - [APK ä¸­å›½é•œåƒ](https://hf-mirror.com/MediaTek-Research/BreezeApp/blob/main/BreezeApp.apk)\n\n| 1 | 2 | 3 |\n|---|---|---|\n|![](https://github.com/user-attachments/assets/1cdbc057-b893-4de6-9e9c-f1d7dfd1d992)|![](https://github.com/user-attachments/assets/d77cd98e-b057-442f-860d-d5befd5c769b)|![](https://github.com/user-attachments/assets/57e546bf-3d39-45b9-b392-b48ca4fb3c58)|\n\n### [Open-LLM-VTuber](https://github.com/t41372/Open-LLM-VTuber)\n\nTalk to any LLM with hands-free voice interaction, voice interruption, and Live2D taking\nface running locally across platforms\n\nSee also <https://github.com/t41372/Open-LLM-VTuber/pull/50>\n\n### [voiceapi](https://github.com/ruzhila/voiceapi)\n\n<details>\n  <summary>Streaming ASR and TTS based on FastAPI</summary>\n\n\nIt shows how to use the ASR and TTS Python APIs with FastAPI.\n</details>\n\n### [è…¾è®¯ä¼šè®®æ‘¸é±¼å·¥å…· TMSpeech](https://github.com/jxlpzqc/TMSpeech)\n\nUses streaming ASR in C# with graphical user interface.\n\nVideo demo in Chinese: [ã€å¼€æºã€‘Windowså®æ—¶å­—å¹•è½¯ä»¶ï¼ˆç½‘è¯¾/å¼€ä¼šå¿…å¤‡ï¼‰](https://www.bilibili.com/video/BV1rX4y1p7Nx)\n\n### [loläº’åŠ¨åŠ©æ‰‹](https://github.com/l1veIn/lol-wom-electron)\n\nIt uses the JavaScript API of sherpa-onnx along with [Electron](https://electronjs.org/)\n\nVideo demo in Chinese: [çˆ†äº†ï¼ç‚«ç¥æ•™ä½ å¼€æ‰“å­—æŒ‚ï¼çœŸæ­£å½±å“èƒœç‡çš„è‹±é›„è”ç›Ÿå·¥å…·ï¼è‹±é›„è”ç›Ÿçš„æœ€åä¸€å—æ‹¼å›¾ï¼å’Œæ¸¸æˆä¸­çš„æ¯ä¸ªäººæ— éšœç¢æ²Ÿé€šï¼](https://www.bilibili.com/video/BV142tje9E74)\n\n### [Sherpa-ONNX è¯­éŸ³è¯†åˆ«æœåŠ¡å™¨](https://github.com/hfyydd/sherpa-onnx-server)\n\nA server based on nodejs providing Restful API for speech recognition.\n\n### [QSmartAssistant](https://github.com/xinhecuican/QSmartAssistant)\n\nä¸€ä¸ªæ¨¡å—åŒ–ï¼Œå…¨è¿‡ç¨‹å¯ç¦»çº¿ï¼Œä½å ç”¨ç‡çš„å¯¹è¯æœºå™¨äºº/æ™ºèƒ½éŸ³ç®±\n\nIt uses QT. Both [ASR](https://github.com/xinhecuican/QSmartAssistant/blob/master/doc/%E5%AE%89%E8%A3%85.md#asr)\nand [TTS](https://github.com/xinhecuican/QSmartAssistant/blob/master/doc/%E5%AE%89%E8%A3%85.md#tts)\nare used.\n\n### [Flutter-EasySpeechRecognition](https://github.com/Jason-chen-coder/Flutter-EasySpeechRecognition)\n\nIt extends [./flutter-examples/streaming_asr](./flutter-examples/streaming_asr) by\ndownloading models inside the app to reduce the size of the app.\n\nNote: [[Team B] Sherpa AI backend](https://github.com/umgc/spring2025/pull/82) also uses\nsherpa-onnx in a Flutter APP.\n\n### [sherpa-onnx-unity](https://github.com/xue-fei/sherpa-onnx-unity)\n\nsherpa-onnx in Unity. See also [#1695](https://github.com/k2-fsa/sherpa-onnx/issues/1695),\n[#1892](https://github.com/k2-fsa/sherpa-onnx/issues/1892), and [#1859](https://github.com/k2-fsa/sherpa-onnx/issues/1859)\n\n### [xiaozhi-esp32-server](https://github.com/xinnan-tech/xiaozhi-esp32-server)\n\næœ¬é¡¹ç›®ä¸ºxiaozhi-esp32æä¾›åç«¯æœåŠ¡ï¼Œå¸®åŠ©æ‚¨å¿«é€Ÿæ­å»ºESP32è®¾å¤‡æ§åˆ¶æœåŠ¡å™¨\nBackend service for xiaozhi-esp32, helps you quickly build an ESP32 device control server.\n\nSee also\n\n  - [ASRæ–°å¢è½»é‡çº§sherpa-onnx-asr](https://github.com/xinnan-tech/xiaozhi-esp32-server/issues/315)\n  - [feat: ASRå¢åŠ sherpa-onnxæ¨¡å‹](https://github.com/xinnan-tech/xiaozhi-esp32-server/pull/379)\n\n### [KaithemAutomation](https://github.com/EternityForest/KaithemAutomation)\n\nPure Python, GUI-focused home automation/consumer grade SCADA.\n\nIt uses TTS from sherpa-onnx. See also [âœ¨ Speak command that uses the new globally configured TTS model.](https://github.com/EternityForest/KaithemAutomation/commit/8e64d2b138725e426532f7d66bb69dd0b4f53693)\n\n### [Open-XiaoAI KWS](https://github.com/idootop/open-xiaoai-kws)\n\nEnable custom wake word for XiaoAi Speakers. è®©å°çˆ±éŸ³ç®±æ”¯æŒè‡ªå®šä¹‰å”¤é†’è¯ã€‚\n\nVideo demo in Chinese: [å°çˆ±åŒå­¦å¯åŠ¨ï½Ë¶â•¹ê‡´â•¹Ë¶ï¼](https://www.bilibili.com/video/BV1YfVUz5EMj)\n\n### [C++ WebSocket ASR Server](https://github.com/mawwalker/stt-server)\n\nIt provides a WebSocket server based on C++ for ASR using sherpa-onnx.\n\n### [Go WebSocket Server](https://github.com/bbeyondllove/asr_server)\n\nIt provides a WebSocket server based on the Go programming language for sherpa-onnx.\n\n### [Making robot Paimon, Ep10 \"The AI Part 1\"](https://www.youtube.com/watch?v=KxPKkwxGWZs)\n\nIt is a [YouTube video](https://www.youtube.com/watch?v=KxPKkwxGWZs),\nshowing how the author tried to use AI so he can have a conversation with Paimon.\n\nIt uses sherpa-onnx for speech-to-text and text-to-speech.\n|1|\n|---|\n|![](https://github.com/user-attachments/assets/f6eea2d5-1807-42cb-9160-be8da2971e1f)|\n\n### [TtsReader - Desktop application](https://github.com/ys-pro-duction/TtsReader)\n\nA desktop text-to-speech application built using Kotlin Multiplatform.\n\n### [MentraOS](https://github.com/Mentra-Community/MentraOS)\n\n> Smart glasses OS, with dozens of built-in apps. Users get AI assistant, notifications,\n> translation, screen mirror, captions, and more. Devs get to write 1 app that runs on\n> any pair of smart glasses.\n\nIt uses sherpa-onnx for real-time speech recognition on iOS and Android devices.\nSee also <https://github.com/Mentra-Community/MentraOS/pull/861>\n\nIt uses Swift for iOS and Java for Android.\n\n### [flet_sherpa_onnx](https://github.com/SamYuan1990/flet_sherpa_onnx)\n\nFlet ASR/STT component based on sherpa-onnx.\nExample [a chat box agent](https://github.com/SamYuan1990/i18n-agent-action)\n\n### [achatbot-go](https://github.com/ai-bot-pro/achatbot-go)\n\na multimodal chatbot based on go with sherpa-onnx's speech lib api.\n\n[sherpa-rs]: https://github.com/thewh1teagle/sherpa-rs\n[silero-vad]: https://github.com/snakers4/silero-vad\n[Raspberry Pi]: https://www.raspberrypi.com/\n[RV1126]: https://www.rock-chips.com/uploads/pdf/2022.8.26/191/RV1126%20Brief%20Datasheet.pdf\n[LicheePi4A]: https://sipeed.com/licheepi4a\n[VisionFive 2]: https://www.starfivetech.com/en/site/boards\n[æ—­æ—¥X3æ´¾]: https://developer.horizon.ai/api/v1/fileData/documents_pi/index.html\n[çˆ±èŠ¯æ´¾]: https://wiki.sipeed.com/hardware/zh/maixIII/ax-pi/axpi.html\n[hf-space-speaker-diarization]: https://huggingface.co/spaces/k2-fsa/speaker-diarization\n[hf-space-speaker-diarization-cn]: https://hf.qhduan.com/spaces/k2-fsa/speaker-diarization\n[hf-space-asr]: https://huggingface.co/spaces/k2-fsa/automatic-speech-recognition\n[hf-space-asr-cn]: https://hf.qhduan.com/spaces/k2-fsa/automatic-speech-recognition\n[Whisper]: https://github.com/openai/whisper\n[hf-space-asr-whisper]: https://huggingface.co/spaces/k2-fsa/automatic-speech-recognition-with-whisper\n[hf-space-asr-whisper-cn]: https://hf.qhduan.com/spaces/k2-fsa/automatic-speech-recognition-with-whisper\n[hf-space-tts]: https://huggingface.co/spaces/k2-fsa/text-to-speech\n[hf-space-tts-cn]: https://hf.qhduan.com/spaces/k2-fsa/text-to-speech\n[hf-space-subtitle]: https://huggingface.co/spaces/k2-fsa/generate-subtitles-for-videos\n[hf-space-subtitle-cn]: https://hf.qhduan.com/spaces/k2-fsa/generate-subtitles-for-videos\n[hf-space-audio-tagging]: https://huggingface.co/spaces/k2-fsa/audio-tagging\n[hf-space-audio-tagging-cn]: https://hf.qhduan.com/spaces/k2-fsa/audio-tagging\n[hf-space-source-separation]: https://huggingface.co/spaces/k2-fsa/source-separation\n[hf-space-source-separation-cn]: https://hf.qhduan.com/spaces/k2-fsa/source-separation\n[hf-space-slid-whisper]: https://huggingface.co/spaces/k2-fsa/spoken-language-identification\n[hf-space-slid-whisper-cn]: https://hf.qhduan.com/spaces/k2-fsa/spoken-language-identification\n[wasm-hf-vad]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-sherpa-onnx\n[wasm-ms-vad]: https://modelscope.cn/studios/csukuangfj/web-assembly-vad-sherpa-onnx\n[wasm-hf-streaming-asr-zh-en-zipformer]: https://huggingface.co/spaces/k2-fsa/web-assembly-asr-sherpa-onnx-zh-en\n[wasm-ms-streaming-asr-zh-en-zipformer]: https://modelscope.cn/studios/k2-fsa/web-assembly-asr-sherpa-onnx-zh-en\n[wasm-hf-streaming-asr-zh-en-paraformer]: https://huggingface.co/spaces/k2-fsa/web-assembly-asr-sherpa-onnx-zh-en-paraformer\n[wasm-ms-streaming-asr-zh-en-paraformer]: https://modelscope.cn/studios/k2-fsa/web-assembly-asr-sherpa-onnx-zh-en-paraformer\n[Paraformer-large]: https://www.modelscope.cn/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/summary\n[wasm-hf-streaming-asr-zh-en-yue-paraformer]: https://huggingface.co/spaces/k2-fsa/web-assembly-asr-sherpa-onnx-zh-cantonese-en-paraformer\n[wasm-ms-streaming-asr-zh-en-yue-paraformer]: https://modelscope.cn/studios/k2-fsa/web-assembly-asr-sherpa-onnx-zh-cantonese-en-paraformer\n[wasm-hf-streaming-asr-en-zipformer]: https://huggingface.co/spaces/k2-fsa/web-assembly-asr-sherpa-onnx-en\n[wasm-ms-streaming-asr-en-zipformer]: https://modelscope.cn/studios/k2-fsa/web-assembly-asr-sherpa-onnx-en\n[SenseVoice]: https://github.com/FunAudioLLM/SenseVoice\n[wasm-hf-vad-asr-zh-zipformer-ctc-07-03]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-zipformer-ctc\n[wasm-ms-vad-asr-zh-zipformer-ctc-07-03]: https://modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-zh-zipformer-ctc/summary\n[wasm-hf-vad-asr-zh-en-ko-ja-yue-sense-voice]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-ja-ko-cantonese-sense-voice\n[wasm-ms-vad-asr-zh-en-ko-ja-yue-sense-voice]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-zh-en-jp-ko-cantonese-sense-voice\n[wasm-hf-vad-asr-en-whisper-tiny-en]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-en-whisper-tiny\n[wasm-ms-vad-asr-en-whisper-tiny-en]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-en-whisper-tiny\n[wasm-hf-vad-asr-en-moonshine-tiny-en]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-en-moonshine-tiny\n[wasm-ms-vad-asr-en-moonshine-tiny-en]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-en-moonshine-tiny\n[wasm-hf-vad-asr-en-zipformer-gigaspeech]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-en-zipformer-gigaspeech\n[wasm-ms-vad-asr-en-zipformer-gigaspeech]: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-en-zipformer-gigaspeech\n[wasm-hf-vad-asr-zh-zipformer-wenetspeech]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-zipformer-wenetspeech\n[wasm-ms-vad-asr-zh-zipformer-wenetspeech]: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-zipformer-wenetspeech\n[reazonspeech]: https://research.reazon.jp/_static/reazonspeech_nlp2023.pdf\n[wasm-hf-vad-asr-ja-zipformer-reazonspeech]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-ja-zipformer\n[wasm-ms-vad-asr-ja-zipformer-reazonspeech]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-ja-zipformer\n[gigaspeech2]: https://github.com/speechcolab/gigaspeech2\n[wasm-hf-vad-asr-th-zipformer-gigaspeech2]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-th-zipformer\n[wasm-ms-vad-asr-th-zipformer-gigaspeech2]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-th-zipformer\n[telespeech-asr]: https://github.com/tele-ai/telespeech-asr\n[wasm-hf-vad-asr-zh-telespeech]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-telespeech\n[wasm-ms-vad-asr-zh-telespeech]: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-telespeech\n[wasm-hf-vad-asr-zh-en-paraformer-large]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-paraformer\n[wasm-ms-vad-asr-zh-en-paraformer-large]: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-paraformer\n[wasm-hf-vad-asr-zh-en-paraformer-small]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-paraformer-small\n[wasm-ms-vad-asr-zh-en-paraformer-small]: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-paraformer-small\n[dolphin]: https://github.com/dataoceanai/dolphin\n[wasm-ms-vad-asr-multi-lang-dolphin-base]: https://modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-multi-lang-dophin-ctc\n[wasm-hf-vad-asr-multi-lang-dolphin-base]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-multi-lang-dophin-ctc\n\n[wasm-hf-tts-matcha-zh-en]: https://huggingface.co/spaces/k2-fsa/web-assembly-zh-en-tts-matcha\n[wasm-hf-tts-matcha-zh]: https://huggingface.co/spaces/k2-fsa/web-assembly-zh-tts-matcha\n[wasm-ms-tts-matcha-zh-en]: https://modelscope.cn/studios/csukuangfj/web-assembly-zh-en-tts-matcha\n[wasm-ms-tts-matcha-zh]: https://modelscope.cn/studios/csukuangfj/web-assembly-zh-tts-matcha\n[wasm-hf-tts-matcha-en]: https://huggingface.co/spaces/k2-fsa/web-assembly-en-tts-matcha\n[wasm-ms-tts-matcha-en]: https://modelscope.cn/studios/csukuangfj/web-assembly-en-tts-matcha\n[wasm-hf-tts-piper-en]: https://huggingface.co/spaces/k2-fsa/web-assembly-tts-sherpa-onnx-en\n[wasm-ms-tts-piper-en]: https://modelscope.cn/studios/k2-fsa/web-assembly-tts-sherpa-onnx-en\n[wasm-hf-tts-piper-de]: https://huggingface.co/spaces/k2-fsa/web-assembly-tts-sherpa-onnx-de\n[wasm-ms-tts-piper-de]: https://modelscope.cn/studios/k2-fsa/web-assembly-tts-sherpa-onnx-de\n[wasm-hf-speaker-diarization]: https://huggingface.co/spaces/k2-fsa/web-assembly-speaker-diarization-sherpa-onnx\n[wasm-ms-speaker-diarization]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-speaker-diarization-sherpa-onnx\n[apk-speaker-diarization]: https://k2-fsa.github.io/sherpa/onnx/speaker-diarization/apk.html\n[apk-speaker-diarization-cn]: https://k2-fsa.github.io/sherpa/onnx/speaker-diarization/apk-cn.html\n[apk-streaming-asr]: https://k2-fsa.github.io/sherpa/onnx/android/apk.html\n[apk-streaming-asr-cn]: https://k2-fsa.github.io/sherpa/onnx/android/apk-cn.html\n[apk-simula-streaming-asr]: https://k2-fsa.github.io/sherpa/onnx/android/apk-simulate-streaming-asr.html\n[apk-simula-streaming-asr-cn]: https://k2-fsa.github.io/sherpa/onnx/android/apk-simulate-streaming-asr-cn.html\n[apk-tts]: https://k2-fsa.github.io/sherpa/onnx/tts/apk-engine.html\n[apk-tts-cn]: https://k2-fsa.github.io/sherpa/onnx/tts/apk-engine-cn.html\n[apk-vad]: https://k2-fsa.github.io/sherpa/onnx/vad/apk.html\n[apk-vad-cn]: https://k2-fsa.github.io/sherpa/onnx/vad/apk-cn.html\n[apk-vad-asr]: https://k2-fsa.github.io/sherpa/onnx/vad/apk-asr.html\n[apk-vad-asr-cn]: https://k2-fsa.github.io/sherpa/onnx/vad/apk-asr-cn.html\n[apk-2pass]: https://k2-fsa.github.io/sherpa/onnx/android/apk-2pass.html\n[apk-2pass-cn]: https://k2-fsa.github.io/sherpa/onnx/android/apk-2pass-cn.html\n[apk-at]: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/apk.html\n[apk-at-cn]: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/apk-cn.html\n[apk-at-wearos]: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/apk-wearos.html\n[apk-at-wearos-cn]: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/apk-wearos-cn.html\n[apk-sid]: https://k2-fsa.github.io/sherpa/onnx/speaker-identification/apk.html\n[apk-sid-cn]: https://k2-fsa.github.io/sherpa/onnx/speaker-identification/apk-cn.html\n[apk-slid]: https://k2-fsa.github.io/sherpa/onnx/spoken-language-identification/apk.html\n[apk-slid-cn]: https://k2-fsa.github.io/sherpa/onnx/spoken-language-identification/apk-cn.html\n[apk-kws]: https://k2-fsa.github.io/sherpa/onnx/kws/apk.html\n[apk-kws-cn]: https://k2-fsa.github.io/sherpa/onnx/kws/apk-cn.html\n[apk-flutter-streaming-asr]: https://k2-fsa.github.io/sherpa/onnx/flutter/asr/app.html\n[apk-flutter-streaming-asr-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/asr/app-cn.html\n[flutter-tts-android]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-android.html\n[flutter-tts-android-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-android-cn.html\n[flutter-tts-linux]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-linux.html\n[flutter-tts-linux-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-linux-cn.html\n[flutter-tts-macos-x64]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-macos-x64.html\n[flutter-tts-macos-arm64-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-macos-arm64-cn.html\n[flutter-tts-macos-arm64]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-macos-arm64.html\n[flutter-tts-macos-x64-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-macos-x64-cn.html\n[flutter-tts-win-x64]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-win.html\n[flutter-tts-win-x64-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-win-cn.html\n[lazarus-subtitle]: https://k2-fsa.github.io/sherpa/onnx/lazarus/download-generated-subtitles.html\n[lazarus-subtitle-cn]: https://k2-fsa.github.io/sherpa/onnx/lazarus/download-generated-subtitles-cn.html\n[asr-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/asr-models\n[tts-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/tts-models\n[vad-models]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/silero_vad.onnx\n[kws-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/kws-models\n[at-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/audio-tagging-models\n[sid-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/speaker-recongition-models\n[slid-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/speaker-recongition-models\n[punct-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/punctuation-models\n[speaker-segmentation-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/speaker-segmentation-models\n[GigaSpeech]: https://github.com/SpeechColab/GigaSpeech\n[WenetSpeech]: https://github.com/wenet-e2e/WenetSpeech\n[sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20.tar.bz2\n[sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16.tar.bz2\n[sherpa-onnx-streaming-zipformer-korean-2024-06-16]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-korean-2024-06-16.tar.bz2\n[sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23.tar.bz2\n[sherpa-onnx-streaming-zipformer-en-20M-2023-02-17]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-en-20M-2023-02-17.tar.bz2\n[sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01.tar.bz2\n[sherpa-onnx-zipformer-ru-2024-09-18]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-ru-2024-09-18.tar.bz2\n[sherpa-onnx-zipformer-korean-2024-06-24]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-korean-2024-06-24.tar.bz2\n[sherpa-onnx-zipformer-thai-2024-06-20]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-thai-2024-06-20.tar.bz2\n[sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24.tar.bz2\n[sherpa-onnx-paraformer-zh-2024-03-09]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-paraformer-zh-2024-03-09.tar.bz2\n[sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24.tar.bz2\n[sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04.tar.bz2\n[sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17.tar.bz2\n[sherpa-onnx-streaming-zipformer-fr-2023-04-14]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-fr-2023-04-14.tar.bz2\n[Moonshine tiny]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-moonshine-tiny-en-int8.tar.bz2\n[NVIDIA Jetson Orin NX]: https://developer.download.nvidia.com/assets/embedded/secure/jetson/orin_nx/docs/Jetson_Orin_NX_DS-10712-001_v0.5.pdf?RCPGu9Q6OVAOv7a7vgtwc9-BLScXRIWq6cSLuditMALECJ_dOj27DgnqAPGVnT2VpiNpQan9SyFy-9zRykR58CokzbXwjSA7Gj819e91AXPrWkGZR3oS1VLxiDEpJa_Y0lr7UT-N4GnXtb8NlUkP4GkCkkF_FQivGPrAucCUywL481GH_WpP_p7ziHU1Wg==&t=eyJscyI6ImdzZW8iLCJsc2QiOiJodHRwczovL3d3dy5nb29nbGUuY29tLmhrLyJ9\n[NVIDIA Jetson Nano B01]: https://www.seeedstudio.com/blog/2020/01/16/new-revision-of-jetson-nano-dev-kit-now-supports-new-jetson-nano-module/\n[speech-enhancement-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/speech-enhancement-models\n[source-separation-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/source-separation-models\n[RK3588]: https://www.rock-chips.com/uploads/pdf/2022.8.26/192/RK3588%20Brief%20Datasheet.pdf\n[spleeter]: https://github.com/deezer/spleeter\n[UVR]: https://github.com/Anjok07/ultimatevocalremovergui\n[gtcrn]: https://github.com/Xiaobin-Rong/gtcrn\n[tts-url]: https://k2-fsa.github.io/sherpa/onnx/tts/all-in-one.html\n[ss-url]: https://k2-fsa.github.io/sherpa/onnx/source-separation/index.html\n[sd-url]: https://k2-fsa.github.io/sherpa/onnx/speaker-diarization/index.html\n[slid-url]: https://k2-fsa.github.io/sherpa/onnx/spoken-language-identification/index.html\n[at-url]: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/index.html\n[vad-url]: https://k2-fsa.github.io/sherpa/onnx/vad/index.html\n[kws-url]: https://k2-fsa.github.io/sherpa/onnx/kws/index.html\n[punct-url]: https://k2-fsa.github.io/sherpa/onnx/punctuation/index.html\n[se-url]: https://k2-fsa.github.io/sherpa/onnx/speech-enhancement/index.html\n[rknpu-doc]: https://k2-fsa.github.io/sherpa/onnx/rknn/index.html\n[qnn-doc]: https://k2-fsa.github.io/sherpa/onnx/qnn/index.html\n[ascend-doc]: https://k2-fsa.github.io/sherpa/onnx/ascend/index.html\n[axera-npu]: https://axera-tech.com/Skill/166.html\n",
      "stars_today": 22
    },
    {
      "id": 619959033,
      "name": "gpt4all",
      "full_name": "nomic-ai/gpt4all",
      "description": "GPT4All: Run Local LLMs on Any Device. Open-source and available for commercial use.",
      "html_url": "https://github.com/nomic-ai/gpt4all",
      "stars": 77107,
      "forks": 8315,
      "language": "C++",
      "topics": [
        "ai-chat",
        "llm-inference"
      ],
      "created_at": "2023-03-27T18:49:32Z",
      "updated_at": "2026-02-07T02:10:05Z",
      "pushed_at": "2025-05-27T20:05:19Z",
      "open_issues": 752,
      "owner": {
        "login": "nomic-ai",
        "avatar_url": "https://avatars.githubusercontent.com/u/102670180?v=4"
      },
      "readme": "<h1 align=\"center\">GPT4All</h1>\n\n<p align=\"center\">\n  Now with support for DeepSeek R1 Distillations\n</p>\n\n<p align=\"center\">\n  <a href=\"https://www.nomic.ai/gpt4all\">Website</a> &bull; <a href=\"https://docs.gpt4all.io\">Documentation</a> &bull; <a href=\"https://discord.gg/mGZE39AS3e\">Discord</a> &bull; <a href=\"https://www.youtube.com/watch?v=gQcZDXRVJok\">YouTube Tutorial</a>\n</p>\n\n<p align=\"center\">\n  GPT4All runs large language models (LLMs) privately on everyday desktops & laptops.\n</p>\n<p align=\"center\">\n  No API calls or GPUs required - you can just download the application and <a href=\"https://docs.gpt4all.io/gpt4all_desktop/quickstart.html#quickstart\">get started</a>.\n</p>\n\n<p align=\"center\">\n  Read about what's new in <a href=\"https://www.nomic.ai/blog/tag/gpt4all\">our blog</a>.\n</p>\n<p align=\"center\">\n  <a href=\"https://nomic.ai/gpt4all/#newsletter-form\">Subscribe to the newsletter</a>\n</p>\n\nhttps://github.com/nomic-ai/gpt4all/assets/70534565/513a0f15-4964-4109-89e4-4f9a9011f311\n\n<p align=\"center\">\nGPT4All is made possible by our compute partner <a href=\"https://www.paperspace.com/\">Paperspace</a>.\n</p>\n\n## Download Links\n\n<p>\n  &mdash; <a href=\"https://gpt4all.io/installers/gpt4all-installer-win64.exe\">\n    <img src=\"gpt4all-bindings/python/docs/assets/windows.png\" style=\"height: 1em; width: auto\" /> Windows Installer\n  </a> &mdash;\n</p>\n<p>\n  &mdash; <a href=\"https://gpt4all.io/installers/gpt4all-installer-win64-arm.exe\">\n    <img src=\"gpt4all-bindings/python/docs/assets/windows.png\" style=\"height: 1em; width: auto\" /> Windows ARM Installer\n  </a> &mdash;\n</p>\n<p>\n  &mdash; <a href=\"https://gpt4all.io/installers/gpt4all-installer-darwin.dmg\">\n    <img src=\"gpt4all-bindings/python/docs/assets/mac.png\" style=\"height: 1em; width: auto\" /> macOS Installer\n  </a> &mdash;\n</p>\n<p>\n  &mdash; <a href=\"https://gpt4all.io/installers/gpt4all-installer-linux.run\">\n    <img src=\"gpt4all-bindings/python/docs/assets/ubuntu.svg\" style=\"height: 1em; width: auto\" /> Ubuntu Installer\n  </a> &mdash;\n</p>\n<p>\n  The Windows and Linux builds require Intel Core i3 2nd Gen / AMD Bulldozer, or better.\n</p>\n<p>\n  The Windows ARM build supports Qualcomm Snapdragon and Microsoft SQ1/SQ2 processors.\n</p>\n<p>\n  The Linux build is x86-64 only (no ARM).\n</p>\n<p>\n  The macOS build requires Monterey 12.6 or newer. Best results with Apple Silicon M-series processors.\n</p>\n\nSee the full [System Requirements](gpt4all-chat/system_requirements.md) for more details.\n\n<br/>\n<br/>\n<p>\n  <a href='https://flathub.org/apps/io.gpt4all.gpt4all'>\n    <img style=\"height: 2em; width: auto\" alt='Get it on Flathub' src='https://flathub.org/api/badge'><br/>\n    Flathub (community maintained)\n  </a>\n</p>\n\n## Install GPT4All Python\n\n`gpt4all` gives you access to LLMs with our Python client around [`llama.cpp`](https://github.com/ggerganov/llama.cpp) implementations. \n\nNomic contributes to open source software like [`llama.cpp`](https://github.com/ggerganov/llama.cpp) to make LLMs accessible and efficient **for all**.\n\n```bash\npip install gpt4all\n```\n\n```python\nfrom gpt4all import GPT4All\nmodel = GPT4All(\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\") # downloads / loads a 4.66GB LLM\nwith model.chat_session():\n    print(model.generate(\"How can I run LLMs efficiently on my laptop?\", max_tokens=1024))\n```\n\n\n## Integrations\n\n:parrot::link: [Langchain](https://python.langchain.com/v0.2/docs/integrations/providers/gpt4all/)\n:card_file_box: [Weaviate Vector Database](https://github.com/weaviate/weaviate) - [module docs](https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-gpt4all)\n:telescope: [OpenLIT (OTel-native Monitoring)](https://github.com/openlit/openlit) - [Docs](https://docs.openlit.io/latest/integrations/gpt4all)\n\n## Release History\n- **July 2nd, 2024**: V3.0.0 Release\n    - Fresh redesign of the chat application UI\n    - Improved user workflow for LocalDocs\n    - Expanded access to more model architectures\n- **October 19th, 2023**: GGUF Support Launches with Support for:\n    - Mistral 7b base model, an updated model gallery on our website, several new local code models including Rift Coder v1.5\n    - [Nomic Vulkan](https://blog.nomic.ai/posts/gpt4all-gpu-inference-with-vulkan) support for Q4\\_0 and Q4\\_1 quantizations in GGUF.\n    - Offline build support for running old versions of the GPT4All Local LLM Chat Client.\n- **September 18th, 2023**: [Nomic Vulkan](https://blog.nomic.ai/posts/gpt4all-gpu-inference-with-vulkan) launches supporting local LLM inference on NVIDIA and AMD GPUs.\n- **July 2023**: Stable support for LocalDocs, a feature that allows you to privately and locally chat with your data.\n- **June 28th, 2023**: [Docker-based API server] launches allowing inference of local LLMs from an OpenAI-compatible HTTP endpoint.\n\n[Docker-based API server]: https://github.com/nomic-ai/gpt4all/tree/cef74c2be20f5b697055d5b8b506861c7b997fab/gpt4all-api\n\n## Contributing\nGPT4All welcomes contributions, involvement, and discussion from the open source community!\nPlease see CONTRIBUTING.md and follow the issues, bug reports, and PR markdown templates.\n\nCheck project discord, with project owners, or through existing issues/PRs to avoid duplicate work.\nPlease make sure to tag all of the above with relevant project identifiers or your contribution could potentially get lost.\nExample tags: `backend`, `bindings`, `python-bindings`, `documentation`, etc.\n\n## Citation\n\nIf you utilize this repository, models or data in a downstream project, please consider citing it with:\n```\n@misc{gpt4all,\n  author = {Yuvanesh Anand and Zach Nussbaum and Brandon Duderstadt and Benjamin Schmidt and Andriy Mulyar},\n  title = {GPT4All: Training an Assistant-style Chatbot with Large Scale Data Distillation from GPT-3.5-Turbo},\n  year = {2023},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/nomic-ai/gpt4all}},\n}\n```\n",
      "stars_today": 21
    },
    {
      "id": 138754790,
      "name": "duckdb",
      "full_name": "duckdb/duckdb",
      "description": "DuckDB is an analytical in-process SQL database management system",
      "html_url": "https://github.com/duckdb/duckdb",
      "stars": 35926,
      "forks": 2910,
      "language": "C++",
      "topics": [
        "analytics",
        "database",
        "embedded-database",
        "olap",
        "sql"
      ],
      "created_at": "2018-06-26T15:04:45Z",
      "updated_at": "2026-02-07T00:51:26Z",
      "pushed_at": "2026-02-06T21:11:27Z",
      "open_issues": 612,
      "owner": {
        "login": "duckdb",
        "avatar_url": "https://avatars.githubusercontent.com/u/82039556?v=4"
      },
      "readme": "<div align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"logo/DuckDB_Logo-horizontal.svg\">\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"logo/DuckDB_Logo-horizontal-dark-mode.svg\">\n    <img alt=\"DuckDB logo\" src=\"logo/DuckDB_Logo-horizontal.svg\" height=\"100\">\n  </picture>\n</div>\n<br>\n\n<p align=\"center\">\n  <a href=\"https://github.com/duckdb/duckdb/actions\"><img src=\"https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=main\" alt=\"Github Actions Badge\"></a>\n  <a href=\"https://discord.gg/tcvwpjfnZx\"><img src=\"https://shields.io/discord/909674491309850675\" alt=\"discord\" /></a>\n  <a href=\"https://github.com/duckdb/duckdb/releases/\"><img src=\"https://img.shields.io/github/v/release/duckdb/duckdb?color=brightgreen&display_name=tag&logo=duckdb&logoColor=white\" alt=\"Latest Release\"></a>\n</p>\n\n## DuckDB\n\nDuckDB is a high-performance analytical database system. It is designed to be fast, reliable, portable, and easy to use. DuckDB provides a rich SQL dialect with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs, maps), and [several extensions designed to make SQL easier to use](https://duckdb.org/docs/stable/sql/dialect/friendly_sql.html).\n\nDuckDB is available as a [standalone CLI application](https://duckdb.org/docs/stable/clients/cli/overview) and has clients for [Python](https://duckdb.org/docs/stable/clients/python/overview), [R](https://duckdb.org/docs/stable/clients/r), [Java](https://duckdb.org/docs/stable/clients/java), [Wasm](https://duckdb.org/docs/stable/clients/wasm/overview), etc., with deep integrations with packages such as [pandas](https://duckdb.org/docs/guides/python/sql_on_pandas) and [dplyr](https://duckdb.org/docs/stable/clients/r#duckplyr-dplyr-api).\n\nFor more information on using DuckDB, please refer to the [DuckDB documentation](https://duckdb.org/docs/stable/).\n\n## Installation\n\nIf you want to install DuckDB, please see [our installation page](https://duckdb.org/docs/installation/) for instructions.\n\n## Data Import\n\nFor CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:\n\n```sql\nSELECT * FROM 'myfile.csv';\nSELECT * FROM 'myfile.parquet';\n```\n\nRefer to our [Data Import](https://duckdb.org/docs/stable/data/overview) section for more information.\n\n## SQL Reference\n\nThe documentation contains a [SQL introduction and reference](https://duckdb.org/docs/stable/sql/introduction).\n\n## Development\n\nFor development, DuckDB requires [CMake](https://cmake.org), Python 3 and a `C++11` compliant compiler. In the root directory, run `make` to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The details of benchmarks are in our [Benchmark Guide](benchmark/README.md).\n\nPlease also refer to our [Build Guide](https://duckdb.org/docs/stable/dev/building/overview) and [Contribution Guide](CONTRIBUTING.md).\n\n## Support\n\nSee the [Support Options](https://duckdblabs.com/support/) page and the dedicated [`endoflife.date`](https://endoflife.date/duckdb) page.\n",
      "stars_today": 21
    },
    {
      "id": 1096547557,
      "name": "Epstein-doc-explorer",
      "full_name": "maxandrews/Epstein-doc-explorer",
      "description": "a graph explorer of the Epstein emails",
      "html_url": "https://github.com/maxandrews/Epstein-doc-explorer",
      "stars": 434,
      "forks": 83,
      "language": "JavaScript",
      "topics": [],
      "created_at": "2025-11-14T15:31:14Z",
      "updated_at": "2026-02-07T02:27:15Z",
      "pushed_at": "2025-11-20T14:20:02Z",
      "open_issues": 8,
      "owner": {
        "login": "maxandrews",
        "avatar_url": "https://avatars.githubusercontent.com/u/173085487?v=4"
      },
      "readme": "# Epstein Document Network Explorer\n\n> **Note:** Additional documents are currently being processed and added to the network. The analysis pipeline is actively ingesting newly released documents from the House Oversight Committee.\n\nAn intelligent document analysis and network visualization system that processes legal documents to extract relationships, entities, and events, then visualizes them as an interactive knowledge graph.\n\n## Project Overview\n\nThis project analyzes the Epstein document corpus to extract structured information about actors, actions, locations, and relationships. It uses Claude AI for intelligent extraction and presents findings through an interactive network visualization interface.\n\n**Live Demo:** [Deployed on Render](https://epstein-doc-explorer-1.onrender.com/)\n\nSource documents are available here: https://drive.google.com/drive/folders/1ldncvdqIf6miiskDp_EDuGSDAaI_fJx8\nand here: https://huggingface.co/datasets/tensonaut/EPSTEIN_FILES_20K/tree/main\n**special thanks to u/tensonaut for extracting the image files with tesseract!**\n\n---\n\n## Architecture Overview\n\nThe project has two main phases:\n\n### 1. Analysis Pipeline\n**Purpose:** Extract structured data from raw documents using AI\n**Technology:** TypeScript, Claude AI (Anthropic), SQLite\n**Location:** Root directory + `analysis_pipeline/`\n\n### 2. Visualization Interface\n**Purpose:** Interactive exploration of the extracted relationship network\n**Technology:** React, TypeScript, Vite, D3.js/Force-Graph\n**Location:** `network-ui/`\n\n---\n\n## Key Features\n\n### Analysis Pipeline Features\n- **AI-Powered Extraction:** Uses Claude to extract entities, relationships, and events from documents\n- **Semantic Tagging:** Automatically tags triples with contextual metadata (legal, financial, travel, etc.)\n- **Tag Clustering:** Groups 28,000+ tags into 30 semantic clusters using K-means for better filtering\n- **Entity Deduplication:** Merges duplicate entities using LLM-based similarity detection\n- **Incremental Processing:** Supports analyzing new documents without reprocessing everything\n- **Top-3 Cluster Assignment:** Each relationship is assigned to its 3 most relevant tag clusters\n\n### Visualization Features\n- **Interactive Network Graph:** Force-directed graph with edge deduplication for performance\n- **Actor-Centric Views:** Click any actor to see their specific relationships\n- **Smart Filtering:** Filter by 30 content categories and hop distance from Jeffrey Epstein\n- **Density-Based Pruning:** Displays highest-density network connections for clarity\n- **Timeline View:** Chronological relationship browser with document links\n- **Document Viewer:** Full-text document display with highlighting\n- **Responsive Design:** Works on desktop and mobile devices\n- **Performance Optimized:** Uses materialized database columns for fast filtering\n\n---\n\n## Project Structure\n\n```\ndocnetwork/\nâ”œâ”€â”€ analysis_pipeline/          # Document analysis scripts\nâ”‚   â”œâ”€â”€ extract_data.py        # Initial document extraction\nâ”‚   â”œâ”€â”€ analyze_documents.ts   # Main AI analysis pipeline\nâ”‚   â”œâ”€â”€ cluster_tags.ts        # K-means tag clustering\nâ”‚   â”œâ”€â”€ dedupe_with_llm.ts     # Entity deduplication\nâ”‚   â””â”€â”€ extracted/             # Raw extracted documents\nâ”‚\nâ”œâ”€â”€ network-ui/                 # React visualization app\nâ”‚   â”œâ”€â”€ src/\nâ”‚   â”‚   â”œâ”€â”€ components/        # React components\nâ”‚   â”‚   â”œâ”€â”€ api.ts            # Backend API client\nâ”‚   â”‚   â””â”€â”€ App.tsx           # Main application\nâ”‚   â””â”€â”€ dist/                  # Production build\nâ”‚\nâ”œâ”€â”€ api_server.ts              # Express API server\nâ”œâ”€â”€ document_analysis.db       # SQLite database (91MB)\nâ”œâ”€â”€ tag_clusters.json          # 30 semantic tag clusters\nâ””â”€â”€ analysis_pipeline/update_top_clusters.ts # Migration: materialize top clusters\n```\n\n---\n\n## Core Components\n\n### Analysis Pipeline\n\n#### 1. Document Extraction (`analysis_pipeline/extract_data.py`)\n**Purpose:** Extract raw text from PDF documents\n**Input:** PDF files in `data/documents/`\n**Output:** JSON files in `analysis_pipeline/extracted/`\n**Key Features:**\n- Preserves document metadata (ID, category, date)\n- Handles various PDF formats\n- Stores full text for AI analysis\n\n#### 2. Document Analysis (`analysis_pipeline/analyze_documents.ts`)\n**Purpose:** Main AI-powered extraction pipeline\n**Input:** Extracted JSON documents\n**Output:** SQLite database with entities and relationships\n**Key Features:**\n- Uses Claude to extract RDF-style triples (subject-action-object)\n- Extracts temporal information (dates, timestamps)\n- Tags relationships with contextual metadata\n- Handles batch processing with rate limiting\n- Stores document full text for search\n\n**Database Schema:**\n```sql\n-- Documents table\nCREATE TABLE documents (\n  id INTEGER PRIMARY KEY AUTOINCREMENT,\n  doc_id TEXT UNIQUE NOT NULL,\n  file_path TEXT NOT NULL,\n  one_sentence_summary TEXT NOT NULL,      -- AI-generated brief summary\n  paragraph_summary TEXT NOT NULL,         -- AI-generated detailed summary\n  date_range_earliest TEXT,                -- Earliest date mentioned in document\n  date_range_latest TEXT,                  -- Latest date mentioned in document\n  category TEXT NOT NULL,                  -- Document category\n  content_tags TEXT NOT NULL,              -- JSON array of content tags\n  analysis_timestamp TEXT NOT NULL,        -- When analysis was performed\n  input_tokens INTEGER,                    -- Claude API usage metrics\n  output_tokens INTEGER,\n  cache_read_tokens INTEGER,\n  cost_usd REAL,                          -- Estimated API cost\n  error TEXT,                             -- Error message if analysis failed\n  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n  full_text TEXT                          -- Complete document text for search\n);\nCREATE INDEX idx_documents_doc_id ON documents(doc_id);\nCREATE INDEX idx_documents_category ON documents(category);\n\n-- RDF triples (relationships)\nCREATE TABLE rdf_triples (\n  id INTEGER PRIMARY KEY AUTOINCREMENT,\n  doc_id TEXT NOT NULL,\n  timestamp TEXT,                         -- When the event occurred\n  actor TEXT NOT NULL,                    -- Subject of the relationship\n  action TEXT NOT NULL,                   -- Action/verb\n  target TEXT NOT NULL,                   -- Object of the relationship\n  location TEXT,                          -- Where the event occurred\n  actor_likely_type TEXT,                 -- Type of actor (person, organization, etc.)\n  triple_tags TEXT,                       -- JSON array of tags\n  explicit_topic TEXT,                    -- Explicit subject matter\n  implicit_topic TEXT,                    -- Inferred subject matter\n  sequence_order INTEGER NOT NULL,        -- Order within document\n  top_cluster_ids TEXT,                   -- JSON array of top 3 cluster IDs (materialized)\n  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n  FOREIGN KEY (doc_id) REFERENCES documents(doc_id) ON DELETE CASCADE\n);\nCREATE INDEX idx_rdf_triples_doc_id ON rdf_triples(doc_id);\nCREATE INDEX idx_rdf_triples_actor ON rdf_triples(actor);\nCREATE INDEX idx_rdf_triples_timestamp ON rdf_triples(timestamp);\nCREATE INDEX idx_top_cluster_ids ON rdf_triples(top_cluster_ids);\n\n-- Entity aliases (deduplication)\nCREATE TABLE entity_aliases (\n  original_name TEXT PRIMARY KEY,\n  canonical_name TEXT NOT NULL,\n  reasoning TEXT,                         -- LLM explanation for the merge\n  created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  created_by TEXT DEFAULT 'llm_dedupe'    -- Source of the alias\n);\n```\n\n#### 3. Tag Clustering (`analysis_pipeline/cluster_tags.ts`)\n**Purpose:** Group 28,000+ tags into semantic clusters\n**Input:** All unique tags from database\n**Output:** `tag_clusters.json` with 30 clusters\n**Process:**\n1. Collect all unique tags from triples\n2. Generate or load cached embeddings using Qwen3-Embedding-0.6B-ONNX\n3. Run K-means clustering with K-means++ initialization\n4. Generate human-readable cluster names from exemplar tags\n5. Save cluster assignments with full tag lists\n\n**Technical Details:**\n- **Algorithm:** K-means with cosine distance metric\n- **Initialization:** K-means++ for better convergence\n- **Convergence:** Typically ~85 iterations\n- **Complexity:** O(nÂ·kÂ·i) - much faster than hierarchical methods\n- **Output:** 30 clusters ranging from 500-1400 tags each\n\n#### 4. Entity Deduplication (`analysis_pipeline/dedupe_with_llm.ts`)\n**Purpose:** Merge duplicate entity mentions\n**Input:** Entity names from database\n**Output:** `entity_aliases` table mapping variants to canonical names\n**Process:**\n1. Identify potential duplicates using fuzzy matching\n2. Use Claude to determine if entities are the same person\n3. Create alias mappings (e.g., \"Jeff Epstein\" â†’ \"Jeffrey Epstein\")\n4. API server resolves aliases in real-time\n\n#### 5. Migration Scripts\n**`analysis_pipeline/update_top_clusters.ts`**\n- Adds and populates `top_cluster_ids` column to `rdf_triples`\n- Computes top 3 clusters for each triple based on tag matches\n- Creates index for fast filtering\n- Improves query performance by 10x+\n\n---\n\n### API Server (`api_server.ts`)\n\n**Purpose:** Express.js backend serving data and frontend\n**Port:** 3001 (configurable via `PORT` env var)\n**Technology:** Express, better-sqlite3, CORS\n\n#### Key Endpoints\n\n**`GET /api/stats`**\n- Returns database statistics (document count, triple count, actor count)\n- Shows top document categories\n\n**`GET /api/tag-clusters`**\n- Returns all 30 tag clusters with metadata\n- Includes cluster names, exemplar tags, and tag counts\n\n**`GET /api/relationships?limit=9600&clusters=0,1,2&maxHops=3`**\n- Returns relationship network filtered by clusters and hop distance\n- Applies density-based pruning (highest-degree nodes prioritized)\n- Edge deduplication before limiting (slider value = unique visual edges)\n- Returns metadata: `{ relationships, totalBeforeLimit, totalBeforeFilter }`\n- Uses materialized `top_cluster_ids` for fast filtering\n\n**`GET /api/actor/:name/relationships?clusters=0,1,2`**\n- Returns all relationships for a specific actor\n- Handles entity aliases (resolves variants to canonical names)\n- Filtered by selected tag clusters\n- Returns: `{ relationships, totalBeforeFilter }`\n\n**`GET /api/search?q=query`**\n- Searches for actors by name\n- Returns fuzzy matches with relationship counts\n\n**`GET /api/document/:docId`**\n- Returns document metadata\n- Includes category, doc_id, file path\n\n**`GET /api/document/:docId/text`**\n- Returns full document text\n- Used for document viewer modal\n\n#### Performance Optimizations\n- **Materialized Clusters:** Pre-computed top 3 clusters per triple\n- **Indexed Columns:** Indexes on `top_cluster_ids`, `actor`, `target`\n- **Database Limits:** 100k row limit to prevent memory exhaustion\n- **Alias Resolution:** Efficient LEFT JOIN on entity_aliases\n- **Rate Limiting:** 1000 requests per 15 minutes per IP\n\n---\n\n### Visualization Interface\n\n#### Frontend Architecture (`network-ui/`)\n\n**Technology Stack:**\n- **React 18** with TypeScript\n- **Vite** for build tooling\n- **TailwindCSS** for styling\n- **react-force-graph-2d** for network visualization\n- **D3.js** for force simulation\n\n#### Key Components\n\n**`App.tsx`** - Main application container\n- Manages global state (relationships, selected actor, filters)\n- Loads tag clusters and enables all by default\n- Coordinates data fetching and updates\n- Handles desktop/mobile layout switching\n\n**`NetworkGraph.tsx`** - Force-directed graph visualization\n- Renders nodes (actors) and links (relationships)\n- Node size based on connection count\n- Click actors to select/deselect\n- Zoom and pan controls\n- Performance: Handles 15,000+ relationships smoothly\n\n**`Sidebar.tsx`** - Desktop left sidebar\n- Displays database statistics\n- Actor search with autocomplete\n- Relationship limit slider (100-25,000, default 9,600 desktop / 3,000 mobile)\n- Hop distance filter (1-10 hops from Jeffrey Epstein, default 3)\n- Tag cluster filter buttons\n- Document category breakdown\n\n**`RightSidebar.tsx`** - Desktop right sidebar (actor details)\n- Shows when actor is selected\n- Timeline view of actor's relationships\n- \"Showing X of Y relationships\" indicator\n- Document links with click-to-view\n\n**`MobileBottomNav.tsx`** - Mobile navigation\n- Tabbed interface: Search, Timeline, Filters\n- Condensed version of desktop sidebars\n- Touch-optimized controls\n\n**`DocumentModal.tsx`** - Full-text document viewer\n- Displays complete document text\n- Highlights actor names in context\n- Scrollable with close button\n- Fetches text on demand\n\n**`WelcomeModal.tsx`** - First-time visitor welcome\n- Introduces users to the explorer\n- Stored in localStorage (shown once)\n- Dismissible\n\n#### State Management\n\n**Global State (in App.tsx):**\n```typescript\nconst [stats, setStats] = useState<Stats | null>(null);\nconst [tagClusters, setTagClusters] = useState<TagCluster[]>([]);\nconst [relationships, setRelationships] = useState<Relationship[]>([]);\nconst [totalBeforeLimit, setTotalBeforeLimit] = useState<number>(0);\nconst [selectedActor, setSelectedActor] = useState<string | null>(null);\nconst [actorRelationships, setActorRelationships] = useState<Relationship[]>([]);\nconst [actorTotalBeforeFilter, setActorTotalBeforeFilter] = useState<number>(0);\nconst [limit, setLimit] = useState(isMobile ? 3000 : 9600);\nconst [maxHops, setMaxHops] = useState<number | null>(3);\nconst [minDensity, setMinDensity] = useState(50);\nconst [enabledClusterIds, setEnabledClusterIds] = useState<Set<number>>(new Set());\n```\n\n**Data Flow:**\n1. Load tag clusters on mount â†’ enable all clusters\n2. Fetch relationships when limit or clusters change\n3. Fetch actor relationships when actor selected or clusters change\n4. Update graph when relationships change\n\n#### Responsive Design\n- **Desktop (>1024px):** Dual sidebar layout with main graph\n- **Mobile (<1024px):** Full-screen graph with bottom navigation\n- **Adaptive Limits:** Mobile defaults to 3k relationships, desktop 9.6k\n\n---\n\n## Local Development\n\n```bash\n# Install dependencies\nnpm install\ncd network-ui && npm install && cd ..\n\n# Run API server\nnpx tsx api_server.ts\n\n# Run frontend (separate terminal)\ncd network-ui && npm run dev\n\n# Access:\n# - API: http://localhost:3001\n# - Frontend: http://localhost:5173\n```\n\n---\n\n## Key Files Reference\n\n### Analysis Scripts\n| File | Purpose | When to Run |\n|------|---------|-------------|\n| `analysis_pipeline/analyze_documents.ts` | Main AI analysis | After impactful schema changes or adding new docs |\n| `analysis_pipeline/cluster_tags.ts` | Create tag clusters with K-means | After major tag changes |\n| `analysis_pipeline/dedupe_with_llm.ts` | Deduplicate entities | After analyzing new documents |\n| `analysis_pipeline/update_top_clusters.ts` | Materialize cluster IDs | After running cluster_tags.ts |\n\n---\n\n## License\n\nMIT License - See LICENSE file for details\n\n## Contact\n\nFor questions or issues, please open a GitHub issue.\n\n**Repository:** https://github.com/maxandrews/Epstein-doc-explorer\n",
      "stars_today": 21
    },
    {
      "id": 44662669,
      "name": "dbeaver",
      "full_name": "dbeaver/dbeaver",
      "description": "Free universal database tool and SQL client",
      "html_url": "https://github.com/dbeaver/dbeaver",
      "stars": 48575,
      "forks": 4028,
      "language": "Java",
      "topics": [
        "ai",
        "copilot",
        "database",
        "db2",
        "dbeaver",
        "erd",
        "gui",
        "java",
        "jdbc",
        "mysql",
        "nosql",
        "openai",
        "oracle",
        "postgresql",
        "redshift",
        "sql",
        "sqlite",
        "sqlserver"
      ],
      "created_at": "2015-10-21T08:26:28Z",
      "updated_at": "2026-02-07T02:07:23Z",
      "pushed_at": "2026-02-07T01:17:05Z",
      "open_issues": 3229,
      "owner": {
        "login": "dbeaver",
        "avatar_url": "https://avatars.githubusercontent.com/u/34743864?v=4"
      },
      "readme": "[![Twitter URL](https://img.shields.io/twitter/url/https/twitter.com/dbeaver_news.svg?style=social&label=Follow%20%40dbeaver_news)](https://twitter.com/dbeaver_news)\n[![Codacy Badge](https://app.codacy.com/project/badge/Grade/fa0bb9cf5a904c7d87424f8f6351ba92)](https://app.codacy.com/gh/dbeaver/dbeaver/dashboard?utm_source=gh&utm_medium=referral&utm_content=&utm_campaign=Badge_grade)\n[![Apache 2.0](https://img.shields.io/github/license/cronn-de/jira-sync.svg)](http://www.apache.org/licenses/LICENSE-2.0)\n[![Tickets in review](https://img.shields.io/github/issues/dbeaver/dbeaver/wait%20for%20review)](https://github.com/dbeaver/dbeaver/issues?q=is%3Aissue+is%3Aopen+label%3A\"wait%20for%20review\")\n<img src=\"https://github.com/dbeaver/dbeaver/wiki/images/dbeaver-icon-64x64.png\" align=\"right\"/>\n\n# DBeaver\n\nFree multi-platform database tool for developers, SQL programmers, database administrators and analysts.  \n\n* Has a lot of <a href=\"https://github.com/dbeaver/dbeaver/wiki\">features</a> including schema editor, SQL editor, data editor, AI integration, ER diagrams, data export/import/migration, SQL execution plans, database administration tools, database dashboards, Spatial data viewer, proxy and SSH tunnelling, custom database drivers editor, etc.\n* Out of the box supports more than <a href=\"#supported-databases\">100 database drivers</a>.\n* Supports any database which has JDBC or ODBC driver (basically - almost all existing databases).\n* Supports smart AI completion and code generation with OpenAI or Copilot\n\n<a href=\"https://dbeaver.io/product/dbeaver-sql-editor.png\"><img src=\"https://dbeaver.io/product/dbeaver-sql-editor.png\" width=\"400\"/></a>\n<a href=\"https://dbeaver.io/product/dbeaver-gis-viewer.png\"><img src=\"https://dbeaver.io/product/dbeaver-gis-viewer.png\" width=\"400\"/></a>\n<a href=\"https://dbeaver.io/product/dbeaver-data-editor.png\"><img src=\"https://dbeaver.io/product/dbeaver-data-editor.png\" width=\"400\"/></a>\n<a href=\"https://dbeaver.io/product/dbeaver-erd.png\"><img src=\"https://dbeaver.io/product/dbeaver-erd.png\" width=\"400\"/></a>\n\n## Download\n\nYou can download prebuilt binaries from <a href=\"https://dbeaver.io/download\" target=\"_blank\">official website</a> or directly from <a href=\"https://github.com/dbeaver/dbeaver/releases\">GitHub releases</a>.  \nYou can also download <a href=\"https://dbeaver.io/files/ea\" target=\"_blank\">Early Access</a> version. We publish daily.  \n\n## Running\n\nJust run an installer (or unzip an archive) and run `dbeaver`.  \n\nNote: DBeaver needs Java to run. <a href=\"https://adoptium.net/temurin/releases/?package=jre\" target=\"_blank\">OpenJDK 21</a> is included in all DBeaver distributions.\nYou can change default JDK version by replacing directory `jre` in dbeaver installation folder.\n\n## Documentation\n\n* [Full product documentation](https://dbeaver.com/docs/dbeaver/)\n* [WIKI](https://github.com/dbeaver/dbeaver/wiki)\n* [Issue tracker](https://github.com/dbeaver/dbeaver/issues)\n* [Building from sources](https://github.com/dbeaver/dbeaver/wiki/Build-from-sources)\n\n## Architecture\n\n- DBeaver is written mostly on Java. However, it also uses a set of native OS-specific components for desktop UI, high performance database drivers and networking.\n- Basic frameworks:\n  - [OSGI](https://en.wikipedia.org/wiki/OSGi) platform for plugins and dependency management. Community version consists of 130+ plugins.\n  - [Eclipse RCP](https://github.com/eclipse-platform/eclipse.platform.ui/blob/master/docs/Rich_Client_Platform.md) platform for rich user interface build.\n  - [JDBC](https://en.wikipedia.org/wiki/Java_Database_Connectivity) for basic database connectivity API.\n  - [JSQLParser](https://github.com/JSQLParser/JSqlParser) and [Antlr4](https://github.com/antlr/antlr4) for SQL grammar and semantic parser.\n- For networking and additional functionality we use wide range of open source libraries such as [SSHJ](https://github.com/hierynomus/sshj), [Apache POI](https://github.com/apache/poi), [JFreeChart](https://github.com/jfree/jfreechart), [JTS](https://github.com/locationtech/jts), [Apache JEXL](https://github.com/apache/commons-jexl) etc.\n- We separate model plugins from desktop UI plugins. This allows us to use the same set of \"back-end\" plugins in both DBeaver and [CloudBeaver](https://github.com/dbeaver/cloudbeaver).\n- Dependencies: being an OSGI application we use P2 repositories for third party dependencies. For additional Maven dependencies we use our own [DBeaver P2 repo](https://github.com/dbeaver/dbeaver-deps-ce).\n\n## Supported databases\n\n### Community version\n\nOut of the box DBeaver supports following database drivers: \nMySQL, MariaDB, Oracle, DB2, PostgreSQL, SQL Server, Sybase, Apache Hive, Drill, Presto, Trino, Phoenix, Exasol, Informix, Teradata, Vertica, Netezza, Firebird, Derby, H2, H2GIS, WMI, Snowflake, Greenplum, Redshift, Athena, SAP HANA, MaxDB, NuoDB, MS Access, SQLite, CSV, DBF, Firebird, TimescaleDB, Yellowbrick, CockroachDB, OrientDB, MonetDB, Google BigQuery, Google Spanner, Apache Hive/Impala/Spark, Apache Ignite, MapD, Azure SQL, CrateDB, Elasticsearch, Ocient, Ingres, OmniSci, Yugabyte, IRIS, Data Virtuality, Denodo, Virtuoso, Machbase, DuckDB, Babelfish, OceanBase, Salesforce, EnterpriseDB, Apache Druid, Apache Kylin, Databricks, OpenSearch, TiDB, TDEngine, Materialize, JDBCX, Dameng, Altibase, StarRocks, CUBRID, GaussDB, DolphinDB, LibSQL, GBase 8s, Databend, Cloudberry, Teiid, Kingbase.\n\n### PRO versions\n\n<a href=\"https://dbeaver.com/download/\">Commercial versions</a> extends functionality of many popular drivers and also support non-JDBC datasources such as:\nODBC, MongoDB, Cassandra, Couchbase, CouchDB, Redis, InfluxDB, Firestore, BigTable, DynamoDB, Kafka KSQL, Neo4j, AWS Neptune, AWS Timestream, Azure CosmosDB, Yugabyte, Salesforce, etc.  \nAlso, we support flat files as databases: CSV, XLSX, Json, XML, Parquet.  \nYou can find the list of all databases supported in commercial versions <a href=\"https://dbeaver.com/databases/\">here</a>.\n\n## Feedback\n\n- For bug reports and feature requests - please <a href=\"https://github.com/dbeaver/dbeaver/issues\">create a ticket</a>.\n- To promote <a href=\"https://github.com/dbeaver/dbeaver/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc+label%3A%22wait+for+votes%22\">a ticket</a> to a higher priority - please vote for it with ğŸ‘ under the ticket description.\n- If you have any questions, ideas, etc - please <a href=\"https://github.com/dbeaver/dbeaver/discussions\">start a discussion</a>.\n- Pull requests are welcome. See our <a href=\"https://github.com/dbeaver/dbeaver/wiki/Contribute-your-code\">guide for contributors</a>.\n- Visit https://dbeaver.com for more information.\n- Follow us on [X](https://x.com/dbeaver_news/) and watch educational video on [YouTube](https://www.youtube.com/@DBeaver_video)\n- Thanks for using DBeaver! Star if you like it.\n\n## Contribution: help the Beaver!\n\nHooray, we have reached 40k+ stars on GitHub and continue to grow!  \nThat's really cool, and we are glad that you like DBeaver.\n\n- We are actively looking for new source code contributors. We have added labels â€œGood first issueâ€ and â€œHelp wantedâ€ to some tickets. If you want to be a part of our development team, just be brave and take a ticket. <a href=\"https://dbeaver.com/help-dbeaver/\">We are happy to reward</a> our most active contributors every major sprint.\n- You can buy <a href=\"https://dbeaver.com/buy/\">one of our commercial versions</a>. They include NoSQL databases support, additional extensions, and official online support. Also, licensed users have priorities in bug fixes and the development of new features.\n\nThank you!  \n\n- <a href=\"https://github.com/dbeaver/dbeaver/graphs/contributors\">DBeaver Team</a> (contributors)\n\n---------\n\n<a href=\"https://github.com/dbeaver/cloudbeaver/\"><img src=\"https://github.com/dbeaver/cloudbeaver/wiki/images/cloudbeaver-logo.png\" width=\"250\"/></a>\n\n<a href=\"https://github.com/dbeaver/cloudbeaver\">CloudBeaver</a> is a web-based database management tool built on the DBeaver platform. It brings the capabilities of DBeaver to the web interface, enabling database management from any device with an internet connection and eliminating the need for local installation.   \nSupporting any database, CloudBeaver incorporates most of DBeaver's features and includes advanced access management for secure collaboration.    \nDesigned with a user-friendly interface, CloudBeaver simplifies complex database operations and is suitable for both individual developers and organizations. Its scalable architecture accommodates various needs, making it a convenient solution for managing databases anytime and anywhere through web-based accessibility.\n",
      "stars_today": 20
    },
    {
      "id": 953142807,
      "name": "chatjs",
      "full_name": "FranciscoMoretti/chatjs",
      "description": "Production-ready AI chat template. Start here and make it your own. Formerly Sparka AI",
      "html_url": "https://github.com/FranciscoMoretti/chatjs",
      "stars": 1104,
      "forks": 109,
      "language": "TypeScript",
      "topics": [
        "ai",
        "anthropic",
        "chat",
        "chatbot",
        "chatgpt",
        "claude",
        "gemini",
        "gemini-ai",
        "grok",
        "llm",
        "multiprovider",
        "openai",
        "xai"
      ],
      "created_at": "2025-03-22T17:04:17Z",
      "updated_at": "2026-02-07T01:16:54Z",
      "pushed_at": "2026-02-06T19:03:52Z",
      "open_issues": 5,
      "owner": {
        "login": "FranciscoMoretti",
        "avatar_url": "https://avatars.githubusercontent.com/u/16997807?v=4"
      },
      "readme": "<div align=\"center\">\n\n<img src=\"app/icon.svg\" alt=\"ChatJS\" width=\"64\" height=\"64\">\n\n# ChatJS\n\nStop rebuilding the same AI chat infrastructure. ChatJS gives you a production-ready foundation with authentication, 120+ models, streaming, and tools so you can focus on what makes your app unique.\n\n[**Documentation**](https://chatjs.dev/docs) Â· [**Live Demo**](https://chatjs.dev)\n\n![DemosOnly](https://github.com/user-attachments/assets/f12e89dd-c10c-4e06-9b1a-a9fbd809d234)\n\n</div>\n\n<br />\n\n## Features\n\n- **120+ Models**: Claude, GPT, Gemini, Grok via one API\n- **Auth**: GitHub, Google, anonymous. Ready to go.\n- **Attachments**: Images, PDFs, docs. Drag and drop.\n- **Resumable Streams**: Continue generation after page refresh\n- **Branching**: Fork conversations, explore alternatives\n- **Sharing**: Share conversations with public links\n- **Web Search**: Real-time web search integration\n- **Image Generation**: AI-powered image creation\n- **Code Execution**: Run code snippets in sandbox\n- **MCP**: Model Context Protocol support\n\n## Stack\n\n- [Next.js](https://nextjs.org) - App Router, React Server Components\n- [TypeScript](https://www.typescriptlang.org) - Full type safety\n- [AI SDK](https://ai-sdk.dev/) - The AI Toolkit for TypeScript\n- [AI Gateway](https://vercel.com/ai-gateway) - Unified access to 120+ AI models\n- [Better Auth](https://www.better-auth.com) - Authentication & authorization\n- [Drizzle ORM](https://orm.drizzle.team) - Type-safe database queries\n- [PostgreSQL](https://www.postgresql.org) - Primary database\n- [Redis](https://redis.io) - Caching & resumable streams\n- [Vercel Blob](https://vercel.com/storage/blob) - Blob storage\n- [Shadcn/UI](https://ui.shadcn.com) - Beautiful, accessible components\n- [Tailwind CSS](https://tailwindcss.com) - Styling\n- [tRPC](https://trpc.io) - End-to-end type-safe APIs\n- [Zod](https://zod.dev) - Schema validation\n- [Zustand](https://docs.pmnd.rs/zustand) - State management\n- [Motion](https://motion.dev) - Animations\n- [t3-env](https://env.t3.gg) - Environment variables\n- [Pino](https://getpino.io) - Structured Logging\n- [Langfuse](https://langfuse.com) - LLM observability & analytics\n- [Vercel Analytics](https://vercel.com/analytics) - Web analytics\n- [Biome](https://biomejs.dev) - Code linting and formatting\n- [Ultracite](https://ultracite.ai) - Biome preset for humans and AI\n- [Streamdown](https://streamdown.ai/) - Markdown for AI streaming\n- [AI Elements](https://ai-sdk.dev/elements/overview) - AI-native Components\n- [AI SDK Tools](https://ai-sdk-tools.dev/) - Developer tools for AI SDK\n\n\n## Documentation\n\nVisit [chatjs.dev/docs](https://chatjs.dev/docs) to view the documentation.\n\n## License\n\nApache-2.0\n\n<br />\n<a href=\"https://vercel.com/oss\">\n  <img alt=\"Vercel OSS Program\" src=\"https://vercel.com/oss/program-badge.svg\" />\n</a>\n<br />\n",
      "stars_today": 20
    },
    {
      "id": 8859474,
      "name": "jadx",
      "full_name": "skylot/jadx",
      "description": "Dex to Java decompiler",
      "html_url": "https://github.com/skylot/jadx",
      "stars": 47211,
      "forks": 5422,
      "language": "Java",
      "topics": [
        "android",
        "decompiler",
        "dex",
        "java"
      ],
      "created_at": "2013-03-18T17:08:21Z",
      "updated_at": "2026-02-07T02:05:01Z",
      "pushed_at": "2026-02-04T20:29:16Z",
      "open_issues": 420,
      "owner": {
        "login": "skylot",
        "avatar_url": "https://avatars.githubusercontent.com/u/118523?v=4"
      },
      "readme": "<img src=\"https://raw.githubusercontent.com/skylot/jadx/master/jadx-gui/src/main/resources/logos/jadx-logo.png\" width=\"64\" align=\"left\" />\n\n## JADX\n\n![Build status](https://img.shields.io/github/actions/workflow/status/skylot/jadx/build-artifacts.yml)\n![GitHub contributors](https://img.shields.io/github/contributors/skylot/jadx)\n![GitHub all releases](https://img.shields.io/github/downloads/skylot/jadx/total)\n![GitHub release (latest by SemVer)](https://img.shields.io/github/downloads/skylot/jadx/latest/total)\n![Latest release](https://img.shields.io/github/release/skylot/jadx.svg)\n[![Maven Central](https://img.shields.io/maven-central/v/io.github.skylot/jadx-core)](https://search.maven.org/search?q=g:io.github.skylot%20AND%20jadx)\n![Java 11+](https://img.shields.io/badge/Java-11%2B-blue)\n[![License](http://img.shields.io/:license-apache-blue.svg)](http://www.apache.org/licenses/LICENSE-2.0.html)\n\n**jadx** - Dex to Java decompiler\n\nCommand line and GUI tools for producing Java source code from Android Dex and Apk files\n\n> [!WARNING]\n> Please note that in most cases **jadx** can't decompile all 100% of the code, so errors will occur.<br />\n> Check [Troubleshooting guide](https://github.com/skylot/jadx/wiki/Troubleshooting-Q&A#decompilation-issues) for workarounds.\n\n**Main features:**\n- decompile Dalvik bytecode to Java code from APK, dex, aar, aab and zip files\n- decode `AndroidManifest.xml` and other resources from `resources.arsc`\n- deobfuscator included\n\n**jadx-gui features:**\n- view decompiled code with highlighted syntax\n- jump to declaration\n- find usage\n- full text search\n- smali debugger, check [wiki page](https://github.com/skylot/jadx/wiki/Smali-debugger) for setup and usage\n\nJadx-gui key bindings can be found [here](https://github.com/skylot/jadx/wiki/JADX-GUI-Key-bindings)\n\nSee these features in action here: [jadx-gui features overview](https://github.com/skylot/jadx/wiki/jadx-gui-features-overview)\n\n<img src=\"https://user-images.githubusercontent.com/118523/142730720-839f017e-38db-423e-b53f-39f5f0a0316f.png\" width=\"700\"/>\n\n### Download\n- release\n  from [github: ![Latest release](https://img.shields.io/github/release/skylot/jadx.svg)](https://github.com/skylot/jadx/releases/latest)\n- latest [unstable build ![GitHub commits since tagged version (branch)](https://img.shields.io/github/commits-since/skylot/jadx/latest/master)](https://nightly.link/skylot/jadx/workflows/build-artifacts/master)\n\nAfter download unpack zip file go to `bin` directory and run:\n- `jadx` - command line version\n- `jadx-gui` - UI version\n\nOn Windows run `.bat` files with double-click\\\n**Note:** ensure you have installed Java 11 or later 64-bit version.\nFor Windows, you can download it from [oracle.com](https://www.oracle.com/java/technologies/downloads/#jdk17-windows) (select x64 Installer).\n\n### Install\n- Arch Linux\n  [![Arch Linux package](https://img.shields.io/archlinux/v/extra/any/jadx)](https://archlinux.org/packages/extra/any/jadx/)\n  [![AUR Version](https://img.shields.io/aur/version/jadx-git)](https://aur.archlinux.org/packages/jadx-git)\n  ```bash\n  sudo pacman -S jadx\n  ```\n- macOS\n  [![homebrew version](https://img.shields.io/homebrew/v/jadx)](https://formulae.brew.sh/formula/jadx)\n  ```bash\n  brew install jadx\n  ```\n- Flathub\n  [![Flathub Version](https://img.shields.io/flathub/v/com.github.skylot.jadx)](https://flathub.org/apps/com.github.skylot.jadx)\n  ```bash\n  flatpak install flathub com.github.skylot.jadx\n  ```\n\n### Use jadx as a library\nYou can use jadx in your java projects, check details on [wiki page](https://github.com/skylot/jadx/wiki/Use-jadx-as-a-library)\n\n### Build from source\nJDK 11 or higher must be installed:\n```\ngit clone https://github.com/skylot/jadx.git\ncd jadx\n./gradlew dist\n```\n\n(on Windows, use `gradlew.bat` instead of `./gradlew`)\n\nScripts for run jadx will be placed in `build/jadx/bin`\nand also packed to `build/jadx-<version>.zip`\n\n### Usage\n```\njadx[-gui] [command] [options] <input files> (.apk, .dex, .jar, .class, .smali, .zip, .aar, .arsc, .aab, .xapk, .apkm, .jadx.kts)\ncommands (use '<command> --help' for command options):\n  plugins\t  - manage jadx plugins\n\noptions:\n  -d, --output-dir                              - output directory\n  -ds, --output-dir-src                         - output directory for sources\n  -dr, --output-dir-res                         - output directory for resources\n  -r, --no-res                                  - do not decode resources\n  -s, --no-src                                  - do not decompile source code\n  -j, --threads-count                           - processing threads count, default: 16\n  --single-class                                - decompile a single class, full name, raw or alias\n  --single-class-output                         - file or dir for write if decompile a single class\n  --output-format                               - can be 'java' or 'json', default: java\n  -e, --export-gradle                           - save as gradle project (set '--export-gradle-type' to 'auto')\n  --export-gradle-type                          - Gradle project template for export:\n                                                   'auto' - detect automatically\n                                                   'android-app' - Android Application (apk)\n                                                   'android-library' - Android Library (aar)\n                                                   'simple-java' - simple Java\n  -m, --decompilation-mode                      - code output mode:\n                                                   'auto' - trying best options (default)\n                                                   'restructure' - restore code structure (normal java code)\n                                                   'simple' - simplified instructions (linear, with goto's)\n                                                   'fallback' - raw instructions without modifications\n  --show-bad-code                               - show inconsistent code (incorrectly decompiled)\n  --no-xml-pretty-print                         - do not prettify XML\n  --no-imports                                  - disable use of imports, always write entire package name\n  --no-debug-info                               - disable debug info parsing and processing\n  --add-debug-lines                             - add comments with debug line numbers if available\n  --no-inline-anonymous                         - disable anonymous classes inline\n  --no-inline-methods                           - disable methods inline\n  --no-move-inner-classes                       - disable move inner classes into parent\n  --no-inline-kotlin-lambda                     - disable inline for Kotlin lambdas\n  --no-finally                                  - don't extract finally block\n  --no-restore-switch-over-string               - don't restore switch over string\n  --no-replace-consts                           - don't replace constant value with matching constant field\n  --escape-unicode                              - escape non latin characters in strings (with \\u)\n  --respect-bytecode-access-modifiers           - don't change original access modifiers\n  --mappings-path                               - deobfuscation mappings file or directory. Allowed formats: Tiny and Tiny v2 (both '.tiny'), Enigma (.mapping) or Enigma directory\n  --mappings-mode                               - set mode for handling the deobfuscation mapping file:\n                                                   'read' - just read, user can always save manually (default)\n                                                   'read-and-autosave-every-change' - read and autosave after every change\n                                                   'read-and-autosave-before-closing' - read and autosave before exiting the app or closing the project\n                                                   'ignore' - don't read or save (can be used to skip loading mapping files referenced in the project file)\n  --deobf                                       - activate deobfuscation\n  --deobf-min                                   - min length of name, renamed if shorter, default: 3\n  --deobf-max                                   - max length of name, renamed if longer, default: 64\n  --deobf-whitelist                             - space separated list of classes (full name) and packages (ends with '.*') to exclude from deobfuscation, default: android.support.v4.* android.support.v7.* android.support.v4.os.* android.support.annotation.Px androidx.core.os.* androidx.annotation.Px\n  --deobf-cfg-file                              - deobfuscation mappings file used for JADX auto-generated names (in the JOBF file format), default: same dir and name as input file with '.jobf' extension\n  --deobf-cfg-file-mode                         - set mode for handling the JADX auto-generated names' deobfuscation map file:\n                                                   'read' - read if found, don't save (default)\n                                                   'read-or-save' - read if found, save otherwise (don't overwrite)\n                                                   'overwrite' - don't read, always save\n                                                   'ignore' - don't read and don't save\n  --deobf-res-name-source                       - better name source for resources:\n                                                   'auto' - automatically select best name (default)\n                                                   'resources' - use resources names\n                                                   'code' - use R class fields names\n  --use-source-name-as-class-name-alias         - use source name as class name alias:\n                                                   'always' - always use source name if it's available\n                                                   'if-better' - use source name if it seems better than the current one\n                                                   'never' - never use source name, even if it's available\n  --source-name-repeat-limit                    - allow using source name if it appears less than a limit number, default: 10\n  --use-kotlin-methods-for-var-names            - use kotlin intrinsic methods to rename variables, values: disable, apply, apply-and-hide, default: apply\n  --use-headers-for-detect-resource-extensions  - Use headers for detect resource extensions if resource obfuscated\n  --rename-flags                                - fix options (comma-separated list of):\n                                                   'case' - fix case sensitivity issues (according to --fs-case-sensitive option),\n                                                   'valid' - rename java identifiers to make them valid,\n                                                   'printable' - remove non-printable chars from identifiers,\n                                                  or single 'none' - to disable all renames\n                                                  or single 'all' - to enable all (default)\n  --integer-format                              - how integers are displayed:\n                                                   'auto' - automatically select (default)\n                                                   'decimal' - use decimal\n                                                   'hexadecimal' - use hexadecimal\n  --type-update-limit                           - type update limit count (per one instruction), default: 10\n  --fs-case-sensitive                           - treat filesystem as case sensitive, false by default\n  --cfg                                         - save methods control flow graph to dot file\n  --raw-cfg                                     - save methods control flow graph (use raw instructions)\n  -f, --fallback                                - set '--decompilation-mode' to 'fallback' (deprecated)\n  --use-dx                                      - use dx/d8 to convert java bytecode\n  --comments-level                              - set code comments level, values: error, warn, info, debug, user-only, none, default: info\n  --log-level                                   - set log level, values: quiet, progress, error, warn, info, debug, default: progress\n  -v, --verbose                                 - verbose output (set --log-level to DEBUG)\n  -q, --quiet                                   - turn off output (set --log-level to QUIET)\n  --disable-plugins                             - comma separated list of plugin ids to disable\n  --config <config-ref>                         - load configuration from file, <config-ref> can be:\n                                                   path to '.json' file\n                                                   short name - uses file with this name from config directory\n                                                   'none' - to disable config loading\n  --save-config <config-ref>                    - save current options into configuration file and exit, <config-ref> can be:\n                                                   empty - for default config\n                                                   path to '.json' file\n                                                   short name - file will be saved in config directory\n  --print-files                                 - print files and directories used by jadx (config, cache, temp)\n  --version                                     - print jadx version\n  -h, --help                                    - print this help\n\nPlugin options (-P<name>=<value>):\n  dex-input: Load .dex and .apk files\n    - dex-input.verify-checksum                 - verify dex file checksum before load, values: [yes, no], default: yes\n  java-convert: Convert .class, .jar and .aar files to dex\n    - java-convert.mode                         - convert mode, values: [dx, d8, both], default: both\n    - java-convert.d8-desugar                   - use desugar in d8, values: [yes, no], default: no\n  kotlin-metadata: Use kotlin.Metadata annotation for code generation\n    - kotlin-metadata.class-alias               - rename class alias, values: [yes, no], default: yes\n    - kotlin-metadata.method-args               - rename function arguments, values: [yes, no], default: yes\n    - kotlin-metadata.fields                    - rename fields, values: [yes, no], default: yes\n    - kotlin-metadata.companion                 - rename companion object, values: [yes, no], default: yes\n    - kotlin-metadata.data-class                - add data class modifier, values: [yes, no], default: yes\n    - kotlin-metadata.to-string                 - rename fields using toString, values: [yes, no], default: yes\n    - kotlin-metadata.getters                   - rename simple getters to field names, values: [yes, no], default: yes\n  kotlin-smap: Use kotlin.SourceDebugExtension annotation for rename class alias\n    - kotlin-smap.class-alias-source-dbg        - rename class alias from SourceDebugExtension, values: [yes, no], default: no\n  rename-mappings: various mappings support\n    - rename-mappings.format                    - mapping format, values: [AUTO, TINY_FILE, TINY_2_FILE, ENIGMA_FILE, ENIGMA_DIR, PROGUARD_FILE, SRG_FILE, XSRG_FILE, JAM_FILE, CSRG_FILE, TSRG_FILE, TSRG_2_FILE, INTELLIJ_MIGRATION_MAP_FILE, RECAF_SIMPLE_FILE, JOBF_FILE], default: AUTO\n    - rename-mappings.invert                    - invert mapping on load, values: [yes, no], default: no\n  smali-input: Load .smali files\n    - smali-input.api-level                     - Android API level, default: 27\n\nEnvironment variables:\n  JADX_DISABLE_XML_SECURITY - set to 'true' to disable all security checks for XML files\n  JADX_DISABLE_ZIP_SECURITY - set to 'true' to disable all security checks for zip files\n  JADX_ZIP_MAX_ENTRIES_COUNT - maximum allowed number of entries in zip files (default: 100 000)\n  JADX_CONFIG_DIR - custom config directory, using system by default\n  JADX_CACHE_DIR - custom cache directory, using system by default\n  JADX_TMP_DIR - custom temp directory, using system by default\n\nExamples:\n  jadx -d out classes.dex\n  jadx --rename-flags \"none\" classes.dex\n  jadx --rename-flags \"valid, printable\" classes.dex\n  jadx --log-level ERROR app.apk\n  jadx -Pdex-input.verify-checksum=no app.apk\n```\nThese options also work in jadx-gui running from command line and override options from preferences' dialog\n\nUsage for `plugins` command\n```\nusage: plugins [options]\noptions:\n  -i, --install <locationId>      - install plugin with locationId\n  -j, --install-jar <path-to.jar> - install plugin from jar file\n  -l, --list                      - list installed plugins\n  -a, --available                 - list available plugins from jadx-plugins-list (aka marketplace)\n  -u, --update                    - update installed plugins\n  --uninstall <pluginId>          - uninstall plugin with pluginId\n  --disable <pluginId>            - disable plugin with pluginId\n  --enable <pluginId>             - enable plugin with pluginId\n  --list-all                      - list all plugins including bundled and dropins\n  --list-versions <locationId>    - fetch latest versions of plugin from locationId (will download all artefacts, limited to 10)\n  -h, --help                      - print this help\n```\n\n\n### Troubleshooting\nPlease check wiki page [Troubleshooting Q&A](https://github.com/skylot/jadx/wiki/Troubleshooting-Q&A)\n\n### Contributing\nTo support this project you can:\n  - Post thoughts about new features/optimizations that important to you\n  - Submit decompilation issues, please read before proceed: [Open issue](CONTRIBUTING.md#Open-Issue)\n  - Open pull request, please follow these rules: [Pull Request Process](CONTRIBUTING.md#Pull-Request-Process)\n\n---------------------------------------\n*Licensed under the Apache 2.0 License*\n",
      "stars_today": 18
    },
    {
      "id": 299354666,
      "name": "rustdesk-server",
      "full_name": "rustdesk/rustdesk-server",
      "description": "RustDesk Server Program",
      "html_url": "https://github.com/rustdesk/rustdesk-server",
      "stars": 9317,
      "forks": 2190,
      "language": "Rust",
      "topics": [
        "remote-access",
        "remote-control",
        "remote-desktop",
        "tauri"
      ],
      "created_at": "2020-09-28T15:37:59Z",
      "updated_at": "2026-02-06T23:28:31Z",
      "pushed_at": "2026-01-13T02:26:46Z",
      "open_issues": 157,
      "owner": {
        "login": "rustdesk",
        "avatar_url": "https://avatars.githubusercontent.com/u/71636191?v=4"
      },
      "readme": "# RustDesk Server Program\n\n[![build](https://github.com/rustdesk/rustdesk-server/actions/workflows/build.yaml/badge.svg)](https://github.com/rustdesk/rustdesk-server/actions/workflows/build.yaml)\n\n[**Download**](https://github.com/rustdesk/rustdesk-server/releases)\n\n[**Manual**](https://rustdesk.com/docs/en/self-host/)\n\n[**FAQ**](https://github.com/rustdesk/rustdesk/wiki/FAQ)\n\n[**How to migrate OSS to Pro**](https://rustdesk.com/docs/en/self-host/rustdesk-server-pro/installscript/#convert-from-open-source)\n\nSelf-host your own RustDesk server, it is free and open source.\n\n## How to build manually\n\n```bash\ncargo build --release\n```\n\nThree executables will be generated in target/release.\n\n- hbbs - RustDesk ID/Rendezvous server\n- hbbr - RustDesk relay server\n- rustdesk-utils - RustDesk CLI utilities\n\nYou can find updated binaries on the [Releases](https://github.com/rustdesk/rustdesk-server/releases) page.\n\nIf you want extra features, [RustDesk Server Pro](https://rustdesk.com/pricing.html) might suit you better.\n\nIf you want to develop your own server, [rustdesk-server-demo](https://github.com/rustdesk/rustdesk-server-demo) might be a better and simpler start for you than this repo.\n\n## Installation\n\nPlease follow this [doc](https://rustdesk.com/docs/en/self-host/rustdesk-server-oss/)\n",
      "stars_today": 18
    },
    {
      "id": 59771425,
      "name": "zephyr",
      "full_name": "zephyrproject-rtos/zephyr",
      "description": "Primary Git Repository for the Zephyr Project. Zephyr is a new generation, scalable, optimized, secure RTOS for multiple hardware architectures.",
      "html_url": "https://github.com/zephyrproject-rtos/zephyr",
      "stars": 14395,
      "forks": 8616,
      "language": "C",
      "topics": [
        "bluetooth",
        "bluetooth-le",
        "embedded",
        "embedded-c",
        "iot",
        "mcu",
        "microcontroller",
        "real-time",
        "rtos",
        "zephyr",
        "zephyr-rtos",
        "zephyros"
      ],
      "created_at": "2016-05-26T17:54:19Z",
      "updated_at": "2026-02-07T00:43:15Z",
      "pushed_at": "2026-02-06T21:24:23Z",
      "open_issues": 3474,
      "owner": {
        "login": "zephyrproject-rtos",
        "avatar_url": "https://avatars.githubusercontent.com/u/19595895?v=4"
      },
      "readme": ".. raw:: html\n\n   <a href=\"https://www.zephyrproject.org\">\n     <p align=\"center\">\n       <picture>\n         <source media=\"(prefers-color-scheme: dark)\" srcset=\"doc/_static/images/logo-readme-dark.svg\">\n         <source media=\"(prefers-color-scheme: light)\" srcset=\"doc/_static/images/logo-readme-light.svg\">\n         <img src=\"doc/_static/images/logo-readme-light.svg\">\n       </picture>\n     </p>\n   </a>\n\n   <a href=\"https://bestpractices.coreinfrastructure.org/projects/74\"><img src=\"https://bestpractices.coreinfrastructure.org/projects/74/badge\"></a>\n   <a href=\"https://scorecard.dev/viewer/?uri=github.com/zephyrproject-rtos/zephyr\"><img src=\"https://api.securityscorecards.dev/projects/github.com/zephyrproject-rtos/zephyr/badge\"></a>\n   <a href=\"https://github.com/zephyrproject-rtos/zephyr/actions/workflows/twister.yaml?query=branch%3Amain\"><img src=\"https://github.com/zephyrproject-rtos/zephyr/actions/workflows/twister.yaml/badge.svg?event=push\"></a>\n\n\nThe Zephyr Project is a scalable real-time operating system (RTOS) supporting\nmultiple hardware architectures, optimized for resource constrained devices,\nand built with security in mind.\n\nThe Zephyr OS is based on a small-footprint kernel designed for use on\nresource-constrained systems: from simple embedded environmental sensors and\nLED wearables to sophisticated smart watches and IoT wireless gateways.\n\nThe Zephyr kernel supports multiple architectures, including ARM (Cortex-A,\nCortex-R, Cortex-M), Intel x86, ARC, Tensilica Xtensa, and RISC-V,\nSPARC, MIPS, and a large number of `supported boards`_.\n\n.. below included in doc/introduction/introduction.rst\n\n\nGetting Started\n***************\n\nWelcome to Zephyr! See the `Introduction to Zephyr`_ for a high-level overview,\nand the documentation's `Getting Started Guide`_ to start developing.\n\n.. start_include_here\n\nCommunity Support\n*****************\n\nCommunity support is provided via mailing lists and Discord; see the Resources\nbelow for details.\n\n.. _project-resources:\n\nResources\n*********\n\nHere's a quick summary of resources to help you find your way around:\n\nGetting Started\n---------------\n\n  | ğŸ“– `Zephyr Documentation`_\n  | ğŸš€ `Getting Started Guide`_\n  | ğŸ™‹ğŸ½ `Tips when asking for help`_\n  | ğŸ’» `Code samples`_\n\nCode and Development\n--------------------\n\n  | ğŸŒ `Source Code Repository`_\n  | ğŸ“¦ `Releases`_\n  | ğŸ¤ `Contribution Guide`_\n\nCommunity and Support\n---------------------\n\n  | ğŸ’¬ `Discord Server`_ for real-time community discussions\n  | ğŸ“§ `User mailing list (users@lists.zephyrproject.org)`_\n  | ğŸ“§ `Developer mailing list (devel@lists.zephyrproject.org)`_\n  | ğŸ“¬ `Other project mailing lists`_\n  | ğŸ“š `Project Wiki`_\n\nIssue Tracking and Security\n---------------------------\n\n  | ğŸ› `GitHub Issues`_\n  | ğŸ”’ `Security documentation`_\n  | ğŸ›¡ï¸ `Security Advisories Repository`_\n  | âš ï¸ Report security vulnerabilities at vulnerabilities@zephyrproject.org\n\nAdditional Resources\n--------------------\n  | ğŸŒ `Zephyr Project Website`_\n  | ğŸ“º `Zephyr Tech Talks`_\n\n.. _Zephyr Project Website: https://www.zephyrproject.org\n.. _Discord Server: https://chat.zephyrproject.org\n.. _supported boards: https://docs.zephyrproject.org/latest/boards/index.html\n.. _Zephyr Documentation: https://docs.zephyrproject.org\n.. _Introduction to Zephyr: https://docs.zephyrproject.org/latest/introduction/index.html\n.. _Getting Started Guide: https://docs.zephyrproject.org/latest/develop/getting_started/index.html\n.. _Contribution Guide: https://docs.zephyrproject.org/latest/contribute/index.html\n.. _Source Code Repository: https://github.com/zephyrproject-rtos/zephyr\n.. _GitHub Issues: https://github.com/zephyrproject-rtos/zephyr/issues\n.. _Releases: https://github.com/zephyrproject-rtos/zephyr/releases\n.. _Project Wiki: https://github.com/zephyrproject-rtos/zephyr/wiki\n.. _User mailing list (users@lists.zephyrproject.org): https://lists.zephyrproject.org/g/users\n.. _Developer mailing list (devel@lists.zephyrproject.org): https://lists.zephyrproject.org/g/devel\n.. _Other project mailing lists: https://lists.zephyrproject.org/g/main/subgroups\n.. _Code samples: https://docs.zephyrproject.org/latest/samples/index.html\n.. _Security documentation: https://docs.zephyrproject.org/latest/security/index.html\n.. _Security Advisories Repository: https://github.com/zephyrproject-rtos/zephyr/security\n.. _Tips when asking for help: https://docs.zephyrproject.org/latest/develop/getting_started/index.html#asking-for-help\n.. _Zephyr Tech Talks: https://www.zephyrproject.org/tech-talks\n",
      "stars_today": 17
    },
    {
      "id": 326404870,
      "name": "signoz",
      "full_name": "SigNoz/signoz",
      "description": "SigNoz is an open-source observability platform native to OpenTelemetry with logs, traces and metrics in a single application. An open-source alternative to DataDog, NewRelic, etc. ğŸ”¥ ğŸ–¥.   ğŸ‘‰  Open source Application Performance Monitoring (APM) & Observability tool",
      "html_url": "https://github.com/SigNoz/signoz",
      "stars": 25612,
      "forks": 1941,
      "language": "TypeScript",
      "topics": [
        "apm",
        "application-monitoring",
        "distributed-tracing",
        "go",
        "good-first-issue",
        "jaeger",
        "log",
        "logs",
        "metrics",
        "monitoring",
        "nextjs",
        "observability",
        "open-source",
        "opentelemetry",
        "prometheus",
        "react",
        "reactjs",
        "self-hosted",
        "tracing",
        "typescript"
      ],
      "created_at": "2021-01-03T12:44:36Z",
      "updated_at": "2026-02-07T02:11:37Z",
      "pushed_at": "2026-02-06T21:52:05Z",
      "open_issues": 1542,
      "owner": {
        "login": "SigNoz",
        "avatar_url": "https://avatars.githubusercontent.com/u/76905799?v=4"
      },
      "readme": "<h1 align=\"center\" style=\"border-bottom: none\">\n    <a href=\"https://signoz.io\" target=\"_blank\">\n        <img alt=\"SigNoz\" src=\"https://github.com/user-attachments/assets/ef9a33f7-12d7-4c94-8908-0a02b22f0c18\" width=\"100\" height=\"100\">\n    </a>\n    <br>SigNoz\n</h1>\n\n<p align=\"center\">All your logs, metrics, and traces in one place. Monitor your application, spot issues before they occur and troubleshoot downtime quickly with rich context. SigNoz is a cost-effective open-source alternative to Datadog and New Relic. Visit <a href=\"https://signoz.io\" target=\"_blank\">signoz.io</a> for the full documentation, tutorials, and guide.</p>\n\n<p align=\"center\">\n    <img alt=\"GitHub issues\" src=\"https://img.shields.io/github/issues/signoz/signoz\"> </a>\n    <a href=\"https://twitter.com/intent/tweet?text=Monitor%20your%20applications%20and%20troubleshoot%20problems%20with%20SigNoz,%20an%20open-source%20alternative%20to%20DataDog,%20NewRelic.&url=https://signoz.io/&via=SigNozHQ&hashtags=opensource,signoz,observability\"> \n        <img alt=\"tweet\" src=\"https://img.shields.io/twitter/url/http/shields.io.svg?style=social\"> </a> \n</p>\n  \n  \n<h3 align=\"center\">\n  <a href=\"https://signoz.io/docs\"><b>Documentation</b></a> &bull;\n  <a href=\"https://github.com/SigNoz/signoz/blob/main/README.zh-cn.md\"><b>ReadMe in Chinese</b></a> &bull;\n  <a href=\"https://github.com/SigNoz/signoz/blob/main/README.de-de.md\"><b>ReadMe in German</b></a> &bull;\n  <a href=\"https://github.com/SigNoz/signoz/blob/main/README.pt-br.md\"><b>ReadMe in Portuguese</b></a> &bull;\n  <a href=\"https://signoz.io/slack\"><b>Slack Community</b></a> &bull;\n  <a href=\"https://twitter.com/SigNozHq\"><b>Twitter</b></a>\n</h3>\n\n## Features\n\n\n### Application Performance Monitoring\n\nUse SigNoz APM to monitor your applications and services. It comes with out-of-box charts for key application metrics like p99 latency, error rate, Apdex and operations per second. You can also monitor the database and external calls made from your application. Read [more](https://signoz.io/application-performance-monitoring/).\n\nYou can [instrument](https://signoz.io/docs/instrumentation/) your application with OpenTelemetry to get started.\n\n![apm-cover](https://github.com/user-attachments/assets/fa5c0396-0854-4c8b-b972-9b62fd2a70d2)\n\n\n### Logs Management\n\nSigNoz can be used as a centralized log management solution. We use ClickHouse (used by likes of Uber & Cloudflare) as a datastore, â¯ an extremely fast and highly optimized storage for logs data. Instantly search through all your logs using quick filters and a powerful query builder.\n\nYou can also create charts on your logs and monitor them with customized dashboards. Read [more](https://signoz.io/log-management/).\n\n![logs-management-cover](https://github.com/user-attachments/assets/343588ee-98fb-4310-b3d2-c5bacf9c7384)\n\n\n### Distributed Tracing\n\nDistributed Tracing is essential to troubleshoot issues in microservices applications. Powered by OpenTelemetry, distributed tracing in SigNoz can help you track user requests across services to help you identify performance bottlenecks. \n\nSee user requests in a detailed breakdown with the help of Flamegraphs and Gantt Charts. Click on any span to see the entire trace represented beautifully, which will help you make sense of where issues actually occurred in the flow of requests.\n\nRead [more](https://signoz.io/distributed-tracing/).\n\n![distributed-tracing-cover](https://github.com/user-attachments/assets/9bfe060a-0c40-4922-9b55-8a97e1a4076c)\n\n\n\n### Metrics and Dashboards\n\nIngest metrics from your infrastructure or applications and create customized dashboards to monitor them. Create visualization that suits your needs with a variety of panel types like pie chart, time-series, bar chart, etc.\n\nCreate queries on your metrics data quickly with an easy-to-use metrics query builder. Add multiple queries and combine those queries with formulae to create really complex queries quickly.\n\nRead [more](https://signoz.io/metrics-and-dashboards/).\n\n![metrics-n-dashboards-cover](https://github.com/user-attachments/assets/a536fd71-1d2c-4681-aa7e-516d754c47a5)\n\n### LLM Observability\n\nMonitor and debug your LLM applications with comprehensive observability. Track LLM calls, analyze token usage, monitor performance, and gain insights into your AI application's behavior in production.\n\nSigNoz LLM observability helps you understand how your language models are performing, identify issues with prompts and responses, track token usage and costs, and optimize your AI applications for better performance and reliability.\n\n[Get started with LLM Observability â†’](https://signoz.io/docs/llm-observability/)\n\n![llm-observability-cover](https://github.com/user-attachments/assets/a6cc0ca3-59df-48f9-9c16-7c843fccff96)\n\n\n### Alerts\n\nUse alerts in SigNoz to get notified when anything unusual happens in your application. You can set alerts on any type of telemetry signal (logs, metrics, traces), create thresholds and set up a notification channel to get notified. Advanced features like alert history and anomaly detection can help you create smarter alerts.\n\nAlerts in SigNoz help you identify issues proactively so that you can address them before they reach your customers.\n\nRead [more](https://signoz.io/alerts-management/).\n\n![alerts-cover](https://github.com/user-attachments/assets/03873bb8-1b62-4adf-8f56-28bb7b1750ea)\n\n### Exceptions Monitoring\n\nMonitor exceptions automatically in Python, Java, Ruby, and Javascript. For other languages, just drop in a few lines of code and start monitoring exceptions.\n\nSee the detailed stack trace for all exceptions caught in your application. You can also log in custom attributes to add more context to your exceptions. For example, you can add attributes to identify users for which exceptions occurred.\n\nRead [more](https://signoz.io/exceptions-monitoring/).\n\n\n![exceptions-cover](https://github.com/user-attachments/assets/4be37864-59f2-4e8a-8d6e-e29ad04298c5)\n\n\n<br /><br />\n\n## Why SigNoz?\n\nSigNoz is a single tool for all your monitoring and observability needs. Here are a few reasons why you should choose SigNoz:\n\n- Single tool for observability(logs, metrics, and traces)\n\n- Built on top of [OpenTelemetry](https://opentelemetry.io/), the open-source standard which frees you from any type of vendor lock-in\n\n- Correlated logs, metrics and traces for much richer context while debugging\n\n- Uses ClickHouse (used by likes of Uber & Cloudflare) as datastore - an extremely fast and highly optimized storage for observability data\n\n- DIY Query builder, PromQL, and ClickHouse queries to fulfill all your use-cases around querying observability data\n\n- Open-Source - you can use open-source, our [cloud service](https://signoz.io/teams/) or a mix of both based on your use case\n\n\n## Getting Started\n\n### Create a SigNoz Cloud Account\n\nSigNoz cloud is the easiest way to get started with SigNoz. Our cloud service is for those users who want to spend more time in getting insights for their application performance without worrying about maintenance. \n\n[Get started for free](https://signoz.io/teams/)\n\n### Deploy using Docker(self-hosted)\n\nPlease follow the steps listed [here](https://signoz.io/docs/install/docker/) to install using docker\n\nThe [troubleshooting instructions](https://signoz.io/docs/install/troubleshooting/) may be helpful if you face any issues.\n\n<p>&nbsp  </p>\n  \n  \n### Deploy in Kubernetes using Helm(self-hosted)\n\nPlease follow the steps listed [here](https://signoz.io/docs/deployment/helm_chart) to install using helm charts\n\n<br /><br />\n\nWe also offer managed services in your infra. Check our [pricing plans](https://signoz.io/pricing/) for all details.\n\n\n## Join our Slack community\n\nCome say Hi to us on [Slack](https://signoz.io/slack) ğŸ‘‹\n\n<br /><br />\n\n\n### Languages supported:\n\nSigNoz supports all major programming languages for monitoring. Any framework and language supported by OpenTelemetry is supported by SigNoz. Find instructions for instrumenting different languages below:\n\n- [Java](https://signoz.io/docs/instrumentation/java/)\n- [Python](https://signoz.io/docs/instrumentation/python/)\n- [Node.js or Javascript](https://signoz.io/docs/instrumentation/javascript/)\n- [Go](https://signoz.io/docs/instrumentation/golang/)\n- [PHP](https://signoz.io/docs/instrumentation/php/)\n- [.NET](https://signoz.io/docs/instrumentation/dotnet/)\n- [Ruby](https://signoz.io/docs/instrumentation/ruby-on-rails/)\n- [Elixir](https://signoz.io/docs/instrumentation/elixir/)\n- [Rust](https://signoz.io/docs/instrumentation/rust/)\n- [Swift](https://signoz.io/docs/instrumentation/swift/)\n\nYou can find our entire documentation [here](https://signoz.io/docs/introduction/).\n\n<br /><br />\n\n\n## Comparisons to Familiar Tools\n\n### SigNoz vs Prometheus\n\nPrometheus is good if you want to do just metrics. But if you want to have a seamless experience between metrics, logs and traces, then current experience of stitching together Prometheus & other tools is not great.\n\nSigNoz is a one-stop solution for metrics and other telemetry signals. And because you will use the same standard(OpenTelemetry) to collect all telemetry signals, you can also correlate these signals to troubleshoot quickly.\n\nFor example, if you see that there are issues with infrastructure metrics of your k8s cluster at a timestamp, you can jump to other signals like logs and traces to understand the issue quickly.\n\n<p>&nbsp  </p>\n\n### SigNoz vs Jaeger\n\nJaeger only does distributed tracing. SigNoz supports metrics, traces and logs - all the 3 pillars of observability.\n\nMoreover, SigNoz has few more advanced features wrt Jaeger:\n\n- Jaegar UI doesnâ€™t show any metrics on traces or on filtered traces\n- Jaeger canâ€™t get aggregates on filtered traces. For example, p99 latency of requests which have tag - customer_type='premium'. This can be done easily on SigNoz\n- You can also go from traces to logs easily in SigNoz\n\n<p>&nbsp  </p>\n\n### SigNoz vs Elastic \n\n- SigNoz Logs management are based on ClickHouse, a columnar OLAP datastore which makes aggregate log analytics queries much more efficient\n- 50% lower resource requirement compared to Elastic during ingestion\n\nWe have published benchmarks comparing Elastic with SigNoz. Check it out [here](https://signoz.io/blog/logs-performance-benchmark/?utm_source=github-readme&utm_medium=logs-benchmark)\n\n<p>&nbsp  </p>\n\n### SigNoz vs Loki\n\n- SigNoz supports aggregations on high-cardinality data over a huge volume while loki doesnâ€™t.\n- SigNoz supports indexes over high cardinality data and has no limitations on the number of indexes, while Loki reaches max streams with a few indexes added to it.\n- Searching over a huge volume of data is difficult and slow in Loki compared to SigNoz\n\nWe have published benchmarks comparing Loki with SigNoz. Check it out [here](https://signoz.io/blog/logs-performance-benchmark/?utm_source=github-readme&utm_medium=logs-benchmark)\n\n<br /><br />\n\n\n## Contributing\n\nWe â¤ï¸ contributions big or small. Please read [CONTRIBUTING.md](CONTRIBUTING.md) to get started with making contributions to SigNoz.\n\nNot sure how to get started? Just ping us on `#contributing` in our [slack community](https://signoz.io/slack)\n\n### Project maintainers\n\n#### Backend\n\n- [Ankit Nayan](https://github.com/ankitnayan)\n- [Nityananda Gohain](https://github.com/nityanandagohain)\n- [Srikanth Chekuri](https://github.com/srikanthccv)\n- [Vishal Sharma](https://github.com/makeavish)\n- [Shivanshu Raj Shrivastava](https://github.com/shivanshuraj1333)\n- [Ekansh Gupta](https://github.com/eKuG)\n- [Aniket Agarwal](https://github.com/aniketio-ctrl)\n\n#### Frontend\n\n- [Yunus M](https://github.com/YounixM)\n- [Vikrant Gupta](https://github.com/vikrantgupta25)\n- [Sagar Rajput](https://github.com/SagarRajput-7)\n- [Shaheer Kochai](https://github.com/ahmadshaheer)\n- [Amlan Kumar Nandy](https://github.com/amlannandy)\n- [Sahil Khan](https://github.com/sawhil)\n- [Aditya Singh](https://github.com/aks07)\n- [Abhi Kumar](https://github.com/ahrefabhi)\n\n#### DevOps\n\n- [Prashant Shahi](https://github.com/prashant-shahi)\n- [Vibhu Pandey](https://github.com/therealpandey)\n\n<br /><br />\n\n\n## Documentation\n\nYou can find docs at https://signoz.io/docs/. If you need any clarification or find something missing, feel free to raise a GitHub issue with the label `documentation` or reach out to us at the community slack channel.\n\n<br /><br />\n\n\n## Community\n\nJoin the [slack community](https://signoz.io/slack) to know more about distributed tracing, observability, or SigNoz and to connect with other users and contributors.\n\nIf you have any ideas, questions, or any feedback, please share on our [Github Discussions](https://github.com/SigNoz/signoz/discussions)\n\nAs always, thanks to our amazing contributors!\n\n<a href=\"https://github.com/signoz/signoz/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=signoz/signoz\" />\n</a>\n",
      "stars_today": 17
    },
    {
      "id": 1098533718,
      "name": "zapret2",
      "full_name": "bol-van/zapret2",
      "description": "anti-dpi software",
      "html_url": "https://github.com/bol-van/zapret2",
      "stars": 1465,
      "forks": 46,
      "language": "C",
      "topics": [
        "anti-dpi",
        "censorship-circumvention",
        "freebsd",
        "linux",
        "openbsd",
        "openwrt",
        "russian",
        "windows"
      ],
      "created_at": "2025-11-17T20:19:26Z",
      "updated_at": "2026-02-07T00:19:45Z",
      "pushed_at": "2026-02-06T14:16:49Z",
      "open_issues": 5,
      "owner": {
        "login": "bol-van",
        "avatar_url": "https://avatars.githubusercontent.com/u/9076680?v=4"
      },
      "readme": "## English\n\n[Manual](manual.en.md)\n\n## Ğ—Ğ°Ñ‡ĞµĞ¼ ÑÑ‚Ğ¾ Ğ½ÑƒĞ¶Ğ½Ğ¾\n\nĞĞ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾Ğµ ÑÑ€ĞµĞ´ÑÑ‚Ğ²Ğ¾ Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ DPI, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğµ Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ ĞºĞ°ĞºĞ¸Ñ…-Ğ»Ğ¸Ğ±Ğ¾ ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ğ½Ğ¸Ñ… ÑĞµÑ€Ğ²ĞµÑ€Ğ¾Ğ². ĞœĞ¾Ğ¶ĞµÑ‚ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‡ÑŒ\nĞ¾Ğ±Ğ¾Ğ¹Ñ‚Ğ¸ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²ĞºĞ¸ Ğ¸Ğ»Ğ¸ Ğ·Ğ°Ğ¼ĞµĞ´Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ°Ğ¹Ñ‚Ğ¾Ğ² HTTP(S), ÑĞ¸Ğ³Ğ½Ğ°Ñ‚ÑƒÑ€Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· TCP Ğ¸ UDP Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ»Ğ¾Ğ², Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Ñ Ñ†ĞµĞ»ÑŒÑ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²ĞºĞ¸\nVPN. ĞœĞ¾Ğ¶ĞµÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ Ğ´Ğ»Ñ Ñ‡Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ·Ñ€Ğ°Ñ‡Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ„ÑƒÑĞºĞ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ»Ğ¾Ğ².\n\nĞŸÑ€Ğ¾ĞµĞºÑ‚ Ğ½Ğ°Ñ†ĞµĞ»ĞµĞ½ Ğ¿Ñ€ĞµĞ¶Ğ´Ğµ Ğ²ÑĞµĞ³Ğ¾ Ğ½Ğ° Ğ¼Ğ°Ğ»Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ñ‹Ğµ embedded ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²Ğ° - Ñ€Ğ¾ÑƒÑ‚ĞµÑ€Ñ‹, Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‰Ğ¸Ğµ Ğ¿Ğ¾Ğ´ OpenWrt. ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ÑÑ‚ÑÑ\nÑ‚Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ Linux-ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹, FreeBSD, OpenBSD, Windows. Ğ’ Ğ½ĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… ÑĞ»ÑƒÑ‡Ğ°ÑÑ… Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ° ÑĞ°Ğ¼Ğ¾ÑÑ‚Ğ¾ÑÑ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ¿Ñ€Ğ¸ĞºÑ€ÑƒÑ‚ĞºĞ°\nÑ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğº Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼ Ğ¿Ñ€Ğ¾ÑˆĞ¸Ğ²ĞºĞ°Ğ¼.\n\n[ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¼Ğ°Ğ½ÑƒĞ°Ğ»](manual.md)\n\n\n## ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ°Ñ‚ÑŒ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ°. Donations\n\nĞ•ÑĞ»Ğ¸ Ğ²Ñ‹ ÑÑ‡Ğ¸Ñ‚Ğ°ĞµÑ‚Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğ¼ Ğ¸ Ğ¶ĞµĞ»Ğ°ĞµÑ‚Ğµ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ°Ñ‚ÑŒ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ, Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞ¹Ñ‚Ğµ Ğ²Ğ°ÑˆĞ¸ Ğ¿Ğ¾Ğ¶ĞµÑ€Ñ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ½Ğ° ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ Ğ°Ğ´Ñ€ĞµÑĞ° ĞºÑ€Ğ¸Ğ¿Ñ‚Ğ¾ĞºĞ¾ÑˆĞµĞ»ÑŒĞºĞ¾Ğ² :\n\nIf you find this project useful and wish to donate here are crypto wallets :\n\nUSDT ERC `0x3d52Ce15B7Be734c53fc9526ECbAB8267b63d66E` \n\nUSDT TRC `TEzAAtn4VhndqEaAyuCM78xh5W2gCjwWEo`\n\nBTC  `bc1qhqew3mrvp47uk2vevt5sctp7p2x9m7m5kkchve`\n\nETH  `0x3d52Ce15B7Be734c53fc9526ECbAB8267b63d66E`\n\n\n## Ğ§ĞµĞ¼ ÑÑ‚Ğ¾ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ°ĞµÑ‚ÑÑ Ğ¾Ñ‚ zapret1\n\nzapret2 ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ´Ğ°Ğ»ÑŒĞ½ĞµĞ¹ÑˆĞ¸Ğ¼ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸ĞµĞ¼ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ° zapret.\nĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° ĞµĞ³Ğ¾ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ñ‡Ğ°ÑÑ‚Ğ¸ *nfqws1* Ğ² Ñ‚Ğ¾Ğ¼, Ñ‡Ñ‚Ğ¾ Ğ¾Ğ½ Ğ¿ĞµÑ€ĞµĞ³Ñ€ÑƒĞ¶ĞµĞ½ Ğ¾Ğ¿Ñ†Ğ¸ÑĞ¼Ğ¸ Ğ¸ Ğ² ÑƒÑĞ»Ğ¾Ğ²Ğ¸ÑÑ… Ğ½Ğ°Ñ€Ğ°ÑÑ‚Ğ°ÑÑ‰ĞµĞ³Ğ¾ Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ Ñ€ĞµĞ³ÑƒĞ»ÑÑ‚Ğ¾Ñ€Ğ° Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹\nĞ½Ğµ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½ÑƒÑ Ğ³Ğ¸Ğ±ĞºĞ¾ÑÑ‚ÑŒ Ğ²Ğ¾Ğ·Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ğ½Ğ° Ñ‚Ñ€Ğ°Ñ„Ğ¸Ğº.\nĞĞ±Ñ…Ğ¾Ğ´ DPI Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ğ²ÑĞµ Ğ±Ğ¾Ğ»ĞµĞµ Ñ‚Ğ¾Ğ½ĞºĞ¸Ñ… Ğ¸ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ²Ğ¾Ğ·Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¼ĞµĞ½ÑÑÑ‚ÑÑ ÑĞ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½ĞµĞ¼, Ğ° ÑÑ‚Ğ°Ñ€Ñ‹Ğµ Ğ¿ĞµÑ€ĞµÑÑ‚Ğ°ÑÑ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ.\n\nĞ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ - ÑÑ‚Ğ¾ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹, ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ÑÑÑ‰Ğ¸Ğµ ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ĞµĞ¼ Ğ°Ñ‚Ğ°ĞºĞ¸ Ğ½Ğ° DPI. Ğ’ *nfqws1* Ğ¾Ğ½Ğ¸ Ğ·Ğ°ÑˆĞ¸Ğ²Ğ°ÑÑ‚ÑÑ Ğ² C ĞºĞ¾Ğ´. ĞĞ°Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ C ĞºĞ¾Ğ´Ğ° - Ğ·Ğ°Ğ½ÑÑ‚Ğ¸Ğµ Ğ½ĞµĞ»ĞµĞ³ĞºĞ¾Ğµ,\nÑ‚Ñ€ĞµĞ±ÑƒÑÑ‰ĞµĞµ Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ¹ ĞºĞ²Ğ°Ğ»Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ° Ğ¸ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸.\n\nĞ¦ĞµĞ»ÑŒ *nfqws2* - ÑĞ´ĞµĞ»Ğ°Ñ‚ÑŒ Ñ‚Ğ°Ğº, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹ Ğ¼Ğ¾Ğ³ Ğ½Ğ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ğ»ÑĞ±Ğ¾Ğ¹ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº, Ğ²Ğ»Ğ°Ğ´ĞµÑÑ‰Ğ¸Ğ¹ Ğ·Ğ½Ğ°Ğ½Ğ¸ÑĞ¼Ğ¸ Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ ÑĞµÑ‚ĞµĞ¹, Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°ÑÑ‰Ğ¸Ğ¹ ÑƒÑĞ·Ğ²Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ DPI\nĞ¸Ğ»Ğ¸ Ñ…Ğ¾Ñ‚Ñ Ğ±Ñ‹ Ğ¾Ğ±Ğ»Ğ°ÑÑ‚ÑŒ , Ğ² ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ¹ Ğ¸Ñ… Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¸ÑĞºĞ°Ñ‚ÑŒ, Ğ¿Ğ»ÑÑ Ğ²Ğ»Ğ°Ğ´ĞµÑÑ‰Ğ¸Ğ¹ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ½Ğ°Ğ²Ñ‹ĞºĞ°Ğ¼Ğ¸ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ.\n\n*nfqws2* Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ² ÑĞµĞ±Ğµ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ñ‚Ğ¾Ñ‚ Ğ¶Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ°Ğ» - Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ»Ğ¾Ğ², Ñ€ĞµĞ°ÑÑĞµĞ¼Ğ±Ğ»Ğ¸Ğ½Ğ³, Ğ´ĞµÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²ĞºĞ°, ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑĞ¼Ğ¸, Ñ…Ğ¾ÑÑ‚Ğ»Ğ¸ÑÑ‚Ñ‹, ipset-Ñ‹, Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ.\nĞĞ¾ Ğ¾Ğ½ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ»Ğ¸ÑˆĞ°ĞµÑ‚ÑÑ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹ ÑĞ°Ğ¼Ğ¾ÑÑ‚Ğ¾ÑÑ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ²Ğ¾Ğ·Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ½Ğ° Ñ‚Ñ€Ğ°Ñ„Ğ¸Ğº. Ğ§Ğ°ÑÑ‚ÑŒ \"Ğ´ÑƒÑ€ĞµĞ½Ğ¸Ñ\" Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¸Ñ‚ÑÑ Ğ² ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ğ¾Ğ²Ğ¾Ğ¹ ÑĞ·Ñ‹Ğº Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Lua.\n\nLua ĞºĞ¾Ğ´ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ¾Ñ‚ C ĞºĞ¾Ğ´Ğ° ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ñ… Ğ¿Ğ°ĞºĞµÑ‚Ğ¾Ğ² Ğ² Ğ²Ğ¸Ğ´Ğµ Ğ´ĞµÑ€ĞµĞ²Ğ° (Ğ´Ğ¸ÑÑĞµĞºÑ‚Ñ‹), Ğ¿Ğ¾Ğ´Ğ¾Ğ±Ğ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµĞ¼, Ñ‡Ñ‚Ğ¾ Ğ²Ñ‹ Ğ²Ğ¸Ğ´Ğ¸Ñ‚Ğµ Ğ² wireshark.\nĞ¢ÑƒĞ´Ğ° Ğ¶Ğµ Ğ¿Ñ€Ğ¸Ñ…Ğ¾Ğ´ÑÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ ÑĞ±Ğ¾Ñ€ĞºĞ¸ Ğ¸Ğ»Ğ¸ Ğ´ĞµÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²ĞºĞ¸ Ñ‡Ğ°ÑÑ‚ĞµĞ¹ Ğ½ĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ»Ğ¾Ğ² (tls, quic).\nĞ¡ ĞºĞ¾Ğ´ Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸-Ñ…ĞµĞ»Ğ¿ĞµÑ€Ñ‹, Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑÑÑ‰Ğ¸Ğµ Ğ¾Ñ‚ÑÑ‹Ğ»Ğ°Ñ‚ÑŒ Ğ¿Ğ°ĞºĞµÑ‚Ñ‹, Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ñ Ğ´Ğ²Ğ¾Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸, Ñ€Ğ°Ğ·Ğ±Ğ¸Ñ€Ğ°Ñ‚ÑŒ TLS, Ğ¸ÑĞºĞ°Ñ‚ÑŒ Ğ¼Ğ°Ñ€ĞºĞµÑ€-Ğ¿Ğ¾Ğ·Ñ†Ğ¸Ğ¸ Ğ¸ Ñ‚.Ğ´.\nĞ˜Ğ¼ĞµĞµÑ‚ÑÑ Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ° Ñ…ĞµĞ»Ğ¿ĞµÑ€Ğ¾Ğ², Ğ½Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ° Lua, Ğ° Ñ‚Ğ°Ğº Ğ¶Ğµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ°Ñ Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ° Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼ Ğ°Ñ‚Ğ°ĞºĞ¸ Ğ½Ğ° DPI (ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹), Ñ€ĞµĞ°Ğ»Ğ¸Ğ·ÑƒÑÑ‰Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ *nfqws1* Ğ² Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ğ¾Ğ¼ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğµ\nĞ¸ Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞµĞ¹ Ğ³Ğ¸Ğ±ĞºĞ¾ÑÑ‚ÑŒÑ.\n\nĞ’Ñ‹ Ğ²ÑĞµĞ³Ğ´Ğ° ÑĞ¼Ğ¾Ğ¶ĞµÑ‚Ğµ Ğ²Ğ·ÑÑ‚ÑŒ Ğ¸ Ğ´Ğ¾Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ñ‡Ñ‚Ğ¾-Ñ‚Ğ¾ ÑĞ²Ğ¾Ğµ. Ğ’ ÑÑ‚Ğ¾Ğ¼ Ğ¸ ĞµÑÑ‚ÑŒ ÑĞ¼Ñ‹ÑĞ», Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ±Ğ¾Ñ€ÑŒĞ±Ğ¾Ğ¹ Ñ DPI ÑĞ¼Ğ¾Ğ³ Ğ·Ğ°Ğ½ÑÑ‚ÑŒÑÑ Ğ»ÑĞ±Ğ¾Ğ¹, ĞºÑ‚Ğ¾ Ñ€Ğ°Ğ·Ğ±Ğ¸Ñ€Ğ°ĞµÑ‚ÑÑ Ğ² Ğ¿Ğ°ĞºĞµÑ‚Ğ°Ñ….\nĞœĞ¾Ğ³ \"Ğ¿Ğ¾Ñ‚Ñ‹ĞºĞ°Ñ‚ÑŒ\" ĞµĞ³Ğ¾, Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ ÑĞ²Ğ¾Ğ¸ Ğ¸Ğ´ĞµĞ¸. Ğ Ğ¿Ğ¾Ñ‚Ğ¾Ğ¼ Ğ¿Ğ¾Ğ´ĞµĞ»Ğ¸Ñ‚ÑŒÑÑ Ñ Ğ´Ñ€ÑƒĞ·ÑŒÑĞ¼Ğ¸ ÑĞ²Ğ¾Ğ¸Ğ¼ Ñ€ĞµÑˆĞµĞ½Ğ¸ĞµĞ¼ \"Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ»Ğ¸ĞºĞ°\".\nzapret2 - Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ñ‚Ğ°ĞºĞ¸Ñ… ÑĞ½Ñ‚ÑƒĞ·Ğ¸Ğ°ÑÑ‚Ğ¾Ğ². ĞĞ¾ ÑÑ‚Ğ¾ Ğ½Ğµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ñ‡Ğ°Ğ¹Ğ½Ğ¸ĞºĞ¾Ğ². ĞŸÑ€Ğ¾ĞµĞºÑ‚ Ğ½Ğµ ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ ÑĞµĞ±Ğµ Ñ†ĞµĞ»ÑŒÑ ÑĞ´ĞµĞ»Ğ°Ñ‚ÑŒ Ğ²ÑĞµ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ğ¼ Ğ´Ğ»Ñ Ğ²ÑĞµÑ….\nĞĞ²Ñ‚Ğ¾Ñ€ ÑÑ‡Ğ¸Ñ‚Ğ°ĞµÑ‚, Ñ‡Ñ‚Ğ¾ ÑÑ‚Ğ¾ Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ² Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ğµ Ğ¿Ğ¾ Ğ¾Ğ±ÑŒĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼ Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°Ğ¼.\n\n\n## Ğ¡ Ñ‡ĞµĞ³Ğ¾ Ğ½Ğ°Ñ‡Ğ°Ñ‚ÑŒ\n\nĞ¥Ğ¾Ñ‚ĞµĞ»Ğ¾ÑÑŒ Ğ±Ñ‹ Ğ¸Ğ·Ğ±ĞµĞ¶Ğ°Ñ‚ÑŒ [Ñ‚Ğ°Ğ»Ğ¼ÑƒĞ´Ğ°](manual.md) Ğ½Ğ° Ğ³Ğ»Ğ°Ğ²Ğ½Ğ¾Ğ¹ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğµ. ĞŸĞ¾ÑÑ‚Ğ¾Ğ¼Ñƒ Ğ½Ğ°Ñ‡Ğ½ĞµĞ¼ ÑĞ¾ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ° Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° *nfqws2* Ğ¸ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ¾Ğ² Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹ *nfqws1* - ĞºĞ°Ğº Ğ² *nfqws2* ÑĞ´ĞµĞ»Ğ°Ñ‚ÑŒ Ñ‚Ğ¾ Ğ¶Ğµ ÑĞ°Ğ¼Ğ¾Ğµ, Ñ‡Ñ‚Ğ¾ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ±Ñ‹Ğ»Ğ¾ Ğ² *nfqws1*.\nĞšĞ¾Ğ³Ğ´Ğ° Ğ²Ñ‹ Ğ¿Ğ¾Ğ¹Ğ¼ĞµÑ‚Ğµ ĞºĞ°Ğº ÑÑ‚Ğ¾ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚, Ğ²Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ Ğ¿Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ Lua ĞºĞ¾Ğ´, Ğ½Ğ°Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğ¹ÑÑ \"Ğ¿Ğ¾Ğ´ ĞºĞ°Ğ¿Ğ¾Ñ‚Ğ¾Ğ¼\". Ğ Ğ°Ğ·Ğ¾Ğ±Ñ€Ğ°Ñ‚ÑŒ ĞºĞ°Ğº Ğ¾Ğ½ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚, Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ½Ğ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ñ‡Ñ‚Ğ¾-Ñ‚Ğ¾ ÑĞ²Ğ¾Ğµ, Ñ€ÑƒĞºĞ¾Ğ²Ğ¾Ğ´ÑÑ‚Ğ²ÑƒÑÑÑŒ [Ñ‚Ğ°Ğ»Ğ¼ÑƒĞ´Ğ¾Ğ¼](manual.md) ĞºĞ°Ğº ÑĞ¿Ñ€Ğ°Ğ²Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ¼.\n\n### ĞœĞµÑ…Ğ°Ğ½Ğ¸ĞºĞ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ñ‚Ñ€Ğ°Ñ„Ğ¸ĞºĞ°\n\nĞ˜Ğ·Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ğ¾ ÑĞµÑ‚ĞµĞ²Ğ¾Ğ¹ Ñ‚Ñ€Ğ°Ñ„Ğ¸Ğº Ğ² Ğ»ÑĞ±Ğ¾Ğ¹ ĞĞ¡ Ğ¿Ğ¾ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ² ÑĞ´Ñ€Ğµ. ĞŸĞµÑ€Ğ²Ğ°Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° - Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ ĞµĞ³Ğ¾ Ğ¾Ñ‚Ñ‚ÑƒĞ´Ğ° Ğ¸ Ğ¿ĞµÑ€ĞµĞ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ½Ğ° Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ *nfqws2*.\nĞ­Ñ‚Ğ° Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° Ñ€ĞµÑˆĞ°ĞµÑ‚ÑÑ Ğ² Linux Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ iptables Ğ¸ nftables, Ğ² BSD - ipfw Ğ¸ pf, Ğ² Windows - windivert.\nĞŸÑ€Ğ¾Ñ†ĞµÑÑ Ğ¿ĞµÑ€ĞµĞ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ñ‚Ñ€Ğ°Ñ„Ğ¸ĞºĞ° Ğ¸Ğ· ÑĞ´Ñ€Ğ° Ğ¾Ñ‚Ğ½Ğ¸Ğ¼Ğ°ĞµÑ‚ Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ², Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ¼Ñƒ Ğ»ÑƒÑ‡ÑˆĞµ Ğ²ÑĞµĞ³Ğ¾ Ğ¾Ñ‚Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºĞ°Ğº Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ¿Ñ€ÑĞ¼Ğ¾ Ğ² Ğ½ĞµĞ¼.\n\nĞ”Ğ»Ñ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ½Ğ° Linux Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ñ‡Ğ°Ñ‚ÑŒ ÑĞ¾ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ñ… nftables, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¿ĞµÑ€ĞµĞ½Ğ°Ğ¿Ñ€Ğ°Ğ²ÑÑ‚ Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ğ°ĞºĞµÑ‚Ñ‹ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğ¹ Ğ½Ğ° Ğ¿Ğ¾Ñ€Ñ‚Ñ‹ tcp 80,443 Ğ¸ udp 443 Ğ² Ğ¾Ñ‡ĞµÑ€ĞµĞ´ÑŒ NFQUEUE Ñ Ğ½Ğ¾Ğ¼ĞµÑ€Ğ¾Ğ¼ 200.\n\n```\nnft delete table inet ztest\nnft create table inet ztest\nnft add chain inet ztest post \"{type filter hook postrouting priority 101;}\"\nnft add rule inet ztest post meta mark and 0x40000000 == 0 tcp dport \"{80,443}\" ct original packets 1-12 queue num 200 bypass\nnft add rule inet ztest post meta mark and 0x40000000 == 0 udp dport \"{443}\" ct original packets 1-12 queue num 200 bypass\n\nsysctl net.netfilter.nf_conntrack_tcp_be_liberal=1 \nnft add chain inet ztest pre \"{type filter hook prerouting priority -101;}\"\nnft add rule inet ztest pre meta mark and 0x40000000 == 0 tcp sport \"{80,443}\" ct reply packets 1-12 queue num 200 bypass\nnft add rule inet ztest pre meta mark and 0x40000000 == 0 udp sport \"{443}\" ct reply packets 1-12 queue num 200 bypass\n\nnft add chain inet ztest predefrag \"{type filter hook output priority -401;}\"\nnft add rule inet ztest predefrag \"mark & 0x40000000 != 0x00000000 notrack\"\n```\n\nĞ’ windows Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿ĞµÑ€ĞµÑ…Ğ²Ğ°Ñ‚Ğ° Ğ²ÑˆĞ¸Ñ‚Ğ° Ğ¿Ñ€ÑĞ¼Ğ¾ Ğ² ĞºĞ¾Ğ´ Ğ´Ğ²Ğ¸Ğ¶ĞºĞ° Ğ´Ğ»Ñ windows, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ½Ğ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ *winws2*. ĞĞ½ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ´Ñ€Ğ°Ğ¹Ğ²ĞµÑ€ windivert.\nĞ”Ğ»Ñ Ğ¿ĞµÑ€ĞµÑ…Ğ²Ğ°Ñ‚Ğ° Ğ¿Ğ¾Ñ€Ñ‚Ğ¾Ğ² Ñ†ĞµĞ»Ğ¸ĞºĞ¾Ğ¼ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ÑÑ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ `--wf-tcp-in`, `--wf-tcp-out`, `--wf-udp-in`, `--wf-udp-out`.\nĞĞ½Ğ¸ Ğ¾Ñ‚Ğ½Ğ¾ÑÑÑ‚ÑÑ Ğº Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ»Ğ°Ğ¼ tcp Ğ¸Ğ»Ğ¸ udp, Ğº Ğ²Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğ¼ Ğ¸Ğ»Ğ¸ Ğ¸ÑÑ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğ¼ Ğ¿Ğ°ĞºĞµÑ‚Ğ°Ğ¼. ĞĞ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, `--wf-tcp-out=80,443`.\nĞ”Ğ»Ñ Ğ±Ğ¾Ğ»ĞµĞµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¿ĞµÑ€ĞµÑ…Ğ²Ğ°Ñ‚Ğ° Ğ¿Ğ¸ÑˆÑƒÑ‚ÑÑ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹ Ğ½Ğ° ÑĞ·Ñ‹ĞºĞµ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ¾Ğ² windivert. ĞĞ½ Ğ¿Ğ¾Ñ…Ğ¾Ğ¶ Ğ½Ğ° ÑĞ·Ñ‹Ğº Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ¾Ğ² tcpdump Ğ¸Ğ»Ğ¸ wireshark.\nĞ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹ Ğ¾Ñ‚Ğ´Ğ°ÑÑ‚ÑÑ *winws2* Ğ² Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ñ… `--wf-raw-part`. ĞšĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ‚Ğ¾Ñ€ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ¾Ğ² Ğ¾Ğ±ÑŒĞµĞ´Ğ¸Ğ½ÑĞµÑ‚ Ğ²ÑĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¾Ğ¿Ñ†Ğ¸Ğ¸ Ğ¿ĞµÑ€ĞµÑ…Ğ²Ğ°Ñ‚Ğ° Ğ²\nĞµĞ´Ğ¸Ğ½Ñ‹Ğ¹ raw Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€ Ğ¸ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°ĞµÑ‚ Ğ¿ĞµÑ€ĞµÑ…Ğ²Ğ°Ñ‚ windivert.\n\nĞš ÑĞ¾Ğ¶Ğ°Ğ»ĞµĞ½Ğ¸Ñ, ÑĞ°Ğ¼Ñ‹Ğ¹ Ğ±Ğ¾Ğ»ĞµĞ·Ğ½ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ğº windivert (Ğ° Ñ‚Ğ°Ğº Ğ¶Ğµ BSD ipfw Ğ¸ pf) - Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ğµ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ñ‚ĞµĞ»Ñ Ğ½Ğ° Ğ½Ğ¾Ğ¼ĞµÑ€ Ğ¿Ğ°ĞºĞµÑ‚Ğ° Ğ² ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğ¸ (connbytes Ğ² iptables, ct packets Ğ² nftables).\nwindivert Ğ²Ğ¾Ğ¾Ğ±Ñ‰Ğµ Ğ½Ğµ Ğ¾Ñ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°ĞµÑ‚ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ. ĞŸĞ¾ÑÑ‚Ğ¾Ğ¼Ñƒ ĞµÑĞ»Ğ¸ Ğ¿ĞµÑ€ĞµÑ…Ğ²Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ñ€Ñ‚ Ñ†ĞµĞ»Ğ¸ĞºĞ¾Ğ¼, Ñ‚Ğ¾ Ğ²ÑĞµ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ğ¾Ğ¼Ñƒ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ\nĞ¿Ğ¾Ğ¹Ğ´ĞµÑ‚ Ğ½Ğ° Ğ¿ĞµÑ€ĞµÑ…Ğ²Ğ°Ñ‚, Ñ‡Ñ‚Ğ¾ Ğ½ĞµĞ»ĞµĞ³ĞºĞ¾ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€Ğ°, ĞµÑĞ»Ğ¸ Ñ‚Ğ°Ğ¼ Ğ¿ĞµÑ€ĞµĞ´Ğ°ÑÑ‚ÑÑ Ğ¼Ğ½Ğ¾Ğ³Ğ¸Ğµ Ğ¼ĞµĞ³Ğ°Ğ±Ğ°Ğ¹Ñ‚Ñ‹.\nĞŸĞ¾ÑÑ‚Ğ¾Ğ¼Ñƒ Ğ¿Ğ¾ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ ÑĞ¾Ğ±ÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğµ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹ windivert, Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑÑÑ‰Ğ¸Ğµ Ñ‚Ğ¸Ğ¿ Ğ¿ĞµĞ¹Ğ»Ğ¾Ğ°Ğ´Ğ° Ñ…Ğ¾Ñ‚Ñ Ğ±Ñ‹ Ñ‡Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾. Ğ”Ğ¾Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ *winws2*.\n\nĞ”Ğ°Ğ»ÑŒÑˆĞµ Ğ¿Ğ¾Ğ´ Ñ€ÑƒÑ‚Ğ¾Ğ¼ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ *nfqws2* Ñ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ½Ğ¾Ğ¹ ÑÑ‚Ñ€Ğ¾ĞºĞ¸. ĞĞ½Ğ¸ ÑÑ‚Ñ€Ğ¾ÑÑ‚ÑÑ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ¼ :\n\n```\nnfqws2 --qnum 200 --debug --lua-init=@zapret-lib.lua --lua-init=@zapret-antidpi.lua \\\n  --filter-tcp=80,443 --filter-l7=tls,http \\\n  --payload=tls_client_hello --lua-desync=fake:blob=fake_default_tls:tcp_md5:tls_mod=rnd,rndsni,dupsid \\\n  --payload=http_req --lua-desync=fake:blob=fake_default_http:tcp_md5 \\\n  --payload=tls_client_hello,http_req --lua-desync=multisplit:pos=1:seqovl=5:seqovl_pattern=0x1603030000\n```\n\nĞ”Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ğ»Ğ°Ğ³Ğ°ĞµÑ‚, Ñ‡Ñ‚Ğ¾ Ğ² Ñ‚Ğ¾Ğ¹ Ğ¶Ğµ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ½Ğ°Ñ…Ğ¾Ğ´ÑÑ‚ÑÑ Ñ„Ğ°Ğ¹Ğ»Ñ‹ `zapret-lib.lua` - Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ° Ñ…ĞµĞ»Ğ¿ĞµÑ€Ğ¾Ğ² Ğ½Ğ° Lua Ğ¸ `zapret-antidpi.lua` - Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ° Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ñ… ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹.\n`--lua-init` Ğ¼Ğ¾Ğ¶ĞµÑ‚ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‚ÑŒ Lua ĞºĞ¾Ğ´ Ğ² Ğ²Ğ¸Ğ´Ğµ ÑÑ‚Ñ€Ğ¾ĞºĞ¸. Ğ¢Ğ°Ğº ÑƒĞ´Ğ¾Ğ±Ğ½Ğ¾ Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ¹ ĞºĞ¾Ğ´, Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ Ğ¿Ñ€Ğ¸ÑĞ²Ğ¾Ğ¸Ñ‚ÑŒ ĞºĞ¾Ğ½ÑÑ‚Ğ°Ğ½Ñ‚Ñƒ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğµ ÑĞ¾Ğ·Ğ´Ğ°Ğ²Ğ°Ñ‚ÑŒ Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ñ€Ğ°Ğ´Ğ¸ ÑÑ‚Ğ¾Ğ¹ Ğ¼ĞµĞ»Ğ¾Ñ‡Ğ¸.\nĞ›Ğ¸Ğ±Ğ¾ Ğ¿Ğ¾Ğ´Ñ†ĞµĞ¿Ğ»ÑĞµÑ‚ÑÑ Ñ„Ğ°Ğ¹Ğ», ĞµÑĞ»Ğ¸ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ° Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ÑÑ Ñ `@`. ĞšĞ¾Ğ´ Ğ¸Ğ· `--lua-init` Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ÑÑ 1 Ñ€Ğ°Ğ· Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ°Ñ€Ñ‚Ğµ.\n\nĞ”Ğ°Ğ»ĞµĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ñ‹ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ `--lua-desync`. ĞĞ½Ğ¸ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‚ Ğ¸Ğ¼Ñ Lua Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸, Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼Ğ¾Ğ¹ Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ¿Ğ°ĞºĞµÑ‚Ğ°, Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´ÑÑ‰ĞµĞ³Ğ¾ Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸.\nĞŸĞ¾ÑĞ»Ğµ Ğ´Ğ²Ğ¾ĞµÑ‚Ğ¾Ñ‡Ğ¸Ñ Ğ¸ Ñ‡ĞµÑ€ĞµĞ· Ğ´Ğ²Ğ¾ĞµÑ‚Ğ¾Ñ‡Ğ¸Ñ ÑĞ»ĞµĞ´ÑƒÑÑ‚ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ´Ğ»Ñ Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ `param[=value]`. Ğ’ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğµ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ° ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ\n\n```\nnfqws --qnum 200 --debug \\\n--filter-tcp=80,443 --filter-l7=tls,http \\\n --dpi-desync=fake,multisplit --dpi-desync-fooling=md5sig --dpi-desync-split-pos=1,midsld \\\n --dpi-desync-split-seqovl=5 --dpi-desync-split-seqovl-pattern=0x1603030000 \\\n --dpi-desync-fake-tls-mod=rnd,rndsni,dupsid\n```\n\nĞ§Ñ‚Ğ¾ ÑÑ€Ğ°Ğ·Ñƒ Ğ·Ğ°Ğ¼ĞµÑ‚Ğ½Ğ¾ - ÑÑ‚Ğ¾ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¿Ğ¾Ğ½ÑÑ‚Ğ¸Ñ \"payload\". Ğ’ *nfqws1* Ğ±Ñ‹Ğ»Ğ¸ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ»Ñ‹ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ ÑƒÑ‡Ğ°ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ»Ğ¸ Ğ² Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹.\nĞĞ½Ğ¸ Ñ‚Ğ°Ğº Ğ¶Ğµ Ğ¾ÑÑ‚Ğ°Ğ»Ğ¸ÑÑŒ Ğ² *nfqws2*, Ğ½Ğ¾ Ğ²Ğ²ĞµĞ´ĞµĞ½Ğ¾ Ğ´Ñ€ÑƒĞ³Ğ¾Ğµ Ğ¿Ğ¾Ğ½ÑÑ‚Ğ¸Ğµ - Ñ‚Ğ¸Ğ¿ Ğ¿ĞµĞ¹Ğ»Ğ¾Ğ°Ğ´Ğ°. ĞŸĞµĞ¹Ğ»Ğ¾Ğ°Ğ´ - ÑÑ‚Ğ¾ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ğ½Ğ¸Ğµ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ğ¿Ğ°ĞºĞµÑ‚Ğ°.\nĞ¢Ğ¸Ğ¿ Ğ¿ĞµĞ¹Ğ»Ğ¾Ğ°Ğ´Ğ° - Ñ‚Ğ¸Ğ¿ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‰Ğ¸Ñ…ÑÑ Ğ² Ğ¿Ğ°ĞºĞµÑ‚Ğµ Ğ¸Ğ»Ğ¸ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğµ Ğ¿Ğ°ĞºĞµÑ‚Ğ¾Ğ². ĞĞ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ» ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ tls, Ğ° Ğ¿ĞµĞ¹Ğ»Ğ¾Ğ°Ğ´Ñ‹ - tls_client_hello, tls_server_hello, unknown.\n\nĞ”Ñ€ÑƒĞ³Ğ¾Ğµ Ğ²Ğ°Ğ¶Ğ½Ğ¾Ğµ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ğµ - Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ğµ Ğ¶ĞµÑÑ‚ĞºĞ¾ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ñ‹Ñ… Ñ„Ğ°Ğ· Ğ´ĞµÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸. Ğ¢Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ²Ñ‹ Ñ€Ğ°Ğ½ÑŒÑˆĞµ Ğ¿Ğ¸ÑĞ°Ğ»Ğ¸ ĞºĞ°Ğº `fake,multisplit` Ñ€ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞµÑ‚ÑÑ Ğ´Ğ²ÑƒĞ¼Ñ\nĞ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼Ñ‹Ğ¼Ğ¸ Lua Ñ„ÑƒĞ½ĞºÑ†Ğ¸ÑĞ¼Ğ¸. Ğ˜Ñ… Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ ÑÑ‚Ğ¾Ğ»ÑŒĞºĞ¾, ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ½ÑƒĞ¶Ğ½Ğ¾, ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºÑƒ Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¿Ğ°ĞºĞµÑ‚Ğ¾Ğ² Ğ¸ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¹ Ñ Ğ½Ğ¸Ğ¼Ğ¸, Ğ¸ Ñƒ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ±Ñ‹Ñ‚ÑŒ ÑĞ²Ğ¾Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹.\nĞœĞ¾Ğ¶ĞµÑ‚ Ğ´Ğ°Ğ¶Ğµ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ñ€Ğ°Ğ· Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒÑÑ Ğ¾Ğ´Ğ½Ğ° Ğ¸ Ñ‚Ğ°Ğº Ğ¶Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸. Ğ¢Ğ°Ğº, Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿Ğ¾ÑĞ»Ğ°Ñ‚ÑŒ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ñ„ĞµĞ¹ĞºĞ¾Ğ², Ğ¿Ñ€Ğ¸Ñ‡ĞµĞ¼ Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼Ğ¸ Ñ„ÑƒĞ»Ğ¸Ğ½Ğ³Ğ°Ğ¼Ğ¸.\nĞšĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² `--lua-desync` Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ½Ğ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ¸Ğ½ÑÑ‚Ğ°Ğ½ÑĞ¾Ğ¼. Ğ˜Ğ½ÑÑ‚Ğ°Ğ½Ñ - ÑÑ‚Ğ¾ ÑĞ²ÑĞ·ĞºĞ° Ğ¸Ğ¼ĞµĞ½Ğ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸, Ğ½Ğ¾Ğ¼ĞµÑ€Ğ° Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ° Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ñ Ğ¸ Ğ½Ğ¾Ğ¼ĞµÑ€Ğ° ÑĞ°Ğ¼Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ñ.\nĞ­Ñ‚Ğ¾ Ğ¿Ğ¾Ñ…Ğ¾Ğ¶Ğµ Ğ½Ğ° Ğ¾Ğ´Ğ½Ñƒ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñƒ, ĞºĞ¾Ñ‚Ğ¾Ñ€ÑƒÑ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ· Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸.\n\nĞ”Ñ€ÑƒĞ³Ğ¾Ğµ Ğ½ĞµĞ¼Ğ°Ğ»Ğ¾Ğ²Ğ°Ğ¶Ğ½Ğ¾Ğµ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ğµ - Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ° Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ tcp ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ ÑÑ€ĞµĞ´ÑÑ‚Ğ²Ğ°Ğ¼Ğ¸ `zapret-lib.lua`. Ğ’Ğ°Ğ¼ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ½Ğµ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ´ÑƒĞ¼Ğ°Ñ‚ÑŒ Ğ¾ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ°Ñ… Ğ¾Ñ‚ÑÑ‹Ğ»Ğ°ĞµĞ¼Ñ‹Ñ… tcp Ğ¿Ğ°ĞºĞµÑ‚Ğ¾Ğ².\nĞŸĞ¾ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼Ñƒ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ Ğ¾Ñ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ MSS. Ğ•ÑĞ»Ğ¸ Ğ¿Ğ°ĞºĞµÑ‚ Ğ½Ğµ Ğ²Ğ»ĞµĞ·Ğ°ĞµÑ‚ Ğ² MSS, Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ÑÑ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ.\nĞĞ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, ÑÑ‚Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ ÑĞ»ÑƒÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğ¿Ñ€Ğ¸ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞµ tls Ñ„ĞµĞ¹ĞºĞ° Ñ kyber. Ğ˜Ğ»Ğ¸ ĞµÑĞ»Ğ¸ Ğ²Ñ‹ Ñ€ĞµĞ¶ĞµÑ‚Ğµ kyber tls Ñ‚Ğ°Ğº, Ñ‡Ñ‚Ğ¾ Ğ¾Ğ´Ğ½Ğ° Ğ¸Ğ· Ñ‡Ğ°ÑÑ‚ĞµĞ¹ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ÑÑ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ¾Ğ¼ 1600 Ğ±Ğ°Ğ¹Ñ‚,\nÑ‡Ñ‚Ğ¾, Ğ¾Ñ‡ĞµĞ²Ğ¸Ğ´Ğ½Ğ¾, Ğ½Ğµ Ğ²Ğ»ĞµĞ·Ğ°ĞµÑ‚ Ğ² MTU. Ğ˜Ğ»Ğ¸ ĞµÑĞ»Ğ¸ Ğ²Ñ‹ Ğ·Ğ°Ğ´Ğ°Ğ»Ğ¸ seqovl=10000. Ğ’ *nfqws1* Ñ‚Ğ°ĞºĞ¾Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ Ğ²Ñ‹Ğ·Ğ²Ğ°Ğ»Ğ¾ Ğ±Ñ‹ Ğ¾ÑˆĞ¸Ğ±ĞºÑƒ. Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Lua `rawsend_dissect_segmented` Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚\nĞ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ tcp ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ñ Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ sequence -10000 Ğ¾Ğ±Ñ‰Ğ¸Ğ¼ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ¾Ğ¼ 10000 Ğ±Ğ°Ğ¹Ñ‚, Ğ² Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ¼ Ğ¸Ğ· ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ğ±ÑƒĞ´ĞµÑ‚ ĞºÑƒÑĞ¾Ğº Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ.\n\nĞ’ *nfqws2* Ğ½ĞµÑ‚ Ğ¶ĞµÑÑ‚ĞºĞ¾ Ğ·Ğ°ÑˆĞ¸Ñ‚Ñ‹Ñ… Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² ĞºĞ°ÑÑ‚Ğ¾Ğ¼Ğ½Ñ‹Ñ… Ñ„ĞµĞ¹ĞºĞ¾Ğ² Ñ‚Ğ¸Ğ¿Ğ° `--dpi-desync-fake-tls`, `dpi-desync-fake-http` Ğ¸ Ñ‚Ğ´.\nĞ’Ğ¼ĞµÑÑ‚Ğ¾ Ğ½Ğ¸Ñ… ĞµÑÑ‚ÑŒ Ğ±Ğ»Ğ¾Ğ±Ñ‹. Ğ‘Ğ»Ğ¾Ğ± (blob) - ÑÑ‚Ğ¾ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ Lua Ñ‚Ğ¸Ğ¿Ğ° *string*, ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‰Ğ°Ñ Ğ±Ğ»Ğ¾Ğº Ğ´Ğ²Ğ¾Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ´Ğ»Ğ¸Ğ½Ñ‹. ĞÑ‚ 1 Ğ±Ğ°Ğ¹Ñ‚Ğ° Ğ´Ğ¾ Ğ³Ğ¸Ğ³Ğ°Ğ±Ğ°Ğ¹Ñ‚Ğ¾Ğ².\n*nfqws2* Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ±Ğ»Ğ¾Ğ±Ñ‹ ÑĞ¾ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğ¼Ğ¸ Ñ„ĞµĞ¹ĞºĞ°Ğ¼Ğ¸ tls, http, quic, ĞºĞ°Ğº ÑÑ‚Ğ¾ Ğ¸ Ğ±Ñ‹Ğ»Ğ¾ Ğ² *nfqws1*.\nĞ‘Ğ»Ğ¾Ğ±Ñ‹ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ·Ğ°Ğ´Ğ°Ğ½Ñ‹ ĞºĞ°Ğº hex-ÑÑ‚Ñ€Ğ¾ĞºĞ° Ğ¿Ñ€ÑĞ¼Ğ¾ Ğ² Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğµ desync Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸, Ğ»Ğ¸Ğ±Ğ¾ Ğ¿Ñ€ĞµĞ´-Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ñ‹ Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ°Ñ€Ñ‚Ğµ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ° `--blob=name:0xHEX|[+ofs]@filename`\n\nĞ§Ñ‚Ğ¾ ĞºĞ°ÑĞ°ĞµÑ‚ÑÑ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ Ğ¸ Ñ…Ğ¾ÑÑ‚Ğ»Ğ¸ÑÑ‚Ğ¾Ğ² , Ñ‚Ğ¾ Ğ¾Ğ½Ğ¸ Ğ¾ÑÑ‚Ğ°Ğ»Ğ¸ÑÑŒ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ² Ğ½ĞµĞ¸Ğ·Ğ¼ĞµĞ½Ğ½Ğ¾Ğ¼ Ğ²Ğ¸Ğ´Ğµ. Ğ—Ğ° Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸ĞµĞ¼ Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ñ‚Ğ¾Ğ½ĞºĞ¾ÑÑ‚Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ»Ğ¸ÑÑ‚Ğ°.\nĞ¢ĞµĞ¿ĞµÑ€ÑŒ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ»Ğ¸ÑÑ‚Ğ¾Ğ¼ Ğ±ĞµÑ€ĞµÑ‚ Ğ½Ğ° ÑĞµĞ±Ñ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚Ğµ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ, Ğ´Ğ»Ñ ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… ÑƒĞ¶Ğµ Ğ¸Ğ·Ğ²ĞµÑÑ‚ĞµĞ½ Ñ…Ğ¾ÑÑ‚. ĞŸĞ¾ĞºĞ° Ñ…Ğ¾ÑÑ‚Ğ° Ğ½ĞµÑ‚ - Ğ¾Ğ½Ğ¸ Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´ÑÑ‚ Ğ¼Ğ¸Ğ¼Ğ¾.\nĞ’ *nfqws1* Ğ¾Ğ½Ğ¸ Ğ¿Ğ°Ğ´Ğ°Ğ»Ğ¸ Ğ½Ğ° Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ»Ğ¸ÑÑ‚Ğ¾Ğ¼.\n\n```\nnfqws2 --qnum 200 --debug --lua-init=@zapret-lib.lua --lua-init=@zapret-antidpi.lua \\\n--filter-tcp=80 --filter-l7=http --hostlist=mylist1.txt --lua-desync=multisplit --new \\\n--filter-tcp=80 --filter-l7=http --hostlist-exclude=mylist2.txt --lua-desync=fake:blob=0x00000000:ip_ttl=5:ip6_ttl=3 --lua-desync=multidisorder:pos=5,endhost-1 --new \\\n--filter-tcp=443 --filter-l7=tls --hostlist=mylist1.txt --lua-desync=multidisorder\n```\n\nĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ *nfqws1* start/cutoff (`--dpi-desync-start`, `--dpi-desync-cutoff`, ...) Ñ‚ĞµĞ¿ĞµÑ€ÑŒ Ğ½Ğ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ÑÑ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğ°Ğ¼Ğ¸ (ranges).\nĞÑÑ‚Ğ°Ğ»Ğ¸ÑÑŒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ 2 range : `--in-range` Ğ¸ `--out-range`. ĞĞ½Ğ¸ Ğ¾Ñ‚Ğ½Ğ¾ÑÑÑ‚ÑÑ Ğº Ğ²Ñ…Ğ¾Ğ´ÑÑ‰ĞµĞ¼Ñƒ Ğ¸ Ğ¸ÑÑ…Ğ¾Ğ´ÑÑ‰ĞµĞ¼Ñƒ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾.\nĞ”Ğ°, Ñ‚ĞµĞ¿ĞµÑ€ÑŒ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ñ†ĞµĞ½Ğ½Ğ¾ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ ĞºĞ°Ğº Ñ Ğ²Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğ¼Ğ¸ Ğ¿Ğ°ĞºĞµÑ‚Ğ°Ğ¼Ğ¸, Ñ‚Ğ°Ğº Ğ¸ Ñ Ğ¸ÑÑ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğ¼Ğ¸. Ğ•ÑÑ‚ÑŒ Ğ¸ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼ Ğ´Ğ»Ñ ÑĞµÑ€Ğ²ĞµÑ€Ğ° - `--server`, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹\nĞ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ñ IP Ğ°Ğ´Ñ€ĞµÑĞ¾Ğ² Ğ¸ Ğ¿Ğ¾Ñ€Ñ‚Ğ¾Ğ² Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ°/Ğ¿Ñ€Ğ¸ĞµĞ¼Ğ½Ğ¸ĞºĞ°, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ ipset-Ñ‹ Ğ¸ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹.\n\nrange Ğ·Ğ°Ğ´Ğ°ĞµÑ‚ÑÑ ĞºĞ°Ğº `mX-mY`, `mX<mY`, `-mY`, `<mY`, `mX-`.\nĞ‘ÑƒĞºĞ²Ğ° `m` Ğ¾Ğ·Ğ½Ğ°Ñ‡Ğ°ĞµÑ‚ Ñ€ĞµĞ¶Ğ¸Ğ¼ ÑÑ‡ĞµÑ‚Ñ‡Ğ¸ĞºĞ°. `n` - Ğ½Ğ¾Ğ¼ĞµÑ€ Ğ¿Ğ°ĞºĞµÑ‚Ğ°, `d` - Ğ½Ğ¾Ğ¼ĞµÑ€ Ğ¿Ğ°ĞºĞµÑ‚Ğ° Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸, `b` - ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ±Ğ°Ğ¹Ñ‚, `s` - Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ sequence Ğ´Ğ»Ñ tcp.\nĞŸĞ¾ÑĞ»Ğµ Ğ±ÑƒĞºĞ²Ñ‹ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ° Ğ¿Ğ¸ÑˆĞµÑ‚ÑÑ Ñ‡Ğ¸ÑĞ»Ğ¾. ĞĞ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, `n5-s10000` Ğ¾Ğ·Ğ½Ğ°Ñ‡Ğ°ĞµÑ‚ Ñ 5-Ğ³Ğ¾ Ğ¿Ğ¾ Ğ¾Ñ‡ĞµÑ€ĞµĞ´Ğ¸ Ğ¿Ğ°ĞºĞµÑ‚Ğ° Ğ´Ğ¾ ÑĞ¼ĞµÑ‰ĞµĞ½Ğ¸Ñ 10000 Ğ±Ğ°Ğ¹Ñ‚ Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° tcp ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ.\nĞ•ÑÑ‚ÑŒ Ğ¸ Ñ€ĞµĞ¶Ğ¸Ğ¼Ñ‹, Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒÑ‰Ğ¸Ğµ Ñ‡Ğ¸ÑĞ»Ğ° - `a` - Ğ²ÑĞµĞ³Ğ´Ğ°, `x` - Ğ½Ğ¸ĞºĞ¾Ğ³Ğ´Ğ°.\nĞ•ÑĞ»Ğ¸ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ĞµĞ¼ ÑƒĞºĞ°Ğ·Ğ°Ğ½ Ğ·Ğ½Ğ°Ğº '-' - ĞºĞ¾Ğ½ĞµÑ‡Ğ½Ğ°Ñ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ğ²ĞºĞ»ÑÑ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°, Ğ° ĞµÑĞ»Ğ¸ '<' - Ğ½Ğµ Ğ²ĞºĞ»ÑÑ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°.\n\nĞ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ `--in-range=x --out-range=a --payload all`. Ğ¢Ğ¾ ĞµÑÑ‚ÑŒ Ğ¾Ñ‚ÑĞµĞºĞ°ÑÑ‚ÑÑ Ğ²ÑĞµ Ğ²Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğµ Ğ¿Ğ°ĞºĞµÑ‚Ñ‹ Ğ¸ Ğ±ĞµÑ€ÑƒÑ‚ÑÑ Ğ²ÑĞµ Ğ¸ÑÑ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğµ.\n\n`--in-range`, `--out-range` Ğ¸ `--payload` Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ¿Ñ€Ğ¸ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ Ğ² Ğ¾Ğ´Ğ½Ğ¾Ğ¼ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğµ.\nĞ˜Ñ… Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ Ñ€Ğ°ÑĞ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑĞµÑ‚ÑÑ Ğ½Ğ° Ğ²ÑĞµ Ğ¿Ğ¾ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ `--lua-desync` Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ´Ğ¾ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ³Ğ¾ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ° Ñ‚Ğ¾Ğ³Ğ¾ Ğ¶Ğµ Ñ‚Ğ¸Ğ¿Ğ° Ğ¸Ğ»Ğ¸ Ğ´Ğ¾ ĞºĞ¾Ğ½Ñ†Ğ° Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ñ.\nĞ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ ÑĞ½Ğ¾Ğ²Ğ° Ğ¿Ñ€Ğ¸Ğ½Ğ¸Ğ¼Ğ°ĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ.\n\nĞ§Ñ‚Ğ¾ Ğ±ÑƒĞ´ĞµÑ‚, ĞµÑĞ»Ğ¸ Ğ²Ñ‹ Ğ½Ğµ Ğ½Ğ°Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€ `--payload` Ğ´Ğ»Ñ fake Ğ¸Ğ»Ğ¸ multisplit ? Ğ’ *nfqws1* Ğ±ĞµĞ· `--dpi-desync-any-protocol` Ğ¾Ğ½Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ğ¾ Ğ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğ¼ Ğ¿ĞµĞ¹Ğ»Ğ¾Ğ°Ğ´Ğ°Ğ¼.\nĞ’ *nfqws2* \"any protocol\" - Ñ€ĞµĞ¶Ğ¸Ğ¼ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ. ĞĞ´Ğ½Ğ°ĞºĞ¾, Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ¸Ğ· Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ¸ `zapret-antidpi.lua` Ğ½Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ñ‹ Ñ‚Ğ°Ğº, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ğ¾ Ğ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğ¼ Ğ¿ĞµĞ¹Ğ»Ğ¾Ğ°Ğ´Ğ°Ğ¼\nĞ¸ Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚ Ğ¿Ğ¾ Ğ¿ÑƒÑÑ‚Ñ‹Ğ¼ Ğ¿Ğ°ĞºĞµÑ‚Ğ°Ğ¼ Ğ¸Ğ»Ğ¸ unknown - Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ñ‚Ğ°Ğº Ğ¶Ğµ, ĞºĞ°Ğº ÑÑ‚Ğ¾ Ğ±Ñ‹Ğ»Ğ¾ Ğ² *nfqws1*.\nĞĞ¾ Ğ»ÑƒÑ‡ÑˆĞµ Ğ²ÑĞµ-Ğ¶Ğµ Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹ `--payload`, Ğ¿Ğ¾Ñ‚Ğ¾Ğ¼Ñƒ Ñ‡Ñ‚Ğ¾ Ğ¾Ğ½Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚ Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ C ĞºĞ¾Ğ´Ğ°, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ÑÑ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ, Ñ‡ĞµĞ¼ Lua.\n\nĞ”Ğ¸ÑÑĞµĞºÑ‚ Ğ¿Ğ°ĞºĞµÑ‚Ğ° Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ¿Ğ¾Ğ¾Ñ‡ĞµÑ€ĞµĞ´Ğ½Ğ¾ Ğ¿Ğ¾ Ğ²ÑĞµĞ¼ `--lua-desync` Ğ¸Ğ½ÑÑ‚Ğ°Ğ½ÑĞ°Ğ¼ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ñ, Ğ´Ğ»Ñ ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ğ½Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ÑÑ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ğµ Ğ¾Ñ‚ÑĞµÑ‡ĞµĞ½Ğ¸Ñ (cutoff).\nĞÑ‚ÑĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ğ¾ range, payload Ğ¸Ğ»Ğ¸ Ğ´Ğ¾Ğ±Ñ€Ğ¾Ğ²Ğ¾Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ñ‚ÑĞµÑ‡ĞµĞ½Ğ¸Ğµ. ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ - ĞºĞ¾Ğ³Ğ´Ğ° Ğ¸Ğ½ÑÑ‚Ğ°Ğ½Ñ ÑĞ°Ğ¼ Ğ¾Ñ‚ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ°ĞºĞµÑ‚Ñ‹\nĞ¿Ğ¾ Ğ²Ñ…Ğ¾Ğ´ÑÑ‰ĞµĞ¼Ñƒ, Ğ¸ÑÑ…Ğ¾Ğ´ÑÑ‰ĞµĞ¼Ñƒ Ğ¸Ğ»Ğ¸ Ğ¾Ğ±Ğ¾Ğ¸Ğ¼ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸ÑĞ¼. ĞĞ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ wsize - Ğ¾Ñ‚Ñ€ĞµĞ°Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½Ğ° Ğ¿Ğ°ĞºĞµÑ‚ Ñ tcp Ñ„Ğ»Ğ°Ğ³Ğ°Ğ¼Ğ¸ SYN,ACK. ĞŸĞ¾ÑĞ»Ğµ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¾Ğ½ Ğ½Ğµ Ğ½ÑƒĞ¶ĞµĞ½, Ğ² ĞºĞ¾Ğ´Ğµ Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¾Ñ‚ÑĞµÑ‡ĞµĞ½Ğ¸Ñ.\nĞ­Ñ‚Ğ¾ ÑĞ´ĞµĞ»Ğ°Ğ½Ğ¾ Ğ´Ğ»Ñ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸ Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€Ğ°.\nĞ•ÑĞ»Ğ¸ Ğ²ÑĞµ Ğ¸Ğ½ÑÑ‚Ğ°Ğ½ÑÑ‹ Ğ² Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ½Ğ¸ĞºĞ¾Ğ³Ğ´Ğ° Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ½Ğµ Ğ±ÑƒĞ´ÑƒÑ‚ Ğ²Ñ‹Ğ·Ğ²Ğ°Ğ½Ñ‹ Ğ¿Ğ¾ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ + Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ - Ğ²Ğ¾ÑˆĞ»Ğ¸ Ğ² Ğ¿Ñ€ĞµĞ²Ñ‹ÑˆĞµĞ½Ğ¸Ğµ Ğ²ĞµÑ€Ñ…Ğ½ĞµĞ¹ Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ range Ğ¸Ğ»Ğ¸ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ğ»Ğ¸ Ğ´Ğ¾Ğ±Ñ€Ğ¾Ğ²Ğ¾Ğ»ÑŒĞ½Ñ‹Ğ¹ cutoff, Ñ‚Ğ¾ Ğ´Ğ²Ğ¸Ğ¶Ğ¾Ğº Lua Ğ½Ğµ Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ²Ğ¾Ğ¾Ğ±Ñ‰Ğµ.\n\nĞÑ‚ Ğ¸Ğ½ÑÑ‚Ğ°Ğ½ÑĞ° Ğº Ğ¸Ğ½ÑÑ‚Ğ°Ğ½ÑÑƒ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ Ğ´Ğ¸ÑÑĞµĞºÑ‚Ğ° Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ¸Ğ¼Ğ¸ Ğ¼ĞµĞ½ÑÑ‚ÑŒÑÑ. Ğ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ Ğ¸Ğ½ÑÑ‚Ğ°Ğ½Ñ Ğ²Ğ¸Ğ´Ğ¸Ñ‚ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰ĞµĞ³Ğ¾.\nĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ¸Ğ½ÑÑ‚Ğ°Ğ½Ñ Ğ²Ñ‹Ğ½Ğ¾ÑĞ¸Ñ‚ ÑĞ²Ğ¾Ğ¹ Ğ²ĞµÑ€Ğ´Ğ¸ĞºÑ‚ - Ñ‡Ñ‚Ğ¾ Ğ´ĞµĞ»Ğ°Ñ‚ÑŒ Ñ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¼ Ğ´Ğ¸ÑÑĞµĞºÑ‚Ğ¾Ğ¼. VERDICT_PASS - Ğ¾Ğ·Ğ½Ğ°Ñ‡Ğ°ĞµÑ‚ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ ĞºĞ°Ğº ĞµÑÑ‚ÑŒ,\nVERDICT_MODIFY - Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ğ²ĞµÑ€ÑĞ¸Ñ, VERDICT_DROP - Ğ´Ñ€Ğ¾Ğ¿Ğ½ÑƒÑ‚ÑŒ Ğ´Ğ¸ÑÑĞµĞºÑ‚ (Ğ½Ğµ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ).\nĞ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ²ĞµÑ€Ğ´Ğ¸ĞºÑ‚ Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ğ²ĞµÑ€Ğ´Ğ¸ĞºÑ‚Ğ¾Ğ² Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ¸Ğ½ÑÑ‚Ğ°Ğ½ÑĞ¾Ğ².\nĞ•ÑĞ»Ğ¸ ĞºĞ°ĞºĞ¾Ğ¹-Ğ»Ğ¸Ğ±Ğ¾ Ğ¸Ğ½ÑÑ‚Ğ°Ğ½Ñ Ğ²Ñ‹Ğ´Ğ°Ğ» VERDICT_DROP - Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ - Ğ²ÑĞµĞ³Ğ´Ğ° VERDICT_DROP.\nĞ•ÑĞ»Ğ¸ Ğ½Ğ¸ Ğ¾Ğ´Ğ¸Ğ½ Ğ¸Ğ½ÑÑ‚Ğ°Ğ½Ñ Ğ½Ğµ Ğ²Ñ‹Ğ´Ğ°Ğ» VERDICT_DROP, Ğ° ĞºĞ°ĞºĞ¾Ğ¹-Ğ»Ğ¸Ğ±Ğ¾ Ğ¸Ğ½ÑÑ‚Ğ°Ğ½Ñ Ğ²Ñ‹Ğ´Ğ°Ğ» VERDICT_MODIFY, Ñ‚Ğ¾ Ğ±ÑƒĞ´ĞµÑ‚ VERDICT_MODIFY.\nĞ•ÑĞ»Ğ¸ Ğ²ÑĞµ Ğ¸Ğ½ÑÑ‚Ğ°Ğ½ÑÑ‹ Ğ²Ñ‹Ğ´Ğ°Ğ»Ğ¸ VERDICT_PASS - Ğ±ÑƒĞ´ĞµÑ‚ VERDICT_PASS.\n\nĞĞ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ pktmod Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ Ñ„ÑƒĞ»Ğ¸Ğ½Ğ³ Ğº Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¼Ñƒ Ğ´Ğ¸ÑÑĞµĞºÑ‚Ñƒ Ğ¸ Ğ²Ñ‹ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ²ĞµÑ€Ğ´Ğ¸ĞºÑ‚ VERDICT_MODIFY.\nĞ•ÑĞ»Ğ¸ Ğ¿Ğ¾ÑĞ»Ğµ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ±ÑƒĞ´ĞµÑ‚ Ğ²Ñ‹Ğ·Ğ²Ğ°Ğ½ Ğ¸Ğ½ÑÑ‚Ğ°Ğ½Ñ multisplit, Ñ‚Ğ¾ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ¾Ğ¹Ğ´ĞµÑ‚ Ñ€ĞµĞ·ĞºĞ° Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ ÑƒĞ¶Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ´Ğ¸ÑÑĞµĞºÑ‚Ğ°, Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ñ‡Ğ°ÑÑ‚ĞµĞ¹ Ğ¸ Ğ² ÑĞ»ÑƒÑ‡Ğ°Ğµ ÑƒÑĞ¿ĞµÑ…Ğ° VERDICT_DROP.\nĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ÑÑ, Ñ‡Ñ‚Ğ¾ Ğ¼Ñ‹ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½Ğ¸Ğ»Ğ¸ Ñ„ÑƒĞ»Ğ¸Ğ½Ğ³ Ğ¸ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ¸ Ñ ÑÑ‚Ğ¸Ğ¼ Ñ„ÑƒĞ»Ğ¸Ğ½Ğ³Ğ¾Ğ¼ Ğ²ÑĞµ tcp ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹.\n\n### ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹ *nfqws1*\n\nĞšÑ€Ğ°Ñ‚ĞºĞ¾, Ğ½Ğ° Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ°Ñ…, Ğ¿Ğ¾ĞºĞ°Ğ¶ĞµĞ¼ ĞºĞ°Ğº ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ Ñ *nfqws1* Ğ¿ĞµÑ€ĞµĞ¿Ğ¸ÑÑ‹Ğ²Ğ°ÑÑ‚ÑÑ Ğ¿Ğ¾Ğ´ *nfqws2*.\nĞ”Ğ»Ñ ĞºÑ€Ğ°Ñ‚ĞºĞ¾ÑÑ‚Ğ¸ Ğ·Ğ´ĞµÑÑŒ Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ñ‹ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¸Ğ²Ñ‹ `--qnum`, `--lua-init`, `--wf-tcp-out` Ğ¸ Ñ‚Ğ¾Ğ¼Ñƒ Ğ¿Ğ¾Ğ´Ğ¾Ğ±Ğ½Ğ¾Ğµ, Ñ‡Ñ‚Ğ¾ Ğ½Ğµ ĞºĞ°ÑĞ°ĞµÑ‚ÑÑ Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹ Ğ¸ Ğ¸Ñ… Ğ½ĞµĞ¿Ğ¾ÑÑ€ĞµĞ´ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑĞ»ÑƒĞ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ.\n\nĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€ `--filter-l7` Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ÑÑ Ğº Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ñƒ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸. Ğ—Ğ´ĞµÑÑŒ Ğ¿Ñ€Ğ¸Ğ²ĞµĞ´ĞµĞ½ ĞºĞ°Ğº ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ, Ñ‡Ñ‚Ğ¾ Ğ±ÑƒĞ´ĞµÑ‚ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ‚ÑŒÑÑ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ».\n\n\nĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ttl Ğ´Ğ»Ñ ipv6 Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ½ĞµÑ‚. ĞÑƒĞ¶Ğ½Ğ¾ Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾ Ğ´Ğ»Ñ ipv4 Ğ¸ ipv6. Ğ•ÑĞ»Ğ¸ Ğ½Ğµ Ğ±ÑƒĞ´ĞµÑ‚ Ğ½Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ğ¾ Ğ´Ğ»Ñ ipv6, Ñ‚Ğ¾ Ğº Ğ½ĞµĞ¼Ñƒ Ğ½Ğµ Ğ±ÑƒĞ´ĞµÑ‚ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½ ttl.\nĞ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ pktmod Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ Ñ„ÑƒĞ»Ğ¸Ğ½Ğ³ Ğº Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¼Ñƒ Ğ´Ğ¸ÑÑĞµĞºÑ‚Ñƒ.\n\n```\nnfqws \\\n --filter-l7=http --dpi-desync=fake --dpi-desync-fake-http=0x00000000 --dpi-desync-ttl=6 \\\n --orig-ttl=1 --orig-mod-start=s1 --orig-mod-cutoff=d1\n\nnfqws2 \\\n --filter-l7=http \\\n --payload=http_req --lua-desync=fake:blob=0x00000000:ip_ttl=6:ip6_ttl=6 \\\n --payload=empty --out-range=\"s1<d1\" --lua-desync=pktmod:ip_ttl=1:ip6_ttl=1\n```\n\nbadseq Ğ±ĞµĞ· Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ² *nfqws1* Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞ» Ğ¸Ğ½ĞºÑ€ĞµĞ¼ĞµĞ½Ñ‚ -10000 Ğ´Ğ»Ñ syn Ğ¸ -66000 Ğ´Ğ»Ñ ack.\nĞ’ Ñ„ÑƒĞ½ĞºÑ†Ğ¸ÑÑ… `zapret-antidpi.lua` Ğ¿Ğ¾Ğ½ÑÑ‚Ğ¸Ñ badseq Ğ½ĞµÑ‚. Ğ•ÑÑ‚ÑŒ Ñ„ÑƒĞ»Ğ¸Ğ½Ğ³Ğ¸ - ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ¸Ñ‚ÑŒ seq Ğ¸Ğ»Ğ¸ ack Ğ½Ğ° ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ.\n\ntcp_ts_up - Ğ¾Ñ‡ĞµĞ½ÑŒ ÑÑ‚Ñ€Ğ°Ğ½Ğ½Ğ¾Ğµ ÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ, Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ğ¾Ğµ Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞµ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ *nfqws2*.\nĞĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ, ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ tcp Ğ¾Ğ¿Ñ†Ğ¸Ñ timestamp, linux ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ Ğ¾Ñ‚Ğ±Ñ€Ğ°ÑÑ‹Ğ²Ğ°ĞµÑ‚ Ğ¿Ğ°ĞºĞµÑ‚Ñ‹ Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¼ seq Ğ¸ Ğ¸Ğ½Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¼ ack Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ Ğ¾Ğ¿Ñ†Ğ¸Ñ Ğ¸Ğ´ĞµÑ‚ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¹.\n*nfqws1* Ğ½Ğµ ÑĞ¾Ğ±Ğ»ÑĞ´Ğ°Ğ» Ğ¿Ğ¾Ñ€ÑĞ´Ğ¾Ğº tcp Ğ¾Ğ¿Ñ†Ğ¸Ğ¹, timestamp Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°Ğ»ÑÑ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¼ Ğ²ÑĞµĞ³Ğ´Ğ°.\nĞŸĞ¾ÑÑ‚Ğ¾Ğ¼Ñƒ Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¾ÑÑŒ, Ñ‡Ñ‚Ğ¾ ÑÑ‚Ğ°Ñ€Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ , Ğ° Ğ½Ğ¾Ğ²Ğ°Ñ Ğ½ĞµÑ‚.\ntcp_ts_up Ğ´ÑƒĞ±Ğ»Ğ¸Ñ€ÑƒĞµÑ‚ ÑÑ‚Ğ°Ñ€Ğ¾Ğµ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ - Ğ´Ğ²Ğ¸Ğ³Ğ°ĞµÑ‚ timestamp Ğ² ÑĞ°Ğ¼Ñ‹Ğ¹ Ğ²ĞµÑ€Ñ….\n\n```\nnfqws \\\n --filter-l7=http \\\n --dpi-desync=fakedsplit --dpi-desync-fooling=badseq --dpi-desync-badseq-increment=0 --dpi-desync-split-pos=method+2\n\nnfqws2 \\\n --filter-l7=http \\\n --payload=http_req --lua-desync=fakedsplit:pos=method+2:tcp_ack=-66000:tcp_ts_up\n```\n\nautottl Ğ¿Ğ¸ÑˆĞµÑ‚ÑÑ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ `delta,min-max`. Ğ’Ğ¼ĞµÑÑ‚Ğ¾ Ğ´Ğ²Ğ¾ĞµÑ‚Ğ¾Ñ‡Ğ¸Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ·Ğ°Ğ¿ÑÑ‚Ğ°Ñ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğµ ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ĞµĞ¼ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸.\n\n```\nnfqws \\\n --filter-l7=tls \\\n --dpi-desync=fakedsplit --dpi-desync-fakedsplit-pattern=tls_clienthello_google_com.bin \\\n --dpi-desync-ttl=1 --dpi-desync-autottl=-1 --dpi-desync-split-pos=method+2 --dpi-desync-fakedsplit-mod=altorder=1\n\nnfqws2 \\\n --blob=tls_google:@tls_clienthello_google_com.bin \\\n --filter-l7=tls \\\n --payload tls_client_hello,http_req \\\n --lua-desync=fakedsplit:pattern=tls_google:pos=method+2:nofake1:ip_ttl=1:ip6_ttl=1:ip_autottl=-1,3-20:ip6_autottl=-1,3-20\n```\n\nĞ—Ğ´ĞµÑÑŒ Ğ²Ğ°Ğ¶ĞµĞ½ Ğ¿Ğ¾Ñ€ÑĞ´Ğ¾Ğº Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ° Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¹.\nwssize Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ ĞºĞ°Ğº Ğ¼Ğ¾Ğ´Ğ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ Ğ´Ğ¸ÑÑĞµĞºÑ‚Ğ° - Ğ¿ĞµÑ€ĞµĞ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚ window size Ğ¸ scale factor. syndata Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ° Ğ±Ñ‹Ñ‚ÑŒ Ğ¾Ñ‚Ğ¾ÑĞ»Ğ°Ğ½Ğ° Ñ Ğ¼Ğ¾Ğ´Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸\nwsize Ğ¸ scale. Ğ•ÑĞ»Ğ¸ Ğ¿ĞµÑ€ĞµĞ¿ÑƒÑ‚Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ñ€ÑĞ´Ğ¾Ğº ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, Ñ‚Ğ¾ syndata Ğ±ÑƒĞ´ĞµÑ‚ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ğ±ĞµĞ· wssize. ĞŸĞ¾ÑĞºĞ¾Ğ»ÑŒĞºÑƒ Ğ²Ğ°Ğ¶Ğ½Ğ° Ğ¼Ğ¾Ğ´Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ, Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°Ñ Ñ SYN Ğ¿Ğ°ĞºĞµÑ‚Ğ°,\nÑ‚Ğ¾ wssize Ğ½Ğµ ÑÑ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ¾Ğ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ñ‹Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ¼.\n\n```\nnfqws --dpi-desync=syndata,multisplit --dpi-desync-split-pos=midsld --wssize 1:6\n\nnfqws2 --lua-desync=wssize:wsize=1:scale=6 --lua-desync=syndata --lua-desync=multisplit:pos=midsld\n```\n\nĞ’ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¼ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğµ Ğ²ÑĞµ Ğ¼Ğ¾Ğ´Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ tls Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑÑÑ‚ÑÑ Ğ½Ğ° Ğ»ĞµÑ‚Ñƒ.\nĞ­Ñ‚Ğ¾ Ñ‚Ğ°Ğº Ğ¶Ğµ Ğ¾Ğ·Ğ½Ğ°Ñ‡Ğ°ĞµÑ‚, Ñ‡Ñ‚Ğ¾ Ñ€Ğ°Ğ½Ğ´Ğ¾Ğ¼Ñ‹ Ğ±ÑƒĞ´ÑƒÑ‚ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑÑ‚ÑŒÑÑ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ñ€Ğ°Ğ·, Ğ° Ğ½Ğµ Ğ¾Ğ´Ğ¸Ğ½ Ñ€Ğ°Ğ·, ĞºĞ°Ğº Ğ² *nfqws1*.\nĞŸĞ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿Ñ€Ğ¸Ğ²ĞµÑÑ‚Ğ¸ Ğº Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ñƒ *nfqws1* Ğ¿Ñ€Ğ¸ Ğ¶ĞµĞ»Ğ°Ğ½Ğ¸Ğ¸ - Ğ²Ğ¾ Ğ²Ñ‚Ğ¾Ñ€Ğ¾Ğ¼ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ½Ğ¾ ĞºĞ°Ğº.\n\n```\nnfqws1 \\\n --filter-l7 tls \\\n --dpi-desync=fake --dpi-desync-fooling=datanoack --dpi-desync-fake-tls=! \\\n --dpi-desync-fake-tls-mod=rnd,rndsni,dupsid\n\nnfqws2\n --filter-l7 tls \\\n --payload=tls_client_hello --lua-desync=fake:blob=fake_default_tls:tcp_flags_unset=ack:tls_mod=rnd,rndsni,dupsid,padencap \\\n --payload=empty --out-range=\"s1<d1\" --lua-desync=pktmod:ip_ttl=1:ip6_ttl=1\n\n\nnfqws2 \\\n --lua-init=\"fake_default_tls=tls_mod(fake_default_tls,'rnd,rndsni')\" \\\n --filter-l7 tls \\\n --payload=tls_client_hello --lua-desync=fake:blob=fake_default_tls:tcp_flags_unset=ack:tls_mod=dupsid,padencap \\\n --payload=empty --out-range=\"s1<d1\" --lua-desync=pktmod:ip_ttl=1:ip6_ttl=1\n```\n\nIP Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ñ‚ĞµĞ¿ĞµÑ€ÑŒ Ğ¾Ğ¿Ñ†Ğ¸ĞµĞ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ° Ğ¾Ñ‚ÑÑ‹Ğ»ĞºĞ¸. Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ send Ğ¾Ñ‚ÑÑ‹Ğ»Ğ°ĞµÑ‚ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ğ´Ğ¸ÑÑĞµĞºÑ‚, Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑÑ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´Ğ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ñ‹, Ğ½Ğ¾ Ğ½Ğµ Ğ´Ñ€Ğ¾Ğ¿Ğ°ĞµÑ‚ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ».\nĞ§Ñ‚Ğ¾Ğ±Ñ‹ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ» Ğ½Ğµ Ğ¿Ğ¾ÑˆĞµĞ» ÑĞ»ĞµĞ´Ğ¾Ğ¼ - Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ÑÑ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ drop. ĞĞ½Ğ° Ğ½Ğ¸Ñ‡ĞµĞ³Ğ¾ Ğ½Ğµ Ğ´ĞµĞ»Ğ°ĞµÑ‚, Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ²Ñ‹Ğ½Ğ¾ÑĞ¸Ñ‚ VERDICT_DROP.\nĞŸÑ€Ğ¸ Ğ¶ĞµĞ»Ğ°Ğ½Ğ¸Ğ¸ ipfrag Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ Ğ¸ Ğº fake, multisplit Ğ¸ Ğ´Ñ€ÑƒĞ³Ğ¸Ğ¼ Ñ„ÑƒĞ½ĞºÑ†Ğ¸ÑĞ¼. Ğ¢Ğ°Ğº Ğ¶Ğµ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ ÑĞ²Ğ¾Ğ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ IP Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸.\nĞ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ ipfrag2 Ğ´ĞµĞ»Ğ¸Ñ‚ Ğ¿Ğ°ĞºĞµÑ‚ Ğ½Ğ° 2 Ñ‡Ğ°ÑÑ‚Ğ¸. ĞĞ¾ Ğ²Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ Ğ½Ğ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ ĞµĞ³Ğ¾ Ğ½Ğ° 10 Ñ‡Ğ°ÑÑ‚ĞµĞ¹ Ğ¸ ÑƒĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ĞµĞµ ĞºĞ°Ğº `ipfrag=my_frag_function`.\nĞ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ´Ğ¸ÑÑĞµĞºÑ‚ Ğ¿Ğ¾Ğ´Ğ»ĞµĞ¶Ğ°Ñ‰ĞµĞ³Ğ¾ Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ°ĞºĞµÑ‚Ğ° Ğ½Ğ° Ğ²Ñ…Ğ¾Ğ´ Ğ¸ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¼Ğ°ÑÑĞ¸Ğ² Ğ´Ğ¸ÑÑĞµĞºÑ‚Ğ¾Ğ² - Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ².\n\n```\nnfqws --dpi-desync=ipfrag2 --dpi-desync-ipfrag-pos-udp=8\nnfqws2 --lua-desync=send:ipfrag:ipfrag_pos_udp=8 --lua-desync=drop\n```\n\nĞ Ğ°ÑÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ğ¼ Ñ‚ĞµĞ¿ĞµÑ€ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ Ğ¸Ğ· zapret-win-bundle. ĞšĞ°Ğº `preset_example.cmd` Ğ±Ñ‹Ğ» Ğ¿ĞµÑ€ĞµĞ¿Ğ¸ÑĞ°Ğ½ Ğ² `preset2_example.cmd`.\n\nĞ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ windivert Ğ¿Ğ¾Ğ¼ĞµĞ½ÑĞ»ÑÑ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¾Ğ´Ğ½Ğ¸Ğ¼ - Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ½ĞµÑ‚ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² `--wf-tcp` Ğ¸ `--wf-udp`. ĞĞ½Ğ¸ Ñ€Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ñ‹ Ğ¿Ğ¾ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸ÑĞ¼ in/out.\nĞ”Ğ»Ñ Ğ¾Ñ‚Ğ»Ğ¾Ğ²Ğ° UDP Ğ½Ğµ Ğ¿ĞµÑ€ĞµÑ…Ğ²Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ²ĞµÑÑŒ udp Ğ¿Ğ¾Ñ€Ñ‚ - Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ÑÑ Ğ¿ĞµĞ¹Ğ»Ğ¾Ğ°Ğ´ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹ windivert. Ğ¢ĞµĞ¼ ÑĞ°Ğ¼Ñ‹Ğ¼ Ğ²Ğ¾ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ· ÑĞºĞ¾Ğ½Ğ¾Ğ¼ÑÑ‚ÑÑ Ñ€ĞµÑÑƒÑ€ÑÑ‹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€Ğ°,\nĞ²Ğ¿Ğ»Ğ¾Ñ‚ÑŒ Ğ´Ğ¾ ÑĞ¾Ñ‚ĞµĞ½ Ñ€Ğ°Ğ·. ĞšĞ¾Ğ³Ğ´Ğ° Ğ¿Ğ¾Ğ¿Ğ°Ğ´ĞµÑ‚ Ñ‡Ñ‚Ğ¾-Ñ‚Ğ¾ Ğ½Ğ° Ğ¼Ğ¾Ñ‰Ğ½ÑƒÑ Ğ²Ñ‹Ğ³Ñ€ÑƒĞ·ĞºÑƒ Ñ‚Ğ¾Ñ€Ñ€ĞµĞ½Ñ‚Ğ°, Ğ¸ Ğ¾Ğ½Ğ° Ğ¿Ğ¾Ğ¹Ğ´ĞµÑ‚ Ñ‡ĞµÑ€ĞµĞ· winws, Ğ²Ñ‹ Ğ²Ğ¿Ğ¾Ğ»Ğ½Ğµ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ ÑĞ»Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºÑƒ Ñ†ĞµĞ»Ğ¾Ğ³Ğ¾ ÑĞ´Ñ€Ğ° CPU\nĞ¸ Ğ²Ğ¾Ğ¹ ĞºÑƒĞ»ĞµÑ€Ğ¾Ğ² Ğ²Ğ°ÑˆĞµĞ³Ğ¾ Ğ½Ğ¾ÑƒÑ‚Ğ°. Ğ Ñ‚Ğ°Ğº ĞµĞ³Ğ¾ Ğ½Ğµ Ğ±ÑƒĞ´ĞµÑ‚.\n\nĞ”Ğ»Ñ TCP Ñ‚Ğ°Ğº Ñ‚Ğ¾Ğ¶Ğµ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ±Ñ‹Ğ»Ğ¾ Ğ±Ñ‹ ÑĞ´ĞµĞ»Ğ°Ñ‚ÑŒ, Ğ½Ğ¾ Ğ½Ğµ Ğ²ÑĞµĞ³Ğ´Ğ°. Ğ’Ğ¾-Ğ¿ĞµÑ€Ğ²Ñ‹Ñ…, Ğ½Ğ°Ğ´Ğ¾ Ğ¿ĞµÑ€ĞµÑ…Ğ²Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ‚ÑŒ SYN Ğ¿Ğ¾ Ğ¿Ğ¾Ñ€Ñ‚Ñƒ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ» conntrack.\nĞĞ¾ ÑÑ‚Ğ¾ Ñ€ĞµÑˆĞ°ĞµĞ¼Ğ¾. Ğ Ñ‡Ñ‚Ğ¾ Ğ½Ğµ Ñ€ĞµÑˆĞ°ĞµĞ¼Ğ¾ - ÑÑ‚Ğ¾ Ğ¿ĞµÑ€ĞµÑ…Ğ²Ğ°Ñ‚ Ğ²Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ñ‡Ğ°ÑÑ‚ĞµĞ¹ kyber tls hello. Ğ˜Ñ… Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¾Ğ¿Ğ¾Ğ·Ğ½Ğ°Ñ‚ÑŒ Ğ±ĞµĞ· ÑĞ²ÑĞ·Ğ¸ Ñ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¼Ğ¸ Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸. ĞŸĞ¾ÑÑ‚Ğ¾Ğ¼Ñƒ Ğ¿ĞµÑ€ĞµÑ…Ğ²Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ²ĞµÑÑŒ Ğ¿Ğ¾Ñ€Ñ‚.\nĞ”Ğ»Ñ HTTP Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ñ€ĞµÑˆĞ°ĞµĞ¼Ñ‹Ğ¹, Ğ¿Ğ¾ÑĞºĞ¾Ğ»ÑŒĞºÑƒ Ñ‚Ğ°Ğ¼ Ğ½ĞµÑ‚ Ñ€ĞµĞ°ÑÑĞµĞ¼Ğ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ², Ğ½Ğ¾ http ÑĞµĞ¹Ñ‡Ğ°Ñ ÑÑ‚Ğ°Ğ» Ğ½Ğ°ÑÑ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ€ĞµĞ´ĞºĞ¸Ğ¼, Ñ‡Ñ‚Ğ¾ Ğ¸ ÑĞ¼Ñ‹ÑĞ»Ğ° Ğ½ĞµÑ‚ Ğ·Ğ°Ğ¼Ğ¾Ñ€Ğ°Ñ‡Ğ¸Ğ²Ğ°Ñ‚ÑŒÑÑ.\n\nĞ’ĞµĞ·Ğ´Ğµ Ñ€Ğ°ÑÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ñ‹ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ `--filter-l7`, Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹ Ğ¿Ğ¾ `--out-range` Ğ¸ Ğ¿Ğ¾ `--payload`. Ğ—Ğ°Ñ‡ĞµĞ¼ ? Ğ’ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¼ Ğ´Ğ»Ñ ÑĞ¾ĞºÑ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ¾Ğ² Lua ĞºĞ¾Ğ´Ğ°, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ·Ğ°Ğ²ĞµĞ´Ğ¾Ğ¼Ğ¾ Ğ¼ĞµĞ´Ğ»ĞµĞ½Ğ½ĞµĞµ C ĞºĞ¾Ğ´Ğ°.\nĞ•ÑĞ»Ğ¸ Ğ¿Ğ°ĞºĞµÑ‚ Ğ½Ğµ Ğ¿Ğ¾Ğ¿Ğ°Ğ´ĞµÑ‚ Ğ² Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸ Ñ Lua - Ğ½Ğ¸ Ğ¾ ĞºĞ°ĞºĞ¾Ğ¼ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğµ ĞºĞ¾Ğ´Ğ° Lua Ñ€ĞµÑ‡Ğ¸ Ğ±Ñ‹Ñ‚ÑŒ Ğ½Ğµ Ğ¼Ğ¾Ğ¶ĞµÑ‚. Ğ•ÑĞ»Ğ¸ Ğ¿Ğ°ĞºĞµÑ‚ Ğ¿Ğ¾Ğ¿Ğ°Ğ» Ğ² Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ Ñ Lua, Ñ‚Ğ¾ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¿ĞµÑ€Ğ²Ñ‹Ñ… 10 Ğ¿Ğ°ĞºĞµÑ‚Ğ¾Ğ² Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ½Ğ°ÑÑ‚ÑƒĞ¿Ğ°ĞµÑ‚ Ğ¾Ñ‚ÑĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ Ğ²ĞµÑ€Ñ…Ğ½ĞµĞ¹ Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ğµ range. Ğ’ÑĞµ Lua Ğ¸Ğ½ÑÑ‚Ğ°Ğ½ÑÑ‹ Ğ²Ñ…Ğ¾Ğ´ÑÑ‚ Ğ² ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ instance cutoff, ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ğ²Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ² ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ \"lua cutoff\" Ğ¿Ğ¾ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ \"out\". Ğ—Ğ½Ğ°Ñ‡Ğ¸Ñ‚ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ¾Ğ² Lua Ğ½Ğµ Ğ±ÑƒĞ´ĞµÑ‚ Ğ²Ğ¾Ğ¾Ğ±Ñ‰Ğµ. ĞĞµ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ¾Ğ², Ğ° Ğ´Ğ°Ğ¶Ğµ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ Ğº Ğ´Ğ²Ğ¸Ğ¶ĞºÑƒ Lua Ñ ĞºĞ°ĞºĞ¾Ğ¹-Ğ»Ğ¸Ğ±Ğ¾ Ñ†ĞµĞ»ÑŒÑ. Ğ‘ÑƒĞ´ĞµÑ‚ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ C ĞºĞ¾Ğ´, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ñ‚ Ğ½Ğ° Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°Ğº \"cutoff\" Ğ¸ ÑÑ€Ğ°Ğ·Ñƒ Ğ¶Ğµ Ğ¾Ñ‚Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ Ğ¿Ğ°ĞºĞµÑ‚.\n\nĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ Ğ¸Ğ¼ĞµĞ½Ğ½Ğ¾ `-d10` ? Ğ§Ñ‚Ğ¾Ğ±Ñ‹ Ñ…Ğ²Ğ°Ñ‚Ğ¸Ğ»Ğ¾ Ğ´Ğ»Ñ Ğ¾Ñ‚Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ½ÑÑ‚Ğ²Ğ° Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ¾Ğ² ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹, ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°Ñ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ñ€ĞµÑ‚Ñ€Ğ°Ğ½ÑĞ¼Ğ¸ÑÑĞ¸Ğ¸ Ğ¸ Ğ¿Ğ»Ğ¾Ñ…ÑƒÑ ÑĞ²ÑĞ·ÑŒ. Ğ’ winws2 Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ Ğ²ĞºĞ»ÑÑ‡ĞµĞ½ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€ `--wf-tcp-empty=0`. ĞĞ½ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€ÑƒĞµÑ‚ Ğ¿ĞµÑ€ĞµÑ…Ğ²Ğ°Ñ‚ Ğ¿ÑƒÑÑ‚Ñ‹Ñ… Ğ¿Ğ°ĞºĞµÑ‚Ğ¾Ğ² Ñ ACK, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ Ğ² 2 Ñ€Ğ°Ğ·Ğ° ÑÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ‚ÑŒ Ğ½Ğ° Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€Ğµ Ğ¿Ñ€Ğ¸ Ğ¸Ğ½Ñ‚ĞµĞ½ÑĞ¸Ğ²Ğ½Ñ‹Ñ… ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸ÑÑ…. ĞŸÑƒÑÑ‚Ñ‹Ğµ ACK Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ½ÑÑ‚Ğ²Ğµ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹ Ğ½Ğµ Ğ½ÑƒĞ¶Ğ½Ñ‹. ĞĞ¾ ÑÑ‚Ğ¾ Ğ¶Ğµ Ğ¸ Ğ»Ğ¾Ğ¼Ğ°ĞµÑ‚ ÑÑ‡ĞµÑ‚Ñ‡Ğ¸Ğº \"n\" - Ğ¾Ğ½ Ğ½Ğµ Ğ±ÑƒĞ´ĞµÑ‚ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¿Ğ°ĞºĞµÑ‚Ğ¾Ğ² Ğ¿Ğ¾ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ. Ğ¡Ñ‡ĞµÑ‚Ñ‡Ğ¸Ğº \"d\" Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ±ÑƒĞ´ĞµÑ‚ ĞºĞ°Ğº Ğ½Ğ°Ğ´Ğ¾.\n\nĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ Ğ½ĞµÑ‚ \"-d10\" Ğ½Ğ° udp ? ĞŸĞ¾Ñ‚Ğ¾Ğ¼Ñƒ Ñ‡Ñ‚Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ windivert Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€ Ğ½Ğ° Ğ¿ĞµĞ¹Ğ»Ğ¾Ğ°Ğ´. Ğ¡Ñ‡ĞµÑ‚Ñ‡Ğ¸ĞºĞ¸ Ğ±ÑƒĞ´ÑƒÑ‚ ÑÑ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ğ½Ğµ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¿Ğ°ĞºĞµÑ‚Ğ¾Ğ² Ğ² Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞµ, Ğ° ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¿ĞµÑ€ĞµÑ…Ğ²Ğ°Ñ‡ĞµĞ½Ğ½Ñ‹Ñ… Ñ Ğ¾Ñ‚Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿ĞµĞ¹Ğ»Ğ¾Ğ°Ğ´Ğ°Ğ¼Ğ¸. ĞŸÑ€Ğ¸Ñ‡ĞµĞ¼ ĞµÑĞ»Ğ¸ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ» Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ½Ğ¸Ğ¼Ğ¸ Ğ±ÑƒĞ´ĞµÑ‚ Ğ±Ğ¾Ğ»ĞµĞµ 1 Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹, Ñ‚Ğ¾ ÑÑ‡ĞµÑ‚ Ğ±ÑƒĞ´ĞµÑ‚ Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°Ñ‚ÑŒÑÑ Ğ·Ğ°Ğ½Ğ¾Ğ²Ğ¾, Ğ¿Ğ¾ÑĞºĞ¾Ğ»ÑŒĞºÑƒ Ñ‚Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚ udp Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ - 60 ÑĞµĞº. ĞŸĞ¾ÑĞ»Ğµ Ñ‚Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚Ğ° Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ conntrack Ğ±ÑƒĞ´ĞµÑ‚ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ°. Ğ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ Ğ¿Ğ°ĞºĞµÑ‚ Ğ¿Ğ¾Ğ¹Ğ´ĞµÑ‚ ĞºĞ°Ğº Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ñ‚Ğ¾Ğº.\n\nĞ¢Ğ°Ğº Ğ¶Ğµ Ğ²ĞµĞ·Ğ´Ğµ Ñ€Ğ°ÑÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ñ‹ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹ Ğ¿Ğ¾ payload type. ĞÑ‚Ñ‡Ğ°ÑÑ‚Ğ¸ Ñ‚Ğ°Ğº Ğ¶Ğµ Ñ Ñ†ĞµĞ»ÑŒÑ ÑĞ¾ĞºÑ€Ğ°Ñ‚Ğ¸Ñ‚ÑŒ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ñ‹ Lua Ğ´Ğ°Ğ¶Ğµ Ğ² Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ°Ñ… Ğ¿ĞµÑ€Ğ²Ñ‹Ñ… 10 Ğ¿Ğ°ĞºĞµÑ‚Ğ¾Ğ² Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸.\nĞ¡ Ğ´Ñ€ÑƒĞ³Ğ¾Ğ¹ ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ñ‹, Ğ´Ğ°Ğ¶Ğµ Ğ¿Ñ€Ğ¸ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ»Ğ° ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ (`--filter-l7`) Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ¶Ğ°Ñ‚ÑŒ Ğ½Ğµ Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑÑƒÑÑ‰Ğ¸Ğ¹ Ğ½Ğ°Ñ Ğ¿ĞµĞ¹Ğ»Ğ¾Ğ°Ğ´.\nĞŸĞ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¸Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ¸Ğ· `zapret-antidpi.lua` Ñ€ĞµĞ°Ğ³Ğ¸Ñ€ÑƒÑÑ‚ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½Ğ° Ğ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğµ Ñ‚Ğ¸Ğ¿Ñ‹ Ğ¿ĞµĞ¹Ğ»Ğ¾Ğ°Ğ´Ğ°, Ğ½Ğ¾ Ğ½Ğµ Ğ½Ğ° ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğµ, Ğ° Ğ½Ğ° Ğ»ÑĞ±Ñ‹Ğµ Ğ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğµ.\nĞ•ÑĞ»Ğ¸ Ğ´Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ğ¼Ğ°Ğ»Ğ¾Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹, Ğ½Ğ¾ Ğ³Ğ¸Ğ¿Ğ¾Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ğ¹ ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¹, Ñ‡Ñ‚Ğ¾ Ğ² Ñ€Ğ°Ğ¼ĞºĞ°Ñ… Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ»Ğ° http Ğ±ÑƒĞ´ĞµÑ‚ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½ Ğ±Ğ»Ğ¾Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ tls Ğ¸Ğ»Ğ¸ Ñ„Ñ€Ğ°Ğ·Ğ°, Ğ¿Ğ¾Ñ…Ğ¾Ğ¶Ğ°Ñ Ğ½Ğ° ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ¸Ğ· xmpp, Ñ‚Ğ¾ Ñ‚Ğ¸Ğ¿ Ğ¿ĞµĞ¹Ğ»Ğ¾Ğ°Ğ´Ğ° Ğ²Ñ‹ÑĞºĞ¾Ñ‡Ğ¸Ñ‚ tls_client_hello Ğ¸Ğ»Ğ¸ xmpp_stream, Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€. Ğ›ÑƒÑ‡ÑˆĞµ Ğ¾Ñ‚ ÑÑ‚Ğ¾Ğ³Ğ¾ ÑÑ€Ğ°Ğ·Ñƒ ÑƒĞ±ĞµÑ€ĞµÑ‡ÑŒÑÑ. Ğ¢ĞµĞ¼ Ğ±Ğ¾Ğ»ĞµĞµ Ñ‡Ñ‚Ğ¾ Ğ² Ğ´Ñ€ÑƒĞ³Ğ¸Ñ… Ğ²Ğ¸Ğ´Ğ°Ñ… Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ»Ğ¾Ğ² - xmpp, Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, -\nĞ¿ĞµĞ¹Ğ»Ğ¾Ğ°Ğ´Ñ‹ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ¿Ñ€Ğ¾ÑĞºĞ°ĞºĞ¸Ğ²Ğ°Ñ‚ÑŒ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ñ‚Ğ¸Ğ¿Ğ¾Ğ² Ğ²Ğ¿Ğ¾Ğ»Ğ½Ğµ Ğ¾Ğ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ğ¾. ĞĞ¾ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ½Ğ°Ğ´Ğ¾ Ğ½Ğµ Ğ¿Ğ¾ Ğ²ÑĞµĞ¼.\n\nĞ’ Ñ„ĞµĞ¹ĞºĞµ Ğ´Ğ»Ñ TLS Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ - fake_default_tls - Ğ¾Ğ´Ğ½Ğ¾ĞºÑ€Ğ°Ñ‚Ğ½Ğ¾ Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ°Ñ€Ñ‚Ğµ Ğ¼ĞµĞ½ÑĞµÑ‚ÑÑ SNI Ñ \"www.microsoft.com\" Ğ½Ğ° ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğ¹ Ğ¸ Ñ€Ğ°Ğ½Ğ´Ğ¾Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ Ğ¿Ğ¾Ğ»Ğµ \"random\" Ğ² TLS handshake.\nĞ­Ñ‚Ğ¾ Ğ´ĞµĞ»Ğ°ĞµÑ‚ÑÑ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ¹ ÑÑ‚Ñ€Ğ¾Ñ‡ĞºĞ¾Ğ¹ Lua ĞºĞ¾Ğ´Ğ°. Ğ‘Ğ¾Ğ»ÑŒÑˆĞµ Ğ½ĞµÑ‚ Ğ½Ğ¸ĞºĞ°ĞºĞ¸Ñ… ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² *nfqws2* Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ¿ĞµĞ¹Ğ»Ğ¾Ğ°Ğ´Ğ¾Ğ².\nĞ’ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğµ Ğ´Ğ»Ñ youtube Ğ½Ğ° Ğ»ĞµÑ‚Ñƒ Ğ¼ĞµĞ½ÑĞµÑ‚ÑÑ SNI Ğ½Ğ° \"www.google.com\", ĞºĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ Ğ¿Ğ¾Ğ»Ğµ TLS \"session id\" Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼Ğ¾Ğ³Ğ¾ Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚ TLS handshake.\n\n```\nstart \"zapret: http,https,quic\" /min \"%~dp0winws.exe\" ^\n--wf-tcp=80,443 ^\n--wf-raw-part=@\"%~dp0windivert.filter\\windivert_part.discord_media.txt\" ^\n--wf-raw-part=@\"%~dp0windivert.filter\\windivert_part.stun.txt\" ^\n--wf-raw-part=@\"%~dp0windivert.filter\\windivert_part.wireguard.txt\" ^\n--wf-raw-part=@\"%~dp0windivert.filter\\windivert_part.quic_initial_ietf.txt\" ^\n--filter-tcp=80 --dpi-desync=fake,fakedsplit --dpi-desync-autottl=2 --dpi-desync-fooling=md5sig --new ^\n--filter-tcp=443 --hostlist=\"%~dp0files\\list-youtube.txt\" --dpi-desync=fake,multidisorder --dpi-desync-split-pos=1,midsld --dpi-desync-repeats=11 --dpi-desync-fooling=md5sig --dpi-desync-fake-tls-mod=rnd,dupsid,sni=www.google.com --new ^\n--filter-tcp=443 --dpi-desync=fake,multidisorder --dpi-desync-split-pos=midsld --dpi-desync-repeats=6 --dpi-desync-fooling=badseq,md5sig --new ^\n--filter-l7=quic --hostlist=\"%~dp0files\\list-youtube.txt\" --dpi-desync=fake --dpi-desync-repeats=11 --dpi-desync-fake-quic=\"%~dp0files\\quic_initial_www_google_com.bin\" --new ^\n--filter-l7=quic --dpi-desync=fake --dpi-desync-repeats=11 ^\n--filter-l7=wireguard,stun,discord --dpi-desync=fake --dpi-desync-repeats=2\n\n\nstart \"zapret: http,https,quic\" /min \"%~dp0winws2.exe\" ^\n--wf-tcp-out=80,443 ^\n--lua-init=@\"%~dp0lua\\zapret-lib.lua\" --lua-init=@\"%~dp0lua\\zapret-antidpi.lua\" ^\n--lua-init=\"fake_default_tls = tls_mod(fake_default_tls,'rnd,rndsni')\" ^\n--blob=quic_google:@\"%~dp0files\\quic_initial_www_google_com.bin\" ^\n--wf-raw-part=@\"%~dp0windivert.filter\\windivert_part.discord_media.txt\" ^\n--wf-raw-part=@\"%~dp0windivert.filter\\windivert_part.stun.txt\" ^\n--wf-raw-part=@\"%~dp0windivert.filter\\windivert_part.wireguard.txt\" ^\n--wf-raw-part=@\"%~dp0windivert.filter\\windivert_part.quic_initial_ietf.txt\" ^\n--filter-tcp=80 --filter-l7=http ^\n  --out-range=-d10 ^\n  --payload=http_req ^\n   --lua-desync=fake:blob=fake_default_http:ip_autottl=-2,3-20:ip6_autottl=-2,3-20:tcp_md5 ^\n   --lua-desync=fakedsplit:ip_autottl=-2,3-20:ip6_autottl=-2,3-20:tcp_md5 ^\n  --new ^\n--filter-tcp=443 --filter-l7=tls --hostlist=\"%~dp0files\\list-youtube.txt\" ^\n  --out-range=-d10 ^\n  --payload=tls_client_hello ^\n   --lua-desync=fake:blob=fake_default_tls:tcp_md5:repeats=11:tls_mod=rnd,dupsid,sni=www.google.com ^\n   --lua-desync=multidisorder:pos=1,midsld ^\n  --new ^\n--filter-tcp=443 --filter-l7=tls ^\n  --out-range=-d10 ^\n  --payload=tls_client_hello ^\n   --lua-desync=fake:blob=fake_default_tls:tcp_md5:tcp_seq=-10000:repeats=6 ^\n   --lua-desync=multidisorder:pos=midsld ^\n  --new ^\n--filter-udp=443 --filter-l7=quic --hostlist=\"%~dp0files\\list-youtube.txt\" ^\n  --payload=quic_initial ^\n   --lua-desync=fake:blob=quic_google:repeats=11 ^\n  --new ^\n--filter-udp=443 --filter-l7=quic ^\n  --payload=quic_initial ^\n   --lua-desync=fake:blob=fake_default_quic:repeats=11 ^\n  --new ^\n--filter-l7=wireguard,stun,discord ^\n  --payload=wireguard_initiation,wireguard_cookie,stun,discord_ip_discovery ^\n   --lua-desync=fake:blob=0x00000000000000000000000000000000:repeats=2\n```\n\nĞ˜ Ğ½Ğ°Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğº ÑÑ‚Ğ¾Ğ¸Ñ‚ Ğ¿Ñ€Ğ¾Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºĞ°Ğº Ğ´ĞµĞ»Ğ°ÑÑ‚ÑÑ Ğ½ĞµÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğµ Ğ²ĞµÑ‰Ğ¸. Ğ¢Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ½ĞµĞ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ² Ñ‡Ğ¸ÑÑ‚Ğ¾ Ğ¾Ğ¿Ğ¸ÑĞ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ğ¸Ğ´Ğµ\nĞ² Ñ„Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¼ ĞºĞ¾Ğ´Ğµ, Ğ½Ğµ Ğ¿Ñ€ĞµĞ²Ñ€Ğ°Ñ‰Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñƒ Ğ² Ğ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¾-ĞºĞ¾Ğ¼Ğ±Ğ°Ğ¹Ğ½, Ğ¿ĞµÑ€ĞµĞ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ‡Ğ°ÑÑ‚Ğ½Ñ‹Ğ¼Ğ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸ÑĞ¼Ğ¸ Ğ¸ Ñ€Ğ°Ğ·Ğ²Ğ°Ğ»Ğ¸Ğ²Ğ°ÑÑ‰Ğ¸Ğ¹ÑÑ Ğ¿Ğ¾Ğ´ ÑĞ²Ğ¾ĞµĞ¹ Ñ‚ÑĞ¶ĞµÑÑ‚ÑŒÑ ÑĞ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½ĞµĞ¼,\nĞºĞ¾Ğ³Ğ´Ğ° ÑÑ‚Ğ¸ Ñ‡Ğ°ÑÑ‚Ğ½Ñ‹Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ¿ĞµÑ€ĞµÑÑ‚Ğ°ÑÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ½ÑƒĞ¶Ğ½Ñ‹ Ğ¸ Ğ·Ğ°Ğ±Ñ‹Ğ²Ğ°ÑÑ‚ÑÑ.\n\nĞĞ°Ğ´Ğ¾ Ğ¿Ğ¾ÑĞ»Ğ°Ñ‚ÑŒ Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ Ğ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğ¼ Ğ¿ĞµĞ¹Ğ»Ğ¾Ğ°Ğ´Ğ¾Ğ¼ Ñ seqovl ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ° Ğ¾Ñ‚ 5 Ğ´Ğ¾ 10 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ² ÑĞ¾ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğ¼ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ñ‹Ğ¼, ÑĞ¾ÑÑ‚Ğ¾ÑÑ‰Ğ¸Ğ¼ Ğ¸Ğ· Ğ±ÑƒĞºĞ² Ğ¾Ñ‚ â€˜aâ€™ Ğ´Ğ¾ â€˜zâ€™.\nĞ—Ğ´ĞµÑÑŒ Ñ€Ğ°ÑĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ½Ğµ Ğ´ĞµĞºĞ»Ğ°Ñ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹, Ğ° Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹. Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ - ÑÑ‚Ğ¾ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ°, Ğ¸ Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ ĞµĞµ Ğ²Ñ‹ Ğ½Ğ° ÑĞ·Ñ‹ĞºĞµ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ.\nĞ”Ğ»Ñ Ğ¾Ğ±Ğ»ĞµĞ³Ñ‡ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ñ… Ğ¸Ğ»Ğ¸ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ñ… Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ ĞµÑÑ‚ÑŒ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğµ ÑÑ€ĞµĞ´ÑÑ‚Ğ²Ğ°, Ñ‚Ğ°Ğº Ñ‡Ñ‚Ğ¾ Ğ´Ğ°Ğ»ĞµĞºĞ¾ Ğ½Ğµ Ğ²ÑĞµĞ³Ğ´Ğ° Ğ½Ğ°Ğ´Ğ¾ Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ ÑĞ²Ğ¾Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ.\nĞ§Ğ°ÑÑ‚ĞµĞ½ÑŒĞºĞ¾ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¾Ğ±Ğ¾Ğ¹Ñ‚Ğ¸ÑÑŒ Ğ¿Ñ€Ğ¾ÑÑ‚ĞµĞ½ÑŒĞºĞ¸Ğ¼Ğ¸ ĞºÑƒÑĞºĞ°Ğ¼Ğ¸ Lua ĞºĞ¾Ğ´Ğ° Ğ² Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğº Ğ¸Ğ¼ĞµÑÑ‰Ğ¸Ğ¼ÑÑ.\n\nĞ—Ğ´ĞµÑÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ `luaexec`, Ğ¿Ñ€ĞµĞ´Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ½Ğ°Ñ Ğ´Ğ»Ñ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Lua ĞºĞ¾Ğ´Ğ° Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞµ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ğ´Ğ¸ÑÑĞµĞºÑ‚Ğ°.\nĞĞ½Ğ° Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚Ñ€ĞµĞ±ÑƒĞµĞ¼Ñ‹Ğ¹ blob, Ğ·Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°Ñ ĞµĞ³Ğ¾ Ğ² Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñƒ desync, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿ĞµÑ€ĞµĞ´Ğ°ĞµÑ‚ÑÑ Ğ¾Ñ‚ Ğ¸Ğ½ÑÑ‚Ğ°Ğ½ÑĞ° Ğº Ğ¸Ğ½ÑÑ‚Ğ°Ğ½ÑÑƒ.\nĞ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ Ğ¸Ğ½ÑÑ‚Ğ°Ğ½Ñ `tcpseg` Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ `rnd` ĞºĞ°Ğº blob - Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº seqovl Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ°.\n\nĞ¡Ğ¸Ğ¼Ğ²Ğ¾Ğ»Ñ‹ `%` Ğ¸ `#` Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ÑÑ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±Ğ»Ğ¾Ğ±Ğ¾Ğ² Ğ¸ Ğ¿Ğ¾Ğ´ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸ Ğ¸Ñ… Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ° ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾. Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ C ĞºĞ¾Ğ´Ğ°.\ndesync Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ ÑƒĞ¶Ğµ Ğ¿Ğ¾Ğ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ. Ğ’ Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¼ ÑĞ»ÑƒÑ‡Ğ°Ğµ seqovl ÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ ĞºĞ°Ğº Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ±Ğ»Ğ¾Ğ±Ğ°.\n\nĞ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ `tcpseg` Ğ¿Ñ€ĞµĞ´Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ° Ğ´Ğ»Ñ Ğ¾Ñ‚ÑÑ‹Ğ»ĞºĞ¸ tcp ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ° - Ñ‡Ğ°ÑÑ‚Ğ¸ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ğ¿ĞµĞ¹Ğ»Ğ¾Ğ°Ğ´Ğ° (Ğ¸Ğ»Ğ¸ Ñ€ĞµĞ°ÑĞ¼Ğ° - ÑĞ±Ğ¾Ñ€ĞºĞ¸ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ğ¿Ğ°ĞºĞµÑ‚Ğ¾Ğ², Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ Ğ² ÑĞ»ÑƒÑ‡Ğ°Ğµ tls kyber).\n`pos=0,-1` - ÑÑ‚Ğ¾ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½, ÑĞ¾ÑÑ‚Ğ¾ÑÑ‰Ğ¸Ğ¹ Ğ¸Ğ· Ğ´Ğ²ÑƒÑ… Ğ¼Ğ°Ñ€ĞºĞµÑ€Ğ¾Ğ² - Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¸ ĞºĞ¾Ğ½Ñ†Ğ°. 0 - Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ±ÑĞ¾Ğ»ÑÑ‚Ğ½Ñ‹Ğ¹ Ğ¼Ğ°Ñ€ĞºĞµÑ€, ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¹ Ğ½Ğ°Ñ‡Ğ°Ğ»Ñƒ Ğ¿Ğ°ĞºĞµÑ‚Ğ°.\n-1 - Ğ¾Ñ‚Ñ€Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ±ÑĞ¾Ğ»ÑÑ‚Ğ½Ñ‹Ğ¹ Ğ¼Ğ°Ñ€ĞºĞµÑ€, ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¹ ĞºĞ¾Ğ½Ñ†Ñƒ Ğ¿Ğ°ĞºĞµÑ‚Ğ°. ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ÑÑ, Ğ¼Ñ‹ Ğ¾Ñ‚ÑÑ‹Ğ»Ğ°ĞµĞ¼ Ñ†ĞµĞ»Ğ¸ĞºĞ¾Ğ¼ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ğ¿ĞµĞ¹Ğ»Ğ¾Ğ°Ğ´, Ğ½Ğ¾ Ñ seqovl.\n`tcpseg` Ğ½Ğµ Ğ´Ñ€Ğ¾Ğ¿Ğ°ĞµÑ‚ Ğ¿Ğ°ĞºĞµÑ‚. Ğ•Ğ³Ğ¾ Ğ½Ğ°Ğ´Ğ¾ Ğ´Ñ€Ğ¾Ğ¿Ğ½ÑƒÑ‚ÑŒ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾. ĞŸĞ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ `tcpseg` Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ Ğ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿ĞµĞ¹Ğ»Ğ¾Ğ°Ğ´Ğ°Ğ¼Ğ¸, Ğ° Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ `drop` - Ñ Ğ»ÑĞ±Ñ‹Ğ¼Ğ¸.\nĞŸĞ¾ÑÑ‚Ğ¾Ğ¼Ñƒ Ğ½ÑƒĞ¶Ğ½Ğ¾ ĞµĞ¹ ÑƒĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ´Ñ€Ğ¾Ğ¿Ğ°Ñ‚ÑŒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğµ Ğ¿ĞµĞ¹Ğ»Ğ¾Ğ°Ğ´Ñ‹.\n\nĞ¢Ğ°ĞºĞ°Ñ ÑĞ²ÑĞ·ĞºĞ° Ğ¸Ğ· 3 Ğ¸Ğ½ÑÑ‚Ğ°Ğ½ÑĞ¾Ğ² Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ½ÑƒÑ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ğ±ĞµĞ· ĞºÑƒÑ‡Ğ¸ Ñ‡Ğ°ÑÑ‚Ğ½Ñ‹Ñ… Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ²Ğ¸Ğ´Ğ° `--dpi-desync...`.\n\n```\nnfqws2 \\\n --lua-desync=luaexec:code='desync.rnd=brandom_az(math.random(5,10))' \\\n --lua-desync=tcpseg:pos=0,-1:seqovl=#rnd:seqovl_pattern=rnd \\\n --lua-desync=drop:payload=known\n```\n\n### ĞšĞ°ĞºĞ¸Ğµ ĞµÑÑ‚ÑŒ ĞµÑ‰Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹\n\nĞšĞ°Ğº ÑƒĞ·Ğ½Ğ°Ñ‚ÑŒ ĞºĞ°ĞºĞ¸Ğµ ĞµÑÑ‚ÑŒ ĞµÑ‰Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ¸ ĞºĞ°ĞºĞ¸Ğµ Ñƒ Ğ½Ğ¸Ñ… Ğ±Ñ‹Ğ²Ğ°ÑÑ‚ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ ? Ğ¡Ğ¼Ğ¾Ñ‚Ñ€Ğ¸Ñ‚Ğµ `zapret-antidpi.lua`. ĞŸĞµÑ€ĞµĞ´ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ñ„ÑƒĞ½ĞºÑ†Ğ¸ĞµĞ¹ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¾ ĞºĞ°ĞºĞ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ¾Ğ½Ğ° Ğ±ĞµÑ€ĞµÑ‚.\nĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ñ… Ğ±Ğ»Ğ¾ĞºĞ¾Ğ² Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² ĞµÑÑ‚ÑŒ Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğµ. ĞŸĞ¾Ğ·Ğ¶Ğµ - Ğ¿Ğ¾ Ğ¼ĞµÑ€Ğµ ÑĞ¸Ğ» Ğ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹ - Ğ±ÑƒĞ´ĞµÑ‚ Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒÑÑ Ñ‚Ğ°Ğ»Ğ¼ÑƒĞ´ - ÑĞ¿Ñ€Ğ°Ğ²Ğ¾Ñ‡Ğ½Ğ¸Ğº Ñ Ñ€ÑƒĞºĞ¾Ğ²Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾Ğ¼ Ğ¿Ğ¾ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ\n*nfqws2* Ğ¸ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ñ… Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞº.\n\n### ĞÑ‡ĞµĞ½ÑŒ Ğ²Ğ°Ğ¶Ğ½Ñ‹Ğ¹ ÑĞ¾Ğ²ĞµÑ‚\n\nĞĞ°ÑƒÑ‡Ğ¸Ñ‚ĞµÑÑŒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ `--debug` Ğ»Ğ¾Ğ³Ğ¾Ğ¼. Ğ‘ĞµĞ· Ğ½ĞµĞ³Ğ¾ Ğ±ÑƒĞ´ĞµÑ‚ Ğ¾Ñ‡ĞµĞ½ÑŒ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿Ğ¾Ğ½ÑÑ‚ÑŒ *nfqws2* Ğ½Ğ° Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¼ ÑÑ‚Ğ°Ğ¿Ğµ Ğ¸ Ğ¿Ñ€Ğ¸ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ¸Ñ‚ÑŒÑÑ Ğº Ğ½Ğ¾Ğ²Ğ¾Ğ¹ ÑÑ…ĞµĞ¼Ğµ.\nĞÑˆĞ¸Ğ±Ğ¾Ğº Ğ±ÑƒĞ´ĞµÑ‚ Ğ¼Ğ½Ğ¾Ğ³Ğ¾. ĞÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾, ĞºĞ¾Ğ³Ğ´Ğ° Ğ²Ñ‹ Ğ½Ğ°Ñ‡Ğ½ĞµÑ‚Ğµ Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ ÑĞ²Ğ¾Ğ¹ Lua ĞºĞ¾Ğ´. Ğ˜Ñ… Ğ½Ğ°Ğ´Ğ¾ Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ.\n\n### ĞĞµ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ»Ğ¸ÑˆÑŒ Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ñ‹Ğ¹ Ğ¾Ğ±Ğ¼Ğ°Ğ½ DPI\n\nĞ Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ğ¹ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ icmp Ğ¾Ğ±Ñ„ÑƒÑĞºĞ°Ñ‚Ğ¾Ñ€Ğ° udp Ğ¾Ñ‚ Ğ²Ğ¸Ğ½Ğ´Ñ‹ Ğº ÑĞµÑ€Ğ²ĞµÑ€Ñƒ Ğ½Ğ° vps.\nĞ”Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ wireguard. ĞĞ¸Ñ‡ĞµĞ³Ğ¾ Ğ² ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğ°Ñ… Ğ¼ĞµĞ½ÑÑ‚ÑŒ Ğ½Ğµ Ğ½Ğ°Ğ´Ğ¾ - wireguard Ğ±ÑƒĞ´ĞµÑ‚ Ğ´ÑƒĞ¼Ğ°Ñ‚ÑŒ, Ñ‡Ñ‚Ğ¾ Ğ¾Ğ½ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ¿Ğ¾ udp, Ğ½Ğ¾ Ğ½Ğ° ÑĞ°Ğ¼Ğ¾Ğ¼ Ğ´ĞµĞ»Ğµ Ğ¾Ğ½ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ÑÑ Ğ² Ğ¿Ğ¸Ğ½Ğ³Ğ¸ icmp, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´Ğ¸Ñ‚ÑŒ NAT. Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ¿Ğ°ĞºĞµÑ‚Ğ¾Ğ² Ğ½Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½ÑĞµÑ‚ÑÑ, Ğ¿Ğ¾Ñ‚Ğ¾Ğ¼Ñƒ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ MTU Ğ½ĞµÑ‚.\n\nĞ‘ÑƒĞ´ĞµĞ¼ Ğ·Ğ°Ğ³Ğ¾Ğ½ÑÑ‚ÑŒ Ğ¸ÑÑ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğµ Ñ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ° Ğ² icmp type 8 (echo request) code 199 , Ğ¸ÑÑ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğµ Ñ ÑĞµÑ€Ğ²ĞµÑ€Ğ° Ğ² icmp type 0 (echo reply) code 199.\nĞšĞ¾Ğ´ Ñƒ Ğ¾Ğ±Ğ¾Ğ¸Ñ… ĞºĞ¾Ğ½Ñ†Ğ¾Ğ² Ğ´ĞµĞ»Ğ°ĞµĞ¼ Ğ¾Ğ´Ğ¸Ğ½Ğ°ĞºĞ¾Ğ²Ñ‹Ğ¹, Ğ¸Ğ½Ğ°Ñ‡Ğµ NAT Ğ½Ğµ ÑĞ¾Ğ¾Ñ‚Ğ½ĞµÑĞµÑ‚. Ğ‘ĞµĞ· NAT Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ĞºĞ¾Ğ´Ñ‹ Ğ´ĞµĞ»Ğ°Ñ‚ÑŒ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ»Ñ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ° Ğ¸ ÑĞµÑ€Ğ²ĞµÑ€Ğ°.\nĞÑĞ¾Ğ±Ñ‹Ğ¹ icmp code Ğ½ÑƒĞ¶ĞµĞ½ Ğ´Ğ»Ñ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ñ‚ Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ñ‹Ñ… Ğ¿Ğ¸Ğ½Ğ³Ğ¾Ğ².\n\nĞŸĞ¾ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ñƒ ĞºĞ¾Ğ´ Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ 0, Ğ½Ğ¾ Ğ½Ğ° Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸ĞºĞµ Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¹ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒÑ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚ Ğ»ÑĞ±Ñ‹Ğµ ĞºĞ¾Ğ´Ñ‹.\nĞ Ğ°Ğ·Ğ½Ñ‹Ğµ Ğ¸Ğ¼Ğ¿Ğ»ĞµĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ NAT Ñ‚ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ½ĞµĞ½ÑƒĞ»ĞµĞ²Ğ¾Ğ¹ ĞºĞ¾Ğ´, ÑĞ¾Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ÑŒ Ğ¸Ğ»Ğ¸ Ğ½Ğµ ÑĞ¾Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ÑŒ ĞºĞ¾Ğ´ Ğ²Ğ¼ĞµÑÑ‚Ğµ Ñ identifier. Linux NAT ÑĞ¾Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚.\nĞŸÑ€Ğ¸ Ğ»ÑĞ±Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°Ñ… ÑƒĞ±Ğ¸Ñ€Ğ°ĞµĞ¼ wireguard, ÑÑ‚Ğ°Ğ²Ğ¸Ğ¼ netcat Ñ Ğ¾Ğ±Ğ¾Ğ¸Ñ… ĞºĞ¾Ğ½Ñ†Ğ¾Ğ² Ğ¸ Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ¾Ğ±Ñ‰Ğ°Ñ‚ÑŒÑÑ, Ğ¿Ğ¾ÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°Ñ Ğ² wireshark.\nĞ’ÑĞµĞ³Ğ´Ğ° Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¾Ñ‚ĞºĞ°Ñ‚Ğ¸Ñ‚ÑŒÑÑ Ğ½Ğ° Ğ½ÑƒĞ»ĞµĞ²Ğ¾Ğ¹ ĞºĞ¾Ğ´, Ğ½Ğ¾ Ñ‚Ğ¾Ğ³Ğ´Ğ° Ñƒ ÑĞµÑ€Ğ²ĞµÑ€Ğ° Ğ±ĞµĞ· Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ° Ğ¿Ğ¾ IP ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ° Ğ±ÑƒĞ´ĞµÑ‚ Ğ¿Ğ»Ğ¾Ñ…Ğ°Ñ Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ğ° Ğ¾Ñ‚ Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ñ‹Ñ… Ğ¿Ğ¸Ğ½Ğ³Ğ¾Ğ² - Ğ²ÑĞµ Ğ¾Ğ½Ğ¸ Ğ±ÑƒĞ´ÑƒÑ‚ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ²Ğ°Ñ‚ÑŒÑÑ Ğ² udp Ğ¸ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒÑÑ Ğ² wireguard,\nĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ±ÑƒĞ´ĞµÑ‚ Ğ¸Ñ… Ğ¸Ğ³Ğ½Ğ¾Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ, Ğ¿Ğ¾ÑĞºĞ¾Ğ»ÑŒĞºÑƒ Ğ¿ĞµÑ€ĞµĞ´Ğ°ĞµÑ‚ÑÑ Ğ¼ÑƒÑĞ¾Ñ€. Ğ¡ĞµÑ€Ğ²ĞµÑ€ Ğ¿ĞµÑ€ĞµÑÑ‚Ğ°Ğ½ĞµÑ‚ Ğ¿Ğ¸Ğ½Ğ³Ğ°Ñ‚ÑŒÑÑ.\n\nĞ”Ñ€ÑƒĞ³Ğ¾Ğ¹ ÑĞ¿Ğ¾ÑĞ¾Ğ± Ğ¸Ğ·Ğ±ĞµĞ¶Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¸ ÑƒĞ¹Ñ‚Ğ¸ Ğ¾Ñ‚ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ñ… Ğ¿Ğ¸Ğ½Ğ³Ğ¾Ğ² - Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ Ñ‚Ğ¸Ğ¿Ñ‹ icmp. Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‰Ğ¸Ğµ Ğ¿Ğ°Ñ€Ñ‹, Ğ¿Ñ€Ğ¾Ğ±Ñ€Ğ°ÑÑ‹Ğ²Ğ°ĞµĞ¼Ñ‹Ğµ Linux NAT :\n\n- `ctype=8:stype=0` - echo request - echo reply (Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ)\n- `ctype=13:stype=14` - timestamp - timestamp reply\n- `ctype=15:stype=16` - information request - information reply\n- `ctype=17:stype=18` - address mask request - address mask reply\n\nĞĞ° Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€ÑĞºĞ¸Ñ… NAT Ğ¸Ğ»Ğ¸ Ğ½Ğ° Ğ°Ğ¿Ğ¿Ğ°Ñ€Ğ°Ñ‚Ğ½Ğ¾Ğ¼ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğ¸ Ñ€Ğ¾ÑƒÑ‚ĞµÑ€Ğ° Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ´Ñ€ÑƒĞ³Ğ¾Ğ¹ Ñ€Ğ°ÑĞºĞ»Ğ°Ğ´ Ğ¿Ğ¾ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‰Ğ¸Ğ¼ Ğ¿Ğ°Ñ€Ğ°Ğ¼.\nĞÑƒĞ¶Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ±Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸ ÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ Ñ‡Ñ‚Ğ¾ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ² ÑĞµÑ‚ÑŒ Ğ¿Ğ¾ÑĞ»Ğµ NAT Ğ¸ Ñ‡Ñ‚Ğ¾ Ğ¿Ñ€Ğ¸Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ½Ğ° ÑĞµÑ€Ğ²ĞµÑ€.\nĞĞ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Linux NAT Ğ²Ğ¾Ğ¾Ğ±Ñ‰Ğµ Ğ½Ğµ Ğ¿Ñ€Ğ¾Ğ±Ñ€Ğ°ÑÑ‹Ğ²Ğ°ĞµÑ‚ type 42 - extended echo request. ĞĞ¾ Ğ°Ğ¿Ğ¿Ğ°Ñ€Ğ°Ñ‚Ğ½Ğ°Ñ Ğ¶ĞµĞ»ĞµĞ·ĞºĞ° Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ñ€Ğ¾ÑĞ¸Ñ‚ÑŒ Ğ¸ Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€ Ñ‚Ğ¾Ğ¶Ğµ.\n\nĞšÑ‚Ğ¾ Ğ·Ğ½Ğ°ĞµÑ‚, Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ DPI Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½ ÑĞµÑ‡ÑŒ icmp Ñ‚Ğ¾Ğ½Ğ½ĞµĞ»Ğ¸ Ğ½Ğ° ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ñ… Ğ¿Ğ¸Ğ½Ğ³Ğ°Ñ…, Ğ° Ğ½Ğ° Ğ´Ñ€ÑƒĞ³Ğ¸Ñ… Ñ‚Ğ¸Ğ¿Ğ°Ñ… icmp Ğ½ĞµÑ‚ ?\n\n\nwireguard server - `1.2.3.4:5555`\n\n```\ntable ip ztest {\n        chain post {\n                type filter hook output priority mangle; policy accept;\n                meta mark & 0x40000000 == 0x00000000 udp sport 5555 queue flags bypass to 200\n        }\n\n        chain pre {\n                type filter hook input priority mangle; policy accept;\n                meta mark & 0x40000000 == 0x00000000 icmp type echo-request icmp code 199 queue flags bypass to 200\n        }\n}\n```\n\n```\nnfqws2 --qnum 200 --server\n --lua-init=@/opt/zapret2/lua/zapret-lib.lua\n --lua-init=@/opt/zapret2/lua/zapret-obfs.lua\n --in-range=a\n --lua-desync=udp2icmp:ccode=199:scode=199\n```\n\nĞšĞ»Ğ¸ĞµĞ½Ñ‚ Ğ½Ğ° Ğ²Ğ¸Ğ½Ğ´Ğµ :\n\n```\nwinws2\n --wf-icmp-in=0:199 --wf-udp-out=5555\n --wf-raw-filter=\"ip.SrcAddr=1.2.3.4 or ip.DstAddr=1.2.3.4\"\n --lua-init=@lua/zapret-lib.lua\n --lua-init=@lua/zapret-obfs.lua\n --in-range=a\n --lua-desync=udp2icmp:ccode=199:scode=199\n```\n\nĞ’ÑĞµ Ğ»Ğ¸ÑˆĞ½ĞµĞµ Ğ¾Ñ‚ÑĞµĞºĞ°ĞµÑ‚ÑÑ Ğ² ÑĞ´Ñ€Ğµ Ğ² windivert - Ğ¿Ñ€Ğ¾Ñ† Ğ·Ğ°Ğ·Ñ€Ñ Ğ½Ğµ Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚.\n--wf-raw-filter ÑĞ¾Ñ‡ĞµÑ‚Ğ°ĞµÑ‚ÑÑ ÑĞ¾ Ğ²ÑĞµĞ¼ Ğ¾ÑÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ ÑĞ¾Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ğ¼ ĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ‚Ğ¾Ñ€Ğ¾Ğ¼ Ğ¿Ğ¾ AND. ĞÑ‚ÑĞµĞºĞ°ĞµÑ‚ Ğ¿Ğ¾ IP Ğ°Ğ´Ñ€ĞµÑÑƒ ÑĞµÑ€Ğ²ĞµÑ€Ğ°.\n--wf-icmp-in Ğ¾Ñ‚ÑĞµĞºĞ°ĞµÑ‚ Ğ²Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğµ icmp Ñ‚Ğ¸Ğ¿Ğ° 0 Ñ ĞºĞ¾Ğ´Ğ¾Ğ¼ 199.\n\nĞ˜ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ wireguard.\nĞ’ ÑˆĞ°Ñ€ĞºĞµ ÑĞ¿Ğ»Ğ¾ÑˆĞ½ÑĞºĞ¾Ğ¼ Ğ¿Ğ¸Ğ½Ğ³Ğ¸ Ğ¸ Ñ€ĞµĞ¿Ğ»Ğ°Ğ¸ Ñ ĞºĞ¾Ğ´Ğ¾Ğ¼ 199\n\nĞ•ÑĞ»Ğ¸ IP ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ° Ğ¿Ğ¾ÑÑ‚Ğ¾ÑĞ½ĞµĞ½, Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ½Ğ° ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ğµ ÑĞµÑ€Ğ²ĞµÑ€Ğ° ÑĞ´ĞµĞ»Ğ°Ñ‚ÑŒ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€ Ğ¿Ğ¾ IP ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°.\n\nĞ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ÑĞ´ĞµĞ»Ğ°Ñ‚ÑŒ dataxor=blob Ğ½Ğ° Ğ¾Ğ±Ğ¾Ğ¸Ñ… ĞºĞ¾Ğ½Ñ†Ğ°Ñ…, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ğ¾ĞºÑĞ¾Ñ€Ğ¸Ñ‚ÑŒ Ğ¿ĞµĞ¹Ğ»Ğ¾Ğ°Ğ´.\nblob Ñ€Ğ°ÑÑ‚ÑĞ³Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ğ¿Ğ°ĞºĞµÑ‚Ğ° ĞºĞ°Ğº pattern. ĞœĞ¾Ğ¶Ğ½Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ñ‚ 1 hex byte Ğ´Ğ¾ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ½Ğ°Ğ³ĞµĞ½ĞµÑ€ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ½Ğ´Ğ¾Ğ¼Ğ°. ĞĞ° Ğ¾Ğ±Ğ¾Ğ¸Ñ… ĞºĞ¾Ğ½Ñ†Ğ°Ñ… Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ¾Ğ´Ğ¸Ğ½Ğ°ĞºĞ¾Ğ²Ñ‹Ğ¹\n",
      "stars_today": 17
    },
    {
      "id": 55626935,
      "name": "WSL",
      "full_name": "microsoft/WSL",
      "description": "Windows Subsystem for Linux",
      "html_url": "https://github.com/microsoft/WSL",
      "stars": 31028,
      "forks": 1609,
      "language": "C++",
      "topics": [],
      "created_at": "2016-04-06T17:32:56Z",
      "updated_at": "2026-02-07T02:09:15Z",
      "pushed_at": "2026-02-07T01:48:20Z",
      "open_issues": 958,
      "owner": {
        "login": "microsoft",
        "avatar_url": "https://avatars.githubusercontent.com/u/6154722?v=4"
      },
      "readme": "# Welcome to the Windows Subsystem for Linux (WSL) repository\n\n<p align=\"center\">\n  <img src=\"./Images/Square44x44Logo.targetsize-256.png\" alt=\"WSL logo\"/>\n</p>\n\n[Learn more about WSL](https://aka.ms/wsldocs) | [Downloads & Release notes](https://github.com/microsoft/WSL/releases) | [Contributing to WSL](./CONTRIBUTING.md)\n\n## About\n\nWindows Subsystem for Linux (WSL) is a powerful way for you to run your Linux command-line tools, utilities and applications, all unmodified and directly on Windows without the overhead of a traditional virtual machine or dual boot setup.\n\nYou can install WSL right away by running this command inside of your Windows command line:\n\n```powershell\nwsl --install\n```\n\nYou can learn more about [best practices for setup](https://learn.microsoft.com/windows/wsl/setup/environment), [overviews of WSL](https://learn.microsoft.com/windows/wsl/about) and more at our [WSL documentation page](https://learn.microsoft.com/windows/wsl/).\n\n## Related repositories\n\nWSL also has related open source repositories:\n\n- [microsoft/WSL2-Linux-Kernel](https://github.com/microsoft/WSL2-Linux-Kernel) - The Linux kernel shipped with WSL\n- [microsoft/WSLg](https://github.com/microsoft/wslg) - Support for Linux GUI apps in WSL\n- [microsoftdocs/wsl](https://github.com/microsoftdocs/wsl) - WSL documentation at aka.ms/wsldocs\n\n## Contributing\n\nThis project welcomes contributions of all types, including coding features / bug fixes, documentation fixes, design proposals and more. \n\nWe ask that before you start working on a contribution, please read our [Contributor's Guide](./CONTRIBUTING.md).\n\nFor guidance on developing for WSL, please read the [developer docs](./doc/docs/dev-loop.md) for instructions on how to build WSL from source and details on its architecture.\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](./CODE_OF_CONDUCT.md)\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow [Microsoftâ€™s Trademark & Brand Guidelines](https://www.microsoft.com/legal/intellectualproperty/trademarks). Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-partyâ€™s policies.\n\n## Privacy and telemetry\n\nThe application logs basic diagnostic data (telemetry). For more information on privacy and what we collect, see our [data and privacy documentation](DATA_AND_PRIVACY.md).\n\nThe software may collect information about you and your use of the software and send it to Microsoft. Microsoft may use this information to provide services and improve our products and services. You may turn off the telemetry as described in the repository. There are also some features in the software that may enable you and Microsoft to collect data from users of your applications. If you use these features, you must comply with applicable law, including providing appropriate notices to users of your applications together with a copy of Microsoftâ€™s privacy statement. Our privacy statement is located at https://go.microsoft.com/fwlink/?LinkID=824704. You can learn more about data collection and use in the help documentation and our privacy statement. Your use of the software operates as your consent to these practices.",
      "stars_today": 16
    },
    {
      "id": 230660669,
      "name": "mediamtx",
      "full_name": "bluenviron/mediamtx",
      "description": "Ready-to-use SRT / WebRTC / RTSP / RTMP / LL-HLS / MPEG-TS / RTP media server and media proxy that allows to read, publish, proxy, record and playback video and audio streams.",
      "html_url": "https://github.com/bluenviron/mediamtx",
      "stars": 17842,
      "forks": 2115,
      "language": "Go",
      "topics": [
        "go",
        "golang",
        "hls",
        "media-server",
        "obs-studio",
        "rtcp",
        "rtmp",
        "rtmp-proxy",
        "rtmp-server",
        "rtp",
        "rtsp",
        "rtsp-proxy",
        "rtsp-relay",
        "rtsp-server",
        "srt",
        "streaming",
        "webrtc",
        "webrtc-proxy"
      ],
      "created_at": "2019-12-28T20:08:43Z",
      "updated_at": "2026-02-07T01:18:18Z",
      "pushed_at": "2026-02-06T15:20:58Z",
      "open_issues": 213,
      "owner": {
        "login": "bluenviron",
        "avatar_url": "https://avatars.githubusercontent.com/u/126152966?v=4"
      },
      "readme": "<h1 align=\"center\">\n  <a href=\"https://mediamtx.org\">\n    <img src=\"logo.png\" alt=\"MediaMTX\">\n  </a>\n\n  <br>\n  <br>\n\n  [![Website](https://img.shields.io/badge/website-mediamtx.org-1c94b5)](https://mediamtx.org)\n  [![Test](https://github.com/bluenviron/mediamtx/actions/workflows/code_test.yml/badge.svg?branch=main)](https://github.com/bluenviron/mediamtx/actions/workflows/code_test.yml?query=branch%3Amain)\n  [![Lint](https://github.com/bluenviron/mediamtx/actions/workflows/code_lint.yml/badge.svg?branch=main)](https://github.com/bluenviron/mediamtx/actions/workflows/code_lint.yml?query=branch%3Amain)\n  [![CodeCov](https://codecov.io/gh/bluenviron/mediamtx/branch/main/graph/badge.svg)](https://app.codecov.io/gh/bluenviron/mediamtx/tree/main)\n  [![Release](https://img.shields.io/github/v/release/bluenviron/mediamtx)](https://github.com/bluenviron/mediamtx/releases)\n  [![Docker Hub](https://img.shields.io/badge/docker-bluenviron/mediamtx-blue)](https://hub.docker.com/r/bluenviron/mediamtx)\n</h1>\n\n<br>\n\n_MediaMTX_ is a ready-to-use and zero-dependency real-time media server and media proxy that allows to publish, read, proxy, record and playback video and audio streams. It has been conceived as a \"media router\" that routes media streams from one end to the other.\n\n<div align=\"center\">\n\n  |[Install](https://mediamtx.org/docs/kickoff/install)|[Documentation](https://mediamtx.org/docs/kickoff/introduction)|\n  |-|-|\n\n</div>\n\n<h3>Features</h3>\n\n- [Publish](https://mediamtx.org/docs/usage/publish) live streams to the server with SRT, WebRTC, RTSP, RTMP, HLS, MPEG-TS, RTP\n- [Read](https://mediamtx.org/docs/usage/read) live streams from the server with SRT, WebRTC, RTSP, RTMP, HLS\n- Streams are automatically converted from a protocol to another\n- Serve several streams at once in separate paths\n- Reload the configuration without disconnecting existing clients (hot reloading)\n- [Serve always-available streams](https://mediamtx.org/docs/usage/always-available) even when the publisher is offline\n- [Record](https://mediamtx.org/docs/usage/record) streams to disk in fMP4 or MPEG-TS format\n- [Playback](https://mediamtx.org/docs/usage/playback) recorded streams\n- [Authenticate](https://mediamtx.org/docs/usage/authentication) users with internal, HTTP or JWT authentication\n- [Forward](https://mediamtx.org/docs/usage/forward) streams to other servers\n- [Proxy](https://mediamtx.org/docs/usage/proxy) requests to other servers\n- [Control](https://mediamtx.org/docs/usage/control-api) the server through the Control API\n- [Extract metrics](https://mediamtx.org/docs/usage/metrics) from the server in a Prometheus-compatible format\n- [Monitor performance](https://mediamtx.org/docs/usage/performance) to investigate CPU and RAM consumption\n- [Run hooks](https://mediamtx.org/docs/usage/hooks) (external commands) when clients connect, disconnect, read or publish streams\n- Compatible with Linux, Windows and macOS, does not require any dependency or interpreter, it's a single executable\n- ...and many [others](https://mediamtx.org/docs/kickoff/introduction).\n",
      "stars_today": 16
    },
    {
      "id": 391055597,
      "name": "DSA-Bootcamp-Java",
      "full_name": "kunal-kushwaha/DSA-Bootcamp-Java",
      "description": "This repository consists of the code samples, assignments, and notes for the Java data structures & algorithms + interview preparation bootcamp of WeMakeDevs.",
      "html_url": "https://github.com/kunal-kushwaha/DSA-Bootcamp-Java",
      "stars": 21861,
      "forks": 13052,
      "language": "Java",
      "topics": [
        "algorithms",
        "competitive-programming",
        "data-structures",
        "faang-interview",
        "faang-preparation",
        "faang-questions",
        "google-interview",
        "interview-preparation",
        "java",
        "leetcode",
        "leetcode-java",
        "leetcode-solutions",
        "math"
      ],
      "created_at": "2021-07-30T12:23:25Z",
      "updated_at": "2026-02-06T19:57:52Z",
      "pushed_at": "2024-08-18T08:21:57Z",
      "open_issues": 631,
      "owner": {
        "login": "kunal-kushwaha",
        "avatar_url": "https://avatars.githubusercontent.com/u/42698533?v=4"
      },
      "readme": "# DSA + Interview preparation bootcamp\n- Subscribe to the [YouTube channel](https://www.youtube.com/KunalKushwaha?sub_confirmation=1)\n- [Lectures](https://www.youtube.com/playlist?list=PL9gnSGHSqcnr_DxHsP7AW9ftq0AtAyYqJ)\n- [Course website](https://www.techwithkunal.com/courses/dsa)\n- [Assignments](https://github.com/kunal-kushwaha/DSA-Bootcamp-Java/tree/main/assignments) (solutions can be found on LeetCode)\n",
      "stars_today": 15
    },
    {
      "id": 576303915,
      "name": "KernelSU",
      "full_name": "tiann/KernelSU",
      "description": "A Kernel based root solution for Android",
      "html_url": "https://github.com/tiann/KernelSU",
      "stars": 14917,
      "forks": 3088,
      "language": "Kotlin",
      "topics": [
        "android",
        "kernel",
        "kernelsu",
        "root",
        "su"
      ],
      "created_at": "2022-12-09T14:03:54Z",
      "updated_at": "2026-02-07T02:11:06Z",
      "pushed_at": "2026-02-06T02:32:05Z",
      "open_issues": 30,
      "owner": {
        "login": "tiann",
        "avatar_url": "https://avatars.githubusercontent.com/u/4233744?v=4"
      },
      "readme": "**English** | [EspaÃ±ol](README_ES.md) | [ç®€ä½“ä¸­æ–‡](README_CN.md) | [ç¹é«”ä¸­æ–‡](README_TW.md) | [æ—¥æœ¬èª](README_JP.md) | [í•œêµ­ì–´](README_KR.md) | [Polski](README_PL.md) | [PortuguÃªs (Brasil)](README_PT-BR.md) | [TÃ¼rkÃ§e](README_TR.md) | [Ğ ÑƒÑÑĞºĞ¸Ğ¹](README_RU.md) | [Tiáº¿ng Viá»‡t](README_VI.md) | [Indonesia](README_ID.md) | [×¢×‘×¨×™×ª](README_IW.md) | [à¤¹à¤¿à¤‚à¤¦à¥€](README_IN.md) | [Italiano](README_IT.md)\n\n# KernelSU\n\n<img src=\"https://kernelsu.org/logo.png\" style=\"width: 96px;\" alt=\"logo\">\n\nA kernel-based root solution for Android devices.\n\n[![Latest release](https://img.shields.io/github/v/release/tiann/KernelSU?label=Release&logo=github)](https://github.com/tiann/KernelSU/releases/latest)\n[![Weblate](https://img.shields.io/badge/Localization-Weblate-teal?logo=weblate)](https://hosted.weblate.org/engage/kernelsu)\n[![Channel](https://img.shields.io/badge/Follow-Telegram-blue.svg?logo=telegram)](https://t.me/KernelSU)\n[![License: GPL v2](https://img.shields.io/badge/License-GPL%20v2-orange.svg?logo=gnu)](https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html)\n[![GitHub License](https://img.shields.io/github/license/tiann/KernelSU?logo=gnu)](/LICENSE)\n\n## Features\n\n1. Kernel-based `su` and root access management.\n2. Module system based on [metamodules](https://kernelsu.org/guide/metamodule.html): Pluggable infrastructure for systemless modifications.\n3. [App Profile](https://kernelsu.org/guide/app-profile.html): Lock up the root power in a cage.\n\n## Compatibility state\n\nKernelSU officially supports Android GKI 2.0 devices (kernel 5.10+). Older kernels (4.14+) are also supported, but the kernel will need to be built manually.\n\nWith this, WSA, ChromeOS, and container-based Android are all supported.\n\nCurrently, only the `arm64-v8a` and `x86_64` architectures are supported.\n\n## Usage\n\n- [Installation](https://kernelsu.org/guide/installation.html)\n- [How to build](https://kernelsu.org/guide/how-to-build.html)\n- [Official website](https://kernelsu.org/)\n\n## Translation\n\nTo help translate KernelSU or improve existing translations, please use [Weblate](https://hosted.weblate.org/engage/kernelsu/). PR of Manager's translation is no longer accepted, because it will conflict with Weblate.\n\n## Discussion\n\n- Telegram: [@KernelSU](https://t.me/KernelSU)\n\n## Security\n\nFor information on reporting security vulnerabilities in KernelSU, see [SECURITY.md](/SECURITY.md).\n\n## License\n\n- Files under the `kernel` directory are [GPL-2.0-only](https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html).\n- All other parts except the `kernel` directory are [GPL-3.0-or-later](https://www.gnu.org/licenses/gpl-3.0.html).\n\n## Credits\n\n- [Kernel-Assisted Superuser](https://git.zx2c4.com/kernel-assisted-superuser/about/): The KernelSU idea.\n- [Magisk](https://github.com/topjohnwu/Magisk): The powerful root tool.\n- [genuine](https://github.com/brevent/genuine/): APK v2 signature validation.\n- [Diamorphine](https://github.com/m0nad/Diamorphine): Some rootkit skills.\n",
      "stars_today": 15
    },
    {
      "id": 831578771,
      "name": "clay",
      "full_name": "nicbarker/clay",
      "description": "High performance UI layout library in C.",
      "html_url": "https://github.com/nicbarker/clay",
      "stars": 16510,
      "forks": 641,
      "language": "C",
      "topics": [
        "layout",
        "ui"
      ],
      "created_at": "2024-07-21T01:40:27Z",
      "updated_at": "2026-02-06T23:00:15Z",
      "pushed_at": "2025-12-30T07:52:27Z",
      "open_issues": 234,
      "owner": {
        "login": "nicbarker",
        "avatar_url": "https://avatars.githubusercontent.com/u/2264338?v=4"
      },
      "readme": "# Clay, A UI Layout Library\n**_Clay_** (short for **C Layout**) is a high performance 2D UI layout library.\n\n### Major Features\n- Microsecond layout performance\n- Flex-box like layout model for complex, responsive layouts including text wrapping, scrolling containers and aspect ratio scaling\n- Single ~4k LOC **clay.h** file with **zero** dependencies (including no standard library)\n- Wasm support: compile with clang to a 15kb uncompressed **.wasm** file for use in the browser\n- Static arena based memory use with no malloc / free, and low total memory overhead (e.g. ~3.5mb for 8192 layout elements).\n- React-like nested declarative syntax\n- Renderer agnostic: outputs a sorted list of rendering primitives that can be easily composited in any 3D engine, and even compiled to HTML (examples provided)\n\nTake a look at the [clay website](https://nicbarker.com/clay) for an example of clay compiled to wasm and running in the browser, or others in the [examples directory](https://github.com/nicbarker/clay/tree/main/examples).\n\nYou can also watch the [introduction video](https://youtu.be/DYWTw19_8r4) for an overview of the motivation behind Clay's development and a short demo of its usage.\n\n<img width=\"1394\" alt=\"A screenshot of a code IDE with lots of visual and textual elements\" src=\"https://github.com/user-attachments/assets/9986149a-ee0f-449a-a83e-64a392267e3d\">\n\n_An example GUI application built with clay_\n\n## Quick Start\n\nDownload or clone clay.h and include it after defining `CLAY_IMPLEMENTATION` in one file.\n\n```C\n// Must be defined in one file, _before_ #include \"clay.h\"\n#define CLAY_IMPLEMENTATION\n#include \"../../clay.h\"\n\nconst Clay_Color COLOR_LIGHT = (Clay_Color) {224, 215, 210, 255};\nconst Clay_Color COLOR_RED = (Clay_Color) {168, 66, 28, 255};\nconst Clay_Color COLOR_ORANGE = (Clay_Color) {225, 138, 50, 255};\n\nvoid HandleClayErrors(Clay_ErrorData errorData) {\n    // See the Clay_ErrorData struct for more information\n    printf(\"%s\", errorData.errorText.chars);\n    switch(errorData.errorType) {\n        // etc\n    }\n}\n\n// Example measure text function\nstatic inline Clay_Dimensions MeasureText(Clay_StringSlice text, Clay_TextElementConfig *config, uintptr_t userData) {\n    // Clay_TextElementConfig contains members such as fontId, fontSize, letterSpacing etc\n    // Note: Clay_String->chars is not guaranteed to be null terminated\n    return (Clay_Dimensions) {\n            .width = text.length * config->fontSize, // <- this will only work for monospace fonts, see the renderers/ directory for more advanced text measurement\n            .height = config->fontSize\n    };\n}\n\n// Layout config is just a struct that can be declared statically, or inline\nClay_ElementDeclaration sidebarItemConfig = (Clay_ElementDeclaration) {\n    .layout = {\n        .sizing = { .width = CLAY_SIZING_GROW(0), .height = CLAY_SIZING_FIXED(50) }\n    },\n    .backgroundColor = COLOR_ORANGE\n};\n\n// Re-useable components are just normal functions\nvoid SidebarItemComponent() {\n    CLAY(id, sidebarItemConfig) {\n        // children go here...\n    }\n}\n\nint main() {\n    // Note: malloc is only used here as an example, any allocator that provides\n    // a pointer to addressable memory of at least totalMemorySize will work\n    uint64_t totalMemorySize = Clay_MinMemorySize();\n    Clay_Arena arena = Clay_CreateArenaWithCapacityAndMemory(totalMemorySize, malloc(totalMemorySize));\n\n    // Note: screenWidth and screenHeight will need to come from your environment, Clay doesn't handle window related tasks\n    Clay_Initialize(arena, (Clay_Dimensions) { screenWidth, screenHeight }, (Clay_ErrorHandler) { HandleClayErrors });\n\n    while(renderLoop()) { // Will be different for each renderer / environment\n        // Optional: Update internal layout dimensions to support resizing\n        Clay_SetLayoutDimensions((Clay_Dimensions) { screenWidth, screenHeight });\n        // Optional: Update internal pointer position for handling mouseover / click / touch events - needed for scrolling & debug tools\n        Clay_SetPointerState((Clay_Vector2) { mousePositionX, mousePositionY }, isMouseDown);\n        // Optional: Update internal pointer position for handling mouseover / click / touch events - needed for scrolling and debug tools\n        Clay_UpdateScrollContainers(true, (Clay_Vector2) { mouseWheelX, mouseWheelY }, deltaTime);\n\n        // All clay layouts are declared between Clay_BeginLayout and Clay_EndLayout\n        Clay_BeginLayout();\n\n        // An example of laying out a UI with a fixed width sidebar and flexible width main content\n        CLAY(CLAY_ID(\"OuterContainer\"), { .layout = { .sizing = {CLAY_SIZING_GROW(0), CLAY_SIZING_GROW(0)}, .padding = CLAY_PADDING_ALL(16), .childGap = 16 }, .backgroundColor = {250,250,255,255} }) {\n            CLAY(CLAY_ID(\"SideBar\"), {\n                .layout = { .layoutDirection = CLAY_TOP_TO_BOTTOM, .sizing = { .width = CLAY_SIZING_FIXED(300), .height = CLAY_SIZING_GROW(0) }, .padding = CLAY_PADDING_ALL(16), .childGap = 16 },\n                .backgroundColor = COLOR_LIGHT\n            }) {\n                CLAY(CLAY_ID(\"ProfilePictureOuter\"), { .layout = { .sizing = { .width = CLAY_SIZING_GROW(0) }, .padding = CLAY_PADDING_ALL(16), .childGap = 16, .childAlignment = { .y = CLAY_ALIGN_Y_CENTER } }, .backgroundColor = COLOR_RED }) {\n                    CLAY(CLAY_ID(\"ProfilePicture\"), {.layout = { .sizing = { .width = CLAY_SIZING_FIXED(60), .height = CLAY_SIZING_FIXED(60) }}, .image = { .imageData = &profilePicture } }) {}\n                    CLAY_TEXT(CLAY_STRING(\"Clay - UI Library\"), CLAY_TEXT_CONFIG({ .fontSize = 24, .textColor = {255, 255, 255, 255} }));\n                }\n\n                // Standard C code like loops etc work inside components\n                for (int i = 0; i < 5; i++) {\n                    SidebarItemComponent();\n                }\n\n                CLAY(CLAY_ID(\"MainContent\"), { .layout = { .sizing = { .width = CLAY_SIZING_GROW(0), .height = CLAY_SIZING_GROW(0) } }, .backgroundColor = COLOR_LIGHT }) {}\n            }\n        }\n\n        // All clay layouts are declared between Clay_BeginLayout and Clay_EndLayout\n        Clay_RenderCommandArray renderCommands = Clay_EndLayout();\n\n        // More comprehensive rendering examples can be found in the renderers/ directory\n        for (int i = 0; i < renderCommands.length; i++) {\n            Clay_RenderCommand *renderCommand = &renderCommands.internalArray[i];\n\n            switch (renderCommand->commandType) {\n                case CLAY_RENDER_COMMAND_TYPE_RECTANGLE: {\n                    DrawRectangle( renderCommand->boundingBox, renderCommand->renderData.rectangle.backgroundColor);\n                }\n                // ... Implement handling of other command types\n            }\n        }\n    }\n}\n```\n    \nThe above example, rendered correctly will look something like the following:\n\n![Clay Example](https://github.com/user-attachments/assets/1928c6d4-ada9-4a4c-a3d1-44fe9b23b3bd)\n\nIn summary, the general order of steps is:\n\n1. [Clay_SetLayoutDimensions(dimensions)](#clay_setlayoutdimensions)\t\n2. [Clay_SetPointerState(pointerPosition, isPointerDown)](#clay_setpointerstate)\n3. [Clay_UpdateScrollContainers(enableDragScrolling, scrollDelta, deltaTime)](#clay_updatescrollcontainers)\n4. [Clay_BeginLayout()](#clay_beginlayout)\n5. Declare your layout with the provided [Element Macros](#element-macros)\n6. [Clay_EndLayout()](#clay_endlayout)\n7. Render the results using the outputted [Clay_RenderCommandArray](#clay_rendercommandarray)\n\nFor help starting out or to discuss clay, considering joining [the discord server.](https://discord.gg/b4FTWkxdvT)\n\n## Summary\n\n- [High Level Documentation](#high-level-documentation)\n  - [Building UI Hierarchies](#building-ui-hierarchies)\n  - [Configuring Layout and Styling UI Elements](#configuring-layout-and-styling-ui-elements)\n  - [Element IDs](#element-ids)\n  - [Mouse, Touch and Pointer Interactions](#mouse-touch-and-pointer-interactions)\n  - [Scrolling Elements](#scrolling-elements)\n  - [Floating Elements](#floating-elements-absolute-positioning)\n  - [Custom Elements](#laying-out-your-own-custom-elements)\n  - [Retained Mode Rendering](#retained-mode-rendering)\n  - [Visibility Culling](#visibility-culling)\n  - [Preprocessor Directives](#preprocessor-directives)\n  - [Bindings](#bindings-for-non-c)\n  - [Debug Tools](#debug-tools)\n- [API](#api)\n  - [Naming Conventions](#naming-conventions)\n  - [Public Functions](#public-functions)\n    - [Lifecycle](#lifecycle-for-public-functions)\n    - [Clay_MinMemorySize](#clay_minmemorysize)\n    - [Clay_CreateArenaWithCapacityAndMemory](#clay_createarenawithcapacityandmemory)\n    - [Clay_SetMeasureTextFunction](#clay_setmeasuretextfunction)\n    - [Clay_ResetMeasureTextCache](#clay_resetmeasuretextcache)\n    - [Clay_SetMaxElementCount](#clay_setmaxelementcount)\n    - [Clay_SetMaxMeasureTextCacheWordCount](#clay_setmaxmeasuretextcachewordcount)\n    - [Clay_Initialize](#clay_initialize)\n    - [Clay_GetCurrentContext](#clay_getcurrentcontext)\n    - [Clay_SetCurrentContext](#clay_setcurrentcontext)\n    - [Clay_SetLayoutDimensions](#clay_setlayoutdimensions)\n    - [Clay_SetPointerState](#clay_setpointerstate)\n    - [Clay_UpdateScrollContainers](#clay_updatescrollcontainers)\n    - [Clay_BeginLayout](#clay_beginlayout)\n    - [Clay_EndLayout](#clay_endlayout)\n    - [Clay_Hovered](#clay_hovered)\n    - [Clay_OnHover](#clay_onhover)\n    - [Clay_PointerOver](#clay_pointerover)\n    - [Clay_GetScrollContainerData](#clay_getscrollcontainerdata)\n    - [Clay_GetElementData](#clay_getelementdata)\n    - [Clay_GetElementId](#clay_getelementid)\n  - [Element Macros](#element-macros)\n    - [CLAY](#clay)\n    - [CLAY_ID](#clay_id)\n    - [CLAY_IDI](#clay_idi)\n  - [Data Structures & Defs](#data-structures--definitions)\n    - [Clay_String](#clay_string)\n    - [Clay_ElementId](#clay_elementid)\n    - [Clay_RenderCommandArray](#clay_rendercommandarray)\n    - [Clay_RenderCommand](#clay_rendercommand)\n    - [Clay_ScrollContainerData](#clay_scrollcontainerdata)\n    - [Clay_ErrorHandler](#clay_errorhandler)\n    - [Clay_ErrorData](#clay_errordata)\n\n## High Level Documentation\n\n### Building UI Hierarchies\nClay UIs are built using the C macro `CLAY(id, { configuration })`. This macro creates a new empty element in the UI hierarchy, and supports modular customisation of layout, styling and functionality. The `CLAY()` macro can also be _nested_, similar to other declarative UI systems like HTML.\n\nChild elements are added by opening a block: `{}` after calling the `CLAY()` macro (exactly like you would with an `if` statement or `for` loop), and declaring child components inside the braces.\n```C\n// Parent element with 8px of padding\nCLAY(CLAY_ID(\"parent\"), { .layout = { .padding = CLAY_PADDING_ALL(8) } }) {\n    // Child element 1\n    CLAY_TEXT(CLAY_STRING(\"Hello World\"), CLAY_TEXT_CONFIG({ .fontSize = 16 }));\n    // Child element 2 with red background\n    CLAY((CLAY_ID(\"child\"), { .backgroundColor = COLOR_RED }) {\n        // etc\n    }\n}\n```\n\nHowever, unlike HTML and other declarative DSLs, this macro is just C. As a result, you can use arbitrary C code such as loops, functions and conditions inside your layout declaration code:\n```C\n// Re-usable \"components\" are just functions that declare more UI\nvoid ButtonComponent(Clay_String buttonText) {\n    // Red box button with 8px of padding\n    CLAY_AUTO_ID({ .layout = { .padding = CLAY_PADDING_ALL(8) }, .backgroundColor = COLOR_RED }) {\n        CLAY_TEXT(buttonText, textConfig);\n    }\n}\n\n// Parent element\nCLAY(CLAY_ID(\"parent\"), { .layout = { .layoutDirection = CLAY_TOP_TO_BOTTOM } }) {\n    // Render a bunch of text elements\n    for (int i = 0; i < textArray.length; i++) {\n        CLAY_TEXT(textArray.elements[i], textConfig);\n    }\n    // Only render this element if we're on a mobile screen\n    if (isMobileScreen) {\n        CLAY(0) {\n            // etc\n        }\n    }\n    // Re-usable components\n    ButtonComponent(CLAY_STRING(\"Click me!\"));\n    ButtonComponent(CLAY_STRING(\"No, click me!\"));\n});\n```\n\n### Configuring Layout and Styling UI Elements\nThe layout and style of clay elements is configured with the [Clay_ElementDeclaration](#clay_elementdeclaration) struct passed to the `CLAY()` macro. \n```C\nCLAY(CLAY_ID(\"box\"), { .layout = { .padding = { 8, 8, 8, 8 }, .layoutDirection = CLAY_TOP_TO_BOTTOM } }) {\n    // Children are 8px inset into parent, and laid out top to bottom\n}\n```\nThis macro isn't magic - all it's doing is wrapping the standard designated initializer syntax. e.g. `(Clay_ElementDeclaration) { .layout = { .padding = { .left = 8, .right = 8 } ...`.\n\nSee the [Clay_ElementDeclaration](#clay_elementdeclaration) API for the full list of options.\n\nA `Clay_ElementDeclaration` struct can be defined in file scope or elsewhere, and reused.\n```C\n// Define a style in the global / file scope\nClay_ElementDeclaration reuseableStyle = (Clay_ElementDeclaration) {\n    .layout = { .padding = { .left = 12 } },\n    .backgroundColor = { 120, 120, 120, 255 },\n    .cornerRadius = { 12, 12, 12, 12 }\n};\n\nCLAY(CLAY_ID(\"box\"), reuseableStyle) {\n    // ...\n}\n```\n\n### Element IDs\n\nThe Clay macro by default accepts an ID as its first argument, which is usually provided by the [CLAY_ID()](#clay_id) convenience macro. Elements can also be created with auto generated IDs, by using the [CLAY_AUTO_ID()](#clay-auto-id) macro.\n\n```C\n// Will always produce the same ID from the same input string\nCLAY(CLAY_ID(\"OuterContainer\"), { ...configuration }) {}\n\n// Generates a unique ID that may not be the same between two layout calls\nCLAY_AUTO_ID({ ...configuration }) {}\n```\n\nElement IDs have two main use cases. Firstly, tagging an element with an ID allows you to query information about the element later, such as its [mouseover state](#clay_pointerover) or dimensions.\n\nSecondly, IDs are visually useful when attempting to read and modify UI code, as well as when using the built-in [debug tools](#debug-tools).\n\nTo avoid having to construct dynamic strings at runtime to differentiate ids in loops, clay provides the [CLAY_IDI(string, index)](#clay_idi) macro to generate different ids from a single input string. Think of IDI as \"**ID** + **I**ndex\"\n```C\n// This is the equivalent of calling CLAY_ID(\"Item0\"), CLAY_ID(\"Item1\") etc\nfor (int index = 0; index < items.length; index++) {\n    CLAY(CLAY_IDI(\"Item\", index), { ..configuration }) {}\n}\n```\n\nThis ID will be forwarded to the final `Clay_RenderCommandArray` for use in retained mode UIs. Using duplicate IDs may cause some functionality to misbehave (i.e. if you're trying to attach a floating container to a specific element with ID that is duplicated, it may not attach to the one you expect)\n\n### Mouse, Touch and Pointer Interactions\n\nClay provides several functions for handling mouse and pointer interactions.\n\nAll pointer interactions depend on the function `void Clay_SetPointerState(Clay_Vector2 position, bool isPointerDown)` being called after each mouse position update and before any other clay functions.\n\n**During UI declaration**\n\nThe function `bool Clay_Hovered()` can be called during element construction or in the body of an element, and returns `true` if the mouse / pointer is over the currently open element.\n\n```C\n// An orange button that turns blue when hovered\nCLAY(CLAY_ID(\"Button\"), { .backgroundColor = Clay_Hovered() ? COLOR_BLUE : COLOR_ORANGE }) {\n    bool buttonHovered = Clay_Hovered();\n    CLAY_TEXT(buttonHovered ? CLAY_STRING(\"Hovered\") : CLAY_STRING(\"Hover me!\"), headerTextConfig);\n}\n```\n\nThe function `void Clay_OnHover()` allows you to attach a function pointer to the currently open element, which will be called if the mouse / pointer is over the element.\n\n```C\nvoid HandleButtonInteraction(Clay_ElementId elementId, Clay_PointerData pointerInfo, void *userData) {\n    ButtonData *buttonData = (ButtonData *)userData;\n    // Pointer state allows you to detect mouse down / hold / release\n    if (pointerInfo.state == CLAY_POINTER_DATA_PRESSED_THIS_FRAME) {\n        // Do some click handling\n        NavigateTo(buttonData->link);\n    }\n}\n\nButtonData linkButton = (ButtonData) { .link = \"https://github.com/nicbarker/clay\" };\n\n// HandleButtonInteraction will be called for each frame the mouse / pointer / touch is inside the button boundaries\nCLAY(CLAY_ID(\"Button\"), { .layout = { .padding = CLAY_PADDING_ALL(8) } }) {\n    Clay_OnHover(HandleButtonInteraction, &linkButton);\n    CLAY_TEXT(CLAY_STRING(\"Button\"), &headerTextConfig);\n}\n```\n\n**Before / After UI declaration**\n\nIf you want to query mouse / pointer overlaps outside layout declarations, you can use the function `bool Clay_PointerOver(Clay_ElementId id)`, which takes an [element id](#element-ids) and returns a bool representing whether the current pointer position is within its bounding box. \n```C\n// Reminder: Clay_SetPointerState must be called before functions that rely on pointer position otherwise it will have no effect\nClay_Vector2 mousePosition = { x, y };\nClay_SetPointerState(mousePosition);\n// ...\n// If profile picture was clicked\nif (mouseButtonDown(0) && Clay_PointerOver(Clay_GetElementId(\"ProfilePicture\"))) {\n    // Handle profile picture clicked\n}\n```\n\nNote that the bounding box queried by `Clay_PointerOver` is from the last frame. This generally shouldn't make a difference except in the case of animations that move at high speed.\nIf this is an issue for you, performing layout twice per frame with the same data will give you the correct interaction the second time.\n\n### Scrolling Elements\n\nElements are configured as scrollable with the `.clip` configuration. Clipping instructs the renderer to not draw any pixels outside the clipped element's boundaries, and by specifying the `.childOffset` field, the clipped element's contents can be shifted around to provide \"scrolling\" behaviour.\n\nYou can either calculate scrolling yourself and simply provide the current offset each frame to `.childOffset`, or alternatively, Clay provides a built in mechanism for tracking and updating scroll container offsets, detailed below.\n\nTo make scroll containers respond to mouse wheel and scroll events, two functions need to be called before `BeginLayout()`:\n```C\nClay_Vector2 mousePosition = { x, y };\n// Reminder: Clay_SetPointerState must be called before Clay_UpdateScrollContainers otherwise it will have no effect\nClay_SetPointerState(mousePosition);\n// Clay_UpdateScrollContainers needs to be called before Clay_BeginLayout for the position to avoid a 1 frame delay\nClay_UpdateScrollContainers(\n    true, // Enable drag scrolling\n    scrollDelta, // Clay_Vector2 scrollwheel / trackpad scroll x and y delta this frame\n    float deltaTime, // Time since last frame in seconds as a float e.g. 8ms is 0.008f\n);\n// ...\n// Clay internally tracks the scroll containers offset, and Clay_GetScrollOffset returns the x,y offset of the currently open element\nCLAY(CLAY_ID(\"ScrollContainer\"), { .clip = { .vertical = true, .childOffset = Clay_GetScrollOffset() } }) {\n    // Scrolling contents\n}\n// .childOffset can be provided directly if you would prefer to manage scrolling outside of clay\nCLAY(CLAY_ID(\"ScrollContainer\"), { .clip = { .vertical = true, .childOffset = myData.scrollContainer.offset } }) {\n    // Scrolling contents\n}\n```\n\nMore specific details can be found in the docs for [Clay_UpdateScrollContainers](#clay_updatescrollcontainers), [Clay_SetPointerState](#clay_setpointerstate), [Clay_ClipElementConfig](#clay_clipelementconfig) and [Clay_GetScrollOffset](#clay_getscrolloffset).\n\n### Floating Elements (\"Absolute\" Positioning)\n\nAll standard elements in clay are laid out on top of, and _within_ their parent, positioned according to their parent's layout rules, and affect the positioning and sizing of siblings.\n\n**\"Floating\"** is configured with the `CLAY_FLOATING()` macro. Floating elements don't affect the parent they are defined in, or the position of their siblings.\nThey also have a **z-index**, and as a result can intersect and render over the top of other elements.\n\nA classic example use case for floating elements is tooltips and modals.\n\n```C\n// The two text elements will be laid out top to bottom, and the floating container\n// will be attached to \"Outer\"\nCLAY(CLAY_ID(\"Outer\"), { .layout = { .layoutDirection = TOP_TO_BOTTOM } }) {\n    CLAY_TEXT(text, &headerTextConfig);\n    CLAY(CLAY_ID(\"Tooltip\"), { .floating = { .attachTo = CLAY_ATTACH_TO_PARENT } }) {}\n    CLAY_TEXT(text, &headerTextConfig);\n}\n```\n\nMore specific details can be found in the full [Floating API](#clay_floatingelementconfig).\n\n### Laying Out Your Own Custom Elements\n\nClay only supports a simple set of UI element primitives, such as rectangles, text and images. Clay provides a singular API for layout out custom elements:\n```C\n#include \"clay.h\"\n\ntypedef enum {\n    CUSTOM_ELEMENT_TYPE_MODEL,\n    CUSTOM_ELEMENT_TYPE_VIDEO\n} CustomElementType;\n\n// A rough example of how you could handle laying out 3d models in your UI\ntypedef struct {\n    CustomElementType type;\n    union {\n        Model model;\n        Video video;\n        // ...\n    };\n} CustomElementData;\n\nModel myModel = Load3DModel(filePath);\nCustomElement modelElement = (CustomElement) { .type = CUSTOM_ELEMENT_TYPE_MODEL, .model = myModel }\n\ntypedef struct {\n    void* memory;\n    uintptr_t offset;\n} Arena;\n\n// During init\nArena frameArena = (Arena) { .memory = malloc(1024) };\n\n// Custom elements only take a single pointer, so we need to store the data somewhere\nCustomElementData *modelData = (CustomElementData *)(frameArena.memory + frameArena.offset);\n*modelData = (CustomElementData) { .type = CUSTOM_ELEMENT_TYPE_MODEL, .model = myModel };\nframeArena.offset += sizeof(CustomElementData);\nCLAY(CLAY_ID(\"3DModelViewer\"), { .custom = { .customData = modelData } }) {}\n\n// Later during your rendering\nswitch (renderCommand->commandType) {\n    // ...\n    case CLAY_RENDER_COMMAND_TYPE_CUSTOM: {\n        // Your extended struct is passed through\n        CustomElementData *customElement = renderCommand->config.customElementConfig->customData;\n        if (!customElement) continue;\n        switch (customElement->type) {\n            case CUSTOM_ELEMENT_TYPE_MODEL: {\n                // Render your 3d model here\n                break;\n            }\n            case CUSTOM_ELEMENT_TYPE_VIDEO: {\n                // Render your video here\n                break;\n            }\n            // ...\n        }\n        break;\n    }\n}\n```\n\nMore specific details can be found in the full [Custom Element API](#clay_customelementconfig).\n\n### Retained Mode Rendering\nClay was originally designed for [Immediate Mode](https://www.youtube.com/watch?v=Z1qyvQsjK5Y) rendering - where the entire UI is redrawn every frame. This may not be possible with your platform, renderer design or performance constraints.\n\nThere are some general techniques that can be used to integrate clay into a retained mode rendering system:\n\n- `Clay_RenderCommand` includes the `uint32_t id` that was used to declare the element. If unique ids are used, these can be mapped to persistent graphics objects across multiple frames / layouts.\n- Render commands are culled automatically to only currently visible elements, and `Clay_RenderCommand` is a small enough struct that you can simply compare the memory of two render commands with matching IDs to determine if the element is \"dirty\" and needs to be re-rendered or updated.\n\nFor a worked example, see the provided [HTML renderer](https://github.com/nicbarker/clay/blob/main/renderers/web/html/clay-html-renderer.html). This renderer converts clay layouts into persistent HTML documents with minimal changes per frame.  \n\n### Visibility Culling\nClay provides a built-in visibility-culling mechanism that is **enabled by default**. It will only output render commands for elements that are visible - that is, **at least one pixel of their bounding box is inside the viewport.**\n\nThis culling mechanism can be disabled via the use of the `#define CLAY_DISABLE_CULLING` directive. See [Preprocessor Directives](#preprocessor-directives) for more information.\n\n### Preprocessor Directives\nClay supports C preprocessor directives to modulate functionality at compile time. These can be set either in code using `#define CLAY_DISABLE_CULLING` or on the command line when compiling using the appropriate compiler specific arguments, e.g. `clang -DCLAY_DISABLE_CULLING main.c ...`\n\nThe supported directives are:\n\n- `CLAY_WASM` - Required when targeting Web Assembly.\n- `CLAY_DLL` - Required when creating a .Dll file.\n\n### Bindings for non C\n\nClay is usable out of the box as a `.h` include in both C99 and C++20 with designated initializer support.\nThere are also supported bindings for other languages, including:\n\n- [Odin Bindings](https://github.com/nicbarker/clay/tree/main/bindings/odin)\n- [Rust Bindings](https://github.com/clay-ui-rs/clay)\n\n### Other implementations\nClay has also been implemented in other languages:\n\n- [`glay`](https://github.com/soypat/glay) - Go line-by-line rewrite with readability as main goal.\n- [`totallygamerjet/clay`](https://github.com/totallygamerjet/clay) - Port using `cxgo`, a C to Go transpiler.\n- [`goclay`](https://github.com/igadmg/goclay) - Go line-by-line rewrite closely matching the reference.\n\n### Debug Tools\n\nClay includes built-in UI debugging tools, similar to the \"inspector\" in browsers such as Chrome or Firefox. These tools are included in `clay.h`, and work by injecting additional render commands into the output [Clay_RenderCommandArray](#clay_rendercommandarray).\n\nAs long as the renderer that you're using works correctly, no additional setup or configuration is required to use the debug tools.\n\nTo enable the debug tools, use the function `Clay_SetDebugModeEnabled(bool enabled)`. This boolean is persistent and does not need to be set every frame.\n\nThe debug tooling by default will render as a panel to the right side of the screen, compressing your layout by its width. The default width is 400 and is currently configurable via the direct mutation of the internal variable `Clay__debugViewWidth`, however this is an internal API and is potentially subject to change.\n\n<img width=\"1506\" alt=\"Screenshot 2024-09-12 at 12 54 03 PM\" src=\"https://github.com/user-attachments/assets/2d122658-3305-4e27-88d6-44f08c0cb4e6\">\n\n_The official Clay website with debug tooling visible_\n\n### Running more than one Clay instance\n\nClay allows you to run more than one instance in a program. To do this, [Clay_Initialize](#clay_initialize) returns a [Clay_Context*](#clay_context) reference. You can activate a specific instance using [Clay_SetCurrentContext](#clay_setcurrentcontext). If [Clay_SetCurrentContext](#clay_setcurrentcontext) is not called, then Clay will default to using the context from the most recently called [Clay_Initialize](#clay_initialize).\n\n**âš  Important: Do not render instances across different threads simultaneously, as Clay does not currently support proper multi-threading.**\n\n```c++\n// Define separate arenas for the instances.\nClay_Arena arena1, arena2;\n// ... allocate arenas\n\n// Initialize both instances, storing the context for each one.\nClay_Context* instance1 = Clay_Initialize(arena1, layoutDimensions, errorHandler);\nClay_Context* instance2 = Clay_Initialize(arena2, layoutDimensions, errorHandler);\n\n// In the program's render function, activate each instance before executing clay commands and macros.\nClay_SetCurrentContext(instance1);\nClay_BeginLayout();\n// ... declare layout for instance1\nClay_RenderCommandArray renderCommands1 = Clay_EndLayout();\nrender(renderCommands1);\n\n// Switch to the second instance\nClay_SetCurrentContext(instance2);\nClay_BeginLayout();\n// ... declare layout for instance2\nClay_RenderCommandArray renderCommands2 = Clay_EndLayout();\nrender(renderCommands2);\n```\n\n# API\n\n### Naming Conventions\n\n- \"**CAPITAL_LETTERS()**\" are used for macros.\n- \"**Clay__**\" (\"Clay\" followed by **double** underscore) is used for internal functions that are not intended for use and are subject to change.\n- \"**Clay_**\" (\"Clay\" followed by **single** underscore) is used for external functions that can be called by the user.\n\n## Public Functions\n\n### Lifecycle for public functions\n\n**At startup / initialization time, run once**\n`Clay_MinMemorySize` -> `Clay_CreateArenaWithCapacityAndMemory` -> `Clay_Initialize` -> `Clay_SetMeasureTextFunction`\n\n**Each Frame**\n`Clay_SetLayoutDimensions` -> `Clay_SetPointerState` -> `Clay_UpdateScrollContainers` -> `Clay_BeginLayout` -> `CLAY() etc...` -> `Clay_EndLayout`\n\n---\n\n### Clay_MinMemorySize\n\n`uint32_t Clay_MinMemorySize()`\n\nReturns the minimum amount of memory **in bytes** that clay needs to accommodate the current [CLAY_MAX_ELEMENT_COUNT](#preprocessor-directives).\n\n---\n\n### Clay_CreateArenaWithCapacityAndMemory\n\n`Clay_Arena Clay_CreateArenaWithCapacityAndMemory(uint32_t capacity, void *offset)`\n\nCreates a `Clay_Arena` struct with the given capacity and base memory pointer, which can be passed to [Clay_Initialize](#clay_initialize).\n\n---\n\n### Clay_SetMeasureTextFunction\n\n`void Clay_SetMeasureTextFunction(Clay_Dimensions (*measureTextFunction)(Clay_StringSlice text, Clay_TextElementConfig *config, uintptr_t userData), uintptr_t userData)`\n\nTakes a pointer to a function that can be used to measure the `width, height` dimensions of a string. Used by clay during layout to determine [CLAY_TEXT](#clay_text) element sizing and wrapping.\n\n**Note 1: This string is not guaranteed to be null terminated.** Clay saves significant performance overhead by using slices when wrapping text instead of having to clone new null terminated strings. If your renderer does not support **ptr, length** style strings (e.g. Raylib), you will need to clone this to a new C string before rendering.\n\n**Note 2: It is essential that this function is as fast as possible.** For text heavy use-cases this function is called many times, and despite the fact that clay caches text measurements internally, it can easily become the dominant overall layout cost if the provided function is slow. **This is on the hot path!**\n\n---\n\n### Clay_ResetMeasureTextCache\n\n`void Clay_ResetMeasureTextCache(void)`\n\nClay caches measurements from the provided MeasureTextFunction, and this will be sufficient for the majority of use-cases. However, if the measurements can depend on external factors that clay does not know about, like DPI changes, then the cached values may be incorrect. When one of these external factors changes, Clay_ResetMeasureTextCache can be called to force clay to recalculate all string measurements in the next frame.\n\n---\n\n### Clay_SetMaxElementCount\n\n`void Clay_SetMaxElementCount(uint32_t maxElementCount)`\n\nSets the internal maximum element count that will be used in subsequent [Clay_Initialize()](#clay_initialize) and [Clay_MinMemorySize()](#clay_minmemorysize) calls, allowing clay to allocate larger UI hierarchies.\n\n**Note: You will need to reinitialize clay, after calling [Clay_MinMemorySize()](#clay_minmemorysize) to calculate updated memory requirements.**\n\n---\n\n### Clay_SetMaxMeasureTextCacheWordCount\n\n`void Clay_SetMaxMeasureTextCacheWordCount(uint32_t maxMeasureTextCacheWordCount)`\n\nSets the internal text measurement cache size that will be used in subsequent [Clay_Initialize()](#clay_initialize) and [Clay_MinMemorySize()](#clay_minmemorysize) calls, allowing clay to allocate more text. The value represents how many separate words can be stored in the text measurement cache.\n\n**Note: You will need to reinitialize clay, after calling [Clay_MinMemorySize()](#clay_minmemorysize) to calculate updated memory requirements.**\n\n---\n\n### Clay_Initialize\n\n`Clay_Context* Clay_Initialize(Clay_Arena arena, Clay_Dimensions layoutDimensions, Clay_ErrorHandler errorHandler)`\n\nInitializes the internal memory mapping, sets the internal dimensions for layout, and binds an error handler for clay to use when something goes wrong. Returns a [Clay_Context*](#clay_context) that can optionally be given to [Clay_SetCurrentContext](#clay_setcurrentcontext) to allow running multiple instances of clay in the same program, and sets it as the current context. See [Running more than one Clay instance](#running-more-than-one-clay-instance).\n\nReference: [Clay_Arena](#clay_createarenawithcapacityandmemory), [Clay_ErrorHandler](#clay_errorhandler), [Clay_SetCurrentContext](#clay_setcurrentcontext)\n\n---\n\n### Clay_SetCurrentContext\n\n`void Clay_SetCurrentContext(Clay_Context* context)`\n\nSets the context that subsequent clay commands will operate on. You can get this reference from [Clay_Initialize](#clay_initialize) or [Clay_GetCurrentContext](#clay_getcurrentcontext). See [Running more than one Clay instance](#running-more-than-one-clay-instance).\n\n---\n\n### Clay_GetCurrentContext\n\n`Clay_Context* Clay_GetCurrentContext()`\n\nReturns the context that clay commands are currently operating on, or null if no context has been set. See [Running more than one Clay instance](#running-more-than-one-clay-instance).\n\n---\n\n### Clay_SetLayoutDimensions\n\n`void Clay_SetLayoutDimensions(Clay_Dimensions dimensions)`\n\nSets the internal layout dimensions. Cheap enough to be called every frame with your screen dimensions to automatically respond to window resizing, etc.\n\n---\n\n### Clay_SetPointerState\n\n`void Clay_SetPointerState(Clay_Vector2 position, bool isPointerDown)`\n\nSets the internal pointer position and state (i.e. current mouse / touch position) and recalculates overlap info, which is used for mouseover / click calculation (via [Clay_PointerOver](#clay_pointerover) and updating scroll containers with [Clay_UpdateScrollContainers](#clay_updatescrollcontainers). **isPointerDown should represent the current state this frame, e.g. it should be `true` for the entire duration the left mouse button is held down.** Clay has internal handling for detecting click / touch start & end.\n\n---\n\n### Clay_UpdateScrollContainers\n\n`void Clay_UpdateScrollContainers(bool enableDragScrolling, Clay_Vector2 scrollDelta, float deltaTime)`\n\nThis function handles scrolling of containers. It responds to both `scrollDelta`, which represents mouse wheel or trackpad scrolling this frame, as well as \"touch scrolling\" on mobile devices, or \"drag scrolling\" with a mouse or similar device.\n\nTouch / drag scrolling only occurs if the `enableDragScrolling` parameter is `true`, **and** [Clay_SetPointerState](#clay_setpointerstate) has been called this frame. As a result, you can simply always call it with `false` as the first argument if you want to disable touch scrolling.\n\n`deltaTime` is the time **in seconds** since the last frame (e.g. 0.016 is **16 milliseconds**), and is used to normalize & smooth scrolling across different refresh rates.\n\n---\n\n### Clay_GetScrollOffset\n\n`Clay_Vector2 Clay_GetScrollOffset()`\n\nReturns the internally stored scroll offset for the currently open element.\n\nGenerally intended for use with [clip elements](#clay_clipelementconfig) and the `.childOffset` field to create scrolling containers.\n\nSee [Scrolling Elements](#scrolling-elements) for more details.\n\n```C\n// Create a horizontally scrolling container\nCLAY(CLAY_ID(\"ScrollContainer\"), {\n    .clip = { .horizontal = true, .childOffset = Clay_GetScrollOffset() }\n})\n```\n\n---\n\n### Clay_BeginLayout\n\n`void Clay_BeginLayout()`\n\nPrepares clay to calculate a new layout. Called each frame / layout **before** any of the [Element Macros](#element-macros).\n\n---\n\n### Clay_EndLayout\n\n`Clay_RenderCommandArray Clay_EndLayout()`\n\nEnds declaration of element macros and calculates the results of the current layout. Renders a [Clay_RenderCommandArray](#clay_rendercommandarray) containing the results of the layout calculation.\n\n---\n\n### Clay_Hovered\n\n`bool Clay_Hovered()`\n\nCalled **during** layout declaration, and returns `true` if the pointer position previously set with `Clay_SetPointerState` is inside the bounding box of the currently open element. Note: this is based on the element's position from the **last** frame.\n\n---\n\n### Clay_OnHover\n\n`void Clay_OnHover(void (*onHoverFunction)(Clay_ElementId elementId, Clay_PointerData pointerData, void *userData), void *userData)`\n\nCalled **during** layout declaration, this function allows you to attach a function pointer to the currently open element that will be called once per layout if the pointer position previously set with `Clay_SetPointerState` is inside the bounding box of the currently open element. See [Clay_PointerData](#clay_pointerdata) for more information on the `pointerData` argument.\n\n```C\nvoid HandleButtonInteraction(Clay_ElementId elementId, Clay_PointerData pointerData, void *userData) {\n    ButtonData *buttonData = (ButtonData *)userData;\n    // Pointer state allows you to detect mouse down / hold / release\n    if (pointerData.state == CLAY_POINTER_DATA_PRESSED_THIS_FRAME) {\n        // Do some click handling\n        NavigateTo(buttonData->link);\n    }\n}\n\nButtonData linkButton = (ButtonData) { .link = \"https://github.com/nicbarker/clay\" };\n\n// HandleButtonInteraction will be called for each frame the mouse / pointer / touch is inside the button boundaries\nCLAY(CLAY_ID(\"Button\"), { .layout = { .padding = CLAY_PADDING_ALL(8) } }) {\n    Clay_OnHover(HandleButtonInteraction, &buttonData);\n    CLAY_TEXT(CLAY_STRING(\"Click me!\"), &headerTextConfig);\n}\n```\n\n---\n\n### Clay_PointerOver\n\n`bool Clay_PointerOver(Clay_ElementId id)`\n\nReturns `true` if the pointer position previously set with `Clay_SetPointerState` is inside the bounding box of the layout element with the provided `id`. Note: this is based on the element's position from the **last** frame. If frame-accurate pointer overlap detection is required, perhaps in the case of significant change in UI layout between frames, you can simply run your layout code twice that frame. The second call to `Clay_PointerOver` will be frame-accurate.\n\n### Clay_GetScrollContainerData\n\n`Clay_ScrollContainerData Clay_GetScrollContainerData(Clay_ElementId id)`\n\nReturns [Clay_ScrollContainerData](#clay_scrollcontainerdata) for the scroll container matching the provided ID. This function allows imperative manipulation of scroll position, allowing you to build things such as scroll bars, buttons that \"jump\" to somewhere in a scroll container, etc.\n\n---\n\n### Clay_GetElementData\n\n`Clay_ElementData Clay_GetElementData(Clay_ElementId id)`\n\nReturns [Clay_ElementData](#clay_elementdata) for the element matching the provided ID.\nUsed to retrieve information about elements such as their final calculated bounding box.\n\n---\n\n### Clay_GetElementId\n\n`Clay_ElementId Clay_GetElementId(Clay_String idString)`\n\nReturns a [Clay_ElementId](#clay_elementid) for the provided id string, used for querying element info such as mouseover state, scroll container data, etc.\n\n## Element Macros\n\n### CLAY()\n**Usage**\n\n`CLAY(...configuration) { ...children }`\n\n**Lifecycle**\n\n`Clay_BeginLayout()` -> `CLAY()` -> `Clay_EndLayout()` \n\n**Notes**\n\n**CLAY** opens a generic empty container, that is configurable and supports nested children.\n**CLAY** requires a parameter, so if you want to create an element without any configuration, use `CLAY(0)`.\n\n**Examples**\n```C\n// Define an element with 16px of x and y padding\nCLAY(CLAY_ID(\"Outer\"), { .layout = { .padding = CLAY_PADDING_ALL(16) } }) {\n    // A nested child element\n    CLAY(CLAY_ID(\"SideBar\"), { .layout = { .layoutDirection = CLAY_TOP_TO_BOTTOM, .childGap = 16 } }) {\n        // Children laid out top to bottom with a 16 px gap between them\n    }\n    // A vertical scrolling container with a colored background\n    CLAY(CLAY_ID(\"ScrollContainer\"), {\n        .layout = { .layoutDirection = CLAY_TOP_TO_BOTTOM, .childGap = 16 },\n        .backgroundColor = { 200, 200, 100, 255 },\n        .cornerRadius = CLAY_CORNER_RADIUS(10),\n        .clip = { .vertical = true, .childOffset = Clay_GetScrollOffset() }\n    }) {\n        // child elements\n    }\n}\n```\n\n---\n\n### CLAY_AUTO_ID()\n\nA version of the core [CLAY()](#clay) element creation macro that generates an ID automatically instead of requiring it as the first argument.\n\nNote that under the hood this ID is generated in the same way as [CLAY_ID_LOCAL()](#clay_id_local), which is based on the element's position in the hierarchy, and may chance between layout calls if elements are added / removed from the hierarchy before the element is defined. As a result, for transitions & retained mode backends to work correctly, IDs should be specified.\n\n```C\n// Note that CLAY_AUTO_ID only takes one argument: the configuration\nCLAY_AUTO_ID({ .layout = { .padding = CLAY_PADDING_ALL(16) } }) {\n    // A nested child element\n    CLAY_AUTO_ID({ .layout = { .layoutDirection = CLAY_TOP_TO_BOTTOM, .childGap = 16 } }) {\n        // Children laid out top to bottom with a 16 px gap between them\n    }\n    // A vertical scrolling container with a colored background\n    CLAY_AUTO_ID({\n        .layout = { .layoutDirection = CLAY_TOP_TO_BOTTOM, .childGap = 16 },\n        .backgroundColor = { 200, 200, 100, 255 },\n        .cornerRadius = CLAY_CORNER_RADIUS(10),\n        .clip = { .vertical = true, .childOffset = Clay_GetScrollOffset() }\n    }) {\n        // child elements\n    }\n}\n```\n\n---\n\n### CLAY_TEXT()\n**Usage**\n\n`CLAY_TEXT(Clay_String textContents, Clay_TextElementConfig *textConfig);`\n\n**Lifecycle**\n\n`Clay_BeginLayout()` -> `CLAY_TEXT()` -> `Clay_EndLayout()`\n\n**Notes**\n\n**TEXT** is a measured, auto-wrapped text element. It uses `Clay_TextElementConfig` to configure text specific options.\n\nNote that `Clay_TextElementConfig` uses `uint32_t fontId`. Font ID to font asset mapping is managed in user code and passed to render commands.\n\n**Struct API (Pseudocode)**\n\n```C\n// CLAY_TEXT(text, CLAY_TEXT_CONFIG({ .member = value })) supports these options\nClay_TextElementConfig {\n    Clay_Color textColor {\n        float r; float g; float b; float a;\n    };\n    uint16_t fontId;\n    uint16_t fontSize;\n    uint16_t letterSpacing;\n    uint16_t lineHeight;\n    Clay_TextElementConfigWrapMode wrapMode {\n        CLAY_TEXT_WRAP_WORDS (default),\n        CLAY_TEXT_WRAP_NEWLINES,\n        CLAY_TEXT_WRAP_NONE,\n    };\n};\n```\n\n**Fields**\n\n**`.textColor`**\n\n`CLAY_TEXT_CONFIG(.textColor = {120, 120, 120, 255})`\n\nUses [Clay_Color](#clay_color). Conventionally accepts `rgba` float values between 0 and 255, but interpretation is left up to the renderer and does not affect layout.\n\n---\n\n**`.fontId`**\n\n`CLAY_TEXT_CONFIG(.fontId = FONT_ID_LATO)`\n\nIt's up to the user to load fonts and create a mapping from `fontId` to a font that can be measured and rendered.\n\n---\n\n**`.fontSize`**\n\n`CLAY_TEXT_CONFIG(.fontSize = 16)`\n\nFont size is generally thought of as `x pixels tall`, but interpretation is left up to the user & renderer.\n\n---\n\n**`.letterSpacing`**\n\n`CLAY_TEXT_CONFIG(.letterSpacing = 1)`\n\n`.letterSpacing` results in **horizontal** white space between individual rendered characters.\n\n---\n\n**`.lineHeight`**\n\n`CLAY_TEXT_CONFIG(.lineHeight = 20)`\n\n`.lineHeight` - when non zero - forcibly sets the `height` of each wrapped line of text to `.lineheight` pixels tall. Will affect the layout of both parents and siblings. A value of `0` will use the measured height of the font.\n\n---\n\n**`.wrapMode`**\n\n`CLAY_TEXT_CONFIG(.wrapMode = CLAY_TEXT_WRAP_NONE)`\n\n`.wrapMode` specifies under what conditions text should [wrap](https://en.wikipedia.org/wiki/Line_wrap_and_word_wrap).\n\nAvailable options are:\n\n- `CLAY_TEXT_WRAP_WORDS` (default) - Text will wrap on whitespace characters as container width shrinks, preserving whole words.\n- `CLAY_TEXT_WRAP_NEWLINES` -  will only wrap when encountering newline characters.\n- `CLAY_TEXT_WRAP_NONE` - Text will never wrap even if its container is compressed beyond the text measured width.\n\n---\n\n**Examples**\n\n```C\n// Define a font somewhere in your code\nconst uint32_t FONT_ID_LATO = 3;\n// ..\nCLAY_TEXT(CLAY_STRING(\"John Smith\"), CLAY_TEXT_CONFIG({ .fontId = FONT_ID_LATO, .fontSize = 24, .textColor = {255, 0, 0, 255} }));\n// Rendering example\nFont fontToUse = LoadedFonts[renderCommand->renderData.text->fontId];\n```\n\n**Rendering**\n\nElement is subject to [culling](#visibility-culling). Otherwise, multiple `Clay_RenderCommand`s with `commandType = CLAY_RENDER_COMMAND_TYPE_TEXT` may be created, one for each wrapped line of text.\n\n`Clay_RenderCommand.textContent` will be populated with a `Clay_String` _slice_ of the original string passed in (i.e. wrapping doesn't reallocate, it just returns a `Clay_String` pointing to the start of the new line with a `length`)\n\n---\n\n### CLAY_ID\n\n`Clay_ElementId CLAY_ID(STRING_LITERAL idString)`\n\n**CLAY_ID()** is used to generate and attach a [Clay_ElementId](#clay_elementid) to a layout element during declaration.\n\nNote this macro only works with String literals and won't compile if used with a `char*` variable. To use a heap allocated `char*` string as an ID, use [CLAY_SID](#clay_sid). \n\nTo regenerate the same ID outside of layout declaration when using utility functions such as [Clay_PointerOver](#clay_pointerover), use the [Clay_GetElementId](#clay_getelementid) function.\n\n**Examples**\n\n```C\n// Tag a button with the Id \"Button\"\nCLAY(CLAY_ID(\"Button\"), {\n    .layout = { .layoutDirection = CLAY_TOP_TO_BOTTOM, .sizing = { .width = CLAY_SIZING_GROW(0) }, .padding = CLAY_PADDING_ALL(16), .childGap = 16 }\n}) {\n    // ...children\n}\n\n// Later on outside of layout code\nbool buttonIsHovered = Clay_IsPointerOver(Clay_GetElementId(\"Button\"));\nif (buttonIsHovered && leftMouseButtonPressed) {\n    // ... do some click handling\n}\n```\n\n---\n\n### CLAY_SID()\n\n`Clay_ElementId CLAY_SID(Clay_String idString)`\n\nA version of [CLAY_ID](#clay_id) that can be used with heap allocated `char *` data. The underlying `char` data will not be copied internally and should live until at least the next frame.\n\n---\n\n### CLAY_IDI()\n\n`Clay_ElementId CLAY_IDI(STRING_LITERAL idString, int32_t index)`\n\nAn offset version of [CLAY_ID](#clay_id). Generates a [Clay_ElementId](#clay_elementid) string id from the provided `char *label`, combined with the `int index`.\n\nUsed for generating ids for sequential elements (such as in a `for` loop) without having to construct dynamic strings at runtime.\n\nNote this macro only works with String literals and won't compile if used with a `char*` variable. To use a heap allocated `char*` string as an ID, use [CLAY_SIDI](#clay_sidi).\n\n---\n\n### CLAY_SIDI()\n\n`Clay_ElementId CLAY_SIDI(Clay_String idString, int32_t index)`\n\nA version of [CLAY_IDI](#clay_idi) that can be used with heap allocated `char *` data. The underlying `char` data will not be copied internally and should live until at least the next frame.\n\n---\n\n### CLAY_ID_LOCAL()\n\n**Usage**\n\n`Clay_ElementId CLAY_ID_LOCAL(STRING_LITERAL idString)`\n\n**Lifecycle**\n\n`Clay_BeginLayout()` -> `CLAY(` -> `CLAY_ID_LOCAL()` -> `)` -> `Clay_EndLayout()`\n\n**Notes**\n\n**CLAY_ID_LOCAL()** is used to generate and attach a [Clay_ElementId](#clay_elementid) to a layout element during declaration.\n\nUnlike [CLAY_ID](#clay_id) which needs to be globally unique, a local ID is based on the ID of it's parent and only needs to be unique among its siblings.\n\nAs a result, local id is suitable for use in reusable components and loops.\n\nNote this macro only works with String literals and won't compile if used with a `char*` variable. To use a heap allocated `char*` string as an ID, use [CLAY_SID_LOCAL](#clay_sid_local).\n\n**Examples**\n\n```C\nvoid RenderHeaderButton(ButtonData button) {\n    CLAY({\n        .id = CLAY_ID_LOCAL(\"HeaderButton\"),\n        .layout = { .layoutDirection = CLAY_TOP_TO_BOTTOM, .sizing = { .width = CLAY_SIZING_GROW(0) }, .padding = CLAY_PADDING_ALL(16), .childGap = 16 }\n    }) {\n        // ...children\n    }\n}\n\nfor (int i = 0; i < headerButtons.length; i++) {\n    RenderHeaderButton(headerButtons.items[i]);\n}\n```\n\n---\n\n### CLAY_SID_LOCAL()\n\n`Clay_ElementId CLAY_SID_LOCAL(Clay_String idString)`\n\nA version of [CLAY_ID_LOCAL](#clay_id_local) that can be used with heap allocated `char *` data. The underlying `char` data will not be copied internally and should live until at least the next frame.\n\n---\n\n### CLAY_IDI_LOCAL()\n\n`Clay_ElementId CLAY_IDI_LOCAL(STRING_LITERAL idString, int32_t index)`\n\nAn offset version of [CLAY_ID_LOCAL](#clay_local_id). Generates a [Clay_ElementId](#clay_elementid) string id from the provided `char *label`, combined with the `int index`.\n\nUsed for generating ids for sequential elements (such as in a `for` loop) without having to construct dynamic strings at runtime.\n\nNote this macro only works with String literals and won't compile if used with a `char*` variable. To use a heap allocated `char*` string as an ID, use [CLAY_SIDI_LOCAL](#clay_sidi_local).\n\n---\n\n### CLAY_SIDI_LOCAL()\n\n`Clay_ElementId CLAY_SIDI_LOCAL(Clay_String idString, int32_t index)`\n\nA version of [CLAY_IDI_LOCAL](#clay_idi_local) that can be used with heap allocated `char *` data. The underlying `char` data will not be copied internally and should live until at least the next frame.\n\n---\n\n## Data Structures & Definitions\n\n### Clay_ElementDeclaration\nThe **Clay_ElementDeclaration** struct is the only argument to the `CLAY()` macro and provides configuration options for layout elements.\n\n```C\ntypedef struct {\n    Clay_ElementId id;\n    Clay_LayoutConfig layout;\n    Clay_Color backgroundColor;\n    Clay_CornerRadius cornerRadius;\n    Clay_AspectRatioElementConfig aspectRatio;\n    Clay_ImageElementConfig image;\n    Clay_FloatingElementConfig floating;\n    Clay_CustomElementConfig custom;\n    Clay_ClipElementConfig clip;\n    Clay_BorderElementConfig border;\n    void *userData;\n} Clay_ElementDeclaration;\n```\n\n**Fields**\n\n**`.layout`** - `Clay_LayoutConfig`\n\n`CLAY(CLAY_ID(\"Element\"), { .layout = { .padding = { 16, 16, 12, 12 }, .layoutDirection = CLAY_TOP_TO_BOTTOM } })`\n\nUses [Clay_LayoutConfig](#clay_layoutconfig). Controls various settings related to _layout_, which can be thought of as \"the size and position of this element and its children\".\n\n---\n\n**`.backgroundColor`** - `Clay_Color`\n\n`CLAY(CLAY_ID(\"Element\"), { .backgroundColor = {120, 120, 120, 255} } })`\n\nUses [Clay_Color](#clay_color). Conventionally accepts `rgba` float values between 0 and 255, but interpretation is left up to the renderer and does not affect layout.\n\n---\n\n**`.cornerRadius`** - `float`\n\n`CLAY(CLAY_ID(\"Element\"), { .cornerRadius = { .topLeft = 16, .topRight = 16, .bottomLeft = 16, .bottomRight = 16 } })`\n\nDefines the radius in pixels for the arc of rectangle corners (`0` is square, `rectangle.width / 2` is circular).\n\nNote that the `CLAY_CORNER_RADIUS(radius)` function-like macro is available to provide short hand for setting all four corner radii to the same value. e.g. `CLAY_BORDER({ .cornerRadius = CLAY_CORNER_RADIUS(10) })`\n\n---\n\n**`.aspectRatio`** - `Clay_AspectRatioElementConfig`\n\n`CLAY(CLAY_ID(\"Element\"), { .aspectRatio = 1 })`\n\nUses [Clay_AspectRatioElementConfig](#clay_aspectratioelementconfig). Configures the element as an aspect ratio scaling element. Especially useful for rendering images, but can also be used to enforce a fixed width / height ratio of other elements.\n\n---\n\n**`.image`** - `Clay_ImageElementConfig`\n\n`CLAY(CLAY_ID(\"Element\"), { .image = { .imageData = &myImage } })`\n\nUses [Clay_ImageElementConfig](#clay_imageelementconfig). Configures the element as an image element. Causes a render command with type `IMAGE` to be emitted.\n\n---\n\n**`.floating`** - `Clay_FloatingElementConfig`\n\n`CLAY(CLAY_ID(\"Element\"), { .floating = { .attachTo = CLAY_ATTACH_TO_PARENT } })`\n\nUses [Clay_FloatingElementConfig](#clay_floatingelementconfig). Configures the element as an floating element, which allows it to stack \"in front\" and \"on top\" of other elements without affecting sibling or parent size or position. \n\n---\n\n**`.custom`** - `Clay_CustomElementConfig`\n\n`CLAY(CLAY_ID(\"Element\"), { .custom = { .customData = &my3DModel } })`\n\nUses [Clay_CustomElementConfig](#clay_customelementconfig). Configures the element as a custom element, which allows you to pass custom data through to the renderer. Causes a render command with type `CUSTOM` to be emitted.\n\n---\n\n**`.clip`** - `Clay_ClipElementConfig`\n\n`CLAY(CLAY_ID(\"Element\"), { .clip = { .vertical = true, .childOffset = Clay_GetScrollOffset() } })`\n\nUses [Clay_ClipElementConfig](#clay_scrollelementconfig). Configures the element as a clip element, which causes child elements to be clipped / masked if they overflow, and together with the functions listed in [Scrolling Elements](#scrolling-elements) enables scrolling of child contents.\n\n<img width=\"580\" alt=\"An image demonstrating the concept of clipping which prevents rendering of a child elements pixels if they fall outside the bounds of the parent element.\" src=\"https://github.com/user-attachments/assets/2eb83ff9-e186-4ea4-8a87-d90cbc0838b5\">\n\n---\n\n**`.border`** - `Clay_BorderElementConfig`\n\n`CLAY(CLAY_ID(\"Element\"), { .border = { .width = { .left = 5 }, .color = COLOR_BLUE } })`\n\nUses [Clay_BorderElementConfig](#clay_borderelementconfig). Configures the element as a border element, which instructs the renderer to draw coloured border lines along the perimeter of this element's bounding box. Causes a render command with type `BORDER` to be emitted.\n\n---\n\n**`.userData`** - `void *`\n\n`CLAY(CLAY_ID(\"Element\"), { .userData = &extraData })`\n\nTransparently passes a pointer through to the corresponding [Clay_RenderCommands](#clay_rendercommand)s generated by this element.\n\n---\n\n**Examples**\n\n```C\n// Declare a reusable rectangle config, with a purple color and 10px rounded corners\nClay_RectangleElementConfig rectangleConfig = (Clay_RectangleElementConfig) { .color = { 200, 200, 100, 255 }, .cornerRadius = CLAY_CORNER_RADIUS(10) };\n// Declare a rectangle element using a reusable config\nCLAY(CLAY_ID(\"Box\"), rectangleConfig) {}\n// Declare a retangle element using an inline config\nCLAY(CLAY_ID(\"BoxInline\"), { .color = { 200, 200, 100, 255 }, .cornerRadius = CLAY_CORNER_RADIUS(10) })) {\n    // child elements\n}\n// Declare a scrolling container with a colored background\nCLAY(CLAY_ID(\"ScrollingContainer\"), { \n    .backgroundColor = { 200, 200, 100, 255 }, \n    .cornerRadius = CLAY_CORNER_RADIUS(10)\n    .clip = { .vertical = true, .childOffset = Clay_GetScrollOffset() }\n) {\n    // child elements\n}\n```\n\nElement is subject to [culling](#visibility-culling). Otherwise, a single `Clay_RenderCommand`s with `commandType = CLAY_RENDER_COMMAND_TYPE_RECTANGLE` will be created, with `renderCommand->elementConfig.rectangleElementConfig` containing a pointer to the element's Clay_RectangleElementConfig.\n\n### Clay_LayoutConfig\n\n**Clay_LayoutConfig** is used for configuring _layout_ options (i.e. options that affect the final position and size of an element, its parents, siblings, and children)\n\n**Struct API (Pseudocode)**\n\n```C\n// CLAY({ .layout = { ...fields } }) supports these options\nClay_LayoutConfig {\n    Clay_LayoutDirection layoutDirection = CLAY_LEFT_TO_RIGHT (default) | CLAY_TOP_TO_BOTTOM;\n    Clay_Padding padding {\n        u16 left; u16 right; u16 top; u16 bottom; \n    };\n    uint16_t childGap;\n    Clay_ChildAlignment childAlignment {\n        .x = CLAY_ALIGN_X_LEFT (default) | CLAY_ALIGN_X_CENTER | CLAY_ALIGN_X_RIGHT;\n        .y = CLAY_ALIGN_Y_TOP (default) | CLAY_ALIGN_Y_CENTER | CLAY_ALIGN_Y_BOTTOM;\n    };\n    Clay_Sizing sizing { // Recommended to use the provided macros here - see #sizing for more in depth explanation\n        .width = CLAY_SIZING_FIT(float min, float max) (default) | CLAY_SIZING_GROW(float min, float max) | CLAY_SIZING_FIXED(float width) | CLAY_SIZING_PERCENT(float percent)\n        .height = CLAY_SIZING_FIT(float min, float max) (default) | CLAY_SIZING_GROW(float min, float max) | CLAY_SIZING_FIXED(float height) | CLAY_SIZING_PERCENT(float percent)\n    }; // See CLAY_SIZING_GROW() etc for more details\n};\n```\n\n**Fields**\n\n**`.layoutDirection`** - `Clay_LayoutDirection`\n\n`CLAY(CLAY_ID(\"Element\"), { .layout = { .layoutDirection = CLAY_TOP_TO_BOTTOM } })`\n\nControls the axis / direction in which child elements are laid out. Available options are `CLAY_LEFT_TO_RIGHT` (default) and `CLAY_TOP_TO_BOTTOM`.\n\n_Did you know that \"left to right\" and \"top to bottom\" both have 13 letters?_\n\n<img width=\"580\" alt=\"Screenshot 2024-08-22 at 11 10 27 AM\" src=\"https://github.com/user-attachments/assets/7008aa47-8826-4338-9257-8bc83f7813ce\">\n\n---\n\n**`.padding`** - `Clay_Padding`\n\n`CLAY(CLAY_ID(\"Element\"), { .layout = { .padding = { .left = 16, .right = 16, .top = 8, .bottom = 8 } } })`\n\nControls white-space \"padding\" around the **outside** of child elements.\n\n<img width=\"486\" alt=\"Screenshot 2024-08-22 at 10 50 49 AM\" src=\"https://github.com/user-attachments/assets/b454fa36-92d5-4b1d-bf8b-e4c25428e9de\">\n\n---\n\n**`.childGap`** - `uint16_t`\n\n`CLAY(CLAY_ID(\"Element\"), { .layout = { .childGap = 16 } })`\n\nControls the white-space **between** child elements as they are laid out. When `.layoutDirection` is `CLAY_LEFT_TO_RIGHT` (default), this will be horizontal space, whereas for `CLAY_TOP_TO_BOTTOM` it will be vertical space.\n\n<img width=\"600\" alt=\"Screenshot 2024-08-22 at 11 05 15 AM\" src=\"https://github.com/user-attachments/assets/fa0dae1f-1936-47f6-a299-634bd7d40d58\">\n\n---\n\n**`.childAlignment`** - `Clay_ChildAlignment`\n\n`CLAY(CLAY_ID(\"Element\"), { .layout = { .childAlignment = { .x = CLAY_ALIGN_X_LEFT, .y = CLAY_ALIGN_Y_CENTER } } })`\n\nControls the alignment of children relative to the height and width of the parent container. Available options are:\n```C\n.x = CLAY_ALIGN_X_LEFT (default) | CLAY_ALIGN_X_CENTER | CLAY_ALIGN_X_RIGHT;\n.y = CLAY_ALIGN_Y_TOP (default) | CLAY_ALIGN_Y_CENTER | CLAY_ALIGN_Y_BOTTOM;\n```\n\n<img width=\"1030\" alt=\"Screenshot 2024-08-22 at 11 25 16 AM\" src=\"https://github.com/user-attachments/assets/be61b4a7-db4f-447c-b6d6-b2d4a91fc664\">\n\n---\n\n**`.sizing`** - `Clay_Sizing`\n\n`CLAY(CLAY_ID(\"Element\"), { .layout = { .sizing = { .width = CLAY_SIZING_FIXED(300), .height = CLAY_SIZING_PERCENT(0.5) } } })`\n\nControls how final width and height of element are calculated. The same configurations are available for both the `.width` and `.height` axis. There are several options:\n\n- `CLAY_SIZING_FIT(float min, float max) (default)` - The element will be sized to fit its children (plus padding and gaps), up to `max`. If `max` is left unspecified, it will default to `FLOAT_MAX`. When elements are compressed to fit into a smaller parent, this element will not shrink below `min`.\n\n- `CLAY_SIZING_GROW(float min, float max)` - The element will grow to fill available space in its parent, up to `max`. If `max` is left unspecified, it will default to `FLOAT_MAX`. When elements are compressed to fit into a smaller parent, this element will not shrink below `min`.\n\n- `CLAY_SIZING_FIXED(float fixed)` - The final size will always be exactly the provided `fixed` value. Shorthand for `CLAY_SIZING_FIT(fixed, fixed)`\n\n- `CLAY_SIZING_PERCENT(float percent)` - Final size will be a percentage of parent size, minus padding and child gaps. `percent` is assumed to be a float between `0` and `1`.\n\n<img width=\"1056\" alt=\"Screenshot 2024-08-22 at 2 10 33 PM\" src=\"https://github.com/user-attachments/assets/1236efb1-77dc-44cd-a207-7944e0f5e500\">\n\n<img width=\"1141\" alt=\"Screenshot 2024-08-22 at 2 19 04 PM\" src=\"https://github.com/user-attachments/assets/a26074ff-f155-4d35-9ca4-9278a64aac00\">\n\n\n**Example Usage**\n\n```C\nCLAY(CLAY_ID(\"Button\"), { .layout = { .layoutDirection = CLAY_TOP_TO_BOTTOM, .sizing = { .width = CLAY_SIZING_GROW(0) }, .padding = CLAY_PADDING_ALL(16, .childGap = 16) } }) {\n    // Children will be laid out vertically with 16px of padding around and between\n}\n```\n\n---\n\n### Clay_ImageElementConfig\n**Usage**\n\n`CLAY(CLAY_ID(\"Element\"), { .image = { ...image config } }) {}`\n\n**Clay_ImageElementConfig** configures a clay element to render an image as its background.\n\n**Struct API (Pseudocode)**\n\n```C\nClay_ImageElementConfig {\n    void * imageData;\n};\n```\n\n**Fields**\n\n**`.imageData`** - `void *`\n\n`CLAY(CLAY_ID(\"Image\"), { .image = { .imageData = &myImage } }) {}`\n\n`.imageData` is a generic void pointer that can be used to pass through image data to the renderer.\n\n```C\n// Load an image somewhere in your code\nYourImage profilePicture = LoadYourImage(\"profilePicture.png\");\n// Note that when rendering, .imageData will be void* type.\nCLAY(CLAY_ID(\"Image\"), { .image = { .imageData = &profilePicture } }) {}\n```\n\n**Examples**\n\n```C\n// Load an image somewhere in your code\nYourImage profilePicture = LoadYourImage(\"profilePicture.png\");\n// Declare a reusable image config\nClay_ImageElementConfig imageConfig = (Clay_ImageElementConfig) { .imageData = &profilePicture };\n// Declare an image element using a reusable config\nCLAY(CLAY_ID(\"Image\"), { .image = imageConfig }) {}\n// Declare an image element using an inline config\nCLAY(CLAY_ID(\"ImageInline\"), { .image = { .imageData = &profilePicture }, .aspectRatio = 16.0 / 9.0 }) {}\n// Rendering example\nYourImage *imageToRender = renderCommand->elementConfig.imageElementConfig->imageData;\n```\n\n**Rendering**\n\nElement is subject to [culling](#visibility-culling). Otherwise, a single `Clay_RenderCommand`s with `commandType = CLAY_RENDER_COMMAND_TYPE_IMAGE` will be created. The user will need to access `renderCommand->renderData.image->imageData` to retrieve image data referenced during layout creation. It's also up to the user to decide how / if they wish to blend `renderCommand->renderData.image->backgroundColor` with the image.\n\n---\n\n### Clay_AspectRatioElementConfig\n\n**Usage**\n\n`CLAY(CLAY_ID(\"Aspect\"), { .aspectRatio = 16.0 / 9.0 }) {}`\n\n**Clay_AspectRatioElementConfig** configures a clay element to enforce a fixed width / height ratio in its final dimensions. Mostly used for image elements, but can also be used for non image elements.\n\n**Struct API (Pseudocode)**\n\n```C\nClay_AspectRatioElementConfig {\n    float aspectRatio;\n};\n```\n\n**Fields**\n\n**`.aspectRatio`** - `float`\n\n`CLAY(CLAY_ID(\"Aspect\"), { .aspectRatio = { .aspectRatio = 16.0 / 9.0 } }) {}`\n\nor alternatively, as C will automatically pass the value to the first nested struct field:\n\n`CLAY(CLAY_ID(\"Aspect\"), { .aspectRatio = 16.0 / 9.0 }) {}`\n\n**Examples**\n\n```C\n// Load an image somewhere in your code\nYourImage profilePicture = LoadYourImage(\"profilePicture.png\");\n// Declare an image element that will grow along the X axis while maintaining its original aspect ratio\nCLAY(CLAY_ID(\"ProfilePicture\"), {\n    .layout = { .width = CLAY_SIZING_GROW() },\n    .aspectRatio = profilePicture.width / profilePicture.height,\n    .image = { .imageData = &profilePicture },\n}) {}\n```\n\n---\n\n### Clay_ImageElementConfig\n**Usage**\n\n`CLAY(CLAY_ID(\"Image\"), { .image = { ...image config } }) {}`\n\n**Clay_ImageElementConfig** configures a clay element to render an image as its background.\n\n**Struct API (Pseudocode)**\n\n```C\nClay_ImageElementConfig {\n    void * imageData;\n};\n```\n\n**Fields**\n\n**`.imageData`** - `void *`\n\n`CLAY(CLAY_ID(\"Image\"), { .image = { .imageData = &myImage } }) {}`\n\n`.imageData` is a generic void pointer that can be used to pass through image data to the renderer.\n\n```C\n// Load an image somewhere in your code\nYourImage profilePicture = LoadYourImage(\"profilePicture.png\");\n// Note that when rendering, .imageData will be void* type.\nCLAY(CLAY_ID(\"Image\"), { .image = { .imageData = &profilePicture } }) {}\n```\n\nNote: for an image to maintain its original aspect ratio when using dynamic scaling, the [.aspectRatio](#clay_aspectratioelementconfig) config option must be used.\n\n**Examples**\n\n```C\n// Load an image somewhere in your code\nYourImage profilePicture = LoadYourImage(\"profilePicture.png\");\n// Declare a reusable image config\nClay_ImageElementConfig imageConfig = (Clay_ImageElementConfig) { .imageData = &profilePicture };\n// Declare an image element using a reusable config\nCLAY(CLAY_ID(\"Image\"), { .image = imageConfig }) {}\n// Declare an image element using an inline config\nCLAY(CLAY_ID(\"ImageInline\"), { .image = { .imageData = &profilePicture }, .aspectRatio = 16.0 / 9.0 }) {}\n// Rendering example\nYourImage *imageToRender = renderCommand->elementConfig.imageElementConfig->imageData;\n```\n\n**Rendering**\n\nElement is subject to [culling](#visibility-culling). Otherwise, a single `Clay_RenderCommand`s with `commandType = CLAY_RENDER_COMMAND_TYPE_IMAGE` will be created. The user will need to access `renderCommand->renderData.image->imageData` to retrieve image data referenced during layout creation. It's also up to the user to decide how / if they wish to blend `renderCommand->renderData.image->backgroundColor` with the image.\n\n---\n\n### Clay_ClipElementConfig\n\n**Usage**\n\n`CLAY(CLAY_ID(\"ScrollBox\"), { .clip = { ...clip config } }) {}`\n\n**Notes**\n\n`Clay_ClipElementConfig` configures the element as a clipping container, enabling masking of children that extend beyond its boundaries.\n\nNote: In order to process scrolling based on pointer position and mouse wheel or touch interactions, you must call `Clay_SetPointerState()` and `Clay_UpdateScrollContainers()` _before_ calling `BeginLayout`.\n\n**Struct Definition (Pseudocode)**\n\n```C\nClay_ClipElementConfig {\n    bool horizontal;\n    bool vertical;\n};\n```\n\n**Fields**\n\n**`.horizontal`** - `bool`\n\n`CLAY(CLAY_ID(\"HorizontalScroll\"), { .clip = { .horizontal = true } })`\n\nEnables or disables horizontal clipping for this container element.\n\n---\n\n**`.vertical`** - `bool`\n\n`CLAY(LAY_ID(\"VerticalScroll\"), { .clip = { .vertical = true } })`\n\nEnables or disables vertical clipping for this container element.\n\n---\n\n**Rendering**\n\nEnabling clip for an element will result in two additional render commands: \n- `commandType = CLAY_RENDER_COMMAND_TYPE_SCISSOR_START`, which should create a rectangle mask with its `boundingBox` and is **not** subject to [culling](#visibility-culling)\n- `commandType = CLAY_RENDER_COMMAND_TYPE_SCISSOR_END`, which disables the previous rectangle mask and is **not** subject to [culling](#visibility-culling)\n\n**Examples**\n\n```C\nCLAY(CLAY_ID(\"ScrollOuter\"), { .clip = { .vertical = true } }) {\n    // Create child content with a fixed height of 5000\n    CLAY(CLAY_ID(\"ScrollInner\"), { .layout = { .sizing = { .height = CLAY_SIZING_FIXED(5000) } } }) {}\n}\n```\n\n---\n\n### Clay_BorderElementConfig\n\n**Usage**\n\n`CLAY(CLAY_ID(\"Border\"), { .border = { ...border config } }) {}`\n\n**Notes**\n\n`Clay_BorderElementConfig` adds borders to the edges or between the children of elements. It uses Clay_BorderElementConfig to configure border specific options.\n\n**Struct Definition (Pseudocode)**\n\n```C\ntypedef struct Clay_BorderElementConfig\n{\n    Clay_Color color {\n        float r; float g; float b; float a;\n    };\n    Clay_BorderWidth width {\n        uint16_t left;\n        uint16_t right;\n        uint16_t top;\n        uint16_t bottom;\n        uint16_t betweenChildren;  \n    };\n} Clay_BorderElementConfig;\n```\n\n**Fields**\n\n**`.color`** - `Clay_Color`\n\n`CLAY(CLAY_ID(\"Border\"), { .border = { .color = { 255, 0, 0, 255 } } })`\n\nUses [Clay_Color](#clay_color). Specifies the shared color for all borders configured by this element. Conventionally accepts `rgba` float values between 0 and 255, but interpretation is left up to the renderer and does not affect layout.\n\n---\n\n**`.width`** - `Clay_BorderWidth`\n\n`CLAY(CLAY_ID(\"Border\"), { .border = { .width = { .left = 2, .right = 10 } } })`\n\nIndicates to the renderer that a border of `.color` should be draw at the specified edges of the bounding box, **inset and overlapping the box contents by `.width`**.\n\nThis means that border configuration does not affect layout, as the width of the border doesn't contribute to the total container width or layout position. Border containers with zero padding will be drawn over the top of child elements.\n\nNote:\n\n**`.width.betweenChildren`**\n\n`CLAY(CLAY_ID(\"Border\"), { .border = { .width = { .betweenChildren = 2 } }, .color = COLOR_RED })`\n\nConfigures the width and color of borders to be drawn between children. These borders will be vertical lines if the parent uses `.layoutDirection = CLAY_LEFT_TO_RIGHT` and horizontal lines if the parent uses `CLAY_TOP_TO_BOTTOM`. Unlike `.left, .top` etc, this option **will generate additional rectangle render commands representing the borders between children.** As a result, the renderer does not need to specifically implement rendering for these border elements.\n\n---\n\n**Examples**\n\n```C\n// 300x300 container with a 1px red border around all the edges\nCLAY(CLAY_ID(\"OuterBorder\"), {\n    .layout = { .sizing = { .width = CLAY_SIZING_FIXED(300), .height = CLAY_SIZING_FIXED(300) } },\n    .border = { .width = { 1, 1, 1, 1, 0 }, .color = COLOR_RED }\n}) {\n    // ...\n}\n\n// Container with a 3px yellow bottom border\nCLAY(CLAY_ID(\"OuterBorder\"), {\n    .border = { .width = { .bottom = 3 }, .color = COLOR_YELLOW }\n}) {\n    // ...\n}\n\n// Container with a 5px curved border around the edges, and a 5px blue border between all children laid out top to bottom\nCLAY(CLAY_ID(\"OuterBorder\"), {\n    .layout = { .layoutDirection = CLAY_TOP_TO_BOTTOM },\n    .border = { .width = { 5, 5, 5, 5, 5 }, .color = COLOR_BLUE }\n}) {\n    // Child\n    // -- 5px blue border will be here --\n    // Child\n    // -- 5px blue border will be here --\n    // Child\n}\n```\n\n**Rendering**\n\nElement is subject to [culling](#visibility-culling). Otherwise, a single `Clay_RenderCommand` with `commandType = CLAY_RENDER_COMMAND_TYPE_BORDER` representing the container will be created.\nRendering of borders and rounded corners is left up to the user. See the provided [Raylib Renderer](https://github.com/nicbarker/clay/tree/main/renderers/raylib) for examples of how to draw borders using line and curve primitives.\n\n---\n\n### Clay_FloatingElementConfig\n\n**Usage**\n\n`CLAY(CLAY_ID(\"Floating\"), { .floating = { ...floating config } }) {}`\n\n**Notes**\n\n**Floating Elements** defines an element that \"floats\" above other content. Typical use-cases include tooltips and modals.\n\nFloating containers:\n\n- With the default configuration, attach to the top left corner of their \"parent\" \n- Don't affect the width and height of their parent\n- Don't affect the positioning of sibling elements\n- Depending on their z-index can appear above or below other elements, partially or completely occluding them\n- Apart from positioning, function just like standard elements - including expanding to fit their children, etc.\n\nThe easiest mental model to use when thinking about floating containers is that they are a completely separate UI hierarchy, attached to a specific x,y point on their \"parent\".\n\nFloating elements uses `Clay_FloatingElementConfig` to configure specific options.\n\n**Struct Definition (Pseudocode)**\n\n```C\nClay_FloatingElementConfig {\n    Clay_Vector2 offset {\n        float x, float y\n    };\n    Clay_Dimensions expand {\n        float width, float height\n    };\n    uint32_t parentId;\n    int16_t zIndex;\n    Clay_FloatingAttachPoints attachPoint {\n        .element = CLAY_ATTACH_POINT_LEFT_TOP (default) | CLAY_ATTACH_POINT_LEFT_CENTER | CLAY_ATTACH_POINT_LEFT_BOTTOM | CLAY_ATTACH_POINT_CENTER_TOP | CLAY_ATTACH_POINT_CENTER_CENTER | CLAY_ATTACH_POINT_CENTER_BOTTOM | CLAY_ATTACH_POINT_RIGHT_TOP | CLAY_ATTACH_POINT_RIGHT_CENTER | CLAY_ATTACH_POINT_RIGHT_BOTTOM\n        .parent = CLAY_ATTACH_POINT_LEFT_TOP (default) | CLAY_ATTACH_POINT_LEFT_CENTER | CLAY_ATTACH_POINT_LEFT_BOTTOM | CLAY_ATTACH_POINT_CENTER_TOP | CLAY_ATTACH_POINT_CENTER_CENTER | CLAY_ATTACH_POINT_CENTER_BOTTOM | CLAY_ATTACH_POINT_RIGHT_TOP | CLAY_ATTACH_POINT_RIGHT_CENTER | CLAY_ATTACH_POINT_RIGHT_BOTTOM\n    };\n    Clay_FloatingAttachToElement attachTo {\n        CLAY_POINTER_CAPTURE_MODE_CAPTURE (default),\n        CLAY_POINTER_CAPTURE_MODE_PASSTHROUGH\n    };\n    Clay_FloatingAttachToElement attachTo {\n        CLAY_ATTACH_TO_NONE (default),\n        CLAY_ATTACH_TO_PARENT,\n        CLAY_ATTACH_TO_ELEMENT_WITH_ID,\n        CLAY_ATTACH_TO_ROOT,\n    };\n};\n```\n\n**Fields**\n\n**`.offset`** - `Clay_Vector2`\n\n`CLAY(CLAY_ID(\"Floating\"), { .floating = { .offset = { -24, -24 } } })`\n\nUsed to apply a position offset to the floating container _after_ all other layout has been calculated. \n\n---\n\n**`.expand`** - `Clay_Dimensions`\n\n`CLAY(CLAY_ID(\"Floating\"), { .floating = { .expand = { 16, 16 } } })`\n\nUsed to expand the width and height of the floating container _before_ laying out child elements.\n\n---\n\n**`.zIndex`** - `float`\n\n`CLAY(CLAY_ID(\"Floating\"), { .floating = { .zIndex = 1 } })`\n\nAll floating elements (as well as their entire child hierarchies) will be sorted by `.zIndex` order before being converted to render commands. If render commands are drawn in order, elements with higher `.zIndex` values will be drawn on top.\n\n---\n\n**`.parentId`** - `uint32_t`\n\n`CLAY(CLAY_ID(\"Floating\"), { .floating = { .parentId = Clay_GetElementId(\"HeaderButton\").id } })`\n\nBy default, floating containers will \"attach\" to the parent element that they are declared inside. However, there are cases where this limitation could cause significant performance or ergonomics problems. `.parentId` allows you to specify a `CLAY_ID().id` to attach the floating container to. The parent element with the matching id can be declared anywhere in the hierarchy, it doesn't need to be declared before or after the floating container in particular.  \n\nConsider the following case:\n```C\n// Load an image somewhere in your code\nCLAY(CLAY_IDI(\"SidebarButton\", 1), { }) {\n    // .. some button contents\n    if (tooltip.attachedButtonIndex == 1) {\n        CLAY(CLAY_ID(\"OptionTooltip\"), { /* floating config... */ })\n    }\n}\nCLAY(CLAY_IDI(\"SidebarButton\", 2), { }) {\n    // .. some button contents\n    if (tooltip.attachedButtonIndex == 2) {\n        CLAY(CLAY_ID(\"OptionTooltip\"), { /* floating config... */ })\n    }\n}\nCLAY(CLAY_IDI(\"SidebarButton\", 3), { }) {\n    // .. some button contents\n    if (tooltip.attachedButtonIndex == 3) {\n        CLAY(CLAY_ID(\"OptionTooltip\"), { /* floating config... */ })\n    }\n}\nCLAY(CLAY_IDI(\"SidebarButton\", 4), { }) {\n    // .. some button contents\n    if (tooltip.attachedButtonIndex == 4) {\n        CLAY(CLAY_ID(\"OptionTooltip\"), { /* floating config... */ })\n    }\n}\nCLAY(CLAY_IDI(\"SidebarButton\", 5), { }) {\n    // .. some button contents\n    if (tooltip.attachedButtonIndex == 5) {\n        CLAY(CLAY_ID(\"OptionTooltip\"), { /* floating config... */ })\n    }\n}\n```\n\nThe definition of the above UI is significantly polluted by the need to conditionally render floating tooltips as a child of many possible elements. The alternative, using `parentId`, looks like this:\n\n```C\n// Load an image somewhere in your code\nCLAY(CLAY_IDI(\"SidebarButton\", 1), { }) {\n    // .. some button contents\n}\nCLAY(CLAY_IDI(\"SidebarButton\", 2), { }) {\n    // .. some button contents\n}\nCLAY(CLAY_IDI(\"SidebarButton\", 3), { }) {\n    // .. some button contents\n}\nCLAY(CLAY_IDI(\"SidebarButton\", 4), { }) {\n    // .. some button contents\n}\nCLAY(CLAY_IDI(\"SidebarButton\", 5), { }) {\n    // .. some button contents\n}\n\n// Any other point in the hierarchy\nCLAY(CLAY_ID(\"OptionTooltip\"), { .floating = { .attachTo = CLAY_ATTACH_TO_ELEMENT_ID, .parentId = CLAY_IDI(\"SidebarButton\", tooltip.attachedButtonIndex).id }) {\n    // Tooltip contents...\n}\n```\n\n---\n\n**`.attachment`** - `Clay_FloatingAttachPoints`\n\n`CLAY(CLAY_ID(\"Floating\"), { .floating = { .attachment = { .element = CLAY_ATTACH_POINT_LEFT_CENTER, .parent = CLAY_ATTACH_POINT_RIGHT_TOP } } }) {}`\n\nIn terms of positioning the floating container, `.attachment` specifies \n\n- The point on the floating container (`.element`)\n- The point on the parent element that it \"attaches\" to (`.parent`)\n\n![Screenshot 2024-08-23 at 11 47 21 AM](https://github.com/user-attachments/assets/b8c6dfaa-c1b1-41a4-be55-013473e4a6ce)\n\nYou can mentally visualise this as finding a point on the floating container, then finding a point on the parent, and lining them up over the top of one another.\n\nFor example:\n\n\"Attach the LEFT_CENTER of the floating container to the RIGHT_TOP of the parent\"\n\n`CLAY(CLAY_ID(\"Floating\"), { .floating = { .attachment = { .element = CLAY_ATTACH_POINT_LEFT_CENTER, .parent = CLAY_ATTACH_POINT_RIGHT_TOP } } });`\n\n![Screenshot 2024-08-23 at 11 53 24 AM](https://github.com/user-attachments/assets/ebe75e0d-1904-46b0-982d-418f929d1516)\n\n**`.pointerCaptureMode`** - `Clay_PointerCaptureMode`\n\n`CLAY({ .floating = { .pointerCaptureMode = CLAY_POINTER_CAPTURE_MODE_CAPTURE } })`\n\nControls whether pointer events like hover and click should pass through to content underneath this floating element, or whether the pointer should be \"captured\" by this floating element. Defaults to `CLAY_POINTER_CAPTURE_MODE_CAPTURE`. \n\n**Examples**\n\n```C\n// Horizontal container with three option buttons\nCLAY(CLAY_ID(\"OptionsList\"), { .layout = { childGap = 16 } }) {\n    CLAY(CLAY_IDI(\"Option\", 1), { .layout = { padding = CLAY_PADDING_ALL(16)), .backgroundColor = COLOR_BLUE } }) {\n        CLAY_TEXT(CLAY_STRING(\"Option 1\"), CLAY_TEXT_CONFIG());\n    }\n    CLAY(CLAY_IDI(\"Option\", 2), { .layout = { padding = CLAY_PADDING_ALL(16)), .backgroundColor = COLOR_BLUE } }) {\n        CLAY_TEXT(CLAY_STRING(\"Option 2\"), CLAY_TEXT_CONFIG());\n        // Floating tooltip will attach above the \"Option 2\" container and not affect widths or positions of other elements\n        CLAY(CLAY_ID(\"OptionTooltip\"), { .floating = { .zIndex = 1, .attachment = { .element = CLAY_ATTACH_POINT_CENTER_BOTTOM, .parent = CLAY_ATTACH_POINT_CENTER_TOP } } }) {\n            CLAY_TEXT(CLAY_STRING(\"Most popular!\"), CLAY_TEXT_CONFIG());\n        }\n    }\n    CLAY(CLAY_IDI(\"Option\", 3), { .layout = { padding = CLAY_PADDING_ALL(16)), .backgroundColor = COLOR_BLUE } }) {\n        CLAY_TEXT(CLAY_STRING(\"Option 3\"), CLAY_TEXT_CONFIG());\n    }\n}\n\n// Floating containers can also be declared elsewhere in a layout, to avoid branching or polluting other UI\nfor (int i = 0; i < 1000; i++) {\n    CLAY(CLAY_IDI(\"Option\", i + 1), { }) {\n        // ...\n    }\n}\n// Note the use of \"parentId\".\n// Floating tooltip will attach above the \"Option 2\" container and not affect widths or positions of other elements\nCLAY(CLAY_ID(\"OptionTooltip\"), { .floating = { .parentId = CLAY_IDI(\"Option\", 2).id, .zIndex = 1, .attachment = { .element = CLAY_ATTACH_POINT_CENTER_BOTTOM, .parent = CLAY_ATTACH_POINT_TOP_CENTER } } }) {\n    CLAY_TEXT(CLAY_STRING(\"Most popular!\"), CLAY_TEXT_CONFIG());\n}\n```\n\nWhen using `.parentId`, the floating container can be declared anywhere after `BeginLayout` and before `EndLayout`. The target element matching the `.parentId` doesn't need to exist when `Clay_FloatingElementConfig` is used.\n\n**Rendering**\n\n`Clay_FloatingElementConfig` will not generate any specific render commands.\n\n---\n\n### Clay_CustomElementConfig\n\n**Usage**\n\n`CLAY(CLAY_ID(\"Custom\"), { .custom = { .customData = &something } }) {}`\n\n**Notes**\n\n**Clay_CustomElementConfig** allows the user to pass custom data to the renderer. \n\n**Struct Definition (Pseudocode)** \n\n```C\ntypedef struct\n{\n    void * customData;\n} Clay_CustomElementConfig;\n```\n\n**Fields**\n\n`.customData` - `void *`\n\n`CLAY({ .custom = { .customData = &myCustomData } })`\n\n`.customData` is a generic void pointer that can be used to pass through custom data to the renderer.\n\n**Examples**\n```C\n#include \"clay.h\"\n\ntypedef enum {\n    CUSTOM_ELEMENT_TYPE_MODEL,\n    CUSTOM_ELEMENT_TYPE_VIDEO\n} CustomElementType;\n\n// A rough example of how you could handle laying out 3d models in your UI\ntypedef struct {\n    CustomElementType type;\n    union {\n        Model model;\n        Video video;\n        // ...\n    };\n} CustomElementData;\n\nModel myModel = Load3DModel(filePath);\nCustomElement modelElement = (CustomElement) { .type = CUSTOM_ELEMENT_TYPE_MODEL, .model = myModel }\n\ntypedef struct {\n    void* memory;\n    uintptr_t offset;\n} Arena;\n\n// During init\nArena frameArena = (Arena) { .memory = malloc(1024) };\n\n// ...\nCLAY(0) {\n    // Custom elements only take a single pointer, so we need to store the data somewhere\n    CustomElementData *modelData = (CustomElementData *)(frameArena.memory + frameArena.offset);\n    *modelData = (CustomElementData) { .type = CUSTOM_ELEMENT_TYPE_MODEL, .model = myModel };\n    frameArena.offset += sizeof(CustomElementData);\n    CLAY(CLAY_ID(\"3DModelViewer\"), { .custom = { .customData = modelData } }) {}\n}\n\n// Later during your rendering\nswitch (renderCommand->commandType) {\n    // ...\n    case CLAY_RENDER_COMMAND_TYPE_CUSTOM: {\n        // Your extended struct is passed through\n        CustomElementData *customElement = renderCommand->config.customElementConfig->customData;\n        if (!customElement) continue;\n        switch (customElement->type) {\n            case CUSTOM_ELEMENT_TYPE_MODEL: {\n                // Render your 3d model here\n                break;\n            }\n            case CUSTOM_ELEMENT_TYPE_VIDEO: {\n                // Render your video here\n                break;\n            }\n            // ...\n        }\n        break;\n    }\n}\n```\n\n**Rendering**\n\nElement is subject to [culling](#visibility-culling). Otherwise, a single `Clay_RenderCommand` with `commandType = CLAY_RENDER_COMMAND_TYPE_CUSTOM` will be created.\n\n### Clay_Color\n\n```C\ntypedef struct {\n    float r, g, b, a;\n} Clay_Color;\n```\n\n`Clay_Color` is an RGBA color struct used in Clay's declarations and rendering. By convention the channels are represented as 0-255, but this is left up to the renderer.\nNote: when using the debug tools, their internal colors are represented as 0-255.\n\n### Clay_String\n\n```C\ntypedef struct {\n    bool isStaticallyAllocated;\n    int32_t length;\n    const char *chars;\n} Clay_String;\n```\n\n`Clay_String` is a string container that clay uses internally to represent all strings.\n\n**Fields**\n\n**`.isStaticallyAllocated`** - `bool`\n\nWhether or not the string is statically allocated, or in other words, whether\nor not it lives for the entire lifetime of the program.\n\n---\n\n**`.length`** - `int32_t`\n\nThe number of characters in the string, _not including an optional null terminator._\n\n---\n\n**`.chars`** - `const char *`\n\nA pointer to the contents of the string. This data is not guaranteed to be null terminated, so if you are passing it to code that expects standard null terminated C strings, you will need to copy the data and append a null terminator.\n\n---\n\n### Clay_ElementId\n\n```C\ntypedef struct {\n    uint32_t id;\n    uint32_t offset;\n    uint32_t baseId;\n    Clay_String stringId;\n} Clay_ElementId;\n```\n\nReturned by [CLAY_ID](#clay_id) and [CLAY_IDI](#clay_idi), this struct contains a hash id, as well as the source string that was used to generate it.\n\n**Fields**\n\n**`.id`** - `uint32_t`\n\nA unique ID derived from the string passed to [CLAY_ID](#clay_id) or [CLAY_IDI](#clay_idi).\n\n---\n\n**`.offset`** - `uint32_t`\n\nIf this id was generated using [CLAY_IDI](#clay_idi), `.offset` is the value passed as the second argument. For [CLAY_ID](#clay_id), this will always be `0`.\n\n---\n\n**`.baseId`** - `uint32_t`\n\nIf this id was generated using [CLAY_IDI](#clay_idi), `.baseId` is the hash of the base string passed, **before it is additionally hashed with `.offset`**. For [CLAY_ID](#clay_id), this will always be the same as `.id`.\n\n---\n\n**`.stringId`** - `Clay_String`\n\nStores the original string that was passed in when [CLAY_ID](#clay_id) or [CLAY_IDI](#clay_idi) were called.\n\n---\n\n### Clay_RenderCommandArray\n\n```C\ntypedef struct\n{\n\tuint32_t capacity;\n\tuint32_t length;\n\tClay_RenderCommand *internalArray;\n} Clay_RenderCommandArray;\n```\n\nReturned by [Clay_EndLayout](#clay_endlayout), this array contains the [Clay_RenderCommand](#clay_rendercommand)s representing the calculated layout.\n\n**Fields**\n\n**`.capacity`** - `uint32_t`\n\nRepresents the total capacity of the allocated memory in `.internalArray`.\n\n---\n\n**`.length`** - `uint32_t`\n\nRepresents the total number of `Clay_RenderCommand` elements stored consecutively at the address `.internalArray`.\n\n---\n\n**`.internalArray`** - `Clay_RenderCommand`\n\nAn array of [Clay_RenderCommand](#clay_rendercommand)s representing the calculated layout. If there was at least one render command, this array will contain elements from `.internalArray[0]` to `.internalArray[.length - 1]`.\n\n---\n\n### Clay_RenderCommand\n\n```C\ntypedef struct {\n    Clay_BoundingBox boundingBox;\n    Clay_RenderData renderData;\n    uintptr_t userData;\n    uint32_t id;\n    int16_t zIndex;\n    Clay_RenderCommandType commandType;\n} Clay_RenderCommand;\n```\n\n**Fields**\n\n**`.commandType`** - `Clay_RenderCommandType`\n\nAn enum indicating how this render command should be handled. Possible values include:\n\n- `CLAY_RENDER_COMMAND_TYPE_NONE` - Should be ignored by the renderer, and never emitted by clay under normal conditions.\n- `CLAY_RENDER_COMMAND_TYPE_RECTANGLE` - A rectangle should be drawn, configured with `.config.rectangleElementConfig`\n- `CLAY_RENDER_COMMAND_TYPE_BORDER` - A border should be drawn, configured with `.config.borderElementConfig`\n- `CLAY_RENDER_COMMAND_TYPE_TEXT` - Text should be drawn, configured with `.config.textElementConfig`\n- `CLAY_RENDER_COMMAND_TYPE_IMAGE` - An image should be drawn, configured with `.config.imageElementConfig`\n- `CLAY_RENDER_COMMAND_TYPE_SCISSOR_START` - Named after [glScissor](https://registry.khronos.org/OpenGL-Refpages/gl4/html/glScissor.xhtml), this indicates that the renderer should begin culling any subsequent pixels that are drawn outside the `.boundingBox` of this render command.\n- `CLAY_RENDER_COMMAND_TYPE_SCISSOR_END` - Only ever appears after a matching `CLAY_RENDER_COMMAND_TYPE_SCISSOR_START` command, and indicates that the scissor has ended.\n- `CLAY_RENDER_COMMAND_TYPE_CUSTOM` - A custom render command controlled by the user, configured with `.config.customElementConfig`\n\n---\n\n**`.boundingBox`** - `Clay_BoundingBox`\n\n```C\ntypedef struct {\n    float x, y, width, height;\n} Clay_BoundingBox;\n```\n\nA rectangle representing the bounding box of this render command, with `.x` and `.y` representing the top left corner of the element.\n\n---\n\n**`.id`** - `uint32_t`\n\nThe id that was originally used with the element macro that created this render command. See [CLAY_ID](#clay_id) for details.\n\n---\n\n**`.zIndex`** - `int16_t`\n\nThe z index of the element, based on what was passed to the root floating configuration that this element is a child of.\nHigher z indexes should be rendered _on top_ of lower z indexes.\n\n---\n\n**`.renderData`** - `Clay_RenderData`\n\n```C\ntypedef union {\n    Clay_RectangleRenderData rectangle;\n    Clay_TextRenderData text;\n    Clay_ImageRenderData image;\n    Clay_CustomRenderData custom;\n    Clay_BorderRenderData border;\n} Clay_RenderData;\n```\n\nA C union containing various structs, with the type dependent on `.commandType`. Possible values include:\n\n- `config.rectangle` - Used when `.commandType == CLAY_RENDER_COMMAND_TYPE_RECTANGLE`.\n- `config.text` - Used when `.commandType == CLAY_RENDER_COMMAND_TYPE_TEXT`. See [Clay_Text](#clay_text) for details.\n- `config.image` - Used when `.commandType == CLAY_RENDER_COMMAND_TYPE_IMAGE`. See [Clay_Image](#clay_imageelementconfig) for details.\n- `config.border` - Used when `.commandType == CLAY_RENDER_COMMAND_TYPE_BORDER`. See [Clay_Border](#clay_borderelementconfig) for details.\n- `config.custom` - Used when `.commandType == CLAY_RENDER_COMMAND_TYPE_CUSTOM`. See [Clay_Custom](#clay_customelementconfig) for details.\n\n**Union Structs**\n\n```C\ntypedef struct {\n    Clay_StringSlice stringContents;\n    Clay_Color textColor;\n    uint16_t fontId;\n    uint16_t fontSize;\n    uint16_t letterSpacing;\n    uint16_t lineHeight;\n} Clay_TextRenderData;\n```\n\n```C\ntypedef struct {\n    Clay_Color backgroundColor;\n    Clay_CornerRadius cornerRadius;\n} Clay_RectangleRenderData;\n```\n\n```C\ntypedef struct {\n    Clay_Color backgroundColor;\n    Clay_CornerRadius cornerRadius;\n    void* imageData;\n} Clay_ImageRenderData;\n```\n\n```C\ntypedef struct {\n    Clay_Color backgroundColor;\n    Clay_CornerRadius cornerRadius;\n    void* customData;\n} Clay_CustomRenderData;\n```\n\n```C\ntypedef struct {\n    Clay_Color color;\n    Clay_CornerRadius cornerRadius;\n    Clay_BorderWidth width;\n} Clay_BorderRenderData;\n```\n\n```C\ntypedef union {\n    Clay_RectangleRenderData rectangle;\n    Clay_TextRenderData text;\n    Clay_ImageRenderData image;\n    Clay_CustomRenderData custom;\n    Clay_BorderRenderData border;\n} Clay_RenderData;\n```\n\n### Clay_ScrollContainerData\n\n```C\n// Data representing the current internal state of a scrolling element.\ntypedef struct {\n    // Note: This is a pointer to the real internal scroll position, mutating it may cause a change in final layout.\n    // Intended for use with external functionality that modifies scroll position, such as scroll bars or auto scrolling.\n    Clay_Vector2 *scrollPosition;\n    // The bounding box of the scroll element.\n    Clay_Dimensions scrollContainerDimensions;\n    // The outer dimensions of the inner scroll container content, including the padding of the parent scroll container.\n    Clay_Dimensions contentDimensions;\n    // The config that was originally passed to the scroll element.\n    Clay_ClipElementConfig config;\n    // Indicates whether an actual scroll container matched the provided ID or if the default struct was returned.\n    bool found;\n} Clay_ScrollContainerData;\n```\n\n**Fields**\n\n**`.scrollPosition`** - `Clay_Vector2 *`\n\nA pointer to the internal scroll position of this scroll container. Mutating it will result in elements inside the scroll container shifting up / down (`.y`) or left / right (`.x`).\n\n---\n\n**`.scrollContainerDimensions`** - `Clay_Dimensions`\n\n```C\ntypedef struct {\n    float width, height;\n} Clay_Dimensions;\n```\n\nDimensions representing the outer width and height of the scroll container itself.\n\n---\n\n**`.contentDimensions`** - `Clay_Dimensions`\n\n```C\ntypedef struct {\n    float width, height;\n} Clay_Dimensions;\n```\n\nDimensions representing the inner width and height of the content _inside_ the scroll container. Scrolling is only possible when the `contentDimensions` are larger in at least one dimension than the `scrollContainerDimensions`.\n\n---\n\n**`.config`** - `Clay_ClipElementConfig`\n\nThe [Clay_ClipElementConfig](#clay_scroll) for the matching scroll container element.\n\n---\n\n### Clay_ElementData\n\n```C\n// Bounding box and other data for a specific UI element.\ntypedef struct {\n    // The rectangle that encloses this UI element, with the position relative to the root of the layout.\n    Clay_BoundingBox boundingBox;\n    // Indicates whether an actual Element matched the provided ID or if the default struct was returned.\n    bool found;\n} Clay_ElementData;\n```\n\n**Fields**\n\n**`.boundingBox`** - `Clay_BoundingBox`\n\n```C\ntypedef struct {\n    float x, y, width, height;\n} Clay_BoundingBox;\n```\n\nA rectangle representing the bounding box of this render command, with `.x` and `.y` representing the top left corner of the element.\n\n---\n\n**`.found`** - `bool`\n\nA boolean representing whether or not the ID passed to [Clay_GetElementData](#clay_getelementdata) matched a valid element or not. In the case that `.found` is `false`, `.boundingBox` will be the default value (zeroed).\n\n---\n\n### Clay_PointerData\n\n```C\ntypedef struct\n{\n    Clay_Vector2 position;\n    Clay_PointerDataInteractionState state;\n} Clay_PointerData;\n```\n\n**Fields**\n\n**`.position`** - `Clay_Vector2`\n\nA Vector2 containing the current x,y coordinates of the mouse pointer, which were originally passed into [Clay_SetPointerState()](#clay_setpointerstate).\n\n---\n\n**`.state`** - `Clay_PointerDataInteractionState`\n\n```C\ntypedef enum\n{\n    CLAY_POINTER_DATA_PRESSED_THIS_FRAME,\n    CLAY_POINTER_DATA_PRESSED,\n    CLAY_POINTER_DATA_RELEASED_THIS_FRAME,\n    CLAY_POINTER_DATA_RELEASED,\n} Clay_PointerDataInteractionState;\n```\n\nAn enum value representing the current \"state\" of the pointer interaction. As an example, consider the case where a user is on a desktop computer, moves the mouse pointer over a button, clicks and holds the left mouse button for a short time, then releases it:\n\n- While the mouse pointer is over (\"hovering\") the button, but no mouse button has been pressed: `CLAY_POINTER_DATA_RELEASED`\n- First frame that the user presses the left mouse button: `CLAY_POINTER_DATA_PRESSED_THIS_FRAME`\n- All subsequent frames where the user is still holding the left mouse button: `CLAY_POINTER_DATA_PRESSED`\n- The single frame where the left mouse button goes from pressed -> released: `CLAY_POINTER_DATA_RELEASED_THIS_FRAME`\n- All subsequent frames while the mouse pointer is still over the button: `CLAY_POINTER_DATA_RELEASED`\n\n---\n\n### Clay_ErrorHandler\n\n```C\ntypedef struct\n{\n    void (*errorHandlerFunction)(Clay_ErrorData errorText);\n    uintptr_t userData;\n} Clay_ErrorHandler;\n```\n\n**Fields**\n\n**`.errorHandlerFunction`** - `void (Clay_ErrorData errorText) {}`\n\nA function pointer to an error handler function, which takes `Clay_ErrorData` as an argument. This function will be called whenever Clay encounters an internal error.\n\n---\n\n**`.userData`** - `uintptr_t`\n\nA generic pointer to extra userdata that is transparently passed through from `Clay_Initialize` to Clay's error handler callback. Defaults to NULL.\n\n---\n\n### Clay_ErrorData\n\n```C\ntypedef struct\n{\n    Clay_ErrorType errorType;\n    Clay_String errorText;\n    uintptr_t userData;\n} Clay_ErrorData;\n```\n\n**Fields**\n\n**`.errorType`** - `Clay_ErrorType`\n\n```C\ntypedef enum {\n    CLAY_ERROR_TYPE_TEXT_MEASUREMENT_FUNCTION_NOT_PROVIDED,\n    CLAY_ERROR_TYPE_ARENA_CAPACITY_EXCEEDED,\n    CLAY_ERROR_TYPE_ELEMENTS_CAPACITY_EXCEEDED,\n    CLAY_ERROR_TYPE_TEXT_MEASUREMENT_CAPACITY_EXCEEDED,\n    CLAY_ERROR_TYPE_DUPLICATE_ID,\n    CLAY_ERROR_TYPE_FLOATING_CONTAINER_PARENT_NOT_FOUND,\n    CLAY_ERROR_TYPE_INTERNAL_ERROR,\n} Clay_ErrorType;\n```\n\nAn enum representing the type of error Clay encountered. It's up to the user to handle on a case by case basis, but as some general guidance:\n\n- `CLAY_ERROR_TYPE_TEXT_MEASUREMENT_FUNCTION_NOT_PROVIDED` - The user is attempting to use `CLAY_TEXT` and either forgot to call [Clay_SetMeasureTextFunction](#clay_setmeasuretextfunction) or accidentally passed a null function pointer.\n- `CLAY_ERROR_TYPE_ARENA_CAPACITY_EXCEEDED` - Clay was initialized with an Arena that was too small for the configured [Clay_SetMaxElementCount](#clay_setmaxelementcount). Try using [Clay_MinMemorySize()](#clay_minmemorysize) to get the exact number of bytes required by the current configuration.\n- `CLAY_ERROR_TYPE_ELEMENTS_CAPACITY_EXCEEDED` - The declared UI hierarchy has too many elements for the configured max element count. Use [Clay_SetMaxElementCount](#clay_setmaxelementcount) to increase the max, then call [Clay_MinMemorySize()](#clay_minmemorysize) again and reinitialize clay's memory with the required size.\n- `CLAY_ERROR_TYPE_ELEMENTS_CAPACITY_EXCEEDED` - The declared UI hierarchy has too much text for the configured text measure cache size. Use [Clay_SetMaxMeasureTextCacheWordCount](#clay_setmeasuretextcachesize) to increase the max, then call [Clay_MinMemorySize()](#clay_minmemorysize) again and reinitialize clay's memory with the required size.\n- `CLAY_ERROR_TYPE_DUPLICATE_ID` - Two elements in Clays UI Hierarchy have been declared with exactly the same ID. Set a breakpoint in your error handler function for a stack trace back to exactly where this occured.\n- `CLAY_ERROR_TYPE_FLOATING_CONTAINER_PARENT_NOT_FOUND` - A `CLAY_FLOATING` element was declared with the `.parentId` property, but no element with that ID was found. Set a breakpoint in your error handler function for a stack trace back to exactly where this occured.\n- `CLAY_ERROR_TYPE_INTERNAL_ERROR` - Clay has encountered an internal logic or memory error. Please report this as a bug with a stack trace to help us fix these!\n\n---\n\n**`.errorText`** - `Clay_String`\n\nA [Clay_String](#clay_string) that provides a human readable description of the error. May change in future and should not be relied on to detect error types.\n\n---\n\n**`.userData`** - `uintptr_t`\n\nA generic pointer to extra userdata that is transparently passed through from `Clay_Initialize` to Clay's error handler callback. Defaults to NULL.\n\n---\n",
      "stars_today": 15
    },
    {
      "id": 1062297179,
      "name": "agentscope-java",
      "full_name": "agentscope-ai/agentscope-java",
      "description": "AgentScope Java: Agent-Oriented Programming for Building LLM Applications",
      "html_url": "https://github.com/agentscope-ai/agentscope-java",
      "stars": 1272,
      "forks": 274,
      "language": "Java",
      "topics": [
        "agent",
        "agentic",
        "agentic-ai",
        "ai",
        "llm"
      ],
      "created_at": "2025-09-23T04:37:43Z",
      "updated_at": "2026-02-06T14:00:51Z",
      "pushed_at": "2026-02-06T07:27:46Z",
      "open_issues": 160,
      "owner": {
        "login": "agentscope-ai",
        "avatar_url": "https://avatars.githubusercontent.com/u/211762292?v=4"
      },
      "readme": "<p align=\"center\">\n  <img\n    src=\"https://img.alicdn.com/imgextra/i1/O1CN01nTg6w21NqT5qFKH1u_!!6000000001621-55-tps-550-550.svg\"\n    alt=\"AgentScope Logo\"\n    width=\"200\"\n  />\n</p>\n\n<h3 align=\"center\">Build Production-Ready AI Agents in Java</h3>\n\n<p align=\"center\">\n  <a href=\"https://java.agentscope.io/\">ğŸ“– Documentation</a>\n  &nbsp;|&nbsp;\n  <a href=\"README_zh.md\">ä¸­æ–‡</a>\n  &nbsp;|&nbsp;\n  <a href=\"https://discord.gg/eYMpfnkG8h\">Discord</a>\n</p>\n\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/license-Apache--2.0-blue\" alt=\"License\" />\n  <img src=\"https://img.shields.io/badge/JDK-17%2B-orange\" alt=\"JDK 17+\" />\n  <img src=\"https://img.shields.io/maven-central/v/io.agentscope/agentscope?color=green\" alt=\"Maven Central\" />\n  <a href=\"https://deepwiki.com/agentscope-ai/agentscope-java\"><img src=\"https://deepwiki.com/badge.svg\" alt=\"Ask DeepWiki\"></a>\n</p>\n\n---\n\nAgentScope Java is an agent-oriented programming framework for building LLM-powered applications. It provides everything you need to create intelligent agents: ReAct reasoning, tool calling, memory management, multi-agent collaboration, and more.\n\n## Highlights\n\n### ğŸ¯ Smart Agents, Full Control\n\nAgentScope adopts the ReAct (Reasoning-Acting) paradigm, enabling agents to autonomously plan and execute complex tasks. Unlike rigid workflow-based approaches, ReAct agents dynamically decide which tools to use and when, adapting to changing requirements in real-time.\n\nHowever, autonomy without control is a liability in production. AgentScope provides comprehensive runtime intervention mechanisms:\n\n- **Safe Interruption** - Pause agent execution at any point while preserving full context and tool state, enabling seamless resumption without data loss\n- **Graceful Cancellation** - Terminate long-running or unresponsive tool calls without corrupting agent state, allowing immediate recovery and redirection\n- **Human-in-the-Loop** - Inject corrections, additional context, or guidance at any reasoning step through the Hook system, maintaining human oversight over critical decisions\n\n### ğŸ› ï¸ Built-in Tools\n\nAgentScope includes production-ready tools that address common challenges in agent development:\n\n- **PlanNotebook** - A structured task management system that decomposes complex objectives into ordered, trackable steps. Agents can create, modify, pause, and resume multiple concurrent plans, ensuring systematic execution of multi-step workflows.\n\n- **Structured Output** - A self-correcting output parser that guarantees type-safe responses. When LLM output deviates from the expected format, the system automatically detects errors and guides the model to produce valid output, mapping results directly to Java POJOs without manual parsing.\n\n- **Long-term Memory** - Persistent memory storage with semantic search capabilities across sessions. Supports automatic management, agent-controlled recording, or hybrid modes. Enables multi-tenant isolation for enterprise deployments where agents serve multiple users independently.\n\n- **RAG (Retrieval-Augmented Generation)** - Seamless integration with enterprise knowledge bases. Supports both self-hosted embedding-based retrieval and managed services like Alibaba Cloud Bailian, grounding agent responses in authoritative data sources.\n\n### ğŸ”Œ Seamless Integration\n\nAgentScope is designed to integrate with existing enterprise infrastructure without requiring extensive modifications:\n\n- **MCP Protocol** - Integrate with any MCP-compatible server to instantly extend agent capabilities. Connect to the growing ecosystem of MCP tools and servicesâ€”from file systems and databases to web browsers and code interpretersâ€”without writing custom integration code.\n\n- **A2A Protocol** - Enable distributed multi-agent collaboration through standard service discovery. Register agent capabilities to Nacos or similar registries, allowing agents to discover and invoke each other as naturally as calling microservices.\n\n### ğŸš€ Production Grade\n\nBuilt for enterprise deployment requirements:\n\n- **High Performance** - Reactive architecture based on Project Reactor ensures non-blocking execution. GraalVM native image compilation achieves 200ms cold start times, making AgentScope suitable for serverless and auto-scaling environments.\n\n- **Security Sandbox** - AgentScope Runtime provides isolated execution environments for untrusted tool code. Includes pre-built sandboxes for GUI automation, file system operations, and mobile device interaction, preventing unauthorized access to system resources.\n\n- **Observability** - Native integration with OpenTelemetry for distributed tracing across the entire agent execution pipeline. AgentScope Studio provides visual debugging, real-time monitoring, and comprehensive logging for development and production environments.\n\n## Quick Start\n\n**Requirements:** JDK 17+\n\n```xml\n<dependency>\n    <groupId>io.agentscope</groupId>\n    <artifactId>agentscope</artifactId>\n    <version>1.0.8</version>\n</dependency>\n```\n\n```java\nReActAgent agent = ReActAgent.builder()\n    .name(\"Assistant\")\n    .sysPrompt(\"You are a helpful AI assistant.\")\n    .model(DashScopeChatModel.builder()\n        .apiKey(System.getenv(\"DASHSCOPE_API_KEY\"))\n        .modelName(\"qwen-max\")\n        .build())\n    .build();\n\nMsg response = agent.call(Msg.builder()\n        .textContent(\"Hello!\")\n        .build()).block();\nSystem.out.println(response.getTextContent());\n```\n\nFor more examples, see the [documentation](https://java.agentscope.io/).\n\n## Contributing\n\nWe welcome contributions! Please see [CONTRIBUTING.md](./CONTRIBUTING.md) for guidelines.\n\n## Community\n\n| [Discord](https://discord.gg/eYMpfnkG8h)                     | DingTalk | WeChat |\n|--------------------------------------------------------------|----------| ---------|\n| <img src=\"./docs/imgs/discord.png\" width=\"100\" height=\"100\"> | <img src=\"./docs/imgs/dingtalk_qr_code.jpg\" width=\"100\" height=\"100\"> | <img src=\"./docs/imgs/wechat.png\" width=\"100\" height=\"100\"> |\n\n## License\n\nApache License 2.0 - see [LICENSE](./LICENSE) for details.\n\n## Publications\n\nIf you find AgentScope helpful, please cite our papers:\n\n- [AgentScope 1.0: A Developer-Centric Framework for Building Agentic Applications](https://arxiv.org/abs/2508.16279)\n- [AgentScope: A Flexible yet Robust Multi-Agent Platform](https://arxiv.org/abs/2402.14034)\n\n## Contributors\n\n<a href=\"https://github.com/agentscope-ai/agentscope-java/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=agentscope-ai/agentscope-java&max=999&columns=12&anon=1\" />\n</a>\n",
      "stars_today": 15
    },
    {
      "id": 2211243,
      "name": "kafka",
      "full_name": "apache/kafka",
      "description": "Mirror of Apache Kafka",
      "html_url": "https://github.com/apache/kafka",
      "stars": 31848,
      "forks": 14944,
      "language": "Java",
      "topics": [
        "kafka",
        "scala"
      ],
      "created_at": "2011-08-15T18:06:16Z",
      "updated_at": "2026-02-06T23:25:49Z",
      "pushed_at": "2026-02-07T01:25:50Z",
      "open_issues": 272,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "<p align=\"center\">\n<picture>\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"docs/images/kafka-logo-readme-light.svg\">\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/kafka-logo-readme-dark.svg\">\n  <img src=\"docs/images/kafka-logo-readme-light.svg\" alt=\"Kafka Logo\" width=\"50%\"> \n</picture>\n</p>\n\n[![CI](https://github.com/apache/kafka/actions/workflows/ci.yml/badge.svg?branch=trunk&event=push)](https://github.com/apache/kafka/actions/workflows/ci.yml?query=event%3Apush+branch%3Atrunk)\n[![Flaky Test Report](https://github.com/apache/kafka/actions/workflows/generate-reports.yml/badge.svg?branch=trunk&event=schedule)](https://github.com/apache/kafka/actions/workflows/generate-reports.yml?query=event%3Aschedule+branch%3Atrunk)\n\n[**Apache Kafka**](https://kafka.apache.org) is an open-source distributed event streaming platform used by thousands of companies for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.\n\nYou need to have [Java](http://www.oracle.com/technetwork/java/javase/downloads/index.html) installed.\n\nWe build and test Apache Kafka with 17 and 25. The `release` parameter in javac is set to `11` for the clients \nand streams modules, and `17` for the rest, ensuring compatibility with their respective\nminimum Java versions. Similarly, the `release` parameter in scalac is set to `11` for the streams modules and `17`\nfor the rest.\n\nScala 2.13 is the only supported version in Apache Kafka.\n\n### Build a jar and run it\n```bash\n./gradlew jar\n```\n\nFollow instructions in https://kafka.apache.org/quickstart\n\n### Build source jar\n```bash\n./gradlew srcJar\n```\n\n### Build aggregated javadoc\n```bash\n./gradlew aggregatedJavadoc --no-parallel\n```\n\n### Build javadoc and scaladoc\n```bash\n./gradlew javadoc\n./gradlew javadocJar # builds a javadoc jar for each module\n./gradlew scaladoc\n./gradlew scaladocJar # builds a scaladoc jar for each module\n./gradlew docsJar # builds both (if applicable) javadoc and scaladoc jars for each module\n```\n\n### Run unit/integration tests\n```bash\n./gradlew test  # runs both unit and integration tests\n./gradlew unitTest\n./gradlew integrationTest\n./gradlew test -Pkafka.test.run.flaky=true  # runs tests that are marked as flaky\n```\n\n### Force re-running tests without code change\n```bash\n./gradlew test --rerun-tasks\n./gradlew unitTest --rerun-tasks\n./gradlew integrationTest --rerun-tasks\n```\n\n### Running a particular unit/integration test\n```bash\n./gradlew clients:test --tests RequestResponseTest\n./gradlew streams:integration-tests:test --tests RestoreIntegrationTest\n```\n\n### Repeatedly running a particular unit/integration test with specific times by setting N\n```bash\nN=500; I=0; while [ $I -lt $N ] && ./gradlew clients:test --tests RequestResponseTest --rerun --fail-fast; do (( I=$I+1 )); echo \"Completed run: $I\"; sleep 1; done\n```\n\n### Running a particular test method within a unit/integration test\n```bash\n./gradlew core:test --tests kafka.api.ProducerFailureHandlingTest.testCannotSendToInternalTopic\n./gradlew clients:test --tests org.apache.kafka.clients.MetadataTest.testTimeToNextUpdate\n./gradlew streams:integration-tests:test --tests org.apache.kafka.streams.integration.RestoreIntegrationTest.shouldRestoreNullRecord\n```\n\n### Running a particular unit/integration test with log4j output\nBy default, there will be only small number of logs output while testing. You can adjust it by changing the `log4j2.yaml` file in the module's `src/test/resources` directory.\n\nFor example, if you want to see more logs for clients project tests, you can modify [the line](https://github.com/apache/kafka/blob/trunk/clients/src/test/resources/log4j2.yaml#L35) in `clients/src/test/resources/log4j2.yaml` \nto `level: INFO` and then run:\n\n```bash\n./gradlew cleanTest clients:test --tests NetworkClientTest\n```\n\nAnd you should see `INFO` level logs in the file under the `clients/build/test-results/test` directory.\n\n### Specifying test retries\nRetries are disabled by default, but you can set maxTestRetryFailures and maxTestRetries to enable retries.\n\nThe following example declares -PmaxTestRetries=1 and -PmaxTestRetryFailures=3 to enable a failed test to be retried once, with a total retry limit of 3.\n\n```bash\n./gradlew test -PmaxTestRetries=1 -PmaxTestRetryFailures=3\n```\n\nSee [Test Retry Gradle Plugin](https://github.com/gradle/test-retry-gradle-plugin) and [build.yml](.github/workflows/build.yml) for more details.\n\n### Generating test coverage reports\nGenerate coverage reports for the whole project:\n\n```bash\n./gradlew reportCoverage -PenableTestCoverage=true -Dorg.gradle.parallel=false\n```\n\nGenerate coverage for a single module, i.e.: \n\n```bash\n./gradlew clients:reportCoverage -PenableTestCoverage=true -Dorg.gradle.parallel=false\n```\n\nCoverage reports are located within the module's build directory, categorized by module type:\n\nCore Module (:core): `core/build/reports/scoverageTest/index.html`\n\nOther Modules: `<module>/build/reports/jacoco/test/html/index.html`\n\n### Building a binary release gzipped tar ball\n```bash\n./gradlew clean releaseTarGz\n```\n\nThe release file can be found inside `./core/build/distributions/`.\n\n### Building auto generated messages\nSometimes it is only necessary to rebuild the RPC auto-generated message data when switching between branches, as they could\nfail due to code changes. You can just run:\n\n```bash\n./gradlew processMessages processTestMessages\n```\n\nSee [Apache Kafka Message Definitions](clients/src/main/resources/common/message/README.md) for details on Apache Kafka message protocol.\n\n### Running a Kafka broker\n\nUsing compiled files:\n\n```bash\nKAFKA_CLUSTER_ID=\"$(./bin/kafka-storage.sh random-uuid)\"\n./bin/kafka-storage.sh format --standalone -t $KAFKA_CLUSTER_ID -c config/server.properties\n./bin/kafka-server-start.sh config/server.properties\n```\n\nUsing docker image:\n\n```bash\ndocker run -p 9092:9092 apache/kafka:latest\n```\n\nSee [docker/README.md](docker/README.md) for detailed information.\n\n### Cleaning the build\n```bash\n./gradlew clean\n```\n\n### Running a task for a specific project\nThis is for `core`, `examples` and `clients`\n\n```bash\n./gradlew core:jar\n./gradlew core:test\n```\n\nStreams has multiple sub-projects, but you can run all the tests:\n\n```bash\n./gradlew :streams:testAll\n```\n\n### Listing all gradle tasks\n```bash\n./gradlew tasks\n```\n\n### Building IDE project\n*Note Please ensure that JDK17 is used when developing Kafka.*\n\nIntelliJ supports Gradle natively and it will automatically check Java syntax and compatibility for each module, even if\nthe Java version shown in the `Structure > Project Settings > Modules` may not be the correct one.\n\nWhen it comes to Eclipse, run:\n\n```bash\n./gradlew eclipse\n```\n\nThe `eclipse` task has been configured to use `${project_dir}/build_eclipse` as Eclipse's build directory. Eclipse's default\nbuild directory (`${project_dir}/bin`) clashes with Kafka's scripts directory and we don't use Gradle's build directory\nto avoid known issues with this configuration.\n\n### Publishing the streams quickstart archetype artifact to maven\nFor the Streams archetype project, one cannot use gradle to upload to maven; instead the `mvn deploy` command needs to be called at the quickstart folder:\n\n```bash\ncd streams/quickstart\nmvn deploy\n```\n\nPlease note for this to work you should create/update user maven settings (typically, `${USER_HOME}/.m2/settings.xml`) to assign the following variables\n\n    <settings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0\n                           https://maven.apache.org/xsd/settings-1.0.0.xsd\">\n    ...                           \n    <servers>\n       ...\n       <server>\n          <id>apache.snapshots.https</id>\n          <username>${maven_username}</username>\n          <password>${maven_password}</password>\n       </server>\n       <server>\n          <id>apache.releases.https</id>\n          <username>${maven_username}</username>\n          <password>${maven_password}</password>\n        </server>\n        ...\n     </servers>\n     ...\n\n### Installing all projects to the local Maven repository\n\n```bash\n./gradlew -PskipSigning=true publishToMavenLocal\n```\n\n### Installing specific projects to the local Maven repository\n\n```bash\n./gradlew -PskipSigning=true :streams:publishToMavenLocal\n```\n\n### Building the test jar\n```bash\n./gradlew testJar\n```\n\n### Running code quality checks\nThere are two code quality analysis tools that we regularly run, spotbugs and checkstyle.\n\n#### Checkstyle\nCheckstyle enforces a consistent coding style in Kafka.\nYou can run checkstyle using:\n\n```bash\n./gradlew checkstyleMain checkstyleTest spotlessCheck\n```\n\nThe checkstyle warnings will be found in `reports/checkstyle/reports/main.html` and `reports/checkstyle/reports/test.html` files in the\nsubproject build directories. They are also printed to the console. The build will fail if Checkstyle fails.\nFor experiments (or regression testing purposes) add `-PcheckstyleVersion=X.y.z` switch (to override project-defined checkstyle version).\n\n#### Spotless\nThe import order is a part of static check. please call `spotlessApply` to optimize the imports of Java codes before filing pull request.\n\n```bash\n./gradlew spotlessApply\n```\n\n#### Spotbugs\nSpotbugs uses static analysis to look for bugs in the code.\nYou can run spotbugs using:\n\n```bash\n./gradlew spotbugsMain spotbugsTest -x test\n```\n\nThe spotbugs warnings will be found in `reports/spotbugs/main.html` and `reports/spotbugs/test.html` files in the subproject build\ndirectories.  Use -PxmlSpotBugsReport=true to generate an XML report instead of an HTML one.\n\n### JMH microbenchmarks\nWe use [JMH](https://openjdk.java.net/projects/code-tools/jmh/) to write microbenchmarks that produce reliable results in the JVM.\n\nSee [jmh-benchmarks/README.md](https://github.com/apache/kafka/blob/trunk/jmh-benchmarks/README.md) for details on how to run the microbenchmarks.\n\n### Dependency Analysis\n\nThe gradle [dependency debugging documentation](https://docs.gradle.org/current/userguide/viewing_debugging_dependencies.html) mentions using the `dependencies` or `dependencyInsight` tasks to debug dependencies for the root project or individual subprojects.\n\nAlternatively, use the `allDeps` or `allDepInsight` tasks for recursively iterating through all subprojects:\n\n```bash\n./gradlew allDeps\n\n./gradlew allDepInsight --configuration runtimeClasspath --dependency com.fasterxml.jackson.core:jackson-databind\n```\n\nThese take the same arguments as the builtin variants.\n\n### Determining if any dependencies could be updated\n```bash\n./gradlew dependencyUpdates --no-parallel\n```\n\n### Common build options ###\n\nThe following options should be set with a `-P` switch, for example `./gradlew -PmaxParallelForks=1 test`.\n\n* `commitId`: sets the build commit ID as .git/HEAD might not be correct if there are local commits added for build purposes.\n* `mavenUrl`: sets the URL of the maven deployment repository (`file://path/to/repo` can be used to point to a local repository).\n* `maxParallelForks`: maximum number of test processes to start in parallel. Defaults to the number of processors available to the JVM.\n* `maxScalacThreads`: maximum number of worker threads for the scalac backend. Defaults to the lowest of `8` and the number of processors\navailable to the JVM. The value must be between 1 and 16 (inclusive). \n* `ignoreFailures`: ignore test failures from junit\n* `showStandardStreams`: shows standard out and standard error of the test JVM(s) on the console.\n* `skipSigning`: skips signing of artifacts.\n* `testLoggingEvents`: unit test events to be logged, separated by comma. For example `./gradlew -PtestLoggingEvents=started,passed,skipped,failed test`.\n* `xmlSpotBugsReport`: enable XML reports for spotBugs. This also disables HTML reports as only one can be enabled at a time.\n* `maxTestRetries`: maximum number of retries for a failing test case.\n* `maxTestRetryFailures`: maximum number of test failures before retrying is disabled for subsequent tests.\n* `enableTestCoverage`: enables test coverage plugins and tasks, including bytecode enhancement of classes required to track said\ncoverage. Note that this introduces some overhead when running tests and hence why it's disabled by default (the overhead\nvaries, but 15-20% is a reasonable estimate).\n* `keepAliveMode`: configures the keep alive mode for the Gradle compilation daemon - reuse improves start-up time. The values should \nbe one of `daemon` or `session` (the default is `daemon`). `daemon` keeps the daemon alive until it's explicitly stopped while\n`session` keeps it alive until the end of the build session. This currently only affects the Scala compiler, see\nhttps://github.com/gradle/gradle/pull/21034 for a PR that attempts to do the same for the Java compiler.\n* `scalaOptimizerMode`: configures the optimizing behavior of the scala compiler, the value should be one of `none`, `method`, `inline-kafka` or\n`inline-scala` (the default is `inline-kafka`). `none` is the scala compiler default, which only eliminates unreachable code. `method` also\nincludes method-local optimizations. `inline-kafka` adds inlining of methods within the kafka packages. Finally, `inline-scala` also\nincludes inlining of methods within the scala library (which avoids lambda allocations for methods like `Option.exists`). `inline-scala` is\nonly safe if the Scala library version is the same at compile time and runtime. Since we cannot guarantee this for all cases (for example, users\nmay depend on the kafka jar for integration tests where they may include a scala library with a different version), we don't enable it by\ndefault. See https://www.lightbend.com/blog/scala-inliner-optimizer for more details.\n\n### Upgrading Gradle version\n\nSee [gradle/wrapper/README.md](gradle/wrapper/README.md) for instructions on upgrading the Gradle version.\n\n### Running system tests\n\nSee [tests/README.md](tests/README.md).\n\n### Using Trogdor for testing\n\nWe use Trogdor as a test framework for Apache Kafka. You can use it to run benchmarks and other workloads.\n\nSee [trogdor/README.md](trogdor/README.md).\n\n### Running in Vagrant\n\nSee [vagrant/README.md](vagrant/README.md).\n\n### Kafka client examples\n\nSee [examples/README.md](examples/README.md).\n\n### Contribution\n\nApache Kafka is interested in building the community; we would welcome any thoughts or [patches](https://issues.apache.org/jira/browse/KAFKA). You can reach us [on the Apache mailing lists](http://kafka.apache.org/contact.html).\n\nTo contribute follow the instructions here:\n * https://kafka.apache.org/contributing.html\n",
      "stars_today": 14
    },
    {
      "id": 29219243,
      "name": "fanqiang",
      "full_name": "bannedbook/fanqiang",
      "description": "ç¿»å¢™-ç§‘å­¦ä¸Šç½‘",
      "html_url": "https://github.com/bannedbook/fanqiang",
      "stars": 42176,
      "forks": 7570,
      "language": "Kotlin",
      "topics": [
        "brook",
        "daze",
        "fanqiang",
        "goflyway",
        "lightsocks",
        "proxy",
        "psiphon",
        "shadowsocks",
        "ssr",
        "trojan",
        "v2ray"
      ],
      "created_at": "2015-01-14T00:34:25Z",
      "updated_at": "2026-02-07T01:59:26Z",
      "pushed_at": "2026-02-06T03:51:41Z",
      "open_issues": 324,
      "owner": {
        "login": "bannedbook",
        "avatar_url": "https://avatars.githubusercontent.com/u/4361923?v=4"
      },
      "readme": "# ç¿»å¢™-ç§‘å­¦ä¸Šç½‘ã€ç¿»å¢™å·¥å…·ã€ç¿»å¢™æ•™ç¨‹é¡¹ç›®åº“\r\n\r\n*   [ç¿»å¢™æ–°é—»-FQNews-å®‰å“APP](https://github.com/bannedbook/fanqiang/tree/master/fqnews2)\r\n*   [å®‰å“ç¿»å¢™è½¯ä»¶](https://github.com/bannedbook/fanqiang/wiki/%E5%AE%89%E5%8D%93%E7%BF%BB%E5%A2%99%E8%BD%AF%E4%BB%B6)\r\n*   [å®‰å“ç¿»å¢™APPæ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/android)\r\n*   [Chromeä¸€é”®ç¿»å¢™åŒ…](https://github.com/bannedbook/fanqiang/wiki/Chrome%E4%B8%80%E9%94%AE%E7%BF%BB%E5%A2%99%E5%8C%85)\r\n*   [Chromeä¸€é”®ç¿»å¢™åŒ… Macç‰ˆ](https://github.com/bannedbook/fanqiang/tree/master/ChromeGoMac#chromegomacchrome%E4%B8%80%E9%94%AE%E7%BF%BB%E5%A2%99%E5%8C%85-mac%E7%89%88)\r\n*   [EdgeGo-Edgeä¸€é”®ç¿»å¢™åŒ…](https://github.com/bannedbook/fanqiang/tree/master/EdgeGo)\r\n*   [ç«ç‹firefoxä¸€é”®ç¿»å¢™åŒ…](https://github.com/bannedbook/fanqiang/wiki/%E7%81%AB%E7%8B%90firefox%E4%B8%80%E9%94%AE%E7%BF%BB%E5%A2%99%E5%8C%85)\r\n*   [Firefoxä¸€é”®ç¿»å¢™åŒ…Linuxç‰ˆ](https://github.com/bannedbook/fanqiang/tree/master/FirefoxFqLinux)\r\n*   [è‡ªå»ºV2rayæœåŠ¡å™¨ç¿»å¢™ç®€æ˜æ•™ç¨‹](https://github.com/bannedbook/fanqiang/blob/master/v2ss/%E8%87%AA%E5%BB%BAV2ray%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B.md)\r\n*   [è‡ªå»ºShadowsocksæœåŠ¡å™¨ç¿»å¢™ç®€æ˜æ•™ç¨‹](https://github.com/bannedbook/fanqiang/blob/master/v2ss/%E8%87%AA%E5%BB%BAShadowsocks%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B.md)\r\n*   [å…è´¹ssè´¦å·](https://github.com/bannedbook/fanqiang/wiki/%E5%85%8D%E8%B4%B9ss%E8%B4%A6%E5%8F%B7)\r\n*   [v2rayå…è´¹è´¦å·](https://github.com/bannedbook/fanqiang/wiki/v2ray%E5%85%8D%E8%B4%B9%E8%B4%A6%E5%8F%B7)\r\n*   [è‹¹æœç”µè„‘MACç¿»å¢™](https://github.com/bannedbook/fanqiang/wiki/%E8%8B%B9%E6%9E%9C%E7%94%B5%E8%84%91MAC%E7%BF%BB%E5%A2%99)\r\n*   [iphoneç¿»å¢™](https://github.com/bannedbook/fanqiang/wiki/iphone%E7%BF%BB%E5%A2%99)\r\n*   [TorBrowserä¸€é”®ç¿»å¢™åŒ…](https://github.com/bannedbook/fanqiang/wiki/TorBrowser%E4%B8%80%E9%94%AE%E7%BF%BB%E5%A2%99%E5%8C%85)\r\n*   [ä¸­å›½å¤§é™†æ³¨å†ŒChatGPTæ•™ç¨‹](https://github.com/bannedbook/fanqiang/blob/master/signup-chatgpt.md#%E4%B8%AD%E5%9B%BD%E5%A4%A7%E9%99%86%E6%B3%A8%E5%86%8Cchatgpt%E6%95%99%E7%A8%8B)\r\n\r\n## [Windows V2ray/SS/SSR ç¿»å¢™æ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/windows)\r\n\r\n  * [Clash for Windows ç¿»å¢™æ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/windows/ClashDotNetFramework.md)\r\n  * [V2rayN æ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/windows/V2RayN.md)\r\n  * [SSTapæ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/windows/SSTap.md)\r\n  * [Windowsç¿»å¢™ä¹‹SSRæ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/windows/ShadowsocksR.md)\r\n  * [TorBrowser+V2rayNé…ç½®ä½¿ç”¨æ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/windows/tor-v2ray.md)\r\n\r\n## [iPhone/iPad/iOS V2ray/SS ç¿»å¢™APPæ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/ios)\r\n\r\n  * [iphoneç¿»å¢™](https://github.com/bannedbook/fanqiang/wiki/iphone%E7%BF%BB%E5%A2%99)\r\n  * [æ³¨å†Œè‹¹æœç¾åŒº Apple ID å¸å·å¹¶è´­ä¹°APPæŒ‡å—](https://github.com/bannedbook/fanqiang/tree/master/ios/AppleID.md)\r\n  * [Iphone/iPadé€šè¿‡ç”µè„‘å±€åŸŸç½‘å…±äº«ç¿»å¢™](https://github.com/bannedbook/fanqiang/tree/master/ios/fqByLan.md)\r\n  * [Potatsoæ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/ios/PotatsoLite.md)\r\n  * [Shadowrocketå°ç«ç®­é…ç½®ä½¿ç”¨æ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/ios/Shadowrocket.md)\r\n  * [Quantumult X é…ç½®ä½¿ç”¨ç®€æ˜“æ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/ios/QuantumultX.md)\r\n  * [iOSç¿»å¢™ä¹‹Surgeæ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/ios/Surge.md)\r\n\r\n## [Android å®‰å“ç¿»å¢™APPæ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/android)\r\n\r\n  * [V2freeå®‰å“ç¿»å¢™æ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/android/v2free.md)\r\n  * [Clash for android æ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/android/clash.md)\r\n  * [BifrostV æ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/android/BifrostV.md)\r\n  * [Shadowsocks for android æ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/android/Shadowsocks.md)\r\n  * [SSR å®‰å“ç¿»å¢™æ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/android/ShadowsocksR.md)\r\n  * [Surfboard æ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/android/Surfboard.md)\r\n  * [V2RayNG æ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/android/V2RayNG.md)\r\n\r\n## [Macç¿»å¢™è½¯ä»¶æ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/macos)\r\n\r\n  * [è‹¹æœç”µè„‘MACç¿»å¢™](https://github.com/bannedbook/fanqiang/wiki/%E8%8B%B9%E6%9E%9C%E7%94%B5%E8%84%91MAC%E7%BF%BB%E5%A2%99)\r\n  * [macOSç¿»å¢™ä¹‹ClashXç¿»å¢™æ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/macos/ClashX.md)\r\n  * [macOSç¿»å¢™ä¹‹V2rayUæ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/macos/V2RayU.md)\r\n  * [macOSç¿»å¢™ä¹‹Surgeæ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/macos/Surge.md)\r\n  * [macOSç¿»å¢™ä¹‹V2rayXæ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/macos/V2rayX.md)\r\n  \r\n## [è·¯ç”±å™¨ç¿»å¢™æ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/router)\r\n\r\n  * [æ¢…æ—è·¯ç”±å™¨ç¿»å¢™æ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/router/Merlin.md)\r\n  * [OpenWRTè·¯ç”±å™¨ç¿»å¢™æ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/router/OpenWRT.md)\r\n\r\n## [Linuxç¿»å¢™æ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/linux)\r\n\r\n## [æ¸¸æˆæœºç¿»å¢™æ•™ç¨‹](https://github.com/bannedbook/fanqiang/tree/master/game)\r\n  * [PS4-PS5æ¸¸æˆæœºé€šè¿‡å±€åŸŸç½‘ç¿»å¢™ï¼ŒåŠ é€Ÿæ¸¸æˆï¼Œä»¥åŠä¸‹è½½æ¸¸æˆæ•™ç¨‹](https://github.com/bannedbook/fanqiang/blob/master/game/PS4-PS5%E6%B8%B8%E6%88%8F%E6%9C%BA%E9%80%9A%E8%BF%87%E5%B1%80%E5%9F%9F%E7%BD%91%E7%BF%BB%E5%A2%99%E6%95%99%E7%A8%8B.md)\r\n  * [SStapå’ŒNetchå…è´¹æ¸¸æˆåŠ é€Ÿå™¨æ•™ç¨‹](https://github.com/bannedbook/fanqiang/blob/master/game/SStap%E5%92%8CNetch%E5%85%8D%E8%B4%B9%E6%B8%B8%E6%88%8F%E5%8A%A0%E9%80%9F%E5%99%A8%E6%95%99%E7%A8%8B.md)\r\n  * [Switchã€ PlayStationã€Xboxç­‰æ¸¸æˆæœºç¿»å¢™æ•™ç¨‹ï¼Œåˆ©ç”¨MACç”µè„‘åšæ—è·¯ç”±åŠ é€Ÿ](https://github.com/bannedbook/fanqiang/blob/master/game/Switch%E3%80%81%20PlayStation%E3%80%81Xbox%E7%AD%89%E6%B8%B8%E6%88%8F%E6%9C%BA%E7%BF%BB%E5%A2%99%E6%95%99%E7%A8%8B%EF%BC%8C%E5%88%A9%E7%94%A8MAC%E7%94%B5%E8%84%91%E5%81%9A%E6%97%81%E8%B7%AF%E7%94%B1%E5%8A%A0%E9%80%9F.md)\r\n  * [Windowså¦‚ä½•å…±äº«Wifiæ— çº¿ç½‘å¡ç¿»å¢™çƒ­ç‚¹ç»™å…¶å®ƒè®¾å¤‡ç¿»å¢™](https://github.com/bannedbook/fanqiang/blob/master/game/Windows%E5%A6%82%E4%BD%95%E5%85%B1%E4%BA%ABWifi%E6%97%A0%E7%BA%BF%E7%BD%91%E5%8D%A1%E7%BF%BB%E5%A2%99%E7%83%AD%E7%82%B9%E7%BB%99%E5%85%B6%E5%AE%83%E8%AE%BE%E5%A4%87%E7%BF%BB%E5%A2%99.md)\r\n  * [Macç”µè„‘ä½¿ç”¨ClashX Proä½œä¸ºç½‘å…³æ—è·¯ç”±ç»™å…¶å®ƒè®¾å¤‡ç¿»å¢™](https://github.com/bannedbook/fanqiang/blob/master/game/Mac%E7%94%B5%E8%84%91%E4%BD%BF%E7%94%A8ClashX%20Pro%E4%BD%9C%E4%B8%BA%E7%BD%91%E5%85%B3%E6%97%81%E8%B7%AF%E7%94%B1%E7%BB%99%E5%85%B6%E5%AE%83%E8%AE%BE%E5%A4%87%E7%BF%BB%E5%A2%99.md)\r\n  * [åœ¨Macä¸Šä½¿ç”¨clashx proç»™switchå¼€å¯æ¸¸æˆåŠ é€Ÿ](https://github.com/bannedbook/fanqiang/blob/master/game/%E5%9C%A8Mac%E4%B8%8A%E4%BD%BF%E7%94%A8clashx%20pro%E7%BB%99switch%E5%BC%80%E5%90%AF%E6%B8%B8%E6%88%8F%E5%8A%A0%E9%80%9F.md)\r\n  * [è‹¹æœç”µè§†Apple Tvç¿»å¢™æŒ‡å—](https://github.com/bannedbook/fanqiang/blob/master/game/%E8%8B%B9%E6%9E%9C%E7%94%B5%E8%A7%86Apple%20Tv%E7%BF%BB%E5%A2%99%E6%8C%87%E5%8D%97.md)\r\n\r\n## ChromeGo - Chromeä¸€é”®ç¿»å¢™åŒ… \r\n\r\nä¸€ä¸ªé›†æˆGoflywayã€v2rayã€Dazeã€SSRã€Brookã€Lightsocksã€trojanã€è“ç¯ã€psiphonç­‰Nå¤šç¿»å¢™å·¥å…·çš„ç”µè„‘ç¿»å¢™åŒ…ï¼ˆæ¨èæŒ‰å‰é¢æ‰€åˆ—é¡ºåºä¾æ¬¡å°è¯•ï¼‰ï¼Œæ‰€æœ‰å·¥å…·å…¨éƒ¨å†…ç½®å…è´¹æœåŠ¡å™¨ï¼Œé•¿æœŸæ›´æ–°ã€‚ç”±äºå›½å†…ç½‘ç»œç¯å¢ƒå¤æ‚ã€åœ°åŒºä¸åŒï¼Œç½‘ç»œè¿è¥å•†ä¸åŒï¼Œå°é”æƒ…å†µéƒ½ä¸åŒï¼Œæ‰€ä»¥ä½¿ç”¨æ•ˆæœä¼šæœ‰å·®åˆ«ï¼Œæœ‰çš„åœ°åŒºå‡ ä¹æ‰€æœ‰çš„è½¯ä»¶éƒ½èƒ½ä½¿ç”¨ï¼Œæœ‰çš„åªèƒ½ç”¨å‡ æ¬¾ï¼Œå› æ­¤å…·ä½“å“ªæ¬¾è½¯ä»¶é€‚åˆä½ çš„ç½‘ç»œç¯å¢ƒï¼Œéœ€è¦ä½ è‡ªå·±æ¥å°è¯•ã€‚ \r\n\r\n**æ¨èï¼š**\r\n\r\n<a href=\"https://github.com/bannedbook/fanqiang/wiki/V2ray%E6%9C%BA%E5%9C%BA\"><img src=\"https://raw.githubusercontent.com/bannedbook/fanqiang/master/v2ss/images/v2free.jpg\" height=\"300\" alt=\"V2freeç¿»å¢™-ä¸é™æµé‡ã€é«˜é€Ÿç¨³å®šã€æ€§ä»·æ¯”è¶…å¼º\"></a>\r\n\r\n**ä¸‹è½½Chromeä¸€é”®ç¿»å¢™åŒ…**\r\n\r\n[Chromeä¸€é”®ç¿»å¢™åŒ…](https://github.com/bannedbook/fanqiang/wiki/Chrome%E4%B8%80%E9%94%AE%E7%BF%BB%E5%A2%99%E5%8C%85)\r\n\r\n**ä½¿ç”¨Chromeä¸€é”®ç¿»å¢™åŒ…**\r\n\r\nè¯·é¦–å…ˆè‡ªè¡Œå®‰è£…Google Chrome æµè§ˆå™¨ï¼Œç„¶åä¸‹è½½Chromeä¸€é”®ç¿»å¢™åŒ…ï¼Œæœ¬è½¯ä»¶ä¼šè‡ªåŠ¨è°ƒç”¨Google Chrome æµè§ˆå™¨ç¿»å¢™ã€‚ ä¸‹è½½åï¼Œè§£å‹å‡ºæ¥ï¼Œè¯·ä¸è¦è§£å‹åˆ°å«æœ‰ä¸­æ–‡æˆ–ç©ºæ ¼çš„ç›®å½•è·¯å¾„ï¼Œè¯·ä¸è¦ä¸è§£å‹å°±ç›´æ¥ä»å‹ç¼©åŒ…é‡Œè¿è¡Œï¼ä¸è§£å‹ä¼šå‡ºé”™ï¼ ä¸‹è½½åï¼Œè¯·è®¤çœŸé˜…è¯»é‡Œé¢çš„ä½¿ç”¨å¸®åŠ©è¯´æ˜ï¼Œç„¶å 0.xx-10.xxç¿»å¢™ å¯ä¾æ¬¡å°è¯•ã€‚ è‡ªåŠ¨å›å¤æœ€æ–°ç¿»å¢™ä¿¡æ¯ç½‘å€ï¼šfreeman105@gmail.comï¼Œé‚®ç®±ä¸è§£ç­”é—®é¢˜,å¦‚éœ€åé¦ˆäº¤æµï¼Œè¯·[ç‚¹æˆ‘](https://github.com/bannedbook/fanqiang/issues)æˆ–åŠ å…¥ç¿»å¢™ç”µæŠ¥ç¾¤: \r\nhttps://t.me/fqchat \r\n\r\n**ç‰ˆæƒå£°æ˜**  \r\n\r\nè¯·éšæ„åˆ†å‘ï¼Œå‹¿åšå•†ä¸šä½¿ç”¨ã€‚",
      "stars_today": 14
    },
    {
      "id": 197081291,
      "name": "iced",
      "full_name": "iced-rs/iced",
      "description": "A cross-platform GUI library for Rust, inspired by Elm",
      "html_url": "https://github.com/iced-rs/iced",
      "stars": 29397,
      "forks": 1483,
      "language": "Rust",
      "topics": [
        "elm",
        "graphics",
        "gui",
        "interface",
        "renderer-agnostic",
        "rust",
        "toolkit",
        "user-interface",
        "widget",
        "widgets"
      ],
      "created_at": "2019-07-15T22:34:46Z",
      "updated_at": "2026-02-07T02:13:53Z",
      "pushed_at": "2026-02-06T08:21:50Z",
      "open_issues": 394,
      "owner": {
        "login": "iced-rs",
        "avatar_url": "https://avatars.githubusercontent.com/u/54513237?v=4"
      },
      "readme": "<div align=\"center\">\n\n<img src=\"docs/logo.svg\" width=\"140px\" />\n\n# Iced\n\n[![Documentation](https://docs.rs/iced/badge.svg)][documentation]\n[![Crates.io](https://img.shields.io/crates/v/iced.svg)](https://crates.io/crates/iced)\n[![License](https://img.shields.io/crates/l/iced.svg)](https://github.com/iced-rs/iced/blob/master/LICENSE)\n[![Downloads](https://img.shields.io/crates/d/iced.svg)](https://crates.io/crates/iced)\n[![Test Status](https://img.shields.io/github/actions/workflow/status/iced-rs/iced/test.yml?branch=master&event=push&label=test)](https://github.com/iced-rs/iced/actions)\n[![Discourse](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscourse.iced.rs%2Fsite%2Fstatistics.json&query=%24.users_count&suffix=%20users&label=discourse&color=5e7ce2)](https://discourse.iced.rs/)\n[![Discord Server](https://img.shields.io/discord/628993209984614400?label=&labelColor=6A7EC2&logo=discord&logoColor=ffffff&color=7389D8)](https://discord.gg/3xZJ65GAhd)\n\nA cross-platform GUI library for Rust focused on simplicity and type-safety.\nInspired by [Elm].\n\n<a href=\"https://github.com/squidowl/halloy\">\n  <img src=\"https://iced.rs/showcase/halloy.gif\" width=\"460px\">\n</a>\n<a href=\"https://github.com/hecrj/icebreaker\">\n  <img src=\"https://iced.rs/showcase/icebreaker.gif\" width=\"360px\">\n</a>\n\n</div>\n\n## Features\n\n* Simple, easy-to-use, batteries-included API\n* Type-safe, reactive programming model\n* [Cross-platform support] (Windows, macOS, Linux, and the Web)\n* Responsive layout\n* Built-in widgets (including [text inputs], [scrollables], and more!)\n* Custom widget support (create your own!)\n* [Debug tooling with performance metrics and time traveling]\n* First-class support for async actions (use futures!)\n* Modular ecosystem split into reusable parts:\n  * A [renderer-agnostic native runtime] enabling integration with existing systems\n  * Two built-in renderers leveraging [`wgpu`] and [`tiny-skia`]\n    * [`iced_wgpu`] supporting Vulkan, Metal and DX12\n    * [`iced_tiny_skia`] offering a software alternative as a fallback\n  * A [windowing shell]\n\n__Iced is currently experimental software.__ [Take a look at the roadmap] and\n[check out the issues].\n\n[Cross-platform support]: https://raw.githubusercontent.com/iced-rs/iced/master/docs/images/todos_desktop.jpg\n[text inputs]: https://iced.rs/examples/text_input.mp4\n[scrollables]: https://iced.rs/examples/scrollable.mp4\n[Debug tooling with performance metrics and time traveling]: https://github.com/user-attachments/assets/2e49695c-0261-4b43-ac2e-8d7da5454c4b\n[renderer-agnostic native runtime]: runtime/\n[`wgpu`]: https://github.com/gfx-rs/wgpu\n[`tiny-skia`]: https://github.com/RazrFalcon/tiny-skia\n[`iced_wgpu`]: wgpu/\n[`iced_tiny_skia`]: tiny_skia/\n[windowing shell]: winit/\n[Take a look at the roadmap]: ROADMAP.md\n[check out the issues]: https://github.com/iced-rs/iced/issues\n\n## Overview\n\nInspired by [The Elm Architecture], Iced expects you to split user interfaces\ninto four different concepts:\n\n* __State__ â€” the state of your application\n* __Messages__ â€” user interactions or meaningful events that you care\n  about\n* __View logic__ â€” a way to display your __state__ as widgets that\n  may produce __messages__ on user interaction\n* __Update logic__ â€” a way to react to __messages__ and update your\n  __state__\n\nWe can build something to see how this works! Let's say we want a simple counter\nthat can be incremented and decremented using two buttons.\n\nWe start by modelling the __state__ of our application:\n\n```rust\n#[derive(Default)]\nstruct Counter {\n    value: i32,\n}\n```\n\nNext, we need to define the possible user interactions of our counter:\nthe button presses. These interactions are our __messages__:\n\n```rust\n#[derive(Debug, Clone, Copy)]\npub enum Message {\n    Increment,\n    Decrement,\n}\n```\n\nNow, let's show the actual counter by putting it all together in our\n__view logic__:\n\n```rust\nuse iced::widget::{button, column, text, Column};\n\nimpl Counter {\n    pub fn view(&self) -> Column<Message> {\n        // We use a column: a simple vertical layout\n        column![\n            // The increment button. We tell it to produce an\n            // `Increment` message when pressed\n            button(\"+\").on_press(Message::Increment),\n\n            // We show the value of the counter here\n            text(self.value).size(50),\n\n            // The decrement button. We tell it to produce a\n            // `Decrement` message when pressed\n            button(\"-\").on_press(Message::Decrement),\n        ]\n    }\n}\n```\n\nFinally, we need to be able to react to any produced __messages__ and change our\n__state__ accordingly in our __update logic__:\n\n```rust\nimpl Counter {\n    // ...\n\n    pub fn update(&mut self, message: Message) {\n        match message {\n            Message::Increment => {\n                self.value += 1;\n            }\n            Message::Decrement => {\n                self.value -= 1;\n            }\n        }\n    }\n}\n```\n\nAnd that's everything! We just wrote a whole user interface. Let's run it:\n\n```rust\nfn main() -> iced::Result {\n    iced::run(Counter::update, Counter::view)\n}\n```\n\nIced will automatically:\n\n  1. Take the result of our __view logic__ and layout its widgets.\n  1. Process events from our system and produce __messages__ for our\n     __update logic__.\n  1. Draw the resulting user interface.\n\nRead the [book], the [documentation], and the [examples] to learn more!\n\n## Implementation details\n\nIced was originally born as an attempt at bringing the simplicity of [Elm] and\n[The Elm Architecture] into [Coffee], a 2D game library I am working on.\n\nThe core of the library was implemented during May 2019 in [this pull request].\n[The first alpha version] was eventually released as\n[a renderer-agnostic GUI library]. The library did not provide a renderer and\nimplemented the current [tour example] on top of [`ggez`], a game library.\n\nSince then, the focus has shifted towards providing a batteries-included,\nend-user-oriented GUI library, while keeping the ecosystem modular.\n\n[this pull request]: https://github.com/hecrj/coffee/pull/35\n[The first alpha version]: https://github.com/iced-rs/iced/tree/0.1.0-alpha\n[a renderer-agnostic GUI library]: https://www.reddit.com/r/rust/comments/czzjnv/iced_a_rendereragnostic_gui_library_focused_on/\n[tour example]: examples/README.md#tour\n[`ggez`]: https://github.com/ggez/ggez\n\n## Contributing / Feedback\n\nIf you want to contribute, please read our [contributing guidelines] for more details.\n\nFeedback is also welcome! You can create a new topic in [our Discourse forum] or\ncome chat to [our Discord server].\n\n## Sponsors\n\nThe development of Iced is sponsored by the [Cryptowatch] team at [Kraken.com]\n\n[book]: https://book.iced.rs/\n[documentation]: https://docs.rs/iced/\n[examples]: https://github.com/iced-rs/iced/tree/master/examples#examples\n[Coffee]: https://github.com/hecrj/coffee\n[Elm]: https://elm-lang.org/\n[The Elm Architecture]: https://guide.elm-lang.org/architecture/\n[the current issues]: https://github.com/iced-rs/iced/issues\n[contributing guidelines]: https://github.com/iced-rs/iced/blob/master/CONTRIBUTING.md\n[our Discourse forum]: https://discourse.iced.rs/\n[our Discord server]: https://discord.gg/3xZJ65GAhd\n[Cryptowatch]: https://cryptowat.ch/charts\n[Kraken.com]: https://kraken.com/\n",
      "stars_today": 14
    },
    {
      "id": 969892666,
      "name": "SQLBot",
      "full_name": "dataease/SQLBot",
      "description": "ğŸ”¥ åŸºäºå¤§æ¨¡å‹å’Œ RAG çš„æ™ºèƒ½é—®æ•°ç³»ç»Ÿï¼Œå¯¹è¯å¼æ•°æ®åˆ†æç¥å™¨ã€‚Text-to-SQL Generation via LLMs using RAG.",
      "html_url": "https://github.com/dataease/SQLBot",
      "stars": 5471,
      "forks": 600,
      "language": "JavaScript",
      "topics": [
        "chatbi",
        "deepseek",
        "llm",
        "nl2sql",
        "rag",
        "sqlbot",
        "text-to-sql",
        "text2sql"
      ],
      "created_at": "2025-04-21T05:33:53Z",
      "updated_at": "2026-02-06T15:41:18Z",
      "pushed_at": "2026-02-05T08:34:24Z",
      "open_issues": 72,
      "owner": {
        "login": "dataease",
        "avatar_url": "https://avatars.githubusercontent.com/u/75054108?v=4"
      },
      "readme": "<p align=\"center\"><img src=\"https://resource-fit2cloud-com.oss-cn-hangzhou.aliyuncs.com/sqlbot/sqlbot.png\" alt=\"SQLBot\" width=\"300\" /></p>\n<h3 align=\"center\">åŸºäºå¤§æ¨¡å‹å’Œ RAG çš„æ™ºèƒ½é—®æ•°ç³»ç»Ÿ</h3>\n\n<p align=\"center\">\n  <a href=\"https://trendshift.io/repositories/14540\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/14540\" alt=\"dataease%2FSQLBot | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/dataease/SQLBot/releases/latest\"><img src=\"https://img.shields.io/github/v/release/dataease/SQLBot\" alt=\"Latest release\"></a>\n  <a href=\"https://github.com/dataease/SQLBot\"><img src=\"https://img.shields.io/github/stars/dataease/SQLBot?color=%231890FF&style=flat-square\" alt=\"Stars\"></a>    \n  <a href=\"https://hub.docker.com/r/dataease/SQLbot\"><img src=\"https://img.shields.io/docker/pulls/dataease/sqlbot?label=downloads\" alt=\"Download\"></a><br/>\n</p>\n\n<p align=\"center\">\n  <a href=\"README.md\"><img alt=\"ä¸­æ–‡(ç®€ä½“)\" src=\"https://img.shields.io/badge/ä¸­æ–‡(ç®€ä½“)-d9d9d9\"></a>\n  <a href=\"/docs/README.en.md\"><img alt=\"English\" src=\"https://img.shields.io/badge/English-d9d9d9\"></a>\n</p>\n<hr/>\n\n\nSQLBot æ˜¯ä¸€æ¬¾åŸºäºå¤§è¯­è¨€æ¨¡å‹å’Œ RAG çš„æ™ºèƒ½é—®æ•°ç³»ç»Ÿï¼Œç”± DataEase å¼€æºé¡¹ç›®ç»„åŒ å¿ƒå‡ºå“ã€‚å€ŸåŠ© SQLBotï¼Œç”¨æˆ·å¯ä»¥å®ç°å¯¹è¯å¼æ•°æ®åˆ†æï¼ˆChatBIï¼‰ï¼Œå¿«é€Ÿæç‚¼è·å–æ‰€éœ€çš„æ•°æ®ä¿¡æ¯åŠå¯è§†åŒ–å›¾è¡¨ï¼Œå¹¶ä¸”æ”¯æŒè¿›ä¸€æ­¥å¼€å±•æ™ºèƒ½åˆ†æã€‚\n\n## å·¥ä½œåŸç†\n\n<img width=\"1153\" height=\"563\" alt=\"image\" src=\"https://github.com/user-attachments/assets/8bc40db1-2602-4b68-9802-b9be36281967\" />\n\n## æ ¸å¿ƒä¼˜åŠ¿\n\n- **å¼€ç®±å³ç”¨**ï¼šä»…éœ€ç®€å•é…ç½®å¤§æ¨¡å‹ä¸æ•°æ®æºï¼Œæ— éœ€å¤æ‚å¼€å‘ï¼Œå³å¯å¿«é€Ÿå¼€å¯æ™ºèƒ½é—®æ•°ï¼›ä¾æ‰˜å¤§æ¨¡å‹è‡ªç„¶è¯­è¨€ç†è§£ä¸ SQL ç”Ÿæˆèƒ½åŠ›ï¼Œç»“åˆ RAG æŠ€æœ¯ï¼Œå®ç°é«˜è´¨é‡ Text-to-SQL è½¬æ¢ã€‚\n- **å®‰å…¨å¯æ§**ï¼šæä¾›å·¥ä½œç©ºé—´çº§èµ„æºéš”ç¦»æœºåˆ¶ï¼Œæ„å»ºæ¸…æ™°æ•°æ®è¾¹ç•Œï¼Œä¿éšœæ•°æ®è®¿é—®å®‰å…¨ï¼›æ”¯æŒç»†ç²’åº¦æ•°æ®æƒé™é…ç½®ï¼Œå¼ºåŒ–æƒé™ç®¡æ§èƒ½åŠ›ï¼Œç¡®ä¿ä½¿ç”¨è¿‡ç¨‹åˆè§„å¯æ§ã€‚\n- **æ˜“äºé›†æˆ**ï¼šæ”¯æŒå¤šç§é›†æˆæ–¹å¼ï¼Œæä¾› Web åµŒå…¥ã€å¼¹çª—åµŒå…¥ã€MCP è°ƒç”¨ç­‰èƒ½åŠ›ï¼›èƒ½å¤Ÿå¿«é€ŸåµŒå…¥åˆ° n8nã€Difyã€MaxKBã€DataEase ç­‰åº”ç”¨ï¼Œè®©å„ç±»åº”ç”¨å¿«é€Ÿæ‹¥æœ‰æ™ºèƒ½é—®æ•°èƒ½åŠ›ã€‚\n- **è¶Šé—®è¶Šå‡†**ï¼šæ”¯æŒè‡ªå®šä¹‰æç¤ºè¯ã€æœ¯è¯­åº“é…ç½®ï¼Œå¯ç»´æŠ¤ SQL ç¤ºä¾‹æ ¡å‡†é€»è¾‘ï¼Œç²¾å‡†åŒ¹é…ä¸šåŠ¡åœºæ™¯ï¼›é«˜æ•ˆè¿è¥ï¼ŒåŸºäºç”¨æˆ·äº¤äº’æ•°æ®æŒç»­è¿­ä»£ä¼˜åŒ–ï¼Œé—®æ•°æ•ˆæœéšä½¿ç”¨é€æ­¥æå‡ï¼Œè¶Šé—®è¶Šå‡†ã€‚\n\n## å¿«é€Ÿå¼€å§‹\n\n### å®‰è£…éƒ¨ç½²\n\nå‡†å¤‡ä¸€å° Linux æœåŠ¡å™¨ï¼Œå®‰è£…å¥½ [Docker](https://docs.docker.com/get-docker/)ï¼Œæ‰§è¡Œä»¥ä¸‹ä¸€é”®å®‰è£…è„šæœ¬ï¼š\n\n```bash\ndocker run -d \\\n  --name sqlbot \\\n  --restart unless-stopped \\\n  -p 8000:8000 \\\n  -p 8001:8001 \\\n  -v ./data/sqlbot/excel:/opt/sqlbot/data/excel \\\n  -v ./data/sqlbot/file:/opt/sqlbot/data/file \\\n  -v ./data/sqlbot/images:/opt/sqlbot/images \\\n  -v ./data/sqlbot/logs:/opt/sqlbot/app/logs \\\n  -v ./data/postgresql:/var/lib/postgresql/data \\\n  --privileged=true \\\n  dataease/sqlbot\n```\n\nä½ ä¹Ÿå¯ä»¥é€šè¿‡ [1Panel åº”ç”¨å•†åº—](https://apps.fit2cloud.com/1panel) å¿«é€Ÿéƒ¨ç½² SQLBotã€‚\n\nå¦‚æœæ˜¯å†…ç½‘ç¯å¢ƒï¼Œä½ å¯ä»¥é€šè¿‡ [ç¦»çº¿å®‰è£…åŒ…æ–¹å¼](https://community.fit2cloud.com/#/products/sqlbot/downloads) éƒ¨ç½² SQLBotã€‚\n\n### è®¿é—®æ–¹å¼\n\n- åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€: http://<ä½ çš„æœåŠ¡å™¨IP>:8000/\n- ç”¨æˆ·å: admin\n- å¯†ç : SQLBot@123456\n\n### è”ç³»æˆ‘ä»¬\n\nå¦‚ä½ æœ‰æ›´å¤šé—®é¢˜ï¼Œå¯ä»¥åŠ å…¥æˆ‘ä»¬çš„æŠ€æœ¯äº¤æµç¾¤ä¸æˆ‘ä»¬äº¤æµã€‚\n\n<img width=\"180\" height=\"180\" alt=\"contact_me_qr\" src=\"https://github.com/user-attachments/assets/2594ff29-5426-4457-b051-279855610030\" />\n\n## UI å±•ç¤º\n\n  <tr>\n    <img alt=\"q&a\" src=\"https://github.com/user-attachments/assets/55526514-52f3-4cfe-98ec-08a986259280\"   />\n  </tr>\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=dataease/sqlbot&type=Date)](https://www.star-history.com/#dataease/sqlbot&Date)\n\n## é£è‡´äº‘æ——ä¸‹çš„å…¶ä»–æ˜æ˜Ÿé¡¹ç›®\n\n- [DataEase](https://github.com/dataease/dataease/) - äººäººå¯ç”¨çš„å¼€æº BI å·¥å…·\n- [1Panel](https://github.com/1panel-dev/1panel/) - ç°ä»£åŒ–ã€å¼€æºçš„ Linux æœåŠ¡å™¨è¿ç»´ç®¡ç†é¢æ¿\n- [MaxKB](https://github.com/1panel-dev/MaxKB/) - å¼ºå¤§æ˜“ç”¨çš„ä¼ä¸šçº§æ™ºèƒ½ä½“å¹³å°\n- [JumpServer](https://github.com/jumpserver/jumpserver/) - å¹¿å—æ¬¢è¿çš„å¼€æºå ¡å’æœº\n- [Cordys CRM](https://github.com/1Panel-dev/CordysCRM) - æ–°ä¸€ä»£çš„å¼€æº AI CRM ç³»ç»Ÿ\n- [Halo](https://github.com/halo-dev/halo/) - å¼ºå¤§æ˜“ç”¨çš„å¼€æºå»ºç«™å·¥å…·\n- [MeterSphere](https://github.com/metersphere/metersphere/) - æ–°ä¸€ä»£çš„å¼€æºæŒç»­æµ‹è¯•å·¥å…·\n\n## License\n\næœ¬ä»“åº“éµå¾ª [FIT2CLOUD Open Source License](LICENSE) å¼€æºåè®®ï¼Œè¯¥è®¸å¯è¯æœ¬è´¨ä¸Šæ˜¯ GPLv3ï¼Œä½†æœ‰ä¸€äº›é¢å¤–çš„é™åˆ¶ã€‚\n\nä½ å¯ä»¥åŸºäº SQLBot çš„æºä»£ç è¿›è¡ŒäºŒæ¬¡å¼€å‘ï¼Œä½†æ˜¯éœ€è¦éµå®ˆä»¥ä¸‹è§„å®šï¼š\n\n- ä¸èƒ½æ›¿æ¢å’Œä¿®æ”¹ SQLBot çš„ Logo å’Œç‰ˆæƒä¿¡æ¯ï¼›\n- äºŒæ¬¡å¼€å‘åçš„è¡ç”Ÿä½œå“å¿…é¡»éµå®ˆ GPL V3 çš„å¼€æºä¹‰åŠ¡ã€‚\n\nå¦‚éœ€å•†ä¸šæˆæƒï¼Œè¯·è”ç³» support@fit2cloud.com ã€‚\n",
      "stars_today": 14
    },
    {
      "id": 6934395,
      "name": "rocksdb",
      "full_name": "facebook/rocksdb",
      "description": "A library that provides an embeddable, persistent key-value store for fast storage.",
      "html_url": "https://github.com/facebook/rocksdb",
      "stars": 31514,
      "forks": 6729,
      "language": "C++",
      "topics": [
        "database",
        "storage-engine"
      ],
      "created_at": "2012-11-30T06:16:18Z",
      "updated_at": "2026-02-06T22:54:51Z",
      "pushed_at": "2026-02-06T21:48:16Z",
      "open_issues": 1404,
      "owner": {
        "login": "facebook",
        "avatar_url": "https://avatars.githubusercontent.com/u/69631?v=4"
      },
      "readme": "## RocksDB: A Persistent Key-Value Store for Flash and RAM Storage\n\n[![CircleCI Status](https://circleci.com/gh/facebook/rocksdb.svg?style=svg)](https://circleci.com/gh/facebook/rocksdb)\n\nRocksDB is developed and maintained by Facebook Database Engineering Team.\nIt is built on earlier work on [LevelDB](https://github.com/google/leveldb) by Sanjay Ghemawat (sanjay@google.com)\nand Jeff Dean (jeff@google.com)\n\nThis code is a library that forms the core building block for a fast\nkey-value server, especially suited for storing data on flash drives.\nIt has a Log-Structured-Merge-Database (LSM) design with flexible tradeoffs\nbetween Write-Amplification-Factor (WAF), Read-Amplification-Factor (RAF)\nand Space-Amplification-Factor (SAF). It has multi-threaded compactions,\nmaking it especially suitable for storing multiple terabytes of data in a\nsingle database.\n\nStart with example usage here: https://github.com/facebook/rocksdb/tree/main/examples\n\nSee the [github wiki](https://github.com/facebook/rocksdb/wiki) for more explanation.\n\nThe public interface is in `include/`.  Callers should not include or\nrely on the details of any other header files in this package.  Those\ninternal APIs may be changed without warning.\n\nQuestions and discussions are welcome on the [RocksDB Developers Public](https://www.facebook.com/groups/rocksdb.dev/) Facebook group and [email list](https://groups.google.com/g/rocksdb) on Google Groups.\n\n## License\n\nRocksDB is dual-licensed under both the GPLv2 (found in the COPYING file in the root directory) and Apache 2.0 License (found in the LICENSE.Apache file in the root directory).  You may select, at your option, one of the above-listed licenses.\n",
      "stars_today": 13
    },
    {
      "id": 29759715,
      "name": "zstd",
      "full_name": "facebook/zstd",
      "description": "Zstandard - Fast real-time compression algorithm",
      "html_url": "https://github.com/facebook/zstd",
      "stars": 26561,
      "forks": 2400,
      "language": "C",
      "topics": [],
      "created_at": "2015-01-24T00:22:38Z",
      "updated_at": "2026-02-06T19:58:57Z",
      "pushed_at": "2026-02-01T05:32:50Z",
      "open_issues": 255,
      "owner": {
        "login": "facebook",
        "avatar_url": "https://avatars.githubusercontent.com/u/69631?v=4"
      },
      "readme": "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/facebook/zstd/dev/doc/images/zstd_logo86.png\" alt=\"Zstandard\"></p>\n\n__Zstandard__, or `zstd` as short version, is a fast lossless compression algorithm,\ntargeting real-time compression scenarios at zlib-level and better compression ratios.\nIt's backed by a very fast entropy stage, provided by [Huff0 and FSE library](https://github.com/Cyan4973/FiniteStateEntropy).\n\nZstandard's format is stable and documented in [RFC8878](https://datatracker.ietf.org/doc/html/rfc8878). Multiple independent implementations are already available.\nThis repository represents the reference implementation, provided as an open-source dual [BSD](LICENSE) OR [GPLv2](COPYING) licensed **C** library,\nand a command line utility producing and decoding `.zst`, `.gz`, `.xz` and `.lz4` files.\nShould your project require another programming language,\na list of known ports and bindings is provided on [Zstandard homepage](https://facebook.github.io/zstd/#other-languages).\n\n**Development branch status:**\n\n[![Build Status][travisDevBadge]][travisLink]\n[![Build status][CircleDevBadge]][CircleLink]\n[![Build status][CirrusDevBadge]][CirrusLink]\n[![Fuzzing Status][OSSFuzzBadge]][OSSFuzzLink]\n\n[travisDevBadge]: https://api.travis-ci.com/facebook/zstd.svg?branch=dev \"Continuous Integration test suite\"\n[travisLink]: https://travis-ci.com/facebook/zstd\n[CircleDevBadge]: https://circleci.com/gh/facebook/zstd/tree/dev.svg?style=shield \"Short test suite\"\n[CircleLink]: https://circleci.com/gh/facebook/zstd\n[CirrusDevBadge]: https://api.cirrus-ci.com/github/facebook/zstd.svg?branch=dev\n[CirrusLink]: https://cirrus-ci.com/github/facebook/zstd\n[OSSFuzzBadge]: https://oss-fuzz-build-logs.storage.googleapis.com/badges/zstd.svg\n[OSSFuzzLink]: https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:zstd\n\n## Benchmarks\n\nFor reference, several fast compression algorithms were tested and compared\non a desktop featuring a Core i7-9700K CPU @ 4.9GHz\nand running Ubuntu 24.04 (`Linux 6.8.0-53-generic`),\nusing [lzbench], an open-source in-memory benchmark by @inikep\ncompiled with [gcc] 14.2.0,\non the [Silesia compression corpus].\n\n[lzbench]: https://github.com/inikep/lzbench\n[Silesia compression corpus]: https://sun.aei.polsl.pl//~sdeor/index.php?page=silesia\n[gcc]: https://gcc.gnu.org/\n\n| Compressor name         | Ratio | Compression| Decompress.|\n| ---------------         | ------| -----------| ---------- |\n| **zstd 1.5.7 -1**       | 2.896 |   510 MB/s |  1550 MB/s |\n| brotli 1.1.0 -1         | 2.883 |   290 MB/s |   425 MB/s |\n| [zlib] 1.3.1 -1         | 2.743 |   105 MB/s |   390 MB/s |\n| **zstd 1.5.7 --fast=1** | 2.439 |   545 MB/s |  1850 MB/s |\n| quicklz 1.5.0 -1        | 2.238 |   520 MB/s |   750 MB/s |\n| **zstd 1.5.7 --fast=4** | 2.146 |   665 MB/s |  2050 MB/s |\n| lzo1x 2.10 -1           | 2.106 |   650 MB/s |   780 MB/s |\n| [lz4] 1.10.0            | 2.101 |   675 MB/s |  3850 MB/s |\n| snappy 1.2.1            | 2.089 |   520 MB/s |  1500 MB/s |\n| lzf 3.6 -1              | 2.077 |   410 MB/s |   820 MB/s |\n\n[zlib]: https://www.zlib.net/\n[lz4]: https://lz4.github.io/lz4/\n\nThe negative compression levels, specified with `--fast=#`,\noffer faster compression and decompression speed\nat the cost of compression ratio.\n\nZstd can also offer stronger compression ratios at the cost of compression speed.\nSpeed vs Compression trade-off is configurable by small increments.\nDecompression speed is preserved and remains roughly the same at all settings,\na property shared by most LZ compression algorithms, such as [zlib] or lzma.\n\nThe following tests were run\non a server running Linux Debian (`Linux version 4.14.0-3-amd64`)\nwith a Core i7-6700K CPU @ 4.0GHz,\nusing [lzbench], an open-source in-memory benchmark by @inikep\ncompiled with [gcc] 7.3.0,\non the [Silesia compression corpus].\n\nCompression Speed vs Ratio | Decompression Speed\n---------------------------|--------------------\n![Compression Speed vs Ratio](doc/images/CSpeed2.png \"Compression Speed vs Ratio\") | ![Decompression Speed](doc/images/DSpeed3.png \"Decompression Speed\")\n\nA few other algorithms can produce higher compression ratios at slower speeds, falling outside of the graph.\nFor a larger picture including slow modes, [click on this link](doc/images/DCspeed5.png).\n\n\n## The case for Small Data compression\n\nPrevious charts provide results applicable to typical file and stream scenarios (several MB). Small data comes with different perspectives.\n\nThe smaller the amount of data to compress, the more difficult it is to compress. This problem is common to all compression algorithms, and reason is, compression algorithms learn from past data how to compress future data. But at the beginning of a new data set, there is no \"past\" to build upon.\n\nTo solve this situation, Zstd offers a __training mode__, which can be used to tune the algorithm for a selected type of data.\nTraining Zstandard is achieved by providing it with a few samples (one file per sample). The result of this training is stored in a file called \"dictionary\", which must be loaded before compression and decompression.\nUsing this dictionary, the compression ratio achievable on small data improves dramatically.\n\nThe following example uses the `github-users` [sample set](https://github.com/facebook/zstd/releases/tag/v1.1.3), created from [github public API](https://developer.github.com/v3/users/#get-all-users).\nIt consists of roughly 10K records weighing about 1KB each.\n\nCompression Ratio | Compression Speed | Decompression Speed\n------------------|-------------------|--------------------\n![Compression Ratio](doc/images/dict-cr.png \"Compression Ratio\") | ![Compression Speed](doc/images/dict-cs.png \"Compression Speed\") | ![Decompression Speed](doc/images/dict-ds.png \"Decompression Speed\")\n\n\nThese compression gains are achieved while simultaneously providing _faster_ compression and decompression speeds.\n\nTraining works if there is some correlation in a family of small data samples. The more data-specific a dictionary is, the more efficient it is (there is no _universal dictionary_).\nHence, deploying one dictionary per type of data will provide the greatest benefits.\nDictionary gains are mostly effective in the first few KB. Then, the compression algorithm will gradually use previously decoded content to better compress the rest of the file.\n\n### Dictionary compression How To:\n\n1. Create the dictionary\n\n   `zstd --train FullPathToTrainingSet/* -o dictionaryName`\n\n2. Compress with dictionary\n\n   `zstd -D dictionaryName FILE`\n\n3. Decompress with dictionary\n\n   `zstd -D dictionaryName --decompress FILE.zst`\n\n\n## Build instructions\n\n`make` is the main build system of this project.\nIt is the reference, and other build systems are periodically updated to stay compatible.\nHowever, small drifts and feature differences can be present, since perfect synchronization is difficult.\nFor this reason, when your build system allows it, prefer employing `make`.\n\n### Makefile\n\nAssuming your system supports standard `make` (or `gmake`),\njust invoking `make` in root directory generates `zstd` cli at root,\nand also generates `libzstd` into `lib/`.\n\nOther standard targets include:\n- `make install` : install zstd cli, library and man pages\n- `make check` : run `zstd`, test its essential behavior on local platform\n\nThe `Makefile` follows the [GNU Standard Makefile conventions](https://www.gnu.org/prep/standards/html_node/Makefile-Conventions.html),\nallowing staged install, standard compilation flags, directory variables and command variables.\n\nFor advanced use cases, specialized flags which control binary generation and installation paths are documented\nin [`lib/README.md`](lib/README.md#modular-build) for the `libzstd` library\nand in [`programs/README.md`](programs/README.md#compilation-variables) for the `zstd` CLI.\n\n### cmake\n\nA `cmake` project generator is available for generating Makefiles or other build scripts\nto create the `zstd` binary as well as `libzstd` dynamic and static libraries.\nThe repository root now contains a minimal `CMakeLists.txt` that forwards to `build/cmake`,\nso you can configure the project with a standard `cmake -S .` invocation,\nwhile the historical `cmake -S build/cmake` entry point remains fully supported.\n\n```bash\ncmake -S . -B build-cmake\ncmake --build build-cmake\n```\n\nBy default, `CMAKE_BUILD_TYPE` is set to `Release`.\n\n#### Support for Fat (Universal2) Output\n\n`zstd` can be built and installed with support for both Apple Silicon (M1/M2) as well as Intel by using CMake's Universal2 support.\nTo perform a Fat/Universal2 build and install use the following commands:\n\n```bash\ncmake -S . -B build-cmake-debug -G Ninja -DCMAKE_OSX_ARCHITECTURES=\"x86_64;x86_64h;arm64\"\ncd build-cmake-debug\nninja\nsudo ninja install\n```\n\n### Meson\n\nA Meson project is provided within [`build/meson`](build/meson). Follow\nbuild instructions in that directory.\n\nYou can also take a look at [`.travis.yml`](.travis.yml) file for an\nexample about how Meson is used to build this project.\n\nNote that default build type is **release**.\n\n### VCPKG\nYou can build and install zstd [vcpkg](https://github.com/Microsoft/vcpkg/) dependency manager:\n\n    git clone https://github.com/Microsoft/vcpkg.git\n    cd vcpkg\n    ./bootstrap-vcpkg.sh\n    ./vcpkg integrate install\n    ./vcpkg install zstd\n\nThe zstd port in vcpkg is kept up to date by Microsoft team members and community contributors.\nIf the version is out of date, please [create an issue or pull request](https://github.com/Microsoft/vcpkg) on the vcpkg repository.\n\n### Conan\n\nYou can install pre-built binaries for zstd or build it from source using [Conan](https://conan.io/). Use the following command:\n\n```bash\nconan install --requires=\"zstd/[*]\" --build=missing\n```\n\nThe zstd Conan recipe is kept up to date by Conan maintainers and community contributors.\nIf the version is out of date, please [create an issue or pull request](https://github.com/conan-io/conan-center-index) on the ConanCenterIndex repository.\n\n### Visual Studio (Windows)\n\nGoing into `build` directory, you will find additional possibilities:\n- Projects for Visual Studio 2008 and 2010.\n  + VS2010 project is compatible with VS2012, VS2013, VS2015 and VS2017.\n- Automated build scripts for Visual compiler by [@KrzysFR](https://github.com/KrzysFR), in `build/VS_scripts`,\n  which will build `zstd` cli and `libzstd` library without any need to open Visual Studio solution.\n- It is now recommended to generate Visual Studio solutions from `cmake`\n\n### Buck\n\nYou can build the zstd binary via buck by executing: `buck build programs:zstd` from the root of the repo.\nThe output binary will be in `buck-out/gen/programs/`.\n\n### Bazel\n\nYou can integrate zstd into your Bazel project by using the module hosted on the [Bazel Central Repository](https://registry.bazel.build/modules/zstd).\n\n## Testing\n\nYou can run quick local smoke tests by running `make check`.\nIf you can't use `make`, execute the `playTest.sh` script from the `src/tests` directory.\nTwo env variables `$ZSTD_BIN` and `$DATAGEN_BIN` are needed for the test script to locate the `zstd` and `datagen` binary.\nFor information on CI testing, please refer to `TESTING.md`.\n\n## Status\n\nZstandard is deployed within Meta and many other large cloud infrastructures,\nto compress humongous amounts of data in various formats and use cases.\nIt is also continuously fuzzed for security issues by Google's [oss-fuzz](https://github.com/google/oss-fuzz/tree/master/projects/zstd) program.\n\n## License\n\nZstandard is dual-licensed under [BSD](LICENSE) OR [GPLv2](COPYING).\n\n## Contributing\n\nThe `dev` branch is the one where all contributions are merged before reaching `release`.\nDirect commit to `release` are not permitted.\nFor more information, please read [CONTRIBUTING](CONTRIBUTING.md).\n",
      "stars_today": 13
    },
    {
      "id": 75255555,
      "name": "requestly",
      "full_name": "requestly/requestly",
      "description": "Free and open-source API Client & Interceptor.",
      "html_url": "https://github.com/requestly/requestly",
      "stars": 6211,
      "forks": 569,
      "language": "TypeScript",
      "topics": [
        "api",
        "api-client",
        "api-mock",
        "api-rest",
        "api-testing",
        "bruno",
        "bruno-alternative",
        "charles-proxy",
        "chrome-extension",
        "fiddler",
        "firefox-extension",
        "hacktoberfest",
        "http-interceptor",
        "insomnia",
        "mock-server",
        "open-source",
        "postman",
        "postman-api",
        "postman-collection",
        "postman-environment"
      ],
      "created_at": "2016-12-01T04:36:06Z",
      "updated_at": "2026-02-07T02:17:20Z",
      "pushed_at": "2026-02-06T11:59:42Z",
      "open_issues": 317,
      "owner": {
        "login": "requestly",
        "avatar_url": "https://avatars.githubusercontent.com/u/12287519?v=4"
      },
      "readme": "[![Requestly](https://github.com/user-attachments/assets/5b8cdaf9-22d6-4aa5-844c-93d70ece41ad)](https://requestly.com)\n\nJoin Requestly community on Discord: [Link](https://rqst.ly/join-community)\n\n\n## Requestly - API Client with HTTP Interceptor, Modfications, Testing & Mocking.\n\nRequestly is a powerful combination of a local API Client (like Postman) & HTTP Interceptor (like Charles Proxy) with API Testing and Mocking. Requestly can be used directly in the browser as a Chrome Extension or installed as a desktop application.\n\n\n#### âš¡ A Local-first & Powerful alternative to Postman & Charles Proxy âš¡\n![requestly-overview](https://github.com/user-attachments/assets/04c32f25-96c4-46d9-a31d-b6887ce7bfdc)\n<br/>\n\n![GitHub closed issues](https://img.shields.io/github/issues-closed/requestly/requestly)     [![Chrome Web Store Rating](https://img.shields.io/chrome-web-store/rating/mdnleldcmiljblolnjhpnblkcekpdkpa) ![Chrome Web Store Reviews](https://img.shields.io/chrome-web-store/rating-count/mdnleldcmiljblolnjhpnblkcekpdkpa?label=reviews) ![Chrome Web Store Downloads](https://img.shields.io/chrome-web-store/users/mdnleldcmiljblolnjhpnblkcekpdkpa?label=downloads)](https://chrome.google.com/webstore/detail/redirect-url-modify-heade/mdnleldcmiljblolnjhpnblkcekpdkpa/) [![Status badge](https://uptime.betterstack.com/status-badges/v2/monitor/13j20.svg)](https://status.requestly.io)\n\n<br/>\n<br/>\n\n## ğŸ¡ Getting Started\n\n*   [A Local-first Solution](#a-local-first-solution-local-workspaces)\n*   [REST API Client](#rest-api-client)\n*   [Environments](#environments)\n*   [HTTP Interceptor - Intercept & Modify HTTP Requests](#http-interceptor--http-rules-intercept--modify-https-requests)\n*   [API Mocking](#api-mocking-helps-in-building-frontend-faster-without-waiting-for-backend)\n*   [1-Click Imports from Postman, Insomnia, Modheader, Charles Proxy, and Resource Override](#1-click-imports)\n*   [Support Channels](#-best-in-class-support)\n*   [ğŸ‘©â€ğŸ’» Development](#-development)\n*   [ğŸ™ Contributing](#-contributing)\n\n<br/>\n<br/>\n\n## A Local-first Solution (Local Workspaces)\n\n**Local Workspaces** is a simple, powerful, and privacy-friendly approach to building, testing & mocking your APIs. All your data is stored in the selected directory on your disk. You can also import all your API client files (requests, collections, environments) and codebase into VSCode and edit them directly in your IDE.\n\nCollaborate with your colleagues using your preferred sync engine - Git, Google Drive, iCloud, or nothing at all.\n\n**Team Workspaces** are great for seamless collaboration through Requestly sync engine.\n\n\n#### âš¡ Local and team workspacesâš¡\n\n![requestly-local-first-support](https://github.com/user-attachments/assets/06f17e34-1614-4396-95ee-1416003261ad)\n\n<br/>\n<br/>\n\n## REST API Client\n\n[**Rest API Client**](https://docs.requestly.com/general/api-client/overview) offers a local API playground to build and test your APIs. It supports features like API Collections, Environments, Environment Switcher, API Requests History with a beautiful and collaborative interface.\n\n#### âš¡ A Local-first, Beautiful & Powerful alternative to Postman & Insomina âš¡\n\n![requestly-api-client](https://github.com/user-attachments/assets/a962b213-8744-4ffc-bd04-fcf891f48914)\n\n<br/>\n<br/>\n\n## Environments\n\n**Environment** is a set of key-value pairs that can be used in API requests. Environments feature lets you manage variables across multiple environments with an easy environment selector. We support Global variables as well as Collection level variables. [Docs](https://docs.requestly.com/general/api-client/environments-and-variables)\n\n#### âš¡ Environments feature âš¡\n\n![requestly-api-client-environments-support](https://github.com/user-attachments/assets/2726fe0e-9f0a-4df7-bfc9-344c65e19353)\n\n<br/>\n<br/>\n\n## HTTP Interceptor / HTTP Rules (Intercept & Modify HTTPs Requests)\n\n[**HTTP Rules**](https://docs.requestly.com/general/http-interceptor/overview) feature can be used to **Intercept, Monitor & Modify HTTPs requests & responses** from browsers & mobile apps.\n\n*   Use the Chrome/Firefox/Edge extension for Intercepting & Modifying traffic from browsers\n*   Use the desktop app for capturing & modifying traffic from browsers, mobile apps & other desktop apps.\n    \n\n#### âš¡ Intercept, Monitor & Modify HTTP Requests & Responses âš¡\n\n![requestly-http-interceptor](https://github.com/user-attachments/assets/791e54cb-d817-4bc2-83a6-e8bdd3b1cef7)\n\n<br/>\n<br/>\n\n**Different Modifications supported**\n\n*   Redirect URLs (Map Local & Map Remote) e.g.\n    *   Change Hostname, QueryParams, etc in the URL\n    *   Redirect traffic from one environment to another (e.g. production to dev)\n    *   Swap Tag Manager scripts from production to staging/dev environment\n*   Modify HTTP Request & Response Headers\n*   Modify API Request & Response body\n*   Inject scripts on web pages\n\n<br/>\n<br/>\n\n## API Mocking (Helps in building frontend faster without waiting for backend)\n\nRequestly offers a complete API Mocking solution. Using Requestly, you can\n\n*   [Create Local API Mocks](https://docs.requestly.com/general/api-mocking/api-mocking): Intercept the API Requests and return the new response\n*   [Static & Dynamic Response Overrides](https://docs.requestly.com/general/http-rules/rule-types/modify-response-body): Override the API response received from server dynamically using simple JS\n*   [GraphQL Support](https://docs.requestly.com/general/http-rules/advanced-usage/graphql-modify-request-response): Override graphQL APIs by targeting on query, operationName\n*   [Create Cloud-based API Mocks](https://docs.requestly.com/general/api-mocking/create-cloud-based-mocks): Create cloud-based API Mocks and get new endpoints for the mocks\n*   [Bulk API Mocks](https://docs.requestly.com/general/sessions/record-api-sessions#bulk-mocking): Record API traffic & Serve the Mocks from the recorded Session\n*   Mock APIs in e2e testing: Use Requestly in your e2e Cypress/Playwright/Selenium and mock the APIs in CI pipeline\n    \n\n#### âš¡ API Mocks - Build & Test your frontend faster without waiting for backend âš¡\n\n![requestly-api-mocking](https://github.com/user-attachments/assets/7bc00c7e-c280-40eb-9a2a-c070ecdea662)\n\n<br/>\n<br/>\n\n## 1-Click Imports\n\nRequestly provides **Importing Configuration** from the following tools\n\nAPI Clients\n\n*   [Import from Postman](https://docs.requestly.com/general/imports/postman)\n*   [Import from Insomnia](#) - Coming Soon\n*   [Import from Bruno](#) - Coming Soon\n\nHTTP Interceptors\n\n*   [Import from Charles Proxy](https://docs.requestly.com/general/imports/charles-proxy)\n*   [Import from Resource Override](https://docs.requestly.com/general/imports/resource-override)\n*   [Import from ModHeader](https://docs.requestly.com/general/imports/modheader)\n\n#### âš¡ Import from Postman, Insomnia, CharlesProxy, ModHeader, etc. âš¡\n![requestly-api-client-environments-support](https://github.com/user-attachments/assets/6186e916-9036-4847-95dd-53b66a4c2730)\n\n<br/>\n<br/>\n\n## ğŸ¤ Best In-Class Support\n\n#### âš¡ Requestly is known for best product, team and Best in-class support (4.3â­ï¸ in 1000+ reviews) âš¡\n\n*   [Documentation](https://docs.requestly.com/): Product Documentation and Understanding of different features\n*   [Security & Privacy](https://docs.requestly.com/security-privacy/): Our Security & Privacy document\n*   [Email contact@requestly.com](mailto:contact@requestly.com): Email Support\n*   [StackOverflow Questions](https://stackoverflow.com/questions/tagged/requestly): Ask Questions on StackOverflow and add \"Requestly\" tag\n\n<br/>\n<br/>\n\n## ğŸ‘©â€ğŸ’» Development\n\nThis repository contains the source code for Browser extension and UI application which make up the core of Requestly.  \nPlease follow the [Getting Started Guide](./getting-started.md) to get to know about the development process in this repository.\n\nStart working on individual modules:\n\n*   [Browser extension](./browser-extension)\n*   [UI application](./app)\n*   [Desktop application](https://github.com/requestly/requestly-desktop-app) (Electron-based application for MacOS, Windows)\n*   [Web SDK](https://github.com/requestly/requestly-web-sdk) (facilitates SessionBook)\n*   [Mock Server](https://github.com/requestly/requestly-mock-server)\n*   [Backend](https://github.com/requestly/requestly-backend)\n\n<br/>\n<br/>\n\n## ğŸ™ Contributing\n\nWe welcome contributions from the community! Whether you're fixing bugs, adding new features, or improving documentation, your contributions help make Requestly better for everyone.\n\n**Getting Started:**\n\n- Check out our [issues](https://github.com/requestly/requestly/issues) to find something to work on\n- Read our [contributing guide](./CONTRIBUTING.md) to learn about our development process and guidelines\n- Join our [Discord community](https://rqst.ly/join-community) if you need help or have questions",
      "stars_today": 13
    },
    {
      "id": 75277003,
      "name": "thingsboard",
      "full_name": "thingsboard/thingsboard",
      "description": "Open-source IoT Platform - Device management, data collection, processing and visualization.",
      "html_url": "https://github.com/thingsboard/thingsboard",
      "stars": 21086,
      "forks": 6109,
      "language": "Java",
      "topics": [
        "big-data",
        "cloud",
        "coap-server",
        "dashboards",
        "http",
        "iiot",
        "iot",
        "iot-analytics",
        "iot-framework",
        "iot-platform",
        "iot-solutions",
        "lwm2m-server",
        "microservices",
        "middleware",
        "mqtt",
        "snmp",
        "thingsboard",
        "visualization"
      ],
      "created_at": "2016-12-01T09:33:30Z",
      "updated_at": "2026-02-06T23:22:36Z",
      "pushed_at": "2026-02-06T16:37:30Z",
      "open_issues": 178,
      "owner": {
        "login": "thingsboard",
        "avatar_url": "https://avatars.githubusercontent.com/u/24291394?v=4"
      },
      "readme": "![banner](https://github.com/user-attachments/assets/3584b592-33dd-4fb4-91d4-47b62b34806c)\n\n<div align=\"center\">\n\n# Open-source IoT platform for data collection, processing, visualization, and device management.\n\n</div>\n<br>\n<div align=\"center\">\n \nğŸ’¡ [Get started](https://thingsboard.io/docs/getting-started-guides/helloworld/)&ensp;â€¢&ensp;ğŸŒ [Website](https://thingsboard.io/)&ensp;â€¢&ensp;ğŸ“š [Documentation](https://thingsboard.io/docs/)&ensp;â€¢&ensp;ğŸ“” [Blog](https://thingsboard.io/blog/)&ensp;â€¢&ensp;ğŸ”— [LinkedIn](https://www.linkedin.com/company/thingsboard/posts/?feedView=all)\n\n</div>\n\n## ğŸš€ Installation options\n\nInstall ThingsBoard [on-premises](https://thingsboard.io/docs/user-guide/install/installation-options/?ceInstallType=onPremise) or use [ThingsBoard Cloud](https://thingsboard.io/installations/).\n\n## ğŸ’¡ Getting started with ThingsBoard\n\nCheck out our [Getting Started guide](https://thingsboard.io/docs/getting-started-guides/helloworld/) or [watch the video](https://www.youtube.com/watch?v=80L0ubQLXsc) to learn the basics of ThingsBoard and create your first dashboard! You will learn to:\n\n* Connect devices to ThingsBoard\n* Push data from devices to ThingsBoard\n* Build real-time dashboards\n* Create a Customer and assign the dashboard with them.\n* Define thresholds and trigger alarms\n* Set up notifications via email, SMS, mobile apps, or integrate with third-party services.\n\n## âœ¨ Features\n\n<table>\n  <tr>\n    <td width=\"50%\" valign=\"top\">\n      <br>\n      <div align=\"center\">\n        <img src=\"https://github.com/user-attachments/assets/255cca4f-b111-44e8-99ea-0af55f8e3681\" alt=\"Provision and manage devices and assets\" width=\"378\" />\n        <h3>Provision and manage <br> devices and assets</h3>\n      </div>\n      <div align=\"center\">\n        <p>Provision, monitor and control your IoT entities in secure way using rich server-side APIs. Define relations between your devices, assets, customers or any other entities.</p>\n      </div>\n      <br>\n      <div align=\"center\">\n        <a href=\"https://thingsboard.io/docs/user-guide/entities-and-relations/\">Read more âœ</a>\n      </div>\n      <br>\n    </td>\n    <td width=\"50%\" valign=\"top\">\n      <br>\n      <div align=\"center\">\n        <img src=\"https://github.com/user-attachments/assets/24b41d10-150a-42dd-ab1a-32ac9b5978c1\" alt=\"Collect and visualize your data\" width=\"378\" />\n        <h3>Collect and visualize <br> your data</h3>\n      </div>\n      <div align=\"center\">\n        <p>Collect and store telemetry data in scalable and fault-tolerant way. Visualize your data with built-in or custom widgets and flexible dashboards. Share dashboards with your customers.</p>\n      </div>\n      <br>\n      <div align=\"center\">\n        <a href=\"https://thingsboard.io/iot-data-visualization/\">Read more âœ</a>\n      </div>\n      <br>\n    </td>\n  </tr>\n  <tr>\n    <td width=\"50%\" valign=\"top\">\n      <br>\n      <div align=\"center\">\n        <img src=\"https://github.com/user-attachments/assets/6f2a6dd2-7b33-4d17-8b92-d1f995adda2c\" alt=\"SCADA Dashboards\" width=\"378\" />\n        <h3>SCADA Dashboards</h3>\n      </div>\n      <div align=\"center\">\n        <p>Monitor and control your industrial processes in real time with SCADA. Use SCADA symbols on dashboards to create and manage any workflow, offering full flexibility to design and oversee operations according to your requirements.</p>\n      </div>\n      <br>\n      <div align=\"center\">\n        <a href=\"https://thingsboard.io/use-cases/scada/\">Read more âœ</a>\n      </div>\n      <br>\n    </td>\n    <td width=\"50%\" valign=\"top\">\n      <br>\n      <div align=\"center\">\n        <img src=\"https://github.com/user-attachments/assets/c23dcc9b-aeba-40ef-9973-49b953fc1257\" alt=\"Process and React\" width=\"378\" />\n        <h3>Process and React</h3>\n      </div>\n      <div align=\"center\">\n        <p>Define data processing rule chains. Transform and normalize your device data. Raise alarms on incoming telemetry events, attribute updates, device inactivity and user actions.<br></p>\n      </div>\n      <br>\n      <br>\n      <div align=\"center\">\n        <a href=\"https://thingsboard.io/docs/user-guide/rule-engine-2-0/re-getting-started/\">Read more âœ</a>\n      </div>\n      <br>\n    </td>\n  </tr>\n</table>\n\n## âš™ï¸ Powerful IoT Rule Engine\n\nThingsBoard allows you to create complex [Rule Chains](https://thingsboard.io/docs/user-guide/rule-engine-2-0/re-getting-started/) to process data from your devices and match your application specific use cases.\n\n[![IoT Rule Engine](https://github.com/user-attachments/assets/43d21dc9-0e18-4f1b-8f9a-b72004e12f07 \"IoT Rule Engine\")](https://thingsboard.io/docs/user-guide/rule-engine-2-0/re-getting-started/)\n\n<div align=\"center\">\n\n[**Read more about Rule Engine âœ**](https://thingsboard.io/docs/user-guide/rule-engine-2-0/re-getting-started/)\n\n</div>\n\n## ğŸ“¦ Real-Time IoT Dashboards\n\nThingsBoard is a scalable, user-friendly, and device-agnostic IoT platform that speeds up time-to-market with powerful built-in solution templates. It enables data collection and analysis from any devices, saving resources on routine tasks and letting you focus on your solutionâ€™s unique aspects. See more our Use Cases [here](https://thingsboard.io/iot-use-cases/).\n\n[**Smart energy**](https://thingsboard.io/use-cases/smart-energy/)\n\n[![Smart energy](https://github.com/user-attachments/assets/2a0abf13-6dc5-4f5e-9c30-1aea1d39af1e \"Smart energy\")](https://thingsboard.io/use-cases/smart-energy/)\n\n[**SCADA swimming pool**](https://thingsboard.io/use-cases/scada/)\n\n[![SCADA Swimming pool](https://github.com/user-attachments/assets/68fd9e29-99f1-4c16-8c4c-476f4ccb20c0 \"SCADA Swimming pool\")](https://thingsboard.io/use-cases/scada/)\n\n[**Site fleet tracking**](https://thingsboard.io/use-cases/site-fleet-tracking/)\n\n[![Site fleet tracking](https://github.com/user-attachments/assets/d6ce0766-b138-4a42-86aa-7112a543026c \"Site fleet tracking\")](https://thingsboard.io/use-cases/site-fleet-tracking/)\n\n[**Smart farming**](https://thingsboard.io/use-cases/smart-farming/)\n\n[![Smart farming](https://github.com/user-attachments/assets/56b84c99-ef24-44e5-a903-b925b7f9d142 \"Smart farming\")](https://thingsboard.io/use-cases/smart-farming/)\n\n[**Smart metering**](https://thingsboard.io/smart-metering/)\n\n[![Smart metering](https://github.com/user-attachments/assets/adc05e3d-397c-48ef-bed6-535bbd698455 \"Smart metering\")](https://thingsboard.io/smart-metering/)\n\n<div align=\"center\">\n\n[**Check more of our use cases âœ**](https://thingsboard.io/iot-use-cases/)\n\n</div>\n\n## ğŸ«¶ Support\n\nTo get support, please visit our [GitHub issues page](https://github.com/thingsboard/thingsboard/issues)\n\n## ğŸ“„ Licenses\n\nThis project is released under [Apache 2.0 License](./LICENSE)\n",
      "stars_today": 12
    },
    {
      "id": 724854743,
      "name": "mlx",
      "full_name": "ml-explore/mlx",
      "description": "MLX: An array framework for Apple silicon",
      "html_url": "https://github.com/ml-explore/mlx",
      "stars": 23817,
      "forks": 1493,
      "language": "C++",
      "topics": [
        "mlx"
      ],
      "created_at": "2023-11-28T23:33:45Z",
      "updated_at": "2026-02-07T01:40:12Z",
      "pushed_at": "2026-02-07T00:38:37Z",
      "open_issues": 157,
      "owner": {
        "login": "ml-explore",
        "avatar_url": "https://avatars.githubusercontent.com/u/102832242?v=4"
      },
      "readme": "# MLX\n\n[**Quickstart**](#quickstart) | [**Installation**](#installation) |\n[**Documentation**](https://ml-explore.github.io/mlx/build/html/index.html) |\n[**Examples**](#examples)\n\n[![CircleCI](https://circleci.com/gh/ml-explore/mlx.svg?style=svg)](https://circleci.com/gh/ml-explore/mlx)\n\nMLX is an array framework for machine learning on Apple silicon,\nbrought to you by Apple machine learning research.\n\nSome key features of MLX include:\n\n- **Familiar APIs**: MLX has a Python API that closely follows NumPy. MLX\n   also has fully featured C++, [C](https://github.com/ml-explore/mlx-c), and\n   [Swift](https://github.com/ml-explore/mlx-swift/) APIs, which closely mirror\n   the Python API. MLX has higher-level packages like `mlx.nn` and\n   `mlx.optimizers` with APIs that closely follow PyTorch to simplify building\n   more complex models.\n\n- **Composable function transformations**: MLX supports composable function\n  transformations for automatic differentiation, automatic vectorization,\n  and computation graph optimization.\n\n- **Lazy computation**: Computations in MLX are lazy. Arrays are only\n  materialized when needed.\n\n- **Dynamic graph construction**: Computation graphs in MLX are constructed\n  dynamically. Changing the shapes of function arguments does not trigger\n  slow compilations, and debugging is simple and intuitive.\n\n- **Multi-device**: Operations can run on any of the supported devices\n  (currently the CPU and the GPU).\n\n- **Unified memory**: A notable difference from MLX and other frameworks\n  is the *unified memory model*. Arrays in MLX live in shared memory.\n  Operations on MLX arrays can be performed on any of the supported\n  device types without transferring data.\n\nMLX is designed by machine learning researchers for machine learning\nresearchers. The framework is intended to be user-friendly, but still efficient\nto train and deploy models. The design of the framework itself is also\nconceptually simple. We intend to make it easy for researchers to extend and\nimprove MLX with the goal of quickly exploring new ideas.\n\nThe design of MLX is inspired by frameworks like\n[NumPy](https://numpy.org/doc/stable/index.html),\n[PyTorch](https://pytorch.org/), [Jax](https://github.com/google/jax), and\n[ArrayFire](https://arrayfire.org/).\n\n## Examples\n\nThe [MLX examples repo](https://github.com/ml-explore/mlx-examples) has a\nvariety of examples, including:\n\n- [Transformer language model](https://github.com/ml-explore/mlx-examples/tree/main/transformer_lm) training.\n- Large-scale text generation with\n  [LLaMA](https://github.com/ml-explore/mlx-examples/tree/main/llms/llama) and\n  finetuning with [LoRA](https://github.com/ml-explore/mlx-examples/tree/main/lora).\n- Generating images with [Stable Diffusion](https://github.com/ml-explore/mlx-examples/tree/main/stable_diffusion).\n- Speech recognition with [OpenAI's Whisper](https://github.com/ml-explore/mlx-examples/tree/main/whisper).\n\n## Quickstart\n\nSee the [quick start\nguide](https://ml-explore.github.io/mlx/build/html/usage/quick_start.html)\nin the documentation.\n\n## Installation\n\nMLX is available on [PyPI](https://pypi.org/project/mlx/). To install MLX on\nmacOS, run:\n\n```bash\npip install mlx\n```\n\nTo install the CUDA backend on Linux, run:\n\n```bash\npip install mlx[cuda]\n```\n\nTo install a CPU-only Linux package, run:\n\n```bash\npip install mlx[cpu]\n```\n\nCheckout the\n[documentation](https://ml-explore.github.io/mlx/build/html/install.html#)\nfor more information on building the C++ and Python APIs from source.\n\n## Contributing\n\nCheck out the [contribution guidelines](https://github.com/ml-explore/mlx/tree/main/CONTRIBUTING.md) for more information\non contributing to MLX. See the\n[docs](https://ml-explore.github.io/mlx/build/html/install.html) for more\ninformation on building from source, and running tests.\n\nWe are grateful for all of [our\ncontributors](https://github.com/ml-explore/mlx/tree/main/ACKNOWLEDGMENTS.md#Individual-Contributors). If you contribute\nto MLX and wish to be acknowledged, please add your name to the list in your\npull request.\n\n## Citing MLX\n\nThe MLX software suite was initially developed with equal contribution by Awni\nHannun, Jagrit Digani, Angelos Katharopoulos, and Ronan Collobert. If you find\nMLX useful in your research and wish to cite it, please use the following\nBibTex entry:\n\n```text\n@software{mlx2023,\n  author = {Awni Hannun and Jagrit Digani and Angelos Katharopoulos and Ronan Collobert},\n  title = {{MLX}: Efficient and flexible machine learning on Apple silicon},\n  url = {https://github.com/ml-explore},\n  version = {0.0},\n  year = {2023},\n}\n```\n",
      "stars_today": 12
    },
    {
      "id": 854337508,
      "name": "spring-ai-alibaba",
      "full_name": "alibaba/spring-ai-alibaba",
      "description": "Agentic AI Framework for Java Developers",
      "html_url": "https://github.com/alibaba/spring-ai-alibaba",
      "stars": 8300,
      "forks": 1823,
      "language": "Java",
      "topics": [
        "agentic",
        "artificial-intelligence",
        "context-engineering",
        "graph",
        "java",
        "multi-agent",
        "reactagent",
        "spring-ai",
        "workflow"
      ],
      "created_at": "2024-09-09T01:35:50Z",
      "updated_at": "2026-02-07T01:18:34Z",
      "pushed_at": "2026-02-06T16:12:02Z",
      "open_issues": 347,
      "owner": {
        "login": "alibaba",
        "avatar_url": "https://avatars.githubusercontent.com/u/1961952?v=4"
      },
      "readme": "# [Spring AI Alibaba](https://java2ai.com)\n\n[![License](https://img.shields.io/badge/license-Apache%202-4EB1BA.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)\n[![CI Status](https://github.com/alibaba/spring-ai-alibaba/workflows/%F0%9F%9B%A0%EF%B8%8F%20Build%20and%20Test/badge.svg)](https://github.com/alibaba/spring-ai-alibaba/actions?query=workflow%3A%22%F0%9F%9B%A0%EF%B8%8F+Build+and+Test%22)\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/alibaba/spring-ai-alibaba)\n[![Maven central](https://img.shields.io/maven-central/v/com.alibaba.cloud.ai/spring-ai-alibaba.svg)](https://img.shields.io/maven-central/v/com.alibaba.cloud.ai/spring-ai-alibaba)\n<img alt=\"gitleaks badge\" src=\"https://img.shields.io/badge/protected%20by-gitleaks-blue\">\n\n<html>\n    <h3 align=\"center\">\n      A production-ready framework for building Agentic, Workflow, and Multi-agent applications.\n    </h3>\n    <h3 align=\"center\">\n      <a href=\"https://java2ai.com/docs/quick-start/\" target=\"_blank\">Agent Framework Docs</a>,\n      <a href=\"https://java2ai.com/docs/frameworks/graph-core/quick-start/\" target=\"_blank\">Graph Docs</a>,\n      <a href=\"https://java2ai.com/ecosystem/spring-ai/reference/concepts/\" target=\"_blank\">Spring AI</a>,\n      <a href=\"https://github.com/alibaba/spring-ai-alibaba/tree/main/examples\" target=\"_blank\">Examples</a>.\n    </h3>\n</html>\n\n## Architecture\n\n<p align=\"center\">\n    <img src=\"./docs/imgs/architecture-new.png\" alt=\"architecture\" style=\"max-width: 740px; height: auto\" />\n</p>\n\n**Spring AI Alibaba Admin** is a one-stop Agent platform that supports visualized Agent development, observability, evaluation, and MCP management, etc. It also integrates with open-source low-code platforms like Dify, enabling rapid migration from DSL to Spring AI Alibaba project.\n\n**Spring AI Alibaba Agent Framework** is an agent development framework that can quickly develop agents with builtin **Context Engineering** and **Human In The Loop** support. For scenarios requiring more complex process control, Agent Framework offers built-in workflows like `SequentialAgent`, `ParallelAgent`, `RoutingAgent`, `LoopAgent` and `SupervisorAgent`.\n\n**Spring AI Alibaba Graph** serves as the underlying runtime of the Agent Framework, providing essential capabilities such as persistence, workflow orchestration, and streaming required for long-running stateful agents. Compared to the Agent Framework, users can build more flexible multi-agent workflows based on the Graph API.\n\n## Core Features\n\n* **[Multi-Agent Orchestration](https://java2ai.com/docs/frameworks/agent-framework/advanced/multi-agent)**: Compose multiple agents with built-in patterns including `SequentialAgent`, `ParallelAgent`, `LlmRoutingAgent`, and `LoopAgent` for complex task execution.\n\n* **[Context Engineering](https://java2ai.com/docs/frameworks/agent-framework/tutorials/hooks)**: Built-in best practices for context engineering policies to improve agent reliability and performance, including human-in-the-loop, context compaction, context editing, model & tool call limit, tool retry, planning, dynamic tool selection.\n\n* **[Graph-based Workflow](https://java2ai.com/docs/frameworks/graph-core/quick-start)**: Graph based workflow runtime and api for conditional routing, nested graphs, parallel execution, and state management. Export workflows to PlantUML and Mermaid formats.\n\n* **[A2A Support](https://java2ai.com/docs/frameworks/agent-framework/advanced/a2a)**: Agent-to-Agent communication support with Nacos integration, enabling distributed agent coordination and collaboration across services.\n\n* **[Rich Model, Tool and MCP Support](https://java2ai.com/integration/chatmodels/dashScope)**: Leveraging core concepts of Spring AI, supports multiple LLM providers (DashScope, OpenAI, etc.), tool calling, and Model Context Protocol (MCP).\n\n* **[One-stop Agent Platform](https://java2ai.com/ecosystem/admin/quick-start)**: Build agent in a visualized way, deploy agent without code or export as a standalone java project.\n\n<p align=\"center\">\n    <img src=\"./docs/imgs/saa-admin.png\" alt=\"architecture\" style=\"max-width: 740px; height: auto\" />\n</p>\n\n## Getting Started\n\n### Prerequisites\n\n* Requires JDK 17+.\n* Choose your LLM provider and get the API-KEY.\n\n### Quickly Run a ChatBot\n\nThere's a ChatBot example provided by the community at [examples/chatbot](https://github.com/alibaba/spring-ai-alibaba/tree/main/examples/chatbot).\n\n1. Download the code.\n\n\t```shell\n\tgit clone --depth=1 https://github.com/alibaba/spring-ai-alibaba.git\n\tcd spring-ai-alibaba/examples/chatbot\n\t```\n\n2. Start the ChatBot.\n\n\tBefore starting, set API-KEY first (visit <a href=\"https://bailian.console.aliyun.com/?apiKey=1&tab=api#/api\" target=\"_blank\">Aliyun Bailian</a> to get API-KEY):\n\t```shell\n\t# this example uses 'spring-ai-alibaba-starter-dashscope', visit https://java2ai.com to learn how to use OpenAI/DeepSeek.\n\texport AI_DASHSCOPE_API_KEY=your-api-key\n\t```\n\t\n\t```shell\n\tmvn spring-boot:run\n\t```\n\n3. Chat with ChatBot.\n\n\tOpen the browser and visit [http://localhost:8080/chatui/index.html](http://localhost:8080/chatui/index.html) to chat with the ChatBot.\n\t\n<p align=\"center\">\n\t<img src=\"./docs/imgs/chatbot-chat-ui.gif\" alt=\"chatbot-ui\" style=\"max-width: 740px; height: auto\" />\n</p>\n\n## Chatbot Code Explained\n\n1. Add dependencies\n\n\t```xml\n\t<dependencies>\n\t  <dependency>\n\t    <groupId>com.alibaba.cloud.ai</groupId>\n\t    <artifactId>spring-ai-alibaba-agent-framework</artifactId>\n\t    <version>1.1.2.0</version>\n\t  </dependency>\n\t  <!-- Assume you are going to use DashScope Model. Refer to docs for how to choose model.-->\n\t  <dependency>\n\t    <groupId>com.alibaba.cloud.ai</groupId>\n\t    <artifactId>spring-ai-alibaba-starter-dashscope</artifactId>\n\t    <version>1.1.2.1</version>\n\t  </dependency>\n\t</dependencies>\n\t```\n\n2. Define Chatbot\n   \n\tFor more details of how to write a Chatbot, please check the [Quick Start](https://java2ai.com/docs/quick-start) on our official website.\n\n## ğŸ“š Documentation\n* [Overview](https://java2ai.com/docs/overview) - High level overview of the framework\n* [Quick Start](https://java2ai.com/docs/quick-start) - Get started with a simple agent\n* [Agent Framework Tutorials](https://java2ai.com/docs/frameworks/agent-framework/tutorials/agents) - Step by step tutorials\n* [Use Graph API to Build Complex Workflows](https://java2ai.com/docs/frameworks/agent-framework/advanced/context-engineering) - In-depth user guide for building multi-agent and workflows\n* [Spring AI Basics](https://java2ai.com/ecosystem/spring-ai/reference/concepts) - Ai Application basic concepts, including ChatModel, MCP, Tool, Messages, etc.\n\n## Project Structure\n\nThis project consists of several core components:\n\n* spring-ai-alibaba-agent-framework: A multi-agent framework designed for building intelligent agents with built-in context engineering best practices.\n* spring-ai-alibaba-graph: The underlying runtime for Agent Framework. We recommend developers to use Agent Framework but it's totally fine to use the Graph API directly.\n* spring-ai-alibaba-admin: A one-stop Agent platform that supports visualized Agent development, observability, evaluation, and MCP management, etc.\n* spring-ai-alibaba-studio: The embedded ui for quickly debugging agent in a visualized way.\n* spring-boot-starters: Starters integrating Agent Framework with Nacos to provide A2A and dynamic config features.\n\n## Spring AI Alibaba Ecosystem\n Repository | Description | â­\n  --- | --- | ---\n| [Spring AI Alibaba Graph](https://github.com/alibaba/spring-ai-alibaba/tree/main/spring-ai-alibaba-graph-core) | A low-level orchestration framework and runtime for building, managing, and deploying long-running, stateful agents. | ![GitHub Repo stars](https://img.shields.io/github/stars/alibaba/spring-ai-alibaba?style=for-the-badge&label=)\n| [Spring AI Alibaba Admin](https://github.com/spring-ai-alibaba/spring-ai-alibaba-admin) |  Local visualization toolkit for the development of agent applications, supporting project management, runtime visualization, tracing, and agent evaluation. | ![GitHub Repo stars](https://img.shields.io/github/stars/spring-ai-alibaba/spring-ai-alibaba-admin?style=for-the-badge&label=)\n| [Spring AI Extensions](https://github.com/spring-ai-alibaba/spring-ai-extensions) | Extended implementations for Spring AI core concepts, including DashScopeChatModel, MCP registry, etc. |  ![GitHub Repo stars](https://img.shields.io/github/stars/spring-ai-alibaba/spring-ai-extensions?style=for-the-badge&label=)\n| [Spring AI Alibaba Examples](https://github.com/spring-ai-alibaba/examples) | Spring AI Alibaba Examples. |  ![GitHub Repo stars](https://img.shields.io/github/stars/spring-ai-alibaba/examples?style=for-the-badge&label=)\n| [JManus](https://github.com/spring-ai-alibaba/jmanus) | A Java implementation of Manus built with Spring AI Alibaba, currently used in many applications within Alibaba Group. | ![GitHub Repo stars](https://img.shields.io/github/stars/spring-ai-alibaba/jmanus?style=for-the-badge&label=)\n| [DataAgent](https://github.com/spring-ai-alibaba/dataagent) | A natural language to SQL project based on Spring AI Alibaba, enabling you to query databases directly with natural language without writing complex SQL. | ![GitHub Repo stars](https://img.shields.io/github/stars/spring-ai-alibaba/dataagent?style=for-the-badge&label=)\n| [DeepResearch](https://github.com/spring-ai-alibaba/deepresearch) |  Deep Research implemented based on spring-ai-alibaba-graph. | ![GitHub Repo stars](https://img.shields.io/github/stars/spring-ai-alibaba/deepresearch?style=for-the-badge&label=)\n\n## Contact Us\n\n* Dingtalk Group (é’‰é’‰ç¾¤), search `130240015687` and join.\n* WeChat Group (å¾®ä¿¡å…¬ä¼—å·), scan the QR code below and follow us.\n\n<img src=\"./docs/imgs/wechat-account.jpg\" style=\"width: 260px; height: auto\"/>\n\n## Resources\n* [AI-Native Application Architecture White Paper](https://developer.aliyun.com/ebook/8479)ï¼šCo-authored by 40 frontline engineers and endorsed by 15 industry experts, this 200,000+ word white paper is the first comprehensive guide dedicated to the full DevOps lifecycle of AI-native applications. It systematically breaks down core concepts and key challenges, offering practical problem-solving approaches and architectural insights.\n\n\n## Star History\n\n[![Star History Chart](https://starchart.cc/alibaba/spring-ai-alibaba.svg?variant=adaptive)](https://starchart.cc/alibaba/spring-ai-alibaba)\n\n---\n\n<p align=\"center\">\n    Made with â¤ï¸ by the Spring AI Alibaba Team\n\n",
      "stars_today": 12
    },
    {
      "id": 363232643,
      "name": "atlas",
      "full_name": "ariga/atlas",
      "description": "Declarative schema migrations with schema-as-code workflows",
      "html_url": "https://github.com/ariga/atlas",
      "stars": 8043,
      "forks": 338,
      "language": "Go",
      "topics": [],
      "created_at": "2021-04-30T18:56:42Z",
      "updated_at": "2026-02-07T00:13:09Z",
      "pushed_at": "2026-02-05T03:07:28Z",
      "open_issues": 240,
      "owner": {
        "login": "ariga",
        "avatar_url": "https://avatars.githubusercontent.com/u/3059335?v=4"
      },
      "readme": "## Atlas: manage your database schema as code\n\n[![Twitter](https://img.shields.io/twitter/url.svg?label=Follow%20%40ariga%2Fatlas&style=social&url=https%3A%2F%2Ftwitter.com%2Fatlasgo_io)](https://twitter.com/atlasgo_io)\n[![Discord](https://img.shields.io/discord/930720389120794674?label=discord&logo=discord&style=flat-square&logoColor=white)](https://discord.com/invite/zZ6sWVg6NT)\n\n<p>\n  <a href=\"https://atlasgo.io\" target=\"_blank\">\n  <img alt=\"image\" src=\"https://github.com/ariga/atlas/assets/7413593/2e27cb81-bad6-491a-8d9c-20920995a186\">\n  </a>\n</p>\n\nAtlas is a language-agnostic tool for managing and migrating database schemas using modern DevOps principles.\nIt offers two workflows:\n\n- **Declarative**: Similar to Terraform, Atlas compares the current state of the database to the desired state, as\ndefined in an [HCL], [SQL], or [ORM] schema. Based on this comparison, it generates and executes a migration plan to \ntransition the database to its desired state.\n\n- **Versioned**: Unlike other tools, Atlas automatically plans schema migrations for you. Users can describe their desired\ndatabase schema in [HCL], [SQL], or their chosen [ORM], and by utilizing Atlas, they can plan, lint, and apply the\nnecessary migrations to the database.\n\n## Quick installation\n\n**macOS + Linux:**\n\n```bash\ncurl -sSf https://atlasgo.sh | sh\n```\n\n**Homebrew:**\n\n```bash\nbrew install ariga/tap/atlas\n```\n\n**Docker:**\n\n```bash\ndocker pull arigaio/atlas\n```\n\n**NPM:**\n\n```bash\nnpx @ariga/atlas\n```\n\nClick [here](https://atlasgo.io/getting-started#installation) to read instructions for other platforms.\n\n## Getting started\nGet started with Atlas by following the [Getting Started](https://atlasgo.io/getting-started/) docs.\nThis tutorial teaches you how to inspect a database, generate a migration plan and apply the migration to your database.\n\n## Key features:\n\n- **Schema management**: The `atlas schema` command offers various options for inspecting, diffing, comparing, and modifying\n  database schemas.\n- **Versioned migration**: The `atlas migrate` command provides a state-of-the-art experience for planning, linting, and\n  applying migrations.\n- **Terraform support**: Managing database changes as part of a Terraform deployment workflow.\n- **[SQL], [HCL] and [ORM] support**: Atlas enables users to define their desired database schema using [HCL], [SQL], or their chosen [ORM].\n- **Multi-tenancy**: Atlas includes built-in support for multi-tenant database schemas.\n- **Cloud integration**: Atlas integrates with standard cloud services and provides an easy way to read secrets from cloud\n  providers such as AWS Secrets Manager and GCP Secret Manager.\n\n## `schema inspect`\n_**Easily inspect your database schema by providing a database URL and convert it to HCL, JSON, SQL, ERD, or other formats.**_\n\nInspect a specific MySQL schema and get its representation in Atlas DDL syntax:\n```shell\natlas schema inspect -u \"mysql://root:pass@localhost:3306/example\" > schema.hcl\n```\n\n<details><summary>Result</summary>\n\n```hcl\ntable \"users\" {\n  schema = schema.example\n  column \"id\" {\n    null = false\n    type = int\n  }\n  ...\n}\n```\n</details>\n\nInspect the entire MySQL database and get its JSON representation:\n```shell\natlas schema inspect \\\n  --url \"mysql://root:pass@localhost:3306/\" \\\n  --format '{{ json . }}' | jq\n```\n\n<details><summary>Result</summary>\n\n```json\n{\n  \"schemas\": [\n    {\n      \"name\": \"example\",\n      \"tables\": [\n        {\n          \"name\": \"users\",\n          \"columns\": [\n            ...\n          ]\n        }\n      ]\n    }\n  ]\n}\n```\n</details>\n\nInspect a specific PostgreSQL schema and get its representation in SQL DDL syntax:\n```shell\natlas schema inspect \\\n  --url \"postgres://root:pass@:5432/test?search_path=public&sslmode=disable\" \\\n  --format '{{ sql . }}'\n```\n\n<details><summary>Result</summary>\n\n```sql\n-- create \"users\" table\nCREATE TABLE \"users\" (\"id\" integer NULL, ...);\n-- create \"posts\" table\nCREATE TABLE \"posts\" (\"id\" integer NULL, ...);\n```\n</details>\n\nInspect a specific PostgreSQL schema and get its ERD representation in the browser:\n```shell\natlas schema inspect \\\n  --url \"postgres://root:pass@:5432/test?search_path=public&sslmode=disable\" \\\n  -w\n```\n\n[![ERD](https://atlasgo.io/uploads/erd-example.png)](https://gh.atlasgo.cloud/explore/40d83919)\n\n\nInspect a specific PostgreSQL schema and get its ERD representation Mermaid syntax:\n```shell\natlas schema inspect \\\n  --url \"postgres://root:pass@:5432/test?search_path=public&sslmode=disable\" \\\n  --format '{{ mermaid . }}'\n```\n\n```mermaid\nerDiagram\n    users {\n      int id PK\n      varchar name \n    }\n    blog_posts {\n      int id PK\n      varchar title \n      text body \n      int author_id FK\n    }\n    blog_posts }o--o| users : author_fk\n```\n\n## `schema diff`\n_**Compare two schema states and get a migration plan to transform one into the other. A state can be specified using a\ndatabase URL, HCL or SQL schema, or a migration directory.**_\n\nCompare two MySQL schemas:\n```shell\natlas schema diff \\\n  --from mysql://root:pass@:3306/db1 \\\n  --to mysql://root:pass@:3306/db2\n```\n\n<details><summary>Result</summary>\n\n```sql\n-- Drop \"users\" table\nDROP TABLE `users`;\n```\n</details>\n\nCompare a MySQL schema with a migration directory:\n```shell\natlas schema diff \\\n  --from mysql://root:pass@:3306/db1 \\\n  --to file://migrations \\\n  --dev-url docker://mysql/8/db1\n````\n\nCompare a PostgreSQL schema with an Atlas schema in HCL format:\n```shell\natlas schema diff \\\n  --from \"postgres://postgres:pass@:5432/test?search_path=public&sslmode=disable\" \\\n  --to file://schema.hcl \\\n  --dev-url \"docker://postgres/15/test\"\n````\n\nCompare an HCL schema with an SQL schema:\n```shell\natlas schema diff \\\n  --from file://schema.sql \\\n  --to file://schema.hcl \\ \n  --dev-url docker://postgres/15/test  \n````\n\n## `schema apply`\n_**Generate a migration plan and apply it to the database to bring it to the desired state. The desired state can be\nspecified using a database URL, HCL or SQL schema, or a migration directory.**_\n\nUpdate the database to the state defined in the HCL schema:\n```shell\natlas schema apply \\\n  --url mysql://root:pass@:3306/db1 \\\n  --to file://schema.hcl \\\n  --dev-url docker://mysql/8/db1\n```\n\n<details><summary>Result</summary>\n\n```shell\n-- Planned Changes:\n-- Modify \"users\" table\nALTER TABLE `db1`.`users` DROP COLUMN `d`, ADD COLUMN `c` int NOT NULL;\nUse the arrow keys to navigate: â†“ â†‘ â†’ â† \n? Are you sure?: \n  â–¸ Apply\n    Abort\n```\n</details>\n\nUpdate the database to the state defined in a specific version of the migration directory:\n```shell\natlas schema apply \\\n  --url mysql://root:pass@:3306/db1 \\\n  --to \"file://migrations?version=20221118091226\" \\\n  --dev-url docker://mysql/8/db1\n```\n\n### Additional `schema` commands\nAtlas offers additional commands to assist users managing their database schemas. These include `schema clean` and\n`schema fmt`. For more information, see the versioned migration documentation at https://atlasgo.io/declarative/inspect.\n\n## `migrate diff`\n_**Write a new migration file to the migration directory that bring it to the desired state. The desired state can be\nspecified using a database URL, HCL or SQL schema, or a migration directory.**_\n\nCreate a migration file named `add_blog_posts` in the migration directory to bring the database to the state defined\nin an HCL schema:\n```shell\natlas migrate diff add_blog_posts \\           \n  --dir file://migrations \\\n  --to file://schema.hcl \\\n  --dev-url docker://mysql/8/test\n```\n\nCreate a migration file named `add_blog_posts` in the migration directory to bring the database to the state defined\nin an SQL schema:\n```shell\natlas migrate diff add_blog_posts \\           \n  --dir file://migrations \\\n  --to file://schema.sql \\\n  --dev-url docker://mysql/8/test\n```\n\nCreate a migration file named `add_blog_posts` in the migration directory to bring the database to the state defined\nby another database:\n```shell\natlas migrate diff add_blog_posts \\           \n  --dir file://migrations \\\n  --to mysql://root:pass@host:3306/db \\\n  --dev-url docker://mysql/8/test\n```\n\n## `migrate apply`\n_**Apply all or part of pending migration files in the migration directory on the database.**_\n\nApply all pending migration files in the migration directory on a MySQL database:\n```shell\natlas migrate apply \\\n  --url mysql://root:pass@:3306/db1 \\\n  --dir file://migrations\n```\n\nApply in **dry run** mode the first the pending migration file in the migration directory on a PostgreSQL schema:\n```shell\natlas migrate apply \\\n  --url \"postgres://root:pass@:5432/test?search_path=public&sslmode=disable\" \\\n  --dir file://migrations \\\n  --dry-run\n```\n\n### Additional `migrate` commands\nAtlas offers additional commands to assist users managing their database migrations. These include `migrate lint`,\n`migrate status`, and more. For more information, see the versioned migration documentation at https://atlasgo.io/versioned/diff.\n\n### Supported databases\nMySQL, MariaDB, PostgresSQL, SQLite, TiDB, CockroachDB, SQL Server, ClickHouse, Redshift.\n\n## Supported Version Policy\n\nTo ensure the best performance, security and compatibility with the Atlas Cloud service, the Atlas team\nwill only support the two most recent minor versions of the CLI. For example, if the latest version is\n`v0.25`, the supported versions will be `v0.24` and `v0.25` (in addition to any patch releases and the\n\"canary\" release which is built twice a day).\n\n### Old Binaries\n\nAs part of the *Supported Version Policy* mentioned above, binaries for versions that were published\nmore than 6 months ago will be removed from the CDN and Docker Hub.\n\n[HCL]: https://atlasgo.io/atlas-schema/hcl\n[SQL]: https://atlasgo.io/atlas-schema/sql\n[ORM]: https://atlasgo.io/orms\n",
      "stars_today": 12
    },
    {
      "id": 659402878,
      "name": "spring-ai",
      "full_name": "spring-projects/spring-ai",
      "description": "An Application Framework for AI Engineering",
      "html_url": "https://github.com/spring-projects/spring-ai",
      "stars": 7871,
      "forks": 2277,
      "language": "Java",
      "topics": [
        "artificial-intelligence",
        "hacktoberfest",
        "java",
        "spring-ai"
      ],
      "created_at": "2023-06-27T18:57:29Z",
      "updated_at": "2026-02-07T02:06:29Z",
      "pushed_at": "2026-02-06T16:30:13Z",
      "open_issues": 1179,
      "owner": {
        "login": "spring-projects",
        "avatar_url": "https://avatars.githubusercontent.com/u/317776?v=4"
      },
      "readme": "# Spring AI [![build status](https://github.com/spring-projects/spring-ai/actions/workflows/continuous-integration.yml/badge.svg)](https://github.com/spring-projects/spring-ai/actions/workflows/continuous-integration.yml) [![build status](https://github.com/spring-projects/spring-ai-integration-tests/actions/workflows/spring-ai-integration-tests.yml/badge.svg)](https://github.com/spring-projects/spring-ai-integration-tests/actions/workflows/spring-ai-integration-tests.yml) [![Maven Central](https://img.shields.io/maven-central/v/org.springframework.ai/spring-ai-model?label=Maven%20Central&versionPrefix=2.0)](https://central.sonatype.com/artifact/org.springframework.ai/spring-ai-model)\n\n### Spring Boot Version Compatibility\n\n> **Spring AI 2.x.x** ([main](https://github.com/spring-projects/spring-ai/tree/main) branch) - Spring Boot `4.x`\n>\n> **Spring AI 1.1.x** ([1.1.x](https://github.com/spring-projects/spring-ai/tree/1.1.x) branch) - Spring Boot `3.5.x`\n\n\nThe Spring AI project provides a Spring-friendly API and abstractions for developing AI applications.\n\nIts goal is to apply to the AI domain Spring ecosystem design principles such as portability and modular design and promote using POJOs as the building blocks of an application to the AI domain.\n\n![spring-ai-integration-diagram-3](https://docs.spring.io/spring-ai/reference/_images/spring-ai-integration-diagram-3.svg)\n\n> At its core, Spring AI addresses the fundamental challenge of AI integration: Connecting your enterprise __Data__ and __APIs__ with the __AI Models__.\n\nThe project draws inspiration from notable Python projects, such as [LangChain](https://docs.langchain.com/docs/) and [LlamaIndex](https://gpt-index.readthedocs.io/en/latest/getting_started/concepts.html), but Spring AI is not a direct port of those projects. The project was founded with the belief that the next wave of Generative AI applications will not be only for Python developers but will be ubiquitous across many programming languages.\n\nYou can check out the blog post [Why Spring AI](https://spring.io/blog/2024/11/19/why-spring-ai) for additional motivations.\n\nThis is a high level feature overview.\nYou can find more details in the [Reference Documentation](https://docs.spring.io/spring-ai/reference/)\n\n* Support for all major [AI Model providers](https://docs.spring.io/spring-ai/reference/api/index.html) such as Anthropic, OpenAI, Microsoft, Amazon, Google, and Ollama. Supported model types include:\n  - [Chat Completion](https://docs.spring.io/spring-ai/reference/api/chatmodel.html)\n  - [Embedding](https://docs.spring.io/spring-ai/reference/api/embeddings.html)\n  - [Text to Image](https://docs.spring.io/spring-ai/reference/api/imageclient.html)\n  - [Audio Transcription](https://docs.spring.io/spring-ai/reference/api/audio/transcriptions.html)\n  - [Text to Speech](https://docs.spring.io/spring-ai/reference/api/audio/speech.html)\n  - [Moderation](https://docs.spring.io/spring-ai/reference/api/index.html#api/moderation)\n  - **Latest Models**: GPT-5, and other cutting-edge models for advanced AI applications.\n* Portable API support across AI providers for both synchronous and streaming options. Access to [model-specific features](https://docs.spring.io/spring-ai/reference/api/chatmodel.html#_chat_options) is also available.\n* [Structured Outputs](https://docs.spring.io/spring-ai/reference/api/structured-output-converter.html) - Mapping of AI Model output to POJOs.\n* Support for all major [Vector Database providers](https://docs.spring.io/spring-ai/reference/api/vectordbs.html) such as *Apache Cassandra, Azure Vector Search, Chroma, Elasticsearch, Milvus, MongoDB Atlas, MariaDB, Neo4j, Oracle, PostgreSQL/PGVector, Pinecone, Qdrant, Redis, and Weaviate*.\n* Portable API across Vector Store providers, including a novel SQL-like [metadata filter API](https://docs.spring.io/spring-ai/reference/api/vectordbs.html#metadata-filters).\n* [Tools/Function Calling](https://docs.spring.io/spring-ai/reference/api/tools.html) - permits the model to request the execution of client-side tools and functions, thereby accessing necessary real-time information as required.\n* [Observability](https://docs.spring.io/spring-ai/reference/observability/index.html) - Provides insights into AI-related operations.\n* Document injection [ETL framework](https://docs.spring.io/spring-ai/reference/api/etl-pipeline.html) for Data Engineering.\n* [AI Model Evaluation](https://docs.spring.io/spring-ai/reference/api/testing.html) - Utilities to help evaluate generated content and protect against hallucinated response.\n* [ChatClient API](https://docs.spring.io/spring-ai/reference/api/chatclient.html) - Fluent API for communicating with AI Chat Models, idiomatically similar to the WebClient and RestClient APIs.\n* [Advisors API](https://docs.spring.io/spring-ai/reference/api/advisors.html) - Encapsulates recurring Generative AI patterns, transforms data sent to and from Language Models (LLMs), and provides portability across various models and use cases.\n* Support for [Chat Conversation Memory](https://docs.spring.io/spring-ai/reference/api/chatclient.html#_chat_memory) and [Retrieval Augmented Generation (RAG)](https://docs.spring.io/spring-ai/reference/api/chatclient.html#_retrieval_augmented_generation).\n* Spring Boot Auto Configuration and Starters for all AI Models and Vector Stores - use the [start.spring.io](https://start.spring.io/) to select the Model or Vector-store of choice. \n\n## Getting Started\n\nPlease refer to the [Getting Started Guide](https://docs.spring.io/spring-ai/reference/getting-started.html) for instruction on adding your dependencies.\n\n## Project Resources\n\n* [Documentation](https://docs.spring.io/spring-ai/reference/)\n* [Issues](https://github.com/spring-projects/spring-ai/issues)\n<!-- * [Discussions](https://github.com/spring-projects/spring-ai/discussions) - Go here if you have a question, suggestion, or feedback! -->\n* [Awesome Spring AI](https://github.com/spring-ai-community/awesome-spring-ai) - A curated list of awesome resources, tools, tutorials, and projects for building generative AI applications using Spring AI\n* [Spring AI Examples](https://github.com/spring-projects/spring-ai-examples) contains example projects that explain specific features in more detail.\n* [Spring AI Community](https://github.com/spring-ai-community) - A community-driven organization for building Spring-based integrations with AI models, agents, vector databases, and more.\n\n## Breaking changes\n\n* Refer to the [upgrade notes](https://docs.spring.io/spring-ai/reference/upgrade-notes.html) to see how to upgrade to 1.0.0.M1 or higher.\n\n## Cloning the repo\n\nThis repository contains [large model files](https://github.com/spring-projects/spring-ai/tree/main/models/spring-ai-transformers/src/main/resources/onnx/all-MiniLM-L6-v2).\nTo clone it you have to either:\n\n- Ignore the large files (won't affect the spring-ai behaviour) :  `GIT_LFS_SKIP_SMUDGE=1 git clone git@github.com:spring-projects/spring-ai.git`.\n- Or install the [Git Large File Storage](https://git-lfs.com/) before cloning the repo.\n\n\n## Building\n\nThe project targets and build artifacts compatible with Java 17+, but requires JDK 21\nto build. This is enforced by the maven enforcer plugin.\n\nTo build with running unit tests\n\n```shell\n./mvnw clean package\n```\n\nTo build including integration tests.\n\n```shell\n./mvnw clean verify -Pintegration-tests\n```\n\nNote that you should set API key environment variables for OpenAI or other model providers before running.  If the API key isn't set for a specific model provider, the integration test is skipped.\n\nTo run a specific integration test allowing for up to two attempts to succeed.  This is useful when a hosted service is not reliable or times out.\n```shell\n./mvnw -pl vector-stores/spring-ai-pgvector-store -Pintegration-tests -Dfailsafe.rerunFailingTestsCount=2 -Dit.test=PgVectorStoreIT verify\n```\n\n### Integration Tests\nThere are many integration tests, so it often isn't realistic to run them all at once.\n\nA quick pass through the most important pathways that runs integration tests for\n\n* OpenAI models \n* OpenAI autoconfiguration\n* PGVector\n* Chroma\n\ncan be done with the profile `-Pci-fast-integration-tests` and is used in the main CI build of this project.\n\nA full integration test is done twice a day in the [Spring AI Integration Test Repository](https://github.com/spring-projects/spring-ai-integration-tests)\n\nOne way to run integration tests on part of the code is to first do a quick compile and install of the project\n\n```shell\n./mvnw clean install -DskipTests -Dmaven.javadoc.skip=true\n```\nThen run the integration test for a specific module using the `-pl` option\n\n```shell\n./mvnw verify -Pintegration-tests -pl spring-ai-spring-boot-testcontainers\n```\n\n### Documentation\n\nTo build the docs\n```shell\n./mvnw -pl spring-ai-docs antora\n```\n\nThe docs are then in the directory `spring-ai-docs/target/antora/site/index.html`\n\n### Formatting the Source Code\n\nThe code is formatted using the [java-format plugin](https://github.com/spring-io/spring-javaformat) as part of the build. Correct\nformatting is enforced by CI.\n\n### Updating License Headers\n\nTo update the year on license headers using the [license-maven-plugin](https://oss.carbou.me/license-maven-plugin/#goals)\n```shell\n./mvnw license:update-file-header -Plicense\n```\n### Javadocs\n\nTo check javadocs using the [javadoc:javadoc](https://maven.apache.org/plugins/maven-javadoc-plugin/)\n```shell\n./mvnw javadoc:javadoc -Pjavadoc\n```\n\n#### Source Code Style\n\nSpring AI source code checkstyle tries to follow the checkstyle guidelines used by the core Spring Framework project with some exceptions.\nThe wiki pages\n[Code Style](https://github.com/spring-projects/spring-framework/wiki/Code-Style) and\n[IntelliJ IDEA Editor Settings](https://github.com/spring-projects/spring-framework/wiki/IntelliJ-IDEA-Editor-Settings)\ndefine the source file coding standards we use along with some IDEA editor settings we customize.\n\n## Contributing\n\nYour contributions are always welcome! Please read the [contribution guidelines](CONTRIBUTING.adoc) first.\n",
      "stars_today": 11
    },
    {
      "id": 379877112,
      "name": "open-meteo",
      "full_name": "open-meteo/open-meteo",
      "description": "Free Weather Forecast API for non-commercial use",
      "html_url": "https://github.com/open-meteo/open-meteo",
      "stars": 4702,
      "forks": 305,
      "language": "Swift",
      "topics": [
        "weather",
        "weather-api",
        "weather-forecast"
      ],
      "created_at": "2021-06-24T09:48:38Z",
      "updated_at": "2026-02-06T21:23:02Z",
      "pushed_at": "2026-02-04T14:09:10Z",
      "open_issues": 161,
      "owner": {
        "login": "open-meteo",
        "avatar_url": "https://avatars.githubusercontent.com/u/86407831?v=4"
      },
      "readme": "# ğŸŒ¤ Open-Meteo Weather API\n\n[![Test](https://github.com/open-meteo/open-meteo/actions/workflows/test.yml/badge.svg?branch=main)](https://github.com/open-meteo/open-meteo/actions/workflows/test.yml) [![GitHub license](https://img.shields.io/github/license/open-meteo/open-meteo)](https://github.com/open-meteo/open-meteo/blob/main/LICENSE) [![license: CC BY 4.0](https://img.shields.io/badge/license-CC%20BY%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/) [![Twitter](https://img.shields.io/badge/follow-%40open_meteo-1DA1F2?logo=twitter&style=social)](https://twitter.com/open_meteo) [![Mastodon](https://img.shields.io/mastodon/follow/109320332765909743?domain=https%3A%2F%2Ffosstodon.org)](https://fosstodon.org/@openmeteo) [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7970649.svg)](https://doi.org/10.5281/zenodo.7970649)\n\nOpen-Meteo is an open-source weather API and offers free access for non-commercial use. No API key is required. You can use it immediately!\n\nHead over to https://open-meteo.com! Stay up to date with our blog at https://openmeteo.substack.com.\n\n## Features\n\n- [Hourly weather forecast](https://open-meteo.com/en/docs) for up to 16 days\n- Global weather models with 11 km and regional models up to 1.5 km resolution\n- Weather model updates every hour for Europe and North America\n- 80 years [Historical Weather API](https://open-meteo.com/en/docs/historical-weather-api)\n- Based on the best weather models: [NOAA GFS with HRRR](https://open-meteo.com/en/docs/gfs-api), [DWD ICON](https://open-meteo.com/en/docs/dwd-api), [MeteoFrance Arome&Arpege](https://open-meteo.com/en/docs/meteofrance-api), [ECMWF IFS](https://open-meteo.com/en/docs/ecmwf-api), [JMA](https://open-meteo.com/en/docs/jma-api), [GEM HRDPS](https://open-meteo.com/en/docs/gem-api), [MET Norway](https://open-meteo.com/en/docs/metno-api)\n- [Marine Forecast API](https://open-meteo.com/en/docs/marine-weather-api), [Air Quality API](https://open-meteo.com/en/docs/air-quality-api), [Geocoding API](https://open-meteo.com/en/docs/geocoding-api), [Elevation API](https://open-meteo.com/en/docs/elevation-api), [Flood API](https://open-meteo.com/en/docs/flood-api)\n- Lightning fast APIs with response times below 10 ms\n- Servers located in Europe and North America with GeoDNS for best latency and high-availability\n- No API key required, CORS supported, no ads, no tracking, not even cookies\n- Free for non-commercial use with data under Attribution 4.0 International (CC BY 4.0)\n- Source code available under AGPLv3\n\n## How does Open-Meteo work?\n\nOpen-Meteo utilizes open-data weather forecasts provided by national weather services. These services offer numerical weather predictions that are free to download. However, working with these models can be challenging, as it requires expertise in binary file formats, grid-systems, projections, and the fundamentals of weather predictions.\n\nLike many other weather APIs, Open-Meteo integrates high-resolution local and global weather models. Over 2 TB of data are downloaded and processed daily from multiple national weather services. The collected data is then stored in local files using a customized file format and compression technique to enhance access to time-series data such as a 14-day temperature forecast.\n\nIn contrast to other weather APIs, Open-Meteo provides complete access to its source code, and all data sources are openly listed, crediting the national weather services for their work. With Docker or prebuilt Ubuntu packages, it is possible to launch your own weather API within minutes. By providing the source code, users can conduct detailed verifications of the weather data processing and even make modifications themselves. Contributions are highly encouraged and welcomed.\n\nThe API is available for non-commercial use at no cost. Despite being free of charge, the forecast accuracy is top-notch. The API utilizes a vast array of local weather models with rapid updates, ensuring that the most precise forecast is generated for any location globally.\n\n## Resources\n\n- All API documentation can be found on https://open-meteo.com. The source code for the website, documentation and API generator is available here: https://github.com/open-meteo/open-meteo-website\n- The free non-commerical API is hosted at [https://api.open-meteo.com](https://api.open-meteo.com/v1/forecast?latitude=52.52&longitude=13.41&hourly=temperature_2m) using to GeoDNS to servers in Europe and North America (HTTPS is optional). The API source code is in this current repository.\n- The geocoding API source code is available in a separate repository https://github.com/open-meteo/geocoding-api\n- Larger changes are announced in the [Open-Meteo Blog](https://openmeteo.substack.com)\n- The [Open-Meteo weather database](https://github.com/open-meteo/open-data) is redistributed as part of an AWS Open-Data Sponsorship\n\n## Who is using Open-Meteo?\n\nApps:\n\n- [Alpine Conditions](https://www.alpineconditions.com) Allows a user to compare multiple models at once & create ensemble forecasts for any location\n- [Breezy Weather](https://github.com/breezy-weather/breezy-weather) A feature-rich, free and open source Material 3 Expressive Android weather app.\n- [Cirrus](https://github.com/woheller69/omweather) Android Weather App\n- [Clima](https://f-droid.org/packages/co.prestosole.clima/) Beautiful, minimal, and fast weather app\n- [DroneWeather](https://play.google.com/store/apps/details?id=xyz.droneweather.app) Weather forecasts, satellite count, and KP index for drone pilots.\n- [Emojiton Weather](https://emojiton.com/weather) Get the local weather forecast for your location with fun emoji representations\n- [Evaporative Cooler Forecaster](https://SwampCooler.app) Swamp cooler effectiveness forecast with cost & energy savings, Android/iOS app\n- [Home Assistant](https://www.home-assistant.io/integrations/open_meteo/) A popular open source smart home platform.\n- [Lively Weather](https://www.rocksdanister.com/weather) Windows native weather app powered by DirectX12 animations.\n- [LunaLink](https://www.lunalink.de) A site for hunters, fishermen and nature observers: It provides sun and moon values â€‹â€‹(including moon brightness) as well as the weather for individual locations in Central Europe.\n- [Meteo-Fly](https://meteo-fly.com) Free flight-weather charts for paraglider & hang-glider pilots.\n- [MeteoHist](https://yotka.org/meteo-hist) A web app to create interactive temperature and precipitation graphs for places around the world\n- [OSS Weather](https://github.com/Akylas/oss-weather) - Multi-model/multi-provider Open Source Android/iOS Weather app\n- [Overmorrow](https://github.com/bmaroti9/Overmorrow) A modern material design Android weather app.\n- [PointWx](https://hh.guidocioni.it/pointwx/) Dash application with interactive plots (from beginner-friendly to weather-enthusiast level) easily deployable\n- [QuickWeather](https://github.com/TylerWilliamson/QuickWeather) Fast, free, and open source Android app\n- [Rain](https://github.com/DarkMooNight/Rain) Free, open source, beautiful, minimal and fast weather app\n- [Raindrop](https://github.com/metalfoxdev/Raindrop) Simple and intuitive weather app for the linux terminal.\n- [Road Vagabond](https://roadvagabond.com) A camping destination discovery app showing zones within your drive time with weather-based filtering.\n- [SkyMuse](https://github.com/cakephone/skymuse) Minimal, privacy-respecting weather app. Built with web technologies.\n- [Slideshow](https://slideshow.digital/) Digital Signage app for Android\n- [solXpect](https://github.com/woheller69/solxpect) Android app which forecasts the output of your solar power plant\n- [The Weather](https://weather.jamesdinovo.com) A detailed, installable, progressive web application\n- [truthclimate](https://www.truthclimate.com) Discover how weather and climate changed all around the world.\n- [Weather Please](https://github.com/ggaidelevicius/weather-please/) Clean and minimal new tab replacement for browsers\n- [Weather.io](https://weather.roessner.tech) A simple Progressive Web App (PWA) for checking the weather.\n- [Weather](https://github.com/GustavLindberg99/AndroidWeather) Free, open source, simple and complete weather app for Android\n- [WeatherAI](https://play.google.com/store/apps/details?id=com.kingfu.weatherai) WeatherAI offers an intuitive user experience that makes checking the weather a breeze.\n- [WeatherGraph](https://weathergraph.app) Apple Watch App\n- [WeatherMaster](https://github.com/PranshulGG/WeatherMaster) A Weather app for android inspired by the Google Pixel weather app.\n- [Weatherian](https://weatherian.com/) Multi-model meteogram (multi-platform)\n- [weewx-DWD](https://github.com/roe-dl/weewx-DWD) Weather forecasts etc. for WeeWX\n- [WetBulb](https://github.com/Isma1306/wetbulb-forecast) A simple app that shows you the wetbulb temp 24h forecast and tells you if it is dangerous.\n\nRepositories:\n\n- [Captain Cold](https://github.com/cburton-godaddy/captain-cold) Simple Open-Meteo -> Discord integration\n- [wthrr-the-weathercrab](https://github.com/tobealive/wthrr-the-weathercrab) Weather companion for the terminal\n- [Weather-Cli](https://github.com/Rayrsn/Weather-Cli) A CLI program written in golang that allows you to get weather information from the terminal\n- [Homepage](https://github.com/benphelps/homepage/) A highly customizable homepage (or startpage / application dashboard) with Docker and service API integrations.\n- [Spots Guru](https://www.spots.guru) Weather forecast for lazy, the best wind & wave spots around you.\n- [WeatherReport.jl](https://github.com/vnegi10/WeatherReport.jl) A simple weather app for the Julia REPL\n- [DIY Arduino esp8266 weather station](https://github.com/AlexeyMal/esp8266-weather-station) esp8266 weather station using Open-Meteo API, an embedded C++ implementation example\n- [biome](https://github.com/SqrtMinusOne/biome) Bountiful Interface to Open Meteo for Emacs\n\nOther:\n\n- [Menubar Weather](https://www.raycast.com/koinzhang/menubar-weather) A Raycast extension that displays live weather information in your menu bar\n- [MiniPavi](https://www.minipavi.fr/emulminitel/) Vintage French Minitel (a kind of BBS) weather forecast service (type \"METEO\" keyword on welcome Minitel screen)\n- [OFM-InternetWeatherModule](https://github.com/OpenKNX/OFM-InternetWeatherModule) An OpenKNX module to provide data of weather services on KNX-bus (configurable via ETS)\n- Contributions welcome!\n\nDo you use Open-Meteo? Please open a pull request and add your repository or app to the list!\n\n## Client SDKs\n\n- Go https://github.com/HectorMalot/omgo\n- Python https://github.com/m0rp43us/openmeteopy\n- Kotlin https://github.com/open-meteo/open-meteo-api-kotlin\n- .Net / C# https://github.com/AlienDwarf/open-meteo-dotnet\n- dotnet 8 / C# https://github.com/colinnuk/open-meteo-dotnet-client-sdk\n- PHP Laravel https://github.com/michaelnabil230/laravel-weather\n- R https://github.com/tpisel/openmeteo\n- PHP Symfony 6.2 https://gitlab.com/flibidi67/open-meteo\n- PHP for Geocoding API: https://gitlab.com/flibidi67/open-meteo-geocoding\n- Android library for Geocoding API: https://github.com/woheller69/OmGeoDialog\n- Dart / Flutter: https://github.com/neursh/open-meteo-dart\n- Rust: https://github.com/angelodlfrtr/open-meteo-rs\n\nContributions welcome! Writing a SDK for Open-Meteo is more than welcome and a great way to help users.\n\n## Support\n\nIf you encounter bugs while using Open-Meteo APIs, please file a new issue ticket. For general ideas or Q&A please use the [Discussion](https://github.com/open-meteo/open-meteo/discussions) section on Github. Thanks!\n\nFor other enquiries please contact info@open-meteo.com\n\n## Run your own API\n\nInstructions to use Docker to run your own weather API are available in the [getting started guide](/docs/getting-started.md).\n\n## Terms & Privacy\n\nOpen-Meteo APIs are free for open-source developer and non-commercial use. We do not restrict access, but ask for fair use.\n\nIf your application exceeds 10'000 requests per day, please contact us. We reserve the right to block applications and IP addresses that misuse our service.\n\nFor commercial use of Open-Meteo APIs, please contact us.\n\nAll data is provided as is without any warranty.\n\nWe do not collect any personal data. We do not share any personal information. We do not integrate any third party analytics, ads, beacons or plugins.\n\n## Data License\n\nAPI data are offered under Attribution 4.0 International (CC BY 4.0)\n\nYou are free to share: copy and redistribute the material in any medium or format and adapt: remix, transform, and build upon the material.\n\nAttribution: You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n\nYou must include a link next to any location, Open-Meteo data are displayed like:\n\n<a href=\"https://open-meteo.com/\">Weather data by Open-Meteo.com</a>\n\n## Source Code License\n\nOpen-Meteo is open-source under the GNU Affero General Public License Version 3 (AGPLv3) or any later version. You can [find the license here](LICENSE). Exceptions are third party source-code with individual licensing in each file.\n",
      "stars_today": 11
    },
    {
      "id": 1061327311,
      "name": "FluidVoice",
      "full_name": "altic-dev/FluidVoice",
      "description": "FluidVoice - Fastest macOS Offline Dictation app - Voice to Text fully Local. One â­ takes us a long way :)) ",
      "html_url": "https://github.com/altic-dev/FluidVoice",
      "stars": 991,
      "forks": 52,
      "language": "Swift",
      "topics": [],
      "created_at": "2025-09-21T17:35:02Z",
      "updated_at": "2026-02-06T23:12:43Z",
      "pushed_at": "2026-02-04T02:51:05Z",
      "open_issues": 28,
      "owner": {
        "login": "altic-dev",
        "avatar_url": "https://avatars.githubusercontent.com/u/224717674?v=4"
      },
      "readme": "# FluidVoice\n\n[![Supported Models](https://img.shields.io/badge/Models-Parakeet%20v3%20%26%20v2%20%7C%20Apple%20Speech%20%7C%20Whisper-blue)](https://github.com/altic-dev/Fluid-oss)\n\nFully open source voice-to-text dictation app for macOS with AI enhancement.\n\n**Get the latest release from [here](https://github.com/altic-dev/Fluid-oss/releases/latest)**\n\n> [!IMPORTANT]\n> This project is completely free and open source. If you find FluidVoice useful, please star the repository. It helps with visibility and motivates continued development. Your support means a lot.\n\n## Star History\n\n<a href=\"https://star-history.com/#altic-dev/Fluid-oss&Date\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=altic-dev/Fluid-oss&type=Date&theme=dark\" />\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=altic-dev/Fluid-oss&type=Date\" />\n    <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=altic-dev/Fluid-oss&type=Date\" />\n  </picture>\n</a>\n\n## Demo\n\n### Command Mode - Take any action on your mac using FluidVoice  \n\nhttps://github.com/user-attachments/assets/ffb47afd-1621-432a-bdca-baa4b8526301\n\n### Write Mode - Write/Rewrite text in ANY text box in ANY App on your mac  \n\nhttps://github.com/user-attachments/assets/c57ef6d5-f0a1-4a3f-a121-637533442c24\n\n## Screenshots\n\n### Command Mode Preview\n\n![Command Mode Preview](assets/cmd_mode_ss.png)\n\n### FluidVoice History\n\n![FluidVoice History](assets/history__ss.png)\n\n## New Features (v1.5)   \n- **Overlay with Notch support**\n- **Command Mode**  \n- **Write Mode**    \n- **New History stats**  \n- **Stats to monitor usage**  \n\n\n## Features\n- **Live Preview Mode**: Real-time transcription preview in overlay\n- **Multiple Speech Models**: Parakeet TDT v3 & v2, Apple Speech, and Whisper\n- **Real-time transcription** with extremely low latency\n- **AI enhancement** with OpenAI, Groq, and custom providers\n- **Global hotkey** for instant voice capture\n- **Smart typing** directly into any app\n- **Menu bar integration** for quick access\n- **Auto-updates** with seamless restart\n\n## Supported Models\n\n### Parakeet TDT v3 (Default)\nOptimized for Apple Silicon. Supports 25 languages with auto-detection:\n**Bulgarian, Croatian, Czech, Danish, Dutch, English, Estonian, Finnish, French, German, Greek, Hungarian, Italian, Latvian, Lithuanian, Maltese, Polish, Portuguese, Romanian, Slovak, Slovenian, Spanish, Swedish, Russian, Ukrainian.**\n\n### Parakeet TDT v2\nEnglish-only model optimized for higher accuracy and consistency on Apple Silicon.\n\n### Apple Speech\nUses the native macOS Speech Recognition engine and Speech Analyzer API (macOS 26+).\n\n### Whisper\nUniversal support (runs on Intel & Apple Silicon). Supports 99 languages.\n\n## Quick Start\n\n1. Download the latest release\n2. Move to Applications folder\n3. Grant microphone and accessibility permissions when prompted\n4. Set your preferred hotkey in settings\n5. Optionally add an AI provider API key for enhanced transcription, keys are stored securely in your macOS Keychain. Make sure select \"Always allow\" for permissions\n\n## Requirements\n\n- macOS 14.0 (Sonoma) or later\n- Apple Silicon Mac (M1, M2, M3, M4)\n- Intel Macs are supported from 1.5.1 builds using Whisper models!\n- Microphone access\n- Accessibility permissions for typing\n\n\n## Join our small community to help us grow and give feedback :) ( Or just hang?!)   \n\nhttps://discord.gg/VUPHaKSvYV  \n\n## Building from Source\n\n```bash\ngit clone https://github.com/altic-dev/Fluid-oss.git\ncd Fluid-oss\nopen FluidVoice.xcodeproj\n```\n\nBuild and run in Xcode. All dependencies are managed via Swift Package Manager.\n\n## Contributing\n\nContributions are welcome! Please create an issue first to discuss any major changes or feature requests before submitting a pull request.\n\n### Setting Up Your Development Environment\n\n1. **Clone the repository:**\n   ```bash\n   git clone https://github.com/altic-dev/Fluid-oss.git\n   cd Fluid-oss\n   ```\n\n2. **Open in Xcode:**\n   ```bash\n   open Fluid.xcodeproj\n   ```\n\n3. **Configure your Team ID:**\n   - Select the project in Xcode's navigator\n   - Go to \"Signing & Capabilities\" tab\n   - Select your Apple Developer Team from the dropdown\n   - Xcode will save this locally in `xcuserdata/` (which is gitignored)\n\n4. **Build and run** - All dependencies are managed via Swift Package Manager\n\n5. **(Optional) Install pre-commit hook** to prevent accidental team ID commits:\n   ```bash\n   cp scripts/check-team-id.sh .git/hooks/pre-commit\n   chmod +x .git/hooks/pre-commit\n   ```\n\n### Pull Request Guidelines\n\n- **Keep changes focused and atomic** - one feature or fix per PR\n- **Update documentation** if adding new features\n- **Test thoroughly** on your machine before submitting\n- **Never commit personal team IDs or API keys** to `project.pbxproj`\n- **Check git diff** before committing to ensure no personal settings leaked in\n\n## Connect\n\nFollow development updates on X: [@ALTIC_DEV](https://x.com/ALTIC_DEV)\n\n## Run integration dictation test\n\n```bash\nxcodebuild test -project Fluid.xcodeproj -scheme Fluid -destination 'platform=macOS'\n```\n\nIf you run into a test bundle load error related to code signing/Team ID, run without overriding code signing flags (the command above), or explicitly:\n\n```bash\nxcodebuild test -project Fluid.xcodeproj -scheme Fluid -destination 'platform=macOS' CODE_SIGN_STYLE=Automatic\n```\n\nCI uses unsigned builds:\n\n```bash\nxcodebuild test -project Fluid.xcodeproj -scheme Fluid -destination 'platform=macOS' CODE_SIGNING_REQUIRED=NO CODE_SIGNING_ALLOWED=NO\n```\n\n## License\n\nThis project is licensed under the [Apache License 2.0](LICENSE).\n\n---\n",
      "stars_today": 11
    },
    {
      "id": 236095576,
      "name": "backstage",
      "full_name": "backstage/backstage",
      "description": "Backstage is an open framework for building developer portals",
      "html_url": "https://github.com/backstage/backstage",
      "stars": 32509,
      "forks": 7080,
      "language": "TypeScript",
      "topics": [
        "backstage",
        "cncf",
        "developer-experience",
        "developer-portal",
        "dx",
        "hacktoberfest",
        "infrastructure",
        "microservices",
        "self-service-portal"
      ],
      "created_at": "2020-01-24T22:39:49Z",
      "updated_at": "2026-02-07T02:09:12Z",
      "pushed_at": "2026-02-07T01:11:57Z",
      "open_issues": 427,
      "owner": {
        "login": "backstage",
        "avatar_url": "https://avatars.githubusercontent.com/u/72526453?v=4"
      },
      "readme": "[![headline](docs/assets/headline.png)](https://backstage.io/)\n\n# [Backstage](https://backstage.io)\n\nEnglish \\| [í•œêµ­ì–´](README-ko_kr.md) \\| [ä¸­æ–‡ç‰ˆ](README-zh_Hans.md) \\| [FranÃ§ais](README-fr_FR.md)\n\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n[![CNCF Status](https://img.shields.io/badge/cncf%20status-incubation-blue.svg)](https://www.cncf.io/projects)\n[![Discord](https://img.shields.io/discord/687207715902193673?logo=discord&label=Discord&color=5865F2&logoColor=white)](https://discord.gg/backstage-687207715902193673)\n![Code style](https://img.shields.io/badge/code_style-prettier-ff69b4.svg)\n[![Codecov](https://img.shields.io/codecov/c/github/backstage/backstage)](https://codecov.io/gh/backstage/backstage)\n[![](https://img.shields.io/github/v/release/backstage/backstage)](https://github.com/backstage/backstage/releases)\n[![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/7678/badge)](https://bestpractices.coreinfrastructure.org/projects/7678)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/backstage/backstage/badge)](https://securityscorecards.dev/viewer/?uri=github.com/backstage/backstage)\n\n## What is Backstage?\n\n[Backstage](https://backstage.io/) is an open source framework for building developer portals. Powered by a centralized software catalog, Backstage restores order to your microservices and infrastructure and enables your product teams to ship high-quality code quickly without compromising autonomy.\n\nBackstage unifies all your infrastructure tooling, services, and documentation to create a streamlined development environment from end to end.\n\n![software-catalog](docs/assets/header.png)\n\nOut of the box, Backstage includes:\n\n- [Backstage Software Catalog](https://backstage.io/docs/features/software-catalog/) for managing all your software such as microservices, libraries, data pipelines, websites, and ML models\n- [Backstage Software Templates](https://backstage.io/docs/features/software-templates/) for quickly spinning up new projects and standardizing your tooling with your organizationâ€™s best practices\n- [Backstage TechDocs](https://backstage.io/docs/features/techdocs/) for making it easy to create, maintain, find, and use technical documentation, using a \"docs like code\" approach\n- Plus, a growing ecosystem of [open source plugins](https://github.com/backstage/backstage/tree/master/plugins) that further expand Backstageâ€™s customizability and functionality\n\nBackstage was created by Spotify but is now hosted by the [Cloud Native Computing Foundation (CNCF)](https://www.cncf.io) as an Incubation level project. For more information, see the [announcement](https://backstage.io/blog/2022/03/16/backstage-turns-two#out-of-the-sandbox-and-into-incubation).\n\n## Project roadmap\n\nFor information about the detailed project roadmap including delivered milestones, see [the Roadmap](https://backstage.io/docs/overview/roadmap).\n\n## Getting Started\n\nTo start using Backstage, see the [Getting Started documentation](https://backstage.io/docs/getting-started).\n\n## Documentation\n\nThe documentation of Backstage includes:\n\n- [Main documentation](https://backstage.io/docs)\n- [Software Catalog](https://backstage.io/docs/features/software-catalog/)\n- [Architecture](https://backstage.io/docs/overview/architecture-overview) ([Decisions](https://backstage.io/docs/architecture-decisions/))\n- [Designing for Backstage](https://backstage.io/docs/dls/design)\n- [Storybook - UI components](https://backstage.io/storybook)\n\n## Community\n\nTo engage with our community, you can use the following resources:\n\n- [Discord chatroom](https://discord.gg/backstage-687207715902193673) - Get support or discuss the project\n- [Contributing to Backstage](https://github.com/backstage/backstage/blob/master/CONTRIBUTING.md) - Start here if you want to contribute\n- [RFCs](https://github.com/backstage/backstage/labels/rfc) - Help shape the technical direction\n- [FAQ](https://backstage.io/docs/faq) - Frequently Asked Questions\n- [Code of Conduct](CODE_OF_CONDUCT.md) - This is how we roll\n- [Adopters](ADOPTERS.md) - Companies already using Backstage\n- [Blog](https://backstage.io/blog/) - Announcements and updates\n- [Newsletter](https://spoti.fi/backstagenewsletter) - Subscribe to our email newsletter\n- [Backstage Community Sessions](https://github.com/backstage/community) - Join monthly meetups and explore Backstage community\n- Give us a star â­ï¸ - If you are using Backstage or think it is an interesting project, we would love a star â¤ï¸\n\n## Governance\n\nSee the [GOVERNANCE.md](https://github.com/backstage/community/blob/main/GOVERNANCE.md) document in the [backstage/community](https://github.com/backstage/community) repository.\n\n## License\n\nCopyright 2020-2026 Â© The Backstage Authors. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our Trademark Usage page: https://www.linuxfoundation.org/trademark-usage\n\nLicensed under the Apache License, Version 2.0: http://www.apache.org/licenses/LICENSE-2.0\n\n## Security\n\nPlease report sensitive security issues using Spotify's [bug-bounty program](https://hackerone.com/spotify) rather than GitHub.\n\nFor further details, see our complete [security release process](SECURITY.md).\n",
      "stars_today": 10
    },
    {
      "id": 129717717,
      "name": "loki",
      "full_name": "grafana/loki",
      "description": "Like Prometheus, but for logs.",
      "html_url": "https://github.com/grafana/loki",
      "stars": 27554,
      "forks": 3920,
      "language": "Go",
      "topics": [
        "cloudnative",
        "grafana",
        "hacktoberfest",
        "logging",
        "loki",
        "prometheus"
      ],
      "created_at": "2018-04-16T09:22:48Z",
      "updated_at": "2026-02-07T02:12:42Z",
      "pushed_at": "2026-02-07T02:29:52Z",
      "open_issues": 2230,
      "owner": {
        "login": "grafana",
        "avatar_url": "https://avatars.githubusercontent.com/u/7195757?v=4"
      },
      "readme": "<p align=\"center\"><img src=\"docs/sources/logo_and_name.png\" alt=\"Loki Logo\"></p>\n\n<a href=\"https://github.com/grafana/loki/actions/workflows/check.yml\"><img src=\"https://github.com/grafana/loki/actions/workflows/check.yml/badge.svg\" alt=\"Check\" /></a>\n<a href=\"https://goreportcard.com/report/github.com/grafana/loki\"><img src=\"https://goreportcard.com/badge/github.com/grafana/loki\" alt=\"Go Report Card\" /></a>\n<a href=\"https://slack.grafana.com/\"><img src=\"https://img.shields.io/badge/join%20slack-%23loki-brightgreen.svg\" alt=\"Slack\" /></a>\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/loki.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:loki)\n\n# Loki: like Prometheus, but for logs.\n\nLoki is a horizontally-scalable, highly-available, multi-tenant log aggregation system inspired by [Prometheus](https://prometheus.io/).\nIt is designed to be very cost effective and easy to operate.\nIt does not index the contents of the logs, but rather a set of labels for each log stream.\n\nCompared to other log aggregation systems, Loki:\n\n- does not do full text indexing on logs. By storing compressed, unstructured logs and only indexing metadata, Loki is simpler to operate and cheaper to run.\n- indexes and groups log streams using the same labels youâ€™re already using with Prometheus, enabling you to seamlessly switch between metrics and logs using the same labels that youâ€™re already using with Prometheus.\n- is an especially good fit for storing [Kubernetes](https://kubernetes.io/) Pod logs. Metadata such as Pod labels is automatically scraped and indexed.\n- has native support in Grafana (needs Grafana v6.0).\n\nA Loki-based logging stack consists of 3 components:\n\n- [Alloy](https://github.com/grafana/alloy) is agent, responsible for gathering logs and sending them to Loki.\n- [Loki](https://github.com/grafana/loki) is the main service, responsible for storing logs and processing queries.\n- [Grafana](https://github.com/grafana/grafana) for querying and displaying the logs.\n\n**Note that Alloy replaced Promtail in the stack, because Promtail is considered to be feature complete, and future development for logs collection will be in [Grafana Alloy](https://github.com/grafana/alloy).**\n\nLoki is like Prometheus, but for logs: we prefer a multidimensional label-based approach to indexing, and want a single-binary, easy to operate system with no dependencies.\nLoki differs from Prometheus by focusing on logs instead of metrics, and delivering logs via push, instead of pull.\n\n## Getting started\n\n* [Installing Loki](https://grafana.com/docs/loki/latest/installation/)\n* [Installing Alloy](https://grafana.com/docs/loki/latest/send-data/alloy/)\n* [Getting Started](https://grafana.com/docs/loki/latest/get-started/)\n\n## Upgrading\n\n* [Upgrading Loki](https://grafana.com/docs/loki/latest/upgrading/)\n\n## Documentation\n\n* [Latest release](https://grafana.com/docs/loki/latest/)\n* [Upcoming release](https://grafana.com/docs/loki/next/), at the tip of the main branch\n\nCommonly used sections:\n\n- [API documentation](https://grafana.com/docs/loki/latest/api/) for getting logs into Loki.\n- [Labels](https://grafana.com/docs/loki/latest/getting-started/labels/)\n- [Operations](https://grafana.com/docs/loki/latest/operations/)\n- [Promtail](https://grafana.com/docs/loki/latest/clients/promtail/) is an agent which tails log files and pushes them to Loki.\n- [Pipelines](https://grafana.com/docs/loki/latest/clients/promtail/pipelines/) details the log processing pipeline.\n- [Docker Driver Client](https://grafana.com/docs/loki/latest/clients/docker-driver/) is a Docker plugin to send logs directly to Loki from Docker containers.\n- [LogCLI](https://grafana.com/docs/loki/latest/query/logcli/) provides a command-line interface for querying logs.\n- [Loki Canary](https://grafana.com/docs/loki/latest/operations/loki-canary/) monitors your Loki installation for missing logs.\n- [Troubleshooting](https://grafana.com/docs/loki/latest/operations/troubleshooting/) presents help dealing with error messages.\n- [Loki in Grafana](https://grafana.com/docs/loki/latest/operations/grafana/) describes how to set up a Loki datasource in Grafana.\n\n## Getting Help\n\nIf you have any questions or feedback regarding Loki:\n\n- Search existing thread in the Grafana Labs community forum for Loki: [https://community.grafana.com](https://community.grafana.com/c/grafana-loki/)\n- Ask a question on the Loki Slack channel. To invite yourself to the Grafana Slack, visit [https://slack.grafana.com/](https://slack.grafana.com/) and join the #loki channel.\n- [File an issue](https://github.com/grafana/loki/issues/new) for bugs, issues and feature suggestions.\n- Send an email to [lokiproject@googlegroups.com](mailto:lokiproject@googlegroups.com), or use the [web interface](https://groups.google.com/forum/#!forum/lokiproject).\n- UI issues should be filed directly in [Grafana](https://github.com/grafana/grafana/issues/new).\n\nYour feedback is always welcome.\n\n## Further Reading\n\n- The original [design doc](https://docs.google.com/document/d/11tjK_lvp1-SVsFZjgOTr1vV3-q6vBAsZYIQ5ZeYBkyM/view) for Loki is a good source for discussion of the motivation and design decisions.\n- Callum Styan's March 2019 DevOpsDays Vancouver talk \"[Grafana Loki: Log Aggregation for Incident Investigations][devopsdays19-talk]\".\n- Grafana Labs blog post \"[How We Designed Loki to Work Easily Both as Microservices and as Monoliths][architecture-blog]\".\n- Tom Wilkie's early-2019 CNCF Paris/FOSDEM talk \"[Grafana Loki: like Prometheus, but for logs][fosdem19-talk]\" ([slides][fosdem19-slides], [video][fosdem19-video]).\n- David Kaltschmidt's KubeCon 2018 talk \"[On the OSS Path to Full Observability with Grafana][kccna18-event]\" ([slides][kccna18-slides], [video][kccna18-video]) on how Loki fits into a cloud-native environment.\n- Goutham Veeramachaneni's blog post \"[Loki: Prometheus-inspired, open source logging for cloud natives](https://grafana.com/blog/2018/12/12/loki-prometheus-inspired-open-source-logging-for-cloud-natives/)\" on details of the Loki architecture.\n- David Kaltschmidt's blog post \"[Closer look at Grafana's user interface for Loki](https://grafana.com/blog/2019/01/02/closer-look-at-grafanas-user-interface-for-loki/)\" on the ideas that went into the logging user interface.\n\n[devopsdays19-talk]: https://grafana.com/blog/2019/05/06/how-loki-correlates-metrics-and-logs-and-saves-you-money/\n[architecture-blog]: https://grafana.com/blog/2019/04/15/how-we-designed-loki-to-work-easily-both-as-microservices-and-as-monoliths/\n[fosdem19-talk]: https://fosdem.org/2019/schedule/event/loki_prometheus_for_logs/\n[fosdem19-slides]: https://speakerdeck.com/grafana/grafana-loki-like-prometheus-but-for-logs\n[fosdem19-video]: https://mirror.as35701.net/video.fosdem.org/2019/UB2.252A/loki_prometheus_for_logs.mp4\n[kccna18-event]: https://kccna18.sched.com/event/GrXC/on-the-oss-path-to-full-observability-with-grafana-david-kaltschmidt-grafana-labs\n[kccna18-slides]: https://speakerdeck.com/davkal/on-the-path-to-full-observability-with-oss-and-launch-of-loki\n[kccna18-video]: https://www.youtube.com/watch?v=U7C5SpRtK74&list=PLj6h78yzYM2PZf9eA7bhWnIh_mK1vyOfU&index=346\n\n## Contributing\n\nRefer to [CONTRIBUTING.md](CONTRIBUTING.md)\n\n### Building from source\n\nLoki can be run in a single host, no-dependencies mode using the following commands.\n\nYou need an up-to-date version of [Go](https://go.dev/), we recommend using the version found in our [Makefile](https://github.com/grafana/loki/blob/main/Makefile)\n\n```bash\n# Checkout source code\n$ git clone https://github.com/grafana/loki\n$ cd loki\n\n# Build binary\n$ go build ./cmd/loki\n\n# Run executable\n$ ./loki -config.file=./cmd/loki/loki-local-config.yaml\n```\n\nAlternatively, on Unix systems you can use `make` to build the binary, which adds additional arguments to the `go build` command.\n\n```bash\n# Build binary\n$ make loki\n\n# Run executable\n$ ./cmd/loki/loki -config.file=./cmd/loki/loki-local-config.yaml\n```\n\nTo build Promtail on non-Linux platforms, use the following command:\n\n```bash\n$ go build ./clients/cmd/promtail\n```\n\nOn Linux, Promtail requires the systemd headers to be installed if\nJournal support is enabled.\nTo enable Journal support the go build tag flag `promtail_journal_enabled` should be passed\n\nWith Journal support on Ubuntu, run with the following commands:\n\n```bash\n$ sudo apt install -y libsystemd-dev\n$ go build --tags=promtail_journal_enabled ./clients/cmd/promtail\n```\n\nWith Journal support on CentOS, run with the following commands:\n\n```bash\n$ sudo yum install -y systemd-devel\n$ go build --tags=promtail_journal_enabled ./clients/cmd/promtail\n```\n\nOtherwise, to build Promtail without Journal support, run `go build`\nwith CGO disabled:\n\n```bash\n$ CGO_ENABLED=0 go build ./clients/cmd/promtail\n```\n\n## Adopters\n\nPlease see [ADOPTERS.md](ADOPTERS.md) for some of the organizations using Loki today.\nIf you would like to add your organization to the list, please open a PR to add it to the list.\n\n## License\n\nGrafana Loki is distributed under [AGPL-3.0-only](LICENSE). For Apache-2.0 exceptions, see [LICENSING.md](LICENSING.md).\n",
      "stars_today": 10
    },
    {
      "id": 19953044,
      "name": "flatbuffers",
      "full_name": "google/flatbuffers",
      "description": "FlatBuffers: Memory Efficient Serialization Library",
      "html_url": "https://github.com/google/flatbuffers",
      "stars": 25528,
      "forks": 3492,
      "language": "C++",
      "topics": [
        "c",
        "c-plus-plus",
        "c-sharp",
        "cross-platform",
        "flatbuffers",
        "go",
        "grpc",
        "java",
        "javascript",
        "json-parser",
        "marshalling",
        "mmap",
        "protobuf",
        "python",
        "rpc",
        "rust",
        "serialization",
        "serialization-library",
        "typescript",
        "zero-copy"
      ],
      "created_at": "2014-05-19T18:33:01Z",
      "updated_at": "2026-02-06T18:32:04Z",
      "pushed_at": "2026-02-06T22:24:09Z",
      "open_issues": 141,
      "owner": {
        "login": "google",
        "avatar_url": "https://avatars.githubusercontent.com/u/1342004?v=4"
      },
      "readme": "![logo](https://flatbuffers.dev/assets/flatbuffers_logo.svg) FlatBuffers\n===========\n\n![Build status](https://github.com/google/flatbuffers/actions/workflows/build.yml/badge.svg?branch=master)\n[![BuildKite status](https://badge.buildkite.com/7979d93bc6279aa539971f271253c65d5e8fe2fe43c90bbb25.svg)](https://buildkite.com/bazel/flatbuffers)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/flatbuffers.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:flatbuffers)\n[![Discord Chat](https://img.shields.io/discord/656202785926152206.svg)](https:///discord.gg/6qgKs3R)\n[![Twitter Follow](https://img.shields.io/twitter/follow/wvo.svg?style=social)](https://twitter.com/wvo)\n[![Twitter Follow](https://img.shields.io/twitter/follow/dbaileychess.svg?style=social)](https://twitter.com/dbaileychess)\n\n\n**FlatBuffers** is a cross platform serialization library architected for\nmaximum memory efficiency. It allows you to directly access serialized data without parsing/unpacking it first, while still having great forwards/backwards compatibility.\n\n## Quick Start\n\n1. Build the compiler for flatbuffers (`flatc`)\n\n    Use `cmake` to create the build files for your platform and then perform the compilation (Linux example).\n\n    ```\n    cmake -G \"Unix Makefiles\"\n    make -j\n    ```\n\n2. Define your flatbuffer schema (`.fbs`)\n\n    Write the [schema](https://flatbuffers.dev/flatbuffers_guide_writing_schema.html) to define the data you want to serialize. See [monster.fbs](https://github.com/google/flatbuffers/blob/master/samples/monster.fbs) for an example.\n\n3. Generate code for your language(s)\n\n    Use the `flatc` compiler to take your schema and generate language-specific code:\n\n    ```\n    ./flatc --cpp --rust monster.fbs\n    ```\n\n    Which generates `monster_generated.h` and `monster_generated.rs` files.\n\n4. Serialize data\n\n    Use the generated code, as well as the `FlatBufferBuilder` to construct your serialized buffer. ([`C++` example](https://github.com/google/flatbuffers/blob/master/samples/sample_binary.cpp#L24-L56))\n\n5. Transmit/store/save Buffer\n\n    Use your serialized buffer however you want. Send it to someone, save it for later, etc...\n\n6. Read the data\n\n    Use the generated accessors to read the data from the serialized buffer.\n\n    It doesn't need to be the same language/schema version, FlatBuffers ensures the data is readable across languages and schema versions. See the [`Rust` example](https://github.com/google/flatbuffers/blob/master/samples/sample_binary.rs#L92-L106) reading the data written by `C++`.\n\n## Documentation\n\n**Go to our [landing page][] to browse our documentation.**\n\n## Supported operating systems\n- Windows\n- macOS\n- Linux\n- Android\n- And any others with a recent C++ compiler (C++ 11 and newer)\n\n## Supported programming languages\n\nCode generation and runtime libraries for many popular languages.\n\n1. C\n1. C++ - [snapcraft.io](https://snapcraft.io/flatbuffers)\n1. C# - [nuget.org](https://www.nuget.org/packages/Google.FlatBuffers)\n1. Dart - [pub.dev](https://pub.dev/packages/flat_buffers)\n1. Go - [go.dev](https://pkg.go.dev/github.com/google/flatbuffers)\n1. Java - [Maven](https://search.maven.org/artifact/com.google.flatbuffers/flatbuffers-java)\n1. JavaScript - [NPM](https://www.npmjs.com/package/flatbuffers)\n1. Kotlin\n1. Lobster\n1. Lua\n1. PHP\n1. Python - [PyPI](https://pypi.org/project/flatbuffers/)\n1. Rust - [crates.io](https://crates.io/crates/flatbuffers)\n1. Swift - [swiftpackageindex](https://swiftpackageindex.com/google/flatbuffers)\n1. TypeScript - [NPM](https://www.npmjs.com/package/flatbuffers)\n1. Nim\n\n## Versioning\n\nFlatBuffers does not follow traditional SemVer versioning (see [rationale](https://github.com/google/flatbuffers/wiki/Versioning)) but rather uses a format of the date of the release.\n\n## Contribution\n\n* [FlatBuffers Issues Tracker][] to submit an issue.\n* [stackoverflow.com][] with [`flatbuffers` tag][] for any questions regarding FlatBuffers.\n\n*To contribute to this project,* see [CONTRIBUTING][].\n\n## Community\n\n* [Discord Server](https:///discord.gg/6qgKs3R)\n\n## Security\n\nPlease see our [Security Policy](SECURITY.md) for reporting vulnerabilities.\n\n## Licensing\n*Flatbuffers* is licensed under the Apache License, Version 2.0. See [LICENSE][] for the full license text.\n\n<br>\n\n   [CONTRIBUTING]: http://github.com/google/flatbuffers/blob/master/CONTRIBUTING.md\n   [`flatbuffers` tag]: https://stackoverflow.com/questions/tagged/flatbuffers\n   [FlatBuffers Google Group]: https://groups.google.com/forum/#!forum/flatbuffers\n   [FlatBuffers Issues Tracker]: http://github.com/google/flatbuffers/issues\n   [stackoverflow.com]: http://stackoverflow.com/search?q=flatbuffers\n   [landing page]: https://google.github.io/flatbuffers\n   [LICENSE]: https://github.com/google/flatbuffers/blob/master/LICENSE\n",
      "stars_today": 10
    },
    {
      "id": 581338100,
      "name": "ChameleonUltra",
      "full_name": "RfidResearchGroup/ChameleonUltra",
      "description": "The new generation chameleon based on NRF52840 makes the performance of card emulation more stable. And gave the chameleon the ability to read, write, and decrypt cards.",
      "html_url": "https://github.com/RfidResearchGroup/ChameleonUltra",
      "stars": 2235,
      "forks": 321,
      "language": "C",
      "topics": [
        "125khz",
        "chameleon",
        "chameleonultra",
        "detection",
        "iso14443a",
        "mifare",
        "nfc",
        "ntag",
        "rfid",
        "simulate",
        "ultralight"
      ],
      "created_at": "2022-12-22T22:53:04Z",
      "updated_at": "2026-02-06T22:58:12Z",
      "pushed_at": "2026-02-06T23:00:33Z",
      "open_issues": 88,
      "owner": {
        "login": "RfidResearchGroup",
        "avatar_url": "https://avatars.githubusercontent.com/u/40314039?v=4"
      },
      "readme": "![logo](docs/images/ultra-logo.png)\n\n![ultra picture](docs/images/ultra-overview.png)\n\n# ChameleonUltra Authorized Distributors\n\nLyon, France: [Lab401](https://lab401.com/)\n\nSanta Ana, United States: [Hackerwarehouse](https://hackerwarehouse.com/)\n\nHastings, UK: [KSEC](https://labs.ksec.co.uk/product/proxgrind-chameleon-ultra/)\n\nMontreal, Canada: [TechSecurityTools](https://techsecuritytools.com/product/chameleon-ultra/)\n\nShenzhen, China: [Sneaktechnology](https://sneaktechnology.com)\n\nGuangdong, China: [MTools Tec](https://shop.mtoolstec.com/)\n\nLazada One, Singapore: [Aliexpress by RRG](https://proxgrind.aliexpress.com/store/1101312023)\n\n# What is it and how to use ?\n\nRead the [available documentation](https://github.com/RfidResearchGroup/ChameleonUltra/wiki).\n\n# Compatible applications\n\n* [ChameleonUltraGUI](https://github.com/GameTec-live/ChameleonUltraGUI)\n* [MTools BLE](https://github.com/RfidResearchGroup/ChameleonUltra/wiki/mtoolsble)\n\n# Videos\n\n*Beware some of the instructions might have changed since recording, check the current documentation when in doubt!*\n\n* [Downloading and compiling the official CLI](https://www.youtube.com/watch?v=VGpAeitNXH0)\n* [Downloading ChameleonUltraGUI](https://www.youtube.com/watch?v=rHH7iqbX3nY)\n* [ChameleonUltraGUI features overview](https://www.youtube.com/watch?v=YqE8wyVSse4)\n* [Using ChameleonUltraGUI and the Chameleon Ultra](https://www.youtube.com/watch?v=9jtKNJ5-kVY)\n* [MTools BLE - How to clone a card with ChameleonUltra](https://youtu.be/IvH-xtdW1Wk?si=4exqgAAeJ-kxU3aN)\n\n# Official channels\n\nWhere do you find the community?\n* [RFID Hacking community discord server](https://t.ly/d4_C)\n  * Software/chameleon-dev for firmware and clients development discussions\n  * Devices/chameleon-ultra for usage discussions\n* [GameTec_live discord server](https://discord.gg/DJ2A4wxncK)\n\n###### Searching for the docs repo? Find it [here](https://github.com/RfidResearchGroup/ChameleonUltraDocs)",
      "stars_today": 10
    },
    {
      "id": 44344606,
      "name": "chi",
      "full_name": "go-chi/chi",
      "description": "lightweight, idiomatic and composable router for building Go HTTP services",
      "html_url": "https://github.com/go-chi/chi",
      "stars": 21528,
      "forks": 1070,
      "language": "Go",
      "topics": [
        "api",
        "context",
        "go",
        "golang",
        "http",
        "microservices",
        "middleware",
        "rest-api",
        "router"
      ],
      "created_at": "2015-10-15T20:46:29Z",
      "updated_at": "2026-02-06T21:59:33Z",
      "pushed_at": "2026-02-05T11:17:55Z",
      "open_issues": 93,
      "owner": {
        "login": "go-chi",
        "avatar_url": "https://avatars.githubusercontent.com/u/29575368?v=4"
      },
      "readme": "# <img alt=\"chi\" src=\"https://cdn.rawgit.com/go-chi/chi/master/_examples/chi.svg\" width=\"220\" />\n\n\n[![GoDoc Widget]][GoDoc]\n\n`chi` is a lightweight, idiomatic and composable router for building Go HTTP services. It's\nespecially good at helping you write large REST API services that are kept maintainable as your\nproject grows and changes. `chi` is built on the new `context` package introduced in Go 1.7 to\nhandle signaling, cancelation and request-scoped values across a handler chain.\n\nThe focus of the project has been to seek out an elegant and comfortable design for writing\nREST API servers, written during the development of the Pressly API service that powers our\npublic API service, which in turn powers all of our client-side applications.\n\nThe key considerations of chi's design are: project structure, maintainability, standard http\nhandlers (stdlib-only), developer productivity, and deconstructing a large system into many small\nparts. The core router `github.com/go-chi/chi` is quite small (less than 1000 LOC), but we've also\nincluded some useful/optional subpackages: [middleware](/middleware), [render](https://github.com/go-chi/render)\nand [docgen](https://github.com/go-chi/docgen). We hope you enjoy it too!\n\n## Install\n\n```sh\ngo get -u github.com/go-chi/chi/v5\n```\n\n\n## Features\n\n* **Lightweight** - cloc'd in ~1000 LOC for the chi router\n* **Fast** - yes, see [benchmarks](#benchmarks)\n* **100% compatible with net/http** - use any http or middleware pkg in the ecosystem that is also compatible with `net/http`\n* **Designed for modular/composable APIs** - middlewares, inline middlewares, route groups and sub-router mounting\n* **Context control** - built on new `context` package, providing value chaining, cancellations and timeouts\n* **Robust** - in production at Pressly, Cloudflare, Heroku, 99Designs, and many others (see [discussion](https://github.com/go-chi/chi/issues/91))\n* **Doc generation** - `docgen` auto-generates routing documentation from your source to JSON or Markdown\n* **Go.mod support** - as of v5, go.mod support (see [CHANGELOG](https://github.com/go-chi/chi/blob/master/CHANGELOG.md))\n* **No external dependencies** - plain ol' Go stdlib + net/http\n\n\n## Examples\n\nSee [_examples/](https://github.com/go-chi/chi/blob/master/_examples/) for a variety of examples.\n\n\n**As easy as:**\n\n```go\npackage main\n\nimport (\n\t\"net/http\"\n\n\t\"github.com/go-chi/chi/v5\"\n\t\"github.com/go-chi/chi/v5/middleware\"\n)\n\nfunc main() {\n\tr := chi.NewRouter()\n\tr.Use(middleware.Logger)\n\tr.Get(\"/\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Write([]byte(\"welcome\"))\n\t})\n\thttp.ListenAndServe(\":3000\", r)\n}\n```\n\n**REST Preview:**\n\nHere is a little preview of what routing looks like with chi. Also take a look at the generated routing docs\nin JSON ([routes.json](https://github.com/go-chi/chi/blob/master/_examples/rest/routes.json)) and in\nMarkdown ([routes.md](https://github.com/go-chi/chi/blob/master/_examples/rest/routes.md)).\n\nI highly recommend reading the source of the [examples](https://github.com/go-chi/chi/blob/master/_examples/) listed\nabove, they will show you all the features of chi and serve as a good form of documentation.\n\n```go\nimport (\n  //...\n  \"context\"\n  \"github.com/go-chi/chi/v5\"\n  \"github.com/go-chi/chi/v5/middleware\"\n)\n\nfunc main() {\n  r := chi.NewRouter()\n\n  // A good base middleware stack\n  r.Use(middleware.RequestID)\n  r.Use(middleware.RealIP)\n  r.Use(middleware.Logger)\n  r.Use(middleware.Recoverer)\n\n  // Set a timeout value on the request context (ctx), that will signal\n  // through ctx.Done() that the request has timed out and further\n  // processing should be stopped.\n  r.Use(middleware.Timeout(60 * time.Second))\n\n  r.Get(\"/\", func(w http.ResponseWriter, r *http.Request) {\n    w.Write([]byte(\"hi\"))\n  })\n\n  // RESTy routes for \"articles\" resource\n  r.Route(\"/articles\", func(r chi.Router) {\n    r.With(paginate).Get(\"/\", listArticles)                           // GET /articles\n    r.With(paginate).Get(\"/{month}-{day}-{year}\", listArticlesByDate) // GET /articles/01-16-2017\n\n    r.Post(\"/\", createArticle)                                        // POST /articles\n    r.Get(\"/search\", searchArticles)                                  // GET /articles/search\n\n    // Regexp url parameters:\n    r.Get(\"/{articleSlug:[a-z-]+}\", getArticleBySlug)                // GET /articles/home-is-toronto\n\n    // Subrouters:\n    r.Route(\"/{articleID}\", func(r chi.Router) {\n      r.Use(ArticleCtx)\n      r.Get(\"/\", getArticle)                                          // GET /articles/123\n      r.Put(\"/\", updateArticle)                                       // PUT /articles/123\n      r.Delete(\"/\", deleteArticle)                                    // DELETE /articles/123\n    })\n  })\n\n  // Mount the admin sub-router\n  r.Mount(\"/admin\", adminRouter())\n\n  http.ListenAndServe(\":3333\", r)\n}\n\nfunc ArticleCtx(next http.Handler) http.Handler {\n  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n    articleID := chi.URLParam(r, \"articleID\")\n    article, err := dbGetArticle(articleID)\n    if err != nil {\n      http.Error(w, http.StatusText(404), 404)\n      return\n    }\n    ctx := context.WithValue(r.Context(), \"article\", article)\n    next.ServeHTTP(w, r.WithContext(ctx))\n  })\n}\n\nfunc getArticle(w http.ResponseWriter, r *http.Request) {\n  ctx := r.Context()\n  article, ok := ctx.Value(\"article\").(*Article)\n  if !ok {\n    http.Error(w, http.StatusText(422), 422)\n    return\n  }\n  w.Write([]byte(fmt.Sprintf(\"title:%s\", article.Title)))\n}\n\n// A completely separate router for administrator routes\nfunc adminRouter() http.Handler {\n  r := chi.NewRouter()\n  r.Use(AdminOnly)\n  r.Get(\"/\", adminIndex)\n  r.Get(\"/accounts\", adminListAccounts)\n  return r\n}\n\nfunc AdminOnly(next http.Handler) http.Handler {\n  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n    ctx := r.Context()\n    perm, ok := ctx.Value(\"acl.permission\").(YourPermissionType)\n    if !ok || !perm.IsAdmin() {\n      http.Error(w, http.StatusText(403), 403)\n      return\n    }\n    next.ServeHTTP(w, r)\n  })\n}\n```\n\n\n## Router interface\n\nchi's router is based on a kind of [Patricia Radix trie](https://en.wikipedia.org/wiki/Radix_tree).\nThe router is fully compatible with `net/http`.\n\nBuilt on top of the tree is the `Router` interface:\n\n```go\n// Router consisting of the core routing methods used by chi's Mux,\n// using only the standard net/http.\ntype Router interface {\n\thttp.Handler\n\tRoutes\n\n\t// Use appends one or more middlewares onto the Router stack.\n\tUse(middlewares ...func(http.Handler) http.Handler)\n\n\t// With adds inline middlewares for an endpoint handler.\n\tWith(middlewares ...func(http.Handler) http.Handler) Router\n\n\t// Group adds a new inline-Router along the current routing\n\t// path, with a fresh middleware stack for the inline-Router.\n\tGroup(fn func(r Router)) Router\n\n\t// Route mounts a sub-Router along a `pattern` string.\n\tRoute(pattern string, fn func(r Router)) Router\n\n\t// Mount attaches another http.Handler along ./pattern/*\n\tMount(pattern string, h http.Handler)\n\n\t// Handle and HandleFunc adds routes for `pattern` that matches\n\t// all HTTP methods.\n\tHandle(pattern string, h http.Handler)\n\tHandleFunc(pattern string, h http.HandlerFunc)\n\n\t// Method and MethodFunc adds routes for `pattern` that matches\n\t// the `method` HTTP method.\n\tMethod(method, pattern string, h http.Handler)\n\tMethodFunc(method, pattern string, h http.HandlerFunc)\n\n\t// HTTP-method routing along `pattern`\n\tConnect(pattern string, h http.HandlerFunc)\n\tDelete(pattern string, h http.HandlerFunc)\n\tGet(pattern string, h http.HandlerFunc)\n\tHead(pattern string, h http.HandlerFunc)\n\tOptions(pattern string, h http.HandlerFunc)\n\tPatch(pattern string, h http.HandlerFunc)\n\tPost(pattern string, h http.HandlerFunc)\n\tPut(pattern string, h http.HandlerFunc)\n\tTrace(pattern string, h http.HandlerFunc)\n\n\t// NotFound defines a handler to respond whenever a route could\n\t// not be found.\n\tNotFound(h http.HandlerFunc)\n\n\t// MethodNotAllowed defines a handler to respond whenever a method is\n\t// not allowed.\n\tMethodNotAllowed(h http.HandlerFunc)\n}\n\n// Routes interface adds two methods for router traversal, which is also\n// used by the github.com/go-chi/docgen package to generate documentation for Routers.\ntype Routes interface {\n\t// Routes returns the routing tree in an easily traversable structure.\n\tRoutes() []Route\n\n\t// Middlewares returns the list of middlewares in use by the router.\n\tMiddlewares() Middlewares\n\n\t// Match searches the routing tree for a handler that matches\n\t// the method/path - similar to routing a http request, but without\n\t// executing the handler thereafter.\n\tMatch(rctx *Context, method, path string) bool\n}\n```\n\nEach routing method accepts a URL `pattern` and chain of `handlers`. The URL pattern\nsupports named params (ie. `/users/{userID}`) and wildcards (ie. `/admin/*`). URL parameters\ncan be fetched at runtime by calling `chi.URLParam(r, \"userID\")` for named parameters\nand `chi.URLParam(r, \"*\")` for a wildcard parameter.\n\n\n### Middleware handlers\n\nchi's middlewares are just stdlib net/http middleware handlers. There is nothing special\nabout them, which means the router and all the tooling is designed to be compatible and\nfriendly with any middleware in the community. This offers much better extensibility and reuse\nof packages and is at the heart of chi's purpose.\n\nHere is an example of a standard net/http middleware where we assign a context key `\"user\"`\nthe value of `\"123\"`. This middleware sets a hypothetical user identifier on the request\ncontext and calls the next handler in the chain.\n\n```go\n// HTTP middleware setting a value on the request context\nfunc MyMiddleware(next http.Handler) http.Handler {\n  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n    // create new context from `r` request context, and assign key `\"user\"`\n    // to value of `\"123\"`\n    ctx := context.WithValue(r.Context(), \"user\", \"123\")\n\n    // call the next handler in the chain, passing the response writer and\n    // the updated request object with the new context value.\n    //\n    // note: context.Context values are nested, so any previously set\n    // values will be accessible as well, and the new `\"user\"` key\n    // will be accessible from this point forward.\n    next.ServeHTTP(w, r.WithContext(ctx))\n  })\n}\n```\n\n\n### Request handlers\n\nchi uses standard net/http request handlers. This little snippet is an example of a http.Handler\nfunc that reads a user identifier from the request context - hypothetically, identifying\nthe user sending an authenticated request, validated+set by a previous middleware handler.\n\n```go\n// HTTP handler accessing data from the request context.\nfunc MyRequestHandler(w http.ResponseWriter, r *http.Request) {\n  // here we read from the request context and fetch out `\"user\"` key set in\n  // the MyMiddleware example above.\n  user := r.Context().Value(\"user\").(string)\n\n  // respond to the client\n  w.Write([]byte(fmt.Sprintf(\"hi %s\", user)))\n}\n```\n\n\n### URL parameters\n\nchi's router parses and stores URL parameters right onto the request context. Here is\nan example of how to access URL params in your net/http handlers. And of course, middlewares\nare able to access the same information.\n\n```go\n// HTTP handler accessing the url routing parameters.\nfunc MyRequestHandler(w http.ResponseWriter, r *http.Request) {\n  // fetch the url parameter `\"userID\"` from the request of a matching\n  // routing pattern. An example routing pattern could be: /users/{userID}\n  userID := chi.URLParam(r, \"userID\")\n\n  // fetch `\"key\"` from the request context\n  ctx := r.Context()\n  key := ctx.Value(\"key\").(string)\n\n  // respond to the client\n  w.Write([]byte(fmt.Sprintf(\"hi %v, %v\", userID, key)))\n}\n```\n\n\n## Middlewares\n\nchi comes equipped with an optional `middleware` package, providing a suite of standard\n`net/http` middlewares. Please note, any middleware in the ecosystem that is also compatible\nwith `net/http` can be used with chi's mux.\n\n### Core middlewares\n\n----------------------------------------------------------------------------------------------------\n| chi/middleware Handler | description                                                             |\n| :--------------------- | :---------------------------------------------------------------------- |\n| [AllowContentEncoding] | Enforces a whitelist of request Content-Encoding headers                |\n| [AllowContentType]     | Explicit whitelist of accepted request Content-Types                    |\n| [BasicAuth]            | Basic HTTP authentication                                               |\n| [Compress]             | Gzip compression for clients that accept compressed responses           |\n| [ContentCharset]       | Ensure charset for Content-Type request headers                         |\n| [CleanPath]            | Clean double slashes from request path                                  |\n| [GetHead]              | Automatically route undefined HEAD requests to GET handlers             |\n| [Heartbeat]            | Monitoring endpoint to check the servers pulse                          |\n| [Logger]               | Logs the start and end of each request with the elapsed processing time |\n| [NoCache]              | Sets response headers to prevent clients from caching                   |\n| [Profiler]             | Easily attach net/http/pprof to your routers                            |\n| [RealIP]               | Sets a http.Request's RemoteAddr to either X-Real-IP or X-Forwarded-For |\n| [Recoverer]            | Gracefully absorb panics and prints the stack trace                     |\n| [RequestID]            | Injects a request ID into the context of each request                   |\n| [RedirectSlashes]      | Redirect slashes on routing paths                                       |\n| [RouteHeaders]         | Route handling for request headers                                      |\n| [SetHeader]            | Short-hand middleware to set a response header key/value                |\n| [StripSlashes]         | Strip slashes on routing paths                                          |\n| [Sunset]               | Sunset set Deprecation/Sunset header to response                        |\n| [Throttle]             | Puts a ceiling on the number of concurrent requests                     |\n| [Timeout]              | Signals to the request context when the timeout deadline is reached     |\n| [URLFormat]            | Parse extension from url and put it on request context                  |\n| [WithValue]            | Short-hand middleware to set a key/value on the request context         |\n----------------------------------------------------------------------------------------------------\n\n[AllowContentEncoding]: https://pkg.go.dev/github.com/go-chi/chi/middleware#AllowContentEncoding\n[AllowContentType]: https://pkg.go.dev/github.com/go-chi/chi/middleware#AllowContentType\n[BasicAuth]: https://pkg.go.dev/github.com/go-chi/chi/middleware#BasicAuth\n[Compress]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Compress\n[ContentCharset]: https://pkg.go.dev/github.com/go-chi/chi/middleware#ContentCharset\n[CleanPath]: https://pkg.go.dev/github.com/go-chi/chi/middleware#CleanPath\n[GetHead]: https://pkg.go.dev/github.com/go-chi/chi/middleware#GetHead\n[GetReqID]: https://pkg.go.dev/github.com/go-chi/chi/middleware#GetReqID\n[Heartbeat]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Heartbeat\n[Logger]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Logger\n[NoCache]: https://pkg.go.dev/github.com/go-chi/chi/middleware#NoCache\n[Profiler]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Profiler\n[RealIP]: https://pkg.go.dev/github.com/go-chi/chi/middleware#RealIP\n[Recoverer]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Recoverer\n[RedirectSlashes]: https://pkg.go.dev/github.com/go-chi/chi/middleware#RedirectSlashes\n[RequestLogger]: https://pkg.go.dev/github.com/go-chi/chi/middleware#RequestLogger\n[RequestID]: https://pkg.go.dev/github.com/go-chi/chi/middleware#RequestID\n[RouteHeaders]: https://pkg.go.dev/github.com/go-chi/chi/middleware#RouteHeaders\n[SetHeader]: https://pkg.go.dev/github.com/go-chi/chi/middleware#SetHeader\n[StripSlashes]: https://pkg.go.dev/github.com/go-chi/chi/middleware#StripSlashes\n[Sunset]: https://pkg.go.dev/github.com/go-chi/chi/v5/middleware#Sunset\n[Throttle]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Throttle\n[ThrottleBacklog]: https://pkg.go.dev/github.com/go-chi/chi/middleware#ThrottleBacklog\n[ThrottleWithOpts]: https://pkg.go.dev/github.com/go-chi/chi/middleware#ThrottleWithOpts\n[Timeout]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Timeout\n[URLFormat]: https://pkg.go.dev/github.com/go-chi/chi/middleware#URLFormat\n[WithLogEntry]: https://pkg.go.dev/github.com/go-chi/chi/middleware#WithLogEntry\n[WithValue]: https://pkg.go.dev/github.com/go-chi/chi/middleware#WithValue\n[Compressor]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Compressor\n[DefaultLogFormatter]: https://pkg.go.dev/github.com/go-chi/chi/middleware#DefaultLogFormatter\n[EncoderFunc]: https://pkg.go.dev/github.com/go-chi/chi/middleware#EncoderFunc\n[HeaderRoute]: https://pkg.go.dev/github.com/go-chi/chi/middleware#HeaderRoute\n[HeaderRouter]: https://pkg.go.dev/github.com/go-chi/chi/middleware#HeaderRouter\n[LogEntry]: https://pkg.go.dev/github.com/go-chi/chi/middleware#LogEntry\n[LogFormatter]: https://pkg.go.dev/github.com/go-chi/chi/middleware#LogFormatter\n[LoggerInterface]: https://pkg.go.dev/github.com/go-chi/chi/middleware#LoggerInterface\n[ThrottleOpts]: https://pkg.go.dev/github.com/go-chi/chi/middleware#ThrottleOpts\n[WrapResponseWriter]: https://pkg.go.dev/github.com/go-chi/chi/middleware#WrapResponseWriter\n\n### Extra middlewares & packages\n\nPlease see https://github.com/go-chi for additional packages.\n\n--------------------------------------------------------------------------------------------------------------------\n| package                                            | description                                                 |\n|:---------------------------------------------------|:-------------------------------------------------------------\n| [cors](https://github.com/go-chi/cors)             | Cross-origin resource sharing (CORS)                        |\n| [docgen](https://github.com/go-chi/docgen)         | Print chi.Router routes at runtime                          |\n| [jwtauth](https://github.com/go-chi/jwtauth)       | JWT authentication                                          |\n| [hostrouter](https://github.com/go-chi/hostrouter) | Domain/host based request routing                           |\n| [httplog](https://github.com/go-chi/httplog)       | Small but powerful structured HTTP request logging          |\n| [httprate](https://github.com/go-chi/httprate)     | HTTP request rate limiter                                   |\n| [httptracer](https://github.com/go-chi/httptracer) | HTTP request performance tracing library                    |\n| [httpvcr](https://github.com/go-chi/httpvcr)       | Write deterministic tests for external sources              |\n| [stampede](https://github.com/go-chi/stampede)     | HTTP request coalescer                                      |\n--------------------------------------------------------------------------------------------------------------------\n\n\n## context?\n\n`context` is a tiny pkg that provides simple interface to signal context across call stacks\nand goroutines. It was originally written by [Sameer Ajmani](https://github.com/Sajmani)\nand is available in stdlib since go1.7.\n\nLearn more at https://blog.golang.org/context\n\nand..\n* Docs: https://golang.org/pkg/context\n* Source: https://github.com/golang/go/tree/master/src/context\n\n\n## Benchmarks\n\nThe benchmark suite: https://github.com/pkieltyka/go-http-routing-benchmark\n\nResults as of Nov 29, 2020 with Go 1.15.5 on Linux AMD 3950x\n\n```shell\nBenchmarkChi_Param          \t3075895\t        384 ns/op\t      400 B/op      2 allocs/op\nBenchmarkChi_Param5         \t2116603\t        566 ns/op\t      400 B/op      2 allocs/op\nBenchmarkChi_Param20        \t 964117\t       1227 ns/op\t      400 B/op      2 allocs/op\nBenchmarkChi_ParamWrite     \t2863413\t        420 ns/op\t      400 B/op      2 allocs/op\nBenchmarkChi_GithubStatic   \t3045488\t        395 ns/op\t      400 B/op      2 allocs/op\nBenchmarkChi_GithubParam    \t2204115\t        540 ns/op\t      400 B/op      2 allocs/op\nBenchmarkChi_GithubAll      \t  10000\t     113811 ns/op\t    81203 B/op    406 allocs/op\nBenchmarkChi_GPlusStatic    \t3337485\t        359 ns/op\t      400 B/op      2 allocs/op\nBenchmarkChi_GPlusParam     \t2825853\t        423 ns/op\t      400 B/op      2 allocs/op\nBenchmarkChi_GPlus2Params   \t2471697\t        483 ns/op\t      400 B/op      2 allocs/op\nBenchmarkChi_GPlusAll       \t 194220\t       5950 ns/op\t     5200 B/op     26 allocs/op\nBenchmarkChi_ParseStatic    \t3365324\t        356 ns/op\t      400 B/op      2 allocs/op\nBenchmarkChi_ParseParam     \t2976614\t        404 ns/op\t      400 B/op      2 allocs/op\nBenchmarkChi_Parse2Params   \t2638084\t        439 ns/op\t      400 B/op      2 allocs/op\nBenchmarkChi_ParseAll       \t 109567\t      11295 ns/op\t    10400 B/op     52 allocs/op\nBenchmarkChi_StaticAll      \t  16846\t      71308 ns/op\t    62802 B/op    314 allocs/op\n```\n\nComparison with other routers: https://gist.github.com/pkieltyka/123032f12052520aaccab752bd3e78cc\n\nNOTE: the allocs in the benchmark above are from the calls to http.Request's\n`WithContext(context.Context)` method that clones the http.Request, sets the `Context()`\non the duplicated (alloc'd) request and returns it the new request object. This is just\nhow setting context on a request in Go works.\n\n\n## Credits\n\n* Carl Jackson for https://github.com/zenazn/goji\n  * Parts of chi's thinking comes from goji, and chi's middleware package\n    sources from [goji](https://github.com/zenazn/goji/tree/master/web/middleware).\n  * Please see goji's [LICENSE](https://github.com/zenazn/goji/blob/master/LICENSE) (MIT)\n* Armon Dadgar for https://github.com/armon/go-radix\n* Contributions: [@VojtechVitek](https://github.com/VojtechVitek)\n\nWe'll be more than happy to see [your contributions](./CONTRIBUTING.md)!\n\n\n## Beyond REST\n\nchi is just a http router that lets you decompose request handling into many smaller layers.\nMany companies use chi to write REST services for their public APIs. But, REST is just a convention\nfor managing state via HTTP, and there's a lot of other pieces required to write a complete client-server\nsystem or network of microservices.\n\nLooking beyond REST, I also recommend some newer works in the field:\n* [webrpc](https://github.com/webrpc/webrpc) - Web-focused RPC client+server framework with code-gen\n* [gRPC](https://github.com/grpc/grpc-go) - Google's RPC framework via protobufs\n* [graphql](https://github.com/99designs/gqlgen) - Declarative query language\n* [NATS](https://nats.io) - lightweight pub-sub\n\n\n## License\n\nCopyright (c) 2015-present [Peter Kieltyka](https://github.com/pkieltyka)\n\nLicensed under [MIT License](./LICENSE)\n\n[GoDoc]: https://pkg.go.dev/github.com/go-chi/chi/v5\n[GoDoc Widget]: https://godoc.org/github.com/go-chi/chi?status.svg\n[Travis]: https://travis-ci.org/go-chi/chi\n[Travis Widget]: https://travis-ci.org/go-chi/chi.svg?branch=master\n",
      "stars_today": 9
    },
    {
      "id": 47648456,
      "name": "espeak-ng",
      "full_name": "espeak-ng/espeak-ng",
      "description": "eSpeak NG is an open source speech synthesizer that supports more than hundred languages and accents.",
      "html_url": "https://github.com/espeak-ng/espeak-ng",
      "stars": 6114,
      "forks": 1183,
      "language": "C",
      "topics": [
        "android",
        "espeak",
        "espeak-ng",
        "speech-synthesis",
        "text-to-speech"
      ],
      "created_at": "2015-12-08T20:42:42Z",
      "updated_at": "2026-02-06T15:09:40Z",
      "pushed_at": "2026-01-20T13:21:38Z",
      "open_issues": 601,
      "owner": {
        "login": "espeak-ng",
        "avatar_url": "https://avatars.githubusercontent.com/u/16214005?v=4"
      },
      "readme": "# eSpeak NG Text-to-Speech\n\n- [Features](#features)\n- [Supported languages](docs/languages.md)\n- [Documentation](#documentation)\n- [eSpeak Compatibility](#espeak-compatibility)\n- [History](#history)\n- [License Information](#license-information)\n----------\n\nThe eSpeak NG is a compact open source software text-to-speech synthesizer for \nLinux, Windows, Android and other operating systems. It supports \n[more than 100 languages and accents](docs/languages.md). It is based on the eSpeak engine\ncreated by Jonathan Duddington.\n\neSpeak NG uses a \"formant synthesis\" method. This allows many languages to be\nprovided in a small size. The speech is clear, and can be used at high speeds,\nbut is not as natural or smooth as larger synthesizers which are based on human\nspeech recordings. It also supports Klatt formant synthesis, and the ability\nto use MBROLA as backend speech synthesizer.\n\neSpeak NG is available as:\n\n*  A [command line](src/espeak-ng.1.ronn) program (Linux and Windows) to speak text from a file or\n   from stdin.\n*  A [shared library](docs/integration.md) version for use by other programs. (On Windows this is\n   a DLL).\n*  A SAPI5 version for Windows, so it can be used with screen-readers and\n   other programs that support the Windows SAPI5 interface.\n*  eSpeak NG has been ported to other platforms, including Solaris and Mac\n   OSX.\n\n## Features\n\n*  Includes different Voices, whose characteristics can be altered.\n*  Can produce speech output as a WAV file.\n*  SSML (Speech Synthesis Markup Language) is supported (not complete),\n   and also HTML.\n*  Compact size.  The program and its data, including many languages,\n   totals about few Mbytes.\n*  Can be used as a front-end to [MBROLA diphone voices](docs/mbrola.md).\n   eSpeak NG converts text to phonemes with pitch and length information.\n*  Can translate text into phoneme codes, so it could be adapted as a\n   front end for another speech synthesis engine.\n*  Potential for other languages. Several are included in varying stages\n   of progress. Help from native speakers for these or other languages is\n   welcome.\n*  Written in C.\n\nSee the [ChangeLog](ChangeLog.md) for a description of the changes in the\nvarious releases and with the eSpeak NG project.\n\nThe following platforms are supported:\n\n| Platform    | Minimum Version | Status |\n|-------------|-----------------|--------|\n| Linux       |                 | ![CI](https://github.com/espeak-ng/espeak-ng/actions/workflows/ci.yml/badge.svg) |\n| BSD         |                 |        |\n| Android     | 4.0             |        |\n| Windows     | Windows 8       |        |\n| Mac         |                 |        |\n\n## Documentation\n\n1. [User guide](docs/guide.md) explains how to set up and use eSpeak NG from command line or as a library.\n2. [Building guide](docs/building.md) provides info how to compile and build eSpeak NG from the source.\n4. [Index](docs/index.md) provides full list of more detailed information for contributors and developers.\n5. Look at [contribution guide](docs/contributing.md) to start your contribution.\n6. Look at [eSpeak NG roadmap](https://github.com/espeak-ng/espeak-ng/wiki/eSpeak-NG-roadmap) to participate in development of eSpeak NG.\n\n## eSpeak Compatibility\n\nThe *espeak-ng* binaries use the same command-line options as *espeak*, with\nseveral additions to provide new functionality from *espeak-ng* such as specifying\nthe output audio device name to use. The build creates symlinks of `espeak` to\n`espeak-ng`, and `speak` to `speak-ng`.\n\nThe espeak `speak_lib.h` include file is located in `espeak-ng/speak_lib.h` with\nan optional symlink in `espeak/speak_lib.h`. This file contains the espeak 1.48.15\nAPI, with a change to the `ESPEAK_API` macro to fix building on Windows\nand some minor changes to the documentation comments. This C API is API and ABI\ncompatible with espeak.\n\nThe `espeak-data` data has been moved to `espeak-ng-data` to avoid conflicts with\nespeak. There have been various changes to the voice, dictionary and phoneme files\nthat make them incompatible with espeak.\n\nThe *espeak-ng* project does not include the *espeakedit* program. It has moved\nthe logic to build the dictionary, phoneme and intonation binary files into the\n`libespeak-ng.so` file that is accessible from the `espeak-ng` command line and\nC API.\n\n## History\n\nThe program was originally known as __speak__ and originally written\nfor Acorn/RISC\\_OS computers starting in 1995 by Jonathan Duddington. This was\nenhanced and re-written in 2007 as __eSpeak__, including a relaxation of the\noriginal memory and processing power constraints, and with support for additional\nlanguages.\n\nIn 2010, Reece H. Dunn started maintaining a version of eSpeak on GitHub that\nwas designed to make it easier to build eSpeak on POSIX systems, porting the\nbuild system to autotools in 2012. In late 2015, this project was officially\nforked to a new __eSpeak NG__ project. The new eSpeak NG project is a significant\ndeparture from the eSpeak project, with the intention of cleaning up the\nexisting codebase, adding new features, and adding to and improving the\nsupported languages.\n\nThe *historical* branch contains the available older releases of the original\neSpeak that are not contained in the subversion repository.\n\n1.24.02 is the first version of eSpeak to appear in the subversion\nrepository, but releases from 1.05 to 1.24 are available at\n[http://sourceforge.net/projects/espeak/files/espeak/](http://sourceforge.net/projects/espeak/files/espeak/).\n\nThese early releases have been checked into the historical branch,\nwith the 1.24.02 release as the last entry. This makes it possible\nto use the replace functionality of git to see the earlier history:\n\n\tgit replace 8d59235f 63c1c019\n\n__NOTE:__ The source releases contain the `big_endian`, `espeak-edit`,\n`praat-mod`, `riskos`, `windows_dll` and `windows_sapi` folders. These\ndo not appear in the source repository until later releases, so have\nbeen excluded from the historical commits to align them better with\nthe 1.24.02 source commit.\n\n## License Information\n\neSpeak NG Text-to-Speech is released under the [GPL version 3](COPYING) or\nlater license.\n\nThe `getopt.c` compatibility implementation for getopt support on Windows is\ntaken from the NetBSD `getopt_long` implementation, which is licensed under a\n[2-clause BSD](COPYING.BSD2) license.\n\nAndroid is a trademark of Google LLC.\n\n## Acknowledgements\n\nThe catalan extension was funded by [Departament de la VicepresidÃ¨ncia i de PolÃ­tiques Digitals i Territori de la Generalitat de Catalunya](https://politiquesdigitals.gencat.cat/ca/inici/index.html#googtrans(ca|en) \nwithin the framework of \n[Projecte AINA](https://politiquesdigitals.gencat.cat/ca/economia/catalonia-ai/aina).\n",
      "stars_today": 9
    },
    {
      "id": 942312530,
      "name": "cocoindex",
      "full_name": "cocoindex-io/cocoindex",
      "description": "Data transformation framework for AI. Ultra performant, with incremental processing.  ğŸŒŸ Star if you like it!",
      "html_url": "https://github.com/cocoindex-io/cocoindex",
      "stars": 6043,
      "forks": 445,
      "language": "Rust",
      "topics": [
        "agentic-data-framework",
        "ai",
        "ai-agents",
        "change-data-capture",
        "context-engineering",
        "data",
        "data-engineering",
        "data-indexing",
        "data-processing",
        "etl",
        "help-wanted",
        "indexing",
        "knowledge-graph",
        "llm",
        "long-horizon-agent",
        "python",
        "rag",
        "real-time",
        "rust",
        "semantic-search"
      ],
      "created_at": "2025-03-03T23:03:09Z",
      "updated_at": "2026-02-07T02:17:07Z",
      "pushed_at": "2026-02-07T00:18:34Z",
      "open_issues": 60,
      "owner": {
        "login": "cocoindex-io",
        "avatar_url": "https://avatars.githubusercontent.com/u/190812870?v=4"
      },
      "readme": "<p align=\"center\">\n    <img src=\"https://cocoindex.io/images/github.svg\" alt=\"CocoIndex\">\n</p>\n\n<h1 align=\"center\">Data transformation for AI</h1>\n\n<div align=\"center\">\n\n[![GitHub](https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6)](https://github.com/cocoindex-io/cocoindex)\n[![Documentation](https://img.shields.io/badge/Documentation-394e79?logo=readthedocs&logoColor=00B9FF)](https://cocoindex.io/docs/getting_started/quickstart)\n[![License](https://img.shields.io/badge/license-Apache%202.0-5B5BD6?logoColor=white)](https://opensource.org/licenses/Apache-2.0)\n[![PyPI version](https://img.shields.io/pypi/v/cocoindex?color=5B5BD6)](https://pypi.org/project/cocoindex/)\n<!--[![PyPI - Downloads](https://img.shields.io/pypi/dm/cocoindex)](https://pypistats.org/packages/cocoindex) -->\n[![PyPI Downloads](https://static.pepy.tech/badge/cocoindex/month)](https://pepy.tech/projects/cocoindex)\n[![CI](https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml/badge.svg?event=push&color=5B5BD6)](https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml)\n[![release](https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml/badge.svg?event=push&color=5B5BD6)](https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml)\n[![Link Check](https://github.com/cocoindex-io/cocoindex/actions/workflows/links.yml/badge.svg)](https://github.com/cocoindex-io/cocoindex/actions/workflows/links.yml)\n[![prek](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/j178/prek/master/docs/assets/badge-v0.json)](https://github.com/j178/prek)\n[![Discord](https://img.shields.io/discord/1314801574169673738?logo=discord&color=5B5BD6&logoColor=white)](https://discord.com/invite/zpA9S2DR7s)\n\n</div>\n\n<div align=\"center\">\n    <a href=\"https://trendshift.io/repositories/13939\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/13939\" alt=\"cocoindex-io%2Fcocoindex | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</div>\n\nUltra performant data transformation framework for AI, with core engine written in Rust. Support incremental processing and data lineage out-of-box.  Exceptional developer velocity. Production-ready at day 0.\n\nâ­ Drop a star to help us grow!\n\n<div align=\"center\">\n\n<!-- Keep these links. Translations will automatically update with the README. -->\n[Deutsch](https://readme-i18n.com/cocoindex-io/cocoindex?lang=de) |\n[English](https://readme-i18n.com/cocoindex-io/cocoindex?lang=en) |\n[EspaÃ±ol](https://readme-i18n.com/cocoindex-io/cocoindex?lang=es) |\n[franÃ§ais](https://readme-i18n.com/cocoindex-io/cocoindex?lang=fr) |\n[æ—¥æœ¬èª](https://readme-i18n.com/cocoindex-io/cocoindex?lang=ja) |\n[í•œêµ­ì–´](https://readme-i18n.com/cocoindex-io/cocoindex?lang=ko) |\n[PortuguÃªs](https://readme-i18n.com/cocoindex-io/cocoindex?lang=pt) |\n[Ğ ÑƒÑÑĞºĞ¸Ğ¹](https://readme-i18n.com/cocoindex-io/cocoindex?lang=ru) |\n[ä¸­æ–‡](https://readme-i18n.com/cocoindex-io/cocoindex?lang=zh)\n\n</div>\n\n</br>\n\n<p align=\"center\">\n    <img src=\"https://cocoindex.io/images/transformation.svg\" alt=\"CocoIndex Transformation\">\n</p>\n\n</br>\n\nCocoIndex makes it effortless to transform data with AI, and keep source data and target in sync. Whether youâ€™re building a vector index, creating knowledge graphs for context engineering or performing any custom data transformations â€” goes beyond SQL.\n\n</br>\n\n<p align=\"center\">\n<img alt=\"CocoIndex Features\" src=\"https://cocoindex.io/images/venn2.svg\" />\n</p>\n\n</br>\n\n## Exceptional velocity\n\nJust declare transformation in dataflow with ~100 lines of python\n\n```python\n# import\ndata['content'] = flow_builder.add_source(...)\n\n# transform\ndata['out'] = data['content']\n    .transform(...)\n    .transform(...)\n\n# collect data\ncollector.collect(...)\n\n# export to db, vector db, graph db ...\ncollector.export(...)\n```\n\nCocoIndex follows the idea of [Dataflow](https://en.wikipedia.org/wiki/Dataflow_programming) programming model. Each transformation creates a new field solely based on input fields, without hidden states and value mutation. All data before/after each transformation is observable, with lineage out of the box.\n\n**Particularly**, developers don't explicitly mutate data by creating, updating and deleting. They just need to define transformation/formula for a set of source data.\n\n## Plug-and-Play Building Blocks\n\nNative builtins for different source, targets and transformations. Standardize interface, make it 1-line code switch between different components - as easy as assembling building blocks.\n\n<p align=\"center\">\n    <img src=\"https://cocoindex.io/images/components.svg\" alt=\"CocoIndex Features\">\n</p>\n\n## Data Freshness\n\nCocoIndex keep source data and target in sync effortlessly.\n\n<p align=\"center\">\n    <img src=\"https://github.com/user-attachments/assets/f4eb29b3-84ee-4fa0-a1e2-80eedeeabde6\" alt=\"Incremental Processing\" width=\"700\">\n</p>\n\nIt has out-of-box support for incremental indexing:\n\n- minimal recomputation on source or logic change.\n- (re-)processing necessary portions; reuse cache when possible\n\n## Quick Start\n\nIf you're new to CocoIndex, we recommend checking out\n\n- ğŸ“– [Documentation](https://cocoindex.io/docs)\n- âš¡  [Quick Start Guide](https://cocoindex.io/docs/getting_started/quickstart)\n- ğŸ¬ [Quick Start Video Tutorial](https://youtu.be/gv5R8nOXsWU?si=9ioeKYkMEnYevTXT)\n\n### Setup\n\n1. Install CocoIndex Python library\n\n```sh\npip install -U cocoindex\n```\n\n2. [Install Postgres](https://cocoindex.io/docs/getting_started/installation#-install-postgres) if you don't have one. CocoIndex uses it for incremental processing.\n\n3. (Optional) Install Claude Code skill for enhanced development experience. Run these commands in [Claude Code](https://claude.com/claude-code):\n\n```\n/plugin marketplace add cocoindex-io/cocoindex-claude\n/plugin install cocoindex-skills@cocoindex\n```\n\n## Define data flow\n\nFollow [Quick Start Guide](https://cocoindex.io/docs/getting_started/quickstart) to define your first indexing flow. An example flow looks like:\n\n```python\n@cocoindex.flow_def(name=\"TextEmbedding\")\ndef text_embedding_flow(flow_builder: cocoindex.FlowBuilder, data_scope: cocoindex.DataScope):\n    # Add a data source to read files from a directory\n    data_scope[\"documents\"] = flow_builder.add_source(cocoindex.sources.LocalFile(path=\"markdown_files\"))\n\n    # Add a collector for data to be exported to the vector index\n    doc_embeddings = data_scope.add_collector()\n\n    # Transform data of each document\n    with data_scope[\"documents\"].row() as doc:\n        # Split the document into chunks, put into `chunks` field\n        doc[\"chunks\"] = doc[\"content\"].transform(\n            cocoindex.functions.SplitRecursively(),\n            language=\"markdown\", chunk_size=2000, chunk_overlap=500)\n\n        # Transform data of each chunk\n        with doc[\"chunks\"].row() as chunk:\n            # Embed the chunk, put into `embedding` field\n            chunk[\"embedding\"] = chunk[\"text\"].transform(\n                cocoindex.functions.SentenceTransformerEmbed(\n                    model=\"sentence-transformers/all-MiniLM-L6-v2\"))\n\n            # Collect the chunk into the collector.\n            doc_embeddings.collect(filename=doc[\"filename\"], location=chunk[\"location\"],\n                                   text=chunk[\"text\"], embedding=chunk[\"embedding\"])\n\n    # Export collected data to a vector index.\n    doc_embeddings.export(\n        \"doc_embeddings\",\n        cocoindex.targets.Postgres(),\n        primary_key_fields=[\"filename\", \"location\"],\n        vector_indexes=[\n            cocoindex.VectorIndexDef(\n                field_name=\"embedding\",\n                metric=cocoindex.VectorSimilarityMetric.COSINE_SIMILARITY)])\n```\n\nIt defines an index flow like this:\n\n<p align=\"center\">\n    <img width=\"400\" alt=\"Data Flow\" src=\"https://github.com/user-attachments/assets/2ea7be6d-3d94-42b1-b2bd-22515577e463\" />\n</p>\n\n## ğŸš€ Examples and demo\n\n| Example | Description |\n|---------|-------------|\n| [Text Embedding](examples/text_embedding) | Index text documents with embeddings for semantic search |\n| [Code Embedding](examples/code_embedding) | Index code embeddings for semantic search |\n| [PDF Embedding](examples/pdf_embedding) | Parse PDF and index text embeddings for semantic search |\n| [PDF Elements Embedding](examples/pdf_elements_embedding) | Extract text and images from PDFs; embed text with SentenceTransformers and images with CLIP; store in Qdrant for multimodal search |\n| [Manuals LLM Extraction](examples/manuals_llm_extraction) | Extract structured information from a manual using LLM |\n| [Amazon S3 Embedding](examples/amazon_s3_embedding) | Index text documents from Amazon S3 |\n| [Azure Blob Storage Embedding](examples/azure_blob_embedding) | Index text documents from Azure Blob Storage |\n| [Google Drive Text Embedding](examples/gdrive_text_embedding) | Index text documents from Google Drive |\n| [Meeting Notes to Knowledge Graph](examples/meeting_notes_graph) | Extract structured meeting info from Google Drive and build a knowledge graph |\n| [Docs to Knowledge Graph](examples/docs_to_knowledge_graph) | Extract relationships from Markdown documents and build a knowledge graph |\n| [Embeddings to Qdrant](examples/text_embedding_qdrant) | Index documents in a Qdrant collection for semantic search |\n| [Embeddings to LanceDB](examples/text_embedding_lancedb) | Index documents in a LanceDB collection for semantic search |\n| [FastAPI Server with Docker](examples/fastapi_server_docker) | Run the semantic search server in a Dockerized FastAPI setup |\n| [Product Recommendation](examples/product_recommendation) | Build real-time product recommendations with LLM and graph database|\n| [Image Search with Vision API](examples/image_search) | Generates detailed captions for images using a vision model, embeds them, enables live-updating semantic search via FastAPI and served on a React frontend|\n| [Face Recognition](examples/face_recognition) | Recognize faces in images and build embedding index |\n| [Paper Metadata](examples/paper_metadata) | Index papers in PDF files, and build metadata tables for each paper |\n| [Multi Format Indexing](examples/multi_format_indexing) | Build visual document index from PDFs and images with ColPali for semantic search |\n| [Custom Source HackerNews](examples/custom_source_hn) | Index HackerNews threads and comments, using *CocoIndex Custom Source* |\n| [Custom Output Files](examples/custom_output_files) | Convert markdown files to HTML files and save them to a local directory, using *CocoIndex Custom Targets* |\n| [Patient intake form extraction](examples/patient_intake_extraction) | Use LLM to extract structured data from patient intake forms with different formats |\n| [HackerNews Trending Topics](examples/hn_trending_topics) | Extract trending topics from HackerNews threads and comments, using *CocoIndex Custom Source* and LLM |\n| [Patient Intake Form Extraction with BAML](examples/patient_intake_extraction_baml) | Extract structured data from patient intake forms using BAML |\n| [Patient Intake Form Extraction with DSPy](examples/patient_intake_extraction_dspy) | Extract structured data from patient intake forms using DSPy |\n\nMore coming and stay tuned ğŸ‘€!\n\n## ğŸ“– Documentation\n\nFor detailed documentation, visit [CocoIndex Documentation](https://cocoindex.io/docs), including a [Quickstart guide](https://cocoindex.io/docs/getting_started/quickstart).\n\n## ğŸ¤ Contributing\n\nWe love contributions from our community â¤ï¸. For details on contributing or running the project for development, check out our [contributing guide](https://cocoindex.io/docs/about/contributing).\n\n## ğŸ‘¥ Community\n\nWelcome with a huge coconut hug ğŸ¥¥â‹†ï½¡ËšğŸ¤—. We are super excited for community contributions of all kinds - whether it's code improvements, documentation updates, issue reports, feature requests, and discussions in our Discord.\n\nJoin our community here:\n\n- ğŸŒŸ [Star us on GitHub](https://github.com/cocoindex-io/cocoindex)\n- ğŸ‘‹ [Join our Discord community](https://discord.com/invite/zpA9S2DR7s)\n- â–¶ï¸ [Subscribe to our YouTube channel](https://www.youtube.com/@cocoindex-io)\n- ğŸ“œ [Read our blog posts](https://cocoindex.io/blogs/)\n\n## Support us\n\nWe are constantly improving, and more features and examples are coming soon. If you love this project, please drop us a star â­ at GitHub repo [![GitHub](https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6)](https://github.com/cocoindex-io/cocoindex) to stay tuned and help us grow.\n\n## License\n\nCocoIndex is Apache 2.0 licensed.\n",
      "stars_today": 9
    },
    {
      "id": 743200516,
      "name": "komikku",
      "full_name": "komikku-app/komikku",
      "description": "Free and open source manga reader for Android",
      "html_url": "https://github.com/komikku-app/komikku",
      "stars": 3273,
      "forks": 131,
      "language": "Kotlin",
      "topics": [
        "android",
        "j2k",
        "komga",
        "kotlin",
        "manga",
        "manga-downloader",
        "manga-reader",
        "mangadex",
        "mangadex-downloader",
        "mangadownloader",
        "mangareader",
        "mihon",
        "neko",
        "tachiyomi",
        "tachiyomisy"
      ],
      "created_at": "2024-01-14T16:25:54Z",
      "updated_at": "2026-02-06T15:58:00Z",
      "pushed_at": "2026-02-06T02:02:07Z",
      "open_issues": 309,
      "owner": {
        "login": "komikku-app",
        "avatar_url": "https://avatars.githubusercontent.com/u/160299335?v=4"
      },
      "readme": "<div align=\"center\">\n\n<a href=\"https://komikku-app.github.io\">\n  <img width=200px height=200px src=\"./.github/readme-images/app-icon.png\"/>\n</a><br/>\n<a href=\"https://trendshift.io/repositories/13696\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/13696\" alt=\"komikku-app%2Fkomikku | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n <h1 align=\"center\"> Komikku </h1>\n\n| Releases | Preview |\n|----------|---------|\n| <div align=\"center\"> [![GitHub downloads](https://img.shields.io/github/downloads/komikku-app/komikku/latest/total?label=Latest%20Downloads&labelColor=27303D&color=0D1117&logo=github&logoColor=FFFFFF&style=flat)](https://github.com/komikku-app/komikku/releases/latest) [![GitHub downloads](https://img.shields.io/github/downloads/komikku-app/komikku/total?label=Total%20Downloads&labelColor=27303D&color=0D1117&logo=github&logoColor=FFFFFF&style=flat)](https://github.com/komikku-app/komikku/releases) [![Stable build](https://img.shields.io/github/actions/workflow/status/komikku-app/komikku/build_release.yml?labelColor=27303D&label=Stable&labelColor=06599d&color=043b69)](https://github.com/komikku-app/komikku/actions/workflows/build_release.yml) | <div align=\"center\"> [![GitHub downloads](https://img.shields.io/github/downloads/komikku-app/komikku-preview/latest/total?label=Latest%20Downloads&labelColor=27303D&color=0D1117&logo=github&logoColor=FFFFFF&style=flat)](https://github.com/komikku-app/komikku-preview/releases/latest) [![GitHub downloads](https://img.shields.io/github/downloads/komikku-app/komikku-preview/total?label=Total%20Downloads&labelColor=27303D&color=0D1117&logo=github&logoColor=FFFFFF&style=flat)](https://github.com/komikku-app/komikku-preview/releases) [![Preview build](https://img.shields.io/github/actions/workflow/status/komikku-app/komikku-preview/build_app.yml?labelColor=27303D&label=Preview&labelColor=2c2c47&color=1c1c39)](https://github.com/komikku-app/komikku-preview/actions/workflows/build_app.yml) |\n\n*Requires Android 8.0 or higher.*\n\n[![Discord](https://img.shields.io/discord/1242381704459452488.svg?label=&labelColor=6A7EC2&color=7389D8&logo=discord&logoColor=FFFFFF)](https://discord.gg/85jB7V5AJR)\n[![CI](https://img.shields.io/github/actions/workflow/status/komikku-app/komikku/build_push.yml?labelColor=27303D&label=CI)](https://github.com/komikku-app/komikku/actions/workflows/build_push.yml)\n[![License: Apache-2.0](https://img.shields.io/github/license/komikku-app/komikku?labelColor=27303D&color=0877d2)](/LICENSE)\n[![Translation status](https://img.shields.io/weblate/progress/komikku-app?labelColor=27303D&color=946300)](https://hosted.weblate.org/engage/komikku-app/)\n\n## Download\n\n[![Stable](https://img.shields.io/github/release/komikku-app/komikku.svg?maxAge=3600&label=Stable&labelColor=06599d&color=043b69)](https://github.com/komikku-app/komikku/releases/latest)\n[![Preview](https://img.shields.io/github/v/release/komikku-app/komikku-preview.svg?maxAge=3600&label=Preview&labelColor=2c2c47&color=1c1c39)](https://github.com/komikku-app/komikku-preview/releases/latest)\n\n*Requires Android 8.0 or higher.*\n\n[![Sponsor me on GitHub](https://custom-icon-badges.demolab.com/badge/-Sponsor-ea4aaa?style=for-the-badge&logo=heart&logoColor=white)](https://github.com/sponsors/cuong-tran \"Sponsor me on GitHub\")\n\n<div align=\"left\">\nA free and open source manga reader which is based off TachiyomiSY & Mihon/Tachiyomi. This fork is meant to provide new & useful features while regularly take features/updates from Mihon or other forks like SY, J2K and Neko...\n\n![screenshots of app](./.github/readme-images/screens.png)\n\n<div align=\"left\">\n\n## Features\n\n### Komikku's unique features:\n- `Suggestions` automatically showing source-website's recommendations / suggestions / related to current entry for all sources.\n- `Hidden categories` to hide yours things from *nosy* people.\n- `Auto theme color` based on each entry's cover for entry View & Reader.\n- `App custom theme` with `Color palettes` for endless color lover.\n- `Bulk-favorite` multiple entries all at once.\n- Source & Language icon on Library & various places. (Some language flags are not really accurate)\n- `Feed` now supports **all** sources, with more items (20 for now).\n- Fast browsing (for who with large library experiencing slow loading)\n- Grouped entries in Update tab (inspired by J2K).\n- Update notification with manga cover.\n- Auto `2-way sync` progress with trackers.\n- Chips for `Saved search` in source browse\n- `Panorama cover` showing wide cover in full.\n- `Merge multiple` library entries together at same time.\n- `Range-selection` for Migration.\n- Ability to `enable/disable repo`, with icon.\n- `Update Error` screen & migrating them away.\n- `to-be-updated` screen: which entries are going to be checked with smart-update?\n- `Search for sources` & Quick NSFW sources filter in Extensions, Browse & Migration screen.\n- `Feed` backup/restore/sync/re-order.\n- Long-click to add/remove single entry to/from library, everywhere.\n- Docking Read/Resume button to left/right.\n- In-app progress banner shows Library syncing / Backup restoring / Library updating progress.\n- Auto-install app update.\n- Configurable interval to refresh entries from downloaded storage.\n- Forked from SY so everything from SY.\n- Always up-to-date with Mihon & SY\n- More app themes & better UI, improvements...\n\n\n<details>\n  <summary>Features from Mihon / Tachiyomi</summary>\n\n#### All up-to-date features from Mihon / Tachiyomi (original), include:\n\n* Online reading from a variety of sources\n* Local reading of downloaded content\n* A configurable reader with multiple viewers, reading directions and other settings.\n* Tracker support: [MyAnimeList](https://myanimelist.net/), [AniList](https://anilist.co/), [Kitsu](https://kitsu.app/), [MangaUpdates](https://mangaupdates.com), [Shikimori](https://shikimori.one), [Bangumi](https://bgm.tv/)\n* Categories to organize your library\n* Light and dark themes\n* Schedule updating your library for new chapters\n* Create backups locally to read offline or to your desired cloud service\n* Continue reading button in library\n\n</details>\n\n<details>\n  <summary>Features from Tachiyomi SY</summary>\n\n#### All features from TachiyomiSY:\n* Feed tab, where you can easily view the latest entries or saved search from multiple sources at same time.\n* Automatic webtoon detection, allowing the reader to switch to webtoon mode automatically when viewing one\n* Manga recommendations, uses MAL and Anilist, as well as Neko Similar Manga for Mangadex manga (Thanks to Az, She11Shocked, Carlos, and Goldbattle)\n* Lewd filter, hide the lewd manga in your library when you want to\n* Tracking filter, filter your tracked manga so you can see them or see non-tracked manga, made by She11Shocked\n* Search tracking status in library, made by She11Shocked\n* Custom categories for sources, liked the pinned sources, but you can make your own versions and put any sources in them\n* Manga info edit\n* Manga Cover view + share and save\n* Dynamic Categories, view the library in multiple ways\n* Smart background for reading modes like LTR or Vertical, changes the background based on the page color\n* Force disable webtoon zoom\n* Hentai features enable/disable, in advanced settings\n* Quick clean titles\n* Source migration, migrate all your manga from one source to another\n* Saving searches\n* Autoscroll\n* Page preload customization\n* Customize image cache size\n* Batch import of custom sources and featured extensions\n* Advanced source settings page, searching, enable/disable all\n* Click tag for local search, long click tag for global search\n* Merge multiple of the same manga from different sources\n* Drag and drop library sorting\n* Library search engine, includes exclude, quotes as absolute, and a bunch of other ways to search\n* New E-Hentai/ExHentai features, such as language settings and watched list settings\n* Enhanced views for internal and integrated sources\n* Enhanced usability for internal and delegated sources\n\nCustom sources:\n* E-Hentai/ExHentai\n\nAdditional features for some extensions, features include custom description, opening in app, batch add to library, and a bunch of other things based on the source:\n* 8Muses (EroMuse)\n* HBrowse\n* Mangadex\n* NHentai\n* Puruin\n* LANraragi\n\n</details>\n\n## Issues, Feature Requests and Contributing\n\nPull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.\n\n<details><summary>Issues</summary>\n\n[Website](https://komikku-app.github.io/)\n\n1. **Before reporting a new issue, take a look at the [FAQ](https://komikku-app.github.io/docs/faq/general), the [changelog](https://github.com/komikku-app/komikku/releases) and the already opened [issues](https://github.com/komikku-app/komikku/issues).**\n2. If you are unsure, ask here: [![Discord](https://img.shields.io/discord/1242381704459452488.svg?label=&labelColor=6A7EC2&color=7389D8&logo=discord&logoColor=FFFFFF)](https://discord.gg/85jB7V5AJR)\n\n</details>\n\n<details><summary>Bugs</summary>\n\n* Include version (More â†’ About â†’ Version)\n * If not latest, try updating, it may have already been solved\n * Preview version is equal to the number of commits as seen on the main page\n* Include steps to reproduce (if not obvious from description)\n* Include screenshot (if needed)\n* If it could be device-dependent, try reproducing on another device (if possible)\n* Don't group unrelated requests into one issue\n\nUse the [issue forms](https://github.com/komikku-app/komikku/issues/new/choose) to submit a bug.\n\n</details>\n\n<details><summary>Feature Requests</summary>\n\n* Write a detailed issue, explaining what it should do or how.\n* Include screenshot (if needed).\n</details>\n\n<details><summary>Contributing</summary>\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md).\n</details>\n\n<details><summary>Code of Conduct</summary>\n\nSee [CODE_OF_CONDUCT.md](./CODE_OF_CONDUCT.md).\n</details>\n\n<div align=\"center\">\n\n### Credits\n\nThank you to all the people who have contributed!\n\n<a href=\"https://github.com/komikku-app/komikku/graphs/contributors\">\n    <img src=\"https://contrib.rocks/image?repo=komikku-app/komikku\" alt=\"Komikku app contributors\" title=\"Komikku app contributors\" width=\"800\"/>\n</a>\n\n![Visitor Count](https://count.getloli.com/get/@komikku-app?theme=capoo-2)\n\n### Disclaimer\n\nThe developer(s) of this application does not have any affiliation with the content providers available, and this application hosts zero content.\n\n<div align=\"left\">\n\n## License\n\n    Copyright 2015 Javier TomÃ¡s\n\n    Licensed under the Apache License, Version 2.0 (the \"License\");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n",
      "stars_today": 9
    },
    {
      "id": 1036704760,
      "name": "xllm",
      "full_name": "jd-opensource/xllm",
      "description": "A high-performance inference engine for LLMs, optimized for diverse AI accelerators.",
      "html_url": "https://github.com/jd-opensource/xllm",
      "stars": 1013,
      "forks": 138,
      "language": "C++",
      "topics": [
        "deepseek",
        "inference",
        "inference-engine",
        "large-language-models",
        "llm-inference",
        "qwen"
      ],
      "created_at": "2025-08-12T13:16:07Z",
      "updated_at": "2026-02-06T15:32:15Z",
      "pushed_at": "2026-02-06T15:22:38Z",
      "open_issues": 111,
      "owner": {
        "login": "jd-opensource",
        "avatar_url": "https://avatars.githubusercontent.com/u/75349771?v=4"
      },
      "readme": "<!-- Copyright 2022 JD Co.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this project except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License. -->\n\n[English](./README.md) | [ä¸­æ–‡](./README_zh.md)\n\n<div align=\"center\">\n<img src=\"docs/assets/logo_with_llm.png\" alt=\"xLLM\" style=\"width:50%; height:auto;\">\n    \n[![Document](https://img.shields.io/badge/Document-black?logo=html5&labelColor=grey&color=red)](https://xllm.readthedocs.io/zh-cn/latest/) [![Docker](https://img.shields.io/badge/Docker-black?logo=docker&labelColor=grey&color=%231E90FF)](https://hub.docker.com/r/xllm/xllm-ai) [![License](https://img.shields.io/badge/license-Apache%202.0-brightgreen?labelColor=grey)](https://opensource.org/licenses/Apache-2.0) [![report](https://img.shields.io/badge/Technical%20Report-red?logo=arxiv&logoColor=%23B31B1B&labelColor=%23F0EBEB&color=%23D42626)](https://arxiv.org/abs/2510.14686) [![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/jd-opensource/xllm) \n    \n</div>\n\n---------------------\n\n<p align=\"center\">\n| <a href=\"https://xllm.readthedocs.io/zh-cn/latest/\"><b>Documentation</b></a> | <a href=\"https://arxiv.org/abs/2510.14686\"><b>Technical Report</b></a> |\n</p>\n\n\n### ğŸ“¢ News\n\n- 2025-12-21: ğŸ‰ We day-0 support high-performance inference for the [GLM-4.7](https://github.com/zai-org) model.\n- 2025-12-08: ğŸ‰ We day-0 support high-performance inference for the [GLM-4.6V](https://github.com/zai-org/GLM-V) model.\n- 2025-12-05: ğŸ‰ We now support high-performance inference for the [GLM-4.5/GLM-4.6](https://github.com/zai-org/GLM-4.5/blob/main/README_zh.md) series models.\n- 2025-12-05: ğŸ‰ We now support high-performance inference for the [VLM-R1](https://github.com/om-ai-lab/VLM-R1) model.\n- 2025-12-05: ğŸ‰ We build hybrid KV cache management based on [Mooncake](https://github.com/kvcache-ai/Mooncake), supporting global KV cache management with intelligent offloading and prefetching.\n- 2025-10-16: ğŸ‰ We recently have released our [xLLM Technical Report](https://arxiv.org/abs/2510.14686) on arXiv, providing comprehensive technical blueprints and implementation insights.\n\n## Project Overview\n\n**xLLM** is an **efficient LLM inference framework**, specifically optimized for **Chinese AI accelerators**, enabling enterprise-grade deployment with enhanced efficiency and reduced cost. The framework adopts a **service-engine decoupled** inference architecture, achieving breakthrough efficiency through several  technologies: at the service layer, including elastic scheduling of online/offline requests, dynamic PD disaggregation, a hybrid EPD mechanism for multimodal and high-availability fault tolerance; and at the engine layer, combined with technologies such as multi-stream parallel computing, graph fusion optimization, speculative inference, dynamic load balancing and global KV cache management. The overall architecture is shown below:\n\n<div align=\"center\">\n<img src=\"docs/assets/xllm_arch.png\" alt=\"xllm_arch\" style=\"width:90%; height:auto;\">\n</div>\n\n**xLLM** already supports efficient deployment of mainstream large models (such as *DeepSeek-V3.1*, *Qwen2/3*, etc.) on Chinese AI accelerators, empowering enterprises to implement high-performance, low-cost AI large model applications. xLLM has been fully deployed in JD.comâ€™s real core retail businesses, covering a variety of scenarios including intelligent customer service, risk control, supply chain optimization, ad recommendation, and more.\n\n\n## Core Features\n\n**xLLM** delivers robust intelligent computing capabilities. By leveraging hardware system optimization and algorithm-driven decision control, it jointly accelerates the inference process, enabling high-throughput, low-latency distributed inference services.\n\n**Full Graph Pipeline Execution Orchestration**\n- Asynchronous decoupled scheduling at the requests scheduling layer, to reduce computational bubbles.\n- Asynchronous parallelism of computation and communication at the model graph layer, overlapping computation and communication.\n- Pipelining of heterogeneous computing units at the operator kernel layer, overlapping computation and memory access.\n\n**Graph Optimization for Dynamic Shapes**\n- Dynamic shape adaptation based on parameterization and multi-graph caching methods to enhance the flexibility of static graph.\n- Controlled tensor memory pool to ensure address security and reusability.\n- Integration and adaptation of performance-critical custom operators (e.g., *PageAttention*, *AllReduce*).\n\n**Efficient Memory Optimization**\n- Mapping management between discrete physical memory and continuous virtual memory.\n- On-demand memory allocation to reduce memory fragmentation.\n- Intelligent scheduling of memory pages to increase memory reusability.\n- Adaptation of corresponding operators for domestic accelerators.\n\n**Global KV Cache Management**\n- Intelligent offloading and prefetching of KV in hierarchical caches.\n- KV cache-centric distributed storage architecture.\n- Intelligent KV routing among computing nodes.\n\n**Algorithm-driven Acceleration**\n- Speculative decoding optimization to improve efficiency through multi-core parallelism.\n- Dynamic load balancing of MoE experts to achieve efficient adjustment of expert distribution.\n\n---\n## Hardware Support\n\n| Hardware | Example | Remark          |\n| -------- | ------- | --------------- |\n| NPU      | A2, A3  | HDK Driver 25.2.0 + |\n| MLU      | MLU590  |                 |\n| ILU      | BI150   |                 |\n| MUSA     | S5000   |                 |\n\nBesides, please check the supported models on different hardwares at [Supported Models List](docs/en/supported_models.md).\n\n---\n\n## Quick Start\n\nPlease refer to [Quick Start](docs/en/getting_started/quick_start.md) for more details.\n\n--- \n\n## Contributing\nThere are several ways you can contribute to xLLM:\n\n1. Reporting Issues (Bugs & Errors)\n2. Suggesting Enhancements\n3. Improving Documentation\n    + Fork the repository\n    + Add your view in document\n    + Send your pull request\n4. Writing Code\n    + Fork the repository\n    + Create a new branch\n    + Add your feature or improvement\n    + Send your pull request\n\nWe appreciate all kinds of contributions! ğŸ‰ğŸ‰ğŸ‰\nIf you have problems about development, please check our document: **[Document](https://xllm.readthedocs.io/zh-cn/latest)**\n\n---\n\n## Community & Support\nIf you encounter any issues along the way, you are welcomed to submit reproducible steps and log snippets in the project's Issues area, or contact the xLLM Core team directly via your internal Slack. In addition, we have established official WeChat groups. You can access the following QR code to join. Welcome to contact us!\n\n<div align=\"center\">\n  <img src=\"docs/assets/wechat_qrcode.jpg\" alt=\"qrcode3\" width=\"50%\" />\n</div>\n\n## Acknowledgment\n\nThis project was made possible thanks to the following open-source projects:  \n- [ScaleLLM](https://github.com/vectorch-ai/ScaleLLM) - xLLM draws inspiration from ScaleLLM's graph construction method and references its runtime execution. \n- [Mooncake](https://github.com/kvcache-ai/Mooncake) - Build xLLM hybrid KV cache management based on Mooncake.\n- [brpc](https://github.com/apache/brpc) - Build high-performance http service based on brpc.\n- [tokenizers-cpp](https://github.com/mlc-ai/tokenizers-cpp) - Build C++ tokenizer based on tokenizers-cpp.\n- [safetensors](https://github.com/huggingface/safetensors) - xLLM relies on the C binding safetensors capability.\n- [Partial JSON Parser](https://github.com/promplate/partial-json-parser) - Implement xLLM's C++ JSON parser with insights from Python and Go implementations.\n- [concurrentqueue](https://github.com/cameron314/concurrentqueue) - A fast multi-producer, multi-consumer lock-free concurrent queue for C++11.\n- [Flashinfer](https://github.com/flashinfer-ai/flashinfer) - High-performance NVIDIA GPU kernels.\n\n\nThanks to the following collaborating university laboratories:\n\n- [THU-MIG](https://ise.thss.tsinghua.edu.cn/mig/projects.html) (School of Software, BNRist, Tsinghua University)\n- USTC-Cloudlab (Cloud Computing Lab, University of Science and Technology of China)\n- [Beihang-HiPO](https://github.com/buaa-hipo) (Beihang HiPO research group)\n- PKU-DS-LAB (Data Structure Laboratory, Peking University)\n- PKU-NetSys-LAB (NetSys Lab, Peking University)\n\nThanks to all the following [developers](https://github.com/jd-opensource/xllm/graphs/contributors) who have contributed to xLLM.\n\n<a href=\"https://github.com/jd-opensource/xllm/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=jd-opensource/xllm\" />\n</a>\n\n---\n\n## License\n[Apache License](LICENSE)\n\n#### xLLM is provided by JD.com \n#### Thanks for your Contributions!\n\n## Citation\n\nIf you think this repository is helpful to you, welcome to cite us:\n```\n@article{liu2025xllm,\n  title={xLLM Technical Report},\n  author={Liu, Tongxuan and Peng, Tao and Yang, Peijun and Zhao, Xiaoyang and Lu, Xiusheng and Huang, Weizhe and Liu, Zirui and Chen, Xiaoyu and Liang, Zhiwei and Xiong, Jun and others},\n  journal={arXiv preprint arXiv:2510.14686},\n  year={2025}\n}\n```\n",
      "stars_today": 9
    },
    {
      "id": 723919857,
      "name": "Geto",
      "full_name": "JackEblan/Geto",
      "description": "Apply device settings to your apps. This multi-modular Android project is structured following Uncle Bob's Clean Architecture principles and Now in Android sample app",
      "html_url": "https://github.com/JackEblan/Geto",
      "stars": 761,
      "forks": 24,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2023-11-27T03:02:49Z",
      "updated_at": "2026-02-06T11:05:03Z",
      "pushed_at": "2026-01-13T04:46:02Z",
      "open_issues": 47,
      "owner": {
        "login": "JackEblan",
        "avatar_url": "https://avatars.githubusercontent.com/u/141921460?v=4"
      },
      "readme": "<div align = \"center\">\n\n<img width=\"100\" src=\"app/src/main/ic_launcher-playstore.png\" alt=\"Geto\" align=\"center\">\n\n# Geto\n\nApply device settings to your apps\n\n![GitHub Release](https://img.shields.io/github/v/release/JackEblan/Geto?style=for-the-badge)\n![GitHub License](https://img.shields.io/github/license/JackEblan/Geto?style=for-the-badge)\n![F-Droid Version](https://img.shields.io/f-droid/v/com.android.geto?style=for-the-badge)\n![GitHub Downloads (all assets, all releases)](https://img.shields.io/github/downloads/JackEblan/Geto/total?style=for-the-badge)\n\n[<img src=\"https://fdroid.gitlab.io/artwork/badge/get-it-on.png\" alt=\"Get it on F-Droid\" height=\"80\">](https://f-droid.org/en/packages/com.android.geto/)\n\n</div>\n\nAbout The Project\n==================\n\nThe only reason I created this app is to turn off that damn Developer Options when using a banking\napp. The only annoying thing about it is you have to go to the Settings app. When you turn off that\nswitch button, your Developer Options configurations will be reset to default. The good thing is\nthat when you modify your settings through its Shared Preferences, you won't lose all your settings\nonce the Developer Options is modified. So basically, you have to grant this app\nwith `android.permission.WRITE_SECURE_SETTINGS` in order for it to modify your Settings values.\n\n> [!IMPORTANT]  \n> Watch the tutorial on [YouTube](https://youtu.be/CJrJyHpVVRM?si=ACrEC0hcPed53RAj)\n\n# Screenshots\n\n<div style=\"width:100%; display:flex; justify-content:space-between;\">\n\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/1.jpg\" width=19% alt=\"1\">](fastlane/metadata/android/en-US/images/phoneScreenshots/1.jpg)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/2.jpg\" width=19% alt=\"2\">](fastlane/metadata/android/en-US/images/phoneScreenshots/2.jpg)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/3.jpg\" width=19% alt=\"3\">](fastlane/metadata/android/en-US/images/phoneScreenshots/3.jpg)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/4.jpg\" width=19% alt=\"4\">](fastlane/metadata/android/en-US/images/phoneScreenshots/4.jpg)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/5.jpg\" width=19% alt=\"5\">](fastlane/metadata/android/en-US/images/phoneScreenshots/5.jpg)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/6.jpg\" width=19% alt=\"6\">](fastlane/metadata/android/en-US/images/phoneScreenshots/6.jpg)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/7.jpg\" width=19% alt=\"6\">](fastlane/metadata/android/en-US/images/phoneScreenshots/7.jpg)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/8.jpg\" width=19% alt=\"6\">](fastlane/metadata/android/en-US/images/phoneScreenshots/8.jpg)\n</div>\n\n# Architecture \nMost of the code in this project is based on [Now In Android](https://github.com/android/nowinandroid), but it follows [Clean Architecture](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html) instead.\n\n# License\n\n**Geto** is licensed under the GNU General Public License v3.0. See the [license](LICENSE) for more\ninformation.\n",
      "stars_today": 9
    },
    {
      "id": 1106576943,
      "name": "ReVancedXposed_Spotify",
      "full_name": "chsbuffer/ReVancedXposed_Spotify",
      "description": null,
      "html_url": "https://github.com/chsbuffer/ReVancedXposed_Spotify",
      "stars": 749,
      "forks": 17,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2025-11-29T14:28:56Z",
      "updated_at": "2026-02-07T00:16:41Z",
      "pushed_at": "2025-12-27T15:30:38Z",
      "open_issues": 7,
      "owner": {
        "login": "chsbuffer",
        "avatar_url": "https://avatars.githubusercontent.com/u/33744752?v=4"
      },
      "readme": "<div align=\"center\">\n  <h1>ReVanced Xposed Spotify</h1>\n  <br>\n</div>\n\n**ReVanced LSPosed module by ChsBuffer, just for Spotify.**  \n>[!IMPORTANT]  \n> - This is **NOT an official ReVanced project**, do not ask the ReVanced developers for help.\n> - **Root access** is strictly **required** to use this module!\n\n### Regarding alleged â€œnew working Spotify modsâ€:\n\nRecent claims that _Nibrut, Obito, AndroForever and Shizuku_ provide functioning Spotify mods are incorrect.  \nTheir mod merely applies _Rootless Xposed Framework_ and _generic signature bypass patcher_ together with this module,  \ne.g. Mochi Cloner, App Cloner, LSPatch, NPatch, HKP, MT Manager, NP Manager.  \nHowever, it **does not** address or bypass the actual mechanisms responsible for detecting and blocking modified clients.    \nReVanced Xposed has nothing to do with the bypass mechanisms.  \n  \nThese mods work for a few days until a Spotify app update is released, then Spotify blacklists users of these modded apps on old versions of the client from the server.  \n  \nBefore ReVanced paused patches for Spotify for legal reason,  \nthey released a working test version that still works to this day.  \nThere is something you need to know in order to use it, so find it on the xManager Discord Server and read the instructions.  \n\n## Patches\n\n### Spotify\n- Unlock Spotify Premium\n- Sanitize sharing links\n\n## Downloads\n- **Release build**: [Download](https://github.com/chsbuffer/ReVancedXposed_Spotify/releases/latest)\n\n> [!NOTE]  \n> The package name and signature of this build are different every day. You don't have to reinstall it every day.\n\n## â­ Credits\n\n[DexKit](https://luckypray.org/DexKit/en/): a high-performance dex runtime parsing library.  \n[ReVanced](https://revanced.app): Continuing the legacy of Vanced at [revanced.app](https://revanced.app)  \n",
      "stars_today": 9
    },
    {
      "id": 1036865607,
      "name": "gh-aw",
      "full_name": "github/gh-aw",
      "description": "GitHub Agentic Workflows",
      "html_url": "https://github.com/github/gh-aw",
      "stars": 380,
      "forks": 50,
      "language": "Go",
      "topics": [
        "actions",
        "cai",
        "ci",
        "claude-code",
        "codex",
        "copilot",
        "gh-extension",
        "github-actions"
      ],
      "created_at": "2025-08-12T17:40:41Z",
      "updated_at": "2026-02-07T01:54:46Z",
      "pushed_at": "2026-02-07T02:28:09Z",
      "open_issues": 102,
      "owner": {
        "login": "github",
        "avatar_url": "https://avatars.githubusercontent.com/u/9919?v=4"
      },
      "readme": "<!--\n\nHello fellow agent! Welcome to GitHub Agentic Workflows = Actions + Agent + Safety. \nHere are some pointers to get you started in using this tool.\n\n- Create a new workflow: https://raw.githubusercontent.com/github/gh-aw/main/create.md\n- Install: https://raw.githubusercontent.com/github/gh-aw/main/install.md\n- Reference: https://raw.githubusercontent.com/github/gh-aw/main/.github/aw/github-agentic-workflows.md\n\n-->\n\n# GitHub Agentic Workflows\n\nWrite agentic workflows in natural language markdown, and run them in GitHub Actions.\n\n## Contents\n\n- [Quick Start](#quick-start)\n- [Overview](#overview)\n- [How It Works](#how-it-works)\n- [Safe Agentic Workflows](#safe-agentic-workflows)\n- [Documentation](#documentation)\n- [Contributing](#contributing)\n- [Share Feedback](#share-feedback)\n- [Peli's Agent Factory](#pelis-agent-factory)\n- [Related Projects](#related-projects)\n\n## Quick Start\n\nReady to get your first agentic workflow running? Follow our step-by-step [Quick Start Guide](https://github.github.com/gh-aw/setup/quick-start/) to install the extension, add a sample workflow, and see it in action.\n\n## Overview\n\nLearn about the concepts behind agentic workflows, explore available workflow types, and understand how AI can automate your repository tasks. See [How It Works](https://github.github.io/gh-aw/introduction/how-they-work/).\n\n## How It Works\n\nGitHub Agentic Workflows transforms natural language markdown files into GitHub Actions that are executed by AI agents. Here's an example:\n\n```markdown\n---\non:\n  schedule: daily\npermissions:\n  contents: read\n  issues: read\n  pull-requests: read\nsafe-outputs:\n  create-issue:\n    title-prefix: \"[team-status] \"\n    labels: [report, daily-status]\n    close-older-issues: true\n---\n\n## Daily Issues Report\n\nCreate an upbeat daily status report for the team as a GitHub issue.\n```\n\nThe `gh aw` cli converts this into a GitHub Actions Workflow (.yml) that runs an AI agent (Copilot, Claude, Codex, ...) in a containerized environment on a schedule or manually.\n\nThe AI agent reads your repository context, analyzes issues, generates visualizations, and creates reports - all defined in natural language rather than complex code.\n\n## Safety\n\nSecurity is foundational to GitHub Agentic Workflows. Workflows run with read-only permissions by default, with write operations only allowed through sanitized `safe-outputs`. The system implements multiple layers of protection including sandboxed execution, input sanitization, network isolation, supply chain security (SHA-pinned dependencies), tool allow-listing, and compile-time validation. Access can be gated to team members only, with human approval gates for critical operations, ensuring AI agents operate safely within controlled boundaries. See the [Security Architecture](https://github.github.com/gh-aw/introduction/architecture/) for comprehensive details on threat modeling, implementation guidelines, and best practices.\n\n> [!WARNING]\n> Using agentic workflows in your repository requires careful attention to security considerations and careful human supervision, and even then things can still go wrong. Use it with caution, and at your own risk.\n\n## Documentation\n\nFor complete documentation, examples, and guides, see the [Documentation](https://github.github.com/gh-aw/).\n\n## Contributing\n\nWe welcome contributions to GitHub Agentic Workflows! Here's how you can help:\n\n- **Report bugs and request features** by filing issues in this repository\n- **Improve documentation** by contributing to our docs\n- **Contribute code** by following our [Development Guide](DEVGUIDE.md)\n  - **Quick Start**: See [Common Development Tasks](DEVGUIDE.md#common-development-tasks) for scenario-based command reference\n- **Share ideas** in the `#continuous-ai` channel in the [GitHub Next Discord](https://gh.io/next-discord)\n\nFor development setup and contribution guidelines, see [CONTRIBUTING.md](CONTRIBUTING.md).\n\n## Share Feedback\n\nWe welcome your feedback on GitHub Agentic Workflows! Please file bugs and feature requests as issues in this repository,\nand share your thoughts in the `#continuous-ai` channel in the [GitHub Next Discord](https://gh.io/next-discord).\n\n## Peli's Agent Factory\n\nSee the [Peli's Agent Factory](https://github.github.com/gh-aw/blog/2026-01-12-welcome-to-pelis-agent-factory/) for a guided tour through many uses of agentic workflows.\n\n## Related Projects\n\nGitHub Agentic Workflows is supported by companion projects that provide additional security and integration capabilities:\n\n- **[Agent Workflow Firewall (AWF)](https://github.com/github/gh-aw-firewall)** - Network egress control for AI agents, providing domain-based access controls and activity logging for secure workflow execution\n- **[MCP Gateway](https://github.com/github/gh-aw-mcpg)** - Routes Model Context Protocol (MCP) server calls through a unified HTTP gateway for centralized access management\n- **[The Agentics](https://github.com/githubnext/agentics)** - A collection of reusable agentic workflow components, tools, and templates to accelerate workflow development\n",
      "stars_today": 9
    },
    {
      "id": 3432266,
      "name": "kotlin",
      "full_name": "JetBrains/kotlin",
      "description": "The Kotlin Programming Language. ",
      "html_url": "https://github.com/JetBrains/kotlin",
      "stars": 52264,
      "forks": 6209,
      "language": "Kotlin",
      "topics": [
        "compiler",
        "gradle-plugin",
        "intellij-plugin",
        "kotlin",
        "kotlin-library",
        "maven-plugin",
        "programming-language",
        "wasm",
        "webassembly"
      ],
      "created_at": "2012-02-13T17:29:58Z",
      "updated_at": "2026-02-07T02:27:08Z",
      "pushed_at": "2026-02-07T01:04:29Z",
      "open_issues": 213,
      "owner": {
        "login": "JetBrains",
        "avatar_url": "https://avatars.githubusercontent.com/u/878437?v=4"
      },
      "readme": "[![official project](https://jb.gg/badges/official.svg)](https://confluence.jetbrains.com/display/ALL/JetBrains+on+GitHub)\n[![TeamCity (simple build status)](https://img.shields.io/teamcity/http/teamcity.jetbrains.com/s/Kotlin_KotlinPublic_Compiler.svg)](https://teamcity.jetbrains.com/buildConfiguration/Kotlin_KotlinPublic_Compiler?branch=%3Cdefault%3E&buildTypeTab=overview&mode=builds)\n[![Maven Central](https://img.shields.io/maven-central/v/org.jetbrains.kotlin/kotlin-maven-plugin.svg)](https://search.maven.org/#search%7Cga%7C1%7Cg%3A%22org.jetbrains.kotlin%22)\n[![GitHub license](https://img.shields.io/badge/license-Apache%20License%202.0-blue.svg?style=flat)](https://www.apache.org/licenses/LICENSE-2.0)\n[![Revved up by Develocity](https://img.shields.io/badge/Revved%20up%20by-Develocity-06A0CE?logo=Gradle&labelColor=02303A)](https://ge.jetbrains.com/scans?search.rootProjectNames=Kotlin)\n\n# Kotlin Programming Language\n\nWelcome to [Kotlin](https://kotlinlang.org/)!   \nKotlin is a concise multiplatform language developed by [JetBrains](https://www.jetbrains.com/) and [contributors](https://kotlinlang.org/docs/contribute.html).\n\nSome handy links:\n\n * [Kotlin Site](https://kotlinlang.org/)\n * [Getting Started Guide](https://kotlinlang.org/docs/tutorials/getting-started.html)\n * [Try Kotlin](https://play.kotlinlang.org/)\n * [Kotlin Standard Library](https://kotlinlang.org/api/latest/jvm/stdlib/index.html)\n * [Issue Tracker](https://youtrack.jetbrains.com/issues/KT)\n * [Kotlin YouTube Channel](https://www.youtube.com/channel/UCP7uiEZIqci43m22KDl0sNw)\n * [Forum](https://discuss.kotlinlang.org/)\n * [Kotlin Blog](https://blog.jetbrains.com/kotlin/)\n * [Subscribe to Kotlin YouTube channel](https://www.youtube.com/channel/UCP7uiEZIqci43m22KDl0sNw)\n * [Follow Kotlin on Twitter](https://twitter.com/kotlin)\n * [Public Slack channel](https://slack.kotlinlang.org/)\n * [TeamCity CI build](https://teamcity.jetbrains.com/project.html?tab=projectOverview&projectId=Kotlin)\n * [Kotlin Foundation](https://kotlinfoundation.org/)\n\n## Kotlin Multiplatform capabilities\n\nSupport for multiplatform programming is one of Kotlinâ€™s key benefits. It reduces time spent writing and maintaining the same code for [different platforms](https://kotlinlang.org/docs/reference/mpp-supported-platforms.html) while retaining the flexibility and benefits of native programming.\n\n * [Kotlin Multiplatform](https://www.jetbrains.com/kotlin-multiplatform/) and [Compose Multiplatform](https://www.jetbrains.com/compose-multiplatform/) for sharing business logic and UI between Android, iOS, desktop, and web.\n * [Get started with Kotlin Multiplatform](https://www.jetbrains.com/help/kotlin-multiplatform-dev/get-started.html)\n * [Kotlin Multiplatform Benefits](https://kotlinlang.org/docs/reference/multiplatform.html)\n * [Share code on all platforms](https://kotlinlang.org/docs/reference/mpp-share-on-platforms.html#share-code-on-all-platforms)\n * [Share code on similar platforms](https://kotlinlang.org/docs/reference/mpp-share-on-platforms.html#share-code-on-similar-platforms)\n\n## Editing Kotlin\n\n * [Kotlin IntelliJ IDEA Plugin](https://kotlinlang.org/docs/tutorials/getting-started.html) ([source code](https://github.com/JetBrains/intellij-community/tree/master/plugins/kotlin))\n * [Kotlin Eclipse Plugin](https://kotlinlang.org/docs/tutorials/getting-started-eclipse.html)\n * [Kotlin Sublime Text Package](https://github.com/vkostyukov/kotlin-sublime-package)\n\n## Build environment requirements\n\nThis repository is using [Gradle toolchains](https://docs.gradle.org/current/userguide/toolchains.html) feature\nto select and auto-provision required JDKs from [Eclipse Adoptium](https://adoptium.net) project.\n\nAlternatively, it is still possible to only provide required JDKs via environment variables \n(see [gradle.properties](./gradle.properties#L5) for supported variable names). To ensure Gradle uses only JDKs \nfrom environmental variables - disable Gradle toolchain auto-detection by passing `-Porg.gradle.java.installations.auto-detect=false` option\n(or put it into `$GRADLE_USER_HOME/gradle.properties`).\n\nOn Windows you might need to add long paths setting to the repo:\n\n    git config core.longpaths true \n\n## Building\n\nThe project is built with Gradle. Run Gradle to build the project and to run the tests \nusing the following command on Unix/macOS:\n\n    ./gradlew <tasks-and-options>\n    \nor the following command on Windows:\n\n    gradlew <tasks-and-options>\n\nOn the first project configuration gradle will download and setup the dependencies on:\n\n* `intellij-core` is a part of command line compiler and contains only necessary APIs.\n* `idea-full` is a full blown IntelliJ IDEA Community Edition to be used in the plugin module.\n\nThese dependencies are quite large, so depending on the quality of your internet connection \nyou might face timeouts getting them. In this case, you can increase timeout by specifying the following \ncommand line parameters on the first run: \n    \n    ./gradlew -Dhttp.socketTimeout=60000 -Dhttp.connectionTimeout=60000\n\n## Important gradle tasks\n\n- `clean` - clean build results\n- `dist` - assembles the compiler distribution into `dist/kotlinc/` folder\n- `install` - build and install all public artifacts into local maven repository\n- `coreLibsTest` - build and run stdlib, reflect and kotlin-test tests\n- `gradlePluginTest` - build and run gradle plugin tests\n- `compilerTest` - build and run all compiler tests\n\nTo reproduce TeamCity build use `-Pteamcity=true` flag. Local builds don't run proguard and have jar compression disabled by default.\n\n**OPTIONAL:** Some artifacts, mainly Maven plugin ones, are built separately with Maven.\nRefer to [libraries/ReadMe.md](libraries/ReadMe.md) for details.\n\nTo build Kotlin/Native, see\n[kotlin-native/README.md](kotlin-native/README.md#building-from-source).\n\n## <a name=\"working-in-idea\"></a> Working with the project in IntelliJ IDEA\n\nIt is recommended to use the latest released version of Intellij IDEA (Community or Ultimate Edition). You can download IntelliJ IDEA [here](https://www.jetbrains.com/idea/download).\n\nAfter cloning the project, import the project in IntelliJ by choosing the project directory in the Open project dialog.\n\nFor handy work with compiler tests it's recommended to use [Kotlin Compiler Test Helper](https://github.com/demiurg906/test-data-helper-plugin).\n\n### Dependency verification\n\nWe have a [dependencies verification](https://docs.gradle.org/current/userguide/dependency_verification.html) feature enabled in the\nrepository for all Gradle builds. Gradle will check hashes (md5 and sha256) of used dependencies and will fail builds with\n`Dependency verification failed` errors when local artifacts are absent or have different hashes listed in the\n[verification-metadata.xml](https://github.com/JetBrains/kotlin/blob/master/gradle/verification-metadata.xml) file.\n\nIt's expected that `verification-metadata.xml` should only be updated with the commits that modify the build. There are some tips how\nto perform such updates:\n\n- Delete `components` section of `verification-metadata.xml` to avoid stockpiling of old unused dependencies. You may use the following command:\n```bash\n#macOS\nsed -i '' -e '/<components>/,/<\\/components>/d' gradle/verification-metadata.xml\n#Linux & Git for Windows\nsed -i -e '/<components>/,/<\\/components>/d' gradle/verification-metadata.xml\n```\n- Re-generate dependencies with Gradle's `--write-verification-metadata` command (verify update relates to your changes)\n\n```bash\n./gradlew --write-verification-metadata sha256,md5 -Pkotlin.native.enabled=true resolveDependencies\n```\n\n*`resolveDependencies` task resolves dependencies for all platforms including dependencies downloaded by plugins.*\n\nYou can also use `./scripts/update-verification-metadata.sh` script which includes both of these steps\n\nKeep in mind:\n\n- If youâ€™re adding a dependency with OS mentioned in an artifact name (`darwin`, `mac`, `osx`, `linux`, `windows`), remember to add them to \n  `implicitDependencies` configuration or update `resolveDependencies` task if needed. `resolveDependencies` should resolve all dependencies\n  including dependencies for different platforms.\n- If you have a `local.properties` file in your Kotlin project folder, make sure that it doesn't contain `kotlin.native.enabled=false`.\n  Otherwise, native-only dependencies may not be added to the verification metadata. This is because `local.properties` has higher \n  precedence than the `-Pkotlin.native.enabled=true` specified in the Gradle command.\n\n## Using -dev versions\n\nWe publish `-dev` versions frequently.\n\nFor `-dev` versions you can use the [list of available versions](https://redirector.kotlinlang.org/maven/bootstrap/org/jetbrains/kotlin/kotlin-compiler/maven-metadata.xml) and include this maven repository:\n\n```kotlin\nmaven(\"https://redirector.kotlinlang.org/maven/bootstrap\")\n```\n\n# License\nKotlin is distributed under the terms of the Apache License (Version 2.0). See [license folder](license/README.md) for details.\n\n# Contributing\n\nPlease be sure to review Kotlin's [contributing guidelines](docs/contributing.md) to learn how to help the project.\n\n# Kotlin Foundation\n\nThe Kotlin Foundation is a non-profit organization whose mission is to promote and advance the Kotlin ecosystem. You can learn more about the structure and goals of the Kotlin Foundation on its [official website](https://kotlinfoundation.org/).\n",
      "stars_today": 8
    },
    {
      "id": 41986369,
      "name": "tidb",
      "full_name": "pingcap/tidb",
      "description": "TiDB - the open-source, cloud-native, distributed SQL database designed for modern applications.",
      "html_url": "https://github.com/pingcap/tidb",
      "stars": 39704,
      "forks": 6109,
      "language": "Go",
      "topics": [
        "cloud-native",
        "database",
        "distributed-database",
        "distributed-transactions",
        "go",
        "hacktoberfest",
        "htap",
        "mysql",
        "mysql-compatibility",
        "scale",
        "serverless",
        "sql",
        "tidb"
      ],
      "created_at": "2015-09-06T04:01:52Z",
      "updated_at": "2026-02-06T23:09:04Z",
      "pushed_at": "2026-02-06T17:54:32Z",
      "open_issues": 5619,
      "owner": {
        "login": "pingcap",
        "avatar_url": "https://avatars.githubusercontent.com/u/11855343?v=4"
      },
      "readme": "<div align=\"center\">\n<a href='https://www.pingcap.com/?utm_source=github&utm_medium=tidb'>\n<img src=\"docs/tidb-logo.png\" alt=\"TiDB, a distributed SQL database\" height=100></img>\n</a>\n\n---\n\n[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://github.com/pingcap/tidb/blob/master/LICENSE)\n[![Language](https://img.shields.io/badge/Language-Go-blue.svg)](https://golang.org/)\n\n[![Build Status](https://prow.tidb.net/badge.svg?jobs=merged-tidb-build)](https://prow.tidb.net/?repo=pingcap%2Ftidb&type=postsubmit&job=merged-tidb-build)\n[![Go Report Card](https://goreportcard.com/badge/github.com/pingcap/tidb)](https://goreportcard.com/report/github.com/pingcap/tidb)\n[![GitHub release](https://img.shields.io/github/tag/pingcap/tidb.svg?label=release)](https://github.com/pingcap/tidb/releases)\n</div>\n\n# TiDB\n\nTiDB (/â€™taÉªdiËbi:/, \"Ti\" stands for Titanium) is an open-source, cloud-native, distributed SQL database designed for high availability, horizontal and vertical scalability, strong consistency, and high performance.\n\n- [Key Features](#key-features)\n- [Quick Start](#quick-start)\n- [Need Help?](#need-help)\n- [Architecture](#architecture)\n- [Contributing](#contributing)\n- [License](#license)\n- [See Also](#see-also)\n- [Acknowledgments](#acknowledgments)\n\n## Key Features\n\n- **[Distributed Transactions](https://www.pingcap.com/blog/distributed-transactions-tidb?utm_source=github&utm_medium=tidb)**: TiDB uses a two-phase commit protocol to ensure ACID compliance, providing strong consistency. Transactions span multiple nodes, and TiDB's distributed nature ensures data correctness even in the presence of network partitions or node failures.\n\n- **[Horizontal and Vertical Scalability](https://docs.pingcap.com/tidb/stable/scale-tidb-using-tiup?utm_source=github&utm_medium=tidb)**: TiDB can be scaled horizontally by adding more nodes or vertically by increasing resources of existing nodes, all without downtime. TiDB's architecture separates computing from storage, enabling you to adjust both independently as needed for flexibility and growth.\n\n- **[High Availability](https://docs.pingcap.com/tidbcloud/high-availability-with-multi-az?utm_source=github&utm_medium=tidb)**: Built-in Raft consensus protocol ensures reliability and automated failover. Data is stored in multiple replicas, and transactions are committed only after writing to the majority of replicas, guaranteeing strong consistency and availability, even if some replicas fail. Geographic placement of replicas can be configured for different disaster tolerance levels.\n\n- **[Hybrid Transactional/Analytical Processing (HTAP)](https://www.pingcap.com/blog/htap-demystified-defining-modern-data-architecture-tidb?utm_source=github&utm_medium=tidb)**: TiDB provides two storage engines: TiKV, a row-based storage engine, and TiFlash, a columnar storage engine. TiFlash uses the Multi-Raft Learner protocol to replicate data from TiKV in real time, ensuring consistent data between the TiKV row-based storage engine and the TiFlash columnar storage engine. The TiDB Server coordinates query execution across both TiKV and TiFlash to optimize performance.\n\n- **[Cloud-Native](https://www.pingcap.com/cloud-native?utm_source=github&utm_medium=tidb)**: TiDB can be deployed in public clouds, on-premises, or natively in Kubernetes. [TiDB Operator](https://docs.pingcap.com/tidb-in-kubernetes/stable/tidb-operator-overview/?utm_source=github&utm_medium=tidb) helps manage TiDB on Kubernetes, automating cluster operations, while [TiDB Cloud](https://tidbcloud.com/?utm_source=github&utm_medium=tidb) provides a fully-managed service for easy and economical deployment, allowing users to set up clusters with just a few clicks.\n\n- **[MySQL Compatibility](https://docs.pingcap.com/tidb/stable/mysql-compatibility?utm_source=github&utm_medium=tidb)**: TiDB is compatible with MySQL 8.0, allowing you to use familiar protocols, frameworks and tools. You can migrate applications to TiDB without changing any code, or with minimal modifications. Additionally, TiDB provides a suite of [data migration tools](https://docs.pingcap.com/tidb/stable/ecosystem-tool-user-guide?utm_source=github&utm_medium=tidb) to help easily migrate application data into TiDB.\n\n- **[Open Source Commitment](https://www.pingcap.com/blog/open-source-is-in-our-dna-reaffirming-tidb-commitment?utm_source=github&utm_medium=tidb)**: Open source is at the core of TiDB's identity. All source code is available on GitHub under the Apache 2.0 license, including enterprise-grade features. TiDB is built with the belief that open source enables transparency, innovation, and collaboration. We actively encourage contributions from the community to help build a vibrant and inclusive ecosystem, reaffirming our commitment to open development and accessibility for everyone.\n\n## Quick Start\n\n1. Start a TiDB cluster.\n\n    - **On local playground**. To start a local test cluster, refer to the [TiDB quick start guide](https://docs.pingcap.com/tidb/stable/quick-start-with-tidb#deploy-a-local-test-cluster?utm_source=github&utm_medium=tidb).\n\n    - **On Kubernetes**. TiDB can be easily deployed in a self-managed Kubernetes environment or Kubernetes services on public clouds using TiDB Operator. For more details, refer to the [TiDB on Kubernetes quick start guide](https://docs.pingcap.com/tidb-in-kubernetes/stable/get-started?utm_source=github&utm_medium=tidb).\n\n    - **Using TiDB Cloud (recommended)**. TiDB Cloud offers a fully managed version of TiDB with a free plan, no credit card required, so you can get a free cluster in seconds and start easily: [Sign up for TiDB Cloud](https://tidbcloud.com/free-trial?utm_source=github&utm_medium=tidb).\n\n2. Learn about TiDB SQL: To explore the SQL capabilities of TiDB, refer to the [TiDB SQL documentation](https://docs.pingcap.com/tidb/stable/sql-statement-overview?utm_source=github&utm_medium=tidb).\n\n3. Use a MySQL driver or an ORM to [Build an App with TiDB](https://docs.pingcap.com/tidbcloud/dev-guide-overview?utm_source=github&utm_medium=tidb).\n\n4. Explore key features, such as [data migration](https://docs.pingcap.com/tidbcloud/tidb-cloud-migration-overview?utm_source=github&utm_medium=tidb), [changefeed](https://docs.pingcap.com/tidbcloud/changefeed-overview?utm_source=github&utm_medium=tidb), [vector search](https://docs.pingcap.com/tidbcloud/vector-search-overview?utm_source=github&utm_medium=tidb), [HTAP](https://docs.pingcap.com/tidbcloud/tidb-cloud-htap-quickstart?utm_source=github&utm_medium=tidb), [disaster recovery](https://docs.pingcap.com/tidb/stable/dr-solution-introduction?utm_source=github&utm_medium=tidb), etc.\n\n\n## Need Help?\n\n- You can connect with TiDB users, ask questions, find answers, and help others on our community platforms: [Discord](https://discord.gg/KVRZBR2DrG?utm_source=github), Slack ([English](https://slack.tidb.io/invite?team=tidb-community&channel=everyone&ref=pingcap-tidb), [Japanese](https://slack.tidb.io/invite?team=tidb-community&channel=tidb-japan&ref=github-tidb)), [Stack Overflow](https://stackoverflow.com/questions/tagged/tidb), [TiDB Chinese Forum](https://asktug.com), X [@PingCAP](https://twitter.com/PingCAP)\n\n- For filing bugs, suggesting improvements, or requesting new features, use [Github Issues](https://github.com/pingcap/tidb/issues) or join discussions on [Github Discussions](https://github.com/orgs/pingcap/discussions).\n\n- To troubleshoot TiDB, refer to [Troubleshooting documentation](https://docs.pingcap.com/tidb/stable/tidb-troubleshooting-map?utm_source=github&utm_medium=tidb).\n\n## Architecture\n\n![TiDB architecture](./docs/tidb-architecture.png)\n\nLearn more details about TiDB architecture in our [Docs](https://docs.pingcap.com/tidb/stable/tidb-architecture?utm_source=github&utm_medium=tidb).\n\n## Contributing\n\nTiDB is built on a commitment to open source, and we welcome contributions from everyone. Whether you are interested in improving documentation, fixing bugs, or developing new features, we invite you to shape the future of TiDB.\n\n- See our [Contributor Guide](https://github.com/pingcap/community/blob/master/contributors/README.md#how-to-contribute) and [TiDB Development Guide](https://pingcap.github.io/tidb-dev-guide/index.html) to get started.\n\n- If you're looking for issues to work on, try looking at the [good first issues](https://github.com/pingcap/tidb/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22) or [help wanted issues](https://github.com/pingcap/tidb/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22).\n\n- The [contribution map](https://github.com/pingcap/tidb-map/blob/master/maps/contribution-map.md#a-map-that-guides-what-and-how-contributors-can-contribute) lists everything you can contribute.\n\n- The [community repository](https://github.com/pingcap/community) contains everything else you need.\n\n- Don't forget to claim your contribution swag by filling in and submitting this [form](https://forms.pingcap.com/f/tidb-contribution-swag).\n\n\n<a href=\"https://next.ossinsight.io/widgets/official/compose-recent-active-contributors?repo_id=41986369&limit=30\" target=\"_blank\" style=\"display: block\" align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://next.ossinsight.io/widgets/official/compose-recent-active-contributors/thumbnail.png?repo_id=41986369&limit=30&image_size=auto&color_scheme=dark\" width=\"655\" height=\"auto\">\n    <img alt=\"Active Contributors of pingcap/tidb - Last 28 days\" src=\"https://next.ossinsight.io/widgets/official/compose-recent-active-contributors/thumbnail.png?repo_id=41986369&limit=30&image_size=auto&color_scheme=light\" width=\"655\" height=\"auto\">\n  </picture>\n</a>\n\n## License\n\nTiDB is under the Apache 2.0 license. See the [LICENSE](./LICENSE) file for details.\n\n## See Also\n\n- [TiDB Online Playground](https://play.tidbcloud.com/?utm_source=github&utm_medium=tidb_readme)\n- TiDB Case Studies: [TiDB Customers](https://www.pingcap.com/customers/?utm_source=github&utm_medium=tidb), [TiDB äº‹ä¾‹è¨˜äº‹](https://pingcap.co.jp/case-study/?utm_source=github&utm_medium=tidb), [TiDB ä¸­æ–‡ç”¨æˆ·æ¡ˆä¾‹](https://cn.pingcap.com/case/?utm_source=github&utm_medium=tidb)\n- [TiDB User Documentation](https://docs.pingcap.com/tidb/stable?utm_source=github&utm_medium=tidb)\n- [TiDB Design Docs](/docs/design)\n- [TiDB Release Notes](https://docs.pingcap.com/tidb/dev/release-notes?utm_source=github&utm_medium=tidb)\n- [TiDB Blog](https://www.pingcap.com/blog/?utm_source=github&utm_medium=tidb)\n- [TiDB Roadmap](roadmap.md)\n\n## Acknowledgments\n\n- Thanks [cznic](https://github.com/cznic) for providing some great open source tools.\n- Thanks [GolevelDB](https://github.com/syndtr/goleveldb), [BoltDB](https://github.com/boltdb/bolt), and [RocksDB](https://github.com/facebook/rocksdb) for their powerful storage engines.\n",
      "stars_today": 8
    },
    {
      "id": 2489216,
      "name": "intellij-community",
      "full_name": "JetBrains/intellij-community",
      "description": "IntelliJ IDEA & IntelliJ Platform",
      "html_url": "https://github.com/JetBrains/intellij-community",
      "stars": 19663,
      "forks": 5682,
      "language": "Java",
      "topics": [
        "code-editor",
        "ide",
        "intellij",
        "intellij-community",
        "intellij-platform"
      ],
      "created_at": "2011-09-30T13:33:05Z",
      "updated_at": "2026-02-07T00:51:51Z",
      "pushed_at": "2026-02-07T00:51:44Z",
      "open_issues": 152,
      "owner": {
        "login": "JetBrains",
        "avatar_url": "https://avatars.githubusercontent.com/u/878437?v=4"
      },
      "readme": "[![official JetBrains project](http://jb.gg/badges/official.svg)](https://github.com/JetBrains/.github/blob/main/profile/README.md) [![IntelliJ IDEA build status](https://github.com/JetBrains/intellij-community/workflows/IntelliJ%20IDEA/badge.svg)](https://github.com/JetBrains/intellij-community/actions/workflows/IntelliJ_IDEA.yml) [![PyCharm build status](https://github.com/JetBrains/intellij-community/workflows/PyCharm/badge.svg)](https://github.com/JetBrains/intellij-community/actions/workflows/PyCharm.yml)\n\n# IntelliJ Open Source Repository\n\nThis repository is the open-source part of the JetBrains IDEs codebase.\nIt also serves as the basis forÂ [IntelliJ Platform development](https://www.jetbrains.com/opensource/idea). \n\nThese instructions will help you build and run open source parts of IntelliJ Platform / IntelliJ IDEA / PyCharm.\n\nIf you are new to the community and would like to contribute code or help others learn, seeÂ [CONTRIBUTING.md](https://github.com/JetBrains/intellij-community/blob/master/CONTRIBUTING.md)Â to get started.\n\nThe following conventions will be used to refer to directories on your machine:\n* `<USER_HOME>` is your OS user's home directory.\n* `<IDEA_HOME>` is the root directory for the **IntelliJ source code**.\n\n___\n## Getting the Source Code\n\nThis section will guide you through getting the project sources and help avoid common issues in git config and other steps before opening it in the IDE.\n\n#### Prerequisites\n- [Git](https://git-scm.com/) installed\n- Install [IntelliJ IDEA 2023.2](https://www.jetbrains.com/idea/download) or higher.\n- For **Windows** set these git config to avoid common issues during cloning:\n  ```\n  git config --global core.longpaths true\n  git config --global core.autocrlf input\n  ```\n\n#### Clone Main Repository\n\nIntelliJ open source repository is available from the [GitHub repository](https://github.com/JetBrains/intellij-community), which can be cloned or downloaded as a zip file (based on a branch) into `<IDEA_HOME>`. \nThe **master** (_default_) branch contains the source code which will be used to create the next major version of all JetBrains IDEs. \nThe branch names and build numbers for older releases of JetBrains IDEs can be found on the\n[Build Number Ranges](https://plugins.jetbrains.com/docs/intellij/build-number-ranges.html) page.\n\nYou can [clone this project](https://www.jetbrains.com/help/idea/manage-projects-hosted-on-github.html#clone-from-GitHub) directly using IntelliJ IDEA. \n\nAlternatively, follow the steps below in a terminal:\n\n   ```\n   git clone https://github.com/JetBrains/intellij-community.git\n   cd intellij-community\n   ```\n\n> [!TIP]\n> - **For faster download**: If the complete repository history isn't needed, create [shallow clone](https://git-scm.com/docs/git-clone#Documentation/git-clone.txt---depthdepth)\n> To download only the latest revision of the repository,  add `--depth 1` option after `clone`.\n> - Cloning in IntelliJ IDEA also supports creating shallow clone.\n\n#### Get Android Modules\nIntelliJ IDEA requires additional Android modules from separate Git repositories.\n\nRun the following script from project root `<IDEA_HOME>` to get the required modules:\n- Linux/macOS: `./getPlugins.sh`\n- Windows: `getPlugins.bat`\n\n> [!IMPORTANT]\n>\n>  Always `git checkout` the `intellij-community` and `android` Git repositories to the same branches/tags.\n\n\n---\n## Building IntelliJ IDEA\n\n> [Standard GitHub runners](https://docs.github.com/en/actions/concepts/runners/github-hosted-runners) can no longer be used to build the project due to the disk size limitation.\n> Now we use [larger runners](https://docs.github.com/en/enterprise-cloud@latest/actions/concepts/runners/larger-runners) which are only available for organizations and enterprises using the GitHub Team or GitHub Enterprise Cloud plans.\n> Users of personal GitHub accounts can use [the prebuilt binaries](https://github.com/JetBrains/intellij-community/releases), \n> or build IntelliJ IDEA from source code locally.\n\nThese instructions will help you build IntelliJ IDEA from source code, which is the basis for IntelliJ Platform development.\nIntelliJ IDEA '**2023.2**' or newer is required.\n\n### Opening the IntelliJ IDEA Source Code in the IDE\nUsing the latest IntelliJ IDEA, click '**File | Open**', select the `<IDEA_HOME>` directory.\nIf IntelliJ IDEA displays a message about a missing or out-of-date required plugin (e.g. Kotlin),\n[enable, upgrade, or install that plugin](https://www.jetbrains.com/help/idea/managing-plugins.html) and restart IntelliJ IDEA.\n\n\n### Build Configuration Steps\n1. **JDK Setup**\n\n- Use JetBrains Runtime 21 (without JCEF) to compile\n  - IDE will prompt to download it on the first build\n> [!IMPORTANT]\n>\n> JetBrains Runtime **without** JCEF is required. If `jbr-21` SDK points to JCEF version, change it to the non-JCEF version:\n> - Add `idea.is.internal=true` to `idea.properties` and restart the IDE.\n> - Go to '**Project Structure | SDKs**'\n> - Click 'Browse' â†’ 'Download...'\n> - Select version 21 and vendor 'JetBrains Runtime'\n> - To confirm if the JDK is correct, navigate to the SDK page with jbr-21 selected. Search for `jcef`, it should **_NOT_** yield a result.\n\n2. **Maven Configuration** : If theÂ **Maven**Â plugin is disabled,Â [add the path variable](https://www.jetbrains.com/help/idea/absolute-path-variables.html)Â \"**MAVEN_REPOSITORY**\" pointing toÂ `<USER_HOME>/.m2/repository`Â directory.\n\n3. **Memory Settings**\n  - Ensure a minimum **8GB** RAM on your computer.\n  - With the minimum RAM, disable \"**Compile independent modules in parallel**\" in '**Settings | Build, Execution, Deployment | Compiler**'.\n  - With notably higher available RAM, Increase \"**User-local heap size**\" to `3000`.\n\n\n### Building the IntelliJ IDEA Application from Source\n\n**To build IntelliJ IDEA from source**, choose '**Build | Build Project**' from the main menu.\n\n**To build installation packages**, run the [installers.cmd](installers.cmd) script in `<IDEA_HOME>` directory. `installers.cmd` will work on both Windows and Unix systems.\nOptions to build installers are passed as system properties to `installers.cmd` command.\nYou may find the list of available properties in [BuildOptions.kt](platform/build-scripts/src/org/jetbrains/intellij/build/BuildOptions.kt)\n\nPass --debug to suspend and wait for debugger at port 5005\n\nInstaller build examples:\n```bash\n# Build installers only for current operating system:\n./installers.cmd -Dintellij.build.target.os=current\n```\n\n> [!TIP]\n> \n> The `installers.cmd` is used to run [OpenSourceCommunityInstallersBuildTarget](build/src/OpenSourceCommunityInstallersBuildTarget.kt) from the command line.\n> You can also call it directly from IDEA, using run configuration `Build IntelliJ IDEA Installers (current OS)`.\n\n\n#### Dockerized Build Environment\nTo build installation packages inside a Docker container with preinstalled dependencies and tools, run the following command in `<IDEA_HOME>` directory (on Windows, use PowerShell):\n```bash\ndocker build . --target intellij_idea --tag intellij_idea_env\ndocker run --rm --user \"$(id -u)\" --volume \"${PWD}:/community\" intellij_idea_env\n```\n> [!NOTE]\n> \n> Please remember to specify the `--user \"$(id -u)\"` argument for the container's user to match the host's user.\n> This prevents issues with permissions for the checked-out repository, the build output, if any.\n\n---\n## Running IntelliJ IDEA\nTo run the IntelliJ IDEA that was built from source, choose '**Run | Run**' from the main menu. This will use the preconfigured run configuration `IDEA`.\n\nTo run tests on the build, apply these settings to the '**Run | Edit Configurations... | Templates | JUnit**' configuration tab:\n* Working dir: `<IDEA_HOME>/bin`\n* VM options:  `-ea`\n\n\n#### Running IntelliJ IDEA in CI/CD environment\n\nTo run tests outside of IntelliJ IDEA, run the `tests.cmd` command in `<IDEA_HOME>` directory.`tests.cmd` can be used in both Windows and Unix systems.\nOptions to run tests are passed as system properties to `tests.cmd` command.\nYou may find the list of available properties in [TestingOptions.kt](platform/build-scripts/src/org/jetbrains/intellij/build/TestingOptions.kt)\n\n```bash\n# Run specific run configuration:\n./tests.cmd -Dintellij.build.test.configurations=ApiCheckTest\n```\n```bash\n# Run a specific test: \n./tests.cmd -Dintellij.build.test.patterns=com.intellij.util.ArrayUtilTest\n```\n\nto debug tests use: `-Dintellij.build.test.debug.suspend=true -Dintellij.build.test.debug.port=5005`\n\n`tests.cmd` is used just to run [CommunityRunTestsBuildTarget](build/src/CommunityRunTestsBuildTarget.kt) from the command line.\nYou can also call it directly from IDEA, see run configuration `tests` for an example.",
      "stars_today": 8
    },
    {
      "id": 118105436,
      "name": "migrate",
      "full_name": "golang-migrate/migrate",
      "description": "Database migrations. CLI and Golang library.",
      "html_url": "https://github.com/golang-migrate/migrate",
      "stars": 18065,
      "forks": 1545,
      "language": "Go",
      "topics": [
        "aws-s3",
        "cassandra",
        "database",
        "databases",
        "go",
        "golang",
        "google-cloud-spanner",
        "google-cloud-storage",
        "hacktoberfest",
        "mariadb",
        "migration",
        "migrations",
        "mongodb",
        "mysql",
        "neo4j",
        "postgres",
        "spanner",
        "sql",
        "sqlite"
      ],
      "created_at": "2018-01-19T09:30:58Z",
      "updated_at": "2026-02-06T20:59:32Z",
      "pushed_at": "2025-12-14T23:16:48Z",
      "open_issues": 449,
      "owner": {
        "login": "golang-migrate",
        "avatar_url": "https://avatars.githubusercontent.com/u/35595841?v=4"
      },
      "readme": "[![GitHub Workflow Status (branch)](https://img.shields.io/github/actions/workflow/status/golang-migrate/migrate/ci.yaml?branch=master)](https://github.com/golang-migrate/migrate/actions/workflows/ci.yaml?query=branch%3Amaster)\n[![GoDoc](https://pkg.go.dev/badge/github.com/golang-migrate/migrate)](https://pkg.go.dev/github.com/golang-migrate/migrate/v4)\n[![Coverage Status](https://img.shields.io/coveralls/github/golang-migrate/migrate/master.svg)](https://coveralls.io/github/golang-migrate/migrate?branch=master)\n[![packagecloud.io](https://img.shields.io/badge/deb-packagecloud.io-844fec.svg)](https://packagecloud.io/golang-migrate/migrate?filter=debs)\n[![Docker Pulls](https://img.shields.io/docker/pulls/migrate/migrate.svg)](https://hub.docker.com/r/migrate/migrate/)\n![Supported Go Versions](https://img.shields.io/badge/Go-1.24%2C%201.25-lightgrey.svg)\n[![GitHub Release](https://img.shields.io/github/release/golang-migrate/migrate.svg)](https://github.com/golang-migrate/migrate/releases)\n[![Go Report Card](https://goreportcard.com/badge/github.com/golang-migrate/migrate/v4)](https://goreportcard.com/report/github.com/golang-migrate/migrate/v4)\n\n# migrate\n\n__Database migrations written in Go. Use as [CLI](#cli-usage) or import as [library](#use-in-your-go-project).__\n\n* Migrate reads migrations from [sources](#migration-sources)\n   and applies them in correct order to a [database](#databases).\n* Drivers are \"dumb\", migrate glues everything together and makes sure the logic is bulletproof.\n   (Keeps the drivers lightweight, too.)\n* Database drivers don't assume things or try to correct user input. When in doubt, fail.\n\nForked from [mattes/migrate](https://github.com/mattes/migrate)\n\n## Databases\n\nDatabase drivers run migrations. [Add a new database?](database/driver.go)\n\n* [PostgreSQL](database/postgres)\n* [PGX v4](database/pgx)\n* [PGX v5](database/pgx/v5)\n* [Redshift](database/redshift)\n* [Ql](database/ql)\n* [Cassandra / ScyllaDB](database/cassandra)\n* [SQLite](database/sqlite)\n* [SQLite3](database/sqlite3) ([todo #165](https://github.com/mattes/migrate/issues/165))\n* [SQLCipher](database/sqlcipher)\n* [MySQL / MariaDB](database/mysql)\n* [Neo4j](database/neo4j)\n* [MongoDB](database/mongodb)\n* [CrateDB](database/crate) ([todo #170](https://github.com/mattes/migrate/issues/170))\n* [Shell](database/shell) ([todo #171](https://github.com/mattes/migrate/issues/171))\n* [Google Cloud Spanner](database/spanner)\n* [CockroachDB](database/cockroachdb)\n* [YugabyteDB](database/yugabytedb)\n* [ClickHouse](database/clickhouse)\n* [Firebird](database/firebird)\n* [MS SQL Server](database/sqlserver)\n* [rqlite](database/rqlite)\n\n### Database URLs\n\nDatabase connection strings are specified via URLs. The URL format is driver dependent but generally has the form: `dbdriver://username:password@host:port/dbname?param1=true&param2=false`\n\nAny [reserved URL characters](https://en.wikipedia.org/wiki/Percent-encoding#Percent-encoding_reserved_characters) need to be escaped. Note, the `%` character also [needs to be escaped](https://en.wikipedia.org/wiki/Percent-encoding#Percent-encoding_the_percent_character)\n\nExplicitly, the following characters need to be escaped:\n`!`, `#`, `$`, `%`, `&`, `'`, `(`, `)`, `*`, `+`, `,`, `/`, `:`, `;`, `=`, `?`, `@`, `[`, `]`\n\nIt's easiest to always run the URL parts of your DB connection URL (e.g. username, password, etc) through an URL encoder. See the example Python snippets below:\n\n```bash\n$ python3 -c 'import urllib.parse; print(urllib.parse.quote(input(\"String to encode: \"), \"\"))'\nString to encode: FAKEpassword!#$%&'()*+,/:;=?@[]\nFAKEpassword%21%23%24%25%26%27%28%29%2A%2B%2C%2F%3A%3B%3D%3F%40%5B%5D\n$ python2 -c 'import urllib; print urllib.quote(raw_input(\"String to encode: \"), \"\")'\nString to encode: FAKEpassword!#$%&'()*+,/:;=?@[]\nFAKEpassword%21%23%24%25%26%27%28%29%2A%2B%2C%2F%3A%3B%3D%3F%40%5B%5D\n$\n```\n\n## Migration Sources\n\nSource drivers read migrations from local or remote sources. [Add a new source?](source/driver.go)\n\n* [Filesystem](source/file) - read from filesystem\n* [io/fs](source/iofs) - read from a Go [io/fs](https://pkg.go.dev/io/fs#FS)\n* [Go-Bindata](source/go_bindata) - read from embedded binary data ([jteeuwen/go-bindata](https://github.com/jteeuwen/go-bindata))\n* [pkger](source/pkger) - read from embedded binary data ([markbates/pkger](https://github.com/markbates/pkger))\n* [GitHub](source/github) - read from remote GitHub repositories\n* [GitHub Enterprise](source/github_ee) - read from remote GitHub Enterprise repositories\n* [Bitbucket](source/bitbucket) - read from remote Bitbucket repositories\n* [Gitlab](source/gitlab) - read from remote Gitlab repositories\n* [AWS S3](source/aws_s3) - read from Amazon Web Services S3\n* [Google Cloud Storage](source/google_cloud_storage) - read from Google Cloud Platform Storage\n\n## CLI usage\n\n* Simple wrapper around this library.\n* Handles ctrl+c (SIGINT) gracefully.\n* No config search paths, no config files, no magic ENV var injections.\n\n[CLI Documentation](cmd/migrate) (includes CLI install instructions)\n\n### Basic usage\n\n```bash\n$ migrate -source file://path/to/migrations -database postgres://localhost:5432/database up 2\n```\n\n### Docker usage\n\n```bash\n$ docker run -v {{ migration dir }}:/migrations --network host migrate/migrate\n    -path=/migrations/ -database postgres://localhost:5432/database up 2\n```\n\n## Use in your Go project\n\n* API is stable and frozen for this release (v3 & v4).\n* Uses [Go modules](https://golang.org/cmd/go/#hdr-Modules__module_versions__and_more) to manage dependencies.\n* To help prevent database corruptions, it supports graceful stops via `GracefulStop chan bool`.\n* Bring your own logger.\n* Uses `io.Reader` streams internally for low memory overhead.\n* Thread-safe and no goroutine leaks.\n\n__[Go Documentation](https://pkg.go.dev/github.com/golang-migrate/migrate/v4)__\n\n```go\nimport (\n    \"github.com/golang-migrate/migrate/v4\"\n    _ \"github.com/golang-migrate/migrate/v4/database/postgres\"\n    _ \"github.com/golang-migrate/migrate/v4/source/github\"\n)\n\nfunc main() {\n    m, err := migrate.New(\n        \"github://mattes:personal-access-token@mattes/migrate_test\",\n        \"postgres://localhost:5432/database?sslmode=enable\")\n    m.Steps(2)\n}\n```\n\nWant to use an existing database client?\n\n```go\nimport (\n    \"database/sql\"\n    _ \"github.com/lib/pq\"\n    \"github.com/golang-migrate/migrate/v4\"\n    \"github.com/golang-migrate/migrate/v4/database/postgres\"\n    _ \"github.com/golang-migrate/migrate/v4/source/file\"\n)\n\nfunc main() {\n    db, err := sql.Open(\"postgres\", \"postgres://localhost:5432/database?sslmode=enable\")\n    driver, err := postgres.WithInstance(db, &postgres.Config{})\n    m, err := migrate.NewWithDatabaseInstance(\n        \"file:///migrations\",\n        \"postgres\", driver)\n    m.Up() // or m.Steps(2) if you want to explicitly set the number of migrations to run\n}\n```\n\n## Getting started\n\nGo to [getting started](GETTING_STARTED.md)\n\n## Tutorials\n\n* [CockroachDB](database/cockroachdb/TUTORIAL.md)\n* [PostgreSQL](database/postgres/TUTORIAL.md)\n\n(more tutorials to come)\n\n## Migration files\n\nEach migration has an up and down migration. [Why?](FAQ.md#why-two-separate-files-up-and-down-for-a-migration)\n\n```bash\n1481574547_create_users_table.up.sql\n1481574547_create_users_table.down.sql\n```\n\n[Best practices: How to write migrations.](MIGRATIONS.md)\n\n## Coming from another db migration tool?\n\nCheck out [migradaptor](https://github.com/musinit/migradaptor/).\n*Note: migradaptor is not affiliated or supported by this project*\n\n## Versions\n\nVersion | Supported? | Import | Notes\n--------|------------|--------|------\n**master** | :white_check_mark: | `import \"github.com/golang-migrate/migrate/v4\"` | New features and bug fixes arrive here first |\n**v4** | :white_check_mark: | `import \"github.com/golang-migrate/migrate/v4\"` | Used for stable releases |\n**v3** | :x: | `import \"github.com/golang-migrate/migrate\"` (with package manager) or `import \"gopkg.in/golang-migrate/migrate.v3\"` (not recommended) | **DO NOT USE** - No longer supported |\n\n## Development and Contributing\n\nYes, please! [`Makefile`](Makefile) is your friend,\nread the [development guide](CONTRIBUTING.md).\n\nAlso have a look at the [FAQ](FAQ.md).\n\n---\n\nLooking for alternatives? [https://awesome-go.com/#database](https://awesome-go.com/#database).\n",
      "stars_today": 8
    },
    {
      "id": 19082715,
      "name": "GmsCore",
      "full_name": "microg/GmsCore",
      "description": "Free implementation of Play Services",
      "html_url": "https://github.com/microg/GmsCore",
      "stars": 12137,
      "forks": 2538,
      "language": "Java",
      "topics": [
        "android",
        "auth",
        "cloud-messaging",
        "firebase",
        "geolocation",
        "google",
        "google-cloud-messaging",
        "java",
        "kotlin",
        "kotlin-android",
        "maps",
        "microg",
        "mobile",
        "push-notifications"
      ],
      "created_at": "2014-04-23T19:28:47Z",
      "updated_at": "2026-02-07T02:04:45Z",
      "pushed_at": "2026-02-06T13:48:05Z",
      "open_issues": 1219,
      "owner": {
        "login": "microg",
        "avatar_url": "https://avatars.githubusercontent.com/u/2758598?v=4"
      },
      "readme": "# microG Services\n\n[![Build status](https://github.com/microg/GmsCore/actions/workflows/build.yml/badge.svg)](https://github.com/microg/GmsCore/actions/workflows/build.yml)\n<a href=TRANSLATION.md>\n<img src=\"https://hosted.weblate.org/widget/microg/svg-badge.svg\" alt=\"Translation status\" />\n</a>\n\nmicroG Services is a FLOSS (Free/Libre Open Source Software) framework to allow applications designed for Google Play Services to run on systems, where Play Services is not available.\n\n### Please refer to the [wiki](https://github.com/microg/GmsCore/wiki) for downloads and instructions\n\n## Translations\n\nIf you'd like to help translate microG, take a look at [TRANSLATION](TRANSLATION.md).\n\n\nLicense\n-------\n    Copyright 2013-2025 microG Project Team\n\n    Licensed under the Apache License, Version 2.0 (the \"License\");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n\n        http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n",
      "stars_today": 8
    },
    {
      "id": 671061529,
      "name": "winlator",
      "full_name": "brunodev85/winlator",
      "description": "Android application for running Windows applications with Wine and Box86/Box64",
      "html_url": "https://github.com/brunodev85/winlator",
      "stars": 16450,
      "forks": 1205,
      "language": "C",
      "topics": [],
      "created_at": "2023-07-26T13:02:11Z",
      "updated_at": "2026-02-07T02:21:10Z",
      "pushed_at": "2025-09-26T20:20:22Z",
      "open_issues": 402,
      "owner": {
        "login": "brunodev85",
        "avatar_url": "https://avatars.githubusercontent.com/u/11407071?v=4"
      },
      "readme": "<p align=\"center\">\r\n\t<img src=\"logo.png\" width=\"376\" height=\"128\" alt=\"Winlator Logo\" />\r\n</p>\r\n\r\n# Winlator\r\n\r\nWinlator is an Android application that lets you to run Windows (x86_64) applications with Wine and Box86/Box64.\r\n\r\n# Installation\r\n\r\n1. Download and install the APK (Winlator_10.1.apk) from [GitHub Releases](https://github.com/brunodev85/winlator/releases)\r\n2. Launch the app and wait for the installation process to finish\r\n\r\n----\r\n\r\n[![Play on Youtube](https://img.youtube.com/vi/ETYDgKz4jBQ/3.jpg)](https://www.youtube.com/watch?v=ETYDgKz4jBQ)\r\n[![Play on Youtube](https://img.youtube.com/vi/9E4wnKf2OsI/2.jpg)](https://www.youtube.com/watch?v=9E4wnKf2OsI)\r\n[![Play on Youtube](https://img.youtube.com/vi/czEn4uT3Ja8/2.jpg)](https://www.youtube.com/watch?v=czEn4uT3Ja8)\r\n[![Play on Youtube](https://img.youtube.com/vi/eD36nxfT_Z0/2.jpg)](https://www.youtube.com/watch?v=eD36nxfT_Z0)\r\n\r\n----\r\n\r\n# Useful Tips\r\n\r\n- If you are experiencing performance issues, try changing the Box64 preset to `Performance` in Container Settings -> Advanced Tab.\r\n- For applications that use .NET Framework, try installing `Wine Mono` found in Start Menu -> System Tools -> Installers.\r\n- If some older games don't open, try adding the environment variable `MESA_EXTENSION_MAX_YEAR=2003` in Container Settings -> Environment Variables.\r\n- Try running the games using the shortcut on the Winlator home screen, there you can define individual settings for each game.\r\n- To display low resolution games correctly, try to enabling the `Force Fullscreen` option in the shortcut settings.\r\n- To improve stability in games that uses Unity Engine, try changing the Box64 preset to `Stability` or in the shortcut settings add the exec argument `-force-gfx-direct`.\r\n\r\n# Information\r\n\r\nThis project has been in constant development since version 1.0, the current app source code is up to version 7.1, I do not update this repository frequently precisely to avoid unofficial releases before the official releases of Winlator.\r\n\r\n# Credits and Third-party apps\r\n- GLIBC Patches by [Termux Pacman](https://github.com/termux-pacman/glibc-packages)\r\n- Wine ([winehq.org](https://www.winehq.org/))\r\n- Box86/Box64 by [ptitseb](https://github.com/ptitSeb)\r\n- Mesa (Turnip/Zink/VirGL) ([mesa3d.org](https://www.mesa3d.org))\r\n- DXVK ([github.com/doitsujin/dxvk](https://github.com/doitsujin/dxvk))\r\n- VKD3D ([gitlab.winehq.org/wine/vkd3d](https://gitlab.winehq.org/wine/vkd3d))\r\n- CNC DDraw ([github.com/FunkyFr3sh/cnc-ddraw](https://github.com/FunkyFr3sh/cnc-ddraw))\r\n\r\nSpecial thanks to all the developers involved in these projects.<br>\r\nThank you to all the people who believe in this project.",
      "stars_today": 8
    },
    {
      "id": 186036865,
      "name": "AltStore",
      "full_name": "altstoreio/AltStore",
      "description": "AltStore is an alternative app store for non-jailbroken iOS devices.",
      "html_url": "https://github.com/altstoreio/AltStore",
      "stars": 13469,
      "forks": 1220,
      "language": "Swift",
      "topics": [],
      "created_at": "2019-05-10T18:29:53Z",
      "updated_at": "2026-02-07T01:16:00Z",
      "pushed_at": "2026-01-11T06:22:32Z",
      "open_issues": 631,
      "owner": {
        "login": "altstoreio",
        "avatar_url": "https://avatars.githubusercontent.com/u/83258927?v=4"
      },
      "readme": "# AltStore\n\n> AltStore is an alternative app store for non-jailbroken iOS devices. \n\n[![Swift Version](https://img.shields.io/badge/swift-5.0-orange.svg)](https://swift.org/)\n[![License: AGPL v3](https://img.shields.io/badge/License-AGPL%20v3-blue.svg)](https://www.gnu.org/licenses/agpl-3.0)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)\n\nAltStore is an iOS application that allows you to sideload other apps (.ipa files) onto your iOS device with just your Apple ID. AltStore resigns apps with your personal development certificate and sends them to a desktop app, AltServer, which installs the resigned apps back to your device using iTunes WiFi sync. To prevent apps from expiring, AltStore will also periodically refresh your apps in the background when on the same WiFi as AltServer.\n\nFor the initial release, I focused on building a solid foundation for distributing my own apps â€” primarily Delta, [my all-in-one emulator for iOS](https://github.com/rileytestut/Delta). Now that Delta has been released, however, I'm beginning work on adding support for *anyone* to list and distribute their apps through AltStore (contributions welcome! ğŸ™‚).\n\n## Features\n- Installs apps over WiFi using AltServer\n- Resigns and installs any app with your Apple ID\n- Refreshes apps periodically in the background to prevent them from expiring (when on same WiFi as AltServer)\n- Handles app updates directly through AltStore \n\n## Minimum Project Requirements\n- Xcode 15\n- Swift 5.9\n- iOS 14.0 (AltStore)\n- macOS 11.0 (AltServer)\n\n## Project Overview\n\n### AltStore\nAltStore is a just regular, sandboxed iOS application. The AltStore app target contains the vast majority of AltStore's functionality, including all the logic for downloading and updating apps through AltStore. AltStore makes heavy use of standard iOS frameworks and technologies most iOS developers are familiar with, such as:\n* Core Data\n* Storyboards/Nibs\n* Auto Layout\n* Background App Refresh\n* Network.framework (new in iOS 12)\n\n### AltServer\nAltServer is also just a regular, sandboxed macOS application. AltServer is significantly less complex than AltStore though, and for that reason consists of only a handful of files.\n\n### AltKit\nAltKit is a shared framework that includes common code between AltStore and AltServer.\n\n### AltSign\nAltSign is my internal framework used by both AltStore and AltServer to communicate with Apple's servers and resign apps. For more info, check the [AltSign repo](https://github.com/rileytestut/altsign).\n\n### Roxas\nRoxas is my internal framework used across all my iOS projects, developed to simplify a variety of common tasks used in iOS development. For more info, check the [Roxas repo](https://github.com/rileytestut/roxas).\n\n## Compilation Instructions\nAltStore and AltServer are both fairly straightforward to compile and run if you're already an iOS or macOS developer. To compile AltStore and/or AltServer:\n\n1. Clone the repository \n\t``` \n\tgit clone https://github.com/rileytestut/AltStore.git\n\t```\n2. Update submodules: \n\t```\n\tcd AltStore \n\tgit submodule update --init --recursive\n\t```\n3. Open `AltStore.xcworkspace` and select the AltStore project in the project navigator. On the `Signing & Capabilities` tab, change the team from `Yvette Testut` to your own account.\n4. **(AltStore only)** Change the value for `ALTDeviceID` in the Info.plist to your device's UDID. Normally, AltServer embeds the device's UDID in AltStore's Info.plist during installation. When running through Xcode you'll need to set the value yourself or else AltStore won't resign (or even install) apps for the proper device.\n5. **(AltStore only)** Change the value for `ALTServerID` in the Info.plist to your AltServer's serverID. This is embedded by AltServer during installation to help AltStore distinguish between multiple AltServers on the same network, and you can find this by using a Bonjour browsing application and noting the serverID advertised by AltServer. This isn't strictly necessary, because if AltStore can't find the AltServer with the embedded serverID it still falls back to trying another AltServer. However, this will help in cases where there are multiple AltServers running (plus the error messages are more helpful).\n6. Build + run app! ğŸ‰\n\n## Licensing\n\nDue to the licensing of some dependencies used by AltStore, I have no choice but to distribute AltStore under the **AGPLv3 license**. That being said, my goal for AltStore is for it to be an open source project *anyone* can use without restrictions, so I explicitly give permission for anyone to use, modify, and distribute all *my* original code for this project in any form, with or without attribution, without fear of legal consequences (dependencies remain under their original licenses, however).\n\n## Contact Me\n\n* Email: riley@altstore.io\n* Mastodon (Preferred): [@rileytestut@mastodon.social](https://mastodon.social/@rileytestut)\n* Twitter (Less active nowadays): [@rileytestut](https://twitter.com/rileytestut)\n\nQuestions about AltStore in general? Make sure to read the FAQ at https://altstore.io/faq/\n",
      "stars_today": 8
    },
    {
      "id": 267054247,
      "name": "grype",
      "full_name": "anchore/grype",
      "description": "A vulnerability scanner for container images and filesystems",
      "html_url": "https://github.com/anchore/grype",
      "stars": 11493,
      "forks": 737,
      "language": "Go",
      "topics": [
        "container-image",
        "containers",
        "cyclonedx",
        "docker",
        "go",
        "golang",
        "hacktoberfest",
        "oci",
        "openvex",
        "security",
        "static-analysis",
        "tool",
        "vex",
        "vulnerabilities",
        "vulnerability"
      ],
      "created_at": "2020-05-26T13:44:38Z",
      "updated_at": "2026-02-07T02:18:10Z",
      "pushed_at": "2026-02-06T18:45:01Z",
      "open_issues": 358,
      "owner": {
        "login": "anchore",
        "avatar_url": "https://avatars.githubusercontent.com/u/16208487?v=4"
      },
      "readme": "<p align=\"center\">\n    <img alt=\"Grype logo\" src=\"https://user-images.githubusercontent.com/5199289/136855393-d0a9eef9-ccf1-4e2b-9d7c-7aad16a567e5.png\" width=\"234\">\n</p>\n\n# Grype\n\n**A vulnerability scanner for container images and filesystems.**\n\n<p align=\"center\">\n    &nbsp;<a href=\"https://github.com/anchore/grype/actions?query=workflow%3A%22Static+Analysis+%2B+Unit+%2B+Integration%22\"><img src=\"https://github.com/anchore/grype/workflows/Static%20Analysis%20+%20Unit%20+%20Integration/badge.svg\" alt=\"Static Analysis + Unit + Integration\"></a>&nbsp;\n    &nbsp;<a href=\"https://github.com/anchore/grype/actions/workflows/validations.yaml\"><img src=\"https://github.com/anchore/grype/workflows/Validations/badge.svg\" alt=\"Validations\"></a>&nbsp;\n    &nbsp;<a href=\"https://goreportcard.com/report/github.com/anchore/grype\"><img src=\"https://goreportcard.com/badge/github.com/anchore/grype\" alt=\"Go Report Card\"></a>&nbsp;\n    &nbsp;<a href=\"https://github.com/anchore/grype/releases/latest\"><img src=\"https://img.shields.io/github/release/anchore/grype.svg\" alt=\"GitHub release\"></a>&nbsp;\n    &nbsp;<a href=\"https://github.com/anchore/grype\"><img src=\"https://img.shields.io/github/go-mod/go-version/anchore/grype.svg\" alt=\"GitHub go.mod Go version\"></a>&nbsp;\n    &nbsp;<a href=\"https://github.com/anchore/grype/blob/main/LICENSE\"><img src=\"https://img.shields.io/badge/License-Apache%202.0-blue.svg\" alt=\"License: Apache-2.0\"></a>&nbsp;\n    &nbsp;<a href=\"https://anchore.com/discourse\"><img src=\"https://img.shields.io/badge/Discourse-Join-blue?logo=discourse\" alt=\"Join our Discourse\"></a>&nbsp;\n    &nbsp;<a rel=\"me\" href=\"https://fosstodon.org/@grype\"><img src=\"https://img.shields.io/badge/Mastodon-Follow-blue?logoColor=white&logo=mastodon\" alt=\"Follow on Mastodon\"></a>&nbsp;\n</p>\n\n![grype-demo](https://user-images.githubusercontent.com/590471/90276236-9868f300-de31-11ea-8068-4268b6b68529.gif)\n\n## Features\n\n- Scan **container images**, **filesystems**, and **SBOMs** for known vulnerabilities (see the docs for a full list of [supported scan targets](https://oss.anchore.com/docs/guides/vulnerability/scan-targets/))\n- Supports major OS package ecosystems (Alpine, Debian, Ubuntu, RHEL, Oracle Linux, Amazon Linux, and [more](https://oss.anchore.com/docs/capabilities/all-os/))\n- Supports language-specific packages (Ruby, Java, JavaScript, Python, .NET, Go, PHP, Rust, and [more](https://oss.anchore.com/docs/capabilities/all-packages/))\n- Supports Docker, OCI, and [Singularity](https://github.com/sylabs/singularity) image formats\n- Threat & risk prioritization with **EPSS**, **KEV**, and **risk scoring** (see [interpreting the results docs](https://oss.anchore.com/docs/guides/vulnerability/interpreting-results/))\n- [OpenVEX](https://github.com/openvex) support for filtering and augmenting scan results\n\n> [!TIP]\n> New to Grype? Check out the [Getting Started guide](https://oss.anchore.com/docs/guides/vulnerability/getting-started/) for a walkthrough!\n\n## Installation\n\nThe quickest way to get up and going:\n```bash\ncurl -sSfL https://get.anchore.io/grype | sudo sh -s -- -b /usr/local/bin\n```\n\n> [!TIP]\n> See [Installation docs](https://oss.anchore.com/docs/installation/grype/) for more ways to get Grype, including Homebrew, Docker, Chocolatey, MacPorts, and more!\n\n## The basics\n\nScan a container image or directory for vulnerabilities:\n\n```bash\n# container image\ngrype alpine:latest\n\n# directory\ngrype ./my-project\n```\n\nScan an SBOM for even faster vulnerability detection:\n\n```bash\n# scan a Syft SBOM\ngrype sbom:./sbom.json\n\n# pipe an SBOM into Grype\ncat ./sbom.json | grype\n```\n\n> [!TIP]\n> Check out the [Getting Started guide](https://oss.anchore.com/docs/guides/vulnerability/getting-started/) to explore all of the capabilities and features.\n>\n> Want to know all of the ins-and-outs of Grype? Check out the [CLI docs](https://oss.anchore.com/docs/reference/grype/cli/) and [configuration docs](https://oss.anchore.com/docs/reference/grype/configuration/).\n\n## Contributing\n\nWe encourage users to help make these tools better by [submitting issues](https://github.com/anchore/grype/issues) when you find a bug or want a new feature.\nCheck out our [contributing overview](https://oss.anchore.com/docs/contributing/) and [developer-specific documentation](https://oss.anchore.com/docs/contributing/grype/) if you are interested in providing code contributions.\n\n<p xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dct=\"http://purl.org/dc/terms/\">\n  Grype development is sponsored by <a href=\"https://anchore.com/\">Anchore</a>, and is released under the <a href=\"https://github.com/anchore/grype?tab=Apache-2.0-1-ov-file\">Apache-2.0 License</a>.\n  The <a property=\"dct:title\" rel=\"cc:attributionURL\" href=\"https://anchore.com/wp-content/uploads/2024/11/grype-logo.svg\">Grype logo</a> by <a rel=\"cc:attributionURL dct:creator\" property=\"cc:attributionName\" href=\"https://anchore.com/\">Anchore</a> is licensed under <a href=\"https://creativecommons.org/licenses/by/4.0/\" target=\"_blank\" rel=\"license noopener noreferrer\" style=\"display:inline-block;\">CC BY 4.0<img style=\"height:22px!important;margin-left:3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/cc.svg\" alt=\"\"><img style=\"height:22px!important;margin-left:3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/by.svg\" alt=\"\"></a>\n</p>\n\nFor commercial support options with Syft or Grype, please [contact Anchore](https://get.anchore.com/contact/).\n\n## Come talk to us!\n\nThe Grype Team holds regular community meetings online. All are welcome to join to bring topics for discussion.\n- Check the [calendar](https://calendar.google.com/calendar/u/0/r?cid=Y182OTM4dGt0MjRtajI0NnNzOThiaGtnM29qNEBncm91cC5jYWxlbmRhci5nb29nbGUuY29t) for the next meeting date.\n- Add items to the [agenda](https://docs.google.com/document/d/1ZtSAa6fj2a6KRWviTn3WoJm09edvrNUp4Iz_dOjjyY8/edit?usp=sharing) (join [this group](https://groups.google.com/g/anchore-oss-community) for write access to the [agenda](https://docs.google.com/document/d/1ZtSAa6fj2a6KRWviTn3WoJm09edvrNUp4Iz_dOjjyY8/edit?usp=sharing))\n- See you there!\n",
      "stars_today": 8
    },
    {
      "id": 558188628,
      "name": "higress",
      "full_name": "alibaba/higress",
      "description": "ğŸ¤– AI Gateway | AI Native API Gateway",
      "html_url": "https://github.com/alibaba/higress",
      "stars": 7471,
      "forks": 979,
      "language": "Go",
      "topics": [
        "ai-gateway",
        "ai-native",
        "api-gateway",
        "cloud-native",
        "envoy"
      ],
      "created_at": "2022-10-27T03:53:00Z",
      "updated_at": "2026-02-07T02:09:20Z",
      "pushed_at": "2026-02-07T00:32:56Z",
      "open_issues": 758,
      "owner": {
        "login": "alibaba",
        "avatar_url": "https://avatars.githubusercontent.com/u/1961952?v=4"
      },
      "readme": "<a name=\"readme-top\"></a>\n<h1 align=\"center\">\n    <img src=\"https://img.alicdn.com/imgextra/i2/O1CN01NwxLDd20nxfGBjxmZ_!!6000000006895-2-tps-960-290.png\" alt=\"Higress\" width=\"240\" height=\"72.5\">\n  <br>\n  AI Gateway\n</h1>\n<h4 align=\"center\"> AI Native API Gateway </h4>\n\n<div align=\"center\">\n    \n[![Build Status](https://github.com/alibaba/higress/actions/workflows/build-and-test.yaml/badge.svg?branch=main)](https://github.com/alibaba/higress/actions)\n[![license](https://img.shields.io/github/license/alibaba/higress.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)\n[![discord](https://img.shields.io/discord/1364956090566971515?color=5865F2&label=discord&labelColor=black&logo=discord&logoColor=white&style=flat-square)](https://discord.gg/tSbww9VDaM)\n\n<a href=\"https://trendshift.io/repositories/10918\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/10918\" alt=\"alibaba%2Fhigress | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a> <a href=\"https://www.producthunt.com/posts/higress?embed=true&utm_source=badge-featured&utm_medium=badge&utm_souce=badge-higress\" target=\"_blank\"><img src=\"https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=951287&theme=light&t=1745492822283\" alt=\"Higress - Global&#0032;APIs&#0032;as&#0032;MCP&#0032;powered&#0032;by&#0032;AI&#0032;Gateway | Product Hunt\" style=\"width: 250px; height: 54px;\" width=\"250\" height=\"54\" /></a>\n\n</div>\n\n[**Official Site**](https://higress.ai/en/) &nbsp; |\n&nbsp; [**Docs**](https://higress.cn/en/docs/latest/overview/what-is-higress/) &nbsp; |\n&nbsp; [**Blog**](https://higress.cn/en/blog/) &nbsp; |\n&nbsp; [**MCP Server QuickStart**](https://higress.cn/en/ai/mcp-quick-start/) &nbsp; |\n&nbsp; [**Developer Guide**](https://higress.cn/en/docs/latest/dev/architecture/) &nbsp; |\n&nbsp; [**Wasm Plugin Hub**](https://higress.cn/en/plugin/) &nbsp; |\n\n<p>\n   English | <a href=\"README_ZH.md\">ä¸­æ–‡</a> | <a href=\"README_JP.md\">æ—¥æœ¬èª</a>\n</p>\n\n## What is Higress?\n\nHigress is a cloud-native API gateway based on Istio and Envoy, which can be extended with Wasm plugins written in Go/Rust/JS. It provides dozens of ready-to-use general-purpose plugins and an out-of-the-box console (try the [demo here](http://demo.higress.io/)).\n\n### Core Use Cases\n\nHigress's AI gateway capabilities support all [mainstream model providers](https://github.com/alibaba/higress/tree/main/plugins/wasm-go/extensions/ai-proxy/provider) both domestic and international. It also supports hosting MCP (Model Context Protocol) Servers through its plugin mechanism, enabling AI Agents to easily call various tools and services. With the [openapi-to-mcp tool](https://github.com/higress-group/openapi-to-mcpserver), you can quickly convert OpenAPI specifications into remote MCP servers for hosting. Higress provides unified management for both LLM API and MCP API. \n\n**ğŸŒŸ Try it now at [https://mcp.higress.ai/](https://mcp.higress.ai/)** to experience Higress-hosted Remote MCP Servers firsthand:\n\n![Higress MCP Server Platform](https://img.alicdn.com/imgextra/i2/O1CN01nmVa0a1aChgpyyWOX_!!6000000003294-0-tps-3430-1742.jpg)\n\n### Enterprise Adoption\n\nHigress was born within Alibaba to solve the issues of Tengine reload affecting long-connection services and insufficient load balancing capabilities for gRPC/Dubbo. Within Alibaba Cloud, Higress's AI gateway capabilities support core AI applications such as Tongyi Bailian model studio, machine learning PAI platform, and other critical AI services. Alibaba Cloud has built its cloud-native API gateway product based on Higress, providing 99.99% gateway high availability guarantee service capabilities for a large number of enterprise customers.\n\nYou can click the button below to install the enterprise version of Higress:\n\n[![Deploy on AlibabaCloud](https://img.alicdn.com/imgextra/i1/O1CN01e6vwe71EWTHoZEcpK_!!6000000000359-55-tps-170-40.svg)](https://www.aliyun.com/product/api-gateway?spm=higress-github.topbar.0.0.0)\n\n\nIf you use open-source Higress and wish to obtain enterprise-level support, you can contact the project maintainer johnlanni's email: **zty98751@alibaba-inc.com** or social media accounts (WeChat ID: **nomadao**, DingTalk ID: **chengtanzty**). Please note **Higress** when adding as a friend :)\n\n## Summary\n\n- [**Quick Start**](#quick-start)    \n- [**Feature Showcase**](#feature-showcase)\n- [**Use Cases**](#use-cases)\n- [**Core Advantages**](#core-advantages)\n- [**Community**](#community)\n\n## Quick Start\n\nHigress can be started with just Docker, making it convenient for individual developers to set up locally for learning or for building simple sites:\n\n```bash\n# Create a working directory\nmkdir higress; cd higress\n# Start higress, configuration files will be written to the working directory\ndocker run -d --rm --name higress-ai -v ${PWD}:/data \\\n        -p 8001:8001 -p 8080:8080 -p 8443:8443  \\\n        higress-registry.cn-hangzhou.cr.aliyuncs.com/higress/all-in-one:latest\n```\n\nPort descriptions:\n\n- Port 8001: Higress UI console entry\n- Port 8080: Gateway HTTP protocol entry\n- Port 8443: Gateway HTTPS protocol entry\n\n> All Higress Docker images use Higress's own image repository and are not affected by Docker Hub rate limits.\n> In addition, the submission and updates of the images are protected by a security scanning mechanism (powered by Alibaba Cloud ACR), making them very secure for use in production environments.\n> \n> If you experience a timeout when pulling image from `higress-registry.cn-hangzhou.cr.aliyuncs.com`, you can try replacing it with the following docker registry mirror source:\n> \n> **North America**: `higress-registry.us-west-1.cr.aliyuncs.com`\n> \n> **Southeast Asia**: `higress-registry.ap-southeast-7.cr.aliyuncs.com`\n\nFor other installation methods such as Helm deployment under K8s, please refer to the official [Quick Start documentation](https://higress.io/en-us/docs/user/quickstart).\n\nIf you are deploying on the cloud, it is recommended to use the [Enterprise Edition](https://www.aliyun.com/product/apigateway?spm=higress-github.topbar.0.0.0)\n\n\n## Use Cases\n\n- **MCP Server Hosting**:\n\n  Higress hosts MCP Servers through its plugin mechanism, enabling AI Agents to easily call various tools and services. With the [openapi-to-mcp tool](https://github.com/higress-group/openapi-to-mcpserver), you can quickly convert OpenAPI specifications into remote MCP servers.\n\n  ![](https://img.alicdn.com/imgextra/i1/O1CN01wv8H4g1mS4MUzC1QC_!!6000000004952-2-tps-1764-597.png)\n\n  Key benefits of hosting MCP Servers with Higress:\n  - Unified authentication and authorization mechanisms\n  - Fine-grained rate limiting to prevent abuse\n  - Comprehensive audit logs for all tool calls\n  - Rich observability for monitoring performance\n  - Simplified deployment through Higress's plugin mechanism\n  - Dynamic updates without disruption or connection drops\n\n     [Learn more...](https://higress.cn/en/ai/mcp-quick-start/?spm=36971b57.7beea2de.0.0.d85f20a94jsWGm)\n\n- **AI Gateway**:\n\n  Higress connects to all LLM model providers using a unified protocol, with AI observability, multi-model load balancing, token rate limiting, and caching capabilities:\n\n  ![](https://img.alicdn.com/imgextra/i2/O1CN01izmBNX1jbHT7lP3Yr_!!6000000004566-0-tps-1920-1080.jpg)\n\n- **Kubernetes ingress controller**:\n\n  Higress can function as a feature-rich ingress controller, which is compatible with many annotations of K8s' nginx ingress controller.\n  \n  [Gateway API](https://gateway-api.sigs.k8s.io/) is already supported, and it supports a smooth migration from Ingress API to Gateway API.\n\n  Compared to ingress-nginx, the resource overhead has significantly decreased, and the speed at which route changes take effect has improved by ten times.\n\n  > The following resource overhead comparison comes from [sealos](https://github.com/labring).\n  >\n  > For details, you can read this [article](https://sealos.io/blog/sealos-envoy-vs-nginx-2000-tenants) to understand how sealos migrates the monitoring of **tens of thousands of ingress** resources from nginx ingress to higress.\n\n   ![](https://img.alicdn.com/imgextra/i1/O1CN01bhEtb229eeMNBWmdP_!!6000000008093-2-tps-750-547.png)\n\n  \n- **Microservice gateway**:\n\n  Higress can function as a microservice gateway, which can discovery microservices from various service registries, such as Nacos, ZooKeeper, Consul, Eureka, etc.\n  \n  It deeply integrates with [Dubbo](https://github.com/apache/dubbo), [Nacos](https://github.com/alibaba/nacos), [Sentinel](https://github.com/alibaba/Sentinel) and other microservice technology stacks.\n  \n- **Security gateway**:\n\n  Higress can be used as a security gateway, supporting WAF and various authentication strategies, such as key-auth, hmac-auth, jwt-auth, basic-auth, oidc, etc.\n\n\n## Core Advantages\n\n- **Production Grade**\n\n  Born from Alibaba's internal product with over 2 years of production validation, supporting large-scale scenarios with hundreds of thousands of requests per second.\n\n  Completely eliminates traffic jitter caused by Nginx reload, configuration changes take effect in milliseconds and are transparent to business. Especially friendly to long-connection scenarios such as AI businesses.\n\n- **Streaming Processing**\n\n  Supports true complete streaming processing of request/response bodies, Wasm plugins can easily customize the handling of streaming protocols such as SSE (Server-Sent Events).\n\n  In high-bandwidth scenarios such as AI businesses, it can significantly reduce memory overhead.\n    \n- **Easy to Extend**\n  \n  Provides a rich official plugin library covering AI, traffic management, security protection and other common functions, meeting more than 90% of business scenario requirements.\n\n  Focuses on Wasm plugin extensions, ensuring memory safety through sandbox isolation, supporting multiple programming languages, allowing plugin versions to be upgraded independently, and achieving traffic-lossless hot updates of gateway logic.\n\n- **Secure and Easy to Use**\n  \n  Based on Ingress API and Gateway API standards, provides out-of-the-box UI console, WAF protection plugin, IP/Cookie CC protection plugin ready to use.\n\n  Supports connecting to Let's Encrypt for automatic issuance and renewal of free certificates, and can be deployed outside of K8s, started with a single Docker command, convenient for individual developers to use.\n\n## Community\n\nJoin our Discord community! This is where you can connect with developers and other enthusiastic users of Higress.\n\n[![discord](https://img.shields.io/discord/1364956090566971515?color=5865F2&label=discord&labelColor=black&logo=discord&logoColor=white&style=for-the-badge)](https://discord.gg/tSbww9VDaM)\n\n\n### Thanks\n\nHigress would not be possible without the valuable open-source work of projects in the community. We would like to extend a special thank you to Envoy and Istio.\n\n### Related Repositories\n\n- Higress Console: https://github.com/higress-group/higress-console\n- Higress Standalone: https://github.com/higress-group/higress-standalone\n\n### Contributors\n\n<a href=\"https://github.com/alibaba/higress/graphs/contributors\">\n  <img alt=\"contributors\" src=\"https://contrib.rocks/image?repo=alibaba/higress\"/>\n</a>\n\n### Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=alibaba/higress&type=Date)](https://star-history.com/#alibaba/higress&Date)\n\n<p align=\"right\" style=\"font-size: 14px; color: #555; margin-top: 20px;\">\n    <a href=\"#readme-top\" style=\"text-decoration: none; color: #007bff; font-weight: bold;\">\n        â†‘ Back to Top â†‘\n    </a>\n</p>\n",
      "stars_today": 8
    },
    {
      "id": 708618207,
      "name": "seanime",
      "full_name": "5rahim/seanime",
      "description": "Open-source media server with a web interface and desktop app for anime and manga.",
      "html_url": "https://github.com/5rahim/seanime",
      "stars": 2623,
      "forks": 166,
      "language": "Go",
      "topics": [
        "anilist",
        "anime",
        "anime-downloader",
        "anime-library",
        "anime-streaming",
        "bittorrent",
        "debrid",
        "go",
        "manga",
        "manga-downloader",
        "media-server",
        "myanimelist",
        "react",
        "scanner",
        "self-hosted"
      ],
      "created_at": "2023-10-23T03:05:04Z",
      "updated_at": "2026-02-06T23:03:20Z",
      "pushed_at": "2026-02-06T20:28:28Z",
      "open_issues": 28,
      "owner": {
        "login": "5rahim",
        "avatar_url": "https://avatars.githubusercontent.com/u/44007774?v=4"
      },
      "readme": "<p align=\"center\">\n<a href=\"https://seanime.app/\">\n<img src=\"docs/images/seanime-logo.png\" alt=\"preview\" width=\"70px\"/>\n</a>\n</p>\n\n<h1 align=\"center\"><b>Seanime</b></h1>\n\n<p align=\"center\">\n<img src=\"https://seanime.app/bucket/gh-showcase.webp\" alt=\"preview\" width=\"100%\"/>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://seanime.app/docs\">Documentation</a> |\n  <a href=\"https://github.com/5rahim/seanime/releases\">Latest release</a> |\n  <a href=\"https://www.youtube.com/playlist?list=PLgQO-Ih6JClhFFdEVuNQJejyX_8iH82gl\">Tutorials</a> |\n  <a href=\"https://discord.gg/Sbr7Phzt6m\">Discord</a> |\n  <a href=\"https://seanime.app/docs/policies\">Copyright</a>\n</p>\n\n<div align=\"center\">\n  <a href=\"https://github.com/5rahim/seanime/releases\">\n    <img src=\"https://img.shields.io/github/v/release/5rahim/seanime?style=flat-square&color=blue\" alt=\"\" />\n  </a>\n  <a href=\"https://github.com/5rahim/seanime/releases\">\n    <img src=\"https://img.shields.io/github/downloads/5rahim/seanime/total?style=flat-square&color=blue\" alt=\"\" />\n  </a>\n\t<a href=\"https://discord.gg/Aruz7wdAaf\">\n\t  <img src=\"https://img.shields.io/discord/1224767201551192224?style=flat-square&logo=Discord&color=blue&label=Discord\" alt=\"discord\">\n\t</a>\n  <a href=\"https://github.com/sponsors/5rahim\">\n    <img src=\"https://img.shields.io/static/v1?label=Sponsor&style=flat-square&message=%E2%9D%A4&logo=GitHub&color=%23fe8e86\" alt=\"\" />\n  </a>\n</div>\n\n\n<h5 align=\"center\">\nLeave a star if you like the project! â­ï¸\n</h5>\n\n## About\n\nSeanime is a **media server** with a **web interface** and **desktop app** for managing your local library, streaming anime and reading manga.\n\n> [!IMPORTANT]\n>Seanime does not provide, host, or distribute any media content. Users are responsible for obtaining media through legal means and complying with their local laws. Extensions listed on the app are unaffiliated with Seanime and may be removed if they violated copyright laws. </strong>\n\n\n## Features\n\n\n- Cross-platform web interface and desktop app\n- Built-in video player with Seanime Denshi (supports SSA/ASS subtitles, Anime4K sharpening, and more)\n- Complete AniList integration (browse, manage, score, discover, etc.)\n- Custom source support for adding series not available on AniList and even non-anime/manga series\n- Offline mode for use without an internet connection\n- Scan your anime library in seconds (no renaming or special folder structure required)\n- Integrated torrent search engine for extensions\n- Stream torrents directly to your media player without downloading using Bittorrent, Torbox and Real-Debrid\n- Support for qBittorrent, Transmission, Torbox and Real-Debrid for downloading\n- Automatically download new episodes with custom filters\n- MPV, VLC and MPC-HC support for watching on desktop\n- Watch on mobile with external player links to mobile apps (Outplayer, VLC, etc.)\n- Transcoding and direct play for streaming to any device web browser\n- Online streaming support for extensions\n- Read manga chapters from your local library or extensions\n- Schedule for tracking upcoming or missed episodes\n- Customizable UI\n- And more\n\n## Get started\n\nRead the installation guide to set up Seanime on your device.\n\n<p align=\"center\">\n<a href=\"https://seanime.app/docs\" style=\"font-size:18px;\" align=\"center\">\nHow to install Seanime\n</a>\n</p>\n\n<br>\n\n## Goal\n\nThis is a one-person project and may not meet every use case. If it doesnâ€™t fully fit your needs, other tools might be a better match.\n\n### Not planned\n\n- Support for other trackers such as Trakt, SIMKL, etc.\n- Support for other media players\n- Dedicated clients (TV, mobile, etc.)\n\nConsider sponsoring or sharing the project if you want to see more features implemented.\n\n## Sponsors\n\nThe maintenance of this project is made possible by the sponsors.\n\n<p align=\"center\">\n<!-- real-sponsors --><a href=\"https://github.com/TorBox-App\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;TorBox-App.png\" width=\"60px\" alt=\"User avatar: TorBox-App\" /></a><!-- real-sponsors -->\n</p>\n\n## Development and Build\n\nBuilding from source is straightforward, you'll need [Node.js](https://nodejs.org/en/download) and [Go](https://go.dev/doc/install) installed on your system.\nDevelopment and testing might require additional configuration.\n\n[Read more here](https://github.com/5rahim/seanime/blob/main/DEVELOPMENT_AND_BUILD.md)\n\n<br>\n\n<br>\n\n> [!NOTE]\n> For copyright-related requests, please contact the maintainer using the contact information provided on [the website](https://seanime.app/docs/policies).\n",
      "stars_today": 8
    },
    {
      "id": 729520568,
      "name": "MitsubishiCN105ESPHome",
      "full_name": "echavet/MitsubishiCN105ESPHome",
      "description": "ESPHome firmware inspired by GeoffDavisâ€™s esphome-mitsubishiheatpump, directly integrating the SwiCago library within its codebase.",
      "html_url": "https://github.com/echavet/MitsubishiCN105ESPHome",
      "stars": 766,
      "forks": 139,
      "language": "C++",
      "topics": [],
      "created_at": "2023-12-09T13:47:54Z",
      "updated_at": "2026-02-06T17:26:04Z",
      "pushed_at": "2026-02-04T19:13:46Z",
      "open_issues": 35,
      "owner": {
        "login": "echavet",
        "avatar_url": "https://avatars.githubusercontent.com/u/3224452?v=4"
      },
      "readme": "# Mitsubishi CN105 ESPHome\n\n> [!WARNING]\n> Due to a change in ESPHome 2025.8.0, some users are facing UART connection issues after a cold boot. Forcing the firmware esphome version to a previous release (2025.7.5 and below) solves the issue (no cold boot required). Alternative is to force ESP32 IDF version to 5.4.0. Note that OTA updates to 2025.8.0+ may work but can break after a subsequent cold boot.\n>\n> _\"commit 116c91e9c5fc6d0d32191bd4e6d6e406e2bff6bf Author: Jonathan Swoboda <154711427+swoboda1337@users.noreply.github.com> Date: Tue Jul 22 19:15:31 2025 -0400_\n>\n> _Bump ESP32 IDF version to 5.4.2 and Arduino version to 3.2.1 (#9770)\"_\n>\n> [!IMPORTANT]\n> Temporary fix included: This component now implements a fallback low-level UART reinitialization that triggers only if the initial (normal) connection fails at boot. It reconfigures the UART controller linked to your `uart:` block (clock source, reapplies baudrate, RX pull-up, flush, etc.). No YAML `on_boot` workaround is required. This aims to mitigate ESP-IDF 5.4.x regressions observed on some ESP32 at low baud (2400, 8E1).\n>\n> If this fallback still doesnâ€™t work on your hardware, you can temporarily force ESPâ€‘IDF 5.4.0 in your YAML:\n>\n> ```yaml\n> esp32:\n>   board: esp32-s3-devkitc-1\n>   framework:\n>     type: esp-idf\n>     version: 5.4.0\n>   variant: esp32s3\n>   flash_size: 8MB\n> ```\n\nThis project is a firmware for ESP32 microcontrollers supporting UART communication via the CN105 Mitsubishi connector. Its purpose is to enable complete control of a compatible Mitsubishi heat pump through Home Assistant, a web interface, or any MQTT client.\n\nIt uses the ESPHome framework and is compatible with the Arduino framework and ESP-IDF.\n\nThis component version is an adaptation of [geoffdavis's esphome-mitsubishiheatpump](https://github.com/geoffdavis/esphome-mitsubishiheatpump). Its purpose is to integrate the Mitsubishi heat pump protocol (enabled by the [SwiCago library](https://github.com/SwiCago/HeatPump)) directly into the ESPHome component classes for a more seamless integration.\n\nThe intended use case is for owners of a Mitsubishi Electric heat pump or air conditioner that includes a CN105 communication port to directly control their air handler or indoor unit using local communication through a web browser, or most commonly, the [HomeAssistant](https://www.home-assistant.io/) home automation platform. Installation requires the use of a WiFi capable ESP32 or ESP8266 device, modified to include a 5 pin plug to connect to the heat pump indoor unit. ESPHome is used to load the custom firmware onto the device, and the web browser or HomeAssistant software is used to send temperature setpoints, external temperature references, and settings to the heat pump. Installation requires basic soldering skills, and basic skills in flashing a firmware to a microcontroller (though ESPHome makes this as painless as possible).\n\nThe benefits include fully local control over your heat pump system, without reliance on a vendor network. Additional visibility, finer control, and even improved energy efficiency and comfort are possible when utilizing the remote temperature features.\n\n> [!CAUTION]\n> Use at your own risk.\n> This is an unofficial implementation of the reverse-engineered Mitsubishi protocol based on the Swicago library. The authors and contributors have extensively tested this firmware across several similar implementations and forks. However, it's important to note that not all units support every feature. While free to use, it is at your own risk. If you are seeking an officially supported method to remotely control your Mitsubishi device via WiFi, a commercial solution is available [here](https://www.mitsubishi-electric.co.nz/wifi/).\n\n### New Features\n\n- Support Fahrenheit users better by mapping unit conversions to Mitsubishi's \"creative\" math, ensuring that HomeAssistant and external thermostats stay in sync. Thanks [@ams2990](https://github.com/ams2990) and [@dsstewa](https://github.com/dsstewa)!\n- Additional components for supported units: vane orientation (fully supporting the Swicago map), compressor frequency for energy monitoring, and i-see sensor.\n- Additional diagnostic sensors for understanding the behavior of the indoor units while in AUTO mode.\n- Additional sensors for power usage and outdoor temperature (not supported by all units).\n- Code is divided into distinct concerns for better readability.\n- Extensive logging for easier troubleshooting and development.\n- Ongoing refactoring to further improve the code quality.\n- Enhanced UART communication with the Heatpump to eliminate delays in the ESPHome loop(), which was a limitation of the original [SwiCago library](https://github.com/SwiCago/HeatPump).\n- Byte-by-byte reading within the loop() function ensures no data loss or lag, as the component continuously reads without blocking ESPHome.\n- UART writes are followed by non-blocking reads. The responses are accumulated byte-by-byte in the loop() method and processed when complete, allowing command stacking without delays for a more responsive UI.\n\n### Retained Features\n\nThis project maintains all functionalities of the original [geoffdavis](https://github.com/geoffdavis/esphome-mitsubishiheatpump) project, including:\n\n- Wireless Mitsubishi Comfort HVAC equipment control via ESP8266 or ESP32, using the [ESPHome](https://esphome.io) framework.\n- Instant feedback of command changes via RF Remote to HomeAssistant or MQTT.\n- Direct control independent of the remote.\n- A slightly modified version of the [SwiCago/HeatPump](https://github.com/SwiCago/HeatPump) Arduino library for direct communication via the internal `CN105` connector.\n- Full mode and vane orientation support (added as an extra component within the Core Climate Component).\n- Thermostat in HomeAssistant with compressor frequency monitoring (an extra component within the Core Climate Component).\n\n## Requirements\n\n- [ESPHome](https://esphome.io/) - Minimum version 1.18.0, installed independently or as an add-on in HomeAssistant\n\n## Supported Microcontrollers\n\n> [!IMPORTANT]\n> ESP8266 boards such as the WeMos D1 Mini clones (LOLIN in particular) tend to be unreliable in this application, and may require an external voltage regulator to work. While some users have successfully used ESP8266 based devices, if you are purchasing new hardware for use with this project, it is recommended to focus on the more modern and powerful ESP32-S3 based devices.\n\n- Generic ESP32 Dev Kit (ESP32): tested\n- M5Stack ATOM Lite : tested\n- M5Stack ATOM S3 Lite: tested w/ [modifications](https://github.com/echavet/MitsubishiCN105ESPHome/discussions/83)\n- M5Stack NanoC6: [tested over both wifi and thread](https://github.com/echavet/MitsubishiCN105ESPHome/discussions/340)\n- M5Stack StampS3\n- Seeed Studios Xiao ESP32S3: tested\n- WeMos D1 Mini Pro (ESP8266): tested (but not currently recommended, see above)\n\n## Supported Mitsubishi Climate Units\n\nGenerally, indoor units with a `CN105` header are compatible. Refer to the [HeatPump wiki](https://github.com/SwiCago/HeatPump/wiki/Supported-models) for a comprehensive list. Additionally, Mitsubishi units listed as compatible with the [Mitsubishi PAC-USWHS002-WF-2 Kumo Cloud interface](https://mylinkdrive.com/USA/Controls/kumo_cloud/kumo_cloud_Devices/PAC_USWHS002_WF_2?product) will _likely_ be compatible with this project, as they use the same CN105 connector and serial protocol.\n\nUnits tested by project contributors include:\n\n- `MSZ-SF50VE3`\n- `MSZ-SF35VE3`\n- `MSZ-GLxxNA`\n- `MSZ-AP20VGK` (https://github.com/echavet/MitsubishiCN105ESPHome/discussions/83)\n- `MSZ-AP42VGK`\n- `MSZ-AP35VGD2` (https://github.com/echavet/MitsubishiCN105ESPHome/discussions/254)\n- `MSZ-AY35VGKP`\n- `MSZ-FSxxNA`\n- `MSZ-FHxxNA`\n- `MSZ-EF42VE`\n- `MSXY-FN10VE` (https://github.com/echavet/MitsubishiCN105ESPHome/discussions/368)\n- `MSZ-AP20VGK`\n- `MSZ-FT50VG2`\n\n## Usage\n\n### Step 1: Building the Control Circuit\n\nFollow the [SwiCago/HeatPump README](https://github.com/SwiCago/HeatPump/blob/master/README.md#demo-circuit) for building a control circuit using either an ESP8266 or ESP32.\n\n### Step 2: Using ESPHome\n\nAdd a new device in your ESPHome dashboard. Create a yaml configuration file for the new device using the templates below, and flash to your device. Refer to the ESPHome documentation for guides on how to install ESPHome, add new devices, and flash the initial firmware.\n\n- [Getting Started with ESPHome and HomeAssistant](https://esphome.io/guides/getting_started_hassio)\n- [Installing ESPHome Locally](https://esphome.io/guides/installing_esphome)\n\n> [!NOTE]\n> This code uses the ESPHome [external components](https://esphome.io/components/external_components.html) integration feature. This means the project is not part of the ESPHome framework, it is an external component not managed by the core ESPHome project.\n\n### Step 3: Configure the board and UART settings\n\nYour ESPHome device configuration file starts with common defaults for ESPHome. To these defaults, add these minimum sections:\n\n#### For ESP32-based Devices\n\n```yaml\nesp32:\n  board: esp32doit-devkit-v1 #or esp32-s3-devkitc-1\n  framework:\n    type: esp-idf\n\nuart:\n  id: HP_UART\n  baud_rate: 2400\n  tx_pin: GPIO17\n  rx_pin: GPIO16\n```\n\n#### For ESP8266-based Devices\n\n```yaml\nesp8266:\n  board: d1_mini\n\nuart:\n  id: HP_UART\n  baud_rate: 2400\n  tx_pin: 1\n  rx_pin: 3\n```\n\n### Step 4: Configure the climate component\n\nAdd these sections to load the external component, setup logging, and enable the climate entity.\n\n```yaml\n# External component reference\nexternal_components:\n  - source: github://echavet/MitsubishiCN105ESPHome\n\n# Climate entity configuration\nclimate:\n  - platform: cn105\n    id: hp\n    name: \"My Heat Pump\"\n    update_interval: 2s # update interval can be adjusted after a first run and logs monitoring\n\n# Default logging level\nlogger:\n  #  hardware_uart: UART1 # Uncomment on ESP8266 devices\n  level: INFO\n```\n\n#### Adjusting the `update_interval`\n\nAn ESPHome firmware implements the esphome::Component interface to be integrated into the Inversion Of Control mechanism of the ESPHome framework.\nThe main method of this process is the `loop()` method. MitsubishiCN105ESPHome performs a series of exchanges with the heat pump through a cycle. This cycle is timed, and its duration is displayed in the logs, provided the `CYCLE` logger is set to at least `INFO`.\n\nIf this is the case, you will see logs in the form:\n\n```\n[09:48:36][I][CYCLE:052]: 6: Cycle ended in 1.2 seconds (with timeout?: NO)\n```\n\nThis will give you a good idea of your microcontroller's performance in completing an entire cycle. It is unnecessary to set the `update_interval` below this value.\nIn this example, setting an `update_interval` to 1500ms could be a fine tuned value.\n\n### Step 5: Optional components and variables\n\nThese optional additional configurations add customization and additional capabilities. The examples below assume you have added a substitutions component to your configuration file to allow for easy renaming, and that you have added a `secrets.yaml` file to your ESPHome configuration to hide private variables like your random API keys, OTA passwords, and Wifi passwords.\n\n```yaml\nsubstitutions:\n  name: heatpump-1 # Do not use underscores, which are not fully compatible with mDNS\n  friendly_name: My Heatpump 1\n```\n\n#### Climate component full example\n\nThis example adds support for configuring the temperature steps, adding an icon, and the optional climate sensors supported by SwiCago (but not supported by all indoor units), `compressor_frequency_sensor`, `vertical_vane_select`, `horizontal_vane_select` and `isee_sensor`. Supports many of the other features of the [ESPHome climate component](https://esphome.io/components/climate/index.html) as well for additional customization.\n\nThe `remote_temperature_timeout` setting allows the unit to revert back to the internal temperature measurement if it does not receive an update in the specified time range (highly recommended if using remote temperature updates).\n\n`remote_temperature_keepalive_interval` configures the automatic keep-alive that periodically re-sends the external temperature to the heat pump (similar to Kumo Cloud behavior). Default is `20s`. Set to `0s` to disable. See [Methods for updating external temperature](#methods-for-updating-external-temperature) for details.\n\n`debounce_delay` adds a small delay to the command processing to account for some HomeAssistant buttons that may send repeat commands too quickly. A shorter value creates a more responsive UI, a longer value protects against repeat commands. (See https://github.com/echavet/MitsubishiCN105ESPHome/issues/21)\n\n`connection_bootstrap_delay` delays the initial CN105 UART connection sequence (UART init + CONNECT handshake) **after boot**, to ensure the OTA log stream has time to attach. This is useful when troubleshooting cold-boot issues remotely: without a delay, the very first connection logs can be missed because the log client connects a few seconds after reboot. While this delay is active, the component will **not start communication cycles** until the heatpump replies with the connection success packet.\n\nRecommended: start with `10s` and increase (e.g., `30s`) if you still miss early logs. A safety fallback starts anyway after 120s.\n\n`installer_mode` enables an extended CN105 connection handshake (CONNECT command `0x5B`) instead of the standard handshake (`0x5A`). Some indoor units (notably some ducted SEZ variants) may require this to unlock installer/service privileges so that Function Settings (ISU / `hardware_settings`) return real values instead of `0`. Default is `false` for maximum compatibility.\n\n`fahrenheit_compatibility` improves compatibility with HomeAssistant installations using Fahrenheit units. Mitsubishi uses a custom lookup table to convert F to C which doesn't correspond to the actual math in all cases. This can result in external thermostats and HomeAssistant \"disagreeing\" on what the current setpoint is. Setting this value to `standard` (or `alt` for alternative conversion tables) forces the component to use the same lookup tables, resulting in more consistent display of setpoints. Recommended for Fahrenheit users. (See https://github.com/echavet/MitsubishiCN105ESPHome/pull/298.)\n\n`use_as_operating_fallback` in the `stage_sensor` enables a fallback mechanism for the activity indicator (idle/heating/cooling/etc.). By default, the activity status is based on the compressor running state. When this option is enabled, the system uses an OR logic: it shows active status if the compressor is running OR if the stage sensor indicates activity (not IDLE). This is particularly useful for 2-stage heating systems where the second stage (e.g., gas heating) may be active while the compressor is off. (See https://github.com/echavet/MitsubishiCN105ESPHome/issues/277 and https://github.com/echavet/MitsubishiCN105ESPHome/issues/469)\n\n```yaml\nclimate:\n  - platform: cn105\n    id: hp\n    name: \"${friendly_name}\"\n    icon: mdi:heat-pump\n    visual:\n      min_temperature: 10 # Adjust to your unit's min temp. SmartSet units can go to 10C for heating\n      max_temperature: 31\n      temperature_step:\n        target_temperature: 1\n        current_temperature: 0.5\n    # Fahrenheit compatibility mode - uses Mitsubishi's \"custom\" unit conversions, set to\n    # \"standard\" (or \"alt\") for better support of Fahrenheit units in HomeAssistant.\n    # Options: \"disabled\" (default), \"standard\", \"alt\"\n    fahrenheit_compatibility: \"disabled\"\n    # Timeout and communication settings\n    remote_temperature_timeout: 30min\n    remote_temperature_keepalive_interval: 20s # Auto re-send external temp (like Kumo)\n    update_interval: 2s\n    debounce_delay: 100ms\n    # Delay the initial UART/CONNECT bootstrap to avoid missing early OTA logs\n    connection_bootstrap_delay: 30s\n    # Optional: use extended CONNECT handshake (0x5B) for installer/service privileges\n    installer_mode: false\n    # Various optional sensors, not all sensors are supported by all heatpumps\n    compressor_frequency_sensor:\n      name: Compressor Frequency\n      entity_category: diagnostic\n      disabled_by_default: true\n    outside_air_temperature_sensor:\n      name: Outside Air Temp\n      disabled_by_default: true\n    vertical_vane_select:\n      name: Vertical Vane\n      disabled_by_default: false\n    horizontal_vane_select:\n      name: Horizontal Vane\n      disabled_by_default: true\n    isee_sensor:\n      name: ISEE Sensor\n      disabled_by_default: true\n    stage_sensor:\n      name: Stage\n      # use_as_operating_fallback: false     # set to true for 2-stage systems or if activity indicator is unreliable\n      entity_category: diagnostic\n      disabled_by_default: true\n    sub_mode_sensor:\n      name: Sub Mode\n      entity_category: diagnostic\n      disabled_by_default: true\n    auto_sub_mode_sensor:\n      name: Auto Sub Mode\n      entity_category: diagnostic\n      disabled_by_default: true\n    input_power_sensor:\n      name: Input Power\n      disabled_by_default: true\n    kwh_sensor:\n      name: Energy Usage\n      disabled_by_default: true\n    runtime_hours_sensor:\n      name: Runtime Hours\n      entity_category: diagnostic\n      disabled_by_default: true\n    air_purifier_switch:\n      name: Air purifier\n      disabled_by_default: true\n    night_mode_switch:\n      name: Night mode\n      disabled_by_default: true\n    circulator_switch:\n      name: Circulator\n      disabled_by_default: true\n    airflow_control_select:\n      name: Airflow Control\n      disabled_by_default: true\n    supports:\n      # Explicitly control dual setpoint support in the UI/traits\n      # Defaults to false when omitted\n      dual_setpoint: true\n      # You can still specify supported modes as before\n      mode: [AUTO, COOL, HEAT, DRY, FAN_ONLY]\n      fan_mode: [AUTO, QUIET, LOW, MEDIUM, HIGH]\n      swing_mode: [\"OFF\", VERTICAL]\n      # Specify which options to display in horizontal_vane_select dropdown\n      # Defaults to all options: [\"â†â†\", \"â†\", \"|\", \"â†’\", \"â†’â†’\", \"â†â†’\", \"SWING\", \"AIRFLOW CONTROL\"]\n      # Example to hide \"â†â†’\" and \"AIRFLOW CONTROL\" if not supported by your unit:\n      horizontal_vane_mode: [\"â†â†\", \"â†\", \"|\", \"â†’\", \"â†’â†’\", SWING]\n```\n\n> [!TIP]\n> An `update_interval` between 1s and 4s is recommended, because the underlying process divides this into three separate requests which need time to complete. If some updates get \"missed\" from your heatpump, consider making this interval longer.\n\n#### Logger granularity\n\nThis firmware supports detailed log granularity for troubleshooting. Below is the full list of logger components and recommended defaults.\n\n```yaml\nlogger:\n  # hardware_uart: UART1 # Uncomment on ESP8266 devices\n  level: INFO\n  logs:\n    EVT_SETS: INFO\n    WIFI: INFO\n    MQTT: INFO\n    WRITE_SETTINGS: INFO\n    SETTINGS: INFO\n    STATUS: INFO\n    # CN105 connection/bootstrap diagnostics (UART init + CONNECT handshake)\n    CN105_CONN: INFO\n    CN105Climate: WARN\n    CN105: INFO\n    climate: WARN\n    sensor: WARN\n    chkSum: INFO\n    WRITE: WARN\n    READ: WARN\n    Header: INFO\n    Decoder: INFO\n    CONTROL_WANTED_SETTINGS: INFO\n# Swap the above settings with these debug settings for development or troubleshooting\n#  level: DEBUG\n#  logs:\n#    EVT_SETS : DEBUG\n#    WIFI : INFO\n#    MQTT : INFO\n#    WRITE_SETTINGS : DEBUG\n#    SETTINGS : DEBUG\n#    STATUS : INFO\n#    CN105Climate: WARN\n#    CN105: DEBUG\n#    climate: WARN\n#    sensor: WARN\n#    chkSum : INFO\n#    WRITE : WARN\n#    READ : WARN\n#    Header: INFO\n#    Decoder : DEBUG\n#    CONTROL_WANTED_SETTINGS: DEBUG\n```\n\n### Step 6: Build the project and install\n\nBuild the project in ESPHome and install to your device. Install the device in your indoor unit connected to the CN105 port, and confirm that it powers up and connects to the Wifi. Visit the local IP address of the device, and confirm that you can change modes and temperature setpoints. HomeAssistant should now include a climate entity for your heatpump.\n\n> [!TIP]\n> To force an OTA upload via command line without interactive prompts, use:\n> `esphome run myfirmware/clim-chambre-awox.yaml --device <IP_ADDRESS>`\n\n### Step 7: (Optional) Install Mitsubishi Climate Proxy via HACS\n\nThis repository also contains a Home Assistant Custom Component that solves the \"Auto vs Heat/Cool\" UI issue by wrapping your ESPHome entity. It enables a dynamic UI that shows a single temperature slider for HEAT/COOL/AUTO modes and dual sliders only for HEAT_COOL mode.\n\n1.  Open **HACS** > **Integrations**.\n2.  Click the three dots in the top right > **Custom repositories**.\n3.  Add `echavet/MitsubishiCN105ESPHome` as category **Integration**.\n4.  Adding the repository will allow you to find \"Mitsubishi Climate Proxy\" in the list.\n5.  Install **Mitsubishi Climate Proxy** and restart Home Assistant.\n\n#### Configuration (UI Method - Recommended)\n\n1.  Navigate to **Settings** > **Devices & Services**.\n2.  Click the **+ ADD INTEGRATION** button at the bottom right.\n3.  Search for **Mitsubishi Climate Proxy**.\n4.  Follow the on-screen instructions:\n    - Select the source ESPHome entity (e.g., `climate.living_room_esphome`).\n    - Give your new proxy entity a name (e.g., `Living Room Climate`).\n5.  Click **Submit**.\n\nYour new entity (e.g., `climate.living_room_climate`) is created immediately and can be used in your dashboard.\n\n#### Configuration (YAML Method - Legacy)\n\nIf you prefer configuration via YAML, add this to your `configuration.yaml`:\n\n```yaml\nclimate:\n  - platform: mitsubishi_climate_proxy\n    source_entity: climate.my_esphome_entity # Replace with your actual ESPHome entity ID\n    name: \"Bedroom Hybrid\" # Name for the new wrapper entity\n```\n\n## Example Configuration - Minimal\n\nThis minimal configuration includes the basic components necessary for the firmware to operate. Note that you need to choose between the ESP32 and the ESP8266 sections to get the correct UART configuration. Utilizes a `secrets.yaml` file to store your credentials.\n\n<details>\n\n<summary>Minimal Configuration</summary>\n\n```yaml\nesphome:\n  name: heatpump-1\n  friendly_name: My Heatpump 1\n\n# For ESP8266 Devices\n\n#esp8266:\n\n# board: d1_mini\n\n#uart:\n\n# id: HP_UART\n\n# baud_rate: 2400\n\n# tx_pin: 1\n\n# rx_pin: 3\n\n# For ESP32 Devices\n\nesp32:\nboard: esp32doit-devkit-v1\nframework:\ntype: esp-idf\n\nuart:\nid: HP_UART\nbaud_rate: 2400\ntx_pin: GPIO17\nrx_pin: GPIO16\n\nexternal_components:\n\n- source: github://echavet/MitsubishiCN105ESPHome\n\n# Climate entity configuration\n\nclimate:\n\n- platform: cn105\n  name: \"My Heat Pump\"\n  update_interval: 2s\n\n# Default logging level\n\nlogger:\n\n# hardware_uart: UART1 # Uncomment on ESP8266 devices\n\nlevel: INFO\n\n# Enable Home Assistant API\n\napi:\nencryption:\nkey: !secret api_key\n\nota:\nplatform: esphome # Required for ESPhome 2024.6.0 and greater\npassword: !secret ota_password\n\nwifi:\nssid: !secret wifi_ssid\npassword: !secret wifi_password\n\n# Enable fallback hotspot (captive portal) in case wifi connection fails\n\n  ap:\n    ssid: \"Heatpump Fallback Hotspot\"\n    password: !secret fallback_password\n\ncaptive_portal:\n\n```\n\n</details>\n\n## Example Configuration - Complete\n\nThis example includes all the bells and whistles, optional components, remote temperature sensing, reboot button, and additional sensors in HomeAssistant including uptime, the current wifi SSID, and signal strength. Note that you need to choose between the ESP32 and the ESP8266 sections to get the correct UART configuration. Utilizes a `secrets.yaml` file to store your credentials. Comment out or remote features your unit doesn't support (such as the isee sensor or horizontal vane). It doesn't hurt to try them, but if your unit doesn't support that feature then it will be inactive.\n\n<details>\n\n<summary>Complete Configuration</summary>\n\n```yaml\nsubstitutions:\n  name: heatpump-1\n  friendly_name: My Heatpump 1\n  remote_temp_sensor: sensor.my_room_temperature # Homeassistant sensor providing remote temperature\n\nesphome:\n  name: ${name}\n  friendly_name: ${friendly_name}\n\n# For ESP8266 Devices\n#esp8266:\n#  board: d1_mini\n#\n#uart:\n#  id: HP_UART\n#  baud_rate: 2400\n#  tx_pin: 1\n#  rx_pin: 3\n\n# For ESP32 Devices\nesp32:\n  board: esp32doit-devkit-v1\n  framework:\n    type: esp-idf\n\nuart:\n  id: HP_UART\n  baud_rate: 2400\n  tx_pin: GPIO17\n  rx_pin: GPIO16\n\nexternal_components:\n  - source: github://echavet/MitsubishiCN105ESPHome\n#    refresh: 0s\n\nwifi:\n  ssid: !secret ssid\n  password: !secret password\n  domain: !secret domain\n\n  # Enable fallback hotspot (captive portal) in case wifi connection fails\n  ap:\n    ssid: \"${friendly_name} ESP\"\n    password: !secret fallback_password\n\ncaptive_portal:\n\n# Enable logging\nlogger:\n  #  hardware_uart: UART1 # Uncomment on ESP8266 devices\n  level: INFO\n  logs:\n    EVT_SETS: INFO\n    WIFI: INFO\n    MQTT: INFO\n    WRITE_SETTINGS: INFO\n    SETTINGS: INFO\n    STATUS: INFO\n    CN105Climate: WARN\n    CN105: INFO\n    climate: WARN\n    sensor: WARN\n    chkSum: INFO\n    WRITE: WARN\n    READ: WARN\n    Header: INFO\n    Decoder: INFO\n    CONTROL_WANTED_SETTINGS: INFO\n#  level: DEBUG\n#  logs:\n#    EVT_SETS : DEBUG\n#    WIFI : INFO\n#    MQTT : INFO\n#    WRITE_SETTINGS : DEBUG\n#    SETTINGS : DEBUG\n#    STATUS : INFO\n#    CN105Climate: WARN\n#    CN105: DEBUG\n#    climate: WARN\n#    sensor: WARN\n#    chkSum : INFO\n#    WRITE : WARN\n#    READ : WARN\n#    Header: INFO\n#    Decoder : DEBUG\n#    CONTROL_WANTED_SETTINGS: DEBUG\n\n# Enable Home Assistant API\napi:\n  encryption:\n    key: !secret api_key\n\nsensor:\n  # Uptime sensor.\n  - platform: uptime\n    name: Uptime\n\n  # WiFi Signal sensor.\n  - platform: wifi_signal\n    name: WiFi Signal\n    update_interval: 120s\n\n  - platform: homeassistant\n    name: \"Remote Temperature Sensor\"\n    entity_id: ${remote_temp_sensor} # Replace with your HomeAssistant remote sensor entity id, or include in substitutions\n    internal: false\n    disabled_by_default: true\n    device_class: temperature\n    state_class: measurement\n    unit_of_measurement: \"Â°C\"\n    filters:\n      # Uncomment the lambda line to convert F to C on incoming temperature\n      #  - lambda: return (x - 32) * (5.0/9.0);\n      - clamp: # Limits values to range accepted by Mitsubishi units\n          min_value: 1\n          max_value: 40\n          ignore_out_of_range: true\n      - throttle: 30s\n    on_value:\n      then:\n        - logger.log:\n            level: INFO\n            format: \"Remote temperature received from HA: %.1f C\"\n            args: [\"x\"]\n        - lambda: \"id(hp).set_remote_temperature(x);\"\n\nota:\n  platform: esphome # Required for ESPhome 2024.6.0 and greater\n\n# Enable Web server.\nweb_server:\n  port: 80\n\n# Sync time with Home Assistant.\ntime:\n  - platform: homeassistant\n    id: homeassistant_time\n\n# Text sensors with general information.\ntext_sensor:\n  # Expose ESPHome version as sensor.\n  - platform: version\n    name: ESPHome Version\n  # Expose WiFi information as sensors.\n  - platform: wifi_info\n    ip_address:\n      name: IP\n    ssid:\n      name: SSID\n    bssid:\n      name: BSSID\n\n# Create a button to restart the unit from HomeAssistant. Rarely needed, but can be handy.\nbutton:\n  - platform: restart\n    name: \"Restart ${friendly_name}\"\n\n# Creates the sensor used to receive the remote temperature from Home Assistant\n# Uses sensor selected in substitutions area at top of config\n# Customize the filters to your application:\n#   Uncomment the first line to convert F to C when remote temps are sent\n#   If you have a fast or noisy sensor, consider some of the other filter\n#   options such as throttle_average.\nclimate:\n  - platform: cn105\n    id: hp\n    name: \"${friendly_name}\"\n    icon: mdi:heat-pump\n    visual:\n      min_temperature: 10 # Adjust to your unit's min temp. SmartSet units can go to 10C for heating\n      max_temperature: 31\n      temperature_step:\n        target_temperature: 1\n        current_temperature: 0.5\n    # Fahrenheit compatibility mode - uses Mitsubishi's \"custom\" unit conversions, set to\n    # \"standard\" (or \"alt\") for better support of Fahrenheit units in HomeAssistant.\n    # Options: \"disabled\" (default), \"standard\", \"alt\"\n    fahrenheit_compatibility: \"disabled\"\n    # Timeout and communication settings\n    remote_temperature_timeout: 30min\n    remote_temperature_keepalive_interval: 20s # Auto re-send external temp (like Kumo)\n    update_interval: 2s\n    debounce_delay: 100ms\n    # Various optional sensors, not all sensors are supported by all heatpumps\n    compressor_frequency_sensor:\n      name: Compressor Frequency\n      entity_category: diagnostic\n      disabled_by_default: true\n    outside_air_temperature_sensor:\n      name: Outside Air Temp\n      disabled_by_default: true\n    vertical_vane_select:\n      name: Vertical Vane\n      disabled_by_default: false\n    horizontal_vane_select:\n      name: Horizontal Vane\n      disabled_by_default: true\n    isee_sensor:\n      name: ISEE Sensor\n      disabled_by_default: true\n    stage_sensor:\n      name: Stage\n      entity_category: diagnostic\n      disabled_by_default: true\n    sub_mode_sensor:\n      name: Sub Mode\n      entity_category: diagnostic\n      disabled_by_default: true\n    auto_sub_mode_sensor:\n      name: Auto Sub Mode\n      entity_category: diagnostic\n      disabled_by_default: true\n    input_power_sensor:\n      name: Input Power\n      disabled_by_default: true\n    kwh_sensor:\n      name: Energy Usage\n      disabled_by_default: true\n    runtime_hours_sensor:\n      name: Runtime Hours\n      entity_category: diagnostic\n      disabled_by_default: true\n```\n\n</details>\n\n## Methods for updating external temperature\n\nThere are several methods for updating the unit with an remote temperature value. This replaces the heat pump's internal temperature measurement with an external temperature measurement as the Mitsubishi wireless thermostats do, allowing you to more precisely control room comfort and improve energy efficiency by increasing cycle length.\n\n### Automatic Keep-Alive and Configuration Options\n\nWhen using an external temperature sensor, the heat pump requires periodic updates to maintain the external temperature reference. Without regular updates, the unit may fall back to its internal sensor.\n\nThis component includes a **built-in keep-alive mechanism** (similar to how Mitsubishi's Kumo Cloud module works) that automatically re-sends the external temperature at regular intervals. This eliminates the need for manual heartbeat automations in your YAML configuration.\n\n**Configuration options:**\n\n| Option                                  | Default | Description                                                                                 |\n| --------------------------------------- | ------- | ------------------------------------------------------------------------------------------- |\n| `remote_temperature_timeout`            | `never` | Time without updates before falling back to internal sensor. Recommended: `5min` to `30min` |\n| `remote_temperature_keepalive_interval` | `20s`   | Interval for automatic re-sending of temperature to the heat pump. Set to `0s` to disable   |\n\n**Example configuration:**\n\n```yaml\nclimate:\n  - platform: cn105\n    id: hp\n    # ... other options ...\n    remote_temperature_timeout: 5min # Fallback to internal sensor after 5 min without HA updates\n    remote_temperature_keepalive_interval: 20s # Re-send temperature every 20s (like Kumo does)\n```\n\n**How it works:**\n\n1. When Home Assistant sends a temperature value via `set_remote_temperature()`, the value is sent to the heat pump immediately\n2. The keep-alive timer starts automatically and re-sends the same value every 20 seconds (configurable)\n3. A debounce mechanism prevents flooding the bus if you have existing automations that send updates too frequently\n4. If Home Assistant stops sending updates (sensor offline, network issue), the `remote_temperature_timeout` triggers a fallback to the internal sensor\n\n> [!NOTE]\n> If you have an existing heartbeat/interval automation in your YAML that periodically calls `set_remote_temperature()`, you can safely remove it - the built-in keep-alive handles this automatically. You may see a warning in the logs if conflicting heartbeat patterns are detected.\n\n### Recommended - Get external temperature from a [HomeAssistant Sensor](https://esphome.io/components/sensor/homeassistant.html) through the HomeAssistant API\n\nCreates the sensor used to receive the remote temperature from Home Assistant. Uses sensor selected in substitutions area at top of config or manually entered into the sensor configuration. When the HomeAssistant sensor updates, it will send the new value to the ESP device, which will update the heatpump's remote temperature value.\n\nCustomize the filters to your application:\n\n- Uncomment the first line to convert F to C when remote temps are sent.\n- If you have a fast or noisy sensor, consider some of the other filter options such as throttle_average.\n\n```yaml\nsensor:\n  - platform: homeassistant\n    name: \"Remote Temperature Sensor\"\n    entity_id: ${remote_temp_sensor} # Replace with your HomeAssistant remote sensor entity id, or include in substitutions\n    internal: false\n    disabled_by_default: true\n    device_class: temperature\n    state_class: measurement\n    unit_of_measurement: \"Â°C\"\n    filters:\n      # Uncomment the lambda line to convert F to C on incoming temperature\n      #  - lambda: return (x - 32) * (5.0/9.0);\n      - clamp: # Limits values to range accepted by Mitsubishi units\n          min_value: 1\n          max_value: 40\n          ignore_out_of_range: true\n      - throttle: 30s\n    on_value:\n      then:\n        - logger.log:\n            level: INFO\n            format: \"Remote temperature received from HA: %.1f C\"\n            args: [\"x\"]\n        - lambda: \"id(hp).set_remote_temperature(x);\"\n```\n\n### Alternate - Get external temperature from a networked sensor with a throttle filter\n\n```yaml\nsensor:\n  - platform: pvvx_mithermometer\n    mac_address: \"A4:C1:38:XX:XX:XX\"\n    temperature:\n      name: Thermometer\n      id: temperature\n      device_class: temperature\n      state_class: measurement\n      filters:\n        throttle_average: 90s\n      on_value:\n        then:\n          - lambda: \"id(hp).set_remote_temperature(x);\"\n```\n\n### Alternate - HomeAssistant Action\n\nThis example extends to default `api:` component to add a `set_remote_temperature` action that can be called from within HomeAssistant, allowing you to send a remote temperature value to the heat pump. You will need to include an automation in HomeAssistant to periodically call the action and update the temperature with `set_remote_temperature`, or disable remote temperature with `use_internal_temperature`. No longer recommended as the default method of updating remote temperature.\n\n```yaml\napi:\n  encryption:\n    key: !secret api_key\n  services:\n    - service: set_remote_temperature\n      variables:\n        temperature: float\n      then:\n        # Select between the C version and the F version\n        # Uncomment just ONE of the below lines. The top receives the temperature value in C,\n        # the bottom receives the value in F, converting to C here.\n        - lambda: \"id(hp).set_remote_temperature(temperature);\"\n    #        - lambda: 'id(hp).set_remote_temperature((temperature - 32.0) * (5.0 / 9.0));'\n    - service: use_internal_temperature\n      then:\n        - lambda: \"id(hp).set_remote_temperature(0);\"\n```\n\n## Diagnostic Sensors\n\n### Outside Air Temperature\n\nThis sensor reads the outdoor unit's air temperature reading, in 1.0 degree C increments. Not all outdoor units support this sensor. Some outdoor units will send an accurate value while the unit is operating, or in heat/cool mode, but will send -63.5C when offline.\n\n```yaml\noutside_air_temperature_sensor:\n  name: Outside Air Temperature\n```\n\nCompatible units (as reported by users):\n\n| Indoor         | Outdoor          | Temperature                        |\n| -------------- | ---------------- | ---------------------------------- |\n| MSZ-AP25VGD    | MXZ-4F80VGD      | Works                              |\n| MSZ-AP35VGD    | MUZ-AP35VG       | Works but reports -63.5C when idle |\n| MSZ-AP60VGD    | MUZ-AP60VG       | Works                              |\n| MSZ-AP71VGD    | MUZ-AP71VG       | Works but reports -63.5C when idle |\n| MSZ-AY35VGKP   | MUZ-AY35VG       | Works                              |\n| MSZ-GLxxNA     | MXZ-SM42NAMHZ    | Works                              |\n|                | MXZ-3C24NA2      | Not working                        |\n| MSZ-RW25VG-SC1 | MUZ-RW25VGHZ-SC1 | Works                              |\n| MSZ-FSxxNA     | MXZ-4C36NA2      | Works                              |\n|                | MUZ-FD25NA       | Not working                        |\n| MSZ-LN35       | MUZ-LN35         | Not working                        |\n| MSZ-AP20VGK    | MXZ-4F83VF       | Works                              |\n| MSZ-FT50VG2    | MUZ-FT50VG       | Works                              |\n\n### Auto and Stage Sensors\n\nThe below sensors were added recently based on the work of others in sorting out other messages and bytes. The names are likely to change as we work to determine exactly what the units are doing.\n\n```yaml\nstage_sensor:\n  name: Stage Sensor\nsub_mode_sensor:\n  name: Sub Mode Sensor\nauto_sub_mode_sensor:\n  name: Auto Sub Mode Sensor\n```\n\n- `stage_sensor` is the actual fan speed of the indoor unit. This is called stage in some documentation. Reported speeds include `IDLE`, `LOW`, `GENTLE`, `MEDIUM`, `MODERATE`, `HIGH` and `DIFFUSE`, named using Mitsubishi documentation conventions.\n\n- `auto_sub_mode_sensor` indicates what actual mode the unit is in when in AUTO. Modes are `AUTO_OFF`, meaning AUTO is disabled, `AUTO_COOL`, meaning AUTO and cooling, `AUTO_HEAT`, meaning AUTO and heating and `AUTO_LEADER`, meaning this unit is the leader in a multi-head unit and selects the heat/cool mode that the others follow.\n\n- `sub_mode_sensor` indicates additional detail on the current behavior of the unit. The Sub Modes are:\n  - `NORMAL` - the unit is in an active mode (heat, cool, dry, etc.) and is either running, or waiting to run\n  - `PREHEAT` - a cold-climate feature that electrically preheats the compressor windings prior to start of operation\n  - `DEFROST` - a cold climate behavior that runs a short AC cycle during heating mode to melt ice from the coils\n  - `STANDBY` - unit is off, or has been put into a \"sleep\" state through AUTO operation on another indoor unit\n\nSome examples of how these all fit together: Unit 1 is in AUTO set to 20C and Unit 2 is in AUTO and set to 20C. Unit 1 senses that the room is 24C and tries to enter `AUTO_COOL`. If Unit 2 wants to heat the room it is in, it will enter `STANDBY` (and in the case of a few units tested, this mean it will go to \"sleep\" as if it is off, but not really be off) making Unit 1 enter `AUTO_LEADER` sub mode. In future releases, it is planned to make the ACTION in HA match these modes. But at this time this is not implemented.\n\nIt is also important to note that the Kumo adapter has many more settings that impact the behaviour above (such as thermal fan behaviour) and if you have set these the exact actions the untis take in these modes/submodes/stages is determined by those. Some of these can also be set by remotes and other devices. The setup you have will dictate the exact actions you see. If you have permutations, please share!\n\n### UART Diagnostic Sensors\n\nThe following ESPHome sensors will not be needed by most users, but can be helpful in diagnosting problems with UART connectivity. Only implement if you are currently troubleshooting or developing new functionality.\n\n```yaml\nsensor:\n  - platform: template\n    name: \"dg_uart_connected\"\n    entity_category: DIAGNOSTIC\n    lambda: |-\n      return (bool) id(hp).isUARTConnected_;\n    update_interval: 30s\n  - platform: template\n    name: \"dg_complete_cycles\"\n    entity_category: DIAGNOSTIC\n    accuracy_decimals: 0\n    lambda: |-\n      return (unsigned long) id(hp).nbCompleteCycles_;\n    update_interval: 60s\n  - platform: template\n    name: \"dg_total_cycles\"\n    accuracy_decimals: 0\n    entity_category: DIAGNOSTIC\n    lambda: |-\n      return (unsigned long) id(hp).nbCycles_;\n    update_interval: 60s\n  - platform: template\n    name: \"dg_nb_hp_connections\"\n    accuracy_decimals: 0\n    entity_category: DIAGNOSTIC\n    lambda: |-\n      return (unsigned int) id(hp).nbHeatpumpConnections_;\n    update_interval: 60s\n  - platform: template\n    name: \"dg_complete_cycles_percent\"\n    unit_of_measurement: \"%\"\n    accuracy_decimals: 1\n    entity_category: DIAGNOSTIC\n    lambda: |-\n      unsigned long nbCompleteCycles = id(hp).nbCompleteCycles_;\n      unsigned long nbCycles = id(hp).nbCycles_;\n      if (nbCycles == 0) {\n        return 0.0;\n      }\n      return (float) nbCompleteCycles / nbCycles * 100.0;\n    update_interval: 60s\n```\n\n## Hardware Settings (Function Settings)\n\nThis advanced feature allows you to read and modify the internal \"Function Settings\" (ISU) of your Mitsubishi unit directly from Home Assistant. These settings control hardware behaviors like auto-restart, temperature sensing location, or static pressure.\n\n> [!NOTE]\n> This feature depends on your unit's compatibility. If your unit returns only zeros, it likely does not support reading/writing function settings via CN105, or it may require installer/service privileges. Try setting `installer_mode: true` if your unit supports Function Settings but reports `0` values (seen on some SEZ units). The component will automatically detect fully-zero responses and disable the polling to save resources.\n> Note that the firmware autor's units do not support theses functions settings. So implementation might not be reliable.\n\n### Configuration\n\nAdd the `hardware_settings` block to your configuration. You can choose which codes to expose and customize the labels.\n\n```yaml\nclimate:\n  - platform: cn105\n    # ... your existing config ...\n\n    # Configure the update interval for reading settings (default: 24h)\n    # These settings rarely change, so a long interval is recommended.\n    hardware_settings:\n      update_interval: 20s\n      list:\n        # Code 101: Auto Restart\n        - code: 101\n          name: \"Auto Restart after Power Failure\"\n          icon: \"mdi:restart\"\n          options:\n            1: \"ON (Default)\"\n            2: \"OFF\"\n\n        # Code 102: Temperature Sensing Source\n        # Important for remote temperature control!\n        - code: 102\n          name: \"Temperature Source\"\n          icon: \"mdi:thermometer-check\"\n          options:\n            1: \"Indoor Unit (Default)\"\n            2: \"Remote Controller\"\n            3: \"External (CN105/WiFi)\"\n\n        # Code 103: Ventilation / Lossnay interaction\n        - code: 103\n          name: \"Ventilation Link\"\n          options:\n            1: \"None (Default)\"\n            2: \"With Lossnay\"\n            3: \"Forced\"\n\n        # Code 105: Auto Energy Saving\n        - code: 105\n          name: \"Auto Energy Saving\"\n          options:\n            1: \"ON (Default)\"\n            2: \"OFF\"\n\n        # Code 107: Filter Sign Interval\n        - code: 107\n          name: \"Filter Sign Interval\"\n          icon: \"mdi:air-filter\"\n          options:\n            1: \"100 Hours (Default)\"\n            2: \"2500 Hours\"\n            3: \"No Indication\"\n\n        # Code 108: Ceiling Height / Static Pressure\n        - code: 108\n          name: \"Ceiling Height Mode\"\n          icon: \"mdi:arrow-expand-vertical\"\n          options:\n            1: \"Standard (Default)\"\n            2: \"High Ceiling\"\n            3: \"Low Ceiling\"\n\n        # Code 109: Number of Air Outlets (Cassette models only)\n        - code: 109\n          name: \"Air Outlets\"\n          options:\n            1: \"4 Directions (Default)\"\n            2: \"3 Directions\"\n            3: \"2 Directions\"\n\n        # Code 110: Auto Mode Switching Logic\n        - code: 110\n          name: \"Auto Mode Logic\"\n          icon: \"mdi:sync\"\n          options:\n            1: \"Energy Saving (Default)\"\n            2: \"Comfort / Performance\"\n\n        # Code 111: Vane Setting (for specific models)\n        - code: 111\n          name: \"Vane Geometry\"\n          options:\n            1: \"Standard (Default)\"\n            2: \"Type 1\"\n            3: \"Type 2\"\n\n        # Code 117: Defrost Control\n        - code: 117\n          name: \"Defrost Logic\"\n          icon: \"mdi:snowflake-melt\"\n          options:\n            1: \"Standard (Default)\"\n            2: \"High Humidity / Frequent\"\n\n        # Code 124: Heating Temperature Offset\n        - code: 124\n          name: \"Heating Offset (+2Â°C)\"\n          options:\n            1: \"ON (Default)\"\n            2: \"OFF\"\n\n        # Code 125: Fan behavior during Thermo-OFF (Heating)\n        - code: 125\n          name: \"Fan during Thermo-OFF (Heat)\"\n          icon: \"mdi:fan-off\"\n          options:\n            1: \"Extra Low (Default)\"\n            2: \"Stop\"\n            3: \"Set Speed\"\n\n        # Code 127: Fan behavior during Thermo-OFF (Cooling)\n        - code: 127\n          name: \"Fan during Thermo-OFF (Cool)\"\n          icon: \"mdi:fan-off\"\n          options:\n            1: \"Set Speed (Default)\"\n            2: \"Stop\"\n\n        # Code 128: System Error Display\n        - code: 128\n          name: \"Error Display on Remote\"\n          options:\n            1: \"ON (Default)\"\n            2: \"OFF\"\n```\n\n## Other Implementations\n\n- [esphome-mitsubishiheatpump](https://github.com/geoffdavis/esphome-mitsubishiheatpump) - The original esphome project from which this one is forked.\n- [gysmo38/mitsubishi2MQTT](https://github.com/gysmo38/mitsubishi2MQTT) - Direct MQTT controls, robust but with a less stable WiFi stack.\n- ESPHome's built-in [Mitsubishi](https://github.com/esphome/esphome/blob/dev/esphome/components/mitsubishi/mitsubishi.h) climate component - Uses IR Remote commands, lacks bi-directional communication.\n\n## Reference Documentation\n\nRefer to these for further understanding:\n\n- [ESPHome Custom Sensors](https://esphome.io/components/sensor/custom.html)\n- [ESPHome Custom Climate Components](https://esphome.io/components/climate/custom.html)\n- [ESPHome External Components](https://esphome.io/components/external_components.html)\n- [ESPHome's Climate Component Source](https://github.com/esphome/esphome/tree/master/esphome/components/climate)\n\n---\n\n## Disclaimer\n\nThis project is not affiliated with, endorsed by, or associated with Mitsubishi Electric Corporation. \"Mitsubishi Electric\" and the three-diamond logo are registered trademarks of Mitsubishi Electric Corporation. The use of these trademarks in this project is for identification purposes only, to indicate compatibility with their products.\n",
      "stars_today": 8
    },
    {
      "id": 27729880,
      "name": "grpc",
      "full_name": "grpc/grpc",
      "description": "C++ based gRPC (C++, Python, Ruby, Objective-C, PHP, C#)",
      "html_url": "https://github.com/grpc/grpc",
      "stars": 44317,
      "forks": 11046,
      "language": "C++",
      "topics": [],
      "created_at": "2014-12-08T18:58:53Z",
      "updated_at": "2026-02-07T01:25:53Z",
      "pushed_at": "2026-02-06T22:29:18Z",
      "open_issues": 1172,
      "owner": {
        "login": "grpc",
        "avatar_url": "https://avatars.githubusercontent.com/u/7802525?v=4"
      },
      "readme": "# gRPC â€“ An RPC library and framework\n\ngRPC is a modern, open source, high-performance remote procedure call (RPC)\nframework that can run anywhere. gRPC enables client and server applications to\ncommunicate transparently, and simplifies the building of connected systems.\n\n<table>\n  <tr>\n    <td><b>Homepage:</b></td>\n    <td><a href=\"https://grpc.io/\">grpc.io</a></td>\n  </tr>\n  <tr>\n    <td><b>Mailing List:</b></td>\n    <td><a href=\"https://groups.google.com/forum/#!forum/grpc-io\">grpc-io@googlegroups.com</a></td>\n  </tr>\n</table>\n\n[![Join the chat at https://gitter.im/grpc/grpc](https://badges.gitter.im/grpc/grpc.svg)](https://gitter.im/grpc/grpc?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\n## To start using gRPC\n\nTo maximize usability, gRPC supports the standard method for adding dependencies\nto a user's chosen language (if there is one). In most languages, the gRPC\nruntime comes as a package available in a user's language package manager.\n\nFor instructions on how to use the language-specific gRPC runtime for a project,\nplease refer to these documents\n\n-   [C++](src/cpp): follow the instructions under the `src/cpp` directory\n-   [C#/.NET](https://github.com/grpc/grpc-dotnet): NuGet packages\n    `Grpc.Net.Client`, `Grpc.AspNetCore.Server`\n-   [Dart](https://github.com/grpc/grpc-dart): pub package `grpc`\n-   [Go](https://github.com/grpc/grpc-go): `go get google.golang.org/grpc`\n-   [Java](https://github.com/grpc/grpc-java): Use JARs from Maven Central\n    Repository\n-   [Kotlin](https://github.com/grpc/grpc-kotlin): Use JARs from Maven Central\n    Repository\n-   [Node](https://github.com/grpc/grpc-node): `npm install @grpc/grpc-js`\n-   [Objective-C](src/objective-c): Add `gRPC-ProtoRPC` dependency to podspec\n-   [PHP](src/php): `pecl install grpc`\n-   [Python](src/python/grpcio): `pip install grpcio`\n-   [Ruby](src/ruby): `gem install grpc`\n-   [WebJS](https://github.com/grpc/grpc-web): follow the grpc-web instructions\n\nPer-language quickstart guides and tutorials can be found in the\n[documentation section on the grpc.io website](https://grpc.io/docs/). Code\nexamples are available in the [examples](examples) directory.\n\nPrecompiled bleeding-edge package builds of gRPC `master` branch's `HEAD` are\nuploaded daily to [packages.grpc.io](https://packages.grpc.io).\n\n## To start developing gRPC\n\nContributions are welcome!\n\nPlease read [How to contribute](CONTRIBUTING.md) which will guide you through\nthe entire workflow of how to build the source code, how to run the tests, and\nhow to contribute changes to the gRPC codebase. The \"How to contribute\" document\nalso contains info on how the contribution process works and contains best\npractices for creating contributions.\n\n## Troubleshooting\n\nSometimes things go wrong. Please check out the\n[Troubleshooting guide](TROUBLESHOOTING.md) if you are experiencing issues with\ngRPC.\n\n## Performance\n\nSee the [Performance dashboard](https://grafana-dot-grpc-testing.appspot.com/)\nfor performance numbers of master branch daily builds.\n\n## Concepts\n\nSee [gRPC Concepts](CONCEPTS.md)\n\n## About This Repository\n\nThis repository contains source code for gRPC libraries implemented in multiple\nlanguages written on top of a shared C++ core library [src/core](src/core).\n\nLibraries in different languages may be in various states of development. We are\nseeking contributions for all of these libraries:\n\nLanguage                  | Source\n------------------------- | ----------------------------------\nShared C++ [core library] | [src/core](src/core)\nC++                       | [src/cpp](src/cpp)\nRuby                      | [src/ruby](src/ruby)\nPython                    | [src/python](src/python)\nPHP                       | [src/php](src/php)\nC# (core library based)   | [src/csharp](src/csharp)\nObjective-C               | [src/objective-c](src/objective-c)\n\nLanguage             | Source repo\n-------------------- | --------------------------------------------------\nJava                 | [grpc-java](https://github.com/grpc/grpc-java)\nKotlin               | [grpc-kotlin](https://github.com/grpc/grpc-kotlin)\nGo                   | [grpc-go](https://github.com/grpc/grpc-go)\nNodeJS               | [grpc-node](https://github.com/grpc/grpc-node)\nWebJS                | [grpc-web](https://github.com/grpc/grpc-web)\nDart                 | [grpc-dart](https://github.com/grpc/grpc-dart)\n.NET (pure C# impl.) | [grpc-dotnet](https://github.com/grpc/grpc-dotnet)\nSwift                | [grpc-swift](https://github.com/grpc/grpc-swift)\n",
      "stars_today": 7
    },
    {
      "id": 104231541,
      "name": "abseil-cpp",
      "full_name": "abseil/abseil-cpp",
      "description": "Abseil Common Libraries (C++)",
      "html_url": "https://github.com/abseil/abseil-cpp",
      "stars": 17011,
      "forks": 2965,
      "language": "C++",
      "topics": [],
      "created_at": "2017-09-20T15:10:30Z",
      "updated_at": "2026-02-07T02:22:33Z",
      "pushed_at": "2026-02-06T21:34:19Z",
      "open_issues": 213,
      "owner": {
        "login": "abseil",
        "avatar_url": "https://avatars.githubusercontent.com/u/26718316?v=4"
      },
      "readme": "# Abseil - C++ Common Libraries\n\nThe repository contains the Abseil C++ library code. Abseil is an open-source\ncollection of C++ code (compliant to C++17) designed to augment the C++\nstandard library.\n\n## Table of Contents\n\n- [About Abseil](#about)\n- [Quickstart](#quickstart)\n- [Building Abseil](#build)\n- [Support](#support)\n- [Codemap](#codemap)\n- [Releases](#releases)\n- [License](#license)\n- [Links](#links)\n\n<a name=\"about\"></a>\n## About Abseil\n\nAbseil is an open-source collection of C++ library code designed to augment\nthe C++ standard library. The Abseil library code is collected from Google's\nown C++ code base, has been extensively tested and used in production, and\nis the same code we depend on in our daily coding lives.\n\nIn some cases, Abseil provides pieces missing from the C++ standard; in\nothers, Abseil provides alternatives to the standard for special needs\nwe've found through usage in the Google code base. We denote those cases\nclearly within the library code we provide you.\n\nAbseil is not meant to be a competitor to the standard library; we've\njust found that many of these utilities serve a purpose within our code\nbase, and we now want to provide those resources to the C++ community as\na whole.\n\n<a name=\"quickstart\"></a>\n## Quickstart\n\nIf you want to just get started, make sure you at least run through the\n[Abseil Quickstart](https://abseil.io/docs/cpp/quickstart). The Quickstart\ncontains information about setting up your development environment, downloading\nthe Abseil code, running tests, and getting a simple binary working.\n\n<a name=\"build\"></a>\n## Building Abseil\n\n[Bazel](https://bazel.build) and [CMake](https://cmake.org/) are the official\nbuild systems for Abseil.\nSee the [quickstart](https://abseil.io/docs/cpp/quickstart) for more information\non building Abseil using the Bazel build system.\nIf you require CMake support, please check the [CMake build\ninstructions](CMake/README.md) and [CMake\nQuickstart](https://abseil.io/docs/cpp/quickstart-cmake).\n\n<a name=\"support\"></a>\n## Support\n\nAbseil follows Google's [Foundational C++ Support\nPolicy](https://opensource.google/documentation/policies/cplusplus-support). See\n[this\ntable](https://github.com/google/oss-policies-info/blob/main/foundational-cxx-support-matrix.md)\nfor a list of currently supported versions compilers, platforms, and build\ntools.\n\n<a name=\"codemap\"></a>\n## Codemap\n\nAbseil contains the following C++ library components:\n\n* [`base`](absl/base/)\n  <br /> The `base` library contains initialization code and other code which\n  all other Abseil code depends on. Code within `base` may not depend on any\n  other code (other than the C++ standard library).\n* [`algorithm`](absl/algorithm/)\n  <br /> The `algorithm` library contains additions to the C++ `<algorithm>`\n  library and container-based versions of such algorithms.\n* [`cleanup`](absl/cleanup/)\n  <br /> The `cleanup` library contains the control-flow-construct-like type\n  `absl::Cleanup` which is used for executing a callback on scope exit.\n* [`container`](absl/container/)\n  <br /> The `container` library contains additional STL-style containers,\n  including Abseil's unordered \"Swiss table\" containers.\n* [`crc`](absl/crc/) The `crc` library contains code for\n  computing error-detecting cyclic redundancy checks on data.\n* [`debugging`](absl/debugging/)\n  <br /> The `debugging` library contains code useful for enabling leak\n  checks, and stacktrace and symbolization utilities.\n* [`flags`](absl/flags/)\n  <br /> The `flags` library contains code for handling command line flags for\n  libraries and binaries built with Abseil.\n* [`hash`](absl/hash/)\n  <br /> The `hash` library contains the hashing framework and default hash\n  functor implementations for hashable types in Abseil.\n* [`log`](absl/log/)\n  <br /> The `log` library contains `LOG` and `CHECK` macros and facilities\n  for writing logged messages out to disk, `stderr`, or user-extensible\n  destinations.\n* [`memory`](absl/memory/)\n  <br /> The `memory` library contains memory management facilities that augment\n  C++'s `<memory>` library.\n* [`meta`](absl/meta/)\n  <br /> The `meta` library contains type checks\n  similar to those available in the C++ `<type_traits>` library.\n* [`numeric`](absl/numeric/)\n  <br /> The `numeric` library contains 128-bit integer types as well as\n  implementations of C++20's bitwise math functions.\n* [`profiling`](absl/profiling/)\n  <br /> The `profiling` library contains utility code for profiling C++\n  entities.  It is currently a private dependency of other Abseil libraries.\n* [`random`](absl/random/)\n  <br /> The `random` library contains functions for generating pseudorandom\n  values.\n* [`status`](absl/status/)\n  <br /> The `status` library contains abstractions for error handling,\n  specifically `absl::Status` and `absl::StatusOr<T>`.\n* [`strings`](absl/strings/)\n  <br /> The `strings` library contains a variety of strings routines and\n  utilities.\n* [`synchronization`](absl/synchronization/)\n  <br /> The `synchronization` library contains concurrency primitives (Abseil's\n  `absl::Mutex` class, an alternative to `std::mutex`) and a variety of\n  synchronization abstractions.\n* [`time`](absl/time/)\n  <br /> The `time` library contains abstractions for computing with absolute\n  points in time, durations of time, and formatting and parsing time within\n  time zones.\n* [`types`](absl/types/)\n  <br /> The `types` library contains non-container utility types.\n* [`utility`](absl/utility/)\n  <br /> The `utility` library contains utility and helper code.\n\n<a name=\"releases\"></a>\n## Releases\n\nAbseil recommends users \"live-at-head\" (update to the latest commit from the\nmaster branch as often as possible). However, we realize this philosophy doesn't\nwork for every project, so we also provide [Long Term Support\nReleases](https://github.com/abseil/abseil-cpp/releases) to which we backport\nfixes for severe bugs. See our [release\nmanagement](https://abseil.io/about/releases) document for more details.\n\n<a name=\"license\"></a>\n## License\n\nThe Abseil C++ library is licensed under the terms of the Apache\nlicense. See [LICENSE](LICENSE) for more information.\n\n<a name=\"links\"></a>\n## Links\n\nFor more information about Abseil:\n\n* Consult our [Abseil Introduction](https://abseil.io/about/intro)\n* Read [Why Adopt Abseil](https://abseil.io/about/philosophy) to understand our\n  design philosophy.\n* Peruse our\n  [Abseil Compatibility Guarantees](https://abseil.io/about/compatibility) to\n  understand both what we promise to you, and what we expect of you in return.\n",
      "stars_today": 7
    },
    {
      "id": 1038242425,
      "name": "EeveeSpotifyReborn",
      "full_name": "whoeevee/EeveeSpotifyReborn",
      "description": "A tweak to enhance Spotify experience",
      "html_url": "https://github.com/whoeevee/EeveeSpotifyReborn",
      "stars": 2126,
      "forks": 9439,
      "language": "Swift",
      "topics": [],
      "created_at": "2025-08-14T21:18:25Z",
      "updated_at": "2026-02-06T23:32:19Z",
      "pushed_at": "2025-12-26T16:38:37Z",
      "open_issues": 73,
      "owner": {
        "login": "whoeevee",
        "avatar_url": "https://avatars.githubusercontent.com/u/94960726?v=4"
      },
      "readme": "# Discontinuation Notice\n\nhttps://t.me/SpotilifeIPAs/196\n\n![Banner](Images/banner.png?)\n\n# The original EeveeSpotify repository was disabled due to a [DMCA takedown](https://github.com/github/dmca/blob/master/2025/08/2025-08-14-spotify.md). This repository will not contain the IPA packages, as they are most likely the reason for the takedown.\n\n# EeveeSpotify\n\nThis tweak makes Spotify think you have a Premium subscription, granting free listening, just like Spotilife, and provides some additional features like custom lyrics.\n\n## How to build an EeveeSpotify IPA using Github actions\n> [!NOTE]\n> If this your first time, complete following steps before starting:\n>\n> 1. Fork this repository using the fork button on the top right\n> 2. On your forked repository, go to **Repository Settings** > **Actions**, enable **Read and Write** permissions.\n\n<details>\n  <summary>How to build the EeveeSpotify IPA</summary>\n  <ol>\n    <li>Click on <strong>Sync fork</strong>, and if your branch is out-of-date, click on <strong>Update branch</strong>.</li>\n    <li>Navigate to the <strong>Actions tab</strong> in your forked repository and select <strong>Create IPA Packages</strong> if you're on desktop/widescreen. Tap on <strong>All Workflows</strong> and select <strong>Create IPA Packages</strong> if you're on mobile/portrait.</li>\n    <li>Click the <strong>Run workflow</strong> button located on the right side.</li>\n    <li>Prepare a decrypted .ipa file <em>(we cannot provide this due to legal reasons)</em>, then upload it to a file provider (e.g., filebin.net, filemail.com, or Dropbox is recommended). Paste the URL of the decrypted IPA file in the provided field.</li>\n    <li><strong>NOTE:</strong> Make sure to provide a direct download link to the file, not a link to a webpage. Otherwise, the process will fail.</li>\n    <li>Go to the releases page of the EeveeSpotify repository (<strong>NOT</strong> the fork). Hold and copy the link of the .deb file, which corresponds to your phone's architecture.</li>\n    <li>Make sure all inputs are correct, then click <strong>Run workflow</strong> to start the process.</li>\n    <li>Wait for the build to finish. You can download the EeveeSpotify IPA from the releases section of your forked repo. (If you can't find the releases section, go to your forked repo and add /releases to the URL, i.e., github.com/user/EeveeSpotifyReborn/releases.)</li>\n  </ol>\n</details>\n\n## The History\n\nIn January 2024, Spotilife, the only tweak to get Spotify Premium, stopped working on new Spotify versions. I decompiled Spotilife, reverse-engineered Spotify, intercepted requests, etc., and created this tweak.\n\n## Restrictions\n\nPlease refrain from opening issues about the following features, as they are server-sided and will **NEVER** work:\n\n- Very High audio quality\n- Native playlist downloading (you can download podcast episodes though)\n- Jam (hosting a Spotify Jam and joining it remotely requires Premium; only joining in-person works)\n- AI DJ/Playlist\n- Spotify Connect (When using Spotify Connect, the device will act as a remote control and stream directly to the connected device. This is a server-sided limitation and is beyond the control of EeveeSpotify, so it will behave as if you have a Free subscription while using this feature.)\n\nIt's possible to implement downloading locally, but it will never be included in EeveeSpotify (unless someone opens a pull request).\n\n## Lyrics Support\n\nEeveeSpotify replaces Spotify monthly limited lyrics with one of the following four lyrics providers:\n\n- Genius: Offers the best quality lyrics, provides the most songs, and updates lyrics the fastest. Does not and will never be time-synced.\n\n- LRCLIB: The most open service, offering time-synced lyrics. However, it lacks lyrics for many songs.\n\n- Musixmatch: The service Spotify uses. Provides time-synced lyrics for many songs, but you'll need a user token to use this source. To obtain the token, download Musixmatch from the App Store, sign up, then go to Settings > Get help > Copy debug info, and paste it into EeveeSpotify alert. You can also extract the token using MITM.\n\n- PetitLyrics: Offers plenty of time-synced Japanese and some international lyrics.\n\nIf the tweak is unable to find a song or process the lyrics, you'll see a \"Couldn't load the lyrics for this song\" message. The lyrics might be wrong for some songs when using Genius due to how the tweak searches songs. While I've made it work in most cases, kindly refrain from opening issues about it.\n\n## How It Works\n\n**Starting with version 4.0, EeveeSpotify intercepts Spotify requests to load user data, deserializes it, and modifies the parameters in real-time. This method is the best so far and works incredibly stable, so the below explanation is no longer valid for v4.0 and later.**\n\nUpon login, Spotify fetches user data and caches it in the `offline.bnk` file in the `/Library/Application Support/PersistentCache` directory. It uses its proprietary binary format to store data, incorporating a length byte before each value, among other conventions. Certain keys, such as `player-license`, `financial-product`, `streaming-rules`, and others, determine the user abilities.\n\nThe tweak patches this file while initializing; Spotify loads it and assumes you have Premium. To be honest, it doesn't really patch due to challenges with dynamic length and varied bytes. The tweak extracts the username from the current `offline.bnk` file and inserts it into `premiumblank.bnk` (a file containing all premium values preset), replacing `offline.bnk`. Spotify may reload user data, and you'll be switched to the Free plan. When this happens, you'll see a popup with quick restart app and reset data actions.\n\n![Hex](Images/hex.png)\n\nTweak also sets `trackRowsEnabled` in `SPTFreeTierArtistHubRemoteURLResolver` to `true`, so Spotify loads not just track names on the artist page, and adds a liked tracks row to the artist view models, allowing you to see the liked tracks row just like with Premium.\n\nTo open Spotify links in sideloaded app, use [OpenSpotifySafariExtension](https://github.com/BillyCurtis/OpenSpotifySafariExtension). Remember to activate it and allow access in Settings > Safari > Extensions.\n\n## Support\n\nEeveeSpotify has always been free and open-source project. However, I started accepting crypto donations if you'd like to support me. I really appreciate it:\n\nUSDT (TRC-20): `TK4AZZLEWrahYUkKDG8r8Pr5BmkoFjs5zU`\n\nETH/USDC/USDT: `0x4eFf79BdfCa9d3BC01a1d145eF343871bb0a3CdF`\n\nBTC: `bc1qspsnjenfq6wgj9a7pmm2xe3up4622wqxlem0g5`\n\nTON: `UQCgt8EfLdT3QOmnC11vsndUBHryi2suTcTOVCQqBgMdmg4l`\n\nLTC: `ltc1qup3v46fm05sxd278r63957wh4qf2esehevpy76`\n\n### Donors\n\nThanks to the following donors for supporting the project and funding the automatic release workflow:\n\n- [Randy](https://github.com/randy-420)\n- [HAMO](https://github.com/hamzaharoon1314)\n",
      "stars_today": 7
    },
    {
      "id": 511691380,
      "name": "lance",
      "full_name": "lance-format/lance",
      "description": "Open Lakehouse Format for Multimodal AI. Convert from Parquet in 2 lines of code for 100x faster random access, vector index, and data versioning. Compatible with Pandas, DuckDB, Polars, Pyarrow, and PyTorch with more integrations coming..",
      "html_url": "https://github.com/lance-format/lance",
      "stars": 6021,
      "forks": 544,
      "language": "Rust",
      "topics": [
        "apache-arrow",
        "computer-vision",
        "data-analysis",
        "data-analytics",
        "data-centric",
        "data-format",
        "data-science",
        "dataops",
        "deep-learning",
        "duckdb",
        "embeddings",
        "llms",
        "machine-learning",
        "mlops",
        "python",
        "rust"
      ],
      "created_at": "2022-07-07T22:29:29Z",
      "updated_at": "2026-02-06T21:27:24Z",
      "pushed_at": "2026-02-06T18:15:44Z",
      "open_issues": 1023,
      "owner": {
        "login": "lance-format",
        "avatar_url": "https://avatars.githubusercontent.com/u/243204601?v=4"
      },
      "readme": "<div align=\"center\">\n<p align=\"center\">\n\n<img width=\"257\" alt=\"Lance Logo\" src=\"https://user-images.githubusercontent.com/917119/199353423-d3e202f7-0269-411d-8ff2-e747e419e492.png\">\n\n**The Open Lakehouse Format for Multimodal AI**<br/>\n**High-performance vector search, full-text search, random access, and feature engineering capabilities for the lakehouse.**<br/>\n**Compatible with Pandas, DuckDB, Polars, PyArrow, Ray, Spark, and more integrations on the way.**\n\n<a href=\"https://lance.org\">Documentation</a> â€¢\n<a href=\"https://lance.org/community\">Community</a> â€¢\n<a href=\"https://discord.gg/lance\">Discord</a>\n\n[CI]: https://github.com/lance-format/lance/actions/workflows/rust.yml\n[CI Badge]: https://github.com/lance-format/lance/actions/workflows/rust.yml/badge.svg\n[Docs]: https://lance.org\n[Docs Badge]: https://img.shields.io/badge/docs-passing-brightgreen\n[crates.io]: https://crates.io/crates/lance\n[crates.io badge]: https://img.shields.io/crates/v/lance.svg\n[Python versions]: https://pypi.org/project/pylance/\n[Python versions badge]: https://img.shields.io/pypi/pyversions/pylance\n\n[![CI Badge]][CI]\n[![Docs Badge]][Docs]\n[![crates.io badge]][crates.io]\n[![Python versions badge]][Python versions]\n\n</p>\n</div>\n\n<hr />\n\nLance is an open lakehouse format for multimodal AI. It contains a file format, table format, and catalog spec that allows you to build a complete lakehouse on top of object storage to power your AI workflows. Lance is perfect for:\n\n1. Building search engines and feature stores with hybrid search capabilities.\n2. Large-scale ML training requiring high performance IO and random access.\n3. Storing, querying, and managing multimodal data including images, videos, audio, text, and embeddings.\n\nThe key features of Lance include:\n\n* **Expressive hybrid search:** Combine vector similarity search, full-text search (BM25), and SQL analytics on the same dataset with accelerated secondary indices.\n\n* **Lightning-fast random access:** 100x faster than Parquet or Iceberg for random access without sacrificing scan performance.\n\n* **Native multimodal data support:** Store images, videos, audio, text, and embeddings in a single unified format with efficient blob encoding and lazy loading.\n\n* **Data evolution:** Efficiently add columns with backfilled values without full table rewrites, perfect for ML feature engineering.\n\n* **Zero-copy versioning:** ACID transactions, time travel, and automatic versioning without needing extra infrastructure.\n\n* **Rich ecosystem integrations:** Apache Arrow, Pandas, Polars, DuckDB, Apache Spark, Ray, Trino, Apache Flink, and open catalogs (Apache Polaris, Unity Catalog, Apache Gravitino).\n\nFor more details, see the full [Lance format specification](https://lance.org/format).\n\n> [!TIP]\n> Lance is in active development and we welcome contributions. Please see our [contributing guide](https://lance.org/community/contributing/) for more information.\n\n## Quick Start\n\n**Installation**\n\n```shell\npip install pylance\n```\n\nTo install a preview release:\n\n```shell\npip install --pre --extra-index-url https://pypi.fury.io/lance-format/pylance\n```\n\n> [!NOTE]\n> For versions prior to 1.0.0-beta.4, you can find them at https://pypi.fury.io/lancedb/pylance\n\n> [!TIP]\n> Preview releases are released more often than full releases and contain the\n> latest features and bug fixes. They receive the same level of testing as full releases.\n> We guarantee they will remain published and available for download for at\n> least 6 months. When you want to pin to a specific version, prefer a stable release.\n\n**Converting to Lance**\n\n```python\nimport lance\n\nimport pandas as pd\nimport pyarrow as pa\nimport pyarrow.dataset\n\ndf = pd.DataFrame({\"a\": [5], \"b\": [10]})\nuri = \"/tmp/test.parquet\"\ntbl = pa.Table.from_pandas(df)\npa.dataset.write_dataset(tbl, uri, format='parquet')\n\nparquet = pa.dataset.dataset(uri, format='parquet')\nlance.write_dataset(parquet, \"/tmp/test.lance\")\n```\n\n**Reading Lance data**\n```python\ndataset = lance.dataset(\"/tmp/test.lance\")\nassert isinstance(dataset, pa.dataset.Dataset)\n```\n\n**Pandas**\n```python\ndf = dataset.to_table().to_pandas()\ndf\n```\n\n**DuckDB**\n```python\nimport duckdb\n\n# If this segfaults, make sure you have duckdb v0.7+ installed\nduckdb.query(\"SELECT * FROM dataset LIMIT 10\").to_df()\n```\n\n**Vector search**\n\nDownload the sift1m subset\n\n```shell\nwget ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz\ntar -xzf sift.tar.gz\n```\n\nConvert it to Lance\n\n```python\nimport lance\nfrom lance.vector import vec_to_table\nimport numpy as np\nimport struct\n\nnvecs = 1000000\nndims = 128\nwith open(\"sift/sift_base.fvecs\", mode=\"rb\") as fobj:\n    buf = fobj.read()\n    data = np.array(struct.unpack(\"<128000000f\", buf[4 : 4 + 4 * nvecs * ndims])).reshape((nvecs, ndims))\n    dd = dict(zip(range(nvecs), data))\n\ntable = vec_to_table(dd)\nuri = \"vec_data.lance\"\nsift1m = lance.write_dataset(table, uri, max_rows_per_group=8192, max_rows_per_file=1024*1024)\n```\n\nBuild the index\n\n```python\nsift1m.create_index(\"vector\",\n                    index_type=\"IVF_PQ\",\n                    num_partitions=256,  # IVF\n                    num_sub_vectors=16)  # PQ\n```\n\nSearch the dataset\n\n```python\n# Get top 10 similar vectors\nimport duckdb\n\ndataset = lance.dataset(uri)\n\n# Sample 100 query vectors. If this segfaults, make sure you have duckdb v0.7+ installed\nsample = duckdb.query(\"SELECT vector FROM dataset USING SAMPLE 100\").to_df()\nquery_vectors = np.array([np.array(x) for x in sample.vector])\n\n# Get nearest neighbors for all of them\nrs = [dataset.to_table(nearest={\"column\": \"vector\", \"k\": 10, \"q\": q})\n      for q in query_vectors]\n```\n\n## Directory structure\n\n| Directory          | Description              |\n|--------------------|--------------------------|\n| [rust](./rust)     | Core Rust implementation |\n| [python](./python) | Python bindings (PyO3)   |\n| [java](./java)     | Java bindings (JNI)      |\n| [docs](./docs)     | Documentation source     |\n\n## Benchmarks\n\n### Vector search\n\nWe used the SIFT dataset to benchmark our results with 1M vectors of 128D\n\n1. For 100 randomly sampled query vectors, we get <1ms average response time (on a 2023 m2 MacBook Air)\n\n![avg_latency.png](docs/src/images/avg_latency.png)\n\n2. ANNs are always a trade-off between recall and performance\n\n![avg_latency.png](docs/src/images/recall_vs_latency.png)\n\n### Vs. parquet\n\nWe create a Lance dataset using the Oxford Pet dataset to do some preliminary performance testing of Lance as compared to Parquet and raw image/XMLs. For analytics queries, Lance is 50-100x better than reading the raw metadata. For batched random access, Lance is 100x better than both parquet and raw files.\n\n![](docs/src/images/lance_perf.png)\n\n## Why Lance for AI/ML workflows?\n\nThe machine learning development cycle involves multiple stages:\n\n```mermaid\ngraph LR\n    A[Collection] --> B[Exploration];\n    B --> C[Analytics];\n    C --> D[Feature Engineer];\n    D --> E[Training];\n    E --> F[Evaluation];\n    F --> C;\n    E --> G[Deployment];\n    G --> H[Monitoring];\n    H --> A;\n```\n\nTraditional lakehouse formats were designed for SQL analytics and struggle with AI/ML workloads that require:\n- **Vector search** for similarity and semantic retrieval\n- **Fast random access** for sampling and interactive exploration\n- **Multimodal data** storage (images, videos, audio alongside embeddings)\n- **Data evolution** for feature engineering without full table rewrites\n- **Hybrid search** combining vectors, full-text, and SQL predicates\n\nWhile existing formats (Parquet, Iceberg, Delta Lake) excel at SQL analytics, they require additional specialized systems for AI capabilities. Lance brings these AI-first features directly into the lakehouse format.\n\nA comparison of different formats across ML development stages:\n\n|                     | Lance | Parquet & ORC | JSON & XML | TFRecord | Database | Warehouse |\n|---------------------|-------|---------------|------------|----------|----------|-----------|\n| Analytics           | Fast  | Fast          | Slow       | Slow     | Decent   | Fast      |\n| Feature Engineering | Fast  | Fast          | Decent     | Slow     | Decent   | Good      |\n| Training            | Fast  | Decent        | Slow       | Fast     | N/A      | N/A       |\n| Exploration         | Fast  | Slow          | Fast       | Slow     | Fast     | Decent    |\n| Infra Support       | Rich  | Rich          | Decent     | Limited  | Rich     | Rich      |\n\n",
      "stars_today": 7
    },
    {
      "id": 802953062,
      "name": "Feather",
      "full_name": "khcrysalis/Feather",
      "description": "Free on-device iOS/iPadOS application manager/installer, using certificates part of the Apple Developer Program.",
      "html_url": "https://github.com/khcrysalis/Feather",
      "stars": 3564,
      "forks": 312,
      "language": "Swift",
      "topics": [
        "esign",
        "ios",
        "ipa",
        "ipados",
        "kravasign",
        "sideload",
        "sideloading",
        "sign",
        "signature",
        "signer",
        "signing",
        "zsign"
      ],
      "created_at": "2024-05-19T17:44:22Z",
      "updated_at": "2026-02-07T01:09:40Z",
      "pushed_at": "2026-02-07T01:09:36Z",
      "open_issues": 16,
      "owner": {
        "login": "khcrysalis",
        "avatar_url": "https://avatars.githubusercontent.com/u/97859147?v=4"
      },
      "readme": "# Feather\n\n[![GitHub Release](https://img.shields.io/github/v/release/khcrysalis/feather?include_prereleases)](https://github.com/khcrysalis/feather/releases)\n[![GitHub Downloads (all assets, all releases)](https://img.shields.io/github/downloads/khcrysalis/feather/total)](https://github.com/khcrysalis/feather/releases)\n[![GitHub License](https://img.shields.io/github/license/khcrysalis/feather?color=%23C96FAD)](https://github.com/khcrysalis/feather/blob/main/LICENSE)\n[![Sponsor Me](https://img.shields.io/static/v1?label=Sponsor&message=%E2%9D%A4&logo=GitHub&color=%23fe8e86)](https://github.com/sponsors/khcrysalis)\n[![Discord](https://img.shields.io/discord/1265361879992242196?style=flat&label=discord)](https://discord.gg/TYnUDJkG66)\n\nThis app allows you to install and manage applications contained in a single app, using certificate pairs and various installation techniques to allow apps to install to your device. This is an entirely stock application and uses built-in features to be able to do this!\n\n<p align=\"center\"><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"Images/Image-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"Images/Image-light.png\"><img alt=\"Feather\" src=\"Images/Image-light.png\"></picture></p>\n\n### Features\n\n- User friendly, and clean UI.\n- Sign and install applications.\n- Supports [AltStore](https://faq.altstore.io/distribute-your-apps/make-a-source#apps) repositories.\n- View detailed information about apps and your certificates.\n- Configurable signing options mainly for modifying the app, such as appearance and allowing support for the files app.\n  - This includes patching apps for compatibility and Liquid Glass.\n- Tweak support for advanced users, using [Ellekit](https://github.com/tealbathingsuit/ellekit) for injection. \n  - Supports injecting `.deb` and `.dylib` files.\n- Actively maintained: always ensuring most apps get installed properly.\n- No tracking or analytics, ensuring user privacy.\n- Of course, open source and free.\n\n## Download\n\nVisit [releases](https://github.com/khcrysalis/Feather/releases) and get the latest `.ipa`.\n\n<a href=\"https://celloserenity.github.io/altdirect/?url=https://raw.githubusercontent.com/khcrysalis/Feather/refs/heads/main/app-repo.json\" target=\"_blank\">\n   <img src=\"https://github.com/CelloSerenity/altdirect/blob/main/assets/png/AltSource_Blue.png?raw=true\" alt=\"Add AltSource\" width=\"200\">\n</a>\n<a href=\"https://github.com/khcrysalis/Feather/releases/latest/download/Feather.ipa\" target=\"_blank\">\n   <img src=\"https://github.com/CelloSerenity/altdirect/blob/main/assets/png/Download_Blue.png?raw=true\" alt=\"Download .ipa\" width=\"200\">\n</a>\n\n## How does it work?\n\nVisit the [HOW IT WORKS](./HOW_IT_WORKS.md) page.\n\n## Sponsors\n\n| Thanks to all my [sponsors](https://github.com/sponsors/khcrysalis)!! |\n|:-:|\n| <img src=\"https://raw.githubusercontent.com/khcrysalis/github-sponsor-graph/main/graph.png\"> |\n| _**\"samara is cute\" - Vendicated**_ |\n\n## Star History\n\n<a href=\"https://star-history.com/#khcrysalis/feather&Date\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=khcrysalis/feather&type=Date&theme=dark\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=khcrysalis/feather&type=Date\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=khcrysalis/feather&type=Date\" />\n </picture>\n</a>\n\n## Acknowledgements\n\n- [Samara](https://github.com/khcrysalis) - The maker\n- [idevice](https://github.com/jkcoxson/idevice) - Backend for builds with this included, used for communication with `installd`.\n- [*.backloop.dev](https://backloop.dev/) - localhost with public CA signed SSL certificate\n- [Vapor](https://github.com/vapor/vapor) - A server-side Swift HTTP web framework.\n- [Zsign](https://github.com/zhlynn/zsign) - Allowing to sign on-device, reimplimented to work on other platforms such as iOS.\n- [LiveContainer](https://github.com/LiveContainer/LiveContainer) - Fixes/some help\n- [Nuke](https://github.com/kean/Nuke) - Image caching.\n- [Asspp](https://github.com/Lakr233/Asspp) - Some code for setting up the http server.\n- [plistserver](https://github.com/nekohaxx/plistserver) - Hosted on https://api.palera.in.\n\n## License \n\nThis project is licensed under the GPL-3.0 license. You can see the full details of the license [here](https://github.com/khcrysalis/Feather/blob/main/LICENSE). It's under this specific license because I wanted to make a project that is transparent to the user thats related to certificate paired sideloading, before this project there weren't any open source projects that filled in this gap.\n\nBy contributing to this project, you agree to license your code under the GPL-3.0 license as well (including agreeing to license exceptions), ensuring that your work, like all other contributions, remains freely accessible and open.\n",
      "stars_today": 7
    },
    {
      "id": 3470471,
      "name": "Font-Awesome",
      "full_name": "FortAwesome/Font-Awesome",
      "description": "The iconic SVG, font, and CSS toolkit",
      "html_url": "https://github.com/FortAwesome/Font-Awesome",
      "stars": 76307,
      "forks": 12252,
      "language": "JavaScript",
      "topics": [
        "css",
        "font",
        "fontawesome",
        "icons",
        "svg-icons",
        "svg-sprites",
        "webfont"
      ],
      "created_at": "2012-02-17T14:19:43Z",
      "updated_at": "2026-02-06T23:39:39Z",
      "pushed_at": "2025-12-12T16:04:31Z",
      "open_issues": 311,
      "owner": {
        "login": "FortAwesome",
        "avatar_url": "https://avatars.githubusercontent.com/u/1505683?v=4"
      },
      "readme": "<h1><img src=\"https://img.fortawesome.com/349cfdf6/fa-free-logo.svg\" alt=\"Font Awesome Free\" width=\"50%\"></h1>\n\n> Version 7\n\nFont Awesome is the Internet's icon library and toolkit, used by millions of\ndesigners, developers, and content creators.\n\n## Documentation\n\nLearn how to get started with Font Awesome and then dive deeper into other and advanced topics:\n\n[Docs for version 7](https://fontawesome.com/docs)\n\n### Where did Font Awesome 6, 5, 4 (or 3) go?\n\nNow that Font Awesome 7 has been released we are marking version 6 as Long Term\nSupport (LTS). Version 6 will get critical bug fixes only. Version 3, 4, and 5 are\nnow end-of-life and we don't plan on releasing any further versions of these.\n\nYou can see a complete list of versions on [our Versions\npage](https://fontawesome.com/versions).\n\n## Change log\n\nThe change log for releases is now [available directly on our site](https://fontawesome.com/docs/changelog/).\n\nLooking for older versions of Font Awesome? Check the [releases](https://github.com/FortAwesome/Font-Awesome/releases).\n\n## Upgrading\n\nFrom time-to-time we'll have special upgrading instructions from one version to the next.\n\n- [Web upgrading guide](https://docs.fontawesome.com/upgrade/upgrade-on-web)\n- [Desktop upgrading guide](https://docs.fontawesome.com/upgrade/upgrade-on-desktop)\n\n## Code of conduct\n\nWe will behave ourselves if you behave yourselves. For more details see our\n[CODE_OF_CONDUCT.md](./CODE_OF_CONDUCT.md).\n\n## Contributing\n\nPlease read through our [contributing guidelines](./CONTRIBUTING.md).  Included\nare directions for opening issues.\n\n## Versioning\n\nFont Awesome will be maintained under the Semantic Versioning guidelines as much as possible. Releases will be numbered\nwith the following format:\n\n`<major>.<minor>.<patch>`\n\nFor more information on SemVer, please visit https://semver.org.\n\n**The major version \"7\" is part of an umbrella release.  It includes many different types of files and technologies. Therefore\nwe deviate from normal SemVer in the following ways:**\n\n* Any release may update the design, look-and-feel, or branding of an existing\n  icon\n* We will never intentionally release a `patch` version update that breaks\n  backward compatibility\n* A `minor` release **may include backward-incompatible changes** but we will\n  write clear upgrading instructions in UPGRADING.md\n* A `minor` or `patch` release will never remove icons\n* Bug fixes will be addressed as `patch` releases unless they include backward\n  incompatibility then they will be `minor` releases\n\n## License\n\nFont Awesome Free is free, open source, and GPL friendly. You can use it for\ncommercial projects, open source projects, or really almost whatever you want.\n\n- Icons â€” CC BY 4.0 License\n  - In the Font Awesome Free download, the CC BY 4.0 license applies to all icons packaged as .svg and .js files types.\n- Fonts â€” SIL OFL 1.1 License\n  - In the Font Awesome Free download, the SIL OFL license applies to all icons packaged as web and desktop font files.\n- Code â€” MIT License\n  - In the Font Awesome Free download, the MIT license applies to all non-font and non-icon files.\n\nAttribution is required by MIT, SIL OFL, and CC BY licenses. Downloaded Font\nAwesome Free files already contain embedded comments with sufficient\nattribution, so you shouldn't need to do anything additional when using these\nfiles normally.\n\nWe've kept attribution comments terse, so we ask that you do not actively work\nto remove them from files, especially code. They're a great way for folks to\nlearn about Font Awesome.\n\n## Team\n\nhttps://github.com/orgs/FortAwesome/people\n",
      "stars_today": 6
    },
    {
      "id": 37912398,
      "name": "nginx",
      "full_name": "nginx/nginx",
      "description": "The official NGINX Open Source repository.",
      "html_url": "https://github.com/nginx/nginx",
      "stars": 29278,
      "forks": 7754,
      "language": "C",
      "topics": [
        "content-cache",
        "http",
        "http2",
        "http3",
        "https",
        "load-balancer",
        "mail-proxy-server",
        "nginx",
        "quic",
        "reverse-proxy",
        "security",
        "tcp-proxy-server",
        "tls",
        "udp-proxy-server",
        "web-server"
      ],
      "created_at": "2015-06-23T10:26:27Z",
      "updated_at": "2026-02-06T20:28:11Z",
      "pushed_at": "2026-02-04T17:28:36Z",
      "open_issues": 330,
      "owner": {
        "login": "nginx",
        "avatar_url": "https://avatars.githubusercontent.com/u/1412239?v=4"
      },
      "readme": "<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/user-attachments/assets/9335b488-ffcc-4157-8364-2370a0b70ad0\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"https://github.com/user-attachments/assets/3a7eeb08-1133-47f5-859c-fad4f5a6a013\">\n  <img alt=\"NGINX Banner\">\n</picture>\n\n[![Project Status: Active â€“ The project has reached a stable, usable state and is being actively developed.](https://www.repostatus.org/badges/latest/active.svg)](https://www.repostatus.org/#active)\n[![Community Forum](https://img.shields.io/badge/community-forum-009639?logo=discourse&link=https%3A%2F%2Fcommunity.nginx.org)](https://community.nginx.org)\n[![License](https://img.shields.io/badge/License-BSD%202--Clause-blue.svg)](/LICENSE)\n[![Code of Conduct](https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg)](/CODE_OF_CONDUCT.md)\n\nNGINX (pronounced \"engine x\" or \"en-jin-eks\") is the world's most popular Web Server, high performance Load Balancer, Reverse Proxy, API Gateway and Content Cache.\n\nNGINX is free and open source software, distributed under the terms of a simplified [2-clause BSD-like license](LICENSE).\n\nEnterprise distributions, commercial support and training are available from [F5, Inc](https://www.f5.com/products/nginx).\n\n> [!IMPORTANT]\n> The goal of this README is to provide a basic, structured introduction to NGINX for novice users. Please refer to the [full NGINX documentation](https://nginx.org/en/docs/) for detailed information on [installing](https://nginx.org/en/docs/install.html), [building](https://nginx.org/en/docs/configure.html), [configuring](https://nginx.org/en/docs/dirindex.html), [debugging](https://nginx.org/en/docs/debugging_log.html), and more. These documentation pages also contain a more detailed [Beginners Guide](https://nginx.org/en/docs/beginners_guide.html), How-Tos, [Development guide](https://nginx.org/en/docs/dev/development_guide.html), and a complete module and [directive reference](https://nginx.org/en/docs/dirindex.html).\n\n# Table of contents\n- [How it works](#how-it-works)\n  - [Modules](#modules)\n  - [Configurations](#configurations)\n  - [Runtime](#runtime)\n- [Downloading and installing](#downloading-and-installing)\n  - [Stable and Mainline binaries](#stable-and-mainline-binaries)\n  - [Linux binary installation process](#linux-binary-installation-process)\n  - [FreeBSD installation process](#freebsd-installation-process)\n  - [Windows executables](#windows-executables)\n  - [Dynamic modules](#dynamic-modules)\n- [Getting started with NGINX](#getting-started-with-nginx)\n  - [Installing SSL certificates and enabling TLS encryption](#installing-ssl-certificates-and-enabling-tls-encryption)\n  - [Load Balancing](#load-balancing)\n  - [Rate limiting](#rate-limiting)\n  - [Content caching](#content-caching)\n- [Building from source](#building-from-source)\n  - [Installing dependencies](#installing-dependencies)\n  - [Cloning the NGINX GitHub repository](#cloning-the-nginx-github-repository)\n  - [Configuring the build](#configuring-the-build)\n  - [Compiling](#compiling)\n  - [Location of binary and installation](#location-of-binary-and-installation)\n  - [Running and testing the installed binary](#running-and-testing-the-installed-binary)\n- [Asking questions and reporting issues](#asking-questions-and-reporting-issues)\n- [Contributing code](#contributing-code)\n- [Additional help and resources](#additional-help-and-resources)\n- [Changelog](#changelog)\n- [License](#license)\n\n# How it works\nNGINX is installed software with binary packages available for all major operating systems and Linux distributions. See [Tested OS and Platforms](https://nginx.org/en/#tested_os_and_platforms) for a full list of compatible systems.\n\n> [!IMPORTANT]\n> While nearly all popular Linux-based operating systems are distributed with a community version of nginx, we highly advise installation and usage of official [packages](https://nginx.org/en/linux_packages.html) or sources from this repository. Doing so ensures that you're using the most recent release or source code, including the latest feature-set, fixes and security patches.\n\n## Modules\nNGINX is comprised of individual modules, each extending core functionality by providing additional, configurable features. See \"Modules reference\" at the bottom of [nginx documentation](https://nginx.org/en/docs/) for a complete list of official modules.\n\nNGINX modules can be built and distributed as static or dynamic modules. Static modules are defined at build-time, compiled, and distributed in the resulting binaries. See [Dynamic Modules](#dynamic-modules) for more information on how they work, as well as, how to obtain, install, and configure them.\n\n> [!TIP]\n> You can issue the following command to see which static modules your NGINX binaries were built with:\n```bash\nnginx -V\n```\n> See [Configuring the build](#configuring-the-build) for information on how to include specific Static modules into your nginx build.\n\n## Configurations\nNGINX is highly flexible and configurable. Provisioning the software is achieved via text-based config file(s) accepting parameters called \"[Directives](https://nginx.org/en/docs/dirindex.html)\". See [Configuration File's Structure](https://nginx.org/en/docs/beginners_guide.html#conf_structure) for a comprehensive description of how NGINX configuration files work.\n\n> [!NOTE]\n> The set of directives available to your distribution of NGINX is dependent on which [modules](#modules) have been made available to it.\n\n## Runtime\nRather than running in a single, monolithic process, NGINX is architected to scale beyond Operating System process limitations by operating as a collection of processes. They include:\n- A \"master\" process that maintains worker processes, as well as, reads and evaluates configuration files.\n- One or more \"worker\" processes that process data (eg. HTTP requests).\n\nThe number of [worker processes](https://nginx.org/en/docs/ngx_core_module.html#worker_processes) is defined in the configuration file and may be fixed for a given configuration or automatically adjusted to the number of available CPU cores. In most cases, the latter option optimally balances load across available system resources, as NGINX is designed to efficiently distribute work across all worker processes.\n\n> [!TIP]\n> Processes synchronize data through shared memory. For this reason, many NGINX directives require the allocation of shared memory zones. As an example, when configuring [rate limiting](https://nginx.org/en/docs/http/ngx_http_limit_req_module.html#limit_req), connecting clients may need to be tracked in a [common memory zone](https://nginx.org/en/docs/http/ngx_http_limit_req_module.html#limit_req_zone) so all worker processes can know how many times a particular client has accessed the server in a span of time.\n\n# Downloading and installing\nFollow these steps to download and install precompiled NGINX binaries. You may also choose to [build NGINX locally from source code](#building-from-source).\n\n## Stable and Mainline binaries\nNGINX binaries are built and distributed in two versions: stable and mainline. Stable binaries are built from stable branches and only contain critical fixes backported from the mainline version. Mainline binaries are built from the [master branch](https://github.com/nginx/nginx/tree/master) and contain the latest features and bugfixes. You'll need to [decide which is appropriate for your purposes](https://docs.nginx.com/nginx/admin-guide/installing-nginx/installing-nginx-open-source/#choosing-between-a-stable-or-a-mainline-version).\n\n## Linux binary installation process\nThe NGINX binary installation process takes advantage of package managers native to specific Linux distributions. For this reason, first-time installations involve adding the official NGINX package repository to your system's package manager. Follow [these steps](https://nginx.org/en/linux_packages.html) to download, verify, and install NGINX binaries using the package manager appropriate for your Linux distribution.\n\n### Upgrades\nFuture upgrades to the latest version can be managed using the same package manager without the need to manually download and verify binaries.\n\n## FreeBSD installation process\nFor more information on installing NGINX on FreeBSD system, visit https://nginx.org/en/docs/install.html\n\n## Windows executables\nWindows executables for mainline and stable releases can be found on the main [NGINX download page](https://nginx.org/en/download.html). Note that the current implementation of NGINX for Windows is at the Proof-of-Concept stage and should only be used for development and testing purposes. For additional information, please see [nginx for Windows](https://nginx.org/en/docs/windows.html).\n\n## Dynamic modules\nNGINX version 1.9.11 added support for [Dynamic Modules](https://nginx.org/en/docs/ngx_core_module.html#load_module). Unlike Static modules, dynamically built modules can be downloaded, installed, and configured after the core NGINX binaries have been built. [Official dynamic module binaries](https://nginx.org/en/linux_packages.html#dynmodules) are available from the same package repository as the core NGINX binaries described in previous steps.\n\n> [!TIP]\n> [NGINX JavaScript (njs)](https://github.com/nginx/njs), is a popular NGINX dynamic module that enables the extension of core NGINX functionality using familiar JavaScript syntax.\n\n> [!IMPORTANT]\n> If desired, dynamic modules can also be built statically into NGINX at compile time.\n\n# Getting started with NGINX\nFor a gentle introduction to NGINX basics, please see our [Beginnerâ€™s Guide](https://nginx.org/en/docs/beginners_guide.html).\n\n## Installing SSL certificates and enabling TLS encryption\nSee [Configuring HTTPS servers](https://nginx.org/en/docs/http/configuring_https_servers.html) for a quick guide on how to enable secure traffic to your NGINX installation.\n\n## Load Balancing\nFor a quick start guide on configuring NGINX as a Load Balancer, please see [Using nginx as HTTP load balancer](https://nginx.org/en/docs/http/load_balancing.html).\n\n## Rate limiting\nSee our [Rate Limiting with NGINX](https://blog.nginx.org/blog/rate-limiting-nginx) blog post for an overview of core concepts for provisioning NGINX as an API Gateway.\n\n## Content caching\nSee [A Guide to Caching with NGINX and NGINX Plus](https://blog.nginx.org/blog/nginx-caching-guide) blog post for an overview of how to use NGINX as a content cache (e.g. edge server of a content delivery network).\n\n# Building from source\nThe following steps can be used to build NGINX from source code available in this repository.\n\n## Installing dependencies\nMost Linux distributions will require several dependencies to be installed in order to build NGINX. The following instructions are specific to the `apt` package manager, widely available on most Ubuntu/Debian distributions and their derivatives.\n\n> [!TIP]\n> It is always a good idea to update your package repository lists prior to installing new packages.\n> ```bash\n> sudo apt update\n> ```\n\n### Installing compiler and make utility\nUse the following command to install the GNU C compiler and Make utility.\n\n```bash\nsudo apt install gcc make\n```\n\n### Installing dependency libraries\n\n```bash\nsudo apt install libpcre3-dev zlib1g-dev\n```\n\n> [!WARNING]\n> This is the minimal set of dependency libraries needed to build NGINX with rewriting and gzip capabilities. Other dependencies may be required if you choose to build NGINX with additional modules. Monitor the output of the `configure` command discussed in the following sections for information on which modules may be missing. For example, if you plan to use SSL certificates to encrypt traffic with TLS, you'll need to install the OpenSSL library. To do so, issue the following command.\n\n>```bash\n>sudo apt install libssl-dev\n\n## Cloning the NGINX GitHub repository\nUsing your preferred method, clone the NGINX repository into your development directory. See [Cloning a GitHub Repository](https://docs.github.com/en/repositories/creating-and-managing-repositories/cloning-a-repository) for additional help.\n\n```bash\ngit clone https://github.com/nginx/nginx.git\n```\n\n## Configuring the build\nPrior to building NGINX, you must run the `configure` script with [appropriate flags](https://nginx.org/en/docs/configure.html). This will generate a Makefile in your NGINX source root directory that can then be used to compile NGINX with [options specified during configuration](https://nginx.org/en/docs/configure.html).\n\nFrom the NGINX source code repository's root directory:\n\n```bash\nauto/configure\n```\n\n> [!IMPORTANT]\n> Configuring the build without any flags will compile NGINX with the default set of options. Please refer to https://nginx.org/en/docs/configure.html for a full list of available build configuration options.\n\n## Compiling\nThe `configure` script will generate a `Makefile` in the NGINX source root directory upon successful execution. To compile NGINX into a binary, issue the following command from that same directory:\n\n```bash\nmake\n```\n\n## Location of binary and installation\nAfter successful compilation, a binary will be generated at `<NGINX_SRC_ROOT_DIR>/objs/nginx`. To install this binary, issue the following command from the source root directory:\n\n```bash\nsudo make install\n```\n\n> [!IMPORTANT]\n> The binary will be installed into the `/usr/local/nginx/` directory.\n\n## Running and testing the installed binary\nTo run the installed binary, issue the following command:\n\n```bash\nsudo /usr/local/nginx/sbin/nginx\n```\n\nYou may test NGINX operation using `curl`.\n\n```bash\ncurl localhost\n```\n\nThe output of which should start with:\n\n```html\n<!DOCTYPE html>\n<html>\n<head>\n<title>Welcome to nginx!</title>\n```\n\n# Asking questions and reporting issues\nSee our [Support](SUPPORT.md) guidelines for information on how discuss the codebase, ask troubleshooting questions, and report issues.\n\n# Contributing code\nPlease see the [Contributing](CONTRIBUTING.md) guide for information on how to contribute code.\n\n# Additional help and resources\n- See the [NGINX Community Blog](https://blog.nginx.org/) for more tips, tricks and HOW-TOs related to NGINX and related projects.\n- Access [nginx.org](https://nginx.org/), your go-to source for all documentation, information and software related to the NGINX suite of projects.\n\n# Changelog\nSee our [changelog](https://nginx.org/en/CHANGES) to keep track of updates.\n\n# License\n[2-clause BSD-like license](LICENSE)\n\n---\nAdditional documentation available at: https://nginx.org/en/docs\n",
      "stars_today": 6
    },
    {
      "id": 4869294,
      "name": "radare2",
      "full_name": "radareorg/radare2",
      "description": "UNIX-like reverse engineering framework and command-line toolset",
      "html_url": "https://github.com/radareorg/radare2",
      "stars": 23040,
      "forks": 3166,
      "language": "C",
      "topics": [
        "binary-analysis",
        "c",
        "commandline",
        "disassembler",
        "forensics",
        "hacktoberfest",
        "malware-analysis",
        "radare2",
        "reverse-engineering",
        "security"
      ],
      "created_at": "2012-07-03T07:42:26Z",
      "updated_at": "2026-02-06T20:25:33Z",
      "pushed_at": "2026-02-06T18:55:58Z",
      "open_issues": 837,
      "owner": {
        "login": "radareorg",
        "avatar_url": "https://avatars.githubusercontent.com/u/2842539?v=4"
      },
      "readme": "<a href=\"https://radare.org/\"><img border=0 src=\"doc/images/r2emoji.png\" alt=\"screenshot\" align=\"left\" width=\"128px\"></a>\n\n## Radare2: Libre Reversing Framework for Unix Geeks\n\n[![Latest packaged version](https://repology.org/badge/latest-versions/radare2.svg)](https://repology.org/project/radare2/versions) [![Tests Status](https://github.com/radareorg/radare2/actions/workflows/ci.yml/badge.svg?branch=master)](https://github.com/radareorg/radare2/actions/workflows/ci.yml?query=branch%3Amaster) [![build](https://github.com/radareorg/radare2/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/radareorg/radare2/actions/workflows/build.yml?query=branch%3Amaster) [![tcc](https://github.com/radareorg/radare2/actions/workflows/tcc.yml/badge.svg?branch=master)](https://github.com/radareorg/radare2/actions/workflows/tcc.yml)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/741/badge)](https://bestpractices.coreinfrastructure.org/projects/741) [![Build Status](https://scan.coverity.com/projects/416/badge.svg)](https://scan.coverity.com/projects/416) [![Discord](https://badgen.net/discord/members/YBey7CR9jf)](https://discord.gg/YBey7CR9jf)\n\nCurrent git `master` branch is `6.0.9`, next release will be `6.1.0`.\n\n### Description\n\nr2 is a complete rewrite of radare. It provides a set of libraries, tools and\nplugins to ease reverse engineering tasks. Distributed under LGPLv3, despite\neach plugin can have different licenses (see `r2 -Lj` for details)\n\nThe **radare** project started as a simple command-line hexadecimal editor\nfocused on forensics. Today, r2 is a full-featured low-level command-line tool\nwith support for scripting with the embedded Javascript interpreter or via r2pipe.\n\nr2 can edit files on local hard drives, view kernel memory, and debug programs\nlocally or via a remote gdb/windbg servers. r2's wide architecture support allows\nyou to analyze, emulate, debug, modify, and disassemble any binary.\n\n<p align=\"center\">\n<a href=\"https://www.radare.org/\"><img src=\"doc/images/shot.png\" alt=\"screenshot\" align=\"center\" border=0 width=\"600px\"></a>\n</p>\n\n## Installation\n\nDownload the last [released](https://github.com/radareorg/radare2/releases) binaries.\n\nThe recommended way to install radare2 is from Git repository source:\n\n```sh\ngit clone https://github.com/radareorg/radare2\nradare2/sys/install.sh\n```\n\n* Run `sys/install.sh` for the default acr+make+symlink installation\n* meson/ninja (muon/samu also works) and make builds are supported.\n\n### Source Build\n\n* r2 can be installed from `git` or via `pip` using `r2env`.\n* Windows builds require meson and msvc or mingw as compilers\n* To uninstall the current build of r2 run `make uninstall`\n* To uninstall ALL the system installations of r2 do: `sudo make purge`\n\nOn Windows use the .bat scripts and msvc:\n\n```bat\npreconfigure.bat       REM setup python, meson, ninja\nconfigure.bat          REM run meson b + vs project\nmake.bat               REM run ninja -C b\nprefix\\bin\\radare2.exe\n```\n\n## Popular Plugins:\n\nUsing the `r2pm` tool you can browse and install many plugins and tools that use radare2.\n\n* [iaito](https://github.com/radareorg/iaito): The official Qt graphical interface\n* [keystone](https://github.com/radareorg/radare2-extras/tree/master/keystone) Assembler instructions using the Keystone library\n* [decai](https://github.com/radareorg/r2ai) Decompiler based on AI\n* [r2ai](https://github.com/radareorg/r2ai) Run a Language Model in localhost with Llama inside r2!\n* [r2dec](https://github.com/wargio/r2dec-js): A decompiler based on r2 written in JS, accessed with the `pdd` command\n* [r2diaphora](https://github.com/FernandoDoming/r2diaphora): [Diaphora](https://github.com/joxeankoret/diaphora)'s binary diffing engine on top of radare2\n* [r2frida](https://github.com/nowsecure/r2frida): The frida io plugin. Start r2 with `r2 frida://0` to use it\n* [r2ghidra](https://github.com/radareorg/r2ghidra): The standalone native ghidra decompiler accessible with `pdg`\n* [r4ghidra](https://github.com/radareorg/r4ghidra): Feel the radare joy inside your Ghidra\n* [r2papi](https://github.com/radareorg/radare2-r2papi) High level api on top of r2pipe\n* [r2pipe](https://github.com/radareorg/radare2-r2pipe) Script radare2 from any programming language\n* [r2poke](https://github.com/radareorg/radare2-extras/tree/master/r2poke) Integration with GNU/Poke for extended binary parsing capabilities\n* [goresym](https://github.com/hanemile/radare2-GoReSym): Import GoReSym symbol as flags\n* [r2yara](https://github.com/radareorg/r2yara) Run Yara from r2 or use r2 primitives from Yara\n* [radius2](https://github.com/radareorg/radius2): A fast symbolic execution engine based on boolector and esil\n* [r2sarif](https://github.com/radareorg/r2sarif) import/extend/export SARIF documents\n\n## Usage\n\nThese are the first steps to use r2, read the book or find tutorials for more details\n\n```sh\n$ r2 /bin/ls   # open file in read-only\n> aaa          # analyse the program (r2 -A)\n> afl          # list all functions (try aflt, aflm)\n> px 32        # print 32 byte hexdump current block\n> s sym.main   # seek to main (using flag name)\n> f~foo        # filter flags matching 'foo' (internal |grep)\n> iS;is        # list sections and symbols (rabin2 -Ss)\n> pdf; agf     # disassembly and ascii-art function graph\n> oo+;w hello  # reopen in read-write and write a string\n> ?*~...       # interactive filter in all command help\n> q            # quit\n```\n\nMany plugins are included in r2 by default. But you can extend its capabilities\nby using the [r2pm](https://github.com/radareorg/radare2-pm) package manager.\n\n```sh\nr2pm -s <word>  # search packages matching a word\nr2pm -Uci <pkg> # update database and clean install a package\nr2pm -u <pkg>   # uninstall the given package\nr2pm -l <pkg>   # list installed packages\n```\n\n## Resources\n\n* [Official Book](https://book.rada.re): Read about r2 usage\n* [COMMUNITY.md](COMMUNITY.md): Community engagement and loose guidelines\n* [CONTRIBUTING.md](CONTRIBUTING.md): Information about reporting issues and\n  contributing. See also [Contributing](#contributing)\n* [DEVELOPERS.md](DEVELOPERS.md): Development guidelines for r2\n* [SECURITY.md](SECURITY.md): Instructions for reporting vulnerabilities\n* [USAGE.md](USAGE.md): Some example commands\n* [INSTALL.md](INSTALL.md): Installation instructions using make or meson\n\n## Documentation\n\nLearn more about r2 watching [youtube talks](https://www.youtube.com/c/r2con) from [r2con](https://rada.re/con). There are also many blogposts, slidedecks and the [official radare2 book](https://book.rada.re), but it's always a good idea to join any of the official chats and drop your questions or feedback there.\n\n## Community\n\n* Website: [https://www.radare.org/](https://www.radare.org/)\n* Discord: [Server](https://discord.gg/YBey7CR9jf)\n* Mastodon: [@radareorg](https://infosec.exchange/@radareorg)\n* Telegram: [Main](https://t.me/radare) and [Side](https://t.me/radare_side) channels\n* [irc.libera.chat](https://libera.chat): `#radare`, `#radare_side`\n* [Matrix](https://matrix.to/#/#radare:matrix.org): `#radare:matrix.org`\n\n# Supported Platforms\n\n## Operating Systems\n\nWindows (since XP for x86/x64/arm64), Linux, Darwin, GNU/Hurd, Apple's {Mac,i,iPad,watch}OS,\nAndroid, Wasmer, [Dragonfly, Net, Free, Open] BSD, Z/OS, QNX, SerenityOS, Solaris, AIX,\nHaiku, Vinix, FirefoxOS.\n\n## Architectures\n\ni386, x86-64, Alpha, ARM, AVR, BPF, sBPF, MIPS, PowerPC, SPARC, RISC-V, SH, m68k,\nS390, XCore, CR16, HPPA, ARC, Blackfin, Z80, H8/300, V810, PDP11, m680x, V850,\nCRIS, XAP (CSR), PIC, LM32, 8051, 6502, i4004, i8080, Propeller, EVM, OR1K\nTricore, CHIP-8, LH5801, T8200, GameBoy, SNES, SPC700, MSP430, Xtensa, xcore,\nNIOS II, Java, Dalvik, Pickle, WebAssembly, MSIL, EBC, TMS320 (c54x, c55x,\nc55+, c64x), Hexagon, Brainfuck, Malbolge, whitespace, DCPU16, LANAI, lm32,\nMSIL, InfernoDis, UXN, Cosmac, PythonBytecode, Sharp sm5xx MCPus, FreeScale QIQa,\nMCORE, mcs96, RSP, SuperH-4, VAX, KVX, Am29000, LOONGARCH, JDH8, s390x, STM8.\n\n## File Formats\n\nELF, Mach-O, Fatmach-O, PE, PE+, MZ, COFF, XCOFF, OMF, TE, XBE, SEP64, BIOS/UEFI, BFLT, Pebble apps,\nApple Dyldcache, Kernelcache, MCLF trustlets, DEX, ART, Java class, Android boot image, Plan9 executables, Amiga HUNK,\nZIMG, MBN/SBL bootloader, ELF coredump, MDMP (Windows minidump), PDP11, XTAC, CGC, DotNet,\nWASM (WebAssembly binary), Commodore VICE emulator, DOL, QNX, WAD, OFF, TIC-80,\nGB/GBA, PSX, PRG (C64), Apple Classic PEF, NDS, z64, and N3DS\n...\n\n## FileSystems\n\nMount in userland several filesystems like NTFS, FAT, HFS+, EXT, APFS, BeosFS, BFS, MINIX, ReiserFS, SFS, ubifs, ufs, jfs, ISO9660, UDF, xfs\n\n## Packaging Status\n\n* [![Snap package](https://snapcraft.io/radare2/badge.svg)](https://snapcraft.io/radare2)\n* [![Termux package](https://repology.org/badge/version-for-repo/termux/radare2.svg)](https://repology.org/project/radare2/versions)\n* [![Alpine Linux 3.23 package](https://repology.org/badge/version-for-repo/alpine_3_23/radare2.svg)](https://repology.org/project/radare2/versions)  [![Alpine Linux 3.22 package](https://repology.org/badge/version-for-repo/alpine_3_22/radare2.svg)](https://repology.org/project/radare2/versions) \n* [![Arch package](https://repology.org/badge/version-for-repo/arch/radare2.svg)](https://repology.org/project/radare2/versions)\n* [![Fedora 42](https://repology.org/badge/version-for-repo/fedora_42/radare2.svg)](https://repology.org/project/radare2/versions) [![Fedora 41](https://repology.org/badge/version-for-repo/fedora_41/radare2.svg)](https://repology.org/project/radare2/versions)\n* [![Homebrew package](https://repology.org/badge/version-for-repo/homebrew/radare2.svg)](https://repology.org/project/radare2/versions) [![MacPorts package](https://repology.org/badge/version-for-repo/macports/radare2.svg)](https://repology.org/project/radare2/versions)\n* [![Haiku Ports](https://repology.org/badge/version-for-repo/haikuports_master/radare2.svg)](https://repology.org/project/radare2/versions) [![Void Linux](https://repology.org/badge/version-for-repo/void_x86_64/radare2.svg)](https://repology.org/project/radare2/versions)\n",
      "stars_today": 6
    },
    {
      "id": 1326671,
      "name": "thunderbird-android",
      "full_name": "thunderbird/thunderbird-android",
      "description": "Thunderbird for Android â€“ Open Source Email App for Android (fka K-9 Mail)",
      "html_url": "https://github.com/thunderbird/thunderbird-android",
      "stars": 13097,
      "forks": 2694,
      "language": "Kotlin",
      "topics": [
        "android",
        "communication",
        "email",
        "mozilla"
      ],
      "created_at": "2011-02-04T02:40:00Z",
      "updated_at": "2026-02-06T21:41:41Z",
      "pushed_at": "2026-02-06T21:45:14Z",
      "open_issues": 928,
      "owner": {
        "login": "thunderbird",
        "avatar_url": "https://avatars.githubusercontent.com/u/15187237?v=4"
      },
      "readme": "# Thunderbird for Android\n\n<a href=\"https://play.google.com/store/apps/details?id=net.thunderbird.android&referrer=utm_campaign%3Dandroid_metadata%26utm_medium%3Dweb%26utm_source%3Dgithub.com%26utm_content%3Dbadge\" target=\"_blank\"><img src=\"./docs/assets/get-it-on-play.png\" alt=\"Get it on Google Play\" height=\"28\"></a>\n<a href=\"https://f-droid.org/packages/net.thunderbird.android\"><img src=\"./docs/assets/get-it-on-fdroid.png\" alt=\"Get it on F-Droid\" height=\"28\"></a>\n<a href=\"https://apps.obtainium.imranr.dev/\"><img src=\"./docs/assets/get-it-on-obtainium.png\" alt=\"Get it on Obtainium\" height=\"28\"></a>\n[![Latest release](https://img.shields.io/github/release/thunderbird/thunderbird-android.svg?style=for-the-badge&filter=THUNDERBIRD_*&logo=thunderbird)](https://github.com/thunderbird/thunderbird-android/releases/latest)\n[![Latest beta release](https://img.shields.io/github/release/thunderbird/thunderbird-android.svg?include_prereleases&style=for-the-badge&label=beta&filter=THUNDERBIRD_*b*&logo=thunderbird)](https://github.com/thunderbird/thunderbird-android/releases)\n\nThunderbird for Android is a powerful, privacy-focused email app. Effortlessly manage multiple email accounts from one app, with a Unified Inbox option for maximum productivity. Built on open-source technology and supported by a dedicated team of developers alongside a global community of volunteers, Thunderbird never treats your private data as a product.\n\nThunderbird for Android is based on K-9 Mail, which comes with a rich history of success and functionality in open source email.\n\n## Download\n\nThunderbird for Android can be downloaded from a couple of sources:\n\n- Thunderbird on [Google Play](https://play.google.com/store/apps/details?id=net.thunderbird.android&referrer=utm_campaign%3Dandroid_metadata%26utm_medium%3Dweb%26utm_source%3Dgithub.com%26utm_content%3Dlink) or [F-Droid](https://f-droid.org/packages/net.thunderbird.android)\n- Thunderbird Beta on [Google Play](https://play.google.com/store/apps/details?id=net.thunderbird.android.beta&referrer=utm_campaign%3Dandroid_metadata%26utm_medium%3Dweb%26utm_source%3Dgithub.com%26utm_content%3Dlink) or [F-Droid](https://f-droid.org/packages/net.thunderbird.android.beta)\n- [Github Releases](https://github.com/thunderbird/thunderbird-android/releases)\n- [FFUpdater](https://f-droid.org/packages/de.marmaro.krt.ffupdater/) allows installing the latest versions from ftp.mozilla.org\n- [Obtainium](https://obtainium.imranr.dev/): Use \"Filter release title by regular expression\" under \"Additional options\" with `Thunderbird`. More info in [Complex Obtainium Apps list](https://apps.obtainium.imranr.dev/).\n\nBy using Thunderbird for Android Beta, you have early access to current development and are able to try new features earlier.\n\nCheck out the [Release Notes](https://github.com/thunderbird/thunderbird-android/releases) to find out what changed in each version of Thunderbird for Android.\n\nThe SHA-256 fingerprints for our signing certificates are available in [SECURITY.md](./SECURITY.md#verifying-fingerprints).\n\n## Need Help? Found a bug? Have an idea? Want to chat?\n\nIf the app is not behaving like it should, or you are not sure if you've encountered a bug:\n\n- Check out our [knowledge base](https://support.mozilla.org/products/thunderbird-android) and [frequently asked questions](https://support.mozilla.org/kb/thunderbird-android-8-faq)\n- Ask a question on our [support forum](https://support.mozilla.org/en-US/questions/new/thunderbird-android)\n\nIf you are certain you've identified a bug in Thunderbird for Android and would like to help fix it:\n\n- File an issue on [our GitHub issue tracker](https://github.com/thunderbird/thunderbird-android/issues)\n\nIf you have an idea how to improve Thunderbird for Android:\n\n- Tell us about and vote on your feature ideas on [connect.mozilla.org](https://connect.mozilla.org/t5/ideas/idb-p/ideas/label-name/thunderbird%20android).\n- Join the discussion about the latest changes in the [Thunderbird Android Beta Topicbox](https://thunderbird.topicbox.com/groups/android-beta).\n\nThe Thunderbird Community uses Matrix to communicate:\n\n- General chat about Thunderbird for Android and K-9 Mail: [#tb-android:mozilla.org](https://matrix.to/#/#tb-android:mozilla.org)\n- Development and other ways to contribute: [#tb-android-dev:mozilla.org](https://matrix.to/#/#tb-android-dev:mozilla.org)\n- Reach the broader Thunderbird Community in the [community space](https://matrix.to/#/#thunderbird-community:mozilla.org)\n\n## Roadmap\n\nTo learn more about all the wonderful things planned for this year please see our\n[roadmap](https://github.com/orgs/thunderbird/projects/19/views/1). The core team's day to day activities are additionally\ntracked in our [sprint board](https://github.com/orgs/thunderbird/projects/20/views/1).\n\n## Contributing\n\nWe welcome contributions from everyone.\n\n- Development: Have you done a little bit of Kotlin? The [CONTRIBUTING](docs/CONTRIBUTING.md) guide will help you get started\n- Translations: Do you speak a language aside from English? [Translating is easy](https://hosted.weblate.org/projects/tb-android/) and just takes a few minutes for your first success.\n- We have [a number of other contribution opportunities](https://blog.thunderbird.net/2024/09/contribute-to-thunderbird-for-android/) available.\n- Thunderbird is supported solely by financial contributions from users like you. [Make a financial contribution today](https://www.thunderbird.net/donate/mobile/?form=tfa)!\n- Make sure to check out the [Mozilla Community Participation Guidelines](https://www.mozilla.org/about/governance/policies/participation/).\n\n### Architecture Decision Records (ADR)\n\nWe use [Architecture Decision Records](https://adr.github.io/) to document the architectural decisions made in the\ndevelopment of Thunderbird for Android. You can find them in the [`docs/architecture/adr`](docs/architecture/adr) directory.\n\nFor more information about our ADRs, please see the [ADRs README](docs/architecture/adr/README.md).\n\nWe encourage team members and contributors to read through our ADRs to understand the architectural decisions that\nhave shaped this project so far. Feel free to propose new ADRs or suggest modifications to existing ones as needed.\n\n## K-9 Mail\n\nIn June 2022, [K-9 Mail joined the Thunderbird family](https://k9mail.app/2022/06/13/K-9-Mail-and-Thunderbird.html)\nas the foundation for Thunderbird on Android. Since then, weâ€™ve been updating both apps to give\nusers the same solid experience, so itâ€™s normal to notice that K-9 Mail and Thunderbird look and\nfeel nearly identical. Theyâ€™re built on the same code, and thatâ€™s intentional. You'll notice some\nfeatures are selectively enabled for Thunderbird as opposed to K-9 Mail, usually when they are\nsimply a better fit for Thunderbird (like the import from K-9 functionality).\n\nIf you prefer the robot dog and would like to keep K-9 Mail around, you can find it here:\n\n- [K-9 Mail on Google Play](https://play.google.com/store/apps/details?id=com.fsck.k9&utm_source=thunderbird-android-github&utm_campaign=download-section)\n- [K-9 Mail on F-Droid](https://f-droid.org/packages/com.fsck.k9/)\n- [K-9 Mail on Obtainium](https://obtainium.imranr.dev/) (use `K-9 Mail` as filter, see [notes](#download) above)\n\n## Forking\n\nIf you want to use a fork of this project please ensure that you replace the OAuth client setup in the `app-k9mail/src/{debug,release}/kotlin/app/k9mail/auth/K9OAuthConfigurationFactory.kt` and `app-thunderbird/src/{debug,daily,beta,release}/kotlin/net/thunderbird/android/auth/TbOAuthConfigurationFactory.kt` with your own OAuth client setup and ensure that the `redirectUri` is different to the one used in the main project. This is to prevent conflicts with the main app when both are installed on the same device.\n\n## License\n\nThunderbird for Android is licensed under the [Apache License, Version 2.0](LICENSE).\n",
      "stars_today": 6
    },
    {
      "id": 261039251,
      "name": "swift-composable-architecture",
      "full_name": "pointfreeco/swift-composable-architecture",
      "description": "A library for building applications in a consistent and understandable way, with composition, testing, and ergonomics in mind.",
      "html_url": "https://github.com/pointfreeco/swift-composable-architecture",
      "stars": 14313,
      "forks": 1629,
      "language": "Swift",
      "topics": [
        "architecture",
        "composition",
        "modularity",
        "swiftui",
        "testability",
        "uikit"
      ],
      "created_at": "2020-05-03T23:18:40Z",
      "updated_at": "2026-02-06T13:59:49Z",
      "pushed_at": "2025-12-30T21:38:44Z",
      "open_issues": 24,
      "owner": {
        "login": "pointfreeco",
        "avatar_url": "https://avatars.githubusercontent.com/u/29466629?v=4"
      },
      "readme": "# The Composable Architecture\n\n[![CI](https://github.com/pointfreeco/swift-composable-architecture/actions/workflows/ci.yml/badge.svg)](https://github.com/pointfreeco/swift-composable-architecture/actions/workflows/ci.yml)\n[![Slack](https://img.shields.io/badge/slack-chat-informational.svg?label=Slack&logo=slack)](https://www.pointfree.co/slack-invite)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-composable-architecture%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-composable-architecture%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture)\n\nThe Composable Architecture (TCA, for short) is a library for building applications in a consistent \nand understandable way, with composition, testing, and ergonomics in mind. It can be used in \nSwiftUI, UIKit, and more, and on any Apple platform (iOS, macOS, iPadOS, visionOS, tvOS, and watchOS).\n\n* [What is the Composable Architecture?](#what-is-the-composable-architecture)\n* [Learn more](#learn-more)\n* [Examples](#examples)\n* [Basic usage](#basic-usage)\n* [Documentation](#documentation)\n* [FAQ](#faq)\n* [Community](#community)\n* [Installation](#installation)\n* [Translations](#translations)\n\n## What is the Composable Architecture?\n\nThis library provides a few core tools that can be used to build applications of varying purpose and \ncomplexity. It provides compelling stories that you can follow to solve many problems you encounter \nday-to-day when building applications, such as:\n\n* **State management**\n  <br> How to manage the state of your application using simple value types, and share state across \n  many screens so that mutations in one screen can be immediately observed in another screen.\n\n* **Composition**\n  <br> How to break down large features into smaller components that can be extracted to their own, \n  isolated modules and be easily glued back together to form the feature.\n\n* **Side effects**\n  <br> How to let certain parts of the application talk to the outside world in the most testable \n  and understandable way possible.\n\n* **Testing**\n  <br> How to not only test a feature built in the architecture, but also write integration tests \n  for features that have been composed of many parts, and write end-to-end tests to understand how \n  side effects influence your application. This allows you to make strong guarantees that your \n  business logic is running in the way you expect.\n\n* **Ergonomics**\n  <br> How to accomplish all of the above in a simple API with as few concepts and moving parts as \n  possible.\n\n## Learn More\n\nThe Composable Architecture was designed over the course of many episodes on \n[Point-Free][pointfreeco], a video series exploring advanced programming topics in the Swift language, \nhosted by [Brandon Williams][mbrandonw] and [Stephen Celis][stephencelis].\n\nYou can watch all of the episodes [here][tca-episode-collection], as well as a dedicated, [multipart\ntour][tca-tour] of the architecture from scratch.\n\n<a href=\"https://www.pointfree.co/collections/tours/composable-architecture-1-0\">\n  <img alt=\"video poster image\" src=\"https://d3rccdn33rt8ze.cloudfront.net/episodes/0243.jpeg\" width=\"600\">\n</a>\n\n## Examples\n\n[![Screen shots of example applications](https://d3rccdn33rt8ze.cloudfront.net/composable-architecture/demos.png)](./Examples)\n\nThis repo comes with _lots_ of examples to demonstrate how to solve common and complex problems with \nthe Composable Architecture. Check out [this](./Examples) directory to see them all, including:\n\n* [Case Studies](./Examples/CaseStudies)\n  * Getting started\n  * Effects\n  * Navigation\n  * Higher-order reducers\n  * Reusable components\n* [Location manager](https://github.com/pointfreeco/composable-core-location/tree/main/Examples/LocationManager)\n* [Motion manager](https://github.com/pointfreeco/composable-core-motion/tree/main/Examples/MotionManager)\n* [Search](./Examples/Search)\n* [Speech Recognition](./Examples/SpeechRecognition)\n* [SyncUps app](./Examples/SyncUps)\n* [Tic-Tac-Toe](./Examples/TicTacToe)\n* [Todos](./Examples/Todos)\n* [Voice memos](./Examples/VoiceMemos)\n\nLooking for something more substantial? Check out the source code for [isowords][gh-isowords], an \niOS word search game built in SwiftUI and the Composable Architecture.\n\n## Basic Usage\n\n> [!Note] \n> For a step-by-step interactive tutorial, be sure to check out [Meet the Composable\n> Architecture][meet-tca].\n\nTo build a feature using the Composable Architecture you define some types and values that model \nyour domain:\n\n* **State**: A type that describes the data your feature needs to perform its logic and render its \nUI.\n* **Action**: A type that represents all of the actions that can happen in your feature, such as \nuser actions, notifications, event sources and more.\n* **Reducer**: A function that describes how to evolve the current state of the app to the next \nstate given an action. The reducer is also responsible for returning any effects that should be \nrun, such as API requests, which can be done by returning an `Effect` value.\n* **Store**: The runtime that actually drives your feature. You send all user actions to the store \nso that the store can run the reducer and effects, and you can observe state changes in the store \nso that you can update UI.\n\nThe benefits of doing this are that you will instantly unlock testability of your feature, and you \nwill be able to break large, complex features into smaller domains that can be glued together.\n\nAs a basic example, consider a UI that shows a number along with \"+\" and \"âˆ’\" buttons that increment \nand decrement the number. To make things interesting, suppose there is also a button that when \ntapped makes an API request to fetch a random fact about that number and displays it in the view.\n\nTo implement this feature we create a new type that will house the domain and behavior of the \nfeature, and it will be annotated with the `@Reducer` macro:\n\n```swift\nimport ComposableArchitecture\n\n@Reducer\nstruct Feature {\n}\n```\n\nIn here we need to define a type for the feature's state, which consists of an integer for the \ncurrent count, as well as an optional string that represents the fact being presented:\n\n```swift\n@Reducer\nstruct Feature {\n  @ObservableState\n  struct State: Equatable {\n    var count = 0\n    var numberFact: String?\n  }\n}\n```\n\n> [!Note] \n> We've applied the `@ObservableState` macro to `State` in order to take advantage of the\n> observation tools in the library.\n\nWe also need to define a type for the feature's actions. There are the obvious actions, such as \ntapping the decrement button, increment button, or fact button. But there are also some slightly \nnon-obvious ones, such as the action that occurs when we receive a response from the fact API \nrequest:\n\n```swift\n@Reducer\nstruct Feature {\n  @ObservableState\n  struct State: Equatable { /* ... */ }\n  enum Action {\n    case decrementButtonTapped\n    case incrementButtonTapped\n    case numberFactButtonTapped\n    case numberFactResponse(String)\n  }\n}\n```\n\nAnd then we implement the `body` property, which is responsible for composing the actual logic and \nbehavior for the feature. In it we can use the `Reduce` reducer to describe how to change the\ncurrent state to the next state, and what effects need to be executed. Some actions don't need to\nexecute effects, and they can return `.none` to represent that:\n\n```swift\n@Reducer\nstruct Feature {\n  @ObservableState\n  struct State: Equatable { /* ... */ }\n  enum Action { /* ... */ }\n\n  var body: some Reducer<State, Action> {\n    Reduce { state, action in\n      switch action {\n      case .decrementButtonTapped:\n        state.count -= 1\n        return .none\n\n      case .incrementButtonTapped:\n        state.count += 1\n        return .none\n\n      case .numberFactButtonTapped:\n        return .run { [count = state.count] send in\n          let (data, _) = try await URLSession.shared.data(\n            from: URL(string: \"http://numbersapi.com/\\(count)/trivia\")!\n          )\n          await send(\n            .numberFactResponse(String(decoding: data, as: UTF8.self))\n          )\n        }\n\n      case let .numberFactResponse(fact):\n        state.numberFact = fact\n        return .none\n      }\n    }\n  }\n}\n```\n\nAnd then finally we define the view that displays the feature. It holds onto a `StoreOf<Feature>` \nso that it can observe all changes to the state and re-render, and we can send all user actions to \nthe store so that state changes:\n\n```swift\nstruct FeatureView: View {\n  let store: StoreOf<Feature>\n\n  var body: some View {\n    Form {\n      Section {\n        Text(\"\\(store.count)\")\n        Button(\"Decrement\") { store.send(.decrementButtonTapped) }\n        Button(\"Increment\") { store.send(.incrementButtonTapped) }\n      }\n\n      Section {\n        Button(\"Number fact\") { store.send(.numberFactButtonTapped) }\n      }\n      \n      if let fact = store.numberFact {\n        Text(fact)\n      }\n    }\n  }\n}\n```\n\nIt is also straightforward to have a UIKit controller driven off of this store. You can observe\nstate changes in the store in `viewDidLoad`, and then populate the UI components with data from\nthe store. The code is a bit longer than the SwiftUI version, so we have collapsed it here:\n\n<details>\n  <summary>Click to expand!</summary>\n\n  ```swift\n  class FeatureViewController: UIViewController {\n    let store: StoreOf<Feature>\n\n    init(store: StoreOf<Feature>) {\n      self.store = store\n      super.init(nibName: nil, bundle: nil)\n    }\n\n    required init?(coder: NSCoder) {\n      fatalError(\"init(coder:) has not been implemented\")\n    }\n\n    override func viewDidLoad() {\n      super.viewDidLoad()\n\n      let countLabel = UILabel()\n      let decrementButton = UIButton()\n      let incrementButton = UIButton()\n      let factLabel = UILabel()\n      \n      // Omitted: Add subviews and set up constraints...\n      \n      observe { [weak self] in\n        guard let self \n        else { return }\n        \n        countLabel.text = \"\\(self.store.count)\"\n        factLabel.text = self.store.numberFact\n      }\n    }\n\n    @objc private func incrementButtonTapped() {\n      self.store.send(.incrementButtonTapped)\n    }\n    @objc private func decrementButtonTapped() {\n      self.store.send(.decrementButtonTapped)\n    }\n    @objc private func factButtonTapped() {\n      self.store.send(.numberFactButtonTapped)\n    }\n  }\n  ```\n</details>\n\nOnce we are ready to display this view, for example in the app's entry point, we can construct a \nstore. This can be done by specifying the initial state to start the application in, as well as \nthe reducer that will power the application:\n\n```swift\nimport ComposableArchitecture\n\n@main\nstruct MyApp: App {\n  var body: some Scene {\n    WindowGroup {\n      FeatureView(\n        store: Store(initialState: Feature.State()) {\n          Feature()\n        }\n      )\n    }\n  }\n}\n```\n\nAnd that is enough to get something on the screen to play around with. It's definitely a few more \nsteps than if you were to do this in a vanilla SwiftUI way, but there are a few benefits. It gives \nus a consistent manner to apply state mutations, instead of scattering logic in some observable \nobjects and in various action closures of UI components. It also gives us a concise way of \nexpressing side effects. And we can immediately test this logic, including the effects, without \ndoing much additional work.\n\n### Testing\n\n> [!Note] \n> For more in-depth information on testing, see the dedicated [testing][testing-article] article. \n\nTo test use a `TestStore`, which can be created with the same information as the `Store`, but it \ndoes extra work to allow you to assert how your feature evolves as actions are sent:\n\n```swift\n@Test\nfunc basics() async {\n  let store = TestStore(initialState: Feature.State()) {\n    Feature()\n  }\n}\n```\n\nOnce the test store is created we can use it to make an assertion of an entire user flow of steps. \nEach step of the way we need to prove that state changed how we expect. For example, we can \nsimulate the user flow of tapping on the increment and decrement buttons:\n\n```swift\n// Test that tapping on the increment/decrement buttons changes the count\nawait store.send(.incrementButtonTapped) {\n  $0.count = 1\n}\nawait store.send(.decrementButtonTapped) {\n  $0.count = 0\n}\n```\n\nFurther, if a step causes an effect to be executed, which feeds data back into the store, we must \nassert on that. For example, if we simulate the user tapping on the fact button we expect to \nreceive a fact response back with the fact, which then causes the `numberFact` state to be \npopulated:\n\n```swift\nawait store.send(.numberFactButtonTapped)\n\nawait store.receive(\\.numberFactResponse) {\n  $0.numberFact = ???\n}\n```\n\nHowever, how do we know what fact is going to be sent back to us?\n\nCurrently our reducer is using an effect that reaches out into the real world to hit an API server, \nand that means we have no way to control its behavior. We are at the whims of our internet \nconnectivity and the availability of the API server in order to write this test.\n\nIt would be better for this dependency to be passed to the reducer so that we can use a live \ndependency when running the application on a device, but use a mocked dependency for tests. We can \ndo this by adding a property to the `Feature` reducer:\n\n```swift\n@Reducer\nstruct Feature {\n  let numberFact: (Int) async throws -> String\n  // ...\n}\n```\n\nThen we can use it in the `reduce` implementation:\n\n```swift\ncase .numberFactButtonTapped:\n  return .run { [count = state.count] send in \n    let fact = try await self.numberFact(count)\n    await send(.numberFactResponse(fact))\n  }\n```\n\nAnd in the entry point of the application we can provide a version of the dependency that actually \ninteracts with the real world API server:\n\n```swift\n@main\nstruct MyApp: App {\n  var body: some Scene {\n    WindowGroup {\n      FeatureView(\n        store: Store(initialState: Feature.State()) {\n          Feature(\n            numberFact: { number in\n              let (data, _) = try await URLSession.shared.data(\n                from: URL(string: \"http://numbersapi.com/\\(number)\")!\n              )\n              return String(decoding: data, as: UTF8.self)\n            }\n          )\n        }\n      )\n    }\n  }\n}\n```\n\nBut in tests we can use a mock dependency that immediately returns a deterministic, predictable \nfact: \n\n```swift\n@Test\nfunc basics() async {\n  let store = TestStore(initialState: Feature.State()) {\n    Feature(numberFact: { \"\\($0) is a good number Brent\" })\n  }\n}\n```\n\nWith that little bit of upfront work we can finish the test by simulating the user tapping on the \nfact button, and then receiving the response from the dependency to present the fact:\n\n```swift\nawait store.send(.numberFactButtonTapped)\n\nawait store.receive(\\.numberFactResponse) {\n  $0.numberFact = \"0 is a good number Brent\"\n}\n```\n\nWe can also improve the ergonomics of using the `numberFact` dependency in our application. Over \ntime the application may evolve into many features, and some of those features may also want access \nto `numberFact`, and explicitly passing it through all layers can get annoying. There is a process \nyou can follow to â€œregisterâ€ dependencies with the library, making them instantly available to any \nlayer in the application.\n\n> [!Note] \n> For more in-depth information on dependency management, see the dedicated\n> [dependencies][dependencies-article] article. \n\nWe can start by wrapping the number fact functionality in a new type:\n\n```swift\nstruct NumberFactClient {\n  var fetch: (Int) async throws -> String\n}\n```\n\nAnd then registering that type with the dependency management system by conforming the client to\nthe `DependencyKey` protocol, which requires you to specify the live value to use when running the\napplication in simulators or devices:\n\n```swift\nextension NumberFactClient: DependencyKey {\n  static let liveValue = Self(\n    fetch: { number in\n      let (data, _) = try await URLSession.shared\n        .data(from: URL(string: \"http://numbersapi.com/\\(number)\")!\n      )\n      return String(decoding: data, as: UTF8.self)\n    }\n  )\n}\n\nextension DependencyValues {\n  var numberFact: NumberFactClient {\n    get { self[NumberFactClient.self] }\n    set { self[NumberFactClient.self] = newValue }\n  }\n}\n```\n\nWith that little bit of upfront work done you can instantly start making use of the dependency in \nany feature by using the `@Dependency` property wrapper:\n\n```diff\n @Reducer\n struct Feature {\n-  let numberFact: (Int) async throws -> String\n+  @Dependency(\\.numberFact) var numberFact\n   \n   â€¦\n\n-  try await self.numberFact(count)\n+  try await self.numberFact.fetch(count)\n }\n```\n\nThis code works exactly as it did before, but you no longer have to explicitly pass the dependency \nwhen constructing the feature's reducer. When running the app in previews, the simulator or on a \ndevice, the live dependency will be provided to the reducer, and in tests the test dependency will \nbe provided.\n\nThis means the entry point to the application no longer needs to construct dependencies:\n\n```swift\n@main\nstruct MyApp: App {\n  var body: some Scene {\n    WindowGroup {\n      FeatureView(\n        store: Store(initialState: Feature.State()) {\n          Feature()\n        }\n      )\n    }\n  }\n}\n```\n\nAnd the test store can be constructed without specifying any dependencies, but you can still \noverride any dependency you need to for the purpose of the test:\n\n```swift\nlet store = TestStore(initialState: Feature.State()) {\n  Feature()\n} withDependencies: {\n  $0.numberFact.fetch = { \"\\($0) is a good number Brent\" }\n}\n\n// ...\n```\n\nThat is the basics of building and testing a feature in the Composable Architecture. There are \n_a lot_ more things to be explored, such as composition, modularity, adaptability, and complex \neffects. The [Examples](./Examples) directory has a bunch of projects to explore to see more \nadvanced usages.\n\n## Documentation\n\nThe documentation for releases and `main` are available here:\n\n* [`main`](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture)\n* [1.x.x](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/~/documentation/composablearchitecture)\n\nThere are a number of articles in the documentation that you may find helpful as you become more \ncomfortable with the library:\n\n* [Getting started][getting-started-article]\n* [Dependencies][dependencies-article]\n* [Testing][testing-article]\n* [Navigation][navigation-article]\n* [Sharing state][sharing-state-article]\n* [Performance][performance-article]\n* [Concurrency][concurrency-article]\n* [Bindings][bindings-article]\n\n## FAQ\n\nWe have a [dedicated article][faq-article] for all of the most frequently asked questions and\ncomments people have concerning the library.\n\n## Community\n\nIf you want to discuss the Composable Architecture or have a question about how to use it to solve \na particular problem, there are a number of places you can discuss with fellow \n[Point-Free](http://www.pointfree.co) enthusiasts:\n\n* For long-form discussions, we recommend the [discussions][gh-discussions] tab of this repo.\n* For casual chat, we recommend the [Point-Free Community slack](http://pointfree.co/slack-invite).\n\n## Installation\n\nYou can add ComposableArchitecture to an Xcode project by adding it as a package dependency.\n\n  1. From the **File** menu, select **Add Package Dependencies...**\n  2. Enter \"https://github.com/pointfreeco/swift-composable-architecture\" into the package \n     repository URL text field\n  3. Depending on how your project is structured:\n      - If you have a single application target that needs access to the library, then add \n        **ComposableArchitecture** directly to your application.\n      - If you want to use this library from multiple Xcode targets, or mix Xcode targets and SPM \n        targets, you must create a shared framework that depends on **ComposableArchitecture** and \n        then depend on that framework in all of your targets. For an example of this, check out the \n        [Tic-Tac-Toe](./Examples/TicTacToe) demo application, which splits lots of features into \n        modules and consumes the static library in this fashion using the **tic-tac-toe** Swift \n        package.\n\n## Companion libraries\n\nThe Composable Architecture is built with extensibility in mind, and there are a number of\ncommunity-supported libraries available to enhance your applications:\n\n* [Composable Architecture Extras](https://github.com/Ryu0118/swift-composable-architecture-extras):\n  A companion library to the Composable Architecture.\n* [TCAComposer](https://github.com/mentalflux/tca-composer): A macro framework for generating\n  boiler-plate code in the Composable Architecture.\n* [TCACoordinators](https://github.com/johnpatrickmorgan/TCACoordinators): The coordinator pattern\n  in the Composable Architecture.\n\nIf you'd like to contribute a library, please [open a\nPR](https://github.com/pointfreeco/swift-composable-architecture/edit/main/README.md) with a link\nto it!\n\n## Translations\n\nThe following translations of this README have been contributed by members of the community:\n\n* [Arabic](https://gist.github.com/NorhanBoghdadi/1b98d55c02b683ddef7e05c2ebcccd47)\n* [French](https://gist.github.com/nikitamounier/0e93eb832cf389db12f9a69da030a2dc)\n* [Hindi](https://gist.github.com/akashsoni01/b358ee0b3b747167964ef6946123c88d)\n* [Indonesian](https://gist.github.com/wendyliga/792ea9ac5cc887f59de70a9e39cc7343)\n* [Italian](https://gist.github.com/Bellaposa/5114e6d4d55fdb1388e8186886d48958)\n* [Japanese](https://gist.github.com/Achoo-kr/2d0712deb77f78b3379551ac7baea3e4)\n* [Korean](https://gist.github.com/Achoo-kr/5d8936d12e71028fcc4a7c5e078ca038)\n* [Polish](https://gist.github.com/MarcelStarczyk/6b6153051f46912a665c32199f0d1d54)\n* [Portuguese](https://gist.github.com/SevioCorrea/2bbf337cd084a58c89f2f7f370626dc8)\n* [Russian](https://gist.github.com/SubvertDev/3317d0c3b35ed601be330d6fc0df5aba)\n* [Simplified Chinese](https://gist.github.com/sh3l6orrr/10c8f7c634a892a9c37214f3211242ad)\n* [Spanish](https://gist.github.com/pitt500/f5e32fccb575ce112ffea2827c7bf942)\n* [Turkish](https://gist.github.com/gokhanamal/93001244ef0c1cec58abeb1afc0de37c)\n* [Ukrainian](https://gist.github.com/barabashd/33b64676195ce41f4bb73c327ea512a8)\n\nIf you'd like to contribute a translation, please [open a\nPR](https://github.com/pointfreeco/swift-composable-architecture/edit/main/README.md) with a link \nto a [Gist](https://gist.github.com)!\n\n## Credits and thanks\n\nThe following people gave feedback on the library at its early stages and helped make the library \nwhat it is today:\n\nPaul Colton, Kaan Dedeoglu, Matt Diephouse, Josef DoleÅ¾al, Eimantas, Matthew Johnson, George \nKaimakas, Nikita Leonov, Christopher Liscio, Jeffrey Macko, Alejandro Martinez, Shai Mishali, Willis \nPlummer, Simon-Pierre Roy, Justin Price, Sven A. Schmidt, Kyle Sherman, Petr Å Ã­ma, Jasdev Singh, \nMaxim Smirnov, Ryan Stone, Daniel Hollis Tavares, and all of the [Point-Free][pointfreeco] \nsubscribers ğŸ˜.\n\nSpecial thanks to [Chris Liscio](https://twitter.com/liscio) who helped us work through many strange \nSwiftUI quirks and helped refine the final API.\n\nAnd thanks to [Shai Mishali](https://github.com/freak4pc) and the\n[CombineCommunity](https://github.com/CombineCommunity/CombineExt/) project, from which we took \ntheir implementation of `Publishers.Create`, which we use in `Effect` to help bridge delegate and \ncallback-based APIs, making it much easier to interface with 3rd party frameworks.\n\n## Other libraries\n\nThe Composable Architecture was built on a foundation of ideas started by other libraries, in \nparticular [Elm](https://elm-lang.org) and [Redux](https://redux.js.org/).\n\nThere are also many architecture libraries in the Swift and iOS community. Each one of these has \ntheir own set of priorities and trade-offs that differ from the Composable Architecture.\n\n* [RIBs](https://github.com/uber/RIBs)\n* [Loop](https://github.com/ReactiveCocoa/Loop)\n* [ReSwift](https://github.com/ReSwift/ReSwift)\n* [Workflow](https://github.com/square/workflow)\n* [ReactorKit](https://github.com/ReactorKit/ReactorKit)\n* [RxFeedback](https://github.com/NoTests/RxFeedback.swift)\n* [Mobius.swift](https://github.com/spotify/mobius.swift)\n* <details>\n  <summary>And more</summary>\n\n  * [Fluxor](https://github.com/FluxorOrg/Fluxor)\n  * [PromisedArchitectureKit](https://github.com/RPallas92/PromisedArchitectureKit)\n  </details>\n\n## License\n\nThis library is released under the MIT license. See [LICENSE](LICENSE) for details.\n\n[pointfreeco]: https://www.pointfree.co\n[mbrandonw]: https://twitter.com/mbrandonw\n[stephencelis]: https://twitter.com/stephencelis\n[tca-episode-collection]: https://www.pointfree.co/collections/composable-architecture\n[tca-tour]: https://www.pointfree.co/collections/tours/composable-architecture-1-0\n[gh-isowords]: https://github.com/pointfreeco/isowords\n[gh-discussions]: https://github.com/pointfreeco/swift-composable-architecture/discussions\n[swift-forum]: https://forums.swift.org/c/related-projects/swift-composable-architecture\n[testing-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/testingtca\n[faq-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/faq\n[dependencies-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/dependencymanagement\n[getting-started-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/gettingstarted\n[navigation-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/navigation\n[performance-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/performance\n[concurrency-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/swiftconcurrency\n[bindings-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/bindings\n[sharing-state-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/sharingstate\n[meet-tca]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/tutorials/meetcomposablearchitecture\n",
      "stars_today": 6
    },
    {
      "id": 29933948,
      "name": "fluent-bit",
      "full_name": "fluent/fluent-bit",
      "description": "Fast and Lightweight Logs, Metrics and Traces processor for Linux, BSD, OSX and Windows",
      "html_url": "https://github.com/fluent/fluent-bit",
      "stars": 7636,
      "forks": 1866,
      "language": "C",
      "topics": [
        "c",
        "cloudnative",
        "data-collector",
        "fluent-bit",
        "fluentd",
        "forwarder",
        "logging",
        "logs",
        "metrics",
        "opentelemetry",
        "prometheus",
        "sql-queries",
        "stream-processing",
        "traces"
      ],
      "created_at": "2015-01-27T20:41:52Z",
      "updated_at": "2026-02-06T19:33:45Z",
      "pushed_at": "2026-02-06T18:37:31Z",
      "open_issues": 737,
      "owner": {
        "login": "fluent",
        "avatar_url": "https://avatars.githubusercontent.com/u/859518?v=4"
      },
      "readme": "# ![logo](fluentbit_logo.png)\n\n### CI Status\n\n| CI Workflow             | Status                                                                                                                                                     |\n|-------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Unit Tests (`master`)   | [![CI/Unit Tests](https://github.com/fluent/fluent-bit/actions/workflows/unit-tests.yaml/badge.svg?branch=master)](https://github.com/fluent/fluent-bit/actions/workflows/unit-tests.yaml) |\n| Integration Tests       | [![CI/Integration Tests](https://github.com/fluent/fluent-bit/actions/workflows/master-integration-test.yaml/badge.svg)](https://github.com/fluent/fluent-bit/actions/workflows/master-integration-test.yaml) |\n| Arm builds              | <a href=\"https://actuated.dev/\"><img alt=\"Arm CI sponsored by Actuated\" src=\"https://docs.actuated.dev/images/actuated-badge.png\" width=\"120px\"></img></a> |\n| Latest Release Pipeline | [![CI/Build](https://github.com/fluent/fluent-bit/actions/workflows/staging-release.yaml/badge.svg)](https://github.com/fluent/fluent-bit/actions/workflows/staging-release.yaml) |\n\n---\n\n## About\n\n[Fluent Bit](https://fluentbit.io) is a lightweight and high-performance Telemetry Agent designed to collect, process, and forward **Logs**, **Metrics**, and **Traces** from any source to any destination.\n\nIt's part of the Graduated [Fluentd](https://fluentd.org) Ecosystem and a CNCF [Cloud Native Computing Foundation](https://cncf.io) project.\n\nFluent Bit supports a wide array of platforms, including Linux, Windows, MacOS, BSD, and Embedded environments, and is built for maximum efficiency with minimal CPU and memory footprint.\n\n![](documentation/fluentbit_ecosystem.png)\n\n---\n\n## ğŸ“Œ Roadmap & Maintenance\n\nWe follow a fast-paced development cycle, with major releases every 3â€“4 months.\nThe active development branch (`master`) is currently focused on **v5.0** (development).\n\nFor version-specific maintenance timelines and policies, see our [MAINTENANCE.md](https://github.com/fluent/fluent-bit/blob/master/MAINTENANCE.md).\n\nTo track upcoming milestones, visit the [project roadmap](https://github.com/fluent/fluent-bit/wiki/Fluent-Bit-Roadmap).\n\n---\n\n## Key Features\n\n- âš¡ **High Performance** with low memory footprint\n- ğŸ“¦ **Pluggable Architecture**: 70+ built-in plugins for Inputs, Filters, and Outputs\n- ğŸ§  **SQL Stream Processing**: Perform analytics and transformations with SQL queries\n- ğŸ”’ **Secure Networking**: Built-in TLS/SSL support and async I/O\n- ğŸ“Š **Monitoring**: Expose internal metrics over HTTP/Prometheus\n- ğŸ§© **Extensibility**:\n  - Write plugins in **C**, filters in **Lua**, and outputs in **Go**\n- ğŸ”Œ **Supports Logs, Metrics, and Traces** with unified processing and delivery\n\n---\n\n## Documentation\n\nOur official documentation includes installation guides, plugin usage, developer resources, and more:\n\nğŸ“š [https://docs.fluentbit.io](https://docs.fluentbit.io)\n\n---\n\n## Quick Start\n\nBuild from source:\n\n```bash\ncd build\ncmake ..\nmake\nbin/fluent-bit -i cpu -o stdout -f 1\n```\n\nMore details: [Build & Install](https://docs.fluentbit.io/manual/installation/downloads/source/build-and-install)\n\n#### Requirements\n\n- CMake >= 3.0\n- Flex & Bison\n- YAML and OpenSSL headers\n\n---\n\n## Install Fluent Bit\n\n- [Linux packages (Debian, Ubuntu, RHEL, etc.)](https://docs.fluentbit.io/manual/installation/downloads/linux)\n- [Docker images](https://docs.fluentbit.io/manual/installation/downloads/docker)\n- [Windows binaries](https://docs.fluentbit.io/manual/installation/downloads/windows)\n\n---\n\n## Plugins: Inputs, Filters, Outputs\n\nFluent Bit is fully modular. It supports:\n\n- [Input Plugins](https://docs.fluentbit.io/manual/pipeline/inputs): collect logs/metrics/traces\n- [Filter Plugins](https://docs.fluentbit.io/manual/pipeline/filters): enrich and transform data\n- [Output Plugins](https://docs.fluentbit.io/manual/pipeline/outputs): deliver data to external services\n\nSee the full plugin list in our [documentation](https://docs.fluentbit.io/manual/pipeline/inputs).\n\n---\n\n## ğŸš€ Production Usage\n\nFluent Bit is deployed **over 10 million times daily** and has surpassed **15 billion downloads**.\n\nUsed by companies like:\n\n![users](documentation/fluentbit_users.png)\n\n> Want to add your logo? [Open an issue](https://github.com/fluent/fluent-bit/issues).\n\n---\n\n## Contributing\n\nFluent Bit is open to community contributions!\n\n- ğŸ¤ [Join our community](https://fluentbit.io/community/)\n- ğŸ›  [CONTRIBUTING.md](CONTRIBUTING.md)\n- ğŸš€ [Developer Guide](DEVELOPER_GUIDE.md)\n\n---\n\n## Community & Contact\n\n- ğŸ’¬ [Slack](http://slack.fluentd.org) (`#fluent-bit` channel)\n- ğŸ¦ [Twitter](https://twitter.com/fluentbit)\n\n---\n\n## License\n\n[Apache License v2.0](http://www.apache.org/licenses/LICENSE-2.0)\n\n---\n\n## Authors\n\nFluent Bit is a CNCF graduated project, sponsored and maintained by major cloud providers and a growing community of contributors and maintainers from across the Cloud Native ecosystem.\n\nğŸ‘‰ [See Contributors](https://github.com/fluent/fluent-bit/graphs/contributors)\n",
      "stars_today": 6
    },
    {
      "id": 196414933,
      "name": "opentelemetry-collector-contrib",
      "full_name": "open-telemetry/opentelemetry-collector-contrib",
      "description": "Contrib repository for the OpenTelemetry Collector",
      "html_url": "https://github.com/open-telemetry/opentelemetry-collector-contrib",
      "stars": 4386,
      "forks": 3307,
      "language": "Go",
      "topics": [
        "open-telemetry",
        "opentelemetry"
      ],
      "created_at": "2019-07-11T14:54:32Z",
      "updated_at": "2026-02-06T19:40:02Z",
      "pushed_at": "2026-02-06T20:04:23Z",
      "open_issues": 904,
      "owner": {
        "login": "open-telemetry",
        "avatar_url": "https://avatars.githubusercontent.com/u/49998002?v=4"
      },
      "readme": "---\n\n<p align=\"center\">\n  <strong>\n    <a href=\"https://opentelemetry.io/docs/collector/getting-started/\">Getting Started</a>\n    &nbsp;&nbsp;&bull;&nbsp;&nbsp;\n    <a href=\"https://github.com/open-telemetry/opentelemetry-collector/blob/main/CONTRIBUTING.md\">Getting Involved</a>\n    &nbsp;&nbsp;&bull;&nbsp;&nbsp;\n    <a href=\"https://cloud-native.slack.com/archives/C01N6P7KR6W\">Getting In Touch</a>\n  </strong>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/open-telemetry/opentelemetry-collector-contrib/actions/workflows/build-and-test.yml?query=branch%3Amain\">\n    <img alt=\"Build Status\" src=\"https://img.shields.io/github/actions/workflow/status/open-telemetry/opentelemetry-collector-contrib/build-and-test.yml?branch=main&style=for-the-badge\">\n  </a>\n  <a href=\"https://goreportcard.com/report/github.com/open-telemetry/opentelemetry-collector-contrib\">\n    <img alt=\"Go Report Card\" src=\"https://goreportcard.com/badge/github.com/open-telemetry/opentelemetry-collector-contrib?style=for-the-badge\">\n  </a>\n  <a href=\"https://codecov.io/gh/open-telemetry/opentelemetry-collector-contrib/branch/main/\">\n    <img alt=\"Codecov Status\" src=\"https://img.shields.io/codecov/c/github/open-telemetry/opentelemetry-collector-contrib?style=for-the-badge\">\n  </a>\n  <a href=\"https://github.com/open-telemetry/opentelemetry-collector-contrib/releases\">\n    <img alt=\"GitHub release (latest by date including pre-releases)\" src=\"https://img.shields.io/github/v/release/open-telemetry/opentelemetry-collector-contrib?include_prereleases&style=for-the-badge\">\n  </a>\n  <img alt=\"Beta\" src=\"https://img.shields.io/badge/status-beta-informational?style=for-the-badge&logo=data:image/png;base64,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\">\n</p>\n\n<p align=\"center\">\n  <strong>\n    <a href=\"https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/vision.md\">Vision</a>\n    &nbsp;&nbsp;&bull;&nbsp;&nbsp;\n    <a href=\"https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/observability.md\">Observability</a>\n    &nbsp;&nbsp;&bull;&nbsp;&nbsp;\n    <a href=\"https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/security-best-practices.md\">Security</a>\n  </strong>\n</p>\n\n---\n\n# OpenTelemetry Collector Contrib\n\nThis is a repository for OpenTelemetry Collector components that are not suitable for the  [core repository](https://github.com/open-telemetry/opentelemetry-collector) of the collector. \n\nThe official distributions, core and contrib, are available as part of the [opentelemetry-collector-releases](https://github.com/open-telemetry/opentelemetry-collector-releases) repository. Some of the components in this repository are part of the \"core\" distribution, such as the Jaeger and Prometheus components, but most of the components here are only available as part of the \"contrib\" distribution. Users of the OpenTelemetry Collector are also encouraged to build their own custom distributions with the [OpenTelemetry Collector Builder](https://github.com/open-telemetry/opentelemetry-collector/tree/main/cmd/builder), using the components they need from the core repository, the contrib repository, and possibly third-party or internal repositories.\n\nEach component has its own support levels, as defined in the following sections. For each signal that a component supports, there's a stability level, setting the right expectations. It is possible then that a component will be **Stable** for traces but **Alpha** for metrics and **Development** for logs.\n\n## Stability levels\n\nStability level for components in this repository follow the [definitions](https://github.com/open-telemetry/opentelemetry-collector#stability-levels) from the OpenTelemetry Collector repository.\n\n## Gated features\n\nSome features are hidden behind feature gates before they are part of the main code path for the component. Note that the feature gates themselves might be at different [lifecycle stages](https://github.com/open-telemetry/opentelemetry-collector/tree/main/featuregate#feature-lifecycle).\n\n## Support\n\nEach component is supported either by the community of OpenTelemetry Collector Contrib maintainers, as defined by the GitHub group [@open-telemetry/collector-contrib-maintainer](https://github.com/orgs/open-telemetry/teams/collector-contrib-maintainer), or by specific vendors. See the individual README files for information about the specific components.\n\nThe OpenTelemetry Collector Contrib maintainers may at any time downgrade specific components if they are deemed unmaintained or if they pose a risk to the repository and/or binary distribution.\n\nEven though the OpenTelemetry Collector Contrib maintainers are ultimately responsible for the components hosted here, actual support will likely be provided by individual contributors, typically a code owner for the specific component.\n\n## Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md).\n\n### Maintainers\n\n- [Alex Boten](https://github.com/codeboten), Honeycomb\n- [Andrzej Stencel](https://github.com/andrzej-stencel), Elastic\n- [Antoine Toulme](https://github.com/atoulme), Splunk\n- [Bogdan Drutu](https://github.com/bogdandrutu), Snowflake\n- [Christos Markou](https://github.com/ChrsMark), Elastic\n- [Dmitrii Anoshin](https://github.com/dmitryax), Splunk\n- [Edmo Vamerlatti Costa](https://github.com/edmocosta), Elastic\n- [Evan Bradley](https://github.com/evan-bradley), Dynatrace\n- [Pablo Baeyens](https://github.com/mx-psi), DataDog\n- [Sean Marciniak](https://github.com/MovieStoreGuy), Splunk\n- [Tyler Helmuth](https://github.com/TylerHelmuth), Honeycomb\n- [Yang Song](https://github.com/songy23), DataDog\n\nFor more information about the maintainer role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#maintainer).\n\n### Approvers\n\n- [Andrew Wilkins](https://github.com/axw), Elastic\n- [Arthur Silva Sens](https://github.com/ArthurSens), Grafana Labs\n- [Braydon Kains](https://github.com/braydonk), Google\n- [Curtis Robert](https://github.com/crobert-1), Splunk\n- [David Ashpole](https://github.com/dashpole), Google\n- [Paulo Janotti](https://github.com/pjanotti), Splunk\n- [Sam DeHaan](https://github.com/dehaansa), Grafana Labs\n- [Vihas Makwana](https://github.com/VihasMakwana), Elastic\n- [Ziqi Zhao](https://github.com/fatsheep9146), Alibaba\n\nFor more information about the approver role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#approver).\n\n### Triagers\n\n- [Benedikt Bongartz](https://github.com/frzifus), Red Hat\n- [Bogdan Stancu](https://github.com/bogdan-st), Adobe\n- [ConstanÃ§a Manteigas](https://github.com/constanca-m), Elastic\n- [Douglas Camata](https://github.com/douglascamata), Coralogix\n- [Israel Blancas](https://github.com/iblancasa), Coralogix\n- [James Moessis](https://github.com/jamesmoessis), Atlassian\n- [Jared Tan](https://github.com/JaredTan95), DaoCloud\n- [Murphy Chen](https://github.com/Frapschen), DaoCloud\n- [Ondrej Dubaj](https://github.com/odubajDT), Dynatrace\n- [Paulo Dias](https://github.com/paulojmdias), Five9\n- [Roger Coll](https://github.com/rogercoll), Elastic\n- Actively seeking contributors to triage issues\n\nFor more information about the triager role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#triager).\n\n### Emeritus Maintainers\n\n- [Daniel Jaglowski](https://github.com/djaglowski)\n- [Juraci PaixÃ£o KrÃ¶hling](https://github.com/jpkrohling)\n- [Tigran Najaryan](https://github.com/tigrannajaryan)\n\nFor more information about the emeritus role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager).\n\n### Emeritus Approvers\n\n- [Anthony Mirabella](https://github.com/Aneurysm9)\n- [Bryan Aguilar](https://github.com/bryan-aguilar)\n- [Matt Wear](https://github.com/mwear)\n- [Przemek Maciolek](https://github.com/pmm-sumo)\n- [Ruslan Kovalov](https://github.com/kovrus)\n\nFor more information about the emeritus role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager).\n\n### Emeritus Triagers\n\n- [Alolita Sharma](https://github.com/alolita)\n- [Gabriel Aszalos](https://github.com/gbbr)\n- [Goutham Veeramachaneni](https://github.com/gouthamve)\n- [Punya Biswal](https://github.com/punya)\n- [Steve Flanders](https://github.com/flands)\n- [Florian Bacher](https://github.com/bacherfl), Dynatrace\n\nFor more information about the emeritus role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager).\n\n### No Over-Representation\n\nA community member cannot be promoted to be a Collector contrib maintainer if, after their promotion, the resulting maintainers group has more than one-fourth (25%) of the members affiliated with the same employer. Job changes and similar events might result in over-representation, and no new maintainers from the same company can be promoted until representation is balanced again. In the event of confusion or concern, the OpenTelemetry Collector SIG will defer to the CNCF definition of \"same employer\".\n\n## PRs and Reviews\n\nWhen creating a PR please follow the process [described\nhere](https://github.com/open-telemetry/opentelemetry-collector/blob/main/CONTRIBUTING.md#how-to-structure-prs-to-get-expedient-reviews).\n\nNew PRs will be automatically associated with the reviewers based on\n[CODEOWNERS](.github/CODEOWNERS). PRs will be also automatically assigned to one of the\nmaintainers or approvers for facilitation.\n\nThe facilitator is responsible for helping the PR author and reviewers to make progress\nor if progress cannot be made for closing the PR.\n\nIf the reviewers do not have approval rights the facilitator is also responsible\nfor the official approval that is required for the PR to be merged and if the facilitator\nis a maintainer they are responsible for merging the PR as well.\n\nThe facilitator is not required to perform a thorough review, but they are encouraged to\nenforce Collector best practices and consistency across the codebase and component\nbehavior. The facilitators will typically rely on codeowner's detailed review of the code\nwhen making the final approval decision.\n\nMarking the PR with the `ready to merge` label should only happen (by triagers/approvers/maintainers)\nonce there is at least one approval from an approver, as per the description above. \n",
      "stars_today": 6
    },
    {
      "id": 140958903,
      "name": "expr",
      "full_name": "expr-lang/expr",
      "description": "Expression language and expression evaluation for Go",
      "html_url": "https://github.com/expr-lang/expr",
      "stars": 7665,
      "forks": 479,
      "language": "Go",
      "topics": [
        "bytecode",
        "configuration-language",
        "engine",
        "evaluator",
        "expr",
        "expression",
        "expression-evaluator",
        "expression-language",
        "go",
        "golang",
        "rule-engine"
      ],
      "created_at": "2018-07-14T15:57:34Z",
      "updated_at": "2026-02-07T00:24:52Z",
      "pushed_at": "2026-02-05T06:25:02Z",
      "open_issues": 56,
      "owner": {
        "login": "expr-lang",
        "avatar_url": "https://avatars.githubusercontent.com/u/144815908?v=4"
      },
      "readme": "<h1><a href=\"https://expr-lang.org\"><img src=\"https://expr-lang.org/img/logo.png\" alt=\"Zx logo\" height=\"48\"align=\"right\"></a> Expr</h1>\n\n[![test](https://github.com/expr-lang/expr/actions/workflows/test.yml/badge.svg)](https://github.com/expr-lang/expr/actions/workflows/test.yml) \n[![Go Report Card](https://goreportcard.com/badge/github.com/expr-lang/expr)](https://goreportcard.com/report/github.com/expr-lang/expr) \n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/expr.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:expr)\n[![GoDoc](https://godoc.org/github.com/expr-lang/expr?status.svg)](https://godoc.org/github.com/expr-lang/expr)\n\n**Expr** is a Go-centric expression language designed to deliver dynamic configurations with unparalleled accuracy, safety, and speed. \n**Expr** combines simple [syntax](https://expr-lang.org/docs/language-definition) with powerful features for ease of use:\n\n```js\n// Allow only admins and moderators to moderate comments.\nuser.Group in [\"admin\", \"moderator\"] || user.Id == comment.UserId\n```\n\n```js\n// Determine whether the request is in the permitted time window.\nrequest.Time - resource.Age < duration(\"24h\")\n```\n\n```js\n// Ensure all tweets are less than 240 characters.\nall(tweets, len(.Content) <= 240)\n```\n\n## Features\n\n**Expr** is a safe, fast, and intuitive expression evaluator optimized for the Go language. \nHere are its standout features:\n\n### Safety and Isolation\n* **Memory-Safe**: Expr is designed with a focus on safety, ensuring that programs do not access unrelated memory or introduce memory vulnerabilities.\n* **Side-Effect-Free**: Expressions evaluated in Expr only compute outputs from their inputs, ensuring no side-effects that can change state or produce unintended results.\n* **Always Terminating**: Expr is designed to prevent infinite loops, ensuring that every program will conclude in a reasonable amount of time.\n\n### Go Integration\n* **Seamless with Go**: Integrate Expr into your Go projects without the need to redefine types.\n\n### Static Typing\n* Ensures type correctness and prevents runtime type errors.\n  ```go\n  out, err := expr.Compile(`name + age`)\n  // err: invalid operation + (mismatched types string and int)\n  // | name + age\n  // | .....^\n  ```\n\n### User-Friendly\n* Provides user-friendly error messages to assist with debugging and development.\n\n### Flexibility and Utility\n* **Rich Operators**: Offers a reasonable set of basic operators for a variety of applications.\n* **Built-in Functions**: Functions like `all`, `none`, `any`, `one`, `filter`, and `map` are provided out-of-the-box.\n\n### Performance\n* **Optimized for Speed**: Expr stands out in its performance, utilizing an optimizing compiler and a bytecode virtual machine. Check out these [benchmarks](https://github.com/antonmedv/golang-expression-evaluation-comparison#readme) for more details.\n\n## Install\n\n```\ngo get github.com/expr-lang/expr\n```\n\n## Documentation\n\n* See [Getting Started](https://expr-lang.org/docs/Getting-Started) page for developer documentation.\n* See [Language Definition](https://expr-lang.org/docs/language-definition) page to learn the syntax.\n\n## Examples\n\n[Play Online](https://go.dev/play/p/XCoNXEjm3TS)\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"github.com/expr-lang/expr\"\n)\n\nfunc main() {\n\tenv := map[string]interface{}{\n\t\t\"greet\":   \"Hello, %v!\",\n\t\t\"names\":   []string{\"world\", \"you\"},\n\t\t\"sprintf\": fmt.Sprintf,\n\t}\n\n\tcode := `sprintf(greet, names[0])`\n\n\tprogram, err := expr.Compile(code, expr.Env(env))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\toutput, err := expr.Run(program, env)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tfmt.Println(output)\n}\n```\n\n[Play Online](https://go.dev/play/p/tz-ZneBfSuw)\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"github.com/expr-lang/expr\"\n)\n\ntype Tweet struct {\n\tLen int\n}\n\ntype Env struct {\n\tTweets []Tweet\n}\n\nfunc main() {\n\tcode := `all(Tweets, {.Len <= 240})`\n\n\tprogram, err := expr.Compile(code, expr.Env(Env{}))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tenv := Env{\n\t\tTweets: []Tweet{{42}, {98}, {69}},\n\t}\n\toutput, err := expr.Run(program, env)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tfmt.Println(output)\n}\n```\n\n## Who uses Expr?\n\n* [Google](https://google.com) uses Expr as one of its expression languages on the [Google Cloud Platform](https://cloud.google.com).\n* [Uber](https://uber.com) uses Expr to allow customization of its Uber Eats marketplace.\n* [GoDaddy](https://godaddy.com) employs Expr for the customization of its GoDaddy Pro product.\n* [ByteDance](https://bytedance.com) incorporates Expr into its internal business rule engine.\n* [Aviasales](https://aviasales.ru) utilizes Expr as a business rule engine for its flight search engine.\n* [Alibaba](https://alibaba.com) uses Expr in a web framework for building recommendation services.\n* [Argo](https://argoproj.github.io) integrates Expr into Argo Rollouts and Argo Workflows for Kubernetes.\n* [Wish.com](https://www.wish.com) employs Expr in its decision-making rule engine for the Wish Assistant.\n* [OpenTelemetry](https://opentelemetry.io) integrates Expr into the OpenTelemetry Collector.\n* [Philips Labs](https://github.com/philips-labs/tabia) employs Expr in Tabia, a tool designed to collect insights on their code bases.\n* [CrowdSec](https://crowdsec.net) incorporates Expr into its security automation tool.\n* [CoreDNS](https://coredns.io) uses Expr in CoreDNS, which is a DNS server.\n* [qiniu](https://www.qiniu.com) implements Expr in its trade systems.\n* [Junglee Games](https://www.jungleegames.com/) uses Expr for its in-house marketing retention tool, Project Audience.\n* [Faceit](https://www.faceit.com) uses Expr to enhance customization of its eSports matchmaking algorithm.\n* [Chaos Mesh](https://chaos-mesh.org) incorporates Expr into Chaos Mesh, a cloud-native Chaos Engineering platform.\n* [Visually.io](https://visually.io) employs Expr as a business rule engine for its personalization targeting algorithm.\n* [Akvorado](https://github.com/akvorado/akvorado) utilizes Expr to classify exporters and interfaces in network flows.\n* [keda.sh](https://keda.sh) uses Expr to allow customization of its Kubernetes-based event-driven autoscaling.\n* [Span Digital](https://spandigital.com/) uses Expr in its Knowledge Management products.\n* [Xiaohongshu](https://www.xiaohongshu.com/) combining yaml with Expr for dynamically policies delivery.\n* [MelrÅse](https://melrÅse.org) uses Expr to implement its music programming language.\n* [Tork](https://www.tork.run/) integrates Expr into its workflow execution.\n* [Critical Moments](https://criticalmoments.io) uses Expr for its mobile realtime conditional targeting system.\n* [WoodpeckerCI](https://woodpecker-ci.org) uses Expr for [filtering workflows/steps](https://woodpecker-ci.org/docs/usage/workflow-syntax#evaluate).\n* [FastSchema](https://github.com/fastschema/fastschema) - A BaaS leveraging Expr for its customizable and dynamic Access Control system.\n* [WunderGraph Cosmo](https://github.com/wundergraph/cosmo) - GraphQL Federeration Router uses Expr to customize Middleware behaviour\n* [SOLO](https://solo.one) uses Expr interally to allow dynamic code execution with custom defined functions.\n* [Naoma.AI](https://www.naoma.ai) uses Expr as a part of its call scoring engine.\n\n[Add your company too](https://github.com/expr-lang/expr/edit/master/README.md)\n\n## License\n\n[MIT](https://github.com/expr-lang/expr/blob/master/LICENSE)\n\n<p align=\"center\"><img src=\"https://expr-lang.org/img/gopher-small.png\" width=\"150\" /></p>\n",
      "stars_today": 6
    },
    {
      "id": 750550657,
      "name": "quarkdown",
      "full_name": "iamgio/quarkdown",
      "description": "ğŸª Markdown with superpowers: from ideas to papers, presentations, websites, books, and knowledge bases.",
      "html_url": "https://github.com/iamgio/quarkdown",
      "stars": 10029,
      "forks": 256,
      "language": "Kotlin",
      "topics": [
        "compiler",
        "knowledge-management",
        "markdown",
        "markup",
        "markup-language",
        "paper",
        "pdf",
        "presentations",
        "scripting-language",
        "slides",
        "static-site-generator",
        "typesetting",
        "typesetting-system"
      ],
      "created_at": "2024-01-30T21:13:04Z",
      "updated_at": "2026-02-06T21:51:02Z",
      "pushed_at": "2026-02-06T08:12:42Z",
      "open_issues": 22,
      "owner": {
        "login": "iamgio",
        "avatar_url": "https://avatars.githubusercontent.com/u/16124324?v=4"
      },
      "readme": "<p align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/iamgio/quarkdown/project-files/images/tbanner-light.svg\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://raw.githubusercontent.com/iamgio/quarkdown/project-files/images/tbanner-dark.svg\">\n    <img alt=\"Quarkdown banner\" src=\"https://github.com/user-attachments/assets/68dfb3bf-9466-44f3-b220-7067322c4887\">\n  </picture>\n  <br>\n  <a href=\"https://github.com/iamgio/quarkdown/wiki\"><img alt=\"Wiki\" src=\"https://img.shields.io/badge/wiki-read-darkcyan\"></a>\n  <a href=\"https://quarkdown.com/docs\"><img alt=\"Docs\" src=\"https://img.shields.io/badge/docs-read-blue\"></a>\n  <a href=\"https://github.com/iamgio/quarkdown/releases/latest\"><img alt=\"Release\" src=\"https://img.shields.io/github/v/release/iamgio/quarkdown?color=mediumseagreen\"></a>\n  <a href=\"https://marketplace.visualstudio.com/items?itemName=quarkdown.quarkdown-vscode\"><img alt=\"Visual Studio Code Extension Version\" src=\"https://img.shields.io/visual-studio-marketplace/v/quarkdown.quarkdown-vscode?label=vscode\"></a>\n  <a href=\"https://pinterest.github.io/ktlint\"><img alt=\"FMT: Ktlint\" src=\"https://img.shields.io/badge/fmt-ktlint-7f52ff?logo=kotlin&logoColor=f5f5f5\"></a>\n  <a href=\"https://www.codefactor.io/repository/github/iamgio/quarkdown\"><img alt=\"CodeFactor\" src=\"https://www.codefactor.io/repository/github/iamgio/quarkdown/badge/main\"></a>\n  <br><br>\n  <a href=\"https://trendshift.io/repositories/13945\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/13945\" alt=\"iamgio%2Fquarkdown | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n  <br><br>\n  <strong>Releases</strong>\n  <br>\n  <a href=\"https://github.com/iamgio/quarkdown/releases/tag/latest\">Latest</a>\n  &nbsp; | &nbsp;\n  <strong><a href=\"https://github.com/iamgio/quarkdown/releases/latest\">Stable</a></strong>&nbsp;\n  <br>\n  <hr>\n</p>\n\n# Table of contents\n\n1. [About](#about)\n2. [Demo](#as-simple-as-you-expect)\n3. [Targets](#targets)\n4. [Comparison](#comparison)\n5. [Getting started](#getting-started)\n    1. [Installation](#installation)\n    2. [Quickstart](#quickstart-)\n    3. [Creating a project](#creating-a-project)\n    4. [Compiling](#compiling)\n6. [Mock document](#mock-document)\n7. [Contributing](#contributing)\n8. [Sponsors](#sponsors)\n9. [Concept](#concept)\n10. [License](#license)\n\n&nbsp;\n\n# About\n\nQuarkdown is a modern Markdown-based typesetting system, designed around the key concept of **versatility**, by seamlessly compiling a project\ninto a print-ready book or an interactive presentation.\nAll through an incredibly powerful Turing-complete extension of Markdown, ensuring your ideas flow automatically into paper.\n\n&nbsp;\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/iamgio/quarkdown/project-files/images/paged-demo.png\" alt=\"Paper demo\">\n  <p align=\"center\"><em>Original credits: <a href=\"https://arxiv.org/abs/1706.03762v7\">Attention Is All You Need</a></em></p>\n</p>\n\n<br>\n\nBorn as an extension of CommonMark and GFM, the Quarkdown Flavor brings **functions** to Markdown, along with many other syntax extensions.\n\n<br>\n\n> This is a function call:\n> ```\n> .somefunction {arg1} {arg2}\n>     Body argument\n> ```\n\n<br>\n\n**Possibilities are unlimited** thanks to an ever-expanding [standard library](quarkdown-stdlib/src/main/kotlin/com/quarkdown/stdlib),\nwhich offers layout builders, I/O, math, conditional statements and loops.\n\n**Not enough?** You can still define your own functions and variables â€” all within Markdown.\nYou can even create awesome libraries for everyone to use.\n\n<br>\n\n> ```\n> .function {greet}\n>     to from:\n>     **Hello, .to** from .from!\n>\n> .greet {world} from:{iamgio}\n> ```\n> Result: **Hello, world** from iamgio!\n\n<br>\n\nThis out-of-the-box scripting support opens doors to complex and dynamic content that would be otherwise impossible\nto achieve with vanilla Markdown.\n\nCombined with live preview, :zap: fast compilation speed and a powerful [VS Code extension](https://marketplace.visualstudio.com/items?itemName=quarkdown.quarkdown-vscode), Quarkdown simply gets the work done,\nwhether it's an academic paper, book, knowledge base or interactive presentation.\n\n&nbsp;\n\n<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/quarkdown-labs/quarkdown-vscode/refs/heads/project-files/live-preview.gif\" alt=\"Live preview\" />\n</p>\n\n&nbsp;\n\n---\n\n<h2 align=\"center\">Looking for something?</h2>\n<p align=\"center\">\n  <strong>\n    Check out the <a href=\"https://github.com/iamgio/quarkdown/wiki\" target=\"_blank\">wiki</a>\n  </strong>\n  to get started and learn more about the language and its features!\n</p>\n\n---\n\n&nbsp;\n\n## As simple as you expect...\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/iamgio/quarkdown/project-files/images/code-paper.png\" alt=\"Paper code demo\">\n  <p align=\"center\"><em>Inspired by: <a href=\"https://news.mit.edu/2025/x-ray-flashes-nearby-supermassive-black-hole-accelerate-mysteriously-0113\">X-ray flashes from a nearby supermassive black hole accelerate mysteriously</a></em></p>\n</p>\n\n&nbsp;\n\n<h2 align=\"right\">...as complex as you need.</h2>\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/iamgio/quarkdown/project-files/images/code-chart.png\" alt=\"Chart code demo\">\n</p>\n\n# Targets\n\n- **HTML**\n  - [X] **Plain**  \n    Continuous flow like Notion/Obsidian, perfect for static websites and knowledge management - check out the author's [personal website](https://iamgio.eu/).\n\n  - [X] **Paged** <sup>via [paged.js](https://pagedjs.org)</sup>  \n    Perfect for papers, articles and books - check out the [demo document](https://github.com/iamgio/quarkdown/tree/generated/pdf/mock).\n\n  - [X] **Slides** <sup>via [reveal.js](https://revealjs.com)</sup>  \n    Perfect for interactive presentations.\n\n- **PDF**\n  - [X] All document types and features supported by HTML are also supported when exporting to PDF.\n\nThe desired document type can be set by calling the [`.doctype` function](https://github.com/iamgio/quarkdown/wiki/document-types) within the source itself:\n- `.doctype {plain}` (default)\n- `.doctype {paged}`\n- `.doctype {slides}`\n\n# Comparison\n\n|                       |     Quarkdown      |       LaTeX        |       Typst        |      AsciiDoc      |        MDX         |\n|-----------------------|:------------------:|:------------------:|:------------------:|:------------------:|:------------------:|\n| Concise and readable  | :white_check_mark: |        :x:         | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| Full document control | :white_check_mark: | :white_check_mark: | :white_check_mark: |        :x:         |        :x:         |\n| Scripting             | :white_check_mark: |      Partial       | :white_check_mark: |        :x:         | :white_check_mark: |\n| Book/article export   | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |    Third-party     |\n| Presentation export   | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |    Third-party     |\n| Static site export    | :white_check_mark: |        :x:         |    Experimental    | :white_check_mark: | :white_check_mark: |\n| Learning curve        |   :green_circle:   |    :red_circle:    |  :orange_circle:   |   :green_circle:   |   :green_circle:   |\n| Targets               |     HTML, PDF      |  PDF, PostScript   |        PDF         |  HTML, PDF, ePub   |        HTML        |\n\n<table>\n  <thead>\n    <tr>\n      <th>LaTeX</th>\n      <th>Quarkdown</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>\n\n```latex\n\\tableofcontents\n\n\\section{Section}\n\n\\subsection{Subsection}\n\n\\begin{enumerate}\n    \\item \\textbf{First} item\n    \\item \\textbf{Second} item\n\\end{itemize}\n\n\\begin{center}\n    This text is \\textit{centered}.\n\\end{center}\n\n\\begin{figure}[!h]\n    \\centering\n    \\begin{subfigure}[b]\n        \\includegraphics[width=0.3\\linewidth]{img1.png}\n    \\end{subfigure}\n    \\begin{subfigure}[b]\n        \\includegraphics[width=0.3\\linewidth]{img2.png}\n    \\end{subfigure}\n    \\begin{subfigure}[b]\n        \\includegraphics[width=0.3\\linewidth]{img3.png}\n    \\end{subfigure}\n\\end{figure}\n```\n\n</td>\n<td>\n\n```markdown\n.tableofcontents\n\n# Section\n\n## Subsection\n\n1. **First** item\n2. **Second** item\n\n.center\n    This text is _centered_.\n\n.row alignment:{spacebetween}\n    ![Image 1](img1.png)\n\n    ![Image 2](img2.png)\n    \n    ![Image 3](img3.png)\n```\n\n</td>\n</tr>\n</tbody>\n</table>\n\n&nbsp;\n\n# Getting started\n\n## Installation\n\n### Install script (Linux/macOS)\n\n```shell\ncurl -fsSL https://raw.githubusercontent.com/quarkdown-labs/get-quarkdown/refs/heads/main/install.sh | sudo env \"PATH=$PATH\" bash\n```\n\nRoot privileges let the script install Quarkdown into `/opt/quarkdown` and its wrapper script into `/usr/local/bin/quarkdown`.  \nIf missing, Java 17, Node.js and npm will be installed automatically using the system's package manager.\n\nFor more installation options, check out [get-quarkdown](https://github.com/quarkdown-labs/get-quarkdown).\n\n### Homebrew (Linux/macOS)\n\n```shell\nbrew install quarkdown-labs/quarkdown/quarkdown\n```\n\n### Scoop (Windows)\n\n```shell\nscoop bucket add java\nscoop bucket add quarkdown https://github.com/quarkdown-labs/scoop-quarkdown\nscoop install quarkdown\n```\n\n### GitHub Actions\n\nSee [setup-quarkdown](https://github.com/quarkdown-labs/setup-quarkdown) to easily integrate Quarkdown into your GitHub Actions workflows.\n\n### Manual installation\n\n<details>\n<summary>Instructions for manual installation</summary>\n\nDownload `quarkdown.zip` from the [latest stable release](https://github.com/iamgio/quarkdown/releases/latest) and unzip it,\nor build it with `gradlew installDist`.\n\nOptionally, adding `<install_dir>/bin` to your `PATH` allows you easier access Quarkdown.\n\nRequirements:\n- Java 17 or higher\n- (Only for PDF export) Node.js, npm, Puppeteer. See [*PDF export*](https://github.com/iamgio/quarkdown/wiki/PDF-export) for details.\n\n</details>\n\n&nbsp;\n\n## Quickstart ğŸ†•\n\nNew user? You'll find **everything you need** in the **[Quickstart guide](https://github.com/iamgio/quarkdown/wiki/quickstart)** to bring life to your first document!\n\n&nbsp;\n\n## Creating a project\n\n**`quarkdown create [directory]`** will launch the prompt-based project wizard, making it quicker than ever\nto set up a new Quarkdown project, with all [metadata](https://github.com/iamgio/quarkdown/wiki/document-metadata) and initial content already present.\n\nFor more information about the project creator, check out its [wiki page](https://github.com/iamgio/quarkdown/wiki/cli%3A-project-creator).\n\nAlternatively, you may manually create a `.qd` source file and start from there.\n\n&nbsp;\n\n## Compiling\n\nRunning **`quarkdown c file.qd`** will compile the given file and save the output to file.\n\n> If the project is composed by multiple source files, the target file must be the root one, i.e. the one that includes the other files.\n>\n> - [How to include other files?](https://github.com/iamgio/quarkdown/wiki/including-other-quarkdown-files)\n\nIf you would like to familiarize yourself with Quarkdown instead, `quarkdown repl` lets you play with an interactive REPL mode.\n\n#### Options\n\n- **`-p`** or **`--preview`**: enables automatic content reloading after compiling.  \n  If a [webserver](https://github.com/iamgio/quarkdown/wiki/cli%3A-webserver) is not running yet, it is started and the document is opened in the default browser.  \n  This is required in order to render paged documents in the browser.\n\n- **`-w`** or **`--watch`**: recompiles the source everytime a file from the source directory is changed.  \n  \n> [!TIP]\n> Combine `-p -w` to achieve ***live preview***!\n\n- **`--pdf`**: produces a PDF file. Learn more in the wiki's [*PDF export*](https://github.com/iamgio/quarkdown/wiki/pdf-export) page.\n\n- `-o <dir>` or `--out <dir>`: sets the directory of the output files. Defaults to `./output`.\n\n- `--out-name <name>`: sets the name of the output resource to be saved inside the output directory.\n  Defaults to the name of the document, set via [`.docname`](https://github.com/iamgio/quarkdown/wiki/document-metadata).  \n  *Note:* special characters will be replaced with dashes in the actual file name.\n\n- `-l <dir>` or `--libs <dir>`: sets the directory where external libraries can be loaded from. Defaults to `<install dir>/lib/qd`. [(?)](https://github.com/iamgio/quarkdown/wiki/importing-external-libraries)\n\n- `-r <renderer>` or `--render <renderer>`: sets the target renderer. Defaults to `html`. Accepted values:\n  - `html`\n  - `html-pdf` (equivalent to `-r html --pdf`)\n  - `text` (plain text)\n\n- `-b <browser>` or `--browser <browser>`: sets the browser to launch the preview with. Defaults to `default`. Accepted values:\n  - `default`\n  - `none`\n  - `chrome`\n  - `chromium`\n  - `firefox`\n  - `edge` (Windows only)\n  - Any other name, backed by the `BROWSER_<NAME>` environment variable\n  - A full path to a browser executable\n\n- `--server-port <port>`: optional customization of the local webserver's port. Defaults to `8089`.\n\n- `--pipe`: outputs the generated content to stdout instead of saving it to file and suppresses other logs,\n  useful for piping to other commands.\n\n- `--clean`: deletes the content of the output directory before producing new files. Destructive operation.\n\n- `--strict`: forces the program to exit if an error occurs. When not in strict mode, errors are shown as boxes in the document.\n\n- `--nowrap`: prevents the rendered output from being wrapped in a full document structure.\n  If enabled in HTML rendering, only the inner content of the `<body>` tag is produced.\n\n- `--pretty`: produces pretty output code. This is useful for debugging or to read the output code more easily,\n  but it should be disabled in production as the results might be visually affected.\n\n- `--no-media-storage`: turns the media storage system off. [(?)](https://github.com/iamgio/quarkdown/wiki/media-storage)\n\n- `--no-subdoc-collisions`: makes generated subdocument file names collision-proof. [(?)](https://github.com/iamgio/quarkdown/wiki/subdocuments)\n\n- `-Dloglevel=<level>` (JVM property): sets the log level. If set to `warning` or higher, the output content is not printed out.\n\n&nbsp;\n\n---\n\n&nbsp;\n\n## Mock document\n\n&nbsp;\n\n<p align=\"center\">\n  <img width=\"550\" src=\"https://raw.githubusercontent.com/iamgio/quarkdown/project-files/images/mock-demo.png\" alt=\"Mock document demo\">\n</p>\n\n***Mock***, written in Quarkdown, is a comprehensive collection of visual elements offered by the language,\nmaking it ideal for exploring and understanding its key features â€” all while playing and experimenting hands-on with a concrete outcome in the form of pages or slides.\n\n- The document's source files are available in the [`mock`](mock) directory, and can be compiled via `quarkdown c mock/main.qd -p`.\n- The PDF artifacts generated for all possible theme combinations are available and can be viewed in the [`generated`](https://github.com/iamgio/quarkdown/tree/generated/pdf/mock) branch.  \n\n## Contributing\n\nContributions are welcome! Please check [CONTRIBUTING.md](CONTRIBUTING.md) to know how contribute via issues or pull requests.\n\n## Sponsors\n\nA special thanks to all the sponsors who [supported this project](https://github.com/sponsors/iamgio)!\n\n<p align=\"center\">\n  <a href=\"https://falconer.ai\"><img src=\"https://media.licdn.com/dms/image/sync/v2/D5627AQEv-rlp3aPoUg/articleshare-shrink_800/articleshare-shrink_800/0/1742584632918?e=2147483647&v=beta&t=TlKe3D56q8e7V-G4j26cX3MV5nhza3Jhwy2O3yg20dE\" alt=\"Falconer\" width=\"350\"></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/RayOffiah\"><img src=\"https://avatars.githubusercontent.com/u/77050471?v=4\" alt=\"RayOffiah\" width=\"90\"></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/vitto4\"><img src=\"https://avatars.githubusercontent.com/u/128498605?v=4\" alt=\"vitto4\" width=\"60\"></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/LunaBluee\"><img src=\"https://avatars.githubusercontent.com/u/145209701?v=4\" alt=\"LunaBluee\" width=\"35\"></a>&nbsp;\n  <a href=\"https://github.com/dcopia\"><img src=\"https://avatars.githubusercontent.com/u/162327812?v=4\" alt=\"dcopia\" width=\"35\"></a>\n  <a href=\"https://github.com/Pallandos\"><img src=\"https://avatars.githubusercontent.com/u/146179143?v=4\" alt=\"Pallandos\" width=\"35\"></a>\n  <a href=\"https://github.com/imogenxingren\"><img src=\"https://avatars.githubusercontent.com/u/36161957?v=4\" alt=\"imogenxingren\" width=\"35\"></a>\n  <a href=\"https://github.com/serkonda7\"><img src=\"https://avatars.githubusercontent.com/u/40118727?v=4\" alt=\"serkonda7\" width=\"35\"></a>\n</p>\n\n## Concept\n\nThe logo resembles the original [Markdown icon](https://github.com/dcurtis/markdown-mark), with focus on Quarkdown's completeness,\nrichness of features and customization options, emphasized by the revolving arrow all around the sphere.\n\n<p align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/iamgio/quarkdown/project-files/images/ticon-light.svg\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://raw.githubusercontent.com/iamgio/quarkdown/project-files/images/ticon-dark.svg\">\n    <img alt=\"Quarkdown icon\" src=\"https://raw.githubusercontent.com/iamgio/quarkdown/project-files/images/ticon-dark.svg\">\n  </picture>\n</p>\n\nWhat could be mistaken for a planet is actually a **quark** or, more specifically, a **down quark**,\nan elementary particle that is a major constituent of matter: they give life to every complex structure we know of,\nwhile also being one of the lightest objects in existence.\n\nThis is, indeed, the concept **Quarkdown** is built upon. \n\n## License\n\nBy default, Quarkdown and its modules are licensed under [GNU GPLv3](./LICENSE), except for modules that include their own `LICENSE` file:\nthe CLI (`quarkdown-cli`) and Language Server (`quarkdown-lsp`) modules and binaries are licensed under GNU AGPLv3.\n",
      "stars_today": 6
    },
    {
      "id": 1016267036,
      "name": "bitchat-android",
      "full_name": "permissionlesstech/bitchat-android",
      "description": "bluetooth mesh chat, IRC vibes",
      "html_url": "https://github.com/permissionlesstech/bitchat-android",
      "stars": 4684,
      "forks": 659,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2025-07-08T18:36:23Z",
      "updated_at": "2026-02-06T23:37:19Z",
      "pushed_at": "2026-02-03T14:33:59Z",
      "open_issues": 238,
      "owner": {
        "login": "permissionlesstech",
        "avatar_url": "https://avatars.githubusercontent.com/u/220183803?v=4"
      },
      "readme": "<p align=\"center\">\n    <img src=\"https://github.com/user-attachments/assets/188c42f8-d249-4a72-b27a-e2b4f10a00a8\" alt=\"Bitchat Android Logo\" width=\"480\">\n</p>\n\n> [!WARNING]\n> This software has not received external security review and may contain vulnerabilities and may not necessarily meet its stated security goals. Do not use it for sensitive use cases, and do not rely on its security until it has been reviewed. Work in progress.\n\n# bitchat for Android\n\nA secure, decentralized, peer-to-peer messaging app that works over Bluetooth mesh networks. No internet required for mesh chats, no servers, no phone numbers - just pure encrypted communication. Bitchat also supports geohash channels, which use an internet connection to connect you with others in your geographic area.\n\nThis is the **Android port** of the original [bitchat iOS app](https://github.com/jackjackbits/bitchat), maintaining 100% protocol compatibility for cross-platform communication.\n\n## Install bitchat\n\nYou can download the latest version of bitchat for Android from the [GitHub Releases page](https://github.com/permissionlesstech/bitchat-android/releases).\n\nOr you can:\n\n[<img alt=\"Get it on Google Play\" height=\"60\" src=\"https://play.google.com/intl/en_us/badges/static/images/badges/en_badge_web_generic.png\"/>](https://play.google.com/store/apps/details?id=com.bitchat.droid)\n\n**Instructions:**\n\n1.  **Download the APK:** On your Android device, navigate to the link above and download the latest `.apk` file. Open it.\n2.  **Allow Unknown Sources:** On some devices, before you can install the APK, you may need to enable \"Install from unknown sources\" in your device's settings. This is typically found under **Settings > Security** or **Settings > Apps & notifications > Special app access**.\n3.  **Install:** Open the downloaded `.apk` file to begin the installation.\n\n## License\n\nThis project is released into the public domain. See the [LICENSE](LICENSE.md) file for details.\n\n## Features\n\n- **âœ… Cross-Platform Compatible**: Full protocol compatibility with iOS bitchat\n- **âœ… Decentralized Mesh Network**: Automatic peer discovery and multi-hop message relay over Bluetooth LE\n- **âœ… End-to-End Encryption**: X25519 key exchange + AES-256-GCM for private messages\n- **âœ… Channel-Based Chats**: Topic-based group messaging with optional password protection\n- **âœ… Store & Forward**: Messages cached for offline peers and delivered when they reconnect\n- **âœ… Privacy First**: No accounts, no phone numbers, no persistent identifiers\n- **âœ… IRC-Style Commands**: Familiar `/join`, `/msg`, `/who` style interface\n- **âœ… Message Retention**: Optional channel-wide message saving controlled by channel owners\n- **âœ… Emergency Wipe**: Triple-tap logo to instantly clear all data\n- **âœ… Modern Android UI**: Jetpack Compose with Material Design 3\n- **âœ… Dark/Light Themes**: Terminal-inspired aesthetic matching iOS version\n- **âœ… Battery Optimization**: Adaptive scanning and power management\n\n## Android Setup\n\n### Prerequisites\n\n- **Android Studio**: Arctic Fox (2020.3.1) or newer\n- **Android SDK**: API level 26 (Android 8.0) or higher\n- **Kotlin**: 1.8.0 or newer\n- **Gradle**: 7.0 or newer\n\n### Build Instructions\n\n1. **Clone the repository:**\n   ```bash\n   git clone https://github.com/permissionlesstech/bitchat-android.git\n   cd bitchat-android\n   ```\n\n2. **Open in Android Studio:**\n   ```bash\n   # Open Android Studio and select \"Open an Existing Project\"\n   # Navigate to the bitchat-android directory\n   ```\n\n3. **Build the project:**\n   ```bash\n   ./gradlew build\n   ```\n\n4. **Install on device:**\n   ```bash\n   ./gradlew installDebug\n   ```\n\n### Development Build\n\nFor development builds with debugging enabled:\n\n```bash\n./gradlew assembleDebug\nadb install -r app/build/outputs/apk/debug/app-debug.apk\n```\n\n### Release Build\n\nFor production releases:\n\n```bash\n./gradlew assembleRelease\n```\n\n## Android-Specific Requirements\n\n### Permissions\n\nThe app requires the following permissions (automatically requested):\n\n- **Bluetooth**: Core BLE functionality\n- **Location**: Required for BLE scanning on Android\n- **Network**: Expand your mesh through public internet relays\n- **Notifications**: Message alerts and background updates\n\n### Hardware Requirements\n\n- **Bluetooth LE (BLE)**: Required for mesh networking\n- **Android 8.0+**: API level 26 minimum\n- **RAM**: 2GB recommended for optimal performance\n\n## Usage\n\n### Basic Commands\n\n- `/j #channel` - Join or create a channel\n- `/m @name message` - Send a private message\n- `/w` - List online users\n- `/channels` - Show all discovered channels\n- `/block @name` - Block a peer from messaging you\n- `/block` - List all blocked peers\n- `/unblock @name` - Unblock a peer\n- `/clear` - Clear chat messages\n- `/pass [password]` - Set/change channel password (owner only)\n- `/transfer @name` - Transfer channel ownership\n- `/save` - Toggle message retention for channel (owner only)\n\n### Getting Started\n\n1. **Install the app** on your Android device (requires Android 8.0+)\n2. **Grant permissions** for Bluetooth and location when prompted\n3. **Launch bitchat** - it will auto-start mesh networking\n4. **Set your nickname** or use the auto-generated one\n5. **Connect automatically** to nearby iOS and Android bitchat users\n6. **Join a channel** with `/j #general` or start chatting in public\n7. **Messages relay** through the mesh network to reach distant peers\n\n### Android UI Features\n\n- **Jetpack Compose UI**: Modern Material Design 3 interface\n- **Dark/Light Themes**: Terminal-inspired aesthetic matching iOS\n- **Haptic Feedback**: Vibrations for interactions and notifications\n- **Adaptive Layout**: Optimized for various Android screen sizes\n- **Message Status**: Real-time delivery and read receipts\n- **RSSI Indicators**: Signal strength colors for each peer\n\n### Channel Features\n\n- **Password Protection**: Channel owners can set passwords with `/pass`\n- **Message Retention**: Owners can enable mandatory message saving with `/save`\n- **@ Mentions**: Use `@nickname` to mention users (with autocomplete)\n- **Ownership Transfer**: Pass control to trusted users with `/transfer`\n\n## Security & Privacy\n\n### Encryption\n- **Private Messages**: X25519 key exchange + AES-256-GCM encryption\n- **Channel Messages**: Argon2id password derivation + AES-256-GCM\n- **Digital Signatures**: Ed25519 for message authenticity\n- **Forward Secrecy**: New key pairs generated each session\n\n### Privacy Features\n- **No Registration**: No accounts, emails, or phone numbers required\n- **Ephemeral by Default**: Messages exist only in device memory\n- **Cover Traffic**: Random delays and dummy messages prevent traffic analysis\n- **Emergency Wipe**: Triple-tap logo to instantly clear all data\n- **Bundled Tor Support**: Built-in Tor network integration for enhanced privacy when internet connectivity is available\n\n## Performance & Efficiency\n\n### Message Compression\n- **LZ4 Compression**: Automatic compression for messages >100 bytes\n- **30-70% bandwidth savings** on typical text messages\n- **Smart compression**: Skips already-compressed data\n\n### Battery Optimization\n- **Adaptive Power Modes**: Automatically adjusts based on battery level\n  - Performance mode: Full features when charging or >60% battery\n  - Balanced mode: Default operation (30-60% battery)\n  - Power saver: Reduced scanning when <30% battery\n  - Ultra-low power: Emergency mode when <10% battery\n- **Background efficiency**: Automatic power saving when app backgrounded\n- **Configurable scanning**: Duty cycle adapts to battery state\n\n### Network Efficiency\n- **Optimized Bloom filters**: Faster duplicate detection with less memory\n- **Message aggregation**: Batches small messages to reduce transmissions\n- **Adaptive connection limits**: Adjusts peer connections based on power mode\n\n## Technical Architecture\n\n### Binary Protocol\nbitchat uses an efficient binary protocol optimized for Bluetooth LE:\n- Compact packet format with 1-byte type field\n- TTL-based message routing (max 7 hops)\n- Automatic fragmentation for large messages\n- Message deduplication via unique IDs\n\n### Mesh Networking\n- Each device acts as both client and peripheral\n- Automatic peer discovery and connection management\n- Store-and-forward for offline message delivery\n- Adaptive duty cycling for battery optimization\n\n### Android-Specific Optimizations\n- **Coroutine Architecture**: Asynchronous operations for mesh networking\n- **Kotlin Coroutines**: Thread-safe concurrent mesh operations\n- **EncryptedSharedPreferences**: Secure storage for user settings\n- **Lifecycle-Aware**: Proper handling of Android app lifecycle\n- **Battery Optimization**: Foreground service and adaptive scanning\n\n## Android Technical Architecture\n\n### Core Components\n\n1. **BitchatApplication.kt**: Application-level initialization and dependency injection\n2. **MainActivity.kt**: Main activity handling permissions and UI hosting\n3. **ChatViewModel.kt**: MVVM pattern managing app state and business logic\n4. **BluetoothMeshService.kt**: Core BLE mesh networking (central + peripheral roles)\n5. **EncryptionService.kt**: Cryptographic operations using BouncyCastle\n6. **BinaryProtocol.kt**: Binary packet encoding/decoding matching iOS format\n7. **ChatScreen.kt**: Jetpack Compose UI with Material Design 3\n\n### Dependencies\n\n- **Jetpack Compose**: Modern declarative UI\n- **BouncyCastle**: Cryptographic operations (X25519, Ed25519, AES-GCM)\n- **Nordic BLE Library**: Reliable Bluetooth LE operations\n- **Kotlin Coroutines**: Asynchronous programming\n- **LZ4**: Message compression (when enabled)\n- **EncryptedSharedPreferences**: Secure local storage\n\n### Binary Protocol Compatibility\n\nThe Android implementation maintains 100% binary protocol compatibility with iOS:\n- **Header Format**: Identical 13-byte header structure\n- **Packet Types**: Same message types and routing logic\n- **Encryption**: Identical cryptographic algorithms and key exchange\n- **UUIDs**: Same Bluetooth service and characteristic identifiers\n- **Fragmentation**: Compatible message fragmentation for large content\n\n## Publishing to Google Play\n\n### Preparation\n\n1. **Update version information:**\n   ```kotlin\n   // In app/build.gradle.kts\n   defaultConfig {\n       versionCode = 2  // Increment for each release\n       versionName = \"1.1.0\"  // User-visible version\n   }\n   ```\n\n2. **Create a signed release build:**\n   ```bash\n   ./gradlew assembleRelease\n   ```\n\n3. **Generate app bundle (recommended for Play Store):**\n   ```bash\n   ./gradlew bundleRelease\n   ```\n\n### Play Store Requirements\n\n- **Target API**: Latest Android API (currently 34)\n- **Privacy Policy**: Required for apps requesting sensitive permissions\n- **App Permissions**: Justify Bluetooth and location usage\n- **Content Rating**: Complete questionnaire for age-appropriate content\n\n### Distribution\n\n- **Google Play Store**: Main distribution channel\n- **F-Droid**: For open-source distribution\n- **Direct APK**: For testing and development\n\n## Cross-Platform Communication\n\nThis Android port enables seamless communication with the original iOS bitchat app:\n\n- **iPhone â†” Android**: Full bidirectional messaging\n- **Mixed Groups**: iOS and Android users in same channels\n- **Feature Parity**: All commands and encryption work across platforms\n- **Protocol Sync**: Identical message format and routing behavior\n\n**iOS Version**: For iPhone/iPad users, get the original bitchat at [github.com/jackjackbits/bitchat](https://github.com/jackjackbits/bitchat)\n\n## Contributing\n\nContributions are welcome! Key areas for enhancement:\n\n1. **Performance**: Battery optimization and connection reliability\n2. **UI/UX**: Additional Material Design 3 features\n3. **Security**: Enhanced cryptographic features\n4. **Testing**: Unit and integration test coverage\n5. **Documentation**: API documentation and development guides\n\n## Support & Issues\n\n- **Bug Reports**: [Create an issue](../../issues) with device info and logs\n- **Feature Requests**: [Start a discussion](https://github.com/orgs/permissionlesstech/discussions)\n- **Security Issues**: Email security concerns privately\n- **iOS Compatibility**: Cross-reference with [original iOS repo](https://github.com/jackjackbits/bitchat)\n\nFor iOS-specific issues, please refer to the [original iOS bitchat repository](https://github.com/jackjackbits/bitchat).\n",
      "stars_today": 6
    },
    {
      "id": 245352386,
      "name": "FEX",
      "full_name": "FEX-Emu/FEX",
      "description": "A fast usermode x86 and x86-64 emulator for Arm64 Linux",
      "html_url": "https://github.com/FEX-Emu/FEX",
      "stars": 6801,
      "forks": 245,
      "language": "C++",
      "topics": [
        "arm64",
        "cpp",
        "emulation",
        "emulator",
        "linux",
        "x86",
        "x86-64"
      ],
      "created_at": "2020-03-06T07:07:03Z",
      "updated_at": "2026-02-07T00:28:50Z",
      "pushed_at": "2026-02-05T19:35:28Z",
      "open_issues": 217,
      "owner": {
        "login": "FEX-Emu",
        "avatar_url": "https://avatars.githubusercontent.com/u/61863475?v=4"
      },
      "readme": "[ä¸­æ–‡](https://github.com/FEX-Emu/FEX/blob/main/docs/Readme_CN.md)\n# FEX: Emulate x86 Programs on ARM64\nFEX allows you to run x86 applications on ARM64 Linux devices, similar to qemu-user and box64.\nIt offers broad compatibility with both 32-bit and 64-bit binaries, and it can be used alongside Wine/Proton to play Windows games.\n\nIt supports forwarding API calls to host system libraries like OpenGL or Vulkan to reduce emulation overhead.\nAn experimental code cache helps minimize in-game stuttering as much as possible.\nFurthermore, a per-app configuration system allows tweaking performance per game, e.g. by skipping costly memory model emulation.\nWe also provide a user-friendly FEXConfig GUI to explore and change these settings.\n\n## Prerequisites\nFEX requires ARMv8.0+ hardware. It has been tested with the following Linux distributions, though others are likely to work as well:\n\n- Arch Linux\n- Fedora Linux\n- openSUSE\n- Ubuntu 22.04/24.04/24.10/25.04\n\nAn x86-64 RootFS is required and can be downloaded using our `FEXRootFSFetcher` tool for many distributions.\nFor other distributions you will need to generate your own RootFS (our [wiki page](https://wiki.fex-emu.com/index.php/Development:Setting_up_RootFS) might help).\n\n## Quick Start\n### For Ubuntu 22.04, 24.04, 24.10 and 25.04\nExecute the following command in the terminal to install FEX through a PPA.\n\n```sh\ncurl --silent https://raw.githubusercontent.com/FEX-Emu/FEX/main/Scripts/InstallFEX.py | python3\n```\n\nThis command will walk you through installing FEX through a PPA, and downloading a RootFS for use with FEX.\n\n### For other Distributions\nFollow the guide on the official FEX-Emu Wiki [here](https://wiki.fex-emu.com/index.php/Development:Setting_up_FEX).\n\n### Navigating the Source\nSee the [Source Outline](docs/SourceOutline.md) for more information.\n",
      "stars_today": 6
    },
    {
      "id": 646423,
      "name": "pgbouncer",
      "full_name": "pgbouncer/pgbouncer",
      "description": "lightweight connection pooler for PostgreSQL",
      "html_url": "https://github.com/pgbouncer/pgbouncer",
      "stars": 3898,
      "forks": 537,
      "language": "C",
      "topics": [
        "postgresql"
      ],
      "created_at": "2010-05-04T10:39:40Z",
      "updated_at": "2026-02-06T19:53:03Z",
      "pushed_at": "2026-01-25T19:03:53Z",
      "open_issues": 274,
      "owner": {
        "login": "pgbouncer",
        "avatar_url": "https://avatars.githubusercontent.com/u/11858179?v=4"
      },
      "readme": "PgBouncer\n=========\n\nLightweight connection pooler for PostgreSQL.\n\nHomepage: <https://www.pgbouncer.org/>\n\nSources, bug tracking: <https://github.com/pgbouncer/pgbouncer>\n\nBuilding\n---------\n\nPgBouncer depends on few things to get compiled:\n\n* [GNU Make] 3.81+\n* [Libevent] 2.0+\n* [pkg-config]\n* [OpenSSL] 1.0.1+ for TLS support\n* (optional) [c-ares] as alternative to Libevent's evdns\n* (optional) LDAP libraries\n* (optional) PAM libraries\n\n[GNU Make]: https://www.gnu.org/software/make/\n[Libevent]: http://libevent.org/\n[pkg-config]: https://www.freedesktop.org/wiki/Software/pkg-config/\n[OpenSSL]: https://www.openssl.org/\n[c-ares]: http://c-ares.haxx.se/\n\nWhen dependencies are installed just run:\n\n    $ ./configure --prefix=/usr/local\n    $ make\n    $ make install\n\nIf you are building from Git, or are building for Windows, please see\nseparate build instructions below.\n\nDNS lookup support\n------------------\n\nPgBouncer does host name lookups at connect time instead of just once\nat configuration load time.  This requires an asynchronous DNS\nimplementation.  The following table shows supported backends and\ntheir probing order:\n\n| backend                    | parallel | EDNS0 (1) | /etc/hosts | SOA lookup (2) | note                                  |\n|----------------------------|----------|-----------|------------|----------------|---------------------------------------|\n| c-ares                     | yes      | yes       | yes        | yes            | IPv6+CNAME buggy in <=1.10            |\n| evdns, libevent 2.x        | yes      | no        | yes        | no             | does not check /etc/hosts updates     |\n| getaddrinfo_a, glibc 2.9+  | yes      | yes (3)   | yes        | no             | N/A on non-glibc                      |\n| getaddrinfo, libc          | no       | yes (3)   | yes        | no             | requires pthreads                     |\n\n1. EDNS0 is required to have more than 8 addresses behind one host name.\n2. SOA lookup is needed to re-check host names on zone serial change.\n3. To enable EDNS0, add `options edns0` to `/etc/resolv.conf`.\n\nc-ares is the most fully-featured implementation and is recommended\nfor most uses and binary packaging (if a sufficiently new version is\navailable).  Libevent's built-in evdns is also suitable for many uses,\nwith the listed restrictions.  The other backends are mostly legacy\noptions at this point and don't receive much testing anymore.\n\nBy default, c-ares is used if it can be found.  Its use can be forced\nwith `configure --with-cares` or disabled with `--without-cares`.  If\nc-ares is not used (not found or disabled), then Libevent is used.  Specify\n`--disable-evdns` to disable the use of Libevent's evdns and fall back to a\nlibc-based implementation.\n\nPAM authentication\n------------------\n\nTo enable PAM authentication, `./configure` has a flag `--with-pam`\n(default value is no).  When compiled with PAM support, a new global\nauthentication type `pam` is available to validate users through PAM.\n\nLDAP authentication\n------------------\n\nTo enable LDAP authentication, `./configure` has a flag `--with-ldap`\n(default value is no).  When compiled with LDAP support, a new global\nauthentication type `ldap` is available to validate users through LDAP.\n\nsystemd integration\n-------------------\n\nTo enable systemd integration, use the `configure` option\n`--with-systemd`.  This allows using `Type=notify` (or `Type=notify-reload` if\nyou are using systemd 253 or later) as well as socket activation.  See\n`etc/pgbouncer.service` and `etc/pgbouncer.socket` for examples.\n\nBuilding from Git\n-----------------\n\nBuilding PgBouncer from Git requires that you generate the header and\nconfiguration files before you can run `configure`:\n\n\t$ git clone https://github.com/pgbouncer/pgbouncer.git\n\t$ cd pgbouncer\n\t$ ./autogen.sh\n\t$ ./configure\n\t$ make\n\t$ make install\n\nAll files will be installed under `/usr/local` by default. You can\nsupply one or more command-line options to `configure`. Run\n`./configure --help` to list the available options and the environment\nvariables that customizes the configuration.\n\nAdditional packages required: autoconf, automake, libtool, pandoc\n\nTesting\n-------\n\nSee the [`README.md` file in the test directory][1] on how to run the tests.\n\n[1]: https://github.com/pgbouncer/pgbouncer/blob/master/test/README.md\n\nBuilding on Windows\n-------------------\n\nThe only supported build environment on Windows is MinGW.  Cygwin and\nVisual $ANYTHING are not supported.\n\nTo build on MinGW, do the usual:\n\n\t$ ./configure\n\t$ make\n\nIf cross-compiling from Unix:\n\n\t$ ./configure --host=i586-mingw32msvc\n\nThe LDAP build option is currently not supported on Windows.\n\nRunning on Windows\n------------------\n\nRunning from the command line goes as usual, except that the `-d` (daemonize),\n`-R` (reboot), and `-u` (switch user) switches will not work.\n\nTo run PgBouncer as a Windows service, you need to configure the\n`service_name` parameter to set a name for the service.  Then:\n\n\t$ pgbouncer -regservice config.ini\n\nTo uninstall the service:\n\n\t$ pgbouncer -unregservice config.ini\n\nTo use the Windows event log, set `syslog = 1` in the configuration file.\nBut before that, you need to register `pgbevent.dll`:\n\n\t$ regsvr32 pgbevent.dll\n\nTo unregister it, do:\n\n\t$ regsvr32 /u pgbevent.dll\n",
      "stars_today": 6
    },
    {
      "id": 631431061,
      "name": "gravitino",
      "full_name": "apache/gravitino",
      "description": "World's most powerful open data catalog for building a high-performance, geo-distributed and federated metadata lake.",
      "html_url": "https://github.com/apache/gravitino",
      "stars": 2769,
      "forks": 722,
      "language": "Java",
      "topics": [
        "ai-catalog",
        "data-catalog",
        "datalake",
        "federated-query",
        "lakehouse",
        "metadata",
        "metalake",
        "model-catalog",
        "opendatacatalog",
        "skycomputing",
        "stratosphere"
      ],
      "created_at": "2023-04-23T02:09:00Z",
      "updated_at": "2026-02-07T01:23:15Z",
      "pushed_at": "2026-02-06T15:10:56Z",
      "open_issues": 825,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "<!--\n  Licensed to the Apache Software Foundation (ASF) under one\n  or more contributor license agreements.  See the NOTICE file\n  distributed with this work for additional information\n  regarding copyright ownership.  The ASF licenses this file\n  to you under the Apache License, Version 2.0 (the\n  \"License\"); you may not use this file except in compliance\n  with the License.  You may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing,\n  software distributed under the License is distributed on an\n  \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n  KIND, either express or implied.  See the License for the\n  specific language governing permissions and limitations\n  under the License.\n-->\n\n# Apache Gravitinoâ„¢\n\n[![GitHub Actions Build](https://github.com/apache/gravitino/actions/workflows/build.yml/badge.svg)](https://github.com/apache/gravitino/actions/workflows/build.yml)\n[![GitHub Actions Integration Test](https://github.com/apache/gravitino/actions/workflows/integration-test.yml/badge.svg)](https://github.com/apache/gravitino/actions/workflows/integration-test.yml)\n[![License](https://img.shields.io/github/license/apache/gravitino)](https://github.com/apache/gravitino/blob/main/LICENSE)\n[![Contributors](https://img.shields.io/github/contributors/apache/gravitino)](https://github.com/apache/gravitino/graphs/contributors)\n[![Release](https://img.shields.io/github/v/release/apache/gravitino)](https://github.com/apache/gravitino/releases)\n[![Open Issues](https://img.shields.io/github/issues-raw/apache/gravitino)](https://github.com/apache/gravitino/issues)\n[![Last Committed](https://img.shields.io/github/last-commit/apache/gravitino)](https://github.com/apache/gravitino/commits/main/)\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/8358/badge)](https://www.bestpractices.dev/projects/8358)\n\n## Introduction\n\nApache Gravitino is a high-performance, geo-distributed, and federated metadata lake. It manages metadata directly in different sources, types, and regions, providing users with unified metadata access for data and AI assets.\n\n![Gravitino Architecture](docs/assets/gravitino-architecture.png)\n\n## ğŸš€ Key Features\n\n- **Unified Metadata Management**: Manage diverse metadata sources through a single model and API (e.g., Hive, MySQL, HDFS, S3).\n- **End-to-End Data Governance**: Features like access control, auditing, and discovery across all metadata assets.\n- **Direct Metadata Integration**: Changes in underlying systems are immediately reflected via Gravitinoâ€™s connectors.\n- **Geo-Distribution Support**: Share metadata across regions and clouds to support global architectures.\n- **Multi-Engine Compatibility**: Seamlessly integrates with query engines without modifying SQL dialects.\n- **AI Asset Management (WIP)**: Support for AI model and feature tracking.\n\n## ğŸŒ Common Use Cases\n\n- Federated metadata discovery across data lakes and data warehouses\n- Multi-region metadata synchronization for hybrid or multi-cloud setups\n- Data and AI asset governance with unified audit and access control\n- Plug-and-play access for engines like Trino or Spark\n- Support for evolving metadata standards, including AI model lineage\n\n## ğŸ“š Documentation\n\nThe latest Gravitino documentation is available at [gravitino.apache.org/docs/latest](https://gravitino.apache.org/docs/latest/).\n\nThis README provides a basic overview; visit the site for full installation, configuration, and development documentation.\n\n## ğŸ§ª Quick Start\n\n### Use Gravitino Playground (Recommended)\n\nGravitino provides a Docker Composeâ€“based playground for a full-stack experience.  \nClone or download the [Gravitino Playground repository](https://github.com/apache/gravitino-playground) and follow its [README](https://github.com/apache/gravitino-playground/blob/main/README.md).\n\n### Run Gravitino Locally\n\n1. [Download](https://gravitino.apache.org/downloads) and extract a binary release.\n2. Edit `conf/gravitino.conf` to configure settings.\n3. Start the server:\n\n```bash\n./bin/gravitino.sh start\n```\n\n4. To stop:\n\n```bash\n./bin/gravitino.sh stop\n```\n\nPress `CTRL+C` to stop.\n\n## ğŸ§Š Iceberg REST Catalog\n\nGravitino provides a native Iceberg REST catalog service.  \nSee: [Iceberg REST catalog service](https://gravitino.apache.org/docs/latest/iceberg-rest-service/)\n\n## ğŸ—„ï¸ Lance REST Catalog\n\nGravitino provides a native Lance REST catalog service.  \nSee: [Lance REST catalog service](https://gravitino.apache.org/docs/latest/lance-rest-service/)\n\n## ğŸ”Œ Trino Integration\n\nGravitino includes a Trino connector for federated metadata access.  \nSee: [Using Trino with Gravitino](https://gravitino.apache.org/docs/latest/trino-connector/index/)\n\n## ğŸ› ï¸ Building from Source\n\nGravitino uses Gradle. Windows is not currently supported.\n\nClean build without tests:\n\n```bash\n./gradlew clean build -x test\n```\n\nBuild a distribution:\n\n```bash\n./gradlew compileDistribution -x test\n```\n\nOr compressed package:\n\n```bash\n./gradlew assembleDistribution -x test\n```\n\nArtifacts are output to the `distribution/` directory.\n\nMore build options: [How to build Gravitino](https://gravitino.apache.org/docs/latest/how-to-build/)\n\n## ğŸ‘¨â€ğŸ’» Developer Resources\n\n- [How to build Gravitino](https://gravitino.apache.org/docs/latest/how-to-build/)\n- [How to test Gravitino](https://gravitino.apache.org/docs/latest/how-to-test/)\n- [Publish Docker images](https://gravitino.apache.org/docs/latest/publish-docker-images)\n\n## ğŸ¤ Contributing\n\nWe welcome all kinds of contributionsâ€”code, documentation, testing, connectors, and more!\n\nTo get started, please read our [CONTRIBUTING.md](CONTRIBUTING.md) guide.\n\n## ğŸ”— ASF Resources\n\n- ğŸ“¬ Mailing List: [dev@gravitino.apache.org](mailto:dev@gravitino.apache.org) ([subscribe](mailto:dev-subscribe@gravitino.apache.org))\n- ğŸ Issue Tracker: [GitHub Issues](https://github.com/apache/gravitino/issues)\n\n## ğŸªª License\n\nApache Gravitino is licensed under the Apache License, Version 2.0.  \nSee the [LICENSE](LICENSE) file for details.\n\n<sub>ApacheÂ®, Apache Gravitinoâ„¢, Apache HadoopÂ®, Apache Hiveâ„¢, Apache Icebergâ„¢, Apache KafkaÂ®, Apache Sparkâ„¢, Apache Submarineâ„¢, Apache Thriftâ„¢, and Apache Zeppelinâ„¢ are trademarks of the Apache Software Foundation in the United States and/or other countries.</sub>\n\n<img src=\"https://analytics.apache.org/matomo.php?idsite=62&rec=1&bots=1&action_name=ReadMe\" style=\"border:0;\" alt=\"\" />\n",
      "stars_today": 6
    },
    {
      "id": 39840932,
      "name": "googletest",
      "full_name": "google/googletest",
      "description": "GoogleTest - Google Testing and Mocking Framework",
      "html_url": "https://github.com/google/googletest",
      "stars": 38190,
      "forks": 10685,
      "language": "C++",
      "topics": [],
      "created_at": "2015-07-28T15:07:53Z",
      "updated_at": "2026-02-06T22:54:48Z",
      "pushed_at": "2026-02-05T16:44:02Z",
      "open_issues": 515,
      "owner": {
        "login": "google",
        "avatar_url": "https://avatars.githubusercontent.com/u/1342004?v=4"
      },
      "readme": "# GoogleTest\n\n### Announcements\n\n#### Documentation Updates\n\nOur documentation is now live on GitHub Pages at\nhttps://google.github.io/googletest/. We recommend browsing the documentation on\nGitHub Pages rather than directly in the repository.\n\n#### Release 1.17.0\n\n[Release 1.17.0](https://github.com/google/googletest/releases/tag/v1.17.0) is\nnow available.\n\nThe 1.17.x branch\n[requires at least C++17](https://opensource.google/documentation/policies/cplusplus-support#c_language_standard).\n\n#### Continuous Integration\n\nWe use Google's internal systems for continuous integration.\n\n#### Coming Soon\n\n*   We are planning to take a dependency on\n    [Abseil](https://github.com/abseil/abseil-cpp).\n\n## Welcome to **GoogleTest**, Google's C++ test framework!\n\nThis repository is a merger of the formerly separate GoogleTest and GoogleMock\nprojects. These were so closely related that it makes sense to maintain and\nrelease them together.\n\n### Getting Started\n\nSee the [GoogleTest User's Guide](https://google.github.io/googletest/) for\ndocumentation. We recommend starting with the\n[GoogleTest Primer](https://google.github.io/googletest/primer.html).\n\nMore information about building GoogleTest can be found at\n[googletest/README.md](googletest/README.md).\n\n## Features\n\n*   xUnit test framework: \\\n    Googletest is based on the [xUnit](https://en.wikipedia.org/wiki/XUnit)\n    testing framework, a popular architecture for unit testing\n*   Test discovery: \\\n    Googletest automatically discovers and runs your tests, eliminating the need\n    to manually register your tests\n*   Rich set of assertions: \\\n    Googletest provides a variety of assertions, such as equality, inequality,\n    exceptions, and more, making it easy to test your code\n*   User-defined assertions: \\\n    You can define your own assertions with Googletest, making it simple to\n    write tests that are specific to your code\n*   Death tests: \\\n    Googletest supports death tests, which verify that your code exits in a\n    certain way, making it useful for testing error-handling code\n*   Fatal and non-fatal failures: \\\n    You can specify whether a test failure should be treated as fatal or\n    non-fatal with Googletest, allowing tests to continue running even if a\n    failure occurs\n*   Value-parameterized tests: \\\n    Googletest supports value-parameterized tests, which run multiple times with\n    different input values, making it useful for testing functions that take\n    different inputs\n*   Type-parameterized tests: \\\n    Googletest also supports type-parameterized tests, which run with different\n    data types, making it useful for testing functions that work with different\n    data types\n*   Various options for running tests: \\\n    Googletest provides many options for running tests including running\n    individual tests, running tests in a specific order and running tests in\n    parallel\n\n## Supported Platforms\n\nGoogleTest follows Google's\n[Foundational C++ Support Policy](https://opensource.google/documentation/policies/cplusplus-support).\nSee\n[this table](https://github.com/google/oss-policies-info/blob/main/foundational-cxx-support-matrix.md)\nfor a list of currently supported versions of compilers, platforms, and build\ntools.\n\n## Who Is Using GoogleTest?\n\nIn addition to many internal projects at Google, GoogleTest is also used by the\nfollowing notable projects:\n\n*   The [Chromium projects](https://www.chromium.org/) (behind the Chrome\n    browser and Chrome OS).\n*   The [LLVM](https://llvm.org/) compiler.\n*   [Protocol Buffers](https://github.com/google/protobuf), Google's data\n    interchange format.\n*   The [OpenCV](https://opencv.org/) computer vision library.\n\n## Related Open Source Projects\n\n[GTest Runner](https://github.com/nholthaus/gtest-runner) is a Qt5 based\nautomated test-runner and Graphical User Interface with powerful features for\nWindows and Linux platforms.\n\n[GoogleTest UI](https://github.com/ospector/gtest-gbar) is a test runner that\nruns your test binary, allows you to track its progress via a progress bar, and\ndisplays a list of test failures. Clicking on one shows failure text. GoogleTest\nUI is written in C#.\n\n[GTest TAP Listener](https://github.com/kinow/gtest-tap-listener) is an event\nlistener for GoogleTest that implements the\n[TAP protocol](https://en.wikipedia.org/wiki/Test_Anything_Protocol) for test\nresult output. If your test runner understands TAP, you may find it useful.\n\n[gtest-parallel](https://github.com/google/gtest-parallel) is a test runner that\nruns tests from your binary in parallel to provide significant speed-up.\n\n[GoogleTest Adapter](https://marketplace.visualstudio.com/items?itemName=DavidSchuldenfrei.gtest-adapter)\nis a VS Code extension allowing to view GoogleTest in a tree view and run/debug\nyour tests.\n\n[C++ TestMate](https://github.com/matepek/vscode-catch2-test-adapter) is a VS\nCode extension allowing to view GoogleTest in a tree view and run/debug your\ntests.\n\n[Cornichon](https://pypi.org/project/cornichon/) is a small Gherkin DSL parser\nthat generates stub code for GoogleTest.\n\n## Contributing Changes\n\nPlease read\n[`CONTRIBUTING.md`](https://github.com/google/googletest/blob/main/CONTRIBUTING.md)\nfor details on how to contribute to this project.\n\nHappy testing!\n",
      "stars_today": 5
    },
    {
      "id": 669686044,
      "name": "llama2.c",
      "full_name": "karpathy/llama2.c",
      "description": "Inference Llama 2 in one file of pure C",
      "html_url": "https://github.com/karpathy/llama2.c",
      "stars": 19154,
      "forks": 2444,
      "language": "C",
      "topics": [],
      "created_at": "2023-07-23T05:15:06Z",
      "updated_at": "2026-02-06T22:50:21Z",
      "pushed_at": "2024-08-06T09:44:40Z",
      "open_issues": 184,
      "owner": {
        "login": "karpathy",
        "avatar_url": "https://avatars.githubusercontent.com/u/241138?v=4"
      },
      "readme": "## llama2.c\n\n<p align=\"center\">\n  <img src=\"assets/llama_cute.jpg\" width=\"300\" height=\"300\" alt=\"Cute Llama\">\n</p>\n\nHave you ever wanted to inference a baby [Llama 2](https://ai.meta.com/llama/) model in pure C? No? Well, now you can!\n\nTrain the Llama 2 LLM architecture in PyTorch then inference it with one simple 700-line C file ([run.c](run.c)). You might think that you need many billion parameter LLMs to do anything useful, but in fact very small LLMs can have surprisingly strong performance if you make the domain narrow enough (ref: [TinyStories](https://huggingface.co/datasets/roneneldan/TinyStories) paper). This repo is a \"fullstack\" train + inference solution for Llama 2 LLM, with focus on minimalism and simplicity.\n\nAs the architecture is identical, you can also load and inference Meta's Llama 2 models. However, the current code only inferences models in fp32, so you will most likely not be able to productively load models larger than 7B. Work on model quantization is currently ongoing.\n\nPlease note that this repo started recently as a fun weekend project: I took my earlier [nanoGPT](https://github.com/karpathy/nanoGPT), tuned it to implement the Llama-2 architecture instead of GPT-2, and the meat of it was writing the C inference engine in [run.c](run.c). So the project is young and moving quickly. Hat tip to the awesome [llama.cpp](https://github.com/ggerganov/llama.cpp) for inspiring this project. Compared to llama.cpp, I wanted something super simple, minimal, and educational so I chose to hard-code the Llama 2 architecture and just roll one inference file of pure C with no dependencies.\n\n## feel the magic\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/karpathy/llama2.c/blob/master/run.ipynb)\n\nFirst, navigate to the folder where you keep your projects and clone this repository to this folder:\n\n```bash\ngit clone https://github.com/karpathy/llama2.c.git\n```\n\nThen, open the repository folder:\n\n```bash\ncd llama2.c\n```\n\nNow, let's just run a baby Llama 2 model in C. You need a model checkpoint. Download this 15M parameter model I trained on the [TinyStories](https://huggingface.co/datasets/roneneldan/TinyStories) dataset (~60MB download):\n\n```bash\nwget https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin\n```\n\nCompile and run the C code:\n\n```bash\nmake run\n./run stories15M.bin\n```\n\nYou'll see the text stream a sample. On my M1 MacBook Air this runs at ~110 tokens/s. See [performance](#performance) or the Makefile for compile flags that can significantly speed this up. We can also try a bit bigger 42M parameter model:\n\n```bash\nwget https://huggingface.co/karpathy/tinyllamas/resolve/main/stories42M.bin\n./run stories42M.bin\n```\n\nThis still runs at interactive rates and samples more coherent and diverse stories:\n\n> Once upon a time, there was a little girl named Lily. She loved playing with her toys on top of her bed. One day, she decided to have a tea party with her stuffed animals. She poured some tea into a tiny teapot and put it on top of the teapot. Suddenly, her little brother Max came into the room and wanted to join the tea party too. Lily didn't want to share her tea and she told Max to go away. Max started to cry and Lily felt bad. She decided to yield her tea party to Max and they both shared the teapot. But then, something unexpected happened. The teapot started to shake and wiggle. Lily and Max were scared and didn't know what to do. Suddenly, the teapot started to fly towards the ceiling and landed on the top of the bed. Lily and Max were amazed and they hugged each other. They realized that sharing was much more fun than being selfish. From that day on, they always shared their tea parties and toys.\n\nYou can also prompt the model with a prefix or a number of additional command line arguments, e.g. to sample at temperature 0.8 for 256 steps and with a prompt:\n\n```bash\n./run stories42M.bin -t 0.8 -n 256 -i \"One day, Lily met a Shoggoth\"\n```\n\n> One day, Lily met a Shoggoth. He was very shy, but was also very generous. Lily said â€œHello Shoggy! Can I be your friend?â€ Shoggy was happy to have a friend and said â€œYes, letâ€™s explore the universe together!â€ So they set off on a journey to explore the universe. As they travelled, Shoggy was happy to explain to Lily about all the wonderful things in the universe. At the end of the day, Lily and Shoggy had gathered lots of wonderful things from the universe, and they both felt very proud. They promised to explore the universe as one big pair and to never stop being generous to each other.\n\nThere is also an even better 110M param model available, see [models](#models).\n\nQuick note on sampling, the recommendation for ~best results is to sample with `-t 1.0 -p 0.9`, i.e. temperature 1.0 (default) but also top-p sampling at 0.9 (default). Intuitively, top-p ensures that tokens with tiny probabilities do not get sampled, so we can't get \"unlucky\" during sampling, and we are less likely to go \"off the rails\" afterwards. More generally, to control the diversity of samples use either the temperature (i.e. vary `-t` between 0 and 1 and keep top-p off with `-p 0`) or the top-p value (i.e. vary `-p` between 0 and 1 and keep `-t 1`), but not both. Nice explainers on LLM sampling strategies include [this](https://peterchng.com/blog/2023/05/02/token-selection-strategies-top-k-top-p-and-temperature/), [this](https://docs.cohere.com/docs/controlling-generation-with-top-k-top-p) or [this](https://huggingface.co/blog/how-to-generate).\n\n## Meta's Llama 2 models\n\nAs the neural net architecture is identical, we can also inference the Llama 2 models released by Meta. Sadly there is a bit of friction here due to licensing (I can't directly upload the checkpoints, I think). So Step 1, get the Llama 2 checkpoints by following the [Meta instructions](https://github.com/facebookresearch/llama). Once we have those checkpoints, we have to convert them into the llama2.c format.\nFor this we need to install the python dependencies (`pip install -r requirements.txt`) and then use the `export.py` file, e.g. for 7B model:\n\n```bash\npython export.py llama2_7b.bin --meta-llama path/to/llama/model/7B\n```\n\nThe export will take ~10 minutes or so and generate a 26GB file (the weights of the 7B model in float32) called `llama2_7b.bin` in the current directory. It has been [reported](https://github.com/karpathy/llama2.c/pull/85) that despite efforts. I would not attempt to run anything above 7B right now for two reasons: first, 13B+ currently doesn't work because of integer flow in pointer arithmetic, which is yet to be fixed, and second, even if it were fixed, this repo is doing float32 inference right now, so it would be fairly unusably slow. Once the export is done, we can run it:\n\n```bash\n./run llama2_7b.bin\n```\n\nThis ran at about 4 tokens/s compiled with [OpenMP](#OpenMP) on 96 threads on my CPU Linux box in the cloud. (On my MacBook Air M1, currently it's closer to 30 seconds per token if you just build with `make runfast`.) Example output:\n\n> The purpose of this document is to highlight the state-of-the-art of CoO generation technologies, both recent developments and those in commercial use. The focus is on the technologies with the highest merit to become the dominating processes of the future and therefore to be technologies of interest to S&amp;T ... R&amp;D. As such, CoO generation technologies developed in Russia, Japan and Europe are described in some depth. The document starts with an introduction to cobalt oxides as complex products and a short view on cobalt as an essential material. The document continues with the discussion of the available CoO generation processes with respect to energy and capital consumption as well as to environmental damage.\n\nbase models... Â¯\\\\_(ãƒ„)_/Â¯. Since we can inference the base model, it should be possible to also inference the chat model quite easily, and have a conversation with it. And if we can find a way to run 7B more efficiently, we can start adding LoRA to our training script, and going wild with finetunes all within the repo!\n\nYou can also chat with the Llama Chat models. Export the chat model exactly as above:\n\n```bash\npython export.py llama2_7b_chat.bin --meta-llama /path/to/7B-chat\n```\n\nThen chat with it by specifying the chat mode using the `-m` flag, e.g.:\n\n```bash\n./run llama2_7b_chat.bin -m chat\n```\n\nYou can also try Meta's Code Llama models even if support for them is incomplete. In particular, some hyperparameters changed (e.g. the constant in RoPE layer), so the inference is not exactly correct and a bit buggy right now. Looking into fixes. Make sure to build the tokenizer for the plain and instruct variants and pass it when doing inference.\n\n```bash\npython export.py codellama2_7b.bin --meta-llama /path/to/CodeLlama-7b\npython tokenizer.py --tokenizer-model=/path/to/CodeLlama-7b/tokenizer.model\n./run codellama2_7b.bin -z /path/to/CodeLlama-7b/tokenizer.bin\n```\n\nChat with Code Llama Instruct:\n\n```bash\npython export.py codellama2_7b_instruct.bin --meta-llama /path/to/CodeLlama-7b-Instruct\npython tokenizer.py --tokenizer-model=/path/to/CodeLlama-7b-Instruct/tokenizer.model\n./run codellama2_7b_instruct.bin -m chat -z /path/to/CodeLlama-7b-Instruct/tokenizer.bin\n```\n\n## int8 quantization\n\nThe (default) script [run.c](run.c), above, uses a float32 forward pass, where the entire calculation of the forward pass is kept in fp32. This is very easy to understand as far as reference code goes, but it has the following downsides: the model checkpoint files are very large (it takes 4 bytes per every individual weight), and the forward pass is relatively slow. The (very) common inference optimization employed in practice is to quantize the model parameters to lower precision, giving up a little bit of correctness in return for smaller checkpoint sizes and faster forward passes (as most of the inference uses integer arithmetic). Empirically, LLMs can tolerate precisions as low as 4-bit (or even lower), but we use int8 here because it is a \"safe\" setting that gets us the benefits but doesn't sacrifice too much of the model accuracy. Only the weights that participate in matmuls are quantized. All the other parameters (e.g. especially the scale and bias in RMSNorm) are kept in float32, because these layers are very sensitive. Now, if all you're after is reduction in checkpoint sizes, you could quantize the weights, save the checkpoint, and then dequantize them in run.c, and do float32 inference as normal and call it a day. This is totally fine. But here, we go one step further (as is standard practice) and additionally quantize the activations in the forward pass. This requires us to dynamically quantize and dequantize between float32 and int8 at runtime, which adds overhead. But the benefit is that now the majority of the calculations (the matmuls especially!) are using pure integer arithmetic, where both weights and activations enter as int8. This is where the speedups can fundamentally come from. The version we use is the \"Q8_0\" quantization (llama.cpp terminology), where the 0 means that the weight quantization is symmetric around 0, quantizing to the range [-127, 127].\n\nThe quantized forward pass is implemented in [runq.c](runq.c). To use it, we have to export the model in the quantized format. For example, the float32 version of Llama 2 7B was exported as:\n\n```\npython export.py llama2_7b.bin --meta-llama path/to/llama/model/7B\n```\n\nThis creates a 26GB file, because each one of 7B parameters is 4 bytes (fp32). To export it quantized, we instead use version 2 export:\n\n```\npython export.py llama2_7b_q80.bin --version 2 --meta-llama path/to/llama/model/7B\n```\n\nThis runs for a few minutes, but now creates only a 6.7GB file. For exporting non-meta checkpoints you would use the --checkpoint arg instead of --meta-llama arg (more docs on this later, below). Now let's inference them. I like to use OMP here because these are big models, so e.g. on my Linux box:\n\n```\nmake runomp\nOMP_NUM_THREADS=64 ./run llama2_7b.bin -n 40\nOMP_NUM_THREADS=64 ./runq llama2_7b_q80.bin -n 40\n```\n\nThis runs 40 steps just to get a timing. The float32 version for me runs at 4.6 tok/s, and the int8 version at 14 tok/s. So we achieved a 3X speedup while reducing the checkpoint size by 4X. However, the forward pass is quantized to int8, and therefore silently very slightly lower quality.\n\n## huggingface models\n\nWe can load any huggingface models that use the Llama 2 architecture. See the script [export.py](export.py) and the `--hf` flag to export the model .bin file.\n\n## models\n\nFor the sake of examples of smaller, from-scratch models, I trained a small model series on TinyStories. All of these trained in a few hours on my training setup (4X A100 40GB GPUs). The 110M took around 24 hours. I am hosting them on huggingface hub [tinyllamas](https://huggingface.co/karpathy/tinyllamas), both in the original PyTorch .pt, and also in the llama2.c format .bin:\n\n| model | dim | n_layers | n_heads | n_kv_heads | max context length | parameters | val loss | download\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 260K | 64 | 5 | 8 | 4 | 512 | 260K | 1.297 | [stories260K](https://huggingface.co/karpathy/tinyllamas/tree/main/stories260K)\n| OG | 288 | 6 | 6 | 6 | 256 | 15M | 1.072 | [stories15M.bin](https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin) |\n| 42M| 512 | 8 | 8 | 8 | 1024 | 42M | 0.847 | [stories42M.bin](https://huggingface.co/karpathy/tinyllamas/resolve/main/stories42M.bin) |\n| 110M| 768 | 12 | 12 | 12 | 1024 | 110M | 0.760 | [stories110M.bin](https://huggingface.co/karpathy/tinyllamas/resolve/main/stories110M.bin) |\n\nYou'll notice that the 110M model is equivalent to GPT-1 in size. Alternatively, this is also the smallest model in the GPT-2 series (`GPT-2 small`), except the max context length is only 1024 instead of 2048. The only notable changes from GPT-1/2 architecture is that Llama uses RoPE relatively positional embeddings instead of absolute/learned positional embeddings, a bit more fancy SwiGLU non-linearity in the MLP, RMSNorm instead of LayerNorm, bias=False on all Linear layers, and is optionally multiquery.\n\n## training\n\nLet's see how we can train a baby Llama 2 from scratch using the code in this repo. First let's download and pretokenize some source dataset, e.g. I like [TinyStories](https://huggingface.co/datasets/roneneldan/TinyStories) so this is the only example currently available in this repo. But it should be very easy to add datasets, see the code.\n\n```bash\npython tinystories.py download\npython tinystories.py pretokenize\n```\n\nThen train our model:\n\n```bash\npython train.py\n```\n\n**brief training guide**. See the train.py script for more exotic launches and hyperparameter overrides. Here is a brief guide to how to set the parameters. Look at the table at the very end of the [Chinchilla paper](https://arxiv.org/abs/2203.15556) to get a sense of how the Transformer parameters (dim, n_layers, n_heads) grow or shrink together. Extrapolate/interpolate this pattern to get bigger or smaller transformers. Set the max context length however you wish, depending on the problem: this should be the max number of tokens that matter to predict the next token. E.g. Llama 2 uses 2048. Next, you want the _total_ batch size per update (printed by the script as \"tokens per iteration will be:\") to be somewhere around 100K tokens for medium-sized applications. For tiny applications it could be lower, for large training (e.g. GPTs/LLamas) it is usually ~0.5M, or even more. You get there by first maxing out the batch_size to whatever your system allows (e.g. mine was 16 in a recent run because after that my GPU runs out of memory), and then you want to increase gradient_accumulation_steps to be as high as necessary to reach the total batch size of ~100K. Finally, you want to tune your learning_rate (LR). You want this to be as high as your training allows. Very small networks can get away with a large LR (e.g. 1e-3 or even higher). Large networks need lower LRs. 3e-4 is a safe choice in most medium-sized applications, but can be too low for small networks, so try to increase it! Finally, max_iters is the length of training. Play with different settings. I mostly only ever tune these parameters and leave most of the others unchanged. Here is an example of how I trained the 110M model, which I don't think is anywhere near optimal, but looked sensible to me: dim 768, n_layers 12, n_heads 12 (so size of each head is 768 / 12 = 64 channels), seq len of 1024, batch size 16 (this is the most that fit my A100 40GB GPU), gradient_accumulation_steps = 8 was needed to get total tokens batch size to be 16 batch size * 1024 tokens in sequence * 8 grad_accum = 131,072 tokens per update. Good. Learning rate 4e-4 (probably a little too low). max_iters 200K (probably a bit too high). Dropout 0.1, as that usually helps a bit at medium size. That was it. I ran using Distributed Data Parallel (DDP) on 4 GPUs on my cloud machine, training took ~day or so.\n\nTotally understand if you want to skip model training, for simple demo just download one of the pretrained models (see [models](#models) section), e.g.:\n\n```bash\nwget https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin\n```\n\nOnce we have the model.bin file, we can inference in C. Compile the C code first:\n\n```bash\nmake run\n```\n\nYou can now run it simply as\n\n```bash\n./run stories15M.bin\n```\n\nWatch the tokens stream by, fun! We can also run the PyTorch inference script for a comparison. Download one of the models again from huggingface hub and point the `sample.py` script at it:\n\n```bash\nwget https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.pt -P out15M\npython sample.py --checkpoint=out15M/stories15M.pt\n```\n\nWhich gives the same results.\n\n## custom tokenizers\n\nIn everything above, we've assumed the custom Lllama 2 tokenizer with 32,000 tokens. However, in many boutique LLMs, using vocabulary this big might be an overkill. If you have a small application you have in mind, you might be much better off training your own tokenizers. This can make everything nicer - with smaller vocabs your model has fewer parameters (because the token embedding table is a lot smaller), the inference is faster (because there are fewer tokens to predict), and your average sequence length per example could also get smaller (because the compression is a lot more efficient on your data). So let's see how we train a custom tokenizer.\n\nBy default, to pretokenize the tinystories dataset we had to run, in order:\n\n```\npython tinystories.py download\npython tinystories.py pretokenize\n```\n\nThe `pretokenize` stage here loads the Llama 2 tokenizer (vocab size 32,000) and uses it to convert the downloaded text into integers, and saves that to file. We now change this as follows, to train an example 4096-token tokenizer:\n\n```\npython tinystories.py download\npython tinystories.py train_vocab --vocab_size=4096\npython tinystories.py pretokenize --vocab_size=4096\n```\n\nThe `train_vocab` stage will call the `sentencepiece` library to train the tokenizer, storing it in a new file `data/tok4096.model`. I tried to reproduce as well as I could the settings that (I think) Meta used to train their vocabulary. This uses the Byte Pair Encoding algorithm that starts out with raw utf8 byte sequences of the text data and then iteratively merges the most common consecutive pairs of tokens to form the vocabulary. Inspect the `tinystories.py` file - the custom tokenizers are stored in a special directory structure indexed by the vocab size.\n\nA quick note of interest is that vocab size of 4096 trained specifically on tinystories creates integer sequences with about the same sequence length per example as the default Llama 2 tokenizer of 32000 tokens! This means that our custom, tailored tokenizer is a lot better adapted to our specific text, and can compress it very effectively. So our trained models are smaller and faster.\n\nNow that we have pretokenized the dataset with our custom tokenizer, we can train the model. The training script `train.py` doesn't care about the exact tokens, it only cares about the vocabulary size so it can correctly initialize the model. So when training your model, make sure to pass in\n\n```\npython train.py --vocab_source=custom --vocab_size=4096\n```\n\n(The defaults are `llama2` and `32000` respectively, which indicates the default Llama 2 tokenizer). This trains the model. Finally we are ready to run inference with our `run.c` script. For that we need two things. Number one, we have to export our tokenizer in the `.bin` format, do that with:\n\n```\npython tokenizer.py --tokenizer-model=data/tok4096.model\n```\n\nThis writes the tokenizer to `data/tok4096.bin`. Now we can run inference, pointing it to this tokenizer using the `-z` flag:\n\n```\n./run out/model.bin -z data/tok4096.bin\n```\n\nThis should print the samples. If you leave out the `-z` flag, it will use the default Llama 2 tokenizer, which would generate a good sequence of integers, but they would get translated using a different vocabulary to text, so it would look like gibberish.\n\n## performance\n\nThere are many ways to potentially speed up this code depending on your system. Have a look at the [Makefile](Makefile), which contains a lot of notes. The `make run` command currently uses the `-O3` optimization by default, i.e.:\n\n```bash\ngcc -O3 -o run run.c -lm\n```\n\n-O3 includes optimizations that are expensive in terms of compile time and memory usage. Including vectorization, loop unrolling, and predicting branches.\n\nTo get a much better performance, try to compile with `make runfast`. This turns on the `-Ofast` flag, which includes additional optimizations that may break compliance with the C/IEEE specifications, in addition to `-O3`. See [the GCC docs](https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html) for more information.\n\nTry `-march=native` to compile the program to use the architecture of the machine you're compiling on rather than a more generic CPU. This may enable additional optimizations and hardware-specific tuning such as improved vector instructions/width.\n\nThe fastest throughput I saw so far on my MacBook Air (M1) so far is with `make runfast`.\n\nYou can also experiment with replacing `gcc` with `clang`.\n\nIf compiling with gcc, try experimenting with `-funroll-all-loops`, see PR [#183](https://github.com/karpathy/llama2.c/pull/183)\n\n**OpenMP**. Big improvements can also be achieved by compiling with OpenMP, which \"activates\" the `#pragma omp parallel for` inside the matmul and attention, allowing the work in the loops to be split up over multiple processors.\nYou'll need to install the OpenMP library and the clang compiler first (e.g. `apt install clang libomp-dev` on ubuntu). Then you can compile with `make runomp`, which does:\n\n```bash\nclang -Ofast -fopenmp -march=native run.c  -lm  -o run\n```\n\nWhen you run inference make sure to use OpenMP flags to set the number of threads, e.g.:\n\n```bash\nOMP_NUM_THREADS=4 ./run out/model.bin\n```\n\nDepending on your system resources you may want to tweak these hyperparameters and use more threads. But more is not always better, usually this is a bit U shaped. In particular, if your CPU has SMT (multithreading), try setting the number of threads to the number of physical cores rather than logical cores. The performance difference can be large due to cache thrashing and communication overhead. The PyTorch documentation [CPU specific optimizations\n](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html#cpu-specific-optimizations) has some good information that applies here too.\n\n## platforms\n\nOn **Windows**, use `build_msvc.bat` in a Visual Studio Command Prompt to build with msvc, or you can use `make win64` to use mingw compiler toolchain from linux or windows to build the windows target. MSVC build will automatically use openmp and max threads appropriate for your CPU unless you set `OMP_NUM_THREADS` env.\n\nOn **Centos 7**, **Amazon Linux 2018** use `rungnu` Makefile target: `make rungnu` or `make runompgnu` to use openmp.\n\nOn **Mac**, use clang from brew for openmp build. Install clang as `brew install llvm` and use the installed clang binary to compile with openmp: `make runomp CC=/opt/homebrew/opt/llvm/bin/clang`\n\n## tests\n\nYou can run tests simply with pytest:\n\n```bash\n$ pip install pytest\n$ pytest\n```\n\nThis will currently invoke two tests inside `test_all.py`, which forward the model in both C and Python for 200 steps and check the output against a known good expected output. The tests currently run in only a few seconds, but will have to download and cache the stories260K models in a temporary `test` directory (only ~2MB download).\n\nThere are also some tests in C, in the file [test.c](test.c). You can run these with `make testcc`, or to see more stuff printed:\n\n```\nmake testcc VERBOSITY=1\n```\n\nCall for help: help add more tests.\n\n## ack\n\nI trained the llama2.c storyteller models on a 4X A100 40GB box graciously provided by the excellent [Lambda labs](https://lambdalabs.com/service/gpu-cloud), thank you.\n\n## discord\n\nFigured it's possible to reuse my existing discord channel (that I use for my [zero to hero youtube series](https://karpathy.ai/zero-to-hero.html)), see #llama2c channel on [discord](https://discord.gg/3zy8kqD9Cp), for any quick questions, related discussions, etc.\n\n## contributing\n\nA few words on this repo and the kinds of PRs that are likely to be accepted. What is the goal of this repo? Basically I think there will be a lot of interest in training or finetuning custom micro-LLMs (think ~100M - ~1B params, but let's say up to ~10B params) across a large diversity of applications, and deploying them in edge-adjacent environments (think MCUs, phones, web browsers, laptops, etc.). I'd like this repo to be the simplest, smallest, most hackable repo to support this workflow, both training and inference. In particular, this repo is not a complex framework with a 1000 knobs controlling inscrutible code across a nested directory structure of hundreds of files. Instead, I expect most applications will wish to create a fork of this repo and hack it to their specific needs and deployment platforms.\n\nPeople who care about deployment efficiency above all else should look at [llama.cpp](https://github.com/ggerganov/llama.cpp). This repo still cares about efficiency, but not at the cost of simplicity, readability or portability. Basically, I expect that a lot of people come to this repo because the training code is 2 readable .py files and the inference code is 500 lines of C. So I'd like this to continue to be a kind of simplest \"reference implementation\" that can be easily hacked in a separate fork into whatever downstream application people are excited about. It shouldn't be full-featured. It shouldn't take 100 different options or settings. It shouldn't be the most efficient. A few examples:\n\n- someone re-ordered two loops to improve data locality for a small efficieny win => instant merge.\n- someone added the one line \"pragma omp parallel for\", which allows you to compile with OpenMP and dramatically speed up the code, or acts as just a comment if you don't compile it that way => instant merge.\n- bug fixes and touchups etc. => happy to merge\n\nA few examples of PRs are that are not an excellent fit:\n\n- adding more than several #ifdefs all over the place in code. If they are localized / few, might be okay.\n- adding a lot of code that is very specific to some specific platform (e.g. MCUs, or some special version of linux or processor). These may be a better fit for forks of the project, and I am very happy to maintain a list of these forks in section below.\n- adding hundreds of lines of code to run.c that are only active in specific scenarios or platforms.\n\nIf your candidate PRs have elements of these it doesn't mean they won't get merged, it just means they will make it into the gray territory. TLDR: I am eager to merge any mostly small, mostly localized, broadly applicable, clean changes that improve the efficiency and portability of the repo, while keep its hackability and readability. I appreciate all PRs seeking to help me improve the project, thank you! <3.\n\n## notable forks\n\n- Rust\n  - [llama2.rs](https://github.com/gaxler/llama2.rs) by @[gaxler](https://github.com/gaxler): a Rust port of this project\n  - [llama2.rs](https://github.com/leo-du/llama2.rs) by @[leo-du](https://github.com/leo-du): A Rust port of this project\n  - [llama2-rs](https://github.com/danielgrittner/llama2-rs) by @[danielgrittner](https://github.com/danielgrittner): a Rust port of this project\n  - [llama2.rs](https://github.com/lintian06/llama2.rs) by @[lintian06](https://github.com/lintian06): A Rust port of this project\n  - [pecca.rs](https://github.com/rahoua/pecca-rs) by @[rahoua](https://github.com/rahoua): A Rust port leveraging [ndarray](https://github.com/rust-ndarray/ndarray), supports BLAS.\n  - [llama2.rs](https://github.com/flaneur2020/llama2.rs) by @[flaneur2020](https://github.com/flaneur2020): A Rust port of this project.\n  - [llama2-burn](https://github.com/code-cp/llama2-burn): A Rust port of this project leveraging [Burn](https://github.com/tracel-ai/burn)\n- Go\n  - [go-llama2](https://github.com/tmc/go-llama2) by @[tmc](https://github.com/tmc): a Go port of this project\n  - [llama2.go](https://github.com/nikolaydubina/llama2.go) by @[nikolaydubina](https://github.com/nikolaydubina): a Go port of this project\n  - [llama2.go](https://github.com/haormj/llama2.go) by @[haormj](https://github.com/haormj): a Go port of this project\n  - [llama2.go](https://github.com/saracen/llama2.go) by @[saracen](https://github.com/saracen): a Go port of this project\n- Android\n  - [llama2.c-android](https://github.com/Manuel030/llama2.c-android): by @[Manuel030](https://github.com/Manuel030): adds Android binaries of this project\n  - [llama2.c-android-wrapper](https://github.com/celikin/llama2.c-android-wrapper): by @[celikin](https://github.com/celikin): added JNI wrapper, PoC\n- C\n  - [llama3.c](https://github.com/jameswdelancey/llama3.c): by @[jameswdelancey](https://github.com/jameswdelancey): a LLaMA 3 8B Base and Instruct port of this project\n- C++\n  - [llama2.cpp](https://github.com/leloykun/llama2.cpp) by @[leloykun](https://github.com/leloykun): a C++ port of this project\n  - [llama2.cpp](https://github.com/coldlarry/llama2.cpp) by @[coldlarry](https://github.com/coldlarry): a C++ port of this project\n- JavaScript\n  - [llama2.js](https://github.com/epicure/llama2.js) by @[epicure](https://github.com/epicure): a JavaScript port of this project\n  - [llamajs](https://github.com/agershun/llamajs) by @[agershun](https://github.com/agershun): a JavaScript port of this project\n  - [llama2.ts](https://github.com/wizzard0/llama2.ts) by @[oleksandr_now](https://twitter.com/oleksandr_now): a TypeScript port of this project. Full Llama2-7B capable.\n  - [llama2.c-emscripten](https://github.com/gohai/llama2.c-emscripten) by @[gohai](https://github.com/gohai): Emscripten (JavaScript) port, based on @ggerganov's initial prototype\n- Zig\n  - [llama2.zig](https://github.com/cgbur/llama2.zig) by @[cgbur](https://github.com/cgbur): A Zig port of this project\n  - [llama2.zig](https://github.com/vodkaslime/llama2.zig) by @[vodkaslime](https://github.com/vodkaslime): a Zig port of this project\n  - [llama2.zig](https://github.com/clebert/llama2.zig) by @[clebert](https://github.com/clebert): a Zig port of this project\n- Julia\n  - [llama2.jl](https://github.com/juvi21/llama2.jl) by @[juvi21](https://github.com/juvi21): a Julia port of this project\n- Scala\n  - [llama2.scala](https://github.com/jrudolph/llama2.scala) by @[jrudolph](https://github.com/jrudolph): a Scala port of this project\n- Java\n  - [llama2.java](https://github.com/mukel/llama2.java) by @[mukel](https://github.com/mukel): a Java port of this project\n  - [llama2.java](https://github.com/neoremind/llama2.java) by @[neoremind](https://github.com/neoremind): a Java port of this project\n  - [llama2.tornadovm.java](https://github.com/mikepapadim/llama2.tornadovm.java) by @[mikepapadim](https://github.com/mikepapadim): an extension of the llama2.java with GPU-support through [TornadoVM](https://github.com/beehive-lab/TornadoVM).\n- Kotlin\n  - [llama2.kt](https://github.com/madroidmaq/llama2.kt) by @[madroidmaq](https://github.com/madroidmaq): a Kotlin port of this project\n  - [llama2-kmp](https://github.com/stepango/llama2-kmp) by @[stepango](https://github.com/stepango): a Kotlin multiplatform(KMP) port of this project \n- Python\n  - [llama2.py](https://github.com/tairov/llama2.py) by @[tairov](https://github.com/tairov): a simple one file pure Python port of this project with zero dependencies\n- C#\n  - [llama2.cs](https://github.com/trrahul/llama2.cs) by @[trrahul](https://github.com/trrahul): a C# port of this project\n- F#\n  - [llama2.fs](https://github.com/micsh/llama2.fs) by @[micsh](https://github.com/micsh): a F# port of this project\n- Dart\n  - [llama2.dart](https://github.com/yiminghan/llama2.dart) by @[yiminghan](https://github.com/yiminghan/llama2.dart): one-file dart port of this project, works with Flutter!\n- Web\n  - [llama2c-web](https://github.com/dmarcos/llama2.c-web) by @[dmarcos](https://github.com/dmarcos): Super simple way to build unmodified llama2.c to WASM and run it in the browser. [Demo](https://diegomarcos.com/llama2.c-web/)\n  - [llama2.rs.wasm](https://github.com/mtb0x1/llama2.rs.wasm) by @[mtb0x1](https://github.com/mtb0x1/) : a [Demo](https://mtb0x1.github.io/llama2.rs.wasm/) of all listed rust ports to WASM, all in one web page.\n- WebAssembly\n  - [icpp-llm](https://github.com/icppWorld/icpp-llm): LLMs for the Internet Computer\n- Fortran\n  - [llama2.f90](https://github.com/rbitr/llama2.f90): a Fortran port of this project\n- Mojo\n  - [llama2.ğŸ”¥](https://github.com/tairov/llama2.mojo) by @[tairov](https://github.com/tairov): pure Mojo port of this project\n- OCaml\n  - [llama2.ml](https://github.com/jackpeck/llama2.ml) by @[jackpeck](https://github.com/jackpeck): an OCaml port of this project\n- Hare\n  - [llama2.ha](https://sr.ht/~dvshkn/llama2.ha) by @[dvshkn](https://git.sr.ht/~dvshkn): a Hare port of this project\n- [llama2.c - Llama 2 Everywhere](https://github.com/trholding/llama2.c) by @[trholding](https://github.com/trholding): Standalone, Bootable & Portable Binary Llama 2\n- [llama2.c-zh - Bilingual Chinese and English](https://github.com/chenyangMl/llama2.c-zh) by @[chenyangMl](https://github.com/chenyangMl): Expand tokenizer to support training and inference in both Chinese and English\n- Haskell\n  - [llama2.hs](https://github.com/chris-ch/llama2.hs) by @[chris-ch](https://github.com/chris-ch): an Haskell port of this project\n\n## unsorted todos\n\n- add support in run.c of reading version 1+ files from export, later deprecate \"version 0\"\n- run.cu (CUDA) investigate and merge\n- add more tests inside [test.c](test.c)\n- add Engine class for use in sample.py that does efficient inference in PyTorch, e.g. KV cache keeping\n- make it easier to add a new dataset with not too much pain\n- (LoRA) finetuning and export of Llama 2 models\n\n## License\n\nMIT\n",
      "stars_today": 5
    },
    {
      "id": 4038949,
      "name": "traccar",
      "full_name": "traccar/traccar",
      "description": "Traccar GPS Tracking System",
      "html_url": "https://github.com/traccar/traccar",
      "stars": 6910,
      "forks": 3097,
      "language": "Java",
      "topics": [
        "gps",
        "gps-tracking",
        "hacktoberfest",
        "java",
        "traccar"
      ],
      "created_at": "2012-04-16T08:33:49Z",
      "updated_at": "2026-02-06T23:10:01Z",
      "pushed_at": "2026-02-05T05:33:28Z",
      "open_issues": 501,
      "owner": {
        "login": "traccar",
        "avatar_url": "https://avatars.githubusercontent.com/u/37892282?v=4"
      },
      "readme": "# [Traccar](https://www.traccar.org)\n\n## Overview\n\nTraccar is an open source GPS tracking system. This repository contains Java-based back-end service. It supports more than 200 GPS protocols and more than 2000 models of GPS tracking devices. Traccar can be used with any major SQL database system. It also provides easy to use [REST API](https://www.traccar.org/traccar-api/).\n\nOther parts of Traccar solution include:\n\n- [Traccar web app](https://github.com/traccar/traccar-web)\n- [Traccar Manager app](https://github.com/traccar/traccar-manager)\n\nThere is also a set of mobile apps that you can use for tracking mobile devices:\n\n- [Traccar Client app](https://github.com/traccar/traccar-client)\n\n## Features\n\nSome of the available features include:\n\n- Real-time GPS tracking\n- Driver behaviour monitoring\n- Detailed and summary reports\n- Geofencing functionality\n- Alarms and notifications\n- Account and device management\n- Email and SMS support\n\n## Build\n\nPlease read [build from source documentation](https://www.traccar.org/build/) on the official website.\n\n## Team\n\n- Anton Tananaev ([anton@traccar.org](mailto:anton@traccar.org))\n- Andrey Kunitsyn ([andrey@traccar.org](mailto:andrey@traccar.org))\n\n## License\n\n    Apache License, Version 2.0\n\n    Licensed under the Apache License, Version 2.0 (the \"License\");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n\n        http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n",
      "stars_today": 5
    },
    {
      "id": 860035177,
      "name": "CopilotForXcode",
      "full_name": "github/CopilotForXcode",
      "description": "AI coding assistant for Xcode",
      "html_url": "https://github.com/github/CopilotForXcode",
      "stars": 5649,
      "forks": 1728,
      "language": "Swift",
      "topics": [
        "ai-assistant",
        "github-copilot",
        "intelligence",
        "ios",
        "macos",
        "objective-c",
        "swift",
        "swiftui",
        "xcode"
      ],
      "created_at": "2024-09-19T17:48:15Z",
      "updated_at": "2026-02-07T00:27:04Z",
      "pushed_at": "2026-02-05T02:46:28Z",
      "open_issues": 196,
      "owner": {
        "login": "github",
        "avatar_url": "https://avatars.githubusercontent.com/u/9919?v=4"
      },
      "readme": "# <img align=\"center\" height=\"70\" src=\"./Docs/Images/AppIcon.png\"/> GitHub Copilot for Xcode\n\n[GitHub Copilot](https://github.com/features/copilot) for Xcode is the leading AI coding assistant for Swift, Objective-C and iOS/macOS development. It delivers intelligent Completions, Chat, and Code Reviewâ€”plus advanced features like Agent Mode, Next Edit Suggestions, MCP Registry, and Copilot Vision to make Xcode development faster and smarter.\n\n## Chat\n\nGitHub Copilot Chat provides suggestions to your specific coding tasks via chat.\n<img alt=\"Chat of GitHub Copilot for Xcode\" src=\"./Docs/Images/chat_agent.gif\" width=\"800\" />\n\n## Agent Mode\n\nGitHub Copilot Agent Mode provides AI-powered assistance that can understand and modify your codebase directly. With Agent Mode, you can:\n- Get intelligent code edits applied directly to your files\n- Run terminal commands and view their output without leaving the interface\n- Search through your codebase to find relevant files and code snippets\n- Create new files and directories as needed for your project\n- Get assistance with enhanced context awareness across multiple files and folders\n- Run Model Context Protocol (MCP) tools you configured to extend the capabilities\n\nAgent Mode integrates with Xcode's environment, creating a seamless development experience where Copilot can help implement features, fix bugs, and refactor code with comprehensive understanding of your project.\n\n## Code Completion\n\nYou can receive auto-complete type suggestions from GitHub Copilot either by starting to write the code you want to use, or by writing a natural language comment describing what you want the code to do.\n<img alt=\"Code Completion of GitHub Copilot for Xcode\" src=\"./Docs/Images/demo.gif\" width=\"800\" />\n\n## Requirements\n\n- macOS 12+\n- Xcode 8+\n- A GitHub account\n\n## Getting Started\n\n1. Install via [Homebrew](https://brew.sh/):\n\n   ```sh\n   brew install --cask github-copilot-for-xcode\n   ```\n\n   Or download the `dmg` from\n   [the latest release](https://github.com/github/CopilotForXcode/releases/latest/download/GitHubCopilotForXcode.dmg).\n   Drag `GitHub Copilot for Xcode` into the `Applications` folder:\n\n   <p align=\"center\">\n     <img alt=\"Screenshot of opened dmg\" src=\"./Docs/Images/dmg-open.png\" width=\"512\" />\n   </p>\n\n   Updates can be downloaded and installed by the app.\n\n1. Open the `GitHub Copilot for Xcode` application (from the `Applications` folder). Accept the security warning.\n   <p align=\"center\">\n     <img alt=\"Screenshot of MacOS download permission request\" src=\"./Docs/Images/macos-download-open-confirm.png\" width=\"350\" />\n   </p>\n\n\n1. A background item will be added to enable the GitHub Copilot for Xcode extension app to connect to the host app. This permission is usually automatically added when first launching the app.\n   <p align=\"center\">\n     <img alt=\"Screenshot of background item\" src=\"./Docs/Images/background-item.png\" width=\"370\" />\n   </p>\n\n1. Three permissions are required for GitHub Copilot for Xcode to function properly: `Background`, `Accessibility`, and `Xcode Source Editor Extension`. For more details on why these permissions are required see [TROUBLESHOOTING.md](./TROUBLESHOOTING.md).\n\n   The first time the application is run the `Accessibility` permission should be requested:\n\n   <p align=\"center\">\n     <img alt=\"Screenshot of accessibility permission request\" src=\"./Docs/Images/accessibility-permission-request.png\" width=\"529\" />\n   </p>\n\n   The `Xcode Source Editor Extension` permission needs to be enabled manually. Click\n   `Extension Permission` from the `GitHub Copilot for Xcode` application settings to open the\n   System Preferences to the `Extensions` panel. Select `Xcode Source Editor`\n   and enable `GitHub Copilot`:\n\n   <p align=\"center\">\n     <img alt=\"Screenshot of extension permission\" src=\"./Docs/Images/extension-permission.png\" width=\"582\" />\n   </p>\n\n1. After granting the extension permission, open Xcode. Verify that the\n   `Github Copilot` menu is available and enabled under the Xcode `Editor`\n   menu.\n    <br>\n    <p align=\"center\">\n      <img alt=\"Screenshot of Xcode Editor GitHub Copilot menu item\" src=\"./Docs/Images/xcode-menu.png\" width=\"648\" />\n    </p>\n\n    Keyboard shortcuts can be set for all menu items in the `Key Bindings`\n    section of Xcode preferences.\n\n1. To sign into GitHub Copilot, click the `Sign in` button in the settings application. This will open a browser window and copy a code to the clipboard. Paste the code into the GitHub login page and authorize the application.\n    <p align=\"center\">\n      <img alt=\"Screenshot of sign-in popup\" src=\"./Docs/Images/device-code.png\" width=\"372\" />\n    </p>\n\n1. To install updates, click `Check for Updates` from the menu item or in the\n   settings application.\n\n   After installing a new version, Xcode must be restarted to use the new\n   version correctly.\n\n   New versions can also be installed from `dmg` files downloaded from the\n   releases page. When installing a new version via `dmg`, the application must\n   be run manually the first time to accept the downloaded from the internet\n   warning.\n\n1. To avoid confusion, we recommend disabling `Predictive code completion` under\n   `Xcode` > `Preferences` > `Text Editing` > `Editing`.\n\n1. Press `tab` to accept the first line of a suggestion, hold `option` to view\n   the full suggestion, and press `option` + `tab` to accept the full suggestion.\n\n## How to use Chat\n\n   Open Copilot Chat in GitHub Copilot.\n  - Open via the Xcode menu `Xcode -> Editor -> GitHub Copilot -> Open Chat`.\n  <p align=\"center\">\n    <img alt=\"Screenshot of Xcode Editor GitHub Copilot menu item\" src=\"./Docs/Images/xcode-menu_dark.png\" width=\"648\" />\n  </p>\n\n  - Open via GitHub Copilot app menu `Open Chat`.\n\n  <p align=\"center\">\n    <img alt=\"Screenshot of GitHub Copilot menu item\" src=\"./Docs/Images/copilot-menu_dark.png\" width=\"244\" />\n  </p>\n\n## How to use Code Completion\n\n   Press `tab` to accept the first line of a suggestion, hold `option` to view\n   the full suggestion, and press `option` + `tab` to accept the full suggestion.\n\n## License\n\nThis project is licensed under the terms of the MIT open source license. Please\nrefer to [LICENSE.txt](./LICENSE.txt) for the full terms.\n\n## Privacy\n\nWe follow responsible practices in accordance with our\n[Privacy Statement](https://docs.github.com/en/site-policy/privacy-policies/github-privacy-statement).\n\nTo get the latest security fixes, please use the latest version of the GitHub\nCopilot for Xcode.\n\n## Support\n\nWeâ€™d love to get your help in making GitHub Copilot better!  If you have\nfeedback or encounter any problems, please reach out on our [Feedback\nforum](https://github.com/github/CopilotForXcode/discussions).\n\n## Acknowledgements\n\nThank you to @intitni for creating the original project that this is based on.\n\nAttributions can be found under About when running the app or in\n[Credits.rtf](./Copilot%20for%20Xcode/Credits.rtf).\n",
      "stars_today": 5
    },
    {
      "id": 58194180,
      "name": "strimzi-kafka-operator",
      "full_name": "strimzi/strimzi-kafka-operator",
      "description": "Apache KafkaÂ® running on Kubernetes",
      "html_url": "https://github.com/strimzi/strimzi-kafka-operator",
      "stars": 5690,
      "forks": 1445,
      "language": "Java",
      "topics": [
        "data-stream",
        "data-streaming",
        "data-streams",
        "hacktoberfest",
        "kafka",
        "kafka-connect",
        "kafka-streams",
        "kubernetes",
        "kubernetes-controller",
        "kubernetes-operator",
        "messaging",
        "openshift"
      ],
      "created_at": "2016-05-06T08:52:33Z",
      "updated_at": "2026-02-07T00:59:03Z",
      "pushed_at": "2026-02-07T00:58:58Z",
      "open_issues": 129,
      "owner": {
        "login": "strimzi",
        "avatar_url": "https://avatars.githubusercontent.com/u/34767428?v=4"
      },
      "readme": "[![Strimzi](./documentation/logo/strimzi.png)](https://strimzi.io/)\n\n# Run Apache Kafka on Kubernetes and OpenShift\n\n[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/strimzi/strimzi-kafka-operator/badge)](https://scorecard.dev/viewer/?uri=github.com/strimzi/strimzi-kafka-operator)\n[![Build Status](https://github.com/strimzi/strimzi-kafka-operator/actions/workflows/build.yml/badge.svg?branch=main)](https://github.com/strimzi/strimzi-kafka-operator/actions/workflows/build.yml?query=branch%3Amain)\n[![GitHub release](https://img.shields.io/github/release/strimzi/strimzi-kafka-operator.svg)](https://github.com/strimzi/strimzi-kafka-operator/releases/latest)\n[![License](https://img.shields.io/badge/license-Apache--2.0-blue.svg)](http://www.apache.org/licenses/LICENSE-2.0)\n[![Twitter Follow](https://img.shields.io/twitter/follow/strimziio?style=social)](https://twitter.com/strimziio)\n[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/strimzi-kafka-operator)](https://artifacthub.io/packages/search?repo=strimzi-kafka-operator)\n\nStrimzi provides a way to run an [Apache KafkaÂ®][kafka] cluster on \n[Kubernetes][k8s] or [OpenShift][os] in various deployment configurations.\nSee our [website][strimzi] for more details about the project.\n\n## Quick Starts\n\nTo get up and running quickly, check our [Quick Start for Minikube, OKD (OpenShift Origin) and Kubernetes Kind](https://strimzi.io/quickstarts/). \n\n## Documentation\n\nDocumentation for the current _main_ branch as well as all releases can be found on our [website][strimzi].\n\n## Roadmap\n\nThe roadmap of the Strimzi Operator project is maintained as [GitHub Project](https://github.com/orgs/strimzi/projects/4).\n\n## Getting help\n\nIf you encounter any issues while using Strimzi, you can get help using:\n\n- [#strimzi channel on CNCF Slack](https://slack.cncf.io/)\n- [Strimzi Users mailing list](https://lists.cncf.io/g/cncf-strimzi-users/topics)\n- [GitHub Discussions](https://github.com/strimzi/strimzi-kafka-operator/discussions)\n\n## Strimzi Community Meetings\n\nYou can join our regular community meetings:\n* Thursday 9:00 AM UTC (every 4 weeks) - [convert to your timezone](https://www.thetimezoneconverter.com/?t=8%3A00&tz=UTC)\n* Thursday 4:00 PM UTC (every 4 weeks, offset by 2 weeks from above meeting) - [convert to your timezone](https://www.thetimezoneconverter.com/?t=16%3A00&tz=UTC)\n\nResources:\n* [Meeting minutes, agenda and Zoom link](https://docs.google.com/document/d/1V1lMeMwn6d2x1LKxyydhjo2c_IFANveelLD880A6bYc/edit#heading=h.vgkvn1hr5uor)\n* [Recordings](https://youtube.com/playlist?list=PLpI4X8PMthYfONZopcRd4X_stq1C14Rtn)\n* [Calendar](https://zoom-lfx.platform.linuxfoundation.org/meetings/strimzi) ([Subscribe to the calendar](https://webcal.prod.itx.linuxfoundation.org/lfx/a092M00001JWrBrQAL))\n\n## Contributing\n\nYou can contribute by:\n- Raising issues you find while using Strimzi\n- Fixing issues by opening Pull Requests\n- Improving Strimzi documentation\n- Talking about Strimzi\n\nAll bugs, tasks or enhancements are tracked as [GitHub issues](https://github.com/strimzi/strimzi-kafka-operator/issues). Issues which \nmight be a good start for new contributors are marked with [\"good-start\"](https://github.com/strimzi/strimzi-kafka-operator/labels/good-start)\nlabel.\n\nThe [Dev guide](https://github.com/strimzi/strimzi-kafka-operator/blob/main/development-docs/DEV_GUIDE.md) describes how to build Strimzi.\nBefore submitting a patch, please make sure to understand, how to test your changes before opening a PR [Test guide](https://github.com/strimzi/strimzi-kafka-operator/blob/main/development-docs/TESTING.md).\n\nThe [Documentation Contributor Guide](https://strimzi.io/contributing/guide/) describes how to contribute to Strimzi documentation.\n\nIf you want to get in touch with us first before contributing, you can use:\n\n- [#strimzi channel on CNCF Slack](https://slack.cncf.io/)\n- [Strimzi Dev mailing list](https://lists.cncf.io/g/cncf-strimzi-dev/topics)\n\n## License\nStrimzi is licensed under the [Apache License](./LICENSE), Version 2.0\n\n## Community Testing\n\n### Linux on IBM Z (s390x)\n\n[![Jenkins](https://ibmz-ci.osuosl.org/job/Strimzi_Kafka_Operator_IBMZ_CI/badge/icon)](https://ibmz-ci.osuosl.org/job/Strimzi_Kafka_Operator_IBMZ_CI/)\n\n_Note: This badge represents a community-led initiative and is not officially endorsed by the Strimzi project maintainers._\n\n## Container signatures\n\nFrom the 0.38.0 release, Strimzi containers are signed using the [`cosign` tool](https://github.com/sigstore/cosign).\nStrimzi uses keyless signing since 0.49.0 release. \nTo verify the container, you can run the following command:\n\n```shell\ncosign verify --certificate-identity-regexp='https://github.com/strimzi/.*' \\\n    --certificate-oidc-issuer='https://token.actions.githubusercontent.com' \\\n    quay.io/strimzi/operator:latest\n```\n\nIn case you want to verify containers of older version of Strimzi than 0.49.0, then use our public key:\n\n```\n-----BEGIN PUBLIC KEY-----\nMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAET3OleLR7h0JqatY2KkECXhA9ZAkC\nTRnbE23Wb5AzJPnpevvQ1QUEQQ5h/I4GobB7/jkGfqYkt6Ct5WOU2cc6HQ==\n-----END PUBLIC KEY-----\n```\n\nAnd use it to verify the signature:\n\n```shell\ncosign verify --key strimzi.pub quay.io/strimzi/operator:latest --insecure-ignore-tlog=true\n```\n\n## Software Bill of Materials (SBOM)\n\nFrom the 0.38.0 release, Strimzi publishes the software bill of materials (SBOM) of our containers.\nThe SBOMs are published as an archive with `SPDX-JSON` and `Syft-Table` formats signed using cosign.\nFor releases, they are also pushed into the container registry.\n\nStrimzi uses keyless signing since 0.49.0 release.\nTo verify the SBOM signatures, you can run the following command:\n\n```shell\ncosign verify-blob --bundle <SBOM-file>.bundle \\\n    --certificate-identity-regexp='https://github.com/strimzi/.*' \\\n    --certificate-oidc-issuer='https://token.actions.githubusercontent.com' \\\n    <SBOM-file>\n```\n\nIn case you want to verify SBOM signatures of older version of Strimzi than 0.49.0, then use our public key:\n\n```\n-----BEGIN PUBLIC KEY-----\nMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAET3OleLR7h0JqatY2KkECXhA9ZAkC\nTRnbE23Wb5AzJPnpevvQ1QUEQQ5h/I4GobB7/jkGfqYkt6Ct5WOU2cc6HQ==\n-----END PUBLIC KEY-----\n```\n\nYou can use it to verify the signature of the SBOM files with the following command:\n\n```shell\ncosign verify-blob --key cosign.pub --bundle <SBOM-file>.bundle --insecure-ignore-tlog=true <SBOM-file>\n```\n\n---\n\nStrimzi is a <a href=\"http://cncf.io\">Cloud Native Computing Foundation</a> incubating project.\n\n![CNCF ><](./documentation/logo/cncf-color.png)\n\n[strimzi]: https://strimzi.io \"Strimzi\"\n[kafka]: https://kafka.apache.org \"Apache Kafka\"\n[k8s]: https://kubernetes.io/ \"Kubernetes\"\n[os]: https://www.openshift.com/ \"OpenShift\"\n",
      "stars_today": 5
    },
    {
      "id": 165214494,
      "name": "library",
      "full_name": "ddd-by-examples/library",
      "description": "A comprehensive Domain-Driven Design example with problem space strategic analysis and various tactical patterns.",
      "html_url": "https://github.com/ddd-by-examples/library",
      "stars": 5681,
      "forks": 812,
      "language": "Java",
      "topics": [
        "aggregate",
        "aggregate-root",
        "archunit",
        "c4",
        "crud",
        "ddd",
        "ddd-architecture",
        "domain-driven-design",
        "event-storming",
        "events",
        "functions",
        "hexagonal-architecture",
        "ports-and-adapters",
        "spring",
        "vavr"
      ],
      "created_at": "2019-01-11T09:14:03Z",
      "updated_at": "2026-02-06T09:25:32Z",
      "pushed_at": "2023-07-07T21:43:17Z",
      "open_issues": 23,
      "owner": {
        "login": "ddd-by-examples",
        "avatar_url": "https://avatars.githubusercontent.com/u/37220248?v=4"
      },
      "readme": "[![CircleCI](https://circleci.com/gh/ddd-by-examples/library.svg?style=svg)](https://circleci.com/gh/ddd-by-examples/library)\n[![Code Coverage](https://codecov.io/gh/ddd-by-examples/library/branch/master/graph/badge.svg)](https://codecov.io/gh/ddd-by-examples/library)\n\n# Table of contents\n\n1. [About](#about)\n2. [Domain description](#domain-description)\n3. [General assumptions](#general-assumptions)  \n    3.1 [Process discovery](#process-discovery)  \n    3.2 [Project structure and architecture](#project-structure-and-architecture)    \n    3.3 [Aggregates](#aggregates)  \n    3.4 [Events](#events)  \n    3.4.1 [Events in Repositories](#events-in-repositories)   \n    3.5 [ArchUnit](#archunit)  \n    3.6 [Functional thinking](#functional-thinking)  \n    3.7 [No ORM](#no-orm)  \n    3.8 [Architecture-code gap](#architecture-code-gap)  \n    3.9 [Model-code gap](#model-code-gap)   \n    3.10 [Spring](#spring)  \n    3.11 [Tests](#tests)  \n4. [How to contribute](#how-to-contribute)\n5. [References](#references)\n\n## About\n\nThis is a project of a library, driven by real [business requirements](#domain-description).\nWe use techniques strongly connected with Domain Driven Design, Behavior-Driven Development,\nEvent Storming, User Story Mapping. \n\n## Domain description\n\nA public library allows patrons to place books on hold at its various library branches.\nAvailable books can be placed on hold only by one patron at any given point in time.\nBooks are either circulating or restricted, and can have retrieval or usage fees.\nA restricted book can only be held by a researcher patron. A regular patron is limited\nto five holds at any given moment, while a researcher patron is allowed an unlimited number\nof holds. An open-ended book hold is active until the patron checks out the book, at which time it\nis completed. A closed-ended book hold that is not completed within a fixed number of \ndays after it was requested will expire. This check is done at the beginning of a day by \ntaking a look at daily sheet with expiring holds. Only a researcher patron can request\nan open-ended hold duration. Any patron with more than two overdue checkouts at a library\nbranch will get a rejection if trying a hold at that same library branch. A book can be\nchecked out for up to 60 days. Check for overdue checkouts is done by taking a look at\ndaily sheet with overdue checkouts. Patron interacts with his/her current holds, checkouts, etc.\nby taking a look at patron profile. Patron profile looks like a daily sheet, but the\ninformation there is limited to one patron and is not necessarily daily. Currently a\npatron can see current holds (not canceled nor expired) and current checkouts (including overdue).\nAlso, he/she is able to hold a book and cancel a hold.\n\nHow actually a patron knows which books are there to lend? Library has its catalogue of\nbooks where books are added together with their specific instances. A specific book\ninstance of a book can be added only if there is book with matching ISBN already in\nthe catalogue.  Book must have non-empty title and price. At the time of adding an instance\nwe decide whether it will be Circulating or Restricted. This enables\nus to have book with same ISBN as circulated and restricted at the same time (for instance,\nthere is a book signed by the author that we want to keep as Restricted)\n\n## General assumptions\n\n### Process discovery\n\nThe first thing we started with was domain exploration with the help of Big Picture EventStorming.\nThe description you found in the previous chapter, landed on our virtual wall:    \n![Event Storming Domain description](docs/images/eventstorming-domain-desc.png)   \nThe EventStorming session led us to numerous discoveries, modeled with the sticky notes:  \n![Event Storming Big Picture](docs/images/eventstorming-big-picture.jpg)   \nDuring the session we discovered following definitions:  \n![Event Storming Definitions](docs/images/eventstorming-definitions.png)    \n\nThis made us think of real life scenarios that might happen. We discovered them described with the help of\nthe **Example mapping**:  \n![Example mapping](docs/images/example-mapping.png)  \n\nThis in turn became the base for our *Design Level* sessions, where we analyzed each example:  \n![Example mapping](docs/images/eventstorming-design-level.jpg)  \n\nPlease follow the links below to get more details on each of the mentioned steps:\n- [Big Picture EventStorming](./docs/big-picture.md)\n- [Example Mapping](docs/example-mapping.md)\n- [Design Level EventStorming](docs/design-level.md)\n\n### Project structure and architecture\nAt the very beginning, not to overcomplicate the project, we decided to assign each bounded context\nto a separate package, which means that the system is a modular monolith. There are no obstacles, though,\nto put contexts into maven modules or finally into microservices.\n\nBounded contexts should (amongst others) introduce autonomy in the sense of architecture. Thus, each module\nencapsulating the context has its own local architecture aligned to problem complexity.\nIn the case of a context, where we identified true business logic (**lending**) we introduced a domain model\nthat is a simplified (for the purpose of the project) abstraction of the reality and utilized\nhexagonal architecture. In the case of a context, that during Event Storming turned out to lack any complex\ndomain logic, we applied CRUD-like local architecture.  \n\n![Architecture](docs/images/architecture-big-picture.png) \n\nIf we are talking about hexagonal architecture, it lets us separate domain and application logic from\nframeworks (and infrastructure). What do we gain with this approach? Firstly, we can unit test most important\npart of the application - **business logic** - usually without the need to stub any dependency.\nSecondly, we create ourselves an opportunity to adjust infrastructure layer without the worry of\nbreaking the core functionality. In the infrastructure layer we intensively use Spring Framework\nas probably the most mature and powerful application framework with an incredible test support.\nMore information about how we use Spring you will find [here](#spring).\n\nAs we already mentioned, the architecture was driven by Event Storming sessions. Apart from identifying\ncontexts and their complexity, we could also make a decision that we separate read and write models (CQRS).\nAs an example you can have a look at **Patron Profiles** and *Daily Sheets*.\n\n### Aggregates\nAggregates discovered during Event Storming sessions communicate with each other with events. There is\na contention, though, should they be consistent immediately or eventually? As aggregates in general\ndetermine business boundaries, eventual consistency sounds like a better choice, but choices in software\nare never costless. Providing eventual consistency requires some infrastructural tools, like message broker\nor event store. That's why we could (and did) start with immediate consistency.\n\n> Good architecture is the one which postpones all important decisions\n\n... that's why we made it easy to change the consistency model, providing tests for each option, including\nbasic implementations based on **DomainEvents** interface, which can be adjusted to our needs and\ntoolset in future. Let's have a look at following examples:\n\n* Immediate consistency\n    ```groovy\n    def 'should synchronize Patron, Book and DailySheet with events'() {\n        given:\n            bookRepository.save(book)\n        and:\n            patronRepo.publish(patronCreated())\n        when:\n            patronRepo.publish(placedOnHold(book))\n        then:\n            patronShouldBeFoundInDatabaseWithOneBookOnHold(patronId)\n        and:\n            bookReactedToPlacedOnHoldEvent()\n        and:\n            dailySheetIsUpdated()\n    }\n    \n    boolean bookReactedToPlacedOnHoldEvent() {\n        return bookRepository.findBy(book.bookId).get() instanceof BookOnHold\n    }\n    \n    boolean dailySheetIsUpdated() {\n        return new JdbcTemplate(datasource).query(\"select count(*) from holds_sheet s where s.hold_by_patron_id = ?\",\n                [patronId.patronId] as Object[],\n                new ColumnMapRowMapper()).get(0)\n                .get(\"COUNT(*)\") == 1\n    }\n    ```\n   _Please note that here we are just reading from database right after events are being published_\n   \n   Simple implementation of the event bus is based on Spring application events:\n    ```java\n    @AllArgsConstructor\n    public class JustForwardDomainEventPublisher implements DomainEvents {\n    \n        private final ApplicationEventPublisher applicationEventPublisher;\n    \n        @Override\n        public void publish(DomainEvent event) {\n            applicationEventPublisher.publishEvent(event);\n        }\n    }\n    ```\n\n* Eventual consistency\n    ```groovy\n    def 'should synchronize Patron, Book and DailySheet with events'() {\n        given:\n            bookRepository.save(book)\n        and:\n            patronRepo.publish(patronCreated())\n        when:\n            patronRepo.publish(placedOnHold(book))\n        then:\n            patronShouldBeFoundInDatabaseWithOneBookOnHold(patronId)\n        and:\n            bookReactedToPlacedOnHoldEvent()\n        and:\n            dailySheetIsUpdated()\n    }\n    \n    void bookReactedToPlacedOnHoldEvent() {\n        pollingConditions.eventually {\n            assert bookRepository.findBy(book.bookId).get() instanceof BookOnHold\n        }\n    }\n    \n    void dailySheetIsUpdated() {\n        pollingConditions.eventually {\n            assert countOfHoldsInDailySheet() == 1\n        }\n    }\n    ```\n    _Please note that the test looks exactly the same as previous one, but now we utilized Groovy's\n    **PollingConditions** to perform asynchronous functionality tests_\n\n    Sample implementation of event bus is following:\n    \n    ```java\n    @AllArgsConstructor\n    public class StoreAndForwardDomainEventPublisher implements DomainEvents {\n    \n        private final JustForwardDomainEventPublisher justForwardDomainEventPublisher;\n        private final EventsStorage eventsStorage;\n    \n        @Override\n        public void publish(DomainEvent event) {\n            eventsStorage.save(event);\n        }\n    \n        @Scheduled(fixedRate = 3000L)\n        @Transactional\n        public void publishAllPeriodically() {\n            List<DomainEvent> domainEvents = eventsStorage.toPublish();\n            domainEvents.forEach(justForwardDomainEventPublisher::publish);\n            eventsStorage.published(domainEvents);\n        }\n    }\n    ```\n\nTo clarify, we should always aim for aggregates that can handle a business operation atomically\n(transactionally if you like), so each aggregate should be as independent and decoupled from other\naggregates as possible. Thus, eventual consistency is promoted. As we already mentioned, it comes\nwith some tradeoffs, so from the pragmatic point of view immediate consistency is also a choice.\nYou might ask yourself a question now: _What if I don't have any events yet?_. Well, a pragmatic\napproach would be to encapsulate the communication between aggregates in a _Service-like_ class,\nwhere you could call proper aggregates line by line explicitly.\n\n### Events\nTalking about inter-aggregate communication, we must remember that events reduce coupling, but don't remove\nit completely. Thus, it is very vital to share(publish) only those events, that are necessary for other\naggregates to exist and function. Otherwise there is a threat that the level of coupling will increase\nintroducing **feature envy**, because other aggregates might start using those events to perform actions\nthey are not supposed to perform. A solution to this problem could be the distinction of domain events\nand integration events, which will be described here soon.  \n\n### Events in Repositories \nRepositories are one of the most popular design pattern. They abstract our domain model from data layer. \nIn other words, they deal with state. That said, a common use-case is when we pass a new state to our repository,\nso that it gets persisted. It may look like so:\n\n```java\npublic class BusinessService {\n   \n    private final PatronRepository patronRepository;\n    \n    void businessMethod(PatronId patronId) {\n        Patron patron = patronRepository.findById(patronId);\n        //do sth\n        patronRepository.save(patron);\n    }\n}\n```\n\nConceptually, between 1st and 3rd line of that business method we change state of our Patron from A to B. \nThis change might be calculated by dirty checking or we might just override entire Patron state in the database. \nThird option is _Let's make implicit explicit_ and actually call this state change A->B an **event**. \nAfter all, event-driven architecture is all about promoting state changes as domain events.\n\nThanks to this our domain model may become immutable and just return events as results of invoking a command like so:\n\n```java\npublic BookPlacedOnHold placeOnHold(AvailableBook book) {\n      ...\n}\n```\n\nAnd our repository might operate directly on events like so:\n\n```java\npublic interface PatronRepository {\n     void save(PatronEvent event) {\n}\n```\n\n### ArchUnit\n\nOne of the main components of a successful project is technical leadership that lets the team go in the right\ndirection. Nevertheless, there are tools that can support teams in keeping the code clean and protect the\narchitecture, so that the project won't become a Big Ball of Mud, and thus will be pleasant to develop and\nto maintain. The first option, the one we proposed, is [ArchUnit](https://www.archunit.org/) - a Java architecture\ntest tool. ArchUnit lets you write unit tests of your architecture, so that it is always consistent with initial\nvision. Maven modules could be an alternative as well, but let's focus on the former.\n\nIn terms of hexagonal architecture, it is essential to ensure, that we do not mix different levels of\nabstraction (hexagon levels):\n```java \n@ArchTest\npublic static final ArchRule model_should_not_depend_on_infrastructure =\n    noClasses()\n        .that()\n        .resideInAPackage(\"..model..\")\n        .should()\n        .dependOnClassesThat()\n        .resideInAPackage(\"..infrastructure..\");\n```      \nand that frameworks do not affect the domain model  \n```java\n@ArchTest\npublic static final ArchRule model_should_not_depend_on_spring =\n    noClasses()\n        .that()\n        .resideInAPackage(\"..io.pillopl.library.lending..model..\")\n        .should()\n        .dependOnClassesThat()\n        .resideInAPackage(\"org.springframework..\");\n```    \n\n### Functional thinking\nWhen you look at the code you might find a scent of functional programming. Although we do not follow\na _clean_ FP, we try to think of business processes as pipelines or workflows, utilizing functional style through\nfollowing concepts.\n\n_Please note that this is not a reference project for FP._\n\n#### Immutable objects\nEach class that represents a business concept is immutable, thanks to which we:\n* provide full encapsulation and objects' states protection,\n* secure objects for multithreaded access,\n* control all side effects much clearer. \n\n#### Pure functions\nWe model domain operations, discovered in Design Level Event Storming, as pure functions, and declare them in\nboth domain and application layers in the form of Java's functional interfaces. Their implementations are placed\nin infrastructure layer as ordinary methods with side effects. Thanks to this approach we can follow the abstraction\nof ubiquitous language explicitly, and keep this abstraction implementation-agnostic. As an example, you could have\na look at `FindAvailableBook` interface and its implementation:\n\n```java\n@FunctionalInterface\npublic interface FindAvailableBook {\n\n    Option<AvailableBook> findAvailableBookBy(BookId bookId);\n}\n```\n\n```java\n@AllArgsConstructor\nclass BookDatabaseRepository implements FindAvailableBook {\n\n    private final JdbcTemplate jdbcTemplate;\n\n    @Override\n    public Option<AvailableBook> findAvailableBookBy(BookId bookId) {\n        return Match(findBy(bookId)).of(\n                Case($Some($(instanceOf(AvailableBook.class))), Option::of),\n                Case($(), Option::none)\n        );\n    }  \n\n    Option<Book> findBy(BookId bookId) {\n        return findBookById(bookId)\n                .map(BookDatabaseEntity::toDomainModel);\n    }\n\n    private Option<BookDatabaseEntity> findBookById(BookId bookId) {\n        return Try\n                .ofSupplier(() -> of(jdbcTemplate.queryForObject(\"SELECT b.* FROM book_database_entity b WHERE b.book_id = ?\",\n                                      new BeanPropertyRowMapper<>(BookDatabaseEntity.class), bookId.getBookId())))\n                .getOrElse(none());\n    }  \n} \n```\n    \n#### Type system\n_Type system - like_ modelling - we modelled each domain object's state discovered during EventStorming as separate\nclasses: `AvailableBook`, `BookOnHold`, `CheckedOutBook`. With this approach we provide much clearer abstraction than\nhaving a single `Book` class with an enum-based state management. Moving the logic to these specific classes brings\nSingle Responsibility Principle to a different level. Moreover, instead of checking invariants in every business method\nwe leave the role to the compiler. As an example, please consider following scenario: _you can place on hold only a book\nthat is currently available_. We could have done it in a following way:\n```java\npublic Either<BookHoldFailed, BookPlacedOnHoldEvents> placeOnHold(Book book) {\n  if (book.status == AVAILABLE) {  \n      ...\n  }\n}\n```\nbut we use the _type system_ and declare method of following signature\n```java\npublic Either<BookHoldFailed, BookPlacedOnHoldEvents> placeOnHold(AvailableBook book) {\n      ...\n}\n```  \nThe more errors we discover at compile time the better.\n\nYet another advantage of applying such type system is that we can represent business flows and state transitions\nwith functions much easier. As an example, following functions:\n```\nplaceOnHold: AvailableBook -> BookHoldFailed | BookPlacedOnHold\ncancelHold: BookOnHold -> BookHoldCancelingFailed | BookHoldCanceled\n``` \nare much more concise and descriptive than these:\n```\nplaceOnHold: Book -> BookHoldFailed | BookPlacedOnHold\ncancelHold: Book -> BookHoldCancelingFailed | BookHoldCanceled\n```\nas here we have a lot of constraints hidden within function implementations.\n\nMoreover if you think of your domain as a set of operations (functions) that are being executed on business objects\n(aggregates) you don't think of any execution model (like async processing). It is fine, because you don't have to.\nDomain functions are free from I/O operations, async, and other side-effects-prone things, which are put into the\ninfrastructure layer. Thanks to this, we can easily test them without mocking mentioned parts. \n\n#### Monads\nBusiness methods might have different results. One might return a value or a `null`, throw an exception when something\nunexpected happens or just return different objects under different circumstances. All those situations are typical\nto object-oriented languages like Java, but do not fit into functional style. We are dealing with this issues\nwith monads (monadic containers provided by [Vavr](https://www.vavr.io)):\n* When a method returns optional value, we use the `Option` monad:\n\n    ```java\n    Option<Book> findBy(BookId bookId) {\n        ...\n    }\n    ```\n\n* When a method might return one of two possible values, we use the `Either` monad:\n\n    ```java\n    Either<BookHoldFailed, BookPlacedOnHoldEvents> placeOnHold(AvailableBook book) {\n        ...\n    }\n    ```\n\n* When an exception might occur, we use `Try` monad:\n\n    ```java\n    Try<Result> placeOnHold(@NonNull PlaceOnHoldCommand command) {\n        ...\n    }\n    ```\n\nThanks to this, we can follow the functional programming style, but we also enrich our domain language and\nmake our code much more readable for the clients.\n\n#### Pattern Matching\nDepending on a type of a given book object we often need to perform different actions. Series of if/else or switch/case statements\ncould be a choice, but it is the pattern matching that provides the most conciseness and flexibility. With the code\nlike below we can check numerous patterns against objects and access their constituents, so our code has a minimal dose\nof language-construct noise:\n```java\nprivate Book handleBookPlacedOnHold(Book book, BookPlacedOnHold bookPlacedOnHold) {\n    return API.Match(book).of(\n        Case($(instanceOf(AvailableBook.class)), availableBook -> availableBook.handle(bookPlacedOnHold)),\n        Case($(instanceOf(BookOnHold.class)), bookOnHold -> raiseDuplicateHoldFoundEvent(bookOnHold, bookPlacedOnHold)),\n        Case($(), () -> book)\n    );\n}\n```\n\n### (No) ORM\nIf you run `mvn dependency:tree` you won't find any JPA implementation. Although we think that ORM solutions (like Hibernate)\nare very powerful and useful, we decided not to use them, as we wouldn't utilize their features. What features are\ntalking about? Lazy loading, caching, dirty checking. Why don't we need them? We want to have more control\nover SQL queries and minimize the object-relational impedance mismatch ourselves. Moreover, thanks to relatively\nsmall aggregates, containing as little data as it is required to protect the invariants, we don't need the\nlazy loading mechanism either.\nWith Hexagonal Architecture we have the ability to separate domain and persistence models and test them\nindependently. Moreover, we can also introduce different persistence strategies for different aggregates. \nIn this project, we utilize both plain SQL queries and `JdbcTemplate` and use new and very promising \nproject called Spring Data JDBC, that is free from the JPA-related overhead mentioned before.\nPlease find below an example of a repository:\n\n```java\ninterface PatronEntityRepository extends CrudRepository<PatronDatabaseEntity, Long> {\n\n    @Query(\"SELECT p.* FROM patron_database_entity p where p.patron_id = :patronId\")\n    PatronDatabaseEntity findByPatronId(@Param(\"patronId\") UUID patronId);\n\n}\n```\n\nAt the same time we propose other way of persisting aggregates, with plain SQL queries and `JdbcTemplate`:  \n\n```java\n@AllArgsConstructor\nclass BookDatabaseRepository implements BookRepository, FindAvailableBook, FindBookOnHold {\n\n    private final JdbcTemplate jdbcTemplate;\n\n    @Override\n    public Option<Book> findBy(BookId bookId) {\n        return findBookById(bookId)\n                .map(BookDatabaseEntity::toDomainModel);\n    }\n\n    private Option<BookDatabaseEntity> findBookById(BookId bookId) {\n        return Try\n                .ofSupplier(() -> of(jdbcTemplate.queryForObject(\"SELECT b.* FROM book_database_entity b WHERE b.book_id = ?\",\n                                     new BeanPropertyRowMapper<>(BookDatabaseEntity.class), bookId.getBookId())))\n                .getOrElse(none());\n    }\n    \n    ...\n}\n```\n_Please note that despite having the ability to choose different persistence implementations for aggregates\nit is recommended to stick to one option within the app/team_ \n    \n### Architecture-code gap\nWe put a lot of attention to keep the consistency between the overall architecture (including diagrams)\nand the code structure. Having identified bounded contexts we could organize them in modules (packages, to\nbe more specific). Thanks to this we gain the famous microservices' autonomy, while having a monolithic\napplication. Each package has well defined public API, encapsulating all implementation details by using\npackage-protected or private scopes.\n\nJust by looking at the package structure:\n\n```\nâ””â”€â”€ library\n    â”œâ”€â”€ catalogue\n    â”œâ”€â”€ commons\n    â”‚Â Â  â”œâ”€â”€ aggregates\n    â”‚Â Â  â”œâ”€â”€ commands\n    â”‚Â Â  â””â”€â”€ events\n    â”‚Â Â      â””â”€â”€ publisher\n    â””â”€â”€ lending\n        â”œâ”€â”€ book\n        â”‚Â Â  â”œâ”€â”€ application\n        â”‚Â Â  â”œâ”€â”€ infrastructure\n        â”‚Â Â  â””â”€â”€ model\n        â”œâ”€â”€ dailysheet\n        â”‚Â Â  â”œâ”€â”€ infrastructure\n        â”‚Â Â  â””â”€â”€ model\n        â”œâ”€â”€ librarybranch\n        â”‚Â Â  â””â”€â”€ model\n        â”œâ”€â”€ patron\n        â”‚Â Â  â”œâ”€â”€ application\n        â”‚Â Â  â”œâ”€â”€ infrastructure\n        â”‚Â Â  â””â”€â”€ model\n        â””â”€â”€ patronprofile\n            â”œâ”€â”€ infrastructure\n            â”œâ”€â”€ model\n            â””â”€â”€ web\n```\nyou can see that the architecture is screaming that it has two bounded contexts: **catalogue**\nand **lending**. Moreover, the **lending context** is built around five business objects: **book**,\n**dailysheet**, **librarybranch**, **patron**, and **patronprofile**, while **catalogue** has no subpackages,\nwhich suggests that it might be a CRUD with no complex logic inside. Please find the architecture diagram\nbelow.\n\n![Component diagram](docs/c4/component-diagram.png)\n\nYet another advantage of this approach comparing to packaging by layer for example is that in order to \ndeliver a functionality you would usually need to do it in one package only, which is the aforementioned\nautonomy. This autonomy, then, could be transferred to the level of application as soon as we split our\n_context-packages_ into separate microservices. Following this considerations, autonomy can be given away\nto a product team that can take care of the whole business area end-to-end.\n\n### Model-code gap\nIn our project we do our best to reduce _model-code gap_ to bare minimum. It means we try to put equal attention\nto both the model and the code and keep them consistent. Below you will find some examples.\n\n#### Placing on hold\n![Placing on hold](docs/images/placing_on_hold.jpg)\n\nStarting with the easiest part, below you will find the model classes corresponding to depicted command and events:\n\n```java\n@Value\nclass PlaceOnHoldCommand {\n    ...\n}\n```\n```java\n@Value\nclass BookPlacedOnHold implements PatronEvent {\n    ...\n}\n```\n```java\n@Value\nclass MaximumNumberOfHoldsReached implements PatronEvent {\n    ...    \n}\n```\n```java\n@Value\nclass BookHoldFailed implements PatronEvent {\n    ...\n}\n```\n\nWe know it might not look impressive now, but if you have a look at the implementation of an aggregate,\nyou will see that the code reflects not only the aggregate name, but also the whole scenario of `PlaceOnHold` \ncommand handling. Let us uncover the details:\n\n```java\npublic class Patron {\n\n    public Either<BookHoldFailed, BookPlacedOnHoldEvents> placeOnHold(AvailableBook book) {\n        return placeOnHold(book, HoldDuration.openEnded());\n    }\n    \n    ...\n}    \n```\n\nThe signature of `placeOnHold` method screams, that it is possible to place a book on hold only when it\nis available (more information about protecting invariants by compiler you will find in [Type system section](#type-system)).\nMoreover, if you try to place available book on hold it can **either** fail (`BookHoldFailed`) or produce some events -\nwhat events?\n\n```java\n@Value\nclass BookPlacedOnHoldEvents implements PatronEvent {\n    @NonNull UUID eventId = UUID.randomUUID();\n    @NonNull UUID patronId;\n    @NonNull BookPlacedOnHold bookPlacedOnHold;\n    @NonNull Option<MaximumNumberOfHoldsReached> maximumNumberOfHoldsReached;\n\n    @Override\n    public Instant getWhen() {\n        return bookPlacedOnHold.when;\n    }\n\n    public static BookPlacedOnHoldEvents events(BookPlacedOnHold bookPlacedOnHold) {\n        return new BookPlacedOnHoldEvents(bookPlacedOnHold.getPatronId(), bookPlacedOnHold, Option.none());\n    }\n\n    public static BookPlacedOnHoldEvents events(BookPlacedOnHold bookPlacedOnHold, MaximumNumberOfHoldsReached maximumNumberOfHoldsReached) {\n        return new BookPlacedOnHoldEvents(bookPlacedOnHold.patronId, bookPlacedOnHold, Option.of(maximumNumberOfHoldsReached));\n    }\n\n    public List<DomainEvent> normalize() {\n        return List.<DomainEvent>of(bookPlacedOnHold).appendAll(maximumNumberOfHoldsReached.toList());\n    }\n}\n```\n\n`BookPlacedOnHoldEvents` is a container for `BookPlacedOnHold` event, and - if patron has 5 book placed on hold already -\n`MaximumNumberOfHoldsReached` (please mind the `Option` monad). You can see now how perfectly the code reflects\nthe model.\n\nIt is not everything, though. In the picture above you can also see a big rectangular yellow card with rules (policies)\nthat define the conditions that need to be fulfilled in order to get the given result. All those rules are implemented \nas functions **either** allowing or rejecting the hold:\n\n![Restricted book policy](docs/images/placing-on-hold-policy-restricted.png)\n```java\nPlacingOnHoldPolicy onlyResearcherPatronsCanHoldRestrictedBooksPolicy = (AvailableBook toHold, Patron patron, HoldDuration holdDuration) -> {\n    if (toHold.isRestricted() && patron.isRegular()) {\n        return left(Rejection.withReason(\"Regular patrons cannot hold restricted books\"));\n    }\n    return right(new Allowance());\n};\n```\n\n![Overdue checkouts policy](docs/images/placing-on-hold-policy-overdue.png)\n\n```java\nPlacingOnHoldPolicy overdueCheckoutsRejectionPolicy = (AvailableBook toHold, Patron patron, HoldDuration holdDuration) -> {\n    if (patron.overdueCheckoutsAt(toHold.getLibraryBranch()) >= OverdueCheckouts.MAX_COUNT_OF_OVERDUE_RESOURCES) {\n        return left(Rejection.withReason(\"cannot place on hold when there are overdue checkouts\"));\n    }\n    return right(new Allowance());\n};\n```\n\n![Max number of holds policy](docs/images/placing-on-hold-policy-max.png)\n\n```java\nPlacingOnHoldPolicy regularPatronMaximumNumberOfHoldsPolicy = (AvailableBook toHold, Patron patron, HoldDuration holdDuration) -> {\n    if (patron.isRegular() && patron.numberOfHolds() >= PatronHolds.MAX_NUMBER_OF_HOLDS) {\n        return left(Rejection.withReason(\"patron cannot hold more books\"));\n    }\n    return right(new Allowance());\n};\n```\n\n![Open ended hold policy](docs/images/placing-on-hold-policy-open-ended.png)\n\n```java\nPlacingOnHoldPolicy onlyResearcherPatronsCanPlaceOpenEndedHolds = (AvailableBook toHold, Patron patron, HoldDuration holdDuration) -> {\n    if (patron.isRegular() && holdDuration.isOpenEnded()) {\n        return left(Rejection.withReason(\"regular patron cannot place open ended holds\"));\n    }\n    return right(new Allowance());\n};\n```\n\n#### Spring\nSpring Framework seems to be the most popular Java framework ever used. Unfortunately it is also quite common\nto overuse its features in the business code. What you find in this project is that the domain packages\nare fully focused on modelling business problems, and are free from any DI, which makes it easy to\nunit-test it which is invaluable in terms of code reliability and maintainability. It does not mean,\nthough, that we do not use Spring Framework - we do. Below you will find some details:\n- Each bounded context has its own independent application context. It means that we removed the runtime\ncoupling, which is a step towards extracting modules (and microservices). How did we do that? Let's have\na look:\n    ```java\n    @SpringBootConfiguration\n    @EnableAutoConfiguration\n    public class LibraryApplication {\n    \n        public static void main(String[] args) {\n            new SpringApplicationBuilder()\n                    .parent(LibraryApplication.class)\n                    .child(LendingConfig.class).web(WebApplicationType.SERVLET)\n                    .sibling(CatalogueConfiguration.class).web(WebApplicationType.NONE)\n                    .run(args);\n        }\n    }\n    ```\n- As you could see above, we also try not to use component scan wherever possible. Instead we utilize\n`@Configuration` classes where we define module specific beans in the infrastructure layer. Those\nconfiguration classes are explicitly declared in the main application class.\n\n### Tests\nTests are written in a BDD manner, expressing stories defined with Example Mapping.\nIt means we utilize both TDD and Domain Language discovered with Event Storming. \n\nWe also made an effort to show how to create a DSL, that enables to write\ntests as if they were sentences taken from the domain descriptions. Please\nfind an example below:\n\n```groovy\ndef 'should make book available when hold canceled'() {\n    given:\n        BookDSL bookOnHold = aCirculatingBook() with anyBookId() locatedIn anyBranch() placedOnHoldBy anyPatron()\n    and:\n        PatronEvent.BookHoldCanceled bookHoldCanceledEvent = the bookOnHold isCancelledBy anyPatron()\n\n    when:\n        AvailableBook availableBook = the bookOnHold reactsTo bookHoldCanceledEvent\n    then:\n        availableBook.bookId == bookOnHold.bookId\n        availableBook.libraryBranch == bookOnHold.libraryBranchId\n        availableBook.version == bookOnHold.version\n}\n``` \n_Please also note the **when** block, where we manifest the fact that books react to \ncancellation event_\n\n## How to contribute\n\nThe project is still under construction, so if you like it enough to collaborate, just let us\nknow or simply create a Pull Request.\n\n\n## How to Build\n\n### Requirements\n\n* Java 11\n* Maven\n\n### Quickstart\n\nYou can run the library app by simply typing the following:\n\n```console\n$ mvn spring-boot:run\n...\n...\n2019-04-03 15:55:39.162  INFO 18957 --- [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 2 endpoint(s) beneath base path '/actuator'\n2019-04-03 15:55:39.425  INFO 18957 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''\n2019-04-03 15:55:39.428  INFO 18957 --- [           main] io.pillopl.library.LibraryApplication    : Started LibraryApplication in 5.999 seconds (JVM running for 23.018)\n\n```\n\n### Build a Jar package\n\nYou can build a jar with maven like so:\n\n```console\n$ mvn clean package\n...\n...\n[INFO] Building jar: /home/pczarkowski/development/spring/library/target/library-0.0.1-SNAPSHOT.jar\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n```\n\n### Build with Docker\n\nIf you've already built the jar file you can run:\n\n```console\ndocker build -t spring/library .\n```\n\nOtherwise you can build the jar file using the multistage dockerfile:\n\n```console\ndocker build -t spring/library -f Dockerfile.build .\n```\n\nEither way once built you can run it like so:\n\n```console\n$ docker run -ti --rm --name spring-library -p 8080:8080 spring/library\n```\n\n### Production ready metrics and visualization\nTo run the application as well as Prometheus and Grafana dashboard for visualizing metrics you can run all services:\n\n```console\n$ docker-compose up\n```\n\nIf everything goes well, you can access the following services at given location:\n* http://localhost:8080/actuator/prometheus - published Micrometer metrics\n* http://localhost:9090 - Prometheus dashboard\n* http://localhost:3000 - Grafana dashboard\n\nIn order to see some metrics, you must create a dashboard. Go to `Create` -> `Import` and select attached `jvm-micrometer_rev8.json`. File has been pulled from \n`https://grafana.com/grafana/dashboards/4701`.\n\nPlease note application will be run with `local` Spring profile to setup some initial data.\n\n## References\n\n1. [Introducing EventStorming](https://leanpub.com/introducing_eventstorming) by Alberto Brandolini\n2. [Domain Modelling Made Functional](https://pragprog.com/book/swdddf/domain-modeling-made-functional) by Scott Wlaschin\n3. [Software Architecture for Developers](https://softwarearchitecturefordevelopers.com) by Simon Brown\n4. [Clean Architecture](https://www.amazon.com/Clean-Architecture-Craftsmans-Software-Structure/dp/0134494164) by Robert C. Martin\n5. [Domain-Driven Design: Tackling Complexity in the Heart of Software](https://www.amazon.com/Domain-Driven-Design-Tackling-Complexity-Software/dp/0321125215) by Eric Evans\n",
      "stars_today": 5
    },
    {
      "id": 227091502,
      "name": "perfetto",
      "full_name": "google/perfetto",
      "description": "Production-grade client-side tracing, profiling, and analysis for complex software systems.",
      "html_url": "https://github.com/google/perfetto",
      "stars": 5503,
      "forks": 684,
      "language": "C++",
      "topics": [],
      "created_at": "2019-12-10T10:32:44Z",
      "updated_at": "2026-02-06T22:55:10Z",
      "pushed_at": "2026-02-06T22:31:54Z",
      "open_issues": 205,
      "owner": {
        "login": "google",
        "avatar_url": "https://avatars.githubusercontent.com/u/1342004?v=4"
      },
      "readme": "# Perfetto - System profiling, app tracing and trace analysis\n\nPerfetto is an open-source suite of SDKs, daemons and tools which use\n**tracing** to help developers understand the behaviour of complex systems and\nroot-cause functional and performance issues on client and embedded systems.\n\nIt is a production-grade tool that is the default tracing system for the\n**Android operating system** and the **Chromium browser**.\n\n![](docs/images/perfetto-stack.svg)\n\n## Core Components\n\nPerfetto is not a single tool, but a collection of components that work\ntogether:\n\n- **High-performance tracing daemons:** For capturing tracing information from\n  many processes on a single machine into a unified trace file.\n- **Low-overhead tracing SDK:** A C++17 library for direct\n  userspace-to-userspace tracing of timings and state changes in your\n  application.\n- **Extensive OS-level probes:** For capturing system-wide context on Android\n  and Linux (e.g. scheduling states, CPU frequencies, memory profiling,\n  callstack sampling).\n- **Browser-based UI:** A powerful, fully local UI for visualizing and exploring\n  large, multi-GB traces on a timeline. It works in all major browsers, requires\n  no installation, and can open traces from other tools.\n- **SQL-based analysis library:** A powerful engine that allows you to\n  programmatically query traces using SQL to automate analysis and extract\n  custom metrics.\n\n## Why Use Perfetto?\n\nPerfetto was designed to be a versatile and powerful tracing system for a wide\nrange of use cases.\n\n- **For Android App & Platform Developers:** Debug and root-cause functional and\n  performance issues like slow startups, dropped frames (jank), animation\n  glitches, low memory kills, and ANRs. Profile both Java/Kotlin and native C++\n  memory usage with heap dumps and profiles.\n- **For C/C++ Developers (Linux, macOS, Windows):** Use the\n  [Tracing SDK](docs/instrumentation/tracing-sdk.md) to instrument your\n  application with custom trace points to understand its execution flow, find\n  performance bottlenecks, and debug complex behavior. On Linux, you can also\n  perform detailed CPU and native heap profiling.\n- **For Linux Kernel & System Developers:** Get deep insights into kernel\n  behavior. Perfetto acts as an efficient userspace daemon for `ftrace`,\n  allowing you to visualize scheduling, syscalls, interrupts, and custom kernel\n  tracepoints on a timeline.\n- **For Chromium Developers:** Perfetto is the tracing backend for\n  `chrome://tracing`. Use it to debug and root-cause issues in the browser, V8,\n  and Blink.\n- **For Performance Engineers & SREs:** Analyze and visualize a wide range of\n  profiling and tracing formats, not just Perfetto's. Use the powerful SQL\n  interface to programmatically analyze traces from tools like **Linux perf**,\n  **macOS Instruments**, **Chrome JSON traces**, and more.\n\n## Getting Started\n\nWe've designed our documentation to guide you to the right information as\nquickly as possible, whether you're a newcomer to performance analysis or an\nexperienced developer.\n\n1.  **New to tracing?** If you're unfamiliar with concepts like tracing and\n    profiling, start here:\n\n    - [**What is Tracing?**](https://perfetto.dev/docs/tracing-101) - A gentle\n      introduction to the world of performance analysis.\n\n2.  **Ready to dive in?** Our \"Getting Started\" guide is the main entry point\n    for all users. It will help you find the right tutorials and documentation\n    for your specific needs:\n\n    - [**How do I start using Perfetto?**](https://perfetto.dev/docs/getting-started/start-using-perfetto) -\n      Find your path based on your role and goals (e.g., Android App Developer,\n      C/C++ Developer, etc.).\n\n3.  **Want the full overview?** For a comprehensive look at what Perfetto is,\n    why it's useful, and who uses it, see our main documentation page:\n    - [**Perfetto Documentation Home**](https://perfetto.dev/docs/)\n\n## Debian Distribution\n\nFor users interested in the Debian distribution of Perfetto, the official source\nof truth and packaging efforts are maintained at\n[Debian Perfetto Salsa Repository](https://salsa.debian.org/debian/perfetto)\n\n## Community & Support\n\nHave questions? Need help?\n\n- **[GitHub Discussions](https://github.com/google/perfetto/discussions/categories/q-a):**\n  For Q&A and general discussions.\n- **[GitHub Issues](https://github.com/google/perfetto/issues):** For bug\n  reports.\n- **[Discord](https://discord.gg/35ShE3A):** For live chat with the community\n  and developers.\n\nWe follow\n[Google's Open Source Community Guidelines](https://opensource.google/conduct/).\n",
      "stars_today": 5
    },
    {
      "id": 184341774,
      "name": "cloud-hypervisor",
      "full_name": "cloud-hypervisor/cloud-hypervisor",
      "description": "A Virtual Machine Monitor for modern Cloud workloads. Features include CPU, memory and device hotplug, support for running Windows and Linux guests, device offload with vhost-user and a minimal compact footprint. Written in Rust with a strong focus on security.",
      "html_url": "https://github.com/cloud-hypervisor/cloud-hypervisor",
      "stars": 5244,
      "forks": 580,
      "language": "Rust",
      "topics": [
        "cloud-workloads",
        "kvm",
        "rust-vmm",
        "virtualization"
      ],
      "created_at": "2019-04-30T22:49:03Z",
      "updated_at": "2026-02-07T01:38:56Z",
      "pushed_at": "2026-02-07T01:39:00Z",
      "open_issues": 162,
      "owner": {
        "login": "cloud-hypervisor",
        "avatar_url": "https://avatars.githubusercontent.com/u/50487650?v=4"
      },
      "readme": "- [1. What is Cloud Hypervisor?](#1-what-is-cloud-hypervisor)\n  - [Objectives](#objectives)\n    - [High Level](#high-level)\n    - [Architectures](#architectures)\n    - [Guest OS](#guest-os)\n- [2. Getting Started](#2-getting-started)\n  - [Host OS](#host-os)\n  - [Use Pre-built Binaries](#use-pre-built-binaries)\n  - [Packages](#packages)\n  - [Building from Source](#building-from-source)\n  - [Booting Linux](#booting-linux)\n    - [Firmware Booting](#firmware-booting)\n    - [Custom Kernel and Disk Image](#custom-kernel-and-disk-image)\n      - [Building your Kernel](#building-your-kernel)\n      - [Disk image](#disk-image)\n      - [Booting the guest VM](#booting-the-guest-vm)\n- [3. Status](#3-status)\n  - [Hot Plug](#hot-plug)\n  - [Device Model](#device-model)\n  - [Roadmap](#roadmap)\n- [4. Relationship with _Rust VMM_ Project](#4-relationship-with-rust-vmm-project)\n  - [Differences with Firecracker and crosvm](#differences-with-firecracker-and-crosvm)\n- [5. Community](#5-community)\n  - [Contribute](#contribute)\n  - [Slack](#slack)\n  - [Mailing list](#mailing-list)\n  - [Security issues](#security-issues)\n\n# 1. What is Cloud Hypervisor?\n\nCloud Hypervisor is an open source Virtual Machine Monitor (VMM) that runs on\ntop of the [KVM](https://www.kernel.org/doc/Documentation/virtual/kvm/api.txt)\nhypervisor and the Microsoft Hypervisor (MSHV).\n\nThe project focuses on running modern, _Cloud Workloads_, on specific, common,\nhardware architectures. In this case _Cloud Workloads_ refers to those that are\nrun by customers inside a Cloud Service Provider. This means modern operating\nsystems with most I/O handled by\nparavirtualised devices (e.g. _virtio_), no requirement for legacy devices, and\n64-bit CPUs.\n\nCloud Hypervisor is implemented in [Rust](https://www.rust-lang.org/) and is\nbased on the [Rust VMM](https://github.com/rust-vmm) crates.\n\n## Objectives\n\n### High Level\n\n- Runs on KVM or MSHV\n- Minimal emulation\n- Low latency\n- Low memory footprint\n- Low complexity\n- High performance\n- Small attack surface\n- 64-bit support only\n- CPU, memory, PCI hotplug\n- Machine to machine migration\n\n### Architectures\n\nCloud Hypervisor supports the `x86-64`, `AArch64` and `riscv64`\narchitectures, with functionality varying across these platforms. The\nfunctionality differences between `x86-64` and `AArch64` are documented\nin [#1125](https://github.com/cloud-hypervisor/cloud-hypervisor/issues/1125).\nThe `riscv64` architecture support is experimental and offers limited\nfunctionality. For more details and instructions, please refer to [riscv\ndocumentation](docs/riscv.md).\n\n### Guest OS\n\nCloud Hypervisor supports `64-bit Linux` and Windows 10/Windows Server 2019.\n\n# 2. Getting Started\n\nThe following sections describe how to build and run Cloud Hypervisor.\n\n## Prerequisites for AArch64\n\n- AArch64 servers (recommended) or development boards equipped with the GICv3\n  interrupt controller.\n\n## Host OS\n\nFor required KVM functionality and adequate performance the recommended host\nkernel version is 5.13. The majority of the CI currently tests with kernel\nversion 5.15.\n\n## Use Pre-built Binaries\n\nThe recommended approach to getting started with Cloud Hypervisor is by using a\npre-built binary. Binaries are available for the [latest\nrelease](https://github.com/cloud-hypervisor/cloud-hypervisor/releases/latest).\nUse `cloud-hypervisor-static` for `x86-64` or `cloud-hypervisor-static-aarch64`\nfor `AArch64` platform.\n\n## Packages\n\nFor convenience, packages are also available targeting some popular Linux\ndistributions. This is thanks to the [Open Build\nService](https://build.opensuse.org). The [OBS\nREADME](https://github.com/cloud-hypervisor/obs-packaging) explains how to\nenable the repository in a supported Linux distribution and install Cloud Hypervisor\nand accompanying packages. Please report any packaging issues in the\n[obs-packaging](https://github.com/cloud-hypervisor/obs-packaging) repository.\n\n## Building from Source\n\nPlease see the [instructions for building from source](docs/building.md) if you\ndo not wish to use the pre-built binaries.\n\n## Booting Linux\n\nCloud Hypervisor supports direct kernel boot (the x86-64 kernel requires the kernel\nbuilt with PVH support or a bzImage) or booting via a firmware (either [Rust Hypervisor\nFirmware](https://github.com/cloud-hypervisor/rust-hypervisor-firmware) or an\nedk2 UEFI firmware called `CLOUDHV` / `CLOUDHV_EFI`.)\n\nBinary builds of the firmware files are available for the latest release of\n[Rust Hypervisor\nFirmware](https://github.com/cloud-hypervisor/rust-hypervisor-firmware/releases/latest)\nand [our edk2\nrepository](https://github.com/cloud-hypervisor/edk2/releases/latest)\n\nThe choice of firmware depends on your guest OS choice; some experimentation\nmay be required.\n\n### Firmware Booting\n\nCloud Hypervisor supports booting disk images containing all needed components\nto run cloud workloads, a.k.a. cloud images.\n\nThe following sample commands will download an Ubuntu Cloud image, converting\nit into a format that Cloud Hypervisor can use and a firmware to boot the image\nwith.\n\n```shell\n$ wget https://cloud-images.ubuntu.com/focal/current/focal-server-cloudimg-amd64.img\n$ qemu-img convert -p -f qcow2 -O raw focal-server-cloudimg-amd64.img focal-server-cloudimg-amd64.raw\n$ wget https://github.com/cloud-hypervisor/rust-hypervisor-firmware/releases/download/0.4.2/hypervisor-fw\n```\n\nThe Ubuntu cloud images do not ship with a default password so it necessary to\nuse a `cloud-init` disk image to customise the image on the first boot. A basic\n`cloud-init` image is generated by this [script](scripts/create-cloud-init.sh).\nThis seeds the image with a default username/password of `cloud/cloud123`. It\nis only necessary to add this disk image on the first boot. Script also assigns\ndefault IP address using `test_data/cloud-init/ubuntu/local/network-config` details\nwith `--net \"mac=12:34:56:78:90:ab,tap=\"` option. Then the matching mac address\ninterface will be enabled as per `network-config` details.\n\n```shell\n$ sudo setcap cap_net_admin+ep ./cloud-hypervisor\n$ ./create-cloud-init.sh\n$ ./cloud-hypervisor \\\n\t--firmware ./hypervisor-fw \\\n\t--disk path=focal-server-cloudimg-amd64.raw path=/tmp/ubuntu-cloudinit.img \\\n\t--cpus boot=4 \\\n\t--memory size=1024M \\\n\t--net \"tap=,mac=,ip=,mask=\"\n```\n\nIf access to the firmware messages or interaction with the boot loader (e.g.\nGRUB) is required then it necessary to switch to the serial console instead of\n`virtio-console`.\n\n```shell\n$ ./cloud-hypervisor \\\n\t--kernel ./hypervisor-fw \\\n\t--disk path=focal-server-cloudimg-amd64.raw path=/tmp/ubuntu-cloudinit.img \\\n\t--cpus boot=4 \\\n\t--memory size=1024M \\\n\t--net \"tap=,mac=,ip=,mask=\" \\\n\t--serial tty \\\n\t--console off\n```\n\n## Booting: `--firmware` vs `--kernel`\n\nThe following scenarios are supported by Cloud Hypervisor to bootstrap a VM, i.e.,\nto load a payload/bootitem(s):\n\n- Provide firmware\n- Provide kernel \\[+ cmdline\\]\\ [+ initrd\\]\n\nPlease note that our Cloud Hypervisor firmware (`hypervisor-fw`) has a Xen PVH\nboot entry, therefore it can also be booted via the `--kernel` parameter, as \nseen in some examples.\n\n### Custom Kernel and Disk Image\n\n#### Building your Kernel\n\nCloud Hypervisor also supports direct kernel boot. For x86-64, a `vmlinux` ELF kernel (compiled with PVH support) or a regular bzImage are supported. In order to support development there is a custom branch; however provided the required options are enabled any recent kernel will suffice.\n\nTo build the kernel:\n\n```shell\n# Clone the Cloud Hypervisor Linux branch\n$ git clone --depth 1 https://github.com/cloud-hypervisor/linux.git -b ch-6.12.8 linux-cloud-hypervisor\n$ pushd linux-cloud-hypervisor\n$ make ch_defconfig\n# Do native build of the x86-64 kernel\n$ KCFLAGS=\"-Wa,-mx86-used-note=no\" make bzImage -j `nproc`\n# Do native build of the AArch64 kernel\n$ make -j `nproc`\n$ popd\n```\n\nFor x86-64, the `vmlinux` kernel image will then be located at\n`linux-cloud-hypervisor/arch/x86/boot/compressed/vmlinux.bin`.\nFor AArch64, the `Image` kernel image will then be located at\n`linux-cloud-hypervisor/arch/arm64/boot/Image`.\n\n#### Disk image\n\nFor the disk image the same Ubuntu image as before can be used. This contains\nan `ext4` root filesystem.\n\n```shell\n$ wget https://cloud-images.ubuntu.com/focal/current/focal-server-cloudimg-amd64.img # x86-64\n$ wget https://cloud-images.ubuntu.com/focal/current/focal-server-cloudimg-arm64.img # AArch64\n$ qemu-img convert -p -f qcow2 -O raw focal-server-cloudimg-amd64.img focal-server-cloudimg-amd64.raw # x86-64\n$ qemu-img convert -p -f qcow2 -O raw focal-server-cloudimg-arm64.img focal-server-cloudimg-arm64.raw # AArch64\n```\n\n#### Booting the guest VM\n\nThese sample commands boot the disk image using the custom kernel whilst also\nsupplying the desired kernel command line.\n\n- x86-64\n\n```shell\n$ sudo setcap cap_net_admin+ep ./cloud-hypervisor\n$ ./create-cloud-init.sh\n$ ./cloud-hypervisor \\\n\t--kernel ./linux-cloud-hypervisor/arch/x86/boot/compressed/vmlinux.bin \\\n\t--disk path=focal-server-cloudimg-amd64.raw path=/tmp/ubuntu-cloudinit.img \\\n\t--cmdline \"console=hvc0 root=/dev/vda1 rw\" \\\n\t--cpus boot=4 \\\n\t--memory size=1024M \\\n\t--net \"tap=,mac=,ip=,mask=\"\n```\n\n- AArch64\n\n```shell\n$ sudo setcap cap_net_admin+ep ./cloud-hypervisor\n$ ./create-cloud-init.sh\n$ ./cloud-hypervisor \\\n\t--kernel ./linux-cloud-hypervisor/arch/arm64/boot/Image \\\n\t--disk path=focal-server-cloudimg-arm64.raw path=/tmp/ubuntu-cloudinit.img \\\n\t--cmdline \"console=hvc0 root=/dev/vda1 rw\" \\\n\t--cpus boot=4 \\\n\t--memory size=1024M \\\n\t--net \"tap=,mac=,ip=,mask=\"\n```\n\nIf earlier kernel messages are required the serial console should be used instead of `virtio-console`.\n\n- x86-64\n\n```shell\n$ ./cloud-hypervisor \\\n\t--kernel ./linux-cloud-hypervisor/arch/x86/boot/compressed/vmlinux.bin \\\n\t--console off \\\n\t--serial tty \\\n\t--disk path=focal-server-cloudimg-amd64.raw \\\n\t--cmdline \"console=ttyS0 root=/dev/vda1 rw\" \\\n\t--cpus boot=4 \\\n\t--memory size=1024M \\\n\t--net \"tap=,mac=,ip=,mask=\"\n```\n\n- AArch64\n\n```shell\n$ ./cloud-hypervisor \\\n\t--kernel ./linux-cloud-hypervisor/arch/arm64/boot/Image \\\n\t--console off \\\n\t--serial tty \\\n\t--disk path=focal-server-cloudimg-arm64.raw \\\n\t--cmdline \"console=ttyAMA0 root=/dev/vda1 rw\" \\\n\t--cpus boot=4 \\\n\t--memory size=1024M \\\n\t--net \"tap=,mac=,ip=,mask=\"\n```\n\n# 3. Status\n\nCloud Hypervisor is under active development. The following stability\nguarantees are currently made:\n\n* The API (including command line options) will not be removed or changed in a\n  breaking way without a minimum of 2 major releases notice. Where possible\n  warnings will be given about the use of deprecated functionality and the\n  deprecations will be documented in the release notes.\n\n* Point releases will be made between individual releases where there are\n  substantial bug fixes or security issues that need to be fixed. These point\n  releases will only include bug fixes.\n\nCurrently the following items are **not** guaranteed across updates:\n\n* Snapshot/restore is not supported across different versions\n* Live migration is not supported across different versions\n* The following features are considered experimental and may change\n  substantially between releases: TDX, vfio-user, vDPA.\n\nFurther details can be found in the [release documentation](docs/releases.md).\n\nAs of 2023-01-03, the following cloud images are supported:\n\n- [Ubuntu Focal](https://cloud-images.ubuntu.com/focal/current/) (focal-server-cloudimg-{amd64,arm64}.img)\n- [Ubuntu Jammy](https://cloud-images.ubuntu.com/jammy/current/) (jammy-server-cloudimg-{amd64,arm64}.img)\n- [Ubuntu Noble](https://cloud-images.ubuntu.com/noble/current/) (noble-server-cloudimg-{amd64,arm64}.img)\n- [Fedora 36](https://archives.fedoraproject.org/pub/archive/fedora/linux/releases/36/Cloud/) ([Fedora-Cloud-Base-36-1.5.x86_64.raw.xz](https://archives.fedoraproject.org/pub/archive/fedora/linux/releases/36/Cloud/x86_64/images/) / [Fedora-Cloud-Base-36-1.5.aarch64.raw.xz](https://archives.fedoraproject.org/pub/archive/fedora/linux/releases/36/Cloud/aarch64/images/))\n\nDirect kernel boot to userspace should work with a rootfs from most\ndistributions although you may need to enable exotic filesystem types in the\nreference kernel configuration (e.g. XFS or btrfs.)\n\n## Hot Plug\n\nCloud Hypervisor supports hotplug of CPUs, passthrough devices (VFIO),\n`virtio-{net,block,pmem,fs,vsock}` and memory resizing. This\n[document](docs/hotplug.md) details how to add devices to a running VM.\n\n## Device Model\n\nDetails of the device model can be found in this\n[documentation](docs/device_model.md).\n\n## Roadmap\n\nThe project roadmap is tracked through a [GitHub\nproject](https://github.com/orgs/cloud-hypervisor/projects/6).\n\n# 4. Relationship with _Rust VMM_ Project\n\nIn order to satisfy the design goal of having a high-performance,\nsecurity-focused hypervisor the decision was made to use the\n[Rust](https://www.rust-lang.org/) programming language. The language's strong\nfocus on memory and thread safety makes it an ideal candidate for implementing\nVMMs.\n\nInstead of implementing the VMM components from scratch, Cloud Hypervisor is\nimporting the [Rust VMM](https://github.com/rust-vmm) crates, and sharing code\nand architecture together with other VMMs like e.g. Amazon's\n[Firecracker](https://firecracker-microvm.github.io/) and Google's\n[crosvm](https://chromium.googlesource.com/chromiumos/platform/crosvm/).\n\nCloud Hypervisor embraces the _Rust VMM_ project's goals, which is to be able\nto share and re-use as many virtualization crates as possible.\n\n## Differences with Firecracker and crosvm\n\nA large part of the Cloud Hypervisor code is based on either the Firecracker or\nthe crosvm project's implementations. Both of these are VMMs written in Rust\nwith a focus on safety and security, like Cloud Hypervisor.\n\nThe goal of the Cloud Hypervisor project differs from the aforementioned\nprojects in that it aims to be a general purpose VMM for _Cloud Workloads_ and\nnot limited to container/serverless or client workloads.\n\nThe Cloud Hypervisor community thanks the communities of both the Firecracker\nand crosvm projects for their excellent work.\n\n# 5. Community\n\nThe Cloud Hypervisor project follows the governance, and community guidelines\ndescribed in the [Community](https://github.com/cloud-hypervisor/community)\nrepository.\n\n## Contribute\n\nThe project strongly believes in building a global, diverse and collaborative\ncommunity around the Cloud Hypervisor project. Anyone who is interested in\n[contributing](CONTRIBUTING.md) to the project is welcome to participate.\n\nContributing to a open source project like Cloud Hypervisor covers a lot more\nthan just sending code. Testing, documentation, pull request\nreviews, bug reports, feature requests, project improvement suggestions, etc,\nare all equal and welcome means of contribution. See the\n[CONTRIBUTING](CONTRIBUTING.md) document for more details.\n\n## Slack\n\nGet an [invite to our Slack channel](https://join.slack.com/t/cloud-hypervisor/shared_invite/enQtNjY3MTE3MDkwNDQ4LWQ1MTA1ZDVmODkwMWQ1MTRhYzk4ZGNlN2UwNTI3ZmFlODU0OTcwOWZjMTkwZDExYWE3YjFmNzgzY2FmNDAyMjI),\n [join us on Slack](https://cloud-hypervisor.slack.com/), and [participate in our community activities](https://cloud-hypervisor.slack.com/archives/C04R5DUQVBN).\n\n## Mailing list\n\nPlease report bugs using the [GitHub issue\ntracker](https://github.com/cloud-hypervisor/cloud-hypervisor/issues) but for\nbroader community discussions you may use our [mailing\nlist](https://lists.cloudhypervisor.org/g/dev/).\n\n## Security issues\n\nPlease contact the maintainers listed in the MAINTAINERS.md file with security issues.\n",
      "stars_today": 5
    },
    {
      "id": 51148780,
      "name": "architecture-samples",
      "full_name": "android/architecture-samples",
      "description": "A collection of samples to discuss and showcase different architectural tools and patterns for Android apps.",
      "html_url": "https://github.com/android/architecture-samples",
      "stars": 45541,
      "forks": 11854,
      "language": "Kotlin",
      "topics": [
        "android",
        "android-architecture",
        "samples"
      ],
      "created_at": "2016-02-05T13:42:07Z",
      "updated_at": "2026-02-07T01:45:53Z",
      "pushed_at": "2026-02-05T09:34:00Z",
      "open_issues": 217,
      "owner": {
        "login": "android",
        "avatar_url": "https://avatars.githubusercontent.com/u/32689599?v=4"
      },
      "readme": "# Android Architecture Samples\n\nThese samples showcase different architectural approaches to developing Android apps. In its different branches you'll find the same app (a TODO app) implemented with small differences.\n\nIn this branch you'll find:\n*   User Interface built with **[Jetpack Compose](https://developer.android.com/jetpack/compose)** \n*   A single-activity architecture, using **[Navigation Compose](https://developer.android.com/jetpack/compose/navigation)**.\n*   A presentation layer that contains a Compose screen (View) and a **ViewModel** per screen (or feature).\n*   Reactive UIs using **[Flow](https://developer.android.com/kotlin/flow)** and **[coroutines](https://kotlinlang.org/docs/coroutines-overview.html)** for asynchronous operations.\n*   A **data layer** with a repository and two data sources (local using Room and a fake remote).\n*   Two **product flavors**, `mock` and `prod`, [to ease development and testing](https://android-developers.googleblog.com/2015/12/leveraging-product-flavors-in-android.html).\n*   A collection of unit, integration and e2e **tests**, including \"shared\" tests that can be run on emulator/device.\n*   Dependency injection using [Hilt](https://developer.android.com/training/dependency-injection/hilt-android).\n\n## Screenshots\n\n<img src=\"screenshots/screenshots.png\" alt=\"Screenshot\">\n\n## Why a to-do app?\n\nThe app in this project aims to be simple enough that you can understand it quickly, but complex enough to showcase difficult design decisions and testing scenarios. For more information, see the [app's specification](https://github.com/googlesamples/android-architecture/wiki/To-do-app-specification).\n\n## What is it not?\n*   A template. Check out the [Architecture Templates](https://github.com/android/architecture-templates) instead.\n*   A UI/Material Design sample. The interface of the app is deliberately kept simple to focus on architecture. Check out the [Compose Samples](https://github.com/android/compose-samples) instead.\n*   A real production app with network access, user authentication, etc. Check out the [Now in Android app](https://github.com/android/nowinandroid) instead.\n\n## Who is it for?\n\n*   Intermediate developers and beginners looking for a way to structure their app in a testable and maintainable way.\n*   Advanced developers looking for quick reference.\n\n## Opening a sample in Android Studio\n\nTo open one of the samples in Android Studio, begin by checking out one of the sample branches, and then open the root directory in Android Studio. The following series of steps illustrate how to open the sample.\n\nClone the repository:\n\n```\ngit clone git@github.com:android/architecture-samples.git\n```\n\nFinally open the `architecture-samples/` directory in Android Studio.\n\n### License\n\n\n```\nCopyright 2024 Google, Inc.\n\nLicensed to the Apache Software Foundation (ASF) under one or more contributor\nlicense agreements. See the NOTICE file distributed with this work for\nadditional information regarding copyright ownership. The ASF licenses this\nfile to you under the Apache License, Version 2.0 (the \"License\"); you may not\nuse this file except in compliance with the License. You may obtain a copy of\nthe License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\nWARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\nLicense for the specific language governing permissions and limitations under\nthe License.\n```\n",
      "stars_today": 4
    },
    {
      "id": 5152285,
      "name": "okhttp",
      "full_name": "square/okhttp",
      "description": "Squareâ€™s meticulous HTTP client for the JVM, Android, and GraalVM.",
      "html_url": "https://github.com/square/okhttp",
      "stars": 46863,
      "forks": 9260,
      "language": "Kotlin",
      "topics": [
        "android",
        "graalvm",
        "java",
        "kotlin"
      ],
      "created_at": "2012-07-23T13:42:55Z",
      "updated_at": "2026-02-06T15:09:22Z",
      "pushed_at": "2026-02-05T22:47:58Z",
      "open_issues": 86,
      "owner": {
        "login": "square",
        "avatar_url": "https://avatars.githubusercontent.com/u/82592?v=4"
      },
      "readme": "OkHttp\n======\n\nSee the [project website][okhttp] for documentation and APIs.\n\nHTTP is the way modern applications network. Itâ€™s how we exchange data & media. Doing HTTP\nefficiently makes your stuff load faster and saves bandwidth.\n\nOkHttp is an HTTP client thatâ€™s efficient by default:\n\n * HTTP/2 support allows all requests to the same host to share a socket.\n * Connection pooling reduces request latency (if HTTP/2 isnâ€™t available).\n * Transparent GZIP shrinks download sizes.\n * Response caching avoids the network completely for repeat requests.\n\nOkHttp perseveres when the network is troublesome: it will silently recover from common connection\nproblems. If your service has multiple IP addresses, OkHttp will attempt alternate addresses if the\nfirst connect fails. This is necessary for IPv4+IPv6 and services hosted in redundant data\ncenters. OkHttp supports modern TLS features (TLS 1.3, ALPN, certificate pinning). It can be\nconfigured to fall back for broad connectivity.\n\nUsing OkHttp is easy. Its request/response API is designed with fluent builders and immutability. It\nsupports both synchronous blocking calls and async calls with callbacks.\n\nA well behaved user agent\n-------------------------\n\nOkHttp follows modern HTTP specifications such as\n\n* HTTP Semantics - [RFC 9110](https://datatracker.ietf.org/doc/html/rfc9110)\n* HTTP Caching- [RFC 9111](https://datatracker.ietf.org/doc/html/rfc9111)\n* HTTP/1.1 - [RFC 9112](https://datatracker.ietf.org/doc/html/rfc9112)\n* HTTP/2 - [RFC 9113](https://datatracker.ietf.org/doc/html/rfc9113)\n* Websockets - [RFC 6455](https://datatracker.ietf.org/doc/html/rfc6455)\n* SSE - [Server-sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events)\n\nWhere the spec is ambiguous, OkHttp follows modern user agents such as popular Browsers or common HTTP Libraries.\n\nOkHttp is principled and avoids being overly configurable, especially when such configuration is\nto workaround a buggy server, test invalid scenarios or that contradict the relevant RFC.\nOther HTTP libraries exist that fill that gap allowing extensive customisation including potentially\ninvalid requests.\n\nExample Limitations\n\n* Does not allow GET with a body.\n* Cache is not an interface with alternative implementations.\n\nGet a URL\n---------\n\nThis program downloads a URL and prints its contents as a string. [Full source][get_example].\n\n```java\nOkHttpClient client = new OkHttpClient();\n\nString run(String url) throws IOException {\n  Request request = new Request.Builder()\n      .url(url)\n      .build();\n\n  try (Response response = client.newCall(request).execute()) {\n    return response.body().string();\n  }\n}\n```\n\n\nPost to a Server\n----------------\n\nThis program posts data to a service. [Full source][post_example].\n\n```java\npublic static final MediaType JSON = MediaType.get(\"application/json\");\n\nOkHttpClient client = new OkHttpClient();\n\nString post(String url, String json) throws IOException {\n  RequestBody body = RequestBody.create(json, JSON);\n  Request request = new Request.Builder()\n      .url(url)\n      .post(body)\n      .build();\n  try (Response response = client.newCall(request).execute()) {\n    return response.body().string();\n  }\n}\n```\n\nFurther examples are on the [OkHttp Recipes page][recipes].\n\n\nRequirements\n------------\n\nOkHttp works on Android 5.0+ (API level 21+) and Java 8+.\n\nOn Android, OkHttp uses [AndroidX Startup][androidx_startup]. If you disable the initializer in the manifest,\nthen apps are responsible for calling `OkHttp.initialize(applicationContext)` in `Application.onCreate`.\n\nOkHttp depends on [Okio][okio] for high-performance I/O and the [Kotlin standard library][kotlin]. Both are small libraries with strong backward-compatibility.\n\nWe highly recommend you keep OkHttp up-to-date. As with auto-updating web browsers, staying current\nwith HTTPS clients is an important defense against potential security problems. [We\ntrack][tls_history] the dynamic TLS ecosystem and adjust OkHttp to improve connectivity and\nsecurity.\n\nOkHttp uses your platform's built-in TLS implementation. On Java platforms OkHttp also supports\n[Conscrypt][conscrypt], which integrates [BoringSSL](https://github.com/google/boringssl) with Java. OkHttp will use Conscrypt if it is\nthe first security provider:\n\n```java\nSecurity.insertProviderAt(Conscrypt.newProvider(), 1);\n```\n\nThe OkHttp `3.12.x` branch supports Android 2.3+ (API level 9+) and Java 7+. These platforms lack\nsupport for TLS 1.2 and should not be used.\n\n\nReleases\n--------\n\nOur [change log][changelog] has release history.\n\nThe latest release is available on [Maven Central](https://search.maven.org/artifact/com.squareup.okhttp3/okhttp/5.3.0/jar).\n\n```kotlin\nimplementation(\"com.squareup.okhttp3:okhttp:5.3.0\")\n```\n\nSnapshot builds are [available][snap]. [R8 and ProGuard][r8_proguard] rules are available.\n\nAlso, we have a [bill of materials (BOM)][bom] available to help you keep OkHttp artifacts up to date and be sure about version compatibility.\n\n```kotlin\n    dependencies {\n       // define a BOM and its version\n       implementation(platform(\"com.squareup.okhttp3:okhttp-bom:5.3.0\"))\n\n       // define any required OkHttp artifacts without version\n       implementation(\"com.squareup.okhttp3:okhttp\")\n       implementation(\"com.squareup.okhttp3:logging-interceptor\")\n    }\n```\n\nMaven and JVM Projects\n----------------------\n\nOkHttp is published as a Kotlin Multiplatform project. While Gradle handles this automatically,\nMaven projects must select between `okhttp-jvm` and `okhttp-android`. The `okhttp` artifact will be empty in\nMaven projects.\n\n```xml\n<dependencyManagement>\n  <dependencies>\n    <dependency>\n      <groupId>com.squareup.okhttp3</groupId>\n      <artifactId>okhttp-bom</artifactId>\n      <version>5.2.0</version>\n      <type>pom</type>\n      <scope>import</scope>\n    </dependency>\n  </dependencies>\n</dependencyManagement>\n```\n\n\n\n```xml\n<dependency>\n  <groupId>com.squareup.okhttp3</groupId>\n  <artifactId>okhttp-jvm</artifactId>\n  <!-- Remove after OkHttp 5.2.0 with updated BOM. -->\n  <version>5.1.0</version>\n</dependency>\n\n<dependency>\n  <groupId>com.squareup.okhttp3</groupId>\n  <artifactId>mockwebserver3</artifactId>\n</dependency>\n\n<dependency>\n  <groupId>com.squareup.okhttp3</groupId>\n  <artifactId>logging-interceptor</artifactId>\n</dependency>\n```\n\nMockWebServer\n-------------\n\nOkHttp includes a library for testing HTTP, HTTPS, and HTTP/2 clients.\n\nThe latest release is available on [Maven Central](https://search.maven.org/artifact/com.squareup.okhttp3/mockwebserver/5.3.0/jar).\n\n```kotlin\ntestImplementation(\"com.squareup.okhttp3:mockwebserver3:5.3.0\")\n```\n\nMockWebServer is used for firstly for internal testing, and for basic testing of apps using OkHttp client.\nIt is not a full featured HTTP testing library that is developed standalone. It is not being actively developed\nfor new features. As such you might find your needs outgrow MockWebServer and you may which to use a\nmore full featured testing library such as [MockServer](https://www.mock-server.com/).\n\nGraalVM Native Image\n--------------------\n\nBuilding your native images with [GraalVM] should work automatically.\n\nSee the okcurl module for an example build.\n\n```shell\n$ ./gradlew okcurl:nativeImage\n$ ./okcurl/build/graal/okcurl https://httpbin.org/get\n```\n\nJava Modules\n------------\n\nOkHttp (5.2+) implements Java 9 Modules.\n\nWith this in place Java builds should fail if apps attempt to use internal packages.\n\n```\nerror: package okhttp3.internal.platform is not visible\n    okhttp3.internal.platform.Platform.get();\n                    ^\n  (package okhttp3.internal.platform is declared in module okhttp3,\n    which does not export it to module com.bigco.sdk)\n```\n\nThe stable public API is based on the list of defined modules:\n\n- okhttp3\n- okhttp3.brotli\n- okhttp3.coroutines\n- okhttp3.dnsoverhttps\n- okhttp3.java.net.cookiejar\n- okhttp3.logging\n- okhttp3.sse\n- okhttp3.tls\n- okhttp3.urlconnection\n- mockwebserver3\n- mockwebserver3.junit4\n- mockwebserver3.junit5\n\nLicense\n-------\n\n```\nCopyright 2019 Square, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n [GraalVM]: https://www.graalvm.org/\n [androidx_startup]: https://developer.android.com/jetpack/androidx/releases/startup\n [bom]: https://docs.gradle.org/6.2/userguide/platforms.html#sub:bom_import\n [changelog]: https://square.github.io/okhttp/changelog/\n [conscrypt]: https://github.com/google/conscrypt/\n [get_example]: https://raw.github.com/square/okhttp/master/samples/guide/src/main/java/okhttp3/guide/GetExample.java\n [kotlin]: https://kotlinlang.org/\n [okhttp3_pro]: https://raw.githubusercontent.com/square/okhttp/master/okhttp/src/main/resources/META-INF/proguard/okhttp3.pro\n [okhttp]: https://square.github.io/okhttp/\n [okhttp_312x]: https://github.com/square/okhttp/tree/okhttp_3.12.x\n [okio]: https://github.com/square/okio\n [post_example]: https://raw.github.com/square/okhttp/master/samples/guide/src/main/java/okhttp3/guide/PostExample.java\n [r8_proguard]: https://square.github.io/okhttp/features/r8_proguard/\n [recipes]: https://square.github.io/okhttp/recipes/\n [snap]: https://s01.oss.sonatype.org/content/repositories/snapshots/\n [tls_history]: https://square.github.io/okhttp/tls_configuration_history/\n",
      "stars_today": 4
    },
    {
      "id": 23418517,
      "name": "hadoop",
      "full_name": "apache/hadoop",
      "description": "Apache Hadoop",
      "html_url": "https://github.com/apache/hadoop",
      "stars": 15469,
      "forks": 9195,
      "language": "Java",
      "topics": [
        "hadoop"
      ],
      "created_at": "2014-08-28T07:00:08Z",
      "updated_at": "2026-02-06T17:41:46Z",
      "pushed_at": "2026-02-06T17:54:31Z",
      "open_issues": 96,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "For the latest information about Hadoop, please visit our website at:\n\n   http://hadoop.apache.org/\n\nand our wiki, at:\n\n   https://cwiki.apache.org/confluence/display/HADOOP/\n",
      "stars_today": 4
    },
    {
      "id": 483402734,
      "name": "nowinandroid",
      "full_name": "android/nowinandroid",
      "description": "A fully functional Android app built entirely with Kotlin and Jetpack Compose",
      "html_url": "https://github.com/android/nowinandroid",
      "stars": 20537,
      "forks": 4163,
      "language": "Kotlin",
      "topics": [
        "android",
        "jetpack-compose",
        "kotlin"
      ],
      "created_at": "2022-04-19T20:40:24Z",
      "updated_at": "2026-02-06T23:53:49Z",
      "pushed_at": "2026-02-07T00:38:59Z",
      "open_issues": 250,
      "owner": {
        "login": "android",
        "avatar_url": "https://avatars.githubusercontent.com/u/32689599?v=4"
      },
      "readme": "![Now in Android](docs/images/nia-splash.jpg \"Now in Android\")\n\n<a href=\"https://play.google.com/store/apps/details?id=com.google.samples.apps.nowinandroid\"><img src=\"https://play.google.com/intl/en_us/badges/static/images/badges/en_badge_web_generic.png\" height=\"70\"></a>\n\nNow in Android App\n==================\n\n**Learn how this app was designed and built in the [design case study](https://goo.gle/nia-figma), [architecture learning journey](docs/ArchitectureLearningJourney.md) and [modularization learning journey](docs/ModularizationLearningJourney.md).**\n\nThis is the repository for the [Now in Android](https://developer.android.com/series/now-in-android)\napp. It is a **work in progress** ğŸš§.\n\n**Now in Android** is a fully functional Android app built entirely with Kotlin and Jetpack Compose. It\nfollows Android design and development best practices and is intended to be a useful reference\nfor developers. As a running app, it's intended to help developers keep up-to-date with the world\nof Android development by providing regular news updates.\n\nThe app is currently in development. The `prodRelease` variant is [available on the Play Store](https://play.google.com/store/apps/details?id=com.google.samples.apps.nowinandroid).\n\n# Features\n\n**Now in Android** displays content from the\n[Now in Android](https://developer.android.com/series/now-in-android) series. Users can browse for\nlinks to recent videos, articles and other content. Users can also follow topics they are interested\nin, and be notified when new content is published which matches interests they are following.\n\n## Screenshots\n\n![Screenshot showing For You screen, Interests screen and Topic detail screen](docs/images/screenshots.png \"Screenshot showing For You screen, Interests screen and Topic detail screen\")\n\n# Development Environment\n\n**Now in Android** uses the Gradle build system and can be imported directly into Android Studio (make sure you are using the latest stable version available [here](https://developer.android.com/studio)). \n\nChange the run configuration to `app`.\n\n![image](https://user-images.githubusercontent.com/873212/210559920-ef4a40c5-c8e0-478b-bb00-4879a8cf184a.png)\n\nThe `demoDebug` and `demoRelease` build variants can be built and run (the `prod` variants use a backend server which is not currently publicly available).\n\n![image](https://user-images.githubusercontent.com/873212/210560507-44045dc5-b6d5-41ca-9746-f0f7acf22f8e.png)\n\nOnce you're up and running, you can refer to the learning journeys below to get a better\nunderstanding of which libraries and tools are being used, the reasoning behind the approaches to\nUI, testing, architecture and more, and how all of these different pieces of the project fit\ntogether to create a complete app.\n\n# Architecture\n\nThe **Now in Android** app follows the\n[official architecture guidance](https://developer.android.com/topic/architecture) \nand is described in detail in the\n[architecture learning journey](docs/ArchitectureLearningJourney.md).\n\n# Modularization\n\nThe **Now in Android** app has been fully modularized and you can find the detailed guidance and\ndescription of the modularization strategy used in\n[modularization learning journey](docs/ModularizationLearningJourney.md).\n\n# Build\n\nThe app contains the usual `debug` and `release` build variants. \n\nIn addition, the `benchmark` variant of `app` is used to test startup performance and generate a\nbaseline profile (see below for more information).\n\n`app-nia-catalog` is a standalone app that displays the list of components that are stylized for\n**Now in Android**.\n\nThe app also uses\n[product flavors](https://developer.android.com/studio/build/build-variants#product-flavors) to\ncontrol where content for the app should be loaded from.\n\nThe `demo` flavor uses static local data to allow immediate building and exploring of the UI.\n\nThe `prod` flavor makes real network calls to a backend server, providing up-to-date content. At \nthis time, there is not a public backend available.\n\nFor normal development use the `demoDebug` variant. For UI performance testing use the\n`demoRelease` variant. \n\n# Testing\n\nTo facilitate testing of components, **Now in Android** uses dependency injection with\n[Hilt](https://developer.android.com/training/dependency-injection/hilt-android).\n\nMost data layer components are defined as interfaces.\nThen, concrete implementations (with various dependencies) are bound to provide those interfaces to\nother components in the app.\nIn tests, **Now in Android** notably does _not_ use any mocking libraries.\nInstead, the production implementations can be replaced with test doubles using Hilt's testing APIs\n(or via manual constructor injection for `ViewModel` tests).\n\nThese test doubles implement the same interface as the production implementations and generally\nprovide a simplified (but still realistic) implementation with additional testing hooks.\nThis results in less brittle tests that may exercise more production code, instead of just verifying\nspecific calls against mocks.\n\nExamples:\n- In instrumentation tests, a temporary folder is used to store the user's preferences, which is\n  wiped after each test.\n  This allows using the real `DataStore` and exercising all related code, instead of mocking the \n  flow of data updates.\n\n- There are `Test` implementations of each repository, which implement the normal, full repository\n  interface and also provide test-only hooks.\n  `ViewModel` tests use these `Test` repositories, and thus can use the test-only hooks to\n  manipulate the state of the `Test` repository and verify the resulting behavior, instead of\n  checking that specific repository methods were called.\n\nTo run the tests execute the following gradle tasks: \n\n- `testDemoDebug` run all local tests against the `demoDebug` variant. Screenshot tests will fail\n(see below for explanation). To avoid this, run `recordRoborazziDemoDebug` prior to running unit tests.\n- `connectedDemoDebugAndroidTest` run all instrumented tests against the `demoDebug` variant. \n\n> [!NOTE]\n> You should not run `./gradlew test` or `./gradlew connectedAndroidTest` as this will execute \ntests against _all_ build variants which is both unnecessary and will result in failures as only the\n`demoDebug` variant is supported. No other variants have any tests (although this might change in future). \n\n## Screenshot tests\nA screenshot test takes a screenshot of a screen or a UI component within the app, and compares it \nwith a previously recorded screenshot which is known to be rendered correctly. \n\nFor example, Now in Android has [screenshot tests](https://github.com/android/nowinandroid/blob/main/app/src/testDemo/kotlin/com/google/samples/apps/nowinandroid/ui/NiaAppScreenSizesScreenshotTests.kt)\nto verify that the navigation is displayed correctly on different screen sizes \n([known correct screenshots](https://github.com/android/nowinandroid/tree/main/app/src/testDemo/screenshots)). \n\nNow In Android uses [Roborazzi](https://github.com/takahirom/roborazzi) to run screenshot tests\nof certain screens and UI components. When working with screenshot tests the following gradle tasks are useful:\n\n- `verifyRoborazziDemoDebug` run all screenshot tests, verifying the screenshots against the known\ncorrect screenshots.\n- `recordRoborazziDemoDebug` record new \"known correct\" screenshots. Use this command when you have\nmade changes to the UI and manually verified that they are rendered correctly. Screenshots will be\nstored in `modulename/src/test/screenshots`.\n- `compareRoborazziDemoDebug` create comparison images between failed tests and the known correct\nimages. These can also be found in `modulename/src/test/screenshots`. \n\n> [!NOTE]\n> **Note on failing screenshot tests**   \n> The known correct screenshots stored in this repository are recorded on CI using Linux. Other\nplatforms may (and probably will) generate slightly different images, making the screenshot tests fail. \nWhen working on a non-Linux platform, a workaround to this is to run `recordRoborazziDemoDebug` on the\n`main` branch before starting work. After making changes, `verifyRoborazziDemoDebug` will identify only\nlegitimate changes. \n\nFor more information about screenshot testing \n[check out this talk](https://www.droidcon.com/2023/11/15/easy-screenshot-testing-with-compose/).\n\n# UI\nThe app was designed using [Material 3 guidelines](https://m3.material.io/). Learn more about the design process and \nobtain the design files in the [Now in Android Material 3 Case Study](https://goo.gle/nia-figma) (design assets [also available as a PDF](docs/Now-In-Android-Design-File.pdf)).\n\nThe Screens and UI elements are built entirely using [Jetpack Compose](https://developer.android.com/jetpack/compose). \n\nThe app has two themes: \n\n- Dynamic color - uses colors based on the [user's current color theme](https://material.io/blog/announcing-material-you) (if supported)\n- Default theme - uses predefined colors when dynamic color is not supported\n\nEach theme also supports dark mode. \n\nThe app uses adaptive layouts to\n[support different screen sizes](https://developer.android.com/guide/topics/large-screens/support-different-screen-sizes).\n\nFind out more about the [UI architecture here](docs/ArchitectureLearningJourney.md#ui-layer).\n\n# Performance\n\n## Benchmarks\n\nFind all tests written using [`Macrobenchmark`](https://developer.android.com/topic/performance/benchmarking/macrobenchmark-overview)\nin the `benchmarks` module. This module also contains the test to generate the Baseline profile.\n\n## Baseline profiles\n\nThe baseline profile for this app is located at [`app/src/main/baseline-prof.txt`](app/src/main/baseline-prof.txt).\nIt contains rules that enable AOT compilation of the critical user path taken during app launch.\nFor more information on baseline profiles, read [this document](https://developer.android.com/studio/profile/baselineprofiles).\n\n> [!NOTE]\n> The baseline profile needs to be re-generated for release builds that touch code which changes app startup.\n\nTo generate the baseline profile, select the `benchmark` build variant and run the\n`BaselineProfileGenerator` benchmark test on an AOSP Android Emulator.\nThen copy the resulting baseline profile from the emulator to [`app/src/main/baseline-prof.txt`](app/src/main/baseline-prof.txt).\n\n## Compose compiler metrics\n\nRun the following command to get and analyze compose compiler metrics:\n\n```bash\n./gradlew assembleRelease -PenableComposeCompilerMetrics=true -PenableComposeCompilerReports=true\n```\n\nThe reports files will be added to [build/compose-reports](build/compose-reports). The metrics files will also be \nadded to [build/compose-metrics](build/compose-metrics).\n\nFor more information on Compose compiler metrics, see [this blog post](https://medium.com/androiddevelopers/jetpack-compose-stability-explained-79c10db270c8).\n\n# License\n\n**Now in Android** is distributed under the terms of the Apache License (Version 2.0). See the\n[license](LICENSE) for more information.\n",
      "stars_today": 4
    },
    {
      "id": 106586124,
      "name": "atomic-red-team",
      "full_name": "redcanaryco/atomic-red-team",
      "description": "Small and highly portable detection tests based on MITRE's ATT&CK.",
      "html_url": "https://github.com/redcanaryco/atomic-red-team",
      "stars": 11560,
      "forks": 3059,
      "language": "C",
      "topics": [
        "mitre",
        "mitre-attack"
      ],
      "created_at": "2017-10-11T17:23:32Z",
      "updated_at": "2026-02-06T21:07:54Z",
      "pushed_at": "2026-01-20T03:25:23Z",
      "open_issues": 6,
      "owner": {
        "login": "redcanaryco",
        "avatar_url": "https://avatars.githubusercontent.com/u/6877001?v=4"
      },
      "readme": "<p><img src=\"https://redcanary.com/wp-content/uploads/Atomic-Red-Team-Logo.png\" width=\"150px\" /></p>\n\n# Atomic Red Team\n\n![GitHub Action Status](https://github.com/redcanaryco/atomic-red-team/actions/workflows/validate-atomics.yml/badge.svg?branch=master) ![Atomics](https://img.shields.io/badge/Atomics-1769-flat.svg) ![GitHub Action Status](https://github.com/redcanaryco/atomic-red-team/actions/workflows/generate-docs.yml/badge.svg?branch=master)\n\n\nAtomic Red Teamâ„¢ is a library of tests mapped to the\n[MITRE ATT&CKÂ®](https://attack.mitre.org/) framework. Security teams can use\nAtomic Red Team to quickly, portably, and reproducibly test their environments.\n\n## Get started\n\nYou can execute atomic tests directly from the command line, no installation\nrequired. See the [Getting started](https://github.com/redcanaryco/atomic-red-team/wiki/Getting-Started)\npage of our wiki.\n\nFor a more robust testing experience, consider using an execution framework like\n[Invoke-Atomic](https://github.com/redcanaryco/invoke-atomicredteam).\n\n## Learn more\n\nThe Atomic Red Team documentation is available as a [wiki](https://github.com/redcanaryco/atomic-red-team/wiki/).\n\nFor information about the philosophy and development of Atomic Red Team, visit\nour website at <https://atomicredteam.io>.\n\nTo stay up to date on all things Atomic Red Team, sign up for the Atomic Newsletter: https://redcanary.com/atomic-newsletter/\n\n## Contribute to Atomic Red Team\n\nAtomic Red Team is open source and community developed. If you're interested in\nbecoming a contributor, check out these resources:\n\n- Join our [Slack workspace](https://slack.atomicredteam.io) and get involved\n  with the community. Don't forget to review the [code of conduct](CODE_OF_CONDUCT.md)\n  before you join.\n- Report bugs and request new features by [submitting an issue](https://github.com/redcanaryco/atomic-red-team/issues/new/choose).\n- Read our [contribution guide](https://github.com/redcanaryco/atomic-red-team/wiki/Contributing)\n  for more information about contributing directly to this repository.\n- Check the [license](LICENSE.txt) for information regarding the distribution\n  and modification of Atomic Red Team.\n- Contribute to linux atomics quickly from GitHub Codespaces. For more details, click [here](https://github.com/redcanaryco/atomic-red-team/wiki/Github-Codespaces)\n\n[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/redcanaryco/atomic-red-team)\n",
      "stars_today": 4
    },
    {
      "id": 79307564,
      "name": "WeChatTweak",
      "full_name": "sunnyyoung/WeChatTweak",
      "description": "A command-line tool for tweaking WeChat - é¦–æ¬¾å¾®ä¿¡ macOS å®¢æˆ·ç«¯æ’¤å›æ‹¦æˆªä¸å¤šå¼€ ğŸ”¨",
      "html_url": "https://github.com/sunnyyoung/WeChatTweak",
      "stars": 13354,
      "forks": 1571,
      "language": "Swift",
      "topics": [
        "alfred",
        "alfred-workflow",
        "macos",
        "no-revoke",
        "norevoke",
        "raycast-extension",
        "revoke",
        "tweak",
        "wechat",
        "wechat-macos",
        "wechat-plugin",
        "wechat-plugin-macos",
        "wechat-raycast",
        "wechat-tweak",
        "wechathook",
        "wechattweak",
        "wechattweak-macos",
        "weixin",
        "weixin-plugin",
        "weixin-tweak"
      ],
      "created_at": "2017-01-18T05:42:16Z",
      "updated_at": "2026-02-06T11:56:40Z",
      "pushed_at": "2025-12-13T17:05:51Z",
      "open_issues": 70,
      "owner": {
        "login": "sunnyyoung",
        "avatar_url": "https://avatars.githubusercontent.com/u/5926284?v=4"
      },
      "readme": "# WeChatTweak\n\n[![README](https://img.shields.io/badge/GitHub-black?logo=github&logoColor=white)](https://github.com/sunnyyoung/WeChatTweak)\n[![README](https://img.shields.io/badge/Telegram-black?logo=telegram&logoColor=white)](https://t.me/wechattweak)\n[![README](https://img.shields.io/badge/FAQ-black?logo=googledocs&logoColor=white)](https://github.com/sunnyyoung/WeChatTweak/wiki/FAQ)\n\nA command-line tool for tweaking WeChat.\n\n## åŠŸèƒ½\n\n- é˜»æ­¢æ¶ˆæ¯æ’¤å›\n- é˜»æ­¢è‡ªåŠ¨æ›´æ–°\n- å®¢æˆ·ç«¯å¤šå¼€\n\n## å®‰è£…&ä½¿ç”¨\n\n```bash\n# å®‰è£…\nbrew install sunnyyoung/tap/wechattweak\n\n# æ›´æ–°\nbrew upgrade wechattweak\n\n# æ‰§è¡Œ Patch\nwechattweak patch\n\n# æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„ WeChat ç‰ˆæœ¬\nwechattweak versions\n```\n\n## å‚è€ƒ\n\n- [å¾®ä¿¡ macOS å®¢æˆ·ç«¯æ— é™å¤šå¼€åŠŸèƒ½å®è·µ](https://blog.sunnyyoung.net/wei-xin-macos-ke-hu-duan-wu-xian-duo-kai-gong-neng-shi-jian/)\n- [å¾®ä¿¡ macOS å®¢æˆ·ç«¯æ‹¦æˆªæ’¤å›åŠŸèƒ½å®è·µ](https://blog.sunnyyoung.net/wei-xin-macos-ke-hu-duan-lan-jie-che-hui-gong-neng-shi-jian/)\n- [è®©å¾®ä¿¡ macOS å®¢æˆ·ç«¯æ”¯æŒ Alfred](https://blog.sunnyyoung.net/rang-wei-xin-macos-ke-hu-duan-zhi-chi-alfred/)\n\n## è´¡çŒ®è€…\n\nThis project exists thanks to all the people who contribute.\n\n[![Contributors](https://contrib.rocks/image?repo=sunnyyoung/WeChatTweak)](https://github.com/sunnyyoung/WeChatTweak/graphs/contributors)\n\n## License\n\nThe [AGPL-3.0](LICENSE).\n",
      "stars_today": 4
    },
    {
      "id": 6687936,
      "name": "mbedtls",
      "full_name": "Mbed-TLS/mbedtls",
      "description": "An open source, portable, easy to use, readable and flexible TLS library, and reference implementation of the PSA Cryptography API. Releases are on a varying cadence, typically around 3 - 6 months between releases.",
      "html_url": "https://github.com/Mbed-TLS/mbedtls",
      "stars": 6456,
      "forks": 2836,
      "language": "C",
      "topics": [
        "crypto",
        "cryptography-library",
        "psa",
        "ssl",
        "tls"
      ],
      "created_at": "2012-11-14T13:13:13Z",
      "updated_at": "2026-02-06T17:04:07Z",
      "pushed_at": "2026-02-03T12:41:04Z",
      "open_issues": 1567,
      "owner": {
        "login": "Mbed-TLS",
        "avatar_url": "https://avatars.githubusercontent.com/u/97226525?v=4"
      },
      "readme": "README for Mbed TLS\n===================\n\nMbed TLS is a C library that implements X.509 certificate manipulation and the TLS and DTLS protocols. Its small code footprint makes it suitable for embedded systems.\nMbed TLS includes the [TF-PSA-Crypto repository](https://github.com/Mbed-TLS/TF-PSA-Crypto) that provides an implementation of the [PSA Cryptography API](https://arm-software.github.io/psa-api).\n\nConfiguration\n-------------\nConfiguration options related to X.509 and TLS are available in `include/mbedtls/mbedtls_config.h`, while cryptography and platform options are located in the TF-PSA-Crypto configuration file `tf-psa-crypto/include/psa/crypto_config.h`.\n\nWith the default platform options, Mbed TLS should build out of the box on most systems.\n\nThese configuration files can be edited manually, or programmatically using the Python script `scripts/config.py` (run with --help for usage instructions).\n\nWe provide some non-standard configurations focused on specific use cases in the `configs/` directory. You can read more about those in `configs/README.txt`.\n\nDocumentation\n-------------\n\nThe main Mbed TLS documentation is available via [ReadTheDocs](https://mbed-tls.readthedocs.io/).\n\nTo generate a local copy of the library documentation in HTML format, tailored to your compile-time configuration:\n\n1. Make sure that [Doxygen](http://www.doxygen.nl/) is installed.\n1. Run `cmake -B /path/to/build_dir /path/to/mbedtls/source`\n1. Run `cmake --build /path/to/build_dir --target mbedtls-apidoc`\n1. Open one of the main generated HTML files:\n   * `apidoc/index.html`\n   * `apidoc/modules.html` or `apidoc/topics.html`\n\nFor other sources of documentation, see the [SUPPORT](SUPPORT.md) document.\n\nCompiling\n---------\n\nWe use CMake to configure and drive our build process. Three libraries are built: `libtfpsacrypto`, `libmbedx509`, and `libmbedtls`. Note that `libmbedtls` depends on `libmbedx509` and `libtfpsacrypto`, and `libmbedx509` depends on `libtfpsacrypto`. As a result, some linkers will expect flags to be in a specific order, for example the GNU linker wants `-lmbedtls -lmbedx509 -ltfpsacrypto`. The cryptographic library `libtfpsacrypto` is also provided under its legacy name, `libmbedcrypto`.\n\n### Tool versions\n\nYou need the following tools to build the library from the main branch with the provided CMake files. Mbed TLS minimum tool version requirements are set based on the versions shipped in the latest or penultimate (depending on the release cadence) long-term support releases of major Linux distributions, namely at time of writing: Ubuntu 22.04, RHEL 9, and SLES 15 SP4.\n\n* CMake 3.20.2 or later.\n* A build system like Make or Ninja for which CMake can generate build files.\n* A C99 toolchain (compiler, linker, archiver). We actively test with GCC 5.4, Clang 3.8, Arm Compiler 6, and Visual Studio 2017 Compiler. More recent versions should work. Slightly older versions may work.\n* Python 3.8 or later to generate the test code. Python is also needed to build the development branch (see next section).\n* Perl to run the tests, and to generate some source files in the development branch.\n* Doxygen 1.8.14 or later (if building the documentation; slightly older versions should work).\n\n### Git usage\n\nThe supported branches (see [`BRANCHES.md`](BRANCHES.md)) use [Git submodules](https://git-scm.com/book/en/v2/Git-Tools-Submodules#_cloning_submodules). They contain two submodules: the [framework](https://github.com/Mbed-TLS/mbedtls-framework) submodule and the [tf-psa-crypto](https://github.com/Mbed-TLS/TF-PSA-Crypto) submodule, except for the 3.6 LTS branch, which contains only the framework submodule. Release tags also use Git submodules.\n\nAfter cloning or checking out a branch or tag, run:\n    ```\n    git submodule update --init --recursive\n    ```\n to initialize and update the submodules before building.\n\nHowever, the official source release tarballs (e.g. [mbedtls-4.0.0.tar.bz2](https://github.com/Mbed-TLS/mbedtls/releases/download/mbedtls-4.0.0/mbedtls-4.0.0.tar.bz2)) include the contents of the submodules.\n\n### Generated source files in the development branch\n\nThe source code of Mbed TLS includes some files that are automatically generated by scripts and whose content depends only on the Mbed TLS source, not on the platform or on the library configuration. These files are not included in the development branch of Mbed TLS, but the generated files are included in official releases. This section explains how to generate the missing files in the development branch.\n\nThe following tools are required:\n\n* Perl, for some library source files.\n* Python 3 and some Python packages, for some library source files, sample programs and test data. To install the necessary packages, run:\n    ```\n    python3 -m pip install --user -r scripts/basic.requirements.txt\n    ```\n    Depending on your Python installation, you may need to invoke `python` instead of `python3`. To install the packages system-wide or in a virtual environment, omit the `--user` option.\n* A C compiler for the host platform, for some test data.\n\nThe scripts that generate the configuration-independent files will look for a host C compiler in the following places (in order of preference):\n\n1. The `HOSTCC` environment variable. This can be used if `CC` is pointing to a cross-compiler.\n2. The `CC` environment variable.\n3. An executable called `cc` in the current path.\n\nNote: If you have multiple toolchains installed, it is recommended to set `CC` or `HOSTCC` to the intended host compiler before generating the files.\n\nAny of the following methods are available to generate the configuration-independent files:\n\n* On non-Windows systems, when not cross-compiling, CMake generates the required files automatically.\n* Run `framework/scripts/make_generated_files.py` to generate all the configuration-independent files.\n\n### CMake\n\nIn order to build the libraries using CMake in a separate directory (recommended), just enter at the command line:\n\n    mkdir /path/to/build_dir && cd /path/to/build_dir\n    cmake /path/to/mbedtls_source\n    cmake --build .\n\nIn order to run the tests, enter:\n\n    ctest\n\nThe test suites need Python to be built. If you don't have Python installed, you'll want to disable the test suites with:\n\n    cmake -DENABLE_TESTING=Off /path/to/mbedtls_source\n\nTo configure CMake for building shared libraries, use:\n\n    cmake -DUSE_SHARED_MBEDTLS_LIBRARY=On /path/to/mbedtls_source\n\nThere are many different build types available with CMake. Most of them are available for gcc and clang, though some are compiler-specific:\n\n-   `Release`. This generates the default code without any unnecessary information in the binary files.\n-   `Debug`. This generates debug information and disables optimization of the code.\n-   `Coverage`. This generates code coverage information in addition to debug information.\n-   `ASan`. This instruments the code with AddressSanitizer to check for memory errors. (This includes LeakSanitizer, with recent version of gcc and clang.) (With recent version of clang, this mode also instruments the code with UndefinedSanitizer to check for undefined behaviour.)\n-   `ASanDbg`. Same as ASan but slower, with debug information and better stack traces.\n-   `MemSan`. This instruments the code with MemorySanitizer to check for uninitialised memory reads.\n-   `MemSanDbg`. Same as MemSan but slower, with debug information, better stack traces and origin tracking.\n-   `Check`. This activates the compiler warnings that depend on optimization and treats all warnings as errors.\n-   `TSan`. This instruments the code with ThreadSanitizer to detect data races and other threading-related concurrency issues at runtime.\n-   `TSanDbg`. Same as TSan but slower, with debug information, better stack traces and origin tracking.\n\nSwitching build types in CMake is simple. For debug mode, enter at the command line:\n\n    cmake -D CMAKE_BUILD_TYPE=Debug /path/to/mbedtls_source\n\nTo list other available CMake options, use:\n\n    cmake -LH\n\nNote that, with CMake, you can't adjust the compiler or its flags after the\ninitial invocation of cmake. This means that `CC=your_cc make` and `make\nCC=your_cc` will *not* work (similarly with `CFLAGS` and other variables).\nThese variables need to be adjusted when invoking cmake for the first time,\nfor example:\n\n    CC=your_cc cmake /path/to/mbedtls_source\n\nIf you already invoked cmake and want to change those settings, you need to\ninvoke the configuration phase of CMake again with the new settings.\n\nNote that it is possible to build in-place; this will however overwrite the\nlegacy Makefiles still used for testing purposes (see\n`scripts/tmp_ignore_makefiles.sh` if you want to prevent `git status` from\nshowing them as modified). In order to do so, from the Mbed TLS source\ndirectory, use:\n\n    cmake .\n    cmake --build .\n\nIf you want to change `CC` or `CFLAGS` afterwards, you will need to remove the\nCMake cache. This can be done with the following command using GNU find:\n\n    find . -iname '*cmake*' -not -name CMakeLists.txt -exec rm -rf {} +\n\nYou can now make the desired change:\n\n    CC=your_cc cmake .\n    cmake --build .\n\nRegarding variables, also note that if you set CFLAGS when invoking cmake,\nyour value of CFLAGS doesn't override the content provided by CMake (depending\non the build mode as seen above), it's merely prepended to it.\n\n#### Consuming Mbed TLS\n\nMbed TLS provides a CMake package configuration file for consumption as a\ndependency in other CMake projects. You can load its CMake targets with:\n\n    find_package(MbedTLS REQUIRED)\n\nYou can help CMake find the package:\n\n- By setting the variable `MbedTLS_DIR` to `${YOUR_MBEDTLS_BUILD_DIR}/cmake`,\n  as shown in `programs/test/cmake_package/CMakeLists.txt`, or\n- By adding the Mbed TLS installation prefix to `CMAKE_PREFIX_PATH`,\n  as shown in `programs/test/cmake_package_install/CMakeLists.txt`.\n\nAfter a successful `find_package(MbedTLS)`, the following imported targets are available:\n\n- `MbedTLS::tfpsacrypto`, the crypto library\n- `MbedTLS::mbedtls`, the TLS library\n- `MbedTLS::mbedx509`, the X.509 library\n\nYou can then use these directly through `target_link_libraries()`:\n\n    add_executable(xyz)\n\n    target_link_libraries(xyz\n        PUBLIC MbedTLS::mbedtls\n               MbedTLS::tfpsacrypto\n               MbedTLS::mbedx509)\n\nThis will link the Mbed TLS libraries to your library or application, and add\nits include directories to your target (transitively, in the case of `PUBLIC` or\n`INTERFACE` link libraries).\n\n#### Mbed TLS as a subproject\n\nMbed TLS supports being built as a CMake subproject. One can\nuse `add_subdirectory()` from a parent CMake project to include Mbed TLS as a\nsubproject.\n\nExample programs\n----------------\n\nWe've included example programs for a lot of different features and uses in [`programs/`](programs/README.md).\nPlease note that the goal of these sample programs is to demonstrate specific features of the library, and the code may need to be adapted to build a real-world application.\n\nTests\n-----\n\nMbed TLS includes an elaborate test suite in `tests/` that initially requires Python to generate the tests files (e.g. `test_suite_ssl.c`). These files are generated from a `function file` (e.g. `suites/test_suite_ssl.function`) and a `data file` (e.g. `suites/test_suite_ssl.data`). The `function file` contains the test functions. The `data file` contains the test cases, specified as parameters that will be passed to the test function.\n\nFor machines with a Unix shell and OpenSSL (and optionally GnuTLS) installed, additional test scripts are available:\n\n-   `tests/ssl-opt.sh` runs integration tests for various TLS options (renegotiation, resumption, etc.) and tests interoperability of these options with other implementations.\n-   `tests/compat.sh` tests interoperability of every ciphersuite with other implementations.\n-   `tests/scripts/depends.py` tests builds in configurations with a single curve, key exchange, hash, cipher, or pkalg on.\n-   `tests/scripts/all.sh` runs a combination of the above tests, plus some more, with various build options (such as ASan, full `mbedtls_config.h`, etc).\n\nInstead of manually installing the required versions of all tools required for testing, it is possible to use the Docker images from our CI systems, as explained in [our testing infrastructure repository](https://github.com/Mbed-TLS/mbedtls-test/blob/main/README.md#quick-start).\n\nPorting Mbed TLS\n----------------\n\nMbed TLS can be ported to many different architectures, OS's and platforms. Before starting a port, you may find the following Knowledge Base articles useful:\n\n-   [Porting Mbed TLS to a new environment or OS](https://mbed-tls.readthedocs.io/en/latest/kb/how-to/how-do-i-port-mbed-tls-to-a-new-environment-OS/)\n-   [What external dependencies does Mbed TLS rely on?](https://mbed-tls.readthedocs.io/en/latest/kb/development/what-external-dependencies-does-mbedtls-rely-on/)\n-   [How do I configure Mbed TLS](https://mbed-tls.readthedocs.io/en/latest/kb/compiling-and-building/how-do-i-configure-mbedtls/)\n\nMbed TLS is mostly written in portable C99; however, it has a few platform requirements that go beyond the standard, but are met by most modern architectures:\n\n- Bytes must be 8 bits.\n- All-bits-zero must be a valid representation of a null pointer.\n- Signed integers must be represented using two's complement.\n- `int` and `size_t` must be at least 32 bits wide.\n- The types `uint8_t`, `uint16_t`, `uint32_t` and their signed equivalents must be available.\n- Mixed-endian platforms are not supported.\n- SIZE_MAX must be at least as big as INT_MAX and UINT_MAX.\n\nLicense\n-------\n\nUnless specifically indicated otherwise in a file, Mbed TLS files are provided under a dual [Apache-2.0](https://spdx.org/licenses/Apache-2.0.html) OR [GPL-2.0-or-later](https://spdx.org/licenses/GPL-2.0-or-later.html) license. See the [LICENSE](LICENSE) file for the full text of these licenses, and [the 'License and Copyright' section in the contributing guidelines](CONTRIBUTING.md#License-and-Copyright) for more information.\n\nContributing\n------------\n\nWe gratefully accept bug reports and contributions from the community. Please see the [contributing guidelines](CONTRIBUTING.md) for details on how to do this.\n\nContact\n-------\n\n* To report a security vulnerability in Mbed TLS, please email <mbed-tls-security@lists.trustedfirmware.org>. For more information, see [`SECURITY.md`](SECURITY.md).\n* To report a bug or request a feature in Mbed TLS, please [file an issue on GitHub](https://github.com/Mbed-TLS/mbedtls/issues/new/choose).\n* Please see [`SUPPORT.md`](SUPPORT.md) for other channels for discussion and support about Mbed TLS.\n",
      "stars_today": 4
    },
    {
      "id": 940018401,
      "name": "3FS",
      "full_name": "deepseek-ai/3FS",
      "description": " A high-performance distributed file system designed to address the challenges of AI training and inference workloads. ",
      "html_url": "https://github.com/deepseek-ai/3FS",
      "stars": 9704,
      "forks": 1004,
      "language": "C++",
      "topics": [
        "distributed-file-system"
      ],
      "created_at": "2025-02-27T13:36:53Z",
      "updated_at": "2026-02-06T21:15:50Z",
      "pushed_at": "2026-02-04T07:54:23Z",
      "open_issues": 145,
      "owner": {
        "login": "deepseek-ai",
        "avatar_url": "https://avatars.githubusercontent.com/u/148330874?v=4"
      },
      "readme": "#  Fire-Flyer File System\n\n[![Build](https://github.com/deepseek-ai/3fs/actions/workflows/build.yml/badge.svg)](https://github.com/deepseek-ai/3fs/actions/workflows/build.yml)\n[![License](https://img.shields.io/badge/LICENSE-MIT-blue.svg)](LICENSE)\n\nThe Fire-Flyer File System (3FS) is a high-performance distributed file system designed to address the challenges of AI training and inference workloads. It leverages modern SSDs and RDMA networks to provide a shared storage layer that simplifies development of distributed applications. Key features and benefits of 3FS include:\n\n- Performance and Usability\n  - **Disaggregated Architecture** Combines the throughput of thousands of SSDs and the network bandwidth of hundreds of storage nodes, enabling applications to access storage resource in a locality-oblivious manner.\n  - **Strong Consistency** Implements Chain Replication with Apportioned Queries (CRAQ) for strong consistency, making application code simple and easy to reason about.\n  - **File Interfaces** Develops stateless metadata services backed by a transactional key-value store (e.g., FoundationDB). The file interface is well known and used everywhere. There is no need to learn a new storage API.\n\n- Diverse Workloads\n  - **Data Preparation** Organizes outputs of data analytics pipelines into hierarchical directory structures and manages a large volume of intermediate outputs efficiently.\n  - **Dataloaders** Eliminates the need for prefetching or shuffling datasets by enabling random access to training samples across compute nodes.\n  - **Checkpointing** Supports high-throughput parallel checkpointing for large-scale training.\n  - **KVCache for Inference** Provides a cost-effective alternative to DRAM-based caching, offering high throughput and significantly larger capacity.\n\n## Documentation\n\n* [Design Notes](docs/design_notes.md)\n* [Setup Guide](deploy/README.md)\n* [USRBIO API Reference](src/lib/api/UsrbIo.md)\n* [P Specifications](./specs/README.md)\n\n## Performance\n\n### 1. Peak throughput\n\nThe following figure demonstrates the throughput of read stress test on a large 3FS cluster. This cluster consists of 180 storage nodes, each equipped with 2Ã—200Gbps InfiniBand NICs and sixteen 14TiB NVMe SSDs. Approximately 500+ client nodes were used for the read stress test, with each client node configured with 1x200Gbps InfiniBand NIC. The final aggregate read throughput reached approximately 6.6 TiB/s with background traffic from training jobs.\n\n![Large block read throughput under stress test on a 180-node cluster](docs/images/peak_throughput.jpg)\n\nTo benchmark 3FS, please use our [fio engine for USRBIO](benchmarks/fio_usrbio/README.md).\n\n### 2. GraySort\n\nWe evaluated [smallpond](https://github.com/deepseek-ai/smallpond) using the GraySort benchmark, which measures sort performance on large-scale datasets. Our implementation adopts a two-phase approach: (1) partitioning data via shuffle using the prefix bits of keys, and (2) in-partition sorting. Both phases read/write data from/to 3FS.\n\nThe test cluster comprised 25 storage nodes (2 NUMA domains/node, 1 storage service/NUMA, 2Ã—400Gbps NICs/node) and 50 compute nodes (2 NUMA domains, 192 physical cores, 2.2 TiB RAM, and 1Ã—200 Gbps NIC/node). Sorting 110.5 TiB of data across 8,192 partitions completed in 30 minutes and 14 seconds, achieving an average throughput of *3.66 TiB/min*.\n\n![](docs/images/gray_sort_server.png)\n![](docs/images/gray_sort_client.png)\n\n### 3. KVCache\n\nKVCache is a technique used to optimize the LLM inference process. It avoids redundant computations by caching the key and value vectors of previous tokens in the decoder layers.\nThe top figure demonstrates the read throughput of all KVCache clients (1Ã—400Gbps NIC/node), highlighting both peak and average values, with peak throughput reaching up to 40 GiB/s. The bottom figure presents the IOPS of removing ops from garbage collection (GC) during the same time period.\n\n![KVCache Read Throughput](./docs/images/kvcache_read_throughput.png)\n![KVCache GC IOPS](./docs/images/kvcache_gc_iops.png)\n\n## Check out source code\n\nClone 3FS repository from GitHub:\n\n\tgit clone https://github.com/deepseek-ai/3fs\n\nWhen `deepseek-ai/3fs` has been cloned to a local file system, run the\nfollowing commands to check out the submodules:\n\n```bash\ncd 3fs\ngit submodule update --init --recursive\n./patches/apply.sh\n```\n\n## Install dependencies\n\nInstall dependencies:\n\n```bash\n# for Ubuntu 20.04.\napt install cmake libuv1-dev liblz4-dev liblzma-dev libdouble-conversion-dev libdwarf-dev libunwind-dev \\\n  libaio-dev libgflags-dev libgoogle-glog-dev libgtest-dev libgmock-dev clang-format-14 clang-14 clang-tidy-14 lld-14 \\\n  libgoogle-perftools-dev google-perftools libssl-dev libclang-rt-14-dev gcc-10 g++-10 libboost1.71-all-dev build-essential\n\n# for Ubuntu 22.04.\napt install cmake libuv1-dev liblz4-dev liblzma-dev libdouble-conversion-dev libdwarf-dev libunwind-dev \\\n  libaio-dev libgflags-dev libgoogle-glog-dev libgtest-dev libgmock-dev clang-format-14 clang-14 clang-tidy-14 lld-14 \\\n  libgoogle-perftools-dev google-perftools libssl-dev gcc-12 g++-12 libboost-all-dev build-essential\n\n# for openEuler 2403sp1\nyum install cmake libuv-devel lz4-devel xz-devel double-conversion-devel libdwarf-devel libunwind-devel \\\n    libaio-devel gflags-devel glog-devel gtest-devel gmock-devel clang-tools-extra clang lld \\\n    gperftools-devel gperftools openssl-devel gcc gcc-c++ boost-devel\n\n# for OpenCloudOS 9 and TencentOS 4\ndnf install epol-release wget git meson cmake perl lld gcc gcc-c++ autoconf lz4 lz4-devel xz xz-devel \\\n    double-conversion-devel libdwarf-devel libunwind-devel libaio-devel gflags-devel glog-devel \\\n    libuv-devel gmock-devel gperftools gperftools-devel openssl-devel boost-static boost-devel mono-devel \\\n    libevent-devel libibverbs-devel numactl-devel python3-devel\n```\n\nInstall other build prerequisites:\n\n- [`libfuse`](https://github.com/libfuse/libfuse/releases/tag/fuse-3.16.1) 3.16.1 or newer version\n- [FoundationDB](https://apple.github.io/foundationdb/getting-started-linux.html) 7.1 or newer version\n- [Rust](https://www.rust-lang.org/tools/install) toolchain: minimal 1.75.0, recommended 1.85.0 or newer version (latest stable version) \n\n## Build 3FS\n\nBuild 3FS in `build` folder:\n\n```bash\n# Replace <method> with 'g++10' or 'g++11' based on your environment\ncmake -S . -B build \\\n      -DCMAKE_CXX_COMPILER=clang++-14 -DCMAKE_C_COMPILER=clang-14 \\\n      -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_EXPORT_COMPILE_COMMANDS=ON \\\n      -DSHUFFLE_METHOD=<method>\ncmake --build build -j 32\n```\n\nDue to the historical use of `std::shuffle`, binaries compiled with different compiler versions (e.g., `g++10` vs. `g++11 +`) may be incompatible ([issue](https://github.com/deepseek-ai/3FS/issues/368)). To resolve this, you must explicitly specify `-DSHUFFLE_METHOD` during compilation to lock in a consistent shuffle algorithm:\n\n- Existing Clusters: Use the method corresponding to the compiler version previously used to deploy the cluster (`g++10` or `g++11`).\n- New Clusters: You can choose either `g++10` or `g++11`. However, once the cluster is deployed, you must stay with the same configuration for all future builds to maintain compatibility.\n\n### Build 3FS use Docker\n- For TencentOS-4:  `docker pull docker.io/tencentos/tencentos4-deepseek3fs-build:latest`\n- For OpenCloudOS-9:  `docker pull docker.io/opencloudos/opencloudos9-deepseek3fs-build:latest`\n  \n## Run a test cluster\n\nFollow instructions in [setup guide](deploy/README.md) to run a test cluster.\n\n## Report Issues\n\nPlease visit https://github.com/deepseek-ai/3fs/issues to report issues.\n",
      "stars_today": 4
    },
    {
      "id": 63882194,
      "name": "calico",
      "full_name": "projectcalico/calico",
      "description": "Cloud native networking and network security",
      "html_url": "https://github.com/projectcalico/calico",
      "stars": 7049,
      "forks": 1536,
      "language": "Go",
      "topics": [
        "cats",
        "cni",
        "cni-plugin",
        "ebpf",
        "host-protection",
        "identity-aware-policy",
        "k8s",
        "kubernetes",
        "kubernetes-networking",
        "kubernetes-windows",
        "network-policy",
        "networking",
        "observability",
        "openstack",
        "security",
        "windows",
        "xdp"
      ],
      "created_at": "2016-07-21T15:45:54Z",
      "updated_at": "2026-02-06T21:29:42Z",
      "pushed_at": "2026-02-07T02:14:52Z",
      "open_issues": 207,
      "owner": {
        "login": "projectcalico",
        "avatar_url": "https://avatars.githubusercontent.com/u/12304728?v=4"
      },
      "readme": "[![Go Report Card](https://goreportcard.com/badge/github.com/projectcalico/calico)](https://goreportcard.com/report/github.com/projectcalico/calico)\n[![ArtifactHub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/tigera-operator)](https://artifacthub.io/packages/helm/projectcalico/tigera-operator)\n[![License](https://img.shields.io/badge/license-Apache-blue.svg)](calico/LICENSE)\n[![GoPkg](https://pkg.go.dev/badge/k8s.io/kubernetes.svg)](https://pkg.go.dev/github.com/projectcalico/api)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/6064/badge)](https://bestpractices.coreinfrastructure.org/projects/6064)\n\n<div align=center>\n<h1>Calico</h1>\n<h2>\n<a href=\"https://projectcalico.docs.tigera.io/getting-started/kubernetes/quickstart\">Quickstart</a> |\n<a href=\"https://projectcalico.docs.tigera.io\">Docs</a> |\n<a href=\"CONTRIBUTING.md\">Contribute</a> |\n<a href=\"https://slack.projectcalico.org\">Slack</a> |\n<a href=\"https://github.com/projectcalico/calico/releases\">Releases</a>\n</h2>\n</div>\n\n## ğŸ¾ Welcome to Project Calico!\n\nProject Calico, created and maintained by [Tigera][tigera], is an open-source project with an active development and user community. Calico Open Source has grown to be the most widely adopted solution for container networking and security, powering 8M+ nodes daily across 166 countries.\n\n## ğŸŒŸ Why use Calico?\n\n- **Data Plane Choice**: eBPF, standard Linux, Windows, and VPP â€” versatility in network solutions.\n- **Interoperability**: Works across multiple distros, multiple clouds, bare metal, and VMs.\n- **Optimized Performance**: Engineered for high speed and low CPU usage, maximizing your cluster investments.\n- **Scalable Architecture**: Grows seamlessly with your Kubernetes clusters without sacrificing performance.\n- **Advanced Security**: Get granular access controls and WireGuard encryption.\n- **Kubernetes Networking Policy Support**: Continually defining excellence in Kubernetes network policy standards and support.\n- **Vibrant Contributor Community**: Over 200 contributors from a wide array of global companies.\n- **Flexible networking**: An array of networking tools at your disposal, including BGP, VXLAN, service advertisement, and more.\n\n<div align=center>\n<img src=\"https://www.tigera.io/app/uploads/2026/01/Ecosystem_2026.svg\">\n</div>\n\n## ğŸ¤ Join the Calico Community\n\n- [Calico Big Cats][big-cats]: Become an ambassador and share your journey\n- [Community Meetings][community-meetings]: Engage and contribute\n- [Contribute on GitHub][first-issues]: Start with 'good first issues'\n- [Connect on Slack][slack]: Join the conversation with fellow contributors and our developers\n\n## ğŸ’¡ Contributing to Project Calico\n\n- [Get Started with Project Calico][get-started]\n- [Repositories][repos]\n- [Contribute to our docs][docs-contrib]\n- Documentation: [Dive into our training and resources][resources]\n- [Make Calico better][issues]\n\n## ğŸ› ï¸ Projects We Maintain\n\n- [Calico Golang API][api]\n- [Calico operator][operator]\n- [VPP dataplane][vpp]\n- [Calico BIRD][bird]\n\n## ğŸ“¢ Stay Connected\n\n- Subscribe: [Join our newsletter][news]\n- [YouTube channel for updates & tutorials][youtube]\n- [Technical Blog][blog]\n- [Careers][join]: Passionate about open source? Join our team.\n\n[tigera]: https://www.tigera.io/\n[big-cats]: https://www.tigera.io/project-calico/calico-big-cats-ambassador-program/#meet-calico-big-cats\n[community-meetings]: https://calendar.google.com/calendar/u/0/embed?src=tigera.io_uunmavdev5ndovf0hc4frtl0i0@group.calendar.google.com\n[first-issues]: https://github.com/projectcalico/calico/labels/good%20first%20issue\n[slack]: https://slack.projectcalico.org/\n[get-started]: https://docs.tigera.io/calico/latest/about\n[repos]: https://github.com/orgs/projectcalico/repositories\n[docs-contrib]: https://github.com/projectcalico/calico/blob/master/CONTRIBUTING_DOCS.md\n[resources]: https://docs.tigera.io/calico/latest/about/training-resources\n[issues]: https://github.com/projectcalico/calico/issues\n[api]: https://github.com/projectcalico/api\n[operator]: https://github.com/tigera/operator\n[vpp]: https://github.com/projectcalico/vpp-dataplane\n[news]: https://www.tigera.io/project-calico/#:~:text=Join%20Calico%20Open%20Source%20community%20newsletter\n[youtube]: https://www.youtube.com/channel/UCFpTnXDNcBoXI4gqCDmegFA\n[blog]: https://www.tigera.io/blog/?_sft_category=technical-blog\n[join]: https://www.tigera.io/careers/\n[bird]: https://github.com/projectcalico/bird\n",
      "stars_today": 4
    },
    {
      "id": 6860771,
      "name": "tinyusb",
      "full_name": "hathach/tinyusb",
      "description": "An open source  cross-platform USB stack for embedded system",
      "html_url": "https://github.com/hathach/tinyusb",
      "stars": 6494,
      "forks": 1353,
      "language": "C",
      "topics": [
        "embedded",
        "midi",
        "msc",
        "tinyusb",
        "usb",
        "usb-cdc",
        "usb-devices",
        "usb-drive",
        "usb-hid",
        "usb-host",
        "webusb"
      ],
      "created_at": "2012-11-26T06:24:00Z",
      "updated_at": "2026-02-06T17:20:58Z",
      "pushed_at": "2026-02-06T16:56:41Z",
      "open_issues": 231,
      "owner": {
        "login": "hathach",
        "avatar_url": "https://avatars.githubusercontent.com/u/249515?v=4"
      },
      "readme": "TinyUSB\n=======\n\n|Build Status| |CircleCI Status| |Documentation Status| |Static Analysis| |Fuzzing Status| |Membrowse| |License|\n\nSponsors\n--------\n\nTinyUSB is funded by: Adafruit. Purchasing products from them helps to support this project.\n\n.. figure:: docs/assets/adafruit_logo.svg\n   :alt: Adafruit Logo\n   :align: left\n   :target: https://www.adafruit.com\n\n.. raw:: html\n\n   <div class=\"clear-both\"></div>\n\nOverview\n--------\n\n.. figure:: docs/assets/logo.svg\n   :alt: TinyUSB\n   :align: left\n\n.. raw:: html\n\n   <div class=\"clear-both\"></div>\n\nTinyUSB is an open-source cross-platform USB Host/Device stack for embedded systems. Itâ€™s designed for memory safety\n(no dynamic allocation) and thread safety (all interrupts deferred to non-ISR task functions). The stack emphasizes portability,\nsmall footprint, and real-time performance across 50+ MCU families.\n\nKey Features\n------------\n\n* **Thread-safe:** USB interrupts deferred to task context\n* **Memory-safe:** No dynamic allocation, all buffers static\n* **Portable:** Supports 50+ MCU families\n* **Comprehensive:** Includes CDC, HID, MSC, Audio, and Host support\n* **RTOS-friendly:** Works with bare metal, FreeRTOS, RT-Thread, and Mynewt\n\n.. figure:: docs/assets/stack.svg\n   :width: 500px\n   :align: left\n   :alt: stackup\n\n.. raw:: html\n\n   <div class=\"clear-both\"></div>\n\n::\n\n    .\n    â”œâ”€â”€ docs            # Documentation\n    â”œâ”€â”€ examples        # Examples with make and cmake build system\n    â”œâ”€â”€ hw\n    â”‚   â”œâ”€â”€ bsp         # Supported boards source files\n    â”‚   â””â”€â”€ mcu         # Low level mcu core & peripheral drivers\n    â”œâ”€â”€ lib             # Sources from 3rd party such as FreeRTOS, FatFs ...\n    â”œâ”€â”€ src             # All sources files for TinyUSB stack itself.\n    â”œâ”€â”€ test            # Tests: unit test, fuzzing, hardware test\n    â””â”€â”€ tools           # Files used internally\n\n\nGetting started\n---------------\n\nSee the `online documentation <https://docs.tinyusb.org>`_ for information about using TinyUSB and how it is implemented.\n\nCheck out `Getting Started`_ guide for adding TinyUSB to your project or building the examples. If you are new to TinyUSB, we recommend starting with the ``cdc_msc`` example. There is a handful of `Supported Boards`_ that should work out of the box.\n\nWe use `GitHub Discussions <https://github.com/hathach/tinyusb/discussions>`_ as our forum. It is a great place to ask questions and advice from the community or to discuss your TinyUSB-based projects.\n\nFor bugs and feature requests, please `raise an issue <https://github.com/hathach/tinyusb/issues>`_ and follow the templates there.\n\nSee `Porting`_ guide for adding support for new MCUs and boards.\n\nDevice Stack\n------------\n\nSupports multiple device configurations by dynamically changing USB descriptors, low power functions such like suspend, resume, and remote wakeup. The following device classes are supported:\n\n-  Audio Class 2.0 (UAC2)\n-  Bluetooth Host Controller Interface (BTH HCI)\n-  Communication Device Class (CDC)\n-  Device Firmware Update (DFU): DFU mode (WIP) and Runtime\n-  Human Interface Device (HID): Generic (In & Out), Keyboard, Mouse, Gamepad etc ...\n-  Mass Storage Class (MSC): with multiple LUNs\n-  Musical Instrument Digital Interface (MIDI)\n-  Media Transfer Protocol (MTP/PTP)\n-  Network with RNDIS, Ethernet Control Model (ECM), Network Control Model (NCM)\n-  Test and Measurement Class (USBTMC)\n-  Video class 1.5 (UVC): work in progress\n-  Vendor-specific class support with generic In & Out endpoints. Can be used with MS OS 2.0 compatible descriptor to load winUSB driver without INF file.\n-  `WebUSB <https://github.com/WICG/webusb>`__ with vendor-specific class\n\nIf you have a special requirement, ``usbd_app_driver_get_cb()`` can be used to write your own class driver without modifying the stack. Here is how the RPi team added their reset interface `raspberrypi/pico-sdk#197 <https://github.com/raspberrypi/pico-sdk/pull/197>`_\n\nHost Stack\n----------\n\n- Human Interface Device (HID): Keyboard, Mouse, Generic\n- Mass Storage Class (MSC)\n- Communication Device Class: CDC-ACM\n- Vendor serial over USB: FTDI, CP210x, CH34x, PL2303\n- Hub with multiple-level support\n\nSimilar to the Device Stack, if you have a special requirement, ``usbh_app_driver_get_cb()`` can be used to write your own class driver without modifying the stack.\n\nPower Delivery Stack\n--------------------\n\n- Power Delivery 3.0 (PD3.0) with USB Type-C support (WIP)\n- Super early stage, only for testing purpose\n- Only support STM32 G4\n\nOS Abstraction layer\n--------------------\n\nTinyUSB is completely thread-safe by pushing all Interrupt Service Request (ISR) events into a central queue, then processing them later in the non-ISR context task function. It also uses semaphore/mutex to access shared resources such as Communication Device Class (CDC) FIFO. Therefore the stack needs to use some of the OS's basic APIs. Following OSes are already supported out of the box.\n\n- **No OS**\n- **FreeRTOS**\n- `RT-Thread <https://github.com/RT-Thread/rt-thread>`_: `repo <https://github.com/RT-Thread-packages/tinyusb>`_\n- **Mynewt** Due to the newt package build system, Mynewt examples are better to be on its `own repo <https://github.com/hathach/mynewt-tinyusb-example>`_\n\nSupported CPUs\n--------------\n\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| Manufacturer | Family                      | Device | Host | Highspeed | Driver                 | Note               |\n+==============+=============================+========+======+===========+========================+====================+\n| Allwinner    | F1C100s/F1C200s             | âœ”      |      | âœ”         | sunxi                  | musb variant       |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| Analog       | MAX3421E                    |        | âœ”    | âœ–         | max3421                | via SPI            |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | MAX32 650, 666, 690,        | âœ”      |      | âœ”         | musb                   | 1-dir ep           |\n|              | MAX78002                    |        |      |           |                        |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| Artery AT32  | F403a_407, F413             | âœ”      |      |           | fsdev                  | 512 USB RAM        |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | F415, F435_437, F423,       | âœ”      | âœ”    |           | dwc2                   |                    |\n|              | F425, F45x                  |        |      |           |                        |                    |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | F402_F405                   | âœ”      | âœ”    | âœ”         | dwc2                   | F405 is HS         |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| Bridgetek    | FT90x                       | âœ”      |      | âœ”         | ft9xx                  | 1-dir ep           |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| Broadcom     | BCM2711, BCM2837            | âœ”      |      | âœ”         | dwc2                   |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| Dialog       | DA1469x                     | âœ”      | âœ–    | âœ–         | da146xx                |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| Espressif    | S2, S3                      | âœ”      | âœ”    | âœ–         | dwc2                   |                    |\n| ESP32        +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | P4                          | âœ”      | âœ”    | âœ”         | dwc2                   |                    |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | H4                          | âœ”      | âœ”    | âœ–         | dwc2                   |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| GigaDevice   | GD32VF103                   | âœ”      |      | âœ–         | dwc2                   |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| HPMicro      | HPM6750                     | âœ”      | âœ”    | âœ”         | ci_hs, ehci            |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| Infineon     | XMC4500                     | âœ”      | âœ”    | âœ–         | dwc2                   |                    |\n+--------------+-----+-----------------------+--------+------+-----------+------------------------+--------------------+\n| MicroChip    | SAM | D11, D21, L21, L22    | âœ”      |      | âœ–         | samd                   |                    |\n|              |     +-----------------------+--------+------+-----------+------------------------+--------------------+\n|              |     | D51, E5x              | âœ”      |      | âœ–         | samd                   |                    |\n|              |     +-----------------------+--------+------+-----------+------------------------+--------------------+\n|              |     | G55                   | âœ”      |      | âœ–         | samg                   | 1-dir ep           |\n|              |     +-----------------------+--------+------+-----------+------------------------+--------------------+\n|              |     | E70,S70,V70,V71       | âœ”      |      | âœ”         | samx7x                 | 1-dir ep           |\n|              +-----+-----------------------+--------+------+-----------+------------------------+--------------------+\n|              | PIC | 24                    | âœ”      |      |           | pic                    | ci_fs variant      |\n|              |     +-----------------------+--------+------+-----------+------------------------+--------------------+\n|              |     | 32 mm, mk, mx         | âœ”      |      |           | pic                    | ci_fs variant      |\n|              |     +-----------------------+--------+------+-----------+------------------------+--------------------+\n|              |     | dsPIC33               | âœ”      |      |           | pic                    | ci_fs variant      |\n|              |     +-----------------------+--------+------+-----------+------------------------+--------------------+\n|              |     | 32mz                  | âœ”      |      |           | pic32mz                | musb variant       |\n+--------------+-----+-----------------------+--------+------+-----------+------------------------+--------------------+\n| MindMotion   | mm32                        | âœ”      |      | âœ–         | mm32f327x_otg          | ci_fs variant      |\n+--------------+-----+-----------------------+--------+------+-----------+------------------------+--------------------+\n| NordicSemi   | nRF 52833, 52840, 5340      | âœ”      | âœ–    | âœ–         | nrf5x                  | only ep8 is ISO    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| Nuvoton      | NUC120                      | âœ”      | âœ–    | âœ–         | nuc120                 |                    |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | NUC121/NUC125, NUC126       | âœ”      | âœ–    | âœ–         | nuc121                 |                    |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | NUC505                      | âœ”      |      | âœ”         | nuc505                 |                    |\n+--------------+---------+-------------------+--------+------+-----------+------------------------+--------------------+\n| NXP          | iMXRT   | RT 10xx, 11xx     | âœ”      | âœ”    | âœ”         | ci_hs, ehci            |                    |\n|              +---------+-------------------+--------+------+-----------+------------------------+--------------------+\n|              | Kinetis | KL                | âœ”      | âš     | âœ–         | ci_fs, khci            |                    |\n|              |         +-------------------+--------+------+-----------+------------------------+--------------------+\n|              |         | K32L2             | âœ”      |      | âœ–         | khci                   | ci_fs variant      |\n|              +---------+-------------------+--------+------+-----------+------------------------+--------------------+\n|              | LPC     | 11u, 13, 15       | âœ”      | âœ–    | âœ–         | lpc_ip3511             |                    |\n|              |         +-------------------+--------+------+-----------+------------------------+--------------------+\n|              |         | 17, 40            | âœ”      | âš     | âœ–         | lpc17_40, ohci         |                    |\n|              |         +-------------------+--------+------+-----------+------------------------+--------------------+\n|              |         | 18, 43            | âœ”      | âœ”    | âœ”         | ci_hs, ehci            |                    |\n|              |         +-------------------+--------+------+-----------+------------------------+--------------------+\n|              |         | 51u               | âœ”      | âœ–    | âœ–         | lpc_ip3511             |                    |\n|              |         +-------------------+--------+------+-----------+------------------------+--------------------+\n|              |         | 54, 55            | âœ”      |      | âœ”         | lpc_ip3511             |                    |\n|              +---------+-------------------+--------+------+-----------+------------------------+--------------------+\n|              | MCX     | N9                | âœ”      |      | âœ”         | ci_fs, ci_hs, ehci     |                    |\n|              |         +-------------------+--------+------+-----------+------------------------+--------------------+\n|              |         | A15               | âœ”      |      |           | ci_fs                  |                    |\n|              +---------+-------------------+--------+------+-----------+------------------------+--------------------+\n|              | RW61x                       | âœ”      | âœ”    | âœ”         | ci_hs, ehci            |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| Raspberry Pi | RP2040, RP2350              | âœ”      | âœ”    | âœ–         | rp2040, pio_usb        |                    |\n+--------------+-----+-----------------------+--------+------+-----------+------------------------+--------------------+\n| Renesas      | RX  | 63N, 65N, 72N         | âœ”      | âœ”    | âœ–         | rusb2                  |                    |\n|              +-----+-----------------------+--------+------+-----------+------------------------+--------------------+\n|              | RA  | 4M1, 4M3, 6M1         | âœ”      | âœ”    | âœ–         | rusb2                  |                    |\n|              |     +-----------------------+--------+------+-----------+------------------------+--------------------+\n|              |     | 6M5                   | âœ”      | âœ”    | âœ”         | rusb2                  |                    |\n+--------------+-----+-----------------------+--------+------+-----------+------------------------+--------------------+\n| Silabs       | EFM32GG12                   | âœ”      |      | âœ–         | dwc2                   |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| Sony         | CXD56                       | âœ”      | âœ–    | âœ”         | cxd56                  |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| ST STM32     | F0, F3, L0, L1, L5, WBx5    | âœ”      | âœ–    | âœ–         | stm32_fsdev            |                    |\n|              +----+------------------------+--------+------+-----------+------------------------+--------------------+\n|              | F1 | 102, 103               | âœ”      | âœ–    | âœ–         | stm32_fsdev            | 512 USB RAM        |\n|              |    +------------------------+--------+------+-----------+------------------------+--------------------+\n|              |    | 105, 107               | âœ”      | âœ”    | âœ–         | dwc2                   |                    |\n|              +----+------------------------+--------+------+-----------+------------------------+--------------------+\n|              | F2, F4, F7, H7, H7RS        | âœ”      | âœ”    | âœ”         | dwc2                   |                    |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | C0, G0, H5, U3              | âœ”      | âœ”    | âœ–         | stm32_fsdev            | 2KB USB RAM        |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | G4                          | âœ”      | âœ–    | âœ–         | stm32_fsdev            | 1KB USB RAM        |\n|              +----+------------------------+--------+------+-----------+------------------------+--------------------+\n|              | L4 | 4x2, 4x3               | âœ”      | âœ–    | âœ–         | stm32_fsdev            | 1KB USB RAM        |\n|              |    +------------------------+--------+------+-----------+------------------------+--------------------+\n|              |    | 4x5, 4x6, 4+           | âœ”      | âœ”    | âœ–         | dwc2                   |                    |\n|              +----+------------------------+--------+------+-----------+------------------------+--------------------+\n|              | N6                          | âœ”      | âœ”    | âœ”         | dwc2                   |                    |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | U0                          | âœ”      | âœ–    | âœ–         | stm32_fsdev            | 1KB USB RAM        |\n|              +----+------------------------+--------+------+-----------+------------------------+--------------------+\n|              | U5 | 535, 545               | âœ”      | âœ”    | âœ–         | stm32_fsdev            | 2KB USB RAM        |\n|              |    +------------------------+--------+------+-----------+------------------------+--------------------+\n|              |    | 575, 585               | âœ”      | âœ”    | âœ–         | dwc2                   |                    |\n|              |    +------------------------+--------+------+-----------+------------------------+--------------------+\n|              |    | 59x,5Ax,5Fx,5Gx        | âœ”      | âœ”    | âœ”         | dwc2                   |                    |\n+--------------+----+------------------------+--------+------+-----------+------------------------+--------------------+\n| TI           | MSP430                      | âœ”      | âœ–    | âœ–         | msp430x5xx             |                    |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | MSP432E4, TM4C123           | âœ”      |      | âœ–         | musb                   |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| ValentyUSB   | eptri                       | âœ”      | âœ–    | âœ–         | eptri                  |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| WCH          | CH32F20x                    | âœ”      |      | âœ”         | ch32_usbhs             |                    |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | CH32V20x                    | âœ”      |      | âœ–         | stm32_fsdev/ch32_usbfs |                    |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | CH32V305, CH32V307          | âœ”      |      | âœ”         | ch32_usbfs/hs          |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n\nTable Legend\n^^^^^^^^^^^^\n\n========= =========================\nâœ”         Supported\nâš          Partial support\nâœ–         Not supported by hardware\n\\[empty\\] Unknown\n========= =========================\n\nDevelopment Tools\n-----------------\n\nThe following tools are provided freely to support the development of the TinyUSB project:\n\n- `IAR Build Tools (CX) <https://iar.com>`_ Professional IDE and compiler for embedded development.\n- `JetBrains CLion <https://www.jetbrains.com/clion/>`_ Cross-platform IDE for C and C++ development.\n- `PVS-Studio <https://pvs-studio.com/en/pvs-studio/?utm_source=website&utm_medium=github&utm_campaign=open_source>`_ static analyzer for C, C++, C#, and Java code.\n\n\n.. |Build Status| image:: https://github.com/hathach/tinyusb/actions/workflows/build.yml/badge.svg\n   :target: https://github.com/hathach/tinyusb/actions/workflows/build.yml\n.. |CircleCI Status| image:: https://dl.circleci.com/status-badge/img/circleci/4AYHvUhFxdnY4rA7LEsdqW/QmrpoL2AjGqetvFQNqtWyq/tree/master.svg?style=svg\n   :target: https://dl.circleci.com/status-badge/redirect/circleci/4AYHvUhFxdnY4rA7LEsdqW/QmrpoL2AjGqetvFQNqtWyq/tree/master\n.. |Documentation Status| image:: https://readthedocs.org/projects/tinyusb/badge/?version=latest\n   :target: https://docs.tinyusb.org/en/latest/?badge=latest\n.. |Static Analysis| image:: https://github.com/hathach/tinyusb/actions/workflows/static_analysis.yml/badge.svg\n   :target: https://github.com/hathach/tinyusb/actions/workflows/static_analysis.yml\n.. |Fuzzing Status| image:: https://oss-fuzz-build-logs.storage.googleapis.com/badges/tinyusb.svg\n   :target: https://oss-fuzz-build-logs.storage.googleapis.com/index.html#tinyusb\n.. |Membrowse| image:: https://membrowse.com/badge.svg\n   :target: https://membrowse.com/public/hathach/tinyusb\n.. |License| image:: https://img.shields.io/badge/license-MIT-brightgreen.svg\n   :target: https://opensource.org/licenses/MIT\n\n\n.. _Changelog: docs/info/changelog.rst\n.. _Contributors: CONTRIBUTORS.rst\n.. _Getting Started: docs/getting_started.rst\n.. _Supported Boards: docs/reference/boards.rst\n.. _Dependencies: docs/reference/dependencies.rst\n.. _Concurrency: docs/reference/concurrency.rst\n.. _Code of Conduct: CODE_OF_CONDUCT.rst\n.. _Porting: docs/porting.rst\n",
      "stars_today": 4
    },
    {
      "id": 453068084,
      "name": "risingwave",
      "full_name": "risingwavelabs/risingwave",
      "description": "Event streaming platform for agents, apps, and analytics. Continuously ingest, transform, and serve event data in real time, at scale.",
      "html_url": "https://github.com/risingwavelabs/risingwave",
      "stars": 8773,
      "forks": 732,
      "language": "Rust",
      "topics": [
        "apache-iceberg",
        "data-engineering",
        "database",
        "etl-pipeline",
        "kafka",
        "materialized-view",
        "postgresql",
        "rust",
        "stream-processing"
      ],
      "created_at": "2022-01-28T12:58:03Z",
      "updated_at": "2026-02-07T02:28:11Z",
      "pushed_at": "2026-02-07T01:32:43Z",
      "open_issues": 1428,
      "owner": {
        "login": "risingwavelabs",
        "avatar_url": "https://avatars.githubusercontent.com/u/77175557?v=4"
      },
      "readme": "\n<p align=\"center\">\n  <picture>\n    <source srcset=\".github/RisingWave-logo-dark.svg\" width=\"500px\" media=\"(prefers-color-scheme: dark)\">\n    <img src=\".github/RisingWave-logo-light.svg\" width=\"500px\">\n  </picture>\n</p>\n\n\n<div align=\"center\">\n\n### ğŸŒŠ Ride the wave of event streaming\n\n</div>\n<p align=\"center\">\n  <a href=\"https://docs.risingwave.com/\">Docs</a> | <a href=\"https://docs.risingwave.com/get-started/rw-benchmarks-stream-processing\">Benchmarks</a> | <a href=\"https://docs.risingwave.com/demos/overview\">Demos</a>\n</p>\n\n<p align=\"center\">\n\n<div align=\"center\">\n  <a\n    href=\"https://github.com/risingwavelabs/risingwave/releases/latest\"\n    target=\"_blank\"\n  >\n    <img alt=\"Release\" src=\"https://img.shields.io/github/v/release/risingwavelabs/risingwave.svg?sort=semver\" />\n  </a>\n  <a\n    href=\"https://go.risingwave.com/slack\"\n    target=\"_blank\"\n  >\n    <img alt=\"Slack\" src=\"https://badgen.net/badge/Slack/Join%20RisingWave/0abd59?icon=slack\" />\n  </a>\n  <a\n    href=\"https://x.com/risingwavelabs\"\n    target=\"_blank\"\n  >\n    <img alt=\"X\" src=\"https://img.shields.io/twitter/follow/risingwavelabs\" />\n  </a>\n  <a\n    href=\"https://www.youtube.com/@risingwave-labs\"\n    target=\"_blank\"\n  >\n    <img alt=\"YouTube\" src=\"https://img.shields.io/youtube/channel/views/UCsHwdyBRxBpmkA5RRd0YNEA\" />\n  </a>\n</div>\n\nRisingWave is an enterprise-grade event streaming platform designed to offer the <i><b>simplest</b></i> and <i><b>most cost-effective</b></i> way to <b>ingest</b>, <b>process</b>, and <b>manage</b> real-time event data â€” with built-in support for the [Apache Icebergâ„¢](https://iceberg.apache.org/) open table format. It provides both a Postgres-compatible [SQL interface](https://docs.risingwave.com/sql/overview) and a DataFrame-style [Python interface](https://docs.risingwave.com/python-sdk/intro).\n\nRisingWave can <b>ingest</b> millions of events per second, continuously <b>join and analyze</b> live streams with historical data, <b>serve</b> ad-hoc queries at low latency, and <b>manage</b> data reliably in Apache Icebergâ„¢ tables.\n\n![RisingWave](./docs/dev/src/images/architecture_20250609.jpg)\n\n## Try it out in 60 seconds\n\nInstall RisingWave standalone mode:\n```shell\ncurl -L https://risingwave.com/sh | sh\n```\n\nTo learn about other installation options, such as using a Docker image, see the [quick start guide](https://docs.risingwave.com/get-started/quickstart).\n\n## Unified platform for streaming data\n\nRisingWave delivers a unified streaming data platform that combines **ultra-low-latency stream processing** and **Iceberg-native data management**.\n\n### Low-latency streaming ingestion and processing\nRisingWave integrates real-time streaming ingestion, stream processing and low-latency serving in a single system. It continuously ingests data from streaming and batch sources, performs incremental computations across streams and tables with end-to-end freshness under 100 ms. Materialized views can be served directly within RisingWave with 10â€“20 ms p99 query latency, or delivered to downstream systems.\n\n### Iceberg lakehouse ingestion, transformation, and management\nRisingWave treats Apache Icebergâ„¢ as a first-class citizen. It directly hosts and manages the Iceberg REST catalog, allowing users to create and operate Iceberg tables through a PostgreSQL-compatible interface. RisingWave supports two write modes: Merge-on-Read (MoR) and Copy-on-Write (CoW), to suit different ingestion and query patterns. It also provides built-in table maintenance capabilities, including compaction, small-file optimization, vacuum, and snapshot cleanup, ensuring efficient and consistent data management without external tools or pipelines.\n\n_Plug: [Nimtable](https://github.com/nimtable/nimtable) is an observability tool developed by RisingWave for easily exploring and managing Iceberg tables._\n\n\n\n## Key design decisions\n\nRisingWave is designed to be easier to use and more cost-efficient:\n\n### PostgreSQL compatibility\n\n* **Seamless integration:** Connects via the PostgreSQL wire protocol, working with psql, JDBC, and any Postgres tool.\n* **Expressive SQL:** Supports structured, semi-structured, and unstructured data with a familiar SQL dialect.\n* **No manual state tuning:** Eliminates complex state management configurations.\n\n### S3 as primary storage\n\nRisingWave stores tables, materialized views, and internal states of stream processing jobs in S3 (or equivalent object storage), providing:\n- **High performance:** Optimized for complex queries, including joins and time windowing.\n- **Fast recovery:** Restores from system failures within seconds.\n- **[Dynamic scaling](https://docs.risingwave.com/deploy/k8s-cluster-scaling):** Instantly adjusts resources to handle workload spikes.\n\nBeyond caching hot data in memory, RisingWave supports [**elastic disk cache**](https://docs.risingwave.com/get-started/disk-cache), a powerful performance optimization that uses local disks or EBS for efficient data caching. This minimizes access to S3, lowering processing latency and cutting S3 access costs.\n\n### Apache Icebergâ„¢ native support\nRisingWave [**natively integrates with Apache Icebergâ„¢**](https://docs.risingwave.com/iceberg/overview), enabling continuous ingestion of streaming data into Iceberg tables. It can also read directly from Iceberg, perform automatic compaction, and maintain table health over time. Since Iceberg is an open table format, results are accessible by other query engines â€” making storage not only cost-efficient, but interoperable by design.\n\n## In what use cases does RisingWave excel?\nRisingWave is particularly effective for the following use cases:\n\n* **Live dashboards**: Achieve sub-second data freshness in live dashboards, ideal for high-stakes scenarios like stock trading, sports betting, and IoT monitoring.\n* **Monitoring and alerting**: Develop sophisticated monitoring and alerting systems for critical applications such as fraud and anomaly detection.\n* **Real-time data enrichment**: Continuously ingest data from diverse sources, conduct real-time data enrichment, and efficiently deliver the results to downstream systems.\n* **Feature engineering**: Transform batch and streaming data into features in your machine learning models using a unified codebase, ensuring seamless integration and consistency.\n* **Iceberg-based lakehouses**: Power real-time lakehouse architectures where streaming data is continuously written to Apache Icebergâ„¢ tables for unified analytics, governance, and long-term retention in open formats.\n\n## Production deployments\n\n[**RisingWave Cloud**](https://cloud.risingwave.com) offers the easiest way to run RisingWave in production.\n\nFor **Docker deployment**, please refer to [Docker Compose](https://docs.risingwave.com/deploy/risingwave-docker-compose/).\n\nFor **Kubernetes deployment**, please refer to [Kubernetes with Helm](https://docs.risingwave.com/deploy/risingwave-k8s-helm/) or [Kubernetes with Operator](https://docs.risingwave.com/deploy/risingwave-kubernetes/).\n\n## Community\n\nLooking for help, discussions, collaboration opportunities, or a casual afternoon chat with our fellow engineers and community members? Join our [Slack workspace](https://risingwave.com/slack)!\n\n## Notes on telemetry\n\n\nRisingWave uses [Scarf](https://scarf.sh/) to collect anonymized installation analytics. These analytics help support us understand and improve the distribution of our package. The privacy policy of Scarf is available at [https://about.scarf.sh/privacy-policy](https://about.scarf.sh/privacy-policy).\n\nRisingWave also collects anonymous usage statistics to better understand how the community is using RisingWave. The sole intention of this exercise is to help improve the product. Users may opt out easily at any time. Please refer to the [user documentation](https://docs.risingwave.com/operate/telemetry/) for more details.\n\n## License\n\nRisingWave is distributed under the Apache License (Version 2.0). Please refer to [LICENSE](LICENSE) for more information.\n\n## Contributing\n\nThanks for your interest in contributing to the project! Please refer to [RisingWave Developer Guide](https://risingwavelabs.github.io/risingwave/) for more information.\n",
      "stars_today": 4
    },
    {
      "id": 236055696,
      "name": "tempo",
      "full_name": "grafana/tempo",
      "description": "Grafana Tempo is a high volume, minimal dependency distributed tracing backend.",
      "html_url": "https://github.com/grafana/tempo",
      "stars": 5049,
      "forks": 659,
      "language": "Go",
      "topics": [
        "distributed-tracing",
        "grafana"
      ],
      "created_at": "2020-01-24T18:05:02Z",
      "updated_at": "2026-02-07T01:02:52Z",
      "pushed_at": "2026-02-06T21:06:10Z",
      "open_issues": 132,
      "owner": {
        "login": "grafana",
        "avatar_url": "https://avatars.githubusercontent.com/u/7195757?v=4"
      },
      "readme": "<p align=\"center\"><img src=\"docs/sources/tempo/logo_and_name.png\" alt=\"Tempo Logo\"></p>\n<p align=\"center\">\n  <a href=\"https://github.com/grafana/tempo/releases\"><img src=\"https://img.shields.io/github/v/release/grafana/tempo?display_name=tag&sort=semver\" alt=\"Latest Release\"/></a>\n  <img src=\"https://img.shields.io/github/license/grafana/tempo\" alt=\"License\" />\n  <a href=\"https://hub.docker.com/r/grafana/tempo/tags\"><image src=\"https://img.shields.io/docker/pulls/grafana/tempo\" alt=\"Docker Pulls\"/></a>\n  <a href=\"https://grafana.slack.com/archives/C01D981PEE5\"><img src=\"https://img.shields.io/badge/join%20slack-%23tempo-brightgreen.svg\" alt=\"Slack\" /></a>\n  <a href=\"https://community.grafana.com/c/grafana-tempo/40\"><img src=\"https://img.shields.io/badge/discuss-tempo%20forum-orange.svg\" alt=\"Community Forum\" /></a>\n  <a href=\"https://goreportcard.com/report/github.com/grafana/tempo\"><img src=\"https://goreportcard.com/badge/github.com/grafana/tempo\" alt=\"Go Report Card\" /></a>\n</p>\n\nGrafana Tempo is an open source, easy-to-use, and high-scale distributed tracing backend. Tempo is cost-efficient, requiring only object storage to operate, and is deeply integrated with Grafana, Prometheus, and Loki.\n\n\n## Business value of distributed tracing\n\nDistributed tracing helps teams quickly pinpoint performance issues and understand the flow of requests across services. The Traces Drilldown UI simplifies this process by offering a user-friendly interface to view and analyze trace data, making it easier to identify and resolve issues without needing to write complex queries.\n\nRefer to [Use traces to find solutions](https://grafana.com/docs/tempo/latest/introduction/solutions-with-traces/) to learn more about how you can use distributed tracing to investigate and solve issues.\n\n## Traces Drilldown UI: A better way to get value from your tracing data\nWe are excited to introduce the [Traces Drilldown](https://github.com/grafana/traces-drilldown) (formerly Explore Traces) app as part of the Grafana Explore suite. This app provides a queryless and intuitive experience for analyzing tracing data, allowing teams to quickly identify performance issues, latency bottlenecks, and errors without needing to write complex queries or use TraceQL.\n\nKey Features:\n- **Intuitive Trace Analysis**: Spot slow or error-prone traces with easy, point-and-click interactions.\n- **RED Metrics Overview**: Use Rate, Errors, and Duration metrics to highlight performance issues.\n- **Automated Comparison**: Identify problematic attributes with automatic trace comparison.\n- **Simplified Visualizations**: Access rich visual data without needing to construct TraceQL queries.\n\n![image](https://github.com/user-attachments/assets/991205df-1b27-489f-8ef0-1a05ee158996)\n\nTo learn more see the following links:\n- [Traces Drilldown repo](https://github.com/grafana/traces-drilldown)\n- [Traces Drilldown documentation](https://grafana.com/docs/grafana/latest/explore/simplified-exploration/traces/)\n- [Demo video](https://www.youtube.com/watch?v=a3uB1C2oHA4)\n\n## TraceQL\n\nTempo implements [TraceQL](https://grafana.com/docs/tempo/latest/traceql/), a traces-first query language inspired by LogQL and PromQL, which enables targeted queries or rich UI-driven analyses.\n\n### TraceQL metrics\n\n[TraceQL metrics](https://grafana.com/docs/tempo/latest/traceql/metrics-queries/) is an experimental feature in Grafana Tempo that creates metrics from traces. Metric queries extend trace queries by applying a function to trace query results. This powerful feature allows for ad hoc aggregation of any existing TraceQL query by any dimension available in your traces, much in the same way that LogQL metric queries create metrics from logs.\n\nTempo is Jaeger, Zipkin, Kafka, OpenCensus, and OpenTelemetry compatible. It ingests batches in any of the mentioned formats, buffers them, and then writes them to Azure, GCS, S3, or local disk. As such, it's robust, cheap, and easy to operate.\n\n## Getting started with Tempo\n\n- [Get started documentation](https://grafana.com/docs/tempo/latest/getting-started/)\n- [Deployment Examples](./example)\n  - [Docker Compose](./example/docker-compose)\n  - [Helm](./example/helm)\n  - [Jsonnet](./example/tk)\n\n## Further reading\n\nTo learn more about Tempo, consult the following documents & talks:\n\n- [How to get started with Tempo with Joe Elliott (video)](https://www.youtube.com/watch?v=zDrA7Ly3ovU)\n- [Grafana blog posts about Tempo](https://grafana.com/tags/tempo/)\n- [New in Grafana Tempo 2.0: Apache Parquet as the default storage format, support for TraceQL][tempo_20_announce]\n- [Get to know TraceQL: A powerful new query language for distributed tracing][traceql-post]\n\n[tempo_20_announce]: https://grafana.com/blog/2023/02/01/new-in-grafana-tempo-2.0-apache-parquet-as-the-default-storage-format-support-for-traceql/\n[traceql-post]: https://grafana.com/blog/2023/02/07/get-to-know-traceql-a-powerful-new-query-language-for-distributed-tracing/\n\n## Getting help\n\nIf you have any questions or feedback regarding Tempo:\n\n- Grafana Labs hosts a [forum](https://community.grafana.com/c/grafana-tempo/40) for Tempo. This is a great place to post questions and search for answers.\n- Ask a question on the [Tempo Slack channel](https://grafana.slack.com/archives/C01D981PEE5).\n- [File an issue](https://github.com/grafana/tempo/issues/new/choose) for bugs, issues and feature suggestions.\n- UI issues should be filed with [Grafana](https://github.com/grafana/grafana/issues/new/choose).\n\n## OpenTelemetry\n\nTempo's receiver layer, wire format and storage format are all based directly on [standards](https://github.com/open-telemetry/opentelemetry-proto) and [code](https://github.com/open-telemetry/opentelemetry-collector) established by [OpenTelemetry](https://opentelemetry.io/).  We support open standards at Grafana!\n\nCheck out the [Integration Guides](https://grafana.com/docs/tempo/latest/guides/instrumentation/) to see examples of OpenTelemetry instrumentation with Tempo.\n\n## Other components\n\n### tempo-vulture\n[tempo-vulture](https://github.com/grafana/tempo/tree/main/cmd/tempo-vulture) is Tempo's bird themed consistency checking tool.  It writes traces to Tempo and then queries them back in a variety of ways.\n\n### tempo-cli\n[tempo-cli](https://github.com/grafana/tempo/tree/main/cmd/tempo-cli) is the place to put any utility functionality related to Tempo. See [Documentation](https://grafana.com/docs/tempo/latest/operations/tempo_cli/) for more info.\n\n## License\n\nGrafana Tempo is distributed under [AGPL-3.0-only](LICENSE). For Apache-2.0 exceptions, see [LICENSING.md](LICENSING.md).\n",
      "stars_today": 4
    },
    {
      "id": 2990192,
      "name": "Signal-Android",
      "full_name": "signalapp/Signal-Android",
      "description": "A private messenger for Android.",
      "html_url": "https://github.com/signalapp/Signal-Android",
      "stars": 28282,
      "forks": 6665,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2011-12-15T20:01:12Z",
      "updated_at": "2026-02-07T00:11:10Z",
      "pushed_at": "2026-02-07T00:11:04Z",
      "open_issues": 441,
      "owner": {
        "login": "signalapp",
        "avatar_url": "https://avatars.githubusercontent.com/u/702459?v=4"
      },
      "readme": "# Signal Android\n\nSignal is a simple, powerful, and secure messenger that uses your phone's data connection (WiFi/3G/4G/5G) to communicate securely.\n\nMillions of people use Signal every day for free and instantaneous communication anywhere in the world. Send and receive high-fidelity messages, participate in HD voice/video calls, and explore a growing set of new features that help you stay connected. \n\nSignalâ€™s advanced privacy-preserving technology is always enabled, so you can focus on sharing the moments that matter with the people who matter to you.\n\nCurrently available on the [Play Store](https://play.google.com/store/apps/details?id=org.thoughtcrime.securesms) and [signal.org](https://signal.org/android/apk/).\n\n<a href='https://play.google.com/store/apps/details?id=org.thoughtcrime.securesms&pcampaignid=MKT-Other-global-all-co-prtnr-py-PartBadge-Mar2515-1'><img alt='Get it on Google Play' src='https://play.google.com/intl/en_us/badges/images/generic/en_badge_web_generic.png' height='80px'/></a>\n\nAlso available on [iOS](https://github.com/signalapp/signal-ios) and [Desktop](https://github.com/signalapp/signal-desktop).\n\n## Contributing Bug Reports\nWe use GitHub for bug tracking. Please search the existing issues for your bug and create a new one if the issue is not yet tracked!\n\nhttps://github.com/signalapp/Signal-Android/issues\n\n## Joining the Beta\nWant to live life on the bleeding edge and help out with testing?\n\nYou can subscribe to Signal Android Beta releases here:\nhttps://play.google.com/apps/testing/org.thoughtcrime.securesms\n\nIf you're interested in a life of peace and tranquility, stick with the standard releases.\n\n## Contributing Translations\nInterested in helping translate Signal? Contribute here:\n\nhttps://community.signalusers.org/c/translation-feedback/\n\n## Contributing Code\n\nIf you're new to the Signal codebase, we recommend going through our issues and picking out a simple bug to fix in order to get yourself familiar. Also please have a look at the [CONTRIBUTING.md](https://github.com/signalapp/Signal-Android/blob/main/CONTRIBUTING.md), that might answer some of your questions.\n\nFor larger changes and feature ideas, we ask that you propose it on the [unofficial Community Forum](https://community.signalusers.org) for a high-level discussion with the wider community before implementation.\n\n## Contributing Ideas\nHave something you want to say about Signal projects or want to be part of the conversation? Get involved in the [community forum](https://community.signalusers.org).\n\nHelp\n====\n## Support\nFor troubleshooting and questions, please visit our support center!\n\nhttps://support.signal.org/\n\n## Documentation\nLooking for documentation? Check out the wiki!\n\nhttps://github.com/signalapp/Signal-Android/wiki\n\n# Legal things\n## Cryptography Notice\n\nThis distribution includes cryptographic software. The country in which you currently reside may have restrictions on the import, possession, use, and/or re-export to another country, of encryption software.\nBEFORE using any encryption software, please check your country's laws, regulations and policies concerning the import, possession, or use, and re-export of encryption software, to see if this is permitted.\nSee <http://www.wassenaar.org/> for more information.\n\nThe U.S. Government Department of Commerce, Bureau of Industry and Security (BIS), has classified this software as Export Commodity Control Number (ECCN) 5D002.C.1, which includes information security software using or performing cryptographic functions with asymmetric algorithms.\nThe form and manner of this distribution makes it eligible for export under the License Exception ENC Technology Software Unrestricted (TSU) exception (see the BIS Export Administration Regulations, Section 740.13) for both object code and source code.\n\n## License\n\nCopyright 2013-2025 Signal Messenger, LLC\n\nLicensed under the GNU AGPLv3: https://www.gnu.org/licenses/agpl-3.0.html\n\nGoogle Play and the Google Play logo are trademarks of Google LLC.\n",
      "stars_today": 3
    },
    {
      "id": 70198664,
      "name": "lottie-ios",
      "full_name": "airbnb/lottie-ios",
      "description": "An iOS library to natively render After Effects vector animations",
      "html_url": "https://github.com/airbnb/lottie-ios",
      "stars": 26656,
      "forks": 3832,
      "language": "Swift",
      "topics": [
        "animation",
        "bodymovin",
        "custom-transitions",
        "ios",
        "ios-animation",
        "ios-transition",
        "keyframes",
        "swift",
        "transition-animation"
      ],
      "created_at": "2016-10-06T22:38:38Z",
      "updated_at": "2026-02-07T01:15:43Z",
      "pushed_at": "2026-02-06T14:42:19Z",
      "open_issues": 47,
      "owner": {
        "login": "airbnb",
        "avatar_url": "https://avatars.githubusercontent.com/u/698437?v=4"
      },
      "readme": "# Lottie for iOS\n [![Version](https://img.shields.io/cocoapods/v/lottie-ios.svg?style=flat)](https://cocoapods.org/pods/lottie-ios) [![Carthage Compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat)](https://github.com/Carthage/Carthage) [![SwiftPM](https://img.shields.io/badge/SPM-supported-DE5C43.svg?style=flat)](https://swift.org/package-manager/) [![License](https://img.shields.io/cocoapods/l/lottie-ios.svg?style=flat)](https://cocoapods.org/pods/lottie-ios) [![Platform](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fairbnb%2Flottie-ios%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/airbnb/lottie-ios) [![Swift Versions](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fairbnb%2Flottie-ios%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/airbnb/lottie-ios)\n\n**View documentation, FAQ, help, examples, and more at [airbnb.io/lottie](https://airbnb.io/lottie/)**\n\nLottie is a cross-platform library for iOS, macOS, tvOS, visionOS, [Android](https://github.com/airbnb/lottie-android), and [Web](https://github.com/airbnb/lottie-web) that natively renders vector-based animations and art in realtime with minimal code.\n\nLottie loads and renders animations and vectors exported in the bodymovin JSON format. Bodymovin JSON can be created and exported from After Effects with [bodymovin](https://github.com/bodymovin/bodymovin), Sketch with [Lottie Sketch Export](https://github.com/buba447/Lottie-Sketch-Export), and from [Haiku](https://www.haikuanimator.com).\n\nDesigners can create **and ship** beautiful animations without an engineer painstakingly recreating them by hand.\nSince the animations are backed by JSON, they are extremely small in size but can be large in complexity!\nAnimations can be played, resized, looped, sped up, slowed down, reversed, and even interactively scrubbed.\nLottie can play or loop just a portion of the animation as well, the possibilities are endless!\nAnimations can even be ***changed at runtime*** in various ways! Change the color, position, or any keyframable value!\n\nHere is just a small sampling of the power of Lottie\n\n![Example1](_Gifs/Examples1.gif)\n![Example2](_Gifs/Examples2.gif)\n\n<img src=\"_Gifs/Community 2_3.gif\" />\n\n![Example3](_Gifs/Examples3.gif)\n\n![Abcs](_Gifs/Examples4.gif)\n\n## Installing Lottie\nLottie supports [Swift Package Manager](https://www.swift.org/package-manager/), [CocoaPods](https://cocoapods.org/), and [Carthage](https://github.com/Carthage/Carthage) (Both dynamic and static).\n\n### Github Repo\n\nYou can pull the [Lottie Github Repo](https://github.com/airbnb/lottie-ios/) and include the `Lottie.xcodeproj` to build a dynamic or static library.\n\n### Swift Package Manager\n\nTo install Lottie using [Swift Package Manager](https://github.com/swiftlang/swift-package-manager) you can follow the [tutorial published by Apple](https://developer.apple.com/documentation/xcode/adding_package_dependencies_to_your_app) using the URL for the Lottie repo with the current version:\n\n1. In Xcode, select â€œFileâ€ â†’ â€œAdd Packages...â€\n1. Enter https://github.com/airbnb/lottie-spm.git\n\nor you can add the following dependency to your `Package.swift`:\n\n```swift\n.package(url: \"https://github.com/airbnb/lottie-spm.git\", from: \"4.5.2\")\n```\n\nWhen using Swift Package Manager we recommend using the [lottie-spm](https://github.com/airbnb/lottie-spm) repo instead of the main lottie-ios repo.  The main git repository for [lottie-ios](https://github.com/airbnb/lottie-ios) is somewhat large (300+ MB), and Swift Package Manager always downloads the full repository with all git history. The [lottie-spm](https://github.com/airbnb/lottie-spm) repo is much smaller (less than 500kb), so can be downloaded much more quickly. \n\nInstead of downloading the full git history of Lottie and building it from source, the lottie-spm repo just contains a pointer to the precompiled XCFramework included in the [latest lottie-ios release](https://github.com/airbnb/lottie-ios/releases/latest) (typically ~8MB). If you prefer to include Lottie source directly your project, you can directly depend on the main lottie-ios repo by referencing `https://github.com/airbnb/lottie-ios.git` instead.\n\n### CocoaPods\nAdd the pod to your Podfile:\n```ruby\npod 'lottie-ios'\n```\n\nAnd then run:\n```ruby\npod install\n```\nAfter installing the cocoapod into your project import Lottie with\n```swift\nimport Lottie\n```\n\n### Carthage\nAdd Lottie to your Cartfile:\n```\ngithub \"airbnb/lottie-ios\" \"master\"\n```\n\nAnd then run:\n```\ncarthage update\n```\nIn your application targets â€œGeneralâ€ tab under the â€œLinked Frameworks and Librariesâ€ section, drag and drop lottie-ios.framework from the Carthage/Build/iOS directory that `carthage update` produced.\n\n## Swift Version Support\n\nLottie supports Swift / Xcode versions back to the minimum version that is permitted by Apple for submissions to the App Store. You can see the most up-to-date information for which Swift versions Lottie supports on [Swift Package Index](https://swiftpackageindex.com/airbnb/lottie-ios):\n\n[![Swift Versions](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fairbnb%2Flottie-ios%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/airbnb/lottie-ios)\n\n## Privacy\n\nLottie does not collect any data. We provide this notice to help you fill out [App Privacy Details](https://developer.apple.com/app-store/app-privacy-details/). We additionally provide a [privacy manifest](https://github.com/airbnb/lottie-ios/blob/master/Sources/PrivacyInfo.xcprivacy) which can be included in your app.\n\n## Security\n\nWe distribute XCFramework bundles for each release on [GitHub](https://github.com/airbnb/lottie-ios/releases/latest). In Lottie 4.4.0 and later, these XCFramework bundles include a [code signature](https://developer.apple.com/documentation/xcode/verifying-the-origin-of-your-xcframeworks). These bundles are self-signed under the name \"Lottie iOS\" and have the following fingerprint:\n\n```\n89 2F 1B 43 04 7B 50 53 8F 2F 46 EA D9 29 00 DD 3D 48 11 F358 21 78 C0 61 A5 FB 20 F1 11 CB 26\n```\n\nIn Xcode you can verify this by selecting `Lottie.xcframework` and confirming that it shows the following information:\n\n![Code Signature in Xcode](_Gifs/code_signature.png)\n\n## Contributing\n\nWe always appreciate contributions from the community. To make changes to the project, you can clone the repo and open `Lottie.xcworkspace`. This workspace includes:\n - the Lottie framework (for iOS, macOS, and tvOS)\n - unit tests and snapshot tests (for iOS, must be run on an iPhone 8 simulator)\n - an Example iOS app that lets you browse and test over 100 sample animations included in the repo\n\nAll pull requests with new features or bug fixes that affect how animations render should include snapshot test cases that validate the included changes. \n  - To add a new sample animation to the snapshot testing suite, you can add the `.json` file to `Tests/Samples`. Re-run the snapshot tests to generate the new snapshot image files.\n  - To update existing snapshots after making changes, you can set `isRecording = true` in `SnapshotTests.swift` `setUp()` method and then re-run the snapshot tests.\n\nThe project also includes several helpful commands defined in our [Rakefile](https://github.com/airbnb/lottie-ios/blob/master/Rakefile). To use these, you need to install [Bundler](https://bundler.io/):\n\n```bash\n$ sudo gem install bundle\n$ bundle install\n```\n\nFor example, all Swift code should be formatted according to the [Airbnb Swift Style Guide](https://github.com/airbnb/swift). After making changes, you can reformat the code automatically using [SwiftFormat](https://github.com/nicklockwood/SwiftFormat) and [SwiftLint](https://github.com/realm/SwiftLint) by running `bundle exec rake format:swift`. Other helpful commands include:\n\n```bash\n$ bundle exec rake build:all # builds all targets for all platforms\n$ bundle exec rake build:package:iOS # builds the Lottie package for iOS\n$ bundle exec rake test:package # tests the Lottie package\n$ bundle exec rake format:swift # reformat Swift code based on the Airbnb Swift Style Guide\n```\n",
      "stars_today": 3
    },
    {
      "id": 35732214,
      "name": "SwiftLint",
      "full_name": "realm/SwiftLint",
      "description": "A tool to enforce Swift style and conventions.",
      "html_url": "https://github.com/realm/SwiftLint",
      "stars": 19436,
      "forks": 2278,
      "language": "Swift",
      "topics": [
        "code-quality",
        "hacktoberfest",
        "linter",
        "linting",
        "static-analysis",
        "swift"
      ],
      "created_at": "2015-05-16T16:59:31Z",
      "updated_at": "2026-02-06T19:07:37Z",
      "pushed_at": "2026-02-06T17:55:57Z",
      "open_issues": 476,
      "owner": {
        "login": "realm",
        "avatar_url": "https://avatars.githubusercontent.com/u/7575099?v=4"
      },
      "readme": "# SwiftLint\n\nA tool to enforce Swift style and conventions, loosely based on the now\narchived [GitHub Swift Style Guide](https://github.com/github/swift-style-guide).\nSwiftLint enforces the style guide rules that are generally accepted by the\nSwift community. These rules are well described in popular style guides like\n[Kodeco's Swift Style Guide](https://github.com/kodecocodes/swift-style-guide).\n\nSwiftLint rules are predominantly based on [SwiftSyntax](https://github.com/swiftlang/swift-syntax).\nSome rules still hook into [Clang](http://clang.llvm.org) and\n[SourceKit](http://www.jpsim.com/uncovering-sourcekit) to access type information.\n\n[![Supported Swift Versions](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Frealm%2FSwiftLint%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/realm/SwiftLint)\n[![Supported Platforms](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Frealm%2FSwiftLint%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/realm/SwiftLint)\n[![Buildkite Build Status](https://badge.buildkite.com/e2a5bc32c347e76e2793e4c5764a5f42bcd42bbe32f79c3a53.svg?branch=main)](https://buildkite.com/swiftlint/swiftlint)\n\n![SwiftLint violations highlighted in the Xcode editor](https://raw.githubusercontent.com/realm/SwiftLint/main/assets/screenshot.png)\n\nThis project adheres to the\n[Contributor Covenant Code of Conduct](https://realm.io/conduct).\nBy participating, you are expected to uphold this code.\n\n> Switch Language:\n> [ä¸­æ–‡](https://github.com/realm/SwiftLint/blob/main/README_CN.md),\n> [í•œêµ­ì–´](https://github.com/realm/SwiftLint/blob/main/README_KR.md)\n\n## Video Introduction\n\nTo get a high-level overview of SwiftLint, we encourage you to watch this\npresentation recorded January 9th, 2017 by JP Simard (transcript provided):\n\n[![Presentation](https://raw.githubusercontent.com/realm/SwiftLint/main/assets/presentation.svg)](https://youtu.be/9Z1nTMTejqU)\n\n## Installation\n\n### [Swift Package Manager](https://github.com/apple/swift-package-manager)\n\nSwiftLint can be used as a [command plugin](#swift-package-command-plugin)\nor a [build tool plugin](#build-tool-plugins).\n\nAdd\n\n```swift\n.package(url: \"https://github.com/SimplyDanny/SwiftLintPlugins\", from: \"<version>\")\n```\n\nto your `Package.swift` file to consume the latest release of SwiftLint\nautomatically or pin the dependency to a specific version:\n\n```swift\n.package(url: \"https://github.com/SimplyDanny/SwiftLintPlugins\", exact: \"<version>\")\n```\n\nTherein, replace `<version>` with the desired minimum or exact version.\n\n> [!NOTE]\n> Consuming the plugins directly from the SwiftLint repository comes\n> with several drawbacks. To avoid them and reduce the overhead imposed, it's\n> highly recommended to consume the plugins from the dedicated\n> [SwiftLintPlugins repository](https://github.com/SimplyDanny/SwiftLintPlugins),\n> even though plugins from the SwiftLint repository are also absolutely\n> functional. If the plugins from SwiftLint are preferred, just use the URL\n> `https://github.com/realm/SwiftLint` in the package declarations above.\n>\n> However, [SwiftLintPlugins](https://github.com/SimplyDanny/SwiftLintPlugins)\n> facilitates plugin adoption massively. It lists some of the reasons that\n> drive the plugins as provided by SwiftLint itself very troublesome. Since\n> the plugin code and the releases are kept in sync, there is no difference\n> in functionality between the two, but you spare yourself a lot of time and\n> trouble using the dedicated plugins repository.\n>\n> This document assumes you're relying on SwiftLintPlugins.\n\n### [Xcode Package Dependency](https://developer.apple.com/documentation/xcode/adding-package-dependencies-to-your-app)\n\nUse the following link to add SwiftLint as a Package Dependency to an Xcode\nproject:\n\n```bash\nhttps://github.com/SimplyDanny/SwiftLintPlugins\n```\n\n### [Homebrew](http://brew.sh)\n\n```bash\nbrew install swiftlint\n```\n\n### [CocoaPods](https://cocoapods.org)\n\nAdd the following to your `Podfile`:\n\n```ruby\npod 'SwiftLint'\n```\n\nThis will download the SwiftLint binaries and dependencies in `Pods/` during\nyour next `pod install` execution and will allow you to invoke it via\n`${PODS_ROOT}/SwiftLint/swiftlint` in your Script Build Phases.\n\nInstalling via Cocoapods also enables pinning to a specific version of\nSwiftLint rather than simply the latest (which is the case with\n[Homebrew](#homebrew)).\n\nNote that this will add the SwiftLint binaries, its dependencies' binaries, and\nthe Swift binary library distribution to the `Pods/` directory, so checking in\nthis directory to SCM such as Git is discouraged.\n\n### [Mint](https://github.com/yonaskolb/mint)\n\n```bash\nmint install realm/SwiftLint\n```\n\n### [Bazel](https://bazel.build)\n\nPut this in your `MODULE.bazel`:\n\n```bzl\nbazel_dep(name = \"swiftlint\", version = \"0.52.4\", repo_name = \"SwiftLint\")\n```\n\nOr put this in your `WORKSPACE`:\n\n<details>\n\n<summary>WORKSPACE</summary>\n\n```bzl\nload(\"@bazel_tools//tools/build_defs/repo:http.bzl\", \"http_archive\")\n\nhttp_archive(\n    name = \"build_bazel_rules_apple\",\n    sha256 = \"390841dd5f8a85fc25776684f4793d56e21b098dfd7243cd145b9831e6ef8be6\",\n    url = \"https://github.com/bazelbuild/rules_apple/releases/download/2.4.1/rules_apple.2.4.1.tar.gz\",\n)\n\nload(\n    \"@build_bazel_rules_apple//apple:repositories.bzl\",\n    \"apple_rules_dependencies\",\n)\n\napple_rules_dependencies()\n\nload(\n    \"@build_bazel_rules_swift//swift:repositories.bzl\",\n    \"swift_rules_dependencies\",\n)\n\nswift_rules_dependencies()\n\nload(\n    \"@build_bazel_rules_swift//swift:extras.bzl\",\n    \"swift_rules_extra_dependencies\",\n)\n\nswift_rules_extra_dependencies()\n\nhttp_archive(\n    name = \"SwiftLint\",\n    sha256 = \"c6ea58b9c72082cdc1ada4a2d48273ecc355896ed72204cedcc586b6ccb8aca6\",\n    url = \"https://github.com/realm/SwiftLint/releases/download/0.52.4/bazel.tar.gz\",\n)\n\nload(\"@SwiftLint//bazel:repos.bzl\", \"swiftlint_repos\")\n\nswiftlint_repos()\n\nload(\"@SwiftLint//bazel:deps.bzl\", \"swiftlint_deps\")\n\nswiftlint_deps()\n```\n\n</details>\n\nThen you can run SwiftLint in the current directory with this command:\n\n```console\nbazel run -c opt @SwiftLint//:swiftlint\n```\n\n### Pre-Built Package\n\nDownload `SwiftLint.pkg` from the\n[latest GitHub release](https://github.com/realm/SwiftLint/releases/latest) and\nrun it.\n\n### From Source\n\nMake sure the build tool [Bazel](https://bazel.build) and a\nrecent [Swift toolchain](https://www.swift.org/download/) are\ninstalled and all tools are discoverable in your `PATH`.\n\nTo build SwiftLint, clone this repository and run `make install`.\n\n## Setup\n\n> [!IMPORTANT]\n> While it may seem intuitive to run SwiftLint before compiling Swift source\n> files to exit a build early when there are lint violations, it is important\n> to understand that SwiftLint is designed to analyze valid source code that\n> is compilable. Non-compiling code can very easily lead to unexpected and\n> confusing results, especially when executing with `--fix`/`--autocorrect`\n> command line arguments.\n\n### Build Tool Plugins\n\nSwiftLint can be used as a build tool plugin for both\n[Swift Package projects](#swift-package-projects)\nand [Xcode projects](#xcode-projects).\n\nThe build tool plugin determines the SwiftLint working directory by locating\nthe topmost config file within the package/project directory. If a config file\nis not found therein, the package/project directory is used as the working\ndirectory.\n\nThe plugin throws an error when it is unable to resolve the SwiftLint working\ndirectory. For example, this will occur in Xcode projects where the target's\nSwift files are not located within the project directory.\n\nTo maximize compatibility with the plugin, avoid project structures that require\nthe use of the `--config` option.\n\n### Swift Package Projects\n\n> [!NOTE]\n> Requires installing via [Swift Package Manager](#swift-package-manager).\n\nBuild tool plugins run when building each target. When a project has multiple\ntargets, the plugin must be added to the desired targets individually.\n\nTo do this, add the plugin to the target(s) to be linted as follows:\n\n```swift\n.target(\n    ...\n    plugins: [.plugin(name: \"SwiftLintBuildToolPlugin\", package: \"SwiftLintPlugins\")]\n),\n```\n\n### Swift Package Command Plugin\n\n> [!NOTE]\n> Requires installing via [Swift Package Manager](#swift-package-manager).\n\nThe command plugin enables running SwiftLint from the command line as follows:\n\n```shell\nswift package plugin swiftlint\n```\n\n### Xcode Projects\n\n> [!NOTE]\n> Requires installing via [Xcode Package Dependency](#xcode-package-dependency).\n\nBuild tool plugins run as a build phase of each target. When a project has\nmultiple targets, the plugin must be added to the desired targets individually.\n\nTo do this, add the `SwiftLintBuildToolPlugin` to the `Run Build Tool Plug-ins`\nphase of the `Build Phases` for the target(s) to be linted.\n\n> [!TIP]\n> When using the plugin for the first time, be sure to trust and enable\n> it when prompted. If a macros build warning exists, select it to trust\n> and enable the macros as well.\n\nFor unattended use (e.g. on CI), package plugin and macro\nvalidations can be disabled with either of the following:\n\n* Using `xcodebuild` options:\n\n  ```bash\n  -skipPackagePluginValidation\n  -skipMacroValidation\n  ```\n\n* Setting Xcode defaults:\n\n  ```bash\n  defaults write com.apple.dt.Xcode IDESkipPackagePluginFingerprintValidatation -bool YES\n  defaults write com.apple.dt.Xcode IDESkipMacroFingerprintValidation -bool YES\n  ```\n\n> [!IMPORTANT]\n> The unattended use options bypass Xcode's validation dialogs\n> and implicitly trust all plugins and macros, which has security implications.\n\n#### Unexpected Xcode Project Structures\n\nProject structures where SwiftLint's configuration file is located\noutside of the package/project directory are not directly supported\nby the build tool plugin. This is because it isn't possible to pass\narguments to build tool plugins (e.g., passing the config file path).\n\nIf your project structure doesn't work directly with the build tool\nplugin, please consider one of the following options:\n\n* To use a config file located outside the package/project directory, a config\n  file may be added to that directory specifying a parent config path to the\n  other config file, e.g., `parent_config: path/to/.swiftlint.yml`.\n* You can also consider the use of a\n  [Run Script Build Phase](#xcode-run-script-build-phase) in place of the build\n  tool plugin.\n\n### Xcode Run Script Build Phase\n\n> [!NOTE]\n> Based upon the installation method used, the shell command syntax in the\n> Run Script Build Phase may be different or additional configuration could\n> be required. Refer to the [installation](#installation) instructions for\n> more information.\n\nIf the build tool plugin does not work for your project setup or when\nadditional custom setup is required, SwiftLint can be added as a Run Script\nBuild Phase. This is useful when a project setup relies on the `--config`\nSwiftLint option; or to lint all targets together in a single `swiftlint`\ninvocation. File inclusions and exclusions can be configured in the\n[`.swiftlint.yml` configuration](#configuration).\n\nTo do this, add a custom script to a `Run Script` phase of the `Build Phases`\nof the primary app target, after the `Compile Sources` phase. Use the\nfollowing script implementation:\n\n```bash\nif command -v swiftlint >/dev/null 2>&1\nthen\n    swiftlint\nelse\n    echo \"warning: `swiftlint` command not found - See https://github.com/realm/SwiftLint#installation for installation instructions.\"\nfi\n```\n\nIf you're using the SwiftLintPlugin in a Swift package,\nyou may refer to the `swiftlint` executable in the\nfollowing way:\n\n```bash\nSWIFT_PACKAGE_DIR=\"${BUILD_DIR%Build/*}SourcePackages/artifacts\"\nSWIFTLINT_CMD=\"$SWIFT_PACKAGE_DIR/swiftlintplugins/SwiftLintBinary/SwiftLintBinary.artifactbundle/macos/swiftlint\"\n\nif test -f \"$SWIFTLINT_CMD\" 2>&1\nthen\n    \"$SWIFTLINT_CMD\"\nelse\n    echo \"warning: `swiftlint` command not found - See https://github.com/realm/SwiftLint#xcode-run-script-build-phase for installation instructions.\"\nfi\n```\n\n> [!NOTE]\n> The `SWIFTLINT_CMD` path uses the default Xcode configuration and has been\n> tested on Xcode 15/16. In case of another configuration (e.g. a custom\n> Swift package path), please adapt the values accordingly.\n<!-- markdownlint-disable MD028 -->\n> [!TIP]\n> Uncheck `Based on dependency analysis` to run `swiftlint` on all incremental\n> builds, suppressing the unspecified outputs warning.\n\n#### Consideration for Xcode 15.0\n\nXcode 15 made a significant change by setting the default value of the\n`ENABLE_USER_SCRIPT_SANDBOXING` build setting from `NO` to `YES`.\nAs a result, SwiftLint encounters an error related to missing file permissions,\nwhich typically manifests as\n`error: Sandbox: swiftlint(19427) deny(1) file-read-data.`\n\nTo resolve this issue, it is necessary to manually set the\n`ENABLE_USER_SCRIPT_SANDBOXING` setting to `NO` for the specific target that\nSwiftLint is being configured for.\n\n#### Consideration for Apple Silicon\n\nIf you installed SwiftLint via Homebrew on Apple Silicon, you might experience\nthis warning:\n\n```bash\nwarning: SwiftLint not installed, download from https://github.com/realm/SwiftLint\n```\n\nThat is because Homebrew on Apple Silicon installs the binaries into the\n`/opt/homebrew/bin` folder by default. To instruct Xcode where to find\nSwiftLint, you can either add `/opt/homebrew/bin` to the `PATH` environment\nvariable in your build phase:\n\n```bash\nif [[ \"$(uname -m)\" == arm64 ]]\nthen\n    export PATH=\"/opt/homebrew/bin:$PATH\"\nfi\n\nif command -v swiftlint >/dev/null 2>&1\nthen\n    swiftlint\nelse\n    echo \"warning: `swiftlint` command not found - See https://github.com/realm/SwiftLint#installation for installation instructions.\"\nfi\n```\n\nor you can create a symbolic link in `/usr/local/bin` pointing to the actual\nbinary:\n\n```bash\nln -s /opt/homebrew/bin/swiftlint /usr/local/bin/swiftlint\n```\n\n#### Additional Considerations\n\nIf you wish to fix violations as well, your script could run\n`swiftlint --fix && swiftlint` instead of just `swiftlint`. This will mean\nthat all correctable violations are fixed while ensuring warnings show up in\nyour project for remaining violations.\n\nIf you've installed SwiftLint via CocoaPods the script should look like this:\n\n```bash\n\"${PODS_ROOT}/SwiftLint/swiftlint\"\n```\n\n### Visual Studio Code\n\nTo integrate SwiftLint with [Visual Studio Code](https://code.visualstudio.com), install the\n[`vscode-swiftlint`](https://marketplace.visualstudio.com/items?itemName=vknabel.vscode-swiftlint)\nextension from the marketplace.\n\n### Fastlane\n\nYou can use the official\n[`swiftlint` fastlane action](https://docs.fastlane.tools/actions/swiftlint)\nto run SwiftLint as part of your fastlane process.\n\n```ruby\nswiftlint(\n    mode: :lint,                            # SwiftLint mode: :lint (default) or :autocorrect\n    executable: \"Pods/SwiftLint/swiftlint\", # The SwiftLint binary path (optional). Important if you've installed it via CocoaPods\n    path: \"/path/to/lint\",                  # Specify path to lint (optional)\n    output_file: \"swiftlint.result.json\",   # The path of the output file (optional)\n    reporter: \"json\",                       # The custom reporter to use (optional)\n    config_file: \".swiftlint-ci.yml\",       # The path of the configuration file (optional)\n    files: [                                # List of files to process (optional)\n        \"AppDelegate.swift\",\n        \"path/to/project/Model.swift\"\n    ],\n    ignore_exit_status: true,               # Allow fastlane to continue even if SwiftLint returns a non-zero exit status (Default: false)\n    quiet: true,                            # Don't print status logs like 'Linting ' & 'Done linting' (Default: false)\n    strict: true                            # Fail on warnings? (Default: false)\n)\n```\n\n### Docker\n\nSwiftLint is also available as a [Docker](https://www.docker.com/) image using\n`Ubuntu`. So just the first time you need to pull the docker image using the\nnext command:\n\n```bash\ndocker pull ghcr.io/realm/swiftlint:latest\n```\n\nThen following times, you just run `swiftlint` inside of the docker like:\n\n```bash\ndocker run -it -v `pwd`:`pwd` -w `pwd` ghcr.io/realm/swiftlint:latest\n```\n\nThis will execute `swiftlint` in the folder where you are right now (`pwd`),\nshowing an output like:\n\n```bash\n$ docker run -it -v `pwd`:`pwd` -w `pwd` ghcr.io/realm/swiftlint:latest\nLinting Swift files in current working directory\nLinting 'RuleDocumentation.swift' (1/490)\n...\nLinting 'YamlSwiftLintTests.swift' (490/490)\nDone linting! Found 0 violations, 0 serious in 490 files.\n```\n\nHere you have more documentation about the usage of\n[Docker Images](https://docs.docker.com/).\n\n## Command Line Usage\n\n```txt\n$ swiftlint help\nOVERVIEW: A tool to enforce Swift style and conventions.\n\nUSAGE: swiftlint <subcommand>\n\nOPTIONS:\n  --version               Show the version.\n  -h, --help              Show help information.\n\nSUBCOMMANDS:\n  analyze                 Run analysis rules\n  docs                    Open SwiftLint documentation website in the default web browser\n  generate-docs           Generates markdown documentation for selected group of rules\n  lint (default)          Print lint warnings and errors\n  baseline                Operations on existing baselines\n  reporters               Display the list of reporters and their identifiers\n  rules                   Display the list of rules and their identifiers\n  version                 Display the current version of SwiftLint\n\n  See 'swiftlint help <subcommand>' for detailed help.\n```\n\nRun `swiftlint` in the directory containing the Swift files to lint. Directories\nwill be searched recursively.\n\nTo specify a list of files when using `lint` or `analyze`\n(like the list of files modified by Xcode specified by the\n[`ExtraBuildPhase`](https://github.com/norio-nomura/ExtraBuildPhase) Xcode\nplugin, or modified files in the working tree based on `git ls-files -m`), you\ncan do so by passing the option `--use-script-input-files` and setting the\nfollowing instance variables: `SCRIPT_INPUT_FILE_COUNT`\nand `SCRIPT_INPUT_FILE_0`, `SCRIPT_INPUT_FILE_1`, ...,\n`SCRIPT_INPUT_FILE_{SCRIPT_INPUT_FILE_COUNT - 1}`.\nSimilarly, files can be read from file lists by passing\nthe option `--use-script-input-file-lists` and setting the\nfollowing instance variables: `SCRIPT_INPUT_FILE_LIST_COUNT`\nand `SCRIPT_INPUT_FILE_LIST_0`, `SCRIPT_INPUT_FILE_LIST_1`, ...,\n`SCRIPT_INPUT_FILE_LIST_{SCRIPT_INPUT_FILE_LIST_COUNT - 1}`.\n\nThese are same environment variables set for input files to\n[custom Xcode script phases](http://indiestack.com/2014/12/speeding-up-custom-script-phases/).\n\n## Working With Multiple Swift Versions\n\nSwiftLint hooks into SourceKit so it continues working even as Swift evolves!\n\nThis also keeps SwiftLint lean, as it doesn't need to ship with a full Swift\ncompiler, it just communicates with the official one you already have installed\non your machine.\n\nYou should always run SwiftLint with the same toolchain you use to compile your\ncode.\n\nYou may want to override SwiftLint's default Swift toolchain if you have\nmultiple toolchains or Xcodes installed.\n\nHere's the order in which SwiftLint determines which Swift toolchain to use:\n\n* `$XCODE_DEFAULT_TOOLCHAIN_OVERRIDE`\n* `$TOOLCHAIN_DIR` or `$TOOLCHAINS`\n* `xcrun -find swift`\n* `/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain`\n* `/Applications/Xcode-beta.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain`\n* `~/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain`\n* `~/Applications/Xcode-beta.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain`\n\n`sourcekitd.framework` is expected to be found in the `usr/lib/` subdirectory of\nthe value passed in the paths above.\n\nYou may also set the `TOOLCHAINS` environment variable to the reverse-DNS\nnotation that identifies a Swift toolchain version:\n\n```shell\nTOOLCHAINS=com.apple.dt.toolchain.Swift_2_3 swiftlint --fix\n```\n\nOn Linux, SourceKit is expected to be located in\n`/usr/lib/libsourcekitdInProc.so` or specified by the `LINUX_SOURCEKIT_LIB_PATH`\nenvironment variable.\n\n## Git `pre-commit` Hook\n\nSwiftLint can be run as a [pre-commit](https://pre-commit.com/) hook.\nOnce [installed](https://pre-commit.com/#install), add this to the\n`.pre-commit-config.yaml` in the root of your repository:\n\n```yaml\nrepos:\n  - repo: https://github.com/realm/SwiftLint\n    rev: 0.57.1\n    hooks:\n      - id: swiftlint\n```\n\nAdjust `rev` to the SwiftLint version of your choice.  `pre-commit autoupdate`\ncan be used to update to the current version.\n\nSwiftLint can be configured using `entry` to apply fixes and fail on errors:\n\n```yaml\n- repo: https://github.com/realm/SwiftLint\n  rev: 0.57.1\n  hooks:\n    - id: swiftlint\n      entry: swiftlint --fix --strict\n```\n\n## Rules\n\nOver 200 rules are included in SwiftLint and the Swift community (that's you!)\ncontinues to contribute more over time.\n[Pull requests](https://github.com/realm/SwiftLint/blob/main/CONTRIBUTING.md)\nare encouraged.\n\nYou can find an updated list of rules and more information about them in the\n[Rule Directory](https://realm.github.io/SwiftLint/rule-directory.html).\n\nYou can also check the\n[Source/SwiftLintBuiltInRules/Rules](https://github.com/realm/SwiftLint/tree/main/Source/SwiftLintBuiltInRules/Rules)\ndirectory to see their implementation.\n\n### Opt-In Rules\n\n`opt_in_rules` are disabled by default (i.e., you have to explicitly enable them\nin your configuration file).\n\nGuidelines on when to mark a rule as opt-in:\n\n* A rule that can have many false positives (e.g. `empty_count`)\n* A rule that is too slow\n* A rule that is not general consensus or is only useful in some cases\n  (e.g. `force_unwrapping`)\n\n### Disable rules in code\n\nRules can be disabled with a comment inside a source file with the following\nformat:\n\n`// swiftlint:disable <rule1> [<rule2> <rule3>...]`\n\nThe rules will be disabled until the end of the file or until the linter sees a\nmatching enable comment:\n\n`// swiftlint:enable <rule1> [<rule2> <rule3>...]`\n\nFor example:\n\n```swift\n// swiftlint:disable colon\nlet noWarning :String = \"\" // No warning about colons immediately after variable names.\n// swiftlint:enable colon\nlet hasWarning :String = \"\" // Warning generated about colons immediately after variable names.\n```\n\nIncluding the `all` keyword will disable all rules until the linter sees a\nmatching enable comment:\n\n`// swiftlint:disable all`\n`// swiftlint:enable all`\n\nFor example:\n\n```swift\n// swiftlint:disable all\nlet noWarning :String = \"\" // No warning about colons immediately after variable names.\nlet i = \"\" // Also no warning about short identifier names.\n// swiftlint:enable all\nlet hasWarning :String = \"\" // Warning generated about colons immediately after variable names.\nlet y = \"\" // Warning generated about short identifier names.\n```\n\nIt's also possible to modify a `disable` or `enable` command by appending\n`:previous`, `:this` or `:next` for only applying the command to the previous,\nthis (current) or next line respectively.\n\nFor example:\n\n```swift\n// swiftlint:disable:next force_cast\nlet noWarning = NSNumber() as! Int\nlet hasWarning = NSNumber() as! Int\nlet noWarning2 = NSNumber() as! Int // swiftlint:disable:this force_cast\nlet noWarning3 = NSNumber() as! Int\n// swiftlint:disable:previous force_cast\n```\n\nRun `swiftlint rules` to print a list of all available rules and their\nidentifiers.\n\n### Configuration\n\nConfigure SwiftLint by adding a `.swiftlint.yml` file from the directory you'll\nrun SwiftLint from. The following parameters can be configured:\n\nRule inclusion:\n\n* `disabled_rules`: Disable rules from the default enabled set.\n* `opt_in_rules`: Enable rules that are not part of the default set. The\n   special `all` identifier will enable all opt in linter rules, except the ones\n   listed in `disabled_rules`.\n* `only_rules`: Only the rules specified in this list will be enabled.\n   Cannot be specified alongside `disabled_rules` or `opt_in_rules`.\n* `analyzer_rules`: This is an entirely separate list of rules that are only\n  run by the `analyze` command. All analyzer rules are opt-in, so this is the\n  only configurable rule list, there are no equivalents for `disabled_rules`\n  and `only_rules`. The special `all` identifier can also be used here to enable\n  all analyzer rules, except the ones listed in `disabled_rules`.\n\n```yaml\n# By default, SwiftLint uses a set of sensible default rules you can adjust. Find all the available rules\n# by running `swiftlint rules` or visiting https://realm.github.io/SwiftLint/rule-directory.html.\n\n# Rules turned on by default can be disabled.\ndisabled_rules:\n  - colon\n  - comma\n  - control_statement\n  \n# Rules turned off by default can be enabled.\nopt_in_rules:\n  - empty_count\n\n# Alternatively, specify all rules explicitly by uncommenting this option and removing the above two.\n# only_rules:\n#   - empty_parameters\n#   - vertical_whitespace\n\n# Rules only run by `swiftlint analyze`. These are all opt-in.\nanalyzer_rules:\n  - explicit_self\n\n# Case-sensitive paths to include during linting. Directory paths supplied on the\n# command line will be ignored. Wildcards are supported.\nincluded: \n  - Sources\n\n# Case-sensitive paths to ignore during linting. Takes precedence over `included`. Wildcards\n# are supported.\nexcluded: \n  - Carthage\n  - Pods\n  - Sources/ExcludedFolder\n  - Sources/ExcludedFile.swift\n  - Sources/*/ExcludedFile.swift\n\n# If true, SwiftLint will not fail if no lintable files are found.\nallow_zero_lintable_files: false\n\n# If true, SwiftLint will treat all warnings as errors.\nstrict: false\n\n# If true, SwiftLint will treat all errors as warnings.\nlenient: false\n\n# The path to a baseline file, which will be used to filter out detected violations.\nbaseline: Baseline.json\n\n# The path to save detected violations to as a new baseline.\nwrite_baseline: Baseline.json\n\n# If true, SwiftLint will check for updates after linting or analyzing.\ncheck_for_updates: true\n\n# Configurable rules can be customized. All rules support setting their severity level.\nforce_cast: warning # implicitly\nforce_try:\n  severity: warning # explicitly\n  \n# Rules that have both warning and error levels can set just the warning level implicitly.\nline_length: 110\n\n# To set both levels implicitly, use an array.\ntype_body_length:\n  - 300 # warning\n  - 400 # error\n\n# To set both levels explicitly, use a dictionary.\nfile_length:\n  warning: 500\n  error: 1200\n  \n# Naming rules can set warnings/errors for `min_length` and `max_length`. Additionally, they can\n# set excluded names and allowed symbols.\ntype_name:\n  min_length: 4 # warning\n  max_length: # warning and error\n    warning: 40\n    error: 50\n  excluded: i(Phone|Pad|Pod) # regex pattern\n  allowed_symbols: [\"_\"]\nidentifier_name:\n  min_length:\n    error: 4 # only error\n  excluded: # excluded via string array\n    - id\n    - URL\n    - GlobalAPIKey\n    \n# The default reporter (SwiftLint's output format) can be configured as `checkstyle`, `codeclimate`, `csv`,\n# `emoji`, `github-actions-logging`, `gitlab`, `html`, `json`, `junit`, `markdown`, `relative-path`, `sarif`,\n# `sonarqube`, `summary`, or `xcode` (default).\nreporter: \"xcode\"\n```\n\nYou can also use environment variables in your configuration file,\nby using `${SOME_VARIABLE}` in a string.\n\n### Defining Custom Rules\n\nIn addition to the rules that the main SwiftLint project ships with, SwiftLint\ncan also run two types of custom rules that you can define yourself in your own\nprojects:\n\n#### 1. Swift Custom Rules\n\nThese rules are written the same way as the Swift-based rules that ship with\nSwiftLint so they're fast, accurate, can leverage SwiftSyntax, can be unit\ntested, and more.\n\nUsing these requires building SwiftLint with Bazel as described in\n[this video](https://vimeo.com/820572803) or its associated code in\n[github.com/jpsim/swiftlint-bazel-example](https://github.com/jpsim/swiftlint-bazel-example).\n\n#### 2. Regex Custom Rules\n\nYou can define custom regex-based rules in your configuration file using the\nfollowing syntax:\n\n```yaml\ncustom_rules:\n  # Rule identifier.\n  pirates_beat_ninjas:\n    # Optional regex that defines paths to include during linting.\n    included:\n      - \".*\\\\.swift\"\n    # Optional regex that defines paths to exclude during linting.\n    excluded:\n      - \".*Test\\\\.swift\"\n    # Optional rule name.\n    name: \"Pirates Beat Ninjas\"\n    # Matching pattern.\n    regex: \"([nN]inja)\"\n    # Number of regex capture group to highlight the rule violation at. Optional, defaults to 0 (the whole match).\n    capture_group: 0\n    # SyntaxKinds to match. optional.\n    match_kinds:\n      - comment\n      - identifier\n    # Optional violation message.\n    message: \"Pirates are better than ninjas.\"\n    # Optional violation severity.\n    severity: error\n  no_hiding_in_strings:\n    regex: \"([nN]inja)\"\n    # Syntax kinds to match. optional.\n    match_kinds: string\n```\n\nThis is what the output would look like:\n\n![Custom violations highlighted in the Xcode editor](https://raw.githubusercontent.com/realm/SwiftLint/main/assets/custom-rule.png)\n\nIt is important to note that the regular expression pattern is used with the\nflags `s` and `m` enabled, that is `.`\n[matches newlines](https://developer.apple.com/documentation/foundation/nsregularexpression/options/1412529-dotmatcheslineseparators)\nand `^`/`$`\n[match the start and end of lines](https://developer.apple.com/documentation/foundation/nsregularexpression/options/1408263-anchorsmatchlines),\nrespectively. If you do not want to have `.` match newlines, for example, the\nregex can be prepended by `(?-s)`.\n\nYou can filter the matches by providing one or more `match_kinds`, which will\nreject matches that include syntax kinds that are not present in this list. Here\nare all the possible syntax kinds:\n\n* `argument`\n* `attribute.builtin`\n* `attribute.id`\n* `buildconfig.id`\n* `buildconfig.keyword`\n* `comment`\n* `comment.mark`\n* `comment.url`\n* `doccomment`\n* `doccomment.field`\n* `identifier`\n* `keyword`\n* `number`\n* `objectliteral`\n* `parameter`\n* `placeholder`\n* `string`\n* `string_interpolation_anchor`\n* `typeidentifier`\n\nAll syntax kinds used in a snippet of Swift code can be extracted asking\n[SourceKitten](https://github.com/jpsim/SourceKitten). For example,\n`sourcekitten syntax --text \"struct S {}\"` delivers\n\n* `source.lang.swift.syntaxtype.keyword` for the `struct` keyword and\n* `source.lang.swift.syntaxtype.identifier` for its name `S`\n\nwhich match to `keyword` and `identifier` in the above list.\n\nIf using custom rules in combination with `only_rules`, you must include the\nliteral string `custom_rules` in the `only_rules` list:\n\n```yaml\nonly_rules:\n  - custom_rules\n\ncustom_rules:\n  no_hiding_in_strings:\n    regex: \"([nN]inja)\"\n    match_kinds: string\n```\n\nUnlike Swift custom rules, you can use official SwiftLint builds\n(e.g. from Homebrew) to run regex custom rules.\n\n### Auto-correct\n\nSwiftLint can automatically correct certain violations. Files on disk are\noverwritten with a corrected version.\n\nPlease make sure to have backups of these files before running\n`swiftlint --fix`, otherwise important data may be lost.\n\nStandard linting is disabled while correcting because of the high likelihood of\nviolations (or their offsets) being incorrect after modifying a file while\napplying corrections.\n\n### Analyze\n\nThe `swiftlint analyze` command can lint Swift files using the\nfull type-checked AST. The compiler log path containing the clean `swiftc` build\ncommand invocation (incremental builds will fail) must be passed to `analyze`\nvia the `--compiler-log-path` flag.\ne.g. `--compiler-log-path /path/to/xcodebuild.log`\n\nThis can be obtained by\n\n1. Cleaning DerivedData (incremental builds won't work with analyze)\n2. Running `xcodebuild -workspace {WORKSPACE}.xcworkspace -scheme {SCHEME} > xcodebuild.log`\n3. Running `swiftlint analyze --compiler-log-path xcodebuild.log`\n\nAnalyzer rules tend to be considerably slower than lint rules.\n\n## Using Multiple Configuration Files\n\nSwiftLint offers a variety of ways to include multiple configuration files.\nMultiple configuration files get merged into one single configuration that is\nthen applied just as a single configuration file would get applied.\n\nThere are quite a lot of use cases where using multiple configuration files\ncould be helpful:\n\nFor instance, one could use a team-wide shared SwiftLint configuration while\nallowing overrides in each project via a child configuration file.\n\nTeam-Wide Configuration:\n\n```yaml\ndisabled_rules:\n  - force_cast\n```\n\nProject-Specific Configuration:\n\n```yaml\nopt_in_rules:\n  - force_cast\n```\n\n### Child/Parent Configs (Locally)\n\nYou can specify a `child_config` and/or a `parent_config` reference within a\nconfiguration file. These references should be local paths relative to the\nfolder of the configuration file they are specified in. This even works\nrecursively, as long as there are no cycles and no ambiguities.\n\n**A child config is treated as a refinement and thus has a higher priority**,\nwhile a parent config is considered a base with lower priority in case of\nconflicts.\n\nHere's an example, assuming you have the following file structure:\n\n```txt\nProjectRoot\n    |_ .swiftlint.yml\n    |_ .swiftlint_refinement.yml\n    |_ Base\n        |_ .swiftlint_base.yml\n```\n\nTo include both the refinement and the base file, your `.swiftlint.yml` should\nlook like this:\n\n```yaml\nchild_config: .swiftlint_refinement.yml\nparent_config: Base/.swiftlint_base.yml\n```\n\nWhen merging parent and child configs, `included` and `excluded` configurations\nare processed carefully to account for differences in the directory location\nof the containing configuration files.\n\n### Child/Parent Configs (Remote)\n\nJust as you can provide local `child_config`/`parent_config` references,\ninstead of referencing local paths, you can just put urls that lead to\nconfiguration files. In order for SwiftLint to detect these remote references,\nthey must start with `http://` or `https://`.\n\nThe referenced remote configuration files may even recursively reference other\nremote configuration files, but aren't allowed to include local references.\n\nUsing a remote reference, your `.swiftlint.yml` could look like this:\n\n```yaml\nparent_config: https://myteamserver.com/our-base-swiftlint-config.yml\n```\n\nEvery time you run SwiftLint and have an Internet connection, SwiftLint tries\nto get a new version of every remote configuration that is referenced. If this\nrequest times out, a cached version is used if available. If there is no cached\nversion available, SwiftLint fails â€“ but no worries, a cached version should be\nthere once SwiftLint has run successfully at least once.\n\nIf needed, the timeouts for the remote configuration fetching can be specified\nmanually via the configuration file(s) using the\n`remote_timeout`/`remote_timeout_if_cached` specifiers. These values default\nto 2 seconds or 1 second, respectively.\n\n### Command Line\n\nInstead of just providing one configuration file when running SwiftLint via the\ncommand line, you can also pass a hierarchy, where the first configuration is\ntreated as a parent, while the last one is treated as the highest-priority\nchild.\n\nA simple example including just two configuration files looks like this:\n\n`swiftlint --config .swiftlint.yml --config .swiftlint_child.yml`\n\n### Nested Configurations\n\nIn addition to a main configuration (the `.swiftlint.yml` file in the root\nfolder), you can put other configuration files named `.swiftlint.yml` into the\ndirectory structure that then get merged as a child config, but only with an\neffect for those files that are within the same directory as the config or in a\ndeeper directory where there isn't another configuration file. In other words:\nNested configurations don't work recursively â€“ there's a maximum number of one\nnested configuration per file that may be applied in addition to the main\nconfiguration.\n\n`.swiftlint.yml` files are only considered as a nested configuration if they\nhave not been used to build the main configuration already (e. g. by having\nbeen referenced via something like `child_config: Folder/.swiftlint.yml`).\nAlso, `parent_config`/`child_config` specifications of nested configurations\nare getting ignored because there's no sense to that.\n\nIf one (or more) SwiftLint file(s) are explicitly specified via the `--config`\nparameter, that configuration will be treated as an override, no matter whether\nthere exist other `.swiftlint.yml` files somewhere within the directory.\n**So if you want to use nested configurations, you can't use the `--config`\nparameter.**\n\n## License\n\n[MIT licensed.](https://github.com/realm/SwiftLint/blob/main/LICENSE)\n\n## About\n\nSwiftLint is utterly maintained by volunteers contributing to its success\nentirely in their free time. As such, SwiftLint isn't a commercial product\nin any way.\n\nBe kind to the people maintaining SwiftLint as a hobby and accept that their\ntime is limited. Support them by contributing to the project, reporting issues,\nand helping others in the community.\n\nSpecial thanks go to [MacStadium](https://www.macstadium.com) for providing\nphysical Mac mini machines to run our performance tests.\n\n![MacStadium](https://raw.githubusercontent.com/realm/SwiftLint/main/assets/macstadium.png)\n\nWe also thank Realm (now MongoDB) for their initial contributions and setup of\nthe project.\n",
      "stars_today": 3
    },
    {
      "id": 99919302,
      "name": "doris",
      "full_name": "apache/doris",
      "description": "Apache Doris is an easy-to-use, high performance and unified analytics database.",
      "html_url": "https://github.com/apache/doris",
      "stars": 14993,
      "forks": 3704,
      "language": "Java",
      "topics": [
        "agent",
        "ai",
        "bigquery",
        "database",
        "dbt",
        "delta-lake",
        "elt",
        "hudi",
        "iceberg",
        "lakehouse",
        "olap",
        "paimon",
        "query-engine",
        "real-time",
        "redshift",
        "snowflake",
        "spark",
        "sql"
      ],
      "created_at": "2017-08-10T12:13:30Z",
      "updated_at": "2026-02-06T20:58:04Z",
      "pushed_at": "2026-02-06T19:48:13Z",
      "open_issues": 787,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "<!--\nLicensed to the Apache Software Foundation (ASF) under one\nor more contributor license agreements.  See the NOTICE file\ndistributed with this work for additional information\nregarding copyright ownership.  The ASF licenses this file\nto you under the Apache License, Version 2.0 (the\n\"License\"); you may not use this file except in compliance\nwith the License.  You may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing,\nsoftware distributed under the License is distributed on an\n\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\nKIND, either express or implied.  See the License for the\nspecific language governing permissions and limitations\nunder the License.\n-->\n\n## ğŸŒ Read this in other languages\n\n[English](README.md) â€¢ [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](docs/ar-SA/README.md) â€¢ [à¦¬à¦¾à¦‚à¦²à¦¾](docs/bn-BD/README.md) â€¢ [Deutsch](docs/de-DE/README.md) â€¢ [EspaÃ±ol](docs/es-ES/README.md) â€¢ [ÙØ§Ø±Ø³ÛŒ](docs/fa-IR/README.md) â€¢ [FranÃ§ais](docs/fr-FR/README.md) â€¢ [à¤¹à¤¿à¤¨à¥à¤¦à¥€](docs/hi-IN/README.md) â€¢ [Bahasa Indonesia](docs/id-ID/README.md) â€¢ [Italiano](docs/it-IT/README.md) â€¢ [æ—¥æœ¬èª](docs/ja-JP/README.md) â€¢ [í•œêµ­ì–´](docs/ko-KR/README.md) â€¢ [Polski](docs/pl-PL/README.md) â€¢ [PortuguÃªs](docs/pt-BR/README.md) â€¢ [RomÃ¢nÄƒ](docs/ro-RO/README.md) â€¢ [Ğ ÑƒÑÑĞºĞ¸Ğ¹](docs/ru-RU/README.md) â€¢ [SlovenÅ¡Äina](docs/sl-SI/README.md) â€¢ [à¹„à¸—à¸¢](docs/th-TH/README.md) â€¢ [TÃ¼rkÃ§e](docs/tr-TR/README.md) â€¢ [Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°](docs/uk-UA/README.md) â€¢ [Tiáº¿ng Viá»‡t](docs/vi-VN/README.md) â€¢ [ç®€ä½“ä¸­æ–‡](docs/zh-CN/README.md) â€¢ [ç¹é«”ä¸­æ–‡](docs/zh-TW/README.md)\n\n<div align=\"center\">\n\n# Apache Doris\n\n[![License](https://img.shields.io/badge/license-Apache%202-4EB1BA.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)\n[![GitHub release](https://img.shields.io/github/release/apache/doris.svg)](https://github.com/apache/doris/releases)\n[![OSSRank](https://shields.io/endpoint?url=https://ossrank.com/shield/516)](https://ossrank.com/p/516)\n[![Commit activity](https://img.shields.io/github/commit-activity/m/apache/doris)](https://github.com/apache/doris/commits/master/)\n[![EN doc](https://img.shields.io/badge/Docs-English-blue.svg)](https://doris.apache.org/docs/gettingStarted/what-is-apache-doris)\n[![CN doc](https://img.shields.io/badge/æ–‡æ¡£-ä¸­æ–‡ç‰ˆ-blue.svg)](https://doris.apache.org/zh-CN/docs/gettingStarted/what-is-apache-doris)\n\n<div>\n\n[![Official Website](<https://img.shields.io/badge/-Visit%20the%20Official%20Website%20%E2%86%92-rgb(15,214,106)?style=for-the-badge>)](https://doris.apache.org/)\n[![Quick Download](<https://img.shields.io/badge/-Quick%20%20Download%20%E2%86%92-rgb(66,56,255)?style=for-the-badge>)](https://doris.apache.org/download)\n\n\n</div>\n\n\n<div>\n    <a href=\"https://twitter.com/doris_apache\"><img src=\"https://img.shields.io/badge/- @Doris_Apache -424549?style=social&logo=x\" height=25></a>\n    &nbsp;\n    <a href=\"https://github.com/apache/doris/discussions\"><img src=\"https://img.shields.io/badge/- Discussion -red?style=social&logo=discourse\" height=25></a>\n    &nbsp;\n    <a href=\"https://doris.apache.org/slack\" height=25></a>\n    &nbsp;\n    <a href=\"https://medium.com/@ApacheDoris\"><img src=\"https://img.shields.io/badge/-Medium-red?style=social&logo=medium\" height=25></a>\n\n</div>\n\n</div>\n\n---\n\n<p align=\"center\">\n\n  <a href=\"https://trendshift.io/repositories/1156\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/1156\" alt=\"apache%2Fdoris | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\n</p>\n\n\n\n\nApache Doris is an easy-to-use, high-performance and real-time analytical database based on MPP architecture, known for its extreme speed and ease of use. It only requires a sub-second response time to return query results under massive data and can support not only high-concurrency point query scenarios but also high-throughput complex analysis scenarios.\n\nAll this makes Apache Doris an ideal tool for scenarios including report analysis, ad-hoc query, unified data warehouse, and data lake query acceleration. On Apache Doris, users can build various applications, such as user behavior analysis, AB test platform, log retrieval analysis, user portrait analysis, and order analysis.\n\nğŸ‰ Check out the ğŸ”—[All releases](https://doris.apache.org/docs/releasenotes/all-release), where you'll find a chronological summary of Apache Doris versions released over the past year.\n\nğŸ‘€ Explore the ğŸ”—[Official Website](https://doris.apache.org/) to discover Apache Doris's core features, blogs, and user cases in detail.\n\n## ğŸ“ˆ Usage Scenarios\n\nAs shown in the figure below, after various data integration and processing, the data sources are usually stored in the real-time data warehouse Apache Doris and the offline data lake or data warehouse (in Apache Hive, Apache Iceberg or Apache Hudi).\n\n<br />\n\n<img src=\"https://cdn.selectdb.com/static/What_is_Apache_Doris_3_a61692c2ce.png\" />\n\n<br />\n\n\nApache Doris is widely used in the following scenarios:\n\n- **Real-time Data Analysis**:\n\n  - **Real-time Reporting and Decision-making**: Doris provides real-time updated reports and dashboards for both internal and external enterprise use, supporting real-time decision-making in automated processes.\n  \n  - **Ad Hoc Analysis**: Doris offers multidimensional data analysis capabilities, enabling rapid business intelligence analysis and ad hoc queries to help users quickly uncover insights from complex data.\n  \n  - **User Profiling and Behavior Analysis**: Doris can analyze user behaviors such as participation, retention, and conversion, while also supporting scenarios like population insights and crowd selection for behavior analysis.\n\n- **Lakehouse Analytics**:\n\n  - **Lakehouse Query Acceleration**: Doris accelerates lakehouse data queries with its efficient query engine.\n  \n  - **Federated Analytics**: Doris supports federated queries across multiple data sources, simplifying architecture and eliminating data silos.\n  \n  - **Real-time Data Processing**: Doris combines real-time data streams and batch data processing capabilities to meet the needs of high concurrency and low-latency complex business requirements.\n\n- **SQL-based Observability**:\n\n  - **Log and Event Analysis**: Doris enables real-time or batch analysis of logs and events in distributed systems, helping to identify issues and optimize performance.\n\n\n## Overall Architecture\n\nApache Doris uses the MySQL protocol, is highly compatible with MySQL syntax, and supports standard SQL. Users can access Apache Doris through various client tools, and it seamlessly integrates with BI tools.\n\n### Storage-Compute Integrated Architecture\n\nThe storage-compute integrated architecture of Apache Doris is streamlined and easy to maintain. As shown in the figure below, it consists of only two types of processes:\n\n- **Frontend (FE):** Primarily responsible for handling user requests, query parsing and planning, metadata management, and node management tasks.\n\n- **Backend (BE):** Primarily responsible for data storage and query execution. Data is partitioned into shards and stored with multiple replicas across BE nodes.\n\n![The overall architecture of Apache Doris](https://cdn.selectdb.com/static/What_is_Apache_Doris_adb26397e2.png)\n\n<br />\n\nIn a production environment, multiple FE nodes can be deployed for disaster recovery. Each FE node maintains a full copy of the metadata. The FE nodes are divided into three roles:\n\n| Role      | Function                                                     |\n| --------- | ------------------------------------------------------------ |\n| Master    | The FE Master node is responsible for metadata read and write operations. When metadata changes occur in the Master, they are synchronized to Follower or Observer nodes via the BDB JE protocol. |\n| Follower  | The Follower node is responsible for reading metadata. If the Master node fails, a Follower node can be selected as the new Master. |\n| Observer  | The Observer node is responsible for reading metadata and is mainly used to increase query concurrency. It does not participate in cluster leadership elections. |\n\nBoth FE and BE processes are horizontally scalable, enabling a single cluster to support hundreds of machines and tens of petabytes of storage capacity. The FE and BE processes use a consistency protocol to ensure high availability of services and high reliability of data. The storage-compute integrated architecture is highly integrated, significantly reducing the operational complexity of distributed systems.\n\n\n## Core Features of Apache Doris\n\n- **High Availability**: In Apache Doris, both metadata and data are stored with multiple replicas, synchronizing data logs via the quorum protocol. Data write is considered successful once a majority of replicas have completed the write, ensuring that the cluster remains available even if a few nodes fail. Apache Doris supports both same-city and cross-region disaster recovery, enabling dual-cluster master-slave modes. When some nodes experience failures, the cluster can automatically isolate the faulty nodes, preventing the overall cluster availability from being affected.\n\n- **High Compatibility**: Apache Doris is highly compatible with the MySQL protocol and supports standard SQL syntax, covering most MySQL and Hive functions. This high compatibility allows users to seamlessly migrate and integrate existing applications and tools. Apache Doris supports the MySQL ecosystem, enabling users to connect Doris using MySQL Client tools for more convenient operations and maintenance. It also supports MySQL protocol compatibility for BI reporting tools and data transmission tools, ensuring efficiency and stability in data analysis and data transmission processes.\n\n- **Real-Time Data Warehouse**: Based on Apache Doris, a real-time data warehouse service can be built. Apache Doris offers second-level data ingestion capabilities, capturing incremental changes from upstream online transactional databases into Doris within seconds. Leveraging vectorized engines, MPP architecture, and Pipeline execution engines, Doris provides sub-second data query capabilities, thereby constructing a high-performance, low-latency real-time data warehouse platform.\n\n- **Unified Lakehouse**: Apache Doris can build a unified lakehouse architecture based on external data sources such as data lakes or relational databases. The Doris unified lakehouse solution enables seamless integration and free data flow between data lakes and data warehouses, helping users directly utilize data warehouse capabilities to solve data analysis problems in data lakes while fully leveraging data lake data management capabilities to enhance data value.\n\n- **Flexible Modeling**: Apache Doris offers various modeling approaches, such as wide table models, pre-aggregation models, star/snowflake schemas, etc. During data import, data can be flattened into wide tables and written into Doris through compute engines like Flink or Spark, or data can be directly imported into Doris, performing data modeling operations through views, materialized views, or real-time multi-table joins.\n\n## Technical overview\n\nDoris provides an efficient SQL interface and is fully compatible with the MySQL protocol. Its query engine is based on an MPP (Massively Parallel Processing) architecture, capable of efficiently executing complex analytical queries and achieving low-latency real-time queries. Through columnar storage technology for data encoding and compression, it significantly optimizes query performance and storage compression ratio.\n\n### Interface\n\nApache Doris adopts the MySQL protocol, supports standard SQL, and is highly compatible with MySQL syntax. Users can access Apache Doris through various client tools and seamlessly integrate it with BI tools, including but not limited to Smartbi, DataEase, FineBI, Tableau, Power BI, and Apache Superset. Apache Doris can work as the data source for any BI tools that support the MySQL protocol.\n\n### Storage engine\n\nApache Doris has a columnar storage engine, which encodes, compresses, and reads data by column. This enables a very high data compression ratio and largely reduces unnecessary data scanning, thus making more efficient use of IO and CPU resources.\n\nApache Doris supports various index structures to minimize data scans:\n\n- **Sorted Compound Key Index**: Users can specify three columns at most to form a compound sort key. This can effectively prune data to better support highly concurrent reporting scenarios.\n\n- **Min/Max Index**: This enables effective data filtering in equivalence and range queries of numeric types.\n\n- **BloomFilter Index**: This is very effective in equivalence filtering and pruning of high-cardinality columns.\n\n- **Inverted Index**: This enables fast searching for any field.\n\nApache Doris supports a variety of data models and has optimized them for different scenarios:\n\n- **Detail Model (Duplicate Key Model):** A detail data model designed to meet the detailed storage requirements of fact tables.\n\n- **Primary Key Model (Unique Key Model):** Ensures unique keys; data with the same key is overwritten, enabling row-level data updates.\n\n- **Aggregate Model (Aggregate Key Model):** Merges value columns with the same key, significantly improving performance through pre-aggregation.\n\nApache Doris also supports strongly consistent single-table materialized views and asynchronously refreshed multi-table materialized views. Single-table materialized views are automatically refreshed and maintained by the system, requiring no manual intervention from users. Multi-table materialized views can be refreshed periodically using in-cluster scheduling or external scheduling tools, reducing the complexity of data modeling.\n\n### ğŸ” Query Engine\n\nApache Doris has an MPP-based query engine for parallel execution between and within nodes. It supports distributed shuffle join for large tables to better handle complicated queries.\n\n<br />\n\n![Query Engine](https://cdn.selectdb.com/static/What_is_Apache_Doris_1_c6f5ba2af9.png)\n\n<br />\n\nThe query engine of Apache Doris is fully vectorized, with all memory structures laid out in a columnar format. This can largely reduce virtual function calls, increase cache hit rates, and make efficient use of SIMD instructions. Apache Doris delivers a 5~10 times higher performance in wide table aggregation scenarios than non-vectorized engines.\n\n<br />\n\n![Doris query engine](https://cdn.selectdb.com/static/What_is_Apache_Doris_2_29cf58cc6b.png)\n\n<br />\n\nApache Doris uses adaptive query execution technology to dynamically adjust the execution plan based on runtime statistics. For example, it can generate a runtime filter and push it to the probe side. Specifically, it pushes the filters to the lowest-level scan node on the probe side, which largely reduces the data amount to be processed and increases join performance. The runtime filter of Apache Doris supports In/Min/Max/Bloom Filter.\n\nApache Doris uses a Pipeline execution engine that breaks down queries into multiple sub-tasks for parallel execution, fully leveraging multi-core CPU capabilities. It simultaneously addresses the thread explosion problem by limiting the number of query threads. The Pipeline execution engine reduces data copying and sharing, optimizes sorting and aggregation operations, thereby significantly improving query efficiency and throughput.\n\nIn terms of the optimizer, Apache Doris employs a combined optimization strategy of CBO (Cost-Based Optimizer), RBO (Rule-Based Optimizer), and HBO (History-Based Optimizer). RBO supports constant folding, subquery rewriting, predicate pushdown, and more. CBO supports join reordering and other optimizations. HBO recommends the optimal execution plan based on historical query information. These multiple optimization measures ensure that Doris can enumerate high-performance query plans across various types of queries.\n\n\n## ğŸ† Why choose Apache Doris?\n\n- ğŸ¯ **Easy to Use:** Two processes, no other dependencies; online cluster scaling, automatic replica recovery; compatible with MySQL protocol, and using standard SQL.\n\n- ğŸš€ **High Performance:** Extremely fast performance for low-latency and high-throughput queries with columnar storage engine, modern MPP architecture, vectorized query engine, pre-aggregated materialized view and data index.\n\n- ğŸ–¥ï¸ **Single Unified:** A single system can support real-time data serving, interactive data analysis and offline data processing scenarios.\n\n- âš›ï¸ **Federated Querying:** Supports federated querying of data lakes such as Hive, Iceberg, Hudi, and databases such as MySQL and Elasticsearch.\n\n- â© **Various Data Import Methods:** Supports batch import from HDFS/S3 and stream import from MySQL Binlog/Kafka; supports micro-batch writing through HTTP interface and real-time writing using Insert in JDBC.\n\n- ğŸš™ **Rich Ecology:** Spark uses Spark-Doris-Connector to read and write Doris; Flink-Doris-Connector enables Flink CDC to implement exactly-once data writing to Doris; DBT Doris Adapter is provided to transform data in Doris with DBT.\n\n## ğŸ™Œ Contributors\n\n**Apache Doris has graduated from Apache incubator successfully and become a Top-Level Project in June 2022**. \n\nWe deeply appreciate ğŸ”—[community contributors](https://github.com/apache/doris/graphs/contributors) for their contribution to Apache Doris.\n\n[![contrib graph](https://contrib.rocks/image?repo=apache/doris)](https://github.com/apache/doris/graphs/contributors)\n\n## ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Users\n\nApache Doris now has a wide user base in China and around the world, and as of today, **Apache Doris is used in production environments in thousands of companies worldwide.** More than 80% of the top 50 Internet companies in China in terms of market capitalization or valuation have been using Apache Doris for a long time, including Baidu, Meituan, Xiaomi, Jingdong, Bytedance, Tencent, NetEase, Kwai, Sina, 360, Mihoyo, and Ke Holdings. It is also widely used in some traditional industries such as finance, energy, manufacturing, and telecommunications.\n\nThe users of Apache Doris: ğŸ”—[Users](https://doris.apache.org/users)\n\nAdd your company logo at Apache Doris Website: ğŸ”—[Add Your Company](https://github.com/apache/doris/discussions/27683)\n \n## ğŸ‘£ Get Started\n\n### ğŸ“š Docs\n\nAll Documentation   ğŸ”—[Docs](https://doris.apache.org/docs/gettingStarted/what-is-apache-doris)  \n\n### â¬‡ï¸ Download \n\nAll release and binary version ğŸ”—[Download](https://doris.apache.org/download) \n\n### ğŸ—„ï¸ Compile\n\nSee how to compile  ğŸ”—[Compilation](https://doris.apache.org/community/source-install/compilation-with-docker))\n\n### ğŸ“® Install\n\nSee how to install and deploy ğŸ”—[Installation and deployment](https://doris.apache.org/docs/install/preparation/env-checking) \n\n## ğŸ§© Components\n\n### ğŸ“ Doris Connector\n\nDoris provides support for Spark/Flink to read data stored in Doris through Connector, and also supports to write data to Doris through Connector.\n\nğŸ”—[apache/doris-flink-connector](https://github.com/apache/doris-flink-connector)\n\nğŸ”—[apache/doris-spark-connector](https://github.com/apache/doris-spark-connector)\n\n\n## ğŸŒˆ Community and Support\n\n### ğŸ“¤ Subscribe Mailing Lists\n\nMail List is the most recognized form of communication in Apache community. See how to ğŸ”—[Subscribe Mailing Lists](https://doris.apache.org/community/subscribe-mail-list)\n\n### ğŸ™‹ Report Issues or Submit Pull Request\n\nIf you meet any questions, feel free to file a ğŸ”—[GitHub Issue](https://github.com/apache/doris/issues) or post it in ğŸ”—[GitHub Discussion](https://github.com/apache/doris/discussions) and fix it by submitting a ğŸ”—[Pull Request](https://github.com/apache/doris/pulls) \n\n### ğŸ» How to Contribute\n\nWe welcome your suggestions, comments (including criticisms), comments and contributions. See ğŸ”—[How to Contribute](https://doris.apache.org/community/how-to-contribute/) and ğŸ”—[Code Submission Guide](https://doris.apache.org/community/how-to-contribute/pull-request/)\n\n### âŒ¨ï¸ Doris Improvement Proposals (DSIP)\n\nğŸ”—[Doris Improvement Proposal (DSIP)](https://cwiki.apache.org/confluence/display/DORIS/Doris+Improvement+Proposals) can be thought of as **A Collection of Design Documents for all Major Feature Updates or Improvements**.\n\n### ğŸ”‘ Backend C++ Coding Specification\nğŸ”— [Backend C++ Coding Specification](https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=240883637) should be strictly followed, which will help us achieve better code quality.\n\n## ğŸ’¬ Contact Us\n\nContact us through the following mailing list.\n\n| Name                                                                          | Scope                           |                                                                 |                                                                     |                                                                              |\n|:------------------------------------------------------------------------------|:--------------------------------|:----------------------------------------------------------------|:--------------------------------------------------------------------|:-----------------------------------------------------------------------------|\n| [dev@doris.apache.org](mailto:dev@doris.apache.org)     | Development-related discussions | [Subscribe](mailto:dev-subscribe@doris.apache.org)   | [Unsubscribe](mailto:dev-unsubscribe@doris.apache.org)   | [Archives](http://mail-archives.apache.org/mod_mbox/doris-dev/)   |\n\n## ğŸ§° Links\n\n* Apache Doris Official Website - [Site](https://doris.apache.org)\n* Developer Mailing list - <dev@doris.apache.org>. Mail to <dev-subscribe@doris.apache.org>, follow the reply to subscribe the mail list.\n* Slack channel - [Join the Slack](https://doris.apache.org/slack)\n* Twitter - [Follow @doris_apache](https://twitter.com/doris_apache)\n\n\n## ğŸ“œ License\n\n[Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0)\n\n> **Note**\n> Some licenses of the third-party dependencies are not compatible with Apache 2.0 License. So you need to disable\nsome Doris features to be complied with Apache 2.0 License. For details, refer to the `thirdparty/LICENSE.txt`\n\n\n\n",
      "stars_today": 3
    },
    {
      "id": 7408108,
      "name": "rt-thread",
      "full_name": "RT-Thread/rt-thread",
      "description": "RT-Thread is an open source IoT Real-Time Operating System (RTOS).                                                                                                https://rt-thread.github.io/rt-thread/",
      "html_url": "https://github.com/RT-Thread/rt-thread",
      "stars": 11766,
      "forks": 5344,
      "language": "C",
      "topics": [
        "aiot",
        "arm",
        "cortex-a",
        "cortex-m",
        "embedded-systems",
        "iot",
        "kernel",
        "microcontroller",
        "microkernel",
        "mips",
        "real-time",
        "risc-v",
        "rtos"
      ],
      "created_at": "2013-01-02T14:49:21Z",
      "updated_at": "2026-02-06T19:53:50Z",
      "pushed_at": "2026-02-06T13:07:48Z",
      "open_issues": 416,
      "owner": {
        "login": "RT-Thread",
        "avatar_url": "https://avatars.githubusercontent.com/u/1783729?v=4"
      },
      "readme": "<p align=\"center\">\n<img src=\"documentation/figures/logo.png\" width=\"60%\" >\n</p>\n\n**English** | [ä¸­æ–‡](README_zh.md) | [EspaÃ±ol](README_es.md) | [Deutsch](README_de.md)\n\n[![GitHubStars](https://img.shields.io/github/stars/RT-Thread/rt-thread?style=flat-square&logo=GitHub)](https://github.com/RT-Thread/rt-thread/stargazers)\n[![GiteeStars](https://gitee.com/rtthread/rt-thread/badge/star.svg?theme=gvp)](https://gitee.com/rtthread/rt-thread/stargazers)\n[![GitHub](https://img.shields.io/github/license/RT-Thread/rt-thread.svg)](https://github.com/RT-Thread/rt-thread/blob/master/LICENSE)\n[![GitHub release](https://img.shields.io/github/release/RT-Thread/rt-thread.svg)](https://github.com/RT-Thread/rt-thread/releases)\n[![Gitter](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/RT-Thread/rt-thread?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n[![GitHub pull-requests](https://img.shields.io/github/issues-pr/RT-Thread/rt-thread.svg)](https://github.com/RT-Thread/rt-thread/pulls)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat)](https://github.com/RT-Thread/rt-thread/pulls)\n[![RT-Thread BSP Static Build Check](https://github.com/RT-Thread/rt-thread/actions/workflows/bsp_buildings.yml/badge.svg)](https://github.com/RT-Thread/rt-thread/actions/workflows/bsp_buildings.yml)\n<a href=\"https://hellogithub.com/repository/5816fc3c1e714d109631ceb377538ca9\" target=\"_blank\"><img src=\"https://api.hellogithub.com/v1/widgets/recommend.svg?rid=5816fc3c1e714d109631ceb377538ca9&claim_uid=kVCe5FXIMGAjJfy\" alt=\"Featuredï½œHelloGitHub\" style=\"width: 100px; height: 20px;\" width=\"250\" height=\"54\" /></a>\n# RT-Thread\n\nRT-Thread was born in 2006, it is an open source, neutral, and community-based real-time operating system (RTOS).\n\nRT-Thread is mainly written in C language, easy to understand and easy to port(can be quickly port to a wide range of mainstream MCUs and module chips). It applies object-oriented programming methods to real-time system design, making the code elegant, structured, modular, and very tailorable.\n\nRT-Thread has Standard version and Nano version. For resource-constrained microcontroller (MCU) systems, the Nano version that requires only 3KB Flash and 1.2KB RAM memory resources can be tailored with easy-to-use tools. For resource-rich IoT devices, RT-Thread can use the on-line software package management tool, together with system configuration tools, to achieve intuitive and rapid modular cutting, seamlessly import rich software packages; thus, achieving complex functions like Android's graphical interface and touch sliding effects, smart voice interaction effects, and so on.\n\n## RT-Thread Architecture\n\nRT-Thread has not only a real-time kernel, but also rich components. Its architecture is as follows:\n\n\n![architecture](./documentation/figures/architecture.png)\n\n\nIt includes:\n\n- Kernel layer: RT-Thread kernel, the core part of RT-Thread, includes the implementation of objects in the kernel system, such as multi-threading and its scheduling, semaphore, mailbox, message queue, memory management, timer, etc.; libcpu/BSP (Chip Migration Related Files/Board Support Package) is closely related to hardware and consists of peripheral drivers and CPU porting.\n\n- Components and Service Layer: Components are based on upper-level software on top of the RT-Thread kernel, such as virtual file systems, FinSH command-line interfaces, network frameworks, device frameworks, and more. Its modular design allows for high internal cohesion inside the components and low coupling between components.\n\n- [RT-Thread software package](https://packages.rt-thread.org/en/index.html): A general-purpose software component running on the RT-Thread IoT operating system platform for different application areas, consisting of description information, source code or library files. RT-Thread provides an open package platform with officially available or developer-supplied packages that provide developers with a choice of reusable packages that are an important part of the RT-Thread ecosystem. The package ecosystem is critical to the choice of an operating system because these packages are highly reusable and modular, making it easy for application developers to build the system they want in the shortest amount of time. RT-Thread supports 450+ software packages.\n\n## RT-Thread Features\n\n- Designed for resource-constrained devices, the minimum kernel requires only 1.2KB of RAM and 3 KB of Flash.\n- A variety of standard interfaces, such as POSIX, CMSIS, C++ application environment.\n- Has rich components and a prosperous and fast growing package ecosystem.\n- Elegant code style, easy to use, read and master.\n- High Scalability. RT-Thread has high-quality scalable software architecture, loose coupling, modularity, is easy to tailor and expand.\n- Supports high-performance applications.\n- Supports all mainstream compiling tools such as GCC, Keil and IAR.\n- Supports a wide range of <a href=\"https://www.rt-thread.io/board.html\">architectures and chips</a>.\n\n## Code Catalogue\n\n   RT-Thread source code catalog is shown as follow:\n\n| Name          | Description                                             |\n| ------------- | ------------------------------------------------------- |\n| bsp        | Board Support Package based on the porting of various development boards |\n| components    | Components, such as finsh shell, file system, protocol stack etc. |\n| documentation | Related documents, like coding style, doxygen etc.        |\n| examples      | Related sample code                                     |\n| include       | Head files of RT-Thread kernel                           |\n| libcpu        | CPU porting code such as ARM/MIPS/RISC-V etc. |\n| src           | The source files for the RT-Thread kernel. |\n| tools         | The script files for the RT-Thread command build tool. |\n\nRT-Thread has now been ported for nearly 200 development boards, most BSPs support MDK, IAR development environment and GCC compiler, and have provided default MDK and IAR project, which allows users to add their own application code directly based on the project. Each BSP has a similar directory structure, and most BSPs provide a README.md file, which is a markdown-format file that contains the basic introduction of BSP, and introduces how to simply start using BSP.\n\n# Resources\n\n## Supported Architectures\n\nRT-Thread supports many architectures, and has covered the major architectures in current applications. Architecture and chip manufacturer involved:\n\n- **ARM Cortex-M0/M0+**ï¼šmanufacturers like ST\n- **ARM Cortex-M3**ï¼šmanufacturers like STã€Winner Microã€MindMotion, ect.\n- **ARM Cortex-M4**ï¼šmanufacturers like STã€Infineonã€Nuvotonã€NXPã€[Nordic](https://github.com/RT-Thread/rt-thread/tree/master/bsp/nrf5x)ã€GigaDeviceã€Realtekã€Ambiq Micro, ect.\n- **ARM Cortex-M7**ï¼šmanufacturers like STã€NXP\n- **ARM Cortex-M23**ï¼šmanufacturers like GigaDevice\n- **ARM Cortex-M33**ï¼šmanufacturers like ST\n- **ARM Cortex-R4**\n- **ARM Cortex-A8/A9**ï¼šmanufacturers like NXP\n- **ARM7**ï¼šmanufacturers like Samsung\n- **ARM9**ï¼šmanufacturers like Allwinnerã€Xilinx ã€GOKE\n- **ARM11**ï¼šmanufacturers like Fullhan\n- **MIPS32**ï¼šmanufacturers like loongsonã€Ingenic\n- **RISC-V RV32E/RV32I[F]/RV64[D]**ï¼šmanufacturers like sifiveã€[Canaan Kendryte](https://github.com/RT-Thread/rt-thread/tree/master/bsp/k210)ã€[bouffalo_lab](https://github.com/RT-Thread/rt-thread/tree/master/bsp/bouffalo_lab)ã€[Nuclei](https://nucleisys.com/)ã€[T-Head](https://www.t-head.cn/)ã€[HPMicro](https://github.com/RT-Thread/rt-thread/tree/master/bsp/hpmicro)\n- **ARC**ï¼šmanufacturers like SYNOPSYS\n- **DSP**ï¼šmanufacturers like TI\n- **C-Sky**\n- **x86**\n\n## Supported IDE and Compiler\n\nThe main IDE/compilers supported by RT-Thread are:\n\n- RT-Thread Studio IDE\n- MDK KEIL\n- IAR\n- GCC\n\n## RT-Thread Studio IDE\n\n[User Manual](https://www.rt-thread.io/document/site/rtthread-studio/um/studio-user-manual/) | [Tutorial Videos](https://youtu.be/ucq5eJgZIQg)\n\nRT-Thread Studio IDE (a.k.a. RT-Studio) is a one-stop intergrated development environment built by RT-Thread team. It has a easy-to-use graphical configuration system and a wealth of software packages and components resources. RT-Studio has the features of project creation, configuration and management,as well as code editing, SDK management, build configuration, debugging configuration, program download and debug. We're looking to make the use of RT-Studio as intuitive as possible, reducing the duplication of work and improving the development efficiency.\n\n![studio](./documentation/figures/studio.gif)\n\n## Env Tool\n\n[User Manual](documentation/env/env.md) | [Tutorial Videos](https://www.youtube.com/watch?v=dEK94o_YoSo)\n\nIn the early stage, RT-Thread team also created an auxiliary tool called Env. It is an auxiliary tool with a TUI (Text-based user interface). Developers can use Env tool to configure and generate the GCC, Keil MDK, and IAR projects.\n\n![env](./documentation/figures/env.png)\n\n# Getting Started\n\n[RT-Thread Programming Guide](https://www.rt-thread.io/document/site/tutorial/quick-start/introduction/introduction/) | [RT-Thread Studio IDE](https://www.rt-thread.io/studio.html) | [Kernel Sample](https://github.com/RT-Thread-packages/kernel-sample) | [RT-Thread Beginners Guide](https://www.youtube.com/watch?v=ZMi1O-Rr7yc&list=PLXUV89C_M3G5KVw2IerI-pqApdSM_IaZo)\n\nBased on [STM32F103 BluePill](https://github.com/RT-Thread/rt-thread/tree/master/bsp/stm32/stm32f103-blue-pill) | [Raspberry Pi Pico](https://github.com/RT-Thread/rt-thread/tree/master/bsp/raspberry-pico)\n\n## Simulator\n\nRT-Thread BSP can be compiled directly and downloaded to the corresponding development board for use. In addition, RT-Thread also provides qemu-vexpress-a9 BSP, which can be used without hardware platform. See the getting started guide below for details. Getting Started of QEMU with Env:\n[Windows](documentation/2.quick-start/quick_start_qemu/quick_start_qemu_windows.md) | [Linux Ubuntu](documentation/2.quick-start/quick_start_qemu/quick_start_qemu_linux.md) | [Mac OS](documentation/2.quick-start/quick_start_qemu/quick_start_qemu_macos.md)\n\n# License\n\nRT-Thread follows the Apache License 2.0 free software license. It's completely open-source, can be used in commercial applications for free, does not require the disclosure of code, and has no potential commercial risk. License information and copyright information can generally be seen at the beginning of the code:\n\n```c\n/* Copyright (c) 2006-2018, RT-Thread Development Team\n *\n * SPDX-License-Identifier: Apache-2.0\n * ...\n */\n```\n\n# Community\n\nRT-Thread is very grateful for the support from all community developers, and if you have any ideas, suggestions or questions in the process of using RT-Thread, RT-Thread can be reached by the following means, and we are also updating RT-Thread in real time on these channels. At the same time, any questions can be asked in the [issue section of RT-Thread repository](https://github.com/RT-Thread/rt-thread/issues) or [RT-Thread forum](https://club.rt-thread.io/), and community members will answer them.\n\n[Website](https://www.rt-thread.io) | [Github](https://github.com/RT-Thread/rt-thread) | [Twitter](https://twitter.com/rt_thread) | [LinkedIn](https://www.linkedin.com/company/rt-thread-iot-os/posts/?feedView=all) | [Youtube](https://www.youtube.com/channel/UCdDHtIfSYPq4002r27ffqPw) | [Facebook](https://www.facebook.com/RT-Thread-IoT-OS-110395723808463/?modal=admin_todo_tour) | [Medium](https://rt-thread.medium.com/)\n\n# Contribution\n\nIf you are interested in RT-Thread and want to join in the development of RT-Thread and become a code contributor,please refer to the [Code Contribution Guide](.github/CONTRIBUTING.md).\n\n## Thanks for the following contributors!\n\n<a href=\"https://github.com/RT-Thread/rt-thread/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=RT-Thread/rt-thread\" />\n</a>\n",
      "stars_today": 3
    },
    {
      "id": 54280778,
      "name": "cJSON",
      "full_name": "DaveGamble/cJSON",
      "description": "Ultralightweight JSON parser in ANSI C",
      "html_url": "https://github.com/DaveGamble/cJSON",
      "stars": 12426,
      "forks": 3427,
      "language": "C",
      "topics": [],
      "created_at": "2016-03-19T18:22:54Z",
      "updated_at": "2026-02-06T09:50:25Z",
      "pushed_at": "2025-09-09T13:58:05Z",
      "open_issues": 294,
      "owner": {
        "login": "DaveGamble",
        "avatar_url": "https://avatars.githubusercontent.com/u/118247?v=4"
      },
      "readme": "# cJSON\n\nUltralightweight JSON parser in ANSI C.\n\n## Table of contents\n* [License](#license)\n* [Usage](#usage)\n  * [Welcome to cJSON](#welcome-to-cjson)\n  * [Building](#building)\n    * [Copying the source](#copying-the-source)\n    * [CMake](#cmake)\n    * [Makefile](#makefile)\n    * [Meson](#meson)\n    * [Vcpkg](#Vcpkg)\n  * [Including cJSON](#including-cjson)\n  * [Data Structure](#data-structure)\n  * [Working with the data structure](#working-with-the-data-structure)\n    * [Basic types](#basic-types)\n    * [Arrays](#arrays)\n    * [Objects](#objects)\n  * [Parsing JSON](#parsing-json)\n  * [Printing JSON](#printing-json)\n  * [Example](#example)\n    * [Printing](#printing)\n    * [Parsing](#parsing)\n  * [Caveats](#caveats)\n    * [Zero Character](#zero-character)\n    * [Character Encoding](#character-encoding)\n    * [C Standard](#c-standard)\n    * [Floating Point Numbers](#floating-point-numbers)\n    * [Deep Nesting Of Arrays And Objects](#deep-nesting-of-arrays-and-objects)\n    * [Thread Safety](#thread-safety)\n    * [Case Sensitivity](#case-sensitivity)\n    * [Duplicate Object Members](#duplicate-object-members)\n  * [Enjoy cJSON!](#enjoy-cjson)\n\n## License\n\nMIT License\n\n>  Copyright (c) 2009-2017 Dave Gamble and cJSON contributors\n>\n>  Permission is hereby granted, free of charge, to any person obtaining a copy\n>  of this software and associated documentation files (the \"Software\"), to deal\n>  in the Software without restriction, including without limitation the rights\n>  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n>  copies of the Software, and to permit persons to whom the Software is\n>  furnished to do so, subject to the following conditions:\n>\n>  The above copyright notice and this permission notice shall be included in\n>  all copies or substantial portions of the Software.\n>\n>  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n>  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n>  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n>  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n>  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n>  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n>  THE SOFTWARE.\n\n## Usage\n\n### Welcome to cJSON.\n\ncJSON aims to be the dumbest possible parser that you can get your job done with.\nIt's a single file of C, and a single header file.\n\nJSON is described best here: http://www.json.org/\nIt's like XML, but fat-free. You use it to move data around, store things, or just\ngenerally represent your program's state.\n\nAs a library, cJSON exists to take away as much legwork as it can, but not get in your way.\nAs a point of pragmatism (i.e. ignoring the truth), I'm going to say that you can use it\nin one of two modes: Auto and Manual. Let's have a quick run-through.\n\nI lifted some JSON from this page: http://www.json.org/fatfree.html\nThat page inspired me to write cJSON, which is a parser that tries to share the same\nphilosophy as JSON itself. Simple, dumb, out of the way.\n\n### Building\n\nThere are several ways to incorporate cJSON into your project.\n\n#### copying the source\n\nBecause the entire library is only one C file and one header file, you can just copy `cJSON.h` and `cJSON.c` to your projects source and start using it.\n\ncJSON is written in ANSI C (C89) in order to support as many platforms and compilers as possible.\n\n#### CMake\n\nWith CMake, cJSON supports a full blown build system. This way you get the most features. CMake with an equal or higher version than 2.8.5 is supported. With CMake it is recommended to do an out of tree build, meaning the compiled files are put in a directory separate from the source files. So in order to build cJSON with CMake on a Unix platform, make a `build` directory and run CMake inside it.\n\n```\nmkdir build\ncd build\ncmake ..\n```\n\nThis will create a Makefile and a bunch of other files. You can then compile it:\n\n```\nmake\n```\n\nAnd install it with `make install` if you want. By default it installs the headers `/usr/local/include/cjson` and the libraries to `/usr/local/lib`. It also installs files for pkg-config to make it easier to detect and use an existing installation of CMake. And it installs CMake config files, that can be used by other CMake based projects to discover the library.\n\nYou can change the build process with a list of different options that you can pass to CMake. Turn them on with `On` and off with `Off`:\n\n* `-DENABLE_CJSON_TEST=On`: Enable building the tests. (on by default)\n* `-DENABLE_CJSON_UTILS=On`: Enable building cJSON_Utils. (off by default)\n* `-DENABLE_TARGET_EXPORT=On`: Enable the export of CMake targets. Turn off if it makes problems. (on by default)\n* `-DENABLE_CUSTOM_COMPILER_FLAGS=On`: Enable custom compiler flags (currently for Clang, GCC and MSVC). Turn off if it makes problems. (on by default)\n* `-DENABLE_VALGRIND=On`: Run tests with [valgrind](http://valgrind.org). (off by default)\n* `-DENABLE_SANITIZERS=On`: Compile cJSON with [AddressSanitizer](https://github.com/google/sanitizers/wiki/AddressSanitizer) and [UndefinedBehaviorSanitizer](https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html) enabled (if possible). (off by default)\n* `-DENABLE_SAFE_STACK`: Enable the [SafeStack](https://clang.llvm.org/docs/SafeStack.html) instrumentation pass. Currently only works with the Clang compiler. (off by default)\n* `-DBUILD_SHARED_LIBS=On`: Build the shared libraries. (on by default)\n* `-DBUILD_SHARED_AND_STATIC_LIBS=On`: Build both shared and static libraries. (off by default)\n* `-DCMAKE_INSTALL_PREFIX=/usr`: Set a prefix for the installation.\n* `-DENABLE_LOCALES=On`: Enable the usage of localeconv method. ( on by default )\n* `-DCJSON_OVERRIDE_BUILD_SHARED_LIBS=On`: Enable overriding the value of `BUILD_SHARED_LIBS` with `-DCJSON_BUILD_SHARED_LIBS`.\n* `-DENABLE_CJSON_VERSION_SO`: Enable cJSON so version. ( on by default )\n\nIf you are packaging cJSON for a distribution of Linux, you would probably take these steps for example:\n```\nmkdir build\ncd build\ncmake .. -DENABLE_CJSON_UTILS=On -DENABLE_CJSON_TEST=Off -DCMAKE_INSTALL_PREFIX=/usr\nmake\nmake DESTDIR=$pkgdir install\n```\n\nOn Windows CMake is usually used to create a Visual Studio solution file by running it inside the Developer Command Prompt for Visual Studio, for exact steps follow the official documentation from CMake and Microsoft and use the online search engine of your choice. The descriptions of the the options above still generally apply, although not all of them work on Windows.\n\n#### Makefile\n\n**NOTE:** This Method is deprecated. Use CMake if at all possible. Makefile support is limited to fixing bugs.\n\nIf you don't have CMake available, but still have GNU make. You can use the makefile to build cJSON:\n\nRun this command in the directory with the source code and it will automatically compile static and shared libraries and a little test program (not the full test suite).\n\n```\nmake all\n```\n\nIf you want, you can install the compiled library to your system using `make install`. By default it will install the headers in `/usr/local/include/cjson` and the libraries in `/usr/local/lib`. But you can change this behavior by setting the `PREFIX` and `DESTDIR` variables: `make PREFIX=/usr DESTDIR=temp install`. And uninstall them with: `make PREFIX=/usr DESTDIR=temp uninstall`.\n\n#### Meson\n\nTo make cjson work in a project using meson, the libcjson dependency has to be included:\n\n```meson\nproject('c-json-example', 'c')\n\ncjson = dependency('libcjson')\n\nexample = executable(\n    'example',\n    'example.c',\n    dependencies: [cjson],\n)\n```\n\n\n#### Vcpkg\n\nYou can download and install cJSON using the [vcpkg](https://github.com/Microsoft/vcpkg) dependency manager:\n```\ngit clone https://github.com/Microsoft/vcpkg.git\ncd vcpkg\n./bootstrap-vcpkg.sh\n./vcpkg integrate install\nvcpkg install cjson\n```\n\nThe cJSON port in vcpkg is kept up to date by Microsoft team members and community contributors. If the version is out of date, please [create an issue or pull request](https://github.com/Microsoft/vcpkg) on the vcpkg repository.\n\n### Including cJSON\n\nIf you installed it via CMake or the Makefile, you can include cJSON like this:\n\n```c\n#include <cjson/cJSON.h>\n```\n\n### Data Structure\n\ncJSON represents JSON data using the `cJSON` struct data type:\n\n```c\n/* The cJSON structure: */\ntypedef struct cJSON\n{\n    struct cJSON *next;\n    struct cJSON *prev;\n    struct cJSON *child;\n    int type;\n    char *valuestring;\n    /* writing to valueint is DEPRECATED, use cJSON_SetNumberValue instead */\n    int valueint;\n    double valuedouble;\n    char *string;\n} cJSON;\n```\n\nAn item of this type represents a JSON value. The type is stored in `type` as a bit-flag (**this means that you cannot find out the type by just comparing the value of `type`**).\n\nTo check the type of an item, use the corresponding `cJSON_Is...` function. It does a `NULL` check followed by a type check and returns a boolean value if the item is of this type.\n\nThe type can be one of the following:\n\n* `cJSON_Invalid` (check with `cJSON_IsInvalid`): Represents an invalid item that doesn't contain any value. You automatically have this type if you set the item to all zero bytes.\n* `cJSON_False` (check with `cJSON_IsFalse`): Represents a `false` boolean value. You can also check for boolean values in general with `cJSON_IsBool`.\n* `cJSON_True` (check with `cJSON_IsTrue`): Represents a `true` boolean value. You can also check for boolean values in general with `cJSON_IsBool`.\n* `cJSON_NULL` (check with `cJSON_IsNull`): Represents a `null` value.\n* `cJSON_Number` (check with `cJSON_IsNumber`): Represents a number value. The value is stored as a double in `valuedouble` and also in `valueint`. If the number is outside of the range of an integer, `INT_MAX` or `INT_MIN` are used for `valueint`.\n* `cJSON_String` (check with `cJSON_IsString`): Represents a string value. It is stored in the form of a zero terminated string in `valuestring`.\n* `cJSON_Array` (check with `cJSON_IsArray`): Represent an array value. This is implemented by pointing `child` to a linked list of `cJSON` items that represent the values in the array. The elements are linked together using `next` and `prev`, where the first element has `prev.next == NULL` and the last element `next == NULL`.\n* `cJSON_Object` (check with `cJSON_IsObject`): Represents an object value. Objects are stored same way as an array, the only difference is that the items in the object store their keys in `string`.\n* `cJSON_Raw` (check with `cJSON_IsRaw`): Represents any kind of JSON that is stored as a zero terminated array of characters in `valuestring`. This can be used, for example, to avoid printing the same static JSON over and over again to save performance. cJSON will never create this type when parsing. Also note that cJSON doesn't check if it is valid JSON.\n\nAdditionally there are the following two flags:\n\n* `cJSON_IsReference`: Specifies that the item that `child` points to and/or `valuestring` is not owned by this item, it is only a reference. So `cJSON_Delete` and other functions will only deallocate this item, not its `child`/`valuestring`.\n* `cJSON_StringIsConst`: This means that `string` points to a constant string. This means that `cJSON_Delete` and other functions will not try to deallocate `string`.\n\n### Working with the data structure\n\nFor every value type there is a `cJSON_Create...` function that can be used to create an item of that type.\nAll of these will allocate a `cJSON` struct that can later be deleted with `cJSON_Delete`.\nNote that you have to delete them at some point, otherwise you will get a memory leak.  \n**Important**: If you have added an item to an array or an object already, you **mustn't** delete it with `cJSON_Delete`. Adding it to an array or object transfers its ownership so that when that array or object is deleted, \nit gets deleted as well. You also could use `cJSON_SetValuestring` to change a `cJSON_String`'s `valuestring`, and you needn't to free the previous `valuestring` manually.\n\n#### Basic types\n\n* **null** is created with `cJSON_CreateNull`\n* **booleans** are created with `cJSON_CreateTrue`, `cJSON_CreateFalse` or `cJSON_CreateBool`\n* **numbers** are created with `cJSON_CreateNumber`. This will set both `valuedouble` and `valueint`. If the number is outside of the range of an integer, `INT_MAX` or `INT_MIN` are used for `valueint`\n* **strings** are created with `cJSON_CreateString` (copies the string) or with `cJSON_CreateStringReference` (directly points to the string. This means that `valuestring` won't be deleted by `cJSON_Delete` and you are responsible for its lifetime, useful for constants)\n\n#### Arrays\n\nYou can create an empty array with `cJSON_CreateArray`. `cJSON_CreateArrayReference` can be used to create an array that doesn't \"own\" its content, so its content doesn't get deleted by `cJSON_Delete`.\n\nTo add items to an array, use `cJSON_AddItemToArray` to append items to the end.\nUsing `cJSON_AddItemReferenceToArray` an element can be added as a reference to another item, array or string. This means that `cJSON_Delete` will not delete that items `child` or `valuestring` properties, so no double frees are occurring if they are already used elsewhere.\nTo insert items in the middle, use `cJSON_InsertItemInArray`. It will insert an item at the given 0 based index and shift all the existing items to the right.\n\nIf you want to take an item out of an array at a given index and continue using it, use `cJSON_DetachItemFromArray`, it will return the detached item, so be sure to assign it to a pointer, otherwise you will have a memory leak.\n\nDeleting items is done with `cJSON_DeleteItemFromArray`. It works like `cJSON_DetachItemFromArray`, but deletes the detached item via `cJSON_Delete`.\n\nYou can also replace an item in an array in place. Either with `cJSON_ReplaceItemInArray` using an index or with `cJSON_ReplaceItemViaPointer` given a pointer to an element. `cJSON_ReplaceItemViaPointer` will return `0` if it fails. What this does internally is to detach the old item, delete it and insert the new item in its place.\n\nTo get the size of an array, use `cJSON_GetArraySize`. Use `cJSON_GetArrayItem` to get an element at a given index.\n\nBecause an array is stored as a linked list, iterating it via index is inefficient (`O(nÂ²)`), so you can iterate over an array using the `cJSON_ArrayForEach` macro in `O(n)` time complexity.\n\n#### Objects\n\nYou can create an empty object with `cJSON_CreateObject`. `cJSON_CreateObjectReference` can be used to create an object that doesn't \"own\" its content, so its content doesn't get deleted by `cJSON_Delete`.\n\nTo add items to an object, use `cJSON_AddItemToObject`. Use `cJSON_AddItemToObjectCS` to add an item to an object with a name that is a constant or reference (key of the item, `string` in the `cJSON` struct), so that it doesn't get freed by `cJSON_Delete`.\nUsing `cJSON_AddItemReferenceToArray` an element can be added as a reference to another object, array or string. This means that `cJSON_Delete` will not delete that items `child` or `valuestring` properties, so no double frees are occurring if they are already used elsewhere.\n\nIf you want to take an item out of an object, use `cJSON_DetachItemFromObjectCaseSensitive`, it will return the detached item, so be sure to assign it to a pointer, otherwise you will have a memory leak.\n\nDeleting items is done with `cJSON_DeleteItemFromObjectCaseSensitive`. It works like `cJSON_DetachItemFromObjectCaseSensitive` followed by `cJSON_Delete`.\n\nYou can also replace an item in an object in place. Either with `cJSON_ReplaceItemInObjectCaseSensitive` using a key or with `cJSON_ReplaceItemViaPointer` given a pointer to an element. `cJSON_ReplaceItemViaPointer` will return `0` if it fails. What this does internally is to detach the old item, delete it and insert the new item in its place.\n\nTo get the size of an object, you can use `cJSON_GetArraySize`, this works because internally objects are stored as arrays.\n\nIf you want to access an item in an object, use `cJSON_GetObjectItemCaseSensitive`.\n\nTo iterate over an object, you can use the `cJSON_ArrayForEach` macro the same way as for arrays.\n\ncJSON also provides convenient helper functions for quickly creating a new item and adding it to an object, like `cJSON_AddNullToObject`. They return a pointer to the new item or `NULL` if they failed.\n\n### Parsing JSON\n\nGiven some JSON in a zero terminated string, you can parse it with `cJSON_Parse`.\n\n```c\ncJSON *json = cJSON_Parse(string);\n```\n\nGiven some JSON in a string (whether zero terminated or not), you can parse it with `cJSON_ParseWithLength`.\n\n```c\ncJSON *json = cJSON_ParseWithLength(string, buffer_length);\n```\n\nIt will parse the JSON and allocate a tree of `cJSON` items that represents it. Once it returns, you are fully responsible for deallocating it after use with `cJSON_Delete`.\n\nThe allocator used by `cJSON_Parse` is `malloc` and `free` by default but can be changed (globally) with `cJSON_InitHooks`.\n\nIf an error occurs a pointer to the position of the error in the input string can be accessed using `cJSON_GetErrorPtr`. Note though that this can produce race conditions in multithreading scenarios, in that case it is better to use `cJSON_ParseWithOpts` with `return_parse_end`.\nBy default, characters in the input string that follow the parsed JSON will not be considered as an error.\n\nIf you want more options, use `cJSON_ParseWithOpts(const char *value, const char **return_parse_end, cJSON_bool require_null_terminated)`.\n`return_parse_end` returns a pointer to the end of the JSON in the input string or the position that an error occurs at (thereby replacing `cJSON_GetErrorPtr` in a thread safe way). `require_null_terminated`, if set to `1` will make it an error if the input string contains data after the JSON.\n\nIf you want more options giving buffer length, use `cJSON_ParseWithLengthOpts(const char *value, size_t buffer_length, const char **return_parse_end, cJSON_bool require_null_terminated)`.\n\n### Printing JSON\n\nGiven a tree of `cJSON` items, you can print them as a string using `cJSON_Print`.\n\n```c\nchar *string = cJSON_Print(json);\n```\n\nIt will allocate a string and print a JSON representation of the tree into it. Once it returns, you are fully responsible for deallocating it after use with your allocator. (usually `free`, depends on what has been set with `cJSON_InitHooks`).\n\n`cJSON_Print` will print with whitespace for formatting. If you want to print without formatting, use `cJSON_PrintUnformatted`.\n\nIf you have a rough idea of how big your resulting string will be, you can use `cJSON_PrintBuffered(const cJSON *item, int prebuffer, cJSON_bool fmt)`. `fmt` is a boolean to turn formatting with whitespace on and off. `prebuffer` specifies the first buffer size to use for printing. `cJSON_Print` currently uses 256 bytes for its first buffer size. Once printing runs out of space, a new buffer is allocated and the old gets copied over before printing is continued.\n\nThese dynamic buffer allocations can be completely avoided by using `cJSON_PrintPreallocated(cJSON *item, char *buffer, const int length, const cJSON_bool format)`. It takes a buffer to a pointer to print to and its length. If the length is reached, printing will fail and it returns `0`. In case of success, `1` is returned. Note that you should provide 5 bytes more than is actually needed, because cJSON is not 100% accurate in estimating if the provided memory is enough.\n\n### Example\n\nIn this example we want to build and parse the following JSON:\n\n```json\n{\n    \"name\": \"Awesome 4K\",\n    \"resolutions\": [\n        {\n            \"width\": 1280,\n            \"height\": 720\n        },\n        {\n            \"width\": 1920,\n            \"height\": 1080\n        },\n        {\n            \"width\": 3840,\n            \"height\": 2160\n        }\n    ]\n}\n```\n\n#### Printing\n\nLet's build the above JSON and print it to a string:\n\n```c\n//create a monitor with a list of supported resolutions\n//NOTE: Returns a heap allocated string, you are required to free it after use.\nchar *create_monitor(void)\n{\n    const unsigned int resolution_numbers[3][2] = {\n        {1280, 720},\n        {1920, 1080},\n        {3840, 2160}\n    };\n    char *string = NULL;\n    cJSON *name = NULL;\n    cJSON *resolutions = NULL;\n    cJSON *resolution = NULL;\n    cJSON *width = NULL;\n    cJSON *height = NULL;\n    size_t index = 0;\n\n    cJSON *monitor = cJSON_CreateObject();\n    if (monitor == NULL)\n    {\n        goto end;\n    }\n\n    name = cJSON_CreateString(\"Awesome 4K\");\n    if (name == NULL)\n    {\n        goto end;\n    }\n    /* after creation was successful, immediately add it to the monitor,\n     * thereby transferring ownership of the pointer to it */\n    cJSON_AddItemToObject(monitor, \"name\", name);\n\n    resolutions = cJSON_CreateArray();\n    if (resolutions == NULL)\n    {\n        goto end;\n    }\n    cJSON_AddItemToObject(monitor, \"resolutions\", resolutions);\n\n    for (index = 0; index < (sizeof(resolution_numbers) / (2 * sizeof(int))); ++index)\n    {\n        resolution = cJSON_CreateObject();\n        if (resolution == NULL)\n        {\n            goto end;\n        }\n        cJSON_AddItemToArray(resolutions, resolution);\n\n        width = cJSON_CreateNumber(resolution_numbers[index][0]);\n        if (width == NULL)\n        {\n            goto end;\n        }\n        cJSON_AddItemToObject(resolution, \"width\", width);\n\n        height = cJSON_CreateNumber(resolution_numbers[index][1]);\n        if (height == NULL)\n        {\n            goto end;\n        }\n        cJSON_AddItemToObject(resolution, \"height\", height);\n    }\n\n    string = cJSON_Print(monitor);\n    if (string == NULL)\n    {\n        fprintf(stderr, \"Failed to print monitor.\\n\");\n    }\n\nend:\n    cJSON_Delete(monitor);\n    return string;\n}\n```\n\nAlternatively we can use the `cJSON_Add...ToObject` helper functions to make our lives a little easier:\n\n```c\n//NOTE: Returns a heap allocated string, you are required to free it after use.\nchar *create_monitor_with_helpers(void)\n{\n    const unsigned int resolution_numbers[3][2] = {\n        {1280, 720},\n        {1920, 1080},\n        {3840, 2160}\n    };\n    char *string = NULL;\n    cJSON *resolutions = NULL;\n    size_t index = 0;\n\n    cJSON *monitor = cJSON_CreateObject();\n\n    if (cJSON_AddStringToObject(monitor, \"name\", \"Awesome 4K\") == NULL)\n    {\n        goto end;\n    }\n\n    resolutions = cJSON_AddArrayToObject(monitor, \"resolutions\");\n    if (resolutions == NULL)\n    {\n        goto end;\n    }\n\n    for (index = 0; index < (sizeof(resolution_numbers) / (2 * sizeof(int))); ++index)\n    {\n        cJSON *resolution = cJSON_CreateObject();\n\n        if (cJSON_AddNumberToObject(resolution, \"width\", resolution_numbers[index][0]) == NULL)\n        {\n            goto end;\n        }\n\n        if (cJSON_AddNumberToObject(resolution, \"height\", resolution_numbers[index][1]) == NULL)\n        {\n            goto end;\n        }\n\n        cJSON_AddItemToArray(resolutions, resolution);\n    }\n\n    string = cJSON_Print(monitor);\n    if (string == NULL)\n    {\n        fprintf(stderr, \"Failed to print monitor.\\n\");\n    }\n\nend:\n    cJSON_Delete(monitor);\n    return string;\n}\n```\n\n#### Parsing\n\nIn this example we will parse a JSON in the above format and check if the monitor supports a Full HD resolution while printing some diagnostic output:\n\n```c\n/* return 1 if the monitor supports full hd, 0 otherwise */\nint supports_full_hd(const char * const monitor)\n{\n    const cJSON *resolution = NULL;\n    const cJSON *resolutions = NULL;\n    const cJSON *name = NULL;\n    int status = 0;\n    cJSON *monitor_json = cJSON_Parse(monitor);\n    if (monitor_json == NULL)\n    {\n        const char *error_ptr = cJSON_GetErrorPtr();\n        if (error_ptr != NULL)\n        {\n            fprintf(stderr, \"Error before: %s\\n\", error_ptr);\n        }\n        status = 0;\n        goto end;\n    }\n\n    name = cJSON_GetObjectItemCaseSensitive(monitor_json, \"name\");\n    if (cJSON_IsString(name) && (name->valuestring != NULL))\n    {\n        printf(\"Checking monitor \\\"%s\\\"\\n\", name->valuestring);\n    }\n\n    resolutions = cJSON_GetObjectItemCaseSensitive(monitor_json, \"resolutions\");\n    cJSON_ArrayForEach(resolution, resolutions)\n    {\n        cJSON *width = cJSON_GetObjectItemCaseSensitive(resolution, \"width\");\n        cJSON *height = cJSON_GetObjectItemCaseSensitive(resolution, \"height\");\n\n        if (!cJSON_IsNumber(width) || !cJSON_IsNumber(height))\n        {\n            status = 0;\n            goto end;\n        }\n\n        if ((width->valuedouble == 1920) && (height->valuedouble == 1080))\n        {\n            status = 1;\n            goto end;\n        }\n    }\n\nend:\n    cJSON_Delete(monitor_json);\n    return status;\n}\n```\n\nNote that there are no NULL checks except for the result of `cJSON_Parse` because `cJSON_GetObjectItemCaseSensitive` checks for `NULL` inputs already, so a `NULL` value is just propagated and `cJSON_IsNumber` and `cJSON_IsString` return `0` if the input is `NULL`.\n\n### Caveats\n\n#### Zero Character\n\ncJSON doesn't support strings that contain the zero character `'\\0'` or `\\u0000`. This is impossible with the current API because strings are zero terminated.\n\n#### Character Encoding\n\ncJSON only supports UTF-8 encoded input. In most cases it doesn't reject invalid UTF-8 as input though, it just propagates it through as is. As long as the input doesn't contain invalid UTF-8, the output will always be valid UTF-8.\n\n#### C Standard\n\ncJSON is written in ANSI C (or C89, C90). If your compiler or C library doesn't follow this standard, correct behavior is not guaranteed.\n\nNOTE: ANSI C is not C++ therefore it shouldn't be compiled with a C++ compiler. You can compile it with a C compiler and link it with your C++ code however. Although compiling with a C++ compiler might work, correct behavior is not guaranteed.\n\n#### Floating Point Numbers\n\ncJSON does not officially support any `double` implementations other than IEEE754 double precision floating point numbers. It might still work with other implementations but bugs with these will be considered invalid.\n\nThe maximum length of a floating point literal that cJSON supports is currently 63 characters.\n\n#### Deep Nesting Of Arrays And Objects\n\ncJSON doesn't support arrays and objects that are nested too deeply because this would result in a stack overflow. To prevent this cJSON limits the depth to `CJSON_NESTING_LIMIT` which is 1000 by default but can be changed at compile time.\n\n#### Thread Safety\n\nIn general cJSON is **not thread safe**.\n\nHowever it is thread safe under the following conditions:\n\n* `cJSON_GetErrorPtr` is never used (the `return_parse_end` parameter of `cJSON_ParseWithOpts` can be used instead)\n* `cJSON_InitHooks` is only ever called before using cJSON in any threads.\n* `setlocale` is never called before all calls to cJSON functions have returned.\n\n#### Case Sensitivity\n\nWhen cJSON was originally created, it didn't follow the JSON standard and didn't make a distinction between uppercase and lowercase letters. If you want the correct, standard compliant, behavior, you need to use the `CaseSensitive` functions where available.\n\n#### Duplicate Object Members\n\ncJSON supports parsing and printing JSON that contains objects that have multiple members with the same name. `cJSON_GetObjectItemCaseSensitive` however will always only return the first one.\n\n# Enjoy cJSON!\n\n- Dave Gamble (original author)\n- Max Bruckner and Alan Wang (current maintainer)\n- and the other [cJSON contributors](CONTRIBUTORS.md)\n",
      "stars_today": 3
    },
    {
      "id": 46374199,
      "name": "librealsense",
      "full_name": "realsenseai/librealsense",
      "description": "RealSense SDK",
      "html_url": "https://github.com/realsenseai/librealsense",
      "stars": 8524,
      "forks": 4971,
      "language": "C++",
      "topics": [
        "camera-api",
        "computer-vision",
        "developer-kits",
        "hardware",
        "library",
        "librealsense",
        "sdk"
      ],
      "created_at": "2015-11-17T20:42:18Z",
      "updated_at": "2026-02-06T21:20:06Z",
      "pushed_at": "2026-02-04T13:45:54Z",
      "open_issues": 446,
      "owner": {
        "login": "realsenseai",
        "avatar_url": "https://avatars.githubusercontent.com/u/204379195?v=4"
      },
      "readme": "<p align=\"center\">\n<!-- Light mode -->\n<img src=\"doc/img/realsense-logo-light-mode.png#gh-light-mode-only\" alt=\"Logo for light mode\" width=\"30%\"/>\n\n<!-- Dark mode -->\n<img src=\"doc/img/realsense-logo-dark-mode.png#gh-dark-mode-only\" alt=\"Logo for dark mode\" width=\"30%\"/>\n<br><br>\n</p>\n\n<p align=\"center\">RealSense SDK 2.0 is a cross-platform library for RealSense depth cameras.\nThe SDK allows depth and color streaming, and provides intrinsic and extrinsic calibration information.</p>\n\n\n<p align=\"center\">\n  <a href=\"https://www.apache.org/licenses/LICENSE-2.0\"><img src=\"https://img.shields.io/github/license/realsenseai/librealsense.svg\" alt=\"License\"></a>\n  <a href=\"https://github.com/realsenseai/librealsense/releases/latest\"><img src=\"https://img.shields.io/github/v/release/realsenseai/librealsense?sort=semver\" alt=\"Latest release\"></a>\n  <a href=\"https://github.com/realsenseai/librealsense/compare/master...development\"><img src=\"https://img.shields.io/github/commits-since/realsenseai/librealsense/master/development?label=commits%20since\" alt=\"Commits since\"></a>\n  <a href=\"https://github.com/realsenseai/librealsense/issues\"><img src=\"https://img.shields.io/github/issues/realsenseai/librealsense.svg\" alt=\"Issues\"></a>\n  <a href=\"https://github.com/realsenseai/librealsense/actions/workflows/buildsCI.yaml?query=branch%3Adevelopment\"><img src=\"https://github.com/realsenseai/librealsense/actions/workflows/buildsCI.yaml/badge.svg?branch=development\" alt=\"GitHub CI\"></a>\n  <a href=\"https://github.com/realsenseai/librealsense/network/members\"><img src=\"https://img.shields.io/github/forks/realsenseai/librealsense.svg\" alt=\"Forks\"></a>\n</p>\n\n## Important Notice\n\nWe are happy to announce that the RealSense GitHub repositories have been successfully migrated to the RealSenseAI organization.\nPlease make sure to update your links to the new RealSenseAI organization for both cloning the repositories and accessing specific files within them.\n\n[https://github.com/**IntelRealSense**/librealsense](https://github.com/IntelRealSense/librealsense) --> [https://github.com/**realsenseai**/librealsense](https://github.com/realsenseai/librealsense)\n\nNote: A redirection from the previous name IntelRealSense is currently in place, but we cannot guarantee how long it will remain active. We recommend that all users update their references to point to the new GitHub location.\n\n#### Branch Policy\nWe have updated our branch policy:\nFrom now on, we will also push beta releases to the master branch, so users can access up-to-date code and features.\nIn the near future, beta binaries will also be pushed to public distribution servers (e.g., APT).\nThe last validated official release can be found on our Releases page on GitHub.\n\n## Use Cases\n\nBelow are some of the many real-world applications powered by RealSense technology:\n\nRobotics | Depth Sensing | 3D Scanning |\n:------------: | :----------: | :-------------: |\n<a href=\"https://realsenseai.com/case-studies/?capability_application=autonomous-mobile-robots\"><img src=\"https://librealsense.realsenseai.com/readme-media/realsense_examplerealsense_example.gif\" width=\"240\"/></a> |<a href=\"https://realsenseai.com/case-studies/?q=/case-studies&\"><img src=\"https://librealsense.realsenseai.com/readme-media/align-expectede.gif\" width=\"240\"/></a> | <a href=\"https://realsenseai.com/case-studies/?capability_application=autonomous-mobile-robots\"><img src=\"https://librealsense.realsenseai.com/readme-media/realsense_dynamic_example.gif\" width=\"240\"/></a>\n\nDrones | Skeletal and People Tracking | Facial Authentication |\n:--------------------------: | :-----: | :----------------------: |\n<a href=\"https://realsenseai.com/case-studies/?q=/case-studies&\"><img src=\"https://librealsense.realsenseai.com/readme-media/drone-demo.gif\" width=\"240\"/></a> |<a href=\"https://realsenseai.com/case-studies/?capability_application=monitoring-and-tracking\"><img src=\"https://librealsense.realsenseai.com/readme-media/SkeletalTracking.gif\" width=\"240\"/></a> | <a href=\"https://realsenseai.com/case-studies/?capability_application=biometrics\"><img src=\"https://librealsense.realsenseai.com/readme-media/face-demo.gif\" width=\"240\"/></a>\n\n\n\n## Why RealSense?\n\n- **High-resolution color and depth** at close and long ranges\n- **Open source SDK** with rich examples and wrappers (Python, ROS, C#, Unity and [more...](https://github.com/realsenseai/librealsense/tree/master/wrappers))\n- **Active developer community and defacto-standard 3D stereo camera for robotics**\n- **Cross-platform** support: Windows, Linux, macOS, Android, and Docker\n\n## Product Line\n\nRealSense stereo depth products use stereo vision to calculate depth, providing high-quality performance in various lighting and environmental conditions.\n\nHere are some examples of the supported models:\n\n| Product | Image | Description |\n|---------|-------|-------------|\n| [**D555 PoE**](https://realsenseai.com/ruggedized-industrial-stereo-depth/d555-poe/) | <img src=\"https://realsenseai.com/wp-content/uploads/2025/07/D555.png\" width=\"1000\"> | The RealSenseâ„¢ Depth Camera D555 introduces Power over Ethernet (PoE) interface on chip, expanding our portfolio of USB and GMSL/FAKRA products. |\n| [**D457 GMSL/FAKRA**](https://realsenseai.com/ruggedized-industrial-stereo-depth/d457-gmsl-fakra/) | <img src=\"https://realsenseai.com/wp-content/uploads/2025/07/D457.png\" width=\"1000\"> | The RealSenseâ„¢ Depth Camera D457 is our first GMSL/FAKRA high bandwidth stereo camera. The D457 has an IP65 grade enclosure protecting it from dust ingress and projected water. |\n| [**D455**](https://realsenseai.com/stereo-depth-cameras/real-sense-depth-camera-d455/) | <img src=\"https://www.realsenseai.com/wp-content/uploads/2021/11/455.png\" width=\"1000\"> | The RealSense D455 is a long-range stereo depth camera with a 95 mm baseline, global-shutter depth sensors, an RGB sensor, and a built-in IMU, delivering accurate depth at distances up to 10 m.. |\n| [**D435if**](https://realsenseai.com/stereo-depth-cameras/depth-camera-d435i/) | <img src=\"https://realsenseai.com/wp-content/uploads/2025/06/D435if-a.png\" width=\"1000\"> | The D435if is one of [RealSenseâ„¢ Depth Camera with IR pass filter family](https://realsenseai.com/stereo-depth-with-ir-pass-filter/) expanding our portfolio targeting the growing robotic market. The D400f family utilizes an IR pass filter to enhance depth quality and performance range in many robotic environments.|\n| [**D405**](https://realsenseai.com/stereo-depth-cameras/stereo-depth-camera-d405/) | <img src=\"https://realsenseai.com/wp-content/uploads/2025/07/D-405.png\" width=\"1000\"> | The RealSenseâ„¢ Depth Camera D405 is a short-range stereo camera providing sub-millimeter accuracy for your close-range computer vision needs. |\n\n\n> ğŸ›ï¸ [Explore more stereo products](https://store.realsenseai.com/)\n\n## Getting Started\n\nStart developing with RealSense in minutes using either method below.\n\n### 1ï¸. Precompiled SDK\n\nThis is the best option if you want to plug in your camera and get started right away.\n1. Download the latest SDK bundle from the [Releases page](https://github.com/realsenseai/librealsense/releases).\n2. Connect your RealSense camera.\n3. Run the included tools:\n    - [RealSense Viewer](./tools/realsense-viewer/): View streams, tune settings, record and playback.\n    - [Depth Quality Tool](./tools/depth-quality/): Measure accuracy and fill rate.\n\n### Setup Guides - precompiled SDK\n\n<a href=\"./doc/distribution_linux.md\"><img src=\"https://img.shields.io/badge/Ubuntu_Guide-333?style=flat&logo=ubuntu&logoColor=white\" style=\"margin: 5px;\" alt=\"Linux\\Jetson Guide\"/></a>\n<a href=\"./doc/distribution_windows.md\"><img src=\"https://custom-icon-badges.demolab.com/badge/Windows_Guide-333?logo=windows11&logoColor=white\" style=\"margin: 5px;\" alt=\"Windows Guide\"/></a>\n\n> **Note:** For **minor releases**, we publish Debian packages as release artifacts that you can download and install directly.\n\n### 2ï¸. Build from Source\nFor a more custom installation, follow these steps to build the SDK from source.\n1. Clone the repository and create a build directory:\n   ```bash\n   git clone https://github.com/realsenseai/librealsense.git\n   cd librealsense\n   mkdir build && cd build\n   ```\n2. Run CMake to configure the build:\n    ```bash\n    cmake ..\n    ```\n3. Build the project:\n    ```bash\n    cmake --build .\n    ```\n\n### Setup Guides - build from source\n\n<a href=\"./doc/installation.md\"><img src=\"https://img.shields.io/badge/Ubuntu_Guide-333?style=flat&logo=ubuntu&logoColor=white\" style=\"margin: 5px;\" alt=\"Linux Guide\"/></a>\n<a href=\"./doc/installation_jetson.md\"><img src=\"https://img.shields.io/badge/Jetson_Guide-333?style=flat&logo=nvidia&logoColor=white\" style=\"margin: 5px;\" alt=\"Jetson Guide\"/></a>\n<a href=\"./doc/installation_windows.md\"><img src=\"https://custom-icon-badges.demolab.com/badge/Windows_Guide-333?logo=windows11&logoColor=white\" style=\"margin: 5px;\" alt=\"Windows Guide\"/></a>\n<a href=\"./doc/installation_osx.md\"><img src=\"https://img.shields.io/badge/macOS_Guide-333?style=flat&logo=apple&logoColor=white\" style=\"margin: 5px;\" alt=\"macOS Guide\"/></a>\n\n\n## Python Packages\n[![pyrealsense2](https://img.shields.io/pypi/v/pyrealsense2.svg?label=pyrealsense2&logo=pypi)](https://pypi.org/project/pyrealsense2/)\n[![PyPI - pyrealsense2-beta](https://img.shields.io/pypi/v/pyrealsense2-beta.svg?label=pyrealsense2-beta&logo=pypi)](https://pypi.org/project/pyrealsense2-beta/)\n\n**Which should I use?**\n- **Stable:** `pyrealsense2` â€” validated releases aligned with SDK tags (Recommended for most users).  \n- **Beta:** `pyrealsense2-beta` â€” fresher builds for early access and testing. Expect faster updates.  \n\n### Install\n```bash\npip install pyrealsense2 # Stable\npip install pyrealsense2-beta # Beta\n```\n> Both packages import as `pyrealsense2`. Install **only one** at a time.\n\n## Ready to Hack!\n\nOur library offers a high level API for using RealSense depth cameras (in addition to lower level ones).\nThe following snippets show how to start streaming frames and extracting the depth value of a pixel:\n\n**C++**\n```cpp\n#include <librealsense2/rs.hpp>\n#include <iostream>\n\nint main() {\n    rs2::pipeline p;                 // Top-level API for streaming & processing frames\n    p.start();                       // Configure and start the pipeline\n\n    while (true) {\n        rs2::frameset frames = p.wait_for_frames();        // Block until frames arrive\n        rs2::depth_frame depth = frames.get_depth_frame(); // Get depth frame\n        if (!depth) continue;\n\n        int w = depth.get_width(), h = depth.get_height();\n        float dist = depth.get_distance(w/2, h/2);         // Distance to center pixel\n        std::cout << \"The camera is facing an object \" << dist << \" meters away\\r\";\n    }\n}\n```\n\n**Python**\n```python\nimport pyrealsense2 as rs\n\npipeline = rs.pipeline() # Create a pipeline\npipeline.start() # Start streaming\n\ntry:\n    while True:\n        frames = pipeline.wait_for_frames()\n        depth_frame = frames.get_depth_frame()\n        if not depth_frame:\n            continue\n\n        width, height = depth_frame.get_width(), depth_frame.get_height()\n        dist = depth_frame.get_distance(width // 2, height // 2)\n        print(f\"The camera is facing an object {dist:.3f} meters away\", end=\"\\r\")\n\nfinally:\n    pipeline.stop() # Stop streaming\n```\n\nFor more information on the library, please follow our [examples](./examples) or [tools](./tools/), and read the [documentation](./doc) to learn more.\n\n## Supported Platforms\n\n### Operating Systems and Platforms\n\n| Ubuntu | Windows | macOS High Sierra | Jetson | Raspberry Pi |\n|--------|---------|-------|--------|----------------|\n| <div align=\"center\"><a href=\"https://dev.realsenseai.com/docs/compiling-librealsense-for-linux-ubuntu-guide\"><img src=\"https://librealsense.realsenseai.com/readme-media/ubuntu.png\" width=\"40%\" alt=\"Ubuntu\" /></a></div> | <div align=\"center\"><a href=\"https://dev.realsenseai.com/docs/compiling-librealsense-for-windows-guide\"><img src=\"https://librealsense.realsenseai.com/readme-media/Windows_logo.png\" width=\"40%\" alt=\"Windows\" /></a></div> | <div align=\"center\"><a href=\"https://dev.realsenseai.com/docs/macos-installation-for-intel-realsense-sdk\"><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"https://librealsense.realsenseai.com/readme-media/apple-dark.png\"><img src=\"https://librealsense.realsenseai.com/readme-media/apple-light.png\" width=\"40%\" alt=\"macOS\" /></picture></a></div> | <div align=\"center\"><a href=\"https://dev.realsenseai.com/docs/nvidia-jetson-tx2-installation\"><img src=\"https://librealsense.realsenseai.com/readme-media/nvidia.png\" width=\"40%\" alt=\"\" /></a></div> | <div align=\"center\"><a href=\"https://dev.realsenseai.com/docs/using-depth-camera-with-raspberry-pi-3\"><img src=\"https://librealsense.realsenseai.com/readme-media/raspberry-pi.png\" width=\"40%\" alt=\"\" /></a></div> \n\n\n\n### Programming Languages and Wrappers\n\n| C++ | C | C# | Python | ROS 2 |Rest API |\n|-----|---|----|--------|-------|---------|\n| <div align=\"center\"><a href=\"https://dev.realsenseai.com/docs/code-samples\"><img src=\"https://librealsense.realsenseai.com/readme-media/cpp.png\" width=\"50%\" alt=\"\" /></a></div> | <div align=\"center\"><a href=\"https://dev.realsenseai.com/docs/code-samples\"><img src=\"https://librealsense.realsenseai.com/readme-media/c.png\" width=\"55%\" alt=\"\" /></a></div> | <div align=\"center\"><a href=\"https://dev.realsenseai.com/docs/csharp-wrapper\"><img src=\"https://librealsense.realsenseai.com/readme-media/c-sharp.png\" width=\"50%\" alt=\"\" /></a></div> | <div align=\"center\"><a href=\"https://dev.realsenseai.com/docs/python2\"><img src=\"https://librealsense.realsenseai.com/readme-media/python.png\" width=\"30%\" alt=\"\" /></a></div> | <div align=\"center\"><a href=\"https://dev.realsenseai.com/docs/ros2-wrapper\"><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"https://librealsense.realsenseai.com/readme-media/ros2-dark.png\"><img src=\"https://librealsense.realsenseai.com/readme-media/ROS2-light.png\" width=\"80%\" alt=\"ROS 2\" /></picture></a></div> | <div align=\"center\"><a href=\"https://github.com/realsenseai/librealsense/blob/development/wrappers/rest-api/README.md\"><img src=\"https://librealsense.realsenseai.com/readme-media/REST_API.png\" width=\"50%\" alt=\"Rest API\" /></a></div>|\n\nFor more platforms and wrappers look over [here](https://dev.realsenseai.com/docs/docs-get-started).\n> Full feature support varies by platform â€“ refer to the [release notes](https://github.com/realsenseai/librealsense/wiki/Release-Notes) for details.\n\n## Community & Support\n\n- [ğŸ“š Wiki & Docs](https://github.com/realsenseai/librealsense/wiki)\n- [ğŸ Report Issues](https://github.com/realsenseai/librealsense/issues)- Found a bug or want to contribute? Read our [contribution guidelines](./CONTRIBUTING.md).\n\n> ğŸ” Looking for legacy devices (F200, R200, LR200, ZR300)? Visit the [legacy release](https://github.com/realsenseai/librealsense/tree/v1.12.1).\n\n---\n<p align=\"center\">\nYou can find us at\n</p>\n<p align=\"center\">\n  <a href=\"https://github.com/realsenseai\" target=\"_blank\" aria-label=\"GitHub\"><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"https://librealsense.realsenseai.com/readme-media/github_light.PNG\"><img src=\"https://librealsense.realsenseai.com/readme-media/github.png\" width=\"32\" alt=\"GitHub\"></picture></a>\n  &nbsp;&nbsp;&nbsp;\n  <a href=\"https://x.com/RealSenseai\" target=\"_blank\" aria-label=\"X (Twitter)\"><img src=\"https://librealsense.realsenseai.com/readme-media/twitter.png\" width=\"32\" alt=\"X (Twitter)\" /></a>\n  &nbsp;&nbsp;&nbsp;\n  <a href=\"https://www.youtube.com/@RealSenseai\" target=\"_blank\" aria-label=\"YouTube\"><img src=\"https://librealsense.realsenseai.com/readme-media/social.png\" width=\"32\" alt=\"YouTube\" /></a>\n  &nbsp;&nbsp;&nbsp;\n  <a href=\"https://www.linkedin.com/company/realsenseai?trk=similar-pages\" target=\"_blank\" aria-label=\"LinkedIn\"><img src=\"https://librealsense.realsenseai.com/readme-media/linkedin.png\" width=\"32\" alt=\"LinkedIn\" /></a>\n  &nbsp;&nbsp;&nbsp;\n  <a href=\"https://realsenseai.com/\" target=\"_blank\" aria-label=\"Community\"><img src=\"https://librealsense.realsenseai.com/readme-media/Real-sense-badge-rgb-c.png\" width=\"32\" alt=\"Community\" /></a>\n</p>\n\n\n\n",
      "stars_today": 3
    },
    {
      "id": 23086893,
      "name": "re2",
      "full_name": "google/re2",
      "description": "RE2 is a fast, safe, thread-friendly alternative to backtracking regular expression engines like those used in PCRE, Perl, and Python. It is a C++ library.",
      "html_url": "https://github.com/google/re2",
      "stars": 9590,
      "forks": 1206,
      "language": "C++",
      "topics": [],
      "created_at": "2014-08-18T21:21:26Z",
      "updated_at": "2026-02-06T10:07:40Z",
      "pushed_at": "2026-01-22T23:28:54Z",
      "open_issues": 11,
      "owner": {
        "login": "google",
        "avatar_url": "https://avatars.githubusercontent.com/u/1342004?v=4"
      },
      "readme": "# RE2, a regular expression library\n\nRE2 is an efficient, principled regular expression library\nthat has been used in production at Google and many other places\nsince 2006.\n\n_**Safety is RE2's primary goal.**_\n\nRE2 was designed and implemented with an explicit goal of being able\nto handle regular expressions from untrusted users without risk.\nOne of its primary guarantees is that the match time is linear in the\nlength of the input string. It was also written with production concerns in mind:\nthe parser, the compiler and the execution engines limit their memory usage\nby working within a configurable budgetâ€”failing gracefully when exhaustedâ€”and\nthey avoid stack overflow by eschewing recursion.\n\nIt is not a goal to be faster than all other engines under all circumstances.\nAlthough RE2 guarantees a running time that is asymptotically linear in\nthe length of the input, more complex expressions may incur larger constant factors;\nlonger expressions increase the overhead required to handle those expressions safely.\nIn a sense, RE2 is pessimistic where a backtracking engine is optimistic:\nA backtracking engine tests each alternative sequentially, making it fast when the first alternative is common.\nBy contrast RE2 evaluates all alternatives in parallel, avoiding the performance penalty for the last alternative,\nat the cost of some overhead. This pessimism is what makes RE2 secure.\n\nIt is also not a goal to implement all of the features offered by Perl, PCRE and other engines.\nAs a matter of principle, RE2 does not support constructs for which only backtracking solutions are known to exist.\nThus, backreferences and look-around assertions are not supported.\n\nFor more information, please refer to Russ Cox's articles on regular expression theory and practice:\n\n* [Regular Expression Matching Can Be Simple And Fast](https://swtch.com/~rsc/regexp/regexp1.html)\n* [Regular Expression Matching: the Virtual Machine Approach](https://swtch.com/~rsc/regexp/regexp2.html)\n* [Regular Expression Matching in the Wild](https://swtch.com/~rsc/regexp/regexp3.html)\n\n### Syntax\n\nIn POSIX mode, RE2 accepts standard POSIX (egrep) syntax regular expressions.\nIn Perl mode, RE2 accepts most Perl operators.  The only excluded ones are\nthose that require backtracking (and its potential for exponential runtime)\nto implement.  These include backreferences (submatching is still okay)\nand generalized assertions.\nThe [Syntax wiki page](https://github.com/google/re2/wiki/Syntax)\ndocuments the supported Perl-mode syntax in detail.\nThe default is Perl mode.\n\n### C++ API\n\nRE2's native language is C++, although there are [ports and wrappers](#ports-and-wrappers) listed below.\n\n#### Matching Interface\n\nThere are two basic operators:\n`RE2::FullMatch` requires the regexp to match the entire input text, and\n`RE2::PartialMatch` looks for a match for a substring of the input text,\nreturning the leftmost-longest match in POSIX mode and the\nsame match that Perl would have chosen in Perl mode.\n\nExamples:\n\n```cpp\nassert(RE2::FullMatch(\"hello\", \"h.*o\"))\nassert(!RE2::FullMatch(\"hello\", \"e\"))\n\nassert(RE2::PartialMatch(\"hello\", \"h.*o\"))\nassert(RE2::PartialMatch(\"hello\", \"e\"))\n```\n\n#### Submatch Extraction\n\nBoth matching functions take additional arguments in which submatches will be stored.\nThe argument can be a `string*`, or an integer type, or the type `absl::string_view*`.\n(The `absl::string_view` type is very similar to the `std::string_view` type,\nbut for historical reasons, RE2 uses the former.)\nA `string_view` is a pointer to the original input text, along with a count.\nIt behaves like a string but doesn't carry its own storage.\nLike when using a pointer, when using a `string_view`\nyou must be careful not to use it once the original text has been deleted or gone out of scope.\n\nExamples:\n\n```cpp\n// Successful parsing.\nint i;\nstring s;\nassert(RE2::FullMatch(\"ruby:1234\", \"(\\\\w+):(\\\\d+)\", &s, &i));\nassert(s == \"ruby\");\nassert(i == 1234);\n\n// Fails: \"ruby\" cannot be parsed as an integer.\nassert(!RE2::FullMatch(\"ruby\", \"(.+)\", &i));\n\n// Success; does not extract the number.\nassert(RE2::FullMatch(\"ruby:1234\", \"(\\\\w+):(\\\\d+)\", &s));\n\n// Success; skips NULL argument.\nassert(RE2::FullMatch(\"ruby:1234\", \"(\\\\w+):(\\\\d+)\", (void*)NULL, &i));\n\n// Fails: integer overflow keeps value from being stored in i.\nassert(!RE2::FullMatch(\"ruby:123456789123\", \"(\\\\w+):(\\\\d+)\", &s, &i));\n```\n\n#### Pre-Compiled Regular Expressions\n\nThe examples above all recompile the regular expression on each call.\nInstead, you can compile it once to an RE2 object and reuse that object for each call.\n\nExample:\n```cpp\nRE2 re(\"(\\\\w+):(\\\\d+)\");\nassert(re.ok());  // compiled; if not, see re.error();\n\nassert(RE2::FullMatch(\"ruby:1234\", re, &s, &i));\nassert(RE2::FullMatch(\"ruby:1234\", re, &s));\nassert(RE2::FullMatch(\"ruby:1234\", re, (void*)NULL, &i));\nassert(!RE2::FullMatch(\"ruby:123456789123\", re, &s, &i));\n```\n\n#### Options\n\nThe constructor takes an optional second argument that can\nbe used to change RE2's default options.\nFor example, `RE2::Quiet` silences the error messages that are\nusually printed when a regular expression fails to parse:\n\n```cpp\nRE2 re(\"(ab\", RE2::Quiet);  // don't write to stderr for parser failure\nassert(!re.ok());  // can check re.error() for details\n```\n\nOther useful predefined options are `Latin1` (disable UTF-8) and `POSIX`\n(use POSIX syntax and leftmost longest matching).\n\nYou can also declare your own `RE2::Options` object and then configure it as you like.\nSee the [header](https://github.com/google/re2/blob/main/re2/re2.h) for the full set of options.\n\n#### Unicode Normalization\n\nRE2 operates on Unicode code points: it makes no attempt at normalization.\nFor example, the regular expression /Ã¼/ (U+00FC, u with diaeresis)\ndoes not match the input \"uÌˆ\" (U+0075 U+0308, u followed by combining diaeresis).\nNormalization is a long, involved topic.\nThe simplest solution, if you need such matches, is to normalize both the regular expressions\nand the input in a preprocessing step before using RE2.\nFor more details on the general topic, see <https://www.unicode.org/reports/tr15/>.\n\n#### Additional Tips and Tricks\n\nFor advanced usage, like constructing your own argument lists,\nor using RE2 as a lexer, or parsing hex, octal, and C-radix numbers,\nsee [re2.h](https://github.com/google/re2/blob/main/re2/re2.h).\n\n### Installation\n\nRE2 can be built and installed using GNU make, CMake, or Bazel.\nThe simplest installation instructions are:\n\n\tmake\n\tmake test\n\tmake benchmark\n\tmake install\n\tmake testinstall\n\nBuilding RE2 requires a C++17 compiler and the [Abseil](https://github.com/abseil/abseil-cpp) library.\nBuilding the tests and benchmarks requires\n[GoogleTest](https://github.com/google/googletest)\nand [Benchmark](https://github.com/google/benchmark).\nTo obtain those:\n\n- Linux: `apt install libabsl-dev libgtest-dev libbenchmark-dev`\n- macOS: `brew install abseil googletest google-benchmark pkg-config-wrapper`\n- Windows: `vcpkg install abseil gtest benchmark` \\\n  or `vcpkg add port abseil gtest benchmark`\n\nOnce those are installed, the build has to be able to find them.\nIf the standard Makefile has trouble, then switching to CMake can help:\n\n\trm -rf build\n\tcmake -DRE2_TEST=ON -DRE2_BENCHMARK=ON -S . -B build\n\tcd build\n\tmake\n\tmake test\n\tmake install\n\nWhen using CMake, with benchmarks enabled, `make test` builds and runs test binaries\nand builds a `regexp_benchmark` binary but does not run it.\nIf you don't need the tests or benchmarks at all, you can omit the corresponding `-D` arguments,\nand then you don't need the GoogleTest or Benchmark dependencies either.\n\nAnother useful option is `-DRE2_USE_ICU=ON`, which adds a dependency on the\nICU Unicode library but also extends the list of property names available in the `\\p` and `\\P` patterns.\n\nCMake can also be used to generate Visual Studio and Xcode projects, as well as\nCygwin, MinGW, and MSYS makefiles.\n\n - Visual Studio users: You need Visual Studio 2019 or later.\n - Cygwin users: You must run CMake from the Cygwin command line, not the Windows command line.\n\nIf you are adding RE2 to your own CMake project,\nCMake has two ways to use a dependency: `add_subdirectory()`,\nwhich is when the dependency's **_sources_** are in a subdirectory of your project;\nand `find_package()`, which is when the dependency's\n**_binaries_** have been built and installed somewhere on your system.\nThe Abseil documentation walks through the former [here](https://abseil.io/docs/cpp/quickstart-cmake)\nversus the latter [here](https://abseil.io/docs/cpp/tools/cmake-installs).\nOnce you get Abseil working, getting RE2 working will be a very similar process and,\neither way, `target_link_libraries(â€¦ re2::re2)` should Just Workâ„¢.\n\nIf you are using [Bazel](https://bazel.io), it will handle the dependencies for you,\nalthough you still need to download Bazel,\nwhich you can do with [Bazelisk](https://github.com/bazelbuild/bazelisk).\n\n\tgo install github.com/bazelbuild/bazelisk@latest\n\t# or on mac: brew install bazelisk\n\n\tbazelisk build :all\n\tbazelisk test :all\n\nIf you are using RE2 from another project, you need to make sure you are\nusing at least C++17.\nSee the RE2 [.bazelrc](https://github.com/google/re2/blob/main/.bazelrc) file for an example.\n\n### Ports and Wrappers\n\nRE2 is implemented in C++.\n\nThe official Python wrapper is [in the `python` directory](https://github.com/google/re2/tree/main/python)\nand [published on PyPI as `google-re2`](https://pypi.org/project/google-re2/).\nNote that there is also a PyPI `re2` but it is not by the RE2 authors and is unmaintained. Use `google-re2`.\n\nThere are also other unofficial wrappers:\n\n- A C wrapper is at <https://github.com/marcomaggi/cre2/>.\n- A D wrapper is at <https://github.com/ShigekiKarita/re2d/> and [on DUB](https://code.dlang.org/packages/re2d).\n- An Erlang wrapper is at <https://github.com/dukesoferl/re2/> and [on Hex](https://hex.pm/packages/re2).\n- An Inferno wrapper is at <https://github.com/powerman/inferno-re2/>.\n- A Node.js wrapper is at <https://github.com/uhop/node-re2/> and [on NPM](https://www.npmjs.com/package/re2).\n- An OCaml wrapper is at <https://github.com/janestreet/re2/> and [on OPAM](https://opam.ocaml.org/packages/re2/).\n- A Perl wrapper is at <https://github.com/dgl/re-engine-RE2/> and [on CPAN](https://metacpan.org/pod/re::engine::RE2).\n- An R wrapper is at <https://github.com/girishji/re2/> and [on CRAN](https://cran.r-project.org/web/packages/re2/index.html).\n- A Ruby wrapper is at <https://github.com/mudge/re2/> and on RubyGems (rubygems.org).\n- A WebAssembly wrapper is at <https://github.com/google/re2-wasm/> and on NPM (npmjs.com).\n\n[RE2J](https://github.com/google/re2j) is a port of the RE2 C++ code to pure Java,\nand [RE2JS](https://github.com/le0pard/re2js) is a port of RE2J to JavaScript.\n\nThe [Go `regexp` package](https://go.dev/pkg/regexp)\nand [Rust `regex` crate](https://docs.rs/regex)\ndo not share code with RE2, but they follow the same principles,\naccept the same syntax, and provide the same efficiency guarantees.\n\n### Contact\n\nThe [issue tracker](https://github.com/google/re2/issues) is the best place for discussions.\n\nThere is a [mailing list](https://groups.google.com/group/re2-dev) for keeping up with code changes.\n\nPlease read the [contribution guide](https://github.com/google/re2/wiki/Contribute) before sending changes.\nIn particular, note that RE2 does not use GitHub pull requests.\n",
      "stars_today": 3
    },
    {
      "id": 189044704,
      "name": "AFLplusplus",
      "full_name": "AFLplusplus/AFLplusplus",
      "description": "The fuzzer afl++ is afl with community patches, qemu 5.1 upgrade, collision-free coverage, enhanced laf-intel & redqueen, AFLfast++ power schedules, MOpt mutators, unicorn_mode, and a lot more!",
      "html_url": "https://github.com/AFLplusplus/AFLplusplus",
      "stars": 6279,
      "forks": 1249,
      "language": "C",
      "topics": [
        "afl",
        "afl-compiler",
        "afl-fuzz",
        "afl-fuzzer",
        "afl-gcc",
        "fuzz-testing",
        "fuzzer",
        "fuzzer-afl",
        "fuzzing",
        "instrumentation",
        "qemu",
        "security",
        "testing",
        "unicorn-emulator",
        "unicorn-mode"
      ],
      "created_at": "2019-05-28T14:29:06Z",
      "updated_at": "2026-02-06T07:58:34Z",
      "pushed_at": "2026-02-07T01:54:08Z",
      "open_issues": 30,
      "owner": {
        "login": "AFLplusplus",
        "avatar_url": "https://avatars.githubusercontent.com/u/62360046?v=4"
      },
      "readme": "# American Fuzzy Lop plus plus (AFL++)\n\n<img align=\"right\" src=\"https://raw.githubusercontent.com/AFLplusplus/Website/main/static/aflpp_bg.svg\" alt=\"AFL++ logo\" width=\"250\" height=\"250\">\n\nRelease version: [4.35c](https://github.com/AFLplusplus/AFLplusplus/releases)\n\nGitHub version: 4.36a\n\nRepository:\n[https://github.com/AFLplusplus/AFLplusplus](https://github.com/AFLplusplus/AFLplusplus)\n\nAFL++ is maintained by:\n\n* Marc \"van Hauser\" Heuse <mh@mh-sec.de>\n* Dominik Maier <mail@dmnk.co>\n* Andrea Fioraldi <andreafioraldi@gmail.com>\n* Heiko \"hexcoder-\" Eissfeldt <heiko.eissfeldt@hexco.de>\n* frida_mode is maintained by @Worksbutnottested\n\nOriginally developed by Michal \"lcamtuf\" Zalewski.\n\nAFL++ is a superior fork to Google's AFL - more speed, more and better\nmutations, more and better instrumentation, custom module support, etc.\n\nYou are free to copy, modify, and distribute AFL++ with attribution under the\nterms of the Apache-2.0 License. See the [LICENSE](LICENSE) for details.\n\n## Getting started\n\nHere is some information to get you started:\n\n* For an overview of the AFL++ documentation and a very helpful graphical guide,\n  please visit [docs/README.md](docs/README.md).\n* To get you started with tutorials, go to\n  [docs/tutorials.md](docs/tutorials.md).\n* For releases, see the\n  [Releases tab](https://github.com/AFLplusplus/AFLplusplus/releases) and\n  [branches](#branches). The best branches to use are, however, `stable` or\n  `dev` - depending on your risk appetite. Also take a look at the list of\n  [important changes in AFL++](docs/important_changes.md) and the list of\n  [features](docs/features.md).\n* If you want to use AFL++ for your academic work, check the\n  [papers page](https://aflplus.plus/papers/) on the website.\n* To cite our work, look at the [Cite](#cite) section.\n* For comparisons, use the fuzzbench `aflplusplus` setup, or use\n  `afl-clang-fast` with `AFL_LLVM_CMPLOG=1`. You can find the `aflplusplus`\n  default configuration on Google's\n  [fuzzbench](https://github.com/google/fuzzbench/tree/master/fuzzers/aflplusplus).\n\n## Building and installing AFL++\n\nTo have AFL++ easily available with everything compiled, pull the image directly\nfrom the Docker Hub (available for both x86_64 and arm64):\n\n```shell\ndocker pull aflplusplus/aflplusplus\ndocker run -ti -v /location/of/your/target:/src aflplusplus/aflplusplus\n```\n\nThis image is automatically published when a push to the stable branch happens\n(see [branches](#branches)). If you use the command above, you will find your\ntarget source code in `/src` in the container.\n\nNote: you can also pull `aflplusplus/aflplusplus:dev` which is the most current\ndevelopment state of AFL++.\n\nTo build AFL++ yourself - *which we recommend* - continue at\n[docs/INSTALL.md](docs/INSTALL.md).\n\n## Quick start: Fuzzing with AFL++\n\n*NOTE: Before you start, please read about the\n[common sense risks of fuzzing](docs/fuzzing_in_depth.md#0-common-sense-risks).*\n\nThis is a quick start for fuzzing targets with the source code available. To\nread about the process in detail, see\n[docs/fuzzing_in_depth.md](docs/fuzzing_in_depth.md).\n\nTo learn about fuzzing other targets, see:\n* Binary-only targets:\n  [docs/fuzzing_binary-only_targets.md](docs/fuzzing_binary-only_targets.md)\n* Network services:\n  [docs/best_practices.md#fuzzing-a-network-service](docs/best_practices.md#fuzzing-a-network-service)\n* GUI programs:\n  [docs/best_practices.md#fuzzing-a-gui-program](docs/best_practices.md#fuzzing-a-gui-program)\n\nStep-by-step quick start:\n\n1. Compile the program or library to be fuzzed using `afl-cc`. A common way to\n   do this would be:\n\n   ```\n   CC=/path/to/afl-cc CXX=/path/to/afl-c++ ./configure --disable-shared\n   make clean all\n   ```\n\n2. Get a small but valid input file that makes sense to the program. When\n   fuzzing verbose syntax (SQL, HTTP, etc.), create a dictionary as described in\n   [dictionaries/README.md](dictionaries/README.md), too.\n\n3. If the program reads from stdin, run `afl-fuzz` like so:\n\n   ```\n   ./afl-fuzz -i seeds_dir -o output_dir -- \\\n   /path/to/tested/program [...program's cmdline...]\n   ```\n\n   To add a dictionary, add `-x /path/to/dictionary.txt` to afl-fuzz.\n\n   If the program takes input from a file, you can put `@@` in the program's\n   command line; AFL++ will put an auto-generated file name in there for you.\n\n4. Investigate anything shown in red in the fuzzer UI by promptly consulting\n   [docs/afl-fuzz_approach.md#understanding-the-status-screen](docs/afl-fuzz_approach.md#understanding-the-status-screen).\n\n5. You will find found crashes and hangs in the subdirectories `crashes/` and\n   `hangs/` in the `-o output_dir` directory. You can replay the crashes by\n   feeding them to the target, e.g. if your target is using stdin:\n\n   ```\n   cat output_dir/crashes/id:000000,* | /path/to/tested/program [...program's cmdline...]\n   ```\n\n   You can generate cores or use gdb directly to follow up the crashes.\n\n6. We cannot stress this enough - if you want to fuzz effectively, read the\n   [docs/fuzzing_in_depth.md](docs/fuzzing_in_depth.md) document!\n\n## Contact\n\nQuestions? Concerns? Bug reports?\n\n* The contributors can be reached via (e.g., by creating an issue):\n  [https://github.com/AFLplusplus/AFLplusplus](https://github.com/AFLplusplus/AFLplusplus).\n* Take a look at our [FAQ](docs/FAQ.md). If you find an interesting or important\n  question missing, submit it via\n  [https://github.com/AFLplusplus/AFLplusplus/discussions](https://github.com/AFLplusplus/AFLplusplus/discussions).\n* Best: join the [Awesome Fuzzing](https://discord.gg/gCraWct) Discord server.\n* There is a (not really used) mailing list for the AFL/AFL++ project\n  ([browse archive](https://groups.google.com/group/afl-users)). To compare\n  notes with other users or to get notified about major new features, send an\n  email to <afl-users+subscribe@googlegroups.com>, but note that this is not\n  managed by us.\n\n## Branches\n\nThe following branches exist:\n\n* [release](https://github.com/AFLplusplus/AFLplusplus/tree/release): the latest\n  release\n* [stable/trunk](https://github.com/AFLplusplus/AFLplusplus/): stable state of\n  AFL++ - it is synced from dev from time to time when we are satisfied with its\n  stability\n* [dev](https://github.com/AFLplusplus/AFLplusplus/tree/dev): development state\n  of AFL++ - bleeding edge and you might catch a checkout which does not compile\n  or has a bug. **We only accept PRs (pull requests) for the 'dev' branch!**\n* (any other): experimental branches to work on specific features or testing new\n  functionality or changes.\n\n## Help wanted\n\nWe have several [ideas](docs/ideas.md) we would like to see in AFL++ to make it\neven better. However, we already work on so many things that we do not have the\ntime for all the big ideas.\n\nThis can be your way to support and contribute to AFL++ - extend it to do\nsomething cool.\n\nFor everyone who wants to contribute (and send pull requests), please read our\n[contributing guidelines](CONTRIBUTING.md) before you submit.\n\n## Special thanks\n\nMany of the improvements to the original AFL and AFL++ wouldn't be possible\nwithout feedback, bug reports, or patches from our contributors.\n\nThank you! (For people sending pull requests - please add yourself to this list\n:-)\n\n<details>\n\n  <summary>List of contributors</summary>\n\n  ```\n    Jann Horn                             Hanno Boeck\n    Felix Groebert                        Jakub Wilk\n    Richard W. M. Jones                   Alexander Cherepanov\n    Tom Ritter                            Hovik Manucharyan\n    Sebastian Roschke                     Eberhard Mattes\n    Padraig Brady                         Ben Laurie\n    @dronesec                             Luca Barbato\n    Tobias Ospelt                         Thomas Jarosch\n    Martin Carpenter                      Mudge Zatko\n    Joe Zbiciak                           Ryan Govostes\n    Michael Rash                          William Robinet\n    Jonathan Gray                         Filipe Cabecinhas\n    Nico Weber                            Jodie Cunningham\n    Andrew Griffiths                      Parker Thompson\n    Jonathan Neuschaefer                  Tyler Nighswander\n    Ben Nagy                              Samir Aguiar\n    Aidan Thornton                        Aleksandar Nikolich\n    Sam Hakim                             Laszlo Szekeres\n    David A. Wheeler                      Turo Lamminen\n    Andreas Stieger                       Richard Godbee\n    Louis Dassy                           teor2345\n    Alex Moneger                          Dmitry Vyukov\n    Keegan McAllister                     Kostya Serebryany\n    Richo Healey                          Martijn Bogaard\n    rc0r                                  Jonathan Foote\n    Christian Holler                      Dominique Pelle\n    Jacek Wielemborek                     Leo Barnes\n    Jeremy Barnes                         Jeff Trull\n    Guillaume Endignoux                   ilovezfs\n    Daniel Godas-Lopez                    Franjo Ivancic\n    Austin Seipp                          Daniel Komaromy\n    Daniel Binderman                      Jonathan Metzman\n    Vegard Nossum                         Jan Kneschke\n    Kurt Roeckx                           Marcel Boehme\n    Van-Thuan Pham                        Abhik Roychoudhury\n    Joshua J. Drake                       Toby Hutton\n    Rene Freingruber                      Sergey Davidoff\n    Sami Liedes                           Craig Young\n    Andrzej Jackowski                     Daniel Hodson\n    Nathan Voss                           Dominik Maier\n    Andrea Biondo                         Vincent Le Garrec\n    Khaled Yakdan                         Kuang-che Wu\n    Josephine Calliotte                   Konrad Welc\n    Thomas Rooijakkers                    David Carlier\n    Ruben ten Hove                        Joey Jiao\n    fuzzah                                @intrigus-lgtm\n    Yaakov Saxon                          Sergej Schumilo\n    Ziqiao Kong                           Ryan Berger\n    Sangjun Park                          Scott Guest\n    Fabian Keil\n  ```\n\n</details>\n\n## Cite\n\nIf you use AFL++ in scientific work, consider citing\n[our paper](https://www.usenix.org/conference/woot20/presentation/fioraldi)\npresented at WOOT'20:\n\n    Andrea Fioraldi, Dominik Maier, Heiko EiÃŸfeldt, and Marc Heuse. â€œAFL++: Combining incremental steps of fuzzing researchâ€. In 14th USENIX Workshop on Offensive Technologies (WOOT 20). USENIX Association, Aug. 2020.\n\n<details>\n\n<summary>BibTeX</summary>\n\n  ```bibtex\n  @inproceedings {AFLplusplus-Woot20,\n  author = {Andrea Fioraldi and Dominik Maier and Heiko Ei{\\ss}feldt and Marc Heuse},\n  title = {{AFL++}: Combining Incremental Steps of Fuzzing Research},\n  booktitle = {14th {USENIX} Workshop on Offensive Technologies ({WOOT} 20)},\n  year = {2020},\n  publisher = {{USENIX} Association},\n  month = aug,\n  }\n  ```\n\n</details>\n\n[![zread](https://img.shields.io/badge/Ask_Zread-_.svg?style=flat&color=00b0aa&labelColor=000000&logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTQuOTYxNTYgMS42MDAxSDIuMjQxNTZDMS44ODgxIDEuNjAwMSAxLjYwMTU2IDEuODg2NjQgMS42MDE1NiAyLjI0MDFWNC45NjAxQzEuNjAxNTYgNS4zMTM1NiAxLjg4ODEgNS42MDAxIDIuMjQxNTYgNS42MDAxSDQuOTYxNTZDNS4zMTUwMiA1LjYwMDEgNS42MDE1NiA1LjMxMzU2IDUuNjAxNTYgNC45NjAxVjIuMjQwMUM1LjYwMTU2IDEuODg2NjQgNS4zMTUwMiAxLjYwMDEgNC45NjE1NiAxLjYwMDFaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00Ljk2MTU2IDEwLjM5OTlIMi4yNDE1NkMxLjg4ODEgMTAuMzk5OSAxLjYwMTU2IDEwLjY4NjQgMS42MDE1NiAxMS4wMzk5VjEzLjc1OTlDMS42MDE1NiAxNC4xMTM0IDEuODg4MSAxNC4zOTk5IDIuMjQxNTYgMTQuMzk5OUg0Ljk2MTU2QzUuMzE1MDIgMTQuMzk5OSA1LjYwMTU2IDE0LjExMzQgNS42MDE1NiAxMy43NTk5VjExLjAzOTlDNS42MDE1NiAxMC42ODY0IDUuMzE1MDIgMTAuMzk5OSA0Ljk2MTU2IDEwLjM5OTlaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik0xMy43NTg0IDEuNjAwMUgxMS4wMzg0QzEwLjY4NSAxLjYwMDEgMTAuMzk4NCAxLjg4NjY0IDEwLjM5ODQgMi4yNDAxVjQuOTYwMUMxMC4zOTg0IDUuMzEzNTYgMTAuNjg1IDUuNjAwMSAxMS4wMzg0IDUuNjAwMUgxMy43NTg0QzE0LjExMTkgNS42MDAxIDE0LjM5ODQgNS4zMTM1NiAxNC4zOTg0IDQuOTYwMVYyLjI0MDFDMTQuMzk4NCAxLjg4NjY0IDE0LjExMTkgMS42MDAxIDEzLjc1ODQgMS42MDAxWiIgZmlsbD0iI2ZmZiIvPgo8cGF0aCBkPSJNNCAxMkwxMiA0TDQgMTJaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00IDEyTDEyIDQiIHN0cm9rZT0iI2ZmZiIgc3Ryb2tlLXdpZHRoPSIxLjUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIvPgo8L3N2Zz4K&logoColor=ffffff)](https://zread.ai/AFLplusplus/AFLplusplus)\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/AFLplusplus/AFLplusplus)\n",
      "stars_today": 3
    },
    {
      "id": 153316914,
      "name": "BehaviorTree.CPP",
      "full_name": "BehaviorTree/BehaviorTree.CPP",
      "description": "Behavior Trees Library in C++. Batteries included.",
      "html_url": "https://github.com/BehaviorTree/BehaviorTree.CPP",
      "stars": 3801,
      "forks": 799,
      "language": "C++",
      "topics": [
        "ai",
        "behaviortree",
        "coordination",
        "games",
        "robotics",
        "ros",
        "state-machine"
      ],
      "created_at": "2018-10-16T16:19:58Z",
      "updated_at": "2026-02-06T14:03:18Z",
      "pushed_at": "2026-02-05T12:10:13Z",
      "open_issues": 28,
      "owner": {
        "login": "BehaviorTree",
        "avatar_url": "https://avatars.githubusercontent.com/u/44158496?v=4"
      },
      "readme": "![License MIT](https://img.shields.io/github/license/BehaviorTree/BehaviorTree.CPP?color=blue)\n[![conan Ubuntu](https://github.com/BehaviorTree/BehaviorTree.CPP/actions/workflows/cmake_ubuntu.yml/badge.svg)](https://github.com/BehaviorTree/BehaviorTree.CPP/actions/workflows/cmake_ubuntu.yml)\n[![conan Windows](https://github.com/BehaviorTree/BehaviorTree.CPP/actions/workflows/cmake_windows.yml/badge.svg)](https://github.com/BehaviorTree/BehaviorTree.CPP/actions/workflows/cmake_windows.yml)\n[![ros2](https://github.com/BehaviorTree/BehaviorTree.CPP/actions/workflows/ros2.yaml/badge.svg)](https://github.com/BehaviorTree/BehaviorTree.CPP/actions/workflows/ros2.yaml)\n[![pixi (Conda)](https://github.com/BehaviorTree/BehaviorTree.CPP/actions/workflows/pixi.yaml/badge.svg)](https://github.com/BehaviorTree/BehaviorTree.CPP/actions/workflows/pixi.yaml)\n[![Coverage Status](https://coveralls.io/repos/github/BehaviorTree/BehaviorTree.CPP/badge.svg?branch=master)](https://coveralls.io/github/BehaviorTree/BehaviorTree.CPP?branch=master)\n\n# BehaviorTree.CPP 4.8\n\n<p align=\"center\"><img width=350 src=\"animated.svg\"></p>\n\nThis  __C++ 17__ library provides a framework to create BehaviorTrees.\nIt was designed to be flexible, easy to use, reactive and fast.\n\nEven if our main use-case is __robotics__, you can use this library to build\n__AI for games__, or to replace Finite State Machines.\n\nThere are a few features that make __BehaviorTree.CPP__ unique, when compared to other implementations:\n\n- It makes __asynchronous Actions__, i.e. non-blocking, a first-class citizen.\n\n- You can build __reactive__ behaviors that execute multiple Actions concurrently (orthogonality).\n\n- Trees are defined using a Domain Specific __scripting language__ (based on XML), and can be loaded at run-time; in other words, even if written in C++, the morphology of the Trees is _not_ hard-coded.\n\n- You can statically link your custom TreeNodes or convert them into __plugins__\nand load them at run-time.\n\n- It provides a type-safe and flexible mechanism to do __Dataflow__ between\n  Nodes of the Tree.\n\n- It includes a __logging/profiling__ infrastructure that allows the user\nto visualize, record, replay, and analyze state transitions.\n\n## Documentation\n\n- **Tutorials and general documentation**: https://www.behaviortree.dev/\n- **Auto-generated Doxygen**: https://behaviortree.github.io/BehaviorTree.CPP/\n- **Community support and forum**: https://github.com/BehaviorTree/BehaviorTree.CPP/discussions\n\n# GUI Editor\n\nEditing a BehaviorTree is as simple as editing an XML file in your favorite text editor.\n\nIf you are looking for a fancier graphical user interface (and I know you do) check\n[Groot2](https://www.behaviortree.dev/groot) out.\n\n![Groot screenshot](docs/groot-screenshot.png)\n\n# How to compile\n\n**BT.CPP** requires a compiler that supports C++17.\n\nThree build systems are supported:\n\n- **colcon (ament)**, if you use ROS2\n- **conan** otherwise (Linux/Windows).\n- **straight cmake** if you want to be personally responsible for dependencies :)\n\nCompiling with [conan](https://conan.io/):\n\n> [!NOTE]\n> Conan builds require CMake 3.23 or newer.\n\nAssuming that you are in the **root** directory of `BehaviorTree.CPP`:\n\n```\nconan install . -s build_type=Release --build=missing\ncmake --preset conan-release\ncmake --build --preset conan-release\n```\n\nIf you have dependencies such as ZeroMQ and SQlite already installed and you don't want to\nuse conan, simply type:\n\n```\nmkdir build_release\ncmake -S . -B build_release\ncmake --build build_release --parallel\n```\n\nIf you want to build in a [pixi](https://pixi.sh/) project (conda virtual environment).\n```\npixi run build\n```\n\nIf you want to use BT.CPP in your application, please refer to the\nexample here: https://github.com/BehaviorTree/btcpp_sample .\n\n## Installing BehaviorTree.CPP (vcpkg)\n\nAlternatively, you can build and install behaviortree-cpp using [vcpkg](https://github.com/Microsoft/vcpkg/) dependency manager:\n\n    git clone https://github.com/Microsoft/vcpkg.git\n    cd vcpkg\n    ./bootstrap-vcpkg.sh\n    ./vcpkg integrate install\n    ./vcpkg install behaviortree-cpp\n\nThe behaviortree-cpp port in vcpkg is kept up to date by Microsoft team members and community contributors. If the version is out of date, please [create an issue or pull request](https://github.com/Microsoft/vcpkg) on the vcpkg repository.\n\n#  Commercial support\n\nAre you using BT.CPP in your commercial product, and do you need technical support / consulting?\nYou can contact the primary author, **dfaconti@aurynrobotics.com**, to discuss your use case and needs.\n\n## Previous version\n\nVersion 3.8 of the software can be found in the branch\n[v3.8](https://github.com/BehaviorTree/BehaviorTree.CPP/tree/v3.8).\n\nThat branch might receive bug fixes, but the new features will be implemented\nonly in the master branch.\n\n# Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=BehaviorTree/BehaviorTree.CPP&type=Date)](https://star-history.com/#BehaviorTree/BehaviorTree.CPP&Date)\n\n# Contributors\n\n<a href=\"https://github.com/BehaviorTree/BehaviorTree.CPP/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=BehaviorTree/BehaviorTree.CPP\" />\n</a>\n\n# License\n\nThe MIT License (MIT)\n\nCopyright (c) 2019-2025 Davide Faconti\n\nCopyright (c) 2018-2019 Davide Faconti, Eurecat\n\nCopyright (c) 2014-2018 Michele Colledanchise\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n",
      "stars_today": 3
    },
    {
      "id": 11457947,
      "name": "dependency-track",
      "full_name": "DependencyTrack/dependency-track",
      "description": "Dependency-Track is an intelligent Component Analysis platform that allows organizations to identify and reduce risk in the software supply chain.",
      "html_url": "https://github.com/DependencyTrack/dependency-track",
      "stars": 3583,
      "forks": 710,
      "language": "Java",
      "topics": [
        "appsec",
        "bill-of-materials",
        "bom",
        "component-analysis",
        "cyclonedx",
        "devsecops",
        "hacktoberfest",
        "nvd",
        "ossindex",
        "owasp",
        "package-url",
        "purl",
        "sbom",
        "sca",
        "security",
        "security-automation",
        "software-composition-analysis",
        "software-security",
        "vulnerabilities",
        "vulnerability-detection"
      ],
      "created_at": "2013-07-16T19:16:43Z",
      "updated_at": "2026-02-06T22:11:24Z",
      "pushed_at": "2026-02-06T22:11:19Z",
      "open_issues": 1026,
      "owner": {
        "login": "DependencyTrack",
        "avatar_url": "https://avatars.githubusercontent.com/u/40258585?v=4"
      },
      "readme": "[![Build Status](https://github.com/DependencyTrack/dependency-track/actions/workflows/ci-build.yaml/badge.svg)](https://github.com/DependencyTrack/dependency-track/actions?workflow=CI+Build)\n[![Codacy Badge](https://app.codacy.com/project/badge/Grade/b2ecd06dab57438a9a55bc4a71c5a8ce)](https://www.codacy.com/gh/DependencyTrack/dependency-track/dashboard?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=DependencyTrack/dependency-track&amp;utm_campaign=Badge_Grade)\n[![Alpine](https://img.shields.io/badge/built%20on-Alpine-blue.svg)](https://github.com/stevespringett/Alpine)\n[![License][license-image]][Apache License 2.0]\n[![OWASP Flagship](https://img.shields.io/badge/owasp-flagship%20project-orange.svg)](https://www.owasp.org/index.php/OWASP_Dependency_Track_Project)\n[![Website](https://img.shields.io/badge/https://-dependencytrack.org-blue.svg)](https://dependencytrack.org/)\n[![Documentation](https://img.shields.io/badge/read-documentation-blue.svg)](https://docs.dependencytrack.org/)\n[![Slack](https://img.shields.io/badge/chat%20on-slack-46BC99.svg)](https://dependencytrack.org/slack)\n[![Group Discussion](https://img.shields.io/badge/discussion-groups.io-blue.svg)](https://dependencytrack.org/discussion)\n[![YouTube Subscribe](https://img.shields.io/badge/youtube-subscribe-%23c4302b.svg)](https://dependencytrack.org/youtube)\n[![Twitter](https://img.shields.io/twitter/follow/dependencytrack.svg?label=Follow&style=social)](https://twitter.com/dependencytrack)\n[![Downloads](https://img.shields.io/github/downloads/DependencyTrack/dependency-track/total.svg)](https://github.com/DependencyTrack/dependency-track/releases)\n[![Latest](https://img.shields.io/github/release/DependencyTrack/dependency-track.svg)](https://github.com/DependencyTrack/dependency-track/releases)\n[![Pulls - API Server](https://img.shields.io/docker/pulls/dependencytrack/apiserver.svg?label=Docker%20Pulls%20%28API%20Server%29)](https://hub.docker.com/r/dependencytrack/apiserver/)\n[![Pulls - Frontend](https://img.shields.io/docker/pulls/dependencytrack/frontend.svg?label=Docker%20Pulls%20%28Frontend%29)](https://hub.docker.com/r/dependencytrack/frontend/)\n[![Pulls - Bundled](https://img.shields.io/docker/pulls/dependencytrack/bundled.svg?label=Docker%20Pulls%20%28Bundled%29)](https://hub.docker.com/r/dependencytrack/bundled/)\n[![Pulls - Legacy](https://img.shields.io/docker/pulls/owasp/dependency-track.svg?label=Docker%20Pulls%20%28OWASP%20Legacy%29)](https://hub.docker.com/r/owasp/dependency-track/)\n\n![logo preview](https://raw.githubusercontent.com/DependencyTrack/branding/master/dt-logo.svg?sanitize=true)\n\n\nDependency-Track is an intelligent [Component Analysis] platform that allows organizations to\nidentify and reduce risk in the software supply chain. Dependency-Track takes a unique\nand highly beneficial approach by leveraging the capabilities of [Software Bill of Materials] (SBOM). This approach\nprovides capabilities that traditional Software Composition Analysis (SCA) solutions cannot achieve.\n\nDependency-Track monitors component usage across all versions of every application in its portfolio in order to\nproactively identify risk across an organization. The platform has an API-first design and is ideal for use in\nCI/CD environments.\n\n## Ecosystem Overview\n![alt text](./docs/images/integrations.png)\n\n## Features\n* Consumes and produces [CycloneDX] Software Bill of Materials (SBOM)\n* Consumes and produces [CycloneDX Vulnerability Exploitability Exchange (VEX)](https://cyclonedx.org/capabilities/vex/)\n* Component support for:\n  * Applications\n  * Libraries\n  * Frameworks\n  * Operating systems\n  * Containers\n  * Firmware\n  * Files\n  * Hardware\n  * Services\n* Tracks component usage across every application in an organizations portfolio\n* Quickly identify what is affected, and where\n* Identifies multiple forms of risk including\n  * Components with known vulnerabilities\n  * Out-of-date components\n  * Modified components\n  * License risk\n  * More coming soon...\n* Integrates with multiple sources of vulnerability intelligence including:\n  * [National Vulnerability Database] (NVD)\n  * [GitHub Advisories]\n  * [Sonatype OSS Index]\n  * [Snyk]\n  * [Trivy]\n  * [OSV]\n  * [VulnDB] from [Risk Based Security]\n  * More coming soon.\n* Helps to prioritize mitigation by incorporating support for the [Exploit Prediction Scoring System (EPSS)](https://www.first.org/epss/)\n* Maintain a private vulnerability database of vulnerability components\n* Robust policy engine with support for global and per-project policies\n  * Security risk and compliance\n  * License risk and compliance\n  * Operational risk and compliance\n* Ecosystem agnostic with built-in repository support for:\n  * Cargo (Rust)\n  * Composer (PHP)\n  * Gems (Ruby)\n  * Hex (Erlang/Elixir)\n  * Maven (Java)\n  * NPM (Javascript)\n  * CPAN (Perl)\n  * NuGet (.NET)\n  * PyPI (Python)\n  * More coming soon.\n* Identifies APIs and external service components including:\n  * Service provider\n  * Endpoint URIs\n  * Data classification\n  * Directional flow of data\n  * Trust boundary traversal\n  * Authentication requirements\n* Includes a comprehensive auditing workflow for triaging results\n* Configurable notifications supporting Slack, Microsoft Teams, Mattermost, Webhooks, Webex, Email and Jira\n* Supports standardized SPDX license IDâ€™s and tracks license use by component\n* Easy to read metrics for components, projects, and portfolio\n* Native support for Kenna Security, Fortify SSC, ThreadFix, and DefectDojo\n* API-first design facilitates easy integration with other systems\n* API documentation available in OpenAPI format\n* OAuth 2.0 + OpenID Connect (OIDC) support for single sign-on (authN/authZ)\n* Supports internally managed users, Active Directory/LDAP, and API Keys\n* Simple to install and configure. Get up and running in just a few minutes\n\n\n<hr>\n\n![alt text](./docs/images/screenshots/dashboard.png)\n\n### Quickstart (Docker Compose)\n\n```bash\n# Downloads the latest Docker Compose file\ncurl -LO https://dependencytrack.org/docker-compose.yml\n\n# Starts the stack using Docker Compose\ndocker compose up -d\n```\n\n### Quickstart (Docker Swarm)\n\n```bash\n# Downloads the latest Docker Compose file\ncurl -LO https://dependencytrack.org/docker-compose.yml\n\n# Initializes Docker Swarm (if not previously initialized)\ndocker swarm init\n\n# Starts the stack using Docker Swarm\ndocker stack deploy -c docker-compose.yml dtrack\n```\n\n### Quickstart (Manual Execution)\n\n```bash\n# Pull the image from the Docker Hub OWASP repo\ndocker pull dependencytrack/bundled\n\n# Creates a dedicated volume where data can be stored outside the container\ndocker volume create --name dependency-track\n\n# Run the bundled container with 8GB RAM on port 8080\ndocker run -d -m 8192m -p 8080:8080 --name dependency-track -v dependency-track:/data dependencytrack/bundled\n```\n\n**NOTICE: Always use official binary releases in production.**\n\n## Distributions\n\nDependency-Track has three distribution variants. They are:\n\n| Package    | Package Format          | Recommended | Supported | Docker | Download |\n|:-----------|:------------------------|:-----------:|:---------:|:------:|:--------:|\n| API Server | Executable WAR          |      âœ…      |     âœ…     |   âœ…    |    âœ…     |\n| Frontend   | Single Page Application |      âœ…      |     âœ…     |   âœ…    |    âœ…     |\n| Bundled    | Executable WAR          |      âŒ      |    â˜‘ï¸     |   âœ…    |    âœ…     |\n\n#### API Server\n\nThe API Server contains an embedded Jetty server and all server-side functionality, but excludes the frontend user\ninterface. This variant is new as of Dependency-Track v4.0.\n\n#### Frontend\n\nThe [Frontend](https://github.com/DependencyTrack/frontend) is the user interface that is accessible in a web browser. The Frontend is a Single Page Application (SPA)\nthat can be deployed independently of the Dependency-Track API Server. This variant is new as of Dependency-Track v3.8.\n\n#### Bundled\n\nThe Bundled variant combines the API Server and the Frontend user interface. This variant was previously referred to as\nthe executable war and was the preferred distribution from Dependency-Track v3.0 - v3.8. This variant is supported but\ndeprecated and will be discontinued in a future release.\n\n#### Traditional\n\nThe Traditional variant combines the API Server and the Frontend user interface and must be deployed to a Servlet\ncontainer. This variant is not supported, deprecated, and will be discontinued in a future release.\n\n## Deploying on Kubernetes with Helm\n\nRefer to https://github.com/DependencyTrack/helm-charts.\n\n## Contributing\n\nInterested in contributing to Dependency-Track? Please check [`CONTRIBUTING.md`](./CONTRIBUTING.md) to see how you can help!\n\n## Resources\n\n* Website: <https://dependencytrack.org/>\n* Documentation: <https://docs.dependencytrack.org/>\n* Component Analysis: <https://owasp.org/www-community/Component_Analysis>\n\n## Community\n\n* Twitter: <https://dependencytrack.org/twitter>\n* YouTube: <https://dependencytrack.org/youtube>\n* Slack: <https://dependencytrack.org/slack> (Invite:  <https://dependencytrack.org/slack/invite>)\n* Discussion (Groups.io): <https://dependencytrack.org/discussion>\n\n## Copyright & License\nDependency-Track is Copyright (c) OWASP Foundation. All Rights Reserved.\n\nPermission to modify and redistribute is granted under the terms of the\n[Apache License 2.0].\n\nDependency-Track makes use of several other open source libraries. Please see\nthe [notices] file for more information.\n\n  [National Vulnerability Database]: https://nvd.nist.gov\n  [GitHub Advisories]: https://www.github.com/advisories\n  [Sonatype OSS Index]: https://ossindex.sonatype.org\n  [Snyk]: https://snyk.io\n  [Trivy]: https://www.aquasec.com/products/trivy/\n  [OSV]: https://osv.dev\n  [VulnDB]: https://vulndb.flashpoint.io\n  [Risk Based Security]: https://www.riskbasedsecurity.com\n  [Component Analysis]: https://owasp.org/www-community/Component_Analysis\n  [Software Bill of Materials]: https://owasp.org/www-community/Component_Analysis#software-bill-of-materials-sbom\n  [CycloneDX]: https://cyclonedx.org\n  [license-image]: https://img.shields.io/badge/license-apache%20v2-brightgreen.svg\n  [Apache License 2.0]: https://github.com/DependencyTrack/dependency-track/blob/master/LICENSE.txt\n  [notices]: https://github.com/DependencyTrack/dependency-track/blob/master/NOTICES.txt\n  [Alpine]: https://github.com/stevespringett/Alpine\n",
      "stars_today": 3
    },
    {
      "id": 982577878,
      "name": "nav3-recipes",
      "full_name": "android/nav3-recipes",
      "description": "Implement common use cases with Jetpack Navigation 3",
      "html_url": "https://github.com/android/nav3-recipes",
      "stars": 1140,
      "forks": 118,
      "language": "Kotlin",
      "topics": [
        "android",
        "compose",
        "navigation"
      ],
      "created_at": "2025-05-13T05:23:51Z",
      "updated_at": "2026-02-06T18:14:10Z",
      "pushed_at": "2026-02-06T20:57:18Z",
      "open_issues": 48,
      "owner": {
        "login": "android",
        "avatar_url": "https://avatars.githubusercontent.com/u/32689599?v=4"
      },
      "readme": "# Navigation 3 - Code recipes\n[Jetpack Navigation 3](https://goo.gle/nav3) is a library for app navigation. This repository contains recipes for how to\nuse its APIs to implement common navigation use cases. Each recipe introduces a single concept. Instead\nof making existing recipes more complex, there should be a new recipe for that particular concept.\n\nEvery Navigation 3 release will be an opportunity for patterns you see in recipes to \"graduate\" and become\n(optional) helpers in the library itself. Then we'll update the recipe to use that prebuilt helper, thus\nensuring that the recipes continue to be a good way to approach these kinds of problems.\n\nRecipes on the `main` branch use the **latest** (which may be an alpha or snapshot) version of Nav3. For recipes that use **stable** versions, check the [releases page](https://github.com/android/nav3-recipes/releases).\n\n## Recipes\nThese are the recipes and what they demonstrate.\n\n### Basic API usage\n- **[Basic](app/src/main/java/com/example/nav3recipes/basic)**: Shows most basic API usage.\n- **[Saveable back stack](app/src/main/java/com/example/nav3recipes/basicsaveable)**: As above, with a persistent back stack.\n- **[Entry provider DSL](app/src/main/java/com/example/nav3recipes/basicdsl)**: As above, using the entryProvider DSL.\n\n### Deep links\nRead the [guide to deeplinking](docs/deeplink-guide.md). Upvote [this issue](https://issuetracker.google.com/470282247) if you would like an API for deeplinks.\n- **[Basic](app/src/main/java/com/example/nav3recipes/deeplink/basic)**: Shows how to parse a deep link URL from an Android Intent into a navigation key.\n- **[Advanced](app/src/main/java/com/example/nav3recipes/deeplink/advanced)**: Shows how to handle deep links with a synthetic back stack and correct \"Up\" navigation behavior.\n\n### Scenes\n#### Use built-in Scenes\n- **[Dialog](app/src/main/java/com/example/nav3recipes/dialog)**: Shows how to create a Dialog.\n\n#### Create custom Scenes\n- **[BottomSheet](app/src/main/java/com/example/nav3recipes/bottomsheet)**: Shows how to create a BottomSheet destination.\n- **[List-Detail Scene](app/src/main/java/com/example/nav3recipes/scenes/listdetail)**: Shows how to create a custom, list-detail layout using a `Scene` and `SceneStrategy` (see video of UI behavior below).\n- **[Two pane Scene](app/src/main/java/com/example/nav3recipes/scenes/twopane)**: Shows how to create a custom, 2-pane layout.\n\n#### Use Material Scenes\nExamples showing how to use the layouts provided by the [Compose Material3 Adaptive Navigation3 library](https://developer.android.com/jetpack/androidx/releases/compose-material3-adaptive#compose_material3_adaptive_navigation3_version_10_2)\n- **[List-Detail](app/src/main/java/com/example/nav3recipes/material/listdetail)**: Shows how to use a Material adaptive list-detail layout.\n- **[Supporting Pane](app/src/main/java/com/example/nav3recipes/material/supportingpane)**: Shows how to use a Material adaptive supporting pane layout.\n\nNote: If you find a bug or have a feature request for Material3 Adaptive Scenes [please file it here](https://issuetracker.google.com/issues/new?component=1467081). Don't file an issue on this repository.\n\n### Animations\n- **[Animations](app/src/main/java/com/example/nav3recipes/animations)**: Shows how to override the default animations for all destinations and a single destination.\n\n### Common back stack behavior\n- **[Common navigation UI](app/src/main/java/com/example/nav3recipes/commonui)**: A common navigation toolbar where each item in the toolbar navigates to a top level destination.\n- **[Multiple back stacks](app/src/main/java/com/example/nav3recipes/multiplestacks)**: Shows how to create multiple top level routes, each with its own back stack. Top level routes are displayed in a navigation bar allowing users to switch between them. State is retained for each top level route, and the navigation state persists config changes and process death.\n\n### Conditional navigation\n- **[Conditional navigation](app/src/main/java/com/example/nav3recipes/conditional)**: Switch to a different navigation flow when a condition is met. For example, for authentication or first-time user onboarding.\n\n### Architecture\n- **[Hilt - Modularized navigation code](app/src/main/java/com/example/nav3recipes/modular/hilt)**: Demonstrates how to decouple navigation code into separate modules (uses Dagger/Hilt for DI).\n- **[Koin - Modularized navigation code](app/src/main/java/com/example/nav3recipes/modular/koin)**: Demonstrates how to decouple navigation code into separate modules (uses Koin for DI).\n\n### Working with ViewModels\n#### Passing navigation arguments\n- **[Basic ViewModel](app/src/main/java/com/example/nav3recipes/passingarguments/viewmodels/basic)**: Navigation arguments are passed to a ViewModel constructed using `viewModel()`\n- **[Hilt injected ViewModel](app/src/main/java/com/example/nav3recipes/passingarguments/viewmodels/hilt)**: Navigation arguments are passed to a ViewModel constructed using `hiltViewModel()`\n- **[Koin injected ViewModel](app/src/main/java/com/example/nav3recipes/passingarguments/viewmodels/koin)**: Navigation arguments are passed to a ViewModel constructed using `koinViewModel()`\n\n#### Sharing a ViewModel between screens\n- **[Shared ViewModel](app/src/main/java/com/example/nav3recipes/sharedviewmodel)**: Demonstrates how to share a `ViewModel` between different screens (entries) in Navigation 3 using a custom `NavEntryDecorator`.\n\n### Returning Results\n- **[Returning Results as Events](app/src/main/java/com/example/nav3recipes/results/event)**: Returning results as events to content in another NavEntry.\n- **[Returning Results as State](app/src/main/java/com/example/nav3recipes/results/state)**: Returning results as state stored in a CompositionLocal.\n\n### Future recipes\nThe most upvoted [recipe requests]([url](https://github.com/android/nav3-recipes/issues?q=is%3Aissue%20state%3Aopen%20label%3Arecipe-request)) will be considered for implementation. Don't see your recipe? [File a request for one here](https://github.com/android/nav3-recipes/issues/new?template=1-recipe-request.md)\n\n## Custom layout example\nThe following is a screen recording showing the navigation behavior of a [custom, list-detail Scene](app/src/main/java/com/example/nav3recipes/scenes/listdetail).\n\n![Custom layout example](/docs/images/ListDetailScene.gif)\n\n## Instructions\nClone this repository and open the root folder in [Android Studio](https://developer.android.com/studio). Each recipe is contained in its own package with its own `Activity`.\n\n## Found an issue?\nIf the issue is _directly related to this project_, as in, it's reproducible without modifying this project's source code, then please [file an issue on github](https://github.com/android/nav3-recipes/issues/new?template=2-bug-report.md). If you've found an issue with the Jetpack Navigation 3 library, please [file an issue on the issue tracker](https://issuetracker.google.com/issues/new?component=1750212&template=2102223).\n\n## Contributing\nWe'd love to accept your contributions. Please follow [these instructions](CONTRIBUTING.md).\n\n## Compose Multiplatform Recipes\nCMP recipes can be found [here](https://github.com/terrakok/nav3-recipes).\n\n## License\n```\nCopyright 2025 The Android Open Source Project\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    https://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n",
      "stars_today": 3
    },
    {
      "id": 31771754,
      "name": "WebGoat",
      "full_name": "WebGoat/WebGoat",
      "description": "WebGoat is a deliberately insecure application",
      "html_url": "https://github.com/WebGoat/WebGoat",
      "stars": 8910,
      "forks": 7297,
      "language": "JavaScript",
      "topics": [],
      "created_at": "2015-03-06T14:02:02Z",
      "updated_at": "2026-02-06T22:46:04Z",
      "pushed_at": "2025-12-08T09:04:16Z",
      "open_issues": 51,
      "owner": {
        "login": "WebGoat",
        "avatar_url": "https://avatars.githubusercontent.com/u/7718244?v=4"
      },
      "readme": "# WebGoat: A deliberately insecure Web Application\n\n[![Build](https://github.com/WebGoat/WebGoat/actions/workflows/build.yml/badge.svg?branch=develop)](https://github.com/WebGoat/WebGoat/actions/workflows/build.yml)\n[![java-jdk](https://img.shields.io/badge/java%20jdk-25-green.svg)](https://jdk.java.net/)\n[![OWASP Labs](https://img.shields.io/badge/OWASP-Lab%20project-f7b73c.svg)](https://owasp.org/projects/)\n[![GitHub release](https://img.shields.io/github/release/WebGoat/WebGoat.svg)](https://github.com/WebGoat/WebGoat/releases/latest)\n[![Gitter](https://badges.gitter.im/OWASPWebGoat/community.svg)](https://gitter.im/OWASPWebGoat/community?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n[![Discussions](https://img.shields.io/github/discussions/WebGoat/WebGoat)](https://github.com/WebGoat/WebGoat/discussions)\n[![Conventional Commits](https://img.shields.io/badge/Conventional%20Commits-1.0.0-%23FE5196?logo=conventionalcommits&logoColor=white)](https://conventionalcommits.org)\n\n# Introduction\n\nWebGoat is a deliberately insecure web application maintained by [OWASP](http://www.owasp.org/) designed to teach web\napplication security lessons.\n\nThis program is a demonstration of common server-side application flaws. The\nexercises are intended to be used by people to learn about application security and\npenetration testing techniques.\n\n**WARNING 1:** *While running this program your machine will be extremely\nvulnerable to attack. You should disconnect from the Internet while using\nthis program.*  WebGoat's default configuration binds to localhost to minimize\nthe exposure.\n\n**WARNING 2:** *This program is for educational purposes only. If you attempt\nthese techniques without authorization, you are very likely to get caught. If\nyou are caught engaging in unauthorized hacking, most companies will fire you.\nClaiming that you were doing security research will not work as that is the\nfirst thing that all hackers claim.*\n\n![WebGoat](docs/images/webgoat.png)\n\n# Installation instructions:\n\nFor more details check [the Contribution guide](/CONTRIBUTING.md)\n\n## 1. Run using Docker\n\nAlready have a browser and ZAP and/or Burp installed on your machine in this case you can run the WebGoat image directly using Docker.\n\nEvery release is also published on [DockerHub](https://hub.docker.com/r/webgoat/webgoat).\n\n```shell\ndocker run -it -p 127.0.0.1:8080:8080 -p 127.0.0.1:9090:9090 webgoat/webgoat\n```\n\nFor some lessons you need the container run in the same timezone. For this you can set the TZ environment variable.\nE.g.\n\n```shell\ndocker run -it -p 127.0.0.1:8080:8080 -p 127.0.0.1:9090:9090 -e TZ=America/Boise webgoat/webgoat\n```\n\nIf you want to use OWASP ZAP or another proxy, you can no longer use 127.0.0.1 or localhost. but\nyou can use custom host entries. For example:\n\n```shell\n127.0.0.1 www.webgoat.local www.webwolf.local\n```\n\nThen you can run the container with:\n\n```shell\ndocker run -it -p 127.0.0.1:8080:8080 -p 127.0.0.1:9090:9090 -e WEBGOAT_HOST=www.webgoat.local -e WEBWOLF_HOST=www.webwolf.local -e TZ=America/Boise webgoat/webgoat\n```\n\nThen visit http://www.webgoat.local:8080/WebGoat/ and http://www.webwolf.local:9090/WebWolf/\n\n## 2. Run using Docker with complete Linux Desktop\n\nInstead of installing tools locally we have a complete Docker image based on running a desktop in your browser. This way you only have to run a Docker image which will give you the best user experience.\n\n```shell\ndocker run -p 127.0.0.1:3000:3000 webgoat/webgoat-desktop\n```\n\n## 3. Standalone\n\nDownload the latest WebGoat release from [https://github.com/WebGoat/WebGoat/releases](https://github.com/WebGoat/WebGoat/releases)\n\n```shell\nexport TZ=Europe/Amsterdam # or your timezone\njava -Dfile.encoding=UTF-8 -jar webgoat-2023.8.jar\n```\n\nClick the link in the log to start WebGoat.\n\n### 3.1 Running on a different port\n\nIf for some reason you want to run WebGoat on a different port, you can do so by adding the following parameter:\n\n```shell\njava -jar webgoat-2023.8.jar --webgoat.port=8001 --webwolf.port=8002\n```\n\nFor a full overview of all the parameters you can use, please check the [WebGoat properties file](webgoat-container/src/main/resources/application-{webgoat, webwolf}.properties).\n\n## 4. Run from the sources\n\n### Prerequisites:\n\n* Java 25\n* Your favorite IDE\n* Git, or Git support in your IDE\n\nOpen a command shell/window:\n\n```Shell\ngit clone git@github.com:WebGoat/WebGoat.git\n```\n\nNow let's start by compiling the project.\n\n```Shell\ncd WebGoat\ngit checkout <<branch_name>>\n# On Linux/Mac:\n./mvnw clean install\n\n# On Windows:\n./mvnw.cmd clean install\n\n# Using docker or podman, you can than build the container locally\ndocker build -f Dockerfile . -t webgoat/webgoat\n```\n\nNow we are ready to run the project. WebGoat is using Spring Boot.\n\n```Shell\n# On Linux/Mac:\n./mvnw spring-boot:run\n# On Windows:\n./mvnw.cmd spring-boot:run\n\n```\n\n... you should be running WebGoat on http://localhost:8080/WebGoat momentarily.\n\nNote: The above link will redirect you to login page if you are not logged in. LogIn/Create account to proceed.\n\nTo change the IP address add the following variable to the `WebGoat/webgoat-container/src/main/resources/application.properties` file:\n\n```\nserver.address=x.x.x.x\n```\n\n## 4. Run with custom menu\n\nFor specialist only. There is a way to set up WebGoat with a personalized menu. You can leave out some menu categories or individual lessons by setting certain environment variables.\n\nFor instance running as a jar on a Linux/macOS it will look like this:\n\n```Shell\nexport TZ=Europe/Amsterdam # or your timezone\nexport EXCLUDE_CATEGORIES=\"CLIENT_SIDE,GENERAL,CHALLENGE\"\nexport EXCLUDE_LESSONS=\"SqlInjectionAdvanced,SqlInjectionMitigations\"\njava -jar target/webgoat-2023.8-SNAPSHOT.jar\n```\n\nOr in a docker run it would (once this version is pushed into docker hub) look like this:\n\n```Shell\ndocker run -d -p 127.0.0.1:8080:8080 -p 127.0.0.1:9090:9090 -e EXCLUDE_CATEGORIES=\"CLIENT_SIDE,GENERAL,CHALLENGE\" -e EXCLUDE_LESSONS=\"SqlInjectionAdvanced,SqlInjectionMitigations\" webgoat/webgoat\n```\n\n",
      "stars_today": 2
    },
    {
      "id": 92313258,
      "name": "cert-manager",
      "full_name": "cert-manager/cert-manager",
      "description": "Automatically provision and manage TLS certificates in Kubernetes",
      "html_url": "https://github.com/cert-manager/cert-manager",
      "stars": 13548,
      "forks": 2312,
      "language": "Go",
      "topics": [
        "certificate",
        "crd",
        "hacktoberfest",
        "kubernetes",
        "letsencrypt",
        "tls"
      ],
      "created_at": "2017-05-24T16:25:59Z",
      "updated_at": "2026-02-07T01:59:49Z",
      "pushed_at": "2026-02-07T00:34:23Z",
      "open_issues": 211,
      "owner": {
        "login": "cert-manager",
        "avatar_url": "https://avatars.githubusercontent.com/u/39950598?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"./logo/logo-small.png\" height=\"256\" width=\"256\" alt=\"cert-manager project logo\" />\n</p>\n<!-- note that the cert-manager logo in this repo is referred to in other README files in the cert-manager org\n     as well as in Helm charts, etc.\n     if you change its location or name, you'll need to update several other repos too! -->\n\n<p align=\"center\"><a href=\"https://prow.infra.cert-manager.io/?job=ci-cert-manager-master-make-test\">\n<!-- prow build badge, godoc, and go report card-->\n<img alt=\"Build Status\" src=\"https://prow.infra.cert-manager.io/badge.svg?jobs=ci-cert-manager-master-make-test\">\n</a>\n<a href=\"https://godoc.org/github.com/cert-manager/cert-manager\"><img src=\"https://godoc.org/github.com/cert-manager/cert-manager?status.svg\"></a>\n<a href=\"https://goreportcard.com/report/github.com/cert-manager/cert-manager\"><img alt=\"Go Report Card\" src=\"https://goreportcard.com/badge/github.com/cert-manager/cert-manager\" /></a>\n<br />\n<a href=\"https://artifacthub.io/packages/search?repo=cert-manager\"><img alt=\"Artifact Hub\" src=\"https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/cert-manager\" /></a>\n<a href=\"https://scorecard.dev/viewer/?uri=github.com/cert-manager/cert-manager\"><img src=\"https://api.scorecard.dev/projects/github.com/cert-manager/cert-manager/badge\" alt=\"Scorecard score\"/></a>\n<a href=\"https://clomonitor.io/projects/cncf/cert-manager\"><img src=\"https://img.shields.io/endpoint?url=https://clomonitor.io/api/projects/cncf/cert-manager/badge\" alt=\"CLOMonitor\"/></a>\n<br />\n<a href=\"https://www.bestpractices.dev/projects/8079\"><img src=\"https://www.bestpractices.dev/projects/8079/badge\"></a>\n</p>\n\n# cert-manager\n\ncert-manager adds certificates and certificate issuers as resource types in Kubernetes clusters, and simplifies the process of obtaining, renewing and using those certificates.\n\nIt supports issuing certificates from a variety of sources, including Let's Encrypt (ACME), HashiCorp Vault, and CyberArk Certificate Manager, as well as local in-cluster issuance.\n\ncert-manager also ensures certificates remain valid and up to date, attempting to renew certificates at an appropriate time before expiry to reduce the risk of outages and remove toil.\n\n![cert-manager high level overview diagram](https://cert-manager.io/images/high-level-overview.svg)\n\n## Documentation\n\nDocumentation for cert-manager can be found at [cert-manager.io](https://cert-manager.io/docs/).\n\nFor the common use-case of automatically issuing TLS certificates for\nIngress resources, see the [cert-manager nginx-ingress quick start guide](https://cert-manager.io/docs/tutorials/acme/nginx-ingress/).\n\nFor a more comprehensive guide to issuing your first certificate, see our [getting started guide](https://cert-manager.io/docs/getting-started/).\n\n### Installation\n\n[Installation](https://cert-manager.io/docs/installation/) is documented on the website, with a variety of supported methods.\n\n## Developing cert-manager\n\nWe actively welcome contributions and we support both Linux and macOS environments for development.\n\nDifferent platforms have different requirements; we document everything on our [Building cert-manager](https://cert-manager.io/docs/contributing/building/)\nwebsite page.\n\nNote in particular that macOS has several extra requirements, to ensure that modern tools are installed and available. Read the page before\ngetting started!\n\n## Troubleshooting\n\nIf you encounter any issues whilst using cert-manager, we have a number of ways to get help:\n\n- A [troubleshooting guide](https://cert-manager.io/docs/faq/troubleshooting/) on our website.\n- Our official [Kubernetes Slack channel](https://cert-manager.io/docs/contributing/#slack) - the quickest way to ask! ([#cert-manager](https://kubernetes.slack.com/messages/cert-manager) and [#cert-manager-dev](https://kubernetes.slack.com/messages/cert-manager-dev))\n- [Searching for an existing issue](https://github.com/cert-manager/cert-manager/issues).\n\nIf you believe you've found a bug and cannot find an existing issue, feel free to [open a new issue](https://github.com/cert-manager/cert-manager/issues)!\nBe sure to include as much information as you can about your environment.\n\n## Community\n\nThe [`cert-manager-dev` Google Group](https://groups.google.com/forum/#!forum/cert-manager-dev)\nis used for project wide announcements and development coordination.\nAnybody with a Google account can join the group by visiting the group and clicking \"Join Group\".\n\n### Meetings\n\nWe have several public meetings which any member of our Google Group is more than welcome to join!\n\nCheck out the details on [our website](https://cert-manager.io/docs/contributing/#meetings). Feel\nfree to drop in and ask questions, chat with us or just to say hi!\n\n## Contributing\n\nWe welcome pull requests with open arms! There's a lot of work to do here, and\nwe're especially concerned with ensuring the longevity and reliability of the\nproject. The [contributing guide](https://cert-manager.io/docs/contributing/)\nwill help you get started.\n\n## Coding Conventions\n\nCode style guidelines are documented on the [coding conventions](https://cert-manager.io/docs/contributing/coding-conventions/) page\nof the cert-manager website. Please try to follow those guidelines if you're submitting a pull request for cert-manager.\n\n## Importing cert-manager as a Module\n\nâš ï¸ Please note that cert-manager **does not** currently provide a Go module compatibility guarantee. That means that\n**most code under `pkg/` is subject to change in a breaking way**, even between minor or patch releases and even if\nthe code is currently publicly exported.\n\nThe lack of a Go module compatibility guarantee does not affect API version guarantees\nunder the [Kubernetes Deprecation Policy](https://kubernetes.io/docs/reference/using-api/deprecation-policy/).\n\nFor more details see [Importing cert-manager in Go](https://cert-manager.io/docs/contributing/importing/) on the\ncert-manager website.\n\nThe import path for cert-manager versions 1.8 and later is `github.com/cert-manager/cert-manager`.\n\nFor all versions of cert-manager before 1.8, including minor and patch releases, the import path is `github.com/jetstack/cert-manager`.\n\n## Security Reporting\n\nSecurity is the number one priority for cert-manager. If you think you've found a security vulnerability, we'd love to hear from you.\n\nFollow the instructions in [SECURITY.md](./SECURITY.md) to make a report.\n\n## Changelog\n\n[Every release](https://github.com/cert-manager/cert-manager/releases) on GitHub has a changelog,\nand we also publish release notes on [the website](https://cert-manager.io/docs/release-notes/).\n\n## History\n\ncert-manager is loosely based upon the work of [kube-lego](https://github.com/jetstack/kube-lego)\nand has borrowed some wisdom from other similar projects such as [kube-cert-manager](https://github.com/PalmStoneGames/kube-cert-manager).\n\n<sub><sup>Logo design by [Zoe Paterson](https://zoepatersonmedia.com)</sup></sub>\n",
      "stars_today": 2
    },
    {
      "id": 6427813,
      "name": "dplyr",
      "full_name": "tidyverse/dplyr",
      "description": "dplyr: A grammar of data manipulation",
      "html_url": "https://github.com/tidyverse/dplyr",
      "stars": 4996,
      "forks": 2131,
      "language": "R",
      "topics": [
        "data-manipulation",
        "grammar",
        "r"
      ],
      "created_at": "2012-10-28T13:39:17Z",
      "updated_at": "2026-02-07T02:28:16Z",
      "pushed_at": "2026-02-04T15:34:45Z",
      "open_issues": 76,
      "owner": {
        "login": "tidyverse",
        "avatar_url": "https://avatars.githubusercontent.com/u/22032646?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# dplyr <a href=\"https://dplyr.tidyverse.org\"><img src=\"man/figures/logo.png\" align=\"right\" height=\"138\" /></a>\n\n<!-- badges: start -->\n\n[![CRAN\nstatus](https://www.r-pkg.org/badges/version/dplyr)](https://cran.r-project.org/package=dplyr)\n[![R-CMD-check](https://github.com/tidyverse/dplyr/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/tidyverse/dplyr/actions/workflows/R-CMD-check.yaml)\n[![Codecov test\ncoverage](https://codecov.io/gh/tidyverse/dplyr/graph/badge.svg)](https://app.codecov.io/gh/tidyverse/dplyr)\n<!-- badges: end -->\n\n## Overview\n\ndplyr is a grammar of data manipulation, providing a consistent set of\nverbs that help you solve the most common data manipulation challenges:\n\n- `mutate()` adds new variables that are functions of existing variables\n- `select()` picks variables based on their names.\n- `filter()` picks cases based on their values.\n- `summarise()` reduces multiple values down to a single summary.\n- `arrange()` changes the ordering of the rows.\n\nThese all combine naturally with `group_by()` which allows you to\nperform any operation â€œby groupâ€. You can learn more about them in\n`vignette(\"dplyr\")`. As well as these single-table verbs, dplyr also\nprovides a variety of two-table verbs, which you can learn about in\n`vignette(\"two-table\")`.\n\nIf you are new to dplyr, the best place to start is the [data\ntransformation chapter](https://r4ds.hadley.nz/data-transform) in R for\nData Science.\n\n## Backends\n\nIn addition to data frames/tibbles, dplyr makes working with other\ncomputational backends accessible and efficient. Below is a list of\nalternative backends:\n\n- [arrow](https://arrow.apache.org/docs/r/) for larger-than-memory\n  datasets, including on remote cloud storage like AWS S3, using the\n  Apache Arrow C++ engine,\n  [Acero](https://arrow.apache.org/docs/cpp/acero/overview.html).\n\n- [dbplyr](https://dbplyr.tidyverse.org/) for data stored in a\n  relational database. Translates your dplyr code to SQL.\n\n- [dtplyr](https://dtplyr.tidyverse.org/) for large, in-memory datasets.\n  Translates your dplyr code to high performance\n  [data.table](https://rdatatable.gitlab.io/data.table/) code.\n\n- [duckplyr](https://duckplyr.tidyverse.org/) for large, in-memory\n  datasets. Translates your dplyr code to high performance\n  [duckdb](https://duckdb.org) queries with zero extra copies and an\n  automatic R fallback when translation isnâ€™t possible.\n\n- [sparklyr](https://spark.posit.co/) for very large datasets stored in\n  [Apache Spark](https://spark.apache.org).\n\n## Installation\n\n``` r\n# The easiest way to get dplyr is to install the whole tidyverse:\ninstall.packages(\"tidyverse\")\n\n# Alternatively, install just dplyr:\ninstall.packages(\"dplyr\")\n```\n\n### Development version\n\nTo get a bug fix or to use a feature from the development version, you\ncan install the development version of dplyr from GitHub.\n\n``` r\n# install.packages(\"pak\")\npak::pak(\"tidyverse/dplyr\")\n```\n\n## Cheat Sheet\n\n<a href=\"https://github.com/rstudio/cheatsheets/blob/main/data-transformation.pdf\"><img src=\"https://raw.githubusercontent.com/rstudio/cheatsheets/main/pngs/thumbnails/data-transformation-cheatsheet-thumbs.png\" width=\"630\" height=\"252\"/></a>\n\n## Usage\n\n``` r\nlibrary(dplyr)\n\nstarwars |>\n  filter(species == \"Droid\")\n#> # A tibble: 6 Ã— 14\n#>   name   height  mass hair_color skin_color  eye_color birth_year sex   gender  \n#>   <chr>   <int> <dbl> <chr>      <chr>       <chr>          <dbl> <chr> <chr>   \n#> 1 C-3PO     167    75 <NA>       gold        yellow           112 none  masculiâ€¦\n#> 2 R2-D2      96    32 <NA>       white, blue red               33 none  masculiâ€¦\n#> 3 R5-D4      97    32 <NA>       white, red  red               NA none  masculiâ€¦\n#> 4 IG-88     200   140 none       metal       red               15 none  masculiâ€¦\n#> 5 R4-P17     96    NA none       silver, red red, blue         NA none  feminine\n#> # â„¹ 1 more row\n#> # â„¹ 5 more variables: homeworld <chr>, species <chr>, films <list>,\n#> #   vehicles <list>, starships <list>\n\nstarwars |>\n  select(name, ends_with(\"color\"))\n#> # A tibble: 87 Ã— 4\n#>   name           hair_color skin_color  eye_color\n#>   <chr>          <chr>      <chr>       <chr>    \n#> 1 Luke Skywalker blond      fair        blue     \n#> 2 C-3PO          <NA>       gold        yellow   \n#> 3 R2-D2          <NA>       white, blue red      \n#> 4 Darth Vader    none       white       yellow   \n#> 5 Leia Organa    brown      light       brown    \n#> # â„¹ 82 more rows\n\nstarwars |>\n  mutate(name, bmi = mass / ((height / 100)^2)) |>\n  select(name:mass, bmi)\n#> # A tibble: 87 Ã— 4\n#>   name           height  mass   bmi\n#>   <chr>           <int> <dbl> <dbl>\n#> 1 Luke Skywalker    172    77  26.0\n#> 2 C-3PO             167    75  26.9\n#> 3 R2-D2              96    32  34.7\n#> 4 Darth Vader       202   136  33.3\n#> 5 Leia Organa       150    49  21.8\n#> # â„¹ 82 more rows\n\nstarwars |>\n  arrange(desc(mass))\n#> # A tibble: 87 Ã— 14\n#>   name      height  mass hair_color skin_color eye_color birth_year sex   gender\n#>   <chr>      <int> <dbl> <chr>      <chr>      <chr>          <dbl> <chr> <chr> \n#> 1 Jabba Deâ€¦    175  1358 <NA>       green-tanâ€¦ orange         600   hermâ€¦ mascuâ€¦\n#> 2 Grievous     216   159 none       brown, whâ€¦ green, yâ€¦       NA   male  mascuâ€¦\n#> 3 IG-88        200   140 none       metal      red             15   none  mascuâ€¦\n#> 4 Darth Vaâ€¦    202   136 none       white      yellow          41.9 male  mascuâ€¦\n#> 5 Tarfful      234   136 brown      brown      blue            NA   male  mascuâ€¦\n#> # â„¹ 82 more rows\n#> # â„¹ 5 more variables: homeworld <chr>, species <chr>, films <list>,\n#> #   vehicles <list>, starships <list>\n\nstarwars |>\n  group_by(species) |>\n  summarise(\n    n = n(),\n    mass = mean(mass, na.rm = TRUE)\n  ) |>\n  filter(\n    n > 1,\n    mass > 50\n  )\n#> # A tibble: 9 Ã— 3\n#>   species      n  mass\n#>   <chr>    <int> <dbl>\n#> 1 Droid        6  69.8\n#> 2 Gungan       3  74  \n#> 3 Human       35  81.3\n#> 4 Kaminoan     2  88  \n#> 5 Mirialan     2  53.1\n#> # â„¹ 4 more rows\n```\n\n## Getting help\n\nIf you encounter a clear bug, please file an issue with a minimal\nreproducible example on\n[GitHub](https://github.com/tidyverse/dplyr/issues). For questions and\nother discussion, please use [forum.posit.co](https://forum.posit.co/).\n\n## Code of conduct\n\nPlease note that this project is released with a [Contributor Code of\nConduct](https://dplyr.tidyverse.org/CODE_OF_CONDUCT). By participating\nin this project you agree to abide by its terms.\n",
      "stars_today": 2
    },
    {
      "id": 207354223,
      "name": "FreeRTOS-Kernel",
      "full_name": "FreeRTOS/FreeRTOS-Kernel",
      "description": "FreeRTOS kernel files only, submoduled into https://github.com/FreeRTOS/FreeRTOS and various other repos.",
      "html_url": "https://github.com/FreeRTOS/FreeRTOS-Kernel",
      "stars": 3851,
      "forks": 1440,
      "language": "C",
      "topics": [],
      "created_at": "2019-09-09T16:28:01Z",
      "updated_at": "2026-02-07T00:32:36Z",
      "pushed_at": "2026-01-30T01:28:28Z",
      "open_issues": 39,
      "owner": {
        "login": "FreeRTOS",
        "avatar_url": "https://avatars.githubusercontent.com/u/54647343?v=4"
      },
      "readme": "[![CMock Unit Tests](https://github.com/FreeRTOS/FreeRTOS-Kernel/actions/workflows/unit-tests.yml/badge.svg?branch=main&event=push)](https://github.com/FreeRTOS/FreeRTOS-Kernel/actions/workflows/unit-tests.yml?query=branch%3Amain+event%3Apush+workflow%3A%22CMock+Unit+Tests%22++)\n[![codecov](https://app.codecov.io/gh/FreeRTOS/FreeRTOS-Kernel/badge.svg?branch=main)](https://codecov.io/gh/FreeRTOS/FreeRTOS-Kernel)\n\n## Getting started\n\nThis repository contains FreeRTOS kernel source/header files and kernel\nports only. This repository is referenced as a submodule in\n[FreeRTOS/FreeRTOS](https://github.com/FreeRTOS/FreeRTOS)\nrepository, which contains pre-configured demo application projects under\n```FreeRTOS/Demo``` directory.\n\nThe easiest way to use FreeRTOS is to start with one of the pre-configured demo\napplication projects.  That way you will have the correct FreeRTOS source files\nincluded, and the correct include paths configured. Once a demo application is\nbuilding and executing you can remove the demo application files, and start to\nadd in your own application source files.  See the\n[FreeRTOS Kernel Quick Start Guide](https://www.freertos.org/Documentation/01-FreeRTOS-quick-start/01-Beginners-guide/02-Quick-start-guide)\nfor detailed instructions and other useful links.\n\nAdditionally, for FreeRTOS kernel feature information refer to the\n[Developer Documentation](https://www.freertos.org/Documentation/02-Kernel/02-Kernel-features/00-Developer-docs),\nand [API Reference](https://www.freertos.org/Documentation/02-Kernel/04-API-references/01-Task-creation/00-TaskHandle).\n\nAlso for contributing and creating a Pull Request please refer to\n[the instructions here](.github/CONTRIBUTING.md#contributing-via-pull-request).\n\n**FreeRTOS-Kernel V11.1.0\n[source code](https://github.com/FreeRTOS/FreeRTOS-Kernel/tree/V11.1.0) is part\nof the\n[FreeRTOS 202406.00 LTS](https://github.com/FreeRTOS/FreeRTOS-LTS/tree/202406-LTS)\nrelease.**\n\n### Getting help\n\nIf you have any questions or need assistance troubleshooting your FreeRTOS project,\nwe have an active community that can help on the\n[FreeRTOS Community Support Forum](https://forums.freertos.org).\n\n## To consume FreeRTOS-Kernel\n\n### Consume with CMake\n\nIf using CMake, it is recommended to use this repository using FetchContent.\nAdd the following into your project's main or a subdirectory's `CMakeLists.txt`:\n\n- Define the source and version/tag you want to use:\n\n```cmake\nFetchContent_Declare( freertos_kernel\n  GIT_REPOSITORY https://github.com/FreeRTOS/FreeRTOS-Kernel.git\n  GIT_TAG        main #Note: Best practice to use specific git-hash or tagged version\n)\n```\n\nIn case you prefer to add it as a git submodule, do:\n\n```bash\ngit submodule add https://github.com/FreeRTOS/FreeRTOS-Kernel.git <path of the submodule>\ngit submodule update --init\n```\n\n- Add a freertos_config library (typically an INTERFACE library) The following assumes the directory structure:\n  - `include/FreeRTOSConfig.h`\n\n```cmake\nadd_library(freertos_config INTERFACE)\n\ntarget_include_directories(freertos_config SYSTEM\nINTERFACE\n    include\n)\n\ntarget_compile_definitions(freertos_config\n  INTERFACE\n    projCOVERAGE_TEST=0\n)\n```\n\nIn case you installed FreeRTOS-Kernel as a submodule, you will have to add it as a subdirectory:\n\n```cmake\nadd_subdirectory(${FREERTOS_PATH})\n```\n\n- Configure the FreeRTOS-Kernel and make it available\n  - this particular example supports a native and cross-compiled build option.\n\n```cmake\nset( FREERTOS_HEAP \"4\" CACHE STRING \"\" FORCE)\n# Select the native compile PORT\nset( FREERTOS_PORT \"GCC_POSIX\" CACHE STRING \"\" FORCE)\n# Select the cross-compile PORT\nif (CMAKE_CROSSCOMPILING)\n  set(FREERTOS_PORT \"GCC_ARM_CA9\" CACHE STRING \"\" FORCE)\nendif()\n\nFetchContent_MakeAvailable(freertos_kernel)\n```\n\n- In case of cross compilation, you should also add the following to `freertos_config`:\n\n```cmake\ntarget_compile_definitions(freertos_config INTERFACE ${definitions})\ntarget_compile_options(freertos_config INTERFACE ${options})\n```\n\n### Consuming stand-alone - Cloning this repository\n\nTo clone using HTTPS:\n\n```\ngit clone https://github.com/FreeRTOS/FreeRTOS-Kernel.git\n```\n\nUsing SSH:\n\n```\ngit clone git@github.com:FreeRTOS/FreeRTOS-Kernel.git\n```\n\n## Repository structure\n\n- The root of this repository contains the three files that are common to\nevery port - list.c, queue.c and tasks.c.  The kernel is contained within these\nthree files.  croutine.c implements the optional co-routine functionality - which\nis normally only used on very memory limited systems.\n\n- The ```./portable``` directory contains the files that are specific to a particular microcontroller and/or compiler.\nSee the readme file in the ```./portable``` directory for more information.\n\n- The ```./include``` directory contains the real time kernel header files.\n\n- The ```./template_configuration``` directory contains a sample `FreeRTOSConfig.h` to help jumpstart a new project.\nSee the [FreeRTOSConfig.h](examples/template_configuration/FreeRTOSConfig.h) file for instructions.\n\n### Code Formatting\n\nFreeRTOS files are formatted using the\n\"[uncrustify](https://github.com/uncrustify/uncrustify)\" tool.\nThe configuration file used by uncrustify can be found in the\n[FreeRTOS/CI-CD-GitHub-Actions's](https://github.com/FreeRTOS/CI-CD-Github-Actions)\n[uncrustify.cfg](https://github.com/FreeRTOS/CI-CD-Github-Actions/tree/main/formatting)\nfile.\n\n### Line Endings\n\nFile checked into the FreeRTOS-Kernel repository use unix-style LF line endings\nfor the best compatibility with git.\n\nFor optimal compatibility with Microsoft Windows tools, it is best to enable\nthe git autocrlf feature. You can enable this setting for the current\nrepository using the following command:\n\n```\ngit config core.autocrlf true\n```\n\n### Git History Optimizations\n\nSome commits in this repository perform large refactors which touch many lines\nand lead to unwanted behavior when using the `git blame` command. You can\nconfigure git to ignore the list of large refactor commits in this repository\nwith the following command:\n\n```\ngit config blame.ignoreRevsFile .git-blame-ignore-revs\n```\n\n### Spelling and Formatting\n\nWe recommend using [Visual Studio Code](https://code.visualstudio.com),\ncommonly referred to as VSCode, when working on the FreeRTOS-Kernel.\nThe FreeRTOS-Kernel also uses [cSpell](https://cspell.org/) as part of its\nspelling check. The config file for which can be found at [cspell.config.yaml](cspell.config.yaml)\nThere is additionally a\n[cSpell plugin for VSCode](https://marketplace.visualstudio.com/items?itemName=streetsidesoftware.code-spell-checker)\nthat can be used as well.\n*[.cSpellWords.txt](.github/.cSpellWords.txt)* contains words that are not\ntraditionally found in an English dictionary. It is used by the spellchecker\nto verify the various jargon, variable names, and other odd words used in the\nFreeRTOS code base are correct. If your pull request fails to pass the spelling\nand you believe this is a mistake, then add the word to\n*[.cSpellWords.txt](.github/.cSpellWords.txt)*. When adding a word please\nthen sort the list, which can be done by running the bash command:\n`sort -u .cSpellWords.txt -o .cSpellWords.txt`\nNote that only the FreeRTOS-Kernel Source Files, [include](include),\n[portable/MemMang](portable/MemMang), and [portable/Common](portable/Common)\nfiles are checked for proper spelling, and formatting at this time.\n\n## Third Party Tools\nVisit [this link](.github/third_party_tools.md) for detailed information about\nthird-party tools with FreeRTOS support.\n",
      "stars_today": 2
    },
    {
      "id": 129699403,
      "name": "tuist",
      "full_name": "tuist/tuist",
      "description": "A virtual platform team for mobile devs who ship ",
      "html_url": "https://github.com/tuist/tuist",
      "stars": 5505,
      "forks": 690,
      "language": "Swift",
      "topics": [
        "ios",
        "objective-c",
        "productivity",
        "scalability",
        "swift",
        "xcode"
      ],
      "created_at": "2018-04-16T07:02:54Z",
      "updated_at": "2026-02-06T17:46:50Z",
      "pushed_at": "2026-02-06T20:33:08Z",
      "open_issues": 264,
      "owner": {
        "login": "tuist",
        "avatar_url": "https://avatars.githubusercontent.com/u/38419084?v=4"
      },
      "readme": "<div align=\"center\">\n  <div>\n    <a href=\"https://tuist.dev\" target=\"_blank\"><img src=\"assets/header.png\" alt=\"header\"/></a>\n  </div>\n  <img src=\"https://img.shields.io/github/commit-activity/w/tuist/tuist?style=flat-square&label=commits\" alt=\"Commit Activity\">\n  <a href=\"https://fosstodon.org/@tuist\"><img src=\"https://img.shields.io/badge/tuist-gray.svg?logo=mastodon&logoColor=f5f5f5\" alt=\"Mastodon badge\"></a>\n  <a href=\"https://bsky.app/profile/tuist.dev\"><img src=\"https://img.shields.io/badge/tuist-gray.svg?logo=bluesky\" alt=\"Bluesky badge\"></a>\n  <a href=\"https://join.slack.com/t/tuistapp/shared_invite/zt-1lqw355mp-zElRwLeoZ2EQsgGEkyaFgg\"><img src=\"https://img.shields.io/badge/tuist-gray.svg?logo=slack\" alt=\"Slack Workspace\"></a>\n  <a href=\"https://t.me/tuist\"><img src=\"https://img.shields.io/badge/tuist-gray.svg?logo=telegram\" alt=\"Slack Workspace\"></a>\n  <div>\n    <a href=\"https://cal.com/team/tuist/cloud?utm_source=banner&utm_campaign=oss\" target=\"_blank\"><img alt=\"Book us with Cal.com\" src=\"https://cal.com/book-with-cal-dark.svg\" width=\"150\"/></a>\n  </div>\n  <a href=\"https://translate.tuist.dev/engage/tuist/\">\n  <img src=\"https://translate.tuist.dev/widget/tuist/svg-badge.svg\" alt=\"Translation status\" />\n  </a>\n</div>\n\n# Tuist\n\nTuist is a virtual platform team for Swift app devs who ship. Through an integrated platform that integrates with your toolchain and projects, we help you stay focused and productive while building apps.\n\nThe following solutions are part of Tuist:\n\n- [ğŸ—‚ï¸ **Generated projects**](https://docs.tuist.dev/en/guides/develop/projects): A solution for more accessible and easier-to-manage Xcode projects.\n- [ğŸš **Cache**](https://docs.tuist.dev/en/guides/develop/cache): Speed up builds across environments with a content-addressable store.\n- [âœ… **Selective testing**](https://docs.tuist.dev/en/guides/develop/selective-testing): Run tests faster by selecting them based on the file changes.\n- [ğŸ“¦ **Registry**](https://docs.tuist.dev/en/guides/develop/registry): Speed up the resolution of [Swift Package Index](https://swiftpackageindex.com/)-indexed packages.\n- [ğŸ“ˆ **Build insights**](https://docs.tuist.dev/en/guides/develop/insights): Get actionable insights from your projects, builds, and test runs to make informed decisions.\n- [ğŸ“± **Bundle insights**](https://docs.tuist.dev/en/guides/develop/bundle-size): Analyze your built apps and get suggestions to improve them.\n- [ğŸ“± **Previews**](https://docs.tuist.dev/en/guides/features/previews): Sharing apps (previews) as easy as sharing a link.\n- [âœ… **QA**](https://docs.tuist.dev/en/guides/features/qa): QA your app using LLM-based agents.\n\nOpenness and community are cornerstones in shaping Tuist, as we believe they are the key to building the best solution. We recommend checking out the following resources:\n\n- [ğŸ“‘ **Documentation**](https://docs.tuist.dev)\n- [ğŸ“š **Handbook**](https://handbook.tuist.dev)\n- [ğŸ’¬ **Community forum**](https://community.tuist.dev)\n\n> [!NOTE]\n> Even though our current focus is on the development phase of Apple native apps, we'll gradually expand our focus to include other ecosystems (e.g., Android, RN, and Flutter), and expand beyond just development.\n\n## Get started\n\nYou can run the following command to get started with [Mise] (check out [this page](https://docs.tuist.dev/en/guides/quick-start/get-started) for other methods):\n\n```bash\nmise x tuist@latest -- tuist init\n```\n\n> [!IMPORTANT]\n> The `init` workflow is designed to integrate with an existing Xcode project or create [a generated project](https://docs.tuist.dev/en/guides/features/projects). If you are migrating an existing Xcode project to a generated project, we recommend [checking out these docs](https://docs.tuist.dev/en/guides/features/projects/adoption/migrate/xcode-project).\n\n## Documentation\n\nDo you want to know more about what Tuist can offer you? Or perhaps want to contribute to the project and you need a starting point?\n\nYou can check out [the project documentation](https://docs.tuist.dev).\n\n### Sample projects\n\nYou can find some sample projects in the [examples folder](examples/xcode) or the [awesome Tuist repo](https://github.com/tuist/awesome-tuist)! ğŸ‰\n\n## Development\n\nThis repository represents a monorepo with the following projects:\n\n| Project | Description |\n| ------ | -------  |\n| [cli](/cli) | The command line interface for Tuist |\n| [app](/app) | The Swift-powered iOS and macOS app |\n| [docs](/docs) | The documentation for Tuist |\n| [handbook](/handbook) | The company's handbook |\n\n## Sponsors\n\nSome companies support our community and open source efforts with contributions through [GitHub Sponsors](https://github.com/sponsors/tuist) and [Open Collective Backers](https://opencollective.com/tuistapp). We'd like to give a special mention to the following sponsors:\n\n<table>\n  <tbody>\n    <tr>\n      <td width=\"30%\" align=\"center\">\n        <a href=\"https://monday.com?utm_source=Github&utm_medium=Github_Repo_Content_Ad&utm_content=Developer&&utm_term=tuist\" target=\"_blank\">\n          <img width=\"300\" src=\"assets/companies/monday.com.svg\" alt=\"mondaycom_logo\"/>\n        </a>\n      </td>\n      <td><a href=\"https://monday.com?utm_source=Github&utm_medium=Github_Repo_Content_Ad&utm_content=Developer&&utm_term=tuist\">Monday.com</a> is a cloud-based work operating system (Work OS) that empowers teams to run projects and workflows with confidence. It's a versatile platform that combines features of project management, workflow automation, and team collaboration to streamline the way teams work together.</td>\n    </tr>\n    <tr>\n      <td width=\"30%\" align=\"center\">\n        <a href=\"https://lapse.com?utm_source=Github&utm_medium=Github_Repo_Content_Ad&utm_content=Developer&&utm_term=tuist\" target=\"_blank\">\n          <img width=\"200\" src=\"assets/companies/lapse.svg\" alt=\"lapse_logo\"/>\n        </a>\n      </td>\n      <td><a href=\"https://lapse.com?utm_source=Github&utm_medium=Github_Repo_Content_Ad&utm_content=Developer&&utm_term=tuist\">Lapse</a> is an app designed to reclaim how we take and share memories. A camera for living in the moment and a private photo journal for friends, not followers.</td>\n    </tr>\n  </tbody>\n</table>\n\n## Companies using Tuist\n\n<table>\n  <tbody>\n    <tr>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://play.tv2.no\" target=\"_blank\">\n          <img src=\"assets/companies/tv2.svg\" alt=\"tv2_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.depop.com\" target=\"_blank\">\n          <img src=\"assets/companies/depop.svg\" alt=\"depop_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://bendingspoons.com\" target=\"_blank\">\n          <picture>\n            <source\n              srcset=\"assets/companies/bendingspoons-darkmode.png\"\n              media=\"(prefers-color-scheme: dark)\">\n            <img src=\"assets/companies/bendingspoons.png\" alt=\"bendingspoons_logo\"/>\n          </picture>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://globekeeper.com\" target=\"_blank\">\n          <img src=\"assets/companies/globekeeper.png\" alt=\"globekeeper_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://getyourguide.com\" target=\"_blank\">\n          <img src=\"assets/companies/getyourguide.png\" alt=\"getyourguide_logo\" height=\"75\"/>\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://emplate.it\" target=\"_blank\">\n          <img src=\"assets/companies/emplate.svg\" alt=\"emplate_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.trendyol.com\" target=\"_blank\">\n          <img src=\"assets/companies/Trendyol.png\" alt=\"trendyol_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://angrynerds.co\" target=\"_blank\">\n          <img src=\"assets/companies/angrynerds.svg\" alt=\"angrynerds_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.compass.com\" target=\"_blank\">\n          <img src=\"assets/companies/compass.png\" alt=\"compass_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.wefox.com\" target=\"_blank\">\n          <img src=\"assets/companies/wefox.png\" alt=\"wefox_logo\"/>\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.hedvig.com\" target=\"_blank\">\n            <img src=\"assets/companies/hedvig.svg\" alt=\"hedvig_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.takeoutcentral.com\" target=\"_blank\">\n          <img src=\"assets/companies/takeoutcentral.svg\" alt=\"takeoutcentral_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.olx.com.br\" target=\"_blank\">\n          <img src=\"assets/companies/olx.png\" alt=\"olx_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.justeattakeaway.com\" target=\"_blank\">\n          <img src=\"assets/companies/justeattakeaway.svg\" alt=\"justeattakeaway_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://qnips.io\" target=\"_blank\">\n          <img src=\"assets/companies/qnips.svg\" alt=\"qnips_logo\"/>\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.telepass.com\" target=\"_blank\">\n          <img src=\"assets/companies/telepass.svg\" alt=\"telepass_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.crunchyroll.com\" target=\"_blank\">\n          <img src=\"assets/companies/crunchyroll.svg\" alt=\"crunchyroll_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://altel.kz\" target=\"_blank\">\n          <img src=\"assets/companies/altel.svg\" alt=\"altel_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://tele2.kz\" target=\"_blank\">\n          <img src=\"assets/companies/tele2.svg\" alt=\"altel_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://izi.me/kz\" target=\"_blank\">\n          <img src=\"assets/companies/izi.svg\" alt=\"izi_logo\" height=\"75\"/>\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://wise.com\" target=\"_blank\">\n          <img src=\"assets/companies/wise.png\" alt=\"wise_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://zapis.kz/\" target=\"_blank\">\n          <img src=\"assets/companies/zapis.svg\" alt=\"wise_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://apps.apple.com/kz/app/rbk-business/id1466194695\" target=\"_blank\">\n          <img src=\"assets/companies/rbkbusiness.svg\" alt=\"rbkbusiness_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://snoonu.com/\" target=\"_blank\">\n          <img src=\"assets/companies/snoonu.svg\" alt=\"rbkbusiness_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://get.sajda.app\" target=\"_blank\">\n          <img src=\"assets/companies/sajda_app.svg\" alt=\"sajda_logo\" height=\"75\"/>\n        </a>\n      </td>\n    </tr>\n    <tr>\n     <td width=\"20%\" align=\"center\">\n        <a href=\"https://abb-bank.az\" target=\"_blank\">\n          <img src=\"assets/companies/abb-logo-slogan.png\" alt=\"abb_mobile_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\"></td>\n      <td width=\"20%\"></td>\n      <td width=\"20%\"></td>\n      <td width=\"20%\"></td>\n    </tr>\n  </tbody>\n</table>\n\n## Want to contribute?\n\nYou can use our [contribution docs](https://docs.tuist.dev/en/contributors/code) to get started. You can find good issues for first-time contributors [here](https://github.com/tuist/tuist/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22).\n\n## Core Alumni\n\nThe following people were once core contributors helping steer the project in the right direction and ensuring we have a reliable foundation we can build new features upon:\n\n<table>\n  <tr>\n    <td align=\"center\"><a href=\"http://www.matrixprojects.net\"><img src=\"https://avatars3.githubusercontent.com/u/11914919?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kas</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/danyf90\"><img src=\"https://avatars.githubusercontent.com/u/2794031?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Daniele Formichelli</b></sub></a><br /></td>\n    <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/waltflanagan\"><img src=\"https://avatars.githubusercontent.com/u/398293?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mike Simons</b></sub></a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"http://natanrolnik.me\"><img src=\"https://avatars3.githubusercontent.com/u/1164565?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Natan Rolnik</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/andreacipriani\"><img src=\"https://avatars3.githubusercontent.com/u/536929?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andrea Cipriani</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/ollieatkinson\"><img src=\"https://avatars1.githubusercontent.com/u/1382565?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Oliver Atkinson</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/RomainBoulay\"><img src=\"https://avatars1.githubusercontent.com/u/169323?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Romain Boulay</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/laxmorek\"><img src=\"https://avatars1.githubusercontent.com/u/4774319?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kamil Harasimowicz</b></sub></a><br /></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"http://www.luispadron.com\"><img src=\"https://avatars3.githubusercontent.com/u/13840545?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Luis Padron</b></sub></a></td>\n    <td align=\"center\"><a href=\"https://github.com/adellibovi\"><img src=\"https://avatars3.githubusercontent.com/u/67916?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alfredo Delli Bovi</b></sub></a><br /></td>\n  </tr>\n</table>\n\n## Contributors\n\nThanks goes to these wonderful people:\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kalkwarf\"><img src=\"https://avatars1.githubusercontent.com/u/1033839?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kalkwarf</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/fortmarek\"><img src=\"https://avatars0.githubusercontent.com/u/9371695?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Marek FoÅ™t</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.matrixprojects.net\"><img src=\"https://avatars3.githubusercontent.com/u/11914919?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kas</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://natanrolnik.me\"><img src=\"https://avatars3.githubusercontent.com/u/1164565?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Natan Rolnik</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/svastven\"><img src=\"https://avatars0.githubusercontent.com/u/42235915?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>svastven</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://bhuemer.github.io\"><img src=\"https://avatars2.githubusercontent.com/u/1212480?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Bernhard Huemer</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://djankowski.dev\"><img src=\"https://avatars0.githubusercontent.com/u/10795657?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Daniel Jankowski</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/facumenzella\"><img src=\"https://avatars1.githubusercontent.com/u/1125252?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Facundo Menzella</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/eito\"><img src=\"https://avatars3.githubusercontent.com/u/775643?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Eric Ito</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/laxmorek\"><img src=\"https://avatars2.githubusercontent.com/u/4774319?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kamil Harasimowicz</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/olejnjak\"><img src=\"https://avatars1.githubusercontent.com/u/3148214?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jakub OlejnÃ­k</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lakpa\"><img src=\"https://avatars0.githubusercontent.com/u/389328?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ldindu</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/gtsifrikas\"><img src=\"https://avatars2.githubusercontent.com/u/8904378?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>George Tsifrikas</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/yurapriv\"><img src=\"https://avatars2.githubusercontent.com/u/7814127?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Privezentsev Yura</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://ferologics.github.io\"><img src=\"https://avatars2.githubusercontent.com/u/5576161?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Fero</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://heberti.com\"><img src=\"https://avatars0.githubusercontent.com/u/103670?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Heberti Almeida</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://benscheirman.com\"><img src=\"https://avatars0.githubusercontent.com/u/59140?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ben Scheirman</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://jsorge.net\"><img src=\"https://avatars3.githubusercontent.com/u/2585841?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jared Sorge</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://joeblau.com\"><img src=\"https://avatars1.githubusercontent.com/u/1218847?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Joe Blau</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/dchavezlive\"><img src=\"https://avatars0.githubusercontent.com/u/2475932?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>David Chavez</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/Ñ€Ğ¾Ğ¼Ğ°Ğ½-Ğ¿Ğ¾Ğ´Ñ‹Ğ¼Ğ¾Ğ²-72338ab0/\"><img src=\"https://avatars3.githubusercontent.com/u/10789692?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Roman Podymov</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/marcinreliga-fn\"><img src=\"https://avatars0.githubusercontent.com/u/76949651?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Marcin Religa</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/adellibovi\"><img src=\"https://avatars3.githubusercontent.com/u/67916?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alfredo Delli Bovi</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Jake-Prickett\"><img src=\"https://avatars1.githubusercontent.com/u/26095410?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jake Prickett</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/danyf90\"><img src=\"https://avatars.githubusercontent.com/u/2794031?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Daniele Formichelli</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.facebook.com/PetrachkovSergey\"><img src=\"https://avatars.githubusercontent.com/u/7995896?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sergey Petrachkov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://jinuman.github.io/resume\"><img src=\"https://avatars.githubusercontent.com/u/26243835?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jinwoo, Kim</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/thedavidharris\"><img src=\"https://avatars.githubusercontent.com/u/5666250?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>David Harris</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/DimaMishchenko\"><img src=\"https://avatars.githubusercontent.com/u/25247301?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dmytro Mishchenko</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.sampettersson.com\"><img src=\"https://avatars.githubusercontent.com/u/5459507?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sam Pettersson</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.joshholtz.com\"><img src=\"https://avatars.githubusercontent.com/u/401294?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Josh Holtz</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://jierong.dev\"><img src=\"https://avatars.githubusercontent.com/u/7414906?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jierong Li</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/freak4pc\"><img src=\"https://avatars.githubusercontent.com/u/605076?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Shai Mishali</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/FranzJBusch\"><img src=\"https://avatars.githubusercontent.com/u/3491887?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Franz Busch</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tiarnann\"><img src=\"https://avatars.githubusercontent.com/u/10522081?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>TÃ­arnÃ¡n McGrath</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/softmaxsg\"><img src=\"https://avatars.githubusercontent.com/u/3723817?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vitaly Chupryk</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rmnblm\"><img src=\"https://avatars.githubusercontent.com/u/5942764?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Roman Blum</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://nanotek.me\"><img src=\"https://avatars.githubusercontent.com/u/7265334?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Giovanni Filaferro</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://twitter.com/tovkal\"><img src=\"https://avatars.githubusercontent.com/u/5960675?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>AndrÃ©s PizÃ¡ BÃ¼ckmann</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://coutinho.dev\"><img src=\"https://avatars.githubusercontent.com/u/17842860?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Gabriel Coutinho</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://medium.com/@riccardocipolleschi\"><img src=\"https://avatars.githubusercontent.com/u/11162307?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Riccardo</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/bolismauro\"><img src=\"https://avatars.githubusercontent.com/u/771999?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mauro Bolis</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/iteractive_man\"><img src=\"https://avatars.githubusercontent.com/u/461805?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Peter Weishapl</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://stackoverflow.com/users/1878594/swiftycruz\"><img src=\"https://avatars.githubusercontent.com/u/2609775?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Cruz</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/svenmuennich\"><img src=\"https://avatars.githubusercontent.com/u/1932115?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sven MÃ¼nnich</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/santi-d\"><img src=\"https://avatars.githubusercontent.com/u/993826?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Santiago A. Delgado</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://wojciechkulik.pl\"><img src=\"https://avatars.githubusercontent.com/u/3128467?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Wojciech Kulik</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/iainsmith\"><img src=\"https://avatars.githubusercontent.com/u/993745?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Iain Smith</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/havebeenfitz\"><img src=\"https://avatars.githubusercontent.com/u/31866271?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Max Kraev</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mstfy\"><img src=\"https://avatars.githubusercontent.com/u/5105861?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mustafa Yusuf</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://twitter.com/danielbarden\"><img src=\"https://avatars.githubusercontent.com/u/104456?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Daniel Barden</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/zzzkk\"><img src=\"https://avatars.githubusercontent.com/u/12541603?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Zofia Kulus</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://randombits.org/\"><img src=\"https://avatars.githubusercontent.com/u/3589315?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>David Peterson</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://bandism.net/\"><img src=\"https://avatars.githubusercontent.com/u/22633385?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ikko Ashimine</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/setoelkahfi\"><img src=\"https://avatars.githubusercontent.com/u/1797197?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Seto Elkahfi / å¡æ‰˜Â·åŸƒå°”å¡è²</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://apps4everyone.at\"><img src=\"https://avatars.githubusercontent.com/u/1915802?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>apps4everyone</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/LorDisturbia\"><img src=\"https://avatars.githubusercontent.com/u/12445776?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Lorenzo</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/DarkoDamjanovic\"><img src=\"https://avatars.githubusercontent.com/u/11902775?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Darko Damjanovic</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/MarvinNazari\"><img src=\"https://avatars.githubusercontent.com/u/926772?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Marvin Nazari</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://twitter.com/codeOfRobin\"><img src=\"https://avatars.githubusercontent.com/u/5009041?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Robin Malhotra</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/astromonkee\"><img src=\"https://avatars.githubusercontent.com/u/44421303?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Astromonkee</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ezraberch\"><img src=\"https://avatars.githubusercontent.com/u/49635435?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ezraberch</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/cconstable\"><img src=\"https://avatars.githubusercontent.com/u/564781?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Christopher Constable</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/neakor\"><img src=\"https://avatars.githubusercontent.com/u/1827517?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Yi Wang</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.mustafadur.com\"><img src=\"https://avatars.githubusercontent.com/u/971530?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mustafa Dur</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lucabartoletti\"><img src=\"https://avatars.githubusercontent.com/u/838925?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Luca Bartoletti</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sujata23\"><img src=\"https://avatars.githubusercontent.com/u/1849089?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sujata Chakraborty</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.viber.com\"><img src=\"https://avatars.githubusercontent.com/u/5096762?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Pavel Trafimuk</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://alexsilva.dev/\"><img src=\"https://avatars.githubusercontent.com/u/633535?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alejandro Silva FernÃ¡ndez</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.jakeadams.co\"><img src=\"https://avatars.githubusercontent.com/u/3605966?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jake Adams</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/wattson12\"><img src=\"https://avatars.githubusercontent.com/u/1217873?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sam Watts</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://erkekin.com\"><img src=\"https://avatars.githubusercontent.com/u/701481?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Erk Ekin</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/morozkin\"><img src=\"https://avatars.githubusercontent.com/u/16591888?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Denis Morozov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/orbitekk\"><img src=\"https://avatars.githubusercontent.com/u/4222449?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>orbitekk</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://blog.naver.com/wogus3602\"><img src=\"https://avatars.githubusercontent.com/u/46857148?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Park Jae Hyun</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/regularberry\"><img src=\"https://avatars.githubusercontent.com/u/565192?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sean Berry</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://hisaac.net\"><img src=\"https://avatars.githubusercontent.com/u/923876?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Isaac Halvorson</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mohitsaxenaknoldus\"><img src=\"https://avatars.githubusercontent.com/u/76725454?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mohit Saxena</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mikchmie\"><img src=\"https://avatars.githubusercontent.com/u/15248837?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>MikoÅ‚aj Chmielewski</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/takinwande\"><img src=\"https://avatars.githubusercontent.com/u/4744429?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Tope Akinwande</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.theinkedengineer.com\"><img src=\"https://avatars.githubusercontent.com/u/13349066?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>TheInkedEngineer</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://alexanderweiss.dev\"><img src=\"https://avatars.githubusercontent.com/u/12934015?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alexander WeiÃŸ</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kyungpyoda\"><img src=\"https://avatars.githubusercontent.com/u/44656036?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kyungpyoda</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.villewitt.net\"><img src=\"https://avatars.githubusercontent.com/u/522544?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ville Witt</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/paulsamuels\"><img src=\"https://avatars.githubusercontent.com/u/527091?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>paul.s</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/aniltaskiran\"><img src=\"https://avatars.githubusercontent.com/u/16738729?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>aniltaskiran</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/unxavi\"><img src=\"https://avatars.githubusercontent.com/u/3817679?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Javier Vieira</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/a-sarris\"><img src=\"https://avatars.githubusercontent.com/u/78614622?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Aris Sarris</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://xxw9999.notion.site/xxw9999/iOS-8585a34b2886419586960c5c02b9d845\"><img src=\"https://avatars.githubusercontent.com/u/67373938?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kimxwan0319</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://florian.codes\"><img src=\"https://avatars.githubusercontent.com/u/7734806?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Florian Fittschen</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jesus-mg-ios\"><img src=\"https://avatars.githubusercontent.com/u/85997060?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jesus (iOS)</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nicholaskim94\"><img src=\"https://avatars.githubusercontent.com/u/7912759?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Nicholas Kim</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Smponias\"><img src=\"https://avatars.githubusercontent.com/u/14213855?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alexandros Smponias</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mangofever\"><img src=\"https://avatars.githubusercontent.com/u/724343?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Go</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/AlbGarciam\"><img src=\"https://avatars.githubusercontent.com/u/45308839?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alberto Garcia</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/andreascuderi/\"><img src=\"https://avatars.githubusercontent.com/u/8319309?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andrea Scuderi</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://dogoautilio.wordpress.com/\"><img src=\"https://avatars.githubusercontent.com/u/1487375?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Diogo Autilio</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/shahzadmajeed\"><img src=\"https://avatars.githubusercontent.com/u/1209459?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Shahzad Majeed</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/danrevah\"><img src=\"https://avatars.githubusercontent.com/u/7808742?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dan</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nivanchikov\"><img src=\"https://avatars.githubusercontent.com/u/1830010?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Nikita Ivanchikov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/xoxo-anastasi-xoxo\"><img src=\"https://avatars.githubusercontent.com/u/28875920?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Anastasia Kazantseva</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/MonocularVision\"><img src=\"https://avatars.githubusercontent.com/u/429790?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Michael McGuire</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.michaelfcollins3.me\"><img src=\"https://avatars.githubusercontent.com/u/104274?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Michael Collins</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/devyhan\"><img src=\"https://avatars.githubusercontent.com/u/45344633?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>YoHan Cho</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/euriasb\"><img src=\"https://avatars.githubusercontent.com/u/3721257?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>euriasb</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/MontakOleg\"><img src=\"https://avatars.githubusercontent.com/u/1800899?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>MontakOleg</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/oozoofrog\"><img src=\"https://avatars.githubusercontent.com/u/3011832?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>oozoofrog</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/MartinStrambach\"><img src=\"https://avatars.githubusercontent.com/u/11178869?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Martin Strambach</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sh-a-n\"><img src=\"https://avatars.githubusercontent.com/u/2219548?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>sh-a-n</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://linkedin.com/in/batuhansaka\"><img src=\"https://avatars.githubusercontent.com/u/9626765?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Batuhan Saka</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://jcsoohwancho.github.io\"><img src=\"https://avatars.githubusercontent.com/u/51935215?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>SooHwanCho</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.bouncingball.mobi\"><img src=\"https://avatars.githubusercontent.com/u/798117?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Gary Riches</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://mustiikhalil.github.io/mustiikhalil/\"><img src=\"https://avatars.githubusercontent.com/u/26250654?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>mustiikhalil</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/serejahh\"><img src=\"https://avatars.githubusercontent.com/u/2575555?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Serhii Butenko</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/petrukha-ivan\"><img src=\"https://avatars.githubusercontent.com/u/93926277?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Petrukha Ivan</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lo1tuma\"><img src=\"https://avatars.githubusercontent.com/u/169170?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mathias Schreck</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Buju77\"><img src=\"https://avatars.githubusercontent.com/u/266349?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Yen-Chia Lin</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://coolmathgames.tech\"><img src=\"https://avatars.githubusercontent.com/u/6877780?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mary </b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/woohyunjin06\"><img src=\"https://avatars.githubusercontent.com/u/30452977?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Hyunjin</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kevin58332\"><img src=\"https://avatars.githubusercontent.com/u/47673410?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kevin Aguilar</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://andrewroan.com\"><img src=\"https://avatars.githubusercontent.com/u/9873566?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andrew Roan</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/ibrahim-oktay-518b4939/\"><img src=\"https://avatars.githubusercontent.com/u/36792481?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ibrahim oktay</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/navartis\"><img src=\"https://avatars.githubusercontent.com/u/7813723?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dmitriy Kulakov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/woin2ee\"><img src=\"https://avatars.githubusercontent.com/u/81426024?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jaewon-Yun</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tatagrigory\"><img src=\"https://avatars.githubusercontent.com/u/5187973?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>tatagrigory</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://linkedin.com/in/denilchungath\"><img src=\"https://avatars.githubusercontent.com/u/95201442?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Denil Chungath</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/victor-sarda/\"><img src=\"https://avatars.githubusercontent.com/u/6460866?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Victor Sarda</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tzxdtc\"><img src=\"https://avatars.githubusercontent.com/u/19767846?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>tzxdtc10</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ThiemeFM\"><img src=\"https://avatars.githubusercontent.com/u/143395823?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Thieme</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Lilfaen\"><img src=\"https://avatars.githubusercontent.com/u/39119695?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Clemens Beck</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://macpaw.com/\"><img src=\"https://avatars.githubusercontent.com/u/119268?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Paul Taykalo</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/in4lio\"><img src=\"https://avatars.githubusercontent.com/u/976061?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vitaly Kravtsov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://dc.wtf\"><img src=\"https://avatars.githubusercontent.com/u/643865?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>dc</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/baekteun\"><img src=\"https://avatars.githubusercontent.com/u/74440939?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>baegteun</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://vcoutasso.com\"><img src=\"https://avatars.githubusercontent.com/u/44986513?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>VinÃ­cius Couto Tasso</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://blog.jihoon.me\"><img src=\"https://avatars.githubusercontent.com/u/68891494?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ì•ˆì§€í›ˆ</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dxmvsh\"><img src=\"https://avatars.githubusercontent.com/u/44325936?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dimash</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/danibachar\"><img src=\"https://avatars.githubusercontent.com/u/6380777?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>danibachar</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dp221125\"><img src=\"https://avatars.githubusercontent.com/u/10572119?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>í•œì„í˜¸(MilKyo)</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://medium.com/@haifengkaohaifengkao&usg=AOvVaw2_xG-ZLdBawBIyS7m-99RQ\"><img src=\"https://avatars.githubusercontent.com/u/4080524?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Hai Feng Kao</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/anlaital-oura\"><img src=\"https://avatars.githubusercontent.com/u/133648611?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Antti Laitala</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/PushedCrayon\"><img src=\"https://avatars.githubusercontent.com/u/37077444?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>PushedCrayon</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://stefanomondino.com\"><img src=\"https://avatars.githubusercontent.com/u/1691903?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Stefano Mondino</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/leszko11\"><img src=\"https://avatars.githubusercontent.com/u/23533452?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Åukasz Lech</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/costapombo\"><img src=\"https://avatars.githubusercontent.com/u/31352351?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>costapombo</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/isavynskyi\"><img src=\"https://avatars.githubusercontent.com/u/18377497?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ihor Savynskyi</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kapitoshka438\"><img src=\"https://avatars.githubusercontent.com/u/3232401?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Eduard Miniakhmetov</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/alexfilimon\"><img src=\"https://avatars.githubusercontent.com/u/19904867?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alexander Filimonov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rofle100lvl\"><img src=\"https://avatars.githubusercontent.com/u/45801227?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Gorbenko Roman</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/lucas-paim/\"><img src=\"https://avatars.githubusercontent.com/u/7849484?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Lucas Mrowskovsky Paim</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://actuallytaylor.com\"><img src=\"https://avatars.githubusercontent.com/u/32944568?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Taylor Lineman</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nandodelauni\"><img src=\"https://avatars.githubusercontent.com/u/1938501?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Miguel Ferrando</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/barredewe\"><img src=\"https://avatars.githubusercontent.com/u/19188911?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>BarredEwe</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/chris-livefront\"><img src=\"https://avatars.githubusercontent.com/u/126101032?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Chris Sessions</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ajkolean\"><img src=\"https://avatars.githubusercontent.com/u/5394701?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andy Kolean</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Binlogo\"><img src=\"https://avatars.githubusercontent.com/u/7845507?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Binlogo</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/DevilDimon\"><img src=\"https://avatars.githubusercontent.com/u/10220441?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dmitry Serov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://darrarski.pl\"><img src=\"https://avatars.githubusercontent.com/u/1384684?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dariusz Rybicki</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dansinclair25\"><img src=\"https://avatars.githubusercontent.com/u/2573447?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dan Sinclair</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.kaioelfke.de\"><img src=\"https://avatars.githubusercontent.com/u/1190948?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kai Oelfke</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://stackoverflow.com/users/468724/inder-kumar-rathore\"><img src=\"https://avatars.githubusercontent.com/u/352443?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Inder</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kyounh12\"><img src=\"https://avatars.githubusercontent.com/u/25301615?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kyounh12</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/alvar-bolt\"><img src=\"https://avatars.githubusercontent.com/u/72379847?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alvar Hansen</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/barakwei\"><img src=\"https://avatars.githubusercontent.com/u/5232161?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Barak Weiss</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/hiltonc\"><img src=\"https://avatars.githubusercontent.com/u/470753?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Hilton Campbell</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rgnns\"><img src=\"https://avatars.githubusercontent.com/u/811827?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Gabriel LiÃ©vano</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/vijaytholpadi\"><img src=\"https://avatars.githubusercontent.com/u/1171868?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vijay Tholpadi</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://withiosdeveloper.blogspot.com/\"><img src=\"https://avatars.githubusercontent.com/u/27220138?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Minhoi Goo</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sphanley\"><img src=\"https://avatars.githubusercontent.com/u/1323769?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sam Hanley</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ahmdyasser\"><img src=\"https://avatars.githubusercontent.com/u/42544598?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ahmdyasser</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/minhaaan\"><img src=\"https://avatars.githubusercontent.com/u/87178301?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>minhaaan</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/TamarMilchtaich\"><img src=\"https://avatars.githubusercontent.com/u/49520876?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Tamar Milchtaich Lavi</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rock88\"><img src=\"https://avatars.githubusercontent.com/u/323908?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andrey K</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://2stable.com\"><img src=\"https://avatars.githubusercontent.com/u/69604865?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alex Vera</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.annalisemariottini.com\"><img src=\"https://avatars.githubusercontent.com/u/14299642?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Annalise Mariottini</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/gustn3965\"><img src=\"https://avatars.githubusercontent.com/u/48749182?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>HyunSu Park</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/vldalx\"><img src=\"https://avatars.githubusercontent.com/u/13873200?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vladimir</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://rhysmorgan.co\"><img src=\"https://avatars.githubusercontent.com/u/11096937?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Rhys Morgan</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pierrerodgers\"><img src=\"https://avatars.githubusercontent.com/u/48193278?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>pierrerodgers</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/honghoker\"><img src=\"https://avatars.githubusercontent.com/u/50417461?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>eunpyo hong</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://medium.com/@dbstj169\"><img src=\"https://avatars.githubusercontent.com/u/65678579?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Yunseo Kang</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ilia3546\"><img src=\"https://avatars.githubusercontent.com/u/4445510?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ilya Kharlamov</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/brianvar\"><img src=\"https://avatars.githubusercontent.com/u/115399684?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>brianvar</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/HossamYoussof\"><img src=\"https://avatars.githubusercontent.com/u/6381926?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Hossam Youssof</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/devMinseok\"><img src=\"https://avatars.githubusercontent.com/u/51021614?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Minseok Kang</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/alpanyukov\"><img src=\"https://avatars.githubusercontent.com/u/36258478?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alexander</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sanghyeok-kim\"><img src=\"https://avatars.githubusercontent.com/u/57667738?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Loyle</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/vvisionnn\"><img src=\"https://avatars.githubusercontent.com/u/24761186?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ydna</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://brucemcrooster.dev\"><img src=\"https://avatars.githubusercontent.com/u/53529192?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Evan</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.snipnotes.de\"><img src=\"https://avatars.githubusercontent.com/u/5102728?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Felix Lisczyk</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lukaswuerzburger\"><img src=\"https://avatars.githubusercontent.com/u/10812458?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Lukas WÃ¼rzburger</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/GetToSet\"><img src=\"https://avatars.githubusercontent.com/u/8158163?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ethan Wong</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://tdkn.dev\"><img src=\"https://avatars.githubusercontent.com/u/1296540?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Shun Tedokon</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://connorricks.com\"><img src=\"https://avatars.githubusercontent.com/u/13373737?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Connor Ricks</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://franciscodiaz.cl\"><img src=\"https://avatars.githubusercontent.com/u/530662?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Francisco Diaz</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Ethan-IS\"><img src=\"https://avatars.githubusercontent.com/u/140235921?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ethan Parker</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lukevanin\"><img src=\"https://avatars.githubusercontent.com/u/550579?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Luke Van In</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://mustafataibah.vercel.app/\"><img src=\"https://avatars.githubusercontent.com/u/83141712?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mustafa Taibah</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/vkondrashkov\"><img src=\"https://avatars.githubusercontent.com/u/16046780?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vladislav Kondrashkov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/chrisjrex\"><img src=\"https://avatars.githubusercontent.com/u/4457170?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Christopher Rex</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/bahattinkoc\"><img src=\"https://avatars.githubusercontent.com/u/61124759?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>baaddin</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mattjung\"><img src=\"https://avatars.githubusercontent.com/u/19891158?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Matt Jung</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://imaginativeworld.org\"><img src=\"https://avatars.githubusercontent.com/u/1952630?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Md. Mahmudul Hasan Shohag</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://ma.tyas.cz\"><img src=\"https://avatars.githubusercontent.com/u/6033733?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Matty Cross</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/YIshihara11201\"><img src=\"https://avatars.githubusercontent.com/u/98417271?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>YIshihara11201</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/PhilippeWeidmann\"><img src=\"https://avatars.githubusercontent.com/u/5843044?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Philippe Weidmann</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Zentaur0\"><img src=\"https://avatars.githubusercontent.com/u/75909658?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Anton SVTSV</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://johannes.plunien.com\"><img src=\"https://avatars.githubusercontent.com/u/31597?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Johannes Plunien</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://emirhankarahan.com\"><img src=\"https://avatars.githubusercontent.com/u/48404459?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Emirhan KARAHAN</b></sub></a></td>\n    </tr>\n  </tbody>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n",
      "stars_today": 2
    },
    {
      "id": 15333809,
      "name": "open62541",
      "full_name": "open62541/open62541",
      "description": "Open source implementation of OPC UA (OPC Unified Architecture) aka IEC 62541 licensed under Mozilla Public License v2.0",
      "html_url": "https://github.com/open62541/open62541",
      "stars": 3024,
      "forks": 1391,
      "language": "C",
      "topics": [
        "c",
        "client",
        "iec-62541",
        "industrial-automation",
        "opc",
        "opc-ua",
        "opcua",
        "publish-subscribe",
        "pubsub",
        "sdk",
        "server",
        "tsn"
      ],
      "created_at": "2013-12-20T08:45:05Z",
      "updated_at": "2026-02-06T22:53:05Z",
      "pushed_at": "2026-02-05T11:58:45Z",
      "open_issues": 884,
      "owner": {
        "login": "open62541",
        "avatar_url": "https://avatars.githubusercontent.com/u/16096536?v=4"
      },
      "readme": "<div align=\"center\">\n  <a href=\"https://open62541.org\">\n    <img alt=\"open62541 Logo\" src=\"https://open62541.org/images/logo-open62541.svg\" width=\"400px\">\n  </a>\n  <br />\n  <a href=\"https://open62541.org\" target=\"_blank\" rel=\"noopener\">https://open62541.org</a> | <a href=\"https://www.o6-automation.com\" target=\"_blank\" rel=\"noopener\">https://www.o6-automation.com</a>\n</div>\n<br />\n\nopen62541 (<http://open62541.org>) is an open source implementation of OPC UA (OPC Unified Architecture / IEC 62541) written in the C language. The library is usable with all major compilers and provides the necessary tools to implement dedicated OPC UA clients and servers, or to integrate OPC UA-based communication into existing applications. See the [features overview](FEATURES.md) for full details.\nThe open62541 library is platform independent: All platform-specific functionality is implemented via exchangeable plugins for easy porting to different (embedded) targets.\n\nopen62541 is licensed under the Mozilla Public License v2.0 (MPLv2). This allows the open62541 library to be combined and distributed with any proprietary software. Only changes to the open62541 library itself need to be licensed under the MPLv2 when copied and distributed. Some plugins and examples are in the public domain (CC0 license) and some are licensed under MPLv2. The CC0 licensed ones can be reused under any license and changes do not have to be published.\n\nThe library is available in standard source and binary form. In addition, the single-file source distribution merges the entire library into a single .c and .h file that can be easily added to existing projects. Example server and client implementations can be found in the [/examples](examples/) directory or further down on this page.\n\n[![Open Hub Project Status](https://www.openhub.net/p/open62541/widgets/project_thin_badge.gif)](https://www.openhub.net/p/open62541/)\n[![Build Status](https://ci.appveyor.com/api/projects/status/github/open62541/open62541?branch=master&svg=true)](https://ci.appveyor.com/project/open62541/open62541/branch/master)\n[![Code Scanning](https://github.com/open62541/open62541/actions/workflows/codeql.yml/badge.svg)](https://github.com/open62541/open62541/actions/workflows/codeql.yml)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/open62541.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:open62541)\n[![codecov](https://codecov.io/gh/open62541/open62541/branch/master/graph/badge.svg)](https://codecov.io/gh/open62541/open62541)\n\n## Documentation and Support\n\nA general introduction to OPC UA and the open62541 documentation can be found at http://open62541.org.\nPast releases of the library can be downloaded at https://github.com/open62541/open62541/releases.\n\nThe overall open62541 community handles public support requests on Github and the mailing list.\nFor individual discussion and support, use the following channels:\n\n- [Mailing List](https://groups.google.com/d/forum/open62541)\n- [Issue Tracker](https://github.com/open62541/open62541/issues)\n- [Pull Requests](https://github.com/open62541/open62541/pulls)\n\n[o6 Automation GmbH](https://www.o6-automation.com/) employs the core contributors to open62541 and provides **[commercial support](https://www.o6-automation.com/services)**.\nThe project is however open to outside contributions and **contributors retain their individual copyright**. This prevents future relicensing under different license conditions.\n\nWe want to foster an open and welcoming community. Please take our [code of conduct](CODE_OF_CONDUCT.md) into regard.\n\n## Commercial Use\n\nopen62541 is licensed under the MPLv2. That is, changes to files under MPLv2 fall under the same open-source license.\nBut the library can be combined with private development from separate files, also if a static binary is produced, without the license affecting the private files.\nSee the full [license document](LICENSE) for details.\n\n## Official Certification\n\nAn example server built with open62541 v1.4 was certified for the 'Standard Server 2017 Profile' by the OPC Foundation.\nSee https://open62541.org/certification for more details.\n\n## Build System, Code Structure and Dependencies\n\nThe build environment of open62541 is generated via CMake. See the [build documentation](https://www.open62541.org/doc/master/building.html) for details.\nTo simplify the integration with existing software projects, the open62541 sources can be compressed (amalgamated) into a single-file-distribution, a pair of `open62541.c/.h` files.\nThe functionality included in the single-file-distribution depends on the current CMake configuration.\n\nThe source code is structured as follows:\n\n- Public API (`/include`): The public API is exposed to applications using open62541. The headers for plugin implementations are in `/plugins/include`.\n- Core Library (`/src`): The core library has no dependencies besides the C99 standard headers.\n- Architecture Support (`/arch`): Architecture support is implemented via the `EventLoop` plugin. This keeps the architecture-specific code - for example to use the POSIX APIs - out of the core library. Ports to different (embedded) architectures are provided.\n- Default Plugins Implementations (`/plugins`): The plugin interfaces allow the integration with different backend systems and libraries. For example concerning crypto primitives, storage of the information model, and so on. Default implementations are provided.\n- Dependencies (`/deps`): Some additional libraries are used via git submodules or have been internalized in the `deps/` folder. More information on the third-party libraries and their respective licenses can be found in [deps/README.md](deps/README.md)\n- Building and Code Generation: Some code is auto-generated from XML definitions that are part of the OPC UA standard. The code generation scripts use Python as part of the build process.\n\nOn most systems, a bare-bones open62541 requires the C standard library only.\nDepending on the build configuration, open62541 depends on additional libraries, such as mbedTLS or OpenSSL for encryption.\n\n## Development\n\nAs an open source project, new contributors are encouraged to help improve open62541.\nThe file [CONTRIBUTING.md](CONTRIBUTING.md) aggregates good practices that we expect for code contributions.\nThe following are good starting points for new contributors:\n\n- [Report bugs](https://github.com/open62541/open62541/issues)\n- Improve the [documentation](http://open62541.org/doc/current)\n- Work on issues marked as \"[good first issue](https://github.com/open62541/open62541/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22)\"\n\nFor custom development that shall eventually become part of the open62541 library, please keep one of the core maintainers in the loop.\n\n### Code Quality\n\nWe emphasize code quality. The following quality metrics are continuously checked and are ensured to hold before an official release is made:\n\n- Zero errors indicated by the Compliance Testing Tool (CTT) of the OPC Foundation for the supported features\n- Zero compiler warnings from GCC/Clang/MSVC with very strict compilation flags\n- Zero issues indicated by unit tests (we target more than 80% code coverage)\n- Zero issues indicated by clang-analyzer, clang-tidy, cpp-check and the Codacy static code analysis tools\n- Zero unresolved issues from fuzzing the library in Google's oss-fuzz infrastructure\n- Zero issues indicated by Valgrind (Linux), DrMemory (Windows) and Clang AddressSanitizer / MemorySanitizer for the CTT tests, unit tests and fuzzing\n\n### Security and Vulnerability Handling\n\nThe project has established a process for handling vulnerabilities.\nSee the [SECURITY.md](SECURITY.md) for details and how to responsibly disclose findings to the maintainers.\n\n## Installation and Examples\n\nOn Debian/Ubuntu systems, a simple ```apt install libopen62541-1.4-dev``` installs the library and the development header files.\nUsing the GCC compiler, just run ```gcc -std=c99 <server.c> -lopen62541 -o server```.\n\nA more detailed explanation on how to install the open62541 SDK is given in our [documentation](https://www.open62541.org/doc/master/building.html#building-the-library).\nIn essence, clone the repository and initialize all the submodules using `git submodule update --init --recursive`. Then use CMake to configure your build.\n\nA complete list of examples can be found in the [examples directory](https://github.com/open62541/open62541/tree/master/examples).\n\n### Example Server Implementation\n\n```c\n#include <open62541/server.h>\n\nint main(int argc, char** argv)\n{\n    /* Create a server listening on port 4840 (default) */\n    UA_Server *server = UA_Server_new();\n\n    /* Add a variable node to the server */\n\n    /* 1) Define the variable attributes */\n    UA_VariableAttributes attr = UA_VariableAttributes_default;\n    attr.displayName = UA_LOCALIZEDTEXT(\"en-US\", \"the answer\");\n    UA_Int32 myInteger = 42;\n    UA_Variant_setScalar(&attr.value, &myInteger, &UA_TYPES[UA_TYPES_INT32]);\n\n    /* 2) Define where the node shall be added with which browsename */\n    UA_NodeId newNodeId = UA_NODEID_STRING(1, \"the.answer\");\n    UA_NodeId parentNodeId = UA_NS0ID(OBJECTSFOLDER);\n    UA_NodeId parentReferenceNodeId = UA_NS0ID(ORGANIZES);\n    UA_NodeId variableType = UA_NODEID_NULL; /* take the default variable type */\n    UA_QualifiedName browseName = UA_QUALIFIEDNAME(1, \"the answer\");\n\n    /* 3) Add the node */\n    UA_Server_addVariableNode(server, newNodeId, parentNodeId,\n                              parentReferenceNodeId, browseName,\n                              variableType, attr, NULL, NULL);\n\n    /* Run the server (until ctrl-c interrupt) */\n    UA_StatusCode status = UA_Server_runUntilInterrupt(server);\n\n    /* Clean up */\n    UA_Server_delete(server);\n    return status == UA_STATUSCODE_GOOD ? EXIT_SUCCESS : EXIT_FAILURE;\n}\n```\n\n### Example Client Implementation\n\n```c\n#include <stdio.h>\n#include <open62541/client.h>\n#include <open62541/client_highlevel.h>\n\nint main(int argc, char *argv[])\n{\n    /* Create a client and connect */\n    UA_Client *client = UA_Client_new();\n    UA_ClientConfig_setDefault(UA_Client_getConfig(client));\n    UA_StatusCode status = UA_Client_connect(client, \"opc.tcp://localhost:4840\");\n    if(status != UA_STATUSCODE_GOOD) {\n        UA_Client_delete(client);\n        return status;\n    }\n\n    /* Read the value attribute of the node. UA_Client_readValueAttribute is a\n     * wrapper for the raw read service available as UA_Client_Service_read. */\n    UA_Variant value; /* Variants can hold scalar values and arrays of any type */\n    UA_Variant_init(&value);\n    status = UA_Client_readValueAttribute(client, UA_NODEID_STRING(1, \"the.answer\"), &value);\n    if(status == UA_STATUSCODE_GOOD &&\n       UA_Variant_hasScalarType(&value, &UA_TYPES[UA_TYPES_INT32])) {\n        printf(\"the value is: %i\\n\", *(UA_Int32*)value.data);\n    }\n\n    /* Clean up */\n    UA_Variant_clear(&value);\n    UA_Client_delete(client); /* Disconnects the client internally */\n    return status == UA_STATUSCODE_GOOD ? EXIT_SUCCESS : EXIT_FAILURE;\n}\n```\n",
      "stars_today": 2
    },
    {
      "id": 143079594,
      "name": "swift-syntax",
      "full_name": "swiftlang/swift-syntax",
      "description": "A set of Swift libraries for parsing, inspecting, generating, and transforming Swift source code.",
      "html_url": "https://github.com/swiftlang/swift-syntax",
      "stars": 3607,
      "forks": 489,
      "language": "Swift",
      "topics": [],
      "created_at": "2018-07-31T23:19:58Z",
      "updated_at": "2026-02-05T22:38:49Z",
      "pushed_at": "2026-02-06T11:57:38Z",
      "open_issues": 159,
      "owner": {
        "login": "swiftlang",
        "avatar_url": "https://avatars.githubusercontent.com/u/42816656?v=4"
      },
      "readme": "# Swift Syntax\n\nThe swift-syntax package is a set of libraries that work on a source-accurate tree representation of Swift source code, called the SwiftSyntax tree. The SwiftSyntax tree forms the backbone of Swiftâ€™s macro system â€“ the macro expansion nodes are represented as SwiftSyntax nodes and a macro generates a SwiftSyntax tree to be inserted into the source file.\n\n## Documentation\n\nYou can read SwiftSyntaxâ€™s documentation on [swiftpackageindex.com](https://swiftpackageindex.com/swiftlang/swift-syntax/documentation).\n\nA great way to interactively explore the SwiftSyntax tree of a source file is https://swift-ast-explorer.com, developed by [@kishikawakatsumi](https://github.com/kishikawakatsumi).\n\nA set of example usages of swift-syntax can be found in [Examples](Examples).\n\n## Releases\n\nReleases of SwiftSyntax are aligned with corresponding language and tooling releases, for example the major version 509 of swift-syntax is aligned with Swift 5.9. \n \nTo depend on swift-syntax in a SwiftPM package, add the following to your `Package.swift`.\n\n\n```swift\ndependencies: [\n  .package(url: \"https://github.com/swiftlang/swift-syntax.git\", from: \"<#latest swift-syntax tag#>\"),\n],\n```\n \nTo add swift-syntax as a dependency of your Xcode project, go to the *Package Dependencies* tab of your Xcode project, click the plus button and search for https://github.com/swiftlang/swift-syntax.git.\n\n## Reporting Issues\n\nIf you should hit any issues while using SwiftSyntax, we appreciate bug reports on [GitHub Issue](https://github.com/swiftlang/swift-syntax/issues).\n\n## Contributing\n\nStart contributing to SwiftSyntax see [this guide](CONTRIBUTING.md) for more information.\n\n## Bazel\n\nSwiftSyntax provides an experimental [Bazel](https://bazel.build) build configuration, maintained by Keith Smiley. \nTo use it, you can pull the source archive from the relevant release tag\ninto your `MODULE.bazel` file (preferred and recommended) with `bazel_dep`. Bzlmod support was added starting release of `509.0.0` and above. All available versions can be found in the [Bazel Central Registry](https://registry.bazel.build/modules/swift-syntax)\n\n```python3\nbazel_dep(name = \"swift-syntax\", version = \"600.0.1\")\n```\n\nYou can also pull source archive with `WORKSPACE` but note that it is preferred to use `MODULE.bazel`. To use `WORKSPACE` and swift-syntax, you can use `http_archive` as such\n\n```python3\nhttp_archive(\n    name = \"SwiftSyntax\",\n    sha256 = \"f070fd44db9b33f430fd5b5d2700f1e2001c0028711859600e80cc975074fab0\",\n    strip_prefix = \"swift-syntax-509.1.0\",\n    url = \"https://github.com/apple/swift-syntax/archive/refs/tags/509.1.0.tar.gz\",\n)\n```\n\nand depend on the libraries you need from the\n[`BUILD.bazel`](BUILD.bazel) file. Each library also has an associated\n`Library_opt` target (such as `SwiftSyntax_opt`) which forces\nSwiftSyntax to always build with optimizations enabled. This may help\nlocal runtime performance at the cost of debuggability, and initial\nbuild time. Please tag any [issues](https://github.com/swiftlang/swift-syntax/issues) related to the Bazel configuration with the label \"Bazel\".\n\n## License\n\nPlease see [LICENSE](LICENSE.txt) for more information.\n",
      "stars_today": 2
    },
    {
      "id": 746689243,
      "name": "kafka-ui",
      "full_name": "kafbat/kafka-ui",
      "description": "Open-Source Web UI for managing Apache Kafka clusters",
      "html_url": "https://github.com/kafbat/kafka-ui",
      "stars": 2003,
      "forks": 252,
      "language": "Java",
      "topics": [
        "apache-kafka",
        "big-data",
        "cluster-management",
        "event-streaming",
        "foss",
        "hacktoberfest",
        "kafka",
        "kafka-brokers",
        "kafka-client",
        "kafka-cluster",
        "kafka-connect",
        "kafka-manager",
        "kafka-producer",
        "kafka-streams",
        "kafka-ui",
        "opensource",
        "streaming-data",
        "streams",
        "web-ui"
      ],
      "created_at": "2024-01-22T13:38:08Z",
      "updated_at": "2026-02-06T22:43:17Z",
      "pushed_at": "2026-02-06T21:00:29Z",
      "open_issues": 261,
      "owner": {
        "login": "kafbat",
        "avatar_url": "https://avatars.githubusercontent.com/u/98461227?v=4"
      },
      "readme": "<div align=\"center\">\n<img src=\"documentation/images/logo_new.png\" alt=\"logo\"/>\n<h3>Kafbat UI</h3>\n\nVersatile, fast and lightweight web UI for managing Apache KafkaÂ® clusters.\n</div>\n\n<div align=\"center\">\n<a href=\"https://github.com/kafbat/kafka-ui/blob/main/LICENSE\"><img src=\"https://img.shields.io/badge/License-Apache%202.0-blue.svg\" alt=\"License\"/></a>\n<img src=\"documentation/images/free-open-source.svg\" alt=\"price free\"/>\n<a href=\"https://github.com/kafbat/kafka-ui/releases\"><img src=\"https://img.shields.io/github/v/release/kafbat/kafka-ui\" alt=\"latest release version\"/></a>\n<a href=\"https://discord.gg/4DWzD7pGE5\"><img src=\"https://img.shields.io/discord/897805035122077716\" alt=\"discord online number count\"/></a>\n<a href=\"https://github.com/sponsors/kafbat\"><img src=\"https://img.shields.io/github/sponsors/kafbat?style=flat&logo=githubsponsors&logoColor=%23EA4AAA&label=Support%20us\" alt=\"\" /></a>\n</div>\n\n<p align=\"center\">\n    <a href=\"https://ui.docs.kafbat.io/\">Documentation</a> â€¢ \n    <a href=\"https://ui.docs.kafbat.io/quick-start/demo-run\">Quick Start</a> â€¢ \n    <a href=\"https://discord.gg/4DWzD7pGE5\">Community</a>\n    <br/>\n    <a href=\"https://aws.amazon.com/marketplace/pp/prodview-6tdqqzzjwmejq\">AWS Marketplace</a>  â€¢\n    <a href=\"https://www.producthunt.com/products/ui-for-apache-kafka/reviews/new\">ProductHunt</a>\n</p>\n\n<p align=\"center\">\n  <img src=\"https://repobeats.axiom.co/api/embed/88d2bd9887380c7d86e2f986725d9af52ebad7f4.svg\" alt=\"stats\"/>\n</p>\n\n#### Kafbat UI is a free, open-source web UI to monitor and manage Apache Kafka clusters.\n\n[Kafbat UI](https://kafbat.io/) is a simple tool that makes your data flows observable, helps find and troubleshoot issues faster and deliver optimal performance. Its lightweight dashboard makes it easy to track key metrics of your Kafka clusters - Brokers, Topics, Partitions, Production, and Consumption.\n\n<i>\nKafbat UI, developed by <b>Kafbat</b>*, proudly carries forward the legacy of the UI Apache Kafka project.\nOur dedication is reflected in the continuous evolution of the project, ensuring adherence to its foundational vision while adapting to meet modern demands.\nWe extend our gratitude to Provectus for their past support in groundbreaking work, which serves as a cornerstone for our ongoing innovation and dedication.\n\n<b>*</b> - The <b>Kafbat</b> team comprises key contributors from the project's inception, bringing a wealth of experience and insight to this renewed endeavor.\n</i>\n\n# Interface\n\n![Interface](https://raw.githubusercontent.com/kafbat/kafka-ui/images/overview.gif)\n\n# Features\n\n* **Topic Insights** â€“ View essential topic details including partition count, replication status, and custom configurations.\n* **Configuration Wizard** â€“ Set up and configure your Kafka clusters directly through the UI.\n* **Multi-Cluster Management** â€“ Monitor and manage all your Kafka clusters in one unified interface.\n* **Metrics Dashboard** â€“ Track key Kafka metrics in real time with a streamlined, lightweight dashboard.\n* **Kafka Brokers Overview** â€“ Inspect brokers, including partition assignments and controller status.\n* **Consumer Group Details** â€“ Analyze parked offsets per partition, and monitor both combined and partition-specific lag.\n* **Message Browser** â€“ Explore messages in JSON, plain text, or Avro encoding formats. Live view is supported, enriched with user-defined CEL message filters.\n* **Dynamic Topic Management** â€“ Create and configure new topics with flexible, real-time settings.\n* **Pluggable Authentication** â€“ Secure your UI using OAuth 2.0 (GitHub, GitLab, Google), LDAP, or basic authentication.\n* **Cloud IAM Support** â€“ Integrate with **GCP IAM**, **Azure IAM**, and **AWS IAM** for cloud-native identity and access management.\n* **Managed Kafka Service Support** â€“ Full support for **Azure EventHub**, **Google Cloud Managed Service for Apache Kafka**, and **AWS Managed Streaming for Apache Kafka (MSK)**â€”both server-based and serverless.\n* **Custom SerDe Plugin Support** â€“ Use built-in serializers/deserializers like AWS Glue and Smile, or create your own custom plugins.\n* **Role-Based Access Control** â€“ [Manage granular UI permissions](https://ui.docs.kafbat.io/configuration/rbac-role-based-access-control) with RBAC.\n* **Data Masking** â€“ [Obfuscate sensitive data](https://ui.docs.kafbat.io/configuration/data-masking) in topic messages to enhance privacy and compliance.\n* **MCP Server** - [Model Context Protocol](https://ui.docs.kafbat.io/faq/mcp) Server\n\n\n## Feature overview\n\n<details>\n    <summary>Click here for the feature overview</summary>\n\n# The Interface\nKafbat UI wraps major functions of Apache Kafka with an intuitive user interface.\n\n![Interface](documentation/images/Interface.gif)\n\n## Topics\nKafbat UI makes it easy for you to create topics in your browser with just a few clicks, by pasting your own parameters, and viewing topics in the list.\n\n![Create Topic](documentation/images/Create_topic_kafka-ui.gif)\n\nYou can jump from the connectors view to corresponding topics and from a topic to consumers (back and forth) for more convenient navigation, including connectors and overview topic settings.\n\n![Connector_Topic_Consumer](documentation/images/Connector_Topic_Consumer.gif)\n\n### Messages\nSuppose you want to produce messages for your topic. With Kafbat UI, you can easily send or write data/messages to Kafka topics by specifying parameters and viewing messages in the list.\n\n![Produce Message](documentation/images/Create_message_kafka-ui.gif)\n\n## Schema registry\nThere are three supported types of schemas: AvroÂ®, JSON Schema, and Protobuf schemas.\n\n![Create Schema Registry](documentation/images/Create_schema.gif)\n\nBefore producing Avro/Protobuf encoded messages, you need to add a schema for the topic in the Schema Registry. All these steps are now easy to do with just a few clicks in a user-friendly interface.\n\n![Avro Schema Topic](documentation/images/Schema_Topic.gif)\n\n</details>\n\n# Getting Started\n\nTo run Kafbat UI, you can use either a pre-built Docker image or build it (or a jar file) yourself.\n\n## Quick start (Demo run)\n\n```bash\ndocker run -it -p 8080:8080 -e DYNAMIC_CONFIG_ENABLED=true ghcr.io/kafbat/kafka-ui\n```\n\nThen access the web UI at [http://localhost:8080](http://localhost:8080)\n\nThis command is sufficient to try things out. When you're done, you can proceed with a [persistent installation](https://ui.docs.kafbat.io/quick-start/persistent-start).\n\n## Persistent installation\n\n```yml\nservices:\n  kafbat-ui:\n    container_name: kafbat-ui\n    image: ghcr.io/kafbat/kafka-ui:latest\n    ports:\n      - 8080:8080\n    environment:\n      DYNAMIC_CONFIG_ENABLED: 'true'\n    volumes:\n      - ~/kui/config.yml:/etc/kafkaui/dynamic_config.yaml\n```\n\nPlease refer to our [configuration](https://ui.docs.kafbat.io/configuration/configuration-file) page to proceed with further app configuration.\n\n## Some useful configuration related links\n\n[Web UI Cluster Configuration Wizard](https://ui.docs.kafbat.io/configuration/configuration-wizard)\n\n[Configuration file explanation](https://ui.docs.kafbat.io/configuration/configuration-file)\n\n[Docker Compose examples](https://ui.docs.kafbat.io/configuration/compose-examples)\n\n[Misc configuration properties](https://ui.docs.kafbat.io/configuration/misc-configuration-properties)\n\n## Helm charts\n\n[Quick start](https://ui.docs.kafbat.io/configuration/helm-charts/quick-start)\n\n## Building from sources\n\n[Quick start](https://ui.docs.kafbat.io/development/building/prerequisites) for building from source\n\n## Liveliness and readiness probes\nThe liveness and readiness endpoint is at `/actuator/health`.<br/>\nThe info endpoint (build info) is located at `/actuator/info`.\n\n# Configuration options\n\nAll environment variables and configuration properties can be found [here](https://ui.docs.kafbat.io/configuration/misc-configuration-properties).\n\n# Contributing\n\nPlease refer to the [contributing guide](https://ui.docs.kafbat.io/development/contributing); we'll guide you from there.\n\n# Support\n\nAs we're fully independent, team members contribute in their free time.\nYour support is crucial for us, if you wish to sponsor us, take a look [here](https://github.com/sponsors/kafbat)\n\n# Powered by\n\n[![JetBrains logo.](https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.svg)](https://jb.gg/OpenSourceSupport)\n",
      "stars_today": 2
    },
    {
      "id": 50672978,
      "name": "gcam-core",
      "full_name": "JGCRI/gcam-core",
      "description": "GCAM -- The Global Change Analysis Model",
      "html_url": "https://github.com/JGCRI/gcam-core",
      "stars": 384,
      "forks": 205,
      "language": "R",
      "topics": [
        "climate",
        "coupled-human-natural-systems",
        "economics",
        "energy",
        "gcam",
        "human-earth-system",
        "integrated-assessment",
        "land",
        "water"
      ],
      "created_at": "2016-01-29T15:57:28Z",
      "updated_at": "2026-02-06T15:12:27Z",
      "pushed_at": "2026-01-22T23:19:22Z",
      "open_issues": 254,
      "owner": {
        "login": "JGCRI",
        "avatar_url": "https://avatars.githubusercontent.com/u/8431983?v=4"
      },
      "readme": "# Global Change Analysis Model (GCAM)\n\nThe Joint Global Change Research Institute (JGCRI) of the Pacific \nNorthwest National Laboratory (PNNL) is the home and primary \ndevelopment institution for GCAM, a multisector model for exploring \nconsequences of and responses to global to local changes and stressors. \nRegional energy, water, land, and economic systems are connected to the\nrest of the globe through trade and interactions with environmental systems.\nThese systems are also connected with each other.\nMultisector models such as GCAM capture these \ninterconnected impacts in an economic framework in order to explore \nthese dynamic interactions and feedbacks between regions and sectors.\n\nGCAM has been developed at PNNL-JGCRI for over 20 years and is a freely\navailable community model and documented online (See below). The team\nat JGCRI is comprised of physical scientists, engineers, economists, energy\nexperts, forest ecologists, agricultural scientists, and environmental system\nscientists who develop the model and apply it to a range of research questions.\nThe JGCRI team works closely with the developers of other Earth system and\necosystem models to integrate the effects of human actions modeled in GCAM\ninto their research.\n\n## Model Overview\n\nGCAM is a dynamic-recursive model with technology-rich representations\nof the economy, energy sector, land use, and water linked to a reduced complexity\nEarth system model that can be used to explore many science and decision-relevant\nquestions including the effects of changes in trade patterns, critical minerals\n& materials availability, and deployment of energy technologies on human and\nEarth systems. Regional population and labor productivity growth assumptions\ndrive the energy and land-use systems, employing numerous technology options to\nproduce, transform, and provide energy services, as well as to produce\nagriculture and forest products, and to determine land use and land cover.\nUsing a run period extending from 1990 â€“ 2100 (historical years through 2021)\nwith annual results computed at 1-5 year intervals, GCAM has been used to\nexplore the potential role of emerging energy supply technologies and\nthe consequences of specific measures or energy technology adoption, including\nbioenergy; critical minerals & materials; hydrogen systems; nuclear energy;\nrenewable energy technologies; carbon capture, storage, and utilization and\nenergy use technology in buildings, industry, and the transportation\nsectors. GCAM outputs include projections of future energy and critical mineral\nsupply, trade, and demand and the resulting radiative forcing and other effects\nof 16 greenhouse gases, aerosols, and short-lived species at 0.5Ã—0.5 degree\nresolution, contingent on assumptions about future population, economy, technology,\ntrade and other polices.\n\n## Community guidelines for peer-reviewed journal articles using GCAM\n\nThis section outlines some suggested language which the GCAM user community \ncan employ to describe GCAM in papers in peer-reviewed journal articles,\nreports, or other public documents using GCAM or versions of GCAM. GCAM is\nunder continuous development. The suggested language for the opening paragraphs\nof a methodology or introduction section of a paper describing GCAM is as\nfollows:\n\n\"The Global Change Analysis Model (GCAM) is a multisector model developed and maintained at the Pacific Northwest National Laboratoryâ€™s Joint Global Change Research Institute (JGCRI, 2023) _\\<include additional citations to previous GCAM studies as relevant\\>_. GCAM is an open-source community model. In this study, we use GCAM v NN. The documentation of the model is available at the GCAM documentation page ([http://jgcri.github.io/gcam-doc](http://jgcri.github.io/gcam-doc)) and the description below is a summary. GCAM includes representations of: economy, energy, agriculture, and water supply in 32 geopolitical regions across the globe; their GHG and air pollutant emissions and global GHG concentrations, radiative forcing, and temperature change; and the associated land allocation, water use, and agriculture production across 396 land sub-regions and 235 water basins.  _\\<If using GCAM-USA, include without quotes: \"This study uses a U.S.-focused version of GCAM called GCAM-USA that includes representation of energy, economy, and water systems for the fifty states and the District of Columbia in addition to 31 regions outside of the United States.â€\\>_. The version of GCAM used in this study is available â€“ along with full source code and instructions for use â€“ in a public repository _\\<include citation including link to the GCAM repository with doi used in paper\\>_. \n\nSubsequent paragraphs of the description might expound on particular capabilities, systems, or sectors of focus in the paper. Details in the GCAM documentation page can be used as a reference to develop these paragraphs.\n\nCommunity users of GCAM might also undertake their own model developments and/or assumptions for papers. It is recommended that these departures from the publicly available version of the model be clearly described. In addition, if these developments are substantial, we suggest making this clear by including an additional phrase (e.g. region name or name of institution) in the name of the model and explicitly calling it out in place of or immediately following the italicized portion in the above paragraphs. For example: _\"This study uses a modified version of GCAM/GCAM-USA called GCAM-\\<institution name\\>/GCAM-USA-\\<institution name\\>. GCAM-\\<institution name\\>/GCAM-USA-\\<institution name\\> incorporates additional details and modified assumptions from GCAM v NN as described subsequently\"_. \n\n## Documentation\n\n* [GCAM Documentation](http://jgcri.github.io/gcam-doc/)\n* [Getting Started with GCAM](http://jgcri.github.io/gcam-doc/user-guide.html)\n* [GCAM Community](https://gcims.pnnl.gov/community)\n* [GCAM Videos and Tutorial Slides](https://gcims.pnnl.gov/community)\n* [GCAM Citation and Co-authorship Guidelines](http://jgcri.github.io/gcam-doc/community-guide.html)\n\n## Selected Publications\n\nCalvin, K., Patel, P., Clarke, L., Asrar, G., Bond-Lamberty, B., Cui, R. Y., Di Vittorio, A., Dorheim, K., Edmonds, J., Hartin, C., Hejazi, M., Horowitz, R., Iyer, G., Kyle, P., Kim, S., Link, R., McJeon, H., Smith, S. J., Snyder, A., Waldhoff, S., and Wise, M.: GCAM v5.1: representing the linkages between energy, water, land, climate, and economic systems, Geosci. Model Dev., 12, 677â€“698, https://doi.org/10.5194/gmd-12-677-2019, 2019.\n\nEdmonds, J., and J. Reilly (1985)Global Energy: Assessing the Future (Oxford University Press, New York) pp.317.\n\nEdmonds, J., M. Wise, H. Pitcher, R. Richels, T. Wigley, and C. MacCracken. (1997) â€œAn Integrated Assessment of Climate Change and the Accelerated Introduction of Advanced Energy Technologiesâ€, Mitigation and Adaptation Strategies for Global Change, 1, pp. 311-39\n\nKim, S.H., J. Edmonds, J. Lurz, S. J. Smith, and M. Wise (2006) â€œThe ObjECTS Framework for Integrated Assessment: Hybrid Modeling of Transportation â€ Energy Journal (Special Issue #2) pp 51-80.\n\n[Full list of GCAM publications](http://jgcri.github.io/gcam-doc/references.html)\n",
      "stars_today": 2
    },
    {
      "id": 248836530,
      "name": "scTenifoldKnk",
      "full_name": "cailab-tamu/scTenifoldKnk",
      "description": " R/MATLAB package to perform virtual knockout experiments on single-cell gene regulatory networks.",
      "html_url": "https://github.com/cailab-tamu/scTenifoldKnk",
      "stars": 153,
      "forks": 17,
      "language": "R",
      "topics": [
        "functional-genomics",
        "gene-function",
        "gene-knockout",
        "gene-regulatory-network",
        "virtual-knockout-experiments"
      ],
      "created_at": "2020-03-20T19:31:03Z",
      "updated_at": "2026-02-06T04:09:33Z",
      "pushed_at": "2026-01-26T15:09:47Z",
      "open_issues": 25,
      "owner": {
        "login": "cailab-tamu",
        "avatar_url": "https://avatars.githubusercontent.com/u/31963060?v=4"
      },
      "readme": "scTenifoldKnk\n=============\n\nA R/MATLAB/Python package to perform virtual knockout experiments on single-cell gene regulatory networks. **scTenifoldKnk** is a machine learning workflow that performs virtual knockout experiments using single-cell RNA sequencing (scRNAseq) data from wild-type (WT) control samples as input. Constructs a single-cell gene regulatory network (scGRN) and knocks out a target gene from the adjacency matrix of the WT scGRN by setting the geneâ€™s outdegree edges to zero. **scTenifoldKnk** then compares the knocked out scGRN with the WT scGRN to identify differentially regulated genes, called virtual-knockout perturbed genes, which are used to assess the impact of the gene knockout and reveal the geneâ€™s function in the analyzed cells.\n\nPython version of scTenifoldKnk is available at: https://github.com/qwerty239qwe/scTenifoldpy\n\nMATLAB version is available at: https://github.com/jamesjcai/scGEAToolbox\n\nInstall:\n-------\nYou can install **scTenifoldKnk/R** using the following command:\n\n```{R}\nlibrary(remotes)\ninstall_github('cailab-tamu/scTenifoldKnk')\nlibrary(scTenifoldKnk)\n```\n\nAvailable functions:\n--------------------\n\n|Code| Function |\n|:-|:-|\n|scTenifoldKnk|Perform virtual knockout experiments on single-cell gene regulatory networks|\n\nInput:\n--------\nThe required input for **scTenifoldKnk** is an expression matrix with genes in the rows and cells (barcodes) in the columns. Data is expected to be previously normalized or _not normalized_ if `QC = TRUE`.\n\nRunning time:\n--------\nThe running time of scTenifoldKnk is largely dependent on how long it takes to construct scGRNs from subsampled expression matrices. Time increases proportional to the number of cells and genes in the dataset used as input. Below is a table of running times under different scenarios:\n\n| Number of Cells | Number of Genes | Running Time |\n|-----------------|-----------------|--------------|\n| 300             | 1000            | 3.45 min     |\n| 1000            | 1000            | 4.25 min     |\n| 1000            | 5000            | 171.88 min (2 h 51.6 min) |\n| 2500            | 5000            | 175.29 min (2 h 55.3 min) |\n| 5000            | 5000            | 188.88 min (3 h 8.9 min) |\n| 5000            | 7500            | 189.51 min (3 h 9.5 min)  |\n| 7500            | 5000            | 615.45 min (10 h 15.5 min) |\n| 7500            | 7500            | 616.12 min (10 h 16.1 min)  |\n\n\nOutput:\n--------\nThe output of **scTenifoldKnk** is a list with 3 slots as follows: \n  * **tensorNetworks**: The computed weight-averaged denoised gene regulatory networks after CANDECOMP/PARAFAC (CP) tensor decomposition. It includes two slots with:\n    * **X**: The constructed network for the _X_ sample.\n    * **Y**: The constructed network for the _Y_ sample.\n  * **manifoldAlignment**: The generated low-dimensional features result of the non-linear manifold alignment. It is a data frame with _2 times the number of genes_ in the rows and _d_ (default= 2) dimensions in the columns\n  * **diffRegulation**: The results of the differential regulation analysis. It is a data frame with 6 columns as follows:\n    * **gene**: A character vector with the gene id identified from the manifoldAlignment output.\n    * **distance**: A numeric vector of the Euclidean distance computed between the coordinates of the same gene in both conditions.\n    * **Z**: A numeric vector of the Z-scores computed after Box-Cox power transformation.\n    * **FC**: A numeric vector of the FC computed with respect to the expectation.\n    * **p.value**: A numeric vector of the p-values associated to the fold-changes, probabilities are asigned as P[X > x] using the Chi-square distribution with one degree of freedom.\n    * **p.adj**: A numeric vector of adjusted p-values using Benjamini & Hochberg (1995) FDR correction.\n\n---\nThe function to plot the egocentric KO, the code is available at [https://github.com/dosorio/utilities/blob/master/singleCell/plotKO.R](https://github.com/dosorio/utilities/blob/master/singleCell/plotKO.R), it requires: The object out of Knk (as X), the gene to knockout (gKO).\n\n\nÂ©ï¸ The Texas A & M University System. All rights reserved.\n",
      "stars_today": 2
    },
    {
      "id": 22458259,
      "name": "Alamofire",
      "full_name": "Alamofire/Alamofire",
      "description": "Elegant HTTP Networking in Swift",
      "html_url": "https://github.com/Alamofire/Alamofire",
      "stars": 42337,
      "forks": 7667,
      "language": "Swift",
      "topics": [
        "alamofire",
        "carthage",
        "certificate-pinning",
        "cocoapods",
        "httpurlresponse",
        "networking",
        "parameter-encoding",
        "public-key-pinning",
        "request",
        "response",
        "swift",
        "swift-package-manager",
        "urlrequest",
        "urlsession",
        "xcode"
      ],
      "created_at": "2014-07-31T05:56:19Z",
      "updated_at": "2026-02-07T02:09:08Z",
      "pushed_at": "2026-02-02T03:30:20Z",
      "open_issues": 40,
      "owner": {
        "login": "Alamofire",
        "avatar_url": "https://avatars.githubusercontent.com/u/7774181?v=4"
      },
      "readme": "![Alamofire: Elegant Networking in Swift](https://raw.githubusercontent.com/Alamofire/Alamofire/master/Resources/AlamofireLogo.png)\n\n[![Swift](https://img.shields.io/badge/Swift-6.0_6.1_6.2-orange?style=flat-square)](https://img.shields.io/badge/Swift-6.0_6.1_6.2-Orange?style=flat-square)\n[![Platforms](https://img.shields.io/badge/Platforms-macOS_iOS_tvOS_watchOS_visionOS_Linux_Windows_Android-yellowgreen?style=flat-square)](https://img.shields.io/badge/Platforms-macOS_iOS_tvOS_watchOS_vision_OS_Linux_Windows_Android-Green?style=flat-square)\n[![CocoaPods Compatible](https://img.shields.io/cocoapods/v/Alamofire.svg?style=flat-square)](https://img.shields.io/cocoapods/v/Alamofire.svg)\n[![Carthage Compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat-square)](https://github.com/Carthage/Carthage)\n[![Swift Package Manager](https://img.shields.io/badge/Swift_Package_Manager-compatible-orange?style=flat-square)](https://img.shields.io/badge/Swift_Package_Manager-compatible-orange?style=flat-square)\n[![Swift Forums](https://img.shields.io/badge/Swift_Forums-Alamofire-orange?style=flat-square)](https://forums.swift.org/c/related-projects/alamofire/37)\n\nAlamofire is an HTTP networking library written in Swift.\n\n- [Features](#features)\n- [Component Libraries](#component-libraries)\n- [Requirements](#requirements)\n- [Migration Guides](#migration-guides)\n- [Communication](#communication)\n- [Installation](#installation)\n- [Contributing](#contributing)\n- [Usage](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#using-alamofire)\n  - [**Introduction -**](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#introduction) [Making Requests](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#making-requests), [Response Handling](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#response-handling), [Response Validation](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#response-validation), [Response Caching](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#response-caching)\n  - **HTTP -** [HTTP Methods](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#http-methods), [Parameters and Parameter Encoder](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md##request-parameters-and-parameter-encoders), [HTTP Headers](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#http-headers), [Authentication](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#authentication)\n  - **Large Data -** [Downloading Data to a File](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#downloading-data-to-a-file), [Uploading Data to a Server](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#uploading-data-to-a-server)\n  - **Tools -** [Statistical Metrics](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#statistical-metrics), [cURL Command Output](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#curl-command-output)\n- [Advanced Usage](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md)\n  - **URL Session -** [Session Manager](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#session), [Session Delegate](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#sessiondelegate), [Request](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#request)\n  - **Routing -** [Routing Requests](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#routing-requests), [Adapting and Retrying Requests](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#adapting-and-retrying-requests-with-requestinterceptor)\n  - **Model Objects -** [Custom Response Handlers](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#customizing-response-handlers)\n  - **Advanced Concurrency -** [Swift Concurrency](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#using-alamofire-with-swift-concurrency) and [Combine](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#using-alamofire-with-combine)\n  - **Connection -** [Security](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#security), [Network Reachability](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#network-reachability)\n- [Open Radars](#open-radars)\n- [FAQ](#faq)\n- [Credits](#credits)\n- [Donations](#donations)\n- [License](#license)\n\n## Features\n\n- [x] Chainable Request / Response Methods\n- [x] Swift Concurrency Support Back to iOS 13, macOS 10.15, tvOS 13, and watchOS 6.\n- [x] Combine Support\n- [x] URL / JSON Parameter Encoding\n- [x] Upload File / Data / Stream / MultipartFormData\n- [x] Download File using Request or Resume Data\n- [x] Authentication with `URLCredential`\n- [x] HTTP Response Validation\n- [x] Upload and Download Progress Closures with Progress\n- [x] cURL Command Output\n- [x] Dynamically Adapt and Retry Requests\n- [x] TLS Certificate and Public Key Pinning\n- [x] Network Reachability\n- [x] Comprehensive Unit and Integration Test Coverage\n- [x] [Complete Documentation](https://alamofire.github.io/Alamofire)\n\n## Write Requests Fast!\n\nAlamofire's compact syntax and extensive feature set allow requests with powerful features like automatic retry to be written in just a few lines of code.\n\n```swift\n// Automatic String to URL conversion, Swift concurrency support, and automatic retry.\nlet response = await AF.request(\"https://httpbin.org/get\", interceptor: .retryPolicy)\n                       // Automatic HTTP Basic Auth.\n                       .authenticate(username: \"user\", password: \"pass\")\n                       // Caching customization.\n                       .cacheResponse(using: .cache)\n                       // Redirect customization.\n                       .redirect(using: .follow)\n                       // Validate response code and Content-Type.\n                       .validate()\n                       // Produce a cURL command for the request.\n                       .cURLDescription { description in\n                         print(description)\n                       }\n                       // Automatic Decodable support with background parsing.\n                       .serializingDecodable(DecodableType.self)\n                       // Await the full response with metrics and a parsed body.\n                       .response\n// Detailed response description for easy debugging.\ndebugPrint(response)\n```\n\n## Component Libraries\n\nIn order to keep Alamofire focused specifically on core networking implementations, additional component libraries have been created by the [Alamofire Software Foundation](https://github.com/Alamofire/Foundation) to bring additional functionality to the Alamofire ecosystem.\n\n- [AlamofireImage](https://github.com/Alamofire/AlamofireImage) - An image library including image response serializers, `UIImage` and `UIImageView` extensions, custom image filters, an auto-purging in-memory cache, and a priority-based image downloading system.\n- [AlamofireNetworkActivityIndicator](https://github.com/Alamofire/AlamofireNetworkActivityIndicator) - Controls the visibility of the network activity indicator on iOS using Alamofire. It contains configurable delay timers to help mitigate flicker and can support `URLSession` instances not managed by Alamofire.\n\n## Requirements\n\n| Platform                                             | Minimum Swift Version | Installation                                                                                                         | Status                   |\n| ---------------------------------------------------- | --------------------- | -------------------------------------------------------------------------------------------------------------------- | ------------------------ |\n| iOS 10.0+ / macOS 10.12+ / tvOS 10.0+ / watchOS 3.0+ | 6.0 / Xcode 16.0      | [CocoaPods](#cocoapods), [Carthage](#carthage), [Swift Package Manager](#swift-package-manager), [Manual](#manually) | Fully Tested             |\n| Linux                                                | Latest Only           | [Swift Package Manager](#swift-package-manager)                                                                      | Building But Unsupported |\n| Windows                                              | Latest Only           | [Swift Package Manager](#swift-package-manager)                                                                      | Building But Unsupported |\n| Android                                              | Latest Only           | [Swift Package Manager](#swift-package-manager)                                                                      | Building But Unsupported |\n\n#### Known Issues on Linux and Windows\n\nAlamofire builds on Linux, Windows, and Android but there are missing features and many issues in the underlying `swift-corelibs-foundation` that prevent full functionality and may cause crashes. These include:\n\n- `ServerTrustManager` and associated certificate functionality is unavailable, so there is no certificate pinning and no client certificate support.\n- Various methods of HTTP authentication may crash, including HTTP Basic and HTTP Digest. Crashes may occur if responses contain server challenges.\n- Cache control through `CachedResponseHandler` and associated APIs is unavailable, as the underlying delegate methods aren't called.\n- `URLSessionTaskMetrics` are never gathered.\n- `WebSocketRequest` is not available.\n\nDue to these issues, Alamofire is unsupported on Linux, Windows, and Android. Please report any crashes to the [Swift bug reporter](https://bugs.swift.org).\n\n## Migration Guides\n\n- [Alamofire 5.0 Migration Guide](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Alamofire%205.0%20Migration%20Guide.md)\n- [Alamofire 4.0 Migration Guide](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Alamofire%204.0%20Migration%20Guide.md)\n- [Alamofire 3.0 Migration Guide](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Alamofire%203.0%20Migration%20Guide.md)\n- [Alamofire 2.0 Migration Guide](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Alamofire%202.0%20Migration%20Guide.md)\n\n## Communication\n\n- If you **need help with making network requests** using Alamofire, use [Stack Overflow](https://stackoverflow.com/questions/tagged/alamofire) and tag `alamofire`.\n- If you need to **find or understand an API**, check [our documentation](http://alamofire.github.io/Alamofire/) or [Apple's documentation for `URLSession`](https://developer.apple.com/documentation/foundation/url_loading_system), on top of which Alamofire is built.\n- If you need **help with an Alamofire feature**, use [our forum on swift.org](https://forums.swift.org/c/related-projects/alamofire).\n- If you'd like to **discuss Alamofire best practices**, use [our forum on swift.org](https://forums.swift.org/c/related-projects/alamofire).\n- If you'd like to **discuss a feature request**, use [our forum on swift.org](https://forums.swift.org/c/related-projects/alamofire).\n- If you **found a bug**, open an issue here on GitHub and follow the guide. The more detail the better!\n\n## Installation\n\n### Swift Package Manager\n\nThe [Swift Package Manager](https://swift.org/package-manager/) is a tool for automating the distribution of Swift code and is integrated into the `swift` compiler.\n\nOnce you have your Swift package set up, adding Alamofire as a dependency is as easy as adding it to the `dependencies` value of your `Package.swift` or the Package list in Xcode.\n\n```swift\ndependencies: [\n    .package(url: \"https://github.com/Alamofire/Alamofire.git\", .upToNextMajor(from: \"5.11.0\"))\n]\n```\n\nNormally you'll want to depend on the `Alamofire` target:\n\n```swift\n.product(name: \"Alamofire\", package: \"Alamofire\")\n```\n\nBut if you want to force Alamofire to be dynamically linked (do not do this unless you're sure you need it), you can depend on the `AlamofireDynamic` target:\n\n```swift\n.product(name: \"AlamofireDynamic\", package: \"Alamofire\")\n```\n\n### CocoaPods\n\n[CocoaPods](https://cocoapods.org) is a dependency manager for Cocoa projects. For usage and installation instructions, visit their website. To integrate Alamofire into your Xcode project using CocoaPods, specify it in your `Podfile`:\n\n```ruby\npod 'Alamofire'\n```\n\n### Carthage\n\n[Carthage](https://github.com/Carthage/Carthage) is a decentralized dependency manager that builds your dependencies and provides you with binary frameworks. To integrate Alamofire into your Xcode project using Carthage, specify it in your `Cartfile`:\n\n```ogdl\ngithub \"Alamofire/Alamofire\"\n```\n\n### Manually\n\nIf you prefer not to use any of the aforementioned dependency managers, you can integrate Alamofire into your project manually.\n\n#### Embedded Framework\n\n- Open up Terminal, `cd` into your top-level project directory, and run the following command \"if\" your project is not initialized as a git repository:\n\n  ```bash\n  $ git init\n  ```\n\n- Add Alamofire as a git [submodule](https://git-scm.com/docs/git-submodule) by running the following command:\n\n  ```bash\n  $ git submodule add https://github.com/Alamofire/Alamofire.git\n  ```\n\n- Open the new `Alamofire` folder, and drag the `Alamofire.xcodeproj` into the Project Navigator of your application's Xcode project.\n\n  > It should appear nested underneath your application's blue project icon. Whether it is above or below all the other Xcode groups does not matter.\n\n- Select the `Alamofire.xcodeproj` in the Project Navigator and verify the deployment target matches that of your application target.\n- Next, select your application project in the Project Navigator (blue project icon) to navigate to the target configuration window and select the application target under the \"Targets\" heading in the sidebar.\n- In the tab bar at the top of that window, open the \"General\" panel.\n- Click on the `+` button under the \"Embedded Binaries\" section.\n- You will see two different `Alamofire.xcodeproj` folders each with two different versions of the `Alamofire.framework` nested inside a `Products` folder.\n\n  > It does not matter which `Products` folder you choose from, but it does matter whether you choose the top or bottom `Alamofire.framework`.\n\n- Select the top `Alamofire.framework` for iOS and the bottom one for macOS.\n\n  > You can verify which one you selected by inspecting the build log for your project. The build target for `Alamofire` will be listed as `Alamofire iOS`, `Alamofire macOS`, `Alamofire tvOS`, or `Alamofire watchOS`.\n\n- And that's it!\n\n  > The `Alamofire.framework` is automagically added as a target dependency, linked framework and embedded framework in a copy files build phase which is all you need to build on the simulator and a device.\n\n## Contributing\n\nBefore contributing to Alamofire, please read the instructions detailed in our [contribution guide](https://github.com/Alamofire/Alamofire/blob/master/CONTRIBUTING.md).\n\n## Open Radars\n\nThe following radars have some effect on the current implementation of Alamofire.\n\n- [`rdar://21349340`](http://www.openradar.me/radar?id=5517037090635776) - Compiler throwing warning due to toll-free bridging issue in the test case\n- `rdar://26870455` - Background URL Session Configurations do not work in the simulator\n- `rdar://26849668` - Some URLProtocol APIs do not properly handle `URLRequest`\n\n## Resolved Radars\n\nThe following radars have been resolved over time after being filed against the Alamofire project.\n\n- [`rdar://26761490`](http://www.openradar.me/radar?id=5010235949318144) - Swift string interpolation causing memory leak with common usage.\n  - (Resolved): 9/1/17 in Xcode 9 beta 6.\n- [`rdar://36082113`](http://openradar.appspot.com/radar?id=4942308441063424) - `URLSessionTaskMetrics` failing to link on watchOS 3.0+\n  - (Resolved): Just add `CFNetwork` to your linked frameworks.\n- `FB7624529` - `urlSession(_:task:didFinishCollecting:)` never called on watchOS\n  - (Resolved): Metrics now collected on watchOS 7+.\n\n## FAQ\n\n### What's the origin of the name Alamofire?\n\nAlamofire is named after the [Alamo Fire flower](https://aggie-horticulture.tamu.edu/wildseed/alamofire.html), a hybrid variant of the Bluebonnet, the official state flower of Texas.\n\n## Credits\n\nAlamofire is owned and maintained by the [Alamofire Software Foundation](http://alamofire.org). You can follow them on Twitter at [@AlamofireSF](https://twitter.com/AlamofireSF) for project updates and releases.\n\n### Security Disclosure\n\nIf you believe you have identified a security vulnerability with Alamofire, you should report it as soon as possible via email to security@alamofire.org. Please do not post it to a public issue tracker.\n\n## Sponsorship\n\nThe [ASF](https://github.com/Alamofire/Foundation#members) is looking to raise money to officially stay registered as a federal non-profit organization.\nRegistering will allow Foundation members to gain some legal protections and also allow us to put donations to use, tax-free.\nSponsoring the ASF will enable us to:\n\n- Pay our yearly legal fees to keep the non-profit in good status\n- Pay for our mail servers to help us stay on top of all questions and security issues\n- Potentially fund test servers to make it easier for us to test the edge cases\n- Potentially fund developers to work on one of our projects full-time\n\nThe community adoption of the ASF libraries has been amazing.\nWe are greatly humbled by your enthusiasm around the projects and want to continue to do everything we can to move the needle forward.\nWith your continued support, the ASF will be able to improve its reach and also provide better legal safety for the core members.\nIf you use any of our libraries for work, see if your employers would be interested in donating.\nAny amount you can donate, whether once or monthly, to help us reach our goal would be greatly appreciated.\n\n[Sponsor Alamofire](https://github.com/sponsors/Alamofire)\n\n## Supporters\n\n[MacStadium](https://macstadium.com) provides Alamofire with a free, hosted Mac mini.\n\n![Powered by MacStadium](https://raw.githubusercontent.com/Alamofire/Alamofire/master/Resources/MacStadiumLogo.png)\n\n## License\n\nAlamofire is released under the MIT license. [See LICENSE](https://github.com/Alamofire/Alamofire/blob/master/LICENSE) for details.\n",
      "stars_today": 1
    },
    {
      "id": 75164823,
      "name": "rocketmq",
      "full_name": "apache/rocketmq",
      "description": "Apache RocketMQ is a cloud native messaging and streaming platform, making it simple to build event-driven applications.",
      "html_url": "https://github.com/apache/rocketmq",
      "stars": 22328,
      "forks": 12003,
      "language": "Java",
      "topics": [
        "cloud-native",
        "eventing",
        "hacktoberfest",
        "java",
        "messaging",
        "rocketmq",
        "streaming"
      ],
      "created_at": "2016-11-30T08:00:08Z",
      "updated_at": "2026-02-06T07:30:30Z",
      "pushed_at": "2026-02-06T07:30:15Z",
      "open_issues": 276,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "## Apache RocketMQ\n\n[![Build Status][maven-build-image]][maven-build-url]\n[![CodeCov][codecov-image]][codecov-url]\n[![Maven Central][maven-central-image]][maven-central-url]\n[![Release][release-image]][release-url]\n[![License][license-image]][license-url]\n[![Average Time to Resolve An Issue][average-time-to-resolve-an-issue-image]][average-time-to-resolve-an-issue-url]\n[![Percentage of Issues Still Open][percentage-of-issues-still-open-image]][percentage-of-issues-still-open-url]\n[![Twitter Follow][twitter-follow-image]][twitter-follow-url]\n\n**[Apache RocketMQ](https://rocketmq.apache.org) is a distributed messaging and streaming platform with low latency, high performance and reliability, trillion-level capacity and flexible scalability.**\n\n\nIt offers a variety of features:\n\n* Messaging patterns including publish/subscribe, request/reply and streaming\n* Financial grade transactional message\n* Built-in fault tolerance and high availability configuration options based on [DLedger Controller](docs/en/controller/quick_start.md)\n* Built-in message tracing capability, also supports opentracing\n* Versatile big-data and streaming ecosystem integration\n* Message retroactivity by time or offset\n* Reliable FIFO and strict ordered messaging in the same queue\n* Efficient pull and push consumption model\n* Million-level message accumulation capacity in a single queue\n* Multiple messaging protocols like gRPC, MQTT, JMS and OpenMessaging\n* Flexible distributed scale-out deployment architecture\n* Lightning-fast batch message exchange system\n* Various message filter mechanics such as SQL and Tag\n* Docker images for isolated testing and cloud isolated clusters\n* Feature-rich administrative dashboard for configuration, metrics and monitoring\n* Authentication and authorization\n* Free open source connectors, for both sources and sinks\n* Lightweight real-time computing\n----------\n\n\n## Quick Start\n\nThis paragraph guides you through steps of installing RocketMQ in different ways.\nFor local development and testing, only one instance will be created for each component.\n\n### Run RocketMQ locally\n\nRocketMQ runs on all major operating systems and requires only a Java JDK version 8 or higher to be installed.\nTo check, run `java -version`:\n```shell\n$ java -version\njava version \"1.8.0_121\"\n```\n\nFor Windows users, click [here](https://dist.apache.org/repos/dist/release/rocketmq/5.4.0/rocketmq-all-5.4.0-bin-release.zip) to download the 5.4.0 RocketMQ binary release,\nunpack it to your local disk, such as `D:\\rocketmq`.\nFor macOS and Linux users, execute following commands:\n\n```shell\n# Download release from the Apache mirror\n$ wget https://dist.apache.org/repos/dist/release/rocketmq/5.4.0/rocketmq-all-5.4.0-bin-release.zip\n\n# Unpack the release\n$ unzip rocketmq-all-5.4.0-bin-release.zip\n```\n\nPrepare a terminal and change to the extracted `bin` directory:\n```shell\n$ cd rocketmq-all-5.4.0-bin-release/bin\n```\n\n**1) Start NameServer**\n\nNameServer will be listening at `0.0.0.0:9876`, make sure that the port is not used by others on the local machine, and then do as follows.\n\nFor macOS and Linux users:\n```shell\n### start Name Server\n$ nohup sh mqnamesrv &\n\n### check whether Name Server is successfully started\n$ tail -f ~/logs/rocketmqlogs/namesrv.log\nThe Name Server boot success...\n```\n\nFor Windows users, you need to set environment variables first:\n- From the desktop, right click the Computer icon.\n- Choose Properties from the context menu.\n- Click the Advanced system settings link.\n- Click Environment Variables.\n- Add Environment `ROCKETMQ_HOME=\"D:\\rocketmq\"`. \n\nThen change directory to rocketmq, type and run:\n```shell\n$ mqnamesrv.cmd\nThe Name Server boot success...\n```\n\n**2) Start Broker**\n\nFor macOS and Linux users:\n```shell\n### start Broker\n$ nohup sh mqbroker -n localhost:9876 &\n\n### check whether Broker is successfully started, eg: Broker's IP is 192.168.1.2, Broker's name is broker-a\n$ tail -f ~/logs/rocketmqlogs/broker.log\nThe broker[broker-a, 192.168.1.2:10911] boot success...\n```\n\nFor Windows users:\n```shell\n$ mqbroker.cmd -n localhost:9876\nThe broker[broker-a, 192.168.1.2:10911] boot success...\n```\n\n### Run RocketMQ in Docker\n\nYou can run RocketMQ on your own machine within Docker containers,\n`host` network will be used to expose listening port in the container.\n\n**1) Start NameServer**\n\n```shell\n$ docker run -it --net=host apache/rocketmq ./mqnamesrv\n```\n\n**2) Start Broker**\n\n```shell\n$ docker run -it --net=host --mount type=bind,source=/tmp/store,target=/home/rocketmq/store apache/rocketmq ./mqbroker -n localhost:9876\n```\n\n### Run RocketMQ in Kubernetes\n\nYou can also run a RocketMQ cluster within a Kubernetes cluster using [RocketMQ Operator](https://github.com/apache/rocketmq-operator).\nBefore your operations, make sure that `kubectl` and related kubeconfig file installed on your machine.\n\n**1) Install CRDs**\n```shell\n### install CRDs\n$ git clone https://github.com/apache/rocketmq-operator\n$ cd rocketmq-operator && make deploy\n\n### check whether CRDs are successfully installed\n$ kubectl get crd | grep rocketmq.apache.org\nbrokers.rocketmq.apache.org                 2022-05-12T09:23:18Z\nconsoles.rocketmq.apache.org                2022-05-12T09:23:19Z\nnameservices.rocketmq.apache.org            2022-05-12T09:23:18Z\ntopictransfers.rocketmq.apache.org          2022-05-12T09:23:19Z\n\n### check whether operator is running\n$ kubectl get pods | grep rocketmq-operator\nrocketmq-operator-6f65c77c49-8hwmj   1/1     Running   0          93s\n```\n\n**2) Create Cluster Instance**\n```shell\n### create RocketMQ cluster resource\n$ cd example && kubectl create -f rocketmq_v1alpha1_rocketmq_cluster.yaml\n\n### check whether cluster resources are running\n$ kubectl get sts\nNAME                 READY   AGE\nbroker-0-master      1/1     107m\nbroker-0-replica-1   1/1     107m\nname-service         1/1     107m\n```\n\n---\n## Apache RocketMQ Community\n* [RocketMQ Streams](https://github.com/apache/rocketmq-streams): A lightweight stream computing engine based on Apache RocketMQ.\n* [RocketMQ Flink](https://github.com/apache/rocketmq-flink): The Apache RocketMQ connector of Apache Flink that supports source and sink connector in data stream and Table.\n* [RocketMQ APIs](https://github.com/apache/rocketmq-apis): RocketMQ protobuf protocol.\n* [RocketMQ Clients](https://github.com/apache/rocketmq-clients): gRPC/protobuf-based RocketMQ clients.\n* RocketMQ Remoting-based Clients\n\t - [RocketMQ Client CPP](https://github.com/apache/rocketmq-client-cpp)\n\t - [RocketMQ Client Go](https://github.com/apache/rocketmq-client-go)\n\t - [RocketMQ Client Python](https://github.com/apache/rocketmq-client-python)\n\t - [RocketMQ Client Nodejs](https://github.com/apache/rocketmq-client-nodejs)\n* [RocketMQ Spring](https://github.com/apache/rocketmq-spring): A project which helps developers quickly integrate Apache RocketMQ with Spring Boot.\n* [RocketMQ Exporter](https://github.com/apache/rocketmq-exporter): An Apache RocketMQ exporter for Prometheus.\n* [RocketMQ Operator](https://github.com/apache/rocketmq-operator): Providing a way to run an Apache RocketMQ cluster on Kubernetes.\n* [RocketMQ Docker](https://github.com/apache/rocketmq-docker): The Git repo of the Docker Image for Apache RocketMQ.\n* [RocketMQ Dashboard](https://github.com/apache/rocketmq-dashboard): Operation and maintenance console of Apache RocketMQ.\n* [RocketMQ Connect](https://github.com/apache/rocketmq-connect): A tool for scalably and reliably streaming data between Apache RocketMQ and other systems.\n* [RocketMQ MQTT](https://github.com/apache/rocketmq-mqtt): A new MQTT protocol architecture model, based on which Apache RocketMQ can better support messages from terminals such as IoT devices and Mobile APP.\n* [RocketMQ EventBridge](https://github.com/apache/rocketmq-eventbridge): EventBridge makes it easier to build an event-driven application.\n* [RocketMQ Incubating Community Projects](https://github.com/apache/rocketmq-externals): Incubator community projects of Apache RocketMQ, including [logappender](https://github.com/apache/rocketmq-externals/tree/master/logappender), [rocketmq-ansible](https://github.com/apache/rocketmq-externals/tree/master/rocketmq-ansible), [rocketmq-beats-integration](https://github.com/apache/rocketmq-externals/tree/master/rocketmq-beats-integration), [rocketmq-cloudevents-binding](https://github.com/apache/rocketmq-externals/tree/master/rocketmq-cloudevents-binding), etc.\n* [RocketMQ Site](https://github.com/apache/rocketmq-site): The repository for Apache RocketMQ website.\n* [RocketMQ E2E](https://github.com/apache/rocketmq-e2e): A project for testing Apache RocketMQ, including end-to-end, performance, compatibility tests.\n\n\n----------\n## Learn it & Contact us\n* Mailing Lists: <https://rocketmq.apache.org/about/contact/>\n* Home: <https://rocketmq.apache.org>\n* Docs: <https://rocketmq.apache.org/docs/quick-start/>\n* Issues: <https://github.com/apache/rocketmq/issues>\n* Rips: <https://github.com/apache/rocketmq/wiki/RocketMQ-Improvement-Proposal>\n* Ask: <https://stackoverflow.com/questions/tagged/rocketmq>\n* Slack: <https://rocketmq-invite-automation.herokuapp.com/>\n\n\n----------\n\n\n\n## Contributing\nWe always welcome new contributions, whether for trivial cleanups, [big new features](https://github.com/apache/rocketmq/wiki/RocketMQ-Improvement-Proposal) or other material rewards, more details see [here](http://rocketmq.apache.org/docs/how-to-contribute/).\n\n----------\n## License\n[Apache License, Version 2.0](http://www.apache.org/licenses/LICENSE-2.0.html) Copyright (C) Apache Software Foundation\n\n\n----------\n## Export Control Notice\nThis distribution includes cryptographic software. The country in which you currently reside may have\nrestrictions on the import, possession, use, and/or re-export to another country, of encryption software.\nBEFORE using any encryption software, please check your country's laws, regulations and policies concerning\nthe import, possession, or use, and re-export of encryption software, to see if this is permitted. See\n<http://www.wassenaar.org/> for more information.\n\nThe U.S. Government Department of Commerce, Bureau of Industry and Security (BIS), has classified this\nsoftware as Export Commodity Control Number (ECCN) 5D002.C.1, which includes information security software\nusing or performing cryptographic functions with asymmetric algorithms. The form and manner of this Apache\nSoftware Foundation distribution makes it eligible for export under the License Exception ENC Technology\nSoftware Unrestricted (TSU) exception (see the BIS Export Administration Regulations, Section 740.13) for\nboth object code and source code.\n\nThe following provides more details on the included cryptographic software:\n\nThis software uses Apache Commons Crypto (https://commons.apache.org/proper/commons-crypto/) to\nsupport authentication, and encryption and decryption of data sent across the network between\nservices.\n\n[maven-build-image]: https://github.com/apache/rocketmq/actions/workflows/maven.yaml/badge.svg\n[maven-build-url]: https://github.com/apache/rocketmq/actions/workflows/maven.yaml\n[codecov-image]: https://codecov.io/gh/apache/rocketmq/branch/master/graph/badge.svg\n[codecov-url]: https://codecov.io/gh/apache/rocketmq\n[maven-central-image]: https://maven-badges.herokuapp.com/maven-central/org.apache.rocketmq/rocketmq-all/badge.svg\n[maven-central-url]: http://search.maven.org/#search%7Cga%7C1%7Corg.apache.rocketmq\n[release-image]: https://img.shields.io/badge/release-download-orange.svg\n[release-url]: https://rocketmq.apache.org/download/\n[license-image]: https://img.shields.io/badge/license-Apache%202-4EB1BA.svg\n[license-url]: https://www.apache.org/licenses/LICENSE-2.0.html\n[average-time-to-resolve-an-issue-image]: http://isitmaintained.com/badge/resolution/apache/rocketmq.svg\n[average-time-to-resolve-an-issue-url]: http://isitmaintained.com/project/apache/rocketmq\n[percentage-of-issues-still-open-image]: http://isitmaintained.com/badge/open/apache/rocketmq.svg\n[percentage-of-issues-still-open-url]: http://isitmaintained.com/project/apache/rocketmq\n[twitter-follow-image]: https://img.shields.io/twitter/follow/ApacheRocketMQ?style=social\n[twitter-follow-url]: https://twitter.com/intent/follow?screen_name=ApacheRocketMQ\n",
      "stars_today": 1
    },
    {
      "id": 402046,
      "name": "jsPDF",
      "full_name": "parallax/jsPDF",
      "description": "Client-side JavaScript PDF generation for everyone.",
      "html_url": "https://github.com/parallax/jsPDF",
      "stars": 31097,
      "forks": 4801,
      "language": "JavaScript",
      "topics": [
        "hacktoberfest"
      ],
      "created_at": "2009-12-06T14:56:32Z",
      "updated_at": "2026-02-07T02:10:37Z",
      "pushed_at": "2026-02-05T14:23:05Z",
      "open_issues": 112,
      "owner": {
        "login": "parallax",
        "avatar_url": "https://avatars.githubusercontent.com/u/320004?v=4"
      },
      "readme": "# ![jsPDF](https://parall.ax/parallax-2016/img/svg/jspdf-logo.svg)\n\n[![Continous Integration](https://github.com/MrRio/jsPDF/actions/workflows/continuous-integration.yml/badge.svg)](https://github.com/MrRio/jsPDF/actions/workflows/continuous-integration.yml?query=branch%3Amaster)\n[![Code Climate](https://codeclimate.com/repos/57f943855cdc43705e00592f/badges/2665cddeba042dc5191f/gpa.svg)](https://codeclimate.com/repos/57f943855cdc43705e00592f/feed)\n[![Test Coverage](https://codeclimate.com/repos/57f943855cdc43705e00592f/badges/2665cddeba042dc5191f/coverage.svg)](https://codeclimate.com/repos/57f943855cdc43705e00592f/coverage)\n[![GitHub license](https://img.shields.io/github/license/MrRio/jsPDF.svg)](https://github.com/MrRio/jsPDF/blob/master/LICENSE)\n[![Total alerts](https://img.shields.io/lgtm/alerts/g/MrRio/jsPDF.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/MrRio/jsPDF/alerts/)\n[![Language grade: JavaScript](https://img.shields.io/lgtm/grade/javascript/g/MrRio/jsPDF.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/MrRio/jsPDF/context:javascript)\n[![Gitpod ready-to-code](https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod)](https://gitpod.io/from-referrer/)\n\n**A library to generate PDFs in JavaScript.**\n\nYou can [catch me on twitter](http://twitter.com/MrRio): [@MrRio](http://twitter.com/MrRio) or head over to [my company's website](http://parall.ax) for consultancy.\n\njsPDF is now co-maintained by [yWorks - the diagramming experts](https://www.yworks.com/).\n\n## [Live Demo](http://raw.githack.com/MrRio/jsPDF/master/) | [Documentation](http://raw.githack.com/MrRio/jsPDF/master/docs/)\n\n## Install\n\nRecommended: get jsPDF from npm:\n\n```sh\nnpm install jspdf --save\n# or\nyarn add jspdf\n```\n\nAlternatively, load it from a CDN:\n\n```html\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jspdf/4.1.0/jspdf.umd.min.js\"></script>\n```\n\nOr always get latest version via [unpkg](https://unpkg.com/browse/jspdf/)\n\n```html\n<script src=\"https://unpkg.com/jspdf@latest/dist/jspdf.umd.min.js\"></script>\n```\n\nThe `dist` folder of this package contains different kinds of files:\n\n- **jspdf.es.\\*.js**: Modern ES2015 module format.\n- **jspdf.node.\\*.js**: For running in Node. Uses file operations for loading/saving files instead of browser APIs.\n- **jspdf.umd.\\*.js**: UMD module format. For AMD or script-tag loading.\n- **polyfills\\*.js**: Required polyfills for older browsers like Internet Explorer. The es variant simply imports all\n  required polyfills from `core-js`, the umd variant is self-contained.\n\nUsually it is not necessary to specify the exact file in the import statement. Build tools or Node automatically figure\nout the right file, so importing \"jspdf\" is enough.\n\n## Usage\n\nThen you're ready to start making your document:\n\n```javascript\nimport { jsPDF } from \"jspdf\";\n\n// Default export is a4 paper, portrait, using millimeters for units\nconst doc = new jsPDF();\n\ndoc.text(\"Hello world!\", 10, 10);\ndoc.save(\"a4.pdf\");\n```\n\nIf you want to change the paper size, orientation, or units, you can do:\n\n```javascript\n// Landscape export, 2Ã—4 inches\nconst doc = new jsPDF({\n  orientation: \"landscape\",\n  unit: \"in\",\n  format: [4, 2]\n});\n\ndoc.text(\"Hello world!\", 1, 1);\ndoc.save(\"two-by-four.pdf\");\n```\n\n### Running in Node.js\n\n```javascript\nconst { jsPDF } = require(\"jspdf\"); // will automatically load the node version\n\nconst doc = new jsPDF();\ndoc.text(\"Hello world!\", 10, 10);\ndoc.save(\"a4.pdf\"); // will save the file in the current working directory\n```\n\n### Other Module Formats\n\n<details>\n  <summary>\n    <b>AMD</b>\n  </summary>\n\n```js\nrequire([\"jspdf\"], ({ jsPDF }) => {\n  const doc = new jsPDF();\n  doc.text(\"Hello world!\", 10, 10);\n  doc.save(\"a4.pdf\");\n});\n```\n\n</details>\n\n<details>\n  <summary>\n    <b>Globals</b>\n  </summary>\n\n```js\nconst { jsPDF } = window.jspdf;\n\nconst doc = new jsPDF();\ndoc.text(\"Hello world!\", 10, 10);\ndoc.save(\"a4.pdf\");\n```\n\n</details>\n\n## Security\n\nWe strongly advise you to sanitize user input before passing it to jsPDF!\n\nFor reporting security vulnerabilities, please see [SECURITY.md](https://github.com/parallax/jsPDF/blob/master/SECURITY.md).\n\n### Reading files from the local file system on node\n\nWhen running under Node.js, jsPDF will restrict reading files from the local file system by default.\n\nStrongly recommended: use Node's permission flags so the runtime enforces access:\n\n```sh\nnode --permission --allow-fs-read=... ./scripts/generate.js\n```\n\nSee [Node's documentation](https://nodejs.org/api/permissions.html) for details. Note that you need to include\nall imported JavaScript files (including all dependencies) in the `--allow-fs-read` flag.\n\nFallback (not recommended): you can allow jsPDF to read specific files by setting `jsPDF.allowFsRead` in your script.\n\n```js\nimport { jsPDF } from \"jspdf\";\n\nconst doc = new jsPDF();\ndoc.allowFsRead = [\"./fonts/*\", \"./images/logo.png\"]; // allow everything under ./fonts and a single file\n```\n\nWarning: We strongly recommend the Node flags over `jsPDF.allowFsRead`, as the flags are enforced by the runtime and offer stronger security.\n\n### Optional dependencies\n\nSome functions of jsPDF require optional dependencies. E.g. the `html` method, which depends on `html2canvas` and,\nwhen supplied with a string HTML document, `dompurify`. JsPDF loads them dynamically when required\n(using the respective module format, e.g. dynamic imports). Build tools like Webpack will automatically create separate\nchunks for each of the optional dependencies. If your application does not use any of the optional dependencies, you\ncan prevent Webpack from generating the chunks by defining them as external dependencies:\n\n```js\n// webpack.config.js\nmodule.exports = {\n  // ...\n  externals: {\n    // only define the dependencies you are NOT using as externals!\n    canvg: \"canvg\",\n    html2canvas: \"html2canvas\",\n    dompurify: \"dompurify\"\n  }\n};\n```\n\nIn **Vue CLI** projects, externals can be defined via the [configureWebpack](https://cli.vuejs.org/config/#configurewebpack)\nor [chainWebpack](https://cli.vuejs.org/config/#chainwebpack) properties of the `vue.config.js` file\n(needs to be created, first, in fresh projects).\n\nIn **Angular** projects, externals can be defined using\n[custom webpack builders](https://github.com/just-jeb/angular-builders/tree/master/packages/custom-webpack).\n\nIn **React** (`create-react-app`) projects, externals can be defined by either using\n[react-app-rewired](https://github.com/timarney/react-app-rewired) or ejecting.\n\n### TypeScript/Angular/Webpack/React/etc. Configuration:\n\njsPDF can be imported just like any other 3rd party library. This works with all major toolkits and frameworks. jsPDF\nalso offers a typings file for TypeScript projects.\n\n```js\nimport { jsPDF } from \"jspdf\";\n```\n\nYou can add jsPDF to your meteor-project as follows:\n\n```\nmeteor add jspdf:core\n```\n\n### Polyfills\n\njsPDF requires modern browser APIs in order to function. To use jsPDF in older browsers like Internet Explorer,\npolyfills are required. You can load all required polyfills as follows:\n\n```js\nimport \"jspdf/dist/polyfills.es.js\";\n```\n\nAlternatively, you can load the prebundled polyfill file. This is not recommended, since you might end up\nloading polyfills multiple times. Might still be nifty for small applications or quick POCs.\n\n```html\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jspdf/4.1.0/polyfills.umd.js\"></script>\n```\n\n## Use of Unicode Characters / UTF-8:\n\nThe 14 standard fonts in PDF are limited to the ASCII-codepage. If you want to use UTF-8 you have to integrate a\ncustom font, which provides the needed glyphs. jsPDF supports .ttf-files. So if you want to have for example\nChinese text in your pdf, your font has to have the necessary Chinese glyphs. So, check if your font supports\nthe wanted glyphs or else it will show garbled characters instead of the right text.\n\nTo add the font to jsPDF use our fontconverter in\n[/fontconverter/fontconverter.html](https://rawgit.com/MrRio/jsPDF/master/fontconverter/fontconverter.html).\nThe fontconverter will create a js-file with the content of the provided ttf-file as base64 encoded string\nand additional code for jsPDF. You just have to add this generated js-File to your project.\nYou are then ready to go to use setFont-method in your code and write your UTF-8 encoded text.\n\nAlternatively you can just load the content of the \\*.ttf file as a binary string using `fetch` or `XMLHttpRequest` and\nadd the font to the PDF file:\n\n```js\nconst doc = new jsPDF();\n\nconst myFont = ... // load the *.ttf font file as binary string\n\n// add the font to jsPDF\ndoc.addFileToVFS(\"MyFont.ttf\", myFont);\ndoc.addFont(\"MyFont.ttf\", \"MyFont\", \"normal\");\ndoc.setFont(\"MyFont\");\n```\n\n## Advanced Functionality\n\nSince the merge with the [yWorks fork](https://github.com/yWorks/jsPDF) there are a lot of new features. However, some\nof them are API breaking, which is why there is an API-switch between two API modes:\n\n- In \"compat\" API mode, jsPDF has the same API as MrRio's original version, which means full compatibility with plugins.\n  However, some advanced features like transformation matrices and patterns won't work. This is the default mode.\n- In \"advanced\" API mode, jsPDF has the API you're used from the yWorks-fork version. This means the availability of\n  all advanced features like patterns, FormObjects, and transformation matrices.\n\nYou can switch between the two modes by calling\n\n```javascript\ndoc.advancedAPI(doc => {\n  // your code\n});\n// or\ndoc.compatAPI(doc => {\n  // your code\n});\n```\n\nJsPDF will automatically switch back to the original API mode after the callback has run.\n\n## Support\n\nPlease check if your question is already handled at Stackoverflow <https://stackoverflow.com/questions/tagged/jspdf>.\nFeel free to ask a question there with the tag `jspdf`.\n\nFeature requests, bug reports, etc. are very welcome as issues. Note that bug reports should follow these guidelines:\n\n- A bug should be reported as an [mcve](https://stackoverflow.com/help/mcve)\n- Make sure code is properly indented and [formatted](https://help.github.com/articles/basic-writing-and-formatting-syntax/#quoting-code) (Use ``` around code blocks)\n- Provide a runnable example.\n- Try to make sure and show in your issue that the issue is actually related to jspdf and not your framework of choice.\n\n## Contributing\n\njsPDF cannot live without help from the community! If you think a feature is missing or you found a bug, please consider\nif you can spare one or two hours and prepare a pull request. If you're simply interested in this project and want to\nhelp, have a look at the open issues, especially those labeled with \"bug\".\n\nYou can find information about building and testing jsPDF in the\n[contribution guide](https://github.com/MrRio/jsPDF/blob/master/CONTRIBUTING.md#pull-requests)\n\n## Credits\n\n- Big thanks to Daniel Dotsenko from [Willow Systems Corporation](https://github.com/willowsystems) for making huge contributions to the codebase.\n- Thanks to Ajaxian.com for [featuring us back in 2009](http://web.archive.org/web/20111011192314/http://ajaxian.com/archives/dynamically-generic-pdfs-with-javascript). (Internet Archive Wayback Machine reference)\n- Our special thanks to GH Lee ([sphilee](https://github.com/sphilee)) for programming the ttf-file-support and providing a large and long sought after feature\n- Everyone else that's contributed patches or bug reports. You rock.\n\n## License (MIT)\n\nCopyright\n(c) 2010-2025 James Hall, https://github.com/MrRio/jsPDF\n(c) 2015-2025 yWorks GmbH, https://www.yworks.com/\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
      "stars_today": 1
    },
    {
      "id": 27729907,
      "name": "grpc-go",
      "full_name": "grpc/grpc-go",
      "description": "The Go language implementation of gRPC. HTTP/2 based RPC",
      "html_url": "https://github.com/grpc/grpc-go",
      "stars": 22774,
      "forks": 4641,
      "language": "Go",
      "topics": [
        "dogs-over-cats",
        "giant-robots",
        "go",
        "golang",
        "grpc",
        "hacktoberfest",
        "microservices",
        "not-nanoservices",
        "proto",
        "rpc"
      ],
      "created_at": "2014-12-08T18:59:34Z",
      "updated_at": "2026-02-06T23:23:55Z",
      "pushed_at": "2026-02-05T17:44:58Z",
      "open_issues": 128,
      "owner": {
        "login": "grpc",
        "avatar_url": "https://avatars.githubusercontent.com/u/7802525?v=4"
      },
      "readme": "# gRPC-Go\n\n[![GoDoc](https://pkg.go.dev/badge/google.golang.org/grpc)][API]\n[![GoReportCard](https://goreportcard.com/badge/grpc/grpc-go)](https://goreportcard.com/report/github.com/grpc/grpc-go)\n[![codecov](https://codecov.io/gh/grpc/grpc-go/graph/badge.svg)](https://codecov.io/gh/grpc/grpc-go)\n\nThe [Go][] implementation of [gRPC][]: A high performance, open source, general\nRPC framework that puts mobile and HTTP/2 first. For more information see the\n[Go gRPC docs][], or jump directly into the [quick start][].\n\n## Prerequisites\n\n- **[Go][]**: any one of the **two latest major** [releases][go-releases].\n\n## Installation\n\nSimply add the following import to your code, and then `go [build|run|test]`\nwill automatically fetch the necessary dependencies:\n\n\n```go\nimport \"google.golang.org/grpc\"\n```\n\n> **Note:** If you are trying to access `grpc-go` from **China**, see the\n> [FAQ](#FAQ) below.\n\n## Learn more\n\n- [Go gRPC docs][], which include a [quick start][] and [API\n  reference][API] among other resources\n- [Low-level technical docs](Documentation) from this repository\n- [Performance benchmark][]\n- [Examples](examples)\n- [Contribution guidelines](CONTRIBUTING.md)\n\n## FAQ\n\n### I/O Timeout Errors\n\nThe `golang.org` domain may be blocked from some countries. `go get` usually\nproduces an error like the following when this happens:\n\n```console\n$ go get -u google.golang.org/grpc\npackage google.golang.org/grpc: unrecognized import path \"google.golang.org/grpc\" (https fetch: Get https://google.golang.org/grpc?go-get=1: dial tcp 216.239.37.1:443: i/o timeout)\n```\n\nTo build Go code, there are several options:\n\n- Set up a VPN and access google.golang.org through that.\n\n- With Go module support: it is possible to use the `replace` feature of `go\n  mod` to create aliases for golang.org packages.  In your project's directory:\n\n  ```sh\n  go mod edit -replace=google.golang.org/grpc=github.com/grpc/grpc-go@latest\n  go mod tidy\n  go mod vendor\n  go build -mod=vendor\n  ```\n\n  Again, this will need to be done for all transitive dependencies hosted on\n  golang.org as well. For details, refer to [golang/go issue\n  #28652](https://github.com/golang/go/issues/28652).\n\n### Compiling error, undefined: grpc.SupportPackageIsVersion\n\nPlease update to the latest version of gRPC-Go using\n`go get google.golang.org/grpc`.\n\n### How to turn on logging\n\nThe default logger is controlled by environment variables. Turn everything on\nlike this:\n\n```console\n$ export GRPC_GO_LOG_VERBOSITY_LEVEL=99\n$ export GRPC_GO_LOG_SEVERITY_LEVEL=info\n```\n\n### The RPC failed with error `\"code = Unavailable desc = transport is closing\"`\n\nThis error means the connection the RPC is using was closed, and there are many\npossible reasons, including:\n 1. mis-configured transport credentials, connection failed on handshaking\n 1. bytes disrupted, possibly by a proxy in between\n 1. server shutdown\n 1. Keepalive parameters caused connection shutdown, for example if you have\n    configured your server to terminate connections regularly to [trigger DNS\n    lookups](https://github.com/grpc/grpc-go/issues/3170#issuecomment-552517779).\n    If this is the case, you may want to increase your\n    [MaxConnectionAgeGrace](https://pkg.go.dev/google.golang.org/grpc/keepalive?tab=doc#ServerParameters),\n    to allow longer RPC calls to finish.\n\nIt can be tricky to debug this because the error happens on the client side but\nthe root cause of the connection being closed is on the server side. Turn on\nlogging on __both client and server__, and see if there are any transport\nerrors.\n\n[API]: https://pkg.go.dev/google.golang.org/grpc\n[Go]: https://golang.org\n[Go module]: https://github.com/golang/go/wiki/Modules\n[gRPC]: https://grpc.io\n[Go gRPC docs]: https://grpc.io/docs/languages/go\n[Performance benchmark]: https://performance-dot-grpc-testing.appspot.com/explore?dashboard=5180705743044608\n[quick start]: https://grpc.io/docs/languages/go/quickstart\n[go-releases]: https://golang.org/doc/devel/release.html\n",
      "stars_today": 1
    },
    {
      "id": 501687,
      "name": "antlr4",
      "full_name": "antlr/antlr4",
      "description": "ANTLR (ANother Tool for Language Recognition) is a powerful parser generator for reading, processing, executing, or translating structured text or binary files.",
      "html_url": "https://github.com/antlr/antlr4",
      "stars": 18703,
      "forks": 3428,
      "language": "Java",
      "topics": [
        "antlr",
        "antlr4",
        "cpp",
        "csharp",
        "dart",
        "golang",
        "grammar",
        "java",
        "javascript",
        "language-recognition",
        "parse",
        "parser-generator",
        "parsing",
        "php",
        "python",
        "swift"
      ],
      "created_at": "2010-02-04T01:36:28Z",
      "updated_at": "2026-02-06T14:16:30Z",
      "pushed_at": "2026-01-01T20:38:26Z",
      "open_issues": 1049,
      "owner": {
        "login": "antlr",
        "avatar_url": "https://avatars.githubusercontent.com/u/80584?v=4"
      },
      "readme": "# ANTLR v4\n\n[![Java 11+](https://img.shields.io/badge/java-11+-4c7e9f.svg)](http://java.oracle.com)\n[![License](https://img.shields.io/badge/license-BSD-blue.svg)](https://raw.githubusercontent.com/antlr/antlr4/master/LICENSE.txt)\n\n**ANTLR** (ANother Tool for Language Recognition) is a powerful parser generator for reading, processing, executing, or translating structured text or binary files. It's widely used to build languages, tools, and frameworks. From a grammar, ANTLR generates a parser that can build parse trees and also generates a listener interface (or visitor) that makes it easy to respond to the recognition of phrases of interest.\n\n**Dev branch build status**\n\n[![MacOSX, Windows, Linux](https://github.com/antlr/antlr4/actions/workflows/hosted.yml/badge.svg)](https://github.com/antlr/antlr4/actions/workflows/hosted.yml) (github actions)\n\n<!--\n* [![Windows](https://github.com/antlr/antlr4/actions/workflows/windows.yml/badge.svg?branch=dev)](https://github.com/antlr/antlr4/actions/workflows/windows.yml) (github actions)\n\n* [![Circle CI Build Status (Linux)](https://img.shields.io/circleci/build/gh/antlr/antlr4/master?label=Linux)](https://app.circleci.com/pipelines/github/antlr/antlr4) (CircleCI)\n\n[![AppVeyor CI Build Status (Windows)](https://img.shields.io/appveyor/build/parrt/antlr4?label=Windows)](https://ci.appveyor.com/project/parrt/antlr4) \n[![Travis-CI Build Status (Swift-Linux)](https://img.shields.io/travis/antlr/antlr4.svg?label=Linux-Swift&branch=master)](https://travis-ci.com/github/antlr/antlr4)\n-->\n\n\n## Versioning\n\nANTLR 4 supports 10 target languages\n(Cpp, CSharp, Dart, Java, JavaScript, PHP, Python3, Swift, TypeScript, Go),\nand ensuring consistency across these targets is a unique and highly valuable feature.\nTo ensure proper support of this feature, each release of ANTLR is a complete release of the tool and the 10 runtimes, all with the same version.\nAs such, ANTLR versioning does not strictly follow semver semantics:\n\n* a component may be released with the latest version number even though nothing has changed within that component since the previous release\n* major version is bumped only when ANTLR is rewritten for a totally new \"generation\", such as ANTLR3 -> ANTLR4 (LL(\\*) -> ALL(\\*) parsing)\n* minor version updates may include minor breaking changes, the policy is to regenerate parsers with every release (4.11 -> 4.12)\n* backwards compatibility is only guaranteed for patch version bumps (4.11.1 -> 4.11.2)\n\nIf you use a semver verifier in your CI, you probably want to apply special rules for ANTLR, such as treating minor change as a major change.\n\n## Repo branch structure\n\nThe default branch for this repo is [`master`](https://github.com/antlr/antlr4/tree/master), which is the latest stable release and has tags for the various releases; e.g., see release tag [4.9.3](https://github.com/antlr/antlr4/tree/4.9.3).  Branch [`dev`](https://github.com/antlr/antlr4/tree/dev) is where development occurs between releases and all pull requests should be derived from that branch. The `dev` branch is merged back into `master` to cut a release and the release state is tagged (e.g., with `4.10-rc1` or `4.10`.) Visually our process looks roughly like this:\n\n<img src=\"doc/images/new-antlr-branches.png\" width=\"500\">\n\nThe Go target now has its own dedicated repo:\n\n```bash\n$ go get github.com/antlr4-go/antlr\n```\n**Note**\nThe dedicated Go repo is for `go get` and `import` only. Go runtime development is still performed in the main `antlr/antlr4` repo. \n\n## Authors and major contributors\n\n* [Terence Parr](http://www.cs.usfca.edu/~parrt/), parrt@cs.usfca.edu\nANTLR project lead and supreme dictator for life\n[University of San Francisco](http://www.usfca.edu/)\n* [Sam Harwell](http://tunnelvisionlabs.com/) (Tool co-author, Java and original C# target)\n* [Eric Vergnaud](https://github.com/ericvergnaud) (Javascript, TypeScript, Python2, Python3 targets and maintenance of C# target)\n* [Peter Boyer](https://github.com/pboyer) (Go target)\n* [Mike Lischke](http://www.soft-gems.net/) (C++ completed target)\n* Dan McLaughlin (C++ initial target)\n* David Sisson (C++ initial target and test)\n* [Janyou](https://github.com/janyou) (Swift target)\n* [Ewan Mellor](https://github.com/ewanmellor), [Hanzhou Shi](https://github.com/hanjoes) (Swift target merging)\n* [Ben Hamilton](https://github.com/bhamiltoncx) (Full Unicode support in serialized ATN and all languages' runtimes for code points > U+FFFF)\n* [Marcos Passos](https://github.com/marcospassos) (PHP target)\n* [Lingyu Li](https://github.com/lingyv-li) (Dart target)\n* [Ivan Kochurkin](https://github.com/KvanTTT) has made major contributions to overall quality, error handling, and Target performance.\n* [Justin King](https://github.com/jcking) has done a huge amount of work across multiple targets, but especially for C++.\n* [Ken Domino](https://github.com/kaby76) has a knack for finding bugs/issues and analysis; also a major contributor on the [grammars-v4 repo](https://github.com/antlr/grammars-v4).\n* [Jim Idle](https://github.com/jimidle) has contributed to previous versions of ANTLR and recently jumped back in to solve a major problem with the Go target.\n\n\n## Useful information\n\n* [Release notes](https://github.com/antlr/antlr4/releases)\n* [Getting started with v4](https://github.com/antlr/antlr4/blob/master/doc/getting-started.md)\n* [Official site](http://www.antlr.org/)\n* [Documentation](https://github.com/antlr/antlr4/blob/master/doc/index.md)\n* [FAQ](https://github.com/antlr/antlr4/blob/master/doc/faq/index.md)\n* [ANTLR code generation targets](https://github.com/antlr/antlr4/blob/master/doc/targets.md)<br>(Currently: Java, C#, Python3, JavaScript, TypeScript, Go, C++, Swift, Dart, PHP)\n* _Note: As of version 4.14, we are dropping support for Python 2. We love the Python\ncommunity, but Python 2 support was officially halted in Jan 2020. More recently,\nGitHub also dropped support for Python 2, which has made it impossible for us to\nmaintain a consistent level of quality across targets (we use GitHub for our CI).\nLong live Python 3!_\n* [Java API](http://www.antlr.org/api/Java/index.html)\n* [ANTLR v3](http://www.antlr3.org/)\n* [v3 to v4 Migration, differences](https://github.com/antlr/antlr4/blob/master/doc/faq/general.md)\n\nYou might also find the following pages useful, particularly if you want to mess around with the various target languages.\n \n* [How to build ANTLR itself](https://github.com/antlr/antlr4/blob/master/doc/building-antlr.md)\n* [How we create and deploy an ANTLR release](https://github.com/antlr/antlr4/blob/master/doc/releasing-antlr.md)\n\n## The Definitive ANTLR 4 Reference\n\nProgrammers run into parsing problems all the time. Whether itâ€™s a data format like JSON, a network protocol like SMTP, a server configuration file for Apache, a PostScript/PDF file, or a simple spreadsheet macro languageâ€”ANTLR v4 and this book will demystify the process. ANTLR v4 has been rewritten from scratch to make it easier than ever to build parsers and the language applications built on top. This completely rewritten new edition of the bestselling Definitive ANTLR Reference shows you how to take advantage of these new features.\n\nYou can buy the book [The Definitive ANTLR 4 Reference](http://amzn.com/dp/1934356999) at amazon or an [electronic version at the publisher's site](https://pragprog.com/book/tpantlr2/the-definitive-antlr-4-reference).\n\nYou will find the [Book source code](http://pragprog.com/titles/tpantlr2/source_code) useful.\n\n## Additional grammars\n[This repository](https://github.com/antlr/grammars-v4) is a collection of grammars without actions where the\nroot directory name is the all-lowercase name of the language parsed\nby the grammar. For example, java, cpp, csharp, c, etc...\n",
      "stars_today": 1
    },
    {
      "id": 738491,
      "name": "facebook-ios-sdk",
      "full_name": "facebook/facebook-ios-sdk",
      "description": "Used to integrate the Facebook Platform with your iOS & tvOS apps.",
      "html_url": "https://github.com/facebook/facebook-ios-sdk",
      "stars": 8022,
      "forks": 3688,
      "language": "Swift",
      "topics": [],
      "created_at": "2010-06-24T22:11:03Z",
      "updated_at": "2026-02-06T17:47:20Z",
      "pushed_at": "2026-02-03T00:32:09Z",
      "open_issues": 413,
      "owner": {
        "login": "facebook",
        "avatar_url": "https://avatars.githubusercontent.com/u/69631?v=4"
      },
      "readme": "# Facebook SDK for iOS\n\n[![Platforms](https://img.shields.io/cocoapods/p/FBSDKCoreKit.svg)](https://cocoapods.org/pods/FBSDKCoreKit)\n[![circleci](https://circleci.com/gh/facebook/facebook-ios-sdk/tree/main.svg?style=shield)](https://circleci.com/gh/facebook/facebook-ios-sdk/tree/main)\n\n[![CocoaPods](https://img.shields.io/cocoapods/v/FBSDKCoreKit.svg)](https://cocoapods.org/pods/FBSDKCoreKit)\n[![Carthage compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat)](https://github.com/Carthage/Carthage)\n\nThis open-source library allows you to integrate Facebook into your iOS app.\n\nLearn more about the provided samples, documentation, integrating the SDK into your app, accessing source code, and more\nat https://developers.facebook.com/docs/ios\n\nPlease take a moment and [subscribe to releases](https://docs.github.com/en/enterprise/2.15/user/articles/watching-and-unwatching-repositories) so that you can be notified about new features, deprecations, and critical fixes. To see information about the latest release, consult our [changelog](CHANGELOG.md).\n\n|:warning: Be Advised :warning:|\n|:---|\n|<p>We have begun rewriting the iOS SDK in Swift in order to modernize the code base.</p><p>Please monitor the changelog for updates to existing interfaces but keep in mind that some interfaces will be unstable during this process. As such, updating to a minor version may introduce compilation issues related to language interoperability. Using symbols now defined in Swift may require using `@import` syntax from Objective-C and using C++ will likely require workarounds like creating wrappers in Objective-C.</p>Please bear with us as we work towards providing an improved experience for integrating with the Facebook platform.|\n\n## TRY IT OUT\n\n### Swift Package Manager\n\n1. In Xcode, select File > Swift Packages > Add Package Dependency.\n1. Follow the prompts using the URL for this repository\n1. Select the `Facebook`-prefixed libraries you want to use\n1. Check-out the tutorials available online at: <https://developers.facebook.com/docs/ios/getting-started>\n1. Start coding! Visit <https://developers.facebook.com/docs/ios> for tutorials and reference documentation.\n\n## iOS 14 CHANGES\n\n### Data Disclosure\n\nDue to the release of iOS 14, tracking events that your app collects and sends to Facebook may require you to disclosed these data types in the App Store Connect questionnaire. It is your responsibility to ensure this is reflected in your applicationâ€™s privacy policy. Visit our blogpost for information on affected Facebook SDKs, APIs, and products and the Apple App Store Privacy Details article to learn more about the data types you will need to disclose.\n\nlink to FB blogpost https://developers.facebook.com/blog/post/2020/10/22/preparing-for-apple-app-store-data-disclosure-requirements/\n\napple store details https://developer.apple.com/app-store/app-privacy-details/\n\n## FEATURES\n\n- Login - <https://developers.facebook.com/docs/facebook-login>\n- Sharing - <https://developers.facebook.com/docs/sharing>\n- App Links - <https://developers.facebook.com/docs/applinks>\n- Graph API - <https://developers.facebook.com/docs/ios/graph>\n- Analytics - <https://developers.facebook.com/docs/analytics>\n\n## GIVE FEEDBACK\n\nPlease report bugs or issues to our designated developer support team -- <https://developers.facebook.com/support/bugs/> -- as this will help us resolve them more quickly.\n\nYou can also visit our [Facebook Developer Community Forum](https://developers.facebook.com/community/),\njoin the [Facebook Developers Group on Facebook](https://www.facebook.com/groups/fbdevelopers/),\nask questions on [Stack Overflow](https://stackoverflow.com/questions/tagged/facebook-ios-sdk),\nor open an issue in this repository.\n\n## CONTRIBUTE\n\nFacebook welcomes contributions to our SDKs. Please see the [CONTRIBUTING](CONTRIBUTING.md) file.\n\n## LICENSE\n\nSee the [LICENSE](LICENSE) file.\n\nCopyright Â© Meta Platforms, Inc\n\n## SECURITY POLICY\n\nSee the [SECURITY POLICY](SECURITY.md) for more info on our bug bounty program.\n\n## DEVELOPER TERMS\n\n- By enabling Facebook integrations, including through this SDK, you can share information with Facebook, including\n  information about peopleâ€™s use of your app. Facebook will use information received in accordance with our\n  [Data Use Policy](https://www.facebook.com/about/privacy/), including to provide you with insights about the\n  effectiveness of your ads and the use of your app. These integrations also enable us and our partners to serve ads on\n  and off Facebook.\n- You may limit your sharing of information with us by updating the Insights control in the developer tool\n  `https://developers.facebook.com/apps/{app_id}/settings/advanced`.\n- If you use a Facebook integration, including to share information with us, you agree and confirm that you have\n  provided appropriate and sufficiently prominent notice to and obtained the appropriate consent from your users\n  regarding such collection, use, and disclosure (including, at a minimum, through your privacy policy). You further\n  agree that you will not share information with us about children under the age of 13.\n- You agree to comply with all applicable laws and regulations and also agree to our Terms\n  <https://www.facebook.com/policies/>, including our Platform Policies <https://developers.facebook.com/policy/> and\n  Advertising Guidelines, as applicable <https://www.facebook.com/ad_guidelines.php>.\n\nBy using the Facebook SDK for iOS you agree to these terms.\n",
      "stars_today": 1
    },
    {
      "id": 4729944,
      "name": "shiny",
      "full_name": "rstudio/shiny",
      "description": "Easy interactive web applications with R",
      "html_url": "https://github.com/rstudio/shiny",
      "stars": 5599,
      "forks": 1883,
      "language": "R",
      "topics": [
        "r",
        "reactive",
        "rstudio",
        "shiny",
        "web-app",
        "web-development"
      ],
      "created_at": "2012-06-20T18:45:11Z",
      "updated_at": "2026-02-06T15:49:16Z",
      "pushed_at": "2026-02-06T21:47:56Z",
      "open_issues": 871,
      "owner": {
        "login": "rstudio",
        "avatar_url": "https://avatars.githubusercontent.com/u/513560?v=4"
      },
      "readme": "# shiny <img src=\"man/figures/logo.png\" align=\"right\" width=120 height=139 alt=\"\" />\n\n<!-- badges: start -->\n[![CRAN](https://www.r-pkg.org/badges/version/shiny)](https://CRAN.R-project.org/package=shiny)\n[![R build status](https://github.com/rstudio/shiny/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/rstudio/shiny/actions)\n[![RStudio community](https://img.shields.io/badge/community-shiny-blue?style=social&logo=rstudio&logoColor=75AADB)](https://forum.posit.co/new-topic?category=shiny&tags=shiny)\n\n<!-- badges: end -->\n\nEasily build rich and productive interactive web apps in R &mdash; no HTML/CSS/JavaScript required.\n\n## Features\n\n* An intuitive and extensible [reactive programming](https://en.wikipedia.org/wiki/Reactive_programming) model which makes it easy to transform existing R code into a \"live app\" where outputs automatically react to new user input.\n  * Compared to event-based programming, reactivity allows Shiny to do the minimum amount of work when input(s) change, and allows humans to more easily reason about complex [MVC logic](https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller).\n* A prebuilt set of highly sophisticated, customizable, and easy-to-use widgets (e.g., plots, tables, sliders, dropdowns, date pickers, and more).\n* An attractive default look based on [Bootstrap](https://getbootstrap.com/) which can also be easily customized with the [bslib](https://github.com/rstudio/bslib) package or avoided entirely with more direct R bindings to HTML/CSS/JavaScript.\n* Seamless integration with [R Markdown](https://shiny.rstudio.com/articles/interactive-docs.html), making it easy to embed numerous applications natively within a larger dynamic document.\n* Tools for improving and monitoring performance, including native support for [async programming](https://posit.co/blog/shiny-1-1-0/), [caching](https://talks.cpsievert.me/20201117), [load testing](https://rstudio.github.io/shinyloadtest/), and more.\n* [Modules](https://shiny.rstudio.com/articles/modules.html): a framework for reducing code duplication and complexity.\n* An ability to [bookmark application state](https://shiny.rstudio.com/articles/bookmarking-state.html) and/or [generate code to reproduce output(s)](https://github.com/rstudio/shinymeta).\n* A rich ecosystem of extension packages for more [custom widgets](http://www.htmlwidgets.org/), [input validation](https://github.com/rstudio/shinyvalidate), [unit testing](https://github.com/rstudio/shinytest), and more.\n\n## Installation\n\nTo install the stable version from CRAN:\n\n```r\ninstall.packages(\"shiny\")\n```\n\n## Getting Started\n\nOnce installed, load the library and run an example:\n\n```r\nlibrary(shiny)\n# Launches an app, with the app's source code included\nrunExample(\"06_tabsets\")\n# Lists more prepackaged examples\nrunExample()\n```\n\nFor more examples and inspiration, check out the [Shiny User Gallery](https://shiny.rstudio.com/gallery/).\n\nFor help with learning fundamental Shiny programming concepts, check out the [Mastering Shiny](https://mastering-shiny.org/) book and the [Shiny Tutorial](https://shiny.rstudio.com/tutorial/). The former is currently more up-to-date with modern Shiny features, whereas the latter takes a deeper, more visual, dive into fundamental concepts.\n\n## Join the conversation\n\nIf you want to chat about Shiny, meet other developers, or help us decide what to work on next, [join us on Discord](https://discord.com/invite/yMGCamUMnS).\n\n## Getting Help\n\nTo ask a question about Shiny, please use the [RStudio Community website](https://forum.posit.co/new-topic?category=shiny&tags=shiny).\n\nFor bug reports, please use the [issue tracker](https://github.com/rstudio/shiny/issues) and also keep in mind that by [writing a good bug report](https://github.com/rstudio/shiny/wiki/Writing-Good-Bug-Reports), you're more likely to get help with your problem.\n\n## Contributing\n\nWe welcome contributions to the **shiny** package. Please see our [CONTRIBUTING.md](https://github.com/rstudio/shiny/blob/main/.github/CONTRIBUTING.md) file for detailed guidelines of how to contribute.\n\n## License\n\nThe shiny package as a whole is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.\n\n## R version support\n\nShiny is supported on the latest release version of R, as well as the previous four minor release versions of R. For example, if the latest release R version is 4.3, then that version is supported, as well as 4.2, 4.1, 4.0, 3.6.\n",
      "stars_today": 1
    },
    {
      "id": 66302557,
      "name": "SwiftFormat",
      "full_name": "nicklockwood/SwiftFormat",
      "description": "A command-line tool and Xcode Extension for formatting Swift code",
      "html_url": "https://github.com/nicklockwood/SwiftFormat",
      "stars": 8686,
      "forks": 674,
      "language": "Swift",
      "topics": [],
      "created_at": "2016-08-22T19:39:05Z",
      "updated_at": "2026-02-06T22:51:29Z",
      "pushed_at": "2026-02-03T23:58:12Z",
      "open_issues": 331,
      "owner": {
        "login": "nicklockwood",
        "avatar_url": "https://avatars.githubusercontent.com/u/546885?v=4"
      },
      "readme": "![](EditorExtension/Application/Assets.xcassets/AppIcon.appiconset/icon_256x256.png)\n\n[![PayPal](https://img.shields.io/badge/paypal-donate-blue.svg)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=9ZGWNK5FEZFF6&source=url)\n[![Build](https://github.com/nicklockwood/SwiftFormat/actions/workflows/build.yml/badge.svg)](https://github.com/nicklockwood/SwiftFormat/actions/workflows/build.yml)\n[![Codecov](https://codecov.io/gh/nicklockwood/SwiftFormat/graphs/badge.svg)](https://codecov.io/gh/nicklockwood/SwiftFormat)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fnicklockwood%2FSwiftFormat%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/nicklockwood/swiftformat)\n[![License](https://img.shields.io/badge/license-MIT-lightgrey.svg)](https://opensource.org/licenses/MIT)\n[![Mastodon](https://img.shields.io/badge/mastodon-@nicklockwood@mastodon.social-636dff.svg)](https://mastodon.social/@nicklockwood)\n\nTable of Contents\n-----------------\n\n- [What?](#what-is-this)\n- [Why?](#why-would-i-want-to-do-that)\n- [How?](#how-do-i-install-it)\n    - [Command-line tool](#command-line-tool)\n    - [Xcode source editor extension](#xcode-source-editor-extension)\n    - [Xcode build phase](#xcode-build-phase)\n    - [Swift Package Manager plugin](#swift-package-manager-plugin)\n    - [Via Applescript](#via-applescript)\n    - [VSCode plugin](#vscode-plugin)\n    - [Sublime Text plugin](#sublime-text-plugin)\n    - [Nova plugin](nova-plugin)\n    - [Git pre-commit hook](#git-pre-commit-hook)\n    - [GitHub Actions](#github-actions)\n    - [On CI using Danger](#on-ci-using-danger)\n    - [Bazel build](#bazel-build)\n    - [Docker](#docker)\n    - [Prerelease Builds](#prerelease-builds)\n- [Configuration](#configuration)\n    - [Options](#options)\n    - [Rules](#rules)\n    - [Swift version](#swift-version)\n    - [Config file](#config-file)\n    - [Globs](#globs)\n    - [Linting](#linting)\n    - [Error codes](#error-codes)\n    - [Cache](#cache)\n    - [File headers](#file-headers)\n    - [Markdown formatting](#markdown-formatting)\n- [FAQ](#faq)\n- [Known issues](#known-issues)\n- [Tip Jar](#tip-jar)\n- [Credits](#credits)\n\n\nWhat is this?\n----------------\n\nSwiftFormat is a code library and command-line tool for reformatting Swift code on macOS, Linux or Windows.\n\nSwiftFormat goes above and beyond what you might expect from a code formatter. In addition to adjusting white space it can insert or remove implicit `self`, remove redundant parentheses, and correct many other deviations from the standard Swift idioms.\n\n\nWhy would I want to do that?\n-----------------------------\n\nMany programmers have a preferred style for formatting their code, and others seem entirely blind to the existing formatting conventions of a project (to the enragement of their colleagues).\n\nWhen collaborating on a project, it can be helpful to agree on a common coding style, but enforcing that manually is tedious and error-prone, and can lead to arguments if some participants take it more seriously than others.\n\nHaving a tool to automatically enforce a common style eliminates those issues, and lets you focus on the behavior of the code, not its presentation.\n\n\nHow do I install it?\n---------------------\n\nThat depends - There are several ways you can use SwiftFormat:\n\n1. As a command-line tool that you run manually, or as part of some other toolchain\n2. As a Source Editor Extension that you can invoke via the Editor > SwiftFormat menu within Xcode\n3. As a build phase in your Xcode project, so that it runs every time you press Cmd-R or Cmd-B, or\n4. As a Git pre-commit hook, so that it runs on any files you've changed before you check them in\n\n\nCommand-line tool\n-------------------\n\n**Installation:**\n\nYou can install the `swiftformat` command-line tool on macOS or Linux using [Homebrew](http://brew.sh/). Assuming you already have Homebrew installed, just type:\n\n```bash\n$ brew install swiftformat\n```\n\nTo update to the latest version once installed:\n\n```bash\n$ brew upgrade swiftformat\n```\n\nAlternatively, you can install the tool on macOS or Linux by using [Mint](https://github.com/yonaskolb/Mint) as follows:\n\n```bash\n$ mint install nicklockwood/SwiftFormat\n```\n\nOr if you prefer, you can check out and build SwiftFormat manually on macOS, Linux or Windows as follows:\n\n```bash\n$ git clone https://github.com/nicklockwood/SwiftFormat\n$ cd SwiftFormat\n$ swift build -c release\n```\n\nIf you are installing SwiftFormat into your project directory, you can use [CocoaPods](https://cocoapods.org/) on macOS to automatically install the swiftformat binary along with your other pods - see the Xcode build phase instructions below for details.\n\nAnother option is to include the binary artifactbundle in your `Package.swift`:\n\n```swift\n.binaryTarget(\n    name: \"swiftformat\",\n    url: \"https://github.com/nicklockwood/SwiftFormat/releases/download/0.55.0/swiftformat-macos.artifactbundle.zip\",\n    checksum: \"CHECKSUM\"\n),\n``` \n\nIf you would prefer not to use a package manager, you can build the command-line app manually:\n\n1. open `SwiftFormat.xcodeproj` and build the `SwiftFormat (Application)` scheme.\n\n2. Drag the `swiftformat` binary into `/usr/local/bin/` (this is a hidden folder, but you can use the Finder's `Go > Go to Folder...` menu to open it).\n\n3. Open `~/.bash_profile` in your favorite text editor (this is a hidden file, but you can type `open ~/.bash_profile` in the terminal to open it).\n\n4. Add the following line to the file: `alias swiftformat=\"/usr/local/bin/swiftformat --indent 4\"` (you can omit the `--indent 4`, or replace it with something else. Run `swiftformat --help` to see the available options).\n\n5. Save the `.bash_profile` file and run the command `source ~/.bash_profile` for the changes to take effect.\n\n**Usage:**\n\nIf you followed the installation instructions above, you can now just type\n\n```bash\n$ swiftformat .\n```\n\n(that's a space and then a period after the command) in the terminal to format any Swift files in the current directory. In place of the `.`, you can instead type an absolute or relative path to the file or directory that you want to format.\n\n**WARNING:** `swiftformat .` will overwrite any Swift files it finds in the current directory, and any subfolders therein. If you run it in your home directory, it will probably reformat every Swift file on your hard drive.\n\nTo use it safely, do the following:\n\n1. Choose a file or directory that you want to apply the changes to.\n\n2. Make sure that you have committed all your changes to that code safely in git (or whatever source control system you use).\n\n3. (Optional) In Terminal, type `swiftformat --infer-options \"/path/to/your/code/\"`. This will suggest a set of formatting options to use that match your existing project style (but you are free to ignore these and use the defaults, or your own settings if you prefer).\n\n    The path can point to either a single Swift file or a directory of files. It can be either be absolute, or relative to the current directory. The `\"\"` quotes around the path are optional, but if the path contains spaces then you either need to use quotes, or escape each space with `\\`. You may include multiple paths separated by spaces.\n\n4. In Terminal, type `swiftformat \"/path/to/your/code/\"`. The same rules apply as above with respect to paths, and multiple space-delimited paths are allowed.\n\n    If you used `--infer-options` to generate a suggested set of options in step 3, you should copy and paste them into the command, either before or after the path(s) to your source files.\n\n    If you have created a [config file](#config-file), you can specify its path using `--config \"/path/to/your/config-file/\"`. Alternatively, if you name the file `.swiftformat` and place it inside the project you are formatting, it will be picked up automatically.\n\n5. Press enter to begin formatting. Once the formatting is complete, use your source control system to check the changes, and verify that no undesirable changes have been introduced. If they have, revert the changes, tweak the options and try again.\n\n6. (Optional) commit the changes.\n\nFollowing these instructions *should* ensure that you avoid catastrophic data loss, but in the unlikely event that it wipes your hard drive, **please note that I accept no responsibility**.\n\n**Using Standard Input/Output:**\n\nIf you prefer, you can use unix pipes to include SwiftFormat as part of a command chain. For example, this is an alternative way to format a file:\n\n```bash\n$ cat /path/to/file.swift | swiftformat --output /path/to/file.swift\n```\n\nOmitting the `--output /path/to/file.swift` will print the formatted file to Standard Output (stdout). You can also pass \"stdout\" explicitly as the output path:\n\n```bash\n$ cat /path/to/file.swift | swiftformat --output stdout\n```\n\nOr you can use `>` to specify the output path as follows:\n\n```bash\n$ cat /path/to/file.swift | swiftformat > /path/to/file.swift\n```\n\nIf you do not supply an input file, SwiftFormat will automatically take its input from Standard Input (stdin), but will time-out if no input is received immediately and display the help screen. To make it explicit, pass \"stdin\" as the input path:\n\n```bash\n$ cat /path/to/file.swift | swiftformat stdin\n```\n\nWhen using stdin, SwiftFormat does not have access to the file path of the input, so features that rely on the file location (such as inserting the creation date into header comments, or detecting `.swiftformat` configuration files in the file path) will not work. To solve this, you can provide the file path using the `--stdin-path` argument:\n\n```bash\n$ cat /path/to/file.swift | swiftformat stdin --stdinpath /path/to/file.swift\n```\n\n\nXcode source editor extension\n-----------------------------\n\n**Installation:**\n\nLike the command-line tool, you can install the SwiftFormat for Xcode extension application via [Homebrew](http://brew.sh/). Assuming you already have Homebrew installed, type:\n\n```bash\n$ brew install --cask swiftformat-for-xcode\n```\n\nThis will install SwiftFormat for Xcode in your Applications folder. Double-click the app to launch it, and then follow the on-screen instructions.\n\n**NOTE:** The app should be correctly signed, but if you get a Gatekeeper warning when trying to open it you can bypass this by right-clicking (or control-clicking) the app and selecting `Open`.\n\nTo update to the latest version once installed use:\n\n```bash\n$ brew upgrade --cask swiftformat-for-xcode\n```\n\nAlternatively, if you prefer not to use Homebrew, you'll find the latest version of the SwiftFormat for Xcode application on the [GitHub Releases](https://github.com/nicklockwood/SwiftFormat/releases) page. Download and unpack the zip archive, then drag `SwiftFormat for Xcode.app` into your `Applications` folder.\n\n**Usage:**\n\nOnce you have launched the app and restarted Xcode, you'll find a SwiftFormat option under Xcode's Editor menu. If the SwiftFormat menu does not appear [this thread](https://github.com/nicklockwood/SwiftFormat/issues/494) may help. \n\nYou can configure the formatting [rules](#rules) and [options](#options) using the SwiftFormat for Xcode host application. There is currently no way to override these per-project, however, you can import and export different configurations using the File menu. You will need to do this again each time you switch projects.\n\nThe format of the configuration file is described in the [Config section](#config-file) below.\n\n**Note:** SwiftFormat for Xcode cannot automatically detect changes to an imported configuration file. If you update the `.swiftformat` file for your project, you will need to manually re-import that file into SwiftFormat for Xcode in order for the Xcode source editor extension to use the new configuration.\n\n\nXcode build phase\n-------------------\n\n**NOTE:** Adding this script will overwrite your source files as you work on them, which has the annoying side-effect of clearing the undo history. You may wish to add the script to your test target rather than your main target, so that it is invoked only when you run the unit tests, and not every time you build the app.\n\nAlternatively, you might want to consider running SwiftFormat in [lint](#linting) mode as part of your normal build, and then running a formatting pass manually, or as part of a less-frequent build target (such as the tests).\n\n### Using Swift Package Manager\n\nTo set up SwiftFormat as an Xcode build phase, do the following:\n\n#### 1) Create a BuildTools folder and Package.swift\n\n1. Create a folder called `BuildTools` in the same folder as your xcodeproj file\n2. In this folder, create a file called `Package.swift`, with the following contents:\n```swift\n// swift-tools-version:5.1\nimport PackageDescription\n\nlet package = Package(\n    name: \"BuildTools\",\n    platforms: [.macOS(.v10_11)],\n    dependencies: [\n        .package(url: \"https://github.com/nicklockwood/SwiftFormat\", from: \"0.59.1\"),\n    ],\n    targets: [.target(name: \"BuildTools\", path: \"\")]\n)\n```\n3. If you are running Xcode 11.4 or later, in the `BuildTools` folder create a file called `Empty.swift` with nothing in it. This is to satisfy a change in Swift Package Manager.\n\n#### 2) Add a Build phase to your app target\n\n1. Click on your project in the file list, choose your target under `TARGETS`, click the `Build Phases` tab\n2. Add a `New Run Script Phase` by clicking the little plus icon in the top left\n3. Uncheck the `Based on dependency analysis` checkbox\n4. Drag the new `Run Script` phase **above** the `Compile Sources` phase, expand it and paste the following script:\n\n    ```bash\n    cd BuildTools\n    SDKROOT=(xcrun --sdk macosx --show-sdk-path)\n    #swift package update #Uncomment this line temporarily to update the version used to the latest matching your BuildTools/Package.swift file\n    swift run -c release swiftformat \"$SRCROOT\"\n    ```\n\nYou can also use `swift run -c release --package-path BuildTools swiftformat \"$SRCROOT\"` if you need a more complex script and `cd BuildTools` breaks stuff.\n\n**NOTE:** You may wish to check BuildTools/Package.swift into your source control so that the version used by your run-script phase is kept in version control. It is recommended to add the following to your .gitignore file: `BuildTools/.build` and `BuildTools/.swiftpm`.\n\n**NOTE (2):** If you are using Xcode 15 or later, make sure that the `ENABLE_USER_SCRIPT_SANDBOXING` (aka \"User Script Sandboxing\") option is set to NO, otherwise SwiftFormat won't be able to run correctly.\n\n### Using CocoaPods\n\n#### 1) Add the SwiftFormat CLI to your Podfile\n\n1. Add the `swiftformat` binary to your project directory via [CocoaPods](https://cocoapods.org/), by adding the following line to your Podfile then running `pod install`:\n\n    ```ruby\n    pod 'SwiftFormat/CLI', '~> 0.59.1'\n    ```\n\n**NOTE:** This will only install the pre-built command-line app, not the source code for the SwiftFormat framework.\n\n**NOTE (2):** When installing this way, GateKeeper may block swiftformat from running until you open it manually the first time by right-clicking in the Finder and selecting \"Open\".\n\n#### 2) Add a Build phase to your app target\n\n1. Click on your project in the file list, choose your target under `TARGETS`, click the `Build Phases` tab\n2. Add a `New Run Script Phase` by clicking the little plus icon in the top left\n3. Uncheck the `Based on dependency analysis` checkbox\n4. Drag the new `Run Script` phase **above** the `Compile Sources` phase, expand it and paste the following script:\n\n    ```bash\n    \"${PODS_ROOT}/SwiftFormat/CommandLineTool/swiftformat\" \"$SRCROOT\"\n    ```\n\n### Alternative: Locally installed SwiftFormat\n\nAlternatively, you could use a locally installed swiftformat command-line tool instead by putting the following in your Run Script build phase:\n\n```bash\nif which swiftformat >/dev/null; then\n  swiftformat .\nelse\n  echo \"warning: SwiftFormat not installed, download from https://github.com/nicklockwood/SwiftFormat\"\nfi\n```\n\nThis is not recommended for shared projects however, as different team members using different versions of SwiftFormat may result in noise in the commit history as code gets reformatted inconsistently.\n\nIf you installed SwiftFormat via Homebrew on Apple Silicon, you might experience this warning:\n\n> warning: SwiftFormat not installed, download from https://github.com/nicklockwood/SwiftFormat\n\nThat is because Homebrew on Apple Silicon installs the binaries into the `/opt/homebrew/bin`\nfolder by default. To instruct Xcode where to find SwiftFormat, you can either add\n`/opt/homebrew/bin` to the `PATH` environment variable in your build phase\n\n```bash\nif [[ \"$(uname -m)\" == arm64 ]]; then\n    export PATH=\"/opt/homebrew/bin:$PATH\"\nfi\n\nif which swiftformat > /dev/null; then\n  swiftformat .\nelse\n  echo \"warning: SwiftFormat not installed, download from https://github.com/nicklockwood/SwiftFormat\"\nfi\n```\n\nor you can create a symbolic link in `/usr/local/bin` pointing to the actual binary:\n\n```bash\nln -s /opt/homebrew/bin/swiftformat /usr/local/bin/swiftformat\n```\n\nSwift Package Manager plugin\n-----------------------------\n\nYou can use `SwiftFormat` as a SwiftPM command plugin.\n\n**NOTE:** Swift 5.6 or higher is required. Add the package to your dependencies in your `Package.swift` file.\n\n```swift\ndependencies: [\n    // ...\n    .package(url: \"https://github.com/nicklockwood/SwiftFormat\", from: \"0.59.1\"),\n]\n```\n\nThe plugin will find an existing `.swiftformat` in your package root folder and honor it automatically.\n\n### Trigger Plugin From Command-Line\n\n```bash\nswift package plugin --allow-writing-to-package-directory swiftformat\n```\n\nYou can limit the formatting to a particular target with `--target` option.\n\nYou can also specify `SwiftFormat` arguments, e.g. `--swift-version`.\n\nExample\n\n```bash\nswift package plugin --allow-writing-to-package-directory swiftformat --target MyLibrary --swift-version 5.6 --verbose\n```\n\n### Trigger Plugin From Xcode\n\nIn Xcode 14 you can trigger the command plugin execution for a Swift package or an Xcode project.\n\nFor an Xcode project the project's main directory will be processed and the `--target` option will be ignored.\n\nYou can also specify `SwiftFormat` arguments, e.g. `--swift-version`.\n\n![Run plugin in Xcode 14](https://user-images.githubusercontent.com/4176826/179352584-db7f7f42-452c-4a42-a329-01b115a237a7.gif)\n\nVia AppleScript\n----------------\n\nTo run SwiftFormat on the frontmost Xcode document (project or workspace) you can use the following AppleScript:\n\n```applescript\ntell application \"Xcode\"\n    set frontWindow to the first window\n    set myPath to path of document of frontWindow\n    do shell script \"cd \" & myPath & \";cd ..; /usr/local/bin/swiftformat .\"\nend tell\n```\n\nSome Apps you can trigger this from are [BetterTouchTool](https://folivora.ai), [Alfred](https://www.alfredapp.com) or [Keyboard Maestro](https://www.keyboardmaestro.com/main/). Another option is to define a QuickAction for Xcode via Automator and then assign a keyboard shortcut for it in the System Preferences.\n\n\nVSCode plugin\n--------------\n\nIf you prefer to use Microsoft's [VSCode](https://code.visualstudio.com) editor for writing Swift, [Valentin Knabel](https://github.com/vknabel) has created a [VSCode plugin](https://marketplace.visualstudio.com/items?itemName=vknabel.vscode-swiftformat) for SwiftFormat.\n\n\nSublime Text plugin\n--------------------\n\nIf you prefer to use the [Sublime Text](https://www.sublimetext.com) editor, try the [Sublime-Swift-Format plugin](https://github.com/aerobounce/Sublime-Swift-Format) by [Aerobounce](https://github.com/aerobounce).\n\n\nNova plugin\n-----------\n\nIf you prefer to use the [Nova](https://panic.com/nova) editor, try the [SwiftFormat extension](https://extensions.panic.com/extensions/org.padraig/org.padraig.SwiftFormat/) by [PÃ¡draig Ã“ CinnÃ©ide](https://mastodon.social/@PadraigOCinneide).\n\n\nGit pre-commit hook\n---------------------\n\n1. Follow the instructions for installing the SwiftFormat command-line tool.\n\n2. Install [git-format-staged](https://github.com/hallettj/git-format-staged).\n\n3. Edit or create a `.git/hooks/pre-commit` file in your project folder. The .git folder is hidden but should already exist if you are using Git with your project, so open it with the terminal, or the Finder's `Go > Go to Folder...` menu.\n\n4. Add the following line in the pre-commit file. The `{}` will be replaced automatically by the path to the Swift file being formatted:\n\n    ```bash\n    #!/bin/bash\n    git-format-staged --formatter \"swiftformat stdin --stdin-path '{}'\" \"*.swift\"\n    ```\n    \n    (Note that this example uses your locally installed version of SwiftFormat, not a separate copy in your project repository. You can replace `swiftformat` with the path to a copy inside your project if you prefer.)\n    \n5. enable the hook by typing `chmod +x .git/hooks/pre-commit` in the terminal.\n \nThe pre-commit hook will now run whenever you run `git commit`. Running `git commit --no-verify` will skip the pre-commit hook.\n\n**NOTE:** If you are using Git via a GUI client such as [Tower](https://www.git-tower.com), [additional steps](https://www.git-tower.com/help/mac/faq-and-tips/faq/hook-scripts) may be needed.\n\n**NOTE (2):** Unlike the Xcode build phase approach, git pre-commit hook won't be checked in to source control, and there's no way to guarantee that all users of the project are using the same version of SwiftFormat. For a collaborative project, you might want to consider a *post*-commit hook instead, which would run on your continuous integration server.\n\nGitHub Actions\n---------------------\n\n1. SwiftFormat comes preinstalled on all macOS GitHub-hosted runners. If you are self hosting you will need to ensure SwiftFormat is installed on your runner.\n2. Create a GitHub Actions workflow using SwiftFormat, passing the `--reporter github-actions-log` command line option. The following example action lints pull requests using SwiftFormat, reporting warnings using the GitHub Actions log.\n```yaml\n# Lint.yml\nname: Lint\non: pull_request\n\njobs:\n  Lint:\n    runs-on: macos-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: SwiftFormat\n        run: swiftformat --lint . --reporter github-actions-log\n```\n\nOn CI using Danger\n-------------------\n\nTo setup SwiftFormat to be used by your continuous integration system using [Danger](http://danger.systems/ruby/), do the following:\n\n1. Follow the [`instructions`](http://danger.systems/guides/getting_started.html) to setup Danger.\n2. Add the [`danger-swiftformat`](https://github.com/garriguv/danger-ruby-swiftformat) plugin to your `Gemfile`.\n3. Add the following to your `Dangerfile`:\n\n    ```ruby\n    swiftformat.binary_path = \"/path/to/swiftformat\" # optional\n    swiftformat.additional_args = \"--indent tab --self insert\" # optional\n    swiftformat.check_format(fail_on_error: true)\n    ```\n\n    **NOTE:** It is recommended to add the `swiftformat` binary to your project directory to ensure the same version is used each time (see the [Xcode build phase](#xcode-build-phase) instructions above).\n\n\nBazel Build\n-----------\n\nIf you use [Bazel](https://bazel.build/) to build your Swift projects and want to ensure that only properly formatted code is merged to your main branch, try [rules_swiftformat](https://github.com/cgrindel/rules_swiftformat). The repository contains Bazel rules and macros that format Swift source files using SwiftFormat, test that the formatted files exist in the workspace directory, and copy the formatted files to the workspace directory.\n\n\nDocker\n-----------\n\nSwiftFormat publishes releases into [GitHub Packages](https://github.com/features/packages) Docker registry. To pull the image call:\n\n```bash\n$ docker pull ghcr.io/nicklockwood/swiftformat:latest\n```\n\nBy default, the container runs `swiftformat .` Therefore, you need to provide a path either via an argument:\n\n```bash\ndocker run --rm -v /local/source/path:/work ghcr.io/nicklockwood/swiftformat:latest /work\n```\n\nor by changing the working dir:\n\n```bash\ndocker run --rm -v /local/source/path:/work -w /work ghcr.io/nicklockwood/swiftformat:latest\n```\n\nTo check the installed SwiftFormat version:\n\n```bash\ndocker run --rm ghcr.io/nicklockwood/swiftformat:latest --version\n```\n\nLinting example:\n\n```bash\ndocker run --rm -v /local/source/path:/work ghcr.io/nicklockwood/swiftformat:latest /work --lint\n```\n\nPrerelease Builds\n-----------------\n\n***Prerelease builds are subject to breaking changes.***\n\nNew rules, options, and fixes are merged to the [`develop`](https://github.com/nicklockwood/SwiftFormat/commits/develop/) branch before being incorporated into an official release. You may want to use a prerelease version of SwiftFormat that includes the latest unreleased changes.\n\n**Homebrew:**\n\nThe [Homebrew](http://brew.sh/) `--HEAD` option downloads, builds, and installs the latest changes from the `develop` branch. \n\nYou can install a prerelease build via Homebrew by running:\n\n```bash\n$ brew install swiftformat --HEAD\n```\n\n**Nightly Builds:**\n\nNightly builds of the `develop` branch are available in the [calda/SwiftFormat-nightly](https://github.com/calda/SwiftFormat-nightly) repo. A new release is published every day, unless there have been no changes to `develop` since the last release. You can download executables for the latest nightly release [here](https://github.com/calda/SwiftFormat-nightly/releases/latest).\n\nCommit SHAs on `develop` are unstable since that branch is occasionally rebased, but artifact URLs and tags in [calda/SwiftFormat-nightly](https://github.com/calda/SwiftFormat-nightly) are stable references that can be used from other repos or tools.\n\nConfiguration\n-------------\n\nSwiftFormat's configuration is split between **rules** and **options**. Rules are functions in the SwiftFormat library that apply changes to the code. Options are settings that control the behavior of the rules. \n\n\nOptions\n-------\n\nThe options available in SwiftFormat can be displayed using the `--options` command-line argument. The default value for each option is indicated in the help text.\n\nRules are configured by adding `--[option_name] [value]` to your command-line arguments, or by creating a `.swiftformat` [config file](#config-file) and placing it in your project directory.\n\nA given option may affect multiple rules. Use `--rule-info [rule_name]` command for details about which options affect a given rule, or see the [Rules.md](https://github.com/nicklockwood/SwiftFormat/blob/main/Rules.md) file.\n\nYou can configure options for specific files or code ranges by using `swiftformat:options` directive in comments inside your Swift file. To temporarily set one or more options inside a source file, use:\n\n```swift\n// swiftformat:options --indent 2 --allman true\n```\n\nTo apply an options override only to a particular line, use the `:this`, `:next` or `:previous` modifiers:\n\n```swift\nlet indexUrl: URL // swiftformat:options:this --preserve-acronyms url \n\n// swiftformat:options:next --semicolons inline\ndoTheThing(); print(\"Did the thing\")\n```\n\n\nRules\n-----\n\nSwiftFormat includes over 50 rules, and new ones are added all the time. An up-to-date list can be found in [Rules.md](https://github.com/nicklockwood/SwiftFormat/blob/main/Rules.md) along with documentation for how they are used.\n\nThe list of available rules can be displayed within the command-line app using the `--rules` argument. Rules can be either enabled or disabled. Most are enabled by default. Disabled rules are marked with \"(disabled)\" when displayed using `--rules`.\n\nYou can use the `--rule-info [rule_name]` command to get information about a specific rule. Pass a comma-delimited list of rule names to get information for multiple rules at once, or use `--rule-info` with no argument for info on all rules.\n\nYou can disable rules individually using `--disable` followed by a list of one or more comma-delimited rule names, or enable opt-in rules using `--enable` followed by the rule names:\n\n```bash\n--disable redundantSelf,trailingClosures\n--enable isEmpty\n```\n\nIf you prefer, you can use multiple `--enable`/`--disable` arguments instead of using commas:\n\n```bash\n--disable indent\n--disable linebreaks\n--disable redundantSelf\n```\n\nAlternatively, you can use the line continuation character `\\` to wrap a single argument over multiple line:\n\n```bash         \n--disable          \\\n    indent,        \\\n    linebreaks,    \\\n    redundantSelf\n```\n\nTo avoid automatically opting-in to new rules when SwiftFormat is updated, you can disable all rules using:\n\n```bash\n--disable all\n```\n\nAnd then individually enable just the rules you want. Alternatively, use the`--rules` argument to *only* enable the rules you specify:\n\n```bash\n--rules indent,linebreaks\n```\n\nAs above, you may include multiple `--rules` arguments, or use the line continuation character `\\` to wrap the rules onto separate lines:\n\n```bash\n--rules redundantSelf\n--rules         \\\n    indent,     \\\n    linebreaks\n```\n\nTo see exactly which rules were applied to a given file, you can use the `--verbose` command-line option to force SwiftFormat to print a more detailed log as it applies the formatting. **NOTE:** running in verbose mode is slower than the default mode.\n\nYou can disable rules for specific files or code ranges by using `swiftformat:` directives in comments inside your Swift file. To temporarily disable one or more rules inside a source file, use:\n\n```swift\n// swiftformat:disable <rule1> [<rule2> [rule<3> ...]]\n```\n\nTo enable the rule(s) again, use:\n\n```swift\n// swiftformat:enable <rule1> [<rule2> [rule<3> ...]]\n```\n\nTo disable all rules use:\n\n```swift\n// swiftformat:disable all\n```\n\nAnd to enable them all again, use:\n\n```swift\n// swiftformat:enable all\n```\n\nTo temporarily prevent one or more rules being applied to just the next line, use:\n\n```swift\n// swiftformat:disable:next <rule1> [<rule2> [rule<3> ...]]\nlet foo = bar // rule(s) will be disabled for this line\nlet bar = baz // rule(s) will be re-enabled for this line\n```\n\nYou can also use `this` or `previous` to enable or disable rules for the current or previous line. There is no need to manually re-enable a rule after using the `next`, `this` or `previous` directives.\n\n**NOTE:** The `swiftformat:enable` directive only serves to counter a previous `swiftformat:disable` directive in the same file. It is not possible to use `swiftformat:enable` to enable a rule that was not already enabled when formatting started.\n\n\nSwift version\n-------------\n\nMost SwiftFormat rules are version-agnostic, but some are applicable only to newer Swift versions. These rules will be disabled automatically if the Swift version is not specified, so to make sure that the full functionality is available you should specify the version of Swift that is used by your project.\n\nYou can specify the Swift compiler version in one of two ways:\n\nYou can specify your project's Swift compiler version using the `--swift-version` command line argument. You can also add the `--swift-version` option to your `.swiftformat` file.\n\nAnother option is to add a `.swift-version` file to your project directory. This is a text file that should contain the minimum Swift version supported by your project, and is also supported by some other tools. Any `.swift-version` files always take precedence over the `--swift-version` argument.\n\nBoth the `.swift-version` file and the `--swift-version` option in a `.swiftformat` file are applied hierarchically; If you have submodules in your project that use a different Swift version, you can add separate swift version configurations for those directories.\n\nSwift language mode\n-------------------\n\nSwiftFormat also allows you to specify the Swift _language mode_ used by your project. This is distinct from the Swift compiler version. For example, you can use the Swift 6.0 compiler with either the Swift 5 language mode or the Swift 6 language mode. Some SwiftFormat rules will behave differently under different Swift language modes.\n\nYou can specify your project's Swift language mode using the `--language-mode` command line argument. You can also add the `--language-mode` option to your `.swiftformat` file.\n\nIf not specified, SwiftFormat uses the default language mode of the specified Swift compiler version. The default language mode in Swift 5.x and Swift 6.x is the Swift 5 language mode. If your project uses the Swift 6 language mode, you should specify `--language-mode 6`.\n\n\nConfig file\n-----------\n\nAlthough it is possible to configure SwiftFormat directly by using the command-line [options](#options) and [rules](#rules) detailed above, it is sometimes more convenient to create a configuration file, which can be added to your project and shared with other developers.\n\nA SwiftFormat configuration file consists of one or more command-line options, split onto separate lines, e.g:\n\n```\n--allman true\n--indent tab\n--disable elseOnSameLine,semicolons\n```\n\nWhile formatting, SwiftFormat will automatically check inside each subdirectory for the presence of a `.swiftformat` file and will apply any options that it finds there to the files in that directory.\n\nThis allows you to override certain rules or formatting options just for a particular directory of files. You can also specify excluded files relative to that directory using `--exclude`, which may be more convenient than specifying them at the top-level:\n\n```\n--exclude Pods,Generated\n```\n\nThe `--exclude` option takes a comma-delimited list of file or directory paths to exclude from formatting. Excluded paths are relative to the config file containing the `--exclude` command. The excluded paths can include wildcards, specified using Unix \"Glob\" syntax, as [documented below](#globs).\n\nConfig files named \".swiftformat\" will be processed automatically, however, you can select an additional configuration file to use for formatting using the `--config \"path/to/config/file\"` command-line argument. A configuration file selected using `--config` does not need to be named \".swiftformat\", and can be located outside of the project directory.\n\nThe config file format is designed to be edited by hand. You may include blank lines for readability, and can also add comments using a hash prefix (#), e.g.\n\n```\n# format options\n--allman true\n--indent tab # tabs FTW!\n\n# file options\n--exclude Pods\n\n# rules\n--disable elseOnSameLine,semicolons\n```\n\nYou can create multiple configuration sections within a single `.swiftformat` file to apply different formatting options to different parts of your project. Each section should specify a `--filter` glob pattern to determine which files the configuration applies to. Options in that section are used when formatting files that match `--filter` glob, in addition to the base options in the file.\n\n```\n--enable indent\n--indent 4\n\n[Tests]\n--filter **/Tests/**\n--enable noForceUnwrapInTests\n--enable noForceTryInTests\n--indent 2\n```\n\nIf you would prefer not to edit the configuration file by hand, you can use the [SwiftFormat for Xcode](#xcode-source-editor-extension) app to edit the configuration and export a configuration file. You can also use the swiftformat command-line-tool's `--infer-options` command to generate a config file from your existing project, like this:\n\n```bash\n$ cd /path/to/project\n$ swiftformat --infer-options . --output .swiftformat\n```\n\nGlobs\n-----\n\nWhen excluding files from formatting using the `--exclude` option, you may wish to make use of wildcard paths (aka \"Globs\") to match all files that match a particular naming convention without having to manually list them all.\n\nSwiftFormat's glob syntax is based on Ruby's implementation, which varies slightly from the Unix standard. The following patterns are supported:\n\n* `*` - A single star matches zero or more characters in a filename, but *not* a `/`.\n\n* `**` - A double star will match anything, including one or more `/`.\n\n* `?` - A question mark will match any single character except `/`.\n\n* `[abc]` - Matches any single character inside the brackets.\n\n* `[a-z]` - Matches a single character in the specified range in the brackets.\n\n* `{foo,bar}` - Matches any one of the comma-delimited strings inside the braces.\n\nExamples:\n\n* `foo.swift` - Matches the file \"foo.swift\" in the same directory as the config file.\n\n* `*.swift` - Matches any Swift file in the same directory as the config file.\n\n* `foo/bar.swift` - Matches the file \"bar.swift\" in the directory \"foo\".\n\n* `**/foo.swift` - Matches any file named \"foo.swift\" in the project.\n\n* `**/*.swift` - Matches any Swift file in the project.\n\n* `**/Generated` - Matches any folder called `Generated` in the project.\n\n* `**/*_generated.swift` - Matches any Swift file with the suffix \"_generated\" in the project.\n\n\nLinting\n-------\n\nSwiftFormat is primarily designed as a formatter rather than a linter, i.e. it is designed to fix your code rather than tell you what's wrong with it. However, sometimes it can be useful to verify that code has been formatted in a context where it is not desirable to actually change it.\n\nA typical example would be as part of a CI (Continuous Integration) process, where you may wish to have an automated script that checks committed code for style violations. While you can use a separate tool such as [SwiftLint](https://github.com/realm/SwiftLint) for this, it makes sense to be able to validate the formatting against the exact same rules as you are using to apply it.\n\nIn order to run SwiftFormat as a linter, you can use the `--lint` command-line option:\n\n```bash\n$ swiftformat --lint path/to/project\n```\n\nThis runs the same rules as format mode, and all the same configuration options apply, however, no files will be modified. Instead, SwiftFormat will format each file in memory and then compare the result against the input and report the lines that required changes.\n\nThe `--lint` option is similar to `--dry-run`, but `--lint` returns warnings for every line that required changes, and will return a nonzero error code (see [Error codes](#error-codes) below) if any changes are detected, which is useful if you want it to fail a build step on your CI server.\n\nIf you would prefer `--lint` not to fail your build, you can use the `--lenient` option to force SwiftFormat to return success in `--lint` mode even when formatting issues were detected.\n\n```bash\n$ swiftformat --lint --lenient path/to/project\n```\n\nBy default, `--lint` will only report lines that require formatting, but you can use the additional `--verbose` flag to display additional info about which files were checked, even if there were no changes needed.\n\nIf you would prefer not to see a warning for each and every formatting change, you can use the `--quiet` flag to suppress all output except errors.\n\nSometimes you may wish to autoformat some rules, but only lint others. To do that, use the `--lintonly` option in your config file to specify rules that should only be applied in `--lint` mode:\n\n```\n--rules braces,indent\n--lint-only trailingClosures,unusedArguments\n```\n\n\nError codes\n-----------\n\nThe swiftformat command-line tool will always exit with one of the following codes:\n\n* 0 - Success. This code will be returned in the event of a successful formatting run or if `--lint` detects no violations.\n* 1 - Lint failure. This code will be returned when running in `--lint` mode, or when autocorrecting in `--strict` mode, if the input requires formatting.\n* 70 - Program error. This code will be returned if there is a problem with the input or configuration arguments.\n\n\nCache\n------\n\nSwiftFormat uses a cache file to avoid reformatting files that haven't changed. For a large project, this can significantly reduce processing time.\n\nBy default, the cache is stored in `~/Library/Caches/com.charcoaldesign.swiftformat` on macOS, or `/tmp/com.charcoaldesign.swiftformat` on Linux. Use the command-line option `--cache ignore` to ignore the cached version and re-apply formatting to all files. Alternatively, you can use `--cache clear` to delete the cache (or you can just manually delete the cache file).\n\nThe cache is shared between all projects. The file is fairly small, as it only stores the path and size for each file, not the contents. If you do start experiencing slowdown due to the cache growing too large, you might want to consider using a separate cache file for each project.\n\nYou can specify a custom cache file location by passing a path as the `--cache` option value. For example, you might want to store the cache file inside your project directory. It is fine to check in the cache file if you want to share it between different users of your project, as the paths stored in the cache are relative to the location of the formatted files.\n\n\nFile headers\n-------------\n\nSwiftFormat can be configured to strip or replace the header comments in every file with a template. The \"header comment\" is defined as a comment block that begins on the first nonblank line in the file, and is followed by at least one blank line. This may consist of a single comment body, or multiple comments on consecutive lines:\n\n```swift\n// This is a header comment\n```\n\n```swift\n// This is a regular comment\nfunc foo(bar: Int) -> Void { ... }\n```\n\nThe header template is a string that you provide using the `--header` command-line option. Passing a value of `ignore` (the default) will leave the header comments unmodified. Passing `strip` or an empty string `\"\"` will remove them. If you wish to provide a custom header template, the format is as follows:\n\nFor a single-line template: `--header \"Copyright (c) 2017 Foobar Industries\"`\n\nFor a multiline comment, mark linebreaks with `\\n`: `--header \"First line\\nSecond line\"`\n\nYou can optionally include Swift comment markup in the template if you wish: `--header \"/*--- Header comment ---*/\"`\n\nIf you do not include comment markup, each line in the template will be prepended with `//` and a single space.\n\nIt is common practice to include the file name, creation date and/or the current year in a comment header copyright notice. To do that, you can use the following placeholders:\n\n* `{file}` - the name of the file\n* `{year}` - the current year\n* `{created}` - the date on which the file was created\n* `{created.year}` - the year in which the file was created\n* `{author.name}` - the name of the user who first committed the file\n* `{author.email}` - the email of the user who first committed the file \n\nFor example, a header template of:\n\n```bash\n--header \"{file}\\nCopyright (c) {year} Foobar Industries\\nCreated by John Smith on {created}.\"\n```\n\nWill be formatted as:\n\n```swift\n// SomeFile.swift\n// Copyright (c) 2019 Foobar Industries\n// Created by John Smith on 01/02/2016.\n```\n\n**NOTE:** the `{year}` value and `{created}` date format are determined from the current locale and timezone of the machine running the script. `{author.name}` and `{author.email}` requires the project to be version controlled by git.\n\n\nMarkdown formatting\n-------------------\n\nSwiftFormat can format Swift code blocks inside Markdown files (`.md`). This is useful for keeping code examples in documentation, README files, and other markdown content properly formatted.\n\n````diff\n  ### Sample README\n  \n  This is a nice project with lots of cool APIs to know about, including:\n  \n  ```swift\n  func foo(\n- bar: Bar,\n- baaz: Baaz\n+     bar: Bar,\n+     baaz: Baaz\n  ) -> Foo { ... }\n  ```\n````\n\nTo format Swift code blocks in markdown files, use the `--markdown-files` option with either `strict` or `lenient`:\n\n```bash\n$ swiftformat . --markdown-files strict\n$ swiftformat . --markdown-files lenient\n```\n\nOr add it to your `.swiftformat` config file:\n\n```\n--markdown-files strict\n```\n\n**Formatting modes:**\n\nSwiftFormat supports two modes for handling markdown files:\n\n- `lenient` (default): Ignores parsing errors in code blocks and continues formatting\n- `strict`: Fails if any code blocks contain parsing errors\n\nSwiftFormat's tokenizer is more permissive than the Swift compiler and typically only emits errors when encountering unbalanced scope tokens like `(` or `{`.\n\n**Code block options:**\n\nYou can specify options for options for individual code blocks by adding them after the opening delimiter. For example, you can use `no-format` to prevent a code block from being parsed or formatted:\n\n````md\n```swift no-format\nfunc example()\n{\n    doSomething()\n}\n```\n````\n\nYou can also specify SwiftFormat command line options to configure the behavior of individual rules:\n\n````md\n```swift --indent 2\nfunc example() {\n  doSomething()\n}\n```\n\n```swift --disable redundantSelf\nfunc example() {\n    self.doSomething()\n}\n```\n````\n\nFAQ\n-----\n\n*Q. How is this different from SwiftLint?*\n\n> A. SwiftLint is primarily designed to find and report code smells and style violations in your code. SwiftFormat is designed to fix them. While SwiftLint can autocorrect some issues, and SwiftFormat has some support for [linting](#linting), their primary functions are different.\n\n\n*Q. Can SwiftFormat and SwiftLint be used together?*\n\n> A. Absolutely! The style rules encouraged by both tools are quite similar, and SwiftFormat even fixes some style violations that SwiftLint warns about but can't currently autocorrect.\n\n\n*Q. What platforms does SwiftFormat support?*\n\n> A. SwiftFormat works on macOS 10.13 (High Sierra) and above, and also runs on Ubuntu Linux and Windows.\n\n\n*Q. What versions of Swift are supported?*\n\n> A. The SwiftFormat framework and command-line tool can be compiled using Swift 5.3 and above, and can format programs written in Swift 4.x or 5. Swift 3.x is no longer actively supported. If you are still using Swift 3.x or earlier and find that SwiftFormat breaks your code, the best solution is probably to revert to an earlier SwiftFormat release, or enable only a small subset of rules. Use the `--swift-version` argument to enable additional rules specific to later Swift versions.\n\n\n*Q. SwiftFormat made changes I didn't want it to. How can I find out which rules to disable?*\n\n> A. If you run SwiftFormat using the `--verbose` option, it will tell you which rules were applied to each file. You can then selectively disable certain rules using the `--disable` argument (see below).\n\n\n*Q. People on my team have different SwiftFormat versions installed. How can we ensure consistent formatting?\n\n> A. You can specify a `--min-version` argument in your project's .swiftformat` file to fail the build if developers attempt to use an older SwiftFormat version.\n\n\n*Q. How can I modify the formatting rules?*\n\n> A. Many configuration options are exposed in the command-line interface or `.swiftformat` configuration file. You can either set these manually, or use the `--infer-options` argument to automatically generate the configuration from your existing project.\n\n> If there is a rule that you don't like, and which cannot be configured to your liking via the command-line options, you can disable one or more rules by using the `--disable` argument, followed by the name of the rules, separated by commas. You can display a list of all supported rules using the `--rules` argument, and their behaviors are documented above this section in the README.\n\n> If you are using the Xcode source editor extension, rules and options can be configured using the [SwiftFormat for Xcode](#xcode-source-editor-extension) host application. Unfortunately, due to limitation of the Extensions API, there is no way to configure these on a per-project basis.\n\n> If the options you want aren't exposed, and disabling the rule doesn't solve the problem, the rules are implemented in the file `Rules.swift`, so you can modify them and build a new version of the command-line tool. If you think your changes might be generally useful, make a pull request.\n\n\nQ. I don't want to be surprised by new rules added when I upgrade SwiftFormat. How can I prevent this?\n\n> A. You can use the `--rules` argument to specify an exclusive list of rules to run. If new rules are added, they won't be enabled if you have specified a `--rules` list in your SwiftFormat configuration.\n\n\n*Q. Why can't I set the indent width or choose between tabs/spaces in the [SwiftFormat for Xcode](#xcode-source-editor-extension) options?*\n\n> Indent width and tabs/spaces can be configured in Xcode on a per project-basis. You'll find the option under \"Text Settings\" in the Files inspector of the right-hand sidebar.\n\n\n*Q. After applying SwiftFormat, my code won't compile. Is that a bug?*\n\n> A. SwiftFormat should ideally never break your code. Check the [known issues](#known-issues), and if it's not already listed there, or the suggested workaround doesn't solve your problem, please [open an issue on GitHub](https://github.com/nicklockwood/SwiftFormat/issues).\n\n\n*Q. Can I use SwiftFormat to lint my code without changing it?*\n\n> A. Yes, see the [linting](#linting) section above for details.\n\n\n*Q. Can I use the `SwiftFormat.framework` inside another app?*\n\n> A. Yes, the SwiftFormat framework can be included in an app or test target, and used for many kinds of parsing and processing of Swift source code besides formatting. The SwiftFormat framework is available as a [CocoaPod](https://cocoapods.org/pods/SwiftFormat) for easy integration.\n\n*Q. How to create own rule?*\n\n> A. 1) Open `SwiftFormat.xcodeproj`; 2) Add a rule in `Sources/Rules/..`; 3) Add a test in `Tests/Rules/..`; 4) Add an example in `Sources/Examples.swift`; 5) Run all tests.\n\n*Q. How do I run and debug the command line tool in Xcode while developing a new rule?*\n\n> A. You can run the `swiftformat` command line tool via the `Swift Format (Command Line Tool)` scheme, and you can pass in arguments like `/path/to/my/code --config /path/to/my/config` as the `Arguments Passed On Launch` in Xcode's scheme editor. More instructions are available [here](https://github.com/nicklockwood/SwiftFormat/pull/1804#issuecomment-2263079432).\n\nKnown issues\n---------------\n\n* When using the Xcode Source Editor Extension, the SwiftFormat menu sometimes disappears from Xcode. If this happens, try moving or renaming Xcode temporarily and then changing it back. Failing that, the suggestions in [this thread](https://github.com/nicklockwood/SwiftFormat/issues/494) may help.\n\n* The `enumNamespaces` rule replaces classes that have only static members with an `enum`. If the class is subclassed, or if there is code that depends on the class exposing certain runtime behaviors, this may break the program. To solve this you can either fix it on a per-case basis by adding a `// swiftformat:disable:next enumNamespaces` comment directive above the class declaration, or you can add `--enum-namespaces structs-only` to prevent the rule being applied to classes, or you can just disable the `enumNamespaces` rule completely.\n\n* The `redundantVoidReturnType` rule can inadvertently alter the type signature for closures, for example in cases where the closure calls a `@discardableResult` function. To solve this you can either fix it on a per-case basis by adding a `// swiftformat:disable:next redundantVoidReturnType` comment directive to disable the rule for a specific call site, or you can add `--closure-void preserve` to your [configuration](#configuration) to disable the rule completely for closures (regular functions or methods aren't affected).\n\n* The `redundantType` rule can introduce ambiguous code in certain cases when using the default mode of `--redundant-type inferred`. This can be worked around by by using `--redundant-type explicit`, or by manually removing the redundant type reference on the affected line, or by using the `// swiftformat:disable:next redundantType` comment directive to disable the rule at the call site (or just disable the `redundantType` rule completely).\n\n* If a type initializer or factory method returns an implicitly unwrapped optional value then the `redundantType` rule may remove the explicit type in a situation where it's actually required. To work around this you can either use `--redundant-type explicit`, or use the `// swiftformat:disable:next redundantType` comment directive to disable the rule at the call site (or just disable the `redundantType` rule completely).\n\n* When using the `initCoderUnavailable` rule, if an `init` that is marked as unavailable is overridden elsewhere in the program then it will cause a compilation error. The recommended workaround is to remove the override (which shouldn't affect the program behavior if the init was really unused) or use the `// swiftformat:disable:next initCoderUnavailable` comment directive to disable the rule for the overridden init (or just disable the `initCoderUnavailable` rule completely).\n\n* When using the `extensionAccessControl` rule with the `--extension-acl on-extension` option, if you have public methods defined on an internal type defined in another file, the resultant public extension will no longer compile. The recommended solution is to manually remove the `public` modifier (this won't change the program behavior) or disable the `extensionAccessControl` rule.\n\n* When using the `preferKeyPath` rule, conversion of `compactMap { $0.foo }` to `compactMap(\\.foo)` or `flatMap { $0.foo }` to `flatMap(\\.foo)` will result in code that fails to compile if `foo` is not an `Optional` property. This is due to a difference in the way that Swift handles type inference for closures vs keyPaths, as discussed [here](https://bugs.swift.org/browse/SR-13347). The recommended workaround is to replace `compactMap()` or `flatMap()` with `map()` in these cases, which will not change the behavior of the code.\n\n* When using the `--self remove` option, the `redundantSelf` rule will remove references to `self` in autoclosure arguments, which may change the meaning of the code, or cause it not to compile. To work around this issue, use the `--self-required` option to provide a comma-delimited list of methods to be excluded from the rule. The `expect()` function from the popular [Nimble](https://github.com/Quick/Nimble) unit testing framework is already excluded by default. If you are using the `--self insert` option then this is not an issue.\n\n* If you assign `SomeClass.self` to a variable and then instantiate an instance of the class using that variable, Swift requires that you use an explicit `.init()`, however, the `redundantInit` rule is not currently capable of detecting this situation in all cases, and may remove the `.init`. To work around this issue, use the `// swiftformat:disable:next redundantInit` comment directive to disable the rule for any affected lines of code (or just disable the `redundantInit` rule completely).\n\n* The `--self insert` option can only recognize locally declared member variables, not ones inherited from superclasses or extensions in other files, so it cannot insert missing `self` references for those. Note that the reverse is not true: `--self remove` should remove *all* redundant `self` references.\n\n* The `trailingClosures` rule can generate ambiguous code if a function has multiple optional closure arguments, or if multiple functions have signatures differing only by the name of the closure argument. For this reason, the rule is limited to anonymous closure arguments by default. You can use the `--trailing-closures` and `--never-trailing` arguments to explicitly opt in or out of trailing closure support for specific functions.\n\n* The `isEmpty` rule will convert `count == 0` to `isEmpty` even for types that do not have an `isEmpty` method, such as `NSArray`/`NSDictionary`/etc. Use of Foundation collections in Swift code is pretty rare, but just in case, the rule is disabled by default.\n\n* The `preferForLoop` rule will convert `foo.forEach` to `for item in foo` even for types that do not conform to the `Sequence` protocol and cannot be used with a `for ... in` loop. There are no such types built in, but custom types may have this issue.\n\n* If a file begins with a comment, the `stripHeaders` rule will remove it if it is followed by a blank line. To avoid this, make sure that the first comment is directly followed by a line of code.\n\n* When running a version of SwiftFormat built using Xcode 10.2 on macOS 10.14.3 or earlier, you may experience a crash with the error \"dyld: Library not loaded: @rpath/libswiftCore.dylib\". To fix this, you need to install the [Swift 5 Runtime Support for Command Line Tools](https://support.apple.com/kb/DL1998). These tools are included by default in macOS 10.14.4 and later.\n\n* If you have a generic typealias that defines a closure (e.g. `typealias ResultCompletion<T> = (Result<T, Error>) -> Void`) and use this closure as an argument in a generic function (e.g. `func handle<T: Decodable>(_ completion: ResultCompletion<T>)`), the `opaqueGenericParameters` rule may update the function definition to use `some` syntax (e.g. `func handle(_ completion: ResultCompletion<some Decodable>)`). `some` syntax is not permitted in closure parameters, so this will no longer compile. Workarounds include spelling out the closure explicitly in the generic function (instead of using a `typealias`) or disabling the `opaqueGenericParameters` rule (e.g. with `// swiftformat:disable:next opaqueGenericParameters`).\n\n* If compiling for macOS with Xcode 14.0 and configuring SwiftFormat with `--swift-version 5.7`, the `genericExtensions` rule may cause a build failure by updating extensions of the format `extension Collection where Element == Foo` to `extension Collection<Foo>`. This fails to compile for macOS in Xcode 14.0, because the macOS SDK in that version of Xcode [does not include](https://forums.swift.org/t/xcode-14-rc-cannot-specialize-protocol-type/60171) the Swift 5.7 standard library. Workarounds include using `--swift-version 5.6` instead, updating to Xcode 14.1+, or disabling the `genericExtensions` rule (e.g. with `// swiftformat:disable:next genericExtensions`).\n\n* The `propertyTypes` rule can cause a build failure in cases where there are multiple static overloads with the same name but different return types. As a workaround you can rename the overloads to no longer conflict, or exclude the property name with `--preserve-symbols propertyName,otherPropertyName,etc`.\n\n* The `propertyTypes` rule can cause a build failure in cases where the property's type is a protocol / existential like `let shapeStyle: ShapeStyle = .myShapeStyle`, and the value used on the right-hand side is defined in an extension like `extension ShapeStyle where Self == MyShapeStyle { static var myShapeStyle: MyShapeStyle { ... } }`. As a workaround you can use the existential `any` syntax (`let shapeStyle: any ShapeStyle = .myShapeStyle`), which the rule will preserve as-is, or exclude the type name and/or property name with `--preserve-symbols ShapeStyle,myShapeStyle,etc`.\n\n* The `propertyTypes` rule can cause a build failure in cases like `let foo = Foo.bar` where the value is a static member that doesn't return the same time. For example, `let foo: Foo = .bar` would be invalid if the `bar` property was defined as `static var bar: Bar`. As a workaround you can write the name of the type explicitly, like `let foo: Bar = Foo.bar`, or exclude the type name and/or property name with `--preserve-symbols Bar,bar,etc`.\n\n\nTip Jar\n-----------\n\nSwiftFormat is not a commercially-funded product, it's a labor of love given freely to the community. If you find it useful, please consider making a donation.\n\n[![Donate via PayPal](https://www.paypalobjects.com/en_GB/i/btn/btn_donate_LG.gif)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=9ZGWNK5FEZFF6&source=url)\n\n\nCredits\n------------\n\n* [Cal Stephens](https://github.com/calda) - Numerous new formatting rules, options and bug fixes\n* [Tony Arnold](https://github.com/tonyarnold) - SwiftFormat for Xcode\n* [Vincent Bernier](https://github.com/vinceburn) - SwiftFormat for Xcode settings UI\n* [Vikram Kriplaney](https://github.com/markiv) - SwiftFormat for Xcode icon and search feature\n* [Hyperphonic](https://github.com/hyperphonic0) - Xcode 12 compatibility for SwiftFormat\n* [Maxime Marinel](https://github.com/bourvill) - Git pre-commit hook script\n* [Romain Pouclet](https://github.com/palleas) - Homebrew formula\n* [Aerobounce](https://github.com/aerobounce) - Homebrew cask and Sublime Text plugin\n* [Facundo Menzella](https://github.com/facumenzella) - Several new formatting rules and options\n* [Ali Akhtarzada](https://github.com/aliak00) - Several path-related CLI enhancements\n* [Yonas Kolb](https://github.com/yonaskolb) - Swift Package Manager integration\n* [Wolfgang Lutz](https://github.com/Lutzifer) - AppleScript integration instructions\n* [BalÃ¡zs KilvÃ¡dy](https://github.com/balitm) - Xcode lint warning integration\n* [Anthony Miller](https://github.com/AnthonyMDev) - Improvements to wrap/indent logic\n* [Shingo Takagi](https://github.com/zizi4n5) - Several brace-related bug fixes\n* [Benedek Kozma](https://github.com/cyberbeni) - Lint-only rules option\n* [Juri Pakaste](https://github.com/juri) - Filelist feature\n* [Jim Puls](https://github.com/puls) - Big Sur icon update\n* [Daniele Formichelli](https://github.com/danyf90) - JSON reporter\n* [Jonas Boberg](https://github.com/bobergj) - Github actions log reporter\n* [Mahdi Bchatnia](https://github.com/inket) - Linux build workflow\n* [Saleem Abdulrasool](https://github.com/compnerd) - Windows build workflow\n* [Arthur Semenyutin](https://github.com/vox-humana) - Docker image\n* [Marco Eidinger](https://github.com/MarcoEidinger) - Swift Package Manager plugin\n* [Hampus TaÌŠgerud](https://github.com/hampustagerud) - Git integration for fileHeader rule\n* [Nick Lockwood](https://github.com/nicklockwood) - Everything else\n\n([Full list of contributors](https://github.com/nicklockwood/SwiftFormat/graphs/contributors))\n",
      "stars_today": 1
    },
    {
      "id": 27358084,
      "name": "proxysql",
      "full_name": "sysown/proxysql",
      "description": "High-performance MySQL proxy with a GPL license.",
      "html_url": "https://github.com/sysown/proxysql",
      "stars": 6614,
      "forks": 1059,
      "language": "C++",
      "topics": [],
      "created_at": "2014-12-01T01:58:26Z",
      "updated_at": "2026-02-06T22:06:25Z",
      "pushed_at": "2026-02-06T16:29:40Z",
      "open_issues": 1099,
      "owner": {
        "login": "sysown",
        "avatar_url": "https://avatars.githubusercontent.com/u/10014617?v=4"
      },
      "readme": "[![CI-selftests](https://github.com/sysown/proxysql/actions/workflows/CI-selftests.yml/badge.svg)](https://github.com/sysown/proxysql/actions/workflows/CI-selftests.yml)\n[![CI-repltests](https://github.com/sysown/proxysql/actions/workflows/CI-repltests.yml/badge.svg)](https://github.com/sysown/proxysql/actions/workflows/CI-repltests.yml)\n[![CodeQL](https://github.com/sysown/proxysql/actions/workflows/CI-codeql.yml/badge.svg)](https://github.com/sysown/proxysql/actions/workflows/CI-codeql.yml)\n[![Package-Build](https://github.com/sysown/proxysql/actions/workflows/CI-package-build.yml/badge.svg)](https://github.com/sysown/proxysql/actions/workflows/-CI-package-build.yml)\n\n<a><img src=\"https://i0.wp.com/proxysql.com/wp-content/uploads/2020/04/ProxySQL-Colour-Logo.png?fit=800%2C278&ssl=1\" alt=\"ProxySQL\"></a>\n\nTable of Contents\n=================\n\n- [Introduction](#introduction)\n- [Useful links](#useful-links)\n- [Getting started](#getting-started)\n  - [Installation](#installation)\n    - [Ubuntu / Debian](#ubuntu--debian)\n    - [Red Hat / CentOS](#red-hat--centos)\n    - [Amazon Linux](#amazon-linux)\n    - [Almalinux](#almalinux)\n    - [OpenSUSE](#opensuse)\n    - [FreeBSD](#freebsd)\n  - [Service management](#service-management)\n    - [Starting ProxySQL](#starting-proxysql)\n    - [Stopping ProxySQL](#stopping-proxysql)\n    - [Restarting ProxySQL](#restarting-proxysql)\n    - [Reinitializing ProxySQL](#reinitializing-proxysql-from-the-config-file-after-first-startup-the-db-file-is-used-instead-of-the-config-file)\n  - [Upgrades](#upgrades)\n  - [How to check the ProxySQL version](#how-to-check-the-proxysql-version)\n  - [Configuring ProxySQL via the admin interface](#configuring-proxysql-via-the-admin-interface)\n    - [Configuring ProxySQL through the admin interface](#configuring-proxysql-through-the-admin-interface)\n    - [Configuring ProxySQL through the config file](#configuring-proxysql-through-the-config-file)\n\nIntroduction<a name=\"introduction\"></a>\n============\n\nProxySQL is a high-performance, high-availability, protocol-aware proxy for MySQL and its forks (such as Percona Server and MariaDB), as well as PostgreSQL.\nAll the while getting the unlimited freedom that comes with a GPL license.\n\nIts development is driven by the lack of open source proxies that provide high performance.\n\nUseful links<a name=\"useful-links\"></a>\t\n===============\t\n\n- [Official website](https://www.proxysql.com/)\t\n- [Subscriptions and Support](https://proxysql.com/services/support/) \n- [Documentation](https://www.proxysql.com/Documentation)\n- [DockerHub Repository](https://hub.docker.com/r/proxysql/proxysql)\n- [Benchmarks and blog posts](http://www.proxysql.blogspot.com/)\t\n- [Forum](https://groups.google.com/forum/#!forum/proxysql/)\n- [Facebook](https://www.facebook.com/proxysql)\t\n- [Linkedin](https://www.linkedin.com/groups/13581070/)\t\n- [Twitter](https://twitter.com/proxysql)\n\nGetting started<a name=\"getting-started\"></a>\n===============\n\n### Installation\nReleased packages can be found here: https://github.com/sysown/proxysql/releases\n\nJust download a package and use your systems package manager to install it:\n```bash\nwget https://github.com/sysown/proxysql/releases/download/v3.0.4/proxysql_3.0.4-ubuntu24_amd64.deb\ndpkg -i proxysql_3.0.4-ubuntu24_amd64.deb\n```\n\nAlternatively you can also use the available repositories:\n\n#### Ubuntu / Debian:\n\nAdding repository:\n```bash\napt-get update && apt-get install -y --no-install-recommends lsb-release wget apt-transport-https ca-certificates\nwget -nv -O /etc/apt/trusted.gpg.d/proxysql-3.0.x-keyring.gpg 'https://repo.proxysql.com/ProxySQL/proxysql-3.0.x/repo_pub_key.gpg'\necho \"deb https://repo.proxysql.com/ProxySQL/proxysql-3.0.x/$(lsb_release -sc)/ ./\" | tee /etc/apt/sources.list.d/proxysql.list\n```\n\nInstalling:\n```bash\napt-get update\napt-get install proxysql OR apt-get install proxysql=version\n```\n\n#### Red Hat / CentOS:\n\nAdding repository:\n```bash\ncat > /etc/yum.repos.d/proxysql.repo << EOF\n[proxysql]\nname=ProxySQL YUM repository\nbaseurl=https://repo.proxysql.com/ProxySQL/proxysql-3.0.x/centos/\\$releasever\ngpgcheck=1\ngpgkey=https://repo.proxysql.com/ProxySQL/proxysql-3.0.x/repo_pub_key\nEOF\n```\n\nInstalling:\n```bash\nyum install proxysql OR yum install proxysql-version\n```\n\n#### Amazon Linux:\n\nAdding repository:\n```bash\ncat > /etc/yum.repos.d/proxysql.repo << EOF\n[proxysql]\nname=ProxySQL YUM repository\nbaseurl=https://repo.proxysql.com/ProxySQL/proxysql-3.0.x/centos/8\ngpgcheck=1\ngpgkey=https://repo.proxysql.com/ProxySQL/proxysql-3.0.x/repo_pub_key\nEOF\n```\n\nInstalling:\n```bash\nyum install proxysql OR yum install proxysql-version\n```\n\n#### Almalinux:\n\nAdding repository:\n```bash\ncat > /etc/yum.repos.d/proxysql.repo << EOF\n[proxysql]\nname=ProxySQL YUM repository\nbaseurl=https://repo.proxysql.com/ProxySQL/proxysql-3.0.x/almalinux/\\$releasever\ngpgcheck=1\ngpgkey=https://repo.proxysql.com/ProxySQL/proxysql-3.0.x/repo_pub_key\nEOF\n```\n\nInstalling:\n```bash\nyum install proxysql OR yum install proxysql-version\n```\n\n#### OpenSUSE:\n\nAdding repository:\n```bash\ncat > /etc/zypp/repos.d/proxysql.repo << EOF\n[proxysql]\nname=ProxySQL Zypper repository\nenabled=1\nautorefresh=0\nbaseurl=https://repo.proxysql.com/ProxySQL/proxysql-3.0.x/opensuse/\\$releasever_major\ngpgcheck=1\nEOF\n```\nor\n```bash\nzypper addrepo -g -n 'ProxySQL Zypper repository' 'https://repo.proxysql.com/ProxySQL/proxysql-3.0.x/opensuse/$releasever_major' proxysql\n```\n\nInstalling:\n```bash\nyum install proxysql OR yum install proxysql-version\n```\n\n#### FreeBSD:\n\nInstalling (via pkg):\n```bash\npkg install proxysql\n```\n\nInstalling (via ports):\n```bash\ncd /usr/ports/databases/proxysql/ && make install clean\n```\n\n### Service management\nOnce the software is installed, you can use the `service` command to control the process:  \n\n#### Starting ProxySQL:\n```bash\nservice proxysql start\n```\n#### Stopping ProxySQL:\n```bash\nservice proxysql stop\n```\n\nOr alternatively via the Admin interface (MySQL admin example):\n```\n$ mysql -u admin -padmin -h 127.0.0.1 -P6032 --prompt='Admin> '\nWarning: Using a password on the command line interface can be insecure.\nWelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 4\nServer version: 5.5.30 (ProxySQL Admin Module)\n\nCopyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved.\n\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nAdmin> proxysql stop\n```\n\nFor PostgreSQL admin interface the same Admin commands apply and the admin port defaults to 6132. \nYou can connect using the psql client as follows:\n```\n$ export PGPASSWORD=admin\n$ psql -U admin -h 127.0.0.1 -p6132\npsql (17.4 (Ubuntu 17.4-1.pgdg22.04+2), server 16.1)\nSSL connection (protocol: TLSv1.3, cipher: TLS_AES_256_GCM_SHA384, compression: off, ALPN: none)\nType \"help\" for help.\n\nadmin=# proxysql stop\n```\n\n_(The examples above show the Admin interface workflow - the Admin SQL commands are the same for both MySQL and PostgreSQL modes.)_\n\n#### Restarting ProxySQL:\n```bash\nservice proxysql restart\n```\n\nOr alternatively via the Admin interface (MySQL example):\n```\n$ mysql -u admin -padmin -h 127.0.0.1 -P6032 --prompt='Admin> '\nWarning: Using a password on the command line interface can be insecure.\nWelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 4\nServer version: 5.5.30 (ProxySQL Admin Module)\n\nCopyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved.\n\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nAdmin> proxysql restart\n```\n\nOr via the PostgreSQL admin port:\n```\n$ export PGPASSWORD=admin\n$ psql -U admin -h 127.0.0.1 -p6132\npsql (17.4 (Ubuntu 17.4-1.pgdg22.04+2), server 16.1)\nSSL connection (protocol: TLSv1.3, cipher: TLS_AES_256_GCM_SHA384, compression: off, ALPN: none)\nType \"help\" for help.\n\nadmin=# proxysql restart\n```\n\n#### Reinitializing ProxySQL from the config file (after first startup the DB file is used instead of the config file):\n```bash\n# If you are using the init script run:\n/etc/init.d/proxysql initial\n# or\nservice proxysql initial\n \n# If you are using the systemd unit file run:\nsystemctl start proxysql-initial\n# or\nservice proxysql-initial start\n```\n\n### Upgrades\nJust install the new package and restart ProxySQL:\n```bash\nwget https://github.com/sysown/proxysql/releases/download/v3.0.4/proxysql_3.0.4-ubuntu24_amd64.deb\ndpkg -i proxysql_3.0.4-ubuntu24_amd64.deb\nservice proxysql restart\n```\n\n### How to check the ProxySQL version\n```bash\n$ proxysql --version\n```\n```bash\nProxySQL version 3.0.4-162-gfaa64a5, codename Truls\n```\nA debug version has `_DEBUG` in its version string.\nIt is slower than non-debug version, but easier to debug in case of failures.\n```bash\n$ proxysql --version\n```\n```bash\nProxySQL version 3.0.4-162-gfaa64a5_DEBUG, codename Truls\n```\n\n### Configuring ProxySQL via the `admin interface`\n\nFirst of all, bear in mind that the best way to configure ProxySQL is through its admin interface. This lends itself to online configuration (without having to restart the proxy) via SQL queries to its admin database. It's an effective way to configure it both manually and in an automated fashion.\n\nAs a secondary way to configure it, we have the configuration file. \n\n#### Configuring ProxySQL through the admin interface\n\nTo log into the admin interface for MySQL (with the default credentials) use a mysql client and connect using the following `admin` credentials locally on port (6032):\n```bash\n$ mysql -u admin -padmin -h 127.0.0.1 -P6032 --prompt='Admin> '\nWarning: Using a password on the command line interface can be insecure.\nWelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 4\nServer version: 5.5.30 (ProxySQL Admin Module)\n\nCopyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved.\n\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nAdmin>\n```\nnote: If your MySQL client version is version 8.04 or higher add `--default-auth=mysql_native_password` to the above command to connect to the admin interface.\n\nTo log into the admin interface for PostgreSQL use the psql client and connect using admin on port 6132 (the Admin SQL commands are the same):\n```bash\n$ export PGPASSWORD=admin\n$ psql -U admin -h 127.0.0.1 -p6132\npsql (17.4 (Ubuntu 17.4-1.pgdg22.04+2), server 16.1)\nSSL connection (protocol: TLSv1.3, cipher: TLS_AES_256_GCM_SHA384, compression: off, ALPN: none)\nType \"help\" for help.\n\nadmin=#\n```\nOnce connected to the admin interface, you will have a list of databases and tables at your disposal that can be queried using the SQL language:\n```mysql\nAdmin> SHOW DATABASES;\n+-----+---------+-------------------------------+\n| seq | name    | file                          |\n+-----+---------+-------------------------------+\n| 0   | main    |                               |\n| 2   | disk    | /var/lib/proxysql/proxysql.db |\n| 3   | stats   |                               |\n| 4   | monitor |                               |\n+-----+---------+-------------------------------+\n4 rows in set (0.00 sec)\n```\nThis will allow you to control the list of the backend servers, how traffic is routed to them, and other important settings (such as caching, access control, etc). Once you've made modifications to the in-memory data structure, you must load the new configuration to the runtime, or persist the new settings to disk (so that they are still there after a restart of the proxy). A detailed tutorial on how to configure ProxySQL through the Admin interface is available [here](https://github.com/sysown/proxysql/wiki/ProxySQL-Configuration).\n\n#### Configuring ProxySQL through the config file\n\nEven though the config file should only be regarded as a secondary way to configure the proxy, we must not discard its value as a valid way to bootstrap a fresh ProxySQL install.\n\nLet's quickly go over the main sections of the configuration file (this overview serves as a very high level overview of ProxySQL configuration).\n\nTop-level sections:\n* `admin_variables`: contains global variables that control the functionality of the admin interface.\n* `mysql_variables`: contains global variables that control the functionality for handling the incoming MySQL traffic.\n* `mysql_servers`: contains rows for the `mysql_servers` table from the admin interface. Basically, these define the backend servers towards which the incoming MySQL traffic is routed. Rows are encoded as per the `.cfg` file format, here is an example:\n\t\n\t```bash\n\tmysql_servers =\n\t(\n\t\t{\n\t\t\taddress=\"127.0.0.1\"\n\t\t\tport=3306\n\t\t\thostgroup=0\n\t\t\tmax_connections=200\n\t\t}\n\t)\n\t```\n* `mysql_users`: contains rows for the `mysql_users` table from the admin interface. Basically, these define the users which can connect to the proxy, and the users with which the proxy can connect to the backend servers. Rows are encoded as per the `.cfg` file format, here is an example:\n\t\n\t```bash\n\tmysql_users:\n\t(\n\t\t{\n\t\t\tusername=\"root\"\n\t\t\tpassword=\"root\"\n\t\t\tdefault_hostgroup=0\n\t\t\tmax_connections=1000\n\t\t\tdefault_schema=\"information_schema\"\n\t\t\tactive=1\n\t\t}\n\t)\n\t```\n* `mysql_query_rules`: contains rows for the `mysql_query_rules` table from the admin interface. Basically, these define the rules used to classify and route the incoming MySQL traffic, according to various criteria (patterns matched, user used to run the query, etc.). Rows are encoded as per the `.cfg` file format, here is an example (Note: the example is a very generic query routing rule and it is recommended to create specific rules for queries rather than using a generic rule such as this):\n\t\n\t```bash\n\tmysql_query_rules:\n\t(\n\t\t{\n\t\t\trule_id=1\n\t\t\tactive=1\n\t\t\tmatch_pattern=\"^SELECT .* FOR UPDATE$\"\n\t\t\tdestination_hostgroup=0\n\t\t\tapply=1\n\t\t},\n\t\t{\n\t\t\trule_id=2\n\t\t\tactive=1\n\t\t\tmatch_pattern=\"^SELECT\"\n\t\t\tdestination_hostgroup=1\n\t\t\tapply=1\n\t\t}\n\t)\n\t```\n* `pgsql_variables`: contains global variables that control the functionality for handling the incoming PostgreSQL traffic.\n* `pgsql_servers`: contains rows for the `pgsql_servers` table from the admin interface. Basically, these define the backend servers towards which the incoming PostgreSQL traffic is routed. Rows are encoded as per the `.cfg` file format, here is an example:\n\t\n\t```bash\n\tpgsql_servers =\n\t(\n\t\t{\n\t\t\taddress=\"127.0.0.1\"\n\t\t\tport=5432\n\t\t\thostgroup=0\n\t\t\tmax_connections=200\n\t\t}\n\t)\n\t```\n* `pgsql_users`: contains rows for the `pgsql_users` table from the admin interface. Basically, these define the users which can connect to the proxy, and the users with which the proxy can connect to the backend servers. Rows are encoded as per the `.cfg` file format, here is an example:\n\t\n\t```bash\n\tpgsql_users:\n\t(\n\t\t{\n\t\t\tusername=\"postgres\"\n\t\t\tpassword=\"postgres\"\n\t\t\tdefault_hostgroup=0\n\t\t\tmax_connections=1000\n\t\t\tactive=1\n\t\t}\n\t)\n\t```\n* `pgsql_query_rules`: contains rows for the `pgsql_query_rules` table from the admin interface. Basically, these define the rules used to classify and route the incoming PostgreSQL traffic, according to various criteria (patterns matched, user used to run the query, etc.). Rows are encoded as per the `.cfg` file format, here is an example (Note: the example is a very generic query routing rule and it is recommended to create specific rules for queries rather than using a generic rule such as this):\n\t\n\t```bash\n\tpgsql_query_rules:\n\t(\n\t\t{\n\t\t\trule_id=1\n\t\t\tactive=1\n\t\t\tmatch_pattern=\"^SELECT .* FOR UPDATE$\"\n\t\t\tdestination_hostgroup=0\n\t\t\tapply=1\n\t\t},\n\t\t{\n\t\t\trule_id=2\n\t\t\tactive=1\n\t\t\tmatch_pattern=\"^SELECT\"\n\t\t\tdestination_hostgroup=1\n\t\t\tapply=1\n\t\t}\n\t)\n\t```\n* top-level configuration item: `datadir`, as a string, to point to the data dir.\n",
      "stars_today": 1
    },
    {
      "id": 35927665,
      "name": "seurat",
      "full_name": "satijalab/seurat",
      "description": "R toolkit for single cell genomics",
      "html_url": "https://github.com/satijalab/seurat",
      "stars": 2648,
      "forks": 980,
      "language": "R",
      "topics": [
        "cran",
        "human-cell-atlas",
        "single-cell-genomics",
        "single-cell-rna-seq"
      ],
      "created_at": "2015-05-20T05:23:02Z",
      "updated_at": "2026-02-07T01:59:46Z",
      "pushed_at": "2026-02-06T23:01:30Z",
      "open_issues": 285,
      "owner": {
        "login": "satijalab",
        "avatar_url": "https://avatars.githubusercontent.com/u/8411851?v=4"
      },
      "readme": "[![CRAN Version](https://www.r-pkg.org/badges/version/Seurat)](https://cran.r-project.org/package=Seurat)\n[![CRAN Downloads](https://cranlogs.r-pkg.org/badges/Seurat)](https://cran.r-project.org/package=Seurat)\n\n\n# Seurat v5\n\nSeurat is an R toolkit for single cell genomics, developed and maintained by the Satija Lab at NYGC.\n\nWe are excited to release Seurat v5! This updates introduces new functionality for spatial, multimodal, and scalable single-cell analysis.\n\nSeurat v5 is backwards-compatible with previous versions, so that users will continue to be able to re-run existing workflows. \n\nInstructions, documentation, and tutorials can be found at:\n\n* https://satijalab.org/seurat\n\nSeurat is also hosted on GitHub, you can view and clone the repository at\n\n* https://github.com/satijalab/seurat\n\nSeurat has been successfully installed on Mac OS X, Linux, and Windows, using the devtools package to install directly from GitHub\n\nImprovements and new features will be added on a regular basis, please post on the [github page](https://github.com/satijalab/seurat) with any questions or if you would like to contribute\n\nFor a version history/changelog, please see the [NEWS file](https://github.com/satijalab/seurat/blob/master/NEWS.md).\n",
      "stars_today": 1
    },
    {
      "id": 807776416,
      "name": "polaris",
      "full_name": "apache/polaris",
      "description": "Apache Polaris, the interoperable, open source catalog for Apache Iceberg",
      "html_url": "https://github.com/apache/polaris",
      "stars": 1824,
      "forks": 366,
      "language": "Java",
      "topics": [
        "apache",
        "iceberg",
        "polaris"
      ],
      "created_at": "2024-05-29T18:44:27Z",
      "updated_at": "2026-02-07T00:45:37Z",
      "pushed_at": "2026-02-06T19:19:33Z",
      "open_issues": 318,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "<!--\n  Licensed to the Apache Software Foundation (ASF) under one\n  or more contributor license agreements.  See the NOTICE file\n  distributed with this work for additional information\n  regarding copyright ownership.  The ASF licenses this file\n  to you under the Apache License, Version 2.0 (the\n  \"License\"); you may not use this file except in compliance\n  with the License.  You may obtain a copy of the License at\n \n   http://www.apache.org/licenses/LICENSE-2.0\n \n  Unless required by applicable law or agreed to in writing,\n  software distributed under the License is distributed on an\n  \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n  KIND, either express or implied.  See the License for the\n  specific language governing permissions and limitations\n  under the License.\n-->\n\n# Apache Polaris (incubating)\n\nApache Polaris&trade; is an open-source, fully-featured catalog for Apache Iceberg&trade;. It implements Iceberg's \n[REST API](https://github.com/apache/iceberg/blob/main/open-api/rest-catalog-open-api.yaml),\nenabling seamless multi-engine interoperability across a wide range of platforms, including Apache Dorisâ„¢, Apache FlinkÂ®,\nApache Sparkâ„¢, DremioÂ® OSS, StarRocks, and Trino. \n\nDocumentation is available at https://polaris.apache.org. The REST OpenAPI specifications are available here:\n[Polaris management API doc](https://editor-next.swagger.io/?url=https://raw.githubusercontent.com/apache/polaris/refs/heads/main/spec/polaris-management-service.yml)\nand [Polaris Catalog API doc](https://editor-next.swagger.io/?url=https://raw.githubusercontent.com/apache/polaris/refs/heads/main/spec/generated/bundled-polaris-catalog-service.yaml).\n\n[Subscribe to the dev mailing list][dev-list-subscribe] to join discussions via email or browse [the archives](https://lists.apache.org/list.html?dev@polaris.apache.org). Check out the [CONTRIBUTING guide](CONTRIBUTING.md)\nfor contribution guidelines.\n\n[![Slack](https://img.shields.io/badge/chat-on%20Slack-brightgreen.svg?style=for-the-badge)](https://join.slack.com/t/apache-polaris/shared_invite/zt-2y3l3r0fr-VtoW42ltir~nSzCYOrQgfw)\n[![Build Status](https://img.shields.io/github/actions/workflow/status/apache/polaris/gradle.yml?branch=main&label=Main%20CI&logo=Github&style=for-the-badge)](https://github.com/apache/polaris/actions/workflows/gradle.yml?query=branch%3Amain)\n\n[dev-list-subscribe]: mailto:dev-subscribe@polaris.apache.org\n\n## Polaris Overview\nClick [here](https://polaris.apache.org/in-dev/unreleased/) for a quick overview of Polaris.\n\n## Quickstart\nClick [here](https://polaris.apache.org/in-dev/unreleased/getting-started/) for the quickstart experience, which will help you set up a Polaris instance locally or on any supported cloud provider.\n\n## Project Structure\n\nApache Polaris is organized into the following modules:\n- Primary modules:\n  - [`polaris-core`](./polaris-core/README.md) - The main Polaris entity definitions and core business logic\n  - [API modules](./api/README.md) - Build scripts for generating Java classes from the OpenAPI specifications:\n  - `polaris-api-management-model` - Polaris Management API model classes\n  - `polaris-api-management-service` - Polaris Management API service classes\n  - `polaris-api-iceberg-service` - The Iceberg REST service classes\n  - `polaris-api-catalog-service` - The Polaris Catalog API service classes\n  - Runtime modules:\n      - [`polaris-admin`](./runtime/admin/README.md) - The Polaris Admin Tool; mainly for bootstrapping persistence\n      - [`polaris-runtime-defaults`](./runtime/defaults/README.md) - The runtime configuration defaults\n      - [`polaris-distribution`](./runtime/distribution/README.md) - The Polaris distribution\n      - [`polaris-server`](./runtime/server/README.md) - The Polaris Quarkus Server\n      - [`polaris-runtime-service`](./runtime/service/README.md) - The package containing the Polaris service.\n      - `polaris-runtime-spark-tests` - Integration tests for the Polaris Spark plugin\n      - `polaris-runtime-test-common` - Test utilities\n  - Persistence modules:\n      - `polaris-relational-jdbc` - The JDBC implementation of BasePersistence to be used via AtomicMetaStoreManager\n  - Extensions modules:\n      - `polaris-extensions-federation-hadoop` - The Hadoop federation extension\n      - [`polaris-extensions-federation-hive`](./extensions/federation/hive/README.md) - The Hive federation extension\n- Secondary modules:\n    - `agregated-license-report` - Generates the aggregated license report\n    - `polaris-bom` - The Bill of Materials (BOM) for Polaris\n    - `polaris-build-logic` - Establishes consistent build logic\n    - [`polaris-tests`](./integration-tests/README.md) - Normative integration tests for reuse in downstream projects\n- Tool modules:\n    - Documentation configuration:\n        - `polaris-config-docs-annotations` - Annotations for documentation generator\n        - `polaris-config-docs-generator` - Generates Polaris reference docs\n        - `polaris-config-docs-site` - The configuration documentation site\n    - Other Tools:\n        - `polaris-container-spec-helper` - Helper for container specifications\n        - `polaris-immutables` - Predefined Immutables configuration & annotations for Polaris\n        - `polaris-minio-testcontainer` - Minio test container\n        - `polaris-misc-types` - Miscellaneous types for Polaris\n        - `polaris-version` - Versioning for Polaris\n\nIn addition to modules, there are:\n- [API specifications](./spec/README.md) - The OpenAPI specifications\n- [Python client](./client/python/README.md) - The Python client\n- [codestyle](./codestyle/README.md) - The code style guidelines\n- [getting-started](./getting-started/README.md) - A collection of getting started examples\n- [gradle](./gradle) - The Gradle wrapper and Gradle configuration files including banned dependencies\n- [helm](./helm) - The Helm charts for Polaris.\n- [Spark Plugin](./plugins/spark/README.md) - The Polaris Spark plugin\n- [regtests](./regtests/README.md) - Regression tests\n- [server-templates](./server-templates) - OpenAPI Generator templates to generate the server code\n- [site](./site/README.md) - The Polaris website\n\nOutside of this repository, there are several other tools that can be found in a separate [Polaris-Tools](https://github.com/apache/polaris-tools) repository.\n\n## Building and Running\n\nApache Polaris is built using Gradle with Java 21+ and Docker 27+.\n\n- `./gradlew build` - To build and run tests. Make sure Docker is running, as the integration tests depend on it.\n- `./gradlew assemble` - To skip tests.\n- `./gradlew check` - To run all checks, including unit tests and integration tests.\n- `./gradlew run` - To run the Polaris server locally; the server is reachable at localhost:8181. This is also suitable for running regression tests, or for connecting with Spark. Set your own credentials by specifying system property `./gradlew run -Dpolaris.bootstrap.credentials=POLARIS,root,secret` where:\n  - `POLARIS` is the realm\n  - `root` is the CLIENT_ID\n  - `secret` is the CLIENT_SECRET\n  - If credentials are not set, it will use preset credentials `POLARIS,root,s3cr3t`\n- `./regtests/run_spark_sql.sh` - To connect from Spark SQL. Here are some example commands to run in the Spark SQL shell:\n```sql\ncreate database db1;\nshow databases;\ncreate table db1.table1 (id int, name string);\ninsert into db1.table1 values (1, 'a');\nselect * from db1.table1;\n```\n- `env POLARIS_HOST=localhost ./regtests/run.sh` - To run regression tests locally, see more options [here](./regtests/README.md).\n\n## Makefile Convenience Commands\n\nTo streamline the developer experience, especially for common setup and build tasks, a root-level Makefile is available. This Makefile acts as a convenient wrapper around various Gradle commands and other tooling, simplifying interactions. While Gradle remains the primary build system, the Makefile provides concise shortcuts for frequent operations like:\n  - Building Polaris components: e.g., `make build-server, make build-admin`\n  - Managing development clusters: e.g., `make minikube-start-cluster, make minikube-cleanup`\n  - Automating Helm tasks: e.g., `make helm-doc-generate, make helm-unittest`\n  - Handling dependencies: e.g., `make install-dependencies-brew`\n  - Managing client operations: e.g., `make client-lint, make client-regenerate`\n\nTo see available commands:\n```bash\nmake help\n```\n\nFor example, to build the Polaris server and its container image, you can simply run:\n```bash\nmake build-server\n```\n\n### More build and run options\n\n#### Running in Docker\n\n- To build the image locally:\n  ```bash\n  ./gradlew \\\n    :polaris-server:assemble \\\n    :polaris-server:quarkusAppPartsBuild --rerun \\\n    -Dquarkus.container-image.build=true\n  ```\n- `docker run -p 8181:8181 -p 8182:8182 apache/polaris:latest` - To run the image.\n\nThe Polaris codebase contains some docker compose examples to quickly get started with Polaris,\nusing different configurations. Check the `./getting-started` directory for more information.\n\n#### Running in Kubernetes\n\n- See [README in `helm/polaris`](helm/polaris/README.md) for more information.\n\n#### Configuring Polaris\n\nPolaris Servers can be configured using a variety of ways.\nPlease see the [Configuration Guide](site/content/in-dev/unreleased/configuration.md)\nfor more information.\n\nDefault configuration values can be found in `runtime/defaults/src/main/resources/application.properties`.\n\n#### Building docs\n\n- Docs are generated using [Hugo](https://gohugo.io/) using the [Docsy](https://www.docsy.dev/docs/) theme.\n- To view the site locally, run\n  ```bash\n  site/bin/run-hugo-in-docker.sh\n  ```\n- See [README in `site/`](site/README.md) for more information.\n\n#### Publishing Build Scans to develocity.apache.org\n\nBuild scans of CI builds from a branch or tag in the `apache/polaris` repository on GitHub publish build scans\nto the ASF Develocity instance at\n[develocity.apache.org](https://develocity.apache.org/scans?search.rootProjectNames=polaris), if the workflow runs have access to the Apache organization-level secret \n`DEVELOCITY_ACCESS_KEY`.\n\nBuild scans of local developer builds publish build scans only if the Gradle command line option `--scan` is used.\nThose build scans are published to Gradle's public Develocity instance (see advanced configuration options below).\nNote that build scans on Gradle's public Develocity instance are publicly accessible to anyone.\nYou have to accept Gradle's terms of service to publish to the Gradle's public Develocity instance.\n\nCI builds originating from pull requests against the `apache/polaris` GitHub repository are published to Gradle's\n_public_ Develocity instance. \n\nOther CI build scans do only publish build scans to the Gradle's _public_ Develocity instance, if the environment\nvariable `GRADLE_TOS_ACCEPTED` is set to `true`.\nBy setting this variable you agree to the [Gradle's terms of service](https://gradle.com/terms-of-service), because\naccepting these ToS is your personal decision. \nYou can configure this environment variable for your GitHub repository in the GitHub repository settings under\n`Secrets` > `Secrets and variables` > `Actions` > choose the `Variables` tab > `New repository variable`. \n\nAdvanced configuration options for publishing build scans (only local and non-`apache/polaris` repository CI):\n* The project ID published with the build scan can be specified using the environment variable `DEVELOCITY_PROJECT_ID`.\n  The project ID defaults to the GitHub repository owner/name, for example `octocat/polaris`.\n* The Develocity server can be specified using the environment variable `DEVELOCITY_SERVER` if build scans should be\n  published to another than Gradle's public Develocity instance.\n* If you have to publish build scans to your own Develocity instance, you can configure the access key using a\n  GitHub secret named `DEVELOCITY_ACCESS_KEY`.\n\n## License\n\nApache Polaris is under the Apache License Version 2.0. See the [LICENSE](LICENSE).\n\n## ASF Incubator disclaimer\n\nApache Polaris&trade; is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the Apache Incubator. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.\n \n<sub>Apache&reg;, Apache Polaris&trade;, Apache Iceberg&trade;, Apache Spark&trade; are either registered trademarks or trademarks of the Apache Software Foundation in the United States and/or other countries.</sub>\n",
      "stars_today": 1
    },
    {
      "id": 573301536,
      "name": "sing-box-for-android",
      "full_name": "SagerNet/sing-box-for-android",
      "description": "Experimental Android client for sing-box",
      "html_url": "https://github.com/SagerNet/sing-box-for-android",
      "stars": 878,
      "forks": 334,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2022-12-02T06:15:42Z",
      "updated_at": "2026-02-07T01:15:49Z",
      "pushed_at": "2026-02-05T12:27:56Z",
      "open_issues": 8,
      "owner": {
        "login": "SagerNet",
        "avatar_url": "https://avatars.githubusercontent.com/u/83217677?v=4"
      },
      "readme": "# SFA\n\nExperimental Android client for sing-box, the universal proxy platform.\n\n## Documentation\n\nhttps://sing-box.sagernet.org/installation/clients/sfa/\n\n## License\n\n```\nCopyright (C) 2022 by nekohasekai <contact-sagernet@sekai.icu>\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program. If not, see <http://www.gnu.org/licenses/>.\n\nIn addition, no derivative work may use the name or imply association\nwith this application without prior consent.\n```\n\nUnder the license, that forks of the app are not allowed to be listed on F-Droid or other app stores\nunder the original name.\n",
      "stars_today": 1
    },
    {
      "id": 159560389,
      "name": "renv",
      "full_name": "rstudio/renv",
      "description": "renv: Project environments for R.",
      "html_url": "https://github.com/rstudio/renv",
      "stars": 1130,
      "forks": 162,
      "language": "R",
      "topics": [],
      "created_at": "2018-11-28T20:25:39Z",
      "updated_at": "2026-02-06T02:20:26Z",
      "pushed_at": "2026-02-03T17:52:16Z",
      "open_issues": 212,
      "owner": {
        "login": "rstudio",
        "avatar_url": "https://avatars.githubusercontent.com/u/513560?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# renv <img src=\"man/figures/logo.svg\" align=\"right\" height=\"115\"/>\n\n<!-- badges: start -->\n\n[![Lifecycle:\nstable](https://img.shields.io/badge/lifecycle-stable-brightgreen.svg)](https://lifecycle.r-lib.org/articles/stages.html)\n[![CRAN\nstatus](https://www.r-pkg.org/badges/version/renv)](https://CRAN.R-project.org/package=renv)\n[![R-CMD-check](https://github.com/rstudio/renv/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/rstudio/renv/actions/workflows/R-CMD-check.yaml)\n\n<!-- badges: end -->\n\n## Overview\n\nThe renv package[^1] helps you create **r**eproducible **env**ironments\nfor your R projects. Use renv to make your R projects more isolated,\nportable and reproducible.\n\n- **Isolated**: Installing a new or updated package for one project\n  wonâ€™t break your other projects, and vice versa. Thatâ€™s because renv\n  gives each project its own private library.\n- **Portable**: Easily transport your projects from one computer to\n  another, even across different platforms. renv makes it easy to\n  install the packages your project depends on.\n- **Reproducible**: renv records the exact package versions you depend\n  on, and ensures those exact versions are the ones that get installed\n  wherever you go.\n\n## Installation\n\nInstall the latest version of renv from CRAN with:\n\n``` r\ninstall.packages(\"renv\")\n```\n\nAlternatively, install the development version from\n[r-universe](https://rstudio.r-universe.dev/renv) with:\n\n``` r\ninstall.packages(\"renv\", repos = \"https://rstudio.r-universe.dev\")\n```\n\n## Workflow\n\n<img src=\"vignettes/renv.png\" alt=\"A diagram showing the most important verbs and nouns of renv. Projects start with init(), which creates a project library using packages from the system library. snapshot() updates the lockfile using the packages installed in the project library, where restore() installs packages into the project library using the metadata from the lockfile, and status() compares the lockfile to the project library. You install and update packages from CRAN and GitHub using install() and update(), but because you'll need to do this for multiple projects, renv uses cache to make this fast.\" width=\"408\" style=\"display: block; margin: auto;\" />\n\nUse `renv::init()` to initialize renv in a new or existing project. This\nwill set up a **project library**, containing all the packages youâ€™re\ncurrently using. The packages (and all the metadata needed to reinstall\nthem) are recorded into a **lockfile**, `renv.lock`, and a `.Rprofile`\nensures that the library is used every time you open that project.\n\nAs you continue to work on your project, you will install and upgrade\npackages, either using `install.packages()` and `update.packages()` or\n`renv::install()` and `renv::update()`. After youâ€™ve confirmed your code\nworks as expected, use `renv::snapshot()` to record the packages and\ntheir sources in the lockfile.\n\nLater, if you need to share your code with someone else or run your code\non new machine, your collaborator (or you) can call `renv::restore()` to\nreinstall the specific package versions recorded in the lockfile.\n\n## Learning more\n\nIf this is your first time using renv, we strongly recommend starting\nwith the [Introduction to\nrenv](https://rstudio.github.io/renv/articles/renv.html) vignette: this\nwill help you understand the most important verbs and nouns of renv.\n\nIf you have a question about renv, please first check the\n[FAQ](https://rstudio.github.io/renv/articles/faq.html) to see whether\nyour question has already been addressed. If it hasnâ€™t, please feel free\nto ask on the [Posit Forum](https://forum.posit.co).\n\nIf you believe youâ€™ve found a bug in renv, please file a bug (and, if\npossible, a [reproducible example](https://reprex.tidyverse.org)) at\n<https://github.com/rstudio/renv/issues>.\n\n[^1]: Pronounced â€œRâ€ â€œenvâ€\n",
      "stars_today": 1
    },
    {
      "id": 902097949,
      "name": "sqlite-data",
      "full_name": "pointfreeco/sqlite-data",
      "description": "A fast, lightweight replacement for SwiftData, powered by SQL and supporting CloudKit synchronization.",
      "html_url": "https://github.com/pointfreeco/sqlite-data",
      "stars": 1575,
      "forks": 79,
      "language": "Swift",
      "topics": [
        "cloudkit",
        "database",
        "observation",
        "persistence",
        "sql",
        "sqlite",
        "swiftdata",
        "swiftui",
        "synchronization"
      ],
      "created_at": "2024-12-11T22:44:01Z",
      "updated_at": "2026-02-05T20:27:46Z",
      "pushed_at": "2026-01-31T20:42:47Z",
      "open_issues": 13,
      "owner": {
        "login": "pointfreeco",
        "avatar_url": "https://avatars.githubusercontent.com/u/29466629?v=4"
      },
      "readme": "# SQLiteData\n\nA [fast](#Performance), lightweight replacement for SwiftData, powered by SQL and supporting\nCloudKit synchronization.\n\n[![CI](https://github.com/pointfreeco/sqlite-data/actions/workflows/ci.yml/badge.svg)](https://github.com/pointfreeco/sqlite-data/actions/workflows/ci.yml)\n[![Slack](https://img.shields.io/badge/slack-chat-informational.svg?label=Slack&logo=slack)](https://www.pointfree.co/slack-invite)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fsqlite-data%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/pointfreeco/sqlite-data)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fsqlite-data%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/pointfreeco/sqlite-data)\n\n  * [Learn more](#Learn-more)\n  * [Overview](#Overview)\n  * [Quick start](#Quick-start)\n  * [Performance](#Performance)\n  * [SQLite knowledge required](#SQLite-knowledge-required)\n  * [Overview](#Overview)\n  * [Demos](#Demos)\n  * [Documentation](#Documentation)\n  * [Installation](#Installation)\n  * [Community](#Community)\n  * [License](#License)\n\n## Learn more\n\nThis library was motivated and designed over the course of many episodes on\n[Point-Free](https://www.pointfree.co), a video series exploring advanced programming topics in the\nSwift language, hosted by [Brandon Williams](https://twitter.com/mbrandonw) and\n[Stephen Celis](https://twitter.com/stephencelis). To support the continued development of this\nlibrary, [subscribe today](https://www.pointfree.co/pricing).\n\n<a href=\"https://www.pointfree.co/collections/modern-persistence\">\n  <img alt=\"video poster image\" src=\"https://d3rccdn33rt8ze.cloudfront.net/episodes/0325.jpeg\" width=\"600\">\n</a>\n\n## Overview\n\nSQLiteData is a [fast](#performance), lightweight replacement for SwiftData, including CloudKit\nsynchronization (and even CloudKit sharing), built on top of the popular [GRDB] library.\nTo populate data from the database you can use `@Table` and `@FetchAll`, which are\nsimilar to SwiftData's `@Model` and `@Query`:\n\n<table>\n<tr>\n<th>SQLiteData</th>\n<th>SwiftData</th>\n</tr>\n<tr valign=top>\n<td width=415>\n\n```swift\n@FetchAll\nvar items: [Item]\n\n@Table\nstruct Item {\n  let id: UUID\n  var title = \"\"\n  var isInStock = true\n  var notes = \"\"\n}\n```\n\n</td>\n<td width=415>\n\n```swift\n@Query\nvar items: [Item]\n\n@Model\nclass Item {\n  var title: String\n  var isInStock: Bool\n  var notes: String\n  init(\n    title: String = \"\",\n    isInStock: Bool = true,\n    notes: String = \"\"\n  ) {\n    self.title = title\n    self.isInStock = isInStock\n    self.notes = notes\n  }\n}\n```\n\n</td>\n</tr>\n</table>\n\nBoth of the above examples fetch items from an external data store using Swift data types, and both\nare automatically observed by SwiftUI so that views are recomputed when the external data changes,\nbut SQLiteData is powered directly by SQLite and is usable from UIKit, `@Observable` models, and\nmore.\n\nFor more information on SQLiteData's querying capabilities, see\n[Fetching model data][fetching-article].\n\n## Quick start\n\nBefore SQLiteData's property wrappers can fetch data from SQLite, you need to provideâ€“at\nruntimeâ€“the default database it should use. This is typically done as early as possible in your\napp's lifetime, like the app entry point in SwiftUI, and is analogous to configuring model storage\nin SwiftData:\n\n<table>\n<tr>\n<th>SQLiteData</th>\n<th>SwiftData</th>\n</tr>\n<tr valign=top>\n<td width=415>\n\n```swift\n@main\nstruct MyApp: App {\n  init() {\n    prepareDependencies {\n      let db = try! DatabaseQueue(\n        // Create/migrate a database\n        // connection\n      )\n      $0.defaultDatabase = db\n    }\n  }\n  // ...\n}\n```\n\n</td>\n<td width=415>\n\n```swift\n@main\nstruct MyApp: App {\n  let container = {\n    // Create/configure a container\n    try! ModelContainer(/* ... */)\n  }()\n\n  var body: some Scene {\n    WindowGroup {\n      ContentView()\n        .modelContainer(container)\n    }\n  }\n}\n```\n\n</td>\n</tr>\n</table>\n\n> [!NOTE]\n> For more information on preparing a SQLite database, see\n> [Preparing a SQLite database][preparing-db-article].\n\nThis `defaultDatabase` connection is used implicitly by SQLiteData's strategies, like\n[`@FetchAll`][fetchall-docs] and [`@FetchOne`][fetchone-docs], which are similar to SwiftData's\n`@Query` macro, but more powerful:\n\n<table>\n<tr>\n<th>SQLiteData</th>\n<th>SwiftData</th>\n</tr>\n<tr valign=top>\n<td width=415>\n\n```swift\n@FetchAll\nvar items: [Item]\n\n@FetchAll(Item.order(by: \\.title))\nvar items\n\n@FetchAll(Item.where(\\.isInStock))\nvar items\n\n\n\n@FetchAll(Item.order(by: \\.isInStock))\nvar items\n\n@FetchOne(Item.count())\nvar itemsCount = 0\n\n```\n\n</td>\n<td width=415>\n\n```swift\n@Query\nvar items: [Item]\n\n@Query(sort: [SortDescriptor(\\.title)])\nvar items: [Item]\n\n@Query(filter: #Predicate<Item> {\n  $0.isInStock\n})\nvar items: [Item]\n\n// No @Query equivalent of ordering\n// by boolean column.\n\n// No @Query equivalent of counting\n// entries in database without loading\n// all entries.\n```\n\n</td>\n</tr>\n</table>\n\nAnd you can access this database throughout your application in a way similar to how one accesses\na model context, via a property wrapper:\n\n<table>\n<tr>\n<th>SQLiteData</th>\n<th>SwiftData</th>\n</tr>\n<tr valign=top>\n<td width=415>\n\n```swift\n@Dependency(\\.defaultDatabase)\nvar database\n\nlet newItem = Item(/* ... */)\ntry database.write { db in\n  try Item.insert { newItem }\n    .execute(db))\n}\n```\n\n</td>\n<td width=415>\n\n```swift\n@Environment(\\.modelContext)\nvar modelContext\n\nlet newItem = Item(/* ... */)\nmodelContext.insert(newItem)\ntry modelContext.save()\n\n```\n\n</td>\n</tr>\n</table>\n\n> [!NOTE]\n> For more information on how SQLiteData compares to SwiftData, see\n> [Comparison with SwiftData][comparison-swiftdata-article].\n\nFurther, if you want to synchronize the local database to CloudKit so that it is available on\nall your user's devices, simply configure a `SyncEngine` in the entry point of the app:\n\n```swift\n@main\nstruct MyApp: App {\n  init() {\n    prepareDependencies {\n      $0.defaultDatabase = try! appDatabase()\n      $0.defaultSyncEngine = SyncEngine(\n        for: $0.defaultDatabase,\n        tables: Item.self\n      )\n    }\n  }\n  // ...\n}\n```\n\n> [!NOTE]\n> For more information on synchronizing the database to CloudKit and sharing records with iCloud\n> users, see [CloudKit Synchronization].\n\nThis is all you need to know to get started with SQLiteData, but there's much more to learn. Read\nthe [articles][articles] below to learn how to best utilize this library:\n\n  * [Fetching model data][fetching-article]\n  * [Observing changes to model data][observing-article]\n  * [Preparing a SQLite database][preparing-db-article]\n  * [Dynamic queries][dynamic-queries-article]\n  * [CloudKit Synchronization]\n  * [Comparison with SwiftData][comparison-swiftdata-article]\n\n[observing-article]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/observing\n[dynamic-queries-article]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/dynamicqueries\n[articles]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata#Essentials\n[comparison-swiftdata-article]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/comparisonwithswiftdata\n[fetching-article]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/fetching\n[preparing-db-article]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/preparingdatabase\n[CloudKit Synchronization]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/cloudkit\n[fetchall-docs]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/fetchall\n[fetchone-docs]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/fetchone\n\n## Performance\n\nSQLiteData leverages high-performance decoding from [StructuredQueries][] to turn fetched data into\nyour Swift domain types, and has a performance profile similar to invoking SQLite's C APIs directly.\n\nSee the following benchmarks against\n[Lighter's performance test suite](https://github.com/Lighter-swift/PerformanceTestSuite) for a\ntaste of how it compares:\n\n```\nOrders.fetchAll                           setup    rampup   duration\n   SQLite (generated by Enlighter 1.4.10) 0        0.144    7.183\n   Lighter (1.4.10)                       0        0.164    8.059\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  SQLiteData (1.0.0)                     0        0.172    8.511  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n   GRDB (7.4.1, manual decoding)          0        0.376    18.819\n   SQLite.swift (0.15.3, manual decoding) 0        0.564    27.994\n   SQLite.swift (0.15.3, Codable)         0        0.863    43.261\n   GRDB (7.4.1, Codable)                  0.002    1.07     53.326\n```\n\n## SQLite knowledge required\n\nSQLite is one of the\n[most established and widely distributed](https://www.sqlite.org/mostdeployed.html) pieces of\nsoftware in the history of software. Knowledge of SQLite is a great skill for any app developer to\nhave, and this library does not want to conceal it from you. So, we feel that to best wield this\nlibrary you should be familiar with the basics of SQLite, including schema design and normalization,\nSQL queries, including joins and aggregates, and performance, including indices.\n\nWith some basic knowledge you can apply this library to your database schema in order to query\nfor data and keep your views up-to-date when data in the database changes, and you can use\n[StructuredQueries][] to build queries, either using its type-safe, discoverable\n[query building APIs][], or using its `#sql` macro for writing [safe SQL strings][].\n\nFurther, this library is built on the popular and battle-tested [GRDB] library for\ninteracting with SQLite, such as executing queries and observing the database for changes.\n\n[StructuredQueries]: https://github.com/pointfreeco/swift-structured-queries\n[GRDB]: https://github.com/groue/GRDB.swift\n[query building APIs]: https://swiftpackageindex.com/pointfreeco/swift-structured-queries/~/documentation/structuredqueriescore\n[safe SQL strings]: https://swiftpackageindex.com/pointfreeco/swift-structured-queries/~/documentation/structuredqueriescore/safesqlstrings\n\n## Demos\n\nThis repo comes with _lots_ of examples to demonstrate how to solve common and complex problems with\nSQLiteData. Check out [this](./Examples) directory to see them all, including:\n\n* [**Case Studies**](./Examples/CaseStudies)\n  <br> Demonstrates how to solve some common application problems in an isolated environment, in\n  both SwiftUI and UIKit. Things like animations, dynamic queries, database transactions, and more.\n\n* [**CloudKitDemo**](./Examples/CloudKitDemo)\n  <br> A simplified demo that shows how to synchronize a SQLite database to CloudKit and how to\n  share records with other iCloud users. See our dedicated articles on [CloudKit Synchronization]\n  and [CloudKit Sharing] for more information.\n\n  [CloudKit Synchronization]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/cloudkit\n  [CloudKit Sharing]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/cloudkitsharing\n\n* [**Reminders**](./Examples/Reminders)\n  <br> A rebuild of Apple's [Reminders][reminders-app-store] app that uses a SQLite database to\n  model the reminders, lists and tags. It features many advanced queries, such as searching, stats\n  aggregation, and multi-table joins. It also features CloudKit synchronization and sharing.\n\n* [**SyncUps**](./Examples/SyncUps)\n  <br> This application is a faithful reconstruction of one of Apple's more interesting sample\n  projects, called [Scrumdinger][scrumdinger], and uses SQLite to persist the data for meetings.\n  We have also added CloudKit synchronization so that all changes are automatically made available\n  on all of the user's devices.\n\n[Scrumdinger]: https://developer.apple.com/tutorials/app-dev-training/getting-started-with-scrumdinger\n[reminders-app-store]: https://apps.apple.com/us/app/reminders/id1108187841\n\n## Documentation\n\nThe documentation for releases and `main` are available here:\n\n  * [`main`](https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/)\n  * [1.x.x](https://swiftpackageindex.com/pointfreeco/sqlite-data/~/documentation/sqlitedata/)\n\n## Installation\n\nYou can add SQLiteData to an Xcode project by adding it to your project as a packageâ€¦\n\n> https://github.com/pointfreeco/sqlite-data\n\nâ€¦and adding the `SQLiteData` product to your target.\n\nIf you want to use SQLiteData in a [SwiftPM](https://swift.org/package-manager/) project, it's as\nsimple as adding it to your `Package.swift`:\n\n``` swift\ndependencies: [\n  .package(url: \"https://github.com/pointfreeco/sqlite-data\", from: \"1.0.0\")\n]\n```\n\nAnd then adding the following product to any target that needs access to the library:\n\n```swift\n.product(name: \"SQLiteData\", package: \"sqlite-data\"),\n```\n\n## Community\n\nIf you want to discuss this library or have a question about how to use it to solve a particular\nproblem, there are a number of places you can discuss with fellow\n[Point-Free](http://www.pointfree.co) enthusiasts:\n\n  * For long-form discussions, we recommend the\n    [discussions](http://github.com/pointfreeco/sqlite-data/discussions) tab of this repo.\n\n  * For casual chat, we recommend the\n    [Point-Free Community Slack](http://www.pointfree.co/slack-invite).\n\n## License\n\nThis library is released under the MIT license. See [LICENSE](LICENSE) for details.\n",
      "stars_today": 1
    },
    {
      "id": 12358097,
      "name": "IQKeyboardManager",
      "full_name": "hackiftekhar/IQKeyboardManager",
      "description": "Codeless drop-in universal library allows to prevent issues of keyboard sliding up and cover UITextField/UITextView. Neither need to write any code nor any setup required and much more.",
      "html_url": "https://github.com/hackiftekhar/IQKeyboardManager",
      "stars": 16636,
      "forks": 2451,
      "language": "Swift",
      "topics": [
        "iqkeyboardmanager",
        "keyboard",
        "objective-c",
        "swift",
        "xcode"
      ],
      "created_at": "2013-08-25T11:32:48Z",
      "updated_at": "2026-02-04T09:11:17Z",
      "pushed_at": "2025-12-26T15:48:09Z",
      "open_issues": 23,
      "owner": {
        "login": "hackiftekhar",
        "avatar_url": "https://avatars.githubusercontent.com/u/3831495?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/hackiftekhar/IQKeyboardManager/master/Screenshot/Social.png\" alt=\"Icon\"/>\n</p>\n\n[![LICENSE.md](https://img.shields.io/github/license/hackiftekhar/IQKeyboardManager.svg)](https://github.com/hackiftekhar/IQKeyboardManager/blob/master/LICENSE.md)\n[![Build Status](https://travis-ci.org/hackiftekhar/IQKeyboardManager.svg)](https://travis-ci.org/hackiftekhar/IQKeyboardManager)\n![Platform iOS](https://img.shields.io/badge/Platform-iOS-blue.svg?style=fla)\n[![CocoaPods](https://img.shields.io/cocoapods/v/IQKeyboardManagerSwift.svg)](http://cocoadocs.org/docsets/IQKeyboardManagerSwift)\n[![Github tag](https://img.shields.io/github/tag/hackiftekhar/iqkeyboardmanager.svg)](https://github.com/hackiftekhar/IQKeyboardManager/tags)\n\n## IQKeyboardManager Objective-C version source code is moved to https://github.com/hackiftekhar/IQKeyboardManagerObjC\n\n\n## Introduction\nWhile developing iOS apps, we often run into issues where the iPhone keyboard slides up and covers the `UITextField/UITextView`. `IQKeyboardManager` allows you to prevent this issue of keyboard sliding up and covering `UITextField/UITextView` without needing you to write any code or make any additional setup. To use `IQKeyboardManager` you simply need to add source files to your project.\n\n\n## Key Features\n\n1. **One Line of Code** - Just enable and it works\n2. **Works Automatically** - No manual setup required\n3. **No More UIScrollView** - Automatically handles scroll views\n4. **No More Subclasses** - Works with standard UIKit components\n5. **No More Manual Work** - Handles all edge cases automatically\n6. **Modular Architecture** - Include only what you need via subspecs\n\n### What's Included\n\n- âœ… Automatic keyboard avoidance for UITextField/UITextView\n- âœ… Support for UIScrollView, UITableView, UICollectionView\n- âœ… All interface orientations\n- âœ… Configurable keyboard distance\n- âœ… Class-level enable/disable control\n\n### Optional Features (via Subspecs)\n\n- ğŸ“¦ Toolbar with Previous/Next/Done buttons\n- ğŸ“¦ Return key handling customization\n- ğŸ“¦ Tap-to-resign keyboard\n- ğŸ“¦ Keyboard appearance configuration\n- ğŸ“¦ UITextView with placeholder supportv\n\n## Subspecs\n\nNow IQKeyboardManagerSwift uses a modular architecture with subspecs.\nBy default, all subspecs are included, but you can include only what you need:\n\n### Available Subspecs\n\n- **Core** (always included): Basic keyboard distance management\n- **Appearance**: Keyboard appearance configuration\n- **IQKeyboardReturnManager**: Return key handling\n- **IQKeyboardToolbarManager**: Toolbar functionality (Previous/Next/Done buttons)\n- **IQTextView**: UITextView with placeholder support\n- **Resign**: Tap-to-resign keyboard functionality\n\n### Including Specific Subspecs\n\n```ruby\n# Include toolbar example\npod 'IQKeyboardManagerSwift/IQKeyboardToolbarManager'\n```\n\n## Screenshot\n[![Screenshot 1](https://raw.githubusercontent.com/hackiftekhar/IQKeyboardManager/master/Screenshot/README_Screenshot1.png)](http://youtu.be/6nhLw6hju2A)\n[![Screenshot 2](https://raw.githubusercontent.com/hackiftekhar/IQKeyboardManager/master/Screenshot/README_Screenshot2.png)](http://youtu.be/6nhLw6hju2A)\n[![Screenshot 3](https://raw.githubusercontent.com/hackiftekhar/IQKeyboardManager/master/Screenshot/README_Screenshot3.png)](http://youtu.be/6nhLw6hju2A)\n[![Screenshot 4](https://raw.githubusercontent.com/hackiftekhar/IQKeyboardManager/master/Screenshot/README_Screenshot4.png)](http://youtu.be/6nhLw6hju2A)\n[![Screenshot 5](https://raw.githubusercontent.com/hackiftekhar/IQKeyboardManager/master/Screenshot/README_Screenshot5.png)](http://youtu.be/6nhLw6hju2A)\n\n## GIF animation\n[![IQKeyboardManager](https://raw.githubusercontent.com/hackiftekhar/IQKeyboardManager/v3.3.0/Screenshot/IQKeyboardManager.gif)](http://youtu.be/6nhLw6hju2A)\n\n## Video\n\n<a href=\"http://youtu.be/WAYc2Qj-OQg\" target=\"_blank\"><img src=\"http://img.youtube.com/vi/WAYc2Qj-OQg/0.jpg\"\nalt=\"IQKeyboardManager Demo Video\" width=\"480\" height=\"360\" border=\"10\" /></a>\n\n## Tutorial video by @rebeloper ([#1135](https://github.com/hackiftekhar/IQKeyboardManager/issues/1135))\n\n@rebeloper demonstrated two videos on how to implement **IQKeyboardManager** at it's core:\n\n<a href=\"https://www.youtube.com/playlist?list=PL_csAAO9PQ8aTL87XnueOXi3RpWE2m_8v\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/hackiftekhar/IQKeyboardManager/master/Screenshot/ThirdPartyYoutubeTutorial.jpg\"\nalt=\"Youtube Tutorial Playlist\"/></a>\n\nhttps://www.youtube.com/playlist?list=PL_csAAO9PQ8aTL87XnueOXi3RpWE2m_8v\n\n## Warning\n\n- **If you're planning to build SDK/library/framework and want to handle UITextField/UITextView with IQKeyboardManager then you're totally going the wrong way.** I would never suggest to add **IQKeyboardManager** as **dependency/adding/shipping** with any third-party library. Instead of adding **IQKeyboardManager** you should implement your own solution to achieve same kind of results. **IQKeyboardManager** is totally designed for projects to help developers for their convenience, it's not designed for **adding/dependency/shipping** with any **third-party library**, because **doing this could block adoption by other developers for their projects as well (who are not using IQKeyboardManager and have implemented their custom solution to handle UITextField/UITextView in the project).**\n- If **IQKeyboardManager** conflicts with other **third-party library**, then it's **developer responsibility** to **enable/disable IQKeyboardManager** when **presenting/dismissing** third-party library UI. Third-party libraries are not responsible to handle IQKeyboardManager.\n\n## Requirements\n\n|                        | Minimum iOS Target | Minimum Xcode Version |\n|------------------------|--------------------|-----------------------|\n| IQKeyboardManagerSwift | iOS 13.0           | Xcode 13              |\n| Demo Project           |                    | Xcode 15              |\n\n#### Swift versions support\n\n| Swift             | Xcode | IQKeyboardManagerSwift |\n|-------------------|-------|------------------------|\n| 5.9, 5.8, 5.7     | 16    | >= 7.0.0       |\n| 5.9, 5.8, 5.7, 5.6| 15    | >= 7.0.0       |\n| 5.5, 5.4, 5.3, 5.2, 5.1, 5.0, 4.2| 11  | >= 6.5.7       |\n| 5.1, 5.0, 4.2, 4.0, 3.2, 3.0| 11  | >= 6.5.0       |\n| 5.0,4.2, 4.0, 3.2, 3.0| 10.2  | >= 6.2.1           |\n| 4.2, 4.0, 3.2, 3.0| 10.0  | >= 6.0.4               |\n| 4.0, 3.2, 3.0     | 9.0   | 5.0.0                  |\n\n\nInstallation\n==========================\n\n#### CocoaPods\n\nTo install it, simply add the following line to your Podfile: ([#236](https://github.com/hackiftekhar/IQKeyboardManager/issues/236))\n\n```ruby\npod 'IQKeyboardManagerSwift'\n```\n\n*Or you can choose the version you need based on Swift support table from [Requirements](README.md#requirements)*\n\n```ruby\npod 'IQKeyboardManagerSwift', '8.0.0'\n```\n\n#### Carthage\n\nTo integrate `IQKeyboardManger` or `IQKeyboardManagerSwift` into your Xcode project using Carthage, add the following line to your `Cartfile`:\n\n```ogdl\ngithub \"hackiftekhar/IQKeyboardManager\"\n```\n\nRun `carthage update --use-xcframeworks` to build the frameworks and drag `IQKeyboardManagerSwift.xcframework` into your Xcode project based on your need. Make sure to add only one framework, not both.\n\n#### Swift Package Manager (SPM)\n\nTo install `IQKeyboardManagerSwift` package via Xcode\n\n * Go to File -> Swift Packages -> Add Package Dependency...\n * Then search for https://github.com/hackiftekhar/IQKeyboardManager.git\n * And choose the version you want\n\n#### Source Code\n\n***IQKeyboardManagerSwift:*** Source code installation is not supported (since 7.2.0) because now the library depends on some other independent libraries. Due to this you may face compilation issues.\n\n#### Basic Usage\n\n### Minimal Setup (Core Only)\n\nIn `AppDelegate.swift`, import and enable IQKeyboardManager:\n\n```swift\nimport IQKeyboardManagerSwift\n\n@UIApplicationMain\nclass AppDelegate: UIResponder, UIApplicationDelegate {\n\n    var window: UIWindow?\n\n    func application(_ application: UIApplication, \n                     didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?) -> Bool {\n\n        // Enable keyboard management\n        IQKeyboardManager.shared.isEnabled = true\n\n        return true\n    }\n}\n```\n\nThat's it! The keyboard will now automatically adjust to avoid covering text fields.\n\n### With Toolbar (Requires IQKeyboardToolbarManager Subspec)\n\n```swift\nimport IQKeyboardManagerSwift\n\nfunc application(_ application: UIApplication, \n                 didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?) -> Bool {\n\n    // Enable keyboard management\n    IQKeyboardManager.shared.isEnabled = true\n    \n    // Enable toolbar (@Deprecated: Please use IQKeyboardToolbarManager pod independently)\n    IQKeyboardManager.shared.enableAutoToolbar = true\n\n    return true\n}\n```\n\n### With All Features\n\n```swift\nimport IQKeyboardManagerSwift\n\nfunc application(_ application: UIApplication, \n                 didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?) -> Bool {\n\n    // Core functionality\n    IQKeyboardManager.shared.isEnabled = true\n    IQKeyboardManager.shared.keyboardDistance = 20.0\n    \n    // Toolbar (if using IQKeyboardToolbarManager subspec)\n    IQKeyboardManager.shared.enableAutoToolbar = true\n    \n    // Tap to resign (if using Resign subspec)\n    IQKeyboardManager.shared.resignOnTouchOutside = true\n    \n    // Appearance (if using Appearance subspec)\n    IQKeyboardManager.shared.keyboardConfiguration.overrideKeyboardAppearance = true\n    IQKeyboardManager.shared.keyboardConfiguration.keyboardAppearance = .dark\n\n    return true\n}\n```\n\n\nMigration Guide\n==========================\n- [IQKeyboardManager 2.0.0 Migration Guide](https://github.com/hackiftekhar/IQKeyboardManager/blob/master/Documentation/MIGRATION%20GUIDE%201.0%20TO%202.0.md)\n- [IQKeyboardManager 3.0.0 Migration Guide](https://github.com/hackiftekhar/IQKeyboardManager/blob/master/Documentation/MIGRATION%20GUIDE%202.0%20TO%203.0.md)\n- [IQKeyboardManager 4.0.0 Migration Guide](https://github.com/hackiftekhar/IQKeyboardManager/blob/master/Documentation/MIGRATION%20GUIDE%203.0%20TO%204.0.md)\n- [IQKeyboardManager 5.0.0 Migration Guide](https://github.com/hackiftekhar/IQKeyboardManager/blob/master/Documentation/MIGRATION%20GUIDE%204.0%20TO%205.0.md)\n- [IQKeyboardManager 6.0.0 Migration Guide](https://github.com/hackiftekhar/IQKeyboardManager/blob/master/Documentation/MIGRATION%20GUIDE%205.0%20TO%206.0.md)\n- [IQKeyboardManager 7.0.0 Migration Guide](https://github.com/hackiftekhar/IQKeyboardManager/blob/master/Documentation/MIGRATION%20GUIDE%206.0%20TO%207.0.md)\n- [IQKeyboardManager 8.0.0 Migration Guide](https://github.com/hackiftekhar/IQKeyboardManager/blob/master/Documentation/MIGRATION%20GUIDE%207.0%20TO%208.0.md)\n\nOther Links\n==========================\n\n- [Known Issues](https://github.com/hackiftekhar/IQKeyboardManager/wiki/Known-Issues)\n- [Manual Management Tweaks](https://github.com/hackiftekhar/IQKeyboardManager/wiki/Manual-Management)\n- [Properties and functions usage](https://github.com/hackiftekhar/IQKeyboardManager/wiki/Properties-&-Functions)\n\n## Dependency Diagram\n[![IQKeyboardManager Dependency Diagram](https://raw.githubusercontent.com/hackiftekhar/IQKeyboardManager/master/Screenshot/IQKeyboardManagerDependency.jpg)](https://raw.githubusercontent.com/hackiftekhar/IQKeyboardManager/master/Screenshot/IQKeyboardManagerDependency.jpg)\n\nLICENSE\n---\nDistributed under the MIT License.\n\nContributions\n---\nAny contribution is more than welcome! You can contribute through pull requests and issues on GitHub.\n\nAuthor\n---\nIf you wish to contact me, email at: hack.iftekhar@gmail.com\n",
      "stars_today": 0
    },
    {
      "id": 139910229,
      "name": "cli",
      "full_name": "npm/cli",
      "description": "the package manager for JavaScript",
      "html_url": "https://github.com/npm/cli",
      "stars": 9499,
      "forks": 4124,
      "language": "JavaScript",
      "topics": [
        "javascript",
        "nodejs",
        "npm",
        "npm-cli",
        "package-manager",
        "tools"
      ],
      "created_at": "2018-07-05T23:26:52Z",
      "updated_at": "2026-02-06T22:15:37Z",
      "pushed_at": "2026-02-06T20:15:13Z",
      "open_issues": 631,
      "owner": {
        "login": "npm",
        "avatar_url": "https://avatars.githubusercontent.com/u/6078720?v=4"
      },
      "readme": "# npm - a JavaScript package manager\n\n### Requirements\n\nYou should be running a currently supported version of [Node.js](https://nodejs.org/en/download/) to run **`npm`**.  For a list of which versions of Node.js are currently supported, please see the [Node.js releases](https://nodejs.org/en/about/previous-releases) page.\n\n### Installation\n\n**`npm`** comes bundled with [**`node`**](https://nodejs.org/), & most third-party distributions, by default. Officially supported downloads/distributions can be found at: [nodejs.org/en/download](https://nodejs.org/en/download)\n\n#### Direct Download\n\nYou can download & install **`npm`** directly from [**npmjs**.com](https://npmjs.com/) using our custom `install.sh` script:\n\n```bash\ncurl -qL https://www.npmjs.com/install.sh | sh\n```\n\n#### Node Version Managers\n\nIf you're looking to manage multiple versions of **`Node.js`** &/or **`npm`**, consider using a [node version manager](https://github.com/search?q=node+version+manager+archived%3Afalse&type=repositories&ref=advsearch)\n\n### Usage\n\n```bash\nnpm <command>\n```\n\n### Links & Resources\n\n* [**Documentation**](https://docs.npmjs.com/) - Official docs & how-tos for all things **npm**\n    * Note: you can also search docs locally with `npm help-search <query>`\n* [**Bug Tracker**](https://github.com/npm/cli/issues) - Search or submit bugs against the CLI\n* [**Community Feedback and Discussions**](https://github.com/orgs/community/discussions/categories/npm) - Contribute ideas & discussion around the npm registry, website & CLI\n* [**RFCs**](https://github.com/npm/rfcs) - Contribute ideas & specifications for the API/design of the npm CLI\n* [**Service Status**](https://status.npmjs.org/) - Monitor the current status & see incident reports for the website & registry\n* [**Project Status**](https://npm.github.io/statusboard/) - See the health of all our maintained OSS projects in one view\n* [**Support**](https://www.npmjs.com/support) - Experiencing problems with the **npm** [website](https://npmjs.com) or [registry](https://registry.npmjs.org)? [File a ticket](https://www.npmjs.com/support)\n\n### Acknowledgments\n\n* `npm` is configured to use the **npm Public Registry** at [https://registry.npmjs.org](https://registry.npmjs.org) by default; Usage of this registry is subject to **Terms of Use** available at [https://npmjs.com/policies/terms](https://npmjs.com/policies/terms)\n* You can configure `npm` to use any other compatible registry you prefer. You can read more about [configuring third-party registries](https://docs.npmjs.com/cli/v7/using-npm/registry)\n\n### FAQ on Branding\n\n#### Is it \"npm\" or \"NPM\" or \"Npm\"?\n\n**`npm`** should never be capitalized unless it is being displayed in a location that is customarily all-capitals (ex. titles on `man` pages).\n\n#### Is \"npm\" an acronym for \"Node Package Manager\"?\n\nContrary to popular belief, **`npm`** **is not** in fact an acronym for \"Node Package Manager\"; It is a recursive bacronymic abbreviation for **\"npm is not an acronym\"** (if the project was named \"ninaa\", then it would be an acronym). The precursor to **`npm`** was actually a bash utility named **\"pm\"**, which was the shortform name of **\"pkgmakeinst\"** - a bash function that installed various things on various platforms. If **`npm`** were to ever have been considered an acronym, it would be as \"node pm\" or, potentially \"new pm\".\n",
      "stars_today": 0
    },
    {
      "id": 17101828,
      "name": "swirl_courses",
      "full_name": "swirldev/swirl_courses",
      "description": ":mortar_board: A collection of interactive courses for the swirl R package.",
      "html_url": "https://github.com/swirldev/swirl_courses",
      "stars": 4520,
      "forks": 7238,
      "language": "R",
      "topics": [],
      "created_at": "2014-02-23T04:48:04Z",
      "updated_at": "2026-02-01T00:46:24Z",
      "pushed_at": "2024-01-10T17:38:19Z",
      "open_issues": 206,
      "owner": {
        "login": "swirldev",
        "avatar_url": "https://avatars.githubusercontent.com/u/5671732?v=4"
      },
      "readme": "# swirl courses\n\nThis is a collection of interactive courses for use with the [swirl R package](http://swirlstats.com). You'll find instructions for installing courses further down on this page. Some courses are still in development and we'd love to hear any [suggestions](https://github.com/swirldev/swirl_courses/issues/new) you have as you work through them.\n\nFor more information regarding swirl, visit [swirlstats.com](http://swirlstats.com) or the [swirl GitHub repository](https://github.com/swirldev/swirl). If you'd like to write your own interactive content, please visit the [Instructors page](http://swirlstats.com/instructors.html) of our website.\n\nHere are our current offerings, organized by level of difficulty:\n\n#### Beginner\n\n- **R Programming**: The basics of programming in R\n- [**R Programming E**](https://github.com/swirldev/R_Programming_E): Same as the original, but modified slightly for in-class use (see below ***)\n- [**The R Programming Environment**](https://swirlstats.com/scn/rpe.html)\n<!-- - **Data Analysis**: Basic ideas in statistics and data visualization -->\n<!-- - **Mathematical Biostatistics Boot Camp**: One- and two-sample t-tests, power, and sample size -->\n<!-- - **Open Intro**: A very basic introduction to statistics, data analysis, and data visualization -->\n\n\\*\\*\\* *R Programming E is identical to R Programming, except we've eliminated the prompts for Coursera credentials at the end of each lesson and instead give students the option to send an email to their instructor notifying them of completion. Admittedly, it's sort of a hack until we come up with a more robust solution for in-class use (i.e. an instructor \"dashboard\").*\n\n#### Intermediate\n\n- **Regression Models**: The basics of regression modeling in R\n- **Getting and Cleaning Data**: dplyr, tidyr, lubridate, oh my!\n\n#### Advanced\n\n- **Statistical Inference**: This intermediate to advanced level course closely follows the\n[Statistical Inference course](https://www.coursera.org/course/statinference) of the Johns Hopkins \n[Data Science Specialization](https://www.coursera.org/specialization/jhudatascience/1) on Coursera. It\nintroduces the student to basic concepts of statistical inference\nincluding probability, hypothesis testing, confidence intervals and\np-values. It concludes with an initiation to topics of particular\nrelevance to big data, issues of multiple testing and resampling.\n- [**Advanced R Programming**](https://swirlstats.com/scn/arp.html)\n\nSince our users come from a variety backgrounds, it's very hard to label material as **Beginner**, **Intermediate**, or **Advanced**. If you find something that is labelled **Beginner** to be challenging, please don't be discouraged. The first step of learning anything is to acknowledge that you are capable of understanding it. True understanding will come with time and practice.\n\n#### Course Authors\n\n- **Writing swirl Courses**: An interactive guides and example \n  for swirl course authors. The first group of lessons cover basics. The rest cover \n  special topics useful primarily as samples--points of departure for one's own material.\n  For more comprehensive documentation about writing your own swirl courses see http://swirlstats.com/swirlify/.\n\n## Install and run a course automatically from swirl\n\n**This is the preferred method of installing courses.** It automates the process by allowing you to do everything right from the R console.\n\n1) Make sure you have a recent version version of swirl:\n\n```\ninstall.packages(\"swirl\")\n```\n\n2) Enter the following from the R console, **substituting the name of the course** that you wish to install:\n\n```\nlibrary(swirl)\ninstall_course(\"Course Name Here\")\nswirl()\n```\n\nFor example, `install_course(\"R Programming\")` will install the R Programming course. **Please note that course names are case sensitive!**\n\nIf that doesn't work for you...\n\n## Install and run a course manually\n\nIf the automatic course installation method outlined above does not work for you, then there's a simple alternative.\n\n1. Find the course you want to install on the [Swirl Course network website](https://swirlstats.com/scn/title.html).\n2. Follow the manual installation instructions on the course page.\n\nIf that does not work for you, consider taking a look at the \n[legacy manual install instructions](https://github.com/swirldev/swirl_courses/wiki/Legacy-Manual-Install-Instructions-for-Swirl-Courses).\n\n## Uninstall a course\n\nIf you'd like to remove a course at any time, you can use `uninstall_course(\"Course Name Here\")`.\n\n## Using swirl in the classroom\n\nInstructors around the world are using swirl in their classrooms. We think this is awesome. If you're an instructor, please feel free to do the same -- free of charge. While your students may be paying to take your course or attend your institution, we simply ask that you don't charge people *directly* for the use of our software or instructional content.\n\nIf you are not sure about a particular use case, don't hesitate to post a\nquestion to our [Google Group](https://groups.google.com/forum/#!forum/swirl-discuss).\n",
      "stars_today": 0
    },
    {
      "id": 15917132,
      "name": "ProgrammingAssignment2",
      "full_name": "rdpeng/ProgrammingAssignment2",
      "description": "Repository for Programming Assignment 2 for R Programming on Coursera",
      "html_url": "https://github.com/rdpeng/ProgrammingAssignment2",
      "stars": 875,
      "forks": 143941,
      "language": "R",
      "topics": [],
      "created_at": "2014-01-14T22:07:41Z",
      "updated_at": "2026-02-04T21:47:39Z",
      "pushed_at": "2024-08-14T21:14:33Z",
      "open_issues": 4320,
      "owner": {
        "login": "rdpeng",
        "avatar_url": "https://avatars.githubusercontent.com/u/9612?v=4"
      },
      "readme": "### Introduction\n\nThis second programming assignment will require you to write an R\nfunction that is able to cache potentially time-consuming computations.\nFor example, taking the mean of a numeric vector is typically a fast\noperation. However, for a very long vector, it may take too long to\ncompute the mean, especially if it has to be computed repeatedly (e.g.\nin a loop). If the contents of a vector are not changing, it may make\nsense to cache the value of the mean so that when we need it again, it\ncan be looked up in the cache rather than recomputed. In this\nProgramming Assignment you will take advantage of the scoping rules of\nthe R language and how they can be manipulated to preserve state inside\nof an R object.\n\n### Example: Caching the Mean of a Vector\n\nIn this example we introduce the `<<-` operator which can be used to\nassign a value to an object in an environment that is different from the\ncurrent environment. Below are two functions that are used to create a\nspecial object that stores a numeric vector and caches its mean.\n\nThe first function, `makeVector` creates a special \"vector\", which is\nreally a list containing a function to\n\n1.  set the value of the vector\n2.  get the value of the vector\n3.  set the value of the mean\n4.  get the value of the mean\n\n<!-- -->\n\n    makeVector <- function(x = numeric()) {\n            m <- NULL\n            set <- function(y) {\n                    x <<- y\n                    m <<- NULL\n            }\n            get <- function() x\n            setmean <- function(mean) m <<- mean\n            getmean <- function() m\n            list(set = set, get = get,\n                 setmean = setmean,\n                 getmean = getmean)\n    }\n\nThe following function calculates the mean of the special \"vector\"\ncreated with the above function. However, it first checks to see if the\nmean has already been calculated. If so, it `get`s the mean from the\ncache and skips the computation. Otherwise, it calculates the mean of\nthe data and sets the value of the mean in the cache via the `setmean`\nfunction.\n\n    cachemean <- function(x, ...) {\n            m <- x$getmean()\n            if(!is.null(m)) {\n                    message(\"getting cached data\")\n                    return(m)\n            }\n            data <- x$get()\n            m <- mean(data, ...)\n            x$setmean(m)\n            m\n    }\n\n### Assignment: Caching the Inverse of a Matrix\n\nMatrix inversion is usually a costly computation and there may be some\nbenefit to caching the inverse of a matrix rather than computing it\nrepeatedly (there are also alternatives to matrix inversion that we will\nnot discuss here). Your assignment is to write a pair of functions that\ncache the inverse of a matrix.\n\nWrite the following functions:\n\n1.  `makeCacheMatrix`: This function creates a special \"matrix\" object\n    that can cache its inverse.\n2.  `cacheSolve`: This function computes the inverse of the special\n    \"matrix\" returned by `makeCacheMatrix` above. If the inverse has\n    already been calculated (and the matrix has not changed), then\n    `cacheSolve` should retrieve the inverse from the cache.\n\nComputing the inverse of a square matrix can be done with the `solve`\nfunction in R. For example, if `X` is a square invertible matrix, then\n`solve(X)` returns its inverse.\n\nFor this assignment, assume that the matrix supplied is always\ninvertible.\n\nIn order to complete this assignment, you must do the following:\n\n1.  Fork the GitHub repository containing the stub R files at\n    [https://github.com/rdpeng/ProgrammingAssignment2](https://github.com/rdpeng/ProgrammingAssignment2)\n    to create a copy under your own account.\n2.  Clone your forked GitHub repository to your computer so that you can\n    edit the files locally on your own machine.\n3.  Edit the R file contained in the git repository and place your\n    solution in that file (please do not rename the file).\n4.  Commit your completed R file into YOUR git repository and push your\n    git branch to the GitHub repository under your account.\n5.  Submit to Coursera the URL to your GitHub repository that contains\n    the completed R code for the assignment.\n\n### Grading\n\nThis assignment will be graded via peer assessment.\n",
      "stars_today": 0
    },
    {
      "id": 187086161,
      "name": "opentelemetry-go",
      "full_name": "open-telemetry/opentelemetry-go",
      "description": "OpenTelemetry Go API and SDK",
      "html_url": "https://github.com/open-telemetry/opentelemetry-go",
      "stars": 6271,
      "forks": 1251,
      "language": "Go",
      "topics": [
        "logging",
        "metrics",
        "opentelemetry",
        "tracing"
      ],
      "created_at": "2019-05-16T19:05:26Z",
      "updated_at": "2026-02-06T12:58:38Z",
      "pushed_at": "2026-02-06T08:59:07Z",
      "open_issues": 201,
      "owner": {
        "login": "open-telemetry",
        "avatar_url": "https://avatars.githubusercontent.com/u/49998002?v=4"
      },
      "readme": "# OpenTelemetry-Go\n\n[![ci](https://github.com/open-telemetry/opentelemetry-go/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/open-telemetry/opentelemetry-go/actions/workflows/ci.yml)\n[![codecov.io](https://codecov.io/gh/open-telemetry/opentelemetry-go/coverage.svg?branch=main)](https://app.codecov.io/gh/open-telemetry/opentelemetry-go?branch=main)\n[![PkgGoDev](https://pkg.go.dev/badge/go.opentelemetry.io/otel)](https://pkg.go.dev/go.opentelemetry.io/otel)\n[![Go Report Card](https://goreportcard.com/badge/go.opentelemetry.io/otel)](https://goreportcard.com/report/go.opentelemetry.io/otel)\n[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/open-telemetry/opentelemetry-go/badge)](https://scorecard.dev/viewer/?uri=github.com/open-telemetry/opentelemetry-go)\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/9996/badge)](https://www.bestpractices.dev/projects/9996)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/opentelemetry-go.svg)](https://issues.oss-fuzz.com/issues?q=project:opentelemetry-go)\n[![FOSSA Status](https://app.fossa.com/api/projects/custom%2B162%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-go.svg?type=shield&issueType=license)](https://app.fossa.com/projects/custom%2B162%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-go?ref=badge_shield&issueType=license)\n[![Slack](https://img.shields.io/badge/slack-@cncf/otel--go-brightgreen.svg?logo=slack)](https://cloud-native.slack.com/archives/C01NPAXACKT)\n\nOpenTelemetry-Go is the [Go](https://golang.org/) implementation of [OpenTelemetry](https://opentelemetry.io/).\nIt provides a set of APIs to directly measure performance and behavior of your software and send this data to observability platforms.\n\n## Project Status\n\n| Signal  | Status             |\n|---------|--------------------|\n| Traces  | Stable             |\n| Metrics | Stable             |\n| Logs    | Beta[^1]           |\n\nProgress and status specific to this repository is tracked in our\n[project boards](https://github.com/open-telemetry/opentelemetry-go/projects)\nand\n[milestones](https://github.com/open-telemetry/opentelemetry-go/milestones).\n\nProject versioning information and stability guarantees can be found in the\n[versioning documentation](VERSIONING.md).\n\n[^1]: https://github.com/orgs/open-telemetry/projects/43\n\n### Compatibility\n\nOpenTelemetry-Go ensures compatibility with the current supported versions of\nthe [Go language](https://golang.org/doc/devel/release#policy):\n\n> Each major Go release is supported until there are two newer major releases.\n> For example, Go 1.5 was supported until the Go 1.7 release, and Go 1.6 was supported until the Go 1.8 release.\n\nFor versions of Go that are no longer supported upstream, opentelemetry-go will\nstop ensuring compatibility with these versions in the following manner:\n\n- A minor release of opentelemetry-go will be made to add support for the new\n  supported release of Go.\n- The following minor release of opentelemetry-go will remove compatibility\n  testing for the oldest (now archived upstream) version of Go. This, and\n  future, releases of opentelemetry-go may include features only supported by\n  the currently supported versions of Go.\n\nCurrently, this project supports the following environments.\n\n| OS       | Go Version | Architecture |\n|----------|------------|--------------|\n| Ubuntu   | 1.25       | amd64        |\n| Ubuntu   | 1.24       | amd64        |\n| Ubuntu   | 1.25       | 386          |\n| Ubuntu   | 1.24       | 386          |\n| Ubuntu   | 1.25       | arm64        |\n| Ubuntu   | 1.24       | arm64        |\n| macOS    | 1.25       | amd64        |\n| macOS    | 1.24       | amd64        |\n| macOS    | 1.25       | arm64        |\n| macOS    | 1.24       | arm64        |\n| Windows  | 1.25       | amd64        |\n| Windows  | 1.24       | amd64        |\n| Windows  | 1.25       | 386          |\n| Windows  | 1.24       | 386          |\n\nWhile this project should work for other systems, no compatibility guarantees\nare made for those systems currently.\n\n## Getting Started\n\nYou can find a getting started guide on [opentelemetry.io](https://opentelemetry.io/docs/languages/go/getting-started/).\n\nOpenTelemetry's goal is to provide a single set of APIs to capture distributed\ntraces and metrics from your application and send them to an observability\nplatform. This project allows you to do just that for applications written in\nGo. There are two steps to this process: instrument your application, and\nconfigure an exporter.\n\n### Instrumentation\n\nTo start capturing distributed traces and metric events from your application\nit first needs to be instrumented. The easiest way to do this is by using an\ninstrumentation library for your code. Be sure to check out [the officially\nsupported instrumentation\nlibraries](https://github.com/open-telemetry/opentelemetry-go-contrib/tree/main/instrumentation).\n\nIf you need to extend the telemetry an instrumentation library provides or want\nto build your own instrumentation for your application directly you will need\nto use the\n[Go otel](https://pkg.go.dev/go.opentelemetry.io/otel)\npackage. The [examples](https://github.com/open-telemetry/opentelemetry-go-contrib/tree/main/examples)\nare a good way to see some practical uses of this process.\n\n### Export\n\nNow that your application is instrumented to collect telemetry, it needs an\nexport pipeline to send that telemetry to an observability platform.\n\nAll officially supported exporters for the OpenTelemetry project are contained in the [exporters directory](./exporters).\n\n| Exporter                              | Logs | Metrics | Traces |\n|---------------------------------------|:----:|:-------:|:------:|\n| [OTLP](./exporters/otlp/)             |  âœ“   |    âœ“    |   âœ“    |\n| [Prometheus](./exporters/prometheus/) |      |    âœ“    |        |\n| [stdout](./exporters/stdout/)         |  âœ“   |    âœ“    |   âœ“    |\n| [Zipkin](./exporters/zipkin/)         |      |         |   âœ“    |\n\n## Contributing\n\nSee the [contributing documentation](CONTRIBUTING.md).\n",
      "stars_today": 0
    },
    {
      "id": 312716297,
      "name": "DefiLlama-Adapters",
      "full_name": "DefiLlama/DefiLlama-Adapters",
      "description": null,
      "html_url": "https://github.com/DefiLlama/DefiLlama-Adapters",
      "stars": 1116,
      "forks": 6896,
      "language": "JavaScript",
      "topics": [],
      "created_at": "2020-11-14T00:41:54Z",
      "updated_at": "2026-02-06T19:07:18Z",
      "pushed_at": "2026-02-06T19:07:24Z",
      "open_issues": 142,
      "owner": {
        "login": "DefiLlama",
        "avatar_url": "https://avatars.githubusercontent.com/u/82048198?v=4"
      },
      "readme": "# Defillama Adapters\n\nFollow [this guide](https://docs.llama.fi/submit-a-project) to create an adapter and submit a PR with it.\n\nAlso, don't hesitate to send a message on [our discord](https://discord.defillama.com/) if we're late to merge your PR.\n\n> If you would like to add a `volume` adapter please submit the PR [here](https://github.com/DefiLlama/adapters)\n> - If you would like to add a `liquidations` adapter, please refer to [this readme document](https://github.com/DefiLlama/DefiLlama-Adapters/tree/main/liquidations) for details.\n\n1. PLEASE PLEASE **enable \"Allow edits by maintainers\" while putting up the PR.**\n2. Once your adapter has been merged, it takes time to show on the UI. No need to notify us on Discord.\n3. TVL must be computed from blockchain data (reason: https://github.com/DefiLlama/DefiLlama-Adapters/discussions/432), if you have trouble with creating the adapter, please hop onto our discord, we are happy to assist you.\n4. **For updating listing info** It is a different repo, you can find your listing in this file: https://github.com/DefiLlama/defillama-server/blob/master/defi/src/protocols/data2.ts, you can  edit it there and put up a PR\n5. Do not edit/push `package-lock.json` file as part of your changes, we use lockfileVersion 2, and most use v1 and using that messes up our CI\n6. No need to go to our discord and announce that you've created a PR, we monitor all PRs and will review it asap\n\n## Getting listed\n\nPlease send answers to questions there https://github.com/DefiLlama/DefiLlama-Adapters/blob/main/pull_request_template.md when creating a PR.\n\n## Work in progress\n\nThis is a work in progress. DefiLlama aims to be transparent, accurate, and open source.\n\nIf you have any suggestions, want to contribute or want to chat, please join [our discord](https://discord.defillama.com/) and drop a message.\n\n## Testing adapters\n```bash\nnode test.js projects/pangolin/index.js\n# Add a timestamp at the end to run the adapter at a historical timestamp\nnode test.js projects/aave/v3.js 1729080692\n# or using YYYY-MM-DD\nnode test.js projects/aave/v3.js 2024-10-16\n```\n\n## Changing RPC providers\nIf you want to change RPC providers because you need archive node access or because the default ones don't work well enough you can do so by creating an `.env` file and filling it with the env variables to overwrite:\n```\nETHEREUM_RPC=\"...\"\nBSC_RPC=\"...\"\nPOLYGON_RPC=\"...\"\n```\n\nThe name of each rpc is `{CHAIN-NAME}_RPC`, and the name we use for each chain can be found [here](https://unpkg.com/@defillama/sdk@latest/build/providers.json). If you run into issues with a chain make sure to update the sdk with `npm update @defillama/sdk`.\n\n## Adapter rules\n- Never add extra npm packages, if you need a chain-level package for your chain, ask us, and we'll consider it, but we can't accept any npm package that is project-specific\n",
      "stars_today": 0
    },
    {
      "id": 156021487,
      "name": "fabric-example-mod",
      "full_name": "FabricMC/fabric-example-mod",
      "description": "Example Fabric mod",
      "html_url": "https://github.com/FabricMC/fabric-example-mod",
      "stars": 2106,
      "forks": 1224,
      "language": "Java",
      "topics": [
        "fabric"
      ],
      "created_at": "2018-11-03T20:32:07Z",
      "updated_at": "2026-02-07T01:32:55Z",
      "pushed_at": "2025-12-09T18:36:28Z",
      "open_issues": 9,
      "owner": {
        "login": "FabricMC",
        "avatar_url": "https://avatars.githubusercontent.com/u/21025855?v=4"
      },
      "readme": "# Fabric Example Mod\n\n## Setup\n\nFor setup instructions please see the [fabric documentation page](https://docs.fabricmc.net/develop/getting-started/setting-up) that relates to the IDE that you are using.\n\n## License\n\nThis template is available under the CC0 license. Feel free to learn from it and incorporate it in your own projects.\n",
      "stars_today": 0
    },
    {
      "id": 30017750,
      "name": "ComplexHeatmap",
      "full_name": "jokergoo/ComplexHeatmap",
      "description": "Make Complex Heatmaps ",
      "html_url": "https://github.com/jokergoo/ComplexHeatmap",
      "stars": 1465,
      "forks": 241,
      "language": "R",
      "topics": [
        "clustering",
        "complex-heatmaps",
        "heatmap"
      ],
      "created_at": "2015-01-29T11:45:58Z",
      "updated_at": "2026-02-04T06:22:25Z",
      "pushed_at": "2026-01-30T06:23:15Z",
      "open_issues": 228,
      "owner": {
        "login": "jokergoo",
        "avatar_url": "https://avatars.githubusercontent.com/u/449218?v=4"
      },
      "readme": "# Make Complex Heatmaps <a href=\"https://jokergoo.github.io/ComplexHeatmap-reference/book/\"><img src=\"https://jokergoo.github.io/ComplexHeatmap-reference/book/complexheatmap-cover.jpg\" width=240 align=\"right\" style=\"border:2px solid black;\" ></a>\n\n[![R-CMD-check](https://github.com/jokergoo/ComplexHeatmap/workflows/R-CMD-check/badge.svg)](https://github.com/jokergoo/ComplexHeatmap/actions)\n[![codecov](https://img.shields.io/codecov/c/github/jokergoo/ComplexHeatmap.svg)](https://codecov.io/github/jokergoo/ComplexHeatmap) \n[![bioc](http://www.bioconductor.org/shields/downloads/devel/ComplexHeatmap.svg)](https://bioconductor.org/packages/stats/bioc/ComplexHeatmap/) \n[![bioc](http://www.bioconductor.org/shields/years-in-bioc/ComplexHeatmap.svg)](http://bioconductor.org/packages/devel/bioc/html/ComplexHeatmap.html)\n\n<img src=\"http://jokergoo.github.io/complexheatmap_logo.svg\" width=\"550\">\n\n\nComplex heatmaps are efficient to visualize associations between different\nsources of data sets and reveal potential patterns. Here the\n**ComplexHeatmap** package provides a highly flexible way to arrange multiple\nheatmaps and supports various annotation graphics.\n\nThe [**InteractiveComplexHeatmap**](https://github.com/jokergoo/InteractiveComplexHeatmap) package can directly export static complex heatmaps into an interactive Shiny app. Have a try!\n\n## Citation\n\nZuguang Gu, et al., [Complex heatmaps reveal patterns and correlations in multidimensional genomic data](http://bioinformatics.oxfordjournals.org/content/early/2016/05/20/bioinformatics.btw313.abstract), Bioinformatics, 2016.\n\nZuguang Gu. [Complex Heatmap Visualization](https://doi.org/10.1002/imt2.43), iMeta, 2022. \n\n\n## Install\n\n`ComplexHeatmap` is available on [Bioconductor](http://www.bioconductor.org/packages/devel/bioc/html/ComplexHeatmap.html), you can install it by:\n\n```r\nif (!requireNamespace(\"BiocManager\", quietly=TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"ComplexHeatmap\")\n```\n\nIf you want the latest version, install it directly from GitHub:\n\n```r\nlibrary(devtools)\ninstall_github(\"jokergoo/ComplexHeatmap\")\n```\n\n## Usage\n\nMake a single heatmap:\n\n```r\nHeatmap(mat, ...)\n```\n\nA single Heatmap with column annotations:\n\n```r\nha = HeatmapAnnotation(df = anno1, anno_fun = anno2, ...)\nHeatmap(mat, ..., top_annotation = ha)\n```\n\nMake a list of heatmaps:\n\n```r\nHeatmap(mat1, ...) + Heatmap(mat2, ...)\n```\n\nMake a list of heatmaps and row annotations:\n\n```r\nha = HeatmapAnnotation(df = anno1, anno_fun = anno2, ..., which = \"row\")\nHeatmap(mat1, ...) + Heatmap(mat2, ...) + ha\n```\n\n## Documentation\n\nThe full documentations are available at https://jokergoo.github.io/ComplexHeatmap-reference/book/ and the website is at https://jokergoo.github.io/ComplexHeatmap.\n\n## Blog posts\n\nThere are following blog posts focusing on specific topics:\n\n- [Make 3D heatmap](https://jokergoo.github.io/2021/03/24/3d-heatmap/)\n- [Translate from pheatmap to ComplexHeatmap](https://jokergoo.github.io/2020/05/06/translate-from-pheatmap-to-complexheatmap/)\n- [Set cell width/height in the heatmap](https://jokergoo.github.io/2020/05/11/set-cell-width/height-in-the-heatmap/)\n- [Interactive ComplexHeatmap](https://jokergoo.github.io/2020/05/15/interactive-complexheatmap/)\n- [Word cloud as heatmap annotation](https://jokergoo.github.io/2020/05/31/word-cloud-as-heatmap-annotation/)\n- [Which heatmap function is faster?](https://jokergoo.github.io/2020/06/19/which-heatmap-function-is-faster/)\n- [Rasterization in ComplexHeatmap](https://jokergoo.github.io/2020/06/30/rasterization-in-complexheatmap/)\n- [Block annotation over several slices](https://jokergoo.github.io/2020/07/06/block-annotation-over-several-slices/)\n- [Integrate ComplexHeatmap with cowplot package](https://jokergoo.github.io/2020/07/14/integrate-complexheatmap-with-cowplot-package/)\n\n\n## Examples\n\n### Visualize Methylation Profile with Complex Annotations\n\n![complexheatmap_example4](https://user-images.githubusercontent.com/449218/47718635-2ec22980-dc49-11e8-9f01-37becb19e0d5.png)\n\n### Correlations between methylation, expression and other genomic features\n\n![complexheatmap_example3](https://user-images.githubusercontent.com/449218/47718636-2ec22980-dc49-11e8-8db0-1659c27dcf40.png)\n\n### Visualize Cell Heterogeneity from Single Cell RNASeq\n\n![complexheatmap_example2](https://user-images.githubusercontent.com/449218/47718637-2ec22980-dc49-11e8-925e-955c16cfa982.png)\n\n### Making Enhanced OncoPrint\n\n![complexheatmap_example1](https://user-images.githubusercontent.com/449218/47718638-2ec22980-dc49-11e8-845e-21e51d3b8e73.png)\n\n### UpSet plot\n\n<img src=\"https://user-images.githubusercontent.com/449218/102615477-48c76a80-4136-11eb-98d9-3c528844fbe8.png\" width=500 />\n\n### 3D heatmap\n\n![image](https://user-images.githubusercontent.com/449218/112284448-8c77c600-8c89-11eb-8d38-c5538900df20.png)\n\n\n\n## License\n\nMIT @ Zuguang Gu\n\n",
      "stars_today": 0
    },
    {
      "id": 20360040,
      "name": "clusterProfiler",
      "full_name": "YuLab-SMU/clusterProfiler",
      "description": ":bar_chart: A universal enrichment tool for interpreting omics data",
      "html_url": "https://github.com/YuLab-SMU/clusterProfiler",
      "stars": 1164,
      "forks": 264,
      "language": "R",
      "topics": [
        "enrichment-analysis",
        "go",
        "gsea",
        "kegg",
        "rstats",
        "visualization"
      ],
      "created_at": "2014-05-31T16:34:32Z",
      "updated_at": "2026-02-07T01:57:22Z",
      "pushed_at": "2026-02-05T13:26:17Z",
      "open_issues": 362,
      "owner": {
        "login": "YuLab-SMU",
        "avatar_url": "https://avatars.githubusercontent.com/u/40430016?v=4"
      },
      "readme": "# clusterProfiler\n\n<img src=\"inst/sticker/clusterProfiler_hex.png\" height=\"200\" align=\"right\" />\n\n[![Project Status: Active - The project has reached a stable, usable\nstate and is being actively\ndeveloped.](http://www.repostatus.org/badges/latest/active.svg)](http://www.repostatus.org/#active)\n[![](https://img.shields.io/badge/release%20version-4.18.4-green.svg)](https://www.bioconductor.org/packages/clusterProfiler)\n[![](https://img.shields.io/badge/devel%20version-4.19.4.006-green.svg)](https://github.com/guangchuangyu/clusterProfiler)\n[![Bioc](http://www.bioconductor.org/shields/years-in-bioc/clusterProfiler.svg)](https://www.bioconductor.org/packages/devel/bioc/html/clusterProfiler.html#since)\n\n[![platform](http://www.bioconductor.org/shields/availability/devel/clusterProfiler.svg)](https://www.bioconductor.org/packages/devel/bioc/html/clusterProfiler.html#archives)\n[![Build\nStatus](http://www.bioconductor.org/shields/build/devel/bioc/clusterProfiler.svg)](https://bioconductor.org/checkResults/devel/bioc-LATEST/clusterProfiler/)\n[![codecov](https://codecov.io/gh/GuangchuangYu/clusterProfiler/branch/master/graph/badge.svg)](https://codecov.io/gh/GuangchuangYu/clusterProfiler/)\n\n<!--\n[![Last-changedate](https://img.shields.io/badge/last%20change-2026--01--21-green.svg)](https://github.com/GuangchuangYu/clusterProfiler/commits/master)\n-->\n\n- [clusterProfiler](http://bioconductor.org/packages/clusterProfiler)\n  supports exploring functional characteristics of both coding and\n  non-coding genomics data for thousands of species with up-to-date gene\n  annotation.\n- It provides a universal interface for gene functional annotation from\n  a variety of sources and thus can be applied in diverse scenarios.\n- It provides a tidy interface to access, manipulate, and visualize\n  enrichment results to help users achieve efficient data interpretation\n- Datasets obtained from multiple treatments and time points can be\n  analyzed and compared in a single run, easily revealing functional\n  consensus and differences among distinct conditions\n\nFor details, please visit:\n\n- <https://yulab-smu.top/contribution-knowledge-mining/>\n- <https://yulab-smu.top/biomedical-knowledge-mining-book/>\n\n<img src=\"graphic-abstract-The-Innovation-2021.jpg\" width=\"890\"/>\n\n## :writing_hand: Authors\n\nGuangchuang YU <https://yulab-smu.top>\n\nSchool of Basic Medical Sciences, Southern Medical University\n\n------------------------------------------------------------------------\n\nIf you use\n[clusterProfiler](http://bioconductor.org/packages/clusterProfiler) in\npublished research, please cite the most appropriate paper(s) from this\nlist:\n\n1.  S Xu<sup>\\#</sup>, E Hu<sup>\\#</sup>, Y Cai<sup>\\#</sup>, Z\n    Xie<sup>\\#</sup>, X Luo<sup>\\#</sup>, L Zhan, W Tang, Q Wang, B Liu,\n    R Wang, W Xie, T Wu, L Xie, **G Yu**<sup>\\*</sup>. Using\n    clusterProfiler to characterise Multi-Omics Data. ***Nature\n    Protocols***. 2024, accepted. doi:\n    [10.1038/s41596-024-01020-z](https://doi.org/10.1038/s41596-024-01020-z)\n2.  T Wu<sup>\\#</sup>, E Hu<sup>\\#</sup>, S Xu, M Chen, P Guo, Z Dai, T\n    Feng, L Zhou, W Tang, L Zhan, X Fu, S Liu, X Bo<sup>\\*</sup>, **G\n    Yu**<sup>\\*</sup>. clusterProfiler 4.0: A universal enrichment tool\n    for interpreting omics data. ***The Innovation***. 2021,\n    2(3):100141. doi:\n    [10.1016/j.xinn.2021.100141](https://doi.org/10.1016/j.xinn.2021.100141)\n3.  **G Yu**<sup>\\*</sup>. Gene Ontology Semantic Similarity Analysis\n    Using GOSemSim. In: Kidder B. (eds) Stem Cell Transcriptional\n    Networks. ***Methods in Molecular Biology***. 2020, 2117:207-215.\n    Humana, New York, NY. doi:\n    [10.1007/978-1-0716-0301-7_11](https://doi.org/10.1007/978-1-0716-0301-7_11)\n4.  **G Yu**<sup>\\*</sup>. Using meshes for MeSH term enrichment and\n    semantic analyses. ***Bioinformatics***. 2018, 34(21):3766â€“3767.\n    doi:\n    [10.1093/bioinformatics/bty410](https://doi.org/10.1093/bioinformatics/bty410)\n5.  **G Yu**, QY He<sup>\\*</sup>. ReactomePA: an R/Bioconductor package\n    for reactome pathway analysis and visualization. ***Molecular\n    BioSystems***. 2016, 12(2):477-479. doi:\n    [10.1039/C5MB00663E](https://doi.org/10.1039/C5MB00663E)\n6.  **G Yu**<sup>\\*</sup>, LG Wang, and QY He<sup>\\*</sup>. ChIPseeker:\n    an R/Bioconductor package for ChIP peak annotation, comparison and\n    visualization. ***Bioinformatics***. 2015, 31(14):2382-2383. doi:\n    [10.1093/bioinformatics/btv145](https://doi.org/10.1093/bioinformatics/btv145)\n7.  **G Yu**<sup>\\*</sup>, LG Wang, GR Yan, QY He<sup>\\*</sup>. DOSE: an\n    R/Bioconductor package for Disease Ontology Semantic and Enrichment\n    analysis. ***Bioinformatics***. 2015, 31(4):608-609. doi:\n    [10.1093/bioinformatics/btu684](https://doi.org/10.1093/bioinformatics/btu684)\n8.  **G Yu**, LG Wang, Y Han and QY He<sup>\\*</sup>. clusterProfiler: an\n    R package for comparing biological themes among gene clusters.\n    ***OMICS: A Journal of Integrative Biology***. 2012, 16(5):284-287.\n    doi: [10.1089/omi.2011.0118](https://doi.org/10.1089/omi.2011.0118)\n9.  **G Yu**, F Li, Y Qin, X Bo<sup>\\*</sup>, Y Wu, S Wang<sup>\\*</sup>.\n    GOSemSim: an R package for measuring semantic similarity among GO\n    terms and gene products. ***Bioinformatics***. 2010, 26(7):976-978.\n    doi:\n    [10.1093/bioinformatics/btq064](https://doi.org/10.1093/bioinformatics/btq064)\n\n<!--\n&#10;\n&#10; r badge_custom(\"1st most cited paper\", \"in OMICS\", \"green\",\n  \"http://online.liebertpub.com/action/showMostCitedArticles?journalCode=omi\")`\n r badge_custom(\"ESI\", \"Highly Cited Paper\", \"green\")`\n r badge_doi(\"10.1089/omi.2011.0118\", \"green\")`\n&#10;\n------------------------------------------------------------------------\n&#10;### Citation\n&#10;\n&#10;\n<img src=\"https://guangchuangyu.github.io/software/citation_trend/clusterProfiler.png\" width=\"890\"/>\n&#10;\n### Download stats\n&#10;r badge_download_bioc(\"clusterProfiler\")\nr badge_bioc_download(\"clusterProfiler\", \"total\", \"blue\")\nr badge_bioc_download(\"clusterProfiler\", \"month\", \"blue\")\n&#10;\n<img src=\"https://guangchuangyu.github.io/software/dlstats/clusterProfiler.png\" width=\"890\"/>\n&#10;-->\n",
      "stars_today": 0
    },
    {
      "id": 695166275,
      "name": "unitree_sdk2",
      "full_name": "unitreerobotics/unitree_sdk2",
      "description": "Unitree robot sdk version 2. https://support.unitree.com/home/zh/developer",
      "html_url": "https://github.com/unitreerobotics/unitree_sdk2",
      "stars": 879,
      "forks": 283,
      "language": "C++",
      "topics": [],
      "created_at": "2023-09-22T13:54:21Z",
      "updated_at": "2026-02-06T18:29:19Z",
      "pushed_at": "2026-01-05T02:26:35Z",
      "open_issues": 11,
      "owner": {
        "login": "unitreerobotics",
        "avatar_url": "https://avatars.githubusercontent.com/u/44998897?v=4"
      },
      "readme": "# unitree_sdk2\nUnitree robot sdk version 2.\n\n### Prebuild environment\n* OS  (Ubuntu 20.04 LTS)  \n* CPU  (aarch64 and x86_64)   \n* Compiler  (gcc version 9.4.0) \n\n### Environment Setup\n\nBefore building or running the SDK, ensure the following dependencies are installed:\n\n- CMake (version 3.10 or higher)\n- GCC (version 9.4.0)\n- Make\n\nYou can install the required packages on Ubuntu 20.04 with:\n\n```bash\napt-get update\napt-get install -y cmake g++ build-essential libyaml-cpp-dev libeigen3-dev libboost-all-dev libspdlog-dev libfmt-dev\n```\n\n### Build examples\n\nTo build the examples inside this repository:\n\n```bash\nmkdir build\ncd build\ncmake ..\nmake\n```\n\n### Installation\n\nTo build your own application with the SDK, you can install the unitree_sdk2 to your system directory:\n\n```bash\nmkdir build\ncd build\ncmake ..\nsudo make install\n```\n\nOr install unitree_sdk2 to a specified directory:\n\n```bash\nmkdir build\ncd build\ncmake .. -DCMAKE_INSTALL_PREFIX=/opt/unitree_robotics\nsudo make install\n```\n\nYou can refer to `example/cmake_sample` on how to import the unitree_sdk2 into your CMake project. \n\nNote that if you install the library to other places other than `/opt/unitree_robotics`, you need to make sure the path is added to \"${CMAKE_PREFIX_PATH}\" so that cmake can find it with \"find_package()\".\n\n### Notice\nFor more reference information, please go to [Unitree Document Center](https://support.unitree.com/home/zh/developer).\n",
      "stars_today": 0
    },
    {
      "id": 259225467,
      "name": "CellChat",
      "full_name": "sqjin/CellChat",
      "description": "R toolkit for inference, visualization and analysis of cell-cell communication from single-cell data",
      "html_url": "https://github.com/sqjin/CellChat",
      "stars": 760,
      "forks": 168,
      "language": "R",
      "topics": [
        "cell-cell-communication",
        "cell-cell-interaction",
        "microenvironment",
        "single-cell-analysis"
      ],
      "created_at": "2020-04-27T06:28:33Z",
      "updated_at": "2026-02-05T09:21:26Z",
      "pushed_at": "2024-01-06T18:23:14Z",
      "open_issues": 455,
      "owner": {
        "login": "sqjin",
        "avatar_url": "https://avatars.githubusercontent.com/u/32399212?v=4"
      },
      "readme": "\n<p align=\"center\">\n  <img width=\"200\"  src=\"https://github.com/sqjin/CellChat/blob/master/CellChat_Logo.png\">\n</p>\n\n# CAUTION\nWe have updated CellChat to v2 and migrated CellChat to a new repository. This repository will be NOT updated and maintained any more. Please check the new repository [jinworks/CellChat](https://github.com/jinworks/CellChat) for the new updates, and the [CellChat v2 paper](https://biorxiv.org/cgi/content/short/2023.11.05.565674v1) for a comprehensive protocol of CellChat.  \n\n# About CellChat and CellChatDB\nCellChat is an R package designed for inference, analysis, and visualization of cell-cell communication from single-cell data. CellChat aims to enable users to identify and interpret cell-cell communication within an easily interpretable framework, with the emphasis of clear, attractive, and interpretable visualizations.  \n\nCellChatDB is a manually curated database of literature-supported ligand-receptor interactions in mutiple species, leading to a comprehensive recapitulation of known molecular interaction mechanisms including multi-subunit structure of ligand-receptor complexes and co-factors.\n\nIf you use CellChat in your research, please considering citing our papers: \n- [Suoqin Jin et al., CellChat for systematic analysis of cell-cell communication from single-cell and spatially resolved transcriptomics, bioRxiv 2023](https://biorxiv.org/cgi/content/short/2023.11.05.565674v1) [CellChat v2]\n- [Suoqin Jin et al., Inference and analysis of cell-cell communication using CellChat, Nature Communications 2021](https://www.nature.com/articles/s41467-021-21246-9) [CellChat v1]\n\n# Capabilities\nIn addition to infer the intercellular communication from any given single-cell data, CellChat provides functionality for further data exploration, analysis, and visualization. \n\n- It can quantitatively characterize and compare the inferred cell-cell communication networks using a systems approach by combining social network analysis, pattern recognition, and manifold learning approaches.\n- It provides an easy-to-use tool for extracting and visualizing high-order information of the inferred networks. For example, it allows ready prediction of major signaling inputs and outputs for all cell populations and how these populations and signals coordinate together for functions.\n- It enables comparative analysis of cell-cell communication across different conditions and identification of altered signaling and cell populations. \n- It provides several visualization outputs to facilitate intuitive user-guided data interpretation.\n\n<p align=\"center\">\n  <img width=\"700\"  src=\"https://github.com/sqjin/CellChat/blob/master/overview_CellChat.png\">\n</p>\n\n\n<p align=\"center\">\n  <a href=\"https://clustrmaps.com/site/1bpq2\">\n     <img width=\"200\"  src=\"https://clustrmaps.com/map_v2.png?cl=ffffff&w=a&t=n&d=42WqeykSXznN_NSaBlpf6CtSXQxhqmIs6QusUsguFdY\" />\n   </a>\n</p>\n<p align=\"center\">\n  <a href=\"#\">\n     <img src=\"https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fsqjin%2FCellChat&labelColor=%233499cc&countColor=%2370c168\" />\n   </a>\n</p>\n\n\n\n\n\n",
      "stars_today": 0
    },
    {
      "id": 2188402,
      "name": "phyloseq",
      "full_name": "joey711/phyloseq",
      "description": "phyloseq is a set of classes, wrappers, and tools (in R) to make it easier to import, store, and analyze phylogenetic sequencing data; and to reproducibly share that data and analysis with others. See the phyloseq front page:",
      "html_url": "https://github.com/joey711/phyloseq",
      "stars": 638,
      "forks": 193,
      "language": "R",
      "topics": [],
      "created_at": "2011-08-11T00:16:34Z",
      "updated_at": "2026-02-07T02:08:40Z",
      "pushed_at": "2024-04-29T20:03:19Z",
      "open_issues": 765,
      "owner": {
        "login": "joey711",
        "avatar_url": "https://avatars.githubusercontent.com/u/841437?v=4"
      },
      "readme": "<link href=\"http://joey711.github.com/phyloseq/markdown.css\" rel=\"stylesheet\"></link>\n\n# [phyloseq](http://joey711.github.com/phyloseq/)\n\n[![Travis-CI Build Status](https://travis-ci.org/joey711/phyloseq.svg?branch=master)](https://travis-ci.org/joey711/phyloseq)\n\n![phyloseq](inst/extdata/phyloseq.png)\n\n## Quick Install\n\nIn R terminal:\n\n```\nif(!requireNamespace(\"BiocManager\")){\n  install.packages(\"BiocManager\")\n}\nBiocManager::install(\"phyloseq\")\n```\n\nSee [the phyloseq installation page](http://joey711.github.io/phyloseq/install.html)\nfor further details, examples.\n\n## Article on Improved Microbiome Analysis\n\nMcMurdie and Holmes (2014)\n[Waste Not, Want Not: Why Rarefying Microbiome Data is Statistically Inadmissible](http://dx.plos.org/10.1371/journal.pcbi.1003531)\n*PLoS Computational Biology*\n10(4): e1003531\n\nPresubmission versions ahead of acceptance (2013):\n[PDF version 2](http://arxiv.org/pdf/1310.0424v2.pdf),\n[PDF version 1](http://arxiv.org/pdf/1310.0424v1.pdf)\n\n\n## Peer-reviewed articles about phyloseq\n\nMcMurdie and Holmes (2014) [Shiny-phyloseq: Web Application for Interactive Microbiome Analysis with Provenance Tracking](http://bioinformatics.oxfordjournals.org/content/early/2014/10/02/bioinformatics.btu616).\n*Bioinformatics (Oxford, England)*\n31(2), 282â€“283.\n\nMcMurdie and Holmes (2013)\n[phyloseq: An R package for reproducible interactive analysis and graphics of microbiome census data](http://dx.plos.org/10.1371/journal.pone.0061217)\n*PLoS ONE* \n8(4):e61217\n\n## Other resources\n\nThe phyloseq project also has a number of supporting online resources,\nincluding (but probably not limited to)\n\n### [the phyloseq home page](http://joey711.github.com/phyloseq/)\n\n### [the phyloseq FAQ](https://www.bioconductor.org/packages/release/bioc/vignettes/phyloseq/inst/doc/phyloseq-FAQ.html)\nI recommend checking this page, and the issues tracker,\nbefore posting new issues.\n\n### [Bioconductor stable release](http://bioconductor.org/packages/release/bioc/html/phyloseq.html).\n\n### [the phyloseq Issue Tracker](https://github.com/joey711/phyloseq/issues)\nThis is the recommended location to post\n\n(1) feature requests\n(2) bug reports\n(3) theoretical considerations\n(4) other issues, feedback\n(5) ask for help\n\nSearch previous posts,\nand check [the phyloseq FAQ](https://www.bioconductor.org/packages/release/bioc/vignettes/phyloseq/inst/doc/phyloseq-FAQ.html)\nbefore posting a new issue.\n",
      "stars_today": 0
    },
    {
      "id": 53894616,
      "name": "infercnv",
      "full_name": "broadinstitute/infercnv",
      "description": "Inferring CNV from Single-Cell RNA-Seq",
      "html_url": "https://github.com/broadinstitute/infercnv",
      "stars": 650,
      "forks": 176,
      "language": "R",
      "topics": [],
      "created_at": "2016-03-14T21:53:54Z",
      "updated_at": "2026-01-20T07:04:11Z",
      "pushed_at": "2025-11-14T17:35:17Z",
      "open_issues": 237,
      "owner": {
        "login": "broadinstitute",
        "avatar_url": "https://avatars.githubusercontent.com/u/393552?v=4"
      },
      "readme": "\n***********************************************\n>InferCNV is no longer supported. Please explore alternatives such as InferCNA (https://jlaffy.github.io/infercna/)[https://jlaffy.github.io/infercna/], CopyKAT (https://github.com/navinlabcode/copykat)[https://github.com/navinlabcode/copykat], and Numbat (https://github.com/kharchenkolab/numbat)[https://github.com/kharchenkolab/numbat]\n***********************************************\n\n# Subclustering\n\nSubclustering resolution is one of the primary settings that will need to be adjusted in most runs to avoid oversplitting. The tutorial below explains how it works and details about it can also be found on the [wiki](https://github.com/broadinstitute/infercnv/wiki/infercnv-tumor-subclusters#tumor-subclustering-by-leiden-clustering-preferred).\n\n# Documentation\n### Full documentation\n\nVisit project [wiki](https://github.com/broadinstitute/inferCNV/wiki) for InferCNV documentation.\n\n\n### Infercnv video tutorial\n\nA **video** tutorial giving on overview of infercnv features and how to run an analysis can be found below **(click on the image)**:\n\n[![Tutorial: Running infercnv](http://img.youtube.com/vi/-qOcHAavZT8/0.jpg)](http://www.youtube.com/watch?v=-qOcHAavZT8 \"Tutorial: Running infercnv\")\n\n\n\n",
      "stars_today": 0
    },
    {
      "id": 28114218,
      "name": "dada2",
      "full_name": "benjjneb/dada2",
      "description": "Accurate sample inference from amplicon data with single nucleotide resolution",
      "html_url": "https://github.com/benjjneb/dada2",
      "stars": 536,
      "forks": 165,
      "language": "R",
      "topics": [
        "amplicon",
        "bioconductor",
        "bioinformatics",
        "metabarcoding",
        "metagenomics",
        "microbiome",
        "taxonomy"
      ],
      "created_at": "2014-12-17T00:53:58Z",
      "updated_at": "2026-02-02T07:43:07Z",
      "pushed_at": "2025-12-15T19:22:15Z",
      "open_issues": 197,
      "owner": {
        "login": "benjjneb",
        "avatar_url": "https://avatars.githubusercontent.com/u/5797204?v=4"
      },
      "readme": "\n[![Build Status](https://app.travis-ci.com/benjjneb/dada2.svg?branch=master)](https://app.travis-ci.com/benjjneb/dada2)\n\n# dada2\n\nExact sample inference from high-throughput amplicon data. Resolves real variants differing by as little as one nucleotide. Visit [the DADA2 website](https://benjjneb.github.io/dada2/index.html) for the most detailed and up-to-date documentation.\n\n### Installation\n\nThe dada2 package binaries are available through Bioconductor:\n\n```S\n## try http:// if https:// URLs are not supported\nif (!requireNamespace(\"BiocManager\", quietly=TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"dada2\")\n```\n\nIn order to install dada2 from source (and get the latest and greatest new features) see our [installation from source instructions](https://benjjneb.github.io/dada2/dada-installation.html).\n\n### Documentation\n\nThe [tutorial walkthrough of the DADA2 pipeline on paired end Illumina Miseq data](https://benjjneb.github.io/dada2/tutorial.html). \n\nThe [dada2 R package manual](https://www.bioconductor.org/packages/3.6/bioc/manuals/dada2/man/dada2.pdf).\n\nFurther documentation is available on [the DADA2 front page](http://benjjneb.github.io/dada2/). \n\n### DADA2 Articles\n\n[DADA2: High resolution sample inference from Illumina amplicon data. Nature Methods, 2016.](http://dx.doi.org/10.1038/nmeth.3869) [(Open Access link.)](http://rdcu.be/ipGh)\n\n[Bioconductor workflow for microbiome data analysis: from raw reads to community analyses. F1000 Research, 2016.](https://f1000research.com/articles/5-1492)\n\n[Exact sequence variants should replace operational taxonomic units in marker-gene data analysis. ISMEJ, 2017.](http://dx.doi.org/10.1038/ismej.2017.119)\n\n[High-throughput amplicon sequencing of the full-length 16S rRNA gene with single-nucleotide resolution. Nucleic Acids Research, 2019.](http://dx.doi.org/10.1093/nar/gkz569)\n\n### Other Resources\n\nPlanned feature improvements are publicly catalogued at the main DADA2 development site on github, specifically on the \"Issues\" page for DADA2:\n\nhttps://github.com/benjjneb/dada2/issues\n\nIf the feature you are hoping for is not listed, you are welcome to add it as a feature request \"issue\" on this page. This request will be publicly available and listed on the page.\n\nBugs and difficulties in using DADA2 are also welcome on [the issue tracker](https://github.com/benjjneb/dada2/issues).\n",
      "stars_today": 0
    },
    {
      "id": 138660553,
      "name": "DoubletFinder",
      "full_name": "chris-mcginnis-ucsf/DoubletFinder",
      "description": "R package for detecting doublets in single-cell RNA sequencing data",
      "html_url": "https://github.com/chris-mcginnis-ucsf/DoubletFinder",
      "stars": 523,
      "forks": 123,
      "language": "R",
      "topics": [],
      "created_at": "2018-06-25T23:32:45Z",
      "updated_at": "2026-02-07T02:04:23Z",
      "pushed_at": "2025-03-21T11:20:52Z",
      "open_issues": 22,
      "owner": {
        "login": "chris-mcginnis-ucsf",
        "avatar_url": "https://avatars.githubusercontent.com/u/40582930?v=4"
      },
      "readme": "~~ Announcement (11/24/21) ~~\nI'm now a postdoc at Stanford and my UCSF email will be decommissioned soon. I also only check my github repos about once per month, so please reach out directly at cmcginni@stanford[dot]edu if you run into any issues. \n\n# DoubletFinder\n\nDoubletFinder is an R package that predicts doublets in single-cell RNA sequencing data. \n\nDoubletFinder is implemented to interface with Seurat >= 2.0 (https://satijalab.org/seurat/) \n\nDoubletFinder was published by Cell Systems in April, 2019: https://www.cell.com/cell-systems/fulltext/S2405-4712(19)30073-0\n\n## Updates\n\n(02/02/2025) Haibo Liu (Senior Bioinformatician at UMass, @haibol2016) added as maintainer after his much-needed improvement updates to the package.\n\n(11/21/2023) Made compatible with Seurat v5 and removed '_v3' flag from relevant function names.\n\n(03/31/2020) Internalized functions normally in 'modes' package to enable compatibility with R v3.6 and highger.\n\n(06/21/2019) Added parallelization to paramSweep_v3 (thanks NathanSkeen!) -- Note: progress no longer updated, but the process is much faster! Fixed bug with smaller datasets. Updated readme.\n\n(04/12/2019) Added SCTransform compatibilities to 'paramSweep_v3' and 'doubletFinder_v3'\n\n(04/08/2019) Added 'PCs' argument to 'doubletFinder', 'doubletFinder_v3', 'paramSweep', and 'paramSweep_v3' to avoid conflicts with dimension reduction preferences. Updated readme.\n\n(01/12/2019) Seurat V3 compatibility: 'doubletFinder_v3' and 'paramSweep_v3' functions added, other functions for parameter estimation remain compatible.  \n\n## DoubletFinder V2.0 (11/28/2018) \n\nNew Features:\n1. Increased computational efficiency during pANN computation\n2. Implemented strategy for determining optimal pK values for any scRNA-seq data using pN-pK parameter sweeps and mean-variance-normalized bimodality coefficient (BCmvn)\n3. Included vignette describing 'best-practices' for applying DoubletFinder to scRNA-seq data generated without sample multiplexing\n\n## Installation (in R/RStudio)\n\n```{r}\nremotes::install_github('chris-mcginnis-ucsf/DoubletFinder', force = TRUE)\n```\n\n## Dependencies\n\nDoubletFinder requires the following R packages: \n* Seurat (>= 2.0) \n* Matrix (1.2.14) \n* fields (9.6) \n* KernSmooth (2.23-15)\n* ROCR (1.0-7)\n* parallel (3.5.1)\n* NOTE: These package versions were used in the bioRxiv paper, but other versions may work, as well.\n\n## Frequently Asked Questions\n\nQuestion: What is my anticipated doublet rate? \nAnswer: This is dependent on your platform (10x, parse, etc.) and will vary with the number of input cells. It will not always be 7.5% as is used in the tutorial. This information is available in the user guides for each technology. See https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/76 and https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/156\n\nQuestion: Can I run DoubletFinder on merged data from multiple 10x lanes?\nAnswer: Technically yes but I would only do this if you were splitting the same sample across multiple lanes. You want to avoid instances where DoubletFinder is attempting to find doublets that do not actually exist in the data. I would also not advise running DF on integrated Seurat objects. See https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/101 \n\nQuestion: I see multiple potential pK values when visualizing BCmvn -- what should I do?\nAnswer: I would spot check the results in GEX space to see what makes the most sense given your understanding of the data. See https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/62 and https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/40\n\n# DoubletFinder Overview\n\nDoubletFinder can be broken up into 4 steps:\n\n(1) Generate artificial doublets from existing scRNA-seq data \n\n(2) Pre-process merged real-artificial data\n\n(3) Perform PCA and use the PC distance matrix to find each cell's proportion of artificial k nearest neighbors (pANN)\n\n(4) Rank order and threshold pANN values according to the expected number of doublets\n\n![alternativetext](DF.screenshots/DoubletFinderOverview.png)\n\nDoubletFinder takes the following arguments:\n\nseu ~ This is a fully-processed Seurat object (i.e., after NormalizeData, FindVariableGenes, ScaleData, RunPCA, and RunTSNE have all been run).\n\nPCs ~ The number of statistically-significant principal components, specified as a range (e.g., PCs = 1:10)\n\npN ~ This defines the number of generated artificial doublets, expressed as a proportion of the merged real-artificial data. Default is set to 25%, based on observation that DoubletFinder performance is largely pN-invariant (see McGinnis, Murrow and Gartner 2019, Cell Systems).\n\npK ~ This defines the PC neighborhood size used to compute pANN, expressed as a proportion of the merged real-artificial data. No default is set, as pK should be adjusted for each scRNA-seq dataset. Optimal pK values should be estimated using the strategy described below.\n\nnExp ~ This defines the pANN threshold used to make final doublet/singlet predictions. This value can best be estimated from cell loading densities into the 10X/Drop-Seq device, and adjusted according to the estimated proportion of homotypic doublets.\n\n## Application to Cell Hashing and Demuxlet data\n\nDoubletFinder successfully recapitulates ground-truth doublet classifications determined using antibody-barcode sample multiplexing (Cell Hashing) and SNP deconvolution (Demuxlet). DoubletFinder identifies false-negative Demuxlet classifications caused by doublets formed from cells with identical SNP profiles. DoubletFinder is insensitive to homotypic doublets -- i.e., doublets dervied from transcriptionally-similar cell states. \n\n![alternativetext](DF.screenshots/Results_Demux.png)\n![alternativetext](DF.screenshots/Results_Hashing.png)\n\n# 'Best-Practices' for scRNA-seq data generated without sample multiplexing\n\n## Input scRNA-seq Data\n\n* Do not apply DoubletFinder to aggregated scRNA-seq data representing multiple *distinct* samples (e.g., multiple 10X lanes). For example, if you run DoubletFinder on aggregated data representing WT and mutant cell lines sequenced across different 10X lanes, artificial doublets will be generated from WT and mutant cells, which cannot exist in your data. These artificial doublets will skew results. Notably, it is okay to run DoubletFinder on data generated by splitting a single sample across multiple 10X lanes. \n\n* Ensure that input data is cleared of low-quality cell clusters. There are a variety of ways to do this, but I usually use the following workflow:\n1. Manually threshold raw gene expression matrices according to RNA nUMIs (especially important when dealing with super-loaded 10X data because of the way CellRanger threholds data -- See Lun et al., 2019, Genome Biology.\n2. Pre-process data using standard workflow.\n3. Identify clusters with (A) low RNA UMIs, (B) High % mitochondrial reads, and/or (C) Uninformative marker genes.\n4. Remove clusters, pre-process again, and run DoubletFinder.\n\n## pK Selection\n\nROC analysis across pN-pK parameter sweeps for Cell Hashing and Demuxlet datasets demonstrate that DoubletFinder performance is largely invariant of pN value selection:\n\n![alternativetext](DF.screenshots/ParamSweep_Schematic.png)\n![alternativetext](DF.screenshots/ParamSweep_HeatMap.png)\n\nROC analysis across pN-pK parameter sweeps for simulated scRNA-seq data with (I) Variable numbers of cell states and (II) Variable magnitudes of transcriptional heterogeneity demonstrates that (I) Optimal pK value selection depends on the total number of cell states and (II) DoubletFinder performance suffers when applied to transcriptionally-homogenous data. Simulated data was generated using a strategy similar to as described in Wolock, Lopex & Klein 2019, Cell Systems.\n\n![alternativetext](DF.screenshots/Simulation_Schematic.png)\n![alternativetext](DF.screenshots/Results_Simulation.png)\n\nSimulated and sample-multiplexed data are unique in that ground-truth doublet classifications can be leveraged to characterize how DoubletFinder parameters must be 'fit' to distinct scRNA-seq datasets. However, doublets remain unknown in real-world contexts -- which is likely why you are interested in DoubletFinder, at all!\n\nTo maximize the accuracy of DoubletFinder predictions, we sought a ground-truth-agnostic metric that coincides with pK values that maximize AUC in Cell Hashing and Demuxlet data. Mean-variance normalized bimodality coefficient (BCmvn) achieves this goal, featuring a single, easily-discernible maximum at pK values that optimize AUC. \n\n![alternativetext](DF.screenshots/BCmvn.png)\n\nBCmvn distributions also feature a single maximum for scRNA-seq datasets generated without sample-multiplexing (e.g., Mouse pancreas, Byrnes et al., 2018, Nature Communcations; Mouse kidney, Park et al., 2018, Science), enabling pK selection.\n\n## Doublet Number Estimation\n\nDoubletFinder is sensitive to heterotypic doublets -- i.e., doublets formed from transcriptionally-distinct cell states -- but is insensitive to homotypic doublets -- i.e., doublets formed from transcriptionally-similar cell states. In our original manuscript, we suggested using DoubletFinder to predict the number of doublets expected from Poisson statistical estimates realting to the droplet microfluidics cell loading density. However, Poisson estimates are agnostic of homotypic doublets, and will thus invariably overestimate the number of *detectable* doublets.\n\nTo address this issue, we suggest users utilize literature-supported cell type annotations to model the proportion of homotypic doublets present in their data. As an example, we present an analysis of mouse kidney scRNA-seq data (Park et al., 2018, Science):\n\n![alternativetext](DF.screenshots/HomotypicAdjustment.png)\n\nNotably, it is conceivable that literature-suppoted cell type annotations may not accurately recapitulate the magnitude of transcriptional divergence necessary for DoubletFinder sensitivity. For example, nominally-homogenous cells (e.g., CD4+ T-cells) may exist along a spectrum of gene expression states (e.g., distinct anatomical locations, disease states, naive/Tregs/Th17 cells, etc.), and doublets formed by cell sub-types may be detectable by DoubletFinder. Thus, we consider doublet number estimates based on Poisson statistics with and without homotypic doublet proportion adjustment to 'bookend' the real detectable doublet rate. \n\n## Example code for 'real-world' applications\n\n```R\n## Pre-process Seurat object (standard) --------------------------------------------------------------------------------------\nseu_kidney <- CreateSeuratObject(kidney.data)\nseu_kidney <- NormalizeData(seu_kidney)\nseu_kidney <- FindVariableFeatures(seu_kidney, selection.method = \"vst\", nfeatures = 2000)\nseu_kidney <- ScaleData(seu_kidney)\nseu_kidney <- RunPCA(seu_kidney)\nseu_kidney <- RunUMAP(seu_kidney, dims = 1:10)\n\n## Pre-process Seurat object (sctransform) -----------------------------------------------------------------------------------\nseu_kidney <- CreateSeuratObject(kidney.data)\nseu_kidney <- SCTransform(seu_kidney)\nseu_kidney <- RunPCA(seu_kidney)\nseu_kidney <- RunUMAP(seu_kidney, dims = 1:10)\n\n## pK Identification (no ground-truth) ---------------------------------------------------------------------------------------\nsweep.res.list_kidney <- paramSweep(seu_kidney, PCs = 1:10, sct = FALSE)\nsweep.stats_kidney <- summarizeSweep(sweep.res.list_kidney, GT = FALSE)\nbcmvn_kidney <- find.pK(sweep.stats_kidney)\n\n## pK Identification (ground-truth) ------------------------------------------------------------------------------------------\nsweep.res.list_kidney <- paramSweep(seu_kidney, PCs = 1:10, sct = FALSE)\ngt.calls <- seu_kidney@meta.data[rownames(sweep.res.list_kidney[[1]]), \"GT\"].   ## GT is a vector containing \"Singlet\" and \"Doublet\" calls recorded using sample multiplexing classification and/or in silico geneotyping results \nsweep.stats_kidney <- summarizeSweep(sweep.res.list_kidney, GT = TRUE, GT.calls = gt.calls)\nbcmvn_kidney <- find.pK(sweep.stats_kidney)\n\n## Homotypic Doublet Proportion Estimate -------------------------------------------------------------------------------------\nhomotypic.prop <- modelHomotypic(annotations)           ## ex: annotations <- seu_kidney@meta.data$ClusteringResults\nnExp_poi <- round(0.075*nrow(seu_kidney@meta.data))  ## Assuming 7.5% doublet formation rate - tailor for your dataset\nnExp_poi.adj <- round(nExp_poi*(1-homotypic.prop))\n\n## Run DoubletFinder with varying classification stringencies ----------------------------------------------------------------\nseu_kidney <- doubletFinder(seu_kidney, PCs = 1:10, pN = 0.25, pK = 0.09, nExp = nExp_poi, reuse.pANN = NULL, sct = FALSE)\nseu_kidney <- doubletFinder(seu_kidney, PCs = 1:10, pN = 0.25, pK = 0.09, nExp = nExp_poi.adj, reuse.pANN = \"pANN_0.25_0.09_913\", sct = FALSE)\n```\n\n![alternativetext](DF.screenshots/DFkidney_low.vs.high.png)\n\n## Other Doublet Detection Methods\n[Scrublet (Py)](https://github.com/AllonKleinLab/scrublet)\n[DoubletDecon (R)](https://github.com/EDePasquale/DoubletDecon)\n[DoubletDetection (Py)](https://github.com/JonathanShor/DoubletDetection)\n[Solo (Py)](https://github.com/calico/solo)\n[scds (R)](https://github.com/kostkalab/scds)\n[scDblFinder (R)](https://github.com/plger/scDblFinder)\n\n## References\n\n1.\tStoeckius M, Zheng S, Houck-Loomis B, Hao S, Yeung BZ, Smibert P, Satija R. Cell Hashing with barcoded antibodies enables multiplexing and doublet detection for single cell genomics. Genome Biology. 2018. 19:224.\n\n2.  Kang HM, Subramaniam M, Targ S, Nguyen M, Maliskova L, McCarthy E, Wan E, Wong S, Byrnes L, Lanata CM, Gate RE, Mostafavi S, Marson A, Zaitlen N, Criswell LA, Ye JC. Multiplexed droplet single-cell RNA-sequencing using natural genetic variation. Nature Biotechnology. 2018. 36(1):89-94. \n\n3.  Wolock SL, Lopez R, Klein AM. Scrublet: Computational Identification of Cell Doublets in Single-Cell Transcriptomic Data. Cell Systems. 2019. 8(4):281-291.e9.\n\n4.  Park J, Shrestha R, Qiu C, Kondo A, Huang S, Werth M, Li M, Barasch J, SusztÃ¡k K. Single-cell transcriptomics of the mouse kidney reveals potential cellular targets of kidney disease. Science. 2018. 360(6390):758-63.\n\n5.  Byrnes LE, Wong DM, Subramaniam M, Meyer NP, Gilchrist CL, Knox SM, Tward AD, Ye CJ, Sneddon JB. Lineage dynamics of murine pancreatic development at single-cell resolution. Nature Communications. 2018; 9:3922.\n\n6.  Bais AS, Kostka D. scds: computational annotation of doublets in single-cell RNA sequencing data. Bioinformatics. 2020. 36(4):1150-8.\n\n7.  Bernstein NJ, Fong NL, Lam I, Roy MA, Hendrickson DG, Kelley DR. Solo: Doublet Identification in Single-Cell RNA-Seq via Semi-Supervised Deep Learning. Cell Systems. 2020. S2405-4712(20)30195-2.\n\n8.  DePasquale EAK, Schnell DJ, Van Camp PJ, Valiente-Alandi I, Blaxall BC, Grimes HL, Singh H, Salomonis N. DoubletDecon: Deconvoluting Doublets from Single-Cell RNA-Sequencing Data. Cell Reports. 2019. 29(6):1718-27.e8.\n",
      "stars_today": 0
    },
    {
      "id": 167440342,
      "name": "monocle3",
      "full_name": "cole-trapnell-lab/monocle3",
      "description": null,
      "html_url": "https://github.com/cole-trapnell-lab/monocle3",
      "stars": 438,
      "forks": 117,
      "language": "R",
      "topics": [
        "single-cell-rna-seq"
      ],
      "created_at": "2019-01-24T21:26:18Z",
      "updated_at": "2026-02-07T01:52:46Z",
      "pushed_at": "2026-01-08T18:32:17Z",
      "open_issues": 261,
      "owner": {
        "login": "cole-trapnell-lab",
        "avatar_url": "https://avatars.githubusercontent.com/u/8060918?v=4"
      },
      "readme": "MONOCLE 3\n=======================\n\nMonocle 3 is an analysis toolkit for single-cell RNA-Seq experiments.  To use this package, you will need the R statistical computing environment (version 3.0 or later) and several packages available through Bioconductor and CRAN.\n\nDetails on how to install and use Monocle 3 are available on our website:\n\nhttp://cole-trapnell-lab.github.io/monocle3/\n\n## Monocle3 with BPCells counts matrix support\n\nThis development branch version of Monocle3 adds the ability to store the counts matrix on-disk using the BPCells package. By default, Monocle3 stores the counts matrix in-memory as a sparse matrix, as in previous versions. In order to store the matrix on-disk, you must set the matrix_control list value `matrix_class=\"BPCells\"` in the affected commands. For example, to load a MatrixMarket file as an on-disk matrix, use the command\n\n```\ncds <- load_mm_data(mat_path=<path_to_mtx_file>,\n                    feature_anno_path=<path_to_feature_anno_file>,\n                    cell_anno_path=<path_to_cell_anno_file>,\n                    matrix_control=list(matrix_class='BPCells'))\n```\n\n### Install Monocle3 with BPCells\n\nYou must install BPCells from Github before you can install this Monocle3 version, and BPCells requires an HDF5 object library for installation. After installing the HDF5 library, you install BPCells using the command\n\n```\nremotes::install_github(\"bnprks/BPCells/r\")\n```\n\nThe [BPCells Github site](https://github.com/bnprks/BPCells)  has additional information.\n\nSome Linux distributions provide the HDF5 library as an option. The\nBPCells site has information about installing the HDF5 library on various operating systems.\n\nI used Homebrew to install an HDF5 library on MacOS. I seemed to need to install the pkg-config package as well, and add a pkg-config configuration file for HDF5. Homebrew installed pkg-config in '/opt/homebrew' so I added the hdf5.pc file in\n\n> /opt/homebrew/lib/pkgconfig/hdf5.pc\n\nwith the contents\n\n```\nprefix=/opt/homebrew/Cellar/hdf5/1.12.2_2\nexec_prefix=${prefix}\nincludedir=${prefix}/include\nlibdir=/opt/homebrew/Cellar/hdf5/1.12.2_2/lib\n  \nName: hdf5\nDescription: HDF5\nURL: xx\nVersion: 1.12.2_2\nCflags: -I${includedir}\nLibs: -L${libdir} -lhdf5\n```\n\nYou may need to update the version strings in your hdf5.pc file.\n\nMonocle3 no longer uses the terra package, so it does not need to be installed.\n\n### Notes\n\n- Monocle3 can use the BPCells package to store the feature-cell counts matrix on-disk rather than in-memory, which enables analysis of considerably larger data sets than before. By default, Monocle3 stores the counts matrix in-memory as a sparse matrix, as it has in the past. To store the counts matrix on-disk, use the parameter `matrix_control=list(matrix_class=\"BPCells\")` when you make the CDS or convert the counts matrix using one of the functions\n  - `load_mm_data()`\n  - `load_mtx_data()`\n  - `load_cellranger_data()`\n  - `load_a549()`\n  - `load_worm_embryo()`\n  - `load_worm_l2()`\n  - `convert_counts_matrix()`\n\n  For example, to convert a dgCMatrix counts matrix to a BPCells on-disk matrix in an existing CDS, use the command `cds <- convert_counts_matrix(cds, matrix_control=list(matrix_class=\"BPCells\"))`.\n- BPCells stores the count matrix information in directories with names similar to `monocle.bpcells.20230830.4c4b1bebe4b4.tmp`. Monocle3 tries to remove those directories when you quit R. Please do not remove them while Monocle3 is running because doing so eliminates the count matrix data. You *can* remove them after quitting R if Monocle3 fails to remove them.\n- The method `new_cell_data_set()` accepts a BPCells on-disk counts matrix.\n- The functions `save_monocle_objects()` and `load_monocle_objects()` store and load BPCells on-disk matrices when the CDS counts matrix is an on-disk BPCells matrix.\n- The Monocle3 `saveRDS()` function warns the user to use `save_monocle_objects()` when saving a CDS with a BPCells on-disk counts matrix. If you insist on using the `saveRDS()` function, the BPCells on-disk matrix directory will not be stored and you will be unable to load it with the `readRDS()` function.\n- The function `combine_cds()` combines CDSes with mixes of dgCMatrix and BPCells on-disk counts matrices into a BPCells on-disk counts matrix. When called with the `matrix_control=list(matrix_class=\"BPCells\")` parameter, `combine_cds()` combines CDSes with all dgCMatrix counts matrices into a BPCells on-disk counts matrix.\n- Note that when the counts matrix is stored as a BPCells on-disk matrix, the `new_cell_data_set()` method stores a second BPCells on-disk copy of the matrix in the CDS assays slot with the name `counts_row_order`. The `counts_row_order` matrix is used by Monocle3 when the counts matrix is accessed intensively by row. The reason is that, by default, BPCells stores the matrix as a one-dimensional vector in column-major order, as does R. As a result, column access is fast and row access is slow. We use BPCell's ability to also store and access matrices in row-major order, which gives fast row access. However, this means that the two copies of the counts matrix must have the same count values. If you replace or change the CDS's counts matrix, you must also update the `counts_row_order` matrix, which you can do using the function `set_cds_row_order_matrix()`.\n  - The CDS assays slot is a named list where the standard, column-major order, matrix is called `counts` and the BPCells row-major order matrix is called `counts_row_order`.\n  - The `counts` matrix getter and setter methods are `counts(cds)` and `counts(cds)<-`.\n  - The Monocle3 setter warns about re-setting the BPCells `counts_row_order` matrix, unless called with the parameter `bpcells_warn=FALSE`.\n  - The `counts_row_order` getter method is called `counts_row_order`.\n  - There is no corresponding `counts_row_order` setter method\n- By default, the BPCells on-disk matrix is stored in a directory that is created where R is started. You can change the directory location using the `matrix_path` value in the `matrix_control` parameter.\n- For more information about the `matrix_control` values, see the help document for the function `set_matrix_control()`.\n- I tested this version using BPCells counts matrices on the examples in the Monocle3 documentation although I did not try all of the plotting functions.\n\n",
      "stars_today": 0
    },
    {
      "id": 185880527,
      "name": "signac",
      "full_name": "stuart-lab/signac",
      "description": "R toolkit for the analysis of single-cell chromatin data",
      "html_url": "https://github.com/stuart-lab/signac",
      "stars": 403,
      "forks": 100,
      "language": "R",
      "topics": [
        "atac",
        "bioinformatics",
        "single-cell"
      ],
      "created_at": "2019-05-09T22:32:26Z",
      "updated_at": "2026-01-28T01:52:36Z",
      "pushed_at": "2026-01-20T08:57:03Z",
      "open_issues": 20,
      "owner": {
        "login": "stuart-lab",
        "avatar_url": "https://avatars.githubusercontent.com/u/102445397?v=4"
      },
      "readme": "# Signac <img align=\"right\" src=\"man/figures/logo.svg\" style=\"height:100px;\" />\n\n[![R-CMD-check](https://github.com/stuart-lab/signac/workflows/R-CMD-check/badge.svg)](https://github.com/stuart-lab/signac/actions)\n[![CRAN\nVersion](https://www.r-pkg.org/badges/version/Signac)](https://cran.r-project.org/package=Signac)\n[![CRAN\nDownloads](https://cranlogs.r-pkg.org/badges/Signac)](https://cran.r-project.org/package=Signac)\n\n## Overview\n\nSignac is a comprehensive R package for the analysis of single-cell\nchromatin data. Signac includes functions for quality control,\nnormalization, dimension reduction, clustering, differential activity,\nand more.\n\nDocumentation and tutorials can be found at\n<https://stuartlab.org/signac/>\n\n## Installation\n\nTo install the latest release of Signac from CRAN:\n\n``` r\nsetRepositories(ind=1:3) # needed to automatically install Bioconductor dependencies\ninstall.packages(\"Signac\")\n```\n\nTo release the latest develop version from GitHub:\n\n``` r\nif (!requireNamespace(\"remotes\", quietly = TRUE))\n    install.packages(\"remotes\")\nremotes::install_github(\"stuart-lab/signac\", ref = \"develop\")\n```\n\n## Release notes\n\nFor a changelog please see the [NEWS\nfile](https://github.com/stuart-lab/signac/blob/develop/NEWS.md), also\navailable on the [Signac\nwebsite](https://stuartlab.org/signac/news/index.html).\n\n## Contributing\n\nWe welcome contributions to the Signac package. Please see the\n[contribution guide](https://github.com/stuart-lab/signac/blob/develop/CONTRIBUTING.md)\nfor more information.\n\n## Getting help\n\nIf you encounter a bug or have a feature request, please open an\n[issue](https://github.com/stuart-lab/signac/issues).\n\nIf you would like to discuss questions related to single-cell analysis,\nyou can open a\n[discussion](https://github.com/stuart-lab/signac/discussions).\n\n## Citing Signac\n\nIf you use the Signac package in your work please cite [Stuart et\nal. 2021](https://doi.org/10.1038/s41592-021-01282-5)\n\n```\n@ARTICLE{signac,\n  title     = \"Single-cell chromatin state analysis with Signac\",\n  author    = \"Stuart, Tim and Srivastava, Avi and Madad, Shaista and Lareau,\n               Caleb A and Satija, Rahul\",\n  journal   = \"Nat. Methods\",\n  publisher = \"Nature Publishing Group\",\n  pages     = \"1--9\",\n  month     =  nov,\n  year      =  2021,\n  url       = \"https://www.nature.com/articles/s41592-021-01282-5\",\n  language  = \"en\"\n}\n```\n\n## Related packages\n\n-   [Seurat](https://github.com/satijalab/seurat)\n-   [SeuratObject](https://github.com/satijalab/seurat-object)\n-   [SeuratDisk](https://github.com/mojaveazure/seurat-disk)\n-   [SeuratData](https://github.com/satijalab/seurat-data)\n-   [SeuratWrappers](https://github.com/satijalab/seurat-wrappers)\n-   [Azimuth](https://github.com/satijalab/azimuth)\n",
      "stars_today": 0
    },
    {
      "id": 308437751,
      "name": "tree-sitter-r",
      "full_name": "r-lib/tree-sitter-r",
      "description": "Tree-sitter grammar for R",
      "html_url": "https://github.com/r-lib/tree-sitter-r",
      "stars": 123,
      "forks": 38,
      "language": "R",
      "topics": [],
      "created_at": "2020-10-29T20:06:05Z",
      "updated_at": "2026-01-28T11:20:12Z",
      "pushed_at": "2025-09-16T20:52:48Z",
      "open_issues": 17,
      "owner": {
        "login": "r-lib",
        "avatar_url": "https://avatars.githubusercontent.com/u/22618716?v=4"
      },
      "readme": "# tree-sitter-r\n\nAn R grammar for [tree-sitter](https://github.com/tree-sitter/tree-sitter).\n\n## R package\n\nThis grammar is available as an [R package](https://cran.r-project.org/web/packages/treesitter.r/index.html).\n\nYou'll also want the [R package providing bindings to tree-sitter](https://davisvaughan.github.io/r-tree-sitter/) itself.\n\n## Rust bindings\n\nThis grammar is available as a [Rust crate on crates.io](https://crates.io/crates/tree-sitter-r).\n\n## Node bindings\n\nThis grammar is available as an [npm package](https://www.npmjs.com/package/@davisvaughan/tree-sitter-r).\n\nNote that it is currently listed as a scoped package under the name `@davisvaughan/tree-sitter-r`.\nWe are working with the npm team to gain ownership of the `tree-sitter-r` package.\nOnce that happens, we will move the npm package there instead.\n\n## References\n\n- [The R Draft Spec](https://cran.r-project.org/doc/manuals/r-release/R-lang.pdf)\n- [gram.y](https://github.com/wch/r-source/blob/trunk/src/main/gram.y)\n\n## Known deviations\n\nThis section describes known deviations from the R grammar.\n\n### `]]` as a literal token\n\nThe following is valid R syntax, note how `]]` has been split over multiple lines.\n\n```r\nx[[\"a\"]\n]\n```\n\nThis applies to `]]`, but not to `[[`, for example, this is not valid R syntax:\n\n```r\nx[\n[\"a\"]]\n```\n\nThe technical reason for this is that [in the grammar](https://github.com/wch/r-source/blob/988774e05497bcf2cfac47bfbec59d551432e3fb/src/main/gram.y#L508) R treats `[[` as a single token, but `]]` is treated as two individual `]` tokens.\nTreating `]]` as two individual `]` tokens allows whitespace, newlines, and even comments to appear between the two `]` tokens:\n\n```r\nx[[\"a\"] # comment\n]\n```\n\nWhile we'd like to precisely support the R grammar, it is also extremely useful to treat all of `(`, `)`, `[`, `]`, `[[`, and `]]` as literal tokens when using the tree-sitter grammar.\nThis allows you to treat call, subset, and subset2 nodes in the same way, since they all have exactly the same node structure.\n\nBecause treating `]]` as a literal token is so useful, and because we've never seen any R code \"in the wild\" written this way, this grammar does not allow whitespace, newlines, or comments between the two `]` tokens.\n",
      "stars_today": 0
    }
  ],
  "created_at": "2026-02-07T02:35:39.029114974Z"
}