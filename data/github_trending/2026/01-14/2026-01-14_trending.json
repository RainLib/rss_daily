{
  "date": "2026-01-14",
  "name": "trending",
  "repositories": [
    {
      "id": 975734319,
      "name": "opencode",
      "full_name": "anomalyco/opencode",
      "description": "The open source coding agent.",
      "html_url": "https://github.com/anomalyco/opencode",
      "stars": 67179,
      "forks": 5807,
      "language": "TypeScript",
      "topics": [],
      "created_at": "2025-04-30T20:08:00Z",
      "updated_at": "2026-01-14T01:07:24Z",
      "pushed_at": "2026-01-14T01:01:58Z",
      "open_issues": 2746,
      "owner": {
        "login": "anomalyco",
        "avatar_url": "https://avatars.githubusercontent.com/u/66570915?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://opencode.ai\">\n    <picture>\n      <source srcset=\"packages/console/app/src/asset/logo-ornate-dark.svg\" media=\"(prefers-color-scheme: dark)\">\n      <source srcset=\"packages/console/app/src/asset/logo-ornate-light.svg\" media=\"(prefers-color-scheme: light)\">\n      <img src=\"packages/console/app/src/asset/logo-ornate-light.svg\" alt=\"OpenCode logo\">\n    </picture>\n  </a>\n</p>\n<p align=\"center\">The open source AI coding agent.</p>\n<p align=\"center\">\n  <a href=\"https://opencode.ai/discord\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1391832426048651334?style=flat-square&label=discord\" /></a>\n  <a href=\"https://www.npmjs.com/package/opencode-ai\"><img alt=\"npm\" src=\"https://img.shields.io/npm/v/opencode-ai?style=flat-square\" /></a>\n  <a href=\"https://github.com/anomalyco/opencode/actions/workflows/publish.yml\"><img alt=\"Build status\" src=\"https://img.shields.io/github/actions/workflow/status/anomalyco/opencode/publish.yml?style=flat-square&branch=dev\" /></a>\n</p>\n\n[![OpenCode Terminal UI](packages/web/src/assets/lander/screenshot.png)](https://opencode.ai)\n\n---\n\n### Installation\n\n```bash\n# YOLO\ncurl -fsSL https://opencode.ai/install | bash\n\n# Package managers\nnpm i -g opencode-ai@latest        # or bun/pnpm/yarn\nscoop bucket add extras; scoop install extras/opencode  # Windows\nchoco install opencode             # Windows\nbrew install anomalyco/tap/opencode # macOS and Linux (recommended, always up to date)\nbrew install opencode              # macOS and Linux (official brew formula, updated less)\nparu -S opencode-bin               # Arch Linux\nmise use -g opencode               # Any OS\nnix run nixpkgs#opencode           # or github:anomalyco/opencode for latest dev branch\n```\n\n> [!TIP]\n> Remove versions older than 0.1.x before installing.\n\n### Desktop App (BETA)\n\nOpenCode is also available as a desktop application. Download directly from the [releases page](https://github.com/anomalyco/opencode/releases) or [opencode.ai/download](https://opencode.ai/download).\n\n| Platform              | Download                              |\n| --------------------- | ------------------------------------- |\n| macOS (Apple Silicon) | `opencode-desktop-darwin-aarch64.dmg` |\n| macOS (Intel)         | `opencode-desktop-darwin-x64.dmg`     |\n| Windows               | `opencode-desktop-windows-x64.exe`    |\n| Linux                 | `.deb`, `.rpm`, or AppImage           |\n\n```bash\n# macOS (Homebrew)\nbrew install --cask opencode-desktop\n```\n\n#### Installation Directory\n\nThe install script respects the following priority order for the installation path:\n\n1. `$OPENCODE_INSTALL_DIR` - Custom installation directory\n2. `$XDG_BIN_DIR` - XDG Base Directory Specification compliant path\n3. `$HOME/bin` - Standard user binary directory (if exists or can be created)\n4. `$HOME/.opencode/bin` - Default fallback\n\n```bash\n# Examples\nOPENCODE_INSTALL_DIR=/usr/local/bin curl -fsSL https://opencode.ai/install | bash\nXDG_BIN_DIR=$HOME/.local/bin curl -fsSL https://opencode.ai/install | bash\n```\n\n### Agents\n\nOpenCode includes two built-in agents you can switch between with the `Tab` key.\n\n- **build** - Default, full access agent for development work\n- **plan** - Read-only agent for analysis and code exploration\n  - Denies file edits by default\n  - Asks permission before running bash commands\n  - Ideal for exploring unfamiliar codebases or planning changes\n\nAlso, included is a **general** subagent for complex searches and multistep tasks.\nThis is used internally and can be invoked using `@general` in messages.\n\nLearn more about [agents](https://opencode.ai/docs/agents).\n\n### Documentation\n\nFor more info on how to configure OpenCode [**head over to our docs**](https://opencode.ai/docs).\n\n### Contributing\n\nIf you're interested in contributing to OpenCode, please read our [contributing docs](./CONTRIBUTING.md) before submitting a pull request.\n\n### Building on OpenCode\n\nIf you are working on a project that's related to OpenCode and is using \"opencode\" as a part of its name; for example, \"opencode-dashboard\" or \"opencode-mobile\", please add a note to your README to clarify that it is not built by the OpenCode team and is not affiliated with us in any way.\n\n### FAQ\n\n#### How is this different from Claude Code?\n\nIt's very similar to Claude Code in terms of capability. Here are the key differences:\n\n- 100% open source\n- Not coupled to any provider. Although we recommend the models we provide through [OpenCode Zen](https://opencode.ai/zen); OpenCode can be used with Claude, OpenAI, Google or even local models. As models evolve the gaps between them will close and pricing will drop so being provider-agnostic is important.\n- Out of the box LSP support\n- A focus on TUI. OpenCode is built by neovim users and the creators of [terminal.shop](https://terminal.shop); we are going to push the limits of what's possible in the terminal.\n- A client/server architecture. This for example can allow OpenCode to run on your computer, while you can drive it remotely from a mobile app. Meaning that the TUI frontend is just one of the possible clients.\n\n---\n\n**Join our community** [Discord](https://discord.gg/opencode) | [X.com](https://x.com/opencode)\n",
      "stars_today": 2222
    },
    {
      "id": 329782568,
      "name": "dioxus",
      "full_name": "DioxusLabs/dioxus",
      "description": "Fullstack app framework for web, desktop, and mobile.",
      "html_url": "https://github.com/DioxusLabs/dioxus",
      "stars": 34004,
      "forks": 1494,
      "language": "Rust",
      "topics": [
        "android",
        "css",
        "desktop",
        "html",
        "ios",
        "native",
        "react",
        "rust",
        "ssr",
        "ui",
        "virtualdom",
        "wasm",
        "web"
      ],
      "created_at": "2021-01-15T01:57:26Z",
      "updated_at": "2026-01-14T00:48:04Z",
      "pushed_at": "2026-01-12T15:34:46Z",
      "open_issues": 609,
      "owner": {
        "login": "DioxusLabs",
        "avatar_url": "https://avatars.githubusercontent.com/u/79236386?v=4"
      },
      "readme": "<p>\n    <p align=\"center\" >\n      <!-- <img src=\"./notes/header-light-updated.svg#gh-light-mode-only\" >\n      <img src=\"./notes/header-dark-updated.svg#gh-dark-mode-only\" > -->\n      <!-- <a href=\"https://dioxuslabs.com\">\n          <img src=\"./notes/flat-splash.avif\">\n      </a> -->\n      <img src=\"./notes/splash-header-darkmode.svg#gh-dark-mode-only\" style=\"width: 80%; height: auto;\">\n      <img src=\"./notes/splash-header.svg#gh-light-mode-only\" style=\"width: 80%; height: auto;\">\n      <img src=\"./notes/image-splash.avif\">\n      <br>\n    </p>\n</p>\n<div align=\"center\">\n  <!-- Crates version -->\n  <a href=\"https://crates.io/crates/dioxus\">\n    <img src=\"https://img.shields.io/crates/v/dioxus.svg?style=flat-square\"\n    alt=\"Crates.io version\" />\n  </a>\n  <!-- Downloads -->\n  <a href=\"https://crates.io/crates/dioxus\">\n    <img src=\"https://img.shields.io/crates/d/dioxus.svg?style=flat-square\"\n      alt=\"Download\" />\n  </a>\n  <!-- docs -->\n  <a href=\"https://docs.rs/dioxus\">\n    <img src=\"https://img.shields.io/badge/docs-latest-blue.svg?style=flat-square\"\n      alt=\"docs.rs docs\" />\n  </a>\n  <!-- CI -->\n  <a href=\"https://github.com/jkelleyrtp/dioxus/actions\">\n    <img src=\"https://github.com/dioxuslabs/dioxus/actions/workflows/main.yml/badge.svg\"\n      alt=\"CI status\" />\n  </a>\n\n  <!--Awesome -->\n  <a href=\"https://dioxuslabs.com/awesome\">\n    <img src=\"https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg\" alt=\"Awesome Page\" />\n  </a>\n  <!-- Discord -->\n  <a href=\"https://discord.gg/XgGxMSkvUM\">\n    <img src=\"https://img.shields.io/discord/899851952891002890.svg?logo=discord&style=flat-square\" alt=\"Discord Link\" />\n  </a>\n</div>\n\n<div align=\"center\">\n  <h3>\n    <a href=\"https://dioxuslabs.com\"> Website </a>\n    <span> | </span>\n    <a href=\"https://github.com/DioxusLabs/dioxus/tree/main/examples\"> Examples </a>\n    <span> | </span>\n    <a href=\"https://dioxuslabs.com/learn/0.7/tutorial\"> Tutorial </a>\n    <span> | </span>\n    <a href=\"https://github.com/DioxusLabs/dioxus/blob/main/notes/translations/zh-cn/README.md\"> ‰∏≠Êñá </a>\n    <span> | </span>\n    <a href=\"https://github.com/DioxusLabs/dioxus/blob/main/notes/translations/pt-br/README.md\"> PT-BR </a>\n    <span> | </span>\n    <a href=\"https://github.com/DioxusLabs/dioxus/blob/main/notes/translations/ja-jp/README.md\"> Êó•Êú¨Ë™û </a>\n    <span> | </span>\n    <a href=\"https://github.com/DioxusLabs/dioxus/blob/main/notes/translations/tr-tr\"> T√ºrk√ße </a>\n    <span> | </span>\n    <a href=\"https://github.com/DioxusLabs/dioxus/blob/main/notes/translations/ko-kr\"> ÌïúÍµ≠Ïñ¥ </a>\n  </h3>\n</div>\n<br>\n<p align=\"center\">\n  <a href=\"https://github.com/DioxusLabs/dioxus/releases/tag/v0.7.0\">‚ú® Dioxus 0.7 is out!!! ‚ú®</a>\n</p>\n<br>\n\nBuild for web, desktop, and mobile, and more with a single codebase. Zero-config setup, integrated hot-reloading, and signals-based state management. Add backend functionality with Server Functions and bundle with our CLI.\n\n```rust\nfn app() -> Element {\n    let mut count = use_signal(|| 0);\n\n    rsx! {\n        h1 { \"High-Five counter: {count}\" }\n        button { onclick: move |_| count += 1, \"Up high!\" }\n        button { onclick: move |_| count -= 1, \"Down low!\" }\n    }\n}\n```\n\n## ‚≠êÔ∏è Unique features:\n\n- Cross-platform apps in three lines of code (web, desktop, mobile, server, and more)\n- [Ergonomic state management](https://dioxuslabs.com/blog/release-050) combines the best of React, Solid, and Svelte\n- Built-in featureful, type-safe, fullstack web framework\n- Integrated bundler for deploying to the web, macOS, Linux, and Windows\n- Subsecond Rust hot-patching and asset hot-reloading\n- And more! [Take a tour of Dioxus](https://dioxuslabs.com/learn/0.7/).\n\n## Instant hot-reloading\n\nWith one command, `dx serve` and your app is running. Edit your markup, styles, and see changes in milliseconds. Use our experimental `dx serve --hotpatch` to update Rust code in real time.\n\n<div align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/DioxusLabs/screenshots/refs/heads/main/blitz/hotreload-video.webp\">\n  <!-- <video src=\"https://private-user-images.githubusercontent.com/10237910/386919031-6da371d5-3340-46da-84ff-628216851ba6.mov\" width=\"500\"></video> -->\n  <!-- <video src=\"https://private-user-images.githubusercontent.com/10237910/386919031-6da371d5-3340-46da-84ff-628216851ba6.mov\" width=\"500\"></video> -->\n</div>\n\n## Build Beautiful Apps\n\nDioxus apps are styled with HTML and CSS. Use the built-in TailwindCSS support or load your favorite CSS library. Easily call into native code (objective-c, JNI, Web-Sys) for a perfect native touch.\n\n<div align=\"center\">\n  <img src=\"./notes/ebou2.avif\">\n</div>\n\n\n\n## Truly fullstack applications\n\nDioxus deeply integrates with [axum](https://github.com/tokio-rs/axum) to provide powerful fullstack capabilities for both clients and servers. Pick from a wide array of built-in batteries like WebSockets, SSE, Streaming, File Upload/Download, Server-Side-Rendering, Forms, Middleware, and Hot-Reload, or go fully custom and integrate your existing axum backend.\n\n<div align=\"center\">\n  <img src=\"./notes/fullstack-websockets.avif\" width=\"700\">\n</div>\n\n## Experimental Native Renderer\n\nRender using web-sys, webview, server-side-rendering, liveview, or even with our experimental WGPU-based renderer. Embed Dioxus in Bevy, WGPU, or even run on embedded Linux!\n\n<div align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/DioxusLabs/screenshots/refs/heads/main/blitz/native-blitz-wgpu.webp\">\n</div>\n\n\n## First-party primitive components\n\nGet started quickly with a complete set of primitives modeled after shadcn/ui and Radix-Primitives.\n\n<div align=\"center\">\n  <img src=\"./notes/primitive-components.avif\" width=\"700\">\n</div>\n\n## First-class Android and iOS support\n\nDioxus is the fastest way to build native mobile apps with Rust. Simply run `dx serve --platform android` and your app is running in an emulator or on device in seconds. Call directly into JNI and Native APIs.\n\n<div align=\"center\">\n  <img src=\"./notes/android_and_ios2.avif\" width=\"500\">\n</div>\n\n\n\n## Bundle for web, desktop, and mobile\n\nSimply run `dx bundle` and your app will be built and bundled with maximization optimizations. On the web, take advantage of [`.avif` generation, `.wasm` compression, minification](https://dioxuslabs.com/learn/0.7/tutorial/assets), and more. Build WebApps weighing [less than 50kb](https://github.com/ealmloff/tiny-dioxus/) and desktop/mobile apps less than 5mb.\n\n<div align=\"center\">\n  <img src=\"./notes/bundle.gif\">\n</div>\n\n\n## Fantastic documentation\n\nWe've put a ton of effort into building clean, readable, and comprehensive documentation. All html elements and listeners are documented with MDN docs, and our Docs runs continuous integration with Dioxus itself to ensure that the docs are always up to date. Check out the [Dioxus website](https://dioxuslabs.com/learn/0.7/) for guides, references, recipes, and more. Fun fact: we use the Dioxus website as a testbed for new Dioxus features - [check it out!](https://github.com/dioxusLabs/docsite)\n\n<div align=\"center\">\n  <img src=\"./notes/docs.avif\">\n</div>\n\n\n## Modular and Customizable\n\nBuild your own renderer, or use a community renderer like [Freya](http://freyaui.dev). Use our modular components like RSX, VirtualDom, Blitz, Taffy, and Subsecond.\n\n\n<div align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/DioxusLabs/screenshots/refs/heads/main/blitz/freya-todo-example.webp\">\n</div>\n\n## Community\n\nDioxus is a community-driven project, with a very active [Discord](https://discord.gg/XgGxMSkvUM) and [GitHub](https://github.com/DioxusLabs/dioxus/issues) community. We're always looking for help, and we're happy to answer questions and help you get started. [Our SDK](https://github.com/DioxusLabs/dioxus-std) is community-run and we even have a [GitHub organization](https://github.com/dioxus-community/) for the best Dioxus crates that receive free upgrades and support.\n\n<div align=\"center\">\n  <img src=\"./notes/dioxus-community.avif\">\n</div>\n\n## Full-time core team\n\nDioxus has grown from a side project to a small team of fulltime engineers. Thanks to the generous support of FutureWei, Satellite.im, the GitHub Accelerator program, we're able to work on Dioxus full-time. Our long term goal is for Dioxus to become self-sustaining by providing paid high-quality enterprise tools. If your company is interested in adopting Dioxus and would like to work with us, please reach out!\n\n## Supported Platforms\n\n<div align=\"center\">\n  <table style=\"width:100%\">\n    <tr>\n      <td>\n      <b>Web</b>\n      </td>\n      <td>\n        <ul>\n          <li>Render directly to the DOM using WebAssembly</li>\n          <li>Pre-render with SSR and rehydrate on the client</li>\n          <li>Simple \"hello world\" at about 50kb, comparable to React</li>\n          <li>Built-in dev server and hot reloading for quick iteration</li>\n        </ul>\n      </td>\n    </tr>\n    <tr>\n      <td>\n      <b>Desktop</b>\n      </td>\n      <td>\n        <ul>\n          <li>Render using Webview or - experimentally - with WGPU or <a href=\"https://freyaui.dev\">Freya</a> (Skia) </li>\n          <li>Zero-config setup. Simply `cargo run` or `dx serve` to build your app </li>\n          <li>Full support for native system access without IPC </li>\n          <li>Supports macOS, Linux, and Windows. Portable <3mb binaries </li>\n        </ul>\n      </td>\n    </tr>\n    <tr>\n      <td>\n      <b>Mobile</b>\n      </td>\n      <td>\n        <ul>\n          <li>Render using Webview or - experimentally - with WGPU or Skia </li>\n          <li>Build .ipa and .apk files for iOS and Android </li>\n          <li>Call directly into Java and Objective-C with minimal overhead</li>\n          <li>From \"hello world\" to running on device in seconds</li>\n        </ul>\n      </td>\n    </tr>\n    <tr>\n      <td>\n      <b>Server-side Rendering</b>\n      </td>\n      <td>\n        <ul>\n          <li>Suspense, hydration, and server-side rendering</li>\n          <li>Quickly drop in backend functionality with server functions</li>\n          <li>Extractors, middleware, and routing integrations</li>\n          <li>Static-site generation and incremental regeneration</li>\n        </ul>\n      </td>\n    </tr>\n  </table>\n</div>\n\n## Running the examples\n\n> The examples in the main branch of this repository target the git version of dioxus and the CLI. If you are looking for examples that work with the latest stable release of dioxus, check out the [0.6 branch](https://github.com/DioxusLabs/dioxus/tree/v0.6/examples).\n\nThe examples in the top level of this repository can be run with:\n\n```sh\ncargo run --example <example>\n```\n\nHowever, we encourage you to download the dioxus-cli to test out features like hot-reloading. To install the most recent binary CLI, you can use cargo binstall.\n\n```sh\ncargo binstall dioxus-cli@0.7.0 --force\n```\n\nIf this CLI is out-of-date, you can install it directly from git\n\n```sh\ncargo install --git https://github.com/DioxusLabs/dioxus dioxus-cli --locked\n```\n\nWith the CLI, you can also run examples with the web platform. You will need to disable the default desktop feature and enable the web feature with this command:\n\n```sh\ndx serve --example <example> --platform web -- --no-default-features\n```\n\n## Contributing\n\n- Check out the website [section on contributing](https://dioxuslabs.com/learn/0.7/beyond/contributing).\n- Report issues on our [issue tracker](https://github.com/dioxuslabs/dioxus/issues).\n- [Join](https://discord.gg/XgGxMSkvUM) the discord and ask questions!\n\n<a href=\"https://github.com/dioxuslabs/dioxus/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=dioxuslabs/dioxus&max=30&columns=10\" />\n</a>\n\n## License\n\nThis project is licensed under either the [MIT license] or the [Apache-2 License].\n\n[apache-2 license]: https://github.com/DioxusLabs/dioxus/blob/master/LICENSE-APACHE\n[mit license]: https://github.com/DioxusLabs/dioxus/blob/master/LICENSE-MIT\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in Dioxus by you, shall be licensed as MIT or Apache-2, without any additional\nterms or conditions.\n",
      "stars_today": 573
    },
    {
      "id": 436297812,
      "name": "memos",
      "full_name": "usememos/memos",
      "description": "An open-source, self-hosted note-taking service. Your thoughts, your data, your control ‚Äî no tracking, no ads, no subscription fees.",
      "html_url": "https://github.com/usememos/memos",
      "stars": 53892,
      "forks": 3867,
      "language": "Go",
      "topics": [
        "docker",
        "foss",
        "go",
        "markdown",
        "memo",
        "microblog",
        "note-taking",
        "notecard",
        "react",
        "self-hosted",
        "social-network",
        "sqlite"
      ],
      "created_at": "2021-12-08T15:30:18Z",
      "updated_at": "2026-01-14T01:03:54Z",
      "pushed_at": "2026-01-13T15:19:48Z",
      "open_issues": 50,
      "owner": {
        "login": "usememos",
        "avatar_url": "https://avatars.githubusercontent.com/u/95764151?v=4"
      },
      "readme": "# Memos\n\n<img align=\"right\" height=\"96px\" src=\"https://raw.githubusercontent.com/usememos/.github/refs/heads/main/assets/logo-rounded.png\" alt=\"Memos\" />\n\nAn open-source, self-hosted note-taking service. Your thoughts, your data, your control ‚Äî no tracking, no ads, no subscription fees.\n\n[![Home](https://img.shields.io/badge/üè†-usememos.com-blue?style=flat-square)](https://usememos.com)\n[![Live Demo](https://img.shields.io/badge/‚ú®-Try%20Demo-orange?style=flat-square)](https://demo.usememos.com/)\n[![Docs](https://img.shields.io/badge/üìö-Documentation-green?style=flat-square)](https://usememos.com/docs)\n[![Discord](https://img.shields.io/badge/üí¨-Discord-5865f2?style=flat-square&logo=discord&logoColor=white)](https://discord.gg/tfPJa4UmAv)\n[![Docker Pulls](https://img.shields.io/docker/pulls/neosmemo/memos?style=flat-square&logo=docker)](https://hub.docker.com/r/neosmemo/memos)\n\n<img src=\"https://raw.githubusercontent.com/usememos/.github/refs/heads/main/assets/demo.png\" alt=\"Memos Demo Screenshot\" height=\"512\" />\n\n### üíé Featured Sponsors\n\n[**Warp** ‚Äî The AI-powered terminal built for speed and collaboration](https://go.warp.dev/memos)\n\n<a href=\"https://go.warp.dev/memos\" target=\"_blank\" rel=\"noopener\">\n  <img src=\"https://raw.githubusercontent.com/warpdotdev/brand-assets/main/Github/Sponsor/Warp-Github-LG-02.png\" alt=\"Warp - The AI-powered terminal built for speed and collaboration\" width=\"512\" />\n</a>\n\n---\n\n[**LambdaTest** - Cross-browser testing cloud](https://www.lambdatest.com/?utm_source=memos&utm_medium=sponsor)\n  \n<a href=\"https://www.lambdatest.com/?utm_source=memos&utm_medium=sponsor\" target=\"_blank\" rel=\"noopener\">\n  <img src=\"https://www.lambdatest.com/blue-logo.png\" alt=\"LambdaTest - Cross-browser testing cloud\" height=\"50\" />\n</a>\n\n## Overview\n\nMemos is a privacy-first, self-hosted knowledge base that works seamlessly for personal notes, team wikis, and knowledge management. Built with Go and React, it offers lightning-fast performance without compromising on features or usability.\n\n**Why choose Memos over cloud services?**\n\n| Feature           | Memos                          | Cloud Services                |\n| ----------------- | ------------------------------ | ----------------------------- |\n| **Privacy**       | ‚úÖ Self-hosted, zero telemetry | ‚ùå Your data on their servers |\n| **Cost**          | ‚úÖ Free forever, MIT license   | ‚ùå Subscription fees          |\n| **Performance**   | ‚úÖ Instant load, no latency    | ‚ö†Ô∏è Depends on internet        |\n| **Ownership**     | ‚úÖ Full control & export       | ‚ùå Vendor lock-in             |\n| **API Access**    | ‚úÖ Full REST + gRPC APIs       | ‚ö†Ô∏è Limited or paid            |\n| **Customization** | ‚úÖ Open source, forkable       | ‚ùå Closed ecosystem           |\n\n## Features\n\n- **üîí Privacy-First Architecture**\n\n  - Self-hosted on your infrastructure with zero telemetry\n  - Complete data ownership and export capabilities\n  - No tracking, no ads, no vendor lock-in\n\n- **üìù Markdown Native**\n\n  - Full markdown support\n  - Plain text storage ‚Äî take your data anywhere\n\n- **‚ö° Blazing Fast**\n\n  - Built with Go backend and React frontend\n  - Optimized for performance at any scale\n\n- **üê≥ Simple Deployment**\n\n  - One-line Docker installation\n  - Supports SQLite, MySQL, and PostgreSQL\n\n- **üîó Developer-Friendly**\n\n  - Full REST and gRPC APIs\n  - Easy integration with existing workflows\n\n- **üé® Beautiful Interface**\n  - Clean, minimal design and dark mode support\n  - Mobile-responsive layout\n\n## Quick Start\n\n### Docker (Recommended)\n\n```bash\ndocker run -d \\\n  --name memos \\\n  -p 5230:5230 \\\n  -v ~/.memos:/var/opt/memos \\\n  neosmemo/memos:stable\n```\n\nOpen `http://localhost:5230` and start writing!\n\n### Try the Live Demo\n\nDon't want to install yet? Try our [live demo](https://demo.usememos.com/) first!\n\n### Other Installation Methods\n\n- **Docker Compose** - Recommended for production deployments\n- **Pre-built Binaries** - Available for Linux, macOS, and Windows\n- **Kubernetes** - Helm charts and manifests available\n- **Build from Source** - For development and customization\n\nSee our [installation guide](https://usememos.com/docs/installation) for detailed instructions.\n\n## Contributing\n\nWe welcome contributions of all kinds! Whether you're fixing bugs, adding features, improving documentation, or helping with translations ‚Äî every contribution matters.\n\n**Ways to contribute:**\n\n- üêõ [Report bugs](https://github.com/usememos/memos/issues/new?template=bug_report.md)\n- üí° [Suggest features](https://github.com/usememos/memos/issues/new?template=feature_request.md)\n- üîß [Submit pull requests](https://github.com/usememos/memos/pulls)\n- üìñ [Improve documentation](https://github.com/usememos/memos/tree/main/docs)\n- üåç [Help with translations](https://github.com/usememos/memos/tree/main/web/src/locales)\n\n## Sponsors\n\nLove Memos? [Sponsor us on GitHub](https://github.com/sponsors/usememos) to help keep the project growing!\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=usememos/memos&type=Date)](https://star-history.com/#usememos/memos&Date)\n\n## License\n\nMemos is open-source software licensed under the [MIT License](LICENSE).\n\n## Privacy Policy\n\nMemos is built with privacy as a core principle. As a self-hosted application, all your data stays on your infrastructure. There is no telemetry, no tracking, and no data collection. See our [Privacy Policy](https://usememos.com/privacy) for details.\n\n---\n\n**[Website](https://usememos.com)** ‚Ä¢ **[Documentation](https://usememos.com/docs)** ‚Ä¢ **[Demo](https://demo.usememos.com/)** ‚Ä¢ **[Discord](https://discord.gg/tfPJa4UmAv)** ‚Ä¢ **[X/Twitter](https://x.com/usememos)**\n\n<a href=\"https://vercel.com/oss\">\n  <img alt=\"Vercel OSS Program\" src=\"https://vercel.com/oss/program-badge.svg\" />\n</a>\n",
      "stars_today": 411
    },
    {
      "id": 1002125012,
      "name": "vibe-kanban",
      "full_name": "BloopAI/vibe-kanban",
      "description": "Get 10X more out of Claude Code, Codex or any coding agent",
      "html_url": "https://github.com/BloopAI/vibe-kanban",
      "stars": 15655,
      "forks": 1456,
      "language": "Rust",
      "topics": [
        "agent",
        "ai-agents",
        "kanban",
        "management",
        "task-manager"
      ],
      "created_at": "2025-06-14T19:10:21Z",
      "updated_at": "2026-01-14T01:06:49Z",
      "pushed_at": "2026-01-13T18:45:52Z",
      "open_issues": 243,
      "owner": {
        "login": "BloopAI",
        "avatar_url": "https://avatars.githubusercontent.com/u/75376775?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://vibekanban.com\">\n    <picture>\n      <source srcset=\"frontend/public/vibe-kanban-logo-dark.svg\" media=\"(prefers-color-scheme: dark)\">\n      <source srcset=\"frontend/public/vibe-kanban-logo.svg\" media=\"(prefers-color-scheme: light)\">\n      <img src=\"frontend/public/vibe-kanban-logo.svg\" alt=\"Vibe Kanban Logo\">\n    </picture>\n  </a>\n</p>\n\n<p align=\"center\">Get 10X more out of Claude Code, Gemini CLI, Codex, Amp and other coding agents...</p>\n<p align=\"center\">\n  <a href=\"https://www.npmjs.com/package/vibe-kanban\"><img alt=\"npm\" src=\"https://img.shields.io/npm/v/vibe-kanban?style=flat-square\" /></a>\n  <a href=\"https://github.com/BloopAI/vibe-kanban/blob/main/.github/workflows/publish.yml\"><img alt=\"Build status\" src=\"https://img.shields.io/github/actions/workflow/status/BloopAI/vibe-kanban/.github%2Fworkflows%2Fpublish.yml\" /></a>\n  <a href=\"https://deepwiki.com/BloopAI/vibe-kanban\"><img src=\"https://deepwiki.com/badge.svg\" alt=\"Ask DeepWiki\"></a>\n</p>\n\n<h1 align=\"center\">\n  <a href=\"https://jobs.polymer.co/vibe-kanban?source=github\"><strong>We're hiring!</strong></a>\n</h1>\n\n![](frontend/public/vibe-kanban-screenshot-overview.png)\n\n## Overview\n\nAI coding agents are increasingly writing the world's code and human engineers now spend the majority of their time planning, reviewing, and orchestrating tasks. Vibe Kanban streamlines this process, enabling you to:\n\n- Easily switch between different coding agents\n- Orchestrate the execution of multiple coding agents in parallel or in sequence\n- Quickly review work and start dev servers\n- Track the status of tasks that your coding agents are working on\n- Centralise configuration of coding agent MCP configs\n- Open projects remotely via SSH when running Vibe Kanban on a remote server\n\nYou can watch a video overview [here](https://youtu.be/TFT3KnZOOAk).\n\n## Installation\n\nMake sure you have authenticated with your favourite coding agent. A full list of supported coding agents can be found in the [docs](https://vibekanban.com/docs). Then in your terminal run:\n\n```bash\nnpx vibe-kanban\n```\n\n## Documentation\n\nPlease head to the [website](https://vibekanban.com/docs) for the latest documentation and user guides.\n\n## Support\n\nWe use [GitHub Discussions](https://github.com/BloopAI/vibe-kanban/discussions) for feature requests. Please open a discussion to create a feature request. For bugs please open an issue on this repo.\n\n## Contributing\n\nWe would prefer that ideas and changes are first raised with the core team via [GitHub Discussions](https://github.com/BloopAI/vibe-kanban/discussions) or [Discord](https://discord.gg/AC4nwVtJM3), where we can discuss implementation details and alignment with the existing roadmap. Please do not open PRs without first discussing your proposal with the team.\n\n## Development\n\n### Prerequisites\n\n- [Rust](https://rustup.rs/) (latest stable)\n- [Node.js](https://nodejs.org/) (>=18)\n- [pnpm](https://pnpm.io/) (>=8)\n\nAdditional development tools:\n```bash\ncargo install cargo-watch\ncargo install sqlx-cli\n```\n\nInstall dependencies:\n```bash\npnpm i\n```\n\n### Running the dev server\n\n```bash\npnpm run dev\n```\n\nThis will start the backend. A blank DB will be copied from the `dev_assets_seed` folder.\n\n### Building the frontend\n\nTo build just the frontend:\n\n```bash\ncd frontend\npnpm build\n```\n\n### Build from source (macOS)\n\n1. Run `./local-build.sh`\n2. Test with `cd npx-cli && node bin/cli.js`\n\n\n### Environment Variables\n\nThe following environment variables can be configured at build time or runtime:\n\n| Variable | Type | Default | Description |\n|----------|------|---------|-------------|\n| `POSTHOG_API_KEY` | Build-time | Empty | PostHog analytics API key (disables analytics if empty) |\n| `POSTHOG_API_ENDPOINT` | Build-time | Empty | PostHog analytics endpoint (disables analytics if empty) |\n| `PORT` | Runtime | Auto-assign | **Production**: Server port. **Dev**: Frontend port (backend uses PORT+1) |\n| `BACKEND_PORT` | Runtime | `0` (auto-assign) | Backend server port (dev mode only, overrides PORT+1) |\n| `FRONTEND_PORT` | Runtime | `3000` | Frontend dev server port (dev mode only, overrides PORT) |\n| `HOST` | Runtime | `127.0.0.1` | Backend server host |\n| `DISABLE_WORKTREE_ORPHAN_CLEANUP` | Runtime | Not set | Disable git worktree cleanup (for debugging) |\n\n**Build-time variables** must be set when running `pnpm run build`. **Runtime variables** are read when the application starts.\n\n### Remote Deployment\n\nWhen running Vibe Kanban on a remote server (e.g., via systemctl, Docker, or cloud hosting), you can configure your editor to open projects via SSH:\n\n1. **Access via tunnel**: Use Cloudflare Tunnel, ngrok, or similar to expose the web UI\n2. **Configure remote SSH** in Settings ‚Üí Editor Integration:\n   - Set **Remote SSH Host** to your server hostname or IP\n   - Set **Remote SSH User** to your SSH username (optional)\n3. **Prerequisites**:\n   - SSH access from your local machine to the remote server\n   - SSH keys configured (passwordless authentication)\n   - VSCode Remote-SSH extension\n\nWhen configured, the \"Open in VSCode\" buttons will generate URLs like `vscode://vscode-remote/ssh-remote+user@host/path` that open your local editor and connect to the remote server.\n\nSee the [documentation](https://vibekanban.com/docs/configuration-customisation/global-settings#remote-ssh-configuration) for detailed setup instructions.\n",
      "stars_today": 357
    },
    {
      "id": 995029641,
      "name": "claude-flow",
      "full_name": "ruvnet/claude-flow",
      "description": "üåä The leading agent orchestration platform for Claude. Deploy intelligent multi-agent swarms, coordinate autonomous workflows, and build conversational AI systems. Features    enterprise-grade architecture, distributed swarm intelligence, RAG integration, and native Claude Code support via MCP protocol. Ranked #1 in agent-based frameworks.",
      "html_url": "https://github.com/ruvnet/claude-flow",
      "stars": 11909,
      "forks": 1501,
      "language": "JavaScript",
      "topics": [
        "agentic-ai",
        "agentic-engineering",
        "agentic-framework",
        "agentic-rag",
        "agentic-workflow",
        "ai-assistant",
        "ai-tools",
        "anthropic-claude",
        "autonomous-agents",
        "claude-code",
        "codex",
        "huggingface",
        "jules",
        "mcp-server",
        "model-context-protocol",
        "multi-agent",
        "multi-agent-systems",
        "npx",
        "swarm",
        "swarm-intelligence"
      ],
      "created_at": "2025-06-02T21:24:20Z",
      "updated_at": "2026-01-14T01:03:51Z",
      "pushed_at": "2026-01-14T00:23:20Z",
      "open_issues": 338,
      "owner": {
        "login": "ruvnet",
        "avatar_url": "https://avatars.githubusercontent.com/u/2934394?v=4"
      },
      "readme": "# üåä Claude-Flow v2.7.0: Enterprise AI Orchestration Platform\n\n<div align=\"center\">\n\n[![üåü Star on GitHub](https://img.shields.io/github/stars/ruvnet/claude-flow?style=for-the-badge&logo=github&color=gold)](https://github.com/ruvnet/claude-flow)\n[![üìà Downloads](https://img.shields.io/npm/dt/claude-flow?style=for-the-badge&logo=npm&color=blue&label=Downloads)](https://www.npmjs.com/package/claude-flow)\n[![üì¶ Latest Release](https://img.shields.io/npm/v/claude-flow/alpha?style=for-the-badge&logo=npm&color=green&label=v2.7.0-alpha.10)](https://www.npmjs.com/package/claude-flow)\n[![‚ö° Claude Code](https://img.shields.io/badge/Claude%20Code-SDK%20Integrated-green?style=for-the-badge&logo=anthropic)](https://github.com/ruvnet/claude-flow)\n[![üèõÔ∏è Agentics Foundation](https://img.shields.io/badge/Agentics-Foundation-crimson?style=for-the-badge&logo=openai)](https://discord.com/invite/dfxmpwkG2D)\n[![üõ°Ô∏è MIT License](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge&logo=opensourceinitiative)](https://opensource.org/licenses/MIT)\n\n</div>\n\n## üåü **Overview**\n\n**Claude-Flow v2.7** is an enterprise-grade AI orchestration platform that combines **hive-mind swarm intelligence**, **persistent memory**, and **100+ advanced MCP tools** to revolutionize AI-powered development workflows.\n\n### üéØ **Key Features**\n\n- **üé® 25 Claude Skills**: Natural language-activated skills for development, GitHub, memory, and automation\n- **üöÄ AgentDB v1.3.9 Integration**: 96x-164x faster vector search with semantic understanding (PR #830)\n- **üß† Hybrid Memory System**: AgentDB + ReasoningBank with automatic fallback\n- **üîç Semantic Vector Search**: HNSW indexing (O(log n)) + 9 RL algorithms\n- **üêù Hive-Mind Intelligence**: Queen-led AI coordination with specialized worker agents\n- **üîß 100 MCP Tools**: Comprehensive toolkit for swarm orchestration and automation\n- **üîÑ Dynamic Agent Architecture (DAA)**: Self-organizing agents with fault tolerance\n- **üíæ Persistent Memory**: 150x faster search, 4-32x memory reduction (quantization)\n- **ü™ù Advanced Hooks System**: Automated workflows with pre/post operation hooks\n- **üìä GitHub Integration**: 6 specialized modes for repository management\n- **üåê Flow Nexus Cloud**: E2B sandboxes, AI swarms, challenges, and marketplace\n\n> üî• **Revolutionary AI Coordination**: Build faster, smarter, and more efficiently with AI-powered development orchestration\n>\n> üÜï **NEW: AgentDB Integration**: 96x-164x performance boost with semantic vector search, reflexion memory, and skill library auto-consolidation\n\n\n---\n\n## ‚ö° **Quick Start**\n\n### üìã **Prerequisites**\n\n- **Node.js 18+** (LTS recommended)\n- **npm 9+** or equivalent package manager\n- **Windows users**: See [Windows Installation Guide](./docs/windows-installation.md) for special instructions\n\n‚ö†Ô∏è **IMPORTANT**: Claude Code must be installed first:\n\n```bash\n# 1. Install Claude Code globally\nnpm install -g @anthropic-ai/claude-code\n\n# 2. (Optional) Skip permissions check for faster setup\nclaude --dangerously-skip-permissions\n```\n\n### üöÄ **Install Latest Alpha**\n\n```bash\n# NPX (recommended - always latest)\nnpx claude-flow@alpha init --force\nnpx claude-flow@alpha --help\n\n# Or install globally\nnpm install -g claude-flow@alpha\nclaude-flow --version\n# v2.7.0-alpha.10\n```\n\n---\n\n## üé® **Skills System**\n\nClaude-Flow includes **25 specialized skills** that activate automatically via natural language - no commands to memorize:\n\n```bash\n# Just describe what you want - skills activate automatically\n\"Let's pair program on this feature\"        ‚Üí pair-programming skill\n\"Review this PR for security issues\"       ‚Üí github-code-review skill\n\"Use vector search to find similar code\"   ‚Üí agentdb-vector-search skill\n\"Create a swarm to build this API\"         ‚Üí swarm-orchestration skill\n```\n\n**Skill Categories:**\n- **Development & Methodology** (3) - SPARC, pair programming, skill builder\n- **Intelligence & Memory** (6) - AgentDB integration with 150x-12,500x performance\n- **Swarm Coordination** (3) - Multi-agent orchestration and hive-mind\n- **GitHub Integration** (5) - PR review, workflows, releases, multi-repo\n- **Automation & Quality** (4) - Hooks, verification, performance analysis\n- **Flow Nexus Platform** (3) - Cloud sandboxes and neural training\n\nüìö **[Complete Skills Tutorial](./docs/skills-tutorial.md)** - Full guide with usage examples\n\n---\n\n## üÜï **What's New in v2.7.0-alpha.10**\n\n### ‚úÖ **Semantic Search Fixed**\nCritical bug fix for semantic search returning 0 results:\n- ‚úÖ Fixed stale compiled code (dist-cjs/ now uses Node.js backend)\n- ‚úÖ Fixed result mapping for `retrieveMemories()` flat structure\n- ‚úÖ Fixed parameter mismatch (namespace vs domain)\n- ‚úÖ 2-3ms query latency with hash embeddings\n- ‚úÖ Works without API keys (deterministic 1024-dim embeddings)\n\n### üß† **ReasoningBank Integration (agentic-flow@1.5.13)**\n- **Node.js Backend**: Replaced WASM with SQLite + better-sqlite3\n- **Persistent Storage**: All memories saved to `.swarm/memory.db`\n- **Semantic Search**: MMR ranking with 4-factor scoring\n- **Database Tables**: patterns, embeddings, trajectories, links\n- **Performance**: 2ms queries, 400KB per pattern with embeddings\n\n```bash\n# Semantic search now fully functional\nnpx claude-flow@alpha memory store test \"API configuration\" --namespace semantic --reasoningbank\nnpx claude-flow@alpha memory query \"configuration\" --namespace semantic --reasoningbank\n# ‚úÖ Found 3 results (semantic search) in 2ms\n```\n\nüìö **Release Notes**: [v2.7.0-alpha.10](./docs/RELEASE-NOTES-v2.7.0-alpha.10.md)\n\n## üß† **Memory System Commands**\n\n### **üöÄ NEW: AgentDB v1.3.9 Integration (96x-164x Performance Boost)**\n\n**Revolutionary Performance Improvements:**\n- **Vector Search**: 96x faster (9.6ms ‚Üí <0.1ms)\n- **Batch Operations**: 125x faster\n- **Large Queries**: 164x faster\n- **Memory Usage**: 4-32x reduction via quantization\n\n```bash\n# Semantic vector search (understands meaning, not just keywords)\nnpx claude-flow@alpha memory vector-search \"user authentication flow\" \\\n  --k 10 --threshold 0.7 --namespace backend\n\n# Store with vector embedding for semantic search\nnpx claude-flow@alpha memory store-vector api_design \"REST endpoints\" \\\n  --namespace backend --metadata '{\"version\":\"v2\"}'\n\n# Get AgentDB integration status and capabilities\nnpx claude-flow@alpha memory agentdb-info\n\n# Installation (hybrid mode - 100% backward compatible)\nnpm install agentdb@1.3.9\n```\n\n**New Features:**\n- ‚úÖ **Semantic vector search** (HNSW indexing, O(log n))\n- ‚úÖ **9 RL algorithms** (Q-Learning, PPO, MCTS, Decision Transformer)\n- ‚úÖ **Reflexion memory** (learn from past experiences)\n- ‚úÖ **Skill library** (auto-consolidate successful patterns)\n- ‚úÖ **Causal reasoning** (understand cause-effect relationships)\n- ‚úÖ **Quantization** (binary 32x, scalar 4x, product 8-16x reduction)\n- ‚úÖ **100% backward compatible** (hybrid mode with graceful fallback)\n\n**Documentation**: `docs/agentdb/PRODUCTION_READINESS.md` | **PR**: #830\n\n---\n\n### **ReasoningBank (Legacy SQLite Memory - Still Supported)**\n\n```bash\n# Store memories with pattern matching\nnpx claude-flow@alpha memory store api_key \"REST API configuration\" \\\n  --namespace backend --reasoningbank\n\n# Query with pattern search (2-3ms latency)\nnpx claude-flow@alpha memory query \"API config\" \\\n  --namespace backend --reasoningbank\n# ‚úÖ Found 3 results (pattern matching)\n\n# List all memories\nnpx claude-flow@alpha memory list --namespace backend --reasoningbank\n\n# Check status and statistics\nnpx claude-flow@alpha memory status --reasoningbank\n# ‚úÖ Total memories: 30\n#    Embeddings: 30\n#    Storage: .swarm/memory.db\n```\n\n**Features:**\n- ‚úÖ **No API Keys Required**: Hash-based embeddings (1024 dimensions)\n- ‚úÖ **Persistent Storage**: SQLite database survives restarts\n- ‚úÖ **Pattern Matching**: LIKE-based search with similarity scoring\n- ‚úÖ **Namespace Isolation**: Organize memories by domain\n- ‚úÖ **Fast Queries**: 2-3ms average latency\n- ‚úÖ **Process Cleanup**: Automatic database closing\n\n**Optional Enhanced Embeddings:**\n```bash\n# For better semantic accuracy with text-embedding-3-small (1536 dimensions)\n# Set OPENAI environment variable (see ReasoningBank documentation)\n```\n\n---\n\n## üêù **Swarm Orchestration**\n\n### **Quick Swarm Commands**\n\n```bash\n# Quick task execution (recommended)\nnpx claude-flow@alpha swarm \"build REST API with authentication\" --claude\n\n# Multi-agent coordination\nnpx claude-flow@alpha swarm init --topology mesh --max-agents 5\nnpx claude-flow@alpha swarm spawn researcher \"analyze API patterns\"\nnpx claude-flow@alpha swarm spawn coder \"implement endpoints\"\nnpx claude-flow@alpha swarm status\n```\n\n### **Hive-Mind for Complex Projects**\n\n```bash\n# Initialize hive-mind system\nnpx claude-flow@alpha hive-mind wizard\nnpx claude-flow@alpha hive-mind spawn \"build enterprise system\" --claude\n\n# Session management\nnpx claude-flow@alpha hive-mind status\nnpx claude-flow@alpha hive-mind resume session-xxxxx\n```\n\n**When to Use:**\n| Feature | `swarm` | `hive-mind` |\n|---------|---------|-------------|\n| **Best For** | Quick tasks | Complex projects |\n| **Setup** | Instant | Interactive wizard |\n| **Memory** | Task-scoped | Project-wide SQLite |\n| **Sessions** | Temporary | Persistent + resume |\n\n---\n\n## üîß **MCP Tools Integration**\n\n### **Setup MCP Servers**\n\n```bash\n# Add Claude Flow MCP server (required)\nclaude mcp add claude-flow npx claude-flow@alpha mcp start\n\n# Optional: Enhanced coordination\nclaude mcp add ruv-swarm npx ruv-swarm mcp start\n\n# Optional: Cloud features (requires registration)\nclaude mcp add flow-nexus npx flow-nexus@latest mcp start\n```\n\n### **Available MCP Tools (100 Total)**\n\n**Core Tools:**\n- `swarm_init`, `agent_spawn`, `task_orchestrate`\n- `memory_usage`, `memory_search`\n- `neural_status`, `neural_train`, `neural_patterns`\n\n**Memory Tools:**\n- `mcp__claude-flow__memory_usage` - Store/retrieve persistent memory\n- `mcp__claude-flow__memory_search` - Pattern-based search\n\n**GitHub Tools:**\n- `github_repo_analyze`, `github_pr_manage`, `github_issue_track`\n\n**Performance Tools:**\n- `benchmark_run`, `performance_report`, `bottleneck_analyze`\n\nüìö **Full Reference**: [MCP Tools Documentation](./docs/MCP-TOOLS.md)\n\n---\n\n## ü™ù **Advanced Hooks System**\n\n### **Automated Workflow Enhancement**\n\nClaude-Flow automatically configures hooks for enhanced operations:\n\n```bash\n# Auto-configures hooks during init\nnpx claude-flow@alpha init --force\n```\n\n### **Available Hooks**\n\n**Pre-Operation:**\n- `pre-task`: Auto-assigns agents by complexity\n- `pre-edit`: Validates files and prepares resources\n- `pre-command`: Security validation\n\n**Post-Operation:**\n- `post-edit`: Auto-formats code\n- `post-task`: Trains neural patterns\n- `post-command`: Updates memory\n\n**Session Management:**\n- `session-start`: Restores previous context\n- `session-end`: Generates summaries\n- `session-restore`: Loads memory\n\n---\n\n## üéØ **Common Workflows**\n\n### **Pattern 1: Single Feature Development**\n```bash\n# Initialize once per feature\nnpx claude-flow@alpha init --force\nnpx claude-flow@alpha hive-mind spawn \"Implement authentication\" --claude\n\n# Continue same feature (reuse hive)\nnpx claude-flow@alpha memory query \"auth\" --recent\nnpx claude-flow@alpha swarm \"Add password reset\" --continue-session\n```\n\n### **Pattern 2: Multi-Feature Project**\n```bash\n# Project initialization\nnpx claude-flow@alpha init --force --project-name \"my-app\"\n\n# Feature 1: Authentication\nnpx claude-flow@alpha hive-mind spawn \"auth-system\" --namespace auth --claude\n\n# Feature 2: User management\nnpx claude-flow@alpha hive-mind spawn \"user-mgmt\" --namespace users --claude\n```\n\n### **Pattern 3: Research & Analysis**\n```bash\n# Start research session\nnpx claude-flow@alpha hive-mind spawn \"Research microservices\" \\\n  --agents researcher,analyst --claude\n\n# Check learned knowledge\nnpx claude-flow@alpha memory stats\nnpx claude-flow@alpha memory query \"microservices patterns\" --reasoningbank\n```\n\n---\n\n## üìä **Performance & Stats**\n\n- **84.8% SWE-Bench solve rate** - Industry-leading problem-solving\n- **32.3% token reduction** - Efficient context management\n- **2.8-4.4x speed improvement** - Parallel coordination\n- **96x-164x faster search** - üÜï AgentDB vector search (9.6ms ‚Üí <0.1ms)\n- **4-32x memory reduction** - üÜï AgentDB quantization\n- **2-3ms query latency** - ReasoningBank pattern search (legacy)\n- **64 specialized agents** - Complete development ecosystem\n- **100 MCP tools** - Comprehensive automation toolkit\n- **180 AgentDB tests** - >90% coverage, production-ready\n\n---\n\n## üìö **Documentation**\n\n### **üìñ Core Documentation**\n- **[Documentation Hub](./docs/)** - Complete documentation index with organized structure\n- **[Skills Tutorial](./docs/guides/skills-tutorial.md)** - Complete guide to 25 Claude Flow skills with natural language invocation\n- **[Installation Guide](./docs/INSTALLATION.md)** - Setup instructions\n- **[Memory System Guide](./docs/MEMORY-SYSTEM.md)** - ReasoningBank + AgentDB hybrid\n- **[MCP Tools Reference](./docs/MCP-TOOLS.md)** - Complete tool catalog\n- **[Agent System](./docs/AGENT-SYSTEM.md)** - All 64 agents\n\n### **üöÄ Release Notes & Changelogs**\n- **[v2.7.1](./docs/releases/v2.7.1/)** - Current stable release with critical fixes\n- **[v2.7.0-alpha.10](./docs/releases/v2.7.0-alpha.10/)** - Semantic search fix\n- **[v2.7.0-alpha.9](./docs/releases/v2.7.0-alpha.9/)** - Process cleanup\n- **[Changelog](./CHANGELOG.md)** - Full version history\n\n### **üß† AgentDB Integration (96x-164x Performance Boost)**\n- **[AgentDB Documentation](./docs/agentdb/)** - üÜï Complete AgentDB v1.3.9 integration docs\n  - [Production Readiness Guide](./docs/agentdb/PRODUCTION_READINESS.md) - Deployment guide\n  - [Implementation Complete](./docs/agentdb/SWARM_IMPLEMENTATION_COMPLETE.md) - 3-agent swarm details (180 tests)\n  - [Backward Compatibility](./docs/agentdb/BACKWARD_COMPATIBILITY_GUARANTEE.md) - 100% compatibility guarantee\n  - [Integration Plan](./docs/agentdb/AGENTDB_INTEGRATION_PLAN.md) - Planning and design\n  - [Optimization Report](./docs/agentdb/OPTIMIZATION_REPORT.md) - Performance analysis\n\n### **‚ö° Performance & Quality**\n- **[Performance Documentation](./docs/performance/)** - Optimization guides and benchmarks\n  - [JSON Improvements](./docs/performance/PERFORMANCE-JSON-IMPROVEMENTS.md) - JSON optimization results\n  - [Metrics Guide](./docs/performance/PERFORMANCE-METRICS-GUIDE.md) - Performance tracking\n- **[Bug Fixes](./docs/fixes/)** - Bug fix documentation and patches\n- **[Validation Reports](./docs/validation/)** - Test reports and verification results\n\n### **üõ†Ô∏è Advanced Topics**\n- **[Neural Module](./docs/NEURAL-MODULE.md)** - SAFLA self-learning\n- **[Goal Module](./docs/GOAL-MODULE.md)** - GOAP intelligent planning\n- **[Hive-Mind Intelligence](./docs/HIVE-MIND.md)** - Queen-led coordination\n- **[GitHub Integration](./docs/GITHUB-INTEGRATION.md)** - Repository automation\n\n### **‚öôÔ∏è Configuration & Setup**\n- **[CLAUDE.md Templates](./docs/CLAUDE-MD-TEMPLATES.md)** - Project configs\n- **[SPARC Methodology](./docs/SPARC.md)** - TDD patterns\n- **[Windows Installation](./docs/windows-installation.md)** - Windows setup\n\n---\n\n## ü§ù **Community & Support**\n\n- **GitHub Issues**: [Report bugs or request features](https://github.com/ruvnet/claude-flow/issues)\n- **Discord**: [Join the Agentics Foundation community](https://discord.com/invite/dfxmpwkG2D)\n- **Documentation**: [Complete guides and tutorials](https://github.com/ruvnet/claude-flow/wiki)\n- **Examples**: [Real-world usage patterns](https://github.com/ruvnet/claude-flow/tree/main/examples)\n\n---\n\n## üöÄ **Roadmap & Targets**\n\n### **Immediate (Q4 2025)**\n- ‚úÖ Semantic search fix (v2.7.0-alpha.10)\n- ‚úÖ ReasoningBank Node.js backend\n- ‚úÖ AgentDB v1.3.9 integration (PR #830) - 96x-164x performance boost\n- üîÑ AgentDB production deployment (Q4 2025)\n- üîÑ Enhanced embedding models\n- üîÑ Multi-user collaboration features\n\n### **Q1 2026**\n- Advanced neural pattern recognition\n- Cloud swarm coordination\n- Real-time agent communication\n- Enterprise SSO integration\n\n### **Growth Targets**\n- 5K+ GitHub stars, 50K npm downloads/month\n- $25K MRR, 15 enterprise customers\n- 90%+ error prevention\n- 30+ minutes saved per developer per week\n\n---\n\n## Star History\n\n<a href=\"https://www.star-history.com/#ruvnet/claude-flow&Date\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=ruvnet/claude-flow&type=Date&theme=dark\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=ruvnet/claude-flow&type=Date\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=ruvnet/claude-flow&type=Date\" />\n </picture>\n</a>\n\n---\n\n## üìÑ **License**\n\nMIT License - see [LICENSE](./LICENSE) for details\n\n---\n\n**Built with ‚ù§Ô∏è by [rUv](https://github.com/ruvnet) | Powered by Revolutionary AI**\n\n*v2.7.0-alpha.10 - Semantic Search Fixed + ReasoningBank Node.js Backend*\n\n</div>\n",
      "stars_today": 350
    },
    {
      "id": 834966974,
      "name": "Pumpkin",
      "full_name": "Pumpkin-MC/Pumpkin",
      "description": "Empowering everyone to host fast and efficient Minecraft servers.",
      "html_url": "https://github.com/Pumpkin-MC/Pumpkin",
      "stars": 6386,
      "forks": 372,
      "language": "Rust",
      "topics": [
        "docker",
        "game-server",
        "gamedev",
        "minecraft",
        "minecraft-bedrock-edition",
        "minecraft-protocol",
        "minecraft-server",
        "networking",
        "rust",
        "server"
      ],
      "created_at": "2024-07-28T21:07:38Z",
      "updated_at": "2026-01-14T00:30:42Z",
      "pushed_at": "2026-01-13T22:50:40Z",
      "open_issues": 153,
      "owner": {
        "login": "Pumpkin-MC",
        "avatar_url": "https://avatars.githubusercontent.com/u/193089026?v=4"
      },
      "readme": "<div align=\"center\">\n\n# Pumpkin\n\n![CI](https://github.com/Pumpkin-MC/Pumpkin/actions/workflows/rust.yml/badge.svg)\n[![Discord](https://img.shields.io/discord/1268592337445978193.svg?label=&logo=discord&logoColor=ffffff&color=7389D8&labelColor=6A7EC2)](https://discord.gg/wT8XjrjKkf)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n![Current version)](https://img.shields.io/badge/current_version-1.21.11-blue)\n\n</div>\n\n[Pumpkin](https://pumpkinmc.org/) is a Minecraft server built entirely in Rust, offering a fast, efficient,\nand customizable experience. It prioritizes performance and player enjoyment while adhering to the core mechanics of the game.\n<div align=\"center\">\n\n![chunk loading](/assets/pumpkin_chunk_loading.GIF)\n\n</div>\n\n## Goals\n\n- **Performance**: Leveraging multi-threading for maximum speed and efficiency.\n- **Compatibility**: Supports the latest Java & Bedrock Minecraft server version while adhering to Vanilla game mechanics.\n- **Security**: Prioritizes security by preventing known security exploits.\n- **Flexibility**: Highly configurable, with the ability to disable unnecessary features.\n- **Extensibility**: Provides a foundation for plugin development.\n\n> [!IMPORTANT]\n> Pumpkin is currently under heavy development\n\n## Features\n\n- [x] Configuration (toml)\n- [x] Server Status/Ping\n- Networking\n  - [x] Encryption\n  - [x] Packet Compression\n- Player Configuration\n  - [x] Registries (biome types, paintings, dimensions)\n  - [x] Server Brand\n  - [x] Server Links\n  - [x] Set Resource Pack\n  - [x] Cookies\n- World\n  - [x] World Joining\n  - [x] Player Tab-list\n  - [x] Scoreboard\n  - [x] World Loading\n  - [x] World Time\n  - [x] World Borders\n  - [x] World Saving\n  - [x] Lighting\n  - [x] Entity Spawning\n  - [x] Item drops (W.I.P)\n  - [x] Bossbar\n  - [x] TNT\n  - [x] Chunk Loading (Vanilla, Linear)\n  - [x] Chunk Generation\n  - [x] Chunk Saving (Vanilla, Linear)\n  - [x] Biomes\n  - [x] Redstone (W.I.P)\n  - [x] Liquid Physics\n  - [x] Vegetation\n  - [ ] Structure Generation\n- Player\n  - [x] Skins\n  - [x] Client brand\n  - [x] Teleport\n  - [x] Movement\n  - [x] Animation\n  - [x] Inventory\n  - [x] Combat\n  - [x] Experience\n  - [x] Hunger\n  - [X] Off Hand\n  - [ ] Advancements\n  - [x] Eating\n- Entities\n  - [x] Non-Living (Minecart, Eggs...) (W.I.P)\n  - [x] Entity Effects\n  - [x] Players\n  - [x] Mobs (W.I.P)\n  - [x] Animals (W.I.P)\n  - [x] Entity AI (W.I.P)\n  - [ ] Boss\n  - [ ] Villagers\n  - [ ] Mobs Inventory\n  - [X] Entity Saving\n- Server\n  - [x] Plugins (W.I.P)\n  - [x] Query\n  - [x] RCON\n  - [x] Inventories\n  - [x] Particles\n  - [x] Chat\n  - [x] Commands (W.I.P)\n  - [x] Permissions\n  - [x] Translations\n- Proxy\n  - [x] Bungeecord\n  - [x] Velocity\n\nCheck out our [Github Project](https://github.com/orgs/Pumpkin-MC/projects/3) to see current progress.\n\n## How to run\n\nSee our [Quick Start](https://docs.pumpkinmc.org/#quick-start) guide to get Pumpkin running.\n\n## Contributions\n\nContributions are welcome! See [CONTRIBUTING.md](CONTRIBUTING.md)\n\n## Docs\n\nPumpkin's documentation can be found at <https://pumpkinmc.org/>\n\n## Communication\n\nConsider joining [our Discord server](https://discord.gg/wT8XjrjKkf) to stay up-to-date on events, updates, and connect with other members.\n\n## Funding\n\nIf you want to fund me and help the project, check out my [GitHub sponsors](https://github.com/sponsors/Snowiiii).\n",
      "stars_today": 205
    },
    {
      "id": 1073433866,
      "name": "openscreen",
      "full_name": "siddharthvaddem/openscreen",
      "description": "Create stunning screen recordings for free. Open-source, no subscriptions, no watermarks, and free for commercial use. An alternative to Screen Studio. ",
      "html_url": "https://github.com/siddharthvaddem/openscreen",
      "stars": 5752,
      "forks": 352,
      "language": "TypeScript",
      "topics": [
        "electron",
        "open-source",
        "pixijs",
        "screen-capture",
        "screen-recorder"
      ],
      "created_at": "2025-10-10T05:36:55Z",
      "updated_at": "2026-01-14T01:07:30Z",
      "pushed_at": "2026-01-11T18:27:18Z",
      "open_issues": 21,
      "owner": {
        "login": "siddharthvaddem",
        "avatar_url": "https://avatars.githubusercontent.com/u/70214527?v=4"
      },
      "readme": "<p align=\"center\">\r\n  <img src=\"openscreen.png\" alt=\"OpenScreen Logo\" width=\"64\" />\r\n  <br />\r\n\t  <br />\r\n  <a href=\"https://deepwiki.com/siddharthvaddem/openscreen\">\r\n    <img src=\"https://deepwiki.com/badge.svg\" alt=\"Ask DeepWiki\" />\r\n  </a>\r\n</p>\r\n\r\n# <p align=\"center\">OpenScreen</p>\r\n\r\n<p align=\"center\"><strong>OpenScreen is your free, open-source alternative to Screen Studio (sort of).</strong></p>\r\n\r\n\r\n\r\nIf you don't want to pay $29/month for Screen Studio but want a much simpler version that does what most people seem to need, making beautiful product demos and walkthroughs, here's a free-to-use app for you. OpenScreen does not offer all Screen Studio features, but covers the basics well!\r\n\r\nScreen Studio is an awesome product and this is definitely not a 1:1 clone. OpenScreen is a much simpler take, just the basics for folks who want control and don't want to pay. If you need all the fancy features, your best bet is to support Screen Studio (they really do a great job, haha). But if you just want something free (no gotchas) and open, this project does the job!\r\n\r\nOpenScreen is 100% free for personal and commercial use. Use it, modify it, distribute it. (Just be cool üòÅ and give a shoutout if you feel like it !)\r\n\r\n\r\n\r\n**‚ö†Ô∏è DISCLAIMER: This is very much in beta and might be buggy here and there (but hope you have a good experience!).**\r\n\r\n</p>\r\n<p align=\"center\">\r\n\t<img src=\"preview.png\" alt=\"OpenScreen App Preview\" style=\"height: 320px; margin-right: 12px;\" />\r\n\t<img src=\"preview2.png\" alt=\"OpenScreen App Preview 2\" style=\"height: 320px; margin-right: 12px;\" />\r\n\t<img src=\"preview3.png\" alt=\"OpenScreen App Preview 3\" style=\"height: 320px; margin-right: 12px;\" />\r\n\t<img src=\"preview4.png\" alt=\"OpenScreen App Preview 4\" style=\"height: 320px; margin-right: 12px;\" />\r\n\t\r\n</p>\r\n</p>\r\n\r\n## Core Features\r\n- Record your whole screen or specific apps\r\n- Add manual zooms (customizable depth levels)\r\n- Customize the duration and position of zooms however you please\r\n- Crop video recordings to hide parts\r\n- Choose between wallpapers, solid colors, gradients or your own picture for your background\r\n- Motion blur for smoother pan and zoom effects\r\n- Add annotations (text, arrows, images)\r\n- Trim sections of the clip\r\n- Export in different aspect ratios and resolutions\r\n\r\n## Installation\r\n\r\nDownload the latest installer for your platform from the [GitHub Releases](https://github.com/siddharthvaddem/openscreen/releases) page.\r\n\r\n### macOS\r\n\r\nIf you encounter issues with macOS Gatekeeper blocking the app (since it does not come with a developer certificate), you can bypass this by running the following command in your terminal after installation:\r\n\r\n```bash\r\nxattr -rd com.apple.quarantine /Applications/Openscreen.app\r\n```\r\n\r\nAfter running this command, proceed to **System Preferences > Security & Privacy** to grant the necessary permissions for \"screen recording\" and \"accessibility\". Once permissions are granted, you can launch the app.\r\n\r\n### Linux\r\n\r\nDownload the `.AppImage` file from the releases page. Make it executable and run:\r\n\r\n```bash\r\nchmod +x Openscreen-Linux-*.AppImage\r\n./Openscreen-Linux-*.AppImage\r\n```\r\n\r\nYou may need to grant screen recording permissions depending on your desktop environment.\r\n\r\n## Built with\r\n- Electron\r\n- React\r\n- TypeScript\r\n- Vite\r\n- PixiJS\r\n- dnd-timeline\r\n\r\n---\r\n\r\n\r\n_I'm new to open source, idk what I'm doing lol. If something is wrong please raise an issue üôè_\r\n\r\n## Contributing\r\n\r\nContributions are welcome! If you‚Äôd like to help out or see what‚Äôs currently being worked on, take a look at the open issues and the [project roadmap](https://github.com/users/siddharthvaddem/projects/3) to understand the current direction of the project and find ways to contribute.\r\n\r\n\r\n## License\r\n\r\n\r\nThis project is licensed under the [MIT License](./LICENSE). By using this software, you agree that the authors are not liable for any issues, damages, or claims arising from its use.\r\n\r\n",
      "stars_today": 167
    },
    {
      "id": 568098118,
      "name": "plane",
      "full_name": "makeplane/plane",
      "description": "üî•üî•üî• Open-source Jira, Linear, Monday, and ClickUp alternative. Plane is a modern project management platform to manage tasks, sprints, docs, and triage.",
      "html_url": "https://github.com/makeplane/plane",
      "stars": 44009,
      "forks": 3313,
      "language": "TypeScript",
      "topics": [
        "boards",
        "bug-tracker",
        "django",
        "docker",
        "gantt",
        "issue-tracker",
        "jira",
        "jira-alternative",
        "kanban",
        "linear",
        "postgresql",
        "product-management",
        "project-management",
        "project-planning",
        "python",
        "react",
        "redis",
        "typescipt",
        "vite",
        "work-management"
      ],
      "created_at": "2022-11-19T12:55:01Z",
      "updated_at": "2026-01-14T00:14:05Z",
      "pushed_at": "2026-01-13T14:53:51Z",
      "open_issues": 631,
      "owner": {
        "login": "makeplane",
        "avatar_url": "https://avatars.githubusercontent.com/u/115727700?v=4"
      },
      "readme": "<br /><br />\n\n<p align=\"center\">\n<a href=\"https://plane.so\">\n  <img src=\"https://media.docs.plane.so/logo/plane_github_readme.png\" alt=\"Plane Logo\" width=\"400\">\n</a>\n</p>\n<p align=\"center\"><b>Modern project management for all teams</b></p>\n\n<p align=\"center\">\n<a href=\"https://discord.com/invite/A92xrEGCge\">\n<img alt=\"Discord online members\" src=\"https://img.shields.io/discord/1031547764020084846?color=5865F2&label=Discord&style=for-the-badge\" />\n</a>\n<img alt=\"Commit activity per month\" src=\"https://img.shields.io/github/commit-activity/m/makeplane/plane?style=for-the-badge\" />\n</p>\n\n<p align=\"center\">\n    <a href=\"https://plane.so/\"><b>Website</b></a> ‚Ä¢\n    <a href=\"https://github.com/makeplane/plane/releases\"><b>Releases</b></a> ‚Ä¢\n    <a href=\"https://twitter.com/planepowers\"><b>Twitter</b></a> ‚Ä¢\n    <a href=\"https://docs.plane.so/\"><b>Documentation</b></a>\n</p>\n\n<p>\n    <a href=\"https://app.plane.so/#gh-light-mode-only\" target=\"_blank\">\n      <img\n        src=\"https://media.docs.plane.so/GitHub-readme/github-top.webp\"\n        alt=\"Plane Screens\"\n        width=\"100%\"\n      />\n    </a>\n</p>\n\nMeet [Plane](https://plane.so/), an open-source project management tool to track issues, run ~sprints~ cycles, and manage product roadmaps without the chaos of managing the tool itself. üßò‚Äç‚ôÄÔ∏è\n\n> Plane is evolving every day. Your suggestions, ideas, and reported bugs help us immensely. Do not hesitate to join in the conversation on [Discord](https://discord.com/invite/A92xrEGCge) or raise a GitHub issue. We read everything and respond to most.\n\n## üöÄ Installation\n\nGetting started with Plane is simple. Choose the setup that works best for you:\n\n- **Plane Cloud**\n  Sign up for a free account on [Plane Cloud](https://app.plane.so)‚Äîit's the fastest way to get up and running without worrying about infrastructure.\n\n- **Self-host Plane**\n  Prefer full control over your data and infrastructure? Install and run Plane on your own servers. Follow our detailed [deployment guides](https://developers.plane.so/self-hosting/overview) to get started.\n\n| Installation methods | Docs link                                                                                                                                                                               |\n| -------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Docker               | [![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white)](https://developers.plane.so/self-hosting/methods/docker-compose)         |\n| Kubernetes           | [![Kubernetes](https://img.shields.io/badge/kubernetes-%23326ce5.svg?style=for-the-badge&logo=kubernetes&logoColor=white)](https://developers.plane.so/self-hosting/methods/kubernetes) |\n\n`Instance admins` can configure instance settings with [God mode](https://developers.plane.so/self-hosting/govern/instance-admin).\n\n## üåü Features\n\n- **Work Items**\n  Efficiently create and manage tasks with a robust rich text editor that supports file uploads. Enhance organization and tracking by adding sub-properties and referencing related issues.\n\n- **Cycles**\n  Maintain your team‚Äôs momentum with Cycles. Track progress effortlessly using burn-down charts and other insightful tools.\n\n- **Modules**\n  Simplify complex projects by dividing them into smaller, manageable modules.\n\n- **Views**\n  Customize your workflow by creating filters to display only the most relevant issues. Save and share these views with ease.\n\n- **Pages**\n  Capture and organize ideas using Plane Pages, complete with AI capabilities and a rich text editor. Format text, insert images, add hyperlinks, or convert your notes into actionable items.\n\n- **Analytics**\n  Access real-time insights across all your Plane data. Visualize trends, remove blockers, and keep your projects moving forward.\n\n## üõ†Ô∏è Local development\n\nSee [CONTRIBUTING](./CONTRIBUTING.md)\n\n## ‚öôÔ∏è Built with\n\n[![React Router](https://img.shields.io/badge/-React%20Router-CA4245?logo=react-router&style=for-the-badge&logoColor=white)](https://reactrouter.com/)\n[![Django](https://img.shields.io/badge/Django-092E20?style=for-the-badge&logo=django&logoColor=green)](https://www.djangoproject.com/)\n[![Node JS](https://img.shields.io/badge/node.js-339933?style=for-the-badge&logo=Node.js&logoColor=white)](https://nodejs.org/en)\n\n## üì∏ Screenshots\n\n  <p>\n    <a href=\"https://plane.so\" target=\"_blank\">\n      <img\n        src=\"https://media.docs.plane.so/GitHub-readme/github-work-items.webp\"\n        alt=\"Plane Views\"\n        width=\"100%\"\n      />\n    </a>\n  </p>\n  <p>\n    <a href=\"https://plane.so\" target=\"_blank\">\n      <img\n        src=\"https://media.docs.plane.so/GitHub-readme/github-cycles.webp\"\n        width=\"100%\"\n      />\n    </a>\n  </p>\n  <p>\n    <a href=\"https://plane.so\" target=\"_blank\">\n      <img\n        src=\"https://media.docs.plane.so/GitHub-readme/github-modules.webp\"\n        alt=\"Plane Cycles and Modules\"\n        width=\"100%\"\n      />\n    </a>\n  </p>\n  <p>\n    <a href=\"https://plane.so\" target=\"_blank\">\n      <img\n        src=\"https://media.docs.plane.so/GitHub-readme/github-views.webp\"\n        alt=\"Plane Analytics\"\n        width=\"100%\"\n      />\n    </a>\n  </p>\n   <p>\n    <a href=\"https://plane.so\" target=\"_blank\">\n      <img\n        src=\"https://media.docs.plane.so/GitHub-readme/github-analytics.webp\"\n        alt=\"Plane Pages\"\n        width=\"100%\"\n      />\n    </a>\n  </p>\n</p>\n\n## üìù Documentation\n\nExplore Plane's [product documentation](https://docs.plane.so/) and [developer documentation](https://developers.plane.so/) to learn about features, setup, and usage.\n\n## ‚ù§Ô∏è Community\n\nJoin the Plane community on [GitHub Discussions](https://github.com/orgs/makeplane/discussions) and our [Discord server](https://discord.com/invite/A92xrEGCge). We follow a [Code of conduct](https://github.com/makeplane/plane/blob/master/CODE_OF_CONDUCT.md) in all our community channels.\n\nFeel free to ask questions, report bugs, participate in discussions, share ideas, request features, or showcase your projects. We‚Äôd love to hear from you!\n\n## üõ°Ô∏è Security\n\nIf you discover a security vulnerability in Plane, please report it responsibly instead of opening a public issue. We take all legitimate reports seriously and will investigate them promptly. See [Security policy](https://github.com/makeplane/plane/blob/master/SECURITY.md) for more info.\n\nTo disclose any security issues, please email us at security@plane.so.\n\n## ü§ù Contributing\n\nThere are many ways you can contribute to Plane:\n\n- Report [bugs](https://github.com/makeplane/plane/issues/new?assignees=srinivaspendem%2Cpushya22&labels=%F0%9F%90%9Bbug&projects=&template=--bug-report.yaml&title=%5Bbug%5D%3A+) or submit [feature requests](https://github.com/makeplane/plane/issues/new?assignees=srinivaspendem%2Cpushya22&labels=%E2%9C%A8feature&projects=&template=--feature-request.yaml&title=%5Bfeature%5D%3A+).\n- Review the [documentation](https://docs.plane.so/) and submit [pull requests](https://github.com/makeplane/docs) to improve it‚Äîwhether it's fixing typos or adding new content.\n- Talk or write about Plane or any other ecosystem integration and [let us know](https://discord.com/invite/A92xrEGCge)!\n- Show your support by upvoting [popular feature requests](https://github.com/makeplane/plane/issues).\n\nPlease read [CONTRIBUTING.md](https://github.com/makeplane/plane/blob/master/CONTRIBUTING.md) for details on the process for submitting pull requests to us.\n\n### Repo activity\n\n![Plane Repo Activity](https://repobeats.axiom.co/api/embed/2523c6ed2f77c082b7908c33e2ab208981d76c39.svg \"Repobeats analytics image\")\n\n### We couldn't have done this without you.\n\n<a href=\"https://github.com/makeplane/plane/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=makeplane/plane\" />\n</a>\n\n## License\n\nThis project is licensed under the [GNU Affero General Public License v3.0](https://github.com/makeplane/plane/blob/master/LICENSE.txt).\n",
      "stars_today": 166
    },
    {
      "id": 6201092,
      "name": "mpv",
      "full_name": "mpv-player/mpv",
      "description": "üé• Command line media player",
      "html_url": "https://github.com/mpv-player/mpv",
      "stars": 33566,
      "forks": 3195,
      "language": "C",
      "topics": [
        "audio",
        "c",
        "ffmpeg",
        "mplayer",
        "mpv",
        "multimedia",
        "video"
      ],
      "created_at": "2012-10-13T08:08:44Z",
      "updated_at": "2026-01-14T00:56:26Z",
      "pushed_at": "2026-01-14T00:56:18Z",
      "open_issues": 1068,
      "owner": {
        "login": "mpv-player",
        "avatar_url": "https://avatars.githubusercontent.com/u/2550273?v=4"
      },
      "readme": "![mpv logo](https://raw.githubusercontent.com/mpv-player/mpv.io/master/source/images/mpv-logo-128.png)\n\n# mpv\n\n\n* [External links](#external-links)\n* [Overview](#overview)\n* [System requirements](#system-requirements)\n* [Downloads](#downloads)\n* [Changelog](#changelog)\n* [Compilation](#compilation)\n* [Release cycle](#release-cycle)\n* [Bug reports](#bug-reports)\n* [Contributing](#contributing)\n* [License](#license)\n* [Contact](#contact)\n\n\n## External links\n\n\n* [Wiki](https://github.com/mpv-player/mpv/wiki)\n* [User Scripts](https://github.com/mpv-player/mpv/wiki/User-Scripts)\n* [FAQ][FAQ]\n* [Manual](https://mpv.io/manual/master/)\n\n\n## Overview\n\n\n**mpv** is a free (as in freedom) media player for the command line. It supports\na wide variety of media file formats, audio and video codecs, and subtitle types.\n\nThere is a [FAQ][FAQ].\n\nReleases can be found on the [release list][releases].\n\n## System requirements\n\n- A not too ancient Linux (usually, only the latest releases of distributions\n  are actively supported), Windows 10 1607 or later, or macOS 10.15 or later.\n- A somewhat capable CPU. Hardware decoding might help if the CPU is too slow to\n  decode video in realtime, but must be explicitly enabled with the `--hwdec`\n  option.\n- A not too crappy GPU. mpv's focus is not on power-efficient playback on\n  embedded or integrated GPUs (for example, hardware decoding is not even\n  enabled by default). Low power GPUs may cause issues like tearing, stutter,\n  etc. On such GPUs, it's recommended to use `--profile=fast` for smooth playback.\n  The main video output uses shaders for video rendering and scaling,\n  rather than GPU fixed function hardware. On Windows, you might want to make\n  sure the graphics drivers are current. In some cases, ancient fallback video\n  output methods can help (such as `--vo=xv` on Linux), but this use is not\n  recommended or supported.\n\nmpv does not go out of its way to break on older hardware or old, unsupported\noperating systems, but development is not done with them in mind. Keeping\ncompatibility with such setups is not guaranteed. If things work, consider it\na happy accident.\n\n## Downloads\n\n\nFor semi-official builds and third-party packages please see\n[mpv.io/installation](https://mpv.io/installation/).\n\n## Changelog\n\n\nThere is no complete changelog; however, changes to the player core interface\nare listed in the [interface changelog][interface-changes].\n\nChanges to the C API are documented in the [client API changelog][api-changes].\n\nThe [release list][releases] has a summary of most of the important changes\non every release.\n\nChanges to the default key bindings are indicated in\n[restore-old-bindings.conf][restore-old-bindings].\n\nChanges to the default OSC bindings are indicated in\n[restore-osc-bindings.conf][restore-osc-bindings].\n\n## Compilation\n\n\nCompiling with full features requires development files for several\nexternal libraries. Mpv requires [meson](https://mesonbuild.com/index.html)\nto build. Meson can be obtained from your distro or PyPI.\n\nAfter creating your build directory (e.g. `meson setup build`), you can view a list\nof all the build options via `meson configure build`. You could also just simply\nlook at the `meson_options.txt` file. Logs are stored in `meson-logs` within\nyour build directory.\n\nExample:\n\n    meson setup build\n    meson compile -C build\n    meson install -C build\n\nFor libplacebo, meson can use a git check out as a subproject for a convenient\nway to compile mpv if a sufficient libplacebo version is not easily available\nin the build environment. It will be statically linked with mpv. Example:\n\n    mkdir -p subprojects\n    git clone https://code.videolan.org/videolan/libplacebo.git --depth=1 --recursive subprojects/libplacebo\n\nEssential dependencies (incomplete list):\n\n- gcc or clang\n- X development headers (xlib, xrandr, xext, xscrnsaver, xpresent, libvdpau,\n  libGL, GLX, EGL, xv, ...)\n- Audio output development headers (libasound/ALSA, pulseaudio)\n- FFmpeg libraries (libavutil libavcodec libavformat libswscale libavfilter\n  and either libswresample or libavresample)\n- libplacebo\n- zlib\n- iconv (normally provided by the system libc)\n- libass (OSD, OSC, text subtitles)\n- Lua (optional, required for the OSC pseudo-GUI and youtube-dl integration)\n- libjpeg (optional, used for screenshots only)\n- uchardet (optional, for subtitle charset detection)\n- nvdec and vaapi libraries for hardware decoding on Linux (optional)\n\nLibass dependencies (when building libass):\n\n- gcc or clang, nasm on x86 and x86_64\n- fribidi, freetype, fontconfig development headers (for libass)\n- harfbuzz (required for correct rendering of combining characters, particularly\n  for correct rendering of non-English text on macOS, and Arabic/Indic scripts on\n  any platform)\n\nFFmpeg dependencies (when building FFmpeg):\n\n- gcc or clang, nasm on x86 and x86_64\n- OpenSSL or GnuTLS (have to be explicitly enabled when compiling FFmpeg)\n- libx264/libmp3lame/libfdk-aac if you want to use encoding (have to be\n  explicitly enabled when compiling FFmpeg)\n- For native DASH playback, FFmpeg needs to be built with --enable-libxml2\n  (although there are security implications, and DASH support has lots of bugs).\n- AV1 decoding support requires dav1d.\n- For good nvidia support on Linux, make sure nv-codec-headers is installed\n  and can be found by configure.\n\nMost of the above libraries are available in suitable versions on normal\nLinux distributions. For ease of compiling the latest git master of everything,\nyou may wish to use the separately available build wrapper ([mpv-build][mpv-build])\nwhich first compiles FFmpeg libraries and libass, and then compiles the player\nstatically linked against those.\n\nIf you want to build a Windows binary, see [Windows compilation][windows_compilation].\n\n\n## Release cycle\n\nOnce or twice a year, a release is cut off from the current development state\nand is assigned a 0.X.0 version number. No further maintenance is done, except\nin the event of security issues.\n\nThe goal of releases is to make Linux distributions happy. Linux distributions\nare also expected to apply their own patches in case of bugs.\n\nReleases other than the latest release are unsupported and unmaintained.\n\nSee the [release policy document][release-policy] for more information.\n\n## Bug reports\n\n\nPlease use the [issue tracker][issue-tracker] provided by GitHub to send us bug\nreports or feature requests. Follow the template's instructions or the issue\nwill likely be ignored or closed as invalid.\n\nQuestions can be asked in the [discussions][discussions] or on IRC (see\n[Contact](#Contact) below).\n\n## Contributing\n\n\nPlease read [contribute.md][contribute.md].\n\nFor small changes you can just send us pull requests through GitHub. For bigger\nchanges come and talk to us on IRC before you start working on them. It will\nmake code review easier for both parties later on.\n\nYou can check [the wiki](https://github.com/mpv-player/mpv/wiki/Stuff-to-do)\nor the [issue tracker](https://github.com/mpv-player/mpv/issues?q=is%3Aopen+is%3Aissue+label%3Ameta%3Afeature-request)\nfor ideas on what you could contribute with.\n\n## License\n\nGPLv2 \"or later\" by default, LGPLv2.1 \"or later\" with `-Dgpl=false`.\nSee [details.](https://github.com/mpv-player/mpv/blob/master/Copyright)\n\n## History\n\nThis software is based on the MPlayer project. Before mpv existed as a project,\nthe code base was briefly developed under the mplayer2 project. For details,\nsee the [FAQ][FAQ].\n\n## Contact\n\n\nMost activity happens on the IRC channel and the GitHub issue tracker.\n\n- **GitHub issue tracker**: [issue tracker][issue-tracker] (report bugs here)\n- **Discussions**: [discussions][discussions]\n- **User IRC Channel**: `#mpv` on `irc.libera.chat`\n- **Developer IRC Channel**: `#mpv-devel` on `irc.libera.chat`\n\n[FAQ]: https://github.com/mpv-player/mpv/wiki/FAQ\n[releases]: https://github.com/mpv-player/mpv/releases\n[mpv-build]: https://github.com/mpv-player/mpv-build\n[issue-tracker]:  https://github.com/mpv-player/mpv/issues\n[discussions]: https://github.com/mpv-player/mpv/discussions\n[release-policy]: https://github.com/mpv-player/mpv/blob/master/DOCS/release-policy.md\n[windows_compilation]: https://github.com/mpv-player/mpv/blob/master/DOCS/compile-windows.md\n[interface-changes]: https://github.com/mpv-player/mpv/blob/master/DOCS/interface-changes.rst\n[api-changes]: https://github.com/mpv-player/mpv/blob/master/DOCS/client-api-changes.rst\n[restore-old-bindings]: https://github.com/mpv-player/mpv/blob/master/etc/restore-old-bindings.conf\n[restore-osc-bindings]: https://github.com/mpv-player/mpv/blob/master/etc/restore-osc-bindings.conf\n[contribute.md]: https://github.com/mpv-player/mpv/blob/master/DOCS/contribute.md\n",
      "stars_today": 142
    },
    {
      "id": 1024118326,
      "name": "WeKnora",
      "full_name": "Tencent/WeKnora",
      "description": "LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.",
      "html_url": "https://github.com/Tencent/WeKnora",
      "stars": 11493,
      "forks": 1262,
      "language": "Go",
      "topics": [
        "agent",
        "agentic",
        "ai",
        "chatbot",
        "chatbots",
        "embeddings",
        "evaluation",
        "generative-ai",
        "golang",
        "knowledge-base",
        "llm",
        "multi-tenant",
        "multimodel",
        "ollama",
        "openai",
        "question-answering",
        "rag",
        "reranking",
        "semantic-search",
        "vector-search"
      ],
      "created_at": "2025-07-22T08:01:23Z",
      "updated_at": "2026-01-14T00:57:03Z",
      "pushed_at": "2026-01-13T12:55:16Z",
      "open_issues": 80,
      "owner": {
        "login": "Tencent",
        "avatar_url": "https://avatars.githubusercontent.com/u/18461506?v=4"
      },
      "readme": "<p align=\"center\">\n  <picture>\n    <img src=\"./docs/images/logo.png\" alt=\"WeKnora Logo\" height=\"120\"/>\n  </picture>\n</p>\n\n<p align=\"center\">\n  <picture>\n    <a href=\"https://trendshift.io/repositories/15289\" target=\"_blank\">\n      <img src=\"https://trendshift.io/api/badge/repositories/15289\" alt=\"Tencent%2FWeKnora | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/>\n    </a>\n  </picture>\n</p>\n<p align=\"center\">\n    <a href=\"https://weknora.weixin.qq.com\" target=\"_blank\">\n        <img alt=\"ÂÆòÊñπÁΩëÁ´ô\" src=\"https://img.shields.io/badge/ÂÆòÊñπÁΩëÁ´ô-WeKnora-4e6b99\">\n    </a>\n    <a href=\"https://chatbot.weixin.qq.com\" target=\"_blank\">\n        <img alt=\"ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞\" src=\"https://img.shields.io/badge/ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞-5ac725\">\n    </a>\n    <a href=\"https://github.com/Tencent/WeKnora/blob/main/LICENSE\">\n        <img src=\"https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&color=2e6cc4\" alt=\"License\">\n    </a>\n    <a href=\"./CHANGELOG.md\">\n        <img alt=\"Version\" src=\"https://img.shields.io/badge/version-0.2.6-2e6cc4?labelColor=d4eaf7\">\n    </a>\n</p>\n\n<p align=\"center\">\n| <b>English</b> | <a href=\"./README_CN.md\"><b>ÁÆÄ‰Ωì‰∏≠Êñá</b></a> | <a href=\"./README_JA.md\"><b>Êó•Êú¨Ë™û</b></a> |\n</p>\n\n<p align=\"center\">\n  <h4 align=\"center\">\n\n  [Overview](#-overview) ‚Ä¢ [Architecture](#-architecture) ‚Ä¢ [Key Features](#-key-features) ‚Ä¢ [Getting Started](#-getting-started) ‚Ä¢ [API Reference](#-api-reference) ‚Ä¢ [Developer Guide](#-developer-guide)\n  \n  </h4>\n</p>\n\n# üí° WeKnora - LLM-Powered Document Understanding & Retrieval Framework\n\n## üìå Overview\n\n[**WeKnora**](https://weknora.weixin.qq.com) is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents. \n\nIt adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the **RAG (Retrieval-Augmented Generation)** paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.\n\n**Website:** https://weknora.weixin.qq.com\n\n## ‚ú® Latest Updates\n\n**v0.2.0 Highlights:**\n\n- ü§ñ **Agent Mode**: New ReACT Agent mode that can call built-in tools, MCP tools, and web search, providing comprehensive summary reports through multiple iterations and reflection\n- üìö **Multi-Type Knowledge Bases**: Support for FAQ and document knowledge base types, with new features including folder import, URL import, tag management, and online entry\n- ‚öôÔ∏è **Conversation Strategy**: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior\n- üåê **Web Search**: Support for extensible web search engines with built-in DuckDuckGo search engine\n- üîå **MCP Tool Integration**: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods\n- üé® **New UI**: Optimized conversation interface with Agent mode/normal mode switching, tool call process display, and comprehensive knowledge base management interface upgrade\n- ‚ö° **Infrastructure Upgrade**: Introduced MQ async task management, support for automatic database migration, and fast development mode\n\n## üîí Security Notice\n\n**Important:** Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:\n\n- Deploy WeKnora services in internal/private network environments rather than public internet\n- Avoid exposing the service directly to public networks to prevent potential information leakage\n- Configure proper firewall rules and access controls for your deployment environment\n- Regularly update to the latest version for security patches and improvements\n\n## üèóÔ∏è Architecture\n\n![weknora-architecture.png](./docs/images/architecture.png)\n\nWeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.\n\n## üéØ Key Features\n\n- **ü§ñ Agent Mode**: Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, MCP tools, and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection\n- **üîç Precise Understanding**: Structured content extraction from PDFs, Word documents, images and more into unified semantic views\n- **üß† Intelligent Reasoning**: Leverages LLMs to understand document context and user intent for accurate Q&A and multi-turn conversations\n- **üìö Multi-Type Knowledge Bases**: Support for FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry capabilities\n- **üîß Flexible Extension**: All components from parsing and embedding to retrieval and generation are decoupled for easy customization\n- **‚ö° Efficient Retrieval**: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs, with cross-knowledge base retrieval support\n- **üåê Web Search**: Support for extensible web search engines with built-in DuckDuckGo search engine\n- **üîå MCP Tool Integration**: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods\n- **‚öôÔ∏è Conversation Strategy**: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior\n- **üéØ User-Friendly**: Intuitive web interface and standardized APIs for zero technical barriers\n- **üîí Secure & Controlled**: Support for local deployment and private cloud, ensuring complete data sovereignty\n\n## üìä Application Scenarios\n\n| Scenario | Applications | Core Value |\n|---------|----------|----------|\n| **Enterprise Knowledge Management** | Internal document retrieval, policy Q&A, operation manual search | Improve knowledge discovery efficiency, reduce training costs |\n| **Academic Research Analysis** | Paper retrieval, research report analysis, scholarly material organization | Accelerate literature review, assist research decisions |\n| **Product Technical Support** | Product manual Q&A, technical documentation search, troubleshooting | Enhance customer service quality, reduce support burden |\n| **Legal & Compliance Review** | Contract clause retrieval, regulatory policy search, case analysis | Improve compliance efficiency, reduce legal risks |\n| **Medical Knowledge Assistance** | Medical literature retrieval, treatment guideline search, case analysis | Support clinical decisions, improve diagnosis quality |\n\n## üß© Feature Matrix\n\n| Module | Support                                                                        | Description                                                                                                                                                        |\n|---------|--------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Agent Mode | ‚úÖ ReACT Agent Mode                                                             | Support for using built-in tools to retrieve knowledge bases, MCP tools, and web search, with cross-knowledge base retrieval and multiple iterations               |\n| Knowledge Base Types | ‚úÖ FAQ / Document                                                               | Support for creating FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry                                       |\n| Document Formats | ‚úÖ PDF / Word / Txt / Markdown / Images (with OCR / Caption)                    | Support for structured and unstructured documents with text extraction from images                                                                                 |\n| Model Management | ‚úÖ Centralized configuration, built-in model sharing                            | Centralized model configuration with model selection in knowledge base settings, support for multi-tenant shared built-in models                                   |\n| Embedding Models | ‚úÖ Local models, BGE / GTE APIs, etc.                                           | Customizable embedding models, compatible with local deployment and cloud vector generation APIs                                                                   |\n| Vector DB Integration | ‚úÖ PostgreSQL (pgvector), Elasticsearch                                         | Support for mainstream vector index backends, flexible switching for different retrieval scenarios                                                                 |\n| Retrieval Strategies | ‚úÖ BM25 / Dense Retrieval / GraphRAG                                            | Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines                                        |\n| LLM Integration | ‚úÖ Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching  | Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration                                                     |\n| Conversation Strategy | ‚úÖ Agent models, normal mode models, retrieval thresholds, Prompt configuration | Support for configuring Agent models, normal mode models, retrieval thresholds, online Prompt configuration, precise control over multi-turn conversation behavior |\n| Web Search | ‚úÖ Extensible search engines, DuckDuckGo / Google                               | Support for extensible web search engines with built-in DuckDuckGo search engine                                                                                   |\n| MCP Tools | ‚úÖ uvx, npx launchers, Stdio/HTTP Streamable/SSE                                | Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting three transport methods                                      |\n| QA Capabilities | ‚úÖ Context-aware, multi-turn dialogue, prompt templates                         | Support for complex semantic modeling, instruction control and chain-of-thought Q&A with configurable prompts and context windows                                  |\n| E2E Testing | ‚úÖ Retrieval+generation process visualization and metric evaluation             | End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics                                                            |\n| Deployment Modes | ‚úÖ Support for local deployment / Docker images                                 | Meets private, offline deployment and flexible operation requirements, with fast development mode support                                                          |\n| User Interfaces | ‚úÖ Web UI + RESTful API                                                         | Interactive interface and standard API endpoints, with Agent mode/normal mode switching and tool call process display                                              |\n| Task Management | ‚úÖ MQ async tasks, automatic database migration                                 | MQ-based async task state maintenance, support for automatic database schema and data migration during version upgrades                                            |\n\n## üöÄ Getting Started\n\n### üõ† Prerequisites\n\nMake sure the following tools are installed on your system:\n\n* [Docker](https://www.docker.com/)\n* [Docker Compose](https://docs.docker.com/compose/)\n* [Git](https://git-scm.com/)\n\n### üì¶ Installation\n\n#### ‚ë† Clone the repository\n\n```bash\n# Clone the main repository\ngit clone https://github.com/Tencent/WeKnora.git\ncd WeKnora\n```\n\n#### ‚ë° Configure environment variables\n\n```bash\n# Copy example env file\ncp .env.example .env\n\n# Edit .env and set required values\n# All variables are documented in the .env.example comments\n```\n\n#### ‚ë¢ Start the services (include Ollama)\n\nCheck the images that need to be started in the .env file.\n\n```bash\n./scripts/start_all.sh\n```\n\nor\n\n```bash\nmake start-all\n```\n\n#### ‚ë¢.0 Start ollama services (Optional)\n\n```bash\nollama serve > /dev/null 2>&1 &\n```\n\n#### ‚ë¢.1 Activate different combinations of features\n\n- Minimum core services\n```bash\ndocker compose up -d\n```\n\n- All features enabled\n```bash\ndocker-compose --profile full up -d\n```\n\n- Tracing logs required\n```bash\ndocker-compose --profile jaeger up -d\n```\n\n- Neo4j knowledge graph required\n```bash\ndocker-compose --profile neo4j up -d\n```\n\n- Minio file storage service required\n```bash\ndocker-compose --profile minio up -d\n```\n\n- Multiple options combination\n```bash\ndocker-compose --profile neo4j --profile minio up -d\n```\n\n#### ‚ë£ Stop the services\n\n```bash\n./scripts/start_all.sh --stop\n# Or\nmake stop-all\n```\n\n### üåê Access Services\n\nOnce started, services will be available at:\n\n* Web UI: `http://localhost`\n* Backend API: `http://localhost:8080`\n* Jaeger Tracing: `http://localhost:16686`\n\n### üîå Using WeChat Dialog Open Platform\n\nWeKnora serves as the core technology framework for the [WeChat Dialog Open Platform](https://chatbot.weixin.qq.com), providing a more convenient usage approach:\n\n- **Zero-code Deployment**: Simply upload knowledge to quickly deploy intelligent Q&A services within the WeChat ecosystem, achieving an \"ask and answer\" experience\n- **Efficient Question Management**: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers\n- **WeChat Ecosystem Integration**: Through the WeChat Dialog Open Platform, WeKnora's intelligent Q&A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences\n\n### üîó Access WeKnora via MCP Server\n\n#### 1Ô∏è‚É£ Clone the repository\n```\ngit clone https://github.com/Tencent/WeKnora\n```\n\n#### 2Ô∏è‚É£ Configure MCP Server\n> It is recommended to directly refer to the [MCP Configuration Guide](./mcp-server/MCP_CONFIG.md) for configuration.\n\nConfigure the MCP client to connect to the server:\n```json\n{\n  \"mcpServers\": {\n    \"weknora\": {\n      \"args\": [\n        \"path/to/WeKnora/mcp-server/run_server.py\"\n      ],\n      \"command\": \"python\",\n      \"env\":{\n        \"WEKNORA_API_KEY\":\"Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk\",\n        \"WEKNORA_BASE_URL\":\"http(s)://your-weknora-address/api/v1\"\n      }\n    }\n  }\n}\n```\n\nRun directly using stdio command:\n```\npip install weknora-mcp-server\npython -m weknora-mcp-server\n```\n\n## üîß Initialization Configuration Guide\n\nTo help users quickly configure various models and reduce trial-and-error costs, we've improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows:\nIf this is your first time using this project, you can skip steps ‚ë†‚ë° and go directly to steps ‚ë¢‚ë£.\n\n### ‚ë† Stop the services\n\n```bash\n./scripts/start_all.sh --stop\n```\n\n### ‚ë° Clear existing data tables (recommended when no important data exists)\n\n```bash\nmake clean-db\n```\n\n### ‚ë¢ Compile and start services\n\n```bash\n./scripts/start_all.sh\n```\n\n### ‚ë£ Access Web UI\n\nhttp://localhost\n\nOn your first visit, you will be automatically redirected to the registration/login page. After completing registration, please create a new knowledge base and finish the relevant settings on its configuration page.\n\n## üì± Interface Showcase\n\n### Web UI Interface\n\n<table>\n  <tr>\n    <td><b>Knowledge Base Management</b><br/><img src=\"./docs/images/knowledgebases.png\" alt=\"Knowledge Base Management\"></td>\n    <td><b>Conversation Settings</b><br/><img src=\"./docs/images/settings.png\" alt=\"Conversation Settings\"></td>\n  </tr>\n  <tr>\n    <td colspan=\"2\"><b>Agent Mode Tool Call Process</b><br/><img src=\"./docs/images/agent-qa.png\" alt=\"Agent Mode Tool Call Process\"></td>\n  </tr>\n</table>\n\n**Knowledge Base Management:** Support for creating FAQ and document knowledge base types, with multiple import methods including drag-and-drop, folder import, and URL import. Automatically identifies document structures and extracts core knowledge to establish indexes. Supports tag management and online entry. The system clearly displays processing progress and document status, achieving efficient knowledge base management.\n\n**Agent Mode:** Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, call user-configured MCP tools and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection. Supports cross-knowledge base retrieval, allowing selection of multiple knowledge bases for simultaneous retrieval.\n\n**Conversation Strategy:** Support for configuring Agent models, normal mode models, retrieval thresholds, and online Prompt configuration, with precise control over multi-turn conversation behavior and retrieval execution methods. The conversation input box supports Agent mode/normal mode switching, enabling/disabling web search, and selecting conversation models.\n\n### Document Knowledge Graph\n\nWeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.\n\nFor detailed configuration, please refer to the [Knowledge Graph Configuration Guide](./docs/KnowledgeGraph.md).\n\n### MCP Server\n\nPlease refer to the [MCP Configuration Guide](./mcp-server/MCP_CONFIG.md) for the necessary setup.\n\n## üìò API Reference\n\nTroubleshooting FAQ: [Troubleshooting FAQ](./docs/QA.md)\n\nDetailed API documentation is available at: [API Docs](./docs/api/README.md)\n\n## üß≠ Developer Guide\n\n### ‚ö° Fast Development Mode (Recommended)\n\nIf you need to frequently modify code, **you don't need to rebuild Docker images every time**! Use fast development mode:\n\n```bash\n# Method 1: Using Make commands (Recommended)\nmake dev-start      # Start infrastructure\nmake dev-app        # Start backend (new terminal)\nmake dev-frontend   # Start frontend (new terminal)\n\n# Method 2: One-click start\n./scripts/quick-dev.sh\n\n# Method 3: Using scripts\n./scripts/dev.sh start     # Start infrastructure\n./scripts/dev.sh app       # Start backend (new terminal)\n./scripts/dev.sh frontend  # Start frontend (new terminal)\n```\n\n**Development Advantages:**\n- ‚úÖ Frontend modifications auto hot-reload (no restart needed)\n- ‚úÖ Backend modifications quick restart (5-10 seconds, supports Air hot-reload)\n- ‚úÖ No need to rebuild Docker images\n- ‚úÖ Support IDE breakpoint debugging\n\n**Detailed Documentation:** [Development Environment Quick Start](./docs/ÂºÄÂèëÊåáÂçó.md)\n\n### üìÅ Directory Structure\n\n```\nWeKnora/\n‚îú‚îÄ‚îÄ client/      # go client\n‚îú‚îÄ‚îÄ cmd/         # Main entry point\n‚îú‚îÄ‚îÄ config/      # Configuration files\n‚îú‚îÄ‚îÄ docker/      # docker images files\n‚îú‚îÄ‚îÄ docreader/   # Document parsing app\n‚îú‚îÄ‚îÄ docs/        # Project documentation\n‚îú‚îÄ‚îÄ frontend/    # Frontend app\n‚îú‚îÄ‚îÄ internal/    # Core business logic\n‚îú‚îÄ‚îÄ mcp-server/  # MCP server\n‚îú‚îÄ‚îÄ migrations/  # DB migration scripts\n‚îî‚îÄ‚îÄ scripts/     # Shell scripts\n```\n\n## ü§ù Contributing\n\nWe welcome community contributions! For suggestions, bugs, or feature requests, please submit an [Issue](https://github.com/Tencent/WeKnora/issues) or directly create a Pull Request.\n\n### üéØ How to Contribute\n\n- üêõ **Bug Fixes**: Discover and fix system defects\n- ‚ú® **New Features**: Propose and implement new capabilities\n- üìö **Documentation**: Improve project documentation\n- üß™ **Test Cases**: Write unit and integration tests\n- üé® **UI/UX Enhancements**: Improve user interface and experience\n\n### üìã Contribution Process\n\n1. **Fork the project** to your GitHub account\n2. **Create a feature branch** `git checkout -b feature/amazing-feature`\n3. **Commit changes** `git commit -m 'Add amazing feature'`\n4. **Push branch** `git push origin feature/amazing-feature`\n5. **Create a Pull Request** with detailed description of changes\n\n### üé® Code Standards\n\n- Follow [Go Code Review Comments](https://github.com/golang/go/wiki/CodeReviewComments)\n- Format code using `gofmt`\n- Add necessary unit tests\n- Update relevant documentation\n\n### üìù Commit Guidelines\n\nUse [Conventional Commits](https://www.conventionalcommits.org/) standard:\n\n```\nfeat: Add document batch upload functionality\nfix: Resolve vector retrieval precision issue\ndocs: Update API documentation\ntest: Add retrieval engine test cases\nrefactor: Restructure document parsing module\n```\n\n## üë• Contributors\n\nThanks to these excellent contributors:\n\n[![Contributors](https://contrib.rocks/image?repo=Tencent/WeKnora)](https://github.com/Tencent/WeKnora/graphs/contributors)\n\n## üìÑ License\n\nThis project is licensed under the [MIT License](./LICENSE).\nYou are free to use, modify, and distribute the code with proper attribution.\n\n## üìà Project Statistics\n\n<a href=\"https://www.star-history.com/#Tencent/WeKnora&type=date&legend=top-left\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=Tencent/WeKnora&type=date&theme=dark&legend=top-left\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=Tencent/WeKnora&type=date&legend=top-left\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=Tencent/WeKnora&type=date&legend=top-left\" />\n </picture>\n</a>\n",
      "stars_today": 109
    },
    {
      "id": 965415649,
      "name": "codex",
      "full_name": "openai/codex",
      "description": "Lightweight coding agent that runs in your terminal",
      "html_url": "https://github.com/openai/codex",
      "stars": 56072,
      "forks": 7214,
      "language": "Rust",
      "topics": [],
      "created_at": "2025-04-13T05:37:54Z",
      "updated_at": "2026-01-14T01:01:40Z",
      "pushed_at": "2026-01-14T01:06:53Z",
      "open_issues": 884,
      "owner": {
        "login": "openai",
        "avatar_url": "https://avatars.githubusercontent.com/u/14957082?v=4"
      },
      "readme": "<p align=\"center\"><code>npm i -g @openai/codex</code><br />or <code>brew install --cask codex</code></p>\n<p align=\"center\"><strong>Codex CLI</strong> is a coding agent from OpenAI that runs locally on your computer.\n<p align=\"center\">\n  <img src=\"./.github/codex-cli-splash.png\" alt=\"Codex CLI splash\" width=\"80%\" />\n</p>\n</br>\nIf you want Codex in your code editor (VS Code, Cursor, Windsurf), <a href=\"https://developers.openai.com/codex/ide\">install in your IDE.</a>\n</br>If you are looking for the <em>cloud-based agent</em> from OpenAI, <strong>Codex Web</strong>, go to <a href=\"https://chatgpt.com/codex\">chatgpt.com/codex</a>.</p>\n\n---\n\n## Quickstart\n\n### Installing and running Codex CLI\n\nInstall globally with your preferred package manager:\n\n```shell\n# Install using npm\nnpm install -g @openai/codex\n```\n\n```shell\n# Install using Homebrew\nbrew install --cask codex\n```\n\nThen simply run `codex` to get started.\n\n<details>\n<summary>You can also go to the <a href=\"https://github.com/openai/codex/releases/latest\">latest GitHub Release</a> and download the appropriate binary for your platform.</summary>\n\nEach GitHub Release contains many executables, but in practice, you likely want one of these:\n\n- macOS\n  - Apple Silicon/arm64: `codex-aarch64-apple-darwin.tar.gz`\n  - x86_64 (older Mac hardware): `codex-x86_64-apple-darwin.tar.gz`\n- Linux\n  - x86_64: `codex-x86_64-unknown-linux-musl.tar.gz`\n  - arm64: `codex-aarch64-unknown-linux-musl.tar.gz`\n\nEach archive contains a single entry with the platform baked into the name (e.g., `codex-x86_64-unknown-linux-musl`), so you likely want to rename it to `codex` after extracting it.\n\n</details>\n\n### Using Codex with your ChatGPT plan\n\nRun `codex` and select **Sign in with ChatGPT**. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan. [Learn more about what's included in your ChatGPT plan](https://help.openai.com/en/articles/11369540-codex-in-chatgpt).\n\nYou can also use Codex with an API key, but this requires [additional setup](https://developers.openai.com/codex/auth#sign-in-with-an-api-key).\n\n## Docs\n\n- [**Codex Documentation**](https://developers.openai.com/codex)\n- [**Contributing**](./docs/contributing.md)\n- [**Installing & building**](./docs/install.md)\n- [**Open source fund**](./docs/open-source-fund.md)\n\nThis repository is licensed under the [Apache-2.0 License](LICENSE).\n",
      "stars_today": 107
    },
    {
      "id": 912559512,
      "name": "sim",
      "full_name": "simstudioai/sim",
      "description": "Open-source platform to build and deploy AI agent workflows.",
      "html_url": "https://github.com/simstudioai/sim",
      "stars": 25656,
      "forks": 3191,
      "language": "TypeScript",
      "topics": [
        "agent-workflow",
        "agentic-workflow",
        "agents",
        "ai",
        "aiagents",
        "anthropic",
        "artificial-intelligence",
        "automation",
        "chatbot",
        "deepseek",
        "gemini",
        "low-code",
        "nextjs",
        "no-code",
        "openai",
        "rag",
        "react",
        "typescript"
      ],
      "created_at": "2025-01-05T22:47:49Z",
      "updated_at": "2026-01-14T01:07:03Z",
      "pushed_at": "2026-01-14T01:03:02Z",
      "open_issues": 150,
      "owner": {
        "login": "simstudioai",
        "avatar_url": "https://avatars.githubusercontent.com/u/199344406?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://sim.ai\" target=\"_blank\" rel=\"noopener noreferrer\">\n    <img src=\"apps/sim/public/logo/reverse/text/large.png\" alt=\"Sim Logo\" width=\"500\"/>\n  </a>\n</p>\n\n<p align=\"center\">Build and deploy AI agent workflows in minutes.</p>\n\n<p align=\"center\">\n  <a href=\"https://sim.ai\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://img.shields.io/badge/sim.ai-6F3DFA\" alt=\"Sim.ai\"></a>\n  <a href=\"https://discord.gg/Hr4UWYEcTT\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://img.shields.io/badge/Discord-Join%20Server-5865F2?logo=discord&logoColor=white\" alt=\"Discord\"></a>\n  <a href=\"https://x.com/simdotai\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://img.shields.io/twitter/follow/simstudioai?style=social\" alt=\"Twitter\"></a>\n  <a href=\"https://docs.sim.ai\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://img.shields.io/badge/Docs-6F3DFA.svg\" alt=\"Documentation\"></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://cursor.com/link/prompt?text=Help%20me%20set%20up%20Sim%20Studio%20locally.%20Follow%20these%20steps%3A%0A%0A1.%20First%2C%20verify%20Docker%20is%20installed%20and%20running%3A%0A%20%20%20docker%20--version%0A%20%20%20docker%20info%0A%0A2.%20Clone%20the%20repository%3A%0A%20%20%20git%20clone%20https%3A%2F%2Fgithub.com%2Fsimstudioai%2Fsim.git%0A%20%20%20cd%20sim%0A%0A3.%20Start%20the%20services%20with%20Docker%20Compose%3A%0A%20%20%20docker%20compose%20-f%20docker-compose.prod.yml%20up%20-d%0A%0A4.%20Wait%20for%20all%20containers%20to%20be%20healthy%20(this%20may%20take%201-2%20minutes)%3A%0A%20%20%20docker%20compose%20-f%20docker-compose.prod.yml%20ps%0A%0A5.%20Verify%20the%20app%20is%20accessible%20at%20http%3A%2F%2Flocalhost%3A3000%0A%0AIf%20there%20are%20any%20errors%2C%20help%20me%20troubleshoot%20them.%20Common%20issues%3A%0A-%20Port%203000%2C%203002%2C%20or%205432%20already%20in%20use%0A-%20Docker%20not%20running%0A-%20Insufficient%20memory%20(needs%2012GB%2B%20RAM)%0A%0AFor%20local%20AI%20models%20with%20Ollama%2C%20use%20this%20instead%20of%20step%203%3A%0A%20%20%20docker%20compose%20-f%20docker-compose.ollama.yml%20--profile%20setup%20up%20-d\"><img src=\"https://img.shields.io/badge/Set%20Up%20with-Cursor-000000?logo=cursor&logoColor=white\" alt=\"Set Up with Cursor\"></a>\n</p>\n\n### Build Workflows with Ease\nDesign agent workflows visually on a canvas‚Äîconnect agents, tools, and blocks, then run them instantly.\n\n<p align=\"center\">\n  <img src=\"apps/sim/public/static/workflow.gif\" alt=\"Workflow Builder Demo\" width=\"800\"/>\n</p>\n\n### Supercharge with Copilot\nLeverage Copilot to generate nodes, fix errors, and iterate on flows directly from natural language.\n\n<p align=\"center\">\n  <img src=\"apps/sim/public/static/copilot.gif\" alt=\"Copilot Demo\" width=\"800\"/>\n</p>\n\n### Integrate Vector Databases\nUpload documents to a vector store and let agents answer questions grounded in your specific content.\n\n<p align=\"center\">\n  <img src=\"apps/sim/public/static/knowledge.gif\" alt=\"Knowledge Uploads and Retrieval Demo\" width=\"800\"/>\n</p>\n\n## Quickstart\n\n### Cloud-hosted: [sim.ai](https://sim.ai)\n\n<a href=\"https://sim.ai\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://img.shields.io/badge/sim.ai-6F3DFA?logo=data:image/svg%2bxml;base64,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&logoColor=white\" alt=\"Sim.ai\"></a>\n\n### Self-hosted: NPM Package\n\n```bash\nnpx simstudio\n```\n‚Üí http://localhost:3000\n\n#### Note\nDocker must be installed and running on your machine.\n\n#### Options\n\n| Flag | Description |\n|------|-------------|\n| `-p, --port <port>` | Port to run Sim on (default `3000`) |\n| `--no-pull` | Skip pulling latest Docker images |\n\n### Self-hosted: Docker Compose\n\n```bash\ngit clone https://github.com/simstudioai/sim.git && cd sim\ndocker compose -f docker-compose.prod.yml up -d\n```\n\nOpen [http://localhost:3000](http://localhost:3000)\n\n#### Using Local Models with Ollama\n\nRun Sim with local AI models using [Ollama](https://ollama.ai) - no external APIs required:\n\n```bash\n# Start with GPU support (automatically downloads gemma3:4b model)\ndocker compose -f docker-compose.ollama.yml --profile setup up -d\n\n# For CPU-only systems:\ndocker compose -f docker-compose.ollama.yml --profile cpu --profile setup up -d\n```\n\nWait for the model to download, then visit [http://localhost:3000](http://localhost:3000). Add more models with:\n```bash\ndocker compose -f docker-compose.ollama.yml exec ollama ollama pull llama3.1:8b\n```\n\n#### Using an External Ollama Instance\n\nIf Ollama is running on your host machine, use `host.docker.internal` instead of `localhost`:\n\n```bash\nOLLAMA_URL=http://host.docker.internal:11434 docker compose -f docker-compose.prod.yml up -d\n```\n\nOn Linux, use your host's IP address or add `extra_hosts: [\"host.docker.internal:host-gateway\"]` to the compose file.\n\n#### Using vLLM\n\nSim supports [vLLM](https://docs.vllm.ai/) for self-hosted models. Set `VLLM_BASE_URL` and optionally `VLLM_API_KEY` in your environment.\n\n### Self-hosted: Dev Containers\n\n1. Open VS Code with the [Remote - Containers extension](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers)\n2. Open the project and click \"Reopen in Container\" when prompted\n3. Run `bun run dev:full` in the terminal or use the `sim-start` alias\n   - This starts both the main application and the realtime socket server\n\n### Self-hosted: Manual Setup\n\n**Requirements:** [Bun](https://bun.sh/), [Node.js](https://nodejs.org/) v20+, PostgreSQL 12+ with [pgvector](https://github.com/pgvector/pgvector)\n\n1. Clone and install:\n\n```bash\ngit clone https://github.com/simstudioai/sim.git\ncd sim\nbun install\n```\n\n2. Set up PostgreSQL with pgvector:\n\n```bash\ndocker run --name simstudio-db -e POSTGRES_PASSWORD=your_password -e POSTGRES_DB=simstudio -p 5432:5432 -d pgvector/pgvector:pg17\n```\n\nOr install manually via the [pgvector guide](https://github.com/pgvector/pgvector#installation).\n\n3. Configure environment:\n\n```bash\ncp apps/sim/.env.example apps/sim/.env\ncp packages/db/.env.example packages/db/.env\n# Edit both .env files to set DATABASE_URL=\"postgresql://postgres:your_password@localhost:5432/simstudio\"\n```\n\n4. Run migrations:\n\n```bash\ncd packages/db && bunx drizzle-kit migrate --config=./drizzle.config.ts\n```\n\n5. Start development servers:\n\n```bash\nbun run dev:full  # Starts both Next.js app and realtime socket server\n```\n\nOr run separately: `bun run dev` (Next.js) and `cd apps/sim && bun run dev:sockets` (realtime).\n\n## Copilot API Keys\n\nCopilot is a Sim-managed service. To use Copilot on a self-hosted instance:\n\n- Go to https://sim.ai ‚Üí Settings ‚Üí Copilot and generate a Copilot API key\n- Set `COPILOT_API_KEY` environment variable in your self-hosted apps/sim/.env file to that value\n\n## Environment Variables\n\nKey environment variables for self-hosted deployments. See [`.env.example`](apps/sim/.env.example) for defaults or [`env.ts`](apps/sim/lib/core/config/env.ts) for the full list.\n\n| Variable | Required | Description |\n|----------|----------|-------------|\n| `DATABASE_URL` | Yes | PostgreSQL connection string with pgvector |\n| `BETTER_AUTH_SECRET` | Yes | Auth secret (`openssl rand -hex 32`) |\n| `BETTER_AUTH_URL` | Yes | Your app URL (e.g., `http://localhost:3000`) |\n| `NEXT_PUBLIC_APP_URL` | Yes | Public app URL (same as above) |\n| `ENCRYPTION_KEY` | Yes | Encrypts environment variables (`openssl rand -hex 32`) |\n| `INTERNAL_API_SECRET` | Yes | Encrypts internal API routes (`openssl rand -hex 32`) |\n| `API_ENCRYPTION_KEY` | Yes | Encrypts API keys (`openssl rand -hex 32`) |\n| `COPILOT_API_KEY` | No | API key from sim.ai for Copilot features |\n\n## Troubleshooting\n\n### Ollama models not showing in dropdown (Docker)\n\nIf you're running Ollama on your host machine and Sim in Docker, change `OLLAMA_URL` from `localhost` to `host.docker.internal`:\n\n```bash\nOLLAMA_URL=http://host.docker.internal:11434 docker compose -f docker-compose.prod.yml up -d\n```\n\nSee [Using an External Ollama Instance](#using-an-external-ollama-instance) for details.\n\n### Database connection issues\n\nEnsure PostgreSQL has the pgvector extension installed. When using Docker, wait for the database to be healthy before running migrations.\n\n### Port conflicts\n\nIf ports 3000, 3002, or 5432 are in use, configure alternatives:\n\n```bash\n# Custom ports\nNEXT_PUBLIC_APP_URL=http://localhost:3100 POSTGRES_PORT=5433 docker compose up -d\n```\n\n## Tech Stack\n\n- **Framework**: [Next.js](https://nextjs.org/) (App Router)\n- **Runtime**: [Bun](https://bun.sh/)\n- **Database**: PostgreSQL with [Drizzle ORM](https://orm.drizzle.team)\n- **Authentication**: [Better Auth](https://better-auth.com)\n- **UI**: [Shadcn](https://ui.shadcn.com/), [Tailwind CSS](https://tailwindcss.com)\n- **State Management**: [Zustand](https://zustand-demo.pmnd.rs/)\n- **Flow Editor**: [ReactFlow](https://reactflow.dev/)\n- **Docs**: [Fumadocs](https://fumadocs.vercel.app/)\n- **Monorepo**: [Turborepo](https://turborepo.org/)\n- **Realtime**: [Socket.io](https://socket.io/)\n- **Background Jobs**: [Trigger.dev](https://trigger.dev/)\n- **Remote Code Execution**: [E2B](https://www.e2b.dev/)\n\n## Contributing\n\nWe welcome contributions! Please see our [Contributing Guide](.github/CONTRIBUTING.md) for details.\n\n## License\n\nThis project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.\n\n<p align=\"center\">Made with ‚ù§Ô∏è by the Sim Team</p>\n",
      "stars_today": 106
    },
    {
      "id": 340547520,
      "name": "zed",
      "full_name": "zed-industries/zed",
      "description": "Code at the speed of thought ‚Äì Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.",
      "html_url": "https://github.com/zed-industries/zed",
      "stars": 73228,
      "forks": 6607,
      "language": "Rust",
      "topics": [
        "gpui",
        "rust-lang",
        "text-editor",
        "zed"
      ],
      "created_at": "2021-02-20T03:01:06Z",
      "updated_at": "2026-01-14T00:46:34Z",
      "pushed_at": "2026-01-14T00:35:50Z",
      "open_issues": 3311,
      "owner": {
        "login": "zed-industries",
        "avatar_url": "https://avatars.githubusercontent.com/u/79345384?v=4"
      },
      "readme": "# Zed\n\n[![Zed](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/zed-industries/zed/main/assets/badge/v0.json)](https://zed.dev)\n[![CI](https://github.com/zed-industries/zed/actions/workflows/run_tests.yml/badge.svg)](https://github.com/zed-industries/zed/actions/workflows/run_tests.yml)\n\nWelcome to Zed, a high-performance, multiplayer code editor from the creators of [Atom](https://github.com/atom/atom) and [Tree-sitter](https://github.com/tree-sitter/tree-sitter).\n\n---\n\n### Installation\n\nOn macOS, Linux, and Windows you can [download Zed directly](https://zed.dev/download) or install Zed via your local package manager ([macOS](https://zed.dev/docs/installation#macos)/[Linux](https://zed.dev/docs/linux#installing-via-a-package-manager)/[Windows](https://zed.dev/docs/windows#package-managers)).\n\nOther platforms are not yet available:\n\n- Web ([tracking issue](https://github.com/zed-industries/zed/issues/5396))\n\n### Developing Zed\n\n- [Building Zed for macOS](./docs/src/development/macos.md)\n- [Building Zed for Linux](./docs/src/development/linux.md)\n- [Building Zed for Windows](./docs/src/development/windows.md)\n\n### Contributing\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md) for ways you can contribute to Zed.\n\nAlso... we're hiring! Check out our [jobs](https://zed.dev/jobs) page for open roles.\n\n### Licensing\n\nLicense information for third party dependencies must be correctly provided for CI to pass.\n\nWe use [`cargo-about`](https://github.com/EmbarkStudios/cargo-about) to automatically comply with open source licenses. If CI is failing, check the following:\n\n- Is it showing a `no license specified` error for a crate you've created? If so, add `publish = false` under `[package]` in your crate's Cargo.toml.\n- Is the error `failed to satisfy license requirements` for a dependency? If so, first determine what license the project has and whether this system is sufficient to comply with this license's requirements. If you're unsure, ask a lawyer. Once you've verified that this system is acceptable add the license's SPDX identifier to the `accepted` array in `script/licenses/zed-licenses.toml`.\n- Is `cargo-about` unable to find the license for a dependency? If so, add a clarification field at the end of `script/licenses/zed-licenses.toml`, as specified in the [cargo-about book](https://embarkstudios.github.io/cargo-about/cli/generate/config.html#crate-configuration).\n",
      "stars_today": 103
    },
    {
      "id": 362234372,
      "name": "cariddi",
      "full_name": "edoardottt/cariddi",
      "description": "Take a list of domains, crawl urls and scan for endpoints, secrets, api keys, file extensions, tokens and more",
      "html_url": "https://github.com/edoardottt/cariddi",
      "stars": 3203,
      "forks": 282,
      "language": "Go",
      "topics": [
        "bugbounty",
        "crawler",
        "crawling",
        "endpoint-discovery",
        "endpoints",
        "go",
        "golang",
        "hacktoberfest",
        "infosec",
        "osint",
        "penetration-testing",
        "pentesting",
        "recon",
        "reconnaissance",
        "redteam",
        "scraper",
        "secret-keys",
        "secrets-detection",
        "security",
        "security-tools"
      ],
      "created_at": "2021-04-27T19:54:43Z",
      "updated_at": "2026-01-14T01:06:23Z",
      "pushed_at": "2026-01-11T10:52:32Z",
      "open_issues": 11,
      "owner": {
        "login": "edoardottt",
        "avatar_url": "https://avatars.githubusercontent.com/u/35783570?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"https://github.com/edoardottt/images/blob/main/cariddi/logo.png\"><br>\n  <b>Take a list of domains, crawl urls and scan for endpoints, secrets, api keys, file extensions, tokens and more</b><br>\n  <br>\n  <!-- go-report-card -->\n  <a href=\"https://goreportcard.com/report/github.com/edoardottt/cariddi\">\n    <img src=\"https://goreportcard.com/badge/github.com/edoardottt/cariddi\" alt=\"go-report-card\" />\n  </a>\n  <!-- workflows -->\n  <a href=\"https://github.com/edoardottt/cariddi/actions\">\n    <img src=\"https://github.com/edoardottt/cariddi/actions/workflows/go.yml/badge.svg?branch=main\" alt=\"workflows\" />\n  </a>\n  <br>\n  <sub>\n    Coded with üíô by edoardottt\n  </sub>\n  <br>\n  <!--Tweet button-->\n  <a href=\"https://twitter.com/intent/tweet?url=https://github.com/edoardottt/cariddi&text=Take%20a%20list%20of%20domains,%20crawl%20urls%20and%20scan%20for%20endpoints,%20secrets,%20api%20keys,%20file%20extensions,%20tokens%20and%20more...%20%23network%20%23security%20%23infosec%20%23oss%20%23github%20%23bugbounty%20%23linux\" target=\"_blank\">Share on Twitter!\n  </a>\n</p>\n<p align=\"center\">\n  <a href=\"#installation-\">Install</a> ‚Ä¢\n  <a href=\"#usage-\">Usage</a> ‚Ä¢\n  <a href=\"#get-started-\">Get Started</a> ‚Ä¢\n  <a href=\"#changelog-\">Changelog</a> ‚Ä¢\n  <a href=\"#contributing-\">Contributing</a> ‚Ä¢\n  <a href=\"#license-\">License</a>\n</p>\n\n<!--[![asciicast](https://asciinema.org/a/415989.svg)](https://asciinema.org/a/415989)-->\n\n<p align=\"center\">\n  <img src=\"https://github.com/edoardottt/images/blob/main/cariddi/cariddi.gif\">\n</p>\n\nInstallation üì°\n----------\n\n#### Homebrew\n\n```console\nbrew install cariddi\n```\n\n#### Snap\n\n```console\nsudo snap install cariddi\n```\n\n#### Golang\n\n```console\ngo install -v github.com/edoardottt/cariddi/cmd/cariddi@latest\n```\n\n#### Pacman\n\n```console\npacman -Syu cariddi\n```\n\n#### NixOS\n\n```console\nnix-shell -p cariddi\n```\n\n#### Building from source\n\nYou need [Go](https://go.dev/) (>=1.24.0)\n\n<details>\n  <summary>Building from source for Linux and Windows</summary>\n\n#### Linux\n\n```console\ngit clone https://github.com/edoardottt/cariddi.git\ncd cariddi\ngo get ./...\nmake linux # (to install)\nmake unlinux # (to uninstall)\n```\n\nOne-liner: `git clone https://github.com/edoardottt/cariddi.git && cd cariddi && go get ./... && make linux`\n\n#### Windows \n\nNote that the executable works only in cariddi folder.\n\n```console\ngit clone https://github.com/edoardottt/cariddi.git\ncd cariddi\ngo get ./...\n.\\make.bat windows # (to install)\n.\\make.bat unwindows # (to uninstall)\n```\n\n</details>\n\nUsage üí°\n----------\n\nIf you want to scan only a single target you can use\n\n```console\necho https://edoardottt.com/ | cariddi\n```\n\nWith multiple targets you can use a file instead, e.g. urls.txt containing:\n\n```console\nhttps://edoardottt.com/\nhttp://testphp.vulnweb.com/\n```\n\nFor Windows:\n\n- use `powershell.exe -Command \"cat urls.txt | .\\cariddi.exe\"` inside the Command prompt\n- or just `cat urls.txt | cariddi.exe` using PowerShell\n\n### Basics\n\n- `cariddi -version` (Print the version)\n- `cariddi -h` (Print the help)\n- `cariddi -examples` (Print the examples)\n\n### Scan options\n\n- `cat urls.txt | cariddi -intensive` (Crawl searching also subdomains, same as `*.target.com`)\n- `cat urls.txt | cariddi -s` (Hunt for secrets)\n- `cat urls.txt | cariddi -err` (Hunt for errors in websites)\n- `cat urls.txt | cariddi -e` (Hunt for juicy endpoints)\n- `cat urls.txt | cariddi -info` (Hunt for useful informations in websites)\n- `cat urls.txt | cariddi -ext 2` (Hunt for juicy (level 2 out of 7) files)\n- `cat urls.txt | cariddi -e -ef endpoints_file` (Hunt for custom endpoints)\n- `cat urls.txt | cariddi -s -sf secrets_file` (Hunt for custom secrets)\n- `cat urls.txt | cariddi -ie pdf,png,jpg` (Ignore these extensions while scanning)\n\nDefault: png, svg, jpg, jpeg, bmp, jfif, gif, webp, woff, woff2, ttf, tiff, tif are ignored while scanning for secrets, info and errors.\n\n### Configuration\n\n- `cat urls.txt | cariddi -proxy http://127.0.0.1:8080` (Set a Proxy, http and socks5 supported)\n- `cat urls.txt | cariddi -d 2` (2 seconds between a page crawled and another)\n- `cat urls.txt | cariddi -c 200` (Set the concurrency level to 200)\n- `cat urls.txt | cariddi -i forum,blog,community,open` (Ignore urls containing these words)\n- `cat urls.txt | cariddi -it ignore_file` (Ignore urls containing at least one line in the input file)\n- `cat urls.txt | cariddi -cache` (Use the .cariddi_cache folder as cache)\n- `cat urls.txt | cariddi -t 5` (Set the timeout for the requests)\n- `cat urls.txt | cariddi -headers \"Cookie: auth=admin;type=2;; X-Custom: customHeader\"`\n- `cat urls.txt | cariddi -headersfile headers.txt` (Read from an external file custom headers)\n- `cat urls.txt | cariddi -ua \"Custom User Agent\"` (Use a custom User Agent)\n- `cat urls.txt | cariddi -rua` (Use a random browser user agent on every request)\n\n### Output\n\n- `cat urls.txt | cariddi -plain` (Print only results)\n- `cat urls.txt | cariddi -ot target_name` (Results in txt file)\n- `cat urls.txt | cariddi -oh target_name` (Results in html file)\n- `cat urls.txt | cariddi -json` (Print the output as JSON in stdout)\n- `cat urls.txt | cariddi -sr` (Store HTTP responses)\n- `cat urls.txt | cariddi -debug` (Print debug information while crawling)\n- `cat urls.txt | cariddi -md 3` (Max 3 depth levels)\n\nGet Started üéâ\n----------\n\n`cariddi -h` prints the help.\n\n```console\nUsage of cariddi:\n  -c int\n     Concurrency level. (default 20)\n  -cache\n     Use the .cariddi_cache folder as cache.\n  -d int\n     Delay between a page crawled and another.\n  -debug\n     Print debug information while crawling.\n  -e Hunt for juicy endpoints.\n  -ef string\n     Use an external file (txt, one per line) to use custom parameters for endpoints hunting.\n  -err\n     Hunt for errors in websites.\n  -examples\n     Print the examples.\n  -ext int\n     Hunt for juicy file extensions. Integer from 1(juicy) to 7(not juicy).\n  -h Print the help.\n  -headers string\n     Use custom headers for each request E.g. -headers \"Cookie: auth=yes;;Client: type=2\".\n  -headersfile string\n     Read from an external file custom headers (same format of headers flag).\n  -json\n     Print the output as JSON in stdout.\n  -md\n     Maximum depth level the crawler will follow from the initial target URL.\n  -i string\n     Ignore the URL containing at least one of the elements of this array.\n  -ie value\n     Comma-separated list of extensions to ignore while scanning.\n  -info\n     Hunt for useful informations in websites.\n  -intensive\n     Crawl searching for resources matching 2nd level domain.\n  -it string\n     Ignore the URL containing at least one of the lines of this file.\n  -oh string\n     Write the output into an HTML file.\n  -ot string\n     Write the output into a TXT file.\n  -plain\n     Print only the results.\n  -proxy string\n     Set a Proxy to be used (http and socks5 supported).\n  -rua\n     Use a random browser user agent on every request.\n  -s Hunt for secrets.\n  -sf string\n     Use an external file (txt, one per line) to use custom regexes for secrets hunting.\n  -sr\n     Store HTTP responses.\n  -t int\n     Set timeout for the requests. (default 10)\n  -ua string\n     Use a custom User Agent.\n  -version\n     Print the version.\n```\n\n<details>\n  <summary>Click to understand <strong>How to integrate cariddi with Burpsuite</strong></summary>\n\n   Normally you use Burpsuite within your browser, so you just have to trust the burpsuite's certificate in the browser and you're done.  \n   In order to use cariddi with the BurpSuite proxy you should do some steps further.  \n\n   If you try to use cariddi with the option `-proxy http://127.0.0.1:8080` you will find this error in the burpsuite error log section:  \n\n   ```bash\n   Received fatal alert: bad_certificate (or something similar related to the certificate).\n   ```\n\n   To make cariddi working fine with Burpsuite you have also to trust the certificate within your entire pc, not just only the browser. These are the steps you have to follow:\n\n   Go to Proxy tab in Bupsuite, then Options. Click on the CA Certificate button and export Certificate in DER format  \n\n   ```bash\n   openssl x509 -in burp.der -inform DER -out burp.pem -outform PEM\n   sudo chown root:root burp.pem\n   sudo chmod 644 burp.pem\n   sudo cp burp.pem /usr/local/share/ca-certificates/\n   sudo c_rehash\n   cd /etc/ssl/certs/\n   sudo ln -s /usr/local/share/ca-certificates/burp.pem\n   sudo c_rehash .\n   ```\n\n   Source: Trust Burp Proxy certificate in Debian/Ubuntu  \n\n   After these steps, in order to use cariddi with Burpsuite you have to:  \n\n   1. Open Burpsuite, making sure that the proxy is listening.  \n   2. Use cariddi with the flag `-proxy http://127.0.0.1:8080`.  \n   3. You will see that requests and responses will be logged in Burpsuite.\n\n</details>\n\nChangelog üìå\n-------\n\nDetailed changes for each release are documented in the [release notes](https://github.com/edoardottt/cariddi/releases).\n\nContributing üõ†\n-------\n\nJust open an [issue](https://github.com/edoardottt/cariddi/issues)/[pull request](https://github.com/edoardottt/cariddi/pulls).\n\nBefore opening a pull request, download [golangci-lint](https://golangci-lint.run/usage/install/) and run\n\n```console\ngolangci-lint run\n```\n\nIf there aren't errors, go ahead :)\n\nTest using [https://edoardottt.github.io/cariddi-test/](https://edoardottt.github.io/cariddi-test/)\n\n```console\necho \"https://edoardottt.github.io/cariddi-test/\" | cariddi\n```\n\n**Help me build this!**\n\nSpecial thanks to: [go-colly](http://go-colly.org/), [ocervell](https://github.com/ocervell), [zricethezav](https://github.com/gitleaks/gitleaks/blob/master/config/gitleaks.toml), [projectdiscovery](https://github.com/projectdiscovery/nuclei-templates/tree/master/file/keys), [tomnomnom](https://github.com/tomnomnom/gf/tree/master/examples), [RegexPassive](https://github.com/hahwul/RegexPassive) and [all the contributors](https://github.com/edoardottt/cariddi/graphs/contributors).\n\nLicense üìù\n-------\n\nThis repository is under [GNU General Public License v3.0](https://github.com/edoardottt/cariddi/blob/main/LICENSE).  \n[edoardottt.com](https://edoardottt.com/) to contact me.\n",
      "stars_today": 103
    },
    {
      "id": 783343310,
      "name": "ConvertX",
      "full_name": "C4illin/ConvertX",
      "description": "üíæ Self-hosted online file converter. Supports 1000+ formats ‚öôÔ∏è",
      "html_url": "https://github.com/C4illin/ConvertX",
      "stars": 14911,
      "forks": 797,
      "language": "TypeScript",
      "topics": [
        "bun",
        "conversion",
        "convert",
        "converter",
        "document-conversion",
        "elysia",
        "file-conversion",
        "file-converter",
        "hacktoberfest",
        "pdf-converter",
        "self-hosted",
        "tailwindcss",
        "typescript"
      ],
      "created_at": "2024-04-07T16:21:39Z",
      "updated_at": "2026-01-14T00:54:59Z",
      "pushed_at": "2026-01-13T20:47:26Z",
      "open_issues": 79,
      "owner": {
        "login": "C4illin",
        "avatar_url": "https://avatars.githubusercontent.com/u/20753603?v=4"
      },
      "readme": "![ConvertX](images/logo.png)\n\n# ConvertX\n\n[![Docker](https://github.com/C4illin/ConvertX/actions/workflows/docker-publish.yml/badge.svg?branch=main)](https://github.com/C4illin/ConvertX/actions/workflows/docker-publish.yml)\n[![ghcr.io Pulls](https://img.shields.io/badge/dynamic/json?logo=github&url=https%3A%2F%2Fipitio.github.io%2Fbackage%2FC4illin%2FConvertX%2Fconvertx.json&query=%24.downloads&label=ghcr.io%20pulls&cacheSeconds=14400)](https://github.com/C4illin/ConvertX/pkgs/container/ConvertX)\n[![Docker Pulls](https://img.shields.io/docker/pulls/c4illin/convertx?style=flat&logo=docker&label=dockerhub%20pulls&link=https%3A%2F%2Fhub.docker.com%2Frepository%2Fdocker%2Fc4illin%2Fconvertx%2Fgeneral)](https://hub.docker.com/r/c4illin/convertx)\n[![GitHub Release](https://img.shields.io/github/v/release/C4illin/ConvertX)](https://github.com/C4illin/ConvertX/pkgs/container/convertx)\n![GitHub commits since latest release](https://img.shields.io/github/commits-since/C4illin/ConvertX/latest)\n![GitHub repo size](https://img.shields.io/github/repo-size/C4illin/ConvertX)\n![Docker container size](https://ghcr-badge.egpl.dev/c4illin/convertx/size?color=%230375b6&tag=latest&label=image+size&trim=)\n\n<a href=\"https://trendshift.io/repositories/13818\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/13818\" alt=\"C4illin%2FConvertX | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\n<!-- ![Dev image size](https://ghcr-badge.egpl.dev/c4illin/convertx/size?color=%230375b6&tag=main&label=dev+image&trim=) -->\n\nA self-hosted online file converter. Supports over a thousand different formats. Written with TypeScript, Bun and Elysia.\n\n## Features\n\n- Convert files to different formats\n- Process multiple files at once\n- Password protection\n- Multiple accounts\n\n## Converters supported\n\n| Converter                                                       | Use case         | Converts from | Converts to |\n| --------------------------------------------------------------- | ---------------- | ------------- | ----------- |\n| [Inkscape](https://inkscape.org/)                               | Vector images    | 7             | 17          |\n| [libjxl](https://github.com/libjxl/libjxl)                      | JPEG XL          | 11            | 11          |\n| [resvg](https://github.com/RazrFalcon/resvg)                    | SVG              | 1             | 1           |\n| [Vips](https://github.com/libvips/libvips)                      | Images           | 45            | 23          |\n| [libheif](https://github.com/strukturag/libheif)                | HEIF             | 2             | 4           |\n| [XeLaTeX](https://tug.org/xetex/)                               | LaTeX            | 1             | 1           |\n| [Calibre](https://calibre-ebook.com/)                           | E-books          | 26            | 19          |\n| [LibreOffice](https://www.libreoffice.org/)                     | Documents        | 41            | 22          |\n| [Dasel](https://github.com/TomWright/dasel)                     | Data Files       | 5             | 4           |\n| [Pandoc](https://pandoc.org/)                                   | Documents        | 43            | 65          |\n| [msgconvert](https://github.com/mvz/email-outlook-message-perl) | Outlook          | 1             | 1           |\n| VCF to CSV                                                      | Contacts         | 1             | 1           |\n| [dvisvgm](https://dvisvgm.de/)                                  | Vector images    | 4             | 2           |\n| [ImageMagick](https://imagemagick.org/)                         | Images           | 245           | 183         |\n| [GraphicsMagick](http://www.graphicsmagick.org/)                | Images           | 167           | 130         |\n| [Assimp](https://github.com/assimp/assimp)                      | 3D Assets        | 77            | 23          |\n| [FFmpeg](https://ffmpeg.org/)                                   | Video            | ~472          | ~199        |\n| [Potrace](https://potrace.sourceforge.net/)                     | Raster to vector | 4             | 11          |\n| [VTracer](https://github.com/visioncortex/vtracer)              | Raster to vector | 8             | 1           |\n| [Markitdown](https://github.com/microsoft/markitdown)           | Documents        | 6             | 1           |\n\n<!-- many ffmpeg fileformats are duplicates -->\n\nAny missing converter? Open an issue or pull request!\n\n## Deployment\n\n> [!WARNING]\n> If you can't login, make sure you are accessing the service over localhost or https otherwise set HTTP_ALLOWED=true\n\n```yml\n# docker-compose.yml\nservices:\n  convertx:\n    image: ghcr.io/c4illin/convertx\n    container_name: convertx\n    restart: unless-stopped\n    ports:\n      - \"3000:3000\"\n    environment:\n      - JWT_SECRET=aLongAndSecretStringUsedToSignTheJSONWebToken1234 # will use randomUUID() if unset\n      # - HTTP_ALLOWED=true # uncomment this if accessing it over a non-https connection\n    volumes:\n      - ./data:/app/data\n```\n\nor\n\n```bash\ndocker run -p 3000:3000 -v ./data:/app/data ghcr.io/c4illin/convertx\n```\n\nThen visit `http://localhost:3000` in your browser and create your account. Don't leave it unconfigured and open, as anyone can register the first account.\n\nIf you get unable to open database file run `chown -R $USER:$USER path` on the path you choose.\n\n### Environment variables\n\nAll are optional, JWT_SECRET is recommended to be set.\n\n| Name                         | Default                                            | Description                                                                                                                                                   |\n| ---------------------------- | -------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| JWT_SECRET                   | when unset it will use the value from randomUUID() | A long and secret string used to sign the JSON Web Token                                                                                                      |\n| ACCOUNT_REGISTRATION         | false                                              | Allow users to register accounts                                                                                                                              |\n| HTTP_ALLOWED                 | false                                              | Allow HTTP connections, only set this to true locally                                                                                                         |\n| ALLOW_UNAUTHENTICATED        | false                                              | Allow unauthenticated users to use the service, only set this to true locally                                                                                 |\n| AUTO_DELETE_EVERY_N_HOURS    | 24                                                 | Checks every n hours for files older then n hours and deletes them, set to 0 to disable                                                                       |\n| WEBROOT                      |                                                    | The address to the root path setting this to \"/convert\" will serve the website on \"example.com/convert/\"                                                      |\n| FFMPEG_ARGS                  |                                                    | Arguments to pass to the input file of ffmpeg, e.g. `-hwaccel vaapi`. See https://github.com/C4illin/ConvertX/issues/190 for more info about hw-acceleration. |\n| FFMPEG_OUTPUT_ARGS           |                                                    | Arguments to pass to the output of ffmpeg, e.g. `-preset veryfast`                                                                                            |\n| HIDE_HISTORY                 | false                                              | Hide the history page                                                                                                                                         |\n| LANGUAGE                     | en                                                 | Language to format date strings in, specified as a [BCP 47 language tag](https://en.wikipedia.org/wiki/IETF_language_tag)                                     |\n| UNAUTHENTICATED_USER_SHARING | false                                              | Shares conversion history between all unauthenticated users                                                                                                   |\n| MAX_CONVERT_PROCESS          | 0                                                  | Maximum number of concurrent conversion processes allowed. Set to 0 for unlimited.                                                                            |\n\n### Docker images\n\nThere is a `:latest` tag that is updated with every release and a `:main` tag that is updated with every push to the main branch. `:latest` is recommended for normal use.\n\nThe image is available on [GitHub Container Registry](https://github.com/C4illin/ConvertX/pkgs/container/ConvertX) and [Docker Hub](https://hub.docker.com/r/c4illin/convertx).\n\n| Image                                  | What it is                       |\n| -------------------------------------- | -------------------------------- |\n| `image: ghcr.io/c4illin/convertx`      | The latest release on ghcr       |\n| `image: ghcr.io/c4illin/convertx:main` | The latest commit on ghcr        |\n| `image: c4illin/convertx`              | The latest release on docker hub |\n| `image: c4illin/convertx:main`         | The latest commit on docker hub  |\n\n![Release image size](https://ghcr-badge.egpl.dev/c4illin/convertx/size?color=%230375b6&tag=latest&label=release+image&trim=)\n![Dev image size](https://ghcr-badge.egpl.dev/c4illin/convertx/size?color=%230375b6&tag=main&label=dev+image&trim=)\n\n<!-- Dockerhub was introduced in 0.9.0 and older releases -->\n\n### Tutorial\n\n> [!NOTE]\n> These are written by other people, and may be outdated, incorrect or wrong.\n\nTutorial in french: <https://belginux.com/installer-convertx-avec-docker/>\n\nTutorial in chinese: <https://xzllll.com/24092901/>\n\nTutorial in polish: <https://www.kreatywnyprogramista.pl/convertx-lokalny-konwerter-plikow>\n\n## Screenshots\n\n![ConvertX Preview](images/preview.png)\n\n## Development\n\n0. Install [Bun](https://bun.sh/) and Git\n1. Clone the repository\n2. `bun install`\n3. `bun run dev`\n\nPull requests are welcome! See open issues for the list of todos. The ones tagged with \"converter request\" are quite easy. Help with docs and cleaning up in issues are also very welcome!\n\nUse [conventional commits](https://www.conventionalcommits.org/en/v1.0.0/#summary) for commit messages.\n\n## Contributors\n\n<a href=\"https://github.com/C4illin/ConvertX/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=C4illin/ConvertX\" alt=\"Image with all contributors\"/>\n</a>\n\n![Alt](https://repobeats.axiom.co/api/embed/dcdabd0564fcdcccbf5680c1bdc2efad54a3d4d9.svg \"Repobeats analytics image\")\n\n## Star History\n\n<a href=\"https://github.com/C4illin/ConvertX/stargazers\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=C4illin/ConvertX&type=Date&theme=dark\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=C4illin/ConvertX&type=Date\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=C4illin/ConvertX&type=Date\" />\n </picture>\n</a>\n",
      "stars_today": 80
    },
    {
      "id": 382496361,
      "name": "uptime-kuma",
      "full_name": "louislam/uptime-kuma",
      "description": "A fancy self-hosted monitoring tool",
      "html_url": "https://github.com/louislam/uptime-kuma",
      "stars": 81304,
      "forks": 7250,
      "language": "JavaScript",
      "topics": [
        "docker",
        "monitor",
        "monitoring",
        "responsive",
        "self-hosted",
        "selfhosted",
        "single-page-app",
        "socket-io",
        "uptime",
        "uptime-monitoring",
        "webapp",
        "websocket"
      ],
      "created_at": "2021-07-03T01:02:42Z",
      "updated_at": "2026-01-14T00:49:57Z",
      "pushed_at": "2026-01-13T12:20:00Z",
      "open_issues": 712,
      "owner": {
        "login": "louislam",
        "avatar_url": "https://avatars.githubusercontent.com/u/1336778?v=4"
      },
      "readme": "<div align=\"center\" width=\"100%\">\n    <img src=\"./public/icon.svg\" width=\"128\" alt=\"Uptime Kuma Logo\" />\n</div>\n\n# Uptime Kuma\n\nUptime Kuma is an easy-to-use self-hosted monitoring tool.\n\n<a target=\"_blank\" href=\"https://github.com/louislam/uptime-kuma\"><img src=\"https://img.shields.io/github/stars/louislam/uptime-kuma?style=flat\" /></a> <a target=\"_blank\" href=\"https://hub.docker.com/r/louislam/uptime-kuma\"><img src=\"https://img.shields.io/docker/pulls/louislam/uptime-kuma\" /></a> <a target=\"_blank\" href=\"https://hub.docker.com/r/louislam/uptime-kuma\"><img src=\"https://img.shields.io/docker/v/louislam/uptime-kuma/2?label=docker%20image%20ver.\" /></a> <a target=\"_blank\" href=\"https://github.com/louislam/uptime-kuma\"><img src=\"https://img.shields.io/github/last-commit/louislam/uptime-kuma\" /></a> <a target=\"_blank\" href=\"https://opencollective.com/uptime-kuma\"><img src=\"https://opencollective.com/uptime-kuma/total/badge.svg?label=Open%20Collective%20Backers&color=brightgreen\" /></a>\n[![GitHub Sponsors](https://img.shields.io/github/sponsors/louislam?label=GitHub%20Sponsors)](https://github.com/sponsors/louislam) <a href=\"https://weblate.kuma.pet/projects/uptime-kuma/uptime-kuma/\">\n<img src=\"https://weblate.kuma.pet/widgets/uptime-kuma/-/svg-badge.svg\" alt=\"Translation status\" />\n</a>\n\n<img src=\"https://user-images.githubusercontent.com/1336778/212262296-e6205815-ad62-488c-83ec-a5b0d0689f7c.jpg\" width=\"700\" alt=\"Uptime Kuma Dashboard Screenshot\" />\n\n## ü•î Live Demo\n\nTry it!\n\nDemo Server (Location: Frankfurt - Germany): <https://demo.kuma.pet/start-demo>\n\nIt is a temporary live demo, all data will be deleted after 10 minutes. Sponsored by [Uptime Kuma Sponsors](https://github.com/louislam/uptime-kuma#%EF%B8%8F-sponsors).\n\n## ‚≠ê Features\n\n- Monitoring uptime for HTTP(s) / TCP / HTTP(s) Keyword / HTTP(s) Json Query / Websocket / Ping / DNS Record / Push / Steam Game Server / Docker Containers\n- Fancy, Reactive, Fast UI/UX\n- Notifications via Telegram, Discord, Gotify, Slack, Pushover, Email (SMTP), and [90+ notification services, click here for the full list](https://github.com/louislam/uptime-kuma/tree/master/src/components/notifications)\n- 20-second intervals\n- [Multi Languages](https://github.com/louislam/uptime-kuma/tree/master/src/lang)\n- Multiple status pages\n- Map status pages to specific domains\n- Ping chart\n- Certificate info\n- Proxy support\n- 2FA support\n\n## üîß How to Install\n\n### üê≥ Docker Compose\n\n```bash\nmkdir uptime-kuma\ncd uptime-kuma\ncurl -o compose.yaml https://raw.githubusercontent.com/louislam/uptime-kuma/master/compose.yaml\ndocker compose up -d\n```\n\nUptime Kuma is now running on all network interfaces (e.g. http://localhost:3001 or http://your-ip:3001).\n\n> [!WARNING]\n> File Systems like **NFS** (Network File System) are **NOT** supported. Please map to a local directory or volume.\n\n### üê≥ Docker Command\n\n```bash\ndocker run -d --restart=always -p 3001:3001 -v uptime-kuma:/app/data --name uptime-kuma louislam/uptime-kuma:2\n```\n\nUptime Kuma is now running on all network interfaces (e.g. http://localhost:3001 or http://your-ip:3001).\n\nIf you want to limit exposure to localhost only:\n\n```bash\ndocker run ... -p 127.0.0.1:3001:3001 ...\n```\n\n### üí™üèª Non-Docker\n\nRequirements:\n\n- Platform\n  - ‚úÖ Major Linux distros such as Debian, Ubuntu, Fedora and ArchLinux etc.\n  - ‚úÖ Windows 10 (x64), Windows Server 2012 R2 (x64) or higher\n  - ‚ùå FreeBSD / OpenBSD / NetBSD\n  - ‚ùå Replit / Heroku\n- [Node.js](https://nodejs.org/en/download/) >= 20.4\n- [Git](https://git-scm.com/downloads)\n- [pm2](https://pm2.keymetrics.io/) - For running Uptime Kuma in the background\n\n```bash\ngit clone https://github.com/louislam/uptime-kuma.git\ncd uptime-kuma\nnpm run setup\n\n# Option 1. Try it\nnode server/server.js\n\n# (Recommended) Option 2. Run in the background using PM2\n# Install PM2 if you don't have it:\nnpm install pm2 -g && pm2 install pm2-logrotate\n\n# Start Server\npm2 start server/server.js --name uptime-kuma\n```\n\nUptime Kuma is now running on all network interfaces (e.g. http://localhost:3001 or http://your-ip:3001).\n\nMore useful PM2 Commands\n\n```bash\n# If you want to see the current console output\npm2 monit\n\n# If you want to add it to startup\npm2 startup && pm2 save\n```\n\n### Advanced Installation\n\nIf you need more options or need to browse via a reverse proxy, please read:\n\n<https://github.com/louislam/uptime-kuma/wiki/%F0%9F%94%A7-How-to-Install>\n\n## üÜô How to Update\n\nPlease read:\n\n<https://github.com/louislam/uptime-kuma/wiki/%F0%9F%86%99-How-to-Update>\n\n## üÜï What's Next?\n\nI will assign requests/issues to the next milestone.\n\n<https://github.com/louislam/uptime-kuma/milestones>\n\n## ‚ù§Ô∏è Sponsors\n\nThank you so much! (GitHub Sponsors will be updated manually. OpenCollective sponsors will be updated automatically, the list will be cached by GitHub though. It may need some time to be updated)\n\n<img src=\"https://uptime.kuma.pet/sponsors?v=6\" alt=\"Uptime Kuma Sponsors\" />\n\n## üñº More Screenshots\n\nLight Mode:\n\n<img src=\"https://uptime.kuma.pet/img/light.jpg\" width=\"512\" alt=\"Uptime Kuma Light Mode Screenshot of how the Dashboard looks\" />\n\nStatus Page:\n\n<img src=\"https://user-images.githubusercontent.com/1336778/134628766-a3fe0981-0926-4285-ab46-891a21c3e4cb.png\" width=\"512\" alt=\"Uptime Kuma Status Page Screenshot\" />\n\nSettings Page:\n\n<img src=\"https://louislam.net/uptimekuma/2.jpg\" width=\"400\" alt=\"Uptime Kuma Settings Page Screenshot\" />\n\nTelegram Notification Sample:\n\n<img src=\"https://louislam.net/uptimekuma/3.jpg\" width=\"400\" alt=\"Uptime Kuma Telegram Notification Sample Screenshot\" />\n\n## Motivation\n\n- I was looking for a self-hosted monitoring tool like \"Uptime Robot\", but it is hard to find a suitable one. One of the closest ones is statping. Unfortunately, it is not stable and no longer maintained.\n- Wanted to build a fancy UI.\n- Learn Vue 3 and vite.js.\n- Show the power of Bootstrap 5.\n- Try to use WebSocket with SPA instead of a REST API.\n- Deploy my first Docker image to Docker Hub.\n\nIf you love this project, please consider giving it a ‚≠ê.\n\n## üó£Ô∏è Discussion / Ask for Help\n\n‚ö†Ô∏è For any general or technical questions, please don't send me an email, as I am unable to provide support in that manner. I will not respond if you ask questions there.\n\nI recommend using Google, GitHub Issues, or Uptime Kuma's subreddit for finding answers to your question. If you cannot find the information you need, feel free to ask:\n\n- [GitHub Issues](https://github.com/louislam/uptime-kuma/issues)\n- [Subreddit (r/UptimeKuma)](https://www.reddit.com/r/UptimeKuma/)\n\nMy Reddit account: [u/louislamlam](https://reddit.com/u/louislamlam)\nYou can mention me if you ask a question on the subreddit.\n\n## Contributions\n\n### Create Pull Requests\n\nPull requests are awesome.\nTo keep reviews fast and effective, please make sure you‚Äôve [read our pull request guidelines](https://github.com/louislam/uptime-kuma/blob/master/CONTRIBUTING.md#can-i-create-a-pull-request-for-uptime-kuma).\n\n### Test Pull Requests\n\nThere are a lot of pull requests right now, but I don't have time to test them all.\n\nIf you want to help, you can check this:\n<https://github.com/louislam/uptime-kuma/wiki/Test-Pull-Requests>\n\n### Test Beta Version\n\nCheck out the latest beta release here: <https://github.com/louislam/uptime-kuma/releases>\n\n### Bug Reports / Feature Requests\n\nIf you want to report a bug or request a new feature, feel free to open a [new issue](https://github.com/louislam/uptime-kuma/issues).\n\n### Translations\n\nIf you want to translate Uptime Kuma into your language, please visit [Weblate Readme](https://github.com/louislam/uptime-kuma/blob/master/src/lang/README.md).\n\n### Spelling & Grammar\n\nFeel free to correct the grammar in the documentation or code.\nMy mother language is not English and my grammar is not that great.\n",
      "stars_today": 77
    },
    {
      "id": 121898717,
      "name": "vaultwarden",
      "full_name": "dani-garcia/vaultwarden",
      "description": "Unofficial Bitwarden compatible server written in Rust, formerly known as bitwarden_rs",
      "html_url": "https://github.com/dani-garcia/vaultwarden",
      "stars": 53434,
      "forks": 2473,
      "language": "Rust",
      "topics": [
        "bitwarden",
        "bitwarden-rs",
        "docker",
        "rocket",
        "rust",
        "vaultwarden"
      ],
      "created_at": "2018-02-17T22:40:20Z",
      "updated_at": "2026-01-14T00:55:42Z",
      "pushed_at": "2026-01-09T18:22:58Z",
      "open_issues": 33,
      "owner": {
        "login": "dani-garcia",
        "avatar_url": "https://avatars.githubusercontent.com/u/725423?v=4"
      },
      "readme": "![Vaultwarden Logo](./resources/vaultwarden-logo-auto.svg)\n\nAn alternative server implementation of the Bitwarden Client API, written in Rust and compatible with [official Bitwarden clients](https://bitwarden.com/download/) [[disclaimer](#disclaimer)], perfect for self-hosted deployment where running the official resource-heavy service might not be ideal.\n\n---\n\n[![GitHub Release](https://img.shields.io/github/release/dani-garcia/vaultwarden.svg?style=for-the-badge&logo=vaultwarden&color=005AA4)](https://github.com/dani-garcia/vaultwarden/releases/latest)\n[![ghcr.io Pulls](https://img.shields.io/badge/dynamic/json?style=for-the-badge&logo=github&logoColor=fff&color=005AA4&url=https%3A%2F%2Fipitio.github.io%2Fbackage%2Fdani-garcia%2Fvaultwarden%2Fvaultwarden.json&query=%24.downloads&label=ghcr.io%20pulls&cacheSeconds=14400)](https://github.com/dani-garcia/vaultwarden/pkgs/container/vaultwarden)\n[![Docker Pulls](https://img.shields.io/docker/pulls/vaultwarden/server.svg?style=for-the-badge&logo=docker&logoColor=fff&color=005AA4&label=docker.io%20pulls)](https://hub.docker.com/r/vaultwarden/server)\n[![Quay.io](https://img.shields.io/badge/quay.io-download-005AA4?style=for-the-badge&logo=redhat&cacheSeconds=14400)](https://quay.io/repository/vaultwarden/server) <br>\n[![Contributors](https://img.shields.io/github/contributors-anon/dani-garcia/vaultwarden.svg?style=flat-square&logo=vaultwarden&color=005AA4)](https://github.com/dani-garcia/vaultwarden/graphs/contributors)\n[![Forks](https://img.shields.io/github/forks/dani-garcia/vaultwarden.svg?style=flat-square&logo=github&logoColor=fff&color=005AA4)](https://github.com/dani-garcia/vaultwarden/network/members)\n[![Stars](https://img.shields.io/github/stars/dani-garcia/vaultwarden.svg?style=flat-square&logo=github&logoColor=fff&color=005AA4)](https://github.com/dani-garcia/vaultwarden/stargazers)\n[![Issues Open](https://img.shields.io/github/issues/dani-garcia/vaultwarden.svg?style=flat-square&logo=github&logoColor=fff&color=005AA4&cacheSeconds=300)](https://github.com/dani-garcia/vaultwarden/issues)\n[![Issues Closed](https://img.shields.io/github/issues-closed/dani-garcia/vaultwarden.svg?style=flat-square&logo=github&logoColor=fff&color=005AA4&cacheSeconds=300)](https://github.com/dani-garcia/vaultwarden/issues?q=is%3Aissue+is%3Aclosed)\n[![AGPL-3.0 Licensed](https://img.shields.io/github/license/dani-garcia/vaultwarden.svg?style=flat-square&logo=vaultwarden&color=944000&cacheSeconds=14400)](https://github.com/dani-garcia/vaultwarden/blob/main/LICENSE.txt) <br>\n[![Dependency Status](https://img.shields.io/badge/dynamic/xml?url=https%3A%2F%2Fdeps.rs%2Frepo%2Fgithub%2Fdani-garcia%2Fvaultwarden%2Fstatus.svg&query=%2F*%5Blocal-name()%3D'svg'%5D%2F*%5Blocal-name()%3D'g'%5D%5B2%5D%2F*%5Blocal-name()%3D'text'%5D%5B4%5D&style=flat-square&logo=rust&label=dependencies&color=005AA4)](https://deps.rs/repo/github/dani-garcia/vaultwarden)\n[![GHA Release](https://img.shields.io/github/actions/workflow/status/dani-garcia/vaultwarden/release.yml?style=flat-square&logo=github&logoColor=fff&label=Release%20Workflow)](https://github.com/dani-garcia/vaultwarden/actions/workflows/release.yml)\n[![GHA Build](https://img.shields.io/github/actions/workflow/status/dani-garcia/vaultwarden/build.yml?style=flat-square&logo=github&logoColor=fff&label=Build%20Workflow)](https://github.com/dani-garcia/vaultwarden/actions/workflows/build.yml) <br>\n[![Matrix Chat](https://img.shields.io/matrix/vaultwarden:matrix.org.svg?style=flat-square&logo=matrix&logoColor=fff&color=953B00&cacheSeconds=14400)](https://matrix.to/#/#vaultwarden:matrix.org)\n[![GitHub Discussions](https://img.shields.io/github/discussions/dani-garcia/vaultwarden?style=flat-square&logo=github&logoColor=fff&color=953B00&cacheSeconds=300)](https://github.com/dani-garcia/vaultwarden/discussions)\n[![Discourse Discussions](https://img.shields.io/discourse/topics?server=https%3A%2F%2Fvaultwarden.discourse.group%2F&style=flat-square&logo=discourse&color=953B00)](https://vaultwarden.discourse.group/)\n\n> [!IMPORTANT]\n> **When using this server, please report any bugs or suggestions directly to us (see [Get in touch](#get-in-touch)), regardless of whatever clients you are using (mobile, desktop, browser...). DO NOT use the official Bitwarden support channels.**\n\n<br>\n\n## Features\n\nA nearly complete implementation of the Bitwarden Client API is provided, including:\n\n * [Personal Vault](https://bitwarden.com/help/managing-items/)\n * [Send](https://bitwarden.com/help/about-send/)\n * [Attachments](https://bitwarden.com/help/attachments/)\n * [Website icons](https://bitwarden.com/help/website-icons/)\n * [Personal API Key](https://bitwarden.com/help/personal-api-key/)\n * [Organizations](https://bitwarden.com/help/getting-started-organizations/)\n   - [Collections](https://bitwarden.com/help/about-collections/),\n     [Password Sharing](https://bitwarden.com/help/sharing/),\n     [Member Roles](https://bitwarden.com/help/user-types-access-control/),\n     [Groups](https://bitwarden.com/help/about-groups/),\n     [Event Logs](https://bitwarden.com/help/event-logs/),\n     [Admin Password Reset](https://bitwarden.com/help/admin-reset/),\n     [Directory Connector](https://bitwarden.com/help/directory-sync/),\n     [Policies](https://bitwarden.com/help/policies/)\n * [Multi/Two Factor Authentication](https://bitwarden.com/help/bitwarden-field-guide-two-step-login/)\n   - [Authenticator](https://bitwarden.com/help/setup-two-step-login-authenticator/),\n     [Email](https://bitwarden.com/help/setup-two-step-login-email/),\n     [FIDO2 WebAuthn](https://bitwarden.com/help/setup-two-step-login-fido/),\n     [YubiKey](https://bitwarden.com/help/setup-two-step-login-yubikey/),\n     [Duo](https://bitwarden.com/help/setup-two-step-login-duo/)\n * [Emergency Access](https://bitwarden.com/help/emergency-access/)\n * [Vaultwarden Admin Backend](https://github.com/dani-garcia/vaultwarden/wiki/Enabling-admin-page)\n * [Modified Web Vault client](https://github.com/dani-garcia/bw_web_builds) (Bundled within our containers)\n\n<br>\n\n## Usage\n\n> [!IMPORTANT]\n> The web-vault requires the use a secure context for the [Web Crypto API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Crypto_API).\n> That means it will only work via `http://localhost:8000` (using the port from the example below) or if you [enable HTTPS](https://github.com/dani-garcia/vaultwarden/wiki/Enabling-HTTPS).\n\nThe recommended way to install and use Vaultwarden is via our container images which are published to [ghcr.io](https://github.com/dani-garcia/vaultwarden/pkgs/container/vaultwarden), [docker.io](https://hub.docker.com/r/vaultwarden/server) and [quay.io](https://quay.io/repository/vaultwarden/server).\nSee [which container image to use](https://github.com/dani-garcia/vaultwarden/wiki/Which-container-image-to-use) for an explanation of the provided tags.\n\nThere are also [community driven packages](https://github.com/dani-garcia/vaultwarden/wiki/Third-party-packages) which can be used, but those might be lagging behind the latest version or might deviate in the way Vaultwarden is configured, as described in our [Wiki](https://github.com/dani-garcia/vaultwarden/wiki).\n\nAlternatively, you can also [build Vaultwarden](https://github.com/dani-garcia/vaultwarden/wiki/Building-binary) yourself.\n\nWhile Vaultwarden is based upon the [Rocket web framework](https://rocket.rs) which has built-in support for TLS our recommendation would be that you setup a reverse proxy (see [proxy examples](https://github.com/dani-garcia/vaultwarden/wiki/Proxy-examples)).\n\n> [!TIP]\n>**For more detailed examples on how to install, use and configure Vaultwarden you can check our [Wiki](https://github.com/dani-garcia/vaultwarden/wiki).**\n\n### Docker/Podman CLI\n\nPull the container image and mount a volume from the host for persistent storage.<br>\nYou can replace `docker` with `podman` if you prefer to use podman.\n\n```shell\ndocker pull vaultwarden/server:latest\ndocker run --detach --name vaultwarden \\\n  --env DOMAIN=\"https://vw.domain.tld\" \\\n  --volume /vw-data/:/data/ \\\n  --restart unless-stopped \\\n  --publish 127.0.0.1:8000:80 \\\n  vaultwarden/server:latest\n```\n\nThis will preserve any persistent data under `/vw-data/`, you can adapt the path to whatever suits you.\n\n### Docker Compose\n\nTo use Docker compose you need to create a `compose.yaml` which will hold the configuration to run the Vaultwarden container.\n\n```yaml\nservices:\n  vaultwarden:\n    image: vaultwarden/server:latest\n    container_name: vaultwarden\n    restart: unless-stopped\n    environment:\n      DOMAIN: \"https://vw.domain.tld\"\n    volumes:\n      - ./vw-data/:/data/\n    ports:\n      - 127.0.0.1:8000:80\n```\n\n<br>\n\n## Get in touch\n\nHave a question, suggestion or need help? Join our community on [Matrix](https://matrix.to/#/#vaultwarden:matrix.org), [GitHub Discussions](https://github.com/dani-garcia/vaultwarden/discussions) or [Discourse Forums](https://vaultwarden.discourse.group/).\n\nEncountered a bug or crash? Please search our issue tracker and discussions to see if it's already been reported. If not, please [start a new discussion](https://github.com/dani-garcia/vaultwarden/discussions) or [create a new issue](https://github.com/dani-garcia/vaultwarden/issues/). Ensure you're using the latest version of Vaultwarden and there aren't any similar issues open or closed!\n\n<br>\n\n## Contributors\n\nThanks for your contribution to the project!\n\n[![Contributors Count](https://img.shields.io/github/contributors-anon/dani-garcia/vaultwarden?style=for-the-badge&logo=vaultwarden&color=005AA4)](https://github.com/dani-garcia/vaultwarden/graphs/contributors)<br>\n[![Contributors Avatars](https://contributors-img.web.app/image?repo=dani-garcia/vaultwarden)](https://github.com/dani-garcia/vaultwarden/graphs/contributors)\n\n<br>\n\n## Disclaimer\n\n**This project is not associated with [Bitwarden](https://bitwarden.com/) or Bitwarden, Inc.**\n\nHowever, one of the active maintainers for Vaultwarden is employed by Bitwarden and is allowed to contribute to the project on their own time. These contributions are independent of Bitwarden and are reviewed by other maintainers.\n\nThe maintainers work together to set the direction for the project, focusing on serving the self-hosting community, including individuals, families, and small organizations, while ensuring the project's sustainability.\n\n**Please note:** We cannot be held liable for any data loss that may occur while using Vaultwarden. This includes passwords, attachments, and other information handled by the application. We highly recommend performing regular backups of your files and database. However, should you experience data loss, we encourage you to contact us immediately.\n\n<br>\n\n## Bitwarden_RS\n\nThis project was known as Bitwarden_RS and has been renamed to separate itself from the official Bitwarden server in the hopes of avoiding confusion and trademark/branding issues.<br>\nPlease see [#1642 - v1.21.0 release and project rename to Vaultwarden](https://github.com/dani-garcia/vaultwarden/discussions/1642) for more explanation.\n",
      "stars_today": 77
    },
    {
      "id": 379877112,
      "name": "open-meteo",
      "full_name": "open-meteo/open-meteo",
      "description": "Free Weather Forecast API for non-commercial use",
      "html_url": "https://github.com/open-meteo/open-meteo",
      "stars": 4477,
      "forks": 291,
      "language": "Swift",
      "topics": [
        "weather",
        "weather-api",
        "weather-forecast"
      ],
      "created_at": "2021-06-24T09:48:38Z",
      "updated_at": "2026-01-13T23:32:29Z",
      "pushed_at": "2026-01-13T21:00:28Z",
      "open_issues": 162,
      "owner": {
        "login": "open-meteo",
        "avatar_url": "https://avatars.githubusercontent.com/u/86407831?v=4"
      },
      "readme": "# üå§ Open-Meteo Weather API\n\n[![Test](https://github.com/open-meteo/open-meteo/actions/workflows/test.yml/badge.svg?branch=main)](https://github.com/open-meteo/open-meteo/actions/workflows/test.yml) [![GitHub license](https://img.shields.io/github/license/open-meteo/open-meteo)](https://github.com/open-meteo/open-meteo/blob/main/LICENSE) [![license: CC BY 4.0](https://img.shields.io/badge/license-CC%20BY%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/) [![Twitter](https://img.shields.io/badge/follow-%40open_meteo-1DA1F2?logo=twitter&style=social)](https://twitter.com/open_meteo) [![Mastodon](https://img.shields.io/mastodon/follow/109320332765909743?domain=https%3A%2F%2Ffosstodon.org)](https://fosstodon.org/@openmeteo) [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7970649.svg)](https://doi.org/10.5281/zenodo.7970649)\n\nOpen-Meteo is an open-source weather API and offers free access for non-commercial use. No API key is required. You can use it immediately!\n\nHead over to https://open-meteo.com! Stay up to date with our blog at https://openmeteo.substack.com.\n\n## Features\n\n- [Hourly weather forecast](https://open-meteo.com/en/docs) for up to 16 days\n- Global weather models with 11 km and regional models up to 1.5 km resolution\n- Weather model updates every hour for Europe and North America\n- 80 years [Historical Weather API](https://open-meteo.com/en/docs/historical-weather-api)\n- Based on the best weather models: [NOAA GFS with HRRR](https://open-meteo.com/en/docs/gfs-api), [DWD ICON](https://open-meteo.com/en/docs/dwd-api), [MeteoFrance Arome&Arpege](https://open-meteo.com/en/docs/meteofrance-api), [ECMWF IFS](https://open-meteo.com/en/docs/ecmwf-api), [JMA](https://open-meteo.com/en/docs/jma-api), [GEM HRDPS](https://open-meteo.com/en/docs/gem-api), [MET Norway](https://open-meteo.com/en/docs/metno-api)\n- [Marine Forecast API](https://open-meteo.com/en/docs/marine-weather-api), [Air Quality API](https://open-meteo.com/en/docs/air-quality-api), [Geocoding API](https://open-meteo.com/en/docs/geocoding-api), [Elevation API](https://open-meteo.com/en/docs/elevation-api), [Flood API](https://open-meteo.com/en/docs/flood-api)\n- Lightning fast APIs with response times below 10 ms\n- Servers located in Europe and North America with GeoDNS for best latency and high-availability\n- No API key required, CORS supported, no ads, no tracking, not even cookies\n- Free for non-commercial use with data under Attribution 4.0 International (CC BY 4.0)\n- Source code available under AGPLv3\n\n## How does Open-Meteo work?\n\nOpen-Meteo utilizes open-data weather forecasts provided by national weather services. These services offer numerical weather predictions that are free to download. However, working with these models can be challenging, as it requires expertise in binary file formats, grid-systems, projections, and the fundamentals of weather predictions.\n\nLike many other weather APIs, Open-Meteo integrates high-resolution local and global weather models. Over 2 TB of data are downloaded and processed daily from multiple national weather services. The collected data is then stored in local files using a customized file format and compression technique to enhance access to time-series data such as a 14-day temperature forecast.\n\nIn contrast to other weather APIs, Open-Meteo provides complete access to its source code, and all data sources are openly listed, crediting the national weather services for their work. With Docker or prebuilt Ubuntu packages, it is possible to launch your own weather API within minutes. By providing the source code, users can conduct detailed verifications of the weather data processing and even make modifications themselves. Contributions are highly encouraged and welcomed.\n\nThe API is available for non-commercial use at no cost. Despite being free of charge, the forecast accuracy is top-notch. The API utilizes a vast array of local weather models with rapid updates, ensuring that the most precise forecast is generated for any location globally.\n\n## Resources\n\n- All API documentation can be found on https://open-meteo.com. The source code for the website, documentation and API generator is available here: https://github.com/open-meteo/open-meteo-website\n- The free non-commerical API is hosted at [https://api.open-meteo.com](https://api.open-meteo.com/v1/forecast?latitude=52.52&longitude=13.41&hourly=temperature_2m) using to GeoDNS to servers in Europe and North America (HTTPS is optional). The API source code is in this current repository.\n- The geocoding API source code is available in a separate repository https://github.com/open-meteo/geocoding-api\n- Larger changes are announced in the [Open-Meteo Blog](https://openmeteo.substack.com)\n- The [Open-Meteo weather database](https://github.com/open-meteo/open-data) is redistributed as part of an AWS Open-Data Sponsorship\n\n## Who is using Open-Meteo?\n\nApps:\n\n- [Alpine Conditions](https://www.alpineconditions.com) Allows a user to compare multiple models at once & create ensemble forecasts for any location\n- [Breezy Weather](https://github.com/breezy-weather/breezy-weather) A feature-rich, free and open source Material 3 Expressive Android weather app.\n- [Cirrus](https://github.com/woheller69/omweather) Android Weather App\n- [Clima](https://f-droid.org/packages/co.prestosole.clima/) Beautiful, minimal, and fast weather app\n- [DroneWeather](https://play.google.com/store/apps/details?id=xyz.droneweather.app) Weather forecasts, satellite count, and KP index for drone pilots.\n- [Emojiton Weather](https://emojiton.com/weather) Get the local weather forecast for your location with fun emoji representations\n- [Evaporative Cooler Forecaster](https://SwampCooler.app) Swamp cooler effectiveness forecast with cost & energy savings, Android/iOS app\n- [Home Assistant](https://www.home-assistant.io/integrations/open_meteo/) A popular open source smart home platform.\n- [Lively Weather](https://www.rocksdanister.com/weather) Windows native weather app powered by DirectX12 animations.\n- [LunaLink](https://www.lunalink.de) A site for hunters, fishermen and nature observers: It provides sun and moon values ‚Äã‚Äã(including moon brightness) as well as the weather for individual locations in Central Europe.\n- [Meteo-Fly](https://meteo-fly.com) Free flight-weather charts for paraglider & hang-glider pilots.\n- [MeteoHist](https://yotka.org/meteo-hist) A web app to create interactive temperature and precipitation graphs for places around the world\n- [OSS Weather](https://github.com/Akylas/oss-weather) - Multi-model/multi-provider Open Source Android/iOS Weather app\n- [Overmorrow](https://github.com/bmaroti9/Overmorrow) A modern material design Android weather app.\n- [PointWx](https://hh.guidocioni.it/pointwx/) Dash application with interactive plots (from beginner-friendly to weather-enthusiast level) easily deployable\n- [QuickWeather](https://github.com/TylerWilliamson/QuickWeather) Fast, free, and open source Android app\n- [Rain](https://github.com/DarkMooNight/Rain) Free, open source, beautiful, minimal and fast weather app\n- [Raindrop](https://github.com/metalfoxdev/Raindrop) Simple and intuitive weather app for the linux terminal.\n- [Road Vagabond](https://roadvagabond.com) A camping destination discovery app showing zones within your drive time with weather-based filtering.\n- [SkyMuse](https://github.com/cakephone/skymuse) Minimal, privacy-respecting weather app. Built with web technologies.\n- [Slideshow](https://slideshow.digital/) Digital Signage app for Android\n- [solXpect](https://github.com/woheller69/solxpect) Android app which forecasts the output of your solar power plant\n- [The Weather](https://weather.jamesdinovo.com) A detailed, installable, progressive web application\n- [truthclimate](https://www.truthclimate.com) Discover how weather and climate changed all around the world.\n- [Weather Please](https://github.com/ggaidelevicius/weather-please/) Clean and minimal new tab replacement for browsers\n- [Weather.io](https://weather.roessner.tech) A simple Progressive Web App (PWA) for checking the weather.\n- [Weather](https://github.com/GustavLindberg99/AndroidWeather) Free, open source, simple and complete weather app for Android\n- [WeatherAI](https://play.google.com/store/apps/details?id=com.kingfu.weatherai) WeatherAI offers an intuitive user experience that makes checking the weather a breeze.\n- [WeatherGraph](https://weathergraph.app) Apple Watch App\n- [WeatherMaster](https://github.com/PranshulGG/WeatherMaster) A Weather app for android inspired by the Google Pixel weather app.\n- [Weatherian](https://weatherian.com/) Multi-model meteogram (multi-platform)\n- [weewx-DWD](https://github.com/roe-dl/weewx-DWD) Weather forecasts etc. for WeeWX\n- [WetBulb](https://github.com/Isma1306/wetbulb-forecast) A simple app that shows you the wetbulb temp 24h forecast and tells you if it is dangerous.\n\nRepositories:\n\n- [Captain Cold](https://github.com/cburton-godaddy/captain-cold) Simple Open-Meteo -> Discord integration\n- [wthrr-the-weathercrab](https://github.com/tobealive/wthrr-the-weathercrab) Weather companion for the terminal\n- [Weather-Cli](https://github.com/Rayrsn/Weather-Cli) A CLI program written in golang that allows you to get weather information from the terminal\n- [Homepage](https://github.com/benphelps/homepage/) A highly customizable homepage (or startpage / application dashboard) with Docker and service API integrations.\n- [Spots Guru](https://www.spots.guru) Weather forecast for lazy, the best wind & wave spots around you.\n- [WeatherReport.jl](https://github.com/vnegi10/WeatherReport.jl) A simple weather app for the Julia REPL\n- [DIY Arduino esp8266 weather station](https://github.com/AlexeyMal/esp8266-weather-station) esp8266 weather station using Open-Meteo API, an embedded C++ implementation example\n- [biome](https://github.com/SqrtMinusOne/biome) Bountiful Interface to Open Meteo for Emacs\n\nOther:\n\n- [Menubar Weather](https://www.raycast.com/koinzhang/menubar-weather) A Raycast extension that displays live weather information in your menu bar\n- [MiniPavi](https://www.minipavi.fr/emulminitel/) Vintage French Minitel (a kind of BBS) weather forecast service (type \"METEO\" keyword on welcome Minitel screen)\n- [OFM-InternetWeatherModule](https://github.com/OpenKNX/OFM-InternetWeatherModule) An OpenKNX module to provide data of weather services on KNX-bus (configurable via ETS)\n- Contributions welcome!\n\nDo you use Open-Meteo? Please open a pull request and add your repository or app to the list!\n\n## Client SDKs\n\n- Go https://github.com/HectorMalot/omgo\n- Python https://github.com/m0rp43us/openmeteopy\n- Kotlin https://github.com/open-meteo/open-meteo-api-kotlin\n- .Net / C# https://github.com/AlienDwarf/open-meteo-dotnet\n- dotnet 8 / C# https://github.com/colinnuk/open-meteo-dotnet-client-sdk\n- PHP Laravel https://github.com/michaelnabil230/laravel-weather\n- R https://github.com/tpisel/openmeteo\n- PHP Symfony 6.2 https://gitlab.com/flibidi67/open-meteo\n- PHP for Geocoding API: https://gitlab.com/flibidi67/open-meteo-geocoding\n- Android library for Geocoding API: https://github.com/woheller69/OmGeoDialog\n- Dart / Flutter: https://github.com/neursh/open-meteo-dart\n- Rust: https://github.com/angelodlfrtr/open-meteo-rs\n\nContributions welcome! Writing a SDK for Open-Meteo is more than welcome and a great way to help users.\n\n## Support\n\nIf you encounter bugs while using Open-Meteo APIs, please file a new issue ticket. For general ideas or Q&A please use the [Discussion](https://github.com/open-meteo/open-meteo/discussions) section on Github. Thanks!\n\nFor other enquiries please contact info@open-meteo.com\n\n## Run your own API\n\nInstructions to use Docker to run your own weather API are available in the [getting started guide](/docs/getting-started.md).\n\n## Terms & Privacy\n\nOpen-Meteo APIs are free for open-source developer and non-commercial use. We do not restrict access, but ask for fair use.\n\nIf your application exceeds 10'000 requests per day, please contact us. We reserve the right to block applications and IP addresses that misuse our service.\n\nFor commercial use of Open-Meteo APIs, please contact us.\n\nAll data is provided as is without any warranty.\n\nWe do not collect any personal data. We do not share any personal information. We do not integrate any third party analytics, ads, beacons or plugins.\n\n## Data License\n\nAPI data are offered under Attribution 4.0 International (CC BY 4.0)\n\nYou are free to share: copy and redistribute the material in any medium or format and adapt: remix, transform, and build upon the material.\n\nAttribution: You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n\nYou must include a link next to any location, Open-Meteo data are displayed like:\n\n<a href=\"https://open-meteo.com/\">Weather data by Open-Meteo.com</a>\n\n## Source Code License\n\nOpen-Meteo is open-source under the GNU Affero General Public License Version 3 (AGPLv3) or any later version. You can [find the license here](LICENSE). Exceptions are third party source-code with individual licensing in each file.\n",
      "stars_today": 72
    },
    {
      "id": 805155266,
      "name": "cherry-studio",
      "full_name": "CherryHQ/cherry-studio",
      "description": "AI Agent + Coding Agent + 300+ assistants: agentic AI desktop with autonomous coding, intelligent automation, and unified access to frontier LLMs.",
      "html_url": "https://github.com/CherryHQ/cherry-studio",
      "stars": 37719,
      "forks": 3479,
      "language": "TypeScript",
      "topics": [
        "ai-agent",
        "ai-sdk",
        "chatbots",
        "claude-code",
        "claude-code-sdk",
        "claude-code-skills",
        "code-agent"
      ],
      "created_at": "2024-05-24T01:56:26Z",
      "updated_at": "2026-01-14T00:35:32Z",
      "pushed_at": "2026-01-13T23:09:27Z",
      "open_issues": 642,
      "owner": {
        "login": "CherryHQ",
        "avatar_url": "https://avatars.githubusercontent.com/u/187777663?v=4"
      },
      "readme": "<div align=\"right\" >\n  <details>\n    <summary >üåê Language</summary>\n    <div>\n      <div align=\"right\">\n        <p><a href=\"https://openaitx.github.io/view.html?user=CherryHQ&project=cherry-studio&lang=en\">English</a></p>\n        <p><a href=\"https://openaitx.github.io/view.html?user=CherryHQ&project=cherry-studio&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a></p>\n        <p><a href=\"https://openaitx.github.io/view.html?user=CherryHQ&project=cherry-studio&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a></p>\n        <p><a href=\"https://openaitx.github.io/view.html?user=CherryHQ&project=cherry-studio&lang=ja\">Êó•Êú¨Ë™û</a></p>\n        <p><a href=\"https://openaitx.github.io/view.html?user=CherryHQ&project=cherry-studio&lang=ko\">ÌïúÍµ≠Ïñ¥</a></p>\n        <p><a href=\"https://openaitx.github.io/view.html?user=CherryHQ&project=cherry-studio&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a></p>\n        <p><a href=\"https://openaitx.github.io/view.html?user=CherryHQ&project=cherry-studio&lang=th\">‡πÑ‡∏ó‡∏¢</a></p>\n        <p><a href=\"https://openaitx.github.io/view.html?user=CherryHQ&project=cherry-studio&lang=fr\">Fran√ßais</a></p>\n        <p><a href=\"https://openaitx.github.io/view.html?user=CherryHQ&project=cherry-studio&lang=de\">Deutsch</a></p>\n        <p><a href=\"https://openaitx.github.io/view.html?user=CherryHQ&project=cherry-studio&lang=es\">Espa√±ol</a></p>\n        <p><a href=\"https://openaitx.github.io/view.html?user=CherryHQ&project=cherry-studio&lang=it\">Italiano</a></p>\n        <p><a href=\"https://openaitx.github.io/view.html?user=CherryHQ&project=cherry-studio&lang=ru\">–†—É—Å—Å–∫–∏–π</a></p>\n        <p><a href=\"https://openaitx.github.io/view.html?user=CherryHQ&project=cherry-studio&lang=pt\">Portugu√™s</a></p>\n        <p><a href=\"https://openaitx.github.io/view.html?user=CherryHQ&project=cherry-studio&lang=nl\">Nederlands</a></p>\n        <p><a href=\"https://openaitx.github.io/view.html?user=CherryHQ&project=cherry-studio&lang=pl\">Polski</a></p>\n        <p><a href=\"https://openaitx.github.io/view.html?user=CherryHQ&project=cherry-studio&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a></p>\n        <p><a href=\"https://openaitx.github.io/view.html?user=CherryHQ&project=cherry-studio&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a></p>\n        <p><a href=\"https://openaitx.github.io/view.html?user=CherryHQ&project=cherry-studio&lang=tr\">T√ºrk√ße</a></p>\n        <p><a href=\"https://openaitx.github.io/view.html?user=CherryHQ&project=cherry-studio&lang=vi\">Ti·∫øng Vi·ªát</a></p>\n        <p><a href=\"https://openaitx.github.io/view.html?user=CherryHQ&project=cherry-studio&lang=id\">Bahasa Indonesia</a></p>\n      </div>\n    </div>\n  </details>\n</div>\n\n<h1 align=\"center\">\n  <a href=\"https://github.com/CherryHQ/cherry-studio/releases\">\n    <img src=\"https://github.com/CherryHQ/cherry-studio/blob/main/build/icon.png?raw=true\" width=\"150\" height=\"150\" alt=\"banner\" /><br>\n  </a>\n</h1>\n\n<p align=\"center\">English | <a href=\"./docs/zh/README.md\">‰∏≠Êñá</a> | <a href=\"https://cherry-ai.com\">Official Site</a> | <a href=\"https://docs.cherry-ai.com/docs/en-us\">Documents</a> | <a href=\"./docs/en/guides/development.md\">Development</a> | <a href=\"https://github.com/CherryHQ/cherry-studio/issues\">Feedback</a><br></p>\n\n<div align=\"center\">\n\n[![][deepwiki-shield]][deepwiki-link]\n[![][twitter-shield]][twitter-link]\n[![][discord-shield]][discord-link]\n[![][telegram-shield]][telegram-link]\n\n</div>\n<div align=\"center\">\n\n[![][github-release-shield]][github-release-link]\n[![][github-nightly-shield]][github-nightly-link]\n[![][github-contributors-shield]][github-contributors-link]\n[![][license-shield]][license-link]\n[![][commercial-shield]][commercial-link]\n[![][sponsor-shield]][sponsor-link]\n\n</div>\n\n<div align=\"center\">\n <a href=\"https://hellogithub.com/repository/1605492e1e2a4df3be07abfa4578dd37\" target=\"_blank\" style=\"text-decoration: none\"><img src=\"https://api.hellogithub.com/v1/widgets/recommend.svg?rid=1605492e1e2a4df3be07abfa4578dd37\" alt=\"FeaturedÔΩúHelloGitHub\"  width=\"220\" height=\"55\" /></a>\n <a href=\"https://trendshift.io/repositories/14318\" target=\"_blank\" style=\"text-decoration: none\"><img src=\"https://trendshift.io/api/badge/repositories/14318\" alt=\"CherryHQ%2Fcherry-studio | Trendshift\" width=\"220\" height=\"55\" /></a>\n <a href=\"https://www.producthunt.com/posts/cherry-studio?embed=true&utm_source=badge-featured&utm_medium=badge&utm_souce=badge-cherry&#0045;studio\" target=\"_blank\"><img src=\"https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=496640&theme=light\" alt=\"Cherry&#0032;Studio - AI&#0032;Chatbots&#0044;&#0032;AI&#0032;Desktop&#0032;Client | Product Hunt\" width=\"220\" height=\"55\" /></a>\n</div>\n\n# üçí Cherry Studio\n\nCherry Studio is a desktop client that supports multiple LLM providers, available on Windows, Mac and Linux.\n\nüëè Join [Telegram Group](https://t.me/CherryStudioAI)ÔΩú[Discord](https://discord.gg/wez8HtpxqQ) | [QQ Group(575014769)](https://qm.qq.com/q/lo0D4qVZKi)\n\n‚ù§Ô∏è Like Cherry Studio? Give it a star üåü or [Sponsor](docs/zh/guides/sponsor.md) to support the development!\n\n# üå† Screenshot\n\n![](https://github.com/user-attachments/assets/36dddb2c-e0fb-4a5f-9411-91447bab6e18)\n\n![](https://github.com/user-attachments/assets/f549e8a0-2385-40b4-b52b-2039e39f2930)\n\n![](https://github.com/user-attachments/assets/58e0237c-4d36-40de-b428-53051d982026)\n\n# üåü Key Features\n\n1. **Diverse LLM Provider Support**:\n\n- ‚òÅÔ∏è Major LLM Cloud Services: OpenAI, Gemini, Anthropic, and more\n- üîó AI Web Service Integration: Claude, Perplexity, [Poe](https://poe.com/), and others\n- üíª Local Model Support with Ollama, LM Studio\n\n2. **AI Assistants & Conversations**:\n\n- üìö 300+ Pre-configured AI Assistants\n- ü§ñ Custom Assistant Creation\n- üí¨ Multi-model Simultaneous Conversations\n\n3. **Document & Data Processing**:\n\n- üìÑ Supports Text, Images, Office, PDF, and more\n- ‚òÅÔ∏è WebDAV File Management and Backup\n- üìä Mermaid Chart Visualization\n- üíª Code Syntax Highlighting\n\n4. **Practical Tools Integration**:\n\n- üîç Global Search Functionality\n- üìù Topic Management System\n- üî§ AI-powered Translation\n- üéØ Drag-and-drop Sorting\n- üîå Mini Program Support\n- ‚öôÔ∏è MCP(Model Context Protocol) Server\n\n5. **Enhanced User Experience**:\n\n- üñ•Ô∏è Cross-platform Support for Windows, Mac, and Linux\n- üì¶ Ready to Use - No Environment Setup Required\n- üé® Light/Dark Themes and Transparent Window\n- üìù Complete Markdown Rendering\n- ü§≤ Easy Content Sharing\n\n# üìù Roadmap\n\nWe're actively working on the following features and improvements:\n\n1. üéØ **Core Features**\n\n- Selection Assistant with smart content selection enhancement\n- Deep Research with advanced research capabilities\n- Memory System with global context awareness\n- Document Preprocessing with improved document handling\n- MCP Marketplace for Model Context Protocol ecosystem\n\n2. üóÇ **Knowledge Management**\n\n- Notes and Collections\n- Dynamic Canvas visualization\n- OCR capabilities\n- TTS (Text-to-Speech) support\n\n3. üì± **Platform Support**\n\n- HarmonyOS Edition (PC)\n- Android App (Phase 1)\n- iOS App (Phase 1)\n- Multi-Window support\n- Window Pinning functionality\n- Intel AI PC (Core Ultra) Support\n\n4. üîå **Advanced Features**\n\n- Plugin System\n- ASR (Automatic Speech Recognition)\n- Assistant and Topic Interaction Refactoring\n\nTrack our progress and contribute on our [project board](https://github.com/orgs/CherryHQ/projects/7).\n\nWant to influence our roadmap? Join our [GitHub Discussions](https://github.com/CherryHQ/cherry-studio/discussions) to share your ideas and feedback!\n\n# üåà Theme\n\n- Theme Gallery: <https://cherrycss.com>\n- Aero Theme: <https://github.com/hakadao/CherryStudio-Aero>\n- PaperMaterial Theme: <https://github.com/rainoffallingstar/CherryStudio-PaperMaterial>\n- Claude dynamic-style: <https://github.com/bjl101501/CherryStudio-Claudestyle-dynamic>\n- Maple Neon Theme: <https://github.com/BoningtonChen/CherryStudio_themes>\n\nWelcome PR for more themes\n\n# ü§ù Contributing\n\nWe welcome contributions to Cherry Studio! Here are some ways you can contribute:\n\n1. **Contribute Code**: Develop new features or optimize existing code.\n2. **Fix Bugs**: Submit fixes for any bugs you find.\n3. **Maintain Issues**: Help manage GitHub issues.\n4. **Product Design**: Participate in design discussions.\n5. **Write Documentation**: Improve user manuals and guides.\n6. **Community Engagement**: Join discussions and help users.\n7. **Promote Usage**: Spread the word about Cherry Studio.\n\nRefer to the [Branching Strategy](docs/en/guides/branching-strategy.md) for contribution guidelines\n\n## Getting Started\n\n1. **Fork the Repository**: Fork and clone it to your local machine.\n2. **Create a Branch**: For your changes.\n3. **Submit Changes**: Commit and push your changes.\n4. **Open a Pull Request**: Describe your changes and reasons.\n\nFor more detailed guidelines, please refer to our [Contributing Guide](CONTRIBUTING.md).\n\nThank you for your support and contributions!\n\n# üîß Developer Co-creation Program\n\nWe are launching the Cherry Studio Developer Co-creation Program to foster a healthy and positive-feedback loop within the open-source ecosystem. We believe that great software is built collaboratively, and every merged pull request breathes new life into the project.\n\nWe sincerely invite you to join our ranks of contributors and shape the future of Cherry Studio with us.\n\n## Contributor Rewards Program\n\nTo give back to our core contributors and create a virtuous cycle, we have established the following long-term incentive plan.\n\n**The inaugural tracking period for this program will be Q3 2025 (July, August, September). Rewards for this cycle will be distributed on October 1st.**\n\nWithin any tracking period (e.g., July 1st to September 30th for the first cycle), any developer who contributes more than **30 meaningful commits** to any of Cherry Studio's open-source projects on GitHub will be eligible for the following benefits:\n\n- **Cursor Subscription Sponsorship**: Receive a **$70 USD** credit or reimbursement for your [Cursor](https://cursor.sh/) subscription, making AI your most efficient coding partner.\n- **Unlimited Model Access**: Get **unlimited** API calls for the **DeepSeek** and **Qwen** models.\n- **Cutting-Edge Tech Access**: Enjoy occasional perks, including API access to models like **Claude**, **Gemini**, and **OpenAI**, keeping you at the forefront of technology.\n\n## Growing Together & Future Plans\n\nA vibrant community is the driving force behind any sustainable open-source project. As Cherry Studio grows, so will our rewards program. We are committed to continuously aligning our benefits with the best-in-class tools and resources in the industry. This ensures our core contributors receive meaningful support, creating a positive cycle where developers, the community, and the project grow together.\n\n**Moving forward, the project will also embrace an increasingly open stance to give back to the entire open-source community.**\n\n## How to Get Started?\n\nWe look forward to your first Pull Request!\n\nYou can start by exploring our repositories, picking up a `good first issue`, or proposing your own enhancements. Every commit is a testament to the spirit of open source.\n\nThank you for your interest and contributions.\n\nLet's build together.\n\n# üè¢ Enterprise Edition\n\nBuilding on the Community Edition, we are proud to introduce **Cherry Studio Enterprise Edition**‚Äîa privately-deployable AI productivity and management platform designed for modern teams and enterprises.\n\nThe Enterprise Edition addresses core challenges in team collaboration by centralizing the management of AI resources, knowledge, and data. It empowers organizations to enhance efficiency, foster innovation, and ensure compliance, all while maintaining 100% control over their data in a secure environment.\n\n## Core Advantages\n\n- **Unified Model Management**: Centrally integrate and manage various cloud-based LLMs (e.g., OpenAI, Anthropic, Google Gemini) and locally deployed private models. Employees can use them out-of-the-box without individual configuration.\n- **Enterprise-Grade Knowledge Base**: Build, manage, and share team-wide knowledge bases. Ensures knowledge retention and consistency, enabling team members to interact with AI based on unified and accurate information.\n- **Fine-Grained Access Control**: Easily manage employee accounts and assign role-based permissions for different models, knowledge bases, and features through a unified admin backend.\n- **Fully Private Deployment**: Deploy the entire backend service on your on-premises servers or private cloud, ensuring your data remains 100% private and under your control to meet the strictest security and compliance standards.\n- **Reliable Backend Services**: Provides stable API services and enterprise-grade data backup and recovery mechanisms to ensure business continuity.\n\n## ‚ú® Online Demo\n\n**üîó [Cherry Studio Enterprise](https://www.cherry-ai.com/enterprise)**\n\n## Version Comparison\n\n| Feature           | Community Edition                                                                    | Enterprise Edition                                                                                                                      |\n| :---------------- | :----------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------- |\n| **Open Source**   | ‚úÖ Yes                                                                               | ‚≠ïÔ∏è Partially released to customers                                                                                                      |\n| **Cost**          | [AGPL-3.0 License](https://github.com/CherryHQ/cherry-studio?tab=AGPL-3.0-1-ov-file) | Buyout / Subscription Fee                                                                                                               |\n| **Admin Backend** | ‚Äî                                                                                    | ‚óè Centralized **Model** Access<br>‚óè **Employee** Management<br>‚óè Shared **Knowledge Base**<br>‚óè **Access** Control<br>‚óè **Data** Backup |\n| **Server**        | ‚Äî                                                                                    | ‚úÖ Dedicated Private Deployment                                                                                                         |\n\n## Get the Enterprise Edition\n\nWe believe the Enterprise Edition will become your team's AI productivity engine. If you are interested in Cherry Studio Enterprise Edition and would like to learn more, request a quote, or schedule a demo, please feel free to contact us.\n\n- **For Business Inquiries & Purchasing**:\n  **üìß [bd@cherry-ai.com](mailto:bd@cherry-ai.com)**\n\n# üîó Related Projects\n\n- [new-api](https://github.com/QuantumNous/new-api): The next-generation LLM gateway and AI asset management system supports multiple languages.\n\n- [one-api](https://github.com/songquanpeng/one-api): LLM API management and distribution system supporting mainstream models like OpenAI, Azure, and Anthropic. Features a unified API interface, suitable for key management and secondary distribution.\n\n- [Poe](https://poe.com/): Poe gives you access to the best AI, all in one place. Explore GPT-5, Claude Opus 4.1, DeepSeek-R1, Veo 3, ElevenLabs, and millions of others.\n\n- [ublacklist](https://github.com/iorate/ublacklist): Blocks specific sites from appearing in Google search results\n\n# üöÄ Contributors\n\n<a href=\"https://github.com/CherryHQ/cherry-studio/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=CherryHQ/cherry-studio\" />\n</a>\n<br /><br />\n\n# üìä GitHub Stats\n\n![Stats](https://repobeats.axiom.co/api/embed/a693f2e5f773eed620f70031e974552156c7f397.svg \"Repobeats analytics image\")\n\n# ‚≠êÔ∏è Star History\n\n<a href=\"https://www.star-history.com/#CherryHQ/cherry-studio&Date\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=CherryHQ/cherry-studio&type=Date&theme=dark\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=CherryHQ/cherry-studio&type=Date\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=CherryHQ/cherry-studio&type=Date\" />\n </picture>\n</a>\n\n# üìú License\n\nThe Cherry Studio Community Edition is governed by the standard GNU Affero General Public License v3.0 (AGPL-3.0), available at https://www.gnu.org/licenses/agpl-3.0.html.\n\nUse of the Cherry Studio Community Edition for commercial purposes is permitted, subject to full compliance with the terms and conditions of the AGPL-3.0 license.\n\nShould you require a commercial license that provides an exemption from the AGPL-3.0 requirements, please contact us at bd@cherry-ai.com.\n\n<!-- Links & Images -->\n\n[deepwiki-shield]: https://img.shields.io/badge/Deepwiki-CherryHQ-0088CC?logo=data:image/svg+xml;base64,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\n[deepwiki-link]: https://deepwiki.com/CherryHQ/cherry-studio\n[twitter-shield]: https://img.shields.io/badge/Twitter-CherryStudioApp-0088CC?logo=x\n[twitter-link]: https://twitter.com/CherryStudioHQ\n[discord-shield]: https://img.shields.io/badge/Discord-@CherryStudio-0088CC?logo=discord\n[discord-link]: https://discord.gg/wez8HtpxqQ\n[telegram-shield]: https://img.shields.io/badge/Telegram-@CherryStudioAI-0088CC?logo=telegram\n[telegram-link]: https://t.me/CherryStudioAI\n\n<!-- Links & Images -->\n\n[github-release-shield]: https://img.shields.io/github/v/release/CherryHQ/cherry-studio?logo=github\n[github-release-link]: https://github.com/CherryHQ/cherry-studio/releases\n[github-nightly-shield]: https://img.shields.io/github/actions/workflow/status/CherryHQ/cherry-studio/nightly-build.yml?label=nightly%20build&logo=github\n[github-nightly-link]: https://github.com/CherryHQ/cherry-studio/actions/workflows/nightly-build.yml\n[github-contributors-shield]: https://img.shields.io/github/contributors/CherryHQ/cherry-studio?logo=github\n[github-contributors-link]: https://github.com/CherryHQ/cherry-studio/graphs/contributors\n\n<!-- Links & Images -->\n\n[license-shield]: https://img.shields.io/badge/License-AGPLv3-important.svg?logo=gnu\n[license-link]: https://www.gnu.org/licenses/agpl-3.0\n[commercial-shield]: https://img.shields.io/badge/License-Contact-white.svg?logoColor=white&logo=telegram&color=blue\n[commercial-link]: mailto:license@cherry-ai.com?subject=Commercial%20License%20Inquiry\n[sponsor-shield]: https://img.shields.io/badge/Sponsor-FF6699.svg?logo=githubsponsors&logoColor=white\n[sponsor-link]: https://github.com/CherryHQ/cherry-studio/blob/main/docs/sponsor.md\n",
      "stars_today": 62
    },
    {
      "id": 820087727,
      "name": "onlook",
      "full_name": "onlook-dev/onlook",
      "description": "The Cursor for Designers ‚Ä¢ An Open-Source AI-First Design tool ‚Ä¢ Visually build, style, and edit your React App with AI",
      "html_url": "https://github.com/onlook-dev/onlook",
      "stars": 24098,
      "forks": 1779,
      "language": "TypeScript",
      "topics": [
        "ai",
        "cursor",
        "cursor-ai",
        "design",
        "design-to-code",
        "drizzle",
        "editor",
        "figma",
        "frontend",
        "ide",
        "low-code",
        "nextjs",
        "react",
        "supabase",
        "tailwindcss",
        "typescript",
        "ui",
        "vibe-coding",
        "vibecoding"
      ],
      "created_at": "2024-06-25T19:16:02Z",
      "updated_at": "2026-01-14T01:05:08Z",
      "pushed_at": "2025-12-29T02:49:53Z",
      "open_issues": 350,
      "owner": {
        "login": "onlook-dev",
        "avatar_url": "https://avatars.githubusercontent.com/u/157326433?v=4"
      },
      "readme": "<!-- Improved compatibility of back to top link: See: https://github.com/othneildrew/Best-README-Template/pull/73 -->\n\n<div align=\"center\">\n<img width=\"800\" alt=\"header image\" src=\"assets/web-preview.png\">\n<h3 align=\"center\">Onlook</h3>\n  <p align=\"center\">\n    Cursor for Designers\n    <br />\n    <a href=\"https://docs.onlook.com\"><strong>Explore the docs ¬ª</strong></a>\n    <br />\n  </p>\n  <p align=\"center\">\n    üë®‚Äçüíªüë©‚Äçüíªüë®‚Äçüíª\n    <a href=\"https://www.ycombinator.com/companies/onlook/jobs/e4gHv1n-founding-engineer-fullstack\">We're hiring engineers in SF!</a>\n    üë©‚Äçüíªüë®‚Äçüíªüë©‚Äçüíª\n  </p>\n    <br />\n    <a href=\"https://youtu.be/RSX_3EaO5eU?feature=shared\">View Demo</a>\n    ¬∑\n    <a href=\"https://github.com/onlook-dev/onlook/issues/new?labels=bug&template=bug-report---.md\">Report Bug</a>\n    ¬∑\n    <a href=\"https://github.com/onlook-dev/onlook/issues/new?labels=enhancement&template=feature-request---.md\">Request Feature</a>\n  </p>\n  <!-- PROJECT SHIELDS -->\n<!--\n*** I'm using markdown \"reference style\" links for readability.\n*** Reference links are enclosed in brackets [ ] instead of parentheses ( ).\n*** See the bottom of this document for the declaration of the reference variables\n*** for contributors-url, forks-url, etc. This is an optional, concise syntax you may use.\n*** https://www.markdownguide.org/basic-syntax/#reference-style-links\n-->\n<!-- [![Contributors][contributors-shield]][contributors-url]\n[![Forks][forks-shield]][forks-url]\n[![Stargazers][stars-shield]][stars-url]\n[![Issues][issues-shield]][issues-url]\n[![Apache License][license-shield]][license-url] -->\n\n[![Discord][discord-shield]][discord-url]\n[![LinkedIn][linkedin-shield]][linkedin-url]\n[![Twitter][twitter-shield]][twitter-url]\n\n[‰∏≠Êñá](https://www.readme-i18n.com/onlook-dev/onlook?lang=zh) |\n[Espa√±ol](https://www.readme-i18n.com/onlook-dev/onlook?lang=es) |\n[Deutsch](https://www.readme-i18n.com/onlook-dev/onlook?lang=de) |\n[fran√ßais](https://www.readme-i18n.com/onlook-dev/onlook?lang=fr) |\n[Portugu√™s](https://www.readme-i18n.com/onlook-dev/onlook?lang=pt) |\n[–†—É—Å—Å–∫–∏–π](https://www.readme-i18n.com/onlook-dev/onlook?lang=ru) |\n[Êó•Êú¨Ë™û](https://www.readme-i18n.com/onlook-dev/onlook?lang=ja) |\n[ÌïúÍµ≠Ïñ¥](https://www.readme-i18n.com/onlook-dev/onlook?lang=ko)\n\n</div>\n\n# An Open-Source, Visual-First Code Editor\n\nCraft websites, prototypes, and designs with AI in Next.js + TailwindCSS. Make\nedits directly in the browser DOM with a visual editor. Design in realtime with\ncode. An open-source alternative to Bolt.new, Lovable, V0, Replit Agent, Figma\nMake, Webflow, etc.\n\n### üöß üöß üöß Onlook is still under development üöß üöß üöß\n\nWe're actively looking for contributors to help make Onlook for Web an\nincredible prompt-to-build experience. Check the\n[open issues](https://github.com/onlook-dev/onlook/issues) for a full list of\nproposed features (and known issues), and join our\n[Discord](https://discord.gg/hERDfFZCsH) to collaborate with hundreds of other\nbuilders.\n\n## What you can do with Onlook:\n\n- [x] Create Next.js app in seconds\n  - [x] Start from text or image\n  - [x] Use prebuilt templates\n  - [ ] Import from Figma\n  - [ ] Import from GitHub repo\n  - [ ] Make a PR to a GitHub repo\n- [x] Visually edit your app\n  - [x] Use Figma-like UI\n  - [x] Preview your app in real-time\n  - [x] Manage brand assets and tokens\n  - [x] Create and navigate to Pages\n  - [x] Browse layers\n  - [x] Manage project Images\n  - [x] Detect and use Components ‚Äì _Previously in\n        [Onlook Desktop](https://github.com/onlook-dev/desktop)_\n  - [ ] Drag-and-drop Components Panel\n  - [x] Use Branching to experiment with designs\n- [x] Development Tools\n  - [x] Real-time code editor\n  - [x] Save and restore from checkpoints\n  - [x] Run commands via CLI\n  - [x] Connect with app marketplace\n- [x] Deploy your app in seconds\n  - [x] Generate sharable links\n  - [x] Link your custom domain    \n- [ ] Collaborate with your team\n  - [x] Real-time editing\n  - [ ] Leave comments\n- [ ] Advanced AI capabilities\n  - [x] Queue multiple messages at once\n  - [ ] Use Images as references and as assets in a project\n  - [ ] Setup and use MCPs in projects\n  - [ ] Allow Onlook to use itself as a toolcall for branch creation and iteration\n- [ ] Advanced project support\n  - [ ] Support non-NextJS projects\n  - [ ] Support non-Tailwind projects\n\n![Onlook-GitHub-Example](https://github.com/user-attachments/assets/642de37a-72cc-4056-8eb7-8eb42714cdc4)\n\n## Getting Started\n\nUse our [hosted app](https://onlook.com) or\n[run locally](https://docs.onlook.com/developers/running-locally).\n\n### Usage\n\nOnlook will run on any Next.js + TailwindCSS project, import your project into\nOnlook or start from scratch within the editor.\n\nUse the AI chat to create or edit a project you're working on. At any time, you\ncan always right-click an element to open up the exact location of the element\nin code.\n\n<img width=\"600\" alt=\"image\" src=\"https://github.com/user-attachments/assets/4ad9f411-b172-4430-81ef-650f4f314666\" />\n\n<br>\n\nDraw-in new divs and re-arrange them within their parent containers by\ndragging-and-dropping.\n\n<img width=\"600\" alt=\"image\" src=\"assets/insert-div.png\">\n\n<br>\n\nPreview the code side-by-side with your site design.\n\n<img width=\"600\" alt=\"image\" src=\"assets/code-connect.png\">\n\n<br>\n\nUse Onlook's editor toolbar to adjust Tailwind styles, directly manipulate\nobjects, and experiment with layouts.\n\n<img width=\"600\" alt=\"image\" src=\"assets/text-styling.png\" />\n\n## Documentation\n\nFor full documentation, visit [docs.onlook.com](https://docs.onlook.com)\n\nTo see how to Contribute, visit\n[Contributing to Onlook](https://docs.onlook.com/developers) in our docs.\n\n## How it works\n\n<img width=\"676\" alt=\"architecture\" src=\"assets/architecture.png\">\n\n1. When you create an app, we load the code into a web container\n2. The container runs and serves the code\n3. Our editor receives the preview link and displays it in an iFrame\n4. Our editor reads and indexes the code from the container\n5. We instrument the code in order to map elements to their place in code\n6. When the element is edited, we edit the element in our iFrame, then in code\n7. Our AI chat also has code access and tools to understand and edit the code\n\nThis architecture can theoretically scale to any language or framework that\ndisplays DOM elements declaratively (e.g. jsx/tsx/html). We are focused on\nmaking it work well with Next.js and TailwindCSS for now.\n\nFor a full walkthrough, check out our\n[Architecture Docs](https://docs.onlook.com/developers/architecture).\n\n### Our Tech Stack\n\n#### Front-end\n\n- [Next.js](https://nextjs.org/) - Full stack\n- [TailwindCSS](https://tailwindcss.com/) - Styling\n- [tRPC](https://trpc.io/) - Server interface\n\n#### Database\n\n- [Supabase](https://supabase.com/) - Auth, Database, Storage\n- [Drizzle](https://orm.drizzle.team/) - ORM\n\n#### AI\n\n- [AI SDK](https://ai-sdk.dev/) - LLM client\n- [OpenRouter](https://openrouter.ai/) - LLM model provider\n- [Morph Fast Apply](https://morphllm.com) - Fast apply model provider\n- [Relace](https://relace.ai) - Fast apply model provider\n\n#### Sandbox and hosting\n\n- [CodeSandboxSDK](https://codesandbox.io/docs/sdk) - Dev sandbox\n- [Freestyle](https://www.freestyle.sh/) - Hosting\n\n#### Runtime\n\n- [Bun](https://bun.sh/) - Monorepo, runtime, bundler\n- [Docker](https://www.docker.com/) - Container management\n\n## Contributing\n\n![image](https://github.com/user-attachments/assets/ecc94303-df23-46ae-87dc-66b040396e0b)\n\nIf you have a suggestion that would make this better, please fork the repo and\ncreate a pull request. You can also\n[open issues](https://github.com/onlook-dev/onlook/issues).\n\nSee the [CONTRIBUTING.md](CONTRIBUTING.md) for instructions and code of conduct.\n\n#### Contributors\n\n<a href=\"https://github.com/onlook-dev/onlook/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=onlook-dev/onlook\" />\n</a>\n\n## Contact\n\n![image](https://github.com/user-attachments/assets/60684b68-1925-4550-8efd-51a1509fc953)\n\n- Team: [Discord](https://discord.gg/hERDfFZCsH) -\n  [Twitter](https://twitter.com/onlookdev) -\n  [LinkedIn](https://www.linkedin.com/company/onlook-dev/) -\n  [Email](mailto:contact@onlook.com)\n- Project:\n  [https://github.com/onlook-dev/onlook](https://github.com/onlook-dev/onlook)\n- Website: [https://onlook.com](https://onlook.com)\n\n## License\n\nDistributed under the Apache 2.0 License. See [LICENSE.md](LICENSE.md) for more\ninformation.\n\n<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->\n\n[contributors-shield]: https://img.shields.io/github/contributors/onlook-dev/studio.svg?style=for-the-badge\n[contributors-url]: https://github.com/onlook-dev/onlook/graphs/contributors\n[forks-shield]: https://img.shields.io/github/forks/onlook-dev/studio.svg?style=for-the-badge\n[forks-url]: https://github.com/onlook-dev/onlook/network/members\n[stars-shield]: https://img.shields.io/github/stars/onlook-dev/studio.svg?style=for-the-badge\n[stars-url]: https://github.com/onlook-dev/onlook/stargazers\n[issues-shield]: https://img.shields.io/github/issues/onlook-dev/studio.svg?style=for-the-badge\n[issues-url]: https://github.com/onlook-dev/onlook/issues\n[license-shield]: https://img.shields.io/github/license/onlook-dev/studio.svg?style=for-the-badge\n[license-url]: https://github.com/onlook-dev/onlook/blob/master/LICENSE.txt\n[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?logo=linkedin&colorB=555\n[linkedin-url]: https://www.linkedin.com/company/onlook-dev\n[twitter-shield]: https://img.shields.io/badge/-Twitter-black?logo=x&colorB=555\n[twitter-url]: https://x.com/onlookdev\n[discord-shield]: https://img.shields.io/badge/-Discord-black?logo=discord&colorB=555\n[discord-url]: https://discord.gg/hERDfFZCsH\n[React.js]: https://img.shields.io/badge/react-%2320232a.svg?logo=react&logoColor=%2361DAFB\n[React-url]: https://reactjs.org/\n[TailwindCSS]: https://img.shields.io/badge/tailwindcss-%2338B2AC.svg?logo=tailwind-css&logoColor=white\n[Tailwind-url]: https://tailwindcss.com/\n[Electron.js]: https://img.shields.io/badge/Electron-191970?logo=Electron&logoColor=white\n[Electron-url]: https://www.electronjs.org/\n[Vite.js]: https://img.shields.io/badge/vite-%23646CFF.svg?logo=vite&logoColor=white\n[Vite-url]: https://vitejs.dev/\n[product-screenshot]: assets/brand.png\n[weave-shield]: https://img.shields.io/endpoint?url=https%3A%2F%2Fapp.workweave.ai%2Fapi%2Frepository%2Fbadge%2Forg_pWcXBHJo3Li2Te2Y4WkCPA33%2F820087727&cacheSeconds=3600&labelColor=#131313\n[weave-url]: https://app.workweave.ai/reports/repository/org_pWcXBHJo3Li2Te2Y4WkCPA33/820087727\n",
      "stars_today": 54
    },
    {
      "id": 784181462,
      "name": "Perplexica",
      "full_name": "ItzCrazyKns/Perplexica",
      "description": "Perplexica is an AI-powered answering engine. It is an Open source alternative to Perplexity AI",
      "html_url": "https://github.com/ItzCrazyKns/Perplexica",
      "stars": 28176,
      "forks": 2965,
      "language": "TypeScript",
      "topics": [
        "ai-search-engine",
        "artificial-intelligence",
        "machine-learning",
        "open-source-ai-search-engine",
        "open-source-perplexity-ai",
        "perplexica",
        "perplexity-ai",
        "search-engine",
        "searxng",
        "searxng-copilot"
      ],
      "created_at": "2024-04-09T10:51:32Z",
      "updated_at": "2026-01-14T01:07:27Z",
      "pushed_at": "2026-01-10T17:33:58Z",
      "open_issues": 214,
      "owner": {
        "login": "ItzCrazyKns",
        "avatar_url": "https://avatars.githubusercontent.com/u/95534749?v=4"
      },
      "readme": "# Perplexica üîç\n\n[![GitHub Repo stars](https://img.shields.io/github/stars/ItzCrazyKns/Perplexica?style=social)](https://github.com/ItzCrazyKns/Perplexica/stargazers)\n[![GitHub forks](https://img.shields.io/github/forks/ItzCrazyKns/Perplexica?style=social)](https://github.com/ItzCrazyKns/Perplexica/network/members)\n[![GitHub watchers](https://img.shields.io/github/watchers/ItzCrazyKns/Perplexica?style=social)](https://github.com/ItzCrazyKns/Perplexica/watchers)\n[![Docker Pulls](https://img.shields.io/docker/pulls/itzcrazykns1337/perplexica?color=blue)](https://hub.docker.com/r/itzcrazykns1337/perplexica)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://github.com/ItzCrazyKns/Perplexica/blob/master/LICENSE)\n[![GitHub last commit](https://img.shields.io/github/last-commit/ItzCrazyKns/Perplexica?color=green)](https://github.com/ItzCrazyKns/Perplexica/commits/master)\n[![Discord](https://dcbadge.limes.pink/api/server/26aArMy8tT?style=flat)](https://discord.gg/26aArMy8tT)\n\nPerplexica is a **privacy-focused AI answering engine** that runs entirely on your own hardware. It combines knowledge from the vast internet with support for **local LLMs** (Ollama) and cloud providers (OpenAI, Claude, Groq), delivering accurate answers with **cited sources** while keeping your searches completely private.\n\n![preview](.assets/perplexica-screenshot.png)\n\nWant to know more about its architecture and how it works? You can read it [here](https://github.com/ItzCrazyKns/Perplexica/tree/master/docs/architecture/README.md).\n\n## ‚ú® Features\n\nü§ñ **Support for all major AI providers** - Use local LLMs through Ollama or connect to OpenAI, Anthropic Claude, Google Gemini, Groq, and more. Mix and match models based on your needs.\n\n‚ö° **Smart search modes** - Choose Speed Mode when you need quick answers, Balanced Mode for everyday searches, or Quality Mode for deep research.\n\nüß≠ **Pick your sources** - Search the web, discussions, or academic papers. More sources and integrations are in progress.\n\nüß© **Widgets** - Helpful UI cards that show up when relevant, like weather, calculations, stock prices, and other quick lookups.\n\nüîç **Web search powered by SearxNG** - Access multiple search engines while keeping your identity private. Support for Tavily and Exa coming soon for even better results.\n\nüì∑ **Image and video search** - Find visual content alongside text results. Search isn't limited to just articles anymore.\n\nüìÑ **File uploads** - Upload documents and ask questions about them. PDFs, text files, images - Perplexica understands them all.\n\nüåê **Search specific domains** - Limit your search to specific websites when you know where to look. Perfect for technical documentation or research papers.\n\nüí° **Smart suggestions** - Get intelligent search suggestions as you type, helping you formulate better queries.\n\nüìö **Discover** - Browse interesting articles and trending content throughout the day. Stay informed without even searching.\n\nüïí **Search history** - Every search is saved locally so you can revisit your discoveries anytime. Your research is never lost.\n\n‚ú® **More coming soon** - We're actively developing new features based on community feedback. Join our Discord to help shape Perplexica's future!\n\n## Sponsors\n\nPerplexica's development is powered by the generous support of our sponsors. Their contributions help keep this project free, open-source, and accessible to everyone.\n\n<div align=\"center\">\n  \n  \n<a href=\"https://www.warp.dev/perplexica\">\n  <img alt=\"Warp Terminal\" src=\".assets/sponsers/warp.png\" width=\"100%\">\n</a>\n\n### **‚ú® [Try Warp - The AI-Powered Terminal ‚Üí](https://www.warp.dev/perplexica)**\n\nWarp is revolutionizing development workflows with AI-powered features, modern UX, and blazing-fast performance. Used by developers at top companies worldwide.\n\n</div>\n\n---\n\nWe'd also like to thank the following partners for their generous support:\n\n<table>\n  <tr>\n    <td width=\"100\" align=\"center\">\n      <a href=\"https://dashboard.exa.ai\" target=\"_blank\">\n        <img src=\".assets/sponsers/exa.png\" alt=\"Exa\" width=\"80\" height=\"80\" style=\"border-radius: .75rem;\" />\n      </a>\n    </td>\n    <td>\n      <a href=\"https://dashboard.exa.ai\">Exa</a> ‚Ä¢ The Perfect Web Search API for LLMs - web search, crawling, deep research, and answer APIs\n    </td>\n  </tr>\n</table>\n\n## Installation\n\nThere are mainly 2 ways of installing Perplexica - With Docker, Without Docker. Using Docker is highly recommended.\n\n### Getting Started with Docker (Recommended)\n\nPerplexica can be easily run using Docker. Simply run the following command:\n\n```bash\ndocker run -d -p 3000:3000 -v perplexica-data:/home/perplexica/data --name perplexica itzcrazykns1337/perplexica:latest\n```\n\nThis will pull and start the Perplexica container with the bundled SearxNG search engine. Once running, open your browser and navigate to http://localhost:3000. You can then configure your settings (API keys, models, etc.) directly in the setup screen.\n\n**Note**: The image includes both Perplexica and SearxNG, so no additional setup is required. The `-v` flags create persistent volumes for your data and uploaded files.\n\n#### Using Perplexica with Your Own SearxNG Instance\n\nIf you already have SearxNG running, you can use the slim version of Perplexica:\n\n```bash\ndocker run -d -p 3000:3000 -e SEARXNG_API_URL=http://your-searxng-url:8080 -v perplexica-data:/home/perplexica/data --name perplexica itzcrazykns1337/perplexica:slim-latest\n```\n\n**Important**: Make sure your SearxNG instance has:\n\n- JSON format enabled in the settings\n- Wolfram Alpha search engine enabled\n\nReplace `http://your-searxng-url:8080` with your actual SearxNG URL. Then configure your AI provider settings in the setup screen at http://localhost:3000.\n\n#### Advanced Setup (Building from Source)\n\nIf you prefer to build from source or need more control:\n\n1. Ensure Docker is installed and running on your system.\n2. Clone the Perplexica repository:\n\n   ```bash\n   git clone https://github.com/ItzCrazyKns/Perplexica.git\n   ```\n\n3. After cloning, navigate to the directory containing the project files.\n\n4. Build and run using Docker:\n\n   ```bash\n   docker build -t perplexica .\n   docker run -d -p 3000:3000 -v perplexica-data:/home/perplexica/data --name perplexica perplexica\n   ```\n\n5. Access Perplexica at http://localhost:3000 and configure your settings in the setup screen.\n\n**Note**: After the containers are built, you can start Perplexica directly from Docker without having to open a terminal.\n\n### Non-Docker Installation\n\n1. Install SearXNG and allow `JSON` format in the SearXNG settings. Make sure Wolfram Alpha search engine is also enabled.\n2. Clone the repository:\n\n   ```bash\n   git clone https://github.com/ItzCrazyKns/Perplexica.git\n   cd Perplexica\n   ```\n\n3. Install dependencies:\n\n   ```bash\n   npm i\n   ```\n\n4. Build the application:\n\n   ```bash\n   npm run build\n   ```\n\n5. Start the application:\n\n   ```bash\n   npm run start\n   ```\n\n6. Open your browser and navigate to http://localhost:3000 to complete the setup and configure your settings (API keys, models, SearxNG URL, etc.) in the setup screen.\n\n**Note**: Using Docker is recommended as it simplifies the setup process, especially for managing environment variables and dependencies.\n\nSee the [installation documentation](https://github.com/ItzCrazyKns/Perplexica/tree/master/docs/installation) for more information like updating, etc.\n\n### Troubleshooting\n\n#### Local OpenAI-API-Compliant Servers\n\nIf Perplexica tells you that you haven't configured any chat model providers, ensure that:\n\n1. Your server is running on `0.0.0.0` (not `127.0.0.1`) and on the same port you put in the API URL.\n2. You have specified the correct model name loaded by your local LLM server.\n3. You have specified the correct API key, or if one is not defined, you have put _something_ in the API key field and not left it empty.\n\n#### Ollama Connection Errors\n\nIf you're encountering an Ollama connection error, it is likely due to the backend being unable to connect to Ollama's API. To fix this issue you can:\n\n1. **Check your Ollama API URL:** Ensure that the API URL is correctly set in the settings menu.\n2. **Update API URL Based on OS:**\n\n   - **Windows:** Use `http://host.docker.internal:11434`\n   - **Mac:** Use `http://host.docker.internal:11434`\n   - **Linux:** Use `http://<private_ip_of_host>:11434`\n\n   Adjust the port number if you're using a different one.\n\n3. **Linux Users - Expose Ollama to Network:**\n\n   - Inside `/etc/systemd/system/ollama.service`, you need to add `Environment=\"OLLAMA_HOST=0.0.0.0:11434\"`. (Change the port number if you are using a different one.) Then reload the systemd manager configuration with `systemctl daemon-reload`, and restart Ollama by `systemctl restart ollama`. For more information see [Ollama docs](https://github.com/ollama/ollama/blob/main/docs/faq.md#setting-environment-variables-on-linux)\n\n   - Ensure that the port (default is 11434) is not blocked by your firewall.\n\n#### Lemonade Connection Errors\n\nIf you're encountering a Lemonade connection error, it is likely due to the backend being unable to connect to Lemonade's API. To fix this issue you can:\n\n1. **Check your Lemonade API URL:** Ensure that the API URL is correctly set in the settings menu.\n2. **Update API URL Based on OS:**\n\n   - **Windows:** Use `http://host.docker.internal:8000`\n   - **Mac:** Use `http://host.docker.internal:8000`\n   - **Linux:** Use `http://<private_ip_of_host>:8000`\n\n   Adjust the port number if you're using a different one.\n\n3. **Ensure Lemonade Server is Running:**\n\n   - Make sure your Lemonade server is running and accessible on the configured port (default is 8000).\n   - Verify that Lemonade is configured to accept connections from all interfaces (`0.0.0.0`), not just localhost (`127.0.0.1`).\n   - Ensure that the port (default is 8000) is not blocked by your firewall.\n\n## Using as a Search Engine\n\nIf you wish to use Perplexica as an alternative to traditional search engines like Google or Bing, or if you want to add a shortcut for quick access from your browser's search bar, follow these steps:\n\n1. Open your browser's settings.\n2. Navigate to the 'Search Engines' section.\n3. Add a new site search with the following URL: `http://localhost:3000/?q=%s`. Replace `localhost` with your IP address or domain name, and `3000` with the port number if Perplexica is not hosted locally.\n4. Click the add button. Now, you can use Perplexica directly from your browser's search bar.\n\n## Using Perplexica's API\n\nPerplexica also provides an API for developers looking to integrate its powerful search engine into their own applications. You can run searches, use multiple models and get answers to your queries.\n\nFor more details, check out the full documentation [here](https://github.com/ItzCrazyKns/Perplexica/tree/master/docs/API/SEARCH.md).\n\n## Expose Perplexica to network\n\nPerplexica runs on Next.js and handles all API requests. It works right away on the same network and stays accessible even with port forwarding.\n\n## One-Click Deployment\n\n[![Deploy to Sealos](https://raw.githubusercontent.com/labring-actions/templates/main/Deploy-on-Sealos.svg)](https://usw.sealos.io/?openapp=system-template%3FtemplateName%3Dperplexica)\n[![Deploy to RepoCloud](https://d16t0pc4846x52.cloudfront.net/deploylobe.svg)](https://repocloud.io/details/?app_id=267)\n[![Run on ClawCloud](https://raw.githubusercontent.com/ClawCloud/Run-Template/refs/heads/main/Run-on-ClawCloud.svg)](https://template.run.claw.cloud/?referralCode=U11MRQ8U9RM4&openapp=system-fastdeploy%3FtemplateName%3Dperplexica)\n[![Deploy on Hostinger](https://assets.hostinger.com/vps/deploy.svg)](https://www.hostinger.com/vps/docker-hosting?compose_url=https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/refs/heads/master/docker-compose.yaml)\n\n## Upcoming Features\n\n- [ ] Adding more widgets, integrations, search sources\n- [ ] Adding ability to create custom agents (name T.B.D.)\n- [ ] Adding authentication\n\n## Support Us\n\nIf you find Perplexica useful, consider giving us a star on GitHub. This helps more people discover Perplexica and supports the development of new features. Your support is greatly appreciated.\n\n### Donations\n\nWe also accept donations to help sustain our project. If you would like to contribute, you can use the following options to donate. Thank you for your support!\n\n| Ethereum                                              |\n| ----------------------------------------------------- |\n| Address: `0xB025a84b2F269570Eb8D4b05DEdaA41D8525B6DD` |\n\n## Contribution\n\nPerplexica is built on the idea that AI and large language models should be easy for everyone to use. If you find bugs or have ideas, please share them in via GitHub Issues. For more information on contributing to Perplexica you can read the [CONTRIBUTING.md](CONTRIBUTING.md) file to learn more about Perplexica and how you can contribute to it.\n\n## Help and Support\n\nIf you have any questions or feedback, please feel free to reach out to us. You can create an issue on GitHub or join our Discord server. There, you can connect with other users, share your experiences and reviews, and receive more personalized help. [Click here](https://discord.gg/EFwsmQDgAu) to join the Discord server. To discuss matters outside of regular support, feel free to contact me on Discord at `itzcrazykns`.\n\nThank you for exploring Perplexica, the AI-powered search engine designed to enhance your search experience. We are constantly working to improve Perplexica and expand its capabilities. We value your feedback and contributions which help us make Perplexica even better. Don't forget to check back for updates and new features!\n",
      "stars_today": 51
    },
    {
      "id": 167694194,
      "name": "frigate",
      "full_name": "blakeblackshear/frigate",
      "description": "NVR with realtime local object detection for IP cameras",
      "html_url": "https://github.com/blakeblackshear/frigate",
      "stars": 28960,
      "forks": 2706,
      "language": "TypeScript",
      "topics": [
        "ai",
        "camera",
        "google-coral",
        "home-assistant",
        "home-automation",
        "homeautomation",
        "mqtt",
        "nvr",
        "object-detection",
        "realtime",
        "rtsp",
        "tensorflow"
      ],
      "created_at": "2019-01-26T13:52:38Z",
      "updated_at": "2026-01-14T01:06:56Z",
      "pushed_at": "2026-01-13T20:57:00Z",
      "open_issues": 150,
      "owner": {
        "login": "blakeblackshear",
        "avatar_url": "https://avatars.githubusercontent.com/u/569905?v=4"
      },
      "readme": "<p align=\"center\">\n  <img align=\"center\" alt=\"logo\" src=\"docs/static/img/branding/frigate.png\">\n</p>\n\n# Frigate NVR‚Ñ¢ - Realtime Object Detection for IP Cameras\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n<a href=\"https://hosted.weblate.org/engage/frigate-nvr/\">\n<img src=\"https://hosted.weblate.org/widget/frigate-nvr/language-badge.svg\" alt=\"Translation status\" />\n</a>\n\n\\[English\\] | [ÁÆÄ‰Ωì‰∏≠Êñá](https://github.com/blakeblackshear/frigate/blob/dev/README_CN.md)\n\nA complete and local NVR designed for [Home Assistant](https://www.home-assistant.io) with AI object detection. Uses OpenCV and Tensorflow to perform realtime object detection locally for IP cameras.\n\nUse of a GPU or AI accelerator is highly recommended. AI accelerators will outperform even the best CPUs with very little overhead. See Frigate's supported [object detectors](https://docs.frigate.video/configuration/object_detectors/).\n\n- Tight integration with Home Assistant via a [custom component](https://github.com/blakeblackshear/frigate-hass-integration)\n- Designed to minimize resource use and maximize performance by only looking for objects when and where it is necessary\n- Leverages multiprocessing heavily with an emphasis on realtime over processing every frame\n- Uses a very low overhead motion detection to determine where to run object detection\n- Object detection with TensorFlow runs in separate processes for maximum FPS\n- Communicates over MQTT for easy integration into other systems\n- Records video with retention settings based on detected objects\n- 24/7 recording\n- Re-streaming via RTSP to reduce the number of connections to your camera\n- WebRTC & MSE support for low-latency live view\n\n## Documentation\n\nView the documentation at https://docs.frigate.video\n\n## Donations\n\nIf you would like to make a donation to support development, please use [Github Sponsors](https://github.com/sponsors/blakeblackshear).\n\n## License\n\nThis project is licensed under the **MIT License**.\n\n- **Code:** The source code, configuration files, and documentation in this repository are available under the [MIT License](LICENSE). You are free to use, modify, and distribute the code as long as you include the original copyright notice.\n- **Trademarks:** The \"Frigate\" name, the \"Frigate NVR\" brand, and the Frigate logo are **trademarks of Frigate, Inc.** and are **not** covered by the MIT License.\n\nPlease see our [Trademark Policy](TRADEMARK.md) for details on acceptable use of our brand assets.\n\n## Screenshots\n\n### Live dashboard\n\n<div>\n<img width=\"800\" alt=\"Live dashboard\" src=\"https://github.com/blakeblackshear/frigate/assets/569905/5e713cb9-9db5-41dc-947a-6937c3bc376e\">\n</div>\n\n### Streamlined review workflow\n\n<div>\n<img width=\"800\" alt=\"Streamlined review workflow\" src=\"https://github.com/blakeblackshear/frigate/assets/569905/6fed96e8-3b18-40e5-9ddc-31e6f3c9f2ff\">\n</div>\n\n### Multi-camera scrubbing\n\n<div>\n<img width=\"800\" alt=\"Multi-camera scrubbing\" src=\"https://github.com/blakeblackshear/frigate/assets/569905/d6788a15-0eeb-4427-a8d4-80b93cae3d74\">\n</div>\n\n### Built-in mask and zone editor\n\n<div>\n<img width=\"800\" alt=\"Built-in mask and zone editor\" src=\"https://github.com/blakeblackshear/frigate/assets/569905/d7885fc3-bfe6-452f-b7d0-d957cb3e31f5\">\n</div>\n\n## Translations\n\nWe use [Weblate](https://hosted.weblate.org/projects/frigate-nvr/) to support language translations. Contributions are always welcome.\n\n<a href=\"https://hosted.weblate.org/engage/frigate-nvr/\">\n<img src=\"https://hosted.weblate.org/widget/frigate-nvr/multi-auto.svg\" alt=\"Translation status\" />\n</a>\n\n---\n\n**Copyright ¬© 2026 Frigate, Inc.**\n",
      "stars_today": 51
    },
    {
      "id": 566931318,
      "name": "live",
      "full_name": "fanmingming/live",
      "description": "‚úØ ÂèØÁõ¥ËøûËÆøÈóÆÁöÑÁîµËßÜ/ÂπøÊí≠ÂõæÊ†áÂ∫ì‰∏éÁõ∏ÂÖ≥Â∑•ÂÖ∑È°πÁõÆ ‚úØ üîï Ê∞∏‰πÖÂÖçË¥π Áõ¥ËøûËÆøÈóÆ ÂÆåÊï¥ÂºÄÊ∫ê ‰∏çÊñ≠ÂÆåÂñÑÁöÑÂè∞Ê†á ÊîØÊåÅIPv4/IPv6ÂèåÊ†àËÆøÈóÆ üîï",
      "html_url": "https://github.com/fanmingming/live",
      "stars": 27266,
      "forks": 4131,
      "language": "JavaScript",
      "topics": [
        "china",
        "converter",
        "epg",
        "iptv",
        "ipv6",
        "live",
        "m3u",
        "m3u8",
        "mp4",
        "radio",
        "television",
        "tv",
        "txt",
        "workers"
      ],
      "created_at": "2022-11-16T18:03:31Z",
      "updated_at": "2026-01-14T00:50:47Z",
      "pushed_at": "2026-01-14T00:43:34Z",
      "open_issues": 28,
      "owner": {
        "login": "fanmingming",
        "avatar_url": "https://avatars.githubusercontent.com/u/4993993?v=4"
      },
      "readme": "<p align=\"center\"><img alt=\"live.fanmingming.com\" src=\"https://live.fanmingming.com/logo.png\"></p>\n<h1 align=\"center\"> ‚úØ ‰∏Ä‰∏™ÂèØÁõ¥ËøûËÆøÈóÆÁöÑÁîµËßÜ/ÂπøÊí≠ÂõæÊ†áÂ∫ì‰∏éÁõ∏ÂÖ≥Â∑•ÂÖ∑È°πÁõÆ ‚úØ </h1>\n<h3 align=\"center\">üîï Ê∞∏‰πÖÂÖçË¥π Áõ¥ËøûËÆøÈóÆ ÂÆåÊï¥ÂºÄÊ∫ê ‰∏çÊñ≠ÂÆåÂñÑÁöÑÂè∞Ê†á ÊîØÊåÅIPv4/IPv6ÂèåÊ†àËÆøÈóÆ üîï</h3>\n\n<p align=\"center\">\n<img alt=\"GitHub Repo stars\" src=\"https://img.shields.io/github/stars/fanmingming/live?style=flat-square\">\n<img alt=\"GitHub forks\" src=\"https://img.shields.io/github/forks/fanmingming/live?style=flat-square\">\n<img alt=\"GitHub issues\" src=\"https://img.shields.io/github/issues/fanmingming/live?style=flat-square\">\n<img alt=\"GitHub watchers\" src=\"https://img.shields.io/github/watchers/fanmingming/live?style=flat-square\">\n<img alt=\"GitHub contributors\" src=\"https://img.shields.io/github/contributors/fanmingming/live?style=flat-square\">\n<img alt=\"GitHub\" src=\"https://img.shields.io/github/license/fanmingming/live?style=flat-square\">\n</p>\n\n---\n\n## ü§π‚Äç‚ôÇÔ∏è‰ΩøÁî®ÊñπÊ≥ï:\n\n### üåáÁîµËßÜ/ÂπøÊí≠ÂõæÊ†áÂ∫ìÔºö\n\n| Á±ª Âà´  | Ë∞ÉÁî®Ë∑ØÂæÑ                                       | ÊúÄÂêéÊõ¥Êñ∞   |\n|-------|------------------------------------------------|------------|\n| üì∫ÁîµËßÜ  | [https://live.fanmingming.cn/tv/{name}.png](https://github.com/fanmingming/live/tree/main/tv) | 2025.04.01    |\n| üìªÂπøÊí≠  | [https://live.fanmingming.cn/radio/{name}.png](https://github.com/fanmingming/live/tree/main/radio) | 2024.8.29   |\n\n### ‚õìÔ∏èÂàõÂª∫ÊÇ®ÁöÑm3uËÆ¢ÈòÖÈìæÊé•Ôºö\n - ‰∏ãËΩΩ `demo.m3u` Á©∫ÁôΩÁ§∫‰æãÊñá‰ª∂Âπ∂‰ΩøÁî®ÊñáÊú¨ÁºñËæëËΩØ‰ª∂ÊâìÂºÄ„ÄÇ\n   - [https://live.fanmingming.cn/tv/m3u/demo.m3u](https://live.fanmingming.cn/tv/m3u/demo.m3u)\n\n - ÂèÇËÄÉ‰∏ãÊñπÁ§∫‰æã‰ª£Á†ÅÂ∞Ü`ÂèØÁî®ÁöÑCCTV1ËäÇÁõÆÊ∫ê`ÊõøÊç¢‰∏∫ÊÇ®ÂΩìÂú∞ÂèØÁî®ÁöÑÁõ¥Êí≠Ê∫êÈìæÊé•Ôºå‰æùÊ≠§Á±ªÊé®ÈÄê‰∏™ÊõøÊç¢„ÄÇ\n\n```\n#EXTM3U x-tvg-url=\"https://live.fanmingming.cn/e.xml\"\n#EXTINF:-1 tvg-name=\"CCTV1\" tvg-logo=\"https://live.fanmingming.cn/tv/CCTV1.png\" group-title=\"Â§ÆËßÜ\",CCTV-1 ÁªºÂêà\nÂèØÁî®ÁöÑCCTV1ËäÇÁõÆÊ∫ê\nÊ≠§Â§ÑÁúÅÁï•...\n```\n\n - Â∞ÜÁºñËæëÂÆåÊàêÁöÑm3uÊñá‰ª∂‰∏ä‰º†Âà∞ÊÇ®ÁöÑGithub‰ªìÂ∫ì„ÄÇ\n - ‰∏∫ÊÇ®ÁöÑGithub‰ªìÂ∫ìÂºÄÂêØPages„ÄÇ\n - ÈÄöËøáÊí≠ÊîæÂô®ËÆ¢ÈòÖÊÇ®ÁöÑm3uÈìæÊé•„ÄÇ\n\n> ÂÖ≥‰∫éGithub PagesÔºö[https://docs.github.com/en/enterprise-cloud@latest/pages/quickstart](https://docs.github.com/en/enterprise-cloud@latest/pages/quickstart)\n\n## üõ†Ô∏èÂ∑•ÂÖ∑\n- üìÜ**EPGÊé•Âè£Âú∞ÂùÄ**Ôºö\n  -  [https://live.fanmingming.cn/e.xml](https://live.fanmingming.cn/e.xml)\n- üèûÔ∏è**BingÊØèÊó•ÂõæÁâá**Ôºö\n  -  [https://fanmingming.com/bing](https://fanmingming.com/bing)\n- üéûÔ∏è**m3u8Âú®Á∫ø‰∏ãËΩΩ**Ôºö\n  -  [https://live.fanmingming.cn/m3u8](https://live.fanmingming.cn/m3u8)\n- üÜï**TXTËΩ¨M3UÊ†ºÂºè**Ôºö\n  - [https://live.fanmingming.cn/txt2m3u](https://live.fanmingming.cn/txt2m3u)\n- üìÑ**Âú®Á∫øM3UËΩ¨TXT**Ôºö\n  - Demoüîó [https://fanmingming.com/txt?url=https://live.fanmingming.com/tv/m3u/ipv6.m3u](https://fanmingming.com/txt?url=https://live.fanmingming.cn/tv/m3u/ipv6.m3u)\n- üåê**M3U8 Web Player**:\n  - Demoüîó [https://live.fanmingming.cn/player/?vurl=https://0472.org/hls/cgtn.m3u8](https://live.fanmingming.cn/player/?vurl=https://0472.org/hls/cgtn.m3u8)\n\n## üìñËØ¥Êòé\n- È°πÁõÆEPGÊé•Âè£‰∏∫112114.xyzÁ´ôÁÇπÂàÜÂèëÔºåÊú¨È°πÁõÆÊó†Ê≥ïÁ°Æ‰øùÂÖ∂ÂáÜÁ°ÆÊÄß„ÄÇ\n- ÈÄöËøáM3U8 Web PlayerÊµãËØïÁõ¥Êí≠Ê∫êÈúÄ‰ΩøÁî®httpsÂçèËÆÆÁöÑÁõ¥Êí≠Ê∫êÈìæÊé•„ÄÇ\n- Âú®Á∫øM3UËΩ¨TXTÂ∑•ÂÖ∑ÊûÑÂª∫Âú®VercelÔºå‰∏ç‰ºöËÆ∞ÂΩïÊÇ®ÁöÑËÆøÈóÆÊó•ÂøóËØ∑ÊîæÂøÉ‰ΩøÁî®„ÄÇ\n- TXTËΩ¨M3UÂ∑•ÂÖ∑‰∏∫ÂâçÁ´ØÁΩëÈ°µËΩ¨Êç¢ÔºåÊó†ÈúÄ‰∏ä‰º†Êñá‰ª∂ÔºåÁ≤òË¥¥Âç≥ËΩ¨Êç¢ÔºåÂÆâÂÖ®‰∏çÂÅ∑Ê∫ê„ÄÇ\n- Êú¨È°πÁõÆ‰∏çÂ≠òÂÇ®‰ªª‰ΩïÁöÑÊµÅÂ™í‰ΩìÂÜÖÂÆπÔºåÊâÄÊúâÁöÑÊ≥ïÂæãË¥£‰ªª‰∏éÂêéÊûúÂ∫îÁî±‰ΩøÁî®ËÄÖËá™Ë°åÊâøÊãÖ„ÄÇ\n- È°πÁõÆ`/tv/m3u/`Âíå`/radio/m3u/`ÁõÆÂΩï‰∏ãÁöÑÂÜÖÂÆπÊî∂ÈõÜ‰∫é‰∫íËÅîÁΩëÔºå‰ªÖ‰æõÊµãËØïÁ†îÁ©∂‰ΩøÁî®ÔºåÊú¨È°πÁõÆÊó†Ê≥ï‰øùËØÅÂÖ∂ÊúâÊïàÊÄß„ÄÇ\n- ‰∏ªÂüüÂêç„Äê`live.fanmingming.com`„ÄëÁöÑWEBËÆøÈóÆÈÄöËøáGithub PagesËá™Âä®ÊûÑÂª∫ÔºåÁî±CloudFlareÊèê‰æõCDNÂíåÂÆâÂÖ®Èò≤Êä§„ÄÇ\n- ÈïúÂÉèÂüüÂêç„Äê`live.fanmingming.cn`„ÄëÊèê‰æõÂÆåÊï¥ÁöÑËµÑÊ∫êWEBËÆøÈóÆÔºåÈÄöËøáGithub ActionsËá™Âä®ÊûÑÂª∫Âú®CloudFlare Pages„ÄÇ\n- È°πÁõÆÊâÄÊúâÊñá‰ª∂ÂùáÊâòÁÆ°Âú®[GitHub](https://github.com/fanmingming/live)‰∏îËá™Âä®ÊûÑÂª∫ÔºåÁî±È°πÁõÆÂèëËµ∑‰∫∫ÂÖ¨ÁõäÁª¥Êä§ÔºåÊ¨¢ËøéStarÊú¨È°πÁõÆÊàñÁÇπÂáª[Issues](https://github.com/fanmingming/live/issues/new/choose)ÂèçÈ¶àÊÇ®ÁöÑÈóÆÈ¢ò„ÄÇ\n- ÊÇ®ÂèØ‰ª•FrokÊú¨È°πÁõÆÂà∞ÊÇ®ÁöÑGithubË¥¶Êà∑ÔºåÂ∞ÜÁº∫Â§±ÁöÑÈ¢ëÈÅìLogo‰∏ä‰º†Âà∞`tv`Êàñ`radio`ÁõÆÂΩï‰∏ãÂπ∂ÂèëËµ∑ÊãâÂèñËØ∑Ê±ÇÔºåÊî∂Âà∞ËØ∑Ê±ÇÂêéÊàë‰ª¨‰ºöÂØπÊÇ®Êèê‰∫§ÁöÑÂÜÖÂÆπËøõË°åÈ™åËØÅÔºåÂÆ°Ê†∏ÈÄöËøáÂêé‰ºöËá™Âä®‰∏∫ÊÇ®ÁΩ≤ÂêçÂπ∂ÂèëÂ∏É„ÄÇ\n\n## üì±ËÅîÁ≥ª\n- Telegram: [@AirfoneBot](https://t.me/AirfoneBot)\n  - Â¶ÇÈÅáËµÑÊ∫êËÆøÈóÆÈóÆÈ¢òËØ∑ÈÄöËøáTelegramÂèçÈ¶à„ÄÇ\n\n## üìîÊõ¥Êñ∞\n- 2025.04.01\n  - Êñ∞Â¢ûÂåó‰∫¨Âç´ËßÜ4KÂè∞Ê†á„ÄÇ\n",
      "stars_today": 48
    },
    {
      "id": 1015044525,
      "name": "VictoriaLogs",
      "full_name": "VictoriaMetrics/VictoriaLogs",
      "description": "Fast and easy to use database for logs, which can efficiently handle terabytes of logs",
      "html_url": "https://github.com/VictoriaMetrics/VictoriaLogs",
      "stars": 1165,
      "forks": 79,
      "language": "Go",
      "topics": [
        "elasticsearch",
        "grafana",
        "kubernetes",
        "logs",
        "loki",
        "observability",
        "opentelemetry",
        "siem"
      ],
      "created_at": "2025-07-06T22:56:52Z",
      "updated_at": "2026-01-13T23:56:20Z",
      "pushed_at": "2026-01-13T16:11:54Z",
      "open_issues": 160,
      "owner": {
        "login": "VictoriaMetrics",
        "avatar_url": "https://avatars.githubusercontent.com/u/43720803?v=4"
      },
      "readme": "# VictoriaLogs\n\n[![Latest Release](https://img.shields.io/github/v/release/VictoriaMetrics/VictoriaLogs?sort=semver&label=&logo=github&labelColor=gray&color=gray&link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaLogs%2Freleases%2Flatest)](https://github.com/VictoriaMetrics/VictoriaLogs/releases)\n![Docker Pulls](https://img.shields.io/docker/pulls/victoriametrics/victoria-logs?label=&logo=docker&logoColor=white&labelColor=2496ED&color=2496ED&link=https%3A%2F%2Fhub.docker.com%2Fr%2Fvictoriametrics%2Fvictoria-logs)\n[![Go Report](https://goreportcard.com/badge/github.com/VictoriaMetrics/VictoriaLogs?link=https%3A%2F%2Fgoreportcard.com%2Freport%2Fgithub.com%2FVictoriaMetrics%2FVictoriaLogs)](https://goreportcard.com/report/github.com/VictoriaMetrics/VictoriaLogs)\n[![Build Status](https://github.com/VictoriaMetrics/VictoriaLogs/actions/workflows/main.yml/badge.svg?branch=master&link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaLogs%2Factions)](https://github.com/VictoriaMetrics/VictoriaLogs/actions/workflows/main.yml)\n[![codecov](https://codecov.io/gh/VictoriaMetrics/VictoriaLogs/branch/master/graph/badge.svg?link=https%3A%2F%2Fcodecov.io%2Fgh%2FVictoriaMetrics%2FVictoriaLogs)](https://app.codecov.io/gh/VictoriaMetrics/VictoriaLogs)\n[![License](https://img.shields.io/github/license/VictoriaMetrics/VictoriaLogs?labelColor=green&label=&link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaLogs%2Fblob%2Fmaster%2FLICENSE)](https://github.com/VictoriaMetrics/VictoriaLogs/blob/master/LICENSE)\n![Slack](https://img.shields.io/badge/Join-4A154B?logo=slack&link=https%3A%2F%2Fslack.victoriametrics.com)\n[![X](https://img.shields.io/twitter/follow/VictoriaMetrics?style=flat&label=Follow&color=black&logo=x&labelColor=black&link=https%3A%2F%2Fx.com%2FVictoriaMetrics)](https://x.com/VictoriaMetrics/)\n[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/VictoriaMetrics?style=flat&label=Join&labelColor=red&logoColor=white&logo=reddit&link=https%3A%2F%2Fwww.reddit.com%2Fr%2FVictoriaMetrics)](https://www.reddit.com/r/VictoriaMetrics/)\n\nVictoriaLogs is a fast easy to use database for logs.\n\nHere are some resources and information about VictoriaLogs:\n\n- Playgrounds: [playground for the built-in web UI](https://play-vmlogs.victoriametrics.com/), [playground for Grafana plugin for VictoriaLogs](https://play-grafana.victoriametrics.com/d/be5zidev72m80f/k8s-logs-via-victorialogs)\n- [Documentation](https://docs.victoriametrics.com/victorialogs/)\n- Available: [Binary releases](https://github.com/VictoriaMetrics/VictoriaLogs/releases/latest), docker images [Docker Hub](https://hub.docker.com/r/victoriametrics/victoria-logs/) and [Quay](https://quay.io/repository/victoriametrics/victoria-logs), [Source code](https://github.com/VictoriaMetrics/VictoriaLogs)\n- Deployment types: [Single-node version](https://docs.victoriametrics.com/victorialogs/), [Cluster version](https://docs.victoriametrics.com/victorialogs/cluster/)\n- Changelog: [CHANGELOG](https://docs.victoriametrics.com/victorialogs/changelog/), and [How to upgrade](https://docs.victoriametrics.com/victorialogs/#upgrading)\n- Community: [Slack](https://slack.victoriametrics.com/), [X (Twitter)](https://x.com/VictoriaMetrics), [LinkedIn](https://www.linkedin.com/company/victoriametrics/), [YouTube](https://www.youtube.com/@VictoriaMetrics)\n\nBoth the single-node and the cluster versions of VictoriaLogs are open source and free to use.\n\n## Community and contributions\n\nFeel free asking any questions regarding VictoriaLogs:\n\n* [Slack Inviter](https://slack.victoriametrics.com/) and [Slack channel](https://victoriametrics.slack.com/)\n* [X (Twitter)](https://x.com/VictoriaMetrics/)\n* [Linkedin](https://www.linkedin.com/company/victoriametrics/)\n* [Reddit](https://www.reddit.com/r/VictoriaMetrics/)\n* [Telegram-en](https://t.me/VictoriaMetrics_en)\n* [Telegram-ru](https://t.me/VictoriaLogs_ru)\n* [Mastodon](https://mastodon.social/@victoriametrics/)\n\nIf you like VictoriaLogs and want to contribute, then please [read these docs](https://docs.victoriametrics.com/victoriametrics/contributing/).\n\nThank you for your cooperation!\n",
      "stars_today": 47
    },
    {
      "id": 825470378,
      "name": "beszel",
      "full_name": "henrygd/beszel",
      "description": "Lightweight server monitoring hub with historical data, docker stats, and alerts.",
      "html_url": "https://github.com/henrygd/beszel",
      "stars": 18602,
      "forks": 593,
      "language": "Go",
      "topics": [
        "homelab",
        "monitoring",
        "self-hosted"
      ],
      "created_at": "2024-07-07T21:36:28Z",
      "updated_at": "2026-01-14T00:52:55Z",
      "pushed_at": "2026-01-13T22:24:57Z",
      "open_issues": 385,
      "owner": {
        "login": "henrygd",
        "avatar_url": "https://avatars.githubusercontent.com/u/8519632?v=4"
      },
      "readme": "# Beszel\n\nBeszel is a lightweight server monitoring platform that includes Docker statistics, historical data, and alert functions.\n\nIt has a friendly web interface, simple configuration, and is ready to use out of the box. It supports automatic backup, multi-user, OAuth authentication, and API access.\n\n[![agent Docker Image Size](https://img.shields.io/docker/image-size/henrygd/beszel-agent/latest?logo=docker&label=agent%20image%20size)](https://hub.docker.com/r/henrygd/beszel-agent)\n[![hub Docker Image Size](https://img.shields.io/docker/image-size/henrygd/beszel/latest?logo=docker&label=hub%20image%20size)](https://hub.docker.com/r/henrygd/beszel)\n[![MIT license](https://img.shields.io/github/license/henrygd/beszel?color=%239944ee)](https://github.com/henrygd/beszel/blob/main/LICENSE)\n[![Crowdin](https://badges.crowdin.net/beszel/localized.svg)](https://crowdin.com/project/beszel)\n\n![Screenshot of Beszel dashboard and system page, side by side. The dashboard shows metrics from multiple connected systems, while the system page shows detailed metrics for a single system.](https://henrygd-assets.b-cdn.net/beszel/screenshot-new.png)\n\n## Features\n\n- **Lightweight**: Smaller and less resource-intensive than leading solutions.\n- **Simple**: Easy setup with little manual configuration required.\n- **Docker stats**: Tracks CPU, memory, and network usage history for each container.\n- **Alerts**: Configurable alerts for CPU, memory, disk, bandwidth, temperature, load average, and status.\n- **Multi-user**: Users manage their own systems. Admins can share systems across users.\n- **OAuth / OIDC**: Supports many OAuth2 providers. Password auth can be disabled.\n- **Automatic backups**: Save to and restore from disk or S3-compatible storage.\n<!-- - **REST API**: Use or update your data in your own scripts and applications. -->\n\n## Architecture\n\nBeszel consists of two main components: the **hub** and the **agent**.\n\n- **Hub**: A web application built on [PocketBase](https://pocketbase.io/) that provides a dashboard for viewing and managing connected systems.\n- **Agent**: Runs on each system you want to monitor and communicates system metrics to the hub.\n\n## Getting started\n\nThe [quick start guide](https://beszel.dev/guide/getting-started) and other documentation is available on our website, [beszel.dev](https://beszel.dev). You'll be up and running in a few minutes.\n\n## Screenshots\n\n![Dashboard](https://beszel.dev/image/dashboard.png)\n![System page](https://beszel.dev/image/system-full.png)\n![Notification Settings](https://beszel.dev/image/settings-notifications.png)\n\n## Supported metrics\n\n- **CPU usage** - Host system and Docker / Podman containers.\n- **Memory usage** - Host system and containers. Includes swap and ZFS ARC.\n- **Disk usage** - Host system. Supports multiple partitions and devices.\n- **Disk I/O** - Host system. Supports multiple partitions and devices.\n- **Network usage** - Host system and containers.\n- **Load average** - Host system.\n- **Temperature** - Host system sensors.\n- **GPU usage / power draw** - Nvidia, AMD, and Intel.\n- **Battery** - Host system battery charge.\n- **Containers** - Status and metrics of all running Docker / Podman containers.\n- **S.M.A.R.T.** - Host system disk health.\n\n## Help and discussion\n\nPlease search existing issues and discussions before opening a new one. I try my best to respond, but may not always have time to do so.\n\n#### Bug reports and feature requests\n\nBug reports and feature requests can be posted on [GitHub issues](https://github.com/henrygd/beszel/issues).\n\n#### Support and general discussion\n\nSupport requests and general discussion can be posted on [GitHub discussions](https://github.com/henrygd/beszel/discussions) or the community-run [Matrix room](https://matrix.to/#/#beszel:matrix.org): `#beszel:matrix.org`.\n\n## License\n\nBeszel is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.\n",
      "stars_today": 38
    },
    {
      "id": 914002768,
      "name": "drawy",
      "full_name": "Prayag2/drawy",
      "description": "Your handy, infinite, brainstorming tool! The project has now moved to KDE Invent.",
      "html_url": "https://github.com/Prayag2/drawy",
      "stars": 861,
      "forks": 25,
      "language": "C++",
      "topics": [
        "drawing",
        "whiteboard"
      ],
      "created_at": "2025-01-08T18:59:32Z",
      "updated_at": "2026-01-14T00:21:02Z",
      "pushed_at": "2025-12-25T08:31:44Z",
      "open_issues": 29,
      "owner": {
        "login": "Prayag2",
        "avatar_url": "https://avatars.githubusercontent.com/u/39525869?v=4"
      },
      "readme": "> [!NOTE]\n> Drawy has moved to KDE Invent. This repository is kept only to track and resolve existing issues. Please open all new issues and pull requests on KDE Invent instead.\n>   \n> https://invent.kde.org/prayag/drawy\n\n  \n<p align=\"center\">\n  <img src=\"assets/logo-256.png\" width=100/>\n  <h1 align=\"center\">Drawy</h1>\n  <p align=\"center\">Your handy, infinite, brainstorming tool!</center>\n</p>\n\n<p align=\"center\">\n<a href=\"https://github.com/prayag2/drawy/stargazers\"><img alt=\"GitHub Stars\" src=\"https://img.shields.io/github/stars/prayag2/drawy?style=for-the-badge&logo=github&labelColor=%23202025&color=%23205CC0\"></a>\n<a href=\"https://github.com/prayag2/drawy/network\"><img alt=\"GitHub Forks\" src=\"https://img.shields.io/github/forks/prayag2/drawy?style=for-the-badge&logo=github&labelColor=%23202025&color=%23205CC0\"></a>\n<a href=\"https://github.com/prayag2/drawy/releases\"><img alt=\"GitHub Release\" src=\"https://img.shields.io/github/v/release/prayag2/drawy?include_prereleases&style=for-the-badge&labelColor=%23202025&color=%23205CC0\"></a>\n</p>\n\n<img src=\"./assets/screenshot.png\" style=\"width: 100%\"/>\n\nDrawy is a work-in-progress infinite whiteboard tool written in Qt/C++, which aims to be a native-desktop alternative to the amazing web-based Excalidraw.  \n\n# Installation  \n<a href=\"https://github.com/Prayag2/drawy/releases/download/1.0.0-alpha/Drawy-47b7552-x86_64.AppImage\">\n<img alt=\"Static Badge\" src=\"https://img.shields.io/badge/Download-Linux-F7B601?style=for-the-badge&labelColor=%23202025\">\n</a>\n\n<a href=\"https://github.com/Prayag2/drawy/releases/download/1.0.0-alpha/drawy-windows-x86_64.zip\">\n<img alt=\"Static Badge\" src=\"https://img.shields.io/badge/Download-Windows-007CF7?style=for-the-badge&labelColor=%23202025\">\n</a>\n\n## Compiling from Source\n- Install `cmake` and `g++`\n- Install Qt 6.9 or above from [here](https://www.qt.io/download-qt-installer-oss) or using [aqtinstall](https://github.com/miurahr/aqtinstall)\n- Clone this repository: `git clone https://github.com/prayag2/drawy && cd drawy`\n- Setup cmake: `cmake -B build -S . -DCMAKE_BUILD_TYPE=Release`\n- Compile: `cmake --build build --config Release`\n- Run: `./build/drawy`\n\n# Keyboard Shortcuts\nFuture releases will allow you to change the keyboard shortcuts. For now they are hardcoded. Here's a list of all available keyboard shortcuts:\n| Key Combination                                                             | Description       |\n|:---------------------------------------------------------------------------:|:-----------------:|\n| <kbd>Ctrl</kbd> + <kbd>Z</kbd>                                              | Undo              |\n| <kbd>Ctrl</kbd> + <kbd>Y</kbd>, <kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>Z</kbd> | Redo              |\n| <kbd>Ctrl</kbd> + <kbd>+</kbd>                                                | Zoom In           |\n| <kbd>Ctrl</kbd> + <kbd>-</kbd>                                                | Zoom Out          |\n| <kbd>Ctrl</kbd> + <kbd>G</kbd>                                                | Group selection   |\n| <kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>G</kbd>                               | Ungroup selection |\n| <kbd>P</kbd>, <kbd>B</kbd>                                                  | Freeform Tool     |\n| <kbd>E</kbd>                                                                | Eraser Tool       |\n| <kbd>S</kbd>                                                                | Selection Tool    |\n| <kbd>R</kbd>                                                                | Rectangle Tool    |\n| <kbd>O</kbd>                                                                | Ellipse Tool      |\n| <kbd>L</kbd>                                                                | Line Tool         |\n| <kbd>A</kbd>                                                                | Arrow Tool        |\n| <kbd>M</kbd>                                                                | Move Tool         |\n| <kbd>T</kbd>                                                                | Text Tool         |\n| <kbd>Ctrl+A</kbd>                                                           | Select All        |\n| <kbd>Delete</kbd>                                                           | Delete selection  |\n| <kbd>Ctrl+S</kbd>                                                           | Save              |\n| <kbd>Ctrl+O</kbd>                                                           | Open File         |\n\n# Contributing\nContributions are welcome. Please read the [contributing guide](CONTRIBUTING.md) before opening pull requests.\n\n# License\nThis project uses the GNU General Public License V3.\n\n# Support Me ‚ô•\nIf you liked this project, then please consider supporting me!  \n  \n<a href=\"https://liberapay.com/Prayag/donate\"><img alt=\"Donate using Liberapay\" src=\"https://img.shields.io/badge/LIBERAPAY-%231A171B?style=for-the-badge&logo=liberapay\"/></a>\n<a href=\"https://ko-fi.com/O5O1FJ70D\"><img alt=\"Buy Me A Coffee\" src=\"https://img.shields.io/badge/Buy%20Me%20A%20Coffee-%234D798C?style=for-the-badge&logo=ko-fi\"/></a>\n<a href=\"https://coindrop.to/prayagjain\"><img alt=\"Done using PayPal\" src=\"https://img.shields.io/badge/PayPal-%23F2BA37?style=for-the-badge&logo=paypal\"/></a>\n\n# TODOs\nStarted: `2025-01-02 04:40PM`  \nDevelopment is divided into phases.  \nThe project will eventually be open sourced. However, I will work on the first few phases myself, to maximize learning.  \nThe following is a list of features I'll be planning to add to it:  \n\n## Phase 1 (Basic Features)\n- [x] A simple fixed size canvas to draw on using a black coloured stroke.\n- [x] Different shapes like rectangle, ellipse, arrow, line and stroke.\n- [x] An eraser to erase the strokes (deleting the strokes).\n- [x] Testing.\n\n## Phase 2\n- [x] Refactor to try to adhere to SOLID principles and utilize useful design patterns\n- [x] A custom Qt layout for toolbar and properties bar\n- [x] Make canvas infinite and add ability to move the viewport\n- [x] Use an LRU cache based uniform grid to optimize moving the canvas around (now 100% faster!!)\n- [x] A properties bar to change the following properties:\n    - [x] Colour of strokes\n    - [x] Stroke width  \n  \n## Phase 3\n- [x] Buttons to zoom in/out\n- [x] Pressure senstivity for drawing tablets\n- [x] Selection tool to select items and do these actions:\n    - [x] Move items\n    - [x] Delete items\n    - [ ] Transform items (resize) (Low priority)\n    - [ ] Rotate items (Low priority)\n- [x] Undo/redo support\n- [x] Basic keybinding support\n- [x] Saving the drawings\n- [x] Text support\n- [ ] Exporting drawings to PNGs\n- [ ] Image support\n- [ ] Text formatting like bold, underline, italics, etc.\n- [ ] Better freeform smoothing algorithms\n- [ ] Allow snapping\n- [ ] Ability to store preferences\n- [ ] A \"settings\" page \n- [ ] Better widgets\n- [ ] Online collaboration\n\nFeature requests are welcome!\n",
      "stars_today": 38
    },
    {
      "id": 322484700,
      "name": "jj",
      "full_name": "jj-vcs/jj",
      "description": "A Git-compatible VCS that is both simple and powerful",
      "html_url": "https://github.com/jj-vcs/jj",
      "stars": 24700,
      "forks": 881,
      "language": "Rust",
      "topics": [
        "cli",
        "git",
        "jj",
        "jujutsu",
        "mercurial",
        "vcs"
      ],
      "created_at": "2020-12-18T04:05:27Z",
      "updated_at": "2026-01-14T01:06:33Z",
      "pushed_at": "2026-01-14T00:58:50Z",
      "open_issues": 978,
      "owner": {
        "login": "jj-vcs",
        "avatar_url": "https://avatars.githubusercontent.com/u/166203655?v=4"
      },
      "readme": "<div class=\"title-block\" style=\"text-align: center;\" align=\"center\">\n\n# Jujutsu‚Äîa version control system\n\n<p><img title=\"jj logo\" src=\"docs/images/jj-logo.svg\" width=\"320\" height=\"320\"></p>\n\n[![Release](https://img.shields.io/github/v/release/martinvonz/jj)](https://github.com/jj-vcs/jj/releases)\n[![Release date](https://img.shields.io/github/release-date/martinvonz/jj)](https://github.com/jj-vcs/jj/releases)\n<br/>\n[![License](https://img.shields.io/github/license/martinvonz/jj)](https://github.com/jj-vcs/jj/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/968932220549103686.svg?label=&logo=discord&logoColor=ffffff&color=7389D8&labelColor=6A7EC2)](https://discord.gg/dkmfj3aGQN)\n[![IRC](https://img.shields.io/badge/irc-%23jujutsu-blue.svg)](https://web.libera.chat/?channel=#jujutsu)\n\n**[Homepage] &nbsp;&nbsp;&bull;&nbsp;&nbsp;**\n**[Installation] &nbsp;&nbsp;&bull;&nbsp;&nbsp;**\n**[Getting Started] &nbsp;&nbsp;&bull;&nbsp;&nbsp;**\n**[Development Roadmap] &nbsp;&nbsp;&bull;&nbsp;&nbsp;**\n**[Contributing](#contributing)**\n\n[Homepage]: https://www.jj-vcs.dev\n[Installation]: https://docs.jj-vcs.dev/latest/install-and-setup\n[Getting Started]: https://docs.jj-vcs.dev/latest/tutorial\n[Development Roadmap]: https://docs.jj-vcs.dev/latest/roadmap\n\n</div>\n\n## Introduction\n\nJujutsu is a powerful [version control system](https://en.wikipedia.org/wiki/Version_control)\nfor software projects. You use it to get a copy of your code, track changes\nto the code, and finally publish those changes for others to see and use.\nIt is designed from the ground up to be easy to use‚Äîwhether you're new or\nexperienced, working on brand new projects alone, or large scale software\nprojects with large histories and teams.\n\nJujutsu is unlike most other systems, because internally it abstracts the user\ninterface and version control algorithms from the *storage systems* used to\nserve your content. This allows it to serve as a VCS with many possible physical\nbackends, that may have their own data or networking models‚Äîlike [Mercurial] or\n[Breezy], or hybrid systems like Google's cloud-based design, [Piper/CitC].\n\n[Mercurial]: https://www.mercurial-scm.org/\n[Breezy]: https://www.breezy-vcs.org/\n[Piper/CitC]: https://youtu.be/W71BTkUbdqE?t=645\n\nToday, we use Git repositories as a storage layer to serve and track content,\nmaking it **compatible with many of your favorite Git-based tools, right now!**\nAll core developers use Jujutsu to develop Jujutsu, right here on GitHub. But it\nshould hopefully work with your favorite Git forges, too.\n\nWe combine many distinct design choices and concepts from other version control\nsystems into a single tool. Some of those sources of inspiration include:\n\n- **Git**: We make an effort to [be fast][perf]‚Äîwith a snappy UX, efficient\n  algorithms, correct data structures, and good-old-fashioned attention to\n  detail. The default storage backend uses Git repositories for \"physical\n  storage\", for wide interoperability and ease of onboarding.\n\n- **Mercurial & Sapling**: There are many Mercurial-inspired features, such as\n  the [revset] language to select commits. There is [no explicit index][no-index]\n  or staging area. Branches are \"anonymous\" like Mercurial, so you don't need\n  to make up a name for each small change. Primitives for rewriting history are\n  powerful and simple. Formatting output is done with a robust template language\n  that can be configured by the user.\n\n- **Darcs**: Jujutsu keeps track of conflicts as [first-class\n  objects][conflicts] in its model; they are first-class in the same way commits\n  are, while alternatives like Git simply think of conflicts as textual diffs.\n  While not as rigorous as systems like Darcs (which is based on a formalized\n  theory of patches, as opposed to snapshots), the effect is that many forms of\n  conflict resolution can be performed and propagated automatically.\n\n[perf]: https://github.com/jj-vcs/jj/discussions/49\n[revset]: https://docs.jj-vcs.dev/latest/revsets/\n[no-index]: https://docs.jj-vcs.dev/latest/git-comparison/#the-index\n[conflicts]: https://docs.jj-vcs.dev/latest/conflicts/\n\nAnd it adds several innovative, useful features of its own:\n\n- **Working-copy-as-a-commit**: Changes to files are [recorded automatically][wcc]\n  as normal commits, and amended on every subsequent change. This \"snapshot\"\n  design simplifies the user-facing data model (commits are the only visible\n  object), simplifies internal algorithms, and completely subsumes features like\n  Git's stashes or the index/staging-area.\n\n- **Operation log & undo**: Jujutsu records every operation that is performed on the\n  repository, from commits, to pulls, to pushes. This makes debugging problems like\n  \"what just happened?\" or \"how did I end up here?\" easier, *especially* when\n  you're helping your coworker answer those questions about their repository!\n  And because everything is recorded, you can undo that mistake you just made\n  with ease. Version control has finally entered [the 1960s][undo-history]!\n\n- **Automatic rebase and conflict resolution**: When you modify a commit, every\n  descendent is automatically rebased on top of the freshly-modified one. This\n  makes \"patch-based\" workflows a breeze. If you resolve a conflict in a commit,\n  the _resolution_ of that conflict is also propagated through descendants as\n  well. In effect, this is a completely transparent version of `git rebase\n  --update-refs` combined with `git rerere`, supported by design.\n\n> [!WARNING]\n> The following features are available for use, but experimental; they may have\n> bugs, backwards incompatible storage changes, and user-interface changes!\n\n- **Safe, concurrent replication**: Have you ever wanted to store your version\n  controlled repositories inside a Dropbox folder? Or continuously backup\n  repositories to S3? No? Well, now you can!\n\n  The fundamental problem with using filesystems like Dropbox and backup tools\n  like `rsync` on your typical Git/Mercurial repositories is that they rely\n  on *local filesystem operations* being atomic, serialized, and non-concurrent\n  with respect to other reads and writes‚Äîwhich is _not_ true when operating on\n  distributed file systems, or when operations like concurrent file copies (for\n  backup) happen while lock files are being held.\n\n  Jujutsu is instead designed to be [safe under concurrent scenarios][conc-safety];\n  simply using rsync or Dropbox and then using that resulting repository\n  should never result in a repository in a *corrupt state*. The worst that\n  _should_ happen is that it will expose conflicts between the local and remote\n  state, leaving you to resolve them.\n\n[wcc]: https://docs.jj-vcs.dev/latest/working-copy/\n[undo-history]: https://en.wikipedia.org/wiki/Undo#History\n[conc-safety]: https://docs.jj-vcs.dev/latest/technical/concurrency/\n\nThe command-line tool is called `jj` for now because it's easy to type and easy\nto replace (rare in English). The project is called \"Jujutsu\" because it matches\n\"jj\".\n\nJujutsu is relatively young, with lots of work to still be done. If you have any\nquestions, or want to talk about future plans, please join us on Discord\n[![Discord](https://img.shields.io/discord/968932220549103686.svg?label=&logo=discord&logoColor=ffffff&color=7389D8&labelColor=6A7EC2)](https://discord.gg/dkmfj3aGQN),\nstart a [GitHub Discussion](https://github.com/jj-vcs/jj/discussions), or\nsend an IRC message to [`#jujutsu` on Libera\nChat](https://web.libera.chat/?channel=#jujutsu). The developers monitor all of\nthese channels[^bridge].\n\n[^bridge]: To be more precise, the `#jujutsu` Libera IRC channel is bridged to\none of the channels on jj's Discord. Some of the developers stay on Discord and\nuse the bridge to follow IRC.\n\n### News and Updates üì£\n\n- **December 2024**: The `jj` Repository has moved to the `jj-vcs` GitHub\n  organization.\n- **November 2024**: Version 0.24 is released which adds `jj file annotate`,\n  which is equivalent to `git blame` or `hg annotate`.\n- **September 2024**: Martin gave a [presentation about Jujutsu][merge-vid-2024] at\n  Git Merge 2024.\n- **Feb 2024**: Version 0.14 is released, which deprecates [\"jj checkout\" and \"jj merge\"](CHANGELOG.md#0140---2024-02-07),\n  as well as `jj init --git`, which is now just called `jj git init`.\n- **Oct 2023**: Version 0.10.0 is released! Now includes a bundled merge and\n  diff editor for all platforms, \"immutable revsets\" to avoid accidentally\n  `edit`-ing the wrong revisions, and lots of polish.\n- **Jan 2023**: Martin gave a presentation about Google's plans for Jujutsu at\n  Git Merge 2022!\n  See the [slides][merge-slides] or the [recording][merge-talk].\n\n### Related Media\n\n- **Mar 2024**: Chris Krycho started [a YouTube series about Jujutsu][krycho-yt].\n- **Feb 2024**: Chris Krycho published an article about Jujutsu called [jj init][krycho]\n  and Steve Klabnik followed up with the [Jujutsu Tutorial][klabnik].\n- **Jan 2024**: Jujutsu was featured in an LWN.net article called\n  [Jujutsu: a new, Git-compatible version control system][lwn].\n- **Jan 2023**: Martin's Talk about Jujutsu at Git Merge 2022, [video][merge-talk]\n  and the associated [slides][merge-slides].\n\nThe wiki also contains a more extensive list of [media references][wiki-media].\n\n[krycho-yt]: https://www.youtube.com/playlist?list=PLelyiwKWHHAq01Pvmpf6x7J0y-yQpmtxp\n[krycho]: https://v5.chriskrycho.com/essays/jj-init/\n[klabnik]: https://steveklabnik.github.io/jujutsu-tutorial/\n[lwn]: https://lwn.net/Articles/958468/\n[merge-talk]: https://www.youtube.com/watch?v=bx_LGilOuE4\n[merge-slides]: https://docs.google.com/presentation/d/1F8j9_UOOSGUN9MvHxPZX_L4bQ9NMcYOp1isn17kTC_M/view\n[merge-vid-2024]: https://www.youtube.com/watch?v=LV0JzI8IcCY\n[wiki-media]: https://github.com/jj-vcs/jj/wiki/Media\n\n## Getting started\n\n> [!IMPORTANT]\n> Jujutsu is an **experimental version control system**. While Git compatibility\n> is stable, and most developers use it daily for all their needs, there may\n> still be work-in-progress features, suboptimal UX, and workflow gaps that make\n> it unusable for your particular use.\n\nFollow the [installation\ninstructions](https://docs.jj-vcs.dev/latest/install-and-setup) to\nobtain and configure `jj`.\n\nThe best way to get started is probably to go through [the\ntutorial](https://docs.jj-vcs.dev/latest/tutorial). Also see the [Git\ncomparison](https://docs.jj-vcs.dev/latest/git-comparison), which\nincludes a table of `jj` vs. `git` commands.\n\nAs you become more familiar with Jujutsu, the following resources may be helpful:\n\n- The [FAQ](https://docs.jj-vcs.dev/latest/FAQ).\n- The [Glossary](https://docs.jj-vcs.dev/latest/glossary).\n- The `jj help` command (e.g. `jj help rebase`).\n- The `jj help -k <keyword>` command (e.g. `jj help -k config`). Use `jj help --help`\n  to see what keywords are available.\n\nIf you are using a **prerelease** version of `jj`, you would want to consult\n[the docs for the prerelease (main branch)\nversion](https://docs.jj-vcs.dev/prerelease/). You can also get there\nfrom the docs for the latest release by using the website's version switcher. The version switcher is visible in\nthe header of the website when you scroll to the top of any page.\n\n## Features\n\n### Compatible with Git\n\nJujutsu is designed so that the underlying data and storage model is abstract.\nToday, only the Git backend is production-ready. The Git backend uses the\n[gitoxide](https://github.com/Byron/gitoxide) Rust library.\n\n[backends]: https://docs.jj-vcs.dev/latest/glossary#backend\n\nThe Git backend is fully featured and maintained, and allows you to use Jujutsu\nwith any Git remote. The commits you create will look like regular Git commits.\nYou can fetch branches from a regular Git remote and push branches to the\nremote. You can always switch back to Git.\n\nHere is how you can explore a GitHub repository with `jj`.\n\n<img src=\"demos/git_compat.png\" />\n\nYou can even have a [colocated local\nworkspace](https://docs.jj-vcs.dev/latest/git-compatibility#colocated-jujutsugit-repos)\nwhere you can use both `jj` and `git` commands interchangeably.\n\n### The working copy is automatically committed\n\nJujutsu uses a real commit to represent the working copy. Checking out a commit\nresults in a new working-copy commit on top of the target commit. Almost all\ncommands automatically amend the working-copy commit.\n\nThe working-copy being a commit means that commands never fail because the\nworking copy is dirty (no \"error: Your local changes to the following\nfiles...\"), and there is no need for `git stash`. Also, because the working copy\nis a commit, commands work the same way on the working-copy commit as on any\nother commit, so you can set the commit message before you're done with the\nchanges.\n\n<img src=\"demos/working_copy.png\" />\n\n### The repo is the source of truth\n\nWith Jujutsu, the working copy plays a smaller role than with Git. Commands\nsnapshot the working copy before they start, then they update the repo, and then\nthe working copy is updated (if the working-copy commit was modified). Almost\nall commands (even checkout!) operate on the commits in the repo, leaving the\ncommon functionality of snapshotting and updating of the working copy to\ncentralized code. For example, `jj restore` (similar to `git restore`) can\nrestore from any commit and into any commit, and `jj describe` can set the\ncommit message of any commit (defaults to the working-copy commit).\n\n### Entire repo is under version control\n\nAll operations you perform in the repo are recorded, along with a snapshot of\nthe repo state after the operation. This means that you can easily restore to\nan earlier repo state, simply undo your operations one-by-one or even _revert_ a\nparticular operation which does not have to be the most recent one.\n\n<img src=\"demos/operation_log.png\" />\n\n### Conflicts can be recorded in commits\n\nIf an operation results in\n[conflicts](https://docs.jj-vcs.dev/latest/glossary#conflict),\ninformation about those conflicts will be recorded in the commit(s). The\noperation will succeed. You can then resolve the conflicts later. One\nconsequence of this design is that there's no need to continue interrupted\noperations. Instead, you get a single workflow for resolving conflicts,\nregardless of which command caused them. This design also lets Jujutsu rebase\nmerge commits correctly (unlike both Git and Mercurial).\n\nBasic conflict resolution:\n\n<img src=\"demos/resolve_conflicts.png\" />\n\nJuggling conflicts:\n\n<img src=\"demos/juggle_conflicts.png\" />\n\n### Automatic rebase\n\nWhenever you modify a commit, any descendants of the old commit will be rebased\nonto the new commit. Thanks to the conflict design described above, that can be\ndone even if there are conflicts. Bookmarks pointing to rebased commits will be\nupdated. So will the working copy if it points to a rebased commit.\n\n### Comprehensive support for rewriting history\n\nBesides the usual rebase command, there's `jj describe` for editing the\ndescription (commit message) of an arbitrary commit. There's also `jj diffedit`,\nwhich lets you edit the changes in a commit without checking it out. To split\na commit into two, use `jj split`. You can even move part of the changes in a\ncommit to any other commit using `jj squash -i --from X --into Y`.\n\n## Status\n\nThe tool is fairly feature-complete, but some important features like support\nfor Git submodules are not yet completed. There\nare also several performance bugs. It's likely that workflows and setups\ndifferent from what the core developers use are not well supported, e.g. there\nis no native support for email-based workflows.\n\nToday, all core developers use `jj` to work on `jj`. I (Martin von Zweigbergk)\nhave almost exclusively used `jj` to develop the project itself since early\nJanuary 2021. I haven't had to re-clone from source (I don't think I've even had\nto restore from backup).\n\nThere *will* be changes to workflows and backward-incompatible changes to the\non-disk formats before version 1.0.0. For any format changes, we'll try to\nimplement transparent upgrades (as we've done with recent changes), or provide\nupgrade commands or scripts if requested.\n\n## Related work\n\nThere are several tools trying to solve similar problems as Jujutsu. See\n[related work](https://docs.jj-vcs.dev/latest/related-work) for details.\n\n## Contributing\n\nWe welcome outside contributions, and there's plenty of things to do, so\ndon't be shy. Please ask if you want a pointer on something you can help with,\nand hopefully we can all figure something out.\n\nWe do have [a few policies and\nsuggestions](https://docs.jj-vcs.dev/prerelease/contributing/)\nfor contributors. The broad TL;DR:\n\n- Bug reports are very welcome!\n- Every commit that lands in the `main` branch is code reviewed.\n- Please behave yourself, and obey the Community Guidelines.\n- There **is** a mandatory CLA you must agree to. Importantly, it **does not**\n  transfer copyright ownership to Google or anyone else; it simply gives us the\n  right to safely redistribute and use your changes.\n\n### Mandatory Google Disclaimer\n\nI (Martin von Zweigbergk, <martinvonz@google.com>) started Jujutsu as a hobby\nproject in late 2019, and it has evolved into my full-time project at Google,\nwith several other Googlers (now) assisting development in various capacities.\nThat said, **this is not a Google product**.\n\n## License\n\nJujutsu is available as Open Source Software, under the Apache 2.0 license. See\n[`LICENSE`](./LICENSE) for details about copyright and redistribution.\n\nThe `jj` logo was contributed by J. Jennings and is licensed under a Creative\nCommons License, see [`docs/images/LICENSE`](docs/images/LICENSE).\n",
      "stars_today": 35
    },
    {
      "id": 566323731,
      "name": "Easydict",
      "full_name": "tisfeng/Easydict",
      "description": "‰∏Ä‰∏™ÁÆÄÊ¥Å‰ºòÈõÖÁöÑËØçÂÖ∏ÁøªËØë macOS App„ÄÇÂºÄÁÆ±Âç≥Áî®ÔºåÊîØÊåÅÁ¶ªÁ∫ø OCR ËØÜÂà´ÔºåÊîØÊåÅÊúâÈÅìËØçÂÖ∏Ôºåüçé ËãπÊûúÁ≥ªÁªüËØçÂÖ∏Ôºåüçé ËãπÊûúÁ≥ªÁªüÁøªËØëÔºåOpenAIÔºåGeminiÔºåDeepLÔºåGoogleÔºåBingÔºåËÖæËÆØÔºåÁôæÂ∫¶ÔºåÈòøÈáåÔºåÂ∞èÁâõÔºåÂΩ©‰∫ëÂíåÁÅ´Â±±ÁøªËØë„ÄÇA concise and elegant Dictionary and Translator macOS App for looking up words and translating text. ",
      "html_url": "https://github.com/tisfeng/Easydict",
      "stars": 11780,
      "forks": 577,
      "language": "Swift",
      "topics": [
        "app",
        "baidu",
        "bing",
        "deepl",
        "dictionary",
        "gemini",
        "google",
        "macos",
        "ocr",
        "openai",
        "shortcuts",
        "tencent",
        "translate",
        "translator",
        "youdao"
      ],
      "created_at": "2022-11-15T12:41:53Z",
      "updated_at": "2026-01-13T23:20:35Z",
      "pushed_at": "2026-01-11T16:31:39Z",
      "open_issues": 119,
      "owner": {
        "login": "tisfeng",
        "avatar_url": "https://avatars.githubusercontent.com/u/25194972?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/tisfeng/ImageBed/main/uPic/icon_512x512@2x.png\" height=\"256\">\n  <h1 align=\"center\">Easydict</h1>\n  <h4 align=\"center\"> Easy to look up words or translate text</h4>\n<p align=\"center\"> \n<a href=\"https://github.com/tisfeng/easydict/blob/main/LICENSE\">\n<img src=\"https://img.shields.io/github/license/tisfeng/easydict\"\n            alt=\"License\"></a>\n<a href=\"https://github.com/tisfeng/Easydict/releases\">\n<img src=\"https://img.shields.io/github/downloads/tisfeng/easydict/total.svg\"\n            alt=\"Downloads\"></a>\n<a href=\"https://img.shields.io/badge/-macOS-black?&logo=apple&logoColor=white\">\n<img src=\"https://img.shields.io/badge/-macOS-black?&logo=apple&logoColor=white\"\n            alt=\"macOS\"></a>  \n</p>\n\n<div align=\"center\">\n<a href=\"./README_ZH.md\">‰∏≠Êñá</a> &nbsp;&nbsp;|&nbsp;&nbsp; <a href=\"./README.md\">English</a>\n</div>\n\n## Easydict\n\n`Easydict` is a concise and easy-to-use translation dictionary macOS App that allows you to easily and elegantly look up words or translate text.\n\nEasydict is ready to use out of the box, can automatically recognize the language of the input text, supports input translate, select translate, and OCR screenshot translate, and can query multiple translation services results at the same time.\n\n**Supported translation services:** [**üçé Apple Dictionary**](./docs/en/How-to-use-macOS-system-dictionary-in-Easydict.md), [üçé **Apple Translate**](./docs/en/How-to-use-macOS-system-translation-in-Easydict.md), [OpenAI](https://chat.openai.com/), [Gemini](https://gemini.google.com/), [DeepSeek](https://www.deepseek.com/), [Ollama](https://ollama.com/), [Groq](https://groq.com/), [Zhipu AI](https://open.bigmodel.cn/), [GitHub Models](https://github.com/marketplace/models), [DeepL](https://www.deepl.com/translator), [Google](https://translate.google.com), [Youdao](https://www.youdao.com/), [Tencent](https://fanyi.qq.com/), [Bing](https://www.bing.com/translator), [Baidu](https://fanyi.baidu.com/), [Niutrans](https://niutrans.com/), [Caiyun](https://fanyi.caiyunapp.com/), [Alibaba](https://translate.alibaba.com/), [Volcano](https://translate.volcengine.com/translate) and [Doubao](https://www.volcengine.com/docs/82379/1820188).\n\n![Log](https://raw.githubusercontent.com/tisfeng/ImageBed/main/uPic/Log-1688378715.png)\n\n<table>\n    <td> <img src=\"https://raw.githubusercontent.com/tisfeng/ImageBed/main/uPic/iShot_2023-05-28_16.32.18-1685262784.png\">\n    <td> <img src=\"https://raw.githubusercontent.com/tisfeng/ImageBed/main/uPic/iShot_2023-05-28_16.32.26-1685262803.png\">\n</table>\n\n![immerse-1686534718.gif](https://raw.githubusercontent.com/tisfeng/ImageBed/main/uPic/immerse-1686534718.gif)\n\n## Features\n\n- üöÄ Out of the box, automatic language recognition\n- üñ±Ô∏è Auto select with mouse and shortcut key\n- üì∏ OCR screenshot translation and slient screenshot OCR\n- üîä Multiple TTS voice services\n- üìö Support üçé [Apple System Dictionary](./docs/en/How-to-use-macOS-system-dictionary-in-Easydict.md) and [System Translation](./docs/en/How-to-use-macOS-system-translation-in-Easydict.md)\n- üåê Support 20+ translation services (OpenAI, Gemini, DeepL, Google, Ollama, Groq, etc.)\n- üó£Ô∏è Support for 48 languages\n\n**If you like this app, please consider giving it a [Star](https://github.com/tisfeng/Easydict) ‚≠êÔ∏è, thanks! (^-^)**\n\n## Installation\n\n### Homebrew Installation (Recommended)\n\n```bash\nbrew install --cask easydict\n```\n\n### Manual Installation\n\n[Download](https://github.com/tisfeng/Easydict/releases) the latest release.\n\n> [!NOTE]\n> Latest version supports macOS 13.0+, for older systems please use [2.7.2](https://github.com/tisfeng/Easydict/releases/tag/2.7.2)\n\n---\n\n## Usage\n\n| Ways                      | Description                                                                                                                                  | Preview                                                                                                                                        |\n| ------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------- |\n| Input Translate           | Press the input translate shortcut key (default `‚å• + A`), enter the text to be translated, and `Enter` key to translate          | ![iShot_2023-01-20_11.28.46-1674185354](https://raw.githubusercontent.com/tisfeng/ImageBed/main/uPic/iShot_2023-01-20_11.28.46-1674185354.gif) |\n| Mouse Select Translate    | The query icon is automatically displayed after the word is selected, and the mouse hovers over it to query                                  | ![iShot_2023-01-20_11.01.35-1674183779](https://raw.githubusercontent.com/tisfeng/ImageBed/main/uPic/iShot_2023-01-20_11.01.35-1674183779.gif) |\n| Shortcut Select Translate | After selecting the text to be translated, press the shortcut key (default `‚å• + D`)                                                          | ![iShot_2023-01-20_11.24.37-1674185125](https://raw.githubusercontent.com/tisfeng/ImageBed/main/uPic/iShot_2023-01-20_11.24.37-1674185125.gif) |\n| Screenshot Translate      | Press the screenshot translate shortcut key (default `‚å• + S`) to capture the area to be translated                                           | ![iShot_2023-01-20_11.26.25-1674185209](https://raw.githubusercontent.com/tisfeng/ImageBed/main/uPic/iShot_2023-01-20_11.26.25-1674185209.gif) |\n| Silent Screenshot OCR     | Press the Silent Screenshot shortcut keyÔºàdefault `‚å• + ‚áß + S`Ôºâto capture the area, the OCR results will be copied directly to the clipboard | ![Â±èÂπïÂΩïÂà∂ 2023-05-20 22 39 11](https://github.com/Jerry23011/Easydict/assets/89069957/c16f3c20-1748-411e-be04-11d8fe0e61af)                     |\n\n---\n\n## Documentation\n\n- üìñ [Complete Usage Guide](./docs/en/GUIDE.md) - Detailed features, configuration and tips\n- üîß [Developer Build Guide](./docs/en/GUIDE.md#developer-build) - Build and run from source code\n- üçé [How to use macOS System Dictionary](./docs/en/How-to-use-macOS-system-dictionary-in-Easydict.md)\n- üçé [How to use macOS System Translation](./docs/en/How-to-use-macOS-system-translation-in-Easydict.md)\n- üåç [How to translate Easydict](./docs/How-to-translate-Easydict-en.md)\n\n---\n\n## Acknowledgements\n\n- This project was inspired by [saladict](https://github.com/crimx/ext-saladict) and [Bob](https://github.com/ripperhe/Bob), and the initial version was made based on [Bob (GPL-3.0)](https://github.com/1xiaocainiao/Bob). Easydict has made many improvements and optimizations on the original project, and many features and UI are referenced from Bob.\n- Screenshot feature is based on [isee15](https://github.com/isee15)'s [Capture-Screen-For-Multi-Screens-On-Mac](https://github.com/isee15/Capture-Screen-For-Multi-Screens-On-Mac), and optimized on this project.\n- Select text feature is referenced from [PopClip](https://pilotmoon.com/popclip/).\n\n## Statement\n\nEasydict is licensed under the [GPL-3.0](https://github.com/tisfeng/Easydict/blob/main/LICENSE) open source license, which is for learning and communication only. Anyone can get this product and source code for free. If you believe that your legal rights have been violated, please contact the [author](https://github.com/tisfeng) immediately. You can use the source code freely, but you must attach the corresponding license and copyright.\n\n## Sponsor\n\nEasydict is a free and open source project, currently mainly developed and maintained by the author. If you like this project and find it helpful, you can consider sponsoring this project to support it, so that it can go further.\n\nThanks to [@CanglongCl](https://github.com/CanglongCl) for providing the Apple Developer account, which solved the app [signature issue](https://github.com/tisfeng/Easydict/issues/2), allowing more people to use Easydict conveniently.\n\n<a href=\"https://afdian.com/a/tisfeng\"><img width=\"20%\" src=\"https://pic1.afdiancdn.com/static/img/welcome/button-sponsorme.jpg\" alt=\"\"></a>\n\n<div>\n  <img src=\"https://raw.githubusercontent.com/tisfeng/ImageBed/main/uPic/IMG_4739-1684680971.JPG\" width=\"30%\">\n</div>\n\nThanks to all sponsors for their generous support. For details, please see the [Sponsor List](./docs/en/SPONSOR_LIST.md).\n\n---\n\n## Star History\n\n<a href=\"https://star-history.com/#tisfeng/easydict&Date\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=tisfeng/easydict&type=Date&theme=dark\" />\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=tisfeng/easydict&type=Date\" />\n    <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=tisfeng/easydict&type=Date\" />\n  </picture>\n</a>",
      "stars_today": 35
    },
    {
      "id": 868811259,
      "name": "prek",
      "full_name": "j178/prek",
      "description": "‚ö° Better `pre-commit`, re-engineered in Rust",
      "html_url": "https://github.com/j178/prek",
      "stars": 3260,
      "forks": 102,
      "language": "Rust",
      "topics": [
        "git",
        "git-hooks",
        "pre-commit"
      ],
      "created_at": "2024-10-07T08:21:29Z",
      "updated_at": "2026-01-14T00:28:05Z",
      "pushed_at": "2026-01-13T15:50:20Z",
      "open_issues": 71,
      "owner": {
        "login": "j178",
        "avatar_url": "https://avatars.githubusercontent.com/u/10510431?v=4"
      },
      "readme": "<div align=\"center\">\n\n<h1>\n  <img width=\"180\" alt=\"prek\" src=\"https://raw.githubusercontent.com/j178/prek/master/docs/assets/logo.webp\" />\n  <br/>prek\n</h1>\n\n[![prek](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/j178/prek/master/docs/assets/badge-v0.json)](https://github.com/j178/prek)\n[![codecov](https://codecov.io/github/j178/prek/graph/badge.svg?token=MP6TY24F43)](https://codecov.io/github/j178/prek)\n[![GitHub Downloads](https://img.shields.io/github/downloads/j178/prek/total?logo=github)](https://github.com/j178/prek/releases)\n[![PyPI Downloads](https://img.shields.io/pypi/dm/prek?logo=python)](https://pepy.tech/projects/prek)\n[![Discord](https://img.shields.io/discord/1403581202102878289?logo=discord)](https://discord.gg/3NRJUqJz86)\n\n</div>\n\n<!-- description:start -->\n[pre-commit](https://pre-commit.com/) is a framework to run hooks written in many languages, and it manages the\nlanguage toolchain and dependencies for running the hooks.\n\n*prek* is a reimagined version of pre-commit, built in Rust.\nIt is designed to be a faster, dependency-free and drop-in alternative for it,\nwhile also providing some additional long-requested features.\n<!-- description:end -->\n\n> [!NOTE]\n> Although prek is pretty new, it‚Äôs already powering real‚Äëworld projects like [Apache Airflow](https://github.com/apache/airflow), [FastAPI](https://github.com/fastapi/fastapi), and more projects are picking it up‚Äîsee [Who is using prek?](#who-is-using-prek). If you‚Äôre looking for an alternative to `pre-commit`, please give it a try‚Äîwe‚Äôd love your feedback!\n>\n> Please note that some subcommands and languages are still missing for full drop‚Äëin parity with `pre-commit`. Track the remaining gaps here: [TODO](https://prek.j178.dev/todo/).\n\n<!-- features:start -->\n## Features\n\n- üöÄ A single binary with no dependencies, does not require Python or any other runtime.\n- ‚ö° [Faster](https://prek.j178.dev/benchmark/) than `pre-commit` and more efficient in disk space usage.\n- üîÑ Fully compatible with the original pre-commit configurations and hooks.\n- üèóÔ∏è Built-in support for monorepos (i.e. [workspace mode](https://prek.j178.dev/workspace/)).\n- üêç Integration with [`uv`](https://github.com/astral-sh/uv) for managing Python virtual environments and dependencies.\n- üõ†Ô∏è Improved toolchain installations for Python, Node.js, Go, Rust and Ruby, shared between hooks.\n- üì¶ [Built-in](https://prek.j178.dev/builtin/) Rust-native implementation of some common hooks.\n<!-- features:end -->\n\n## Table of contents\n\n- [Installation](#installation)\n- [Quick start](#quick-start)\n- [Why prek?](#why-prek)\n- [Who is using prek?](#who-is-using-prek)\n- [Acknowledgements](#acknowledgements)\n\n## Installation\n\n<details>\n<summary>Standalone installer</summary>\n\nprek provides a standalone installer script to download and install the tool,\n\nOn Linux and macOS:\n\n<!-- linux-standalone-install:start -->\n```bash\ncurl --proto '=https' --tlsv1.2 -LsSf https://github.com/j178/prek/releases/download/v0.2.28/prek-installer.sh | sh\n```\n<!-- linux-standalone-install:end -->\n\nOn Windows:\n\n<!-- windows-standalone-install:start -->\n```powershell\npowershell -ExecutionPolicy ByPass -c \"irm https://github.com/j178/prek/releases/download/v0.2.28/prek-installer.ps1 | iex\"\n```\n<!-- windows-standalone-install:end -->\n\n</details>\n\n<details>\n<summary>PyPI</summary>\n\n<!-- pypi-install:start -->\nprek is published as Python binary wheel to PyPI, you can install it using `pip`, `uv` (recommended), or `pipx`:\n\n```bash\n# Using uv (recommended)\nuv tool install prek\n\n# Using uvx (install and run in one command)\nuvx prek\n\n# Adding prek to the project dev-dependencies\nuv add --dev prek\n\n# Using pip\npip install prek\n\n# Using pipx\npipx install prek\n```\n<!-- pypi-install:end -->\n\n</details>\n\n<details>\n<summary>Homebrew</summary>\n\n<!-- homebrew-install:start -->\n```bash\nbrew install prek\n```\n<!-- homebrew-install:end -->\n\n</details>\n\n<details>\n<summary>mise</summary>\n\n<!-- mise-install:start -->\nTo use prek with [mise](https://mise.jdx.dev) ([v2025.8.11](https://github.com/jdx/mise/releases/tag/v2025.8.11) or later):\n\n```bash\nmise use prek\n```\n<!-- mise-install:end -->\n\n</details>\n\n<details>\n<summary>Cargo binstall</summary>\n\n<!-- cargo-binstall:start -->\nInstall pre-compiled binaries from GitHub using [cargo-binstall](https://github.com/cargo-bins/cargo-binstall):\n\n```bash\ncargo binstall prek\n```\n<!-- cargo-binstall:end -->\n\n</details>\n\n<details>\n<summary>Cargo</summary>\n\n<!-- cargo-install:start -->\nBuild from source using Cargo (Rust 1.89+ is required):\n\n```bash\ncargo install --locked prek\n```\n<!-- cargo-install:end -->\n\n</details>\n\n<details>\n<summary>npmjs</summary>\n\n<!-- npmjs-install:start -->\nprek is published as a Node.js package, you can install it using `npm`, `pnpm`, or `npx`:\n\n```bash\n# Using npm\nnpm add -D @j178/prek\n\n# Using pnpm\npnpm add -D @j178/prek\n\n# Using npx\nnpx @j178/prek --version\n\n# or install globally\nnpm install -g @j178/prek\n\n# then use `prek` command\nprek --version\n```\n<!-- npmjs-install:end -->\n\n</details>\n\n<details>\n<summary>Nix</summary>\n\n<!-- nix-install:start -->\nprek is available via [Nixpkgs](https://search.nixos.org/packages?channel=unstable&show=prek&query=prek).\n\n```shell\n# Choose what's appropriate for your use case.\n# One-off in a shell:\nnix-shell -p prek\n\n# NixOS or non-NixOS without flakes:\nnix-env -iA nixos.prek\n\n# Non-NixOS with flakes:\nnix profile install nixpkgs#prek\n```\n<!-- nix-install:end -->\n\n</details>\n\n<details>\n<summary>Conda</summary>\n\n<!-- conda-forge-install:start -->\nprek is available as `prek` via [conda-forge](https://anaconda.org/conda-forge/prek).\n\n```shell\nconda install conda-forge::prek\n```\n<!-- conda-forge-install:end -->\n\n</details>\n\n<details>\n<summary>Scoop (Windows)</summary>\n\n<!-- scoop-install:start -->\nprek is available via [Scoop](https://scoop.sh/#/apps?q=prek).\n\n```powershell\nscoop install main/prek\n```\n<!-- scoop-install:end -->\n</details>\n\n<details>\n<summary>MacPorts</summary>\n\n<!-- macports-install:start -->\nprek is available via [MacPorts](https://ports.macports.org/port/prek/).\n\n```bash\nsudo port install prek\n```\n<!-- macports-install:end -->\n</details>\n\n<details>\n<summary>GitHub Releases</summary>\n\n<!-- pre-built-binaries:start -->\nPre-built binaries are available for download from the [GitHub releases](https://github.com/j178/prek/releases) page.\n<!-- pre-built-binaries:end -->\n\n</details>\n\n<details>\n<summary>GitHub Actions</summary>\n\n<!-- github-actions:start -->\nprek can be used in GitHub Actions via the [j178/prek-action](https://github.com/j178/prek-action) repository.\n\nExample workflow:\n\n```yaml\nname: Prek checks\non: [push, pull_request]\n\njobs:\n  prek:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v5\n      - uses: j178/prek-action@v1\n```\n\nThis action installs prek and runs `prek run --all-files` on your repository.\n\nprek is also available via [`taiki-e/install-action`](https://github.com/taiki-e/install-action) for installing various tools.\n<!-- github-actions:end -->\n</details>\n\n<!-- self-update:start -->\nIf installed via the standalone installer, prek can update itself to the latest version:\n\n```bash\nprek self update\n```\n<!-- self-update:end -->\n\n## Quick start\n\n- **I already use pre-commit:** follow the short migration checklist in the [quickstart guide](https://prek.j178.dev/quickstart/#already-using-pre-commit) to swap in `prek` safely.\n- **I'm new to pre-commit-style tools:** learn the basics‚Äîcreating a config, running hooks, and installing git hooks‚Äîin the [beginner quickstart walkthrough](https://prek.j178.dev/quickstart/#new-to-pre-commit-style-workflows).\n\n<!-- why:start -->\n## Why prek?\n\n### prek is faster\n\n- It is [multiple times faster](https://prek.j178.dev/benchmark/) than `pre-commit` and takes up half the disk space.\n- It redesigned how hook environments and toolchains are managed, they are all shared between hooks, which reduces the disk space usage and speeds up the installation process.\n- Repositories are cloned in parallel, and hooks are installed in parallel if their dependencies are disjoint.\n- Hooks can run in parallel by priority (hooks with the same [`priority`](https://prek.j178.dev/configuration/#priority) may run concurrently), reducing end-to-end runtime.\n- It uses [`uv`](https://github.com/astral-sh/uv) for creating Python virtualenvs and installing dependencies, which is known for its speed and efficiency.\n- It implements some common hooks in Rust, [built in prek](https://prek.j178.dev/builtin/), which are faster than their Python counterparts.\n- It supports `repo: builtin` for offline, zero-setup hooks, which is not available in `pre-commit`.\n\n### prek provides a better user experience\n\n- No need to install Python or any other runtime, just download a single binary.\n- No hassle with your Python version or virtual environments, prek automatically installs the required Python version and creates a virtual environment for you.\n- Built-in support for [workspaces](https://prek.j178.dev/workspace/) (or monorepos), each subproject can have its own `.pre-commit-config.yaml` file.\n- [`prek run`](https://prek.j178.dev/cli/#prek-run) has some nifty improvements over `pre-commit run`, such as:\n  - `prek run --directory <dir>` runs hooks for files in the specified directory, no need to use `git ls-files -- <dir> | xargs pre-commit run --files` anymore.\n  - `prek run --last-commit` runs hooks for files changed in the last commit.\n  - `prek run [HOOK] [HOOK]` selects and runs multiple hooks.\n- [`prek list`](https://prek.j178.dev/cli/#prek-list) command lists all available hooks, their ids, and descriptions, providing a better overview of the configured hooks.\n- [`prek auto-update`](https://prek.j178.dev/cli/#prek-auto-update) supports `--cooldown-days` to mitigate open source supply chain attacks.\n- prek provides shell completions for `prek run <hook_id>` command, making it easier to run specific hooks without remembering their ids.\n\nFor more detailed improvements prek offers, take a look at [Difference from pre-commit](https://prek.j178.dev/diff/).\n\n## Who is using prek?\n\nprek is pretty new, but it is already being used or recommend by some projects and organizations:\n\n- [apache/airflow](https://github.com/apache/airflow/issues/44995)\n- [python/cpython](https://github.com/python/cpython/issues/143148)\n- [pdm-project/pdm](https://github.com/pdm-project/pdm/pull/3593)\n- [fastapi/fastapi](https://github.com/fastapi/fastapi/pull/14572)\n- [fastapi/typer](https://github.com/fastapi/typer/pull/1453)\n- [fastapi/asyncer](https://github.com/fastapi/asyncer/pull/437)\n- [astral-sh/ruff](https://github.com/astral-sh/ruff/pull/22505)\n- [astral-sh/ty](https://github.com/astral-sh/ty/pull/2469)\n- [home-assistant/core](https://github.com/home-assistant/core/pull/160427)\n- [DetachHead/basedpyright](https://github.com/DetachHead/basedpyright/pull/1413)\n- [OpenLineage/OpenLineage](https://github.com/OpenLineage/OpenLineage/pull/3965)\n- [authlib/authlib](https://github.com/authlib/authlib/pull/804)\n- [django/djangoproject.com](https://github.com/django/djangoproject.com/pull/2252)\n- [Future-House/paper-qa](https://github.com/Future-House/paper-qa/pull/1098)\n- [requests-cache/requests-cache](https://github.com/requests-cache/requests-cache/pull/1116)\n- [Goldziher/kreuzberg](https://github.com/Goldziher/kreuzberg/pull/142)\n- [python-attrs/attrs](https://github.com/python-attrs/attrs/commit/c95b177682e76a63478d29d040f9cb36a8d31915)\n- [jlowin/fastmcp](https://github.com/jlowin/fastmcp/pull/2309)\n- [apache/iceberg-python](https://github.com/apache/iceberg-python/pull/2533)\n- [jcrist/msgspec](https://github.com/jcrist/msgspec/pull/918)\n- [python-humanize/humanize](https://github.com/python-humanize/humanize/pull/276)\n- [MoonshotAI/kimi-cli](https://github.com/MoonshotAI/kimi-cli/pull/535)\n- [ZhuoZhuoCrayon/throttled-py](https://github.com/ZhuoZhuoCrayon/throttled-py/pull/119)\n\n<!-- why:end -->\n\n## Acknowledgements\n\nThis project is heavily inspired by the original [pre-commit](https://pre-commit.com/) tool, and it wouldn't be possible without the hard work\nof the maintainers and contributors of that project.\n\nAnd a special thanks to the [Astral](https://github.com/astral-sh) team for their remarkable projects, particularly [uv](https://github.com/astral-sh/uv),\nfrom which I've learned a lot on how to write efficient and idiomatic Rust code.\n",
      "stars_today": 34
    },
    {
      "id": 878310916,
      "name": "swark",
      "full_name": "swark-io/swark",
      "description": "Create architecture diagrams from code automatically using large language models (LLMs).",
      "html_url": "https://github.com/swark-io/swark",
      "stars": 1408,
      "forks": 95,
      "language": "TypeScript",
      "topics": [
        "architecture",
        "developer-tools",
        "language-model",
        "llm",
        "system-design",
        "visualization",
        "vscode-extension"
      ],
      "created_at": "2024-10-25T06:45:13Z",
      "updated_at": "2026-01-14T01:05:10Z",
      "pushed_at": "2025-03-21T09:51:01Z",
      "open_issues": 7,
      "owner": {
        "login": "swark-io",
        "avatar_url": "https://avatars.githubusercontent.com/u/182284829?v=4"
      },
      "readme": "<h1 align=\"center\">\n  <a href=\"https://swark.io\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"assets/logo/swark-logo-dark-mode.png\">\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"assets/logo/swark-logo-light-mode.png\">\n      <img alt=\"Swark logo\" src=\"assets/logo/swark-logo-light-mode.png\" width=\"30%\">\n    </picture>\n  </a>\n</h1>\n\n<p align=\"center\">\n  <b>Automatic Architecture Diagrams from Code</b><br />\n  Free ‚Ä¢ Open Source ‚Ä¢ Powered by LLMs\n</p>\n\n<p align=\"center\">\n  <a href=\"https://marketplace.visualstudio.com/items?itemName=swark.swark\">\n    <img src=\"https://img.shields.io/visual-studio-marketplace/v/swark.swark?label=Visual%20Studio%20Marketplace\" /></a>\n  <a href=\"https://github.com/swark-io/swark/issues\">\n    <img alt=\"GitHub Issues\" src=\"https://img.shields.io/github/issues/swark-io/swark\" /></a>\n  <a href=\"https://github.com/swark-io/swark/blob/main/CONTRIBUTING.md\">\n    <img src=\"https://img.shields.io/badge/PRs-Welcome-brightgreen\" alt=\"PRs welcome!\" />\n  </a>\n</p>\n\n## Swark\n\nSwark is a VS Code extension that allows creating architecture diagrams from code automatically using large language models (LLMs).\\\nSwark is **directly integrated with GitHub Copilot**, and requires no authentication or API key.\n\n<h1 align=\"center\">\n    <img src=\"./assets/demo.png\" width=\"85%\"/>\n</h1>\n\n### Why Swark?\n\n-   üåü **Free and Open Source**: All you need is GitHub Copilot, which is now available for free. You can review Swark‚Äôs code to understand how it works, and contribute to make it better.\n-   üåç **Universal Language Support**: Classic code visualization solutions are deterministic and require to incrementally add support in new languages or frameworks. With Swark, all the ‚Äúlogic‚Äù is encapsulated within the LLM, and therefore it natively support all languages.\n-   üîë **Seamless Integration**: Swark integrates directly with GitHub Copilot. No additional setup, authentication, or API keys required.\n-   üõ°Ô∏è **Privacy First**: Your source code is shared only with GitHub Copilot ‚Äî no other external APIs or providers involved.\n-   üßú‚Äç‚ôÄÔ∏è **Mermaid.js**: Swark generates diagrams in Mermaid.js, a popular diagram-as-code framework. You can edit and refine the diagrams as needed.\n\n### Use Cases\n\n-   üîé **Learn a New Codebase**: Instantly generate architecture diagrams to gain a high-level understanding of unfamiliar repositories. Ideal for onboarding and tackling new projects.\n-   ü§ñ **Review AI-Generated Code**: As AI-generated projects become more common, Swark helps you quickly visualize their structure and ensure they meet your standards.\n-   üìï **Improve Documentation**: Keep your documentation fresh and detailed with up-to-date architecture diagrams that take minutes to create.\n-   üï∞Ô∏è **Understand Legacy Code**: Quickly visualize and comprehend the structure of legacy codebases, making it easier to maintain and refactor.\n-   üß© **Spot Design Flaws**: Visualize your repo‚Äôs dependency graph to identify unwanted dependencies or areas for optimization.\n-   ‚úÖ **Test Coverage Insights**: Include test files in Swark‚Äôs input to see test coverage at a glance and address gaps.\n\n## Requirements\n\n-   **GitHub Copilot**: Swark is integrated with GitHub Copilot to invoke LLM queries. Install it via [Visual Studio Marketplace](https://marketplace.visualstudio.com/items?itemName=GitHub.copilot). Notice that **GitHub Copilot now offers a free tier**.\n-   **[Optional] Mermaid Markdown Preview**: To preview the diagram in VS Code you can install the [Markdown Preview Mermaid Support](https://marketplace.visualstudio.com/items?itemName=bierner.markdown-mermaid) extension. Alternatively, you can use the provided links to open it in Mermaid Live Editor.\n\n## Installation\n\nSimply install Swark via the [VS Code Extension Marketplace](https://marketplace.visualstudio.com/items?itemName=swark.swark).\n\n## How to Use\n\n1. In VS Code, open the [Command Palette](https://code.visualstudio.com/docs/getstarted/userinterface#_command-palette) and run: **Swark: Create Architecture Diagram**.\\\n   Alternatively, you can use Swark's default keybindings: `cmd+shift+r` (Mac) or `ctrl+shift+r` (Windows).\n2. Select a folder to use in Swark's file search.\n3. Within a few seconds, a tab will open displaying your architecture diagram.\n\n<h1 align=\"center\">\n    <a href=\"https://github.com/user-attachments/assets/5b885430-d958-47a0-9daa-f64542844fba\"><img src=\"https://github.com/swark-io/swark/raw/main/assets/demo.gif\" width=\"85%\" alt=\"Swark Demo\"/></a>\n</h1>\n\n### Output\n\nSwark saves its output in `swark-output` folder under your workspace root folder.\\\nOn each run, Swark creates two output files:\n\n-   **Diagram file**: Contains the diagram's Mermaid code. This file is presented when you run Swark.\\\n    Filename: `<date>__<time>__diagram.md`\n-   **Log file**: Contains information about the run, configuration, and files used to create the diagram. Can be used for debugging and issue reporting.\\\n    Filename: `<date>__<time>__log.md`\n\nFor example:\n\n```bash\nworkspace-root\n‚îî‚îÄ‚îÄ swark-output\n ¬†¬† ‚îú‚îÄ‚îÄ 2025-01-09__20-18-38__diagram.md\n ¬†¬† ‚îî‚îÄ‚îÄ 2025-01-09__20-18-38__log.md\n```\n\n## How it Works\n\n1. **File Retrieval**: Swark retrieves code files within the chosen folder. Swark automatically adjusts the number of retrieved files to match the LLM max token limit.\n2. **Prompt Building**: Based on the retrieved files, Swark builds a prompt to generate an architecture diagram. The code files are included in the prompt, together with instructions on how to build the diagram.\n3. **LLM Request**: Swark invokes LLM request to GitHub Copilot via VS Code [Language Model API](https://code.visualstudio.com/api/extension-guides/language-model).\n4. **Diagram Preview**: Upon a successful response, the diagram is presented. This is done by creating a markdown file that includes the diagram in [Mermaid](https://mermaid.js.org/) syntax and previewing it.\n\n### Code Access and File Sharing\n\nIt's important to note that source code is **only shared with GitHub Copilot**, and with no other external APIs or providers.\n\n## Extension Settings\n\nThis extension contributes the following settings:\n\n| Setting                  | Description                                                                                                                              |\n| ------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------- |\n| `swark.maxFiles`         | Max number of files to read.<br>The number of files read is also affected by the LLM max token limit.                                    |\n| `swark.fileExtensions`   | List of file extensions to include in search.                                                                                            |\n| `swark.excludePatterns`  | List of glob patterns to exclude from file search.<br>Defaults include: `**/.*` for hidden files, `**/node_modules/**` for node modules. |\n| `swark.languageModel`    | Language model to use for diagram generation.                                                                                            |\n| `swark.fixMermaidCycles` | Automatically fix cycles in the generated Mermaid diagram to prevent rendering failures.                                                 |\n\n## Release Notes\n\nSee [CHANGELOG.md](CHANGELOG.md).\n\n## Contributing\n\nSwark welcomes community contributions.\nPlease see our [Contribution Guide](CONTRIBUTING.md) for details on how to contribute.\n\n## Privacy Notice\n\nThis extension collects telemetry data to help improve the product experience. The data collected includes:\n\n-   Extension activation and usage events\n-   Selected model information\n-   Number of files processed and prompt length\n-   LLM response time\n-   Error events\n\nNo source code, file contents, or personal information is ever included in the telemetry data.\n\nWe use [@vscode/extension-telemetry](https://github.com/microsoft/vscode-extension-telemetry) module to collect this data. The data is sent to Azure Application Insights and is used solely to improve Swark's functionality and user experience.\n\nYou can disable telemetry collection by setting `\"telemetry.telemetryLevel\": \"off\"` in your VS Code settings.\n\n## License\n\nSwark is licensed under the [GNU Affero General Public License v3.0](https://github.com/swark-io/swark/blob/main/LICENSE)\n",
      "stars_today": 33
    },
    {
      "id": 531380835,
      "name": "sherpa-onnx",
      "full_name": "k2-fsa/sherpa-onnx",
      "description": "Speech-to-text, text-to-speech, speaker diarization, speech enhancement, source separation, and VAD using next-gen Kaldi with onnxruntime without Internet connection. Support embedded systems, Android, iOS, HarmonyOS, Raspberry Pi, RISC-V, RK NPU, Axera NPU, Ascend NPU, x86_64 servers, websocket server/client, support 12 programming languages",
      "html_url": "https://github.com/k2-fsa/sherpa-onnx",
      "stars": 9738,
      "forks": 1092,
      "language": "C++",
      "topics": [
        "aarch64",
        "android",
        "arm32",
        "asr",
        "cpp",
        "csharp",
        "dotnet",
        "ios",
        "lazarus",
        "linux",
        "macos",
        "mfc",
        "object-pascal",
        "onnx",
        "raspberry-pi",
        "risc-v",
        "speech-to-text",
        "text-to-speech",
        "vits",
        "windows"
      ],
      "created_at": "2022-09-01T05:47:33Z",
      "updated_at": "2026-01-13T17:33:28Z",
      "pushed_at": "2026-01-13T08:26:18Z",
      "open_issues": 506,
      "owner": {
        "login": "k2-fsa",
        "avatar_url": "https://avatars.githubusercontent.com/u/71431748?v=4"
      },
      "readme": " ### Supported functions\n\n|Speech recognition| [Speech synthesis][tts-url] | [Source separation][ss-url] |\n|------------------|------------------|-------------------|\n|   ‚úîÔ∏è              |         ‚úîÔ∏è        |       ‚úîÔ∏è           |\n\n|Speaker identification| [Speaker diarization][sd-url] | Speaker verification |\n|----------------------|-------------------- |------------------------|\n|   ‚úîÔ∏è                  |         ‚úîÔ∏è           |            ‚úîÔ∏è           |\n\n| [Spoken Language identification][slid-url] | [Audio tagging][at-url] | [Voice activity detection][vad-url] |\n|--------------------------------|---------------|--------------------------|\n|                 ‚úîÔ∏è              |          ‚úîÔ∏è    |                ‚úîÔ∏è         |\n\n| [Keyword spotting][kws-url] | [Add punctuation][punct-url] | [Speech enhancement][se-url] |\n|------------------|-----------------|--------------------|\n|     ‚úîÔ∏è            |       ‚úîÔ∏è         |      ‚úîÔ∏è             |\n\n\n### Supported platforms\n\n|Architecture| Android | iOS     | Windows    | macOS | linux | HarmonyOS |\n|------------|---------|---------|------------|-------|-------|-----------|\n|   x64      |  ‚úîÔ∏è      |         |   ‚úîÔ∏è      | ‚úîÔ∏è    |  ‚úîÔ∏è    |   ‚úîÔ∏è   |\n|   x86      |  ‚úîÔ∏è      |         |   ‚úîÔ∏è      |       |        |        |\n|   arm64    |  ‚úîÔ∏è      | ‚úîÔ∏è      |   ‚úîÔ∏è      | ‚úîÔ∏è    |  ‚úîÔ∏è    |   ‚úîÔ∏è   |\n|   arm32    |  ‚úîÔ∏è      |         |           |       |  ‚úîÔ∏è    |   ‚úîÔ∏è   |\n|   riscv64  |          |         |           |       |  ‚úîÔ∏è    |        |\n\n### Supported programming languages\n\n| 1. C++ | 2. C  | 3. Python | 4. JavaScript |\n|--------|-------|-----------|---------------|\n|   ‚úîÔ∏è    | ‚úîÔ∏è     | ‚úîÔ∏è         |    ‚úîÔ∏è          |\n\n|5. Java | 6. C# | 7. Kotlin | 8. Swift |\n|--------|-------|-----------|----------|\n| ‚úîÔ∏è      |  ‚úîÔ∏è    | ‚úîÔ∏è         |  ‚úîÔ∏è       |\n\n| 9. Go | 10. Dart | 11. Rust | 12. Pascal |\n|-------|----------|----------|------------|\n| ‚úîÔ∏è     |  ‚úîÔ∏è       |   ‚úîÔ∏è      |    ‚úîÔ∏è       |\n\nFor Rust support, please see [sherpa-rs][sherpa-rs]\n\nIt also supports WebAssembly.\n\n### Supported NPUs\n\n| [1. Rockchip NPU (RKNN)][rknpu-doc] | [2. Qualcomm NPU (QNN)][qnn-doc]  | [3. Ascend NPU][ascend-doc] |\n|-------------------------------------|-----------------------------------|-----------------------------|\n|     ‚úîÔ∏è                              |                  ‚úîÔ∏è               |     ‚úîÔ∏è                      |\n\n| [4. Axera NPU][axera-npu] |\n|---------------------------|\n|     ‚úîÔ∏è                    |\n\n[Join our discord](https://discord.gg/fJdxzg2VbG)\n\n\n## Introduction\n\nThis repository supports running the following functions **locally**\n\n  - Speech-to-text (i.e., ASR); both streaming and non-streaming are supported\n  - Text-to-speech (i.e., TTS)\n  - Speaker diarization\n  - Speaker identification\n  - Speaker verification\n  - Spoken language identification\n  - Audio tagging\n  - VAD (e.g., [silero-vad][silero-vad])\n  - Speech enhancement (e.g., [gtcrn][gtcrn])\n  - Keyword spotting\n  - Source separation (e.g., [spleeter][spleeter], [UVR][UVR])\n\non the following platforms and operating systems:\n\n  - x86, ``x86_64``, 32-bit ARM, 64-bit ARM (arm64, aarch64), RISC-V (riscv64), **RK NPU**, **Ascend NPU**\n  - Linux, macOS, Windows, openKylin\n  - Android, WearOS\n  - iOS\n  - HarmonyOS\n  - NodeJS\n  - WebAssembly\n  - [NVIDIA Jetson Orin NX][NVIDIA Jetson Orin NX] (Support running on both CPU and GPU)\n  - [NVIDIA Jetson Nano B01][NVIDIA Jetson Nano B01] (Support running on both CPU and GPU)\n  - [Raspberry Pi][Raspberry Pi]\n  - [RV1126][RV1126]\n  - [LicheePi4A][LicheePi4A]\n  - [VisionFive 2][VisionFive 2]\n  - [Êó≠Êó•X3Ê¥æ][Êó≠Êó•X3Ê¥æ]\n  - [Áà±ËäØÊ¥æ][Áà±ËäØÊ¥æ]\n  - [RK3588][RK3588]\n  - etc\n\nwith the following APIs\n\n  - C++, C, Python, Go, ``C#``\n  - Java, Kotlin, JavaScript\n  - Swift, Rust\n  - Dart, Object Pascal\n\n### Links for Huggingface Spaces\n\n<details>\n<summary>You can visit the following Huggingface spaces to try sherpa-onnx without\ninstalling anything. All you need is a browser.</summary>\n\n| Description                                           | URL                                     | ‰∏≠ÂõΩÈïúÂÉè                               |\n|-------------------------------------------------------|-----------------------------------------|----------------------------------------|\n| Speaker diarization                                   | [Click me][hf-space-speaker-diarization]| [ÈïúÂÉè][hf-space-speaker-diarization-cn]|\n| Speech recognition                                    | [Click me][hf-space-asr]                | [ÈïúÂÉè][hf-space-asr-cn]                |\n| Speech recognition with [Whisper][Whisper]            | [Click me][hf-space-asr-whisper]        | [ÈïúÂÉè][hf-space-asr-whisper-cn]        |\n| Speech synthesis                                      | [Click me][hf-space-tts]                | [ÈïúÂÉè][hf-space-tts-cn]                |\n| Generate subtitles                                    | [Click me][hf-space-subtitle]           | [ÈïúÂÉè][hf-space-subtitle-cn]           |\n| Audio tagging                                         | [Click me][hf-space-audio-tagging]      | [ÈïúÂÉè][hf-space-audio-tagging-cn]      |\n| Source separation                                     | [Click me][hf-space-source-separation]  | [ÈïúÂÉè][hf-space-source-separation-cn]  |\n| Spoken language identification with [Whisper][Whisper]| [Click me][hf-space-slid-whisper]       | [ÈïúÂÉè][hf-space-slid-whisper-cn]       |\n\nWe also have spaces built using WebAssembly. They are listed below:\n\n| Description                                                                              | Huggingface space| ModelScope space|\n|------------------------------------------------------------------------------------------|------------------|-----------------|\n|Voice activity detection with [silero-vad][silero-vad]                                    | [Click me][wasm-hf-vad]|[Âú∞ÂùÄ][wasm-ms-vad]|\n|Real-time speech recognition (Chinese + English) with Zipformer                           | [Click me][wasm-hf-streaming-asr-zh-en-zipformer]|[Âú∞ÂùÄ][wasm-hf-streaming-asr-zh-en-zipformer]|\n|Real-time speech recognition (Chinese + English) with Paraformer                          |[Click me][wasm-hf-streaming-asr-zh-en-paraformer]| [Âú∞ÂùÄ][wasm-ms-streaming-asr-zh-en-paraformer]|\n|Real-time speech recognition (Chinese + English + Cantonese) with [Paraformer-large][Paraformer-large]|[Click me][wasm-hf-streaming-asr-zh-en-yue-paraformer]| [Âú∞ÂùÄ][wasm-ms-streaming-asr-zh-en-yue-paraformer]|\n|Real-time speech recognition (English) |[Click me][wasm-hf-streaming-asr-en-zipformer]    |[Âú∞ÂùÄ][wasm-ms-streaming-asr-en-zipformer]|\n|VAD + speech recognition (Chinese) with [Zipformer CTC](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-ctc/icefall/zipformer.html#sherpa-onnx-zipformer-ctc-zh-int8-2025-07-03-chinese)|[Click me][wasm-hf-vad-asr-zh-zipformer-ctc-07-03]| [Âú∞ÂùÄ][wasm-ms-vad-asr-zh-zipformer-ctc-07-03]|\n|VAD + speech recognition (Chinese + English + Korean + Japanese + Cantonese) with [SenseVoice][SenseVoice]|[Click me][wasm-hf-vad-asr-zh-en-ko-ja-yue-sense-voice]| [Âú∞ÂùÄ][wasm-ms-vad-asr-zh-en-ko-ja-yue-sense-voice]|\n|VAD + speech recognition (English) with [Whisper][Whisper] tiny.en|[Click me][wasm-hf-vad-asr-en-whisper-tiny-en]| [Âú∞ÂùÄ][wasm-ms-vad-asr-en-whisper-tiny-en]|\n|VAD + speech recognition (English) with [Moonshine tiny][Moonshine tiny]|[Click me][wasm-hf-vad-asr-en-moonshine-tiny-en]| [Âú∞ÂùÄ][wasm-ms-vad-asr-en-moonshine-tiny-en]|\n|VAD + speech recognition (English) with Zipformer trained with [GigaSpeech][GigaSpeech]    |[Click me][wasm-hf-vad-asr-en-zipformer-gigaspeech]| [Âú∞ÂùÄ][wasm-ms-vad-asr-en-zipformer-gigaspeech]|\n|VAD + speech recognition (Chinese) with Zipformer trained with [WenetSpeech][WenetSpeech]  |[Click me][wasm-hf-vad-asr-zh-zipformer-wenetspeech]| [Âú∞ÂùÄ][wasm-ms-vad-asr-zh-zipformer-wenetspeech]|\n|VAD + speech recognition (Japanese) with Zipformer trained with [ReazonSpeech][ReazonSpeech]|[Click me][wasm-hf-vad-asr-ja-zipformer-reazonspeech]| [Âú∞ÂùÄ][wasm-ms-vad-asr-ja-zipformer-reazonspeech]|\n|VAD + speech recognition (Thai) with Zipformer trained with [GigaSpeech2][GigaSpeech2]      |[Click me][wasm-hf-vad-asr-th-zipformer-gigaspeech2]| [Âú∞ÂùÄ][wasm-ms-vad-asr-th-zipformer-gigaspeech2]|\n|VAD + speech recognition (Chinese Â§öÁßçÊñπË®Ä) with a [TeleSpeech-ASR][TeleSpeech-ASR] CTC model|[Click me][wasm-hf-vad-asr-zh-telespeech]| [Âú∞ÂùÄ][wasm-ms-vad-asr-zh-telespeech]|\n|VAD + speech recognition (English + Chinese, ÂèäÂ§öÁßç‰∏≠ÊñáÊñπË®Ä) with Paraformer-large          |[Click me][wasm-hf-vad-asr-zh-en-paraformer-large]| [Âú∞ÂùÄ][wasm-ms-vad-asr-zh-en-paraformer-large]|\n|VAD + speech recognition (English + Chinese, ÂèäÂ§öÁßç‰∏≠ÊñáÊñπË®Ä) with Paraformer-small          |[Click me][wasm-hf-vad-asr-zh-en-paraformer-small]| [Âú∞ÂùÄ][wasm-ms-vad-asr-zh-en-paraformer-small]|\n|VAD + speech recognition (Â§öËØ≠ÁßçÂèäÂ§öÁßç‰∏≠ÊñáÊñπË®Ä) with [Dolphin][Dolphin]-base          |[Click me][wasm-hf-vad-asr-multi-lang-dolphin-base]| [Âú∞ÂùÄ][wasm-ms-vad-asr-multi-lang-dolphin-base]|\n|Speech synthesis (Piper, English)                                                                  |[Click me][wasm-hf-tts-piper-en]| [Âú∞ÂùÄ][wasm-ms-tts-piper-en]|\n|Speech synthesis (Piper, German)                                                                   |[Click me][wasm-hf-tts-piper-de]| [Âú∞ÂùÄ][wasm-ms-tts-piper-de]|\n|Speech synthesis (Matcha, Chinese)                                                                  |[Click me][wasm-hf-tts-matcha-zh]| [Âú∞ÂùÄ][wasm-ms-tts-matcha-zh]|\n|Speech synthesis (Matcha, English)                                                                  |[Click me][wasm-hf-tts-matcha-en]| [Âú∞ÂùÄ][wasm-ms-tts-matcha-en]|\n|Speech synthesis (Matcha, Chinese+English)                                                          |[Click me][wasm-hf-tts-matcha-zh-en]| [Âú∞ÂùÄ][wasm-ms-tts-matcha-zh-en]|\n|Speaker diarization                                                                         |[Click me][wasm-hf-speaker-diarization]|[Âú∞ÂùÄ][wasm-ms-speaker-diarization]|\n\n</details>\n\n### Links for pre-built Android APKs\n\n<details>\n\n<summary>You can find pre-built Android APKs for this repository in the following table</summary>\n\n| Description                            | URL                                | ‰∏≠ÂõΩÁî®Êà∑                          |\n|----------------------------------------|------------------------------------|-----------------------------------|\n| Speaker diarization                    | [Address][apk-speaker-diarization] | [ÁÇπÊ≠§][apk-speaker-diarization-cn]|\n| Streaming speech recognition           | [Address][apk-streaming-asr]       | [ÁÇπÊ≠§][apk-streaming-asr-cn]      |\n| Simulated-streaming speech recognition | [Address][apk-simula-streaming-asr]| [ÁÇπÊ≠§][apk-simula-streaming-asr-cn]|\n| Text-to-speech                         | [Address][apk-tts]                 | [ÁÇπÊ≠§][apk-tts-cn]                |\n| Voice activity detection (VAD)         | [Address][apk-vad]                 | [ÁÇπÊ≠§][apk-vad-cn]                |\n| VAD + non-streaming speech recognition | [Address][apk-vad-asr]             | [ÁÇπÊ≠§][apk-vad-asr-cn]            |\n| Two-pass speech recognition            | [Address][apk-2pass]               | [ÁÇπÊ≠§][apk-2pass-cn]              |\n| Audio tagging                          | [Address][apk-at]                  | [ÁÇπÊ≠§][apk-at-cn]                 |\n| Audio tagging (WearOS)                 | [Address][apk-at-wearos]           | [ÁÇπÊ≠§][apk-at-wearos-cn]          |\n| Speaker identification                 | [Address][apk-sid]                 | [ÁÇπÊ≠§][apk-sid-cn]                |\n| Spoken language identification         | [Address][apk-slid]                | [ÁÇπÊ≠§][apk-slid-cn]               |\n| Keyword spotting                       | [Address][apk-kws]                 | [ÁÇπÊ≠§][apk-kws-cn]                |\n\n</details>\n\n### Links for pre-built Flutter APPs\n\n<details>\n\n#### Real-time speech recognition\n\n| Description                    | URL                                 | ‰∏≠ÂõΩÁî®Êà∑                            |\n|--------------------------------|-------------------------------------|-------------------------------------|\n| Streaming speech recognition   | [Address][apk-flutter-streaming-asr]| [ÁÇπÊ≠§][apk-flutter-streaming-asr-cn]|\n\n#### Text-to-speech\n\n| Description                              | URL                                | ‰∏≠ÂõΩÁî®Êà∑                           |\n|------------------------------------------|------------------------------------|------------------------------------|\n| Android (arm64-v8a, armeabi-v7a, x86_64) | [Address][flutter-tts-android]     | [ÁÇπÊ≠§][flutter-tts-android-cn]     |\n| Linux (x64)                              | [Address][flutter-tts-linux]       | [ÁÇπÊ≠§][flutter-tts-linux-cn]       |\n| macOS (x64)                              | [Address][flutter-tts-macos-x64]   | [ÁÇπÊ≠§][flutter-tts-macos-x64-cn] |\n| macOS (arm64)                            | [Address][flutter-tts-macos-arm64] | [ÁÇπÊ≠§][flutter-tts-macos-arm64-cn]   |\n| Windows (x64)                            | [Address][flutter-tts-win-x64]     | [ÁÇπÊ≠§][flutter-tts-win-x64-cn]     |\n\n> Note: You need to build from source for iOS.\n\n</details>\n\n### Links for pre-built Lazarus APPs\n\n<details>\n\n#### Generating subtitles\n\n| Description                    | URL                        | ‰∏≠ÂõΩÁî®Êà∑                   |\n|--------------------------------|----------------------------|----------------------------|\n| Generate subtitles (ÁîüÊàêÂ≠óÂπï)  | [Address][lazarus-subtitle]| [ÁÇπÊ≠§][lazarus-subtitle-cn]|\n\n</details>\n\n### Links for pre-trained models\n\n<details>\n\n| Description                                 | URL                                                                                   |\n|---------------------------------------------|---------------------------------------------------------------------------------------|\n| Speech recognition (speech to text, ASR)    | [Address][asr-models]                                                                 |\n| Text-to-speech (TTS)                        | [Address][tts-models]                                                                 |\n| VAD                                         | [Address][vad-models]                                                                 |\n| Keyword spotting                            | [Address][kws-models]                                                                 |\n| Audio tagging                               | [Address][at-models]                                                                  |\n| Speaker identification (Speaker ID)         | [Address][sid-models]                                                                 |\n| Spoken language identification (Language ID)| See multi-lingual [Whisper][Whisper] ASR models from  [Speech recognition][asr-models]|\n| Punctuation                                 | [Address][punct-models]                                                               |\n| Speaker segmentation                        | [Address][speaker-segmentation-models]                                                |\n| Speech enhancement                          | [Address][speech-enhancement-models]                                                  |\n| Source separation                           | [Address][source-separation-models]                                                  |\n\n</details>\n\n#### Some pre-trained ASR models (Streaming)\n\n<details>\n\nPlease see\n\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-paraformer/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-ctc/index.html>\n\nfor more models. The following table lists only **SOME** of them.\n\n\n|Name | Supported Languages| Description|\n|-----|-----|----|\n|[sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20][sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20]| Chinese, English| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20-bilingual-chinese-english)|\n|[sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16][sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16]| Chinese, English| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16-bilingual-chinese-english)|\n|[sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23][sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23]|Chinese| Suitable for Cortex A7 CPU. See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-zh-14m-2023-02-23)|\n|[sherpa-onnx-streaming-zipformer-en-20M-2023-02-17][sherpa-onnx-streaming-zipformer-en-20M-2023-02-17]|English|Suitable for Cortex A7 CPU. See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-en-20m-2023-02-17)|\n|[sherpa-onnx-streaming-zipformer-korean-2024-06-16][sherpa-onnx-streaming-zipformer-korean-2024-06-16]|Korean| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-korean-2024-06-16-korean)|\n|[sherpa-onnx-streaming-zipformer-fr-2023-04-14][sherpa-onnx-streaming-zipformer-fr-2023-04-14]|French| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#shaojieli-sherpa-onnx-streaming-zipformer-fr-2023-04-14-french)|\n\n</details>\n\n\n#### Some pre-trained ASR models (Non-Streaming)\n\n<details>\n\nPlease see\n\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-paraformer/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-ctc/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/telespeech/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/whisper/index.html>\n\nfor more models. The following table lists only **SOME** of them.\n\n|Name | Supported Languages| Description|\n|-----|-----|----|\n|[sherpa-onnx-nemo-parakeet-tdt-0.6b-v2-int8](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/nemo-transducer-models.html#sherpa-onnx-nemo-parakeet-tdt-0-6b-v2-int8-english)| English | It is converted from <https://huggingface.co/nvidia/parakeet-tdt-0.6b-v2>|\n|[Whisper tiny.en](https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-whisper-tiny.en.tar.bz2)|English| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/whisper/tiny.en.html)|\n|[Moonshine tiny][Moonshine tiny]|English|See [also](https://github.com/usefulsensors/moonshine)|\n|[sherpa-onnx-zipformer-ctc-zh-int8-2025-07-03](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-ctc/icefall/zipformer.html#sherpa-onnx-zipformer-ctc-zh-int8-2025-07-03-chinese)|Chinese| A Zipformer CTC model|\n|[sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17][sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17]|Chinese, Cantonese, English, Korean, Japanese| ÊîØÊåÅÂ§öÁßç‰∏≠ÊñáÊñπË®Ä. See [also](https://k2-fsa.github.io/sherpa/onnx/sense-voice/index.html)|\n|[sherpa-onnx-paraformer-zh-2024-03-09][sherpa-onnx-paraformer-zh-2024-03-09]|Chinese, English| ‰πüÊîØÊåÅÂ§öÁßç‰∏≠ÊñáÊñπË®Ä. See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-zh-2024-03-09-chinese-english)|\n|[sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01][sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01]|Japanese|See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01-japanese)|\n|[sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24][sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24]|Russian|See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/nemo-transducer-models.html#sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24-russian)|\n|[sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24][sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24]|Russian| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-ctc/nemo/russian.html#sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24)|\n|[sherpa-onnx-zipformer-ru-2024-09-18][sherpa-onnx-zipformer-ru-2024-09-18]|Russian|See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-ru-2024-09-18-russian)|\n|[sherpa-onnx-zipformer-korean-2024-06-24][sherpa-onnx-zipformer-korean-2024-06-24]|Korean|See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-korean-2024-06-24-korean)|\n|[sherpa-onnx-zipformer-thai-2024-06-20][sherpa-onnx-zipformer-thai-2024-06-20]|Thai| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-thai-2024-06-20-thai)|\n|[sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04][sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04]|Chinese| ÊîØÊåÅÂ§öÁßçÊñπË®Ä. See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/telespeech/models.html#sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04)|\n\n</details>\n\n### Useful links\n\n- Documentation: https://k2-fsa.github.io/sherpa/onnx/\n- Bilibili ÊºîÁ§∫ËßÜÈ¢ë: https://search.bilibili.com/all?keyword=%E6%96%B0%E4%B8%80%E4%BB%A3Kaldi\n\n### How to reach us\n\nPlease see\nhttps://k2-fsa.github.io/sherpa/social-groups.html\nfor Êñ∞‰∏Ä‰ª£ Kaldi **ÂæÆ‰ø°‰∫§ÊµÅÁæ§** and **QQ ‰∫§ÊµÅÁæ§**.\n\n## Projects using sherpa-onnx\n\n### [BreezeApp](https://github.com/mtkresearch/BreezeApp) from [MediaTek Research](https://github.com/mtkresearch)\n\n> BreezeAPP is a mobile AI application developed for both Android and iOS platforms.\n> Users can download it directly from the App Store and enjoy a variety of features\n> offline, including speech-to-text, text-to-speech, text-based chatbot interactions,\n> and image question-answering\n\n  - [Download APK for BreezeAPP](https://huggingface.co/MediaTek-Research/BreezeApp/resolve/main/BreezeApp.apk)\n  - [APK ‰∏≠ÂõΩÈïúÂÉè](https://hf-mirror.com/MediaTek-Research/BreezeApp/blob/main/BreezeApp.apk)\n\n| 1 | 2 | 3 |\n|---|---|---|\n|![](https://github.com/user-attachments/assets/1cdbc057-b893-4de6-9e9c-f1d7dfd1d992)|![](https://github.com/user-attachments/assets/d77cd98e-b057-442f-860d-d5befd5c769b)|![](https://github.com/user-attachments/assets/57e546bf-3d39-45b9-b392-b48ca4fb3c58)|\n\n### [Open-LLM-VTuber](https://github.com/t41372/Open-LLM-VTuber)\n\nTalk to any LLM with hands-free voice interaction, voice interruption, and Live2D taking\nface running locally across platforms\n\nSee also <https://github.com/t41372/Open-LLM-VTuber/pull/50>\n\n### [voiceapi](https://github.com/ruzhila/voiceapi)\n\n<details>\n  <summary>Streaming ASR and TTS based on FastAPI</summary>\n\n\nIt shows how to use the ASR and TTS Python APIs with FastAPI.\n</details>\n\n### [ËÖæËÆØ‰ºöËÆÆÊë∏È±ºÂ∑•ÂÖ∑ TMSpeech](https://github.com/jxlpzqc/TMSpeech)\n\nUses streaming ASR in C# with graphical user interface.\n\nVideo demo in Chinese: [„ÄêÂºÄÊ∫ê„ÄëWindowsÂÆûÊó∂Â≠óÂπïËΩØ‰ª∂ÔºàÁΩëËØæ/ÂºÄ‰ºöÂøÖÂ§áÔºâ](https://www.bilibili.com/video/BV1rX4y1p7Nx)\n\n### [lol‰∫íÂä®Âä©Êâã](https://github.com/l1veIn/lol-wom-electron)\n\nIt uses the JavaScript API of sherpa-onnx along with [Electron](https://electronjs.org/)\n\nVideo demo in Chinese: [ÁàÜ‰∫ÜÔºÅÁÇ´Á•ûÊïô‰Ω†ÂºÄÊâìÂ≠óÊåÇÔºÅÁúüÊ≠£ÂΩ±ÂìçËÉúÁéáÁöÑËã±ÈõÑËÅîÁõüÂ∑•ÂÖ∑ÔºÅËã±ÈõÑËÅîÁõüÁöÑÊúÄÂêé‰∏ÄÂùóÊãºÂõæÔºÅÂíåÊ∏∏Êàè‰∏≠ÁöÑÊØè‰∏™‰∫∫Êó†ÈöúÁ¢çÊ≤üÈÄöÔºÅ](https://www.bilibili.com/video/BV142tje9E74)\n\n### [Sherpa-ONNX ËØ≠Èü≥ËØÜÂà´ÊúçÂä°Âô®](https://github.com/hfyydd/sherpa-onnx-server)\n\nA server based on nodejs providing Restful API for speech recognition.\n\n### [QSmartAssistant](https://github.com/xinhecuican/QSmartAssistant)\n\n‰∏Ä‰∏™Ê®°ÂùóÂåñÔºåÂÖ®ËøáÁ®ãÂèØÁ¶ªÁ∫øÔºå‰ΩéÂç†Áî®ÁéáÁöÑÂØπËØùÊú∫Âô®‰∫∫/Êô∫ËÉΩÈü≥ÁÆ±\n\nIt uses QT. Both [ASR](https://github.com/xinhecuican/QSmartAssistant/blob/master/doc/%E5%AE%89%E8%A3%85.md#asr)\nand [TTS](https://github.com/xinhecuican/QSmartAssistant/blob/master/doc/%E5%AE%89%E8%A3%85.md#tts)\nare used.\n\n### [Flutter-EasySpeechRecognition](https://github.com/Jason-chen-coder/Flutter-EasySpeechRecognition)\n\nIt extends [./flutter-examples/streaming_asr](./flutter-examples/streaming_asr) by\ndownloading models inside the app to reduce the size of the app.\n\nNote: [[Team B] Sherpa AI backend](https://github.com/umgc/spring2025/pull/82) also uses\nsherpa-onnx in a Flutter APP.\n\n### [sherpa-onnx-unity](https://github.com/xue-fei/sherpa-onnx-unity)\n\nsherpa-onnx in Unity. See also [#1695](https://github.com/k2-fsa/sherpa-onnx/issues/1695),\n[#1892](https://github.com/k2-fsa/sherpa-onnx/issues/1892), and [#1859](https://github.com/k2-fsa/sherpa-onnx/issues/1859)\n\n### [xiaozhi-esp32-server](https://github.com/xinnan-tech/xiaozhi-esp32-server)\n\nÊú¨È°πÁõÆ‰∏∫xiaozhi-esp32Êèê‰æõÂêéÁ´ØÊúçÂä°ÔºåÂ∏ÆÂä©ÊÇ®Âø´ÈÄüÊê≠Âª∫ESP32ËÆæÂ§áÊéßÂà∂ÊúçÂä°Âô®\nBackend service for xiaozhi-esp32, helps you quickly build an ESP32 device control server.\n\nSee also\n\n  - [ASRÊñ∞Â¢ûËΩªÈáèÁ∫ßsherpa-onnx-asr](https://github.com/xinnan-tech/xiaozhi-esp32-server/issues/315)\n  - [feat: ASRÂ¢ûÂä†sherpa-onnxÊ®°Âûã](https://github.com/xinnan-tech/xiaozhi-esp32-server/pull/379)\n\n### [KaithemAutomation](https://github.com/EternityForest/KaithemAutomation)\n\nPure Python, GUI-focused home automation/consumer grade SCADA.\n\nIt uses TTS from sherpa-onnx. See also [‚ú® Speak command that uses the new globally configured TTS model.](https://github.com/EternityForest/KaithemAutomation/commit/8e64d2b138725e426532f7d66bb69dd0b4f53693)\n\n### [Open-XiaoAI KWS](https://github.com/idootop/open-xiaoai-kws)\n\nEnable custom wake word for XiaoAi Speakers. ËÆ©Â∞èÁà±Èü≥ÁÆ±ÊîØÊåÅËá™ÂÆö‰πâÂî§ÈÜíËØç„ÄÇ\n\nVideo demo in Chinese: [Â∞èÁà±ÂêåÂ≠¶ÂêØÂä®ÔΩûÀ∂‚ïπÍá¥‚ïπÀ∂ÔºÅ](https://www.bilibili.com/video/BV1YfVUz5EMj)\n\n### [C++ WebSocket ASR Server](https://github.com/mawwalker/stt-server)\n\nIt provides a WebSocket server based on C++ for ASR using sherpa-onnx.\n\n### [Go WebSocket Server](https://github.com/bbeyondllove/asr_server)\n\nIt provides a WebSocket server based on the Go programming language for sherpa-onnx.\n\n### [Making robot Paimon, Ep10 \"The AI Part 1\"](https://www.youtube.com/watch?v=KxPKkwxGWZs)\n\nIt is a [YouTube video](https://www.youtube.com/watch?v=KxPKkwxGWZs),\nshowing how the author tried to use AI so he can have a conversation with Paimon.\n\nIt uses sherpa-onnx for speech-to-text and text-to-speech.\n|1|\n|---|\n|![](https://github.com/user-attachments/assets/f6eea2d5-1807-42cb-9160-be8da2971e1f)|\n\n### [TtsReader - Desktop application](https://github.com/ys-pro-duction/TtsReader)\n\nA desktop text-to-speech application built using Kotlin Multiplatform.\n\n### [MentraOS](https://github.com/Mentra-Community/MentraOS)\n\n> Smart glasses OS, with dozens of built-in apps. Users get AI assistant, notifications,\n> translation, screen mirror, captions, and more. Devs get to write 1 app that runs on\n> any pair of smart glasses.\n\nIt uses sherpa-onnx for real-time speech recognition on iOS and Android devices.\nSee also <https://github.com/Mentra-Community/MentraOS/pull/861>\n\nIt uses Swift for iOS and Java for Android.\n\n### [flet_sherpa_onnx](https://github.com/SamYuan1990/flet_sherpa_onnx)\n\nFlet ASR/STT component based on sherpa-onnx.\nExample [a chat box agent](https://github.com/SamYuan1990/i18n-agent-action)\n\n### [achatbot-go](https://github.com/ai-bot-pro/achatbot-go)\n\na multimodal chatbot based on go with sherpa-onnx's speech lib api.\n\n[sherpa-rs]: https://github.com/thewh1teagle/sherpa-rs\n[silero-vad]: https://github.com/snakers4/silero-vad\n[Raspberry Pi]: https://www.raspberrypi.com/\n[RV1126]: https://www.rock-chips.com/uploads/pdf/2022.8.26/191/RV1126%20Brief%20Datasheet.pdf\n[LicheePi4A]: https://sipeed.com/licheepi4a\n[VisionFive 2]: https://www.starfivetech.com/en/site/boards\n[Êó≠Êó•X3Ê¥æ]: https://developer.horizon.ai/api/v1/fileData/documents_pi/index.html\n[Áà±ËäØÊ¥æ]: https://wiki.sipeed.com/hardware/zh/maixIII/ax-pi/axpi.html\n[hf-space-speaker-diarization]: https://huggingface.co/spaces/k2-fsa/speaker-diarization\n[hf-space-speaker-diarization-cn]: https://hf.qhduan.com/spaces/k2-fsa/speaker-diarization\n[hf-space-asr]: https://huggingface.co/spaces/k2-fsa/automatic-speech-recognition\n[hf-space-asr-cn]: https://hf.qhduan.com/spaces/k2-fsa/automatic-speech-recognition\n[Whisper]: https://github.com/openai/whisper\n[hf-space-asr-whisper]: https://huggingface.co/spaces/k2-fsa/automatic-speech-recognition-with-whisper\n[hf-space-asr-whisper-cn]: https://hf.qhduan.com/spaces/k2-fsa/automatic-speech-recognition-with-whisper\n[hf-space-tts]: https://huggingface.co/spaces/k2-fsa/text-to-speech\n[hf-space-tts-cn]: https://hf.qhduan.com/spaces/k2-fsa/text-to-speech\n[hf-space-subtitle]: https://huggingface.co/spaces/k2-fsa/generate-subtitles-for-videos\n[hf-space-subtitle-cn]: https://hf.qhduan.com/spaces/k2-fsa/generate-subtitles-for-videos\n[hf-space-audio-tagging]: https://huggingface.co/spaces/k2-fsa/audio-tagging\n[hf-space-audio-tagging-cn]: https://hf.qhduan.com/spaces/k2-fsa/audio-tagging\n[hf-space-source-separation]: https://huggingface.co/spaces/k2-fsa/source-separation\n[hf-space-source-separation-cn]: https://hf.qhduan.com/spaces/k2-fsa/source-separation\n[hf-space-slid-whisper]: https://huggingface.co/spaces/k2-fsa/spoken-language-identification\n[hf-space-slid-whisper-cn]: https://hf.qhduan.com/spaces/k2-fsa/spoken-language-identification\n[wasm-hf-vad]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-sherpa-onnx\n[wasm-ms-vad]: https://modelscope.cn/studios/csukuangfj/web-assembly-vad-sherpa-onnx\n[wasm-hf-streaming-asr-zh-en-zipformer]: https://huggingface.co/spaces/k2-fsa/web-assembly-asr-sherpa-onnx-zh-en\n[wasm-ms-streaming-asr-zh-en-zipformer]: https://modelscope.cn/studios/k2-fsa/web-assembly-asr-sherpa-onnx-zh-en\n[wasm-hf-streaming-asr-zh-en-paraformer]: https://huggingface.co/spaces/k2-fsa/web-assembly-asr-sherpa-onnx-zh-en-paraformer\n[wasm-ms-streaming-asr-zh-en-paraformer]: https://modelscope.cn/studios/k2-fsa/web-assembly-asr-sherpa-onnx-zh-en-paraformer\n[Paraformer-large]: https://www.modelscope.cn/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/summary\n[wasm-hf-streaming-asr-zh-en-yue-paraformer]: https://huggingface.co/spaces/k2-fsa/web-assembly-asr-sherpa-onnx-zh-cantonese-en-paraformer\n[wasm-ms-streaming-asr-zh-en-yue-paraformer]: https://modelscope.cn/studios/k2-fsa/web-assembly-asr-sherpa-onnx-zh-cantonese-en-paraformer\n[wasm-hf-streaming-asr-en-zipformer]: https://huggingface.co/spaces/k2-fsa/web-assembly-asr-sherpa-onnx-en\n[wasm-ms-streaming-asr-en-zipformer]: https://modelscope.cn/studios/k2-fsa/web-assembly-asr-sherpa-onnx-en\n[SenseVoice]: https://github.com/FunAudioLLM/SenseVoice\n[wasm-hf-vad-asr-zh-zipformer-ctc-07-03]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-zipformer-ctc\n[wasm-ms-vad-asr-zh-zipformer-ctc-07-03]: https://modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-zh-zipformer-ctc/summary\n[wasm-hf-vad-asr-zh-en-ko-ja-yue-sense-voice]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-ja-ko-cantonese-sense-voice\n[wasm-ms-vad-asr-zh-en-ko-ja-yue-sense-voice]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-zh-en-jp-ko-cantonese-sense-voice\n[wasm-hf-vad-asr-en-whisper-tiny-en]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-en-whisper-tiny\n[wasm-ms-vad-asr-en-whisper-tiny-en]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-en-whisper-tiny\n[wasm-hf-vad-asr-en-moonshine-tiny-en]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-en-moonshine-tiny\n[wasm-ms-vad-asr-en-moonshine-tiny-en]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-en-moonshine-tiny\n[wasm-hf-vad-asr-en-zipformer-gigaspeech]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-en-zipformer-gigaspeech\n[wasm-ms-vad-asr-en-zipformer-gigaspeech]: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-en-zipformer-gigaspeech\n[wasm-hf-vad-asr-zh-zipformer-wenetspeech]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-zipformer-wenetspeech\n[wasm-ms-vad-asr-zh-zipformer-wenetspeech]: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-zipformer-wenetspeech\n[reazonspeech]: https://research.reazon.jp/_static/reazonspeech_nlp2023.pdf\n[wasm-hf-vad-asr-ja-zipformer-reazonspeech]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-ja-zipformer\n[wasm-ms-vad-asr-ja-zipformer-reazonspeech]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-ja-zipformer\n[gigaspeech2]: https://github.com/speechcolab/gigaspeech2\n[wasm-hf-vad-asr-th-zipformer-gigaspeech2]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-th-zipformer\n[wasm-ms-vad-asr-th-zipformer-gigaspeech2]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-th-zipformer\n[telespeech-asr]: https://github.com/tele-ai/telespeech-asr\n[wasm-hf-vad-asr-zh-telespeech]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-telespeech\n[wasm-ms-vad-asr-zh-telespeech]: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-telespeech\n[wasm-hf-vad-asr-zh-en-paraformer-large]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-paraformer\n[wasm-ms-vad-asr-zh-en-paraformer-large]: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-paraformer\n[wasm-hf-vad-asr-zh-en-paraformer-small]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-paraformer-small\n[wasm-ms-vad-asr-zh-en-paraformer-small]: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-paraformer-small\n[dolphin]: https://github.com/dataoceanai/dolphin\n[wasm-ms-vad-asr-multi-lang-dolphin-base]: https://modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-multi-lang-dophin-ctc\n[wasm-hf-vad-asr-multi-lang-dolphin-base]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-multi-lang-dophin-ctc\n\n[wasm-hf-tts-matcha-zh-en]: https://huggingface.co/spaces/k2-fsa/web-assembly-zh-en-tts-matcha\n[wasm-hf-tts-matcha-zh]: https://huggingface.co/spaces/k2-fsa/web-assembly-zh-tts-matcha\n[wasm-ms-tts-matcha-zh-en]: https://modelscope.cn/studios/csukuangfj/web-assembly-zh-en-tts-matcha\n[wasm-ms-tts-matcha-zh]: https://modelscope.cn/studios/csukuangfj/web-assembly-zh-tts-matcha\n[wasm-hf-tts-matcha-en]: https://huggingface.co/spaces/k2-fsa/web-assembly-en-tts-matcha\n[wasm-ms-tts-matcha-en]: https://modelscope.cn/studios/csukuangfj/web-assembly-en-tts-matcha\n[wasm-hf-tts-piper-en]: https://huggingface.co/spaces/k2-fsa/web-assembly-tts-sherpa-onnx-en\n[wasm-ms-tts-piper-en]: https://modelscope.cn/studios/k2-fsa/web-assembly-tts-sherpa-onnx-en\n[wasm-hf-tts-piper-de]: https://huggingface.co/spaces/k2-fsa/web-assembly-tts-sherpa-onnx-de\n[wasm-ms-tts-piper-de]: https://modelscope.cn/studios/k2-fsa/web-assembly-tts-sherpa-onnx-de\n[wasm-hf-speaker-diarization]: https://huggingface.co/spaces/k2-fsa/web-assembly-speaker-diarization-sherpa-onnx\n[wasm-ms-speaker-diarization]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-speaker-diarization-sherpa-onnx\n[apk-speaker-diarization]: https://k2-fsa.github.io/sherpa/onnx/speaker-diarization/apk.html\n[apk-speaker-diarization-cn]: https://k2-fsa.github.io/sherpa/onnx/speaker-diarization/apk-cn.html\n[apk-streaming-asr]: https://k2-fsa.github.io/sherpa/onnx/android/apk.html\n[apk-streaming-asr-cn]: https://k2-fsa.github.io/sherpa/onnx/android/apk-cn.html\n[apk-simula-streaming-asr]: https://k2-fsa.github.io/sherpa/onnx/android/apk-simulate-streaming-asr.html\n[apk-simula-streaming-asr-cn]: https://k2-fsa.github.io/sherpa/onnx/android/apk-simulate-streaming-asr-cn.html\n[apk-tts]: https://k2-fsa.github.io/sherpa/onnx/tts/apk-engine.html\n[apk-tts-cn]: https://k2-fsa.github.io/sherpa/onnx/tts/apk-engine-cn.html\n[apk-vad]: https://k2-fsa.github.io/sherpa/onnx/vad/apk.html\n[apk-vad-cn]: https://k2-fsa.github.io/sherpa/onnx/vad/apk-cn.html\n[apk-vad-asr]: https://k2-fsa.github.io/sherpa/onnx/vad/apk-asr.html\n[apk-vad-asr-cn]: https://k2-fsa.github.io/sherpa/onnx/vad/apk-asr-cn.html\n[apk-2pass]: https://k2-fsa.github.io/sherpa/onnx/android/apk-2pass.html\n[apk-2pass-cn]: https://k2-fsa.github.io/sherpa/onnx/android/apk-2pass-cn.html\n[apk-at]: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/apk.html\n[apk-at-cn]: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/apk-cn.html\n[apk-at-wearos]: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/apk-wearos.html\n[apk-at-wearos-cn]: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/apk-wearos-cn.html\n[apk-sid]: https://k2-fsa.github.io/sherpa/onnx/speaker-identification/apk.html\n[apk-sid-cn]: https://k2-fsa.github.io/sherpa/onnx/speaker-identification/apk-cn.html\n[apk-slid]: https://k2-fsa.github.io/sherpa/onnx/spoken-language-identification/apk.html\n[apk-slid-cn]: https://k2-fsa.github.io/sherpa/onnx/spoken-language-identification/apk-cn.html\n[apk-kws]: https://k2-fsa.github.io/sherpa/onnx/kws/apk.html\n[apk-kws-cn]: https://k2-fsa.github.io/sherpa/onnx/kws/apk-cn.html\n[apk-flutter-streaming-asr]: https://k2-fsa.github.io/sherpa/onnx/flutter/asr/app.html\n[apk-flutter-streaming-asr-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/asr/app-cn.html\n[flutter-tts-android]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-android.html\n[flutter-tts-android-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-android-cn.html\n[flutter-tts-linux]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-linux.html\n[flutter-tts-linux-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-linux-cn.html\n[flutter-tts-macos-x64]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-macos-x64.html\n[flutter-tts-macos-arm64-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-macos-arm64-cn.html\n[flutter-tts-macos-arm64]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-macos-arm64.html\n[flutter-tts-macos-x64-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-macos-x64-cn.html\n[flutter-tts-win-x64]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-win.html\n[flutter-tts-win-x64-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-win-cn.html\n[lazarus-subtitle]: https://k2-fsa.github.io/sherpa/onnx/lazarus/download-generated-subtitles.html\n[lazarus-subtitle-cn]: https://k2-fsa.github.io/sherpa/onnx/lazarus/download-generated-subtitles-cn.html\n[asr-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/asr-models\n[tts-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/tts-models\n[vad-models]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/silero_vad.onnx\n[kws-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/kws-models\n[at-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/audio-tagging-models\n[sid-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/speaker-recongition-models\n[slid-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/speaker-recongition-models\n[punct-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/punctuation-models\n[speaker-segmentation-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/speaker-segmentation-models\n[GigaSpeech]: https://github.com/SpeechColab/GigaSpeech\n[WenetSpeech]: https://github.com/wenet-e2e/WenetSpeech\n[sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20.tar.bz2\n[sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16.tar.bz2\n[sherpa-onnx-streaming-zipformer-korean-2024-06-16]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-korean-2024-06-16.tar.bz2\n[sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23.tar.bz2\n[sherpa-onnx-streaming-zipformer-en-20M-2023-02-17]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-en-20M-2023-02-17.tar.bz2\n[sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01.tar.bz2\n[sherpa-onnx-zipformer-ru-2024-09-18]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-ru-2024-09-18.tar.bz2\n[sherpa-onnx-zipformer-korean-2024-06-24]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-korean-2024-06-24.tar.bz2\n[sherpa-onnx-zipformer-thai-2024-06-20]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-thai-2024-06-20.tar.bz2\n[sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24.tar.bz2\n[sherpa-onnx-paraformer-zh-2024-03-09]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-paraformer-zh-2024-03-09.tar.bz2\n[sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24.tar.bz2\n[sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04.tar.bz2\n[sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17.tar.bz2\n[sherpa-onnx-streaming-zipformer-fr-2023-04-14]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-fr-2023-04-14.tar.bz2\n[Moonshine tiny]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-moonshine-tiny-en-int8.tar.bz2\n[NVIDIA Jetson Orin NX]: https://developer.download.nvidia.com/assets/embedded/secure/jetson/orin_nx/docs/Jetson_Orin_NX_DS-10712-001_v0.5.pdf?RCPGu9Q6OVAOv7a7vgtwc9-BLScXRIWq6cSLuditMALECJ_dOj27DgnqAPGVnT2VpiNpQan9SyFy-9zRykR58CokzbXwjSA7Gj819e91AXPrWkGZR3oS1VLxiDEpJa_Y0lr7UT-N4GnXtb8NlUkP4GkCkkF_FQivGPrAucCUywL481GH_WpP_p7ziHU1Wg==&t=eyJscyI6ImdzZW8iLCJsc2QiOiJodHRwczovL3d3dy5nb29nbGUuY29tLmhrLyJ9\n[NVIDIA Jetson Nano B01]: https://www.seeedstudio.com/blog/2020/01/16/new-revision-of-jetson-nano-dev-kit-now-supports-new-jetson-nano-module/\n[speech-enhancement-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/speech-enhancement-models\n[source-separation-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/source-separation-models\n[RK3588]: https://www.rock-chips.com/uploads/pdf/2022.8.26/192/RK3588%20Brief%20Datasheet.pdf\n[spleeter]: https://github.com/deezer/spleeter\n[UVR]: https://github.com/Anjok07/ultimatevocalremovergui\n[gtcrn]: https://github.com/Xiaobin-Rong/gtcrn\n[tts-url]: https://k2-fsa.github.io/sherpa/onnx/tts/all-in-one.html\n[ss-url]: https://k2-fsa.github.io/sherpa/onnx/source-separation/index.html\n[sd-url]: https://k2-fsa.github.io/sherpa/onnx/speaker-diarization/index.html\n[slid-url]: https://k2-fsa.github.io/sherpa/onnx/spoken-language-identification/index.html\n[at-url]: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/index.html\n[vad-url]: https://k2-fsa.github.io/sherpa/onnx/vad/index.html\n[kws-url]: https://k2-fsa.github.io/sherpa/onnx/kws/index.html\n[punct-url]: https://k2-fsa.github.io/sherpa/onnx/punctuation/index.html\n[se-url]: https://k2-fsa.github.io/sherpa/onnx/speech-enhancement/index.html\n[rknpu-doc]: https://k2-fsa.github.io/sherpa/onnx/rknn/index.html\n[qnn-doc]: https://k2-fsa.github.io/sherpa/onnx/qnn/index.html\n[ascend-doc]: https://k2-fsa.github.io/sherpa/onnx/ascend/index.html\n[axera-npu]: https://axera-tech.com/Skill/166.html\n",
      "stars_today": 32
    },
    {
      "id": 122758193,
      "name": "video2x",
      "full_name": "k4yt3x/video2x",
      "description": "A machine learning-based video super resolution and frame interpolation framework. Est. Hack the Valley II, 2018.",
      "html_url": "https://github.com/k4yt3x/video2x",
      "stars": 16887,
      "forks": 1494,
      "language": "C++",
      "topics": [
        "anime4k",
        "frame-interpolation",
        "machine-learning",
        "neural-networks",
        "realcugan",
        "realesrgan",
        "rife",
        "super-resoluion",
        "upscale-video",
        "vulkan"
      ],
      "created_at": "2018-02-24T16:34:41Z",
      "updated_at": "2026-01-14T00:55:22Z",
      "pushed_at": "2025-11-23T00:40:57Z",
      "open_issues": 84,
      "owner": {
        "login": "k4yt3x",
        "avatar_url": "https://avatars.githubusercontent.com/u/21986859?v=4"
      },
      "readme": "<p align=\"center\">\n   <img src=\"https://github.com/user-attachments/assets/5cd63373-e806-474f-94ec-6e04963bf90f\"\n        alt=\"Video2X: A machine learning-based video super resolution and frame interpolation framework.\"/>\n   </br>\n   <img src=\"https://img.shields.io/github/v/release/k4yt3x/video2x?style=flat-square\"/>\n   <img src=\"https://img.shields.io/github/downloads/k4yt3x/video2x/total?style=flat-square\"/>\n   <img src=\"https://img.shields.io/github/license/k4yt3x/video2x?style=flat-square\"/>\n   <img src=\"https://img.shields.io/github/sponsors/k4yt3x?style=flat-square&link=https%3A%2F%2Fgithub.com%2Fsponsors%2Fk4yt3x\"/>\n   <img src=\"https://img.shields.io/badge/dynamic/json?color=%23e85b46&label=Patreon&query=data.attributes.patron_count&suffix=%20patrons&url=https%3A%2F%2Fwww.patreon.com%2Fapi%2Fcampaigns%2F4507807&style=flat-square\"/>\n</p>\n\n## üåü Version 6.0.0\n\nVideo2X 6.0.0 highlights:\n\n- Complete rewrite of the Video2X project in C/C++.\n- Faster and more efficient architecture.\n- Cross-platform support for Windows and Linux.\n- Vastly improved output quality.\n- New GUI and installer for easy setup on Windows.\n\n<details>\n<summary>Click to see more details</summary>\n\nVersion 6.0.0 is a complete rewrite of this project in C/C++. It:\n\n- genuinely works this time, with much less hassle compared to the 5.0.0 beta;\n- is blazing fast, thanks to the new optimized pipeline and the efficiency of C/C++;\n- is cross-platform, available now for both Windows and Linux;\n- offers significantly better output quality with Anime4K v4, Real-ESRGAN, Real-CUGAN, and RIFE;\n- supports two modes: filtering (upscaling) and frame interpolation;\n- supports Anime4K v4 and all custom MPV-compatible GLSL shaders;\n- supports Real-ESRGAN, Real-CUGAN, and RIFE (all models) via ncnn and Vulkan;\n- requires zero additional disk space during processing, just space for the final output.\n\n</details>\n\n![6.4.0-screenshot](https://github.com/user-attachments/assets/9b1cc8a7-2903-4d2c-80a2-8d81f007e45b)\n\n## üñ•Ô∏è Hardware Requirements\n\nYour system must meet the minimum hardware requirements below to run Video2X.\n\n- **CPU**\n  - The precompiled binaries require CPUs with AVX2 support.\n  - **Intel**: Haswell (Q2 2013) or newer\n  - **AMD**: Excavator (Q2 2015) or newer\n- **GPU**\n  - The GPU must support Vulkan.\n  - **NVIDIA**: Kepler (GTX 600 series, Q2 2012) or newer\n  - **AMD**: GCN 1.0 (Radeon HD 7000 series, Q1 2012) or newer\n  - **Intel**: HD Graphics 4000 (Q2 2012) or newer\n\n## [ü™ü Install on Windows](https://docs.video2x.org/installing/windows-qt6.html)\n\n**[Download the Latest Windows Installer Executable (6.4.0)](https://github.com/k4yt3x/video2x/releases/download/6.4.0/video2x-qt6-windows-amd64-installer.exe)**\n\nYou can download the latest Windows release on the [releases page](https://github.com/k4yt3x/video2x/releases/latest). For basic GUI usage, refer to the [documentation](https://docs.video2x.org/running/desktop.html). If you're unable to download directly from GitHub, try the [mirror site](https://files.k4yt3x.com). The GUI currently supports the following languages:\n\n- English (United States)\n- ÁÆÄ‰Ωì‰∏≠ÊñáÔºà‰∏≠ÂõΩÔºâ\n- Êó•Êú¨Ë™ûÔºàÊó•Êú¨Ôºâ\n- Portugu√™s (Portugal)\n- Fran√ßais (France)\n- Deutsch (Deutschland)\n\n## [üêß Install on Linux](https://docs.video2x.org/installing/linux.html)\n\nVideo2X packages are available for the Linux distros listed below. A universal AppImage is also available for other distros. If you'd like to build it from source code, refer to the [PKGBUILD](packaging/arch/PKGBUILD) file for a general overview of the required dependencies and commands.\n\n- Arch Linux: AUR packages, maintained by [@K4YT3X](https://github.com/k4yt3x).\n  - [aur/video2x](https://aur.archlinux.org/packages/video2x)\n  - [aur/video2x-git](https://aur.archlinux.org/packages/video2x-git)\n  - [aur/video2x-qt6](https://aur.archlinux.org/packages/video2x-qt6)\n  - [aur/video2x-qt6-git](https://aur.archlinux.org/packages/video2x-qt6-git)\n- Arch Linux (Chinese Mainland): archlinuxcn packages, maintained by [@Integral-Tech](https://github.com/Integral-Tech).\n  - [archlinuxcn/video2x](https://github.com/archlinuxcn/repo/tree/master/archlinuxcn/video2x)\n  - [archlinuxcn/video2x-git](https://github.com/archlinuxcn/repo/tree/master/archlinuxcn/video2x-git)\n  - [archlinuxcn/video2x-qt6](https://github.com/archlinuxcn/repo/tree/master/archlinuxcn/video2x-qt6)\n  - [archlinuxcn/video2x-qt6-git](https://github.com/archlinuxcn/repo/tree/master/archlinuxcn/video2x-qt6-git)\n- Other distros: `Video2X-x86_64.AppImage` on the [releases page](https://github.com/k4yt3x/video2x/releases/latest).\n\n## [üì¶ Container Image](https://docs.video2x.org/running/container.html)\n\nVideo2X [container images](https://github.com/k4yt3x/video2x/pkgs/container/video2x) are available on the GitHub Container Registry for easy deployment on Linux and macOS. If you already have Docker/Podman installed, only one command is needed to start upscaling a video. For more information on how to use Video2X's Docker image, please refer to the [documentation](https://docs.video2x.org/running/container.html).\n\n## [üìî Google Colab](https://colab.research.google.com/drive/1gWEwcA9y57EsxwOjmLNmNMXPsafw0kGo)\n\nYou can use Video2X on [Google Colab](https://colab.research.google.com/) **for free** if you don't have a powerful GPU of your own. You can borrow a powerful GPU (NVIDIA T4, L4, or A100) on Google's server for free for a maximum of 12 hours per session. **Please use the free resource fairly** and do not create sessions back-to-back and run upscaling 24/7. This might result in you getting banned. You can get [Colab Pro/Pro+](https://colab.research.google.com/signup/pricing) if you'd like to use better GPUs and get longer runtimes. Usage instructions are embedded in the [Colab Notebook](https://colab.research.google.com/drive/1gWEwcA9y57EsxwOjmLNmNMXPsafw0kGo).\n\n## [üí¨ Telegram Discussion Group](https://t.me/video2x)\n\nJoin our Telegram discussion group to ask any questions you have about Video2X, chat directly with the developers, or discuss super resolution, frame interpolation technologies, or the future of Video2X in general.\n\n## [üìñ Documentation](https://docs.video2x.org/)\n\nComprehensive documentation for Video2X is available at [https://docs.video2x.org/](https://docs.video2x.org/). It offers detailed instructions on how to [build](https://docs.video2x.org/building/index.html), [install](https://docs.video2x.org/installing/index.html), [use](https://docs.video2x.org/running/index.html), and [develop](https://docs.video2x.org/developing/index.html) with this program.\n\n## üìΩÔ∏è Video Demos (Outdated)\n\n![Spirited Away Demo](https://user-images.githubusercontent.com/21986859/49412428-65083280-f73a-11e8-8237-bb34158a545e.png)\\\n_Upscale demo: Spirited Away's movie trailer_\n\n- **Spirited Away**: [YouTube](https://youtu.be/mGEfasQl2Zo) | [Bilibili](https://www.bilibili.com/video/BV1V5411471i/)\n  - 360P to 4K\n  - The [original video](https://www.youtube.com/watch?v=ByXuk9QqQkk)'s copyright belongs to Ê†™Âºè‰ºöÁ§æ„Çπ„Çø„Ç∏„Ç™„Ç∏„Éñ„É™\n- **Bad Apple!!**: [YouTube](https://youtu.be/A81rW_FI3cw) | [Bilibili](https://www.bilibili.com/video/BV16K411K7ue)\n  - 384P 30 FPS to 4K 120 FPS with waifu2x and DAIN\n  - The [original video](https://www.nicovideo.jp/watch/sm8628149)'s copyright belongs to „ÅÇ„Å´„Çâ\n- **The Pet Girl of Sakurasou**: [YouTube](https://youtu.be/M0vDI1HH2_Y) | [Bilibili](https://www.bilibili.com/video/BV14k4y167KP/)\n  - 240P 29.97 to 1080P 60 FPS with waifu2x and DAIN\n  - The original video's copyright belongs to ASCII Media Works\n\n### Standard Test Clip\n\nThe following clip can be used to test if your setup works properly. This is also the standard clip used for running performance benchmarks.\n\n- [Standard Test Clip (240P)](https://files.k4yt3x.com/resources/videos/standard-test.mp4) 4.54 MiB\n- [Real-CUGAN Upscaled Sample (1704P)](https://files.k4yt3x.com/resources/videos/standard-realcugan.mp4) 3.5 MiB\n- [Real-ESRGAN Upscaled Sample (1704P)](https://files.k4yt3x.com/resources/videos/standard-realesrgan.mp4) 3.1 MiB\n- [waifu2x Upscaled Sample (1080P)](https://files.k4yt3x.com/resources/videos/standard-waifu2x.mp4) 4.54 MiB\n- [Ground Truth (1080P)](https://files.k4yt3x.com/resources/videos/standard-original.mp4) 22.2 MiB\n\nThe original clip came from the anime \"„Åï„Åè„ÇâËçò„ÅÆ„Éö„ÉÉ„Éà„Å™ÂΩºÂ•≥.\"\\\nCopyright of this clip belongs to Ê†™Âºè‰ºöÁ§æ„Ç¢„Éã„Éó„É¨„ÉÉ„ÇØ„Çπ.\n\n## ‚öñÔ∏è License\n\nThis project is licensed under [GNU AGPL version 3](https://www.gnu.org/licenses/agpl-3.0.txt).\\\nCopyright (C) 2018-2025 K4YT3X and [contributors](https://github.com/k4yt3x/video2x/graphs/contributors).\n\n![AGPLv3](https://www.gnu.org/graphics/agplv3-155x51.png)\n\nThis project includes or depends on these following projects:\n\n| Project                                                                               | License         |\n| ------------------------------------------------------------------------------------- | --------------- |\n| [FFmpeg/FFmpeg](https://www.ffmpeg.org/)                                              | LGPLv2.1, GPLv2 |\n| [Tencent/ncnn](https://github.com/Tencent/ncnn)                                       | BSD 3-Clause    |\n| [bloc97/Anime4K](https://github.com/bloc97/Anime4K)                                   | MIT License     |\n| [nihui/realcugan-ncnn-vulkan](https://github.com/nihui/realcugan-ncnn-vulkan)         | MIT License     |\n| [nihui/rife-ncnn-vulkan](https://github.com/nihui/rife-ncnn-vulkan)                   | MIT License     |\n| [xinntao/Real-ESRGAN-ncnn-vulkan](https://github.com/xinntao/Real-ESRGAN-ncnn-vulkan) | MIT License     |\n\nMore licensing information can be found in the [NOTICE](NOTICE) file.\n\n## üå∫ Special Thanks\n\nSpecial thanks to the following individuals for their significant contributions to the project, listed in alphabetical order.\n\n- [@ArchieMeng](https://github.com/archiemeng)\n- [@BrianPetkovsek](https://github.com/BrianPetkovsek)\n- [@Integral-Tech](https://github.com/Integral-Tech)\n- [@ddouglas87](https://github.com/ddouglas87)\n- [@lhanjian](https://github.com/lhanjian)\n- [@nihui](https://github.com/nihui)\n- [@sat3ll](https://github.com/sat3ll)\n",
      "stars_today": 29
    },
    {
      "id": 24586308,
      "name": "os-tutorial",
      "full_name": "cfenollosa/os-tutorial",
      "description": "How to create an OS from scratch",
      "html_url": "https://github.com/cfenollosa/os-tutorial",
      "stars": 30057,
      "forks": 3523,
      "language": "C",
      "topics": [],
      "created_at": "2014-09-29T08:39:34Z",
      "updated_at": "2026-01-14T00:38:47Z",
      "pushed_at": "2024-07-25T10:57:29Z",
      "open_issues": 128,
      "owner": {
        "login": "cfenollosa",
        "avatar_url": "https://avatars.githubusercontent.com/u/2249551?v=4"
      },
      "readme": "os-tutorial\n===========\n\n_‚ö†Ô∏è Hey! This is an old, abandoned project, with both technical and design issues [listed here](https://github.com/cfenollosa/os-tutorial/issues/269). Please have fun with this tutorial but do look for more modern and authoritative sources if you want to learn about OS design. ‚ö†Ô∏è_\n\nHow to create an OS from scratch!\n\nI have always wanted to learn how to make an OS from scratch. In college I was taught\nhow to implement advanced features (pagination, semaphores, memory management, etc)\nbut:\n\n- I never got to start from my own boot sector\n- College is hard so I don't remember most of it.\n- I'm fed up with people who think that reading an already existing kernel, even if small, is \na good idea to learn operating systems.\n\nInspired by [this document](http://www.cs.bham.ac.uk/~exr/lectures/opsys/10_11/lectures/os-dev.pdf)\nand the [OSDev wiki](http://wiki.osdev.org/), I'll try to make short step-by-step READMEs and\ncode samples for anybody to follow. Honestly, this tutorial is basically the first document but\nsplit into smaller pieces and without the theory.\n\nUpdated: more sources: [the little book about OS development](https://littleosbook.github.io),\n[JamesM's kernel development tutorials](https://web.archive.org/web/20160412174753/http://www.jamesmolloy.co.uk/tutorial_html/index.html)\n\n\nFeatures\n--------\n\n- This course is a code tutorial aimed at people who are comfortable with low level computing. For example,\nprogrammers who have curiosity on how an OS works but don't have the time or willpower to start reading the Linux kernel\ntop to bottom.\n- There is little theory. Yes, this is a feature. Google is your theory lecturer. Once you pass college, \nexcessive theory is worse than no theory because it makes things seem more difficult than they really are.\n- The lessons are tiny and may take 5-15 minutes to complete. Trust me and trust yourself. You can do it!\n\n\nHow to use this tutorial\n------------------------\n\n1. Start with the first folder and go down in order. They build on previous code, so if \nyou jump right to folder 05 and don't know why there is a `mov ah, 0x0e`, it's because you missed lecture 02.\nReally, just go in order. You can always skip stuff you already know.\n\n2. Open the README and read the first line, which details the concepts you should be familiar with\nbefore reading the code. Google concepts you are not familiar with. The second line states the goals for each lesson. \nRead them, because they explain why we do what we do. The \"why\" is as important as the \"how\".\n \n3. Read the rest of the README. It is **very concise**.\n\n4. (Optional) Try to write the code files by yourself after reading the README.\n\n5. Look at the code examples. They are extremely well commented.\n\n6. (Optional) Experiment with them and try to break things. The only way to make sure you understood something is\ntrying to break it or replicate it with different commands.\n\n\nTL;DR: First read the README on each folder, then the code files. If you're brave, try to code them yourself.\n\n\nStrategy\n--------\n\nWe will want to do many things with our OS:\n\n- Boot from scratch, without GRUB - DONE!\n- Enter 32-bit mode - DONE\n- Jump from Assembly to C - DONE!\n- Interrupt handling - DONE!\n- Screen output and keyboard input - DONE!\n- A tiny, basic `libc` which grows to suit our needs - DONE!\n- Memory management\n- Write a filesystem to store files\n- Create a very simple shell\n- User mode\n- Maybe we will write a simple text editor\n- Multiple processes and scheduling\n\nProbably we will go through them in that order, however it's soon to tell.\n\nIf we feel brave enough:\n\n- A BASIC interpreter, like in the 70s!\n- A GUI\n- Networking\n\n\n\nContributing\n------------\n\nThis is a personal learning project, and even though it hasn't been updated for a long time, I still have hopes to get into it at some point.\n\nI'm thankful to all those who have pointed out bugs and submitted pull requests. I will need some time to review everything and I cannot guarantee that at this moment.\n\nPlease feel free to fork this repo. If many of you are interested in continuing the project, let me know and I'll link the \"main fork\" from here.\n",
      "stars_today": 28
    },
    {
      "id": 7270538,
      "name": "anki",
      "full_name": "ankitects/anki",
      "description": "Anki is a smart spaced repetition flashcard program",
      "html_url": "https://github.com/ankitects/anki",
      "stars": 25720,
      "forks": 2691,
      "language": "Rust",
      "topics": [],
      "created_at": "2012-12-21T08:03:31Z",
      "updated_at": "2026-01-13T23:46:44Z",
      "pushed_at": "2026-01-11T11:50:16Z",
      "open_issues": 323,
      "owner": {
        "login": "ankitects",
        "avatar_url": "https://avatars.githubusercontent.com/u/42564322?v=4"
      },
      "readme": "# Anki¬Æ\n\n[![Build status](https://badge.buildkite.com/c9edf020a4aec976f9835e54751cc5409d843adbb66d043bd3.svg?branch=main)](https://buildkite.com/ankitects/anki-ci)\n\nThis repo contains the source code for the computer version of\n[Anki](https://apps.ankiweb.net).\n\n# About\n\nAnki is a spaced repetition program. Please see the [website](https://apps.ankiweb.net) to learn more.\n\n# Getting Started\n\n### Anki Betas\n\nIf you'd like to try development builds of Anki but don't feel comfortable\nbuilding the code, please see [Anki betas](https://betas.ankiweb.net/)\n\n### Developing\n\nFor more information on building and developing, please see [Development](./docs/development.md).\n\n### Contributing\n\nWant to contribute to Anki? Check out the [Contribution Guidelines](./docs/contributing.md).\n\n### Anki Contributors\n\n[CONTRIBUTORS](./CONTRIBUTORS)\n\n# License\n\nAnki's license: [LICENSE](./LICENSE)\n",
      "stars_today": 27
    },
    {
      "id": 157402758,
      "name": "portmaster",
      "full_name": "safing/portmaster",
      "description": "üèî Love Freedom - ‚ùå Block Mass Surveillance",
      "html_url": "https://github.com/safing/portmaster",
      "stars": 11738,
      "forks": 433,
      "language": "Go",
      "topics": [
        "application-firewall",
        "dns",
        "firewall",
        "go",
        "golang",
        "networking",
        "privacy",
        "privacy-by-design",
        "privacy-enhancing-technologies",
        "privacy-protection",
        "privacy-tools"
      ],
      "created_at": "2018-11-13T15:31:45Z",
      "updated_at": "2026-01-14T01:06:10Z",
      "pushed_at": "2026-01-07T08:46:00Z",
      "open_issues": 89,
      "owner": {
        "login": "safing",
        "avatar_url": "https://avatars.githubusercontent.com/u/20678162?v=4"
      },
      "readme": "# Get Peace of Mind <br> with [Easy Privacy](https://safing.io/)\n\nPortmaster is a free and open-source application firewall that does the heavy lifting for you.\nRestore privacy and take back control over all your computer's network activity.\n\nWith great defaults your privacy improves without any effort. And if you want to configure and control everything down to the last detail - Portmaster has you covered too. Developed in the EU üá™üá∫, Austria.\n\n__[Download for Free](https://safing.io/download/)__\n\n__[About Us](https://safing.io/about/)__\n\n![Portmaster User Interface](https://safing.io/assets/img/page-specific/landing/portmaster-thumbnail.png?)\n\n_seen on:_  \n\n[<img src=\"https://safing.io/assets/img/external/heise_online.svg\" height=\"35\">](https://www.heise.de/tests/Datenschutz-Firewall-Portmaster-im-Test-9611687.html)\n&nbsp;&nbsp;&nbsp;\n[![ghacks.net](https://safing.io/assets/img/external/ghacks.png)](https://www.ghacks.net/2022/11/08/portmaster-1-0-released-open-source-application-firewall/)\n&nbsp;&nbsp;&nbsp;\n[![Techlore](https://safing.io/assets/img/external/techlore.png)](https://www.youtube.com/watch?v=E8cTRhGtmcM)\n&nbsp;&nbsp;&nbsp;\n[![Lifehacker](https://safing.io/assets/img/external/logos/lifehacker.webp)](https://lifehacker.com/the-lesser-known-apps-everyone-should-install-on-a-new-1850223434)\n\n## [Features](https://safing.io/features/)\n\n1. Monitor All Network Activity\n2. Full Control: Block Anything\n3. Automatically Block Trackers & Malware\n4. Set Global & Per‚ÄëApp Settings\n5. Secure DNS (Doh/DoT)\n6. Record and Search Network Activity ([$](https://safing.io/pricing/))\n7. Per-App Bandwidth Usage ([$](https://safing.io/pricing/))\n8. [SPN, our Next-Gen Privacy Network](https://safing.io/spn/) ([$$](https://safing.io/pricing/))\n\n# Technical Introduction\n\nPortmaster is a privacy suite for your Windows and Linux desktop.\n\n### Base Technology\n\n- Portmaster integrates into network stack using nfqueue on Linux and a kernel driver (WFP) on Windows.\n- Packets are intercepted at the raw packet level - every packet is seen and can be stopped.\n- Ownership of connections is found using eBPF and `/proc` on Linux and a kernel driver and the IP Helper API (`iphlpapi.dll`) on Windows.\n- Most settings can be defined per app, which can be matched in different ways.\n- Support for special processes with weird or concealed paths/actors:\n  - Snap, AppImage and Script support on Linux\n  - Windows Store apps and svchost.exe system services support on Windows\n- Everything is 100% local on your device. (except the SPN, naturally)\n  - Updates are fully signed and downloaded automatically.\n  - Intelligence data (block lists, geoip) is downloaded and applied automatically.\n- The Portmaster Core Service runs as a system service, the UI elements (App, Notifier) run in user context.\n- The main UI still uses electron as a wrapper :/ - but this will change in the future. You can also open the UI in the browser\n\n### Feature: Secure DNS\n\n- Portmaster intercepts \"astray\" DNS queries and reroutes them to itself for seamless integration.\n- DNS queries are resolved by the default or configured DoT/DoH resolvers.\n- Full support for split horizon and horizon validation to defend against rebinding attacks.\n\n### Feature: Privacy Filter\n\n- Define allowed network scopes: Localhost, LAN, Internet, P2P, Inbound.\n- Easy rules based on Internet entities: Domain, IP, Country and more.\n- Filter Lists block common malware, ad, tracker domains etc.\n\n### Feature: Network History ($)\n\n- Record connections and their details in a local database and search all of it later\n- Auto-delete old history or delete on demand\n\n### Feature: Bandwidth Visibility ($)\n\n- Monitor bandwidth usage per connection and app\n\n### Feature: SPN - Safing Privacy Network ($$)\n\n- A Privacy Network aimed at use cases \"between\" VPN and Tor.\n- Uses onion encryption over multiple hops just like Tor.\n- Routes are chosen to cover most distance within the network to increase privacy.\n- Exits are chosen near the destination server. This automatically geo-unblocks in many cases.\n- Exclude apps and domains/entities from using SPN.\n- Change routing algorithm and focus per app.\n- Nodes are hosted by Safing (company behind Portmaster) and the community.\n- Speeds are pretty decent (>100MBit/s).\n- Further Reading: [SPN Whitepaper](https://safing.io/files/whitepaper/Gate17.pdf)\n\n## Documentation\n\nAll details and guides in the dedicated [wiki](https://wiki.safing.io/)\n\n- [Getting Started](https://wiki.safing.io/en/Portmaster/App)\n- Install\n  - [on Windows](https://wiki.safing.io/en/Portmaster/Install/Windows)\n  - [on Linux](https://wiki.safing.io/en/Portmaster/Install/Linux)\n- [Contribute](https://wiki.safing.io/en/Contribute)\n- [VPN Compatibility](https://wiki.safing.io/en/Portmaster/App/Compatibility#vpn-compatibly)\n- [Software Compatibility](https://wiki.safing.io/en/Portmaster/App/Compatibility)\n- [Architecture](https://wiki.safing.io/en/Portmaster/Architecture)\n- [Settings Handbook](https://docs.safing.io/portmaster/settings)\n- [Portmaster Developer API](https://docs.safing.io/portmaster/api)\n\n# Build Portmaster Yourself (WIP)\n\n1. [Install Earthly CLI](https://earthly.dev/get-earthly)\n2. [Install Docker Engine](https://docs.docker.com/engine/install/)\n3. Run `earthly +release`\n4. Find artifacts in `./dist`\n",
      "stars_today": 27
    },
    {
      "id": 908589694,
      "name": "meeting-minutes",
      "full_name": "Zackriya-Solutions/meeting-minutes",
      "description": "Privacy first, AI meeting assistant with 4x faster Parakeet/Whisper live transcription, speaker diarization, and Ollama summarization built on Rust. 100% local processing. no cloud required. Meetily (Meetly Ai - https://meetily.ai) is the #1 Self-hosted,  Open-source Ai meeting note taker for macOS & Windows.  ",
      "html_url": "https://github.com/Zackriya-Solutions/meeting-minutes",
      "stars": 9198,
      "forks": 784,
      "language": "Rust",
      "topics": [
        "ai",
        "ai-meeting-assistant",
        "llm",
        "local-ai",
        "mac",
        "meeting-minutes",
        "meeting-notes",
        "offline-first",
        "ollama",
        "parakeet",
        "privacy-focused",
        "privacy-tools",
        "rust",
        "self-hosted",
        "speech-to-text",
        "transcription",
        "whisper",
        "whisper-cpp",
        "windows"
      ],
      "created_at": "2024-12-26T12:52:14Z",
      "updated_at": "2026-01-13T23:04:36Z",
      "pushed_at": "2026-01-12T07:01:38Z",
      "open_issues": 108,
      "owner": {
        "login": "Zackriya-Solutions",
        "avatar_url": "https://avatars.githubusercontent.com/u/82556810?v=4"
      },
      "readme": "<div align=\"center\" style=\"border-bottom: none\">\n    <h1>\n        <img src=\"docs/Meetily-6.png\" style=\"border-radius: 10px;\" />\n        <br>\n        Privacy-First AI Meeting Assistant\n    </h1>\n    <a href=\"https://trendshift.io/repositories/13272\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/13272\" alt=\"Zackriya-Solutions%2Fmeeting-minutes | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n    <br>\n    <br>\n    <a href=\"https://github.com/Zackriya-Solutions/meeting-minutes/releases/\"><img src=\"https://img.shields.io/badge/Pre_Release-Link-brightgreen\" alt=\"Pre-Release\"></a>\n    <a href=\"https://github.com/Zackriya-Solutions/meeting-minutes/releases\"><img alt=\"GitHub Repo stars\" src=\"https://img.shields.io/github/stars/zackriya-solutions/meeting-minutes?style=flat\">\n</a>\n <a href=\"https://github.com/Zackriya-Solutions/meeting-minutes/releases\"> <img alt=\"GitHub Downloads (all assets, all releases)\" src=\"https://img.shields.io/github/downloads/zackriya-solutions/meeting-minutes/total?style=plastic\"> </a>\n    <a href=\"https://github.com/Zackriya-Solutions/meeting-minutes/releases\"><img src=\"https://img.shields.io/badge/License-MIT-blue\" alt=\"License\"></a>\n    <a href=\"https://github.com/Zackriya-Solutions/meeting-minutes/releases\"><img src=\"https://img.shields.io/badge/Supported_OS-macOS,_Windows-white\" alt=\"Supported OS\"></a>\n    <a href=\"https://github.com/Zackriya-Solutions/meeting-minutes/releases\"><img alt=\"GitHub Tag\" src=\"https://img.shields.io/github/v/tag/zackriya-solutions/meeting-minutes?include_prereleases&color=yellow\">\n</a>\n    <br>\n    <h3>\n    <br>\n    Open Source ‚Ä¢ Privacy-First ‚Ä¢ Enterprise-Ready\n    </h3>\n    <p align=\"center\">\n    Get latest <a href=\"https://www.zackriya.com/meetily-subscribe/\"><b>Product updates</b></a> <br><br>\n    <a href=\"https://meetily.ai\"><b>Website</b></a> ‚Ä¢\n    <a href=\"https://www.linkedin.com/company/106363062/\"><b>LinkedIn</b></a> ‚Ä¢\n    <a href=\"https://discord.gg/crRymMQBFH\"><b>Meetily Discord</b></a> ‚Ä¢\n    <a href=\"https://discord.com/invite/vCFJvN4BwJ\"><b>Privacy-First AI</b></a> ‚Ä¢\n    <a href=\"https://www.reddit.com/r/meetily/\"><b>Reddit</b></a>\n</p>\n    <p align=\"center\">\n\nA privacy-first AI meeting assistant that captures, transcribes, and summarizes meetings entirely on your infrastructure. Built by expert AI engineers passionate about data sovereignty and open source solutions. Perfect for enterprises that need advanced meeting intelligence without compromising on privacy, compliance, or control.\n\n</p>\n\n<p align=\"center\">\n    <img src=\"docs/meetily_demo.gif\" width=\"650\" alt=\"Meetily Demo\" />\n    <br>\n    <a href=\"https://youtu.be/6FnhSC_eSz8\">View full Demo Video</a>\n</p>\n\n</div>\n\n---\n\n> **üéâ New: Meetily PRO Available** - Looking for enhanced accuracy and advanced features? Check out our professional-grade solution with custom summary templates, advanced exports (PDF, DOCX), auto-meeting detection, built-in GDPR compliance, and many more. **This Community Edition remains forever free & open source**. [Learn more about PRO ‚Üí](https://meetily.ai/pro/)\n\n---\n\n<details>\n<summary>Table of Contents</summary>\n\n- [Introduction](#introduction)\n- [Why Meetily?](#why-meetily)\n- [Features](#features)\n- [Installation](#installation)\n- [Key Features in Action](#key-features-in-action)\n- [System Architecture](#system-architecture)\n- [For Developers](#for-developers)\n- [Meetily PRO](#meetily-pro)\n- [Contributing](#contributing)\n- [License](#license)\n\n</details>\n\n## Introduction\n\nMeetily is a privacy-first AI meeting assistant that runs entirely on your local machine. It captures your meetings, transcribes them in real-time, and generates summaries, all without sending any data to the cloud. This makes it the perfect solution for professionals and enterprises who need to maintain complete control over their sensitive information.\n\n## Why Meetily?\n\nWhile there are many meeting transcription tools available, this solution stands out by offering:\n\n- **Privacy First:** All processing happens locally on your device.\n- **Cost-Effective:** Uses open-source AI models instead of expensive APIs.\n- **Flexible:** Works offline and supports multiple meeting platforms.\n- **Customizable:** Self-host and modify for your specific needs.\n\n<details>\n<summary>The Privacy Problem</summary>\n\nMeeting AI tools create significant privacy and compliance risks across all sectors:\n\n- **$4.4M average cost per data breach** (IBM 2024)\n- **‚Ç¨5.88 billion in GDPR fines** issued by 2025\n- **400+ unlawful recording cases** filed in California this year\n\nWhether you're a defense consultant, enterprise executive, legal professional, or healthcare provider, your sensitive discussions shouldn't live on servers you don't control. Cloud meeting tools promise convenience but deliver privacy nightmares with unclear data storage practices and potential unauthorized access.\n\n**Meetily solves this:** Complete data sovereignty on your infrastructure, zero vendor lock-in, and full control over your sensitive conversations.\n\n</details>\n\n## Features\n\n- **Local First:** All processing is done on your machine. No data ever leaves your computer.\n- **Real-time Transcription:** Get a live transcript of your meeting as it happens.\n- **AI-Powered Summaries:** Generate summaries of your meetings using powerful language models.\n- **Multi-Platform:** Works on macOS, Windows, and Linux.\n- **Open Source:** Meetily is open source and free to use.\n- **Flexible AI Provider Support:** Choose from Ollama (local), Claude, Groq, OpenRouter, or use your own OpenAI-compatible endpoint.\n\n## Installation\n\n### ü™ü **Windows**\n\n1. Download the latest `x64-setup.exe` from [Releases](https://github.com/Zackriya-Solutions/meeting-minutes/releases/latest)\n2. Right-click the downloaded file ‚Üí **Properties** ‚Üí Check **Unblock** ‚Üí Click **OK**\n3. Run the installer (if Windows shows a security warning: Click **More info** ‚Üí **Run anyway**)\n\n### üçé **macOS**\n\n1. Download `meetily_0.2.0_aarch64.dmg` from [Releases](https://github.com/Zackriya-Solutions/meeting-minutes/releases/latest)\n2. Open the downloaded `.dmg` file\n3. Drag **Meetily** to your Applications folder\n4. Open **Meetily** from Applications folder\n\n### üêß **Linux**\n\nBuild from source following our detailed guides:\n\n- [Building on Linux](docs/building_in_linux.md)\n- [General Build Instructions](docs/BUILDING.md)\n\n**Quick start:**\n\n```bash\ngit clone https://github.com/Zackriya-Solutions/meeting-minutes\ncd meeting-minutes/frontend\npnpm install\n./build-gpu.sh\n```\n\n## Key Features in Action\n\n### üéØ Local Transcription\n\nTranscribe meetings entirely on your device using **Whisper** or **Parakeet** models. No cloud required.\n\n<p align=\"center\">\n    <img src=\"docs/home.png\" width=\"650\" style=\"border-radius: 10px;\" alt=\"Meetily Demo\" />\n</p>\n\n### ü§ñ AI-Powered Summaries\n\nGenerate meeting summaries with your choice of AI provider. **Ollama** (local) is recommended, with support for Claude, Groq, OpenRouter, and OpenAI.\n\n<p align=\"center\">\n    <img src=\"docs/summary.png\" width=\"650\" style=\"border-radius: 10px;\" alt=\"Summary generation\" />\n</p>\n\n<p align=\"center\">\n    <img src=\"docs/editor1.png\" width=\"650\" style=\"border-radius: 10px;\" alt=\"Editor Summary generation\" />\n</p>\n\n### üîí Privacy-First Design\n\nAll data stays on your machine. Transcription models, recordings, and transcripts are stored locally.\n\n<p align=\"center\">\n    <img src=\"docs/settings.png\" width=\"650\" style=\"border-radius: 10px;\" alt=\"Local Transcription and storage\" />\n</p>\n\n### üåê Custom OpenAI Endpoint Support\n\nUse your own OpenAI-compatible endpoint for AI summaries. Perfect for organizations with custom AI infrastructure or preferred providers.\n\n<p align=\"center\">\n    <img src=\"docs/custom.png\" width=\"650\" style=\"border-radius: 10px;\" alt=\"Custom OpenAI Endpoint Configuration\" />\n</p>\n\n### üéôÔ∏è Professional Audio Mixing\n\nCapture microphone and system audio simultaneously with intelligent ducking and clipping prevention.\n\n<p align=\"center\">\n    <img src=\"docs/audio.png\" width=\"650\" style=\"border-radius: 10px;\" alt=\"Device selection\" />\n</p>\n\n### ‚ö° GPU Acceleration\n\nBuilt-in support for hardware acceleration across platforms:\n\n- **macOS**: Apple Silicon (Metal) + CoreML\n- **Windows/Linux**: NVIDIA (CUDA), AMD/Intel (Vulkan)\n\nAutomatically enabled at build time - no configuration needed.\n\n## System Architecture\n\nMeetily is a single, self-contained application built with [Tauri](https://tauri.app/). It uses a Rust-based backend to handle all the core logic, and a Next.js frontend for the user interface.\n\nFor more details, see the [Architecture documentation](docs/architecture.md).\n\n## For Developers\n\nIf you want to contribute to Meetily or build it from source, you'll need to have Rust and Node.js installed. For detailed build instructions, please see the [Building from Source guide](docs/BUILDING.md).\n\n## Meetily Pro\n\n<p align=\"center\">\n    <img src=\"docs/pv2.1.png\" width=\"650\" style=\"border-radius: 10px;\" alt=\"Upcoming version\" />\n</p>\n\n**Meetily PRO** is a professional-grade solution with enhanced accuracy and advanced features for serious users and teams. Built on a different codebase with superior transcription models and enterprise-ready capabilities.\n\n### Key Advantages Over Community Edition:\n\n- **Enhanced Accuracy**: Superior transcription models for professional-grade accuracy\n- **Custom Summary Templates**: Tailor summaries to your specific workflow and needs\n- **Advanced Export Options**: PDF, DOCX, and Markdown exports with formatting\n- **Auto-detect and Join Meetings**: Automatic meeting detection and joining\n- **Speaker Identification**: Distinguish between speakers automatically *(Coming Soon)*\n- **Chat with Meetings**: AI-powered meeting insights and queries *(Coming Soon)*\n- **Calendar Integration**: Seamless integration with your calendar *(Coming Soon)*\n- **Self-Hosted Deployment**: Deploy on your own infrastructure for teams\n- **GDPR Compliance Built-In**: Privacy by design architecture with complete audit trails\n- **Priority Support**: Dedicated support for PRO users\n\n### Who is PRO for?\n\n- **Professionals** who need the highest accuracy for critical meetings\n- **Teams and organizations** (2-100 users) requiring self-hosted deployment\n- **Power users** who need advanced export formats and custom workflows\n- **Compliance-focused organizations** requiring GDPR readiness\n\n> **Note:** Meetily Community Edition remains **free & open source forever** with local transcription, AI summaries, and core features. PRO is a separate professional solution for users who need enhanced accuracy and advanced capabilities.\n\nFor organizations needing 100+ users or managed compliance solutions, explore [Meetily Enterprise](https://meetily.ai/enterprise/).\n\n**Learn more about pricing and features:** [https://meetily.ai/pro/](https://meetily.ai/pro/)\n\n## Contributing\n\nWe welcome contributions from the community! If you have any questions or suggestions, please open an issue or submit a pull request. Please follow the established project structure and guidelines. For more details, refer to the [CONTRIBUTING.md](CONTRIBUTING.md) file.\n\nThanks for all the contributions. Our community is what makes this project possible.\n\n## License\n\nMIT License - Feel free to use this project for your own purposes.\n\n## Acknowledgments\n\n- We borrowed some code from [Whisper.cpp](https://github.com/ggerganov/whisper.cpp).\n- We borrowed some code from [Screenpipe](https://github.com/mediar-ai/screenpipe).\n- We borrowed some code from [transcribe-rs](https://crates.io/crates/transcribe-rs).\n- Thanks to **NVIDIA** for developing the **Parakeet** model.\n- Thanks to [istupakov](https://huggingface.co/istupakov/parakeet-tdt-0.6b-v3-onnx) for providing the **ONNX conversion** of the Parakeet model.\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=Zackriya-Solutions/meeting-minutes&type=Date)](https://star-history.com/#Zackriya-Solutions/meeting-minutes&Date)\n",
      "stars_today": 26
    },
    {
      "id": 878733839,
      "name": "mago",
      "full_name": "carthage-software/mago",
      "description": "Mago is a toolchain for PHP that aims to provide a set of tools to help developers write better code.",
      "html_url": "https://github.com/carthage-software/mago",
      "stars": 2652,
      "forks": 106,
      "language": "Rust",
      "topics": [
        "code-analyzer",
        "code-style",
        "coding-standards",
        "formatter",
        "lexer",
        "linter",
        "parser",
        "php",
        "static-analysis",
        "type-checker"
      ],
      "created_at": "2024-10-26T01:11:18Z",
      "updated_at": "2026-01-13T23:51:59Z",
      "pushed_at": "2026-01-13T13:03:11Z",
      "open_issues": 63,
      "owner": {
        "login": "carthage-software",
        "avatar_url": "https://avatars.githubusercontent.com/u/140348628?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"docs/public/assets/banner.svg\" alt=\"Mago Banner\" width=\"600\" />\n</p>\n\n<div align=\"center\">\n\n**An extremely fast PHP linter, formatter, and static analyzer, written in Rust.**\n\n</div>\n\n<div align=\"center\">\n\n[![CI Status](https://github.com/carthage-software/mago/actions/workflows/ci.yml/badge.svg)](https://github.com/carthage-software/mago/actions/workflows/ci.yml)\n[![CD Status](https://github.com/carthage-software/mago/actions/workflows/cd.yml/badge.svg)](https://github.com/carthage-software/mago/actions/workflows/cd.yml)\n[![CodeQL](https://github.com/carthage-software/mago/actions/workflows/github-code-scanning/codeql/badge.svg)](https://github.com/carthage-software/mago/actions/workflows/github-code-scanning/codeql)\n[![Crates.io](https://img.shields.io/crates/v/mago.svg)](https://crates.io/crates/mago)\n[![Latest Stable Version for PHP](https://poser.pugx.org/carthage-software/mago/v)](https://packagist.org/packages/carthage-software/mago)\n[![Total Composer Downloads](http://poser.pugx.org/carthage-software/mago/downloads)](https://packagist.org/packages/carthage-software/mago)\n[![License](https://img.shields.io/crates/l/mago.svg)](https://github.com/carthage-software/mago/blob/main/LICENSE-MIT)\n\n</div>\n\n**Mago** is a comprehensive toolchain for PHP that helps developers write better code. Inspired by the Rust ecosystem, Mago brings speed, reliability, and an exceptional developer experience to PHP projects of all sizes.\n\n## Table of Contents\n\n- [Installation](#installation)\n- [Getting Started](#getting-started)\n- [Features](#features)\n- [Our Sponsors](#our-sponsors)\n- [Contributing](#contributing)\n- [Inspiration & Acknowledgements](#inspiration--acknowledgements)\n- [License](#license)\n\n## Installation\n\nThe most common way to install Mago on macOS and Linux is by using our shell script:\n\n```sh\ncurl --proto '=https' --tlsv1.2 -sSf https://carthage.software/mago.sh | bash\n```\n\nTo install a specific version:\n\n```sh\ncurl --proto '=https' --tlsv1.2 -sSf https://carthage.software/mago.sh | bash -s -- --version=1.1.0\n```\n\nFor all other installation methods, including Homebrew, Composer, and Cargo, please refer to our official **[Installation Guide](https://mago.carthage.software/guide/installation)**.\n\n## Getting Started\n\nTo get started with Mago and learn how to configure your project, please visit our **[Getting Started Guide](https://mago.carthage.software/guide/getting-started)** in the official documentation.\n\n## Features\n\n- ‚ö°Ô∏è Extremely Fast: Built in Rust for maximum performance.\n- üîç Lint: Identify issues in your codebase with customizable rules.\n- üî¨ Static Analysis: Perform deep analysis of your codebase to catch potential type errors and bugs.\n- üõ†Ô∏è Automated Fixes: Apply fixes for many lint issues automatically.\n- üìú Formatting: Automatically format your code to adhere to best practices and style guides.\n- üß† Semantic Checks: Ensure code correctness with robust semantic analysis.\n- üå≥ AST Visualization: Explore your code‚Äôs structure with Abstract Syntax Tree (AST) parsing.\n\n## Our Sponsors\n\n<!-- START-SPONSORS -->\n<p align=\"center\"><a href=\"https://www.jetbrains.com/\" title=\"JetBrains\"><kbd><img src=\"https://avatars.githubusercontent.com/u/60931315?u=f9b545e50cace9e9028f77eaf1e83104d18d4d48&v=4&s=240\" width=\"120\" height=\"120\" alt=\"JetBrains\" /></kbd></a></p><p align=\"center\"><a href=\"https://github.com/jasonrm\" title=\"Jason R. McNeil\"><kbd><img src=\"https://avatars.githubusercontent.com/u/39949?u=69c0e4fb08c439250978d41dbc3371d2f0609b98&v=4&s=160\" width=\"80\" height=\"80\" alt=\"Jason R. McNeil\" /></kbd></a><a href=\"https://ofcompute.rs/\" title=\"Vincent Berset\"><kbd><img src=\"https://avatars.githubusercontent.com/u/5173120?u=95efc76cd8fc804536dc6dd25781a95b650bf902&v=4&s=160\" width=\"80\" height=\"80\" alt=\"Vincent Berset\" /></kbd></a></p><p align=\"center\"><a href=\"https://github.com/kambo-1st\" title=\"Bohuslav ≈†imek\"><kbd><img src=\"https://avatars.githubusercontent.com/u/6493048?u=5eddf1eb923810745d8bdd62496d245238833d07&v=4&s=96\" width=\"48\" height=\"48\" alt=\"Bohuslav ≈†imek\" /></kbd></a><a href=\"https://www.ticketswap.com\" title=\"TicketSwap\"><kbd><img src=\"https://avatars.githubusercontent.com/u/5766233?v=4&s=96\" width=\"48\" height=\"48\" alt=\"TicketSwap\" /></kbd></a></p>\n\n[See all sponsors](SPONSORS.md)\n<!-- END-SPONSORS -->\n\n## Contributing\n\nMago is a community-driven project, and we welcome contributions! Whether you're reporting bugs, suggesting features, writing documentation, or submitting code, your help is valued.\n\n- See our [Contributing Guide](./CONTRIBUTING.md) to get started.\n- Join the discussion on [Discord](https://discord.gg/mwyyjr27eu).\n\n## Inspiration & Acknowledgements\n\nMago stands on the shoulders of giants. Our design and functionality are heavily inspired by pioneering tools in both the Rust and PHP ecosystems.\n\n### Inspirations:\n\n- [Clippy](https://github.com/rust-lang/rust-clippy): For its comprehensive linting approach.\n- [OXC](https://github.com/oxc-project/oxc/): A major inspiration for building a high-performance toolchain in Rust.\n- [Hakana](https://github.com/slackhq/hakana/): For its deep static analysis capabilities.\n\n### Acknowledgements:\n\nWe deeply respect the foundational work of tools like [PHP-CS-Fixer](https://github.com/PHP-CS-Fixer/PHP-CS-Fixer), [Psalm](https://github.com/vimeo/psalm), [PHPStan](https://github.com/phpstan/phpstan), and [PHP_CodeSniffer](https://github.com/PHPCSStandards/PHP_CodeSniffer). While Mago aims to offer a unified and faster alternative, these tools paved the way for modern PHP development.\n\n## License\n\nMago is dual-licensed under your choice of the following:\n\n- MIT License ([LICENSE-MIT](./LICENSE-MIT))\n- Apache License, Version 2.0 ([LICENSE-APACHE](./LICENSE-APACHE))\n",
      "stars_today": 26
    },
    {
      "id": 237647258,
      "name": "firmware",
      "full_name": "meshtastic/firmware",
      "description": "The official firmware for Meshtastic, an open-source, off-grid mesh communication system.",
      "html_url": "https://github.com/meshtastic/firmware",
      "stars": 6549,
      "forks": 1890,
      "language": "C++",
      "topics": [
        "esp32",
        "gps",
        "heltec",
        "hiking",
        "lora",
        "mesh",
        "mesh-networks",
        "meshtastic",
        "nrf52",
        "off-grid",
        "pico",
        "rp2040",
        "stm32",
        "ttgo",
        "ttgo-tbeam"
      ],
      "created_at": "2020-02-01T17:00:35Z",
      "updated_at": "2026-01-14T00:21:33Z",
      "pushed_at": "2026-01-13T21:59:50Z",
      "open_issues": 400,
      "owner": {
        "login": "meshtastic",
        "avatar_url": "https://avatars.githubusercontent.com/u/61627050?v=4"
      },
      "readme": "<div align=\"center\" markdown=\"1\">\n\n<img src=\".github/meshtastic_logo.png\" alt=\"Meshtastic Logo\" width=\"80\"/>\n<h1>Meshtastic Firmware</h1>\n\n![GitHub release downloads](https://img.shields.io/github/downloads/meshtastic/firmware/total)\n[![CI](https://img.shields.io/github/actions/workflow/status/meshtastic/firmware/main_matrix.yml?branch=master&label=actions&logo=github&color=yellow)](https://github.com/meshtastic/firmware/actions/workflows/ci.yml)\n[![CLA assistant](https://cla-assistant.io/readme/badge/meshtastic/firmware)](https://cla-assistant.io/meshtastic/firmware)\n[![Fiscal Contributors](https://opencollective.com/meshtastic/tiers/badge.svg?label=Fiscal%20Contributors&color=deeppink)](https://opencollective.com/meshtastic/)\n[![Vercel](https://img.shields.io/static/v1?label=Powered%20by&message=Vercel&style=flat&logo=vercel&color=000000)](https://vercel.com?utm_source=meshtastic&utm_campaign=oss)\n\n<a href=\"https://trendshift.io/repositories/5524\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/5524\" alt=\"meshtastic%2Ffirmware | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\n</div>\n\n</div>\n\n<div align=\"center\">\n\t<a href=\"https://meshtastic.org\">Website</a>\n\t-\n\t<a href=\"https://meshtastic.org/docs/\">Documentation</a>\n</div>\n\n## Overview\n\nThis repository contains the official device firmware for Meshtastic, an open-source LoRa mesh networking project designed for long-range, low-power communication without relying on internet or cellular infrastructure. The firmware supports various hardware platforms, including ESP32, nRF52, RP2040/RP2350, and Linux-based devices.\n\nMeshtastic enables text messaging, location sharing, and telemetry over a decentralized mesh network, making it ideal for outdoor adventures, emergency preparedness, and remote operations.\n\n### Get Started\n\n- üîß **[Building Instructions](https://meshtastic.org/docs/development/firmware/build)** ‚Äì Learn how to compile the firmware from source.\n- ‚ö° **[Flashing Instructions](https://meshtastic.org/docs/getting-started/flashing-firmware/)** ‚Äì Install or update the firmware on your device.\n\nJoin our community and help improve Meshtastic! üöÄ\n\n## Stats\n\n![Alt](https://repobeats.axiom.co/api/embed/8025e56c482ec63541593cc5bd322c19d5c0bdcf.svg \"Repobeats analytics image\")\n",
      "stars_today": 25
    },
    {
      "id": 814684486,
      "name": "gpui-component",
      "full_name": "longbridge/gpui-component",
      "description": "Rust GUI components for building fantastic cross-platform desktop application by using GPUI.",
      "html_url": "https://github.com/longbridge/gpui-component",
      "stars": 9750,
      "forks": 416,
      "language": "Rust",
      "topics": [
        "desktop-application",
        "gpui",
        "rust",
        "uikit"
      ],
      "created_at": "2024-06-13T13:45:39Z",
      "updated_at": "2026-01-14T00:29:42Z",
      "pushed_at": "2026-01-13T16:20:38Z",
      "open_issues": 58,
      "owner": {
        "login": "longbridge",
        "avatar_url": "https://avatars.githubusercontent.com/u/68419756?v=4"
      },
      "readme": "# GPUI Component\n\n[![Build Status](https://github.com/longbridge/gpui-component/actions/workflows/ci.yml/badge.svg)](https://github.com/longbridge/gpui-component/actions/workflows/ci.yml) [![Docs](https://docs.rs/gpui-component/badge.svg)](https://docs.rs/gpui-component/) [![Crates.io](https://img.shields.io/crates/v/gpui-component.svg)](https://crates.io/crates/gpui-component)\n\nUI components for building fantastic desktop applications using [GPUI](https://gpui.rs).\n\n## Features\n\n- **Richness**: 60+ cross-platform desktop UI components.\n- **Native**: Inspired by macOS and Windows controls, combined with shadcn/ui design for a modern experience.\n- **Ease of Use**: Stateless `RenderOnce` components, simple and user-friendly.\n- **Customizable**: Built-in `Theme` and `ThemeColor`, supporting multi-theme and variable-based configurations.\n- **Versatile**: Supports sizes like `xs`, `sm`, `md`, and `lg`.\n- **Flexible Layout**: Dock layout for panel arrangements, resizing, and freeform (Tiles) layouts.\n- **High Performance**: Virtualized Table and List components for smooth large-data rendering.\n- **Content Rendering**: Native support for Markdown and simple HTML.\n- **Charting**: Built-in charts for visualizing your data.\n- **Editor**: High performance code editor (support up to 200K lines) with LSP (diagnostics, completion, hover, etc).\n- **Syntax Highlighting**: Syntax highlighting for editor and markdown components using Tree Sitter.\n\n## Showcase\n\nHere is the first application: [Longbridge Pro](https://longbridge.com/desktop), built using GPUI Component.\n\n<img width=\"1763\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e1ecb9c3-2dd3-431e-bd97-5a819c30e551\" />\n\n## Usage\n\n```toml\ngpui = \"0.2.2\"\ngpui-component = \"0.5.0\"\n```\n\n### Basic Example\n\n```rs\nuse gpui::*;\nuse gpui_component::{button::*, *};\n\npub struct HelloWorld;\nimpl Render for HelloWorld {\n    fn render(&mut self, _: &mut Window, _: &mut Context<Self>) -> impl IntoElement {\n        div()\n            .v_flex()\n            .gap_2()\n            .size_full()\n            .items_center()\n            .justify_center()\n            .child(\"Hello, World!\")\n            .child(\n                Button::new(\"ok\")\n                    .primary()\n                    .label(\"Let's Go!\")\n                    .on_click(|_, _, _| println!(\"Clicked!\")),\n            )\n    }\n}\n\nfn main() {\n    let app = Application::new();\n\n    app.run(move |cx| {\n        // This must be called before using any GPUI Component features.\n        gpui_component::init(cx);\n\n        cx.spawn(async move |cx| {\n            cx.open_window(WindowOptions::default(), |window, cx| {\n                let view = cx.new(|_| HelloWorld);\n                // This first level on the window, should be a Root.\n                cx.new(|cx| Root::new(view, window, cx))\n            })?;\n\n            Ok::<_, anyhow::Error>(())\n        })\n        .detach();\n    });\n}\n```\n\n### Icons\n\nGPUI Component has an `Icon` element, but it does not include SVG files by default.\n\nThe example uses [Lucide](https://lucide.dev) icons, but you can use any icons you like. Just name the SVG files as defined in [IconName](https://github.com/longbridge/gpui-component/blob/main/crates/ui/src/icon.rs#L86). You can add any icons you need to your project.\n\n## Development\n\nWe have a gallery of applications built with GPUI Component.\n\n```bash\ncargo run\n```\n\nMore examples can be found in the `examples` directory. You can run them with `cargo run --example <example_name>`.\n\nCheck out [CONTRIBUTING.md](CONTRIBUTING.md) for more details.\n\n## Compare to others\n\n| Features              | GPUI Component                 | [Iced]             | [egui]                | [Qt 6]                                            |\n| --------------------- | ------------------------------ | ------------------ | --------------------- | ------------------------------------------------- |\n| Language              | Rust                           | Rust               | Rust                  | C++/QML                                           |\n| Core Render           | GPUI                           | wgpu               | wgpu                  | QT                                                |\n| License               | Apache 2.0                     | MIT                | MIT/Apache 2.0        | [Commercial/LGPL](https://www.qt.io/qt-licensing) |\n| Min Binary Size [^1]  | 12MB                           | 11MB               | 5M                    | 20MB [^2]                                         |\n| Cross-Platform        | Yes                            | Yes                | Yes                   | Yes                                               |\n| Documentation         | Simple                         | Simple             | Simple                | Good                                              |\n| Web                   | No                             | Yes                | Yes                   | Yes                                               |\n| UI Style              | Modern                         | Basic              | Basic                 | Basic                                             |\n| CJK Support           | Yes                            | Yes                | Bad                   | Yes                                               |\n| Chart                 | Yes                            | No                 | No                    | Yes                                               |\n| Table (Large dataset) | Yes<br>(Virtual Rows, Columns) | No                 | Yes<br>(Virtual Rows) | Yes<br>(Virtual Rows, Columns)                    |\n| Table Column Resize   | Yes                            | No                 | Yes                   | Yes                                               |\n| Text base             | Rope                           | [COSMIC Text] [^3] | trait TextBuffer [^4] | [QTextDocument]                                   |\n| CodeEditor            | Simple                         | Simple             | Simple                | Basic API                                         |\n| Dock Layout           | Yes                            | Yes                | Yes                   | Yes                                               |\n| Syntax Highlight      | [Tree Sitter]                  | [Syntect]          | [Syntect]             | [QSyntaxHighlighter]                              |\n| Markdown Rendering    | Yes                            | Yes                | Basic                 | No                                                |\n| Markdown mix HTML     | Yes                            | No                 | No                    | No                                                |\n| HTML Rendering        | Basic                          | No                 | No                    | Basic                                             |\n| Text Selection        | TextView                       | No                 | Any Label             | Yes                                               |\n| Custom Theme          | Yes                            | Yes                | Yes                   | Yes                                               |\n| Built Themes          | Yes                            | No                 | No                    | No                                                |\n| I18n                  | Yes                            | Yes                | Yes                   | Yes                                               |\n\n> Please submit an issue or PR if any mistakes or outdated are found.\n\n[Iced]: https://github.com/iced-rs/iced\n[egui]: https://github.com/emilk/egui\n[QT 6]: https://www.qt.io/product/qt6\n[Tree Sitter]: https://tree-sitter.github.io/tree-sitter/\n[Syntect]: https://github.com/trishume/syntect\n[QSyntaxHighlighter]: https://doc.qt.io/qt-6/qsyntaxhighlighter.html\n[QTextDocument]: https://doc.qt.io/qt-6/qtextdocument.html\n[COSMIC Text]: https://github.com/pop-os/cosmic-text\n\n[^1]: Release builds by use simple hello world example.\n\n[^2]: [Reducing Binary Size of Qt Applications](https://www.qt.io/blog/reducing-binary-size-of-qt-applications-part-3-more-platforms)\n\n[^3]: Iced Editor: <https://github.com/iced-rs/iced/blob/db5a1f6353b9f8520c4f9633d1cdc90242c2afe1/graphics/src/text/editor.rs#L65-L68>\n\n[^4]: egui TextBuffer: <https://github.com/emilk/egui/blob/0a81372cfd3a4deda640acdecbbaf24bf78bb6a2/crates/egui/src/widgets/text_edit/text_buffer.rs#L20>\n\n## License\n\nApache-2.0\n\n- UI design based on [shadcn/ui](https://ui.shadcn.com).\n- Icons from [Lucide](https://lucide.dev).\n",
      "stars_today": 24
    },
    {
      "id": 667731914,
      "name": "kiss-translator",
      "full_name": "fishjar/kiss-translator",
      "description": "A simple, open source bilingual translation extension & Greasemonkey script (‰∏Ä‰∏™ÁÆÄÁ∫¶„ÄÅÂºÄÊ∫êÁöÑ ÂèåËØ≠ÂØπÁÖßÁøªËØëÊâ©Â±ï & Ê≤πÁå¥ËÑöÊú¨)",
      "html_url": "https://github.com/fishjar/kiss-translator",
      "stars": 8573,
      "forks": 360,
      "language": "JavaScript",
      "topics": [
        "extension",
        "translate",
        "translation",
        "translator",
        "userscript",
        "userscripts"
      ],
      "created_at": "2023-07-18T07:20:49Z",
      "updated_at": "2026-01-13T23:04:53Z",
      "pushed_at": "2026-01-13T16:15:09Z",
      "open_issues": 46,
      "owner": {
        "login": "fishjar",
        "avatar_url": "https://avatars.githubusercontent.com/u/1157624?v=4"
      },
      "readme": "# KISS Translator ÁÆÄÁ∫¶ÁøªËØë\n\n[English](README.en.md) | [‰∏≠Êñá](README.md) | [Êó•Êú¨Ë™û](README.ja.md) | [ÌïúÍµ≠Ïñ¥](README.ko.md)\n\n‰∏Ä‰∏™ÁÆÄÁ∫¶„ÄÅÂºÄÊ∫êÁöÑ [ÂèåËØ≠ÂØπÁÖßÁøªËØëÊâ©Â±ï & Ê≤πÁå¥ËÑöÊú¨](https://github.com/fishjar/kiss-translator)„ÄÇ\n\n[kiss-translator.webm](https://github.com/fishjar/kiss-translator/assets/1157624/f7ba8a5c-e4a8-4d5a-823a-5c5c67a0a47f)\n\n## ÁâπÊÄß\n\n- [x] ‰øùÊåÅÁÆÄÁ∫¶\n- [x] ÂºÄÊîæÊ∫ê‰ª£Á†Å\n- [x] ÈÄÇÈÖçÂ∏∏ËßÅÊµèËßàÂô®\n  - [x] Chrome/Edge\n  - [x] Firefox\n  - [x] Kiwi (Android)\n  - [x] Orion (iOS)\n  - [x] Safari\n  - [x] Thunderbird\n- [x] ÊîØÊåÅÂ§öÁßçÁøªËØëÊúçÂä°\n  - [x] Google/Microsoft\n  - [x] Tencent/Volcengine\n  - [x] OpenAI/Gemini/Claude/Ollama/DeepSeek/OpenRouter\n  - [x] DeepL/DeepLX/NiuTrans\n  - [x] AzureAI/CloudflareAI\n  - [x] ChromeÊµèËßàÂô®ÂÜÖÁΩÆAIÁøªËØë(BuiltinAI)\n- [x] Ë¶ÜÁõñÂ∏∏ËßÅÁøªËØëÂú∫ÊôØ\n  - [x] ÁΩëÈ°µÂèåËØ≠ÂØπÁÖßÁøªËØë\n  - [x] ËæìÂÖ•Ê°ÜÁøªËØë\n    - ÈÄöËøáÂø´Êç∑ÈîÆÁ´ãÂç≥Â∞ÜËæìÂÖ•Ê°ÜÂÜÖÊñáÊú¨ÁøªËØëÊàêÂÖ∂‰ªñËØ≠Ë®Ä\n  - [x] ÂàíËØçÁøªËØë\n    - [x] ‰ªªÊÑèÈ°µÈù¢ÊâìÂºÄÁøªËØëÊ°ÜÔºåÂèØÁî®Â§öÁßçÁøªËØëÊúçÂä°ÂØπÊØîÁøªËØë\n    - [x] Ëã±ÊñáËØçÂÖ∏ÁøªËØë\n    - [x] Êî∂ËóèËØçÊ±á\n  - [x] Èº†Ê†áÊÇ¨ÂÅúÁøªËØë\n  - [x] YouTube Â≠óÂπïÁøªËØë\n    - ÊîØÊåÅ‰ªªÊÑèÁøªËØëÊúçÂä°ÂØπËßÜÈ¢ëÂ≠óÂπïËøõË°åÁøªËØëÂπ∂ÂèåËØ≠ÊòæÁ§∫\n    - ÂÜÖÁΩÆÂü∫Á°ÄÁöÑÂ≠óÂπïÂêàÂπ∂‰∏éÊñ≠Âè•ÁÆóÊ≥ïÔºåÊèêÂçáÁøªËØëÊïàÊûú\n    - ÊîØÊåÅAIÊñ≠Âè•ÂäüËÉΩÔºåÂèØËøõ‰∏ÄÊ≠•ÊèêÂçáÁøªËØëË¥®Èáè\n    - Ëá™ÂÆö‰πâÂ≠óÂπïÊ†∑Âºè\n- [x] ÊîØÊåÅÂ§öÊ†∑ÁøªËØëÊïàÊûú\n  - [x] ÊîØÊåÅËá™Âä®ËØÜÂà´ÊñáÊú¨‰∏éÊâãÂä®ËßÑÂàô‰∏§ÁßçÊ®°Âºè\n    - Ëá™Âä®ËØÜÂà´ÊñáÊú¨Ê®°Âºè‰ΩøÂæóÁªùÂ§ßÈÉ®ÂàÜÁΩëÁ´ôÊó†ÈúÄÁºñÂÜôËßÑÂàô‰πüËÉΩÁøªËØëÂÆåÊï¥\n    - ÊâãÂä®ËßÑÂàôÊ®°ÂºèÔºåÂèØ‰ª•ÈíàÂØπÁâπÂÆöÁΩëÁ´ôÊûÅËá¥‰ºòÂåñ\n  - [x] Ëá™ÂÆö‰πâËØëÊñáÊ†∑Âºè\n  - [x] ÊîØÊåÅÂØåÊñáÊú¨ÁøªËØëÂèäÊòæÁ§∫ÔºåËÉΩÂ§üÂ∞ΩÈáè‰øùÁïôÂéüÊñá‰∏≠ÁöÑÈìæÊé•ÂèäÂÖ∂‰ªñÊñáÊú¨Ê†∑Âºè\n  - [x] ÊîØÊåÅ‰ªÖÊòæÁ§∫ËØëÊñáÔºàÈöêËóèÂéüÊñáÔºâ\n- [x] ÁøªËØëÊé•Âè£È´òÁ∫ßÂäüËÉΩ\n  - [x] ÈÄöËøáËá™ÂÆö‰πâÊé•Âè£ÔºåÁêÜËÆ∫‰∏äÊîØÊåÅ‰ªª‰ΩïÁøªËØëÊé•Âè£\n  - [x] ËÅöÂêàÊâπÈáèÂèëÈÄÅÁøªËØëÊñáÊú¨\n  - [x] ÊîØÊåÅÊµÅÂºè‰º†ËæìÔºåÂÆûÊó∂ÊòæÁ§∫ÁøªËØëÁªìÊûú\n  - [x] ÊîØÊåÅAI‰∏ä‰∏ãÊñá‰ºöËØùËÆ∞ÂøÜÂäüËÉΩÔºåÊèêÂçáÁøªËØëÊïàÊûú\n  - [x] Ëá™ÂÆö‰πâAIÊúØËØ≠ËØçÂÖ∏\n  - [x] ÊâÄÊúâÊé•Âè£ÂùáÊîØÊåÅHookÂíåËá™ÂÆö‰πâÂèÇÊï∞Á≠âÈ´òÁ∫ßÂäüËÉΩ\n- [x] Ë∑®ÂÆ¢Êà∑Á´ØÊï∞ÊçÆÂêåÊ≠•\n  - [x] KISS-WorkerÔºàcloudflare/dockerÔºâ\n  - [x] WebDAV\n- [x] Ëá™ÂÆö‰πâÁøªËØëËßÑÂàô\n  - [x] ËßÑÂàôËÆ¢ÈòÖ/ËßÑÂàôÂàÜ‰∫´\n  - [x] Ëá™ÂÆö‰πâ‰∏ì‰∏öÊúØËØ≠\n- [x] Ëá™ÂÆö‰πâÂø´Êç∑ÈîÆ\n  - `Alt+Q` ÂºÄÂêØÁøªËØë\n  - `Alt+C` ÂàáÊç¢Ê†∑Âºè\n  - `Alt+K` ÊâìÂºÄËÆæÁΩÆÂºπÁ™ó\n  - `Alt+S` ÊâìÂºÄÁøªËØëÂºπÁ™ó/ÁøªËØëÈÄâ‰∏≠ÊñáÂ≠ó\n  - `Alt+O` ÊâìÂºÄËÆæÁΩÆÈ°µÈù¢\n  - `Alt+I` ËæìÂÖ•Ê°ÜÁøªËØë\n\n## ÂÆâË£Ö\n\n> Ê≥®ÔºöÂü∫‰∫é‰ª•‰∏ãÂéüÂõ†ÔºåÂª∫ËÆÆ‰ºòÂÖà‰ΩøÁî®ÊµèËßàÂô®Êâ©Â±ï\n>\n> - ÊµèËßàÂô®Êâ©Â±ïÁöÑÂäüËÉΩÊõ¥ÂÆåÊï¥ÔºàÊú¨Âú∞ËØ≠Ë®ÄËØÜÂà´„ÄÅÂè≥ÈîÆËèúÂçïÁ≠âÔºâ\n> - Ê≤πÁå¥ËÑöÊú¨‰ºöÈÅáÂà∞Êõ¥Â§ö‰ΩøÁî®‰∏äÁöÑÈóÆÈ¢òÔºàË∑®ÂüüÈóÆÈ¢ò„ÄÅËÑöÊú¨ÂÜ≤Á™ÅÁ≠âÔºâ\n\n- [x] ÊµèËßàÂô®Êâ©Â±ï\n  - [x] Chrome [ÂÆâË£ÖÂú∞ÂùÄ](https://chrome.google.com/webstore/detail/kiss-translator/bdiifdefkgmcblbcghdlonllpjhhjgof?hl=zh-CN)\n    - [x] Kiwi (Android)\n    - [x] Orion (iOS)\n  - [x] Edge [ÂÆâË£ÖÂú∞ÂùÄ](https://microsoftedge.microsoft.com/addons/detail/%E7%AE%80%E7%BA%A6%E7%BF%BB%E8%AF%91/jemckldkclkinpjighnoilpbldbdmmlh?hl=zh-CN)\n  - [x] Firefox [ÂÆâË£ÖÂú∞ÂùÄ](https://addons.mozilla.org/zh-CN/firefox/addon/kiss-translator/)\n  - [ ] Safari\n    - [ ] Safari (Mac)\n    - [ ] Safari (iOS) \n  - [x] Thunderbird [‰∏ãËΩΩÂú∞ÂùÄ](https://github.com/fishjar/kiss-translator/releases)\n- [x] Ê≤πÁå¥ËÑöÊú¨\n  - [x] Chrome/Edge/Firefox ([Tampermonkey](https://www.tampermonkey.net/)/[Violentmonkey](https://violentmonkey.github.io/)) [ÂÆâË£ÖÈìæÊé•](https://fishjar.github.io/kiss-translator/kiss-translator.user.js)\n    - [Greasy Fork](https://greasyfork.org/zh-CN/scripts/472840-kiss-translator)\n  - [x] iOS Safari ([Userscripts Safari](https://github.com/quoid/userscripts)) [ÂÆâË£ÖÈìæÊé•](https://fishjar.github.io/kiss-translator/kiss-translator-ios-safari.user.js)\n\n## ÂÖ≥ËÅîÈ°πÁõÆ\n\n- Êï∞ÊçÆÂêåÊ≠•ÊúçÂä°: [https://github.com/fishjar/kiss-worker](https://github.com/fishjar/kiss-worker)\n  - ÂèØÁî®‰∫éÊú¨È°πÁõÆÁöÑÊï∞ÊçÆÂêåÊ≠•ÊúçÂä°„ÄÇ\n  - ‰∫¶ÂèØÁî®‰∫éÂàÜ‰∫´‰∏™‰∫∫ÁöÑÁßÅÊúâËßÑÂàôÂàóË°®„ÄÇ\n  - Ëá™Â∑±ÈÉ®ÁΩ≤ÔºåËá™Â∑±ÁÆ°ÁêÜÔºåÊï∞ÊçÆÁßÅÊúâ„ÄÇ\n- Á§æÂå∫ËÆ¢ÈòÖËßÑÂàô: [https://github.com/fishjar/kiss-rules](https://github.com/fishjar/kiss-rules)\n  - Êèê‰æõÁ§æÂå∫Áª¥Êä§ÁöÑÔºåÊúÄÊñ∞ÊúÄÂÖ®ÁöÑËÆ¢ÈòÖËßÑÂàôÂàóË°®„ÄÇ\n  - Ê±ÇÂä©ËßÑÂàôÁõ∏ÂÖ≥ÁöÑÈóÆÈ¢ò„ÄÇ\n\n## Â∏∏ËßÅÈóÆÈ¢ò\n\n### Â¶Ç‰ΩïËÆæÁΩÆÂø´Êç∑ÈîÆ\n\nÂú®Êèí‰ª∂ÁÆ°ÁêÜÈÇ£ÈáåËÆæÁΩÆÔºå‰æãÂ¶ÇÔºö \n\n- chrome [chrome://extensions/shortcuts](chrome://extensions/shortcuts)\n- firefox [about:addons](about:addons)\n\n### ËßÑÂàôËÆæÁΩÆÁöÑ‰ºòÂÖàÁ∫ßÊòØÂ¶Ç‰ΩïÁöÑ\n\n‰∏™‰∫∫ËßÑÂàô > ËÆ¢ÈòÖËßÑÂàô > ÂÖ®Â±ÄËßÑÂàô\n\nÂÖ∂‰∏≠ÂÖ®Â±ÄËßÑÂàô‰ºòÂÖàÁ∫ßÊúÄ‰ΩéÔºå‰ΩÜÈùûÂ∏∏ÈáçË¶ÅÔºåÁõ∏ÂΩì‰∫éÂÖúÂ∫ïËßÑÂàô„ÄÇ\n\n### Êé•Âè£ÔºàOllamaÁ≠âÔºâÊµãËØïÂ§±Ë¥•\n\n‰∏ÄËà¨Êé•Âè£ÊµãËØïÂ§±Ë¥•Â∏∏ËßÅÊúâ‰ª•‰∏ãÂá†ÁßçÂéüÂõ†Ôºö\n\n- Âú∞ÂùÄÂ°´Èîô‰∫ÜÔºö\n  - ÊØîÂ¶Ç `Ollama` ÊúâÂéüÁîüÊé•Âè£Âú∞ÂùÄÂíå `Openai` ÂÖºÂÆπÁöÑÂú∞ÂùÄÔºåÊú¨Êèí‰ª∂ÁõÆÂâçÁªü‰∏ÄÊîØÊåÅ `Openai` ÂÖºÂÆπÁöÑÂú∞ÂùÄÔºå‰∏çÊîØÊåÅ `Ollama` ÂéüÁîüÊé•Âè£Âú∞ÂùÄ\n- Êüê‰∫õAIÊ®°Âûã‰∏çÊîØÊåÅËÅöÂêàÁøªËØëÔºö\n  - Ê≠§ÁßçÊÉÖÂÜµÂèØ‰ª•ÈÄâÊã©Á¶ÅÁî®ËÅöÂêàÁøªËØëÊàñÈÄöËøáËá™ÂÆö‰πâÊé•Âè£ÁöÑÊñπÂºèÊù•‰ΩøÁî®„ÄÇ\n  - ÊàñÈÄöËøáËá™ÂÆö‰πâÊé•Âè£ÁöÑÊñπÂºèÊù•‰ΩøÁî®ÔºåËØ¶ÊÉÖÂèÇËÄÉÔºö [Ëá™ÂÆö‰πâÊé•Âè£Á§∫‰æãÊñáÊ°£](https://github.com/fishjar/kiss-translator/blob/master/custom-api_v2.md)\n- Êüê‰∫õAIÊ®°ÂûãÁöÑÂèÇÊï∞‰∏ç‰∏ÄËá¥Ôºö\n  - ÊØîÂ¶Ç `Gemini` ÂéüÁîüÊé•Âè£ÂèÇÊï∞ÈùûÂ∏∏‰∏ç‰∏ÄËá¥ÔºåÈÉ®ÂàÜÁâàÊú¨ÁöÑÊ®°Âûã‰∏çÊîØÊåÅÊüê‰∫õÂèÇÊï∞‰ºöÂØºËá¥ËøîÂõûÈîôËØØ„ÄÇ\n  - Ê≠§ÁßçÊÉÖÂÜµÂèØ‰ª•ÈÄöËøá `Hook` ‰øÆÊîπËØ∑Ê±Ç `body` ,ÊàñËÄÖÊõ¥Êç¢‰∏∫ `Gemini2` (`Openai` ÂÖºÂÆπÁöÑÂú∞ÂùÄ)\n- ÊúçÂä°Âô®Ë∑®ÂüüÈôêÂà∂ËÆøÈóÆÔºåËøîÂõû403ÈîôËØØÔºö\n  - ÊØîÂ¶Ç `Ollama` ÂêØÂä®Êó∂È°ªÊ∑ªÂä†ÁéØÂ¢ÉÂèòÈáè `OLLAMA_ORIGINS=*`, ÂèÇËÄÉÔºöhttps://github.com/fishjar/kiss-translator/issues/174\n\n### Â°´ÂÜôÁöÑÊé•Âè£Âú®Ê≤πÁå¥ËÑöÊú¨‰∏çËÉΩ‰ΩøÁî®\n\nÊ≤πÁå¥ËÑöÊú¨ÈúÄË¶ÅÂ¢ûÂä†ÂüüÂêçÁôΩÂêçÂçïÔºåÂê¶Âàô‰∏çËÉΩÂèëÂá∫ËØ∑Ê±Ç„ÄÇ\n\n### Â¶Ç‰ΩïËÆæÁΩÆËá™ÂÆö‰πâÊé•Âè£ÁöÑhookÂáΩÊï∞\n\nËá™ÂÆö‰πâÊé•Âè£ÂäüËÉΩÈùûÂ∏∏Âº∫Â§ß„ÄÅÁÅµÊ¥ªÔºåÁêÜËÆ∫ÂèØ‰ª•Êé•ÂÖ•‰ªª‰ΩïÁøªËØëÊé•Âè£„ÄÇ\n\nÁ§∫‰æãÂèÇËÄÉÔºö [custom-api_v2.md](https://github.com/fishjar/kiss-translator/blob/master/custom-api_v2.md)\n\n### Â¶Ç‰ΩïÁõ¥Êé•ËøõÂÖ•Ê≤πÁå¥ËÑöÊú¨ËÆæÁΩÆÈ°µÈù¢\n\nËÆæÁΩÆÈ°µÈù¢Âú∞ÂùÄÔºö https://fishjar.github.io/kiss-translator/options.html\n\n## Êú™Êù•ËßÑÂàí \n\n Êú¨È°πÁõÆ‰∏∫‰∏ö‰ΩôÂºÄÂèëÔºåÊó†‰∏•Ê†ºÊó∂Èó¥Ë°®ÔºåÊ¨¢ËøéÁ§æÂå∫ÂÖ±Âª∫„ÄÇ‰ª•‰∏ã‰∏∫ÂàùÊ≠•ËÆæÊÉ≥ÁöÑÂäüËÉΩÊñπÂêëÔºö\n\n- [x] **ËÅöÂêàÂèëÈÄÅÊñáÊú¨**Ôºö‰ºòÂåñËØ∑Ê±ÇÁ≠ñÁï•ÔºåÂáèÂ∞ëÁøªËØëÊé•Âè£Ë∞ÉÁî®Ê¨°Êï∞ÔºåÊèêÂçáÊÄßËÉΩ„ÄÇ\n- [x] **Â¢ûÂº∫ÂØåÊñáÊú¨ÁøªËØë**ÔºöÊîØÊåÅÊõ¥Â§çÊùÇÁöÑÈ°µÈù¢ÁªìÊûÑÂíåÂØåÊñáÊú¨ÂÜÖÂÆπÁöÑÂáÜÁ°ÆÁøªËØë„ÄÇ\n- [x] **Âº∫ÂåñËá™ÂÆö‰πâ/AI Êé•Âè£**ÔºöÊîØÊåÅÊµÅÂºè‰º†Ëæì„ÄÅ‰∏ä‰∏ãÊñáËÆ∞ÂøÜ„ÄÅÂ§öËΩÆÂØπËØùÁ≠âÈ´òÁ∫ß AI ÂäüËÉΩ„ÄÇ\n- [x] **Ëã±ÊñáËØçÂÖ∏Â§áÁÅæÊú∫Âà∂**ÔºöÂΩìÁøªËØëÊúçÂä°Â§±ÊïàÊó∂ÔºåÂèØÂàáÊç¢ÂÖ∂‰ªñËØçÂÖ∏Êàñ fallback Âà∞Êú¨Âú∞ËØçÂÖ∏Êü•ËØ¢„ÄÇ\n- [x] **‰ºòÂåñ YouTube Â≠óÂπïÊîØÊåÅ**ÔºöÊîπËøõÊµÅÂºèÂ≠óÂπïÁöÑÂêàÂπ∂‰∏éÁøªËØë‰ΩìÈ™åÔºåÂáèÂ∞ëÊñ≠Âè•„ÄÇ\n- [ ] **ËßÑÂàôÂÖ±Âª∫Êú∫Âà∂ÂçáÁ∫ß**ÔºöÂºïÂÖ•Êõ¥ÁÅµÊ¥ªÁöÑËßÑÂàôÂàÜ‰∫´„ÄÅÁâàÊú¨ÁÆ°ÁêÜ‰∏éÁ§æÂå∫ËØÑÂÆ°ÊµÅÁ®ã„ÄÇ\n \n Â¶ÇÊûú‰Ω†ÂØπÊüê‰∏™ÊñπÂêëÊÑüÂÖ¥Ë∂£ÔºåÊ¨¢ËøéÂú® [Issues](https://github.com/fishjar/kiss-translator/issues) ‰∏≠ËÆ®ËÆ∫ÊàñÊèê‰∫§ PRÔºÅ\n\n## ÂºÄÂèëÊåáÂºï\n\n```sh\ngit clone https://github.com/fishjar/kiss-translator.git\ncd kiss-translator\ngit checkout dev # Êèê‰∫§PRÂª∫ËÆÆÊé®ÈÄÅÂà∞devÂàÜÊîØ\npnpm install\npnpm build\n```\n\n### Â§ñÈÉ®Ëß¶ÂèëÁ§∫‰æã\n\n```js\n// `toggle_translate`   ÂàáÊç¢ÁøªËØë\n// `toggle_styles`      ÂàáÊç¢Ê†∑Âºè\n// `toggle_popup`       ÊâìÂºÄ/ÂÖ≥Èó≠ÊéßÂà∂Èù¢Êùø\n// `toggle_transbox`    ÊâìÂºÄ/ÂÖ≥Èó≠ÁøªËØëÂºπÁ™ó\n// `toggle_hover_node`  ÁøªËØëÈº†Ê†áÊÇ¨ÂÅúÊÆµËêΩ\n// `input_translate`    ÁøªËØëËæìÂÖ•Ê°Ü\nwindow.dispatchEvent(new CustomEvent(\"kiss_translator\", {detail: { action: \"toggle_translate\" }}));\n```\n\n## ‰∫§ÊµÅ\n\n- Âä†ÂÖ• [Telegram Áæ§](https://t.me/+RRCu_4oNwrM2NmFl)\n\n## ËµûËµè\n\n![appreciate](https://github.com/fishjar/kiss-translator/assets/1157624/ebaecabe-2934-4172-8085-af236f5ee399)\n",
      "stars_today": 24
    },
    {
      "id": 925273833,
      "name": "flowsint",
      "full_name": "reconurge/flowsint",
      "description": "A modern platform for visual, flexible, and extensible graph-based investigations. For cybersecurity analysts and investigators.",
      "html_url": "https://github.com/reconurge/flowsint",
      "stars": 1581,
      "forks": 198,
      "language": "TypeScript",
      "topics": [
        "investigation",
        "osint",
        "python",
        "recon"
      ],
      "created_at": "2025-01-31T15:10:41Z",
      "updated_at": "2026-01-14T01:04:31Z",
      "pushed_at": "2026-01-13T08:21:21Z",
      "open_issues": 25,
      "owner": {
        "login": "reconurge",
        "avatar_url": "https://avatars.githubusercontent.com/u/182449807?v=4"
      },
      "readme": "# Flowsint\n\n[![License: AGPL-3.0](https://img.shields.io/badge/License-AGPL--3.0-blue.svg)](./LICENSE)\n[![Ethical Software](https://img.shields.io/badge/ethical-use-blue.svg)](./ETHICS.md)\n\nFlowsint is an open-source OSINT graph exploration tool designed for ethical investigation, transparency, and verification.\n\n**Ethics:** Please read [ETHICS.md](./ETHICS.md) for responsible use guidelines.\n\n<img width=\"1439\" height=\"899\" alt=\"hero-dark\" src=\"https://github.com/user-attachments/assets/01eb128e-bef4-486e-9276-c4da58f829ae\" />\n<img width=\"1511\" height=\"946\" alt=\"Capture d‚ÄôeÃÅcran 2026-01-13 aÃÄ 09 15 58\" src=\"https://github.com/user-attachments/assets/d1a9eca6-9ec4-4402-93f4-303c3dc30de1\" />\n<img width=\"1511\" height=\"948\" alt=\"Capture d‚ÄôeÃÅcran 2026-01-13 aÃÄ 09 19 45\" src=\"https://github.com/user-attachments/assets/6d9e9e6d-d8c7-4ed2-8b8c-53a945b28d05\" />\n\n## Contributing\n\nFlowsint is still in early development and definetly needs the help of the community! Feel free to raise issues, propose features, etc.\n\n## Get started\n\nDon't want to read ? Got it. Here's your install instructions:\n\n#### 1. Install pre-requisites\n\n- Docker\n- Make\n\n#### 2. Run install command\n\n```bash\ngit clone https://github.com/reconurge/flowsint.git\ncd flowsint\nmake prod\n```\n\nThen go to [http://localhost:5173/register](http://localhost:5173/register) and create an account. There are no credentials or account by default.\n\n\n> ‚úÖ OSINT investigations need a high level of privacy. Everything is stored on your machine.\n\n\n## What is it?\n\nFlowsint is a graph-based investigation tool focused on reconnaissance and OSINT (Open Source Intelligence). It allows you to explore relationships between entities through a visual graph interface and automated enrichers.\n\n### Available Enrichers\n\n**Domain Enrichers**\n- Reverse DNS Resolution - Find domains pointing to an IP\n- DNS Resolution - Resolve domain to IP addresses\n- Subdomain Discovery - Enumerate subdomains\n- WHOIS Lookup - Get domain registration information\n- Domain to Website - Convert domain to website entity\n- Domain to Root Domain - Extract root domain\n- Domain to ASN - Find ASN associated with domain\n- Domain History - Retrieve historical domain data\n\n**IP Enrichers**\n- IP Information - Get geolocation and network details\n- IP to ASN - Find ASN for IP address\n\n**ASN Enrichers**\n- ASN to CIDRs - Get IP ranges for an ASN\n\n**CIDR Enrichers**\n- CIDR to IPs - Enumerate IPs in a range\n\n**Social Media Enrichers**\n- Maigret - Username search across social platforms\n\n**Organization Enrichers**\n- Organization to ASN - Find ASNs owned by organization\n- Organization Information - Get company details\n- Organization to Domains - Find domains owned by organization\n\n**Cryptocurrency Enrichers**\n- Wallet to Transactions - Get transaction history\n- Wallet to NFTs - Find NFTs owned by wallet\n\n**Website Enrichers**\n- Website Crawler - Crawl and map website structure\n- Website to Links - Extract all links\n- Website to Domain - Extract domain from URL\n- Website to Webtrackers - Identify tracking scripts\n- Website to Text - Extract text content\n\n**Email Enrichers**\n- Email to Gravatar - Find Gravatar profile\n- Email to Breaches - Check data breach databases\n- Email to Domains - Find associated domains\n\n**Phone Enrichers**\n- Phone to Breaches - Check phone number in breaches\n\n**Individual Enrichers**\n- Individual to Organization - Find organizational affiliations\n- Individual to Domains - Find domains associated with person\n\n**Integration Enrichers**\n- N8n Connector - Connect to N8n workflows\n\n## Project structure\n\nThe project is organized into autonomous modules:\n\n### Core modules\n\n- **flowsint-core**: Core utilities, orchestrator, vault, celery tasks, and base classes\n- **flowsint-types**: Pydantic models and type definitions\n- **flowsint-enrichers**: Enricher modules, scanning logic, and tools\n- **flowsint-api**: FastAPI server, API routes, and schemas only\n- **flowsint-app**: Frontend application\n\n### Module dependencies\n\n```\nflowsint-app (frontend)\n    ‚Üì\nflowsint-api (API server)\n    ‚Üì\nflowsint-core (orchestrator, tasks, vault)\n    ‚Üì\nflowsint-enrichers (enrichers & tools)\n    ‚Üì\nflowsint-types (types)\n```\n\n## Development setup\n\n### Prerequisites\n\n- Docker\n\n### Run\n\nMake sure you have **Make** installed.\n\n```bash\nmake dev\n```\n\n### Development\n\nThe app is accessible at [http://localhost:5173](http://localhost:5173).\n\n## Module details\n\n### flowsint-core\n\nCore utilities and base classes used by all other modules:\n\n- Database connections (PostgreSQL, Neo4j)\n- Authentication and authorization\n- Logging and event handling\n- Configuration management\n- Base classes for enrichers and tools\n- Utility functions\n\n### flowsint-types\n\nPydantic models for all data types:\n\n- Domain, IP, ASN, CIDR\n- Individual, Organization, Email, Phone\n- Website, Social profiles, Credentials\n- Crypto wallets, Transactions, NFTs\n- And many more...\n\n### flowsint-enrichers\n\nEnricher modules that process data:\n\n- Domain enrichers (subdomains, WHOIS, resolution)\n- IP enrichers (geolocation, ASN lookup)\n- Social media enrichers (Maigret, Sherlock)\n- Email enrichers (breaches, Gravatar)\n- Crypto enrichers (transactions, NFTs)\n- And many more...\n\n### flowsint-api\n\nFastAPI server providing:\n\n- REST API endpoints\n- Authentication and user management\n- Graph database integration\n- Real-time event streaming\n\n### flowsint-app\n\nFrontend application.\n\n- Modern and UI friendly interface\n- Built for performance (no lag even on thousands of nodes)\n\n## Development workflow\n\n1. **Adding new types**: Add to `flowsint-types` module\n2. **Adding new enrichers**: Add to `flowsint-enrichers` module\n3. **Adding new API endpoints**: Add to `flowsint-api` module\n4. **Adding new utilities**: Add to `flowsint-core` module\n\n## Testing\n\nEach module has its own (incomplete) test suite:\n\n```bash\n# Test core module\ncd flowsint-core\npoetry run pytest\n\n# Test types module\ncd ../flowsint-types\npoetry run pytest\n\n# Test enrichers module\ncd ../flowsint-enrichers\npoetry run pytest\n\n# Test API module\ncd ../flowsint-api\npoetry run pytest\n```\n\n## Contributing\n\n1. Follow the modular structure\n2. Use Poetry for dependency management\n3. Write tests for new functionality\n4. Update documentation as needed\n\n\n---\n\n## ‚öñÔ∏è Legal & Ethical Use\n\n**Ethics:** Please read [ETHICS.md](./ETHICS.md) for responsible use guidelines.\n\nFlowsint is designed **strictly for lawful, ethical investigation and research purposes**.\n\nIt was created to assist:\n- Cybersecurity researchers and analysts\n- Journalists and OSINT investigators\n- Law enforcement or fraud investigation teams\n- Organizations conducting internal threat intelligence or digital risk analysis\n\n**Flowsint must not be used for:**\n- Unauthorized intrusion, surveillance, or data collection\n- Harassment, doxxing, or targeting of individuals\n- Political manipulation, misinformation, or violation of privacy laws\n\nAny misuse of this software is strictly prohibited and goes against the ethical principles defined in [ETHICS.md](./ETHICS.md).\n\n",
      "stars_today": 24
    },
    {
      "id": 36836475,
      "name": "tmux",
      "full_name": "tmux/tmux",
      "description": "tmux source code",
      "html_url": "https://github.com/tmux/tmux",
      "stars": 40755,
      "forks": 2359,
      "language": "C",
      "topics": [],
      "created_at": "2015-06-03T23:32:55Z",
      "updated_at": "2026-01-13T23:43:11Z",
      "pushed_at": "2026-01-13T20:29:29Z",
      "open_issues": 25,
      "owner": {
        "login": "tmux",
        "avatar_url": "https://avatars.githubusercontent.com/u/12054114?v=4"
      },
      "readme": "# Welcome to tmux!\n\ntmux is a terminal multiplexer: it enables a number of terminals to be created,\naccessed, and controlled from a single screen. tmux may be detached from a\nscreen and continue running in the background, then later reattached.\n\nThis release runs on OpenBSD, FreeBSD, NetBSD, Linux, macOS and Solaris.\n\n## Dependencies\n\ntmux depends on [libevent](https://libevent.org) 2.x, available from [this\npage](https://github.com/libevent/libevent/releases/latest).\n\nIt also depends on [ncurses](https://www.gnu.org/software/ncurses/), available\nfrom [this page](https://invisible-mirror.net/archives/ncurses/).\n\nTo build tmux, a C compiler (for example gcc or clang), make, pkg-config and a\nsuitable yacc (yacc or bison) are needed.\n\n## Installation\n\n### Binary packages\n\nSome platforms provide binary packages for tmux, although these are sometimes\nout of date. Examples are listed on\n[this page](https://github.com/tmux/tmux/wiki/Installing).\n\n### From release tarball\n\nTo build and install tmux from a release tarball, use:\n\n~~~bash\n./configure && make\nsudo make install\n~~~\n\ntmux can use the utempter library to update utmp(5), if it is installed - run\nconfigure with `--enable-utempter` to enable this.\n\nFor more detailed instructions on building and installing tmux, see\n[this page](https://github.com/tmux/tmux/wiki/Installing).\n\n### From version control\n\nTo get and build the latest from version control - note that this requires\n`autoconf`, `automake` and `pkg-config`:\n\n~~~bash\ngit clone https://github.com/tmux/tmux.git\ncd tmux\nsh autogen.sh\n./configure && make\n~~~\n\n## Contributing\n\nBug reports, feature suggestions and especially code contributions are most\nwelcome. Please send by email to:\n\ntmux-users@googlegroups.com\n\nOr open a GitHub issue or pull request. **Please read [this\ndocument](CONTRIBUTING.md) before opening an issue.**\n\nThere is [a list of suggestions for contributions](https://github.com/tmux/tmux/wiki/Contributing).\nPlease feel free to ask on the mailing list if you're thinking of working on something or need\nfurther information.\n\n## Documentation\n\nFor documentation on using tmux, see the tmux.1 manpage. View it from the\nsource tree with:\n\n~~~bash\nnroff -mdoc tmux.1|less\n~~~\n\nA small example configuration is in `example_tmux.conf`.\n\nAnd a bash(1) completion file at:\n\nhttps://github.com/scop/bash-completion/blob/main/completions/tmux\n\nFor debugging, run tmux with `-v` or `-vv` to generate server and client log\nfiles in the current directory.\n\n## Support\n\nThe tmux mailing list for general discussion and bug reports is:\n\nhttps://groups.google.com/forum/#!forum/tmux-users\n\nSubscribe by sending an email to:\n\ntmux-users+subscribe@googlegroups.com\n",
      "stars_today": 23
    },
    {
      "id": 1008726722,
      "name": "coze-studio",
      "full_name": "coze-dev/coze-studio",
      "description": "An AI agent development platform with all-in-one visual tools, simplifying agent creation, debugging, and deployment like never before. Coze your way to AI Agent creation.",
      "html_url": "https://github.com/coze-dev/coze-studio",
      "stars": 19443,
      "forks": 2763,
      "language": "TypeScript",
      "topics": [
        "agent",
        "agent-platform",
        "ai-plugins",
        "chatbot",
        "chatbot-framework",
        "coze",
        "coze-platform",
        "generative-ai",
        "go",
        "kouzi",
        "low-code-ai",
        "multimodel-ai",
        "no-code",
        "rag",
        "studio",
        "typescript",
        "workflow"
      ],
      "created_at": "2025-06-26T02:19:21Z",
      "updated_at": "2026-01-14T01:04:25Z",
      "pushed_at": "2026-01-12T09:54:52Z",
      "open_issues": 439,
      "owner": {
        "login": "coze-dev",
        "avatar_url": "https://avatars.githubusercontent.com/u/157483752?v=4"
      },
      "readme": "![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/943f576df3424fa98580c2ad18946719~tplv-goo7wpa0wc-image.image)\n\n<div align=\"center\"><p>\n<a href=\"#what-is-coze-studio\">Coze Studio</a> ‚Ä¢\n<a href=\"#feature-list\">Feature list</a> ‚Ä¢\n<a href=\"#quickstart\">Quickstart</a> ‚Ä¢\n<a href=\"#developer-guide\">Developer Guide</a>\n</p>\n<p>\n  <img alt=\"License\" src=\"https://img.shields.io/badge/license-apache2.0-blue.svg\">\n  <img alt=\"Go Version\" src=\"https://img.shields.io/badge/go-%3E%3D%201.23.4-blue\">\n</p>\n\nEnglish | [‰∏≠Êñá](README.zh_CN.md)\n\n</div>\n\n## What is Coze Studio?\n\n[Coze Studio](https://www.coze.cn/home) is an all-in-one AI agent development tool. Providing the latest large models and tools, various development modes and frameworks, Coze Studio offers the most convenient AI agent development environment, from development to deployment. \n\n* **Provides all core technologies needed for AI agent development**: prompt, RAG, plugin, workflow, enabling developers to focus on creating the core value of AI.\n* **Ready to use for professional AI agent development at the lowest cost**: Coze Studio provides developers with complete app templates and build frameworks, allowing you to quickly construct various AI agents and turn creative ideas into reality.\n\nCoze Studio, derived from the \"Coze Development Platform\" which has served tens of thousands of enterprises and millions of developers, we have made its core engine completely open. It is a one-stop visual development tool for AI Agents that makes creating, debugging, and deploying AI Agents unprecedentedly simple. Through Coze Studio's visual design and build tools, developers can quickly create and debug agents, apps, and workflows using no-code or low-code approaches, enabling powerful AI app development and more customized business logic. It's an ideal choice for building low-code AI products tailored . Coze Studio aims to lower the threshold for AI agent development and application, encouraging community co-construction and sharing for deeper exploration and practice in the AI field.\n\nThe backend of Coze Studio is developed using Golang, the frontend uses React + TypeScript, and the overall architecture is based on microservices and built following domain-driven design (DDD) principles. Provide developers with a high-performance, highly scalable, and easy-to-customize underlying framework to help them address complex business needs.\n## Feature list\n| **Module** | **Feature** |\n| --- | --- |\n| Model service | Manage the model list, integrate services such as OpenAI and Volcengine |\n| Build agent | * Build, publish, and manage agent <br> * Support configuring workflows, knowledge bases, and other resources |\n| Build apps | * Create and publish apps <br> * Build business logic through workflows |\n| Build a workflow | Create, modify, publish, and delete workflows |\n| Develop resources | Support creating and managing the following resources: <br> * Plugins <br> * Knowledge bases <br> * Databases <br> * Prompts |\n| API and SDK | * Create conversations, initiate chats, and other OpenAPI <br> * Integrate agents or apps into your own app through Chat SDK |\n\n## Quickstart\nLearn how to obtain and deploy the open-source version of Coze Studio, quickly build projects, and experience Coze Studio's open-source version.\n\nEnvironment requirements:\n\n* Before installing Coze Studio, please ensure that your machine meets the following minimum system requirements: 2 Core„ÄÅ4 GB\n* Pre-install Docker and Docker Compose, and start the Docker service.\n\nDeployment steps:\n\n1. Retrieve the source code.\n   ```Bash\n   # Clone code\n   git clone https://github.com/coze-dev/coze-studio.git\n   ```\n2. Deploy and start the service. When deploying and starting Coze Studio for the first time, it may take a while to retrieve images and build local images. Please be patient. If you see the message \"Container coze-server Started,\" it means the Coze Studio service has started successfully.\n\n   ```Bash\n   cd coze-studio\n   # start service\n   # for macOS or Linux\n   make web  \n   # for windows\n   cp .env.example .env\n   docker compose -f ./docker/docker-compose.yml up\n   ```\n\n   For common startup failure issues, **please refer to the [FAQ](https://github.com/coze-dev/coze-studio/wiki/9.-FAQ)**.\n3.\tRegister an account by visiting `http://localhost:8888/sign`, entering your username and password, and clicking the Register button.\n4.\tConfigure the model at `http://localhost:8888/admin/#model-management` by adding a new model. (The image version must be greater than or equal to 0.5.0.)\n5.\tVisit Coze Studio at `http://localhost:8888/`.\n\n> [!WARNING]\n> If you want to deploy Coze Studio in a public network environment, it is recommended to assess security risks before you begin, and take corresponding protection measures. Possible security risks include account registration functions, Python execution environments in workflow code nodes, Coze Server listening address configurations, SSRF (Server - Side Request Forgery), and some horizontal privilege escalations in APIs.  For more details, refer to [Quickstart](https://github.com/coze-dev/coze-studio/wiki/2.-Quickstart#security-risks-in-public-networks).\n\n## Developer Guide\n\n* **Project Configuration**:\n   * [Model Configuration](https://github.com/coze-dev/coze-studio/wiki/3.-Model-configuration): Before deploying the open-source version of Coze Studio, you must configure the model service. Otherwise, you cannot select models when building agents, workflows, and apps.\n   * [Plugin Configuration](https://github.com/coze-dev/coze-studio/wiki/4.-Plugin-Configuration): To use official plugins from the plugin store, you must first configure the plugins and add the authentication keys for third-party services.\n   * [Basic Component Configuration](https://github.com/coze-dev/coze-studio/wiki/5.-Basic-component-configuration): Learn how to configure components such as image uploaders to use functions like image uploading in Coze Studio .\n* [API Reference](https://github.com/coze-dev/coze-studio/wiki/6.-API-Reference): The Coze Studio Community Edition API and Chat SDK are authenticated using Personal Access Token, providing APIs for conversations and workflows.\n* [Development Guidelines](https://github.com/coze-dev/coze-studio/wiki/7.-Development-Standards):\n   * [Project Architecture](https://github.com/coze-dev/coze-studio/wiki/7.-Development-Standards#project-architecture): Learn about the technical architecture and core components of the open-source version of Coze Studio.\n   * [Code Development and Testing](https://github.com/coze-dev/coze-studio/wiki/7.-Development-Standards#code-development-and-testing): Learn how to perform secondary development and testing based on the open-source version of Coze Studio.\n   * [Troubleshooting](https://github.com/coze-dev/coze-studio/wiki/7.-Development-Standards#troubleshooting): Learn how to view container states and system logs.\n\n## Using the open-source version of Coze Studio\n> Regarding how to use Coze Studio, refer to the [Coze Development Platform Official Documentation Center](https://www.coze.cn/open/docs) for more information. Please note that certain features, such as tone customization, are limited to the commercial version. Differences between the open-source and commercial versions can be found in the **Feature List**.\n\n\n* [Quick Start](https://www.coze.cn/open/docs/guides/quickstart): Quickly build an AI assistant agent with Coze Studio.\n* [Developing Agents](https://www.coze.cn/open/docs/guides/agent_overview): Learn how to create, build, publish, and manage agents. You can use functions such as knowledge, plugins, etc., to resolve model hallucination and lack of expertise in professional fields. In addition, Coze Studio provides rich memory features that enable agents to generate more accurate responses based on a personal user's historical conversations during interactions.\n* [Develop workflows](https://www.coze.cn/open/docs/guides/workflow): A workflow is a set of executable instructions used to implement business logic or complete specific tasks. It structures data flow and task processing for apps or agents. Coze Studio provides a visual canvas where you can quickly build workflows by dragging and dropping nodes.\n* [Resources such as plugins](https://www.coze.cn/open/docs/guides/plugin): In Coze Studio, workflows, plugins, databases, knowledge bases, and variables are collectively referred to as resources.\n* **API & SDK**: Coze Studio supports [API related to chat and workflows](https://github.com/coze-dev/coze-studio/wiki/6.-API-Reference), and you can also integrate agents or apps with local business systems through [Chat SDK](https://www.coze.cn/open/docs/developer_guides/web_sdk_overview).\n* [Tutorials for practice](https://www.coze.cn/open/docs/tutorial/chat_sdk_web_online_customer_service): Learn how to use Coze Studio to implement various AI scenarios, such as building web-based online customer service using Chat SDK.\n\n## License\nThis project uses the Apache 2.0 license. For details, please refer to the [LICENSE](https://github.com/coze-dev/coze-studio/blob/main/LICENSE-APACHE) file.\n## Community contributions\nWe welcome community contributions. For contribution guidelines, please refer to [CONTRIBUTING](https://github.com/coze-dev/coze-studio/blob/main/CONTRIBUTING.md) and [Code of conduct](https://github.com/coze-dev/coze-studio/blob/main/CODE_OF_CONDUCT.md). We look forward to your contributions!\n## Security and privacy\nIf you discover potential security issues in the project, or believe you may have found a security issue, please notify the ByteDance security team through our [security center](https://security.bytedance.com/src) or [vulnerability reporting email](mailto:sec@bytedance.com).\nPlease **do not** create public GitHub Issues.\n## Join Community\n\nWe are committed to building an open and friendly developer community. All developers interested in AI Agent development are welcome to join us!\n\n### üêõ Issue Reports & Feature Requests\nTo efficiently track and resolve issues while ensuring transparency and collaboration, we recommend participating through:\n- **GitHub Issues**: [Submit bug reports or feature requests](https://github.com/coze-dev/coze-studio/issues)\n- **Pull Requests**: [Contribute code or documentation improvements](https://github.com/coze-dev/coze-studio/pulls)\n\n### üí¨ Technical Discussion & Communication\nJoin our technical discussion groups to share experiences with other developers and stay updated with the latest project developments:\n\n**Feishu Group Chat**  \nScan the QR code below with Feishu mobile app to join:\n\n![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/0a49081e8f3743e8bf3dcdded4bb571a~tplv-goo7wpa0wc-image.image)\n\n**Discord Server**  \nClick to join: [Coze Community](https://discord.gg/sTVN9EVS4B)\n\n**Telegram Group**  \nClick to join: Telegram Group [Coze](https://t.me/+pP9CkPnomDA0Mjgx)\n\n## Acknowledgments\nThank you to all the developers and community members who have contributed to the Coze Studio project. Special thanks:\n\n* The [Eino](https://github.com/cloudwego/eino) framework team - providing powerful support for Coze Studio's agent and workflow runtime engines, model abstractions and implementations, and knowledge base indexing and retrieval\n* The [FlowGram](https://github.com/bytedance/flowgram.ai) team - providing a high-quality workflow building engine for Coze Studio's frontend workflow canvas editor\n* The [Hertz](https://github.com/cloudwego/hertz) team - Go HTTP framework with high-performance and strong-extensibility for building micro-services\n* All users who participated in testing and feedback",
      "stars_today": 23
    },
    {
      "id": 656264456,
      "name": "langchain4j",
      "full_name": "langchain4j/langchain4j",
      "description": "LangChain4j is an open-source Java library that simplifies the integration of LLMs into Java applications through a unified API, providing access to popular LLMs and vector databases. It makes implementing RAG, tool calling (including support for MCP), and agents easy. LangChain4j integrates seamlessly with various enterprise Java frameworks.",
      "html_url": "https://github.com/langchain4j/langchain4j",
      "stars": 10366,
      "forks": 1895,
      "language": "Java",
      "topics": [
        "anthropic",
        "chatgpt",
        "chroma",
        "embeddings",
        "gemini",
        "gpt",
        "huggingface",
        "java",
        "langchain",
        "llama",
        "llm",
        "llms",
        "milvus",
        "ollama",
        "onnx",
        "openai",
        "openai-api",
        "pgvector",
        "pinecone",
        "vector-database"
      ],
      "created_at": "2023-06-20T15:30:29Z",
      "updated_at": "2026-01-14T01:03:59Z",
      "pushed_at": "2026-01-13T13:00:07Z",
      "open_issues": 655,
      "owner": {
        "login": "langchain4j",
        "avatar_url": "https://avatars.githubusercontent.com/u/132277850?v=4"
      },
      "readme": "# LangChain for Java: Supercharge your Java application with the power of LLMs\n\n[![Build Status](https://img.shields.io/github/actions/workflow/status/langchain4j/langchain4j/main.yaml?branch=main&style=for-the-badge&label=CI%20BUILD&logo=github)](https://github.com/langchain4j/langchain4j/actions/workflows/main.yaml)\n[![Nightly Build](https://img.shields.io/github/actions/workflow/status/langchain4j/langchain4j/nightly_jdk17.yaml?branch=main&style=for-the-badge&label=NIGHTLY%20BUILD&logo=github)](https://github.com/langchain4j/langchain4j/actions/workflows/nightly_jdk17.yaml)\n[![CODACY](https://img.shields.io/badge/Codacy-Dashboard-blue?style=for-the-badge&logo=codacy)](https://app.codacy.com/gh/langchain4j/langchain4j/dashboard)\n\n[![Discord](https://img.shields.io/discord/1156626270772269217?logo=discord&style=for-the-badge)](https://discord.gg/JzTFvyjG6R)\n[![BlueSky](https://img.shields.io/badge/@langchain4j-follow-blue?logo=bluesky&style=for-the-badge)](https://bsky.app/profile/langchain4j.dev)\n[![X](https://img.shields.io/badge/@langchain4j-follow-blue?logo=x&style=for-the-badge)](https://x.com/langchain4j)\n[![Maven Version](https://img.shields.io/maven-central/v/dev.langchain4j/langchain4j?logo=apachemaven&style=for-the-badge)](https://search.maven.org/#search|gav|1|g:\"dev.langchain4j\"%20AND%20a:\"langchain4j\")\n\n\n## Introduction\n\nWelcome!\n\nThe goal of LangChain4j is to simplify integrating LLMs into Java applications.\n\nHere's how:\n1. **Unified APIs:**\n   LLM providers (like OpenAI or Google Vertex AI) and embedding (vector) stores (such as Pinecone or Milvus)\n   use proprietary APIs. LangChain4j offers a unified API to avoid the need for learning and implementing specific APIs for each of them.\n   To experiment with different LLMs or embedding stores, you can easily switch between them without the need to rewrite your code.\n   LangChain4j currently supports [20+ popular LLM providers](https://docs.langchain4j.dev/integrations/language-models/)\n   and [30+ embedding stores](https://docs.langchain4j.dev/integrations/embedding-stores/).\n2. **Comprehensive Toolbox:**\n   Since early 2023, the community has been building numerous LLM-powered applications,\n   identifying common abstractions, patterns, and techniques. LangChain4j has refined these into practical code.\n   Our toolbox includes tools ranging from low-level prompt templating, chat memory management, and function calling\n   to high-level patterns like Agents and RAG.\n   For each abstraction, we provide an interface along with multiple ready-to-use implementations based on common techniques.\n   Whether you're building a chatbot or developing a RAG with a complete pipeline from data ingestion to retrieval,\n   LangChain4j offers a wide variety of options.\n3. **Numerous Examples:**\n   These [examples](https://github.com/langchain4j/langchain4j-examples) showcase how to begin creating various LLM-powered applications,\n   providing inspiration and enabling you to start building quickly.\n\nLangChain4j began development in early 2023 amid the ChatGPT hype.\nWe noticed a lack of Java counterparts to the numerous Python and JavaScript LLM libraries and frameworks,\nand we had to fix that!\nAlthough \"LangChain\" is in our name, the project is a fusion of ideas and concepts from LangChain, Haystack,\nLlamaIndex, and the broader community, spiced up with a touch of our own innovation.\n\nWe actively monitor community developments, aiming to quickly incorporate new techniques and integrations,\nensuring you stay up-to-date.\nThe library is under active development. While some features are still being worked on,\nthe core functionality is in place, allowing you to start building LLM-powered apps now!\n\n\n## Documentation\nDocumentation can be found [here](https://docs.langchain4j.dev).\n\nThe documentation chatbot (experimental) can be found [here](https://chat.langchain4j.dev/).\n\n\n## Getting Started\nGetting started guide can be found [here](https://docs.langchain4j.dev/get-started).\n\n\n## Code Examples\nPlease see examples of how LangChain4j can be used in [langchain4j-examples](https://github.com/langchain4j/langchain4j-examples) repo:\n- [Examples in plain Java](https://github.com/langchain4j/langchain4j-examples/tree/main/other-examples/src/main/java)\n- [Examples with Quarkus](https://github.com/quarkiverse/quarkus-langchain4j/tree/main/samples) (uses [quarkus-langchain4j](https://github.com/quarkiverse/quarkus-langchain4j) dependency)\n- [Example with Spring Boot](https://github.com/langchain4j/langchain4j-examples/tree/main/spring-boot-example/src/main/java/dev/langchain4j/example)\n- [Examples with Helidon](https://github.com/helidon-io/helidon-examples/tree/helidon-4.x/examples/integrations/langchain4j) (uses [io.helidon.integrations.langchain4j](https://mvnrepository.com/artifact/io.helidon.integrations.langchain4j) dependency)\n- [Examples with Micronaut](https://github.com/micronaut-projects/micronaut-langchain4j/tree/0.3.x/doc-examples/example-openai-java) (uses [micronaut-langchain4j](https://micronaut-projects.github.io/micronaut-langchain4j/latest/guide/) dependency)\n\n## Useful Materials\nUseful materials can be found [here](https://docs.langchain4j.dev/useful-materials).\n\n\n## Get Help\nPlease use [Discord](https://discord.gg/JzTFvyjG6R) or [GitHub discussions](https://github.com/langchain4j/langchain4j/discussions)\nto get help.\n\n\n## Request Features\nPlease let us know what features you need by [opening an issue](https://github.com/langchain4j/langchain4j/issues/new/choose).\n\n\n## Contribute\nContribution guidelines can be found [here](https://github.com/langchain4j/langchain4j/blob/main/CONTRIBUTING.md).\n",
      "stars_today": 23
    },
    {
      "id": 1028918361,
      "name": "eloqstore",
      "full_name": "eloqdata/eloqstore",
      "description": "Hybrid-tier key-value storage engine built on object storage & local SSDs. Engineered for batch-write efficiency and read optimization with ultra-low tail latency.",
      "html_url": "https://github.com/eloqdata/eloqstore",
      "stars": 125,
      "forks": 9,
      "language": "C++",
      "topics": [
        "coroutines",
        "cpp",
        "eloqdoc",
        "eloqkv",
        "eloqsql",
        "iouring",
        "key-value-store"
      ],
      "created_at": "2025-07-30T08:53:40Z",
      "updated_at": "2026-01-14T00:40:39Z",
      "pushed_at": "2026-01-13T12:06:35Z",
      "open_issues": 36,
      "owner": {
        "login": "eloqdata",
        "avatar_url": "https://avatars.githubusercontent.com/u/173772865?v=4"
      },
      "readme": "<div align=\"center\">\n<a href='https://www.eloqdata.com'>\n<img src=\"images/eloqstore_github_logo.jpg\" alt=\"EloqStore\" height=150></img>\n</a>\n\n---\n\n[![License: BSL 2.0](https://img.shields.io/badge/License-BSL_2.0-blue.svg)](https://github.com/eloqdata/eloqstore/blob/main/LICENSE.md) [![License: AGPL v3](https://img.shields.io/badge/License-AGPL_v3-green.svg)](https://www.gnu.org/licenses/agpl-3.0)\n[![Language](https://img.shields.io/badge/language-C++-orange)](https://isocpp.org/)\n[![GitHub issues](https://img.shields.io/github/issues/eloqdata/eloqstore)](https://github.com/eloqdata/eloqstore/issues)\n[![Release](https://img.shields.io/badge/release-latest-blue)](https://www.eloqdata.com/download)\n<a href=\"https://discord.com/invite/nmYjBkfak6\">\n  <img alt=\"EloqKV\" src=\"https://img.shields.io/badge/discord-blue.svg?logo=discord&logoColor=white\">\n</a>\n</div>\n\n# EloqStore\n\n**EloqStore** is a high-performance hybrid-tier key-value storage engine that combines object storage (S3-compatible) with local NVMe SSDs to deliver exceptional write throughput and sub-millisecond read latency. Built in C++ with a focus on production-grade reliability and performance.\n\nEloqStore serves as the foundational storage layer for EloqData's database products ([EloqKV](https://github.com/eloqdata/eloqkv), [EloqDoc](https://github.com/eloqdata/eloqdoc), [EloqSQL](https://github.com/eloqdata/eloqsql), enabling SSD-based workloads to achieve memory-like latency characteristics while maintaining durability and cost efficiency.\n\nFor example, EloqKV on EloqStore delivers 4x higher disk access throughput compared to Redis's memory access, with **10x** cost reduction, making it a viable drop-in replacement for Redis.\n\n<div align=\"center\">\n<a href='https://www.eloqdata.com'>\n<img src=\"images/eloqstore_benchmark.jpg\" alt=\"EloqStore\" height=250></img>\n</a>\n</div>\n\n## üìã Requirements\n\nEloqStore uses `io_uring` for high-performance asynchronous I/O operations. As a result, it requires:\n\n- **Minimum OS**: Ubuntu 24.04 or later (or equivalent Linux kernel 6.8+)\n- **Kernel**: Linux kernel 6.8+ (required for full io_uring support)\n\n\n## üèóÔ∏è Architecture\n\nEloqStore implements a multi-tier storage architecture:\n\n- **Hot Tier**: In-memory B-tree index with non-leaf nodes cached for O(log n) point lookups\n- **Warm Tier**: Local NVMe SSD for frequently accessed data with single I/O point reads\n- **Cold Tier**: Object storage (S3-compatible) as the primary durable storage backend\n\nThe engine uses a copy-on-write (COW) B-tree structure that enables lock-free reads during batch writes, eliminating read-write contention and ensuring consistent tail latency.\n\n## ‚ú® Core Features\n\n- **Batch Write Optimization**: Copy-on-write B-tree enables high-throughput batch writes without blocking concurrent reads. MVCC-based design eliminates lock contention and provides predictable write amplification.\n\n- **Point Read Tail Latency Optimization**: In-memory B-tree non-leaf nodes ensure exactly one disk I/O per point read on cold data, delivering consistent P99 latency with deterministic I/O patterns.\n\n- **Object Storage as Primary Storage**: S3-compatible object storage backend provides 11 9's durability, unlimited scalability, and high availability with intelligent caching for low-latency access.\n\n- **Zero-Copy Snapshots**: Copy-on-write semantics enable O(1) snapshot creation without data duplication, supporting point-in-time recovery and consistent backups.\n\n- **Agent Branching**: Instant branch creation for isolated data views in AI/ML workloads, enabling experimentation and multi-tenant isolation without data duplication.\n\n## üöÄ Deployment Models\n\n### Self-Hosted\n\nDeploy on-premises or in your cloud infrastructure with full control over data and operations. EloqStore is available under dual license: BSL 2.0 or AGPL v3. Complete source code access.\n\n### Cloud & Enterprise\n\nManaged service [EloqCloud](https://cloud.eloqdata.com) offering with:\n- Serverless architecture (no infrastructure management)\n- High performance and fast scaling\n- Enterprise-grade security and compliance\n\n## üåê Ecosystem\n\nEloqStore exposes a C++ API for direct integration. EloqStore powers different kinds of database products including:\n\n- **Redis/Valkey Protocol**: Drop-in replacement for Redis with persistent storage\n- **MongoDB Wire Protocol**: Document database with MongoDB API compatibility\n- **SQL Interface**: Relational database with MySQL API compatibility\n- **Vector Search**: Native vector indexing and similarity search capabilities\n\n## üî® Compile\n\n### Install Dependencies\n\nFor Ubuntu 24.04, you can install all required dependencies using the provided script:\n\n```shell\nbash scripts/install_dependency_ubuntu2404.sh\n```\n\nThis script installs all necessary dependencies including:\n- Build tools (CMake, GCC, Ninja)\n- System libraries (Boost, glog, jsoncpp, liburing, zstd, etc.)\n- AWS SDK C++ (S3)\n- Testing framework (Catch2)\n- Additional libraries (Abseil, gRPC, etc.)\n\n**Note**: This script requires sudo privileges and may take several minutes to complete.\n\n### Debug Mode\n\n```shell\nmkdir build\ncd build\ncmake .. -DCMAKE_BUILD_TYPE=Debug\ncmake --build . -j8\ncd ..\n```\n\n### Release Mode\n\n```shell\nmkdir Release\ncd Release\ncmake .. -DCMAKE_BUILD_TYPE=Release\ncmake --build . -j8\ncd ..\n```\n\n## üß™ Testing\n\n### Run Unit Tests\n\nEloqStore requires an S3-compatible object storage backend for testing. MinIO is recommended for local development and testing.\n\n**1. Download and start MinIO:**\n\n```shell\n# Download MinIO\nwget https://dl.min.io/server/minio/release/linux-amd64/minio\nchmod +x minio\n\n# Start MinIO server (runs on port 9000 by default)\n./minio server /tmp/minio-data --console-address \":9001\"\n```\n\n**2. Create test bucket\n\n```shell\nmc alias set 'myminio' 'http://127.0.0.1:9000' 'minioadmin' 'minioadmin'\nmc mb myminio/eloqstore\n```\n\n**3. Run unit tests:**\n\n```shell\nctest --test-dir build/tests/\n```\n\n**Note**: Ensure MinIO is running before executing the tests. The tests will connect to MinIO running on `127.0.0.1:9000` by default.\n\n### Benchmark\n\n```shell\n# An example to run eloqstore with 10GB data, with each record 1K.\n# load\n./build/benchmark/simple_bench --kvoptions=./benchmark/opts_append.ini --workload=write-read --kv_size=1024 --batch_size=20000 --max_key=10000000 --read_per_part=4 --partitions=1 --load\n# run\n./build/benchmark/simple_bench --kvoptions=./benchmark/opts_append.ini --workload=write-read --kv_size=1024 --batch_size=20000 --max_key=10000000 --read_per_part=4 --partitions=1\n```\n\n## ü§ù Contributing\n\nWe welcome contributions from the developer community! \n\n1. Check [CONTRIBUTING.md](CONTRIBUTING.md) for development guidelines\n2. Review [GitHub Issues](https://github.com/eloqdata/eloqstore/issues) for planned features\n3. Join our [Discord](https://discord.com/invite/nmYjBkfak6) for discussions\n4. Submit PRs for bug fixes, features, or documentation improvements\n",
      "stars_today": 23
    },
    {
      "id": 60246359,
      "name": "ClickHouse",
      "full_name": "ClickHouse/ClickHouse",
      "description": "ClickHouse¬Æ is a real-time analytics database management system",
      "html_url": "https://github.com/ClickHouse/ClickHouse",
      "stars": 45152,
      "forks": 7977,
      "language": "C++",
      "topics": [
        "ai",
        "analytics",
        "big-data",
        "clickhouse",
        "cloud-native",
        "cpp",
        "database",
        "dbms",
        "distributed",
        "embedded",
        "hacktoberfest",
        "lakehouse",
        "mpp",
        "olap",
        "rust",
        "self-hosted",
        "sql"
      ],
      "created_at": "2016-06-02T08:28:18Z",
      "updated_at": "2026-01-14T00:42:26Z",
      "pushed_at": "2026-01-14T00:42:21Z",
      "open_issues": 5612,
      "owner": {
        "login": "ClickHouse",
        "avatar_url": "https://avatars.githubusercontent.com/u/54801242?v=4"
      },
      "readme": "<div align=center>\n\n[![Website](https://img.shields.io/website?up_message=AVAILABLE&down_message=DOWN&url=https%3A%2F%2Fclickhouse.com&style=for-the-badge)](https://clickhouse.com)\n[![Apache 2.0 License](https://img.shields.io/badge/license-Apache%202.0-blueviolet?style=for-the-badge)](https://www.apache.org/licenses/LICENSE-2.0)\n\n<picture align=center>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/ClickHouse/clickhouse-docs/assets/9611008/4ef9c104-2d3f-4646-b186-507358d2fe28\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://github.com/ClickHouse/clickhouse-docs/assets/9611008/b001dc7b-5a45-4dcd-9275-e03beb7f9177\">\n    <img alt=\"The ClickHouse company logo.\" src=\"https://github.com/ClickHouse/clickhouse-docs/assets/9611008/b001dc7b-5a45-4dcd-9275-e03beb7f9177\">\n</picture>\n\n<h4>ClickHouse¬Æ is an open-source column-oriented database management system that allows generating analytical data reports in real-time.</h4>\n\n</div>\n\n## How To Install (Linux, macOS, FreeBSD)\n\n```\ncurl https://clickhouse.com/ | sh\n```\n\n## Useful Links\n\n* [Official website](https://clickhouse.com/) has a quick high-level overview of ClickHouse on the main page.\n* [ClickHouse Cloud](https://clickhouse.cloud) ClickHouse as a service, built by the creators and maintainers.\n* [Tutorial](https://clickhouse.com/docs/getting_started/tutorial/) shows how to set up and query a small ClickHouse cluster.\n* [Documentation](https://clickhouse.com/docs/) provides more in-depth information.\n* [YouTube channel](https://www.youtube.com/c/ClickHouseDB) has a lot of content about ClickHouse in video format.\n* [ClickHouse Theater](https://presentations.clickhouse.com/) contains presentations and videos about ClickHouse.\n* [Slack](https://clickhouse.com/slack) and [Telegram](https://telegram.me/clickhouse_en) allow chatting with ClickHouse users in real-time.\n* [Blog](https://clickhouse.com/blog/) contains various ClickHouse-related articles, as well as announcements and reports about events.\n* [Bluesky](https://bsky.app/profile/clickhouse.com) and [X](https://x.com/ClickHouseDB) for short news.\n* [Code Browser (github.dev)](https://github.dev/ClickHouse/ClickHouse) with syntax highlighting, powered by github.dev.\n* [Contacts](https://clickhouse.com/company/contact) can help to get your questions answered if there are any.\n\n## Monthly Release & Community Call\n\nClickHouse release 25.12, 2025-12-18. [Presentation](https://presentations.clickhouse.com/2025-release-25.12/), [Video](https://www.youtube.com/watch?v=UdxLygnjsRY)\n\nWatch all release presentations and videos at [ClickHouse Theater](https://presentations.clickhouse.com/) and [YouTube Playlist](https://www.youtube.com/playlist?list=PL0Z2YDlm0b3jAlSy1JxyP8zluvXaN3nxU).\n\n## Upcoming Events\n\nKeep an eye out for upcoming meetups and events around the world.\nSomewhere else you want us to be?\nPlease feel free to reach out to tyler `<at>` clickhouse `<dot>` com.\nYou can also peruse [ClickHouse Events](https://clickhouse.com/company/news-events) for a list of all upcoming trainings, meetups, speaking engagements, etc.\n\nUpcoming meetups\n* [Gurgaon/Delhi Meetup](https://www.meetup.com/clickhouse-delhi-user-group/events/312621832/) - January 10th, 2026\n* [Iceberg Meetup Menlo Park](https://luma.com/abggijbh) - January 21st, 2026\n* [Data & AI Paris Meetup](https://luma.com/3szhmv9h) - January 22nd, 2026\n* [Iceberg Meetup New York](https://luma.com/ifxnj82q) - January 23rd, 2026\n* [ClickHouse France Meetup](https://www.meetup.com/clickhouse-france-user-group/events/312295018/) - January 28th, 2026\n* [Seoul Meetup](https://www.meetup.com/clickhouse-seoul-user-group/events/312679894/) - January 29th, 2026\n* [Iceberg Meetup Brussels](https://luma.com/yx3lhqu9) - January 30th, 2026\n* [ClickHouse Dinner at FOSDEM](https://luma.com/czvs584m) - January 31st, 2026\n* [ClickHouse Barcelona Meetup](https://www.meetup.com/clickhouse-barcelona-user-group/events/312714616/) - February 5th, 2026\n* [ClickHouse London Meetup](https://www.meetup.com/clickhouse-london-user-group/events/312314505/) - February 10th, 2026\n\nRecent meetups\n* [Tel Aviv Meetup](https://www.meetup.com/clickhouse-meetup-israel/events/311868191) - December 29, 2025\n* [Tokyo Meetup](https://www.meetup.com/clickhouse-tokyo-user-group/events/311974739/) - December 15, 2025\n* [Jakarta Meetup](https://www.meetup.com/clickhouse-indonesia-user-group/events/311988089/) - December 9, 2025\n* [San Francisco Meetup](https://www.meetup.com/clickhouse-silicon-valley-meetup-group/events/312075592) - December 8, 2025\n* [New York Meetup](https://www.meetup.com/clickhouse-new-york-user-group/events/312080179/) - December 8, 2025\n* [Warsaw Meetup](https://www.meetup.com/clickhouse-poland-user-group/events/311309076) - November 26, 2025\n* [Bangkok Meetup](https://www.meetup.com/clickhouse-thailand-meetup-group/events/311852739/) - November 25, 2025\n* [Mumbai Meetup](https://www.meetup.com/clickhouse-mumbai-user-group/events/311852373/) - November 22, 2025\n* [Seoul Meetup](https://www.meetup.com/clickhouse-seoul-user-group/events/311633023/) - November 18, 2025\n* [Bogota Meetup](https://www.meetup.com/clickhouse-latinoamerica/events/311069048) - November 13, 2025\n* [Stockholm Meetup](https://www.meetup.com/clickhouse-stockholm-user-group/events/311630931/) - Nov 3, 2025\n\n\n## Recent Recordings\n\n* **Recent Meetup Videos**: [Meetup Playlist](https://www.youtube.com/playlist?list=PL0Z2YDlm0b3iNDUzpY1S3L_iV4nARda_U) Whenever possible recordings of the ClickHouse Community Meetups are edited and presented as individual talks. \n\n## Interested in joining ClickHouse and making it your full-time job?\n\nClickHouse is a nice DBMS, and it's a good place to work.\n\nCheck out our **current openings** here: https://clickhouse.com/company/careers\n\nEmail: careers@clickhouse.com!\n",
      "stars_today": 22
    },
    {
      "id": 359952601,
      "name": "pgvector",
      "full_name": "pgvector/pgvector",
      "description": "Open-source vector similarity search for Postgres",
      "html_url": "https://github.com/pgvector/pgvector",
      "stars": 19231,
      "forks": 1024,
      "language": "C",
      "topics": [
        "approximate-nearest-neighbor-search",
        "nearest-neighbor-search"
      ],
      "created_at": "2021-04-20T21:13:52Z",
      "updated_at": "2026-01-13T22:44:41Z",
      "pushed_at": "2026-01-05T21:02:11Z",
      "open_issues": 14,
      "owner": {
        "login": "pgvector",
        "avatar_url": "https://avatars.githubusercontent.com/u/98363230?v=4"
      },
      "readme": "# pgvector\n\nOpen-source vector similarity search for Postgres\n\nStore your vectors with the rest of your data. Supports:\n\n- exact and approximate nearest neighbor search\n- single-precision, half-precision, binary, and sparse vectors\n- L2 distance, inner product, cosine distance, L1 distance, Hamming distance, and Jaccard distance\n- any [language](#languages) with a Postgres client\n\nPlus [ACID](https://en.wikipedia.org/wiki/ACID) compliance, point-in-time recovery, JOINs, and all of the other [great features](https://www.postgresql.org/about/) of Postgres\n\n[![Build Status](https://github.com/pgvector/pgvector/actions/workflows/build.yml/badge.svg)](https://github.com/pgvector/pgvector/actions)\n\n## Installation\n\n### Linux and Mac\n\nCompile and install the extension (supports Postgres 13+)\n\n```sh\ncd /tmp\ngit clone --branch v0.8.1 https://github.com/pgvector/pgvector.git\ncd pgvector\nmake\nmake install # may need sudo\n```\n\nSee the [installation notes](#installation-notes---linux-and-mac) if you run into issues\n\nYou can also install it with [Docker](#docker), [Homebrew](#homebrew), [PGXN](#pgxn), [APT](#apt), [Yum](#yum), [pkg](#pkg), [APK](#apk), or [conda-forge](#conda-forge), and it comes preinstalled with [Postgres.app](#postgresapp) and many [hosted providers](#hosted-postgres). There are also instructions for [GitHub Actions](https://github.com/pgvector/setup-pgvector).\n\n### Windows\n\nEnsure [C++ support in Visual Studio](https://learn.microsoft.com/en-us/cpp/build/building-on-the-command-line?view=msvc-170#download-and-install-the-tools) is installed and run `x64 Native Tools Command Prompt for VS [version]` as administrator. Then use `nmake` to build:\n\n```cmd\nset \"PGROOT=C:\\Program Files\\PostgreSQL\\18\"\ncd %TEMP%\ngit clone --branch v0.8.1 https://github.com/pgvector/pgvector.git\ncd pgvector\nnmake /F Makefile.win\nnmake /F Makefile.win install\n```\n\nSee the [installation notes](#installation-notes---windows) if you run into issues\n\nYou can also install it with [Docker](#docker) or [conda-forge](#conda-forge).\n\n## Getting Started\n\nEnable the extension (do this once in each database where you want to use it)\n\n```tsql\nCREATE EXTENSION vector;\n```\n\nCreate a vector column with 3 dimensions\n\n```sql\nCREATE TABLE items (id bigserial PRIMARY KEY, embedding vector(3));\n```\n\nInsert vectors\n\n```sql\nINSERT INTO items (embedding) VALUES ('[1,2,3]'), ('[4,5,6]');\n```\n\nGet the nearest neighbors by L2 distance\n\n```sql\nSELECT * FROM items ORDER BY embedding <-> '[3,1,2]' LIMIT 5;\n```\n\nAlso supports inner product (`<#>`), cosine distance (`<=>`), and L1 distance (`<+>`)\n\nNote: `<#>` returns the negative inner product since Postgres only supports `ASC` order index scans on operators\n\n## Storing\n\nCreate a new table with a vector column\n\n```sql\nCREATE TABLE items (id bigserial PRIMARY KEY, embedding vector(3));\n```\n\nOr add a vector column to an existing table\n\n```sql\nALTER TABLE items ADD COLUMN embedding vector(3);\n```\n\nAlso supports [half-precision](#half-precision-vectors), [binary](#binary-vectors), and [sparse](#sparse-vectors) vectors\n\nInsert vectors\n\n```sql\nINSERT INTO items (embedding) VALUES ('[1,2,3]'), ('[4,5,6]');\n```\n\nOr load vectors in bulk using `COPY` ([example](https://github.com/pgvector/pgvector-python/blob/master/examples/loading/example.py))\n\n```sql\nCOPY items (embedding) FROM STDIN WITH (FORMAT BINARY);\n```\n\nUpsert vectors\n\n```sql\nINSERT INTO items (id, embedding) VALUES (1, '[1,2,3]'), (2, '[4,5,6]')\n    ON CONFLICT (id) DO UPDATE SET embedding = EXCLUDED.embedding;\n```\n\nUpdate vectors\n\n```sql\nUPDATE items SET embedding = '[1,2,3]' WHERE id = 1;\n```\n\nDelete vectors\n\n```sql\nDELETE FROM items WHERE id = 1;\n```\n\n## Querying\n\nGet the nearest neighbors to a vector\n\n```sql\nSELECT * FROM items ORDER BY embedding <-> '[3,1,2]' LIMIT 5;\n```\n\nSupported distance functions are:\n\n- `<->` - L2 distance\n- `<#>` - (negative) inner product\n- `<=>` - cosine distance\n- `<+>` - L1 distance\n- `<~>` - Hamming distance (binary vectors)\n- `<%>` - Jaccard distance (binary vectors)\n\nGet the nearest neighbors to a row\n\n```sql\nSELECT * FROM items WHERE id != 1 ORDER BY embedding <-> (SELECT embedding FROM items WHERE id = 1) LIMIT 5;\n```\n\nGet rows within a certain distance\n\n```sql\nSELECT * FROM items WHERE embedding <-> '[3,1,2]' < 5;\n```\n\nNote: Combine with `ORDER BY` and `LIMIT` to use an index\n\n#### Distances\n\nGet the distance\n\n```sql\nSELECT embedding <-> '[3,1,2]' AS distance FROM items;\n```\n\nFor inner product, multiply by -1 (since `<#>` returns the negative inner product)\n\n```tsql\nSELECT (embedding <#> '[3,1,2]') * -1 AS inner_product FROM items;\n```\n\nFor cosine similarity, use 1 - cosine distance\n\n```sql\nSELECT 1 - (embedding <=> '[3,1,2]') AS cosine_similarity FROM items;\n```\n\n#### Aggregates\n\nAverage vectors\n\n```sql\nSELECT AVG(embedding) FROM items;\n```\n\nAverage groups of vectors\n\n```sql\nSELECT category_id, AVG(embedding) FROM items GROUP BY category_id;\n```\n\n## Indexing\n\nBy default, pgvector performs exact nearest neighbor search, which provides perfect recall.\n\nYou can add an index to use approximate nearest neighbor search, which trades some recall for speed. Unlike typical indexes, you will see different results for queries after adding an approximate index.\n\nSupported index types are:\n\n- [HNSW](#hnsw)\n- [IVFFlat](#ivfflat)\n\n## HNSW\n\nAn HNSW index creates a multilayer graph. It has better query performance than IVFFlat (in terms of speed-recall tradeoff), but has slower build times and uses more memory. Also, an index can be created without any data in the table since there isn‚Äôt a training step like IVFFlat.\n\nAdd an index for each distance function you want to use.\n\nL2 distance\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding vector_l2_ops);\n```\n\nNote: Use `halfvec_l2_ops` for `halfvec` and `sparsevec_l2_ops` for `sparsevec` (and similar with the other distance functions)\n\nInner product\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding vector_ip_ops);\n```\n\nCosine distance\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding vector_cosine_ops);\n```\n\nL1 distance\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding vector_l1_ops);\n```\n\nHamming distance\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding bit_hamming_ops);\n```\n\nJaccard distance\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding bit_jaccard_ops);\n```\n\nSupported types are:\n\n- `vector` - up to 2,000 dimensions\n- `halfvec` - up to 4,000 dimensions\n- `bit` - up to 64,000 dimensions\n- `sparsevec` - up to 1,000 non-zero elements\n\n### Index Options\n\nSpecify HNSW parameters\n\n- `m` - the max number of connections per layer (16 by default)\n- `ef_construction` - the size of the dynamic candidate list for constructing the graph (64 by default)\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding vector_l2_ops) WITH (m = 16, ef_construction = 64);\n```\n\nA higher value of `ef_construction` provides better recall at the cost of index build time / insert speed.\n\n### Query Options\n\nSpecify the size of the dynamic candidate list for search (40 by default)\n\n```sql\nSET hnsw.ef_search = 100;\n```\n\nA higher value provides better recall at the cost of speed.\n\nUse `SET LOCAL` inside a transaction to set it for a single query\n\n```sql\nBEGIN;\nSET LOCAL hnsw.ef_search = 100;\nSELECT ...\nCOMMIT;\n```\n\n### Index Build Time\n\nIndexes build significantly faster when the graph fits into `maintenance_work_mem`\n\n```sql\nSET maintenance_work_mem = '8GB';\n```\n\nA notice is shown when the graph no longer fits\n\n```text\nNOTICE:  hnsw graph no longer fits into maintenance_work_mem after 100000 tuples\nDETAIL:  Building will take significantly more time.\nHINT:  Increase maintenance_work_mem to speed up builds.\n```\n\nNote: Do not set `maintenance_work_mem` so high that it exhausts the memory on the server\n\nLike other index types, it‚Äôs faster to create an index after loading your initial data\n\nYou can also speed up index creation by increasing the number of parallel workers (2 by default)\n\n```sql\nSET max_parallel_maintenance_workers = 7; -- plus leader\n```\n\nFor a large number of workers, you may need to increase `max_parallel_workers` (8 by default)\n\nThe [index options](#index-options) also have a significant impact on build time (use the defaults unless seeing low recall)\n\n### Indexing Progress\n\nCheck [indexing progress](https://www.postgresql.org/docs/current/progress-reporting.html#CREATE-INDEX-PROGRESS-REPORTING)\n\n```sql\nSELECT phase, round(100.0 * blocks_done / nullif(blocks_total, 0), 1) AS \"%\" FROM pg_stat_progress_create_index;\n```\n\nThe phases for HNSW are:\n\n1. `initializing`\n2. `loading tuples`\n\n## IVFFlat\n\nAn IVFFlat index divides vectors into lists, and then searches a subset of those lists that are closest to the query vector. It has faster build times and uses less memory than HNSW, but has lower query performance (in terms of speed-recall tradeoff).\n\nThree keys to achieving good recall are:\n\n1. Create the index *after* the table has some data\n2. Choose an appropriate number of lists - a good place to start is `rows / 1000` for up to 1M rows and `sqrt(rows)` for over 1M rows\n3. When querying, specify an appropriate number of [probes](#query-options) (higher is better for recall, lower is better for speed) - a good place to start is `sqrt(lists)`\n\nAdd an index for each distance function you want to use.\n\nL2 distance\n\n```sql\nCREATE INDEX ON items USING ivfflat (embedding vector_l2_ops) WITH (lists = 100);\n```\n\nNote: Use `halfvec_l2_ops` for `halfvec` (and similar with the other distance functions)\n\nInner product\n\n```sql\nCREATE INDEX ON items USING ivfflat (embedding vector_ip_ops) WITH (lists = 100);\n```\n\nCosine distance\n\n```sql\nCREATE INDEX ON items USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);\n```\n\nHamming distance\n\n```sql\nCREATE INDEX ON items USING ivfflat (embedding bit_hamming_ops) WITH (lists = 100);\n```\n\nSupported types are:\n\n- `vector` - up to 2,000 dimensions\n- `halfvec` - up to 4,000 dimensions\n- `bit` - up to 64,000 dimensions\n\n### Query Options\n\nSpecify the number of probes (1 by default)\n\n```sql\nSET ivfflat.probes = 10;\n```\n\nA higher value provides better recall at the cost of speed, and it can be set to the number of lists for exact nearest neighbor search (at which point the planner won‚Äôt use the index)\n\nUse `SET LOCAL` inside a transaction to set it for a single query\n\n```sql\nBEGIN;\nSET LOCAL ivfflat.probes = 10;\nSELECT ...\nCOMMIT;\n```\n\n### Index Build Time\n\nSpeed up index creation on large tables by increasing the number of parallel workers (2 by default)\n\n```sql\nSET max_parallel_maintenance_workers = 7; -- plus leader\n```\n\nFor a large number of workers, you may also need to increase `max_parallel_workers` (8 by default)\n\n### Indexing Progress\n\nCheck [indexing progress](https://www.postgresql.org/docs/current/progress-reporting.html#CREATE-INDEX-PROGRESS-REPORTING)\n\n```sql\nSELECT phase, round(100.0 * tuples_done / nullif(tuples_total, 0), 1) AS \"%\" FROM pg_stat_progress_create_index;\n```\n\nThe phases for IVFFlat are:\n\n1. `initializing`\n2. `performing k-means`\n3. `assigning tuples`\n4. `loading tuples`\n\nNote: `%` is only populated during the `loading tuples` phase\n\n## Filtering\n\nThere are a few ways to index nearest neighbor queries with a `WHERE` clause.\n\n```sql\nSELECT * FROM items WHERE category_id = 123 ORDER BY embedding <-> '[3,1,2]' LIMIT 5;\n```\n\nA good place to start is creating an index on the filter column. This can provide fast, exact nearest neighbor search in many cases. Postgres has a number of [index types](https://www.postgresql.org/docs/current/indexes-types.html) for this: B-tree (default), hash, GiST, SP-GiST, GIN, and BRIN.\n\n```sql\nCREATE INDEX ON items (category_id);\n```\n\nFor multiple columns, consider a [multicolumn index](https://www.postgresql.org/docs/current/indexes-multicolumn.html).\n\n```sql\nCREATE INDEX ON items (location_id, category_id);\n```\n\nExact indexes work well for conditions that match a low percentage of rows. Otherwise, [approximate indexes](#indexing) can work better.\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding vector_l2_ops);\n```\n\nWith approximate indexes, filtering is applied *after* the index is scanned. If a condition matches 10% of rows, with HNSW and the default `hnsw.ef_search` of 40, only 4 rows will match on average. For more rows, increase `hnsw.ef_search`.\n\n```sql\nSET hnsw.ef_search = 200;\n```\n\nStarting with 0.8.0, you can enable [iterative index scans](#iterative-index-scans), which will automatically scan more of the index when needed.\n\n```sql\nSET hnsw.iterative_scan = strict_order;\n```\n\nIf filtering by only a few distinct values, consider [partial indexing](https://www.postgresql.org/docs/current/indexes-partial.html).\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding vector_l2_ops) WHERE (category_id = 123);\n```\n\nIf filtering by many different values, consider [partitioning](https://www.postgresql.org/docs/current/ddl-partitioning.html).\n\n```sql\nCREATE TABLE items (embedding vector(3), category_id int) PARTITION BY LIST(category_id);\n```\n\n## Iterative Index Scans\n\nWith approximate indexes, queries with filtering can return less results since filtering is applied *after* the index is scanned. Starting with 0.8.0, you can enable iterative index scans, which will automatically scan more of the index until enough results are found (or it reaches `hnsw.max_scan_tuples` or `ivfflat.max_probes`).\n\nIterative scans can use strict or relaxed ordering.\n\nStrict ensures results are in the exact order by distance\n\n```sql\nSET hnsw.iterative_scan = strict_order;\n```\n\nRelaxed allows results to be slightly out of order by distance, but provides better recall\n\n```sql\nSET hnsw.iterative_scan = relaxed_order;\n# or\nSET ivfflat.iterative_scan = relaxed_order;\n```\n\nWith relaxed ordering, you can use a [materialized CTE](https://www.postgresql.org/docs/current/queries-with.html#QUERIES-WITH-CTE-MATERIALIZATION) to get strict ordering\n\n```sql\nWITH relaxed_results AS MATERIALIZED (\n    SELECT id, embedding <-> '[1,2,3]' AS distance FROM items WHERE category_id = 123 ORDER BY distance LIMIT 5\n) SELECT * FROM relaxed_results ORDER BY distance + 0;\n```\n\nNote: `+ 0` is needed for Postgres 17+\n\nFor queries that filter by distance, use a materialized CTE and place the distance filter outside of it for best performance (due to the [current behavior](https://www.postgresql.org/message-id/flat/CAOdR5yGUoMQ6j7M5hNUXrySzaqZVGf_Ne%2B8fwZMRKTFxU1nbJg%40mail.gmail.com) of the Postgres executor)\n\n```sql\nWITH nearest_results AS MATERIALIZED (\n    SELECT id, embedding <-> '[1,2,3]' AS distance FROM items ORDER BY distance LIMIT 5\n) SELECT * FROM nearest_results WHERE distance < 5 ORDER BY distance;\n```\n\nNote: Place any other filters inside the CTE\n\n### Iterative Scan Options\n\nSince scanning a large portion of an approximate index is expensive, there are options to control when a scan ends.\n\n#### HNSW\n\nSpecify the max number of tuples to visit (20,000 by default)\n\n```sql\nSET hnsw.max_scan_tuples = 20000;\n```\n\nNote: This is approximate and does not affect the initial scan\n\nSpecify the max amount of memory to use, as a multiple of `work_mem` (1 by default)\n\n```sql\nSET hnsw.scan_mem_multiplier = 2;\n```\n\nNote: Try increasing this if increasing `hnsw.max_scan_tuples` does not improve recall\n\n#### IVFFlat\n\nSpecify the max number of probes\n\n```sql\nSET ivfflat.max_probes = 100;\n```\n\nNote: If this is lower than `ivfflat.probes`, `ivfflat.probes` will be used\n\n## Half-Precision Vectors\n\nUse the `halfvec` type to store half-precision vectors\n\n```sql\nCREATE TABLE items (id bigserial PRIMARY KEY, embedding halfvec(3));\n```\n\n## Half-Precision Indexing\n\nIndex vectors at half precision for smaller indexes\n\n```sql\nCREATE INDEX ON items USING hnsw ((embedding::halfvec(3)) halfvec_l2_ops);\n```\n\nGet the nearest neighbors\n\n```sql\nSELECT * FROM items ORDER BY embedding::halfvec(3) <-> '[1,2,3]' LIMIT 5;\n```\n\n## Binary Vectors\n\nUse the `bit` type to store binary vectors ([example](https://github.com/pgvector/pgvector-python/blob/master/examples/imagehash/example.py))\n\n```sql\nCREATE TABLE items (id bigserial PRIMARY KEY, embedding bit(3));\nINSERT INTO items (embedding) VALUES ('000'), ('111');\n```\n\nGet the nearest neighbors by Hamming distance\n\n```sql\nSELECT * FROM items ORDER BY embedding <~> '101' LIMIT 5;\n```\n\nAlso supports Jaccard distance (`<%>`)\n\n## Binary Quantization\n\nUse expression indexing for binary quantization\n\n```sql\nCREATE INDEX ON items USING hnsw ((binary_quantize(embedding)::bit(3)) bit_hamming_ops);\n```\n\nGet the nearest neighbors by Hamming distance\n\n```sql\nSELECT * FROM items ORDER BY binary_quantize(embedding)::bit(3) <~> binary_quantize('[1,-2,3]') LIMIT 5;\n```\n\nRe-rank by the original vectors for better recall\n\n```sql\nSELECT * FROM (\n    SELECT * FROM items ORDER BY binary_quantize(embedding)::bit(3) <~> binary_quantize('[1,-2,3]') LIMIT 20\n) ORDER BY embedding <=> '[1,-2,3]' LIMIT 5;\n```\n\n## Sparse Vectors\n\nUse the `sparsevec` type to store sparse vectors\n\n```sql\nCREATE TABLE items (id bigserial PRIMARY KEY, embedding sparsevec(5));\n```\n\nInsert vectors\n\n```sql\nINSERT INTO items (embedding) VALUES ('{1:1,3:2,5:3}/5'), ('{1:4,3:5,5:6}/5');\n```\n\nThe format is `{index1:value1,index2:value2}/dimensions` and indices start at 1 like SQL arrays\n\nGet the nearest neighbors by L2 distance\n\n```sql\nSELECT * FROM items ORDER BY embedding <-> '{1:3,3:1,5:2}/5' LIMIT 5;\n```\n\n## Hybrid Search\n\nUse together with Postgres [full-text search](https://www.postgresql.org/docs/current/textsearch-intro.html) for hybrid search.\n\n```sql\nSELECT id, content FROM items, plainto_tsquery('hello search') query\n    WHERE textsearch @@ query ORDER BY ts_rank_cd(textsearch, query) DESC LIMIT 5;\n```\n\nYou can use [Reciprocal Rank Fusion](https://github.com/pgvector/pgvector-python/blob/master/examples/hybrid_search/rrf.py) or a [cross-encoder](https://github.com/pgvector/pgvector-python/blob/master/examples/hybrid_search/cross_encoder.py) to combine results.\n\n## Indexing Subvectors\n\nUse expression indexing to index subvectors\n\n```sql\nCREATE INDEX ON items USING hnsw ((subvector(embedding, 1, 3)::vector(3)) vector_cosine_ops);\n```\n\nGet the nearest neighbors by cosine distance\n\n```sql\nSELECT * FROM items ORDER BY subvector(embedding, 1, 3)::vector(3) <=> subvector('[1,2,3,4,5]'::vector, 1, 3) LIMIT 5;\n```\n\nRe-rank by the full vectors for better recall\n\n```sql\nSELECT * FROM (\n    SELECT * FROM items ORDER BY subvector(embedding, 1, 3)::vector(3) <=> subvector('[1,2,3,4,5]'::vector, 1, 3) LIMIT 20\n) ORDER BY embedding <=> '[1,2,3,4,5]' LIMIT 5;\n```\n\n## Performance\n\n### Tuning\n\nUse a tool like [PgTune](https://pgtune.leopard.in.ua/) to set initial values for Postgres server parameters. For instance, `shared_buffers` should typically be 25% of the server‚Äôs memory. You can find the config file with:\n\n```sql\nSHOW config_file;\n```\n\nAnd check individual settings with:\n\n```sql\nSHOW shared_buffers;\n```\n\nBe sure to restart Postgres for changes to take effect.\n\n### Loading\n\nUse `COPY` for bulk loading data ([example](https://github.com/pgvector/pgvector-python/blob/master/examples/loading/example.py)).\n\n```sql\nCOPY items (embedding) FROM STDIN WITH (FORMAT BINARY);\n```\n\nAdd any indexes *after* loading the initial data for best performance.\n\n### Indexing\n\nSee index build time for [HNSW](#index-build-time) and [IVFFlat](#index-build-time-1).\n\nIn production environments, create indexes concurrently to avoid blocking writes.\n\n```sql\nCREATE INDEX CONCURRENTLY ...\n```\n\n### Querying\n\nUse `EXPLAIN (ANALYZE, BUFFERS)` to debug performance.\n\n```sql\nEXPLAIN (ANALYZE, BUFFERS) SELECT * FROM items ORDER BY embedding <-> '[3,1,2]' LIMIT 5;\n```\n\n#### Exact Search\n\nTo speed up queries without an index, increase `max_parallel_workers_per_gather`.\n\n```sql\nSET max_parallel_workers_per_gather = 4;\n```\n\nIf vectors are normalized to length 1 (like [OpenAI embeddings](https://platform.openai.com/docs/guides/embeddings/which-distance-function-should-i-use)), use inner product for best performance.\n\n```tsql\nSELECT * FROM items ORDER BY embedding <#> '[3,1,2]' LIMIT 5;\n```\n\n#### Approximate Search\n\nTo speed up queries with an IVFFlat index, increase the number of inverted lists (at the expense of recall).\n\n```sql\nCREATE INDEX ON items USING ivfflat (embedding vector_l2_ops) WITH (lists = 1000);\n```\n\n### Vacuuming\n\nVacuuming can take a while for HNSW indexes. Speed it up by reindexing first.\n\n```sql\nREINDEX INDEX CONCURRENTLY index_name;\nVACUUM table_name;\n```\n\n## Monitoring\n\nMonitor performance with [pg_stat_statements](https://www.postgresql.org/docs/current/pgstatstatements.html) (be sure to add it to `shared_preload_libraries`).\n\n```sql\nCREATE EXTENSION pg_stat_statements;\n```\n\nGet the most time-consuming queries with:\n\n```sql\nSELECT query, calls, ROUND((total_plan_time + total_exec_time) / calls) AS avg_time_ms,\n    ROUND((total_plan_time + total_exec_time) / 60000) AS total_time_min\n    FROM pg_stat_statements ORDER BY total_plan_time + total_exec_time DESC LIMIT 20;\n```\n\nMonitor recall by comparing results from approximate search with exact search.\n\n```sql\nBEGIN;\nSET LOCAL enable_indexscan = off; -- use exact search\nSELECT ...\nCOMMIT;\n```\n\n## Scaling\n\nScale pgvector the same way you scale Postgres.\n\nScale vertically by increasing memory, CPU, and storage on a single instance. Use existing tools to [tune parameters](#tuning) and [monitor performance](#monitoring).\n\nScale horizontally with [replicas](https://www.postgresql.org/docs/current/hot-standby.html), or use [Citus](https://github.com/citusdata/citus) or another approach for sharding ([example](https://github.com/pgvector/pgvector-python/blob/master/examples/citus/example.py)).\n\n## Languages\n\nUse pgvector from any language with a Postgres client. You can even generate and store vectors in one language and query them in another.\n\nLanguage | Libraries / Examples\n--- | ---\nAda | [pgvector-ada](https://github.com/pgvector/pgvector-ada)\nAlgol | [pgvector-algol](https://github.com/pgvector/pgvector-algol)\nC | [pgvector-c](https://github.com/pgvector/pgvector-c)\nC++ | [pgvector-cpp](https://github.com/pgvector/pgvector-cpp)\nC#, F#, Visual Basic | [pgvector-dotnet](https://github.com/pgvector/pgvector-dotnet)\nCOBOL | [pgvector-cobol](https://github.com/pgvector/pgvector-cobol)\nCrystal | [pgvector-crystal](https://github.com/pgvector/pgvector-crystal)\nD | [pgvector-d](https://github.com/pgvector/pgvector-d)\nDart | [pgvector-dart](https://github.com/pgvector/pgvector-dart)\nElixir | [pgvector-elixir](https://github.com/pgvector/pgvector-elixir)\nErlang | [pgvector-erlang](https://github.com/pgvector/pgvector-erlang)\nFortran | [pgvector-fortran](https://github.com/pgvector/pgvector-fortran)\nGleam | [pgvector-gleam](https://github.com/pgvector/pgvector-gleam)\nGo | [pgvector-go](https://github.com/pgvector/pgvector-go)\nHaskell | [pgvector-haskell](https://github.com/pgvector/pgvector-haskell)\nJava, Kotlin, Groovy, Scala | [pgvector-java](https://github.com/pgvector/pgvector-java)\nJavaScript, TypeScript | [pgvector-node](https://github.com/pgvector/pgvector-node)\nJulia | [Pgvector.jl](https://github.com/pgvector/Pgvector.jl)\nLisp | [pgvector-lisp](https://github.com/pgvector/pgvector-lisp)\nLua | [pgvector-lua](https://github.com/pgvector/pgvector-lua)\nNim | [pgvector-nim](https://github.com/pgvector/pgvector-nim)\nOCaml | [pgvector-ocaml](https://github.com/pgvector/pgvector-ocaml)\nPascal | [pgvector-pascal](https://github.com/pgvector/pgvector-pascal)\nPerl | [pgvector-perl](https://github.com/pgvector/pgvector-perl)\nPHP | [pgvector-php](https://github.com/pgvector/pgvector-php)\nProlog | [pgvector-prolog](https://github.com/pgvector/pgvector-prolog)\nPython | [pgvector-python](https://github.com/pgvector/pgvector-python)\nR | [pgvector-r](https://github.com/pgvector/pgvector-r)\nRacket | [pgvector-racket](https://github.com/pgvector/pgvector-racket)\nRaku | [pgvector-raku](https://github.com/pgvector/pgvector-raku)\nRuby | [pgvector-ruby](https://github.com/pgvector/pgvector-ruby), [Neighbor](https://github.com/ankane/neighbor)\nRust | [pgvector-rust](https://github.com/pgvector/pgvector-rust)\nSwift | [pgvector-swift](https://github.com/pgvector/pgvector-swift)\nTcl | [pgvector-tcl](https://github.com/pgvector/pgvector-tcl)\nZig | [pgvector-zig](https://github.com/pgvector/pgvector-zig)\n\n## Frequently Asked Questions\n\n#### How many vectors can be stored in a single table?\n\nA non-partitioned table has a limit of 32 TB by default in Postgres. A partitioned table can have thousands of partitions of that size.\n\n#### Is replication supported?\n\nYes, pgvector uses the write-ahead log (WAL), which allows for replication and point-in-time recovery.\n\n#### What if I want to index vectors with more than 2,000 dimensions?\n\nYou can use [half-precision vectors](#half-precision-vectors) or [half-precision indexing](#half-precision-indexing) to index up to 4,000 dimensions or [binary quantization](#binary-quantization) to index up to 64,000 dimensions. Other options are [indexing subvectors](#indexing-subvectors) (for models that support it) or [dimensionality reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction).\n\n#### Can I store vectors with different dimensions in the same column?\n\nYou can use `vector` as the type (instead of `vector(n)`).\n\n```sql\nCREATE TABLE embeddings (model_id bigint, item_id bigint, embedding vector, PRIMARY KEY (model_id, item_id));\n```\n\nHowever, you can only create indexes on rows with the same number of dimensions (using [expression](https://www.postgresql.org/docs/current/indexes-expressional.html) and [partial](https://www.postgresql.org/docs/current/indexes-partial.html) indexing):\n\n```sql\nCREATE INDEX ON embeddings USING hnsw ((embedding::vector(3)) vector_l2_ops) WHERE (model_id = 123);\n```\n\nand query with:\n\n```sql\nSELECT * FROM embeddings WHERE model_id = 123 ORDER BY embedding::vector(3) <-> '[3,1,2]' LIMIT 5;\n```\n\n#### Can I store vectors with more precision?\n\nYou can use the `double precision[]` or `numeric[]` type to store vectors with more precision.\n\n```sql\nCREATE TABLE items (id bigserial PRIMARY KEY, embedding double precision[]);\n\n-- use {} instead of [] for Postgres arrays\nINSERT INTO items (embedding) VALUES ('{1,2,3}'), ('{4,5,6}');\n```\n\nOptionally, add a [check constraint](https://www.postgresql.org/docs/current/ddl-constraints.html) to ensure data can be converted to the `vector` type and has the expected dimensions.\n\n```sql\nALTER TABLE items ADD CHECK (vector_dims(embedding::vector) = 3);\n```\n\nUse [expression indexing](https://www.postgresql.org/docs/current/indexes-expressional.html) to index (at a lower precision):\n\n```sql\nCREATE INDEX ON items USING hnsw ((embedding::vector(3)) vector_l2_ops);\n```\n\nand query with:\n\n```sql\nSELECT * FROM items ORDER BY embedding::vector(3) <-> '[3,1,2]' LIMIT 5;\n```\n\n#### Do indexes need to fit into memory?\n\nNo, but like other index types, you‚Äôll likely see better performance if they do. You can get the size of an index with:\n\n```sql\nSELECT pg_size_pretty(pg_relation_size('index_name'));\n```\n\n## Troubleshooting\n\n#### Why isn‚Äôt a query using an index?\n\nThe query needs to have an `ORDER BY` and `LIMIT`, and the `ORDER BY` must be the result of a distance operator (not an expression) in ascending order.\n\n```sql\n-- index\nORDER BY embedding <=> '[3,1,2]' LIMIT 5;\n\n-- no index\nORDER BY 1 - (embedding <=> '[3,1,2]') DESC LIMIT 5;\n```\n\nYou can encourage the planner to use an index for a query with:\n\n```sql\nBEGIN;\nSET LOCAL enable_seqscan = off;\nSELECT ...\nCOMMIT;\n```\n\nAlso, if the table is small, a table scan may be faster.\n\n#### Why isn‚Äôt a query using a parallel table scan?\n\nThe planner doesn‚Äôt consider [out-of-line storage](https://www.postgresql.org/docs/current/storage-toast.html) in cost estimates, which can make a serial scan look cheaper. You can reduce the cost of a parallel scan for a query with:\n\n```sql\nBEGIN;\nSET LOCAL min_parallel_table_scan_size = 1;\nSET LOCAL parallel_setup_cost = 1;\nSELECT ...\nCOMMIT;\n```\n\nor choose to store vectors inline:\n\n```sql\nALTER TABLE items ALTER COLUMN embedding SET STORAGE PLAIN;\n```\n\n#### Why are there less results for a query after adding an HNSW index?\n\nResults are limited by the size of the dynamic candidate list (`hnsw.ef_search`), which is 40 by default. There may be even less results due to dead tuples or filtering conditions in the query. Enabling [iterative index scans](#iterative-index-scans) can help address this.\n\nAlso, note that `NULL` vectors are not indexed (as well as zero vectors for cosine distance).\n\n#### Why are there less results for a query after adding an IVFFlat index?\n\nThe index was likely created with too little data for the number of lists. Drop the index until the table has more data.\n\n```sql\nDROP INDEX index_name;\n```\n\nResults can also be limited by the number of probes (`ivfflat.probes`). Enabling [iterative index scans](#iterative-index-scans) can address this.\n\nAlso, note that `NULL` vectors are not indexed (as well as zero vectors for cosine distance).\n\n## Reference\n\n- [Vector](#vector-type)\n- [Halfvec](#halfvec-type)\n- [Bit](#bit-type)\n- [Sparsevec](#sparsevec-type)\n\n### Vector Type\n\nEach vector takes `4 * dimensions + 8` bytes of storage. Each element is a single-precision floating-point number (like the `real` type in Postgres), and all elements must be finite (no `NaN`, `Infinity` or `-Infinity`). Vectors can have up to 16,000 dimensions.\n\n### Vector Operators\n\nOperator | Description | Added\n--- | --- | ---\n\\+ | element-wise addition |\n\\- | element-wise subtraction |\n\\* | element-wise multiplication | 0.5.0\n\\|\\| | concatenate | 0.7.0\n<-> | Euclidean distance |\n<#> | negative inner product |\n<=> | cosine distance |\n<+> | taxicab distance | 0.7.0\n\n### Vector Functions\n\nFunction | Description | Added\n--- | --- | ---\nbinary_quantize(vector) ‚Üí bit | binary quantize | 0.7.0\ncosine_distance(vector, vector) ‚Üí double precision | cosine distance |\ninner_product(vector, vector) ‚Üí double precision | inner product |\nl1_distance(vector, vector) ‚Üí double precision | taxicab distance | 0.5.0\nl2_distance(vector, vector) ‚Üí double precision | Euclidean distance |\nl2_normalize(vector) ‚Üí vector | Normalize with Euclidean norm | 0.7.0\nsubvector(vector, integer, integer) ‚Üí vector | subvector | 0.7.0\nvector_dims(vector) ‚Üí integer | number of dimensions |\nvector_norm(vector) ‚Üí double precision | Euclidean norm |\n\n### Vector Aggregate Functions\n\nFunction | Description | Added\n--- | --- | ---\navg(vector) ‚Üí vector | average |\nsum(vector) ‚Üí vector | sum | 0.5.0\n\n### Halfvec Type\n\nEach half vector takes `2 * dimensions + 8` bytes of storage. Each element is a half-precision floating-point number, and all elements must be finite (no `NaN`, `Infinity` or `-Infinity`). Half vectors can have up to 16,000 dimensions.\n\n### Halfvec Operators\n\nOperator | Description | Added\n--- | --- | ---\n\\+ | element-wise addition | 0.7.0\n\\- | element-wise subtraction | 0.7.0\n\\* | element-wise multiplication | 0.7.0\n\\|\\| | concatenate | 0.7.0\n<-> | Euclidean distance | 0.7.0\n<#> | negative inner product | 0.7.0\n<=> | cosine distance | 0.7.0\n<+> | taxicab distance | 0.7.0\n\n### Halfvec Functions\n\nFunction | Description | Added\n--- | --- | ---\nbinary_quantize(halfvec) ‚Üí bit | binary quantize | 0.7.0\ncosine_distance(halfvec, halfvec) ‚Üí double precision | cosine distance | 0.7.0\ninner_product(halfvec, halfvec) ‚Üí double precision | inner product | 0.7.0\nl1_distance(halfvec, halfvec) ‚Üí double precision | taxicab distance | 0.7.0\nl2_distance(halfvec, halfvec) ‚Üí double precision | Euclidean distance | 0.7.0\nl2_norm(halfvec) ‚Üí double precision | Euclidean norm | 0.7.0\nl2_normalize(halfvec) ‚Üí halfvec | Normalize with Euclidean norm | 0.7.0\nsubvector(halfvec, integer, integer) ‚Üí halfvec | subvector | 0.7.0\nvector_dims(halfvec) ‚Üí integer | number of dimensions | 0.7.0\n\n### Halfvec Aggregate Functions\n\nFunction | Description | Added\n--- | --- | ---\navg(halfvec) ‚Üí halfvec | average | 0.7.0\nsum(halfvec) ‚Üí halfvec | sum | 0.7.0\n\n### Bit Type\n\nEach bit vector takes `dimensions / 8 + 8` bytes of storage. See the [Postgres docs](https://www.postgresql.org/docs/current/datatype-bit.html) for more info.\n\n### Bit Operators\n\nOperator | Description | Added\n--- | --- | ---\n<~> | Hamming distance | 0.7.0\n<%> | Jaccard distance | 0.7.0\n\n### Bit Functions\n\nFunction | Description | Added\n--- | --- | ---\nhamming_distance(bit, bit) ‚Üí double precision | Hamming distance | 0.7.0\njaccard_distance(bit, bit) ‚Üí double precision | Jaccard distance | 0.7.0\n\n### Sparsevec Type\n\nEach sparse vector takes `8 * non-zero elements + 16` bytes of storage. Each element is a single-precision floating-point number, and all elements must be finite (no `NaN`, `Infinity` or `-Infinity`). Sparse vectors can have up to 16,000 non-zero elements.\n\n### Sparsevec Operators\n\nOperator | Description | Added\n--- | --- | ---\n<-> | Euclidean distance | 0.7.0\n<#> | negative inner product | 0.7.0\n<=> | cosine distance | 0.7.0\n<+> | taxicab distance | 0.7.0\n\n### Sparsevec Functions\n\nFunction | Description | Added\n--- | --- | ---\ncosine_distance(sparsevec, sparsevec) ‚Üí double precision | cosine distance | 0.7.0\ninner_product(sparsevec, sparsevec) ‚Üí double precision | inner product | 0.7.0\nl1_distance(sparsevec, sparsevec) ‚Üí double precision | taxicab distance | 0.7.0\nl2_distance(sparsevec, sparsevec) ‚Üí double precision | Euclidean distance | 0.7.0\nl2_norm(sparsevec) ‚Üí double precision | Euclidean norm | 0.7.0\nl2_normalize(sparsevec) ‚Üí sparsevec | Normalize with Euclidean norm | 0.7.0\n\n## Installation Notes - Linux and Mac\n\n### Postgres Location\n\nIf your machine has multiple Postgres installations, specify the path to [pg_config](https://www.postgresql.org/docs/current/app-pgconfig.html) with:\n\n```sh\nexport PG_CONFIG=/Library/PostgreSQL/18/bin/pg_config\n```\n\nThen re-run the installation instructions (run `make clean` before `make` if needed). If `sudo` is needed for `make install`, use:\n\n```sh\nsudo --preserve-env=PG_CONFIG make install\n```\n\nA few common paths on Mac are:\n\n- EDB installer - `/Library/PostgreSQL/18/bin/pg_config`\n- Homebrew (arm64) - `/opt/homebrew/opt/postgresql@18/bin/pg_config`\n- Homebrew (x86-64) - `/usr/local/opt/postgresql@18/bin/pg_config`\n\nNote: Replace `18` with your Postgres server version\n\n### Missing Header\n\nIf compilation fails with `fatal error: postgres.h: No such file or directory`, make sure Postgres development files are installed on the server.\n\nFor Ubuntu and Debian, use:\n\n```sh\nsudo apt install postgresql-server-dev-18\n```\n\nNote: Replace `18` with your Postgres server version\n\n### Missing SDK\n\nIf compilation fails and the output includes `warning: no such sysroot directory` on Mac, your Postgres installation points to a path that no longer exists.\n\n```sh\npg_config --cppflags\n```\n\nReinstall Postgres to fix this.\n\n### Portability\n\nBy default, pgvector compiles with `-march=native` on some platforms for best performance. However, this can lead to `Illegal instruction` errors if trying to run the compiled extension on a different machine.\n\nTo compile for portability, use:\n\n```sh\nmake OPTFLAGS=\"\"\n```\n\n## Installation Notes - Windows\n\n### Missing Header\n\nIf compilation fails with `Cannot open include file: 'postgres.h': No such file or directory`, make sure `PGROOT` is correct.\n\n### Mismatched Architecture\n\nIf compilation fails with `error C2196: case value '4' already used`, make sure you‚Äôre using the `x64 Native Tools Command Prompt`. Then run `nmake /F Makefile.win clean` and re-run the installation instructions.\n\n### Missing Symbol\n\nIf linking fails with `unresolved external symbol float_to_shortest_decimal_bufn` with Postgres 17.0-17.2, upgrade to Postgres 17.3+.\n\n### Permissions\n\nIf installation fails with `Access is denied`, re-run the installation instructions as an administrator.\n\n## Additional Installation Methods\n\n### Docker\n\nGet the [Docker image](https://hub.docker.com/r/pgvector/pgvector) with:\n\n```sh\ndocker pull pgvector/pgvector:pg18-trixie\n```\n\nThis adds pgvector to the [Postgres image](https://hub.docker.com/_/postgres) (replace `18` with your Postgres server version, and run it the same way).\n\nSupported tags are:\n\n- `pg18-trixie`, `0.8.1-pg18-trixie`\n- `pg18-bookworm`, `0.8.1-pg18-bookworm`, `pg18`, `0.8.1-pg18`\n- `pg17-trixie`, `0.8.1-pg17-trixie`\n- `pg17-bookworm`, `0.8.1-pg17-bookworm`, `pg17`, `0.8.1-pg17`\n- `pg16-trixie`, `0.8.1-pg16-trixie`\n- `pg16-bookworm`, `0.8.1-pg16-bookworm`, `pg16`, `0.8.1-pg16`\n- `pg15-trixie`, `0.8.1-pg15-trixie`\n- `pg15-bookworm`, `0.8.1-pg15-bookworm`, `pg15`, `0.8.1-pg15`\n- `pg14-trixie`, `0.8.1-pg14-trixie`\n- `pg14-bookworm`, `0.8.1-pg14-bookworm`, `pg14`, `0.8.1-pg14`\n- `pg13-trixie`, `0.8.1-pg13-trixie`\n- `pg13-bookworm`, `0.8.1-pg13-bookworm`, `pg13`, `0.8.1-pg13`\n\nYou can also build the image manually:\n\n```sh\ngit clone --branch v0.8.1 https://github.com/pgvector/pgvector.git\ncd pgvector\ndocker build --pull --build-arg PG_MAJOR=18 -t myuser/pgvector .\n```\n\nIf you increase `maintenance_work_mem`, make sure `--shm-size` is at least that size to avoid an error with parallel HNSW index builds.\n\n```sh\ndocker run --shm-size=1g ...\n```\n\n### Homebrew\n\nWith Homebrew Postgres, you can use:\n\n```sh\nbrew install pgvector\n```\n\nNote: This only adds it to the `postgresql@18` and `postgresql@17` formulas\n\n### PGXN\n\nInstall from the [PostgreSQL Extension Network](https://pgxn.org/dist/vector) with:\n\n```sh\npgxn install vector\n```\n\n### APT\n\nDebian and Ubuntu packages are available from the [PostgreSQL APT Repository](https://wiki.postgresql.org/wiki/Apt). Follow the [setup instructions](https://wiki.postgresql.org/wiki/Apt#Quickstart) and run:\n\n```sh\nsudo apt install postgresql-18-pgvector\n```\n\nNote: Replace `18` with your Postgres server version\n\n### Yum\n\nRPM packages are available from the [PostgreSQL Yum Repository](https://yum.postgresql.org/). Follow the [setup instructions](https://www.postgresql.org/download/linux/redhat/) for your distribution and run:\n\n```sh\nsudo yum install pgvector_18\n# or\nsudo dnf install pgvector_18\n```\n\nNote: Replace `18` with your Postgres server version\n\n### pkg\n\nInstall the FreeBSD package with:\n\n```sh\npkg install postgresql17-pgvector\n```\n\nor the port with:\n\n```sh\ncd /usr/ports/databases/pgvector\nmake install\n```\n\n### APK\n\nInstall the Alpine package with:\n\n```sh\napk add postgresql-pgvector\n```\n\n### conda-forge\n\nWith Conda Postgres, install from [conda-forge](https://anaconda.org/conda-forge/pgvector) with:\n\n```sh\nconda install -c conda-forge pgvector\n```\n\nThis method is [community-maintained](https://github.com/conda-forge/pgvector-feedstock) by [@mmcauliffe](https://github.com/mmcauliffe)\n\n### Postgres.app\n\nDownload the [latest release](https://postgresapp.com/downloads.html) with Postgres 15+.\n\n## Hosted Postgres\n\npgvector is available on [these providers](https://github.com/pgvector/pgvector/issues/54).\n\n## Upgrading\n\n[Install](#installation) the latest version (use the same method as the original installation). Then in each database you want to upgrade, run:\n\n```sql\nALTER EXTENSION vector UPDATE;\n```\n\nYou can check the version in the current database with:\n\n```sql\nSELECT extversion FROM pg_extension WHERE extname = 'vector';\n```\n\n## Thanks\n\nThanks to:\n\n- [PASE: PostgreSQL Ultra-High-Dimensional Approximate Nearest Neighbor Search Extension](https://dl.acm.org/doi/pdf/10.1145/3318464.3386131)\n- [Faiss: A Library for Efficient Similarity Search and Clustering of Dense Vectors](https://github.com/facebookresearch/faiss)\n- [Using the Triangle Inequality to Accelerate k-means](https://cdn.aaai.org/ICML/2003/ICML03-022.pdf)\n- [k-means++: The Advantage of Careful Seeding](https://theory.stanford.edu/~sergei/papers/kMeansPP-soda.pdf)\n- [Concept Decompositions for Large Sparse Text Data using Clustering](https://www.cs.utexas.edu/users/inderjit/public_papers/concept_mlj.pdf)\n- [Efficient and Robust Approximate Nearest Neighbor Search using Hierarchical Navigable Small World Graphs](https://arxiv.org/ftp/arxiv/papers/1603/1603.09320.pdf)\n\n## History\n\nView the [changelog](https://github.com/pgvector/pgvector/blob/master/CHANGELOG.md)\n\n## Contributing\n\nEveryone is encouraged to help improve this project. Here are a few ways you can help:\n\n- [Report bugs](https://github.com/pgvector/pgvector/issues)\n- Fix bugs and [submit pull requests](https://github.com/pgvector/pgvector/pulls)\n- Write, clarify, or fix documentation\n- Suggest or add new features\n\nTo get started with development:\n\n```sh\ngit clone https://github.com/pgvector/pgvector.git\ncd pgvector\nmake\nmake install\n```\n\nTo run all tests:\n\n```sh\nmake installcheck        # regression tests\nmake prove_installcheck  # TAP tests\n```\n\nTo run single tests:\n\n```sh\nmake installcheck REGRESS=functions                            # regression test\nmake prove_installcheck PROVE_TESTS=test/t/001_ivfflat_wal.pl  # TAP test\n```\n\nTo enable assertions:\n\n```sh\nmake clean && PG_CFLAGS=\"-DUSE_ASSERT_CHECKING\" make && make install\n```\n\nTo enable benchmarking:\n\n```sh\nmake clean && PG_CFLAGS=\"-DIVFFLAT_BENCH\" make && make install\n```\n\nTo show memory usage:\n\n```sh\nmake clean && PG_CFLAGS=\"-DHNSW_MEMORY -DIVFFLAT_MEMORY\" make && make install\n```\n\nTo get k-means metrics:\n\n```sh\nmake clean && PG_CFLAGS=\"-DIVFFLAT_KMEANS_DEBUG\" make && make install\n```\n\nResources for contributors\n\n- [Extension Building Infrastructure](https://www.postgresql.org/docs/current/extend-pgxs.html)\n- [Index Access Method Interface Definition](https://www.postgresql.org/docs/current/indexam.html)\n- [Generic WAL Records](https://www.postgresql.org/docs/current/generic-wal.html)\n",
      "stars_today": 22
    },
    {
      "id": 189285554,
      "name": "stats",
      "full_name": "exelban/stats",
      "description": "macOS system monitor in your menu bar",
      "html_url": "https://github.com/exelban/stats",
      "stars": 35732,
      "forks": 1142,
      "language": "Swift",
      "topics": [
        "battery",
        "bluetooth",
        "clock",
        "cpu",
        "disk",
        "fans",
        "gpu",
        "macos",
        "menubar",
        "monitor",
        "network",
        "sensors",
        "stats",
        "temperature"
      ],
      "created_at": "2019-05-29T19:24:56Z",
      "updated_at": "2026-01-13T23:34:38Z",
      "pushed_at": "2026-01-11T14:45:42Z",
      "open_issues": 30,
      "owner": {
        "login": "exelban",
        "avatar_url": "https://avatars.githubusercontent.com/u/13332412?v=4"
      },
      "readme": "<div align=\"center\" markdown=\"1\">\n <sup>Special thanks to:</sup>\n <br><br>\n <a href=\"https://go.warp.dev/stats\">\n  <img width=\"400\" alt=\"Warp sponsorship\" src=\"https://github.com/user-attachments/assets/67ff3655-983d-43cf-9e99-51ce76afa3e7\"/>\n </a>\n <br><br>\n <a href=\"https://go.warp.dev/stats\">Warp is built for coding with multiple AI agents</a>\n</div>\n\n---\n\n# Stats\n\n<a href=\"https://github.com/exelban/stats/releases\"><p align=\"center\"><img src=\"https://github.com/exelban/stats/raw/master/Stats/Supporting%20Files/Assets.xcassets/AppIcon.appiconset/icon_256x256.png\" width=\"120\"></p></a>\n\n[![Stats](https://serhiy.s3.eu-central-1.amazonaws.com/Github_repo/stats/menus%3Fv2.3.2.png?v1)](https://github.com/exelban/stats/releases)\n[![Stats](https://serhiy.s3.eu-central-1.amazonaws.com/Github_repo/stats/popups%3Fv2.3.2.png?v3)](https://github.com/exelban/stats/releases)\n\nmacOS system monitor in your menu bar\n\n## Installation\n### Manual\nYou can download the latest version [here](https://github.com/exelban/stats/releases/latest/download/Stats.dmg).\nThis will download a file called `Stats.dmg`. Open it and move the app to the application folder.\n\n### Homebrew\nTo install it using Homebrew, open the Terminal app and type:\n```bash\nbrew install stats\n```\n\n### Legacy version\nLegacy version for older systems could be found [here](https://mac-stats.com/downloads).\n\n## Requirements\nStats is supported on the released macOS version starting from macOS 10.15 (Catalina).\n\n## Features\nStats is an application that allows you to monitor your macOS system.\n\n - CPU utilization\n - GPU utilization\n - Memory usage\n - Disk utilization\n - Network usage\n - Battery level\n - Fan's control (not maintained)\n - Sensors information (Temperature/Voltage/Power)\n - Bluetooth devices\n - Multiple time zone clock\n\n## FAQs\n\n### How do you change the order of the menu bar icons?\nmacOS decides the order of the menu bar items not `Stats` - it may change after the first reboot after installing Stats.\n\nTo change the order of any menu bar icon - macOS Mojave (version 10.14) and up.\n\n1. Hold down ‚åò (command key).\n2. Drag the icon to the desired position on the menu bar.\n3. Release ‚åò (command key)\n\n### How to reduce energy impact or CPU usage of Stats?\nStats tries to be efficient as it's possible. But reading some data periodically is not a cheap task. Each module has its own \"price\". So, if you want to reduce energy impact from the Stats you need to disable some Stats modules. The most inefficient modules are Sensors and Bluetooth. Disabling these modules could reduce CPU usage and power efficiency by up to 50% in some cases.\n\n### Fan control\nFan control is in legacy mode. It does not receive any updates or fixes. It's not dropped from the app just because in the old Macs it works pretty acceptable. I'm open to accepting fixed or improvements (via PR) for this feature in case someone would like to help with that. But have no option and time to provide support for this feature.\n\n### Sensors show incorrect CPU/GPU core count\nCPU/GPU sensors are simply thermal zones (sensors) on the CPU/GPU. They have no relation to the number of cores or specific cores.\nFor example, a CPU is typically divided into two clusters: efficiency and performance. Each cluster contains multiple temperature sensors, and Stats simply displays these sensors. However, \"CPU Efficient Core 1\" does not represent the temperature of a single efficient core‚Äîit only indicates one of the temperature sensors within the efficiency core cluster.\nAdditionally, with each new SoC, Apple changes the sensor keys. As a result, it takes time to determine which SMC values correspond to the appropriate sensors. If anyone knows how to accurately match the sensors for Apple Silicon, please contact me.\n\n### App crash ‚Äì what to do?\nFirst, ensure that you are using the latest version of Stats. There is a high chance that a fix preventing the crash has already been released. If you are already running the latest version, check the open issues. Only if none of the existing issues address your problem should you open a new issue.\n\n### Why my issue was closed without any response?\nMost probably because it's a duplicated issue and there is an answer to the question, report, or proposition. Please use a search by closed issues to get an answer.\nSo, if your issue was closed without any response, most probably it already has a response.\n\n### External API\nStats uses some external APIs, such as:\n\n- https://api.mac-stats.com ‚Äì For update checks and retrieving the public IP address\n- https://api.github.com ‚Äì Fallback for update checks\n\nBoth of these APIs are used to check for updates. Additionally, an external request is required to obtain the public IP address. I do not want to use any third-party providers for retrieving the public IP address, so I use my own server for this purpose.\n\nIf you have concerns about these requests, you have a few options:\n\n- propose a PR that allows these features to work without an external server\n- block both of these servers using any network filtering app (if you're reading this, you're likely using something like Little Snitch, so you can easily do this). In this case do not expect to receive any updates or see your public IP in the network module.\n\n\n## Supported languages\n- English\n- Polski\n- –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞\n- –†—É—Å—Å–∫–∏–π\n- ‰∏≠Êñá (ÁÆÄ‰Ωì) (thanks to [chenguokai](https://github.com/chenguokai), [Tai-Zhou](https://github.com/Tai-Zhou), and [Jerry](https://github.com/Jerry23011))\n- T√ºrk√ße (thanks to [yusufozgul](https://github.com/yusufozgul) and [setanarut](https://github.com/setanarut))\n- ÌïúÍµ≠Ïñ¥ (thanks to [escapeanaemia](https://github.com/escapeanaemia) and [iamhslee](https://github.com/iamhslee))\n- German (thanks to [natterstefan](https://github.com/natterstefan) and [aneitel](https://github.com/aneitel))\n- ‰∏≠Êñá (ÁπÅÈ´î) (thanks to [iamch15542](https://github.com/iamch15542) and [jrthsr700tmax](https://github.com/jrthsr700tmax))\n- Spanish (thanks to [jcconca](https://github.com/jcconca))\n- Vietnamese (thanks to [HXD.VN](https://github.com/xuandung38))\n- French (thanks to [RomainLt](https://github.com/RomainLt))\n- Italian (thanks to [gmcinalli](https://github.com/gmcinalli))\n- Portuguese (Brazil) (thanks to [marcelochaves95](https://github.com/marcelochaves95) and [pedroserigatto](https://github.com/pedroserigatto))\n- Norwegian Bokm√•l (thanks to [rubjo](https://github.com/rubjo))\n- Êó•Êú¨Ë™û (thanks to [treastrain](https://github.com/treastrain))\n- Portuguese (Portugal) (thanks to [AdamModus](https://github.com/AdamModus))\n- Czech (thanks to [mpl75](https://github.com/mpl75))\n- Magyar (thanks to [moriczr](https://github.com/moriczr))\n- Bulgarian (thanks to [zbrox](https://github.com/zbrox))\n- Romanian (thanks to [razluta](https://github.com/razluta))\n- Dutch (thanks to [ngohungphuc](https://github.com/ngohungphuc))\n- Hrvatski (thanks to [milotype](https://github.com/milotype))\n- Danish (thanks to [casperes1996](https://github.com/casperes1996) and [aleksanderbl29](https://github.com/aleksanderbl29))\n- Catalan (thanks to [davidalonso](https://github.com/davidalonso))\n- Indonesian (thanks to [yooody](https://github.com/yooody))\n- Hebrew (thanks to [BadSugar](https://github.com/BadSugar))\n- Slovenian (thanks to [zigapovhe](https://github.com/zigapovhe))\n- Greek (thanks to [sudoxcess](https://github.com/sudoxcess) and [vaionicle](https://github.com/vaionicle))\n- Persian (thanks to [ShawnAlisson](https://github.com/ShawnAlisson))\n- Slovensk√Ω (thanks to [martinbernat](https://github.com/martinbernat))\n- Thai (thanks to [apiphoomchu](https://github.com/apiphoomchu))\n- Estonian (thanks to [postylem](https://github.com/postylem))\n- Hindi (thanks to [patiljignesh](https://github.com/patiljignesh))\n- Finnish (thanks to [eightscrow](https://github.com/eightscrow))\n\nYou can help by adding a new language or improving the existing translation.\n\n## License\n[MIT License](https://github.com/exelban/stats/blob/master/LICENSE)\n",
      "stars_today": 20
    },
    {
      "id": 41889031,
      "name": "NewPipe",
      "full_name": "TeamNewPipe/NewPipe",
      "description": "A libre lightweight streaming front-end for Android.",
      "html_url": "https://github.com/TeamNewPipe/NewPipe",
      "stars": 36273,
      "forks": 3377,
      "language": "Java",
      "topics": [
        "4k",
        "android",
        "bandcamp",
        "download-videos",
        "newpipe",
        "peertube",
        "soundcloud",
        "translation",
        "video",
        "watch",
        "youtube-video"
      ],
      "created_at": "2015-09-03T23:39:26Z",
      "updated_at": "2026-01-13T21:12:54Z",
      "pushed_at": "2026-01-13T14:36:02Z",
      "open_issues": 1362,
      "owner": {
        "login": "TeamNewPipe",
        "avatar_url": "https://avatars.githubusercontent.com/u/22159318?v=4"
      },
      "readme": "<h3 align=\"center\">We are <i>rewriting</i> large chunks of the codebase, to bring about <a href=\"https://newpipe.net/blog/pinned/announcement/newpipe-0.27.6-rewrite-team-states/#the-refactor\">a modern and stable NewPipe</a>! You can download nightly builds <a href=\"https://github.com/TeamNewPipe/NewPipe-refactor-nightly/releases\">here</a>.</h3>\n<h4 align=\"center\">Please work on the <code>refactor</code> branch if you want to contribute <i>new features</i>. The current codebase is in maintenance mode and will only receive <i>bugfixes</i>.</h4>\n\n<p align=\"center\"><a href=\"https://newpipe.net\"><img src=\"assets/new_pipe_icon_5.png\" width=\"150\"></a></p> \n<h2 align=\"center\"><b>NewPipe</b></h2>\n<h4 align=\"center\">A libre lightweight streaming front-end for Android.</h4>\n\n<p align=\"center\"><a href=\"https://f-droid.org/packages/org.schabi.newpipe/\"><img src=\"https://fdroid.gitlab.io/artwork/badge/get-it-on-en.svg\" alt=\"Get it on F-Droid\" width=206/></a></p>\n\n<p align=\"center\">\n<a href=\"https://github.com/TeamNewPipe/NewPipe/releases\" alt=\"GitHub NewPipe releases\"><img src=\"https://img.shields.io/github/release/TeamNewPipe/NewPipe.svg\" ></a>\n<a href=\"https://github.com/TeamNewPipe/NewPipe-nightly/releases\" alt=\"GitHub NewPipe nightly releases\"><img src=\"https://img.shields.io/github/release/TeamNewPipe/NewPipe-nightly.svg?labelColor=purple&label=dev%20nightly\"></a>\n<a href=\"https://github.com/TeamNewPipe/NewPipe-refactor-nightly/releases\" alt=\"GitHub NewPipe refactor nightly releases\"><img src=\"https://img.shields.io/github/release/TeamNewPipe/NewPipe-refactor-nightly.svg?labelColor=purple&label=refactor%20nightly\"></a>\n<a href=\"https://www.gnu.org/licenses/gpl-3.0\" alt=\"License: GPLv3\"><img src=\"https://img.shields.io/badge/License-GPL%20v3-blue.svg\"></a>\n<a href=\"https://github.com/TeamNewPipe/NewPipe/actions\" alt=\"Build Status\"><img src=\"https://github.com/TeamNewPipe/NewPipe/actions/workflows/ci.yml/badge.svg?branch=dev&event=push\"></a>\n<a href=\"https://hosted.weblate.org/engage/newpipe/\" alt=\"Translation Status\"><img src=\"https://hosted.weblate.org/widgets/newpipe/-/svg-badge.svg\"></a>\n</p>\n\n<p align=\"center\">\n<a href=\"https://web.libera.chat/#newpipe\" alt=\"IRC channel: #newpipe\"><img src=\"https://img.shields.io/badge/IRC%20chat-%23newpipe-brightgreen.svg\"></a>\n<a href=\"https://matrix.to/#/#newpipe:matrix.newpipe-ev.de\" alt=\"Matrix channel: #newpipe\"><img src=\"https://img.shields.io/badge/Matrix%20chat-%23newpipe-blue\"></a>\n</p>\n\n<hr>\n<p align=\"center\"><a href=\"#screenshots\">Screenshots</a> &bull; <a href=\"#supported-services\">Supported Services</a> &bull; <a href=\"#description\">Description</a> &bull; <a href=\"#features\">Features</a> &bull; <a href=\"#installation-and-updates\">Installation and updates</a> &bull; <a href=\"#contribution\">Contribution</a> &bull; <a href=\"#donate\">Donate</a> &bull; <a href=\"#license\">License</a></p>\n<p align=\"center\"><a href=\"https://newpipe.net\">Website</a> &bull; <a href=\"https://newpipe.net/blog/\">Blog</a> &bull; <a href=\"https://newpipe.net/FAQ/\">FAQ</a> &bull; <a href=\"https://newpipe.net/press/\">Press</a></p>\n<hr>\n\n*Read this document in other languages: [Deutsch](doc/README.de.md), [English](README.md), [Espa√±ol](doc/README.es.md), [Fran√ßais](doc/README.fr.md), [‡§π‡§ø‡§®‡•ç‡§¶‡•Ä](doc/README.hi.md), [Italiano](doc/README.it.md), [ÌïúÍµ≠Ïñ¥](doc/README.ko.md), [Portugu√™s Brasil](doc/README.pt_BR.md), [Polski](doc/README.pl.md), [‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä ](doc/README.pa.md), [Êó•Êú¨Ë™û](doc/README.ja.md), [Rom√¢nƒÉ](doc/README.ro.md), [Soomaali](doc/README.so.md), [T√ºrk√ße](doc/README.tr.md), [Ê≠£È´î‰∏≠Êñá](doc/README.zh_TW.md), [‡¶Ö‡¶∏‡¶Æ‡ßÄ‡¶Ø‡¶º‡¶æ](doc/README.asm.md), [–°—Ä–ø—Å–∫–∏](doc/README.sr.md), [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](README.ar.md)* \n\n> [!warning]\n> <b>THIS APP IS IN BETA, SO YOU MAY ENCOUNTER BUGS. IF YOU DO, OPEN AN ISSUE IN OUR GITHUB REPOSITORY BY FILLING OUT THE ISSUE TEMPLATE.</b>\n> \n> <b>PUTTING NEWPIPE, OR ANY FORK OF IT, INTO THE GOOGLE PLAY STORE VIOLATES THEIR TERMS AND CONDITIONS.</b>\n\n## Screenshots\n\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/00.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/00.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/01.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/01.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/02.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/02.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/03.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/03.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/04.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/04.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/05.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/05.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/06.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/06.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/07.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/07.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/08.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/08.png)\n<br/><br/>\n[<img src=\"fastlane/metadata/android/en-US/images/tenInchScreenshots/09.png\" width=405>](fastlane/metadata/android/en-US/images/tenInchScreenshots/09.png)\n[<img src=\"fastlane/metadata/android/en-US/images/tenInchScreenshots/10.png\" width=405>](fastlane/metadata/android/en-US/images/tenInchScreenshots/10.png)\n\n### Supported Services\n\nNewPipe currently supports these services:\n\n<!-- We link to the service websites separately to avoid people accidentally opening a website they didn't want to. -->\n* YouTube ([website](https://www.youtube.com/)) and YouTube Music ([website](https://music.youtube.com/)) ([wiki](https://en.wikipedia.org/wiki/YouTube))\n* PeerTube ([website](https://joinpeertube.org/)) and all its instances (open the website to know what that means!) ([wiki](https://en.wikipedia.org/wiki/PeerTube))\n* Bandcamp ([website](https://bandcamp.com/)) ([wiki](https://en.wikipedia.org/wiki/Bandcamp))\n* SoundCloud ([website](https://soundcloud.com/)) ([wiki](https://en.wikipedia.org/wiki/SoundCloud))\n* media.ccc.de ([website](https://media.ccc.de/)) ([wiki](https://en.wikipedia.org/wiki/Chaos_Computer_Club))\n\nAs you can see, NewPipe supports multiple video and audio services. Though it started off with YouTube, other people have added more services over the years, making NewPipe more and more versatile!\n\nPartially due to circumstance, and partially due to its popularity, YouTube is the best supported out of these services. If you use or are familiar with any of these other services, please help us improve support for them! We're looking for maintainers for SoundCloud and PeerTube.\n\nIf you intend to add a new service, please get in touch with us first! Our [docs](https://teamnewpipe.github.io/documentation/) provide more information on how a new service can be added to the app and to the [NewPipe Extractor](https://github.com/TeamNewPipe/NewPipeExtractor).\n\n## Description\n\nNewPipe works by fetching the required data from the official API (e.g. PeerTube) of the service you're using. If the official API is restricted (e.g. YouTube) for our purposes, or is proprietary, the app parses the website or uses an internal API instead. This means that you don't need an account on any service to use NewPipe.\n\nAlso, since they are free and open source software, neither the app nor the Extractor use any proprietary libraries or frameworks, such as Google Play Services. This means you can use NewPipe on devices or custom ROMs that do not have Google apps installed.\n\n### Features\n\n* Watch videos at resolutions up to 4K\n* Listen to audio in the background, only loading the audio stream to save data\n* Popup mode (floating player, aka Picture-in-Picture)\n* Watch live streams\n* Show/hide subtitles/closed captions\n* Search videos and audios (on YouTube, you can specify the content language as well)\n* Enqueue videos (and optionally save them as local playlists)\n* Show/hide general information about videos (such as description and tags)\n* Show/hide next/related videos\n* Show/hide comments\n* Search videos, audios, channels, playlists and albums\n* Browse videos and audios within a channel\n* Subscribe to channels (yes, without logging into any account!)\n* Get notifications about new videos from channels you're subscribed to\n* Create and edit channel groups (for easier browsing and management)\n* Browse video feeds generated from your channel groups\n* View and search your watch history\n* Search and watch playlists (these are remote playlists, which means they're fetched from the service you're browsing)\n* Create and edit local playlists (these are created and saved within the app, and have nothing to do with any service)\n* Download videos/audios/subtitles (closed captions)\n* Open in Kodi\n* Watch/Block age-restricted material\n\n<!-- Hidden span to keep old links compatible. You should remove this span if you're translating the README into another language.-->\n<span id=\"updates\"></span>\n\n## Installation and updates\nYou can install NewPipe using one of the following methods:\n 1. Add our custom repo to F-Droid and install it from there. The instructions are here: https://newpipe.net/FAQ/tutorials/install-add-fdroid-repo/\n 2. Download the APK from [GitHub Releases](https://github.com/TeamNewPipe/NewPipe/releases), [compare the signing key](#apk-info) and install it.\n 3. Update via F-Droid. This is the slowest method of getting updates, as F-Droid must recognize changes, build the APK itself, sign it, and then push the update to users.\n 4. Build a debug APK yourself. This is the fastest way to get new features on your device, but is much more complicated, so we recommend using one of the other methods.\n 5. If you're interested in a specific feature or bugfix provided in a Pull Request in this repo, you can also download its APK from within the PR. Read the PR description for instructions. The great thing about PR-specific APKs is that they're installed side-by-side the official app, so you don't have to worry about losing your data or messing anything up.\n\nWe recommend method 1 for most users. APKs installed using method 1 or 2 are compatible with each other (meaning that if you installed NewPipe using either method 1 or 2, you can also update NewPipe using the other), but not with those installed using method 3. This is due to the same signing key (ours) being used for 1 and 2, but a different signing key (F-Droid's) being used for 3. Building a debug APK using method 4 excludes a key entirely. Signing keys help ensure that a user isn't tricked into installing a malicious update to an app. When using method 5, each APK is signed with a different random key supplied by GitHub Actions, so you cannot even update it. You will have to backup and restore the app data each time you wish to use a new APK.\n\nIn the meanwhile, if you want to switch sources for some reason (e.g. NewPipe's core functionality breaks and F-Droid doesn't have the latest update yet), we recommend following this procedure:\n1. Back up your data via Settings > Backup and Restore > Export Database so you keep your history, subscriptions, and playlists\n2. Uninstall NewPipe\n3. Download the APK from the new source and install it\n4. Import the data from step 1 via Settings > Backup and Restore > Import Database\n\n> [!Note]\n> When you're importing a database into the official app, always make sure that it is the one you exported _from_ the official app. If you import a database exported from an APK other than the official app, it may break things. Such an action is unsupported, and you should only do so when you're absolutely certain you know what you're doing.\n\n### APK Info\n\nThis is the SHA fingerprint of NewPipe's signing key to verify downloaded APKs which are signed by us. The fingerprint is also available on [NewPipe's website](https://newpipe.net#download). This is relevant for method 2.\n```\nCB:84:06:9B:D6:81:16:BA:FA:E5:EE:4E:E5:B0:8A:56:7A:A6:D8:98:40:4E:7C:B1:2F:9E:75:6D:F5:CF:5C:AB\n```\n\n## Contribution\nWhether you have ideas, translations, design changes, code cleaning, or even major code changes, help is always welcome. The app gets better and better with each contribution, no matter how big or small! If you'd like to get involved, check our [contribution notes](.github/CONTRIBUTING.md).\n\n<a href=\"https://hosted.weblate.org/engage/newpipe/\">\n<img src=\"https://hosted.weblate.org/widgets/newpipe/-/287x66-grey.png\" alt=\"Translation status\" />\n</a>\n\n## Donate\nIf you like NewPipe, you're welcome to send a donation. We prefer Liberapay, as it is both open-source and non-profit. For further info on donating to NewPipe, please visit our [website](https://newpipe.net/donate).\n\n<table>\n  <tr>\n    <td><a href=\"https://liberapay.com/TeamNewPipe/\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/Liberapay_logo_v2_white-on-yellow.svg\" alt=\"Liberapay\" width=\"80px\" ></a></td>\n    <td><a href=\"https://liberapay.com/TeamNewPipe/\"><img src=\"assets/liberapay_qr_code.png\" alt=\"Visit NewPipe at liberapay.com\" width=\"100px\"></a></td>\n    <td><a href=\"https://liberapay.com/TeamNewPipe/donate\"><img src=\"assets/liberapay_donate_button.svg\" alt=\"Donate via Liberapay\" height=\"35px\"></a></td>\n  </tr>\n</table>\n\n## Privacy Policy\n\nThe NewPipe project aims to provide a private, anonymous experience for using web-based media services. Therefore, the app does not collect any data without your consent. NewPipe's privacy policy explains in detail what data is sent and stored when you send a crash report, or leave a comment in our blog. You can find the document [here](https://newpipe.net/legal/privacy/).\n\n## License\n[![GNU GPLv3 Image](https://www.gnu.org/graphics/gplv3-127x51.png)](https://www.gnu.org/licenses/gpl-3.0.en.html)  \n\nNewPipe is Free Software: You can use, study, share, and improve it at will. Specifically you can redistribute and/or modify it under the terms of the [GNU General Public License](https://www.gnu.org/licenses/gpl.html) as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\n",
      "stars_today": 19
    },
    {
      "id": 252813491,
      "name": "nuclei",
      "full_name": "projectdiscovery/nuclei",
      "description": "Nuclei is a fast, customizable vulnerability scanner powered by the global security community and built on a simple YAML-based DSL, enabling collaboration to tackle trending vulnerabilities on the internet. It helps you find vulnerabilities in your applications, APIs, networks, DNS, and cloud configurations.",
      "html_url": "https://github.com/projectdiscovery/nuclei",
      "stars": 26509,
      "forks": 3047,
      "language": "Go",
      "topics": [
        "attack-surface",
        "cve-scanner",
        "dast",
        "hacktoberfest",
        "nuclei-engine",
        "security",
        "security-scanner",
        "subdomain-takeover",
        "vulnerability-assessment",
        "vulnerability-detection",
        "vulnerability-scanner"
      ],
      "created_at": "2020-04-03T18:47:11Z",
      "updated_at": "2026-01-14T00:54:31Z",
      "pushed_at": "2026-01-12T13:07:26Z",
      "open_issues": 198,
      "owner": {
        "login": "projectdiscovery",
        "avatar_url": "https://avatars.githubusercontent.com/u/50994705?v=4"
      },
      "readme": "![nuclei](/static/nuclei-cover-image.png)\n\n<div align=\"center\">\n  \n  <a href=\"https://github.com/projectdiscovery/nuclei/blob/main/README.md\">`English`</a> ‚Ä¢\n  <a href=\"https://github.com/projectdiscovery/nuclei/blob/main/README_CN.md\">`‰∏≠Êñá`</a> ‚Ä¢\n  <a href=\"https://github.com/projectdiscovery/nuclei/blob/main/README_KR.md\">`Korean`</a> ‚Ä¢\n  <a href=\"https://github.com/projectdiscovery/nuclei/blob/main/README_ID.md\">`Indonesia`</a> ‚Ä¢\n  <a href=\"https://github.com/projectdiscovery/nuclei/blob/main/README_ES.md\">`Spanish`</a> ‚Ä¢\n  <a href=\"https://github.com/projectdiscovery/nuclei/blob/main/README_JP.md\">`Êó•Êú¨Ë™û`</a> ‚Ä¢\n  <a href=\"https://github.com/projectdiscovery/nuclei/blob/main/README_PT-BR.md\">`Portuguese`</a> ‚Ä¢\n  <a href=\"https://github.com/projectdiscovery/nuclei/blob/main/README_TR.md\">`T√ºrk√ße`</a>\n  \n</div>\n\n<p align=\"center\">\n\n<a href=\"https://docs.projectdiscovery.io/tools/nuclei/overview?utm_source=github&utm_medium=web&utm_campaign=nuclei_readme\"><img src=\"https://img.shields.io/badge/Documentation-%23000000.svg?style=for-the-badge&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9IiNmZmZmZmYiIHN0cm9rZS13aWR0aD0iMiIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIiBzdHJva2UtbGluZWpvaW49InJvdW5kIiBjbGFzcz0ibHVjaWRlIGx1Y2lkZS1ib29rLW9wZW4iPjxwYXRoIGQ9Ik0xMiA3djE0Ii8+PHBhdGggZD0iTTMgMThhMSAxIDAgMCAxLTEtMVY0YTEgMSAwIDAgMSAxLTFoNWE0IDQgMCAwIDEgNCA0IDQgNCAwIDAgMSA0LTRoNWExIDEgMCAwIDEgMSAxdjEzYTEgMSAwIDAgMS0xIDFoLTZhMyAzIDAgMCAwLTMgMyAzIDMgMCAwIDAtMy0zeiIvPjwvc3ZnPg==&logoColor=white\"></a>\n&nbsp;&nbsp;\n<a href=\"https://github.com/projectdiscovery/nuclei-templates\"><img src=\"https://img.shields.io/badge/Templates Library-%23000000.svg?style=for-the-badge&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgaGVpZ2h0PSIxNiIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9IiNmZmZmZmYiIHN0cm9rZS13aWR0aD0iMS41IiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiIGNsYXNzPSJsdWNpZGUgbHVjaWRlLXNoaWVsZCI+PHBhdGggZD0iTTIwIDEzYzAgNS0zLjUgNy41LTcuNjYgOC45NWExIDEgMCAwIDEtLjY3LS4wMUM3LjUgMjAuNSA0IDE4IDQgMTNWNmExIDEgMCAwIDEgMS0xYzIgMCA0LjUtMS4yIDYuMjQtMi43MmExLjE3IDEuMTcgMCAwIDEgMS41MiAwQzE0LjUxIDMuODEgMTcgNSAxOSA1YTEgMSAwIDAgMSAxIDF6Ii8+PC9zdmc+&logoColor=white\"></a>\n&nbsp;&nbsp;\n<a href=\"https://discord.gg/projectdiscovery?utm_source=github&utm_medium=web&utm_campaign=nuclei_readme\"><img src=\"https://img.shields.io/badge/Discord-%235865F2.svg?style=for-the-badge&logo=discord&logoColor=white\"></a>\n\n<hr>\n\n</p>\n\n<br>\n\n**Nuclei is a modern, high-performance vulnerability scanner that leverages simple YAML-based templates. It empowers you to design custom vulnerability detection scenarios that mimic real-world conditions, leading to zero false positives.**\n\n- Simple YAML format for creating and customizing vulnerability templates.\n- Contributed by thousands of security professionals to tackle trending vulnerabilities.\n- Reduce false positives by simulating real-world steps to verify a vulnerability.\n- Ultra-fast parallel scan processing and request clustering.\n- Integrate into CI/CD pipelines for vulnerability detection and regression testing.\n- Supports multiple protocols like TCP, DNS, HTTP, SSL, WHOIS, JavaScript, Code and more.\n- Integrate with Jira, Splunk, GitHub, Elastic, GitLab.\n\n<br>\n<br>\n\n## Table of Contents\n\n- [**`Get Started`**](#get-started)\n  - [_`1. Nuclei CLI`_](#1-nuclei-cli)\n  - [_`2. Pro and Enterprise Editions`_](#2-pro-and-enterprise-editions)\n- [**`Documentation`**](#documentation)\n  - [_`Command Line Flags`_](#command-line-flags)\n  - [_`Single target scan`_](#single-target-scan)\n  - [_`Scanning multiple targets`_](#scanning-multiple-targets)\n  - [_`Network scan`_](#network-scan)\n  - [_`Scanning with your custom template`_](#scanning-with-your-custom-template)\n  - [_`Connect Nuclei to ProjectDiscovery_`_](#connect-nuclei-to-projectdiscovery)\n- [**`Nuclei Templates, Community and Rewards`**](#nuclei-templates-community-and-rewards-) üíé\n- [**`Our Mission`**](#our-mission)\n- [**`Contributors`**](#contributors-heart) ‚ù§\n- [**`License`**](#license)\n\n<br>\n<br>\n\n## Get Started\n\n### **1. Nuclei CLI**\n\n_Install Nuclei on your machine. Get started by following the installation guide [**`here`**](https://docs.projectdiscovery.io/tools/nuclei/install?utm_source=github&utm_medium=web&utm_campaign=nuclei_readme). Additionally, We provide [**`a free cloud tier`**](https://cloud.projectdiscovery.io/sign-up) and comes with a generous monthly free limits:_\n\n- Store and visualize your vulnerability findings\n- Write and manage your nuclei templates\n- Access latest nuclei templates\n- Discover and store your targets\n\n> [!Important]\n> |**This project is in active development**. Expect breaking changes with releases. Review the release changelog before updating.|\n> |:--------------------------------|\n> | This project is primarily built to be used as a standalone CLI tool. **Running nuclei as a service may pose security risks.** It's recommended to use with caution and additional security measures. |\n\n<br>\n\n### **2. Pro and Enterprise Editions**\n\n_For security teams and enterprises, we provide a cloud-hosted service built on top of Nuclei OSS, fine-tuned to help you continuously run vulnerability scans at scale with your team and existing workflows:_\n\n- 50x faster scans\n- Large scale scanning with high accuracy\n- Integrations with cloud services (AWS, GCP, Azure, Cloudflare, Fastly, Terraform, Kubernetes)\n- Jira, Slack, Linear, APIs and Webhooks\n- Executive and compliance reporting\n- Plus: Real-time scanning, SAML SSO, SOC 2 compliant platform (with EU and US hosting options), shared team workspaces, and more\n- We're constantly [**`adding new features`**](https://feedback.projectdiscovery.io/changelog)!\n- **Ideal for:** Pentesters, security teams, and enterprises\n\n[**`Sign up to Pro`**](https://projectdiscovery.io/pricing?utm_source=github&utm_medium=web&utm_campaign=nuclei_readme) or [**`Talk to our team`**](https://projectdiscovery.io/request-demo?utm_source=github&utm_medium=web&utm_campaign=nuclei_readme) if you have large organization and complex requirements.\n\n<br>\n<br>\n\n## Documentation\n\nBrowse the full Nuclei [**`documentation here`**](https://docs.projectdiscovery.io/tools/nuclei/running). If you‚Äôre new to Nuclei, check out our [**`foundational YouTube series`**](https://www.youtube.com/playlist?list=PLZRbR9aMzTTpItEdeNSulo8bYsvil80Rl).\n\n<div align=\"center\">\n\n<a href=\"https://www.youtube.com/watch?v=b5qMyQvL1ZA&list=PLZRbR9aMzTTpItEdeNSulo8bYsvil80Rl&utm_source=github&utm_medium=web&utm_campaign=nuclei_readme\" target=\"_blank\"><img src=\"/static/nuclei-getting-started.png\" width=\"350px\"></a> <a href=\"https://www.youtube.com/watch?v=nFXygQdtjyw&utm_source=github&utm_medium=web&utm_campaign=nuclei_readme\" target=\"_blank\"><img src=\"/static/nuclei-write-your-first-template.png\" width=\"350px\"></a>\n\n</div>\n\n<br>\n\n### Installation\n\n`nuclei` requires **go >= 1.24.2** to install successfully. Run the following command to get the repo:\n\n```sh\ngo install -v github.com/projectdiscovery/nuclei/v3/cmd/nuclei@latest\n```\n\nTo learn more about installing nuclei, see `https://docs.projectdiscovery.io/tools/nuclei/install`.\n\n### Command Line Flags\n\nTo display all the flags for the tool:\n\n```sh\nnuclei -h\n```\n\n<details>\n  <summary>Expand full help flags</summary>\n\n```yaml\nNuclei is a fast, template based vulnerability scanner focusing\non extensive configurability, massive extensibility and ease of use.\n\nUsage:\n  ./nuclei [flags]\n\nFlags:\nTARGET:\n   -u, -target string[]          target URLs/hosts to scan\n   -l, -list string              path to file containing a list of target URLs/hosts to scan (one per line)\n   -eh, -exclude-hosts string[]  hosts to exclude to scan from the input list (ip, cidr, hostname)\n   -resume string                resume scan from and save to specified file (clustering will be disabled)\n   -sa, -scan-all-ips            scan all the IP's associated with dns record\n   -iv, -ip-version string[]     IP version to scan of hostname (4,6) - (default 4)\n\nTARGET-FORMAT:\n   -im, -input-mode string        mode of input file (list, burp, jsonl, yaml, openapi, swagger) (default \"list\")\n   -ro, -required-only            use only required fields in input format when generating requests\n   -sfv, -skip-format-validation  skip format validation (like missing vars) when parsing input file\n\nTEMPLATES:\n   -nt, -new-templates                    run only new templates added in latest nuclei-templates release\n   -ntv, -new-templates-version string[]  run new templates added in specific version\n   -as, -automatic-scan                   automatic web scan using wappalyzer technology detection to tags mapping\n   -t, -templates string[]                list of template or template directory to run (comma-separated, file)\n   -turl, -template-url string[]          template url or list containing template urls to run (comma-separated, file)\n   -ai, -prompt string                    generate and run template using ai prompt\n   -w, -workflows string[]                list of workflow or workflow directory to run (comma-separated, file)\n   -wurl, -workflow-url string[]          workflow url or list containing workflow urls to run (comma-separated, file)\n   -validate                              validate the passed templates to nuclei\n   -nss, -no-strict-syntax                disable strict syntax check on templates\n   -td, -template-display                 displays the templates content\n   -tl                                    list all templates matching current filters\n   -tgl                                   list all available tags\n   -sign                                  signs the templates with the private key defined in NUCLEI_SIGNATURE_PRIVATE_KEY env variable\n   -code                                  enable loading code protocol-based templates\n   -dut, -disable-unsigned-templates      disable running unsigned templates or templates with mismatched signature\n   -esc, -enable-self-contained           enable loading self-contained templates\n   -egm, -enable-global-matchers          enable loading global matchers templates\n   -file                                  enable loading file templates\n\nFILTERING:\n   -a, -author string[]               templates to run based on authors (comma-separated, file)\n   -tags string[]                     templates to run based on tags (comma-separated, file)\n   -etags, -exclude-tags string[]     templates to exclude based on tags (comma-separated, file)\n   -itags, -include-tags string[]     tags to be executed even if they are excluded either by default or configuration\n   -id, -template-id string[]         templates to run based on template ids (comma-separated, file, allow-wildcard)\n   -eid, -exclude-id string[]         templates to exclude based on template ids (comma-separated, file)\n   -it, -include-templates string[]   path to template file or directory to be executed even if they are excluded either by default or configuration\n   -et, -exclude-templates string[]   path to template file or directory to exclude (comma-separated, file)\n   -em, -exclude-matchers string[]    template matchers to exclude in result\n   -s, -severity value[]              templates to run based on severity. Possible values: info, low, medium, high, critical, unknown\n   -es, -exclude-severity value[]     templates to exclude based on severity. Possible values: info, low, medium, high, critical, unknown\n   -pt, -type value[]                 templates to run based on protocol type. Possible values: dns, file, http, headless, tcp, workflow, ssl, websocket, whois, code, javascript\n   -ept, -exclude-type value[]        templates to exclude based on protocol type. Possible values: dns, file, http, headless, tcp, workflow, ssl, websocket, whois, code, javascript\n   -tc, -template-condition string[]  templates to run based on expression condition\n\nOUTPUT:\n   -o, -output string            output file to write found issues/vulnerabilities\n   -sresp, -store-resp           store all request/response passed through nuclei to output directory\n   -srd, -store-resp-dir string  store all request/response passed through nuclei to custom directory (default \"output\")\n   -silent                       display findings only\n   -nc, -no-color                disable output content coloring (ANSI escape codes)\n   -j, -jsonl                    write output in JSONL(ines) format\n   -irr, -include-rr -omit-raw   include request/response pairs in the JSON, JSONL, and Markdown outputs (for findings only) [DEPRECATED use -omit-raw] (default true)\n   -or, -omit-raw                omit request/response pairs in the JSON, JSONL, and Markdown outputs (for findings only)\n   -ot, -omit-template           omit encoded template in the JSON, JSONL output\n   -nm, -no-meta                 disable printing result metadata in cli output\n   -ts, -timestamp               enables printing timestamp in cli output\n   -rdb, -report-db string       nuclei reporting database (always use this to persist report data)\n   -ms, -matcher-status          display match failure status\n   -me, -markdown-export string  directory to export results in markdown format\n   -se, -sarif-export string     file to export results in SARIF format\n   -je, -json-export string      file to export results in JSON format\n   -jle, -jsonl-export string    file to export results in JSONL(ine) format\n   -rd, -redact string[]         redact given list of keys from query parameter, request header and body\n\nCONFIGURATIONS:\n   -config string                        path to the nuclei configuration file\n   -tp, -profile string                  template profile config file to run\n   -tpl, -profile-list                   list community template profiles\n   -fr, -follow-redirects                enable following redirects for http templates\n   -fhr, -follow-host-redirects          follow redirects on the same host\n   -mr, -max-redirects int               max number of redirects to follow for http templates (default 10)\n   -dr, -disable-redirects               disable redirects for http templates\n   -rc, -report-config string            nuclei reporting module configuration file\n   -H, -header string[]                  custom header/cookie to include in all http request in header:value format (cli, file)\n   -V, -var value                        custom vars in key=value format\n   -r, -resolvers string                 file containing resolver list for nuclei\n   -sr, -system-resolvers                use system DNS resolving as error fallback\n   -dc, -disable-clustering              disable clustering of requests\n   -passive                              enable passive HTTP response processing mode\n   -fh2, -force-http2                    force http2 connection on requests\n   -ev, -env-vars                        enable environment variables to be used in template\n   -cc, -client-cert string              client certificate file (PEM-encoded) used for authenticating against scanned hosts\n   -ck, -client-key string               client key file (PEM-encoded) used for authenticating against scanned hosts\n   -ca, -client-ca string                client certificate authority file (PEM-encoded) used for authenticating against scanned hosts\n   -sml, -show-match-line                show match lines for file templates, works with extractors only\n   -ztls                                 use ztls library with autofallback to standard one for tls13 [Deprecated] autofallback to ztls is enabled by default\n   -sni string                           tls sni hostname to use (default: input domain name)\n   -dka, -dialer-keep-alive value        keep-alive duration for network requests.\n   -lfa, -allow-local-file-access        allows file (payload) access anywhere on the system\n   -lna, -restrict-local-network-access  blocks connections to the local / private network\n   -i, -interface string                 network interface to use for network scan\n   -at, -attack-type string              type of payload combinations to perform (batteringram,pitchfork,clusterbomb)\n   -sip, -source-ip string               source ip address to use for network scan\n   -rsr, -response-size-read int         max response size to read in bytes\n   -rss, -response-size-save int         max response size to read in bytes (default 1048576)\n   -reset                                reset removes all nuclei configuration and data files (including nuclei-templates)\n   -tlsi, -tls-impersonate               enable experimental client hello (ja3) tls randomization\n   -hae, -http-api-endpoint string       experimental http api endpoint\n\nINTERACTSH:\n   -iserver, -interactsh-server string  interactsh server url for self-hosted instance (default: oast.pro,oast.live,oast.site,oast.online,oast.fun,oast.me)\n   -itoken, -interactsh-token string    authentication token for self-hosted interactsh server\n   -interactions-cache-size int         number of requests to keep in the interactions cache (default 5000)\n   -interactions-eviction int           number of seconds to wait before evicting requests from cache (default 60)\n   -interactions-poll-duration int      number of seconds to wait before each interaction poll request (default 5)\n   -interactions-cooldown-period int    extra time for interaction polling before exiting (default 5)\n   -ni, -no-interactsh                  disable interactsh server for OAST testing, exclude OAST based templates\n\nFUZZING:\n   -ft, -fuzzing-type string           overrides fuzzing type set in template (replace, prefix, postfix, infix)\n   -fm, -fuzzing-mode string           overrides fuzzing mode set in template (multiple, single)\n   -fuzz                               enable loading fuzzing templates (Deprecated: use -dast instead)\n   -dast                               enable / run dast (fuzz) nuclei templates\n   -dts, -dast-server                  enable dast server mode (live fuzzing)\n   -dtr, -dast-report                  write dast scan report to file\n   -dtst, -dast-server-token string    dast server token (optional)\n   -dtsa, -dast-server-address string  dast server address (default \"localhost:9055\")\n   -dfp, -display-fuzz-points          display fuzz points in the output for debugging\n   -fuzz-param-frequency int           frequency of uninteresting parameters for fuzzing before skipping (default 10)\n   -fa, -fuzz-aggression string        fuzzing aggression level controls payload count for fuzz (low, medium, high) (default \"low\")\n   -cs, -fuzz-scope string[]           in scope url regex to be followed by fuzzer\n   -cos, -fuzz-out-scope string[]      out of scope url regex to be excluded by fuzzer\n\nUNCOVER:\n   -uc, -uncover                  enable uncover engine\n   -uq, -uncover-query string[]   uncover search query\n   -ue, -uncover-engine string[]  uncover search engine (shodan,censys,fofa,shodan-idb,quake,hunter,zoomeye,netlas,criminalip,publicwww,hunterhow,google) (default shodan)\n   -uf, -uncover-field string     uncover fields to return (ip,port,host) (default \"ip:port\")\n   -ul, -uncover-limit int        uncover results to return (default 100)\n   -ur, -uncover-ratelimit int    override ratelimit of engines with unknown ratelimit (default 60 req/min) (default 60)\n\nRATE-LIMIT:\n   -rl, -rate-limit int               maximum number of requests to send per second (default 150)\n   -rld, -rate-limit-duration value   maximum number of requests to send per second (default 1s)\n   -rlm, -rate-limit-minute int       maximum number of requests to send per minute (DEPRECATED)\n   -bs, -bulk-size int                maximum number of hosts to be analyzed in parallel per template (default 25)\n   -c, -concurrency int               maximum number of templates to be executed in parallel (default 25)\n   -hbs, -headless-bulk-size int      maximum number of headless hosts to be analyzed in parallel per template (default 10)\n   -headc, -headless-concurrency int  maximum number of headless templates to be executed in parallel (default 10)\n   -jsc, -js-concurrency int          maximum number of javascript runtimes to be executed in parallel (default 120)\n   -pc, -payload-concurrency int      max payload concurrency for each template (default 25)\n   -prc, -probe-concurrency int       http probe concurrency with httpx (default 50)\n   -tlc, -template-loading-concurrency int  maximum number of concurrent template loading operations (default 50)\n\nOPTIMIZATIONS:\n   -timeout int                     time to wait in seconds before timeout (default 10)\n   -retries int                     number of times to retry a failed request (default 1)\n   -ldp, -leave-default-ports       leave default HTTP/HTTPS ports (eg. host:80,host:443)\n   -mhe, -max-host-error int        max errors for a host before skipping from scan (default 30)\n   -te, -track-error string[]       adds given error to max-host-error watchlist (standard, file)\n   -nmhe, -no-mhe                   disable skipping host from scan based on errors\n   -project                         use a project folder to avoid sending same request multiple times\n   -project-path string             set a specific project path (default \"/tmp\")\n   -spm, -stop-at-first-match       stop processing HTTP requests after the first match (may break template/workflow logic)\n   -stream                          stream mode - start elaborating without sorting the input\n   -ss, -scan-strategy value        strategy to use while scanning(auto/host-spray/template-spray) (default auto)\n   -irt, -input-read-timeout value  timeout on input read (default 3m0s)\n   -nh, -no-httpx                   disable httpx probing for non-url input\n   -no-stdin                        disable stdin processing\n\nHEADLESS:\n   -headless                        enable templates that require headless browser support (root user on Linux will disable sandbox)\n   -page-timeout int                seconds to wait for each page in headless mode (default 20)\n   -sb, -show-browser               show the browser on the screen when running templates with headless mode\n   -ho, -headless-options string[]  start headless chrome with additional options\n   -sc, -system-chrome              use local installed Chrome browser instead of nuclei installed\n   -cdpe, -cdp-endpoint string      use remote browser via Chrome DevTools Protocol (CDP) endpoint\n   -lha, -list-headless-action      list available headless actions\n\nDEBUG:\n   -debug                     show all requests and responses\n   -dreq, -debug-req          show all sent requests\n   -dresp, -debug-resp        show all received responses\n   -p, -proxy string[]        list of http/socks5 proxy to use (comma separated or file input)\n   -pi, -proxy-internal       proxy all internal requests\n   -ldf, -list-dsl-function   list all supported DSL function signatures\n   -tlog, -trace-log string   file to write sent requests trace log\n   -elog, -error-log string   file to write sent requests error log\n   -version                   show nuclei version\n   -hm, -hang-monitor         enable nuclei hang monitoring\n   -v, -verbose               show verbose output\n   -profile-mem string        generate memory (heap) profile & trace files\n   -vv                        display templates loaded for scan\n   -svd, -show-var-dump       show variables dump for debugging\n   -vdl, -var-dump-limit int  limit the number of characters displayed in var dump (default 255)\n   -ep, -enable-pprof         enable pprof debugging server\n   -tv, -templates-version    shows the version of the installed nuclei-templates\n   -hc, -health-check         run diagnostic check up\n\nUPDATE:\n   -up, -update                      update nuclei engine to the latest released version\n   -ut, -update-templates            update nuclei-templates to latest released version\n   -ud, -update-template-dir string  custom directory to install / update nuclei-templates\n   -duc, -disable-update-check       disable automatic nuclei/templates update check\n\nSTATISTICS:\n   -stats                    display statistics about the running scan\n   -sj, -stats-json          display statistics in JSONL(ines) format\n   -si, -stats-interval int  number of seconds to wait between showing a statistics update (default 5)\n   -mp, -metrics-port int    port to expose nuclei metrics on (default 9092)\n   -hps, -http-stats         enable http status capturing (experimental)\n\nCLOUD:\n   -auth                           configure projectdiscovery cloud (pdcp) api key (default true)\n   -tid, -team-id string           upload scan results to given team id (optional) (default \"none\")\n   -cup, -cloud-upload             upload scan results to pdcp dashboard [DEPRECATED use -dashboard]\n   -sid, -scan-id string           upload scan results to existing scan id (optional)\n   -sname, -scan-name string       scan name to set (optional)\n   -pd, -dashboard                 upload / view nuclei results in projectdiscovery cloud (pdcp) UI dashboard\n   -pdu, -dashboard-upload string  upload / view nuclei results file (jsonl) in projectdiscovery cloud (pdcp) UI dashboard\n\nAUTHENTICATION:\n   -sf, -secret-file string[]  path to config file containing secrets for nuclei authenticated scan\n   -ps, -prefetch-secrets      prefetch secrets from the secrets file\n   # NOTE: Headers in secrets files preserve exact casing (useful for case-sensitive APIs)\n\n\nEXAMPLES:\nRun nuclei on single host:\n\t$ nuclei -target example.com\n\nRun nuclei with specific template directories:\n\t$ nuclei -target example.com -t http/cves/ -t ssl\n\nRun nuclei against a list of hosts:\n\t$ nuclei -list hosts.txt\n\nRun nuclei with a JSON output:\n\t$ nuclei -target example.com -json-export output.json\n\nRun nuclei with sorted Markdown outputs (with environment variables):\n\t$ MARKDOWN_EXPORT_SORT_MODE=template nuclei -target example.com -markdown-export nuclei_report/\n\nAdditional documentation is available at: https://docs.nuclei.sh/getting-started/running\n\n```\n\nAdditional documentation is available at: [**`docs.nuclei.sh/getting-started/running`**](https://docs.nuclei.sh/getting-started/running?utm_source=github&utm_medium=web&utm_campaign=nuclei_readme)\n\n</details>\n\n### Single target scan\n\nTo perform a quick scan on web-application:\n\n```sh\nnuclei -target https://example.com\n```\n\n### Scanning multiple targets\n\nNuclei can handle bulk scanning by providing a list of targets. You can use a file containing multiple URLs.\n\n```sh\nnuclei -list urls.txt\n```\n\n### Network scan\n\nThis will scan the entire subnet for network-related issues, such as open ports or misconfigured services.\n\n```sh\nnuclei -target 192.168.1.0/24\n```\n\n### Scanning with your custom template\n\nTo write and use your own template, create a `.yaml` file with specific rules, then use it as follows.\n\n```sh\nnuclei -u https://example.com -t /path/to/your-template.yaml\n```\n\n### Connect Nuclei to ProjectDiscovery\n\nYou can run the scans on your machine and upload the results to the cloud platform for further analysis and remediation.\n\n```sh\nnuclei -target https://example.com -dashboard\n```\n\n> [!NOTE]\n> This feature is absolutely free and does not require any subscription. For a detailed guide, refer to the [**`documentation`**](https://docs.projectdiscovery.io/cloud/scanning/nuclei-scan?utm_source=github&utm_medium=web&utm_campaign=nuclei_readme).\n\n<br>\n<br>\n\n## Nuclei Templates, Community and Rewards üíé\n[**Nuclei templates**](https://github.com/projectdiscovery/nuclei-templates) are based on the concepts of YAML based template files that define how the requests will be sent and processed. This allows easy extensibility capabilities to nuclei. The templates are written in YAML which specifies a simple human-readable format to quickly define the execution process.\n\n**Try it online with our free AI powered Nuclei Templates Editor by** [**`clicking here`**](https://cloud.projectdiscovery.io/templates).\n\nNuclei Templates offer a streamlined way to identify and communicate vulnerabilities, combining essential details like severity ratings and detection methods. This open-source, community-developed tool accelerates threat response and is widely recognized in the cybersecurity world. Nuclei templates are actively contributed by thousands of security researchers globally. We run two programs for our contributors: [**`Pioneers`**](https://projectdiscovery.io/pioneers) and [**`üíé bounties`**](https://github.com/projectdiscovery/nuclei-templates/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22%F0%9F%92%8E%20Bounty%22).\n\n\n<p align=\"left\">\n    <a href=\"/static/nuclei-templates-teamcity.png\"  target=\"_blank\"><img src=\"/static/nuclei-templates-teamcity.png\" width=\"1200px\" alt=\"Nuclei template example for detecting TeamCity misconfiguration\" /></a>\n</p>\n\n#### Examples\n\nVisit [**our documentation**](https://docs.projectdiscovery.io/templates/introduction) for use cases and ideas.\n\n| Use case                             | Nuclei template                                    |\n| :----------------------------------- | :------------------------------------------------- |\n| Detect known CVEs                    | **[CVE-2021-44228 (Log4Shell)](https://cloud.projectdiscovery.io/public/CVE-2021-45046)**                     |\n| Identify Out-of-Band vulnerabilities | **[Blind SQL Injection via OOB](https://cloud.projectdiscovery.io/public/CVE-2024-22120)**                    |\n| SQL Injection detection              | **[Generic SQL Injection](https://cloud.projectdiscovery.io/public/CVE-2022-34265)**                          |\n| Cross-Site Scripting (XSS)           | **[Reflected XSS Detection](https://cloud.projectdiscovery.io/public/CVE-2023-4173)**                        |\n| Default or weak passwords            | **[Default Credentials Check](https://cloud.projectdiscovery.io/public/airflow-default-login)**                      |\n| Secret files or data exposure        | **[Sensitive File Disclosure](https://cloud.projectdiscovery.io/public/airflow-configuration-exposure)**                      |\n| Identify open redirects              | **[Open Redirect Detection](https://cloud.projectdiscovery.io/public/open-redirect)**                        |\n| Detect subdomain takeovers           | **[Subdomain Takeover Templates](https://cloud.projectdiscovery.io/public/azure-takeover-detection)**                   |\n| Security misconfigurations           | **[Unprotected Jenkins Console](https://cloud.projectdiscovery.io/public/unauthenticated-jenkins)**                    |\n| Weak SSL/TLS configurations          | **[SSL Certificate Expiry](https://cloud.projectdiscovery.io/public/expired-ssl)**                         |\n| Misconfigured cloud services         | **[Open S3 Bucket Detection](https://cloud.projectdiscovery.io/public/s3-public-read-acp)**                       |\n| Remote code execution vulnerabilities| **[RCE Detection Templates](https://cloud.projectdiscovery.io/public/CVE-2024-29824)**                        |\n| Directory traversal attacks          | **[Path Traversal Detection](https://cloud.projectdiscovery.io/public/oracle-fatwire-lfi)**                       |\n| File inclusion vulnerabilities       | **[Local/Remote File Inclusion](https://cloud.projectdiscovery.io/public/CVE-2023-6977)**                    |\n\n\n<br>\n<br>\n\n## Our Mission\n\nTraditional vulnerability scanners were built decades ago. They are closed-source, incredibly slow, and vendor-driven. Today's attackers are mass exploiting newly released CVEs across the internet within days, unlike the years it used to take. This shift requires a completely different approach to tackling trending exploits on the internet.\n\nWe built Nuclei to solve this challenge. We made the entire scanning engine framework open and customizable‚Äîallowing the global security community to collaborate and tackle the trending attack vectors and vulnerabilities on the internet. Nuclei is now used and contributed by Fortune 500 enterprises, government agencies, universities.\n\nYou can participate by contributing to our code, [**`templates library`**](https://github.com/projectdiscovery/nuclei-templates), or [**`joining our team`**](https://projectdiscovery.io/).\n\n<br>\n<br>\n\n## Contributors :heart:\n\nThanks to all the amazing [**`community contributors for sending PRs`**](https://github.com/projectdiscovery/nuclei/graphs/contributors) and keeping this project updated. :heart:\n\n<p align=\"left\">\n<a href=\"https://github.com/Ice3man543\"><img src=\"https://avatars.githubusercontent.com/u/22318055?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/apps/dependabot\"><img src=\"https://avatars.githubusercontent.com/in/29110?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/ehsandeep\"><img src=\"https://avatars.githubusercontent.com/u/8293321?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/Mzack9999\"><img src=\"https://avatars.githubusercontent.com/u/13421144?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/forgedhallpass\"><img src=\"https://avatars.githubusercontent.com/u/13679401?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/tarunKoyalwar\"><img src=\"https://avatars.githubusercontent.com/u/45962551?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/manuelbua\"><img src=\"https://avatars.githubusercontent.com/u/819314?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/actions-user\"><img src=\"https://avatars.githubusercontent.com/u/65916846?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/dogancanbakir\"><img src=\"https://avatars.githubusercontent.com/u/65292895?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/parrasajad\"><img src=\"https://avatars.githubusercontent.com/u/16835787?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/vzamanillo\"><img src=\"https://avatars.githubusercontent.com/u/10209695?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/ShubhamRasal\"><img src=\"https://avatars.githubusercontent.com/u/45902122?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/RamanaReddy0M\"><img src=\"https://avatars.githubusercontent.com/u/90540245?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/LuitelSamikshya\"><img src=\"https://avatars.githubusercontent.com/u/85764322?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/kchason\"><img src=\"https://avatars.githubusercontent.com/u/1111099?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/pmareke\"><img src=\"https://avatars.githubusercontent.com/u/3502075?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/dwisiswant0\"><img src=\"https://avatars.githubusercontent.com/u/25837540?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/xm1k3\"><img src=\"https://avatars.githubusercontent.com/u/73166077?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/5amu\"><img src=\"https://avatars.githubusercontent.com/u/39925709?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/ehrishirajsharma\"><img src=\"https://avatars.githubusercontent.com/u/35542790?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/zerodivisi0n\"><img src=\"https://avatars.githubusercontent.com/u/687694?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/geeknik\"><img src=\"https://avatars.githubusercontent.com/u/466878?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/TerminalFi\"><img src=\"https://avatars.githubusercontent.com/u/32599364?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/KaulSe\"><img src=\"https://avatars.githubusercontent.com/u/45340011?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/sullo\"><img src=\"https://avatars.githubusercontent.com/u/1474884?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/wdahlenburg\"><img src=\"https://avatars.githubusercontent.com/u/4451504?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/ghost\"><img src=\"https://avatars.githubusercontent.com/u/10137?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/Nishan8583\"><img src=\"https://avatars.githubusercontent.com/u/20457968?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/jdk2588\"><img src=\"https://avatars.githubusercontent.com/u/985054?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/nothinux\"><img src=\"https://avatars.githubusercontent.com/u/17433202?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/CodFrm\"><img src=\"https://avatars.githubusercontent.com/u/22783163?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/CasperGN\"><img src=\"https://avatars.githubusercontent.com/u/5549643?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/ankh2054\"><img src=\"https://avatars.githubusercontent.com/u/6784287?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/revblock\"><img src=\"https://avatars.githubusercontent.com/u/72813848?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/cn-kali-team\"><img src=\"https://avatars.githubusercontent.com/u/30642514?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/EndPositive\"><img src=\"https://avatars.githubusercontent.com/u/25148195?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/jimen0\"><img src=\"https://avatars.githubusercontent.com/u/6826244?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/xstevens\"><img src=\"https://avatars.githubusercontent.com/u/69216?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/mjkim610\"><img src=\"https://avatars.githubusercontent.com/u/17107206?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/organiccrap\"><img src=\"https://avatars.githubusercontent.com/u/376317?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/lu4nx\"><img src=\"https://avatars.githubusercontent.com/u/3006875?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/souvikhazra1\"><img src=\"https://avatars.githubusercontent.com/u/13842393?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/tovask\"><img src=\"https://avatars.githubusercontent.com/u/22732484?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/Marmelatze\"><img src=\"https://avatars.githubusercontent.com/u/199681?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/doug-threatmate\"><img src=\"https://avatars.githubusercontent.com/u/127235272?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/yabeow\"><img src=\"https://avatars.githubusercontent.com/u/21117771?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/olearycrew\"><img src=\"https://avatars.githubusercontent.com/u/6044920?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/gano3s\"><img src=\"https://avatars.githubusercontent.com/u/2551605?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/alizmhdi\"><img src=\"https://avatars.githubusercontent.com/u/79321261?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/hackerpain\"><img src=\"https://avatars.githubusercontent.com/u/61242234?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/lc\"><img src=\"https://avatars.githubusercontent.com/u/19563282?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/savushkin-yauheni\"><img src=\"https://avatars.githubusercontent.com/u/5173352?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/74616e696d\"><img src=\"https://avatars.githubusercontent.com/u/97121933?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/edoardottt\"><img src=\"https://avatars.githubusercontent.com/u/35783570?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/zt2\"><img src=\"https://avatars.githubusercontent.com/u/7644862?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/moonD4rk\"><img src=\"https://avatars.githubusercontent.com/u/24284231?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/wk8\"><img src=\"https://avatars.githubusercontent.com/u/2536231?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/mikerott\"><img src=\"https://avatars.githubusercontent.com/u/857712?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/toufik-airane\"><img src=\"https://avatars.githubusercontent.com/u/5610269?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/hktalent\"><img src=\"https://avatars.githubusercontent.com/u/18223385?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/jturner\"><img src=\"https://avatars.githubusercontent.com/u/1825202?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/gaby\"><img src=\"https://avatars.githubusercontent.com/u/835733?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/vavkamil\"><img src=\"https://avatars.githubusercontent.com/u/47953210?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/leonjza\"><img src=\"https://avatars.githubusercontent.com/u/1148127?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/mionskowski-form3\"><img src=\"https://avatars.githubusercontent.com/u/91873652?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/chenrui333\"><img src=\"https://avatars.githubusercontent.com/u/1580956?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/iamargus95\"><img src=\"https://avatars.githubusercontent.com/u/77744293?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/shashikarsiddharth\"><img src=\"https://avatars.githubusercontent.com/u/60960197?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/trypa11\"><img src=\"https://avatars.githubusercontent.com/u/67585616?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/Zeokat\"><img src=\"https://avatars.githubusercontent.com/u/1313154?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/alban-stourbe-wmx\"><img src=\"https://avatars.githubusercontent.com/u/159776828?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/anykno\"><img src=\"https://avatars.githubusercontent.com/u/2528207?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/ronaudinho\"><img src=\"https://avatars.githubusercontent.com/u/10264710?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/boy-hack\"><img src=\"https://avatars.githubusercontent.com/u/18695984?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/iuliu8899\"><img src=\"https://avatars.githubusercontent.com/u/31680027?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/debasishbsws\"><img src=\"https://avatars.githubusercontent.com/u/65381620?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/denysvitali-niantic\"><img src=\"https://avatars.githubusercontent.com/u/157139422?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/fail-open\"><img src=\"https://avatars.githubusercontent.com/u/72417455?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/Xc1Ym\"><img src=\"https://avatars.githubusercontent.com/u/29765332?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/XTeam-Wing\"><img src=\"https://avatars.githubusercontent.com/u/25416365?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/Weltolk\"><img src=\"https://avatars.githubusercontent.com/u/40228052?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/tonghuaroot\"><img src=\"https://avatars.githubusercontent.com/u/23011166?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/praetorian-thendrickson\"><img src=\"https://avatars.githubusercontent.com/u/69640071?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/S0obi\"><img src=\"https://avatars.githubusercontent.com/u/4180104?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/skahn007gl\"><img src=\"https://avatars.githubusercontent.com/u/144735608?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/shouichi\"><img src=\"https://avatars.githubusercontent.com/u/99586?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/seb-elttam\"><img src=\"https://avatars.githubusercontent.com/u/111818823?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/AdallomRoy\"><img src=\"https://avatars.githubusercontent.com/u/4046118?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/rotemreiss\"><img src=\"https://avatars.githubusercontent.com/u/9288082?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/oscarintherocks\"><img src=\"https://avatars.githubusercontent.com/u/1785821?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/xxcdd\"><img src=\"https://avatars.githubusercontent.com/u/42600601?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/chen2aaron\"><img src=\"https://avatars.githubusercontent.com/u/9978183?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/voidz0r\"><img src=\"https://avatars.githubusercontent.com/u/1032286?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/vince-isec\"><img src=\"https://avatars.githubusercontent.com/u/149686094?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/true13\"><img src=\"https://avatars.githubusercontent.com/u/18207552?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/skhalsa-sigsci\"><img src=\"https://avatars.githubusercontent.com/u/68570441?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/ShuBo6\"><img src=\"https://avatars.githubusercontent.com/u/41125338?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/seeyarh\"><img src=\"https://avatars.githubusercontent.com/u/16869800?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/securibee\"><img src=\"https://avatars.githubusercontent.com/u/51520913?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/sduc\"><img src=\"https://avatars.githubusercontent.com/u/2879617?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/scottdharvey\"><img src=\"https://avatars.githubusercontent.com/u/25498254?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/rykkard\"><img src=\"https://avatars.githubusercontent.com/u/51889048?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/monitor403\"><img src=\"https://avatars.githubusercontent.com/u/45124775?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/mlec1\"><img src=\"https://avatars.githubusercontent.com/u/42201667?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/meme-lord\"><img src=\"https://avatars.githubusercontent.com/u/17912559?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/LazyMaple\"><img src=\"https://avatars.githubusercontent.com/u/12314941?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/lvyaoting\"><img src=\"https://avatars.githubusercontent.com/u/166296299?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/llussy\"><img src=\"https://avatars.githubusercontent.com/u/18432966?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/linchizhen\"><img src=\"https://avatars.githubusercontent.com/u/170242051?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/kiokuless\"><img src=\"https://avatars.githubusercontent.com/u/110003596?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/Jarnpher553\"><img src=\"https://avatars.githubusercontent.com/u/10233873?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/c-f\"><img src=\"https://avatars.githubusercontent.com/u/35263248?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/hanghuge\"><img src=\"https://avatars.githubusercontent.com/u/166206050?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/testwill\"><img src=\"https://avatars.githubusercontent.com/u/8717479?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/galoget\"><img src=\"https://avatars.githubusercontent.com/u/8353133?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/fudancoder\"><img src=\"https://avatars.githubusercontent.com/u/171416994?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/revolunet\"><img src=\"https://avatars.githubusercontent.com/u/124937?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/jsoref\"><img src=\"https://avatars.githubusercontent.com/u/2119212?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/MachadoOtto\"><img src=\"https://avatars.githubusercontent.com/u/93268441?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/jonathanwalker\"><img src=\"https://avatars.githubusercontent.com/u/14978093?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/nHurD\"><img src=\"https://avatars.githubusercontent.com/u/233374?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/jessekelly881\"><img src=\"https://avatars.githubusercontent.com/u/22938931?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/JaneX8\"><img src=\"https://avatars.githubusercontent.com/u/5116641?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/eltociear\"><img src=\"https://avatars.githubusercontent.com/u/22633385?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/atomiczsec\"><img src=\"https://avatars.githubusercontent.com/u/75549184?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/M-Faheem-Khan\"><img src=\"https://avatars.githubusercontent.com/u/17150767?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/denandz\"><img src=\"https://avatars.githubusercontent.com/u/5291556?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/tibbon\"><img src=\"https://avatars.githubusercontent.com/u/82880?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/dany74q\"><img src=\"https://avatars.githubusercontent.com/u/2129762?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/0x123456789\"><img src=\"https://avatars.githubusercontent.com/u/36066426?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/danigoland\"><img src=\"https://avatars.githubusercontent.com/u/15079567?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/ChrisMandich\"><img src=\"https://avatars.githubusercontent.com/u/14286797?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/austintraver\"><img src=\"https://avatars.githubusercontent.com/u/25112463?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/socialsister\"><img src=\"https://avatars.githubusercontent.com/u/155628741?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/Anemys\"><img src=\"https://avatars.githubusercontent.com/u/51196227?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/andreangelucci\"><img src=\"https://avatars.githubusercontent.com/u/18552197?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/AlexS778\"><img src=\"https://avatars.githubusercontent.com/u/98418121?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/noraj\"><img src=\"https://avatars.githubusercontent.com/u/16578570?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/akkuman\"><img src=\"https://avatars.githubusercontent.com/u/7813511?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/zrquan\"><img src=\"https://avatars.githubusercontent.com/u/33086594?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/1efty\"><img src=\"https://avatars.githubusercontent.com/u/18194777?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/rsrdesarrollo\"><img src=\"https://avatars.githubusercontent.com/u/5142014?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/razin99\"><img src=\"https://avatars.githubusercontent.com/u/44442082?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/MetzinAround\"><img src=\"https://avatars.githubusercontent.com/u/65838556?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/vil02\"><img src=\"https://avatars.githubusercontent.com/u/65706193?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/mrschyte\"><img src=\"https://avatars.githubusercontent.com/u/8571?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/PeterDaveHello\"><img src=\"https://avatars.githubusercontent.com/u/3691490?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/parthmalhotra\"><img src=\"https://avatars.githubusercontent.com/u/28601533?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/owenrumney\"><img src=\"https://avatars.githubusercontent.com/u/3049157?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/Ovi3\"><img src=\"https://avatars.githubusercontent.com/u/29408109?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/Bisstocuz\"><img src=\"https://avatars.githubusercontent.com/u/42398278?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/daffainfo\"><img src=\"https://avatars.githubusercontent.com/u/36522826?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/mhmdiaa\"><img src=\"https://avatars.githubusercontent.com/u/19687798?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/MiryangJung\"><img src=\"https://avatars.githubusercontent.com/u/48237511?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/0xmin\"><img src=\"https://avatars.githubusercontent.com/u/44919834?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/maikthulhu\"><img src=\"https://avatars.githubusercontent.com/u/680830?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/sttlr\"><img src=\"https://avatars.githubusercontent.com/u/40246850?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/iamRjarpan\"><img src=\"https://avatars.githubusercontent.com/u/45498226?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/leoloobeek\"><img src=\"https://avatars.githubusercontent.com/u/8801754?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/KristinnVikar\"><img src=\"https://avatars.githubusercontent.com/u/93918469?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/kant01ne\"><img src=\"https://avatars.githubusercontent.com/u/5072452?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/KeisukeYamashita\"><img src=\"https://avatars.githubusercontent.com/u/23056537?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/1hehaq\"><img src=\"https://avatars.githubusercontent.com/u/162917546?v=4\" width=\"50\" height=\"50\" alt=\"\" style=\"max-width: 100%;\"></a>\n</p>\n\n<br>\n<br>\n<br>\n\n<div align=\"center\">\n  \n  <sub>**`nuclei`** is distributed under [**MIT License**](https://github.com/projectdiscovery/nuclei/blob/main/LICENSE.md)</sub>\n\n</div>\n",
      "stars_today": 19
    },
    {
      "id": 884278258,
      "name": "InstallerX-Revived",
      "full_name": "wxxsfxyzm/InstallerX-Revived",
      "description": "More Expressive InstallerX !",
      "html_url": "https://github.com/wxxsfxyzm/InstallerX-Revived",
      "stars": 3160,
      "forks": 91,
      "language": "Kotlin",
      "topics": [
        "android",
        "apk",
        "apks",
        "dhizuku",
        "installer",
        "miuix",
        "root",
        "shizuku"
      ],
      "created_at": "2024-11-06T13:19:18Z",
      "updated_at": "2026-01-13T22:27:48Z",
      "pushed_at": "2026-01-13T20:29:32Z",
      "open_issues": 13,
      "owner": {
        "login": "wxxsfxyzm",
        "avatar_url": "https://avatars.githubusercontent.com/u/65166044?v=4"
      },
      "readme": "# InstallerX Revived (Community Edition)\n\n**English** | [ÁÆÄ‰Ωì‰∏≠Êñá](README_CN.md) | [Espa√±ol](README_ES.md)\n\n[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)[![Latest Release](https://img.shields.io/github/v/release/wxxsfxyzm/InstallerX?label=Stable)](https://github.com/wxxsfxyzm/InstallerX/releases/latest)[![Prerelease](https://img.shields.io/github/v/release/wxxsfxyzm/InstallerX?include_prereleases&label=Beta)](https://github.com/wxxsfxyzm/InstallerX/releases)[![Telegram](https://img.shields.io/badge/Telegram-2CA5E0?logo=telegram&logoColor=white)](https://t.me/installerx_revived)\n\n- This is a community-maintained fork after the [original project](https://github.com/iamr0s/InstallerX) was archived by the author\n- Provides limited open-source updates and support\n- Strictly follows GNU GPLv3 - all modifications are open source\n- We welcome community contributions!\n\n## Introduction\n\n> A modern and functional Android app installer. (You know some birds are not meant to be caged, their feathers are just too bright.)\n\nLooking for a better app installer? Try **InstallerX**!\n\nMany customized Chinese ROMs come with subpar default installers. You can replace them with **InstallerX Revived**.\n\nCompared to stock installers, **InstallerX Revived** offers more installation features:\n- Rich installation types: APK, APKS, APKM, XAPK, APKs inside ZIP, and batch APKs.\n- Dialog-based installation\n- Notification-based installation (Live Activity API supported)\n- Automatic installation\n- Installer declaration\n- Setting install flags (can inherit Profile settings)\n- Install for specific user / all users\n- Dex2oat after successful installation\n- Block the installation of specific app's packageName or by sharedUID\n- Auto-delete APK after installation\n- No shell commands, native API calls only\n\n## Supported Versions\n\n- **Full support:** Android SDK 34 - 36.1 (Android 14 - 16)\n- **Limited support:** Android SDK 26 - 33 (Android 8.0 - 13) (please report issues)\n\n## Key Changes and Features\n\n- **UI Options:** Switchable between a new UI design based on Material 3 Expressive and Miuix which is like HyperOS.\n- **More Customization:** More customizable interface settings.\n- **Bug fixes:** Resolved APK deletion issues from the original project on certain systems.\n- **Performance:** Optimized parsing speed, improved parsing of various package types.\n- **Multilingual support:** More languages supported. Contributions for more languages are welcome!\n- **Dialog optimization:** Improved installation dialog display.\n- **System Icons:** Support for displaying system icon packs during installation. Allows switching between APK icons and system icon packs through a toggle.\n- **Version Comparison:** Support for displaying version number comparison in single-line or multi-line format.\n- **SDK Information:** Installation dialogs show targetSDK and minSDK in single-line or multi-line format.\n- **Session Install Confirmation**: With the help of [InxLocker](https://github.com/Chimioo/InxLocker), confirming installations from store apps (Aurora Store, F-Droid, etc.) is now supported.\n- **Bypass Interceptions:** Shizuku/Root can bypass custom OS chain-start restrictions when opening an App after installation.\n    - Currently only works for dialog installation.\n    - Dhizuku lacks sufficient permissions, so a customizable countdown option was added to reserve time for the app opening action.\n- **Extended Menu:** For dialog installation (can be enabled in settings):\n    - Displays permissions requested by the application.\n    - InstallFlags configuration (can inherit global Profile settings).\n      - **Important:** Setting InstallFlags **does not guarantee** they will always work. Some options might pose security risks, depending on the system.\n- **Preset Sources:** Support for pre-configuring installation source package names in settings, allowing quick selection in profiles and the dialog installation menu.\n- **Install from ZIP:** Support for installing APK files inside ZIP archives (dialog installation only).\n    - Supports unlimited quantity and multiple ZIP files.\n    - Supports APK files in nested directories within the ZIP, **not limited to the root directory**.\n    - Supports automatic handling of multiple versions of the same package:\n        - Deduplication\n        - Smart selection of the best package to install.\n- **Batch Installation:** Support for installing multiple APKs at once (multi-select and share to InstallerX).\n    - Dialog installation only.\n    - No quantity limit.\n    - APK files only.\n    - Supports automatic handling of multiple versions of the same package (deduplication and smart selection).\n- **APKS/APKM/XAPK Files:** Support for automatic selection of the best split.\n    - Supports both notification and dialog installation.\n        - Clicking \"Install\" in the notification selects the best option and proceeds with installation.\n        - In the dialog, the best option is selected by default, but can be chosen manually.\n    - The split selection interface shows user-friendly descriptions.\n- **Architecture Support:** Allows installing armeabi-v7a packages on arm64-v8a only systems (actual functionality depends on the system providing runtime translation).\n- **Downgrade with or without Data:** Support for performing app downgrades with or without data preservation on some OEM Android 15 systems.\n    - This feature only supports Android 15. On Android 14 or below, try the `Allow downgrade` option in the install options.\n    - The feature is available in the smart suggestions of the dialog installation. To use it, first enable the `Show smart suggestions` option.\n    - **Use this feature with extreme caution on system apps!** Loss of data from a system app could render the device unusable.\n    - Not compatible with OneUI 7.0, RealmeUI, and some ColorOS versions (AOSP has fixed). If you only see the downgrade option *without* data preservation, it means your system does not support downgrade *with* data.\n- **Blacklist:** Support for configuring a list of banned package names for installation in the settings.\n    - Support blacklist by packageName / sharedUID with exemptions\n    - `Allow once` in smart suggestions\n- **DexOpt:** After successful installation, the app can automatically perform dex2oat on the installed applications according to the configured Profile settings.\n    - Does not support Dhizuku\n- **Signature VerificationÔºö** Verify the signature of the installed app and apk to install, and give a warning if they do not match.\n- **Select Target User:** Support installing apps to a specific user.\n    - Dynamically obtain current user details.\n    - Does not support Dhizuku\n    - Can be overridden by `Install For All Users` install option\n- **Declare as Uninstaller:** Accept Uninstall intent on certain OS, custom OS may not be supported.\n- [Experimental] **Directly Install From Download Link:** The online version supports directly sharing the download link of an APK file to InstallerX for installation. Currently, the APK is not kept locally, but an option to retain the installation package will be added in the future.\n\n## FAQ\n\n> [!NOTE]\n> Please read the FAQ before providing feedback.\n> When providing feedback, please specify your phone brand, system version, software version, and operation in detail.\n\n- **Dhizuku not working properly?**\n    - Support for **official Dhizuku** is limited. Tested on AVDs with SDK ‚â•34. Operation on SDK <34 is not guaranteed.\n    - When using `OwnDroid`, the `Auto delete after installation` function might not work correctly.\n    - On Chinese ROMs, occasional errors are usually due to the system restricting Dhizuku's background operation. It is recommended to restart the Dhizuku app first.\n    - Dhizuku has limited permissions. Many operations are not possible (like bypassing system intent interceptors or specifying the installation source). Using Shizuku is recommended if possible.\n\n- **Unable to lock InstallerX as default installer?**\n    - Some Systems have very strict policy on Package Installers. You must use a LSPosed module to intercept the intent and forward it to the installer in this case.\n    - Works best with: [Chimioo/InxLocker](https://github.com/Chimioo/InxLocker)\n    - Other lockers working as LSPosed are no longer recommended\n\n- An error occurred in the resolution phase: `No Content Provider` or `reading provider` reported `Permission Denial`?\n    - You have enabled Hide app list or similar functions, please configure the whitelist.\n\n- **HyperOS shows \"Installing system apps requires declaring a valid installer\" error**\n    - It's a system security restriction. You must declare an installer that is a system app (recommended: `com.android.fileexplorer` or `com.android.vending` for HyperOS; app store for Vivo).\n    - Works with Shizuku/Root. **Dhizuku is not supported**.\n    - New feature: InstallerX automatically detects HyperOS and adds a default configuration (`com.miui.packageinstaller`). You can change it in the settings if needed.\n\n- **HyperOS reinstalls the default installer / locking fails**\n    - Try enabling `Auto Lock Installer` in settings.\n    - On some HyperOS versions, locking failure is expected.\n    - HyperOS intercepts USB installation requests (ADB/Shizuku) with a dialog. If the user rejects the installation of a new app, the system will revoke the installer setting and force the default one. If this happens, lock InstallerX again.\n\n- **Notification progress bar freezes**\n    - Some custom OS has very strict background app controls. Set \"No background restrictions\" for the app if you encounter this.\n    - The app is optimized: it ends all background services and closes 1 second after completing the installation task (when the user clicks \"Done\" or clears the notification). You can enable the foreground service notification to monitor.\n\n- **Problems on Oppo/Vivo/Lenovo/... systems?**\n    - We do not have devices from these brands for testing. You can discuss it in [Discussions](https://github.com/wxxsfxyzm/InstallerX-Revived/discussions), or report through our [Telegram Channel](https://t.me/installerx_revived).\n    - To lock the installer on Oppo/Vivo, use the lock tool.\n    - To install apps through shizuku on Honor devices, disable `Monitor ADB install` in developer settings.\n\n## About Releases\n\n> [!WARNING]\n> Development versions may be unstable and features may change/be removed without any notice.\n> Switching build channels may require data wipe/reinstallation.\n\n- **`dev` branch:** Contains features under development. If you want to test them, look for the corresponding CI builds in Github Actions.\n- **`main` branch:** When stable changes are merged from `dev`, the CI/CD system automatically builds and publishes a new alpha version.\n- **Stable releases:** Manually published when finishing a development/testing phase. CI/CD automatically publishes them as a release.\n- **About network permission:** As features have expanded, some network-related functions have been introduced. However, many users prefer the installer to remain purely local without requiring network access. Therefore, two versions will be released: **online** and **offline**. Both versions share the same package name, version code, and signature, so they can't be installed side by side (but can be replaced directly). Please download according to your needs.\n  - **Online version**: Supports sharing direct download links to InstallerX for installation. More network-related utilities may be added in the future, but network permission will **never** be used for non-installation purposes. Safe to use.\n  - **Offline version**: Requests no network permissions at all. When attempting to use online features, you will receive a clear error message. This version remains a purely local installer.\n\n## About Localization\n\nHelp us translate this project! You can contribute at: https://hosted.weblate.org/engage/installerx-revived/\n\n### Localization Status\n\n[![Localization Status](https://hosted.weblate.org/widget/installerx-revived/strings/multi-auto.svg)](https://hosted.weblate.org/engage/installerx-revived/)\n\n## License\n\nCopyright ¬© [iamr0s](https://github.com/iamr0s) and [contributors](https://github.com/wxxsfxyzm/InstallerX-Revived/graphs/contributors)\n\nInstallerX is currently released under [**GNU General Public License v3 (GPL-3)**](http://www.gnu.org/licenses/gpl-3.0), though this commitment may change in the future. Maintainers reserve the right to modify license terms or the open-source status of the project.\n\nIf you base your development on InstallerX, you must comply with the terms of the open-source license of the specific version of the source code you use as a base, regardless of future changes made to the main project.\n\n## Acknowledgements\n\nThis project uses code from, or is based on the implementation of, the following projects:\n\n- [iamr0s/InstallerX](https://github.com/iamr0s/InstallerX)\n- [tiann/KernelSU](https://github.com/tiann/KernelSU)\n- [RikkaApps/Shizuku](https://github.com/RikkaApps/Shizuku)\n- [zacharee/InstallWithOptions](https://github.com/zacharee/InstallWithOptions)\n- [vvb2060/PackageInstaller](https://github.com/vvb2060/PackageInstaller)\n- [compose-miuix-ui/miuix](https://github.com/compose-miuix-ui/miuix)\n",
      "stars_today": 19
    },
    {
      "id": 1013830656,
      "name": "bitchat",
      "full_name": "permissionlesstech/bitchat",
      "description": "bluetooth mesh chat, IRC vibes",
      "html_url": "https://github.com/permissionlesstech/bitchat",
      "stars": 23899,
      "forks": 2234,
      "language": "Swift",
      "topics": [],
      "created_at": "2025-07-04T14:34:38Z",
      "updated_at": "2026-01-14T00:38:47Z",
      "pushed_at": "2026-01-13T23:07:52Z",
      "open_issues": 218,
      "owner": {
        "login": "permissionlesstech",
        "avatar_url": "https://avatars.githubusercontent.com/u/220183803?v=4"
      },
      "readme": "<img width=\"256\" height=\"256\" alt=\"icon_128x128@2x\" src=\"https://github.com/user-attachments/assets/90133f83-b4f6-41c6-aab9-25d0859d2a47\" />\n\n## bitchat\n\nA decentralized peer-to-peer messaging app with dual transport architecture: local Bluetooth mesh networks for offline communication and internet-based Nostr protocol for global reach. No accounts, no phone numbers, no central servers. It's the side-groupchat.\n\n[bitchat.free](http://bitchat.free)\n\nüì≤ [App Store](https://apps.apple.com/us/app/bitchat-mesh/id6748219622)\n\n> [!WARNING]\n> Private messages have not received external security review and may contain vulnerabilities. Do not use for sensitive use cases, and do not rely on its security until it has been reviewed. Now uses the [Noise Protocol](https://www.noiseprotocol.org) for identity and encryption. Public local chat (the main feature) has no security concerns.\n\n## License\n\nThis project is released into the public domain. See the [LICENSE](LICENSE) file for details.\n\n## Features\n\n- **Dual Transport Architecture**: Bluetooth mesh for offline + Nostr protocol for internet-based messaging\n- **Location-Based Channels**: Geographic chat rooms using geohash coordinates over global Nostr relays\n- **Intelligent Message Routing**: Automatically chooses best transport (Bluetooth ‚Üí Nostr fallback)\n- **Decentralized Mesh Network**: Automatic peer discovery and multi-hop message relay over Bluetooth LE\n- **Privacy First**: No accounts, no phone numbers, no persistent identifiers\n- **Private Message End-to-End Encryption**: [Noise Protocol](https://noiseprotocol.org) for mesh, NIP-17 for Nostr\n- **IRC-Style Commands**: Familiar `/slap`, `/msg`, `/who` style interface\n- **Universal App**: Native support for iOS and macOS\n- **Emergency Wipe**: Triple-tap to instantly clear all data\n- **Performance Optimizations**: LZ4 message compression, adaptive battery modes, and optimized networking\n\n## [Technical Architecture](https://deepwiki.com/permissionlesstech/bitchat)\n\nBitChat uses a **hybrid messaging architecture** with two complementary transport layers:\n\n### Bluetooth Mesh Network (Offline)\n\n- **Local Communication**: Direct peer-to-peer within Bluetooth range\n- **Multi-hop Relay**: Messages route through nearby devices (max 7 hops)\n- **No Internet Required**: Works completely offline in disaster scenarios\n- **Noise Protocol Encryption**: End-to-end encryption with forward secrecy\n- **Binary Protocol**: Compact packet format optimized for Bluetooth LE constraints\n- **Automatic Discovery**: Peer discovery and connection management\n- **Adaptive Power**: Battery-optimized duty cycling\n\n### Nostr Protocol (Internet)\n\n- **Global Reach**: Connect with users worldwide via internet relays\n- **Location Channels**: Geographic chat rooms using geohash coordinates\n- **290+ Relay Network**: Distributed across the globe for reliability\n- **NIP-17 Encryption**: Gift-wrapped private messages for internet privacy\n- **Ephemeral Keys**: Fresh cryptographic identity per geohash area\n\n### Channel Types\n\n#### `mesh #bluetooth`\n\n- **Transport**: Bluetooth Low Energy mesh network\n- **Scope**: Local devices within multi-hop range\n- **Internet**: Not required\n- **Use Case**: Offline communication, protests, disasters, remote areas\n\n#### Location Channels (`block #dr5rsj7`, `neighborhood #dr5rs`, `country #dr`)\n\n- **Transport**: Nostr protocol over internet\n- **Scope**: Geographic areas defined by geohash precision\n  - `block` (7 chars): City block level\n  - `neighborhood` (6 chars): District/neighborhood\n  - `city` (5 chars): City level\n  - `province` (4 chars): State/province\n  - `region` (2 chars): Country/large region\n- **Internet**: Required (connects to Nostr relays)\n- **Use Case**: Location-based community chat, local events, regional discussions\n\n### Direct Message Routing\n\nPrivate messages use **intelligent transport selection**:\n\n1. **Bluetooth First** (preferred when available)\n\n   - Direct connection with established Noise session\n   - Fastest and most private option\n\n2. **Nostr Fallback** (when Bluetooth unavailable)\n\n   - Uses recipient's Nostr public key\n   - NIP-17 gift-wrapping for privacy\n   - Routes through global relay network\n\n3. **Smart Queuing** (when neither available)\n   - Messages queued until transport becomes available\n   - Automatic delivery when connection established\n\nFor detailed protocol documentation, see the [Technical Whitepaper](WHITEPAPER.md).\n\n## Setup\n\n### Option 1: Using Xcode\n\n   ```bash\n   cd bitchat\n   open bitchat.xcodeproj\n   ```\n\n   To run on a device there're a few steps to prepare the code:\n   - Clone the local configs: `cp Configs/Local.xcconfig.example Configs/Local.xcconfig`\n   - Add your Developer Team ID into the newly created `Configs/Local.xcconfig`\n      - Bundle ID would be set to `chat.bitchat.<team_id>` (unless you set to something else)\n   - Entitlements need to be updated manually (TODO: Automate):\n      - Search and replace `group.chat.bitchat` with `group.<your_bundle_id>` (e.g. `group.chat.bitchat.ABC123`)\n\n### Option 2: Using `just`\n\n   ```bash\n   brew install just\n   ```\n\nWant to try this on macos: `just run` will set it up and run from source.\nRun `just clean` afterwards to restore things to original state for mobile app building and development.\n\n## Localization\n\n- Base app resources live under `bitchat/Localization/Base.lproj/`. Add new copy to `Localizable.strings` and plural rules to `Localizable.stringsdict`.\n- Share extension strings are separate in `bitchatShareExtension/Localization/Base.lproj/Localizable.strings`.\n- Prefer keys that describe intent (`app_info.features.offline.title`) and reuse existing ones where possible.\n- Run `xcodebuild -project bitchat.xcodeproj -scheme \"bitchat (macOS)\" -configuration Debug CODE_SIGNING_ALLOWED=NO build` to compile-check any localization updates.\n",
      "stars_today": 18
    },
    {
      "id": 964473113,
      "name": "yourtv",
      "full_name": "horsemail/yourtv",
      "description": "ÂÆâÂçìÁîµËßÜÁõ¥Êí≠APKÔºöIPTV/Á∂≤È†ÅË¶ñÈ†ªÊîØÊåÅX5ÔºåÂèØËá™ÂÆöÁæ©Ê∫ê(ÊîØÊåÅwebview://Ê†ºÂºè)ÔºåIPTVÊîØÊåÅÁï´‰∏≠Áï´ÂíåÁÜÑÂ±èÊí≠Êîæ„ÄÇ Android TV Live APK: IPTV/web video supports X5, customizable sources (support webview:// format), IPTV supports picture-in-picture and off-screen playback.",
      "html_url": "https://github.com/horsemail/yourtv",
      "stars": 894,
      "forks": 101,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2025-04-11T09:12:13Z",
      "updated_at": "2026-01-13T12:48:50Z",
      "pushed_at": "2026-01-11T12:34:13Z",
      "open_issues": 13,
      "owner": {
        "login": "horsemail",
        "avatar_url": "https://avatars.githubusercontent.com/u/91647741?v=4"
      },
      "readme": "## üåê Ë™ûË®Ä / Languages\n\n- [üá®üá≥ ‰∏≠ÊñáË™™Êòé](README.MD)\n- [üá∫üá∏ English Version](README.en.md)\n# ‰Ω†ÁöÑÈõªË¶ñÔºöÂÆâÂçìÈõªË¶ñ/ÊâãÊú∫Áõ¥Êí≠APK\nÊîØÊåÅÂÆâÂçì6.0(API23)Á¥ö‰ª•‰∏äÁâàÊú¨<br>\nÁ∂úÂêàmy-tv/my-tv-0/my-tv-1/mytv-android/WebViewTVLiveÁ≠âÈ†ÖÁõÆÁöÑÂäüËÉΩ„ÄÇ<br>  \nIPTV/Á∂≤È†ÅË¶ñÈ†ªÊí≠ÊîæÂÆâÂçìAPKËªü‰ª∂ÔºåÊîØÊåÅËÖæËÆØwebview x5Ôºå<br>\nÂèØËá™ÂÆöÁæ©Ê∫ê(ÊîØÊåÅwebview://Ê†ºÂºèÁ∂≤È†ÅË¶ñÈ†ªÊ∫ê)ÔºåÊîØÊåÅÊâãÊ©üÁï´‰∏≠Áï´ÔºåIPTVÊîØÊåÅÊâãÊ©üÁÜÑÂ±èÊí≠Êîæ„ÄÇ<br>\n[yourtv](https://github.com/horsemail/yourtv)\n<br>\n## **Ë´ã‰ªîÁ¥∞Èñ±ËÆÄÂæåÈù¢ÁöÑ[‰ΩøÁî®Ë™™Êòé](#‰ΩøÁî®)„ÄÇ**\n## Âú®Á∑öÂä†ÂØÜËß£ÂØÜÔºöÔºàÂÖºÂÆπTvboxÁöÑÊé•Âè£Ê∫êÂä†ÂØÜËß£ÂØÜÔºâ\nhttps://yourtvcrypto.horsenma.net<br>\nËàáÈ†ÖÁõÆÂÖßÂä†ÂØÜËß£ÂØÜÈÇèËºØÂÆåÂÖ®‰∏ÄËá¥<br>\n\nÈõªÂ†±Áæ§ÁµÑ<br>\nhttps://t.me/yourtvapp<br>\n<img src=\"./screenshots/appreciate.jpg\" alt=\"image\" width=200 /><br><br>\n<img src=\"./screenshots/527.jpg\" alt=\"image\"/><br><br>\n<img src=\"./screenshots/090901.jpg\" alt=\"image\"/><br><br>\n<img src=\"./screenshots/090902.jpg\" alt=\"image\"/><br><br>\n<br>\n## ‰ΩøÁî®\n\nÈõªË¶ñÊ©üÔºö<br>\n1„ÄÅÈñãÊ©ü‰ΩøÁî®Ôºå‰∏ãËºâÁõ¥Êí≠Ê∫êË≥áÊ∫êÔºåË´ãËÄêÂøÉÁ≠âÂæÖ3-5ÁßíÔºå<br>\n2„ÄÅÁ¢∫ÂÆö/‰∏≠ÂøÉÈçµÔºöÂΩàÂá∫ÁµÑ/È†ªÈÅìÊ∏ÖÂñÆÔºå‰∏ä‰∏ãÂ∑¶Âè≥ÈÅ∏ÊìáÁµÑ/È†ªÈÅìÔºåÁ¢∫ÂÆöÈÅ∏ÊìáÈ†ªÈÅìÔºåÂè≥ÈçµÊî∂Ëóè/ÂèñÊ∂àÊî∂Ëóè<br>\n3„ÄÅ‰∏äÈçµ/‰∏ãÈçµÔºöÂàáÊèõÈ†ªÈÅì<br>\n4„ÄÅÂ∑¶ÈçµÔºöÈ°ØÁ§∫ÁØÄÁõÆÂñÆ‰ø°ÊÅØ<br>\n5„ÄÅÂè≥ÈçµÔºöÂàáÊèõÂêå‰∏ÄÈ†ªÈÅìÁöÑ‰∏çÈÄöÁõ¥Êí≠Ê∫êÂú∞ÂùÄ<br>\n„ÄÅÈïøÊåâËèúÂçïÈîÆ/Âè≥ÈîÆÔºåÊàñÂø´ÈÄüÊåâ4Ê¨°ËèúÂçïÈîÆ/Âè≥ÈîÆÔºåÊòæÁ§∫ËÆæÁΩÆÁïåÈù¢<br>\n7„ÄÅÈïøÊåâÁ°ÆËÆ§‰∏≠ÂøÉÈîÆÔºåÊàñÂø´ÈÄüËøûÊåâ4Ê¨°ÔºåÊòæÁ§∫ÂΩìÂâçÈ¢ëÈÅìÁõ¥Êí≠Ê∫ê‰ø°ÊÅØÔºåÂπ∂ÂèØÈÄâÊã©‰∏çÂêåÁõ¥Êí≠Ê∫ê<br>\n8„ÄÅÈï∑ÊåâÂàÜÁµÑÈö±ËóèÔºåÈõôÊìäÁ¥ÖËâ≤XÊÅ¢Âæ©„ÄÇ<br>\n\n<br>\nËß∏Êë∏Â±èÔºö<br>\n1„ÄÅÂºÄÊú∫‰ΩøÁî®Ôºå‰∏ãËΩΩÁõ¥Êí≠Ê∫êËµÑÊ∫êÔºåËØ∑Á≠âÂæÖ3-5ÁßíÔºå<br>\n2„ÄÅÂ∑¶‰æß‰∏äÂ±èÂø´ÈÄüË∞ÉËäÇÂÆΩÂ∫¶<br>\n3„ÄÅÂè≥‰æß‰∏äÂ±èÔºöË∞ÉËäÇÂ£∞Èü≥<br>\n4„ÄÅ‰∏≠Èó¥ÈÉ®ÂàÜÊªëÂ±èÔºöÂàáÊç¢È¢ëÈÅì<br>\n5„ÄÅÂçïÂáªÂ±èÂπïÔºöÂºπÂá∫ÁªÑ/È¢ëÈÅìÂàóË°®ÔºåÁÇπÂáªÈÄâÊã©ÔºåÁÇπÂáªÁà±ÂøÉÊî∂Ëóè/ÂèñÊ∂àÊî∂Ëóè<br>\n6„ÄÅÂèåÂáªÈ¢ëÂπïÔºåÊòæÁ§∫IPTVÁõ¥Êí≠Ê∫êÁöÑËøõÂ∫¶Êù°„ÄÇ<br>\n7„ÄÅËøûÁª≠ÁÇπÂáªÂ±èÂπï4Ê¨°ÔºöÊòæÁ§∫ËÆæÁΩÆÁïåÈù¢<br>\n8„ÄÅÁÇπÂáªËôöÊãüÊç¢Ê∫êÂÅ•ÔºöÂàáÊç¢Áõ¥Êí≠Ê∫êÔºàAPP‰πüÊ†πÊçÆÂç°È°øÊÉÖÂÜµËá™Âä®ÂàáÊç¢Áõ¥Êí≠Ê∫êÔºâÔºåËÆæÁΩÆÁïåÈù¢ÂèØÂàáÊç¢ÊòæÁ§∫ËôöÊãüÈîÆ<br>\nÈïøÊåâËôöÊãüÊç¢Ê∫êÂÅ•ÔºöÊòæÁ§∫Âêå‰∏ÄÈ¢ëÈÅìÁöÑÊâÄÊúâ‰∏çÂêåÁõ¥Êí≠Ê∫êÂπ∂ÂèØÂàáÊç¢„ÄÇ<br>\n9„ÄÅÈïøÊåâËß¶Êë∏Â±èÂπïÔºöÊòæÁ§∫ÂΩìÂâçÈ¢ëÈÅìËäÇÁõÆÂçï<br>\n10„ÄÅÊåâ‰∏ªÈ°µÔºàÊâãÊú∫ËôöÊãüËØ∑Ê±ÇÈîÆÔºâÈîÆËøõÂÖ•Áîª‰∏≠Áîª<br>\n11„ÄÅËß¶Êë∏Â±èÁÜÑÂ±è‰ªçÂèØÊí≠ÊîæÔºàËÆæÁΩÆÁïåÈù¢ÊúâÂèñÊ∂àÂºÄÂÖ≥Ôºâ<br>\n12„ÄÅÈï∑ÊåâÂàÜÁµÑÈö±ËóèÔºåÈõôÊìäÁ¥ÖËâ≤XÊÅ¢Âæ©„ÄÇ<br>\n\n\n* ÊâìÈñãÈÖçÁΩÆÂêéÔºåÈÅ∏ÊìáÈÅ†Á®ãÈÖçÁΩÆÔºåÊéÉÊèè‰∫åÁ∂≠Á¢ºÂèØ‰ª•ÈÖçÁΩÆË¶ñÈ†ªÊ∫êÁ≠â„ÄÇ‰πüÂèØ‰ª•Áõ¥Êé•ÈÅ†Á®ãÈÖçÁΩÆÂú∞ÂùÄ http://0.0.0.0:34567\n* ÊâìÈñã‚ÄúÊØèÂ§©Ëá™ÂãïÊõ¥Êñ∞Áõ¥Êí≠Ê∫ê‚ÄùÂêéÔºåÊáâÁî®ÂïüÂãïÂêéÊúÉËá™ÂãïÊõ¥Êñ∞Áõ¥Êí≠Ê∫ê\n\nÊ≥®ÊÑèÔºö\n\n* ÈÅáÂà∞ÂïèÈ°åÂèØ‰ª•ÂÖàËÄÉÊÖÆÈáçÂïü/ÊÅ¢Âæ©ÈªòË™ç/Ê∏ÖÈô§Êï∏Êìö/ÈáçÊñ∞ÂÆâË£ùÁ≠âÊñπÂºèËá™Âä©Ëß£Ê±∫\n\n‰∏ãËºâÂÆâË£ù [releases](https://github.com/horsemail/yourtv)\n\n## ÂÖ∂‰ªñ\n\nÂª∫Ë≠∞ÈÄöÈÅéADBÈÄ≤Ë°åÂÆâË£ùÔºö\n\n```shell\nadb install YourTV.apk\n```\n\nÂ∞èÁ±≥ÈõªË¶ñÂèØ‰ª•‰ΩøÁî®Â∞èÁ±≥ÈõªË¶ñÂä©ÊâãÈÄ≤Ë°åÂÆâË£ù\n\n## Â∏∏Ë¶ãÂïèÈ°å\n\n* ÁÇ∫‰ªÄÈ∫ºÈÅ†Á®ãÈÖçÁΩÆË¶ñÈ†ªÊ∫êÊñáÊú¨ÂæåÔºåÂÜçÊ¨°ÊâìÈñãÊáâÁî®ÂæåÂèàÊÅ¢Âæ©Âà∞Âéü‰æÜÁöÑÈÖçÁΩÆÔºü<br>\n\n  Â¶ÇÊûú‚ÄúÊáâÁî®ÂïüÂãïÂêéÊõ¥Êñ∞Ë¶ñÈ†ªÊ∫ê‚ÄùÈñãÂïüÂæåÔºå‰∏îÂ≠òÂú®Ë¶ñÈ†ªÊ∫êÂú∞ÂùÄÔºåÂâáÊúÉËá™ÂãïÊõ¥Êñ∞ÔºåÂèØËÉΩÊúÉË¶ÜËìãÂ∑≤‰øùÂ≠òÁöÑË¶ñÈ†ªÊ∫êÊñáÊú¨„ÄÇ<br>\n\n* Ëá™Â∑±Á∑®Ë≠ØAPPÊ≥®ÊÑè‰∫ãÈ†ÖÔºö<br>\n  1„ÄÅË≥áÊ∫êÊñá‰ª∂ÈúÄË¶ÅËá™Â∑±ÈÄêÂÄãÁ¢∫Ë™çË®≠ÁΩÆÁÇ∫Ëá™Â∑±ÁöÑ‰ø°ÊÅØÔºåÁâπÂà•ÊòØcloudflare.txt/github_private.txt/sources.txt<br>\n  ÈúÄ‰ΩøÁî®Âä†ÂØÜËß£ÂØÜÂ∑•ÂÖ∑Á∂≤Á´ô https://yourtvcrypto.horsenma.net  Âä†ÂØÜÂæåÂ≠òÂÑ≤„ÄÇ<br>\n  2„ÄÅÊàë‰∏äÂÇ≥ÁöÑAPKÊñá‰ª∂ËàáÊ∫êÁ¢ºÂèØËÉΩ‰∏çÂêåÊ≠•ÔºåAPKÊñá‰ª∂ÊØîËºÉÊñ∞ÔºåÊ∫êÁ¢ºÊõ¥Êñ∞‰∏ÄËà¨ËêΩÂæåÂπæÂ§©ÔºåË´ãÊ≥®ÊÑèÊü•ÁúãÔºå<br>\n  3„ÄÅÊàë‰∏äÂÇ≥ÁöÑAPKÊñá‰ª∂‰ΩøÁî®ÁöÑÂä†ÂØÜËß£ÂØÜÈÇèËºØËàáÈ†ÖÁõÆÂÖßÂä†ÂØÜËß£ÂØÜÈÇèËºØÔºöhttps://yourtvcrypto.horsenma.net  ‰∏çÂêåÔºåÁõÆÁöÑ‰øùË≠∑ÊàëÁöÑÁßÅÊúâË≥áÊ∫ê‰ø°ÊÅØ„ÄÇ<br>\n* ÊóßÁîµËßÜÊú∫Êó†Ê≥ïËßÇÁúãwebviewÁΩëÈ°µËßÜÈ¢ëÈ¢ëÈÅìÁöÑÔºåÊâãÂä®Âº∫Âà∂ÂÆâË£Ö<br>\n**[Android System WebView 6.0+ ‰∏ãËΩΩ](https://ftp.horsenma.net/tv/Android_System_WebView_Android_6_0.apk)**<br>\n\n## ÊÑüË¨ù\n\n[live](https://github.com/fanmingming/live)<br>\n[my-tv-0](https://github.com/lizongying/my-tv-0)<br>\n[my-tv-1](https://github.com/lizongying/my-tv-1)<br>\n\n",
      "stars_today": 18
    },
    {
      "id": 181042062,
      "name": "UTM",
      "full_name": "utmapp/UTM",
      "description": "Virtual machines for iOS and macOS",
      "html_url": "https://github.com/utmapp/UTM",
      "stars": 32213,
      "forks": 1624,
      "language": "Swift",
      "topics": [
        "apple",
        "emulation",
        "ios",
        "jailbreak",
        "macos",
        "qemu",
        "utm",
        "virtual-machines",
        "vm"
      ],
      "created_at": "2019-04-12T16:09:24Z",
      "updated_at": "2026-01-14T00:39:41Z",
      "pushed_at": "2026-01-12T02:14:14Z",
      "open_issues": 972,
      "owner": {
        "login": "utmapp",
        "avatar_url": "https://avatars.githubusercontent.com/u/49966544?v=4"
      },
      "readme": "#  UTM\n[![Build](https://github.com/utmapp/UTM/workflows/Build/badge.svg?branch=main&event=push)][1]\n\n> It is possible to invent a single machine which can be used to compute any computable sequence.\n\n-- <cite>Alan Turing, 1936</cite>\n\nUTM is a full featured system emulator and virtual machine host for iOS and macOS. It is based off of QEMU. In short, it allows you to run Windows, Linux, and more on your Mac, iPhone, and iPad. More information at https://getutm.app/ and https://mac.getutm.app/\n\n<p align=\"center\">\n  <img width=\"450px\" alt=\"UTM running on an iPhone\" src=\"screen.png\">\n  <br>\n  <img width=\"450px\" alt=\"UTM running on a MacBook\" src=\"screenmac.png\">\n</p>\n\n## Features\n\n* Full system emulation (MMU, devices, etc) using QEMU\n* 30+ processors supported including x86_64, ARM64, and RISC-V\n* VGA graphics mode using SPICE and QXL\n* Text terminal mode\n* USB devices\n* JIT based acceleration using QEMU TCG\n* Frontend designed from scratch for macOS 11 and iOS 11+ using the latest and greatest APIs\n* Create, manage, run VMs directly from your device\n\n## Additional macOS Features\n\n* Hardware accelerated virtualization using Hypervisor.framework and QEMU\n* Boot macOS guests with Virtualization.framework on macOS 12+\n\n## UTM SE\n\nUTM/QEMU requires dynamic code generation (JIT) for maximum performance. JIT on iOS devices require either a jailbroken device, or one of the various workarounds found for specific versions of iOS (see \"Install\" for more details).\n\nUTM SE (\"slow edition\") uses a [threaded interpreter][3] which performs better than a traditional interpreter but still slower than JIT. This technique is similar to what [iSH][4] does for dynamic execution. As a result, UTM SE does not require jailbreaking or any JIT workarounds and can be sideloaded as a regular app.\n\nTo optimize for size and build times, only the following architectures are included in UTM SE: ARM, PPC, RISC-V, and x86 (all with both 32-bit and 64-bit variants).\n\n## Install\n\nUTM (SE) for iOS: https://getutm.app/install/\n\nUTM is also available for macOS: https://mac.getutm.app/\n\n## Development\n\n### [macOS Development](Documentation/MacDevelopment.md)\n\n### [iOS Development](Documentation/iOSDevelopment.md)\n\n## Related\n\n* [iSH][4]: emulates a usermode Linux terminal interface for running x86 Linux applications on iOS\n* [a-shell][5]: packages common Unix commands and utilities built natively for iOS and accessible through a terminal interface\n\n## License\n\nUTM is distributed under the permissive Apache 2.0 license. However, it uses several (L)GPL components. Most are dynamically linked but the gstreamer plugins are statically linked and parts of the code are taken from qemu. Please be aware of this if you intend on redistributing this application.\n\nSome icons made by [Freepik](https://www.freepik.com) from [www.flaticon.com](https://www.flaticon.com/).\n\nAdditionally, UTM frontend depends on the following MIT/BSD License components:\n\n* [IQKeyboardManager](https://github.com/hackiftekhar/IQKeyboardManager)\n* [SwiftTerm](https://github.com/migueldeicaza/SwiftTerm)\n* [ZIP Foundation](https://github.com/weichsel/ZIPFoundation)\n* [InAppSettingsKit](https://github.com/futuretap/InAppSettingsKit)\n\nContinuous integration hosting is provided by [MacStadium](https://www.macstadium.com/opensource)\n\n[<img src=\"https://uploads-ssl.webflow.com/5ac3c046c82724970fc60918/5c019d917bba312af7553b49_MacStadium-developerlogo.png\" alt=\"MacStadium logo\" width=\"250\">](https://www.macstadium.com)\n\n  [1]: https://github.com/utmapp/UTM/actions?query=event%3Arelease+workflow%3ABuild\n  [2]: screen.png\n  [3]: https://github.com/ktemkin/qemu/blob/with_tcti/tcg/aarch64-tcti/README.md\n  [4]: https://github.com/ish-app/ish\n  [5]: https://github.com/holzschu/a-shell\n",
      "stars_today": 17
    },
    {
      "id": 60667730,
      "name": "lvgl",
      "full_name": "lvgl/lvgl",
      "description": "Embedded graphics library to create beautiful UIs for any MCU, MPU and display type. ",
      "html_url": "https://github.com/lvgl/lvgl",
      "stars": 22471,
      "forks": 3987,
      "language": "C",
      "topics": [
        "c",
        "embedded",
        "graphics",
        "gui",
        "mcu",
        "microcontroller",
        "tft"
      ],
      "created_at": "2016-06-08T04:14:34Z",
      "updated_at": "2026-01-13T23:38:23Z",
      "pushed_at": "2026-01-13T12:05:25Z",
      "open_issues": 137,
      "owner": {
        "login": "lvgl",
        "avatar_url": "https://avatars.githubusercontent.com/u/19811762?v=4"
      },
      "readme": "<p align=\"right\">\n  <b>English</b> | <a href=\"./docs/README_zh.md\">‰∏≠Êñá</a> | <a href=\"./docs/README_pt_BR.md\">Portugu√™s do Brasil</a> | <a href=\"./docs/README_jp.md\">Êó•Êú¨Ë™û</a> | <a href=\"./docs/README_he.md\">◊¢◊ë◊®◊ô◊™</a>\n</p>\n\n<br>\n\n<p align=\"center\">\n¬† <img src=\"https://lvgl.io/github-assets/logo-colored.png\" width=300px>\n</p>\n\n<h1 align=\"center\">Light and Versatile Graphics Library</h1>\n\n<br/>\n\n<div align=\"center\">\n  <img src=\"https://lvgl.io/github-assets/smartwatch-demo.gif\">\n  &nbsp;\n¬† <img border=\"1px\" src=\"https://lvgl.io/github-assets/widgets-demo.gif\">\n</div>\n\n<br/>\n\n<p align=\"center\">\n  <a href=\"https://lvgl.io\" title=\"Homepage of LVGL\">Website</a> |\n  <a href=\"https://pro.lvgl.io\" title=\"LVGL Pro XML based UI Editor\">LVGL Pro Editor</a> |\n  <a href=\"https://docs.lvgl.io/\" title=\"Detailed documentation with 100+ examples\">Docs</a> |\n  <a href=\"https://forum.lvgl.io\" title=\"Get help and help others\">Forum</a> |\n  <a href=\"https://lvgl.io/demos\" title=\"Demos running in your browser\">Demos</a> |\n<a href=\"https://lvgl.io/services\" title=\"Graphics design, UI implementation and consulting\">Services</a>\n</p>\n\n<br/>\n\n### Table of Contents\n<p>\n  <a href=\"#ledger-overview\">Overview</a> <br/>\n  <a href=\"#-features\">Features</a> <br/>\n  <a href=\"#%EF%B8%8F-platform-support\">Platform Support</a> <br/>\n  <a href=\"#-lvgl-pro-editor\">LVGL Pro Editor</a> <br/>\n  <a href=\"#-commercial-services\">Commercial Services</a> <br/>\n  <a href=\"#%E2%80%8D-integrating-lvgl\">Integrating LVGL</a> <br/>\n  <a href=\"#-examples\">Examples</a> <br/>\n  <a href=\"#-contributing\">Contributing</a>\n</p>\n\n<br/>\n\n## üìí Overview\n\n**LVGL** is a free and open-source UI library that enables you to create graphical user interfaces\nfor any MCUs and MPUs from any vendor on any platform.\n\n**Requirements**: LVGL has no external dependencies, which makes it easy to compile for any modern target,\nfrom small MCUs to multi-core Linux-based MPUs with 3D support. For a simple UI, you need only ~100kB RAM,\n~200‚Äì300kB flash, and a buffer size of 1/10 of the screen for rendering.\n\n**To get started**, pick a ready-to-use VSCode, Eclipse, or any other project and try out LVGL\non your PC. The LVGL UI code is fully platform-independent, so you can use the same UI code\non embedded targets too.\n\n**LVGL Pro** is a complete toolkit to help you build, test, share, and ship UIs faster.\nIt comes with an XML Editor where you can quickly create and test reusable components,\nexport C code, or load the XMLs at runtime. Learn more here.\n\n## üí° Features\n\n**Free and Portable**\n  - A fully portable C (C++ compatible) library with no external dependencies.\n  - Can be compiled for any MCU or MPU, with any (RT)OS. Make, CMake, and simple globbing are all supported.\n  - Supports monochrome, ePaper, OLED, or TFT displays, or even monitors. [Displays](https://docs.lvgl.io/master/main-modules/display/index.html)\n  - Distributed under the MIT license, so you can easily use it in commercial projects too.\n  - Needs only 32kB RAM and 128kB Flash, a frame buffer, and at least a 1/10 screen-sized buffer for rendering.\n  - OS, external memory, and GPU are supported but not required.\n\n**Widgets, Styles, Layouts, and More**\n  - 30+ built-in [Widgets](https://docs.lvgl.io/master/widgets/index.html): Button, Label, Slider, Chart, Keyboard, Meter, Arc, Table, and many more.\n  - Flexible [Style system](https://docs.lvgl.io/master/common-widget-features/styles/index.html) with ~100 style properties to customize any part of the widgets in any state.\n  - [Flexbox](https://docs.lvgl.io/master/common-widget-features/layouts/flex.html) and [Grid](https://docs.lvgl.io/master/common-widget-features/layouts/grid.html)-like layout engines to automatically size and position the widgets responsively.\n  - Text is rendered with UTF-8 encoding, supporting CJK, Thai, Hindi, Arabic, and Persian writing systems.\n  - [Data bindings](https://docs.lvgl.io/master/main-modules/observer/index.html) to easily connect the UI with the application.\n  - Rendering engine supports animations, anti-aliasing, opacity, smooth scrolling, shadows, image transformation, etc.\n  - [Powerful 3D rendering engine](https://docs.lvgl.io/master/libs/gltf.html) to show [glTF models](https://sketchfab.com/) with OpenGL.\n  - Supports Mouse, Touchpad, Keypad, Keyboard, External buttons, Encoder [Input devices](https://docs.lvgl.io/master/main-modules/indev.html).\n  - [Multiple display](https://docs.lvgl.io/master/main-modules/display/overview.html#how-many-displays-can-lvgl-use) support.\n\n## üì¶Ô∏è Platform Support\n\nLVGL has no external dependencies, so it can be easily compiled for any devices and it's  also available in many package managers and RTOSes:\n\n- [Arduino library](https://docs.lvgl.io/master/integration/framework/arduino.html)\n- [PlatformIO package](https://registry.platformio.org/libraries/lvgl/lvgl)\n- [Zephyr library](https://docs.lvgl.io/master/integration/os/zephyr.html)\n- [ESP-IDF(ESP32) component](https://components.espressif.com/components/lvgl/lvgl)\n- [NXP MCUXpresso component](https://www.nxp.com/design/software/embedded-software/lvgl-open-source-graphics-library:LITTLEVGL-OPEN-SOURCE-GRAPHICS-LIBRARY)\n- [NuttX library](https://docs.lvgl.io/master/integration/os/nuttx.html)\n- [RT-Thread RTOS](https://docs.lvgl.io/master/integration/os/rt-thread.html)\n- CMSIS-Pack\n- [RIOT OS package](https://doc.riot-os.org/group__pkg__lvgl.html#details)\n\n## üöÄ LVGL Pro Editor\n\nLVGL Pro is a complete toolkit to build, test, share, and ship embedded UIs efficiently.\n\nIt consists of four tightly related tools:\n\n1. **XML Editor**: The heart of LVGL Pro. A desktop app to build components and screens in XML, manage data bindings, translations, animations, tests, and more. Learn more about the [XML Format](https://docs.lvgl.io/master/xml/xml/index.html) and the [Editor](https://docs.lvgl.io/master/xml/editor/index.html).\n2. **Online Viewer**: Run the Editor in your browser, open GitHub projects, and share easily without setting up a developer environment. Visit [https://viewer.lvgl.io](https://viewer.lvgl.io).\n3. **CLI Tool**: Generate C code and run tests in CI/CD. See the details [here](https://docs.lvgl.io/master/xml/tools/cli.html).\n4. **Figma Plugin**: Sync and extract styles directly from Figma. See how it works [here](https://docs.lvgl.io/master/xml/tools/figma.html).\n\nTogether, these tools let developers build UIs efficiently, test them reliably, and collaborate with team members and customers.\n\nLearn more at https://pro.lvgl.io\n\n## ü§ù Commercial Services\n\nLVGL LLC provides several types of commercial services to help you with UI development. With 15+ years of experience in the user interface and graphics industry, we can help bring your UI to the next level.\n\n- **Graphics design**: Our in-house graphic designers are experts in creating beautiful modern designs that fit your product and the capabilities of your hardware.\n- **UI implementation**: We can implement your UI based on the design you or we have created. You can be sure that we will make the most of your hardware and LVGL. If a feature or widget is missing from LVGL, don't worry, we will implement it for you.\n- **Consulting and Support**: We also offer consulting to help you avoid costly and time-consuming mistakes during UI development.\n- **Board certification**: For companies offering development boards or production-ready kits, we provide board certification to show how the board can run LVGL.\n\nCheck out our [Demos](https://lvgl.io/demos) as references. For more information, take a look at the [Services page](https://lvgl.io/services).\n\n[Contact us](https://lvgl.io/#contact) and tell us how we can help.\n\n## üßë‚Äçüíª Integrating LVGL\n\nIntegrating LVGL is very simple. Just drop it into any project and compile it as you would compile other files.\nTo configure LVGL, copy `lv_conf_template.h` as `lv_conf.h`, enable the first `#if 0`, and adjust the configs as needed.\n(The default config is usually fine.) If available, LVGL can also be used with Kconfig.\n\nOnce in the project, you can initialize LVGL and create display and input devices as follows:\n\n```c\n#include \"lvgl/lvgl.h\" /*Define LV_LVGL_H_INCLUDE_SIMPLE to include as \"lvgl.h\"*/\n\n#define TFT_HOR_RES 320\n#define TFT_VER_RES 240\n\nstatic uint32_t my_tick_cb(void)\n{\n    return my_get_millisec();\n}\n\nstatic void my_flush_cb(lv_display_t * disp, const lv_area_t * area, uint8_t * px_map)\n{\n    /*Write px_map to the area->x1, area->x2, area->y1, area->y2 area of the\n     *frame buffer or external display controller. */\n}\n\nstatic void my_touch_read_cb(lv_indev_t * indev, lv_indev_data_t * data)\n{\n   if(my_touch_is_pressed()) {\n       data->point.x = touchpad_x;\n       data->point.y = touchpad_y;\n       data->state = LV_INDEV_STATE_PRESSED;\n   } else {\n       data->state = LV_INDEV_STATE_RELEASED;\n   }\n}\n\nvoid main(void)\n{\n    my_hardware_init();\n\n    /*Initialize LVGL*/\n    lv_init();\n\n    /*Set millisecond-based tick source for LVGL so that it can track time.*/\n    lv_tick_set_cb(my_tick_cb);\n\n    /*Create a display where screens and widgets can be added*/\n    lv_display_t * display = lv_display_create(TFT_HOR_RES, TFT_VER_RES);\n\n    /*Add rendering buffers to the screen.\n     *Here adding a smaller partial buffer assuming 16-bit (RGB565 color format)*/\n    static uint8_t buf[TFT_HOR_RES * TFT_VER_RES / 10 * 2]; /* x2 because of 16-bit color depth */\n    lv_display_set_buffers(display, buf, NULL, sizeof(buf), LV_DISPLAY_RENDER_MODE_PARTIAL);\n\n    /*Add a callback that can flush the content from `buf` when it has been rendered*/\n    lv_display_set_flush_cb(display, my_flush_cb);\n\n    /*Create an input device for touch handling*/\n    lv_indev_t * indev = lv_indev_create();\n    lv_indev_set_type(indev, LV_INDEV_TYPE_POINTER);\n    lv_indev_set_read_cb(indev, my_touch_read_cb);\n\n    /*The drivers are in place; now we can create the UI*/\n    lv_obj_t * label = lv_label_create(lv_screen_active());\n    lv_label_set_text(label, \"Hello world\");\n    lv_obj_center(label);\n\n    /*Execute the LVGL-related tasks in a loop*/\n    while(1) {\n        lv_timer_handler();\n        my_sleep_ms(5);         /*Wait a little to let the system breathe*/\n    }\n}\n```\n\n## ü§ñ Examples\n\nYou can check out more than 100 examples at https://docs.lvgl.io/master/examples.html\n\nThe Online Viewer also contains tutorials to easily learn XML: https://viewer.lvgl.io/\n\n\n### Hello World Button with an Event\n\n<img width=\"311\" height=\"232\" alt=\"image\" src=\"https://github.com/user-attachments/assets/5948b485-e3f7-4a63-bb21-984381417c4a\" />\n\n<details>\n  <summary>C code</summary>\n\n  ```c\nstatic void button_clicked_cb(lv_event_t * e)\n{\n\tprintf(\"Clicked\\n\");\n}\n\n[...]\n\n  lv_obj_t * button = lv_button_create(lv_screen_active());\n  lv_obj_center(button);\n  lv_obj_add_event_cb(button, button_clicked_cb, LV_EVENT_CLICKED, NULL);\n\n  lv_obj_t * label = lv_label_create(button);\n  lv_label_set_text(label, \"Hello from LVGL!\");\n```\n</details>\n\n<details>\n  <summary>In XML with LVGL Pro</summary>\n\n```xml\n<screen>\n\t<view>\n\t\t<lv_button align=\"center\">\n\t\t\t<event_cb callback=\"button_clicked_cb\" />\n\t\t\t<lv_label text=\"Hello from LVGL!\" />\n\t\t</lv_button>\n\t</view>\n</screen>\n```\n\n</details>\n\n### Styled Slider with Data-binding\n\n<img width=\"314\" height=\"233\" alt=\"image\" src=\"https://github.com/user-attachments/assets/268db1a0-946c-42e2-aee4-9550bdf5f4f9\" />\n\n<details>\n  <summary>C code</summary>\n\n```c\nstatic void my_observer_cb(lv_observer_t * observer, lv_subject_t * subject)\n{\n\tprintf(\"Slider value: %d\\n\", lv_subject_get_int(subject));\n}\n\n[...]\n\nstatic lv_subject_t subject_value;\nlv_subject_init_int(&subject_value, 35);\nlv_subject_add_observer(&subject_value, my_observer_cb, NULL);\n\nlv_style_t style_base;\nlv_style_init(&style_base);\nlv_style_set_bg_color(&style_base, lv_color_hex(0xff8800));\nlv_style_set_bg_opa(&style_base, 255);\nlv_style_set_radius(&style_base, 4);\n\nlv_obj_t * slider = lv_slider_create(lv_screen_active());\nlv_obj_center(slider);\nlv_obj_set_size(slider, lv_pct(80), 16);\nlv_obj_add_style(slider, &style_base, LV_PART_INDICATOR);\nlv_obj_add_style(slider, &style_base, LV_PART_KNOB);\nlv_obj_add_style(slider, &style_base, 0);\nlv_obj_set_style_bg_opa(slider, LV_OPA_50, 0);\nlv_obj_set_style_border_width(slider, 3, LV_PART_KNOB);\nlv_obj_set_style_border_color(slider, lv_color_hex3(0xfff), LV_PART_KNOB);\nlv_slider_bind_value(slider, &subject_value);\n\nlv_obj_t * label = lv_label_create(lv_screen_active());\nlv_obj_align(label, LV_ALIGN_CENTER, 0, -30);\nlv_label_bind_text(label, &subject_value, \"Temperature: %d ¬∞C\");\n```\n\n</details>\n\n<details>\n  <summary>In XML with LVGL Pro</summary>\n\n```xml\n<screen>\n\t<styles>\n\t\t<style name=\"style_base\" bg_opa=\"100%\" bg_color=\"0xff8800\" radius=\"4\" />\n\t\t<style name=\"style_border\" border_color=\"0xfff\" border_width=\"3\" />\n\t</styles>\n\n\t<view>\n\t\t<lv_label bind_text=\"value\" bind_text-fmt=\"Temperature: %d ¬∞C\" align=\"center\" y=\"-30\" />\n\t\t<lv_slider align=\"center\" bind_value=\"value\" style_bg_opa=\"30%\">\n\t\t\t<style name=\"style_base\" />\n\t\t\t<style name=\"style_base\" selector=\"knob\" />\n\t\t\t<style name=\"style_base\" selector=\"indicator\" />\n\t\t\t<style name=\"style_border\" selector=\"knob\" />\n\t\t</lv_slider>\n\t</view>\n</screen>\n```\n\n</details>\n\n### Checkboxes in a Layout\n\n<img width=\"311\" height=\"231\" alt=\"image\" src=\"https://github.com/user-attachments/assets/ba9af647-2ea1-4bc8-b53d-c7b43ce24b6e\" />\n\n<details>\n  <summary>C code</summary>\n\n  ```c\n/*Create a new screen and load it*/\nlv_obj_t * scr = lv_obj_create(NULL);\nlv_screen_load(scr);\n\n/*Set a column layout*/\nlv_obj_set_flex_flow(scr, LV_FLEX_FLOW_COLUMN);\nlv_obj_set_flex_align(scr, LV_FLEX_ALIGN_SPACE_EVENLY, /*Vertical alignment*/\n\t\t\t\t\t\t   LV_FLEX_ALIGN_START,\t       /*Horizontal alignment in the track*/\n\t\t\t\t\t\t   LV_FLEX_ALIGN_CENTER);      /*Horizontal alignment of the track*/\n\n/*Create 5 checkboxes*/\nconst char * texts[5] = {\"Input 1\", \"Input 2\", \"Input 3\", \"Output 1\", \"Output 2\"};\nfor(int i = 0; i < 5; i++) {\n\tlv_obj_t * cb = lv_checkbox_create(scr);\n\tlv_checkbox_set_text(cb, texts[i]);\n}\n\n/*Change some states*/\nlv_obj_add_state(lv_obj_get_child(scr, 1), LV_STATE_CHECKED);\nlv_obj_add_state(lv_obj_get_child(scr, 3), LV_STATE_DISABLED);\n```\n\n</details>\n\n<details>\n  <summary>In XML with LVGL Pro</summary>\n\n```xml\n<screen>\n\t<view\n\t\tflex_flow=\"column\"\n\t\tstyle_flex_main_place=\"space_evenly\"\n\t\tstyle_flex_cross_place=\"start\"\n\t\tstyle_flex_track_place=\"center\"\n\t>\n\t\t<lv_checkbox text=\"Input 1\"/>\n\t\t<lv_checkbox text=\"Input 2\"/>\n\t\t<lv_checkbox text=\"Input 3\" checked=\"true\"/>\n\t\t<lv_checkbox text=\"Output 1\"/>\n\t\t<lv_checkbox text=\"Output 2\" disabled=\"true\"/>\n   </view>\n</screen>\n```\n\n</details>\n\n\n## üåü Contributing\n\nLVGL is an open project, and contributions are very welcome. There are many ways to contribute, from simply speaking about your project, writing examples, improving the documentation, fixing bugs, or even hosting your own project under the LVGL organization.\n\nFor a detailed description of contribution opportunities, visit the [Contributing](https://docs.lvgl.io/master/contributing/index.html)\nsection of the documentation.\n\nMore than 600 people have already left their fingerprint on LVGL. Be one of them! See you here! üôÇ\n\n<a href=\"https://github.com/lvgl/lvgl/graphs/contributors\"> <img src=\"https://contrib.rocks/image?repo=lvgl/lvgl&max=48\" /> </a>\n\n... and many more.\n",
      "stars_today": 16
    },
    {
      "id": 126493684,
      "name": "gotenberg",
      "full_name": "gotenberg/gotenberg",
      "description": "A developer-friendly API for converting numerous document formats into PDF files, and more!",
      "html_url": "https://github.com/gotenberg/gotenberg",
      "stars": 10917,
      "forks": 722,
      "language": "Go",
      "topics": [
        "api",
        "chrome",
        "chromium",
        "convert-to-pdf",
        "docker",
        "docx-to-pdf",
        "excel",
        "exiftool",
        "html-to-pdf",
        "libreoffice",
        "openoffice",
        "pdf",
        "pdf-converter",
        "pdftk",
        "puppeteer",
        "qpdf",
        "screenshots",
        "unoconv",
        "wkhtmltopdf",
        "word"
      ],
      "created_at": "2018-03-23T14:05:59Z",
      "updated_at": "2026-01-14T00:57:55Z",
      "pushed_at": "2026-01-13T22:39:14Z",
      "open_issues": 51,
      "owner": {
        "login": "gotenberg",
        "avatar_url": "https://avatars.githubusercontent.com/u/66820499?v=4"
      },
      "readme": "<p align=\"center\">\n    <img src=\"https://user-images.githubusercontent.com/8983173/130322857-185831e2-f041-46eb-a17f-0a69d066c4e5.png\" alt=\"Gotenberg Logo\" width=\"150\" height=\"150\" />\n    <h3 align=\"center\">Gotenberg</h3>\n    <p align=\"center\">A containerized API for seamless PDF conversion</p>\n    <p align=\"center\">\n        <a href=\"https://hub.docker.com/r/gotenberg/gotenberg\"><img alt=\"Total downloads (gotenberg/gotenberg)\" src=\"https://img.shields.io/docker/pulls/gotenberg/gotenberg\"></a>\n        <a href=\"https://hub.docker.com/r/thecodingmachine/gotenberg\"><img alt=\"Total downloads (thecodingmachine/gotenberg)\" src=\"https://img.shields.io/docker/pulls/thecodingmachine/gotenberg\"></a>\n        <a href=\"https://github.com/gotenberg/gotenberg/actions/workflows/continuous-integration.yml\"><img alt=\"Continuous Integration\" src=\"https://github.com/gotenberg/gotenberg/actions/workflows/continuous-integration.yml/badge.svg\"></a>\n        <a href=\"https://pkg.go.dev/github.com/gotenberg/gotenberg/v8\"><img alt=\"Go Reference\" src=\"https://pkg.go.dev/badge/github.com/gotenberg/gotenberg.svg\"></a>\n    </p>\n    <p align=\"center\">\n        <a href=\"https://trendshift.io/repositories/2996\"><img src=\"https://trendshift.io/api/badge/repositories/2996\" alt=\"gotenberg%2Fgotenberg | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n    </p>\n    <p align=\"center\"><a href=\"https://gotenberg.dev/docs/getting-started/introduction\">Documentation</a> &#183; <a href=\"https://gotenberg.dev/docs/getting-started/installation#live-demo-\">Live Demo</a> üî•</p>\n</p>\n\n---\n\n**Gotenberg** provides a developer-friendly API to interact with powerful tools like Chromium and LibreOffice for converting\nnumerous document formats (HTML, Markdown, Word, Excel, etc.) into PDF files, and more!\n\n## Quick Start\n\nOpen a terminal and run the following command:\n\n```\ndocker run --rm -p 3000:3000 gotenberg/gotenberg:8\n```\n\nAlternatively, using the historic Docker repository from our sponsor [TheCodingMachine](https://www.thecodingmachine.com):\n\n```\ndocker run --rm -p 3000:3000 thecodingmachine/gotenberg:8\n```\n\nThe API is now available on your host at http://localhost:3000.\n\nHead to the [documentation](https://gotenberg.dev/docs/getting-started/introduction) to learn how to interact with it üöÄ\n\n## Sponsors\n\n<p align=\"center\">\n    <a href=\"https://thecodingmachine.com\">\n        <img src=\"https://user-images.githubusercontent.com/8983173/130324668-9d6e7b35-53a3-49c7-a574-38190d2bd6b0.png\" alt=\"TheCodingMachine Logo\" width=\"333\" height=\"163\" />\n    </a>\n    <a href=\"https://pdfme.com?utm_source=gotenberg_github&utm_medium=website\" target=\"_blank\">\n        <img src=\"https://github.com/user-attachments/assets/2a75dd40-ca18-4d34-acd5-5dd474595168\" alt=\"pdfme Logo\" width=\"333\" height=\"163\" />\n    </a>\n</p>\n\nSponsorships help maintain and improve Gotenberg - [become a sponsor](https://github.com/sponsors/gulien) ‚ù§Ô∏è\n\n---\n\n<p align=\"center\">\n  <strong>Powered by</strong>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://jb.gg/OpenSource\">\n    <img src=\"https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.svg\" alt=\"JetBrains logo\" width=\"200\"/>\n  </a>\n</p>\n",
      "stars_today": 16
    },
    {
      "id": 949523404,
      "name": "cursor-talk-to-figma-mcp",
      "full_name": "grab/cursor-talk-to-figma-mcp",
      "description": "TalkToFigma: MCP integration between Cursor and Figma, allowing Cursor Agentic AI to communicate with Figma for reading designs and modifying them programmatically.",
      "html_url": "https://github.com/grab/cursor-talk-to-figma-mcp",
      "stars": 5903,
      "forks": 632,
      "language": "JavaScript",
      "topics": [
        "agent",
        "agentic",
        "agentic-ai",
        "ai",
        "ai-agents",
        "automation",
        "cursor",
        "design",
        "figma",
        "generative-ai",
        "llm",
        "llms",
        "mcp",
        "model-context-protocol"
      ],
      "created_at": "2025-03-16T16:45:37Z",
      "updated_at": "2026-01-13T23:29:15Z",
      "pushed_at": "2025-11-03T01:00:00Z",
      "open_issues": 72,
      "owner": {
        "login": "grab",
        "avatar_url": "https://avatars.githubusercontent.com/u/17284363?v=4"
      },
      "readme": "# Cursor Talk to Figma MCP\n\nThis project implements a Model Context Protocol (MCP) integration between Cursor AI and Figma, allowing Cursor to communicate with Figma for reading designs and modifying them programmatically.\n\nhttps://github.com/user-attachments/assets/129a14d2-ed73-470f-9a4c-2240b2a4885c\n\n## Project Structure\n\n- `src/talk_to_figma_mcp/` - TypeScript MCP server for Figma integration\n- `src/cursor_mcp_plugin/` - Figma plugin for communicating with Cursor\n- `src/socket.ts` - WebSocket server that facilitates communication between the MCP server and Figma plugin\n\n## Get Started\n\n1. Install Bun if you haven't already:\n\n```bash\ncurl -fsSL https://bun.sh/install | bash\n```\n\n2. Run setup, this will also install MCP in your Cursor's active project\n\n```bash\nbun setup\n```\n\n3. Start the Websocket server\n\n```bash\nbun socket\n```\n\n4. **NEW** Install Figma plugin from [Figma community page](https://www.figma.com/community/plugin/1485687494525374295/cursor-talk-to-figma-mcp-plugin) or [install locally](#figma-plugin)\n\n## Quick Video Tutorial\n\n[Video Link](https://www.linkedin.com/posts/sonnylazuardi_just-wanted-to-share-my-latest-experiment-activity-7307821553654657024-yrh8)\n\n## Design Automation Example\n\n**Bulk text content replacement**\n\nThanks to [@dusskapark](https://github.com/dusskapark) for contributing the bulk text replacement feature. Here is the [demo video](https://www.youtube.com/watch?v=j05gGT3xfCs).\n\n**Instance Override Propagation**\nAnother contribution from [@dusskapark](https://github.com/dusskapark)\nPropagate component instance overrides from a source instance to multiple target instances with a single command. This feature dramatically reduces repetitive design work when working with component instances that need similar customizations. Check out our [demo video](https://youtu.be/uvuT8LByroI).\n\n## Development Setup\n\nTo develop, update your mcp config to direct to your local directory.\n\n```json\n{\n  \"mcpServers\": {\n    \"TalkToFigma\": {\n      \"command\": \"bun\",\n      \"args\": [\"/path-to-repo/src/talk_to_figma_mcp/server.ts\"]\n    }\n  }\n}\n```\n\n## Manual Setup and Installation\n\n### MCP Server: Integration with Cursor\n\nAdd the server to your Cursor MCP configuration in `~/.cursor/mcp.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"TalkToFigma\": {\n      \"command\": \"bunx\",\n      \"args\": [\"cursor-talk-to-figma-mcp@latest\"]\n    }\n  }\n}\n```\n\n### WebSocket Server\n\nStart the WebSocket server:\n\n```bash\nbun socket\n```\n\n### Figma Plugin\n\n1. In Figma, go to Plugins > Development > New Plugin\n2. Choose \"Link existing plugin\"\n3. Select the `src/cursor_mcp_plugin/manifest.json` file\n4. The plugin should now be available in your Figma development plugins\n\n## Windows + WSL Guide\n\n1. Install bun via powershell\n\n```bash\npowershell -c \"irm bun.sh/install.ps1|iex\"\n```\n\n2. Uncomment the hostname `0.0.0.0` in `src/socket.ts`\n\n```typescript\n// uncomment this to allow connections in windows wsl\nhostname: \"0.0.0.0\",\n```\n\n3. Start the websocket\n\n```bash\nbun socket\n```\n\n## Usage\n\n1. Start the WebSocket server\n2. Install the MCP server in Cursor\n3. Open Figma and run the Cursor MCP Plugin\n4. Connect the plugin to the WebSocket server by joining a channel using `join_channel`\n5. Use Cursor to communicate with Figma using the MCP tools\n\n## MCP Tools\n\nThe MCP server provides the following tools for interacting with Figma:\n\n### Document & Selection\n\n- `get_document_info` - Get information about the current Figma document\n- `get_selection` - Get information about the current selection\n- `read_my_design` - Get detailed node information about the current selection without parameters\n- `get_node_info` - Get detailed information about a specific node\n- `get_nodes_info` - Get detailed information about multiple nodes by providing an array of node IDs\n- `set_focus` - Set focus on a specific node by selecting it and scrolling viewport to it\n- `set_selections` - Set selection to multiple nodes and scroll viewport to show them\n\n### Annotations\n\n- `get_annotations` - Get all annotations in the current document or specific node\n- `set_annotation` - Create or update an annotation with markdown support\n- `set_multiple_annotations` - Batch create/update multiple annotations efficiently\n- `scan_nodes_by_types` - Scan for nodes with specific types (useful for finding annotation targets)\n\n### Prototyping & Connections\n\n- `get_reactions` - Get all prototype reactions from nodes with visual highlight animation\n- `set_default_connector` - Set a copied FigJam connector as the default connector style for creating connections (must be set before creating connections)\n- `create_connections` - Create FigJam connector lines between nodes, based on prototype flows or custom mapping\n\n### Creating Elements\n\n- `create_rectangle` - Create a new rectangle with position, size, and optional name\n- `create_frame` - Create a new frame with position, size, and optional name\n- `create_text` - Create a new text node with customizable font properties\n\n### Modifying text content\n\n- `scan_text_nodes` - Scan text nodes with intelligent chunking for large designs\n- `set_text_content` - Set the text content of a single text node\n- `set_multiple_text_contents` - Batch update multiple text nodes efficiently\n\n### Auto Layout & Spacing\n\n- `set_layout_mode` - Set the layout mode and wrap behavior of a frame (NONE, HORIZONTAL, VERTICAL)\n- `set_padding` - Set padding values for an auto-layout frame (top, right, bottom, left)\n- `set_axis_align` - Set primary and counter axis alignment for auto-layout frames\n- `set_layout_sizing` - Set horizontal and vertical sizing modes for auto-layout frames (FIXED, HUG, FILL)\n- `set_item_spacing` - Set distance between children in an auto-layout frame\n\n### Styling\n\n- `set_fill_color` - Set the fill color of a node (RGBA)\n- `set_stroke_color` - Set the stroke color and weight of a node\n- `set_corner_radius` - Set the corner radius of a node with optional per-corner control\n\n### Layout & Organization\n\n- `move_node` - Move a node to a new position\n- `resize_node` - Resize a node with new dimensions\n- `delete_node` - Delete a node\n- `delete_multiple_nodes` - Delete multiple nodes at once efficiently\n- `clone_node` - Create a copy of an existing node with optional position offset\n\n### Components & Styles\n\n- `get_styles` - Get information about local styles\n- `get_local_components` - Get information about local components\n- `create_component_instance` - Create an instance of a component\n- `get_instance_overrides` - Extract override properties from a selected component instance\n- `set_instance_overrides` - Apply extracted overrides to target instances\n\n### Export & Advanced\n\n- `export_node_as_image` - Export a node as an image (PNG, JPG, SVG, or PDF) - limited support on image currently returning base64 as text\n\n### Connection Management\n\n- `join_channel` - Join a specific channel to communicate with Figma\n\n### MCP Prompts\n\nThe MCP server includes several helper prompts to guide you through complex design tasks:\n\n- `design_strategy` - Best practices for working with Figma designs\n- `read_design_strategy` - Best practices for reading Figma designs\n- `text_replacement_strategy` - Systematic approach for replacing text in Figma designs\n- `annotation_conversion_strategy` - Strategy for converting manual annotations to Figma's native annotations\n- `swap_overrides_instances` - Strategy for transferring overrides between component instances in Figma\n- `reaction_to_connector_strategy` - Strategy for converting Figma prototype reactions to connector lines using the output of 'get_reactions', and guiding the use 'create_connections' in sequence\n\n## Development\n\n### Building the Figma Plugin\n\n1. Navigate to the Figma plugin directory:\n\n   ```\n   cd src/cursor_mcp_plugin\n   ```\n\n2. Edit code.js and ui.html\n\n## Best Practices\n\nWhen working with the Figma MCP:\n\n1. Always join a channel before sending commands\n2. Get document overview using `get_document_info` first\n3. Check current selection with `get_selection` before modifications\n4. Use appropriate creation tools based on needs:\n   - `create_frame` for containers\n   - `create_rectangle` for basic shapes\n   - `create_text` for text elements\n5. Verify changes using `get_node_info`\n6. Use component instances when possible for consistency\n7. Handle errors appropriately as all commands can throw exceptions\n8. For large designs:\n   - Use chunking parameters in `scan_text_nodes`\n   - Monitor progress through WebSocket updates\n   - Implement appropriate error handling\n9. For text operations:\n   - Use batch operations when possible\n   - Consider structural relationships\n   - Verify changes with targeted exports\n10. For converting legacy annotations:\n    - Scan text nodes to identify numbered markers and descriptions\n    - Use `scan_nodes_by_types` to find UI elements that annotations refer to\n    - Match markers with their target elements using path, name, or proximity\n    - Categorize annotations appropriately with `get_annotations`\n    - Create native annotations with `set_multiple_annotations` in batches\n    - Verify all annotations are properly linked to their targets\n    - Delete legacy annotation nodes after successful conversion\n11. Visualize prototype noodles as FigJam connectors:\n\n- Use `get_reactions` to extract prototype flows,\n- set a default connector with `set_default_connector`,\n- and generate connector lines with `create_connections` for clear visual flow mapping.\n\n## License\n\nMIT\n",
      "stars_today": 16
    },
    {
      "id": 10744183,
      "name": "netdata",
      "full_name": "netdata/netdata",
      "description": "The fastest path to AI-powered full stack observability, even for lean teams.",
      "html_url": "https://github.com/netdata/netdata",
      "stars": 77331,
      "forks": 6299,
      "language": "C",
      "topics": [
        "ai",
        "alerting",
        "cncf",
        "data-visualization",
        "database",
        "devops",
        "docker",
        "grafana",
        "influxdb",
        "kubernetes",
        "linux",
        "machine-learning",
        "mcp",
        "mongodb",
        "monitoring",
        "mysql",
        "netdata",
        "observability",
        "postgresql",
        "prometheus"
      ],
      "created_at": "2013-06-17T18:39:10Z",
      "updated_at": "2026-01-14T00:34:41Z",
      "pushed_at": "2026-01-14T00:17:21Z",
      "open_issues": 241,
      "owner": {
        "login": "netdata",
        "avatar_url": "https://avatars.githubusercontent.com/u/43390781?v=4"
      },
      "readme": "<p align=\"center\">\n<a href=\"https://www.netdata.cloud#gh-light-mode-only\">\n  <img src=\"https://www.netdata.cloud/img/readme-images/netdata_readme_logo_light.png\" alt=\"Netdata\" width=\"300\"/>\n</a>\n<a href=\"https://www.netdata.cloud#gh-dark-mode-only\">\n  <img src=\"https://www.netdata.cloud/img/readme-images/netdata_readme_logo_dark.png\" alt=\"Netdata\" width=\"300\"/>\n</a>\n</p>\n<h3 align=\"center\">X-Ray Vision for your infrastructure!</h3>\n<h4 align=\"center\">Every Metric, Every Second. No BS.</h4>\n\n<br />\n<p align=\"center\">\n  <a href=\"https://github.com/netdata/netdata/\"><img src=\"https://img.shields.io/github/stars/netdata/netdata?style=social\" alt=\"GitHub Stars\"></a>\n  <br />\n  <a href=\"https://app.netdata.cloud/spaces/netdata-demo?utm_campaign=github_readme_demo_badge\"><img src=\"https://img.shields.io/badge/Live%20Demo-green\" alt=\"Live Demo\"></a>\n  <a href=\"https://github.com/netdata/netdata/releases/latest\"><img src=\"https://img.shields.io/github/release/netdata/netdata.svg\" alt=\"Latest release\"></a>\n  <a href=\"https://github.com/netdata/netdata-nightlies/releases/latest\"><img src=\"https://img.shields.io/github/release/netdata/netdata-nightlies.svg\" alt=\"Latest nightly build\"></a>\n  <br/>\n  <a href=\"https://community.netdata.cloud\"><img alt=\"Discourse topics\" src=\"https://img.shields.io/discourse/topics?server=https%3A%2F%2Fcommunity.netdata.cloud%2F&logo=discourse&label=discourse%20forum\"></a>\n  <a href=\"https://github.com/netdata/netdata/discussions\"><img alt=\"GitHub Discussions\" src=\"https://img.shields.io/github/discussions/netdata/netdata?logo=github&label=github%20discussions\"></a>\n  <br/>\n  <a href=\"https://bestpractices.coreinfrastructure.org/projects/2231\"><img src=\"https://bestpractices.coreinfrastructure.org/projects/2231/badge\" alt=\"CII Best Practices\"></a>\n  <a href=\"https://scan.coverity.com/projects/netdata-netdata?tab=overview\"><img alt=\"Coverity Scan\" src=\"https://img.shields.io/coverity/scan/netdata\"></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://registry.my-netdata.io/#menu_netdata_submenu_registry\"><img src=\"https://registry.my-netdata.io/api/v3/badge.svg?chart=netdata.registry_entries&dimensions=persons&label=user%20base&units=M&value_color=blue&precision=2&divide=1000000&options=unaligned&tier=1&v44\" alt=\"User base\"></a>\n  <a href=\"https://registry.my-netdata.io/#menu_netdata_submenu_registry\"><img src=\"https://registry.my-netdata.io/api/v3/badge.svg?chart=netdata.registry_entries&dimensions=machines&label=servers%20monitored&units=M&divide=1000000&value_color=orange&precision=2&options=unaligned&tier=1&v44\" alt=\"Servers monitored\"></a>\n  <a href=\"https://registry.my-netdata.io/#menu_netdata_submenu_registry\"><img src=\"https://registry.my-netdata.io/api/v3/badge.svg?chart=netdata.registry_sessions&label=sessions%20served&units=M&value_color=yellowgreen&precision=2&divide=1000000&options=unaligned&tier=1&v44\" alt=\"Sessions served\"></a>\n  <a href=\"https://hub.docker.com/r/netdata/netdata\"><img src=\"https://registry.my-netdata.io/api/v3/badge.svg?chart=dockerhub.pulls_sum&divide=1000000&precision=1&units=M&label=docker+hub+pulls&options=unaligned&tier=1&v44\" alt=\"Docker Hub pulls\"></a>\n</p>\n<p align=\"center\"><b>Visit our <a href=\"https://www.netdata.cloud\">Home Page</a></b></p>\n\n<hr class=\"solid\">\n\nMENU: **[WHO WE ARE](#who-we-are)** | **[KEY FEATURES](#key-features)** | **[GETTING STARTED](#getting-started)** | **[HOW IT WORKS](#how-it-works)** | **[FAQ](#faq)** | **[DOCS](#book-documentation)** | **[COMMUNITY](#tada-community)** | **[CONTRIBUTE](#pray-contribute)** | **[LICENSE](#scroll-license)**\n\n\n> [!WARNING]\n> People **get addicted to Netdata.**\n> Once you use it on your systems, *there's no going back.*\n\n[![Platforms](https://img.shields.io/badge/Platforms-Linux%20%7C%20macOS%20%7C%20FreeBSD%20%7C%20Windows-blue)]()\n\n---\n\n## WHO WE ARE\n\nNetdata is an open-source, real-time infrastructure monitoring platform. Monitor, detect, and act across your entire infrastructure.\n\n**Core Advantages:**\n\n* **Instant Insights** ‚Äì With Netdata you can access per-second metrics and visualizations.\n* **Zero Configuration** ‚Äì You can deploy immediately without complex setup.\n* **ML-Powered** ‚Äì You can detect anomalies, predict issues, and automate analysis.\n* **Efficient** ‚Äì You can monitor with minimal resource usage and maximum scalability.\n* **Secure & Distributed** ‚Äì You can keep your data local with no central collection needed.\n\nWith Netdata, you get real-time, per-second updates. Clear **insights at a glance**, no complexity.\n\n<details>\n  <summary><strong>All heroes have a great origin story. Click to discover ours.</strong></summary>\n  <br/>\n\nIn 2013, at the company where Costa Tsaousis was COO, a significant percentage of their cloud-based transactions failed silently, severely impacting business performance.\n\nCosta and his team tried every troubleshooting tool available at the time. None could identify the root cause. As Costa later wrote:\n\n‚Äú*I couldn‚Äôt believe that monitoring systems provide so few metrics and with such low resolution, scale so badly, and cost so much to run.*‚Äù\n\nFrustrated, he decided to build his own monitoring tool, starting from scratch.\n\nThat decision led to countless late nights and weekends. It also sparked a fundamental shift in how infrastructure monitoring and troubleshooting are approached, both in method and in cost.\n</details>\n\n### Most Energy-Efficient Monitoring Tool\n\n<p align=\"center\">\n<a href=\"https://www.ivanomalavolta.com/files/papers/ICSOC_2023.pdf#gh-dark-mode-only\">\n  <img src=\"https://github.com/netdata/netdata/assets/139226121/7118757a-38fb-48d7-b12a-53e709a8e8c0\" alt=\"Energy Efficiency\" width=\"800\"/>\n</a>\n<a href=\"https://www.ivanomalavolta.com/files/papers/ICSOC_2023.pdf#gh-light-mode-only\">\n  <img src=\"https://github.com/netdata/netdata/assets/139226121/4f64cbb6-05e4-48e3-b7c0-d1b79e37e219\" alt=\"Energy efficiency\" width=\"800\"/>\n</a>\n</p>\n\nAccording to the [University of Amsterdam study](https://www.ivanomalavolta.com/files/papers/ICSOC_2023.pdf), Netdata is the most energy-efficient tool for monitoring Docker-based systems. The study also shows Netdata excels in CPU usage, RAM usage, and execution time compared to other monitoring solutions.\n\n---\n\n## Key Features\n\n| Feature                    | Description                               | What Makes It Unique                                     |\n|----------------------------|-------------------------------------------|----------------------------------------------------------|\n| **Real-Time**              | Per-second data collection and processing | Works in a beat ‚Äì click and see results instantly        |\n| **Zero-Configuration**     | Automatic detection and discovery         | Auto-discovers everything on the nodes it runs           |\n| **ML-Powered**             | Unsupervised anomaly detection            | Trains multiple ML models per metric at the edge         |\n| **Long-Term Retention**    | High-performance storage                  | ~0.5 bytes per sample with tiered storage for archiving  |\n| **Advanced Visualization** | Rich, interactive dashboards              | Slice and dice data without query language               |\n| **Extreme Scalability**    | Native horizontal scaling                 | Parent-Child centralization with multi-million samples/s |\n| **Complete Visibility**    | From infrastructure to applications       | Simplifies operations and eliminates silos               |\n| **Edge-Based**             | Processing at your premises               | Distributes code instead of centralizing data            |\n\n> [!NOTE]  \n> Want to put Netdata to the test against Prometheus?\n> Explore the [full comparison](https://www.netdata.cloud/blog/netdata-vs-prometheus-2025/).\n\n---\n\n## Netdata Ecosystem\n\nThis three-part architecture enables you to scale from single nodes to complex multi-cloud environments:\n\n| Component         | Description                                                                                                                                                 | License                                         |\n|-------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------|\n| **Netdata Agent** | ‚Ä¢ Core monitoring engine<br>‚Ä¢ Handles collection, storage, ML, alerts, exports<br>‚Ä¢ Runs on servers, cloud, K8s, IoT<br>‚Ä¢ Zero production impact            | [GPL v3+](https://www.gnu.org/licenses/gpl-3.0) |\n| **Netdata Cloud** | ‚Ä¢ Enterprise features<br>‚Ä¢ User management, RBAC, horizontal scaling<br>‚Ä¢ Centralized alerts<br>‚Ä¢ Free community tier<br>‚Ä¢ No metric storage centralization |                                                 |\n| **Netdata UI**    | ‚Ä¢ Dashboards and visualizations<br>‚Ä¢ Free to use<br>‚Ä¢ Included in standard packages<br>‚Ä¢ Latest version via CDN                                             | [NCUL1](https://app.netdata.cloud/LICENSE.txt)  |\n\n## What You Can Monitor\n\nWith Netdata you can monitor all these components across platforms:\n\n|                                                                                                   Component |              Linux               | FreeBSD | macOS |                      Windows                      |\n|------------------------------------------------------------------------------------------------------------:|:--------------------------------:|:-------:|:-----:|:-------------------------------------------------:|\n|                             **System Resources**<small><br/>CPU, Memory and system shared resources</small> |               Full               |   Yes   |  Yes  |                        Yes                        |\n|                                **Storage**<small><br/>Disks, Mount points, Filesystems, RAID arrays</small> |               Full               |   Yes   |  Yes  |                        Yes                        |\n|                                 **Network**<small><br/>Network Interfaces, Protocols, Firewall, etc</small> |               Full               |   Yes   |  Yes  |                        Yes                        |\n|                        **Hardware & Sensors**<small><br/>Fans, Temperatures, Controllers, GPUs, etc</small> |               Full               |  Some   | Some  |                       Some                        |\n|                                       **O/S Services**<small><br/>Resources, Performance and Status</small> | Yes<small><br/>`systemd`</small> |    -    |   -   |                         -                         |\n|                                      **Processes**<small><br/>Resources, Performance, OOM, and more</small> |               Yes                |   Yes   |  Yes  |                        Yes                        |\n|                                                                             System and Application **Logs** | Yes<small><br/>`systemd`-journal |    -    |   -   | Yes<small><br/>`Windows Event Log`, `ETW`</small> |\n|                                 **Network Connections**<small><br/>Live TCP and UDP sockets per PID</small> |               Yes                |    -    |   -   |                         -                         |\n|                               **Containers**<small><br/>Docker/containerd, LXC/LXD, Kubernetes, etc</small> |               Yes                |    -    |   -   |                         -                         |\n|                                 **VMs** (from the host)<small><br/>KVM, qemu, libvirt, Proxmox, etc</small> | Yes<small><br/>`cgroups`</small> |    -    |   -   |         Yes<small><br/>`Hyper-V`</small>          |\n|                       **Synthetic Checks**<small><br/>Test APIs, TCP ports, Ping, Certificates, etc</small> |               Yes                |   Yes   |  Yes  |                        Yes                        |\n| **Packaged Applications**<small><br/>nginx, apache, postgres, redis, mongodb,<br/>and hundreds more</small> |               Yes                |   Yes   |  Yes  |                        Yes                        |\n|                              **Cloud Provider Infrastructure**<small><br/>AWS, GCP, Azure, and more</small> |               Yes                |   Yes   |  Yes  |                        Yes                        |\n|                       **Custom Applications**<small><br/>OpenMetrics, StatsD and soon OpenTelemetry</small> |               Yes                |   Yes   |  Yes  |                        Yes                        |\n\nOn Linux, you can continuously monitor all kernel features and hardware sensors for errors, including Intel/AMD/Nvidia GPUs, PCI AER, RAM EDAC, IPMI, S.M.A.R.T, Intel RAPL, NVMe, fans, power supplies, and voltage readings.\n\n---\n\n## Getting Started\n\nYou can install Netdata on all major operating systems. To begin:\n\n### 1. Install Netdata\n\nChoose your platform and follow the installation guide:\n\n* [Linux Installation](https://learn.netdata.cloud/docs/installing/one-line-installer-for-all-linux-systems)\n* [macOS](https://learn.netdata.cloud/docs/installing/macos)\n* [FreeBSD](https://learn.netdata.cloud/docs/installing/freebsd)\n* [Windows](https://learn.netdata.cloud/docs/netdata-agent/installation/windows)\n* [Docker Guide](/packaging/docker/README.md)\n* [Kubernetes Setup](https://learn.netdata.cloud/docs/installation/install-on-specific-environments/kubernetes)\n\n> [!NOTE]\n> You can access the Netdata UI at `http://localhost:19999` (or `http://NODE:19999` if remote).\n\n### 2. Configure Collectors\n\nNetdata auto-discovers most metrics, but you can manually configure some collectors:\n\n* [All collectors](https://learn.netdata.cloud/docs/data-collection/)\n* [SNMP monitoring](https://learn.netdata.cloud/docs/data-collection/monitor-anything/networking/snmp)\n\n### 3. Configure Alerts\n\nYou can use hundreds of built-in alerts and integrate with:\n\n`email`, `Slack`, `Telegram`, `PagerDuty`, `Discord`, `Microsoft Teams`, and more.\n\n> [!NOTE]  \n> Email alerts work by default if there's a configured MTA.\n\n### 4. Configure Parents\n\nYou can centralize dashboards, alerts, and storage with Netdata Parents:\n\n* [Streaming Reference](https://learn.netdata.cloud/docs/streaming/streaming-configuration-reference)\n\n> [!NOTE]  \n> You can use Netdata Parents for central dashboards, longer retention, and alert configuration.\n\n### 5. Connect to Netdata Cloud\n\n[Sign in to Netdata Cloud](https://app.netdata.cloud/sign-in) and connect your nodes for:\n\n* Access from anywhere\n* Horizontal scalability and multi-node dashboards\n* UI configuration for alerts and data collection\n* Role-based access control\n* Free tier available\n\n> [!NOTE]  \n> Netdata Cloud is optional. Your data stays in your infrastructure.\n\n## Live Demo Sites\n\n<p align=\"center\">\n  <b>See Netdata in action</b><br/>\n  <a href=\"https://frankfurt.netdata.rocks\"><b>FRANKFURT</b></a> |\n  <a href=\"https://newyork.netdata.rocks\"><b>NEWYORK</b></a> |\n  <a href=\"https://atlanta.netdata.rocks\"><b>ATLANTA</b></a> |\n  <a href=\"https://sanfrancisco.netdata.rocks\"><b>SANFRANCISCO</b></a> |\n  <a href=\"https://toronto.netdata.rocks\"><b>TORONTO</b></a> |\n  <a href=\"https://singapore.netdata.rocks\"><b>SINGAPORE</b></a> |\n  <a href=\"https://bangalore.netdata.rocks\"><b>BANGALORE</b></a>\n  <br/>\n  <i>These demo clusters run with default configuration and show real monitoring data.</i>\n  <br/>\n  <i>Choose the instance closest to you for the best performance.</i>\n</p>\n\n---\n\n## How It Works\n\nWith Netdata you can run a modular pipeline for metrics collection, processing, and visualization.\n\n```mermaid\nflowchart TB\n  A[Netdata Agent]:::mainNode\n  A1(Collect):::green --> A\n  A2(Store):::green --> A\n  A3(Learn):::green --> A\n  A4(Detect):::green --> A\n  A5(Check):::green --> A\n  A6(Stream):::green --> A\n  A7(Archive):::green --> A\n  A8(Query):::green --> A\n  A9(Score):::green --> A\n\n  classDef green fill:#bbf3bb,stroke:#333,stroke-width:1px,color:#000\n  classDef mainNode fill:#f0f0f0,stroke:#333,stroke-width:1px,color:#333\n```\n\nWith each Agent you can:\n\n1. **Collect** ‚Äì Gather metrics from systems, containers, apps, logs, APIs, and synthetic checks.\n2. **Store** ‚Äì Save metrics to a high-efficiency, tiered time-series database.\n3. **Learn** ‚Äì Train ML models per metric using recent behavior.\n4. **Detect** ‚Äì Identify anomalies using trained ML models.\n5. **Check** ‚Äì Evaluate metrics against pre-set or custom alert rules.\n6. **Stream** ‚Äì Send metrics to Netdata Parents in real time.\n7. **Archive** ‚Äì Export metrics to Prometheus, InfluxDB, OpenTSDB, Graphite, and others.\n8. **Query** ‚Äì Access metrics via an API for dashboards or third-party tools.\n9. **Score** ‚Äì Use a scoring engine to find patterns and correlations across metrics.\n\n> [!NOTE]  \n> Learn more: [Netdata's architecture](https://learn.netdata.cloud/docs/netdata-agent/#distributed-observability-pipeline)\n\n## Agent Capabilities\n\nWith the Netdata Agent, you can use these core capabilities out-of-the-box:\n\n| Capability                   | Description                                                                                                                                   |\n|------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------|\n| **Comprehensive Collection** | ‚Ä¢ 800+ integrations<br>‚Ä¢ Systems, containers, VMs, hardware sensors<br>‚Ä¢ OpenMetrics, StatsD, and logs<br>‚Ä¢ OpenTelemetry support coming soon |\n| **Performance & Precision**  | ‚Ä¢ Per-second collection<br>‚Ä¢ Real-time visualization with 1-second latency<br>‚Ä¢ High-resolution metrics                                       |\n| **Edge-Based ML**            | ‚Ä¢ ML models trained at the edge<br>‚Ä¢ Automatic anomaly detection per metric<br>‚Ä¢ Pattern recognition based on historical behavior             |\n| **Advanced Log Management**  | ‚Ä¢ Direct systemd-journald and Windows Event Log integration<br>‚Ä¢ Process logs at the edge<br>‚Ä¢ Rich log visualization                         |\n| **Observability Pipeline**   | ‚Ä¢ Parent-Child relationships<br>‚Ä¢ Flexible centralization<br>‚Ä¢ Multi-level replication and retention                                          |\n| **Automated Visualization**  | ‚Ä¢ NIDL data model<br>‚Ä¢ Auto-generated dashboards<br>‚Ä¢ No query language needed                                                                |\n| **Smart Alerting**           | ‚Ä¢ Pre-configured alerts<br>‚Ä¢ Multiple notification methods<br>‚Ä¢ Proactive detection                                                           |\n| **Low Maintenance**          | ‚Ä¢ Auto-detection<br>‚Ä¢ Zero-touch ML<br>‚Ä¢ Easy scalability<br>‚Ä¢ CI/CD friendly                                                                 |\n| **Open & Extensible**        | ‚Ä¢ Modular architecture<br>‚Ä¢ Easy to customize<br>‚Ä¢ Integrates with existing tools                                                             |\n\n---\n\n## CNCF Membership\n\n<p align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/cncf/artwork/master/other/cncf/horizontal/white/cncf-white.svg\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://raw.githubusercontent.com/cncf/artwork/master/other/cncf/horizontal/color/cncf-color.svg\">\n    <img alt=\"CNCF Logo\" src=\"https://raw.githubusercontent.com/cncf/artwork/master/other/cncf/horizontal/color/cncf-color.svg\" width=\"300\">\n  </picture>\n  <br />\n  Netdata actively supports and is a member of the Cloud Native Computing Foundation (CNCF).<br />\n  It is one of the most starred projects in the <a href=\"https://landscape.cncf.io/?item=observability-and-analysis--observability--netdata\">CNCF landscape</a>.\n</p>\n\n---\n\n## FAQ\n\n<details>\n<summary><strong>Is Netdata secure?</strong></summary>\n<br/>\n\nYes. Netdata follows [OpenSSF best practices](https://bestpractices.coreinfrastructure.org/en/projects/2231), has a security-first design, and is regularly audited by the community.\n\n* [Security design](https://learn.netdata.cloud/docs/security-and-privacy-design)\n* [Security policies and advisories](https://github.com/netdata/netdata/security)\n\n</details>\n\n<details>\n<summary><strong>Does Netdata use a lot of resources?</strong></summary>\n<br/>\n\nNo. Even with ML and per-second metrics, Netdata uses minimal resources.\n\n* \\~5% CPU and 150MiB RAM by default on production systems\n* <1% CPU and \\~100MiB RAM when ML and alerts are disabled and using ephemeral storage\n* Parents scale to millions of metrics per second with appropriate hardware\n\n> You can use the **Netdata Monitoring** section in the dashboard to inspect its resource usage.\n\n</details>\n\n<details>\n<summary><strong>How much data retention is possible?</strong></summary>\n<br/>\n\nAs much as your disk allows.\n\nWith Netdata you can use tiered retention:\n\n* Tier 0: per-second resolution\n* Tier 1: per-minute resolution\n* Tier 2: per-hour resolution\n\nThese are queried automatically based on the zoom level.\n</details>\n\n<details>\n<summary><strong>Can Netdata scale to many servers?</strong></summary>\n<br/>\n\nYes. With Netdata you can:\n\n* Scale horizontally with many Agents\n* Scale vertically with powerful Parents\n* Scale infinitely via Netdata Cloud\n\n> You can use Netdata Cloud to merge many independent infrastructures into one logical view.\n\n</details>\n\n<details>\n<summary><strong>Is disk I/O a concern?</strong></summary>\n<br/>\n\nNo. Netdata minimizes disk usage:\n\n* Metrics are flushed to disk every 17 minutes, spread out evenly\n* Uses direct I/O and compression (ZSTD)\n* Can run entirely in RAM or stream to a Parent\n\n> You can use `alloc` or `ram` mode for no disk writes.\n\n</details>\n\n<details>\n<summary><strong>How is Netdata different from Prometheus + Grafana?</strong></summary>\n<br/>\n\nWith Netdata you get a complete monitoring solution‚Äînot just tools.\n\n* No manual setup or dashboards needed\n* Built-in ML, alerts, dashboards, and correlations\n* More efficient and easier to deploy\n\n> [Performance comparison](https://blog.netdata.cloud/netdata-vs-prometheus-performance-analysis/)\n\n</details>\n\n<details>\n<summary><strong>How is Netdata different from commercial SaaS tools?</strong></summary>\n<br/>\n\nWith Netdata you can store all metrics on your infrastructure‚Äîno sampling, no aggregation, no loss.\n\n* High-resolution metrics by default\n* ML per metric, not shared models\n* Unlimited scalability without skyrocketing cost\n\n</details>\n\n<details>\n<summary><strong>Can Netdata run alongside Nagios, Zabbix, etc.?</strong></summary>\n<br/>\n\nYes. You can use Netdata together with traditional tools.\n\nWith Netdata you get:\n\n* Real-time, high-resolution monitoring\n* Zero configuration and auto-generated dashboards\n* Anomaly detection and advanced visualization\n\n</details>\n\n<details>\n<summary><strong>What if I feel overwhelmed?</strong></summary>\n<br/>\n\nYou can start small:\n\n* Use the dashboard's table of contents and search\n* Explore anomaly scoring (\"AR\" toggle)\n* Create custom dashboards in Netdata Cloud\n\n> [Docs and guides](https://learn.netdata.cloud/guides)\n\n</details>\n\n<details>\n<summary><strong>Do I have to use Netdata Cloud?</strong></summary>\n<br/>\n\nNo. Netdata Cloud is optional.\n\nNetdata works without it, but with Cloud you can:\n\n* Access remotely with SSO\n* Save dashboard customizations\n* Configure alerts centrally\n* Collaborate with role-based access\n\n</details>\n\n<details>\n<summary><strong>What telemetry does Netdata collect?</strong></summary>\n<br/>\n\nAnonymous telemetry helps improve the product. You can disable it:\n\n* Add `--disable-telemetry` to the installer, or\n* Create `/etc/netdata/.opt-out-from-anonymous-statistics` and restart Netdata\n\n> Telemetry helps us understand usage, not track users. No private data is collected.\n\n</details>\n\n<details>\n<summary><strong>Who uses Netdata?</strong></summary>\n<br/>\n\nYou'll join users including:\n\n* Major companies (Amazon, ABN AMRO Bank, Facebook, Google, IBM, Intel, Netflix, Samsung)\n* Universities (NYU, Columbia, Seoul National, UCL)\n* Government organizations worldwide\n* Infrastructure-intensive organizations\n* Technology operators\n* Startups and freelancers\n* SysAdmins and DevOps professionals\n\n</details>\n\n---\n\n## \\:book: Documentation\n\nVisit [Netdata Learn](https://learn.netdata.cloud) for full documentation and guides.\n\n> [!NOTE]  \n> Includes deployment, configuration, alerting, exporting, troubleshooting, and more.\n\n---\n\n## \\:tada: Community\n\nJoin the Netdata community:\n\n* [Discord](https://discord.com/invite/2mEmfW735j)\n* [Forum](https://community.netdata.cloud)\n* [GitHub Discussions](https://github.com/netdata/netdata/discussions)\n\n> [!NOTE]  \n> [Code of Conduct](https://github.com/netdata/.github/blob/main/CODE_OF_CONDUCT.md)\n\nFollow us on:\n[Twitter](https://twitter.com/netdatahq) | [Reddit](https://www.reddit.com/r/netdata/) | [YouTube](https://www.youtube.com/c/Netdata) | [LinkedIn](https://www.linkedin.com/company/netdata-cloud/)\n\n---\n\n## \\:pray: Contribute\n\nWe welcome your contributions.\n\nWays you help us stay sharp:\n\n* Share best practices and monitoring insights\n* Report issues or missing features\n* Improve documentation\n* Develop new integrations or collectors\n* Help users in forums and chats\n\n> [!NOTE]  \n> [Contribution guide](https://github.com/netdata/.github/blob/main/CONTRIBUTING.md)\n\n---\n\n## \\:scroll: License\n\nThe Netdata ecosystem includes:\n\n* **Netdata Agent** ‚Äì Open-source core (GPLv3+). **Includes** data collection, storage, ML, alerting, APIs and **redistributes** several other open-source tools and libraries.\n    * [Netdata Agent License](https://github.com/netdata/netdata/blob/master/LICENSE)\n    * [Netdata Agent Redistributed](https://github.com/netdata/netdata/blob/master/REDISTRIBUTED.md)\n* **Netdata UI** ‚Äì Closed-source but free to use with Netdata Agent and Cloud. Delivered via CDN. It integrates third-party open-source components.\n    * [Netdata Cloud UI License](https://app.netdata.cloud/LICENSE.txt)\n    * [Netdata UI third-party licenses](https://app.netdata.cloud/3D_PARTY_LICENSES.txt)\n* **Netdata Cloud** ‚Äì Closed-source, with free and paid tiers. Adds remote access, SSO, scalability.\n",
      "stars_today": 15
    },
    {
      "id": 167596393,
      "name": "k9s",
      "full_name": "derailed/k9s",
      "description": "üê∂ Kubernetes CLI To Manage Your Clusters In Style!",
      "html_url": "https://github.com/derailed/k9s",
      "stars": 32449,
      "forks": 2048,
      "language": "Go",
      "topics": [
        "go",
        "golang",
        "k8s",
        "k8s-cluster",
        "k9s",
        "kubernetes",
        "kubernetes-cli",
        "kubernetes-clusters"
      ],
      "created_at": "2019-01-25T18:46:02Z",
      "updated_at": "2026-01-14T00:21:36Z",
      "pushed_at": "2026-01-13T03:18:35Z",
      "open_issues": 277,
      "owner": {
        "login": "derailed",
        "avatar_url": "https://avatars.githubusercontent.com/u/4060?v=4"
      },
      "readme": "<img src=\"assets/k9s.png\" alt=\"k9s\">\n\n## K9s - Kubernetes CLI To Manage Your Clusters In Style!\n\nK9s provides a terminal UI to interact with your Kubernetes clusters.\nThe aim of this project is to make it easier to navigate, observe and manage\nyour applications in the wild. K9s continually watches Kubernetes\nfor changes and offers subsequent commands to interact with your observed resources.\n\n---\n\n## Note...\n\nK9s is not pimped out by a big corporation with deep pockets.\nIt is a complex OSS project that demands a lot of my time to maintain and support.\nK9s will always remain OSS and therefore free! That said, if you feel k9s makes your day to day Kubernetes journey a tad brighter, saves you time and makes you more productive, please consider [sponsoring us!](https://github.com/sponsors/derailed)\nYour donations will go a long way in keeping our servers lights on and beers in our fridge!\n\n**Thank you!**\n\n---\n\n[![Go Report Card](https://goreportcard.com/badge/github.com/derailed/k9s?)](https://goreportcard.com/report/github.com/derailed/k9s)\n[![golangci badge](https://github.com/golangci/golangci-web/blob/master/src/assets/images/badge_a_plus_flat.svg)](https://golangci.com/r/github.com/derailed/k9s)\n[![Docker Pulls](https://img.shields.io/docker/pulls/derailed/k9s.svg?maxAge=604800)](https://hub.docker.com/r/derailed/k9s/)\n[![release](https://img.shields.io/github/release-pre/derailed/k9s.svg)](https://github.com/derailed/k9s/releases)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://github.com/mum4k/termdash/blob/master/LICENSE)\n[![Releases](https://img.shields.io/github/downloads/derailed/k9s/total.svg)](https://github.com/derailed/k9s/releases)\n\n---\n\n## Screenshots\n\n1. Pods\n      <img src=\"assets/screen_po.png\"/>\n2. Logs\n      <img src=\"assets/screen_logs.png\"/>\n3. Deployments\n      <img src=\"assets/screen_dp.png\"/>\n\n---\n\n## Demo Videos/Recordings\n\n* [K9s v0.40.0 -Column Blow- Sneak peek](https://youtu.be/iy6RDozAM4A)\n* [K9s v0.31.0 Configs+Sneak peek](https://youtu.be/X3444KfjguE)\n* [K9s v0.30.0 Sneak peek](https://youtu.be/mVBc1XneRJ4)\n* [Vulnerability Scans](https://youtu.be/ULkl0MsaidU)\n* [K9s v0.29.0](https://youtu.be/oiU3wmoAkBo)\n* [K9s v0.21.3](https://youtu.be/wG8KCwDAhnw)\n* [K9s v0.19.X](https://youtu.be/kj-WverKZ24)\n* [K9s v0.18.0](https://www.youtube.com/watch?v=zMnD5e53yRw)\n* [K9s v0.17.0](https://www.youtube.com/watch?v=7S33CNLAofk&feature=youtu.be)\n* [K9s Pulses](https://asciinema.org/a/UbXKPal6IWpTaVAjBBFmizcGN)\n* [K9s v0.15.1](https://youtu.be/7Fx4XQ2ftpM)\n* [K9s v0.13.0](https://www.youtube.com/watch?v=qaeR2iK7U0o&t=15s)\n* [K9s v0.9.0](https://www.youtube.com/watch?v=bxKfqumjW4I)\n* [K9s v0.7.0 Features](https://youtu.be/83jYehwlql8)\n* [K9s v0 Demo](https://youtu.be/k7zseUhaXeU)\n\n---\n\n## Documentation\n\nPlease refer to our [K9s documentation](https://k9scli.io) site for installation, usage, customization and tips.\n\n---\n\n## Slack Channel\n\nWanna discuss K9s features with your fellow `K9sers` or simply show your support for this tool?\n\n* Channel: [K9sersSlack](https://k9sers.slack.com/)\n* Invite: [K9slackers Invite](https://join.slack.com/t/k9sers/shared_invite/zt-3360a389v-ElLHrb0Dp1kAXqYUItSAFA)\n\n---\n\n## Installation\n\nK9s is available on Linux, macOS and Windows platforms.\nBinaries for Linux, Windows and Mac are available as tarballs in the [release page](https://github.com/derailed/k9s/releases).\n\n* Via [Homebrew](https://brew.sh/) for macOS or Linux\n\n   ```shell\n   brew install derailed/k9s/k9s\n   ```\n\n* Via [MacPorts](https://www.macports.org)\n\n   ```shell\n   sudo port install k9s\n   ```\n\n* Via [snap](https://snapcraft.io/k9s) for Linux\n\n  ```shell\n  snap install k9s --devmode\n  ```\n\n* On Arch Linux\n\n  ```shell\n  pacman -S k9s\n  ```\n\n* On OpenSUSE Linux distribution\n\n  ```shell\n  zypper install k9s\n  ```\n\n* On FreeBSD\n\n  ```shell\n  pkg install k9s\n  ```\n\n* On Ubuntu\n\n  ```shell\n  wget https://github.com/derailed/k9s/releases/latest/download/k9s_linux_amd64.deb && apt install ./k9s_linux_amd64.deb && rm k9s_linux_amd64.deb\n  ```\n\n* On Fedora (42+)\n\n  ```shell\n  dnf install k9s\n  ```\n\n* Via [Winget](https://github.com/microsoft/winget-cli) for Windows\n\n  ```shell\n  winget install k9s\n  ```\n\n* Via [Scoop](https://scoop.sh) for Windows\n\n  ```shell\n  scoop install k9s\n  ```\n\n* Via [Chocolatey](https://chocolatey.org/packages/k9s) for Windows\n\n  ```shell\n  choco install k9s\n  ```\n\n* Via a GO install\n\n  ```shell\n  # NOTE: The dev version will be in effect!\n  go install github.com/derailed/k9s@latest\n  ```\n\n* Via [Webi](https://webinstall.dev) for Linux and macOS\n\n  ```shell\n  curl -sS https://webinstall.dev/k9s | bash\n  ```\n\n* Via [pkgx](https://pkgx.dev/pkgs/k9scli.io/) for Linux and macOS\n\n  ```shell\n  pkgx k9s\n  ```\n\n* Via [gah](https://github.com/marverix/gah) for Linux and macOS\n\n  ```shell\n  gah install k9s\n  ```\n\n* Via [Webi](https://webinstall.dev) for Windows\n\n  ```shell\n  curl.exe -A MS https://webinstall.dev/k9s | powershell\n  ```\n\n* As a [Docker Desktop Extension](https://docs.docker.com/desktop/extensions/) (for the Docker Desktop built in Kubernetes Server)\n\n  ```shell\n  docker extension install spurin/k9s-dd-extension:latest\n  ```\n\n---\n\n## Building From Source\n\n K9s is currently using GO v1.23.X or above.\n In order to build K9s from source you must:\n\n 1. Clone the repo\n 2. Build and run the executable\n\n      ```shell\n      make build && ./execs/k9s\n      ```\n\n---\n\n## Running with Docker\n\n### Running the official Docker image\n\n  You can run k9s as a Docker container by mounting your `KUBECONFIG`:\n\n  ```shell\n  docker run --rm -it -v $KUBECONFIG:/root/.kube/config derailed/k9s\n  ```\n\n  For default path it would be:\n\n  ```shell\n  docker run --rm -it -v ~/.kube/config:/root/.kube/config derailed/k9s\n  ```\n\n### Building your own Docker image\n\n  You can build your own Docker image of k9s from the [Dockerfile](Dockerfile) with the following:\n\n  ```shell\n  docker build -t k9s-docker:v0.0.1 .\n  ```\n\n  You can get the latest stable `kubectl` version and pass it to the `docker build` command with the `--build-arg` option.\n  You can use the `--build-arg` option to pass any valid `kubectl` version (like `v1.18.0` or `v1.19.1`).\n\n  ```shell\n  KUBECTL_VERSION=$(make kubectl-stable-version 2>/dev/null)\n  docker build --build-arg KUBECTL_VERSION=${KUBECTL_VERSION} -t k9s-docker:0.1 .\n  ```\n\n  Run your container:\n\n  ```shell\n  docker run --rm -it -v ~/.kube/config:/root/.kube/config k9s-docker:0.1\n  ```\n\n---\n\n## PreFlight Checks\n\n* K9s uses 256 colors terminal mode. On `Nix system make sure TERM is set accordingly.\n\n    ```shell\n    export TERM=xterm-256color\n    ```\n\n* In order to issue resource edit commands make sure your EDITOR and KUBE_EDITOR env vars are set.\n\n    ```shell\n    # Kubectl edit command will use this env var.\n    export KUBE_EDITOR=my_fav_editor\n    ```\n\n* K9s prefers recent kubernetes versions ie 1.28+\n\n---\n\n## K8S Compatibility Matrix\n\n|         k9s        | k8s client |\n| ------------------ | ---------- |\n|     >= v0.27.0     |   1.26.1   |\n| v0.26.7 - v0.26.6  |   1.25.3   |\n| v0.26.5 - v0.26.4  |   1.25.1   |\n| v0.26.3 - v0.26.1  |   1.24.3   |\n| v0.26.0 - v0.25.19 |   1.24.2   |\n| v0.25.18 - v0.25.3 |   1.22.3   |\n| v0.25.2 - v0.25.0  |   1.22.0   |\n|      <= v0.24      |   1.21.3   |\n\n---\n\n## The Command Line\n\n```shell\n# List current version\nk9s version\n\n# To get info about K9s runtime (logs, configs, etc..)\nk9s info\n\n# List all available CLI options\nk9s help\n\n# To run K9s in a given namespace\nk9s -n mycoolns\n\n# Start K9s in an existing KubeConfig context\nk9s --context coolCtx\n\n# Start K9s in readonly mode - with all cluster modification commands disabled\nk9s --readonly\n```\n\n## Logs And Debug Logs\n\nGiven the nature of the ui k9s does produce logs to a specific location.\nTo view the logs and turn on debug mode, use the following commands:\n\n```shell\n# Find out where the logs are stored\nk9s info\n```\n\n```text\n ____  __.________\n|    |/ _/   __   \\______\n|      < \\____    /  ___/\n|    |  \\   /    /\\___ \\\n|____|__ \\ /____//____  >\n        \\/            \\/\n\nVersion:           vX.Y.Z\nConfig:            /Users/fernand/.config/k9s/config.yaml\nLogs:              /Users/fernand/.local/state/k9s/k9s.log\nDumps dir:         /Users/fernand/.local/state/k9s/screen-dumps\nBenchmarks dir:    /Users/fernand/.local/state/k9s/benchmarks\nSkins dir:         /Users/fernand/.local/share/k9s/skins\nContexts dir:      /Users/fernand/.local/share/k9s/clusters\nCustom views file: /Users/fernand/.local/share/k9s/views.yaml\nPlugins file:      /Users/fernand/.local/share/k9s/plugins.yaml\nHotkeys file:      /Users/fernand/.local/share/k9s/hotkeys.yaml\nAlias file:        /Users/fernand/.local/share/k9s/aliases.yaml\n```\n\n### View K9s logs\n\n```shell\ntail -f /Users/fernand/.local/data/k9s/k9s.log\n```\n\n### Start K9s in debug mode\n\n```shell\nk9s -l debug\n```\n\n### Customize logs destination\n\nYou can override the default log file destination either with the `--logFile` argument:\n\n```shell\nk9s --logFile /tmp/k9s.log\nless /tmp/k9s.log\n```\n\nOr through the `K9S_LOGS_DIR` environment variable:\n\n```shell\nK9S_LOGS_DIR=/var/log k9s\nless /var/log/k9s.log\n```\n\n## Key Bindings\n\nK9s uses aliases to navigate most K8s resources.\n\n| Action                                                                          | Command                       | Comment                                                                |\n|---------------------------------------------------------------------------------|-------------------------------|------------------------------------------------------------------------|\n| Show active keyboard mnemonics and help                                         | `?`                           |                                                                        |\n| Show all available resource alias                                               | `ctrl-a`                      |                                                                        |\n| To bail out of K9s                                                              | `:quit`, `:q`, `ctrl-c`       |                                                                        |\n| To go up/back to the previous view                                              | `esc`                         | If you have crumbs on, this will go to the previous one                |\n| View a Kubernetes resource using singular/plural or short-name                  | `:`pod‚èé                       | accepts singular, plural, short-name or alias ie pod or pods           |\n| View a Kubernetes resource in a given namespace                                 | `:`pod ns-x‚èé                  |                                                                        |\n| View filtered pods (New v0.30.0!)                                               | `:`pod /fred‚èé                 | View all pods filtered by fred                                         |\n| View labeled pods (New v0.30.0!)                                                | `:`pod app=fred,env=dev‚èé      | View all pods with labels matching app=fred and env=dev                |\n| View pods in a given context (New v0.30.0!)                                     | `:`pod @ctx1‚èé                 | View all pods in context ctx1. Switches out your current k9s context!  |\n| Filter out a resource view given a filter                                       | `/`filter‚èé                    | Regex2 supported ie `fred|blee` to filter resources named fred or blee |\n| Inverse regex filter                                                            | `/`! filter‚èé                  | Keep everything that *doesn't* match.                                  |\n| Filter resource view by labels                                                  | `/`-l label-selector‚èé         |                                                                        |\n| Fuzzy find a resource given a filter                                            | `/`-f filter‚èé                 |                                                                        |\n| Bails out of view/command/filter mode                                           | `<esc>`                       |                                                                        |\n| Key mapping to describe, view, edit, view logs,...                              | `d`,`v`, `e`, `l`,...         |                                                                        |\n| To view and switch to another Kubernetes context (Pod view)                     | `:`ctx‚èé                       |                                                                        |\n| To view and switch directly to another Kubernetes context (Last used view)      | `:`ctx context-name‚èé          |                                                                        |\n| To view and switch to another Kubernetes namespace                              | `:`ns‚èé                        |                                                                        |\n| To switch back to the last active command (like how \"cd -\" works)               | `-`                           | Navigation that adds breadcrumbs to the bottom are not commands        |\n| To go back and forward through the command history                              | back: `[`, forward: `]`       | Same as above                                                          |\n| To view all saved resources                                                     | `:`screendump or sd‚èé          |                                                                        |\n| To delete a resource (TAB and ENTER to confirm)                                 | `ctrl-d`                      |                                                                        |\n| To kill a resource (no confirmation dialog, equivalent to kubectl delete --now) | `ctrl-k`                      |                                                                        |\n| Launch pulses view                                                              | `:`pulses or pu‚èé              |                                                                        |\n| Launch XRay view                                                                | `:`xray RESOURCE [NAMESPACE]‚èé | RESOURCE can be one of po, svc, dp, rs, sts, ds, NAMESPACE is optional |\n| Launch Popeye view                                                              | `:`popeye or pop‚èé             | See [popeye](#popeye)                                                  |\n\n---\n\n## K9s Configuration\n\n  K9s keeps its configurations as YAML files inside of a `k9s` directory and the location depends on your operating system. K9s leverages [XDG](https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html) to load its various configurations files. For information on the default locations for your OS please see [this link](https://github.com/adrg/xdg/blob/master/README.md). If you are still confused a quick `k9s info` will reveal where k9s is loading its configurations from. Alternatively, you can set `K9S_CONFIG_DIR` to tell K9s the directory location to pull its configurations from.\n\n  | Unix            | macOS                              | Windows               |\n  |-----------------|------------------------------------|-----------------------|\n  | `~/.config/k9s` | `~/Library/Application Support/k9s` | `%LOCALAPPDATA%\\k9s`  |\n\n  > NOTE: This is still in flux and will change while in pre-release stage!\n\nYou can now override the context portForward default address configuration by setting an env variable that can override all clusters portForward local address using `K9S_DEFAULT_PF_ADDRESS=a.b.c.d`\n\n  ```yaml\n  # $XDG_CONFIG_HOME/k9s/config.yaml\n  k9s:\n    # Enable periodic refresh of resource browser windows. Default false\n    liveViewAutoRefresh: false\n    # !!New!! v0.50.8...\n    # Extends the list of supported GPU vendors. The key is the vendor name, the value must correspond to k8s resource driver designation.\n    # Default known GPU vendors:\n    # nvidia: nvidia.com/gpu\n\t  # nvidia-shared: nvidia.com/gpu.shared\n\t  # amd: amd.com/gpu\n\t  # intel: gpu.intel.com/i915\n    gpuVendors:\n      bozo: bozo/gpu  # extends the gpu vendor and add \"bozo\"\n    # The path to screen dump. Default: '%temp_dir%/k9s-screens-%username%' (k9s info)\n    screenDumpDir: /tmp/dumps\n    # Represents ui poll intervals in seconds. Default 2.0 secs. Minimum value is 2.0 - values below will be capped to the minimum.\n    refreshRate: 2\n    # Overrides the default k8s api server requests timeout. Defaults 120s\n    apiServerTimeout: 15s\n    # Number of retries once the connection to the api-server is lost. Default 15.\n    maxConnRetry: 5\n    # Indicates whether modification commands like delete/kill/edit are disabled. Default is false\n    readOnly: false\n    # This setting allows users to specify the default view, but it is not set by default.\n    defaultView: \"\"\n    # Toggles whether k9s should exit when CTRL-C is pressed. When set to true, you will need to exit k9s via the :quit command. Default is false.\n    noExitOnCtrlC: false\n    #UI settings\n    ui:\n      # Enable mouse support. Default false\n      enableMouse: false\n      # Set to true to hide K9s header. Default false\n      headless: false\n      # Set to true to hide the K9S logo Default false\n      logoless: false\n      # Set to true to hide K9s crumbs. Default false\n      crumbsless: false\n      # Set to true to suppress the K9s splash screen on start. Default false. Note that for larger clusters or higher latency connections, there may be no resources visible initially until local caches have finished populating.\n      splashless: false\n      # Toggles icons display as not all terminal support these chars. Default: true\n      noIcons: false\n      # Toggles reactive UI. This option provide for watching on disk artifacts changes and update the UI live Defaults to false.\n      reactive: false\n      # By default all contexts will use the dracula skin unless explicitly overridden in the context config file.\n      skin: dracula # => assumes the file skins/dracula.yaml is present in the  $XDG_DATA_HOME/k9s/skins directory. Can be overriden with K9S_SKIN.\n      # Convert dark skins to light, or vice versa, preserving hue. Default: false\n      invert: false\n      # Allows to set certain views default fullscreen mode. (yaml, helm history, describe, value_extender, details, logs) Default false\n      defaultsToFullScreen: false\n      # Show full resource GVR (Group/Version/Resource) vs just R. Default: false.\n      useFullGVRTitle: false\n    # Toggles icons display as not all terminal support these chars.\n    noIcons: false\n    # Toggles whether k9s should check for the latest revision from the GitHub repository releases. Default is false.\n    skipLatestRevCheck: false\n    # When altering kubeconfig or using multiple kube configs, k9s will clean up clusters configurations that are no longer in use. Setting this flag to true will keep k9s from cleaning up inactive cluster configs. Defaults to false.\n    keepMissingClusters: false\n    # Logs configuration\n    logger:\n      # Defines the number of lines to return. Default 100\n      tail: 200\n      # Defines the total number of log lines to allow in the view. Default 1000\n      buffer: 500\n      # Represents how far to go back in the log timeline in seconds. Setting to -1 will tail logs. Default is -1.\n      sinceSeconds: 300 # => tail the last 5 mins.\n      # Toggles log line wrap. Default false\n      textWrap: false\n      # Autoscroll in logs will be disabled. Default is false.\n      disableAutoscroll: false\n      # Enable column locking when autoscroll is enabled. Default is false.\n      columnLock: false\n      # Toggles log line timestamp info. Default false\n      showTime: false\n    # Provide shell pod customization when nodeShell feature gate is enabled!\n    shellPod:\n      # The shell pod image to use.\n      image: killerAdmin\n      # The namespace to launch to shell pod into.\n      namespace: default\n      # The resource limit to set on the shell pod.\n      limits:\n        cpu: 100m\n        memory: 100Mi\n      # Enable TTY\n      tty: true\n      hostPathVolume:\n      - name: docker-socket\n        # Mount the Docker socket into the shell pod\n        mountPath: /var/run/docker.sock\n        # The path on the host to mount\n        hostPath: /var/run/docker.sock\n        readOnly: true\n  ```\n\n---\n\n## <a id=\"popeye\"></a>Popeye Configuration\n\nK9s has integration with [Popeye](https://popeyecli.io/), which is a Kubernetes cluster sanitizer.  Popeye itself uses a configuration called `spinach.yml`, but when integrating with K9s the cluster-specific file should be name `$XDG_CONFIG_HOME/share/k9s/clusters/clusterX/contextY/spinach.yml`.  This allows you to have a different spinach config per cluster.\n\n---\n\n## Node Shell\n\nBy enabling the nodeShell feature gate on a given cluster, K9s allows you to shell into your cluster nodes. Once enabled, you will have a new `s` for `shell` menu option while in node view. K9s will launch a pod on the selected node using a special k9s_shell pod. Furthermore, you can refine your shell pod by using a custom docker image preloaded with the shell tools you love. By default k9s uses a BusyBox image, but you can configure it as follows:\n\nAlternatively, you can now override the context configuration by setting an env variable that can override all clusters node shell gate using `K9S_FEATURE_GATE_NODE_SHELL=true|false`\n\n```yaml\n# $XDG_CONFIG_HOME/k9s/config.yaml\nk9s:\n  # You can also further tune the shell pod specification\n  shellPod:\n    image: cool_kid_admin:42\n    namespace: blee\n    limits:\n      cpu: 100m\n      memory: 100Mi\n```\n\nThen in your cluster configuration file...\n\n```yaml\n# $XDG_DATA_HOME/k9s/clusters/cluster-1/context-1\nk9s:\n  cluster: cluster-1\n  readOnly: false\n  namespace:\n    active: default\n    lockFavorites: false\n    favorites:\n    - kube-system\n    - default\n  view:\n    active: po\n  featureGates:\n    nodeShell: true # => Enable this feature gate to make nodeShell available on this cluster\n  portForwardAddress: localhost\n```\n\n### Customizing the Shell Pod\nYou can also customize the shell pod by adding a `hostPathVolume` to your shell pod. This allows you to mount a local directory or file into the shell pod. For example, if you want to mount the Docker socket into the shell pod, you can do so as follows:\n```yaml\nk9s:\n  shellPod:\n    hostPathVolume:\n    - name: docker-socket\n      # Mount the Docker socket into the shell pod\n      mountPath: /var/run/docker.sock\n      # The path on the host to mount\n      hostPath: /var/run/docker.sock\n      readOnly: true\n```\nThis will mount the Docker socket into the shell pod at `/var/run/docker.sock` and make it read-only. You can also mount any other directory or file in a similar way.\n\n---\n\n## Command Aliases\n\nIn K9s, you can define your very own command aliases (shortnames) to access your resources. In your `$HOME/.config/k9s` define a file called `aliases.yaml`.\nA K9s alias defines pairs of alias:gvr. A gvr (Group/Version/Resource) represents a fully qualified Kubernetes resource identifier. Here is an example of an alias file:\n\n```yaml\n#  $XDG_DATA_HOME/k9s/aliases.yaml\naliases:\n  pp: v1/pods\n  crb: rbac.authorization.k8s.io/v1/clusterrolebindings\n  # As of v0.30.0 you can also refer to another command alias...\n  fred: pod fred app=blee # => view pods in namespace fred with labels matching app=blee\n```\n\nUsing this aliases file, you can now type `:pp` or `:crb` or `:fred` to activate their respective commands.\n\n---\n\n## HotKey Support\n\nEntering the command mode and typing a resource name or alias, could be cumbersome for navigating thru often used resources.\nWe're introducing hotkeys that allow users to define their own key combination to activate their favorite resource views.\n\nAdditionally, you can define context specific hotkeys by add a context level configuration file in `$XDG_DATA_HOME/k9s/clusters/clusterX/contextY/hotkeys.yaml`\n\nIn order to surface hotkeys globally please follow these steps:\n\n1. Create a file named `$XDG_CONFIG_HOME/k9s/hotkeys.yaml`\n2. Add the following to your `hotkeys.yaml`. You can use resource name/short name to specify a command ie same as typing it while in command mode.\n\n      ```yaml\n      #  $XDG_CONFIG_HOME/k9s/hotkeys.yaml\n      hotKeys:\n        # Hitting Shift-0 navigates to your pod view\n        shift-0:\n          shortCut:    Shift-0\n          description: Viewing pods\n          command:     pods\n        # Hitting Shift-1 navigates to your deployments\n        shift-1:\n          shortCut:    Shift-1\n          description: View deployments\n          command:     dp\n        # Hitting Shift-2 navigates to your xray deployments\n        shift-2:\n          shortCut:    Shift-2\n          description: Xray Deployments\n          command:     xray deploy\n        # Hitting Shift-S view the resources in the namespace of your current selection\n        shift-s:\n          shortCut:    Shift-S\n          override:    true # => will override the default shortcut related action if set to true (default to false)\n          description: Namespaced resources\n          command:     \"$RESOURCE_NAME $NAMESPACE\"\n          keepHistory: true # whether you can return to the previous view\n      ```\n\n Not feeling so hot? Your custom hotkeys will be listed in the help view `?`.\n Also your hotkeys file will be automatically reloaded so you can readily use your hotkeys as you define them.\n\n You can choose any keyboard shortcuts that make sense to you, provided they are not part of the standard K9s shortcuts list.\n\n Similarly, referencing environment variables in hotkeys is also supported. The available environment variables can refer to the description in the [Plugins](#plugins) section.\n\n> NOTE: This feature/configuration might change in future releases!\n\n---\n\n## Port Forwarding over websockets\n\nK9s follows `kubectl` feature flag environment variables to enable/disable port-forwarding over websockets. (default enabled in >1.30)\nTo disable Websocket support, set `KUBECTL_PORT_FORWARD_WEBSOCKETS=false`\n\n---\n\n## FastForwards\n\nAs of v0.25.0, you can leverage the `FastForwards` feature to tell K9s how to default port-forwards. In situations where you are dealing with multiple containers or containers exposing multiple ports, it can be cumbersome to specify the desired port-forward from the dialog as in most cases, you already know which container/port tuple you desire. For these use cases, you can now annotate your manifests with the following annotations:\n\n@ `k9scli.io/auto-port-forwards`\n  activates one or more port-forwards directly bypassing the port-forward dialog all together.\n@ `k9scli.io/port-forwards`\n  pre-selects one or more port-forwards when launching the port-forward dialog.\n\nThe annotation value takes on the shape `container-name::[local-port:]container-port`\n\n> NOTE: for either cases above you can specify the container port by name or number in your annotation!\n\n### Example\n\n```yaml\n# Pod fred\napiVersion: v1\nkind: Pod\nmetadata:\n  name: fred\n  annotations:\n    k9scli.io/auto-port-forwards: zorg::5556        # => will default to container zorg port 5556 and local port 5566. No port-forward dialog will be shown.\n    # Or...\n    k9scli.io/port-forwards: bozo::9090:p1          # => launches the port-forward dialog selecting default port-forward on container bozo port named p1(8081)\n                                                    # mapping to local port 9090.\n    ...\nspec:\n  containers:\n  - name: zorg\n    ports:\n    - name: p1\n      containerPort: 5556\n    ...\n  - name: bozo\n    ports:\n    - name: p1\n      containerPort: 8081\n    - name: p2\n      containerPort: 5555\n    ...\n```\n\nThe annotation value must specify a container to forward to as well as a local port and container port. The container port may be specified as either a port number or port name. If the local port is omitted then the local port will default to the container port number. Here are a few examples:\n\n1. bozo::http      - creates a pf on container `bozo` with port name http. If http specifies port number 8080 then the local port will be 8080 as well.\n2. bozo::9090:http - creates a pf on container `bozo` mapping local port 9090->http(8080)\n3. bozo::9090:8080 - creates a pf on container `bozo` mapping local port 9090->8080\n\n---\n\n## Custom Views\n\n[SneakCast v0.17.0 on The Beach! - Yup! sound is sucking but what a setting!](https://youtu.be/7S33CNLAofk)\n\nYou can change which columns shows up for a given resource via custom views. To surface this feature, you will need to create a new configuration file, namely `$XDG_CONFIG_HOME/k9s/views.yaml`. This file leverages GVR (Group/Version/Resource) to configure the associated table view columns. If no GVR is found for a view the default rendering will take over (ie what we have now). Going wide will add all the remaining columns that are available on the given resource after your custom columns. To boot, you can edit your views config file and tune your resources views live!\n\nüì¢ üéâ As of `release v0.40.0` you can specify json parse expressions to further customize your resources rendering.\n\nThe new column syntax is as follows:\n\n> COLUMN_NAME<:json_parse_expression><|column_attributes>\n\nWhere `:json_parse_expression` represents an expression to pull a specific snippet out of the resource manifest.\nSimilar to `kubectl -o custom-columns` command. This expression is optional.\n\n> IMPORTANT! Columns must be valid YAML strings. Thus if your column definition contains non-alpha chars\n> they must figure with either single/double quotes or escaped via `\\`\n\n> NOTE! Be sure to watch k9s logs as any issues with the custom views specification are only surfaced in the logs.\n\nAdditionally, you can specify column attributes to further tailor the column rendering.\nTo use this you will need to add a `|` indicator followed by your rendering bits.\nYou can have one or more of the following attributes:\n\n* `T` -> time column indicator\n* `N` -> number column indicator\n* `W` -> turns on wide column aka only shows while in wide mode. Defaults to the standard resource definition when present.\n* `S` -> Ensures a column is visible and not wide. Overrides `wide` std resource definition if present.\n* `H` -> Hides the column\n* `L` -> Left align (default)\n* `R` -> Right align\n\nHere is a sample views configuration that customize a pods and services views.\n\n```yaml\n# $XDG_CONFIG_HOME/k9s/views.yaml\nviews:\n  v1/pods:\n    columns:\n      - AGE\n      - NAMESPACE|WR                                     # => üåö Specifies the NAMESPACE column to be right aligned and only visible while in wide mode\n      - ZORG:.metadata.labels.fred\\.io\\.kubernetes\\.blee # => üåö extract fred.io.kubernetes.blee label into it's own column\n      - BLEE:.metadata.annotations.blee|R                # => üåö extract annotation blee into it's own column and right align it\n      - NAME\n      - IP\n      - NODE\n      - STATUS\n      - READY\n      - MEM/RL|S                                         # => üåö Overrides std resource default wide attribute via `S` for `Show`\n      - '%MEM/R|'                                        # => NOTE! column names with non alpha names need to be quoted as columns must be strings!\n\n  v1/pods@fred:                                          # => üåö New v0.40.6! Customize columns for a given resource and namespace!\n    columns:\n      - AGE\n      - NAME|WR\n\n  v1/pods@kube*:                                         # => üåö New v0.40.6! You can also specify a namespace using a regular expression.\n    columns:\n      - NAME\n      - AGE\n      - LABELS\n\n  cool-kid:                                              # => üåö New v0.40.8! You can also reference a specific alias and display a custom view for it\n    columns:\n      - AGE\n      - NAMESPACE|WR\n\n  v1/services:\n    columns:\n      - AGE\n      - NAMESPACE\n      - NAME\n      - TYPE\n      - CLUSTER-IP\n```\n\n> ü©ª NOTE: This is experimental and will most likely change as we iron this out!\n\n---\n\n## Plugins\n\nK9s allows you to extend your command line and tooling by defining your very own cluster commands via plugins.\nMinimally we look at `$XDG_CONFIG_HOME/k9s/plugins.yaml` to locate all available plugins.\nAdditionally, K9s will scan the following directories for additional plugins:\n\n* `$XDG_CONFIG_HOME/k9s/plugins`\n* `$XDG_DATA_HOME/k9s/plugins`\n* `$XDG_DATA_DIRS/k9s/plugins`\n\nThe plugin file content can be either a single plugin snippet, a collections of snippets or a complete plugins definition (see examples below...).\n\nA plugin is defined as follows:\n\n* Shortcut option represents the key combination a user would type to activate the plugin. Valid values are [a-z], Shift-[A-Z], Ctrl-[A-Z].\n* Override option make that the default action related to the shortcut will be overridden by the plugin\n* Confirm option (when enabled) lets you see the command that is going to be executed and gives you an option to confirm or prevent execution\n* Description will be printed next to the shortcut in the k9s menu\n* Scopes defines a collection of resources names/short-names for the views associated with the plugin. You can specify `all` to provide this shortcut for all views.\n* Command represents ad-hoc commands the plugin runs upon activation\n* Background specifies whether or not the command runs in the background\n* Args specifies the various arguments that should apply to the command above\n* OverwriteOutput boolean option allows plugin developers to provide custom messages on plugin stdout execution. See example in [#2644](https://github.com/derailed/k9s/pull/2644)\n* Dangerous boolean option enables disabling the plugin when read-only mode is set. See [#2604](https://github.com/derailed/k9s/issues/2604)\n\nK9s does provide additional environment variables for you to customize your plugins arguments. Currently, the available environment variables are as follows:\n\n* `$RESOURCE_GROUP` -- the selected resource group\n* `$RESOURCE_VERSION` -- the selected resource api version\n* `$RESOURCE_NAME` -- the selected resource name\n* `$NAMESPACE` -- the selected resource namespace\n* `$NAME` -- the selected resource name\n* `$CONTAINER` -- the current container if applicable\n* `$FILTER` -- the current filter if any\n* `$KUBECONFIG` -- the KubeConfig location.\n* `$CLUSTER` the active cluster name\n* `$CONTEXT` the active context name\n* `$USER` the active user\n* `$GROUPS` the active groups\n* `$POD` while in a container view\n* `$COL-<RESOURCE_COLUMN_NAME>` use a given column name for a viewed resource. Must be prefixed by `COL-`!\n\nCurly braces can be used to embed an environment variable inside another string, or if the column name contains special characters. (e.g. `${NAME}-example` or `${COL-%CPU/L}`)\n\n### Plugin Examples\n\nDefine several plugins and host them in a single file. These can leave in the K9s root config so that they are available on any clusters. Additionally, you can define cluster/context specific plugins for your clusters of choice by adding clusterA/contextB/plugins.yaml file.\n\nThe following defines a plugin for viewing logs on a selected pod using `ctrl-l` as shortcut.\n\n```yaml\n# Define several plugins in a single file in the K9s root configuration\n# $XDG_DATA_HOME/k9s/plugins.yaml\nplugins:\n  # Defines a plugin to provide a `ctrl-l` shortcut to tail the logs while in pod view.\n  fred:\n    shortCut: Ctrl-L\n    override: false\n    overwriteOutput: false\n    confirm: false\n    dangerous: false\n    description: Pod logs\n    scopes:\n    - pods\n    command: kubectl\n    background: false\n    args:\n    - logs\n    - -f\n    - $NAME\n    - -n\n    - $NAMESPACE\n    - --context\n    - $CONTEXT\n```\n\nSimilarly you can define the plugin above in a directory using either a file per plugin or several plugins per files as follow...\n\nThe following defines two plugins namely fred and zorg.\n\n```yaml\n# Multiple plugins in a single file...\n# Note: as of v0.40.9 you can have ad-hoc plugin dirs\n# Loads plugins fred and zorg\n# $XDG_DATA_HOME/k9s/plugins/misc-plugins/blee.yaml\nfred:\n  shortCut: Shift-B\n  description: Bozo\n  scopes:\n  - deploy\n  command: bozo\n\nzorg:\n  shortCut: Shift-Z\n  description: Pod logs\n  scopes:\n  - svc\n  command: zorg\n```\n\nLastly you can define plugin snippets in their own file. The snippet will be named from the file name. In this case, we define a `bozo` plugin using a plugin snippet.\n\n```yaml\n# $XDG_DATA_HOME/k9s/plugins/schtuff/bozo.yaml\nshortCut: Shift-B\ndescription: Bozo\nscopes:\n- deploy\ncommand: bozo\n```\n\n> NOTE: This is an experimental feature! Options and layout may change in future K9s releases as this feature solidifies.\n\n---\n\n## Benchmark Your Applications\n\nK9s integrates [Hey](https://github.com/rakyll/hey) from the brilliant and super talented [Jaana Dogan](https://github.com/rakyll). `Hey` is a CLI tool to benchmark HTTP endpoints similar to AB bench. This preliminary feature currently supports benchmarking port-forwards and services (Read the paint on this is way fresh!).\n\nTo setup a port-forward, you will need to navigate to the PodView, select a pod and a container that exposes a given port. Using `SHIFT-F` a dialog comes up to allow you to specify a local port to forward. Once acknowledged, you can navigate to the PortForward view (alias `pf`) listing out your active port-forwards. Selecting a port-forward and using `CTRL-B` will run a benchmark on that HTTP endpoint. To view the results of your benchmark runs, go to the Benchmarks view (alias `be`). You should now be able to select a benchmark and view the run stats details by pressing `<ENTER>`. NOTE: Port-forwards only last for the duration of the K9s session and will be terminated upon exit.\n\nInitially, the benchmarks will run with the following defaults:\n\n* Concurrency Level: 1\n* Number of Requests: 200\n* HTTP Verb: GET\n* Path: /\n\nThe PortForward view is backed by a new K9s config file namely: `$XDG_DATA_HOME/k9s/clusters/clusterX/contextY/benchmarks.yaml`. Each cluster you connect to will have its own bench config file, containing the name of the K8s context for the cluster. Changes to this file should automatically update the PortForward view to indicate how you want to run your benchmarks.\n\nBenchmarks result reports are stored in `$XDG_STATE_HOME/k9s/clusters/clusterX/contextY`\n\nHere is a sample benchmarks.yaml configuration. Please keep in mind this file will likely change in subsequent releases!\n\n```yaml\n# This file resides in  $XDG_DATA_HOME/k9s/clusters/clusterX/contextY/benchmarks.yaml\nbenchmarks:\n  # Indicates the default concurrency and number of requests setting if a container or service rule does not match.\n  defaults:\n    # One concurrent connection\n    concurrency: 1\n    # Number of requests that will be sent to an endpoint\n    requests: 500\n  containers:\n    # Containers section allows you to configure your http container's endpoints and benchmarking settings.\n    # NOTE: the container ID syntax uses namespace/pod-name:container-name\n    default/nginx:nginx:\n      # Benchmark a container named nginx using POST HTTP verb using http://localhost:port/bozo URL and headers.\n      concurrency: 1\n      requests: 10000\n      http:\n        path: /bozo\n        method: POST\n        body:\n          {\"fred\":\"blee\"}\n        header:\n          Accept:\n            - text/html\n          Content-Type:\n            - application/json\n  services:\n    # Similarly you can Benchmark an HTTP service exposed either via NodePort, LoadBalancer types.\n    # Service ID is ns/svc-name\n    default/nginx:\n      # Set the concurrency level\n      concurrency: 5\n      # Number of requests to be sent\n      requests: 500\n      http:\n        method: GET\n        # This setting will depend on whether service is NodePort or LoadBalancer. NodePort may require vendor port tunneling setting.\n        # Set this to a node if NodePort or LB if applicable. IP or dns name.\n        host: A.B.C.D\n        path: /bumblebeetuna\n      auth:\n        user: jean-baptiste-emmanuel\n        password: Zorg!\n```\n\n---\n\n## K9s RBAC FU\n\nOn RBAC enabled clusters, you would need to give your users/groups capabilities so that they can use K9s to explore their Kubernetes cluster. K9s needs minimally read privileges at both the cluster and namespace level to display resources and metrics.\n\nThese rules below are just suggestions. You will need to customize them based on your environment policies. If you need to edit/delete resources extra Fu will be necessary.\n\n> NOTE! Cluster/Namespace access may change in the future as K9s evolves.\n> NOTE! We expect K9s to keep running even in atrophied clusters/namespaces. Please file issues if this is not the case!\n\n### Cluster RBAC scope\n\n```yaml\n---\n# K9s Reader ClusterRole\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: k9s\nrules:\n  # Grants RO access to cluster resources node and namespace\n  - apiGroups: [\"\"]\n    resources: [\"nodes\", \"namespaces\"]\n    verbs: [\"get\", \"list\", \"watch\"]\n  # Grants RO access to RBAC resources\n  - apiGroups: [\"rbac.authorization.k8s.io\"]\n    resources: [\"clusterroles\", \"roles\", \"clusterrolebindings\", \"rolebindings\"]\n    verbs: [\"get\", \"list\", \"watch\"]\n  # Grants RO access to CRD resources\n  - apiGroups: [\"apiextensions.k8s.io\"]\n    resources: [\"customresourcedefinitions\"]\n    verbs: [\"get\", \"list\", \"watch\"]\n  # Grants RO access to metric server (if present)\n  - apiGroups: [\"metrics.k8s.io\"]\n    resources: [\"nodes\", \"pods\"]\n    verbs: [\"get\", \"list\", \"watch\"]\n\n---\n# Sample K9s user ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: k9s\nsubjects:\n  - kind: User\n    name: fernand\n    apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: ClusterRole\n  name: k9s\n  apiGroup: rbac.authorization.k8s.io\n```\n\n### Namespace RBAC scope\n\nIf your users are constrained to certain namespaces, K9s will need to following role to enable read access to namespaced resources.\n\n```yaml\n---\n# K9s Reader Role (default namespace)\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: k9s\n  namespace: default\nrules:\n  # Grants RO access to most namespaced resources\n  - apiGroups: [\"\", \"apps\", \"autoscaling\", \"batch\", \"extensions\"]\n    resources: [\"*\"]\n    verbs: [\"get\", \"list\", \"watch\"]\n  # Grants RO access to metric server\n  - apiGroups: [\"metrics.k8s.io\"]\n    resources: [\"pods\", \"nodes\"]\n    verbs:\n      - get\n      - list\n      - watch\n\n---\n# Sample K9s user RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: k9s\n  namespace: default\nsubjects:\n  - kind: User\n    name: fernand\n    apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: k9s\n  apiGroup: rbac.authorization.k8s.io\n```\n\n---\n\n## Skins\n\nExample: Dracula Skin ;)\n\n<img src=\"assets/skins/dracula.png\" alt=\"Dracula Skin\">\n\nYou can style K9s based on your own sense of look and style. Skins are YAML files, that enable a user to change the K9s presentation layer. See this repo `skins` directory for examples.\nYou can skin k9s by default by specifying a UI.skin attribute. You can also change K9s skins based on the context you are connecting too.\nIn this case, you can specify a skin field on your cluster config aka `skin: dracula` (just the name of the skin file without the extension!) and copy this repo\n`skins/dracula.yaml` to `$XDG_CONFIG_HOME/k9s/skins/` directory. You can also change the skin by setting `K9S_SKIN` in the environment, e.g. `export K9S_SKIN=\"dracula\"`.\n\nIn the case where your cluster spans several contexts, you can add a skin context configuration to your context configuration.\nThis is a collection of {context_name, skin} tuples (please see example below!)\n\nColors can be defined by name or using a hex representation. Of recent, we've added a color named `default` to indicate a transparent background color to preserve your terminal background color settings if so desired.\n\n> NOTE: This is very much an experimental feature at this time, more will be added/modified if this feature has legs so thread accordingly!\n> NOTE: Please see [K9s Skins](https://k9scli.io/topics/skins/) for a list of available colors.\n\nTo skin a specific context and provided the file `in-the-navy.yaml` is present in your skins directory.\n\n```yaml\n#  $XDG_DATA_HOME/k9s/clusters/clusterX/contextY/config.yaml\nk9s:\n  cluster: clusterX\n  skin: in-the-navy\n  readOnly: false\n  namespace:\n    active: default\n    lockFavorites: false\n    favorites:\n    - kube-system\n    - default\n  view:\n    active: po\n  featureGates:\n    nodeShell: false\n  portForwardAddress: localhost\n```\n\nYou can also specify a default skin for all contexts in the root k9s config file as so:\n\n```yaml\n#  $XDG_CONFIG_HOME/k9s/config.yaml\nk9s:\n  liveViewAutoRefresh: false\n  screenDumpDir: /tmp/dumps\n  refreshRate: 2\n  maxConnRetry: 5\n  readOnly: false\n  noExitOnCtrlC: false\n  ui:\n    enableMouse: false\n    headless: false\n    logoless: false\n    crumbsless: false\n    splashless: false\n    noIcons: false\n    invert: false\n    # Toggles reactive UI. This option provide for watching on disk artifacts changes and update the UI live  Defaults to false.\n    reactive: false\n    # By default all contexts will use the dracula skin unless explicitly overridden in the context config file.\n    skin: dracula # => assumes the file skins/dracula.yaml is present in the  $XDG_DATA_HOME/k9s/skins directory\n    defaultsToFullScreen: false\n  skipLatestRevCheck: false\n  disablePodCounting: false\n  shellPod:\n    image: busybox\n    namespace: default\n    limits:\n      cpu: 100m\n      memory: 100Mi\n  imageScans:\n    enable: false\n    exclusions:\n      namespaces: []\n      labels: {}\n  logger:\n    tail: 100\n    buffer: 5000\n    sinceSeconds: -1\n    textWrap: false\n    disableAutoscroll: false\n    columnLock: false\n    showTime: false\n  thresholds:\n    cpu:\n      critical: 90\n      warn: 70\n    memory:\n      critical: 90\n      warn: 70\n```\n\n```yaml\n# $XDG_DATA_HOME/k9s/skins/in-the-navy.yaml\n# Skin InTheNavy!\nk9s:\n  # General K9s styles\n  body:\n    fgColor: dodgerblue\n    bgColor: '#ffffff'\n    logoColor: '#0000ff'\n  # ClusterInfoView styles.\n  info:\n    fgColor: lightskyblue\n    sectionColor: steelblue\n  # Help panel styles\n  help:\n    fgColor: white\n    bgColor: black\n    keyColor: cyan\n    numKeyColor: blue\n    sectionColor: gray\n  frame:\n    # Borders styles.\n    border:\n      fgColor: dodgerblue\n      focusColor: aliceblue\n    # MenuView attributes and styles.\n    menu:\n      fgColor: darkblue\n      # Style of menu text. Supported options are \"dim\" (default), \"normal\", and \"bold\"\n      fgStyle: dim\n      keyColor: cornflowerblue\n      # Used for favorite namespaces\n      numKeyColor: cadetblue\n    # CrumbView attributes for history navigation.\n    crumbs:\n      fgColor: white\n      bgColor: steelblue\n      activeColor: skyblue\n    # Resource status and update styles\n    status:\n      newColor: '#00ff00'\n      modifyColor: powderblue\n      addColor: lightskyblue\n      errorColor: indianred\n      highlightcolor: royalblue\n      killColor: slategray\n      completedColor: gray\n    # Border title styles.\n    title:\n      fgColor: aqua\n      bgColor: white\n      highlightColor: skyblue\n      counterColor: slateblue\n      filterColor: slategray\n  views:\n    # TableView attributes.\n    table:\n      fgColor: blue\n      bgColor: darkblue\n      cursorColor: aqua\n      # Header row styles.\n      header:\n        fgColor: white\n        bgColor: darkblue\n        sorterColor: orange\n    # YAML info styles.\n    yaml:\n      keyColor: steelblue\n      colonColor: blue\n      valueColor: royalblue\n    # Logs styles.\n    logs:\n      fgColor: lightskyblue\n      bgColor: black\n      indicator:\n        fgColor: dodgerblue\n        bgColor: black\n        toggleOnColor: limegreen\n        toggleOffColor: gray\n```\n\n---\n\n## Contributors\n\nWithout the contributions from these fine folks, this project would be a total dud!\n\n<a href=\"https://github.com/derailed/k9s/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=derailed/k9s\" />\n</a>\n\n---\n\n## Known Issues\n\nThis is still work in progress! If something is broken or there's a feature\nthat you want, please file an issue and if so inclined submit a PR!\n\nK9s will most likely blow up if...\n\n1. You're running older versions of Kubernetes. K9s works best on later Kubernetes versions.\n2. You don't have enough RBAC fu to manage your cluster.\n\n---\n\n## ATTA Girls/Boys!\n\nK9s sits on top of many open source projects and libraries. Our *sincere*\nappreciations to all the OSS contributors that work nights and weekends\nto make this project a reality!\n\n---\n\n## Meet The Core Team!\n\nIf you have chops in GO and K8s and would like to offer your time to help maintain and enhance this project, please reach out to me.\n\n* [Fernand Galiana](https://github.com/derailed)\n  * <img src=\"assets/mail.png\" width=\"16\" height=\"auto\" alt=\"email\"/>  fernand@imhotep.io\n  * <img src=\"assets/twitter.png\" width=\"16\" height=\"auto\" alt=\"twitter\"/> [@kitesurfer](https://twitter.com/kitesurfer?lang=en)\n\nWe always enjoy hearing from folks who benefit from our work!\n\n## Contributions Guideline\n\n* File an issue first prior to submitting a PR!\n* Ensure all exported items are properly commented\n* If applicable, submit a test suite against your PR\n\n---\n\n<img src=\"assets/imhotep_logo.png\" width=\"32\" height=\"auto\" alt=\"Imhotep\"/> &nbsp;¬© 2026 Imhotep Software LLC. All materials licensed under [Apache v2.0](http://www.apache.org/licenses/LICENSE-2.0)\n",
      "stars_today": 15
    },
    {
      "id": 875661263,
      "name": "VoiceInk",
      "full_name": "Beingpax/VoiceInk",
      "description": "Voice-to-text app for macOS to transcribe what you say to text almost instantly",
      "html_url": "https://github.com/Beingpax/VoiceInk",
      "stars": 3151,
      "forks": 385,
      "language": "Swift",
      "topics": [
        "macos",
        "macos-app",
        "swift"
      ],
      "created_at": "2024-10-20T15:11:17Z",
      "updated_at": "2026-01-14T00:43:07Z",
      "pushed_at": "2026-01-13T05:13:46Z",
      "open_issues": 172,
      "owner": {
        "login": "Beingpax",
        "avatar_url": "https://avatars.githubusercontent.com/u/101010368?v=4"
      },
      "readme": "<div align=\"center\">\n  <img src=\"VoiceInk/Assets.xcassets/AppIcon.appiconset/256-mac.png\" width=\"180\" height=\"180\" />\n  <h1>VoiceInk</h1>\n  <p>Voice to text app for macOS to transcribe what you say to text almost instantly</p>\n\n  [![License](https://img.shields.io/badge/License-GPL%20v3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)\n  ![Platform](https://img.shields.io/badge/platform-macOS%2014.0%2B-brightgreen)\n  [![GitHub release (latest by date)](https://img.shields.io/github/v/release/Beingpax/VoiceInk)](https://github.com/Beingpax/VoiceInk/releases)\n  ![GitHub all releases](https://img.shields.io/github/downloads/Beingpax/VoiceInk/total)\n  ![GitHub stars](https://img.shields.io/github/stars/Beingpax/VoiceInk?style=social)\n  <p>\n    <a href=\"https://tryvoiceink.com\">Website</a> ‚Ä¢\n    <a href=\"https://www.youtube.com/@tryvoiceink\">YouTube</a>\n  </p>\n\n  <a href=\"https://tryvoiceink.com\">\n    <img src=\"https://img.shields.io/badge/Download%20Now-Latest%20Version-blue?style=for-the-badge&logo=apple\" alt=\"Download VoiceInk\" width=\"250\"/>\n  </a>\n</div>\n\n---\n\nVoiceInk is a native macOS application that transcribes what you say to text almost instantly. You can find all the information and download the app from [here](https://tryvoiceink.com). \n\n![VoiceInk Mac App](https://github.com/user-attachments/assets/12367379-83e7-48a6-b52c-4488a6a04bba)\n\nAfter dedicating the past 5 months to developing this app, I've decided to open source it for the greater good. \n\nMy goal is to make it **the most efficient and privacy-focused voice-to-text solution for macOS** that is a joy to use. While the source code is now open for experienced developers to build and contribute, purchasing a license helps support continued development and gives you access to automatic updates, priority support, and upcoming features.\n\n## Features\n\n- üéôÔ∏è **Accurate Transcription**: Local AI models that transcribe your voice to text with 99% accuracy, almost instantly\n- üîí **Privacy First**: 100% offline processing ensures your data never leaves your device\n- ‚ö° **Power Mode**: Intelligent app detection automatically applies your perfect pre-configured settings based on the app/ URL you're on\n- üß† **Context Aware**: Smart AI that understands your screen content and adapts to the context\n- üéØ **Global Shortcuts**: Configurable keyboard shortcuts for quick recording and push-to-talk functionality\n- üìù **Personal Dictionary**: Train the AI to understand your unique terminology with custom words, industry terms, and smart text replacements\n- üîÑ **Smart Modes**: Instantly switch between AI-powered modes optimized for different writing styles and contexts\n- ü§ñ **AI Assistant**: Built-in voice assistant mode for a quick chatGPT like conversational assistant\n\n## Get Started\n\n### Download\nGet the latest version with a free trial from [tryvoiceink.com](https://tryvoiceink.com). Your purchase helps me work on VoiceInk full-time and continuously improve it with new features and updates.\n\n#### Homebrew\nAlternatively, you can install VoiceInk via `brew`:\n\n```shell\nbrew install --cask voiceink\n```\n\n### Build from Source\nAs an open-source project, you can build VoiceInk yourself by following the instructions in [BUILDING.md](BUILDING.md). However, the compiled version includes additional benefits like automatic updates, priority support via Discord and email, and helps fund ongoing development.\n\n## Requirements\n\n- macOS 14.0 or later\n\n## Documentation\n\n- [Building from Source](BUILDING.md) - Detailed instructions for building the project\n- [Contributing Guidelines](CONTRIBUTING.md) - How to contribute to VoiceInk\n- [Code of Conduct](CODE_OF_CONDUCT.md) - Our community standards\n\n## Contributing\n\nWe welcome contributions! However, please note that all contributions should align with the project's goals and vision. Before starting work on any feature or fix:\n\n1. Read our [Contributing Guidelines](CONTRIBUTING.md)\n2. Open an issue to discuss your proposed changes\n3. Wait for maintainer feedback\n\nFor build instructions, see our [Building Guide](BUILDING.md).\n\n## License\n\nThis project is licensed under the GNU General Public License v3.0 - see the [LICENSE](LICENSE) file for details.\n\n## Support\n\nIf you encounter any issues or have questions, please:\n1. Check the existing issues in the GitHub repository\n2. Create a new issue if your problem isn't already reported\n3. Provide as much detail as possible about your environment and the problem\n\n## Acknowledgments\n\n### Core Technology\n- [whisper.cpp](https://github.com/ggerganov/whisper.cpp) - High-performance inference of OpenAI's Whisper model\n- [FluidAudio](https://github.com/FluidInference/FluidAudio) - Used for Parakeet model implementation\n\n### Essential Dependencies\n- [Sparkle](https://github.com/sparkle-project/Sparkle) - Keeping VoiceInk up to date\n- [KeyboardShortcuts](https://github.com/sindresorhus/KeyboardShortcuts) - User-customizable keyboard shortcuts\n- [LaunchAtLogin](https://github.com/sindresorhus/LaunchAtLogin) - Launch at login functionality\n- [MediaRemoteAdapter](https://github.com/ejbills/mediaremote-adapter) - Media playback control during recording\n- [Zip](https://github.com/marmelroy/Zip) - File compression and decompression utilities\n- [SelectedTextKit](https://github.com/tisfeng/SelectedTextKit) - A modern macOS library for getting selected text\n- [Swift Atomics](https://github.com/apple/swift-atomics) - Low-level atomic operations for thread-safe concurrent programming\n\n\n---\n\nMade with ‚ù§Ô∏è by Pax\n",
      "stars_today": 15
    },
    {
      "id": 845594676,
      "name": "tansu",
      "full_name": "tansu-io/tansu",
      "description": "Apache Kafka¬Æ compatible broker with S3, PostgreSQL, SQLite, Apache Iceberg and Delta Lake",
      "html_url": "https://github.com/tansu-io/tansu",
      "stars": 1204,
      "forks": 48,
      "language": "Rust",
      "topics": [
        "apache-arrow",
        "apache-iceberg",
        "apache-kafka",
        "built-with-rust",
        "datafusion",
        "datalake",
        "delta-lake",
        "parquet",
        "postgres",
        "postgresql",
        "s3",
        "sqlite"
      ],
      "created_at": "2024-08-21T14:47:15Z",
      "updated_at": "2026-01-14T01:03:00Z",
      "pushed_at": "2026-01-13T14:22:23Z",
      "open_issues": 58,
      "owner": {
        "login": "tansu-io",
        "avatar_url": "https://avatars.githubusercontent.com/u/161749514?v=4"
      },
      "readme": "<div align=\"center\">\n\n# Tansu üóÉÔ∏è\nstateless Kafka-compatible broker with pluggable storage (PostgreSQL, SQLite, S3, memory)\n\n<br>\n\n[![License](https://img.shields.io/badge/License-Apache-165dfc.svg)](https://github.com/tansu-io/tansu/blob/main/LICENSE)\n&nbsp;\n[![Built with Rust](https://img.shields.io/badge/built_with-Rust-165dfc.svg?logo=rust)](https://www.rust-lang.org/)\n&nbsp;\n<br>\n[![Docs](https://img.shields.io/badge/üìñ%20docs-docs.tansu.io-165dfc.svg)](https://docs.tansu.io/)\n&nbsp;\n[![Blog](https://img.shields.io/badge/%F0%9F%93%98%20blog-blog.tansu.io-165dfc.svg)](https://blog.tansu.io/articles)\n&nbsp;\n<br>\n[![GitHub stars](https://img.shields.io/github/stars/tansu-io/tansu?style=social)](https://github.com/tansu-io/tansu)\n&nbsp;\n[![Bluesky](https://img.shields.io/bluesky/followers/tansu.io)](https://bsky.app/profile/tansu.io)\n\n<br>\n\n</div>\n\n# What is Tansu?\n\n[Tansu][github-com-tansu-io] is a drop-in replacement for\nApache Kafka with PostgreSQL, libSQL (SQLite), S3 or memory storage engines.\nSchema backed topics (Avro, JSON or Protocol buffers) can\nbe written as [Apache Iceberg](https://iceberg.apache.org) or [Delta Lake](https://delta.io) tables.\n\nFeatures:\n\n- Apache Kafka API compatible\n- Available with [PostgreSQL](https://www.postgresql.org), [libSQL](https://docs.turso.tech/libsql), [S3](https://en.wikipedia.org/wiki/Amazon_S3) or memory storage engines\n- Topics [validated](docs/schema-registry.md) by [JSON Schema][json-schema-org], [Apache Avro](https://avro.apache.org)\n  or [Protocol buffers](protocol-buffers) can be written as [Apache Iceberg](https://iceberg.apache.org) or [Delta Lake](https://delta.io) tables\n\nSee [examples using pyiceberg](https://github.com/tansu-io/example-pyiceberg), [examples using Apache Spark](https://github.com/tansu-io/example-spark) or üÜï [examples using Delta Lake](https://github.com/tansu-io/example-delta-lake).\n\nFor data durability:\n\n- S3 is designed to exceed [99.999999999% (11 nines)][aws-s3-storage-classes]\n- PostgreSQL with [continuous archiving][continuous-archiving]\n  streaming transaction logs files to an archive\n- The memory storage engine is designed for ephemeral non-production environments\n\nTansu is a single statically linked binary containing the following:\n\n- **broker** an Apache Kafka API compatible broker and schema registry\n- **topic** a CLI to create/delete Topics\n- **cat** a CLI to consume or produce Avro, JSON or Protobuf messages to a topic\n- **proxy** an Apache Kafka compatible proxy\n\n## broker\n\nThe broker subcommand is default if no other command is supplied.\n\n```shell\nUsage: tansu [OPTIONS]\n       tansu <COMMAND>\n\nCommands:\n  broker  Apache Kafka compatible broker with Avro, JSON, Protobuf schema validation [default if no command supplied]\n  cat     Easily consume or produce Avro, JSON or Protobuf messages to a topic\n  topic   Create or delete topics managed by the broker\n  proxy   Apache Kafka compatible proxy\n  help    Print this message or the help of the given subcommand(s)\n\nOptions:\n      --kafka-cluster-id <KAFKA_CLUSTER_ID>\n          All members of the same cluster should use the same id [env: CLUSTER_ID=RvQwrYegSUCkIPkaiAZQlQ] [default: tansu_cluster]\n      --kafka-listener-url <KAFKA_LISTENER_URL>\n          The broker will listen on this address [env: LISTENER_URL=] [default: tcp://[::]:9092]\n      --kafka-advertised-listener-url <KAFKA_ADVERTISED_LISTENER_URL>\n          This location is advertised to clients in metadata [env: ADVERTISED_LISTENER_URL=tcp://localhost:9092] [default: tcp://localhost:9092]\n      --storage-engine <STORAGE_ENGINE>\n          Storage engine examples are: postgres://postgres:postgres@localhost, memory://tansu/ or s3://tansu/ [env: STORAGE_ENGINE=s3://tansu/] [default: memory://tansu/]\n      --schema-registry <SCHEMA_REGISTRY>\n          Schema registry examples are: file://./etc/schema or s3://tansu/, containing: topic.json, topic.proto or topic.avsc [env: SCHEMA_REGISTRY=file://./etc/schema]\n      --data-lake <DATA_LAKE>\n          Apache Parquet files are written to this location, examples are: file://./lake or s3://lake/ [env: DATA_LAKE=s3://lake/]\n      --iceberg-catalog <ICEBERG_CATALOG>\n          Apache Iceberg Catalog, examples are: http://localhost:8181/ [env: ICEBERG_CATALOG=http://localhost:8181/]\n      --iceberg-namespace <ICEBERG_NAMESPACE>\n          Iceberg namespace [env: ICEBERG_NAMESPACE=] [default: tansu]\n      --prometheus-listener-url <PROMETHEUS_LISTENER_URL>\n          Broker metrics can be scraped by Prometheus from this URL [env: PROMETHEUS_LISTENER_URL=tcp://0.0.0.0:9100] [default: tcp://[::]:9100]\n  -h, --help\n          Print help\n  -V, --version\n          Print version\n```\n\nA broker can be started by simply running `tansu`, all options have defaults. Tansu pickup any existing environment,\nloading any found in `.env`. An [example.env](example.env) is provided as part of the distribution\nand can be copied into `.env` for local modification. Sample schemas can be found in [etc/schema](etc/schema), used in the examples.\n\nIf an Apache Avro, Protobuf or JSON schema has been assigned to a topic, the\nbroker will reject any messages that are invalid. Schema backed topics are written\nas Apache Parquet when the `-data-lake` option is provided.\n\n## topic\n\nThe `tansu topic` command has the following subcommands:\n\n```shell\nCreate or delete topics managed by the broker\n\nUsage: tansu topic <COMMAND>\n\nCommands:\n  create  Create a topic\n  delete  Delete an existing topic\n  help    Print this message or the help of the given subcommand(s)\n\nOptions:\n  -h, --help  Print help\n```\n\nTo create a topic use:\n\n```shell\ntansu topic create taxi\n```\n\n## cat\n\nThe `tansu cat` command, has the following subcommands:\n\n```shell\ntansu cat --help\nEasily consume or produce Avro, JSON or Protobuf messages to a topic\n\nUsage: tansu cat <COMMAND>\n\nCommands:\n  produce  Produce Avro/JSON/Protobuf messages to a topic\n  consume  Consume Avro/JSON/Protobuf messages from a topic\n  help     Print this message or the help of the given subcommand(s)\n\nOptions:\n  -h, --help  Print help\n```\n\nThe `produce` subcommand reads JSON formatted messages encoding them into\nApache Avro, Protobuf or JSON depending on the schema used by the topic.\n\nFor example, the `taxi` topic is backed by [taxi.proto](etc/schema/taxi.proto).\nUsing [trips.json](etc/data/trips.json) containing a JSON array of objects,\n`tansu cat produce` encodes each message into protobuf into the broker:\n\n```\ntansu cat produce taxi etc/data/trips.json\n```\n\nUsing [duckdb](https://duckdb.org) we can read the\n[Apache Parquet](https://parquet.apache.org) files\ncreated by the broker:\n\n```shell\nduckdb :memory: \"SELECT * FROM 'data/taxi/*/*.parquet'\"\n```\n\nResults in the following output:\n\n```shell\n|-----------+---------+---------------+-------------+---------------|\n| vendor_id | trip_id | trip_distance | fare_amount | store_and_fwd |\n|     int64 |   int64 |         float |      double |         int32 |\n|-----------+---------+---------------+-------------+---------------|\n|         1 | 1000371 |           1.8 |       15.32 |             0 |\n|         2 | 1000372 |           2.5 |       22.15 |             0 |\n|         2 | 1000373 |           0.9 |        9.01 |             0 |\n|         1 | 1000374 |           8.4 |       42.13 |             1 |\n|-----------+---------+---------------+-------------+---------------|\n```\n\n\n### s3\n\nThe following will configure a S3 storage engine\nusing the \"tansu\" bucket (full context is in\n[compose.yaml](compose.yaml) and [example.env](example.env)):\n\nCopy `example.env` into `.env` so that you have a local working copy:\n\n```shell\ncp example.env .env\n```\n\nEdit `.env` so that `STORAGE_ENGINE` is defined as:\n\n```shell\nSTORAGE_ENGINE=\"s3://tansu/\"\n```\n\nFirst time startup, you'll need to create a bucket, an access key\nand a secret in minio.\n\nJust bring minio up, without tansu:\n\n```shell\ndocker compose up -d minio\n```\n\nCreate a minio `local` alias representing `http://localhost:9000` with the default credentials of `minioadmin`:\n\n```shell\ndocker compose exec minio \\\n   /usr/bin/mc \\\n   alias \\\n   set \\\n   local \\\n   http://localhost:9000 \\\n   minioadmin \\\n   minioadmin\n```\n\nCreate a `tansu` bucket in minio using the `local` alias:\n\n```shell\ndocker compose exec minio \\\n   /usr/bin/mc mb local/tansu\n```\n\nOnce this is done, you can start tansu with:\n\n```shell\ndocker compose up -d tansu\n```\n\nUsing the regular Apache Kafka CLI you can create topics, produce and consume\nmessages with Tansu:\n\n```shell\nkafka-topics \\\n  --bootstrap-server localhost:9092 \\\n  --partitions=3 \\\n  --replication-factor=1 \\\n  --create --topic test\n```\n\nDescribe the `test` topic:\n\n```shell\nkafka-topics \\\n  --bootstrap-server localhost:9092 \\\n  --describe \\\n  --topic test\n```\n\nNote that node 111 is the leader and ISR for each topic partition.\nThis node represents the broker handling your request. All brokers are node 111.\n\nProducer:\n\n```shell\necho \"hello world\" | kafka-console-producer \\\n    --bootstrap-server localhost:9092 \\\n    --topic test\n```\n\nGroup consumer using `test-consumer-group`:\n\n```shell\nkafka-console-consumer \\\n  --bootstrap-server localhost:9092 \\\n  --group test-consumer-group \\\n  --topic test \\\n  --from-beginning \\\n  --property print.timestamp=true \\\n  --property print.key=true \\\n  --property print.offset=true \\\n  --property print.partition=true \\\n  --property print.headers=true \\\n  --property print.value=true\n```\n\nDescribe the consumer `test-consumer-group` group:\n\n```shell\nkafka-consumer-groups \\\n  --bootstrap-server localhost:9092 \\\n  --group test-consumer-group \\\n  --describe\n```\n\n### PostgreSQL\n\nTo switch between the minio and PostgreSQL examples, firstly\nshutdown Tansu:\n\n```shell\ndocker compose down tansu\n```\n\nSwitch to the PostgreSQL storage engine by updating [.env](.env):\n\n```env\n# minio storage engine\n# STORAGE_ENGINE=\"s3://tansu/\"\n\n# PostgreSQL storage engine -- NB: @db and NOT @localhost :)\nSTORAGE_ENGINE=\"postgres://postgres:postgres@db\"\n```\n\nStart PostgreSQL:\n\n```shell\ndocker compose up -d db\n```\n\nBring Tansu back up:\n\n```shell\ndocker compose up -d tansu\n```\n\nUsing the regular Apache Kafka CLI you can create topics, produce and consume\nmessages with Tansu:\n\n```shell\nkafka-topics \\\n  --bootstrap-server localhost:9092 \\\n  --partitions=3 \\\n  --replication-factor=1 \\\n  --create --topic test\n```\n\nProducer:\n\n```shell\necho \"hello world\" | kafka-console-producer \\\n    --bootstrap-server localhost:9092 \\\n    --topic test\n```\n\nConsumer:\n\n```shell\nkafka-console-consumer \\\n  --bootstrap-server localhost:9092 \\\n  --group test-consumer-group \\\n  --topic test \\\n  --from-beginning \\\n  --property print.timestamp=true \\\n  --property print.key=true \\\n  --property print.offset=true \\\n  --property print.partition=true \\\n  --property print.headers=true \\\n  --property print.value=true\n```\n\nOr using [librdkafka][librdkafka] to produce:\n\n```shell\necho \"Lorem ipsum dolor...\" | \\\n  ./examples/rdkafka_example -P \\\n  -t test -p 1 \\\n  -b localhost:9092 \\\n  -z gzip\n```\n\nConsumer:\n\n```shell\n./examples/rdkafka_example \\\n  -C \\\n  -t test -p 1 \\\n  -b localhost:9092\n```\n\n## Feedback\n\nPlease [raise an issue][tansu-issues] if you encounter a problem.\n\n## License\n\nTansu is licensed under [Apache 2.0][apache-license].\n\n[apache-license]: https://www.apache.org/licenses/LICENSE-2.0\n[apache-zookeeper]: https://en.wikipedia.org/wiki/Apache_ZooKeeper\n[aws-s3-conditional-requests]: https://docs.aws.amazon.com/AmazonS3/latest/userguide/conditional-requests.html\n[aws-s3-conditional-writes]: https://aws.amazon.com/about-aws/whats-new/2024/08/amazon-s3-conditional-writes/\n[aws-s3-storage-classes]: https://aws.amazon.com/s3/storage-classes/\n[cloudflare-r2]: https://developers.cloudflare.com/r2/\n[continuous-archiving]: https://www.postgresql.org/docs/current/continuous-archiving.html\n[crates-io-object-store]: https://crates.io/crates/object_store\n[github-com-tansu-io]: https://github.com/tansu-io/tansu\n[json-schema-org]: https://json-schema.org/\n[librdkafka]: https://github.com/confluentinc/librdkafka\n[min-io]: https://min.io\n[minio-create-access-key]: https://min.io/docs/minio/container/administration/console/security-and-access.html#id1\n[minio-create-bucket]: https://min.io/docs/minio/container/administration/console/managing-objects.html#creating-buckets\n[object-store-dynamo-conditional-put]: https://docs.rs/object_store/0.11.0/object_store/aws/struct.DynamoCommit.html\n[protocol-buffers]: https://protobuf.dev\n[raft-consensus]: https://raft.github.io\n[rust-lang-org]: https://www.rust-lang.org\n[tansu-issues]: https://github.com/tansu-io/tansu/issues\n[tigris-conditional-writes]: https://www.tigrisdata.com/blog/s3-conditional-writes/\n",
      "stars_today": 15
    },
    {
      "id": 29028775,
      "name": "react-native",
      "full_name": "facebook/react-native",
      "description": "A framework for building native applications using React",
      "html_url": "https://github.com/facebook/react-native",
      "stars": 125047,
      "forks": 25047,
      "language": "C++",
      "topics": [
        "android",
        "app-framework",
        "cross-platform",
        "ios",
        "mobile",
        "mobile-development",
        "react",
        "react-native"
      ],
      "created_at": "2015-01-09T18:10:16Z",
      "updated_at": "2026-01-14T00:48:12Z",
      "pushed_at": "2026-01-14T00:12:09Z",
      "open_issues": 1141,
      "owner": {
        "login": "facebook",
        "avatar_url": "https://avatars.githubusercontent.com/u/69631?v=4"
      },
      "readme": "<h1 align=\"center\">\n  <a href=\"https://reactnative.dev/\">\n    React Native\n  </a>\n</h1>\n\n<p align=\"center\">\n  <strong>Learn once, write anywhere:</strong><br>\n  Build mobile apps with React.\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/facebook/react-native/blob/HEAD/LICENSE\">\n    <img src=\"https://img.shields.io/badge/license-MIT-blue.svg\" alt=\"React Native is released under the MIT license.\" />\n  </a>\n  <a href=\"https://www.npmjs.org/package/react-native\">\n    <img src=\"https://img.shields.io/npm/v/react-native?color=brightgreen&label=npm%20package\" alt=\"Current npm package version.\" />\n  </a>\n  <a href=\"https://reactnative.dev/docs/contributing\">\n    <img src=\"https://img.shields.io/badge/PRs-welcome-brightgreen.svg\" alt=\"PRs are welcome!\" />\n  </a>\n  <a href=\"https://twitter.com/intent/follow?screen_name=reactnative\">\n    <img src=\"https://img.shields.io/twitter/follow/reactnative.svg?label=Follow%20@reactnative\" alt=\"Follow @reactnative on X\" />\n  </a>\n  <a href=\"https://bsky.app/profile/reactnative.dev\">\n    <img src=\"https://img.shields.io/badge/Bluesky-0285FF?logo=bluesky&logoColor=fff\" alt=\"Follow @reactnative.dev on Bluesky\" />\n  </a>\n</p>\n\n<h3 align=\"center\">\n  <a href=\"https://reactnative.dev/docs/getting-started\">Getting Started</a>\n  <span> ¬∑ </span>\n  <a href=\"https://reactnative.dev/docs/tutorial\">Learn the Basics</a>\n  <span> ¬∑ </span>\n  <a href=\"https://reactnative.dev/showcase\">Showcase</a>\n  <span> ¬∑ </span>\n  <a href=\"https://reactnative.dev/docs/contributing\">Contribute</a>\n  <span> ¬∑ </span>\n  <a href=\"https://reactnative.dev/help\">Community</a>\n  <span> ¬∑ </span>\n  <a href=\"https://github.com/facebook/react-native/blob/HEAD/.github/SUPPORT.md\">Support</a>\n</h3>\n\nReact Native brings [**React**'s][r] declarative UI framework to iOS and Android. With React Native, you use native UI controls and have full access to the native platform.\n\n- **Declarative.** React makes it painless to create interactive UIs. Declarative views make your code more predictable and easier to debug.\n- **Component-Based.** Build encapsulated components that manage their state, then compose them to make complex UIs.\n- **Developer Velocity.** See local changes in seconds. Changes to JavaScript code can be live reloaded without rebuilding the native app.\n- **Portability.** Reuse code across iOS, Android, and [other platforms][p].\n\nReact Native is developed and supported by many companies and individual core contributors. Find out more in our [ecosystem overview][e].\n\n[r]: https://react.dev/\n[p]: https://reactnative.dev/docs/out-of-tree-platforms\n[e]: https://github.com/facebook/react-native/blob/HEAD/ECOSYSTEM.md\n\n## Contents\n\n- [Requirements](#-requirements)\n- [Building your first React Native app](#-building-your-first-react-native-app)\n- [Documentation](#-documentation)\n- [Upgrading](#-upgrading)\n- [How to Contribute](#-how-to-contribute)\n- [Code of Conduct](#code-of-conduct)\n- [License](#-license)\n\n\n## üìã Requirements\n\nReact Native apps may target iOS 15.1 and Android 7.0 (API 24) or newer. You may use Windows, macOS, or Linux as your development operating system, though building and running iOS apps is limited to macOS. Tools like [Expo](https://expo.dev) can be used to work around this.\n\n## üéâ Building your first React Native app\n\nFollow the [Getting Started guide](https://reactnative.dev/docs/getting-started). The recommended way to install React Native depends on your project. Here you can find short guides for the most common scenarios:\n\n- [Trying out React Native][hello-world]\n- [Creating a New Application][new-app]\n- [Adding React Native to an Existing Application][existing]\n\n[hello-world]: https://snack.expo.dev/@samples/hello-world\n[new-app]: https://reactnative.dev/docs/getting-started\n[existing]: https://reactnative.dev/docs/integration-with-existing-apps\n\n## üìñ Documentation\n\nThe full documentation for React Native can be found on our [website][docs].\n\nThe React Native documentation discusses components, APIs, and topics that are specific to React Native. For further documentation on the React API that is shared between React Native and React DOM, refer to the [React documentation][r-docs].\n\nThe source for the React Native documentation and website is hosted on a separate repository, [**@facebook/react-native-website**][repo-website].\n\n[docs]: https://reactnative.dev/docs/getting-started\n[r-docs]: https://react.dev/learn\n[repo-website]: https://github.com/facebook/react-native-website\n\n## üöÄ Upgrading\n\nUpgrading to new versions of React Native may give you access to more APIs, views, developer tools, and other goodies. See the [Upgrading Guide][u] for instructions.\n\nReact Native releases are discussed [in this discussion repo](https://github.com/reactwg/react-native-releases/discussions).\n\n[u]: https://reactnative.dev/docs/upgrading\n[repo-releases]: https://github.com/react-native-community/react-native-releases\n\n## üëè How to Contribute\n\nThe main purpose of this repository is to continue evolving React Native core. We want to make contributing to this project as easy and transparent as possible, and we are grateful to the community for contributing bug fixes and improvements. Read below to learn how you can take part in improving React Native.\n\n### [Code of Conduct][code]\n\nFacebook has adopted a Code of Conduct that we expect project participants to adhere to.\nPlease read the [full text][code] so that you can understand what actions will and will not be tolerated.\n\n[code]: https://code.fb.com/codeofconduct/\n\n### [Contributing Guide][contribute]\n\nRead our [**Contributing Guide**][contribute] to learn about our development process, how to propose bugfixes and improvements, and how to build and test your changes to React Native.\n\n[contribute]: https://reactnative.dev/docs/contributing\n\n### [Open Source Roadmap][roadmap]\n\nYou can learn more about our vision for React Native in the [**Roadmap**][roadmap].\n\n[roadmap]: https://github.com/facebook/react-native/wiki/Roadmap\n\n### Good First Issues\n\nWe have a list of [good first issues][gfi] that contain bugs which have a relatively limited scope. This is a great place to get started, gain experience, and get familiar with our contribution process.\n\n[gfi]: https://github.com/facebook/react-native/labels/good%20first%20issue\n\n### Discussions\n\nLarger discussions and proposals are discussed in [**@react-native-community/discussions-and-proposals**][repo-meta].\n\n[repo-meta]: https://github.com/react-native-community/discussions-and-proposals\n\n## üìÑ License\n\nReact Native is MIT licensed, as found in the [LICENSE][l] file.\n\n[l]: https://github.com/facebook/react-native/blob/main/LICENSE\n",
      "stars_today": 14
    },
    {
      "id": 11171548,
      "name": "json",
      "full_name": "nlohmann/json",
      "description": "JSON for Modern C++",
      "html_url": "https://github.com/nlohmann/json",
      "stars": 48524,
      "forks": 7285,
      "language": "C++",
      "topics": [
        "bson",
        "cbor",
        "header-only",
        "json",
        "json-diff",
        "json-merge-patch",
        "json-parser",
        "json-patch",
        "json-pointer",
        "json-serialization",
        "messagepack",
        "msgpack",
        "rfc-6901",
        "rfc-6902",
        "rfc-7049",
        "rfc-7159",
        "rfc-8259",
        "stl-containers",
        "ubjson"
      ],
      "created_at": "2013-07-04T08:47:49Z",
      "updated_at": "2026-01-13T21:20:20Z",
      "pushed_at": "2026-01-13T16:19:39Z",
      "open_issues": 97,
      "owner": {
        "login": "nlohmann",
        "avatar_url": "https://avatars.githubusercontent.com/u/159488?v=4"
      },
      "readme": "[![JSON for Modern C++](docs/mkdocs/docs/images/json.gif)](https://github.com/nlohmann/json/releases)\n\n[![Build Status](https://ci.appveyor.com/api/projects/status/1acb366xfyg3qybk/branch/develop?svg=true)](https://ci.appveyor.com/project/nlohmann/json)\n[![Ubuntu](https://github.com/nlohmann/json/workflows/Ubuntu/badge.svg)](https://github.com/nlohmann/json/actions?query=workflow%3AUbuntu)\n[![macOS](https://github.com/nlohmann/json/workflows/macOS/badge.svg)](https://github.com/nlohmann/json/actions?query=workflow%3AmacOS)\n[![Windows](https://github.com/nlohmann/json/workflows/Windows/badge.svg)](https://github.com/nlohmann/json/actions?query=workflow%3AWindows)\n[![Coverage Status](https://coveralls.io/repos/github/nlohmann/json/badge.svg?branch=develop)](https://coveralls.io/github/nlohmann/json?branch=develop)\n[![Coverity Scan Build Status](https://scan.coverity.com/projects/5550/badge.svg)](https://scan.coverity.com/projects/nlohmann-json)\n[![Codacy Badge](https://app.codacy.com/project/badge/Grade/e0d1a9d5d6fd46fcb655c4cb930bb3e8)](https://app.codacy.com/gh/nlohmann/json/dashboard?utm_source=gh&utm_medium=referral&utm_content=&utm_campaign=Badge_grade)\n[![Cirrus CI](https://api.cirrus-ci.com/github/nlohmann/json.svg)](https://cirrus-ci.com/github/nlohmann/json)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/json.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:json)\n[![Try online](https://img.shields.io/badge/try-online-blue.svg)](https://wandbox.org/permlink/1mp10JbaANo6FUc7)\n[![Documentation](https://img.shields.io/badge/docs-mkdocs-blue.svg)](https://json.nlohmann.me)\n[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://raw.githubusercontent.com/nlohmann/json/master/LICENSE.MIT)\n[![GitHub Releases](https://img.shields.io/github/release/nlohmann/json.svg)](https://github.com/nlohmann/json/releases)\n[![Packaging status](https://repology.org/badge/tiny-repos/nlohmann-json.svg)](https://repology.org/project/nlohmann-json/versions)\n[![GitHub Downloads](https://img.shields.io/github/downloads/nlohmann/json/total)](https://github.com/nlohmann/json/releases)\n[![GitHub Issues](https://img.shields.io/github/issues/nlohmann/json.svg)](https://github.com/nlohmann/json/issues)\n[![Average time to resolve an issue](https://isitmaintained.com/badge/resolution/nlohmann/json.svg)](https://isitmaintained.com/project/nlohmann/json \"Average time to resolve an issue\")\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/289/badge)](https://bestpractices.coreinfrastructure.org/projects/289)\n[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/nlohmann/json/badge)](https://scorecard.dev/viewer/?uri=github.com/nlohmann/json)\n[![Backup Status](https://app.cloudback.it/badge/nlohmann/json)](https://cloudback.it)\n[![GitHub Sponsors](https://img.shields.io/badge/GitHub-Sponsors-ff69b4)](https://github.com/sponsors/nlohmann)\n[![REUSE status](https://api.reuse.software/badge/github.com/nlohmann/json)](https://api.reuse.software/info/github.com/nlohmann/json)\n[![Discord](https://img.shields.io/discord/1003743314341793913)](https://discord.gg/6mrGXKvX7y)\n\n- [Design goals](#design-goals)\n- [Sponsors](#sponsors)\n- [Support](#support) ([documentation](https://json.nlohmann.me), [FAQ](https://json.nlohmann.me/home/faq/), [discussions](https://github.com/nlohmann/json/discussions), [API](https://json.nlohmann.me/api/basic_json/), [bug issues](https://github.com/nlohmann/json/issues))\n- [Quick reference](#quick-reference)\n- [Examples](#examples)\n  - [Read JSON from a file](#read-json-from-a-file)\n  - [Creating `json` objects from JSON literals](#creating-json-objects-from-json-literals)\n  - [JSON as a first-class data type](#json-as-a-first-class-data-type)\n  - [Serialization / Deserialization](#serialization--deserialization)\n  - [STL-like access](#stl-like-access)\n  - [Conversion from STL containers](#conversion-from-stl-containers)\n  - [JSON Pointer and JSON Patch](#json-pointer-and-json-patch)\n  - [JSON Merge Patch](#json-merge-patch)\n  - [Implicit conversions](#implicit-conversions)\n  - [Conversions to/from arbitrary types](#arbitrary-types-conversions)\n  - [Specializing enum conversion](#specializing-enum-conversion)\n  - [Binary formats (BSON, CBOR, MessagePack, UBJSON, and BJData)](#binary-formats-bson-cbor-messagepack-ubjson-and-bjdata)\n- [Customers](#customers)\n- [Supported compilers](#supported-compilers)\n- [Integration](#integration)\n  - [CMake](#cmake)\n  - [Package Managers](#package-managers)\n  - [Pkg-config](#pkg-config)\n- [License](#license)\n- [Contact](#contact)\n- [Thanks](#thanks)\n- [Used third-party tools](#used-third-party-tools)\n- [Notes](#notes)\n- [Execute unit tests](#execute-unit-tests)\n\n## Design goals\n\nThere are myriads of [JSON](https://json.org) libraries out there, and each may even have its reason to exist. Our class had these design goals:\n\n- **Intuitive syntax**. In languages such as Python, JSON feels like a first-class data type. We used all the operator magic of modern C++ to achieve the same feeling in your code. Check out the [examples below](#examples) and you'll know what I mean.\n\n- **Trivial integration**. Our whole code consists of a single header file [`json.hpp`](https://github.com/nlohmann/json/blob/develop/single_include/nlohmann/json.hpp). That's it. No library, no subproject, no dependencies, no complex build system. The class is written in vanilla C++11. All in all, everything should require no adjustment of your compiler flags or project settings. The library is also included in all popular [package managers](https://json.nlohmann.me/integration/package_managers/).\n\n- **Serious testing**. Our code is heavily [unit-tested](https://github.com/nlohmann/json/tree/develop/tests/src) and covers [100%](https://coveralls.io/r/nlohmann/json) of the code, including all exceptional behavior. Furthermore, we checked with [Valgrind](https://valgrind.org) and the [Clang Sanitizers](https://clang.llvm.org/docs/index.html) that there are no memory leaks. [Google OSS-Fuzz](https://github.com/google/oss-fuzz/tree/master/projects/json) additionally runs fuzz tests against all parsers 24/7, effectively executing billions of tests so far. To maintain high quality, the project is following the [Core Infrastructure Initiative (CII) best practices](https://bestpractices.coreinfrastructure.org/projects/289). See the [quality assurance](https://json.nlohmann.me/community/quality_assurance) overview documentation.\n\nOther aspects were not so important to us:\n\n- **Memory efficiency**. Each JSON object has an overhead of one pointer (the maximal size of a union) and one enumeration element (1 byte). The default generalization uses the following C++ data types: `std::string` for strings, `int64_t`, `uint64_t` or `double` for numbers, `std::map` for objects, `std::vector` for arrays, and `bool` for Booleans. However, you can template the generalized class `basic_json` to your needs.\n\n- **Speed**. There are certainly [faster JSON libraries](https://github.com/miloyip/nativejson-benchmark#parsing-time) out there. However, if your goal is to speed up your development by adding JSON support with a single header, then this library is the way to go. If you know how to use a `std::vector` or `std::map`, you are already set.\n\nSee the [contribution guidelines](https://github.com/nlohmann/json/blob/master/.github/CONTRIBUTING.md#please-dont) for more information.\n\n## Sponsors\n\nYou can sponsor this library at [GitHub Sponsors](https://github.com/sponsors/nlohmann).\n\n### :raising_hand: Priority Sponsor\n\n- [Martti Laine](https://github.com/codeclown)\n- [Paul Harrington](https://github.com/phrrngtn)\n\n### :label: Named Sponsors\n\n- [Michael Hartmann](https://github.com/reFX-Mike)\n- [Stefan Hagen](https://github.com/sthagen)\n- [Steve Sperandeo](https://github.com/homer6)\n- [Robert Jefe Lindst√§dt](https://github.com/eljefedelrodeodeljefe)\n- [Steve Wagner](https://github.com/ciroque)\n- [Lion Yang](https://github.com/LionNatsu)\n\n### Further support\n\nThe development of the library is further supported by JetBrains by providing free access to their IDE tools.\n\n[![JetBrains logo.](https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.svg)](https://jb.gg/OpenSourceSupport)\n\nThanks everyone!\n\n## Support\n\n:question: If you have a **question**, please check if it is already answered in the [**FAQ**](https://json.nlohmann.me/home/faq/) or the [**Q&A**](https://github.com/nlohmann/json/discussions/categories/q-a) section. If not, please [**ask a new question**](https://github.com/nlohmann/json/discussions/new) there.\n\n:books: If you want to **learn more** about how to use the library, check out the rest of the [**README**](#examples), have a look at [**code examples**](https://github.com/nlohmann/json/tree/develop/docs/mkdocs/docs/examples), or browse through the [**help pages**](https://json.nlohmann.me).\n\n:construction: If you want to understand the **API** better, check out the [**API Reference**](https://json.nlohmann.me/api/basic_json/) or have a look at the [quick reference](#quick-reference) below.\n\n:bug: If you found a **bug**, please check the [**FAQ**](https://json.nlohmann.me/home/faq/) if it is a known issue or the result of a design decision. Please also have a look at the [**issue list**](https://github.com/nlohmann/json/issues) before you [**create a new issue**](https://github.com/nlohmann/json/issues/new/choose). Please provide as much information as possible to help us understand and reproduce your issue.\n\nThere is also a [**docset**](https://github.com/Kapeli/Dash-User-Contributions/tree/master/docsets/JSON_for_Modern_C%2B%2B) for the documentation browsers [Dash](https://kapeli.com/dash), [Velocity](https://velocity.silverlakesoftware.com), and [Zeal](https://zealdocs.org) that contains the full [documentation](https://json.nlohmann.me) as an offline resource.\n\n## Quick reference\n\n- **Constructors** [basic_json](https://json.nlohmann.me/api/basic_json/basic_json), [array](https://json.nlohmann.me/api/basic_json/array), [binary](https://json.nlohmann.me/api/basic_json/binary), [object](https://json.nlohmann.me/api/basic_json/object)\n- **Object inspection**: [type](https://json.nlohmann.me/api/basic_json/type), [operator value_t](https://json.nlohmann.me/api/basic_json/operator_value_t), [type_name](https://json.nlohmann.me/api/basic_json/type_name), [is_primitive](https://json.nlohmann.me/api/basic_json/is_primitive), [is_structured](https://json.nlohmann.me/api/basic_json/is_structured), [is_null](https://json.nlohmann.me/api/basic_json/is_null), [is_boolean](https://json.nlohmann.me/api/basic_json/is_boolean), [is_number](https://json.nlohmann.me/api/basic_json/is_number), [is_number_integer](https://json.nlohmann.me/api/basic_json/is_number_integer), [is_number_unsigned](https://json.nlohmann.me/api/basic_json/is_number_unsigned), [is_number_float](https://json.nlohmann.me/api/basic_json/is_number_float), [is_object](https://json.nlohmann.me/api/basic_json/is_object), [is_array](https://json.nlohmann.me/api/basic_json/is_array), [is_string](https://json.nlohmann.me/api/basic_json/is_string), [is_binary](https://json.nlohmann.me/api/basic_json/is_binary), [is_discarded](https://json.nlohmann.me/api/basic_json/is_discarded)\n- **Value access**; [get](https://json.nlohmann.me/api/basic_json/get), [get_to](https://json.nlohmann.me/api/basic_json/get_to), [get_ptr](https://json.nlohmann.me/api/basic_json/get_ptr), [get_ref](https://json.nlohmann.me/api/basic_json/get_ref), [operator ValueType](https://json.nlohmann.me/api/basic_json/operator_ValueType), [get_binary](https://json.nlohmann.me/api/basic_json/get_binary)\n- **Element access**: [at](https://json.nlohmann.me/api/basic_json/at), [operator[]](https://json.nlohmann.me/api/basic_json/operator[]), [value](https://json.nlohmann.me/api/basic_json/value), [front](https://json.nlohmann.me/api/basic_json/front), [back](https://json.nlohmann.me/api/basic_json/back)\n- **Lookup**: [find](https://json.nlohmann.me/api/basic_json/find), [count](https://json.nlohmann.me/api/basic_json/count), [contains](https://json.nlohmann.me/api/basic_json/contains)\n- **Iterators**: [begin](https://json.nlohmann.me/api/basic_json/begin), [cbegin](https://json.nlohmann.me/api/basic_json/cbegin), [end](https://json.nlohmann.me/api/basic_json/end), [cend](https://json.nlohmann.me/api/basic_json/cend), [rbegin](https://json.nlohmann.me/api/basic_json/rbegin), [rend](https://json.nlohmann.me/api/basic_json/rend), [crbegin](https://json.nlohmann.me/api/basic_json/crbegin), [crend](https://json.nlohmann.me/api/basic_json/crend), [items](https://json.nlohmann.me/api/basic_json/items)\n- **Capacity**: [empty](https://json.nlohmann.me/api/basic_json/empty), [size](https://json.nlohmann.me/api/basic_json/size), [max_size](https://json.nlohmann.me/api/basic_json/max_size)\n- **Modifiers**: [clear](https://json.nlohmann.me/api/basic_json/clear), [push_back](https://json.nlohmann.me/api/basic_json/push_back), [operator+=](https://json.nlohmann.me/api/basic_json/operator+=), [emplace_back](https://json.nlohmann.me/api/basic_json/emplace_back), [emplace](https://json.nlohmann.me/api/basic_json/emplace), [erase](https://json.nlohmann.me/api/basic_json/erase), [insert](https://json.nlohmann.me/api/basic_json/insert), [update](https://json.nlohmann.me/api/basic_json/update), [swap](https://json.nlohmann.me/api/basic_json/swap)\n- **Lexicographical comparison operators**: [operator==](https://json.nlohmann.me/api/basic_json/operator_eq), [operator!=](https://json.nlohmann.me/api/basic_json/operator_ne), [operator<](https://json.nlohmann.me/api/basic_json/operator_lt), [operator>](https://json.nlohmann.me/api/basic_json/operator_gt), [operator<=](https://json.nlohmann.me/api/basic_json/operator_le), [operator>=](https://json.nlohmann.me/api/basic_json/operator_ge), [operator<=>](https://json.nlohmann.me/api/basic_json/operator_spaceship)\n- **Serialization / Dumping**: [dump](https://json.nlohmann.me/api/basic_json/dump)\n- **Deserialization / Parsing**: [parse](https://json.nlohmann.me/api/basic_json/parse), [accept](https://json.nlohmann.me/api/basic_json/accept), [sax_parse](https://json.nlohmann.me/api/basic_json/sax_parse)\n- **JSON Pointer functions**: [flatten](https://json.nlohmann.me/api/basic_json/flatten), [unflatten](https://json.nlohmann.me/api/basic_json/unflatten)\n- **JSON Patch functions**: [patch](https://json.nlohmann.me/api/basic_json/patch), [patch_inplace](https://json.nlohmann.me/api/basic_json/patch_inplace), [diff](https://json.nlohmann.me/api/basic_json/diff), [merge_patch](https://json.nlohmann.me/api/basic_json/merge_patch)\n- **Static functions**: [meta](https://json.nlohmann.me/api/basic_json/meta), [get_allocator](https://json.nlohmann.me/api/basic_json/get_allocator)\n- **Binary formats**: [from_bjdata](https://json.nlohmann.me/api/basic_json/from_bjdata), [from_bson](https://json.nlohmann.me/api/basic_json/from_bson), [from_cbor](https://json.nlohmann.me/api/basic_json/from_cbor), [from_msgpack](https://json.nlohmann.me/api/basic_json/from_msgpack), [from_ubjson](https://json.nlohmann.me/api/basic_json/from_ubjson), [to_bjdata](https://json.nlohmann.me/api/basic_json/to_bjdata), [to_bson](https://json.nlohmann.me/api/basic_json/to_bson), [to_cbor](https://json.nlohmann.me/api/basic_json/to_cbor), [to_msgpack](https://json.nlohmann.me/api/basic_json/to_msgpack), [to_ubjson](https://json.nlohmann.me/api/basic_json/to_ubjson)\n- **Non-member functions**: [operator<<](https://json.nlohmann.me/api/operator_ltlt/), [operator>>](https://json.nlohmann.me/api/operator_gtgt/), [to_string](https://json.nlohmann.me/api/basic_json/to_string)\n- **Literals**: [operator\"\"_json](https://json.nlohmann.me/api/operator_literal_json)\n- **Helper classes**: [std::hash&lt;basic_json&gt;](https://json.nlohmann.me/api/basic_json/std_hash), [std::swap&lt;basic_json&gt;](https://json.nlohmann.me/api/basic_json/std_swap)\n\n[**Full API documentation**](https://json.nlohmann.me/api/basic_json/)\n\n## Examples\n\nHere are some examples to give you an idea how to use the class.\n\nBesides the examples below, you may want to:\n\n‚Üí Check the [documentation](https://json.nlohmann.me/)\\\n‚Üí Browse the [standalone example files](https://github.com/nlohmann/json/tree/develop/docs/mkdocs/docs/examples)\\\n‚Üí Read the full [API Documentation](https://json.nlohmann.me/api/basic_json/) with self-contained examples for every function\n\n### Read JSON from a file\n\nThe `json` class provides an API for manipulating a JSON value. To create a `json` object by reading a JSON file:\n\n```cpp\n#include <fstream>\n#include <nlohmann/json.hpp>\nusing json = nlohmann::json;\n\n// ...\n\nstd::ifstream f(\"example.json\");\njson data = json::parse(f);\n```\n\nIf using modules (enabled with `NLOHMANN_JSON_BUILD_MODULES`), this example becomes:\n```cpp\nimport std;\nimport nlohmann.json;\n\nusing json = nlohmann::json;\n\n// ...\n\nstd::ifstream f(\"example.json\");\njson data = json::parse(f);\n```\n\n### Creating `json` objects from JSON literals\n\nAssume you want to create hard-code this literal JSON value in a file, as a `json` object:\n\n```json\n{\n  \"pi\": 3.141,\n  \"happy\": true\n}\n```\n\nThere are various options:\n\n```cpp\n// Using (raw) string literals and json::parse\njson ex1 = json::parse(R\"(\n  {\n    \"pi\": 3.141,\n    \"happy\": true\n  }\n)\");\n\n// Using user-defined (raw) string literals\nusing namespace nlohmann::literals;\njson ex2 = R\"(\n  {\n    \"pi\": 3.141,\n    \"happy\": true\n  }\n)\"_json;\n\n// Using initializer lists\njson ex3 = {\n  {\"happy\", true},\n  {\"pi\", 3.141},\n};\n```\n\n### JSON as a first-class data type\n\nHere are some examples to give you an idea how to use the class.\n\nAssume you want to create the JSON object\n\n```json\n{\n  \"pi\": 3.141,\n  \"happy\": true,\n  \"name\": \"Niels\",\n  \"nothing\": null,\n  \"answer\": {\n    \"everything\": 42\n  },\n  \"list\": [1, 0, 2],\n  \"object\": {\n    \"currency\": \"USD\",\n    \"value\": 42.99\n  }\n}\n```\n\nWith this library, you could write:\n\n```cpp\n// create an empty structure (null)\njson j;\n\n// add a number stored as double (note the implicit conversion of j to an object)\nj[\"pi\"] = 3.141;\n\n// add a Boolean stored as bool\nj[\"happy\"] = true;\n\n// add a string stored as std::string\nj[\"name\"] = \"Niels\";\n\n// add another null object by passing nullptr\nj[\"nothing\"] = nullptr;\n\n// add an object inside the object\nj[\"answer\"][\"everything\"] = 42;\n\n// add an array stored as std::vector (using an initializer list)\nj[\"list\"] = { 1, 0, 2 };\n\n// add another object (using an initializer list of pairs)\nj[\"object\"] = { {\"currency\", \"USD\"}, {\"value\", 42.99} };\n\n// instead, you could also write (which looks very similar to the JSON above)\njson j2 = {\n  {\"pi\", 3.141},\n  {\"happy\", true},\n  {\"name\", \"Niels\"},\n  {\"nothing\", nullptr},\n  {\"answer\", {\n    {\"everything\", 42}\n  }},\n  {\"list\", {1, 0, 2}},\n  {\"object\", {\n    {\"currency\", \"USD\"},\n    {\"value\", 42.99}\n  }}\n};\n```\n\nNote that in all these cases, you never need to \"tell\" the compiler which JSON value type you want to use. If you want to be explicit or express some edge cases, the functions [`json::array()`](https://json.nlohmann.me/api/basic_json/array/) and [`json::object()`](https://json.nlohmann.me/api/basic_json/object/) will help:\n\n```cpp\n// a way to express the empty array []\njson empty_array_explicit = json::array();\n\n// ways to express the empty object {}\njson empty_object_implicit = json({});\njson empty_object_explicit = json::object();\n\n// a way to express an _array_ of key/value pairs [[\"currency\", \"USD\"], [\"value\", 42.99]]\njson array_not_object = json::array({ {\"currency\", \"USD\"}, {\"value\", 42.99} });\n```\n\n### Serialization / Deserialization\n\n#### To/from strings\n\nYou can create a JSON value (deserialization) by appending `_json` to a string literal:\n\n```cpp\n// create object from string literal\njson j = \"{ \\\"happy\\\": true, \\\"pi\\\": 3.141 }\"_json;\n\n// or even nicer with a raw string literal\nauto j2 = R\"(\n  {\n    \"happy\": true,\n    \"pi\": 3.141\n  }\n)\"_json;\n```\n\nNote that without appending the `_json` suffix, the passed string literal is not parsed, but just used as JSON string\nvalue. That is, `json j = \"{ \\\"happy\\\": true, \\\"pi\\\": 3.141 }\"` would just store the string\n`\"{ \"happy\": true, \"pi\": 3.141 }\"` rather than parsing the actual object.\n\nThe string literal should be brought into scope with `using namespace nlohmann::literals;`\n(see [`json::parse()`](https://json.nlohmann.me/api/operator_literal_json/)).\n\nThe above example can also be expressed explicitly using [`json::parse()`](https://json.nlohmann.me/api/basic_json/parse/):\n\n```cpp\n// parse explicitly\nauto j3 = json::parse(R\"({\"happy\": true, \"pi\": 3.141})\");\n```\n\nYou can also get a string representation of a JSON value (serialize):\n\n```cpp\n// explicit conversion to string\nstd::string s = j.dump();    // {\"happy\":true,\"pi\":3.141}\n\n// serialization with pretty printing\n// pass in the amount of spaces to indent\nstd::cout << j.dump(4) << std::endl;\n// {\n//     \"happy\": true,\n//     \"pi\": 3.141\n// }\n```\n\nNote the difference between serialization and assignment:\n\n```cpp\n// store a string in a JSON value\njson j_string = \"this is a string\";\n\n// retrieve the string value\nauto cpp_string = j_string.get<std::string>();\n// retrieve the string value (alternative when a variable already exists)\nstd::string cpp_string2;\nj_string.get_to(cpp_string2);\n\n// retrieve the serialized value (explicit JSON serialization)\nstd::string serialized_string = j_string.dump();\n\n// output of original string\nstd::cout << cpp_string << \" == \" << cpp_string2 << \" == \" << j_string.get<std::string>() << '\\n';\n// output of serialized value\nstd::cout << j_string << \" == \" << serialized_string << std::endl;\n```\n\n[`.dump()`](https://json.nlohmann.me/api/basic_json/dump/) returns the originally stored string value.\n\nNote the library only supports UTF-8. When you store strings with different encodings in the library, calling [`dump()`](https://json.nlohmann.me/api/basic_json/dump/) may throw an exception unless `json::error_handler_t::replace` or `json::error_handler_t::ignore` are used as error handlers.\n\n#### To/from streams (e.g., files, string streams)\n\nYou can also use streams to serialize and deserialize:\n\n```cpp\n// deserialize from standard input\njson j;\nstd::cin >> j;\n\n// serialize to standard output\nstd::cout << j;\n\n// the setw manipulator was overloaded to set the indentation for pretty printing\nstd::cout << std::setw(4) << j << std::endl;\n```\n\nThese operators work for any subclasses of `std::istream` or `std::ostream`. Here is the same example with files:\n\n```cpp\n// read a JSON file\nstd::ifstream i(\"file.json\");\njson j;\ni >> j;\n\n// write prettified JSON to another file\nstd::ofstream o(\"pretty.json\");\no << std::setw(4) << j << std::endl;\n```\n\nPlease note that setting the exception bit for `failbit` is inappropriate for this use case. It will result in program termination due to the `noexcept` specifier in use.\n\n#### Read from iterator range\n\nYou can also parse JSON from an iterator range; that is, from any container accessible by iterators whose `value_type` is an integral type of 1, 2, or 4 bytes, which will be interpreted as UTF-8, UTF-16, and UTF-32 respectively. For instance, a `std::vector<std::uint8_t>`, or a `std::list<std::uint16_t>`:\n\n```cpp\nstd::vector<std::uint8_t> v = {'t', 'r', 'u', 'e'};\njson j = json::parse(v.begin(), v.end());\n```\n\nYou may leave the iterators for the range [begin, end):\n\n```cpp\nstd::vector<std::uint8_t> v = {'t', 'r', 'u', 'e'};\njson j = json::parse(v);\n```\n\n#### Custom data source\n\nSince the parse function accepts arbitrary iterator ranges, you can provide your own data sources by implementing the `LegacyInputIterator` concept.\n\n```cpp\nstruct MyContainer {\n  void advance();\n  const char& get_current();\n};\n\nstruct MyIterator {\n    using difference_type = std::ptrdiff_t;\n    using value_type = char;\n    using pointer = const char*;\n    using reference = const char&;\n    using iterator_category = std::input_iterator_tag;\n\n    MyIterator& operator++() {\n        target->advance();\n        return *this;\n    }\n\n    bool operator!=(const MyIterator& rhs) const {\n        return rhs.target != target;\n    }\n\n    reference operator*() const {\n        return target->get_current();\n    }\n\n    MyContainer* target = nullptr;\n};\n\nMyIterator begin(MyContainer& tgt) {\n    return MyIterator{&tgt};\n}\n\nMyIterator end(const MyContainer&) {\n    return {};\n}\n\nvoid foo() {\n    MyContainer c;\n    json j = json::parse(c);\n}\n```\n\n#### SAX interface\n\nThe library uses a SAX-like interface with the following functions:\n\n```cpp\n// called when null is parsed\nbool null();\n\n// called when a boolean is parsed; value is passed\nbool boolean(bool val);\n\n// called when a signed or unsigned integer number is parsed; value is passed\nbool number_integer(number_integer_t val);\nbool number_unsigned(number_unsigned_t val);\n\n// called when a floating-point number is parsed; value and original string is passed\nbool number_float(number_float_t val, const string_t& s);\n\n// called when a string is parsed; value is passed and can be safely moved away\nbool string(string_t& val);\n// called when a binary value is parsed; value is passed and can be safely moved away\nbool binary(binary_t& val);\n\n// called when an object or array begins or ends, resp. The number of elements is passed (or -1 if not known)\nbool start_object(std::size_t elements);\nbool end_object();\nbool start_array(std::size_t elements);\nbool end_array();\n// called when an object key is parsed; value is passed and can be safely moved away\nbool key(string_t& val);\n\n// called when a parse error occurs; byte position, the last token, and an exception is passed\nbool parse_error(std::size_t position, const std::string& last_token, const detail::exception& ex);\n```\n\nThe return value of each function determines whether parsing should proceed.\n\nTo implement your own SAX handler, proceed as follows:\n\n1. Implement the SAX interface in a class. You can use class `nlohmann::json_sax<json>` as base class, but you can also use any class where the functions described above are implemented and public.\n2. Create an object of your SAX interface class, e.g. `my_sax`.\n3. Call `bool json::sax_parse(input, &my_sax)`; where the first parameter can be any input like a string or an input stream and the second parameter is a pointer to your SAX interface.\n\nNote the `sax_parse` function only returns a `bool` indicating the result of the last executed SAX event. It does not return a  `json` value - it is up to you to decide what to do with the SAX events. Furthermore, no exceptions are thrown in case of a parse error -- it is up to you what to do with the exception object passed to your `parse_error` implementation. Internally, the SAX interface is used for the DOM parser (class `json_sax_dom_parser`) as well as the acceptor (`json_sax_acceptor`), see file [`json_sax.hpp`](https://github.com/nlohmann/json/blob/develop/include/nlohmann/detail/input/json_sax.hpp).\n\n### STL-like access\n\nWe designed the JSON class to behave just like an STL container. In fact, it satisfies the [**ReversibleContainer**](https://en.cppreference.com/w/cpp/named_req/ReversibleContainer) requirement.\n\n```cpp\n// create an array using push_back\njson j;\nj.push_back(\"foo\");\nj.push_back(1);\nj.push_back(true);\n\n// also use emplace_back\nj.emplace_back(1.78);\n\n// iterate the array\nfor (json::iterator it = j.begin(); it != j.end(); ++it) {\n  std::cout << *it << '\\n';\n}\n\n// range-based for\nfor (auto& element : j) {\n  std::cout << element << '\\n';\n}\n\n// getter/setter\nconst auto tmp = j[0].get<std::string>();\nj[1] = 42;\nbool foo = j.at(2);\n\n// comparison\nj == R\"([\"foo\", 1, true, 1.78])\"_json;  // true\n\n// other stuff\nj.size();     // 4 entries\nj.empty();    // false\nj.type();     // json::value_t::array\nj.clear();    // the array is empty again\n\n// convenience type checkers\nj.is_null();\nj.is_boolean();\nj.is_number();\nj.is_object();\nj.is_array();\nj.is_string();\n\n// create an object\njson o;\no[\"foo\"] = 23;\no[\"bar\"] = false;\no[\"baz\"] = 3.141;\n\n// also use emplace\no.emplace(\"weather\", \"sunny\");\n\n// special iterator member functions for objects\nfor (json::iterator it = o.begin(); it != o.end(); ++it) {\n  std::cout << it.key() << \" : \" << it.value() << \"\\n\";\n}\n\n// the same code as range for\nfor (auto& el : o.items()) {\n  std::cout << el.key() << \" : \" << el.value() << \"\\n\";\n}\n\n// even easier with structured bindings (C++17)\nfor (auto& [key, value] : o.items()) {\n  std::cout << key << \" : \" << value << \"\\n\";\n}\n\n// find an entry\nif (o.contains(\"foo\")) {\n  // there is an entry with key \"foo\"\n}\n\n// or via find and an iterator\nif (o.find(\"foo\") != o.end()) {\n  // there is an entry with key \"foo\"\n}\n\n// or simpler using count()\nint foo_present = o.count(\"foo\"); // 1\nint fob_present = o.count(\"fob\"); // 0\n\n// delete an entry\no.erase(\"foo\");\n```\n\n### Conversion from STL containers\n\nAny sequence container (`std::array`, `std::vector`, `std::deque`, `std::forward_list`, `std::list`) whose values can be used to construct JSON values (e.g., integers, floating point numbers, Booleans, string types, or again STL containers described in this section) can be used to create a JSON array. The same holds for similar associative containers (`std::set`, `std::multiset`, `std::unordered_set`, `std::unordered_multiset`), but in these cases the order of the elements of the array depends on how the elements are ordered in the respective STL container.\n\n```cpp\nstd::vector<int> c_vector {1, 2, 3, 4};\njson j_vec(c_vector);\n// [1, 2, 3, 4]\n\nstd::deque<double> c_deque {1.2, 2.3, 3.4, 5.6};\njson j_deque(c_deque);\n// [1.2, 2.3, 3.4, 5.6]\n\nstd::list<bool> c_list {true, true, false, true};\njson j_list(c_list);\n// [true, true, false, true]\n\nstd::forward_list<int64_t> c_flist {12345678909876, 23456789098765, 34567890987654, 45678909876543};\njson j_flist(c_flist);\n// [12345678909876, 23456789098765, 34567890987654, 45678909876543]\n\nstd::array<unsigned long, 4> c_array {{1, 2, 3, 4}};\njson j_array(c_array);\n// [1, 2, 3, 4]\n\nstd::set<std::string> c_set {\"one\", \"two\", \"three\", \"four\", \"one\"};\njson j_set(c_set); // only one entry for \"one\" is used\n// [\"four\", \"one\", \"three\", \"two\"]\n\nstd::unordered_set<std::string> c_uset {\"one\", \"two\", \"three\", \"four\", \"one\"};\njson j_uset(c_uset); // only one entry for \"one\" is used\n// maybe [\"two\", \"three\", \"four\", \"one\"]\n\nstd::multiset<std::string> c_mset {\"one\", \"two\", \"one\", \"four\"};\njson j_mset(c_mset); // both entries for \"one\" are used\n// maybe [\"one\", \"two\", \"one\", \"four\"]\n\nstd::unordered_multiset<std::string> c_umset {\"one\", \"two\", \"one\", \"four\"};\njson j_umset(c_umset); // both entries for \"one\" are used\n// maybe [\"one\", \"two\", \"one\", \"four\"]\n```\n\nLikewise, any associative key-value containers (`std::map`, `std::multimap`, `std::unordered_map`, `std::unordered_multimap`) whose keys can construct an `std::string` and whose values can be used to construct JSON values (see examples above) can be used to create a JSON object. Note that in case of multimaps, only one key is used in the JSON object and the value depends on the internal order of the STL container.\n\n```cpp\nstd::map<std::string, int> c_map { {\"one\", 1}, {\"two\", 2}, {\"three\", 3} };\njson j_map(c_map);\n// {\"one\": 1, \"three\": 3, \"two\": 2 }\n\nstd::unordered_map<const char*, double> c_umap { {\"one\", 1.2}, {\"two\", 2.3}, {\"three\", 3.4} };\njson j_umap(c_umap);\n// {\"one\": 1.2, \"two\": 2.3, \"three\": 3.4}\n\nstd::multimap<std::string, bool> c_mmap { {\"one\", true}, {\"two\", true}, {\"three\", false}, {\"three\", true} };\njson j_mmap(c_mmap); // only one entry for key \"three\" is used\n// maybe {\"one\": true, \"two\": true, \"three\": true}\n\nstd::unordered_multimap<std::string, bool> c_ummap { {\"one\", true}, {\"two\", true}, {\"three\", false}, {\"three\", true} };\njson j_ummap(c_ummap); // only one entry for key \"three\" is used\n// maybe {\"one\": true, \"two\": true, \"three\": true}\n```\n\n### JSON Pointer and JSON Patch\n\nThe library supports **JSON Pointer** ([RFC 6901](https://tools.ietf.org/html/rfc6901)) as an alternative means to address structured values. On top of this, **JSON Patch** ([RFC 6902](https://tools.ietf.org/html/rfc6902)) allows describing differences between two JSON values -- effectively allowing patch and diff operations known from Unix.\n\n```cpp\n// a JSON value\njson j_original = R\"({\n  \"baz\": [\"one\", \"two\", \"three\"],\n  \"foo\": \"bar\"\n})\"_json;\n\n// access members with a JSON pointer (RFC 6901)\nj_original[\"/baz/1\"_json_pointer];\n// \"two\"\n\n// a JSON patch (RFC 6902)\njson j_patch = R\"([\n  { \"op\": \"replace\", \"path\": \"/baz\", \"value\": \"boo\" },\n  { \"op\": \"add\", \"path\": \"/hello\", \"value\": [\"world\"] },\n  { \"op\": \"remove\", \"path\": \"/foo\"}\n])\"_json;\n\n// apply the patch\njson j_result = j_original.patch(j_patch);\n// {\n//    \"baz\": \"boo\",\n//    \"hello\": [\"world\"]\n// }\n\n// calculate a JSON patch from two JSON values\njson::diff(j_result, j_original);\n// [\n//   { \"op\":\" replace\", \"path\": \"/baz\", \"value\": [\"one\", \"two\", \"three\"] },\n//   { \"op\": \"remove\",\"path\": \"/hello\" },\n//   { \"op\": \"add\", \"path\": \"/foo\", \"value\": \"bar\" }\n// ]\n```\n\n### JSON Merge Patch\n\nThe library supports **JSON Merge Patch** ([RFC 7386](https://tools.ietf.org/html/rfc7386)) as a patch format. Instead of using JSON Pointer (see above) to specify values to be manipulated, it describes the changes using a syntax that closely mimics the document being modified.\n\n```cpp\n// a JSON value\njson j_document = R\"({\n  \"a\": \"b\",\n  \"c\": {\n    \"d\": \"e\",\n    \"f\": \"g\"\n  }\n})\"_json;\n\n// a patch\njson j_patch = R\"({\n  \"a\":\"z\",\n  \"c\": {\n    \"f\": null\n  }\n})\"_json;\n\n// apply the patch\nj_document.merge_patch(j_patch);\n// {\n//  \"a\": \"z\",\n//  \"c\": {\n//    \"d\": \"e\"\n//  }\n// }\n```\n\n### Implicit conversions\n\nSupported types can be implicitly converted to JSON values.\n\nIt is recommended to **NOT USE** implicit conversions **FROM** a JSON value.\nYou can find more details about this recommendation [here](https://www.github.com/nlohmann/json/issues/958).\nYou can switch off implicit conversions by defining `JSON_USE_IMPLICIT_CONVERSIONS` to `0` before including the `json.hpp` header. When using CMake, you can also achieve this by setting the option `JSON_ImplicitConversions` to `OFF`.\n\n```cpp\n// strings\nstd::string s1 = \"Hello, world!\";\njson js = s1;\nauto s2 = js.get<std::string>();\n// NOT RECOMMENDED\nstd::string s3 = js;\nstd::string s4;\ns4 = js;\n\n// Booleans\nbool b1 = true;\njson jb = b1;\nauto b2 = jb.get<bool>();\n// NOT RECOMMENDED\nbool b3 = jb;\nbool b4;\nb4 = jb;\n\n// numbers\nint i = 42;\njson jn = i;\nauto f = jn.get<double>();\n// NOT RECOMMENDED\ndouble f2 = jb;\ndouble f3;\nf3 = jb;\n\n// etc.\n```\n\nNote that `char` types are not automatically converted to JSON strings, but to integer numbers. A conversion to a string must be specified explicitly:\n\n```cpp\nchar ch = 'A';                       // ASCII value 65\njson j_default = ch;                 // stores integer number 65\njson j_string = std::string(1, ch);  // stores string \"A\"\n```\n\n### Arbitrary types conversions\n\nEvery type can be serialized in JSON, not just STL containers and scalar types. Usually, you would do something along those lines:\n\n```cpp\nnamespace ns {\n    // a simple struct to model a person\n    struct person {\n        std::string name;\n        std::string address;\n        int age;\n    };\n}\n\nns::person p = {\"Ned Flanders\", \"744 Evergreen Terrace\", 60};\n\n// convert to JSON: copy each value into the JSON object\njson j;\nj[\"name\"] = p.name;\nj[\"address\"] = p.address;\nj[\"age\"] = p.age;\n\n// ...\n\n// convert from JSON: copy each value from the JSON object\nns::person p {\n    j[\"name\"].get<std::string>(),\n    j[\"address\"].get<std::string>(),\n    j[\"age\"].get<int>()\n};\n```\n\nIt works, but that's quite a lot of boilerplate... Fortunately, there's a better way:\n\n```cpp\n// create a person\nns::person p {\"Ned Flanders\", \"744 Evergreen Terrace\", 60};\n\n// conversion: person -> json\njson j = p;\n\nstd::cout << j << std::endl;\n// {\"address\":\"744 Evergreen Terrace\",\"age\":60,\"name\":\"Ned Flanders\"}\n\n// conversion: json -> person\nauto p2 = j.get<ns::person>();\n\n// that's it\nassert(p == p2);\n```\n\n#### Basic usage\n\nTo make this work with one of your types, you only need to provide two functions:\n\n```cpp\nusing json = nlohmann::json;\n\nnamespace ns {\n    void to_json(json& j, const person& p) {\n        j = json{{\"name\", p.name}, {\"address\", p.address}, {\"age\", p.age}};\n    }\n\n    void from_json(const json& j, person& p) {\n        j.at(\"name\").get_to(p.name);\n        j.at(\"address\").get_to(p.address);\n        j.at(\"age\").get_to(p.age);\n    }\n} // namespace ns\n```\n\nThat's all! When calling the `json` constructor with your type, your custom `to_json` method will be automatically called.\nLikewise, when calling `get<your_type>()` or `get_to(your_type&)`, the `from_json` method will be called.\n\nSome important things:\n\n- Those methods **MUST** be in your type's namespace (which can be the global namespace), or the library will not be able to locate them (in this example, they are in namespace `ns`, where `person` is defined).\n- Those methods **MUST** be available (e.g., proper headers must be included) everywhere you use these conversions. Look at [issue 1108](https://github.com/nlohmann/json/issues/1108) for errors that may occur otherwise.\n- When using `get<your_type>()`, `your_type` **MUST** be [DefaultConstructible](https://en.cppreference.com/w/cpp/named_req/DefaultConstructible). (There is a way to bypass this requirement described later.)\n- In function `from_json`, use function [`at()`](https://json.nlohmann.me/api/basic_json/at/) to access the object values rather than `operator[]`. In case a key does not exist, `at` throws an exception that you can handle, whereas `operator[]` exhibits undefined behavior.\n- You do not need to add serializers or deserializers for STL types like `std::vector`: the library already implements these.\n\n#### Simplify your life with macros\n\nIf you just want to serialize/deserialize some structs, the `to_json`/`from_json` functions can be a lot of boilerplate. There are [**several macros**](https://json.nlohmann.me/features/arbitrary_types/#simplify-your-life-with-macros) to make your life easier as long as you (1) want to use a JSON object as serialization and (2) want to use the member variable names as object keys in that object.\n\nWhich macro to choose depends on whether private member variables need to be accessed, a deserialization is needed, missing values should yield an error or should be replaced by default values, and if derived classes are used. See [this overview to choose the right one for your use case](https://json.nlohmann.me/api/macros/#serializationdeserialization-macros).\n\n##### Example usage of macros\n\nThe `to_json`/`from_json` functions for the `person` struct above can be created with [`NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE`](https://json.nlohmann.me/api/macros/nlohmann_define_type_non_intrusive/). In all macros, the first parameter is the name of the class/struct, and all remaining parameters name the members.\n\n```cpp\nnamespace ns {\n    NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE(person, name, address, age)\n}\n```\n\nHere is another example with private members, where [`NLOHMANN_DEFINE_TYPE_INTRUSIVE`](https://json.nlohmann.me/api/macros/nlohmann_define_type_intrusive/) is needed:\n\n```cpp\nnamespace ns {\n    class address {\n      private:\n        std::string street;\n        int housenumber;\n        int postcode;\n  \n      public:\n        NLOHMANN_DEFINE_TYPE_INTRUSIVE(address, street, housenumber, postcode)\n    };\n}\n```\n\n#### How do I convert third-party types?\n\nThis requires a bit more advanced technique. But first, let's see how this conversion mechanism works:\n\nThe library uses **JSON Serializers** to convert types to JSON.\nThe default serializer for `nlohmann::json` is `nlohmann::adl_serializer` (ADL means [Argument-Dependent Lookup](https://en.cppreference.com/w/cpp/language/adl)).\n\nIt is implemented like this (simplified):\n\n```cpp\ntemplate <typename T>\nstruct adl_serializer {\n    static void to_json(json& j, const T& value) {\n        // calls the \"to_json\" method in T's namespace\n    }\n\n    static void from_json(const json& j, T& value) {\n        // same thing, but with the \"from_json\" method\n    }\n};\n```\n\nThis serializer works fine when you have control over the type's namespace. However, what about `boost::optional` or `std::filesystem::path` (C++17)? Hijacking the `boost` namespace is pretty bad, and it's illegal to add something other than template specializations to `std`...\n\nTo solve this, you need to add a specialization of `adl_serializer` to the `nlohmann` namespace, here's an example:\n\n```cpp\n// partial specialization (full specialization works too)\nnamespace nlohmann {\n    template <typename T>\n    struct adl_serializer<boost::optional<T>> {\n        static void to_json(json& j, const boost::optional<T>& opt) {\n            if (opt == boost::none) {\n                j = nullptr;\n            } else {\n              j = *opt; // this will call adl_serializer<T>::to_json which will\n                        // find the free function to_json in T's namespace!\n            }\n        }\n\n        static void from_json(const json& j, boost::optional<T>& opt) {\n            if (j.is_null()) {\n                opt = boost::none;\n            } else {\n                opt = j.get<T>(); // same as above, but with\n                                  // adl_serializer<T>::from_json\n            }\n        }\n    };\n}\n```\n\n#### How can I use `get()` for non-default constructible/non-copyable types?\n\nThere is a way if your type is [MoveConstructible](https://en.cppreference.com/w/cpp/named_req/MoveConstructible). You will need to specialize the `adl_serializer` as well, but with a special `from_json` overload:\n\n```cpp\nstruct move_only_type {\n    move_only_type() = delete;\n    move_only_type(int ii): i(ii) {}\n    move_only_type(const move_only_type&) = delete;\n    move_only_type(move_only_type&&) = default;\n\n    int i;\n};\n\nnamespace nlohmann {\n    template <>\n    struct adl_serializer<move_only_type> {\n        // note: the return type is no longer 'void', and the method only takes\n        // one argument\n        static move_only_type from_json(const json& j) {\n            return {j.get<int>()};\n        }\n\n        // Here's the catch! You must provide a to_json method! Otherwise, you\n        // will not be able to convert move_only_type to json, since you fully\n        // specialized adl_serializer on that type\n        static void to_json(json& j, move_only_type t) {\n            j = t.i;\n        }\n    };\n}\n```\n\n#### Can I write my own serializer? (Advanced use)\n\nYes. You might want to take a look at [`unit-udt.cpp`](https://github.com/nlohmann/json/blob/develop/tests/src/unit-udt.cpp) in the test suite, to see a few examples.\n\nIf you write your own serializer, you'll need to do a few things:\n\n- use a different `basic_json` alias than `nlohmann::json` (the last template parameter of `basic_json` is the `JSONSerializer`)\n- use your `basic_json` alias (or a template parameter) in all your `to_json`/`from_json` methods\n- use `nlohmann::to_json` and `nlohmann::from_json` when you need ADL\n\nHere is an example, without simplifications, that only accepts types with a size <= 32, and uses ADL.\n\n```cpp\n// You should use void as a second template argument\n// if you don't need compile-time checks on T\ntemplate<typename T, typename SFINAE = typename std::enable_if<sizeof(T) <= 32>::type>\nstruct less_than_32_serializer {\n    template <typename BasicJsonType>\n    static void to_json(BasicJsonType& j, T value) {\n        // we want to use ADL, and call the correct to_json overload\n        using nlohmann::to_json; // this method is called by adl_serializer,\n                                 // this is where the magic happens\n        to_json(j, value);\n    }\n\n    template <typename BasicJsonType>\n    static void from_json(const BasicJsonType& j, T& value) {\n        // same thing here\n        using nlohmann::from_json;\n        from_json(j, value);\n    }\n};\n```\n\nBe **very** careful when reimplementing your serializer, you can stack overflow if you don't pay attention:\n\n```cpp\ntemplate <typename T, void>\nstruct bad_serializer\n{\n    template <typename BasicJsonType>\n    static void to_json(BasicJsonType& j, const T& value) {\n      // this calls BasicJsonType::json_serializer<T>::to_json(j, value)\n      // if BasicJsonType::json_serializer == bad_serializer ... oops!\n      j = value;\n    }\n\n    template <typename BasicJsonType>\n    static void to_json(const BasicJsonType& j, T& value) {\n      // this calls BasicJsonType::json_serializer<T>::from_json(j, value)\n      // if BasicJsonType::json_serializer == bad_serializer ... oops!\n      value = j.get<T>(); // oops!\n    }\n};\n```\n\n### Specializing enum conversion\n\nBy default, enum values are serialized to JSON as integers. In some cases, this could result in undesired behavior. If an enum is modified or re-ordered after data has been serialized to JSON, the later deserialized JSON data may be undefined or a different enum value than was originally intended.\n\nIt is possible to more precisely specify how a given enum is mapped to and from JSON as shown below:\n\n```cpp\n// example enum type declaration\nenum TaskState {\n    TS_STOPPED,\n    TS_RUNNING,\n    TS_COMPLETED,\n    TS_INVALID=-1,\n};\n\n// map TaskState values to JSON as strings\nNLOHMANN_JSON_SERIALIZE_ENUM( TaskState, {\n    {TS_INVALID, nullptr},\n    {TS_STOPPED, \"stopped\"},\n    {TS_RUNNING, \"running\"},\n    {TS_COMPLETED, \"completed\"},\n})\n```\n\nThe `NLOHMANN_JSON_SERIALIZE_ENUM()` macro declares a set of `to_json()` / `from_json()` functions for type `TaskState` while avoiding repetition and boilerplate serialization code.\n\n**Usage:**\n\n```cpp\n// enum to JSON as string\njson j = TS_STOPPED;\nassert(j == \"stopped\");\n\n// json string to enum\njson j3 = \"running\";\nassert(j3.get<TaskState>() == TS_RUNNING);\n\n// undefined json value to enum (where the first map entry above is the default)\njson jPi = 3.14;\nassert(jPi.get<TaskState>() == TS_INVALID);\n```\n\nJust as in [Arbitrary Type Conversions](#arbitrary-types-conversions) above,\n\n- `NLOHMANN_JSON_SERIALIZE_ENUM()` MUST be declared in your enum type's namespace (which can be the global namespace), or the library will not be able to locate it, and it will default to integer serialization.\n- It MUST be available (e.g., proper headers must be included) everywhere you use the conversions.\n\nOther Important points:\n\n- When using `get<ENUM_TYPE>()`, undefined JSON values will default to the first pair specified in your map. Select this default pair carefully.\n- If an enum or JSON value is specified more than once in your map, the first matching occurrence from the top of the map will be returned when converting to or from JSON.\n\n### Binary formats (BSON, CBOR, MessagePack, UBJSON, and BJData)\n\nThough JSON is a ubiquitous data format, it is not a very compact format suitable for data exchange, for instance over a network. Hence, the library supports [BSON](https://bsonspec.org) (Binary JSON), [CBOR](https://cbor.io) (Concise Binary Object Representation), [MessagePack](https://msgpack.org), [UBJSON](https://ubjson.org) (Universal Binary JSON Specification) and [BJData](https://neurojson.org/bjdata) (Binary JData) to efficiently encode JSON values to byte vectors and to decode such vectors.\n\n```cpp\n// create a JSON value\njson j = R\"({\"compact\": true, \"schema\": 0})\"_json;\n\n// serialize to BSON\nstd::vector<std::uint8_t> v_bson = json::to_bson(j);\n\n// 0x1B, 0x00, 0x00, 0x00, 0x08, 0x63, 0x6F, 0x6D, 0x70, 0x61, 0x63, 0x74, 0x00, 0x01, 0x10, 0x73, 0x63, 0x68, 0x65, 0x6D, 0x61, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00\n\n// roundtrip\njson j_from_bson = json::from_bson(v_bson);\n\n// serialize to CBOR\nstd::vector<std::uint8_t> v_cbor = json::to_cbor(j);\n\n// 0xA2, 0x67, 0x63, 0x6F, 0x6D, 0x70, 0x61, 0x63, 0x74, 0xF5, 0x66, 0x73, 0x63, 0x68, 0x65, 0x6D, 0x61, 0x00\n\n// roundtrip\njson j_from_cbor = json::from_cbor(v_cbor);\n\n// serialize to MessagePack\nstd::vector<std::uint8_t> v_msgpack = json::to_msgpack(j);\n\n// 0x82, 0xA7, 0x63, 0x6F, 0x6D, 0x70, 0x61, 0x63, 0x74, 0xC3, 0xA6, 0x73, 0x63, 0x68, 0x65, 0x6D, 0x61, 0x00\n\n// roundtrip\njson j_from_msgpack = json::from_msgpack(v_msgpack);\n\n// serialize to UBJSON\nstd::vector<std::uint8_t> v_ubjson = json::to_ubjson(j);\n\n// 0x7B, 0x69, 0x07, 0x63, 0x6F, 0x6D, 0x70, 0x61, 0x63, 0x74, 0x54, 0x69, 0x06, 0x73, 0x63, 0x68, 0x65, 0x6D, 0x61, 0x69, 0x00, 0x7D\n\n// roundtrip\njson j_from_ubjson = json::from_ubjson(v_ubjson);\n```\n\nThe library also supports binary types from BSON, CBOR (byte strings), and MessagePack (bin, ext, fixext). They are stored by default as `std::vector<std::uint8_t>` to be processed outside the library.\n\n```cpp\n// CBOR byte string with payload 0xCAFE\nstd::vector<std::uint8_t> v = {0x42, 0xCA, 0xFE};\n\n// read value\njson j = json::from_cbor(v);\n\n// the JSON value has type binary\nj.is_binary(); // true\n\n// get reference to stored binary value\nauto& binary = j.get_binary();\n\n// the binary value has no subtype (CBOR has no binary subtypes)\nbinary.has_subtype(); // false\n\n// access std::vector<std::uint8_t> member functions\nbinary.size(); // 2\nbinary[0]; // 0xCA\nbinary[1]; // 0xFE\n\n// set subtype to 0x10\nbinary.set_subtype(0x10);\n\n// serialize to MessagePack\nauto cbor = json::to_msgpack(j); // 0xD5 (fixext2), 0x10, 0xCA, 0xFE\n```\n\n## Customers\n\nThe library is used in multiple projects, applications, operating systems, etc. The list below is not exhaustive, but the result of an internet search. If you know further customers of the library, please let me know, see [contact](#contact).\n\n[![logos of customers using the library](docs/mkdocs/docs/images/customers.png)](https://json.nlohmann.me/home/customers/)\n\n## Supported compilers\n\nThough it's 2026 already, the support for C++11 is still a bit sparse. Currently, the following compilers are known to work:\n\n- GCC 4.8 - 14.2 (and possibly later)\n- Clang 3.4 - 21.0 (and possibly later)\n- Apple Clang 9.1 - 16.0 (and possibly later)\n- Intel C++ Compiler 17.0.2 (and possibly later)\n- Nvidia CUDA Compiler 11.0.221 (and possibly later)\n- Microsoft Visual C++ 2015 / Build Tools 14.0.25123.0 (and possibly later)\n- Microsoft Visual C++ 2017 / Build Tools 15.5.180.51428 (and possibly later)\n- Microsoft Visual C++ 2019 / Build Tools 16.3.1+1def00d3d (and possibly later)\n- Microsoft Visual C++ 2022 / Build Tools 19.30.30709.0 (and possibly later)\n\nI would be happy to learn about other compilers/versions.\n\nPlease note:\n\n- GCC 4.8 has a bug [57824](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=57824): multiline raw strings cannot be the arguments to macros. Don't use multiline raw strings directly in macros with this compiler.\n- Android defaults to using very old compilers and C++ libraries. To fix this, add the following to your `Application.mk`. This will switch to the LLVM C++ library, the Clang compiler, and enable C++11 and other features disabled by default.\n\n    ```makefile\n    APP_STL := c++_shared\n    NDK_TOOLCHAIN_VERSION := clang3.6\n    APP_CPPFLAGS += -frtti -fexceptions\n    ```\n\n    The code compiles successfully with [Android NDK](https://developer.android.com/ndk/index.html?hl=ml), Revision 9 - 11 (and possibly later) and [CrystaX's Android NDK](https://www.crystax.net/en/android/ndk) version 10.\n\n- For GCC running on MinGW or Android SDK, the error `'to_string' is not a member of 'std'` (or similarly, for `strtod` or `strtof`) may occur. Note this is not an issue with the code, but rather with the compiler itself. On Android, see above to build with a newer environment.  For MinGW, please refer to [this site](https://tehsausage.com/mingw-to-string) and [this discussion](https://github.com/nlohmann/json/issues/136) for information on how to fix this bug. For Android NDK using `APP_STL := gnustl_static`, please refer to [this discussion](https://github.com/nlohmann/json/issues/219).\n\n- Unsupported versions of GCC and Clang are rejected by `#error` directives. This can be switched off by defining `JSON_SKIP_UNSUPPORTED_COMPILER_CHECK`. Note that you can expect no support in this case.\n\nSee the page [quality assurance](https://json.nlohmann.me/community/quality_assurance) on the compilers used to check the library in the CI.\n\n## Integration\n\n[`json.hpp`](https://github.com/nlohmann/json/blob/develop/single_include/nlohmann/json.hpp) is the single required file in `single_include/nlohmann` or [released here](https://github.com/nlohmann/json/releases). You need to add\n\n```cpp\n#include <nlohmann/json.hpp>\n\n// for convenience\nusing json = nlohmann::json;\n```\n\nto the files you want to process JSON and set the necessary switches to enable C++11 (e.g., `-std=c++11` for GCC and Clang).\n\nYou can further use file [`include/nlohmann/json_fwd.hpp`](https://github.com/nlohmann/json/blob/develop/include/nlohmann/json_fwd.hpp) for forward-declarations. The installation of `json_fwd.hpp` (as part of cmake's install step) can be achieved by setting `-DJSON_MultipleHeaders=ON`.\n\n### CMake\n\nYou can also use the `nlohmann_json::nlohmann_json` interface target in CMake.  This target populates the appropriate usage requirements for `INTERFACE_INCLUDE_DIRECTORIES` to point to the appropriate include directories and `INTERFACE_COMPILE_FEATURES` for the necessary C++11 flags.\n\n#### External\n\nTo use this library from a CMake project, you can locate it directly with `find_package()` and use the namespaced imported target from the generated package configuration:\n\n```cmake\n# CMakeLists.txt\nfind_package(nlohmann_json 3.12.0 REQUIRED)\n...\nadd_library(foo ...)\n...\ntarget_link_libraries(foo PRIVATE nlohmann_json::nlohmann_json)\n```\n\nThe package configuration file, `nlohmann_jsonConfig.cmake`, can be used either from an install tree or directly out of the build tree.\n\n#### Embedded\n\nTo embed the library directly into an existing CMake project, place the entire source tree in a subdirectory and call `add_subdirectory()` in your `CMakeLists.txt` file:\n\n```cmake\n# Typically you don't care so much for a third party library's tests to be\n# run from your own project's code.\nset(JSON_BuildTests OFF CACHE INTERNAL \"\")\n\n# If you only include this third party in PRIVATE source files, you do not\n# need to install it when your main project gets installed.\n# set(JSON_Install OFF CACHE INTERNAL \"\")\n\n# Don't use include(nlohmann_json/CMakeLists.txt) since that carries with it\n# unintended consequences that will break the build.  It's generally\n# discouraged (although not necessarily well documented as such) to use\n# include(...) for pulling in other CMake projects anyways.\nadd_subdirectory(nlohmann_json)\n...\nadd_library(foo ...)\n...\ntarget_link_libraries(foo PRIVATE nlohmann_json::nlohmann_json)\n```\n\n##### Embedded (FetchContent)\n\nSince CMake v3.11,\n[FetchContent](https://cmake.org/cmake/help/v3.11/module/FetchContent.html) can\nbe used to automatically download a release as a dependency at configure time.\n\nExample:\n\n```cmake\ninclude(FetchContent)\n\nFetchContent_Declare(json URL https://github.com/nlohmann/json/releases/download/v3.12.0/json.tar.xz)\nFetchContent_MakeAvailable(json)\n\ntarget_link_libraries(foo PRIVATE nlohmann_json::nlohmann_json)\n```\n\n**Note**: It is recommended to use the URL approach described above, which is supported as of version 3.10.0. See\n<https://json.nlohmann.me/integration/cmake/#fetchcontent> for more information.\n\n#### Supporting Both\n\nTo allow your project to support either an externally supplied or an embedded JSON library, you can use a pattern akin to the following:\n\n``` cmake\n# Top level CMakeLists.txt\nproject(FOO)\n...\noption(FOO_USE_EXTERNAL_JSON \"Use an external JSON library\" OFF)\n...\nadd_subdirectory(thirdparty)\n...\nadd_library(foo ...)\n...\n# Note that the namespaced target will always be available regardless of the\n# import method\ntarget_link_libraries(foo PRIVATE nlohmann_json::nlohmann_json)\n```\n\n```cmake\n# thirdparty/CMakeLists.txt\n...\nif(FOO_USE_EXTERNAL_JSON)\n  find_package(nlohmann_json 3.12.0 REQUIRED)\nelse()\n  set(JSON_BuildTests OFF CACHE INTERNAL \"\")\n  add_subdirectory(nlohmann_json)\nendif()\n...\n```\n\n`thirdparty/nlohmann_json` is then a complete copy of this source tree.\n\n### Package Managers\n\nUse your favorite [**package manager**](https://json.nlohmann.me/integration/package_managers/) to use the library.\n\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/homebrew.svg\" height=\"20\">&nbsp;[**Homebrew**](https://json.nlohmann.me/integration/package_managers/#homebrew) `nlohmann-json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/meson.svg\" height=\"20\">&nbsp;[**Meson**](https://json.nlohmann.me/integration/package_managers/#meson) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/bazel.svg\" height=\"20\">&nbsp;[**Bazel**](https://json.nlohmann.me/integration/package_managers/#bazel) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/conan.svg\" height=\"20\">&nbsp;[**Conan**](https://json.nlohmann.me/integration/package_managers/#conan) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/spack.svg\" height=\"20\">&nbsp;[**Spack**](https://json.nlohmann.me/integration/package_managers/#spack) `nlohmann-json`\n- [**Hunter**](https://json.nlohmann.me/integration/package_managers/#hunter) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/vcpkg.png\" height=\"20\">&nbsp;[**vcpkg**](https://json.nlohmann.me/integration/package_managers/#vcpkg) `nlohmann-json`\n- [**cget**](https://json.nlohmann.me/integration/package_managers/#cget) `nlohmann/json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/swift.svg\" height=\"20\">&nbsp;[**Swift Package Manager**](https://json.nlohmann.me/integration/package_managers/#swift-package-manager) `nlohmann/json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/nuget.svg\" height=\"20\">&nbsp;[**Nuget**](https://json.nlohmann.me/integration/package_managers/#nuget) `nlohmann.json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/conda.svg\" height=\"20\">&nbsp;[**Conda**](https://json.nlohmann.me/integration/package_managers/#conda) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/macports.svg\" height=\"20\">&nbsp;[**MacPorts**](https://json.nlohmann.me/integration/package_managers/#macports) `nlohmann-json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/CPM.png\" height=\"20\">&nbsp;[**cpm.cmake**](https://json.nlohmann.me/integration/package_managers/#cpmcmake) `gh:nlohmann/json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/xmake.svg\" height=\"20\">&nbsp;[**xmake**](https://json.nlohmann.me/integration/package_managers/#xmake) `nlohmann_json`\n\nThe library is part of many package managers. See the [**documentation**](https://json.nlohmann.me/integration/package_managers/) for detailed descriptions and examples.\n\n### Pkg-config\n\nIf you are using bare Makefiles, you can use `pkg-config` to generate the include flags that point to where the library is installed:\n\n```sh\npkg-config nlohmann_json --cflags\n```\n\n## License\n\n<img align=\"right\" src=\"https://149753425.v2.pressablecdn.com/wp-content/uploads/2009/06/OSIApproved_100X125.png\" alt=\"OSI approved license\">\n\nThe class is licensed under the [MIT License](https://opensource.org/licenses/MIT):\n\nCopyright &copy; 2013-2026 [Niels Lohmann](https://nlohmann.me)\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ‚ÄúSoftware‚Äù), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ‚ÄúAS IS‚Äù, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n* * *\n\n- The class contains the UTF-8 Decoder from Bjoern Hoehrmann which is licensed under the [MIT License](https://opensource.org/licenses/MIT) (see above). Copyright &copy; 2008-2009 [Bj√∂rn Hoehrmann](https://bjoern.hoehrmann.de/) <bjoern@hoehrmann.de>\n- The class contains a slightly modified version of the Grisu2 algorithm from Florian Loitsch which is licensed under the [MIT License](https://opensource.org/licenses/MIT) (see above). Copyright &copy; 2009 [Florian Loitsch](https://florian.loitsch.com/)\n- The class contains a copy of [Hedley](https://nemequ.github.io/hedley/) from Evan Nemerson which is licensed as [CC0-1.0](https://creativecommons.org/publicdomain/zero/1.0/).\n- The class contains parts of [Google Abseil](https://github.com/abseil/abseil-cpp) which is licensed under the [Apache 2.0 License](https://opensource.org/licenses/Apache-2.0).\n\n<img align=\"right\" src=\"https://git.fsfe.org/reuse/reuse-ci/raw/branch/master/reuse-horizontal.png\" alt=\"REUSE Software\">\n\nThe library is compliant to version 3.3 of the [**REUSE specification**](https://reuse.software):\n\n- Every source file contains an SPDX copyright header.\n- The full text of all licenses used in the repository can be found in the `LICENSES` folder.\n- File `.reuse/dep5` contains an overview of all files' copyrights and licenses.\n- Run `pipx run reuse lint` to verify the project's REUSE compliance and `pipx run reuse spdx` to generate a SPDX SBOM.\n\n## Contact\n\nIf you have questions regarding the library, I would like to invite you to [open an issue at GitHub](https://github.com/nlohmann/json/issues/new/choose). Please describe your request, problem, or question as detailed as possible, and also mention the version of the library you are using as well as the version of your compiler and operating system. Opening an issue at GitHub allows other users and contributors to this library to collaborate. For instance, I have little experience with MSVC, and most issues in this regard have been solved by a growing community. If you have a look at the [closed issues](https://github.com/nlohmann/json/issues?q=is%3Aissue+is%3Aclosed), you will see that we react quite timely in most cases.\n\nOnly if your request would contain confidential information, please [send me an email](mailto:mail@nlohmann.me). For encrypted messages, please use [this key](https://keybase.io/nlohmann/pgp_keys.asc).\n\n## Security\n\n[Commits by Niels Lohmann](https://github.com/nlohmann/json/commits) and [releases](https://github.com/nlohmann/json/releases) are signed with this [PGP Key](https://keybase.io/nlohmann/pgp_keys.asc?fingerprint=797167ae41c0a6d9232e48457f3cea63ae251b69).\n\n## Thanks\n\nI deeply appreciate the help of the following people.\n\n<img src=\"https://raw.githubusercontent.com/nlohmann/json/develop/docs/avatars.png\" align=\"right\" alt=\"GitHub avatars of the contributors\">\n\n1. [Teemperor](https://github.com/Teemperor) implemented CMake support and lcov integration, realized escape and Unicode handling in the string parser, and fixed the JSON serialization.\n2. [elliotgoodrich](https://github.com/elliotgoodrich) fixed an issue with double deletion in the iterator classes.\n3. [kirkshoop](https://github.com/kirkshoop) made the iterators of the class composable to other libraries.\n4. [wancw](https://github.com/wanwc) fixed a bug that hindered the class to compile with Clang.\n5. Tomas √Öblad found a bug in the iterator implementation.\n6. [Joshua C. Randall](https://github.com/jrandall) fixed a bug in the floating-point serialization.\n7. [Aaron Burghardt](https://github.com/aburgh) implemented code to parse streams incrementally. Furthermore, he greatly improved the parser class by allowing the definition of a filter function to discard undesired elements while parsing.\n8. [Daniel Kopeƒçek](https://github.com/dkopecek) fixed a bug in the compilation with GCC 5.0.\n9. [Florian Weber](https://github.com/Florianjw) fixed a bug in and improved the performance of the comparison operators.\n10. [Eric Cornelius](https://github.com/EricMCornelius) pointed out a bug in the handling with NaN and infinity values. He also improved the performance of the string escaping.\n11. [ÊòìÊÄùÈæô](https://github.com/likebeta) implemented a conversion from anonymous enums.\n12. [kepkin](https://github.com/kepkin) patiently pushed forward the support for Microsoft Visual Studio.\n13. [gregmarr](https://github.com/gregmarr) simplified the implementation of reverse iterators and helped with numerous hints and improvements. In particular, he pushed forward the implementation of user-defined types.\n14. [Caio Luppi](https://github.com/caiovlp) fixed a bug in the Unicode handling.\n15. [dariomt](https://github.com/dariomt) fixed some typos in the examples.\n16. [Daniel Frey](https://github.com/d-frey) cleaned up some pointers and implemented exception-safe memory allocation.\n17. [Colin Hirsch](https://github.com/ColinH) took care of a small namespace issue.\n18. [Huu Nguyen](https://github.com/whoshuu) corrected a variable name in the documentation.\n19. [Silverweed](https://github.com/silverweed) overloaded `parse()` to accept an rvalue reference.\n20. [dariomt](https://github.com/dariomt) fixed a subtlety in MSVC type support and implemented the `get_ref()` function to get a reference to stored values.\n21. [ZahlGraf](https://github.com/ZahlGraf) added a workaround that allows compilation using Android NDK.\n22. [whackashoe](https://github.com/whackashoe) replaced a function that was marked as unsafe by Visual Studio.\n23. [406345](https://github.com/406345) fixed two small warnings.\n24. [Glen Fernandes](https://github.com/glenfe) noted a potential portability problem in the `has_mapped_type` function.\n25. [Corbin Hughes](https://github.com/nibroc) fixed some typos in the contribution guidelines.\n26. [twelsby](https://github.com/twelsby) fixed the array subscript operator, an issue that failed the MSVC build, and floating-point parsing/dumping. He further added support for unsigned integer numbers and implemented better roundtrip support for parsed numbers.\n27. [Volker Diels-Grabsch](https://github.com/vog) fixed a link in the README file.\n28. [msm-](https://github.com/msm-) added support for American Fuzzy Lop.\n29. [Annihil](https://github.com/Annihil) fixed an example in the README file.\n30. [Themercee](https://github.com/Themercee) noted a wrong URL in the README file.\n31. [Lv Zheng](https://github.com/lv-zheng) fixed a namespace issue with `int64_t` and `uint64_t`.\n32. [abc100m](https://github.com/abc100m) analyzed the issues with GCC 4.8 and proposed a [partial solution](https://github.com/nlohmann/json/pull/212).\n33. [zewt](https://github.com/zewt) added useful notes to the README file about Android.\n34. [R√≥bert M√°rki](https://github.com/robertmrk) added a fix to use move iterators and improved the integration via CMake.\n35. [Chris Kitching](https://github.com/ChrisKitching) cleaned up the CMake files.\n36. [Tom Needham](https://github.com/06needhamt) fixed a subtle bug with MSVC 2015 which was also proposed by [Michael K.](https://github.com/Epidal).\n37. [M√°rio Feroldi](https://github.com/thelostt) fixed a small typo.\n38. [duncanwerner](https://github.com/duncanwerner) found a really embarrassing performance regression in the 2.0.0 release.\n39. [Damien](https://github.com/dtoma) fixed one of the last conversion warnings.\n40. [Thomas Braun](https://github.com/t-b) fixed a warning in a test case and adjusted MSVC calls in the CI.\n41. [Th√©o DELRIEU](https://github.com/theodelrieu) patiently and constructively oversaw the long way toward [iterator-range parsing](https://github.com/nlohmann/json/issues/290). He also implemented the magic behind the serialization/deserialization of user-defined types and split the single header file into smaller chunks.\n42. [Stefan](https://github.com/5tefan) fixed a minor issue in the documentation.\n43. [Vasil Dimov](https://github.com/vasild) fixed the documentation regarding conversions from `std::multiset`.\n44. [ChristophJud](https://github.com/ChristophJud) overworked the CMake files to ease project inclusion.\n45. [Vladimir Petrigo](https://github.com/vpetrigo) made a SFINAE hack more readable and added Visual Studio 17 to the build matrix.\n46. [Denis Andrejew](https://github.com/seeekr) fixed a grammar issue in the README file.\n47. [Pierre-Antoine Lacaze](https://github.com/palacaze) found a subtle bug in the `dump()` function.\n48. [TurpentineDistillery](https://github.com/TurpentineDistillery) pointed to [`std::locale::classic()`](https://en.cppreference.com/w/cpp/locale/locale/classic) to avoid too much locale joggling, found some nice performance improvements in the parser, improved the benchmarking code, and realized locale-independent number parsing and printing.\n49. [cgzones](https://github.com/cgzones) had an idea how to fix the Coverity scan.\n50. [Jared Grubb](https://github.com/jaredgrubb) silenced a nasty documentation warning.\n51. [Yixin Zhang](https://github.com/qwename) fixed an integer overflow check.\n52. [Bosswestfalen](https://github.com/Bosswestfalen) merged two iterator classes into a smaller one.\n53. [Daniel599](https://github.com/Daniel599) helped to get Travis to execute the tests with Clang's sanitizers.\n54. [Jonathan Lee](https://github.com/vjon) fixed an example in the README file.\n55. [gnzlbg](https://github.com/gnzlbg) supported the implementation of user-defined types.\n56. [Alexej Harm](https://github.com/qis) helped to get the user-defined types working with Visual Studio.\n57. [Jared Grubb](https://github.com/jaredgrubb) supported the implementation of user-defined types.\n58. [EnricoBilla](https://github.com/EnricoBilla) noted a typo in an example.\n59. [Martin Ho≈ôe≈àovsk√Ω](https://github.com/horenmar) found a way for a 2x speedup for the compilation time of the test suite.\n60. [ukhegg](https://github.com/ukhegg) found proposed an improvement for the examples section.\n61. [rswanson-ihi](https://github.com/rswanson-ihi) noted a typo in the README.\n62. [Mihai Stan](https://github.com/stanmihai4) fixed a bug in the comparison with `nullptr`s.\n63. [Tushar Maheshwari](https://github.com/tusharpm) added [cotire](https://github.com/sakra/cotire) support to speed up the compilation.\n64. [TedLyngmo](https://github.com/TedLyngmo) noted a typo in the README, removed unnecessary bit arithmetic, and fixed some `-Weffc++` warnings.\n65. [Krzysztof Wo≈õ](https://github.com/krzysztofwos) made exceptions more visible.\n66. [ftillier](https://github.com/ftillier) fixed a compiler warning.\n67. [tinloaf](https://github.com/tinloaf) made sure all pushed warnings are properly popped.\n68. [Fytch](https://github.com/Fytch) found a bug in the documentation.\n69. [Jay Sistar](https://github.com/Type1J) implemented a Meson build description.\n70. [Henry Lee](https://github.com/HenryRLee) fixed a warning in ICC and improved the iterator implementation.\n71. [Vincent Thiery](https://github.com/vthiery) maintains a package for the Conan package manager.\n72. [Steffen](https://github.com/koemeet) fixed a potential issue with MSVC and `std::min`.\n73. [Mike Tzou](https://github.com/Chocobo1) fixed some typos.\n74. [amrcode](https://github.com/amrcode) noted misleading documentation about comparison of floats.\n75. [Oleg Endo](https://github.com/olegendo) reduced the memory consumption by replacing `<iostream>` with `<iosfwd>`.\n76. [dan-42](https://github.com/dan-42) cleaned up the CMake files to simplify including/reusing of the library.\n77. [Nikita Ofitserov](https://github.com/himikof) allowed for moving values from initializer lists.\n78. [Greg Hurrell](https://github.com/wincent) fixed a typo.\n79. [Dmitry Kukovinets](https://github.com/DmitryKuk) fixed a typo.\n80. [kbthomp1](https://github.com/kbthomp1) fixed an issue related to the Intel OSX compiler.\n81. [Markus Werle](https://github.com/daixtrose) fixed a typo.\n82. [WebProdPP](https://github.com/WebProdPP) fixed a subtle error in a precondition check.\n83. [Alex](https://github.com/leha-bot) noted an error in a code sample.\n84. [Tom de Geus](https://github.com/tdegeus) reported some warnings with ICC and helped to fix them.\n85. [Perry Kundert](https://github.com/pjkundert) simplified reading from input streams.\n86. [Sonu Lohani](https://github.com/sonulohani) fixed a small compilation error.\n87. [Jamie Seward](https://github.com/jseward) fixed all MSVC warnings.\n88. [Nate Vargas](https://github.com/eld00d) added a Doxygen tag file.\n89. [pvleuven](https://github.com/pvleuven) helped to fix a warning in ICC.\n90. [Pavel](https://github.com/crea7or) helped to fix some warnings in MSVC.\n91. [Jamie Seward](https://github.com/jseward) avoided unnecessary string copies in `find()` and `count()`.\n92. [Mitja](https://github.com/Itja) fixed some typos.\n93. [Jorrit Wronski](https://github.com/jowr) updated the Hunter package links.\n94. [Matthias M√∂ller](https://github.com/TinyTinni) added a `.natvis` for the MSVC debug view.\n95. [bogemic](https://github.com/bogemic) fixed some C++17 deprecation warnings.\n96. [Eren Okka](https://github.com/erengy) fixed some MSVC warnings.\n97. [abolz](https://github.com/abolz) integrated the Grisu2 algorithm for proper floating-point formatting, allowing more roundtrip checks to succeed.\n98. [Vadim Evard](https://github.com/Pipeliner) fixed a Markdown issue in the README.\n99. [zerodefect](https://github.com/zerodefect) fixed a compiler warning.\n100. [Kert](https://github.com/kaidokert) allowed to template the string type in the serialization and added the possibility to override the exceptional behavior.\n101. [mark-99](https://github.com/mark-99) helped fix an ICC error.\n102. [Patrik Huber](https://github.com/patrikhuber) fixed links in the README file.\n103. [johnfb](https://github.com/johnfb) found a bug in the implementation of CBOR's indefinite length strings.\n104. [Paul Fultz II](https://github.com/pfultz2) added a note on the cget package manager.\n105. [Wilson Lin](https://github.com/wla80) made the integration section of the README more concise.\n106. [RalfBielig](https://github.com/ralfbielig) detected and fixed a memory leak in the parser callback.\n107. [agrianius](https://github.com/agrianius) allowed dumping JSON to an alternative string type.\n108. [Kevin Tonon](https://github.com/ktonon) overworked the C++11 compiler checks in CMake.\n109. [Axel Huebl](https://github.com/ax3l) simplified a CMake check and added support for the [Spack package manager](https://spack.io).\n110. [Carlos O'Ryan](https://github.com/coryan) fixed a typo.\n111. [James Upjohn](https://github.com/jammehcow) fixed a version number in the compilers section.\n112. [Chuck Atkins](https://github.com/chuckatkins) adjusted the CMake files to the CMake packaging guidelines and provided documentation for the CMake integration.\n113. [Jan Sch√∂ppach](https://github.com/dns13) fixed a typo.\n114. [martin-mfg](https://github.com/martin-mfg) fixed a typo.\n115. [Matthias M√∂ller](https://github.com/TinyTinni) removed the dependency from `std::stringstream`.\n116. [agrianius](https://github.com/agrianius) added code to use alternative string implementations.\n117. [Daniel599](https://github.com/Daniel599) allowed to use more algorithms with the `items()` function.\n118. [Julius Rakow](https://github.com/jrakow) fixed the Meson include directory and fixed the links to [cppreference.com](https://cppreference.com).\n119. [Sonu Lohani](https://github.com/sonulohani) fixed the compilation with MSVC 2015 in debug mode.\n120. [grembo](https://github.com/grembo) fixed the test suite and re-enabled several test cases.\n121. [Hyeon Kim](https://github.com/simnalamburt) introduced the macro `JSON_INTERNAL_CATCH` to control the exception handling inside the library.\n122. [thyu](https://github.com/thyu) fixed a compiler warning.\n123. [David Guthrie](https://github.com/LEgregius) fixed a subtle compilation error with Clang 3.4.2.\n124. [Dennis Fischer](https://github.com/dennisfischer) allowed to call `find_package` without installing the library.\n125. [Hyeon Kim](https://github.com/simnalamburt) fixed an issue with a double macro definition.\n126. [Ben Berman](https://github.com/rivertam) made some error messages more understandable.\n127. [zakalibit](https://github.com/zakalibit) fixed a compilation problem with the Intel C++ compiler.\n128. [mandreyel](https://github.com/mandreyel) fixed a compilation problem.\n129. [Kostiantyn Ponomarenko](https://github.com/koponomarenko) added version and license information to the Meson build file.\n130. [Henry Schreiner](https://github.com/henryiii) added support for GCC 4.8.\n131. [knilch](https://github.com/knilch0r) made sure the test suite does not stall when run in the wrong directory.\n132. [Antonio Borondo](https://github.com/antonioborondo) fixed an MSVC 2017 warning.\n133. [Dan Gendreau](https://github.com/dgendreau) implemented the `NLOHMANN_JSON_SERIALIZE_ENUM` macro to quickly define an enum/JSON mapping.\n134. [efp](https://github.com/efp) added line and column information to parse errors.\n135. [julian-becker](https://github.com/julian-becker) added BSON support.\n136. [Pratik Chowdhury](https://github.com/pratikpc) added support for structured bindings.\n137. [David Avedissian](https://github.com/davedissian) added support for Clang 5.0.1 (PS4 version).\n138. [Jonathan Dumaresq](https://github.com/dumarjo) implemented an input adapter to read from `FILE*`.\n139. [kjpus](https://github.com/kjpus) fixed a link in the documentation.\n140. [Manvendra Singh](https://github.com/manu-chroma) fixed a typo in the documentation.\n141. [ziggurat29](https://github.com/ziggurat29) fixed an MSVC warning.\n142. [Sylvain Corlay](https://github.com/SylvainCorlay) added code to avoid an issue with MSVC.\n143. [mefyl](https://github.com/mefyl) fixed a bug when JSON was parsed from an input stream.\n144. [Millian Poquet](https://github.com/mpoquet) allowed to install the library via Meson.\n145. [Michael Behrns-Miller](https://github.com/moodboom) found an issue with a missing namespace.\n146. [Nasztanovics Ferenc](https://github.com/naszta) fixed a compilation issue with libc 2.12.\n147. [Andreas Schwab](https://github.com/andreas-schwab) fixed the endian conversion.\n148. [Mark-Dunning](https://github.com/Mark-Dunning) fixed a warning in MSVC.\n149. [Gareth Sylvester-Bradley](https://github.com/garethsb-sony) added `operator/` for JSON Pointers.\n150. [John-Mark](https://github.com/johnmarkwayve) noted a missing header.\n151. [Vitaly Zaitsev](https://github.com/xvitaly) fixed compilation with GCC 9.0.\n152. [Laurent Stacul](https://github.com/stac47) fixed compilation with GCC 9.0.\n153. [Ivor Wanders](https://github.com/iwanders) helped to reduce the CMake requirement to version 3.1.\n154. [njlr](https://github.com/njlr) updated the Buckaroo instructions.\n155. [Lion](https://github.com/lieff) fixed a compilation issue with GCC 7 on CentOS.\n156. [Isaac Nickaein](https://github.com/nickaein) improved the integer serialization performance and implemented the `contains()` function.\n157. [past-due](https://github.com/past-due) suppressed an unfixable warning.\n158. [Elvis Oric](https://github.com/elvisoric) improved Meson support.\n159. [Matƒõj Plch](https://github.com/Afforix) fixed an example in the README.\n160. [Mark Beckwith](https://github.com/wythe) fixed a typo.\n161. [scinart](https://github.com/scinart) fixed a bug in the serializer.\n162. [Patrick Boettcher](https://github.com/pboettch) implemented `push_back()` and `pop_back()` for JSON Pointers.\n163. [Bruno Oliveira](https://github.com/nicoddemus) added support for Conda.\n164. [Michele Caini](https://github.com/skypjack) fixed links in the README.\n165. [Hani](https://github.com/hnkb) documented how to install the library with NuGet.\n166. [Mark Beckwith](https://github.com/wythe) fixed a typo.\n167. [yann-morin-1998](https://github.com/yann-morin-1998) helped to reduce the CMake requirement to version 3.1.\n168. [Konstantin Podsvirov](https://github.com/podsvirov) maintains a package for the MSYS2 software distro.\n169. [remyabel](https://github.com/remyabel) added GNUInstallDirs to the CMake files.\n170. [Taylor Howard](https://github.com/taylorhoward92) fixed a unit test.\n171. [Gabe Ron](https://github.com/Macr0Nerd) implemented the `to_string` method.\n172. [Watal M. Iwasaki](https://github.com/heavywatal) fixed a Clang warning.\n173. [Viktor Kirilov](https://github.com/onqtam) switched the unit tests from [Catch](https://github.com/philsquared/Catch) to [doctest](https://github.com/onqtam/doctest)\n174. [Juncheng E](https://github.com/ejcjason) fixed a typo.\n175. [tete17](https://github.com/tete17) fixed a bug in the `contains` function.\n176. [Xav83](https://github.com/Xav83) fixed some cppcheck warnings.\n177. [0xflotus](https://github.com/0xflotus) fixed some typos.\n178. [Christian Deneke](https://github.com/chris0x44) added a const version of `json_pointer::back`.\n179. [Julien Hamaide](https://github.com/crazyjul) made the `items()` function work with custom string types.\n180. [Evan Nemerson](https://github.com/nemequ) updated fixed a bug in Hedley and updated this library accordingly.\n181. [Florian Pigorsch](https://github.com/flopp) fixed a lot of typos.\n182. [Camille B√©gu√©](https://github.com/cbegue) fixed an issue in the conversion from  `std::pair` and `std::tuple` to `json`.\n183. [Anthony VH](https://github.com/AnthonyVH) fixed a compile error in an enum deserialization.\n184. [Yuriy Vountesmery](https://github.com/ua-code-dragon) noted a subtle bug in a preprocessor check.\n185. [Chen](https://github.com/dota17) fixed numerous issues in the library.\n186. [Antony Kellermann](https://github.com/aokellermann) added a CI step for GCC 10.1.\n187. [Alex](https://github.com/gistrec) fixed an MSVC warning.\n188. [Rainer](https://github.com/rvjr) proposed an improvement in the floating-point serialization in CBOR.\n189. [Francois Chabot](https://github.com/FrancoisChabot) made performance improvements in the input adapters.\n190. [Arthur Sonzogni](https://github.com/ArthurSonzogni) documented how the library can be included via `FetchContent`.\n191. [Rimas Miseviƒçius](https://github.com/rmisev) fixed an error message.\n192. [Alexander Myasnikov](https://github.com/alexandermyasnikov) fixed some examples and a link in the README.\n193. [Hubert Chathi](https://github.com/uhoreg) made CMake's version config file architecture-independent.\n194. [OmnipotentEntity](https://github.com/OmnipotentEntity) implemented the binary values for CBOR, MessagePack, BSON, and UBJSON.\n195. [ArtemSarmini](https://github.com/ArtemSarmini) fixed a compilation issue with GCC 10 and fixed a leak.\n196. [Evgenii Sopov](https://github.com/sea-kg) integrated the library to the wsjcpp package manager.\n197. [Sergey Linev](https://github.com/linev) fixed a compiler warning.\n198. [Miguel Magalh√£es](https://github.com/magamig) fixed the year in the copyright.\n199. [Gareth Sylvester-Bradley](https://github.com/garethsb-sony) fixed a compilation issue with MSVC.\n200. [Alexander ‚Äúweej‚Äù Jones](https://github.com/alex-weej) fixed an example in the README.\n201. [Antoine C≈ìur](https://github.com/Coeur) fixed some typos in the documentation.\n202. [jothepro](https://github.com/jothepro) updated links to the Hunter package.\n203. [Dave Lee](https://github.com/kastiglione) fixed a link in the README.\n204. [Jo√´l Lamotte](https://github.com/Klaim) added instruction for using Build2's package manager.\n205. [Paul Jurczak](https://github.com/pauljurczak) fixed an example in the README.\n206. [Sonu Lohani](https://github.com/sonulohani) fixed a warning.\n207. [Carlos Gomes Martinho](https://github.com/gocarlos) updated the Conan package source.\n208. [Konstantin Podsvirov](https://github.com/podsvirov) fixed the MSYS2 package documentation.\n209. [Tridacnid](https://github.com/Tridacnid) improved the CMake tests.\n210. [Michael](https://github.com/MBalszun) fixed MSVC warnings.\n211. [Quentin Barbarat](https://github.com/quentin-dev) fixed an example in the documentation.\n212. [XyFreak](https://github.com/XyFreak) fixed a compiler warning.\n213. [TotalCaesar659](https://github.com/TotalCaesar659) fixed links in the README.\n214. [Tanuj Garg](https://github.com/tanuj208) improved the fuzzer coverage for UBSAN input.\n215. [AODQ](https://github.com/AODQ) fixed a compiler warning.\n216. [jwittbrodt](https://github.com/jwittbrodt) made `NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE` inline.\n217. [pfeatherstone](https://github.com/pfeatherstone) improved the upper bound of arguments of the `NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE`/`NLOHMANN_DEFINE_TYPE_INTRUSIVE` macros.\n218. [Jan Proch√°zka](https://github.com/jprochazk) fixed a bug in the CBOR parser for binary and string values.\n219. [T0b1-iOS](https://github.com/T0b1-iOS) fixed a bug in the new hash implementation.\n220. [Matthew Bauer](https://github.com/matthewbauer) adjusted the CBOR writer to create tags for binary subtypes.\n221. [gatopeich](https://github.com/gatopeich) implemented an ordered map container for `nlohmann::ordered_json`.\n222. [√ârico Nogueira Rolim](https://github.com/ericonr) added support for pkg-config.\n223. [KonanM](https://github.com/KonanM) proposed an implementation for the `NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE`/`NLOHMANN_DEFINE_TYPE_INTRUSIVE` macros.\n224. [Guillaume Racicot](https://github.com/gracicot) implemented `string_view` support and allowed C++20 support.\n225. [Alex Reinking](https://github.com/alexreinking) improved CMake support for `FetchContent`.\n226. [Hannes Domani](https://github.com/ssbssa) provided a GDB pretty printer.\n227. Lars Wirzenius reviewed the README file.\n228. [Jun Jie](https://github.com/ongjunjie) fixed a compiler path in the CMake scripts.\n229. [Ronak Buch](https://github.com/rbuch) fixed typos in the documentation.\n230. [Alexander Karzhenkov](https://github.com/karzhenkov) fixed a move constructor and the Travis builds.\n231. [Leonardo Lima](https://github.com/leozz37) added CPM.Cmake support.\n232. [Joseph Blackman](https://github.com/jbzdarkid) fixed a warning.\n233. [Yaroslav](https://github.com/YarikTH) updated doctest and implemented unit tests.\n234. [Martin Stump](https://github.com/globberwops) fixed a bug in the CMake files.\n235. [Jaakko Moisio](https://github.com/jasujm) fixed a bug in the input adapters.\n236. [bl-ue](https://github.com/bl-ue) fixed some Markdown issues in the README file.\n237. [William A. Wieselquist](https://github.com/wawiesel) fixed an example from the README.\n238. [abbaswasim](https://github.com/abbaswasim) fixed an example from the README.\n239. [Remy Jette](https://github.com/remyjette) fixed a warning.\n240. [Fraser](https://github.com/frasermarlow) fixed the documentation.\n241. [Ben Beasley](https://github.com/musicinmybrain) updated doctest.\n242. [Doron Behar](https://github.com/doronbehar) fixed pkg-config.pc.\n243. [raduteo](https://github.com/raduteo) fixed a warning.\n244. [David Pfahler](https://github.com/theShmoo) added the possibility to compile the library without I/O support.\n245. [Morten Fyhn Amundsen](https://github.com/mortenfyhn) fixed a typo.\n246. [jpl-mac](https://github.com/jpl-mac) allowed treating the library as a system header in CMake.\n247. [Jason Dsouza](https://github.com/jasmcaus) fixed the indentation of the CMake file.\n248. [offa](https://github.com/offa) added a link to Conan Center to the documentation.\n249. [TotalCaesar659](https://github.com/TotalCaesar659) updated the links in the documentation to use HTTPS.\n250. [Rafail Giavrimis](https://github.com/grafail) fixed the Google Benchmark default branch.\n251. [Louis Dionne](https://github.com/ldionne) fixed a conversion operator.\n252. [justanotheranonymoususer](https://github.com/justanotheranonymoususer) made the examples in the README more consistent.\n253. [Finkman](https://github.com/Finkman) suppressed some `-Wfloat-equal` warnings.\n254. [Ferry Huberts](https://github.com/fhuberts) fixed `-Wswitch-enum` warnings.\n255. [Arseniy Terekhin](https://github.com/senyai) made the GDB pretty-printer robust against unset variable names.\n256. [Amir Masoud Abdol](https://github.com/amirmasoudabdol) updated the Homebrew command as nlohmann/json is now in homebrew-core.\n257. [Hallot](https://github.com/Hallot) fixed some `-Wextra-semi-stmt warnings`.\n258. [Giovanni Cerretani](https://github.com/gcerretani) fixed `-Wunused` warnings on `JSON_DIAGNOSTICS`.\n259. [Bogdan Popescu](https://github.com/Kapeli) hosts the [docset](https://github.com/Kapeli/Dash-User-Contributions/tree/master/docsets/JSON_for_Modern_C%2B%2B) for offline documentation viewers.\n260. [Carl Smedstad](https://github.com/carlsmedstad) fixed an assertion error when using `JSON_DIAGNOSTICS`.\n261. [miikka75](https://github.com/miikka75) provided an important fix to compile C++17 code with Clang 9.\n262. [Maarten Becker](https://github.com/kernie) fixed a warning for shadowed variables.\n263. [Cristi V√Æjdea](https://github.com/axnsan12) fixed typos in the `operator[]` documentation.\n264. [Alex Beregszaszi](https://github.com/axic) fixed spelling mistakes in comments.\n265. [Dirk Stolle](https://github.com/striezel) fixed typos in documentation.\n266. [Daniel Albuschat](https://github.com/daniel-kun) corrected the parameter name in the `parse` documentation.\n267. [Prince Mendiratta](https://github.com/Prince-Mendiratta) fixed a link to the FAQ.\n268. [Florian Albrechtskirchinger](https://github.com/falbrechtskirchinger) implemented `std::string_view` support for object keys and made dozens of other improvements.\n269. [Qianqian Fang](https://github.com/fangq) implemented the Binary JData (BJData) format.\n270. [pketelsen](https://github.com/pketelsen) added macros `NLOHMANN_DEFINE_TYPE_INTRUSIVE_WITH_DEFAULT` and `NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE_WITH_DEFAULT`.\n271. [DarkZeros](https://github.com/DarkZeros) adjusted to code to not clash with Arduino defines.\n272. [flagarde](https://github.com/flagarde) fixed the output of `meta()` for MSVC.\n273. [Giovanni Cerretani](https://github.com/gcerretani) fixed a check for `std::filesystem`.\n274. [Dimitris Apostolou](https://github.com/rex4539) fixed a typo.\n275. [Ferry Huberts](https://github.com/fhuberts) fixed a typo.\n276. [Michael Nosthoff](https://github.com/heinemml) fixed a typo.\n277. [JungHoon Lee](https://github.com/jhnlee) fixed a typo.\n278. [Faruk D.](https://github.com/fdiblen) fixed the CITATION.CFF file.\n279. [Andrea Cocito](https://github.com/puffetto) added a clarification on macro usage to the documentation.\n280. [Krzysiek Karbowiak](https://github.com/kkarbowiak) refactored the tests to use `CHECK_THROWS_WITH_AS`.\n281. [Chaoqi Zhang](https://github.com/prncoprs) fixed a typo.\n282. [ivanovmp](https://github.com/ivanovmp) fixed a whitespace error.\n283. [KsaNL](https://github.com/KsaNL) fixed a build error when including `<windows.h>`.\n284. [Andrea Pappacoda](https://github.com/Tachi107) moved `.pc` and `.cmake` files to `share` directory.\n285. [Wolf Vollprecht](https://github.com/wolfv) added the `patch_inplace` function.\n286. [Jake Zimmerman](https://github.com/jez) highlighted common usage patterns in the README file.\n287. [NN](https://github.com/NN---) added the Visual Studio output directory to `.gitignore`.\n288. [Romain Reignier](https://github.com/romainreignier) improved the performance of the vector output adapter.\n289. [Mike](https://github.com/Mike-Leo-Smith) fixed the `std::iterator_traits`.\n290. [Richard Hoz√°k](https://github.com/zxey) added macro `JSON_NO_ENUM` to disable default enum conversions.\n291. [vakokako](https://github.com/vakokako) fixed tests when compiling with C++20.\n292. [Alexander ‚Äúweej‚Äù Jones](https://github.com/alexweej) fixed an example in the README.\n293. [Eli Schwartz](https://github.com/eli-schwartz) added more files to the `include.zip` archive.\n294. [Kevin Lu](https://github.com/kevinlul) fixed a compilation issue when typedefs with certain names were present.\n295. [Trevor Hickey](https://github.com/luxe) improved the description of an example.\n296. [Jef LeCompte](https://github.com/jef) updated the year in the README file.\n297. [Alexandre Hamez](https://github.com/ahamez) fixed a warning.\n298. [Maninderpal Badhan](https://github.com/mbadhan) fixed a typo.\n299. [kevin--](https://github.com/kevin--) added a note to an example in the README file.\n300. [I](https://github.com/wx257osn2) fixed a typo.\n301. [Gregorio Litenstein](https://github.com/Lord-Kamina) fixed the Clang detection.\n302. [Andreas Smas](https://github.com/andoma) added a Doozer badge.\n303. [WanCW](https://github.com/wancw) fixed the string conversion with Clang.\n304. [zhaohuaxishi](https://github.com/zhaohuaxishi) fixed a Doxygen error.\n305. [emvivre](https://github.com/emvivre) removed an invalid parameter from CMake.\n306. [Tobias Hermann](https://github.com/Dobiasd) fixed a link in the README file.\n307. [Michael](https://github.com/traits) fixed a warning.\n308. [Ryan Mulder](https://github.com/ryanjmulder) added `ensure_ascii` to the `dump` function.\n309. [Muri Nicanor](https://github.com/murinicanor) fixed the `sed` discovery in the Makefile.\n310. [David Avedissian](https://github.com/dgavedissian) implemented SFINAE-friendly `iterator_traits`.\n311. [AQNOUCH Mohammed](https://github.com/aqnouch) fixed a typo in the README.\n312. [Gareth Sylvester-Bradley](https://github.com/garethsb) added `operator/=` and `operator/` to construct JSON pointers.\n313. [Michael Macnair](https://github.com/mykter) added support for afl-fuzz testing.\n314. [Berkus Decker](https://github.com/berkus) fixed a typo in the README.\n315. [Illia Polishchuk](https://github.com/effolkronium) improved the CMake testing.\n316. [Ikko Ashimine](https://github.com/eltociear) fixed a typo.\n317. [Raphael Grimm](https://github.com/barcode) added the possibility to define a custom base class.\n318. [tocic](https://github.com/tocic) fixed typos in the documentation.\n319. [Vertexwahn](https://github.com/Vertexwahn) added Bazel build support.\n320. [Dirk Stolle](https://github.com/striezel) fixed typos in the documentation.\n321. [DavidKorczynski](https://github.com/DavidKorczynski) added a CIFuzz CI GitHub action.\n322. [Finkman](https://github.com/Finkman) fixed the debug pretty-printer.\n323. [Florian Segginger](https://github.com/floriansegginger) bumped the years in the README.\n324. [haadfida](https://github.com/haadfida) cleaned up the badges of used services.\n325. [Arsen Arsenoviƒá](https://github.com/ArsenArsen) fixed a build error.\n326. [theevilone45](https://github.com/theevilone45) fixed a typo in a CMake file.\n327. [Sergei Trofimovich](https://github.com/trofi) fixed the custom allocator support.\n328. [Joyce](https://github.com/joycebrum) fixed some security issues in the GitHub workflows.\n329. [Nicolas Jakob](https://github.com/njakob) add vcpkg version badge.\n330. [Tomerkm](https://github.com/Tomerkm) added tests.\n331. [No.](https://github.com/tusooa) fixed the use of `get<>` calls.\n332. [taro](https://github.com/tarolling) fixed a typo in the `CODEOWNERS` file.\n333. [Ikko Eltociear Ashimine](https://github.com/eltociear) fixed a typo.\n334. [Felix Yan](https://github.com/felixonmars) fixed a typo in the README.\n335. [HO-COOH](https://github.com/HO-COOH) fixed a parenthesis in the documentation.\n336. [Ivor Wanders](https://github.com/iwanders) fixed the examples to catch exception by `const&`.\n337. [miny1233](https://github.com/miny1233) fixed a parenthesis in the documentation.\n338. [tomalakgeretkal](https://github.com/tomalakgeretkal) fixed a compilation error.\n339. [alferov](https://github.com/ALF-ONE) fixed a compilation error.\n340. [Craig Scott](https://github.com/craigscott-crascit) fixed a deprecation warning in CMake.\n341. [Vyacheslav Zhdanovskiy](https://github.com/ZeronSix) added macros for serialization-only types.\n342. [Mathieu Westphal](https://github.com/mwestphal) fixed typos.\n343. [scribam](https://github.com/scribam) fixed the MinGW workflow.\n344. [Aleksei Sapitskii](https://github.com/aleksproger) added support for Apple's Swift Package Manager.\n345. [Benjamin Buch](https://github.com/bebuch) fixed the installation path in CMake.\n346. [Colby Haskell](https://github.com/colbychaskell) clarified the parse error message in case a file cannot be opened.\n347. [Juan Carlos Arevalo Baeza](https://github.com/TheJCAB) fixed the enum conversion.\n348. [alferov](https://github.com/ALF-ONE) fixed a version in the documentation.\n349. [ss](https://github.com/serge-s) fixed the amalgamation call.\n350. [AniketDhemare](https://github.com/AniketDhemare) fixed a version in the documentation.\n351. [Philip M√ºller](https://github.com/philip-paul-mueller) fixed an example.\n352. [Leila Shcheglova](https://github.com/LeilaShcheglova) fixed a warning in a test.\n353. [Alex Prabhat Bara](https://github.com/alexprabhat99) fixed a function name in the documentation.\n354. [laterlaugh](https://github.com/laterlaugh) fixed some typos.\n355. [Yuanhao Jia](https://github.com/MrJia1997) fixed the GDB pretty printer.\n356. [Fallen_Breath](https://github.com/Fallen-Breath) fixed an example for JSON Pointer.\n357. [Nikhil Idiculla](https://github.com/tsnl) fixed some typos.\n358. [Griffin Myers](https://github.com/gmyers18) updated the Natvis file.\n359. [thetimr](https://github.com/thetimr) fixed a typo in the documentation.\n360. [Balazs Erseki](https://github.com/zerocukor287) fixed a URL in the contribution guidelines.\n361. [Niccol√≤ Iardella](https://github.com/rotolof) added `NLOHMANN_DEFINE_DERIVED_TYPE_*` macros.\n362. [Borislav Stanimirov](https://github.com/iboB) allowed overriding the CMake target name.\n363. [Captain Crutches](https://github.com/captaincrutches) made `iterator_proxy_value` a `std::forward_iterator`.\n364. [Fredrik Sandhei](https://github.com/fsandhei) added type conversion support for `std::optional`.\n365. [jh96](https://github.com/jordan-hoang) added exceptions when `nullptr` is passed to `parse`.\n366. [Stuart Gorman](https://github.com/StuartGorman) fixed number parsing when `EINTR` set in `errno`.\n367. [Dylan Baker](https://github.com/dcbaker) generated a pkg-config file that follows the pkg-config conventions.\n368. [Tianyi Chen](https://github.com/TianyiChen) optimized the binary `get_number` implementation.\n369. [peng-wang-cn](https://github.com/peng-wang-cn) added type conversion support for multidimensional arrays.\n370. [Einars Netlis-Galejs](https://github.com/EinarsNG) added `ONLY_SERIALIZE` for `NLOHMANN_DEFINE_DERIVED_TYPE_*` macros.\n371. [Marcel](https://github.com/mering) removed `alwayslink=True` Bazel flag.\n372. [Harinath Nampally](https://github.com/hnampally) added diagnostic positions to exceptions.\n373. [Nissim Armand Ben Danan](https://github.com/NissimBendanan) fixed `NLOHMANN_DEFINE_TYPE_INTRUSIVE_WITH_DEFAULT` with an empty JSON instance.\n374. [Michael Valladolid](https://github.com/codenut) added support for BSON uint64 serialization/deserialization.\n375. [Nikhil](https://github.com/nikhilreddydev) updated the documentation.\n376. [Neboj≈°a Cvetkoviƒá](https://github.com/nebkat) added support for BJDATA optimized binary array type.\n377. [Sushrut Shringarputale](https://github.com/sushshring) added support for diagnostic positions. \n378. [kimci86](https://github.com/kimci86) templated to `NLOHMANN_DEFINE_TYPE` macros to also support `ordered_json`.\n379. [Richard Topchii](https://github.com/richardtop) added support for VisionOS in the Swift Package Manager.\n380. [Robert Chisholm](https://github.com/Robadob) fixed a typo.\n381. [zjyhjqs](https://github.com/zjyhjqs) added CPack support.\n382. [bitFiedler](https://github.com/bitFiedler) made GDB pretty printer work with Python 3.8.\n383. [Gianfranco Costamagna](https://github.com/LocutusOfBorg) fixed a compiler warning.\n384. [risa2000](https://github.com/risa2000) made `std::filesystem::path` conversion to/from UTF-8 encoded string explicit.\n\nThanks a lot for helping out! Please [let me know](mailto:mail@nlohmann.me) if I forgot someone.\n\n## Used third-party tools\n\nThe library itself consists of a single header file licensed under the MIT license. However, it is built, tested, documented, and whatnot using a lot of third-party tools and services. Thanks a lot!\n\n- [**amalgamate.py - Amalgamate C source and header files**](https://github.com/edlund/amalgamate) to create a single header file\n- [**American fuzzy lop**](https://lcamtuf.coredump.cx/afl/) for fuzz testing\n- [**AppVeyor**](https://www.appveyor.com) for [continuous integration](https://ci.appveyor.com/project/nlohmann/json) on Windows\n- [**Artistic Style**](http://astyle.sourceforge.net) for automatic source code indentation\n- [**Clang**](https://clang.llvm.org) for compilation with code sanitizers\n- [**CMake**](https://cmake.org) for build automation\n- [**Codacy**](https://www.codacy.com) for further [code analysis](https://app.codacy.com/gh/nlohmann/json/dashboard)\n- [**Coveralls**](https://coveralls.io) to measure [code coverage](https://coveralls.io/github/nlohmann/json)\n- [**Coverity Scan**](https://scan.coverity.com) for [static analysis](https://scan.coverity.com/projects/nlohmann-json)\n- [**cppcheck**](http://cppcheck.sourceforge.net) for static analysis\n- [**doctest**](https://github.com/onqtam/doctest) for the unit tests\n- [**GitHub Changelog Generator**](https://github.com/skywinder/github-changelog-generator) to generate the [ChangeLog](https://github.com/nlohmann/json/blob/develop/ChangeLog.md)\n- [**Google Benchmark**](https://github.com/google/benchmark) to implement the benchmarks\n- [**Hedley**](https://nemequ.github.io/hedley/) to avoid re-inventing several compiler-agnostic feature macros\n- [**lcov**](https://github.com/linux-test-project/lcov) to process coverage information and create an HTML view\n- [**libFuzzer**](https://llvm.org/docs/LibFuzzer.html) to implement fuzz testing for OSS-Fuzz\n- [**Material for MkDocs**](https://squidfunk.github.io/mkdocs-material/) for the style of the documentation site\n- [**MkDocs**](https://www.mkdocs.org) for the documentation site\n- [**OSS-Fuzz**](https://github.com/google/oss-fuzz) for continuous fuzz testing of the library ([project repository](https://github.com/google/oss-fuzz/tree/master/projects/json))\n- [**Probot**](https://probot.github.io) for automating maintainer tasks such as closing stale issues, requesting missing information, or detecting toxic comments.\n- [**Valgrind**](https://valgrind.org) to check for correct memory management\n\n## Notes\n\n### Character encoding\n\nThe library supports **Unicode input** as follows:\n\n- Only **UTF-8** encoded input is supported, which is the default encoding for JSON according to [RFC 8259](https://tools.ietf.org/html/rfc8259.html#section-8.1).\n- `std::u16string` and `std::u32string` can be parsed, assuming UTF-16 and UTF-32 encoding, respectively. These encodings are not supported when reading from files or other input containers.\n- Other encodings such as Latin-1 or ISO 8859-1 are **not** supported and will yield parse or serialization errors.\n- [Unicode noncharacters](https://www.unicode.org/faq/private_use.html#nonchar1) will not be replaced by the library.\n- Invalid surrogates (e.g., incomplete pairs such as `\\uDEAD`) will yield parse errors.\n- The strings stored in the library are UTF-8 encoded. When using the default string type (`std::string`), note that its length/size functions return the number of stored bytes rather than the number of characters or glyphs.\n- When you store strings with different encodings in the library, calling [`dump()`](https://json.nlohmann.me/api/basic_json/dump/) may throw an exception unless `json::error_handler_t::replace` or `json::error_handler_t::ignore` are used as error handlers.\n- To store wide strings (e.g., `std::wstring`), you need to convert them to a UTF-8 encoded `std::string` before, see [an example](https://json.nlohmann.me/home/faq/#wide-string-handling).\n\n### Comments in JSON\n\nThis library does not support comments by default. It does so for three reasons:\n\n1. Comments are not part of the [JSON specification](https://tools.ietf.org/html/rfc8259). You may argue that `//` or `/* */` are allowed in JavaScript, but JSON is not JavaScript.\n2. This was not an oversight: Douglas Crockford [wrote on this](https://plus.google.com/118095276221607585885/posts/RK8qyGVaGSr) in May 2012:\n  \n    > I removed comments from JSON because I saw people were using them to hold parsing directives, a practice which would have destroyed interoperability.  I know that the lack of comments makes some people sad, but it shouldn't.\n    >\n    > Suppose you are using JSON to keep configuration files, which you would like to annotate. Go ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser.\n  \n3. It is dangerous for interoperability if some libraries would add comment support while others don't. Please check [The Harmful Consequences of the Robustness Principle](https://tools.ietf.org/html/draft-iab-protocol-maintenance-01) on this.\n\nHowever, you can set set parameter `ignore_comments` to true in the `parse` function to ignore `//` or `/* */` comments. Comments will then be treated as whitespace.\n\n### Trailing commas\n\nThe JSON specification does not allow trailing commas in arrays and objects, and hence this library is treating them as parsing errors by default.\n\nLike comments, you can set parameter `ignore_trailing_commas` to true in the `parse` function to ignore trailing commas in arrays and objects. Note that a single comma as the only content of the array or object (`[,]` or `{,}`) is not allowed, and multiple trailing commas (`[1,,]`) are not allowed either.\n\nThis library does not add trailing commas when serializing JSON data.\n\nFor more information, see [JSON With Commas and Comments (JWCC)](https://nigeltao.github.io/blog/2021/json-with-commas-comments.html).\n\n### Order of object keys\n\nBy default, the library does not preserve the **insertion order of object elements**. This is standards-compliant, as the [JSON standard](https://tools.ietf.org/html/rfc8259.html) defines objects as \"an unordered collection of zero or more name/value pairs\".\n\nIf you do want to preserve the insertion order, you can try the type [`nlohmann::ordered_json`](https://github.com/nlohmann/json/issues/2179). Alternatively, you can use a more sophisticated ordered map like [`tsl::ordered_map`](https://github.com/Tessil/ordered-map) ([integration](https://github.com/nlohmann/json/issues/546#issuecomment-304447518)) or [`nlohmann::fifo_map`](https://github.com/nlohmann/fifo_map) ([integration](https://github.com/nlohmann/json/issues/485#issuecomment-333652309)).\n\nSee the [**documentation on object order**](https://json.nlohmann.me/features/object_order/) for more information.\n\n### Memory Release\n\nWe checked with Valgrind and the Address Sanitizer (ASAN) that there are no memory leaks.\n\nIf you find that a parsing program with this library does not release memory, please consider the following case, and it may be unrelated to this library.\n\n**Your program is compiled with glibc.** There is a tunable threshold that glibc uses to decide whether to actually return memory to the system or whether to cache it for later reuse. If in your program you make lots of small allocations and those small allocations are not a contiguous block and are presumably below the threshold, then they will not get returned to the OS.\nHere is a related issue [#1924](https://github.com/nlohmann/json/issues/1924).\n\n### Further notes\n\n- The code contains numerous debug **assertions** which can be switched off by defining the preprocessor macro `NDEBUG`, see the [documentation of `assert`](https://en.cppreference.com/w/cpp/error/assert). In particular, note [`operator[]`](https://json.nlohmann.me/api/basic_json/operator%5B%5D/) implements **unchecked access** for const objects: If the given key is not present, the behavior is undefined (think of a dereferenced null pointer) and yields an [assertion failure](https://github.com/nlohmann/json/issues/289) if assertions are switched on. If you are not sure whether an element in an object exists, use checked access with the [`at()` function](https://json.nlohmann.me/api/basic_json/at/). Furthermore, you can define `JSON_ASSERT(x)` to replace calls to `assert(x)`. See the [**documentation on runtime assertions**](https://json.nlohmann.me/features/assertions/) for more information.\n- As the exact number type is not defined in the [JSON specification](https://tools.ietf.org/html/rfc8259.html), this library tries to choose the best fitting C++ number type automatically. As a result, the type `double` may be used to store numbers which may yield [**floating-point exceptions**](https://github.com/nlohmann/json/issues/181) in certain rare situations if floating-point exceptions have been unmasked in the calling code. These exceptions are not caused by the library and need to be fixed in the calling code, such as by re-masking the exceptions prior to calling library functions.\n- The code can be compiled without C++ **runtime type identification** features; that is, you can use the `-fno-rtti` compiler flag.\n- **Exceptions** are used widely within the library. They can, however, be switched off with either using the compiler flag `-fno-exceptions` or by defining the symbol `JSON_NOEXCEPTION`. In this case, exceptions are replaced by `abort()` calls. You can further control this behavior by defining `JSON_THROW_USER` (overriding `throw`), `JSON_TRY_USER` (overriding `try`), and `JSON_CATCH_USER` (overriding `catch`). Note that `JSON_THROW_USER` should leave the current scope (e.g., by throwing or aborting), as continuing after it may yield undefined behavior. Note the explanatory [`what()`](https://en.cppreference.com/w/cpp/error/exception/what) string of exceptions is not available for MSVC if exceptions are disabled, see [#2824](https://github.com/nlohmann/json/discussions/2824). See the [**documentation of exceptions**](https://json.nlohmann.me/home/exceptions/) for more information.\n\n## Execute unit tests\n\nTo compile and run the tests, you need to execute\n\n```shell\nmkdir build\ncd build\ncmake .. -DJSON_BuildTests=On\ncmake --build .\nctest --output-on-failure\n```\n\nNote that during the `ctest` stage, several JSON test files are downloaded from an [external repository](https://github.com/nlohmann/json_test_data). If policies forbid downloading artifacts during testing, you can download the files yourself and pass the directory with the test files via `-DJSON_TestDataDirectory=path` to CMake. Then, no Internet connectivity is required. See [issue #2189](https://github.com/nlohmann/json/issues/2189) for more information.\n\nIf the testdata is not found, several test suites will fail like this:\n\n```\n===============================================================================\njson/tests/src/make_test_data_available.hpp:21:\nTEST CASE:  check test suite is downloaded\n\njson/tests/src/make_test_data_available.hpp:23: FATAL ERROR: REQUIRE( utils::check_testsuite_downloaded() ) is NOT correct!\n  values: REQUIRE( false )\n  logged: Test data not found in 'json/cmake-build-debug/json_test_data'.\n          Please execute target 'download_test_data' before running this test suite.\n          See <https://github.com/nlohmann/json#execute-unit-tests> for more information.\n\n===============================================================================\n```\n\nIn case you have downloaded the library rather than checked out the code via Git, test `cmake_fetch_content_configure` will fail. Please execute `ctest -LE git_required` to skip these tests. See [issue #2189](https://github.com/nlohmann/json/issues/2189) for more information.\n\nSome tests are requiring network to be properly execute. They are labeled as `git_required`. Please execute `ctest -LE git_required` to skip these tests. See [issue #4851](https://github.com/nlohmann/json/issues/4851) for more information.\n\nSome tests change the installed files and hence make the whole process not reproducible. Please execute `ctest -LE not_reproducible` to skip these tests. See [issue #2324](https://github.com/nlohmann/json/issues/2324) for more information. Furthermore, assertions must be switched off to ensure reproducible builds (see [discussion 4494](https://github.com/nlohmann/json/discussions/4494)).\n\nNote you need to call `cmake -LE \"not_reproducible|git_required\"` to exclude both labels. See [issue #2596](https://github.com/nlohmann/json/issues/2596) for more information.\n\nAs Intel compilers use unsafe floating point optimization by default, the unit tests may fail. Use flag [`/fp:precise`](https://www.intel.com/content/www/us/en/docs/cpp-compiler/developer-guide-reference/2021-8/fp-model-fp.html) then.\n",
      "stars_today": 14
    },
    {
      "id": 784788673,
      "name": "CookLikeHOC",
      "full_name": "Gar-b-age/CookLikeHOC",
      "description": "ü•¢ÂÉèËÄÅ‰π°È∏°üêîÈÇ£Ê†∑ÂÅöÈ•≠„ÄÇ‰∏ªË¶ÅÈÉ®ÂàÜ‰∫é2024Âπ¥ÂÆåÂ∑•ÔºåÈùûËÄÅ‰π°È∏°ÂÆòÊñπ‰ªìÂ∫ì„ÄÇÊñáÂ≠óÊù•Ëá™„ÄäËÄÅ‰π°È∏°ËèúÂìÅÊ∫ØÊ∫êÊä•Âëä„ÄãÔºåÂπ∂ÂÅöÂΩíÁ∫≥„ÄÅÁºñËæë‰∏éÊï¥ÁêÜ„ÄÇCookLikeHOC.",
      "html_url": "https://github.com/Gar-b-age/CookLikeHOC",
      "stars": 22814,
      "forks": 2300,
      "language": "JavaScript",
      "topics": [],
      "created_at": "2024-04-10T15:01:12Z",
      "updated_at": "2026-01-14T00:41:58Z",
      "pushed_at": "2025-10-17T20:04:04Z",
      "open_issues": 135,
      "owner": {
        "login": "Gar-b-age",
        "avatar_url": "https://avatars.githubusercontent.com/u/167223032?v=4"
      },
      "readme": "![pic](/banner.png)\n\n<div align=\"center\">\n\n[**Docker Support**](./docker_support/README.md) | [**Development**](./docs/development.md)\n\n</div>\n\n# ÂÉèËÄÅ‰π°È∏°ÈÇ£Ê†∑ÂÅöÈ•≠\n\n[**‰∏Ä‰∫õËØ¥Êòé**](https://github.com/Gar-b-age/CookLikeHOC/issues/26)\n\n‰ªìÂ∫ì‰∏ª‰ΩìÈÉ®ÂàÜ‰∫é2024Âπ¥ÂÆåÂ∑•ÔºåÂíå2025Âπ¥9Êúà‰ªΩÁöÑËàÜËÆ∫‰∫ã‰ª∂Êó†ÂÖ≥„ÄÇÊà™Ê≠¢Êèê‰∫§Êó∂Ôºå‰ªìÂ∫ìÁöÑË¥°ÁåÆËÄÖ‰ª¨‰∏éËÄÅ‰π°È∏°ÁöÑÂîØ‰∏ÄÂÖ≥Á≥ªÂè™ÊúâÊ∂àË¥πËÄÖÂíåÂïÜÂÆ∂ÁöÑÂÖ≥Á≥ª„ÄÇÊú¨‰ªìÂ∫ì‰∏çÊòØËÄÅ‰π°È∏°ÁöÑÂÆòÊñπ‰ªìÂ∫ì„ÄÇÂ¶ÇÊûúÊúâ‰ªª‰ΩïÈóÆÈ¢òÊàñÊÑèËßÅÂª∫ËÆÆÔºåÊ¨¢ËøéÊåáÂá∫\n\n## Êñ∞Êõ¥Êñ∞\n\n- Ê¨¢ËøéÂ§ßÂÆ∂Êù•Ë¥°ÁåÆÂÆûÊãçÂõæ\n\n- Áé∞Â∑≤‰∏äÁ∫øÁΩëÈ°µÁ´ØÔºå[ÁÇπÂáªËÆøÈóÆ](https://cooklikehoc.soilzhu.su)\n\n- Run with Docker? Check it out [here](https://github.com/Gar-b-age/CookLikeHOC/tree/main/docker_support), supported by [@honestAnt](https://github.com/honestAnt) in [PR #141](https://github.com/Gar-b-age/CookLikeHOC/pull/141)\n\n- AI ÁªòÂà∂ÁöÑÊâãÁªòÂõæÁâàÂèäAIÈÖçÂõæÊµÅÁ®ãÁâàÁΩëÈ°µÔºö [ÁÇπÂáªËÆøÈóÆ](https://ai.cooklikehoc.soilzhu.su), ÊâãÁªòÂõæÁî± [@liucongg](https://github.com/liucongg) Ë¥°ÁåÆÔºåËßÅ [PR #143](https://github.com/Gar-b-age/CookLikeHOC/pull/143)\n\n---\n\n[![link](/tg.png)](https://t.me/cooklikehoc)\n\n„ÄäËÄÅ‰π°È∏°ËèúÂìÅÊ∫ØÊ∫êÊä•Âëä„Äã‰∏≠ÂÖ¨Â∏ÉÁöÑÊâÄÊúâËèúÂìÅÂ∑≤ÁªèÂÖ®ÈÉ®ÂΩïÂÖ•ÂÆåÔºåÊ¨¢ËøéÂ§ßÂÆ∂Êü•ÈòÖÂíåË°•ÂÖÖ„ÄÇ\n\nÊñáÂ≠óË∂ÖÂ§ßÊÆµcopyËá™[„ÄäËÄÅ‰π°È∏°ËèúÂìÅÊ∫ØÊ∫êÊä•Âëä„Äã](https://www.lxjchina.com.cn/display.asp?id=4226)ÔºåÊúâÁºñËæë‰∏éÊï¥ÁêÜ\n\nÊåáË∑ØÈöîÂ£Å [How To Cook](https://cook.aiursoft.cn/)\n\nËá≥‰∫é‰∏∫‰ªÄ‰πà‰ªìÂ∫ìÂêçË¶ÅÂè´CookLikeHOCÔºåÂõ†‰∏∫Áõ¥Êé•ÂÜôLaoxiangjiÂ§ßÊ¶Ç‰∏çÊñπ‰æøÈòÖËØªÔºåËÄåHome Original ChickenÊòØchina dailyÊä•ÈÅì‰∏≠ÊâÄ‰ΩøÁî®ÁöÑËÄÅ‰π°È∏°ÁöÑËã±ÊñáÂêçÔºåÊïÖÁÆÄÂÜôÊàêHOC„ÄÇ\n\n\n## Contributor\n\n![cr](https://contrib.rocks/image?repo=Gar-b-age/CookLikeHOC)\n\n## Logo\n![pic](/logo.png) \n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=Gar-b-age/CookLikeHOC&type=Date)](https://star-history.com/#Gar-b-age/CookLikeHOC&Date)",
      "stars_today": 14
    },
    {
      "id": 150954997,
      "name": "VictoriaMetrics",
      "full_name": "VictoriaMetrics/VictoriaMetrics",
      "description": "VictoriaMetrics: fast, cost-effective monitoring solution and time series database",
      "html_url": "https://github.com/VictoriaMetrics/VictoriaMetrics",
      "stars": 15962,
      "forks": 1536,
      "language": "Go",
      "topics": [
        "database",
        "grafana",
        "graphite",
        "influxdb",
        "kubernetes",
        "monitoring",
        "observability",
        "opentelemetry",
        "opentsdb",
        "prometheus",
        "promql",
        "thanos",
        "tsdb"
      ],
      "created_at": "2018-09-30T09:58:01Z",
      "updated_at": "2026-01-14T01:04:21Z",
      "pushed_at": "2026-01-13T19:34:42Z",
      "open_issues": 771,
      "owner": {
        "login": "VictoriaMetrics",
        "avatar_url": "https://avatars.githubusercontent.com/u/43720803?v=4"
      },
      "readme": "# VictoriaMetrics\n\n[![Latest Release](https://img.shields.io/github/v/release/VictoriaMetrics/VictoriaMetrics?sort=semver&label=&filter=!*-victorialogs&logo=github&labelColor=gray&color=gray&link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Freleases%2Flatest)](https://github.com/VictoriaMetrics/VictoriaMetrics/releases)\n![Docker Pulls](https://img.shields.io/docker/pulls/victoriametrics/victoria-metrics?label=&logo=docker&logoColor=white&labelColor=2496ED&color=2496ED&link=https%3A%2F%2Fhub.docker.com%2Fr%2Fvictoriametrics%2Fvictoria-metrics)\n[![Go Report](https://goreportcard.com/badge/github.com/VictoriaMetrics/VictoriaMetrics?link=https%3A%2F%2Fgoreportcard.com%2Freport%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics)](https://goreportcard.com/report/github.com/VictoriaMetrics/VictoriaMetrics)\n[![Build Status](https://github.com/VictoriaMetrics/VictoriaMetrics/actions/workflows/build.yml/badge.svg?branch=master&link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Factions)](https://github.com/VictoriaMetrics/VictoriaMetrics/actions/workflows/build.yml)\n[![codecov](https://codecov.io/gh/VictoriaMetrics/VictoriaMetrics/branch/master/graph/badge.svg?link=https%3A%2F%2Fcodecov.io%2Fgh%2FVictoriaMetrics%2FVictoriaMetrics)](https://app.codecov.io/gh/VictoriaMetrics/VictoriaMetrics)\n[![License](https://img.shields.io/github/license/VictoriaMetrics/VictoriaMetrics?labelColor=green&label=&link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Fblob%2Fmaster%2FLICENSE)](https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/LICENSE)\n![Slack](https://img.shields.io/badge/Join-4A154B?logo=slack&link=https%3A%2F%2Fslack.victoriametrics.com)\n[![X](https://img.shields.io/twitter/follow/VictoriaMetrics?style=flat&label=Follow&color=black&logo=x&labelColor=black&link=https%3A%2F%2Fx.com%2FVictoriaMetrics)](https://x.com/VictoriaMetrics/)\n[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/VictoriaMetrics?style=flat&label=Join&labelColor=red&logoColor=white&logo=reddit&link=https%3A%2F%2Fwww.reddit.com%2Fr%2FVictoriaMetrics)](https://www.reddit.com/r/VictoriaMetrics/)\n\n<picture>\n  <source srcset=\"docs/victoriametrics/logo_white.webp\" media=\"(prefers-color-scheme: dark)\">\n  <source srcset=\"docs/victoriametrics/logo.webp\" media=\"(prefers-color-scheme: light)\">\n  <img src=\"docs/victoriametrics/logo.webp\" width=\"300\" alt=\"VictoriaMetrics logo\">\n</picture>\n\nVictoriaMetrics is a fast, cost-saving, and scalable solution for monitoring and managing time series data. It delivers high performance and reliability, making it an ideal choice for businesses of all sizes.\n\nHere are some resources and information about VictoriaMetrics:\n\n- Documentation: [docs.victoriametrics.com](https://docs.victoriametrics.com)\n- Case studies: [Grammarly, Roblox, Wix,...](https://docs.victoriametrics.com/victoriametrics/casestudies/).\n- Available: [Binary releases](https://github.com/VictoriaMetrics/VictoriaMetrics/releases/latest), docker images [Docker Hub](https://hub.docker.com/r/victoriametrics/victoria-metrics/) and [Quay](https://quay.io/repository/victoriametrics/victoria-metrics), [Source code](https://github.com/VictoriaMetrics/VictoriaMetrics)\n- Deployment types: [Single-node version](https://docs.victoriametrics.com/), [Cluster version](https://docs.victoriametrics.com/victoriametrics/cluster-victoriametrics/), and [Enterprise version](https://docs.victoriametrics.com/victoriametrics/enterprise/)\n- Changelog: [CHANGELOG](https://docs.victoriametrics.com/victoriametrics/changelog/), and [How to upgrade](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-upgrade-victoriametrics)\n- Community: [Slack](https://slack.victoriametrics.com/), [X (Twitter)](https://x.com/VictoriaMetrics), [LinkedIn](https://www.linkedin.com/company/victoriametrics/), [YouTube](https://www.youtube.com/@VictoriaMetrics)\n\nYes, we open-source both the single-node VictoriaMetrics and the cluster version.\n\n## Prominent features\n\nVictoriaMetrics is optimized for timeseries data, even when old time series are constantly replaced by new ones at a high rate, it offers a lot of features:\n\n* **Long-term storage for Prometheus** or as a drop-in replacement for Prometheus and Graphite in Grafana.\n* **Powerful stream aggregation**: Can be used as a StatsD alternative.\n* **Ideal for big data**: Works well with large amounts of time series data from APM, Kubernetes, IoT sensors, connected cars, industrial telemetry, financial data and various [Enterprise workloads](https://docs.victoriametrics.com/victoriametrics/enterprise/).\n* **Query language**: Supports both PromQL and the more performant MetricsQL.\n* **Easy to setup**: No dependencies, single [small binary](https://medium.com/@valyala/stripping-dependency-bloat-in-victoriametrics-docker-image-983fb5912b0d), configuration through command-line flags, but the default is also fine-tuned; backup and restore with [instant snapshots](https://medium.com/@valyala/how-victoriametrics-makes-instant-snapshots-for-multi-terabyte-time-series-data-e1f3fb0e0282).\n* **Global query view**: Multiple Prometheus instances or any other data sources may ingest data into VictoriaMetrics and queried via a single query.\n* **Various Protocols**: Support metric scraping, ingestion and backfilling in various protocol.\n    * [Prometheus exporters](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-scrape-prometheus-exporters-such-as-node-exporter), [Prometheus remote write API](https://docs.victoriametrics.com/victoriametrics/integrations/prometheus/), [Prometheus exposition format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-prometheus-exposition-format).\n    * [InfluxDB line protocol](https://docs.victoriametrics.com/victoriametrics/integrations/influxdb/) over HTTP, TCP and UDP.\n    * [Graphite plaintext protocol](https://docs.victoriametrics.com/victoriametrics/integrations/graphite/#ingesting) with [tags](https://graphite.readthedocs.io/en/latest/tags.html#carbon).\n    * [OpenTSDB put message](https://docs.victoriametrics.com/victoriametrics/integrations/opentsdb/#sending-data-via-telnet).\n    * [HTTP OpenTSDB /api/put requests](https://docs.victoriametrics.com/victoriametrics/integrations/opentsdb/#sending-data-via-http).\n    * [JSON line format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-json-line-format).\n    * [Arbitrary CSV data](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-csv-data).\n    * [Native binary format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-native-format).\n    * [DataDog agent or DogStatsD](https://docs.victoriametrics.com/victoriametrics/integrations/datadog/).\n    * [NewRelic infrastructure agent](https://docs.victoriametrics.com/victoriametrics/integrations/newrelic/#sending-data-from-agent).\n    * [OpenTelemetry metrics format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#sending-data-via-opentelemetry).\n* **NFS-based storages**: Supports storing data on NFS-based storages such as Amazon EFS, Google Filestore.\n* And many other features such as metrics relabeling, cardinality limiter, etc.\n\n## Enterprise version\n\nIn addition, the Enterprise version includes extra features:\n\n- **Anomaly detection**: Automation and simplification of your alerting rules, covering complex anomalies found in metrics data.\n- **Backup automation**: Automates regular backup procedures.\n- **Multiple retentions**: Reducing storage costs by specifying different retentions for different datasets.\n- **Downsampling**: Reducing storage costs and increasing performance for queries over historical data.\n- **Stable releases** with long-term support lines ([LTS](https://docs.victoriametrics.com/victoriametrics/lts-releases/)).\n- **Comprehensive support**: First-class consulting, feature requests and technical support provided by the core VictoriaMetrics dev team.\n- Many other features, which you can read about on [the Enterprise page](https://docs.victoriametrics.com/victoriametrics/enterprise/).\n\n[Contact us](mailto:info@victoriametrics.com) if you need enterprise support for VictoriaMetrics. Or you can request a free trial license [here](https://victoriametrics.com/products/enterprise/trial/), downloaded Enterprise binaries are available at [Github Releases](https://github.com/VictoriaMetrics/VictoriaMetrics/releases/latest).\n\nWe strictly apply security measures in everything we do. VictoriaMetrics has achieved security certifications for Database Software Development and Software-Based Monitoring Services. See [Security page](https://victoriametrics.com/security/) for more details.\n\n## Benchmarks \n\nSome good benchmarks VictoriaMetrics achieved:\n\n* **Minimal memory footprint**: handling millions of unique timeseries with [10x less RAM](https://medium.com/@valyala/insert-benchmarks-with-inch-influxdb-vs-victoriametrics-e31a41ae2893) than InfluxDB, up to [7x less RAM](https://valyala.medium.com/prometheus-vs-victoriametrics-benchmark-on-node-exporter-metrics-4ca29c75590f) than Prometheus, Thanos or Cortex.\n* **Highly scalable and performance** for [data ingestion](https://medium.com/@valyala/high-cardinality-tsdb-benchmarks-victoriametrics-vs-timescaledb-vs-influxdb-13e6ee64dd6b) and [querying](https://medium.com/@valyala/when-size-matters-benchmarking-victoriametrics-vs-timescale-and-influxdb-6035811952d4), [20x outperforms](https://medium.com/@valyala/insert-benchmarks-with-inch-influxdb-vs-victoriametrics-e31a41ae2893) InfluxDB and TimescaleDB.\n* **High data compression**: [70x more data points](https://medium.com/@valyala/when-size-matters-benchmarking-victoriametrics-vs-timescale-and-influxdb-6035811952d4) may be stored into limited storage than TimescaleDB, [7x less storage](https://valyala.medium.com/prometheus-vs-victoriametrics-benchmark-on-node-exporter-metrics-4ca29c75590f) space is required than Prometheus, Thanos or Cortex.\n* **Reducing storage costs**: [10x more effective](https://docs.victoriametrics.com/victoriametrics/casestudies/#grammarly) than Graphite according to the Grammarly case study.\n* **A single-node VictoriaMetrics** can replace medium-sized clusters built with competing solutions such as Thanos, M3DB, Cortex, InfluxDB or TimescaleDB. See [VictoriaMetrics vs Thanos](https://medium.com/@valyala/comparing-thanos-to-victoriametrics-cluster-b193bea1683), [Measuring vertical scalability](https://medium.com/@valyala/measuring-vertical-scalability-for-time-series-databases-in-google-cloud-92550d78d8ae), [Remote write storage wars - PromCon 2019](https://promcon.io/2019-munich/talks/remote-write-storage-wars/).\n* **Optimized for storage**: [Works well with high-latency IO](https://medium.com/@valyala/high-cardinality-tsdb-benchmarks-victoriametrics-vs-timescaledb-vs-influxdb-13e6ee64dd6b) and low IOPS (HDD and network storage in AWS, Google Cloud, Microsoft Azure, etc.).\n\n## Community and contributions\n\nFeel free asking any questions regarding VictoriaMetrics:\n\n* [Slack Inviter](https://slack.victoriametrics.com/) and [Slack channel](https://victoriametrics.slack.com/)\n* [X (Twitter)](https://x.com/VictoriaMetrics/)\n* [Linkedin](https://www.linkedin.com/company/victoriametrics/)\n* [Reddit](https://www.reddit.com/r/VictoriaMetrics/)\n* [Telegram-en](https://t.me/VictoriaMetrics_en)\n* [Telegram-ru](https://t.me/VictoriaMetrics_ru1)\n* [Mastodon](https://mastodon.social/@victoriametrics/)\n\nIf you like VictoriaMetrics and want to contribute, then please [read these docs](https://docs.victoriametrics.com/victoriametrics/contributing/).\n\n## VictoriaMetrics Logo\n\nThe provided [ZIP file](https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/VM_logo.zip) contains three folders with different logo orientations. Each folder includes the following file types:\n\n* JPEG: Preview files\n* PNG: Preview files with transparent background\n* AI: Adobe Illustrator files\n\n### VictoriaMetrics Logo Usage Guidelines\n\n#### Font\n\n* Font Used: Lato Black\n* Download here: [Lato Font](https://fonts.google.com/specimen/Lato)\n\n#### Color Palette\n\n* Black [#000000](https://www.color-hex.com/color/000000)\n* Purple [#4d0e82](https://www.color-hex.com/color/4d0e82)\n* Orange [#ff2e00](https://www.color-hex.com/color/ff2e00)\n* White [#ffffff](https://www.color-hex.com/color/ffffff)\n\n### Logo Usage Rules\n\n* Only use the Lato Black font as specified.\n* Maintain sufficient clear space around the logo for visibility.\n* Do not modify the spacing, alignment, or positioning of design elements.\n* You may resize the logo as needed, but ensure all proportions remain intact.\n\nThank you for your cooperation!\n",
      "stars_today": 14
    },
    {
      "id": 19316619,
      "name": "monero",
      "full_name": "monero-project/monero",
      "description": "Monero: the secure, private, untraceable cryptocurrency",
      "html_url": "https://github.com/monero-project/monero",
      "stars": 10219,
      "forks": 3352,
      "language": "C++",
      "topics": [
        "blockchain",
        "c-plus-plus",
        "cmake",
        "cryptocurrency",
        "cryptography",
        "cryptonote",
        "monero",
        "p2p",
        "privacy",
        "security"
      ],
      "created_at": "2014-04-30T14:38:28Z",
      "updated_at": "2026-01-13T18:55:48Z",
      "pushed_at": "2026-01-09T16:10:08Z",
      "open_issues": 741,
      "owner": {
        "login": "monero-project",
        "avatar_url": "https://avatars.githubusercontent.com/u/7450663?v=4"
      },
      "readme": "# Monero\n\nCopyright (c) 2014-2024, The Monero Project\nPortions Copyright (c) 2012-2013 The Cryptonote developers.\n\n## Table of Contents\n\n  - [Development resources](#development-resources)\n  - [Vulnerability response](#vulnerability-response)\n  - [Research](#research)\n  - [Announcements](#announcements)\n  - [Translations](#translations)\n  - [Coverage](#coverage)\n  - [Introduction](#introduction)\n  - [About this project](#about-this-project)\n  - [Supporting the project](#supporting-the-project)\n  - [License](#license)\n  - [Contributing](#contributing)\n  - [Scheduled software upgrades](#scheduled-software-upgrades)\n  - [Release staging schedule and protocol](#release-staging-schedule-and-protocol)\n  - [Compiling Monero from source](#compiling-monero-from-source)\n    - [Dependencies](#dependencies)\n    - [Guix builds](#guix-builds)\n  - [Internationalization](#Internationalization)\n  - [Using Tor](#using-tor)\n  - [Pruning](#Pruning)\n  - [Debugging](#Debugging)\n  - [Known issues](#known-issues)\n\n## Development resources\n\n- Web: [getmonero.org](https://getmonero.org)\n- Mail: [dev@getmonero.org](mailto:dev@getmonero.org)\n- GitHub: [https://github.com/monero-project/monero](https://github.com/monero-project/monero)\n- IRC: [#monero-dev on Libera](https://web.libera.chat/#monero-dev)\n- It is HIGHLY recommended that you join the #monero-dev IRC channel if you are developing software that uses Monero. Due to the nature of this open source software project, joining this channel and idling is the best way to stay updated on best practices and new developments in the Monero ecosystem. All you need to do is join the IRC channel and idle to stay updated with the latest in Monero development. If you do not, you risk wasting resources on developing integrations that are not compatible with the Monero network. The Monero core team and community continuously make efforts to communicate updates, developments, and documentation via other platforms ‚Äì but for the best information, you need to talk to other Monero developers, and they are on IRC. #monero-dev is about Monero development, not getting help about using Monero, or help about development of other software, including yours, unless it also pertains to Monero code itself. For these cases, checkout #monero.\n\n## Vulnerability response\n\n- Our [Vulnerability Response Process](https://github.com/monero-project/meta/blob/master/VULNERABILITY_RESPONSE_PROCESS.md) encourages responsible disclosure\n- We are also available via [HackerOne](https://hackerone.com/monero)\n\n## Research\n\nThe [Monero Research Lab](https://src.getmonero.org/resources/research-lab/) is an open forum where the community coordinates research into Monero cryptography, protocols, fungibility, analysis, and more. We welcome collaboration and contributions from outside researchers! Because not all Lab work and publications are distributed as traditional preprints or articles, they may be easy to miss if you are conducting literature reviews for your own Monero research. You are encouraged to get in touch with the Monero research community if you have questions, wish to collaborate, or would like guidance to help avoid unnecessarily duplicating earlier or known work.\n\nThe Monero research community is available on IRC in [#monero-research-lab on Libera](https://web.libera.chat/#monero-research-lab), which is also accessible via Matrix.\n\n## Announcements\n\n- You can subscribe to an [announcement listserv](https://lists.getmonero.org) to get critical announcements from the Monero core team. The announcement list can be very helpful for knowing when software updates are needed.\n\n## Translations\nThe CLI wallet is available in different languages. If you want to help translate it, see our self-hosted localization platform, Weblate, on [translate.getmonero.org]( https://translate.getmonero.org/projects/monero/cli-wallet/). Every translation *must* be uploaded on the platform, pull requests directly editing the code in this repository will be closed. If you need help with Weblate, you can find a guide with screenshots [here](https://github.com/monero-ecosystem/monero-translations/blob/master/weblate.md).\n&nbsp;\n\nIf you need help/support/info about translations, contact the localization workgroup. You can find the complete list of contacts on the repository of the workgroup: [monero-translations](https://github.com/monero-ecosystem/monero-translations#contacts).\n\n## Coverage\n\n| Type      | Status |\n|-----------|--------|\n| Coverity  | [![Coverity Status](https://scan.coverity.com/projects/9657/badge.svg)](https://scan.coverity.com/projects/9657/)\n| OSS Fuzz  | [![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/monero.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:monero)\n| Coveralls | [![Coveralls Status](https://coveralls.io/repos/github/monero-project/monero/badge.svg?branch=master)](https://coveralls.io/github/monero-project/monero?branch=master)\n| License   | [![License](https://img.shields.io/badge/license-BSD3-blue.svg)](https://opensource.org/licenses/BSD-3-Clause)\n\n## Introduction\n\nMonero is a private, secure, untraceable, decentralised digital currency. You are your bank, you control your funds, and nobody can trace your transfers unless you allow them to do so.\n\n**Privacy:** Monero uses a cryptographically sound system to allow you to send and receive funds without your transactions being easily revealed on the blockchain (the ledger of transactions that everyone has). This ensures that your purchases, receipts, and all transfers remain private by default.\n\n**Security:** Using the power of a distributed peer-to-peer consensus network, every transaction on the network is cryptographically secured. Individual wallets have a 25-word mnemonic seed that is only displayed once and can be written down to backup the wallet. Wallet files should be encrypted with a strong passphrase to ensure they are useless if ever stolen.\n\n**Untraceability:** By taking advantage of ring signatures, a special property of a certain type of cryptography, Monero is able to ensure that transactions are not only untraceable but have an optional measure of ambiguity that ensures that transactions cannot easily be tied back to an individual user or computer.\n\n**Decentralization:** The utility of Monero depends on its decentralised peer-to-peer consensus network - anyone should be able to run the monero software, validate the integrity of the blockchain, and participate in all aspects of the monero network using consumer-grade commodity hardware. Decentralization of the monero network is maintained by software development that minimizes the costs of running the monero software and inhibits the proliferation of specialized, non-commodity hardware.\n\n## About this project\n\nThis is the core implementation of Monero. It is open source and completely free to use without restrictions, except for those specified in the license agreement below. There are no restrictions on anyone creating an alternative implementation of Monero that uses the protocol and network in a compatible manner.\n\nAs with many development projects, the repository on GitHub is considered to be the \"staging\" area for the latest changes. Before changes are merged into that branch on the main repository, they are tested by individual developers in their own branches, submitted as a pull request, and then subsequently tested by contributors who focus on testing and code reviews. That having been said, the repository should be carefully considered before using it in a production environment, unless there is a patch in the repository for a particular show-stopping issue you are experiencing. It is generally a better idea to use a tagged release for stability.\n\n**Anyone is welcome to contribute to Monero's codebase!** If you have a fix or code change, feel free to submit it as a pull request directly to the \"master\" branch. In cases where the change is relatively small or does not affect other parts of the codebase, it may be merged in immediately by any one of the collaborators. On the other hand, if the change is particularly large or complex, it is expected that it will be discussed at length either well in advance of the pull request being submitted, or even directly on the pull request.\n\n## Supporting the project\n\nMonero is a 100% community-sponsored endeavor. If you want to join our efforts, the easiest thing you can do is support the project financially. Both Monero and Bitcoin donations can be made to **donate.getmonero.org** if using a client that supports the [OpenAlias](https://openalias.org) standard. Alternatively, you can send XMR to the Monero donation address via the `donate` command (type `help` in the command-line wallet for details).\n\nThe Monero donation address is:  \n`888tNkZrPN6JsEgekjMnABU4TBzc2Dt29EPAvkRxbANsAnjyPbb3iQ1YBRk1UXcdRsiKc9dhwMVgN5S9cQUiyoogDavup3H`  \nViewkey:  \n`f359631075708155cc3d92a32b75a7d02a5dcf27756707b47a2b31b21c389501`  \nBase address for restoring with address and viewkey:\n`44AFFq5kSiGBoZ4NMDwYtN18obc8AemS33DBLWs3H7otXft3XjrpDtQGv7SqSsaBYBb98uNbr2VBBEt7f2wfn3RVGQBEP3A`  \n\nThe Bitcoin donation address is:  \n`1KTexdemPdxSBcG55heUuTjDRYqbC5ZL8H`\n\nCore development funding and/or some supporting services are also graciously provided by [sponsors](https://www.getmonero.org/community/sponsorships/):\n\n[<img width=\"150\" src=\"https://www.getmonero.org/img/sponsors/tarilabs.png\"/>](https://tarilabs.com/)\n[<img width=\"150\" src=\"https://www.getmonero.org/img/sponsors/symas.png\"/>](https://symas.com/)\n[<img width=\"150\" src=\"https://www.getmonero.org/img/sponsors/macstadium.png\"/>](https://www.macstadium.com/)\n\nThere are also several mining pools that kindly donate a portion of their fees, [a list of them can be found on our Bitcointalk post](https://bitcointalk.org/index.php?topic=583449.0).\n\n## License\n\nSee [LICENSE](LICENSE).\n\n## Contributing\n\nIf you want to help out, see [CONTRIBUTING](docs/CONTRIBUTING.md) for a set of guidelines.\n\n## Scheduled software/network upgrades\n\nMonero uses a scheduled software/network upgrade (hard fork) mechanism to implement new features into the Monero software and network. This means that users of Monero (end users and service providers) should run current versions and upgrade their software when new releases are available. Software upgrades occur when new features are developed and implemented in the codebase. Network upgrades occur in tandem with software upgrades that modify the consensus rules of the Monero network. The required software for network upgrades will be available prior to the scheduled network upgrade date. Please check the repository prior to this date for the proper Monero software version. Below is the historical schedule and the projected schedule for the next upgrade.\n\nDates are provided in the format YYYY-MM-DD. The \"Minimum\" is the software version that follows the new consensus rules. The \"Recommended\" version may include bug fixes and other new features that do not affect the consensus rules.\n\n\n| Software upgrade block height  | Date       | Fork version      | Minimum Monero version | Recommended Monero version | Details                                                                            |\n| ------------------------------ | -----------| ----------------- | ---------------------- | -------------------------- | ---------------------------------------------------------------------------------- |\n| 1009827                        | 2016-03-22 | v2                | v0.9.4                 | v0.9.4                     | Allow only >= ringsize 3, blocktime = 120 seconds, fee-free blocksize 60 kb       |\n| 1141317                        | 2016-09-21 | v3                | v0.9.4                 | v0.10.0                    | Splits coinbase into denominations  |\n| 1220516                        | 2017-01-05 | v4                | v0.10.1                | v0.10.2.1                  | Allow normal and RingCT transactions |\n| 1288616                        | 2017-04-15 | v5                | v0.10.3.0              | v0.10.3.1                  | Adjusted minimum blocksize and fee algorithm      |\n| 1400000                        | 2017-09-16 | v6                | v0.11.0.0              | v0.11.0.0                  | Allow only RingCT transactions, allow only >= ringsize 5      |\n| 1546000                        | 2018-04-06 | v7                | v0.12.0.0              | v0.12.3.0                  | Cryptonight variant 1, ringsize >= 7, sorted inputs\n| 1685555                        | 2018-10-18 | v8                | v0.13.0.0              | v0.13.0.4                  | max transaction size at half the penalty free block size, bulletproofs enabled, cryptonight variant 2, fixed ringsize [11](https://youtu.be/KOO5S4vxi0o)\n| 1686275                        | 2018-10-19 | v9                | v0.13.0.0              | v0.13.0.4                  | bulletproofs required\n| 1788000                        | 2019-03-09 | v10               | v0.14.0.0              | v0.14.1.2                  | New PoW based on Cryptonight-R, new block weight algorithm, slightly more efficient RingCT format\n| 1788720                        | 2019-03-10 | v11               | v0.14.0.0              | v0.14.1.2                  | forbid old RingCT transaction format\n| 1978433                        | 2019-11-30 | v12               | v0.15.0.0              | v0.16.0.0                  | New PoW based on RandomX, only allow >= 2 outputs, change to the block median used to calculate penalty, v1 coinbases are forbidden, rct sigs in coinbase forbidden, 10 block lock time for incoming outputs\n| 2210000                        | 2020-10-17 | v13               | v0.17.0.0              | v0.17.3.2                  | New CLSAG transaction format\n| 2210720                        | 2020-10-18 | v14               | v0.17.1.1              | v0.17.3.2                  | forbid old MLSAG transaction format\n| 2688888                        | 2022-08-13 | v15               | v0.18.0.0              | v0.18.4.5                  | ringsize = 16, bulletproofs+, view tags, adjusted dynamic block weight algorithm\n| 2689608                        | 2022-08-14 | v16               | v0.18.0.0              | v0.18.4.5                  | forbid old v14 transaction format\n| XXXXXXX                        | XXX-XX-XX | XXX                | vX.XX.X.X              | vX.XX.X.X                  | XXX |\n\nX's indicate that these details have not been determined as of commit date.\n\n\\* indicates estimate as of commit date\n\n## Release staging schedule and protocol\n\nApproximately three months prior to a scheduled software upgrade, a branch from master will be created with the new release version tag. Pull requests that address bugs should then be made to both master and the new release branch. Pull requests that require extensive review and testing (generally, optimizations and new features) should *not* be made to the release branch.\n\n## Compiling Monero from source\n\n### Dependencies\n\nThe following table summarizes the tools and libraries required to build. A\nfew of the libraries are also included in this repository (marked as\n\"Vendored\"). By default, the build uses the library installed on the system\nand ignores the vendored sources. However, if no library is found installed on\nthe system, then the vendored source will be built and used. The vendored\nsources are also used for statically-linked builds because distribution\npackages often include only shared library binaries (`.so`) but not static\nlibrary archives (`.a`).\n\n| Dep          | Min. version  | Vendored | Debian/Ubuntu pkg    | Arch pkg     | Void pkg           | Fedora pkg          | Optional | Purpose         |\n| ------------ | ------------- | -------- | -------------------- | ------------ | ------------------ | ------------------- | -------- | --------------- |\n| GCC          | 7             | NO       | `build-essential`    | `base-devel` | `base-devel`       | `gcc`               | NO       |                 |\n| CMake        | 3.10          | NO       | `cmake`              | `cmake`      | `cmake`            | `cmake`             | NO       |                 |\n| pkg-config   | any           | NO       | `pkg-config`         | `base-devel` | `base-devel`       | `pkgconf`           | NO       |                 |\n| Boost        | 1.66          | NO       | `libboost-all-dev`   | `boost`      | `boost-devel`      | `boost-devel`       | NO       | C++ libraries   |\n| OpenSSL      | basically any | NO       | `libssl-dev`         | `openssl`    | `openssl-devel`    | `openssl-devel`     | NO       | sha256 sum      |\n| libzmq       | 4.2.0         | NO       | `libzmq3-dev`        | `zeromq`     | `zeromq-devel`     | `zeromq-devel`      | NO       | ZeroMQ library  |\n| libunbound   | 1.4.16        | NO       | `libunbound-dev`     | `unbound`    | `unbound-devel`    | `unbound-devel`     | NO       | DNS resolver    |\n| libsodium    | ?             | NO       | `libsodium-dev`      | `libsodium`  | `libsodium-devel`  | `libsodium-devel`   | NO       | cryptography    |\n| libunwind    | any           | NO       | `libunwind8-dev`     | `libunwind`  | `libunwind-devel`  | `libunwind-devel`   | YES      | Stack traces    |\n| liblzma      | any           | NO       | `liblzma-dev`        | `xz`         | `liblzma-devel`    | `xz-devel`          | YES      | For libunwind   |\n| libreadline  | 6.3.0         | NO       | `libreadline6-dev`   | `readline`   | `readline-devel`   | `readline-devel`    | YES      | Input editing   |\n| expat        | 1.1           | NO       | `libexpat1-dev`      | `expat`      | `expat-devel`      | `expat-devel`       | YES      | XML parsing     |\n| GTest        | 1.5           | YES      | `libgtest-dev`       | `gtest`      | `gtest-devel`      | `gtest-devel`       | YES      | Test suite      |\n| ccache       | any           | NO       | `ccache`             | `ccache`     | `ccache`           | `ccache`            | YES      | Compil. cache   |\n| Doxygen      | any           | NO       | `doxygen`            | `doxygen`    | `doxygen`          | `doxygen`           | YES      | Documentation   |\n| Graphviz     | any           | NO       | `graphviz`           | `graphviz`   | `graphviz`         | `graphviz`          | YES      | Documentation   |\n| lrelease     | ?             | NO       | `qttools5-dev-tools` | `qt5-tools`  | `qt5-tools`        | `qt5-linguist`      | YES      | Translations    |\n| libhidapi    | ?             | NO       | `libhidapi-dev`      | `hidapi`     | `hidapi-devel`     | `hidapi-devel`      | YES      | Hardware wallet |\n| libusb       | ?             | NO       | `libusb-1.0-0-dev`   | `libusb`     | `libusb-devel`     | `libusbx-devel`     | YES      | Hardware wallet |\n| libprotobuf  | ?             | NO       | `libprotobuf-dev`    | `protobuf`   | `protobuf-devel`   | `protobuf-devel`    | YES      | Hardware wallet |\n| protoc       | ?             | NO       | `protobuf-compiler`  | `protobuf`   | `protobuf`         | `protobuf-compiler` | YES      | Hardware wallet |\n| libudev      | ?             | NO       | `libudev-dev`        | `systemd`    | `eudev-libudev-devel` | `systemd-devel`  | YES      | Hardware wallet |\n\nInstall all dependencies at once on Debian/Ubuntu:\n\n```\nsudo apt update && sudo apt install build-essential cmake pkg-config libssl-dev libzmq3-dev libunbound-dev libsodium-dev libunwind8-dev liblzma-dev libreadline6-dev libexpat1-dev qttools5-dev-tools libhidapi-dev libusb-1.0-0-dev libprotobuf-dev protobuf-compiler libudev-dev libboost-chrono-dev libboost-date-time-dev libboost-filesystem-dev libboost-locale-dev libboost-program-options-dev libboost-regex-dev libboost-serialization-dev libboost-system-dev libboost-thread-dev python3 ccache doxygen graphviz git curl autoconf libtool gperf\n```\n\nInstall all dependencies at once on Arch:\n```\nsudo pacman -Syu --needed base-devel cmake boost openssl zeromq unbound libsodium libunwind xz readline expat python3 ccache doxygen graphviz qt5-tools hidapi libusb protobuf systemd\n```\n\nInstall all dependencies at once on Fedora:\n```\nsudo dnf install gcc gcc-c++ cmake pkgconf boost-devel openssl-devel zeromq-devel unbound-devel libsodium-devel libunwind-devel xz-devel readline-devel expat-devel ccache doxygen graphviz qt5-linguist hidapi-devel libusbx-devel protobuf-devel protobuf-compiler systemd-devel\n```\n\nInstall all dependencies at once on openSUSE:\n\n```\nsudo zypper ref && sudo zypper in cppzmq-devel libboost_chrono-devel libboost_date_time-devel libboost_filesystem-devel libboost_locale-devel libboost_program_options-devel libboost_regex-devel libboost_serialization-devel libboost_system-devel libboost_thread-devel libexpat-devel libminiupnpc-devel libsodium-devel libunwind-devel unbound-devel cmake doxygen ccache fdupes gcc-c++ libevent-devel libopenssl-devel pkgconf-pkg-config readline-devel xz-devel libqt5-qttools-devel patterns-devel-C-C++-devel_C_C++\n```\n\nInstall all dependencies at once on macOS with the provided Brewfile:\n\n```\nbrew update && brew bundle --file=contrib/brew/Brewfile\n```\n\nFreeBSD 12.1 one-liner required to build dependencies:\n\n```\npkg install git gmake cmake pkgconf boost-libs libzmq4 libsodium unbound\n```\n\n### Cloning the repository\n\nClone recursively to pull-in needed submodule(s):\n\n```\ngit clone --recursive https://github.com/monero-project/monero\n```\n\nIf you already have a repo cloned, initialize and update:\n\n```\ncd monero && git submodule init && git submodule update\n```\n\n*Note*: If there are submodule differences between branches, you may need \nto use `git submodule sync && git submodule update` after changing branches\nto build successfully.\n\n### Build instructions\n\nMonero uses the CMake build system and a top-level [Makefile](Makefile) that\ninvokes cmake commands as needed.\n\n#### On Linux and macOS\n\n* Install the dependencies\n* Change to the root of the source code directory, change to the most recent release branch, and build:\n\n    ```bash\n    cd monero\n    git checkout release-v0.18\n    make\n    ```\n\n    *Optional*: If your machine has several cores and enough memory, enable\n    parallel build by running `make -j<number of threads>` instead of `make`. For\n    this to be worthwhile, the machine should have one core and about 2GB of RAM\n    available per thread.\n\n    *Note*: The instructions above will compile the most stable release of the\n    Monero software. If you would like to use and test the most recent software,\n    use `git checkout master`. The master branch may contain updates that are\n    both unstable and incompatible with release software, though testing is always\n    encouraged.\n\n* The resulting executables can be found in `build/release/bin`\n\n* Add `PATH=\"$PATH:$HOME/monero/build/release/bin\"` to `.profile`\n\n* Run Monero with `monerod --detach`\n\n* **Optional**: build and run the test suite to verify the binaries:\n\n    ```bash\n    make release-test\n    ```\n\n    *NOTE*: `core_tests` test may take a few hours to complete.\n\n* **Optional**: to build binaries suitable for debugging:\n\n    ```bash\n    make debug\n    ```\n\n* **Optional**: build documentation in `doc/html` (omit `HAVE_DOT=YES` if `graphviz` is not installed):\n\n    ```bash\n    HAVE_DOT=YES doxygen Doxyfile\n    ```\n\n* **Optional**: use ccache not to rebuild translation units, that haven't really changed. Monero's CMakeLists.txt file automatically handles it\n\n    ```bash\n    sudo apt install ccache\n    ```\n\n#### On the Raspberry Pi\n\nTested on a Raspberry Pi 5B with a clean installation of Raspberry Pi OS (64-bit) with Debian 12 from https://www.raspberrypi.com/software/operating-systems/.\n\n* `apt-get update && apt-get upgrade` to install the latest software\n\n* Install the dependencies for Monero from the 'Debian' column in the table above.\n\n* **Optional**: increase the system swap size:\n\n    ```bash\n    sudo /etc/init.d/dphys-swapfile stop  \n    sudo nano /etc/dphys-swapfile  \n    CONF_SWAPSIZE=2048\n    sudo /etc/init.d/dphys-swapfile start\n    ```\n\n* If using an external hard disk without an external power supply, ensure it gets enough power to avoid hardware issues when syncing, by adding the line \"max_usb_current=1\" to /boot/config.txt\n\n* Clone Monero and checkout the most recent release version:\n\n    ```bash\n    git clone --recursive https://github.com/monero-project/monero.git\n    cd monero\n    git checkout v0.18.4.1\n    ```\n\n* Build:\n\n    ```bash\n    USE_SINGLE_BUILDDIR=1 make release\n    ```\n\n* Wait a few hours\n\n* The resulting executables can be found in `build/release/bin`\n\n* Add `export PATH=\"$PATH:$HOME/monero/build/release/bin\"` to `$HOME/.profile`\n\n* Run `source $HOME/.profile`\n\n* Run Monero with `monerod --detach`\n\n* You may wish to reduce the size of the swap file after the build has finished, and delete the boost directory from your home directory\n\n#### On Windows:\n\nBinaries for Windows can be built on Windows using the MinGW toolchain within\n[MSYS2 environment](https://www.msys2.org). The MSYS2 environment emulates a\nPOSIX system. The toolchain runs within the environment and *cross-compiles*\nbinaries that can run outside of the environment as a regular Windows\napplication.\n\n**Preparing the build environment**\n\n* Download and install the [MSYS2 installer](https://www.msys2.org). Installing MSYS2 requires 64-bit Windows 10 or newer.\n* Open the MSYS shell via the `MSYS2 MSYS` shortcut\n* Update packages using pacman:\n\n    ```bash\n    pacman -Syu\n    ```\n\n* Install dependencies:\n\n    ```bash\n    pacman -S mingw-w64-x86_64-toolchain make mingw-w64-x86_64-cmake mingw-w64-x86_64-boost mingw-w64-x86_64-openssl mingw-w64-x86_64-zeromq mingw-w64-x86_64-libsodium mingw-w64-x86_64-hidapi mingw-w64-x86_64-unbound\n    ```\n\n* Open the MingW shell via `MSYS2 MINGW64` shortcut.\n\n**Cloning**\n\n* To git clone, run:\n\n    ```bash\n    git clone --recursive https://github.com/monero-project/monero.git\n    ```\n\n**Building**\n\n* Change to the cloned directory, run:\n\n    ```bash\n    cd monero\n    ```\n\n* If you would like a specific [version/tag](https://github.com/monero-project/monero/tags), do a git checkout for that version. eg. 'v0.18.4.1'. If you don't care about the version and just want binaries from master, skip this step:\n\n    ```bash\n    git checkout v0.18.4.1\n    ```\n\n* To build Monero, run:\n\n    ```bash\n    make release-static -j $(nproc)\n    ```\n\n   The resulting executables can be found in `build/release/bin`\n\n\n* **Optional**: to build Windows binaries suitable for debugging, run:\n\n    ```bash\n    make debug -j $(nproc)\n    ```\n\n   The resulting executables can be found in `build/debug/bin`\n\n### On FreeBSD:\n\nThe project can be built from scratch by following instructions for Linux above(but use `gmake` instead of `make`). \nIf you are running Monero in a jail, you need to add `sysvsem=\"new\"` to your jail configuration, otherwise lmdb will throw the error message: `Failed to open lmdb environment: Function not implemented`.\n\nMonero is also available as a port or package as `monero-cli`.\n\n### On OpenBSD:\n\nYou will need to add a few packages to your system. `pkg_add cmake gmake zeromq libiconv boost libunbound`.\n\nThe `doxygen` and `graphviz` packages are optional and require the xbase set.\nRunning the test suite also requires `py3-requests` package.\n\nBuild monero: `gmake`\n\nNote: you may encounter the following error when compiling the latest version of Monero as a normal user:\n\n```\nLLVM ERROR: out of memory\nc++: error: unable to execute command: Abort trap (core dumped)\n```\n\nThen you need to increase the data ulimit size to 2GB and try again: `ulimit -d 2000000`\n\n### On NetBSD:\n\nCheck that the dependencies are present: `pkg_info -c libexecinfo boost-headers boost-libs protobuf readline libusb1 zeromq git-base pkgconf gmake cmake | more`, and install any that are reported missing, using `pkg_add` or from your pkgsrc tree.  Readline is optional but worth having.\n\nThird-party dependencies are usually under `/usr/pkg/`, but if you have a custom setup, adjust the \"/usr/pkg\" (below) accordingly.\n\nClone the monero repository recursively and checkout the most recent release as described above. Then build monero: `gmake BOOST_ROOT=/usr/pkg LDFLAGS=\"-Wl,-R/usr/pkg/lib\" release`.  The resulting executables can be found in `build/NetBSD/[Release version]/Release/bin/`.\n\n### On Solaris:\n\nThe default Solaris linker can't be used, you have to install GNU ld, then run cmake manually with the path to your copy of GNU ld:\n\n```bash\nmkdir -p build/release\ncd build/release\ncmake -DCMAKE_LINKER=/path/to/ld -D CMAKE_BUILD_TYPE=Release ../..\ncd ../..\n```\n\nThen you can run make as usual.\n\n### Cross Compiling\n\nYou can also cross-compile static binaries on Linux for Windows and macOS with the `depends` system.\n\n* ```make depends target=x86_64-linux-gnu``` for 64-bit linux binaries.\n* ```make depends target=x86_64-w64-mingw32``` for 64-bit windows binaries.\n  * Requires: `g++-mingw-w64-x86-64`\n  * You also need to run:\n    ```shell\n    update-alternatives --set x86_64-w64-mingw32-g++ $(which x86_64-w64-mingw32-g++-posix) && \\\n    update-alternatives --set x86_64-w64-mingw32-gcc $(which x86_64-w64-mingw32-gcc-posix)\n    ```\n* ```make depends target=x86_64-apple-darwin``` for Intel macOS binaries.\n  * Requires: `clang-18 lld-18`\n* ```make depends target=arm64-apple-darwin``` for Apple Silicon macOS binaries.\n  * Requires: `clang-18 lld-18`\n  * You also need to run:\n    ```shell\n    export PATH=\"/usr/lib/llvm-18/bin/:$PATH\"\n    ```\n* ```make depends target=i686-linux-gnu``` for 32-bit linux binaries.\n  * Requires: `g++-multilib bc`\n* ```make depends target=i686-w64-mingw32``` for 32-bit windows binaries.\n  * Requires: `python3 g++-mingw-w64-i686`\n* ```make depends target=arm-linux-gnueabihf``` for armv7 binaries.\n  * Requires: `g++-arm-linux-gnueabihf`\n* ```make depends target=aarch64-linux-gnu``` for armv8 binaries.\n  * Requires: `g++-aarch64-linux-gnu`\n* ```make depends target=riscv64-linux-gnu``` for RISC V 64 bit binaries.\n  * Requires: `g++-riscv64-linux-gnu`\n* ```make depends target=x86_64-unknown-freebsd``` for freebsd binaries.\n  * Requires: `clang-8`\n* ```make depends target=arm-linux-android``` for 32bit android binaries\n* ```make depends target=aarch64-linux-android``` for 64bit android binaries\n\n\nThe required packages are the names for each toolchain on apt. Depending on your distro, they may have different names. The `depends` system has been tested on Ubuntu 18.04 and 20.04.\n\nUsing `depends` might also be easier to compile Monero on Windows than using MSYS. Activate Windows Subsystem for Linux (WSL) with a distro (for example Ubuntu), install the apt build-essentials and follow the `depends` steps as depicted above.\n\nThe produced binaries still link libc dynamically. If the binary is compiled on a current distribution, it might not run on an older distribution with an older installation of libc.\n\n### Trezor hardware wallet support\n\nIf you have an issue with building Monero with Trezor support, you can disable it by setting `USE_DEVICE_TREZOR=OFF`, e.g., \n\n```bash\nUSE_DEVICE_TREZOR=OFF make release\n```\n\nFor more information, please check out Trezor [src/device_trezor/README.md](src/device_trezor/README.md).\n\n### Guix builds\n\nSee [contrib/guix/README.md](contrib/guix/README.md).\n\n## Installing Monero from a package\n\n**DISCLAIMER: These packages are not part of this repository or maintained by this project's contributors, and as such, do not go through the same review process to ensure their trustworthiness and security.**\n\nPackages are available for\n\n* Debian 12 (Bookworm) or later\n\n    ```bash\n    sudo apt install monero\n    ```\n  More info and versions in the [Debian package tracker](https://tracker.debian.org/pkg/monero).\n\n\n* Arch Linux:\n\n    ```bash\n    sudo pacman -S monero\n    ```\n\n* NixOS:\n\n    ```bash\n    nix-shell -p monero-cli\n    ```\n\n* Guix:\n\n    ```bash\n    guix package -i monero\n    ```\n\n* Gentoo [Monero overlay](https://github.com/gentoo-monero/gentoo-monero)\n\n    ```bash\n    emerge --noreplace eselect-repository\n    eselect repository enable monero\n    emaint sync -r monero\n    echo '*/*::monero ~amd64' >> /etc/portage/package.accept_keywords\n    emerge net-p2p/monero\n    ```\n\n* Alpine Linux:\n\n    ```bash\n    apk add monero\n    ```\n\n* macOS [(homebrew)](https://brew.sh/)\n    ```bash\n    brew install monero\n    ```\n\n* Docker\n\n    ```bash\n    # Build using all available cores\n    docker build -t monero .\n\n    # or build using a specific number of cores (reduce RAM requirement)\n    docker build --build-arg NPROC=1 -t monero .\n\n    # either run in foreground\n    docker run -it -v /monero/chain:/home/monero/.bitmonero -v /monero/wallet:/wallet -p 18080:18080 monero\n\n    # or in background\n    docker run -it -d -v /monero/chain:/home/monero/.bitmonero -v /monero/wallet:/wallet -p 18080:18080 monero\n    ```\n\n  * The build needs 3 GB space.\n  * Wait one hour or more\n\nPackaging for your favorite distribution would be a welcome contribution!\n\n## Running monerod\n\nThe build places the binary in `bin/` sub-directory within the build directory\nfrom which cmake was invoked (repository root by default). To run in the\nforeground:\n\n```bash\n./bin/monerod\n```\n\nTo list all available options, run `./bin/monerod --help`.  Options can be\nspecified either on the command line or in a configuration file passed by the\n`--config-file` argument.  To specify an option in the configuration file, add\na line with the syntax `argumentname=value`, where `argumentname` is the name\nof the argument without the leading dashes, for example, `log-level=1`.\n\nTo run in background:\n\n```bash\n./bin/monerod --log-file monerod.log --detach\n```\n\nTo run as a systemd service, copy\n[monerod.service](utils/systemd/monerod.service) to `/etc/systemd/system/` and\n[monerod.conf](utils/conf/monerod.conf) to `/etc/`. The [example\nservice](utils/systemd/monerod.service) assumes that the user `monero` exists\nand its home is the data directory specified in the [example\nconfig](utils/conf/monerod.conf).\n\nIf you're on Mac, you may need to add the `--max-concurrency 1` option to\nmonero-wallet-cli, and possibly monerod, if you get crashes refreshing.\n\n## Internationalization\n\nSee [README.i18n.md](docs/README.i18n.md).\n\n## Using Tor\n\n> There is a new, still experimental, [integration with Tor](docs/ANONYMITY_NETWORKS.md). The\n> feature allows connecting over IPv4 and Tor simultaneously - IPv4 is used for\n> relaying blocks and relaying transactions received by peers whereas Tor is\n> used solely for relaying transactions received over local RPC. This provides\n> privacy and better protection against surrounding node (sybil) attacks.\n\nWhile Monero isn't made to integrate with Tor, it can be used wrapped with torsocks, by\nsetting the following configuration parameters and environment variables:\n\n* `--p2p-bind-ip 127.0.0.1` on the command line or `p2p-bind-ip=127.0.0.1` in\n  monerod.conf to disable listening for connections on external interfaces.\n* `--no-igd` on the command line or `no-igd=1` in monerod.conf to disable IGD\n  (UPnP port forwarding negotiation), which is pointless with Tor.\n* If you use the wallet with a Tor daemon via the loopback IP (eg, 127.0.0.1:9050),\n  then use `--untrusted-daemon` unless it is your own hidden service.\n\nExample command line to start monerod through Tor:\n\n```bash\nmonerod --proxy 127.0.0.1:9050 --p2p-bind-ip 127.0.0.1 --no-igd\n```\n\nA helper script is in contrib/tor/monero-over-tor.sh. It assumes Tor is installed\nalready, and runs Tor and Monero with the right configuration.\n\n### Using Tor on Tails\n\nTAILS ships with a very restrictive set of firewall rules. Therefore, you need\nto add a rule to allow this connection too, in addition to telling torsocks to\nallow inbound connections. Full example:\n\n```bash\nsudo iptables -I OUTPUT 2 -p tcp -d 127.0.0.1 -m tcp --dport 18081 -j ACCEPT\nDNS_PUBLIC=tcp torsocks ./monerod --p2p-bind-ip 127.0.0.1 --no-igd --rpc-bind-ip 127.0.0.1 \\\n    --data-dir /home/amnesia/Persistent/your/directory/to/the/blockchain\n```\n\n## Pruning\n\nAs of April 2022, the full Monero blockchain file is about 130 GB. One can store a pruned blockchain, which is about 45 GB.\nA pruned blockchain can only serve part of the historical chain data to other peers, but is otherwise identical in\nfunctionality to the full blockchain.\nTo use a pruned blockchain, it is best to start the initial sync with `--prune-blockchain`. However, it is also possible\nto prune an existing blockchain using the `monero-blockchain-prune` tool or using the `--prune-blockchain` `monerod` option\nwith an existing chain. If an existing chain exists, pruning will temporarily require disk space to store both the full\nand pruned blockchains.\n\nFor more detailed information see the ['Pruning' entry in the Moneropedia](https://www.getmonero.org/resources/moneropedia/pruning.html)\n\n## Debugging\n\nThis section contains general instructions for debugging failed installs or problems encountered with Monero. First, ensure you are running the latest version built from the GitHub repo.\n\n### Obtaining stack traces and core dumps on Unix systems\n\nWe generally use the tool `gdb` (GNU debugger) to provide stack trace functionality, and `ulimit` to provide core dumps in builds which crash or segfault.\n\n* To use `gdb` in order to obtain a stack trace for a build that has stalled:\n\nRun the build.\n\nOnce it stalls, enter the following command:\n\n```bash\ngdb /path/to/monerod `pidof monerod`\n```\n\nType `thread apply all bt` within gdb in order to obtain the stack trace\n\n* If however the core dumps or segfaults:\n\nEnter `ulimit -c unlimited` on the command line to enable unlimited filesizes for core dumps\n\nEnter `echo core | sudo tee /proc/sys/kernel/core_pattern` to stop cores from being hijacked by other tools\n\nRun the build.\n\nWhen it terminates with an output along the lines of \"Segmentation fault (core dumped)\", there should be a core dump file in the same directory as monerod. It may be named just `core`, or `core.xxxx` with numbers appended.\n\nYou can now analyse this core dump with `gdb` as follows:\n\n```bash\ngdb /path/to/monerod /path/to/dumpfile`\n```\n\nPrint the stack trace with `bt`\n\n * If a program crashed and cores are managed by systemd, the following can also get a stack trace for that crash:\n\n```bash\ncoredumpctl -1 gdb\n```\n\n#### To run Monero within gdb:\n\nType `gdb /path/to/monerod`\n\nPass command-line options with `--args` followed by the relevant arguments\n\nType `run` to run monerod\n\n### Analysing memory corruption\n\nThere are two tools available:\n\n#### ASAN\n\nConfigure Monero with the -D SANITIZE=ON cmake flag, eg:\n\n```bash\ncd build/debug && cmake -D SANITIZE=ON -D CMAKE_BUILD_TYPE=Debug ../..\n```\n\nYou can then run the monero tools normally. Performance will typically halve.\n\n#### valgrind\n\nInstall valgrind and run as `valgrind /path/to/monerod`. It will be very slow.\n\n### LMDB\n\nInstructions for debugging suspected blockchain corruption as per @HYC\n\nThere is an `mdb_stat` command in the LMDB source that can print statistics about the database but it's not routinely built. This can be built with the following command:\n\n```bash\ncd ~/monero/external/db_drivers/liblmdb && make\n```\n\nThe output of `mdb_stat -ea <path to blockchain dir>` will indicate inconsistencies in the blocks, block_heights and block_info table.\n\nThe output of `mdb_dump -s blocks <path to blockchain dir>` and `mdb_dump -s block_info <path to blockchain dir>` is useful for indicating whether blocks and block_info contain the same keys.\n\nThese records are dumped as hex data, where the first line is the key and the second line is the data.\n\n# Known Issues\n\n## Protocols\n\n### Socket-based\n\nBecause of the nature of the socket-based protocols that drive monero, certain protocol weaknesses are somewhat unavoidable at this time. While these weaknesses can theoretically be fully mitigated, the effort required (the means) may not justify the ends. As such, please consider taking the following precautions if you are a monero node operator:\n\n- Run `monerod` on a \"secured\" machine. If operational security is not your forte, at a very minimum, have a dedicated a computer running `monerod` and **do not** browse the web, use email clients, or use any other potentially harmful apps on your `monerod` machine. **Do not click links or load URL/MUA content on the same machine**. Doing so may potentially exploit weaknesses in commands which accept \"localhost\" and \"127.0.0.1\".\n- If you plan on hosting a public \"remote\" node, start `monerod` with `--restricted-rpc`. This is a must.\n\n### Blockchain-based\n\nCertain blockchain \"features\" can be considered \"bugs\" if misused correctly. Consequently, please consider the following:\n\n- When receiving monero, be aware that it may be locked for an arbitrary time if the sender elected to, preventing you from spending that monero until the lock time expires. You may want to hold off acting upon such a transaction until the unlock time lapses. To get a sense of that time, you can consider the remaining blocktime until unlock as seen in the `show_transfers` command.\n",
      "stars_today": 14
    },
    {
      "id": 31558937,
      "name": "teleport",
      "full_name": "gravitational/teleport",
      "description": "The easiest, and most secure way to access and protect all of your infrastructure.",
      "html_url": "https://github.com/gravitational/teleport",
      "stars": 19660,
      "forks": 1974,
      "language": "Go",
      "topics": [
        "audit",
        "bastion",
        "certificate",
        "cluster",
        "database-access",
        "firewall",
        "firewalls",
        "go",
        "golang",
        "jumpserver",
        "kubernetes",
        "kubernetes-access",
        "pam",
        "postgres",
        "rbac",
        "rdp",
        "security",
        "ssh",
        "teleport",
        "teleport-binaries"
      ],
      "created_at": "2015-03-02T19:36:00Z",
      "updated_at": "2026-01-14T00:15:52Z",
      "pushed_at": "2026-01-14T00:42:29Z",
      "open_issues": 3020,
      "owner": {
        "login": "gravitational",
        "avatar_url": "https://avatars.githubusercontent.com/u/10781132?v=4"
      },
      "readme": "Teleport provides connectivity, authentication, access controls and audit for\ninfrastructure.\n\nYou might use Teleport to:\n\n* Set up single sign-on (SSO) for all of your cloud and on-prem\n  infrastructure.\n* Protect access to servers, Kubernetes clusters, databases, Windows\n  desktops, web applications, and cloud APIs without long-lived keys or\n  passwords.\n* Establish secure tunnels to reach resources behind NATs and firewalls\n  without VPNs or bastion hosts.\n* Record and audit activity across SSH, Kubernetes, database, RDP, and web\n  sessions.\n* Apply consistent Role-Based and Attribute-Based Access Control (RBAC/ABAC)\n  across users, machines, workloads, and resource types.\n* Enforce least privilege and Just-in-Time (JIT) access requests for\n  elevated roles or sensitive systems.\n* Maintain a single identity and access layer for both human users and\n  workloads.\n\nTeleport works with SSH, Kubernetes, databases, RDP, cloud consoles,\ninternal web services, Git repositories, and Model Context Protocol (MCP)\nservers.\n\n<div align=\"center\">\n   <a href=\"https://goteleport.com/download\">\n   <img src=\"./assets/img/hero-teleport-platform.png\" width=750/>\n   </a>\n   <div align=\"center\" style=\"padding: 25px\">\n      <a href=\"https://goteleport.com/download\">\n      <img src=\"https://img.shields.io/github/v/release/gravitational/teleport?sort=semver&label=Release&color=651FFF\" />\n      </a>\n      <a href=\"https://golang.org/\">\n      <img src=\"https://img.shields.io/github/go-mod/go-version/gravitational/teleport?color=7fd5ea\" />\n      </a>\n      <a href=\"https://github.com/gravitational/teleport/blob/master/CODE_OF_CONDUCT.md\">\n      <img src=\"https://img.shields.io/badge/Contribute-üôå-green.svg\" />\n      </a>\n      <a href=\"https://www.gnu.org/licenses/agpl-3.0.en.html\">\n      <img src=\"https://img.shields.io/badge/AGPL-3.0-red.svg\" />\n      </a>\n   </div>\n</div>\n</br>\n\n## More Information\n[Teleport Getting Started](https://goteleport.com/docs/get-started/)  \n[Teleport Architecture](https://goteleport.com/docs/reference/architecture/)  \n[Reference Guides](https://goteleport.com/docs/reference/)  \n[FAQ](https://goteleport.com/docs/faq)\n\n\n## Table of Contents\n\n1. [Introduction](#introduction)\n1. [Why We Built Teleport](#why-we-built-teleport)\n1. [Supporting & Contributing](#supporting--contributing)\n1. [Installing & Running](#installing--running)\n1. [Docker](#docker)\n1. [Building Teleport](#building-teleport)\n1. [License](#license)\n1. [FAQ](#faq)\n\n## Introduction\n\nTeleport includes an identity-aware access proxy, a CA that issues short-lived\ncertificates, a unified access control system, and a tunneling system to access\nresources behind the firewall.\n\nTeleport is a single Go binary that integrates with multiple protocols and\ncloud services, including\n\n* [SSH nodes](https://goteleport.com/docs/enroll-resources/server-access/introduction/)\n* [Kubernetes clusters](https://goteleport.com/docs/enroll-resources/kubernetes-access/introduction/)\n* [PostgreSQL, MongoDB, CockroachDB and MySQL\n  databases](https://goteleport.com/docs/enroll-resources/database-access/)\n* [Model Context Protocol](https://goteleport.com/docs/connect-your-client/model-context-protocol/)\n* [Internal Web apps](https://goteleport.com/docs/enroll-resources/application-access/introduction/)\n* [Windows Hosts](https://goteleport.com/docs/enroll-resources/desktop-access/introduction/)\n* [Networked servers](https://goteleport.com/docs/enroll-resources/server-access/introduction/)\n\nYou can set up Teleport as a [Linux\ndaemon](https://goteleport.com/docs/admin-guides/deploy-a-cluster/linux-demo)\nor a [Kubernetes\ndeployment](https://goteleport.com/docs/admin-guides/deploy-a-cluster/helm-deployments/).\n\nTeleport focuses on best practices for infrastructure security, including:\n\n- No shared secrets such as SSH keys or Kubernetes tokens; Teleport uses\n  certificate-based auth with automatic expiration for all protocols.\n- Multi-factor authentication (MFA) for everything.\n- Single sign-on (SSO) for everything via GitHub Auth, OpenID Connect, or\n  SAML with endpoints like Okta or Microsoft Entra ID.\n- Session sharing for collaborative troubleshooting for issues.\n- Infrastructure introspection to view the status of every SSH node, database\n  instance, Kubernetes cluster, or internal web app through the Teleport CLI\n  or Web UI.\n\nTeleport uses [Go crypto](https://godoc.org/golang.org/x/crypto). It is\n_fully compatible with OpenSSH_, `sshd` servers, and `ssh` clients,\nKubernetes clusters and more.\n\n| Project Links                                                  | Description                                                                                                                 |\n|----------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------|\n| [Teleport Website](https://goteleport.com/)                    | The official website of the project.                                                                                        |\n| [Documentation](https://goteleport.com/docs/)                  | Admin guide, user manual and more.                                                                                          |\n| [Features](https://goteleport.com/docs/feature-matrix/)        | Explore the complete list of Teleport capabilities.                                                                         |\n| [Blog](https://goteleport.com/blog/)                           | Our blog where we publish Teleport news and helpful articles.                                                               |\n| [Forum](https://github.com/gravitational/teleport/discussions) | Ask us a setup question or post tutorials, feedback, or ideas.                                                              |\n| [Developer Tools](https://goteleport.com/resources/tools/)     | Dozens of free browser-based tools for code processing, cryptography, data transformation, and more.                        |\n| [Teleport Academy](https://goteleport.com/learn/)              | How-to guides, best practices, and deep dives into topics like SSH, Kubernetes, MCP, and more.                              |\n| [Slack](https://goteleport.com/slack)                          | Need help with your setup? Ping us in our Slack channel.                                                                    |\n| [Cloud  & Self-Hosted](https://goteleport.com/pricing/)        | Teleport Enterprise is a cloud-hosted option for teams that require easy and secure access to their computing environments. |\n\n## Why We Built Teleport\n\nWhile working together at Rackspace, the creators of Teleport noticed that\nmost cloud users struggle with setting up and configuring infrastructure\nsecurity. Many popular tools designed for this are complex to understand and\nexpensive to maintain across modern, distributed computing infrastructure.\n\nWe decided to build a solution that's easy to use, understand, and scale. A\nreal-time representation of all your servers in the same room as you, as if\nthey were magically **teleported**. And thus, Teleport was born! \n\nToday, Teleport is trusted by everyone from hobbyists to hyperscalers to\nsimplify security across cloud CLIs and consoles, Kubernetes clusters, SSH\nservers, databases, internal web apps, and Model Context Protocol (MCP) used\nby AI agents.\n\n[Learn more about Teleport and our history](https://goteleport.com/about/)\n\n## Supporting & Contributing\n\nWe aim to make Teleport easy to adopt and contribute to, starting with clear and comprehensive [documentation](https://goteleport.com/docs/). \n\nIf you have questions, are exploring ideas, or want to sanity-check something, please start with a GitHub Discussion. Discussions help us answer questions, explore use cases, and decide together whether something should become a bug report or feature request.\n\n- Start a conversation in [Teleport Discussions](https://github.com/gravitational/teleport/discussions)  \n  This is the best place to ask questions, share ideas, and get help. Our engineers actively participate there, and discussions can be promoted to issues when there is a clear, actionable next step.\n\n- Issues are for confirmed bugs and well-defined feature requests  \n  If something has already been validated as a bug or an enhancement, feel free to open an issue. When in doubt, start a discussion and we will help guide it.\n\n- Enterprise and POC support  \n  If you are evaluating Teleport Enterprise or need more responsive support during a POC, we can set up a dedicated Slack channel. You can [reach out to us through our website](https://goteleport.com/contact-sales/) to get started.\n\n## Installing and Running\n\nTo set up a single-instance Teleport cluster, follow our [getting started\nguide](https://goteleport.com/docs/admin-guides/deploy-a-cluster/linux-demo/).\nYou can then register your servers, Kubernetes clusters, and other\ninfrastructure with your Teleport cluster.\n\nYou can also get started with Teleport Enterprise Cloud, a managed Teleport\ndeployment that makes it easier to enable secure access to your\ninfrastructure.\n\n[Sign up for a free trial](https://goteleport.com/signup/) of Teleport\nEnterprise Cloud, and follow this guide to [register your first\nserver](https://goteleport.com/docs/get-started/).\n\n## Docker\n\n### Deploy Teleport\n\nIf you wish to deploy Teleport inside a Docker container see the\n[installation guide](https://goteleport.com/docs/installation/#running-teleport-on-docker).\n\n### For Local Testing and Development\n\nTo run a full test suite locally, see [the test dependencies\nlist](BUILD_macos.md#local-tests-dependencies)\n\n## Building Teleport\n\nThe `teleport` repository contains the Teleport daemon binary (written in Go)\nand a web UI written in TypeScript.\n\nIf your intention is to build and deploy for use in a production infrastructure\na released tag should be used.  The default branch, `master`, is the current\ndevelopment branch for an upcoming major version.  Get the latest release tags\nlisted at https://goteleport.com/download/ and then use that tag in the `git\nclone`. For example `git clone\nhttps://github.com/gravitational/teleport.git -b v18.5.0` gets release\nv18.5.0.\n\n### Dockerized Build\n\nIt is often easiest to build with Docker, which ensures that all required\ntooling is available for the build. To execute a dockerized build, ensure\nthat docker is installed and running, and execute:\n\n```\nmake -C build.assets build-binaries\n```\n\nThis command will build Linux binaries matching the host architecture.\nIt is not possible to cross-compile to a different target architecture.\n\n### Local Build\n\n#### Dependencies\n\nThe following dependencies are required to build Teleport from source. For\nmaximum compatibility, install the versions of these dependencies using the\nversions listed in [`build.assets/versions.mk`](/build.assets/versions.mk):\n\n1. [`Go`](https://golang.org/dl/)\n1. [`Rust`](https://www.rust-lang.org/tools/install)\n1. [`Node.js`](https://nodejs.org/en/download/)\n1. [`libfido2`](https://github.com/Yubico/libfido2)\n1. [`pkg-config`](https://www.freedesktop.org/wiki/Software/pkg-config/)\n\nFor an example of dev environment setup on macOS, see [these\ninstructions](/BUILD_macos.md).\n\n#### Perform a build\n\n>**Important**\n>\n>* The Go compiler is somewhat sensitive to the amount of memory: you will\n   need **at least** 1GB of virtual memory to compile Teleport. A 512MB\n   instance without swap will **not** work.\n>* This will build the latest version of Teleport. \n\nGet the source\n\n```shell\ngit clone https://github.com/gravitational/teleport.git\ncd teleport\n```\n\nTo perform a build\n\n```shell\nmake full\n```\n\n`tsh` dynamically links against libfido2 by default, to support development\nenvironments, as long as the library itself can be found:\n\n```shell\n$ brew install libfido2 pkg-config  # Replace with your package manager of choice\n\n$ make build/tsh\n> libfido2 found, setting FIDO2=dynamic\n> (...)\n```\n\nRelease binaries are linked statically against libfido2. You may switch the\nlinking mode using the FIDO2 variable:\n\n```shell\nmake build/tsh FIDO2=dynamic # dynamic linking\nmake build/tsh FIDO2=static  # static linking, for an easy setup use `make enter`\n                             # or `build.assets/macos/build-fido2-macos.sh`.\nmake build/tsh FIDO2=off     # doesn't link libfido2 in any way\n```\n\n`tsh` builds with Touch ID support require access to an Apple Developer\naccount. If you are a Teleport maintainer, ask the team for access.\n\n#### Build output and run locally\n\nIf the build succeeds, the installer will place the binaries in the `build`\ndirectory.\n\nBefore starting, create default data directories:\n\n```shell\nsudo mkdir -p -m0700 /var/lib/teleport\nsudo chown $USER /var/lib/teleport\n```\n\n#### Running Teleport in a hot reload mode\n\nTo speed up your development process, you can run Teleport using\n[`CompileDaemon`](https://github.com/githubnemo/CompileDaemon). This will\nbuild and run the Teleport binary, and then rebuild and restart it whenever\nany Go source files change.\n\n1. Install CompileDaemon:\n\n    ```shell\n    go install github.com/githubnemo/CompileDaemon@latest\n    ```\n\n    Note that we use `go install` instead of the suggested `go get`, because\n    we don't want CompileDaemon to become a dependency of the project.\n\n1. Build and run the Teleport binary:\n\n    ```shell\n    make teleport-hot-reload\n    ```\n\n    By default, this runs a `teleport start` command. If you want to\n    customize the command, for example by providing a custom config file\n    location, you can use the `TELEPORT_ARGS` parameter:\n\n    ```shell\n    make teleport-hot-reload TELEPORT_ARGS='start --config=/path/to/config.yaml'\n    ```\n\nNote that you still need to run [`make grpc`](api/proto/README.md) if you\nmodify any Protocol Buffers files to regenerate the generated Go sources;\nregenerating these sources should in turn cause the CompileDaemon to rebuild\nand restart Teleport.\n\n### Web UI\n\nThe Teleport Web UI resides in the [web](web) directory.\n\n#### Rebuilding Web UI for development\n\nTo rebuild the Teleport UI package, run the following command:\n\n```bash\nmake docker-ui\n```\n\nThen you can replace Teleport Web UI files with the files from the\nnewly-generated `/dist` folder.\n\nTo enable speedy iterations on the Web UI, you can run a [local web-dev\nserver](web#web-ui).\n\nYou can also tell Teleport to load the Web UI assets from the source\ndirectory. To enable this behavior, set the environment variable `DEBUG=1`\nand rebuild with the default target:\n\n```bash\n# Run Teleport as a single-node cluster in development mode:\nDEBUG=1 ./build/teleport start -d\n```\n\nKeep the server running in this mode, and make your UI changes in `/dist`\ndirectory. For instructions about how to update the Web UI, read [the `web`\nREADME](web#readme).\n\n### Managing dependencies\n\nAll dependencies are managed using [Go\nmodules](https://blog.golang.org/using-go-modules). Here are the\ninstructions for some common tasks:\n\n#### Add a new dependency\n\nLatest version:\n\n```bash\ngo get github.com/new/dependency\n```\n\nand update the source to use this dependency.\n\n\nTo get a specific version, use `go get\ngithub.com/new/dependency@version` instead.\n\n#### Set dependency to a specific version\n\n```bash\ngo get github.com/new/dependency@version\n```\n\n#### Update dependency to the latest version\n\n```bash\ngo get -u github.com/new/dependency\n```\n\n#### Update all dependencies\n\n```bash\ngo get -u all\n```\n\n#### Debugging dependencies\n\nWhy is a specific package imported?\n\n`go mod why $pkgname`\n\nWhy is a specific module imported?\n\n`go mod why -m $modname`\n\nWhy is a specific version of a module imported?\n\n`go mod graph | grep $modname`\n\n## License\n\nTeleport is distributed in multiple forms with different licensing\nimplications.\n\nThe Teleport API module (all code in this repository under `/api`) is\navailable under the [Apache 2.0 license](./api/LICENSE).\n\nThe remainder of the source code in this repository is available under the\n[GNU Affero General Public License](./LICENSE). Users compiling Teleport\nfrom source must comply with the terms of this license.\n\nTeleport Community Edition builds distributed on\nhttp://goteleport.com/download are available under a [modified Apache 2.0\nlicense](./build.assets/LICENSE-community).\n\n## FAQ\n\n### Is Teleport production-ready?\n\nYes, Teleport is production-ready and used to protect and facilitate\naccess to the most precious and mission-critical applications at many of\ntoday's leading companies. You can learn more about the companies using\nTeleport in production [on our website](https://goteleport.com/case-study/).\n\n### Is Teleport secure?\n\nYes, Teleport has completed several security audits from nationally and\ninternationally recognized technology security companies. We publicize\naudit results, our security philosophy, and related information on our\n[trust page](https://trust.goteleport.com/).\n\n### What resources does Teleport support?\n\nTeleport secures access to a [broad set of infrastructure\nresources](https://goteleport.com/docs/enroll-resources), including Linux\nservers, Windows desktops, Kubernetes clusters, databases, internal web\napplications, cloud provider APIs and consoles (such as AWS, Azure, and\nGCP), and Model Context Protocol (MCP) servers used by AI agents.\n\n### How is Teleport deployed?\n\nTeleport can be [deployed to fit most\nenvironments](https://goteleport.com/docs/feature-matrix/#platform-integrations-management-licensing-and-deployment),\neither as a self-hosted cluster on Linux or Kubernetes or using Teleport\nEnterprise Cloud. In all cases, Teleport agents run close to your\nresources and connect through an Auth Service and Proxy Service that\nenforces identity, access control, and audit.\n\n### Is Teleport an identity provider (IdP)?\n\nTeleport uses existing IdPs (Okta, Google Workspace, Microsoft Entra ID,\nor GitHub) to issue short-lived certificates and apply access policies.\nTeleport can also be [configured to act as a SAML\nIdP](https://goteleport.com/docs/identity-governance/idps/) to authenticate\nusers into applications when needed.\n\n### Does Teleport require credential handling or secrets management?\n\nTeleport eliminates long-lived passwords, SSH keys, database credentials,\ncredential rotations, and vault processes by issuing [short-lived,\nauto-expiring mTLS and SSH\ncertificates](https://goteleport.com/docs/reference/architecture/authentication/#short-lived-certificates)\nbound to human or non-human identity.\n\n### Is Teleport a Privileged Access Management (PAM) solution?\n\nTeleport provides modern PAM software capabilities like strong\nauthentication, session recording, policy-based access, and JIT elevation\nwithout secrets, credential rotation, or vault dependencies. This enables\ncontrolled, audited access to servers, Kubernetes, databases, cloud\nconsoles, and other privileged environments using short-lived certificates\nand role-based policies.\n\n### Is Teleport a Just-in-Time (JIT) access solution?\n\nTeleport enables [JIT access through time-bound Access\nRequests](https://goteleport.com/docs/identity-governance/access-requests/).\nUsers request the roles or resources they temporarily need, policies decide\nwhether approval is required, and privileges automatically expire. This\napproach maintains least privilege while keeping access workflows\nefficient and predictable.\n\n### Does Teleport secure access to Kubernetes?\n\nTeleport can [proxy and secure Kubernetes\naccess](https://goteleport.com/docs/enroll-resources/kubernetes-access/introduction/)\nwith identity-based authentication, role-based access controls, and\ndetailed auditing of kubectl activity.\n\n### Does Teleport support SPIFFE?\n\nTeleport supports [SPIFFE-compatible identities for\nworkloads](https://goteleport.com/docs/machine-workload-identity/workload-identity/spiffe/),\nallowing it to participate in SPIFFE ecosystems and federation.\nTeleport issues short-lived SVIDs and can integrate with external PKI\nhierarchies.\n\n### Is Teleport an alternative for VPNs or bastion hosts?\n\nYes. Teleport is frequently used as an alternative to traditional VPNs\nand bastion hosts, enabling [direct, identity-based access to\nresources](https://goteleport.com/docs/core-concepts/#teleport-proxy-service)\ninstead of broad network access.\n\n### Does Teleport secure the Model Context Protocol (MCP) and AI agents?\n\nTeleport [secures MCP\nconnections](https://goteleport.com/docs/connect-your-client/model-context-protocol/)\nby placing identity-aware policy enforcement between MCP clients and\nservers. This ensures all tool invocations are authenticated, authorized,\nand audited without custom authorization code and that sensitive systems\nare protected from overly broad access.\n",
      "stars_today": 13
    },
    {
      "id": 390873100,
      "name": "komorebi",
      "full_name": "LGUG2Z/komorebi",
      "description": "A tiling window manager for Windows üçâ",
      "html_url": "https://github.com/LGUG2Z/komorebi",
      "stars": 13781,
      "forks": 297,
      "language": "Rust",
      "topics": [
        "autohotkey",
        "palestine",
        "rust",
        "status-bar",
        "tiling-window-manager",
        "whkd",
        "windows"
      ],
      "created_at": "2021-07-29T23:20:15Z",
      "updated_at": "2026-01-13T23:41:15Z",
      "pushed_at": "2026-01-13T16:26:52Z",
      "open_issues": 88,
      "owner": {
        "login": "LGUG2Z",
        "avatar_url": "https://avatars.githubusercontent.com/u/13164844?v=4"
      },
      "readme": "# komorebi\n\nTiling Window Management for Windows.\n\n<p>\n  <a href=\"https://techforpalestine.org/learn-more\">\n    <img alt=\"Tech for Palestine\" src=\"https://badge.techforpalestine.org/default\">\n  </a>\n  <img alt=\"GitHub Workflow Status\" src=\"https://img.shields.io/github/actions/workflow/status/LGUG2Z/komorebi/.github/workflows/windows.yaml\">\n  <img alt=\"GitHub all releases\" src=\"https://img.shields.io/github/downloads/LGUG2Z/komorebi/total\">\n  <img alt=\"GitHub commits since latest release (by date) for a branch\" src=\"https://img.shields.io/github/commits-since/LGUG2Z/komorebi/latest\">\n  <img alt=\"Active Individual Commercial Use Licenses\" src=\"https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Flgug2z-ecstaticmagentacheetah.web.val.run&query=%24.&label=active%20individual%20commercial%20use%20licenses&cacheSeconds=3600&link=https%3A%2F%2Flgug2z.com%2Fsoftware%2Fkomorebi\">\n  <a href=\"https://discord.gg/mGkn66PHkx\">\n    <img alt=\"Discord\" src=\"https://img.shields.io/discord/898554690126630914\">\n  </a>\n  <a href=\"https://github.com/sponsors/LGUG2Z\">\n    <img alt=\"GitHub Sponsors\" src=\"https://img.shields.io/github/sponsors/LGUG2Z\">\n  </a>\n  <a href=\"https://ko-fi.com/lgug2z\">\n    <img alt=\"Ko-fi\" src=\"https://img.shields.io/badge/kofi-tip-green\">\n  </a>\n  <a href=\"https://notado.app/feeds/jado/software-development\">\n    <img alt=\"Notado Feed\" src=\"https://img.shields.io/badge/Notado-Subscribe-informational\">\n  </a>\n  <a href=\"https://www.youtube.com/channel/UCeai3-do-9O4MNy9_xjO6mg?sub_confirmation=1\">\n    <img alt=\"YouTube\" src=\"https://img.shields.io/youtube/channel/subscribers/UCeai3-do-9O4MNy9_xjO6mg\">\n  </a>\n</p>\n\n![screenshot](https://user-images.githubusercontent.com/13164844/184027064-f5a6cec2-2865-4d65-a549-a1f1da589abf.png)\n\n## Note: Students using devices enrolled in mobile device management (MDM)\n\nYour usage still falls under the [Komorebi License 2.0.0](./LICENSE.md).\n\nYou can email me at the address I sign my commits with (add `.patch` to the end\nof any commit URL on GitHub to find it) from the address associated with your\ninstitution with the subject \"komorebi - student with an MDM device\", and I will\nbe able to remove the splash intended for corporate users, whose usage falls\nunder the [Individual Commercial Use\nLicense](https://lgug2z.com/software/komorebi).\n\nThis is currently a manual process - most days this shouldn't take more than\n12h, and you will receive an email reply from me when the process is complete.\n\nIf you haven't had a reply to your email within 24h you can reach out to me on\nDiscord.\n\n## Note: Unexpected mobile device management (MDM) detection prompts\n\nYou have most likely unintentionally enrolled your device in \"Bring Your Own\nDevice\" (BYOD) MDM. You can confirm if this is the case by running `dsregcmd\n/status` and then take the appropriate steps to remove the MDM profile and take\nback full control of your system.\n\nIf you need help doing this you can ask on Discord.\n\n## Note: komorebi for Mac\n\nIf you made your way to this repo looking for [komorebi for\nMac](https://github.com/KomoCorp/komorebi-for-mac), the project is currently\nbeing developed in private with [early access available to GitHub\nSponsors](https://github.com/sponsors/LGUG2Z).\n\nIf you want to see how far along development is before signing up for early\naccess (spoiler: it's very far along!) there is an overview video you can watch\n[here](https://www.youtube.com/watch?v=u3eJcsa_MJk).\n\nSponsors with early access can install komorebi for Mac either by compiling\nfrom source, by using Homebrew, or by using the project's Nix Flake. \n\n## Overview\n\n_komorebi_ is a tiling window manager that works as an extension to Microsoft's\n[Desktop Window\nManager](https://docs.microsoft.com/en-us/windows/win32/dwm/dwm-overview) in\nWindows 10 and above.\n\n_komorebi_ allows you to control application windows, virtual workspaces and display monitors with a CLI which can be\nused with third-party software such as [`whkd`](https://github.com/LGUG2Z/whkd)\nand [AutoHotKey](https://github.com/Lexikos/AutoHotkey_L) to set user-defined keyboard shortcuts.\n\n_komorebi_ aims to make _as few modifications as possible_ to the operating\nsystem and desktop environment by default. Users are free to make such\nmodifications in their own configuration files for _komorebi_, but these will\nremain opt-in and off-by-default for the foreseeable future.\n\nPlease refer to the [documentation](https://lgug2z.github.io/komorebi) for instructions on how\nto [install](https://lgug2z.github.io/komorebi/installation.html) and\n[configure](https://lgug2z.github.io/komorebi/example-configurations.html)\n_komorebi_, [common workflows](https://lgug2z.github.io/komorebi/common-workflows/komorebi-config-home.html), a complete\n[configuration schema reference](https://komorebi.lgug2z.com/schema) and a\ncomplete [CLI reference](https://lgug2z.github.io/komorebi/cli/quickstart.html).\n\n## Community\n\nThere is a [Discord server](https://discord.gg/mGkn66PHkx) available for\n_komorebi_-related discussion, help, troubleshooting etc. If you have any\nspecific feature requests or bugs to report, please create an issue in this\nrepository.\n\nThere is a [YouTube\nchannel](https://www.youtube.com/channel/UCeai3-do-9O4MNy9_xjO6mg) where I post\n_komorebi_ development videos, feature previews and release overviews. Subscribing\nto the channel (which is monetized as part of the YouTube Partner Program) and\nwatching videos is a really simple and passive way to contribute financially to\nthe development and maintenance of _komorebi_.\n\nThere is an [Awesome List](https://github.com/LGUG2Z/awesome-komorebi) which\nshowcases the many awesome projects that exist in the _komorebi_ ecosystem.\n\n## Licensing for Personal Use\n\n`komorebi` is [educational source\nsoftware](https://lgug2z.com/articles/educational-source-software/).\n\n`komorebi` is licensed under the [Komorebi 2.0.0\nlicense](https://github.com/LGUG2Z/komorebi-license), which is a fork of the\n[PolyForm Strict 1.0.0\nlicense](https://polyformproject.org/licenses/strict/1.0.0). On a high level\nthis means that you are free to do whatever you want with `komorebi` for\npersonal use other than redistribution, or distribution of new works (i.e.\nhard-forks) based on the software.\n\nAnyone is free to make their own fork of `komorebi` with changes intended either\nfor personal use or for integration back upstream via pull requests.\n\nThe [Komorebi 2.0.0 License](https://github.com/LGUG2Z/komorebi-license) does\nnot permit any kind of commercial use (i.e. using `komorebi` at work).\n\n## Sponsorship for Personal Use\n\n_komorebi_ is a free and educational source project, and one that encourages you\nto make charitable donations if you find the software to be useful and have the\nfinancial means.\n\nI encourage you to make a charitable donation to the [Palestine Children's\nRelief Fund](https://pcrf1.app.neoncrm.com/forms/gaza-recovery) or to contribute\nto a [Gaza Funds campaign](https://gazafunds.com) before you consider sponsoring\nme on GitHub.\n\n[GitHub Sponsors is enabled for this\nproject](https://github.com/sponsors/LGUG2Z). Sponsors can claim custom roles on\nthe Discord server, get shout outs at the end of _komorebi_-related videos on\nYouTube, gain the ability to submit feature requests on the issue tracker, and\nreceive releases of komorebi with \"easter eggs\" on physical media.\n\nIf you would like to tip or sponsor the project but are unable to use GitHub\nSponsors, you may also sponsor through [Ko-fi](https://ko-fi.com/lgug2z), or\nmake an anonymous Bitcoin donation to `bc1qv73wzspc77k46uty4vp85x8sdp24mphvm58f6q`.\n\n## Licensing for Commercial Use\n\nA dedicated Individual Commercial Use License is available for those who want to\nuse `komorebi` at work.\n\nThe Individual Commerical Use License adds ‚ÄúCommercial Use‚Äù as a ‚ÄúPermitted Use‚Äù\nfor the licensed individual only, for the duration of a valid paid license\nsubscription only. All provisions and restrictions enumerated in the [Komorebi\nLicense](https://github.com/LGUG2Z/komorebi-license) continue to apply.\n\nMore information, pricing and purchase links for Individual Commercial Use\nLicenses [can be found here](https://lgug2z.com/software/komorebi).\n\n# Installation\n\nA [detailed installation and quickstart\nguide](https://lgug2z.github.io/komorebi/installation.html) is available which shows how to get started\nusing `scoop`, `winget` or building from source.\n\n[![Watch the quickstart walkthrough video](https://img.youtube.com/vi/MMZUAtHbTYY/hqdefault.jpg)](https://www.youtube.com/watch?v=MMZUAtHbTYY)\n\n# Comparison With Fancy Zones\n\nCommunity member [Olge](https://www.youtube.com/@polle5555) has created an\nexcellent video which compares the default window management features of\nWindows 11, Fancy Zones and komorebi.\n\nIf you are not familiar with tiling window managers or if you are looking at\nkomorebi and wondering \"how is this different from Fancy Zones? ü§î\", this short\nvideo will answer the majority of your questions.\n\n[![Watch the comparison video](https://img.youtube.com/vi/0LCbS_gm0RA/hqdefault.jpg)](https://www.youtube.com/watch?v=0LCbS_gm0RA)\n\n# Demonstrations\n\n[@amnweb](https://github.com/amnweb) showing _komorebi_ `v0.1.28` running on Windows 11 with window borders,\nunfocused window transparency and animations enabled, using a custom status bar integrated using\n_komorebi_'\ns [Window Manager Event Subscriptions](https://github.com/LGUG2Z/komorebi?tab=readme-ov-file#window-manager-event-subscriptions).\n\nhttps://github.com/LGUG2Z/komorebi/assets/13164844/21be8dc4-fa76-4f70-9b37-1d316f4b40c2\n\n[@haxibami](https://github.com/haxibami) showing _komorebi_ running on Windows\n11 with a terminal emulator, a web browser and a code editor. The original\nvideo can be viewed\n[here](https://twitter.com/haxibami/status/1501560766578659332).\n\nhttps://user-images.githubusercontent.com/13164844/163496447-20c3ff0a-c5d8-40d1-9cc8-156c4cebf12e.mp4\n\n[@aik2mlj](https://github.com/aik2mlj) showing _komorebi_ running on Windows 11\nwith multiple workspaces, terminal emulators, a web browser, and the\n[yasb](https://github.com/DenBot/yasb) status bar with the _komorebi_ workspace\nwidget enabled. The original video can be viewed\n[here](https://zhuanlan.zhihu.com/p/455064481).\n\nhttps://user-images.githubusercontent.com/13164844/163496414-a9cde3d1-b8a7-4a7a-96fb-a8985380bc70.mp4\n\n# Contribution Guidelines\n\nIf you would like to contribute to `komorebi` please take the time to carefully\nread the guidelines below.\n\nPlease see [CONTRIBUTING.md](./CONTRIBUTING.md) for more information about how\ncode contributions to `komorebi` are licensed.\n\n## Commit hygiene\n\n- Flatten all `use` statements\n- Run `cargo +stable clippy` and ensure that all lints and suggestions have been addressed before committing\n- Run `cargo +nightly fmt --all` to ensure consistent formatting before committing\n- Use `git cz` with\n  the [Commitizen CLI](https://github.com/commitizen/cz-cli#conventional-commit-messages-as-a-global-utility) to prepare\n  commit messages\n- Provide **at least** one short sentence or paragraph in your commit message body to describe your thought process for\n  the changes being committed\n\n## PRs should contain only a single feature or bug fix\n\nIt is very difficult to review pull requests which touch multiple unrelated features and parts of the codebase.\n\nPlease do not submit pull requests like this; you will be asked to separate them into smaller PRs that deal only with\none feature or bug fix at a time.\n\nIf you are working on multiple features and bug fixes, I suggest that you cut a branch called `local-trunk`\nfrom `master` which you keep up to date, and rebase the various independent branches you are working on onto that branch\nif you want to test them together or create a build with everything integrated.\n\n## Refactors to the codebase must have prior approval\n\n`komorebi` is a mature codebase with an internal consistency and structure that has developed organically over close to\nhalf a decade.\n\nThere are [countless hours of live coding videos](https://youtube.com/@LGUG2Z) demonstrating work on this project and\nshowing new contributors how to do everything from basic tasks like implementing new `komorebic` commands to\ndistinguishing monitors by manufacturer hardware identifiers and video card ports.\n\nRefactors to the structure of the codebase are not taken lightly and require prior discussion and approval.\n\nPlease do not start refactoring the codebase with the expectation of having your changes integrated until you receive an\nexplicit approval or a request to do so.\n\nSimilarly, when implementing features and bug fixes, please stick to the structure of the codebase as much as possible\nand do not take this as an opportunity to do some \"refactoring along the way\".\n\nIt is extremely difficult to review PRs for features and bug fixes if they are lost in sweeping changes to the structure\nof the codebase.\n\n## Breaking changes to user-facing interfaces are unacceptable\n\nThis includes but is not limited to:\n\n- All `komorebic` commands\n- The `komorebi.json` schema\n- The [\n  `komorebi-application-specific-configuration`](https://github.com/LGUG2Z/komorebi-application-specific-configuration)\n  schema\n\nNo user should ever find that their configuration file has stopped working after upgrading to a new version\nof `komorebi`.\n\nMore often than not there are ways to reformulate changes that may initially seem like they require breaking user-facing\ninterfaces into additive changes.\n\nFor some inspiration please take a look\nat [this commit](https://github.com/LGUG2Z/komorebi/commit/e7d928a065eb63bb4ea1fb864c69c1cae8cc763b) which added the\nability for users to specify colours in `komorebi.json` in Hex format alongside RGB.\n\nThere is also a process in place for graceful, non-breaking, deprecation of configuration options that are no longer\nrequired.\n\n# Development\n\nIf you use IntelliJ, you should enable the following settings to ensure that code generated by macros is recognised by\nthe IDE for completions and navigation:\n\n- Set `Expand declarative macros`\n  to `Use new engine` under \"Settings > Langauges & Frameworks > Rust\"\n- Enable the following experimental features:\n    - `org.rust.cargo.evaluate.build.scripts`\n    - `org.rust.macros.proc`\n\n# Logs and Debugging\n\nLogs from `komorebi` will be appended to `%LOCALAPPDATA%/komorebi/komorebi.log`; this file is never rotated or\noverwritten, so it will keep growing until it is deleted by the user.\n\nWhenever running the `komorebic stop` command or sending a Ctrl-C signal to `komorebi` directly, the `komorebi` process\nensures that all hidden windows are restored before termination.\n\nIf however, you ever end up with windows that are hidden and cannot be restored, a list of window handles known\nto `komorebi` are stored and continuously updated in `%LOCALAPPDATA%/komorebi//komorebi.hwnd.json`.\n\n## Restoring Windows\n\nRunning `komorebic restore-windows` will read the list of window handles and forcibly restore them, regardless of\nwhether the main `komorebi` process is running.\n\n## Panics and Deadlocks\n\nIf `komorebi` ever stops responding, it is most likely either due to either a panic or a deadlock. In the case of a\npanic, this will be reported in the log. In the case of a deadlock, there will not be any errors in the log, but the\nprocess and the log will appear frozen.\n\nIf you believe you have encountered a deadlock, you can compile `komorebi` with `--features deadlock_detection` and try\nreproducing the deadlock again. This will check for deadlocks every 5 seconds in the background, and if a deadlock is\nfound, information about it will appear in the log which can be shared when opening an issue.\n\n# Window Manager State and Integrations\n\nThe current state of the window manager can be queried using the `komorebic state` command, which returns a JSON\nrepresentation of the `State` struct.\n\nThis may also be polled to build further integrations and widgets on top of.\n\n# Window Manager Event Subscriptions\n\n## Named Pipes\n\nIt is possible to subscribe to notifications of every `WindowManagerEvent` and `SocketMessage` handled\nby `komorebi` using [Named Pipes](https://docs.microsoft.com/en-us/windows/win32/ipc/named-pipes).\n\nFirst, your application must create a named pipe. Once the named pipe has been created, run the following command:\n\n```powershell\nkomorebic.exe subscribe-pipe <your pipe name>\n```\n\nNote that you do not have to include the full path of the named pipe, just the name.\n\nIf the named pipe exists, `komorebi` will start pushing JSON data of successfully handled events and messages:\n\n```json lines\n{\"event\":{\"type\":\"AddSubscriber\",\"content\":\"yasb\"},\"state\":{}}\n{\"event\":{\"type\":\"FocusWindow\",\"content\":\"Left\"},\"state\":{}}\n{\"event\":{\"type\":\"FocusChange\",\"content\":[\"SystemForeground\",{\"hwnd\":131444,\"title\":\"komorebi ‚Äì README.md\",\"exe\":\"idea64.exe\",\"class\":\"SunAwtFrame\",\"rect\":{\"left\":13,\"top\":60,\"right\":1520,\"bottom\":1655}}]},\"state\":{}}\n{\"event\":{\"type\":\"MonitorPoll\",\"content\":[\"ObjectCreate\",{\"hwnd\":5572450,\"title\":\"OLEChannelWnd\",\"exe\":\"explorer.exe\",\"class\":\"OleMainThreadWndClass\",\"rect\":{\"left\":0,\"top\":0,\"right\":0,\"bottom\":0}}]},\"state\":{}}\n{\"event\":{\"type\":\"FocusWindow\",\"content\":\"Right\"},\"state\":{}}\n{\"event\":{\"type\":\"FocusChange\",\"content\":[\"SystemForeground\",{\"hwnd\":132968,\"title\":\"Windows PowerShell\",\"exe\":\"WindowsTerminal.exe\",\"class\":\"CASCADIA_HOSTING_WINDOW_CLASS\",\"rect\":{\"left\":1539,\"top\":60,\"right\":1520,\"bottom\":821}}]},\"state\":{}}\n{\"event\":{\"type\":\"FocusWindow\",\"content\":\"Down\"},\"state\":{}}\n{\"event\":{\"type\":\"FocusChange\",\"content\":[\"SystemForeground\",{\"hwnd\":329264,\"title\":\"den ‚Äî Mozilla Firefox\",\"exe\":\"firefox.exe\",\"class\":\"MozillaWindowClass\",\"rect\":{\"left\":1539,\"top\":894,\"right\":1520,\"bottom\":821}}]},\"state\":{}}\n{\"event\":{\"type\":\"FocusWindow\",\"content\":\"Up\"},\"state\":{}}\n{\"event\":{\"type\":\"FocusChange\",\"content\":[\"SystemForeground\",{\"hwnd\":132968,\"title\":\"Windows PowerShell\",\"exe\":\"WindowsTerminal.exe\",\"class\":\"CASCADIA_HOSTING_WINDOW_CLASS\",\"rect\":{\"left\":1539,\"top\":60,\"right\":1520,\"bottom\":821}}]},\"state\":{}}\n```\n\nYou may then filter on the `type` key to listen to the events that you are interested in. For a full list of possible\nnotification types, refer to the enum variants of `WindowManagerEvent` in `komorebi` and `SocketMessage`\nin `komorebi::core`.\n\nBelow is an example of how you can subscribe to and filter on events using a named pipe in `nodejs`.\n\n```javascript\nconst { exec } = require(\"child_process\");\nconst net = require(\"net\");\n\nconst pipeName = \"\\\\\\\\.\\\\pipe\\\\komorebi-js\";\nconst server = net.createServer((stream) => {\n  console.log(\"Client connected\");\n\n  // Every time there is a workspace-related event, let's log the names of all\n  // workspaces on the currently focused monitor, and then log the name of the\n  // currently focused workspace on that monitor\n\n  stream.on(\"data\", (data) => {\n    let json = JSON.parse(data.toString());\n    let event = json.event;\n\n    if (event.type.includes(\"Workspace\")) {\n      let monitors = json.state.monitors;\n      let current_monitor = monitors.elements[monitors.focused];\n      let workspaces = monitors.elements[monitors.focused].workspaces;\n      let current_workspace = workspaces.elements[workspaces.focused];\n\n      console.log(\n        workspaces.elements\n          .map((workspace) => workspace.name)\n          .filter((name) => name !== null)\n      );\n      console.log(current_workspace.name);\n    }\n  });\n\n  stream.on(\"end\", () => {\n    console.log(\"Client disconnected\");\n  });\n});\n\nserver.listen(pipeName, () => {\n  console.log(\"Named pipe server listening\");\n});\n\nconst command = \"komorebic subscribe-pipe komorebi-js\";\n\nexec(command, (error, stdout, stderr) => {\n  if (error) {\n    console.error(`Error executing command: ${error}`);\n    return;\n  }\n});\n```\n\n## Unix Domain Sockets\n\nIt is possible to subscribe to notifications of every `WindowManagerEvent` and `SocketMessage` handled\nby `komorebi` using [Unix Domain Sockets](https://devblogs.microsoft.com/commandline/af_unix-comes-to-windows/).\n\nUDS are also the only mode of communication between `komorebi` and `komorebic`.\n\nFirst, your application must create a socket in `$ENV:LocalAppData\\komorebi`. Once the socket has been created, run the\nfollowing command:\n\n```powershell\nkomorebic.exe subscribe-socket <your socket name>\n```\n\nIf the socket exists, komorebi will start pushing JSON data of successfully handled events and messages as in the\nexample above in the Named Pipes section.\n\n## Rust Client\n\nAs of `v0.1.22` it is possible to use the `komorebi-client` crate to subscribe to notifications of\nevery `WindowManagerEvent` and `SocketMessage` handled by `komorebi` in a Rust codebase.\n\nBelow is a simple example of how to use `komorebi-client` in a basic Rust application.\n\n```rust\n// komorebi-client = { git = \"https://github.com/LGUG2Z/komorebi\", tag = \"v0.1.39\"}\n\nuse anyhow::Result;\nuse komorebi_client::Notification;\nuse komorebi_client::NotificationEvent;\nuse komorebi_client::UnixListener;\nuse komorebi_client::WindowManagerEvent;\nuse std::io::BufRead;\nuse std::io::BufReader;\nuse std::io::Read;\n\npub fn main() -> anyhow::Result<()> {\n  let socket = komorebi_client::subscribe(NAME)?;\n\n  for incoming in socket.incoming() {\n    match incoming {\n      Ok(data) => {\n        let reader = BufReader::new(data.try_clone()?);\n\n        for line in reader.lines().flatten() {\n          let notification: Notification = match serde_json::from_str(&line) {\n            Ok(notification) => notification,\n            Err(error) => {\n              log::debug!(\"discarding malformed komorebi notification: {error}\");\n              continue;\n            }\n          };\n\n          // match and filter on desired notifications\n        }\n      }\n      Err(error) => {\n        log::debug!(\"{error}\");\n      }\n    }\n  }\n\n}\n```\n\nA read-world example can be found\nin [komokana](https://github.com/LGUG2Z/komokana/blob/feature/komorebi-uds/src/main.rs).\n\n## Subscription Event Notification Schema\n\nA [JSON Schema](https://json-schema.org/) of the event notifications emitted to subscribers can be generated with\nthe `komorebic notification-schema` command. The output of this command can be redirected to the clipboard or a file,\nwhich can be used with services such as [Quicktype](https://app.quicktype.io/) to generate type definitions in different\nprogramming languages.\n\n## Communication over TCP\n\nA TCP listener can optionally be exposed on a port of your choosing with the `--tcp-port=N` flag. If this flag is not\nprovided to `komorebi` or `komorebic start`, no TCP listener will be created.\n\nOnce created, your client may send\nany [SocketMessage](https://github.com/LGUG2Z/komorebi/blob/master/komorebi/src/core/mod.rs#L37) to `komorebi` in the\nsame way that `komorebic` would.\n\nThis can be used if you would like to create your own alternative to `komorebic` which incorporates scripting and\nvarious middleware layers, and similarly it can be used if you would like to integrate `komorebi` with\na [custom input handler](https://github.com/LGUG2Z/komorebi/issues/176#issue-1302643961).\n\nIf a client sends an unrecognized message, it will be disconnected and have to reconnect before trying to communicate\nagain.\n\n## Socket Message Schema\n\nA [JSON Schema](https://json-schema.org/) of socket messages used to send instructions to `komorebi` can be generated\nwith the `komorebic socket-schema` command. The output of this command can be redirected to the clipboard or a file,\nwhich can be used with services such as [Quicktype](https://app.quicktype.io/) to generate type definitions in different\nprogramming languages.\n\n# Appreciations\n\n- First and foremost, thank you to my wife, both for naming this project and for her patience throughout its\n  never-ending development\n\n- Thank you to [@sitiom](https://github.com/sitiom) for\n  being [an exemplary open source community leader](https://jeezy.substack.com/p/the-open-source-contributions-i-appreciate)\n\n- Thank you to the developers of [nog](https://github.com/TimUntersberger/nog) who came before me and whose work taught\n  me more than I can ever hope to repay\n\n- Thank you to the developers of [GlazeWM](https://github.com/lars-berger/GlazeWM) for pushing the boundaries of tiling\n  window management on Windows with me and having an excellent spirit of collaboration\n\n- Thank you to [@Ciantic](https://github.com/Ciantic) for helping me bring\n  the [hidden Virtual Desktops cloaking function](https://github.com/Ciantic/AltTabAccessor/issues/1) to `komorebi`\n",
      "stars_today": 13
    },
    {
      "id": 769564277,
      "name": "code2prompt",
      "full_name": "mufeedvh/code2prompt",
      "description": "A CLI tool to convert your codebase into a single LLM prompt with source tree, prompt templating, and token counting.",
      "html_url": "https://github.com/mufeedvh/code2prompt",
      "stars": 7010,
      "forks": 395,
      "language": "Rust",
      "topics": [
        "ai",
        "chatgpt",
        "claude",
        "cli",
        "command-line",
        "command-line-tool",
        "gpt",
        "llm",
        "prompt",
        "prompt-engineering",
        "prompt-generator",
        "prompt-toolkit",
        "rust"
      ],
      "created_at": "2024-03-09T12:42:06Z",
      "updated_at": "2026-01-14T00:37:42Z",
      "pushed_at": "2026-01-12T22:37:38Z",
      "open_issues": 16,
      "owner": {
        "login": "mufeedvh",
        "avatar_url": "https://avatars.githubusercontent.com/u/26198477?v=4"
      },
      "readme": "<div align=\"center\">\n  <a href=\"https://code2prompt.dev\">\n    <img align=\"center\" width=\"550px\" src=\"https://github.com/mufeedvh/code2prompt/blob/main/.assets/logo_dark_v0.0.2.svg?raw=true\" alt=\"Code2prompt\"/>\n  </a>\n  <br>\n  <h3>Convert your codebase into a single LLM prompt.</h3>\n</div>\n\n<p align=\"center\">\n  <a href=\"https://code2prompt.dev\"><b>Website</b></a> ‚Ä¢\n  <a href=\"https://code2prompt.dev/docs/welcome/\"><b>Documentation</b></a> ‚Ä¢\n  <a href=\"https://discord.com/invite/ZZyBbsHTwH\"><b>Discord</b></a>\n</p>\n\n<div align=\"center\">\n\n[![License](https://img.shields.io/github/license/mufeedvh/code2prompt.svg?style=flat-square)](https://github.com/mufeedvh/code2prompt/blob/master/LICENSE)\n[![Crates.io](https://img.shields.io/crates/v/code2prompt.svg?style=flat-square)](https://crates.io/crates/code2prompt)\n[![PyPI](https://img.shields.io/pypi/v/code2prompt-rs?style=flat-square&logo=pypi&logoColor=white)](https://pypi.org/project/code2prompt-rs/)\n[![CI](https://github.com/mufeedvh/code2prompt/actions/workflows/ci.yml/badge.svg?style=flat-square)](https://github.com/mufeedvh/code2prompt/actions)\n[![Discord](https://img.shields.io/discord/1342336677905039451?style=flat-square&logo=discord&logoColor=white)](https://discord.com/invite/ZZyBbsHTwH)\n[![Docs.rs](https://docs.rs/code2prompt-core/badge.svg?style=flat-square)](https://docs.rs/code2prompt-core)\n[![Crates.io Downloads](https://img.shields.io/crates/d/code2prompt.svg?style=flat-square)](https://crates.io/crates/code2prompt)\n[![GitHub Stars](https://img.shields.io/github/stars/mufeedvh/code2prompt?style=social)](https://github.com/mufeedvh/code2prompt)\n\n</div>\n\n---\n\n<h1 align=\"center\">\n  <a href=\"https://code2prompt.dev\"><img src=\"https://github.com/mufeedvh/code2prompt/blob/main/.assets/demo.gif?raw=true\" alt=\"code2prompt demo\"></a>\n</h1>\n\n![Flow Diagram](https://github.com/mufeedvh/code2prompt/blob/main/.assets/flow_diagram.png?raw=true)\n\n**Code2Prompt** is a powerful context engineering tool designed to ingest codebases and format them for Large Language Models. Whether you are manually copying context for ChatGPT, building AI agents via Python, or running a MCP server, Code2Prompt streamlines the context preparation process.\n\n## ‚ö° Quick Install\n\n### Cargo\n\n```bash\ncargo install code2prompt \n```\n\nTo enable optional Wayland support (e.g., for clipboard integration on Wayland-based systems), use the `wayland` feature flag:\n\n```bash\ncargo install --features wayland code2prompt\n```\n\n### Homebrew\n\n```bash\nbrew install code2prompt\n```\n\n### SDK with pip üêç\n\n```bash\npip install code2prompt-rs\n```\n\n## üöÄ Quick Start\n\nOnce installed, generating a prompt from your codebase is as simple as pointing the tool to your directory.\n\n**Basic Usage**: Generate a prompt from the current directory and copy it to the clipboard.\n\n```sh\ncode2prompt .\n```\n\n**Save to file**:\n\n```sh\ncode2prompt path/to/project --output prompt.txt\n```\n\n## üåê Ecosystem\n\nCode2Prompt is more than just a CLI tool. It is a complete ecosystem for codebase context.\n\n| üß± Core Library <br><img src=\"https://img.shields.io/badge/Rust-FF6700?style=for-the-badge&logo=rust&logoColor=white\" alt=\"Rust Core Badge\"/>| üíª CLI Tool <br><img src=\"https://img.shields.io/badge/Terminal-2C3E50?style=for-the-badge&logo=gnu-bash&logoColor=white\" alt=\"CLI Badge\"/> | üêç Python SDK <br><img src=\"https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white\" alt=\"Python SDK Badge\"/> | ü§ñ MCP Server <img src=\"https://img.shields.io/badge/Agentic%20Flow-7E57C2?style=for-the-badge&logo=server&logoColor=white\" alt=\"MCP Server Badge\"/> |\n| :---: | :---: | :---: | :---: |\n| The internal, high-speed library responsible for secure file traversal, respecting `.gitignore` rules, and structuring Git metadata. | Designed for humans, featuring both a minimal CLI and an interactive TUI. Generate formatted prompts, track token usage, and outputs the result to your clipboard or stdout. | Provides fast Python bindings to the Rust Core. Ideal for AI Agents, automation scripts, or deep integration into RAG pipelines. Available on PyPI. | Run Code2Prompt as a local service, enabling agentic applications to read your local codebase efficiently without bloating your context window. |\n\n## üìö Documentation\n\nCheck our online [documentation](https://code2prompt.dev/docs/welcome/) for detailed instructions\n\n## ‚ú® Features\n\nCode2Prompt transforms your entire codebase into a well-structured prompt for large language models. Key features include:\n\n- **Terminal User Interface (TUI)**: Interactive terminal interface for configuring and generating prompts\n- **Smart Filtering**: Include/exclude files using glob patterns and respect `.gitignore` rules\n- **Flexible Templating**: Customize prompts with Handlebars templates for different use cases\n- **Automatic Code Processing**: Convert codebases of any size into readable, formatted prompts\n- **Token Tracking**: Track token usage to stay within LLM context limits\n- **Smart File Reading**: Simplify reading various file formats for LLMs (CSV, Notebooks, JSONL, etc.)\n- **Git Integration**: Include diffs, logs, and branch comparisons in your prompts\n- **Blazing Fast**: Built in Rust for high performance and low resource usage\n\nStop manually copying files and formatting code for LLMs. Code2Prompt handles the tedious work so you can focus on getting insights and solutions from AI models.\n\n## Alternative Installation\n\nRefer to the [documentation](https://code2prompt.dev/docs/how_to/install/) for detailed installation instructions.\n\n### Binary releases\n\nDownload the latest binary for your OS from [Releases](https://github.com/mufeedvh/code2prompt/releases).\n\n### Source build\n\nRequires:\n\n- [Git](https://git-scm.org/downloads), [Rust](https://rust-lang.org/tools/install) and `Cargo`.\n\n```sh\ngit clone https://github.com/mufeedvh/code2prompt.git\ncd code2prompt/\ncargo install --path crates/code2prompt\n```\n\n## ‚≠ê Star Gazing\n\n[![Star History Chart](https://api.star-history.com/svg?repos=mufeedvh/code2prompt&type=Date)](https://star-history.com/#mufeedvh/code2prompt&Date)\n\n## üìú License\n\nLicensed under the MIT License, see <a href=\"https://github.com/mufeedvh/code2prompt/blob/master/LICENSE\">LICENSE</a> for more information.\n\n## Liked the project?\n\nIf you liked the project and found it useful, please give it a :star: !\n\n## üë• Contribution\n\nWays to contribute:\n\n- Suggest a feature\n- Report a bug\n- Fix something and open a pull request\n- Help me document the code\n- Spread the word\n",
      "stars_today": 13
    },
    {
      "id": 497133950,
      "name": "ytdlnis",
      "full_name": "deniscerri/ytdlnis",
      "description": "Full-featured audio/video downloader for Android using yt-dlp",
      "html_url": "https://github.com/deniscerri/ytdlnis",
      "stars": 7293,
      "forks": 300,
      "language": "Kotlin",
      "topics": [
        "android",
        "audio",
        "downloader",
        "kotlin",
        "material-design",
        "mp3",
        "video",
        "youtube",
        "youtube-dl",
        "youtube-downloader",
        "yt-dlp",
        "yt-dlp-gui"
      ],
      "created_at": "2022-05-27T20:46:51Z",
      "updated_at": "2026-01-14T00:15:19Z",
      "pushed_at": "2026-01-10T08:15:26Z",
      "open_issues": 32,
      "owner": {
        "login": "deniscerri",
        "avatar_url": "https://avatars.githubusercontent.com/u/64997243?v=4"
      },
      "readme": "<h1 align=\"center\">\n\t<img src=\"fastlane/metadata/android/en-US/images/icon.png\" width=\"25%\" /> <br>\n\tYTDLnis\n</h1>\n\n<div align=\"center\">\n\tEnglish\n\t&nbsp;&nbsp;| &nbsp;&nbsp;\n\t<a href=\"https://github.com/deniscerri/ytdlnis/blob/main/README-sq.md\">Shqip</a>\n\t&nbsp;&nbsp;| &nbsp;&nbsp;\n\t<a href=\"https://github.com/deniscerri/ytdlnis/blob/main/README-az.md\">Az…ôrbaycanca</a>\n\t&nbsp;&nbsp;| &nbsp;&nbsp;\n\t<a href=\"https://github.com/deniscerri/ytdlnis/blob/main/README-tr.md\">T√ºrk√ße</a>\n\t&nbsp;&nbsp;| &nbsp;&nbsp;\n\t<a href=\"https://github.com/deniscerri/ytdlnis/blob/main/README-id.md\">Indonesia</a>\n\t&nbsp;&nbsp;| &nbsp;&nbsp;\n\t<a href=\"https://github.com/deniscerri/ytdlnis/blob/main/README-pt.md\">Portugu√™s</a>\n\t&nbsp;&nbsp;| &nbsp;&nbsp;\n\t<a href=\"https://github.com/deniscerri/ytdlnis/blob/main/README-es.md\">Espa√±ol</a>\n\t&nbsp;&nbsp;| &nbsp;&nbsp;\n\t<a href=\"https://github.com/deniscerri/ytdlnis/blob/main/README-ja.md\">Japanese</a>\n\t&nbsp;&nbsp;| &nbsp;&nbsp;\n\t<a href=\"https://github.com/deniscerri/ytdlnis/blob/main/README-ro.md\">Rom√¢nƒÉ</a>\n</div>\n\n<h3 align=\"center\">\n\tYTDLnis is a free and open source video/audio downloader using yt-dlp for Android 7.0 and above.\n</h3>\n<h4 align=\"center\">\n\tCreated by Denis √áerri\n</h4>\n\n<div align=\"center\">\n\n[![GitHub Releases](https://custom-icon-badges.herokuapp.com/badge/Download-blue?style=for-the-badge&logo=download&logoColor=white)](https://github.com/deniscerri/ytdlnis/releases/latest)\n[![F-Droid](https://custom-icon-badges.herokuapp.com/badge/FDroid-violet?style=for-the-badge&logo=download&logoColor=white)](https://f-droid.org/en/packages/com.deniscerri.ytdl)\n[![IzzyOnDroid repository](https://custom-icon-badges.herokuapp.com/badge/IzzyOnDroid%20Repo-red?style=for-the-badge&logo=download&logoColor=white)](https://android.izzysoft.de/repo/apk/com.deniscerri.ytdl)\n[![Uptodown](https://custom-icon-badges.herokuapp.com/badge/UpToDown-green?style=for-the-badge&logo=download&logoColor=white)](https://ytdlnis.en.uptodown.com/android/download)\n\n![CI](https://github.com/deniscerri/ytdlnis/actions/workflows/android.yml/badge.svg?branch=main&event=pull)\n[![Preview release](https://img.shields.io/github/release/deniscerri/ytdlnis.svg?maxAge=3600&include_prereleases&label=preview)](https://github.com/deniscerri/ytdlnis/releases) \n[![Downloads](https://img.shields.io/github/downloads/deniscerri/ytdlnis/total?style=flat-square)](https://github.com/deniscerri/ytdlnis/releases) \n[![Translation status](https://hosted.weblate.org/widgets/ytdlnis/-/svg-badge.svg)](https://hosted.weblate.org/engage/ytdlnis/?utm_source=widget) \n[![community](https://img.shields.io/badge/Discord-YTDLnis-blueviolet?style=flat-square&logo=discord)](https://discord.gg/WW3KYWxAPm) \n[![community](https://img.shields.io/badge/Telegram-YTDLnis-blue?style=flat-square&logo=telegram)](https://t.me/ytdlnis)\n[![community](https://img.shields.io/badge/Telegram-Updates-red?style=flat-square&logo=telegram)](https://t.me/ytdlnisupdates)\n[![website](https://img.shields.io/badge/Website-orange?style=flat-square&logo=youtube)](https://ytdlnis.org)\n![GitHub Sponsor](https://img.shields.io/github/sponsors/deniscerri?label=Sponsor&logo=GitHub)\n\n### Only the links above are the only trusted sources of YTDLnis. Everything else is not related to me.\n\n</div>\n\n## üí° Features:\n\n- Download audio/video files from more than <a href=\"https://github.com/yt-dlp/yt-dlp/blob/master/supportedsites.md\">1000 websites</a>\n- Process playlists\n\t- Edit every playlist item separately just like in a normal download item\n\t- Select a common format for all items and/or select multiple audio formats in case you are downloading them as a video\n\t- Select a download path for all items\n\t- Select a filename template for all items\n\t- Batch update download type to audio/video/custom command in one click\n- Queue downloads and schedule them by date and time\n\t- You can also schedule multiple items at the same time\n- Download multiple items at the same time\n- Use custom commands and templates or use yt-dlp with the built-in terminal\n\t- You can backup and restore templates so you can share them with your buddies\n- Supports cookies. Log in with your accounts and download private/unavailable videos, unlock premium formats etc.\n- Cut videos based on timestamps and video chapters (experimental yt-dlp feature)\n\t- You can make unlimited cuts\n- Remove SponsorBlock elements from downloaded items\n\t- Embed them as a chapters in your video \n- Embed subtitles/metadata/chapters etc\n- Modify metadata such as title and author\n- Split item into separate files depending on its chapters\n- Select different download formats\n- Bottom card right from the share menu, no need to open the app \n\t- You can create a txt file and fill it with links/playlists/search queries separate by a new line and the app will process them\n- Search or insert a link from the app\n\t- You can stack searches so you can process them at the same time\n- Log downloads in case of problems\n- Re-download cancelled or failed downloads\n\t- You can use gestures to swipe left to redownload and right to delete\n\t- You can long click the redownload button in the details sheet to show the download card for more functionality\n- Incognito mode when you don't want to save a download history or logs\n- Quick download mode\n\t- Download immediately without having to wait for data to process. Turn off the bottom card and it will instantly start\n- Open / share downloaded files right from the finished notification\n- Most yt-dlp features are implemented, suggestions are welcome\n- Material You interface\n- Theming options\n- Backup and restore features\n- MVVM architecture with WorkManager\n\n## üì≤ Screenshots\n\n<div>\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/01.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/02.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/03.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/04.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/05.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/06.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/07.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/08.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/09.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/10.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/11.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/12.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/13.png\" width=\"90%\" />\n</div>\n\n## üí¨ Contact\n\nJoin our [Discord](https://discord.gg/WW3KYWxAPm) or [Telegram channel](https://t.me/ytdlnis) for announcements, discussion and releases.\n\n## üòá Contributing\n\nPlease read the [contributing](CONTRIBUTING.MD) section if you would like to contribute.\n\n## üìù Help translate on Weblate\n<a href=\"https://hosted.weblate.org/engage/ytdlnis/\">\n<img src=\"https://hosted.weblate.org/widgets/ytdlnis/-/strings/open-graph.png\" alt=\"Translation status\" />\n</a>\n\n\n<a href=\"https://hosted.weblate.org/engage/ytdlnis/\">\n<img src=\"https://hosted.weblate.org/widgets/ytdlnis/-/multi-auto.svg\" alt=\"Translation status\" />\n</a>\n\n## üîë Connect with third-party apps using the package name\n\nThe app's package name is \"com.deniscerri.ytdl\".\n\n\n## ü§ñ Connect with third-party apps using intents\n\nYou can use intents to push commands to the app to run downloads without user interaction.\nAccepted variables:\n\n<b>TYPE</b> -> it can be: audio,video,command <br/>\n<b>BACKGROUND</b> -> it can be: true,false. If its true the app won't show the download card no matter what and run the download in the background <br/>\n\n### An example of downloading an audio item in the background with Tasker\n1. Create Send Intent task\n2. Action: android.intent.action.SEND\n3. Cat: Default\n4. Mime Type: text/*\n5. Extra: android.intent.extra.TEXT:url (instead of \"url\" write the URL of the video you want to download)\n6. Extra: TYPE:audio\n7. Extra: BACKGROUND:true\n\n## üìÑ License\n\n[GNU GPL v3.0](https://github.com/deniscerri/ytdlnis/blob/main/LICENSE)\n\nExcept for the source code licensed under the GPLv3 license, all other parties are prohibited from using the \"YTDLnis\" name as a downloader app, and the same is true for its derivatives. Derivatives include but are not limited to forks and unofficial builds.\n\n## üòÅ Donate\n\n\n[<img src=\"https://raw.githubusercontent.com/WSTxda/WSTxda/main/images/BMC.svg\"\nalt='Donate with BMC'\nheight=\"80\">](https://www.buymeacoffee.com/deniscerri)\n\n## üôè Thanks\n\n- [decipher3114](https://github.com/decipher3114) for the app's icon\n- [dvd](https://github.com/yausername/dvd) for being an example youtubedl-android implementation\n- [seal](https://github.com/JunkFood02/Seal) for certain design elements and features I wanted to have in this app when I started developing it\n- [youtubedl-android](https://github.com/yausername/youtubedl-android) for porting yt-dlp to Android\n- [yt-dlp](https://github.com/yt-dlp/yt-dlp) and its contributors for making this tool possible. Without it this app wouldn't exist\n\n\nand to a lot of other people, such as contributors.\n",
      "stars_today": 13
    },
    {
      "id": 6296790,
      "name": "spring-boot",
      "full_name": "spring-projects/spring-boot",
      "description": "Spring Boot helps you to create Spring-powered, production-grade applications and services with absolute minimum fuss.",
      "html_url": "https://github.com/spring-projects/spring-boot",
      "stars": 79657,
      "forks": 41798,
      "language": "Java",
      "topics": [
        "framework",
        "java",
        "spring",
        "spring-boot"
      ],
      "created_at": "2012-10-19T15:02:57Z",
      "updated_at": "2026-01-13T21:07:50Z",
      "pushed_at": "2026-01-13T17:10:33Z",
      "open_issues": 491,
      "owner": {
        "login": "spring-projects",
        "avatar_url": "https://avatars.githubusercontent.com/u/317776?v=4"
      },
      "readme": "= Spring Boot image:https://github.com/spring-projects/spring-boot/actions/workflows/build-and-deploy-snapshot.yml/badge.svg?branch=main[\"Build Status\", link=\"https://github.com/spring-projects/spring-boot/actions/workflows/build-and-deploy-snapshot.yml?query=branch%3Amain\"] image:https://img.shields.io/badge/Revved%20up%20by-Develocity-06A0CE?logo=Gradle&labelColor=02303A[\"Revved up by Develocity\", link=\"https://ge.spring.io/scans?&search.rootProjectNames=Spring%20Boot%20Build&search.rootProjectNames=spring-boot-build\"]\n\n:docs: https://docs.spring.io/spring-boot\n:github: https://github.com/spring-projects/spring-boot\n\nSpring Boot helps you to create Spring-powered, production-grade applications and services with absolute minimum fuss.\nIt takes an opinionated view of the Spring platform so that new and existing users can quickly get to the bits they need.\n\nYou can use Spring Boot to create stand-alone Java applications that can be started using `java -jar` or more traditional WAR deployments.\nWe also provide a command-line tool that runs Spring scripts.\n\nOur primary goals are:\n\n* Provide a radically faster and widely accessible getting started experience for all Spring development.\n* Be opinionated, but get out of the way quickly as requirements start to diverge from the defaults.\n* Provide a range of non-functional features common to large classes of projects (for example, embedded servers, security, metrics, health checks, externalized configuration).\n* Absolutely no code generation and no requirement for XML configuration.\n\n\n\n== Installation and Getting Started\n\nThe {docs}[reference documentation] includes detailed {docs}/installing.html[installation instructions] as well as a comprehensive {docs}/tutorial/first-application/index.html[``getting started``] guide.\n\nHere is a quick teaser of a complete Spring Boot application in Java:\n\n[source,java]\n----\nimport org.springframework.boot.*;\nimport org.springframework.boot.autoconfigure.*;\nimport org.springframework.web.bind.annotation.*;\n\n@RestController\n@SpringBootApplication\npublic class Example {\n\n\t@RequestMapping(\"/\")\n\tString home() {\n\t\treturn \"Hello World!\";\n\t}\n\n\tpublic static void main(String[] args) {\n\t\tSpringApplication.run(Example.class, args);\n\t}\n\n}\n----\n\n\n\n== Getting Help\n\nAre you having trouble with Spring Boot? We want to help!\n\n* Check the {docs}/[reference documentation], especially the {docs}/how-to/index.html[How-to's] -- they provide solutions to the most common questions.\n* Learn the Spring basics -- Spring Boot builds on many other Spring projects; check the https://spring.io[spring.io] website for a wealth of reference documentation.\n  If you are new to Spring, try one of the https://spring.io/guides[guides].\n* If you are upgrading, read the {github}/wiki[release notes] for upgrade instructions and \"new and noteworthy\" features.\n* Ask a question -- we monitor https://stackoverflow.com[stackoverflow.com] for questions tagged with https://stackoverflow.com/tags/spring-boot[`spring-boot`].\n* Report bugs with Spring Boot at {github}/issues[github.com/spring-projects/spring-boot/issues].\n\n\n\n== Contributing\n\nWe welcome contributions of all kinds!\nPlease read our link:CONTRIBUTING.adoc[contribution guidelines] before submitting a pull request.\n\n\n\n== Reporting Issues\n\nSpring Boot uses GitHub's integrated issue tracking system to record bugs and feature requests.\nIf you want to raise an issue, please follow the recommendations below:\n\n* Before you log a bug, please search the {github}/issues[issue tracker] to see if someone has already reported the problem.\n* If the issue doesn't already exist, {github}/issues/new[create a new issue].\n* Please provide as much information as possible with the issue report.\nWe like to know the Spring Boot version, operating system, and JVM version you're using.\n* If you need to paste code or include a stack trace, use Markdown.\n+++```+++ escapes before and after your text.\n* If possible, try to create a test case or project that replicates the problem and attach it to the issue.\n\n\n\n== Building from Source\n\nYou don't need to build from source to use Spring Boot.\nIf you want to try out the latest and greatest, Spring Boot can be built and published to your local Maven cache using the https://docs.gradle.org/current/userguide/gradle_wrapper.html[Gradle wrapper].\nYou also need JDK 25.\n\n[source,shell]\n----\n$ ./gradlew publishToMavenLocal\n----\n\nThis command builds all modules and publishes them to your local Maven cache.\nIt won't run any of the tests.\nIf you want to build everything, use the `build` task:\n\n[source,shell]\n----\n$ ./gradlew build\n----\n\n\n\n== Guides\n\nThe https://spring.io/[spring.io] site contains several guides that show how to use Spring Boot step-by-step:\n\n* https://spring.io/guides/gs/spring-boot/[Building an Application with Spring Boot] is an introductory guide that shows you how to create an application, run it, and add some management services.\n* https://spring.io/guides/gs/actuator-service/[Building a RESTful Web Service with Spring Boot Actuator] is a guide to creating a REST web service and also shows how the server can be configured.\n\n\n\n== License\n\nSpring Boot is Open Source software released under the https://www.apache.org/licenses/LICENSE-2.0.html[Apache 2.0 license].\n",
      "stars_today": 12
    },
    {
      "id": 1016267036,
      "name": "bitchat-android",
      "full_name": "permissionlesstech/bitchat-android",
      "description": "bluetooth mesh chat, IRC vibes",
      "html_url": "https://github.com/permissionlesstech/bitchat-android",
      "stars": 4330,
      "forks": 607,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2025-07-08T18:36:23Z",
      "updated_at": "2026-01-14T00:56:03Z",
      "pushed_at": "2026-01-13T23:09:59Z",
      "open_issues": 206,
      "owner": {
        "login": "permissionlesstech",
        "avatar_url": "https://avatars.githubusercontent.com/u/220183803?v=4"
      },
      "readme": "<p align=\"center\">\n    <img src=\"https://github.com/user-attachments/assets/188c42f8-d249-4a72-b27a-e2b4f10a00a8\" alt=\"Bitchat Android Logo\" width=\"480\">\n</p>\n\n> [!WARNING]\n> This software has not received external security review and may contain vulnerabilities and may not necessarily meet its stated security goals. Do not use it for sensitive use cases, and do not rely on its security until it has been reviewed. Work in progress.\n\n# bitchat for Android\n\nA secure, decentralized, peer-to-peer messaging app that works over Bluetooth mesh networks. No internet required for mesh chats, no servers, no phone numbers - just pure encrypted communication. Bitchat also supports geohash channels, which use an internet connection to connect you with others in your geographic area.\n\nThis is the **Android port** of the original [bitchat iOS app](https://github.com/jackjackbits/bitchat), maintaining 100% protocol compatibility for cross-platform communication.\n\n## Install bitchat\n\nYou can download the latest version of bitchat for Android from the [GitHub Releases page](https://github.com/permissionlesstech/bitchat-android/releases).\n\nOr you can:\n\n[<img alt=\"Get it on Google Play\" height=\"60\" src=\"https://play.google.com/intl/en_us/badges/static/images/badges/en_badge_web_generic.png\"/>](https://play.google.com/store/apps/details?id=com.bitchat.droid)\n\n**Instructions:**\n\n1.  **Download the APK:** On your Android device, navigate to the link above and download the latest `.apk` file. Open it.\n2.  **Allow Unknown Sources:** On some devices, before you can install the APK, you may need to enable \"Install from unknown sources\" in your device's settings. This is typically found under **Settings > Security** or **Settings > Apps & notifications > Special app access**.\n3.  **Install:** Open the downloaded `.apk` file to begin the installation.\n\n## License\n\nThis project is released into the public domain. See the [LICENSE](LICENSE.md) file for details.\n\n## Features\n\n- **‚úÖ Cross-Platform Compatible**: Full protocol compatibility with iOS bitchat\n- **‚úÖ Decentralized Mesh Network**: Automatic peer discovery and multi-hop message relay over Bluetooth LE\n- **‚úÖ End-to-End Encryption**: X25519 key exchange + AES-256-GCM for private messages\n- **‚úÖ Channel-Based Chats**: Topic-based group messaging with optional password protection\n- **‚úÖ Store & Forward**: Messages cached for offline peers and delivered when they reconnect\n- **‚úÖ Privacy First**: No accounts, no phone numbers, no persistent identifiers\n- **‚úÖ IRC-Style Commands**: Familiar `/join`, `/msg`, `/who` style interface\n- **‚úÖ Message Retention**: Optional channel-wide message saving controlled by channel owners\n- **‚úÖ Emergency Wipe**: Triple-tap logo to instantly clear all data\n- **‚úÖ Modern Android UI**: Jetpack Compose with Material Design 3\n- **‚úÖ Dark/Light Themes**: Terminal-inspired aesthetic matching iOS version\n- **‚úÖ Battery Optimization**: Adaptive scanning and power management\n\n## Android Setup\n\n### Prerequisites\n\n- **Android Studio**: Arctic Fox (2020.3.1) or newer\n- **Android SDK**: API level 26 (Android 8.0) or higher\n- **Kotlin**: 1.8.0 or newer\n- **Gradle**: 7.0 or newer\n\n### Build Instructions\n\n1. **Clone the repository:**\n   ```bash\n   git clone https://github.com/permissionlesstech/bitchat-android.git\n   cd bitchat-android\n   ```\n\n2. **Open in Android Studio:**\n   ```bash\n   # Open Android Studio and select \"Open an Existing Project\"\n   # Navigate to the bitchat-android directory\n   ```\n\n3. **Build the project:**\n   ```bash\n   ./gradlew build\n   ```\n\n4. **Install on device:**\n   ```bash\n   ./gradlew installDebug\n   ```\n\n### Development Build\n\nFor development builds with debugging enabled:\n\n```bash\n./gradlew assembleDebug\nadb install -r app/build/outputs/apk/debug/app-debug.apk\n```\n\n### Release Build\n\nFor production releases:\n\n```bash\n./gradlew assembleRelease\n```\n\n## Android-Specific Requirements\n\n### Permissions\n\nThe app requires the following permissions (automatically requested):\n\n- **Bluetooth**: Core BLE functionality\n- **Location**: Required for BLE scanning on Android\n- **Network**: Expand your mesh through public internet relays\n- **Notifications**: Message alerts and background updates\n\n### Hardware Requirements\n\n- **Bluetooth LE (BLE)**: Required for mesh networking\n- **Android 8.0+**: API level 26 minimum\n- **RAM**: 2GB recommended for optimal performance\n\n## Usage\n\n### Basic Commands\n\n- `/j #channel` - Join or create a channel\n- `/m @name message` - Send a private message\n- `/w` - List online users\n- `/channels` - Show all discovered channels\n- `/block @name` - Block a peer from messaging you\n- `/block` - List all blocked peers\n- `/unblock @name` - Unblock a peer\n- `/clear` - Clear chat messages\n- `/pass [password]` - Set/change channel password (owner only)\n- `/transfer @name` - Transfer channel ownership\n- `/save` - Toggle message retention for channel (owner only)\n\n### Getting Started\n\n1. **Install the app** on your Android device (requires Android 8.0+)\n2. **Grant permissions** for Bluetooth and location when prompted\n3. **Launch bitchat** - it will auto-start mesh networking\n4. **Set your nickname** or use the auto-generated one\n5. **Connect automatically** to nearby iOS and Android bitchat users\n6. **Join a channel** with `/j #general` or start chatting in public\n7. **Messages relay** through the mesh network to reach distant peers\n\n### Android UI Features\n\n- **Jetpack Compose UI**: Modern Material Design 3 interface\n- **Dark/Light Themes**: Terminal-inspired aesthetic matching iOS\n- **Haptic Feedback**: Vibrations for interactions and notifications\n- **Adaptive Layout**: Optimized for various Android screen sizes\n- **Message Status**: Real-time delivery and read receipts\n- **RSSI Indicators**: Signal strength colors for each peer\n\n### Channel Features\n\n- **Password Protection**: Channel owners can set passwords with `/pass`\n- **Message Retention**: Owners can enable mandatory message saving with `/save`\n- **@ Mentions**: Use `@nickname` to mention users (with autocomplete)\n- **Ownership Transfer**: Pass control to trusted users with `/transfer`\n\n## Security & Privacy\n\n### Encryption\n- **Private Messages**: X25519 key exchange + AES-256-GCM encryption\n- **Channel Messages**: Argon2id password derivation + AES-256-GCM\n- **Digital Signatures**: Ed25519 for message authenticity\n- **Forward Secrecy**: New key pairs generated each session\n\n### Privacy Features\n- **No Registration**: No accounts, emails, or phone numbers required\n- **Ephemeral by Default**: Messages exist only in device memory\n- **Cover Traffic**: Random delays and dummy messages prevent traffic analysis\n- **Emergency Wipe**: Triple-tap logo to instantly clear all data\n- **Bundled Tor Support**: Built-in Tor network integration for enhanced privacy when internet connectivity is available\n\n## Performance & Efficiency\n\n### Message Compression\n- **LZ4 Compression**: Automatic compression for messages >100 bytes\n- **30-70% bandwidth savings** on typical text messages\n- **Smart compression**: Skips already-compressed data\n\n### Battery Optimization\n- **Adaptive Power Modes**: Automatically adjusts based on battery level\n  - Performance mode: Full features when charging or >60% battery\n  - Balanced mode: Default operation (30-60% battery)\n  - Power saver: Reduced scanning when <30% battery\n  - Ultra-low power: Emergency mode when <10% battery\n- **Background efficiency**: Automatic power saving when app backgrounded\n- **Configurable scanning**: Duty cycle adapts to battery state\n\n### Network Efficiency\n- **Optimized Bloom filters**: Faster duplicate detection with less memory\n- **Message aggregation**: Batches small messages to reduce transmissions\n- **Adaptive connection limits**: Adjusts peer connections based on power mode\n\n## Technical Architecture\n\n### Binary Protocol\nbitchat uses an efficient binary protocol optimized for Bluetooth LE:\n- Compact packet format with 1-byte type field\n- TTL-based message routing (max 7 hops)\n- Automatic fragmentation for large messages\n- Message deduplication via unique IDs\n\n### Mesh Networking\n- Each device acts as both client and peripheral\n- Automatic peer discovery and connection management\n- Store-and-forward for offline message delivery\n- Adaptive duty cycling for battery optimization\n\n### Android-Specific Optimizations\n- **Coroutine Architecture**: Asynchronous operations for mesh networking\n- **Kotlin Coroutines**: Thread-safe concurrent mesh operations\n- **EncryptedSharedPreferences**: Secure storage for user settings\n- **Lifecycle-Aware**: Proper handling of Android app lifecycle\n- **Battery Optimization**: Foreground service and adaptive scanning\n\n## Android Technical Architecture\n\n### Core Components\n\n1. **BitchatApplication.kt**: Application-level initialization and dependency injection\n2. **MainActivity.kt**: Main activity handling permissions and UI hosting\n3. **ChatViewModel.kt**: MVVM pattern managing app state and business logic\n4. **BluetoothMeshService.kt**: Core BLE mesh networking (central + peripheral roles)\n5. **EncryptionService.kt**: Cryptographic operations using BouncyCastle\n6. **BinaryProtocol.kt**: Binary packet encoding/decoding matching iOS format\n7. **ChatScreen.kt**: Jetpack Compose UI with Material Design 3\n\n### Dependencies\n\n- **Jetpack Compose**: Modern declarative UI\n- **BouncyCastle**: Cryptographic operations (X25519, Ed25519, AES-GCM)\n- **Nordic BLE Library**: Reliable Bluetooth LE operations\n- **Kotlin Coroutines**: Asynchronous programming\n- **LZ4**: Message compression (when enabled)\n- **EncryptedSharedPreferences**: Secure local storage\n\n### Binary Protocol Compatibility\n\nThe Android implementation maintains 100% binary protocol compatibility with iOS:\n- **Header Format**: Identical 13-byte header structure\n- **Packet Types**: Same message types and routing logic\n- **Encryption**: Identical cryptographic algorithms and key exchange\n- **UUIDs**: Same Bluetooth service and characteristic identifiers\n- **Fragmentation**: Compatible message fragmentation for large content\n\n## Publishing to Google Play\n\n### Preparation\n\n1. **Update version information:**\n   ```kotlin\n   // In app/build.gradle.kts\n   defaultConfig {\n       versionCode = 2  // Increment for each release\n       versionName = \"1.1.0\"  // User-visible version\n   }\n   ```\n\n2. **Create a signed release build:**\n   ```bash\n   ./gradlew assembleRelease\n   ```\n\n3. **Generate app bundle (recommended for Play Store):**\n   ```bash\n   ./gradlew bundleRelease\n   ```\n\n### Play Store Requirements\n\n- **Target API**: Latest Android API (currently 34)\n- **Privacy Policy**: Required for apps requesting sensitive permissions\n- **App Permissions**: Justify Bluetooth and location usage\n- **Content Rating**: Complete questionnaire for age-appropriate content\n\n### Distribution\n\n- **Google Play Store**: Main distribution channel\n- **F-Droid**: For open-source distribution\n- **Direct APK**: For testing and development\n\n## Cross-Platform Communication\n\nThis Android port enables seamless communication with the original iOS bitchat app:\n\n- **iPhone ‚Üî Android**: Full bidirectional messaging\n- **Mixed Groups**: iOS and Android users in same channels\n- **Feature Parity**: All commands and encryption work across platforms\n- **Protocol Sync**: Identical message format and routing behavior\n\n**iOS Version**: For iPhone/iPad users, get the original bitchat at [github.com/jackjackbits/bitchat](https://github.com/jackjackbits/bitchat)\n\n## Contributing\n\nContributions are welcome! Key areas for enhancement:\n\n1. **Performance**: Battery optimization and connection reliability\n2. **UI/UX**: Additional Material Design 3 features\n3. **Security**: Enhanced cryptographic features\n4. **Testing**: Unit and integration test coverage\n5. **Documentation**: API documentation and development guides\n\n## Support & Issues\n\n- **Bug Reports**: [Create an issue](../../issues) with device info and logs\n- **Feature Requests**: [Start a discussion](https://github.com/orgs/permissionlesstech/discussions)\n- **Security Issues**: Email security concerns privately\n- **iOS Compatibility**: Cross-reference with [original iOS repo](https://github.com/jackjackbits/bitchat)\n\nFor iOS-specific issues, please refer to the [original iOS bitchat repository](https://github.com/jackjackbits/bitchat).\n",
      "stars_today": 12
    },
    {
      "id": 997143988,
      "name": "ComfyUI-Prompt-Assistant",
      "full_name": "yawiii/ComfyUI-Prompt-Assistant",
      "description": "ÊèêÁ§∫ËØçÂ∞èÂä©ÊâãÂèØ‰ª•‰∏ÄÈîÆË∞ÉÁî®Êô∫Ë∞±„ÄÅÁ°ÖÂü∫ÊµÅÂä®„ÄÅgemini„ÄÅÊú¨Âú∞ollama„ÄÅÁôæÂ∫¶Á≠âÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊúçÂä°ÔºåÂÆûÁé∞ÊèêÁ§∫ËØçÁøªËØë„ÄÅÊ∂¶Ëâ≤Êâ©ÂÜô„ÄÅÂõæÁâáÂèçÊé®„ÄÇÊîØÊåÅÊèêÁ§∫ËØçÈ¢ÑËÆæÂÆûÁé∞‰∏ÄÈîÆÊèíÂÖ•„ÄÅÂéÜÂè≤ÊèêÁ§∫ËØçÊü•ÊâæÁ≠âÂäüËÉΩ„ÄÇÊòØ‰∏Ä‰∏™ÂÖ®ËÉΩÂûãÊèêÁ§∫ËØçÊèí‰ª∂„ÄÇThe Prompt Assistant enables one-click access to LLMs/VLMs for prompt translation, expansion, and image captioning. It also supports one-click preset insertion and historical prompt search.",
      "html_url": "https://github.com/yawiii/ComfyUI-Prompt-Assistant",
      "stars": 1338,
      "forks": 49,
      "language": "JavaScript",
      "topics": [
        "comfyui",
        "expand",
        "prompt",
        "tags",
        "translate"
      ],
      "created_at": "2025-06-06T03:10:12Z",
      "updated_at": "2026-01-14T01:03:23Z",
      "pushed_at": "2026-01-12T07:09:17Z",
      "open_issues": 9,
      "owner": {
        "login": "yawiii",
        "avatar_url": "https://avatars.githubusercontent.com/u/82788731?v=4"
      },
      "readme": "<div align=\"center\">\r\n\r\n<h1 align=\"center\">ComfyUI Prompt Assistant‚ú®ÊèêÁ§∫ËØçÂ∞èÂä©ÊâãV2.0</h1>\r\n\r\n<img alt=\"GitHub Repo stars\" src=\"https://img.shields.io/github/stars/yawiii/ComfyUI-Prompt-Assistant\">\r\n<a href=\"https://space.bilibili.com/520680644\"><img alt=\"bilibili\" src=\"https://img.shields.io/badge/ËØ¶ÁªÜËßÜÈ¢ëÊïôÁ®ã-blue?style=flat&logo=bilibili&logoColor=2300A5DC&labelColor=%23FFFFFF&color=%2307A3D7\"></a>\r\n<a href=\"https://data.xflow.cc/wechat.png\"><img alt=\"weChat\" src=\"https://img.shields.io/badge/Ê¨¢ËøéÂä†ÂÖ•‰∫§ÊµÅÁæ§-blue?logo=wechat&logoColor=green&labelColor=%23FFFFFF&color=%2307A3D7\"></a>\r\n<a href=\"https://ycn58r88iss5.feishu.cn/share/base/form/shrcnJ1AzbUJCynW9qrNJ2zPugy\"><img alt=\"bug\" src=\"https://img.shields.io/badge/Bug-ÂèçÈ¶à-orange\"></a>\r\n\r\n</div>\r\n\r\n<h4 align=\"center\">üéâüéâÂÖ®Êñ∞ÁâàÊú¨ÁöÑÊèêÁ§∫ËØçÂ∞èÂä©Êâã‰∏äÁ∫øÂï¶ÔºÅÂäüËÉΩÊõ¥Âº∫ÔºåÂìçÂ∫îÈÄüÂ∫¶Êõ¥Âø´ÔºÅÈÄÇÈÖçComfyUI node2.0ÔºÅüéâüéâ</h4>\r\n\r\n> ÊîØÊåÅË∞ÉÁî®‰∫ëÁ´ØÂ§ßÊ®°ÂûãAPI„ÄÅÊú¨Âú∞OllamaÂ§ßÊ®°Âûã„ÄÇÂÆûÁé∞ÊèêÁ§∫ËØç„ÄÅMarkdownËäÇÁÇπ„ÄÅËäÇÁÇπÊñáÊ°£ÁøªËØëÔºõÊèêÁ§∫ËØç‰ºòÂåñ„ÄÅÂõæÂÉèÂèçÊé®ÂíåËßÜÈ¢ëÂèçÊé®ÔºõÂ∏∏Áî®Ê†áÁ≠æÊî∂Ëóè„ÄÅÂéÜÂè≤ËÆ∞ÂΩïÁ≠âÂäüËÉΩ„ÄÇÊòØ‰∏Ä‰∏™ÂÖ®ËÉΩall in oneÁöÑÊèêÁ§∫ËØçÊèí‰ª∂ÔºÅ\r\n\r\n\r\n## **üì£Êõ¥Êñ∞**\r\n\r\n<details open>\r\n<summary><strong>[2025-1-10] üî•V2.0.2</strong></summary>\r\n\r\n* **Ê†áÁ≠æÊ®°Âùó**Ôºö‰øÆÂ§çÊ†ºÂºèÈóÆÈ¢òÔºåÁé∞Âú®ÂèØ‰ª•Âú®Ëá™Áî±Êñ∞Âª∫ÂàÜÁ±ªÂíåÁÆ°ÁêÜÊ†áÁ≠æ‰∫Ü„ÄÇ‰øÆÂ§çÈ¢ÑËÆæÂàõÂª∫ÂíåËøÅÁßªÂá∫ÈîôÈóÆÈ¢òÔºõ\r\n  \r\n* **Â∞èÂä©ÊâãUI**Ôºö‰ºòÂåñnode2.0‰∏ãÁöÑÊåÇËΩΩÊñπÊ≥ïÔºå‰øÆÂ§çÂ≠êÂõæÊó†Ê≥ïÂàõÂª∫Â∞èÂä©ÊâãÂíåÊüê‰∫õÊÉÖÂÜµ‰∏ã‰∏çÁ®≥ÂÆöÁöÑÈóÆÈ¢òÔºåÂπ∂ÊèêÂçáÊÄßËÉΩÔºõ\r\n  \r\n* **‰∫§‰∫í‰ºòÂåñ**ÔºöËØ∑Ê±ÇËøáÁ®ãÊñ∞Â¢ûÊµÅÂºèËæìÂÖ•ÊïàÊûú„ÄÅ‰ºòÂåñ‰∫§‰∫íÁªÜËäÇÔºõ\r\n  \r\n* **ÁøªËØëÊ®°Âùó**ÔºöÊñ∞Â¢ûÊ∑∑ÂêàËØ≠Ë®ÄÁøªËØëËßÑÂàôÂèÇÊï∞ÔºåÂèØ‰ª•ËÆæÁΩÆÈªòËÆ§ÁøªËØëÊàê‰∏≠Êñá\\Ëã±Êñá„ÄÅÂÆåÂñÑ‰∫ÜËäÇÁÇπÊñáÊ°£ÁøªËØëÔºõ\r\n\r\n* **ÂÜÖÁΩÆËßÑÂàô**Ôºö‰øÆÂ§çÈÉ®ÂàÜËßÑÂàôÔºåÂá∫Áé∞‰∏≠Ëã±Ê∑∑Âêà„ÄÅkontextËæìÂá∫Ê≤°ÊúâÁøªËØëÁ≠âÈóÆÈ¢òÔºõ\r\n  \r\n* **APIËØ∑Ê±Ç**Ôºö‰øÆÂ§çgemimi-3-proÊó†Ê≥ïËØ∑Ê±ÇÁöÑÈóÆÈ¢òÔºõ‰øÆÂ§çollama404ÈóÆÈ¢òÔºõ\r\n  \r\n* **ËäÇÁÇπ‰ºòÂåñ**ÔºöÂÆåÂñÑËßÜÈ¢ëÂèçÊé®ËäÇÁÇπ„ÄÅÊâÄÊúâËäÇÁÇπÂä†ÂÖ•‚Äú[R]‚ÄùËß¶ÂèëËØçÔºåÁî®‰∫éÂº∫Âà∂ËäÇÁÇπÂßãÁªàÂèØË¢´ÊâßË°åÔºõ\r\n  \r\n* **ÊéßÂà∂Âè∞Êó•Âøó**Ôºö‰ºòÂåñÊó•ÂøóËæìÂá∫Ôºå‰øÆÂ§çËøõÂ∫¶Êó•ÂøóÊó†ÈôêËæìÂá∫ÁöÑbugÔºõ\r\n \r\n* **‰æùËµñÊõ¥Êñ∞**ÔºöÈÅøÂÖçÁº∫Â∞ë‰æùËµñÊó†Ê≥ïÂêØÂä®ÈóÆÈ¢òÔºõ\r\n\r\n</details>\r\n\r\n<details>\r\n<summary><strong>[2025-12-21] V2.0.0</strong></summary>\r\n\r\n* **Ë∞ÉÁî®‰ºòÂåñ**ÔºöÂÖ®Èù¢ÈáçÊûÑÂ∞èÂä©ÊâãÔºåÊèêÂçáAPI„ÄÅOllamaË∞ÉÁî®ÂíåÁ®≥ÂÆöÂ∫¶„ÄÅÂìçÂ∫îÈÄüÂ∫¶Ôºõ\r\n  \r\n* **UI‰ºòÂåñ**ÔºöÈáçÊûÑÂâçÁ´ØÂ∞èÂä©ÊâãÁªÑ‰ª∂ÔºåÊõ¥Âä†Á®≥ÂÆöÔºåÊîØÊåÅ**node2.0**Ê®°ÂºèÔºåÂèØ‰ª•Ëá™ÂÆö‰πâÊòæÁ§∫‰ΩçÁΩÆ„ÄÅÊãñÂä®ÊåâÈíÆÊéíÂ∫èÔºõ\r\n  \r\n* **Ê†áÁ≠æÊ®°Âùó‰ºòÂåñ**ÔºöÂÖ®Êñ∞Ê†áÁ≠æÊú∫Âà∂„ÄÇÊîπ‰∏∫Âä†ËΩΩcsvÊ®°ÂºèÔºåÊîØÊåÅÂ§öÂà∞csvÈöèÊó∂ÂàáÊç¢„ÄÅÊîØÊåÅÊ†áÁ≠æÊî∂ËóèÔºõ\r\n* **ËßÑÂàôÊ®°Âùó‰ºòÂåñ**ÔºöÂÖ®Êñ∞ÈÖçÁΩÆÁ™óÂè£„ÄÅÊîØÊåÅÂàÜÁ±ª„ÄÅÂÆö‰πâËßÑÂàôÊòæÁ§∫ÁöÑ‰ΩçÁΩÆÔºõÂä†ÂÖ•Â§ö‰∏™È¢ÑÁΩÆËßÑÂàôÔºõ\r\n* **APIÊúçÂä°Ê®°Âùó‰ºòÂåñ**ÔºöÂÖ®Êñ∞**api**ÈÖçÁΩÆÁïåÈù¢„ÄÇÊîØÊåÅËá™ÂÆö‰πâÊúçÂä°„ÄÅÊîØÊåÅÊ∑ªÂä†Â§ö‰∏™Ê®°Âûã‰Ωú‰∏∫Â§áÈÄâÔºõÊâ©ÂÜô„ÄÅÁøªËØë„ÄÅÂèçÊé®ÂèØÁã¨Á´ãÈÄâÊã©ÊúçÂä°\r\n* **ËäÇÁÇπÈáçÊûÑ**ÔºöÈáçÊûÑÊâÄÊúâËäÇÁÇπÔºåÊîØÊåÅÂ§öËØ≠Ë®ÄÔºåÊ∑ªÂä†ËßÜÈ¢ëÂèçÊé®ËäÇÁÇπÔºà**beta**ÔºâÔºõ\r\n* **Áî®Êà∑ÈÖçÁΩÆÊñá‰ª∂ËøÅÁßª**ÔºöËøÅÁßªÂà∞ `\\user\\default\\prompt-assistant` ÈÅøÂÖçÈáçË£ÖÊó∂Áî®Êà∑Êï∞ÊçÆ‰∏¢Â§±Ôºõ\r\n* **Êñ∞Â¢ûÂäüËÉΩ**ÔºöËäÇÁÇπÊñáÊ°£ÁøªËØë„ÄÅmarkdownËäÇÁÇπÁøªËØë\r\n\r\n</details>\r\n\r\n<details>\r\n\r\n<summary><strong>V1.2.x </strong></summary>\r\n\r\n<details>\r\n\r\n<summary>[2025-11-12]  V1.2.3 </summary>\r\n\r\n* ‰øÆÂ§çollamaÂíåËá™ÂÆö‰πâÊúçÂä°Êó∂ÔºåËøîÂõû‰∏∫Á©∫ÁöÑÈóÆÈ¢òÔºõ\r\n* OllamaÊîπÁî®ÂéüÁîüÊé•Âè£ÔºåÊõ¥Â•ΩÊîØÊåÅqwen3vlÔºõ\r\n* Êñ∞Â¢ûhttp api‰Ωú‰∏∫‰øùÂ∫ïÔºåÈÅøÂÖçÂá∫Áé∞ËØ∑Ê±ÇÂºÇÂ∏∏;\r\n\r\n</details>\r\n\r\n<details>\r\n\r\n<summary>[2025-10-14]  V1.2.2 </summary>\r\n\r\n* ÁßªÈô§ÂÖºÂÆπ‰ª£Á†ÅÔºå‰∏çÂÜçÊîØÊåÅcomfyUI0.3.27‰ª•‰∏ãÁöÑÁâàÊú¨„ÄÇÈÅøÂÖçÂ∞èÂä©ÊâãUIÂá∫Áé∞ÈóÆÈ¢òÔºõ\r\n* ‰øÆÂ§çÊâ©ÂÜô„ÄÅÁøªËØë‰ΩøÁî®302.aiÊúçÂä°Êó∂Êä•ÈîôÈóÆÈ¢òÔºåollamaÊó†Ê≥ïËá™Âä®ÈáäÊîæÈóÆÈ¢òÔºõ\r\n* ÊâÄÊúâËäÇÁÇπÊ∑ªÂä†Áã¨Á´ãÁöÑollamaÈáäÊîæÈÄâÈ°πÔºõ\r\n* ÁßªÈô§llmÂíåvlmÁöÑÂº∫Âà∂Áõ¥ËøûÂèÇÊï∞ÔºåÈÅøÂÖçÂÅ∂ÂèëËØ∑Ê±ÇÊä•ÈîôÈóÆÈ¢òÔºåÂú®ËÆæÁΩÆÁïåÈù¢‰∏≠Ê∑ªÂä†ÊòØÂê¶Áõ¥ËøûÈÄâÈ°πÔºõ\r\n* ‰ºòÂåñÊéßÂà∂Âè∞Êó•ÂøóËæìÂá∫Ê†ºÂºèÔºåÊòæÁ§∫Êõ¥Âä†Ê∏ÖÊô∞Áõ¥ËßÇÔºõ\r\n\r\n</details>\r\n\r\n<details>\r\n\r\n<summary>[2025-10-14]V1.2.1 </summary>\r\n\r\n* ‰ºòÂåñÂ∞èÂä©ÊâãUIÁöÑÂèçÂ∫îÁÅµÊïèÂ∫¶Ôºõ\r\n* Â¢ûÂº∫apiËØ∑Ê±ÇÈáçËØïÊú∫Âà∂Ôºõ\r\n* ËÆæÁΩÆÁïåÈù¢Êñ∞Â¢ûÁøªËØëÊ†áÁÇπÁ¨¶Âè∑„ÄÅËá™Âä®ÁßªÈô§Â§ö‰ΩôÁ©∫Ê†º„ÄÅÁßªÈô§Â§ö‰ΩôËøûÁª≠ÁÇπÂè∑„ÄÅ‰øùÁïôÊç¢Ë°åÁ¨¶Á≠âÈÄâÈ°πÔºõ\r\n* Ê†áÁ≠æÁ™óÂè£ËÆ∞ÂøÜÁ™óÂè£Â§ßÂ∞èÔºåËÆ∞ÂøÜ‰∏äÊ¨°ÈÄâ‰∏≠ÁöÑÂàÜÁ±ªÔºå‰ª•ÂèäÊ†áÁ≠æÊ†èÊªöÂä®Ôºõ\r\n* APIÈÖçÁΩÆÁïåÈù¢ÔºåÊñ∞Â¢ûËá™Âä®Ëé∑ÂèñÊ®°ÂûãÂàóË°®ÂäüËÉΩÔºõ\r\n* OllamaÊñ∞Â¢ûËá™Âä®ÈáäÊîæÊòæÂ≠òÈÄâÈ°πÔºõ\r\n* ‰øÆÂ§çÈ¢ÑËßà‰ªªÊÑèËäÇÁÇπÂú®ÂàóË°®ÊÉÖÂÜµÊó†Ê≥ï‰∏∫ÊØè‰∏™ÊñáÊú¨Ê°ÜÂàõÂª∫Â∞èÂä©ÊâãÁöÑbug„ÄÇ\r\n\r\n</details>\r\n\r\n<details>\r\n\r\n<summary>[2025-9-16]V1.2.0 </summary>\r\n\r\n* Êñ∞Â¢ûÊèêÁ§∫ËØçÊâ©ÂÜôËäÇÁÇπ\r\n* Êñ∞Â¢û302.AI„ÄÅOllamaÊúçÂä°\r\n* Ê†áÁ≠æÈù¢ÊùøÊñ∞Â¢ûËÆ∞ÂøÜÂäüËÉΩ\r\n* Âè≥ÈîÆËèúÂçïÊîØÊåÅÂø´ÈÄüÂàáÊç¢ÊúçÂä°\r\n* ÈíàÂØπÊüê‰∫õ‰∏ªÊµÅÊ®°ÂûãÊîØÊåÅÂÖ≥Èó≠ÊÄùÁª¥Èìæ\r\n* ‰ºòÂåñÂèçÊé®ÂíåÁøªËØëËäÇÁÇπ\r\n* Êñ∞Â¢û‰∫§ÊµÅÂèçÈ¶àÂÖ•Âè£ÂæΩÊ†á\r\n* ‰øÆÂ§ç‰∏ãÊãâËèúÂçïbug\r\n* ‰øÆÂ§çÊ†áÁ≠æÈù¢ÊùøÊêúÁ¥¢Ê†áÁ≠æÊó†Ê≥ïÊèíÂÖ•bug\r\n* ‰øÆÂ§çbase\\_urlË£ÅÂâ™ÈîôËØØÔºåËß£ÂÜ≥ÂÅ∂ÂèëÊÄßËØ∑Ê±ÇÊä•Èîô\r\n\r\n</details>\r\n</details>\r\n\r\n<details>\r\n\r\n<summary><strong>V1.1.x </strong></summary>\r\n\r\n<details>\r\n\r\n<summary>[2025-8-28]V1.1.3 </summary>\r\n\r\n* ‰ºòÂåñÂ∞èÂä©ÊâãUIÔºåÂÆûÁé∞Ëá™Âä®ÈÅøÂºÄÊªöÂä®Êù°ÔºåÈÅøÂÖçÈáçÂè†ËØØËß¶\r\n* ‰øÆÂ§çÊ†áÁ≠æÂºπÁ™óÊó†ÊªöÂä®Êù°ÔºåÂÜÖÂÆπÊòæÁ§∫‰∏çÂÖ®ÁöÑÈóÆÈ¢ò\r\n\r\n</details>\r\n\r\n<details>\r\n\r\n<summary>[2025-8-23]V1.1.2 </summary>\r\n\r\n* ÈáçÊûÑËäÇÁÇπÔºåËß£ÂÜ≥ÊâßË°åÊó∂‰∫ßÁîüÂ§öÈòüÂàóÂíåÈáçÂ§çÊâßË°åÁöÑÈóÆÈ¢ò\r\n* APIÈÖçÁΩÆÁïåÈù¢Ê∑ªÂä†Ê®°ÂûãÂèÇÊï∞ÔºåÊüê‰∫õÊä•ÈîôÂèØ‰ª•Â∞ùËØïË∞ÉÊï¥ÊúÄÂ§ßtokenÊï∞Ëß£ÂÜ≥\r\n* ÁÆÄÂåñÂõæÂÉèÂèçÊé®ÊµÅÁ®ãÔºåÊèêÂçáÂèçÊé®ÈÄüÂ∫¶\r\n* ‰øÆÂ§ç‰∫ÜÊ†áÁ≠æÊåâÈúÄÂä†ËΩΩÊó∂ÔºåÊó†Ê≥ïÊêúÁ¥¢Âà∞Êú™Âä†ËΩΩÁöÑÊ†áÁ≠æ\r\n\r\n</details>\r\n\r\n<details>\r\n\r\n<summary>[2025-8-10]V1.1.1 </summary>\r\n\r\n-‰øÆÂ§çÂõæÂÉèÂèçÊé®ËäÇÁÇπÊä•Èîô\r\n\r\n</details>\r\n\r\n<details>\r\n\r\n<summary>[2025-8-10]V1.1.0 </summary>\r\n\r\n* ‰øÆÊîπ‰∫ÜUI‰∫§‰∫í\r\n* ÊîØÊåÅÊâÄÊúâÂÖºÂÆπOpenAI SDK API\r\n* Êñ∞Â¢ûËá™ÂÆöËá™ÂÆö‰πâËßÑÂàô\r\n* Êñ∞Â¢ûËá™ÂÆö‰πâÊ†áÁ≠æ\r\n* Êñ∞Â¢ûÂõæÂÉèÂèçÊé®„ÄÅKontextÈ¢ÑËÆæ„ÄÅÁøªËØëËäÇÁÇπËäÇÁÇπ\r\n\r\n</details>\r\n\r\n</details>\r\n\r\n<details>\r\n\r\n<summary><strong>V1.0.x</strong> </summary>\r\n\r\n<details>\r\n\r\n<summary>[2025-6-24]V1.0.6Ôºö </summary>\r\n\r\n* ‰øÆÂ§ç‰∫Ü‰∏Ä‰∫õÁïåÈù¢bug\r\n\r\n</details>\r\n\r\n<details>\r\n\r\n<summary>[2025-6-24]V1.0.5Ôºö </summary>\r\n\r\n* ‰øÆÂ§çÊñ∞ÁâàÂàõÂª∫‰ΩøÁî®ÈÄâÊã©Â∑•ÂÖ∑Ê†èÂàõÂª∫kontextËäÇÁÇπÊó∂ÔºåÂá∫Áé∞Â∞èÂä©ÊâãUIÂºÇÂ∏∏ÈóÆÈ¢ò\r\n* ‰øÆÂ§çÂèØËÉΩÁΩëÁªúÁéØÂ¢ÉÈóÆÈ¢òÈÄ†ÊàêÁöÑÊô∫Ë∞±Êó†Ê≥ïÊúçÂä°Êó†Ê≥ï‰ΩøÁî®ÈóÆÈ¢ò\r\n* ‰øÆÂ§çÂèØËÉΩÂá∫Áé∞ÂÆû‰æãÊ∏ÖÈô§Âá∫ÈîôÂØºËá¥Â∑•‰ΩúÊµÅÊó†Ê≥ïÂä†ËΩΩÈóÆÈ¢ò\r\n* ‰øÆÂ§çAIGODLIKE-COMFYUI-TRANSLATIONÊ±âÂåñÊèí‰ª∂ÂØºËá¥Ê†áÁ≠æÂºπÁ™óÊâìÂºÄÂç°‰ΩèÁöÑÈóÆÈ¢ò\r\n* Êñ∞Â¢ûÊ†áÁ≠æÈù¢ÊùøÂèØ‰ª•Ë∞ÉÊï¥Â§ßÂ∞è\r\n* ‰ºòÂåñUIËµÑÊ∫êÂä†ËΩΩÊú∫Âà∂\r\n\r\n</details>\r\n\r\n<details>\r\n\r\n<summary>[2025-6-24]V1.0.3Ôºö </summary>\r\n\r\n* ÈáçÊûÑ‰∫ÜapiËØ∑Ê±ÇÊúçÂä°ÔºåÈÅøÂÖçapikeyÊö¥Èú≤Âú®ÂâçÁ´Ø\r\n* ‰øÆÊîπ‰∫ÜÈÖçÁΩÆÁöÑ‰øùÂ≠òÂíåËØªÂèñÊú∫Âà∂ÔºåËß£ÂÜ≥ÈÖçÁΩÆÊó†Ê≥ï‰øùÂ≠òÈóÆÈ¢ò\r\n* ‰øÆÂ§ç‰∫ÜÂ∞ëËÆ∏bug\r\n\r\n</details>\r\n\r\n<details>\r\n\r\n<summary>[2025-6-21]V1.0.2Ôºö</summary>\r\n\r\n* ‰øÆÂ§ç‰∫ÜÂ∞ëËÆ∏bug\r\n\r\n</details>\r\n\r\n<details>\r\n\r\n<summary>[2025-6-15]V1.0.0:</summary>\r\n\r\n* ‰∏ÄÈîÆÊèíÂÖ•tag\r\n* ÊîØÊåÅllmÊâ©ÂÜô\r\n* ÊîØÊåÅÁôæÂ∫¶ÁøªËØëÂíållmÁøªËØëÂàáÊç¢\r\n* ÂõæÁâáÂèçÊé®ÊèêÁ§∫ËØç\r\n* ÂéÜÂè≤„ÄÅÊí§ÈîÄ„ÄÅÈáçÂÅö\r\n\r\n</details>\r\n\r\n</details>\r\n\r\n## **‚ú® ÂäüËÉΩ‰ªãÁªç**\r\n#### üí°ÊèêÁ§∫ËØç‰ºòÂåñ+ÁøªËØë\r\n\r\n`ÊîØÊåÅÈ¢ÑËÆæÂ§öÂ•óÊèêÁ§∫ËØç‰ºòÂåñËßÑÂàôÔºàÂ¶ÇÊâ©ÂÜô„ÄÅqwen-editÊåá‰ª§‰ºòÂåñÔºåkontextÊåá‰ª§‰ºòÂåñÂπ∂ÁøªËØëÁ≠â`\r\n\r\n`Êó†ËØ≠ËÆæÁΩÆÁõÆÊ†áËØ≠Ë®ÄÔºåËá™Âä®‰∏≠Ëã±‰∫íËØëÔºåËá™Â∏¶ÁøªËØëÁºìÂ≠òÂäüËÉΩÔºåÈÅøÂÖçÈáçÂ§çÁøªËØëÂØºËá¥ÂéüÊñáÂÅèÂ∑Æ`\r\n\r\n![ÁøªËØëÊâ©ÂÜô](https://github.com/user-attachments/assets/a37b715e-ecfd-47d6-a4b8-a0b1e6bb9fcd) \r\n\r\n\r\n#### üñºÂõæÂÉèÂèçÊé®\r\n\r\n`Âú®ÂõæÂÉèËäÇÁÇπ‰∏äÂø´ÈÄüÂÆûÁé∞Â∞ÜÂõæÁâáÂèçÊé®ÊàêÊèêÁ§∫ËØçÔºåÊîØÊåÅÔºà‰∏≠/Ëã±ÔºâÔºåÊîØÊåÅÂ§öÁßçÂèçÊé®È£éÊ†ºÔºàÂ¶ÇËá™ÁÑ∂ËØ≠Ë®Ä„ÄÅTagÈ£éÊ†º...Ôºâ`\r\n\r\n![ÂèçÊé®](https://github.com/user-attachments/assets/3713ddc5-4e2e-4412-88ee-077d86f21b99)\r\n\r\n\r\n#### üîñÊ†áÁ≠æ„ÄÅÁü≠ËØ≠È¢ÑËÆæ‰∏éÊî∂Ëóè\r\n\r\n`ÂèØÂ∞ÜÂ∏∏Áî®Ê†áÁ≠æ„ÄÅÁü≠ËØ≠„ÄÅLoraËß¶ÂèëËØçÊî∂ÈõÜÔºåÂø´ÈÄüÊèíÂÖ•„ÄÇÊ†áÁ≠æÂèØÊî∂Ëóè„ÄÅËá™ÂÆö‰πâ„ÄÅÊéíÂ∫è„ÄÅÂπ∂‰∏îÊîØÊåÅÂ§öÂ•óÊ†áÁ≠æÂàáÊç¢„ÄÇ`\r\n\r\n![Ê†áÁ≠æÂäüËÉΩ](https://github.com/user-attachments/assets/944173be-8167-42eb-93d9-e0c05256ccf8)\r\n\r\n\r\n#### üïêÂéÜÂè≤„ÄÅÊí§ÈîÄ„ÄÅÈáçÂÅö\r\n\r\n`ÂèØ‰ª•ÊåâÂè•‰∏∫Âçï‰ΩçËÆ∞ÂΩïÔºàËæìÂÖ•Ê°ÜÂ§±ÁÑ¶Ëß¶ÂèëËÆ∞ÂΩïÔºâÔºåÊí§ÈîÄÂíåÈáçÂÅöÊèêÁ§∫ËØçÔºåÊîØÊåÅË∑®ËäÇÁÇπÊü•ÁúãÊèêÁ§∫ËØçÂéÜÂè≤ËÆ∞ÂΩï„ÄÇ`\r\n\r\n![ÂéÜÂè≤](https://github.com/user-attachments/assets/85868b9e-1bf5-4789-9a71-97af80ef2bc8)\r\n\r\n\r\n#### üìúMarkdownÂíåËäÇÁÇπÊñáÊ°£ÁøªËØë\r\n\r\n`ÊîØÊåÅÁøªËØënoteËäÇÁÇπÂíåMarkdownËäÇÁÇπÔºåÂπ∂‰øùÊåÅÊ†ºÂºè`\r\n\r\n![markdown](https://github.com/user-attachments/assets/c2ac1266-f8c1-4b27-ba41-13c5b5e5e689)\r\n\r\n`ÊîØÊåÅÁøªËØëËã±ÊñáËäÇÁÇπÊñáÊ°£ÔºàbetaÔºö‰ªÖÂú®Ëã±ÊñáËäÇÁÇπÊâç‰ºöÂá∫Áé∞ÁøªËØëÊåâÈíÆÔºâ`\r\n\r\n![nodedoc](https://github.com/user-attachments/assets/32c9a712-20c3-4b5e-b331-bfb885b7b5d4)\r\n\r\n\r\n\r\n### üìíËäÇÁÇπ‰ªãÁªç\r\nËäÇÁÇπÂàÜÁ±ª`‚ú®Prompt Assistant`\r\n\r\n#### **üîπÁøªËØëËäÇÁÇπ**\r\n`‚ú®Prompt Assistant ‚Üí ÊèêÁ§∫ËØçÁøªËØë`\r\n\r\n<img width=\"1700\" height=\"700\" alt=\"ÁøªËØëËäÇÁÇπ\" src=\"https://github.com/user-attachments/assets/9dbc9fc9-1b91-43b6-822e-d598b2c8168f\" />\r\n\r\n\r\n#### **üîπÊèêÁ§∫ËØç‰ºòÂåñËäÇÁÇπ**\r\n`‚ú®Prompt Assistant ‚Üí ÊèêÁ§∫ËØç‰ºòÂåñ`\r\n\r\n<img width=\"1700\" height=\"911\" alt=\"Êâ©ÂÜôËäÇÁÇπ\" src=\"https://github.com/user-attachments/assets/ea821506-d684-4526-9119-621bb0467ddf\" />\r\n\r\n\r\n#### **üîπÂõæÂÉèÂèçÊé®ËäÇÁÇπ**\r\n`‚ú®Prompt Assistant ‚Üí ÂõæÂÉèÂèçÊé®ÊèêÁ§∫ËØç`\r\n\r\n`ÂèØ‰ª•ÂèçÊé®ÂõæÂÉè„ÄÅÁªìÂêàËßÜËßâÊ®°Âûã‰ºòÂåñÂõæÂÉèÁºñËæëÊåá‰ª§`\r\n\r\n<img width=\"1700\" height=\"800\" alt=\"ÂõæÂÉèÂèçÊé®ËäÇÁÇπ\" src=\"https://github.com/user-attachments/assets/8ff3ac96-724a-48d0-8e15-23fe0b28bec1\" />\r\n\r\n<img width=\"1700\" height=\"800\" alt=\"ÁºñËæëÊ®°ÂûãÈÖçÂêàËßÜËßâÁêÜËß£\" src=\"https://github.com/user-attachments/assets/a95dc0f4-1d46-438f-a242-4087f6e8361a\" />\r\n\r\n\r\n\r\n\r\n#### **üîπËßÜÈ¢ëÂèçÊé®ËäÇÁÇπ**\r\n`‚ú®Prompt Assistant ‚Üí ËßÜÈ¢ëÂèçÊé®ÊèêÁ§∫ËØç`\r\n\r\n<img width=\"1700\" height=\"1080\" alt=\"ËßÜÈ¢ëÂèçÊé®ËäÇÁÇπ\" src=\"https://github.com/user-attachments/assets/0143096b-24d5-4308-82ff-e0a99144db0b\" />\r\n<img width=\"1700\" height=\"1102\" alt=\"ÈÄâÂèñÂ∏ßÂ∑•ÂÖ∑\" src=\"https://github.com/user-attachments/assets/96c2bd08-b26c-4df1-b32c-be8e20328c97\" />\r\n\r\n\r\n\r\n> üí°Âú®‰ªªÊÑèËäÇÁÇπËæìÂÖ•Ê°Ü‰∏≠ËæìÂÖ•[R],Âú®ËäÇÁÇπËæìÂÖ•ÂíåÂèÇÊï∞Ê≤°ÊúâÂèëÁîüÂèòÂåñÁöÑÊÉÖÂÜµ‰∏ãÔºåÊØèÊ¨°ÈÉΩË¢´ÊâßË°åÔºàÁ±ª‰ººÈöèÊú∫ÁßçÂ≠êÔºâ\r\n>\r\n> \r\n\r\n## **üì¶ ÂÆâË£ÖÊñπÊ≥ï**\r\n\r\n### ‚ö†Ô∏èÊóßÁâàÊú¨ËøÅÁßªÊ≥®ÊÑè‰∫ãÈ°π\r\n\r\n`Â¶ÇÊûúÊÇ®ÂÆâË£ÖËøáÊèêÁ§∫ËØçÂ∞èÂä©Êâã2.0‰πãÂâçÁöÑÁâàÊú¨ÔºåËØ∑Ê≥®ÊÑèÂ§á‰ªΩÂéüÊèí‰ª∂ÁõÆÂΩï‰∏ãÁöÑconfigÁõÆÂΩï„ÄÇÈÅøÂÖçapiÈÖçÁΩÆ„ÄÅËá™ÂÆö‰πâËßÑÂàô„ÄÅËá™ÂÆö‰πâÊ†áÁ≠æÊï∞ÊçÆ‰∏¢Â§±ÔºÅ`\r\n\r\nÂ¶ÇÊûúÊÇ®‰πãÂâçÊòØÈÄöËøá**Manager**ÂÆâË£ÖÂàôÁõ¥Êé•Êõ¥Êñ∞Âç≥ÂèØÔºåÂ¶ÇÊûúÊÇ®‰ΩøÁî®ÁöÑÊòØÊâãÂä®ÂÆâË£ÖÔºåÂª∫ËÆÆÂà†Èô§ÊóßÁöÑÊèí‰ª∂ÁõÆÂΩïÔºàËÆ∞ÂæóÂ§á‰ªΩconfigÁõÆÂΩïÔºÅÔºÅÔºâÂ∞ÜÊñ∞ÁöÑÊèí‰ª∂ÊîæÂÖ•Âà∞`custom\\custom_nodes`ÁõÆÂΩïÔºåÂÜçÂ∞ÜÈúÄË¶ÅÊÅ¢Â§çÁöÑÈÖçÁΩÆÊñá‰ª∂ÊîæÂõûconfigÁõÆÂΩï\r\n\r\n#### **‰ªéComfyUI Manager‰∏≠ÂÆâË£Ö**\r\n\r\nÂú®Manager‰∏≠ËæìÂÖ•`Prompt Assistant`Êàñ`ÊèêÁ§∫ËØçÂ∞èÂä©Êâã`ÔºåÁÇπÂáª`Install`ÔºåÈÄâÊã©ÊúÄÊñ∞ÁâàÊú¨ÂÆâË£Ö„ÄÇ\r\n\r\n<img width=\"1800\" height=\"1098\" alt=\"ÂÆâË£Ö\" src=\"https://github.com/user-attachments/assets/167eb467-a77d-4a37-a95b-e935ca354284\" />\r\n\r\n\r\n\r\n#### **ÂÖãÈöÜ‰ª£Á†Å‰ªìÂ∫ì**\r\n\r\n\r\n1. ÂØºËà™Âà∞ÊÇ®ÁöÑComfyUIËá™ÂÆö‰πâËäÇÁÇπÊñá‰ª∂Â§π:\r\n   ```bash\r\n   cd ComfyUI/custom_nodes\r\n   ```\r\n\r\n2. ÂÖãÈöÜËøô‰∏™‰ª£Á†Å‰ªìÂ∫ì:\r\n   ```bash\r\n   git clone https://github.com/yawiii/ComfyUI-Prompt-Assistant.git\r\n   ```\r\n\r\n3. ÈáçÂêØ ComfyUIÔºö\r\n\r\n#### **‰∏ãËΩΩÊèí‰ª∂ÂéãÁº©ÂåÖ**\r\n\r\n1.  ‰ªé[ÂÖãÈöÜ‰ªìÂ∫ì](https://github.com/yawiii/comfyui_prompt_assistant/releases)‰∏≠‰∏ãËΩΩÊúÄÊñ∞ÁâàÊú¨\r\n\r\n    Ëß£ÂéãÁº©Âà∞ `ComfyUI/custom_nodes` ÁõÆÂΩï‰∏ã\r\n\r\n    `‚ö†Ô∏èÊ≥®ÊÑèÔºöÂª∫ËÆÆÂ∞ÜÊèí‰ª∂ÁõÆÂΩïÂêçÁß∞‰øÆÊîπ‰∏∫Ôºöprompt-assistantÔºå‰ª•Á¨¶ÂêàComfyUIËßÑËåÉ`\r\n<img width=\"600\" height=\"276\" alt=\"githubÂÆâË£Ö\" src=\"https://github.com/user-attachments/assets/99783a78-6e0b-42aa-8f9e-7146ebcef5fd\" />\r\n\r\n\r\n2. ÈáçÂêØ ComfyUI\r\n\r\n### Êï∞ÊçÆËá™Âä®ËøÅÁßª\r\n\r\nÊñ∞ÁâàÊú¨ËÉΩËá™Âä®Â∞ÜÁî®Êà∑ÁöÑapiÈÖçÁΩÆ„ÄÅËá™ÂÆö‰πâËßÑÂàô„ÄÅËá™ÂÆö‰πâÊ†áÁ≠æËøõË°åÂçáÁ∫ßÂíåËøÅÁßª„ÄÇÊÇ®ÂèØ‰ª•Ê†πÊçÆËá™Â∑±ÁöÑÈúÄË¶ÅÔºåÂ∞ÜË¶ÅÂÅöËøÅÁßªÁöÑÊñá‰ª∂ÔºåÊîæÁΩÆÂú®`prompt-assistant\\config`ÁõÆÂΩï‰∏ã„ÄÇÂ¶ÇÊûú‰∏çÈÄâÊã©ËøÅÁßªÔºåÈáçÊñ∞ÂÆâË£ÖÂêéÔºåAPIÈÖçÁΩÆ‰ø°ÊÅØÔºåÈúÄË¶ÅÈáçÊñ∞ÊâãÂä®ÈÖçÁΩÆÔºÅ ÂèØËøÅÁßªÊñá‰ª∂Êúâ\r\nÊñ∞ÁâàÊú¨ÁöÑÂ∞èÂä©ÊâãÈÖçÁΩÆÊñá‰ª∂ÂÇ®Â≠òÂú®`ComfyUI\\user\\default\\prompt-assistant`ÁõÆÂΩï‰∏ãÔºå\r\n\r\n<img width=\"600\" height=\"419\" alt=\"ËøÅÁßª\" src=\"https://github.com/user-attachments/assets/90b8f90f-51df-4537-b735-ae07c3cdff7f\" />\r\n\r\n\r\n\r\n\r\n\r\n\r\n## **‚öôÔ∏è ÈÖçÁΩÆËØ¥Êòé**\r\n\r\n### ÈÖçÁΩÆAPI KeyÔºåÂπ∂ÈÖçÁΩÆÊ®°Âûã\r\n\r\n<img width=\"1593\" height=\"1119\" alt=\"ËøõÂÖ•ÈÖçÁΩÆÈ°µÈù¢\" src=\"https://github.com/user-attachments/assets/ea01c0bc-fe0f-40be-991c-d7833965213a\" />\r\n\r\n<img width=\"1569\" height=\"1137\" alt=\"apIÈÖçÁΩÆÁ™óÂè£\" src=\"https://github.com/user-attachments/assets/9d982773-2939-480b-a691-bb89a227a9ff\" />\r\n\r\n\r\n### ÊúçÂä°ËØ¥Êòé\r\n\r\nÊÇ®ÂèØ‰ª•ÈúÄÊ±ÇÊñ∞Â¢ûÊúçÂä°ÂïÜÔºåÊàñËÄÖÈÄâÊã©ÂÜÖÁΩÆÁöÑÊúçÂä°ÂïÜËøõË°å‰ΩøÁî®Ôºö\r\n\r\n`‚ö†Ô∏èÂÖçË¥£Â£∞ÊòéÔºöÊú¨Êèí‰ª∂‰ªÖÊèê‰æõAPIË∞ÉÁî®Â∑•ÂÖ∑ÔºåÁ¨¨‰∏âÊñπÊúçÂä°Ë¥£‰ªª‰∏éÊú¨Êèí‰ª∂Êó†ÂÖ≥ÔºåÊèí‰ª∂ÊâÄÊ∂âÁî®Êà∑ÈÖçÁΩÆ‰ø°ÊÅØÂùáÂ≠òÂÇ®‰∫éÊú¨Âú∞„ÄÇÂØπ‰∫éÂõ†Ë¥¶Âè∑‰ΩøÁî®‰∫ßÁîüÁöÑ‰ªª‰ΩïÈóÆÈ¢òÔºåÊú¨Êèí‰ª∂‰∏çÊâøÊãÖË¥£‰ªªÔºÅ`\r\n\r\n\r\n‚Äã**ÁôæÂ∫¶ÁøªËØëÔºàÊú∫Âô®ÁøªËØë**‚ÄãÔºâÔºö[ÁôæÂ∫¶ÈÄöÁî®ÊñáÊú¨ÁøªËØëÁî≥ËØ∑ÂÖ•Âè£](https://fanyi-api.baidu.com/product/11)\r\n\r\n`ÈÄüÂ∫¶Âø´Ôºå‰ΩÜÊòØÁøªËØëË¥®Èáè‰∏ÄËà¨„ÄÇ‰ΩøÁî®È≠îÊ≥ïÊó∂ÂèØËÉΩ‰ºöÂØºËá¥Êó†Ê≥ïËØ∑Ê±ÇÊØè‰∏™ÊúàÊúâÂÖçË¥π500wÈ¢ùÂ∫¶`\r\n\r\n\r\n**‚ÄãÊô∫Ë∞±ÔºàÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊ®°ÂûãÔºâÔºö‚Äã**[Êô∫Ë∞±APIÁî≥ËØ∑ÂÖ•Âè£](https://www.bigmodel.cn/invite?icode=Wz1tQAT40T9M8vwp%2F1db7nHEaazDlIZGj9HxftzTbt4%3D)\r\n\r\n`ÈÄüÂ∫¶Âø´ÔºåÊó†ÈôêÈ¢ùÂ∫¶ÔºõÊ≥®ÊÑèÔºöÊ®°ÂûãÊúâÂÆ°Êü•ÔºåÂ¶ÇÊûúËØ∑Ê±ÇÂÜÖÂÆπËøùËßÑÔºå‰ºöËøîÂõûÁ©∫ÁªìÊûú„ÄÇÂπ∂ÈùûÊèí‰ª∂bug„ÄÇÊúÄËøëÊô∫Ë∞±ÂºÄÂßãÈôêÂà∂ËØ∑Ê±ÇÈ¢ëÁéá‰∫Ü„ÄÇ`\r\n\r\n\r\n**‚ÄãxFlow-APIËÅöÂêàÔºö‚Äã**[xFlow APIÁî≥ËØ∑ÂÖ•Âè£](https://api.xflow.cc/register?aff=Z063)\r\n\r\n`Êèê‰æõÂêÑÁ±ªÊ®°ÂûãAPIËÅöÂêàÔºàÂ¶ÇGemini„ÄÅnano Bannana„ÄÅGrok„ÄÅChatGTP...ÔºâÔºåÂÆûÁé∞‰∏Ä‰∏™APIkeyË∞ÉÁî®ÊâÄÊúâ‰∏ªÊµÅÂ§ßÊ®°ÂûãÔºåÊó†ÈúÄËß£ÂÜ≥ÁΩëÁªúÈóÆÈ¢òÔºõ`\r\n\r\n**ÂÖ∂‰ªñÊúçÂä°ÂïÜÂèØËá™Ë°åÊ∑ªÂä†**\r\n\r\n\r\n\r\n## **üéÄÁâπÂà´ÊÑüË∞¢‰ª•‰∏ãÊúãÂèãÔºÅ**\r\n\r\nÊÑüË∞¢Áæ§Âèã‰∏∫V2.0.0ÁâàÊú¨Êèê‰æõËßÑÂàôÊ®°ÊùøÔºöÈòø‰∏π„ÄÅCJL„ÄÅËØ∫ÊõºÂ∫ï\r\n\r\n\r\n\r\n\r\n\r\n",
      "stars_today": 12
    },
    {
      "id": 15045751,
      "name": "compose",
      "full_name": "docker/compose",
      "description": "Define and run multi-container applications with Docker",
      "html_url": "https://github.com/docker/compose",
      "stars": 36795,
      "forks": 5691,
      "language": "Go",
      "topics": [
        "docker",
        "docker-compose",
        "go",
        "golang",
        "orchestration"
      ],
      "created_at": "2013-12-09T11:40:58Z",
      "updated_at": "2026-01-13T23:54:19Z",
      "pushed_at": "2026-01-13T09:21:25Z",
      "open_issues": 57,
      "owner": {
        "login": "docker",
        "avatar_url": "https://avatars.githubusercontent.com/u/5429470?v=4"
      },
      "readme": "# Table of Contents\n- [Docker Compose](#docker-compose)\n- [Where to get Docker Compose](#where-to-get-docker-compose)\n    + [Windows and macOS](#windows-and-macos)\n    + [Linux](#linux)\n- [Quick Start](#quick-start)\n- [Contributing](#contributing)\n- [Legacy](#legacy)\n\n# Docker Compose\n\n[![GitHub release](https://img.shields.io/github/v/release/docker/compose.svg?style=flat-square)](https://github.com/docker/compose/releases/latest)\n[![PkgGoDev](https://img.shields.io/badge/go.dev-docs-007d9c?style=flat-square&logo=go&logoColor=white)](https://pkg.go.dev/github.com/docker/compose/v5)\n[![Build Status](https://img.shields.io/github/actions/workflow/status/docker/compose/ci.yml?label=ci&logo=github&style=flat-square)](https://github.com/docker/compose/actions?query=workflow%3Aci)\n[![Go Report Card](https://goreportcard.com/badge/github.com/docker/compose/v5?style=flat-square)](https://goreportcard.com/report/github.com/docker/compose/v5)\n[![Codecov](https://codecov.io/gh/docker/compose/branch/main/graph/badge.svg?token=HP3K4Y4ctu)](https://codecov.io/gh/docker/compose)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/docker/compose/badge)](https://api.securityscorecards.dev/projects/github.com/docker/compose)\n![Docker Compose](logo.png?raw=true \"Docker Compose Logo\")\n\nDocker Compose is a tool for running multi-container applications on Docker\ndefined using the [Compose file format](https://compose-spec.io).\nA Compose file is used to define how one or more containers that make up\nyour application are configured.\nOnce you have a Compose file, you can create and start your application with a\nsingle command: `docker compose up`.\n\n> **Note**: About Docker Swarm\n> Docker Swarm used to rely on the legacy compose file format but did not adopt the compose specification\n> so is missing some of the recent enhancements in the compose syntax. After \n> [acquisition by Mirantis](https://www.mirantis.com/software/swarm/) swarm isn't maintained by Docker Inc, and\n> as such some Docker Compose features aren't accessible to swarm users.\n\n# Where to get Docker Compose\n\n### Windows and macOS\n\nDocker Compose is included in\n[Docker Desktop](https://www.docker.com/products/docker-desktop/)\nfor Windows and macOS.\n\n### Linux\n\nYou can download Docker Compose binaries from the\n[release page](https://github.com/docker/compose/releases) on this repository.\n\nRename the relevant binary for your OS to `docker-compose` and copy it to `$HOME/.docker/cli-plugins`\n\nOr copy it into one of these folders to install it system-wide:\n\n* `/usr/local/lib/docker/cli-plugins` OR `/usr/local/libexec/docker/cli-plugins`\n* `/usr/lib/docker/cli-plugins` OR `/usr/libexec/docker/cli-plugins`\n\n(might require making the downloaded file executable with `chmod +x`)\n\n\nQuick Start\n-----------\n\nUsing Docker Compose is a three-step process:\n1. Define your app's environment with a `Dockerfile` so it can be\n   reproduced anywhere.\n2. Define the services that make up your app in `compose.yaml` so\n   they can be run together in an isolated environment.\n3. Lastly, run `docker compose up` and Compose will start and run your entire\n   app.\n\nA Compose file looks like this:\n\n```yaml\nservices:\n  web:\n    build: .\n    ports:\n      - \"5000:5000\"\n    volumes:\n      - .:/code\n  redis:\n    image: redis\n```\n\nContributing\n------------\n\nWant to help develop Docker Compose? Check out our\n[contributing documentation](CONTRIBUTING.md).\n\nIf you find an issue, please report it on the\n[issue tracker](https://github.com/docker/compose/issues/new/choose).\n\nLegacy\n-------------\n\nThe Python version of Compose is available under the `v1` [branch](https://github.com/docker/compose/tree/v1).\n",
      "stars_today": 11
    },
    {
      "id": 178079595,
      "name": "opencost",
      "full_name": "opencost/opencost",
      "description": "Cost monitoring for Kubernetes workloads and cloud costs",
      "html_url": "https://github.com/opencost/opencost",
      "stars": 6254,
      "forks": 719,
      "language": "Go",
      "topics": [
        "aws",
        "azure",
        "cncf",
        "cost",
        "cost-optimization",
        "finops",
        "gcp",
        "k8s",
        "kubernetes",
        "monitoring",
        "opencost",
        "prometheus"
      ],
      "created_at": "2019-03-27T21:49:05Z",
      "updated_at": "2026-01-13T23:10:23Z",
      "pushed_at": "2026-01-13T20:20:03Z",
      "open_issues": 156,
      "owner": {
        "login": "opencost",
        "avatar_url": "https://avatars.githubusercontent.com/u/105945214?v=4"
      },
      "readme": "[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/6219/badge)](https://www.bestpractices.dev/projects/6219)\n[![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20OpenCost%20Guru-006BFF)](https://gurubase.io/g/opencost)\n\n![](./opencost-header.png)\n\n# OpenCost ‚Äî your favorite open source cost monitoring tool for Kubernetes and cloud spend\n\nOpenCost give teams visibility into current and historical Kubernetes and cloud spend and resource allocation.\nThese models provide cost transparency in Kubernetes environments that support multiple applications, teams, departments, etc.\nIt also provides visibility into the cloud costs across multiple providers.\n\nOpenCost was originally developed and open sourced by [Kubecost](https://kubecost.com). This project combines a [specification](/spec/) as well as a Golang implementation of these detailed requirements. The web UI is available in the [opencost/opencost-ui](http://github.com/opencost/opencost-ui) repository.\n\n[![OpenCost UI Walkthrough](./ui/src/thumbnail.png)](https://youtu.be/lCP4Ci9Kcdg)\n*OpenCost UI Walkthrough*\n\nTo see the full functionality of OpenCost you can view [OpenCost features](https://opencost.io). Here is a summary of features enabled:\n\n- Real-time cost allocation by Kubernetes cluster, node, namespace, controller kind, controller, service, or pod\n- Multi-cloud cost monitoring for all cloud services on AWS, Azure, GCP\n- Dynamic on-demand k8s asset pricing enabled by integrations with AWS, Azure, and GCP billing APIs\n- Supports on-prem k8s clusters with custom CSV pricing\n- Allocation for in-cluster K8s resources like CPU, GPU, memory, and persistent volumes\n- Easily export pricing data to Prometheus with /metrics endpoint ([learn more](https://www.opencost.io/docs/installation/prometheus))\n- Carbon costs for cloud resources\n- MCP support\n- Support for external costs like Datadog through [OpenCost Plugins](https://github.com/opencost/opencost-plugins)\n- Free and open source distribution ([Apache2 license](LICENSE))\n\n## Getting Started\n\nOpenCost is now installed and managed via the official Helm chart only.\n\nQuick install on any Kubernetes 1.20+ cluster:\n\n```bash\nhelm repo add opencost https://opencost.github.io/opencost-helm-chart\nhelm repo update\nhelm install opencost opencost/opencost\n```\n\nNote: The standalone Kubernetes manifest files have been removed. Please use Helm for all installations and upgrades. See the [Helm installation docs](https://www.opencost.io/docs/installation/install) for details and configuration.\n\n> **Note for sharded Prometheus users:**\n> If you run Prometheus in a sharded (HA) setup, set `PROMETHEUS_SERVER_ENDPOINT` to a global query endpoint (e.g., Thanos Query, Cortex, or Mimir). Pointing to a single Prometheus pod may result in incomplete or intermittent export results. See the [Prometheus integration docs](https://www.opencost.io/docs/installation/prometheus) for details.\n\n## Usage\n\n- [Cost APIs](https://www.opencost.io/docs/integrations/api)\n- [CLI / kubectl cost](https://www.opencost.io/docs/integrations/kubectl-cost)\n- [Prometheus Metrics](https://www.opencost.io/docs/integrations/prometheus)\n- [User Interface](https://www.opencost.io/docs/installation/ui)\n\n## MCP Server\n\nThe OpenCost MCP (Model Context Protocol) server provides AI agents with access to cost allocation and asset data through a standardized interface. The MCP server is **enabled by default** in all OpenCost deployments, runs on port 8081, and is **built into the Helm chart** for easy production deployment. Users have full control to disable it or configure custom ports and settings.\n\n### Features\n\n- **Enabled by Default**: MCP server starts automatically with OpenCost\n- **Full User Control**: Easy to disable or configure port and settings\n- **Allocation Queries**: Retrieve cost allocation data with filtering and aggregation\n- **Asset Queries**: Access detailed asset information including nodes, disks, load balancers, and more\n- **Cloud Cost Queries**: Query cloud cost data with provider, service, and region filtering\n- **HTTP Transport**: Uses HTTP for reliable communication with MCP clients\n- **Zero Configuration**: Works out of the box with default OpenCost deployment\n- **Helm Integration**: Built into the official Helm chart for production deployments\n\n### Quick Start\n\n#### Using Tilt (Development)\n```bash\n# Clone and start OpenCost with MCP server\ngit clone https://github.com/opencost/opencost.git\ncd opencost\ntilt up\n```\n\nTilt configuration notes (cloud costs):\n\nOpenCost's Tilt values (`tilt-values.yaml`) include extra environment variables to enable Cloud Cost ingestion in dev:\n\n```yaml\n# tilt-values.yaml (excerpt)\nopencost:\n  exporter:\n    extraEnv:\n      CLOUD_COST_ENABLED: \"true\"\n      CLOUD_COST_CONFIG_PATH: \"/var/cloud-integration/cloud-integration.json\"\n```\n\n- Set `CLOUD_COST_ENABLED` to \"true\" to turn on cloud cost ingestion.\n- Point `CLOUD_COST_CONFIG_PATH` to the mounted cloud integration file used by Tilt (e.g., `/var/cloud-integration/cloud-integration.json`).\n- Adjust other values in `tilt-values.yaml` as needed during development.\n\n#### Using Helm (Production)\n```bash\n# Add the OpenCost Helm repository\nhelm repo add opencost https://opencost.github.io/opencost-helm-chart\nhelm repo update\n\n# Deploy OpenCost with MCP server (enabled by default)\nhelm install opencost opencost/opencost\n\n# Access MCP server via port forwarding (example)\nkubectl port-forward svc/opencost 8081:8081\n```\n\nThe MCP server is **enabled by default** in the Helm chart. For custom configuration:\n\n```bash\n# Deploy with MCP server disabled\nhelm install opencost opencost/opencost \\\n  --set opencost.mcp.enabled=false\n\n# Deploy with custom MCP port\nhelm install opencost opencost/opencost \\\n  --set opencost.mcp.port=9091\n\n# Deploy with debug logging\nhelm install opencost opencost/opencost \\\n  --set opencost.mcp.extraEnv.MCP_LOG_LEVEL=debug\n```\n\n#### Configuration Summary\n\n| Configuration | Command | Description |\n|---------------|---------|-------------|\n| **Default** | `helm install opencost opencost/opencost` | MCP enabled on port 8081 |\n| **Disable** | `--set opencost.mcp.enabled=false` | Completely disable MCP server |\n| **Custom Port** | `--set opencost.mcp.port=9091` | Use different port |\n| **Debug Mode** | `--set opencost.mcp.extraEnv.MCP_LOG_LEVEL=debug` | Enable debug logging |\n\n### MCP Client Configuration\n\nConfigure your MCP client (e.g., Cursor) to connect to the OpenCost MCP server:\n\n**Default configuration (port 8081):**\n```json\n{\n  \"mcpServers\": {\n    \"opencost\": {\n      \"type\": \"http\",\n      \"url\": \"http://localhost:8081\"\n    }\n  }\n}\n```\n\n**Custom port configuration:**\n```json\n{\n  \"mcpServers\": {\n    \"opencost\": {\n      \"type\": \"http\",\n      \"url\": \"http://localhost:9091\"\n    }\n  }\n}\n```\n\n**For Kubernetes deployments:**\n```json\n{\n  \"mcpServers\": {\n    \"opencost\": {\n      \"type\": \"http\",\n      \"url\": \"http://opencost.opencost.svc.cluster.local:8081\"\n    }\n  }\n}\n```\n\n**For external access (with LoadBalancer/Ingress):**\n```json\n{\n  \"mcpServers\": {\n    \"opencost\": {\n      \"type\": \"http\",\n      \"url\": \"http://your-opencost-domain.com:8081\"\n    }\n  }\n}\n```\n\n### Available MCP Tools\n\nThe MCP server provides these tools for AI agents:\n\n#### `get_allocation_costs`\nRetrieve cost allocation data with filtering and aggregation.\n\n**Parameters:**\n- `window` (required): Time window (e.g., \"7d\", \"1h\", \"30m\")\n- `aggregate` (optional): Aggregation properties (e.g., \"namespace\", \"pod\", \"node\")\n- `step` (optional): Resolution step size\n- `accumulate` (optional): Whether to accumulate over time\n- `share_idle` (optional): Whether to share idle costs\n- `include_idle` (optional): Whether to include idle resources\n\n#### `get_asset_costs`\nRetrieve asset cost data including nodes, disks, load balancers, and more.\n\n**Parameters:**\n- `window` (required): Time window (e.g., \"7d\", \"1h\", \"30m\")\n\n#### `get_cloud_costs`\nRetrieve cloud cost data with provider, service, and region filtering.\n\n**Parameters:**\n- `window` (required): Time window (e.g., \"7d\", \"1h\", \"30m\")\n- `aggregate` (optional): Aggregation properties (e.g., \"provider\", \"service\", \"region\")\n- `accumulate` (optional): Time accumulation (\"day\", \"week\", \"month\")\n- `provider` (optional): Filter by cloud provider (e.g., \"aws\", \"gcp\", \"azure\")\n- `service` (optional): Filter by service (e.g., \"ec2\", \"compute\", \"s3\")\n- `category` (optional): Filter by category (e.g., \"compute\", \"storage\", \"network\")\n- `region` (optional): Filter by region (e.g., \"us-west-1\", \"us-central1\")\n- `accountID` (optional): Filter by account ID\n\n### Supported Asset Types\n\n- **Node**: Compute instances with CPU, RAM, GPU details\n- **Disk**: Storage volumes with usage and cost breakdown\n- **LoadBalancer**: Load balancer instances with IP and private status\n- **Network**: Network-related costs and usage\n- **Cloud**: Cloud service costs with credit information\n- **ClusterManagement**: Kubernetes cluster management costs\n\n### Example Usage\n\nOnce configured, AI agents can query cost data like:\n\n```javascript\n// Get cost allocation for the last 7 days\nconst allocation = await mcpClient.callTool('get_allocation_costs', {\n  window: '7d',\n  aggregate: 'namespace,node'\n});\n\n// Get asset costs for the last 24 hours\nconst assets = await mcpClient.callTool('get_asset_costs', {\n  window: '1d'\n});\n\n// Get cloud costs for AWS EC2 in us-west-1\nconst cloudCosts = await mcpClient.callTool('get_cloud_costs', {\n  window: '7d',\n  aggregate: 'service',\n  provider: 'aws',\n  service: 'ec2',\n  accumulate: 'day',\n  filter: 'regionID:\"us-west-1\"'\n});\n```\n\nFor detailed setup instructions and advanced configuration, see the [Helm chart documentation](https://github.com/opencost/opencost-helm-chart/blob/main/charts/opencost/README.md#mcp-server).\n\n## Contributing\n\nWe :heart: pull requests! See [`CONTRIBUTING.md`](CONTRIBUTING.md) for information on building the project from source and contributing changes.\n\n## Community\n\nIf you need any support or have any questions on contributing to the project, you can reach us on [CNCF Slack](https://slack.cncf.io/) in the [#opencost](https://cloud-native.slack.com/archives/C03D56FPD4G) channel or attend the biweekly [OpenCost Working Group community meeting](https://bit.ly/opencost-meeting) from the [Community Calendar](https://bit.ly/opencost-calendar) to discuss OpenCost development.\n\n## FAQ\n\nYou can view [OpenCost documentation](https://www.opencost.io/docs/FAQ) for a list of commonly asked questions.\n",
      "stars_today": 11
    },
    {
      "id": 716719284,
      "name": "openbao",
      "full_name": "openbao/openbao",
      "description": "OpenBao exists to provide a software solution to manage, store, and distribute sensitive data including secrets, certificates, and keys.",
      "html_url": "https://github.com/openbao/openbao",
      "stars": 5213,
      "forks": 308,
      "language": "Go",
      "topics": [
        "go",
        "secret-management",
        "security"
      ],
      "created_at": "2023-11-09T18:17:33Z",
      "updated_at": "2026-01-14T01:06:13Z",
      "pushed_at": "2026-01-14T00:09:57Z",
      "open_issues": 222,
      "owner": {
        "login": "openbao",
        "avatar_url": "https://avatars.githubusercontent.com/u/152585220?v=4"
      },
      "readme": "# OpenBao\n\n\n----\n\n**Please note**: We take OpenBao's security and our users' trust very seriously. If you believe you have found a security issue in OpenBao, _please responsibly disclose_ by contacting us at [openbao-security@lists.openssf.org](mailto:openbao-security@lists.openssf.org).\n\n----\n\n[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/openbao/openbao/badge)](https://scorecard.dev/viewer/?uri=github.com/openbao/openbao) [![OpenSSF Best Practices](https://www.bestpractices.dev/projects/9126/badge)](https://www.bestpractices.dev/projects/9126)\n\n- [Website](https://www.openbao.org)\n- [Mailing List](https://lists.openssf.org/g/openbao)\n- [GitHub Discussions](https://github.com/openbao/openbao/discussions)\n- [Chat Server](https://linuxfoundation.zulipchat.com/)\n  - [`#openssf-openbao-discussion`](https://linuxfoundation.zulipchat.com/#narrow/channel/529890-openssf-openbao-discussion)\n  - [`#openssf-openbao-support`](https://linuxfoundation.zulipchat.com/#narrow/channel/530381-openssf-openbao-support)\n  - [`#openssf-openbao-tsc`](https://linuxfoundation.zulipchat.com/#narrow/channel/530382-openssf-openbao-tsc)\n  - Working Groups:\n    - [`#openssf-openbao-wg-namespaces`](https://linuxfoundation.zulipchat.com/#narrow/channel/532995-openssf-openbao-wg-namespaces)\n    - [`#openssf-openbao-wg-pkcs11`](https://linuxfoundation.zulipchat.com/#narrow/channel/532994-openssf-openbao-wg-pkcs11)\n    - [`#openssf-openbao-wg-scalability`](https://linuxfoundation.zulipchat.com/#narrow/channel/532998-openssf-openbao-wg-scalability)\n    - [`#openssf-openbao-wg-supply`](https://linuxfoundation.zulipchat.com/#narrow/channel/532999-openssf-openbao-wg-supply)\n    - [`#openssf-openbao-wg-ui`](https://linuxfoundation.zulipchat.com/#narrow/channel/532997-openssf-openbao-wg-ui)\n\n<p align=\"center\">\n  <img width=\"300\" alt=\"OpenBao Mascot\" src=\"https://raw.githubusercontent.com/openbao/artwork/main/color/openbao-color.svg\">\n</p>\n\n**OpenBao exists to provide a software solution to manage, store, and distribute sensitive data including secrets, certificates, and keys. The OpenBao community intends to provide this software under an OSI-approved open-source license, led by a community run under open governance principles.**\n\nA modern system requires access to a multitude of secrets: database credentials, API keys for external services, credentials for service-oriented architecture communication, etc. Understanding who is accessing what secrets is already very difficult and platform-specific. Adding on key rolling, secure storage, and detailed audit logs is almost impossible without a custom solution. This is where OpenBao steps in.\n\nThe key features of OpenBao are:\n\n* **Secure Secret Storage**: Arbitrary key/value secrets can be stored\n  in OpenBao. OpenBao encrypts these secrets prior to writing them to persistent\n  storage, so gaining access to the raw storage isn't enough to access\n  your secrets. OpenBao can write to disk, [PostgreSQL](https://www.postgresql.org/),\n  and more.\n\n* **Dynamic Secrets**: OpenBao can generate secrets on-demand for some\n  systems, such as AWS or SQL databases. For example, when an application\n  needs to access an S3 bucket, it asks OpenBao for credentials, and OpenBao\n  will generate an AWS keypair with valid permissions on demand. After\n  creating these dynamic secrets, OpenBao will also automatically revoke them\n  after the lease is up.\n\n* **Data Encryption**: OpenBao can encrypt and decrypt data without storing\n  it. This allows security teams to define encryption parameters and\n  developers to store encrypted data in a location such as a SQL database without\n  having to design their own encryption methods.\n\n* **Leasing and Renewal**: All secrets in OpenBao have a _lease_ associated\n  with them. At the end of the lease, OpenBao will automatically revoke that\n  secret. Clients are able to renew leases via built-in renew APIs.\n\n* **Revocation**: OpenBao has built-in support for secret revocation. OpenBao\n  can revoke not only single secrets, but a tree of secrets, for example,\n  all secrets read by a specific user, or all secrets of a particular type.\n  Revocation assists in key rolling as well as locking down systems in the\n  case of an intrusion.\n\nDocumentation, Getting Started, and Certification Exams\n-------------------------------\n\nDocumentation is available on the [OpenBao website](https://www.openbao.org/docs/).\n\nDeveloping OpenBao\n--------------------\n\nIf you wish to work on OpenBao itself or any of its built-in systems, you'll\nfirst need [Go](https://www.golang.org) installed on your machine.\n\nFor local dev first make sure Go is properly installed, including setting up a\n[GOPATH](https://golang.org/doc/code.html#GOPATH). Ensure that `$GOPATH/bin` is in\nyour path as some distributions bundle the old version of build tools. Next, clone this\nrepository. OpenBao uses [Go Modules](https://github.com/golang/go/wiki/Modules),\nso it is recommended that you clone the repository ***outside*** of the GOPATH.\nYou can then download any required build tools by bootstrapping your environment:\n\n```sh\n$ make bootstrap\n...\n```\n\nTo compile a development version of OpenBao, run `make` or `make dev`. This will\nput the OpenBao binary in the `bin` and `$GOPATH/bin` folders:\n\n```sh\n$ make dev\n...\n$ bin/bao\n...\n```\n\nTo compile a development version of OpenBao with the UI, run `make static-dist dev-ui`. This will\nput the OpenBao binary in the `bin` and `$GOPATH/bin` folders:\n\n```sh\n$ make static-dist dev-ui\n...\n$ bin/bao\n...\n```\n\nTo run tests, type `make test`. Note: this requires Docker to be installed. If\nthis exits with exit status 0, then everything is working!\n\n```sh\n$ make test\n...\n```\n\nIf you're developing a specific package, you can run tests for just that\npackage by specifying the `TEST` variable. For example below, only\n`vault` package tests will be run.\n\n```sh\n$ make test TEST=./vault\n...\n```\n\n### Importing OpenBao\n\nThis repository publishes two libraries that may be imported by other projects:\n`github.com/openbao/openbao/api/v2` and `github.com/openbao/openbao/sdk/v2`.\n\nNote that this repository also contains OpenBao (the product), and as with most Go\nprojects, OpenBao uses Go modules to manage its dependencies. The mechanism to do\nthat is the [go.mod](./go.mod) file. As it happens, the presence of that file\nalso makes it theoretically possible to import OpenBao as a dependency into other\nprojects. Some other projects have made a practice of doing so in order to take\nadvantage of testing tooling that was developed for testing OpenBao itself. This\nis not, and has never been, a supported way to use the OpenBao project. We aren't\nlikely to fix bugs relating to failure to import `github.com/openbao/openbao`\ninto your project.\n\nSee also the section \"Docker-based tests\" below.\n\n### Acceptance Tests\n\nOpenBao has comprehensive [acceptance tests](https://en.wikipedia.org/wiki/Acceptance_testing)\ncovering most of the features of the secret and auth methods.\n\nIf you're working on a feature of a secret or auth method and want to\nverify it is functioning (and also hasn't broken anything else), we recommend\nrunning the acceptance tests.\n\n**Warning:** The acceptance tests create/destroy/modify *real resources*, which\nmay incur real costs in some cases. In the presence of a bug, it is technically\npossible that broken backends could leave dangling data behind. Therefore,\nplease run the acceptance tests at your own risk. At the very least,\nwe recommend running them in their own private account for whatever backend\nyou're testing.\n\nTo run the acceptance tests, invoke `make testacc`:\n\n```sh\n$ make testacc TEST=./builtin/logical/pki\n...\n```\n\nThe `TEST` variable is required, and you should specify the folder where the\nbackend is. The `TESTARGS` variable is recommended to filter down to a specific\nresource to test, since testing all of them at once can sometimes take a very\nlong time.\n\nAcceptance tests typically require other environment variables to be set for\nthings such as access keys. The test itself should error early and tell\nyou what to set, so it is not documented here.\n\n### Docker-based Tests\n\nWe have created an experimental new testing mechanism inspired by NewTestCluster.\nAn example of how to use it:\n\n```go\nimport (\n  \"testing\"\n  \"github.com/openbao/openbao/sdk/v2/helper/testcluster/docker\"\n)\n\nfunc Test_Something_With_Docker(t *testing.T) {\n  opts := &docker.DockerClusterOptions{\n    ImageRepo: \"openbao/openbao\",\n    ImageTag:    \"latest\",\n  }\n  cluster := docker.NewTestDockerCluster(t, opts)\n  defer cluster.Cleanup()\n\n  client := cluster.Nodes()[0].APIClient()\n  _, err := client.Logical().Read(\"sys/storage/raft/configuration\")\n  if err != nil {\n    t.Fatal(err)\n  }\n}\n```\n\nHere is a more realistic example of how we use it in practice.  `DefaultOptions` uses\n`hashicorp/vault:latest` as the repo and tag, but it also looks at the environment\nvariable `BAO_BINARY`. If populated, it will copy the local file referenced by\n`BAO_BINARY` into the container. This is useful when testing local changes.\n\nOptionally you can set `COMMIT_SHA`, which will be appended to the image name we\nbuild as a debugging convenience.\n\n```go\nfunc Test_Custom_Build_With_Docker(t *testing.T) {\n  opts := docker.DefaultOptions(t)\n  cluster := docker.NewTestDockerCluster(t, opts)\n  defer cluster.Cleanup()\n}\n```\n\nFinally, here's an example of running an existing OSS docker test with a custom binary:\n\n```bash\n$ GOOS=linux make dev\n$ VAULT_BINARY=$(pwd)/bin/bao go test -run 'TestRaft_Configuration_Docker' ./vault/external_tests/raft/raft_binary\nok      github.com/openbao/openbao/vault/external_tests/raft/raft_binary        20.960s\n```\n",
      "stars_today": 11
    },
    {
      "id": 743200516,
      "name": "komikku",
      "full_name": "komikku-app/komikku",
      "description": "Free and open source manga reader for Android",
      "html_url": "https://github.com/komikku-app/komikku",
      "stars": 3082,
      "forks": 121,
      "language": "Kotlin",
      "topics": [
        "android",
        "j2k",
        "komga",
        "kotlin",
        "manga",
        "manga-downloader",
        "manga-reader",
        "mangadex",
        "mangadex-downloader",
        "mangadownloader",
        "mangareader",
        "mihon",
        "neko",
        "tachiyomi",
        "tachiyomisy"
      ],
      "created_at": "2024-01-14T16:25:54Z",
      "updated_at": "2026-01-13T16:16:57Z",
      "pushed_at": "2026-01-13T08:45:48Z",
      "open_issues": 311,
      "owner": {
        "login": "komikku-app",
        "avatar_url": "https://avatars.githubusercontent.com/u/160299335?v=4"
      },
      "readme": "<div align=\"center\">\n\n<a href=\"https://komikku-app.github.io\">\n  <img width=200px height=200px src=\"./.github/readme-images/app-icon.png\"/>\n</a><br/>\n<a href=\"https://trendshift.io/repositories/13696\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/13696\" alt=\"komikku-app%2Fkomikku | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n <h1 align=\"center\"> Komikku </h1>\n\n| Releases | Preview |\n|----------|---------|\n| <div align=\"center\"> [![GitHub downloads](https://img.shields.io/github/downloads/komikku-app/komikku/latest/total?label=Latest%20Downloads&labelColor=27303D&color=0D1117&logo=github&logoColor=FFFFFF&style=flat)](https://github.com/komikku-app/komikku/releases/latest) [![GitHub downloads](https://img.shields.io/github/downloads/komikku-app/komikku/total?label=Total%20Downloads&labelColor=27303D&color=0D1117&logo=github&logoColor=FFFFFF&style=flat)](https://github.com/komikku-app/komikku/releases) [![Stable build](https://img.shields.io/github/actions/workflow/status/komikku-app/komikku/build_release.yml?labelColor=27303D&label=Stable&labelColor=06599d&color=043b69)](https://github.com/komikku-app/komikku/actions/workflows/build_release.yml) | <div align=\"center\"> [![GitHub downloads](https://img.shields.io/github/downloads/komikku-app/komikku-preview/latest/total?label=Latest%20Downloads&labelColor=27303D&color=0D1117&logo=github&logoColor=FFFFFF&style=flat)](https://github.com/komikku-app/komikku-preview/releases/latest) [![GitHub downloads](https://img.shields.io/github/downloads/komikku-app/komikku-preview/total?label=Total%20Downloads&labelColor=27303D&color=0D1117&logo=github&logoColor=FFFFFF&style=flat)](https://github.com/komikku-app/komikku-preview/releases) [![Preview build](https://img.shields.io/github/actions/workflow/status/komikku-app/komikku-preview/build_app.yml?labelColor=27303D&label=Preview&labelColor=2c2c47&color=1c1c39)](https://github.com/komikku-app/komikku-preview/actions/workflows/build_app.yml) |\n\n*Requires Android 8.0 or higher.*\n\n[![Discord](https://img.shields.io/discord/1242381704459452488.svg?label=&labelColor=6A7EC2&color=7389D8&logo=discord&logoColor=FFFFFF)](https://discord.gg/85jB7V5AJR)\n[![CI](https://img.shields.io/github/actions/workflow/status/komikku-app/komikku/build_push.yml?labelColor=27303D&label=CI)](https://github.com/komikku-app/komikku/actions/workflows/build_push.yml)\n[![License: Apache-2.0](https://img.shields.io/github/license/komikku-app/komikku?labelColor=27303D&color=0877d2)](/LICENSE)\n[![Translation status](https://img.shields.io/weblate/progress/komikku-app?labelColor=27303D&color=946300)](https://hosted.weblate.org/engage/komikku-app/)\n\n## Download\n\n[![Stable](https://img.shields.io/github/release/komikku-app/komikku.svg?maxAge=3600&label=Stable&labelColor=06599d&color=043b69)](https://github.com/komikku-app/komikku/releases/latest)\n[![Preview](https://img.shields.io/github/v/release/komikku-app/komikku-preview.svg?maxAge=3600&label=Preview&labelColor=2c2c47&color=1c1c39)](https://github.com/komikku-app/komikku-preview/releases/latest)\n\n*Requires Android 8.0 or higher.*\n\n[![Sponsor me on GitHub](https://custom-icon-badges.demolab.com/badge/-Sponsor-ea4aaa?style=for-the-badge&logo=heart&logoColor=white)](https://github.com/sponsors/cuong-tran \"Sponsor me on GitHub\")\n\n<div align=\"left\">\nA free and open source manga reader which is based off TachiyomiSY & Mihon/Tachiyomi. This fork is meant to provide new & useful features while regularly take features/updates from Mihon or other forks like SY, J2K and Neko...\n\n![screenshots of app](./.github/readme-images/screens.png)\n\n<div align=\"left\">\n\n## Features\n\n### Komikku's unique features:\n- `Suggestions` automatically showing source-website's recommendations / suggestions / related to current entry for all sources.\n- `Hidden categories` to hide yours things from *nosy* people.\n- `Auto theme color` based on each entry's cover for entry View & Reader.\n- `App custom theme` with `Color palettes` for endless color lover.\n- `Bulk-favorite` multiple entries all at once.\n- Source & Language icon on Library & various places. (Some language flags are not really accurate)\n- `Feed` now supports **all** sources, with more items (20 for now).\n- Fast browsing (for who with large library experiencing slow loading)\n- Grouped entries in Update tab (inspired by J2K).\n- Update notification with manga cover.\n- Auto `2-way sync` progress with trackers.\n- Chips for `Saved search` in source browse\n- `Panorama cover` showing wide cover in full.\n- `Merge multiple` library entries together at same time.\n- `Range-selection` for Migration.\n- Ability to `enable/disable repo`, with icon.\n- `Update Error` screen & migrating them away.\n- `to-be-updated` screen: which entries are going to be checked with smart-update?\n- `Search for sources` & Quick NSFW sources filter in Extensions, Browse & Migration screen.\n- `Feed` backup/restore/sync/re-order.\n- Long-click to add/remove single entry to/from library, everywhere.\n- Docking Read/Resume button to left/right.\n- In-app progress banner shows Library syncing / Backup restoring / Library updating progress.\n- Auto-install app update.\n- Configurable interval to refresh entries from downloaded storage.\n- Forked from SY so everything from SY.\n- Always up-to-date with Mihon & SY\n- More app themes & better UI, improvements...\n\n\n<details>\n  <summary>Features from Mihon / Tachiyomi</summary>\n\n#### All up-to-date features from Mihon / Tachiyomi (original), include:\n\n* Online reading from a variety of sources\n* Local reading of downloaded content\n* A configurable reader with multiple viewers, reading directions and other settings.\n* Tracker support: [MyAnimeList](https://myanimelist.net/), [AniList](https://anilist.co/), [Kitsu](https://kitsu.app/), [MangaUpdates](https://mangaupdates.com), [Shikimori](https://shikimori.one), [Bangumi](https://bgm.tv/)\n* Categories to organize your library\n* Light and dark themes\n* Schedule updating your library for new chapters\n* Create backups locally to read offline or to your desired cloud service\n* Continue reading button in library\n\n</details>\n\n<details>\n  <summary>Features from Tachiyomi SY</summary>\n\n#### All features from TachiyomiSY:\n* Feed tab, where you can easily view the latest entries or saved search from multiple sources at same time.\n* Automatic webtoon detection, allowing the reader to switch to webtoon mode automatically when viewing one\n* Manga recommendations, uses MAL and Anilist, as well as Neko Similar Manga for Mangadex manga (Thanks to Az, She11Shocked, Carlos, and Goldbattle)\n* Lewd filter, hide the lewd manga in your library when you want to\n* Tracking filter, filter your tracked manga so you can see them or see non-tracked manga, made by She11Shocked\n* Search tracking status in library, made by She11Shocked\n* Custom categories for sources, liked the pinned sources, but you can make your own versions and put any sources in them\n* Manga info edit\n* Manga Cover view + share and save\n* Dynamic Categories, view the library in multiple ways\n* Smart background for reading modes like LTR or Vertical, changes the background based on the page color\n* Force disable webtoon zoom\n* Hentai features enable/disable, in advanced settings\n* Quick clean titles\n* Source migration, migrate all your manga from one source to another\n* Saving searches\n* Autoscroll\n* Page preload customization\n* Customize image cache size\n* Batch import of custom sources and featured extensions\n* Advanced source settings page, searching, enable/disable all\n* Click tag for local search, long click tag for global search\n* Merge multiple of the same manga from different sources\n* Drag and drop library sorting\n* Library search engine, includes exclude, quotes as absolute, and a bunch of other ways to search\n* New E-Hentai/ExHentai features, such as language settings and watched list settings\n* Enhanced views for internal and integrated sources\n* Enhanced usability for internal and delegated sources\n\nCustom sources:\n* E-Hentai/ExHentai\n\nAdditional features for some extensions, features include custom description, opening in app, batch add to library, and a bunch of other things based on the source:\n* 8Muses (EroMuse)\n* HBrowse\n* Mangadex\n* NHentai\n* Puruin\n* Tsumino\n\n</details>\n\n## Issues, Feature Requests and Contributing\n\nPull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.\n\n<details><summary>Issues</summary>\n\n[Website](https://komikku-app.github.io/)\n\n1. **Before reporting a new issue, take a look at the [FAQ](https://komikku-app.github.io/docs/faq/general), the [changelog](https://github.com/komikku-app/komikku/releases) and the already opened [issues](https://github.com/komikku-app/komikku/issues).**\n2. If you are unsure, ask here: [![Discord](https://img.shields.io/discord/1242381704459452488.svg?label=&labelColor=6A7EC2&color=7389D8&logo=discord&logoColor=FFFFFF)](https://discord.gg/85jB7V5AJR)\n\n</details>\n\n<details><summary>Bugs</summary>\n\n* Include version (More ‚Üí About ‚Üí Version)\n * If not latest, try updating, it may have already been solved\n * Preview version is equal to the number of commits as seen on the main page\n* Include steps to reproduce (if not obvious from description)\n* Include screenshot (if needed)\n* If it could be device-dependent, try reproducing on another device (if possible)\n* Don't group unrelated requests into one issue\n\nUse the [issue forms](https://github.com/komikku-app/komikku/issues/new/choose) to submit a bug.\n\n</details>\n\n<details><summary>Feature Requests</summary>\n\n* Write a detailed issue, explaining what it should do or how.\n* Include screenshot (if needed).\n</details>\n\n<details><summary>Contributing</summary>\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md).\n</details>\n\n<details><summary>Code of Conduct</summary>\n\nSee [CODE_OF_CONDUCT.md](./CODE_OF_CONDUCT.md).\n</details>\n\n<div align=\"center\">\n\n### Credits\n\nThank you to all the people who have contributed!\n\n<a href=\"https://github.com/komikku-app/komikku/graphs/contributors\">\n    <img src=\"https://contrib.rocks/image?repo=komikku-app/komikku\" alt=\"Komikku app contributors\" title=\"Komikku app contributors\" width=\"800\"/>\n</a>\n\n![Visitor Count](https://count.getloli.com/get/@komikku-app?theme=capoo-2)\n\n### Disclaimer\n\nThe developer(s) of this application does not have any affiliation with the content providers available, and this application hosts zero content.\n\n<div align=\"left\">\n\n## License\n\n    Copyright 2015 Javier Tom√°s\n\n    Licensed under the Apache License, Version 2.0 (the \"License\");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n",
      "stars_today": 11
    },
    {
      "id": 1103607,
      "name": "jenkins",
      "full_name": "jenkinsci/jenkins",
      "description": "Jenkins automation server",
      "html_url": "https://github.com/jenkinsci/jenkins",
      "stars": 24892,
      "forks": 9311,
      "language": "Java",
      "topics": [
        "cicd",
        "continuous-delivery",
        "continuous-deployment",
        "continuous-integration",
        "devops",
        "groovy",
        "hacktoberfest",
        "java",
        "jenkins",
        "pipelines-as-code"
      ],
      "created_at": "2010-11-22T21:21:23Z",
      "updated_at": "2026-01-13T21:29:33Z",
      "pushed_at": "2026-01-14T00:12:38Z",
      "open_issues": 3544,
      "owner": {
        "login": "jenkinsci",
        "avatar_url": "https://avatars.githubusercontent.com/u/107424?v=4"
      },
      "readme": "<a href=\"https://jenkins.io\">\n    <img width=\"400\" src=\"https://www.jenkins.io/images/jenkins-logo-title-dark.svg\" alt=\"Jenkins logo\"> \n</a>\n\n[![Jenkins Regular Release](https://img.shields.io/endpoint?url=https%3A%2F%2Fwww.jenkins.io%2Fchangelog%2Fbadge.json)](https://www.jenkins.io/changelog)\n[![Jenkins LTS Release](https://img.shields.io/endpoint?url=https%3A%2F%2Fwww.jenkins.io%2Fchangelog-stable%2Fbadge.json)](https://www.jenkins.io/changelog-stable)\n[![Docker Pulls](https://img.shields.io/docker/pulls/jenkins/jenkins.svg)](https://hub.docker.com/r/jenkins/jenkins/)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/3538/badge)](https://bestpractices.coreinfrastructure.org/projects/3538)\n[![Reproducible Builds](https://img.shields.io/badge/Reproducible_Builds-ok-green)](https://maven.apache.org/guides/mini/guide-reproducible-builds.html)\n[![Gitter](https://img.shields.io/gitter/room/jenkinsci/jenkins)](https://app.gitter.im/#/room/#jenkinsci_jenkins:gitter.im)\n\n---\n\n# Table of Contents\n\n- [About](#about)\n- [What to Use Jenkins for and When to Use It](#what-to-use-jenkins-for-and-when-to-use-it)\n- [Downloads](#downloads)\n- [Getting Started (Development)](#getting-started-development)\n- [Source](#source)\n- [Contributing to Jenkins](#contributing-to-jenkins)\n- [News and Website](#news-and-website)\n- [Governance](#governance)\n- [Adopters](#adopters)\n- [License](#license)\n\n---\n\n# About\n\nIn a nutshell, Jenkins is the leading open-source automation server.\nBuilt with Java, it provides over 2,000 [plugins](https://plugins.jenkins.io/) to support automating virtually anything,\nso that humans can spend their time doing things machines cannot.\n\n# What to Use Jenkins for and When to Use It\n\nUse Jenkins to automate your development workflow, so you can focus on work that matters most. Jenkins is commonly used for:\n\n- Building projects\n- Running tests to detect bugs and other issues as soon as they are introduced\n- Static code analysis\n- Deployment\n\nExecute repetitive tasks, save time, and optimize your development process with Jenkins.\n\n# Downloads\n\nThe Jenkins project provides official distributions as WAR files, Docker images, native packages and installers for platforms including several Linux distributions and Windows.\nSee the [Downloads](https://www.jenkins.io/download) page for references.\n\nFor all distributions Jenkins offers two release lines:\n\n- [Weekly](https://www.jenkins.io/download/weekly/) -\n  Frequent releases which include all new features, improvements, and bug fixes.\n- [Long-Term Support (LTS)](https://www.jenkins.io/download/lts/) -\n  Older release line which gets periodically updated via bug fix backports.\n\nLatest releases:\n\n[![Jenkins Regular Release](https://img.shields.io/endpoint?url=https%3A%2F%2Fwww.jenkins.io%2Fchangelog%2Fbadge.json)](https://www.jenkins.io/changelog)\n[![Jenkins LTS Release](https://img.shields.io/endpoint?url=https%3A%2F%2Fwww.jenkins.io%2Fchangelog-stable%2Fbadge.json)](https://www.jenkins.io/changelog-stable)\n\n# Getting Started (Development)\n\nFor more information on setting up your development environment, contributing, and working with Jenkins internals, check the [contributing guide](CONTRIBUTING.md) and the [Jenkins Developer Documentation](https://www.jenkins.io/doc/developer/).\n\n# Source\n\nOur latest and greatest source of Jenkins can be found on [GitHub](https://github.com/jenkinsci/jenkins). Fork us!\n\n# Contributing to Jenkins\n\nNew to open source or Jenkins? Here‚Äôs how to get started:\n\n- Read the [Contribution Guidelines](CONTRIBUTING.md)\n- Check our [good first issues](https://github.com/jenkinsci/jenkins/issues?q=is%3Aissue%20is%3Aopen%20label%3A%22good%20first%20issue%22)\n- Join our [Gitter chat](https://app.gitter.im/#/room/#jenkinsci_newcomer-contributors:gitter.im) for questions and help\n\nFor more information about participating in the community and contributing to the Jenkins project,\nsee [this page](https://www.jenkins.io/participate/).\n\nDocumentation for Jenkins core maintainers is in the [maintainers guidelines](docs/MAINTAINERS.adoc).\n\n# News and Website\n\nAll information about Jenkins can be found on our [official website](https://www.jenkins.io/), including documentation, blog posts, plugin listings, community updates, and more.\n\nStay up-to-date with the latest Jenkins news, tutorials, and release notes:\n\n- [Jenkins Blog](https://www.jenkins.io/blog/)\n- [Documentation](https://www.jenkins.io/doc/)\n- [Plugins Index](https://plugins.jenkins.io/)\n- [Events](https://www.jenkins.io/events/)\n\nFollow Jenkins on social media to stay connected with the community:\n\n- [Twitter / X](https://x.com/jenkinsci)\n- [YouTube](https://www.youtube.com/@jenkinscicd)\n- [LinkedIn](https://www.linkedin.com/company/jenkins-project/)\n\n# Governance\n\nThe Jenkins project is governed by an open source community.\nTo learn more about the governance structure, project leadership, and how decisions are made, visit the [Governance Page](https://www.jenkins.io/project/governance/).\n\n# Adopters\n\nJenkins is trusted by **millions of users** and adopted by **thousands of companies** around the world ‚Äî from startups to enterprises ‚Äî to automate their software delivery pipelines.\n\nExplore the [Adopters Page](https://www.jenkins.io/project/adopters/) and https://stories.jenkins.io to see:\n\n- Companies and organizations using Jenkins\n- Success stories and case studies\n- How Jenkins is used in different industries\n\n> If your company uses Jenkins and you'd like to be featured, feel free to [submit your story](https://www.jenkins.io/project/adopters/contributing/#share-your-story)!\n\n# License\n\nJenkins is **licensed** under the **[MIT License](LICENSE.txt)**.\n",
      "stars_today": 10
    },
    {
      "id": 65899476,
      "name": "esp-idf",
      "full_name": "espressif/esp-idf",
      "description": "Espressif IoT Development Framework. Official development framework for Espressif SoCs.",
      "html_url": "https://github.com/espressif/esp-idf",
      "stars": 17065,
      "forks": 8061,
      "language": "C",
      "topics": [],
      "created_at": "2016-08-17T10:40:35Z",
      "updated_at": "2026-01-13T22:59:21Z",
      "pushed_at": "2026-01-14T00:16:56Z",
      "open_issues": 1516,
      "owner": {
        "login": "espressif",
        "avatar_url": "https://avatars.githubusercontent.com/u/9460735?v=4"
      },
      "readme": "# Espressif IoT Development Framework\n\n* [‰∏≠ÊñáÁâà](./README_CN.md)\n\nESP-IDF is the development framework for Espressif SoCs supported on Windows, Linux and macOS.\n\n# ESP-IDF Release Support Schedule\n\n![Support Schedule](https://dl.espressif.com/dl/esp-idf/support-periods.svg?v=1)\n\n- Please read [the support policy](SUPPORT_POLICY.md) and [the documentation](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/versions.html) for more information about ESP-IDF versions.\n- Please see the [End-of-Life Advisories](https://www.espressif.com/en/support/documents/advisories?keys=&field_type_of_advisory_tid%5B%5D=817) for information about ESP-IDF releases with discontinued support.\n\n# ESP-IDF Release and SoC Compatibility\n\n![Chip support](https://dl.espressif.com/dl/esp-idf/chip-support.svg?v=1)\n\nSee [Compatibility Between ESP-IDF Releases and Revisions of Espressif SoCs](https://github.com/espressif/esp-idf/blob/master/COMPATIBILITY.md) for the details of the compatibility between ESP-IDF and chip revisions.\n\nEspressif SoCs released before 2016 (ESP8266 and ESP8285) are supported by [RTOS SDK](https://github.com/espressif/ESP8266_RTOS_SDK) instead.\n\n# Developing With ESP-IDF\n\n## Setting Up ESP-IDF\n\nSee https://idf.espressif.com/ for links to detailed instructions on how to set up the ESP-IDF depending on chip you use.\n\n**Note:** Each SoC series and each ESP-IDF release has its own documentation. Please see Section [Versions](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/versions.html) on how to find documentation and how to checkout specific release of ESP-IDF.\n\n### Non-GitHub forks\n\nESP-IDF uses relative locations as its submodules URLs ([.gitmodules](.gitmodules)). So they link to GitHub. If ESP-IDF is forked to a Git repository which is not on GitHub, you will need to run the script [tools/set-submodules-to-github.sh](tools/set-submodules-to-github.sh) after git clone.\n\nThe script sets absolute URLs for all submodules, allowing `git submodule update --init --recursive` to complete. If cloning ESP-IDF from GitHub, this step is not needed.\n\n## Finding a Project\n\nAs well as the [esp-idf-template](https://github.com/espressif/esp-idf-template) project mentioned in Getting Started, ESP-IDF comes with some example projects in the [examples](examples) directory.\n\nOnce you've found the project you want to work with, change to its directory and you can configure and build it.\n\nTo start your own project based on an example, copy the example project directory outside of the ESP-IDF directory.\n\n# Quick Reference\n\nSee the Getting Started guide links above for a detailed setup guide. This is a quick reference for common commands when working with ESP-IDF projects:\n\n## Setup Build Environment\n\n(See the Getting Started guide listed above for a full list of required steps with more details.)\n\n* Install host build dependencies mentioned in the Getting Started guide.\n* Run the install script to set up the build environment. The options include `install.bat` or `install.ps1` for Windows, and `install.sh` or `install.fish` for Unix shells.\n* Run the export script on Windows (`export.bat`) or source it on Unix (`source export.sh`) in every shell environment before using ESP-IDF.\n\n## Configuring the Project\n\n* `idf.py set-target <chip_name>` sets the target of the project to `<chip_name>`. Run `idf.py set-target` without any arguments to see a list of supported targets.\n* `idf.py menuconfig` opens a text-based configuration menu where you can configure the project.\n\n## Compiling the Project\n\n`idf.py build`\n\n... will compile app, bootloader and generate a partition table based on the config.\n\n## Flashing the Project\n\nWhen the build finishes, it will print a command line to use `esptool` to flash the chip. However you can also do this automatically by running:\n\n`idf.py -p PORT flash`\n\nReplace PORT with the name of your serial port (like `COM3` on Windows, `/dev/ttyUSB0` on Linux, or `/dev/cu.usbserial-X` on MacOS. If the `-p` option is left out, `idf.py flash` will try to flash the first available serial port.\n\nThis will flash the entire project (app, bootloader and partition table) to a new chip. The settings for serial port flashing can be configured with `idf.py menuconfig`.\n\nYou don't need to run `idf.py build` before running `idf.py flash`, `idf.py flash` will automatically rebuild anything which needs it.\n\n## Viewing Serial Output\n\nThe `idf.py monitor` target uses the [esp-idf-monitor tool](https://github.com/espressif/esp-idf-monitor) to display serial output from Espressif SoCs. esp-idf-monitor also has a range of features to decode crash output and interact with the device. [Check the documentation page for details](https://docs.espressif.com/projects/esp-idf/en/latest/get-started/idf-monitor.html).\n\nExit the monitor by typing Ctrl-].\n\nTo build, flash and monitor output in one pass, you can run:\n\n`idf.py flash monitor`\n\n## Compiling & Flashing Only the App\n\nAfter the initial flash, you may just want to build and flash just your app, not the bootloader and partition table:\n\n* `idf.py app` - build just the app.\n* `idf.py app-flash` - flash just the app.\n\n`idf.py app-flash` will automatically rebuild the app if any source files have changed.\n\n(In normal development there's no downside to reflashing the bootloader and partition table each time, if they haven't changed.)\n\n## Erasing Flash\n\nThe `idf.py flash` target does not erase the entire flash contents. However it is sometimes useful to set the device back to a totally erased state, particularly when making partition table changes or OTA app updates. To erase the entire flash, run `idf.py erase-flash`.\n\nThis can be combined with other targets, ie `idf.py -p PORT erase-flash flash` will erase everything and then re-flash the new app, bootloader and partition table.\n\n# Resources\n\n* Documentation for the latest version: https://docs.espressif.com/projects/esp-idf/. This documentation is built from the [docs directory](docs) of this repository.\n\n* [Beginner's Guide to Key Concepts and Resources of ESP-IDF](https://youtu.be/J8zc8mMNKtc?feature=shared)\n\n* The [esp32.com forum](https://esp32.com/) is a place to ask questions and find community resources.\n\n* [Check the Issues section on github](https://github.com/espressif/esp-idf/issues) if you find a bug or have a feature request. Please check existing Issues before opening a new one.\n\n* If you're interested in contributing to ESP-IDF, please check the [Contributions Guide](https://docs.espressif.com/projects/esp-idf/en/latest/contribute/index.html).\n",
      "stars_today": 10
    },
    {
      "id": 598164,
      "name": "noVNC",
      "full_name": "novnc/noVNC",
      "description": "VNC client web application",
      "html_url": "https://github.com/novnc/noVNC",
      "stars": 13311,
      "forks": 2554,
      "language": "JavaScript",
      "topics": [
        "arraybuffer",
        "html",
        "html-canvas",
        "html5",
        "javascript",
        "modern-browsers",
        "novnc",
        "vnc-client",
        "websockets",
        "websockify",
        "wss"
      ],
      "created_at": "2010-04-07T01:55:44Z",
      "updated_at": "2026-01-13T22:15:19Z",
      "pushed_at": "2026-01-10T23:45:47Z",
      "open_issues": 102,
      "owner": {
        "login": "novnc",
        "avatar_url": "https://avatars.githubusercontent.com/u/24572588?v=4"
      },
      "readme": "## noVNC: HTML VNC client library and application\n\n[![Test Status](https://github.com/novnc/noVNC/workflows/Test/badge.svg)](https://github.com/novnc/noVNC/actions?query=workflow%3ATest)\n[![Lint Status](https://github.com/novnc/noVNC/workflows/Lint/badge.svg)](https://github.com/novnc/noVNC/actions?query=workflow%3ALint)\n\n### Description\n\nnoVNC is both a HTML VNC client JavaScript library and an application built on\ntop of that library. noVNC runs well in any modern browser including mobile\nbrowsers (iOS and Android).\n\nMany companies, projects and products have integrated noVNC including\n[OpenStack](http://www.openstack.org),\n[OpenNebula](http://opennebula.org/),\n[LibVNCServer](http://libvncserver.sourceforge.net), and\n[ThinLinc](https://cendio.com/thinlinc). See\n[the Projects and companies wiki page](https://github.com/novnc/noVNC/wiki/Projects-and-companies-using-noVNC)\nfor a more complete list with additional info and links.\n\n### Table of contents\n\n- [News/help/contact](#newshelpcontact)\n- [Features](#features)\n- [Screenshots](#screenshots)\n- [Browser requirements](#browser-requirements)\n- [Server requirements](#server-requirements)\n- [Quick start](#quick-start)\n- [Installation from snap package](#installation-from-snap-package)\n- [Integration and deployment](#integration-and-deployment)\n- [Authors/Contributors](#authorscontributors)\n\n### News/help/contact\n\nThe project website is found at [novnc.com](http://novnc.com).\n\nIf you are a noVNC developer/integrator/user (or want to be) please join the\n[noVNC discussion group](https://groups.google.com/forum/?fromgroups#!forum/novnc).\n\nBugs and feature requests can be submitted via\n[github issues](https://github.com/novnc/noVNC/issues). If you have questions\nabout using noVNC then please first use the\n[discussion group](https://groups.google.com/forum/?fromgroups#!forum/novnc).\nWe also have a [wiki](https://github.com/novnc/noVNC/wiki/) with lots of\nhelpful information.\n\nIf you are looking for a place to start contributing to noVNC, a good place to\nstart would be the issues that are marked as\n[\"patchwelcome\"](https://github.com/novnc/noVNC/issues?labels=patchwelcome).\nPlease check our\n[contribution guide](https://github.com/novnc/noVNC/wiki/Contributing) though.\n\nIf you want to show appreciation for noVNC you could donate to a great non-\nprofits such as:\n[Compassion International](http://www.compassion.com/),\n[SIL](http://www.sil.org),\n[Habitat for Humanity](http://www.habitat.org),\n[Electronic Frontier Foundation](https://www.eff.org/),\n[Against Malaria Foundation](http://www.againstmalaria.com/),\n[Nothing But Nets](http://www.nothingbutnets.net/), etc.\n\n\n### Features\n\n* Supports all modern browsers including mobile (iOS, Android)\n* Supported authentication methods: none, classical VNC, RealVNC's\n  RSA-AES, Tight, VeNCrypt Plain, XVP, Apple's Diffie-Hellman,\n  UltraVNC's MSLogonII\n* Supported VNC encodings: raw, copyrect, rre, hextile, tight, tightPNG,\n  ZRLE, JPEG, Zlib, H.264\n* Supports scaling, clipping and resizing the desktop\n* Supports back & forward mouse buttons\n* Local cursor rendering\n* Clipboard copy/paste with full Unicode support\n* Translations\n* Touch gestures for emulating common mouse actions\n* Licensed mainly under the [MPL 2.0](http://www.mozilla.org/MPL/2.0/), see\n  [the license document](LICENSE.txt) for details\n\n### Screenshots\n\nRunning in Firefox before and after connecting:\n\n<img src=\"http://novnc.com/img/noVNC-1-login.png\" width=400>&nbsp;\n<img src=\"http://novnc.com/img/noVNC-3-connected.png\" width=400>\n\nSee more screenshots\n[here](http://novnc.com/screenshots.html).\n\n\n### Browser requirements\n\nnoVNC uses many modern web technologies so a formal requirement list is\nnot available. However these are the minimum versions we are currently\naware of:\n\n* Chrome 89, Firefox 89, Safari 15, Opera 75, Edge 89\n\n\n### Server requirements\n\nnoVNC follows the standard VNC protocol, but unlike other VNC clients it does\nrequire WebSockets support. Many servers include support (e.g.\n[x11vnc/libvncserver](http://libvncserver.sourceforge.net/),\n[QEMU](http://www.qemu.org/), and\n[MobileVNC](http://www.smartlab.at/mobilevnc/)), but for the others you need to\nuse a WebSockets to TCP socket proxy. noVNC has a sister project\n[websockify](https://github.com/novnc/websockify) that provides a simple such\nproxy.\n\n\n### Quick start\n\n* Use the `novnc_proxy` script to automatically download and start websockify, which\n  includes a mini-webserver and the WebSockets proxy. The `--vnc` option is\n  used to specify the location of a running VNC server:\n\n    `./utils/novnc_proxy --vnc localhost:5901`\n    \n* If you don't need to expose the web server to public internet, you can\n  bind to localhost:\n  \n    `./utils/novnc_proxy --vnc localhost:5901 --listen localhost:6081`\n\n* Point your browser to the cut-and-paste URL that is output by the `novnc_proxy`\n  script. Hit the Connect button, enter a password if the VNC server has one\n  configured, and enjoy!\n\n### Installation from snap package\nRunning the command below will install the latest release of noVNC from snap:\n\n`sudo snap install novnc`\n\n#### Running noVNC from snap directly\n\nYou can run the snap package installed novnc directly with, for example:\n\n`novnc --listen 6081 --vnc localhost:5901 # /snap/bin/novnc if /snap/bin is not in your PATH`\n\nIf you want to use certificate files, due to standard snap confinement restrictions you need to have them in the /home/\\<user\\>/snap/novnc/current/ directory. If your username is jsmith an example command would be:\n  \n  `novnc --listen 8443 --cert ~jsmith/snap/novnc/current/self.crt --key ~jsmith/snap/novnc/current/self.key --vnc ubuntu.example.com:5901`\n\n#### Running noVNC from snap as a service (daemon)\nThe snap package also has the capability to run a 'novnc' service which can be\nconfigured to listen on multiple ports connecting to multiple VNC servers \n(effectively a service running multiple instances of novnc).\nInstructions (with example values):\n\nList current services (out-of-box this will be blank):\n\n```\nsudo snap get novnc services\nKey             Value\nservices.n6080  {...}\nservices.n6081  {...}\n```\n\nCreate a new service that listens on port 6082 and connects to the VNC server \nrunning on port 5902 on localhost:\n\n`sudo snap set novnc services.n6082.listen=6082 services.n6082.vnc=localhost:5902`\n\n(Any services you define with 'snap set' will be automatically started)\nNote that the name of the service, 'n6082' in this example, can be anything \nas long as it doesn't start with a number or contain spaces/special characters.\n\nView the configuration of the service just created:\n\n```\nsudo snap get novnc services.n6082\nKey                    Value\nservices.n6082.listen  6082\nservices.n6082.vnc     localhost:5902\n```\n\nDisable a service (note that because of a limitation in snap it's currently not\npossible to unset config variables, setting them to blank values is the way \nto disable a service):\n\n`sudo snap set novnc services.n6082.listen='' services.n6082.vnc=''`\n\n(Any services you set to blank with 'snap set' like this will be automatically stopped)\n\nVerify that the service is disabled (blank values):\n\n```\nsudo snap get novnc services.n6082\nKey                    Value\nservices.n6082.listen  \nservices.n6082.vnc\n```\n\n### Integration and deployment\n\nPlease see our other documents for how to integrate noVNC in your own software,\nor deploying the noVNC application in production environments:\n\n* [Embedding](docs/EMBEDDING.md) - For the noVNC application\n* [Library](docs/LIBRARY.md) - For the noVNC JavaScript library\n\n\n### Authors/Contributors\n\nSee [AUTHORS](AUTHORS) for a (full-ish) list of authors.  If you're not on\nthat list and you think you should be, feel free to send a PR to fix that.\n\n* Core team:\n    * [Samuel Mannehed](https://github.com/samhed) (Cendio)\n    * [Pierre Ossman](https://github.com/CendioOssman) (Cendio)\n\n* Previous core contributors:\n    * [Joel Martin](https://github.com/kanaka) (Project founder)\n    * [Solly Ross](https://github.com/DirectXMan12) (Red Hat / OpenStack)\n\n* Notable contributions:\n    * UI and icons : Pierre Ossman, Chris Gordon\n    * Original logo : Michael Sersen\n    * tight encoding : Michael Tinglof (Mercuri.ca)\n    * RealVNC RSA AES authentication : USTC Vlab Team\n\n* Included libraries:\n    * base64 : Martijn Pieters (Digital Creations 2), Samuel Sieb (sieb.net)\n    * DES : Dave Zimmerman (Widget Workshop), Jef Poskanzer (ACME Labs)\n    * Pako : Vitaly Puzrin (https://github.com/nodeca/pako)\n\nDo you want to be on this list? Check out our\n[contribution guide](https://github.com/novnc/noVNC/wiki/Contributing) and\nstart hacking!\n",
      "stars_today": 10
    },
    {
      "id": 230595891,
      "name": "sqlx",
      "full_name": "launchbadge/sqlx",
      "description": "üß∞ The Rust SQL Toolkit. An async, pure Rust SQL crate featuring compile-time checked queries without a DSL. Supports PostgreSQL, MySQL, and SQLite.",
      "html_url": "https://github.com/launchbadge/sqlx",
      "stars": 16336,
      "forks": 1542,
      "language": "Rust",
      "topics": [
        "async",
        "await",
        "mariadb",
        "mysql",
        "postgres",
        "postgresql",
        "rust",
        "sql",
        "sqlite"
      ],
      "created_at": "2019-12-28T10:40:57Z",
      "updated_at": "2026-01-14T00:30:53Z",
      "pushed_at": "2026-01-05T03:24:48Z",
      "open_issues": 728,
      "owner": {
        "login": "launchbadge",
        "avatar_url": "https://avatars.githubusercontent.com/u/10077001?v=4"
      },
      "readme": "<h1 align=\"center\">SQLx</h1>\n<div align=\"center\">\n <strong>\n   üß∞ The Rust SQL Toolkit\n </strong>\n</div>\n\n<br />\n\n<div align=\"center\">\n  <!-- Github Actions -->\n  <a href=\"https://github.com/launchbadge/sqlx/actions/workflows/sqlx.yml?query=branch%3Amain\">\n    <img src=\"https://img.shields.io/github/actions/workflow/status/launchbadge/sqlx/sqlx.yml?branch=main&style=flat-square\" alt=\"actions status\" /></a>\n  <!-- Version -->\n  <a href=\"https://crates.io/crates/sqlx\">\n    <img src=\"https://img.shields.io/crates/v/sqlx.svg?style=flat-square\"\n    alt=\"Crates.io version\" /></a>\n  <!-- Discord -->\n  <a href=\"https://discord.gg/uuruzJ7\">\n  <img src=\"https://img.shields.io/discord/665528275556106240?style=flat-square\" alt=\"chat\" /></a>\n  <!-- Docs -->\n  <a href=\"https://docs.rs/sqlx\">\n  <img src=\"https://img.shields.io/badge/docs-latest-blue.svg?style=flat-square\" alt=\"docs.rs docs\" /></a>\n  <!-- Downloads -->\n  <a href=\"https://crates.io/crates/sqlx\">\n    <img src=\"https://img.shields.io/crates/d/sqlx.svg?style=flat-square\" alt=\"Download\" />\n  </a>\n</div>\n\n<div align=\"center\">\n  <h4>\n    <a href=\"#install\">\n      Install\n    </a>\n    <span> | </span>\n    <a href=\"#usage\">\n      Usage\n    </a>\n    <span> | </span>\n    <a href=\"https://docs.rs/sqlx\">\n      Docs\n    </a>\n    <span> | </span>\n    <a href=\"https://github.com/launchbadge/sqlx/wiki/Ecosystem\">\n      Ecosystem\n    </a>    \n    <span> | </span>\n    <a href=\"https://discord.gg/uuruzJ7\">\n      Discord\n    </a>\n  </h4>\n</div>\n\n<br />\n\n<div align=\"center\">\n  <small>Built with ‚ù§Ô∏è by <a href=\"https://launchbadge.com\">The LaunchBadge team</a></small>\n</div>\n\n<br />\n\n<div align=\"center\">\n    <h5>Have a question? Be sure to <a href=\"FAQ.md\">check the FAQ first!</a></h5>\n</div>\n\n<br />\n\nSQLx is an async, pure Rust<sub>‚Ä†</sub> SQL crate featuring compile-time checked queries without a DSL.\n\n-   **Truly Asynchronous**. Built from the ground-up using async/await for maximum concurrency.\n\n-   **Compile-time checked queries** (if you want). See [SQLx is not an ORM](#sqlx-is-not-an-orm).\n\n-   **Database Agnostic**. Support for [PostgreSQL], [MySQL], [MariaDB], [SQLite].\n    -   [MSSQL] was supported prior to version 0.7, but has been removed pending a full rewrite of the driver as part of our [SQLx Pro initiative].\n\n-   **Pure Rust**. The Postgres and MySQL/MariaDB drivers are written in pure Rust using **zero** unsafe<sub>‚Ä†‚Ä†</sub> code.\n\n-   **Runtime Agnostic**. Works on different runtimes ([`async-std`] / [`tokio`] / [`actix`]) and TLS backends ([`native-tls`], [`rustls`]).\n\n<small><small>\n\n‚Ä† The SQLite driver uses the libsqlite3 C library as SQLite is an embedded database (the only way\nwe could be pure Rust for SQLite is by porting _all_ of SQLite to Rust).\n\n‚Ä†‚Ä† SQLx uses `#![forbid(unsafe_code)]` unless the `sqlite` feature is enabled.\nThe SQLite driver directly invokes the SQLite3 API via `libsqlite3-sys`, which requires `unsafe`.\n\n</small></small>\n\n[postgresql]: http://postgresql.org/\n[sqlite]: https://sqlite.org/\n[mysql]: https://www.mysql.com/\n[mariadb]: https://www.mariadb.org/\n[mssql]: https://www.microsoft.com/en-us/sql-server\n[SQLx Pro initiative]: https://github.com/launchbadge/sqlx/discussions/1616\n\n---\n\n-   Cross-platform. Being native Rust, SQLx will compile anywhere Rust is supported.\n\n-   Built-in connection pooling with `sqlx::Pool`.\n\n-   Row streaming. Data is read asynchronously from the database and decoded on demand.\n\n-   Automatic statement preparation and caching. When using the high-level query API (`sqlx::query`), statements are\n    prepared and cached per connection.\n\n-   Simple (unprepared) query execution including fetching results into the same `Row` types used by\n    the high-level API. Supports batch execution and returns results from all statements.\n\n-   Transport Layer Security (TLS) where supported ([MySQL], [MariaDB] and [PostgreSQL]).\n\n-   Asynchronous notifications using `LISTEN` and `NOTIFY` for [PostgreSQL].\n\n-   Nested transactions with support for save points.\n\n-   `Any` database driver for changing the database driver at runtime. An `AnyPool` connects to the driver indicated by the URL scheme.\n\n## Install\n\nSQLx is compatible with the [`async-std`], [`tokio`], and [`actix`] runtimes; and, the [`native-tls`] and [`rustls`] TLS backends. When adding the dependency, you must choose a runtime feature that is `runtime` + `tls`.\n\n[`async-std`]: https://github.com/async-rs/async-std\n[`tokio`]: https://github.com/tokio-rs/tokio\n[`actix`]: https://github.com/actix/actix-net\n[`native-tls`]: https://crates.io/crates/native-tls\n[`rustls`]: https://crates.io/crates/rustls\n\n```toml\n# Cargo.toml\n[dependencies]\n# PICK ONE OF THE FOLLOWING:\n\n# tokio (no TLS)\nsqlx = { version = \"0.8\", features = [ \"runtime-tokio\" ] }\n# tokio + native-tls\nsqlx = { version = \"0.8\", features = [ \"runtime-tokio\", \"tls-native-tls\" ] }\n# tokio + rustls with ring and WebPKI CA certificates\nsqlx = { version = \"0.8\", features = [ \"runtime-tokio\", \"tls-rustls-ring-webpki\" ] }\n# tokio + rustls with ring and platform's native CA certificates\nsqlx = { version = \"0.8\", features = [ \"runtime-tokio\", \"tls-rustls-ring-native-roots\" ] }\n# tokio + rustls with aws-lc-rs\nsqlx = { version = \"0.8\", features = [ \"runtime-tokio\", \"tls-rustls-aws-lc-rs\" ] }\n\n# async-std (no TLS)\nsqlx = { version = \"0.8\", features = [ \"runtime-async-std\" ] }\n# async-std + native-tls\nsqlx = { version = \"0.8\", features = [ \"runtime-async-std\", \"tls-native-tls\" ] }\n# async-std + rustls with ring and WebPKI CA certificates\nsqlx = { version = \"0.8\", features = [ \"runtime-async-std\", \"tls-rustls-ring-webpki\" ] }\n# async-std + rustls with ring and platform's native CA certificates\nsqlx = { version = \"0.8\", features = [ \"runtime-async-std\", \"tls-rustls-ring-native-roots\" ] }\n# async-std + rustls with aws-lc-rs\nsqlx = { version = \"0.8\", features = [ \"runtime-async-std\", \"tls-rustls-aws-lc-rs\" ] }\n```\n\n#### Cargo Feature Flags\n\nFor backward-compatibility reasons, the runtime and TLS features can either be chosen together as a single feature,\nor separately.\n\nFor forward compatibility, you should use the separate runtime and TLS features as the combination features may\nbe removed in the future.\n\n-   `runtime-async-std`: Use the `async-std` runtime without enabling a TLS backend.\n\n-   `runtime-tokio`: Use the `tokio` runtime without enabling a TLS backend.\n\n    - Actix-web is fully compatible with Tokio and so a separate runtime feature is no longer needed.\n\n-   `tls-native-tls`: Use the `native-tls` TLS backend (OpenSSL on *nix, SChannel on Windows, Secure Transport on macOS).\n\n-   `tls-rustls`: Use the `rustls` TLS backend (cross-platform backend, only supports TLS 1.2 and 1.3).\n\n-   `postgres`: Add support for the Postgres database server.\n\n-   `mysql`: Add support for the MySQL/MariaDB database server.\n\n-   `mssql`: Add support for the MSSQL database server.\n\n-   `sqlite`: Add support for the self-contained [SQLite](https://sqlite.org/) database engine with SQLite bundled and statically-linked.\n\n-   `sqlite-unbundled`: The same as above (`sqlite`), but link SQLite from the system instead of the bundled version.\n    * Allows updating SQLite independently of SQLx or using forked versions.\n    * You must have SQLite installed on the system or provide a path to the library at build time.\n       See [the `rusqlite` README](https://github.com/rusqlite/rusqlite?tab=readme-ov-file#notes-on-building-rusqlite-and-libsqlite3-sys) for details.\n    * May result in link errors if the SQLite version is too old. Version `3.20.0` or newer is recommended.\n    * Can increase build time due to the use of bindgen.\n\n-   `sqlite-preupdate-hook`: enables SQLite's [preupdate hook](https://sqlite.org/c3ref/preupdate_count.html) API.\n    * Exposed as a separate feature because it's generally not enabled by default.\n    * Using this feature with `sqlite-unbundled` may cause linker failures if the system SQLite version does not support it.\n\n-   `any`: Add support for the `Any` database driver, which can proxy to a database driver at runtime.\n\n-   `derive`: Add support for the derive family macros, those are `FromRow`, `Type`, `Encode`, `Decode`.\n\n-   `macros`: Add support for the `query*!` macros, which allows compile-time checked queries.\n\n-   `migrate`: Add support for the migration management and `migrate!` macro, which allow compile-time embedded migrations.\n\n-   `uuid`: Add support for UUID.\n\n-   `chrono`: Add support for date and time types from `chrono`.\n\n-   `time`: Add support for date and time types from `time` crate (alternative to `chrono`, which is preferred by `query!` macro, if both enabled)\n\n-   `bstr`: Add support for `bstr::BString`.\n\n-   `bigdecimal`: Add support for `NUMERIC` using the `bigdecimal` crate.\n\n-   `rust_decimal`: Add support for `NUMERIC` using the `rust_decimal` crate.\n\n-   `ipnet`: Add support for `INET` and `CIDR` (in postgres) using the `ipnet` crate.\n\n-   `ipnetwork`: Add support for `INET` and `CIDR` (in postgres) using the `ipnetwork` crate.\n\n-   `json`: Add support for `JSON` and `JSONB` (in postgres) using the `serde_json` crate.\n\n-   Offline mode is now always enabled. See [sqlx-cli/README.md][readme-offline].\n\n[readme-offline]: sqlx-cli/README.md#enable-building-in-offline-mode-with-query\n\n## SQLx is not an ORM!\n\nSQLx supports **compile-time checked queries**. It does not, however, do this by providing a Rust\nAPI or DSL (domain-specific language) for building queries. Instead, it provides macros that take\nregular SQL as input and ensure that it is valid for your database. The way this works is that\nSQLx connects to your development DB at compile time to have the database itself verify (and return\nsome info on) your SQL queries. This has some potentially surprising implications:\n\n- Since SQLx never has to parse the SQL string itself, any syntax that the development DB accepts\n  can be used (including things added by database extensions)\n- Due to the different amount of information databases let you retrieve about queries, the extent of\n  SQL verification you get from the query macros depends on the database\n\n**If you are looking for an (asynchronous) ORM,** you can check out our new [Ecosystem wiki page](https://github.com/launchbadge/sqlx/wiki/Ecosystem#orms)!\n\n[`ormx`]: https://crates.io/crates/ormx\n[`SeaORM`]: https://github.com/SeaQL/sea-orm\n## Usage\n\nSee the `examples/` folder for more in-depth usage.\n\n### Quickstart\n\n```rust\nuse sqlx::postgres::PgPoolOptions;\n// use sqlx::mysql::MySqlPoolOptions;\n// etc.\n\n#[async_std::main] // Requires the `attributes` feature of `async-std`\n// or #[tokio::main]\n// or #[actix_web::main]\nasync fn main() -> Result<(), sqlx::Error> {\n    // Create a connection pool\n    //  for MySQL/MariaDB, use MySqlPoolOptions::new()\n    //  for SQLite, use SqlitePoolOptions::new()\n    //  etc.\n    let pool = PgPoolOptions::new()\n        .max_connections(5)\n        .connect(\"postgres://postgres:password@localhost/test\").await?;\n\n    // Make a simple query to return the given parameter (use a question mark `?` instead of `$1` for MySQL/MariaDB)\n    let row: (i64,) = sqlx::query_as(\"SELECT $1\")\n        .bind(150_i64)\n        .fetch_one(&pool).await?;\n\n    assert_eq!(row.0, 150);\n\n    Ok(())\n}\n```\n\n\n### Connecting\n\nA single connection can be established using any of the database connection types and calling `connect()`.\n\n```rust\nuse sqlx::Connection;\n\nlet conn = SqliteConnection::connect(\"sqlite::memory:\").await?;\n```\n\nGenerally, you will want to instead create a connection pool (`sqlx::Pool`) for the application to\nregulate how many server-side connections it's using.\n\n```rust\nlet pool = MySqlPool::connect(\"mysql://user:pass@host/database\").await?;\n```\n\n### Querying\n\nIn SQL, queries can be separated into prepared (parameterized) or unprepared (simple). Prepared queries have their\nquery plan _cached_, use a binary mode of communication (lower bandwidth and faster decoding), and utilize parameters\nto avoid SQL injection. Unprepared queries are simple and intended only for use where a prepared statement\nwill not work, such as various database commands (e.g., `PRAGMA` or `SET` or `BEGIN`).\n\nSQLx supports all operations with both types of queries. In SQLx, a `&str` is treated as an unprepared query,\nand a `Query` or `QueryAs` struct is treated as a prepared query.\n\n```rust\n// low-level, Executor trait\nconn.execute(\"BEGIN\").await?; // unprepared, simple query\nconn.execute(sqlx::query(\"DELETE FROM table\")).await?; // prepared, cached query\n```\n\nWe should prefer to use the high-level `query` interface whenever possible. To make this easier, there are finalizers\non the type to avoid the need to wrap with an executor.\n\n```rust\nsqlx::query(\"DELETE FROM table\").execute(&mut conn).await?;\nsqlx::query(\"DELETE FROM table\").execute(&pool).await?;\n```\n\nThe `execute` query finalizer returns the number of affected rows, if any, and drops all received results.\nIn addition, there are `fetch`, `fetch_one`, `fetch_optional`, and `fetch_all` to receive results.\n\nThe `Query` type returned from `sqlx::query` will return `Row<'conn>` from the database. Column values can be accessed\nby ordinal or by name with `row.get()`. As the `Row` retains an immutable borrow on the connection, only one\n`Row` may exist at a time.\n\nThe `fetch` query finalizer returns a stream-like type that iterates through the rows in the result sets.\n\n```rust\n// provides `try_next`\nuse futures_util::TryStreamExt;\n// provides `try_get`\nuse sqlx::Row;\n\nlet mut rows = sqlx::query(\"SELECT * FROM users WHERE email = ?\")\n    .bind(email)\n    .fetch(&mut conn);\n\nwhile let Some(row) = rows.try_next().await? {\n    // map the row into a user-defined domain type\n    let email: &str = row.try_get(\"email\")?;\n}\n```\n\nTo assist with mapping the row into a domain type, one of two idioms may be used:\n\n```rust\nlet mut stream = sqlx::query(\"SELECT * FROM users\")\n    .map(|row: PgRow| {\n        // map the row into a user-defined domain type\n    })\n    .fetch(&mut conn);\n```\n\n```rust\n#[derive(sqlx::FromRow)]\nstruct User { name: String, id: i64 }\n\nlet mut stream = sqlx::query_as::<_, User>(\"SELECT * FROM users WHERE email = ? OR name = ?\")\n    .bind(user_email)\n    .bind(user_name)\n    .fetch(&mut conn);\n```\n\nInstead of a stream of results, we can use `fetch_one` or `fetch_optional` to request one required or optional result\nfrom the database.\n\n### Compile-time verification\n\nWe can use the macro, `sqlx::query!` to achieve compile-time syntactic and semantic verification of the SQL, with\nan output to an anonymous record type where each SQL column is a Rust field (using raw identifiers where needed).\n\n```rust\nlet countries = sqlx::query!(\n        \"\nSELECT country, COUNT(*) as count\nFROM users\nGROUP BY country\nWHERE organization = ?\n        \",\n        organization\n    )\n    .fetch_all(&pool) // -> Vec<{ country: String, count: i64 }>\n    .await?;\n\n// countries[0].country\n// countries[0].count\n```\n\nDifferences from `query()`:\n\n-   The input (or bind) parameters must be given all at once (and they are compile-time validated to be\n    the right number and the right type).\n\n-   The output type is an anonymous record. In the above example the type would be similar to:\n\n    ```rust\n    { country: String, count: i64 }\n    ```\n\n-   The `DATABASE_URL` environment variable must be set at build time to a database which it can prepare\n    queries against; the database does not have to contain any data but must be the same\n    kind (MySQL, Postgres, etc.) and have the same schema as the database you will be connecting to at runtime.\n\n    For convenience, you can use [a `.env` file][dotenv]<sup>1</sup> to set DATABASE_URL so that you don't have to pass it every time:\n\n    ```\n    DATABASE_URL=mysql://localhost/my_database\n    ```\n\n[dotenv]: https://github.com/dotenv-rs/dotenv#examples\n\nThe biggest downside to `query!()` is that the output type cannot be named (due to Rust not\nofficially supporting anonymous records). To address that, there is a `query_as!()` macro that is\nmostly identical except that you can name the output type.\n\n```rust\n// no traits are needed\nstruct Country { country: String, count: i64 }\n\nlet countries = sqlx::query_as!(Country,\n        \"\nSELECT country, COUNT(*) as count\nFROM users\nGROUP BY country\nWHERE organization = ?\n        \",\n        organization\n    )\n    .fetch_all(&pool) // -> Vec<Country>\n    .await?;\n\n// countries[0].country\n// countries[0].count\n```\n\nTo avoid the need of having a development database around to compile the project even when no\nmodifications (to the database-accessing parts of the code) are done, you can enable \"offline mode\"\nto cache the results of the SQL query analysis using the `sqlx` command-line tool. See\n[sqlx-cli/README.md](./sqlx-cli/README.md#enable-building-in-offline-mode-with-query).\n\nCompile-time verified queries do quite a bit of work at compile time. Incremental actions like\n`cargo check` and `cargo build` can be significantly faster when using an optimized build by\nputting the following in your `Cargo.toml` (More information in the\n[Profiles section](https://doc.rust-lang.org/cargo/reference/profiles.html) of The Cargo Book)\n\n```toml\n[profile.dev.package.sqlx-macros]\nopt-level = 3\n```\n\n<sup>1</sup> The `dotenv` crate itself appears abandoned as of [December 2021](https://github.com/dotenv-rs/dotenv/issues/74)\nso we now use the `dotenvy` crate instead. The file format is the same.\n\n## Safety\n\nThis crate uses `#![forbid(unsafe_code)]` to ensure everything is implemented in 100% Safe Rust.\n\nIf the `sqlite` feature is enabled, this is downgraded to `#![deny(unsafe_code)]` with `#![allow(unsafe_code)]` on the\n`sqlx::sqlite` module. There are several places where we interact with the C SQLite API. We try to document each call for the invariants we're assuming. We absolutely welcome auditing of, and feedback on, our unsafe code usage.\n\n## License\n\nLicensed under either of\n\n-   Apache License, Version 2.0\n    ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n-   MIT license\n    ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n## Contribution\n\nUnless you explicitly state otherwise, any Contribution intentionally submitted\nfor inclusion in the work by you, as defined in the Apache-2.0 license, shall be\ndual licensed as above, without any additional terms or conditions.\n",
      "stars_today": 10
    },
    {
      "id": 343533419,
      "name": "lipgloss",
      "full_name": "charmbracelet/lipgloss",
      "description": "Style definitions for nice terminal layouts üëÑ",
      "html_url": "https://github.com/charmbracelet/lipgloss",
      "stars": 10320,
      "forks": 298,
      "language": "Go",
      "topics": [
        "cli",
        "go",
        "golang",
        "hacktoberfest",
        "layout",
        "style",
        "tui"
      ],
      "created_at": "2021-03-01T19:31:36Z",
      "updated_at": "2026-01-14T01:05:53Z",
      "pushed_at": "2026-01-12T11:55:31Z",
      "open_issues": 99,
      "owner": {
        "login": "charmbracelet",
        "avatar_url": "https://avatars.githubusercontent.com/u/57376114?v=4"
      },
      "readme": "# Lip Gloss\n\n<p>\n    <picture>\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"https://stuff.charm.sh/lipgloss/lip-gloss-light-2025-06.png\" width=\"340\">\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://stuff.charm.sh/lipgloss/lip-gloss-dark-2025-06.png\" width=\"340\">\n      <img src=\"https://stuff.charm.sh/lipgloss/lip-gloss-light-2025-06.png\" width=\"340\" />\n    </picture>\n    <br>\n    <a href=\"https://github.com/charmbracelet/lipgloss/releases\"><img src=\"https://img.shields.io/github/release/charmbracelet/lipgloss.svg\" alt=\"Latest Release\"></a>\n    <a href=\"https://pkg.go.dev/github.com/charmbracelet/lipgloss?tab=doc\"><img src=\"https://godoc.org/github.com/golang/gddo?status.svg\" alt=\"GoDoc\"></a>\n    <a href=\"https://github.com/charmbracelet/lipgloss/actions\"><img src=\"https://github.com/charmbracelet/lipgloss/workflows/build/badge.svg\" alt=\"Build Status\"></a>\n</p>\n\nStyle definitions for nice terminal layouts. Built with TUIs in mind.\n\n![Lip Gloss example](https://github.com/user-attachments/assets/92560e60-d70e-4ce0-b39e-a60bb933356b)\n\nLip Gloss takes an expressive, declarative approach to terminal rendering.\nUsers familiar with CSS will feel at home with Lip Gloss.\n\n```go\n\nimport \"github.com/charmbracelet/lipgloss\"\n\nvar style = lipgloss.NewStyle().\n    Bold(true).\n    Foreground(lipgloss.Color(\"#FAFAFA\")).\n    Background(lipgloss.Color(\"#7D56F4\")).\n    PaddingTop(2).\n    PaddingLeft(4).\n    Width(22)\n\nfmt.Println(style.Render(\"Hello, kitty\"))\n```\n\n## Colors\n\nLip Gloss supports the following color profiles:\n\n### ANSI 16 colors (4-bit)\n\n```go\nlipgloss.Color(\"5\")  // magenta\nlipgloss.Color(\"9\")  // red\nlipgloss.Color(\"12\") // light blue\n```\n\n### ANSI 256 Colors (8-bit)\n\n```go\nlipgloss.Color(\"86\")  // aqua\nlipgloss.Color(\"201\") // hot pink\nlipgloss.Color(\"202\") // orange\n```\n\n### True Color (16,777,216 colors; 24-bit)\n\n```go\nlipgloss.Color(\"#0000FF\") // good ol' 100% blue\nlipgloss.Color(\"#04B575\") // a green\nlipgloss.Color(\"#3C3C3C\") // a dark gray\n```\n\n...as well as a 1-bit ASCII profile, which is black and white only.\n\nThe terminal's color profile will be automatically detected, and colors outside\nthe gamut of the current palette will be automatically coerced to their closest\navailable value.\n\n### Adaptive Colors\n\nYou can also specify color options for light and dark backgrounds:\n\n```go\nlipgloss.AdaptiveColor{Light: \"236\", Dark: \"248\"}\n```\n\nThe terminal's background color will automatically be detected and the\nappropriate color will be chosen at runtime.\n\n### Complete Colors\n\nCompleteColor specifies exact values for True Color, ANSI256, and ANSI color\nprofiles.\n\n```go\nlipgloss.CompleteColor{TrueColor: \"#0000FF\", ANSI256: \"86\", ANSI: \"5\"}\n```\n\nAutomatic color degradation will not be performed in this case and it will be\nbased on the color specified.\n\n### Complete Adaptive Colors\n\nYou can use `CompleteColor` with `AdaptiveColor` to specify the exact values for\nlight and dark backgrounds without automatic color degradation.\n\n```go\nlipgloss.CompleteAdaptiveColor{\n    Light: CompleteColor{TrueColor: \"#d7ffae\", ANSI256: \"193\", ANSI: \"11\"},\n    Dark:  CompleteColor{TrueColor: \"#d75fee\", ANSI256: \"163\", ANSI: \"5\"},\n}\n```\n\n## Inline Formatting\n\nLip Gloss supports the usual ANSI text formatting options:\n\n```go\nvar style = lipgloss.NewStyle().\n    Bold(true).\n    Italic(true).\n    Faint(true).\n    Blink(true).\n    Strikethrough(true).\n    Underline(true).\n    Reverse(true)\n```\n\n## Block-Level Formatting\n\nLip Gloss also supports rules for block-level formatting:\n\n```go\n// Padding\nvar style = lipgloss.NewStyle().\n    PaddingTop(2).\n    PaddingRight(4).\n    PaddingBottom(2).\n    PaddingLeft(4)\n\n// Margins\nvar style = lipgloss.NewStyle().\n    MarginTop(2).\n    MarginRight(4).\n    MarginBottom(2).\n    MarginLeft(4)\n```\n\nThere is also shorthand syntax for margins and padding, which follows the same\nformat as CSS:\n\n```go\n// 2 cells on all sides\nlipgloss.NewStyle().Padding(2)\n\n// 2 cells on the top and bottom, 4 cells on the left and right\nlipgloss.NewStyle().Margin(2, 4)\n\n// 1 cell on the top, 4 cells on the sides, 2 cells on the bottom\nlipgloss.NewStyle().Padding(1, 4, 2)\n\n// Clockwise, starting from the top: 2 cells on the top, 4 on the right, 3 on\n// the bottom, and 1 on the left\nlipgloss.NewStyle().Margin(2, 4, 3, 1)\n```\n\n## Aligning Text\n\nYou can align paragraphs of text to the left, right, or center.\n\n```go\nvar style = lipgloss.NewStyle().\n    Width(24).\n    Align(lipgloss.Left).  // align it left\n    Align(lipgloss.Right). // no wait, align it right\n    Align(lipgloss.Center) // just kidding, align it in the center\n```\n\n## Width and Height\n\nSetting a minimum width and height is simple and straightforward.\n\n```go\nvar style = lipgloss.NewStyle().\n    SetString(\"What‚Äôs for lunch?\").\n    Width(24).\n    Height(32).\n    Foreground(lipgloss.Color(\"63\"))\n```\n\n## Borders\n\nAdding borders is easy:\n\n```go\n// Add a purple, rectangular border\nvar style = lipgloss.NewStyle().\n    BorderStyle(lipgloss.NormalBorder()).\n    BorderForeground(lipgloss.Color(\"63\"))\n\n// Set a rounded, yellow-on-purple border to the top and left\nvar anotherStyle = lipgloss.NewStyle().\n    BorderStyle(lipgloss.RoundedBorder()).\n    BorderForeground(lipgloss.Color(\"228\")).\n    BorderBackground(lipgloss.Color(\"63\")).\n    BorderTop(true).\n    BorderLeft(true)\n\n// Make your own border\nvar myCuteBorder = lipgloss.Border{\n    Top:         \"._.:*:\",\n    Bottom:      \"._.:*:\",\n    Left:        \"|*\",\n    Right:       \"|*\",\n    TopLeft:     \"*\",\n    TopRight:    \"*\",\n    BottomLeft:  \"*\",\n    BottomRight: \"*\",\n}\n```\n\nThere are also shorthand functions for defining borders, which follow a similar\npattern to the margin and padding shorthand functions.\n\n```go\n// Add a thick border to the top and bottom\nlipgloss.NewStyle().\n    Border(lipgloss.ThickBorder(), true, false)\n\n// Add a double border to the top and left sides. Rules are set clockwise\n// from top.\nlipgloss.NewStyle().\n    Border(lipgloss.DoubleBorder(), true, false, false, true)\n```\n\nFor more on borders see [the docs][docs].\n\n## Copying Styles\n\nJust use assignment:\n\n```go\nstyle := lipgloss.NewStyle().Foreground(lipgloss.Color(\"219\"))\n\ncopiedStyle := style // this is a true copy\n\nwildStyle := style.Blink(true) // this is also true copy, with blink added\n\n```\n\nSince `Style` data structures contains only primitive types, assigning a style\nto another effectively creates a new copy of the style without mutating the\noriginal.\n\n## Inheritance\n\nStyles can inherit rules from other styles. When inheriting, only unset rules\non the receiver are inherited.\n\n```go\nvar styleA = lipgloss.NewStyle().\n    Foreground(lipgloss.Color(\"229\")).\n    Background(lipgloss.Color(\"63\"))\n\n// Only the background color will be inherited here, because the foreground\n// color will have been already set:\nvar styleB = lipgloss.NewStyle().\n    Foreground(lipgloss.Color(\"201\")).\n    Inherit(styleA)\n```\n\n## Unsetting Rules\n\nAll rules can be unset:\n\n```go\nvar style = lipgloss.NewStyle().\n    Bold(true).                        // make it bold\n    UnsetBold().                       // jk don't make it bold\n    Background(lipgloss.Color(\"227\")). // yellow background\n    UnsetBackground()                  // never mind\n```\n\nWhen a rule is unset, it won't be inherited or copied.\n\n## Enforcing Rules\n\nSometimes, such as when developing a component, you want to make sure style\ndefinitions respect their intended purpose in the UI. This is where `Inline`\nand `MaxWidth`, and `MaxHeight` come in:\n\n```go\n// Force rendering onto a single line, ignoring margins, padding, and borders.\nsomeStyle.Inline(true).Render(\"yadda yadda\")\n\n// Also limit rendering to five cells\nsomeStyle.Inline(true).MaxWidth(5).Render(\"yadda yadda\")\n\n// Limit rendering to a 5x5 cell block\nsomeStyle.MaxWidth(5).MaxHeight(5).Render(\"yadda yadda\")\n```\n\n## Tabs\n\nThe tab character (`\\t`) is rendered differently in different terminals (often\nas 8 spaces, sometimes 4). Because of this inconsistency, Lip Gloss converts\ntabs to 4 spaces at render time. This behavior can be changed on a per-style\nbasis, however:\n\n```go\nstyle := lipgloss.NewStyle() // tabs will render as 4 spaces, the default\nstyle = style.TabWidth(2)    // render tabs as 2 spaces\nstyle = style.TabWidth(0)    // remove tabs entirely\nstyle = style.TabWidth(lipgloss.NoTabConversion) // leave tabs intact\n```\n\n## Rendering\n\nGenerally, you just call the `Render(string...)` method on a `lipgloss.Style`:\n\n```go\nstyle := lipgloss.NewStyle().Bold(true).SetString(\"Hello,\")\nfmt.Println(style.Render(\"kitty.\")) // Hello, kitty.\nfmt.Println(style.Render(\"puppy.\")) // Hello, puppy.\n```\n\nBut you could also use the Stringer interface:\n\n```go\nvar style = lipgloss.NewStyle().SetString(\"‰Ω†Â•ΩÔºåÁå´Âí™„ÄÇ\").Bold(true)\nfmt.Println(style) // ‰Ω†Â•ΩÔºåÁå´Âí™„ÄÇ\n```\n\n### Custom Renderers\n\nCustom renderers allow you to render to a specific outputs. This is\nparticularly important when you want to render to different outputs and\ncorrectly detect the color profile and dark background status for each, such as\nin a server-client situation.\n\n```go\nfunc myLittleHandler(sess ssh.Session) {\n    // Create a renderer for the client.\n    renderer := lipgloss.NewRenderer(sess)\n\n    // Create a new style on the renderer.\n    style := renderer.NewStyle().Background(lipgloss.AdaptiveColor{Light: \"63\", Dark: \"228\"})\n\n    // Render. The color profile and dark background state will be correctly detected.\n    io.WriteString(sess, style.Render(\"Heyyyyyyy\"))\n}\n```\n\nFor an example on using a custom renderer over SSH with [Wish][wish] see the\n[SSH example][ssh-example].\n\n## Utilities\n\nIn addition to pure styling, Lip Gloss also ships with some utilities to help\nassemble your layouts.\n\n### Joining Paragraphs\n\nHorizontally and vertically joining paragraphs is a cinch.\n\n```go\n// Horizontally join three paragraphs along their bottom edges\nlipgloss.JoinHorizontal(lipgloss.Bottom, paragraphA, paragraphB, paragraphC)\n\n// Vertically join two paragraphs along their center axes\nlipgloss.JoinVertical(lipgloss.Center, paragraphA, paragraphB)\n\n// Horizontally join three paragraphs, with the shorter ones aligning 20%\n// from the top of the tallest\nlipgloss.JoinHorizontal(0.2, paragraphA, paragraphB, paragraphC)\n```\n\n### Measuring Width and Height\n\nSometimes you‚Äôll want to know the width and height of text blocks when building\nyour layouts.\n\n```go\n// Render a block of text.\nvar style = lipgloss.NewStyle().\n    Width(40).\n    Padding(2)\nvar block string = style.Render(someLongString)\n\n// Get the actual, physical dimensions of the text block.\nwidth := lipgloss.Width(block)\nheight := lipgloss.Height(block)\n\n// Here's a shorthand function.\nw, h := lipgloss.Size(block)\n```\n\n### Placing Text in Whitespace\n\nSometimes you‚Äôll simply want to place a block of text in whitespace.\n\n```go\n// Center a paragraph horizontally in a space 80 cells wide. The height of\n// the block returned will be as tall as the input paragraph.\nblock := lipgloss.PlaceHorizontal(80, lipgloss.Center, fancyStyledParagraph)\n\n// Place a paragraph at the bottom of a space 30 cells tall. The width of\n// the text block returned will be as wide as the input paragraph.\nblock := lipgloss.PlaceVertical(30, lipgloss.Bottom, fancyStyledParagraph)\n\n// Place a paragraph in the bottom right corner of a 30x80 cell space.\nblock := lipgloss.Place(30, 80, lipgloss.Right, lipgloss.Bottom, fancyStyledParagraph)\n```\n\nYou can also style the whitespace. For details, see [the docs][docs].\n\n## Rendering Tables\n\nLip Gloss ships with a table rendering sub-package.\n\n```go\nimport \"github.com/charmbracelet/lipgloss/table\"\n```\n\nDefine some rows of data.\n\n```go\nrows := [][]string{\n    {\"Chinese\", \"ÊÇ®Â•Ω\", \"‰Ω†Â•Ω\"},\n    {\"Japanese\", \"„Åì„Çì„Å´„Å°„ÅØ\", \"„ÇÑ„ÅÇ\"},\n    {\"Arabic\", \"ÿ£ŸáŸÑŸäŸÜ\", \"ÿ£ŸáŸÑÿß\"},\n    {\"Russian\", \"–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ\", \"–ü—Ä–∏–≤–µ—Ç\"},\n    {\"Spanish\", \"Hola\", \"¬øQu√© tal?\"},\n}\n```\n\nUse the table package to style and render the table.\n\n```go\nvar (\n    purple    = lipgloss.Color(\"99\")\n    gray      = lipgloss.Color(\"245\")\n    lightGray = lipgloss.Color(\"241\")\n\n    headerStyle  = lipgloss.NewStyle().Foreground(purple).Bold(true).Align(lipgloss.Center)\n    cellStyle    = lipgloss.NewStyle().Padding(0, 1).Width(14)\n    oddRowStyle  = cellStyle.Foreground(gray)\n    evenRowStyle = cellStyle.Foreground(lightGray)\n)\n\nt := table.New().\n    Border(lipgloss.NormalBorder()).\n    BorderStyle(lipgloss.NewStyle().Foreground(purple)).\n    StyleFunc(func(row, col int) lipgloss.Style {\n        switch {\n        case row == table.HeaderRow:\n            return headerStyle\n        case row%2 == 0:\n            return evenRowStyle\n        default:\n            return oddRowStyle\n        }\n    }).\n    Headers(\"LANGUAGE\", \"FORMAL\", \"INFORMAL\").\n    Rows(rows...)\n\n// You can also add tables row-by-row\nt.Row(\"English\", \"You look absolutely fabulous.\", \"How's it going?\")\n```\n\nPrint the table.\n\n```go\nfmt.Println(t)\n```\n\n![Table Example](https://github.com/charmbracelet/lipgloss/assets/42545625/6e4b70c4-f494-45da-a467-bdd27df30d5d)\n\n> [!WARNING]\n> Table `Rows` need to be declared before `Offset` otherwise it does nothing.\n\n### Table Borders\n\nThere are helpers to generate tables in markdown or ASCII style:\n\n#### Markdown Table\n\n```go\ntable.New().Border(lipgloss.MarkdownBorder()).BorderTop(false).BorderBottom(false)\n```\n\n```\n| LANGUAGE |    FORMAL    | INFORMAL  |\n|----------|--------------|-----------|\n| Chinese  | N«ên h«éo      | N«ê h«éo    |\n| French   | Bonjour      | Salut     |\n| Russian  | Zdravstvuyte | Privet    |\n| Spanish  | Hola         | ¬øQu√© tal? |\n```\n\n#### ASCII Table\n\n```go\ntable.New().Border(lipgloss.ASCIIBorder())\n```\n\n```\n+----------+--------------+-----------+\n| LANGUAGE |    FORMAL    | INFORMAL  |\n+----------+--------------+-----------+\n| Chinese  | N«ên h«éo      | N«ê h«éo    |\n| French   | Bonjour      | Salut     |\n| Russian  | Zdravstvuyte | Privet    |\n| Spanish  | Hola         | ¬øQu√© tal? |\n+----------+--------------+-----------+\n```\n\nFor more on tables see [the docs](https://pkg.go.dev/github.com/charmbracelet/lipgloss?tab=doc) and [examples](https://github.com/charmbracelet/lipgloss/tree/master/examples/table).\n\n## Rendering Lists\n\nLip Gloss ships with a list rendering sub-package.\n\n```go\nimport \"github.com/charmbracelet/lipgloss/list\"\n```\n\nDefine a new list.\n\n```go\nl := list.New(\"A\", \"B\", \"C\")\n```\n\nPrint the list.\n\n```go\nfmt.Println(l)\n\n// ‚Ä¢ A\n// ‚Ä¢ B\n// ‚Ä¢ C\n```\n\nLists have the ability to nest.\n\n```go\nl := list.New(\n    \"A\", list.New(\"Artichoke\"),\n    \"B\", list.New(\"Baking Flour\", \"Bananas\", \"Barley\", \"Bean Sprouts\"),\n    \"C\", list.New(\"Cashew Apple\", \"Cashews\", \"Coconut Milk\", \"Curry Paste\", \"Currywurst\"),\n    \"D\", list.New(\"Dill\", \"Dragonfruit\", \"Dried Shrimp\"),\n    \"E\", list.New(\"Eggs\"),\n    \"F\", list.New(\"Fish Cake\", \"Furikake\"),\n    \"J\", list.New(\"Jicama\"),\n    \"K\", list.New(\"Kohlrabi\"),\n    \"L\", list.New(\"Leeks\", \"Lentils\", \"Licorice Root\"),\n)\n```\n\nPrint the list.\n\n```go\nfmt.Println(l)\n```\n\n<p align=\"center\">\n<img width=\"600\" alt=\"image\" src=\"https://github.com/charmbracelet/lipgloss/assets/42545625/0dc9f440-0748-4151-a3b0-7dcf29dfcdb0\">\n</p>\n\nLists can be customized via their enumeration function as well as using\n`lipgloss.Style`s.\n\n```go\nenumeratorStyle := lipgloss.NewStyle().Foreground(lipgloss.Color(\"99\")).MarginRight(1)\nitemStyle := lipgloss.NewStyle().Foreground(lipgloss.Color(\"212\")).MarginRight(1)\n\nl := list.New(\n    \"Glossier\",\n    \"Claire‚Äôs Boutique\",\n    \"Nyx\",\n    \"Mac\",\n    \"Milk\",\n    ).\n    Enumerator(list.Roman).\n    EnumeratorStyle(enumeratorStyle).\n    ItemStyle(itemStyle)\n```\n\nPrint the list.\n\n<p align=\"center\">\n<img width=\"600\" alt=\"List example\" src=\"https://github.com/charmbracelet/lipgloss/assets/42545625/360494f1-57fb-4e13-bc19-0006efe01561\">\n</p>\n\nIn addition to the predefined enumerators (`Arabic`, `Alphabet`, `Roman`, `Bullet`, `Tree`),\nyou may also define your own custom enumerator:\n\n```go\nl := list.New(\"Duck\", \"Duck\", \"Duck\", \"Duck\", \"Goose\", \"Duck\", \"Duck\")\n\nfunc DuckDuckGooseEnumerator(l list.Items, i int) string {\n    if l.At(i).Value() == \"Goose\" {\n        return \"Honk ‚Üí\"\n    }\n    return \"\"\n}\n\nl = l.Enumerator(DuckDuckGooseEnumerator)\n```\n\nPrint the list:\n\n<p align=\"center\">\n<img width=\"600\" alt=\"image\" src=\"https://github.com/charmbracelet/lipgloss/assets/42545625/157aaf30-140d-4948-9bb4-dfba46e5b87e\">\n</p>\n\nIf you need, you can also build lists incrementally:\n\n```go\nl := list.New()\n\nfor i := 0; i < repeat; i++ {\n    l.Item(\"Lip Gloss\")\n}\n```\n\n## Rendering Trees\n\nLip Gloss ships with a tree rendering sub-package.\n\n```go\nimport \"github.com/charmbracelet/lipgloss/tree\"\n```\n\nDefine a new tree.\n\n```go\nt := tree.Root(\".\").\n    Child(\"A\", \"B\", \"C\")\n```\n\nPrint the tree.\n\n```go\nfmt.Println(t)\n\n// .\n// ‚îú‚îÄ‚îÄ A\n// ‚îú‚îÄ‚îÄ B\n// ‚îî‚îÄ‚îÄ C\n```\n\nTrees have the ability to nest.\n\n```go\nt := tree.Root(\".\").\n    Child(\"macOS\").\n    Child(\n        tree.New().\n            Root(\"Linux\").\n            Child(\"NixOS\").\n            Child(\"Arch Linux (btw)\").\n            Child(\"Void Linux\"),\n        ).\n    Child(\n        tree.New().\n            Root(\"BSD\").\n            Child(\"FreeBSD\").\n            Child(\"OpenBSD\"),\n    )\n```\n\nPrint the tree.\n\n```go\nfmt.Println(t)\n```\n\n<p align=\"center\">\n<img width=\"663\" alt=\"Tree Example (simple)\" src=\"https://github.com/user-attachments/assets/5ef14eb8-a5d4-4f94-8834-e15d1e714f89\">\n</p>\n\nTrees can be customized via their enumeration function as well as using\n`lipgloss.Style`s.\n\n```go\nenumeratorStyle := lipgloss.NewStyle().Foreground(lipgloss.Color(\"63\")).MarginRight(1)\nrootStyle := lipgloss.NewStyle().Foreground(lipgloss.Color(\"35\"))\nitemStyle := lipgloss.NewStyle().Foreground(lipgloss.Color(\"212\"))\n\nt := tree.\n    Root(\"‚Åú Makeup\").\n    Child(\n        \"Glossier\",\n        \"Fenty Beauty\",\n        tree.New().Child(\n            \"Gloss Bomb Universal Lip Luminizer\",\n            \"Hot Cheeks Velour Blushlighter\",\n        ),\n        \"Nyx\",\n        \"Mac\",\n        \"Milk\",\n    ).\n    Enumerator(tree.RoundedEnumerator).\n    EnumeratorStyle(enumeratorStyle).\n    RootStyle(rootStyle).\n    ItemStyle(itemStyle)\n```\n\nPrint the tree.\n\n<p align=\"center\">\n<img width=\"663\" alt=\"Tree Example (makeup)\" src=\"https://github.com/user-attachments/assets/06d12d87-744a-4c89-bd98-45de9094a97e\">\n</p>\n\nThe predefined enumerators for trees are `DefaultEnumerator` and `RoundedEnumerator`.\n\nIf you need, you can also build trees incrementally:\n\n```go\nt := tree.New()\n\nfor i := 0; i < repeat; i++ {\n    t.Child(\"Lip Gloss\")\n}\n```\n\n---\n\n## FAQ\n\n<details>\n<summary>\nWhy are things misaligning? Why are borders at the wrong widths?\n</summary>\n<p>This is most likely due to your locale and encoding, particularly with\nregard to Chinese, Japanese, and Korean (for example, <code>zh_CN.UTF-8</code>\nor <code>ja_JP.UTF-8</code>). The most direct way to fix this is to set\n<code>RUNEWIDTH_EASTASIAN=0</code> in your environment.</p>\n\n<p>For details see <a href=\"https://github.com/charmbracelet/lipgloss/issues/40\">https://github.com/charmbracelet/lipgloss/issues/40.</a></p>\n</details>\n\n<details>\n<summary>\nWhy isn't Lip Gloss displaying colors?\n</summary>\n<p>Lip Gloss automatically degrades colors to the best available option in the\ngiven terminal, and if output's not a TTY it will remove color output entirely.\nThis is common when running tests, CI, or when piping output elsewhere.</p>\n\n<p>If necessary, you can force a color profile in your tests with\n<a href=\"https://pkg.go.dev/github.com/charmbracelet/lipgloss#SetColorProfile\"><code>SetColorProfile</code></a>.</p>\n\n```go\nimport (\n    \"github.com/charmbracelet/lipgloss\"\n    \"github.com/muesli/termenv\"\n)\n\nlipgloss.SetColorProfile(termenv.TrueColor)\n```\n\n_Note:_ this option limits the flexibility of your application and can cause\nANSI escape codes to be output in cases where that might not be desired. Take\ncareful note of your use case and environment before choosing to force a color\nprofile.\n\n</details>\n\n## What about [Bubble Tea][tea]?\n\nLip Gloss doesn‚Äôt replace Bubble Tea. Rather, it is an excellent Bubble Tea\ncompanion. It was designed to make assembling terminal user interface views as\nsimple and fun as possible so that you can focus on building your application\ninstead of concerning yourself with low-level layout details.\n\nIn simple terms, you can use Lip Gloss to help build your Bubble Tea views.\n\n[tea]: https://github.com/charmbracelet/tea\n\n## Under the Hood\n\nLip Gloss is built on the excellent [Termenv][termenv] and [Reflow][reflow]\nlibraries which deal with color and ANSI-aware text operations, respectively.\nFor many use cases Termenv and Reflow will be sufficient for your needs.\n\n[termenv]: https://github.com/muesli/termenv\n[reflow]: https://github.com/muesli/reflow\n\n## Rendering Markdown\n\nFor a more document-centric rendering solution with support for things like\nlists, tables, and syntax-highlighted code have a look at [Glamour][glamour],\nthe stylesheet-based Markdown renderer.\n\n[glamour]: https://github.com/charmbracelet/glamour\n\n## Contributing\n\nSee [contributing][contribute].\n\n[contribute]: https://github.com/charmbracelet/lipgloss/contribute\n\n## Feedback\n\nWe‚Äôd love to hear your thoughts on this project. Feel free to drop us a note!\n\n- [Twitter](https://twitter.com/charmcli)\n- [The Fediverse](https://mastodon.social/@charmcli)\n- [Discord](https://charm.sh/chat)\n\n## License\n\n[MIT](https://github.com/charmbracelet/lipgloss/raw/master/LICENSE)\n\n---\n\nPart of [Charm](https://charm.sh).\n\n<a href=\"https://charm.sh/\"><img alt=\"The Charm logo\" src=\"https://stuff.charm.sh/charm-banner-next.jpg\" width=\"400\"></a>\n\nCharmÁÉ≠Áà±ÂºÄÊ∫ê ‚Ä¢ Charm loves open source\n\n[docs]: https://pkg.go.dev/github.com/charmbracelet/lipgloss?tab=doc\n[wish]: https://github.com/charmbracelet/wish\n[ssh-example]: examples/ssh\n",
      "stars_today": 10
    },
    {
      "id": 490984887,
      "name": "PipePipe",
      "full_name": "InfinityLoop1308/PipePipe",
      "description": "An open-source Android app to let you browse YouTube, NicoNico and BiliBili freely. ",
      "html_url": "https://github.com/InfinityLoop1308/PipePipe",
      "stars": 4340,
      "forks": 117,
      "language": "Kotlin",
      "topics": [
        "android",
        "bilibili",
        "mediaplayer",
        "newpipe",
        "niconico",
        "sponsorblock",
        "youtube"
      ],
      "created_at": "2022-05-11T06:30:25Z",
      "updated_at": "2026-01-13T22:39:17Z",
      "pushed_at": "2026-01-10T08:46:33Z",
      "open_issues": 120,
      "owner": {
        "login": "InfinityLoop1308",
        "avatar_url": "https://avatars.githubusercontent.com/u/96324692?v=4"
      },
      "readme": "<hr>\n<p align=\"center\"><img src=\"assets/logo.png\" width=\"150\"></p> \n<h2 align=\"center\"><b>PipePipe</b></h2>\n<h4 align=\"center\">\nNewPipe, reimagined: faster, more stable, and packed with more features.</h4>\n<p align=\"center\"><a href=\"https://f-droid.org/packages/InfinityLoop1309.NewPipeEnhanced/\"><img src=\"https://fdroid.gitlab.io/artwork/badge/get-it-on.png\" alt=\"Get it on F-Droid\"  width=\"207\" /></a>\n<a href=\"https://apt.izzysoft.de/fdroid/index/apk/InfinityLoop1309.NewPipeEnhanced\"><img src=\"assets/IzzyOnDroid.png\" alt=\"Get it on IzzyOnDroid\" width=\"207\" /></a></p>\n<hr>\n\n## Beyond NewPipe\n\n#### YouTube Enhancements\n* Integrate SponsorBlock for skipping sponsored segments (YouTube & BiliBili) \n* Restore YouTube dislikes with ReturnYouTubeDislike \n* Show original titles on YouTube (non-localized) \n* Log in to access restricted or premium content \n\n#### Media Features\n* Display live chats in danmaku-style overlays\n* Support AV1 and VP9 codecs for efficient, high-quality playback \n* Enable music player mode with background playback \n\n#### Filtering\n* Apply advanced search filters for better discovery \n* Filter out unwanted items by keywords or channels \n* Block shorts and paid videos for a cleaner feed \n\n#### Playback Controls\n* Use swipe-to-seek and fullscreen gestures for intuitive navigation \n* Long-press to speed up playback \n* Set a sleep timer for bedtime listening \n\n#### Enhanced Playlists\n* Download full playlists at once \n* Search and sort within local playlists and histories\n\n... and many more improvements!\n\n\n## Screenshots\n\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/00-v2.png\" width=640>](fastlane/metadata/android/en-US/images/phoneScreenshots/00-v1.png)\n\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/01-v3.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/01-v3.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/02-v3.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/02-v3.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/03-v3.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/03-v3.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/04-v3.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/04-v3.png)\n<br/>\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/05-v3.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/05-v3.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/06-v3.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/06-v3.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/07-v3.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/07-v3.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/08-v3.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/08-v3.png)\n<br/>\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/09-v3.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/09-v3.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/10-v3.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/10-v3.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/11-v3.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/11-v3.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/12-v3.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/12-v3.png)\n\n\n## About this fork\n\nDue to differences in development philosophy, I forked NewPipe in early 2022 and began independent development based on it.\n\nThis means that PipePipe neither receives updates from NewPipe nor pushes updates to NewPipe. They have become two separate projects. Issues that occur in NewPipe don't necessarily happen in PipePipe, and changes made in NewPipe may not be adopted by PipePipe. In contrast, forks like Tubular track the latest version of NewPipe and develop based on it.\n\nMaking a hard fork allows us to effectively address issues with quick fixes and maintain frequent feature updates.\n\n## About sign in\n\nPipePipe will ONLY use the login cookie for the specified scenarios you set. You can configure it in \"Cookie Functions.\"\n\nFor YouTube, the cookie will only be used when retrieving playback streams.\n\n## Contribute\n\nIssues and PRs are welcomed. Please note that I will **NOT** accept service requests. \n\nAnyone interested in creating their own service is encouraged to fork this repository.\n\n## Getting Nightly Builds\n\nVisit https://nightly.pipepipe.dev to download the latest nightly builds. These give you access to the most recent updates and fixes before they're included in the next official release.\n\n## Donation\n\nIf you find PipePipe useful, please consider becoming a supporter on Ko-Fi. Your support is important to me and helps me add more exciting new features. Every bit counts! üòá\n\nLiberapay: https://liberapay.com/PipePipe\n\nKo-fi: https://ko-fi.com/pipepipe\n\n## Special Thanks\n\n[SocialSisterYi/bilibili-API-collect](https://github.com/SocialSisterYi/bilibili-API-collect) for providing some BiliBili API lists.\n\n[AioiLight](https://github.com/AioiLight) for providing some code of NicoNico service.\n",
      "stars_today": 10
    },
    {
      "id": 966768509,
      "name": "ygege",
      "full_name": "UwUDev/ygege",
      "description": "High-performance indexer for YGG Torrent written in Rust",
      "html_url": "https://github.com/UwUDev/ygege",
      "stars": 335,
      "forks": 26,
      "language": "Rust",
      "topics": [
        "prowlarr",
        "ygg",
        "yggtorrent"
      ],
      "created_at": "2025-04-15T12:30:39Z",
      "updated_at": "2026-01-13T21:40:11Z",
      "pushed_at": "2026-01-12T16:03:20Z",
      "open_issues": 10,
      "owner": {
        "login": "UwUDev",
        "avatar_url": "https://avatars.githubusercontent.com/u/61664271?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"website/img/ygege-logo-text.png\" alt=\"Logo Yg√©g√©\" width=\"400\"/>\n</p>\n\n<div align=\"right\">\n  <details>\n    <summary>üåê Language</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"README.md\">Fran√ßais</a>\n        | <a href=\"README-en.md\">English</a>\n      </div>\n    </div>\n  </details>\n</div>\n\nIndexeur haute performance pour YGG Torrent √©crit en Rust \n\n## https://discord.gg/rcsgdzNrvJ\n\n<!--\n> [!CAUTION]\n> Suite a la nouvelle mise en place de la limite de 5 torrents gratuits par jour sur YGG Torrent, Yg√©g√© n'est plus en mesure de fonctionner correctement. Je travaille actuellement sur une solution pour contourner cette limitation. Votre aide est possible meme si vous ne savez pas coder en Rust ni coder du tout. N'hesitez pas a aller voir le discord pour plus d'infos: https://discord.gg/rcsgdzNrvJ\n>\n> Edit: Ils ont patch√©s les 2 bypass et forcent le captcha turnstile... Merci de ne plus cr√©er d'isssues a ce sujet (erreur 403)\n-->\n\n**Caract√©ristiques principales** :\n- R√©solution automatique du domaine actuel de YGG Torrent\n- Bypass Cloudflare automatis√© (sans r√©solution manuelle)\n- Recherche quasi instantan√©e\n- Reconnexion transparente aux sessions expir√©es\n- Caching des sessions\n- Contournement des DNS menteurs\n- Consommation m√©moire faible (14.7Mo en mode release sur Linux)\n- Recherche de torrents tr√®s modulaire (par nom, seed, leech, commentaires, date de publication, etc.)\n- Recuperation des informations compl√©mentaires sur les torrents (description, taille, nombre de seeders, leechers, etc.)\n- Pas de d√©pendances externes\n- Pas de drivers de navigateur\n\n## Pr√©requis pour la compilation\n- Rust 1.85.0+\n- OpenSSL 3+\n- Toutes les d√©pendances requises pour la compilation de [wreq](https://crates.io/crates/wreq)\n\n# Installation\n\nUne image Docker pr√™te √† l'emploi est disponible pour Yg√©g√©.\nPour commencer le d√©ploiement et la configuration de Docker, consultez le [Guide d√©di√© √† Docker](https://ygege.lila.ws/installation/docker-guide).\n\n## Docker\n\nPour cr√©er une image Docker personnalis√©e avec vos propres optimisations, consultez le [Guide de cr√©ation Docker](https://ygege.lila.ws/installation/docker-guide).\n\n## Installation manuelle\n\nPour compiler l'application √† partir des sources, suivez le [Guide d'installation manuel](https://ygege.lila.ws/installation/source-guide).\n\nPour les fans de Docker, n'h√©sitez pas √† contribuer au projet en m'aidant √† cr√©er une image Docker.\n\n## Configuration IMDB et TMDB\n\nPour activer la r√©cup√©ration des m√©tadonn√©es IMDB et TMDB, veuillez suivre les instructions du [guide d'assistance TMDB et IMDB](https://ygege.lila.ws/tmdb-imdb).\n\n## Int√©gration √† Prowlarr\n\nYg√©g√© peut √™tre utilis√© comme indexeur personnalis√© pour Prowlarr. Pour le mettre en place, trouvez votre r√©pertoire AppData (situ√© dans la page `/system/status` de Prowlarr) et copiez le fichier `ygege.yml` du repo dans le dossier `{votre chemin appdata prowlarr}/Definitions/Custom`, vous aurez probablement besoin de cr√©er le dossier `Custom`.\n\nUne fois que c'est fait, red√©marrez Prowlarr et allez dans les param√®tres des indexeurs, vous devriez voir Yg√©g√© dans la liste des indexeurs disponibles.\n\n> [!NOTE]\n> Prowlarr ne permet pas de personnaliser le \"Base URL\". Par d√©faut, utilisez `http://localhost:8715/`. Pour les configurations Docker Compose, utilisez `http://ygege:8715/`. Alternativement, utilisez ygege-dns-redirect.local avec un DNS personnalis√© ou en √©ditant le fichier hosts.\n\n## Int√©gration √† Jackett\n\nYg√©g√© peut √™tre utilis√© comme indexeur personnalis√© pour Jackett. Pour le mettre en place, localisez votre r√©pertoire AppData Jackett et copiez le fichier `ygege.yml` du d√©p√¥t dans le dossier `{votre chemin appdata jackett}/cardigann/definitions/`. Vous devrez peut-√™tre cr√©er le sous-dossier `cardigann/definitions/` s'il n'existe pas.\n\n> [!NOTE]\n> L'image Docker LinuxServer Jackett fournit une structure de dossiers bien organis√©e. Si vous utilisez une autre image Docker, adaptez les chemins en cons√©quence.\n\nUne fois termin√©, red√©marrez Jackett et acc√©dez aux param√®tres des indexeurs. Vous devriez voir Yg√©g√© dans la liste des indexeurs disponibles.\n\n## Contournement Cloudflare\nPour contourner le d√©fi de Cloudflare, Yg√©g√© n'utilise pas de navigateur ni de services tiers.\n\nUne r√®gle Cloudflare est appliqu√©e sur le site YGG Torrent pour emp√™cher l'apparition du challenge Cloudflare via le cookie `account_created=true` cens√© garantir que l'utilisateur a un compte valide et est connect√©.\n\nMais ce n'est pas si simple, Cloudflare vous surveille toujours et d√©tecte les faux clients HTTPS et les faux navigateurs.\n\nPour contourner cela, Yg√©g√© utilise la librairie [wreq](https://crates.io/crates/wreq) qui est un client HTTP bas√© sur `reqwest` et `tokio` permettant de reproduire 1:1 l'√©change TLS et HTTP/2 avec le serveur afin de simuler un vrai navigateur.\n\nJ'ai aussi remarqu√© que cela ne passait plus √† partir de Chrome 133, s√ªrement √† cause de l'integration de HTTP/3 dans Chrome qui n'est pas encore simul√©e par `wreq`.\n\nJe recommande aux curieux [cet article](https://fingerprint.com/blog/what-is-tls-fingerprinting-transport-layer-security/) qui explique comment fonctionne le fingerprinting TLS et [cet autre article](https://www.trickster.dev/post/understanding-http2-fingerprinting/) qui explique comment fonctionne le fingerprinting HTTP/2 et comment il est possible de le contourner.\n\n## Test de performance\n\nQuery pour la recherche:\n- Nom: `Vaiana 2`\n- Tri: `seeders`\n- Ordre: `descendant`\n\n|                                     | Nombre de tests | Temps total de tous les tests | Temps moyen par test |\n|-------------------------------------|-----------------|-------------------------------|----------------------|\n| R√©solution du domaine actuel de YGG |        25       |           3220,378ms          |      128,81512ms     |\n| Nouvelle connection YGG             |        10       |          4881.71361ms         |     488.1713616ms    |\n| Restoration de session YGG          |        10       |         2064.672142ms         |     206.4672142ms    |\n| Recherche                           |       100       |         17621.045874ms        |    176,21045874ms    |\n\n# Documentation\n\n## Documentation utilisateur\n\nLa documentation compl√®te est disponible sur [ygege.lila.ws](https://ygege.lila.ws) :\n- [Guide de d√©marrage](https://ygege.lila.ws/getting-started)\n- [Installation](https://ygege.lila.ws/installation/docker-guide)\n- [Configuration](https://ygege.lila.ws/configuration)\n- [Int√©grations (Prowlarr/Jackett)](https://ygege.lila.ws/integrations/prowlarr)\n- [Documentation de l'API](https://ygege.lila.ws/api)\n- [FAQ](https://ygege.lila.ws/faq)\n\n## Documentation d√©veloppeur\n\nPour contribuer au projet ou comprendre le fonctionnement interne :\n- [Guide de contribution](docs/contribution-fr.md)\n- [Pipeline CI/CD](docs/ci_implementation-fr.md)\n- [Workflow de preview des PRs](docs/preview_workflow-fr.md)\n- [Workflow de release](docs/release_workflow-fr.md)\n",
      "stars_today": 10
    },
    {
      "id": 552877440,
      "name": "hyperswitch",
      "full_name": "juspay/hyperswitch",
      "description": "An open source payments switch written in Rust to make payments fast, reliable and affordable",
      "html_url": "https://github.com/juspay/hyperswitch",
      "stars": 39288,
      "forks": 4564,
      "language": "Rust",
      "topics": [
        "beginner-friendly",
        "featured",
        "finance",
        "hacktoberfest",
        "high-performance",
        "open-source",
        "orchestration",
        "payments",
        "postgresql",
        "redis",
        "restful-api",
        "rust",
        "sdk",
        "works-with-react"
      ],
      "created_at": "2022-10-17T11:18:28Z",
      "updated_at": "2026-01-14T00:39:51Z",
      "pushed_at": "2026-01-14T00:39:48Z",
      "open_issues": 1368,
      "owner": {
        "login": "juspay",
        "avatar_url": "https://avatars.githubusercontent.com/u/11497632?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"./docs/imgs/hyperswitch-logo-dark.svg#gh-dark-mode-only\" alt=\"Hyperswitch-Logo\" width=\"40%\" />\n  <img src=\"./docs/imgs/hyperswitch-logo-light.svg#gh-light-mode-only\" alt=\"Hyperswitch-Logo\" width=\"40%\" />\n</p>\n\n<h1 align=\"center\">Composable Open-Source Payments Infrastructure</h1>\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/gifs/quickstart.gif\" alt=\"Quickstart demo\" />\n</p>\n\n\n<!-- @import \"[TOC]\" {cmd=\"toc\" depthFrom=1 depthTo=6 orderedList=false} -->\n\n<p align=\"center\">\n  <a href=\"https://github.com/juspay/hyperswitch/actions?query=workflow%3ACI+branch%3Amain\">\n    <img src=\"https://github.com/juspay/hyperswitch/workflows/CI-push/badge.svg\" />\n  </a>\n  <a href=\"https://github.com/juspay/hyperswitch/blob/main/LICENSE\">\n    <img src=\"https://img.shields.io/github/license/juspay/hyperswitch\" />\n  </a>\n  <a href=\"https://github.com/juspay/hyperswitch/blob/main/LICENSE\">\n    <img src=\"https://img.shields.io/badge/Made_in-Rust-orange\" />\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://www.linkedin.com/company/hyperswitch/\">\n    <img src=\"https://img.shields.io/badge/follow-hyperswitch-blue?logo=linkedin&labelColor=grey\"/>\n  </a>\n  <a href=\"https://x.com/hyperswitchio\">\n    <img src=\"https://img.shields.io/badge/follow-%40hyperswitchio-white?logo=x&labelColor=grey\"/>\n  </a>\n  <a href=\"https://inviter.co/hyperswitch-slack\">\n    <img src=\"https://img.shields.io/badge/chat-on_slack-blue?logo=slack&labelColor=grey&color=%233f0e40\"/>\n  </a>\n</p>\n\n<hr/>\n\n<details>\n<summary><strong>üìÅ Table of Contents</strong></summary>\n\n- [What Can I Do with Hyperswitch?](#-what-can-i-do-with-hyperswitch)\n- [Quickstart (Local Setup)](#-quickstart-local-setup)\n- [Cloud Deployment](#cloud-deployment)\n- [Hosted Sandbox (No Setup Required)](#hosted-sandbox-no-setup-required)\n- [Why Hyperswitch?](#-why-hyperswitch)\n- [Architectural Overview](#architectural-overview)\n- [Our Vision](#our-vision)\n- [Community & Contributions](#community--contributions)\n- [Feature Requests & Bugs](#feature-requests--bugs)\n- [Versioning](#versioning)\n- [License](#copyright-and-license)\n- [Team Behind Hyperswitch](#team-behind-hyperswitch)\n\n</details>\n\n<summary><h2> What Can I Do with Hyperswitch?</h2></summary>\n\nHyperswitch offers a modular, open-source payments infrastructure designed for flexibility and control. Apart from our Payment Suite offering, this solution allows businesses to pick and integrate only the modules they need on top of their existing payment stack ‚Äî without unnecessary complexity or vendor lock-in.\n\nEach module is independent and purpose-built to optimize different aspects of payment processing.\n\n<h3> Learn More About The Payment Modules </h3>\n<details>\n\n- **Cost Observability**  \n  Advanced observability tools to audit, monitor, and optimize your payment costs. Detect hidden fees, downgrades, and penalties with self-serve dashboards and actionable insights.  \n  _[Read more](https://docs.hyperswitch.io/about-hyperswitch/payments-modules/ai-powered-cost-observability)_\n\n- **Revenue Recovery**  \n  Combat passive churn with intelligent retry strategies tuned by card bin, region, method, and more. Offers fine-grained control over retry algorithms, penalty budgets, and recovery transparency.  \n  _[Read more](https://docs.hyperswitch.io/about-hyperswitch/payments-modules/revenue-recovery)_\n\n- **Vault**  \n  A PCI-compliant vault service to store cards, tokens, wallets, and bank credentials. Provides a unified, secure, and reusable store of customer-linked payment methods.  \n  _[Read more](https://docs.hyperswitch.io/about-hyperswitch/payments-modules/vault)_\n\n- **Intelligent Routing**  \n  Route each transaction to the PSP with the highest predicted auth rate. Reduce retries, avoid downtime, and minimize latency while maximizing first attempt success.  \n  _[Read more](https://docs.hyperswitch.io/about-hyperswitch/payments-modules/intelligent-routing)_\n\n- **Reconciliation**  \n  Automate 2-way and 3-way reconciliation with backdated support, staggered scheduling, and customizable outputs. Reduces manual ops effort and increases audit confidence.  \n  _[Read more](https://docs.hyperswitch.io/about-hyperswitch/payments-modules/reconciliation)_\n\n- **Alternate Payment Methods**  \n  Drop-in widgets for PayPal, Apple Pay, Google Pay, Samsung Pay, Pay by Bank, and BNPL providers like Klarna. Maximizes conversions with seamless one-click checkout.  \n  _[Read more](https://docs.hyperswitch.io/about-hyperswitch/payments-modules/enable-alternate-payment-method-widgets)_\n\n</details>\n\n## Quickstart \n\n<h3> Local Setup via Docker </h3>\n\n```bash\n# One-click local setup\n\ngit clone --depth 1 --branch latest https://github.com/juspay/hyperswitch\n\ncd hyperswitch\n\nscripts/setup.sh\n```\n<details>\n  <summary><strong>This script: </strong></summary>\n\n  - Detects Docker/Podman  \n  - Offers multiple deployment profiles:\n    - **Standard**: App server + Control Center  \n    - **Full**: Includes monitoring + schedulers  \n    - **Minimal**: Standalone App server  \n  - Provides access links when done\n\n  If you need further help, check out our [video tutorial](https://docs.hyperswitch.io/hyperswitch-open-source/overview/unified-local-setup-using-docker).  \n\n  üëâ After setup, [configure a connector](https://docs.hyperswitch.io/hyperswitch-open-source/account-setup/using-hyperswitch-control-center#add-a-payment-processor) and [test a payment](https://docs.hyperswitch.io/hyperswitch-open-source/account-setup/test-a-payment).\n</details>\n\n\n<h3>Hosted Sandbox (No Setup Required)</h3>\n\nHyperswitch offers a fully hosted sandbox environment that requires no setup. You can explore the Control Center, configure payment connectors, and test payments directly from the UI.\n\n   <a href=\"https://app.hyperswitch.io\">\n     <img src=\"https://github.com/juspay/hyperswitch/blob/main/docs/imgs/try-the-sandbox.png?raw=true\" height=\"35\">\n   </a>\n\n\n<details>\n  <summary><strong> What you can do in the Hosted Sandbox</strong></summary>\n\n  - Access the full Control Center  \n  - Configure payment connectors  \n  - View logs, routing rules, and retry strategies  \n  - Try payments directly from the UI  \n</details>\n\n<h3><strong>Cloud Deployment</strong></h3>\n\nYou can deploy to AWS, GCP, or Azure using Helm or CDK scripts. Fastest path:\n\nClick to deploy via AWS:\n\n   <a href=\"https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=HyperswitchBootstarp&templateURL=https://hyperswitch-synth.s3.eu-central-1.amazonaws.com/hs-starter-config.yaml\">\n     <img src=\"https://github.com/juspay/hyperswitch/blob/main/docs/imgs/aws_button.png?raw=true\" height=\"35\">\n   </a>\n\n<details>\n  <summary><strong>Cloud Deployment Instructions</strong></summary>\n\n  1. Click the AWS deployment button above to launch the stack.  \n  2. Follow the guided steps in the AWS Console (approx. 30‚Äì45 mins).  \n\n  ‚úÖ This setup provisions Hyperswitch on your cloud account using CloudFormation.  \n\n  üìò For full instructions and Helm-based deployments, check out the  \n  <a href=\"https://docs.hyperswitch.io/hyperswitch-open-source/deploy-on-kubernetes-using-helm\">Cloud Install Guide</a>.\n</details>\n\n\n<a href=\"#architectural-overview\">\n  <h2 id=\"architectural-overview\">Architectural Overview</h2>\n</a>\n<img src=\"./docs/imgs/features.png\" />\n<img src=\"./docs/imgs/non-functional-features.png\" />\n<img src=\"./docs/imgs/hyperswitch-architecture-v1.png\" />\n\n## Why Hyperswitch?\n\nHyperswitch is a commercial open-source payments stack purpose-built for scale, flexibility, and developer experience. Designed with a modular architecture, Hyperswitch lets you pick only the components you need‚Äîwhether it‚Äôs routing, retries, vaulting, or observability‚Äîwithout vendor lock-in or bloated integrations.\n\nBuilt in Rust for performance and reliability, Hyperswitch supports global payment methods (cards, wallets, BNPL, UPI, Pay by Bank), exposes smart routing and retry logic, and provides a visual workflow builder in the Control Center. Whether you're integrating a full payment suite or augmenting an existing stack with a single module, Hyperswitch meets you where you are.\n\n<strong>‚ÄúLinux for Payments‚Äù</strong> ‚Äî Hyperswitch is a well-architected reference for teams who want to own their payments stack.\n\nWe believe in:\n\n- <strong> Embracing Payment Diversity:</strong> Innovation comes from enabling choice‚Äîacross payment methods, processors, and flows.\n\n- <strong> Open Source by Default:</strong> Transparency drives trust and builds better, reusable software.\n\n- <strong> Community-Driven Development:</strong> Our roadmap is shaped by real-world use cases and contributors. \n\n- <strong> Systems-Level Engineering:</strong> We hold ourselves to a high bar for reliability, security, and performance.\n\n- <strong> Maximizing Value Creation:</strong> For developers, customers, and partners alike.\n\n- <strong> Community-Driven, Enterprise-Tested:</strong> Hyperswitch is built in the open with real-world feedback from developers and contributors, and maintained by Juspay, the team powering payment infrastructure for 400+ leading enterprises worldwide.\n\n## Contributing\n\nWe welcome contributors from around the world to help build Hyperswitch. Whether you're fixing bugs, improving documentation, or adding new features, your help is appreciated.\n\nPlease read our [contributing guidelines](https://github.com/juspay/hyperswitch/blob/main/docs/CONTRIBUTING.md) to get started.\n\nJoin the conversation on [Slack](https://inviter.co/hyperswitch-slack) or explore open issues on [GitHub](https://github.com/juspay/hyperswitch/issues).\n\n<a href=\"#feature-requests\">\n  <h2 id=\"feature-requests\">Feature requests & Bugs</h2>\n</a>\n\nFor new product features, enhancements, roadmap discussions, or to share queries and ideas, visit our [GitHub Discussions](https://github.com/juspay/hyperswitch/discussions)\n\nFor reporting a bug, please read the issue guidelines and search for [existing and closed issues](https://github.com/juspay/hyperswitch/issues). If your problem or idea is not addressed yet, please [open a new issue](https://github.com/juspay/hyperswitch/issues/new/choose).\n\n<a href=\"#versioning\">\n  <h2 id=\"versioning\">Versioning</h2>\n</a>\n\nCheck the [CHANGELOG.md](./CHANGELOG.md) file for details.\n\n<a href=\"#copyright-and-license\">\n  <h2 id=\"copyright-and-license\">Copyright and License</h2>\n</a>\n\nThis product is licensed under the [Apache 2.0 License](LICENSE).\n\n<a href=\"#team-behind-hyperswitch\">\n  <h2 id=\"team-behind-hyperswitch\">Team behind Hyperswitch</h2>\n</a>\n\nThe core team of 150+ engineers building Hyperswitch. Keep up the great work! ü•Ç\n\n<a href=\"https://github.com/juspay/hyperswitch/graphs/contributors\">\n  <img src=\"https://contributors-img.web.app/image?repo=juspay/hyperswitch\" alt=\"Contributors\"/>\n</a>\n",
      "stars_today": 9
    },
    {
      "id": 99919302,
      "name": "doris",
      "full_name": "apache/doris",
      "description": "Apache Doris is an easy-to-use, high performance and unified analytics database.",
      "html_url": "https://github.com/apache/doris",
      "stars": 14875,
      "forks": 3681,
      "language": "Java",
      "topics": [
        "agent",
        "ai",
        "bigquery",
        "database",
        "dbt",
        "delta-lake",
        "elt",
        "hudi",
        "iceberg",
        "lakehouse",
        "olap",
        "paimon",
        "query-engine",
        "real-time",
        "redshift",
        "snowflake",
        "spark",
        "sql"
      ],
      "created_at": "2017-08-10T12:13:30Z",
      "updated_at": "2026-01-13T13:31:43Z",
      "pushed_at": "2026-01-13T15:38:59Z",
      "open_issues": 770,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "<!--\nLicensed to the Apache Software Foundation (ASF) under one\nor more contributor license agreements.  See the NOTICE file\ndistributed with this work for additional information\nregarding copyright ownership.  The ASF licenses this file\nto you under the Apache License, Version 2.0 (the\n\"License\"); you may not use this file except in compliance\nwith the License.  You may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing,\nsoftware distributed under the License is distributed on an\n\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\nKIND, either express or implied.  See the License for the\nspecific language governing permissions and limitations\nunder the License.\n-->\n\n## üåç Read this in other languages\n\n[English](README.md) ‚Ä¢ [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](docs/ar-SA/README.md) ‚Ä¢ [‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ](docs/bn-BD/README.md) ‚Ä¢ [Deutsch](docs/de-DE/README.md) ‚Ä¢ [Espa√±ol](docs/es-ES/README.md) ‚Ä¢ [ŸÅÿßÿ±ÿ≥€å](docs/fa-IR/README.md) ‚Ä¢ [Fran√ßais](docs/fr-FR/README.md) ‚Ä¢ [‡§π‡§ø‡§®‡•ç‡§¶‡•Ä](docs/hi-IN/README.md) ‚Ä¢ [Bahasa Indonesia](docs/id-ID/README.md) ‚Ä¢ [Italiano](docs/it-IT/README.md) ‚Ä¢ [Êó•Êú¨Ë™û](docs/ja-JP/README.md) ‚Ä¢ [ÌïúÍµ≠Ïñ¥](docs/ko-KR/README.md) ‚Ä¢ [Polski](docs/pl-PL/README.md) ‚Ä¢ [Portugu√™s](docs/pt-BR/README.md) ‚Ä¢ [Rom√¢nƒÉ](docs/ro-RO/README.md) ‚Ä¢ [–†—É—Å—Å–∫–∏–π](docs/ru-RU/README.md) ‚Ä¢ [Sloven≈°ƒçina](docs/sl-SI/README.md) ‚Ä¢ [‡πÑ‡∏ó‡∏¢](docs/th-TH/README.md) ‚Ä¢ [T√ºrk√ße](docs/tr-TR/README.md) ‚Ä¢ [–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞](docs/uk-UA/README.md) ‚Ä¢ [Ti·∫øng Vi·ªát](docs/vi-VN/README.md) ‚Ä¢ [ÁÆÄ‰Ωì‰∏≠Êñá](docs/zh-CN/README.md) ‚Ä¢ [ÁπÅÈ´î‰∏≠Êñá](docs/zh-TW/README.md)\n\n<div align=\"center\">\n\n# Apache Doris\n\n[![License](https://img.shields.io/badge/license-Apache%202-4EB1BA.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)\n[![GitHub release](https://img.shields.io/github/release/apache/doris.svg)](https://github.com/apache/doris/releases)\n[![OSSRank](https://shields.io/endpoint?url=https://ossrank.com/shield/516)](https://ossrank.com/p/516)\n[![Commit activity](https://img.shields.io/github/commit-activity/m/apache/doris)](https://github.com/apache/doris/commits/master/)\n[![EN doc](https://img.shields.io/badge/Docs-English-blue.svg)](https://doris.apache.org/docs/gettingStarted/what-is-apache-doris)\n[![CN doc](https://img.shields.io/badge/ÊñáÊ°£-‰∏≠ÊñáÁâà-blue.svg)](https://doris.apache.org/zh-CN/docs/gettingStarted/what-is-apache-doris)\n\n<div>\n\n[![Official Website](<https://img.shields.io/badge/-Visit%20the%20Official%20Website%20%E2%86%92-rgb(15,214,106)?style=for-the-badge>)](https://doris.apache.org/)\n[![Quick Download](<https://img.shields.io/badge/-Quick%20%20Download%20%E2%86%92-rgb(66,56,255)?style=for-the-badge>)](https://doris.apache.org/download)\n\n\n</div>\n\n\n<div>\n    <a href=\"https://twitter.com/doris_apache\"><img src=\"https://img.shields.io/badge/- @Doris_Apache -424549?style=social&logo=x\" height=25></a>\n    &nbsp;\n    <a href=\"https://github.com/apache/doris/discussions\"><img src=\"https://img.shields.io/badge/- Discussion -red?style=social&logo=discourse\" height=25></a>\n    &nbsp;\n    <a href=\"https://doris.apache.org/slack\" height=25></a>\n    &nbsp;\n    <a href=\"https://medium.com/@ApacheDoris\"><img src=\"https://img.shields.io/badge/-Medium-red?style=social&logo=medium\" height=25></a>\n\n</div>\n\n</div>\n\n---\n\n<p align=\"center\">\n\n  <a href=\"https://trendshift.io/repositories/1156\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/1156\" alt=\"apache%2Fdoris | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\n</p>\n\n\n\n\nApache Doris is an easy-to-use, high-performance and real-time analytical database based on MPP architecture, known for its extreme speed and ease of use. It only requires a sub-second response time to return query results under massive data and can support not only high-concurrency point query scenarios but also high-throughput complex analysis scenarios.\n\nAll this makes Apache Doris an ideal tool for scenarios including report analysis, ad-hoc query, unified data warehouse, and data lake query acceleration. On Apache Doris, users can build various applications, such as user behavior analysis, AB test platform, log retrieval analysis, user portrait analysis, and order analysis.\n\nüéâ Check out the üîó[All releases](https://doris.apache.org/docs/releasenotes/all-release), where you'll find a chronological summary of Apache Doris versions released over the past year.\n\nüëÄ Explore the üîó[Official Website](https://doris.apache.org/) to discover Apache Doris's core features, blogs, and user cases in detail.\n\n## üìà Usage Scenarios\n\nAs shown in the figure below, after various data integration and processing, the data sources are usually stored in the real-time data warehouse Apache Doris and the offline data lake or data warehouse (in Apache Hive, Apache Iceberg or Apache Hudi).\n\n<br />\n\n<img src=\"https://cdn.selectdb.com/static/What_is_Apache_Doris_3_a61692c2ce.png\" />\n\n<br />\n\n\nApache Doris is widely used in the following scenarios:\n\n- **Real-time Data Analysis**:\n\n  - **Real-time Reporting and Decision-making**: Doris provides real-time updated reports and dashboards for both internal and external enterprise use, supporting real-time decision-making in automated processes.\n  \n  - **Ad Hoc Analysis**: Doris offers multidimensional data analysis capabilities, enabling rapid business intelligence analysis and ad hoc queries to help users quickly uncover insights from complex data.\n  \n  - **User Profiling and Behavior Analysis**: Doris can analyze user behaviors such as participation, retention, and conversion, while also supporting scenarios like population insights and crowd selection for behavior analysis.\n\n- **Lakehouse Analytics**:\n\n  - **Lakehouse Query Acceleration**: Doris accelerates lakehouse data queries with its efficient query engine.\n  \n  - **Federated Analytics**: Doris supports federated queries across multiple data sources, simplifying architecture and eliminating data silos.\n  \n  - **Real-time Data Processing**: Doris combines real-time data streams and batch data processing capabilities to meet the needs of high concurrency and low-latency complex business requirements.\n\n- **SQL-based Observability**:\n\n  - **Log and Event Analysis**: Doris enables real-time or batch analysis of logs and events in distributed systems, helping to identify issues and optimize performance.\n\n\n## Overall Architecture\n\nApache Doris uses the MySQL protocol, is highly compatible with MySQL syntax, and supports standard SQL. Users can access Apache Doris through various client tools, and it seamlessly integrates with BI tools.\n\n### Storage-Compute Integrated Architecture\n\nThe storage-compute integrated architecture of Apache Doris is streamlined and easy to maintain. As shown in the figure below, it consists of only two types of processes:\n\n- **Frontend (FE):** Primarily responsible for handling user requests, query parsing and planning, metadata management, and node management tasks.\n\n- **Backend (BE):** Primarily responsible for data storage and query execution. Data is partitioned into shards and stored with multiple replicas across BE nodes.\n\n![The overall architecture of Apache Doris](https://cdn.selectdb.com/static/What_is_Apache_Doris_adb26397e2.png)\n\n<br />\n\nIn a production environment, multiple FE nodes can be deployed for disaster recovery. Each FE node maintains a full copy of the metadata. The FE nodes are divided into three roles:\n\n| Role      | Function                                                     |\n| --------- | ------------------------------------------------------------ |\n| Master    | The FE Master node is responsible for metadata read and write operations. When metadata changes occur in the Master, they are synchronized to Follower or Observer nodes via the BDB JE protocol. |\n| Follower  | The Follower node is responsible for reading metadata. If the Master node fails, a Follower node can be selected as the new Master. |\n| Observer  | The Observer node is responsible for reading metadata and is mainly used to increase query concurrency. It does not participate in cluster leadership elections. |\n\nBoth FE and BE processes are horizontally scalable, enabling a single cluster to support hundreds of machines and tens of petabytes of storage capacity. The FE and BE processes use a consistency protocol to ensure high availability of services and high reliability of data. The storage-compute integrated architecture is highly integrated, significantly reducing the operational complexity of distributed systems.\n\n\n## Core Features of Apache Doris\n\n- **High Availability**: In Apache Doris, both metadata and data are stored with multiple replicas, synchronizing data logs via the quorum protocol. Data write is considered successful once a majority of replicas have completed the write, ensuring that the cluster remains available even if a few nodes fail. Apache Doris supports both same-city and cross-region disaster recovery, enabling dual-cluster master-slave modes. When some nodes experience failures, the cluster can automatically isolate the faulty nodes, preventing the overall cluster availability from being affected.\n\n- **High Compatibility**: Apache Doris is highly compatible with the MySQL protocol and supports standard SQL syntax, covering most MySQL and Hive functions. This high compatibility allows users to seamlessly migrate and integrate existing applications and tools. Apache Doris supports the MySQL ecosystem, enabling users to connect Doris using MySQL Client tools for more convenient operations and maintenance. It also supports MySQL protocol compatibility for BI reporting tools and data transmission tools, ensuring efficiency and stability in data analysis and data transmission processes.\n\n- **Real-Time Data Warehouse**: Based on Apache Doris, a real-time data warehouse service can be built. Apache Doris offers second-level data ingestion capabilities, capturing incremental changes from upstream online transactional databases into Doris within seconds. Leveraging vectorized engines, MPP architecture, and Pipeline execution engines, Doris provides sub-second data query capabilities, thereby constructing a high-performance, low-latency real-time data warehouse platform.\n\n- **Unified Lakehouse**: Apache Doris can build a unified lakehouse architecture based on external data sources such as data lakes or relational databases. The Doris unified lakehouse solution enables seamless integration and free data flow between data lakes and data warehouses, helping users directly utilize data warehouse capabilities to solve data analysis problems in data lakes while fully leveraging data lake data management capabilities to enhance data value.\n\n- **Flexible Modeling**: Apache Doris offers various modeling approaches, such as wide table models, pre-aggregation models, star/snowflake schemas, etc. During data import, data can be flattened into wide tables and written into Doris through compute engines like Flink or Spark, or data can be directly imported into Doris, performing data modeling operations through views, materialized views, or real-time multi-table joins.\n\n## Technical overview\n\nDoris provides an efficient SQL interface and is fully compatible with the MySQL protocol. Its query engine is based on an MPP (Massively Parallel Processing) architecture, capable of efficiently executing complex analytical queries and achieving low-latency real-time queries. Through columnar storage technology for data encoding and compression, it significantly optimizes query performance and storage compression ratio.\n\n### Interface\n\nApache Doris adopts the MySQL protocol, supports standard SQL, and is highly compatible with MySQL syntax. Users can access Apache Doris through various client tools and seamlessly integrate it with BI tools, including but not limited to Smartbi, DataEase, FineBI, Tableau, Power BI, and Apache Superset. Apache Doris can work as the data source for any BI tools that support the MySQL protocol.\n\n### Storage engine\n\nApache Doris has a columnar storage engine, which encodes, compresses, and reads data by column. This enables a very high data compression ratio and largely reduces unnecessary data scanning, thus making more efficient use of IO and CPU resources.\n\nApache Doris supports various index structures to minimize data scans:\n\n- **Sorted Compound Key Index**: Users can specify three columns at most to form a compound sort key. This can effectively prune data to better support highly concurrent reporting scenarios.\n\n- **Min/Max Index**: This enables effective data filtering in equivalence and range queries of numeric types.\n\n- **BloomFilter Index**: This is very effective in equivalence filtering and pruning of high-cardinality columns.\n\n- **Inverted Index**: This enables fast searching for any field.\n\nApache Doris supports a variety of data models and has optimized them for different scenarios:\n\n- **Detail Model (Duplicate Key Model):** A detail data model designed to meet the detailed storage requirements of fact tables.\n\n- **Primary Key Model (Unique Key Model):** Ensures unique keys; data with the same key is overwritten, enabling row-level data updates.\n\n- **Aggregate Model (Aggregate Key Model):** Merges value columns with the same key, significantly improving performance through pre-aggregation.\n\nApache Doris also supports strongly consistent single-table materialized views and asynchronously refreshed multi-table materialized views. Single-table materialized views are automatically refreshed and maintained by the system, requiring no manual intervention from users. Multi-table materialized views can be refreshed periodically using in-cluster scheduling or external scheduling tools, reducing the complexity of data modeling.\n\n### üîç Query Engine\n\nApache Doris has an MPP-based query engine for parallel execution between and within nodes. It supports distributed shuffle join for large tables to better handle complicated queries.\n\n<br />\n\n![Query Engine](https://cdn.selectdb.com/static/What_is_Apache_Doris_1_c6f5ba2af9.png)\n\n<br />\n\nThe query engine of Apache Doris is fully vectorized, with all memory structures laid out in a columnar format. This can largely reduce virtual function calls, increase cache hit rates, and make efficient use of SIMD instructions. Apache Doris delivers a 5~10 times higher performance in wide table aggregation scenarios than non-vectorized engines.\n\n<br />\n\n![Doris query engine](https://cdn.selectdb.com/static/What_is_Apache_Doris_2_29cf58cc6b.png)\n\n<br />\n\nApache Doris uses adaptive query execution technology to dynamically adjust the execution plan based on runtime statistics. For example, it can generate a runtime filter and push it to the probe side. Specifically, it pushes the filters to the lowest-level scan node on the probe side, which largely reduces the data amount to be processed and increases join performance. The runtime filter of Apache Doris supports In/Min/Max/Bloom Filter.\n\nApache Doris uses a Pipeline execution engine that breaks down queries into multiple sub-tasks for parallel execution, fully leveraging multi-core CPU capabilities. It simultaneously addresses the thread explosion problem by limiting the number of query threads. The Pipeline execution engine reduces data copying and sharing, optimizes sorting and aggregation operations, thereby significantly improving query efficiency and throughput.\n\nIn terms of the optimizer, Apache Doris employs a combined optimization strategy of CBO (Cost-Based Optimizer), RBO (Rule-Based Optimizer), and HBO (History-Based Optimizer). RBO supports constant folding, subquery rewriting, predicate pushdown, and more. CBO supports join reordering and other optimizations. HBO recommends the optimal execution plan based on historical query information. These multiple optimization measures ensure that Doris can enumerate high-performance query plans across various types of queries.\n\n\n## üéÜ Why choose Apache Doris?\n\n- üéØ **Easy to Use:** Two processes, no other dependencies; online cluster scaling, automatic replica recovery; compatible with MySQL protocol, and using standard SQL.\n\n- üöÄ **High Performance:** Extremely fast performance for low-latency and high-throughput queries with columnar storage engine, modern MPP architecture, vectorized query engine, pre-aggregated materialized view and data index.\n\n- üñ•Ô∏è **Single Unified:** A single system can support real-time data serving, interactive data analysis and offline data processing scenarios.\n\n- ‚öõÔ∏è **Federated Querying:** Supports federated querying of data lakes such as Hive, Iceberg, Hudi, and databases such as MySQL and Elasticsearch.\n\n- ‚è© **Various Data Import Methods:** Supports batch import from HDFS/S3 and stream import from MySQL Binlog/Kafka; supports micro-batch writing through HTTP interface and real-time writing using Insert in JDBC.\n\n- üöô **Rich Ecology:** Spark uses Spark-Doris-Connector to read and write Doris; Flink-Doris-Connector enables Flink CDC to implement exactly-once data writing to Doris; DBT Doris Adapter is provided to transform data in Doris with DBT.\n\n## üôå Contributors\n\n**Apache Doris has graduated from Apache incubator successfully and become a Top-Level Project in June 2022**. \n\nWe deeply appreciate üîó[community contributors](https://github.com/apache/doris/graphs/contributors) for their contribution to Apache Doris.\n\n[![contrib graph](https://contrib.rocks/image?repo=apache/doris)](https://github.com/apache/doris/graphs/contributors)\n\n## üë®‚Äçüë©‚Äçüëß‚Äçüë¶ Users\n\nApache Doris now has a wide user base in China and around the world, and as of today, **Apache Doris is used in production environments in thousands of companies worldwide.** More than 80% of the top 50 Internet companies in China in terms of market capitalization or valuation have been using Apache Doris for a long time, including Baidu, Meituan, Xiaomi, Jingdong, Bytedance, Tencent, NetEase, Kwai, Sina, 360, Mihoyo, and Ke Holdings. It is also widely used in some traditional industries such as finance, energy, manufacturing, and telecommunications.\n\nThe users of Apache Doris: üîó[Users](https://doris.apache.org/users)\n\nAdd your company logo at Apache Doris Website: üîó[Add Your Company](https://github.com/apache/doris/discussions/27683)\n \n## üë£ Get Started\n\n### üìö Docs\n\nAll Documentation   üîó[Docs](https://doris.apache.org/docs/gettingStarted/what-is-apache-doris)  \n\n### ‚¨áÔ∏è Download \n\nAll release and binary version üîó[Download](https://doris.apache.org/download) \n\n### üóÑÔ∏è Compile\n\nSee how to compile  üîó[Compilation](https://doris.apache.org/community/source-install/compilation-with-docker))\n\n### üìÆ Install\n\nSee how to install and deploy üîó[Installation and deployment](https://doris.apache.org/docs/install/preparation/env-checking) \n\n## üß© Components\n\n### üìù Doris Connector\n\nDoris provides support for Spark/Flink to read data stored in Doris through Connector, and also supports to write data to Doris through Connector.\n\nüîó[apache/doris-flink-connector](https://github.com/apache/doris-flink-connector)\n\nüîó[apache/doris-spark-connector](https://github.com/apache/doris-spark-connector)\n\n\n## üåà Community and Support\n\n### üì§ Subscribe Mailing Lists\n\nMail List is the most recognized form of communication in Apache community. See how to üîó[Subscribe Mailing Lists](https://doris.apache.org/community/subscribe-mail-list)\n\n### üôã Report Issues or Submit Pull Request\n\nIf you meet any questions, feel free to file a üîó[GitHub Issue](https://github.com/apache/doris/issues) or post it in üîó[GitHub Discussion](https://github.com/apache/doris/discussions) and fix it by submitting a üîó[Pull Request](https://github.com/apache/doris/pulls) \n\n### üçª How to Contribute\n\nWe welcome your suggestions, comments (including criticisms), comments and contributions. See üîó[How to Contribute](https://doris.apache.org/community/how-to-contribute/) and üîó[Code Submission Guide](https://doris.apache.org/community/how-to-contribute/pull-request/)\n\n### ‚å®Ô∏è Doris Improvement Proposals (DSIP)\n\nüîó[Doris Improvement Proposal (DSIP)](https://cwiki.apache.org/confluence/display/DORIS/Doris+Improvement+Proposals) can be thought of as **A Collection of Design Documents for all Major Feature Updates or Improvements**.\n\n### üîë Backend C++ Coding Specification\nüîó [Backend C++ Coding Specification](https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=240883637) should be strictly followed, which will help us achieve better code quality.\n\n## üí¨ Contact Us\n\nContact us through the following mailing list.\n\n| Name                                                                          | Scope                           |                                                                 |                                                                     |                                                                              |\n|:------------------------------------------------------------------------------|:--------------------------------|:----------------------------------------------------------------|:--------------------------------------------------------------------|:-----------------------------------------------------------------------------|\n| [dev@doris.apache.org](mailto:dev@doris.apache.org)     | Development-related discussions | [Subscribe](mailto:dev-subscribe@doris.apache.org)   | [Unsubscribe](mailto:dev-unsubscribe@doris.apache.org)   | [Archives](http://mail-archives.apache.org/mod_mbox/doris-dev/)   |\n\n## üß∞ Links\n\n* Apache Doris Official Website - [Site](https://doris.apache.org)\n* Developer Mailing list - <dev@doris.apache.org>. Mail to <dev-subscribe@doris.apache.org>, follow the reply to subscribe the mail list.\n* Slack channel - [Join the Slack](https://doris.apache.org/slack)\n* Twitter - [Follow @doris_apache](https://twitter.com/doris_apache)\n\n\n## üìú License\n\n[Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0)\n\n> **Note**\n> Some licenses of the third-party dependencies are not compatible with Apache 2.0 License. So you need to disable\nsome Doris features to be complied with Apache 2.0 License. For details, refer to the `thirdparty/LICENSE.txt`\n\n\n\n",
      "stars_today": 9
    },
    {
      "id": 166515022,
      "name": "trino",
      "full_name": "trinodb/trino",
      "description": "Official repository of Trino, the distributed SQL query engine for big data, formerly known as PrestoSQL (https://trino.io)",
      "html_url": "https://github.com/trinodb/trino",
      "stars": 12410,
      "forks": 3445,
      "language": "Java",
      "topics": [
        "analytics",
        "big-data",
        "data-science",
        "database",
        "databases",
        "datalake",
        "delta-lake",
        "distributed-database",
        "distributed-systems",
        "hadoop",
        "hive",
        "iceberg",
        "java",
        "jdbc",
        "presto",
        "prestodb",
        "query-engine",
        "sql",
        "trino"
      ],
      "created_at": "2019-01-19T06:38:14Z",
      "updated_at": "2026-01-13T20:30:04Z",
      "pushed_at": "2026-01-14T00:16:44Z",
      "open_issues": 2502,
      "owner": {
        "login": "trinodb",
        "avatar_url": "https://avatars.githubusercontent.com/u/34147222?v=4"
      },
      "readme": "<p align=\"center\">\n    <a href=\"https://trino.io/\"><img alt=\"Trino Logo\" src=\".github/homepage.png\" /></a>\n</p>\n<p align=\"center\">\n    <b>Trino is a fast distributed SQL query engine for big data analytics.</b>\n</p>\n<p align=\"center\">\n    See the <a href=\"https://trino.io/docs/current/\">User Manual</a> for deployment instructions and end user documentation.\n</p>\n<p align=\"center\">\n  <a href=\"https://trino.io/download.html\" style=\"text-decoration: none\"><img\n    src=\"https://img.shields.io/github/v/release/trinodb/trino\"\n    alt=\"Trino download\"\n  /></a>\n  <a href=\"https://github.com/jvm-repo-rebuild/reproducible-central/blob/master/content/io/trino/README.md\" style=\"text-decoration: none\"><img\n    src=\"https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/jvm-repo-rebuild/reproducible-central/master/content/io/trino/badge.json\"\n    alt=\"Reproducible builds supported\"\n  /></a>\n  <a href=\"https://trino.io/slack.html\" style=\"text-decoration: none\"><img\n    src=\"https://img.shields.io/static/v1?logo=slack&logoColor=959DA5&label=Slack&labelColor=333a41&message=join%20conversation&color=3AC358\"\n    alt=\"Trino Slack\"\n  /></a>\n  <a href=\"https://trino.io/trino-the-definitive-guide.html\" style=\"text-decoration: none\"><img\n    src=\"https://img.shields.io/badge/Trino%3A%20The%20Definitive%20Guide-download-brightgreen\"\n    alt=\"Trino: The Definitive Guide book download\"\n  /></a>\n</p>\n\n## Development\n\nSee [DEVELOPMENT](.github/DEVELOPMENT.md) for information about development and release process,\ncode style and guidelines for implementors of Trino plugins.\n\nSee [CONTRIBUTING](.github/CONTRIBUTING.md) for contribution requirements.\n\n## Security\n\nSee the project [security policy](.github/SECURITY.md) for\ninformation about reporting vulnerabilities.\n\nTrino supports [reproducible builds](https://reproducible-builds.org) as of version 449.\n\n## Build requirements\n\n* Mac OS X or Linux\n  * Note that some npm packages used to build the web UI are only available\n    for x86 architectures, so if you're building on Apple Silicon, you need \n    to have Rosetta 2 installed\n* Java 25.0.1+, 64-bit\n* Docker\n  * Turn SELinux or other systems disabling write access to the local checkout\n    off, to allow containers to mount parts of the Trino source tree\n\n## Building Trino\n\nTrino is a standard Maven project. Simply run the following command from the\nproject root directory:\n\n    ./mvnw clean install -DskipTests\n\nOn the first build, Maven downloads all the dependencies from the internet\nand caches them in the local repository (`~/.m2/repository`), which can take a\nwhile, depending on your connection speed. Subsequent builds are faster.\n\nTrino has a comprehensive set of tests that take a considerable amount of time\nto run, and are thus disabled by the above command. These tests are run by the\nCI system when you submit a pull request. We recommend only running tests\nlocally for the areas of code that you change.\n\n## Running Trino in your IDE\n\n### Overview\n\nAfter building Trino for the first time, you can load the project into your IDE\nand run the server.  We recommend using\n[IntelliJ IDEA](http://www.jetbrains.com/idea/). Because Trino is a standard\nMaven project, you easily can import it into your IDE.  In IntelliJ, choose\n*Open Project* from the *Quick Start* box or choose *Open*\nfrom the *File* menu and select the root `pom.xml` file.\n\nAfter opening the project in IntelliJ, double check that the Java SDK is\nproperly configured for the project:\n\n* Open the File menu and select Project Structure\n* In the SDKs section, ensure that JDK 25 is selected (create one if none exist)\n* In the Project section, ensure the Project language level is set to 25\n\n### Running a testing server\n\nThe simplest way to run Trino for development is to run the `TpchQueryRunner`\nclass. It will start a development version of the server that is configured with\nthe TPCH connector. You can then use the CLI to execute queries against this\nserver. Many other connectors have their own `*QueryRunner` class that you can\nuse when working on a specific connector.\n\n### Running the full server\n\nTrino comes with sample configuration that should work out-of-the-box for\ndevelopment. Use the following options to create a run configuration:\n\n* Main Class: `io.trino.server.DevelopmentServer`\n* VM Options: `-ea -Dconfig=etc/config.properties -Dlog.levels-file=etc/log.properties -Djdk.attach.allowAttachSelf=true --sun-misc-unsafe-memory-access=allow --add-modules jdk.incubator.vector`\n* Working directory: `$MODULE_DIR$`\n* Use classpath of module: `trino-server-dev`\n\nThe working directory should be the `trino-server-dev` subdirectory. In\nIntelliJ, using `$MODULE_DIR$` accomplishes this automatically.\n\nIf `VM options` doesn't exist in the dialog, you need to select `Modify options`\nand enable `Add VM options`.\n\nTo adjust which plugins are enabled for the development server, adjust the value of\n`plugin.bundles` in `config.properties`. Each entry in this list must represent a plugin\nspecified by one of the following options:\n* A path to a `pom.xml` or `*.pom` file describing a Maven project that produces a plugin.\n* Maven coordinates, in the form `<groupId>:<artifactId>[:<extension>[:<classifier>]]:<version>`. The plugin will be loaded via Maven and therefore must be available in your local repository or a remote repository.\n* A path to a plugin directory containing JAR files. See [Deploying a custom plugin](https://trino.io/docs/current/develop/spi-overview.html#deploying-a-custom-plugin) for more details.\n\nIf you want to use a plugin in a catalog, you must add a corresponding\n`<catalog_name>.properties` file to `testing/trino-server-dev/etc/catalog`.\n\n### Running the CLI\n\nStart the CLI to connect to the server and run SQL queries:\n\n    client/trino-cli/target/trino-cli-*-executable.jar\n\nRun a query to see the nodes in the cluster:\n\n    SELECT * FROM system.runtime.nodes;\n\nRun a query against the TPCH connector:\n\n    SELECT * FROM tpch.tiny.region;\n",
      "stars_today": 9
    },
    {
      "id": 860100131,
      "name": "typescript-go",
      "full_name": "microsoft/typescript-go",
      "description": "Staging repo for development of native port of TypeScript",
      "html_url": "https://github.com/microsoft/typescript-go",
      "stars": 23725,
      "forks": 790,
      "language": "Go",
      "topics": [],
      "created_at": "2024-09-19T20:25:12Z",
      "updated_at": "2026-01-14T01:04:10Z",
      "pushed_at": "2026-01-14T00:08:43Z",
      "open_issues": 263,
      "owner": {
        "login": "microsoft",
        "avatar_url": "https://avatars.githubusercontent.com/u/6154722?v=4"
      },
      "readme": "# TypeScript 7\n\n[Not sure what this is? Read the announcement post!](https://devblogs.microsoft.com/typescript/typescript-native-port/)\n\n## Preview\n\nA preview build is available on npm as [`@typescript/native-preview`](https://www.npmjs.com/package/@typescript/native-preview).\n\n```sh\nnpm install @typescript/native-preview\nnpx tsgo # Use this as you would tsc.\n```\n\nA preview VS Code extension is [available on the VS Code marketplace](https://marketplace.visualstudio.com/items?itemName=TypeScriptTeam.native-preview).\n\nTo use this, set this in your VS Code settings:\n\n```json\n{\n    \"typescript.experimental.useTsgo\": true\n}\n```\n\n## What Works So Far?\n\nThis is still a work in progress and is not yet at full feature parity with TypeScript. Bugs may exist. Please check this list carefully before logging a new issue or assuming an intentional change.\n\n| Feature | Status | Notes |\n|---------|--------|-------|\n| Program creation | done | Same files and module resolution as TS 5.9. Not all resolution modes supported yet. |\n| Parsing/scanning | done | Exact same syntax errors as TS 5.9 |\n| Commandline and `tsconfig.json` parsing | done | Done, though `tsconfig` errors may not be as helpful. |\n| Type resolution | done | Same types as TS 5.9. |\n| Type checking | done | Same errors, locations, and messages as TS 5.9. Types printback in errors may display differently. |\n| JavaScript-specific inference and JSDoc | in progress | Mostly complete, but intentionally lacking some features. Declaration emit not complete. |\n| JSX | done | - |\n| Declaration emit | in progress | Most common features are in place, but some edge cases and feature flags are still unhandled. |\n| Emit (JS output) | in progress | `target: esnext` well-supported, other targets may have gaps. |\n| Watch mode | prototype | Watches files and rebuilds, but no incremental rechecking. Not optimized. |\n| Build mode / project references | done | - |\n| Incremental build | done | - |\n| Language service (LSP) | in progress | Most functionality. More features coming soon. |\n| API | not ready | - |\n\nDefinitions:\n\n * **done** aka \"believed done\": We're not currently aware of any deficits or major left work to do. OK to log bugs\n * **in progress**: currently being worked on; some features may work and some might not. OK to log panics, but nothing else please\n * **prototype**: proof-of-concept only; do not log bugs\n * **not ready**: either haven't even started yet, or far enough from ready that you shouldn't bother messing with it yet\n\n## Other Notes\n\nLong-term, we expect that this repo and its contents will be merged into `microsoft/TypeScript`.\nAs a result, the repo and issue tracker for typescript-go will eventually be closed, so treat discussions/issues accordingly.\n\nFor a list of intentional changes with respect to TypeScript 5.9, see CHANGES.md.\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit [Contributor License Agreements](https://cla.opensource.microsoft.com).\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft\ntrademarks or logos is subject to and must follow\n[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general).\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\nAny use of third-party trademarks or logos are subject to those third-party's policies.\n",
      "stars_today": 9
    },
    {
      "id": 55072677,
      "name": "weaviate",
      "full_name": "weaviate/weaviate",
      "description": "Weaviate is an open-source vector database that stores both objects and vectors, allowing for the combination of vector search with structured filtering with the fault tolerance and scalability of a cloud-native database‚Äã.",
      "html_url": "https://github.com/weaviate/weaviate",
      "stars": 15392,
      "forks": 1175,
      "language": "Go",
      "topics": [
        "approximate-nearest-neighbor-search",
        "generative-search",
        "grpc",
        "hnsw",
        "hybrid-search",
        "image-search",
        "information-retrieval",
        "mlops",
        "nearest-neighbor-search",
        "neural-search",
        "recommender-system",
        "search-engine",
        "semantic-search",
        "semantic-search-engine",
        "similarity-search",
        "vector-database",
        "vector-search",
        "vector-search-engine",
        "vectors",
        "weaviate"
      ],
      "created_at": "2016-03-30T15:03:17Z",
      "updated_at": "2026-01-13T23:10:06Z",
      "pushed_at": "2026-01-13T20:39:03Z",
      "open_issues": 555,
      "owner": {
        "login": "weaviate",
        "avatar_url": "https://avatars.githubusercontent.com/u/37794290?v=4"
      },
      "readme": "# Weaviate <img alt='Weaviate logo' src='https://weaviate.io/img/site/weaviate-logo-light.png' width='148' align='right' />\n\n[![GitHub Repo stars](https://img.shields.io/github/stars/weaviate/weaviate?style=social)](https://github.com/weaviate/weaviate)\n[![Go Reference](https://pkg.go.dev/badge/github.com/weaviate/weaviate.svg)](https://pkg.go.dev/github.com/weaviate/weaviate)\n[![Build Status](https://github.com/weaviate/weaviate/actions/workflows/.github/workflows/pull_requests.yaml/badge.svg?branch=main)](https://github.com/weaviate/weaviate/actions/workflows/.github/workflows/pull_requests.yaml)\n[![Go Report Card](https://goreportcard.com/badge/github.com/weaviate/weaviate)](https://goreportcard.com/report/github.com/weaviate/weaviate)\n[![Coverage Status](https://codecov.io/gh/weaviate/weaviate/branch/main/graph/badge.svg)](https://codecov.io/gh/weaviate/weaviate)\n[![Slack](https://img.shields.io/badge/slack--channel-blue?logo=slack)](https://weaviate.io/slack)\n\n**Weaviate** is an open-source, cloud-native vector database that stores both objects and vectors, enabling semantic search at scale. It combines vector similarity search with keyword filtering, retrieval-augmented generation (RAG), and reranking in a single query interface. Common use cases include RAG systems, semantic and image search, recommendation engines, chatbots, and content classification.\n\nWeaviate supports two approaches to store vectors: automatic vectorization at import using [integrated models](https://docs.weaviate.io/weaviate/model-providers) (OpenAI, Cohere, HuggingFace, and others) or direct import of [pre-computed vector embeddings](https://docs.weaviate.io/weaviate/starter-guides/custom-vectors). Production deployments benefit from built-in multi-tenancy, replication, RBAC authorization, and [many other features](#weaviate-features).\n\nTo get started quickly, have a look at one of these tutorials:\n\n- [Quickstart - Weaviate Cloud](https://docs.weaviate.io/weaviate/quickstart)\n- [Quickstart - local Docker instance](https://docs.weaviate.io/weaviate/quickstart/local)\n\n## Installation\n\nWeaviate offers multiple installation and deployment options:\n\n- [Docker](https://docs.weaviate.io/deploy/installation-guides/docker-installation)\n- [Kubernetes](https://docs.weaviate.io/deploy/installation-guides/k8s-installation)\n- [Weaviate Cloud](https://console.weaviate.cloud)\n\nSee the [installation docs](https://docs.weaviate.io/deploy) for more deployment options, such as [AWS](https://docs.weaviate.io/deploy/installation-guides/aws-marketplace) and [GCP](https://docs.weaviate.io/deploy/installation-guides/gcp-marketplace).\n\n## Getting started\n\nYou can easily start Weaviate and a local vector embedding model with [Docker](https://docs.docker.com/desktop/).\nCreate a `docker-compose.yml` file:\n\n```yml\nservices:\n  weaviate:\n    image: cr.weaviate.io/semitechnologies/weaviate:1.32.2\n    ports:\n      - \"8080:8080\"\n      - \"50051:50051\"\n    environment:\n      ENABLE_MODULES: text2vec-model2vec\n      MODEL2VEC_INFERENCE_API: http://text2vec-model2vec:8080\n\n  # A lightweight embedding model that will generate vectors from objects during import\n  text2vec-model2vec:\n    image: cr.weaviate.io/semitechnologies/model2vec-inference:minishlab-potion-base-32M\n```\n\nStart Weaviate and the embedding service with:\n\n```bash\ndocker compose up -d\n```\n\nInstall the Python client (or use another [client library](#client-libraries-and-apis)):\n\n```bash\npip install -U weaviate-client\n```\n\nThe following Python example shows how easy it is to populate a Weaviate database with data, create vector embeddings and perform semantic search:\n\n```python\nimport weaviate\nfrom weaviate.classes.config import Configure, DataType, Property\n\n# Connect to Weaviate\nclient = weaviate.connect_to_local()\n\n# Create a collection\nclient.collections.create(\n    name=\"Article\",\n    properties=[Property(name=\"content\", data_type=DataType.TEXT)],\n    vector_config=Configure.Vectors.text2vec_model2vec(),  # Use a vectorizer to generate embeddings during import\n    # vector_config=Configure.Vectors.self_provided()  # If you want to import your own pre-generated embeddings\n)\n\n# Insert objects and generate embeddings\narticles = client.collections.get(\"Article\")\narticles.data.insert_many(\n    [\n        {\"content\": \"Vector databases enable semantic search\"},\n        {\"content\": \"Machine learning models generate embeddings\"},\n        {\"content\": \"Weaviate supports hybrid search capabilities\"},\n    ]\n)\n\n# Perform semantic search\nresults = articles.query.near_text(query=\"Search objects by meaning\", limit=1)\nprint(results.objects[0])\n\nclient.close()\n```\n\nThis example uses the `Model2Vec` vectorizer, but you can choose any other [embedding model provider](https://docs.weaviate.io/weaviate/model-providers) or [bring your own pre-generated vectors](https://docs.weaviate.io/weaviate/starter-guides/custom-vectors).\n\n## Client libraries and APIs\n\nWeaviate provides client libraries for several programming languages:\n\n- [Python](https://docs.weaviate.io/weaviate/client-libraries/python)\n- [JavaScript/TypeScript](https://docs.weaviate.io/weaviate/client-libraries/typescript)\n- [Java](https://docs.weaviate.io/weaviate/client-libraries/java)\n- [Go](https://docs.weaviate.io/weaviate/client-libraries/go)\n- C# (üöß Coming soon üöß)\n\nThere are also additional [community-maintained libraries](https://docs.weaviate.io/weaviate/client-libraries/community).\n\nWeaviate exposes [REST API](https://docs.weaviate.io/weaviate/api/rest), [gRPC API](https://docs.weaviate.io/weaviate/api/grpc), and [GraphQL API](https://docs.weaviate.io/weaviate/api/graphql) to communicate with the database server.\n\n## Weaviate features\n\nThese features enable you to build AI-powered applications:\n\n- **‚ö° Fast Search Performance**: Perform complex semantic [searches](https://docs.weaviate.io/weaviate/search/similarity) over billions of vectors in milliseconds. Weaviate's architecture is built in Go for speed and reliability, ensuring your AI applications are highly responsive even under heavy load. See our [ANN benchmarks](https://docs.weaviate.io/weaviate/benchmarks/ann) for more info.\n\n- **üîå Flexible Vectorization**: Seamlessly vectorize data at import time with [integrated vectorizers](https://docs.weaviate.io/weaviate/model-providers) from OpenAI, Cohere, HuggingFace, Google, and more. Or you can import [your own vector embeddings](https://docs.weaviate.io/weaviate/starter-guides/custom-vectors).\n\n- **üîç Advanced Hybrid & Image Search**: Combine the power of semantic search with traditional [keyword (BM25) search](https://docs.weaviate.io/weaviate/search/bm25), [image search](https://docs.weaviate.io/weaviate/search/image) and [advanced filtering](https://docs.weaviate.io/weaviate/search/filters) to get the best results with a single API call.\n\n- **ü§ñ Integrated RAG & Reranking**: Go beyond simple retrieval with built-in [generative search (RAG)](https://docs.weaviate.io/weaviate/search/generative) and [reranking](https://docs.weaviate.io/weaviate/search/rerank) capabilities. Power sophisticated Q&A systems, chatbots, and summarizers directly from your database without additional tooling.\n\n- **üìà Production-Ready & Scalable**: Weaviate is built for mission-critical applications. Go from rapid prototyping to production at scale with native support for [horizontal scaling](https://docs.weaviate.io/deploy/configuration/horizontal-scaling), [multi-tenancy](https://docs.weaviate.io/weaviate/manage-collections/multi-tenancy), [replication](https://docs.weaviate.io/deploy/configuration/replication), and fine-grained [role-based access control (RBAC)](https://docs.weaviate.io/weaviate/configuration/rbac).\n\n- **üí∞ Cost-Efficient Operations**: Radically lower resource consumption and operational costs with built-in [vector compression](https://docs.weaviate.io/weaviate/configuration/compression). Vector quantization and multi-vector encoding reduce memory usage with minimal impact on search performance.\n\nFor a complete list of all functionalities, visit the [official Weaviate documentation](https://docs.weaviate.io).\n\n## Useful resources\n\n### Demo projects & recipes\n\nThese demos are working applications that highlight some of Weaviate's capabilities. Their source code is available on GitHub.\n\n- [Elysia](https://elysia.weaviate.io) ([GitHub](https://github.com/weaviate/elysia)): Elysia is a decision tree based agentic system which intelligently decides what tools to use, what results have been obtained, whether it should continue the process or whether its goal has been completed.\n- [Verba](https://weaviate.io/blog/verba-open-source-rag-app) ([GitHub](https://github.com/weaviate/verba)): A community-driven open-source application designed to offer an end-to-end, streamlined, and user-friendly interface for Retrieval-Augmented Generation (RAG) out of the box.\n- [Healthsearch](https://weaviate.io/blog/healthsearch-demo) ([GitHub](https://github.com/weaviate/healthsearch-demo)): An open-source project aimed at showcasing the potential of leveraging user-written reviews and queries to retrieve supplement products based on specific health effects.\n- Awesome-Moviate ([GitHub](https://github.com/weaviate-tutorials/awesome-moviate)): A movie search and recommendation engine that allows keyword-based (BM25), semantic, and hybrid searches.\n\nWe also maintain extensive repositories of **Jupyter Notebooks** and **TypeScript code snippets** that cover how to use Weaviate features and integrations:\n\n- [Weaviate Python Recipes](https://github.com/weaviate/recipes/)\n- [Weaviate TypeScript Recipes](https://github.com/weaviate/recipes-ts/)\n\n### Blog posts\n\n- [What is a Vector Database](https://weaviate.io/blog/what-is-a-vector-database)\n- [What is Vector Search](https://weaviate.io/blog/vector-search-explained)\n- [What is Hybrid Search](https://weaviate.io/blog/hybrid-search-explained)\n- [How to Choose an Embedding Model](https://weaviate.io/blog/how-to-choose-an-embedding-model)\n- [What is RAG](https://weaviate.io/blog/introduction-to-rag)\n- [RAG Evaluation](https://weaviate.io/blog/rag-evaluation)\n- [Advanced RAG Techniques](https://weaviate.io/blog/advanced-rag)\n- [What is Multimodal RAG](https://weaviate.io/blog/multimodal-rag)\n- [What is Agentic RAG](https://weaviate.io/blog/what-is-agentic-rag)\n- [What is Graph RAG](https://weaviate.io/blog/graph-rag)\n- [Overview of Late Interaction Models](https://weaviate.io/blog/late-interaction-overview)\n\n### Integrations\n\nWeaviate integrates with many external services:\n\n| Category                                                                                   | Description                                                | Integrations                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n| ------------------------------------------------------------------------------------------ | ---------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **[Cloud Hyperscalers](https://docs.weaviate.io/integrations/cloud-hyperscalers)**         | Large-scale computing and storage                          | [AWS](https://docs.weaviate.io/integrations/cloud-hyperscalers/aws), [Google](https://docs.weaviate.io/integrations/cloud-hyperscalers/google)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n| **[Compute Infrastructure](https://docs.weaviate.io/integrations/compute-infrastructure)** | Run and scale containerized applications                   | [Modal](https://docs.weaviate.io/integrations/compute-infrastructure/modal), [Replicate](https://docs.weaviate.io/integrations/compute-infrastructure/replicate), [Replicated](https://docs.weaviate.io/integrations/compute-infrastructure/replicated)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n| **[Data Platforms](https://docs.weaviate.io/integrations/data-platforms)**                 | Data ingestion and web scraping                            | [Airbyte](https://docs.weaviate.io/integrations/data-platforms/airbyte), [Aryn](https://docs.weaviate.io/integrations/data-platforms/aryn), [Boomi](https://docs.weaviate.io/integrations/data-platforms/boomi), [Box](https://docs.weaviate.io/integrations/data-platforms/box), [Confluent](https://docs.weaviate.io/integrations/data-platforms/confluent), [Astronomer](https://docs.weaviate.io/integrations/data-platforms/astronomer), [Context Data](https://docs.weaviate.io/integrations/data-platforms/context-data), [Databricks](https://docs.weaviate.io/integrations/data-platforms/databricks), [Firecrawl](https://docs.weaviate.io/integrations/data-platforms/firecrawl), [IBM](https://docs.weaviate.io/integrations/data-platforms/ibm), [Unstructured](https://docs.weaviate.io/integrations/data-platforms/unstructured)                |\n| **[LLM and Agent Frameworks](https://docs.weaviate.io/integrations/llm-agent-frameworks)** | Build agents and generative AI applications                | [Agno](https://docs.weaviate.io/integrations/llm-agent-frameworks/agno), [Composio](https://docs.weaviate.io/integrations/llm-agent-frameworks/composio), [CrewAI](https://docs.weaviate.io/integrations/llm-agent-frameworks/crewai), [DSPy](https://docs.weaviate.io/integrations/llm-agent-frameworks/dspy), [Dynamiq](https://docs.weaviate.io/integrations/llm-agent-frameworks/dynamiq), [Haystack](https://docs.weaviate.io/integrations/llm-agent-frameworks/haystack), [LangChain](https://docs.weaviate.io/integrations/llm-agent-frameworks/langchain), [LlamaIndex](https://docs.weaviate.io/integrations/llm-agent-frameworks/llamaindex), [N8n](https://docs.weaviate.io/integrations/llm-agent-frameworks/n8n), [Semantic Kernel](https://docs.weaviate.io/integrations/llm-agent-frameworks/semantic-kernel)                                   |\n| **[Operations](https://docs.weaviate.io/integrations/operations)**                         | Tools for monitoring and analyzing generative AI workflows | [AIMon](https://docs.weaviate.io/integrations/operations/aimon), [Arize](https://docs.weaviate.io/integrations/operations/arize), [Cleanlab](https://docs.weaviate.io/integrations/operations/cleanlab), [Comet](https://docs.weaviate.io/integrations/operations/comet), [DeepEval](https://docs.weaviate.io/integrations/operations/deepeval), [Langtrace](https://docs.weaviate.io/integrations/operations/langtrace), [LangWatch](https://docs.weaviate.io/integrations/operations/langwatch), [Nomic](https://docs.weaviate.io/integrations/operations/nomic), [Patronus AI](https://docs.weaviate.io/integrations/operations/patronus), [Ragas](https://docs.weaviate.io/integrations/operations/ragas), [TruLens](https://docs.weaviate.io/integrations/operations/trulens), [Weights & Biases](https://docs.weaviate.io/integrations/operations/wandb) |\n\n## Contributing\n\nWe welcome and appreciate contributions! Please see our [Contributor guide](https://docs.weaviate.io/contributor-guide) for the development setup, code style guidelines, testing requirements and the pull request process.\n\nJoin our [Slack community](https://weaviate.io/slack) or [Community forum](https://forum.weaviate.io/) to discuss ideas and get help.\n\n## License\n\nBSD 3-Clause License. See [LICENSE](./LICENSE) for details.\n",
      "stars_today": 9
    },
    {
      "id": 427166323,
      "name": "gyroflow",
      "full_name": "gyroflow/gyroflow",
      "description": "Video stabilization using gyroscope data",
      "html_url": "https://github.com/gyroflow/gyroflow",
      "stars": 8151,
      "forks": 380,
      "language": "Rust",
      "topics": [
        "fpv",
        "gopro",
        "gpu",
        "gpu-computing",
        "gyroscope",
        "insta360",
        "rolling-shutter-undistortion",
        "rust",
        "sony-alpha-cameras",
        "stabilization",
        "video",
        "video-processing"
      ],
      "created_at": "2021-11-11T22:55:00Z",
      "updated_at": "2026-01-14T01:02:09Z",
      "pushed_at": "2026-01-03T21:31:29Z",
      "open_issues": 50,
      "owner": {
        "login": "gyroflow",
        "avatar_url": "https://avatars.githubusercontent.com/u/94141432?v=4"
      },
      "readme": "<p align=\"center\">\n  <h1 align=\"center\">\n    <a href=\"https://github.com/gyroflow/gyroflow#gh-light-mode-only\">\n      <img src=\"./resources/logo_black.svg\" alt=\"Gyroflow logo\" height=\"100\">\n    </a>\n    <a href=\"https://github.com/gyroflow/gyroflow#gh-dark-mode-only\">\n      <img src=\"./resources/logo_white.svg\" alt=\"Gyroflow logo\" height=\"100\">\n    </a>\n  </h1>\n\n  <p align=\"center\">\n    Video stabilization using gyroscope data\n    <br/>\n    <br/>\n    <a href=\"https://gyroflow.xyz\">Homepage</a> ‚Ä¢\n    <a href=\"https://github.com/gyroflow/gyroflow/releases\">Download</a> ‚Ä¢\n    <a href=\"https://docs.gyroflow.xyz\">Documentation</a> ‚Ä¢\n    <a href=\"https://discord.gg/YaUtNpWTUh\">Discord</a> ‚Ä¢\n    <a href=\"https://github.com/gyroflow/gyroflow/issues\">Report bug</a> ‚Ä¢\n    <a href=\"https://github.com/gyroflow/gyroflow/issues\">Request feature</a>\n  </p>\n  <p align=\"center\">\n    <a href=\"https://github.com/gyroflow/gyroflow/releases\">\n      <img src=\"https://img.shields.io/github/downloads/gyroflow/gyroflow/total\" alt=\"Downloads\">\n    </a>\n    <a href=\"https://github.com/gyroflow/gyroflow/graphs/contributors\">\n      <img src=\"https://img.shields.io/github/contributors/gyroflow/gyroflow?color=dark-green\" alt=\"Contributors\">\n    </a>\n    <a title=\"Crowdin\" target=\"_blank\" href=\"https://crowdin.com/project/gyroflow\"><img src=\"https://badges.crowdin.net/gyroflow/localized.svg\">\n    </a>\n    <a href=\"https://github.com/gyroflow/gyroflow/issues/\">\n      <img src=\"https://img.shields.io/github/issues/gyroflow/gyroflow\" alt=\"Issues\">\n    </a>\n    <a href=\"https://github.com/gyroflow/gyroflow/blob/master/LICENSE\">\n      <img src=\"https://img.shields.io/github/license/gyroflow/gyroflow\" alt=\"License\">\n    </a>\n    <a href=\"https://gurubase.io/g/gyroflow\">\n      <img src=\"https://img.shields.io/badge/Gurubase-Ask%20Gyroflow%20Guru-006BFF\" alt=\"Gurubase\">\n    </a>\n  </p>\n</p>\n\n## About the project\nGyroflow is an application that can stabilize your video by using motion data from a gyroscope and optionally an accelerometer. Modern cameras record that data internally (GoPro, Sony, Insta360 etc), and this application stabilizes the captured footage precisely by using them. It can also use gyro data from an external source (eg. from Betaflight blackbox).\n\n[Trailer / results video](https://www.youtube.com/watch?v=QR-SINyvNyI)\n\n![Screenshot](resources/screenshot.jpg)\n\n<p align=\"center\">\n  <a href=\"resources/comparison1.mp4\"><img src=\"resources/comparison1.gif\" height=\"200\"></a>\n  <a href=\"resources/comparison2.mp4\"><img src=\"resources/comparison2.gif\" height=\"200\"></a>\n</p>\n\n## Features\n- Real-time preview, parameter adjustments and all calculations\n- GPU processing and rendering, all algorithms fully multi-threaded\n- Rolling shutter correction\n- [Video editor plugins](https://github.com/gyroflow/gyroflow-plugins) (Adobe Premiere/Ae, DaVinci Resolve, Final Cut Pro and more), allowing you to apply stabilization directly in a video editor without transcoding\n- Supports full Sony metadata (recording params, automatic lens, support for IBIS, OIS, EIS - you can have IBIS enabled in camera and still apply Gyroflow on top)\n- Supports already stabilized GoPro videos (captured with Hypersmooth enabled) (Hero 8 and up)\n- Supports and renders 10-bit videos (up to 16-bit 4:4:4:4 for regular codecs and 32-bit float for OpenEXR - working directly on YUV data to maintain maximum quality)\n- Customizable lens correction strength\n- Render queue\n- Keyframes\n- Ability to create custom settings presets\n- Visual chart with gyro data (displays gyro, accelerometer, magnetometer, and quaternions, including smoothed quaternions)\n- Supports underwater footage (corrects underwater distortions)\n- Modern responsive user interface with Dark and Light theme\n- Adaptive zoom (dynamic cropping)\n- Zoom limit\n- Supports image sequences (PNG, OpenEXR, CinemaDNG)\n- Based on [telemetry-parser](https://github.com/AdrianEddy/telemetry-parser) - supports all gyro sources out of the box\n- Gyro low pass filter, arbitrary rotation (pitch, roll, yaw angles) and orientation\n- Multiple gyro integration methods for orientation determination\n- Multiple video orientation smoothing algorithms, including horizon levelling and per-axis smoothness adjustment.\n- Cross-platform - works on Windows/Linux/Mac/Android/iOS\n- Multiple UI languages\n- Supports variable and high frame rate videos - all calculations are done on timestamps\n- H.264/AVC, H.265/HEVC, ProRes, DNxHD, CineForm, PNG and OpenEXR outputs, with H.264 and H.265 fully GPU accelerated (ProRes also accelerated on Apple Silicon)\n- Easy lens calibration process\n- Fully zero-copy GPU preview rendering\n- Core engine is a separate library without external dependencies (no Qt, no ffmpeg, no OpenCV), and can be used to create OpenFX and Adobe plugins (on the TODO list)\n- Automatic updates of lens profile database\n- Built-in official lens profiles for GoPro HERO 6-13; Sony; DJI; Insta360 action cameras; RunCam: Thumb series, 5 Orange\n- Easy management of the video editor plugins from within the app\n- Ability to add an additional 3D rotation (useful for framing vertical videos)\n\n## Supported gyro sources\n- [x] GoPro (HERO 5 and later)\n- [x] Sony (a1, a7c, a7r V, a7 IV, a7s III, a9 II, a9 III, FX3, FX6, FX9, RX0 II, RX100 VII, ZV1, ZV-E10, ZV-E10 II, ZV-E1, a6700)\n- [x] Insta360 (OneR, OneRS, SMO 4k, Go, GO2, GO3, GO3S, GOUltra, Caddx Peanut, Ace, Ace Pro)\n- [x] DJI (Avata, Avata 2, O3/O4 Air Unit, Action 2/4/5/6/Nano, Neo, Neo2)\n- [x] XTRA (Edge, Edge Pro)\n- [x] Blackmagic RAW (*.braw)\n- [x] RED RAW (V-Raptor, KOMODO) (*.r3d)\n- [x] Canon (C50, C80, C400, R6 Mk3, R5 Mk2) (*.mp4, *.mov, *.mxf)\n- [x] Freefly (Ember)\n- [x] Betaflight blackbox (*.bfl, *.bbl, *.csv)\n- [x] ArduPilot logs (*.bin, *.log)\n- [x] Gyroflow [.gcsv log](https://docs.gyroflow.xyz/app/technical-details/gcsv-format)\n- [x] iOS apps: [`Sensor Logger`](https://apps.apple.com/us/app/sensor-logger/id1531582925), [`G-Field Recorder`](https://apps.apple.com/at/app/g-field-recorder/id1154585693), [`Gyro`](https://apps.apple.com/us/app/gyro-record-device-motion-data/id1161532981)\n- [x] Android apps: [`Sensor Logger`](https://play.google.com/store/apps/details?id=com.kelvin.sensorapp&hl=de_AT&gl=US), [`Sensor Record`](https://play.google.com/store/apps/details?id=de.martingolpashin.sensor_record), [`OpenCamera Sensors`](https://github.com/MobileRoboticsSkoltech/OpenCamera-Sensors), [`MotionCam Pro`](https://play.google.com/store/apps/details?id=com.motioncam.pro)\n- [x] Runcam CSV (Runcam 5 Orange, iFlight GOCam GR, Runcam Thumb, Mobius Maxi 4K)\n- [x] Hawkeye Firefly X Lite CSV\n- [x] XTU (S2Pro, S3Pro)\n- [x] WitMotion (WT901SDCL binary and *.txt)\n- [x] Vuze (VuzeXR)\n- [x] KanDao (Obisidian Pro, Qoocam EGO)\n- [x] [CAMM format](https://developers.google.com/streetview/publish/camm-spec)\n\n### Info for cameras not on the list\n\n- For cameras which do have built-in gyro, please contact us and we will implement support for that camera. Refer to the [documentation](https://docs.gyroflow.xyz) for information about the gyro logging process.\n- For cameras which don't have built-in gyro, you can use any other device which records gyro data. It may be a phone, an action camera, or an external device like a Betaflight FC, [flowshutter](https://github.com/gyroflow/flowshutter), [esp-gyrologger](https://github.com/VladimirP1/esp-gyrologger) (eg. on an [AtomS3](https://shop.m5stack.com/products/atoms3-dev-kit-w-0-85-inch-screen)). You just have to mount it on your main camera.\n\n## Installation\n### Windows - [Microsoft Store](https://apps.microsoft.com/store/detail/gyroflow/9NZG7T0JCG9H) or:\n- Download `Gyroflow-windows64.zip` from the [Releases](https://github.com/gyroflow/gyroflow/releases) page, extract the files somewhere and run `Gyroflow.exe`\n- If it shows an error about `VCRUNTIME140.dll` or `0xc0000142`, [install VC redist](https://aka.ms/vs/17/release/vc_redist.x64.exe)\n\n### MacOS - [App Store](https://apps.apple.com/us/app/gyroflow/id6447994244) or:\n- Download `Gyroflow-mac-universal.dmg` from the [Releases](https://github.com/gyroflow/gyroflow/releases) page, run the downloaded file, and drag & drop `Gyroflow` app to the Applications folder (or anywhere you want, like on Desktop)\n- You can also install using brew: `brew install gyroflow`. To upgrade Gyroflow, run `brew update` then `brew upgrade gyroflow`\n\n### Linux\n- Download `Gyroflow-linux64.tar.gz` from the [Releases](https://github.com/gyroflow/gyroflow/releases) page, extract the files somewhere and run `./Gyroflow` in the terminal.\n- If that doesn't work, you can try the `Gyroflow-linux64.AppImage`, but the .tar.gz one is preferred.\n- Make sure you have latest graphics drivers installed\n- Possibly needed packages: `sudo apt install libva2 libvdpau1 libasound2 libxkbcommon0 libpulse0 libc++-dev libvulkan1`\n- GPU specific packages:\n    - NVIDIA: `nvidia-opencl-icd nvidia-vaapi-driver nvidia-vdpau-driver nvidia-egl-icd nvidia-vulkan-icd libnvcuvid1 libnvidia-encode1`\n    - Intel: `intel-media-va-driver i965-va-driver beignet-opencl-icd intel-opencl-icd`\n    - AMD: `mesa-vdpau-drivers mesa-va-drivers mesa-opencl-icd libegl-mesa0 mesa-vulkan-drivers`\n\n### Android\n- [Google Play](https://play.google.com/store/apps/details?id=xyz.gyroflow)\n\n### iOS\n- [App Store](https://apps.apple.com/us/app/gyroflow/id6447994244)\n\n### Nightly build\nLatest development version is always available here: https://gyroflow.xyz/devbuild/.\n\n## Minimum system requirements:\n- Windows 10 64-bit (1809 or later)\n    - If you have Windows \"N\" install, go to `Settings` -> `Apps` -> `Optional features` -> `Add a feature` -> enable `Media Feature Pack`\n- macOS 10.15 or later (both Intel and Apple Silicon are supported natively)\n- Linux:\n    - `.tar.gz` package (recommended): Debian 10+, Ubuntu 18.10+, CentOS 8.2+, openSUSE 15.3+. Other distros require glibc 2.28+ (`ldd --version` to check)\n    - `.AppImage` should work everywhere\n- Android 6+\n- iOS 14+\n\n## Help and support\nFor general support and discussion, you can find the developers and other users on the [Gyroflow Discord server](https://discord.gg/YaUtNpWTUh).\n\nFor companies or people wishing to get in touch with the team privately for collaborative purposes: devteam@gyroflow.xyz.\n\n## Test data\nYou can download some clips with gyro data from here: https://drive.google.com/drive/folders/1sbZiLN5-sv_sGul1E_DUOluB5OMHfySh?usp=sharing\n\n## Roadmap\n\nSee the [open issues](https://github.com/gyroflow/gyroflow/issues) for a list of proposed features and known issues.\nThere's also a ton of TODO comments throughout the code.\n\n### Video editor plugins\nGyroflow OpenFX plugin is available [here](https://github.com/gyroflow/gyroflow-plugins). OpenFX plugin was tested in DaVinci Resolve\n\nAdobe Premiere and After Effects plugin is available [here](https://github.com/gyroflow/gyroflow-plugins)\n\nFinal Cut Pro plugin is available as [Gyroflow Toolbox](https://gyroflowtoolbox.io).\n\n## Contributing\n\nContributions are what make the open source community such an amazing place to learn, inspire, and create. Any contributors are **greatly appreciated**.\n* If you have suggestions for adding or removing features, feel free to [open an issue](https://github.com/gyroflow/gyroflow/issues/new) to discuss it.\n* If you want to implement a feature, you can fork this project, implement your code and open a pull request.\n\n### Translations\nCurrently *Gyroflow* is available in:\n* **English** (base language)\n* **Chinese Simplified** (by [DusKing1](https://github.com/DusKing1))\n* **Chinese Traditional** (by [DusKing1](https://github.com/DusKing1))\n* **Czech** (by Jakub E≈°pandr, VitroidFPV, davidazarian, Michael Kmoch)\n* **Danish** (by [ElvinC](https://github.com/ElvinC))\n* **Finnish** (by Jesse Julkunen)\n* **French** (by KennyDorion)\n* **Galician** (by Mart√≠n Costas)\n* **German** (by [Grommi](https://github.com/Gro2mi) and [Nicecrash](https://github.com/B-nutze-RR))\n* **Greek** (by [Stamatis Galiatsatos](https://github.com/Logicenios))\n* **Indonesian** (by Aloysius Puspandono)\n* **Italian** (by Rosario Casciello)\n* **Japanese** (by ‰∫ï‰∏äÂ∫∑)\n* **Korean** (by EP45)\n* **Norwegian** (by [MiniGod](https://github.com/MiniGod) and [alexagv](https://github.com/alexagv))\n* **Polish** (by [AdrianEddy](https://github.com/AdrianEddy))\n* **Portuguese Brazilian** (by KallelGaNewk)\n* **Portuguese** (by Ricardo Pimentel)\n* **Russian** (by –ê–Ω–¥—Ä–µ–π –ì—É—Ä—å—è–Ω–æ–≤, redstar01 and lukdut)\n* **Slovak** (by Radovan Leitman and Eduard Petrovsky)\n* **Spanish** (by Pelado-Mat)\n* **Turkish** (by [Metin Oktay Yƒ±lmaz](https://github.com/mettinoktay))\n* **Ukrainian** (by Artem Alexandrov)\n\nHelp us translate *Gyroflow* to your language! We use *crowdin* to manage translations and you can contribute there: https://crowdin.com/project/gyroflow\n\n#### I want to contribute but I don't know Rust or QML\n* The Rust book is a great way to get started with Rust: https://doc.rust-lang.org/book/\n* Additional useful resources for Rust: https://quickref.me/rust and https://cheats.rs/\n* For the UI stuff, there's a nice QML book by The Qt Company: https://www.qt.io/product/qt6/qml-book\n\n\n## Development\n### Used languages and technologies\n*Gyroflow* is written in [Rust](https://www.rust-lang.org/), with UI written in [QML](https://doc.qt.io/qt-6/qmlfirststeps.html). It uses *Qt*, *ffmpeg*, *OpenCV* and *mdk-sdk* external dependencies for the main program, but the core library is written in pure Rust without any external dependencies.\n\nOpenCV usage is kept to a minimum, used only for lens calibration and optical flow (`src/core/calibration/mod.rs` and `src/core/synchronization/opencv.rs`). Core algorithms and undistortion don't use OpenCV.\n\nGPU stuff supports *DirectX*, *OpenGL*, *Metal* and *Vulkan* thanks to *Qt RHI* and *wgpu*.\nFor GPU processing we use *OpenCL* or *wgpu*, with highly parallelized CPU implementation as a fallback.\n\n### Code structure\n1. Entire GUI is in the `src/ui` directory\n2. `src/controller.rs` is a bridge between UI and core, it takes all commands from QML and calls functions in core\n3. `src/core` contains the whole gyroflow engine and doesn't depend on *Qt* or *ffmpeg*. *OpenCV* is optional\n4. `src/rendering` contains all FFmpeg related code for rendering final video and processing for synchronization\n5. `src/core/gpu` contains GPU implementations of the undistortion\n6. `src/qt_gpu` contains zero-copy GPU undistortion path, using Qt RHI and GLSL compute shader\n7. `src/gyroflow.rs` is the main entry point\n8. `mod.rs` or `lib.rs` in each directory act as a main entry of the module (directory name is the module name and `mod.rs` is kind of an entry point)\n\n### Dev environment\n`Visual Studio Code` with `rust-analyzer` extension.\n\nFor working with QML I recommend to use Qt Creator and load all QML files there, as it has auto-complete and syntax highlighting.\nThe project also supports UI live reload, it's a super quick way of working with the UI. Just change `live_reload = true` in `gyroflow.rs` and it should work right away. Now every time you change any QML file, the app should reload it immediately.\n\n### Building on Windows\n0. Prerequisites: `git`, `7z` and working `powershell`. If you never ran powershell scripts before, run `set-executionpolicy remotesigned` in powershell as admin\n1. Get latest stable Rust language from: https://rustup.rs/\n    - Please make sure to check the English language pack option when installing the C++ build tools from Visual Studio Installer\n2. Install `Just` by running `cargo install --force just`\n3. Clone the repo: `git clone https://github.com/gyroflow/gyroflow.git`\n4. Enter the project directory and:\n    - Install dependencies: `just install-deps`\n    - Compile and run: `just run`\n\n### Building on MacOS\n0. Prerequisites: `git`, `brew`\n1. Get latest stable Rust language from: https://rustup.rs/\n2. Install `Just` by running `cargo install --force just`\n3. Clone the repo: `git clone https://github.com/gyroflow/gyroflow.git`\n4. Enter the project directory and:\n    - Install dependencies: `just install-deps`\n    - Compile and run: `just run`\n    - The first time you run it won't work, run `just deploy` once and then `just run` will work\n\n### Building on Linux\n0. Prerequisites: `git`, `7z`, `python`, `apt` package manager (or adjust commands inside scripts if on different distro)\n1. Get latest stable Rust language from: https://rustup.rs/\n2. Install `Just` by running `cargo install --force just`\n3. Clone the repo: `git clone https://github.com/gyroflow/gyroflow.git`\n4. Enter the project directory and:\n    - Install dependencies: `just install-deps`\n    - Compile and run: `just run`\n\n### Building for Android\n0. Prerequisites: `git`, `7z`, working `powershell`, Android SDK and NDK. Android is not well supported yet, but the app can be built and somewhat works. Building is supported only on Windows\n1. Get latest stable Rust language from: https://rustup.rs/\n2. Install `Just` by running `cargo install --force just`\n3. Clone the repo: `git clone https://github.com/gyroflow/gyroflow.git`\n4. Install Android SDK and NDK r23c and update paths in `_scripts/android.just`\n5. Enter the project directory and:\n    - Install dependencies: `just android install-deps`\n    - Compile the apk and install on device: `just android deploy`\n\n### Building for iOS\n0. Prerequisites: `git`, `brew`\n1. Get latest stable Rust language from: https://rustup.rs/\n2. Install `Just` by running `cargo install --force just`\n3. Clone the repo: `git clone https://github.com/gyroflow/gyroflow.git`\n4. Enter the project directory and:\n    - Install dependencies: `just ios install-deps`\n    - Update Team ID, signing keys and provisioning profiles in `_scripts/ios.just`\n    - Compile and run on device: `just ios run`\n\n### Profiling on Windows\n1. Install and run `Visual Studio Community Edition`\n2. Compile and run Gyroflow with the `profile` profile: `just profile`\n3. In Visual Studio, go to `Debug -> Performance Profiler...`\n    - Under `Target`, open `Change Target` and select `Running Process...`, select the running `gyroflow.exe` process\n\n### Profiling QML\n1. Uncomment `config.define(\"QT_QML_DEBUG\", None);` in `build.rs`\n2. Comment `cli::run()` in `gyroflow.rs`\n3. Run in debug mode with QML debugger args: `cargo run -- \"-qmljsdebugger=port:1234,block,services:CanvasFrameRate,EngineControl,DebugMessages\"`\n4. In Qt Creator go to `Analyze` -> `QML Profiler (Attach to Waiting Application)` and enter port 1234\n\n## License\n\nDistributed under the GPLv3 License with App Store Exception. See [LICENSE](https://github.com/gyroflow/gyroflow/blob/main/LICENSE) for more information.\n\nAs additional permission under section 7, you are allowed to distribute [`gyroflow_core`](https://github.com/gyroflow/gyroflow/tree/master/src/core) through an app store, even if that store has restrictive terms and conditions that are incompatible with the GPL, provided that the source is also available under the GPL with or without this permission through a channel without those restrictive terms and conditions.\n\n## Authors\n\n* [AdrianEddy](https://github.com/AdrianEddy/) - *Author of the Rust implementation (code in this repository), author of the UI, GPU processing, rolling shutter correction, advanced rendering features and the Adobe plugin*\n* [Elvin Chen](https://github.com/ElvinC/) - *Author of the first version in Python, laid the groundwork to make all this possible*\n\n### Notable contributors\n* [Maik Menz](https://github.com/mycosd/) - *Contributed to all areas of Gyroflow with fixes and improvements*\n* [Aphobius](https://github.com/Aphobius/) - *Author of the velocity dampened smoothing algorithm*\n* [Marc Roeschlin](https://github.com/marcroe/) - *Author of the adaptive zoom algorithm*\n* [Ilya Epifanov](https://github.com/ilya-epifanov/) - *Author of the OpenFX plugin*\n* [Vladimir Pinchuk](https://github.com/VladimirP1/) - *Author of robust gyro-to-video synchronization algorithm and Sony lens/IBIS data*\n* [Chris Hocking](https://github.com/latenitefilms) - *Author of the [Gyroflow Toolbox](https://gyroflowtoolbox.io) Final Cut Pro Plugin*\n\n## Acknowledgements\n\n* [Gyroflow Python version (legacy code)](https://github.com/ElvinC/gyroflow)\n* [telemetry-parser](https://github.com/AdrianEddy/telemetry-parser)\n",
      "stars_today": 9
    },
    {
      "id": 902097949,
      "name": "sqlite-data",
      "full_name": "pointfreeco/sqlite-data",
      "description": "A fast, lightweight replacement for SwiftData, powered by SQL and supporting CloudKit synchronization.",
      "html_url": "https://github.com/pointfreeco/sqlite-data",
      "stars": 1523,
      "forks": 74,
      "language": "Swift",
      "topics": [
        "cloudkit",
        "database",
        "observation",
        "persistence",
        "sql",
        "sqlite",
        "swiftdata",
        "swiftui",
        "synchronization"
      ],
      "created_at": "2024-12-11T22:44:01Z",
      "updated_at": "2026-01-14T00:10:17Z",
      "pushed_at": "2026-01-13T22:01:54Z",
      "open_issues": 15,
      "owner": {
        "login": "pointfreeco",
        "avatar_url": "https://avatars.githubusercontent.com/u/29466629?v=4"
      },
      "readme": "# SQLiteData\n\nA [fast](#Performance), lightweight replacement for SwiftData, powered by SQL and supporting\nCloudKit synchronization.\n\n[![CI](https://github.com/pointfreeco/sqlite-data/actions/workflows/ci.yml/badge.svg)](https://github.com/pointfreeco/sqlite-data/actions/workflows/ci.yml)\n[![Slack](https://img.shields.io/badge/slack-chat-informational.svg?label=Slack&logo=slack)](https://www.pointfree.co/slack-invite)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fsqlite-data%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/pointfreeco/sqlite-data)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fsqlite-data%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/pointfreeco/sqlite-data)\n\n  * [Learn more](#Learn-more)\n  * [Overview](#Overview)\n  * [Quick start](#Quick-start)\n  * [Performance](#Performance)\n  * [SQLite knowledge required](#SQLite-knowledge-required)\n  * [Overview](#Overview)\n  * [Demos](#Demos)\n  * [Documentation](#Documentation)\n  * [Installation](#Installation)\n  * [Community](#Community)\n  * [License](#License)\n\n## Learn more\n\nThis library was motivated and designed over the course of many episodes on\n[Point-Free](https://www.pointfree.co), a video series exploring advanced programming topics in the\nSwift language, hosted by [Brandon Williams](https://twitter.com/mbrandonw) and\n[Stephen Celis](https://twitter.com/stephencelis). To support the continued development of this\nlibrary, [subscribe today](https://www.pointfree.co/pricing).\n\n<a href=\"https://www.pointfree.co/collections/modern-persistence\">\n  <img alt=\"video poster image\" src=\"https://d3rccdn33rt8ze.cloudfront.net/episodes/0325.jpeg\" width=\"600\">\n</a>\n\n## Overview\n\nSQLiteData is a [fast](#performance), lightweight replacement for SwiftData, including CloudKit\nsynchronization (and even CloudKit sharing), built on top of the popular [GRDB] library.\nTo populate data from the database you can use `@Table` and `@FetchAll`, which are\nsimilar to SwiftData's `@Model` and `@Query`:\n\n<table>\n<tr>\n<th>SQLiteData</th>\n<th>SwiftData</th>\n</tr>\n<tr valign=top>\n<td width=415>\n\n```swift\n@FetchAll\nvar items: [Item]\n\n@Table\nstruct Item {\n  let id: UUID\n  var title = \"\"\n  var isInStock = true\n  var notes = \"\"\n}\n```\n\n</td>\n<td width=415>\n\n```swift\n@Query\nvar items: [Item]\n\n@Model\nclass Item {\n  var title: String\n  var isInStock: Bool\n  var notes: String\n  init(\n    title: String = \"\",\n    isInStock: Bool = true,\n    notes: String = \"\"\n  ) {\n    self.title = title\n    self.isInStock = isInStock\n    self.notes = notes\n  }\n}\n```\n\n</td>\n</tr>\n</table>\n\nBoth of the above examples fetch items from an external data store using Swift data types, and both\nare automatically observed by SwiftUI so that views are recomputed when the external data changes,\nbut SQLiteData is powered directly by SQLite and is usable from UIKit, `@Observable` models, and\nmore.\n\nFor more information on SQLiteData's querying capabilities, see\n[Fetching model data][fetching-article].\n\n## Quick start\n\nBefore SQLiteData's property wrappers can fetch data from SQLite, you need to provide‚Äìat\nruntime‚Äìthe default database it should use. This is typically done as early as possible in your\napp's lifetime, like the app entry point in SwiftUI, and is analogous to configuring model storage\nin SwiftData:\n\n<table>\n<tr>\n<th>SQLiteData</th>\n<th>SwiftData</th>\n</tr>\n<tr valign=top>\n<td width=415>\n\n```swift\n@main\nstruct MyApp: App {\n  init() {\n    prepareDependencies {\n      let db = try! DatabaseQueue(\n        // Create/migrate a database\n        // connection\n      )\n      $0.defaultDatabase = db\n    }\n  }\n  // ...\n}\n```\n\n</td>\n<td width=415>\n\n```swift\n@main\nstruct MyApp: App {\n  let container = {\n    // Create/configure a container\n    try! ModelContainer(/* ... */)\n  }()\n\n  var body: some Scene {\n    WindowGroup {\n      ContentView()\n        .modelContainer(container)\n    }\n  }\n}\n```\n\n</td>\n</tr>\n</table>\n\n> [!NOTE]\n> For more information on preparing a SQLite database, see\n> [Preparing a SQLite database][preparing-db-article].\n\nThis `defaultDatabase` connection is used implicitly by SQLiteData's strategies, like\n[`@FetchAll`][fetchall-docs] and [`@FetchOne`][fetchone-docs], which are similar to SwiftData's\n`@Query` macro, but more powerful:\n\n<table>\n<tr>\n<th>SQLiteData</th>\n<th>SwiftData</th>\n</tr>\n<tr valign=top>\n<td width=415>\n\n```swift\n@FetchAll\nvar items: [Item]\n\n@FetchAll(Item.order(by: \\.title))\nvar items\n\n@FetchAll(Item.where(\\.isInStock))\nvar items\n\n\n\n@FetchAll(Item.order(by: \\.isInStock))\nvar items\n\n@FetchOne(Item.count())\nvar itemsCount = 0\n\n```\n\n</td>\n<td width=415>\n\n```swift\n@Query\nvar items: [Item]\n\n@Query(sort: [SortDescriptor(\\.title)])\nvar items: [Item]\n\n@Query(filter: #Predicate<Item> {\n  $0.isInStock\n})\nvar items: [Item]\n\n// No @Query equivalent of ordering\n// by boolean column.\n\n// No @Query equivalent of counting\n// entries in database without loading\n// all entries.\n```\n\n</td>\n</tr>\n</table>\n\nAnd you can access this database throughout your application in a way similar to how one accesses\na model context, via a property wrapper:\n\n<table>\n<tr>\n<th>SQLiteData</th>\n<th>SwiftData</th>\n</tr>\n<tr valign=top>\n<td width=415>\n\n```swift\n@Dependency(\\.defaultDatabase)\nvar database\n\nlet newItem = Item(/* ... */)\ntry database.write { db in\n  try Item.insert { newItem }\n    .execute(db))\n}\n```\n\n</td>\n<td width=415>\n\n```swift\n@Environment(\\.modelContext)\nvar modelContext\n\nlet newItem = Item(/* ... */)\nmodelContext.insert(newItem)\ntry modelContext.save()\n\n```\n\n</td>\n</tr>\n</table>\n\n> [!NOTE]\n> For more information on how SQLiteData compares to SwiftData, see\n> [Comparison with SwiftData][comparison-swiftdata-article].\n\nFurther, if you want to synchronize the local database to CloudKit so that it is available on\nall your user's devices, simply configure a `SyncEngine` in the entry point of the app:\n\n```swift\n@main\nstruct MyApp: App {\n  init() {\n    prepareDependencies {\n      $0.defaultDatabase = try! appDatabase()\n      $0.defaultSyncEngine = SyncEngine(\n        for: $0.defaultDatabase,\n        tables: Item.self\n      )\n    }\n  }\n  // ...\n}\n```\n\n> [!NOTE]\n> For more information on synchronizing the database to CloudKit and sharing records with iCloud\n> users, see [CloudKit Synchronization].\n\nThis is all you need to know to get started with SQLiteData, but there's much more to learn. Read\nthe [articles][articles] below to learn how to best utilize this library:\n\n  * [Fetching model data][fetching-article]\n  * [Observing changes to model data][observing-article]\n  * [Preparing a SQLite database][preparing-db-article]\n  * [Dynamic queries][dynamic-queries-article]\n  * [CloudKit Synchronization]\n  * [Comparison with SwiftData][comparison-swiftdata-article]\n\n[observing-article]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/observing\n[dynamic-queries-article]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/dynamicqueries\n[articles]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata#Essentials\n[comparison-swiftdata-article]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/comparisonwithswiftdata\n[fetching-article]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/fetching\n[preparing-db-article]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/preparingdatabase\n[CloudKit Synchronization]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/cloudkit\n[fetchall-docs]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/fetchall\n[fetchone-docs]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/fetchone\n\n## Performance\n\nSQLiteData leverages high-performance decoding from [StructuredQueries][] to turn fetched data into\nyour Swift domain types, and has a performance profile similar to invoking SQLite's C APIs directly.\n\nSee the following benchmarks against\n[Lighter's performance test suite](https://github.com/Lighter-swift/PerformanceTestSuite) for a\ntaste of how it compares:\n\n```\nOrders.fetchAll                           setup    rampup   duration\n   SQLite (generated by Enlighter 1.4.10) 0        0.144    7.183\n   Lighter (1.4.10)                       0        0.164    8.059\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  SQLiteData (1.0.0)                     0        0.172    8.511  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n   GRDB (7.4.1, manual decoding)          0        0.376    18.819\n   SQLite.swift (0.15.3, manual decoding) 0        0.564    27.994\n   SQLite.swift (0.15.3, Codable)         0        0.863    43.261\n   GRDB (7.4.1, Codable)                  0.002    1.07     53.326\n```\n\n## SQLite knowledge required\n\nSQLite is one of the\n[most established and widely distributed](https://www.sqlite.org/mostdeployed.html) pieces of\nsoftware in the history of software. Knowledge of SQLite is a great skill for any app developer to\nhave, and this library does not want to conceal it from you. So, we feel that to best wield this\nlibrary you should be familiar with the basics of SQLite, including schema design and normalization,\nSQL queries, including joins and aggregates, and performance, including indices.\n\nWith some basic knowledge you can apply this library to your database schema in order to query\nfor data and keep your views up-to-date when data in the database changes, and you can use\n[StructuredQueries][] to build queries, either using its type-safe, discoverable\n[query building APIs][], or using its `#sql` macro for writing [safe SQL strings][].\n\nFurther, this library is built on the popular and battle-tested [GRDB] library for\ninteracting with SQLite, such as executing queries and observing the database for changes.\n\n[StructuredQueries]: https://github.com/pointfreeco/swift-structured-queries\n[GRDB]: https://github.com/groue/GRDB.swift\n[query building APIs]: https://swiftpackageindex.com/pointfreeco/swift-structured-queries/~/documentation/structuredqueriescore\n[safe SQL strings]: https://swiftpackageindex.com/pointfreeco/swift-structured-queries/~/documentation/structuredqueriescore/safesqlstrings\n\n## Demos\n\nThis repo comes with _lots_ of examples to demonstrate how to solve common and complex problems with\nSQLiteData. Check out [this](./Examples) directory to see them all, including:\n\n* [**Case Studies**](./Examples/CaseStudies)\n  <br> Demonstrates how to solve some common application problems in an isolated environment, in\n  both SwiftUI and UIKit. Things like animations, dynamic queries, database transactions, and more.\n\n* [**CloudKitDemo**](./Examples/CloudKitDemo)\n  <br> A simplified demo that shows how to synchronize a SQLite database to CloudKit and how to\n  share records with other iCloud users. See our dedicated articles on [CloudKit Synchronization]\n  and [CloudKit Sharing] for more information.\n\n  [CloudKit Synchronization]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/cloudkit\n  [CloudKit Sharing]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/cloudkitsharing\n\n* [**Reminders**](./Examples/Reminders)\n  <br> A rebuild of Apple's [Reminders][reminders-app-store] app that uses a SQLite database to\n  model the reminders, lists and tags. It features many advanced queries, such as searching, stats\n  aggregation, and multi-table joins. It also features CloudKit synchronization and sharing.\n\n* [**SyncUps**](./Examples/SyncUps)\n  <br> This application is a faithful reconstruction of one of Apple's more interesting sample\n  projects, called [Scrumdinger][scrumdinger], and uses SQLite to persist the data for meetings.\n  We have also added CloudKit synchronization so that all changes are automatically made available\n  on all of the user's devices.\n\n[Scrumdinger]: https://developer.apple.com/tutorials/app-dev-training/getting-started-with-scrumdinger\n[reminders-app-store]: https://apps.apple.com/us/app/reminders/id1108187841\n\n## Documentation\n\nThe documentation for releases and `main` are available here:\n\n  * [`main`](https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/)\n  * [1.x.x](https://swiftpackageindex.com/pointfreeco/sqlite-data/~/documentation/sqlitedata/)\n\n## Installation\n\nYou can add SQLiteData to an Xcode project by adding it to your project as a package‚Ä¶\n\n> https://github.com/pointfreeco/sqlite-data\n\n‚Ä¶and adding the `SQLiteData` product to your target.\n\nIf you want to use SQLiteData in a [SwiftPM](https://swift.org/package-manager/) project, it's as\nsimple as adding it to your `Package.swift`:\n\n``` swift\ndependencies: [\n  .package(url: \"https://github.com/pointfreeco/sqlite-data\", from: \"1.0.0\")\n]\n```\n\nAnd then adding the following product to any target that needs access to the library:\n\n```swift\n.product(name: \"SQLiteData\", package: \"sqlite-data\"),\n```\n\n## Community\n\nIf you want to discuss this library or have a question about how to use it to solve a particular\nproblem, there are a number of places you can discuss with fellow\n[Point-Free](http://www.pointfree.co) enthusiasts:\n\n  * For long-form discussions, we recommend the\n    [discussions](http://github.com/pointfreeco/sqlite-data/discussions) tab of this repo.\n\n  * For casual chat, we recommend the\n    [Point-Free Community Slack](http://www.pointfree.co/slack-invite).\n\n## License\n\nThis library is released under the MIT license. See [LICENSE](LICENSE) for details.\n",
      "stars_today": 9
    },
    {
      "id": 143455116,
      "name": "filament",
      "full_name": "google/filament",
      "description": "Filament is a real-time physically based rendering engine for Android, iOS, Windows, Linux, macOS, and WebGL2",
      "html_url": "https://github.com/google/filament",
      "stars": 19350,
      "forks": 2091,
      "language": "C++",
      "topics": [
        "3d-graphics",
        "android",
        "gltf",
        "gltf-viewer",
        "graphics",
        "metal",
        "opengl",
        "opengl-es",
        "pbr",
        "real-time",
        "vulkan",
        "wasm",
        "webgl"
      ],
      "created_at": "2018-08-03T17:26:00Z",
      "updated_at": "2026-01-13T23:53:33Z",
      "pushed_at": "2026-01-13T22:24:50Z",
      "open_issues": 195,
      "owner": {
        "login": "google",
        "avatar_url": "https://avatars.githubusercontent.com/u/1342004?v=4"
      },
      "readme": "# Filament\n\n[![Android Build Status](https://github.com/google/filament/workflows/Android/badge.svg)](https://github.com/google/filament/actions?query=workflow%3AAndroid)\n[![iOS Build Status](https://github.com/google/filament/workflows/iOS/badge.svg)](https://github.com/google/filament/actions?query=workflow%3AiOS)\n[![Linux Build Status](https://github.com/google/filament/workflows/Linux/badge.svg)](https://github.com/google/filament/actions?query=workflow%3ALinux)\n[![macOS Build Status](https://github.com/google/filament/workflows/macOS/badge.svg)](https://github.com/google/filament/actions?query=workflow%3AmacOS)\n[![Windows Build Status](https://github.com/google/filament/workflows/Windows/badge.svg)](https://github.com/google/filament/actions?query=workflow%3AWindows)\n[![Web Build Status](https://github.com/google/filament/workflows/Web/badge.svg)](https://github.com/google/filament/actions?query=workflow%3AWeb)\n\nFilament is a real-time physically based rendering engine for Android, iOS, Linux, macOS, Windows,\nand WebGL. It is designed to be as small as possible and as efficient as possible on Android.\n\n## Download\n\n[Download Filament releases](https://github.com/google/filament/releases) to access stable builds.\nFilament release archives contains host-side tools that are required to generate assets.\n\nMake sure you always use tools from the same release as the runtime library. This is particularly\nimportant for `matc` (material compiler).\n\nIf you'd rather build Filament yourself, please refer to our [build manual](/BUILDING.md).\n\n### Android\n\nAndroid projects can simply declare Filament libraries as Maven dependencies:\n\n```gradle\nrepositories {\n    // ...\n    mavenCentral()\n}\n\ndependencies {\n    implementation 'com.google.android.filament:filament-android:1.68.3'\n}\n```\n\nHere are all the libraries available in the group `com.google.android.filament`:\n\n| Artifact      | Description   |\n| ------------- | ------------- |\n| [![filament-android](https://maven-badges.herokuapp.com/maven-central/com.google.android.filament/filament-android/badge.svg?subject=filament-android)](https://maven-badges.herokuapp.com/maven-central/com.google.android.filament/filament-android)  | The Filament rendering engine itself. |\n| [![filament-android-debug](https://maven-badges.herokuapp.com/maven-central/com.google.android.filament/filament-android-debug/badge.svg?subject=filament-android-debug)](https://maven-badges.herokuapp.com/maven-central/com.google.android.filament/filament-android-debug)  | Debug version of `filament-android`. |\n| [![gltfio-android](https://maven-badges.herokuapp.com/maven-central/com.google.android.filament/gltfio-android/badge.svg?subject=gltfio-android)](https://maven-badges.herokuapp.com/maven-central/com.google.android.filament/gltfio-android) | A glTF 2.0 loader for Filament, depends on `filament-android`. |\n| [![filament-utils-android](https://maven-badges.herokuapp.com/maven-central/com.google.android.filament/filament-utils-android/badge.svg?subject=filament-utils-android)](https://maven-badges.herokuapp.com/maven-central/com.google.android.filament/filament-utils-android) | KTX loading, Kotlin math, and camera utilities, depends on `gltfio-android`. |\n| [![filamat-android](https://maven-badges.herokuapp.com/maven-central/com.google.android.filament/filamat-android/badge.svg?subject=filamat-android)](https://maven-badges.herokuapp.com/maven-central/com.google.android.filament/filamat-android) | A runtime material builder/compiler. This library is large but contains a full shader compiler/validator/optimizer and supports both OpenGL and Vulkan. |\n| [![filamat-android-lite](https://maven-badges.herokuapp.com/maven-central/com.google.android.filament/filamat-android-lite/badge.svg?subject=filamat-android-lite)](https://maven-badges.herokuapp.com/maven-central/com.google.android.filament/filamat-android-lite) | A much smaller alternative to `filamat-android` that can only generate OpenGL shaders. It does not provide validation or optimizations. |\n\n### iOS\n\niOS projects can use CocoaPods to install the latest release:\n\n```shell\npod 'Filament', '~> 1.68.3'\n```\n\n## Documentation\n\n- [Filament](https://google.github.io/filament/Filament.html), an in-depth explanation of\n  real-time physically based rendering, the graphics capabilities and implementation of Filament.\n  This document explains the math and reasoning behind most of our decisions. This document is a\n  good introduction to PBR for graphics programmers.\n- [Materials](https://google.github.io/filament/Materials.html), the full reference\n  documentation for our material system. This document explains our different material models, how\n  to use the material compiler `matc` and how to write custom materials.\n- [Material Properties](https://google.github.io/filament/notes/material_properties.html), a reference\n  sheet for the standard material model.\n\n## Examples\n\n![Night scene](docs/images/samples/example_bistro1.jpg)\n![Night scene](docs/images/samples/example_bistro2.jpg)\n![Materials](docs/images/samples/example_materials1.jpg)\n![Materials](docs/images/samples/example_materials2.jpg)\n![Helmet](docs/images/samples/example_helmet.jpg)\n![Screen-space refraction](docs/images/samples/example_ssr.jpg)\n\n## Features\n\n### APIs\n\n- Native C++ API for Android, iOS, Linux, macOS and Windows\n- Java/JNI API for Android\n- JavaScript API\n\n### Backends\n\n- OpenGL 4.1+ for Linux, macOS and Windows\n- OpenGL ES 3.0+ for Android and iOS\n- Metal for macOS and iOS\n- Vulkan 1.0 for Android, Linux, macOS, and Windows\n- WebGL 2.0 for all platforms\n\n### Rendering\n\n- Clustered forward renderer\n- Cook-Torrance microfacet specular BRDF\n- Lambertian diffuse BRDF\n- Custom lighting/surface shading\n- HDR/linear lighting\n- Metallic workflow\n- Clear coat\n- Anisotropic lighting\n- Approximated translucent (subsurface) materials\n- Cloth/fabric/sheen shading\n- Normal mapping & ambient occlusion mapping\n- Image-based lighting\n- Physically-based camera (shutter speed, sensitivity and aperture)\n- Physical light units\n- Point lights, spot lights, and directional light\n- Specular anti-aliasing\n- Point, spot, and directional light shadows\n- Cascaded shadows\n- EVSM, PCSS, DPCF, or PCF shadows\n- Transparent shadows\n- Contact shadows\n- Screen-space ambient occlusion\n- Screen-space reflections\n- Screen-space refraction\n- Global fog\n- Dynamic resolution (with support for AMD FidelityFX FSR)\n\n### Post processing\n\n- HDR bloom\n- Depth of field bokeh\n- Multiple tone mappers: generic (customizable), ACES, filmic, etc.\n- Color and tone management: luminance scaling, gamut mapping\n- Color grading: exposure, night adaptation, white balance, channel mixer,\n  shadows/mid-tones/highlights, ASC CDL, contrast, saturation, etc.\n- TAA, FXAA, MSAA\n- Screen-space lens flares\n\n### glTF 2.0\n\n- Encodings\n  - [x] Embeded\n  - [x] Binary\n\n- Primitive Types\n  - [x] Points\n  - [x] Lines\n  - [ ] Line Loop\n  - [x] Line Strip\n  - [x] Triangles\n  - [x] Triangle Strip\n  - [ ] Triangle Fan\n\n- Animation\n  - [x] Transform animation\n  - [x] Linear interpolation\n  - [x] Morph animation\n    - [x] Sparse accessor\n  - [x] Skin animation\n  - [x] Joint animation\n\n- Extensions\n  - [x] KHR_draco_mesh_compression\n  - [x] KHR_lights_punctual\n  - [x] KHR_materials_clearcoat\n  - [x] KHR_materials_emissive_strength\n  - [x] KHR_materials_ior\n  - [x] KHR_materials_pbrSpecularGlossiness\n  - [x] KHR_materials_sheen\n  - [x] KHR_materials_transmission\n  - [x] KHR_materials_unlit\n  - [x] KHR_materials_variants\n  - [x] KHR_materials_volume\n  - [x] KHR_materials_specular\n  - [x] KHR_mesh_quantization\n  - [x] KHR_texture_basisu\n  - [x] KHR_texture_transform\n  - [x] EXT_meshopt_compression\n\n\n## Rendering with Filament\n\n### Native Linux, macOS and Windows\n\nYou must create an `Engine`, a `Renderer` and a `SwapChain`. The `SwapChain` is created from a\nnative window pointer (an `NSView` on macOS or a `HWND` on Windows for instance):\n\n```c++\nEngine* engine = Engine::create();\nSwapChain* swapChain = engine->createSwapChain(nativeWindow);\nRenderer* renderer = engine->createRenderer();\n```\n\nTo render a frame you must then create a `View`, a `Scene` and a `Camera`:\n\n```c++\nCamera* camera = engine->createCamera(EntityManager::get().create());\nView* view = engine->createView();\nScene* scene = engine->createScene();\n\nview->setCamera(camera);\nview->setScene(scene);\n```\n\nRenderables are added to the scene:\n\n```c++\nEntity renderable = EntityManager::get().create();\n// build a quad\nRenderableManager::Builder(1)\n        .boundingBox({{ -1, -1, -1 }, { 1, 1, 1 }})\n        .material(0, materialInstance)\n        .geometry(0, RenderableManager::PrimitiveType::TRIANGLES, vertexBuffer, indexBuffer, 0, 6)\n        .culling(false)\n        .build(*engine, renderable);\nscene->addEntity(renderable);\n```\n\nThe material instance is obtained from a material, itself loaded from a binary blob generated\nby `matc`:\n\n```c++\nMaterial* material = Material::Builder()\n        .package((void*) BAKED_MATERIAL_PACKAGE, sizeof(BAKED_MATERIAL_PACKAGE))\n        .build(*engine);\nMaterialInstance* materialInstance = material->createInstance();\n```\n\nTo learn more about materials and `matc`, please refer to the\n[materials documentation](https://google.github.io/filament/Materials.html).\n\nTo render, simply pass the `View` to the `Renderer`:\n\n```c++\n// beginFrame() returns false if we need to skip a frame\nif (renderer->beginFrame(swapChain)) {\n    // for each View\n    renderer->render(view);\n    renderer->endFrame();\n}\n```\n\nFor complete examples of Linux, macOS and Windows Filament applications, look at the source files\nin the `samples/` directory. These samples are all based on `libs/filamentapp/` which contains the\ncode that creates a native window with SDL2 and initializes the Filament engine, renderer and views.\n\nFor more information on how to prepare environment maps for image-based lighting please refer to\n[BUILDING.md](/BUILDING.md#running-the-native-samples).\n\n### Android\n\nSee `android/samples` for examples of how to use Filament on Android.\n\nYou must always first initialize Filament by calling `Filament.init()`.\n\nRendering with Filament on Android is similar to rendering from native code (the APIs are largely\nthe same across languages). You can render into a `Surface` by passing a `Surface` to the\n`createSwapChain` method. This allows you to render to a `SurfaceTexture`, a `TextureView` or\na `SurfaceView`. To make things easier we provide an Android specific API called `UiHelper` in the\npackage `com.google.android.filament.android`. All you need to do is set a render callback on the\nhelper and attach your `SurfaceView` or `TextureView` to it. You are still responsible for\ncreating the swap chain in the `onNativeWindowChanged()` callback.\n\n### iOS\n\nFilament is supported on iOS 11.0 and above. See `ios/samples` for examples of using Filament on\niOS.\n\nFilament on iOS is largely the same as native rendering with C++. A `CAEAGLLayer` or `CAMetalLayer`\nis passed to the `createSwapChain` method. Filament for iOS supports both Metal (preferred) and\nOpenGL ES.\n\n## Assets\n\nTo get started you can use the textures and environment maps found respectively in\n`third_party/textures` and `third_party/environments`. These assets are under CC0 license. Please\nrefer to their respective `URL.txt` files to know more about the original authors.\n\nEnvironments must be pre-processed using\n[`cmgen`](/BUILDING.md#running-the-native-samples) or\nusing the `libiblprefilter` library.\n\n## How to make contributions\n\nPlease read and follow the steps in [CONTRIBUTING.md](/CONTRIBUTING.md). Make sure you are\nfamiliar with the [code style](/CODE_STYLE.md).\n\n## Directory structure\n\nThis repository not only contains the core Filament engine, but also its supporting libraries\nand tools.\n\n- `android`:                  Android libraries and projects\n  - `filamat-android`:        Filament material generation library (AAR) for Android\n  - `filament-android`:       Filament library (AAR) for Android\n  - `filament-utils-android`: Extra utilities (KTX loader, math types, etc.)\n  - `gltfio-android`:         Filament glTF loading library (AAR) for Android\n  - `samples`:                Android-specific Filament samples\n- `art`:                      Source for various artworks (logos, PDF manuals, etc.)\n- `assets`:                   3D assets to use with sample applications\n- `build`:                    CMake build scripts\n- `docs`:                     Documentation\n  - `math`:                   Mathematica notebooks used to explore BRDFs, equations, etc.\n- `filament`:                 Filament rendering engine (minimal dependencies)\n  - `backend`:                Rendering backends/drivers (Vulkan, Metal, OpenGL/ES)\n- `ide`:                      Configuration files for IDEs (CLion, etc.)\n- `ios`:                      Sample projects for iOS\n- `libs`:                     Libraries\n  - `bluegl`:                 OpenGL bindings for macOS, Linux and Windows\n  - `bluevk`:                 Vulkan bindings for macOS, Linux, Windows and Android\n  - `camutils`:               Camera manipulation utilities\n  - `filabridge`:             Library shared by the Filament engine and host tools\n  - `filaflat`:               Serialization/deserialization library used for materials\n  - `filagui`:                Helper library for [Dear ImGui](https://github.com/ocornut/imgui)\n  - `filamat`:                Material generation library\n  - `filamentapp`:            SDL2 skeleton to build sample apps\n  - `filameshio`:             Tiny filamesh parsing library (see also `tools/filamesh`)\n  - `geometry`:               Mesh-related utilities\n  - `gltfio`:                 Loader for glTF 2.0\n  - `ibl`:                    IBL generation tools\n  - `image`:                  Image filtering and simple transforms\n  - `imageio`:                Image file reading / writing, only intended for internal use\n  - `matdbg`:                 DebugServer for inspecting shaders at run-time (debug builds only)\n  - `math`:                   Math library\n  - `mathio`:                 Math types support for output streams\n  - `utils`:                  Utility library (threads, memory, data structures, etc.)\n  - `viewer`:                 glTF viewer library (requires gltfio)\n- `samples`:                  Sample desktop applications\n- `shaders`:                  Shaders used by `filamat` and `matc`\n- `third_party`:              External libraries and assets\n  - `environments`:           Environment maps under CC0 license that can be used with `cmgen`\n  - `models`:                 Models under permissive licenses\n  - `textures`:               Textures under CC0 license\n- `tools`:                    Host tools\n  - `cmgen`:                  Image-based lighting asset generator\n  - `filamesh`:               Mesh converter\n  - `glslminifier`:           Minifies GLSL source code\n  - `matc`:                   Material compiler\n  - `filament-matp`:          Material parser\n  - `matinfo`                 Displays information about materials compiled with `matc`\n  - `mipgen`                  Generates a series of miplevels from a source image\n  - `normal-blending`:        Tool to blend normal maps\n  - `resgen`                  Aggregates binary blobs into embeddable resources\n  - `roughness-prefilter`:    Pre-filters a roughness map from a normal map to reduce aliasing\n  - `specular-color`:         Computes the specular color of conductors based on spectral data\n- `web`:                      JavaScript bindings, documentation, and samples\n\n## License\n\nPlease see [LICENSE](/LICENSE).\n\n## Disclaimer\n\nThis is not an officially supported Google product.\n",
      "stars_today": 8
    },
    {
      "id": 31102092,
      "name": "or-tools",
      "full_name": "google/or-tools",
      "description": "Google's Operations Research tools:",
      "html_url": "https://github.com/google/or-tools",
      "stars": 12973,
      "forks": 2343,
      "language": "C++",
      "topics": [
        "combinatorial-optimization",
        "linear-programming",
        "operations-research",
        "optimization",
        "or-tools"
      ],
      "created_at": "2015-02-21T01:25:35Z",
      "updated_at": "2026-01-13T18:16:12Z",
      "pushed_at": "2026-01-13T20:11:19Z",
      "open_issues": 71,
      "owner": {
        "login": "google",
        "avatar_url": "https://avatars.githubusercontent.com/u/1342004?v=4"
      },
      "readme": "# OR-Tools - Google Optimization Tools\n\n[![PyPI version](https://img.shields.io/pypi/v/ortools.svg)](https://pypi.org/project/ortools/)\n[![PyPI download](https://img.shields.io/pypi/dm/ortools.svg)](https://pypi.org/project/ortools/#files)\n\\\n[![NuGet version](https://img.shields.io/nuget/v/Google.OrTools.svg)](https://www.nuget.org/packages/Google.OrTools)\n[![NuGet download](https://img.shields.io/nuget/dt/Google.OrTools.svg)](https://www.nuget.org/packages/Google.OrTools)\n\\\n[![Maven Central](https://img.shields.io/maven-central/v/com.google.ortools/ortools-java)](https://mvnrepository.com/artifact/com.google.ortools/ortools-java)\n\\\n[![Discord](https://img.shields.io/discord/693088862481678374?color=7289DA&logo=discord&style=plastic)](https://discord.gg/ENkQrdf)\n\nGoogle's software suite for combinatorial optimization.\n\n## Table of Contents\n\n*   [About OR-Tools](#about)\n*   [Codemap](#codemap)\n*   [Installation](#installation)\n*   [Quick Start](#quick-start)\n*   [Documentation](#documentation)\n*   [Contributing](#contributing)\n*   [License](#license)\n\n<a name=\"about\"></a>\n## About OR-Tools\n\nGoogle Optimization Tools (a.k.a., OR-Tools) is an open-source, fast and\nportable software suite for solving combinatorial optimization problems.\n\nThe suite contains:\n\n*   Two constraint programming solver (CP* and CP-SAT);\n*   Two linear programming solvers (Glop and PDLP);\n*   Wrappers around commercial and other open source solvers, including mixed\n    integer solvers;\n*   Bin packing and knapsack algorithms;\n*   Algorithms for the Traveling Salesman Problem and Vehicle Routing Problem;\n*   Graph algorithms (shortest paths, min cost flow, max flow, linear sum\n    assignment).\n\nWe wrote OR-Tools in C++, but provide wrappers in Python, C# and Java.\n\n## Codemap\n\nThis software suite is composed of the following components:\n\n*   [Makefile](Makefile) Top-level for\n    [GNU Make](https://www.gnu.org/software/make/manual/make.html) based build.\n*   [makefiles](makefiles) Subsidiary Make files, CI and build system documentation.\n*   [CMakeLists.txt](CMakeLists.txt) Top-level for\n    [CMake](https://cmake.org/cmake/help/latest/) based build.\n*   [cmake](cmake) Subsidiary CMake files, CI and build system documentation.\n*   [WORKSPACE](WORKSPACE) Top-level for\n    [Bazel](https://bazel.build/start/bazel-intro) based build.\n*   [bazel](bazel) Subsidiary Bazel files, CI and build system documentation.\n*   [ortools](ortools) Root directory for source code.\n    *   [base](ortools/base) Basic utilities.\n    *   [algorithms](ortools/algorithms) Basic algorithms.\n        *   [samples](ortools/algorithms/samples) Carefully crafted samples.\n    *   [graph](ortools/graph) Graph algorithms.\n        *   [samples](ortools/graph/samples) Carefully crafted samples.\n    *   [linear_solver](ortools/linear_solver) Linear solver wrapper.\n        *   [samples](ortools/linear_solver/samples) Carefully crafted samples.\n    *   [glop](ortools/glop) Simplex-based linear programming solver.\n        *   [samples](ortools/glop/samples) Carefully crafted samples.\n    *   [pdlp](ortools/pdlp) First-order linear programming solver.\n        *   [samples](ortools/pdlp/samples) Carefully crafted samples.\n    *   [lp_data](ortools/lp_data) Data structures for linear models.\n    *   [constraint_solver](ortools/constraint_solver) Constraint and Routing\n        solver.\n        *   [docs](ortools/constraint_solver/docs) Documentation of the component.\n        *   [samples](ortools/constraint_solver/samples) Carefully crafted samples.\n    *   [sat](ortools/sat) SAT solver.\n        *   [docs](ortools/sat/docs) Documentation of the component.\n        *   [samples](ortools/sat/samples) Carefully crafted samples.\n    *   [bop](ortools/bop) Boolean solver based on SAT.\n    *   [util](ortools/util) Utilities needed by the constraint solver\n*   [examples](examples) Root directory for all examples.\n    *   [contrib](examples/contrib) Examples from the community.\n    *   [cpp](examples/cpp) C++ examples.\n    *   [dotnet](examples/dotnet) .Net examples.\n    *   [java](examples/java) Java examples.\n    *   [python](examples/python) Python examples.\n    *   [notebook](examples/notebook) Jupyter/IPython notebooks.\n    *   [flatzinc](examples/flatzinc) FlatZinc examples.\n*   [tools](tools) Delivery Tools (e.g. Windows GNU binaries, scripts, release dockers)\n\n## Installation\n\nThis software suite has been tested under:\n\n*   Ubuntu 18.04 LTS and up (64-bit);\n*   Apple macOS Mojave with Xcode 9.x (64-bit);\n*   Microsoft Windows with Visual Studio 2022 (64-bit).\n\nOR-Tools currently builds with a Makefile, but also provides Bazel and CMake\nsupport.\n\nFor installation instructions (both source and binary), please visit\nhttps://developers.google.com/optimization/introduction/installing.\n\n### Build from source using Make (legacy)\n\nWe provide a Make based build.<br>Please check the\n[Make build instructions](makefiles/README.md).\n\n### Build from source using CMake\n\nWe provide a CMake based build.<br>Please check the\n[CMake build instructions](cmake/README.md).\n\n### Build from source using Bazel\n\nWe provide a Bazel based build.<br>Please check the\n[Bazel build instructions](bazel/README.md).\n\n## Quick Start\n\nThe best way to learn how to use OR-Tools is to follow the tutorials in our\ndeveloper guide:\n\nhttps://developers.google.com/optimization/introduction/get_started\n\nIf you want to learn from code examples, take a look at the examples in the\n[examples](examples) directory.\n\n## Documentation\n\nThe complete documentation for OR-Tools is available at:\nhttps://developers.google.com/optimization/\n\n## Contributing\n\nThe [CONTRIBUTING.md](CONTRIBUTING.md) file contains instructions on how to\nsubmit the Contributor License Agreement before sending any pull requests (PRs).\nOf course, if you're new to the project, it's usually best to discuss any\nproposals and reach consensus before sending your first PR.\n\n## License\n\nThe OR-Tools software suite is licensed under the terms of the Apache License 2.0.\n<br>See [LICENSE](LICENSE) for more information.\n",
      "stars_today": 8
    },
    {
      "id": 654870350,
      "name": "SpacetimeDB",
      "full_name": "clockworklabs/SpacetimeDB",
      "description": "Multiplayer at the speed of light",
      "html_url": "https://github.com/clockworklabs/SpacetimeDB",
      "stars": 18804,
      "forks": 668,
      "language": "Rust",
      "topics": [
        "database",
        "dataoriented",
        "game-development",
        "relational",
        "relational-database",
        "smart-contracts"
      ],
      "created_at": "2023-06-17T07:28:29Z",
      "updated_at": "2026-01-14T00:43:04Z",
      "pushed_at": "2026-01-14T01:06:41Z",
      "open_issues": 721,
      "owner": {
        "login": "clockworklabs",
        "avatar_url": "https://avatars.githubusercontent.com/u/48072542?v=4"
      },
      "readme": "<p align=\"center\">\n    <a href=\"https://spacetimedb.com#gh-dark-mode-only\" target=\"_blank\">\n\t<img width=\"320\" src=\"./images/dark/logo.svg\" alt=\"SpacetimeDB Logo\">\n    </a>\n    <a href=\"https://spacetimedb.com#gh-light-mode-only\" target=\"_blank\">\n\t<img width=\"320\" src=\"./images/light/logo.svg\" alt=\"SpacetimeDB Logo\">\n    </a>\n</p>\n<p align=\"center\">\n    <a href=\"https://spacetimedb.com#gh-dark-mode-only\" target=\"_blank\">\n        <img width=\"250\" src=\"./images/dark/logo-text.svg\" alt=\"SpacetimeDB\">\n    </a>\n    <a href=\"https://spacetimedb.com#gh-light-mode-only\" target=\"_blank\">\n        <img width=\"250\" src=\"./images/light/logo-text.svg\" alt=\"SpacetimeDB\">\n    </a>\n    <h3 align=\"center\">\n        Multiplayer at the speed of light.\n    </h3>\n</p>\n<p align=\"center\">\n    <a href=\"https://github.com/clockworklabs/spacetimedb\"><img src=\"https://img.shields.io/github/v/release/clockworklabs/spacetimedb?color=%23ff00a0&include_prereleases&label=version&sort=semver&style=flat-square\"></a>\n    &nbsp;\n    <a href=\"https://github.com/clockworklabs/spacetimedb\"><img src=\"https://img.shields.io/badge/built_with-Rust-dca282.svg?style=flat-square\"></a>\n    &nbsp;\n\t<a href=\"https://github.com/clockworklabs/spacetimedb/actions\"><img src=\"https://img.shields.io/github/actions/workflow/status/clockworklabs/spacetimedb/ci.yml?style=flat-square&branch=master\"></a>\n    &nbsp;\n    <a href=\"https://status.spacetimedb.com\"><img src=\"https://img.shields.io/uptimerobot/ratio/7/m784409192-e472ca350bb615372ededed7?label=cloud%20uptime&style=flat-square\"></a>\n    &nbsp;\n    <a href=\"https://hub.docker.com/r/clockworklabs/spacetimedb\"><img src=\"https://img.shields.io/docker/pulls/clockworklabs/spacetimedb?style=flat-square\"></a>\n    &nbsp;\n    <a href=\"https://github.com/clockworklabs/spacetimedb/blob/master/LICENSE.txt\"><img src=\"https://img.shields.io/badge/license-BSL_1.1-00bfff.svg?style=flat-square\"></a>\n</p>\n<p align=\"center\">\n    <a href=\"https://crates.io/crates/spacetimedb\"><img src=\"https://img.shields.io/crates/d/spacetimedb?color=e45928&label=Rust%20Crate&style=flat-square\"></a>\n    &nbsp;\n    <a href=\"https://www.nuget.org/packages/SpacetimeDB.Runtime\"><img src=\"https://img.shields.io/nuget/dt/spacetimedb.runtime?color=0b6cff&label=NuGet%20Package&style=flat-square\"></a>\n</p>\n<p align=\"center\">\n    <a href=\"https://discord.gg/spacetimedb\"><img src=\"https://img.shields.io/discord/1037340874172014652?label=discord&style=flat-square&color=5a66f6\"></a>\n    &nbsp;\n    <a href=\"https://twitter.com/spacetime_db\"><img src=\"https://img.shields.io/badge/twitter-Follow_us-1d9bf0.svg?style=flat-square\"></a>\n    &nbsp;\n    <a href=\"https://clockworklabs.io/join\"><img src=\"https://img.shields.io/badge/careers-Join_us-86f7b7.svg?style=flat-square\"></a>\n    &nbsp;\n    <a href=\"https://www.linkedin.com/company/clockworklabs/\"><img src=\"https://img.shields.io/badge/linkedin-Connect_with_us-0a66c2.svg?style=flat-square\"></a>\n</p>\n\n<p align=\"center\">\n    <a href=\"https://discord.gg/spacetimedb\"><img height=\"25\" src=\"./images/social/discord.svg\" alt=\"Discord\"></a>\n    &nbsp;\n    <a href=\"https://twitter.com/spacetime_db\"><img height=\"25\" src=\"./images/social/twitter.svg\" alt=\"Twitter\"></a>\n    &nbsp;\n    <a href=\"https://github.com/clockworklabs/spacetimedb\"><img height=\"25\" src=\"./images/social/github.svg\" alt=\"GitHub\"></a>\n    &nbsp;\n    <a href=\"https://twitch.tv/SpacetimeDB\"><img height=\"25\" src=\"./images/social/twitch.svg\" alt=\"Twitch\"></a>\n    &nbsp;\n    <a href=\"https://youtube.com/@SpacetimeDB\"><img height=\"25\" src=\"./images/social/youtube.svg\" alt=\"YouTube\"></a>\n    &nbsp;\n    <a href=\"https://www.linkedin.com/company/clockwork-labs/\"><img height=\"25\" src=\"./images/social/linkedin.svg\" alt=\"LinkedIn\"></a>\n    &nbsp;\n    <a href=\"https://stackoverflow.com/questions/tagged/spacetimedb\"><img height=\"25\" src=\"./images/social/stackoverflow.svg\" alt=\"StackOverflow\"></a>\n</p>\n\n<br>\n\n## What is [SpacetimeDB](https://spacetimedb.com)?\n\nYou can think of SpacetimeDB as both a database and server combined into one.\n\nIt is a relational database system that lets you upload your application logic directly into the database by way of fancy stored procedures called \"modules.\"\n\nInstead of deploying a web or game server that sits in between your clients and your database, your clients connect directly to the database and execute your application logic inside the database itself. You can write all of your permission and authorization logic right inside your module just as you would in a normal server.\n\nThis means that you can write your entire application in a single language, Rust, and deploy it as a single binary. No more microservices, no more containers, no more Kubernetes, no more Docker, no more VMs, no more DevOps, no more infrastructure, no more ops, no more servers.\n\n<figure>\n    <img src=\"./images/basic-architecture-diagram.png\" alt=\"SpacetimeDB Architecture\" style=\"width:100%\">\n    <figcaption align=\"center\">\n        <p align=\"center\"><b>SpacetimeDB application architecture</b><br /><sup><sub>(elements in white are provided by SpacetimeDB)</sub></sup></p>\n    </figcaption>\n</figure>\n\nIt's actually similar to the idea of smart contracts, except that SpacetimeDB is a database, has nothing to do with blockchain, and is orders of magnitude faster than any smart contract system.\n\nSo fast, in fact, that the entire backend of our MMORPG [BitCraft Online](https://bitcraftonline.com) is just a SpacetimeDB module. We don't have any other servers or services running, which means that everything in the game, all of the chat messages, items, resources, terrain, and even the locations of the players are stored and processed by the database before being synchronized out to all of the clients in real-time.\n\nSpacetimeDB is optimized for maximum speed and minimum latency rather than batch processing or OLAP workloads. It is designed to be used for real-time applications like games, chat, and collaboration tools.\n\nThis speed and latency is achieved by holding all of application state in memory, while persisting the data in a write-ahead-log (WAL) which is used to recover application state.\n\n## Installation\n\nYou can run SpacetimeDB as a standalone database server via the `spacetime` CLI tool.\nInstall instructions for supported platforms are outlined below.\nThe same install instructions can be found on our website at https://spacetimedb.com/install.\n\n#### Install on macOS\n\nInstalling on macOS is as simple as running our install script. After that you can use the spacetime command to manage versions.\n\n```bash\ncurl -sSf https://install.spacetimedb.com | sh\n```\n\n#### Install on Linux\n\nInstalling on Linux is as simple as running our install script. After that you can use the spacetime command to manage versions.\n\n```bash\ncurl -sSf https://install.spacetimedb.com | sh\n```\n\n#### Install on Windows\n\nInstalling on Windows is as simple as pasting the snippet below into PowerShell. If you would like to use WSL instead, please follow the Linux install instructions.\n\n```ps1\niwr https://windows.spacetimedb.com -useb | iex\n```\n\n#### Installing from Source\n\nA quick note on installing from source: we recommend that you don't install from source unless there is a feature that is available in `master` that hasn't been released yet, otherwise follow the official installation instructions.\n\n##### MacOS + Linux\n\nInstalling on macOS + Linux is pretty straightforward. First we are going to build all of the binaries that we need:\n\n```bash\n# Install rustup, you can skip this step if you have cargo and the wasm32-unknown-unknown target already installed.\ncurl https://sh.rustup.rs -sSf | sh\n# Clone SpacetimeDB\ngit clone https://github.com/clockworklabs/SpacetimeDB\n# Build and install the CLI\ncd SpacetimeDB\ncargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli\n\n# Create directories\nmkdir -p ~/.local/bin\nexport STDB_VERSION=\"$(./target/release/spacetimedb-cli --version | sed -n 's/.*spacetimedb tool version \\([0-9.]*\\);.*/\\1/p')\"\nmkdir -p ~/.local/share/spacetime/bin/$STDB_VERSION\n\n# Install the update binary\ncp target/release/spacetimedb-update ~/.local/bin/spacetime\ncp target/release/spacetimedb-cli ~/.local/share/spacetime/bin/$STDB_VERSION\ncp target/release/spacetimedb-standalone ~/.local/share/spacetime/bin/$STDB_VERSION\n```\n\nAt this stage you'll need to add ~/.local/bin to your path if you haven't already.\n\n```\n# Please add the following line to your shell configuration and open a new shell session:\nexport PATH=\"$HOME/.local/bin:$PATH\"\n\n```\n\nThen finally set your SpacetimeDB version:\n```\n\n# Then, in a new shell, set the current version:\nspacetime version use $STDB_VERSION\n\n# If STDB_VERSION is not set anymore then you can use the following command to list your versions:\nspacetime version list\n```\n\nYou can verify that the correct version has been installed via `spacetime --version`.\n\n##### Windows\n\nBuilding on windows is a bit more complicated. You'll need a slightly different version of perl compared to what comes pre-bundled in most Windows terminals. We recommend [Strawberry Perl](https://strawberryperl.com/). You may also need access to an `openssl` binary which actually comes pre-installed with [Git for Windows](https://git-scm.com/downloads/win). Also, you'll need to install [rustup](https://rustup.rs/) for Windows.\n\nIn a Git for Windows shell you should have something that looks like this:\n```\n$ which perl\n/c/Strawberry/perl/bin/perl\n$ which openssl\n/mingw64/bin/openssl\n$ which cargo \n/c/Users/<user>/.cargo/bin/cargo\n```\n\nIf that looks correct then you're ready to proceed!\n\n```powershell\n# Clone SpacetimeDB\ngit clone https://github.com/clockworklabs/SpacetimeDB\n\n# Build and install the CLI\ncd SpacetimeDB\ncargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli\n\n# Create directories\n$stdbDir = \"$HOME\\AppData\\Local\\SpacetimeDB\"\n$stdbVersion = & \".\\target\\release\\spacetimedb-cli\" --version | Select-String -Pattern 'spacetimedb tool version ([0-9.]+);' | ForEach-Object { $_.Matches.Groups[1].Value }\nNew-Item -ItemType Directory -Path \"$stdbDir\\bin\\$stdbVersion\" -Force | Out-Null\n\n# Install the update binary\nCopy-Item \"target\\release\\spacetimedb-update.exe\" \"$stdbDir\\spacetime.exe\"\nCopy-Item \"target\\release\\spacetimedb-cli.exe\" \"$stdbDir\\bin\\$stdbVersion\\\"\nCopy-Item \"target\\release\\spacetimedb-standalone.exe\" \"$stdbDir\\bin\\$stdbVersion\\\"\n\n```\n\nNow add the directory we just created to your path. We recommend adding it to the system path because then it will be available to all of your applications (including Unity3D). After you do this, restart your shell!\n\n```\n%USERPROFILE%\\AppData\\Local\\SpacetimeDB\n```\n\nThen finally, open a new shell and use the installed SpacetimeDB version:\n```\nspacetime version use $stdbVersion\n\n# If stdbVersion is no longer set, list versions using the following command:\nspacetime version list\n```\n\nYou can verify that the correct version has been installed via `spacetime --version`.\n\nIf you're using Git for Windows you can follow these instructions instead:\n\n```bash\n# Clone SpacetimeDB\ngit clone https://github.com/clockworklabs/SpacetimeDB\n# Build and install the CLI\ncd SpacetimeDB\n# Build the CLI binaries - this takes a while on windows so go grab a coffee :)\ncargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli\n\n# Create directories\nexport STDB_VERSION=\"$(./target/release/spacetimedb-cli --version | sed -n 's/.*spacetimedb tool version \\([0-9.]*\\);.*/\\1/p')\"\nmkdir -p ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION\n\n# Install the update binary\ncp target/release/spacetimedb-update ~/AppData/Local/SpacetimeDB/spacetime\ncp target/release/spacetimedb-cli ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION\ncp target/release/spacetimedb-standalone ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION\n\n# Now add the directory we just created to your path. We recommend adding it to the system path because then it will be available to all of your applications (including Unity3D). After you do this, restart your shell!\n# %USERPROFILE%\\AppData\\Local\\SpacetimeDB\n\n# Set the current version\nspacetime version use $STDB_VERSION\n```\n\nYou can verify that the correct version has been installed via `spacetime --version`.\n\n#### Running with Docker\n\nIf you prefer to run Spacetime in a container, you can use the following command to start a new instance.\n\n```bash\ndocker run --rm --pull always -p 3000:3000 clockworklabs/spacetime start\n```\n\n## Documentation\n\nFor more information about SpacetimeDB, getting started guides, game development guides, and reference material please see our [documentation](https://spacetimedb.com/docs).\n\n## Getting Started\n\nWe've prepared several getting started guides in each of our supported languages to help you get up and running with SpacetimeDB as quickly as possible. You can find them on our [docs page](https://spacetimedb.com/docs).\n\nIn summary there are only 4 steps to getting started with SpacetimeDB.\n\n1. Install the `spacetime` CLI tool.\n2. Start a SpacetimeDB standalone node with `spacetime start`.\n3. Write and upload a module in one of our supported module languages.\n4. Connect to the database with one of our client libraries.\n\nYou can see a summary of the supported languages below with a link to the getting started guide for each.\n\n## Language Support\n\nYou can write SpacetimeDB modules in several popular languages, with more to come in the future!\n\n#### Serverside Libraries\n\n- [Rust](https://spacetimedb.com/docs/modules/rust/quickstart)\n- [C#](https://spacetimedb.com/docs/modules/c-sharp/quickstart)\n\n#### Client Libraries\n\n- [Rust](https://spacetimedb.com/docs/sdks/rust/quickstart)\n- [C#](https://spacetimedb.com/docs/sdks/c-sharp/quickstart)\n- [Typescript](https://spacetimedb.com/docs/sdks/typescript/quickstart)\n\n## License\n\nSpacetimeDB is licensed under the BSL 1.1 license. This is not an open source or free software license, however, it converts to the AGPL v3.0 license with a linking exception after a few years.\n\nNote that the AGPL v3.0 does not typically include a linking exception. We have added a custom linking exception to the AGPL license for SpacetimeDB. Our motivation for choosing a free software license is to ensure that contributions made to SpacetimeDB are propagated back to the community. We are expressly not interested in forcing users of SpacetimeDB to open source their own code if they link with SpacetimeDB, so we needed to include a linking exception.\n",
      "stars_today": 8
    },
    {
      "id": 280608729,
      "name": "ORB_SLAM3",
      "full_name": "UZ-SLAMLab/ORB_SLAM3",
      "description": "ORB-SLAM3: An Accurate Open-Source Library for Visual, Visual-Inertial and Multi-Map SLAM",
      "html_url": "https://github.com/UZ-SLAMLab/ORB_SLAM3",
      "stars": 8179,
      "forks": 2952,
      "language": "C++",
      "topics": [
        "slam-algorithms"
      ],
      "created_at": "2020-07-18T07:47:46Z",
      "updated_at": "2026-01-13T23:14:37Z",
      "pushed_at": "2024-07-24T08:41:52Z",
      "open_issues": 562,
      "owner": {
        "login": "UZ-SLAMLab",
        "avatar_url": "https://avatars.githubusercontent.com/u/25055183?v=4"
      },
      "readme": "# ORB-SLAM3\n\n### V1.0, December 22th, 2021\n**Authors:** Carlos Campos, Richard Elvira, Juan J. G√≥mez Rodr√≠guez, [Jos√© M. M. Montiel](http://webdiis.unizar.es/~josemari/), [Juan D. Tardos](http://webdiis.unizar.es/~jdtardos/).\n\nThe [Changelog](https://github.com/UZ-SLAMLab/ORB_SLAM3/blob/master/Changelog.md) describes the features of each version.\n\nORB-SLAM3 is the first real-time SLAM library able to perform **Visual, Visual-Inertial and Multi-Map SLAM** with **monocular, stereo and RGB-D** cameras, using **pin-hole and fisheye** lens models. In all sensor configurations, ORB-SLAM3 is as robust as the best systems available in the literature, and significantly more accurate. \n\nWe provide examples to run ORB-SLAM3 in the [EuRoC dataset](http://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets) using stereo or monocular, with or without IMU, and in the [TUM-VI dataset](https://vision.in.tum.de/data/datasets/visual-inertial-dataset) using fisheye stereo or monocular, with or without IMU. Videos of some example executions can be found at [ORB-SLAM3 channel](https://www.youtube.com/channel/UCXVt-kXG6T95Z4tVaYlU80Q).\n\nThis software is based on [ORB-SLAM2](https://github.com/raulmur/ORB_SLAM2) developed by [Raul Mur-Artal](http://webdiis.unizar.es/~raulmur/), [Juan D. Tardos](http://webdiis.unizar.es/~jdtardos/), [J. M. M. Montiel](http://webdiis.unizar.es/~josemari/) and [Dorian Galvez-Lopez](http://doriangalvez.com/) ([DBoW2](https://github.com/dorian3d/DBoW2)).\n\n<a href=\"https://youtu.be/HyLNq-98LRo\" target=\"_blank\"><img src=\"https://img.youtube.com/vi/HyLNq-98LRo/0.jpg\" \nalt=\"ORB-SLAM3\" width=\"240\" height=\"180\" border=\"10\" /></a>\n\n### Related Publications:\n\n[ORB-SLAM3] Carlos Campos, Richard Elvira, Juan J. G√≥mez Rodr√≠guez, Jos√© M. M. Montiel and Juan D. Tard√≥s, **ORB-SLAM3: An Accurate Open-Source Library for Visual, Visual-Inertial and Multi-Map SLAM**, *IEEE Transactions on Robotics 37(6):1874-1890, Dec. 2021*. **[PDF](https://arxiv.org/abs/2007.11898)**.\n\n[IMU-Initialization] Carlos Campos, J. M. M. Montiel and Juan D. Tard√≥s, **Inertial-Only Optimization for Visual-Inertial Initialization**, *ICRA 2020*. **[PDF](https://arxiv.org/pdf/2003.05766.pdf)**\n\n[ORBSLAM-Atlas] Richard Elvira, J. M. M. Montiel and Juan D. Tard√≥s, **ORBSLAM-Atlas: a robust and accurate multi-map system**, *IROS 2019*. **[PDF](https://arxiv.org/pdf/1908.11585.pdf)**.\n\n[ORBSLAM-VI] Ra√∫l Mur-Artal, and Juan D. Tard√≥s, **Visual-inertial monocular SLAM with map reuse**, IEEE Robotics and Automation Letters, vol. 2 no. 2, pp. 796-803, 2017. **[PDF](https://arxiv.org/pdf/1610.05949.pdf)**. \n\n[Stereo and RGB-D] Ra√∫l Mur-Artal and Juan D. Tard√≥s. **ORB-SLAM2: an Open-Source SLAM System for Monocular, Stereo and RGB-D Cameras**. *IEEE Transactions on Robotics,* vol. 33, no. 5, pp. 1255-1262, 2017. **[PDF](https://arxiv.org/pdf/1610.06475.pdf)**.\n\n[Monocular] Ra√∫l Mur-Artal, Jos√© M. M. Montiel and Juan D. Tard√≥s. **ORB-SLAM: A Versatile and Accurate Monocular SLAM System**. *IEEE Transactions on Robotics,* vol. 31, no. 5, pp. 1147-1163, 2015. (**2015 IEEE Transactions on Robotics Best Paper Award**). **[PDF](https://arxiv.org/pdf/1502.00956.pdf)**.\n\n[DBoW2 Place Recognition] Dorian G√°lvez-L√≥pez and Juan D. Tard√≥s. **Bags of Binary Words for Fast Place Recognition in Image Sequences**. *IEEE Transactions on Robotics,* vol. 28, no. 5, pp. 1188-1197, 2012. **[PDF](http://doriangalvez.com/php/dl.php?dlp=GalvezTRO12.pdf)**\n\n# 1. License\n\nORB-SLAM3 is released under [GPLv3 license](https://github.com/UZ-SLAMLab/ORB_SLAM3/LICENSE). For a list of all code/library dependencies (and associated licenses), please see [Dependencies.md](https://github.com/UZ-SLAMLab/ORB_SLAM3/blob/master/Dependencies.md).\n\nFor a closed-source version of ORB-SLAM3 for commercial purposes, please contact the authors: orbslam (at) unizar (dot) es.\n\nIf you use ORB-SLAM3 in an academic work, please cite:\n  \n    @article{ORBSLAM3_TRO,\n      title={{ORB-SLAM3}: An Accurate Open-Source Library for Visual, Visual-Inertial \n               and Multi-Map {SLAM}},\n      author={Campos, Carlos AND Elvira, Richard AND G\\¬¥omez, Juan J. AND Montiel, \n              Jos\\'e M. M. AND Tard\\'os, Juan D.},\n      journal={IEEE Transactions on Robotics}, \n      volume={37},\n      number={6},\n      pages={1874-1890},\n      year={2021}\n     }\n\n# 2. Prerequisites\nWe have tested the library in **Ubuntu 16.04** and **18.04**, but it should be easy to compile in other platforms. A powerful computer (e.g. i7) will ensure real-time performance and provide more stable and accurate results.\n\n## C++11 or C++0x Compiler\nWe use the new thread and chrono functionalities of C++11.\n\n## Pangolin\nWe use [Pangolin](https://github.com/stevenlovegrove/Pangolin) for visualization and user interface. Dowload and install instructions can be found at: https://github.com/stevenlovegrove/Pangolin.\n\n## OpenCV\nWe use [OpenCV](http://opencv.org) to manipulate images and features. Dowload and install instructions can be found at: http://opencv.org. **Required at leat 3.0. Tested with OpenCV 3.2.0 and 4.4.0**.\n\n## Eigen3\nRequired by g2o (see below). Download and install instructions can be found at: http://eigen.tuxfamily.org. **Required at least 3.1.0**.\n\n## DBoW2 and g2o (Included in Thirdparty folder)\nWe use modified versions of the [DBoW2](https://github.com/dorian3d/DBoW2) library to perform place recognition and [g2o](https://github.com/RainerKuemmerle/g2o) library to perform non-linear optimizations. Both modified libraries (which are BSD) are included in the *Thirdparty* folder.\n\n## Python\nRequired to calculate the alignment of the trajectory with the ground truth. **Required Numpy module**.\n\n* (win) http://www.python.org/downloads/windows\n* (deb) `sudo apt install libpython2.7-dev`\n* (mac) preinstalled with osx\n\n## ROS (optional)\n\nWe provide some examples to process input of a monocular, monocular-inertial, stereo, stereo-inertial or RGB-D camera using ROS. Building these examples is optional. These have been tested with ROS Melodic under Ubuntu 18.04.\n\n# 3. Building ORB-SLAM3 library and examples\n\nClone the repository:\n```\ngit clone https://github.com/UZ-SLAMLab/ORB_SLAM3.git ORB_SLAM3\n```\n\nWe provide a script `build.sh` to build the *Thirdparty* libraries and *ORB-SLAM3*. Please make sure you have installed all required dependencies (see section 2). Execute:\n```\ncd ORB_SLAM3\nchmod +x build.sh\n./build.sh\n```\n\nThis will create **libORB_SLAM3.so**  at *lib* folder and the executables in *Examples* folder.\n\n# 4. Running ORB-SLAM3 with your camera\n\nDirectory `Examples` contains several demo programs and calibration files to run ORB-SLAM3 in all sensor configurations with Intel Realsense cameras T265 and D435i. The steps needed to use your own camera are: \n\n1. Calibrate your camera following `Calibration_Tutorial.pdf` and write your calibration file `your_camera.yaml`\n\n2. Modify one of the provided demos to suit your specific camera model, and build it\n\n3. Connect the camera to your computer using USB3 or the appropriate interface\n\n4. Run ORB-SLAM3. For example, for our D435i camera, we would execute:\n\n```\n./Examples/Stereo-Inertial/stereo_inertial_realsense_D435i Vocabulary/ORBvoc.txt ./Examples/Stereo-Inertial/RealSense_D435i.yaml\n```\n\n# 5. EuRoC Examples\n[EuRoC dataset](http://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets) was recorded with two pinhole cameras and an inertial sensor. We provide an example script to launch EuRoC sequences in all the sensor configurations.\n\n1. Download a sequence (ASL format) from http://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets\n\n2. Open the script \"euroc_examples.sh\" in the root of the project. Change **pathDatasetEuroc** variable to point to the directory where the dataset has been uncompressed. \n\n3. Execute the following script to process all the sequences with all sensor configurations:\n```\n./euroc_examples\n```\n\n## Evaluation\nEuRoC provides ground truth for each sequence in the IMU body reference. As pure visual executions report trajectories centered in the left camera, we provide in the \"evaluation\" folder the transformation of the ground truth to the left camera reference. Visual-inertial trajectories use the ground truth from the dataset.\n\nExecute the following script to process sequences and compute the RMS ATE:\n```\n./euroc_eval_examples\n```\n\n# 6. TUM-VI Examples\n[TUM-VI dataset](https://vision.in.tum.de/data/datasets/visual-inertial-dataset) was recorded with two fisheye cameras and an inertial sensor.\n\n1. Download a sequence from https://vision.in.tum.de/data/datasets/visual-inertial-dataset and uncompress it.\n\n2. Open the script \"tum_vi_examples.sh\" in the root of the project. Change **pathDatasetTUM_VI** variable to point to the directory where the dataset has been uncompressed. \n\n3. Execute the following script to process all the sequences with all sensor configurations:\n```\n./tum_vi_examples\n```\n\n## Evaluation\nIn TUM-VI ground truth is only available in the room where all sequences start and end. As a result the error measures the drift at the end of the sequence. \n\nExecute the following script to process sequences and compute the RMS ATE:\n```\n./tum_vi_eval_examples\n```\n\n# 7. ROS Examples\n\n### Building the nodes for mono, mono-inertial, stereo, stereo-inertial and RGB-D\nTested with ROS Melodic and ubuntu 18.04.\n\n1. Add the path including *Examples/ROS/ORB_SLAM3* to the ROS_PACKAGE_PATH environment variable. Open .bashrc file:\n  ```\n  gedit ~/.bashrc\n  ```\nand add at the end the following line. Replace PATH by the folder where you cloned ORB_SLAM3:\n\n  ```\n  export ROS_PACKAGE_PATH=${ROS_PACKAGE_PATH}:PATH/ORB_SLAM3/Examples/ROS\n  ```\n  \n2. Execute `build_ros.sh` script:\n\n  ```\n  chmod +x build_ros.sh\n  ./build_ros.sh\n  ```\n  \n### Running Monocular Node\nFor a monocular input from topic `/camera/image_raw` run node ORB_SLAM3/Mono. You will need to provide the vocabulary file and a settings file. See the monocular examples above.\n\n  ```\n  rosrun ORB_SLAM3 Mono PATH_TO_VOCABULARY PATH_TO_SETTINGS_FILE\n  ```\n\n### Running Monocular-Inertial Node\nFor a monocular input from topic `/camera/image_raw` and an inertial input from topic `/imu`, run node ORB_SLAM3/Mono_Inertial. Setting the optional third argument to true will apply CLAHE equalization to images (Mainly for TUM-VI dataset).\n\n  ```\n  rosrun ORB_SLAM3 Mono PATH_TO_VOCABULARY PATH_TO_SETTINGS_FILE [EQUALIZATION]\t\n  ```\n\n### Running Stereo Node\nFor a stereo input from topic `/camera/left/image_raw` and `/camera/right/image_raw` run node ORB_SLAM3/Stereo. You will need to provide the vocabulary file and a settings file. For Pinhole camera model, if you **provide rectification matrices** (see Examples/Stereo/EuRoC.yaml example), the node will recitify the images online, **otherwise images must be pre-rectified**. For FishEye camera model, rectification is not required since system works with original images:\n\n  ```\n  rosrun ORB_SLAM3 Stereo PATH_TO_VOCABULARY PATH_TO_SETTINGS_FILE ONLINE_RECTIFICATION\n  ```\n\n### Running Stereo-Inertial Node\nFor a stereo input from topics `/camera/left/image_raw` and `/camera/right/image_raw`, and an inertial input from topic `/imu`, run node ORB_SLAM3/Stereo_Inertial. You will need to provide the vocabulary file and a settings file, including rectification matrices if required in a similar way to Stereo case:\n\n  ```\n  rosrun ORB_SLAM3 Stereo_Inertial PATH_TO_VOCABULARY PATH_TO_SETTINGS_FILE ONLINE_RECTIFICATION [EQUALIZATION]\t\n  ```\n  \n### Running RGB_D Node\nFor an RGB-D input from topics `/camera/rgb/image_raw` and `/camera/depth_registered/image_raw`, run node ORB_SLAM3/RGBD. You will need to provide the vocabulary file and a settings file. See the RGB-D example above.\n\n  ```\n  rosrun ORB_SLAM3 RGBD PATH_TO_VOCABULARY PATH_TO_SETTINGS_FILE\n  ```\n\n**Running ROS example:** Download a rosbag (e.g. V1_02_medium.bag) from the EuRoC dataset (http://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets). Open 3 tabs on the terminal and run the following command at each tab for a Stereo-Inertial configuration:\n  ```\n  roscore\n  ```\n  \n  ```\n  rosrun ORB_SLAM3 Stereo_Inertial Vocabulary/ORBvoc.txt Examples/Stereo-Inertial/EuRoC.yaml true\n  ```\n  \n  ```\n  rosbag play --pause V1_02_medium.bag /cam0/image_raw:=/camera/left/image_raw /cam1/image_raw:=/camera/right/image_raw /imu0:=/imu\n  ```\n  \nOnce ORB-SLAM3 has loaded the vocabulary, press space in the rosbag tab.\n\n**Remark:** For rosbags from TUM-VI dataset, some play issue may appear due to chunk size. One possible solution is to rebag them with the default chunk size, for example:\n  ```\n  rosrun rosbag fastrebag.py dataset-room1_512_16.bag dataset-room1_512_16_small_chunks.bag\n  ```\n\n# 8. Running time analysis\nA flag in `include\\Config.h` activates time measurements. It is necessary to uncomment the line `#define REGISTER_TIMES` to obtain the time stats of one execution which is shown at the terminal and stored in a text file(`ExecTimeMean.txt`).\n\n# 9. Calibration\nYou can find a tutorial for visual-inertial calibration and a detailed description of the contents of valid configuration files at  `Calibration_Tutorial.pdf`\n",
      "stars_today": 8
    },
    {
      "id": 19816070,
      "name": "server",
      "full_name": "MariaDB/server",
      "description": "MariaDB server is a community developed fork of MySQL server. Started by core members of the original MySQL team, MariaDB actively works with outside developers to deliver the most featureful, stable, and sanely licensed open SQL server in the industry.",
      "html_url": "https://github.com/MariaDB/server",
      "stars": 6925,
      "forks": 1926,
      "language": "C++",
      "topics": [
        "amazon-web-services",
        "database",
        "fulltext-search",
        "galera",
        "geographical-information-system",
        "innodb",
        "json",
        "mariadb",
        "mysql",
        "nearest-neighbor-search",
        "rdbms",
        "relational-databases",
        "sql",
        "storage-engine",
        "vector-database"
      ],
      "created_at": "2014-05-15T10:58:50Z",
      "updated_at": "2026-01-13T20:41:33Z",
      "pushed_at": "2026-01-14T00:51:49Z",
      "open_issues": 250,
      "owner": {
        "login": "MariaDB",
        "avatar_url": "https://avatars.githubusercontent.com/u/4739304?v=4"
      },
      "readme": "# Code status:\n\n* [![Appveyor CI status](https://ci.appveyor.com/api/projects/status/4u6pexmtpuf8jq66?svg=true)](https://ci.appveyor.com/project/rasmushoj/server) ci.appveyor.com\n\n## MariaDB: The innovative open source database\n\nMariaDB was designed as a drop-in replacement of MySQL(R) with more\nfeatures, new storage engines, fewer bugs, and better performance.\n\nMariaDB is brought to you by the MariaDB Foundation and the MariaDB Corporation.\nPlease read the CREDITS file for details about the MariaDB Foundation,\nand who is developing MariaDB.\n\nMariaDB is developed by many of the original developers of MySQL who\nnow work for the MariaDB Corporation, the MariaDB Foundation and by\nmany people in the community.\n\nMySQL, which is the base of MariaDB, is a product and trademark of Oracle\nCorporation, Inc. For a list of developers and other contributors,\nsee the Credits appendix.  You can also run 'SHOW authors' to get a\nlist of active contributors.\n\nA description of the MariaDB project and a manual can be found at:\n\nhttps://mariadb.org\n\nhttps://mariadb.com/kb/en/\n\nhttps://mariadb.com/kb/en/mariadb-vs-mysql-features/\n\nhttps://mariadb.com/kb/en/mariadb-versus-mysql-compatibility/\n\nhttps://mariadb.com/kb/en/new-and-old-releases/\n\n# Getting the code, building it and testing it\n\nRefer to the following guide: https://mariadb.org/get-involved/getting-started-for-developers/get-code-build-test/\nwhich outlines how to build the source code correctly and run the MariaDB testing framework,\nas well as which branch to target for your contributions.\n\n# Help\n\nMore help is available from the Maria Discuss mailing list\nhttps://lists.mariadb.org/postorius/lists/discuss.lists.mariadb.org/ and MariaDB's Zulip\ninstance, https://mariadb.zulipchat.com/\n\n# Licensing\n\n***************************************************************************\n\nMariaDB is specifically available only under version 2 of the GNU\nGeneral Public License (GPLv2). (I.e. Without the \"any later version\"\nclause.) This is inherited from MySQL. Please see the README file in\nthe MySQL distribution for more information.\n\nLicense information can be found in the COPYING file. Third party\nlicense information can be found in the THIRDPARTY file.\n\n***************************************************************************\n\n# Bug Reports\n\nBug and/or error reports regarding MariaDB should be submitted at:\nhttps://jira.mariadb.org\n\nFor reporting security vulnerabilities, see our [security-policy](https://mariadb.org/about/security-policy/).\n\nThe code for MariaDB, including all revision history, can be found at:\nhttps://github.com/MariaDB/server\n",
      "stars_today": 8
    },
    {
      "id": 881723326,
      "name": "Atoll",
      "full_name": "Ebullioscopic/Atoll",
      "description": "Dynamic Island for macOS",
      "html_url": "https://github.com/Ebullioscopic/Atoll",
      "stars": 668,
      "forks": 46,
      "language": "Swift",
      "topics": [
        "dynamicisland",
        "hacktoberfest",
        "macbook",
        "macos"
      ],
      "created_at": "2024-11-01T05:06:09Z",
      "updated_at": "2026-01-13T20:54:36Z",
      "pushed_at": "2026-01-12T12:03:01Z",
      "open_issues": 31,
      "owner": {
        "login": "Ebullioscopic",
        "avatar_url": "https://avatars.githubusercontent.com/u/83903166?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\".github/assets/atoll-logo.png\" alt=\"Atoll logo\" width=\"120\">\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/Ebullioscopic/Atoll/stargazers\">\n    <img src=\"https://img.shields.io/github/stars/Ebullioscopic/Atoll?style=social\" alt=\"GitHub stars\"/>\n  </a>\n  <a href=\"https://github.com/Ebullioscopic/Atoll/network/members\">\n    <img src=\"https://img.shields.io/github/forks/Ebullioscopic/Atoll?style=social\" alt=\"GitHub forks\"/>\n  </a>\n  <a href=\"https://github.com/Ebullioscopic/Atoll/releases\">\n    <img src=\"https://img.shields.io/github/downloads/Ebullioscopic/Atoll/total?label=Downloads\" alt=\"GitHub downloads\"/>\n  </a>\n  <a href=\"https://discord.gg/PaqFkRTDF8\">\n    <img src=\"https://img.shields.io/discord/1429481472942669896?label=Discord&logo=discord&color=7289da\" alt=\"Discord server\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/sponsors/Ebullioscopic\">\n    <img src=\"https://img.shields.io/badge/Sponsor-Ebullioscopic-ff69b4?style=for-the-badge&logo=github\" alt=\"Sponsor Ebullioscopic\"/>\n  </a>\n  <a href=\"https://github.com/Ebullioscopic/Atoll/releases/download/v1.2.2-beta/Atoll.1.2.2-beta.dmg\">\n    <img src=\"https://img.shields.io/badge/Download-Atoll%20for%20macOS-0A84FF?style=for-the-badge&logo=apple\" alt=\"Download Atoll for macOS\"/>\n  </a>\n  <a href=\"https://www.buymeacoffee.com/kryoscopic\">\n    <img src=\"https://img.shields.io/badge/Buy%20Me%20A%20Coffee-kryoscopic-FFDD00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=000000\" alt=\"Buy Me a Coffee for kryoscopic\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://discord.gg/PaqFkRTDF8\">Join our Discord community</a>\n</p>\n\n**Project rename:** DynamicIsland is now called **Atoll**. Visit the new repository at [github.com/Ebullioscopic/Atoll](https://github.com/Ebullioscopic/Atoll).\n\n# Atoll\n\nAtoll turns the MacBook notch into a focused command surface for media, system insight, and quick utilities. It stays out of the way until needed, then expands with responsive, native SwiftUI animations.\n\n## UI Modes\n\n### Minimalistic Mode\n- Compact layout focused on core actions and quick glance info.\n- Ideal when you want media and essentials without wider panels.\n\n<p align=\"center\">\n  <img src=\".github/assets/Minimalistic-v1.2.gif\" alt=\"Minimalistic UI\" width=\"520\">\n</p>\n\n### Standard Mode\n- Full-width experience with richer layouts, panels, and context.\n- Best for deep control of media, stats, and productivity tools.\n\n<p align=\"center\">\n  <img src=\".github/assets/Non-minimalistic-v1.2.gif\" alt=\"Standard UI\" width=\"520\">\n</p>\n\n## Calendar & Reminders\n- Clean calendar panel with upcoming events and reminders.\n- Efficient EventKit usage to minimise refreshes and background churn.\n- Clear timeline of upcoming items; grants only when you approve Calendar access.\n\n<p align=\"center\">\n  <img src=\".github/assets/Calendar-v1.2.gif\" alt=\"Calendar and reminders\" width=\"520\">\n</p>\n\n## Timers\n- Named timers with live activity state, clear progress, and alerts.\n- Choose circular ring or linear bar; pick tints that match your setup.\n- Controls live both in the notch and via menu bar for quick access.\n\n<p align=\"center\">\n  <img src=\".github/assets/Timer-v1.2.gif\" alt=\"Timers\" width=\"520\">\n</p>\n\n## Do Not Disturb\n- One-tap Focus toggle with immediate visual feedback near the notch.\n- See current status at a glance without digging through menus.\n\n<p align=\"center\">\n  <img src=\".github/assets/DND-v1.2.gif\" alt=\"Do Not Disturb\" width=\"520\">\n</p>\n\n## Lock Screen Widgets\n- Media playback controls with artwork and transport.\n- Active timer progress with visual feedback.\n- Device charging status and battery levels.\n- Connected Bluetooth devices and their battery states.\n- Current weather conditions and forecast.\n\n<p align=\"center\">\n  <img src=\".github/assets/lockscreen-v1.2.gif\" alt=\"Do Not Disturb\" width=\"520\">\n</p>\n\n## Live Activities\n\n- Media Playback\n- Focus Mode\n- Screen Recording\n- Microphone, Camera Privacy Indicators\n- Connected Bluetooth Devices\n- Download progress `beta`\n- Low Battery status, Charging\n\n## Overview\n- Media controls for Apple Music, Spotify, and more with inline previews.\n- Live system insight (CPU, GPU, memory, network, disk) with lightweight graphs.\n- Productivity tools: clipboard history, colour picker, timers, calendar.\n- Optional minimalistic layout for a compact 420px notch footprint.\n\n## Features\n- Media: artwork and transport controls, inline sneak-peek, adaptive lighting that subtly echoes album colours.\n- System: lightweight CPU/GPU/memory/network/disk graphs; drill into quick popovers when you need details.\n- Productivity: rich timers with live activity, precise colour picker with formats, and a searchable clipboard history.\n- Calendar: streamlined agenda with snapshot-driven updates to keep EventKit usage lean.\n- Lock Screen: weather, media, charging, and Bluetooth battery widgets that respect system accessory styles.\n- Parallax interactions: hover tilt now stays responsive while clicks fire immediately, and the lock screen album art suspends the effect mid-animation for smooth expansions.\n- Customisation: minimalistic/standard layouts, animation styles, hover behaviour, and full shortcut remapping.\n\n## Requirements\n- macOS 14.0 or later (optimised for macOS 15+).\n- MacBook with a notch (14/16‚Äëinch MBP across Apple silicon generations).\n- Xcode 15+ to build from source.\n- Permissions as needed: Accessibility, Camera, Calendar, Screen Recording, Music.\n\n## Installation\n1) Clone and open the project\n```bash\ngit clone https://github.com/Ebullioscopic/Atoll.git\ncd Atoll\nopen DynamicIsland.xcodeproj\n```\n2) Select your Mac as the run destination, then build and run (‚åòR).\n3) Grant prompted permissions. The menu bar icon appears and the notch activates on hover.\n\n## Quick Start\n- Hover near the notch to expand; click to enter controls.\n- Use tabs for Media, Stats, Timers, Clipboard, and more.\n- Toggle Minimalistic Mode from Settings for a smaller layout.\n\n## Settings\n- Choose appearance, animation style, and per‚Äëfeature toggles.\n- Remap global shortcuts and adjust hover behaviour.\n- Enable lock screen widgets and select data sources.\n\n## Gesture Controls\n- Two-finger swipe down to open the notch when hover-to-open is disabled; swipe up to close.\n- Enable horizontal media gestures in **Settings ‚Üí General ‚Üí Gesture control** to turn the music pane into a trackpad for previous/next or ¬±10 second seeks.\n- Pick the gesture skip behaviour (track vs ¬±10s) independently from the skip button configuration so swipes can scrub while buttons change tracks‚Äîor vice versa.\n- Horizontal swipes trigger the same haptics and button animations you see in the notch, keeping visual feedback consistent with tap interactions.\n\n## Troubleshooting (Basics)\n- After granting Accessibility or Screen Recording, quit and relaunch the app.\n- If metrics are empty, enable categories in Settings ‚Üí Stats.\n- Media not responding: verify player is active and Music permission is granted.\n\n## License\nAtoll is released under the GPL v3 License. Refer to [LICENSE](LICENSE) for the full terms.\n\n## Acknowledgments\n\nAtoll builds upon the work of several open-source projects and draws inspiration from innovative macOS applications:\n\n- [**Boring.Notch**](https://github.com/TheBoredTeam/boring.notch) - foundational codebase that provided the initial media player integration, AirDrop surface implementation, file dock functionality, and calendar event display. Major architectural patterns and notch interaction models were adapted from this project.\n\n- [**Alcove**](https://tryalcove.com) - primary inspiration for the Minimalistic Mode interface design and the conceptual framework for lock screen widget integration that informed Atoll's compact layout strategy.\n\n- [**Stats**](https://github.com/exelban/stats) - source implementation for CPU temperature monitoring via SMC (System Management Controller) access, frequency sampling through IOReport bindings, and per-core CPU utilisation tracking. The system metrics collection architecture derives from Stats project readers.\n\n- [**Open Meteo**](https://open-meteo.com) - weather apis for the lock screen widgets\n\n- [**SkyLightWindow**](https://github.com/Lakr233/SkyLightWindow) - window rendering for Lock Screen Widgets\n\n- Wick - Thanks Nate for allowing us to replicate the iOS like Timer design for the Lock Screen Widget\n## Contributors\n\n<a href=\"https://github.com/Ebullioscopic/Atoll/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=Ebullioscopic/Atoll\" />\n</a>\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=Ebullioscopic/Atoll&type=timeline&legend=top-left)](https://www.star-history.com/#Ebullioscopic/Atoll&type=timeline&legend=top-left)\n\n## Updating Existing Clones\nIf you previously cloned DynamicIsland, update the remote to track the Atoll repository:\n\n```bash\ngit remote set-url origin https://github.com/Ebullioscopic/Atoll.git\n```\n\nA heartfelt thanks to [TheBoredTeam](https://github.com/TheBoredTeam) for being supportive and being totally awesome, Atoll would not have been possible without Boring.Notch\n\n---\n\n<p align=\"center\">\n  <img src=\".github/assets/iosdevcentre.jpeg\" alt=\"iOS Development Centre exterior\" width=\"420\">\n  <br>\n  <sub>Backed by</sub>\n  <br>\n  <strong>iOS Development Centre</strong>\n  <br>\n  Powered by Apple and Infosys\n  <br>\n  SRM Institute of Science and Technology, Chennai, India\n</p>",
      "stars_today": 8
    },
    {
      "id": 3470471,
      "name": "Font-Awesome",
      "full_name": "FortAwesome/Font-Awesome",
      "description": "The iconic SVG, font, and CSS toolkit",
      "html_url": "https://github.com/FortAwesome/Font-Awesome",
      "stars": 76217,
      "forks": 12247,
      "language": "JavaScript",
      "topics": [
        "css",
        "font",
        "fontawesome",
        "icons",
        "svg-icons",
        "svg-sprites",
        "webfont"
      ],
      "created_at": "2012-02-17T14:19:43Z",
      "updated_at": "2026-01-14T00:33:15Z",
      "pushed_at": "2025-12-12T16:04:31Z",
      "open_issues": 303,
      "owner": {
        "login": "FortAwesome",
        "avatar_url": "https://avatars.githubusercontent.com/u/1505683?v=4"
      },
      "readme": "<h1><img src=\"https://img.fortawesome.com/349cfdf6/fa-free-logo.svg\" alt=\"Font Awesome Free\" width=\"50%\"></h1>\n\n> Version 7\n\nFont Awesome is the Internet's icon library and toolkit, used by millions of\ndesigners, developers, and content creators.\n\n## Documentation\n\nLearn how to get started with Font Awesome and then dive deeper into other and advanced topics:\n\n[Docs for version 7](https://fontawesome.com/docs)\n\n### Where did Font Awesome 6, 5, 4 (or 3) go?\n\nNow that Font Awesome 7 has been released we are marking version 6 as Long Term\nSupport (LTS). Version 6 will get critical bug fixes only. Version 3, 4, and 5 are\nnow end-of-life and we don't plan on releasing any further versions of these.\n\nYou can see a complete list of versions on [our Versions\npage](https://fontawesome.com/versions).\n\n## Change log\n\nThe change log for releases is now [available directly on our site](https://fontawesome.com/docs/changelog/).\n\nLooking for older versions of Font Awesome? Check the [releases](https://github.com/FortAwesome/Font-Awesome/releases).\n\n## Upgrading\n\nFrom time-to-time we'll have special upgrading instructions from one version to the next.\n\n- [Web upgrading guide](https://docs.fontawesome.com/upgrade/upgrade-on-web)\n- [Desktop upgrading guide](https://docs.fontawesome.com/upgrade/upgrade-on-desktop)\n\n## Code of conduct\n\nWe will behave ourselves if you behave yourselves. For more details see our\n[CODE_OF_CONDUCT.md](./CODE_OF_CONDUCT.md).\n\n## Contributing\n\nPlease read through our [contributing guidelines](./CONTRIBUTING.md).  Included\nare directions for opening issues.\n\n## Versioning\n\nFont Awesome will be maintained under the Semantic Versioning guidelines as much as possible. Releases will be numbered\nwith the following format:\n\n`<major>.<minor>.<patch>`\n\nFor more information on SemVer, please visit https://semver.org.\n\n**The major version \"7\" is part of an umbrella release.  It includes many different types of files and technologies. Therefore\nwe deviate from normal SemVer in the following ways:**\n\n* Any release may update the design, look-and-feel, or branding of an existing\n  icon\n* We will never intentionally release a `patch` version update that breaks\n  backward compatibility\n* A `minor` release **may include backward-incompatible changes** but we will\n  write clear upgrading instructions in UPGRADING.md\n* A `minor` or `patch` release will never remove icons\n* Bug fixes will be addressed as `patch` releases unless they include backward\n  incompatibility then they will be `minor` releases\n\n## License\n\nFont Awesome Free is free, open source, and GPL friendly. You can use it for\ncommercial projects, open source projects, or really almost whatever you want.\n\n- Icons ‚Äî CC BY 4.0 License\n  - In the Font Awesome Free download, the CC BY 4.0 license applies to all icons packaged as .svg and .js files types.\n- Fonts ‚Äî SIL OFL 1.1 License\n  - In the Font Awesome Free download, the SIL OFL license applies to all icons packaged as web and desktop font files.\n- Code ‚Äî MIT License\n  - In the Font Awesome Free download, the MIT license applies to all non-font and non-icon files.\n\nAttribution is required by MIT, SIL OFL, and CC BY licenses. Downloaded Font\nAwesome Free files already contain embedded comments with sufficient\nattribution, so you shouldn't need to do anything additional when using these\nfiles normally.\n\nWe've kept attribution comments terse, so we ask that you do not actively work\nto remove them from files, especially code. They're a great way for folks to\nlearn about Font Awesome.\n\n## Team\n\nhttps://github.com/orgs/FortAwesome/people\n",
      "stars_today": 7
    },
    {
      "id": 3777210,
      "name": "squirrel",
      "full_name": "rime/squirrel",
      "description": "„ÄêÈº†È¨öÁÆ°„ÄëRime for macOS",
      "html_url": "https://github.com/rime/squirrel",
      "stars": 5618,
      "forks": 458,
      "language": "Swift",
      "topics": [],
      "created_at": "2012-03-20T16:17:18Z",
      "updated_at": "2026-01-14T00:17:34Z",
      "pushed_at": "2026-01-14T00:24:56Z",
      "open_issues": 193,
      "owner": {
        "login": "rime",
        "avatar_url": "https://avatars.githubusercontent.com/u/10554324?v=4"
      },
      "readme": "    Èº†È¨öÁÆ°\n    Áà≤Áâ©ÈõñÂæÆÊÉÖ‰∏çÊ∑∫\n    Êñ∞Ë©©ÈÜâÂ¢®ÊôÇ‰∏ÄÊèÆ\n    Âà•ÂæåÂØÑÊàëÁÑ°Ëæ≠ÈÅ†\n\n    „ÄÄ„ÄÄ„ÄÄ‚Äî‚ÄîÊ≠êÈôΩ‰øÆ\n\n‰ªäÁî±„ÄÄ[‰∏≠Â∑ûÈüªËº∏ÂÖ•Ê≥ïÂºïÊìéÔºèRime Input Method Engine](https://rime.im)\nÂèäÂÖ∂‰ªñÈñãÊ∫êÊäÄË°ìÂº∑ÂäõÈ©ÖÂãï\n\n„ÄêÈº†È¨öÁÆ°„ÄëËº∏ÂÖ•Ê≥ï\n===\n[![Download](https://img.shields.io/github/v/release/rime/squirrel)](https://github.com/rime/squirrel/releases/latest)\n[![Build Status](https://github.com/rime/squirrel/actions/workflows/commit-ci.yml/badge.svg)](https://github.com/rime/squirrel/actions/workflows)\n[![GitHub Tag](https://img.shields.io/github/tag/rime/squirrel.svg)](https://github.com/rime/squirrel)\n\nÂºèÊÅïÂ†Ç ÁâàÊ¨äÊâÄÁÑ°\n\nÊéàÊ¨äÊ¢ùÊ¨æÔºö[GPL v3](https://www.gnu.org/licenses/gpl-3.0.en.html)\n\nÈ†ÖÁõÆ‰∏ªÈ†ÅÔºö[rime.im](https://rime.im)\n\nÊÇ®ÂèØËÉΩÈÇÑÈúÄË¶Å Rime Áî®ÊñºÂÖ∂‰ªñÊìç‰ΩúÁ≥ªÁµ±ÁöÑÁôºË°åÁâàÔºö\n\n  * „Äê‰∏≠Â∑ûÈüª„ÄëÔºàibus-rime„ÄÅfcitx-rimeÔºâÁî®Êñº Linux\n  * „ÄêÂ∞èÁãºÊØ´„ÄëÁî®Êñº Windows\n\nÂÆâË£ùËº∏ÂÖ•Ê≥ï\n---\n\nÊú¨ÂìÅÈÅ©Áî®Êñº macOS 13.0+\n\nÂàùÊ¨°ÂÆâË£ùÔºåÂ¶ÇÊûúÂú®ÈÉ®‰ªΩÊáâÁî®Á®ãÂ∫è‰∏≠Êâì‰∏çÂá∫Â≠óÔºåË´ãË®ªÈä∑‰∏¶ÈáçÊñ∞ÁôªÈåÑ„ÄÇ\n\n‰ΩøÁî®Ëº∏ÂÖ•Ê≥ï\n---\n\nÈÅ∏ÂèñËº∏ÂÖ•Ê≥ïÊåáÁ§∫Âô®ËèúÂñÆË£èÁöÑ„Äê„Ñì„ÄëÂ≠óÊ®£ÂúñÊ®ôÔºåÈñãÂßãÁî®Èº†È¨öÁÆ°ÂØ´Â≠ó„ÄÇ\nÈÄöÈÅéÂø´Êç∑Èçµ `` Ctrl+` `` Êàñ `F4` ÂëºÂá∫ÊñπÊ°àÈÅ∏ÂñÆ„ÄÅÂàáÊèõËº∏ÂÖ•ÊñπÂºè„ÄÇ\n\nÂÆöË£ΩËº∏ÂÖ•Ê≥ï\n---\n\nÂÆöË£ΩÊñπÊ≥ïÔºåË´ãÂèÉËÄÉÁ∑ö‰∏ä [Âπ´Âä©ÊñáÊ™î](https://rime.im/docs/)„ÄÇ\n\n‰ΩøÁî®Á≥ªÁµ±Ëº∏ÂÖ•Ê≥ïËèúÂñÆÔºö\n\n  * ÈÅ∏‰∏≠„ÄåÂú®Á∑öÊñáÊ™î„ÄçÂèØÊâìÈñã‰ª•‰∏äÁ∂≤ÂùÄ\n  * Á∑®ËºØÁî®Êà∂Ë®≠ÂÆöÂæåÔºåÈÅ∏Êìá„ÄåÈáçÊñ∞ÈÉ®ÁΩ≤„Äç‰ª•‰ª§‰øÆÊîπÁîüÊïà\n\nÂÆâË£ùËº∏ÂÖ•ÊñπÊ°à\n---\n\n‰ΩøÁî® [/plum/](https://github.com/rime/plum) ÈÖçÁΩÆÁÆ°ÁêÜÂô®Áç≤ÂèñÊõ¥Â§öËº∏ÂÖ•ÊñπÊ°à„ÄÇ\n\nËá¥Ë¨ù\n---\n\nËº∏ÂÖ•ÊñπÊ°àË®≠Ë®àÔºö\n\n  * „ÄêÊúôÊúàÊãºÈü≥„ÄëÁ≥ªÂàó\n\n    ÊÑüË¨ù CC-CEDICT„ÄÅAndroid ÊãºÈü≥„ÄÅÊñ∞ÈÖ∑Èü≥„ÄÅopencc Á≠âÈñãÊ∫êÈ†ÖÁõÆ\n\nÁ®ãÂ∫èË®≠Ë®àÔºö\n\n  * ‰ΩõÊåØ\n  * Linghua Zhang\n  * Chongyu Zhu\n  * Èõ™ÈΩã\n  * faberii\n  * Chun-wei Kuo\n  * Junlu Cheng\n  * Jak Wings\n  * xiehuc\n\nÁæéË°ìÔºö\n\n  * ÂúñÊ®ôË®≠Ë®à ‰ΩõÊåØ„ÄÅÊ¢ÅÊµ∑„ÄÅÈõ®ÈÅé‰πãÂæå\n  * ÈÖçËâ≤ÊñπÊ°à Aben„ÄÅChongyu Zhu„ÄÅskoj„ÄÅSuperoutman„ÄÅ‰ΩõÊåØ„ÄÅÊ¢ÅÊµ∑\n\nÊú¨ÂìÅÂºïÁî®‰∫Ü‰ª•‰∏ãÈñãÊ∫êËªü‰ª∂Ôºö\n\n  * Boost C++ Libraries  (Boost Software License)\n  * capnproto (MIT License)\n  * darts-clone  (New BSD License)\n  * google-glog  (New BSD License)\n  * Google Test  (New BSD License)\n  * LevelDB  (New BSD License)\n  * librime  (New BSD License)\n  * OpenCC / ÈñãÊîæ‰∏≠ÊñáËΩâÊèõ  (Apache License 2.0)\n  * plum / Êù±È¢®Á†¥ (GNU Lesser General Public License 3.0)\n  * Sparkle  (MIT License)\n  * UTF8-CPP  (Boost Software License)\n  * yaml-cpp  (MIT License)\n\nÊÑüË¨ùÁéãÂÖ¨Â≠êÊçêË¥àÈñãÁôºÁî®Ê©ü„ÄÇ\n\nÂïèÈ°åËàáÂèçÈ•ã\n---\n\nÁôºÁèæÁ®ãÂ∫èÊúâ BUGÔºåÊàñÂª∫Ë≠∞ÔºåÊàñÊÑüÊÉ≥ÔºåË´ãÂèçÈ•ãÂà∞ [Rime ‰ª£Á¢º‰πãÂÆ∂Ë®éË´ñÂçÄ](https://github.com/rime/home/discussions)\n\nËÅØÁπ´ÊñπÂºè\n---\n\nÊäÄË°ì‰∫§ÊµÅÔºåÊ≠°ËøéÂÖâËá® [Rime ‰ª£Á¢º‰πãÂÆ∂](https://github.com/rime/home)Ôºå\nÊàñËá¥‰ø° Rime ÈñãÁôºËÄÖ <rimeime@gmail.com>„ÄÇ\n\nË¨ùË¨ù\n",
      "stars_today": 7
    },
    {
      "id": 834082440,
      "name": "camoufox",
      "full_name": "daijro/camoufox",
      "description": "ü¶ä Anti-detect browser",
      "html_url": "https://github.com/daijro/camoufox",
      "stars": 4749,
      "forks": 444,
      "language": "C++",
      "topics": [
        "antidetect",
        "antidetect-browser",
        "fingerprint",
        "firefox",
        "networking",
        "playwright",
        "scraping",
        "webscraping"
      ],
      "created_at": "2024-07-26T11:31:27Z",
      "updated_at": "2026-01-14T00:22:23Z",
      "pushed_at": "2026-01-12T05:40:26Z",
      "open_issues": 185,
      "owner": {
        "login": "daijro",
        "avatar_url": "https://avatars.githubusercontent.com/u/72637910?v=4"
      },
      "readme": "<img src=\"https://i.imgur.com/enUBkXt.png\" align=\"center\">\n\n<h1 align=\"center\">Camoufox</h1>\n\n<h4 align=\"center\">A stealthy, minimalistic, custom build of Firefox for web scraping ü¶ä</h4>\n\n<p align=\"center\">                                      \nCamoufox is an open source anti-detect browser for robust fingerprint injection & anti-bot evasion.\n</p>\n\n<p align=\"center\">\n  <a href=\"https://trendshift.io/repositories/12224\" target=\"_blank\">\n  <img src=\"https://trendshift.io/api/badge/repositories/12224\" alt=\"daijro%2Fcamoufox | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</p>\n\n---\n\n> [!NOTE]\n> All of the latest documentation is avaliable at [camoufox.com](https://camoufox.com).\n\nCamoufox is the most modern, effective & future-proof open source solution for avoiding bot detection and intelligent fingerprint rotation. It outperforms most commercial anti-bot browsers.\n\n## <span style=\"color:yellow\">Firefox Version Upgrade Notice</span>\nThe current main branch is built for Firefox v146. It is an experimental change and may contain several bugs. If you are building from source and require a stable production version, use branch `releases/135`.\n\nFF146 only works for MacOS. Linux support is coming in the next week and windows support by the end of January.\n\nSee the [Beta Testing Guide](docs/beta-testing-ff146.md) for instructions on testing FF146.\n\n---\n\n## Sponsors\n\n<a href=\"https://scrapfly.io/?utm_source=github&utm_medium=sponsoring&utm_campaign=camoufox\" target=\"_blank\">\n<img src=\"https://raw.githubusercontent.com/daijro/camoufox/main/assets/scrapfly.png\" alt=\"Scrapfly.io\" width=\"149\">\n</a>\n\n[Scrapfly](https://scrapfly.io/?utm_source=github&utm_medium=sponsoring&utm_campaign=camoufox) is an enterprise-grade solution providing Web Scraping API that aims to simplify the scraping process by managing everything: real browser rendering, rotating proxies, and fingerprints (TLS, HTTP, browser) to bypass all major anti-bots. Scrapfly also unlocks the observability by providing an analytical dashboard and measuring the success rate/block rate in detail.\n\n---\n\n\n<a href=\"https://cloverlabs.ai/?utm_source=github&utm_medium=sponsoring&utm_campaign=camoufox\" target=\"_blank\">\n<img src=\"https://i.imgur.com/I3oe7xG.jpeg\" alt=\"cloverlabs.ai\" width=\"149\">\n</a>\n\n[Clover Labs](https://cloverlabs.ai/?utm_source=github&utm_medium=sponsoring&utm_campaign=camoufox) is a Toronto based venture studio building AI agents for growth and distribution.\n\n\n## Features\n\n- Invisible to **all anti-bot systems** üé≠\n  - Camoufox performs better than most commercial anti-bot browsers.\n\n* Fingerprint injection & rotation (without JS injection!)\n  - All navigator properties (device, OS, hardware, browser, etc.) ‚úÖ\n  - Screen size, resolution, window, & viewport properties ‚úÖ\n  - Geolocation, timezone, & locale spoofing ‚úÖ\n  - Font spoofing & anti-fingerprinting ‚úÖ\n  - WebGL parameters, supported extensions, context attributes, & shader precision formats ‚úÖ\n  - WebRTC IP spoofing at the protocol level ‚úÖ\n  - Media devices, voices, speech playback rate, etc. ‚úÖ\n  - And much, much more!\n\n- Quality of life features\n  - Human-like mouse movement üñ±Ô∏è\n  - Blocks & circumvents ads üõ°Ô∏è\n  - No CSS animations üí®\n\n* Debloated & optimized for memory efficiency ‚ö°\n* [PyPi package](https://pypi.org/project/camoufox/) for updates & auto fingerprint injection üì¶\n* Stays up to date with the latest Firefox version üïì\n\n---\n\n## Fingerprint Injection\n\nIn Camoufox, data is intercepted at the C++ implementation level, making the changes undetectable through JavaScript inspection.\n\nTo spoof fingerprint properties, pass a JSON containing properties to spoof to the [Python interface](https://github.com/daijro/camoufox/tree/main/pythonlib#camoufox-python-interface):\n\n```py\n>>> with Camoufox(config={\"property\": \"value\"}) as browser:\n```\n\nConfig data not set by the user will be automatically populated using [BrowserForge](https://github.com/daijro/browserforge) fingerprints, which mimic the statistical distribution of device characteristics in real-world traffic.\n\n<details>\n<summary>\nLegacy documentation\n</summary>\n\n#### The following properties can be spoofed:\n\n<details>\n<summary>\nNavigator \n</summary>\n\nNavigator properties can be fully spoofed to other Firefox fingerprints, and it is **completely safe**! However, there are some issues when spoofing Chrome (leaks noted).\n\n| Property                       | Notes |\n| ------------------------------ | ----- |\n| navigator.userAgent            | ‚úÖ    |\n| navigator.doNotTrack           | ‚úÖ    |\n| navigator.appCodeName          | ‚úÖ    |\n| navigator.appName              | ‚úÖ    |\n| navigator.appVersion           | ‚úÖ    |\n| navigator.oscpu                | ‚úÖ    |\n| navigator.language             | ‚úÖ    |\n| navigator.languages            | ‚úÖ    |\n| navigator.platform             | ‚úÖ    |\n| navigator.hardwareConcurrency  | ‚úÖ    |\n| navigator.product              | ‚úÖ    |\n| navigator.productSub           | ‚úÖ    |\n| navigator.maxTouchPoints       | ‚úÖ    |\n| navigator.cookieEnabled        | ‚úÖ    |\n| navigator.globalPrivacyControl | ‚úÖ    |\n| navigator.appVersion           | ‚úÖ    |\n| navigator.buildID              | ‚úÖ    |\n| navigator.doNotTrack           | ‚úÖ    |\n\nCamoufox will automatically add the following default fonts associated your spoofed User-Agent OS (the value passed in `navigator.userAgent`).\n\n**Notes**:\n\n- **navigator.webdriver** is set to false at all times.\n- `navigator.language` & `navigator.languages` will fall back to the `locale:language`/`locale:region` values if not set.\n- When spoofing Chrome fingerprints, the following may leak:\n  - navigator.userAgentData missing.\n  - navigator.deviceMemory missing.\n- Changing the presented Firefox version can be detected by some testing websites, but typically will not flag production WAFs.\n\n</details>\n\n<details>\n<summary>\nCursor movement\n</summary>\n\n### Human-like Cursor movement\n\nCamoufox has built-in support for human-like cursor movement. The natural motion algorithm was originally from [rifosnake's HumanCursor](https://github.com/riflosnake/HumanCursor), but has been rewritten in C++ and modified for more distance-aware trajectories.\n\n### Demo\n\n<video src=\"https://github.com/user-attachments/assets/6d33d6af-3537-4603-bf24-6bd3f4f8f455\" width=\"500px\" autoplay loop muted></video>\n\n### Properties\n\n| Property         | Supported | Description                                                         |\n| ---------------- | --------- | ------------------------------------------------------------------- |\n| humanize         | ‚úÖ        | Enable/disable human-like cursor movement. Defaults to False.       |\n| humanize:maxTime | ‚úÖ        | Maximum time in seconds for the cursor movement. Defaults to `1.5`. |\n| showcursor       | ‚úÖ        | Toggles the cursor highlighter. Defaults to True.                   |\n\n**Notes:**\n\n- The cursor highlighter is **not** ran in the page context. It will not be visible to the page. You don't have to worry about it leaking.\n\n</details>\n\n<details>\n<summary>\nFonts\n</summary>\n\n### Adding Fonts\n\nFonts can be passed to be used in Camoufox through the `fonts` config property.\n\nBy default, Camoufox is bundled with the default Windows 11 22H2 fonts, macOS Sonma fonts, and Linux fonts used in the TOR bundle.\n\nCamoufox will automatically add the default fonts associated your spoofed User-Agent OS (the value passed in `navigator.userAgent`):\n\n- **Mac OS fonts** (from macOS Sonma):\n\n  ```bash\n  [\".Al Bayan PUA\", \".Al Nile PUA\", \".Al Tarikh PUA\", \".Apple Color Emoji UI\", \".Apple SD Gothic NeoI\", \".Aqua Kana\", \".Aqua Kana Bold\", \".Aqua „Åã„Å™\", \".Aqua „Åã„Å™ „Éú„Éº„É´„Éâ\", \".Arial Hebrew Desk Interface\", \".Baghdad PUA\", \".Beirut PUA\", \".Damascus PUA\", \".DecoType Naskh PUA\", \".Diwan Kufi PUA\", \".Farah PUA\", \".Geeza Pro Interface\", \".Geeza Pro PUA\", \".Helvetica LT MM\", \".Hiragino Kaku Gothic Interface\", \".Hiragino Sans GB Interface\", \".Keyboard\", \".KufiStandardGK PUA\", \".LastResort\", \".Lucida Grande UI\", \".Muna PUA\", \".Nadeem PUA\", \".New York\", \".Noto Nastaliq Urdu UI\", \".PingFang HK\", \".PingFang SC\", \".PingFang TC\", \".SF Arabic\", \".SF Arabic Rounded\", \".SF Compact\", \".SF Compact Rounded\", \".SF NS\", \".SF NS Mono\", \".SF NS Rounded\", \".Sana PUA\", \".Savoye LET CC.\", \".ThonburiUI\", \".ThonburiUIWatch\", \".ËãπÊñπ-Ê∏Ø\", \".ËãπÊñπ-ÁÆÄ\", \".ËãπÊñπ-ÁπÅ\", \".ËòãÊñπ-Ê∏Ø\", \".ËòãÊñπ-Á∞°\", \".ËòãÊñπ-ÁπÅ\", \"Academy Engraved LET\", \"Al Bayan\", \"Al Nile\", \"Al Tarikh\", \"American Typewriter\", \"Andale Mono\", \"Apple Braille\", \"Apple Chancery\", \"Apple Color Emoji\", \"Apple SD Gothic Neo\", \"Apple SD ÏÇ∞ÎèåÍ≥†Îîï Neo\", \"Apple Symbols\", \"AppleGothic\", \"AppleMyungjo\", \"Arial\", \"Arial Black\", \"Arial Hebrew\", \"Arial Hebrew Scholar\", \"Arial Narrow\", \"Arial Rounded MT Bold\", \"Arial Unicode MS\", \"Athelas\", \"Avenir\", \"Avenir Black\", \"Avenir Black Oblique\", \"Avenir Book\", \"Avenir Heavy\", \"Avenir Light\", \"Avenir Medium\", \"Avenir Next\", \"Avenir Next Condensed\", \"Avenir Next Condensed Demi Bold\", \"Avenir Next Condensed Heavy\", \"Avenir Next Condensed Medium\", \"Avenir Next Condensed Ultra Light\", \"Avenir Next Demi Bold\", \"Avenir Next Heavy\", \"Avenir Next Medium\", \"Avenir Next Ultra Light\", \"Ayuthaya\", \"Baghdad\", \"Bangla MN\", \"Bangla Sangam MN\", \"Baskerville\", \"Beirut\", \"Big Caslon\", \"Bodoni 72\", \"Bodoni 72 Oldstyle\", \"Bodoni 72 Smallcaps\", \"Bodoni Ornaments\", \"Bradley Hand\", \"Brush Script MT\", \"Chalkboard\", \"Chalkboard SE\", \"Chalkduster\", \"Charter\", \"Charter Black\", \"Cochin\", \"Comic Sans MS\", \"Copperplate\", \"Corsiva Hebrew\", \"Courier\", \"Courier New\", \"Czcionka systemowa\", \"DIN Alternate\", \"DIN Condensed\", \"Damascus\", \"DecoType Naskh\", \"Devanagari MT\", \"Devanagari Sangam MN\", \"Didot\", \"Diwan Kufi\", \"Diwan Thuluth\", \"Euphemia UCAS\", \"Farah\", \"Farisi\", \"Font Sistem\", \"Font de sistem\", \"Font di sistema\", \"Font sustava\", \"Fonte do Sistema\", \"Futura\", \"GB18030 Bitmap\", \"Galvji\", \"Geeza Pro\", \"Geneva\", \"Georgia\", \"Gill Sans\", \"Grantha Sangam MN\", \"Gujarati MT\", \"Gujarati Sangam MN\", \"Gurmukhi MN\", \"Gurmukhi MT\", \"Gurmukhi Sangam MN\", \"Heiti SC\", \"Heiti TC\", \"Heiti-Í∞ÑÏ≤¥\", \"Heiti-Î≤àÏ≤¥\", \"Helvetica\", \"Helvetica Neue\", \"Herculanum\", \"Hiragino Kaku Gothic Pro\", \"Hiragino Kaku Gothic Pro W3\", \"Hiragino Kaku Gothic Pro W6\", \"Hiragino Kaku Gothic ProN\", \"Hiragino Kaku Gothic ProN W3\", \"Hiragino Kaku Gothic ProN W6\", \"Hiragino Kaku Gothic Std\", \"Hiragino Kaku Gothic Std W8\", \"Hiragino Kaku Gothic StdN\", \"Hiragino Kaku Gothic StdN W8\", \"Hiragino Maru Gothic Pro\", \"Hiragino Maru Gothic Pro W4\", \"Hiragino Maru Gothic ProN\", \"Hiragino Maru Gothic ProN W4\", \"Hiragino Mincho Pro\", \"Hiragino Mincho Pro W3\", \"Hiragino Mincho Pro W6\", \"Hiragino Mincho ProN\", \"Hiragino Mincho ProN W3\", \"Hiragino Mincho ProN W6\", \"Hiragino Sans\", \"Hiragino Sans GB\", \"Hiragino Sans GB W3\", \"Hiragino Sans GB W6\", \"Hiragino Sans W0\", \"Hiragino Sans W1\", \"Hiragino Sans W2\", \"Hiragino Sans W3\", \"Hiragino Sans W4\", \"Hiragino Sans W5\", \"Hiragino Sans W6\", \"Hiragino Sans W7\", \"Hiragino Sans W8\", \"Hiragino Sans W9\", \"Hoefler Text\", \"Hoefler Text Ornaments\", \"ITF Devanagari\", \"ITF Devanagari Marathi\", \"Impact\", \"InaiMathi\", \"Iowan Old Style\", \"Iowan Old Style Black\", \"J√§rjestelm√§fontti\", \"Kailasa\", \"Kannada MN\", \"Kannada Sangam MN\", \"Kefa\", \"Khmer MN\", \"Khmer Sangam MN\", \"Kohinoor Bangla\", \"Kohinoor Devanagari\", \"Kohinoor Gujarati\", \"Kohinoor Telugu\", \"Kokonor\", \"Krungthep\", \"KufiStandardGK\", \"Lao MN\", \"Lao Sangam MN\", \"Lucida Grande\", \"Luminari\", \"Malayalam MN\", \"Malayalam Sangam MN\", \"Marion\", \"Marker Felt\", \"Menlo\", \"Microsoft Sans Serif\", \"Mishafi\", \"Mishafi Gold\", \"Monaco\", \"Mshtakan\", \"Mukta Mahee\", \"MuktaMahee Bold\", \"MuktaMahee ExtraBold\", \"MuktaMahee ExtraLight\", \"MuktaMahee Light\", \"MuktaMahee Medium\", \"MuktaMahee Regular\", \"MuktaMahee SemiBold\", \"Muna\", \"Myanmar MN\", \"Myanmar Sangam MN\", \"Nadeem\", \"New Peninim MT\", \"Noteworthy\", \"Noto Nastaliq Urdu\", \"Noto Sans Adlam\", \"Noto Sans Armenian\", \"Noto Sans Armenian Blk\", \"Noto Sans Armenian ExtBd\", \"Noto Sans Armenian ExtLt\", \"Noto Sans Armenian Light\", \"Noto Sans Armenian Med\", \"Noto Sans Armenian SemBd\", \"Noto Sans Armenian Thin\", \"Noto Sans Avestan\", \"Noto Sans Bamum\", \"Noto Sans Bassa Vah\", \"Noto Sans Batak\", \"Noto Sans Bhaiksuki\", \"Noto Sans Brahmi\", \"Noto Sans Buginese\", \"Noto Sans Buhid\", \"Noto Sans CanAborig\", \"Noto Sans Canadian Aboriginal\", \"Noto Sans Carian\", \"Noto Sans CaucAlban\", \"Noto Sans Caucasian Albanian\", \"Noto Sans Chakma\", \"Noto Sans Cham\", \"Noto Sans Coptic\", \"Noto Sans Cuneiform\", \"Noto Sans Cypriot\", \"Noto Sans Duployan\", \"Noto Sans EgyptHiero\", \"Noto Sans Egyptian Hieroglyphs\", \"Noto Sans Elbasan\", \"Noto Sans Glagolitic\", \"Noto Sans Gothic\", \"Noto Sans Gunjala Gondi\", \"Noto Sans Hanifi Rohingya\", \"Noto Sans HanifiRohg\", \"Noto Sans Hanunoo\", \"Noto Sans Hatran\", \"Noto Sans ImpAramaic\", \"Noto Sans Imperial Aramaic\", \"Noto Sans InsPahlavi\", \"Noto Sans InsParthi\", \"Noto Sans Inscriptional Pahlavi\", \"Noto Sans Inscriptional Parthian\", \"Noto Sans Javanese\", \"Noto Sans Kaithi\", \"Noto Sans Kannada\", \"Noto Sans Kannada Black\", \"Noto Sans Kannada ExtraBold\", \"Noto Sans Kannada ExtraLight\", \"Noto Sans Kannada Light\", \"Noto Sans Kannada Medium\", \"Noto Sans Kannada SemiBold\", \"Noto Sans Kannada Thin\", \"Noto Sans Kayah Li\", \"Noto Sans Kharoshthi\", \"Noto Sans Khojki\", \"Noto Sans Khudawadi\", \"Noto Sans Lepcha\", \"Noto Sans Limbu\", \"Noto Sans Linear A\", \"Noto Sans Linear B\", \"Noto Sans Lisu\", \"Noto Sans Lycian\", \"Noto Sans Lydian\", \"Noto Sans Mahajani\", \"Noto Sans Mandaic\", \"Noto Sans Manichaean\", \"Noto Sans Marchen\", \"Noto Sans Masaram Gondi\", \"Noto Sans Meetei Mayek\", \"Noto Sans Mende Kikakui\", \"Noto Sans Meroitic\", \"Noto Sans Miao\", \"Noto Sans Modi\", \"Noto Sans Mongolian\", \"Noto Sans Mro\", \"Noto Sans Multani\", \"Noto Sans Myanmar\", \"Noto Sans Myanmar Blk\", \"Noto Sans Myanmar ExtBd\", \"Noto Sans Myanmar ExtLt\", \"Noto Sans Myanmar Light\", \"Noto Sans Myanmar Med\", \"Noto Sans Myanmar SemBd\", \"Noto Sans Myanmar Thin\", \"Noto Sans NKo\", \"Noto Sans Nabataean\", \"Noto Sans New Tai Lue\", \"Noto Sans Newa\", \"Noto Sans Ol Chiki\", \"Noto Sans Old Hungarian\", \"Noto Sans Old Italic\", \"Noto Sans Old North Arabian\", \"Noto Sans Old Permic\", \"Noto Sans Old Persian\", \"Noto Sans Old South Arabian\", \"Noto Sans Old Turkic\", \"Noto Sans OldHung\", \"Noto Sans OldNorArab\", \"Noto Sans OldSouArab\", \"Noto Sans Oriya\", \"Noto Sans Osage\", \"Noto Sans Osmanya\", \"Noto Sans Pahawh Hmong\", \"Noto Sans Palmyrene\", \"Noto Sans Pau Cin Hau\", \"Noto Sans PhagsPa\", \"Noto Sans Phoenician\", \"Noto Sans PsaPahlavi\", \"Noto Sans Psalter Pahlavi\", \"Noto Sans Rejang\", \"Noto Sans Samaritan\", \"Noto Sans Saurashtra\", \"Noto Sans Sharada\", \"Noto Sans Siddham\", \"Noto Sans Sora Sompeng\", \"Noto Sans SoraSomp\", \"Noto Sans Sundanese\", \"Noto Sans Syloti Nagri\", \"Noto Sans Syriac\", \"Noto Sans Tagalog\", \"Noto Sans Tagbanwa\", \"Noto Sans Tai Le\", \"Noto Sans Tai Tham\", \"Noto Sans Tai Viet\", \"Noto Sans Takri\", \"Noto Sans Thaana\", \"Noto Sans Tifinagh\", \"Noto Sans Tirhuta\", \"Noto Sans Ugaritic\", \"Noto Sans Vai\", \"Noto Sans Wancho\", \"Noto Sans Warang Citi\", \"Noto Sans Yi\", \"Noto Sans Zawgyi\", \"Noto Sans Zawgyi Blk\", \"Noto Sans Zawgyi ExtBd\", \"Noto Sans Zawgyi ExtLt\", \"Noto Sans Zawgyi Light\", \"Noto Sans Zawgyi Med\", \"Noto Sans Zawgyi SemBd\", \"Noto Sans Zawgyi Thin\", \"Noto Serif Ahom\", \"Noto Serif Balinese\", \"Noto Serif Hmong Nyiakeng\", \"Noto Serif Myanmar\", \"Noto Serif Myanmar Blk\", \"Noto Serif Myanmar ExtBd\", \"Noto Serif Myanmar ExtLt\", \"Noto Serif Myanmar Light\", \"Noto Serif Myanmar Med\", \"Noto Serif Myanmar SemBd\", \"Noto Serif Myanmar Thin\", \"Noto Serif Yezidi\", \"Optima\", \"Oriya MN\", \"Oriya Sangam MN\", \"PT Mono\", \"PT Sans\", \"PT Sans Caption\", \"PT Sans Narrow\", \"PT Serif\", \"PT Serif Caption\", \"Palatino\", \"Papyrus\", \"Party LET\", \"Phosphate\", \"Ph√¥ng ch·ªØ H·ªá th·ªëng\", \"PingFang HK\", \"PingFang SC\", \"PingFang TC\", \"Plantagenet Cherokee\", \"Police syst√®me\", \"Raanana\", \"Rendszerbet≈±t√≠pus\", \"Rockwell\", \"STIX Two Math\", \"STIX Two Text\", \"STIXGeneral\", \"STIXIntegralsD\", \"STIXIntegralsSm\", \"STIXIntegralsUp\", \"STIXIntegralsUpD\", \"STIXIntegralsUpSm\", \"STIXNonUnicode\", \"STIXSizeFiveSym\", \"STIXSizeFourSym\", \"STIXSizeOneSym\", \"STIXSizeThreeSym\", \"STIXSizeTwoSym\", \"STIXVariants\", \"STSong\", \"Sana\", \"Sathu\", \"Savoye LET\", \"Seravek\", \"Seravek ExtraLight\", \"Seravek Light\", \"Seravek Medium\", \"Shree Devanagari 714\", \"SignPainter\", \"SignPainter-HouseScript\", \"Silom\", \"Sinhala MN\", \"Sinhala Sangam MN\", \"Sistem Fontu\", \"Skia\", \"Snell Roundhand\", \"Songti SC\", \"Songti TC\", \"Sukhumvit Set\", \"Superclarendon\", \"Symbol\", \"Systeemlettertype\", \"System Font\", \"Systemschrift\", \"Systemskrift\", \"Systemtypsnitt\", \"Syst√©mov√© p√≠smo\", \"Tahoma\", \"Tamil MN\", \"Tamil Sangam MN\", \"Telugu MN\", \"Telugu Sangam MN\", \"Thonburi\", \"Times\", \"Times New Roman\", \"Tipo de letra del sistema\", \"Tipo de letra do sistema\", \"Tipus de lletra del sistema\", \"Trattatello\", \"Trebuchet MS\", \"Verdana\", \"Waseem\", \"Webdings\", \"Wingdings\", \"Wingdings 2\", \"Wingdings 3\", \"Zapf Dingbats\", \"Zapfino\", \"ŒìœÅŒ±ŒºŒºŒ±œÑŒøœÉŒµŒπœÅŒ¨ œÉœÖœÉœÑŒÆŒºŒ±œÑŒøœÇ\", \"–°–∏—Å—Ç–µ–º–Ω–∏–π —à—Ä–∏—Ñ—Ç\", \"–°–∏—Å—Ç–µ–º–Ω—ã–π —à—Ä–∏—Ñ—Ç\", \"◊í◊ï◊§◊ü ◊û◊¢◊®◊õ◊™\", \"ÿßŸÑÿ®ŸäÿßŸÜ\", \"ÿßŸÑÿ™ÿßÿ±ŸäÿÆ\", \"ÿßŸÑŸÜŸäŸÑ\", \"ÿ®ÿ∫ÿØÿßÿØ\", \"ÿ®Ÿäÿ±Ÿàÿ™\", \"ÿ¨Ÿäÿ≤ÿ©\", \"ÿÆÿ∑ ÿßŸÑŸÜÿ∏ÿßŸÖ\", \"ÿØŸÖÿ¥ŸÇ\", \"ÿØŸäŸàÿßŸÜ ÿ´ŸÑÿ´\", \"ÿØŸäŸàÿßŸÜ ŸÉŸàŸÅŸä\", \"ÿµŸÜÿπÿßÿ°\", \"ŸÅÿßÿ±ÿ≥Ÿä\", \"ŸÅÿ±ÿ≠\", \"ŸÉŸàŸÅŸä\", \"ŸÖŸÜŸâ\", \"ŸÖŸêÿµÿ≠ŸÅŸä\", \"ŸÖŸêÿµÿ≠ŸÅŸä ÿ∞Ÿáÿ®Ÿä\", \"ŸÜÿØŸäŸÖ\", \"ŸÜÿ≥ÿÆ\", \"Ÿàÿ≥ŸäŸÖ\", \"‡§Ü‡§à‡•∞‡§ü‡•Ä‡•∞‡§è‡§´‡§º‡•∞ ‡§¶‡•á‡§µ‡§®‡§æ‡§ó‡§∞‡•Ä\", \"‡§Ü‡§à‡•∞‡§ü‡•Ä‡•∞‡§è‡§´‡§º‡•∞ ‡§¶‡•á‡§µ‡§®‡§æ‡§ó‡§∞‡•Ä ‡§Æ‡§∞‡§æ‡§†‡•Ä\", \"‡§ï‡•ã‡§π‡§ø‡§®‡•Ç‡§∞ ‡§¶‡•á‡§µ‡§®‡§æ‡§ó‡§∞‡•Ä\", \"‡§¶‡•á‡§µ‡§®‡§æ‡§ó‡§∞‡•Ä ‡§è‡§Æ‡•∞‡§ü‡•Ä‡•∞\", \"‡§¶‡•á‡§µ‡§®‡§æ‡§ó‡§∞‡•Ä ‡§∏‡§Ç‡§ó‡§Æ ‡§è‡§Æ‡•∞‡§è‡§®‡•∞\", \"‡§∂‡•ç‡§∞‡•Ä ‡§¶‡•á‡§µ‡§®‡§æ‡§ó‡§∞‡•Ä ‡•≠‡•ß‡•™\", \"‡πÅ‡∏ö‡∏ö‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏£‡∏∞‡∏ö‡∏ö\", \"‚πÅÁÖµÊÑ†Ëä©Ëãà\", \"„Ç∑„Çπ„ÉÜ„É†„Éï„Ç©„É≥„Éà\", \"„Éí„É©„ÇÆ„Éé‰∏∏„Ç¥ Pro\", \"„Éí„É©„ÇÆ„Éé‰∏∏„Ç¥ Pro W4\", \"„Éí„É©„ÇÆ„Éé‰∏∏„Ç¥ ProN\", \"„Éí„É©„ÇÆ„Éé‰∏∏„Ç¥ ProN W4\", \"„Éí„É©„ÇÆ„ÉéÊòéÊúù Pro\", \"„Éí„É©„ÇÆ„ÉéÊòéÊúù Pro W3\", \"„Éí„É©„ÇÆ„ÉéÊòéÊúù Pro W6\", \"„Éí„É©„ÇÆ„ÉéÊòéÊúù ProN\", \"„Éí„É©„ÇÆ„ÉéÊòéÊúù ProN W3\", \"„Éí„É©„ÇÆ„ÉéÊòéÊúù ProN W6\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥ Pro\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥ Pro W3\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥ Pro W6\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥ ProN\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥ ProN W3\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥ ProN W6\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥ Std\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥ Std W8\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥ StdN\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥ StdN W8\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥ Á∞°‰Ωì‰∏≠Êñá\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥ Á∞°‰Ωì‰∏≠Êñá W3\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥ Á∞°‰Ωì‰∏≠Êñá W6\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥„Ç∑„ÉÉ„ÇØ\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥„Ç∑„ÉÉ„ÇØ W0\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥„Ç∑„ÉÉ„ÇØ W1\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥„Ç∑„ÉÉ„ÇØ W2\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥„Ç∑„ÉÉ„ÇØ W3\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥„Ç∑„ÉÉ„ÇØ W4\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥„Ç∑„ÉÉ„ÇØ W5\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥„Ç∑„ÉÉ„ÇØ W6\", \"„Éí„É©„ÇÆ„ÉéËßí „Ç¥„Ç∑„ÉÉ„ÇØ W7\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥„Ç∑„ÉÉ„ÇØ W8\", \"„Éí„É©„ÇÆ„ÉéËßí„Ç¥„Ç∑„ÉÉ„ÇØ W9\", \"ÂÜ¨ÈùíÈªë‰ΩìÁÆÄ‰Ωì‰∏≠Êñá\", \"ÂÜ¨ÈùíÈªë‰ΩìÁÆÄ‰Ωì‰∏≠Êñá W3\", \"ÂÜ¨ÈùíÈªë‰ΩìÁÆÄ‰Ωì‰∏≠Êñá W6\", \"ÂÜ¨ÈùíÈªëÈ´îÁ∞°È´î‰∏≠Êñá\", \"ÂÜ¨ÈùíÈªëÈ´îÁ∞°È´î‰∏≠Êñá W3\", \"ÂÜ¨ÈùíÈªëÈ´îÁ∞°È´î‰∏≠Êñá W6\", \"ÂÆã‰Ωì-ÁÆÄ\", \"ÂÆã‰Ωì-ÁπÅ\", \"ÂÆãÈ´î-Á∞°\", \"ÂÆãÈ´î-ÁπÅ\", \"Á≥ªÁµ±Â≠óÈ´î\", \"Á≥ªÁªüÂ≠ó‰Ωì\", \"ËãπÊñπ-Ê∏Ø\", \"ËãπÊñπ-ÁÆÄ\", \"ËãπÊñπ-ÁπÅ\", \"Ëç±ËéâËççËç≠Ë©∞Ëçì‚ÅêÁâØ\", \"Ëç±ËéâËççËç≠Ë©∞Ëçì‚ÅìÁë§\", \"Ëç±ËéâËççËç≠Ë©∞ËçìËçñËç¢Ëçé\", \"Ëç±ËéâËççËç≠Ë´õËçì‚ÅêÁâØ\", \"Ëç±ËéâËççËç≠ÈöæÈä©‚ÅêÁâØ\", \"ËòãÊñπ-Ê∏Ø\", \"ËòãÊñπ-Á∞°\", \"ËòãÊñπ-ÁπÅ\", \"Èªë‰Ωì-ÁÆÄ\", \"Èªë‰Ωì-ÁπÅ\", \"ÈªëÈ´î-Á∞°\", \"ÈªëÈ´î-ÁπÅ\", \"Èªí‰Ωì-Á∞°\", \"Èªí‰Ωì-ÁπÅ\", \"ÏãúÏä§ÌÖú ÏÑúÏ≤¥\"]\n  ```\n\n- **Windows fonts** (from Windows 11 22H2):\n\n  ```bash\n  [\"Arial\", \"Arial Black\", \"Bahnschrift\", \"Calibri\", \"Calibri Light\", \"Cambria\", \"Cambria Math\", \"Candara\", \"Candara Light\", \"Comic Sans MS\", \"Consolas\", \"Constantia\", \"Corbel\", \"Corbel Light\", \"Courier New\", \"Ebrima\", \"Franklin Gothic Medium\", \"Gabriola\", \"Gadugi\", \"Georgia\", \"HoloLens MDL2 Assets\", \"Impact\", \"Ink Free\", \"Javanese Text\", \"Leelawadee UI\", \"Leelawadee UI Semilight\", \"Lucida Console\", \"Lucida Sans Unicode\", \"MS Gothic\", \"MS PGothic\", \"MS UI Gothic\", \"MV Boli\", \"Malgun Gothic\", \"Malgun Gothic Semilight\", \"Marlett\", \"Microsoft Himalaya\", \"Microsoft JhengHei\", \"Microsoft JhengHei Light\", \"Microsoft JhengHei UI\", \"Microsoft JhengHei UI Light\", \"Microsoft New Tai Lue\", \"Microsoft PhagsPa\", \"Microsoft Sans Serif\", \"Microsoft Tai Le\", \"Microsoft YaHei\", \"Microsoft YaHei Light\", \"Microsoft YaHei UI\", \"Microsoft YaHei UI Light\", \"Microsoft Yi Baiti\", \"MingLiU-ExtB\", \"MingLiU_HKSCS-ExtB\", \"Mongolian Baiti\", \"Myanmar Text\", \"NSimSun\", \"Nirmala UI\", \"Nirmala UI Semilight\", \"PMingLiU-ExtB\", \"Palatino Linotype\", \"Segoe Fluent Icons\", \"Segoe MDL2 Assets\", \"Segoe Print\", \"Segoe Script\", \"Segoe UI\", \"Segoe UI Black\", \"Segoe UI Emoji\", \"Segoe UI Historic\", \"Segoe UI Light\", \"Segoe UI Semibold\", \"Segoe UI Semilight\", \"Segoe UI Symbol\", \"Segoe UI Variable\", \"SimSun\", \"SimSun-ExtB\", \"Sitka\", \"Sitka Text\", \"Sylfaen\", \"Symbol\", \"Tahoma\", \"Times New Roman\", \"Trebuchet MS\", \"Twemoji Mozilla\", \"Verdana\", \"Webdings\", \"Wingdings\", \"Yu Gothic\", \"Yu Gothic Light\", \"Yu Gothic Medium\", \"Yu Gothic UI\", \"Yu Gothic UI Light\", \"Yu Gothic UI Semibold\", \"Yu Gothic UI Semilight\", \"ÂÆã‰Ωì\", \"ÂæÆËªüÊ≠£ÈªëÈ´î\", \"ÂæÆËªüÊ≠£ÈªëÈ´î Light\", \"ÂæÆËΩØÈõÖÈªë\", \"ÂæÆËΩØÈõÖÈªë Light\", \"Êñ∞ÂÆã‰Ωì\", \"Êñ∞Á¥∞ÊòéÈ´î-ExtB\", \"Ê∏∏„Ç¥„Ç∑„ÉÉ„ÇØ\", \"Ê∏∏„Ç¥„Ç∑„ÉÉ„ÇØ Light\", \"Ê∏∏„Ç¥„Ç∑„ÉÉ„ÇØ Medium\", \"Á¥∞ÊòéÈ´î-ExtB\", \"Á¥∞ÊòéÈ´î_HKSCS-ExtB\", \"ÎßëÏùÄ Í≥†Îîï\", \"ÎßëÏùÄ Í≥†Îîï Semilight\", \"Ôº≠Ôº≥ „Ç¥„Ç∑„ÉÉ„ÇØ\", \"Ôº≠Ôº≥ Ôº∞„Ç¥„Ç∑„ÉÉ„ÇØ\"]\n  ```\n\n- **Linux fonts** (from TOR Browser):\n\n  ```bash\n  [\"Arimo\", \"Cousine\", \"Noto Naskh Arabic\", \"Noto Sans Adlam\", \"Noto Sans Armenian\", \"Noto Sans Balinese\", \"Noto Sans Bamum\", \"Noto Sans Bassa Vah\", \"Noto Sans Batak\", \"Noto Sans Bengali\", \"Noto Sans Buginese\", \"Noto Sans Buhid\", \"Noto Sans Canadian Aboriginal\", \"Noto Sans Chakma\", \"Noto Sans Cham\", \"Noto Sans Cherokee\", \"Noto Sans Coptic\", \"Noto Sans Deseret\", \"Noto Sans Devanagari\", \"Noto Sans Elbasan\", \"Noto Sans Ethiopic\", \"Noto Sans Georgian\", \"Noto Sans Grantha\", \"Noto Sans Gujarati\", \"Noto Sans Gunjala Gondi\", \"Noto Sans Gurmukhi\", \"Noto Sans Hanifi Rohingya\", \"Noto Sans Hanunoo\", \"Noto Sans Hebrew\", \"Noto Sans JP\", \"Noto Sans Javanese\", \"Noto Sans KR\", \"Noto Sans Kannada\", \"Noto Sans Kayah Li\", \"Noto Sans Khmer\", \"Noto Sans Khojki\", \"Noto Sans Khudawadi\", \"Noto Sans Lao\", \"Noto Sans Lepcha\", \"Noto Sans Limbu\", \"Noto Sans Lisu\", \"Noto Sans Mahajani\", \"Noto Sans Malayalam\", \"Noto Sans Mandaic\", \"Noto Sans Masaram Gondi\", \"Noto Sans Medefaidrin\", \"Noto Sans Meetei Mayek\", \"Noto Sans Mende Kikakui\", \"Noto Sans Miao\", \"Noto Sans Modi\", \"Noto Sans Mongolian\", \"Noto Sans Mro\", \"Noto Sans Multani\", \"Noto Sans Myanmar\", \"Noto Sans NKo\", \"Noto Sans New Tai Lue\", \"Noto Sans Newa\", \"Noto Sans Ol Chiki\", \"Noto Sans Oriya\", \"Noto Sans Osage\", \"Noto Sans Osmanya\", \"Noto Sans Pahawh Hmong\", \"Noto Sans Pau Cin Hau\", \"Noto Sans Rejang\", \"Noto Sans Runic\", \"Noto Sans SC\", \"Noto Sans Samaritan\", \"Noto Sans Saurashtra\", \"Noto Sans Sharada\", \"Noto Sans Shavian\", \"Noto Sans Sinhala\", \"Noto Sans Sora Sompeng\", \"Noto Sans Soyombo\", \"Noto Sans Sundanese\", \"Noto Sans Syloti Nagri\", \"Noto Sans Symbols\", \"Noto Sans Symbols 2\", \"Noto Sans Syriac\", \"Noto Sans TC\", \"Noto Sans Tagalog\", \"Noto Sans Tagbanwa\", \"Noto Sans Tai Le\", \"Noto Sans Tai Tham\", \"Noto Sans Tai Viet\", \"Noto Sans Takri\", \"Noto Sans Tamil\", \"Noto Sans Telugu\", \"Noto Sans Thaana\", \"Noto Sans Thai\", \"Noto Sans Tifinagh\", \"Noto Sans Tifinagh APT\", \"Noto Sans Tifinagh Adrar\", \"Noto Sans Tifinagh Agraw Imazighen\", \"Noto Sans Tifinagh Ahaggar\", \"Noto Sans Tifinagh Air\", \"Noto Sans Tifinagh Azawagh\", \"Noto Sans Tifinagh Ghat\", \"Noto Sans Tifinagh Hawad\", \"Noto Sans Tifinagh Rhissa Ixa\", \"Noto Sans Tifinagh SIL\", \"Noto Sans Tifinagh Tawellemmet\", \"Noto Sans Tirhuta\", \"Noto Sans Vai\", \"Noto Sans Wancho\", \"Noto Sans Warang Citi\", \"Noto Sans Yi\", \"Noto Sans Zanabazar Square\", \"Noto Serif Armenian\", \"Noto Serif Balinese\", \"Noto Serif Bengali\", \"Noto Serif Devanagari\", \"Noto Serif Dogra\", \"Noto Serif Ethiopic\", \"Noto Serif Georgian\", \"Noto Serif Grantha\", \"Noto Serif Gujarati\", \"Noto Serif Gurmukhi\", \"Noto Serif Hebrew\", \"Noto Serif Kannada\", \"Noto Serif Khmer\", \"Noto Serif Khojki\", \"Noto Serif Lao\", \"Noto Serif Malayalam\", \"Noto Serif Myanmar\", \"Noto Serif NP Hmong\", \"Noto Serif Sinhala\", \"Noto Serif Tamil\", \"Noto Serif Telugu\", \"Noto Serif Thai\", \"Noto Serif Tibetan\", \"Noto Serif Yezidi\", \"STIX Two Math\", \"Tinos\", \"Twemoji Mozilla\"]\n  ```\n\nOther fonts can be added by copying them into the `fonts/` directory in Camoufox, or by installing them on your system.\n\n**Note**: It is highly recommended that you randomly pass custom fonts to the `fonts` config property to avoid font fingerprinting!\n\n### Font Metrics\n\nCamoufox has a built in mechanism to prevent fingerprinting by font metrics & unicode glyphs:\n\n<img src=\"https://i.imgur.com/X9hLKhO.gif\">\n\nThis works by shifting the spacing of each letter by a random value between 0-0.1px.\n\n</details>\n\n<details>\n<summary>\nScreen\n</summary>\n\n| Property           | Status |\n| ------------------ | ------ |\n| screen.availHeight | ‚úÖ     |\n| screen.availWidth  | ‚úÖ     |\n| screen.availTop    | ‚úÖ     |\n| screen.availLeft   | ‚úÖ     |\n| screen.height      | ‚úÖ     |\n| screen.width       | ‚úÖ     |\n| screen.colorDepth  | ‚úÖ     |\n| screen.pixelDepth  | ‚úÖ     |\n| screen.pageXOffset | ‚úÖ     |\n| screen.pageYOffset | ‚úÖ     |\n\n**Notes:**\n\n- `screen.colorDepth` and `screen.pixelDepth` are synonymous.\n\n</details>\n\n<details>\n<summary>\nWindow\n</summary>\n\n| Property                | Status | Notes                           |\n| ----------------------- | ------ | ------------------------------- |\n| window.scrollMinX       | ‚úÖ     |\n| window.scrollMinY       | ‚úÖ     |\n| window.scrollMaxX       | ‚úÖ     |\n| window.scrollMaxY       | ‚úÖ     |\n| window.outerHeight      | ‚úÖ     | Sets the window height.         |\n| window.outerWidth       | ‚úÖ     | Sets the window width.          |\n| window.innerHeight      | ‚úÖ     | Sets the inner viewport height. |\n| window.innerWidth       | ‚úÖ     | Sets the inner viewport width.  |\n| window.screenX          | ‚úÖ     |\n| window.screenY          | ‚úÖ     |\n| window.history.length   | ‚úÖ     |\n| window.devicePixelRatio | ‚úÖ     | Works, but not recommended.     |\n\n**Notes:**\n\n- Setting the outer window viewport will cause some cosmetic defects to the Camoufox window if the user attempts to manually resize it. Under no circumstances will Camoufox allow the outer window viewport to be resized.\n\n</details>\n\n<details>\n<summary>\nDocument\n</summary>\n\nSpoofing document.body has been implemented, but it is more advicable to set `window.innerWidth` and `window.innerHeight` instead.\n\n| Property                   | Status |\n| -------------------------- | ------ |\n| document.body.clientWidth  | ‚úÖ     |\n| document.body.clientHeight | ‚úÖ     |\n| document.body.clientTop    | ‚úÖ     |\n| document.body.clientLeft   | ‚úÖ     |\n\n</details>\n\n<details>\n<summary>\nHTTP Headers\n</summary>\n\nCamoufox can override the following network headers:\n\n| Property                | Status |\n| ----------------------- | ------ |\n| headers.User-Agent      | ‚úÖ     |\n| headers.Accept-Language | ‚úÖ     |\n| headers.Accept-Encoding | ‚úÖ     |\n\n**Notes:**\n\n- If `headers.User-Agent` is not set, it will fall back to `navigator.userAgent`.\n\n</details>\n\n<details>\n<summary>\nGeolocation & Intl\n</summary>\n\n| Property              | Status | Description                                                                                                                                            | Required Keys           |\n| --------------------- | ------ | ------------------------------------------------------------------------------------------------------------------------------------------------------ | ----------------------- |\n| geolocation:latitude  | ‚úÖ     | Latitude to use.                                                                                                                                       | `geolocation:longitude` |\n| geolocation:longitude | ‚úÖ     | Longitude to use.                                                                                                                                      | `geolocation:latitude`  |\n| geolocation:accuracy  | ‚úÖ     | Accuracy in meters. This will be calculated automatically using the decminal percision of `geolocation:latitude` & `geolocation:longitude` if not set. |                         |\n| timezone              | ‚úÖ     | Set a custom TZ timezone (e.g. \"America/Chicago\"). This will also change `Date()` to return the local time.                                            |                         |\n| locale:language       | ‚úÖ     | Spoof the Intl API, headers, and system language (e.g. \"en\")                                                                                           | `locale:region`         |\n| locale:region         | ‚úÖ     | Spoof the Intl API, headers, and system region (e.g. \"US\").                                                                                            | `locale:language`       |\n| locale:script         | ‚úÖ     | Set a custom script (e.g. \"Latn\"). Will be set automatically if not specified.                                                                         |                         |\n\nThe **Required Keys** are keys that must also be set for the property to work.\n\n**Notes:**\n\n- Location permission prompts will be accepted automatically if `geolocation:latitude` and `geolocation:longitude` are set.\n- `timezone` **must** be set to a valid TZ identifier. See [here](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones) for a list of valid timezones.\n- `locale:language` & `locale:region` **must** be set to valid locale values. See [here](https://simplelocalize.io/data/locales/) for a list of valid locale-region values.\n\n</details>\n\n<details>\n<summary>\nWebRTC IP\n</summary>\n\nCamoufox implements WebRTC IP spoofing at the protocol level by modifying ICE candidates and SDP before they're sent.\n\n| Property    | Status | Description         |\n| ----------- | ------ | ------------------- |\n| webrtc:ipv4 | ‚úÖ     | IPv4 address to use |\n| webrtc:ipv6 | ‚úÖ     | IPv6 address to use |\n\n**Notes:**\n\n- To completely disable WebRTC, set the `media.peerconnection.enabled` preference to `false`.\n\n</details>\n\n<details>\n<summary>\nWebGL\n</summary>\n\n### WebGL in Camoufox\n\nWebGL is disabled in Camoufox by default. To enable it, set the `webgl.disabled` Firefox preference to `false`.\n\nWebGL being disabled typically doesn't trigger detection by WAFs, so you generally don't need to be concerned about it. Only use WebGL when it's absolutely necessary for your specific use case.\n\nBecause I don't have a dataset of WebGL fingerprints to rotate against, WebGL fingerprint rotation is not implemented in the Camoufox Python library. If you need to spoof WebGL, you can do so manually with the following properties.\n\n### Demo site\n\nThis repository includes a demo site (see [here](https://github.com/daijro/camoufox/blob/main/scripts/examples/webgl.html)) that prints your browser's WebGL parameters. You can use this site to generate WebGL fingerprints for Camoufox from other devices.\n\n<img src=\"https://i.imgur.com/jwT5VqG.png\">\n\n### Properties\n\nCamoufox supports spoofing WebGL parameters, supported extensions, context attributes, and shader precision formats.\n\n**Note**: Do NOT randomly assign values to these properties. WAFs hash your WebGL fingerprint and compare it against a dataset. Randomly assigning values will lead to detection as an unknown device.\n\n| Property                                        | Description                                                                                                           | Example                                                                                 |\n| ----------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------- |\n| webGl:renderer                                  | Spoofs the name of the unmasked WebGL renderer.                                                                       | `\"NVIDIA GeForce GTX 980, or similar\"`                                                  |\n| webGl:vendor                                    | Spoofs the name of the unmasked WebGL vendor.                                                                         | `\"NVIDIA Corporation\"`                                                                  |\n| webGl:supportedExtensions                       | An array of supported WebGL extensions ([full list](https://registry.khronos.org/webgl/extensions/)).                 | `[\"ANGLE_instanced_arrays\", \"EXT_color_buffer_float\", \"EXT_disjoint_timer_query\", ...]` |\n| webGl2:supportedExtensions                      | The same as `webGl:supportedExtensions`, but for WebGL2.                                                              | `[\"ANGLE_instanced_arrays\", \"EXT_color_buffer_float\", \"EXT_disjoint_timer_query\", ...]` |\n| webGl:contextAttributes                         | A dictionary of WebGL context attributes.                                                                             | `{\"alpha\": true, \"antialias\": true, \"depth\": true, ...}`                                |\n| webGl2:contextAttributes                        | The same as `webGl:contextAttributes`, but for WebGL2.                                                                | `{\"alpha\": true, \"antialias\": true, \"depth\": true, ...}`                                |\n| webGl:parameters                                | A dictionary of WebGL parameters. Keys must be GL enums, and values are the values to spoof them as.                  | `{\"2849\": 1, \"2884\": false, \"2928\": [0, 1], ...}`                                       |\n| webGl2:parameters                               | The same as `webGl:parameters`, but for WebGL2.                                                                       | `{\"2849\": 1, \"2884\": false, \"2928\": [0, 1], ...}`                                       |\n| webGl:parameters:blockIfNotDefined              | If set to `true`, only the parameters in `webGl:parameters` will be allowed. Can be dangerous if not used correctly.  | `true`/`false`                                                                          |\n| webGl2:parameters:blockIfNotDefined             | If set to `true`, only the parameters in `webGl2:parameters` will be allowed. Can be dangerous if not used correctly. | `true`/`false`                                                                          |\n| webGl:shaderPrecisionFormats                    | A dictionary of WebGL shader precision formats. Keys are formatted as `\"<shaderType>,<precisionType>\"`.               | `{\"35633,36336\": {\"rangeMin\": 127, \"rangeMax\": 127, \"precision\": 23}, ...}`             |\n| webGl2:shaderPrecisionFormats                   | The same as `webGL:shaderPrecisionFormats`, but for WebGL2.                                                           | `{\"35633,36336\": {\"rangeMin\": 127, \"rangeMax\": 127, \"precision\": 23}, ...}`             |\n| webGl:shaderPrecisionFormats:blockIfNotDefined  | If set to `true`, only the shader percisions in `webGl:shaderPrecisionFormats` will be allowed.                       | `true`/`false`                                                                          |\n| webGl2:shaderPrecisionFormats:blockIfNotDefined | If set to `true`, only the shader percisions in `webGl2:shaderPrecisionFormats` will be allowed.                      | `true`/`false`                                                                          |\n\n</details>\n\n<details>\n<summary>\nAudioContext\n</summary>\n\nCamoufox can spoof the AudioContext sample rate, output latency, and max channel count.\n\n| Property                     | Status | Description                                |\n| ---------------------------- | ------ | ------------------------------------------ |\n| AudioContext:sampleRate      | ‚úÖ     | Spoofs the AudioContext sample rate.       |\n| AudioContext:outputLatency   | ‚úÖ     | Spoofs the AudioContext output latency.    |\n| AudioContext:maxChannelCount | ‚úÖ     | Spoofs the AudioContext max channel count. |\n\nHere is a testing site: https://audiofingerprint.openwpm.com/\n\n</details>\n\n<details>\n<summary>\nAddons\n</summary>\n\nIn the Camoufox Python library, addons can be loaded with the `addons` parameter:\n\n```python\nfrom camoufox.sync_api import Camoufox\n\nwith Camoufox(addons=['/path/to/addon', '/path/to/addon2']) as browser:\n    page = browser.new_page()\n```\n\nCamoufox will automatically download and use the latest uBlock Origin with custom privacy/adblock filters, and B.P.C. by default to help with ad circumvention.\n\nYou can also exclude default addons with the `exclude_addons` parameter:\n\n```python\nfrom camoufox.sync_api import Camoufox\nfrom camoufox import DefaultAddons\n\nwith Camoufox(exclude_addons=[DefaultAddons.UBO, DefaultAddons.BPC]) as browser:\n    page = browser.new_page()\n```\n\n<details>\n<summary>\nLoading addons with the legacy launcher...\n</summary>\n\nAddons can be loaded with the `--addons` flag.\n\nExample:\n\n```bash\n./launcher --addons '[\"/path/to/addon\", \"/path/to/addon2\"]'\n```\n\nCamoufox will automatically download and use the latest uBlock Origin with custom privacy/adblock filters, and B.P.C. by default to help with scraping.\n\nYou can also exclude default addons with the `--exclude-addons` flag:\n\n```bash\n./launcher --exclude-addons '[\"uBO\", \"BPC\"]'\n```\n\n</details>\n\n---\n\n</details>\n\n<details>\n<summary>\nMiscellaneous (battery status, etc)\n</summary>\n\n| Property                | Status | Description                                                                                                                     |\n| ----------------------- | ------ | ------------------------------------------------------------------------------------------------------------------------------- |\n| pdfViewer               | ‚úÖ     | Sets navigator.pdfViewerEnabled. Please keep this on though, many websites will flag a lack of pdfViewer as a headless browser. |\n| battery:charging        | ‚úÖ     | Spoofs the battery charging status.                                                                                             |\n| battery:chargingTime    | ‚úÖ     | Spoofs the battery charging time.                                                                                               |\n| battery:dischargingTime | ‚úÖ     | Spoofs the battery discharging time.                                                                                            |\n| battery:level           | ‚úÖ     | Spoofs the battery level.                                                                                                       |\n\n</details>\n\n</details>\n\n<hr width=50>\n\n## Patches\n\n### What changes were made?\n\n#### Fingerprint spoofing\n\n- Navigator properties spoofing (device, browser, locale, etc.)\n- Support for emulating screen size, resolution, etc.\n- Spoof WebGL parameters, supported extensions, context attributes, and shader precision formats.\n- Spoof inner and outer window viewport sizes\n- Spoof AudioContext sample rate, output latency, and max channel count\n- Spoof device voices & playback rates\n- Network headers (Accept-Languages and User-Agent) are spoofed to match the navigator properties\n- WebRTC IP spoofing at the protocol level\n- Geolocation, timezone, and locale spoofing\n- Battery API spoofing\n- etc.\n\n#### Stealth patches\n\n- Avoids main world execution leaks. All page agent javascript is sandboxed\n- Avoids frame execution context leaks\n- Fixes `navigator.webdriver` detection\n- Fixes Firefox headless detection via pointer type ([#26](https://github.com/daijro/camoufox/issues/26))\n- Removed potentially leaking anti-zoom/meta viewport handling patches\n- Uses non-default screen & window sizes\n- Re-enable fission content isolations\n- Re-enable PDF.js\n- Other leaking config properties changed\n\n#### Anti font fingerprinting\n\n- Automatically uses the correct system fonts for your User Agent\n- Bundled with Windows, Mac, and Linux system fonts\n- Prevents font metrics fingerprinting by randomly offsetting letter spacing\n\n#### Playwright support\n\n- Custom implementation of Playwright for the latest Firefox\n- Various config patches to evade bot detection\n\n#### Debloat/Optimizations\n\n- Stripped out/disabled _many, many_ Mozilla services. Runs faster than the original Mozilla Firefox, and uses less memory (200mb)\n- Patches from LibreWolf & Ghostery to help remove telemetry & bloat\n- Debloat config from PeskyFox, LibreWolf, and others\n- Speed & network optimizations from FastFox\n- Removed all CSS animations\n- Minimalistic theming\n- etc.\n\n#### Addons\n\n- Firefox addons can be loaded with the `--addons` flag\n- Added uBlock Origin with custom privacy filters\n- Addons are not allowed to open tabs\n- Addons are automatically enabled in Private Browsing mode\n- Addons are automatically pinned to the toolbar\n- Fixes DNS leaks with uBO prefetching\n\n## Stealth Performance\n\nIn Camoufox, all of Playwright's internal Page Agent Javascript is sandboxed and isolated.\nThis makes it **impossible** for a page to detect the presence of Playwright through Javascript inspection.\n\n### Tests\n\nCamoufox performs well against every major WAF I've tested. (Original test sites from [Botright](https://github.com/Vinyzu/botright/?tab=readme-ov-file#browser-stealth))\n\n| Test                                                                                               | Status                                                    |\n| -------------------------------------------------------------------------------------------------- | --------------------------------------------------------- |\n| [**CreepJS**](https://abrahamjuliot.github.io/creepjs/)                                            | ‚úîÔ∏è 71.5%. Successfully spoofs all OS predictions.         |\n| [**Rebrowser Bot Detector**](https://bot-detector.rebrowser.net/)                                  | ‚úîÔ∏è All tests pass.                                        |\n| [**BrowserScan**](https://browserscan.net/)                                                        | ‚úîÔ∏è 100%. Spoofs all geolocation & locale proxy detection. |\n| **reCaptcha Score**                                                                                | ‚úîÔ∏è                                                        |\n| ‚Ä£ [nopecha.com](https://nopecha.com/demo/recaptcha)                                                | ‚úîÔ∏è                                                        |\n| ‚Ä£ [recaptcha-demo.appspot.com](https://recaptcha-demo.appspot.com/recaptcha-v3-request-scores.php) | ‚úîÔ∏è 0.9                                                    |\n| ‚Ä£ [berstend.github.io](https://berstend.github.io/static/recaptcha/v3-programmatic.html)           | ‚úîÔ∏è 0.9                                                    |\n| **DataDome**                                                                                       | ‚úîÔ∏è                                                        |\n| ‚Ä£ [DataDome bot bounty](https://yeswehack.com/programs/datadome-bot-bounty#program-description)    | ‚úîÔ∏è All test sites pass.                                   |\n| ‚Ä£ [hermes.com](https://www.hermes.com/us/en/)                                                      | ‚úîÔ∏è                                                        |\n| **Imperva**                                                                                        | ‚úîÔ∏è                                                        |\n| ‚Ä£ [ticketmaster.es](https://www.ticketmaster.es/)                                                  | ‚úîÔ∏è                                                        |\n| **Cloudflare**                                                                                     | ‚úîÔ∏è                                                        |\n| ‚Ä£ [Turnstile](https://nopecha.com/demo/turnstile)                                                  | ‚úîÔ∏è                                                        |\n| ‚Ä£ [Interstitial](https://nopecha.com/demo/cloudflare)                                              | ‚úîÔ∏è                                                        |\n| **WebRTC IP Spoofing**                                                                             | ‚úîÔ∏è                                                        |\n| ‚Ä£ [Browserleaks WebRTC](https://browserleaks.net/webrtc)                                           | ‚úîÔ∏è Spoofs public IP correctly.                            |\n| ‚Ä£ [CreepJS WebRTC](https://abrahamjuliot.github.io/creepjs/)                                       | ‚úîÔ∏è Spoofs Host & STUN IP correctly.                       |\n| ‚Ä£ [BrowserScan WebRTC](https://www.browserscan.net/webrtc)                                         | ‚úîÔ∏è Spoofs Host & STUN IP correctly.                       |\n| **Font Fingerprinting**                                                                            | ‚úîÔ∏è                                                        |\n| ‚Ä£ [Browserleaks Fonts](https://browserleaks.net/fonts)                                             | ‚úîÔ∏è Rotates all metrics.                                   |\n| ‚Ä£ [CreepJS TextMetrics](https://abrahamjuliot.github.io/creepjs/tests/fonts.html)                  | ‚úîÔ∏è Rotates all metrics.                                   |\n| [**Incolumitas**](https://bot.incolumitas.com/)                                                    | ‚úîÔ∏è 0.8-1.0                                                |\n| [**SannySoft**](https://bot.sannysoft.com/)                                                        | ‚úîÔ∏è                                                        |\n| [**Fingerprint.com**](https://fingerprint.com/products/bot-detection/)                             | ‚úîÔ∏è                                                        |\n| [**IpHey**](https://iphey.com/)                                                                    | ‚úîÔ∏è                                                        |\n| [**Bet365**](https://www.bet365.com/#/AC/B1/C1/D1002/E79147586/G40/)                               | ‚úîÔ∏è                                                        |\n\nCamoufox does **not** fully support injecting Chromium fingerprints. Some WAFs (such as [Interstitial](https://nopecha.com/demo/cloudflare)) test for Spidermonkey engine behavior, which is impossible to spoof.\n\n## Playwright Usage\n\n#### See [here](https://github.com/daijro/camoufox/tree/main/pythonlib#camoufox-python-interface) for documentation on Camoufox's Python interface.\n\nIt is strongly recommended to use the Camoufox Python library instead of the legacy launcher, which is now deprecated.\n\n<details>\n<summary>\nSee legacy launcher usage (deprecated)\n</summary>\n\nCamoufox is fully compatible with your existing Playwright code. You only have to change your browser initialization:\n\n```py\nbrowser = pw.firefox.launch(\n  executable_path='/path/to/camoufox/launch',  # Path to the Camoufox launcher\n  args=['--config', '/path/to/config.json'],   # File path or JSON string\n)\n```\n\n<details>\n<summary>\nSee full example script...\n</summary>\n\n```py\nimport asyncio\nimport json\nfrom playwright.async_api import async_playwright\n\n# Example config\nCONFIG = {\n 'window.outerHeight': 1056,\n 'window.outerWidth': 1920,\n 'window.innerHeight': 1008,\n 'window.innerWidth': 1920,\n 'window.history.length': 4,\n 'navigator.userAgent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:125.0) Gecko/20100101 Firefox/125.0',\n 'navigator.appCodeName': 'Mozilla',\n 'navigator.appName': 'Netscape',\n 'navigator.appVersion': '5.0 (Windows)',\n 'navigator.oscpu': 'Windows NT 10.0; Win64; x64',\n 'navigator.language': 'en-US',\n 'navigator.languages': ['en-US'],\n 'navigator.platform': 'Win32',\n 'navigator.hardwareConcurrency': 12,\n 'navigator.product': 'Gecko',\n 'navigator.productSub': '20030107',\n 'navigator.maxTouchPoints': 10,\n}\n\nasync def main():\n    async with async_playwright() as p:\n        # Create a Firefox instance to the launcher\n        browser = await p.firefox.launch(\n          # Pass in the Camoufox launcher and config JSON\n          executable_path='/path/to/camoufox/launch',\n          args=['--config', json.dumps(CONFIG)],\n          # Launch in headful mode\n          headless=False\n        )\n        # Continue as normal\n        page = await browser.new_page()\n        await page.goto('https://abrahamjuliot.github.io/creepjs/')\n        await asyncio.sleep(10)\n        await browser.close()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n</details>\n</details>\n\n---\n\n> [!NOTE]\n> The content below is intended for those interested in building & debugging Camoufox. For Playwright usage instructions, see [here](https://github.com/daijro/camoufox/tree/main/pythonlib#camoufox-python-interface).\n\n<h1 align=\"center\">Build System</h1>\n\n### Overview\n\nHere is a diagram of the build system, and its associated make commands:\n\n```mermaid\ngraph TD\n    FFSRC[Firefox Source] -->|make fetch| REPO\n\n    subgraph REPO[Camoufox Repository]\n        PATCHES[Fingerprint masking patches]\n        ADDONS[uBlock & B.P.C.]\n        DEBLOAT[Debloat/optimizations]\n        SYSTEM_FONTS[Win, Mac, Linux fonts]\n        JUGGLER[Patched Juggler]\n    end\n\n    subgraph Local\n    REPO -->|make dir| PATCH[Patched Source]\n    PATCH -->|make build| BUILD[Built]\n    BUILD -->|make package-linux| LINUX[Linux Portable]\n    BUILD -->|make package-windows| WIN[Windows Portable]\n    BUILD -->|make package-macos| MAC[macOS Portable]\n    end\n```\n\nThis was originally based on the LibreWolf build system.\n\n## Build CLI\n\n> [!WARNING]\n> Camoufox's build system is designed to be used in Linux. WSL will not work!\n\nFirst, clone this repository with Git:\n\n```bash\ngit clone --depth 1 https://github.com/daijro/camoufox\ncd camoufox\n```\n\nNext, build the Camoufox source code with the following command:\n\n```bash\nmake dir\n```\n\nAfter that, you have to bootstrap your system to be able to build Camoufox. You only have to do this one time. It is done by running the following command:\n\n```bash\nmake bootstrap\n```\n\nFinally you can build and package Camoufox the following command:\n\n```bash\npython3 multibuild.py --target linux windows macos --arch x86_64 arm64 i686\n```\n\n<details>\n<summary>\nCLI Parameters\n</summary>\n\n```bash\nOptions:\n  -h, --help            show this help message and exit\n  --target {linux,windows,macos} [{linux,windows,macos} ...]\n                        Target platforms to build\n  --arch {x86_64,arm64,i686} [{x86_64,arm64,i686} ...]\n                        Target architectures to build for each platform\n  --bootstrap           Bootstrap the build system\n  --clean               Clean the build directory before starting\n\nExample:\n$ python3 multibuild.py --target linux windows macos --arch x86_64 arm64\n```\n\n</details>\n\n### Using Docker\n\nCamoufox can be built through Docker on all platforms.\n\n1. Create the Docker image containing Firefox's source code:\n\n```bash\ndocker build -t camoufox-builder .\n```\n\n2. Build Camoufox patches to a target platform and architecture:\n\n```bash\ndocker run -v \"$(pwd)/dist:/app/dist\" camoufox-builder --target <os> --arch <arch>\n```\n\n<details>\n<summary>\nHow can I use my local ~/.mozbuild directory?\n</summary>\n\nIf you want to use the host's .mozbuild directory, you can use the following command instead to run the docker:\n\n```bash\ndocker run \\\n  -v \"$HOME/.mozbuild\":/root/.mozbuild:rw,z \\\n  -v \"$(pwd)/dist:/app/dist\" \\\n  camoufox-builder \\\n  --target <os> \\\n  --arch <arch>\n```\n\n</details>\n\n<details>\n<summary>\nDocker CLI Parameters\n</summary>\n\n```bash\nOptions:\n  -h, --help            show this help message and exit\n  --target {linux,windows,macos} [{linux,windows,macos} ...]\n                        Target platforms to build\n  --arch {x86_64,arm64,i686} [{x86_64,arm64,i686} ...]\n                        Target architectures to build for each platform\n  --bootstrap           Bootstrap the build system\n  --clean               Clean the build directory before starting\n\nExample:\n$ docker run -v \"$(pwd)/dist:/app/dist\" camoufox-builder --target windows macos linux --arch x86_64 arm64 i686\n```\n\n</details>\n\nBuild artifacts will now appear written under the `dist/` folder.\n\n---\n\n## Development Tools\n\nThis repo comes with a developer UI under scripts/developer.py:\n\n```\nmake edits\n```\n\nPatches can be edited, created, removed, and managed through here.\n\n<img src=\"https://i.imgur.com/BYAN5J0.png\">\n\n### How to make a patch\n\n1. In the developer UI, click **Reset workspace**.\n2. Make changes in the `camoufox-*/` folder as needed. You can test your changes with `make build` and `make run`.\n3. After you're done making changes, click **Write workspace to patch** and save the patch file.\n\n### How to work on an existing patch\n\n1. In the developer UI, click **Edit a patch**.\n2. Select the patch you'd like to edit. Your workspace will be reset to the state of the selected patch.\n3. After you're done making changes, hit **Write workspace to patch** and overwrite the existing patch file.\n\n---\n\n## Leak Debugging\n\nThis is a flow chart demonstrating my process for determining leaks without deobfuscating WAF Javascript. The method incrementally reintroduces Camoufox's features into Firefox's source code until the testing site flags.\n\nThis process requires a Linux system and assumes you have Firefox build tools installed (see [here](https://github.com/daijro/camoufox?tab=readme-ov-file#build-cli)).\n\n<details>\n<summary>\nSee flow chart...\n</summary>\n\n```mermaid\nflowchart TD\n    A[Start] --> B[Does website flag in the official Firefox?]\n    B -->|Yes| C[Likely bad IP/rate-limiting. If the website fails on both headless and headful mode on the official Firefox distribution, the issue is not with the browser.]\n    B -->|No| D[\"Run make ff-dbg(1) and build(2) a clean distribution of Firefox. Does the website flag in Firefox **headless** mode(4)?\"]\n    D -->|Yes| E[\"Does the website flag in headful mode(3) AND headless mode(4)?\"]\n    D -->|No| F[\"Open the developer UI(5), apply config.patch, then rebuild(2). Does the website still flag(3)?\"]\n    E -->|No| G[\"Enable privacy.resistFingerprinting in the config(6). Does the website still flag(3)?\"]\n    E -->|Yes| C\n    G -->|No| H[\"In the config(6), enable FPP and start omitting overrides until you find the one that fixed the leak.\"]\n    G -->|Yes| I[If you get to this point, you may need to deobfuscate the Javascript behind the website to identify what it's testing.]\n    F -->|Yes| K[\"Open the developer UI, apply the playwright bootstrap patch, then rebuild. Does it still flag?\"]\n    F -->|No| J[\"Omit options from camoufox.cfg(6) and rerun(3) until you find the one causing the leak.\"]\n    K -->|No| M[Juggler needs to be debugged to locate the leak.]\n    K -->|Yes| L[The issue has nothing to do with Playwright. Apply the rest of the Camoufox patches one by one until the one causing the leak is found.]\n    M --> I\n```\n\n#### Cited Commands\n\n| #   | Command                                       | Description                                                                                                 |\n| --- | --------------------------------------------- | ----------------------------------------------------------------------------------------------------------- |\n| (1) | `make ff-dbg`                                 | Setup vanilla Firefox with minimal patches.                                                                 |\n| (2) | `make build`                                  | Build the source code.                                                                                      |\n| (3) | `make run`                                    | Runs the built browser.                                                                                     |\n| (4) | `make run args=\"--headless https://test.com\"` | Run a URL in headless mode. All redirects will be printed to the console to determine if the test passed.   |\n| (5) | `make edits`                                  | Opens the developer UI. Allows the user to apply/undo patches, and see which patches are currently applied. |\n| (6) | `make edit-cfg`                               | Edit camoufox.cfg in the default system editor.                                                             |\n\n</details>\n\n---\n\n## Thanks\n\n- [LibreWolf](https://gitlab.com/librewolf-community/browser/source) - Debloat patches & build system inspiration\n- [BetterFox](https://github.com/yokoffing/BetterFox) - Debloat & optimizations\n- [Ghostery](https://github.com/ghostery/user-agent-desktop) - Debloat reference\n- [TOR Browser](https://2019.www.torproject.org/projects/torbrowser/design/) - Anti fingerprinting reference\n- [Jamir-boop/minimalisticfox](https://github.com/Jamir-boop/minimalisticfox) - Inspired Camoufox's minimalistic theming\n- [nicoth-in/Dark-Space-Theme](https://github.com/nicoth-in/Dark-Space-Theme) - Camoufox's dark theme\n- [Playwright](https://github.com/microsoft/playwright/tree/main/browser_patches/firefox), [Puppeteer/Juggler](https://github.com/puppeteer/juggler) - Original Juggler implementation\n- [CreepJS](https://github.com/abrahamjuliot/creepjs), [Browserleaks](https://browserleaks.com), [BrowserScan](https://www.browserscan.net/) - Valuable leak testing sites\n- [riflosnake/HumanCursor](https://github.com/riflosnake/HumanCursor) - Original human-like cursor movement algorithm\n",
      "stars_today": 7
    },
    {
      "id": 528898425,
      "name": "hftbacktest",
      "full_name": "nkaz001/hftbacktest",
      "description": "Free, open source, a high frequency trading and market making backtesting and trading bot, which accounts for limit orders, queue positions, and latencies, utilizing full tick data for trades and order books(Level-2 and Level-3), with real-world crypto trading examples for Binance and Bybit",
      "html_url": "https://github.com/nkaz001/hftbacktest",
      "stars": 3528,
      "forks": 695,
      "language": "Rust",
      "topics": [
        "algorithmic-trading",
        "algotrading",
        "backtesting",
        "backtesting-engine",
        "backtesting-trading-strategies",
        "binance",
        "crypto-bot",
        "crypto-trading",
        "hft",
        "high-frequency-trading",
        "limit-order-book",
        "market-maker",
        "market-making",
        "orderbook",
        "orderbook-tick-data",
        "quantitative-trading",
        "trading-algorithms",
        "trading-simulator",
        "trading-strategies",
        "tradingbot"
      ],
      "created_at": "2022-08-25T14:56:36Z",
      "updated_at": "2026-01-13T22:12:56Z",
      "pushed_at": "2025-12-23T15:57:58Z",
      "open_issues": 15,
      "owner": {
        "login": "nkaz001",
        "avatar_url": "https://avatars.githubusercontent.com/u/75321484?v=4"
      },
      "readme": "===========\nHftBacktest\n===========\n\n|codeql| |python| |pypi| |downloads| |rustc| |crates| |license| |docs| |roadmap| |github|\n\nHigh-Frequency Trading Backtesting Tool\n=======================================\n\nThis framework is designed for developing high frequency trading and market making strategies. It focuses on accounting for both feed and order latencies, as well as the order queue position for order fill simulation. The framework aims to provide more accurate market replay-based backtesting, based on full order book and trade tick feed data.\n\nKey Features\n============\n\n* Working in `Numba <https://numba.pydata.org/>`_ JIT function (Python).\n* Complete tick-by-tick simulation with a customizable time interval or based on the feed and order receipt.\n* Full order book reconstruction based on Level-2 Market-By-Price and Level-3 Market-By-Order feeds.\n* Backtest accounting for both feed and order latency, using provided models or your own custom model.\n* Order fill simulation that takes into account the order queue position, using provided models or your own custom model.\n* Backtesting of multi-asset and multi-exchange models\n* Deployment of a live trading bot for quick prototyping and testing using the same algorithm code: currently for Binance Futures and Bybit. (Rust-only)\n\nDocumentation\n=============\n\nSee `full document here <https://hftbacktest.readthedocs.io/>`_.\n\nTutorials you‚Äôll likely find interesting:\n\n* `High-Frequency Grid Trading - Simplified from GLFT <https://hftbacktest.readthedocs.io/en/latest/tutorials/High-Frequency%20Grid%20Trading%20-%20Simplified%20from%20GLFT.html>`_\n* `Market Making with Alpha - Order Book Imbalance <https://hftbacktest.readthedocs.io/en/latest/tutorials/Market%20Making%20with%20Alpha%20-%20Order%20Book%20Imbalance.html>`_\n* `Market Making with Alpha - APT <https://hftbacktest.readthedocs.io/en/latest/tutorials/Market%20Making%20with%20Alpha%20-%20APT.html>`_\n* `Accelerated Backtesting <https://hftbacktest.readthedocs.io/en/latest/tutorials/Accelerated%20Backtesting.html>`_\n* `Pricing Framework <https://hftbacktest.readthedocs.io/en/latest/tutorials/Pricing%20Framework.html>`_\n\nWhy Accurate Backtesting Matters ‚Äî Not Just Conservative Approach\n=================================================================\n\nTrading is a highly competitive field where only the small edges usually exist, but they can still make a significant\ndifference. Because of this, backtesting must accurately simulate real-world conditions.: It should neither rely on an\noverly pessimistic approach that hides these small edges and profit opportunities, nor on an overly optimistic one that\noverstates them through unrealistic simulation. Or at the very least, you should clearly understand what differs from\nlive trading and by how much, since sometimes fully accurate backtesting is not practical due to the time it requires.\n\nThis is not about overfitting at the start‚Äîbefore you even consider issues like overfitting, you need confidence that\nyour backtesting truly reflects real-world execution. For example, if you run a live trading strategy in January 2025,\nthe backtest for that exact period should produce results that closely align with the actual results. Once you‚Äôve\nvalidated that your backtesting can accurately reproduce live trading results, then you can proceed to deeper research,\noptimization, and considerations around overfitting.\n\nAccurate backtesting is the foundation. Without it, all further analysis‚Äîwhether conservative or aggressive‚Äîbecomes\nunreliable.\n\nGetting started\n===============\n\nInstallation\n------------\n\nhftbacktest supports Python 3.11+. You can install hftbacktest using ``pip``:\n\n.. code-block:: console\n\n pip install hftbacktest\n\nOr you can clone the latest development version from the Git repository with:\n\n.. code-block:: console\n\n git clone https://github.com/nkaz001/hftbacktest\n\nData Source & Format\n--------------------\n\nPlease see `Data <https://hftbacktest.readthedocs.io/en/latest/data.html>`_ or `Data Preparation <https://hftbacktest.readthedocs.io/en/latest/tutorials/Data%20Preparation.html>`_.\n\nYou can also find some data `here <https://reach.stratosphere.capital/data/usdm/>`_, hosted by the supporter.\n\nA Quick Example\n---------------\n\nGet a glimpse of what backtesting with hftbacktest looks like with these code snippets:\n\n.. code-block:: python\n\n    @njit\n    def market_making_algo(hbt):\n        asset_no = 0\n        tick_size = hbt.depth(asset_no).tick_size\n        lot_size = hbt.depth(asset_no).lot_size\n\n        # in nanoseconds\n        while hbt.elapse(10_000_000) == 0:\n            hbt.clear_inactive_orders(asset_no)\n\n            a = 1\n            b = 1\n            c = 1\n            hs = 1\n\n            # Alpha, it can be a combination of several indicators.\n            forecast = 0\n            # In HFT, it can be various measurements of short-term market movements,\n            # such as the high-low range in the last X minutes.\n            volatility = 0\n            # Delta risk, it can be a combination of several risks.\n            position = hbt.position(asset_no)\n            risk = (c + volatility) * position\n            half_spread = (c + volatility) * hs\n\n            max_notional_position = 1000\n            notional_qty = 100\n\n            depth = hbt.depth(asset_no)\n\n            mid_price = (depth.best_bid + depth.best_ask) / 2.0\n\n            # fair value pricing = mid_price + a * forecast\n            #                      or underlying(correlated asset) + adjustment(basis + cost + etc) + a * forecast\n            # risk skewing = -b * risk\n            reservation_price = mid_price + a * forecast - b * risk\n            new_bid = reservation_price - half_spread\n            new_ask = reservation_price + half_spread\n\n            new_bid_tick = min(np.round(new_bid / tick_size), depth.best_bid_tick)\n            new_ask_tick = max(np.round(new_ask / tick_size), depth.best_ask_tick)\n\n            order_qty = np.round(notional_qty / mid_price / lot_size) * lot_size\n\n            # Elapses a process time.\n            if not hbt.elapse(1_000_000) != 0:\n                return False\n\n            last_order_id = -1\n            update_bid = True\n            update_ask = True\n            buy_limit_exceeded = position * mid_price > max_notional_position\n            sell_limit_exceeded = position * mid_price < -max_notional_position\n            orders = hbt.orders(asset_no)\n            order_values = orders.values()\n            while order_values.has_next():\n                order = order_values.get()\n                if order.side == BUY:\n                    if order.price_tick == new_bid_tick or buy_limit_exceeded:\n                        update_bid = False\n                    if order.cancellable and (update_bid or buy_limit_exceeded):\n                        hbt.cancel(asset_no, order.order_id, False)\n                        last_order_id = order.order_id\n                elif order.side == SELL:\n                    if order.price_tick == new_ask_tick or sell_limit_exceeded:\n                        update_ask = False\n                    if order.cancellable and (update_ask or sell_limit_exceeded):\n                        hbt.cancel(asset_no, order.order_id, False)\n                        last_order_id = order.order_id\n\n            # It can be combined with a grid trading strategy by submitting multiple orders to capture better spreads and\n            # have queue position.\n            # This approach requires more sophisticated logic to efficiently manage resting orders in the order book.\n            if update_bid:\n                # There is only one order at a given price, with new_bid_tick used as the order ID.\n                order_id = new_bid_tick\n                hbt.submit_buy_order(asset_no, order_id, new_bid_tick * tick_size, order_qty, GTX, LIMIT, False)\n                last_order_id = order_id\n            if update_ask:\n                # There is only one order at a given price, with new_ask_tick used as the order ID.\n                order_id = new_ask_tick\n                hbt.submit_sell_order(asset_no, order_id, new_ask_tick * tick_size, order_qty, GTX, LIMIT, False)\n                last_order_id = order_id\n\n            # All order requests are considered to be requested at the same time.\n            # Waits until one of the order responses is received.\n            if last_order_id >= 0:\n                # Waits for the order response for a maximum of 5 seconds.\n                timeout = 5_000_000_000\n                if not hbt.wait_order_response(asset_no, last_order_id, timeout):\n                    return False\n\n        return True\n\n\nTutorials\n=========\n* `Data Preparation <https://hftbacktest.readthedocs.io/en/latest/tutorials/Data%20Preparation.html>`_\n* `Getting Started <https://hftbacktest.readthedocs.io/en/latest/tutorials/Getting%20Started.html>`_\n* `Working with Market Depth and Trades <https://hftbacktest.readthedocs.io/en/latest/tutorials/Working%20with%20Market%20Depth%20and%20Trades.html>`_\n* `Integrating Custom Data <https://hftbacktest.readthedocs.io/en/latest/tutorials/Integrating%20Custom%20Data.html>`_\n* `Making Multiple Markets - Introduction <https://hftbacktest.readthedocs.io/en/latest/tutorials/Making%20Multiple%20Markets%20-%20Introduction.html>`_\n* `High-Frequency Grid Trading <https://hftbacktest.readthedocs.io/en/latest/tutorials/High-Frequency%20Grid%20Trading.html>`_\n* `High-Frequency Grid Trading - Comparison Across Other Exchanges <https://hftbacktest.readthedocs.io/en/latest/tutorials/High-Frequency%20Grid%20Trading%20-%20Comparison%20Across%20Other%20Exchanges.html>`_\n* `High-Frequency Grid Trading - Simplified from GLFT <https://hftbacktest.readthedocs.io/en/latest/tutorials/High-Frequency%20Grid%20Trading%20-%20Simplified%20from%20GLFT.html>`_\n* `Impact of Order Latency <https://hftbacktest.readthedocs.io/en/latest/tutorials/Impact%20of%20Order%20Latency.html>`_\n* `Order Latency Data <https://hftbacktest.readthedocs.io/en/latest/tutorials/Order%20Latency%20Data.html>`_\n* `Gu√©ant‚ÄìLehalle‚ÄìFernandez-Tapia Market Making Model and Grid Trading <https://hftbacktest.readthedocs.io/en/latest/tutorials/GLFT%20Market%20Making%20Model%20and%20Grid%20Trading.html>`_\n* `Making Multiple Markets <https://hftbacktest.readthedocs.io/en/latest/tutorials/Making%20Multiple%20Markets.html>`_\n* `Risk Mitigation through Price Protection in Extreme Market Conditions <https://hftbacktest.readthedocs.io/en/latest/tutorials/Risk%20Mitigation%20through%20Price%20Protection%20in%20Extreme%20Market%20Conditions.html>`_\n* `Level-3 Backtesting <https://hftbacktest.readthedocs.io/en/latest/tutorials/Level-3%20Backtesting.html>`_\n* `Market Making with Alpha - Order Book Imbalance <https://hftbacktest.readthedocs.io/en/latest/tutorials/Market%20Making%20with%20Alpha%20-%20Order%20Book%20Imbalance.html>`_\n* `Market Making with Alpha - Basis <https://hftbacktest.readthedocs.io/en/latest/tutorials/Market%20Making%20with%20Alpha%20-%20Basis.html>`_\n* `Market Making with Alpha - APT <https://hftbacktest.readthedocs.io/en/latest/tutorials/Market%20Making%20with%20Alpha%20-%20APT.html>`_\n* `Queue-Based Market Making in Large Tick Size Assets <https://hftbacktest.readthedocs.io/en/latest/tutorials/Queue-Based%20Market%20Making%20in%20Large%20Tick%20Size%20Assets.html>`_\n* `Fusing Depth Data <https://hftbacktest.readthedocs.io/en/latest/tutorials/Fusing%20Depth%20Data.html>`_\n* `Accelerated Backtesting <https://hftbacktest.readthedocs.io/en/latest/tutorials/Accelerated%20Backtesting.html>`_\n* `Pricing Framework <https://hftbacktest.readthedocs.io/en/latest/tutorials/Pricing%20Framework.html>`_\n\nExamples\n========\n\nYou can find more examples in `examples <https://github.com/nkaz001/hftbacktest/tree/master/examples>`_ directory and `Rust examples <https://github.com/nkaz001/hftbacktest/blob/master/hftbacktest/examples/>`_.\n\nThe complete process of backtesting Binance Futures\n---------------------------------------------------\n`high-frequency gridtrading <https://github.com/nkaz001/hftbacktest/blob/master/hftbacktest/examples/gridtrading.ipynb>`_: The complete process of backtesting Binance Futures using a high-frequency grid trading strategy implemented in Rust.\n\nMigration to V2\n===============\nPlease see the `migration guide <https://hftbacktest.readthedocs.io/en/latest/migration2.html>`_.\n\nRoadmap\n=======\n\nPlease see the `roadmap <https://github.com/nkaz001/hftbacktest/blob/master/ROADMAP.md>`_.\n\nContributing\n============\n\nThank you for considering contributing to hftbacktest! Welcome any and all help to improve the project. If you have an\nidea for an enhancement or a bug fix, please open an issue or discussion on GitHub to discuss it.\n\nThe following items are examples of contributions you can make to this project:\n\nPlease see the `roadmap <https://github.com/nkaz001/hftbacktest/blob/master/ROADMAP.md>`_.\n\n.. |python| image:: https://shields.io/badge/python-3.11+-blue\n    :alt: Python Version\n    :target: https://www.python.org/\n\n.. |codeql| image:: https://github.com/nkaz001/hftbacktest/actions/workflows/codeql.yml/badge.svg?branch=master&event=push\n    :alt: CodeQL\n    :target: https://github.com/nkaz001/hftbacktest/actions/workflows/codeql.yml\n\n.. |pypi| image:: https://badge.fury.io/py/hftbacktest.svg\n    :alt: Package Version\n    :target: https://pypi.org/project/hftbacktest\n\n.. |downloads| image:: https://static.pepy.tech/badge/hftbacktest\n    :alt: Downloads\n    :target: https://pepy.tech/project/hftbacktest\n\n.. |crates| image:: https://img.shields.io/crates/v/hftbacktest.svg\n    :alt: Rust crates.io version\n    :target: https://crates.io/crates/hftbacktest\n\n.. |license| image:: https://img.shields.io/badge/License-MIT-green.svg\n    :alt: License\n    :target: https://github.com/nkaz001/hftbacktest/blob/master/LICENSE\n\n.. |docs| image:: https://readthedocs.org/projects/hftbacktest/badge/?version=latest\n    :target: https://hftbacktest.readthedocs.io/en/latest/?badge=latest\n    :alt: Documentation Status\n\n.. |roadmap| image:: https://img.shields.io/badge/Roadmap-gray\n    :target: https://github.com/nkaz001/hftbacktest/blob/master/ROADMAP.md\n    :alt: Roadmap\n\n.. |github| image:: https://img.shields.io/github/stars/nkaz001/hftbacktest?style=social\n    :target: https://github.com/nkaz001/hftbacktest\n    :alt: Github\n\n.. |rustc| image:: https://shields.io/badge/rustc-1.90-blue\n    :alt: Rust Version\n    :target: https://www.rust-lang.org/\n",
      "stars_today": 7
    },
    {
      "id": 241178673,
      "name": "f3d",
      "full_name": "f3d-app/f3d",
      "description": "Fast and minimalist 3D viewer.",
      "html_url": "https://github.com/f3d-app/f3d",
      "stars": 4037,
      "forks": 366,
      "language": "C++",
      "topics": [
        "3d",
        "3d-graphics",
        "3d-viewer",
        "command-line-tool",
        "dxf",
        "fbx",
        "glb",
        "gltf",
        "gltf-viewer",
        "graphics",
        "obj",
        "physically-based-rendering",
        "raytracing",
        "rendering",
        "step",
        "stl-viewer",
        "usd",
        "volume-rendering",
        "vtk"
      ],
      "created_at": "2020-02-17T18:26:59Z",
      "updated_at": "2026-01-14T00:21:21Z",
      "pushed_at": "2026-01-13T16:11:14Z",
      "open_issues": 273,
      "owner": {
        "login": "f3d-app",
        "avatar_url": "https://avatars.githubusercontent.com/u/93085409?v=4"
      },
      "readme": "[![CI](https://img.shields.io/github/actions/workflow/status/f3d-app/f3d/ci.yml?label=CI&logo=github)](https://github.com/f3d-app/f3d/actions/workflows/ci.yml) [![Packaging](https://img.shields.io/github/actions/workflow/status/f3d-app/f3d-superbuild/nightly.yml?label=Packaging&logo=github)](https://github.com/f3d-app/f3d-superbuild) [![codecov](https://codecov.io/gh/f3d-app/f3d/branch/master/graph/badge.svg?token=siwG82IXK7)](https://codecov.io/gh/f3d-app/f3d) [![Downloads](https://img.shields.io/github/downloads/f3d-app/f3d/total.svg)](https://github.com/f3d-app/f3d/releases) [![Sponsors](https://img.shields.io/static/v1?label=Sponsor&message=%E2%9D%A4&logo=GitHub&color=%23fe8e86)](https://f3d.app/thanks) [![Discord](https://discordapp.com/api/guilds/1046005690809978911/widget.png?style=shield)](https://discord.f3d.app) [![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg)](CODE_OF_CONDUCT.md)\n\n# F3D - Fast and minimalist 3D viewer\n\nBy the F3D-APP Foundation.\n\n<img src=\"https://raw.githubusercontent.com/f3d-app/f3d/master/resources/logo.svg\" align=\"left\" width=\"20px\"/>\nF3D (pronounced `/f…õd/`) is a fast and minimalist 3D viewer desktop application. It supports many file formats, from digital content to scientific datasets (including glTF, USD, STL, STEP, PLY, OBJ, FBX, Alembic), can show animations and support thumbnails and many rendering and texturing options including real time physically based rendering and raytracing.\n<br clear=\"left\"/>\n\nIt is fully controllable from the command line and support configuration files. It can provide thumbnails, support interactive hotkeys, drag&drop and integration into file managers.\n\nF3D also contains the libf3d, a simple library to render meshes, with a C++17 API, C, Python, Java and Javascript Bindings.\n\n<img src=\"https://media.githubusercontent.com/media/f3d-app/f3d-website/refs/heads/main/static/images/typical.png\" width=\"640\" />\n\n_A typical render by F3D_\n\n<img src=\"https://user-images.githubusercontent.com/3129530/194735261-dd6f1c1c-fa57-47b0-9d27-f735d18ccd5e.gif\" width=\"640\" />\n\n_Animation of a glTF file within F3D_\n\n<img src=\"https://media.githubusercontent.com/media/f3d-app/f3d-website/refs/heads/main/static/images/directScalars.png\" width=\"640\" />\n\n_A direct scalars render by F3D_\n\nSee the [gallery](https://f3d.app/gallery) for more images, take a look at the [changelog](doc/CHANGELOG.md) or go to the [download page](https://f3d.app/download) to download and install F3D!\n\nYou can even use F3D directly in your [browser](https://f3d.app/viewer)!\n\nIf you need any help or want to discuss with other F3D users and developers, head over to our [discord](https://discord.f3d.app).\n\n# Quickstart\n\nOpen a file directly in F3D or from the command line by running:\n\n```\nf3d /path/to/file.ext\n```\n\nOptionally, append `--output=/path/to/img.png` to save the rendering into an image file.\n\nSee the [Quickstart Guide](doc/user/01-QUICKSTART.md) for more information about getting started with F3D.\n\n# Documentation\n\n- To get started, please take a look at the [user documentation](doc/user/01-QUICKSTART.md).\n- If you need any help, are looking for a feature or found a bug, please open an [issue](https://github.com/f3d-app/f3d/issues).\n- If you want to use the libf3d, please take a look at its [documentation](doc/libf3d/01-OVERVIEW.md).\n- If you want to build F3D, please take a look at the [contribution guide](CONTRIBUTING.md).\n\n# Support\n\nF3D needs your help!\n\nIf you can, please consider sponsoring F3D. Even a small donation would help us offset the recurring maintenance costs.\nWith enough sponsors we would be able to make F3D grow faster and stronger! Read more about it [here](https://f3d.app/thanks).\n\nIf you are an industry user of F3D and want to make sure it can keep growing and being maintained, [please reach out](https://f3d.app/thanks)!\n\nIn any case, please star it on github and share the word about it!\n\n## Sponsors\n\nMany thanks to our sponsors for supporting F3D\n\n<a href=\"https://nlnet.nl/project/F3D/\" target=\"_blank\"><img src=\"https://nlnet.nl/image/logos/NGI0Core_tag.svg\" height=\"45\"/></a>\n<a href=\"https://www.lambdatest.com/?utm_source=f3d&utm_medium=sponsor\" target=\"_blank\"><img src=\"https://www.lambdatest.com/blue-logo.png\" height=\"45\" /></a>\n<a href=\"https://www.opendronemap.org/\" target=\"_blank\"><img src=\"https://f3d.app/assets/images/opendronemap-95d4ad6e24c091a06ec00e1828e1eb38.png\" height=\"45\" /></a>\n\n# Vision\n\nAs a minimalist 3D viewer F3D aims to:\n\n- Support as many 3D file formats as possible\n- Support many types of renderings (textures, edges, etc... ) and visualizations (meshes, volumic, point sprites)\n- Support any and all use-cases dealing with 3D datasets\n- Let any user easily and quickly view any model with good defaults\n- Be as configurable as possible\n- Be fully controllable from the command line and configuration file\n- Be usable non-interactively\n- Be as modular as possible to be built with a small number of dependencies\n\nbut there is no plan to:\n\n- Provide a classic mouse-based UI, with menus and buttons\n- Provide data processing tools\n- Provide export feature\n\n# Contributing\n\nF3D as a community-driven, inclusive and beginner-friendly project. We love to see how the project is growing thanks to the contributions from the community. We would love to see your face in the list below! If you want to contribute to F3D, you are very welcome to! Take a look at our [contribution documentation](CONTRIBUTING.md), [governance documentation](doc/dev/10-GOVERNANCE.md) and [code of conduct](CODE_OF_CONDUCT.md).\n\n<a href=\"https://github.com/f3d-app/f3d/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=f3d-app/f3d\" />\n</a>\n\n# Acknowledgments\n\nF3D was initially created by [Kitware SAS](https://www.kitware.eu/), by Joachim Pouderoux, Michael Migliore and Mathieu Westphal, and is relying on many awesome open source projects, including [VTK](https://vtk.org/), [OCCT](https://dev.opencascade.org/), [Assimp](https://www.assimp.org/), [Alembic](http://www.alembic.io/), [Draco](https://google.github.io/draco/), [OpenUSD](https://openusd.org/release/index.html), [OpenVDB](https://www.openvdb.org/), [OSPRay](https://www.ospray.org/) and [ImGui](https://github.com/ocornut/imgui/).\n\n# License\n\nF3D can be used and distributed under the 3-Clause BSD License, see the [license](LICENSE.md).\nF3D integrate the sources of other libraries and tools, all under permissive licenses, see the [third party licenses](THIRD_PARTY_LICENSES.md).\nF3D packages relies on other libraries and tools, all under permissive licenses, all listed in the respective packages.\n",
      "stars_today": 7
    },
    {
      "id": 2211243,
      "name": "kafka",
      "full_name": "apache/kafka",
      "description": "Mirror of Apache Kafka",
      "html_url": "https://github.com/apache/kafka",
      "stars": 31703,
      "forks": 14895,
      "language": "Java",
      "topics": [
        "kafka",
        "scala"
      ],
      "created_at": "2011-08-15T18:06:16Z",
      "updated_at": "2026-01-14T00:50:38Z",
      "pushed_at": "2026-01-13T17:08:56Z",
      "open_issues": 254,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "<p align=\"center\">\n<picture>\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"docs/images/kafka-logo-readme-light.svg\">\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/kafka-logo-readme-dark.svg\">\n  <img src=\"docs/images/kafka-logo-readme-light.svg\" alt=\"Kafka Logo\" width=\"50%\"> \n</picture>\n</p>\n\n[![CI](https://github.com/apache/kafka/actions/workflows/ci.yml/badge.svg?branch=trunk&event=push)](https://github.com/apache/kafka/actions/workflows/ci.yml?query=event%3Apush+branch%3Atrunk)\n[![Flaky Test Report](https://github.com/apache/kafka/actions/workflows/generate-reports.yml/badge.svg?branch=trunk&event=schedule)](https://github.com/apache/kafka/actions/workflows/generate-reports.yml?query=event%3Aschedule+branch%3Atrunk)\n\n[**Apache Kafka**](https://kafka.apache.org) is an open-source distributed event streaming platform used by thousands of companies for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.\n\nYou need to have [Java](http://www.oracle.com/technetwork/java/javase/downloads/index.html) installed.\n\nWe build and test Apache Kafka with 17 and 25. The `release` parameter in javac is set to `11` for the clients \nand streams modules, and `17` for the rest, ensuring compatibility with their respective\nminimum Java versions. Similarly, the `release` parameter in scalac is set to `11` for the streams modules and `17`\nfor the rest.\n\nScala 2.13 is the only supported version in Apache Kafka.\n\n### Build a jar and run it ###\n    ./gradlew jar\n\nFollow instructions in https://kafka.apache.org/quickstart\n\n### Build source jar ###\n    ./gradlew srcJar\n\n### Build aggregated javadoc ###\n    ./gradlew aggregatedJavadoc --no-parallel\n\n### Build javadoc and scaladoc ###\n    ./gradlew javadoc\n    ./gradlew javadocJar # builds a javadoc jar for each module\n    ./gradlew scaladoc\n    ./gradlew scaladocJar # builds a scaladoc jar for each module\n    ./gradlew docsJar # builds both (if applicable) javadoc and scaladoc jars for each module\n\n### Run unit/integration tests ###\n    ./gradlew test  # runs both unit and integration tests\n    ./gradlew unitTest\n    ./gradlew integrationTest\n    ./gradlew test -Pkafka.test.run.flaky=true  # runs tests that are marked as flaky\n\n    \n### Force re-running tests without code change ###\n    ./gradlew test --rerun-tasks\n    ./gradlew unitTest --rerun-tasks\n    ./gradlew integrationTest --rerun-tasks\n\n### Running a particular unit/integration test ###\n    ./gradlew clients:test --tests RequestResponseTest\n    ./gradlew streams:integration-tests:test --tests RestoreIntegrationTest\n\n### Repeatedly running a particular unit/integration test with specific times by setting N ###\n    N=500; I=0; while [ $I -lt $N ] && ./gradlew clients:test --tests RequestResponseTest --rerun --fail-fast; do (( I=$I+1 )); echo \"Completed run: $I\"; sleep 1; done\n\n### Running a particular test method within a unit/integration test ###\n    ./gradlew core:test --tests kafka.api.ProducerFailureHandlingTest.testCannotSendToInternalTopic\n    ./gradlew clients:test --tests org.apache.kafka.clients.MetadataTest.testTimeToNextUpdate\n    ./gradlew streams:integration-tests:test --tests org.apache.kafka.streams.integration.RestoreIntegrationTest.shouldRestoreNullRecord\n\n### Running a particular unit/integration test with log4j output ###\nBy default, there will be only small number of logs output while testing. You can adjust it by changing the `log4j2.yaml` file in the module's `src/test/resources` directory.\n\nFor example, if you want to see more logs for clients project tests, you can modify [the line](https://github.com/apache/kafka/blob/trunk/clients/src/test/resources/log4j2.yaml#L35) in `clients/src/test/resources/log4j2.yaml` \nto `level: INFO` and then run:\n    \n    ./gradlew cleanTest clients:test --tests NetworkClientTest   \n\nAnd you should see `INFO` level logs in the file under the `clients/build/test-results/test` directory.\n\n### Specifying test retries ###\nRetries are disabled by default, but you can set maxTestRetryFailures and maxTestRetries to enable retries.\n\nThe following example declares -PmaxTestRetries=1 and -PmaxTestRetryFailures=3 to enable a failed test to be retried once, with a total retry limit of 3.\n\n    ./gradlew test -PmaxTestRetries=1 -PmaxTestRetryFailures=3\n\nSee [Test Retry Gradle Plugin](https://github.com/gradle/test-retry-gradle-plugin) and [build.yml](.github/workflows/build.yml) for more details.\n\n### Generating test coverage reports ###\nGenerate coverage reports for the whole project:\n\n    ./gradlew reportCoverage -PenableTestCoverage=true -Dorg.gradle.parallel=false\n\nGenerate coverage for a single module, i.e.: \n\n    ./gradlew clients:reportCoverage -PenableTestCoverage=true -Dorg.gradle.parallel=false\n\nCoverage reports are located within the module's build directory, categorized by module type:\n\nCore Module (:core): `core/build/reports/scoverageTest/index.html`\n\nOther Modules: `<module>/build/reports/jacoco/test/html/index.html`\n\n### Building a binary release gzipped tar ball ###\n    ./gradlew clean releaseTarGz\n\nThe release file can be found inside `./core/build/distributions/`.\n\n### Building auto generated messages ###\nSometimes it is only necessary to rebuild the RPC auto-generated message data when switching between branches, as they could\nfail due to code changes. You can just run:\n \n    ./gradlew processMessages processTestMessages\n\nSee [Apache Kafka Message Definitions](clients/src/main/resources/common/message/README.md) for details on Apache Kafka message protocol.\n\n### Running a Kafka broker\n\nUsing compiled files:\n\n    KAFKA_CLUSTER_ID=\"$(./bin/kafka-storage.sh random-uuid)\"\n    ./bin/kafka-storage.sh format --standalone -t $KAFKA_CLUSTER_ID -c config/server.properties\n    ./bin/kafka-server-start.sh config/server.properties\n\nUsing docker image:\n\n    docker run -p 9092:9092 apache/kafka:latest\n\nSee [docker/README.md](docker/README.md) for detailed information.\n\n### Cleaning the build ###\n    ./gradlew clean\n\n### Running a task for a specific project ###\nThis is for `core`, `examples` and `clients`\n\n    ./gradlew core:jar\n    ./gradlew core:test\n\nStreams has multiple sub-projects, but you can run all the tests:\n\n    ./gradlew :streams:testAll\n\n### Listing all gradle tasks ###\n    ./gradlew tasks\n\n### Building IDE project ####\n*Note Please ensure that JDK17 is used when developing Kafka.*\n\nIntelliJ supports Gradle natively and it will automatically check Java syntax and compatibility for each module, even if\nthe Java version shown in the `Structure > Project Settings > Modules` may not be the correct one.\n\nWhen it comes to Eclipse, run:\n\n    ./gradlew eclipse\n\nThe `eclipse` task has been configured to use `${project_dir}/build_eclipse` as Eclipse's build directory. Eclipse's default\nbuild directory (`${project_dir}/bin`) clashes with Kafka's scripts directory and we don't use Gradle's build directory\nto avoid known issues with this configuration.\n\n### Publishing the streams quickstart archetype artifact to maven ###\nFor the Streams archetype project, one cannot use gradle to upload to maven; instead the `mvn deploy` command needs to be called at the quickstart folder:\n\n    cd streams/quickstart\n    mvn deploy\n\nPlease note for this to work you should create/update user maven settings (typically, `${USER_HOME}/.m2/settings.xml`) to assign the following variables\n\n    <settings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0\n                           https://maven.apache.org/xsd/settings-1.0.0.xsd\">\n    ...                           \n    <servers>\n       ...\n       <server>\n          <id>apache.snapshots.https</id>\n          <username>${maven_username}</username>\n          <password>${maven_password}</password>\n       </server>\n       <server>\n          <id>apache.releases.https</id>\n          <username>${maven_username}</username>\n          <password>${maven_password}</password>\n        </server>\n        ...\n     </servers>\n     ...\n\n### Installing all projects to the local Maven repository ###\n\n    ./gradlew -PskipSigning=true publishToMavenLocal\n\n### Installing specific projects to the local Maven repository ###\n\n    ./gradlew -PskipSigning=true :streams:publishToMavenLocal\n    \n### Building the test jar ###\n    ./gradlew testJar\n\n### Running code quality checks ###\nThere are two code quality analysis tools that we regularly run, spotbugs and checkstyle.\n\n#### Checkstyle ####\nCheckstyle enforces a consistent coding style in Kafka.\nYou can run checkstyle using:\n\n    ./gradlew checkstyleMain checkstyleTest spotlessCheck\n\nThe checkstyle warnings will be found in `reports/checkstyle/reports/main.html` and `reports/checkstyle/reports/test.html` files in the\nsubproject build directories. They are also printed to the console. The build will fail if Checkstyle fails.\nFor experiments (or regression testing purposes) add `-PcheckstyleVersion=X.y.z` switch (to override project-defined checkstyle version).\n\n#### Spotless ####\nThe import order is a part of static check. please call `spotlessApply` to optimize the imports of Java codes before filing pull request.\n\n    ./gradlew spotlessApply\n\n#### Spotbugs ####\nSpotbugs uses static analysis to look for bugs in the code.\nYou can run spotbugs using:\n\n    ./gradlew spotbugsMain spotbugsTest -x test\n\nThe spotbugs warnings will be found in `reports/spotbugs/main.html` and `reports/spotbugs/test.html` files in the subproject build\ndirectories.  Use -PxmlSpotBugsReport=true to generate an XML report instead of an HTML one.\n\n### JMH microbenchmarks ###\nWe use [JMH](https://openjdk.java.net/projects/code-tools/jmh/) to write microbenchmarks that produce reliable results in the JVM.\n    \nSee [jmh-benchmarks/README.md](https://github.com/apache/kafka/blob/trunk/jmh-benchmarks/README.md) for details on how to run the microbenchmarks.\n\n### Dependency Analysis ###\n\nThe gradle [dependency debugging documentation](https://docs.gradle.org/current/userguide/viewing_debugging_dependencies.html) mentions using the `dependencies` or `dependencyInsight` tasks to debug dependencies for the root project or individual subprojects.\n\nAlternatively, use the `allDeps` or `allDepInsight` tasks for recursively iterating through all subprojects:\n\n    ./gradlew allDeps\n\n    ./gradlew allDepInsight --configuration runtimeClasspath --dependency com.fasterxml.jackson.core:jackson-databind\n\nThese take the same arguments as the builtin variants.\n\n### Determining if any dependencies could be updated ###\n    ./gradlew dependencyUpdates --no-parallel\n\n### Common build options ###\n\nThe following options should be set with a `-P` switch, for example `./gradlew -PmaxParallelForks=1 test`.\n\n* `commitId`: sets the build commit ID as .git/HEAD might not be correct if there are local commits added for build purposes.\n* `mavenUrl`: sets the URL of the maven deployment repository (`file://path/to/repo` can be used to point to a local repository).\n* `maxParallelForks`: maximum number of test processes to start in parallel. Defaults to the number of processors available to the JVM.\n* `maxScalacThreads`: maximum number of worker threads for the scalac backend. Defaults to the lowest of `8` and the number of processors\navailable to the JVM. The value must be between 1 and 16 (inclusive). \n* `ignoreFailures`: ignore test failures from junit\n* `showStandardStreams`: shows standard out and standard error of the test JVM(s) on the console.\n* `skipSigning`: skips signing of artifacts.\n* `testLoggingEvents`: unit test events to be logged, separated by comma. For example `./gradlew -PtestLoggingEvents=started,passed,skipped,failed test`.\n* `xmlSpotBugsReport`: enable XML reports for spotBugs. This also disables HTML reports as only one can be enabled at a time.\n* `maxTestRetries`: maximum number of retries for a failing test case.\n* `maxTestRetryFailures`: maximum number of test failures before retrying is disabled for subsequent tests.\n* `enableTestCoverage`: enables test coverage plugins and tasks, including bytecode enhancement of classes required to track said\ncoverage. Note that this introduces some overhead when running tests and hence why it's disabled by default (the overhead\nvaries, but 15-20% is a reasonable estimate).\n* `keepAliveMode`: configures the keep alive mode for the Gradle compilation daemon - reuse improves start-up time. The values should \nbe one of `daemon` or `session` (the default is `daemon`). `daemon` keeps the daemon alive until it's explicitly stopped while\n`session` keeps it alive until the end of the build session. This currently only affects the Scala compiler, see\nhttps://github.com/gradle/gradle/pull/21034 for a PR that attempts to do the same for the Java compiler.\n* `scalaOptimizerMode`: configures the optimizing behavior of the scala compiler, the value should be one of `none`, `method`, `inline-kafka` or\n`inline-scala` (the default is `inline-kafka`). `none` is the scala compiler default, which only eliminates unreachable code. `method` also\nincludes method-local optimizations. `inline-kafka` adds inlining of methods within the kafka packages. Finally, `inline-scala` also\nincludes inlining of methods within the scala library (which avoids lambda allocations for methods like `Option.exists`). `inline-scala` is\nonly safe if the Scala library version is the same at compile time and runtime. Since we cannot guarantee this for all cases (for example, users\nmay depend on the kafka jar for integration tests where they may include a scala library with a different version), we don't enable it by\ndefault. See https://www.lightbend.com/blog/scala-inliner-optimizer for more details.\n\n### Upgrading Gradle version ###\n\nSee [gradle/wrapper/README.md](gradle/wrapper/README.md) for instructions on upgrading the Gradle version.\n\n### Running system tests ###\n\nSee [tests/README.md](tests/README.md).\n\n### Using Trogdor for testing ###\n\nWe use Trogdor as a test framework for Apache Kafka. You can use it to run benchmarks and other workloads.\n\nSee [trogdor/README.md](trogdor/README.md).\n\n### Running in Vagrant ###\n\nSee [vagrant/README.md](vagrant/README.md).\n\n### Kafka client examples ###\n\nSee [examples/README.md](examples/README.md).\n\n### Contribution ###\n\nApache Kafka is interested in building the community; we would welcome any thoughts or [patches](https://issues.apache.org/jira/browse/KAFKA). You can reach us [on the Apache mailing lists](http://kafka.apache.org/contact.html).\n\nTo contribute follow the instructions here:\n * https://kafka.apache.org/contributing.html \n",
      "stars_today": 6
    },
    {
      "id": 30102273,
      "name": "Mobile-Security-Framework-MobSF",
      "full_name": "MobSF/Mobile-Security-Framework-MobSF",
      "description": "Mobile Security Framework (MobSF) is an automated, all-in-one mobile application (Android/iOS/Windows) pen-testing, malware analysis and security assessment framework capable of performing static and dynamic analysis.",
      "html_url": "https://github.com/MobSF/Mobile-Security-Framework-MobSF",
      "stars": 20175,
      "forks": 3562,
      "language": "JavaScript",
      "topics": [
        "android-security",
        "api-testing",
        "apk",
        "cwe",
        "devsecops",
        "dynamic-analysis",
        "ios-security",
        "malware-analysis",
        "mastg",
        "masvs",
        "mobile-security",
        "mobsf",
        "mstg",
        "owasp",
        "rest",
        "runtime-security",
        "static-analysis",
        "web-security",
        "windows-mobile-security"
      ],
      "created_at": "2015-01-31T04:36:01Z",
      "updated_at": "2026-01-14T00:51:19Z",
      "pushed_at": "2026-01-13T20:59:31Z",
      "open_issues": 24,
      "owner": {
        "login": "MobSF",
        "avatar_url": "https://avatars.githubusercontent.com/u/25052637?v=4"
      },
      "readme": "# Mobile Security Framework (MobSF)\n\n![](https://cloud.githubusercontent.com/assets/4301109/20019521/cc61f7fc-a2f2-11e6-95f3-407030d9fdde.png)\n\nMobile Security Framework (MobSF) is a security research platform for mobile applications in Android, iOS and Windows Mobile. MobSF can be used for a variety of use cases such as mobile application security, penetration testing, malware analysis, and privacy analysis. The Static Analyzer supports popular mobile app binaries like APK, IPA, APPX and source code. Meanwhile, the Dynamic Analyzer supports both Android and iOS applications and offers a platform for interactive instrumented testing, runtime data and network traffic analysis. MobSF seamlessly integrates with your DevSecOps or CI/CD pipeline, facilitated by REST APIs and CLI tools, enhancing your security workflow with ease.\n\nMade with ![Love](https://cloud.githubusercontent.com/assets/4301109/16754758/82e3a63c-4813-11e6-9430-6015d98aeaab.png) in India\n\n[![Docker Pulls](https://img.shields.io/docker/pulls/opensecurity/mobile-security-framework-mobsf?style=social)](https://hub.docker.com/r/opensecurity/mobile-security-framework-mobsf/) [![python](https://img.shields.io/badge/python-3.12+-blue.svg?logo=python&labelColor=yellow)](https://www.python.org/downloads/)\n[![PyPI version](https://badge.fury.io/py/mobsf.svg)](https://badge.fury.io/py/mobsf)\n[![platform](https://img.shields.io/badge/platform-osx%2Flinux%2Fwindows-green.svg)](https://github.com/MobSF/Mobile-Security-Framework-MobSF/)\n[![License](https://img.shields.io/:license-GPL--3.0--only-blue.svg)](https://www.gnu.org/licenses/gpl-3.0.html)\n[![MobSF tests](https://github.com/MobSF/Mobile-Security-Framework-MobSF/workflows/MobSF%20tests/badge.svg?branch=master)](https://github.com/MobSF/Mobile-Security-Framework-MobSF/actions)\n[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=MobSF_Mobile-Security-Framework-MobSF&metric=alert_status)](https://sonarcloud.io/dashboard?id=MobSF_Mobile-Security-Framework-MobSF)\n![GitHub closed issues](https://img.shields.io/github/issues-closed/MobSF/Mobile-Security-Framework-MobSF)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/6392/badge)](https://bestpractices.coreinfrastructure.org/projects/6392)\n\n\n[![ToolsWatch Best Security Tools 2016](https://img.shields.io/badge/ToolsWatch-Rank%205%20%7C%20Year%202016-red.svg)](http://www.toolswatch.org/2017/02/2016-top-security-tools-as-voted-by-toolswatch-org-readers/)\n[![ToolsWatch Best Security Tools 2017](https://img.shields.io/badge/ToolsWatch-Rank%209%20%7C%20Year%202017-red.svg)](http://www.toolswatch.org/2018/01/black-hat-arsenal-top-10-security-tools/)\n[![Blackhat Arsenal Asia 2015](https://img.shields.io/badge/Black%20Hat%20Arsenal-Asia%202015-blue.svg)](https://www.blackhat.com/asia-15/arsenal.html#yso-mobile-security-framework)\n[![Blackhat Arsenal Asia 2018](https://img.shields.io/badge/Black%20Hat%20Arsenal-Asia%202018-blue.svg)](https://www.blackhat.com/asia-18/arsenal.html#mobile-security-framework-mobsf)\n[![Blackhat Arsenal Europe 2023](https://img.shields.io/badge/Black%20Hat%20Arsenal-Europe%202023-blue.svg)](https://www.blackhat.com/eu-23/arsenal/schedule/index.html#mobile-security-framework---mobsf-35327)\n\n\nMobSF is also bundled with [Android Tamer](https://tamerplatform.com), [BlackArch](https://blackarch.org/mobile.html) and [Pentoo](https://www.pentoo.ch/).\n\n### Support MobSF\n\n[![Donate to MobSF](https://user-images.githubusercontent.com/4301109/117404264-7aab5480-aebe-11eb-9cbd-da82d7346bb3.png)](https://opensecurity.in/donate)\n\n\n> Has MobSF made a difference for you? Show your support and help us innovate with a donation. It's easy to build open source, maintaining one is a different story. \n\n*Long live open source!*\n\n## Documentation\n\nQuick setup with docker\n\n```\ndocker pull opensecurity/mobile-security-framework-mobsf:latest\ndocker run -it --rm -p 8000:8000 opensecurity/mobile-security-framework-mobsf:latest\n\n# Default username and password: mobsf/mobsf\n```\n\n[![See MobSF Documentation](https://user-images.githubusercontent.com/4301109/70686099-3855f780-1c79-11ea-8141-899e39459da2.png)](https://mobsf.github.io/docs)\n\n* Try MobSF Static Analyzer Online: [mobsf.live](https://mobsf.live)\n* MobSF in CI/CD: [mobsfscan](https://github.com/MobSF/mobsfscan)\n* Conference Presentations: [Slides & Videos](https://mobsf.github.io/Mobile-Security-Framework-MobSF/presentations.html)\n* MobSF Online Course: [OpSecX MAS](https://opsecx.com/index.php/product/automated-mobile-application-security-assessment-with-mobsf/)\n* What's New: [See Changelog](https://mobsf.github.io/Mobile-Security-Framework-MobSF/changelog.html)\n\n## Collaborators\n\n[Ajin Abraham](https://in.linkedin.com/in/ajinabraham) ![india](https://user-images.githubusercontent.com/4301109/37564171-6549d678-2ab6-11e8-9b9d-21327c7f5d5b.png)  | [Magaofei](https://github.com/magaofei) ![china](https://user-images.githubusercontent.com/4301109/44515364-00bbe880-a6e0-11e8-944d-5b48a86427da.png) | [Matan Dobrushin](https://github.com/matandobr) ![israel](https://user-images.githubusercontent.com/4301109/37564177-782f1758-2ab6-11e8-91e5-c76bde37b330.png) | [Vincent Nadal](https://github.com/superpoussin22) ![france](https://user-images.githubusercontent.com/4301109/37564175-71d6d92c-2ab6-11e8-89d7-d21f5aa0bda8.png)\n\n## e-Learning Courses & Certifications\n![MobSF Course](https://user-images.githubusercontent.com/4301109/76344880-ad68b580-62d8-11ea-8cde-9e3475fc92f6.png) [Automated Mobile Application Security Assessment with MobSF -MAS](https://opsecx.com/index.php/product/automated-mobile-application-security-assessment-with-mobsf/)\n\n![Android Security Tools Course](https://user-images.githubusercontent.com/4301109/76344939-c709fd00-62d8-11ea-8208-774f1d5a7c52.png) [Android Security Tools Expert -ATX](https://opsecx.com/index.php/product/android-security-tools-expert-atx/)\n\n## MobSF Support\n\n* **Free Support:** Free limited support, questions, help and discussions, join our Slack channel [![Join_MobSF_Slack](https://img.shields.io/badge/mobsf%20slack-join-green?logo=slack&labelColor=4A154B)](https://join.slack.com/t/mobsf/shared_invite/zt-3ephptj6c-OuDMatJ9z9MT0T_Vb~l2pg)\n* **Enterprise Support:** Priority feature requests, live support & onsite training, see [![MobSF Support Packages](https://img.shields.io/badge/enterprise-support%20package-blue?logo=data:image/png;base64,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)](https://opensecurity.in/#support)\n\n\n## Contribution, Feature Requests & Bugs\n\n* Read [CONTRIBUTING.md](https://github.com/MobSF/Mobile-Security-Framework-MobSF/blob/master/.github/CONTRIBUTING.md) before opening bugs, feature requests and pull request.\n* For Project updates and announcements, follow [@ajinabraham](https://twitter.com/ajinabraham) or [@OpenSecurity_IN](https://twitter.com/OpenSecurity_IN).\n* Github Issues are only for tracking bugs and feature requests. Do not post support or help queries there. We have a slack channel for that.\n\n### Static Analysis - Android\n\n![mobsf_android_static_analysis](https://user-images.githubusercontent.com/4301109/95506503-f9b6c980-097d-11eb-803a-f88321e1feb7.gif)\n\n### Static Analysis - iOS\n\n![mobsf_ios_ipa_static_analysis](https://user-images.githubusercontent.com/4301109/95507865-16540100-0980-11eb-9e4d-887668d46969.gif)\n\n### Dynamic Analysis - Android APK\n\n![mobsf_android_dynamic_analysis](https://user-images.githubusercontent.com/4301109/95514697-5e782100-098a-11eb-8390-47bb3822a2d7.gif)\n\n### Web API Viewer\n\n![mobsf_web_api_fuzzing_with_burp](https://user-images.githubusercontent.com/4301109/95516560-69808080-098d-11eb-9e0b-fb5a25e96585.gif)\n\n### Dynamic Analysis - iOS IPA\n\n![mobsf_ios_dynamic_analysis](https://github.com/MobSF/Mobile-Security-Framework-MobSF/assets/4301109/34014c4d-1535-48ad-9944-a4b1b728a030)\n\n## Past Collaborators\n\n* [Dominik Schlecht](https://github.com/sn0b4ll) ![germany](https://user-images.githubusercontent.com/4301109/37564176-743238ba-2ab6-11e8-9666-5d98f0a1d127.png)\n\n## Honorable Contributors & Shoutouts\n\n* Amrutha VC - For the new MobSF logo\n* Dominik Schlecht - For the awesome work on adding Windows Phone App Static Analysis to MobSF\n* Esteban - Better Android Manifest Analysis and Static Analysis Improvement.\n* Matan Dobrushin - For adding Android ARM Emulator support to MobSF - Special thanks goes for cuckoo-droid\n* Shuxin - Android Binary Analysis\n* Abhinav Saxena - (@xandfury) - For Travis CI and Logging integration\n* ![netguru](https://user-images.githubusercontent.com/4301109/76340877-a3dc4f00-62d2-11ea-8631-b4cc8d9e42ed.png) [Netguru](https://www.netguru.com/) (@karolpiateknet, @mtbrzeski) - For iOS Swift support, Rule contributions and SAST refactoring.\n* Maxime Fawe - (@Arenash13) - For Matching Strategy implementation of SAST pattern matching algorithms.\n* Abhinav Sejpal (@Abhinav_Sejpal) - For poking me with bugs, feature requests, and UI & UX suggestions\n* Anant Srivastava (@anantshri) - For Activity Tester Idea\n* Anto Joseph (@antojoseph) - For the help with SuperSU\n* Bharadwaj Machiraju (@tunnelshade) - For writing pyWebProxy from scratch\n* Rahul (@c0dist) - Kali Support\n* MindMac - For writing Android Blue Pill\n* Oscar Alfonso Diaz - (@OscarAkaElvis) - For Dockerfile contributions\n* Thomas Abraham - For JS Hacks on UI\n* Tim Brown (@timb_machine) - For the iOS Binary Analysis Ruleset\n* Shanil Prasad (@Rajuraju14) - For improving iOS ATS Analysis\n* Jovan Petrovic (@JovanPetrovic) - For sponsoring a server to host mobsf.live\n",
      "stars_today": 6
    },
    {
      "id": 104231541,
      "name": "abseil-cpp",
      "full_name": "abseil/abseil-cpp",
      "description": "Abseil Common Libraries (C++)",
      "html_url": "https://github.com/abseil/abseil-cpp",
      "stars": 16907,
      "forks": 2947,
      "language": "C++",
      "topics": [],
      "created_at": "2017-09-20T15:10:30Z",
      "updated_at": "2026-01-13T18:19:18Z",
      "pushed_at": "2026-01-13T18:19:12Z",
      "open_issues": 212,
      "owner": {
        "login": "abseil",
        "avatar_url": "https://avatars.githubusercontent.com/u/26718316?v=4"
      },
      "readme": "# Abseil - C++ Common Libraries\n\nThe repository contains the Abseil C++ library code. Abseil is an open-source\ncollection of C++ code (compliant to C++17) designed to augment the C++\nstandard library.\n\n## Table of Contents\n\n- [About Abseil](#about)\n- [Quickstart](#quickstart)\n- [Building Abseil](#build)\n- [Support](#support)\n- [Codemap](#codemap)\n- [Releases](#releases)\n- [License](#license)\n- [Links](#links)\n\n<a name=\"about\"></a>\n## About Abseil\n\nAbseil is an open-source collection of C++ library code designed to augment\nthe C++ standard library. The Abseil library code is collected from Google's\nown C++ code base, has been extensively tested and used in production, and\nis the same code we depend on in our daily coding lives.\n\nIn some cases, Abseil provides pieces missing from the C++ standard; in\nothers, Abseil provides alternatives to the standard for special needs\nwe've found through usage in the Google code base. We denote those cases\nclearly within the library code we provide you.\n\nAbseil is not meant to be a competitor to the standard library; we've\njust found that many of these utilities serve a purpose within our code\nbase, and we now want to provide those resources to the C++ community as\na whole.\n\n<a name=\"quickstart\"></a>\n## Quickstart\n\nIf you want to just get started, make sure you at least run through the\n[Abseil Quickstart](https://abseil.io/docs/cpp/quickstart). The Quickstart\ncontains information about setting up your development environment, downloading\nthe Abseil code, running tests, and getting a simple binary working.\n\n<a name=\"build\"></a>\n## Building Abseil\n\n[Bazel](https://bazel.build) and [CMake](https://cmake.org/) are the official\nbuild systems for Abseil.\nSee the [quickstart](https://abseil.io/docs/cpp/quickstart) for more information\non building Abseil using the Bazel build system.\nIf you require CMake support, please check the [CMake build\ninstructions](CMake/README.md) and [CMake\nQuickstart](https://abseil.io/docs/cpp/quickstart-cmake).\n\n<a name=\"support\"></a>\n## Support\n\nAbseil follows Google's [Foundational C++ Support\nPolicy](https://opensource.google/documentation/policies/cplusplus-support). See\n[this\ntable](https://github.com/google/oss-policies-info/blob/main/foundational-cxx-support-matrix.md)\nfor a list of currently supported versions compilers, platforms, and build\ntools.\n\n<a name=\"codemap\"></a>\n## Codemap\n\nAbseil contains the following C++ library components:\n\n* [`base`](absl/base/)\n  <br /> The `base` library contains initialization code and other code which\n  all other Abseil code depends on. Code within `base` may not depend on any\n  other code (other than the C++ standard library).\n* [`algorithm`](absl/algorithm/)\n  <br /> The `algorithm` library contains additions to the C++ `<algorithm>`\n  library and container-based versions of such algorithms.\n* [`cleanup`](absl/cleanup/)\n  <br /> The `cleanup` library contains the control-flow-construct-like type\n  `absl::Cleanup` which is used for executing a callback on scope exit.\n* [`container`](absl/container/)\n  <br /> The `container` library contains additional STL-style containers,\n  including Abseil's unordered \"Swiss table\" containers.\n* [`crc`](absl/crc/) The `crc` library contains code for\n  computing error-detecting cyclic redundancy checks on data.\n* [`debugging`](absl/debugging/)\n  <br /> The `debugging` library contains code useful for enabling leak\n  checks, and stacktrace and symbolization utilities.\n* [`flags`](absl/flags/)\n  <br /> The `flags` library contains code for handling command line flags for\n  libraries and binaries built with Abseil.\n* [`hash`](absl/hash/)\n  <br /> The `hash` library contains the hashing framework and default hash\n  functor implementations for hashable types in Abseil.\n* [`log`](absl/log/)\n  <br /> The `log` library contains `LOG` and `CHECK` macros and facilities\n  for writing logged messages out to disk, `stderr`, or user-extensible\n  destinations.\n* [`memory`](absl/memory/)\n  <br /> The `memory` library contains memory management facilities that augment\n  C++'s `<memory>` library.\n* [`meta`](absl/meta/)\n  <br /> The `meta` library contains type checks\n  similar to those available in the C++ `<type_traits>` library.\n* [`numeric`](absl/numeric/)\n  <br /> The `numeric` library contains 128-bit integer types as well as\n  implementations of C++20's bitwise math functions.\n* [`profiling`](absl/profiling/)\n  <br /> The `profiling` library contains utility code for profiling C++\n  entities.  It is currently a private dependency of other Abseil libraries.\n* [`random`](absl/random/)\n  <br /> The `random` library contains functions for generating pseudorandom\n  values.\n* [`status`](absl/status/)\n  <br /> The `status` library contains abstractions for error handling,\n  specifically `absl::Status` and `absl::StatusOr<T>`.\n* [`strings`](absl/strings/)\n  <br /> The `strings` library contains a variety of strings routines and\n  utilities.\n* [`synchronization`](absl/synchronization/)\n  <br /> The `synchronization` library contains concurrency primitives (Abseil's\n  `absl::Mutex` class, an alternative to `std::mutex`) and a variety of\n  synchronization abstractions.\n* [`time`](absl/time/)\n  <br /> The `time` library contains abstractions for computing with absolute\n  points in time, durations of time, and formatting and parsing time within\n  time zones.\n* [`types`](absl/types/)\n  <br /> The `types` library contains non-container utility types.\n* [`utility`](absl/utility/)\n  <br /> The `utility` library contains utility and helper code.\n\n<a name=\"releases\"></a>\n## Releases\n\nAbseil recommends users \"live-at-head\" (update to the latest commit from the\nmaster branch as often as possible). However, we realize this philosophy doesn't\nwork for every project, so we also provide [Long Term Support\nReleases](https://github.com/abseil/abseil-cpp/releases) to which we backport\nfixes for severe bugs. See our [release\nmanagement](https://abseil.io/about/releases) document for more details.\n\n<a name=\"license\"></a>\n## License\n\nThe Abseil C++ library is licensed under the terms of the Apache\nlicense. See [LICENSE](LICENSE) for more information.\n\n<a name=\"links\"></a>\n## Links\n\nFor more information about Abseil:\n\n* Consult our [Abseil Introduction](https://abseil.io/about/intro)\n* Read [Why Adopt Abseil](https://abseil.io/about/philosophy) to understand our\n  design philosophy.\n* Peruse our\n  [Abseil Compatibility Guarantees](https://abseil.io/about/compatibility) to\n  understand both what we promise to you, and what we expect of you in return.\n",
      "stars_today": 6
    },
    {
      "id": 334274271,
      "name": "OpenSearch",
      "full_name": "opensearch-project/OpenSearch",
      "description": "üîé Open source distributed and RESTful search engine.",
      "html_url": "https://github.com/opensearch-project/OpenSearch",
      "stars": 12198,
      "forks": 2369,
      "language": "Java",
      "topics": [
        "analytics",
        "apache2",
        "foss",
        "java",
        "search",
        "search-engine"
      ],
      "created_at": "2021-01-29T22:10:00Z",
      "updated_at": "2026-01-14T00:39:46Z",
      "pushed_at": "2026-01-13T18:27:56Z",
      "open_issues": 2528,
      "owner": {
        "login": "opensearch-project",
        "avatar_url": "https://avatars.githubusercontent.com/u/80134844?v=4"
      },
      "readme": "<a href=\"https://opensearch.org/\">\n  <img src=\"https://opensearch.org/assets/img/opensearch-logo-themed.svg\" height=\"64px\">\n</a>\n\n[![License](https://img.shields.io/badge/license-Apache%20v2-blue.svg)](https://github.com/opensearch-project/OpenSearch/blob/main/LICENSE.txt)\n[![LFX Health Score](https://insights.linuxfoundation.org/api/badge/health-score?project=opensearch-foundation)](https://insights.linuxfoundation.org/project/opensearch-foundation)\n[![LFX Active Contributors](https://insights.linuxfoundation.org/api/badge/active-contributors?project=opensearch-foundation)](https://insights.linuxfoundation.org/project/opensearch-foundation)\n[![Code Coverage](https://codecov.io/gh/opensearch-project/OpenSearch/branch/main/graph/badge.svg)](https://codecov.io/gh/opensearch-project/OpenSearch)\n![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/opensearch-project/OpenSearch?sort=semver)\n[![Linkedin](https://img.shields.io/badge/Follow-Linkedin-blue)](https://www.linkedin.com/company/opensearch-project)\n\n- [Welcome!](#welcome)\n- [Project Resources](#project-resources)\n- [Code of Conduct](#code-of-conduct)\n- [Security](#security)\n- [License](#license)\n- [Copyright](#copyright)\n- [Trademark](#trademark)\n\n## Welcome!\n\nOpenSearch is an open-source, enterprise-grade search and observability suite that brings order to unstructured data at scale.\n\n## Project Resources\n\n* [Project Website](https://opensearch.org/)\n* [Downloads](https://opensearch.org/downloads/)\n* [Documentation](https://docs.opensearch.org/)\n* Need help? Try [Forums](https://discuss.opendistrocommunity.dev/) or [Slack](https://opensearch.org/slack/)\n* [Contributing to OpenSearch](CONTRIBUTING.md)\n* [Maintainer Responsibilities](MAINTAINERS.md)\n* [Release Management](RELEASING.md)\n* [Admin Responsibilities](ADMINS.md)\n* [Testing](TESTING.md)\n* [Security](SECURITY.md)\n\n## Code of Conduct\n\nThe project's [Code of Conduct](CODE_OF_CONDUCT.md) outlines our expectations for all participants in our community, based on the [OpenSearch Code of Conduct](https://opensearch.org/code-of-conduct/). Please contact [conduct@opensearch.foundation](mailto:conduct@opensearch.foundation) with any additional questions or comments.\n\n## Security\nIf you discover a potential security issue in this project we ask that you notify OpenSearch Security directly via email to security@opensearch.org. Please do **not** create a public GitHub issue.\n\n## License\n\nThis project is licensed under the [Apache v2.0 License](LICENSE.txt).\n\n## Copyright\n\nCopyright OpenSearch Contributors. See [NOTICE](NOTICE.txt) for details.\n\n## Trademark\n\nOpenSearch is a registered trademark of LF Projects, LLC.\n\nOpenSearch includes certain Apache-licensed Elasticsearch code from Elasticsearch B.V. and other source code. Elasticsearch B.V. is not the source of that other source code. ELASTICSEARCH is a registered trademark of Elasticsearch B.V.\n\n",
      "stars_today": 6
    },
    {
      "id": 592882602,
      "name": "Loop",
      "full_name": "MrKai77/Loop",
      "description": "Window management made elegant.",
      "html_url": "https://github.com/MrKai77/Loop",
      "stars": 9886,
      "forks": 211,
      "language": "Swift",
      "topics": [
        "hacktoberfest",
        "macos",
        "macos-app",
        "menu",
        "productivity",
        "radial-menu",
        "swift",
        "swiftui",
        "window-management"
      ],
      "created_at": "2023-01-24T18:33:33Z",
      "updated_at": "2026-01-13T23:40:03Z",
      "pushed_at": "2026-01-13T20:38:26Z",
      "open_issues": 45,
      "owner": {
        "login": "MrKai77",
        "avatar_url": "https://avatars.githubusercontent.com/u/68963405?v=4"
      },
      "readme": "<div align=\"center\">\n  <img width=\"225\" height=\"225\" src=\"/assets/graphics/Classic.png\" alt=\"Logo\">\n  <h1><b>Loop</b></h1>\n  <p>Window management made elegant.<br>\n  <a href=\"https://github.com/MrKai77/Loop#features\"><strong>Explore Loop ¬ª</strong></a><br><br>\n  <a href=\"https://github.com/MrKai77/Loop/releases/latest/download/Loop.zip\">Download for macOS</a><br>\n  <i>~ Compatible with macOS 13 and later. ~</i></p>\n</div>\n\nLoop is a macOS app that simplifies window management for you. You can effortlessly choose your window direction using a radial menu triggered by a simple key press, and customize it according to your preferences with personalized colors and settings. You can easily move, resize, and arrange your windows with just a few clicks, saving you valuable time and energy.\n\n> [!NOTE]\n>\n> Loop is constantly evolving, with new features and improvements added regularly to enhance your window management experience on macOS.\n\n<h6 align=\"center\">\n  <img src=\"assets/graphics/loop_demo.gif\" alt=\"Loop Demo\">\n  <br /><br />\n  <a href=\"https://discord.gg/2CZ2N6PKjq\">\n    <img src=\"https://img.shields.io/badge/Discord-join%20us-7289DA?logo=discord&logoColor=white&style=for-the-badge&labelColor=23272A\" />\n  </a>\n  <a href=\"https://github.com/MrKai77/Loop/blob/main/LICENSE\">\n    <img src=\"https://img.shields.io/github/license/MrKai77/Loop?label=License&color=5865F2&style=for-the-badge&labelColor=23272A\" />\n  </a>\n  <a href=\"https://github.com/MrKai77/Loop/stargazers\">\n    <img src=\"https://img.shields.io/github/stars/MrKai77/Loop?label=Stars&color=57F287&style=for-the-badge&labelColor=23272A\" />\n  </a>\n  <a href=\"https://github.com/MrKai77/Loop/network/members\">\n    <img src=\"https://img.shields.io/github/forks/MrKai77/Loop?label=Forks&color=ED4245&style=for-the-badge&labelColor=23272A\" />\n  </a>\n  <a href=\"https://github.com/MrKai77/Loop/issues\">\n    <img src=\"https://img.shields.io/github/issues/MrKai77/Loop?label=Issues&color=FEE75C&style=for-the-badge&labelColor=23272A\" />\n  </a>\n  <br />\n</h6>\n\n## Features\n\n### Radial Menu\n\nThe Radial Menu allows you to manipulate windows using your mouse/trackpad. Hold down the trigger key and move your cursor in the desired direction to move and resize the window.\n\n<div><video controls src=\"https://github.com/user-attachments/assets/658f7043-79a1-4690-83b6-a714fe6245c8\" muted=\"false\"></video></div>\n\n### Preview\n\nThe preview window enables you to see the resize action *before* committing to it.\n\n<div><video controls src=\"https://github.com/user-attachments/assets/5ecb3ae8-f295-406f-b968-31e539f4a098\" muted=\"false\"></video></div>\n\n### Keyboard Shortcuts\n\nLoop allows you to assign any key in tandem with the trigger key to initiate a window manipulation action.\n\n<div><video controls src=\"https://github.com/user-attachments/assets/d865329f-0533-4eeb-829d-9aa6159f454b\" muted=\"false\"></video></div>\n\n### Cycles\n\nLoop can become very powerful when paired with cycles. These enable you to perform multiple window manipulations in quick succession by pressing the same key combination repeatedly, or by left-clicking repeatedly!\n\n<div><video controls src=\"https://github.com/user-attachments/assets/1adb1325-775d-4687-9085-71c7f775d65d\" muted=\"false\"></video></div>\n\n### Stash\n\nHide windows at the screen edge to declutter your workspace. Hover near the edge or use a keybind to access them whenever you need.\n\n<div><video controls src=\"https://github.com/user-attachments/assets/080ba2fb-41b3-4b39-9000-a76f2fc794ed\" muted=\"false\"></video></div>\n\n### Theming\n\n#### Radial Menu\n\nThe radial menu is fully customizable in terms of width, shape, and color. It is also completely optional and can be disabled. Both the cursor interaction and the radial menu itself are independently toggleable.\n\n<div><video controls src=\"https://github.com/user-attachments/assets/b2d3f6c8-dd68-4ac2-a30a-19f36a8fd94d\" muted=\"false\"></video></div>\n\n#### Preview\n\nAdjust the padding, corner radius, border color, and border width of the optional preview window.\n\n<div><video controls src=\"https://github.com/user-attachments/assets/fc107861-8125-42c2-b987-2fff554078d5\" muted=\"false\"></video></div>\n\n## Usage\n\n### Installation\n\n#### Homebrew\n\n```bash\nbrew install loop\n```\n\n#### Manual Download\n\nNavigate to the [release page](https://github.com/MrKai77/Loop/releases/latest) and download the latest `.zip` file located at the bottom, or [click me](https://github.com/MrKai77/Loop/releases/latest/download/Loop.zip).\n\n### Triggering\n\nLoop uses a trigger key to function. This key must be held down or pressed to activate certain features within Loop. To access the radial menu, hold down the trigger key and move the cursor in the desired direction. Users who prefer keyboard shortcuts can assign a key to work with the trigger key, activating specific actions. The trigger key can be set in the \"Behavior\" tab of the \"Settings\" section. The trigger key can consist of one or multiple keys.\n\nTo set Caps Lock as your trigger key, you have two options:\n\n#### a. Change System Settings\n\n1. Go to System Settings ‚Üí Keyboard ‚Üí \"Keyboard Shortcuts...\".\n2. In the \"Modifier Keys\" tab, remap `Caps Lock (‚á™) key` to `(^) Control`.\n3. Repeat this remapping process for every connected keyboard.\n4. In Loop, select the `Right Control` key as your trigger.\n\n#### b. Use an external App\n\n- [Hyperkey](https://hyperkey.app/)\n- [Karabiner Elements](https://karabiner-elements.pqrs.org/)\n\n#### c. Shell/AppleScript\n\nLoop can be controlled via shell commands or AppleScript using its URL scheme:\n\n```bash\n# Shell examples\nopen \"loop://direction/right\"     # Move window to right half\nopen \"loop://action/maximize\"     # Maximize window\nopen \"loop://screen/next\"         # Move to next screen\n\n# AppleScript examples\nosascript -e 'tell application \"Loop\" to activate'\nosascript -e 'open location \"loop://direction/left\"'\n```\n\nYou can also create custom scripts to chain multiple actions:\n\n```bash\n#!/bin/bash\n# Example: Move window right and then maximize\nopen \"loop://direction/right\"\nsleep 0.5\nopen \"loop://action/maximize\"\n```\n\nFor a complete list of available commands:\n\n```bash\nopen \"loop://list/all\"           # List all commands\nopen \"loop://list/actions\"       # List window actions\nopen \"loop://list/keybinds\"      # List custom keybinds\n```\n\n### Keyboard Shortcuts\n\n<table>\n  <thead>\n    <tr>\n      <th>Category</th>\n      <th>Actions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td><strong>General</strong></td>\n      <td>Fullscreen, Maximize, Almost Maximize, Centre, MacOS Centre, Minimize, Hide</td>\n    </tr>\n    <tr>\n      <td><strong>Halves</strong></td>\n      <td>Top Half, Bottom Half, Left Half, Right Half</td>\n    </tr>\n    <tr>\n      <td><strong>Quarters</strong></td>\n      <td>Top Left Quarter, Top Right Quarter, Bottom Left Quarter, Bottom Right Quarter</td>\n    </tr>\n    <tr>\n      <td><strong>Horizontal Thirds</strong></td>\n      <td>Right Third, Right Two Thirds, Horizontal Center Third, Left Two Thirds, Left Third</td>\n    </tr>\n    <tr>\n      <td><strong>Vertical Thirds</strong></td>\n      <td>Top Third, Top Two Thirds, Vertical Center Third, Bottom Two Thirds, Bottom Third</td>\n    </tr>\n    <tr>\n      <td><strong>Screen Switching</strong></td>\n      <td>Next Screen, Previous Screen, Left Screen, Right Screen, Top Screen, Bottom Screen</td>\n    </tr>\n    <tr>\n      <td><strong>Window Manipulation</strong></td>\n      <td>Larger, Smaller, Shrink Top, Shrink Bottom, Shrink Right, Shrink Left, Grow Top, Grow Bottom, Grow Right, Grow Left, Move Up, Move Down, Move Right, Move Left</td>\n    </tr>\n    <tr>\n      <td><strong>More</strong></td>\n      <td>Initial Frame, Undo, Custom, Cycle</td>\n    </tr>\n  </tbody>\n</table>\n\n## Contributors\n\nTo see all the contributors who have played a significant role in developing Loop, visit our [Contributors](CONTRIBUTORS.md) page.\n\n### How to Contribute\n\nFor an extensive guide on how to contribute, check out the [contributing guide](CONTRIBUTING.md).\n\n## FAQ\n\n### Comparison\n\n<table>\n  <thead>\n    <tr>\n      <th></th>\n      <th>Loop</th>\n      <th>macOS&nbsp;15+</th>\n      <th>Rectangle&nbsp;Pro</th>\n      <th>Rectangle</th>\n      <th>Magnet</th>\n      <th>Moom</th>\n      <th>Swish</th>\n      <th>BetterTouchTool</th>\n      <th>Multitouch</th>\n      <th>Hammerspoon</th>\n      <th>Yabai</th>\n      <th>Amethyst</th>\n      <th>AeroSpace</th>\n      <th>1Piece</th>\n      <th>Wins</th>\n      <th>MacsyZones</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Price</td>\n      <td>Free</td>\n      <td>Free</td>\n      <td>$9.99</td>\n      <td>Free</td>\n      <td>$4.99</td>\n      <td>$15.00</td>\n      <td>$16.00</td>\n      <td>$14.00</td>\n      <td>$15.99</td>\n      <td>Free</td>\n      <td>Free</td>\n      <td>Free</td>\n      <td>Free</td>\n      <td>Free</td>\n      <td>$13.99</td>\n      <td>Free</td>\n    </tr>\n    <tr>\n      <td>Open&nbsp;Source</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n    </tr>\n    <tr>\n      <td>Custom&nbsp;Frames</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n    </tr>\n    <tr>\n      <td>Preview&nbsp;Window</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n    </tr>\n    <tr>\n      <td>Theming&nbsp;Options</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n    </tr>\n    <tr>\n      <td>Modifier&nbsp;+&nbsp;Mouse</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n    </tr>\n    <tr>\n      <td>Modifier&nbsp;+&nbsp;Arrows</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n    </tr>\n    <tr>\n      <td>Modifier&nbsp;+&nbsp;Trackpad</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n    </tr>\n    <tr>\n      <td>Trackpad&nbsp;Gestures</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n    </tr>\n    <tr>\n      <td>Padding&nbsp;/&nbsp;Margins</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n    </tr>\n    <tr>\n      <td>Stashed&nbsp;Windows</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n    </tr>\n    <tr>\n      <td>Save&nbsp;Workspace</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n    </tr>\n    <tr>\n      <td>Restore&nbsp;Initial&nbsp;Frame</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n    </tr>\n    <tr>\n      <td>Pin&nbsp;Windows&nbsp;On&nbsp;Top</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n    </tr>\n    <tr>\n      <td>Snap&nbsp;Windows&nbsp;via&nbsp;Drag</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n    </tr>\n    <tr>\n      <td>Resize&nbsp;Adjacent&nbsp;Windows</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n    </tr>\n    <tr>\n      <td>Action&nbsp;Sequences&nbsp;(Cycles)</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n    </tr>\n    <tr>\n      <td>Move&nbsp;Windows&nbsp;Across&nbsp;Screens</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n    </tr>\n    <tr>\n      <td>Switch&nbsp;Focus&nbsp;Between&nbsp;Windows</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n    </tr>\n    <tr>\n      <td>Scripting&nbsp;(URL&nbsp;/&nbsp;AppleScript&nbsp;or&nbsp;other)</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚úÖ</td>\n      <td>‚úÖ</td>\n      <td>‚ùå</td>\n      <td>‚ùå</td>\n    </tr>\n  </tbody>\n</table>\n\n> Information was gathered from each app‚Äôs official website and other online sources and may be outdated.\n> If you notice any inaccuracies, please open an issue or contact the maintainers.\n> Special thanks to the [Definitive MacApp Comparisons](https://docs.google.com/spreadsheets/d/1HtJN4oQ6oBDFmFaF4Qeq5vCGEU1g-KB1DEz5Sp_OwXo/edit?gid=456166567#gid=456166567) spreadsheet.\n\n### License\n\nThis project is licensed under the [GNU GPLv3 license](LICENSE).\n",
      "stars_today": 6
    },
    {
      "id": 47726042,
      "name": "WiFiAnalyzer",
      "full_name": "VREMSoftwareDevelopment/WiFiAnalyzer",
      "description": "Android application to analyze Wi-Fi signals.",
      "html_url": "https://github.com/VREMSoftwareDevelopment/WiFiAnalyzer",
      "stars": 4512,
      "forks": 711,
      "language": "Kotlin",
      "topics": [
        "android",
        "gplv3",
        "wifi-analyzer",
        "wifi-network"
      ],
      "created_at": "2015-12-09T23:37:23Z",
      "updated_at": "2026-01-13T19:20:22Z",
      "pushed_at": "2026-01-10T17:27:32Z",
      "open_issues": 5,
      "owner": {
        "login": "VREMSoftwareDevelopment",
        "avatar_url": "https://avatars.githubusercontent.com/u/6217364?v=4"
      },
      "readme": "<h1>WiFiAnalyzer <img src=\"images/icon.png\" alt=\"Application Icon\" width=\"45\" height=\"45\"></h1>\n\n[<img src=\"https://play.google.com/intl/en_us/badges/images/generic/en_badge_web_generic.png\" alt=\"Get it on Google Play\" height=\"80\">](https://play.google.com/store/apps/details?id=com.vrem.wifianalyzer)\n[<img src=\"https://f-droid.org/badge/get-it-on.png\" alt=\"Get it on F-Droid\" height=\"80\">](https://f-droid.org/repository/browse/?fdid=com.vrem.wifianalyzer)\n[<img src=\"https://raw.githubusercontent.com/andOTP/andOTP/master/assets/badges/get-it-on-github.png\" alt=\"Get it on GitHub\" height=\"80\">](https://github.com/VREMSoftwareDevelopment/WiFiAnalyzer/releases/latest)\n\nThis is the official repository of WiFiAnalyzer.\n\n<img src=\"images/feature-graphic.png\" alt=\"Feature Graphic - Dark Theme\" height=\"200\">\n<img src=\"images/feature-graphic-light.png\" alt=\"Feature Graphic - Light Theme\" height=\"200\">\n\n## Table of Contents\n\n- [Features](#features)\n- [Documentation](#documentation)\n- [How-to](#how-to)\n- [FAQ](#faq)\n- [Feedback](#feedback)\n- [License](#license)\n- [Privacy policy](#privacy-policy)\n- [WiFiAnalyzer Build](#wifianalyzer-build)\n- [Contribute](#contribute)\n- [Translation](#translation)\n\n## Features\n\n* Identify nearby Access Points\n* Graph channels signal strength\n* Graph Access Point signal strength over time\n* Analyze Wi-Fi networks to rate channels\n* HT/VHT Detection - 40/80/160/320 MHz (Requires hardware/software support)\n* 2.4 GHz, 5 GHz and 6 GHz Wi-Fi bands (Requires hardware/software support)\n* Access Point view: complete or compact\n* Estimated Distance to the Access Points\n* Export access points details\n* Dark, Light and System theme available\n* Pause/Resume scanning\n* Available filters: Wi-Fi band, Signal strength, Security and SSID\n* Vendor/OUI Database Lookup\n* The application has too many features to mention them all\n\n**Please note WiFiAnalyzer is not a Wi-Fi password cracking or phishing tool.**\n\n## Documentation\n\nThe complete guide to using WiFiAnalyzer can be found in the [User Manual](USER_MANUAL.md). For quick access to specific topics, see:\n\n## How-to\n\n* [How to video](https://youtu.be/JJVKja0VDR0)\n* [How to find the best 5 GHz Wi-Fi Channel](https://www.maketecheasier.com/best-wifi-channel-for-5ghz-frequency/)\n* [Understand Wi-Fi 4/5/6/6E/7 (802.11 n/ac/ax/be) - Make educated wireless router/AP upgrade decisions](https://www.duckware.com/tech/wifi-in-the-us.html)\n* [Why Wi-Fi stinks and how to fix it](http://spectrum.ieee.org/telecom/wireless/why-wifi-stinksand-how-to-fix-it)\n* [Wi-Fi channels list](https://en.wikipedia.org/wiki/List_of_WLAN_channels)\n* [How is distance calculated to Access Point](https://en.wikipedia.org/wiki/Free-space_path_loss)\n\n## FAQ\n\n* [Android Wi-Fi scanning throttling](https://github.com/VREMSoftwareDevelopment/WiFiAnalyzer/wiki/Android-Wi%E2%80%90Fi-scanning-throttling)\n* [Location Service Permission Requirements](https://github.com/VREMSoftwareDevelopment/WiFiAnalyzer/wiki/Location-Service-Permission-Requirements)\n* [WiFiAnalyzer on secondary user accounts](https://github.com/VREMSoftwareDevelopment/WiFiAnalyzer/wiki/WiFiAnalyzer-on-secondary-user-accounts)\n* [How does the channel graph display...](https://github.com/VREMSoftwareDevelopment/WiFiAnalyzer/issues/64)\n* [How to use SSID filter?](https://github.com/VREMSoftwareDevelopment/WiFiAnalyzer/issues/125)\n* [WiFiAnalyzer equivalent on iOS](https://github.com/VREMSoftwareDevelopment/WiFiAnalyzer/issues/69)\n\n## Feedback\n\n* Bug reports can be submitted [here](https://github.com/VREMSoftwareDevelopment/WiFiAnalyzer/issues).\n* To learn how to submit a bug [click here](https://github.com/VREMSoftwareDevelopment/WiFiAnalyzer/wiki/Feedback).\n* [Discussions](https://github.com/VREMSoftwareDevelopment/WiFiAnalyzer/discussions)\n\n## License\n\n[<img src=\"https://www.gnu.org/graphics/gplv3-127x51.png\" alt=\"GPLv3\" >](http://www.gnu.org/licenses/gpl-3.0.html)\n\nWiFiAnalyzer is licensed under the GNU General Public License v3.0 (GPLv3).\n\n### GPLv3 License key requirements:\n\n* Disclose Source\n* License and Copyright Notice\n* Same License\n* State Changes\n\n[GNU General Public License v3.0 (GPLv3) Explained in Plain English](https://tldrlegal.com/license/gnu-general-public-license-v3-(gpl-3))\n\n[GNU General Public License v3.0 (GPLv3)](http://www.gnu.org/licenses/gpl-3.0.html).\n\n## Privacy policy\n\n* WiFiAnalyzer does not collect any personal/device information.\n* WiFiAnalyzer is designed to use as few permissions as possible. It asks for just enough to perform the analysis.\n* Plus, it is all open source so nothing is hidden!\n* Most notably, this application does not require access to the internet, so you can be sure it does not send any personal/device information to any other source and it does not receive any information from other sources.\n\n## WiFiAnalyzer Build\n\n[![Workflow Status](https://github.com/VREMSoftwareDevelopment/WiFiAnalyzer/workflows/Android%20CI/badge.svg)](https://github.com/VREMSoftwareDevelopment/WiFiAnalyzer/actions?query=workflow%3A%22Android+CI%22)\n[![Workflow Status](https://github.com/VREMSoftwareDevelopment/WiFiAnalyzer/workflows/Android%20Emulator%20Tests/badge.svg)](https://github.com/VREMSoftwareDevelopment/WiFiAnalyzer/actions?query=workflow%3A%22Android+Emulator+Tests%22)\n[![Workflow Status](https://github.com/VREMSoftwareDevelopment/WiFiAnalyzer/workflows/CodeQL%20Analyze/badge.svg)](https://github.com/VREMSoftwareDevelopment/WiFiAnalyzer/actions?query=workflow%3A%22CodeQL+Analyze%22)\n\n[![Codacy Badge](https://app.codacy.com/project/badge/Grade/203eaa0583694bcca6554190513179ba)](https://app.codacy.com/gh/VREMSoftwareDevelopment/WiFiAnalyzer/dashboard?utm_source=gh&utm_medium=referral&utm_content=&utm_campaign=Badge_grade)\n[![codecov](https://codecov.io/gh/VREMSoftwareDevelopment/WiFiAnalyzer/branch/main/graph/badge.svg)](https://codecov.io/gh/VREMSoftwareDevelopment/WiFiAnalyzer)\n\n[![Translation status](https://hosted.weblate.org/widget/wifianalyzer/language-badge.svg)](https://hosted.weblate.org/engage/wifianalyzer/)\n[![Translation status](https://hosted.weblate.org/widget/wifianalyzer/svg-badge.svg)](https://hosted.weblate.org/engage/wifianalyzer/)\n\n[![Known Vulnerabilities](https://snyk.io/test/github/vremsoftwaredevelopment/wifianalyzer/badge.svg)](https://snyk.io/test/github/vremsoftwaredevelopment/wifianalyzer)\n[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bgithub.com%2FVREMSoftwareDevelopment%2FWiFiAnalyzer.svg?type=shield)](https://app.fossa.io/projects/git%2Bgithub.com%2FVREMSoftwareDevelopment%2FWiFiAnalyzer?ref=badge_shield)\n\n[![Issues](https://img.shields.io/github/issues/VREMSoftwareDevelopment/WiFiAnalyzer.svg)](https://github.com/VREMSoftwareDevelopment/WiFiAnalyzer/issues)\n[![Star](https://img.shields.io/github/stars/VREMSoftwareDevelopment/WiFiAnalyzer.svg)](https://github.com/VREMSoftwareDevelopment/WiFiAnalyzer/stargazers)\n[![Fork](https://img.shields.io/github/forks/VREMSoftwareDevelopment/WiFiAnalyzer.svg)](https://github.com/VREMSoftwareDevelopment/WiFiAnalyzer/network)\n\n## Contribute\n\n* Want to contribute? Check out our [CONTRIBUTING.md](CONTRIBUTING.md) to see how you can help.\n* We want to express our gratitude to all [contributors](https://github.com/VREMSoftwareDevelopment/WiFiAnalyzer/graphs/contributors) for their contributions, such as patches, bug fixes, updates, and more.\n* If you would like to contribute financially to the project, please feel free to send any amount through PayPal.\n    * [![](https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=62PA6HJ3BZL3E)\n    * Thanks to everyone who has already donated!\n\n## Build project\n\n1. Install Android Studio\n2. Import the project into Android Studio\n    * In the Welcome to Android Studio screen, select \"Import project ...\"\n    * Select the root directory of the WiFiAnalyzer repository and click \"OK\".\n    * WiFiAnalyzer will build automatically.\n\n## Running various Gradle commands\n\n### Check Kotlin code style\n`./gradlew ktlintCheck`\n\n### Apply Kotlin code style\n`./gradlew ktlintFormat`\n\n### Run lint analysis\n`./gradlew lintDebug`\n\nThis command generates the following report:\n- Lint report: `app/build/reports/lint-results.html`\n\n### Run unit tests\n`./gradlew testDebugUnitTest`\n\nThis command generates the following report:\n- Unit test report: `app/build/reports/tests/testDebugUnitTest/index.html`\n\n### Run unit tests with coverage\n`./gradlew jacocoTestCoverageVerification`\n\nThis command generates the following report:\n- Code coverage report: `app/build/reports/jacoco/jacocoTestReport/html/index.html`\n\n### Run instrumented tests\n`./gradlew connectedDebugAndroidTest`\n\nThis command generates the following report:\n- Instrumented test report: `app/build/reports/androidTests/connected/debug/index.html`\n\n## Continuous Integration\n\nThis project uses GitHub Actions for CI/CD. On every push and pull request, the following checks are performed automatically:\n- Code style check with ktlint\n- Lint analysis\n- Unit tests with coverage (uploaded to Codecov)\n- APK build (debug)\n- Instrumented tests on Android emulator\n- Artifacts (reports and APK) are available for download in the workflow run\n\n## Translation\n\nWe support many languages, all done by people like you! We make use of free [Weblate's Libre hosting](https://weblate.org/en/donate/) to allow this.\nThis means if you don't like how a translation was done for your language, you can change it!\nOr, you can add a whole new language! Visit [our Weblate project](https://hosted.weblate.org/engage/wifianalyzer/) to help.\n\n[![Translation status](https://hosted.weblate.org/widget/wifianalyzer/multi-auto.svg?threshold=0)](https://hosted.weblate.org/engage/wifianalyzer/)\n",
      "stars_today": 6
    },
    {
      "id": 938863633,
      "name": "claude-code-reverse",
      "full_name": "Yuyz0112/claude-code-reverse",
      "description": "A Tool to Visualize Claude Code's LLM Interactions",
      "html_url": "https://github.com/Yuyz0112/claude-code-reverse",
      "stars": 1925,
      "forks": 343,
      "language": "JavaScript",
      "topics": [],
      "created_at": "2025-02-25T16:12:21Z",
      "updated_at": "2026-01-13T11:52:43Z",
      "pushed_at": "2025-08-26T15:29:53Z",
      "open_issues": 5,
      "owner": {
        "login": "Yuyz0112",
        "avatar_url": "https://avatars.githubusercontent.com/u/13651389?v=4"
      },
      "readme": "# Claude Code Reverse Engineering: New Version (July 2025)\n\n[‰∏≠ÊñáÁâà](./README.zh_CN.md)\n\n**üöÄ Quick Try**: Experience the reverse engineering analysis results through our interactive visualization tool at [https://yuyz0112.github.io/claude-code-reverse/visualize.html](https://yuyz0112.github.io/claude-code-reverse/visualize.html)\n\nWhen Anthropic released Claude Code (February 2025), I couldn't try it directly because registrations were paused due to high load. So, I implemented a solution to reverse engineer static code using LLMs, which became the first version of this repository. The code for the initial version is currently archived in the [v1](./v1) directory.\n\n> At the time, there was another version by someone else that directly restored the source code based on sourcemaps. However, that repository was later taken down, indicating that Anthropic officially does not support this type of reverse engineering.\n\nActually, the implementation of v1 was less about reverse engineering Claude Code and more an experiment to explore the limits of \"analyzing large uglify JS code using LLMs.\"\n\nWhen we were able to actually run Claude Code, we found many simpler and more efficient ways to understand how it works. However, I recently noticed a repository gaining popularity that referenced the v1 approach (it mentioned referring to my v1 solution). Yet, a deeper look reveals that this method isn't effective for analyzing the overall architecture and design.\n\nSo, I spent a night exploring a reverse engineering approach based on **runtime behavior and API data** (hereafter referred to as v2). I also created a log visualization tool to help researchers interested in Claude Code analyze the parts they care about.\n\n- If you're interested in the implementation ideas behind v2, please read the following sections in order.\n- If you're only interested in the results of the v2 reverse engineering analysis, you can jump directly to the \"Analysis Results\" section.\n\n## Monkey Patching API Request Code\n\nAs an agent, Claude Code ultimately needs to interact with LLM APIs. Therefore, the core idea behind v2 is to ignore Claude Code's complex internal processing and instead focus only on the requests and responses that Claude Code ultimately exchanges with the LLM API in different task scenarios.\n\nIf you want to develop an agent as powerful as Claude Code, theoretically, you just need to implement your own code to construct similar API requests under the same task scenarios. This type of code is typically application code, with many different implementation methods and styles. Therefore, I believe implementing it from scratch yourself is the most reasonable approach.\n\nWhat's truly worth learning from Claude Code, however, is the content of its interactions with the LLM API, as this reflects its understanding of LLMs and agents.\n\nTo get the API data, there are many methods, but my current approach involves modifying Claude Code's installed files.\n\nFirst, locate the `cli.js` file:\n\n```shell\nwhich claude\n$PATH_TO_CLAUDE\nls -l $PATH_TO_CLAUDE\n$PATH_TO_CLAUDE -> $REAL_PATH/cli.js\n```\n\nNext, use `js-beautify` to format `cli.js`:\n\n```shell\nmv cli.js cli.bak\njs-beautify cli.bak > cli.js\n```\n\nUpon examining the formatted `cli.js` and referring to Anthropic's [TS SDK](https://github.com/anthropics/anthropic-sdk-typescript), you'll find that Claude Code uses this SDK for all its requests, specifically the `beta.messages.create` method.\n\nWe just need to find the bundled TS SDK code within `cli.js` and monkey patch the `beta.messages.create` method. The TS SDK has some intricacies regarding Promise and Stream encapsulation that I won't detail here; please refer to the actual patch code in [cli.js.patch](./cli.js.patch) for specifics.\n\nThis patch implements the following logic:\n\n1.  Create a `messages.log` file every time Claude Code starts.\n2.  Record corresponding logs whenever an API request is sent and a response is received.\n\nAfter making this modification, using Claude Code will generate these logs. Based on this, we can use Claude Code to perform various tasks and analyze the logs to understand how it works.\n\n## Log Visualization\n\nBecause each conversational request includes lengthy common prompts and tool definitions, the raw logs are difficult to read.\n\nTo accelerate the efficiency of reverse engineering analysis, v2 provides a log parsing tool, **[parser.js](./parser.js)**, and a visualization tool, **[visualize.html](./visualize.html)**.\n\nAfter opening the visualization tool, you can select a recorded log file to view the entire conversation. The tool attempts to automatically identify which prompts are common prompts (injected by the program) based on their frequency and position within the conversation.\n\n## Analysis Results\n\n> This section on analysis results will be continuously updated as more task scenarios are explored.\n\nThe internal processes of Claude Code that have been reverse-engineered include:\n\n- Quota check\n- Topic detection\n- Core Agent workflow\n- Context compaction\n- IDE integration\n- Todo short-term memory management\n- Task/Sub Agent workflow\n- Summarize previous conversations\n\nThe analyzed prompts are recorded in the [prompts directory](./results/prompts/), and the analyzed tool definitions are recorded in the [tools directory](./results/tools/).\n\nPrompts and tool designs both contain many highlights and valuable details worth studying. You can read through them at your leisure.\n\n### Quota Check\n\nEach time Claude Code starts, it performs a lightweight conversation, inputting the text `quota`. This is likely used to check if the quota is sufficient; a successful request indicates enough quota.\n\nIt uses the Haiku 3.5 model.\n\n### Topic Detection\n\nWhenever a user inputs content, the LLM uses the [check-new-topic prompt](./results/prompts/check-new-topic.prompt.md) to determine if it's a new topic.\n\nIt uses the Haiku 3.5 model.\n\nIt's important to note that topic detection only considers the current conversation content, without any context. This makes it a very broad check. Currently, it seems to be used solely for updating the terminal title.\n\n### Core Agent Workflow\n\nWhen there's sufficient context, messages are continuously appended to the current context.\n\nThe core process that defines the Agent's workflow is the [system workflow prompt](./results/prompts/system-workflow.prompt.md). It contains a wealth of detail, so reading it directly is recommended.\n\nBefore and after the first user message in a context-based conversation, Claude Code also inserts the [system reminder start prompt](./results/prompts/system-reminder-start.prompt.md) and [system reminder end prompt](./results/prompts/system-reminder-end.prompt.md), respectively. The former dynamically loads information based on the current environment, while the latter checks if any short-term memories managed by the Todo tool need to be loaded.\n\nCurrently, it appears all tools are consistently loaded within the core Agent workflow.\n\nIt uses the Sonnet 4 model.\n\n### Context Compaction\n\nTriggered manually or when context becomes insufficient, this process compresses the current context into a single block of text, which then serves as the initial information for the next conversation. This effectively conserves context space.\n\nDuring compaction, the system prompt loads the [system compact prompt](./results/prompts/system-compact.prompt.md), and a [compact prompt](./results/prompts/compact.prompt.md) is appended to the end of the current context, instructing the LLM to complete the compression in a specific format.\n\nIt uses the Sonnet 4 model.\n\n### IDE Integration\n\nWhen Claude Code is used within an IDE environment, it reads the paths of currently open files to provide more context for the conversation.\n\nThese file paths are then incorporated into the [IDE open file prompt](./results/prompts/ide-opened-file.prompt.md).\n\nIn the IDE integration state, Claude Code will also register some IDE-specific tools through MCP, such as obtaining error information in the IDE, executing code, etc.\n\nYou can see in [ide-integration.log](./logs/ide-integration.log) how we guided Claude Code to use IDE tools to fix lint errors in files.\n\n### Todo Short-Term Memory Management\n\nWithin the \"Task Management\" section of the [system workflow prompt](./results/prompts/system-workflow.prompt.md), a task management method based on the `TodoWrite` tool is defined.\n\nWhen `TodoWrite` executes, it actually creates a JSON file in `~/.claude/todos/` to record the Todos from the current conversation, serving as short-term memory. When a Todo is completed, the model also uses this tool to update the JSON file.\n\nAs mentioned in the Core Agent Workflow section, the system reminder end prompt dynamically loads the latest Todo list, enabling the model to keep track of its previous progress.\n\n### Task/Sub Agent Workflow\n\nClaude Code designed a Sub Agent system, implemented by loading the [Task Tool](./results/tools/Task.tool.yaml), using prompts to guide the model to initiate a Sub Agent through calling this tool when specific independent tasks need to be executed.\n\nClaude Code's Sub Agent, as a specific form of Multi Agent, has its special design:\n\n1. There's always a concept of Main Agent (the object users initially interact with).\n2. When initiating a Sub Agent, it extracts the task to be processed from the main context and uses it as the initial prompt for the sub context.\n3. After the Sub Agent completes the task, it returns the final result as a tool result to the main context.\n\nThis design makes Sub Agent an effective way to optimize main context space. In some independent tasks (such as \"finding specific function implementations from the codebase\"), multiple rounds of Agent tool call/result interactions generate a lot of context irrelevant to the final required result (such as searching irrelevant files that are excluded by the LLM after reading). Sub Agent can isolate this \"dirty context\" in the sub context, which disappears when the Sub Agent task is completed, while the main context only retains the small portion of needed results.\n\n### Summarize Previous Conversations\n\nWhen starting Claude Code, it summarizes previous conversations.\n\nCorresponds to the [Summarize prompt](./results/prompts/summarize-previous-conversation.prompt.md).\n\nIt uses the Haiku 3.5 model.\n",
      "stars_today": 6
    },
    {
      "id": 512268334,
      "name": "Dumper-7",
      "full_name": "Encryqed/Dumper-7",
      "description": "Unreal Engine SDK Generator",
      "html_url": "https://github.com/Encryqed/Dumper-7",
      "stars": 1578,
      "forks": 365,
      "language": "C",
      "topics": [],
      "created_at": "2022-07-09T19:23:46Z",
      "updated_at": "2026-01-13T18:42:57Z",
      "pushed_at": "2025-12-30T20:16:57Z",
      "open_issues": 18,
      "owner": {
        "login": "Encryqed",
        "avatar_url": "https://avatars.githubusercontent.com/u/67229555?v=4"
      },
      "readme": "\n# Dumper-7\n\nSDK Generator for all Unreal Engine games. Supported versions are all of UE4 and UE5.\n\n## How to use\n\n- Compile the dll in x64-Release\n- Inject the dll into your target game\n- The SDK is generated into the path specified by `Settings::SDKGenerationPath`, by default this is `C:\\\\Dumper-7`\n- **See [UsingTheSDK](UsingTheSDK.md) for a guide to get started, or to migrate from an old SDK.**\n## Support Me\n\nKoFi: https://ko-fi.com/fischsalat \\\nPatreon: https://www.patreon.com/u119629245\n\nLTC (LTC-network): `LLtXWxDbc5H9d96VJF36ZpwVX6DkYGpTJU` \\\nBTC (Bitcoin): `1DVDUMcotWzEG1tyd1FffyrYeu4YEh7spx`\n\n## Overriding Offsets\n\n- ### Only override any offsets if the generator doesn't find them, or if they are incorrect\n- All overrides are made in **Generator::InitEngineCore()** inside of **Generator.cpp**\n\n- GObjects (see [GObjects-Layout](#overriding-gobjects-layout) too)\n  ```cpp\n  ObjectArray::Init(/*GObjectsOffset*/, /*ChunkSize*/, /*bIsChunked*/);\n  ```\n  ```cpp\n  /* Make sure only to use types which exist in the sdk (eg. uint8, uint64) */\n  InitObjectArrayDecryption([](void* ObjPtr) -> uint8* { return reinterpret_cast<uint8*>(uint64(ObjPtr) ^ 0x8375); });\n  ```\n- FName::AppendString\n  - Forcing GNames:\n    ```cpp\n    FName::Init(/*bForceGNames*/); // Useful if the AppendString offset is wrong\n    ```\n  - Overriding the offset:\n    ```cpp\n    FName::Init(/*OverrideOffset, OverrideType=[AppendString, ToString, GNames], bIsNamePool*/);\n    ```\n- ProcessEvent\n  ```cpp\n  Off::InSDK::InitPE(/*PEIndex*/);\n  ```\n## Overriding GObjects-Layout\n- Only add a new layout if GObjects isn't automatically found for your game.\n- Layout overrides are at roughly line 30 of `ObjectArray.cpp`\n- For UE4.11 to UE4.20 add the layout to `FFixedUObjectArrayLayouts`\n- For UE4.21 and higher add the layout to `FChunkedFixedUObjectArrayLayouts`\n- **Examples:**\n  ```cpp\n  FFixedUObjectArrayLayout // Default UE4.11 - UE4.20\n  {\n      .ObjectsOffset = 0x0,\n      .MaxObjectsOffset = 0x8,\n      .NumObjectsOffset = 0xC\n  }\n  ```\n  ```cpp\n  FChunkedFixedUObjectArrayLayout // Default UE4.21 and above\n  {\n      .ObjectsOffset = 0x00,\n      .MaxElementsOffset = 0x10,\n      .NumElementsOffset = 0x14,\n      .MaxChunksOffset = 0x18,\n      .NumChunksOffset = 0x1C,\n  }\n  ```\n\n## Config File\nYou can optionally dynamically change settings through a `Dumper-7.ini` file, instead of modifying `Settings.h`.\n- **Per-game**: Create `Dumper-7.ini` in the same directory as the game's exe file.\n- **Global**: Create `Dumper-7.ini` under `C:\\Dumper-7`\n\nExample:\n```ini\n[Settings]\nSleepTimeout=100\nSDKNamespaceName=MyOwnSDKNamespace\n```\n## Issues\n\nIf you have any issues using the Dumper, please create an Issue on this repository\\\nand explain the problem **in detail**.\n\n- Should your game be crashing while dumping, attach Visual Studios' debugger to the game and inject the Dumper-7.dll in debug-configuration.\nThen include screenshots of the exception causing the crash, a screenshot of the callstack, as well as the console output.\n\n- Should there be any compiler-errors in the SDK please send screenshots of them. Please note that **only build errors** are considered errors, as Intellisense often reports false positives.\nMake sure to always send screenshots of the code causing the first error, as it's likely to cause a chain-reaction of errors.\n\n- Should your own dll-project crash, verify your code thoroughly to make sure the error actually lies within the generated SDK.\n",
      "stars_today": 6
    },
    {
      "id": 7691631,
      "name": "moby",
      "full_name": "moby/moby",
      "description": "The Moby Project - a collaborative project for the container ecosystem to assemble container-based systems",
      "html_url": "https://github.com/moby/moby",
      "stars": 71345,
      "forks": 18877,
      "language": "Go",
      "topics": [
        "containers",
        "docker",
        "go",
        "golang"
      ],
      "created_at": "2013-01-18T18:10:57Z",
      "updated_at": "2026-01-14T00:00:44Z",
      "pushed_at": "2026-01-12T16:51:43Z",
      "open_issues": 3775,
      "owner": {
        "login": "moby",
        "avatar_url": "https://avatars.githubusercontent.com/u/27259197?v=4"
      },
      "readme": "The Moby Project\n================\n\n[![PkgGoDev](https://pkg.go.dev/badge/github.com/moby/moby/v2)](https://pkg.go.dev/github.com/moby/moby/v2)\n![GitHub License](https://img.shields.io/github/license/moby/moby)\n[![Go Report Card](https://goreportcard.com/badge/github.com/moby/moby/v2)](https://goreportcard.com/report/github.com/moby/moby/v2)\n[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/moby/moby/badge)](https://scorecard.dev/viewer/?uri=github.com/moby/moby)\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10989/badge)](https://www.bestpractices.dev/projects/10989)\n\n\n![Moby Project logo](docs/static_files/moby-project-logo.png \"The Moby Project\")\n\nMoby is an open-source project created by Docker to enable and accelerate software containerization.\n\nIt provides a \"Lego set\" of toolkit components, the framework for assembling them into custom container-based systems, and a place for all container enthusiasts and professionals to experiment and exchange ideas.\nComponents include container build tools, a container registry, orchestration tools, a runtime and more, and these can be used as building blocks in conjunction with other tools and projects.\n\n## Principles\n\nMoby is an open project guided by strong principles, aiming to be modular, flexible and without too strong an opinion on user experience.\nIt is open to the community to help set its direction.\n\n- Modular: the project includes lots of components that have well-defined functions and APIs that work together.\n- Batteries included but swappable: Moby includes enough components to build fully featured container systems, but its modular architecture ensures that most of the components can be swapped by different implementations.\n- Usable security: Moby provides secure defaults without compromising usability.\n- Developer focused: The APIs are intended to be functional and useful to build powerful tools.\nThey are not necessarily intended as end user tools but as components aimed at developers.\nDocumentation and UX is aimed at developers not end users.\n\n## Audience\n\nThe Moby Project is intended for engineers, integrators and enthusiasts looking to modify, hack, fix, experiment, invent and build systems based on containers.\nIt is not for people looking for a commercially supported system, but for people who want to work and learn with open source code.\n\n## Relationship with Docker\n\nThe components and tools in the Moby Project are initially the open source components that Docker and the community have built for the Docker Project.\nNew projects can be added if they fit with the community goals. Docker is committed to using Moby as the upstream for the Docker Product.\nHowever, other projects are also encouraged to use Moby as an upstream, and to reuse the components in diverse ways, and all these uses will be treated in the same way. External maintainers and contributors are welcomed.\n\nThe Moby project is not intended as a location for support or feature requests for Docker products, but as a place for contributors to work on open source code, fix bugs, and make the code more useful.\nThe releases are supported by the maintainers, community and users, on a best efforts basis only. For customers who want enterprise or commercial support, [Docker Desktop](https://www.docker.com/products/docker-desktop/) and [Mirantis Container Runtime](https://www.mirantis.com/software/mirantis-container-runtime/) are the appropriate products for these use cases.\n\n-----\n\nLegal\n=====\n\n*Brought to you courtesy of our legal counsel. For more context,\nplease see the [NOTICE](https://github.com/moby/moby/blob/master/NOTICE) document in this repo.*\n\nUse and transfer of Moby may be subject to certain restrictions by the\nUnited States and other governments.\n\nIt is your responsibility to ensure that your use and/or transfer does not\nviolate applicable laws.\n\nFor more information, please see https://www.bis.doc.gov\n\nLicensing\n=========\nMoby is licensed under the Apache License, Version 2.0. See\n[LICENSE](https://github.com/moby/moby/blob/master/LICENSE) for the full\nlicense text.\n",
      "stars_today": 5
    },
    {
      "id": 19872456,
      "name": "react-router",
      "full_name": "remix-run/react-router",
      "description": "Declarative routing for React",
      "html_url": "https://github.com/remix-run/react-router",
      "stars": 56112,
      "forks": 10813,
      "language": "TypeScript",
      "topics": [],
      "created_at": "2014-05-16T22:22:51Z",
      "updated_at": "2026-01-13T23:51:05Z",
      "pushed_at": "2026-01-13T15:54:06Z",
      "open_issues": 141,
      "owner": {
        "login": "remix-run",
        "avatar_url": "https://avatars.githubusercontent.com/u/64235328?v=4"
      },
      "readme": "[![npm package][npm-badge]][npm] [![build][build-badge]][build]\n\n[npm-badge]: https://img.shields.io/npm/v/react-router-dom.svg\n[npm]: https://www.npmjs.org/package/react-router-dom\n[build-badge]: https://img.shields.io/github/actions/workflow/status/remix-run/react-router/test.yml?branch=dev&style=square\n[build]: https://github.com/remix-run/react-router/actions/workflows/test.yml\n\nReact Router is a multi-strategy router for React bridging the gap from React 18 to React 19. You can use it maximally as a React framework or minimally as a library with your own architecture.\n\n- [Getting Started - Framework](https://reactrouter.com/start/framework/installation)\n- [Getting Started - Library](https://reactrouter.com/start/library/installation)\n- [Upgrade from v6](https://reactrouter.com/upgrading/v6)\n- [Upgrade from Remix](https://reactrouter.com/upgrading/remix)\n- [Changelog](https://github.com/remix-run/react-router/blob/main/CHANGELOG.md)\n\n## Packages\n\n- [`react-router`](./packages/react-router)\n- [`@react-router/dev`](./packages/react-router-dev)\n- [`@react-router/node`](./packages/react-router-node)\n- [`@react-router/cloudflare`](./packages/react-router-cloudflare)\n- [`@react-router/serve`](./packages/react-router-serve)\n- [`@react-router/fs-routes`](./packages/react-router-fs-routes)\n\n## Previous Versions\n\n- [v6](https://reactrouter.com/v6)\n- [v5](https://v5.reactrouter.com/)\n",
      "stars_today": 5
    },
    {
      "id": 22458259,
      "name": "Alamofire",
      "full_name": "Alamofire/Alamofire",
      "description": "Elegant HTTP Networking in Swift",
      "html_url": "https://github.com/Alamofire/Alamofire",
      "stars": 42297,
      "forks": 7668,
      "language": "Swift",
      "topics": [
        "alamofire",
        "carthage",
        "certificate-pinning",
        "cocoapods",
        "httpurlresponse",
        "networking",
        "parameter-encoding",
        "public-key-pinning",
        "request",
        "response",
        "swift",
        "swift-package-manager",
        "urlrequest",
        "urlsession",
        "xcode"
      ],
      "created_at": "2014-07-31T05:56:19Z",
      "updated_at": "2026-01-13T20:56:40Z",
      "pushed_at": "2025-12-20T07:34:46Z",
      "open_issues": 39,
      "owner": {
        "login": "Alamofire",
        "avatar_url": "https://avatars.githubusercontent.com/u/7774181?v=4"
      },
      "readme": "![Alamofire: Elegant Networking in Swift](https://raw.githubusercontent.com/Alamofire/Alamofire/master/Resources/AlamofireLogo.png)\n\n[![Swift](https://img.shields.io/badge/Swift-6.0_6.1_6.2-orange?style=flat-square)](https://img.shields.io/badge/Swift-6.0_6.1_6.2-Orange?style=flat-square)\n[![Platforms](https://img.shields.io/badge/Platforms-macOS_iOS_tvOS_watchOS_visionOS_Linux_Windows_Android-yellowgreen?style=flat-square)](https://img.shields.io/badge/Platforms-macOS_iOS_tvOS_watchOS_vision_OS_Linux_Windows_Android-Green?style=flat-square)\n[![CocoaPods Compatible](https://img.shields.io/cocoapods/v/Alamofire.svg?style=flat-square)](https://img.shields.io/cocoapods/v/Alamofire.svg)\n[![Carthage Compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat-square)](https://github.com/Carthage/Carthage)\n[![Swift Package Manager](https://img.shields.io/badge/Swift_Package_Manager-compatible-orange?style=flat-square)](https://img.shields.io/badge/Swift_Package_Manager-compatible-orange?style=flat-square)\n[![Swift Forums](https://img.shields.io/badge/Swift_Forums-Alamofire-orange?style=flat-square)](https://forums.swift.org/c/related-projects/alamofire/37)\n\nAlamofire is an HTTP networking library written in Swift.\n\n- [Features](#features)\n- [Component Libraries](#component-libraries)\n- [Requirements](#requirements)\n- [Migration Guides](#migration-guides)\n- [Communication](#communication)\n- [Installation](#installation)\n- [Contributing](#contributing)\n- [Usage](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#using-alamofire)\n  - [**Introduction -**](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#introduction) [Making Requests](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#making-requests), [Response Handling](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#response-handling), [Response Validation](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#response-validation), [Response Caching](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#response-caching)\n  - **HTTP -** [HTTP Methods](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#http-methods), [Parameters and Parameter Encoder](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md##request-parameters-and-parameter-encoders), [HTTP Headers](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#http-headers), [Authentication](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#authentication)\n  - **Large Data -** [Downloading Data to a File](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#downloading-data-to-a-file), [Uploading Data to a Server](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#uploading-data-to-a-server)\n  - **Tools -** [Statistical Metrics](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#statistical-metrics), [cURL Command Output](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#curl-command-output)\n- [Advanced Usage](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md)\n  - **URL Session -** [Session Manager](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#session), [Session Delegate](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#sessiondelegate), [Request](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#request)\n  - **Routing -** [Routing Requests](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#routing-requests), [Adapting and Retrying Requests](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#adapting-and-retrying-requests-with-requestinterceptor)\n  - **Model Objects -** [Custom Response Handlers](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#customizing-response-handlers)\n  - **Advanced Concurrency -** [Swift Concurrency](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#using-alamofire-with-swift-concurrency) and [Combine](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#using-alamofire-with-combine)\n  - **Connection -** [Security](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#security), [Network Reachability](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#network-reachability)\n- [Open Radars](#open-radars)\n- [FAQ](#faq)\n- [Credits](#credits)\n- [Donations](#donations)\n- [License](#license)\n\n## Features\n\n- [x] Chainable Request / Response Methods\n- [x] Swift Concurrency Support Back to iOS 13, macOS 10.15, tvOS 13, and watchOS 6.\n- [x] Combine Support\n- [x] URL / JSON Parameter Encoding\n- [x] Upload File / Data / Stream / MultipartFormData\n- [x] Download File using Request or Resume Data\n- [x] Authentication with `URLCredential`\n- [x] HTTP Response Validation\n- [x] Upload and Download Progress Closures with Progress\n- [x] cURL Command Output\n- [x] Dynamically Adapt and Retry Requests\n- [x] TLS Certificate and Public Key Pinning\n- [x] Network Reachability\n- [x] Comprehensive Unit and Integration Test Coverage\n- [x] [Complete Documentation](https://alamofire.github.io/Alamofire)\n\n## Write Requests Fast!\n\nAlamofire's compact syntax and extensive feature set allow requests with powerful features like automatic retry to be written in just a few lines of code.\n\n```swift\n// Automatic String to URL conversion, Swift concurrency support, and automatic retry.\nlet response = await AF.request(\"https://httpbin.org/get\", interceptor: .retryPolicy)\n                       // Automatic HTTP Basic Auth.\n                       .authenticate(username: \"user\", password: \"pass\")\n                       // Caching customization.\n                       .cacheResponse(using: .cache)\n                       // Redirect customization.\n                       .redirect(using: .follow)\n                       // Validate response code and Content-Type.\n                       .validate()\n                       // Produce a cURL command for the request.\n                       .cURLDescription { description in\n                         print(description)\n                       }\n                       // Automatic Decodable support with background parsing.\n                       .serializingDecodable(DecodableType.self)\n                       // Await the full response with metrics and a parsed body.\n                       .response\n// Detailed response description for easy debugging.\ndebugPrint(response)\n```\n\n## Component Libraries\n\nIn order to keep Alamofire focused specifically on core networking implementations, additional component libraries have been created by the [Alamofire Software Foundation](https://github.com/Alamofire/Foundation) to bring additional functionality to the Alamofire ecosystem.\n\n- [AlamofireImage](https://github.com/Alamofire/AlamofireImage) - An image library including image response serializers, `UIImage` and `UIImageView` extensions, custom image filters, an auto-purging in-memory cache, and a priority-based image downloading system.\n- [AlamofireNetworkActivityIndicator](https://github.com/Alamofire/AlamofireNetworkActivityIndicator) - Controls the visibility of the network activity indicator on iOS using Alamofire. It contains configurable delay timers to help mitigate flicker and can support `URLSession` instances not managed by Alamofire.\n\n## Requirements\n\n| Platform                                             | Minimum Swift Version | Installation                                                                                                         | Status                   |\n| ---------------------------------------------------- | --------------------- | -------------------------------------------------------------------------------------------------------------------- | ------------------------ |\n| iOS 10.0+ / macOS 10.12+ / tvOS 10.0+ / watchOS 3.0+ | 6.0 / Xcode 16.0      | [CocoaPods](#cocoapods), [Carthage](#carthage), [Swift Package Manager](#swift-package-manager), [Manual](#manually) | Fully Tested             |\n| Linux                                                | Latest Only           | [Swift Package Manager](#swift-package-manager)                                                                      | Building But Unsupported |\n| Windows                                              | Latest Only           | [Swift Package Manager](#swift-package-manager)                                                                      | Building But Unsupported |\n| Android                                              | Latest Only           | [Swift Package Manager](#swift-package-manager)                                                                      | Building But Unsupported |\n\n#### Known Issues on Linux and Windows\n\nAlamofire builds on Linux, Windows, and Android but there are missing features and many issues in the underlying `swift-corelibs-foundation` that prevent full functionality and may cause crashes. These include:\n\n- `ServerTrustManager` and associated certificate functionality is unavailable, so there is no certificate pinning and no client certificate support.\n- Various methods of HTTP authentication may crash, including HTTP Basic and HTTP Digest. Crashes may occur if responses contain server challenges.\n- Cache control through `CachedResponseHandler` and associated APIs is unavailable, as the underlying delegate methods aren't called.\n- `URLSessionTaskMetrics` are never gathered.\n- `WebSocketRequest` is not available.\n\nDue to these issues, Alamofire is unsupported on Linux, Windows, and Android. Please report any crashes to the [Swift bug reporter](https://bugs.swift.org).\n\n## Migration Guides\n\n- [Alamofire 5.0 Migration Guide](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Alamofire%205.0%20Migration%20Guide.md)\n- [Alamofire 4.0 Migration Guide](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Alamofire%204.0%20Migration%20Guide.md)\n- [Alamofire 3.0 Migration Guide](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Alamofire%203.0%20Migration%20Guide.md)\n- [Alamofire 2.0 Migration Guide](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Alamofire%202.0%20Migration%20Guide.md)\n\n## Communication\n\n- If you **need help with making network requests** using Alamofire, use [Stack Overflow](https://stackoverflow.com/questions/tagged/alamofire) and tag `alamofire`.\n- If you need to **find or understand an API**, check [our documentation](http://alamofire.github.io/Alamofire/) or [Apple's documentation for `URLSession`](https://developer.apple.com/documentation/foundation/url_loading_system), on top of which Alamofire is built.\n- If you need **help with an Alamofire feature**, use [our forum on swift.org](https://forums.swift.org/c/related-projects/alamofire).\n- If you'd like to **discuss Alamofire best practices**, use [our forum on swift.org](https://forums.swift.org/c/related-projects/alamofire).\n- If you'd like to **discuss a feature request**, use [our forum on swift.org](https://forums.swift.org/c/related-projects/alamofire).\n- If you **found a bug**, open an issue here on GitHub and follow the guide. The more detail the better!\n\n## Installation\n\n### Swift Package Manager\n\nThe [Swift Package Manager](https://swift.org/package-manager/) is a tool for automating the distribution of Swift code and is integrated into the `swift` compiler.\n\nOnce you have your Swift package set up, adding Alamofire as a dependency is as easy as adding it to the `dependencies` value of your `Package.swift` or the Package list in Xcode.\n\n```swift\ndependencies: [\n    .package(url: \"https://github.com/Alamofire/Alamofire.git\", .upToNextMajor(from: \"5.11.0\"))\n]\n```\n\nNormally you'll want to depend on the `Alamofire` target:\n\n```swift\n.product(name: \"Alamofire\", package: \"Alamofire\")\n```\n\nBut if you want to force Alamofire to be dynamically linked (do not do this unless you're sure you need it), you can depend on the `AlamofireDynamic` target:\n\n```swift\n.product(name: \"AlamofireDynamic\", package: \"Alamofire\")\n```\n\n### CocoaPods\n\n[CocoaPods](https://cocoapods.org) is a dependency manager for Cocoa projects. For usage and installation instructions, visit their website. To integrate Alamofire into your Xcode project using CocoaPods, specify it in your `Podfile`:\n\n```ruby\npod 'Alamofire'\n```\n\n### Carthage\n\n[Carthage](https://github.com/Carthage/Carthage) is a decentralized dependency manager that builds your dependencies and provides you with binary frameworks. To integrate Alamofire into your Xcode project using Carthage, specify it in your `Cartfile`:\n\n```ogdl\ngithub \"Alamofire/Alamofire\"\n```\n\n### Manually\n\nIf you prefer not to use any of the aforementioned dependency managers, you can integrate Alamofire into your project manually.\n\n#### Embedded Framework\n\n- Open up Terminal, `cd` into your top-level project directory, and run the following command \"if\" your project is not initialized as a git repository:\n\n  ```bash\n  $ git init\n  ```\n\n- Add Alamofire as a git [submodule](https://git-scm.com/docs/git-submodule) by running the following command:\n\n  ```bash\n  $ git submodule add https://github.com/Alamofire/Alamofire.git\n  ```\n\n- Open the new `Alamofire` folder, and drag the `Alamofire.xcodeproj` into the Project Navigator of your application's Xcode project.\n\n  > It should appear nested underneath your application's blue project icon. Whether it is above or below all the other Xcode groups does not matter.\n\n- Select the `Alamofire.xcodeproj` in the Project Navigator and verify the deployment target matches that of your application target.\n- Next, select your application project in the Project Navigator (blue project icon) to navigate to the target configuration window and select the application target under the \"Targets\" heading in the sidebar.\n- In the tab bar at the top of that window, open the \"General\" panel.\n- Click on the `+` button under the \"Embedded Binaries\" section.\n- You will see two different `Alamofire.xcodeproj` folders each with two different versions of the `Alamofire.framework` nested inside a `Products` folder.\n\n  > It does not matter which `Products` folder you choose from, but it does matter whether you choose the top or bottom `Alamofire.framework`.\n\n- Select the top `Alamofire.framework` for iOS and the bottom one for macOS.\n\n  > You can verify which one you selected by inspecting the build log for your project. The build target for `Alamofire` will be listed as `Alamofire iOS`, `Alamofire macOS`, `Alamofire tvOS`, or `Alamofire watchOS`.\n\n- And that's it!\n\n  > The `Alamofire.framework` is automagically added as a target dependency, linked framework and embedded framework in a copy files build phase which is all you need to build on the simulator and a device.\n\n## Contributing\n\nBefore contributing to Alamofire, please read the instructions detailed in our [contribution guide](https://github.com/Alamofire/Alamofire/blob/master/CONTRIBUTING.md).\n\n## Open Radars\n\nThe following radars have some effect on the current implementation of Alamofire.\n\n- [`rdar://21349340`](http://www.openradar.me/radar?id=5517037090635776) - Compiler throwing warning due to toll-free bridging issue in the test case\n- `rdar://26870455` - Background URL Session Configurations do not work in the simulator\n- `rdar://26849668` - Some URLProtocol APIs do not properly handle `URLRequest`\n\n## Resolved Radars\n\nThe following radars have been resolved over time after being filed against the Alamofire project.\n\n- [`rdar://26761490`](http://www.openradar.me/radar?id=5010235949318144) - Swift string interpolation causing memory leak with common usage.\n  - (Resolved): 9/1/17 in Xcode 9 beta 6.\n- [`rdar://36082113`](http://openradar.appspot.com/radar?id=4942308441063424) - `URLSessionTaskMetrics` failing to link on watchOS 3.0+\n  - (Resolved): Just add `CFNetwork` to your linked frameworks.\n- `FB7624529` - `urlSession(_:task:didFinishCollecting:)` never called on watchOS\n  - (Resolved): Metrics now collected on watchOS 7+.\n\n## FAQ\n\n### What's the origin of the name Alamofire?\n\nAlamofire is named after the [Alamo Fire flower](https://aggie-horticulture.tamu.edu/wildseed/alamofire.html), a hybrid variant of the Bluebonnet, the official state flower of Texas.\n\n## Credits\n\nAlamofire is owned and maintained by the [Alamofire Software Foundation](http://alamofire.org). You can follow them on Twitter at [@AlamofireSF](https://twitter.com/AlamofireSF) for project updates and releases.\n\n### Security Disclosure\n\nIf you believe you have identified a security vulnerability with Alamofire, you should report it as soon as possible via email to security@alamofire.org. Please do not post it to a public issue tracker.\n\n## Sponsorship\n\nThe [ASF](https://github.com/Alamofire/Foundation#members) is looking to raise money to officially stay registered as a federal non-profit organization.\nRegistering will allow Foundation members to gain some legal protections and also allow us to put donations to use, tax-free.\nSponsoring the ASF will enable us to:\n\n- Pay our yearly legal fees to keep the non-profit in good status\n- Pay for our mail servers to help us stay on top of all questions and security issues\n- Potentially fund test servers to make it easier for us to test the edge cases\n- Potentially fund developers to work on one of our projects full-time\n\nThe community adoption of the ASF libraries has been amazing.\nWe are greatly humbled by your enthusiasm around the projects and want to continue to do everything we can to move the needle forward.\nWith your continued support, the ASF will be able to improve its reach and also provide better legal safety for the core members.\nIf you use any of our libraries for work, see if your employers would be interested in donating.\nAny amount you can donate, whether once or monthly, to help us reach our goal would be greatly appreciated.\n\n[Sponsor Alamofire](https://github.com/sponsors/Alamofire)\n\n## Supporters\n\n[MacStadium](https://macstadium.com) provides Alamofire with a free, hosted Mac mini.\n\n![Powered by MacStadium](https://raw.githubusercontent.com/Alamofire/Alamofire/master/Resources/MacStadiumLogo.png)\n\n## License\n\nAlamofire is released under the MIT license. [See LICENSE](https://github.com/Alamofire/Alamofire/blob/master/LICENSE) for details.\n",
      "stars_today": 5
    },
    {
      "id": 284134871,
      "name": "flipperzero-firmware",
      "full_name": "flipperdevices/flipperzero-firmware",
      "description": "Flipper Zero firmware source code",
      "html_url": "https://github.com/flipperdevices/flipperzero-firmware",
      "stars": 15392,
      "forks": 3237,
      "language": "C",
      "topics": [
        "armv7m",
        "ble",
        "firmware",
        "flipper",
        "flipperzero",
        "infrared",
        "nfc",
        "onewire",
        "rfid",
        "stm32",
        "subghz"
      ],
      "created_at": "2020-07-31T21:43:20Z",
      "updated_at": "2026-01-13T20:54:10Z",
      "pushed_at": "2025-12-05T19:35:25Z",
      "open_issues": 224,
      "owner": {
        "login": "flipperdevices",
        "avatar_url": "https://avatars.githubusercontent.com/u/57576566?v=4"
      },
      "readme": "<picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"/.github/assets/dark_theme_banner.png\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"/.github/assets/light_theme_banner.png\">\n    <img\n        alt=\"A pixel art of a Dophin with text: Flipper Zero Official Repo\"\n        src=\"/.github/assets/light_theme_banner.png\">\n</picture>\n\n# Flipper Zero Firmware\n\n- [Flipper Zero Official Website](https://flipperzero.one). A simple way to explain to your friends what Flipper Zero can do.\n- [Flipper Zero Firmware Update](https://flipperzero.one/update). Improvements for your dolphin: latest firmware releases, upgrade tools for PC and mobile devices.\n- [User Documentation](https://docs.flipper.net). Learn more about your dolphin: specs, usage guides, and anything you want to ask.\n- [Developer Documentation](https://developer.flipper.net/flipperzero/doxygen). Dive into the Flipper Zero Firmware source code: build system, firmware structure, and more.\n\n# Contributing\n\nOur main goal is to build a healthy and sustainable community around Flipper, so we're open to any new ideas and contributions. We also have some rules and taboos here, so please read this page and our [Code of Conduct](/CODE_OF_CONDUCT.md) carefully.\n\n## I need help\n\nThe best place to search for answers is our [User Documentation](https://docs.flipper.net). If you can't find the answer there, check our [Discord Server](https://flipp.dev/discord) or our [Forum](https://forum.flipperzero.one/). If you want to contribute to the firmware development or modify it for your own needs, you can also check our [Developer Documentation](https://developer.flipper.net/flipperzero/doxygen).\n\n## I want to report an issue\n\nIf you've found an issue and want to report it, please check our [Issues](https://github.com/flipperdevices/flipperzero-firmware/issues) page. Make sure the description contains information about the firmware version you're using, your platform, and a clear explanation of the steps to reproduce the issue.\n\n## I want to contribute code\n\nBefore opening a PR, please confirm that your changes must be contained in the firmware. Many ideas can easily be implemented as external applications and published in the [Flipper Application Catalog](https://github.com/flipperdevices/flipper-application-catalog). If you are unsure, reach out to us on the [Discord Server](https://flipp.dev/discord) or the [Issues](https://github.com/flipperdevices/flipperzero-firmware/issues) page, and we'll help you find the right place for your code.\n\nAlso, please read our [Contribution Guide](/CONTRIBUTING.md) and our [Coding Style](/CODING_STYLE.md), and make sure your code is compatible with our [Project License](/LICENSE).\n\nFinally, open a [Pull Request](https://github.com/flipperdevices/flipperzero-firmware/pulls) and make sure that CI/CD statuses are all green.\n\n# Development\n\nFlipper Zero Firmware is written in C, with some bits and pieces written in C++ and armv7m assembly languages. An intermediate level of C knowledge is recommended for comfortable programming. C, C++, and armv7m assembly languages are supported for Flipper applications.\n\n# Firmware RoadMap\n\n[Firmware RoadMap Miro Board](https://miro.com/app/board/uXjVO_3D6xU=/)\n\n## Requirements\n\nSupported development platforms:\n\n- Windows 10+ with PowerShell and Git (x86_64)\n- macOS 12+ with Command Line tools (x86_64, arm64)\n- Ubuntu 20.04+ with build-essential and Git (x86_64)\n\nSupported in-circuit debuggers (optional but highly recommended):\n\n- [Flipper Zero Wi-Fi Development Board](https://shop.flipperzero.one/products/wifi-devboard)\n- CMSIS-DAP compatible: Raspberry Pi Debug Probe and etc...\n- ST-Link (v2, v3, v3mods)\n- J-Link\n\nFlipper Build System will take care of all the other dependencies.\n\n## Cloning source code\n\nMake sure you have enough space and clone the source code:\n\n```shell\ngit clone --recursive https://github.com/flipperdevices/flipperzero-firmware.git\n```\n\n## Building\n\nBuild firmware using Flipper Build Tool:\n\n```shell\n./fbt\n```\n\n## Flashing firmware using an in-circuit debugger\n\nConnect your in-circuit debugger to your Flipper and flash firmware using Flipper Build Tool:\n\n```shell\n./fbt flash\n```\n\n## Flashing firmware using USB\n\nMake sure your Flipper is on, and your firmware is functioning. Connect your Flipper with a USB cable and flash firmware using Flipper Build Tool:\n\n```shell\n./fbt flash_usb\n```\n\n## Documentation\n\n- [Flipper Build Tool](/documentation/fbt.md) - building, flashing, and debugging Flipper software\n- [Applications](/documentation/AppsOnSDCard.md), [Application Manifest](/documentation/AppManifests.md) - developing, building, deploying, and debugging Flipper applications\n- [Hardware combos and Un-bricking](/documentation/KeyCombo.md) - recovering your Flipper from the most nasty situations\n- [Flipper File Formats](/documentation/file_formats) - everything about how Flipper stores your data and how you can work with it\n- [Universal Remotes](/documentation/UniversalRemotes.md) - contributing your infrared remote to the universal remote database\n- [Firmware Roadmap](https://miro.com/app/board/uXjVO_3D6xU=/)\n- And much more in the [Developer Documentation](https://developer.flipper.net/flipperzero/doxygen)\n\n# Project structure\n\n- `applications`        - Applications and services used in firmware\n- `applications_users`  - Place for your additional applications and services\n- `assets`              - Assets used by applications and services\n- `documentation`       - Documentation generation system configs and input files\n- `furi`                - Furi Core: OS-level primitives and helpers\n- `lib`                 - Our and 3rd party libraries, drivers, tools and etc...\n- `site_scons`          - Build system configuration and modules\n- `scripts`             - Supplementary scripts and various python libraries\n- `targets`             - Firmware targets: platform specific code\n\nAlso, see `ReadMe.md` files inside those directories for further details.\n\n# Links\n\n- Discord: [flipp.dev/discord](https://flipp.dev/discord)\n- Website: [flipperzero.one](https://flipperzero.one)\n- Forum: [forum.flipperzero.one](https://forum.flipperzero.one/)\n- Kickstarter: [kickstarter.com](https://www.kickstarter.com/projects/flipper-devices/flipper-zero-tamagochi-for-hackers)\n\n## SAST Tools\n\n- [PVS-Studio](https://pvs-studio.com/pvs-studio/?utm_source=website&utm_medium=github&utm_campaign=open_source) - static analyzer for C, C++, C#, and Java code.\n",
      "stars_today": 5
    },
    {
      "id": 38304949,
      "name": "GRDB.swift",
      "full_name": "groue/GRDB.swift",
      "description": "A toolkit for SQLite databases, with a focus on application development",
      "html_url": "https://github.com/groue/GRDB.swift",
      "stars": 8097,
      "forks": 824,
      "language": "Swift",
      "topics": [
        "database",
        "database-observation",
        "grdb",
        "spm",
        "sql",
        "sql-builder",
        "sqlite",
        "sqlite-databases"
      ],
      "created_at": "2015-06-30T11:17:06Z",
      "updated_at": "2026-01-13T22:23:24Z",
      "pushed_at": "2026-01-09T15:30:58Z",
      "open_issues": 11,
      "owner": {
        "login": "groue",
        "avatar_url": "https://avatars.githubusercontent.com/u/54219?v=4"
      },
      "readme": "<picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/groue/GRDB.swift/master/GRDB~dark.png\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://raw.githubusercontent.com/groue/GRDB.swift/master/GRDB.png\">\n    <img alt=\"GRDB: A toolkit for SQLite databases, with a focus on application development.\" src=\"https://raw.githubusercontent.com/groue/GRDB.swift/master/GRDB.png\">\n</picture>\n\n<p align=\"center\">\n    <strong>A toolkit for SQLite databases, with a focus on application development</strong><br>\n    Proudly serving the community since 2015\n</p>\n\n<p align=\"center\">\n    <a href=\"https://developer.apple.com/swift/\"><img alt=\"Swift 6.1\" src=\"https://img.shields.io/badge/swift-6.1-orange.svg?style=flat\"></a>\n    <a href=\"https://github.com/groue/GRDB.swift/blob/master/LICENSE\"><img alt=\"License\" src=\"https://img.shields.io/github/license/groue/GRDB.swift.svg?maxAge=2592000\"></a>\n    <a href=\"https://github.com/groue/GRDB.swift/actions/workflows/CI.yml\"><img alt=\"CI Status\" src=\"https://github.com/groue/GRDB.swift/actions/workflows/CI.yml/badge.svg?branch=master\"></a>\n</p>\n\n**Latest release**: December 13, 2025 ‚Ä¢ [version 7.9.0](https://github.com/groue/GRDB.swift/tree/v7.9.0) ‚Ä¢ [CHANGELOG](CHANGELOG.md) ‚Ä¢ [Migrating From GRDB 6 to GRDB 7](Documentation/GRDB7MigrationGuide.md)\n\n**Requirements**: iOS 13.0+ / macOS 10.15+ / tvOS 13.0+ / watchOS 7.0+ &bull; SQLite 3.20.0+ &bull; Swift 6.1+ / Xcode 16.3+\n\n**Contact**:\n\n- Release announcements and usage tips: follow [@groue@hachyderm.io](https://hachyderm.io/@groue) on Mastodon.\n- Report bugs in a [Github issue](https://github.com/groue/GRDB.swift/issues/new). Make sure you check the [existing issues](https://github.com/groue/GRDB.swift/issues?q=is%3Aopen) first.\n- A question? Looking for advice? Do you wonder how to contribute? Fancy a chat? Go to the [GitHub discussions](https://github.com/groue/GRDB.swift/discussions), or the [GRDB forums](https://forums.swift.org/c/related-projects/grdb).\n\n\n## What is GRDB?\n\nUse this library to save your application‚Äôs permanent data into SQLite databases. It comes with built-in tools that address common needs:\n\n- **SQL Generation**\n    \n    Enhance your application models with persistence and fetching methods, so that you don't have to deal with SQL and raw database rows when you don't want to.\n\n- **Database Observation**\n    \n    Get notifications when database values are modified. \n\n- **Robust Concurrency**\n    \n    Multi-threaded applications can efficiently use their databases, including WAL databases that support concurrent reads and writes. \n\n- **Migrations**\n    \n    Evolve the schema of your database as you ship new versions of your application.\n    \n- **Leverage your SQLite skills**\n\n    Not all developers need advanced SQLite features. But when you do, GRDB is as sharp as you want it to be. Come with your SQL and SQLite skills, or learn new ones as you go!\n\n---\n\n<p align=\"center\">\n    <a href=\"#usage\">Usage</a> &bull;\n    <a href=\"#documentation\">Documentation</a> &bull;\n    <a href=\"#installation\">Installation</a> &bull;\n    <a href=\"#faq\">FAQ</a>\n</p>\n\n---\n\n## Usage\n\n<details open>\n  <summary>Start using the database in four steps</summary>\n\n```swift\nimport GRDB\n\n// 1. Open a database connection\nlet dbQueue = try DatabaseQueue(path: \"/path/to/database.sqlite\")\n\n// 2. Define the database schema\ntry dbQueue.write { db in\n    try db.create(table: \"player\") { t in\n        t.primaryKey(\"id\", .text)\n        t.column(\"name\", .text).notNull()\n        t.column(\"score\", .integer).notNull()\n    }\n}\n\n// 3. Define a record type\nstruct Player: Codable, Identifiable, FetchableRecord, PersistableRecord {\n    var id: String\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n\n// 4. Write and read in the database\ntry dbQueue.write { db in\n    try Player(id: \"1\", name: \"Arthur\", score: 100).insert(db)\n    try Player(id: \"2\", name: \"Barbara\", score: 1000).insert(db)\n}\n\ntry dbQueue.read { db in\n    let player = try Player.find(db, id: \"1\"))\n    \n    let bestPlayers = try Player\n        .order(\\.score.desc)\n        .limit(10)\n        .fetchAll(db)\n}\n```\n\n</details>\n\n<details>\n    <summary>Access to raw SQL</summary>\n\n```swift\ntry dbQueue.write { db in\n    try db.execute(sql: \"\"\"\n        CREATE TABLE player (\n          id TEXT PRIMARY KEY,\n          name TEXT NOT NULL,\n          score INT NOT NULL)\n        \"\"\")\n    \n    try db.execute(sql: \"\"\"\n        INSERT INTO player (id, name, score)\n        VALUES (?, ?, ?)\n        \"\"\", arguments: [\"1\", \"Arthur\", 100])\n    \n    // Avoid SQL injection with SQL interpolation\n    let id = \"2\"\n    let name = \"O'Brien\"\n    let score = 1000\n    try db.execute(literal: \"\"\"\n        INSERT INTO player (id, name, score)\n        VALUES (\\(id), \\(name), \\(score))\n        \"\"\")\n}\n```\n\nSee [Executing Updates](#executing-updates)\n\n</details>\n\n<details>\n    <summary>Access to raw database rows and values</summary>\n\n```swift\ntry dbQueue.read { db in\n    // Fetch database rows\n    let rows = try Row.fetchCursor(db, sql: \"SELECT * FROM player\")\n    while let row = try rows.next() {\n        let id: String = row[\"id\"]\n        let name: String = row[\"name\"]\n        let score: Int = row[\"score\"]\n    }\n    \n    // Fetch values\n    let playerCount = try Int.fetchOne(db, sql: \"SELECT COUNT(*) FROM player\")! // Int\n    let playerNames = try String.fetchAll(db, sql: \"SELECT name FROM player\") // [String]\n}\n\nlet playerCount = try dbQueue.read { db in\n    try Int.fetchOne(db, sql: \"SELECT COUNT(*) FROM player\")!\n}\n```\n\nSee [Fetch Queries](#fetch-queries)\n\n</details>\n\n<details>\n    <summary>Database model types aka \"records\"</summary>\n\n```swift\nstruct Player: Codable, Identifiable, FetchableRecord, PersistableRecord {\n    var id: String\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n\ntry dbQueue.write { db in\n    // Create database table\n    try db.create(table: \"player\") { t in\n        t.primaryKey(\"id\", .text)\n        t.column(\"name\", .text).notNull()\n        t.column(\"score\", .integer).notNull()\n    }\n    \n    // Insert a record\n    var player = Player(id: \"1\", name: \"Arthur\", score: 100)\n    try player.insert(db)\n    \n    // Update a record\n    player.score += 10\n    try score.update(db)\n    \n    try player.updateChanges { $0.score += 10 }\n    \n    // Delete a record\n    try player.delete(db)\n}\n```\n\nSee [Records](#records)\n\n</details>\n\n<details>\n    <summary>Query the database with the Swift query interface</summary>\n\n```swift\ntry dbQueue.read { db in\n    // Player\n    let player = try Player.find(db, id: \"1\")\n    \n    // Player?\n    let arthur = try Player.filter { $0.name == \"Arthur\" }.fetchOne(db)\n    \n    // [Player]\n    let bestPlayers = try Player.order(\\.score.desc).limit(10).fetchAll(db)\n    \n    // Int\n    let playerCount = try Player.fetchCount(db)\n    \n    // SQL is always welcome\n    let players = try Player.fetchAll(db, sql: \"SELECT * FROM player\")\n}\n```\n\nSee the [Query Interface](#the-query-interface)\n\n</details>\n\n<details>\n    <summary>Database changes notifications</summary>\n\n```swift\n// Define the observed value\nlet observation = ValueObservation.tracking { db in\n    try Player.fetchAll(db)\n}\n\n// Start observation\nlet cancellable = observation.start(\n    in: dbQueue,\n    onError: { error in ... },\n    onChange: { (players: [Player]) in print(\"Fresh players: \\(players)\") })\n```\n\nReady-made support for Combine and RxSwift:\n\n```swift\n// Swift concurrency\nfor try await players in observation.values(in: dbQueue) {\n    print(\"Fresh players: \\(players)\")\n}\n\n// Combine\nlet cancellable = observation.publisher(in: dbQueue).sink(\n    receiveCompletion: { completion in ... },\n    receiveValue: { (players: [Player]) in print(\"Fresh players: \\(players)\") })\n\n// RxSwift\nlet disposable = observation.rx.observe(in: dbQueue).subscribe(\n    onNext: { (players: [Player]) in print(\"Fresh players: \\(players)\") },\n    onError: { error in ... })\n```\n\nSee [Database Observation], [Combine Support], [RxGRDB].\n\n</details>\n\nDocumentation\n=============\n\n**GRDB runs on top of SQLite**: you should get familiar with the [SQLite FAQ](http://www.sqlite.org/faq.html). For general and detailed information, jump to the [SQLite Documentation](http://www.sqlite.org/docs.html).\n\n\n#### Demo Applications & Frequently Asked Questions\n\n- [Demo Applications]\n- [FAQ]\n\n#### Reference\n\n- üìñ [GRDB Reference](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/)\n\n#### Getting Started\n\n- [Installation](#installation)\n- [Database Connections]: Connect to SQLite databases\n\n#### SQLite and SQL\n\n- [SQLite API](#sqlite-api): The low-level SQLite API &bull; [executing updates](#executing-updates) &bull; [fetch queries](#fetch-queries) &bull; [SQL Interpolation]\n\n#### Records and the Query Interface\n\n- [Records](#records): Fetching and persistence methods for your custom structs and class hierarchies\n- [Query Interface](#the-query-interface): A swift way to generate SQL &bull; [create tables, indexes, etc](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseschema) &bull; [requests](#requests) ‚Ä¢ [associations between record types](Documentation/AssociationsBasics.md)\n\n#### Application Tools\n\n- [Migrations]: Transform your database as your application evolves.\n- [Full-Text Search]: Perform efficient and customizable full-text searches.\n- [Database Observation]: Observe database changes and transactions.\n- [Encryption](#encryption): Encrypt your database with SQLCipher.\n- [Backup](#backup): Dump the content of a database to another.\n- [Interrupt a Database](#interrupt-a-database): Abort any pending database operation.\n- [Sharing a Database]: How to share an SQLite database between multiple processes - recommendations for App Group containers, App Extensions, App Sandbox, and file coordination.\n\n#### Good to Know\n\n- [Concurrency]: How to access databases in a multi-threaded application.\n- [Combine](Documentation/Combine.md): Access and observe the database with Combine publishers.\n- [Avoiding SQL Injection](#avoiding-sql-injection)\n- [Error Handling](#error-handling)\n- [Unicode](#unicode)\n- [Memory Management](#memory-management)\n- [Data Protection](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseconnections)\n- :bulb: [Migrating From GRDB 6 to GRDB 7](Documentation/GRDB7MigrationGuide.md)\n- :bulb: [Why Adopt GRDB?](Documentation/WhyAdoptGRDB.md)\n- :bulb: [Recommended Practices for Designing Record Types](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recordrecommendedpractices)\n\n#### Companion Libraries\n\n- [GRDBQuery](https://github.com/groue/GRDBQuery): Access and observe the database from your SwiftUI views.\n- [GRDBSnapshotTesting](https://github.com/groue/GRDBSnapshotTesting): Test your database. \n\n**[FAQ]**\n\n**[Sample Code](#sample-code)**\n\n\nInstallation\n============\n\n**The installation procedures below have GRDB use the version of SQLite that ships with the target operating system.**\n\nSee [Encryption](#encryption) for the installation procedure of GRDB with SQLCipher.\n\nSee [Custom SQLite builds](Documentation/CustomSQLiteBuilds.md) for the installation procedure of GRDB with a customized build of SQLite.\n\n\n## Swift Package Manager\n\nThe [Swift Package Manager](https://swift.org/package-manager/) automates the distribution of Swift code. To use GRDB with SPM, add a dependency to `https://github.com/groue/GRDB.swift.git`\n\nGRDB offers two libraries, `GRDB` and `GRDB-dynamic`. Pick only one. When in doubt, prefer `GRDB`. The `GRDB-dynamic` library can reveal useful if you are going to link it with multiple targets within your app and only wish to link to a shared, dynamic framework once. See [How to link a Swift Package as dynamic](https://forums.swift.org/t/how-to-link-a-swift-package-as-dynamic/32062) for more information.\n\n> **Note**: Linux support is provided by contributors. It is not automatically tested, and not officially maintained. If you notice a build or runtime failure on Linux, please open a pull request with the necessary fix, thank you!\n\n\n## CocoaPods\n\n[CocoaPods](http://cocoapods.org/) is a dependency manager for Xcode projects. To use GRDB with CocoaPods (version 1.2 or higher), specify in your `Podfile`:\n\n```ruby\npod 'GRDB.swift'\n```\n\nGRDB can be installed as a framework, or a static library.\n\n**Important Note for CocoaPods installation**\n\nDue to an [issue](https://github.com/CocoaPods/CocoaPods/issues/11839) in CocoaPods, it is currently not possible to deploy new versions of GRDB to CocoaPods. The last version available on CocoaPods is 6.24.1. To install later versions of GRDB using CocoaPods, use one of the following workarounds:\n\n- Depend on the `GRDB7` branch. This is more or less equivalent to what `pod 'GRDB.swift', '~> 7.0'` would normally do, if CocoaPods would accept new GRDB versions to be published:\n\n    ```ruby\n    # Can't use semantic versioning due to https://github.com/CocoaPods/CocoaPods/issues/11839\n    pod 'GRDB.swift', git: 'https://github.com/groue/GRDB.swift.git', branch: 'GRDB7'\n    ```\n\n- Depend on a specific version explicitly (Replace the tag with the version you want to use):\n\n    ```ruby\n    # Can't use semantic versioning due to https://github.com/CocoaPods/CocoaPods/issues/11839\n    # Replace the tag with the tag that you want to use.\n    pod 'GRDB.swift', git: 'https://github.com/groue/GRDB.swift.git', tag: 'v6.29.0' \n    ```\n\n## Carthage\n\n[Carthage](https://github.com/Carthage/Carthage) is **unsupported**. For some context about this decision, see [#433](https://github.com/groue/GRDB.swift/issues/433).\n\n\n## Manually\n\n1. [Download](https://github.com/groue/GRDB.swift/releases) a copy of GRDB, or clone its repository and make sure you checkout the latest tagged version.\n\n2. Embed the `GRDB.xcodeproj` project in your own project.\n\n3. Add the `GRDB` target in the **Target Dependencies** section of the **Build Phases** tab of your application target (extension target for WatchOS).\n\n4. Add the `GRDB.framework` to the **Embedded Binaries** section of the **General**  tab of your application target (extension target for WatchOS).\n\n\nDatabase Connections\n====================\n\nGRDB provides two classes for accessing SQLite databases: [`DatabaseQueue`] and [`DatabasePool`]:\n\n```swift\nimport GRDB\n\n// Pick one:\nlet dbQueue = try DatabaseQueue(path: \"/path/to/database.sqlite\")\nlet dbPool = try DatabasePool(path: \"/path/to/database.sqlite\")\n```\n\nThe differences are:\n\n- Database pools allow concurrent database accesses (this can improve the performance of multithreaded applications).\n- Database pools open your SQLite database in the [WAL mode](https://www.sqlite.org/wal.html) (unless read-only).\n- Database queues support [in-memory databases](https://www.sqlite.org/inmemorydb.html).\n\n**If you are not sure, choose [`DatabaseQueue`].** You will always be able to switch to [`DatabasePool`] later.\n\nFor more information and tips when opening connections, see [Database Connections](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseconnections).\n\n\nSQLite API\n==========\n\n**In this section of the documentation, we will talk SQL.** Jump to the [query interface](#the-query-interface) if SQL is not your cup of tea.\n\n- [Executing Updates](#executing-updates)\n- [Fetch Queries](#fetch-queries)\n    - [Fetching Methods](#fetching-methods)\n    - [Row Queries](#row-queries)\n    - [Value Queries](#value-queries)\n- [Values](#values)\n    - [Data](#data-and-memory-savings)\n    - [Date and DateComponents](#date-and-datecomponents)\n    - [NSNumber, NSDecimalNumber, and Decimal](#nsnumber-nsdecimalnumber-and-decimal)\n    - [Swift enums](#swift-enums)\n    - [`DatabaseValueConvertible`]: the protocol for custom value types\n- [Transactions and Savepoints]\n- [SQL Interpolation]\n\nAdvanced topics:\n\n- [Prepared Statements]\n- [Custom SQL Functions and Aggregates](#custom-sql-functions-and-aggregates)\n- [Database Schema Introspection](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseschemaintrospection)\n- [Row Adapters](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/rowadapter)\n- [Raw SQLite Pointers](#raw-sqlite-pointers)\n\n\n## Executing Updates\n\nOnce granted with a [database connection], the [`execute(sql:arguments:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/execute(sql:arguments:)) method executes the SQL statements that do not return any database row, such as `CREATE TABLE`, `INSERT`, `DELETE`, `ALTER`, etc.\n\nFor example:\n\n```swift\ntry dbQueue.write { db in\n    try db.execute(sql: \"\"\"\n        CREATE TABLE player (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            name TEXT NOT NULL,\n            score INT)\n        \"\"\")\n    \n    try db.execute(\n        sql: \"INSERT INTO player (name, score) VALUES (?, ?)\",\n        arguments: [\"Barbara\", 1000])\n    \n    try db.execute(\n        sql: \"UPDATE player SET score = :score WHERE id = :id\",\n        arguments: [\"score\": 1000, \"id\": 1])\n    }\n}\n```\n\nThe `?` and colon-prefixed keys like `:score` in the SQL query are the **statements arguments**. You pass arguments with arrays or dictionaries, as in the example above. See [Values](#values) for more information on supported arguments types (Bool, Int, String, Date, Swift enums, etc.), and [`StatementArguments`] for a detailed documentation of SQLite arguments.\n\nYou can also embed query arguments right into your SQL queries, with [`execute(literal:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/execute(literal:)), as in the example below. See [SQL Interpolation] for more details.\n\n```swift\ntry dbQueue.write { db in\n    let name = \"O'Brien\"\n    let score = 550\n    try db.execute(literal: \"\"\"\n        INSERT INTO player (name, score) VALUES (\\(name), \\(score))\n        \"\"\")\n}\n```\n\n**Never ever embed values directly in your raw SQL strings**. See [Avoiding SQL Injection](#avoiding-sql-injection) for more information:\n\n```swift\n// WRONG: don't embed values in raw SQL strings\nlet id = 123\nlet name = textField.text\ntry db.execute(\n    sql: \"UPDATE player SET name = '\\(name)' WHERE id = \\(id)\")\n\n// CORRECT: use arguments dictionary\ntry db.execute(\n    sql: \"UPDATE player SET name = :name WHERE id = :id\",\n    arguments: [\"name\": name, \"id\": id])\n\n// CORRECT: use arguments array\ntry db.execute(\n    sql: \"UPDATE player SET name = ? WHERE id = ?\",\n    arguments: [name, id])\n\n// CORRECT: use SQL Interpolation\ntry db.execute(\n    literal: \"UPDATE player SET name = \\(name) WHERE id = \\(id)\")\n```\n\n**Join multiple statements with a semicolon**:\n\n```swift\ntry db.execute(sql: \"\"\"\n    INSERT INTO player (name, score) VALUES (?, ?);\n    INSERT INTO player (name, score) VALUES (?, ?);\n    \"\"\", arguments: [\"Arthur\", 750, \"Barbara\", 1000])\n\ntry db.execute(literal: \"\"\"\n    INSERT INTO player (name, score) VALUES (\\(\"Arthur\"), \\(750));\n    INSERT INTO player (name, score) VALUES (\\(\"Barbara\"), \\(1000));\n    \"\"\")\n```\n\nWhen you want to make sure that a single statement is executed, use a prepared [`Statement`].\n\n**After an INSERT statement**, you can get the row ID of the inserted row with [`lastInsertedRowID`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/lastinsertedrowid):\n\n```swift\ntry db.execute(\n    sql: \"INSERT INTO player (name, score) VALUES (?, ?)\",\n    arguments: [\"Arthur\", 1000])\nlet playerId = db.lastInsertedRowID\n```\n\nDon't miss [Records](#records), that provide classic **persistence methods**:\n\n```swift\nvar player = Player(name: \"Arthur\", score: 1000)\ntry player.insert(db)\nlet playerId = player.id\n```\n\n\n## Fetch Queries\n\n[Database connections] let you fetch database rows, plain values, and custom models aka \"records\".\n\n**Rows** are the raw results of SQL queries:\n\n```swift\ntry dbQueue.read { db in\n    if let row = try Row.fetchOne(db, sql: \"SELECT * FROM wine WHERE id = ?\", arguments: [1]) {\n        let name: String = row[\"name\"]\n        let color: Color = row[\"color\"]\n        print(name, color)\n    }\n}\n```\n\n\n**Values** are the Bool, Int, String, Date, Swift enums, etc. stored in row columns:\n\n```swift\ntry dbQueue.read { db in\n    let urls = try URL.fetchCursor(db, sql: \"SELECT url FROM wine\")\n    while let url = try urls.next() {\n        print(url)\n    }\n}\n```\n\n\n**Records** are your application objects that can initialize themselves from rows:\n\n```swift\nlet wines = try dbQueue.read { db in\n    try Wine.fetchAll(db, sql: \"SELECT * FROM wine\")\n}\n```\n\n- [Fetching Methods](#fetching-methods) and [Cursors](#cursors)\n- [Row Queries](#row-queries)\n- [Value Queries](#value-queries)\n- [Records](#records)\n\n\n### Fetching Methods\n\n**Throughout GRDB**, you can always fetch *cursors*, *arrays*, *sets*, or *single values* of any fetchable type (database [row](#row-queries), simple [value](#value-queries), or custom [record](#records)):\n\n```swift\ntry Row.fetchCursor(...) // A Cursor of Row\ntry Row.fetchAll(...)    // [Row]\ntry Row.fetchSet(...)    // Set<Row>\ntry Row.fetchOne(...)    // Row?\n```\n\n- `fetchCursor` returns a **[cursor](#cursors)** over fetched values:\n    \n    ```swift\n    let rows = try Row.fetchCursor(db, sql: \"SELECT ...\") // A Cursor of Row\n    ```\n    \n- `fetchAll` returns an **array**:\n    \n    ```swift\n    let players = try Player.fetchAll(db, sql: \"SELECT ...\") // [Player]\n    ```\n\n- `fetchSet` returns a **set**:\n    \n    ```swift\n    let names = try String.fetchSet(db, sql: \"SELECT ...\") // Set<String>\n    ```\n\n- `fetchOne` returns a **single optional value**, and consumes a single database row (if any).\n    \n    ```swift\n    let count = try Int.fetchOne(db, sql: \"SELECT COUNT(*) ...\") // Int?\n    ```\n\n**All those fetching methods require an SQL string that contains a single SQL statement.** When you want to fetch from multiple statements joined with a semicolon, iterate the multiple [prepared statements] found in the SQL string.\n\n### Cursors\n\nüìñ [`Cursor`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/cursor)\n\n**Whenever you consume several rows from the database, you can fetch an Array, a Set, or a Cursor**.\n\nThe `fetchAll()` and `fetchSet()` methods return regular Swift array and sets, that you iterate like all other arrays and sets:\n\n```swift\ntry dbQueue.read { db in\n    // [Player]\n    let players = try Player.fetchAll(db, sql: \"SELECT ...\")\n    for player in players {\n        // use player\n    }\n}\n```\n\nUnlike arrays and sets, cursors returned by `fetchCursor()` load their results step after step:\n\n```swift\ntry dbQueue.read { db in\n    // Cursor of Player\n    let players = try Player.fetchCursor(db, sql: \"SELECT ...\")\n    while let player = try players.next() {\n        // use player\n    }\n}\n```\n\n- **Cursors can not be used on any thread**: you must consume a cursor on the dispatch queue it was created in. Particularly, don't extract a cursor out of a database access method:\n    \n    ```swift\n    // Wrong\n    let cursor = try dbQueue.read { db in\n        try Player.fetchCursor(db, ...)\n    }\n    while let player = try cursor.next() { ... }\n    ```\n    \n    Conversely, arrays and sets may be consumed on any thread:\n    \n    ```swift\n    // OK\n    let array = try dbQueue.read { db in\n        try Player.fetchAll(db, ...)\n    }\n    for player in array { ... }\n    ```\n    \n- **Cursors can be iterated only one time.** Arrays and sets can be iterated many times.\n\n- **Cursors iterate database results in a lazy fashion**, and don't consume much memory. Arrays and sets contain copies of database values, and may take a lot of memory when there are many fetched results.\n\n- **Cursors are granted with direct access to SQLite,** unlike arrays and sets that have to take the time to copy database values. If you look after extra performance, you may prefer cursors.\n\n- **Cursors can feed Swift collections.**\n    \n    You will most of the time use `fetchAll` or `fetchSet` when you want an array or a set. For more specific needs, you may prefer one of the initializers below. All of them accept an extra optional `minimumCapacity` argument which helps optimizing your app when you have an idea of the number of elements in a cursor (the built-in `fetchAll` and `fetchSet` do not perform such an optimization).\n    \n    **Arrays** and all types conforming to `RangeReplaceableCollection`:\n    \n    ```swift\n    // [String]\n    let cursor = try String.fetchCursor(db, ...)\n    let array = try Array(cursor)\n    ```\n    \n    **Sets**:\n    \n    ```swift\n    // Set<Int>\n    let cursor = try Int.fetchCursor(db, ...)\n    let set = try Set(cursor)\n    ```\n    \n    **Dictionaries**:\n    \n    ```swift\n    // [Int64: [Player]]\n    let cursor = try Player.fetchCursor(db)\n    let dictionary = try Dictionary(grouping: cursor, by: { $0.teamID })\n    \n    // [Int64: Player]\n    let cursor = try Player.fetchCursor(db).map { ($0.id, $0) }\n    let dictionary = try Dictionary(uniqueKeysWithValues: cursor)\n    ```\n\n- **Cursors adopt the [Cursor](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/cursor) protocol, which looks a lot like standard [lazy sequences](https://developer.apple.com/reference/swift/lazysequenceprotocol) of Swift.** As such, cursors come with many convenience methods: `compactMap`, `contains`, `dropFirst`, `dropLast`, `drop(while:)`, `enumerated`, `filter`, `first`, `flatMap`, `forEach`, `joined`, `joined(separator:)`, `max`, `max(by:)`, `min`, `min(by:)`, `map`, `prefix`, `prefix(while:)`, `reduce`, `reduce(into:)`, `suffix`:\n    \n    ```swift\n    // Prints all Github links\n    try URL\n        .fetchCursor(db, sql: \"SELECT url FROM link\")\n        .filter { url in url.host == \"github.com\" }\n        .forEach { url in print(url) }\n    \n    // An efficient cursor of coordinates:\n    let locations = try Row.\n        .fetchCursor(db, sql: \"SELECT latitude, longitude FROM place\")\n        .map { row in\n            CLLocationCoordinate2D(latitude: row[0], longitude: row[1])\n        }\n    ```\n\n- **Cursors are not Swift sequences.** That's because Swift sequences can't handle iteration errors, when reading SQLite results may fail at any time.\n\n- **Cursors require a little care**:\n    \n    - Don't modify the results during a cursor iteration:\n        \n        ```swift\n        // Undefined behavior\n        while let player = try players.next() {\n            try db.execute(sql: \"DELETE ...\")\n        }\n        ```\n    \n    - Don't turn a cursor of `Row` into an array or a set. You would not get the distinct rows you expect. To get a array of rows, use `Row.fetchAll(...)`. To get a set of rows, use `Row.fetchSet(...)`. Generally speaking, make sure you copy a row whenever you extract it from a cursor for later use: `row.copy()`.\n\nIf you don't see, or don't care about the difference, use arrays. If you care about memory and performance, use cursors when appropriate.\n\n\n### Row Queries\n\n- [Fetching Rows](#fetching-rows)\n- [Column Values](#column-values)\n- [DatabaseValue](#databasevalue)\n- [Rows as Dictionaries](#rows-as-dictionaries)\n- üìñ [`Row`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/row)\n\n\n#### Fetching Rows\n\nFetch **cursors** of rows, **arrays**, **sets**, or **single** rows (see [fetching methods](#fetching-methods)):\n\n```swift\ntry dbQueue.read { db in\n    try Row.fetchCursor(db, sql: \"SELECT ...\", arguments: ...) // A Cursor of Row\n    try Row.fetchAll(db, sql: \"SELECT ...\", arguments: ...)    // [Row]\n    try Row.fetchSet(db, sql: \"SELECT ...\", arguments: ...)    // Set<Row>\n    try Row.fetchOne(db, sql: \"SELECT ...\", arguments: ...)    // Row?\n    \n    let rows = try Row.fetchCursor(db, sql: \"SELECT * FROM wine\")\n    while let row = try rows.next() {\n        let name: String = row[\"name\"]\n        let color: Color = row[\"color\"]\n        print(name, color)\n    }\n}\n\nlet rows = try dbQueue.read { db in\n    try Row.fetchAll(db, sql: \"SELECT * FROM player\")\n}\n```\n\nArguments are optional arrays or dictionaries that fill the positional `?` and colon-prefixed keys like `:name` in the query:\n\n```swift\nlet rows = try Row.fetchAll(db,\n    sql: \"SELECT * FROM player WHERE name = ?\",\n    arguments: [\"Arthur\"])\n\nlet rows = try Row.fetchAll(db,\n    sql: \"SELECT * FROM player WHERE name = :name\",\n    arguments: [\"name\": \"Arthur\"])\n```\n\nSee [Values](#values) for more information on supported arguments types (Bool, Int, String, Date, Swift enums, etc.), and [`StatementArguments`] for a detailed documentation of SQLite arguments.\n\nUnlike row arrays that contain copies of the database rows, row cursors are close to the SQLite metal, and require a little care:\n\n> **Note**: **Don't turn a cursor of `Row` into an array or a set**. You would not get the distinct rows you expect. To get a array of rows, use `Row.fetchAll(...)`. To get a set of rows, use `Row.fetchSet(...)`. Generally speaking, make sure you copy a row whenever you extract it from a cursor for later use: `row.copy()`.\n\n\n#### Column Values\n\n**Read column values** by index or column name:\n\n```swift\nlet name: String = row[0]      // 0 is the leftmost column\nlet name: String = row[\"name\"] // Leftmost matching column - lookup is case-insensitive\nlet name: String = row[Column(\"name\")] // Using query interface's Column\n```\n\nMake sure to ask for an optional when the value may be NULL:\n\n```swift\nlet name: String? = row[\"name\"]\n```\n\nThe `row[]` subscript returns the type you ask for. See [Values](#values) for more information on supported value types:\n\n```swift\nlet bookCount: Int     = row[\"bookCount\"]\nlet bookCount64: Int64 = row[\"bookCount\"]\nlet hasBooks: Bool     = row[\"bookCount\"] // false when 0\n\nlet string: String     = row[\"date\"]      // \"2015-09-11 18:14:15.123\"\nlet date: Date         = row[\"date\"]      // Date\nself.date = row[\"date\"] // Depends on the type of the property.\n```\n\nYou can also use the `as` type casting operator:\n\n```swift\nrow[...] as Int\nrow[...] as Int?\n```\n\nThrowing accessors exist as well. Their use is not encouraged, because a database decoding error is a programming error. If an application stores invalid data in the database file, that is a bug that needs to be fixed:\n\n```swift\nlet name = try row.decode(String.self, atIndex: 0)\nlet bookCount = try row.decode(Int.self, forColumn: \"bookCount\")\n```\n\n> **Warning**: avoid the `as!` and `as?` operators:\n> \n> ```swift\n> if let int = row[...] as? Int { ... } // BAD - doesn't work\n> if let int = row[...] as Int? { ... } // GOOD\n> ```\n\n> **Warning**: avoid nil-coalescing row values, and prefer the `coalesce` method instead:\n>\n> ```swift\n> let name: String? = row[\"nickname\"] ?? row[\"name\"]     // BAD - doesn't work\n> let name: String? = row.coalesce([\"nickname\", \"name\"]) // GOOD\n> ```\n\nGenerally speaking, you can extract the type you need, provided it can be converted from the underlying SQLite value:\n\n- **Successful conversions include:**\n    \n    - All numeric SQLite values to all numeric Swift types, and Bool (zero is the only false boolean).\n    - Text SQLite values to Swift String.\n    - Blob SQLite values to Foundation Data.\n    \n    See [Values](#values) for more information on supported types (Bool, Int, String, Date, Swift enums, etc.)\n    \n- **NULL returns nil.**\n    \n    ```swift\n    let row = try Row.fetchOne(db, sql: \"SELECT NULL\")!\n    row[0] as Int? // nil\n    row[0] as Int  // fatal error: could not convert NULL to Int.\n    ```\n    \n    There is one exception, though: the [DatabaseValue](#databasevalue) type:\n    \n    ```swift\n    row[0] as DatabaseValue // DatabaseValue.null\n    ```\n    \n- **Missing columns return nil.**\n    \n    ```swift\n    let row = try Row.fetchOne(db, sql: \"SELECT 'foo' AS foo\")!\n    row[\"missing\"] as String? // nil\n    row[\"missing\"] as String  // fatal error: no such column: missing\n    ```\n    \n    You can explicitly check for a column presence with the `hasColumn` method.\n\n- **Invalid conversions throw a fatal error.**\n    \n    ```swift\n    let row = try Row.fetchOne(db, sql: \"SELECT 'Mom‚Äôs birthday'\")!\n    row[0] as String // \"Mom‚Äôs birthday\"\n    row[0] as Date?  // fatal error: could not convert \"Mom‚Äôs birthday\" to Date.\n    row[0] as Date   // fatal error: could not convert \"Mom‚Äôs birthday\" to Date.\n    \n    let row = try Row.fetchOne(db, sql: \"SELECT 256\")!\n    row[0] as Int    // 256\n    row[0] as UInt8? // fatal error: could not convert 256 to UInt8.\n    row[0] as UInt8  // fatal error: could not convert 256 to UInt8.\n    ```\n    \n    Those conversion fatal errors can be avoided with the [DatabaseValue](#databasevalue) type:\n    \n    ```swift\n    let row = try Row.fetchOne(db, sql: \"SELECT 'Mom‚Äôs birthday'\")!\n    let dbValue: DatabaseValue = row[0]\n    if dbValue.isNull {\n        // Handle NULL\n    } else if let date = Date.fromDatabaseValue(dbValue) {\n        // Handle valid date\n    } else {\n        // Handle invalid date\n    }\n    ```\n    \n    This extra verbosity is the consequence of having to deal with an untrusted database: you may consider fixing the content of your database instead. See [Fatal Errors](#fatal-errors) for more information.\n    \n- **SQLite has a weak type system, and provides [convenience conversions](https://www.sqlite.org/c3ref/column_blob.html) that can turn String to Int, Double to Blob, etc.**\n    \n    GRDB will sometimes let those conversions go through:\n    \n    ```swift\n    let rows = try Row.fetchCursor(db, sql: \"SELECT '20 small cigars'\")\n    while let row = try rows.next() {\n        row[0] as Int   // 20\n    }\n    ```\n    \n    Don't freak out: those conversions did not prevent SQLite from becoming the immensely successful database engine you want to use. And GRDB adds safety checks described just above. You can also prevent those convenience conversions altogether by using the [DatabaseValue](#databasevalue) type.\n\n\n#### DatabaseValue\n\nüìñ [`DatabaseValue`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalue)\n\n**`DatabaseValue` is an intermediate type between SQLite and your values, which gives information about the raw value stored in the database.**\n\nYou get `DatabaseValue` just like other value types:\n\n```swift\nlet dbValue: DatabaseValue = row[0]\nlet dbValue: DatabaseValue? = row[\"name\"] // nil if and only if column does not exist\n\n// Check for NULL:\ndbValue.isNull // Bool\n\n// The stored value:\ndbValue.storage.value // Int64, Double, String, Data, or nil\n\n// All the five storage classes supported by SQLite:\nswitch dbValue.storage {\ncase .null:                 print(\"NULL\")\ncase .int64(let int64):     print(\"Int64: \\(int64)\")\ncase .double(let double):   print(\"Double: \\(double)\")\ncase .string(let string):   print(\"String: \\(string)\")\ncase .blob(let data):       print(\"Data: \\(data)\")\n}\n```\n\nYou can extract regular [values](#values) (Bool, Int, String, Date, Swift enums, etc.) from `DatabaseValue` with the [fromDatabaseValue()](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalueconvertible/fromdatabasevalue(_:)-21zzv) method:\n\n```swift\nlet dbValue: DatabaseValue = row[\"bookCount\"]\nlet bookCount   = Int.fromDatabaseValue(dbValue)   // Int?\nlet bookCount64 = Int64.fromDatabaseValue(dbValue) // Int64?\nlet hasBooks    = Bool.fromDatabaseValue(dbValue)  // Bool?, false when 0\n\nlet dbValue: DatabaseValue = row[\"date\"]\nlet string = String.fromDatabaseValue(dbValue)     // \"2015-09-11 18:14:15.123\"\nlet date   = Date.fromDatabaseValue(dbValue)       // Date?\n```\n\n`fromDatabaseValue` returns nil for invalid conversions:\n\n```swift\nlet row = try Row.fetchOne(db, sql: \"SELECT 'Mom‚Äôs birthday'\")!\nlet dbValue: DatabaseValue = row[0]\nlet string = String.fromDatabaseValue(dbValue) // \"Mom‚Äôs birthday\"\nlet int    = Int.fromDatabaseValue(dbValue)    // nil\nlet date   = Date.fromDatabaseValue(dbValue)   // nil\n```\n\n\n#### Rows as Dictionaries\n\nRow adopts the standard [RandomAccessCollection](https://developer.apple.com/documentation/swift/randomaccesscollection) protocol, and can be seen as a dictionary of [DatabaseValue](#databasevalue):\n\n```swift\n// All the (columnName, dbValue) tuples, from left to right:\nfor (columnName, dbValue) in row {\n    ...\n}\n```\n\n**You can build rows from dictionaries** (standard Swift dictionaries and NSDictionary). See [Values](#values) for more information on supported types:\n\n```swift\nlet row: Row = [\"name\": \"foo\", \"date\": nil]\nlet row = Row([\"name\": \"foo\", \"date\": nil])\nlet row = Row(/* [AnyHashable: Any] */) // nil if invalid dictionary\n```\n\nYet rows are not real dictionaries: they may contain duplicate columns:\n\n```swift\nlet row = try Row.fetchOne(db, sql: \"SELECT 1 AS foo, 2 AS foo\")!\nrow.columnNames    // [\"foo\", \"foo\"]\nrow.databaseValues // [1, 2]\nrow[\"foo\"]         // 1 (leftmost matching column)\nfor (columnName, dbValue) in row { ... } // (\"foo\", 1), (\"foo\", 2)\n```\n\n**When you build a dictionary from a row**, you have to disambiguate identical columns, and choose how to present database values. For example:\n\n- A `[String: DatabaseValue]` dictionary that keeps leftmost value in case of duplicated column name:\n\n    ```swift\n    let dict = Dictionary(row, uniquingKeysWith: { (left, _) in left })\n    ```\n\n- A `[String: AnyObject]` dictionary which keeps rightmost value in case of duplicated column name. This dictionary is identical to FMResultSet's resultDictionary from FMDB. It contains NSNull values for null columns, and can be shared with Objective-C:\n\n    ```swift\n    let dict = Dictionary(\n        row.map { (column, dbValue) in\n            (column, dbValue.storage.value as AnyObject)\n        },\n        uniquingKeysWith: { (_, right) in right })\n    ```\n\n- A `[String: Any]` dictionary that can feed, for example, JSONSerialization:\n    \n    ```swift\n    let dict = Dictionary(\n        row.map { (column, dbValue) in\n            (column, dbValue.storage.value)\n        },\n        uniquingKeysWith: { (left, _) in left })\n    ```\n\nSee the documentation of [`Dictionary.init(_:uniquingKeysWith:)`](https://developer.apple.com/documentation/swift/dictionary/2892961-init) for more information.\n\n\n### Value Queries\n\nüìñ [`DatabaseValueConvertible`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalueconvertible)\n\n**Instead of rows, you can directly fetch values.** There are many supported [value types](#values) (Bool, Int, String, Date, Swift enums, etc.).\n\nLike rows, fetch values as **cursors**, **arrays**, **sets**, or **single** values (see [fetching methods](#fetching-methods)). Values are extracted from the leftmost column of the SQL queries:\n\n```swift\ntry dbQueue.read { db in\n    try Int.fetchCursor(db, sql: \"SELECT ...\", arguments: ...) // A Cursor of Int\n    try Int.fetchAll(db, sql: \"SELECT ...\", arguments: ...)    // [Int]\n    try Int.fetchSet(db, sql: \"SELECT ...\", arguments: ...)    // Set<Int>\n    try Int.fetchOne(db, sql: \"SELECT ...\", arguments: ...)    // Int?\n    \n    let maxScore = try Int.fetchOne(db, sql: \"SELECT MAX(score) FROM player\") // Int?\n    let names = try String.fetchAll(db, sql: \"SELECT name FROM player\")       // [String]\n}\n```\n\n`Int.fetchOne` returns nil in two cases: either the SELECT statement yielded no row, or one row with a NULL value:\n\n```swift\n// No row:\ntry Int.fetchOne(db, sql: \"SELECT 42 WHERE FALSE\") // nil\n\n// One row with a NULL value:\ntry Int.fetchOne(db, sql: \"SELECT NULL\")           // nil\n\n// One row with a non-NULL value:\ntry Int.fetchOne(db, sql: \"SELECT 42\")             // 42\n```\n\nFor requests which may contain NULL, fetch optionals:\n\n```swift\ntry dbQueue.read { db in\n    try Optional<Int>.fetchCursor(db, sql: \"SELECT ...\", arguments: ...) // A Cursor of Int?\n    try Optional<Int>.fetchAll(db, sql: \"SELECT ...\", arguments: ...)    // [Int?]\n    try Optional<Int>.fetchSet(db, sql: \"SELECT ...\", arguments: ...)    // Set<Int?>\n}\n```\n\n> :bulb: **Tip**: One advanced use case, when you fetch one value, is to distinguish the cases of a statement that yields no row, or one row with a NULL value. To do so, use `Optional<Int>.fetchOne`, which returns a double optional `Int??`:\n> \n> ```swift\n> // No row:\n> try Optional<Int>.fetchOne(db, sql: \"SELECT 42 WHERE FALSE\") // .none\n> // One row with a NULL value:\n> try Optional<Int>.fetchOne(db, sql: \"SELECT NULL\")           // .some(.none)\n> // One row with a non-NULL value:\n> try Optional<Int>.fetchOne(db, sql: \"SELECT 42\")             // .some(.some(42))\n> ```\n\nThere are many supported value types (Bool, Int, String, Date, Swift enums, etc.). See [Values](#values) for more information.\n\n\n## Values\n\nGRDB ships with built-in support for the following value types:\n\n- **Swift Standard Library**: Bool, Double, Float, all signed and unsigned integer types, String, [Swift enums](#swift-enums).\n    \n- **Foundation**: [Data](#data-and-memory-savings), [Date](#date-and-datecomponents), [DateComponents](#date-and-datecomponents), [Decimal](#nsnumber-nsdecimalnumber-and-decimal), NSNull, [NSNumber](#nsnumber-nsdecimalnumber-and-decimal), NSString, URL, [UUID](#uuid).\n    \n- **CoreGraphics**: CGFloat.\n\n- **[DatabaseValue](#databasevalue)**, the type which gives information about the raw value stored in the database.\n\n- **Full-Text Patterns**: [FTS3Pattern](Documentation/FullTextSearch.md#fts3pattern) and [FTS5Pattern](Documentation/FullTextSearch.md#fts5pattern).\n\n- Generally speaking, all types that adopt the [`DatabaseValueConvertible`] protocol.\n\nValues can be used as [statement arguments](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statementarguments):\n\n```swift\nlet url: URL = ...\nlet verified: Bool = ...\ntry db.execute(\n    sql: \"INSERT INTO link (url, verified) VALUES (?, ?)\",\n    arguments: [url, verified])\n```\n\nValues can be [extracted from rows](#column-values):\n\n```swift\nlet rows = try Row.fetchCursor(db, sql: \"SELECT * FROM link\")\nwhile let row = try rows.next() {\n    let url: URL = row[\"url\"]\n    let verified: Bool = row[\"verified\"]\n}\n```\n\nValues can be [directly fetched](#value-queries):\n\n```swift\nlet urls = try URL.fetchAll(db, sql: \"SELECT url FROM link\")  // [URL]\n```\n\nUse values in [Records](#records):\n\n```swift\nstruct Link: FetchableRecord {\n    var url: URL\n    var isVerified: Bool\n    \n    init(row: Row) {\n        url = row[\"url\"]\n        isVerified = row[\"verified\"]\n    }\n}\n```\n\nUse values in the [query interface](#the-query-interface):\n\n```swift\nlet url: URL = ...\nlet link = try Link.filter { $0.url == url }.fetchOne(db)\n```\n\n\n### Data (and Memory Savings)\n\n**Data** suits the BLOB SQLite columns. It can be stored and fetched from the database just like other [values](#values):\n\n```swift\nlet rows = try Row.fetchCursor(db, sql: \"SELECT data, ...\")\nwhile let row = try rows.next() {\n    let data: Data = row[\"data\"]\n}\n```\n\nAt each step of the request iteration, the `row[]` subscript creates *two copies* of the database bytes: one fetched by SQLite, and another, stored in the Swift Data value.\n\n**You have the opportunity to save memory** by not copying the data fetched by SQLite:\n\n```swift\nwhile let row = try rows.next() {\n    try row.withUnsafeData(name: \"data\") { (data: Data?) in\n        ...\n    }\n}\n```\n\nThe non-copied data does not live longer than the iteration step: make sure that you do not use it past this point.\n\n\n### Date and DateComponents\n\n[**Date**](#date) and [**DateComponents**](#datecomponents) can be stored and fetched from the database.\n\nHere is how GRDB supports the various [date formats](https://www.sqlite.org/lang_datefunc.html) supported by SQLite:\n\n| SQLite format                | Date               | DateComponents |\n|:---------------------------- |:------------------:|:--------------:|\n| YYYY-MM-DD                   |       Read ¬π       | Read / Write   |\n| YYYY-MM-DD HH:MM             |       Read ¬π ¬≤     | Read ¬≤ / Write |\n| YYYY-MM-DD HH:MM:SS          |       Read ¬π ¬≤     | Read ¬≤ / Write |\n| YYYY-MM-DD HH:MM:SS.SSS      | Read ¬π ¬≤ / Write ¬π | Read ¬≤ / Write |\n| YYYY-MM-DD**T**HH:MM         |       Read ¬π ¬≤     |      Read ¬≤    |\n| YYYY-MM-DD**T**HH:MM:SS      |       Read ¬π ¬≤     |      Read ¬≤    |\n| YYYY-MM-DD**T**HH:MM:SS.SSS  |       Read ¬π ¬≤     |      Read ¬≤    |\n| HH:MM                        |                    | Read ¬≤ / Write |\n| HH:MM:SS                     |                    | Read ¬≤ / Write |\n| HH:MM:SS.SSS                 |                    | Read ¬≤ / Write |\n| Timestamps since unix epoch  |       Read ¬≥       |                |\n| `now`                        |                    |                |\n\n¬π Missing components are assumed to be zero. Dates are stored and read in the UTC time zone, unless the format is followed by a timezone indicator ‚ÅΩ¬≤‚Åæ.\n\n¬≤ This format may be optionally followed by a timezone indicator of the form `[+-]HH:MM` or just `Z`.\n\n¬≥ GRDB 2+ interprets numerical values as timestamps that fuel `Date(timeIntervalSince1970:)`. Previous GRDB versions used to interpret numbers as [julian days](https://en.wikipedia.org/wiki/Julian_day). Julian days are still supported, with the `Date(julianDay:)` initializer.\n\n> **Warning**: the range of valid years in the SQLite date formats is 0000-9999. You will need to pick another date format when your application needs to process years outside of this range. See the following chapters.\n\n\n#### Date\n\n**Date** can be stored and fetched from the database just like other [values](#values):\n\n```swift\ntry db.execute(\n    sql: \"INSERT INTO player (creationDate, ...) VALUES (?, ...)\",\n    arguments: [Date(), ...])\n\nlet row = try Row.fetchOne(db, ...)!\nlet creationDate: Date = row[\"creationDate\"]\n```\n\nDates are stored using the format \"YYYY-MM-DD HH:MM:SS.SSS\" in the UTC time zone. It is precise to the millisecond.\n\n> **Note**: this format was chosen because it is the only format that is:\n> \n> - Comparable (`ORDER BY date` works)\n> - Comparable with the SQLite keyword CURRENT_TIMESTAMP (`WHERE date > CURRENT_TIMESTAMP` works)\n> - Able to feed [SQLite date & time functions](https://www.sqlite.org/lang_datefunc.html)\n> - Precise enough\n>\n> **Warning**: the range of valid years in the SQLite date format is 0000-9999. You will experience problems with years outside of this range, such as decoding errors, or invalid date computations with [SQLite date & time functions](https://www.sqlite.org/lang_datefunc.html).\n\nSome applications may prefer another date format:\n\n- Some may prefer ISO-8601, with a `T` separator.\n- Some may prefer ISO-8601, with a time zone.\n- Some may need to store years beyond the 0000-9999 range.\n- Some may need sub-millisecond precision.\n- Some may need exact `Date` roundtrip.\n- Etc.\n\n**You should think twice before choosing a different date format:**\n\n- ISO-8601 is about *exchange and communication*, when SQLite is about *storage and data manipulation*. Sharing the same representation in your database and in JSON files only provides a superficial convenience, and should be the least of your priorities. Don't store dates as ISO-8601 without understanding what you lose. For example, ISO-8601 time zones forbid database-level date comparison. \n- Sub-millisecond precision and exact `Date` roundtrip are not as obvious needs as it seems at first sight. Dates generally don't precisely roundtrip as soon as they leave your application anyway, because the other systems your app communicates with use their own date representation (the Android version of your app, the server your application is talking to, etc.) On top of that, `Date` comparison is at least as hard and nasty as [floating point comparison](https://www.google.com/search?q=floating+point+comparison+is+hard).\n\nThe customization of date format is explicit. For example:\n\n```swift\nlet date = Date()\nlet timeInterval = date.timeIntervalSinceReferenceDate\ntry db.execute(\n    sql: \"INSERT INTO player (creationDate, ...) VALUES (?, ...)\",\n    arguments: [timeInterval, ...])\n\nif let row = try Row.fetchOne(db, ...) {\n    let timeInterval: TimeInterval = row[\"creationDate\"]\n    let creationDate = Date(timeIntervalSinceReferenceDate: timeInterval)\n}\n```\n\nSee also [Codable Records] for more date customization options, and [`DatabaseValueConvertible`] if you want to define a Date-wrapping type with customized database representation.\n\n\n#### DateComponents\n\nDateComponents is indirectly supported, through the **DatabaseDateComponents** helper type.\n\nDatabaseDateComponents reads date components from all [date formats supported by SQLite](https://www.sqlite.org/lang_datefunc.html), and stores them in the format of your choice, from HH:MM to YYYY-MM-DD HH:MM:SS.SSS.\n\n> **Warning**: the range of valid years is 0000-9999. You will experience problems with years outside of this range, such as decoding errors, or invalid date computations with [SQLite date & time functions](https://www.sqlite.org/lang_datefunc.html). See [Date](#date) for more information.\n\nDatabaseDateComponents can be stored and fetched from the database just like other [values](#values):\n\n```swift\nlet components = DateComponents()\ncomponents.year = 1973\ncomponents.month = 9\ncomponents.day = 18\n\n// Store \"1973-09-18\"\nlet dbComponents = DatabaseDateComponents(components, format: .YMD)\ntry db.execute(\n    sql: \"INSERT INTO player (birthDate, ...) VALUES (?, ...)\",\n    arguments: [dbComponents, ...])\n\n// Read \"1973-09-18\"\nlet row = try Row.fetchOne(db, sql: \"SELECT birthDate ...\")!\nlet dbComponents: DatabaseDateComponents = row[\"birthDate\"]\ndbComponents.format         // .YMD (the actual format found in the database)\ndbComponents.dateComponents // DateComponents\n```\n\n\n### NSNumber, NSDecimalNumber, and Decimal\n\n**NSNumber** and **Decimal** can be stored and fetched from the database just like other [values](#values).\n\nHere is how GRDB supports the various data types supported by SQLite:\n\n|                 |    Integer   |     Double   |    String    |\n|:--------------- |:------------:|:------------:|:------------:|\n| NSNumber        | Read / Write | Read / Write |     Read     |\n| NSDecimalNumber | Read / Write | Read / Write |     Read     |\n| Decimal         |     Read     |     Read     | Read / Write |\n\n- All three types can decode database integers and doubles:\n\n    ```swift\n    let number = try NSNumber.fetchOne(db, sql: \"SELECT 10\")            // NSNumber\n    let number = try NSDecimalNumber.fetchOne(db, sql: \"SELECT 1.23\")   // NSDecimalNumber\n    let number = try Decimal.fetchOne(db, sql: \"SELECT -100\")           // Decimal\n    ```\n    \n- All three types decode database strings as decimal numbers:\n\n    ```swift\n    let number = try NSNumber.fetchOne(db, sql: \"SELECT '10'\")          // NSDecimalNumber (sic)\n    let number = try NSDecimalNumber.fetchOne(db, sql: \"SELECT '1.23'\") // NSDecimalNumber\n    let number = try Decimal.fetchOne(db, sql: \"SELECT '-100'\")         // Decimal\n    ```\n\n- `NSNumber` and `NSDecimalNumber` send 64-bit signed integers and doubles in the database:\n\n    ```swift\n    // INSERT INTO transfer VALUES (10)\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [NSNumber(value: 10)])\n    \n    // INSERT INTO transfer VALUES (10.0)\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [NSNumber(value: 10.0)])\n    \n    // INSERT INTO transfer VALUES (10)\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [NSDecimalNumber(string: \"10.0\")])\n    \n    // INSERT INTO transfer VALUES (10.5)\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [NSDecimalNumber(string: \"10.5\")])\n    ```\n    \n    > **Warning**: since SQLite does not support decimal numbers, sending a non-integer `NSDecimalNumber` can result in a loss of precision during the conversion to double.\n    >\n    > Instead of sending non-integer `NSDecimalNumber` to the database, you may prefer:\n    >\n    > - Send `Decimal` instead (those store decimal strings in the database).\n    > - Send integers instead (for example, store amounts of cents instead of amounts of Euros).\n\n- `Decimal` sends decimal strings in the database:\n\n    ```swift\n    // INSERT INTO transfer VALUES ('10')\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [Decimal(10)])\n    \n    // INSERT INTO transfer VALUES ('10.5')\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [Decimal(string: \"10.5\")!])\n    ```\n\n\n### UUID\n\n**UUID** can be stored and fetched from the database just like other [values](#values).\n\nGRDB stores uuids as 16-bytes data blobs, and decodes them from both 16-bytes data blobs and strings such as \"E621E1F8-C36C-495A-93FC-0C247A3E6E5F\".\n\n\n### Swift Enums\n\n**Swift enums** and generally all types that adopt the [RawRepresentable](https://developer.apple.com/library/tvos/documentation/Swift/Reference/Swift_RawRepresentable_Protocol/index.html) protocol can be stored and fetched from the database just like their raw [values](#values):\n\n```swift\nenum Color : Int {\n    case red, white, rose\n}\n\nenum Grape : String {\n    case chardonnay, merlot, riesling\n}\n\n// Declare empty DatabaseValueConvertible adoption\nextension Color : DatabaseValueConvertible { }\nextension Grape : DatabaseValueConvertible { }\n\n// Store\ntry db.execute(\n    sql: \"INSERT INTO wine (grape, color) VALUES (?, ?)\",\n    arguments: [Grape.merlot, Color.red])\n\n// Read\nlet rows = try Row.fetchCursor(db, sql: \"SELECT * FROM wine\")\nwhile let row = try rows.next() {\n    let grape: Grape = row[\"grape\"]\n    let color: Color = row[\"color\"]\n}\n```\n\n**When a database value does not match any enum case**, you get a fatal error. This fatal error can be avoided with the [DatabaseValue](#databasevalue) type:\n\n```swift\nlet row = try Row.fetchOne(db, sql: \"SELECT 'syrah'\")!\n\nrow[0] as String  // \"syrah\"\nrow[0] as Grape?  // fatal error: could not convert \"syrah\" to Grape.\nrow[0] as Grape   // fatal error: could not convert \"syrah\" to Grape.\n\nlet dbValue: DatabaseValue = row[0]\nif dbValue.isNull {\n    // Handle NULL\n} else if let grape = Grape.fromDatabaseValue(dbValue) {\n    // Handle valid grape\n} else {\n    // Handle unknown grape\n}\n```\n\n\n## Custom SQL Functions and Aggregates\n\n**SQLite lets you define SQL functions and aggregates.**\n\nA custom SQL function or aggregate extends SQLite:\n\n```sql\nSELECT reverse(name) FROM player;   -- custom function\nSELECT maxLength(name) FROM player; -- custom aggregate\n```\n\n- [Custom SQL Functions](#custom-sql-functions)\n- [Custom Aggregates](#custom-aggregates)\n\n\n### Custom SQL Functions\n\nüìñ [`DatabaseFunction`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasefunction)\n\nA *function* argument takes an array of [DatabaseValue](#databasevalue), and returns any valid [value](#values) (Bool, Int, String, Date, Swift enums, etc.) The number of database values is guaranteed to be *argumentCount*.\n\nSQLite has the opportunity to perform additional optimizations when functions are \"pure\", which means that their result only depends on their arguments. So make sure to set the *pure* argument to true when possible.\n\n```swift\nlet reverse = DatabaseFunction(\"reverse\", argumentCount: 1, pure: true) { (values: [DatabaseValue]) in\n    // Extract string value, if any...\n    guard let string = String.fromDatabaseValue(values[0]) else {\n        return nil\n    }\n    // ... and return reversed string:\n    return String(string.reversed())\n}\n```\n\nYou make a function available to a database connection through its configuration:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.add(function: reverse)\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n\ntry dbQueue.read { db in\n    // \"oof\"\n    try String.fetchOne(db, sql: \"SELECT reverse('foo')\")!\n}\n```\n\n\n**Functions can take a variable number of arguments:**\n\nWhen you don't provide any explicit *argumentCount*, the function can take any number of arguments:\n\n```swift\nlet averageOf = DatabaseFunction(\"averageOf\", pure: true) { (values: [DatabaseValue]) in\n    let doubles = values.compactMap { Double.fromDatabaseValue($0) }\n    return doubles.reduce(0, +) / Double(doubles.count)\n}\ndb.add(function: averageOf)\n\n// 2.0\ntry Double.fetchOne(db, sql: \"SELECT averageOf(1, 2, 3)\")!\n```\n\n\n**Functions can throw:**\n\n```swift\nlet sqrt = DatabaseFunction(\"sqrt\", argumentCount: 1, pure: true) { (values: [DatabaseValue]) in\n    guard let double = Double.fromDatabaseValue(values[0]) else {\n        return nil\n    }\n    guard double >= 0 else {\n        throw DatabaseError(message: \"invalid negative number\")\n    }\n    return sqrt(double)\n}\ndb.add(function: sqrt)\n\n// SQLite error 1 with statement `SELECT sqrt(-1)`: invalid negative number\ntry Double.fetchOne(db, sql: \"SELECT sqrt(-1)\")!\n```\n\n\n**Use custom functions in the [query interface](#the-query-interface):**\n\n```swift\n// SELECT reverseString(\"name\") FROM player\nPlayer.select { reverseString($0.name) }\n```\n\n\n**GRDB ships with built-in SQL functions that perform unicode-aware string transformations.** See [Unicode](#unicode).\n\n\n### Custom Aggregates\n\nüìñ [`DatabaseFunction`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasefunction), [`DatabaseAggregate`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseaggregate)\n\nBefore registering a custom aggregate, you need to define a type that adopts the `DatabaseAggregate` protocol:\n\n```swift\nprotocol DatabaseAggregate {\n    // Initializes an aggregate\n    init()\n    \n    // Called at each step of the aggregation\n    mutating func step(_ dbValues: [DatabaseValue]) throws\n    \n    // Returns the final result\n    func finalize() throws -> DatabaseValueConvertible?\n}\n```\n\nFor example:\n\n```swift\nstruct MaxLength : DatabaseAggregate {\n    var maxLength: Int = 0\n    \n    mutating func step(_ dbValues: [DatabaseValue]) {\n        // At each step, extract string value, if any...\n        guard let string = String.fromDatabaseValue(dbValues[0]) else {\n            return\n        }\n        // ... and update the result\n        let length = string.count\n        if length > maxLength {\n            maxLength = length\n        }\n    }\n    \n    func finalize() -> DatabaseValueConvertible? {\n        maxLength\n    }\n}\n\nlet maxLength = DatabaseFunction(\n    \"maxLength\",\n    argumentCount: 1,\n    pure: true,\n    aggregate: MaxLength.self)\n```\n\nLike [custom SQL Functions](#custom-sql-functions), you make an aggregate function available to a database connection through its configuration:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.add(function: maxLength)\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n\ntry dbQueue.read { db in\n    // Some Int\n    try Int.fetchOne(db, sql: \"SELECT maxLength(name) FROM player\")!\n}\n```\n\nThe `step` method of the aggregate takes an array of [DatabaseValue](#databasevalue). This array contains as many values as the *argumentCount* parameter (or any number of values, when *argumentCount* is omitted).\n\nThe `finalize` method of the aggregate returns the final aggregated [value](#values) (Bool, Int, String, Date, Swift enums, etc.).\n\nSQLite has the opportunity to perform additional optimizations when aggregates are \"pure\", which means that their result only depends on their inputs. So make sure to set the *pure* argument to true when possible.\n\n\n**Use custom aggregates in the [query interface](#the-query-interface):**\n\n```swift\n// SELECT maxLength(\"name\") FROM player\nlet request = Player.select { maxLength($0.name) }\ntry Int.fetchOne(db, request) // Int?\n```\n\n\n## Raw SQLite Pointers\n\n**If not all SQLite APIs are exposed in GRDB, you can still use the [SQLite C Interface](https://www.sqlite.org/c3ref/intro.html) and call [SQLite C functions](https://www.sqlite.org/c3ref/funclist.html).**\n\nTo access the C SQLite functions from SQLCipher or the system SQLite, you need to perform an extra import:\n\n```swift\nimport SQLite3   // System SQLite\nimport SQLCipher // SQLCipher\n\nlet sqliteVersion = String(cString: sqlite3_libversion())\n```\n\nRaw pointers to database connections and statements are available through the `Database.sqliteConnection` and `Statement.sqliteStatement` properties:\n\n```swift\ntry dbQueue.read { db in\n    // The raw pointer to a database connection:\n    let sqliteConnection = db.sqliteConnection\n\n    // The raw pointer to a statement:\n    let statement = try db.makeStatement(sql: \"SELECT ...\")\n    let sqliteStatement = statement.sqliteStatement\n}\n```\n\n> **Note**\n>\n> - Those pointers are owned by GRDB: don't close connections or finalize statements created by GRDB.\n> - GRDB opens SQLite connections in the \"[multi-thread mode](https://www.sqlite.org/threadsafe.html)\", which (oddly) means that **they are not thread-safe**. Make sure you touch raw databases and statements inside their dedicated dispatch queues.\n> - Use the raw SQLite C Interface at your own risk. GRDB won't prevent you from shooting yourself in the foot.\n\n\nRecords\n=======\n\n**On top of the [SQLite API](#sqlite-api), GRDB provides protocols** that help manipulating database rows as regular objects named \"records\":\n\n```swift\ntry dbQueue.write { db in\n    if var place = try Player.fetchOne(db, id: 1) {\n        player.score += 10\n        try player.update(db)\n    }\n}\n```\n\nOf course, you need to open a [database connection], and [create database tables](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseschema) first.\n\nTo define a record type, define a type and extend it with database protocols:\n\n- `FetchableRecord` makes it possible to fetch instances from the database.\n- `PersistableRecord` makes it possible to save instances into the database.\n- `Codable` (not mandatory) provides ready-made serialization to and from database rows.\n- `Identifiable` (not mandatory) provides extra convenience database methods.\n\nTo make it easier to customize database requests, also nest a `Columns` enum: \n\n```swift\nstruct Player: Codable, Identifiable {\n    var id: Int64\n    var name: String\n    var score: Int\n    var team: String?\n}\n\n// Add database support\nextension Player: FetchableRecord, PersistableRecord {\n    enum Columns {\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n        static let team = Column(CodingKeys.team)\n    }\n}\n```\n\nSee more [examples of record definitions](#examples-of-record-definitions) below.\n\n> Note: if you are familiar with Core Data's NSManagedObject or Realm's Object, you may experience a cultural shock: GRDB records are not uniqued, do not auto-update, and do not lazy-load. This is both a purpose, and a consequence of protocol-oriented programming.\n>\n> Tip: The [Recommended Practices for Designing Record Types](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recordrecommendedpractices) guide provides general guidance..\n>\n> Tip: See the [Demo Applications] for sample apps that uses records.\n\n**Overview**\n\n- [Inserting Records](#inserting-records)\n- [Fetching Records](#fetching-records)\n- [Updating Records](#updating-records)\n- [Deleting Records](#deleting-records)\n- [Counting Records](#counting-records)\n\n**Protocols and the Record Class**\n\n- [Record Protocols Overview](#record-protocols-overview)\n- [FetchableRecord Protocol](#fetchablerecord-protocol)\n- [TableRecord Protocol](#tablerecord-protocol)\n- [PersistableRecord Protocol](#persistablerecord-protocol)\n    - [Persistence Methods]\n    - [Persistence Methods and the `RETURNING` clause]\n    - [Persistence Callbacks]\n- [Identifiable Records]\n- [Codable Records]\n- [Record Comparison]\n- [Record Customization Options]\n- [Record Timestamps and Transaction Date]\n\n\n### Inserting Records\n\nTo insert a record in the database, call the `insert` method:\n\n```swift\nlet player = Player(id: 1, name: \"Arthur\", score: 1000)\ntry player.insert(db)\n```\n\n:point_right: `insert` is available for types that adopt the [PersistableRecord] protocol.\n\n\n### Fetching Records\n\nTo fetch records from the database, call a [fetching method](#fetching-methods):\n\n```swift\nlet arthur = try Player.fetchOne(db,            // Player?\n    sql: \"SELECT * FROM players WHERE name = ?\",\n    arguments: [\"Arthur\"])\n\nlet bestPlayers = try Player                    // [Player]\n    .order(\\.score.desc)\n    .limit(10)\n    .fetchAll(db)\n    \nlet spain = try Country.fetchOne(db, id: \"ES\")  // Country?\nlet italy = try Country.find(db, id: \"IT\")      // Country\n```\n\n:point_right: Fetching from raw SQL is available for types that adopt the [FetchableRecord] protocol.\n\n:point_right: Fetching without SQL, using the [query interface](#the-query-interface), is available for types that adopt both [FetchableRecord] and [TableRecord] protocol.\n\n\n### Updating Records\n\nTo update a record in the database, call the `update` method:\n\n```swift\nvar player: Player = ...\nplayer.score = 1000\ntry player.update(db)\n```\n\nIt is possible to [avoid useless updates](#record-comparison):\n\n```swift\n// does not hit the database if score has not changed\ntry player.updateChanges(db) {\n    $0.score = 1000\n}\n```\n\nSee the [query interface](#the-query-interface) for batch updates:\n\n```swift\ntry Player\n    .filter { $0.team == \"red\" }\n    .updateAll(db) { $0.score += 1 }\n```\n\n:point_right: update methods are available for types that adopt the [PersistableRecord] protocol. Batch updates are available on the [TableRecord] protocol.\n\n\n### Deleting Records\n\nTo delete a record in the database, call the `delete` method:\n\n```swift\nlet player: Player = ...\ntry player.delete(db)\n```\n\nYou can also delete by primary key, unique key, or perform batch deletes (see [Delete Requests](#delete-requests)):\n\n```swift\ntry Player.deleteOne(db, id: 1)\ntry Player.deleteOne(db, key: [\"email\": \"arthur@example.com\"])\ntry Country.deleteAll(db, ids: [\"FR\", \"US\"])\ntry Player\n    .filter { $0.email == nil }\n    .deleteAll(db)\n```\n\n:point_right: delete methods are available for types that adopt the [PersistableRecord] protocol. Batch deletes are available on the [TableRecord] protocol.\n\n\n### Counting Records\n\nTo count records, call the `fetchCount` method:\n\n```swift\nlet playerCount: Int = try Player.fetchCount(db)\n\nlet playerWithEmailCount: Int = try Player\n    .filter { $0.email == nil }\n    .fetchCount(db)\n```\n\n:point_right: `fetchCount` is available for types that adopt the [TableRecord] protocol.\n\n\nDetails follow:\n\n- [Record Protocols Overview](#record-protocols-overview)\n- [FetchableRecord Protocol](#fetchablerecord-protocol)\n- [TableRecord Protocol](#tablerecord-protocol)\n- [PersistableRecord Protocol](#persistablerecord-protocol)\n- [Identifiable Records]\n- [Codable Records]\n- [Record Comparison]\n- [Record Customization Options]\n- [Examples of Record Definitions](#examples-of-record-definitions)\n\n\n## Record Protocols Overview\n\n**GRDB ships with three record protocols**. Your own types will adopt one or several of them, according to the abilities you want to extend your types with.\n\n- [FetchableRecord] is able to **decode database rows**.\n    \n    ```swift\n    struct Place: FetchableRecord { ... }\n    \n    let places = try dbQueue.read { db in\n        try Place.fetchAll(db, sql: \"SELECT * FROM place\")\n    }\n    ```\n    \n    > :bulb: **Tip**: `FetchableRecord` can derive its implementation from the standard `Decodable` protocol. See [Codable Records] for more information.\n    \n    `FetchableRecord` can decode database rows, but it is not able to build SQL requests for you. For that, you also need `TableRecord`:\n    \n- [TableRecord] is able to **generate SQL queries**:\n    \n    ```swift\n    struct Place: TableRecord { ... }\n    \n    let placeCount = try dbQueue.read { db in\n        // Generates and runs `SELECT COUNT(*) FROM place`\n        try Place.fetchCount(db)\n    }\n    ```\n    \n    When a type adopts both `TableRecord` and `FetchableRecord`, it can load from those requests:\n    \n    ```swift\n    struct Place: TableRecord, FetchableRecord { ... }\n    \n    try dbQueue.read { db in\n        let places = try Place.order(\\.title).fetchAll(db)\n        let paris = try Place.fetchOne(id: 1)\n    }\n    ```\n\n- [PersistableRecord] is able to **write**: it can create, update, and delete rows in the database:\n    \n    ```swift\n    struct Place : PersistableRecord { ... }\n    \n    try dbQueue.write { db in\n        try Place.delete(db, id: 1)\n        try Place(...).insert(db)\n    }\n    ```\n    \n    A persistable record can also [compare](#record-comparison) itself against other records, and avoid useless database updates.\n    \n    > :bulb: **Tip**: `PersistableRecord` can derive its implementation from the standard `Encodable` protocol. See [Codable Records] for more information.\n\n\n## FetchableRecord Protocol\n\nüìñ [`FetchableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/fetchablerecord)\n\n**The FetchableRecord protocol grants fetching methods to any type** that can be built from a database row:\n\n```swift\nprotocol FetchableRecord {\n    /// Row initializer\n    init(row: Row) throws\n}\n```\n\nFor example:\n\n```swift\nstruct Place {\n    var id: Int64?\n    var title: String\n    var coordinate: CLLocationCoordinate2D\n}\n\nextension Place: FetchableRecord {\n    enum Columns {\n        static let id = Column(\"id\")\n        static let title = Column(\"title\")\n        static let latitude = Column(\"latitude\")\n        static let longitude = Column(\"longitude\")\n    }\n    \n    init(row: Row) {\n        id = row[Columns.id]\n        title = row[Columns.title]\n        coordinate = CLLocationCoordinate2D(\n            latitude: row[Columns.latitude],\n            longitude: row[Columns.longitude])\n    }\n}\n```\n\nSee [column values](#column-values) for more information about the `row[]` subscript.\n\nWhen your record type adopts the standard Decodable protocol, you don't have to provide the implementation for `init(row:)`. See [Codable Records] for more information:\n\n```swift\n// That's all\nstruct Player: Decodable, FetchableRecord {\n    var id: Int64\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n```\n\nFetchableRecord allows adopting types to be fetched from SQL queries:\n\n```swift\ntry Place.fetchCursor(db, sql: \"SELECT ...\", arguments:...) // A Cursor of Place\ntry Place.fetchAll(db, sql: \"SELECT ...\", arguments:...)    // [Place]\ntry Place.fetchSet(db, sql: \"SELECT ...\", arguments:...)    // Set<Place>\ntry Place.fetchOne(db, sql: \"SELECT ...\", arguments:...)    // Place?\n```\n\nSee [fetching methods](#fetching-methods) for information about the `fetchCursor`, `fetchAll`, `fetchSet` and `fetchOne` methods. See [`StatementArguments`] for more information about the query arguments.\n\n> **Note**: for performance reasons, the same row argument to `init(row:)` is reused during the iteration of a fetch query. If you want to keep the row for later use, make sure to store a copy: `self.row = row.copy()`.\n\n> **Note**: The `FetchableRecord.init(row:)` initializer fits the needs of most applications. But some application are more demanding than others. When FetchableRecord does not exactly provide the support you need, have a look at the [Beyond FetchableRecord] chapter.\n\n\n## TableRecord Protocol\n\nüìñ [`TableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerecord)\n\n**The TableRecord protocol** generates SQL for you:\n\n```swift\nprotocol TableRecord {\n    static var databaseTableName: String { get }\n    static var databaseSelection: [any SQLSelectable] { get }\n}\n```\n\nThe `databaseSelection` type property is optional, and documented in the [Columns Selected by a Request] chapter.\n\nThe `databaseTableName` type property is the name of a database table. By default, it is derived from the type name:\n\n```swift\nstruct Place: TableRecord { }\n\nprint(Place.databaseTableName) // prints \"place\"\n```\n\nFor example:\n\n- Place: `place`\n- Country: `country`\n- PostalAddress: `postalAddress`\n- HTTPRequest: `httpRequest`\n- TOEFL: `toefl`\n\nYou can still provide a custom table name:\n\n```swift\nstruct Place: TableRecord {\n    static let databaseTableName = \"location\"\n}\n\nprint(Place.databaseTableName) // prints \"location\"\n```\n\nWhen a type adopts both TableRecord and [FetchableRecord](#fetchablerecord-protocol), it can be fetched using the [query interface](#the-query-interface):\n\n```swift\n// SELECT * FROM place WHERE name = 'Paris'\nlet paris = try Place.filter { $0.name == \"Paris\" }.fetchOne(db)\n```\n\nTableRecord can also fetch deal with primary and unique keys: see [Fetching by Key](#fetching-by-key) and [Testing for Record Existence](#testing-for-record-existence).\n\n\n## PersistableRecord Protocol\n\nüìñ [`EncodableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/encodablerecord), [`MutablePersistableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/mutablepersistablerecord), [`PersistableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/persistablerecord)\n\n**GRDB record types can create, update, and delete rows in the database.**\n\nThose abilities are granted by three protocols:\n\n```swift\n// Defines how a record encodes itself into the database\nprotocol EncodableRecord {\n    /// Defines the values persisted in the database\n    func encode(to container: inout PersistenceContainer) throws\n}\n\n// Adds persistence methods\nprotocol MutablePersistableRecord: TableRecord, EncodableRecord {\n    /// Optional method that lets your adopting type store its rowID upon\n    /// successful insertion. Don't call it directly: it is called for you.\n    mutating func didInsert(_ inserted: InsertionSuccess)\n}\n\n// Adds immutability\nprotocol PersistableRecord: MutablePersistableRecord {\n    /// Non-mutating version of the optional didInsert(_:)\n    func didInsert(_ inserted: InsertionSuccess)\n}\n```\n\nYes, three protocols instead of one. Here is how you pick one or the other:\n\n- **If your type is a class**, choose `PersistableRecord`. On top of that, implement `didInsert(_:)` if the database table has an auto-incremented primary key.\n\n- **If your type is a struct, and the database table has an auto-incremented primary key**, choose `MutablePersistableRecord`, and implement `didInsert(_:)`.\n\n- **Otherwise**, choose `PersistableRecord`, and ignore `didInsert(_:)`.\n\nThe `encode(to:)` method defines which [values](#values) (Bool, Int, String, Date, Swift enums, etc.) are assigned to database columns.\n\nThe optional `didInsert` method lets the adopting type store its rowID after successful insertion, and is only useful for tables that have an auto-incremented primary key. It is called from a protected dispatch queue, and serialized with all database updates.\n\nFor example:\n\n```swift\nextension Place: MutablePersistableRecord {\n    enum Columns {\n        static let id = Column(\"id\")\n        static let title = Column(\"title\")\n        static let latitude = Column(\"latitude\")\n        static let longitude = Column(\"longitude\")\n    }\n    \n    /// The values persisted in the database\n    func encode(to container: inout PersistenceContainer) {\n        container[Columns.id] = id\n        container[Columns.title] = title\n        container[Columns.latitude] = coordinate.latitude\n        container[Columns.longitude] = coordinate.longitude\n    }\n    \n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n\nvar paris = Place(\n    id: nil,\n    title: \"Paris\",\n    coordinate: CLLocationCoordinate2D(latitude: 48.8534100, longitude: 2.3488000))\n\ntry paris.insert(db)\nparis.id   // some value\n```\n\nWhen your record type adopts the standard Encodable protocol, you don't have to provide the implementation for `encode(to:)`. See [Codable Records] for more information:\n\n```swift\n// That's all\nstruct Player: Encodable, MutablePersistableRecord {\n    var id: Int64?\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n    \n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n```\n\n\n### Persistence Methods\n\nTypes that adopt the [PersistableRecord] protocol are given methods that insert, update, and delete:\n\n```swift\n// INSERT\ntry place.insert(db)\nlet insertedPlace = try place.inserted(db) // non-mutating\n\n// UPDATE\ntry place.update(db)\ntry place.update(db, columns: [\"title\"])\n\n// Maybe UPDATE\ntry place.updateChanges(db, from: otherPlace)\ntry place.updateChanges(db) { $0.isFavorite = true }\n\n// INSERT or UPDATE\ntry place.save(db)\nlet savedPlace = place.saved(db) // non-mutating\n\n// UPSERT\ntry place.upsert(db)\nlet insertedPlace = place.upsertAndFetch(db)\n\n// DELETE\ntry place.delete(db)\n\n// EXISTENCE CHECK\nlet exists = try place.exists(db)\n```\n\nSee [Upsert](#upsert) below for more information about upserts.\n\n**The [TableRecord] protocol comes with batch operations**:\n\n```swift\n// UPDATE\ntry Place.updateAll(db, ...)\n\n// DELETE\ntry Place.deleteAll(db)\ntry Place.deleteAll(db, ids:...)\ntry Place.deleteAll(db, keys:...)\ntry Place.deleteOne(db, id:...)\ntry Place.deleteOne(db, key:...)\n```\n\nFor more information about batch updates, see [Update Requests](#update-requests).\n\n- All persistence methods can throw a [DatabaseError](#error-handling).\n\n- `update` and `updateChanges` throw [RecordError] if the database does not contain any row for the primary key of the record.\n\n- `save` makes sure your values are stored in the database. It performs an UPDATE if the record has a non-null primary key, and then, if no row was modified, an INSERT. It directly performs an INSERT if the record has no primary key, or a null primary key.\n\n- `delete` and `deleteOne` returns whether a database row was deleted or not. `deleteAll` returns the number of deleted rows. `updateAll` returns the number of updated rows. `updateChanges` returns whether a database row was updated or not.\n\n**All primary keys are supported**, including composite primary keys that span several columns, and the [hidden `rowid` column](https://www.sqlite.org/rowidtable.html).\n\n**To customize persistence methods**, you provide [Persistence Callbacks], described below. Do not attempt at overriding the ready-made persistence methods.\n\n### Upsert\n\n[UPSERT](https://www.sqlite.org/lang_UPSERT.html) is an SQLite feature that causes an INSERT to behave as an UPDATE or a no-op if the INSERT would violate a uniqueness constraint (primary key or unique index).\n\n> **Note**: Upsert apis are available from SQLite 3.35.0+: iOS 15.0+, macOS 12.0+, tvOS 15.0+, watchOS 8.0+, or with a [custom SQLite build] or [SQLCipher](#encryption).\n>\n> **Note**: With regard to [persistence callbacks](#available-callbacks), an upsert behaves exactly like an insert. In particular: the `aroundInsert(_:)` and `didInsert(_:)` callbacks reports the rowid of the inserted or updated row; `willUpdate`, `aroundUpdate`, `didUpdate` are not called.\n\n[PersistableRecord] provides three upsert methods:\n\n- `upsert(_:)`\n    \n    Inserts or updates a record.\n    \n    The upsert behavior is triggered by a violation of any uniqueness constraint on the table (primary key or unique index). In case of conflict, all columns but the primary key are overwritten with the inserted values:\n    \n    ```swift\n    struct Player: Encodable, PersistableRecord {\n        var id: Int64\n        var name: String\n        var score: Int\n    }\n    \n    // INSERT INTO player (id, name, score)\n    // VALUES (1, 'Arthur', 1000)\n    // ON CONFLICT DO UPDATE SET\n    //   name = excluded.name,\n    //   score = excluded.score\n    let player = Player(id: 1, name: \"Arthur\", score: 1000)\n    try player.upsert(db)\n    ```\n\n- `upsertAndFetch(_:onConflict:doUpdate:)` (requires [FetchableRecord] conformance)\n\n    Inserts or updates a record, and returns the upserted record.\n    \n    The `onConflict` and `doUpdate` arguments let you further control the upsert behavior. Make sure you check the [SQLite UPSERT documentation](https://www.sqlite.org/lang_UPSERT.html) for detailed information.\n    \n    - `onConflict`: the \"conflict target\" is the array of columns in the uniqueness constraint (primary key or unique index) that triggers the upsert.\n        \n        If empty (the default), all uniqueness constraint are considered.\n    \n    - `doUpdate`: a closure that returns columns assignments to perform in case of conflict. Other columns are overwritten with the inserted values.\n        \n        By default, all inserted columns but the primary key and the conflict target are overwritten.\n    \n    In the example below, we upsert the new vocabulary word \"jovial\". It is inserted if that word is not already in the dictionary. Otherwise, `count` is incremented, `isTainted` is not overwritten, and `kind` is overwritten:\n    \n    ```swift\n    // CREATE TABLE vocabulary(\n    //   word TEXT NOT NULL PRIMARY KEY,\n    //   kind TEXT NOT NULL,\n    //   isTainted BOOLEAN DEFAULT 0,\n    //   count INT DEFAULT 1))\n    struct Vocabulary: Encodable, PersistableRecord {\n        var word: String\n        var kind: String\n        var isTainted: Bool\n    }\n    \n    // INSERT INTO vocabulary(word, kind, isTainted)\n    // VALUES('jovial', 'adjective', 0)\n    // ON CONFLICT(word) DO UPDATE SET \\\n    //   count = count + 1,   -- on conflict, count is incremented\n    //   kind = excluded.kind -- on conflict, kind is overwritten\n    // RETURNING *\n    let vocabulary = Vocabulary(word: \"jovial\", kind: \"adjective\", isTainted: false)\n    let upserted = try vocabulary.upsertAndFetch(\n        db, onConflict: [\"word\"],\n        doUpdate: { _ in\n            [Column(\"count\") += 1,            // on conflict, count is incremented\n             Column(\"isTainted\").noOverwrite] // on conflict, isTainted is NOT overwritten\n        })\n    ```\n    \n    The `doUpdate` closure accepts an `excluded` TableAlias argument that refers to the inserted values that trigger the conflict. You can use it to specify an explicit overwrite, or to perform a computation. In the next example, the upsert keeps the maximum date in case of conflict:\n    \n    ```swift\n    // INSERT INTO message(id, text, date)\n    // VALUES(...)\n    // ON CONFLICT DO UPDATE SET \\\n    //   text = excluded.text,\n    //   date = MAX(date, excluded.date)\n    // RETURNING *\n    let upserted = try message.upsertAndFetch(doUpdate: { excluded in\n        // keep the maximum date in case of conflict\n        [Column(\"date\").set(to: max(Column(\"date\"), excluded[\"date\"]))]\n    })\n    ```\n\n- `upsertAndFetch(_:as:onConflict:doUpdate:)` (does not require [FetchableRecord] conformance)\n\n    This method is identical to `upsertAndFetch(_:onConflict:doUpdate:)` described above, but you can provide a distinct [FetchableRecord] record type as a result, in order to specify the returned columns.\n\n### Persistence Methods and the `RETURNING` clause\n\nSQLite is able to return values from a inserted, updated, or deleted row, with the [`RETURNING` clause](https://www.sqlite.org/lang_returning.html).\n\n> **Note**: Support for the `RETURNING` clause is available from SQLite 3.35.0+: iOS 15.0+, macOS 12.0+, tvOS 15.0+, watchOS 8.0+, or with a [custom SQLite build] or [SQLCipher](#encryption).\n\nThe `RETURNING` clause helps dealing with database features such as auto-incremented ids, default values, and [generated columns](https://sqlite.org/gencol.html). You can, for example, insert a few columns and fetch the default or generated ones in one step.\n\nGRDB uses the `RETURNING` clause in all persistence methods that contain `AndFetch` in their name.\n\nFor example, given a database table with an auto-incremented primary key and a default score:\n\n```swift\ntry dbQueue.write { db in\n    try db.execute(sql: \"\"\"\n        CREATE TABLE player(\n          id INTEGER PRIMARY KEY AUTOINCREMENT,\n          name TEXT NOT NULL,\n          score INTEGER NOT NULL DEFAULT 1000)\n        \"\"\")\n}\n```\n\nYou can define a record type with full database information, and another partial record type that deals with a subset of columns:\n\n```swift\n// A player with full database information\nstruct Player: Codable, PersistableRecord, FetchableRecord {\n    var id: Int64\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n\n// A partial player\nstruct PartialPlayer: Encodable, PersistableRecord {\n    static let databaseTableName = \"player\"\n    var name: String\n    \n    typealias Columns = Player.Columns\n}\n```\n\nAnd now you can get a full player by inserting a partial one:\n\n```swift\ntry dbQueue.write { db in\n    let partialPlayer = PartialPlayer(name: \"Alice\")\n    \n    // INSERT INTO player (name) VALUES ('Alice') RETURNING *\n    let player = try partialPlayer.insertAndFetch(db, as: Player.self)\n    print(player.id)    // The inserted id\n    print(player.name)  // The inserted name\n    print(player.score) // The default score\n}\n```\n\nFor extra precision, you can select only the columns you need, and fetch the desired value from the provided prepared [`Statement`]:\n\n```swift\ntry dbQueue.write { db in\n    let partialPlayer = PartialPlayer(name: \"Alice\")\n    \n    // INSERT INTO player (name) VALUES ('Alice') RETURNING score\n    let score = try partialPlayer.insertAndFetch(db) { statement in\n        try Int.fetchOne(statement)\n    } select: {\n        [$0.score]\n    }\n    print(score) // Prints 1000, the default score\n}\n```\n\nThere are other similar persistence methods, such as `upsertAndFetch`, `saveAndFetch`, `updateAndFetch`, `updateChangesAndFetch`, etc. They all behave like `upsert`, `save`, `update`, `updateChanges`, except that they return saved values. For example:\n\n```swift\n// Save and return the saved player\nlet savedPlayer = try player.saveAndFetch(db)\n```\n\nSee [Persistence Methods], [Upsert](#upsert), and [`updateChanges` methods](#the-updatechanges-methods) for more information.\n\n**Batch operations** can return updated or deleted values:\n\n> **Warning**: Make sure you check the [documentation of the `RETURNING` clause](https://www.sqlite.org/lang_returning.html#limitations_and_caveats), which describes important limitations and caveats for batch operations.\n\n```swift\nlet request = Player.filter(...)...\n\n// Fetch all deleted players\n// DELETE FROM player RETURNING *\nlet deletedPlayers = try request.deleteAndFetchAll(db) // [Player]\n\n// Fetch a selection of columns from the deleted rows\n// DELETE FROM player RETURNING name\nlet statement = try request.deleteAndFetchStatement(db) { [$0.name] }\nlet deletedNames = try String.fetchSet(statement)\n\n// Fetch all updated players\n// UPDATE player SET score = score + 10 RETURNING *\nlet updatedPlayers = try request.updateAndFetchAll(db) { [$0.score += 10] } // [Player]\n\n// Fetch a selection of columns from the updated rows\n// UPDATE player SET score = score + 10 RETURNING score\nlet statement = try request.updateAndFetchStatement(db) {\n    [$0.score += 10]\n} select: {\n    [$0.score]\n}\nlet updatedScores = try Int.fetchAll(statement)\n```\n\n\n### Persistence Callbacks\n\nYour custom type may want to perform extra work when the persistence methods are invoked.\n\nTo this end, your record type can implement **persistence callbacks**. Callbacks are methods that get called at certain moments of a record's life cycle. With callbacks it is possible to write code that will run whenever an record is inserted, updated, or deleted.\n\nIn order to use a callback method, you need to provide its implementation. For example, a frequently used callback is `didInsert`, in the case of auto-incremented database ids:\n\n```swift\nstruct Player: MutablePersistableRecord {\n    var id: Int64?\n    \n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n\ntry dbQueue.write { db in\n    var player = Player(id: nil, ...)\n    try player.insert(db)\n    print(player.id) // didInsert was called: prints some non-nil id\n}\n```\n\nCallbacks can also help implementing record validation:\n\n```swift\nstruct Link: PersistableRecord {\n    var url: URL\n    \n    func willSave(_ db: Database) throws {\n        if url.host == nil {\n            throw ValidationError(\"url must be absolute.\")\n        }\n    }\n}\n\ntry link.insert(db) // Calls the willSave callback\ntry link.update(db) // Calls the willSave callback\ntry link.save(db)   // Calls the willSave callback\ntry link.upsert(db) // Calls the willSave callback\n```\n\n#### Available Callbacks\n\nHere is a list with all the available [persistence callbacks], listed in the same order in which they will get called during the respective operations:\n\n- Inserting a record (all `record.insert` and `record.upsert` methods)\n    - `willSave`\n    - `aroundSave`\n    - `willInsert`\n    - `aroundInsert`\n    - `didInsert`\n    - `didSave`\n    \n- Updating a record (all `record.update` methods)\n    - `willSave`\n    - `aroundSave`\n    - `willUpdate`\n    - `aroundUpdate`\n    - `didUpdate`\n    - `didSave`\n    \n- Deleting a record (only the `record.delete(_:)` method)\n    - `willDelete`\n    - `aroundDelete`\n    - `didDelete`\n\nFor detailed information about each callback, check the [reference](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/mutablepersistablerecord/).\n\nIn the `MutablePersistableRecord` protocol, `willInsert` and `didInsert` are mutating methods. In `PersistableRecord`, they are not mutating.\n\n> **Note**: The `record.save(_:)` method performs an UPDATE if the record has a non-null primary key, and then, if no row was modified, an INSERT. It directly performs an INSERT if the record has no primary key, or a null primary key. It triggers update and/or insert callbacks accordingly.\n>\n> **Warning**: Callbacks are only invoked from persistence methods called on record instances. Callbacks are not invoked when you call a type method, perform a batch operations, or execute raw SQL.\n>\n> **Warning**: When a `did***` callback is invoked, do not assume that the change is actually persisted on disk, because the database may still be inside an uncommitted transaction. When you need to handle transaction completions, use the [afterNextTransaction(onCommit:onRollback:)](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/afternexttransaction(oncommit:onrollback:)). For example:\n>\n> ```swift\n> struct PictureFile: PersistableRecord {\n>     var path: String\n>     \n>     func willDelete(_ db: Database) {\n>         db.afterNextTransaction { _ in\n>             try? deleteFileOnDisk()\n>         }\n>     }\n> }\n> ```\n\n\n## Identifiable Records\n\n**When a record type maps a table with a single-column primary key, it is recommended to have it adopt the standard [Identifiable] protocol.**\n\n```swift\nstruct Player: Identifiable, FetchableRecord, PersistableRecord {\n    var id: Int64 // fulfills the Identifiable requirement\n    var name: String\n    var score: Int\n}\n```\n\nWhen `id` has a [database-compatible type](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalueconvertible) (Int64, Int, String, UUID, ...), the `Identifiable` conformance unlocks type-safe record and request methods:\n\n```swift\nlet player = try Player.find(db, id: 1)               // Player\nlet player = try Player.fetchOne(db, id: 1)           // Player?\nlet players = try Player.fetchAll(db, ids: [1, 2, 3]) // [Player]\nlet players = try Player.fetchSet(db, ids: [1, 2, 3]) // Set<Player>\n\nlet request = Player.filter(id: 1)\nlet request = Player.filter(ids: [1, 2, 3])\n\ntry Player.deleteOne(db, id: 1)\ntry Player.deleteAll(db, ids: [1, 2, 3])\n```\n\n> **Note**: Not all record types can be made `Identifiable`, and not all tables have a single-column primary key. GRDB provides other methods that deal with primary and unique keys, but they won't check the type of their arguments:\n> \n> ```swift\n> // Available on non-Identifiable types\n> try Player.fetchOne(db, key: 1)\n> try Player.fetchOne(db, key: [\"email\": \"arthur@example.com\"])\n> try Country.fetchAll(db, keys: [\"FR\", \"US\"])\n> try Citizenship.fetchOne(db, key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n> \n> let request = Player.filter(key: 1)\n> let request = Player.filter(keys: [1, 2, 3])\n> \n> try Player.deleteOne(db, key: 1)\n> try Player.deleteAll(db, keys: [1, 2, 3])\n> ```\n\n> **Note**: It is not recommended to use `Identifiable` on record types that use an auto-incremented primary key:\n>\n> ```swift\n> // AVOID declaring Identifiable conformance when key is auto-incremented\n> struct Player {\n>     var id: Int64? // Not an id suitable for Identifiable\n>     var name: String\n>     var score: Int\n> }\n> \n> extension Player: FetchableRecord, MutablePersistableRecord {\n>     // Update auto-incremented id upon successful insertion\n>     mutating func didInsert(_ inserted: InsertionSuccess) {\n>         id = inserted.rowID\n>     }\n> }\n> ```\n>\n> For a detailed rationale, please see [issue #1435](https://github.com/groue/GRDB.swift/issues/1435#issuecomment-1740857712).\n\nSome database tables have a single-column primary key which is not called \"id\":\n\n```swift\ntry db.create(table: \"country\") { t in\n    t.primaryKey(\"isoCode\", .text)\n    t.column(\"name\", .text).notNull()\n    t.column(\"population\", .integer).notNull()\n}\n```\n\nIn this case, `Identifiable` conformance can be achieved, for example, by returning the primary key column from the `id` property:\n\n```swift\nstruct Country: Identifiable, FetchableRecord, PersistableRecord {\n    var isoCode: String\n    var name: String\n    var population: Int\n    \n    // Fulfill the Identifiable requirement\n    var id: String { isoCode }\n}\n\nlet france = try dbQueue.read { db in\n    try Country.fetchOne(db, id: \"FR\")\n}\n```\n\n\n## Codable Records\n\nRecord types that adopt an archival protocol ([Codable, Encodable or Decodable](https://developer.apple.com/documentation/foundation/archives_and_serialization/encoding_and_decoding_custom_types)) get free database support just by declaring conformance to the desired [record protocols](#record-protocols-overview):\n\n```swift\n// Declare a record...\nstruct Player: Codable, FetchableRecord, PersistableRecord {\n    var id: Int64\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n\n// ...and there you go:\ntry dbQueue.write { db in\n    try Player(id: 1, name: \"Arthur\", score: 100).insert(db)\n    let players = try Player.order(\\.score.desc).fetchAll(db)\n}\n```\n\nCodable records encode and decode their properties according to their own implementation of the Encodable and Decodable protocols. Yet databases have specific requirements:\n\n- Properties are always coded according to their preferred database representation, when they have one (all [values](#values) that adopt the [`DatabaseValueConvertible`] protocol).\n- You can customize the encoding and decoding of dates and uuids.\n- Complex properties (arrays, dictionaries, nested structs, etc.) are stored as JSON.\n\nFor more information about Codable records, see:\n\n- [JSON Columns]\n- [Column Names Coding Strategies]\n- [Data, Date, and UUID Coding Strategies]\n- [The userInfo Dictionary]\n- [Tip: Derive Columns from Coding Keys](#tip-derive-columns-from-coding-keys)\n\n> :bulb: **Tip**: see the [Demo Applications] for sample code that uses Codable records.\n\n\n### JSON Columns\n\nWhen a [Codable record](#codable-records) contains a property that is not a simple [value](#values) (Bool, Int, String, Date, Swift enums, etc.), that value is encoded and decoded as a **JSON string**. For example:\n\n```swift\nenum AchievementColor: String, Codable {\n    case bronze, silver, gold\n}\n\nstruct Achievement: Codable {\n    var name: String\n    var color: AchievementColor\n}\n\nstruct Player: Codable, FetchableRecord, PersistableRecord {\n    var name: String\n    var score: Int\n    var achievements: [Achievement] // stored in a JSON column\n}\n\ntry dbQueue.write { db in\n    // INSERT INTO player (name, score, achievements)\n    // VALUES (\n    //   'Arthur',\n    //   100,\n    //   '[{\"color\":\"gold\",\"name\":\"Use Codable Records\"}]')\n    let achievement = Achievement(name: \"Use Codable Records\", color: .gold)\n    let player = Player(name: \"Arthur\", score: 100, achievements: [achievement])\n    try player.insert(db)\n}\n```\n\nGRDB uses the standard [JSONDecoder](https://developer.apple.com/documentation/foundation/jsondecoder) and [JSONEncoder](https://developer.apple.com/documentation/foundation/jsonencoder) from Foundation. By default, Data values are handled with the `.base64` strategy, Date with the `.millisecondsSince1970` strategy, and non conforming floats with the `.throw` strategy.\n\nYou can customize the JSON format by implementing those methods:\n\n```swift\nprotocol FetchableRecord {\n    static func databaseJSONDecoder(for column: String) -> JSONDecoder\n}\n\nprotocol EncodableRecord {\n    static func databaseJSONEncoder(for column: String) -> JSONEncoder\n}\n```\n\n> :bulb: **Tip**: Make sure you set the JSONEncoder `sortedKeys` option. This option makes sure that the JSON output is stable. This stability is required for [Record Comparison] to work as expected, and database observation tools such as [ValueObservation] to accurately recognize changed records.\n\n\n### Column Names Coding Strategies\n\nBy default, [Codable Records] store their values into database columns that match their coding keys: the `teamID` property is stored into the `teamID` column.\n\nThis behavior can be overridden, so that you can, for example, store the `teamID` property into the `team_id` column:\n\n```swift\nprotocol FetchableRecord {\n    static var databaseColumnDecodingStrategy: DatabaseColumnDecodingStrategy { get }\n}\n\nprotocol EncodableRecord {\n    static var databaseColumnEncodingStrategy: DatabaseColumnEncodingStrategy { get }\n}\n```\n\nSee [DatabaseColumnDecodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasecolumndecodingstrategy) and [DatabaseColumnEncodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasecolumnencodingstrategy/) to learn about all available strategies.\n\n\n### Data, Date, and UUID Coding Strategies\n\nBy default, [Codable Records] encode and decode their Data properties as blobs, and Date and UUID properties as described in the general [Date and DateComponents](#date-and-datecomponents) and [UUID](#uuid) chapters.\n\nTo sum up: dates encode themselves in the \"YYYY-MM-DD HH:MM:SS.SSS\" format, in the UTC time zone, and decode a variety of date formats and timestamps. UUIDs encode themselves as 16-bytes data blobs, and decode both 16-bytes data blobs and strings such as \"E621E1F8-C36C-495A-93FC-0C247A3E6E5F\".\n\nThose behaviors can be overridden:\n\n```swift\nprotocol FetchableRecord {\n    static func databaseDataDecodingStrategy(for column: String) -> DatabaseDataDecodingStrategy\n    static func databaseDateDecodingStrategy(for column: String) -> DatabaseDateDecodingStrategy\n}\n\nprotocol EncodableRecord {\n    static func databaseDataEncodingStrategy(for column: String) -> DatabaseDataEncodingStrategy\n    static func databaseDateEncodingStrategy(for column: String) -> DatabaseDateEncodingStrategy\n    static func databaseUUIDEncodingStrategy(for column: String) -> DatabaseUUIDEncodingStrategy\n}\n```\n\nSee [DatabaseDataDecodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasedatadecodingstrategy/), [DatabaseDateDecodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasedatedecodingstrategy/), [DatabaseDataEncodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasedataencodingstrategy/), [DatabaseDateEncodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasedateencodingstrategy/), and [DatabaseUUIDEncodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseuuidencodingstrategy/) to learn about all available strategies.\n\nThere is no customization of uuid decoding, because UUID can already decode all its encoded variants (16-bytes blobs and uuid strings, both uppercase and lowercase).\n\nCustomized coding strategies apply:\n\n- When encoding and decoding database rows to and from records (fetching and persistence methods).\n- In requests by single-column primary key: `fetchOne(_:id:)`, `filter(id:)`, `deleteAll(_:keys:)`, etc.\n\n*They do not apply* in other requests based on data, date, or uuid values.\n\nSo make sure that those are properly encoded in your requests. For example:\n\n```swift\nstruct Player: Codable, FetchableRecord, PersistableRecord, Identifiable {\n    // UUIDs are stored as strings\n    static func databaseUUIDEncodingStrategy(for column: String) -> DatabaseUUIDEncodingStrategy {\n        .uppercaseString\n    }\n    \n    var id: UUID\n    ...\n}\n\ntry dbQueue.write { db in\n    let uuid = UUID()\n    let player = Player(id: uuid, ...)\n    \n    // OK: inserts a player in the database, with a string uuid\n    try player.insert(db)\n    \n    // OK: performs a string-based query, finds the inserted player\n    _ = try Player.filter(id: uuid).fetchOne(db)\n\n    // NOT OK: performs a blob-based query, fails to find the inserted player\n    _ = try Player.filter { $0.id == uuid }.fetchOne(db)\n    \n    // OK: performs a string-based query, finds the inserted player\n    _ = try Player.filter { $0.id == uuid.uuidString }.fetchOne(db)\n}\n```\n\n\n### The userInfo Dictionary\n\nYour [Codable Records] can be stored in the database, but they may also have other purposes. In this case, you may need to customize their implementations of `Decodable.init(from:)` and `Encodable.encode(to:)`, depending on the context.\n\nThe standard way to provide such context is the `userInfo` dictionary. Implement those properties:\n\n```swift\nprotocol FetchableRecord {\n    static var databaseDecodingUserInfo: [CodingUserInfoKey: Any] { get }\n}\n\nprotocol EncodableRecord {\n    static var databaseEncodingUserInfo: [CodingUserInfoKey: Any] { get }\n}\n```\n\nFor example, here is a Player type that customizes its decoding:\n\n```swift\n// A key that holds a decoder's name\nlet decoderName = CodingUserInfoKey(rawValue: \"decoderName\")!\n\nstruct Player: FetchableRecord, Decodable {\n    init(from decoder: Decoder) throws {\n        // Print the decoder name\n        let decoderName = decoder.userInfo[decoderName] as? String\n        print(\"Decoded from \\(decoderName ?? \"unknown decoder\")\")\n        ...\n    }\n}\n```\n\nYou can have a specific decoding from JSON...\n\n```swift\n// prints \"Decoded from JSON\"\nlet decoder = JSONDecoder()\ndecoder.userInfo = [decoderName: \"JSON\"]\nlet player = try decoder.decode(Player.self, from: jsonData)\n```\n\n... and another one from database rows:\n\n```swift\nextension Player: FetchableRecord {\n    static var databaseDecodingUserInfo: [CodingUserInfoKey: Any] {\n        [decoderName: \"database row\"]\n    }\n}\n\n// prints \"Decoded from database row\"\nlet player = try Player.fetchOne(db, ...)\n```\n\n> **Note**: make sure the `databaseDecodingUserInfo` and `databaseEncodingUserInfo` properties are explicitly declared as `[CodingUserInfoKey: Any]`. If they are not, the Swift compiler may silently miss the protocol requirement, resulting in sticky empty userInfo.\n\n\n### Tip: Derive Columns from Coding Keys\n\nCodable types are granted with a [CodingKeys](https://developer.apple.com/documentation/foundation/archives_and_serialization/encoding_and_decoding_custom_types) enum. You can use them to safely define database columns:\n\n```swift\nstruct Player: Codable {\n    var id: Int64\n    var name: String\n    var score: Int\n}\n\nextension Player: FetchableRecord, PersistableRecord {\n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n```\n\nSee the [query interface](#the-query-interface) and [Recommended Practices for Designing Record Types](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recordrecommendedpractices) for further information.\n\n\n## Record Comparison\n\n**Records that adopt the [EncodableRecord] protocol can compare against other records, or against previous versions of themselves.**\n\nThis helps avoiding costly UPDATE statements when a record has not been edited.\n\n- [The `updateChanges` Methods](#the-updatechanges-methods)\n- [The `databaseEquals` Method](#the-databaseequals-method)\n- [The `databaseChanges` and `hasDatabaseChanges` Methods](#the-databasechanges-and-hasdatabasechanges-methods)\n\n\n### The `updateChanges` Methods\n\nThe `updateChanges` methods perform a database update of the changed columns only (and does nothing if record has no change).\n\n- `updateChanges(_:from:)`\n\n    This method lets you compare two records:\n\n    ```swift\n    if let oldPlayer = try Player.fetchOne(db, id: 42) {\n        var newPlayer = oldPlayer\n        newPlayer.score = 100\n        if try newPlayer.updateChanges(db, from: oldPlayer) {\n            print(\"player was modified, and updated in the database\")\n        } else {\n            print(\"player was not modified, and database was not hit\")\n        }\n    }\n    ```\n\n- `updateChanges(_:modify:)`\n    \n    This method lets you update a record in place:\n    \n    ```swift\n    if var player = try Player.fetchOne(db, id: 42) {\n        let modified = try player.updateChanges(db) {\n            $0.score = 100\n        }\n        if modified {\n            print(\"player was modified, and updated in the database\")\n        } else {\n            print(\"player was not modified, and database was not hit\")\n        }\n    }\n    ```\n\n### The `databaseEquals` Method\n\nThis method returns whether two records have the same database representation:\n\n```swift\nlet oldPlayer: Player = ...\nvar newPlayer: Player = ...\nif newPlayer.databaseEquals(oldPlayer) == false {\n    try newPlayer.save(db)\n}\n```\n\n> **Note**: The comparison is performed on the database representation of records. As long as your record type adopts the EncodableRecord protocol, you don't need to care about Equatable.\n\n\n### The `databaseChanges` and `hasDatabaseChanges` Methods\n\n`databaseChanges(from:)` returns a dictionary of differences between two records:\n\n```swift\nlet oldPlayer = Player(id: 1, name: \"Arthur\", score: 100)\nlet newPlayer = Player(id: 1, name: \"Arthur\", score: 1000)\nfor (column, oldValue) in try newPlayer.databaseChanges(from: oldPlayer) {\n    print(\"\\(column) was \\(oldValue)\")\n}\n// prints \"score was 100\"\n```\n\nFor an efficient algorithm which synchronizes the content of a database table with a JSON payload, check [groue/SortedDifference](https://github.com/groue/SortedDifference).\n\n\n## Record Customization Options\n\nGRDB records come with many default behaviors, that are designed to fit most situations. Many of those defaults can be customized for your specific needs:\n\n- [Persistence Callbacks]: define what happens when you call a persistence method such as `player.insert(db)`\n- [Conflict Resolution]: Run `INSERT OR REPLACE` queries, and generally define what happens when a persistence method violates a unique index.\n- [Columns Selected by a Request]: define which columns are selected by requests such as `Player.fetchAll(db)`.\n- [Beyond FetchableRecord]: the FetchableRecord protocol is not the end of the story.\n\n[Codable Records] have a few extra options:\n\n- [JSON Columns]: control the format of JSON columns.\n- [Column Names Coding Strategies]: control how coding keys are turned into column names\n- [Date and UUID Coding Strategies]: control the format of Date and UUID properties in your Codable records.\n- [The userInfo Dictionary]: adapt your Codable implementation for the database.\n\n\n### Conflict Resolution\n\n**Insertions and updates can create conflicts**: for example, a query may attempt to insert a duplicate row that violates a unique index.\n\nThose conflicts normally end with an error. Yet SQLite let you alter the default behavior, and handle conflicts with specific policies. For example, the `INSERT OR REPLACE` statement handles conflicts with the \"replace\" policy which replaces the conflicting row instead of throwing an error.\n\nThe [five different policies](https://www.sqlite.org/lang_conflict.html) are: abort (the default), replace, rollback, fail, and ignore.\n\n**SQLite let you specify conflict policies at two different places:**\n\n- In the definition of the database table:\n    \n    ```swift\n    // CREATE TABLE player (\n    //     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    //     email TEXT UNIQUE ON CONFLICT REPLACE\n    // )\n    try db.create(table: \"player\") { t in\n        t.autoIncrementedPrimaryKey(\"id\")\n        t.column(\"email\", .text).unique(onConflict: .replace) // <--\n    }\n    \n    // Despite the unique index on email, both inserts succeed.\n    // The second insert replaces the first row:\n    try db.execute(sql: \"INSERT INTO player (email) VALUES (?)\", arguments: [\"arthur@example.com\"])\n    try db.execute(sql: \"INSERT INTO player (email) VALUES (?)\", arguments: [\"arthur@example.com\"])\n    ```\n    \n- In each modification query:\n    \n    ```swift\n    // CREATE TABLE player (\n    //     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    //     email TEXT UNIQUE\n    // )\n    try db.create(table: \"player\") { t in\n        t.autoIncrementedPrimaryKey(\"id\")\n        t.column(\"email\", .text).unique()\n    }\n    \n    // Again, despite the unique index on email, both inserts succeed.\n    try db.execute(sql: \"INSERT OR REPLACE INTO player (email) VALUES (?)\", arguments: [\"arthur@example.com\"])\n    try db.execute(sql: \"INSERT OR REPLACE INTO player (email) VALUES (?)\", arguments: [\"arthur@example.com\"])\n    ```\n\nWhen you want to handle conflicts at the query level, specify a custom `persistenceConflictPolicy` in your type that adopts the PersistableRecord protocol. It will alter the INSERT and UPDATE queries run by the `insert`, `update` and `save` [persistence methods]:\n\n```swift\nprotocol MutablePersistableRecord {\n    /// The policy that handles SQLite conflicts when records are\n    /// inserted or updated.\n    ///\n    /// This property is optional: its default value uses the ABORT\n    /// policy for both insertions and updates, so that GRDB generate\n    /// regular INSERT and UPDATE queries.\n    static var persistenceConflictPolicy: PersistenceConflictPolicy { get }\n}\n\nstruct Player : MutablePersistableRecord {\n    static let persistenceConflictPolicy = PersistenceConflictPolicy(\n        insert: .replace,\n        update: .replace)\n}\n\n// INSERT OR REPLACE INTO player (...) VALUES (...)\ntry player.insert(db)\n```\n\n> **Note**: If you specify the `ignore` policy for inserts, the [`didInsert` callback](#persistence-callbacks) will be called with some random id in case of failed insert. You can detect failed insertions with `insertAndFetch`:\n>     \n> ```swift\n> // How to detect failed `INSERT OR IGNORE`:\n> // INSERT OR IGNORE INTO player ... RETURNING *\n> do {\n>     let insertedPlayer = try player.insertAndFetch(db) {\n>     // Successful insertion\n> catch RecordError.recordNotFound {\n>     // Failed insertion due to IGNORE policy\n> }\n> ```\n>\n> **Note**: The `replace` policy may have to delete rows so that inserts and updates can succeed. Those deletions are not reported to [transaction observers](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/transactionobserver) (this might change in a future release of SQLite).\n\n### Beyond FetchableRecord\n\n**Some GRDB users eventually discover that the [FetchableRecord] protocol does not fit all situations.** Use cases that are not well handled by FetchableRecord include:\n\n- Your application needs polymorphic row decoding: it decodes some type or another, depending on the values contained in a database row.\n\n- Your application needs to decode rows with a context: each decoded value should be initialized with some extra value that does not come from the database.\n\nSince those use cases are not well handled by FetchableRecord, don't try to implement them on top of this protocol: you'll just fight the framework.\n\n\n## Examples of Record Definitions\n\nWe will show below how to declare a record type for the following database table:\n\n```swift\ntry dbQueue.write { db in\n    try db.create(table: \"place\") { t in\n        t.autoIncrementedPrimaryKey(\"id\")\n        t.column(\"title\", .text).notNull()\n        t.column(\"isFavorite\", .boolean).notNull().defaults(to: false)\n        t.column(\"longitude\", .double).notNull()\n        t.column(\"latitude\", .double).notNull()\n    }\n}\n```\n\nEach one of the three examples below is correct. You will pick one or the other depending on your personal preferences and the requirements of your application:\n\n<details>\n  <summary>Define a Codable struct, and adopt the record protocols you need</summary>\n\nThis is the shortest way to define a record type.\n\nSee the [Record Protocols Overview](#record-protocols-overview), and [Codable Records] for more information.\n\n```swift\nstruct Place: Codable {\n    var id: Int64?\n    var title: String\n    var isFavorite: Bool\n    private var latitude: CLLocationDegrees\n    private var longitude: CLLocationDegrees\n    \n    var coordinate: CLLocationCoordinate2D {\n        get {\n            CLLocationCoordinate2D(\n                latitude: latitude,\n                longitude: longitude)\n        }\n        set {\n            latitude = newValue.latitude\n            longitude = newValue.longitude\n        }\n    }\n}\n\n// SQL generation\nextension Place: TableRecord {\n    /// The table columns\n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let title = Column(CodingKeys.title)\n        static let isFavorite = Column(CodingKeys.isFavorite)\n        static let latitude = Column(CodingKeys.latitude)\n        static let longitude = Column(CodingKeys.longitude)\n    }\n}\n\n// Fetching methods\nextension Place: FetchableRecord { }\n\n// Persistence methods\nextension Place: MutablePersistableRecord {\n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n```\n\n</details>\n\n<details>\n  <summary>Define a plain struct, and adopt the record protocols you need</summary>\n\nSee the [Record Protocols Overview](#record-protocols-overview) for more information.\n    \n```swift\nstruct Place {\n    var id: Int64?\n    var title: String\n    var isFavorite: Bool\n    var coordinate: CLLocationCoordinate2D\n}\n\n// SQL generation\nextension Place: TableRecord {\n    /// The table columns\n    enum Columns {\n        static let id = Column(\"id\")\n        static let title = Column(\"title\")\n        static let isFavorite = Column(\"isFavorite\")\n        static let latitude = Column(\"latitude\")\n        static let longitude = Column(\"longitude\")\n    }\n}\n\n// Fetching methods\nextension Place: FetchableRecord {\n    /// Creates a record from a database row\n    init(row: Row) {\n        id = row[Columns.id]\n        title = row[Columns.title]\n        isFavorite = row[Columns.isFavorite]\n        coordinate = CLLocationCoordinate2D(\n            latitude: row[Columns.latitude],\n            longitude: row[Columns.longitude])\n    }\n}\n\n// Persistence methods\nextension Place: MutablePersistableRecord {\n    /// The values persisted in the database\n    func encode(to container: inout PersistenceContainer) {\n        container[Columns.id] = id\n        container[Columns.title] = title\n        container[Columns.isFavorite] = isFavorite\n        container[Columns.latitude] = coordinate.latitude\n        container[Columns.longitude] = coordinate.longitude\n    }\n    \n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n```\n\n</details>\n\n<details>\n  <summary>Define a plain struct optimized for fetching performance</summary>\n\nThis struct derives its persistence methods from the standard Encodable protocol (see [Codable Records]), but performs optimized row decoding by accessing database columns with numeric indexes.\n\nSee the [Record Protocols Overview](#record-protocols-overview) for more information.\n    \n```swift\nstruct Place: Encodable {\n    var id: Int64?\n    var title: String\n    var isFavorite: Bool\n    private var latitude: CLLocationDegrees\n    private var longitude: CLLocationDegrees\n    \n    var coordinate: CLLocationCoordinate2D {\n        get {\n            CLLocationCoordinate2D(\n                latitude: latitude,\n                longitude: longitude)\n        }\n        set {\n            latitude = newValue.latitude\n            longitude = newValue.longitude\n        }\n    }\n}\n\n// SQL generation\nextension Place: TableRecord {\n    /// The table columns\n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let title = Column(CodingKeys.title)\n        static let isFavorite = Column(CodingKeys.isFavorite)\n        static let latitude = Column(CodingKeys.latitude)\n        static let longitude = Column(CodingKeys.longitude)\n    }\n    \n    /// Arrange the selected columns and lock their order\n    static var databaseSelection: [any SQLSelectable] {\n        [\n            Columns.id,\n            Columns.title,\n            Columns.favorite,\n            Columns.latitude,\n            Columns.longitude,\n        ]\n    }\n}\n\n// Fetching methods\nextension Place: FetchableRecord {\n    /// Creates a record from a database row\n    init(row: Row) {\n        // For high performance, use numeric indexes that match the\n        // order of Place.databaseSelection\n        id = row[0]\n        title = row[1]\n        isFavorite = row[2]\n        coordinate = CLLocationCoordinate2D(\n            latitude: row[3],\n            longitude: row[4])\n    }\n}\n\n// Persistence methods\nextension Place: MutablePersistableRecord {\n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n```\n\n</details>\n\n\nThe Query Interface\n===================\n\n**The query interface lets you write pure Swift instead of SQL:**\n\n```swift\ntry dbQueue.write { db in\n    // Update database schema\n    try db.create(table: \"player\") { t in ... }\n    \n    // Fetch records\n    let bestPlayers = try Player\n        .order(\\.score.desc)\n        .limit(10)\n        .fetchAll(db)\n    \n    // Count\n    let count = try Player\n        .filter { $0.score >= 1000 }\n        .fetchCount(db)\n    \n    // Batch update\n    try Player\n        .filter { $0.team == \"Reds\" }\n        .updateAll(db) { $0.score += 100 }\n    \n    // Batch delete\n    try Player\n        .filter { $0.score == 0 }\n        .deleteAll(db)\n}\n```\n\nYou need to open a [database connection] before you can query the database.\n\nPlease bear in mind that the query interface can not generate all possible SQL queries. You may also *prefer* writing SQL, and this is just OK. From little snippets to full queries, your SQL skills are welcome:\n\n```swift\ntry dbQueue.write { db in\n    // Update database schema (with SQL)\n    try db.execute(sql: \"CREATE TABLE player (...)\")\n    \n    // Fetch records (with SQL)\n    let bestPlayers = try Player.fetchAll(db, sql: \"\"\"\n        SELECT * FROM player ORDER BY score DESC LIMIT 10\n        \"\"\")\n    \n    // Count (with an SQL snippet)\n    let minScore = 1000\n    let count = try Player\n        .filter(sql: \"score >= ?\", arguments: [minScore])\n        .fetchCount(db)\n    \n    // Update (with SQL)\n    try db.execute(sql: \"UPDATE player SET score = score + 100 WHERE team = 'Reds'\")\n    \n    // Delete (with SQL)\n    try db.execute(sql: \"DELETE FROM player WHERE score = 0\")\n}\n```\n\nSo don't miss the [SQL API](#sqlite-api).\n\n> **Note**: the generated SQL may change between GRDB releases, without notice: don't have your application rely on any specific SQL output.\n\n- [The Database Schema](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseschema)\n- [Requests](#requests)\n- [Expressions](#expressions)\n    - [SQL Operators](#sql-operators)\n    - [SQL Functions](#sql-functions)\n- [Embedding SQL in Query Interface Requests]\n- [Fetching from Requests]\n- [Fetching by Key](#fetching-by-key)\n- [Testing for Record Existence](#testing-for-record-existence)\n- [Fetching Aggregated Values](#fetching-aggregated-values)\n- [Delete Requests](#delete-requests)\n- [Update Requests](#update-requests)\n- [Custom Requests](#custom-requests)\n- :blue_book: [Associations and Joins](Documentation/AssociationsBasics.md)\n- :blue_book: [Common Table Expressions]\n- :blue_book: [Query Interface Organization]\n\n## Requests\n\nüìñ [`QueryInterfaceRequest`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest), [`Table`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/table)\n\n**The query interface requests** let you fetch values from the database:\n\n```swift\nlet request = Player.filter { $0.email != nil }.order(\\.name)\nlet players = try request.fetchAll(db)  // [Player]\nlet count = try request.fetchCount(db)  // Int\n```\n\nQuery interface requests usually start from **a type** that adopts the `TableRecord` protocol:\n\n```swift\nstruct Player: TableRecord { ... }\n\n// The request for all players:\nlet request = Player.all()\nlet players = try request.fetchAll(db) // [Player]\n```\n\nWhen you can not use a record type, use `Table`:\n\n```swift\n// The request for all rows from the player table:\nlet table = Table(\"player\")\nlet request = table.all()\nlet rows = try request.fetchAll(db)    // [Row]\n\n// The request for all players from the player table:\nlet table = Table<Player>(\"player\")\nlet request = table.all()\nlet players = try request.fetchAll(db) // [Player]\n```\n\n> **Note**: all examples in the documentation below use a record type, but you can always substitute a `Table` instead.\n\nNext, declare the table **columns** that you want to use for filtering, or sorting, in a nested type named `Columns`:\n\n```swift\nextension Player {\n    enum Columns {\n        static let id = Column(\"id\")\n        static let name = Column(\"name\")\n    }\n}\n```\n\nWhen `Player` is `Codable`, you'll prefer defining columns from coding keys:\n\n```swift\nextension Player {\n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n    }\n}\n```\n\nYou can now build requests with the following methods: `all`, `none`, `select`, `distinct`, `filter`, `matching`, `group`, `having`, `order`, `reversed`, `limit`, `joining`, `including`, `with`. All those methods return another request, which you can further refine by applying another method: `Player.select(...).filter(...).order(...)`.\n\n- [`all()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerecord/all()), [`none()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerecord/none()): the requests for all rows, or no row.\n\n    ```swift\n    // SELECT * FROM player\n    Player.all()\n    ```\n    \n    By default, all columns are selected. See [Columns Selected by a Request].\n\n- [`select(...)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/selectionrequest/select(_:)-ruzy) and [`select(..., as:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/select(_:as:)-58954) define the selected columns. See [Columns Selected by a Request].\n    \n    ```swift\n    // SELECT name FROM player\n    Player.select(\\.name, as: String.self)\n    ```\n\n- [`selectID()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/selectID()) is available on [Identifiable Records]. It supports all tables that have a single-column primary key:\n\n    ```swift\n    // SELECT id FROM player\n    Player.selectID()\n    \n    // SELECT id FROM player WHERE name IS NOT NULL\n    Player.filter { $0.name != nil }.selectID()\n    ```\n\n- [`annotated(with: expression...)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/selectionrequest/annotated(with:)-1satx) extends the selection.\n\n    ```swift\n    // SELECT *, (score + bonus) AS total FROM player\n    Player.annotated { ($0.score + $0.bonus).forKey(\"total\") }\n    ```\n\n- [`annotated(with: aggregate)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/derivablerequest/annotated(with:)-74xfs) extends the selection with [association aggregates](Documentation/AssociationsBasics.md#association-aggregates).\n    \n    ```swift\n    // SELECT team.*, COUNT(DISTINCT player.id) AS playerCount\n    // FROM team\n    // LEFT JOIN player ON player.teamId = team.id\n    // GROUP BY team.id\n    Team.annotated(with: Team.players.count)\n    ```\n\n- [`annotated(withRequired: association)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/annotated(withrequired:)) and [`annotated(withOptional: association)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/annotated(withoptional:)) extends the selection with [Associations].\n    \n    ```swift\n    // SELECT player.*, team.color\n    // FROM player\n    // JOIN team ON team.id = player.teamId\n    Player.annotated(withRequired: Player.team.select(\\.color))\n    ```\n\n- [`distinct()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/derivablerequest/distinct()) performs uniquing.\n    \n    ```swift\n    // SELECT DISTINCT name FROM player\n    Player.select(\\.name, as: String.self).distinct()\n    ```\n\n- [`filter(expression)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/filteredrequest/filter(_:)-6xr3d) applies conditions.\n    \n    ```swift\n    // SELECT * FROM player WHERE id IN (1, 2, 3)\n    Player.filter { [1,2,3].contains($0.id) }\n    \n    // SELECT * FROM player WHERE (name IS NOT NULL) AND (height > 1.75)\n    Player.filter { $0.name != nil && $0.height > 1.75 }\n    ```\n\n- [`filter(id:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/filter(id:)) and [`filter(ids:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/filter(ids:)) are type-safe methods available on [Identifiable Records]:\n    \n    ```swift\n    // SELECT * FROM player WHERE id = 1\n    Player.filter(id: 1)\n    \n    // SELECT * FROM country WHERE isoCode IN ('FR', 'US')\n    Country.filter(ids: [\"FR\", \"US\"])\n    ```\n    \n- [`filter(key:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/filter(key:)-1p9sq) and [`filter(keys:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/filter(keys:)-6ggt1) apply conditions on primary and unique keys:\n    \n    ```swift\n    // SELECT * FROM player WHERE id = 1\n    Player.filter(key: 1)\n    \n    // SELECT * FROM country WHERE isoCode IN ('FR', 'US')\n    Country.filter(keys: [\"FR\", \"US\"])\n    \n    // SELECT * FROM citizenship WHERE citizenId = 1 AND countryCode = 'FR'\n    Citizenship.filter(key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n    \n    // SELECT * FROM player WHERE email = 'arthur@example.com'\n    Player.filter(key: [\"email\": \"arthur@example.com\"])\n    ```\n\n- `matching(pattern)` ([FTS3](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/matching(_:)-3s3zr), [FTS5](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/matching(_:)-7c1e8)) performs [full-text search](Documentation/FullTextSearch.md).\n    \n    ```swift\n    // SELECT * FROM document WHERE document MATCH 'sqlite database'\n    let pattern = FTS3Pattern(matchingAllTokensIn: \"SQLite database\")\n    Document.matching(pattern)\n    ```\n    \n    When the pattern is nil, no row will match.\n\n- [`group(expression, ...)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/aggregatingrequest/group(_:)-2g7br) groups rows.\n    \n    ```swift\n    // SELECT name, MAX(score) FROM player GROUP BY name\n    Player\n        .select { [$0.name, max($0.score)] }\n        .group(\\.name)\n    ```\n\n- [`having(expression)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/aggregatingrequest/having(_:)-2oggh) applies conditions on grouped rows.\n    \n    ```swift\n    // SELECT team, MAX(score) FROM player GROUP BY team HAVING MIN(score) >= 1000\n    Player\n        .select { [$0.team, max($0.score)] }\n        .group(\\.team)\n        .having { min($0.score) >= 1000 }\n    ```\n\n- [`having(aggregate)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/derivablerequest/having(_:)) applies conditions on grouped rows, according to an [association aggregate](Documentation/AssociationsBasics.md#association-aggregates).\n    \n    ```swift\n    // SELECT team.*\n    // FROM team\n    // LEFT JOIN player ON player.teamId = team.id\n    // GROUP BY team.id\n    // HAVING COUNT(DISTINCT player.id) >= 5\n    Team.having(Team.players.count >= 5)\n    ```\n\n- [`order(ordering, ...)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/orderedrequest/order(_:)-9d0hr) sorts.\n    \n    ```swift\n    // SELECT * FROM player ORDER BY name\n    Player.order(\\.name)\n    \n    // SELECT * FROM player ORDER BY score DESC\n    Player.order(\\.score.desc)\n    \n    // SELECT * FROM player ORDER BY score DESC, name\n    Player.order { [$0.score.desc, $0.name] }\n    ```\n    \n    SQLite considers NULL values to be smaller than any other values for sorting purposes. Hence, NULLs naturally appear at the beginning of an ascending ordering and at the end of a descending ordering. With a [custom SQLite build], this can be changed using `.ascNullsLast` and `.descNullsFirst`:\n    \n    ```swift\n    // SELECT * FROM player ORDER BY score ASC NULLS LAST\n    Player.order(\\.name.ascNullsLast)\n    ```\n    \n    Each `order` call clears any previous ordering:\n    \n    ```swift\n    // SELECT * FROM player ORDER BY name\n    Player.order(\\.score).order(\\.name)\n    ```\n\n- [`reversed()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/orderedrequest/reversed()) reverses the eventual orderings.\n    \n    ```swift\n    // SELECT * FROM player ORDER BY score ASC, name DESC\n    Player.order { [$0.score.desc, $0.name] }.reversed()\n    ```\n    \n    If no ordering was already specified, this method has no effect:\n    \n    ```swift\n    // SELECT * FROM player\n    Player.all().reversed()\n    ```\n\n- [`limit(limit, offset: offset)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/limit(_:offset:)) limits and pages results.\n    \n    ```swift\n    // SELECT * FROM player LIMIT 5\n    Player.limit(5)\n    \n    // SELECT * FROM player LIMIT 5 OFFSET 10\n    Player.limit(5, offset: 10)\n    ```\n\n- [`joining(required:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/joining(required:)), [`joining(optional:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/joining(optional:)), [`including(required:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/including(required:)), [`including(optional:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/including(optional:)), and [`including(all:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/including(all:)) fetch and join records through [Associations].\n    \n    ```swift\n    // SELECT player.*, team.*\n    // FROM player\n    // JOIN team ON team.id = player.teamId\n    Player.including(required: Player.team)\n    ```\n\n- [`with(cte)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/derivablerequest/with(_:)) embeds a [common table expression]:\n    \n    ```swift\n    // WITH ... SELECT * FROM player\n    let cte = CommonTableExpression(...)\n    Player.with(cte)\n    ```\n\n- Other requests that involve the primary key:\n    \n    - [`selectPrimaryKey(as:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/selectprimarykey(as:)) selects the primary key.\n    \n        ```swift\n        // SELECT id FROM player\n        Player.selectPrimaryKey(as: Int64.self)    // QueryInterfaceRequest<Int64>\n        \n        // SELECT code FROM country\n        Country.selectPrimaryKey(as: String.self)  // QueryInterfaceRequest<String>\n        \n        // SELECT citizenId, countryCode FROM citizenship\n        Citizenship.selectPrimaryKey(as: Row.self) // QueryInterfaceRequest<Row>\n        ```\n        \n    - [`orderByPrimaryKey()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/orderbyprimarykey()) sorts by primary key.\n        \n        ```swift\n        // SELECT * FROM player ORDER BY id\n        Player.orderByPrimaryKey()\n        \n        // SELECT * FROM country ORDER BY code\n        Country.orderByPrimaryKey()\n        \n        // SELECT * FROM citizenship ORDER BY citizenId, countryCode\n        Citizenship.orderByPrimaryKey()\n        ```\n    \n    - [`groupByPrimaryKey()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/groupbyprimarykey()) groups rows by primary key.\n\n\nYou can refine requests by chaining those methods:\n\n```swift\n// SELECT * FROM player WHERE (email IS NOT NULL) ORDER BY name\nPlayer.order(\\.name).filter { $0.email != nil }\n```\n\nThe `select`, `order`, `group`, and `limit` methods ignore and replace previously applied selection, orderings, grouping, and limits. On the opposite, `filter`, `matching`, and `having` methods extend the query:\n\n```swift\nPlayer                          // SELECT * FROM player\n    .filter { $0.name != nil }  // WHERE (name IS NOT NULL)\n    .filter { $0.email != nil } //        AND (email IS NOT NULL)\n    .order(\\.name)              // - ignored -\n    .reversed()                 // - ignored -\n    .order(\\.score)             // ORDER BY score\n    .limit(20, offset: 40)      // - ignored -\n    .limit(10)                  // LIMIT 10\n```\n\n\nRaw SQL snippets are also accepted, with eventual [arguments](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statementarguments):\n\n```swift\n// SELECT DATE(creationDate), COUNT(*) FROM player WHERE name = 'Arthur' GROUP BY date(creationDate)\nPlayer\n    .select(sql: \"DATE(creationDate), COUNT(*)\")\n    .filter(sql: \"name = ?\", arguments: [\"Arthur\"])\n    .group(sql: \"DATE(creationDate)\")\n```\n\n\n### Columns Selected by a Request\n\nBy default, query interface requests select all columns:\n\n```swift\n// SELECT * FROM player\nstruct Player: TableRecord { ... }\nlet request = Player.all()\n\n// SELECT * FROM player\nlet table = Table(\"player\")\nlet request = table.all()\n```\n\n**The selection can be changed for each individual requests, or in the case of record-based requests, for all requests built from this record type.**\n\nThe `select(...)` and `select(..., as:)` methods change the selection of a single request (see [Fetching from Requests] for detailed information):\n\n```swift\nlet request = Player.select { max($0.score) }\nlet maxScore = try Int.fetchOne(db, request) // Int?\n\nlet request = Player.select({ max($0.score) }, as: Int.self)\nlet maxScore = try request.fetchOne(db)      // Int?\n```\n\nThe default selection for a record type is controlled by the `databaseSelection` property. For example:\n\n```swift\n// Select a limited set of columns\nstruct RestrictedPlayer: TableRecord {\n    static let databaseTableName = \"player\"\n    \n    enum Columns {\n        static let id = Column(\"id\")\n        static let name = Column(\"name\")\n    }\n    \n    static var databaseSelection: [any SQLSelectable] {\n        [Columns.id, Columns.name]\n    }\n}\n\n// SELECT id, name FROM player\nlet request = RestrictedPlayer.all()\n```\n\n```swift\n// Select all but a few columns\nstruct Player : TableRecord {\n    static var databaseSelection: [any SQLSelectable] { \n        [.allColumns(excluding: [\"generatedColumn\"])]\n    }\n}\n\n// SELECT id, name FROM player\nlet request = RestrictedPlayer.all()\n```\n\n```swift\n// Select all columns and more\nstruct ExtendedPlayer : TableRecord {\n    static let databaseTableName = \"player\"\n    static var databaseSelection: [any SQLSelectable] {\n        [.allColumns, .rowID]\n    }\n}\n\n// SELECT *, rowid FROM player\nlet request = ExtendedPlayer.all()\n```\n\n> **Note**: make sure the `databaseSelection` property is explicitly declared as `[any SQLSelectable]`. If it is not, the Swift compiler may silently miss the protocol requirement, resulting in sticky `SELECT *` requests. To verify your setup, see the [How do I print a request as SQL?](#how-do-i-print-a-request-as-sql) FAQ.\n\n\n## Expressions\n\nFeed [requests](#requests) with SQL expressions built from your Swift code:\n\n\n### SQL Operators\n\nüìñ [`SQLSpecificExpressible`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/sqlspecificexpressible)\n\nGRDB comes with a Swift version of many SQLite [built-in operators](https://sqlite.org/lang_expr.html#operators), listed below. But not all: see [Embedding SQL in Query Interface Requests] for a way to add support for missing SQL operators.\n\n- `=`, `<>`, `<`, `<=`, `>`, `>=`, `IS`, `IS NOT`\n    \n    Comparison operators are based on the Swift operators `==`, `!=`, `===`, `!==`, `<`, `<=`, `>`, `>=`:\n    \n    ```swift\n    // SELECT * FROM player WHERE (name = 'Arthur')\n    Player.filter { $0.name == \"Arthur\" }\n    \n    // SELECT * FROM player WHERE (name IS NULL)\n    Player.filter { $0.name == nil }\n    \n    // SELECT * FROM player WHERE (score IS 1000)\n    Player.filter { $0.score === 1000 }\n    \n    // SELECT * FROM rectangle WHERE width < height\n    Rectangle.filter { $0.width < $0.height }\n    ```\n    \n    Subqueries are supported:\n    \n    ```swift\n    // SELECT * FROM player WHERE score = (SELECT max(score) FROM player)\n    let maximumScore = Player.select { max($0.score) }\n    Player.filter { $0.score == maximumScore }\n    \n    // SELECT * FROM player WHERE score = (SELECT max(score) FROM player)\n    let maximumScore = SQLRequest(\"SELECT max(score) FROM player\")\n    Player.filter { $0.score == maximumScore }\n    ```\n    \n    > **Note**: SQLite string comparison, by default, is case-sensitive and not Unicode-aware. See [string comparison](#string-comparison) if you need more control.\n\n- `*`, `/`, `+`, `-`\n    \n    SQLite arithmetic operators are derived from their Swift equivalent:\n    \n    ```swift\n    // SELECT ((temperature * 1.8) + 32) AS fahrenheit FROM planet\n    Planet.select { ($0.temperature * 1.8 + 32).forKey(\"fahrenheit\") }\n    ```\n    \n    > **Note**: an expression like `nameColumn + \"rrr\"` will be interpreted by SQLite as a numerical addition (with funny results), not as a string concatenation. See the `concat` operator below.\n    \n    When you want to join a sequence of expressions with the `+` or `*` operator, use `joined(operator:)`:\n    \n    ```swift\n    // SELECT score + bonus + 1000 FROM player\n    Player.select {\n        [$0.score, $0.bonus, 1000.databaseValue].joined(operator: .add)\n    }\n    ```\n    \n    Note in the example above how you concatenate raw values: `1000.databaseValue`. A plain `1000` would not compile.\n    \n    When the sequence is empty, `joined(operator: .add)` returns 0, and `joined(operator: .multiply)` returns 1.\n\n- `&`, `|`, `~`, `<<`, `>>`\n    \n    Bitwise operations (bitwise and, or, not, left shift, right shift) are derived from their Swift equivalent:\n    \n    ```swift\n    // SELECT mask & 2 AS isRocky FROM planet\n    Planet.select { ($0.mask & 2).forKey(\"isRocky\") }\n    ```\n\n- `||`\n    \n    Concatenate several strings:\n    \n    ```swift\n    // SELECT firstName || ' ' || lastName FROM player\n    Player.select {\n        [$0.firstName, \" \".databaseValue, $0.lastName].joined(operator: .concat)\n    }\n    ```\n    \n    Note in the example above how you concatenate raw strings: `\" \".databaseValue`. A plain `\" \"` would not compile.\n    \n    When the sequence is empty, `joined(operator: .concat)` returns the empty string.\n\n- `AND`, `OR`, `NOT`\n    \n    The SQL logical operators are derived from the Swift `&&`, `||` and `!`:\n    \n    ```swift\n    // SELECT * FROM player WHERE ((NOT isVerified) OR (score < 1000))\n    Player.filter { !$0.isVerified || $0.score < 1000 }\n    ```\n    \n    When you want to join a sequence of expressions with the `AND` or `OR` operator, use `joined(operator:)`:\n    \n    ```swift\n    // SELECT * FROM player WHERE (isVerified AND (score >= 1000) AND (name IS NOT NULL))\n    Player.filter {\n        [$0.isVerified, $0.score >= 1000, $0.name != nil].joined(operator: .and)\n    }\n    ```\n    \n    When the sequence is empty, `joined(operator: .and)` returns true, and `joined(operator: .or)` returns false:\n\n- `BETWEEN`, `IN`, `NOT IN`\n    \n    To check inclusion in a Swift sequence (array, set, range‚Ä¶), call the `contains` method:\n    \n    ```swift\n    // SELECT * FROM player WHERE id IN (1, 2, 3)\n    Player.filter { [1, 2, 3].contains($0.id) }\n    \n    // SELECT * FROM player WHERE id NOT IN (1, 2, 3)\n    Player.filter { ![1, 2, 3].contains($0.id) }\n    \n    // SELECT * FROM player WHERE score BETWEEN 0 AND 1000\n    Player.filter { (0...1000).contains($0.score) }\n    \n    // SELECT * FROM player WHERE (score >= 0) AND (score < 1000)\n    Player.filter { (0..<1000).contains($0.score) }\n    \n    // SELECT * FROM player WHERE initial BETWEEN 'A' AND 'N'\n    Player.filter { (\"A\"...\"N\").contains($0.initial) }\n    \n    // SELECT * FROM player WHERE (initial >= 'A') AND (initial < 'N')\n    Player.filter { (\"A\"..<\"N\").contains($0.initial) }\n    ```\n    \n    To check inclusion inside a subquery, call the `contains` method as well:\n    \n    ```swift\n    // SELECT * FROM player WHERE id IN (SELECT playerId FROM playerSelection)\n    let selectedPlayerIds = PlayerSelection.select(\\.playerId)\n    Player.filter { selectedPlayerIds.contains($0.id) }\n    \n    // SELECT * FROM player WHERE id IN (SELECT playerId FROM playerSelection)\n    let selectedPlayerIds = SQLRequest(\"SELECT playerId FROM playerSelection\")\n    Player.filter { selectedPlayerIds.contains($0.id) }\n    ```\n    \n    To check inclusion inside a [common table expression], call the `contains` method as well:\n    \n    ```swift\n    // WITH selectedName AS (...)\n    // SELECT * FROM player WHERE name IN selectedName\n    let cte = CommonTableExpression(named: \"selectedName\", ...)\n    Player\n        .with(cte)\n        .filter { cte.contains($0.name) }\n    ```\n    \n    > **Note**: SQLite string comparison, by default, is case-sensitive and not Unicode-aware. See [string comparison](#string-comparison) if you need more control.\n\n- `EXISTS`, `NOT EXISTS`\n    \n    To check if a subquery would return rows, call the `exists` method:\n    \n    ```swift\n    // Teams that have at least one other player\n    //\n    //  SELECT * FROM team\n    //  WHERE EXISTS (SELECT * FROM player WHERE teamId = team.id)\n    let teamAlias = TableAlias<Team>()\n    let player = Player.filter { $0.teamId == teamAlias.id }\n    let teams = Team.aliased(teamAlias).filter(player.exists())\n    \n    // Teams that have no player\n    //\n    //  SELECT * FROM team\n    //  WHERE NOT EXISTS (SELECT * FROM player WHERE teamId = team.id)\n    let teams = Team.aliased(teamAlias).filter(!player.exists())\n    ```\n    \n    In the above example, you use a `TableAlias` in order to let a subquery refer to a column from another table.\n    \n    In the next example, which involves the same table twice, the table alias requires an explicit disambiguation with `TableAlias(name:)`:\n    \n    ```swift    \n    // Players who coach at least one other player\n    //\n    //  SELECT coach.* FROM player coach\n    //  WHERE EXISTS (SELECT * FROM player WHERE coachId = coach.id)\n    let coachAlias = TableAlias<Player>(name: \"coach\")\n    let coachedPlayer = Player.filter { $0.coachId == coachAlias.id }\n    let coaches = Player.aliased(coachAlias).filter(coachedPlayer.exists())\n    ```\n    \n    Finally, subqueries can also be expressed as SQL, with [SQL Interpolation]:\n    \n    ```swift\n    // SELECT coach.* FROM player coach\n    // WHERE EXISTS (SELECT * FROM player WHERE coachId = coach.id)\n    let coachedPlayer = SQLRequest(\"SELECT * FROM player WHERE coachId = \\(coachAlias.id)\")\n    let coaches = Player.aliased(coachAlias).filter(coachedPlayer.exists())\n    ```\n    \n- `LIKE`\n    \n    The SQLite LIKE operator is available as the `like` method:\n    \n    ```swift\n    // SELECT * FROM player WHERE (email LIKE '%@example.com')\n    Player.filter { $0.email.like(\"%@example.com\") }\n    \n    // SELECT * FROM book WHERE (title LIKE '%10\\%%' ESCAPE '\\')\n    Player.filter { $0.email.like(\"%10\\\\%%\", escape: \"\\\\\") }\n    ```\n    \n    > **Note**: the SQLite LIKE operator is case-insensitive but not Unicode-aware. For example, the expression `'a' LIKE 'A'` is true but `'√¶' LIKE '√Ü'` is false.\n\n- `MATCH`\n    \n    The full-text MATCH operator is available through [FTS3Pattern](Documentation/FullTextSearch.md#fts3pattern) (for FTS3 and FTS4 tables) and [FTS5Pattern](Documentation/FullTextSearch.md#fts5pattern) (for FTS5):\n    \n    FTS3 and FTS4:\n    \n    ```swift\n    let pattern = FTS3Pattern(matchingAllTokensIn: \"SQLite database\")\n    \n    // SELECT * FROM document WHERE document MATCH 'sqlite database'\n    Document.matching(pattern)\n    \n    // SELECT * FROM document WHERE content MATCH 'sqlite database'\n    Document.filter { $0.content.match(pattern) }\n    ```\n    \n    FTS5:\n    \n    ```swift\n    let pattern = FTS5Pattern(matchingAllTokensIn: \"SQLite database\")\n    \n    // SELECT * FROM document WHERE document MATCH 'sqlite database'\n    Document.matching(pattern)\n    ```\n- `AS`\n    \n    To give an alias to an expression, use the `forKey` method:\n    \n    ```swift\n    // SELECT (score + bonus) AS total\n    // FROM player\n    Player.select { ($0.score + $0.bonus).forKey(\"total\") }\n    ```\n    \n    If you need to refer to this aliased column in another place of the request, use a detached column:\n    \n    ```swift\n    // SELECT (score + bonus) AS total\n    // FROM player \n    // ORDER BY total\n    Player\n        .select { ($0.score + $0.bonus).forKey(\"total\") }\n        .order(Column(\"total\").detached)\n    ```\n    \n    The detached column `Column(\"total\").detached` is not considered as a part of the \"player\" table, so it is always rendered as `total` in the generated SQL, even when the request involves other tables via an [association](Documentation/AssociationsBasics.md) or a [common table expression].\n\n\n### SQL Functions\n\nüìñ [`SQLSpecificExpressible`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/sqlspecificexpressible)\n\nGRDB comes with a Swift version of many SQLite [built-in functions](https://sqlite.org/lang_corefunc.html), listed below. But not all: see [Embedding SQL in Query Interface Requests] for a way to add support for missing SQL functions.\n\n- `ABS`, `AVG`, `COALESCE`, `COUNT`, `DATETIME`, `JULIANDAY`, `LENGTH`, `MAX`, `MIN`, `SUM`, `TOTAL`:\n    \n    Those are based on the `abs`, `average`, `coalesce`, `count`, `dateTime`, `julianDay`, `length`, `max`, `min`, `sum`, and `total` Swift functions:\n    \n    ```swift\n    // SELECT MIN(score), MAX(score) FROM player\n    Player.select { [min($0.score), max($0.score)] }\n    \n    // SELECT COUNT(name) FROM player\n    Player.select { count($0.name) }\n    \n    // SELECT COUNT(DISTINCT name) FROM player\n    Player.select { count(distinct: $0.name) }\n    \n    // SELECT JULIANDAY(date, 'start of year') FROM game\n    Game.select { julianDay($0.date, .startOfYear) }\n    ```\n    \n    For more information about the functions `dateTime` and `julianDay`, see [Date And Time Functions](https://www.sqlite.org/lang_datefunc.html).\n\n- `CAST`\n\n    Use the `cast` Swift function:\n    \n    ```swift\n    // SELECT (CAST(wins AS REAL) / games) AS successRate FROM player\n    Player.select { (cast($0.wins, as: .real) / $0.games).forKey(\"successRate\") }\n    ```\n    \n    See [CAST expressions](https://www.sqlite.org/lang_expr.html#castexpr) for more information about SQLite conversions.\n\n- `IFNULL`\n    \n    Use the Swift `??` operator:\n    \n    ```swift\n    // SELECT IFNULL(name, 'Anonymous') FROM player\n    Player.select { $0.name ?? \"Anonymous\" }\n    \n    // SELECT IFNULL(name, email) FROM player\n    Player.select { $0.name ?? $0.email }\n    ```\n\n- `LOWER`, `UPPER`\n    \n    The query interface does not give access to those SQLite functions. Nothing against them, but they are not unicode aware.\n    \n    Instead, GRDB extends SQLite with SQL functions that call the Swift built-in string functions `capitalized`, `lowercased`, `uppercased`, `localizedCapitalized`, `localizedLowercased` and `localizedUppercased`:\n    \n    ```swift\n    Player.select { $0.name.uppercased() }\n    ```\n    \n    > **Note**: When *comparing* strings, you'd rather use a [collation](#string-comparison):\n    >\n    > ```swift\n    > let name: String = ...\n    >\n    > // Not recommended\n    > Player.filter { $0.name.uppercased() == name.uppercased() }\n    >\n    > // Better\n    > Player.filter { $0.name.collating(.caseInsensitiveCompare) == name }\n    > ```\n\n- Custom SQL functions and aggregates\n    \n    You can apply your own [custom SQL functions and aggregates](#custom-functions-):\n    \n    ```swift\n    let myFunction = DatabaseFunction(\"myFunction\", ...)\n    \n    // SELECT myFunction(name) FROM player\n    Player.select { myFunction($0.name) }\n    ```\n\n## Embedding SQL in Query Interface Requests\n\nYou will sometimes want to extend your query interface requests with SQL snippets. This can happen because GRDB does not provide a Swift interface for some SQL function or operator, or because you want to use an SQLite construct that GRDB does not support.\n\nSupport for extensibility is large, but not unlimited. All the SQL queries built by the query interface request have the shape below. _If you need something else, you'll have to use [raw SQL requests](#sqlite-api)._\n\n```sql\nWITH ...     -- 1\nSELECT ...   -- 2\nFROM ...     -- 3\nJOIN ...     -- 4\nWHERE ...    -- 5\nGROUP BY ... -- 6\nHAVING ...   -- 7\nORDER BY ... -- 8\nLIMIT ...    -- 9\n```\n\n1. `WITH ...`: see [Common Table Expressions].\n\n2. `SELECT ...`\n\n    The selection can be provided as raw SQL:\n    \n    ```swift\n    // SELECT IFNULL(name, 'O''Brien'), score FROM player\n    let request = Player.select(sql: \"IFNULL(name, 'O''Brien'), score\")\n    \n    // SELECT IFNULL(name, 'O''Brien'), score FROM player\n    let defaultName = \"O'Brien\"\n    let request = Player.select(sql: \"IFNULL(name, ?), score\", arguments: [suffix])\n    ```\n\n    The selection can be provided with [SQL Interpolation]:\n    \n    ```swift\n    // SELECT IFNULL(name, 'O''Brien'), score FROM player\n    let defaultName = \"O'Brien\"\n    let request = Player.select(literal: \"IFNULL(name, \\(defaultName)), score\")\n    ```\n    \n    The selection can be provided with a mix of Swift and [SQL Interpolation]:\n    \n    ```swift\n    // SELECT IFNULL(name, 'O''Brien') AS displayName, score FROM player\n    let defaultName = \"O'Brien\"\n    let request = Player.select {\n        let displayName: SQL = \"IFNULL(\\($0.name), \\(defaultName)) AS displayName\"\n        return [displayName, $0.score]\n    }\n    ```\n    \n    When the custom SQL snippet should behave as a full-fledged expression, with support for the `+` Swift operator, the `forKey` aliasing method, and all other [SQL Operators](#sql-operators), build an _expression literal_ with the `SQL.sqlExpression` method:\n    \n    ```swift\n    // SELECT IFNULL(name, 'O''Brien') AS displayName, score FROM player\n    let defaultName = \"O'Brien\"\n    let request = Player.select {\n        let displayName = SQL(\"IFNULL(\\($0.name), \\(defaultName))\").sqlExpression\n        return [displayName.forKey(\"displayName\"), $0.score]\n    }\n    ```\n    \n    Such expression literals allow you to build a reusable support library of SQL functions or operators that are missing from the query interface. For example, you can define a Swift `date` function:\n    \n    ```swift\n    func date(_ value: some SQLSpecificExpressible) -> SQLExpression {\n        SQL(\"DATE(\\(value))\").sqlExpression\n    }\n    \n    // SELECT * FROM \"player\" WHERE DATE(\"createdAt\") = '2020-01-23'\n    let request = Player.filter { date($0.createdAt) == \"2020-01-23\" }\n    ```\n    \n    See the [Query Interface Organization] for more information about `SQLSpecificExpressible` and `SQLExpression`.\n    \n3. `FROM ...`: only one table is supported here. You can not customize this SQL part.\n\n4. `JOIN ...`: joins are fully controlled by [Associations]. You can not customize this SQL part.\n\n5. `WHERE ...`\n    \n    The WHERE clause can be provided as raw SQL:\n    \n    ```swift\n    // SELECT * FROM player WHERE score >= 1000\n    let request = Player.filter(sql: \"score >= 1000\")\n    \n    // SELECT * FROM player WHERE score >= 1000\n    let minScore = 1000\n    let request = Player.filter(sql: \"score >= ?\", arguments: [minScore])\n    ```\n\n    The WHERE clause can be provided with [SQL Interpolation]:\n    \n    ```swift\n    // SELECT * FROM player WHERE score >= 1000\n    let minScore = 1000\n    let request = Player.filter(literal: \"score >= \\(minScore)\")\n    ```\n    \n    The WHERE clause can be provided with a mix of Swift and [SQL Interpolation]:\n    \n    ```swift\n    // SELECT * FROM player WHERE (score >= 1000) AND (team = 'red')\n    let minScore = 1000\n    let request = Player.filter { \n        let scoreCondition: SQL = \"\\($0.score) >= \\(minScore)\"\n        return scoreCondition && $0.team == \"red\"\n    }\n    ```\n    \n    See `SELECT ...` above for more SQL Interpolation examples.\n    \n6. `GROUP BY ...`\n\n    The GROUP BY clause can be provided as raw SQL, SQL Interpolation, or a mix of Swift and SQL Interpolation, just as the selection and the WHERE clause (see above).\n    \n7. `HAVING ...`\n\n    The HAVING clause can be provided as raw SQL, SQL Interpolation, or a mix of Swift and SQL Interpolation, just as the selection and the WHERE clause (see above).\n    \n8. `ORDER BY ...`\n\n    The ORDER BY clause can be provided as raw SQL, SQL Interpolation, or a mix of Swift and SQL Interpolation, just as the selection and the WHERE clause (see above).\n    \n    In order to support the `desc` and `asc` query interface operators, and the `reversed()` query interface method, you must provide your orderings as _expression literals_ with the `SQL.sqlExpression` method:\n    \n    ```swift\n    // SELECT * FROM \"player\" \n    // ORDER BY (score + bonus) ASC, name DESC\n    let request = Player\n        .order {\n            let total = SQL(\"(\\($0.score) + \\($0.bonus))\").sqlExpression\n            return [total.desc, $0.name]\n        }\n        .reversed()\n    ```\n    \n9. `LIMIT ...`: use the `limit(_:offset:)` method. You can not customize this SQL part.\n\n\n## Fetching from Requests\n\nOnce you have a request, you can fetch the records at the origin of the request:\n\n```swift\n// Some request based on `Player`\nlet request = Player.filter { ... }... // QueryInterfaceRequest<Player>\n\n// Fetch players:\ntry request.fetchCursor(db) // A Cursor of Player\ntry request.fetchAll(db)    // [Player]\ntry request.fetchSet(db)    // Set<Player>\ntry request.fetchOne(db)    // Player?\n```\n\nFor example:\n\n```swift\nlet allPlayers = try Player.fetchAll(db)                            // [Player]\nlet arthur = try Player.filter { $0.name == \"Arthur\" }.fetchOne(db) // Player?\n```\n\nSee [fetching methods](#fetching-methods) for information about the `fetchCursor`, `fetchAll`, `fetchSet` and `fetchOne` methods.\n\n**You sometimes want to fetch other values**.\n\nThe simplest way is to use the request as an argument to a fetching method of the desired type:\n\n```swift\n// Fetch an Int\nlet request = Player.select { max($0.score) }\nlet maxScore = try Int.fetchOne(db, request) // Int?\n\n// Fetch a Row\nlet request = Player.select { [min($0.score), max($0.score)] }\nlet row = try Row.fetchOne(db, request)!     // Row\nlet minScore = row[0] as Int?\nlet maxScore = row[1] as Int?\n```\n\nYou can also change the request so that it knows the type it has to fetch:\n\n- With `asRequest(of:)`, useful when you use [Associations]:\n    \n    ```swift\n    struct BookInfo: FetchableRecord, Decodable {\n        var book: Book\n        var author: Author\n    }\n    \n    // A request of BookInfo\n    let request = Book\n        .including(required: Book.author)\n        .asRequest(of: BookInfo.self)\n    \n    let bookInfos = try dbQueue.read { db in\n        try request.fetchAll(db) // [BookInfo]\n    }\n    ```\n    \n- With `select(..., as:)`, which is handy when you change the selection:\n    \n    ```swift\n    // A request of Int\n    let request = Player.select({ max($0.score) }, as: Int.self)\n    \n    let maxScore = try dbQueue.read { db in\n        try request.fetchOne(db) // Int?\n    }\n    ```\n\n\n## Fetching by Key\n\n**Fetching records according to their primary key** is a common task.\n\n[Identifiable Records] can use the type-safe methods `find(_:id:)`, `fetchOne(_:id:)`, `fetchAll(_:ids:)` and `fetchSet(_:ids:)`:\n\n```swift\ntry Player.find(db, id: 1)                   // Player\ntry Player.fetchOne(db, id: 1)               // Player?\ntry Country.fetchAll(db, ids: [\"FR\", \"US\"])  // [Countries]\n```\n\nAll record types can use `find(_:key:)`, `fetchOne(_:key:)`, `fetchAll(_:keys:)` and `fetchSet(_:keys:)` that apply conditions on primary and unique keys:\n\n```swift\ntry Player.find(db, key: 1)                  // Player\ntry Player.fetchOne(db, key: 1)              // Player?\ntry Country.fetchAll(db, keys: [\"FR\", \"US\"]) // [Country]\ntry Player.fetchOne(db, key: [\"email\": \"arthur@example.com\"])            // Player?\ntry Citizenship.fetchOne(db, key: [\"citizenId\": 1, \"countryCode\": \"FR\"]) // Citizenship?\n```\n\nWhen the table has no explicit primary key, GRDB uses the [hidden `rowid` column](https://www.sqlite.org/rowidtable.html):\n\n```swift\n// SELECT * FROM document WHERE rowid = 1\ntry Document.fetchOne(db, key: 1)            // Document?\n```\n\n**When you want to build a request and plan to fetch from it later**, use a `filter` method:\n\n```swift\nlet request = Player.filter(id: 1)\nlet request = Country.filter(ids: [\"FR\", \"US\"])\nlet request = Player.filter(key: [\"email\": \"arthur@example.com\"])\nlet request = Citizenship.filter(key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n```\n\n\n## Testing for Record Existence\n\n**You can check if a request has matching rows in the database.**\n\n```swift\n// Some request based on `Player`\nlet request = Player.filter { ... }...\n\n// Check for player existence:\nlet noSuchPlayer = try request.isEmpty(db) // Bool\n```\n\nYou should check for emptiness instead of counting:\n\n```swift\n// Correct\nlet noSuchPlayer = try request.fetchCount(db) == 0\n// Even better\nlet noSuchPlayer = try request.isEmpty(db)\n```\n\n**You can also check if a given primary or unique key exists in the database.**\n\n[Identifiable Records] can use the type-safe method `exists(_:id:)`:\n\n```swift\ntry Player.exists(db, id: 1)\ntry Country.exists(db, id: \"FR\")\n```\n\nAll record types can use `exists(_:key:)` that can check primary and unique keys:\n\n```swift\ntry Player.exists(db, key: 1)\ntry Country.exists(db, key: \"FR\")\ntry Player.exists(db, key: [\"email\": \"arthur@example.com\"])\ntry Citizenship.exists(db, key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n```\n\nYou should check for key existence instead of fetching a record and checking for nil:\n\n```swift\n// Correct\nlet playerExists = try Player.fetchOne(db, id: 1) != nil\n// Even better\nlet playerExists = try Player.exists(db, id: 1)\n```\n\n\n## Fetching Aggregated Values\n\n**Requests can count.** The `fetchCount()` method returns the number of rows that would be returned by a fetch request:\n\n```swift\n// SELECT COUNT(*) FROM player\nlet count = try Player.fetchCount(db) // Int\n\n// SELECT COUNT(*) FROM player WHERE email IS NOT NULL\nlet count = try Player.filter { $0.email != nil }.fetchCount(db)\n\n// SELECT COUNT(DISTINCT name) FROM player\nlet count = try Player.select(\\.name).distinct().fetchCount(db)\n\n// SELECT COUNT(*) FROM (SELECT DISTINCT name, score FROM player)\nlet count = try Player.select { [$0.name, $0.score] }.distinct().fetchCount(db)\n```\n\n\n**Other aggregated values** can also be selected and fetched (see [SQL Functions](#sql-functions)):\n\n```swift\nlet request = Player.select { max($0.score) }\nlet maxScore = try Int.fetchOne(db, request) // Int?\n\nlet request = Player.select { [min($0.score), max($0.score)] }\nlet row = try Row.fetchOne(db, request)!     // Row\nlet minScore = row[0] as Int?\nlet maxScore = row[1] as Int?\n```\n\n\n## Delete Requests\n\n**Requests can delete records**, with the `deleteAll()` method:\n\n```swift\n// DELETE FROM player\ntry Player.deleteAll(db)\n\n// DELETE FROM player WHERE team = 'Reds'\ntry Player\n    .filter { $0.team == \"Reds\" }\n    .deleteAll(db)\n\n// DELETE FROM player ORDER BY score LIMIT 10\ntry Player\n    .order(\\.score)\n    .limit(10)\n    .deleteAll(db)\n```\n\n> **Note** Deletion methods are available on types that adopt the [TableRecord] protocol, and `Table`:\n>\n> ```swift\n> struct Player: TableRecord { ... }\n> try Player.deleteAll(db)          // Fine\n> try Table(\"player\").deleteAll(db) // Just as fine\n> ```\n\n**Deleting records according to their primary key** is a common task.\n\n[Identifiable Records] can use the type-safe methods `deleteOne(_:id:)` and `deleteAll(_:ids:)`:\n\n```swift\ntry Player.deleteOne(db, id: 1)\ntry Country.deleteAll(db, ids: [\"FR\", \"US\"])\n```\n\nAll record types can use `deleteOne(_:key:)` and `deleteAll(_:keys:)` that apply conditions on primary and unique keys:\n\n```swift\ntry Player.deleteOne(db, key: 1)\ntry Country.deleteAll(db, keys: [\"FR\", \"US\"])\ntry Player.deleteOne(db, key: [\"email\": \"arthur@example.com\"])\ntry Citizenship.deleteOne(db, key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n```\n\nWhen the table has no explicit primary key, GRDB uses the [hidden `rowid` column](https://www.sqlite.org/rowidtable.html):\n\n```swift\n// DELETE FROM document WHERE rowid = 1\ntry Document.deleteOne(db, id: 1)             // Document?\n```\n\n\n## Update Requests\n\n**Requests can batch update records**. The `updateAll()` method accepts *column assignments* defined with the `set(to:)` method:\n\n```swift\n// UPDATE player SET score = 0, isHealthy = 1, bonus = NULL\ntry Player.updateAll(db) { [\n    $0.score.set(to: 0), \n    $0.isHealthy.set(to: true), \n    $0.bonus.set(to: nil),\n] }\n\n// UPDATE player SET score = 0 WHERE team = 'Reds'\ntry Player\n    .filter { $0.team == \"Reds\" }\n    .updateAll(db) { $0.score.set(to: 0) }\n\n// UPDATE player SET isGreat = 1 ORDER BY score DESC LIMIT 10\ntry Player\n    .order(\\.score.desc)\n    .limit(10)\n    .updateAll(db) { $0.isGreat.set(to: true) }\n\n// UPDATE country SET population = 67848156 WHERE id = 'FR'\ntry Country\n    .filter(id: \"FR\")\n    .updateAll(db) { $0.population.set(to: 67_848_156) }\n```\n\nColumn assignments accept any expression:\n\n```swift\n// UPDATE player SET score = score + (bonus * 2)\ntry Player.updateAll(db) {\n    $0.score.set(to: $0.score + $0.bonus * 2)\n}\n```\n\nAs a convenience, you can also use the `+=`, `-=`, `*=`, or `/=` operators:\n\n```swift\n// UPDATE player SET score = score + (bonus * 2)\ntry Player.updateAll(db) { $0.score += $0.bonus * 2 }\n```\n\nDefault [Conflict Resolution] rules apply, and you may also provide a specific one:\n\n```swift\n// UPDATE OR IGNORE player SET ...\ntry Player.updateAll(db, onConflict: .ignore) { /* assignments... */ }\n```\n\n> **Note** The `updateAll` method is available on types that adopt the [TableRecord] protocol, and `Table`:\n>\n> ```swift\n> struct Player: TableRecord { ... }\n> try Player.updateAll(db, ...)          // Fine\n> try Table(\"player\").updateAll(db, ...) // Just as fine\n> ```\n\n\n## Custom Requests\n\nUntil now, we have seen [requests](#requests) created from any type that adopts the [TableRecord] protocol:\n\n```swift\nlet request = Player.all()  // QueryInterfaceRequest<Player>\n```\n\nThose requests of type `QueryInterfaceRequest` can fetch and count:\n\n```swift\ntry request.fetchCursor(db) // A Cursor of Player\ntry request.fetchAll(db)    // [Player]\ntry request.fetchSet(db)    // Set<Player>\ntry request.fetchOne(db)    // Player?\ntry request.fetchCount(db)  // Int\n```\n\n**When the query interface can not generate the SQL you need**, you can still fallback to [raw SQL](#fetch-queries):\n\n```swift\n// Custom SQL is always welcome\ntry Player.fetchAll(db, sql: \"SELECT ...\")   // [Player]\n```\n\nBut you may prefer to bring some elegance back in, and build custom requests:\n\n```swift\n// No custom SQL in sight\ntry Player.customRequest().fetchAll(db) // [Player]\n```\n\n**To build custom requests**, you can use one of the built-in requests or derive requests from other requests.\n\n- [SQLRequest] is a fetch request built from raw SQL. For example:\n    \n    ```swift\n    extension Player {\n        static func filter(color: Color) -> SQLRequest<Player> {\n            SQLRequest<Player>(\n                sql: \"SELECT * FROM player WHERE color = ?\"\n                arguments: [color])\n        }\n    }\n    \n    // [Player]\n    try Player.filter(color: .red).fetchAll(db)\n    ```\n    \n    SQLRequest supports [SQL Interpolation]:\n    \n    ```swift\n    extension Player {\n        static func filter(color: Color) -> SQLRequest<Player> {\n            \"SELECT * FROM player WHERE color = \\(color)\"\n        }\n    }\n    ```\n    \n- The [`asRequest(of:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/asrequest(of:)) method changes the type fetched by the request. It is useful, for example, when you use [Associations]:\n\n    ```swift\n    struct BookInfo: FetchableRecord, Decodable {\n        var book: Book\n        var author: Author\n    }\n    \n    let request = Book\n        .including(required: Book.author)\n        .asRequest(of: BookInfo.self)\n    \n    // [BookInfo]\n    try request.fetchAll(db)\n    ```\n\n- The [`adapted(_:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/fetchrequest/adapted(_:)) method eases the consumption of complex rows with row adapters. See [`RowAdapter`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/rowadapter) and [`splittingRowAdapters(columnCounts:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/splittingrowadapters(columncounts:)) for a sample code that uses `adapted(_:)`.\n\n\nEncryption\n==========\n\n**GRDB can encrypt your database with [SQLCipher](http://sqlcipher.net) v3.4+.**\n\nUse [CocoaPods](http://cocoapods.org/), and specify in your `Podfile`:\n\n```ruby\n# GRDB with SQLCipher 4\npod 'GRDB.swift/SQLCipher'\npod 'SQLCipher', '~> 4.0'\n\n# GRDB with SQLCipher 3\npod 'GRDB.swift/SQLCipher'\npod 'SQLCipher', '~> 3.4'\n```\n\nMake sure you remove any existing `pod 'GRDB.swift'` from your Podfile. `GRDB.swift/SQLCipher` must be the only active GRDB pod in your whole project, or you will face linker or runtime errors, due to the conflicts between SQLCipher and the system SQLite.\n\n- [Creating or Opening an Encrypted Database](#creating-or-opening-an-encrypted-database)\n- [Changing the Passphrase of an Encrypted Database](#changing-the-passphrase-of-an-encrypted-database)\n- [Exporting a Database to an Encrypted Database](#exporting-a-database-to-an-encrypted-database)\n- [Security Considerations](#security-considerations)\n\n\n### Creating or Opening an Encrypted Database\n\n**You create and open an encrypted database** by providing a passphrase to your [database connection]:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(\"secret\")\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nIt is also in `prepareDatabase` that you perform other [SQLCipher configuration steps](https://www.zetetic.net/sqlcipher/sqlcipher-api/) that must happen early in the lifetime of a SQLCipher connection. For example:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(\"secret\")\n    try db.execute(sql: \"PRAGMA cipher_page_size = ...\")\n    try db.execute(sql: \"PRAGMA kdf_iter = ...\")\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nWhen you want to open an existing SQLCipher 3 database with SQLCipher 4, you may want to run the `cipher_compatibility` pragma:\n\n```swift\n// Open an SQLCipher 3 database with SQLCipher 4\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(\"secret\")\n    try db.execute(sql: \"PRAGMA cipher_compatibility = 3\")\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nSee [SQLCipher 4.0.0 Release](https://www.zetetic.net/blog/2018/11/30/sqlcipher-400-release/) and [Upgrading to SQLCipher 4](https://discuss.zetetic.net/t/upgrading-to-sqlcipher-4/3283) for more information.\n\n\n### Changing the Passphrase of an Encrypted Database\n\n**You can change the passphrase** of an already encrypted database.\n\nWhen you use a [database queue](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasequeue), open the database with the old passphrase, and then apply the new passphrase:\n\n```swift\ntry dbQueue.write { db in\n    try db.changePassphrase(\"newSecret\")\n}\n```\n\nWhen you use a [database pool](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool), make sure that no concurrent read can happen by changing the passphrase within the `barrierWriteWithoutTransaction` block. You must also ensure all future reads open a new database connection by calling the `invalidateReadOnlyConnections` method:\n\n```swift\ntry dbPool.barrierWriteWithoutTransaction { db in\n    try db.changePassphrase(\"newSecret\")\n    dbPool.invalidateReadOnlyConnections()\n}\n```\n\n> **Note**: When an application wants to keep on using a database queue or pool after the passphrase has changed, it is responsible for providing the correct passphrase to the `usePassphrase` method called in the database preparation function. Consider:\n>\n> ```swift\n> // WRONG: this won't work across a passphrase change\n> let passphrase = try getPassphrase()\n> var config = Configuration()\n> config.prepareDatabase { db in\n>     try db.usePassphrase(passphrase)\n> }\n>\n> // CORRECT: get the latest passphrase when it is needed\n> var config = Configuration()\n> config.prepareDatabase { db in\n>     let passphrase = try getPassphrase()\n>     try db.usePassphrase(passphrase)\n> }\n> ```\n\n> **Note**: The `DatabasePool.barrierWriteWithoutTransaction` method does not prevent [database snapshots](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasesnapshot) from accessing the database during the passphrase change, or after the new passphrase has been applied to the database. Those database accesses may throw errors. Applications should provide their own mechanism for invalidating open snapshots before the passphrase is changed.\n\n> **Note**: Instead of changing the passphrase \"in place\" as described here, you can also export the database in a new encrypted database that uses the new passphrase. See [Exporting a Database to an Encrypted Database](#exporting-a-database-to-an-encrypted-database).\n\n\n### Exporting a Database to an Encrypted Database\n\nProviding a passphrase won't encrypt a clear-text database that already exists, though. SQLCipher can't do that, and you will get an error instead: `SQLite error 26: file is encrypted or is not a database`.\n\nInstead, create a new encrypted database, at a distinct location, and export the content of the existing database. This can both encrypt a clear-text database, or change the passphrase of an encrypted database.\n\nThe technique to do that is [documented](https://discuss.zetetic.net/t/how-to-encrypt-a-plaintext-sqlite-database-to-use-sqlcipher-and-avoid-file-is-encrypted-or-is-not-a-database-errors/868/1) by SQLCipher.\n\nWith GRDB, it gives:\n\n```swift\n// The existing database\nlet existingDBQueue = try DatabaseQueue(path: \"/path/to/existing.db\")\n\n// The new encrypted database, at some distinct location:\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(\"secret\")\n}\nlet newDBQueue = try DatabaseQueue(path: \"/path/to/new.db\", configuration: config)\n\ntry existingDBQueue.inDatabase { db in\n    try db.execute(\n        sql: \"\"\"\n            ATTACH DATABASE ? AS encrypted KEY ?;\n            SELECT sqlcipher_export('encrypted');\n            DETACH DATABASE encrypted;\n            \"\"\",\n        arguments: [newDBQueue.path, \"secret\"])\n}\n\n// Now the export is completed, and the existing database can be deleted.\n```\n\n\n### Security Considerations\n\n#### Managing the lifetime of the passphrase string\n\nIt is recommended to avoid keeping the passphrase in memory longer than necessary. To do this, make sure you load the passphrase from the `prepareDatabase` method:\n\n```swift\n// NOT RECOMMENDED: this keeps the passphrase in memory longer than necessary\nlet passphrase = try getPassphrase()\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(passphrase)\n}\n\n// RECOMMENDED: only load the passphrase when it is needed\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    let passphrase = try getPassphrase()\n    try db.usePassphrase(passphrase)\n}\n```\n\nThis technique helps manages the lifetime of the passphrase, although keep in mind that the content of a String may remain intact in memory long after the object has been released.\n\nFor even better control over the lifetime of the passphrase in memory, use a Data object which natively provides the `resetBytes` function.\n\n```swift\n// RECOMMENDED: only load the passphrase when it is needed and reset its content immediately after use\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    var passphraseData = try getPassphraseData() // Data\n    defer {\n        passphraseData.resetBytes(in: 0..<passphraseData.count)\n    }\n    try db.usePassphrase(passphraseData)\n}\n```\n\nSome demanding users will want to go further, and manage the lifetime of the raw passphrase bytes. See below.\n\n\n#### Managing the lifetime of the passphrase bytes\n\nGRDB offers convenience methods for providing the database passphrases as Swift strings: `usePassphrase(_:)` and `changePassphrase(_:)`. Those methods don't keep the passphrase String in memory longer than necessary. But they are as secure as the standard String type: the lifetime of actual passphrase bytes in memory is not under control.\n\nWhen you want to precisely manage the passphrase bytes, talk directly to SQLCipher, using its raw C functions.\n\nFor example:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    ... // Carefully load passphrase bytes\n    let code = sqlite3_key(db.sqliteConnection, /* passphrase bytes */)\n    ... // Carefully dispose passphrase bytes\n    guard code == SQLITE_OK else {\n        throw DatabaseError(\n            resultCode: ResultCode(rawValue: code), \n            message: db.lastErrorMessage)\n    }\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\n#### Passphrase availability vs. Database availability\n\nWhen the passphrase is securely stored in the system keychain, your application can protect it using the [`kSecAttrAccessible`](https://developer.apple.com/documentation/security/ksecattraccessible) attribute.\n\nSuch protection prevents GRDB from creating SQLite connections when the passphrase is not available:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    let passphrase = try loadPassphraseFromSystemKeychain()\n    try db.usePassphrase(passphrase)\n}\n\n// Success if and only if the passphrase is available\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nFor the same reason, [database pools], which open SQLite connections on demand, may fail at any time as soon as the passphrase becomes unavailable:\n\n```swift\n// Success if and only if the passphrase is available\nlet dbPool = try DatabasePool(path: dbPath, configuration: config)\n\n// May fail if passphrase has turned unavailable\ntry dbPool.read { ... }\n\n// May trigger value observation failure if passphrase has turned unavailable\ntry dbPool.write { ... }\n```\n\nBecause DatabasePool maintains a pool of long-lived SQLite connections, some database accesses will use an existing connection, and succeed. And some other database accesses will fail, as soon as the pool wants to open a new connection. It is impossible to predict which accesses will succeed or fail.\n\nFor the same reason, a database queue, which also maintains a long-lived SQLite connection, will remain available even after the passphrase has turned unavailable.\n\nApplications are thus responsible for protecting database accesses when the passphrase is unavailable. To this end, they can use [Data Protection](https://developer.apple.com/documentation/uikit/protecting_the_user_s_privacy/encrypting_your_app_s_files). They can also destroy their instances of database queue or pool when the passphrase becomes unavailable.\n\n\n## Backup\n\n**You can backup (copy) a database into another.**\n\nBackups can for example help you copying an in-memory database to and from a database file when you implement NSDocument subclasses.\n\n```swift\nlet source: DatabaseQueue = ...      // or DatabasePool\nlet destination: DatabaseQueue = ... // or DatabasePool\ntry source.backup(to: destination)\n```\n\nThe `backup` method blocks the current thread until the destination database contains the same contents as the source database.\n\nWhen the source is a [database pool](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool), concurrent writes can happen during the backup. Those writes may, or may not, be reflected in the backup, but they won't trigger any error.\n\n`Database` has an analogous `backup` method.\n\n```swift\nlet source: DatabaseQueue = ...      // or DatabasePool\nlet destination: DatabaseQueue = ... // or DatabasePool\ntry source.write { sourceDb in\n    try destination.barrierWriteWithoutTransaction { destDb in\n        try sourceDb.backup(to: destDb)\n    }\n}\n```\n\nThis method allows for the choice of source and destination `Database` handles with which to backup the database.\n\n### Backup Progress Reporting\n\nThe `backup` methods take optional `pagesPerStep` and `progress` parameters. Together these parameters can be used to track a database backup in progress and abort an incomplete backup.\n\nWhen `pagesPerStep` is provided, the database backup is performed in _steps_. At each step, no more than `pagesPerStep` database pages are copied from the source to the destination. The backup proceeds one step at a time until all pages have been copied.\n\nWhen a `progress` callback is provided, `progress` is called after every backup step, including the last. Even if a non-default `pagesPerStep` is specified or the backup is otherwise completed in a single step, the `progress` callback will be called.\n\n```swift\ntry source.backup(\n    to: destination,\n    pagesPerStep: ...)\n    { backupProgress in\n       print(\"Database backup progress:\", backupProgress)\n    }\n```\n\n### Aborting an Incomplete Backup\n\nIf a call to `progress` throws when `backupProgress.isComplete == false`, the backup will be aborted and the error rethrown. However, if a call to `progress` throws when `backupProgress.isComplete == true`, the backup is unaffected and the error is silently ignored.\n\n> **Warning**: Passing non-default values of `pagesPerStep` or `progress` to the backup methods is an advanced API intended to provide additional capabilities to expert users. GRDB's backup API provides a faithful, low-level wrapper to the underlying SQLite online backup API. GRDB's documentation is not a comprehensive substitute for the official SQLite [documentation of their backup API](https://www.sqlite.org/c3ref/backup_finish.html).\n\n## Interrupt a Database\n\n**The `interrupt()` method** causes any pending database operation to abort and return at its earliest opportunity.\n\nIt can be called from any thread.\n\n```swift\ndbQueue.interrupt()\ndbPool.interrupt()\n```\n\nA call to `interrupt()` that occurs when there are no running SQL statements is a no-op and has no effect on SQL statements that are started after `interrupt()` returns.\n\nA database operation that is interrupted will throw a DatabaseError with code `SQLITE_INTERRUPT`. If the interrupted SQL operation is an INSERT, UPDATE, or DELETE that is inside an explicit transaction, then the entire transaction will be rolled back automatically. If the rolled back transaction was started by a transaction-wrapping method such as `DatabaseWriter.write` or `Database.inTransaction`, then all database accesses will throw a DatabaseError with code `SQLITE_ABORT` until the wrapping method returns.\n\nFor example:\n\n```swift\ntry dbQueue.write { db in\n    try Player(...).insert(db)     // throws SQLITE_INTERRUPT\n    try Player(...).insert(db)     // not executed\n}                                  // throws SQLITE_INTERRUPT\n\ntry dbQueue.write { db in\n    do {\n        try Player(...).insert(db) // throws SQLITE_INTERRUPT\n    } catch { }\n}                                  // throws SQLITE_ABORT\n\ntry dbQueue.write { db in\n    do {\n        try Player(...).insert(db) // throws SQLITE_INTERRUPT\n    } catch { }\n    try Player(...).insert(db)     // throws SQLITE_ABORT\n}                                  // throws SQLITE_ABORT\n```\n\nYou can catch both `SQLITE_INTERRUPT` and `SQLITE_ABORT` errors:\n\n```swift\ndo {\n    try dbPool.write { db in ... }\n} catch DatabaseError.SQLITE_INTERRUPT, DatabaseError.SQLITE_ABORT {\n    // Oops, the database was interrupted.\n}\n```\n\nFor more information, see [Interrupt A Long-Running Query](https://www.sqlite.org/c3ref/interrupt.html).\n\n\n## Avoiding SQL Injection\n\nSQL injection is a technique that lets an attacker nuke your database.\n\n> ![XKCD: Exploits of a Mom](https://imgs.xkcd.com/comics/exploits_of_a_mom.png)\n>\n> https://xkcd.com/327/\n\nHere is an example of code that is vulnerable to SQL injection:\n\n```swift\n// BAD BAD BAD\nlet id = 1\nlet name = textField.text\ntry dbQueue.write { db in\n    try db.execute(sql: \"UPDATE students SET name = '\\(name)' WHERE id = \\(id)\")\n}\n```\n\nIf the user enters a funny string like `Robert'; DROP TABLE students; --`, SQLite will see the following SQL, and drop your database table instead of updating a name as intended:\n\n```sql\nUPDATE students SET name = 'Robert';\nDROP TABLE students;\n--' WHERE id = 1\n```\n\nTo avoid those problems, **never embed raw values in your SQL queries**. The only correct technique is to provide [arguments](#executing-updates) to your raw SQL queries:\n\n```swift\nlet name = textField.text\ntry dbQueue.write { db in\n    // Good\n    try db.execute(\n        sql: \"UPDATE students SET name = ? WHERE id = ?\",\n        arguments: [name, id])\n    \n    // Just as good\n    try db.execute(\n        sql: \"UPDATE students SET name = :name WHERE id = :id\",\n        arguments: [\"name\": name, \"id\": id])\n}\n```\n\nWhen you use [records](#records) and the [query interface](#the-query-interface), GRDB always prevents SQL injection for you:\n\n```swift\nlet id = 1\nlet name = textField.text\ntry dbQueue.write { db in\n    if var student = try Student.fetchOne(db, id: id) {\n        student.name = name\n        try student.update(db)\n    }\n}\n```\n\n\n## Error Handling\n\nGRDB can throw [DatabaseError](#databaseerror), [RecordError], [RowDecodingError], or crash your program with a [fatal error](#fatal-errors).\n\nConsidering that a local database is not some JSON loaded from a remote server, GRDB focuses on **trusted databases**. Dealing with [untrusted databases](#how-to-deal-with-untrusted-inputs) requires extra care.\n\n- [DatabaseError](#databaseerror)\n- [RecordError]\n- [RowDecodingError]\n- [Fatal Errors](#fatal-errors)\n- [How to Deal with Untrusted Inputs](#how-to-deal-with-untrusted-inputs)\n- [Error Log](#error-log)\n\n\n### DatabaseError\n\nüìñ [`DatabaseError`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseerror)\n\n**DatabaseError** are thrown on SQLite errors:\n\n```swift\ndo {\n    try Pet(masterId: 1, name: \"Bobby\").insert(db)\n} catch let error as DatabaseError {\n    // The SQLite error code: 19 (SQLITE_CONSTRAINT)\n    error.resultCode\n    \n    // The extended error code: 787 (SQLITE_CONSTRAINT_FOREIGNKEY)\n    error.extendedResultCode\n    \n    // The eventual SQLite message: FOREIGN KEY constraint failed\n    error.message\n    \n    // The eventual erroneous SQL query\n    // \"INSERT INTO pet (masterId, name) VALUES (?, ?)\"\n    error.sql\n    \n    // The eventual SQL arguments\n    // [1, \"Bobby\"]\n    error.arguments\n    \n    // Full error description\n    // > SQLite error 19: FOREIGN KEY constraint failed -\n    // > while executing `INSERT INTO pet (masterId, name) VALUES (?, ?)`\n    error.description\n}\n```\n\nIf you want to see statement arguments in the error description, [make statement arguments public](https://swiftpackageindex.com/groue/GRDB.swift/configuration/publicstatementarguments).\n\n**SQLite uses [results codes](https://www.sqlite.org/rescode.html) to distinguish between various errors**.\n\nYou can catch a DatabaseError and match on result codes:\n\n```swift\ndo {\n    try ...\n} catch let error as DatabaseError {\n    switch error {\n    case DatabaseError.SQLITE_CONSTRAINT_FOREIGNKEY:\n        // foreign key constraint error\n    case DatabaseError.SQLITE_CONSTRAINT:\n        // any other constraint error\n    default:\n        // any other database error\n    }\n}\n```\n\nYou can also directly match errors on result codes:\n\n```swift\ndo {\n    try ...\n} catch DatabaseError.SQLITE_CONSTRAINT_FOREIGNKEY {\n    // foreign key constraint error\n} catch DatabaseError.SQLITE_CONSTRAINT {\n    // any other constraint error\n} catch {\n    // any other database error\n}\n```\n\nEach DatabaseError has two codes: an `extendedResultCode` (see [extended result code](https://www.sqlite.org/rescode.html#extended_result_code_list)), and a less precise `resultCode` (see [primary result code](https://www.sqlite.org/rescode.html#primary_result_code_list)). Extended result codes are refinements of primary result codes, as `SQLITE_CONSTRAINT_FOREIGNKEY` is to `SQLITE_CONSTRAINT`, for example.\n\n> **Warning**: SQLite has progressively introduced extended result codes across its versions. The [SQLite release notes](http://www.sqlite.org/changes.html) are unfortunately not quite clear about that: write your handling of extended result codes with care.\n\n\n### RecordError\n\nüìñ [`RecordError`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recorderror)\n\n**RecordError** is thrown by the [PersistableRecord] protocol when the `update` method could not find any row to update:\n\n```swift\ndo {\n    try player.update(db)\n} catch let RecordError.recordNotFound(databaseTableName: table, key: key) {\n    print(\"Key \\(key) was not found in table \\(table).\")\n}\n```\n\n**RecordError** is also thrown by the [FetchableRecord] protocol when the `find` method does not find any record:\n\n```swift\ndo {\n    let player = try Player.find(db, id: 42)\n} catch let RecordError.recordNotFound(databaseTableName: table, key: key) {\n    print(\"Key \\(key) was not found in table \\(table).\")\n}\n```\n\n\n### RowDecodingError\n\nüìñ [`RowDecodingError`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/rowdecodingerror)\n\n**RowDecodingError** is thrown when the application can not decode a value from a database row. For example:\n\n```swift\nlet row = try Row.fetchOne(db, sql: \"SELECT NULL AS name\")!\n// RowDecodingError: could not decode String from database value NULL.\nlet name = try row.decode(String.self, forColumn: \"name\")\n```\n\n### Fatal Errors\n\n**Fatal errors notify that the program, or the database, has to be changed.**\n\nThey uncover programmer errors, false assumptions, and prevent misuses. Here are a few examples:\n\n- **The code asks for a non-optional value, when the database contains NULL:**\n    \n    ```swift\n    // fatal error: could not convert NULL to String.\n    let name: String = row[\"name\"]\n    ```\n    \n    Solution: fix the contents of the database, use [NOT NULL constraints](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/columndefinition/notnull(onconflict:)), or load an optional:\n    \n    ```swift\n    let name: String? = row[\"name\"]\n    ```\n\n- **Conversion from database value to Swift type fails:**\n    \n    ```swift\n    // fatal error: could not convert \"Mom‚Äôs birthday\" to Date.\n    let date: Date = row[\"date\"]\n    \n    // fatal error: could not convert \"\" to URL.\n    let url: URL = row[\"url\"]\n    ```\n    \n    Solution: fix the contents of the database, or use [DatabaseValue](#databasevalue) to handle all possible cases:\n    \n    ```swift\n    let dbValue: DatabaseValue = row[\"date\"]\n    if dbValue.isNull {\n        // Handle NULL\n    } else if let date = Date.fromDatabaseValue(dbValue) {\n        // Handle valid date\n    } else {\n        // Handle invalid date\n    }\n    ```\n\n- **The database can't guarantee that the code does what it says:**\n\n    ```swift\n    // fatal error: table player has no unique index on column email\n    try Player.deleteOne(db, key: [\"email\": \"arthur@example.com\"])\n    ```\n    \n    Solution: add a unique index to the player.email column, or use the `deleteAll` method to make it clear that you may delete more than one row:\n    \n    ```swift\n    try Player.filter { $0.email == \"arthur@example.com\" }.deleteAll(db)\n    ```\n\n- **Database connections are not reentrant:**\n    \n    ```swift\n    // fatal error: Database methods are not reentrant.\n    dbQueue.write { db in\n        dbQueue.write { db in\n            ...\n        }\n    }\n    ```\n    \n    Solution: avoid reentrancy, and instead pass a database connection along.\n\n\n### How to Deal with Untrusted Inputs\n\nLet's consider the code below:\n\n```swift\nlet sql = \"SELECT ...\"\n\n// Some untrusted arguments for the query\nlet arguments: [String: Any] = ...\nlet rows = try Row.fetchCursor(db, sql: sql, arguments: StatementArguments(arguments))\n\nwhile let row = try rows.next() {\n    // Some untrusted database value:\n    let date: Date? = row[0]\n}\n```\n\nIt has two opportunities to throw fatal errors:\n\n- **Untrusted arguments**: The dictionary may contain values that do not conform to the [DatabaseValueConvertible protocol](#values), or may miss keys required by the statement.\n- **Untrusted database content**: The row may contain a non-null value that can't be turned into a date.\n\nIn such a situation, you can still avoid fatal errors by exposing and handling each failure point, one level down in the GRDB API:\n\n```swift\n// Untrusted arguments\nif let arguments = StatementArguments(arguments) {\n    let statement = try db.makeStatement(sql: sql)\n    try statement.setArguments(arguments)\n    \n    var cursor = try Row.fetchCursor(statement)\n    while let row = try iterator.next() {\n        // Untrusted database content\n        let dbValue: DatabaseValue = row[0]\n        if dbValue.isNull {\n            // Handle NULL\n        if let date = Date.fromDatabaseValue(dbValue) {\n            // Handle valid date\n        } else {\n            // Handle invalid date\n        }\n    }\n}\n```\n\nSee [`Statement`] and [DatabaseValue](#databasevalue) for more information.\n\n\n### Error Log\n\n**SQLite can be configured to invoke a callback function containing an error code and a terse error message whenever anomalies occur.**\n\nThis global error callback must be configured early in the lifetime of your application:\n\n```swift\nDatabase.logError = { (resultCode, message) in\n    NSLog(\"%@\", \"SQLite error \\(resultCode): \\(message)\")\n}\n```\n\n> **Warning**: Database.logError must be set before any database connection is opened. This includes the connections that your application opens with GRDB, but also connections opened by other tools, such as third-party libraries. Setting it after a connection has been opened is an SQLite misuse, and has no effect.\n\nSee [The Error And Warning Log](https://sqlite.org/errlog.html) for more information.\n\n\n## Unicode\n\nSQLite lets you store unicode strings in the database.\n\nHowever, SQLite does not provide any unicode-aware string transformations or comparisons.\n\n\n### Unicode functions\n\nThe `UPPER` and `LOWER` built-in SQLite functions are not unicode-aware:\n\n```swift\n// \"J√©R√¥ME\"\ntry String.fetchOne(db, sql: \"SELECT UPPER('J√©r√¥me')\")\n```\n\nGRDB extends SQLite with [SQL functions](#custom-sql-functions-and-aggregates) that call the Swift built-in string functions `capitalized`, `lowercased`, `uppercased`, `localizedCapitalized`, `localizedLowercased` and `localizedUppercased`:\n\n```swift\n// \"J√âR√îME\"\nlet uppercased = DatabaseFunction.uppercase\ntry String.fetchOne(db, sql: \"SELECT \\(uppercased.name)('J√©r√¥me')\")\n```\n\nThose unicode-aware string functions are also readily available in the [query interface](#sql-functions):\n\n```swift\nPlayer.select { $0.name.uppercased }\n```\n\n\n### String Comparison\n\nSQLite compares strings in many occasions: when you sort rows according to a string column, or when you use a comparison operator such as `=` and `<=`.\n\nThe comparison result comes from a *collating function*, or *collation*. SQLite comes with three built-in collations that do not support Unicode: [binary, nocase, and rtrim](https://www.sqlite.org/datatype3.html#collation).\n\nGRDB comes with five extra collations that leverage unicode-aware comparisons based on the standard Swift String comparison functions and operators:\n\n- `unicodeCompare` (uses the built-in `<=` and `==` Swift operators)\n- `caseInsensitiveCompare`\n- `localizedCaseInsensitiveCompare`\n- `localizedCompare`\n- `localizedStandardCompare`\n\nA collation can be applied to a table column. All comparisons involving this column will then automatically trigger the comparison function:\n    \n```swift\ntry db.create(table: \"player\") { t in\n    // Guarantees case-insensitive email unicity\n    t.column(\"email\", .text).unique().collate(.nocase)\n    \n    // Sort names in a localized case insensitive way\n    t.column(\"name\", .text).collate(.localizedCaseInsensitiveCompare)\n}\n\n// Players are sorted in a localized case insensitive way:\nlet players = try Player.order(\\.name).fetchAll(db)\n```\n\n> **Warning**: SQLite *requires* host applications to provide the definition of any collation other than binary, nocase and rtrim. When a database file has to be shared or migrated to another SQLite library of platform (such as the Android version of your application), make sure you provide a compatible collation.\n\nIf you can't or don't want to define the comparison behavior of a column (see warning above), you can still use an explicit collation in SQL requests and in the [query interface](#the-query-interface):\n\n```swift\nlet collation = DatabaseCollation.localizedCaseInsensitiveCompare\nlet players = try Player.fetchAll(db,\n    sql: \"SELECT * FROM player ORDER BY name COLLATE \\(collation.name))\")\nlet players = try Player.order { $0.name.collating(collation) }.fetchAll(db)\n```\n\n\n**You can also define your own collations**:\n\n```swift\nlet collation = DatabaseCollation(\"customCollation\") { (lhs, rhs) -> NSComparisonResult in\n    // return the comparison of lhs and rhs strings.\n}\n\n// Make the collation available to a database connection\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.add(collation: collation)\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\n\n\n## Memory Management\n\nBoth SQLite and GRDB use non-essential memory that help them perform better.\n\nYou can reclaim this memory with the `releaseMemory` method:\n\n```swift\n// Release as much memory as possible.\ndbQueue.releaseMemory()\ndbPool.releaseMemory()\n```\n\nThis method blocks the current thread until all current database accesses are completed, and the memory collected.\n\n> **Warning**: If `DatabasePool.releaseMemory()` is called while a long read is performed concurrently, then no other read access will be possible until this long read has completed, and the memory has been released. If this does not suit your application needs, look for the asynchronous options below:\n\nYou can release memory in an asynchronous way as well:\n\n```swift\n// On a DatabaseQueue\ndbQueue.asyncWriteWithoutTransaction { db in\n    db.releaseMemory()\n}\n\n// On a DatabasePool\ndbPool.releaseMemoryEventually()\n```\n\n`DatabasePool.releaseMemoryEventually()` does not block the current thread, and does not prevent concurrent database accesses. In exchange for this convenience, you don't know when memory has been freed.\n\n\n### Memory Management on iOS\n\n**The iOS operating system likes applications that do not consume much memory.**\n\n[Database queues] and [pools](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool) automatically free non-essential memory when the application receives a memory warning, and when the application enters background.\n\nYou can opt out of this automatic memory management:\n\n```swift\nvar config = Configuration()\nconfig.automaticMemoryManagement = false\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config) // or DatabasePool\n```\n\nFAQ\n===\n\n**[FAQ: Opening Connections](#faq-opening-connections)**\n\n- [How do I create a database in my application?](#how-do-i-create-a-database-in-my-application)\n- [How do I open a database stored as a resource of my application?](#how-do-i-open-a-database-stored-as-a-resource-of-my-application)\n- [How do I close a database connection?](#how-do-i-close-a-database-connection)\n\n**[FAQ: SQL](#faq-sql)**\n\n- [How do I print a request as SQL?](#how-do-i-print-a-request-as-sql)\n\n**[FAQ: General](#faq-general)**\n\n- [How do I monitor the duration of database statements execution?](#how-do-i-monitor-the-duration-of-database-statements-execution)\n- [What Are Experimental Features?](#what-are-experimental-features)\n- [Does GRDB support library evolution and ABI stability?](#does-grdb-support-library-evolution-and-abi-stability)\n\n**[FAQ: Associations](#faq-associations)**\n\n- [How do I filter records and only keep those that are associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-associated-to-another-record)\n- [How do I filter records and only keep those that are NOT associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-not-associated-to-another-record)\n- [How do I select only one column of an associated record?](#how-do-i-select-only-one-column-of-an-associated-record)\n\n**[FAQ: ValueObservation](#faq-valueobservation)**\n\n- [Why is ValueObservation not publishing value changes?](#why-is-valueobservation-not-publishing-value-changes)\n\n**[FAQ: Errors](#faq-errors)**\n\n- [Generic parameter 'T' could not be inferred](#generic-parameter-t-could-not-be-inferred)\n- [Mutation of captured var in concurrently-executing code](#mutation-of-captured-var-in-concurrently-executing-code)\n- [SQLite error 1 \"no such column\"](#sqlite-error-1-no-such-column)\n- [SQLite error 10 \"disk I/O error\", SQLite error 23 \"not authorized\"](#sqlite-error-10-disk-io-error-sqlite-error-23-not-authorized)\n- [SQLite error 21 \"wrong number of statement arguments\" with LIKE queries](#sqlite-error-21-wrong-number-of-statement-arguments-with-like-queries)\n\n\n## FAQ: Opening Connections\n\n- :arrow_up: [FAQ]\n- [How do I create a database in my application?](#how-do-i-create-a-database-in-my-application)\n- [How do I open a database stored as a resource of my application?](#how-do-i-open-a-database-stored-as-a-resource-of-my-application)\n- [How do I close a database connection?](#how-do-i-close-a-database-connection)\n\n### How do I create a database in my application?\n\nFirst choose a proper location for the database file. Document-based applications will let the user pick a location. Apps that use the database as a global storage will prefer the Application Support directory.\n\nThe sample code below creates or opens a database file inside its dedicated directory (a [recommended practice](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseconnections)). On the first run, a new empty database file is created. On subsequent runs, the database file already exists, so it just opens a connection:\n\n```swift\n// HOW TO create an empty database, or open an existing database file\n\n// Create the \"Application Support/MyDatabase\" directory\nlet fileManager = FileManager.default\nlet appSupportURL = try fileManager.url(\n    for: .applicationSupportDirectory, in: .userDomainMask,\n    appropriateFor: nil, create: true) \nlet directoryURL = appSupportURL.appendingPathComponent(\"MyDatabase\", isDirectory: true)\ntry fileManager.createDirectory(at: directoryURL, withIntermediateDirectories: true)\n\n// Open or create the database\nlet databaseURL = directoryURL.appendingPathComponent(\"db.sqlite\")\nlet dbQueue = try DatabaseQueue(path: databaseURL.path)\n```\n\n### How do I open a database stored as a resource of my application?\n\nOpen a read-only connection to your resource:\n\n```swift\n// HOW TO open a read-only connection to a database resource\n\n// Get the path to the database resource.\nif let dbPath = Bundle.main.path(forResource: \"db\", ofType: \"sqlite\") {\n    // If the resource exists, open a read-only connection.\n    // Writes are disallowed because resources can not be modified. \n    var config = Configuration()\n    config.readonly = true\n    let dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n} else {\n    // The database resource can not be found.\n    // Fix your setup, or report the problem to the user. \n}\n```\n\n### How do I close a database connection?\n\nDatabase connections are automatically closed when `DatabaseQueue` or `DatabasePool` instances are deinitialized.\n\nIf the correct execution of your program depends on precise database closing, perform an explicit call to [`close()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasereader/close()). This method may fail and create zombie connections, so please check its detailed documentation.\n\n## FAQ: SQL\n\n- :arrow_up: [FAQ]\n- [How do I print a request as SQL?](#how-do-i-print-a-request-as-sql)\n\n### How do I print a request as SQL?\n\nWhen you want to debug a request that does not deliver the expected results, you may want to print the SQL that is actually executed.\n\nYou can compile the request into a prepared [`Statement`]:\n\n```swift\ntry dbQueue.read { db in\n    let request = Player.filter { $0.email == \"arthur@example.com\" }\n    let statement = try request.makePreparedRequest(db).statement\n    print(statement) // SELECT * FROM player WHERE email = ?\n    print(statement.arguments) // [\"arthur@example.com\"]\n}\n```\n\nAnother option is to setup a tracing function that prints out the executed SQL requests. For example, provide a tracing function when you connect to the database:\n\n```swift\n// Prints all SQL statements\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.trace { print($0) }\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n\ntry dbQueue.read { db in\n    // Prints \"SELECT * FROM player WHERE email = ?\"\n    let players = try Player.filter { $0.email == \"arthur@example.com\" }.fetchAll(db)\n}\n```\n\nIf you want to see statement arguments such as `'arthur@example.com'` in the logged statements, [make statement arguments public](https://swiftpackageindex.com/groue/GRDB.swift/configuration/publicstatementarguments).\n\n> **Note**: the generated SQL may change between GRDB releases, without notice: don't have your application rely on any specific SQL output.\n\n\n## FAQ: General\n\n- :arrow_up: [FAQ]\n- [How do I monitor the duration of database statements execution?](#how-do-i-monitor-the-duration-of-database-statements-execution)\n- [What Are Experimental Features?](#what-are-experimental-features)\n- [Does GRDB support library evolution and ABI stability?](#does-grdb-support-library-evolution-and-abi-stability)\n\n### How do I monitor the duration of database statements execution?\n\nUse the `trace(options:_:)` method, with the `.profile` option:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.trace(options: .profile) { event in\n        // Prints all SQL statements with their duration\n        print(event)\n        \n        // Access to detailed profiling information\n        if case let .profile(statement, duration) = event, duration > 0.5 {\n            print(\"Slow query: \\(statement.sql)\")\n        }\n    }\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n\ntry dbQueue.read { db in\n    let players = try Player.filter { $0.email == \"arthur@example.com\" }.fetchAll(db)\n    // Prints \"0.003s SELECT * FROM player WHERE email = ?\"\n}\n```\n\nIf you want to see statement arguments such as `'arthur@example.com'` in the logged statements, [make statement arguments public](https://swiftpackageindex.com/groue/GRDB.swift/configuration/publicstatementarguments).\n\n### What Are Experimental Features?\n\nSince GRDB 1.0, all backwards compatibility guarantees of [semantic versioning](http://semver.org) apply: no breaking change will happen until the next major version of the library.\n\nThere is an exception, though: *experimental features*, marked with the \"**:fire: EXPERIMENTAL**\" badge. Those are advanced features that are too young, or lack user feedback. They are not stabilized yet.\n\nThose experimental features are not protected by semantic versioning, and may break between two minor releases of the library. To help them becoming stable, [your feedback](https://github.com/groue/GRDB.swift/issues) is greatly appreciated.\n\n### Does GRDB support library evolution and ABI stability?\n\nNo, GRDB does not support library evolution and ABI stability. The only promise is API stability according to [semantic versioning](http://semver.org), with an exception for [experimental features](#what-are-experimental-features).\n\nYet, GRDB can be built with the \"Build Libraries for Distribution\" Xcode option (`BUILD_LIBRARY_FOR_DISTRIBUTION`), so that you can build binary frameworks at your convenience.\n\n## FAQ: Associations\n\n- :arrow_up: [FAQ]\n- [How do I filter records and only keep those that are associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-associated-to-another-record)\n- [How do I filter records and only keep those that are NOT associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-not-associated-to-another-record)\n- [How do I select only one column of an associated record?](#how-do-i-select-only-one-column-of-an-associated-record)\n\n### How do I filter records and only keep those that are associated to another record?\n\nLet's say you have two record types, `Book` and `Author`, and you want to only fetch books that have an author, and discard anonymous books.\n\nWe start by defining the association between books and authors:\n\n```swift\nstruct Book: TableRecord {\n    ...\n    static let author = belongsTo(Author.self)\n}\n\nstruct Author: TableRecord {\n    ...\n}\n```\n\nAnd then we can write our request and only fetch books that have an author, discarding anonymous ones:\n\n```swift\nlet books: [Book] = try dbQueue.read { db in\n    // SELECT book.* FROM book \n    // JOIN author ON author.id = book.authorID\n    let request = Book.joining(required: Book.author)\n    return try request.fetchAll(db)\n}\n```\n\nNote how this request does not use the `filter` method. Indeed, we don't have any condition to express on any column. Instead, we just need to \"require that a book can be joined to its author\".\n\nSee [How do I filter records and only keep those that are NOT associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-not-associated-to-another-record) below for the opposite question.\n\n\n### How do I filter records and only keep those that are NOT associated to another record?\n\nLet's say you have two record types, `Book` and `Author`, and you want to only fetch anonymous books that do not have any author.\n\nWe start by defining the association between books and authors:\n\n```swift\nstruct Book: TableRecord {\n    ...\n    static let author = belongsTo(Author.self)\n}\n\nstruct Author: TableRecord {\n    ...\n}\n```\n\nAnd then we can write our request and only fetch anonymous books that don't have any author:\n\n```swift\nlet books: [Book] = try dbQueue.read { db in\n    // SELECT book.* FROM book\n    // LEFT JOIN author ON author.id = book.authorID\n    // WHERE author.id IS NULL\n    let authorAlias = TableAlias<Author>()\n    let request = Book\n        .joining(optional: Book.author.aliased(authorAlias))\n        .filter(!authorAlias.exists)\n    return try request.fetchAll(db)\n}\n```\n\nThis request uses a TableAlias in order to be able to filter on the eventual associated author. We make sure that the `Author.primaryKey` is nil, which is another way to say it does not exist: the book has no author.\n\nSee [How do I filter records and only keep those that are associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-associated-to-another-record) above for the opposite question.\n\n\n### How do I select only one column of an associated record?\n\nLet's say you have two record types, `Book` and `Author`, and you want to fetch all books with their author name, but not the full associated author records.\n\nWe start by defining the association between books and authors:\n\n```swift\nstruct Book: Decodable, TableRecord {\n    ...\n    static let author = belongsTo(Author.self)\n}\n\nstruct Author: Decodable, TableRecord {\n    ...\n    enum Columns {\n        static let name = Column(CodingKeys.name)\n    }\n}\n```\n\nAnd then we can write our request and the ad-hoc record that decodes it:\n\n```swift\nstruct BookInfo: Decodable, FetchableRecord {\n    var book: Book\n    var authorName: String? // nil when the book is anonymous\n    \n    static func all() -> QueryInterfaceRequest<BookInfo> {\n        // SELECT book.*, author.name AS authorName\n        // FROM book\n        // LEFT JOIN author ON author.id = book.authorID\n        return Book\n            .annotated(withOptional: Book.author.select { \n                $0.name.forKey(CodingKeys.authorName)\n            })\n            .asRequest(of: BookInfo.self)\n    }\n}\n\nlet bookInfos: [BookInfo] = try dbQueue.read { db in\n    BookInfo.all().fetchAll(db)\n}\n```\n\nBy defining the request as a static method of BookInfo, you have access to the private `CodingKeys.authorName`, and a compiler-checked SQL column name.\n\nBy using the `annotated(withOptional:)` method, you append the author name to the top-level selection that can be decoded by the ad-hoc record.\n\nBy using `asRequest(of:)`, you enhance the type-safety of your request.\n\n\n## FAQ: ValueObservation\n\n- :arrow_up: [FAQ]\n- [Why is ValueObservation not publishing value changes?](#why-is-valueobservation-not-publishing-value-changes)\n\n### Why is ValueObservation not publishing value changes?\n\nSometimes it looks that a [ValueObservation] does not notify the changes you expect.\n\nThere may be four possible reasons for this:\n\n1. The expected changes were not committed into the database.\n2. The expected changes were committed into the database, but were quickly overwritten.\n3. The observation was stopped.\n4. The observation does not track the expected database region.\n\nTo answer the first two questions, look at SQL statements executed by the database. This is done when you open the database connection:\n\n```swift\n// Prints all SQL statements\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.trace { print(\"SQL: \\($0)\") }\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nIf, after that, you are convinced that the expected changes were committed into the database, and not overwritten soon after, trace observation events:\n\n```swift\nlet observation = ValueObservation\n    .tracking { db in ... }\n    .print() // <- trace observation events\nlet cancellable = observation.start(...)\n```\n\nLook at the observation logs which start with `cancel` or `failure`: maybe the observation was cancelled by your app, or did fail with an error.\n\nLook at the observation logs which start with `value`: make sure, again, that the expected value was not actually notified, then overwritten.\n\nFinally, look at the observation logs which start with `tracked region`. Does the printed database region cover the expected changes?\n\nFor example:\n\n- `empty`: The empty region, which tracks nothing and never triggers the observation.\n- `player(*)`: The full `player` table\n- `player(id,name)`: The `id` and `name` columns of the `player` table\n- `player(id,name)[1]`: The `id` and `name` columns of the row with id 1 in the `player` table\n- `player(*),team(*)`: Both the full `player` and `team` tables\n\nIf you happen to use the `ValueObservation.trackingConstantRegion(_:)` method and see a mismatch between the tracked region and your expectation, then change the definition of your observation by using `tracking(_:)`. You should witness that the logs which start with `tracked region` now evolve in order to include the expected changes, and that you get the expected notifications.\n\nIf after all those steps (thanks you!), your observation is still failing you, please [open an issue](https://github.com/groue/GRDB.swift/issues/new) and provide a [minimal reproducible example](https://stackoverflow.com/help/minimal-reproducible-example)!\n\n\n## FAQ: Errors\n\n- :arrow_up: [FAQ]\n- [Generic parameter 'T' could not be inferred](#generic-parameter-t-could-not-be-inferred)\n- [Mutation of captured var in concurrently-executing code](#mutation-of-captured-var-in-concurrently-executing-code)\n- [SQLite error 1 \"no such column\"](#sqlite-error-1-no-such-column)\n- [SQLite error 10 \"disk I/O error\", SQLite error 23 \"not authorized\"](#sqlite-error-10-disk-io-error-sqlite-error-23-not-authorized)\n- [SQLite error 21 \"wrong number of statement arguments\" with LIKE queries](#sqlite-error-21-wrong-number-of-statement-arguments-with-like-queries)\n\n### Generic parameter 'T' could not be inferred\n    \nYou may get this error when using the `read` and `write` methods of database queues and pools:\n\n```swift\n// Generic parameter 'T' could not be inferred\nlet string = try dbQueue.read { db in\n    let result = try String.fetchOne(db, ...)\n    return result\n}\n```\n\nThis is a limitation of the Swift compiler.\n\nThe general workaround is to explicitly declare the type of the closure result:\n\n```swift\n// General Workaround\nlet string = try dbQueue.read { db -> String? in\n    let result = try String.fetchOne(db, ...)\n    return result\n}\n```\n\nYou can also, when possible, write a single-line closure:\n\n```swift\n// Single-line closure workaround:\nlet string = try dbQueue.read { db in\n    try String.fetchOne(db, ...)\n}\n```\n\n\n### Mutation of captured var in concurrently-executing code\n\nThe `insert` and `save` [persistence methods](#persistablerecord-protocol) can trigger a compiler error in async contexts:\n\n```swift\nvar player = Player(id: nil, name: \"Arthur\")\ntry await dbWriter.write { db in\n    // Error: Mutation of captured var 'player' in concurrently-executing code\n    try player.insert(db)\n}\nprint(player.id) // A non-nil id\n```\n\nWhen this happens, prefer the `inserted` and `saved` methods instead:\n\n```swift\n// OK\nvar player = Player(id: nil, name: \"Arthur\")\nplayer = try await dbWriter.write { [player] db in\n    return try player.inserted(db)\n}\nprint(player.id) // A non-nil id\n```\n\n\n### SQLite error 1 \"no such column\"\n\nThis error message is self-explanatory: do check for misspelled or non-existing column names.\n\nHowever, sometimes this error only happens when an app runs on a recent operating system (iOS 14+, Big Sur+, etc.) The error does not happen with previous ones.\n\nWhen this is the case, there are two possible explanations:\n\n1. Maybe a column name is *really* misspelled or missing from the database schema.\n    \n    To find it, check the SQL statement that comes with the [DatabaseError](#databaseerror).\n\n2. Maybe the application is using the character `\"` instead of the single quote `'` as the delimiter for string literals in raw SQL queries. Recent versions of SQLite have learned to tell about this deviation from the SQL standard, and this is why you are seeing this error. \n    \n    For example: this is not standard SQL: `UPDATE player SET name = \"Arthur\"`.\n    \n    The standard version is: `UPDATE player SET name = 'Arthur'`.\n    \n    It just happens that old versions of SQLite used to accept the former, non-standard version. Newer versions are able to reject it with an error.\n    \n    The fix is to change the SQL statements run by the application: replace `\"` with `'` in your string literals.\n    \n    It may also be time to learn about statement arguments and [SQL injection](#avoiding-sql-injection):\n    \n    ```swift\n    let name: String = ...\n    \n    // NOT STANDARD (double quote)\n    try db.execute(sql: \"\"\"\n        UPDATE player SET name = \"\\(name)\"\n        \"\"\")\n    \n    // STANDARD, BUT STILL NOT RECOMMENDED (single quote)\n    try db.execute(sql: \"UPDATE player SET name = '\\(name)'\")\n    \n    // STANDARD, AND RECOMMENDED (statement arguments)\n    try db.execute(sql: \"UPDATE player SET name = ?\", arguments: [name])\n    \n    // STANDARD, AND RECOMMENDED (SQL interpolation)\n    try db.execute(literal: \"UPDATE player SET name = \\(name)\")\n    ```\n    \nFor more information, see [Double-quoted String Literals Are Accepted](https://sqlite.org/quirks.html#double_quoted_string_literals_are_accepted), and [Configuration.acceptsDoubleQuotedStringLiterals](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/configuration/acceptsdoublequotedstringliterals).\n    \n\n\n### SQLite error 10 \"disk I/O error\", SQLite error 23 \"not authorized\"\n\nThose errors may be the sign that SQLite can't access the database due to [data protection](https://developer.apple.com/documentation/uikit/protecting_the_user_s_privacy/encrypting_your_app_s_files).\n\nWhen your application should be able to run in the background on a locked device, it has to catch this error, and, for example, wait for [UIApplicationDelegate.applicationProtectedDataDidBecomeAvailable(_:)](https://developer.apple.com/reference/uikit/uiapplicationdelegate/1623044-applicationprotecteddatadidbecom) or [UIApplicationProtectedDataDidBecomeAvailable](https://developer.apple.com/reference/uikit/uiapplicationprotecteddatadidbecomeavailable) notification and retry the failed database operation.\n\n```swift\ndo {\n    try ...\n} catch DatabaseError.SQLITE_IOERR, DatabaseError.SQLITE_AUTH {\n    // Handle possible data protection error\n}\n```\n\nThis error can also be prevented altogether by using a more relaxed [file protection](https://developer.apple.com/reference/foundation/filemanager/1653059-file_protection_values).\n\n\n### SQLite error 21 \"wrong number of statement arguments\" with LIKE queries\n\nYou may get the error \"wrong number of statement arguments\" when executing a LIKE query similar to:\n\n```swift\nlet name = textField.text\nlet players = try dbQueue.read { db in\n    try Player.fetchAll(db, sql: \"SELECT * FROM player WHERE name LIKE '%?%'\", arguments: [name])\n}\n```\n\nThe problem lies in the `'%?%'` pattern.\n\nSQLite only interprets `?` as a parameter when it is a placeholder for a whole value (int, double, string, blob, null). In this incorrect query, `?` is just a character in the `'%?%'` string: it is not a query parameter, and is not processed in any way. See [https://www.sqlite.org/lang_expr.html#varparam](https://www.sqlite.org/lang_expr.html#varparam) for more information about SQLite parameters.\n\nTo fix the error, you can feed the request with the pattern itself, instead of the name:\n\n```swift\nlet name = textField.text\nlet players: [Player] = try dbQueue.read { db in\n    let pattern = \"%\\(name)%\"\n    return try Player.fetchAll(db, sql: \"SELECT * FROM player WHERE name LIKE ?\", arguments: [pattern])\n}\n```\n\n\nSample Code\n===========\n\n- The [Documentation](#documentation) is full of GRDB snippets.\n- [Demo Applications]\n- Open `GRDB.xcworkspace`: it contains GRDB-enabled playgrounds to play with.\n- [groue/SortedDifference](https://github.com/groue/SortedDifference): How to synchronize a database table with a JSON payload\n\n\n---\n\n**Thanks**\n\n- [Pierlis](http://pierlis.com), where we write great software.\n- [@alextrob](https://github.com/alextrob), [@alexwlchan](https://github.com/alexwlchan), [@bellebethcooper](https://github.com/bellebethcooper), [@bfad](https://github.com/bfad), [@cfilipov](https://github.com/cfilipov), [@charlesmchen-signal](https://github.com/charlesmchen-signal), [@Chiliec](https://github.com/Chiliec), [@chrisballinger](https://github.com/chrisballinger), [@darrenclark](https://github.com/darrenclark), [@davidkraus](https://github.com/davidkraus), [@eburns-vmware](https://github.com/eburns-vmware), [@felixscheinost](https://github.com/felixscheinost), [@fpillet](https://github.com/fpillet), [@gcox](https://github.com/gcox), [@GetToSet](https://github.com/GetToSet), [@gjeck](https://github.com/gjeck), [@guidedways](https://github.com/guidedways), [@gusrota](https://github.com/gusrota), [@haikusw](https://github.com/haikusw), [@hartbit](https://github.com/hartbit), [@holsety](https://github.com/holsety), [@jroselightricks](https://github.com/jroselightricks), [@kdubb](https://github.com/kdubb), [@kluufger](https://github.com/kluufger), [@KyleLeneau](https://github.com/KyleLeneau), [@layoutSubviews](https://github.com/layoutSubviews), [@mallman](https://github.com/mallman), [@MartinP7r](https://github.com/MartinP7r), [@Marus](https://github.com/Marus), [@mattgallagher](https://github.com/mattgallagher), [@MaxDesiatov](https://github.com/MaxDesiatov), [@michaelkirk-signal](https://github.com/michaelkirk-signal), [@mtancock](https://github.com/mtancock), [@pakko972](https://github.com/pakko972), [@peter-ss](https://github.com/peter-ss), [@pierlo](https://github.com/pierlo), [@pocketpixels](https://github.com/pocketpixels), [@pp5x](https://github.com/pp5x), [@professordeng](https://github.com/professordeng), [@robcas3](https://github.com/robcas3), [@runhum](https://github.com/runhum), [@sberrevoets](https://github.com/sberrevoets), [@schveiguy](https://github.com/schveiguy), [@SD10](https://github.com/SD10), [@sobri909](https://github.com/sobri909), [@sroddy](https://github.com/sroddy), [@steipete](https://github.com/steipete), [@swiftlyfalling](https://github.com/swiftlyfalling), [@Timac](https://github.com/Timac), [@tternes](https://github.com/tternes), [@valexa](https://github.com/valexa), [@wuyuehyang](https://github.com/wuyuehyang), [@ZevEisenberg](https://github.com/ZevEisenberg), and [@zmeyc](https://github.com/zmeyc) for their contributions, help, and feedback on GRDB.\n- [@aymerick](https://github.com/aymerick) and [@kali](https://github.com/kali) because SQL.\n- [ccgus/fmdb](https://github.com/ccgus/fmdb) for its excellency.\n\n---\n\n[URIs don't change: people change them.](https://www.w3.org/Provider/Style/URI)\n\n#### Adding support for missing SQL functions or operators\n\nThis chapter was renamed to [Embedding SQL in Query Interface Requests].\n\n#### Advanced DatabasePool\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### After Commit Hook\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/afternexttransaction(oncommit:onrollback:)).\n\n#### Asynchronous APIs\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### Changes Tracking\n\nThis chapter has been renamed [Record Comparison].\n\n#### Concurrency\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### Custom Value Types\n\nCustom Value Types conform to the [`DatabaseValueConvertible`] protocol.\n\n#### Customized Decoding of Database Rows\n\nThis chapter has been renamed [Beyond FetchableRecord].\n\n#### Customizing the Persistence Methods\n\nThis chapter was replaced with [Persistence Callbacks].\n\n#### Database Changes Observation\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseobservation).\n\n#### Database Configuration\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/configuration).\n\n#### Database Queues\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasequeue).\n\n#### Database Pools\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool).\n\n#### Database Snapshots\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### DatabaseWriter and DatabaseReader Protocols\n\nThis chapter was removed. See the references of [DatabaseReader](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasereader) and [DatabaseWriter](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasewriter).\n\n#### Date and UUID Coding Strategies\n\nThis chapter has been renamed [Data, Date, and UUID Coding Strategies].\n\n#### Dealing with External Connections\n\nThis chapter has been superseded by the [Sharing a Database] guide.\n\n#### Differences between Database Queues and Pools\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### Enabling FTS5 Support\n\nFTS5 is enabled by default since GRDB 6.7.0.\n\n#### FetchedRecordsController\n\nFetchedRecordsController has been removed in GRDB 5.\n\nThe [Database Observation] chapter describes the other ways to observe the database.\n\n#### Full-Text Search\n\nThis chapter has [moved](Documentation/FullTextSearch.md).\n\n#### Guarantees and Rules\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### Joined Queries Support\n\nThis chapter was replaced with the documentation of [splittingRowAdapters(columnCounts:)](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/splittingrowadapters(columncounts:)).\n\n#### List of Record Methods\n\nSee [Records and the Query Interface](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterface).\n\n#### Migrations\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/migrations).\n\n#### NSNumber and NSDecimalNumber\n\nThis chapter has [moved](#nsnumber-nsdecimalnumber-and-decimal).\n\n#### Persistable Protocol\n\nThis protocol has been renamed [PersistableRecord] in GRDB 3.0.\n\n#### PersistenceError\n\nThis error was renamed to [RecordError].\n\n#### Prepared Statements\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statement).\n\n#### Record Class\n\nThe [`Record`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/record) class is a legacy GRDB type. Since GRDB 7, it is not recommended to define record types by subclassing the `Record` class.\n\n#### Row Adapters\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/rowadapter).\n\n#### RowConvertible Protocol\n\nThis protocol has been renamed [FetchableRecord] in GRDB 3.0.\n\n#### TableMapping Protocol\n\nThis protocol has been renamed [TableRecord] in GRDB 3.0.\n\n#### Transactions and Savepoints\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/transactions).\n\n#### Transaction Hook\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/afternexttransaction(oncommit:onrollback:)).\n\n#### TransactionObserver Protocol\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/transactionobserver).\n\n#### Unsafe Concurrency APIs\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### ValueObservation\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/valueobservation).\n\n#### ValueObservation and DatabaseRegionObservation\n\nThis chapter has been superseded by [ValueObservation] and [DatabaseRegionObservation].\n\n[Associations]: Documentation/AssociationsBasics.md\n[Beyond FetchableRecord]: #beyond-fetchablerecord\n[Identifiable Records]: #identifiable-records\n[Codable Records]: #codable-records\n[Columns Selected by a Request]: #columns-selected-by-a-request\n[common table expression]: Documentation/CommonTableExpressions.md\n[Common Table Expressions]: Documentation/CommonTableExpressions.md\n[Conflict Resolution]: #conflict-resolution\n[Column Names Coding Strategies]: #column-names-coding-strategies\n[Data, Date, and UUID Coding Strategies]: #data-date-and-uuid-coding-strategies\n[Fetching from Requests]: #fetching-from-requests\n[Embedding SQL in Query Interface Requests]: #embedding-sql-in-query-interface-requests\n[Full-Text Search]: Documentation/FullTextSearch.md\n[Migrations]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/migrations\n[The userInfo Dictionary]: #the-userinfo-dictionary\n[JSON Columns]: #json-columns\n[FetchableRecord]: #fetchablerecord-protocol\n[EncodableRecord]: #persistablerecord-protocol\n[PersistableRecord]: #persistablerecord-protocol\n[Record Comparison]: #record-comparison\n[Record Customization Options]: #record-customization-options\n[Persistence Callbacks]: #persistence-callbacks\n[persistence callbacks]: #persistence-callbacks\n[Record Timestamps and Transaction Date]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recordtimestamps\n[TableRecord]: #tablerecord-protocol\n[ValueObservation]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/valueobservation\n[DatabaseRegionObservation]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseregionobservation\n[RxGRDB]: https://github.com/RxSwiftCommunity/RxGRDB\n[DatabaseRegion]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseregion\n[SQL Interpolation]: Documentation/SQLInterpolation.md\n[custom SQLite build]: Documentation/CustomSQLiteBuilds.md\n[Combine]: https://developer.apple.com/documentation/combine\n[Combine Support]: Documentation/Combine.md\n[Concurrency]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency\n[Demo Applications]: Documentation/DemoApps\n[Sharing a Database]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasesharing\n[FAQ]: #faq\n[Database Observation]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseobservation\n[SQLRequest]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/sqlrequest\n[SQL literal]: Documentation/SQLInterpolation.md#sql-literal\n[Identifiable]: https://developer.apple.com/documentation/swift/identifiable\n[Query Interface Organization]: Documentation/QueryInterfaceOrganization.md\n[Database Configuration]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/configuration\n[Persistence Methods]: #persistence-methods\n[persistence methods]: #persistence-methods\n[Persistence Methods and the `RETURNING` clause]: #persistence-methods-and-the-returning-clause\n[RecordError]: #recorderror\n[RowDecodingError]: #rowdecodingerror\n[Transactions and Savepoints]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/transactions\n[`DatabaseQueue`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasequeue\n[Database queues]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasequeue\n[`DatabasePool`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool\n[database pools]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool\n[`DatabaseValueConvertible`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalueconvertible\n[`StatementArguments`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statementarguments\n[Prepared Statements]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statement\n[prepared statements]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statement\n[`Statement`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statement\n[Database Connections]: #database-connections\n[Database connections]: #database-connections\n[database connection]: #database-connections\n",
      "stars_today": 5
    },
    {
      "id": 860035177,
      "name": "CopilotForXcode",
      "full_name": "github/CopilotForXcode",
      "description": "AI coding assistant for Xcode",
      "html_url": "https://github.com/github/CopilotForXcode",
      "stars": 5513,
      "forks": 1681,
      "language": "Swift",
      "topics": [
        "ai-assistant",
        "github-copilot",
        "intelligence",
        "ios",
        "macos",
        "objective-c",
        "swift",
        "swiftui",
        "xcode"
      ],
      "created_at": "2024-09-19T17:48:15Z",
      "updated_at": "2026-01-13T22:23:47Z",
      "pushed_at": "2026-01-07T04:07:17Z",
      "open_issues": 186,
      "owner": {
        "login": "github",
        "avatar_url": "https://avatars.githubusercontent.com/u/9919?v=4"
      },
      "readme": "# <img align=\"center\" height=\"70\" src=\"./Docs/Images/AppIcon.png\"/> GitHub Copilot for Xcode\n\n[GitHub Copilot](https://github.com/features/copilot) for Xcode is the leading AI coding assistant for Swift, Objective-C and iOS/macOS development. It delivers intelligent Completions, Chat, and Code Review‚Äîplus advanced features like Agent Mode, Next Edit Suggestions, MCP Registry, and Copilot Vision to make Xcode development faster and smarter.\n\n## Chat\n\nGitHub Copilot Chat provides suggestions to your specific coding tasks via chat.\n<img alt=\"Chat of GitHub Copilot for Xcode\" src=\"./Docs/Images/chat_agent.gif\" width=\"800\" />\n\n## Agent Mode\n\nGitHub Copilot Agent Mode provides AI-powered assistance that can understand and modify your codebase directly. With Agent Mode, you can:\n- Get intelligent code edits applied directly to your files\n- Run terminal commands and view their output without leaving the interface\n- Search through your codebase to find relevant files and code snippets\n- Create new files and directories as needed for your project\n- Get assistance with enhanced context awareness across multiple files and folders\n- Run Model Context Protocol (MCP) tools you configured to extend the capabilities\n\nAgent Mode integrates with Xcode's environment, creating a seamless development experience where Copilot can help implement features, fix bugs, and refactor code with comprehensive understanding of your project.\n\n## Code Completion\n\nYou can receive auto-complete type suggestions from GitHub Copilot either by starting to write the code you want to use, or by writing a natural language comment describing what you want the code to do.\n<img alt=\"Code Completion of GitHub Copilot for Xcode\" src=\"./Docs/Images/demo.gif\" width=\"800\" />\n\n## Requirements\n\n- macOS 12+\n- Xcode 8+\n- A GitHub account\n\n## Getting Started\n\n1. Install via [Homebrew](https://brew.sh/):\n\n   ```sh\n   brew install --cask github-copilot-for-xcode\n   ```\n\n   Or download the `dmg` from\n   [the latest release](https://github.com/github/CopilotForXcode/releases/latest/download/GitHubCopilotForXcode.dmg).\n   Drag `GitHub Copilot for Xcode` into the `Applications` folder:\n\n   <p align=\"center\">\n     <img alt=\"Screenshot of opened dmg\" src=\"./Docs/Images/dmg-open.png\" width=\"512\" />\n   </p>\n\n   Updates can be downloaded and installed by the app.\n\n1. Open the `GitHub Copilot for Xcode` application (from the `Applications` folder). Accept the security warning.\n   <p align=\"center\">\n     <img alt=\"Screenshot of MacOS download permission request\" src=\"./Docs/Images/macos-download-open-confirm.png\" width=\"350\" />\n   </p>\n\n\n1. A background item will be added to enable the GitHub Copilot for Xcode extension app to connect to the host app. This permission is usually automatically added when first launching the app.\n   <p align=\"center\">\n     <img alt=\"Screenshot of background item\" src=\"./Docs/Images/background-item.png\" width=\"370\" />\n   </p>\n\n1. Three permissions are required for GitHub Copilot for Xcode to function properly: `Background`, `Accessibility`, and `Xcode Source Editor Extension`. For more details on why these permissions are required see [TROUBLESHOOTING.md](./TROUBLESHOOTING.md).\n\n   The first time the application is run the `Accessibility` permission should be requested:\n\n   <p align=\"center\">\n     <img alt=\"Screenshot of accessibility permission request\" src=\"./Docs/Images/accessibility-permission-request.png\" width=\"529\" />\n   </p>\n\n   The `Xcode Source Editor Extension` permission needs to be enabled manually. Click\n   `Extension Permission` from the `GitHub Copilot for Xcode` application settings to open the\n   System Preferences to the `Extensions` panel. Select `Xcode Source Editor`\n   and enable `GitHub Copilot`:\n\n   <p align=\"center\">\n     <img alt=\"Screenshot of extension permission\" src=\"./Docs/Images/extension-permission.png\" width=\"582\" />\n   </p>\n\n1. After granting the extension permission, open Xcode. Verify that the\n   `Github Copilot` menu is available and enabled under the Xcode `Editor`\n   menu.\n    <br>\n    <p align=\"center\">\n      <img alt=\"Screenshot of Xcode Editor GitHub Copilot menu item\" src=\"./Docs/Images/xcode-menu.png\" width=\"648\" />\n    </p>\n\n    Keyboard shortcuts can be set for all menu items in the `Key Bindings`\n    section of Xcode preferences.\n\n1. To sign into GitHub Copilot, click the `Sign in` button in the settings application. This will open a browser window and copy a code to the clipboard. Paste the code into the GitHub login page and authorize the application.\n    <p align=\"center\">\n      <img alt=\"Screenshot of sign-in popup\" src=\"./Docs/Images/device-code.png\" width=\"372\" />\n    </p>\n\n1. To install updates, click `Check for Updates` from the menu item or in the\n   settings application.\n\n   After installing a new version, Xcode must be restarted to use the new\n   version correctly.\n\n   New versions can also be installed from `dmg` files downloaded from the\n   releases page. When installing a new version via `dmg`, the application must\n   be run manually the first time to accept the downloaded from the internet\n   warning.\n\n1. To avoid confusion, we recommend disabling `Predictive code completion` under\n   `Xcode` > `Preferences` > `Text Editing` > `Editing`.\n\n1. Press `tab` to accept the first line of a suggestion, hold `option` to view\n   the full suggestion, and press `option` + `tab` to accept the full suggestion.\n\n## How to use Chat\n\n   Open Copilot Chat in GitHub Copilot.\n  - Open via the Xcode menu `Xcode -> Editor -> GitHub Copilot -> Open Chat`.\n  <p align=\"center\">\n    <img alt=\"Screenshot of Xcode Editor GitHub Copilot menu item\" src=\"./Docs/Images/xcode-menu_dark.png\" width=\"648\" />\n  </p>\n\n  - Open via GitHub Copilot app menu `Open Chat`.\n\n  <p align=\"center\">\n    <img alt=\"Screenshot of GitHub Copilot menu item\" src=\"./Docs/Images/copilot-menu_dark.png\" width=\"244\" />\n  </p>\n\n## How to use Code Completion\n\n   Press `tab` to accept the first line of a suggestion, hold `option` to view\n   the full suggestion, and press `option` + `tab` to accept the full suggestion.\n\n## License\n\nThis project is licensed under the terms of the MIT open source license. Please\nrefer to [LICENSE.txt](./LICENSE.txt) for the full terms.\n\n## Privacy\n\nWe follow responsible practices in accordance with our\n[Privacy Statement](https://docs.github.com/en/site-policy/privacy-policies/github-privacy-statement).\n\nTo get the latest security fixes, please use the latest version of the GitHub\nCopilot for Xcode.\n\n## Support\n\nWe‚Äôd love to get your help in making GitHub Copilot better!  If you have\nfeedback or encounter any problems, please reach out on our [Feedback\nforum](https://github.com/github/CopilotForXcode/discussions).\n\n## Acknowledgements\n\nThank you to @intitni for creating the original project that this is based on.\n\nAttributions can be found under About when running the app or in\n[Credits.rtf](./Copilot%20for%20Xcode/Credits.rtf).\n",
      "stars_today": 5
    },
    {
      "id": 814708478,
      "name": "unitycatalog",
      "full_name": "unitycatalog/unitycatalog",
      "description": "Open, Multi-modal Catalog for Data & AI",
      "html_url": "https://github.com/unitycatalog/unitycatalog",
      "stars": 3262,
      "forks": 562,
      "language": "Java",
      "topics": [],
      "created_at": "2024-06-13T14:39:25Z",
      "updated_at": "2026-01-13T20:53:21Z",
      "pushed_at": "2026-01-13T20:53:17Z",
      "open_issues": 350,
      "owner": {
        "login": "unitycatalog",
        "avatar_url": "https://avatars.githubusercontent.com/u/171874451?v=4"
      },
      "readme": "<img src=\"./docs/assets/images/uc-logo.png\" width=\"600px\" />\n\n# Unity Catalog: Open, Multimodal Catalog for Data & AI\n\nUnity Catalog is the industry‚Äôs only universal catalog for data and AI.\n\n- **Multimodal interface supports any format, engine, and asset**\n  - Multi-format support: It is extensible and supports Delta Lake, Apache Iceberg and Apache Hudi via UniForm, Apache Parquet, JSON, CSV, and many others.\n  - Multi-engine support: With its open APIs, data cataloged in Unity can be read by many leading compute engines.\n  - Multimodal: It supports all your data and AI assets, including tables, files, functions, AI models.\n- **Open source API and implementation** - OpenAPI spec and OSS implementation (Apache 2.0 license). It is also compatible with Apache Hive's metastore API and Apache Iceberg's REST catalog API. Unity Catalog is currently a sandbox project with LF AI and Data Foundation (part of the Linux Foundation).\n- **Unified governance** for data and AI - Govern and secure tabular data, unstructured assets, and AI assets with a single interface.\n\nThe current roadmap is available at [Unity Catalog Roadmap](roadmap.md).\n\n![UC Hero Image](./docs/assets/images/uc.png)\n\n### Vibrant ecosystem\n\nThis is a community effort. Unity Catalog is supported by\n\n- [Amazon Web Services](https://aws.amazon.com/)\n- [Confluent](https://www.confluent.io/)\n- [Daft (Eventual)](https://github.com/Eventual-Inc/Daft)\n- [dbt Labs](https://www.getdbt.com/)\n- [DuckDB](https://duckdblabs.com/)\n- [Fivetran](https://www.fivetran.com/)\n- [Google Cloud](https://cloud.google.com/)\n- [Granica](https://granica.ai/)\n- [Immuta](https://www.immuta.com/)\n- [Informatica](https://www.informatica.com/)\n- [Kuzu](https://www.kuzudb.com/)\n- [LanceDB](https://lancedb.com/)\n- [LangChain](https://www.langchain.com/)\n- [LlamaIndex](https://www.llamaindex.ai/)\n- [Microsoft Azure](https://azure.microsoft.com)\n- [NVIDIA](https://www.nvidia.com/)\n- [Onehouse](https://www.onehouse.ai/)\n- [PuppyGraph](https://www.puppygraph.com/)\n- [Salesforce](https://www.salesforce.com/)\n- [StarRocks (CelerData)](https://celerdata.com/)\n- [Spice AI](https://github.com/spiceai/spiceai)\n- [Tecton](https://www.tecton.ai/)\n- [Unstructured](https://unstructured.io/)\n\nUnity Catalog is proud to be hosted by the LF AI & Data Foundation.\n\n<a href=\"https://lfaidata.foundation/projects\">\n  <img src=\"./docs/assets/images/lfaidata-project-badge-sandbox-color.png\" width=\"200px\" />\n</a>\n\n## Quickstart - Hello UC!\n\nLet's take Unity Catalog for spin. In this guide, we are going to do the following:\n\n- In one terminal, run the UC server.\n- In another terminal, we will explore the contents of the UC server using a CLI.\n  An example project is provided to demonstrate how to use the UC SDK for various assets\n  as well as provide a convenient way to explore the content of any UC server implementation.\n\n> If you prefer to run Unity Catalog in Docker use `docker compose up`. See the [Docker Compose docs](./docs/docker_compose.md) for more details.\n\n### Prerequisites\n\nYou have to ensure that your local environment has the following:\n\n- Clone this repository.\n- Ensure the `JAVA_HOME` environment variable your terminal is configured to point to JDK17.\n- Compile the project using `build/sbt package`\n\n### Run the UC Server\n\nIn a terminal, in the cloned repository root directory, start the UC server.\n\n```sh\nbin/start-uc-server\n```\n\nFor the remaining steps, continue in a different terminal.\n\n### Operate on Delta tables with the CLI\n\nLet's list the tables.\n\n```sh\nbin/uc table list --catalog unity --schema default\n```\n\nYou should see a few tables. Some details are truncated because of the nested nature of the data.\nTo see all the content, you can add `--output jsonPretty` to any command.\n\nNext, let's get the metadata of one of those tables.\n\n```sh\nbin/uc table get --full_name unity.default.numbers\n```\n\nYou can see that it is a Delta table. Now, specifically for Delta tables, this CLI can\nprint a snippet of the contents of a Delta table (powered by the [Delta Kernel Java](https://delta.io/blog/delta-kernel/) project).\nLet's try that.\n\n```sh\nbin/uc table read --full_name unity.default.numbers\n```\n\n### Operate on Delta tables with DuckDB\n\nFor operating on tables with DuckDB, you will have to [install it](https://duckdb.org/docs/installation/) (version 1.0).\nLet's start DuckDB and install a couple of extensions. To start DuckDB, run the command `duckdb` in the terminal.\nThen, in the DuckDB shell, run the following commands:\n\n```sql\ninstall uc_catalog from core_nightly;\nload uc_catalog;\ninstall delta;\nload delta;\n```\n\nIf you have installed these extensions before, you may have to run `update extensions` and restart DuckDB\nfor the following steps to work.\n\nNow that we have DuckDB all set up, let's try connecting to UC by specifying a secret.\n\n```sql\nCREATE SECRET (\n      TYPE UC,\n      TOKEN 'not-used',\n      ENDPOINT 'http://127.0.0.1:8080',\n      AWS_REGION 'us-east-2'\n );\n```\n\nYou should see it print a short table saying `Success` = `true`. Then we attach the `unity` catalog to DuckDB.\n\n```sql\nATTACH 'unity' AS unity (TYPE UC_CATALOG);\n```\n\nNow we are ready to query. Try the following:\n\n```sql\nSHOW ALL TABLES;\nSELECT * from unity.default.numbers;\n```\n\nYou should see the tables listed and the contents of the `numbers` table printed.\nTo quit DuckDB, press `Ctrl`+`D` (if your platform supports it), press `Ctrl`+`C`, or use the `.exit` command in the DuckDB shell.\n\n### Interact with the Unity Catalog UI\n\n![UC UI](./docs/assets/images/uc-ui.png)\n\nTo use the Unity Catalog UI, start a new terminal and ensure you have already started the UC server (e.g., `./bin/start-uc-server`)\n\n**Prerequisites**\n\n- Node: https://nodejs.org/en/download/package-manager\n- Yarn: https://classic.yarnpkg.com/lang/en/docs/install\n\n**How to start the UI through yarn**\n\n```\ncd /ui\nyarn install\nyarn start\n```\n\n## CLI tutorial\n\nYou can interact with a Unity Catalog server to create and manage catalogs, schemas and tables,\noperate on volumes and functions from the CLI, and much more.\nSee the [cli usage](docs/usage/cli.md) for more details.\n\n## APIs and Compatibility\n\n- Open API specification: See the [Unity Catalog Rest API](https://docs.unitycatalog.io/swagger-docs/).\n- Compatibility and stability: The APIs are currently evolving and should not be assumed to be stable.\n\n## Building Unity Catalog\n\nUnity Catalog is built using [sbt](https://www.scala-sbt.org/).\n\nTo build UC (incl. [Spark Integration](./connectors/spark) module), run the following command:\n\n```sh\nbuild/sbt clean package publishLocal\n```\n\nRefer to [sbt docs](https://www.scala-sbt.org/1.x/docs/) for more commands.\n\n## Deployment\n\n- To create a tarball that can be used to deploy the UC server or run the CLI, run the following:\n  ```sh\n  build/sbt createTarball\n  ```\n  This will create a tarball in the `target` directory. See the full [deployment guide](docs/deployment.md) for more details.\n\n## Compiling and testing\n\n- Install JDK 17 by whatever mechanism is appropriate for your system, and\n  set that version to be the default Java version (e.g. via the env variable `JAVA_HOME`)\n- To compile all the code without running tests, run the following:\n  ```sh\n  build/sbt clean compile\n  ```\n- To compile and execute tests, run the following:\n  ```sh\n  build/sbt -J-Xmx2G clean test\n  ```\n- To execute tests with coverage, run the following:\n  ```sh\n  build/sbt -J-Xmx2G jacoco\n  ```\n- To update the API specification, just update the `api/all.yaml` and then run the following:\n  ```sh\n  build/sbt generate\n  ```\n  This will regenerate the OpenAPI data models in the UC server and data models + APIs in the client SDK.\n- To format the code, run the following:\n  ```sh\n  build/sbt javafmtAll\n  ```\n\n## Setting up IDE\n\nIntelliJ is the recommended IDE to use when developing Unity Catalog. The below steps outline how to add the project to IntelliJ:\n\n1. Clone Unity Catalog into a local folder, such as `~/unitycatalog`.\n2. Select `File` > `New Project` > `Project from Existing Sources...` and select `~/unitycatalog`.\n3. Under `Import project from external model` select `sbt`. Click `Next`.\n4. Click `Finish`.\n\nJava code adheres to the [Google style](https://google.github.io/styleguide/javaguide.html), which is verified via `build/sbt javafmtCheckAll` during builds.\nIn order to automatically fix Java code style issues, please use `build/sbt javafmtAll`.\n\n### Configuring Code Formatter for Eclipse/IntelliJ\n\nFollow the instructions for [Eclipse](https://github.com/google/google-java-format#eclipse) or\n[IntelliJ](https://github.com/google/google-java-format#intellij-android-studio-and-other-jetbrains-ides) to install the **google-java-format** plugin (note the required manual actions for IntelliJ).\n\n### Using more recent JDKs\n\nThe build script [checks for a lower bound on the JDK](./build.sbt#L14) but the [current SBT version](./project/build.properties)\nimposes an upper bound. Please check the [JDK compatibility](https://docs.scala-lang.org/overviews/jdk-compatibility/overview.html) documentation for more information\n\n### Serving the documentation with mkdocs\n\nFor an overview of how to contribute to the documentation, please see our introduction [here](./docs/README.md).\nFor the official documentation, please take a look at [https://docs.unitycatalog.io/](https://docs.unitycatalog.io/).\n",
      "stars_today": 5
    },
    {
      "id": 815904141,
      "name": "ReVancedXposed",
      "full_name": "chsbuffer/ReVancedXposed",
      "description": "ReVanced LSPosed module. YouTube & YT Music Remove ads, Background playback",
      "html_url": "https://github.com/chsbuffer/ReVancedXposed",
      "stars": 1959,
      "forks": 84,
      "language": "Kotlin",
      "topics": [
        "android",
        "revanced",
        "xposed-module",
        "youtube",
        "youtube-music"
      ],
      "created_at": "2024-06-16T13:36:30Z",
      "updated_at": "2026-01-13T23:40:33Z",
      "pushed_at": "2026-01-11T12:06:02Z",
      "open_issues": 15,
      "owner": {
        "login": "chsbuffer",
        "avatar_url": "https://avatars.githubusercontent.com/u/33744752?v=4"
      },
      "readme": "<div align=\"center\">\n  <h1>ReVanced Xposed</h1>\n  <a href=\"https://discord.gg/QWUrAA2mKq\"><img alt=\"Discord Server\" src=\"https://img.shields.io/badge/Discord%20Server-5865F2.svg?logo=discord&logoColor=white\"></a>\n  <a href=\"https://t.me/revancedxposed\"><img alt=\"Telegram Channel\" src=\"https://img.shields.io/badge/Telegram_Channel-blue.svg?logo=telegram&logoColor=white\"></a>\n  <a href=\"https://github.com/chsbuffer/ReVancedXposed/releases/latest\"><img alt=\"GitHub Downloads\" src=\"https://img.shields.io/endpoint?url=https%3A%2F%2Fshields.chsbuffer.workers.dev%2F%3Frepos%3Dchsbuffer%2FReVancedXposed%2CXposed-Modules-Repo%2Fio.github.chsbuffer.revancedxposed&cacheSeconds=3600\"></a>\n  <a href=\"https://github.com/chsbuffer/ReVancedXposed\"><img alt=\"GitHub Stars\" src=\"https://img.shields.io/github/stars/chsbuffer/ReVancedXposed\"></a>  \n  <br>\n</div>\n\n**ReVanced LSPosed module by ChsBuffer.**  \n>[!IMPORTANT]  \n> - This is **NOT an official ReVanced project**, do not ask the ReVanced developers for help.  \n> - **Root access** is strictly **required** to use this module!\n> - **Spotify is no longer supported!** Get the new module [here](https://github.com/chsbuffer/ReVancedXposed_Spotify)\n> - **Having issues?** Check the **[FAQ](https://github.com/chsbuffer/ReVancedXposed/wiki/Frequently-Asked-Questions)** before reporting.\n\n## Downloads\n- **Release build**: [Download](https://github.com/chsbuffer/ReVancedXposed/releases/latest)\n- **Nightly build**: [Download](https://nightly.link/chsbuffer/ReVancedXposed/workflows/android/main)\n\n<sub>If you've joined the YouTube beta program, please try the nightly build before reporting an issue.</sub>\n\n## Patches\n\n### Youtube\n- Remove ads\n- SponsorBlock\n- Remove background playback restrictions\n- Remove share links tracking query parameter\n- Hide and change navigation buttons\n- Swipe controls\n- Remember video quality changes\n- Show video quality button\n- Show advanced video quality menu\n- Copy video url video player button\n- Open external downloader app\n- Custom playback speed\n- Remember playback speed\n- Playback speed dialog button\n- Hide layout components\n- Hide video action buttons\n- Disable resuming Shorts on startup\n- Disable video codecs\n- Disable auto captions\n\n### Spotify (Moved to Dedicated Repository)\n\n[ReVancedXposed_Spotify](https://github.com/chsbuffer/ReVancedXposed_Spotify)\n\n### Google Photos\n- Spoof Pixel XL\n\n### Youtube Music\n- Remove music video ads\n- Remove background playback restrictions\n- Hide upgrade button\n- Hide 'Get Music Premium' label\n- Enable exclusive audio playback\n\n### Instagram\n- Hide ads\n\n### Threads\n- Hide ads\n\n### Reddit\n- Hide ads\n- Sanitize sharing links\n\n### Strava\n- Unlock subscription features\n- Disable subscription suggestions\n\n### Photomath\n- Unlock plus\n\n## Supports\n[![Discord Server](https://img.shields.io/badge/Join-Discord-5865F2.svg?logo=discord)](https://discord.gg/QWUrAA2mKq)  \n[![FAQ](https://img.shields.io/badge/Read-FAQ-orange.svg?logo=github)](https://github.com/chsbuffer/ReVancedXposed/wiki/Frequently-Asked-Questions)  \nor [Create an issue](https://github.com/chsbuffer/ReVancedXposed/issues/new/choose)\n\n## ‚≠ê Credits\n\n[DexKit](https://luckypray.org/DexKit/en/): a high-performance dex runtime parsing library.  \n[ReVanced](https://revanced.app): Continuing the legacy of Vanced at [revanced.app](https://revanced.app)  \n",
      "stars_today": 5
    },
    {
      "id": 46398090,
      "name": "datahub",
      "full_name": "datahub-project/datahub",
      "description": "The Metadata Platform for your Data and AI Stack",
      "html_url": "https://github.com/datahub-project/datahub",
      "stars": 11425,
      "forks": 3332,
      "language": "Java",
      "topics": [
        "data-catalog",
        "data-discovery",
        "data-governance",
        "datahub",
        "hacktoberfest",
        "metadata"
      ],
      "created_at": "2015-11-18T05:47:40Z",
      "updated_at": "2026-01-13T22:26:21Z",
      "pushed_at": "2026-01-13T23:46:44Z",
      "open_issues": 681,
      "owner": {
        "login": "datahub-project",
        "avatar_url": "https://avatars.githubusercontent.com/u/78121374?v=4"
      },
      "readme": "<!--HOSTED_DOCS_ONLY\nimport useBaseUrl from '@docusaurus/useBaseUrl';\n\nexport const Logo = (props) => {\n  return (\n    <div style={{ display: \"flex\", justifyContent: \"center\", padding: \"20px\", height: \"190px\" }}>\n      <img\n        alt=\"DataHub Logo\"\n        src=\"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/datahub-logo-color-mark.svg\"\n        {...props}\n      />\n    </div>\n  );\n};\n\n<Logo />\n\n<!--\nHOSTED_DOCS_ONLY-->\n<p align=\"center\">\n<a href=\"https://datahub.com\">\n<img alt=\"DataHub\" src=\"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/datahub-logo-color-mark.svg\" height=\"150\" />\n</a>\n</p>\n<!-- -->\n\n# DataHub: The Data Discovery Platform for the Modern Data Stack\n\n### Built with ‚ù§Ô∏è by <img src=\"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/datahub-logo-color-mark.svg\" width=\"20\"/> [DataHub](https://datahub.com) and <img src=\"https://docs.datahub.com/img/LI-In-Bug.png\" width=\"20\"/> [LinkedIn](https://engineering.linkedin.com)\n\n<div>\n  <a target=\"_blank\" href=\"https://github.com/datahub-project/datahub/blob/master/LICENSE\">\n    <img alt=\"Apache 2.0 License\" src=\"https://img.shields.io/badge/License-Apache_2.0-blue.svg?label=license&labelColor=133554&color=1890ff\" /></a>\n  <a target=\"_blank\" href=\"https://pypi.org/project/acryl-datahub/\">\n    <img alt=\"PyPI\" src=\"https://img.shields.io/pypi/dm/acryl-datahub?label=downloads&labelColor=133554&color=1890ff\" /></a>\n  <a target=\"_blank\" href=\"https://github.com/datahub-project/datahub/pulse\">\n    <img alt=\"GitHub commit activity\" src=\"https://img.shields.io/github/commit-activity/m/datahub-project/datahub?label=commits&labelColor=133554&color=1890ff\" /></a>\n  <br />\n  <a target=\"_blank\" href=\"https://datahub.com/slack?utm_source=github&utm_medium=readme&utm_campaign=github_readme\">\n    <img alt=\"Slack\" src=\"https://img.shields.io/badge/slack-join_community-red.svg?logo=slack&labelColor=133554&color=1890ff\" /></a>\n  <a href=\"https://www.youtube.com/channel/UC3qFQC5IiwR5fvWEqi_tJ5w\">\n    <img alt=\"YouTube\" src=\"https://img.shields.io/youtube/channel/subscribers/UC3qFQC5IiwR5fvWEqi_tJ5w?style=flat&logo=youtube&label=subscribers&labelColor=133554&color=1890ff\"/></a>\n  <a href=\"https://medium.com/datahub-project/\">\n    <img alt=\"Medium\" src=\"https://img.shields.io/badge/blog-DataHub-red.svg?style=flat&logo=medium&logoColor=white&labelColor=133554&color=1890ff\" /></a>\n  <a href=\"https://x.com/datahubproject\">\n    <img alt=\"X (formerly Twitter) Follow\" src=\"https://img.shields.io/badge/follow-datahubproject-red.svg?style=flat&logo=x&labelColor=133554&color=1890ff\" /></a>\n</div>\n\n---\n\n### üè† Docs: [docs.datahub.com](https://docs.datahub.com/)\n\n[Quickstart](https://docs.datahub.com/docs/quickstart) |\n[Features](https://docs.datahub.com/docs/features) |\n[Roadmap](https://feature-requests.datahubproject.io/roadmap) |\n[Adoption](#adoption) |\n[Demo](https://demo.datahub.com/) |\n[Town Hall](https://docs.datahub.com/docs/townhalls)\n\n---\n\n> üì£‚ÄÇDataHub Town Hall is the 4th Thursday at 9am US PT of every month - [add it to your calendar!](https://lu.ma/datahubevents/)\n>\n> - Town-hall Zoom link: [zoom.datahubproject.io](https://zoom.datahubproject.io)\n> - [Meeting details](docs/townhalls.md) & [past recordings](docs/townhall-history.md)\n\n> ‚ú®‚ÄÇDataHub Community Highlights:\n>\n> - Read our Monthly Project Updates [here](https://medium.com/datahub-project/tagged/project-updates).\n> - Bringing The Power Of The DataHub Real-Time Metadata Graph To Everyone At DataHub: [Data Engineering Podcast](https://www.dataengineeringpodcast.com/acryl-data-datahub-metadata-graph-episode-230/)\n> - Check out our most-read blog post, [DataHub: Popular Metadata Architectures Explained](https://engineering.linkedin.com/blog/2020/datahub-popular-metadata-architectures-explained) @ LinkedIn Engineering Blog.\n> - Join us on [Slack](docs/slack.md)! Ask questions and keep up with the latest announcements.\n\n## Introduction\n\nDataHub is an open-source data catalog for the modern data stack. Read about the architectures of different metadata systems and why DataHub excels [here](https://engineering.linkedin.com/blog/2020/datahub-popular-metadata-architectures-explained). Also read our\n[LinkedIn Engineering blog post](https://engineering.linkedin.com/blog/2019/data-hub), check out our [Strata presentation](https://speakerdeck.com/shirshanka/the-evolution-of-metadata-linkedins-journey-strata-nyc-2019) and watch our [Crunch Conference Talk](https://www.youtube.com/watch?v=OB-O0Y6OYDE). You should also visit [DataHub Architecture](docs/architecture/architecture.md) to get a better understanding of how DataHub is implemented.\n\n## Features & Roadmap\n\nCheck out DataHub's [Features](docs/features.md) & [Roadmap](https://feature-requests.datahubproject.io/roadmap).\n\n## Demo and Screenshots\n\nThere's a [hosted demo environment](https://demo.datahub.com/) courtesy of DataHub where you can explore DataHub without installing it locally.\n\n## Quickstart\n\nPlease follow the [DataHub Quickstart Guide](https://docs.datahub.com/docs/quickstart) to run DataHub locally using [Docker](https://docker.com).\n\n## Development\n\nIf you're looking to build & modify datahub please take a look at our [Development Guide](https://docs.datahub.com/docs/developers).\n\n<p align=\"center\">\n<a href=\"https://demo.datahub.com/\">\n  <img width=\"70%\"  src=\"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/entity.png\"/>\n</a>\n</p>\n\n## Source Code and Repositories\n\n- [datahub-project/datahub](https://github.com/datahub-project/datahub): This repository contains the complete source code for DataHub's metadata model, metadata services, integration connectors and the web application.\n- [acryldata/datahub-actions](https://github.com/acryldata/datahub-actions): DataHub Actions is a framework for responding to changes to your DataHub Metadata Graph in real time.\n- [acryldata/datahub-helm](https://github.com/acryldata/datahub-helm): Helm charts for deploying DataHub on a Kubernetes cluster\n- [acryldata/meta-world](https://github.com/acryldata/meta-world): A repository to store recipes, custom sources, transformations and other things to make your DataHub experience magical.\n- [dbt-impact-action](https://github.com/acryldata/dbt-impact-action): A github action for commenting on your PRs with a summary of the impact of changes within a dbt project.\n- [datahub-tools](https://github.com/makenotion/datahub-tools): Additional python tools to interact with the DataHub GraphQL endpoints, built by Notion.\n- [business-glossary-sync-action](https://github.com/acryldata/business-glossary-sync-action): A github action that opens PRs to update your business glossary yaml file.\n- [mcp-server-datahub](https://github.com/acryldata/mcp-server-datahub): A [Model Context Protocol](https://modelcontextprotocol.io/) server implementation for DataHub.\n\n## Releases\n\nSee [Releases](https://github.com/datahub-project/datahub/releases) page for more details. We follow the [SemVer Specification](https://semver.org) when versioning the releases and adopt the [Keep a Changelog convention](https://keepachangelog.com/) for the changelog format.\n\n## Contributing\n\nWe welcome contributions from the community. Please refer to our [Contributing Guidelines](docs/CONTRIBUTING.md) for more details. We also have a [contrib](contrib) directory for incubating experimental features.\n\n## Community\n\nJoin our [Slack workspace](https://datahub.com/slack?utm_source=github&utm_medium=readme&utm_campaign=github_readme) for discussions and important announcements. You can also find out more about our upcoming [town hall meetings](docs/townhalls.md) and view past recordings.\n\n## Security\n\nSee [Security Stance](docs/SECURITY_STANCE.md) for information on DataHub's Security.\n\n## Adoption\n\nHere are the companies that have officially adopted DataHub. Please feel free to add yours to the list if we missed it.\n\n- [ABLY](https://ably.team/)\n- [Adevinta](https://www.adevinta.com/)\n- [Banksalad](https://www.banksalad.com)\n- [Cabify](https://cabify.tech/)\n- [ClassDojo](https://www.classdojo.com/)\n- [Coursera](https://www.coursera.org/)\n- [CVS Health](https://www.cvshealth.com/)\n- [DefinedCrowd](http://www.definedcrowd.com)\n- [DFDS](https://www.dfds.com/)\n- [Digital Turbine](https://www.digitalturbine.com/)\n- [Expedia Group](http://expedia.com)\n- [Experius](https://www.experius.nl)\n- [Geotab](https://www.geotab.com)\n- [Grofers](https://grofers.com)\n- [Haibo Technology](https://www.botech.com.cn)\n- [hipages](https://hipages.com.au/)\n- [inovex](https://www.inovex.de/)\n- [Inter&Co](https://inter.co/)\n- [IOMED](https://iomed.health)\n- [Klarna](https://www.klarna.com)\n- [LinkedIn](http://linkedin.com)\n- [Moloco](https://www.moloco.com/en)\n- [N26](https://n26brasil.com/)\n- [Optum](https://www.optum.com/)\n- [Peloton](https://www.onepeloton.com)\n- [PITS Global Data Recovery Services](https://www.pitsdatarecovery.net/)\n- [Razer](https://www.razer.com)\n- [Rippling](https://www.rippling.com/)\n- [Showroomprive](https://www.showroomprive.com/)\n- [SpotHero](https://spothero.com)\n- [Stash](https://www.stash.com)\n- [Shanghai HuaRui Bank](https://www.shrbank.com)\n- [s7 Airlines](https://www.s7.ru/)\n- [ThoughtWorks](https://www.thoughtworks.com)\n- [TypeForm](http://typeform.com)\n- [Udemy](https://www.udemy.com/)\n- [Uphold](https://uphold.com)\n- [Viasat](https://viasat.com)\n- [Wealthsimple](https://www.wealthsimple.com)\n- [Wikimedia](https://www.wikimedia.org)\n- [Wolt](https://wolt.com)\n- [Zynga](https://www.zynga.com)\n\n## Select Articles & Talks\n\n- [DataHub Blog](https://medium.com/datahub-project/)\n- [DataHub YouTube Channel](https://www.youtube.com/channel/UC3qFQC5IiwR5fvWEqi_tJ5w)\n- [Optum: Data Mesh via DataHub](https://opensource.optum.com/blog/2022/03/23/data-mesh-via-datahub)\n- [Saxo Bank: Enabling Data Discovery in Data Mesh](https://medium.com/datahub-project/enabling-data-discovery-in-a-data-mesh-the-saxo-journey-451b06969c8f)\n- [Bringing The Power Of The DataHub Real-Time Metadata Graph To Everyone At DataHub](https://www.dataengineeringpodcast.com/acryl-data-datahub-metadata-graph-episode-230/)\n- [DataHub: Popular Metadata Architectures Explained](https://engineering.linkedin.com/blog/2020/datahub-popular-metadata-architectures-explained)\n- [Driving DataOps Culture with LinkedIn DataHub](https://www.youtube.com/watch?v=ccsIKK9nVxk) @ [DataOps Unleashed 2021](https://dataopsunleashed.com/#shirshanka-session)\n- [The evolution of metadata: LinkedIn‚Äôs story](https://speakerdeck.com/shirshanka/the-evolution-of-metadata-linkedins-journey-strata-nyc-2019) @ [Strata Data Conference 2019](https://conferences.oreilly.com/strata/strata-ny-2019.html)\n- [Journey of metadata at LinkedIn](https://www.youtube.com/watch?v=OB-O0Y6OYDE) @ [Crunch Data Conference 2019](https://crunchconf.com/2019)\n- [DataHub Journey with Expedia Group](https://www.youtube.com/watch?v=ajcRdB22s5o)\n- [Data Discoverability at SpotHero](https://www.slideshare.net/MaggieHays/data-discoverability-at-spothero)\n- [Data Catalogue ‚Äî Knowing your data](https://medium.com/albert-franzi/data-catalogue-knowing-your-data-15f7d0724900)\n- [DataHub: A Generalized Metadata Search & Discovery Tool](https://engineering.linkedin.com/blog/2019/data-hub)\n- [Open sourcing DataHub: LinkedIn‚Äôs metadata search and discovery platform](https://engineering.linkedin.com/blog/2020/open-sourcing-datahub--linkedins-metadata-search-and-discovery-p)\n- [Emerging Architectures for Modern Data Infrastructure](https://future.com/emerging-architectures-for-modern-data-infrastructure-2020/)\n\nSee the full list [here](docs/links.md).\n\n## License\n\n[Apache License 2.0](./LICENSE).\n",
      "stars_today": 4
    },
    {
      "id": 261039251,
      "name": "swift-composable-architecture",
      "full_name": "pointfreeco/swift-composable-architecture",
      "description": "A library for building applications in a consistent and understandable way, with composition, testing, and ergonomics in mind.",
      "html_url": "https://github.com/pointfreeco/swift-composable-architecture",
      "stars": 14253,
      "forks": 1624,
      "language": "Swift",
      "topics": [
        "architecture",
        "composition",
        "modularity",
        "swiftui",
        "testability",
        "uikit"
      ],
      "created_at": "2020-05-03T23:18:40Z",
      "updated_at": "2026-01-13T20:27:02Z",
      "pushed_at": "2025-12-30T21:38:44Z",
      "open_issues": 23,
      "owner": {
        "login": "pointfreeco",
        "avatar_url": "https://avatars.githubusercontent.com/u/29466629?v=4"
      },
      "readme": "# The Composable Architecture\n\n[![CI](https://github.com/pointfreeco/swift-composable-architecture/actions/workflows/ci.yml/badge.svg)](https://github.com/pointfreeco/swift-composable-architecture/actions/workflows/ci.yml)\n[![Slack](https://img.shields.io/badge/slack-chat-informational.svg?label=Slack&logo=slack)](https://www.pointfree.co/slack-invite)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-composable-architecture%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-composable-architecture%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture)\n\nThe Composable Architecture (TCA, for short) is a library for building applications in a consistent \nand understandable way, with composition, testing, and ergonomics in mind. It can be used in \nSwiftUI, UIKit, and more, and on any Apple platform (iOS, macOS, iPadOS, visionOS, tvOS, and watchOS).\n\n* [What is the Composable Architecture?](#what-is-the-composable-architecture)\n* [Learn more](#learn-more)\n* [Examples](#examples)\n* [Basic usage](#basic-usage)\n* [Documentation](#documentation)\n* [FAQ](#faq)\n* [Community](#community)\n* [Installation](#installation)\n* [Translations](#translations)\n\n## What is the Composable Architecture?\n\nThis library provides a few core tools that can be used to build applications of varying purpose and \ncomplexity. It provides compelling stories that you can follow to solve many problems you encounter \nday-to-day when building applications, such as:\n\n* **State management**\n  <br> How to manage the state of your application using simple value types, and share state across \n  many screens so that mutations in one screen can be immediately observed in another screen.\n\n* **Composition**\n  <br> How to break down large features into smaller components that can be extracted to their own, \n  isolated modules and be easily glued back together to form the feature.\n\n* **Side effects**\n  <br> How to let certain parts of the application talk to the outside world in the most testable \n  and understandable way possible.\n\n* **Testing**\n  <br> How to not only test a feature built in the architecture, but also write integration tests \n  for features that have been composed of many parts, and write end-to-end tests to understand how \n  side effects influence your application. This allows you to make strong guarantees that your \n  business logic is running in the way you expect.\n\n* **Ergonomics**\n  <br> How to accomplish all of the above in a simple API with as few concepts and moving parts as \n  possible.\n\n## Learn More\n\nThe Composable Architecture was designed over the course of many episodes on \n[Point-Free][pointfreeco], a video series exploring advanced programming topics in the Swift language, \nhosted by [Brandon Williams][mbrandonw] and [Stephen Celis][stephencelis].\n\nYou can watch all of the episodes [here][tca-episode-collection], as well as a dedicated, [multipart\ntour][tca-tour] of the architecture from scratch.\n\n<a href=\"https://www.pointfree.co/collections/tours/composable-architecture-1-0\">\n  <img alt=\"video poster image\" src=\"https://d3rccdn33rt8ze.cloudfront.net/episodes/0243.jpeg\" width=\"600\">\n</a>\n\n## Examples\n\n[![Screen shots of example applications](https://d3rccdn33rt8ze.cloudfront.net/composable-architecture/demos.png)](./Examples)\n\nThis repo comes with _lots_ of examples to demonstrate how to solve common and complex problems with \nthe Composable Architecture. Check out [this](./Examples) directory to see them all, including:\n\n* [Case Studies](./Examples/CaseStudies)\n  * Getting started\n  * Effects\n  * Navigation\n  * Higher-order reducers\n  * Reusable components\n* [Location manager](https://github.com/pointfreeco/composable-core-location/tree/main/Examples/LocationManager)\n* [Motion manager](https://github.com/pointfreeco/composable-core-motion/tree/main/Examples/MotionManager)\n* [Search](./Examples/Search)\n* [Speech Recognition](./Examples/SpeechRecognition)\n* [SyncUps app](./Examples/SyncUps)\n* [Tic-Tac-Toe](./Examples/TicTacToe)\n* [Todos](./Examples/Todos)\n* [Voice memos](./Examples/VoiceMemos)\n\nLooking for something more substantial? Check out the source code for [isowords][gh-isowords], an \niOS word search game built in SwiftUI and the Composable Architecture.\n\n## Basic Usage\n\n> [!Note] \n> For a step-by-step interactive tutorial, be sure to check out [Meet the Composable\n> Architecture][meet-tca].\n\nTo build a feature using the Composable Architecture you define some types and values that model \nyour domain:\n\n* **State**: A type that describes the data your feature needs to perform its logic and render its \nUI.\n* **Action**: A type that represents all of the actions that can happen in your feature, such as \nuser actions, notifications, event sources and more.\n* **Reducer**: A function that describes how to evolve the current state of the app to the next \nstate given an action. The reducer is also responsible for returning any effects that should be \nrun, such as API requests, which can be done by returning an `Effect` value.\n* **Store**: The runtime that actually drives your feature. You send all user actions to the store \nso that the store can run the reducer and effects, and you can observe state changes in the store \nso that you can update UI.\n\nThe benefits of doing this are that you will instantly unlock testability of your feature, and you \nwill be able to break large, complex features into smaller domains that can be glued together.\n\nAs a basic example, consider a UI that shows a number along with \"+\" and \"‚àí\" buttons that increment \nand decrement the number. To make things interesting, suppose there is also a button that when \ntapped makes an API request to fetch a random fact about that number and displays it in the view.\n\nTo implement this feature we create a new type that will house the domain and behavior of the \nfeature, and it will be annotated with the `@Reducer` macro:\n\n```swift\nimport ComposableArchitecture\n\n@Reducer\nstruct Feature {\n}\n```\n\nIn here we need to define a type for the feature's state, which consists of an integer for the \ncurrent count, as well as an optional string that represents the fact being presented:\n\n```swift\n@Reducer\nstruct Feature {\n  @ObservableState\n  struct State: Equatable {\n    var count = 0\n    var numberFact: String?\n  }\n}\n```\n\n> [!Note] \n> We've applied the `@ObservableState` macro to `State` in order to take advantage of the\n> observation tools in the library.\n\nWe also need to define a type for the feature's actions. There are the obvious actions, such as \ntapping the decrement button, increment button, or fact button. But there are also some slightly \nnon-obvious ones, such as the action that occurs when we receive a response from the fact API \nrequest:\n\n```swift\n@Reducer\nstruct Feature {\n  @ObservableState\n  struct State: Equatable { /* ... */ }\n  enum Action {\n    case decrementButtonTapped\n    case incrementButtonTapped\n    case numberFactButtonTapped\n    case numberFactResponse(String)\n  }\n}\n```\n\nAnd then we implement the `body` property, which is responsible for composing the actual logic and \nbehavior for the feature. In it we can use the `Reduce` reducer to describe how to change the\ncurrent state to the next state, and what effects need to be executed. Some actions don't need to\nexecute effects, and they can return `.none` to represent that:\n\n```swift\n@Reducer\nstruct Feature {\n  @ObservableState\n  struct State: Equatable { /* ... */ }\n  enum Action { /* ... */ }\n\n  var body: some Reducer<State, Action> {\n    Reduce { state, action in\n      switch action {\n      case .decrementButtonTapped:\n        state.count -= 1\n        return .none\n\n      case .incrementButtonTapped:\n        state.count += 1\n        return .none\n\n      case .numberFactButtonTapped:\n        return .run { [count = state.count] send in\n          let (data, _) = try await URLSession.shared.data(\n            from: URL(string: \"http://numbersapi.com/\\(count)/trivia\")!\n          )\n          await send(\n            .numberFactResponse(String(decoding: data, as: UTF8.self))\n          )\n        }\n\n      case let .numberFactResponse(fact):\n        state.numberFact = fact\n        return .none\n      }\n    }\n  }\n}\n```\n\nAnd then finally we define the view that displays the feature. It holds onto a `StoreOf<Feature>` \nso that it can observe all changes to the state and re-render, and we can send all user actions to \nthe store so that state changes:\n\n```swift\nstruct FeatureView: View {\n  let store: StoreOf<Feature>\n\n  var body: some View {\n    Form {\n      Section {\n        Text(\"\\(store.count)\")\n        Button(\"Decrement\") { store.send(.decrementButtonTapped) }\n        Button(\"Increment\") { store.send(.incrementButtonTapped) }\n      }\n\n      Section {\n        Button(\"Number fact\") { store.send(.numberFactButtonTapped) }\n      }\n      \n      if let fact = store.numberFact {\n        Text(fact)\n      }\n    }\n  }\n}\n```\n\nIt is also straightforward to have a UIKit controller driven off of this store. You can observe\nstate changes in the store in `viewDidLoad`, and then populate the UI components with data from\nthe store. The code is a bit longer than the SwiftUI version, so we have collapsed it here:\n\n<details>\n  <summary>Click to expand!</summary>\n\n  ```swift\n  class FeatureViewController: UIViewController {\n    let store: StoreOf<Feature>\n\n    init(store: StoreOf<Feature>) {\n      self.store = store\n      super.init(nibName: nil, bundle: nil)\n    }\n\n    required init?(coder: NSCoder) {\n      fatalError(\"init(coder:) has not been implemented\")\n    }\n\n    override func viewDidLoad() {\n      super.viewDidLoad()\n\n      let countLabel = UILabel()\n      let decrementButton = UIButton()\n      let incrementButton = UIButton()\n      let factLabel = UILabel()\n      \n      // Omitted: Add subviews and set up constraints...\n      \n      observe { [weak self] in\n        guard let self \n        else { return }\n        \n        countLabel.text = \"\\(self.store.count)\"\n        factLabel.text = self.store.numberFact\n      }\n    }\n\n    @objc private func incrementButtonTapped() {\n      self.store.send(.incrementButtonTapped)\n    }\n    @objc private func decrementButtonTapped() {\n      self.store.send(.decrementButtonTapped)\n    }\n    @objc private func factButtonTapped() {\n      self.store.send(.numberFactButtonTapped)\n    }\n  }\n  ```\n</details>\n\nOnce we are ready to display this view, for example in the app's entry point, we can construct a \nstore. This can be done by specifying the initial state to start the application in, as well as \nthe reducer that will power the application:\n\n```swift\nimport ComposableArchitecture\n\n@main\nstruct MyApp: App {\n  var body: some Scene {\n    WindowGroup {\n      FeatureView(\n        store: Store(initialState: Feature.State()) {\n          Feature()\n        }\n      )\n    }\n  }\n}\n```\n\nAnd that is enough to get something on the screen to play around with. It's definitely a few more \nsteps than if you were to do this in a vanilla SwiftUI way, but there are a few benefits. It gives \nus a consistent manner to apply state mutations, instead of scattering logic in some observable \nobjects and in various action closures of UI components. It also gives us a concise way of \nexpressing side effects. And we can immediately test this logic, including the effects, without \ndoing much additional work.\n\n### Testing\n\n> [!Note] \n> For more in-depth information on testing, see the dedicated [testing][testing-article] article. \n\nTo test use a `TestStore`, which can be created with the same information as the `Store`, but it \ndoes extra work to allow you to assert how your feature evolves as actions are sent:\n\n```swift\n@Test\nfunc basics() async {\n  let store = TestStore(initialState: Feature.State()) {\n    Feature()\n  }\n}\n```\n\nOnce the test store is created we can use it to make an assertion of an entire user flow of steps. \nEach step of the way we need to prove that state changed how we expect. For example, we can \nsimulate the user flow of tapping on the increment and decrement buttons:\n\n```swift\n// Test that tapping on the increment/decrement buttons changes the count\nawait store.send(.incrementButtonTapped) {\n  $0.count = 1\n}\nawait store.send(.decrementButtonTapped) {\n  $0.count = 0\n}\n```\n\nFurther, if a step causes an effect to be executed, which feeds data back into the store, we must \nassert on that. For example, if we simulate the user tapping on the fact button we expect to \nreceive a fact response back with the fact, which then causes the `numberFact` state to be \npopulated:\n\n```swift\nawait store.send(.numberFactButtonTapped)\n\nawait store.receive(\\.numberFactResponse) {\n  $0.numberFact = ???\n}\n```\n\nHowever, how do we know what fact is going to be sent back to us?\n\nCurrently our reducer is using an effect that reaches out into the real world to hit an API server, \nand that means we have no way to control its behavior. We are at the whims of our internet \nconnectivity and the availability of the API server in order to write this test.\n\nIt would be better for this dependency to be passed to the reducer so that we can use a live \ndependency when running the application on a device, but use a mocked dependency for tests. We can \ndo this by adding a property to the `Feature` reducer:\n\n```swift\n@Reducer\nstruct Feature {\n  let numberFact: (Int) async throws -> String\n  // ...\n}\n```\n\nThen we can use it in the `reduce` implementation:\n\n```swift\ncase .numberFactButtonTapped:\n  return .run { [count = state.count] send in \n    let fact = try await self.numberFact(count)\n    await send(.numberFactResponse(fact))\n  }\n```\n\nAnd in the entry point of the application we can provide a version of the dependency that actually \ninteracts with the real world API server:\n\n```swift\n@main\nstruct MyApp: App {\n  var body: some Scene {\n    WindowGroup {\n      FeatureView(\n        store: Store(initialState: Feature.State()) {\n          Feature(\n            numberFact: { number in\n              let (data, _) = try await URLSession.shared.data(\n                from: URL(string: \"http://numbersapi.com/\\(number)\")!\n              )\n              return String(decoding: data, as: UTF8.self)\n            }\n          )\n        }\n      )\n    }\n  }\n}\n```\n\nBut in tests we can use a mock dependency that immediately returns a deterministic, predictable \nfact: \n\n```swift\n@Test\nfunc basics() async {\n  let store = TestStore(initialState: Feature.State()) {\n    Feature(numberFact: { \"\\($0) is a good number Brent\" })\n  }\n}\n```\n\nWith that little bit of upfront work we can finish the test by simulating the user tapping on the \nfact button, and then receiving the response from the dependency to present the fact:\n\n```swift\nawait store.send(.numberFactButtonTapped)\n\nawait store.receive(\\.numberFactResponse) {\n  $0.numberFact = \"0 is a good number Brent\"\n}\n```\n\nWe can also improve the ergonomics of using the `numberFact` dependency in our application. Over \ntime the application may evolve into many features, and some of those features may also want access \nto `numberFact`, and explicitly passing it through all layers can get annoying. There is a process \nyou can follow to ‚Äúregister‚Äù dependencies with the library, making them instantly available to any \nlayer in the application.\n\n> [!Note] \n> For more in-depth information on dependency management, see the dedicated\n> [dependencies][dependencies-article] article. \n\nWe can start by wrapping the number fact functionality in a new type:\n\n```swift\nstruct NumberFactClient {\n  var fetch: (Int) async throws -> String\n}\n```\n\nAnd then registering that type with the dependency management system by conforming the client to\nthe `DependencyKey` protocol, which requires you to specify the live value to use when running the\napplication in simulators or devices:\n\n```swift\nextension NumberFactClient: DependencyKey {\n  static let liveValue = Self(\n    fetch: { number in\n      let (data, _) = try await URLSession.shared\n        .data(from: URL(string: \"http://numbersapi.com/\\(number)\")!\n      )\n      return String(decoding: data, as: UTF8.self)\n    }\n  )\n}\n\nextension DependencyValues {\n  var numberFact: NumberFactClient {\n    get { self[NumberFactClient.self] }\n    set { self[NumberFactClient.self] = newValue }\n  }\n}\n```\n\nWith that little bit of upfront work done you can instantly start making use of the dependency in \nany feature by using the `@Dependency` property wrapper:\n\n```diff\n @Reducer\n struct Feature {\n-  let numberFact: (Int) async throws -> String\n+  @Dependency(\\.numberFact) var numberFact\n   \n   ‚Ä¶\n\n-  try await self.numberFact(count)\n+  try await self.numberFact.fetch(count)\n }\n```\n\nThis code works exactly as it did before, but you no longer have to explicitly pass the dependency \nwhen constructing the feature's reducer. When running the app in previews, the simulator or on a \ndevice, the live dependency will be provided to the reducer, and in tests the test dependency will \nbe provided.\n\nThis means the entry point to the application no longer needs to construct dependencies:\n\n```swift\n@main\nstruct MyApp: App {\n  var body: some Scene {\n    WindowGroup {\n      FeatureView(\n        store: Store(initialState: Feature.State()) {\n          Feature()\n        }\n      )\n    }\n  }\n}\n```\n\nAnd the test store can be constructed without specifying any dependencies, but you can still \noverride any dependency you need to for the purpose of the test:\n\n```swift\nlet store = TestStore(initialState: Feature.State()) {\n  Feature()\n} withDependencies: {\n  $0.numberFact.fetch = { \"\\($0) is a good number Brent\" }\n}\n\n// ...\n```\n\nThat is the basics of building and testing a feature in the Composable Architecture. There are \n_a lot_ more things to be explored, such as composition, modularity, adaptability, and complex \neffects. The [Examples](./Examples) directory has a bunch of projects to explore to see more \nadvanced usages.\n\n## Documentation\n\nThe documentation for releases and `main` are available here:\n\n* [`main`](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture)\n* [1.x.x](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/~/documentation/composablearchitecture)\n\nThere are a number of articles in the documentation that you may find helpful as you become more \ncomfortable with the library:\n\n* [Getting started][getting-started-article]\n* [Dependencies][dependencies-article]\n* [Testing][testing-article]\n* [Navigation][navigation-article]\n* [Sharing state][sharing-state-article]\n* [Performance][performance-article]\n* [Concurrency][concurrency-article]\n* [Bindings][bindings-article]\n\n## FAQ\n\nWe have a [dedicated article][faq-article] for all of the most frequently asked questions and\ncomments people have concerning the library.\n\n## Community\n\nIf you want to discuss the Composable Architecture or have a question about how to use it to solve \na particular problem, there are a number of places you can discuss with fellow \n[Point-Free](http://www.pointfree.co) enthusiasts:\n\n* For long-form discussions, we recommend the [discussions][gh-discussions] tab of this repo.\n* For casual chat, we recommend the [Point-Free Community slack](http://pointfree.co/slack-invite).\n\n## Installation\n\nYou can add ComposableArchitecture to an Xcode project by adding it as a package dependency.\n\n  1. From the **File** menu, select **Add Package Dependencies...**\n  2. Enter \"https://github.com/pointfreeco/swift-composable-architecture\" into the package \n     repository URL text field\n  3. Depending on how your project is structured:\n      - If you have a single application target that needs access to the library, then add \n        **ComposableArchitecture** directly to your application.\n      - If you want to use this library from multiple Xcode targets, or mix Xcode targets and SPM \n        targets, you must create a shared framework that depends on **ComposableArchitecture** and \n        then depend on that framework in all of your targets. For an example of this, check out the \n        [Tic-Tac-Toe](./Examples/TicTacToe) demo application, which splits lots of features into \n        modules and consumes the static library in this fashion using the **tic-tac-toe** Swift \n        package.\n\n## Companion libraries\n\nThe Composable Architecture is built with extensibility in mind, and there are a number of\ncommunity-supported libraries available to enhance your applications:\n\n* [Composable Architecture Extras](https://github.com/Ryu0118/swift-composable-architecture-extras):\n  A companion library to the Composable Architecture.\n* [TCAComposer](https://github.com/mentalflux/tca-composer): A macro framework for generating\n  boiler-plate code in the Composable Architecture.\n* [TCACoordinators](https://github.com/johnpatrickmorgan/TCACoordinators): The coordinator pattern\n  in the Composable Architecture.\n\nIf you'd like to contribute a library, please [open a\nPR](https://github.com/pointfreeco/swift-composable-architecture/edit/main/README.md) with a link\nto it!\n\n## Translations\n\nThe following translations of this README have been contributed by members of the community:\n\n* [Arabic](https://gist.github.com/NorhanBoghdadi/1b98d55c02b683ddef7e05c2ebcccd47)\n* [French](https://gist.github.com/nikitamounier/0e93eb832cf389db12f9a69da030a2dc)\n* [Hindi](https://gist.github.com/akashsoni01/b358ee0b3b747167964ef6946123c88d)\n* [Indonesian](https://gist.github.com/wendyliga/792ea9ac5cc887f59de70a9e39cc7343)\n* [Italian](https://gist.github.com/Bellaposa/5114e6d4d55fdb1388e8186886d48958)\n* [Japanese](https://gist.github.com/Achoo-kr/2d0712deb77f78b3379551ac7baea3e4)\n* [Korean](https://gist.github.com/Achoo-kr/5d8936d12e71028fcc4a7c5e078ca038)\n* [Polish](https://gist.github.com/MarcelStarczyk/6b6153051f46912a665c32199f0d1d54)\n* [Portuguese](https://gist.github.com/SevioCorrea/2bbf337cd084a58c89f2f7f370626dc8)\n* [Russian](https://gist.github.com/SubvertDev/3317d0c3b35ed601be330d6fc0df5aba)\n* [Simplified Chinese](https://gist.github.com/sh3l6orrr/10c8f7c634a892a9c37214f3211242ad)\n* [Spanish](https://gist.github.com/pitt500/f5e32fccb575ce112ffea2827c7bf942)\n* [Turkish](https://gist.github.com/gokhanamal/93001244ef0c1cec58abeb1afc0de37c)\n* [Ukrainian](https://gist.github.com/barabashd/33b64676195ce41f4bb73c327ea512a8)\n\nIf you'd like to contribute a translation, please [open a\nPR](https://github.com/pointfreeco/swift-composable-architecture/edit/main/README.md) with a link \nto a [Gist](https://gist.github.com)!\n\n## Credits and thanks\n\nThe following people gave feedback on the library at its early stages and helped make the library \nwhat it is today:\n\nPaul Colton, Kaan Dedeoglu, Matt Diephouse, Josef Dole≈æal, Eimantas, Matthew Johnson, George \nKaimakas, Nikita Leonov, Christopher Liscio, Jeffrey Macko, Alejandro Martinez, Shai Mishali, Willis \nPlummer, Simon-Pierre Roy, Justin Price, Sven A. Schmidt, Kyle Sherman, Petr ≈†√≠ma, Jasdev Singh, \nMaxim Smirnov, Ryan Stone, Daniel Hollis Tavares, and all of the [Point-Free][pointfreeco] \nsubscribers üòÅ.\n\nSpecial thanks to [Chris Liscio](https://twitter.com/liscio) who helped us work through many strange \nSwiftUI quirks and helped refine the final API.\n\nAnd thanks to [Shai Mishali](https://github.com/freak4pc) and the\n[CombineCommunity](https://github.com/CombineCommunity/CombineExt/) project, from which we took \ntheir implementation of `Publishers.Create`, which we use in `Effect` to help bridge delegate and \ncallback-based APIs, making it much easier to interface with 3rd party frameworks.\n\n## Other libraries\n\nThe Composable Architecture was built on a foundation of ideas started by other libraries, in \nparticular [Elm](https://elm-lang.org) and [Redux](https://redux.js.org/).\n\nThere are also many architecture libraries in the Swift and iOS community. Each one of these has \ntheir own set of priorities and trade-offs that differ from the Composable Architecture.\n\n* [RIBs](https://github.com/uber/RIBs)\n* [Loop](https://github.com/ReactiveCocoa/Loop)\n* [ReSwift](https://github.com/ReSwift/ReSwift)\n* [Workflow](https://github.com/square/workflow)\n* [ReactorKit](https://github.com/ReactorKit/ReactorKit)\n* [RxFeedback](https://github.com/NoTests/RxFeedback.swift)\n* [Mobius.swift](https://github.com/spotify/mobius.swift)\n* <details>\n  <summary>And more</summary>\n\n  * [Fluxor](https://github.com/FluxorOrg/Fluxor)\n  * [PromisedArchitectureKit](https://github.com/RPallas92/PromisedArchitectureKit)\n  </details>\n\n## License\n\nThis library is released under the MIT license. See [LICENSE](LICENSE) for details.\n\n[pointfreeco]: https://www.pointfree.co\n[mbrandonw]: https://twitter.com/mbrandonw\n[stephencelis]: https://twitter.com/stephencelis\n[tca-episode-collection]: https://www.pointfree.co/collections/composable-architecture\n[tca-tour]: https://www.pointfree.co/collections/tours/composable-architecture-1-0\n[gh-isowords]: https://github.com/pointfreeco/isowords\n[gh-discussions]: https://github.com/pointfreeco/swift-composable-architecture/discussions\n[swift-forum]: https://forums.swift.org/c/related-projects/swift-composable-architecture\n[testing-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/testingtca\n[faq-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/faq\n[dependencies-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/dependencymanagement\n[getting-started-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/gettingstarted\n[navigation-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/navigation\n[performance-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/performance\n[concurrency-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/swiftconcurrency\n[bindings-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/bindings\n[sharing-state-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/sharingstate\n[meet-tca]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/tutorials/meetcomposablearchitecture\n",
      "stars_today": 4
    },
    {
      "id": 272457606,
      "name": "cosmopolitan",
      "full_name": "jart/cosmopolitan",
      "description": "build-once run-anywhere c library",
      "html_url": "https://github.com/jart/cosmopolitan",
      "stars": 20374,
      "forks": 733,
      "language": "C",
      "topics": [
        "bios",
        "containers",
        "darwin",
        "efi",
        "freebsd",
        "libc",
        "linux",
        "netbsd",
        "openbsd",
        "polyglot",
        "windows",
        "zip"
      ],
      "created_at": "2020-06-15T14:16:13Z",
      "updated_at": "2026-01-13T21:49:44Z",
      "pushed_at": "2025-12-02T08:37:54Z",
      "open_issues": 197,
      "owner": {
        "login": "jart",
        "avatar_url": "https://avatars.githubusercontent.com/u/49262?v=4"
      },
      "readme": "![Cosmopolitan Honeybadger](usr/share/img/honeybadger.png)\n\n[![build](https://github.com/jart/cosmopolitan/actions/workflows/build.yml/badge.svg)](https://github.com/jart/cosmopolitan/actions/workflows/build.yml)\n# Cosmopolitan\n\n[Cosmopolitan Libc](https://justine.lol/cosmopolitan/index.html) makes C/C++\na build-once run-anywhere language, like Java, except it doesn't need an\ninterpreter or virtual machine. Instead, it reconfigures stock GCC and\nClang to output a POSIX-approved polyglot format that runs natively on\nLinux + Mac + Windows + FreeBSD + OpenBSD 7.3 + NetBSD + BIOS with the\nbest possible performance and the tiniest footprint imaginable.\n\n## Background\n\nFor an introduction to this project, please read the [actually portable\nexecutable](https://justine.lol/ape.html) blog post and [cosmopolitan\nlibc](https://justine.lol/cosmopolitan/index.html) website. We also have\n[API\ndocumentation](https://justine.lol/cosmopolitan/documentation.html).\n\n## Getting Started\n\nYou can start by obtaining a release of our `cosmocc` compiler from\n<https://cosmo.zip/pub/cosmocc/>.\n\n```sh\nmkdir -p cosmocc\ncd cosmocc\nwget https://cosmo.zip/pub/cosmocc/cosmocc.zip\nunzip cosmocc.zip\n```\n\nHere's an example program we can write:\n\n```c\n// hello.c\n#include <stdio.h>\n\nint main() {\n  printf(\"hello world\\n\");\n}\n```\n\nIt can be compiled as follows:\n\n```sh\ncosmocc -o hello hello.c\n./hello\n```\n\nThe Cosmopolitan Libc runtime links some heavyweight troubleshooting\nfeatures by default, which are very useful for developers and admins.\nHere's how you can log system calls:\n\n```sh\n./hello --strace\n```\n\nHere's how you can get a much more verbose log of function calls:\n\n```sh\n./hello --ftrace\n```\n\nYou can use the Cosmopolitan's toolchain to build conventional open\nsource projects which use autotools. This strategy normally works:\n\n```sh\nexport CC=x86_64-unknown-cosmo-cc\nexport CXX=x86_64-unknown-cosmo-c++\n./configure --prefix=/opt/cosmos/x86_64\nmake -j\nmake install\n```\n\n## Cosmopolitan Source Builds\n\nCosmopolitan can be compiled from source on any of our supported\nplatforms. The Makefile will download cosmocc automatically.\n\nIt's recommended that you install a systemwide APE Loader. This command\nrequires `sudo` access to copy the `ape` command to a system folder and\nregister with binfmt_misc on Linux, for even more performance.\n\n```sh\nape/apeinstall.sh\n```\n\nYou can now build the mono repo with any modern version of GNU Make. To\nbootstrap your build, you can install Cosmopolitan Make from this site:\n\nhttps://cosmo.zip/pub/cosmos/bin/make\n\nE.g.:\n\n```sh\ncurl -LO https://cosmo.zip/pub/cosmos/bin/make\n./make -j8\no//examples/hello\n```\n\nAfter you've built the repo once, you can also use the make from your\ncosmocc at `.cosmocc/current/bin/make`. You might even prefer to alias\nmake to `$COSMO/.cosmocc/current/bin/make`.\n\nSince the Cosmopolitan repository is very large, you might only want to\nbuild one particular thing. Here's an example of a target that can be\ncompiled relatively quickly, which is a simple POSIX test that only\ndepends on core LIBC packages.\n\n```sh\nrm -rf o//libc o//test\n.cosmocc/current/bin/make o//test/posix/signal_test\no//test/posix/signal_test\n```\n\nSometimes it's desirable to build a subset of targets, without having to\nlist out each individual one. For example if you wanted to build and run\nall the unit tests in the `TEST_POSIX` package, you could say:\n\n```sh\n.cosmocc/current/bin/make o//test/posix\n```\n\nCosmopolitan provides a variety of build modes. For example, if you want\nreally tiny binaries (as small as 12kb in size) then you'd say:\n\n```sh\n.cosmocc/current/bin/make m=tiny\n```\n\nYou can furthermore cut out the bloat of other operating systems, and\nhave Cosmopolitan become much more similar to Musl Libc.\n\n```sh\n.cosmocc/current/bin/make m=tinylinux\n```\n\nFor further details, see [//build/config.mk](build/config.mk).\n\n## Debugging\n\nTo print a log of system calls to stderr:\n\n```sh\ncosmocc -o hello hello.c\n./hello --strace\n```\n\nTo print a log of function calls to stderr:\n\n```sh\ncosmocc -o hello hello.c\n./hello --ftrace\n```\n\nBoth strace and ftrace use the unbreakable kprintf() facility, which is\nable to be sent to a file by setting an environment variable.\n\n```sh\nexport KPRINTF_LOG=log\n./hello --strace\n```\n\n## GDB\n\nHere's the recommended `~/.gdbinit` config:\n\n```gdb\nset host-charset UTF-8\nset target-charset UTF-8\nset target-wide-charset UTF-8\nset osabi none\nset complaints 0\nset confirm off\nset history save on\nset history filename ~/.gdb_history\ndefine asm\n  layout asm\n  layout reg\nend\ndefine src\n  layout src\n  layout reg\nend\nsrc\n```\n\nYou normally run the `.dbg` file under gdb. If you need to debug the\n`` file itself, then you can load the debug symbols independently as\n\n```sh\ngdb foo -ex 'add-symbol-file foo.dbg 0x401000'\n```\n\n## Platform Notes\n\n### Shells\n\nIf you use zsh and have trouble running APE programs try `sh -c ./prog`\nor simply upgrade to zsh 5.9+ (since we patched it two years ago). The\nsame is the case for Python `subprocess`, old versions of fish, etc.\n\n### Linux\n\nSome Linux systems are configured to launch MZ executables under WINE.\nOther distros configure their stock installs so that APE programs will\nprint \"run-detectors: unable to find an interpreter\". For example:\n\n```sh\njart@ubuntu:~$ wget https://cosmo.zip/pub/cosmos/bin/dash\njart@ubuntu:~$ chmod +x dash\njart@ubuntu:~$ ./dash\nrun-detectors: unable to find an interpreter for ./dash\n```\n\nYou can fix that by registering APE with `binfmt_misc`:\n\n```sh\nsudo wget -O /usr/bin/ape https://cosmo.zip/pub/cosmos/bin/ape-$(uname -m).elf\nsudo chmod +x /usr/bin/ape\nsudo sh -c \"echo ':APE:M::MZqFpD::/usr/bin/ape:' >/proc/sys/fs/binfmt_misc/register\"\nsudo sh -c \"echo ':APE-jart:M::jartsr::/usr/bin/ape:' >/proc/sys/fs/binfmt_misc/register\"\n```\n\nYou should be good now. APE will not only work, it'll launch executables\n400¬µs faster now too. However if things still didn't work out, it's also\npossible to disable `binfmt_misc` as follows:\n\n```sh\nsudo sh -c 'echo -1 > /proc/sys/fs/binfmt_misc/cli'     # remove Ubuntu's MZ interpreter\nsudo sh -c 'echo -1 > /proc/sys/fs/binfmt_misc/status'  # remove ALL binfmt_misc entries\n```\n\n### WSL\n\nIt's normally unsafe to use APE in a WSL environment, because it tries\nto run MZ executables as WIN32 binaries within the WSL environment. In\norder to make it safe to use Cosmopolitan software on WSL, run this:\n\n```sh\nsudo sh -c \"echo -1 > /proc/sys/fs/binfmt_misc/WSLInterop\"\n```\n\n## Discord Chatroom\n\nThe Cosmopolitan development team collaborates on the Redbean Discord\nserver. You're welcome to join us! <https://discord.gg/FwAVVu7eJ4>\n\n## Support Vector\n\n| Platform       | Min Version    | Circa |\n| :---           | ---:           | ---:  |\n| AMD            | K8             | 2003  |\n| Intel          | Core           | 2006  |\n| Linux          | 2.6.18         | 2007  |\n| Windows        | 8 [1]          | 2012  |\n| Darwin (macOS) | 23.1.0+        | 2023  |\n| OpenBSD        | 7.3 or earlier | 2023  |\n| FreeBSD        | 13             | 2020  |\n| NetBSD         | 9.2            | 2021  |\n\n[1] See our [vista branch](https://github.com/jart/cosmopolitan/tree/vista)\n    for a community supported version of Cosmopolitan that works on Windows\n    Vista and Windows 7.\n\n## Special Thanks\n\nFunding for this project is crowdsourced using\n[GitHub Sponsors](https://github.com/sponsors/jart) and\n[Patreon](https://www.patreon.com/jart). Your support is what makes this\nproject possible. Thank you! We'd also like to give special thanks to\nthe following groups and individuals:\n\n- [Joe Drumgoole](https://github.com/jdrumgoole)\n- [Rob Figueiredo](https://github.com/robfig)\n- [Wasmer](https://wasmer.io/)\n\nFor publicly sponsoring our work at the highest tier.\n",
      "stars_today": 4
    },
    {
      "id": 66645293,
      "name": "gantt",
      "full_name": "frappe/gantt",
      "description": "Open Source Javascript Gantt",
      "html_url": "https://github.com/frappe/gantt",
      "stars": 5796,
      "forks": 1249,
      "language": "JavaScript",
      "topics": [
        "frappe-gantt",
        "gantt",
        "gantt-chart",
        "ganttjs",
        "javascript-gantt"
      ],
      "created_at": "2016-08-26T12:17:58Z",
      "updated_at": "2026-01-13T20:03:15Z",
      "pushed_at": "2025-10-31T09:32:00Z",
      "open_issues": 70,
      "owner": {
        "login": "frappe",
        "avatar_url": "https://avatars.githubusercontent.com/u/836974?v=4"
      },
      "readme": "<div align=\"center\" markdown=\"1\">\n    <img src=\".github/gantt-logo.jpg\" width=\"80\">\n    <h1>Frappe Gantt</h1>\n\n**A modern, configurable, Gantt library for the web.**\n\n</div>\n\n![Hero Image](.github/hero-image.png)\n\n## Frappe Gantt\n\nGantt charts are bar charts that visually illustrate a project's tasks, schedule, and dependencies. With Frappe Gantt, you can build beautiful, customizable, Gantt charts with ease.\n\nYou can use it anywhere from hobby projects to tracking the goals of your team at the worksplace.\n\n[ERPNext](https://erpnext.com/) uses Frappe Gantt.\n\n### Motivation\n\nWe needed a Gantt View for ERPNext. Surprisingly, we couldn't find a visually appealing Gantt library that was open source - so we decided to build it. Initially, the design was heavily inspired by Google Gantt and DHTMLX.\n\n### Key Features\n\n-   **Customizable Views**: customize the timeline based on various time periods - day, hour, or year, you have it. You can also create your own views.\n-   **Ignore Periods**: exclude weekends and other holidays from your tasks' progress calculation.\n-   **Configure Anything**: spacing, edit access, labels, you can control it all. Change both the style and functionality to meet your needs.\n-   **Multi-lingual Support**: suitable for companies with an international base.\n\n## Usage\n\nInstall with:\n\n```bash\nnpm install frappe-gantt\n```\n\nInclude it in your HTML:\n\n```html\n<script src=\"frappe-gantt.umd.js\"></script>\n<link rel=\"stylesheet\" href=\"frappe-gantt.css\" />\n```\n\nOr from the CDN:\n\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/frappe-gantt/dist/frappe-gantt.umd.js\"></script>\n<link\n    rel=\"stylesheet\"\n    href=\"https://cdn.jsdelivr.net/npm/frappe-gantt/dist/frappe-gantt.css\"\n/>\n```\n\nStart using Gantt:\n\n```js\nlet tasks = [\n  {\n    id: '1',\n    name: 'Redesign website',\n    start: '2016-12-28',\n    end: '2016-12-31',\n    progress: 20\n  },\n  ...\n]\nlet gantt = new Gantt(\"#gantt\", tasks);\n\n// Use .refresh to update the chart\ngantt.tasks.append(...)\ngantt.tasks.refresh()\n```\n\n### Configuration\n\nFrappe Gantt offers a wide range of options to customize your chart.\n\n| **Option**               | **Description**                                               | **Possible Values**                                                                                                                                                           | **Default**                                         |\n| ------------------------ | ------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------- |\n| `arrow_curve`            | Curve radius of arrows connecting dependencies.               | Any positive integer.                                                                                                                                                         | `5`                                                 |\n| `auto_move_label`        | Move task labels when user scrolls horizontally.              | `true`, `false`                                                                                                                                                               | `false`                                             |\n| `bar_corner_radius`      | Radius of the task bar corners (in pixels).                   | Any positive integer.                                                                                                                                                         | `3`                                                 |\n| `bar_height`             | Height of task bars (in pixels).                              | Any positive integer.                                                                                                                                                         | `30`                                                |\n| `container_height`       | Height of the container.                                      | `auto` - dynamic container height to fit all tasks - _or_ any positive integer (for pixels).                                                                                  | `auto`                                              |\n| `column_width`           | Width of each column in the timeline.                         | Any positive integer.                                                                                                                                                         | 45                                                  |\n| `date_format`            | Format for displaying dates.                                  | Any valid JS date format string.                                                                                                                                              | `YYYY-MM-DD`                                        |\n| `upper_header_height`    | Height of the upper header in the timeline (in pixels).       | Any positive integer.                                                                                                                                                         | `45`                                                |\n| `lower_header_height`    | Height of the lower header in the timeline (in pixels).       | Any positive integer.                                                                                                                                                         | `30`                                                |\n| `snap_at`                | Snap tasks at particular intervel while resizing or dragging. | Any _interval_ (see below)                                                                                                                                                    | `1d`                                                |\n| `infinite_padding`       | Whether to extend timeline infinitely when user scrolls.      | `true`, `false`                                                                                                                                                               | `true`                                              |\n| `holidays`               | Highlighted holidays on the timeline.                         | Object mapping CSS colors to holiday types. Types can either be a) 'weekend', or b) array of _strings_ or _date objects_ or _objects_ in the format `{date: ..., label: ...}` | `{ 'var(--g-weekend-highlight-color)': 'weekend' }` |\n| `is_weekend`             | Determines whether a day is a weekend                         | Function                                                                                                                                                                      | `(d) => d.getDay() === 0 \\|\\| d.getDay() === 6`     |\n| `ignore`                 | Ignored areas in the rendering                                | `weekend` _or_ Array of strings or date objects (`weekend` can be present to the array also).                                                                                 | `[]`                                                |\n| `language`               | Language for localization.                                    | ISO 639-1 codes like `en`, `fr`, `es`.                                                                                                                                        | `en`                                                |\n| `lines`                  | Determines which grid lines to display.                       | `none` for no lines, `vertical` for only vertical lines, `horizontal` for only horizontal lines, `both` for complete grid.                                                    | `both`                                              |\n| `move_dependencies`      | Whether moving a task automatically moves its dependencies.   | `true`, `false`                                                                                                                                                               | `true`                                              |\n| `padding`                | Padding around task bars (in pixels).                         | Any positive integer.                                                                                                                                                         | `18`                                                |\n| `popup_on`               | Event to trigger the popup display.                           | `click` _or_ `hover`                                                                                                                                                          | `click`                                             |\n| `readonly_progress`      | Disables editing task progress.                               | `true`, `false`                                                                                                                                                               | `false`                                             |\n| `readonly_dates`         | Disables editing task dates.                                  | `true`, `false`                                                                                                                                                               | `false`                                             |\n| `readonly`               | Disables all editing features.                                | `true`, `false`                                                                                                                                                               | `false`                                             |\n| `scroll_to`              | Determines the starting point when chart is rendered.         | `today`, `start`, `end`, or a date string.                                                                                                                                    | `today`                                             |\n| `show_expected_progress` | Shows expected progress for tasks.                            | `true`, `false`                                                                                                                                                               | `false`                                             |\n| `today_button`           | Adds a button to navigate to today‚Äôs date.                    | `true`, `false`                                                                                                                                                               | `true`                                              |\n| `view_mode`              | The initial view mode of the Gantt chart.                     | `Day`, `Week`, `Month`, `Year`.                                                                                                                                               | `Day`                                               |\n| `view_mode_select`       | Allows selecting the view mode from a dropdown.               | `true`, `false`                                                                                                                                                               | `false`                                             |\n\nApart from these ones, two options - `popup` and `view_modes` (plural, not singular) - are available. They have \"sub\"-APIs, and thus are listed separately.\n\n#### View Mode Configuration\n\nThe `view_modes` option determines all the available view modes for the chart. It should be an array of objects.\n\nEach object can have the following properties:\n\n-   `name` (string) - the name of view mode.\n-   `padding` (interval) - the time above.\n-   `step` - the interval of each column\n-   `lower_text` (date format string _or_ function) - the format for text in lower header. Blank string for none. The function takes in `currentDate`, `previousDate`, and `lang`, and should return a string.\n-   `upper_text` (date format string _or_ function) - the format for text in upper header. Blank string for none. The function takes in `currentDate`, `previousDate`, and `lang`, and should return a string.\n-   `upper_text_frequency` (number) - how often the upper text has a value. Utilized in internal calculation to improve performance.\n-   `thick_line` (function) - takes in `currentDate`, returns Boolean determining whether the line for that date should be thicker than the others.\n\nThree other options allow you to override general configuration for this view mode alone:\n\n-   `date_format`\n-   `column_width`\n-   `snap_at`\n    For details, see the above table.\n\n#### Popup Configuration\n\n`popup` is a function. If it returns\n\n-   `false`, there will be no popup.\n-   `undefined`, the popup will be rendered based on manipulation within the function\n-   a HTML string, the popup will be that string.\n\nThe function receives one object as an argument, containing:\n\n-   `task` - the task as an object\n-   `chart` - the entire Gantt chart\n-   `get_title`, `get_subtitle`, `get_details` (functions) - get the relevant section as a HTML node.\n-   `set_title`, `set_subtitle`, `set_details` (functions) - take in the HTML of the relevant section\n-   `add_action` (function) - accepts two parameters, `html` and `func` - respectively determining the HTML of the action and the callback when the action is pressed.\n\n### API\n\nFrappe Gantt exposes a few helpful methods for you to interact with the chart:\n\n| **Name**            | **Description**                                       | **Parameters**                                                                                                                                                               |\n| ------------------- | ----------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `.update_options`   | Re-renders the chart after updating specific options. | `new_options` - object containing new options.                                                                                                                               |\n| `.change_view_mode` | Updates the view mode.                                | `view_mode` - Name of view mode _or_ view mode object (see above) and `maintain_pos` - whether to go back to current scroll position after rerendering, defaults to `false`. |\n| `.scroll_current`   | Scrolls to the current date                           | No parameters.                                                                                                                                                               |\n| `.update_task`      | Re-renders a specific task bar alone                  | `task_id` - id of task and `new_details` - object containing the task properties to be updated.                                                                              |\n\n## Development Setup\n\nIf you want to contribute enhancements or fixes:\n\n1. Clone this repo.\n2. `cd` into project directory.\n3. Run `pnpm i` to install dependencies.\n4. `pnpm run build` to build files - or `pnpm run build-dev` to build and watch for changes.\n5. Open `index.html` in your browser.\n6. Make your code changes and test them.\n\n<br />\n<br />\n<div align=\"center\" style=\"padding-top: 0.75rem;\">\n\t<a href=\"https://frappe.io\" target=\"_blank\">\n\t\t<picture>\n\t\t\t<source media=\"(prefers-color-scheme: dark)\" srcset=\"https://frappe.io/files/Frappe-white.png\">\n\t\t\t<img src=\"https://frappe.io/files/Frappe-black.png\" alt=\"Frappe Technologies\" height=\"28\"/>\n\t\t</picture>\n\t</a>\n</div>\n",
      "stars_today": 4
    },
    {
      "id": 571702700,
      "name": "bv",
      "full_name": "aaa1115910/bv",
      "description": "ÂìîÂì©ÂìîÂì© ÁöÑÁ¨¨‰∏âÊñπ Android Â∫îÁî®„ÄÇA third-party Android app for Bilibili.",
      "html_url": "https://github.com/aaa1115910/bv",
      "stars": 3643,
      "forks": 455,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2022-11-28T17:50:33Z",
      "updated_at": "2026-01-14T00:21:02Z",
      "pushed_at": "2025-12-08T16:08:45Z",
      "open_issues": 29,
      "owner": {
        "login": "aaa1115910",
        "avatar_url": "https://avatars.githubusercontent.com/u/34527143?v=4"
      },
      "readme": "<div align=\"center\">\n\n<img src=\"app/shared/src/main/res/drawable/ic_banner.webp\" style=\"border-radius: 24px; margin-top: 32px;\"/>\n\n# BV\n\n~~Bug Video~~\n\n[![GitHub Release Release](https://img.shields.io/endpoint?url=https%3A%2F%2Fbadge.versions.bv.aaa1115910.dev%2Fgithub%3Fprerelease%3Dfalse)](https://github.com/aaa1115910/bv/releases?q=prerelease%3Afalse)\n[![GitHub Release Pre-Release](https://img.shields.io/endpoint?url=https%3A%2F%2Fbadge.versions.bv.aaa1115910.dev%2Fgithub%3Fprerelease%3Dtrue)](https://github.com/aaa1115910/bv/releases?q=prerelease%3Atrue)\n\n[![Workflow Release](https://github.com/aaa1115910/bv/actions/workflows/release.yml/badge.svg)](https://github.com/aaa1115910/bv/actions/workflows/release.yml)\n[![Workflow Alpha](https://github.com/aaa1115910/bv/actions/workflows/alpha.yml/badge.svg)](https://github.com/aaa1115910/bv/actions/workflows/alpha.yml)\n[![Android Sdk Require](https://img.shields.io/badge/Android-6.0%2B-informational?logo=android)](https://developer.android.com/jetpack/androidx/versions#version-table)\n[![GitHub](https://img.shields.io/github/license/aaa1115910/bv)](https://github.com/aaa1115910/bv)\n\n**BV Êó†Ê≥ïÂú®‰∏≠ÂõΩÂ§ßÈôÜÂú∞Âå∫ÂÜÖÁöÑÊô∫ËÉΩÁîµËßÜ‰∏ä‰ΩøÁî®ÔºåÂ¶ÇÊúâÁõ∏ÂÖ≥‰ΩøÁî®ÈúÄÊ±ÇËØ∑‰ΩøÁî® [‰∫ëËßÜÂê¨Â∞èÁîµËßÜ](https://app.bilibili.com)**\n\n**Á¶ÅÊ≠¢Âú®‰∏≠ÂõΩÂ¢ÉÂÜÖ‰º†Êí≠„ÄÅÂÆ£‰º†„ÄÅÂàÜÂèë BV**\n\n</div>\n\n---\nBV ~~(Bug Video)~~ ÊòØ‰∏ÄÊ¨æ [ÂìîÂì©ÂìîÂì©](https://www.bilibili.com) ÁöÑÁ¨¨‰∏âÊñπÂ∫îÁî®ÔºåÈÄÇÈÖç `Android ÁßªÂä®Á´Ø`\nÂíå `Android TV`Ôºå‰ΩøÁî® `Jetpack Compose` ÂºÄÂèë\n\n**ÈÉΩÊòØÈöèÂøÉ‰π±ÂÜôÁöÑ‰ª£Á†ÅÔºåËÉΩË∑ëÂ∞±Ë°å„ÄÇ**\n\n## ÁâπËâ≤\n\n- :bug: ‰∏∞ÂØåÂ§öÊ†∑ÁöÑ Bug\n- :children_crossing: Âèç‰∫∫Á±ªËÆæËÆ°\n- :zap: Âç°Âç°Âç°Âç°Âç°\n- :art: ÂºÇÊ†∑ÂÆ°Áæé\n- :disappointed: Â∑®ÈöæÁî®\n\n## ÂÆâË£Ö\n\n### Release\n\n- [Github Release](https://github.com/aaa1115910/bv/releases?q=prerelease%3Afalse)\n\n### Alpha\n\n- [Github Release](https://github.com/aaa1115910/bv/releases?q=prerelease%3Atrue)\n\n## License\n\n[MIT](LICENSE) ¬© aaa1115910",
      "stars_today": 4
    },
    {
      "id": 746689243,
      "name": "kafka-ui",
      "full_name": "kafbat/kafka-ui",
      "description": "Open-Source Web UI for managing Apache Kafka clusters",
      "html_url": "https://github.com/kafbat/kafka-ui",
      "stars": 1914,
      "forks": 236,
      "language": "Java",
      "topics": [
        "apache-kafka",
        "big-data",
        "cluster-management",
        "event-streaming",
        "foss",
        "hacktoberfest",
        "kafka",
        "kafka-brokers",
        "kafka-client",
        "kafka-cluster",
        "kafka-connect",
        "kafka-manager",
        "kafka-producer",
        "kafka-streams",
        "kafka-ui",
        "opensource",
        "streaming-data",
        "streams",
        "web-ui"
      ],
      "created_at": "2024-01-22T13:38:08Z",
      "updated_at": "2026-01-13T20:36:11Z",
      "pushed_at": "2026-01-13T17:07:55Z",
      "open_issues": 260,
      "owner": {
        "login": "kafbat",
        "avatar_url": "https://avatars.githubusercontent.com/u/98461227?v=4"
      },
      "readme": "<div align=\"center\">\n<img src=\"documentation/images/logo_new.png\" alt=\"logo\"/>\n<h3>Kafbat UI</h3>\n\nVersatile, fast and lightweight web UI for managing Apache Kafka¬Æ clusters.\n</div>\n\n<div align=\"center\">\n<a href=\"https://github.com/kafbat/kafka-ui/blob/main/LICENSE\"><img src=\"https://img.shields.io/badge/License-Apache%202.0-blue.svg\" alt=\"License\"/></a>\n<img src=\"documentation/images/free-open-source.svg\" alt=\"price free\"/>\n<a href=\"https://github.com/kafbat/kafka-ui/releases\"><img src=\"https://img.shields.io/github/v/release/kafbat/kafka-ui\" alt=\"latest release version\"/></a>\n<a href=\"https://discord.gg/4DWzD7pGE5\"><img src=\"https://img.shields.io/discord/897805035122077716\" alt=\"discord online number count\"/></a>\n<a href=\"https://github.com/sponsors/kafbat\"><img src=\"https://img.shields.io/github/sponsors/kafbat?style=flat&logo=githubsponsors&logoColor=%23EA4AAA&label=Support%20us\" alt=\"\" /></a>\n</div>\n\n<p align=\"center\">\n    <a href=\"https://ui.docs.kafbat.io/\">Documentation</a> ‚Ä¢ \n    <a href=\"https://ui.docs.kafbat.io/quick-start/demo-run\">Quick Start</a> ‚Ä¢ \n    <a href=\"https://discord.gg/4DWzD7pGE5\">Community</a>\n    <br/>\n    <a href=\"https://aws.amazon.com/marketplace/pp/prodview-6tdqqzzjwmejq\">AWS Marketplace</a>  ‚Ä¢\n    <a href=\"https://www.producthunt.com/products/ui-for-apache-kafka/reviews/new\">ProductHunt</a>\n</p>\n\n<p align=\"center\">\n  <img src=\"https://repobeats.axiom.co/api/embed/88d2bd9887380c7d86e2f986725d9af52ebad7f4.svg\" alt=\"stats\"/>\n</p>\n\n#### Kafbat UI is a free, open-source web UI to monitor and manage Apache Kafka clusters.\n\n[Kafbat UI](https://kafbat.io/) is a simple tool that makes your data flows observable, helps find and troubleshoot issues faster and deliver optimal performance. Its lightweight dashboard makes it easy to track key metrics of your Kafka clusters - Brokers, Topics, Partitions, Production, and Consumption.\n\n<i>\nKafbat UI, developed by <b>Kafbat</b>*, proudly carries forward the legacy of the UI Apache Kafka project.\nOur dedication is reflected in the continuous evolution of the project, ensuring adherence to its foundational vision while adapting to meet modern demands.\nWe extend our gratitude to Provectus for their past support in groundbreaking work, which serves as a cornerstone for our ongoing innovation and dedication.\n\n<b>*</b> - The <b>Kafbat</b> team comprises key contributors from the project's inception, bringing a wealth of experience and insight to this renewed endeavor.\n</i>\n\n# Interface\n\n![Interface](https://raw.githubusercontent.com/kafbat/kafka-ui/images/overview.gif)\n\n# Features\n\n* **Topic Insights** ‚Äì View essential topic details including partition count, replication status, and custom configurations.\n* **Configuration Wizard** ‚Äì Set up and configure your Kafka clusters directly through the UI.\n* **Multi-Cluster Management** ‚Äì Monitor and manage all your Kafka clusters in one unified interface.\n* **Metrics Dashboard** ‚Äì Track key Kafka metrics in real time with a streamlined, lightweight dashboard.\n* **Kafka Brokers Overview** ‚Äì Inspect brokers, including partition assignments and controller status.\n* **Consumer Group Details** ‚Äì Analyze parked offsets per partition, and monitor both combined and partition-specific lag.\n* **Message Browser** ‚Äì Explore messages in JSON, plain text, or Avro encoding formats. Live view is supported, enriched with user-defined CEL message filters.\n* **Dynamic Topic Management** ‚Äì Create and configure new topics with flexible, real-time settings.\n* **Pluggable Authentication** ‚Äì Secure your UI using OAuth 2.0 (GitHub, GitLab, Google), LDAP, or basic authentication.\n* **Cloud IAM Support** ‚Äì Integrate with **GCP IAM**, **Azure IAM**, and **AWS IAM** for cloud-native identity and access management.\n* **Managed Kafka Service Support** ‚Äì Full support for **Azure EventHub**, **Google Cloud Managed Service for Apache Kafka**, and **AWS Managed Streaming for Apache Kafka (MSK)**‚Äîboth server-based and serverless.\n* **Custom SerDe Plugin Support** ‚Äì Use built-in serializers/deserializers like AWS Glue and Smile, or create your own custom plugins.\n* **Role-Based Access Control** ‚Äì [Manage granular UI permissions](https://ui.docs.kafbat.io/configuration/rbac-role-based-access-control) with RBAC.\n* **Data Masking** ‚Äì [Obfuscate sensitive data](https://ui.docs.kafbat.io/configuration/data-masking) in topic messages to enhance privacy and compliance.\n* **MCP Server** - [Model Context Protocol](https://ui.docs.kafbat.io/faq/mcp) Server\n\n\n## Feature overview\n\n<details>\n    <summary>Click here for the feature overview</summary>\n\n# The Interface\nKafbat UI wraps major functions of Apache Kafka with an intuitive user interface.\n\n![Interface](documentation/images/Interface.gif)\n\n## Topics\nKafbat UI makes it easy for you to create topics in your browser with just a few clicks, by pasting your own parameters, and viewing topics in the list.\n\n![Create Topic](documentation/images/Create_topic_kafka-ui.gif)\n\nYou can jump from the connectors view to corresponding topics and from a topic to consumers (back and forth) for more convenient navigation, including connectors and overview topic settings.\n\n![Connector_Topic_Consumer](documentation/images/Connector_Topic_Consumer.gif)\n\n### Messages\nSuppose you want to produce messages for your topic. With Kafbat UI, you can easily send or write data/messages to Kafka topics by specifying parameters and viewing messages in the list.\n\n![Produce Message](documentation/images/Create_message_kafka-ui.gif)\n\n## Schema registry\nThere are three supported types of schemas: Avro¬Æ, JSON Schema, and Protobuf schemas.\n\n![Create Schema Registry](documentation/images/Create_schema.gif)\n\nBefore producing Avro/Protobuf encoded messages, you need to add a schema for the topic in the Schema Registry. All these steps are now easy to do with just a few clicks in a user-friendly interface.\n\n![Avro Schema Topic](documentation/images/Schema_Topic.gif)\n\n</details>\n\n# Getting Started\n\nTo run Kafbat UI, you can use either a pre-built Docker image or build it (or a jar file) yourself.\n\n## Quick start (Demo run)\n\n```bash\ndocker run -it -p 8080:8080 -e DYNAMIC_CONFIG_ENABLED=true ghcr.io/kafbat/kafka-ui\n```\n\nThen access the web UI at [http://localhost:8080](http://localhost:8080)\n\nThis command is sufficient to try things out. When you're done, you can proceed with a [persistent installation](https://ui.docs.kafbat.io/quick-start/persistent-start).\n\n## Persistent installation\n\n```yml\nservices:\n  kafbat-ui:\n    container_name: kafbat-ui\n    image: ghcr.io/kafbat/kafka-ui:latest\n    ports:\n      - 8080:8080\n    environment:\n      DYNAMIC_CONFIG_ENABLED: 'true'\n    volumes:\n      - ~/kui/config.yml:/etc/kafkaui/dynamic_config.yaml\n```\n\nPlease refer to our [configuration](https://ui.docs.kafbat.io/configuration/configuration-file) page to proceed with further app configuration.\n\n## Some useful configuration related links\n\n[Web UI Cluster Configuration Wizard](https://ui.docs.kafbat.io/configuration/configuration-wizard)\n\n[Configuration file explanation](https://ui.docs.kafbat.io/configuration/configuration-file)\n\n[Docker Compose examples](https://ui.docs.kafbat.io/configuration/compose-examples)\n\n[Misc configuration properties](https://ui.docs.kafbat.io/configuration/misc-configuration-properties)\n\n## Helm charts\n\n[Quick start](https://ui.docs.kafbat.io/configuration/helm-charts/quick-start)\n\n## Building from sources\n\n[Quick start](https://ui.docs.kafbat.io/development/building/prerequisites) for building from source\n\n## Liveliness and readiness probes\nThe liveness and readiness endpoint is at `/actuator/health`.<br/>\nThe info endpoint (build info) is located at `/actuator/info`.\n\n# Configuration options\n\nAll environment variables and configuration properties can be found [here](https://ui.docs.kafbat.io/configuration/misc-configuration-properties).\n\n# Contributing\n\nPlease refer to the [contributing guide](https://ui.docs.kafbat.io/development/contributing); we'll guide you from there.\n\n# Support\n\nAs we're fully independent, team members contribute in their free time.\nYour support is crucial for us, if you wish to sponsor us, take a look [here](https://github.com/sponsors/kafbat)\n\n# Powered by\n\n[![JetBrains logo.](https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.svg)](https://jb.gg/OpenSourceSupport)\n",
      "stars_today": 4
    },
    {
      "id": 728212692,
      "name": "ColorBlendr",
      "full_name": "Mahmud0808/ColorBlendr",
      "description": "An Android app for customizing Material You colors on devices with Android 12+. It lets you tweak accent colors, background saturation, and more for a personalized look.",
      "html_url": "https://github.com/Mahmud0808/ColorBlendr",
      "stars": 1837,
      "forks": 36,
      "language": "Kotlin",
      "topics": [
        "accent-color",
        "color-scheme",
        "material",
        "saturation",
        "theme-ui"
      ],
      "created_at": "2023-12-06T13:20:16Z",
      "updated_at": "2026-01-14T00:18:36Z",
      "pushed_at": "2026-01-13T10:00:33Z",
      "open_issues": 10,
      "owner": {
        "login": "Mahmud0808",
        "avatar_url": "https://avatars.githubusercontent.com/u/29881338?v=4"
      },
      "readme": "<div align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/Mahmud0808/ColorBlendr/master/.github/resources/banner.png\" width=\"100%\" alt=\"Banner\">\n\n#\n</div>\n<p align=\"center\">\n  <a href=\"https://github.com/Mahmud0808/ColorBlendr\"><img alt=\"Repo Size\" src=\"https://img.shields.io/github/repo-size/Mahmud0808/ColorBlendr?style=for-the-badge\"></a>\n  <a href=\"https://github.com/Mahmud0808/ColorBlendr/releases\"><img src=\"https://img.shields.io/github/downloads/Mahmud0808/ColorBlendr/total?color=%233DDC84&logo=android&logoColor=%23fff&style=for-the-badge\" alt=\"Downloads\"></a>\n  <a href=\"https://t.me/DrDsProjects\"><img src=\"https://img.shields.io/badge/Telegram-Join-2CA5E0?style=for-the-badge&logo=telegram&logoColor=white\" alt=\"Telegram\"></a>\n</p>\n<div align=\"center\">\n\n# ColorBlendr\n\n### Customize Material You colors of your device.\n</div>\n<p align=\"center\">\nElevate your creativity with effortless material customization. Instantly tweak colors for a personalized touch in just a few taps.\n</p>\n<br>\n<div align=\"center\">\n  <a href=\"https://f-droid.org/en/packages/com.drdisagree.colorblendr/\"><img src=\"https://raw.githubusercontent.com/Mahmud0808/ColorBlendr/master/.github/resources/fdroid-button.png\" width=\"30%\" alt=\"Get it on F-Droid\" /></a>\n  <br>\n  <a href=\"https://apt.izzysoft.de/packages/com.drdisagree.colorblendr/\"><img src=\"https://raw.githubusercontent.com/Mahmud0808/ColorBlendr/master/.github/resources/izzyondroid-button.png\" width=\"30%\" alt=\"Get it on IzzyOnDroid\" /></a>\n  <br>\n  <a href=\"https://www.buymeacoffee.com/DrDisagree\"><img src=\"https://raw.githubusercontent.com/Mahmud0808/ColorBlendr/master/.github/resources/bmc-button.png\" width=\"30%\" alt=\"Buy me a coffee\" /></a>\n  <br><br>\n  <img src=\"https://raw.githubusercontent.com/Mahmud0808/ColorBlendr/master/.github/resources/features.png\" width=\"100%\" alt=\"Features\">\n</div>\n\n## Features üî•\n\n- Accent saturation changer\n\n- Background saturation changer\n\n- Background lightness changer\n\n- Pitch black theme in dark mode\n\n- Manual color overriding\n\n- and many more...\n\n## Requirements üõ†\n\n- Android 12+ ROM with Material You support\n\n- Working **Root**, **Shizuku**, or **Wireless ADB** environment\n\n> [!WARNING]\n> \n> SuperSU root is not supported.\n\n## How to Use üöÄ\n\n- Download and install the apk\n\n- Allow permissions for the app\n\n- Select **Root**, **Shizuku**, or **Wireless ADB** mode\n\n- That's it. Now you are good to go!\n\n## Note üìù\n\n- Root is recommended if you want to have the full experience\n\n- Shizuku and Wireless ADB are also supported but customizations are limited\n\n## FAQ ü§ì\n\n<details>\n  <summary>How does ColorBlendr work without root access?</summary>\n\n- ColorBlendr utilizes adb commands to change Material You colors, allowing users to modify these colors without needing root access.\n</details>\n\n<details>\n  <summary>How does ColorBlendr work with root access?</summary>\n\n- ColorBlendr leverages the [FabricatedOverlay](https://developer.android.com/reference/android/content/om/FabricatedOverlay) API to dynamically change Material You colors at runtime without creating any permanent files.\n</details>\n\n<details>\n  <summary>Why doesn't ColorBlendr work properly on OneUI?</summary>\n\n- OneUI uses its own color palette for system apps, not Material You colors. As a result, ColorBlendr's modifications only affect Google apps and other apps that support Material You, but not OneUI system apps.\n</details>\n\n<details>\n  <summary>Why are some features grayed out or cannot be enabled?</summary>\n\n- These features either require a specific Android version or higher, or you need root access to unlock all features.\n</details>\n\n<details>\n  <summary>How do I properly uninstall ColorBlendr?</summary>\n\n- First, disable the ColorBlendr Service from app settings. Then, uninstall the app and reboot your device.\n</details>\n\n## Translation üåê\n\n- Assist in translating ColorBlendr into your preferred language through [our Crowdin platform](https://crowdin.com/project/ColorBlendr). Your contribution will help make ColorBlendr accessible to a wider audience.\n\n## Credits ü§ù\n\n- [@siavash79](https://github.com/siavash79) for helping me.\n- [@fennifith](https://github.com/fennifith) for color picker.\n- [@MuntashirAkon](https://github.com/MuntashirAkon) for lib adb.\n- And everyone who [contributed](https://github.com/Mahmud0808/ColorBlendr/blob/master/docs/contributors.md) and [translated](https://github.com/Mahmud0808/ColorBlendr/blob/master/docs/translators.md)... :)\n",
      "stars_today": 4
    },
    {
      "id": 196353673,
      "name": "TDengine",
      "full_name": "taosdata/TDengine",
      "description": "High-performance, scalable time-series database designed for Industrial IoT (IIoT) scenarios",
      "html_url": "https://github.com/taosdata/TDengine",
      "stars": 24664,
      "forks": 4990,
      "language": "C",
      "topics": [
        "bigdata",
        "cloud-native",
        "cluster",
        "connected-vehicles",
        "database",
        "distributed",
        "financial-analysis",
        "industrial-iot",
        "iot",
        "metrics",
        "monitoring",
        "scalability",
        "sql",
        "tdengine",
        "time-series",
        "time-series-database",
        "tsdb"
      ],
      "created_at": "2019-07-11T08:33:48Z",
      "updated_at": "2026-01-13T23:14:40Z",
      "pushed_at": "2026-01-14T01:05:03Z",
      "open_issues": 480,
      "owner": {
        "login": "taosdata",
        "avatar_url": "https://avatars.githubusercontent.com/u/48876650?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://tdengine.com\" target=\"_blank\">\n  <img\n    src=\"docs/assets/tdengine.svg\"\n    alt=\"TDengine\"\n    width=\"500\"\n  />\n  </a>\n</p>\n\n[![TDengine Release Build](https://github.com/taosdata/TDengine/actions/workflows/tdengine-release-build.yml/badge.svg)](https://github.com/taosdata/TDengine/actions/workflows/tdengine-release-build.yml)\n[![Coverage Status](https://coveralls.io/repos/github/taosdata/TDengine/badge.svg?branch=3.0)](https://coveralls.io/github/taosdata/TDengine?branch=3.0)\n[![GitHub commit activity](https://img.shields.io/github/commit-activity/m/taosdata/tdengine)](https://github.com/feici02/TDengine/commits/main/)\n<br />\n[![GitHub Release](https://img.shields.io/github/v/release/taosdata/tdengine)](https://github.com/taosdata/TDengine/releases)\n[![GitHub License](https://img.shields.io/github/license/taosdata/tdengine)](https://github.com/taosdata/TDengine/blob/main/LICENSE)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/4201/badge)](https://bestpractices.coreinfrastructure.org/projects/4201)\n<br />\n[![Twitter Follow](https://img.shields.io/twitter/follow/tdenginedb?label=TDengine&style=social)](https://twitter.com/tdenginedb)\n[![YouTube Channel](https://img.shields.io/badge/Subscribe_@tdengine--white?logo=youtube&style=social)](https://www.youtube.com/@tdengine)\n[![Discord Community](https://img.shields.io/badge/Join_Discord--white?logo=discord&style=social)](https://discord.com/invite/VZdSuUg4pS)\n[![LinkedIn](https://img.shields.io/badge/Follow_LinkedIn--white?logo=linkedin&style=social)](https://www.linkedin.com/company/tdengine)\n[![StackOverflow](https://img.shields.io/badge/Ask_StackOverflow--white?logo=stackoverflow&style=social&logoColor=orange)](https://stackoverflow.com/questions/tagged/tdengine)\n[![DeepWiki](https://img.shields.io/badge/Ask%20DeepWiki-white.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAyCAYAAAAnWDnqAAAAAXNSR0IArs4c6QAAA05JREFUaEPtmUtyEzEQhtWTQyQLHNak2AB7ZnyXZMEjXMGeK/AIi+QuHrMnbChYY7MIh8g01fJoopFb0uhhEqqcbWTp06/uv1saEDv4O3n3dV60RfP947Mm9/SQc0ICFQgzfc4CYZoTPAswgSJCCUJUnAAoRHOAUOcATwbmVLWdGoH//PB8mnKqScAhsD0kYP3j/Yt5LPQe2KvcXmGvRHcDnpxfL2zOYJ1mFwrryWTz0advv1Ut4CJgf5uhDuDj5eUcAUoahrdY/56ebRWeraTjMt/00Sh3UDtjgHtQNHwcRGOC98BJEAEymycmYcWwOprTgcB6VZ5JK5TAJ+fXGLBm3FDAmn6oPPjR4rKCAoJCal2eAiQp2x0vxTPB3ALO2CRkwmDy5WohzBDwSEFKRwPbknEggCPB/imwrycgxX2NzoMCHhPkDwqYMr9tRcP5qNrMZHkVnOjRMWwLCcr8ohBVb1OMjxLwGCvjTikrsBOiA6fNyCrm8V1rP93iVPpwaE+gO0SsWmPiXB+jikdf6SizrT5qKasx5j8ABbHpFTx+vFXp9EnYQmLx02h1QTTrl6eDqxLnGjporxl3NL3agEvXdT0WmEost648sQOYAeJS9Q7bfUVoMGnjo4AZdUMQku50McDcMWcBPvr0SzbTAFDfvJqwLzgxwATnCgnp4wDl6Aa+Ax283gghmj+vj7feE2KBBRMW3FzOpLOADl0Isb5587h/U4gGvkt5v60Z1VLG8BhYjbzRwyQZemwAd6cCR5/XFWLYZRIMpX39AR0tjaGGiGzLVyhse5C9RKC6ai42ppWPKiBagOvaYk8lO7DajerabOZP46Lby5wKjw1HCRx7p9sVMOWGzb/vA1hwiWc6jm3MvQDTogQkiqIhJV0nBQBTU+3okKCFDy9WwferkHjtxib7t3xIUQtHxnIwtx4mpg26/HfwVNVDb4oI9RHmx5WGelRVlrtiw43zboCLaxv46AZeB3IlTkwouebTr1y2NjSpHz68WNFjHvupy3q8TFn3Hos2IAk4Ju5dCo8B3wP7VPr/FGaKiG+T+v+TQqIrOqMTL1VdWV1DdmcbO8KXBz6esmYWYKPwDL5b5FA1a0hwapHiom0r/cKaoqr+27/XcrS5UwSMbQAAAABJRU5ErkJggg==)](https://deepwiki.com/taosdata/TDengine)\n\nEnglish | [ÁÆÄ‰Ωì‰∏≠Êñá](README-CN.md) | [TDengine Cloud](https://cloud.tdengine.com) | [Learn more about TSDB](https://tdengine.com/time-series-database/)\n\n# Table of Contents\n\n- [1. Introduction](#1-introduction)\n- [2. Documentation](#2-documentation)\n- [3. Prerequisites](#3-prerequisites)\n  - [3.1 Prerequisites on Linux](#31-prerequisites-on-linux)\n    - [3.1.1 For Ubuntu](#311-for-ubuntu)\n    - [3.1.2 For CentOS](#312-for-centos)\n  - [3.2 Prerequisites on macOS](#32-prerequisites-on-macos)\n  - [3.3 Prerequisites on Windows](#33-prerequisites-on-windows)\n  - [3.4 Clone the repo](#34-clone-the-repo)\n- [4. Building](#4-building)\n  - [4.1 Build on Linux](#41-build-on-linux)\n  - [4.2 Build on macOS](#42-build-on-macos)\n  - [4.3 Build on Windows](#43-build-on-windows)\n- [5. Packaging](#5-packaging)\n- [6. Installation](#6-installation)\n  - [6.1 Install on Linux](#61-install-on-linux)\n  - [6.2 Install on macOS](#62-install-on-macos)\n  - [6.3 Install on Windows](#63-install-on-windows)\n- [7. Running](#7-running)\n  - [7.1 Run TDengine on Linux](#71-run-tdengine-on-linux)\n  - [7.2 Run TDengine on macOS](#72-run-tdengine-on-macos)\n  - [7.3 Run TDengine on Windows](#73-run-tdengine-on-windows)\n- [8. Testing](#8-testing)\n- [9. Releasing](#9-releasing)\n- [10. Workflow](#10-workflow)\n- [11. Coverage](#11-coverage)\n- [12. Contributing](#12-contributing)\n\n# 1. Introduction\n\nTDengine is an open source, high-performance, cloud native and AI powered [time-series database](https://tdengine.com/tsdb/) designed for Internet of Things (IoT), Connected Cars, and Industrial IoT. It enables efficient, real-time data ingestion, processing, and analysis of TB and even PB scale data per day, generated by billions of sensors and data collectors. TDengine differentiates itself from other time-series databases with the following advantages:\n\n- **[High Performance](https://tdengine.com/tdengine/high-performance-time-series-database/)**: TDengine is the only time-series database to solve the high cardinality issue to support billions of data collection points while out performing other time-series databases for data ingestion, querying and data compression.\n\n- **[Simplified Solution](https://tdengine.com/tdengine/simplified-time-series-data-solution/)**: Through built-in caching, stream processing, data subscription and AI agent features, TDengine provides a simplified solution for time-series data processing. It reduces system design complexity and operation costs significantly.\n\n- **[Cloud Native](https://tdengine.com/tdengine/cloud-native-time-series-database/)**: Through native distributed design, sharding and partitioning, separation of compute and storage, RAFT, support for kubernetes deployment and full observability, TDengine is a cloud native Time-Series Database and can be deployed on public, private or hybrid clouds.\n\n- **[AI Powered](https://tdengine.com/tdengine/tdgpt/)**: Through the built in AI agent TDgpt, TDengine can connect to a variety of time series foundation model, large language model, machine learning and traditional algorithms to provide time series data forecasting, anomly detection, imputation and classification.\n\n- **[Ease of Use](https://tdengine.com/tdengine/easy-time-series-data-platform/)**: For administrators, TDengine significantly reduces the effort to deploy and maintain. For developers, it provides a simple interface, simplified solution and seamless integrations for third party tools. For data users, it gives easy data access.\n\n- **[Easy Data Analytics](https://tdengine.com/tdengine/time-series-data-analytics-made-easy/)**: Through super tables, storage and compute separation, data partitioning by time interval, pre-computation and AI agent, TDengine makes it easy to explore, format, and get access to data in a highly efficient way.\n\n- **[Open Source](https://tdengine.com/tdengine/open-source-time-series-database/)**: TDengine‚Äôs core modules, including cluster feature and AI agent, are all available under open source licenses. It has gathered 23.7k stars on GitHub. There is an active developer community, and over 730k running instances worldwide.\n\nFor a full list of TDengine competitive advantages, please [check here](https://tdengine.com/tdengine/). The easiest way to experience TDengine is through [TDengine Cloud](https://cloud.tdengine.com). For the latest TDengine component TDgpt, please refer to [TDgpt README](./tools/tdgpt/README.md) for details.\n\n# 2. Documentation\n\nFor user manual, system design and architecture, please refer to [TDengine Documentation](https://docs.tdengine.com) ([TDengine ÊñáÊ°£](https://docs.taosdata.com))\n\nYou can choose to install TDengine via [container](https://docs.tdengine.com/get-started/deploy-in-docker/), [installation package](https://docs.tdengine.com/get-started/deploy-from-package/), [Kubernetes](https://docs.tdengine.com/operations-and-maintenance/deploy-your-cluster/#kubernetes-deployment) or try [fully managed service](https://cloud.tdengine.com/) without installation. This quick guide is for developers who want to contribute, build, release and test TDengine by themselves.\n\nFor contributing/building/testing TDengine Connectors, please check the following repositories: [JDBC Connector](https://github.com/taosdata/taos-connector-jdbc), [Go Connector](https://github.com/taosdata/driver-go), [Python Connector](https://github.com/taosdata/taos-connector-python), [Node.js Connector](https://github.com/taosdata/taos-connector-node), [C# Connector](https://github.com/taosdata/taos-connector-dotnet), [Rust Connector](https://github.com/taosdata/taos-connector-rust).\n\n# 3. Prerequisites\n\nAt the moment, TDengine server supports running on Linux/MacOS systems. Any application can also choose the RESTful interface provided by taosAdapter to connect the taosd service. TDengine supports X64/ARM64 CPU, and it will support MIPS64, Alpha64, ARM32, RISC-V and other CPU architectures in the future. Right now we don't support build with cross-compiling environment.\n\nStarting from version 3.1.0.0, TDengine supports the Windows system exclusively in its TSDB-Enterprise edition.\n\nIf you want to compile taosAdapter or taosKeeper, you need to install Go 1.23 or above.\n\n## 3.1 Prerequisites on Linux\n\n<details>\n\n<summary>Install required tools on Linux</summary>\n\n### 3.1.1 For Ubuntu\n\nVerified on Ubuntu 18.04, 20.04, 22.04.\n\n```bash\nsudo apt-get update\nsudo apt-get install -y gcc cmake build-essential git libjansson-dev \\\n  libsnappy-dev liblzma-dev zlib1g-dev pkg-config libtool autoconf automake groff\n```\n\n### 3.1.2 For CentOS\n\nVerified on CentOS 8.\n\n```bash\nsudo yum update\nyum install -y epel-release gcc gcc-c++ make cmake git perl dnf-plugins-core autoconf automake libtool groff\nyum config-manager --set-enabled powertools\nyum install -y zlib-static xz-devel snappy-devel jansson-devel pkgconfig libatomic-static libstdc++-static \n```\n\n</details>\n\n## 3.2 Prerequisites on macOS\n\n<details>\n\n<summary>Install required tools on macOS</summary>\n\nPlease install the dependencies with [brew](https://brew.sh/).\n\n```bash\nbrew install argp-standalone gflags pkgconfig\n```\n\n</details>\n\n## 3.3 Prerequisites on Windows\n\nNot available for TDengine TSDB-OSS.\n\n## 3.4 Clone the repo\n\nClone the repository to the target machine:\n\n```bash\ngit clone https://github.com/taosdata/TDengine.git\ncd TDengine\n```\n\n</details>\n\n# 4. Building\n\nTDengine provide a few useful tools such as taosBenchmark (was named taosdemo) and taosdump. They were part of TDengine. By default, TDengine compiling does not include taosTools. You can use `cmake .. -DBUILD_TOOLS=true` to make them be compiled with TDengine.\n\nTDengine requires [GCC](https://gcc.gnu.org/) 9.3.1 or higher and [CMake](https://cmake.org/) 3.18.0 or higher for building.\n\n## 4.1 Build on Linux\n\n<details>\n\n<summary>Detailed steps to build on Linux</summary>\n\nYou can run the bash script `build.sh` to build both TDengine and taosTools including taosBenchmark and taosdump as below:\n\n```bash\n./build.sh\n```\n\nIt equals to execute following commands:\n\n```bash\nmkdir debug && cd debug\ncmake .. -DBUILD_TOOLS=true -DBUILD_CONTRIB=true\nmake\n```\n\nIf you want to compile taosAdapter, you need to add the `-DBUILD_HTTP=false` option.\n\nIf you want to compile taosKeeper, you need to add the `-DBUILD_KEEPER=true` option.\n\nYou can use Jemalloc as memory allocator instead of glibc:\n\n```bash\ncmake .. -DJEMALLOC_ENABLED=ON\n```\n\nTDengine build script can auto-detect the host machine's architecture on x86, x86-64, arm64 platform.\nYou can also specify architecture manually by CPUTYPE option:\n\n```bash\ncmake .. -DCPUTYPE=aarch64 && cmake --build .\n```\n\n</details>\n\n## 4.2 Build on macOS\n\n<details>\n\n<summary>Detailed steps to build on macOS</summary>\n\nPlease install XCode command line tools and cmake. Verified with XCode 11.4+ on Catalina and Big Sur.\n\n```shell\nmkdir debug && cd debug\ncmake .. && cmake --build .\n```\n\nIf you want to compile taosAdapter, you need to add the `-DBUILD_HTTP=false` option.\n\nIf you want to compile taosKeeper, you need to add the `-DBUILD_KEEPER=true` option.\n\n</details>\n\n## 4.3 Build on Windows\n\nNot available for TDengine TSDB-OSS.\n\n# 5. Packaging\n\nThe TDengine TSDB-OSS installer can NOT be created by this repository only, due to some component dependencies. We are still working on this improvement.\n\n# 6. Installation\n\n## 6.1 Install on Linux\n\n<details>\n\n<summary>Detailed steps to install on Linux</summary>\n\nAfter building successfully, TDengine can be installed by:\n\n```bash\nsudo make install\n```\n\nInstalling from source code will also configure service management for TDengine. Users can also choose to [install from packages](https://docs.tdengine.com/get-started/deploy-from-package/) for it.\n\n</details>\n\n## 6.2 Install on macOS\n\n<details>\n\n<summary>Detailed steps to install on macOS</summary>\n\nAfter building successfully, TDengine can be installed by:\n\n```bash\nsudo make install\n```\n\n</details>\n\n## 6.3 Install on Windows\n\nNot available for TDengine TSDB-OSS.\n\n# 7. Running\n\n## 7.1 Run TDengine on Linux\n\n<details>\n\n<summary>Detailed steps to run on Linux</summary>\n\nTo start the service after installation on linux, in a terminal, use:\n\n```bash\nsudo systemctl start taosd\n```\n\nThen users can use the TDengine CLI to connect the TDengine server. In a terminal, use:\n\n```bash\ntaos\n```\n\nIf TDengine CLI connects the server successfully, welcome messages and version info are printed. Otherwise, an error message is shown.\n\nIf you don't want to run TDengine as a service, you can run it in current shell. For example, to quickly start a TDengine server after building, run the command below in terminal: (We take Linux as an example, command on Windows will be `taosd.exe`)\n\n```bash\n./build/bin/taosd -c test/cfg\n```\n\nIn another terminal, use the TDengine CLI to connect the server:\n\n```bash\n./build/bin/taos -c test/cfg\n```\n\nOption `-c test/cfg` specifies the system configuration file directory.\n\n</details>\n\n## 7.2 Run TDengine on macOS\n\n<details>\n\n<summary>Detailed steps to run on macOS</summary>\n\nTo start the service after installation on macOS, double-click the /applications/TDengine to start the program, or in a terminal, use:\n\n```bash\nsudo launchctl start com.tdengine.taosd\n```\n\nThen users can use the TDengine CLI to connect the TDengine server. In a terminal, use:\n\n```bash\ntaos\n```\n\nIf TDengine CLI connects the server successfully, welcome messages and version info are printed. Otherwise, an error message is shown.\n\n</details>\n\n## 7.3 Run TDengine on Windows\n\nNot available for TDengine TSDB-OSS.\n\n# 8. Testing\n\nFor how to run different types of tests on TDengine, please see [Testing TDengine](./tests/README.md).\n\n# 9. Releasing\n\nFor the complete list of TDengine Releases, please see [Releases](https://github.com/taosdata/TDengine/releases).\n\n# 10. Workflow\n\nTDengine build check workflow can be found in this [Github Action](https://github.com/taosdata/TDengine/actions/workflows/taosd-ci-build.yml). More workflows will be available soon.\n\n# 11. Coverage\n\nLatest TDengine test coverage report can be found on [coveralls.io](https://coveralls.io/github/taosdata/TDengine)\n\n<details>\n\n<summary>How to run the coverage report locally?</summary>\nTo create the test coverage report (in HTML format) locally, please run following commands:\n\n```bash\ncd tests\nbash setup-lcov.sh -v 1.16 && ./run_local_coverage.sh -b main -c task \n# on main branch and run cases in longtimeruning_cases.task \n# for more information about options please refer to ./run_local_coverage.sh -h\n```\n\n> **NOTE**:\n> Please note that the -b and -i options will recompile TDengine with the -DCOVER=true option, which may take a amount of time.\n\n</details>\n\n# 12. Contributing\n\nPlease follow the [contribution guidelines](CONTRIBUTING.md) to contribute to TDengine.\n",
      "stars_today": 3
    },
    {
      "id": 1062572,
      "name": "Catch2",
      "full_name": "catchorg/Catch2",
      "description": "A modern, C++-native, test framework for unit-tests, TDD and BDD - using C++14, C++17 and later (C++11 support is in v2.x branch, and C++03 on the Catch1.x branch)",
      "html_url": "https://github.com/catchorg/Catch2",
      "stars": 20105,
      "forks": 3180,
      "language": "C++",
      "topics": [
        "bdd",
        "cpp",
        "cpp14",
        "framework",
        "no-dependencies",
        "tdd",
        "test-framework",
        "testing"
      ],
      "created_at": "2010-11-08T18:22:56Z",
      "updated_at": "2026-01-14T00:37:51Z",
      "pushed_at": "2026-01-13T08:10:07Z",
      "open_issues": 414,
      "owner": {
        "login": "catchorg",
        "avatar_url": "https://avatars.githubusercontent.com/u/33321405?v=4"
      },
      "readme": "<a id=\"top\"></a>\n\n<table width=\"100%\">\n  <tr>\n    <td align=\"center\" width=\"50%\"><img src=\"/data/artwork/catch2-logo-full-with-background.svg\" width=\"100%\"></td>\n    <td align=\"center\" width=\"50%\">\n      <figure>\n        <figcaption>Special thanks to:</figcaption>\n        <a href=\"https://tuple.app/catch2\"><img src=\"/data/sponsors/github_repo_sponsorship.png\" width=\"100%\"></a>\n      </figure>\n    </td>\n  </tr>\n</table>\n\n[![Github Releases](https://img.shields.io/github/release/catchorg/catch2.svg)](https://github.com/catchorg/catch2/releases)\n[![Linux build status](https://github.com/catchorg/Catch2/actions/workflows/linux-simple-builds.yml/badge.svg)](https://github.com/catchorg/Catch2/actions/workflows/linux-simple-builds.yml)\n[![Linux build status](https://github.com/catchorg/Catch2/actions/workflows/linux-other-builds.yml/badge.svg)](https://github.com/catchorg/Catch2/actions/workflows/linux-other-builds.yml)\n[![MacOS build status](https://github.com/catchorg/Catch2/actions/workflows/mac-builds.yml/badge.svg)](https://github.com/catchorg/Catch2/actions/workflows/mac-builds.yml)\n[![Build Status](https://ci.appveyor.com/api/projects/status/github/catchorg/Catch2?svg=true&branch=devel)](https://ci.appveyor.com/project/catchorg/catch2)\n[![Code Coverage](https://codecov.io/gh/catchorg/Catch2/branch/devel/graph/badge.svg)](https://codecov.io/gh/catchorg/Catch2)\n[![Try online](https://img.shields.io/badge/try-online-blue.svg)](https://godbolt.org/z/EdoY15q9G)\n[![Join the chat in Discord: https://discord.gg/4CWS9zD](https://img.shields.io/badge/Discord-Chat!-brightgreen.svg)](https://discord.gg/4CWS9zD)\n\n\n## What is Catch2?\n\nCatch2 is mainly a unit testing framework for C++, but it also\nprovides basic micro-benchmarking features, and simple BDD macros.\n\nCatch2's main advantage is that using it is both simple and natural.\nTest names do not have to be valid identifiers, assertions look like\nnormal C++ boolean expressions, and sections provide a nice and local way\nto share set-up and tear-down code in tests.\n\n**Example unit test**\n```cpp\n#include <catch2/catch_test_macros.hpp>\n\n#include <cstdint>\n\nuint32_t factorial( uint32_t number ) {\n    return number <= 1 ? number : factorial(number-1) * number;\n}\n\nTEST_CASE( \"Factorials are computed\", \"[factorial]\" ) {\n    REQUIRE( factorial( 1) == 1 );\n    REQUIRE( factorial( 2) == 2 );\n    REQUIRE( factorial( 3) == 6 );\n    REQUIRE( factorial(10) == 3'628'800 );\n}\n```\n\n**Example microbenchmark**\n```cpp\n#include <catch2/catch_test_macros.hpp>\n#include <catch2/benchmark/catch_benchmark.hpp>\n\n#include <cstdint>\n\nuint64_t fibonacci(uint64_t number) {\n    return number < 2 ? number : fibonacci(number - 1) + fibonacci(number - 2);\n}\n\nTEST_CASE(\"Benchmark Fibonacci\", \"[!benchmark]\") {\n    REQUIRE(fibonacci(5) == 5);\n\n    REQUIRE(fibonacci(20) == 6'765);\n    BENCHMARK(\"fibonacci 20\") {\n        return fibonacci(20);\n    };\n\n    REQUIRE(fibonacci(25) == 75'025);\n    BENCHMARK(\"fibonacci 25\") {\n        return fibonacci(25);\n    };\n}\n```\n\n_Note that benchmarks are not run by default, so you need to run it explicitly\nwith the `[!benchmark]` tag._\n\n\n## Catch2 v3 has been released!\n\nYou are on the `devel` branch, where the v3 version is being developed.\nv3 brings a bunch of significant changes, the big one being that Catch2\nis no longer a single-header library. Catch2 now behaves as a normal\nlibrary, with multiple headers and separately compiled implementation.\n\nThe documentation is slowly being updated to take these changes into\naccount, but this work is currently still ongoing.\n\nFor migrating from the v2 releases to v3, you should look at [our\ndocumentation](docs/migrate-v2-to-v3.md#top). It provides a simple\nguidelines on getting started, and collects most common migration\nproblems.\n\nFor the previous major version of Catch2 [look into the `v2.x` branch\nhere on GitHub](https://github.com/catchorg/Catch2/tree/v2.x).\n\n\n## How to use it\nThis documentation comprises these three parts:\n\n* [Why do we need yet another C++ Test Framework?](docs/why-catch.md#top)\n* [Tutorial](docs/tutorial.md#top) - getting started\n* [Reference section](docs/Readme.md#top) - all the details\n\n\n## More\n* Issues and bugs can be raised on the [Issue tracker on GitHub](https://github.com/catchorg/Catch2/issues)\n* For discussion or questions please use [our Discord](https://discord.gg/4CWS9zD)\n* See who else is using Catch2 in [Open Source Software](docs/opensource-users.md#top)\nor [commercially](docs/commercial-users.md#top).\n",
      "stars_today": 3
    },
    {
      "id": 44350607,
      "name": "dashboard",
      "full_name": "kubernetes/dashboard",
      "description": "General-purpose web UI for Kubernetes clusters",
      "html_url": "https://github.com/kubernetes/dashboard",
      "stars": 15419,
      "forks": 4290,
      "language": "Go",
      "topics": [],
      "created_at": "2015-10-15T23:09:14Z",
      "updated_at": "2026-01-13T23:23:16Z",
      "pushed_at": "2026-01-05T10:50:31Z",
      "open_issues": 164,
      "owner": {
        "login": "kubernetes",
        "avatar_url": "https://avatars.githubusercontent.com/u/13629408?v=4"
      },
      "readme": "# Kubernetes Dashboard\n\n[![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes/dashboard)](https://goreportcard.com/report/github.com/kubernetes/dashboard)\n[![Coverage Status](https://codecov.io/github/kubernetes/dashboard/coverage.svg?branch=master)](https://codecov.io/github/kubernetes/dashboard?branch=master)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://github.com/kubernetes/dashboard/blob/master/LICENSE)\n\n## IMPORTANT\n\n**This project is now archived and no longer maintained due to lack of active maintainers and contributors.**\n\nThank you to everyone who used, starred, or contributed to this project! Feel free to fork this repository if you want to continue development yourself.\n\nPlease consider using **[Headlamp](https://github.com/kubernetes-sigs/headlamp)** instead. It was recently moved under the sig-ui. From the creators:\n> Headlamp is an easy-to-use and extensible Kubernetes web UI.\n\n## Introduction\n\nKubernetes Dashboard is a general purpose, web-based UI for Kubernetes clusters. It allows users to manage applications running in the cluster and troubleshoot them, as well as manage the cluster itself.\n\nAs of version 7.0.0, we have dropped support for Manifest-based installation. Only Helm-based installation is supported now. Due to multi-container setup and hard dependency on Kong gateway API proxy\nit would not be feasible to easily support Manifest-based installation.\n\nAdditionally, we have changed the versioning scheme and dropped `appVersion` from Helm chart. It is because, with a multi-container setup, every module is now versioned separately. Helm chart version\ncan be considered an app version now.\n\n![Dashboard UI workloads page](docs/images/overview.png)\n\n## Installation\n\nKubernetes Dashboard supports only Helm-based installation currently as it is faster and gives us better control\nover all dependencies required by Dashboard to run. We now use a single-container, DBless [Kong](https://hub.docker.com/r/kong/kong-gateway) installation\nas a gateway that connects all our containers and exposes the UI. Users can then use any ingress controller or proxy\nin front of kong gateway. To find out more about ways to customize your installation check out [helm chart values](charts/kubernetes-dashboard/values.yaml).\n\nIn order to install Kubernetes Dashboard simply run:\n```console\n# Add kubernetes-dashboard repository\nhelm repo add kubernetes-dashboard https://kubernetes.github.io/dashboard/\n# Deploy a Helm Release named \"kubernetes-dashboard\" using the kubernetes-dashboard chart\nhelm upgrade --install kubernetes-dashboard kubernetes-dashboard/kubernetes-dashboard --create-namespace --namespace kubernetes-dashboard\n```\n\nFor more information about our Helm chart visit [ArtifactHub](https://artifacthub.io/packages/helm/k8s-dashboard/kubernetes-dashboard).\n\n## Documentation\n\nDashboard documentation can be found in the [docs](docs/README.md) directory which contains:\n\n* [Common](docs/common/README.md): Entry-level overview.\n* [User Guide](docs/user/README.md): Helpful information for users.\n* [How to access Dashboard](docs/user/accessing-dashboard/README.md) - Everything you need to know to get access to you Kubernetes Dashboard instance after installation.\n* [Access Control](docs/user/access-control/README.md): Find out how to control access to your Kubernetes Dashboard and [create sample user](docs/user/access-control/creating-sample-user.md) that can be used to log in.\n* [Developer Guide](DEVELOPMENT.md): Important information for contributors that would like to test, run and work on Dashboard locally.\n\n## Community, discussion, contribution, and support\n\nLearn how to engage with the Kubernetes community on the [community page](http://kubernetes.io/community/).\n\nYou can reach the maintainers of this project at:\n\n* [**#sig-ui on Kubernetes Slack**](https://kubernetes.slack.com)\n* [**kubernetes-sig-ui mailing list** ](https://groups.google.com/forum/#!forum/kubernetes-sig-ui)\n* [**Issue tracker**](https://github.com/kubernetes/dashboard/issues)\n* [**SIG info**](https://github.com/kubernetes/community/tree/master/sig-ui)\n* [**Roles**](ROLES.md)\n\n### Contribution\n\nLearn how to start contributing to the [Contributing Guideline](CONTRIBUTING.md).\n\n### Code of conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes Code of Conduct](code-of-conduct.md).\n\n## License\n\n[Apache License 2.0](https://github.com/kubernetes/dashboard/blob/master/LICENSE)\n\n----\n_Copyright 2019 [The Kubernetes Dashboard Authors](https://github.com/kubernetes/dashboard/graphs/contributors)_\n",
      "stars_today": 3
    },
    {
      "id": 206424,
      "name": "cassandra",
      "full_name": "apache/cassandra",
      "description": "Apache Cassandra¬Æ",
      "html_url": "https://github.com/apache/cassandra",
      "stars": 9582,
      "forks": 3823,
      "language": "Java",
      "topics": [
        "cassandra",
        "database",
        "java"
      ],
      "created_at": "2009-05-21T02:10:09Z",
      "updated_at": "2026-01-13T16:19:07Z",
      "pushed_at": "2026-01-13T13:14:19Z",
      "open_issues": 578,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "image:https://img.shields.io/badge/License-Apache%202.0-blue.svg[License, link=https://github.com/apache/cassandra/blob/trunk/LICENSE.txt]\nimage:https://ci-cassandra.apache.org/job/Cassandra-trunk/badge/icon[Build Status, link=https://ci-cassandra.apache.org/job/Cassandra-trunk/] ¬†  ¬† \nimage:https://img.shields.io/badge/Official-Downloads-brightgreen[Official Downloads, link=https://cassandra.apache.org/$$_$$/download.html]\nimage:https://img.shields.io/docker/pulls/$$_$$/cassandra[Docker Pulls, link=https://hub.docker.com/r/$$_$$/cassandra] ¬†  ¬† \nimage:https://img.shields.io/badge/Slack-4A154B?style=flat&logo=slack&logoColor=white[Slack, link=https://infra.apache.org/slack.html]\nimage:https://img.shields.io/badge/Bluesky-0285FF?logo=bluesky&logoColor=fff&color=0285FF[Bluesky, link=https://bsky.app/profile/cassandra.apache.org]\nimage:https://img.shields.io/badge/-LinkedIn-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/company/apache-cassandra/[LinkedIn, link=https://www.linkedin.com/company/apache-cassandra/]\nimage:https://img.shields.io/badge/YouTube-FF0000?style=flat&logo=youtube&logoColor=white[Youtube, link=https://www.youtube.com/c/PlanetCassandra]\n\n\nApache Cassandra\n-----------------\n\nApache Cassandra is a highly-scalable partitioned row store. Rows are organized into tables with a required primary key.\n\nhttps://cwiki.apache.org/confluence/display/CASSANDRA2/Partitioners[Partitioning] means that Cassandra can distribute your data across multiple machines in an application-transparent matter. Cassandra will automatically repartition as machines are added and removed from the cluster.\n\nhttps://cwiki.apache.org/confluence/display/CASSANDRA2/DataModel[Row store] means that like relational databases, Cassandra organizes data by rows and columns. The Cassandra Query Language (CQL) is a close relative of SQL.\n\nFor more information, see http://cassandra.apache.org/[the Apache Cassandra web site].\n\nIssues should be reported on https://issues.apache.org/jira/projects/CASSANDRA/issues/[The Cassandra Jira].\n\nRequirements\n------------\n- Java: see supported versions in build.xml (search for property \"java.supported\").\n- Python: for `cqlsh`, see `bin/cqlsh` (search for function \"is_supported_version\").\n\n\nGetting started\n---------------\n\nThis short guide will walk you through getting a basic one node cluster up\nand running, and demonstrate some simple reads and writes. For a more-complete guide, please see the Apache Cassandra website's https://cassandra.apache.org/doc/latest/cassandra/getting_started/index.html[Getting Started Guide].\n\nFirst, we'll unpack our archive:\n\n  $ tar -zxvf apache-cassandra-$VERSION.tar.gz\n  $ cd apache-cassandra-$VERSION\n\nAfter that we start the server. Running the startup script with the -f argument will cause\nCassandra to remain in the foreground and log to standard out; it can be stopped with ctrl-C.\n\n  $ bin/cassandra -f\n\nNow let's try to read and write some data using the Cassandra Query Language:\n\n  $ bin/cqlsh\n\nThe command line client is interactive so if everything worked you should\nbe sitting in front of a prompt:\n\n----\nConnected to Test Cluster at localhost:9160.\n[cqlsh 6.3.0 | Cassandra 5.0-SNAPSHOT | CQL spec 3.4.8 | Native protocol v5]\nUse HELP for help.\ncqlsh>\n----\n\nAs the banner says, you can use 'help;' or '?' to see what CQL has to\noffer, and 'quit;' or 'exit;' when you've had enough fun. But lets try\nsomething slightly more interesting:\n\n----\ncqlsh> CREATE KEYSPACE schema1\n       WITH replication = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 };\ncqlsh> USE schema1;\ncqlsh:Schema1> CREATE TABLE users (\n                 user_id varchar PRIMARY KEY,\n                 first varchar,\n                 last varchar,\n                 age int\n               );\ncqlsh:Schema1> INSERT INTO users (user_id, first, last, age)\n               VALUES ('jsmith', 'John', 'Smith', 42);\ncqlsh:Schema1> SELECT * FROM users;\n user_id | age | first | last\n---------+-----+-------+-------\n  jsmith |  42 |  john | smith\ncqlsh:Schema1>\n----\n\nIf your session looks similar to what's above, congrats, your single node\ncluster is operational!\n\nFor more on what commands are supported by CQL, see\nhttps://cassandra.apache.org/doc/trunk/cassandra/developing/cql/index.html[the CQL reference]. A\nreasonable way to think of it is as, \"SQL minus joins and subqueries, plus collections.\"\n\nWondering where to go from here?\n\n  * Join us in #cassandra on the https://s.apache.org/slack-invite[ASF Slack] and ask questions.\n  * Subscribe to the Users mailing list by sending a mail to\n    user-subscribe@cassandra.apache.org.\n  * Subscribe to the Developer mailing list by sending a mail to\n    dev-subscribe@cassandra.apache.org.\n  * Visit the http://cassandra.apache.org/community/[community section] of the Cassandra website for more information on getting involved.\n  * Visit the http://cassandra.apache.org/doc/latest/development/index.html[development section] of the Cassandra website for more information on how to contribute.\n",
      "stars_today": 3
    },
    {
      "id": 15122806,
      "name": "benchmark",
      "full_name": "google/benchmark",
      "description": "A microbenchmark support library",
      "html_url": "https://github.com/google/benchmark",
      "stars": 9945,
      "forks": 1727,
      "language": "C++",
      "topics": [
        "benchmark"
      ],
      "created_at": "2013-12-12T00:10:48Z",
      "updated_at": "2026-01-13T13:45:58Z",
      "pushed_at": "2026-01-13T10:28:23Z",
      "open_issues": 178,
      "owner": {
        "login": "google",
        "avatar_url": "https://avatars.githubusercontent.com/u/1342004?v=4"
      },
      "readme": "# Benchmark\n\n[![build-and-test](https://github.com/google/benchmark/workflows/build-and-test/badge.svg)](https://github.com/google/benchmark/actions?query=workflow%3Abuild-and-test)\n[![bazel](https://github.com/google/benchmark/actions/workflows/bazel.yml/badge.svg)](https://github.com/google/benchmark/actions/workflows/bazel.yml)\n[![test-bindings](https://github.com/google/benchmark/workflows/test-bindings/badge.svg)](https://github.com/google/benchmark/actions?query=workflow%3Atest-bindings)\n[![Coverage Status](https://coveralls.io/repos/google/benchmark/badge.svg)](https://coveralls.io/r/google/benchmark)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/google/benchmark/badge)](https://securityscorecards.dev/viewer/?uri=github.com/google/benchmark)\n\n[![Discord](https://discordapp.com/api/guilds/1125694995928719494/widget.png?style=shield)](https://discord.gg/cz7UX7wKC2)\n\nA library to benchmark code snippets, similar to unit tests. Example:\n\n```c++\n#include <benchmark/benchmark.h>\n\nstatic void BM_SomeFunction(benchmark::State& state) {\n  // Perform setup here\n  for (auto _ : state) {\n    // This code gets timed\n    SomeFunction();\n  }\n}\n// Register the function as a benchmark\nBENCHMARK(BM_SomeFunction);\n// Run the benchmark\nBENCHMARK_MAIN();\n```\n\n## Getting Started\n\nTo get started, see [Requirements](#requirements) and\n[Installation](#installation). See [Usage](#usage) for a full example and the\n[User Guide](docs/user_guide.md) for a more comprehensive feature overview.\n\nIt may also help to read the [Google Test documentation](https://github.com/google/googletest/blob/main/docs/primer.md)\nas some of the structural aspects of the APIs are similar.\n\n## Resources\n\n[Discussion group](https://groups.google.com/d/forum/benchmark-discuss)\n\nIRC channels:\n* [libera](https://libera.chat) #benchmark\n\n[Additional Tooling Documentation](docs/tools.md)\n\n[Assembly Testing Documentation](docs/AssemblyTests.md)\n\n[Building and installing Python bindings](docs/python_bindings.md)\n\n## Requirements\n\nThe library can be used with C++11. However, it requires C++17 to build,\nincluding compiler and standard library support.\n\n_See [dependencies.md](docs/dependencies.md) for more details regarding supported\ncompilers and standards._\n\nIf you have need for a particular compiler to be supported, patches are very welcome.\n\nSee [Platform-Specific Build Instructions](docs/platform_specific_build_instructions.md).\n\n## Installation\n\nThis describes the installation process using cmake. As pre-requisites, you'll\nneed git and cmake installed.\n\n_See [dependencies.md](docs/dependencies.md) for more details regarding supported\nversions of build tools._\n\n```bash\n# Check out the library.\n$ git clone https://github.com/google/benchmark.git\n# Go to the library root directory\n$ cd benchmark\n# Make a build directory to place the build output.\n$ cmake -E make_directory \"build\"\n# Generate build system files with cmake, and download any dependencies.\n$ cmake -E chdir \"build\" cmake -DBENCHMARK_DOWNLOAD_DEPENDENCIES=on -DCMAKE_BUILD_TYPE=Release ../\n# or, starting with CMake 3.13, use a simpler form:\n# cmake -DBENCHMARK_DOWNLOAD_DEPENDENCIES=on -DCMAKE_BUILD_TYPE=Release -S . -B \"build\"\n# Build the library.\n$ cmake --build \"build\" --config Release\n```\nThis builds the `benchmark` and `benchmark_main` libraries and tests.\nOn a unix system, the build directory should now look something like this:\n\n```\n/benchmark\n  /build\n    /src\n      /libbenchmark.a\n      /libbenchmark_main.a\n    /test\n      ...\n```\n\nNext, you can run the tests to check the build.\n\n```bash\n$ cmake -E chdir \"build\" ctest --build-config Release\n```\n\nIf you want to install the library globally, also run:\n\n```\nsudo cmake --build \"build\" --config Release --target install\n```\n\nNote that Google Benchmark requires Google Test to build and run the tests. This\ndependency can be provided two ways:\n\n* Checkout the Google Test sources into `benchmark/googletest`.\n* Otherwise, if `-DBENCHMARK_DOWNLOAD_DEPENDENCIES=ON` is specified during\n  configuration as above, the library will automatically download and build\n  any required dependencies.\n\nIf you do not wish to build and run the tests, add `-DBENCHMARK_ENABLE_GTEST_TESTS=OFF`\nto `CMAKE_ARGS`.\n\n### Debug vs Release\n\nBy default, benchmark builds as a debug library. You will see a warning in the\noutput when this is the case. To build it as a release library instead, add\n`-DCMAKE_BUILD_TYPE=Release` when generating the build system files, as shown\nabove. The use of `--config Release` in build commands is needed to properly\nsupport multi-configuration tools (like Visual Studio for example) and can be\nskipped for other build systems (like Makefile).\n\nTo enable link-time optimisation, also add `-DBENCHMARK_ENABLE_LTO=true` when\ngenerating the build system files.\n\nIf you are using gcc, you might need to set `GCC_AR` and `GCC_RANLIB` cmake\ncache variables, if autodetection fails.\n\nIf you are using clang, you may need to set `LLVMAR_EXECUTABLE`,\n`LLVMNM_EXECUTABLE` and `LLVMRANLIB_EXECUTABLE` cmake cache variables.\n\nTo enable sanitizer checks (eg., `asan` and `tsan`), add:\n```\n -DCMAKE_C_FLAGS=\"-g -O2 -fno-omit-frame-pointer -fsanitize=address -fsanitize=thread -fno-sanitize-recover=all\"\n -DCMAKE_CXX_FLAGS=\"-g -O2 -fno-omit-frame-pointer -fsanitize=address -fsanitize=thread -fno-sanitize-recover=all \"  \n```\n\n### Stable and Experimental Library Versions\n\nThe main branch contains the latest stable version of the benchmarking library;\nthe API of which can be considered largely stable, with source breaking changes\nbeing made only upon the release of a new major version.\n\nNewer, experimental, features are implemented and tested on the\n[`v2` branch](https://github.com/google/benchmark/tree/v2). Users who wish\nto use, test, and provide feedback on the new features are encouraged to try\nthis branch. However, this branch provides no stability guarantees and reserves\nthe right to change and break the API at any time.\n\n## Usage\n\n### Basic usage\n\nDefine a function that executes the code to measure, register it as a benchmark\nfunction using the `BENCHMARK` macro, and ensure an appropriate `main` function\nis available:\n\n```c++\n#include <benchmark/benchmark.h>\n\nstatic void BM_StringCreation(benchmark::State& state) {\n  for (auto _ : state)\n    std::string empty_string;\n}\n// Register the function as a benchmark\nBENCHMARK(BM_StringCreation);\n\n// Define another benchmark\nstatic void BM_StringCopy(benchmark::State& state) {\n  std::string x = \"hello\";\n  for (auto _ : state)\n    std::string copy(x);\n}\nBENCHMARK(BM_StringCopy);\n\nBENCHMARK_MAIN();\n```\n\nTo run the benchmark, compile and link against the `benchmark` library\n(libbenchmark.a/.so). If you followed the build steps above, this library will \nbe under the build directory you created.\n\n```bash\n# Example on linux after running the build steps above. Assumes the\n# `benchmark` and `build` directories are under the current directory.\n$ g++ mybenchmark.cc -std=c++11 -isystem benchmark/include \\\n  -Lbenchmark/build/src -lbenchmark -lpthread -o mybenchmark\n```\n\nAlternatively, link against the `benchmark_main` library and remove\n`BENCHMARK_MAIN();` above to get the same behavior.\n\nThe compiled executable will run all benchmarks by default. Pass the `--help`\nflag for option information or see the [User Guide](docs/user_guide.md).\n\n### Usage with CMake\n\nIf using CMake, it is recommended to link against the project-provided\n`benchmark::benchmark` and `benchmark::benchmark_main` targets using\n`target_link_libraries`.\nIt is possible to use ```find_package``` to import an installed version of the\nlibrary.\n```cmake\nfind_package(benchmark REQUIRED)\n```\nAlternatively, ```add_subdirectory``` will incorporate the library directly in\nto one's CMake project.\n```cmake\nadd_subdirectory(benchmark)\n```\nEither way, link to the library as follows.\n```cmake\ntarget_link_libraries(MyTarget benchmark::benchmark)\n```\n",
      "stars_today": 3
    },
    {
      "id": 9120526,
      "name": "pgx",
      "full_name": "jackc/pgx",
      "description": "PostgreSQL driver and toolkit for Go",
      "html_url": "https://github.com/jackc/pgx",
      "stars": 13159,
      "forks": 982,
      "language": "Go",
      "topics": [],
      "created_at": "2013-03-30T19:06:26Z",
      "updated_at": "2026-01-13T18:44:13Z",
      "pushed_at": "2026-01-10T11:25:48Z",
      "open_issues": 254,
      "owner": {
        "login": "jackc",
        "avatar_url": "https://avatars.githubusercontent.com/u/94130?v=4"
      },
      "readme": "[![Go Reference](https://pkg.go.dev/badge/github.com/jackc/pgx/v5.svg)](https://pkg.go.dev/github.com/jackc/pgx/v5)\n[![Build Status](https://github.com/jackc/pgx/actions/workflows/ci.yml/badge.svg)](https://github.com/jackc/pgx/actions/workflows/ci.yml)\n\n# pgx - PostgreSQL Driver and Toolkit\n\npgx is a pure Go driver and toolkit for PostgreSQL.\n\nThe pgx driver is a low-level, high performance interface that exposes PostgreSQL-specific features such as `LISTEN` /\n`NOTIFY` and `COPY`. It also includes an adapter for the standard `database/sql` interface.\n\nThe toolkit component is a related set of packages that implement PostgreSQL functionality such as parsing the wire protocol\nand type mapping between PostgreSQL and Go. These underlying packages can be used to implement alternative drivers,\nproxies, load balancers, logical replication clients, etc.\n\n## Example Usage\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\n\t\"github.com/jackc/pgx/v5\"\n)\n\nfunc main() {\n\t// urlExample := \"postgres://username:password@localhost:5432/database_name\"\n\tconn, err := pgx.Connect(context.Background(), os.Getenv(\"DATABASE_URL\"))\n\tif err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Unable to connect to database: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer conn.Close(context.Background())\n\n\tvar name string\n\tvar weight int64\n\terr = conn.QueryRow(context.Background(), \"select name, weight from widgets where id=$1\", 42).Scan(&name, &weight)\n\tif err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"QueryRow failed: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\tfmt.Println(name, weight)\n}\n```\n\nSee the [getting started guide](https://github.com/jackc/pgx/wiki/Getting-started-with-pgx) for more information.\n\n## Features\n\n* Support for approximately 70 different PostgreSQL types\n* Automatic statement preparation and caching\n* Batch queries\n* Single-round trip query mode\n* Full TLS connection control\n* Binary format support for custom types (allows for much quicker encoding/decoding)\n* `COPY` protocol support for faster bulk data loads\n* Tracing and logging support\n* Connection pool with after-connect hook for arbitrary connection setup\n* `LISTEN` / `NOTIFY`\n* Conversion of PostgreSQL arrays to Go slice mappings for integers, floats, and strings\n* `hstore` support\n* `json` and `jsonb` support\n* Maps `inet` and `cidr` PostgreSQL types to `netip.Addr` and `netip.Prefix`\n* Large object support\n* NULL mapping to pointer to pointer\n* Supports `database/sql.Scanner` and `database/sql/driver.Valuer` interfaces for custom types\n* Notice response handling\n* Simulated nested transactions with savepoints\n\n## Choosing Between the pgx and database/sql Interfaces\n\nThe pgx interface is faster. Many PostgreSQL specific features such as `LISTEN` / `NOTIFY` and `COPY` are not available\nthrough the `database/sql` interface.\n\nThe pgx interface is recommended when:\n\n1. The application only targets PostgreSQL.\n2. No other libraries that require `database/sql` are in use.\n\nIt is also possible to use the `database/sql` interface and convert a connection to the lower-level pgx interface as needed.\n\n## Testing\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md) for setup instructions.\n\n## Architecture\n\nSee the presentation at Golang Estonia, [PGX Top to Bottom](https://www.youtube.com/watch?v=sXMSWhcHCf8) for a description of pgx architecture.\n\n## Supported Go and PostgreSQL Versions\n\npgx supports the same versions of Go and PostgreSQL that are supported by their respective teams. For [Go](https://golang.org/doc/devel/release.html#policy) that is the two most recent major releases and for [PostgreSQL](https://www.postgresql.org/support/versioning/) the major releases in the last 5 years. This means pgx supports Go 1.24 and higher and PostgreSQL 13 and higher. pgx also is tested against the latest version of [CockroachDB](https://www.cockroachlabs.com/product/).\n\n## Version Policy\n\npgx follows semantic versioning for the documented public API on stable releases. `v5` is the latest stable major version.\n\n## PGX Family Libraries\n\n### [github.com/jackc/pglogrepl](https://github.com/jackc/pglogrepl)\n\npglogrepl provides functionality to act as a client for PostgreSQL logical replication.\n\n### [github.com/jackc/pgmock](https://github.com/jackc/pgmock)\n\npgmock offers the ability to create a server that mocks the PostgreSQL wire protocol. This is used internally to test pgx by purposely inducing unusual errors. pgproto3 and pgmock together provide most of the foundational tooling required to implement a PostgreSQL proxy or MitM (such as for a custom connection pooler).\n\n### [github.com/jackc/tern](https://github.com/jackc/tern)\n\ntern is a stand-alone SQL migration system.\n\n### [github.com/jackc/pgerrcode](https://github.com/jackc/pgerrcode)\n\npgerrcode contains constants for the PostgreSQL error codes.\n\n## Adapters for 3rd Party Types\n\n* [github.com/jackc/pgx-gofrs-uuid](https://github.com/jackc/pgx-gofrs-uuid)\n* [github.com/jackc/pgx-shopspring-decimal](https://github.com/jackc/pgx-shopspring-decimal)\n* [github.com/twpayne/pgx-geos](https://github.com/twpayne/pgx-geos) ([PostGIS](https://postgis.net/) and [GEOS](https://libgeos.org/) via [go-geos](https://github.com/twpayne/go-geos))\n* [github.com/vgarvardt/pgx-google-uuid](https://github.com/vgarvardt/pgx-google-uuid)\n\n\n## Adapters for 3rd Party Tracers\n\n* [github.com/jackhopner/pgx-xray-tracer](https://github.com/jackhopner/pgx-xray-tracer)\n* [github.com/exaring/otelpgx](https://github.com/exaring/otelpgx)\n\n## Adapters for 3rd Party Loggers\n\nThese adapters can be used with the tracelog package.\n\n* [github.com/jackc/pgx-go-kit-log](https://github.com/jackc/pgx-go-kit-log)\n* [github.com/jackc/pgx-log15](https://github.com/jackc/pgx-log15)\n* [github.com/jackc/pgx-logrus](https://github.com/jackc/pgx-logrus)\n* [github.com/jackc/pgx-zap](https://github.com/jackc/pgx-zap)\n* [github.com/jackc/pgx-zerolog](https://github.com/jackc/pgx-zerolog)\n* [github.com/mcosta74/pgx-slog](https://github.com/mcosta74/pgx-slog)\n* [github.com/kataras/pgx-golog](https://github.com/kataras/pgx-golog)\n\n## 3rd Party Libraries with PGX Support\n\n### [github.com/pashagolub/pgxmock](https://github.com/pashagolub/pgxmock)\n\npgxmock is a mock library implementing pgx interfaces.\npgxmock has one and only purpose - to simulate pgx behavior in tests, without needing a real database connection.\n\n### [github.com/georgysavva/scany](https://github.com/georgysavva/scany)\n\nLibrary for scanning data from a database into Go structs and more.\n\n### [github.com/vingarcia/ksql](https://github.com/vingarcia/ksql)\n\nA carefully designed SQL client for making using SQL easier,\nmore productive, and less error-prone on Golang.\n\n### [github.com/otan/gopgkrb5](https://github.com/otan/gopgkrb5)\n\nAdds GSSAPI / Kerberos authentication support.\n\n### [github.com/wcamarao/pmx](https://github.com/wcamarao/pmx)\n\nExplicit data mapping and scanning library for Go structs and slices.\n\n### [github.com/stephenafamo/scan](https://github.com/stephenafamo/scan)\n\nType safe and flexible package for scanning database data into Go types.\nSupports, structs, maps, slices and custom mapping functions.\n\n### [github.com/z0ne-dev/mgx](https://github.com/z0ne-dev/mgx)\n\nCode first migration library for native pgx (no database/sql abstraction).\n\n### [github.com/amirsalarsafaei/sqlc-pgx-monitoring](https://github.com/amirsalarsafaei/sqlc-pgx-monitoring)\n\nA database monitoring/metrics library for pgx and sqlc. Trace, log and monitor your sqlc query performance using OpenTelemetry.\n\n### [https://github.com/nikolayk812/pgx-outbox](https://github.com/nikolayk812/pgx-outbox)\n\nSimple Golang implementation for transactional outbox pattern for PostgreSQL using jackc/pgx driver.\n\n### [https://github.com/Arlandaren/pgxWrappy](https://github.com/Arlandaren/pgxWrappy)\n\nSimplifies working with the pgx library, providing convenient scanning of nested structures.\n\n### [https://github.com/KoNekoD/pgx-colon-query-rewriter](https://github.com/KoNekoD/pgx-colon-query-rewriter)\n\nImplementation of the pgx query rewriter to use ':' instead of '@' in named query parameters.\n",
      "stars_today": 3
    },
    {
      "id": 192805335,
      "name": "mimalloc",
      "full_name": "microsoft/mimalloc",
      "description": "mimalloc is a compact general purpose allocator with excellent performance.",
      "html_url": "https://github.com/microsoft/mimalloc",
      "stars": 12353,
      "forks": 1044,
      "language": "C",
      "topics": [],
      "created_at": "2019-06-19T21:14:44Z",
      "updated_at": "2026-01-13T22:31:27Z",
      "pushed_at": "2026-01-12T21:52:30Z",
      "open_issues": 413,
      "owner": {
        "login": "microsoft",
        "avatar_url": "https://avatars.githubusercontent.com/u/6154722?v=4"
      },
      "readme": "\n<img align=\"left\" width=\"100\" height=\"100\" src=\"doc/mimalloc-logo.png\"/>\n\n[<img align=\"right\" src=\"https://dev.azure.com/Daan0324/mimalloc/_apis/build/status/microsoft.mimalloc?branchName=dev3\"/>](https://dev.azure.com/Daan0324/mimalloc/_build?definitionId=1&_a=summary)\n\n# mimalloc\n\n&nbsp;\n\nmimalloc (pronounced \"me-malloc\")\nis a general purpose allocator with excellent [performance](#performance) characteristics.\nInitially developed by Daan Leijen for the runtime systems of the\n[Koka](https://koka-lang.github.io) and [Lean](https://github.com/leanprover/lean) languages.\n\nLatest release   : `v3.2.6` (2026-01-08) release candidate 1, please report any issues.  \nLatest v2 release: `v2.2.6` (2026-01-08).  \nLatest v1 release: `v1.9.6` (2026-01-08).\n\nmimalloc is a drop-in replacement for `malloc` and can be used in other programs\nwithout code changes, for example, on dynamically linked ELF-based systems (Linux, BSD, etc.) you can use it as:\n```\n> LD_PRELOAD=/usr/lib/libmimalloc.so  myprogram\n```\nIt also includes a way to dynamically override the default allocator in [Windows](#override_on_windows). \nNotable aspects of the design include:\n\n- __small and consistent__: the library is about 10k LOC using simple and\n  consistent data structures. This makes it very suitable\n  to integrate and adapt in other projects. For runtime systems it\n  provides hooks for a monotonic _heartbeat_ and deferred freeing (for\n  bounded worst-case times with reference counting).\n  Partly due to its simplicity, mimalloc has been ported to many systems (Windows, macOS,\n  Linux, WASM, various BSD's, Haiku, MUSL, etc) and has excellent support for dynamic overriding.\n  At the same time, it is an industrial strength allocator that runs (very) large scale\n  distributed services on thousands of machines with excellent worst case latencies.\n- __free list sharding__: instead of one big free list (per size class) we have\n  many smaller lists per \"mimalloc page\" which reduces fragmentation and\n  increases locality --\n  things that are allocated close in time get allocated close in memory.\n  (A mimalloc page contains blocks of one size class and is usually 64KiB on a 64-bit system).\n- __free list multi-sharding__: the big idea! Not only do we shard the free list\n  per mimalloc page, but for each page we have multiple free lists. In particular, there\n  is one list for thread-local `free` operations, and another one for concurrent `free`\n  operations. Free-ing from another thread can now be a single CAS without needing\n  sophisticated coordination between threads. Since there will be\n  thousands of separate free lists, contention is naturally distributed over the heap,\n  and the chance of contending on a single location will be low -- this is quite\n  similar to randomized algorithms like skip lists where adding\n  a random oracle removes the need for a more complex algorithm.\n- __eager page purging__: when a \"page\" becomes empty (with increased chance\n  due to free list sharding) the memory is marked to the OS as unused (reset or decommitted)\n  reducing (real) memory pressure and fragmentation, especially in long running\n  programs.\n- __secure__: _mimalloc_ can be built in secure mode, adding guard pages,\n  randomized allocation, encrypted free lists, etc. to protect against various\n  heap vulnerabilities. The performance penalty is usually around 10% on average\n  over our benchmarks.\n- __first-class heaps__: efficiently create and use multiple heaps to allocate across different regions.\n  A heap can be destroyed at once instead of deallocating each object separately.\n  New: v3 has true first-class heaps where one can allocate in a heap from any thread.   \n- __bounded__: it does not suffer from _blowup_ \\[1\\], has bounded worst-case allocation\n  times (_wcat_) (upto OS primitives), bounded space overhead (~0.2% meta-data, with low\n  internal fragmentation), and has no internal points of contention using only atomic operations.\n- __fast__: In our benchmarks (see [below](#performance)),\n  _mimalloc_ outperforms other leading allocators (_jemalloc_, _tcmalloc_, _Hoard_, etc),\n  and often uses less memory. A nice property is that it does consistently well over a wide range\n  of benchmarks. There is also good huge OS page support for larger server programs.\n\nThe [documentation](https://microsoft.github.io/mimalloc) gives a full overview of the API.\nYou can read more on the design of _mimalloc_ in the [technical report](https://www.microsoft.com/en-us/research/publication/mimalloc-free-list-sharding-in-action) which also has detailed benchmark results.\n\nEnjoy!\n\n### Branches\n\n* `main`: latest stable release (still based on `dev2`).\n* `dev`:  development branch for mimalloc v1. Use this branch for submitting PR's.\n* `dev2`: development branch for mimalloc v2. This branch is downstream of `dev` \n          (and is essentially equal to `dev` except for `src/segment.c`). Uses larger sliced segments to manage\n          mimalloc pages that can reduce fragmentation.\n* `dev3`: development branch for mimalloc v3 rc1. This branch is downstream of `dev`. This version \n          simplifies the lock-free ownership of previous versions, and improves sharing of memory between \n          threads. On certain large workloads this version may use (much) less memory.\n          Also support true first-class heaps and more efficient heap-walking.\n\n### Releases\n\n* 2026-01-08, `v1.9.6`, `v2.2.6`, `v3.2.6` (rc1) : Important bug fixes. Many improvements to v3 including \n  true first-class heaps where one can allocate in heap from any thread, and track statistics per heap as well.\n  Added `MIMALLOC_ALLOW_THP` option. This is by default enabled except on Android. When THP is detected on v3,\n  mimalloc will set the `MIMALLOC_MINIMAL_PURGE_SIZE` to 2MiB to avoid breaking up potential THP huge pages.\n  v3 uses faster TLS access on Windows, and has improved performance for `mi_calloc` and aligned allocations.\n  Fixed rare race condition on older v3, fixed potential buffer overflow in debug statistics, add API for returning\n  allocated sizes on allocation and free.\n* 2025-06-13, `v3.1.5`: Bug fix release where memory was not always correctly committed (issue #1098).\n* 2025-06-09, `v1.9.4`, `v2.2.4`, `v3.1.4` (beta) : Some important bug fixes, including a case where OS memory\n  was not always fully released. Improved v3 performance, build on XBox, fix build on Android, support interpose \n  for older macOS versions, use MADV_FREE_REUSABLE on macOS, always check commit success, better support for Windows \n  fixed TLS offset, etc.\n* 2025-03-28, `v1.9.3`, `v2.2.3`, `v3.0.3` (beta) : Various small bug and build fixes, including:\n  fix arm32 pre v7 builds, fix mingw build, get runtime statistics, improve statistic commit counts, \n  fix execution on non BMI1 x64 systems. \n* 2025-03-06, `v1.9.2`, `v2.2.2`, `v3.0.2-beta`: Various small bug and build fixes. \n  Add `mi_options_print`, `mi_arenas_print`, and the experimental `mi_stat_get` and `mi_stat_get_json`. \n  Add `mi_thread_set_in_threadpool` and `mi_heap_set_numa_affinity` (v3 only). Add vcpkg portfile. \n  Upgrade mimalloc-redirect to v1.3.2. `MI_OPT_ARCH` is off by default now but still assumes armv8.1-a on arm64\n  for fast atomic operations. Add QNX support.\n* 2025-01-03, `v1.8.9`, `v2.1.9`, `v3.0.1-alpha`: Interim release. Support Windows arm64. New [guarded](#guarded) build that can place OS \n  guard pages behind objects to catch buffer overflows as they occur. \n  Many small fixes: build on Windows arm64, cygwin, riscV, and dragonfly; fix Windows static library initialization to account for\n  thread local destructors (in Rust/C++); macOS tag change; macOS TLS slot fix; improve stats; \n  consistent `mimalloc.dll` on Windows (instead of `mimalloc-override.dll`); fix mimalloc-redirect on Win11 H2; \n  add 0-byte to canary; upstream CPython fixes; reduce .bss size; allow fixed TLS slot on Windows for improved performance.\n* 2024-05-21, `v1.8.7`, `v2.1.7`: Fix build issues on less common platforms. Started upstreaming patches\n  from the CPython [integration](https://github.com/python/cpython/issues/113141#issuecomment-2119255217). Upstream `vcpkg` patches.\n\n* [Older release notes](#older-release-notes)\n\nSpecial thanks to:\n\n* Sergiy Kuryata for his contributions on reducing memory commit -- especially on Windows with the Windows thread pool (now implemented in v3).\n* [David Carlier](https://devnexen.blogspot.com/) (@devnexen) for his _many_ contributions, and making\n  mimalloc work better on many less common operating systems, like Haiku, Dragonfly, etc.\n* Mary Feofanova (@mary3000), Evgeniy Moiseenko, and Manuel P√∂ter (@mpoeter) for making mimalloc TSAN checkable, and finding\n  memory model bugs using the [genMC] model checker.\n* Weipeng Liu (@pongba), Zhuowei Li, Junhua Wang, and Jakub Szymanski, for their early support of mimalloc and deployment\n  at large scale services, leading to many improvements in the mimalloc algorithms for large workloads.\n* Jason Gibson (@jasongibson) for exhaustive testing on large scale workloads and server environments, and finding complex bugs\n  in (early versions of) `mimalloc`.\n* Manuel P√∂ter (@mpoeter) and Sam Gross(@colesbury) for finding an ABA concurrency issue in abandoned segment reclamation. Sam also created the [no GIL](https://github.com/colesbury/nogil) Python fork which\n  uses mimalloc internally.\n\n\n[genMC]: https://plv.mpi-sws.org/genmc/\n\n### Usage\n\nmimalloc is used in various large scale low-latency services and programs, for example:\n\n<a href=\"https://www.bing.com\"><img height=\"50\" align=\"left\" src=\"https://upload.wikimedia.org/wikipedia/commons/e/e9/Bing_logo.svg\"></a>\n<a href=\"https://azure.microsoft.com/\"><img height=\"50\" align=\"left\" src=\"https://upload.wikimedia.org/wikipedia/commons/a/a8/Microsoft_Azure_Logo.svg\"></a>\n<a href=\"https://deathstrandingpc.505games.com\"><img height=\"100\" src=\"doc/ds-logo.png\"></a>\n<a href=\"https://docs.unrealengine.com/4.26/en-US/WhatsNew/Builds/ReleaseNotes/4_25/\"><img height=\"100\" src=\"doc/unreal-logo.svg\"></a>\n<a href=\"https://cab.spbu.ru/software/spades/\"><img height=\"100\" src=\"doc/spades-logo.png\"></a>\n\n\n# Building\n\n## Windows\n\nOpen `ide/vs2022/mimalloc.sln` in Visual Studio 2022 and build.\nThe `mimalloc-lib` project builds a static library (in `out/msvc-x64`), while the\n`mimalloc-override-dll` project builds a DLL for overriding malloc\nin the entire program.\n\n## Linux, macOS, BSD, etc.\n\nWe use [`cmake`](https://cmake.org) as the build system:\n\n```\n> mkdir -p out/release\n> cd out/release\n> cmake ../..\n> make\n```\nThis builds the library as a shared (dynamic)\nlibrary (`.so` or `.dylib`), a static library (`.a`), and\nas a single object file (`.o`).\n\n`> sudo make install` (install the library and header files in `/usr/local/lib`  and `/usr/local/include`)\n\nYou can build the debug version which does many internal checks and\nmaintains detailed statistics as:\n\n```\n> mkdir -p out/debug\n> cd out/debug\n> cmake -DCMAKE_BUILD_TYPE=Debug ../..\n> make\n```\n\nThis will name the shared library as `libmimalloc-debug.so`.\n\nFinally, you can build a _secure_ version that uses guard pages, encrypted free lists, etc., as:\n\n```\n> mkdir -p out/secure\n> cd out/secure\n> cmake -DMI_SECURE=ON ../..\n> make\n```\n\nThis will name the shared library as `libmimalloc-secure.so`.\nUse `cmake ../.. -LH` to see all the available build options.\n\nThe examples use the default compiler. If you like to use another, use:\n\n```\n> CC=clang CXX=clang++ cmake ../..\n```\n\n## Cmake with Visual Studio\n\nYou can also use cmake on Windows. Open a Visual Studio 2022 development prompt \nand invoke `cmake` with the right [generator](https://cmake.org/cmake/help/latest/generator/Visual%20Studio%2017%202022.html) \nand architecture, like:\n\n```\n> cmake ..\\.. -G \"Visual Studio 17 2022\" -A x64 -DMI_OVERRIDE=ON\n```\n\nThe cmake build type is specified when actually building, for example:\n\n```\n> cmake --build . --config=Release\n```\n\nYou can also install the [LLVM toolset](https://learn.microsoft.com/en-us/cpp/build/clang-support-msbuild?view=msvc-170#install-1) \non Windows to build with the `clang-cl` compiler directly:\n\n```\n> cmake ../.. -G \"Visual Studio 17 2022\" -T ClangCl\n```\n\n\n## Single Source\n\nYou can also directly build the single `src/static.c` file as part of your project without\nneeding `cmake` at all. Make sure to also add the mimalloc `include` directory to the include path.\n\n\n# Using the Library\n\nThe preferred usage is including `<mimalloc.h>`, linking with\nthe shared- or static library, and using the `mi_malloc` API exclusively for allocation. For example,\n```\n> gcc -o myprogram -lmimalloc myfile.c\n```\n\nmimalloc uses only safe OS calls (`mmap` and `VirtualAlloc`) and can co-exist\nwith other allocators linked to the same program.\nIf you use `cmake`, you can simply use:\n```\nfind_package(mimalloc 1.8 REQUIRED)\n```\nin your `CMakeLists.txt` to find a locally installed mimalloc. Then use either:\n```\ntarget_link_libraries(myapp PUBLIC mimalloc)\n```\nto link with the shared (dynamic) library, or:\n```\ntarget_link_libraries(myapp PUBLIC mimalloc-static)\n```\nto link with the static library. See `test\\CMakeLists.txt` for an example.\n\nFor best performance in C++ programs, it is also recommended to override the\nglobal `new` and `delete` operators. For convenience, mimalloc provides\n[`mimalloc-new-delete.h`](include/mimalloc-new-delete.h) which does this for you -- just include it in a single(!) source file in your project.\nIn C++, mimalloc also provides the `mi_stl_allocator` struct which implements the `std::allocator`\ninterface.\n\nYou can pass environment variables to print verbose messages (`MIMALLOC_VERBOSE=1`)\nand statistics (`MIMALLOC_SHOW_STATS=1`) (in the debug version):\n```\n> env MIMALLOC_SHOW_STATS=1 ./cfrac 175451865205073170563711388363\n\n175451865205073170563711388363 = 374456281610909315237213 * 468551\n\nheap stats:     peak      total      freed       unit\nnormal   2:    16.4 kb    17.5 mb    17.5 mb      16 b   ok\nnormal   3:    16.3 kb    15.2 mb    15.2 mb      24 b   ok\nnormal   4:      64 b      4.6 kb     4.6 kb      32 b   ok\nnormal   5:      80 b    118.4 kb   118.4 kb      40 b   ok\nnormal   6:      48 b       48 b       48 b       48 b   ok\nnormal  17:     960 b      960 b      960 b      320 b   ok\n\nheap stats:     peak      total      freed       unit\n    normal:    33.9 kb    32.8 mb    32.8 mb       1 b   ok\n      huge:       0 b        0 b        0 b        1 b   ok\n     total:    33.9 kb    32.8 mb    32.8 mb       1 b   ok\nmalloc requested:         32.8 mb\n\n committed:    58.2 kb    58.2 kb    58.2 kb       1 b   ok\n  reserved:     2.0 mb     2.0 mb     2.0 mb       1 b   ok\n     reset:       0 b        0 b        0 b        1 b   ok\n  segments:       1          1          1\n-abandoned:       0\n     pages:       6          6          6\n-abandoned:       0\n     mmaps:       3\n mmap fast:       0\n mmap slow:       1\n   threads:       0\n   elapsed:     2.022s\n   process: user: 1.781s, system: 0.016s, faults: 756, reclaims: 0, rss: 2.7 mb\n```\n\nThe above model of using the `mi_` prefixed API is not always possible\nthough in existing programs that already use the standard malloc interface,\nand another option is to override the standard malloc interface\ncompletely and redirect all calls to the _mimalloc_ library instead .\n\n## Environment Options\n\nYou can set further options either programmatically (using [`mi_option_set`](https://microsoft.github.io/mimalloc/group__options.html)), or via environment variables:\n\n- `MIMALLOC_SHOW_STATS=1`: show statistics when the program terminates.\n- `MIMALLOC_VERBOSE=1`: show verbose messages (including statistics).\n- `MIMALLOC_SHOW_ERRORS=1`: show error and warning messages.\n\nAdvanced options:\n\n- `MIMALLOC_ARENA_EAGER_COMMIT=2`: turns on eager commit for the large arenas (usually 1GiB) from which mimalloc\n   allocates segments and pages. Set this to 2 (default) to\n   only enable this on overcommit systems (e.g. Linux). Set this to 1 to enable explicitly on other systems\n   as well (like Windows or macOS) which may improve performance (as the whole arena is committed at once).\n   Note that eager commit only increases the commit but not the actual the peak resident set\n   (rss) so it is generally ok to enable this.\n- `MIMALLOC_PURGE_DELAY=N`: the delay in `N` milli-seconds (by default `1000` in v3) after which mimalloc will purge\n   OS pages that are not in use. This signals to the OS that the underlying physical memory can be reused which\n   can reduce memory fragmentation especially in long running (server) programs. Setting `N` to `0` purges immediately when\n   a page becomes unused which can improve memory usage but also decreases performance.\n   Setting it to `-1` disables purging completely.\n- `MIMALLOC_PURGE_DECOMMITS=1`: By default \"purging\" memory means unused memory is decommitted (`MEM_DECOMMIT` on Windows,\n   `MADV_DONTNEED` (which decresease rss immediately) on `mmap` systems). Set this to 0 to instead \"reset\" unused\n   memory on a purge (`MEM_RESET` on Windows, generally `MADV_FREE` (which does not decrease rss immediately) on `mmap` systems).\n   Mimalloc generally does not \"free\" OS memory but only \"purges\" OS memory, in other words, it tries to keep virtual\n   address ranges and decommits within those ranges (to make the underlying physical memory available to other processes).\n\nFurther options for large workloads and services:\n\n- `MIMALLOC_ALLOW_THP=1`: By default always allow transparent huge pages (THP) on Linux systems. On Android only this is\n   by default off. When set to `0`, THP is disabled for the process that mimalloc runs in. If enabled, mimalloc also sets\n   the `MIMALLOC_MINIMAL_PURGE_SIZE` in v3 to 2MiB to avoid potentially breaking up transparent huge pages.\n- `MIMALLOC_USE_NUMA_NODES=N`: pretend there are at most `N` NUMA nodes. If not set, the actual NUMA nodes are detected\n   at runtime. Setting `N` to 1 may avoid problems in some virtual environments. Also, setting it to a lower number than\n   the actual NUMA nodes is fine and will only cause threads to potentially allocate more memory across actual NUMA\n   nodes (but this can happen in any case as NUMA local allocation is always a best effort but not guaranteed).\n- `MIMALLOC_ALLOW_LARGE_OS_PAGES=0`: Set to 1 to use large OS pages (2 or 4MiB) when available; for some workloads this can\n   significantly improve performance. However, large OS pages cannot be purged or shared with other processes so may lead\n   to increased memory usage in some cases.\n   Use `MIMALLOC_VERBOSE` to check if the large OS pages are enabled -- usually one needs\n   to explicitly give permissions for large OS pages (as on [Windows][windows-huge] and [Linux][linux-huge]). However, sometimes\n   the OS is very slow to reserve contiguous physical memory for large OS pages so use with care on systems that\n   can have fragmented memory (for that reason, we generally recommend to use `MIMALLOC_RESERVE_HUGE_OS_PAGES` instead whenever possible).\n- `MIMALLOC_RESERVE_HUGE_OS_PAGES=N`: where `N` is the number of 1GiB _huge_ OS pages. This reserves the huge pages at\n   startup and sometimes this can give a large (latency) performance improvement on big workloads.\n   Usually it is better to not use `MIMALLOC_ALLOW_LARGE_OS_PAGES=1` in combination with this setting. Just like large\n   OS pages, use with care as reserving\n   contiguous physical memory can take a long time when memory is fragmented (but reserving the huge pages is done at\n   startup only once).\n   Note that we usually need to explicitly give permission for huge OS pages (as on [Windows][windows-huge] and [Linux][linux-huge])).\n   The huge pages are usually allocated evenly among NUMA nodes.\n   We can use `MIMALLOC_RESERVE_HUGE_OS_PAGES_AT=N` where `N` is the numa node (starting at 0) to allocate all\n   the huge pages at a specific numa node instead.\n\nUse caution when using `fork` in combination with either large or huge OS pages: on a fork, the OS uses copy-on-write\nfor all pages in the original process including the huge OS pages. When any memory is now written in that area, the\nOS will copy the entire 1GiB huge page (or 2MiB large page) which can cause the memory usage to grow in large increments.\n\n[linux-huge]: https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/5/html/tuning_and_optimizing_red_hat_enterprise_linux_for_oracle_9i_and_10g_databases/sect-oracle_9i_and_10g_tuning_guide-large_memory_optimization_big_pages_and_huge_pages-configuring_huge_pages_in_red_hat_enterprise_linux_4_or_5\n[windows-huge]: https://docs.microsoft.com/en-us/sql/database-engine/configure-windows/enable-the-lock-pages-in-memory-option-windows?view=sql-server-2017\n\n## Secure Mode\n\n_mimalloc_ can be build in secure mode by using the `-DMI_SECURE=ON` flags in `cmake`. This build enables various mitigations\nto make mimalloc more robust against exploits. In particular:\n\n- All internal mimalloc pages are surrounded by guard pages and the heap metadata is behind a guard page as well (so a buffer overflow\n  exploit cannot reach into the metadata).\n- All free list pointers are\n  [encoded](https://github.com/microsoft/mimalloc/blob/783e3377f79ee82af43a0793910a9f2d01ac7863/include/mimalloc-internal.h#L396)\n  with per-page keys which is used both to prevent overwrites with a known pointer, as well as to detect heap corruption.\n- Double free's are detected (and ignored).\n- The free lists are initialized in a random order and allocation randomly chooses between extension and reuse within a page to\n  mitigate against attacks that rely on a predicable allocation order. Similarly, the larger heap blocks allocated by mimalloc\n  from the OS are also address randomized.\n\nAs always, evaluate with care as part of an overall security strategy as all of the above are mitigations but not guarantees.\n\n## Debug Mode\n\nWhen _mimalloc_ is built using debug mode, (`-DCMAKE_BUILD_TYPE=Debug`), \nvarious checks are done at runtime to catch development errors.\n\n- Statistics are maintained in detail for each object size. They can be shown using `MIMALLOC_SHOW_STATS=1` at runtime.\n- All objects have padding at the end to detect (byte precise) heap block overflows.\n- Double free's, and freeing invalid heap pointers are detected.\n- Corrupted free-lists and some forms of use-after-free are detected.\n\n## Guarded Mode\n\n<span id=\"guarded\">_mimalloc_ can be build in guarded mode using the `-DMI_GUARDED=ON` flags in `cmake`.</span>\nThis enables placing OS guard pages behind certain object allocations to catch buffer overflows as they occur.\nThis can be invaluable to catch buffer-overflow bugs in large programs. However, it also means that any object\nallocated with a guard page takes at least 8 KiB memory for the guard page and its alignment. As such, allocating\na guard page for every allocation may be too expensive both in terms of memory, and in terms of performance with\nmany system calls. Therefore, there are various environment variables (and options) to tune this:\n\n- `MIMALLOC_GUARDED_SAMPLE_RATE=N`: Set the sample rate to `N` (by default 4000). This mode places a guard page\n  behind every `N` suitable object allocations (per thread). Since the performance in guarded mode without placing\n  guard pages is close to release mode, this can be used to enable guard pages even in production to catch latent \n  buffer overflow bugs. Set the sample rate to `1` to guard every object, and to `0` to place no guard pages at all.\n\n- `MIMALLOC_GUARDED_SAMPLE_SEED=N`: Start sampling at `N` (by default random). Can be used to reproduce a buffer\n  overflow if needed.\n\n- `MIMALLOC_GUARDED_MIN=N`, `MIMALLOC_GUARDED_MAX=N`: Minimal and maximal _rounded_ object sizes for which a guard \n  page is considered (`0` and `1GiB` respectively). If you suspect a buffer overflow occurs with an object of size\n  141, set the minimum and maximum to `148` and the sample rate to `1` to have all of those guarded.\n\n- `MIMALLOC_GUARDED_PRECISE=1`: If we have an object of size 13, we would usually place it an aligned 16 bytes in\n  front of the guard page. Using `MIMALLOC_GUARDED_PRECISE` places it exactly 13 bytes before a page so that even\n  a 1 byte overflow is detected. This violates the C/C++ minimal alignment guarantees though so use with care.\n\n\n# Overriding Standard Malloc\n\nOverriding the standard `malloc` (and `new`) can be done either _dynamically_ or _statically_.\n\n## Dynamic override\n\nThis is the recommended way to override the standard malloc interface.\n\n### Dynamic Override on Linux, BSD\n\nOn these ELF-based systems we preload the mimalloc shared\nlibrary so all calls to the standard `malloc` interface are\nresolved to the _mimalloc_ library.\n```\n> env LD_PRELOAD=/usr/lib/libmimalloc.so myprogram\n```\n\nYou can set extra environment variables to check that mimalloc is running,\nlike:\n```\n> env MIMALLOC_VERBOSE=1 LD_PRELOAD=/usr/lib/libmimalloc.so myprogram\n```\nor run with the debug version to get detailed statistics:\n```\n> env MIMALLOC_SHOW_STATS=1 LD_PRELOAD=/usr/lib/libmimalloc-debug.so myprogram\n```\n\n### Dynamic Override on MacOS\n\nOn macOS we can also preload the mimalloc shared\nlibrary so all calls to the standard `malloc` interface are\nresolved to the _mimalloc_ library.\n```\n> env DYLD_INSERT_LIBRARIES=/usr/lib/libmimalloc.dylib myprogram\n```\n\nNote that certain security restrictions may apply when doing this from\nthe [shell](https://stackoverflow.com/questions/43941322/dyld-insert-libraries-ignored-when-calling-application-through-bash).\n\n\n### Dynamic Override on Windows\n\n<span id=\"override_on_windows\">We use a separate redirection DLL to override mimalloc on Windows</span> \nsuch that we redirect all malloc/free calls that go through the (dynamic) C runtime allocator, \nincluding those from other DLL's or libraries. As it intercepts all allocation calls on a low level, \nit can be used on large programs that include other 3rd party components.\nThere are four requirements to make the overriding work well:\n\n1. Use the C-runtime library as a DLL (using the `/MD` or `/MDd` switch).\n\n2. Link your program explicitly with the `mimalloc.dll.lib` export library for the `mimalloc.dll`.\n   (which must be compiled with `-DMI_OVERRIDE=ON`, which is the default though).\n   To ensure the `mimalloc.dll` is actually loaded at run-time it is easiest \n   to insert some call to the mimalloc API in the `main` function, like `mi_version()`\n   (or use the `/include:mi_version` switch on the linker command, or\n   similarly, `#pragma comment(linker, \"/include:mi_version\")` in some source file). \n   See the `mimalloc-test-override` project for an example on how to use this. \n\n3. The `mimalloc-redirect.dll` must be put in the same directory as the main \n   `mimalloc.dll` at runtime (as it is a dependency of that DLL).\n   The redirection DLL ensures that all calls to the C runtime malloc API get \n   redirected to mimalloc functions (which reside in `mimalloc.dll`).\n\n4. Ensure the `mimalloc.dll` comes as early as possible in the import\n   list of the final executable (so it can intercept all potential allocations).\n   You can use `minject -l <exe>` to check this if needed.\n\nFor best performance on Windows with C++, it is also recommended to also override \nthe `new`/`delete` operations (by including [`mimalloc-new-delete.h`](include/mimalloc-new-delete.h)\na single(!) source file in your project).\n\nThe environment variable `MIMALLOC_DISABLE_REDIRECT=1` can be used to disable dynamic\noverriding at run-time. Use `MIMALLOC_VERBOSE=1` to check if mimalloc was successfully \nredirected.\n\nFor different platforms than x64, you may need a specific [redirection dll](bin).\nFurthermore, we cannot always re-link an executable or ensure `mimalloc.dll` comes\nfirst in the import table. In such cases the [`minject`](bin) tool can be used\nto patch the executable's import tables.\n\n\n## Static override\n\nOn Unix-like systems, you can also statically link with _mimalloc_ to override the standard\nmalloc interface. The recommended way is to link the final program with the\n_mimalloc_ single object file (`mimalloc.o`). We use\nan object file instead of a library file as linkers give preference to\nthat over archives to resolve symbols. To ensure that the standard\nmalloc interface resolves to the _mimalloc_ library, link it as the first\nobject file. For example:\n\n```\n> gcc -o myprogram mimalloc.o  myfile1.c ...\n```\n\nAnother way to override statically that works on all platforms, is to\nlink statically to mimalloc (as shown in the introduction) and include a\nheader file in each source file that re-defines `malloc` etc. to `mi_malloc`.\nThis is provided by [`mimalloc-override.h`](include/mimalloc-override.h). This only works \nreliably though if all sources are\nunder your control or otherwise mixing of pointers from different heaps may occur!\n\n\n# Tools\n\nGenerally, we recommend using the standard allocator with memory tracking tools, but mimalloc\ncan also be build to support the [address sanitizer][asan] or the excellent [Valgrind] tool.\nMoreover, it can be build to support Windows event tracing ([ETW]).\nThis has a small performance overhead but does allow detecting memory leaks and byte-precise\nbuffer overflows directly on final executables. See also the `test/test-wrong.c` file to test with various tools.\n\n## Valgrind\n\nTo build with [valgrind] support, use the `MI_TRACK_VALGRIND=ON` cmake option:\n\n```\n> cmake ../.. -DMI_TRACK_VALGRIND=ON\n```\n\nThis can also be combined with secure mode or debug mode.\nYou can then run your programs directly under valgrind:\n\n```\n> valgrind <myprogram>\n```\n\nIf you rely on overriding `malloc`/`free` by mimalloc (instead of using the `mi_malloc`/`mi_free` API directly),\nyou also need to tell `valgrind` to not intercept those calls itself, and use:\n\n```\n> MIMALLOC_SHOW_STATS=1 valgrind  --soname-synonyms=somalloc=*mimalloc* -- <myprogram>\n```\n\nBy setting the `MIMALLOC_SHOW_STATS` environment variable you can check that mimalloc is indeed\nused and not the standard allocator. Even though the [Valgrind option][valgrind-soname]\nis called `--soname-synonyms`, this also works when overriding with a static library or object file.\nTo dynamically override mimalloc using `LD_PRELOAD` together with `valgrind`, use:\n\n```\n> valgrind --trace-children=yes --soname-synonyms=somalloc=*mimalloc* /usr/bin/env LD_PRELOAD=/usr/lib/libmimalloc.so -- <myprogram>\n```\n\nSee also the `test/test-wrong.c` file to test with `valgrind`.\n\nValgrind support is in its initial development -- please report any issues.\n\n[Valgrind]: https://valgrind.org/\n[valgrind-soname]: https://valgrind.org/docs/manual/manual-core.html#opt.soname-synonyms\n\n## ASAN\n\nTo build with the address sanitizer, use the `-DMI_TRACK_ASAN=ON` cmake option:\n\n```\n> cmake ../.. -DMI_TRACK_ASAN=ON\n```\n\nThis can also be combined with secure mode or debug mode.\nYou can then run your programs as:'\n\n```\n> ASAN_OPTIONS=verbosity=1 <myprogram>\n```\n\nWhen you link a program with an address sanitizer build of mimalloc, you should\ngenerally compile that program too with the address sanitizer enabled.\nFor example, assuming you build mimalloc in `out/debug`:\n\n```\nclang -g -o test-wrong -Iinclude test/test-wrong.c out/debug/libmimalloc-asan-debug.a -lpthread -fsanitize=address -fsanitize-recover=address\n```\n\nSince the address sanitizer redirects the standard allocation functions, on some platforms (macOSX for example)\nit is required to compile mimalloc with `-DMI_OVERRIDE=OFF`.\nAddress sanitizer support is in its initial development -- please report any issues.\n\n[asan]: https://github.com/google/sanitizers/wiki/AddressSanitizer\n\n## ETW\n\nEvent tracing for Windows ([ETW]) provides a high performance way to capture all allocations though\nmimalloc and analyze them later. To build with ETW support, use the `-DMI_TRACK_ETW=ON` cmake option.\n\nYou can then capture an allocation trace using the Windows performance recorder (WPR), using the\n`src/prim/windows/etw-mimalloc.wprp` profile. In an admin prompt, you can use:\n```\n> wpr -start src\\prim\\windows\\etw-mimalloc.wprp -filemode\n> <my_mimalloc_program>\n> wpr -stop <my_mimalloc_program>.etl\n```\nand then open `<my_mimalloc_program>.etl` in the Windows Performance Analyzer (WPA), or\nuse a tool like [TraceControl] that is specialized for analyzing mimalloc traces.\n\n[ETW]: https://learn.microsoft.com/en-us/windows-hardware/test/wpt/event-tracing-for-windows\n[TraceControl]: https://github.com/xinglonghe/TraceControl\n\n\n# Performance\n\nLast update: 2021-01-30\n\nWe tested _mimalloc_ against many other top allocators over a wide\nrange of benchmarks, ranging from various real world programs to\nsynthetic benchmarks that see how the allocator behaves under more\nextreme circumstances. In our benchmark suite, _mimalloc_ outperforms other leading\nallocators (_jemalloc_, _tcmalloc_, _Hoard_, etc), and has a similar memory footprint. A nice property is that it\ndoes consistently well over the wide range of benchmarks.\n\nGeneral memory allocators are interesting as there exists no algorithm that is\noptimal -- for a given allocator one can usually construct a workload\nwhere it does not do so well. The goal is thus to find an allocation\nstrategy that performs well over a wide range of benchmarks without\nsuffering from (too much) underperformance in less common situations.\n\nAs always, interpret these results with care since some benchmarks test synthetic\nor uncommon situations that may never apply to your workloads. For example, most\nallocators do not do well on `xmalloc-testN` but that includes even the best\nindustrial allocators like _jemalloc_ and _tcmalloc_ that are used in some of\nthe world's largest systems (like Chrome or FreeBSD).\n\nAlso, the benchmarks here do not measure the behaviour on very large and long-running server workloads,\nor worst-case latencies of allocation. Much work has gone into `mimalloc` to work well on such\nworkloads (for example, to reduce virtual memory fragmentation on long-running services)\nbut such optimizations are not always reflected in the current benchmark suite.\n\nWe show here only an overview -- for\nmore specific details and further benchmarks we refer to the\n[technical report](https://www.microsoft.com/en-us/research/publication/mimalloc-free-list-sharding-in-action).\nThe benchmark suite is automated and available separately\nas [mimalloc-bench](https://github.com/daanx/mimalloc-bench).\n\n\n## Benchmark Results on a 16-core AMD 5950x (Zen3)\n\nTesting on the 16-core AMD 5950x processor at 3.4Ghz (4.9Ghz boost), with\nwith 32GiB memory at 3600Mhz, running\tUbuntu 20.04 with glibc 2.31 and GCC 9.3.0.\n\nWe measure three versions of _mimalloc_: the main version `mi` (tag:v1.7.0),\nthe new v2.0 beta version as `xmi` (tag:v2.0.0), and the main version in secure mode as `smi` (tag:v1.7.0).\n\nThe other allocators are\nGoogle's [_tcmalloc_](https://github.com/gperftools/gperftools) (`tc`, tag:gperftools-2.8.1) used in Chrome,\nFacebook's [_jemalloc_](https://github.com/jemalloc/jemalloc) (`je`, tag:5.2.1) by Jason Evans used in Firefox and FreeBSD,\nthe Intel thread building blocks [allocator](https://github.com/intel/tbb) (`tbb`, tag:v2020.3),\n[rpmalloc](https://github.com/mjansson/rpmalloc) (`rp`,tag:1.4.1) by Mattias Jansson,\nthe original scalable [_Hoard_](https://github.com/emeryberger/Hoard) (git:d880f72) allocator by Emery Berger \\[1],\nthe memory compacting [_Mesh_](https://github.com/plasma-umass/Mesh) (git:67ff31a) allocator by\nBobby Powers _et al_ \\[8],\nand finally the default system allocator (`glibc`, 2.31) (based on _PtMalloc2_).\n\n<img width=\"90%\" src=\"doc/bench-2021/bench-amd5950x-2021-01-30-a.svg\"/>\n<img width=\"90%\" src=\"doc/bench-2021/bench-amd5950x-2021-01-30-b.svg\"/>\n\nAny benchmarks ending in `N` run on all 32 logical cores in parallel.\nResults are averaged over 10 runs and reported relative\nto mimalloc (where 1.2 means it took 1.2&times; longer to run).\nThe legend also contains the _overall relative score_ between the\nallocators where 100 points is the maximum if an allocator is fastest on\nall benchmarks.\n\nThe single threaded _cfrac_ benchmark by Dave Barrett is an implementation of\ncontinued fraction factorization which uses many small short-lived allocations.\nAll allocators do well on such common usage, where _mimalloc_ is just a tad\nfaster than _tcmalloc_ and\n_jemalloc_.\n\nThe _leanN_ program is interesting as a large realistic and\nconcurrent workload of the [Lean](https://github.com/leanprover/lean)\ntheorem prover compiling its own standard library, and there is a 13%\nspeedup over _tcmalloc_. This is\nquite significant: if Lean spends 20% of its time in the\nallocator that means that _mimalloc_ is 1.6&times; faster than _tcmalloc_\nhere. (This is surprising as that is not measured in a pure\nallocation benchmark like _alloc-test_. We conjecture that we see this\noutsized improvement here because _mimalloc_ has better locality in\nthe allocation which improves performance for the *other* computations\nin a program as well).\n\nThe single threaded _redis_ benchmark again show that most allocators do well on such workloads.\n\nThe _larsonN_ server benchmark by Larson and Krishnan \\[2] allocates and frees between threads. They observed this\nbehavior (which they call _bleeding_) in actual server applications, and the benchmark simulates this.\nHere, _mimalloc_ is quite a bit faster than _tcmalloc_ and _jemalloc_ probably due to the object migration between different threads.\n\nThe _mstressN_ workload performs many allocations and re-allocations,\nand migrates objects between threads (as in _larsonN_). However, it also\ncreates  and destroys the _N_ worker threads a few times keeping some objects\nalive beyond the life time of the allocating thread. We observed this\nbehavior in many larger server applications.\n\nThe [_rptestN_](https://github.com/mjansson/rpmalloc-benchmark) benchmark\nby Mattias Jansson is a allocator test originally designed\nfor _rpmalloc_, and tries to simulate realistic allocation patterns over\nmultiple threads. Here the differences between allocators become more apparent.\n\nThe second benchmark set tests specific aspects of the allocators and\nshows even more extreme differences between them.\n\nThe _alloc-test_, by\n[OLogN Technologies AG](http://ithare.com/testing-memory-allocators-ptmalloc2-tcmalloc-hoard-jemalloc-while-trying-to-simulate-real-world-loads/), is a very allocation intensive benchmark doing millions of\nallocations in various size classes. The test is scaled such that when an\nallocator performs almost identically on _alloc-test1_ as _alloc-testN_ it\nmeans that it scales linearly.\n\nThe _sh6bench_ and _sh8bench_ benchmarks are\ndeveloped by [MicroQuill](http://www.microquill.com/) as part of SmartHeap.\nIn _sh6bench_ _mimalloc_ does much\nbetter than the others (more than 2.5&times; faster than _jemalloc_).\nWe cannot explain this well but believe it is\ncaused in part by the \"reverse\" free-ing pattern in _sh6bench_.\nThe _sh8bench_ is a variation with object migration\nbetween threads; whereas _tcmalloc_ did well on _sh6bench_, the addition of object migration causes it to be 10&times; slower than before.\n\nThe _xmalloc-testN_ benchmark by Lever and Boreham \\[5] and Christian Eder, simulates an asymmetric workload where\nsome threads only allocate, and others only free -- they observed this pattern in\nlarger server applications. Here we see that\nthe _mimalloc_ technique of having non-contended sharded thread free\nlists pays off as it outperforms others by a very large margin. Only _rpmalloc_, _tbb_, and _glibc_ also scale well on this benchmark.\n\nThe _cache-scratch_ benchmark by Emery Berger \\[1], and introduced with\nthe Hoard allocator to test for _passive-false_ sharing of cache lines.\nWith a single thread they all\nperform the same, but when running with multiple threads the potential allocator\ninduced false sharing of the cache lines can cause large run-time differences.\nCrundal \\[6] describes in detail why the false cache line sharing occurs in the _tcmalloc_ design, and also discusses how this\ncan be avoided with some small implementation changes.\nOnly the _tbb_, _rpmalloc_ and _mesh_ allocators also avoid the\ncache line sharing completely, while _Hoard_ and _glibc_ seem to mitigate\nthe effects. Kukanov and Voss \\[7] describe in detail\nhow the design of _tbb_ avoids the false cache line sharing.\n\n\n## On a 36-core Intel Xeon\n\nFor completeness, here are the results on a big Amazon\n[c5.18xlarge](https://aws.amazon.com/ec2/instance-types/#Compute_Optimized) instance\nconsisting of a 2&times;18-core Intel Xeon (Cascade Lake) at 3.4GHz (boost 3.5GHz)\nwith 144GiB ECC memory, running\tUbuntu 20.04 with glibc 2.31, GCC 9.3.0, and\nClang 10.0.0. This time, the mimalloc allocators (mi, xmi, and smi) were\ncompiled with the Clang compiler instead of GCC.\nThe results are similar to the AMD results but it is interesting to\nsee the differences in the _larsonN_, _mstressN_, and _xmalloc-testN_ benchmarks.\n\n<img width=\"90%\" src=\"doc/bench-2021/bench-c5-18xlarge-2021-01-30-a.svg\"/>\n<img width=\"90%\" src=\"doc/bench-2021/bench-c5-18xlarge-2021-01-30-b.svg\"/>\n\n\n## Peak Working Set\n\nThe following figure shows the peak working set (rss) of the allocators\non the benchmarks (on the c5.18xlarge instance).\n\n<img width=\"90%\" src=\"doc/bench-2021/bench-c5-18xlarge-2021-01-30-rss-a.svg\"/>\n<img width=\"90%\" src=\"doc/bench-2021/bench-c5-18xlarge-2021-01-30-rss-b.svg\"/>\n\nNote that the _xmalloc-testN_ memory usage should be disregarded as it\nallocates more the faster the program runs. Similarly, memory usage of\n_larsonN_, _mstressN_, _rptestN_ and _sh8bench_ can vary depending on scheduling and\nspeed. Nevertheless, we hope to improve the memory usage on _mstressN_\nand _rptestN_ (just as _cfrac_, _larsonN_ and _sh8bench_ have a small working set which skews the results).\n\n<!--\n# Previous Benchmarks\n\nTodo: should we create a separate page for this?\n\n## Benchmark Results on 36-core Intel: 2020-01-20\n\nTesting on a big Amazon EC2 compute instance\n([c5.18xlarge](https://aws.amazon.com/ec2/instance-types/#Compute_Optimized))\nconsisting of a 72 processor Intel Xeon at 3GHz\nwith 144GiB ECC memory, running\tUbuntu 18.04.1 with glibc 2.27 and GCC 7.4.0.\nThe measured allocators are _mimalloc_ (xmi, tag:v1.4.0, page reset enabled)\nand its secure build as _smi_,\nGoogle's [_tcmalloc_](https://github.com/gperftools/gperftools) (tc, tag:gperftools-2.7) used in Chrome,\nFacebook's [_jemalloc_](https://github.com/jemalloc/jemalloc) (je, tag:5.2.1) by Jason Evans used in Firefox and FreeBSD,\nthe Intel thread building blocks [allocator](https://github.com/intel/tbb) (tbb, tag:2020),\n[rpmalloc](https://github.com/mjansson/rpmalloc) (rp,tag:1.4.0) by Mattias Jansson,\nthe original scalable [_Hoard_](https://github.com/emeryberger/Hoard) (tag:3.13) allocator by Emery Berger \\[1],\nthe memory compacting [_Mesh_](https://github.com/plasma-umass/Mesh) (git:51222e7) allocator by\nBobby Powers _et al_ \\[8],\nand finally the default system allocator (glibc, 2.27) (based on _PtMalloc2_).\n\n<img width=\"90%\" src=\"doc/bench-2020/bench-c5-18xlarge-2020-01-20-a.svg\"/>\n<img width=\"90%\" src=\"doc/bench-2020/bench-c5-18xlarge-2020-01-20-b.svg\"/>\n\nThe following figure shows the peak working set (rss) of the allocators\non the benchmarks (on the c5.18xlarge instance).\n\n<img width=\"90%\" src=\"doc/bench-2020/bench-c5-18xlarge-2020-01-20-rss-a.svg\"/>\n<img width=\"90%\" src=\"doc/bench-2020/bench-c5-18xlarge-2020-01-20-rss-b.svg\"/>\n\n\n## On 24-core AMD Epyc, 2020-01-16\n\nFor completeness, here are the results on a\n[r5a.12xlarge](https://aws.amazon.com/ec2/instance-types/#Memory_Optimized) instance\nhaving a 48 processor AMD Epyc 7000 at 2.5GHz with 384GiB of memory.\nThe results are similar to the Intel results but it is interesting to\nsee the differences in the _larsonN_, _mstressN_, and _xmalloc-testN_ benchmarks.\n\n<img width=\"90%\" src=\"doc/bench-2020/bench-r5a-12xlarge-2020-01-16-a.svg\"/>\n<img width=\"90%\" src=\"doc/bench-2020/bench-r5a-12xlarge-2020-01-16-b.svg\"/>\n\n-->\n\n\n# References\n\n- \\[1] Emery D. Berger, Kathryn S. McKinley, Robert D. Blumofe, and Paul R. Wilson.\n   _Hoard: A Scalable Memory Allocator for Multithreaded Applications_\n   the Ninth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-IX). Cambridge, MA, November 2000.\n   [pdf](http://www.cs.utexas.edu/users/mckinley/papers/asplos-2000.pdf)\n\n- \\[2] P. Larson and M. Krishnan. _Memory allocation for long-running server applications_.\n  In ISMM, Vancouver, B.C., Canada, 1998. [pdf](http://citeseer.ist.psu.edu/viewdoc/download?doi=10.1.1.45.1947&rep=rep1&type=pdf)\n\n- \\[3] D. Grunwald, B. Zorn, and R. Henderson.\n  _Improving the cache locality of memory allocation_. In R. Cartwright, editor,\n  Proceedings of the Conference on Programming Language Design and Implementation, pages 177‚Äì186, New York, NY, USA, June 1993. [pdf](http://citeseer.ist.psu.edu/viewdoc/download?doi=10.1.1.43.6621&rep=rep1&type=pdf)\n\n- \\[4] J. Barnes and P. Hut. _A hierarchical O(n*log(n)) force-calculation algorithm_. Nature, 324:446-449, 1986.\n\n- \\[5] C. Lever, and D. Boreham. _Malloc() Performance in a Multithreaded Linux Environment._\n  In USENIX Annual Technical Conference, Freenix Session. San Diego, CA. Jun. 2000.\n  Available at <https://github.com/kuszmaul/SuperMalloc/tree/master/tests>\n\n- \\[6] Timothy Crundal. _Reducing Active-False Sharing in TCMalloc_. 2016. CS16S1 project at the Australian National University. [pdf](http://courses.cecs.anu.edu.au/courses/CSPROJECTS/16S1/Reports/Timothy_Crundal_Report.pdf)\n\n- \\[7] Alexey Kukanov, and Michael J Voss.\n   _The Foundations for Scalable Multi-Core Software in Intel Threading Building Blocks._\n   Intel Technology Journal 11 (4). 2007\n\n- \\[8] Bobby Powers, David Tench, Emery D. Berger, and Andrew McGregor.\n _Mesh: Compacting Memory Management for C/C++_\n In Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI'19), June 2019, pages 333-‚Äì346.\n\n<!--\n- \\[9] Paul Li√©tar, Theodore Butler, Sylvan Clebsch, Sophia Drossopoulou, Juliana Franco, Matthew J Parkinson,\n  Alex Shamis, Christoph M Wintersteiger, and David Chisnall.\n  _Snmalloc: A Message Passing Allocator._\n  In Proceedings of the 2019 ACM SIGPLAN International Symposium on Memory Management, 122‚Äì135. ACM. 2019.\n-->\n\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\n\n# Older Release Notes\n\n* 2024-05-13, `v1.8.6`, `v2.1.6`: Fix build errors on various (older) platforms. Refactored aligned allocation.\n* 2024-04-22, `v1.8.4`, `v2.1.4`: Fixes various bugs and build issues. Add `MI_LIBC_MUSL` cmake flag for musl builds.\n  Free-ing code is refactored into a separate module (`free.c`). Mimalloc page info is simplified with the block size\n  directly available (and new `block_size_shift` to improve aligned block free-ing).\n  New approach to collection of abandoned segments: When\n  a thread terminates the segments it owns are abandoned (containing still live objects) and these can be\n  reclaimed by other threads. We no longer use a list of abandoned segments but this is now done using bitmaps in arena's\n  which is more concurrent (and more aggressive). Abandoned memory can now also be reclaimed if a thread frees an object in\n  an abandoned page (which can be disabled using `mi_option_abandoned_reclaim_on_free`). The option `mi_option_max_segment_reclaim`\n  gives a maximum percentage of abandoned segments that can be reclaimed per try (=10%).\n\n* 2023-04-24, `v1.8.2`, `v2.1.2`: Fixes build issues on freeBSD, musl, and C17 (UE 5.1.1). Reduce code size/complexity\n  by removing regions and segment-cache's and only use arenas with improved memory purging -- this may improve memory\n  usage as well for larger services. Renamed options for consistency. Improved Valgrind and ASAN checking.\n\n* 2023-04-03, `v1.8.1`, `v2.1.1`: Fixes build issues on some platforms.\n\n* 2023-03-29, `v1.8.0`, `v2.1.0`: Improved support dynamic overriding on Windows 11. Improved tracing precision\n  with [asan](#asan) and [Valgrind](#valgrind), and added Windows event tracing [ETW](#ETW) (contributed by Xinglong He). Created an OS\n  abstraction layer to make it easier to port and separate platform dependent code (in `src/prim`). Fixed C++ STL compilation on older Microsoft C++ compilers, and various small bug fixes.\n\n* 2022-12-23, `v1.7.9`, `v2.0.9`: Supports building with [asan](#asan) and improved [Valgrind](#valgrind) support.\n  Support arbitrary large alignments (in particular for `std::pmr` pools).\n  Added C++ STL allocators attached to a specific heap (thanks @vmarkovtsev).\n  Heap walks now visit all object (including huge objects). Support Windows nano server containers (by Johannes Schindelin,@dscho).\n  Various small bug fixes.\n\n* 2022-11-03, `v1.7.7`, `v2.0.7`: Initial support for [Valgrind](#valgrind) for leak testing and heap block overflow\n  detection. Initial\n  support for attaching heaps to a specific memory area (only in v2). Fix `realloc` behavior for zero size blocks, remove restriction to integral multiple of the alignment in `alloc_align`, improved aligned allocation performance, reduced contention with many threads on few processors (thank you @dposluns!), vs2022 support, support `pkg-config`, .\n\n* 2022-04-14, `v1.7.6`, `v2.0.6`: fix fallback path for aligned OS allocation on Windows, improve Windows aligned allocation\n  even when compiling with older SDK's, fix dynamic overriding on macOS Monterey, fix MSVC C++ dynamic overriding, fix\n  warnings under Clang 14, improve performance if many OS threads are created and destroyed, fix statistics for large object\n  allocations, using MIMALLOC_VERBOSE=1 has no maximum on the number of error messages, various small fixes.\n\n* 2022-02-14, `v1.7.5`, `v2.0.5` (alpha): fix malloc override on\n  Windows 11, fix compilation with musl, potentially reduced\n  committed memory, add `bin/minject` for Windows,\n  improved wasm support, faster aligned allocation,\n  various small fixes.\n\n* 2021-11-14, `v1.7.3`, `v2.0.3` (beta): improved WASM support, improved macOS support and performance (including\n  M1), improved performance for v2 for large objects, Python integration improvements, more standard\n  installation directories, various small fixes.\n* 2021-06-17, `v1.7.2`, `v2.0.2` (beta): support M1, better installation layout on Linux, fix\n  thread_id on Android, prefer 2-6TiB area for aligned allocation to work better on pre-windows 8, various small fixes.\n* 2021-04-06, `v1.7.1`, `v2.0.1` (beta): fix bug in arena allocation for huge pages, improved aslr on large allocations, initial M1 support (still experimental).\n* 2021-01-31, `v2.0.0`: beta release 2.0: new slice algorithm for managing internal mimalloc pages.\n* 2021-01-31, `v1.7.0`: stable release 1.7: support explicit user provided memory regions, more precise statistics,\n  improve macOS overriding, initial support for Apple M1, improved DragonFly support, faster memcpy on Windows, various small fixes.\n\n* 2020-09-24, `v1.6.7`: stable release 1.6: using standard C atomics, passing tsan testing, improved\n  handling of failing to commit on Windows, add [`mi_process_info`](https://github.com/microsoft/mimalloc/blob/master/include/mimalloc.h#L156) api call.\n* 2020-08-06, `v1.6.4`: stable release 1.6: improved error recovery in low-memory situations,\n  support for IllumOS and Haiku, NUMA support for Vista/XP, improved NUMA detection for AMD Ryzen, ubsan support.\n* 2020-05-05, `v1.6.3`: stable release 1.6: improved behavior in out-of-memory situations, improved malloc zones on macOS,\n  build PIC static libraries by default, add option to abort on out-of-memory, line buffered statistics.\n* 2020-04-20, `v1.6.2`: stable release 1.6: fix compilation on Android, MingW, Raspberry, and Conda,\n  stability fix for Windows 7, fix multiple mimalloc instances in one executable, fix `strnlen` overload,\n  fix aligned debug padding.\n* 2020-02-17, `v1.6.1`: stable release 1.6: minor updates (build with clang-cl, fix alignment issue for small objects).\n* 2020-02-09, `v1.6.0`: stable release 1.6: fixed potential memory leak, improved overriding\n  and thread local support on FreeBSD, NetBSD, DragonFly, and macOSX. New byte-precise\n  heap block overflow detection in debug mode (besides the double-free detection and free-list\n  corruption detection). Add `nodiscard` attribute to most allocation functions.\n  Enable `MIMALLOC_PAGE_RESET` by default. New reclamation strategy for abandoned heap pages\n  for better memory footprint.\n* 2020-02-09, `v1.5.0`: stable release 1.5: improved free performance, small bug fixes.\n* 2020-01-22, `v1.4.0`: stable release 1.4: improved performance for delayed OS page reset,\nmore eager concurrent free, addition of STL allocator, fixed potential memory leak.\n* 2020-01-15, `v1.3.0`: stable release 1.3: bug fixes, improved randomness and [stronger\nfree list encoding](https://github.com/microsoft/mimalloc/blob/783e3377f79ee82af43a0793910a9f2d01ac7863/include/mimalloc-internal.h#L396) in secure mode.\n\n* 2019-12-22, `v1.2.2`: stable release 1.2: minor updates.\n* 2019-11-22, `v1.2.0`: stable release 1.2: bug fixes, improved secure mode (free list corruption checks, double free mitigation). Improved dynamic overriding on Windows.\n* 2019-10-07, `v1.1.0`: stable release 1.1.\n* 2019-09-01, `v1.0.8`: pre-release 8: more robust windows dynamic overriding, initial huge page support.\n* 2019-08-10, `v1.0.6`: pre-release 6: various performance improvements.\n",
      "stars_today": 3
    },
    {
      "id": 29102367,
      "name": "junit-framework",
      "full_name": "junit-team/junit-framework",
      "description": "‚úÖ The programmer-friendly testing framework for Java and the JVM",
      "html_url": "https://github.com/junit-team/junit-framework",
      "stars": 6947,
      "forks": 1637,
      "language": "Java",
      "topics": [
        "java",
        "junit",
        "junit-jupiter",
        "junit-platform",
        "junit-vintage",
        "kotlin",
        "kotlin-testing",
        "test-framework"
      ],
      "created_at": "2015-01-11T19:06:10Z",
      "updated_at": "2026-01-13T20:38:06Z",
      "pushed_at": "2026-01-14T00:25:22Z",
      "open_issues": 122,
      "owner": {
        "login": "junit-team",
        "avatar_url": "https://avatars.githubusercontent.com/u/874086?v=4"
      },
      "readme": "# <img alt=\"JUnit\" src=\"https://junit.org/assets/img/junit-logo-adaptive.svg\" width=\"200\">\n\nThis repository is the home of JUnit Platform, Jupiter, and Vintage.\n\n## Sponsors\n\n[![Support JUnit](https://img.shields.io/badge/%F0%9F%92%9A-Support%20JUnit-brightgreen.svg)](https://junit.org/sponsoring)\n\n* **Gold Sponsors:** [JetBrains](https://jb.gg/junit-logo), [Netflix](https://www.netflix.com/)\n* **Silver Sponsors:** [Micromata](https://www.micromata.de), [Quo Card](https://quo-digital.jp)\n* **Bronze Sponsors:** [Premium Minds](https://www.premium-minds.com), [codefortynine](https://codefortynine.com), [Info Support](https://www.infosupport.com), [Code Intelligence](https://www.code-intelligence.com), [Route4Me](https://route4me.com/), [Testiny](https://www.testiny.io/), [LambdaTest](https://www.lambdatest.com)\n\n## Latest Releases\n\n- General Availability (GA): [JUnit 6.0.2](https://github.com/junit-team/junit-framework/releases/tag/r6.0.2) (January 6, 2026)\n- Preview (Milestone/Release Candidate): [JUnit 6.1.0-M1](https://github.com/junit-team/junit-framework/releases/tag/r6.1.0-M1) (November 17, 2025)\n\n## Documentation\n\n- [User Guide]\n- [Javadoc]\n- [Release Notes]\n- [Examples]\n\n## Contributing\n\nContributions to JUnit are both welcomed and appreciated. For specific guidelines\nregarding contributions, please see [CONTRIBUTING.md] in the root directory of the\nproject. Those willing to use milestone or SNAPSHOT releases are encouraged\nto file feature requests and bug reports using the project's\n[issue tracker](https://github.com/junit-team/junit-framework/issues). Issues marked with an\n<a href=\"https://github.com/junit-team/junit-framework/issues?q=is%3Aissue+is%3Aopen+label%3Aup-for-grabs\">`up-for-grabs`</a>\nlabel are specifically targeted for community contributions.\n\n## Getting Help\n\nAsk JUnit-related questions on [StackOverflow] or use the Q&A category on [GitHub Discussions].\n\n## Continuous Integration Builds\n\n[![CI](https://github.com/junit-team/junit-framework/actions/workflows/main.yml/badge.svg?branch=main)](https://github.com/junit-team/junit-framework/actions/workflows/main.yml) [![Cross-Version](https://github.com/junit-team/junit-framework/actions/workflows/cross-version.yml/badge.svg?branch=main)](https://github.com/junit-team/junit-framework/actions/workflows/cross-version.yml)\n\nOfficial CI build server used to perform quick checks on submitted pull requests and for\nbuild matrices including the latest released OpenJDK and early access builds of the next\nOpenJDK.\n\n## Code Coverage\n\nCode coverage using [JaCoCo] for the latest build is available on [Codecov].\n\nA code coverage report can also be generated locally via the [Gradle Wrapper] by\nexecuting `./gradlew clean jacocoRootReport`. The results will be available\nin `build/reports/jacoco/jacocoRootReport/html/index.html`.\n\n## Develocity\n\n[![Revved up by Develocity](https://img.shields.io/badge/Revved%20up%20by-Develocity-06A0CE?logo=Gradle&labelColor=02303A)](https://ge.junit.org/scans)\n\nJUnit utilizes [Develocity](https://gradle.com/) for [Build Scans](https://scans.gradle.com/),\n[Build Cache](https://docs.gradle.org/current/userguide/build_cache.html), and\n[Predictive Test Selection](https://docs.gradle.com/enterprise/predictive-test-selection/).\n\nThe latest Build Scans are available on [ge.junit.org](https://ge.junit.org/). Currently,\nonly core team members can publish Build Scans on that server.\nYou can, however, publish a Build Scan to [scans.gradle.com](https://scans.gradle.com/) by\nusing the `--scan` parameter explicitly.\n\nThe remote Build Cache is enabled by default for everyone so that local builds can reuse\ntask outputs from previous CI builds.\n\n## Building from Source\n\nYou need [JDK 25] to build JUnit. [Gradle toolchains] are used to detect and\npotentially download additional JDKs for compilation and test execution.\n\nAll modules can be _built_ and _tested_ with the [Gradle Wrapper] using the following command:\n\n`./gradlew build`\n\nAll modules can be _installed_ in a local Maven repository for consumption in other local\nprojects via the following command:\n\n`./gradlew publishToMavenLocal`\n\n## Dependency Metadata\n\n[![JUnit Jupiter version](https://img.shields.io/maven-central/v/org.junit.jupiter/junit-jupiter/6..svg?color=25a162&label=Jupiter)](https://central.sonatype.com/search?namespace=org.junit.jupiter)\n[![JUnit Vintage version](https://img.shields.io/maven-central/v/org.junit.vintage/junit-vintage-engine/6..svg?color=25a162&label=Vintage)](https://central.sonatype.com/search?namespace=org.junit.vintage)\n[![JUnit Platform version](https://img.shields.io/maven-central/v/org.junit.platform/junit-platform-commons/6..svg?color=25a162&label=Platform)](https://central.sonatype.com/search?namespace=org.junit.platform)\n\nConsult the [Dependency Metadata] section of the [User Guide] for a list of all artifacts\nof the JUnit Platform, JUnit Jupiter, and JUnit Vintage.\n\n\n[Codecov]: https://codecov.io/gh/junit-team/junit-framework\n[CONTRIBUTING.md]: https://github.com/junit-team/junit-framework/blob/HEAD/CONTRIBUTING.md\n[Dependency Metadata]: https://docs.junit.org/current/appendix.html#dependency-metadata\n[GitHub Discussions]: https://github.com/junit-team/junit-framework/discussions/categories/q-a\n[Gradle toolchains]: https://docs.gradle.org/current/userguide/toolchains.html\n[Gradle Wrapper]: https://docs.gradle.org/current/userguide/gradle_wrapper.html#sec:using_wrapper\n[JaCoCo]: https://www.eclemma.org/jacoco/\n[Javadoc]: https://api.junit.org\n[JDK 25]: https://javaalmanac.io/jdk/25/\n[Release Notes]: https://docs.junit.org/current/release-notes.html\n[Examples]: https://github.com/junit-team/junit-examples\n[StackOverflow]: https://stackoverflow.com/questions/tagged/junit5\n[User Guide]: https://docs.junit.org\n",
      "stars_today": 3
    },
    {
      "id": 21193524,
      "name": "calcite",
      "full_name": "apache/calcite",
      "description": "Apache Calcite",
      "html_url": "https://github.com/apache/calcite",
      "stars": 5040,
      "forks": 2457,
      "language": "Java",
      "topics": [
        "big-data",
        "calcite",
        "geospatial",
        "hadoop",
        "java",
        "sql"
      ],
      "created_at": "2014-06-25T07:00:07Z",
      "updated_at": "2026-01-13T22:58:47Z",
      "pushed_at": "2026-01-13T22:58:41Z",
      "open_issues": 324,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "<!--\n{% comment %}\nLicensed to the Apache Software Foundation (ASF) under one or more\ncontributor license agreements.  See the NOTICE file distributed with\nthis work for additional information regarding copyright ownership.\nThe ASF licenses this file to you under the Apache License, Version 2.0\n(the \"License\"); you may not use this file except in compliance with\nthe License.  You may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n{% endcomment %}\n-->\n\n[![Maven Central](https://maven-badges.herokuapp.com/maven-central/org.apache.calcite/calcite-core/badge.svg)](https://maven-badges.herokuapp.com/maven-central/org.apache.calcite/calcite-core)\n[![CI Status](https://github.com/apache/calcite/workflows/CI/badge.svg?branch=main)](https://github.com/apache/calcite/actions?query=branch%3Amain)\n\n# Apache Calcite\n\nApache Calcite is a dynamic data management framework.\n\nIt contains many of the pieces that comprise a typical\ndatabase management system but omits the storage primitives.\nIt provides an industry standard SQL parser and validator,\na customisable optimizer with pluggable rules and cost functions,\nlogical and physical algebraic operators, various transformation\nalgorithms from SQL to algebra (and the opposite), and many\nadapters for executing SQL queries over Cassandra, Druid,\nElasticsearch, MongoDB, Kafka, and others, with minimal\nconfiguration.\n\nFor more details, see the [home page](http://calcite.apache.org).\n\nThe project uses [JIRA](https://issues.apache.org/jira/browse/CALCITE)\nfor issue tracking. For further information, please see the [JIRA accounts guide](https://calcite.apache.org/develop/#jira-accounts).\n",
      "stars_today": 3
    },
    {
      "id": 58194180,
      "name": "strimzi-kafka-operator",
      "full_name": "strimzi/strimzi-kafka-operator",
      "description": "Apache Kafka¬Æ running on Kubernetes",
      "html_url": "https://github.com/strimzi/strimzi-kafka-operator",
      "stars": 5642,
      "forks": 1439,
      "language": "Java",
      "topics": [
        "data-stream",
        "data-streaming",
        "data-streams",
        "hacktoberfest",
        "kafka",
        "kafka-connect",
        "kafka-streams",
        "kubernetes",
        "kubernetes-controller",
        "kubernetes-operator",
        "messaging",
        "openshift"
      ],
      "created_at": "2016-05-06T08:52:33Z",
      "updated_at": "2026-01-13T16:30:16Z",
      "pushed_at": "2026-01-13T11:15:29Z",
      "open_issues": 134,
      "owner": {
        "login": "strimzi",
        "avatar_url": "https://avatars.githubusercontent.com/u/34767428?v=4"
      },
      "readme": "[![Strimzi](./documentation/logo/strimzi.png)](https://strimzi.io/)\n\n# Run Apache Kafka on Kubernetes and OpenShift\n\n[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/strimzi/strimzi-kafka-operator/badge)](https://scorecard.dev/viewer/?uri=github.com/strimzi/strimzi-kafka-operator)\n[![Build Status](https://github.com/strimzi/strimzi-kafka-operator/actions/workflows/build.yml/badge.svg?branch=main)](https://github.com/strimzi/strimzi-kafka-operator/actions/workflows/build.yml?query=branch%3Amain)\n[![GitHub release](https://img.shields.io/github/release/strimzi/strimzi-kafka-operator.svg)](https://github.com/strimzi/strimzi-kafka-operator/releases/latest)\n[![License](https://img.shields.io/badge/license-Apache--2.0-blue.svg)](http://www.apache.org/licenses/LICENSE-2.0)\n[![Twitter Follow](https://img.shields.io/twitter/follow/strimziio?style=social)](https://twitter.com/strimziio)\n[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/strimzi-kafka-operator)](https://artifacthub.io/packages/search?repo=strimzi-kafka-operator)\n\nStrimzi provides a way to run an [Apache Kafka¬Æ][kafka] cluster on \n[Kubernetes][k8s] or [OpenShift][os] in various deployment configurations.\nSee our [website][strimzi] for more details about the project.\n\n## Quick Starts\n\nTo get up and running quickly, check our [Quick Start for Minikube, OKD (OpenShift Origin) and Kubernetes Kind](https://strimzi.io/quickstarts/). \n\n## Documentation\n\nDocumentation for the current _main_ branch as well as all releases can be found on our [website][strimzi].\n\n## Roadmap\n\nThe roadmap of the Strimzi Operator project is maintained as [GitHub Project](https://github.com/orgs/strimzi/projects/4).\n\n## Getting help\n\nIf you encounter any issues while using Strimzi, you can get help using:\n\n- [#strimzi channel on CNCF Slack](https://slack.cncf.io/)\n- [Strimzi Users mailing list](https://lists.cncf.io/g/cncf-strimzi-users/topics)\n- [GitHub Discussions](https://github.com/strimzi/strimzi-kafka-operator/discussions)\n\n## Strimzi Community Meetings\n\nYou can join our regular community meetings:\n* Thursday 9:00 AM UTC (every 4 weeks) - [convert to your timezone](https://www.thetimezoneconverter.com/?t=8%3A00&tz=UTC)\n* Thursday 4:00 PM UTC (every 4 weeks, offset by 2 weeks from above meeting) - [convert to your timezone](https://www.thetimezoneconverter.com/?t=16%3A00&tz=UTC)\n\nResources:\n* [Meeting minutes, agenda and Zoom link](https://docs.google.com/document/d/1V1lMeMwn6d2x1LKxyydhjo2c_IFANveelLD880A6bYc/edit#heading=h.vgkvn1hr5uor)\n* [Recordings](https://youtube.com/playlist?list=PLpI4X8PMthYfONZopcRd4X_stq1C14Rtn)\n* [Calendar](https://calendar.google.com/calendar/embed?src=c_m9pusj5ce1b4hr8c92hsq50i00%40group.calendar.google.com) ([Subscribe to the calendar](https://calendar.google.com/calendar/u/0?cid=Y19tOXB1c2o1Y2UxYjRocjhjOTJoc3E1MGkwMEBncm91cC5jYWxlbmRhci5nb29nbGUuY29t))\n\n## Contributing\n\nYou can contribute by:\n- Raising issues you find while using Strimzi\n- Fixing issues by opening Pull Requests\n- Improving Strimzi documentation\n- Talking about Strimzi\n\nAll bugs, tasks or enhancements are tracked as [GitHub issues](https://github.com/strimzi/strimzi-kafka-operator/issues). Issues which \nmight be a good start for new contributors are marked with [\"good-start\"](https://github.com/strimzi/strimzi-kafka-operator/labels/good-start)\nlabel.\n\nThe [Dev guide](https://github.com/strimzi/strimzi-kafka-operator/blob/main/development-docs/DEV_GUIDE.md) describes how to build Strimzi.\nBefore submitting a patch, please make sure to understand, how to test your changes before opening a PR [Test guide](https://github.com/strimzi/strimzi-kafka-operator/blob/main/development-docs/TESTING.md).\n\nThe [Documentation Contributor Guide](https://strimzi.io/contributing/guide/) describes how to contribute to Strimzi documentation.\n\nIf you want to get in touch with us first before contributing, you can use:\n\n- [#strimzi channel on CNCF Slack](https://slack.cncf.io/)\n- [Strimzi Dev mailing list](https://lists.cncf.io/g/cncf-strimzi-dev/topics)\n\n## License\nStrimzi is licensed under the [Apache License](./LICENSE), Version 2.0\n\n## Community Testing\n\n### Linux on IBM Z (s390x)\n\n[![Jenkins](https://ibmz-ci.osuosl.org/job/Strimzi_Kafka_Operator_IBMZ_CI/badge/icon)](https://ibmz-ci.osuosl.org/job/Strimzi_Kafka_Operator_IBMZ_CI/)\n\n_Note: This badge represents a community-led initiative and is not officially endorsed by the Strimzi project maintainers._\n\n## Container signatures\n\nFrom the 0.38.0 release, Strimzi containers are signed using the [`cosign` tool](https://github.com/sigstore/cosign).\nStrimzi uses keyless signing since 0.49.0 release. \nTo verify the container, you can run the following command:\n\n```shell\ncosign verify --certificate-identity-regexp='https://github.com/strimzi/.*' \\\n    --certificate-oidc-issuer='https://token.actions.githubusercontent.com' \\\n    quay.io/strimzi/operator:latest\n```\n\nIn case you want to verify containers of older version of Strimzi than 0.49.0, then use our public key:\n\n```\n-----BEGIN PUBLIC KEY-----\nMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAET3OleLR7h0JqatY2KkECXhA9ZAkC\nTRnbE23Wb5AzJPnpevvQ1QUEQQ5h/I4GobB7/jkGfqYkt6Ct5WOU2cc6HQ==\n-----END PUBLIC KEY-----\n```\n\nAnd use it to verify the signature:\n\n```shell\ncosign verify --key strimzi.pub quay.io/strimzi/operator:latest --insecure-ignore-tlog=true\n```\n\n## Software Bill of Materials (SBOM)\n\nFrom the 0.38.0 release, Strimzi publishes the software bill of materials (SBOM) of our containers.\nThe SBOMs are published as an archive with `SPDX-JSON` and `Syft-Table` formats signed using cosign.\nFor releases, they are also pushed into the container registry.\n\nStrimzi uses keyless signing since 0.49.0 release.\nTo verify the SBOM signatures, you can run the following command:\n\n```shell\ncosign verify-blob --bundle <SBOM-file>.bundle \\\n    --certificate-identity-regexp='https://github.com/strimzi/.*' \\\n    --certificate-oidc-issuer='https://token.actions.githubusercontent.com' \\\n    <SBOM-file>\n```\n\nIn case you want to verify SBOM signatures of older version of Strimzi than 0.49.0, then use our public key:\n\n```\n-----BEGIN PUBLIC KEY-----\nMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAET3OleLR7h0JqatY2KkECXhA9ZAkC\nTRnbE23Wb5AzJPnpevvQ1QUEQQ5h/I4GobB7/jkGfqYkt6Ct5WOU2cc6HQ==\n-----END PUBLIC KEY-----\n```\n\nYou can use it to verify the signature of the SBOM files with the following command:\n\n```shell\ncosign verify-blob --key cosign.pub --bundle <SBOM-file>.bundle --insecure-ignore-tlog=true <SBOM-file>\n```\n\n---\n\nStrimzi is a <a href=\"http://cncf.io\">Cloud Native Computing Foundation</a> incubating project.\n\n![CNCF ><](./documentation/logo/cncf-color.png)\n\n[strimzi]: https://strimzi.io \"Strimzi\"\n[kafka]: https://kafka.apache.org \"Apache Kafka\"\n[k8s]: https://kubernetes.io/ \"Kubernetes\"\n[os]: https://www.openshift.com/ \"OpenShift\"\n",
      "stars_today": 3
    },
    {
      "id": 49970739,
      "name": "datadog-agent",
      "full_name": "DataDog/datadog-agent",
      "description": "Main repository for Datadog Agent",
      "html_url": "https://github.com/DataDog/datadog-agent",
      "stars": 3472,
      "forks": 1369,
      "language": "Go",
      "topics": [
        "apm-agent",
        "apm-instrumentation",
        "datadog",
        "distributed-tracing",
        "go",
        "logging",
        "metrics",
        "monitoring",
        "observability",
        "open-telemetry",
        "otel",
        "profiling",
        "tracing"
      ],
      "created_at": "2016-01-19T17:40:41Z",
      "updated_at": "2026-01-13T23:12:04Z",
      "pushed_at": "2026-01-14T01:02:50Z",
      "open_issues": 1008,
      "owner": {
        "login": "DataDog",
        "avatar_url": "https://avatars.githubusercontent.com/u/365230?v=4"
      },
      "readme": "# Datadog Agent\n\n![GitHub Release](https://img.shields.io/github/v/release/DataDog/datadog-agent?style=flat&logo=datadog&logoColor=%23632CA6&labelColor=%23FFF&color=%23632CA6)\n[![Coverage status](https://codecov.io/github/DataDog/datadog-agent/coverage.svg?branch=main)](https://codecov.io/github/DataDog/datadog-agent?branch=main)\n[![GoDoc](https://godoc.org/github.com/DataDog/datadog-agent?status.svg)](https://godoc.org/github.com/DataDog/datadog-agent)\n\nThis repository contains the source code of the Datadog Agent version 7 and version 6. Please refer to the [Agent user documentation](https://docs.datadoghq.com/agent/) for information about differences between Agent v5, Agent v6 and Agent v7. Additionally, we provide a list of prepackaged binaries for an easy install process [here](https://app.datadoghq.com/fleet/install-agent/latest?platform=overview).\n\n## Documentation\n\nThe [developer docs site](https://datadoghq.dev/datadog-agent/setup/) contains information about how to develop the Datadog Agent itself.\n\nThe source of the content is located under [the docs directory](docs) and may contain pages that are not yet published.\n\n## Contributing code\n\nYou'll find information and help on how to contribute code to this project under\n[the `docs/dev` directory](docs/dev) of the present repo.\n\n## License\n\nThe Datadog Agent user space components are licensed under the\n[Apache License, Version 2.0](LICENSE). The BPF code is licensed\nunder the [General Public License, Version 2.0](pkg/ebpf/c/COPYING).\n",
      "stars_today": 3
    },
    {
      "id": 179008173,
      "name": "android",
      "full_name": "home-assistant/android",
      "description": "Home Assistant Companion for Android",
      "html_url": "https://github.com/home-assistant/android",
      "stars": 3305,
      "forks": 861,
      "language": "Kotlin",
      "topics": [
        "android",
        "automotive",
        "compose",
        "hacktoberfest",
        "home-assistant",
        "home-automation",
        "kotlin",
        "open-source-app",
        "wear"
      ],
      "created_at": "2019-04-02T05:52:50Z",
      "updated_at": "2026-01-13T21:43:32Z",
      "pushed_at": "2026-01-13T21:43:29Z",
      "open_issues": 349,
      "owner": {
        "login": "home-assistant",
        "avatar_url": "https://avatars.githubusercontent.com/u/13844975?v=4"
      },
      "readme": "# Home Assistant Companion for Android\n\n[![Build Status](https://github.com/home-assistant/android/actions/workflows/onPush.yml/badge.svg)](https://github.com/home-assistant/android/actions/workflows/onPush.yml)  \n[![Play Store](https://img.shields.io/badge/Play%20Store-Download-blue?logo=google-play)](https://play.google.com/store/apps/details?id=io.homeassistant.companion.android)\n[![Play Store Beta](https://img.shields.io/badge/Play%20Store%20Beta-Download-blue?logo=google-play)](https://play.google.com/apps/testing/io.homeassistant.companion.android)\n[![Discord](https://img.shields.io/discord/330944238910963714?label=Discord&logo=discord)](https://discord.gg/c5DvZ4e)\n[![Stars](https://img.shields.io/github/stars/home-assistant/android?style=social)](https://github.com/home-assistant/android/stargazers)\n\nWelcome to the **Home Assistant Companion for Android**! This is the official Android app for [Home Assistant](https://www.home-assistant.io/), a powerful open-source home automation platform. Join us in building an app used by millions of users worldwide.\n\n---\n\n## Features\n\n- **Control Your Smart Home**: Seamlessly interact with your Home Assistant instance.\n- **Native Android Experience**: Leverage Android-specific features like widgets, notifications, and location tracking.\n- **Customizable**: Tailor the app to your needs with themes, dashboards, and more.\n- **Open Source**: Contribute to a project that empowers users to take control of their smart homes.\n\n## Get the app\n\n- **[Download from the Play Store](https://play.google.com/store/apps/details?id=io.homeassistant.companion.android)**  \n  Join the [Play Store Beta](https://play.google.com/apps/testing/io.homeassistant.companion.android) to test new features early.\n- **Other Stores**: The app is also available in other app stores.\n\n## Documentation\n\nLooking for help? Check out the [Home Assistant Companion Documentation](https://companion.home-assistant.io/) for detailed guides on using the app.\n\n## Report a bug or request a feature\n\nFound a bug or have an idea for a new feature? Let us know!  \n\n- **[Open a Bug Report](https://github.com/home-assistant/android/issues/new?template=Bug_report.md)**  \n- **[Request a Feature](https://github.com/home-assistant/android/issues/new?template=feature_request.md)**  \n\nWe appreciate your feedback and contributions to make the app even better!\n\n## Contributing\n\nWe are thrilled to welcome contributions from the community! This app exists thanks to the incredible efforts of the Home Assistant community. Whether you're fixing bugs, adding new features, or improving documentation, your contributions make a difference.\n\nEvery contribution, big or small, is greatly appreciated. Together, we can make the Home Assistant Companion for Android even better!\n\n### Getting started\n\n1. Read the [Developer Guide](https://developers.home-assistant.io/docs/android/).\n2. Fork the repository and create a branch for your changes.\n3. Submit a pull request and join the discussion!\n\n## Join the community\n\nConnect with other contributors and users in our vibrant **[Discord Community](https://discord.gg/c5DvZ4e)**: Join the **[#Android](https://discord.com/channels/330944238910963714/1346948551892009101)** channel to chat with developers and contributors.\n\n## Star the repository\n\nIf you find this project useful, consider giving it a star on GitHub!  \nIt helps others discover the project and motivates us to keep improving.\n\n<a href=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-history?repo_id=179008173\" target=\"_blank\" style=\"display: block\" align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-history/thumbnail.png?repo_id=179008173&image_size=auto&color_scheme=dark\" width=\"721\" height=\"auto\">\n    <img alt=\"Star History of home-assistant/android\" src=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-history/thumbnail.png?repo_id=179008173&image_size=auto&color_scheme=light\" width=\"721\" height=\"auto\">\n  </picture>\n</a>\n\n[![Home Assistant - A project from the Open Home Foundation](https://www.openhomefoundation.org/badges/home-assistant.png)](https://www.openhomefoundation.org/)\n",
      "stars_today": 3
    },
    {
      "id": 55336932,
      "name": "iOS",
      "full_name": "home-assistant/iOS",
      "description": ":iphone: Home Assistant for Apple platforms",
      "html_url": "https://github.com/home-assistant/iOS",
      "stars": 2068,
      "forks": 407,
      "language": "Swift",
      "topics": [
        "hacktoberfest",
        "home-assistant",
        "home-automation",
        "ios",
        "macos",
        "open-source-app",
        "swift"
      ],
      "created_at": "2016-04-03T08:28:34Z",
      "updated_at": "2026-01-13T15:06:08Z",
      "pushed_at": "2026-01-13T16:51:31Z",
      "open_issues": 177,
      "owner": {
        "login": "home-assistant",
        "avatar_url": "https://avatars.githubusercontent.com/u/13844975?v=4"
      },
      "readme": "Home Assistant for Apple Platforms\n=================\n\n[![TestFlight Beta invite](https://img.shields.io/badge/TestFlight-Beta-blue.svg)](https://www.home-assistant.io/ios/beta/)\n[![Download on the App Store](https://img.shields.io/itunes/v/1099568401.svg)](https://itunes.apple.com/app/home-assistant-open-source-home-automation/id1099568401)\n[![GitHub issues](https://img.shields.io/github/issues/home-assistant/iOS.svg?style=flat)](https://github.com/home-assistant/iOS/issues)\n[![License Apache 2.0](https://img.shields.io/badge/license-Apache%202.0-green.svg?style=flat)](https://github.com/home-assistant/iOS/blob/master/LICENSE)\n\n## Getting Started\n\nHome Assistant uses Bundler, Homebrew and Cocoapods to manage build dependencies. You'll need Xcode 26.2 (or later) which you can download from the [App Store](https://developer.apple.com/download/). You can get the app running using the following commands:\n\n```bash\ngit clone https://github.com/home-assistant/iOS.git\ncd iOS\n\n# you must do one of the following, but you do not need to do all of them:\n\n## install cocoapods via homebrew, use that\nbrew install cocoapods\n$(brew --prefix)/opt/ruby/bin/gem install cocoapods-acknowledgements\npod install --repo-update\n\n## install ruby via homebrew, use that\nbrew install ruby@3.1\n$(brew --prefix)/opt/ruby@3.1/bin/bundle install\n$(brew --prefix)/opt/ruby@3.1/bin/bundle exec pod install --repo-update\n\n## install ruby via rbenv, use that\nbrew install rbenv ruby-build\nrbenv install\nbundle install\nbundle exec pod install --repo-update\n```\n\nOnce this completes, you can launch  `HomeAssistant.xcworkspace` and run the `App-Debug` scheme onto your simulator or iOS device.\n\n## Testing just the frontend\n\nTo just test the [frontend](https://github.com/home-assistant/frontend), you can use a simulator version built by our GitHub actions.\n\n1. Install Xcode from the [App Store](https://developer.apple.com/download/) making sure it's at least the version noted above. You do not need to install or run anything else.\n2. Launch the simulator at `/Applications/Xcode.app/Contents/Developer/Applications/Simulator.app` or in Xcode under the Xcode menu > Open Developer Tool.\n3. Open a simulator under File > Open Simulator. You can install older versions of iOS in Xcode's Components preferences.\n4. Download a simulator build from the [the GitHub action](https://github.com/home-assistant/iOS/actions/workflows/ci.yml?query=branch%3Amaster) under \"Artifacts.\"\n5. Drag the result `.app` on drop it on top of the simulator.\n6. Locate the app on the home screen and click it to launch.\n\nThe simulator behaves different than you might expect:\n\n| Action | Effect |\n| -- | -- |\n| Click | Tap |\n| Click & drag | Scroll |\n| Hold ‚å• | Add a second touch point |\n| Hold ‚áß‚å• | Move both touch points |\n| ‚åò‚Üê, ‚åò‚Üí | Rotate |\n| ‚åòS | Take screenshot |\n| ‚åòR | Record video |\n| ‚åòK | Toggle software keyboard |\n\nYou can now debug the WebView in this simulator build using Safari's Web Inspector:\n\n1. Make sure \"Show Develop menu in menu bar\" is enabled in Safari's Advanced preferences.\n2. Under the Develop menu, expand the \"Simulator\" menu for the simulator you've opened.\n3. Choose the WebView you want to inspect. A new window will open.\n\n## Code Signing\n\nAlthough the app is set up to use Automatic provisioning for Debug builds, you'll need to customize a few of the options. This is because the app makes heavy use of entitlements that require code signing, even for simulator builds.\n\nEdit the file `Configuration/HomeAssistant.overrides.xcconfig` (which will not exist by default and is ignored by git) and add the following:\n\n```bash\nDEVELOPMENT_TEAM = YourTeamID\nBUNDLE_ID_PREFIX = some.bundle.prefix\n```\n\nXcode should generate provisioning profiles in your Team ID and our configuration will disable features your team doesn't have like Critical Alerts. You can find your Team ID on Apple's [developer portal](https://developer.apple.com/account); it looks something like `ABCDEFG123`.\n\n## Code style\n\nLinters run as part of Pull Request checks. Additionally, some linting requirements can be autocorrected.\n\n```bash\n# checks for linting problems, doesn't fix\nbundle exec fastlane lint\n# checks for linting problems and fixes them\nbundle exec fastlane autocorrect\n```\n\nIn the Xcode project, the autocorrectable linters will not modify your source code but will provide warnings. This project uses several linters:\n\n- [SwiftFormat](https://github.com/nicklockwood/SwiftFormat)\n- [SwiftLint](https://github.com/realm/swiftlint) (for things SwiftFormat doesn't automate)\n- [Rubocop](https://rubocop.org) (largely for Fastlane)\n- [YamlLint](https://yamllint.readthedocs.io/en/stable/index.html) (largely for GitHub Actions)\n\n## Continuous Integration\n\nWe use [Github Actions](https://github.com/home-assistant/iOS/actions) alongside [Fastlane](https://fastlane.tools/) to perform continuous integration both by unit testing and deploying to [App Store Connect](https://appstoreconnect.apple.com). Mac Developer ID builds are available as an artifact on every build of master.\n\n### Environment variables\n\nFastlane scripts read from the environment or `.env` file for configuration like team IDs. See [`.env.sample`](https://github.com/home-assistant/iOS/blob/master/.env.sample) for available values.\n\n### Deployment\n\nAlthough all the deployment is done through Github Actions, you can do it manually through [Fastlane](https://github.com/home-assistant/iOS/blob/master/fastlane/README.md):\n\n### Deployment to App Store Connect\n\n```bash\n# creates the builds and uploads to the app store\n# each save their artifacts to build/\nbundle exec fastlane mac build\nbundle exec fastlane ios build\n```\n\n## Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md)\n\n## LICENSE\n\nApache-2.0\n\n## Credits\n\nThe format and some content of this README.md comes from the [SwipeIt](https://github.com/ivanbruel/SwipeIt) project.\n\n[![Home Assistant - A project from the Open Home Foundation](https://www.openhomefoundation.org/badges/home-assistant.png)](https://www.openhomefoundation.org/)\n",
      "stars_today": 3
    },
    {
      "id": 914013408,
      "name": "anikku",
      "full_name": "komikku-app/anikku",
      "description": "Free and open source anime watcher for Android",
      "html_url": "https://github.com/komikku-app/anikku",
      "stars": 609,
      "forks": 22,
      "language": "Kotlin",
      "topics": [
        "android",
        "anime",
        "anime-downloader",
        "animetail",
        "animiru",
        "aniyomi",
        "kotlin"
      ],
      "created_at": "2025-01-08T19:27:30Z",
      "updated_at": "2026-01-13T15:29:14Z",
      "pushed_at": "2025-12-17T18:11:09Z",
      "open_issues": 63,
      "owner": {
        "login": "komikku-app",
        "avatar_url": "https://avatars.githubusercontent.com/u/160299335?v=4"
      },
      "readme": "<div align=\"center\">\n\n<a href=\"https://anikku-app.github.io\">\n    <img src=\"./.github/assets/icon.png\" alt=\"anikku logo\" title=\"anikku logo\" width=\"80\"/>\n</a>\n\n# Anikku [App](#)\n\n### Full-featured player, based on Aniyomi.\nDiscover and watch anime, cartoons, series, and more ‚Äì easier than ever on your Android device.\n\n| Releases | Preview |\n|----------|---------|\n| <div align=\"center\"> [![GitHub downloads](https://img.shields.io/github/downloads/komikku-app/anikku/latest/total?label=Latest%20Downloads&labelColor=27303D&color=0D1117&logo=github&logoColor=FFFFFF&style=flat)](https://github.com/komikku-app/anikku/releases/latest) [![GitHub downloads](https://img.shields.io/github/downloads/komikku-app/anikku/total?label=Total%20Downloads&labelColor=27303D&color=0D1117&logo=github&logoColor=FFFFFF&style=flat)](https://github.com/komikku-app/anikku/releases) [![Stable build](https://img.shields.io/github/actions/workflow/status/komikku-app/anikku/build_release.yml?labelColor=27303D&label=Stable&labelColor=06599d&color=043b69)](https://github.com/komikku-app/anikku/actions/workflows/build_release.yml) | <div align=\"center\"> [![GitHub downloads](https://img.shields.io/github/downloads/komikku-app/anikku-preview/latest/total?label=Latest%20Downloads&labelColor=27303D&color=0D1117&logo=github&logoColor=FFFFFF&style=flat)](https://github.com/komikku-app/anikku-preview/releases/latest) [![GitHub downloads](https://img.shields.io/github/downloads/komikku-app/anikku-preview/total?label=Total%20Downloads&labelColor=27303D&color=0D1117&logo=github&logoColor=FFFFFF&style=flat)](https://github.com/komikku-app/anikku-preview/releases) [![Preview build](https://img.shields.io/github/actions/workflow/status/komikku-app/anikku-preview/build_app.yml?labelColor=27303D&label=Preview&labelColor=2c2c47&color=1c1c39)](https://github.com/komikku-app/anikku-preview/actions/workflows/build_app.yml) |\n\n[![Discord](https://img.shields.io/discord/1242381704459452488.svg?label=&labelColor=6A7EC2&color=7389D8&logo=discord&logoColor=FFFFFF)](https://discord.gg/85jB7V5AJR)\n[![CI](https://img.shields.io/github/actions/workflow/status/komikku-app/anikku/build_push.yml?labelColor=27303D&label=CI)](https://github.com/komikku-app/anikku/actions/workflows/build_push.yml)\n[![License: Apache-2.0](https://img.shields.io/github/license/komikku-app/anikku?labelColor=27303D&color=0877d2)](/LICENSE)\n[![Translation status](https://hosted.weblate.org/widget/komikku-app/anikku/svg-badge.svg)](https://hosted.weblate.org/projects/komikku-app/anikku/)\n\n## Download\n\n[![Stable](https://img.shields.io/github/release/komikku-app/anikku.svg?maxAge=3600&label=Stable&labelColor=06599d&color=043b69)](https://github.com/komikku-app/anikku/releases/latest)\n[![Preview](https://img.shields.io/github/v/release/komikku-app/anikku-preview.svg?maxAge=3600&label=Preview&labelColor=2c2c47&color=1c1c39)](https://github.com/komikku-app/anikku-preview/releases/latest)\n\n*Requires Android 8.0 or higher.*\n\n[![Sponsor me on GitHub](https://custom-icon-badges.demolab.com/badge/-Sponsor-ea4aaa?style=for-the-badge&logo=heart&logoColor=white)](https://github.com/sponsors/cuong-tran \"Sponsor me on GitHub\")\n\n## Features\n\n![screenshots of app](./.github/readme-images/screens.png)\n\n<div align=\"left\">\n\n### Features include:\n\n* **Anikku**:\n  * `Anime Suggestions` automatically showing source-website's recommendations / suggestions / related to current entry for all sources.\n  * `Auto theme color` based on each entry's cover for entry View & Reader.\n  * `App custom theme` with `Color palettes` for endless color lover.\n  * `Bulk-favorite` multiple entries all at once.\n  * `Fast browsing` (for who with large library experiencing slow loading)\n  * Auto `2-way sync` progress with trackers.\n  * Support `Android TV`, `Fire TV`.\n  * From SY:\n    * `Anime Recommendations` showing community recommends from Anilist, MyAnimeList.\n    * Edit `Anime Info` manually, or fill data from MyAnimeList, Kitsu, Shikimori, Bangumi, Simkl.\n    * `Custom cover` with files or URL.\n    * `Feed tab`, where you can easily view the latest entries or saved search from multiple sources at same time.\n    * `Saving searches` & filters, can use them with `Feed-tab`\n    * `Pin anime` to top of Library with `Tag` sort.\n    * `Merge anime` allow merging separated anime/episodes into one entry.\n    * `Lewd filter`, hide the lewd anime in your library when you want to.\n    * `Tracking filter`, filter your tracked anime so you can see them or see non-tracked anime.\n    * `Search tracking` status in library.\n    * `Mass-migration` all your anime from one source to another at same time.\n    * `Dynamic Categories`, view the library in multiple ways.\n    * `Custom categories` for sources, liked the pinned sources, but you can make your own versions and put any sources in them.\n    * Cross device `Library sync` with SyncYomi & Google Drive.\n  * Anime `cover on Updates notification`.\n  * `Panorama cover` showing wide cover in full.\n  * `to-be-updated` screen: which entries are going to be checked with smart-update?\n  * `Update Error` screen & migrating them away.\n  * `Source & Language icon` on Library & various places. (Some language flags are not really accurate)\n  * `Grouped updates` in Update tab (inspired by J2K).\n  * Drag & Drop re-order `Categories`.\n  * Ability to `enable/disable repo`, with icon.\n  * `Search for sources` & Quick NSFW sources filter in Extensions, Browse & Migration screen.\n  * In-app `progress banner` shows Library syncing / Backup restoring / Library updating progress.\n  * Long-click to add/remove single entry to/from library, everywhere.\n  * Docking Watch/Resume button to left/right.\n  * Auto-install app update.\n  * Configurable interval to refresh entries from downloaded storage.\n  * And many more from same maintainer's app for Manga reader: [Komikku](https://github.com/komikku-app/komikku)\n* Aniyomi:\n  * Watching videos\n  * Local watching of downloaded content\n  * A configurable player built on mpv-android with multiple options and settings\n  * Tracker support: [MyAnimeList](https://myanimelist.net/), [AniList](https://anilist.co/), [Kitsu](https://kitsu.app/), [Simkl](https://simkl.in/), [Shikimori](https://shikimori.one), and [Bangumi](https://bgm.tv/)\n  * Categories to organize your library\n  * Create backups locally to watch offline or to your desired cloud service\n* Other forks' features:\n  * Torrent support (Needs right extensions) (@Diegopyl1209)\n  * Support for Cast functionality (Animetail)\n  * Group by tags in library (Kuukiyomi)\n  * Discord Rich Presence (Animiru, Kuukiyomi, Animetail)\n\n# Issues, Feature Requests and Contributing\n\nPull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.\n\n<details><summary>Issues</summary>\n\n[Website](https://anikku-app.github.io/)\n\n1. **Before reporting a new issue, take a look at the [FAQ](https://anikku-app.github.io/docs/faq/general), the [changelog](https://github.com/komikku-app/anikku/releases) and the already opened [issues](https://github.com/komikku-app/anikku/issues).**\n2. If you are unsure, ask here: [![Discord](https://img.shields.io/discord/1242381704459452488.svg?label=&labelColor=6A7EC2&color=7389D8&logo=discord&logoColor=FFFFFF)](https://discord.gg/85jB7V5AJR)\n\n</details>\n\n<details><summary>Bugs</summary>\n\n* Include version (More ‚Üí About ‚Üí Version)\n * If not latest, try updating, it may have already been solved\n * Preview version is equal to the number of commits as seen on the main page\n* Include steps to reproduce (if not obvious from description)\n* Include screenshot (if needed)\n* If it could be device-dependent, try reproducing on another device (if possible)\n* Don't group unrelated requests into one issue\n\nUse the [issue forms](https://github.com/komikku-app/anikku/issues/new/choose) to submit a bug.\n\n</details>\n\n<details><summary>Feature Requests</summary>\n\n* Write a detailed issue, explaining what it should do or how.\n* Include screenshot (if needed).\n</details>\n\n<details><summary>Contributing</summary>\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md).\n</details>\n\n<details><summary>Code of Conduct</summary>\n\nSee [CODE_OF_CONDUCT.md](./CODE_OF_CONDUCT.md).\n</details>\n\n</div>\n\n### Credits\n\nThank you to all the people who have contributed!\n\n<a href=\"https://github.com/komikku-app/anikku/graphs/contributors\">\n    <img src=\"https://contrib.rocks/image?repo=aniyomiorg/aniyomi\" alt=\"Anikku app contributors\" title=\"Anikku app contributors\" width=\"800\"/>\n</a>\n\n![Visitor Count](https://count.getloli.com/get/@komikku-app?theme=capoo-2)\n\n### Disclaimer\n\nThe developer(s) of this application does not have any affiliation with the content providers available, and this application hosts zero content.\n\n<div align=\"left\">\n\n## License\n\n<pre>\nCopyright ¬© 2015 Javier Tom√°s\nCopyright ¬© 2024 The Mihon Open Source Project\nCopyright ¬© 2024 The Aniyomi Open Source Project\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n</pre>\n\n</div>\n",
      "stars_today": 3
    },
    {
      "id": 248836530,
      "name": "scTenifoldKnk",
      "full_name": "cailab-tamu/scTenifoldKnk",
      "description": " R/MATLAB package to perform virtual knockout experiments on single-cell gene regulatory networks.",
      "html_url": "https://github.com/cailab-tamu/scTenifoldKnk",
      "stars": 122,
      "forks": 13,
      "language": "R",
      "topics": [
        "functional-genomics",
        "gene-function",
        "gene-knockout",
        "gene-regulatory-network",
        "virtual-knockout-experiments"
      ],
      "created_at": "2020-03-20T19:31:03Z",
      "updated_at": "2026-01-13T11:23:16Z",
      "pushed_at": "2025-09-16T19:17:04Z",
      "open_issues": 23,
      "owner": {
        "login": "cailab-tamu",
        "avatar_url": "https://avatars.githubusercontent.com/u/31963060?v=4"
      },
      "readme": "scTenifoldKnk\n=============\n\nA R/MATLAB/Python package to perform virtual knockout experiments on single-cell gene regulatory networks. **scTenifoldKnk** is a machine learning workflow that performs virtual knockout experiments using single-cell RNA sequencing (scRNAseq) data from wild-type (WT) control samples as input. Constructs a single-cell gene regulatory network (scGRN) and knocks out a target gene from the adjacency matrix of the WT scGRN by setting the gene‚Äôs outdegree edges to zero. **scTenifoldKnk** then compares the knocked out scGRN with the WT scGRN to identify differentially regulated genes, called virtual-knockout perturbed genes, which are used to assess the impact of the gene knockout and reveal the gene‚Äôs function in the analyzed cells.\n\nPython version of scTenifoldKnk is available at: https://github.com/qwerty239qwe/scTenifoldpy\n\nMATLAB version is available at: https://github.com/jamesjcai/scGEAToolbox\n\nInstall:\n-------\nYou can install **scTenifoldKnk/R** using the following command:\n\n```{R}\nlibrary(remotes)\ninstall_github('cailab-tamu/scTenifoldKnk')\nlibrary(scTenifoldKnk)\n```\n\nAvailable functions:\n--------------------\n\n|Code| Function |\n|:-|:-|\n|scTenifoldKnk|Perform virtual knockout experiments on single-cell gene regulatory networks|\n\nInput:\n--------\nThe required input for **scTenifoldKnk** is an expression matrix with genes in the rows and cells (barcodes) in the columns. Data is expected to be previously normalized or _not normalized_ if `QC = TRUE`.\n\nRunning time:\n--------\nThe running time of scTenifoldKnk is largely dependent on how long it takes to construct scGRNs from subsampled expression matrices. Time increases proportional to the number of cells and genes in the dataset used as input. Below is a table of running times under different scenarios:\n\n| Number of Cells | Number of Genes | Running Time |\n|-----------------|-----------------|--------------|\n| 300             | 1000            | 3.45 min     |\n| 1000            | 1000            | 4.25 min     |\n| 1000            | 5000            | 171.88 min (2 h 51.6 min) |\n| 2500            | 5000            | 175.29 min (2 h 55.3 min) |\n| 5000            | 5000            | 188.88 min (3 h 8.9 min) |\n| 5000            | 7500            | 189.51 min (3 h 9.5 min)  |\n| 7500            | 5000            | 615.45 min (10 h 15.5 min) |\n| 7500            | 7500            | 616.12 min (10 h 16.1 min)  |\n\n\nOutput:\n--------\nThe output of **scTenifoldKnk** is a list with 3 slots as follows: \n  * **tensorNetworks**: The computed weight-averaged denoised gene regulatory networks after CANDECOMP/PARAFAC (CP) tensor decomposition. It includes two slots with:\n    * **X**: The constructed network for the _X_ sample.\n    * **Y**: The constructed network for the _Y_ sample.\n  * **manifoldAlignment**: The generated low-dimensional features result of the non-linear manifold alignment. It is a data frame with _2 times the number of genes_ in the rows and _d_ (default= 2) dimensions in the columns\n  * **diffRegulation**: The results of the differential regulation analysis. It is a data frame with 6 columns as follows:\n    * **gene**: A character vector with the gene id identified from the manifoldAlignment output.\n    * **distance**: A numeric vector of the Euclidean distance computed between the coordinates of the same gene in both conditions.\n    * **Z**: A numeric vector of the Z-scores computed after Box-Cox power transformation.\n    * **FC**: A numeric vector of the FC computed with respect to the expectation.\n    * **p.value**: A numeric vector of the p-values associated to the fold-changes, probabilities are asigned as P[X > x] using the Chi-square distribution with one degree of freedom.\n    * **p.adj**: A numeric vector of adjusted p-values using Benjamini & Hochberg (1995) FDR correction.\n\n---\nThe function to plot the egocentric KO, the code is available at [https://github.com/dosorio/utilities/blob/master/singleCell/plotKO.R](https://github.com/dosorio/utilities/blob/master/singleCell/plotKO.R), it requires: The object out of Knk (as X), the gene to knockout (gKO).\n\n\n¬©Ô∏è The Texas A & M University System. All rights reserved.\n",
      "stars_today": 3
    },
    {
      "id": 49876476,
      "name": "shardingsphere",
      "full_name": "apache/shardingsphere",
      "description": "Empowering Data Intelligence with Distributed SQL for Sharding, Scalability, and Security Across All Databases.",
      "html_url": "https://github.com/apache/shardingsphere",
      "stars": 20622,
      "forks": 6911,
      "language": "Java",
      "topics": [
        "bigdata",
        "data-encryption",
        "data-pipeline",
        "database",
        "database-cluster",
        "database-gateway",
        "database-middleware",
        "distributed-database",
        "distributed-sql-database",
        "distributed-transaction",
        "encrypt",
        "mysql",
        "postgresql",
        "read-write-splitting",
        "shard",
        "sql"
      ],
      "created_at": "2016-01-18T12:49:26Z",
      "updated_at": "2026-01-13T21:27:09Z",
      "pushed_at": "2026-01-13T21:27:01Z",
      "open_issues": 372,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "## [Apache ShardingSphere - Enterprise Distributed Database Ecosystem](https://shardingsphere.apache.org/)\n\nBuilding the standards and ecosystem on top of heterogeneous databases, empowering enterprise data architecture transformation\n\n**Official Website:** [https://shardingsphere.apache.org/](https://shardingsphere.apache.org/)\n\n[![GitHub Release](https://img.shields.io/github/release/apache/shardingsphere.svg)](https://github.com/apache/shardingsphere/releases)\n[![Lines of Code](https://sonarcloud.io/api/project_badges/measure?project=apache_shardingsphere&metric=ncloc)](https://sonarcloud.io/summary/new_code?id=apache_shardingsphere)\n\n[![CI](https://github.com/apache/shardingsphere/actions/workflows/ci.yml/badge.svg)](https://github.com/apache/shardingsphere/actions/workflows/ci.yml)\n[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=apache_shardingsphere&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=apache_shardingsphere)\n[![Technical Debt](https://sonarcloud.io/api/project_badges/measure?project=apache_shardingsphere&metric=sqale_index)](https://sonarcloud.io/summary/new_code?id=apache_shardingsphere)\n[![Maintainability Rating](https://sonarcloud.io/api/project_badges/measure?project=apache_shardingsphere&metric=sqale_rating)](https://sonarcloud.io/summary/new_code?id=apache_shardingsphere)\n[![Security Rating](https://sonarcloud.io/api/project_badges/measure?project=apache_shardingsphere&metric=security_rating)](https://sonarcloud.io/summary/new_code?id=apache_shardingsphere)\n[![codecov](https://codecov.io/gh/apache/shardingsphere/branch/master/graph/badge.svg)](https://codecov.io/gh/apache/shardingsphere)\n\n[![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/5394/badge)](https://bestpractices.coreinfrastructure.org/projects/5394)\n\n[![Slack](https://img.shields.io/badge/%20Slack-ShardingSphere%20Channel-blueviolet)](https://join.slack.com/t/apacheshardingsphere/shared_invite/zt-sbdde7ie-SjDqo9~I4rYcR18bq0SYTg)\n[![Gitter](https://badges.gitter.im/shardingsphere/shardingsphere.svg)](https://gitter.im/shardingsphere/Lobby)\n\n[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/ShardingSphere.svg?style=social&label=Follow%20%40ShardingSphere)](https://twitter.com/ShardingSphere)\n\n<table style=\"width:100%\">\n    <tr>\n        <th>\n            <a href=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map?activity=stars&repo_id=49876476\" target=\"_blank\" style=\"display: block\" align=\"center\">\n                <picture>\n                    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map/thumbnail.png?activity=stars&repo_id=49876476&image_size=auto&color_scheme=dark\" width=\"721\" height=\"auto\">\n                    <img alt=\"Star Geographical Distribution of apache/shardingsphere\" src=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map/thumbnail.png?activity=stars&repo_id=49876476&image_size=auto&color_scheme=light\" width=\"721\" height=\"auto\">\n                </picture>\n            </a>\n        </th>\n        <th>\n            <a href=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map?activity=pull-request-creators&repo_id=49876476\" target=\"_blank\" style=\"display: block\" align=\"center\">\n                <picture>\n                    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map/thumbnail.png?activity=pull-request-creators&repo_id=49876476&image_size=auto&color_scheme=dark\" width=\"721\" height=\"auto\">\n                    <img alt=\"Pull Request Creator Geographical Distribution of apache/shardingsphere\" src=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map/thumbnail.png?activity=pull-request-creators&repo_id=49876476&image_size=auto&color_scheme=light\" width=\"721\" height=\"auto\">\n                </picture>\n            </a>\n        </th>\n        <th>\n            <a href=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map?activity=issue-creators&repo_id=49876476\" target=\"_blank\" style=\"display: block\" align=\"center\">\n                <picture>\n                    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map/thumbnail.png?activity=issue-creators&repo_id=49876476&image_size=auto&color_scheme=dark\" width=\"721\" height=\"auto\">\n                    <img alt=\"Issue Creator Geographical Distribution of apache/shardingsphere\" src=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map/thumbnail.png?activity=issue-creators&repo_id=49876476&image_size=auto&color_scheme=light\" width=\"721\" height=\"auto\">\n                </picture>\n            </a>\n        </th>\n    </tr>\n</table>\n\n### OVERVIEW\n\n<hr>\n\nApache ShardingSphere is positioned as **Database Plus**, a standard and ecosystem built on top of heterogeneous databases. As an operating system layer above databases, ShardingSphere does not create new databases but focuses on maximizing the computing capabilities of existing databases, providing unified data access and enhanced computing capabilities.\n\n**Database Plus Core Concept**: By building a standardized and scalable enhancement layer above databases, it makes heterogeneous databases as simple to use as a single database, providing unified governance capabilities and distributed computing capabilities for enterprise data architectures.\n\n**Connect, Enhance, and Pluggable** are the three core pillars of Apache ShardingSphere:\n\n- **Connect:** Building database upper-layer standards, quickly connecting applications with multi-modal heterogeneous databases through flexible adaptation of database protocols, SQL dialects, and storage formats, providing unified data access experience;\n\n- **Enhance:** As a database computing enhancement engine, transparently providing enterprise-grade capabilities including distributed computing (data sharding, readwrite-splitting, SQL federation), data security (encryption, masking, audit), traffic control (circuit breaker, rate limiting), and observability (monitoring, tracing, analysis);\n\n- **Pluggable:** Adopting a micro-kernel + 3-layer pluggable architecture to achieve complete decoupling of kernel, functional components, and ecosystem integration. Developers can flexibly customize unique data architecture solutions that meet enterprise needs, just like building with LEGO blocks.\n\n**Differentiation Advantages**:\n- **vs Distributed Databases**: More lightweight, protecting existing investments, avoiding vendor lock-in\n- **vs Traditional Middleware**: Richer features, more complete ecosystem, more flexible architecture\n- **vs Cloud Vendor Solutions**: Support multi-cloud deployment, avoid technology binding, autonomous and controllable\n\nShardingSphere became an [Apache](https://apache.org/index.html#projects-list) Top-Level Project on April 16, 2020, and has been adopted by [19,000+ projects](https://github.com/search?l=Maven+POM&q=shardingsphere+language%3A%22Maven+POM%22&type=Code) worldwide.\n\n### DUAL-ACCESS ARCHITECTURE DESIGN\n\n<hr>\n\nShardingSphere adopts a unique dual-access architecture design, providing two access ends - JDBC and Proxy - that can be deployed independently or in hybrid deployment, meeting diverse requirements for different scenarios.\n\n#### ShardingSphere-JDBC: Lightweight Access End\n\n**Positioning**: Lightweight Java framework, enhanced JDBC driver\n\n**Core Features**:\n- **Client-side direct connection**: Shares resources with applications, decentralized architecture\n- **High performance, low overhead**: Direct database connection with minimal performance loss\n- **Complete compatibility**: Compatible with all ORM frameworks (MyBatis, JPA, Hibernate, etc.)\n- **Zero additional deployment**: Provided as JAR package, no independent deployment and dependencies required\n\n**Use Cases**: High-performance Java applications, integrated deployment with business applications, pursuing ultimate performance\n\n#### ShardingSphere-Proxy: Enterprise Access End\n\n**Positioning**: Transparent database proxy, independently deployed server-side\n\n**Core Features**:\n- **Static entry point**: Independent deployment from applications, providing stable database access entry\n- **Heterogeneous language support**: Supports any MySQL/PostgreSQL protocol compatible client\n- **DBA friendly**: Database operation and maintenance management interface, convenient for O&M personnel\n- **Enterprise-grade features**: Supports cluster deployment, load balancing, failover\n\n**Use Cases**: Heterogeneous language environments, database operation and maintenance management, enterprise applications requiring unified access entry\n\n#### Hybrid Architecture Advantages\n\nBy hybridizing ShardingSphere-JDBC and ShardingSphere-Proxy with unified configuration through the same registry center, you can flexibly build application systems suitable for various scenarios:\n\n- **Architectural flexibility**: Architects can freely adjust the optimal system architecture\n- **Scenario adaptability**: Select the most suitable access method according to different business scenarios\n- **Unified management**: Single configuration, multi-end collaboration, simplifying O&M complexity\n- **Progressive evolution**: Support smooth evolution path from JDBC to Proxy\n\n### AI ABSTRACTION\n\n[![DeepWiki](https://img.shields.io/badge/DeepWiki-apache%2Fshardingsphere-blue.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAyCAYAAAAnWDnqAAAAAXNSR0IArs4c6QAAA05JREFUaEPtmUtyEzEQhtWTQyQLHNak2AB7ZnyXZMEjXMGeK/AIi+QuHrMnbChYY7MIh8g01fJoopFb0uhhEqqcbWTp06/uv1saEDv4O3n3dV60RfP947Mm9/SQc0ICFQgzfc4CYZoTPAswgSJCCUJUnAAoRHOAUOcATwbmVLWdGoH//PB8mnKqScAhsD0kYP3j/Yt5LPQe2KvcXmGvRHcDnpxfL2zOYJ1mFwrryWTz0advv1Ut4CJgf5uhDuDj5eUcAUoahrdY/56ebRWeraTjMt/00Sh3UDtjgHtQNHwcRGOC98BJEAEymycmYcWwOprTgcB6VZ5JK5TAJ+fXGLBm3FDAmn6oPPjR4rKCAoJCal2eAiQp2x0vxTPB3ALO2CRkwmDy5WohzBDwSEFKRwPbknEggCPB/imwrycgxX2NzoMCHhPkDwqYMr9tRcP5qNrMZHkVnOjRMWwLCcr8ohBVb1OMjxLwGCvjTikrsBOiA6fNyCrm8V1rP93iVPpwaE+gO0SsWmPiXB+jikdf6SizrT5qKasx5j8ABbHpFTx+vFXp9EnYQmLx02h1QTTrl6eDqxLnGjporxl3NL3agEvXdT0WmEost648sQOYAeJS9Q7bfUVoMGnjo4AZdUMQku50McDcMWcBPvr0SzbTAFDfvJqwLzgxwATnCgnp4wDl6Aa+Ax283gghmj+vj7feE2KBBRMW3FzOpLOADl0Isb5587h/U4gGvkt5v60Z1VLG8BhYjbzRwyQZemwAd6cCR5/XFWLYZRIMpX39AR0tjaGGiGzLVyhse5C9RKC6ai42ppWPKiBagOvaYk8lO7DajerabOZP46Lby5wKjw1HCRx7p9sVMOWGzb/vA1hwiWc6jm3MvQDTogQkiqIhJV0nBQBTU+3okKCFDy9WwferkHjtxib7t3xIUQtHxnIwtx4mpg26/HfwVNVDb4oI9RHmx5WGelRVlrtiw43zboCLaxv46AZeB3IlTkwouebTr1y2NjSpHz68WNFjHvupy3q8TFn3Hos2IAk4Ju5dCo8B3wP7VPr/FGaKiG+T+v+TQqIrOqMTL1VdWV1DdmcbO8KXBz6esmYWYKPwDL5b5FA1a0hwapHiom0r/cKaoqr+27/XcrS5UwSMbQAAAABJRU5ErkJggg==)](https://deepwiki.com/apache/shardingsphere)\n[![zread](https://img.shields.io/badge/Ask_Zread-_.svg?style=flat&color=00b0aa&labelColor=000000&logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTQuOTYxNTYgMS42MDAxSDIuMjQxNTZDMS44ODgxIDEuNjAwMSAxLjYwMTU2IDEuODg2NjQgMS42MDE1NiAyLjI0MDFWNC45NjAxQzEuNjAxNTYgNS4zMTM1NiAxLjg4ODEgNS42MDAxIDIuMjQxNTYgNS42MDAxSDQuOTYxNTZDNS4zMTUwMiA1LjYwMDEgNS42MDE1NiA1LjMxMzU2IDUuNjAxNTYgNC45NjAxVjIuMjQwMUM1LjYwMTU2IDEuODg2NjQgNS4zMTUwMiAxLjYwMDEgNC45NjE1NiAxLjYwMDFaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00Ljk2MTU2IDEwLjM5OTlIMi4yNDE1NkMxLjg4ODEgMTAuMzk5OSAxLjYwMTU2IDEwLjY4NjQgMS42MDE1NiAxMS4wMzk5VjEzLjc1OTlDMS42MDE1NiAxNC4xMTM0IDEuODg4MSAxNC4zOTk5IDIuMjQxNTYgMTQuMzk5OUg0Ljk2MTU2QzUuMzE1MDIgMTQuMzk5OSA1LjYwMTU2IDE0LjExMzQgNS42MDE1NiAxMy43NTk5VjExLjAzOTlDNS42MDE1NiAxMC42ODY0IDUuMzE1MDIgMTAuMzk5OSA0Ljk2MTU2IDEwLjM5OTlaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik0xMy43NTg0IDEuNjAwMUgxMS4wMzg0QzEwLjY4NSAxLjYwMDEgMTAuMzk4NCAxLjg4NjY0IDEwLjM5ODQgMi4yNDAxVjQuOTYwMUMxMC4zOTg0IDUuMzEzNTYgMTAuNjg1IDUuNjAwMSAxMS4wMzg0IDUuNjAwMUgxMy43NTg0QzE0LjExMTkgNS42MDAxIDE0LjM5ODQgNS4zMTM1NiAxNC4zOTg0IDQuOTYwMVYyLjI0MDFDMTQuMzk4NCAxLjg4NjY0IDE0LjExMTkgMS42MDAxIDEzLjc1ODQgMS42MDAxWiIgZmlsbD0iI2ZmZiIvPgo8cGF0aCBkPSJNNCAxMkwxMiA0TDQgMTJaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00IDEyTDEyIDQiIHN0cm9rZT0iI2ZmZiIgc3Ryb2tlLXdpZHRoPSIxLjUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIvPgo8L3N2Zz4K&logoColor=ffffff)](https://zread.ai/apache/shardingsphere)\n\n### DOCUMENTATIONüìú\n\n<hr>\n\n[![EN doc](https://img.shields.io/badge/document-English-blue.svg)](https://shardingsphere.apache.org/document/current/en/overview/)\n[![CN doc](https://img.shields.io/badge/ÊñáÊ°£-‰∏≠ÊñáÁâà-blue.svg)](https://shardingsphere.apache.org/document/current/cn/overview/)\n\nFor full documentation & more details, visit: [Docs](https://shardingsphere.apache.org/document/current/en/overview/)\n\n### CONTRIBUTIONüöÄüßëüíª\n\n<hr>\n\nFor guides on how to get started and setup your environment, contributor & committer guides, visit: [Contribution Guidelines](https://shardingsphere.apache.org/community/en/involved/)\n\n### Team\n\n<hr>\n\nWe deeply appreciate [community contributors](https://shardingsphere.apache.org/community/en/team) for their dedication to Apache ShardingSphere.\n\n##\n\n### COMMUNITY & SUPPORTüíùüñ§\n\n<hr>\n\n:link: [Mailing List](https://shardingsphere.apache.org/community/en/involved/subscribe/). Best for: Apache community updates, releases, changes.\n\n:link: [GitHub Issues](https://github.com/apache/shardingsphere/issues). Best for: larger systemic questions/bug reports or anything development related.\n\n:link: [GitHub Discussions](https://github.com/apache/shardingsphere/discussions). Best for: technical questions & support, requesting new features, proposing new features.\n\n:link: [Slack channel](https://join.slack.com/t/apacheshardingsphere/shared_invite/zt-sbdde7ie-SjDqo9~I4rYcR18bq0SYTg). Best for: instant communications and online meetings, sharing your applications.\n\n:link: [Twitter](https://twitter.com/ShardingSphere). Best for: keeping up to date on everything ShardingSphere.\n\n:link: [LinkedIn](https://www.linkedin.com/showcase/apache-shardingsphere/e). Best for: professional networking and career development with other ShardingSphere contributors.\n\n##\n\n### PROJECT STATUS\n\n<hr>\n\n:white_check_mark: **Version 5.5.3-SNAPSHOT**: Actively under development :tada:\n\nüîó For the release notes, follow this link to the relevant [GitHub page](https://github.com/apache/shardingsphere/blob/master/RELEASE-NOTES.md).\n\n:soon: **Version 5.5.3**\n\nWe are currently developing version 5.5.3, which includes multiple security enhancements and performance optimizations.\nKeep an eye on the [milestones page](https://github.com/apache/shardingsphere/milestones) of this repo for the latest development progress.\n\n[comment]: <> (##)\n\n[comment]: <> (### NIGHTLY BUILDS:)\n\n[comment]: <> (<hr>)\n\n[comment]: <> (A nightly build of ShardingSphere from the latest master branch is available. )\n\n[comment]: <> (The package is updated daily and is available [here]&#40;http://117.48.121.24:8080&#41;.)\n\n[comment]: <> (##)\n\n[comment]: <> (**‚ÄºÔ∏è Notice:**)\n\n[comment]: <> (<hr>)\n\n[comment]: <> (Use this nightly build at your own risk! )\n\n[comment]: <> (The branch is not always fully tested. )\n\n[comment]: <> (The nightly build may contain bugs, and there may be new features added which may cause problems with your environment. )\n\n##\n\n### TECHNICAL ARCHITECTURE EVOLUTION\n\n<hr>\n\nApache ShardingSphere adopts a micro-kernel + 3-layer pluggable architecture, achieving complete decoupling of the kernel, functional components, and ecosystem integration, providing developers with ultimate flexibility and extensibility.\n\n#### Micro-Kernel + 3-Layer Pluggable Model\n\n**Core Layer**:\n- Query optimizer: Intelligent SQL routing and execution plan optimization\n- Distributed transaction: ACID transaction guarantees and consistency coordination\n- Execution engine: Efficient distributed execution and result aggregation\n\n**Feature Layer**:\n- Data sharding, readwrite-splitting, federation query\n- Data encryption, data masking, SQL audit\n- Shadow database, observability, traffic control\n\n**Ecosystem Layer**:\n- Database protocol adaptation (MySQL, PostgreSQL, Oracle, etc.)\n- Registry center integration (ZooKeeper, ETCD, etc.)\n- Configuration management, service discovery, monitoring integration\n\n#### Technical Innovation Highlights\n\n**Complete Decoupling Architecture**:\n- Database types completely decoupled, supporting rapid integration of new databases\n- Functional modules completely decoupled, supporting on-demand feature combination\n\nApache ShardingSphere consists of two access ends - JDBC and Proxy - that can be deployed independently or in hybrid deployment, providing unified distributed database solutions for diverse application scenarios including Java isomorphism, heterogeneous languages, and cloud-native environments.\n\n### ShardingSphere-JDBC\n\n<hr>\n\n[![Maven Status](https://img.shields.io/maven-central/v/org.apache.shardingsphere/shardingsphere-jdbc.svg?color=green)](https://mvnrepository.com/artifact/org.apache.shardingsphere/shardingsphere-jdbc)\n\nA lightweight Java framework providing extra services at the Java JDBC layer. \nWith the client end connecting directly to the database, it provides services in the form of a jar and requires no extra deployment and dependence.\n\n:link: For more details, follow this [link to the official website](https://shardingsphere.apache.org/document/current/en/overview/#shardingsphere-jdbc).\n\n> **Note**: When using ShardingSphere-JDBC adapter, pay attention to your application's memory configuration. Antlr uses an internal cache to improve performance during SQL parsing. If your application has too many SQL templates, the cache will continue to grow, occupying a large amount of heap memory.\nAccording to feedback from the ANTLR official [issue#4232](https://github.com/antlr/antlr4/issues/4232), this issue has not yet been optimized. When connecting your application to ShardingSphere-JDBC, it is recommended to set a reasonable heap memory size using the `-Xmx` parameter to avoid OOM errors caused by insufficient memory.\n\n### ShardingSphere-Proxy\n\n<hr>\n\n[![Nightly-Download](https://img.shields.io/static/v1?label=nightly-builds&message=download&color=orange)](https://nightlies.apache.org/shardingsphere/)\n[![Download](https://img.shields.io/badge/release-download-orange.svg)](https://www.apache.org/dyn/closer.lua/shardingsphere/5.3.2/apache-shardingsphere-5.3.2-shardingsphere-proxy-bin.tar.gz)\n[![Docker Pulls](https://img.shields.io/docker/pulls/apache/shardingsphere-proxy.svg)](https://store.docker.com/community/images/apache/shardingsphere-proxy)\n\nA transparent database proxy, providing a database server that encapsulates the database binary protocol to support heterogeneous languages. \nFriendlier to DBAs, the MariaDB, MySQL and PostgreSQL version now provided can use any kind of terminal.\n\n:link: For more details, follow this [link to the official website](https://shardingsphere.apache.org/document/current/en/overview/#shardingsphere-proxy).\n\n### Hybrid Architecture\n\n<hr>\n\nShardingSphere-JDBC adopts a decentralized architecture, applicable to high-performance light-weight OLTP applications developed with Java. \nShardingSphere-Proxy provides static entry and all languages support, suitable for an OLAP application and sharding databases management and operation.\n\nThrough the combination of ShardingSphere-JDBC & ShardingSphere-Proxy together with a unified sharding strategy by the same registry center, the ShardingSphere ecosystem can build an application system suitable to all kinds of scenarios.\n\n:link: More details can be found following this [link to the official website](https://shardingsphere.apache.org/document/current/en/overview/#hybrid-architecture).\n\n##\n\n### CORE FEATURE MATRIX\n\n<hr>\n\n#### Distributed Database Core Capabilities\n- **Data Sharding**: Horizontal sharding, vertical sharding, custom sharding strategies, automatic sharding routing\n- **Read/Write Splitting**: Master-slave replication, load balancing, failover, read weight configuration\n- **Distributed Transaction**: XA transactions, BASE transactions, transaction propagation\n\n#### Data Security & Governance\n- **Data Encryption**: Field-level encryption, transparent encryption, key management, encryption algorithm support\n- **Data Masking**: Sensitive data protection, masking strategy customization, dynamic masking rules\n- **Access Control**: Fine-grained permissions, access control, SQL firewall, security policies\n\n#### Database Gateway Capabilities\n- **Heterogeneous Databases**: MySQL, PostgreSQL, Oracle, SQL Server, Firebird, etc.\n- **SQL Dialect Translation**: Cross-database SQL compatibility, dialect adaptation, syntax conversion\n- **Protocol Adaptation**: Database protocol conversion, multi-protocol support, communication optimization\n\n#### Full-link Stress Testing & Observability\n- **Shadow Database**: Stress testing data isolation, environment separation, real data simulation\n- **Observability**: Performance monitoring, distributed tracing, QoS analysis, metrics collection\n- **Traffic Analysis**: SQL performance analysis, traffic statistics, bottleneck identification\n\n#### Enterprise-grade Features\n- **High Availability**: Cluster deployment, fault recovery, service discovery, health checks\n- **Cloud Native**: Containerized deployment, Kubernetes integration, native image support\n- **Monitoring & Alerting**: Real-time monitoring, alert notifications, performance metrics, O&M dashboard\n\n##\n\n### Roadmap\n\n<hr>\n\n![Roadmap](https://shardingsphere.apache.org/document/current/img/roadmap_en.png)\n\n##\n\n### How to Build Apache ShardingSphere\n\n<hr>\n\nCheck out [Wiki](https://github.com/apache/shardingsphere/wiki) section for details on how to build Apache ShardingSphere and a full guide on how to get started and setup your local dev environment.\n\n##\n\n### Landscapes\n\n<hr>\n\n<p align=\"center\">\n<br/><br/>\n<img src=\"https://landscape.cncf.io/images/cncf-landscape-horizontal-color.svg\" width=\"165\"/>&nbsp;&nbsp;<img src=\"https://www.cncf.io/wp-content/uploads/2023/04/cncf-main-site-logo.svg\" width=\"200\"/>\n<br/><br/>\nApache ShardingSphere enriches the <a href=\"https://landscape.cncf.io/?category=app-definition-and-development&grouping=category\">CNCF CLOUD NATIVE Landscape</a>.\n</p>\n\n##\n",
      "stars_today": 2
    },
    {
      "id": 24420506,
      "name": "v8",
      "full_name": "v8/v8",
      "description": "The official mirror of the V8 Git repository",
      "html_url": "https://github.com/v8/v8",
      "stars": 24769,
      "forks": 4205,
      "language": "C++",
      "topics": [
        "compiler",
        "interpreter",
        "javascript",
        "javascript-engine",
        "virtual-machine"
      ],
      "created_at": "2014-09-24T15:24:30Z",
      "updated_at": "2026-01-14T00:07:09Z",
      "pushed_at": "2026-01-14T00:06:44Z",
      "open_issues": 6,
      "owner": {
        "login": "v8",
        "avatar_url": "https://avatars.githubusercontent.com/u/113781?v=4"
      },
      "readme": "V8 JavaScript Engine\n=============\n\nV8 is Google's open source JavaScript engine.\n\nV8 implements ECMAScript as specified in ECMA-262.\n\nV8 is written in C++ and is used in Google Chrome, the open source\nbrowser from Google.\n\nV8 can run standalone, or can be embedded into any C++ application.\n\nV8 Project page: https://v8.dev/docs\n\n\nGetting the Code\n=============\n\nCheckout [depot tools](http://www.chromium.org/developers/how-tos/install-depot-tools), and run\n\n        fetch v8\n\nThis will checkout V8 into the directory `v8` and fetch all of its dependencies.\nTo stay up to date, run\n\n        git pull origin\n        gclient sync\n\nFor fetching all branches, add the following into your remote\nconfiguration in `.git/config`:\n\n        fetch = +refs/branch-heads/*:refs/remotes/branch-heads/*\n        fetch = +refs/tags/*:refs/tags/*\n\n\nContributing\n=============\n\nPlease follow the instructions mentioned at\n[v8.dev/docs/contribute](https://v8.dev/docs/contribute).\n",
      "stars_today": 2
    },
    {
      "id": 19257422,
      "name": "questdb",
      "full_name": "questdb/questdb",
      "description": "QuestDB is a high performance, open-source, time-series database",
      "html_url": "https://github.com/questdb/questdb",
      "stars": 16555,
      "forks": 1527,
      "language": "Java",
      "topics": [
        "capital-markets",
        "cpp",
        "database",
        "financial-analysis",
        "grafana",
        "java",
        "kdb",
        "low-latency",
        "market-data",
        "olap",
        "parquet",
        "postgresql",
        "questdb",
        "real-time-analytics",
        "simd",
        "sql",
        "tick-data",
        "time-series",
        "time-series-database",
        "tsdb"
      ],
      "created_at": "2014-04-28T23:29:15Z",
      "updated_at": "2026-01-14T00:48:55Z",
      "pushed_at": "2026-01-14T00:42:44Z",
      "open_issues": 802,
      "owner": {
        "login": "questdb",
        "avatar_url": "https://avatars.githubusercontent.com/u/52297642?v=4"
      },
      "readme": "<div align=\"center\">\n  <a href=\"https://questdb.com/\" target=\"blank\"><img alt=\"QuestDB Logo\" src=\"https://questdb.com/img/questdb-logo-themed.svg\" width=\"305px\"/></a>\n</div>\n<p>&nbsp;</p>\n\n<p align=\"center\">\n  <a href=\"#contribute\">\n    <img src=\"https://img.shields.io/github/contributors/questdb/questdb\" alt=\"QuestDB open source contributors\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  English |\n  <a href=\"./i18n/README.zh-cn.md\">ÁÆÄ‰Ωì‰∏≠Êñá</a> |\n  <a href=\"./i18n/README.zh-hk.md\">ÁπÅÈ´î‰∏≠Êñá</a> |\n  <a href=\"./i18n/README.ar-dz.md\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a> |\n  <a href=\"./i18n/README.it-it.md\">Italiano</a> |\n  <a href=\"./i18n/README.ua-ua.md\">–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞</a> |\n  <a href=\"./i18n/README.es-es.md\">Espa√±ol</a> |\n  <a href=\"./i18n/README.pt.md\">Portugu√™s</a> |\n  <a href=\"./i18n/README.fr-fr.md\">Fran√ßais</a> |\n  <a href=\"./i18n/README.de-de.md\">Deutsch</a> |\n  <a href=\"./i18n/README.ja-ja.md\">Êó•Êú¨Ë™û</a> |\n  <a href=\"./i18n/README.ko-kr.md\">ÌïúÍµ≠Ïñ¥</a> |\n  <a href=\"./i18n/README.he-il.md\">◊¢◊ë◊®◊ô◊™</a> |\n  <a href=\"./i18n/README.nl-nl.md\">Nederlands</a> |\n  <a href=\"./i18n/README.tr-tr.md\">T√ºrk√ße</a> |\n  <a href=\"./i18n/README.hn-in.md\">‡§π‡§ø‡§Ç‡§¶‡•Ä</a> |\n  <a href=\"./i18n/README.vi-vn.md\">Ti·∫øng Vi·ªát</a> |\n  <a href=\"./i18n/README.ms-my.md\">Bahasa Melayu</a>\n</p>\n\n---\n\nQuestDB is an open-source time-series database offering blazingly fast ingestion\nand dynamic, low-latency SQL queries.\n\nQuestDB delivers a multi-tier storage engine (WAL ‚Üí native ‚Üí Parquet on object storage), \nand the core engine is implemented in zero-GC Java and C++; QuestDB Enterprise includes additional components in Rust.\n\nWe achieve high performance via a column-oriented storage model, parallelized\nvector execution, SIMD instructions, and low-latency techniques. In addition,\nQuestDB is hardware efficient, with quick setup and operational efficiency.\n\n> Ready to go? Jump to the\n> [Get started](#get-started) section.\n\n<p>&nbsp;</p>\n\n<div align=\"center\">\n  <a href=\"https://demo.questdb.com/\">\n    <img alt=\"QuestDB Web Console showing a SQL statement and query result\" src=\"https://raw.githubusercontent.com/questdb/questdb/master/.github/console.png\" width=\"900\" />\n  </a>\n  <p><em>QuestDB Web Console - click to launch demo</em></p>\n</div>\n\n<p>&nbsp;</p>\n\n## Benefits of QuestDB\n\nFeature highlights include:\n\n- Low-latency, high-throughput ingestion ‚Äî from single events to millions/sec\n- Low-latency SQL with time-series extensions (ASOF JOIN, SAMPLE BY, LATEST ON)\n- SIMD-accelerated, parallel execution\n- Multi-tier storage: WAL ‚Üí native columnar ‚Üí Parquet (time-partitioned and time-ordered)\n- Postgres protocol (PGwire) and REST API\n- Materialized views and n-dimensional arrays (incl. 2D arrays for order books)\n- Web console for queries and data management\n- Apache 2.0 open source and open formats ‚Äî no vendor lock-in\n- [Finance functions](https://questdb.com/docs/reference/function/finance/) and [orderbook analytics](https://questdb.com/docs/guides/order-book/)\n\nQuestDB excels with:\n\n- financial market data (tick data, trades, order books, OHLC)\n- Sensor/telemetry data with high data cardinality\n- real-time dashboards and monitoring\n\nAnd why use a time-series database?\n\nBeyond performance and efficiency, with a specialized time-series database, you\ndon't need to worry about:\n\n- out-of-order data\n- deduplication and exactly one semantics\n- Continuous streaming ingest with many concurrent queries\n- streaming data (low latency)\n- volatile and \"bursty\" data\n- adding new columns - change schema \"on the fly\" while streaming data\n\n## Try QuestDB, demo and dashboards\n\nThe [live, public demo](https://demo.questdb.com/) is provisioned with the latest\nQuestDB release and sample datasets:\n\n- Trades: live crypto trades with 30M+ rows per month (OKX exchange)\n- FX order book: live charts with orderbook FX pairs.\n- Trips: 10 years of NYC taxi trips with 1.6 billion rows\n\nWe also have some public, real-time demo dashboards using\nour [Grafana-native](https://questdb.com/docs/third-party-tools/grafana/) plugin:\n\n- [Real-time crypto trades:](https://questdb.com/dashboards/crypto/) executed\n  trades on OKX from more than 20 assets in real time\n- [FX order book:](https://questdb.com/dashboards/FX-orderbook/) live depth/imbalance charts for major FX pairs\n\n### QuestDB performance vs. other databases\n\nQuestDB performs very well in performance benchmarks compared to alternatives.\n\nFor deep dives into internals and performance, see the following blog posts:\n\n- [QuestDB vs InfluxDB](https://questdb.com/blog/2024/02/26/questdb-versus-influxdb/)\n- [QuestDB vs Kdb+](https://questdb.com/compare/questdb-vs-kdb/)\n- [QuestDB vs TimescaleDB](https://questdb.com/blog/timescaledb-vs-questdb-comparison/)\n- [QuestDB vs MongoDB](https://questdb.com/blog/mongodb-time-series-benchmark-review/)\n\nAs always, we encourage you to run your own benchmarks.\n\n<div align=\"center\">\n  <img alt=\"A chart comparing the ingestion rate of QuestDB, InfluxDB and TimescaleDB.\" src=\".github/readme-benchmark.png\" width=\"600\"/>\n</div>\n\n## Get started\n\nUse [Docker](https://www.docker.com/) to start quickly:\n\n```bash\ndocker run -p 9000:9000 -p 9009:9009 -p 8812:8812 questdb/questdb\n```\n\nOr macOS users can use Homebrew:\n\n```bash\nbrew install questdb\nbrew services start questdb\n```\n\n```bash\nquestdb start\nquestdb stop\n```\n\nAlternatively, to kickoff the full onboarding journey, start with our concise\n[quick start guide](https://questdb.com/docs/quick-start/).\n\n### First-party ingestion clients\n\nQuestDB clients for ingesting data via the InfluxDB Line Protocol:\n\n- [Python](https://questdb.com/docs/clients/ingest-python/)\n- [.NET](https://questdb.com/docs/clients/ingest-dotnet/)\n- [C/C++](https://questdb.com/docs/clients/ingest-c-and-cpp/)\n- [Go](https://questdb.com/docs/clients/ingest-go/)\n- [Java](https://questdb.com/docs/clients/java-ilp/)\n- [NodeJS](https://questdb.com/docs/clients/ingest-node/)\n- [Rust](https://questdb.com/docs/clients/ingest-rust/)\n\n### Connect to QuestDB\n\nInteract with QuestDB and your data via the following interfaces:\n\n- [Web Console](https://questdb.com/docs/web-console/) for an interactive SQL\n  editor and CSV import on port `9000`\n- [InfluxDB Line Protocol](https://questdb.com/docs/reference/api/ilp/overview/)\n  for streaming ingestion on port `9000`\n- [PostgreSQL Wire Protocol](https://questdb.com/docs/reference/api/postgres/)\n  for programmatic queries on port `8812`\n- [REST API](https://questdb.com/docs/reference/api/rest/) for CSV import and\n  cURL on port `9000`\n\n### Popular third-party tools\n\nPopular tools that integrate with QuestDB include:\n\n- [Kafka](https://questdb.com/docs/third-party-tools/kafka/)\n- [Redpanda](https://questdb.com/docs/third-party-tools/redpanda/)\n- [Grafana](https://questdb.com/docs/third-party-tools/grafana/)\n- [Polars](https://questdb.com/docs/third-party-tools/polars/)\n- [Pandas](https://questdb.com/docs/third-party-tools/pandas/)\n- [PowerBI](https://questdb.com/docs/third-party-tools/powerbi/)\n- [Superset](https://questdb.com/docs/third-party-tools/superset/)\n- [Apache Flink](https://questdb.com/docs/third-party-tools/flink/)\n- [Telegraf](https://questdb.com/docs/third-party-tools/telegraf/)\n- [MindsDB](https://questdb.com/docs/third-party-tools/mindsdb/)\n\n### End-to-end code scaffolds\n\nFrom streaming ingestion to visualization with Grafana, start with code\nscaffolds in from our\n[quickstart repository](https://github.com/questdb/questdb-quickstart).\n\n### Configure QuestDB for production workloads\n\nFind our\n[capacity planning](https://questdb.com/docs/deployment/capacity-planning/) to\nfine-tune QuestDB for production workloads.\n\n### QuestDB Enterprise\n\nFor secure operation at greater scale or within larger organizations.\n\nAdditional features include:\n\n- high Availablity and read replica(s)\n- multi-primary ingestion\n- cold storage integration\n- role-based access control\n- TLS encryption\n- native querying of Parquet files via object storage\n- support SLAs, enhanced monitoring and more\n\nVisit the [Enterprise page](https://questdb.com/enterprise/) for further details\nand contact information.\n\n## Additional resources\n\n### üìö Read the docs\n\n- [QuestDB documentation:](https://questdb.com/docs/) begin the journey\n- [Product roadmap:](https://github.com/orgs/questdb/projects/1/views/5) check\n  out our plan for upcoming releases\n- [Tutorials:](https://questdb.com/tutorial/) learn what's possible with QuestDB,\n  step by step\n\n### ‚ùì Get support\n\n- [Community Discourse forum:](https://community.questdb.com/) join technical\n  discussions, ask questions, and meet other users!\n- [Public Slack:](https://slack.questdb.com/) chat with the QuestDB team and\n  community members\n- [GitHub issues:](https://github.com/questdb/questdb/issues) report bugs or\n  issues with QuestDB\n- [Stack Overflow:](https://stackoverflow.com/questions/tagged/questdb) look for\n  common troubleshooting solutions\n\n### üö¢ Deploy QuestDB\n\n- [AWS AMI](https://questdb.com/docs/guides/aws-official-ami)\n- [Google Cloud Platform](https://questdb.com/docs/guides/google-cloud-platform)\n- [Official Docker image](https://questdb.com/docs/get-started/docker)\n- [DigitalOcean droplets](https://questdb.com/docs/guides/digitalocean)\n- [Kubernetes Helm charts](https://questdb.com/docs/guides/kubernetes)\n\n## Contribute\n\nContributions welcome!\n\nWe appreciate:\n\n- source code\n- documentation (see our\n  [documentation repository](https://github.com/questdb/documentation))\n- bug reports\n- feature requests or feedback.\n\nTo get started with contributing:\n\n- Have a look through GitHub issues labelled\n  \"[Good first issue](https://github.com/questdb/questdb/issues?q=is%3Aissue+is%3Aopen+label%3A%22Good+first+issue%22)\"\n- For Hacktoberfest, see the relevant\n  [labelled issues](https://github.com/questdb/questdb/issues?q=is%3Aissue+is%3Aopen+label%3Ahacktoberfest)\n- Read the\n  [contribution guide](https://github.com/questdb/questdb/blob/master/CONTRIBUTING.md)\n- For details on building QuestDB, see the\n  [build instructions](https://github.com/questdb/questdb/blob/master/core/README.md)\n- [Create a fork](https://docs.github.com/en/github/getting-started-with-github/fork-a-repo)\n  of QuestDB and submit a pull request with your proposed changes\n- Stuck? Join our [public Slack](https://slack.questdb.com/) for assistance\n\n‚ú® As a sign of our gratitude, we send QuestDB swagto our contributors!\n\nA big thanks goes to the following wonderful people who have contributed to\nQuestDB [emoji key](https://allcontributors.org/docs/en/emoji-key):\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/clickingbuttons\"><img src=\"https://avatars1.githubusercontent.com/u/43246297?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>clickingbuttons</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=clickingbuttons\" title=\"Code\">üíª</a> <a href=\"#ideas-clickingbuttons\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"#userTesting-clickingbuttons\" title=\"User Testing\">üìì</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ideoma\"><img src=\"https://avatars0.githubusercontent.com/u/2159629?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ideoma</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=ideoma\" title=\"Code\">üíª</a> <a href=\"#userTesting-ideoma\" title=\"User Testing\">üìì</a> <a href=\"https://github.com/questdb/questdb/commits?author=ideoma\" title=\"Tests\">‚ö†Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tonytamwk\"><img src=\"https://avatars2.githubusercontent.com/u/20872271?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>tonytamwk</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=tonytamwk\" title=\"Code\">üíª</a> <a href=\"#userTesting-tonytamwk\" title=\"User Testing\">üìì</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://sirinath.com/\"><img src=\"https://avatars2.githubusercontent.com/u/637415?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>sirinath</b></sub></a><br /><a href=\"#ideas-sirinath\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/suhorukov\"><img src=\"https://avatars1.githubusercontent.com/u/10332206?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>igor-suhorukov</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=igor-suhorukov\" title=\"Code\">üíª</a> <a href=\"#ideas-igor-suhorukov\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mick2004\"><img src=\"https://avatars1.githubusercontent.com/u/2042132?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>mick2004</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=mick2004\" title=\"Code\">üíª</a> <a href=\"#platform-mick2004\" title=\"Packaging/porting to new platform\">üì¶</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://rawkode.com\"><img src=\"https://avatars3.githubusercontent.com/u/145816?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>rawkode</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=rawkode\" title=\"Code\">üíª</a> <a href=\"#infra-rawkode\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">üöá</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://solidnerd.dev\"><img src=\"https://avatars0.githubusercontent.com/u/886383?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>solidnerd</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=solidnerd\" title=\"Code\">üíª</a> <a href=\"#infra-solidnerd\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">üöá</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://solanav.github.io\"><img src=\"https://avatars1.githubusercontent.com/u/32469597?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>solanav</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=solanav\" title=\"Code\">üíª</a> <a href=\"https://github.com/questdb/questdb/commits?author=solanav\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://shantanoo-desai.github.io\"><img src=\"https://avatars1.githubusercontent.com/u/12070966?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>shantanoo-desai</b></sub></a><br /><a href=\"#blog-shantanoo-desai\" title=\"Blogposts\">üìù</a> <a href=\"#example-shantanoo-desai\" title=\"Examples\">üí°</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://alexprut.com\"><img src=\"https://avatars2.githubusercontent.com/u/1648497?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>alexprut</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=alexprut\" title=\"Code\">üíª</a> <a href=\"#maintenance-alexprut\" title=\"Maintenance\">üöß</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lbowman\"><img src=\"https://avatars1.githubusercontent.com/u/1477427?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>lbowman</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=lbowman\" title=\"Code\">üíª</a> <a href=\"https://github.com/questdb/questdb/commits?author=lbowman\" title=\"Tests\">‚ö†Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://tutswiki.com/\"><img src=\"https://avatars1.githubusercontent.com/u/424822?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>chankeypathak</b></sub></a><br /><a href=\"#blog-chankeypathak\" title=\"Blogposts\">üìù</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/upsidedownsmile\"><img src=\"https://avatars0.githubusercontent.com/u/26444088?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>upsidedownsmile</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=upsidedownsmile\" title=\"Code\">üíª</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Nagriar\"><img src=\"https://avatars0.githubusercontent.com/u/2361099?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Nagriar</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=Nagriar\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/piotrrzysko\"><img src=\"https://avatars.githubusercontent.com/u/6481553?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>piotrrzysko</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=piotrrzysko\" title=\"Code\">üíª</a> <a href=\"https://github.com/questdb/questdb/commits?author=piotrrzysko\" title=\"Tests\">‚ö†Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mpsq/dotfiles\"><img src=\"https://avatars.githubusercontent.com/u/5734722?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>mpsq</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=mpsq\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/siddheshlatkar\"><img src=\"https://avatars.githubusercontent.com/u/39632173?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>siddheshlatkar</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=siddheshlatkar\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://yitaekhwang.com\"><img src=\"https://avatars.githubusercontent.com/u/6628444?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Yitaek</b></sub></a><br /><a href=\"#tutorial-Yitaek\" title=\"Tutorials\">‚úÖ</a> <a href=\"#example-Yitaek\" title=\"Examples\">üí°</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.gaboros.hu\"><img src=\"https://avatars.githubusercontent.com/u/19173947?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>gabor-boros</b></sub></a><br /><a href=\"#tutorial-gabor-boros\" title=\"Tutorials\">‚úÖ</a> <a href=\"#example-gabor-boros\" title=\"Examples\">üí°</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kovid-r\"><img src=\"https://avatars.githubusercontent.com/u/62409489?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kovid-r</b></sub></a><br /><a href=\"#tutorial-kovid-r\" title=\"Tutorials\">‚úÖ</a> <a href=\"#example-kovid-r\" title=\"Examples\">üí°</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://borowski-software.de/\"><img src=\"https://avatars.githubusercontent.com/u/8701341?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>TimBo93</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3ATimBo93\" title=\"Bug reports\">üêõ</a> <a href=\"#userTesting-TimBo93\" title=\"User Testing\">üìì</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://zikani.me\"><img src=\"https://avatars.githubusercontent.com/u/1501387?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>zikani03</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=zikani03\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jaugsburger\"><img src=\"https://avatars.githubusercontent.com/u/10787042?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>jaugsburger</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=jaugsburger\" title=\"Code\">üíª</a> <a href=\"#maintenance-jaugsburger\" title=\"Maintenance\">üöß</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.questdb.com\"><img src=\"https://avatars.githubusercontent.com/u/52114895?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>TheTanc</b></sub></a><br /><a href=\"#projectManagement-TheTanc\" title=\"Project Management\">üìÜ</a> <a href=\"#content-TheTanc\" title=\"Content\">üñã</a> <a href=\"#ideas-TheTanc\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://davidgs.com\"><img src=\"https://avatars.githubusercontent.com/u/2071898?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>davidgs</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Adavidgs\" title=\"Bug reports\">üêõ</a> <a href=\"#content-davidgs\" title=\"Content\">üñã</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://redalemeden.com\"><img src=\"https://avatars.githubusercontent.com/u/519433?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kaishin</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=kaishin\" title=\"Code\">üíª</a> <a href=\"#example-kaishin\" title=\"Examples\">üí°</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://questdb.com\"><img src=\"https://avatars.githubusercontent.com/u/7276403?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>bluestreak01</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=bluestreak01\" title=\"Code\">üíª</a> <a href=\"#maintenance-bluestreak01\" title=\"Maintenance\">üöß</a> <a href=\"https://github.com/questdb/questdb/commits?author=bluestreak01\" title=\"Tests\">‚ö†Ô∏è</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://patrick.spacesurfer.com/\"><img src=\"https://avatars.githubusercontent.com/u/29952889?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>patrickSpaceSurfer</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=patrickSpaceSurfer\" title=\"Code\">üíª</a> <a href=\"#maintenance-patrickSpaceSurfer\" title=\"Maintenance\">üöß</a> <a href=\"https://github.com/questdb/questdb/commits?author=patrickSpaceSurfer\" title=\"Tests\">‚ö†Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://chenrui.dev\"><img src=\"https://avatars.githubusercontent.com/u/1580956?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>chenrui333</b></sub></a><br /><a href=\"#infra-chenrui333\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">üöá</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://bsmth.de\"><img src=\"https://avatars.githubusercontent.com/u/43580235?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>bsmth</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=bsmth\" title=\"Documentation\">üìñ</a> <a href=\"#content-bsmth\" title=\"Content\">üñã</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Ugbot\"><img src=\"https://avatars.githubusercontent.com/u/2143631?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ugbot</b></sub></a><br /><a href=\"#question-Ugbot\" title=\"Answering Questions\">üí¨</a> <a href=\"#userTesting-Ugbot\" title=\"User Testing\">üìì</a> <a href=\"#talk-Ugbot\" title=\"Talks\">üì¢</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lepolac\"><img src=\"https://avatars.githubusercontent.com/u/6312424?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>lepolac</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=lepolac\" title=\"Code\">üíª</a> <a href=\"#tool-lepolac\" title=\"Tools\">üîß</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tiagostutz\"><img src=\"https://avatars.githubusercontent.com/u/3986989?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>tiagostutz</b></sub></a><br /><a href=\"#userTesting-tiagostutz\" title=\"User Testing\">üìì</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Atiagostutz\" title=\"Bug reports\">üêõ</a> <a href=\"#projectManagement-tiagostutz\" title=\"Project Management\">üìÜ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Lyncee59\"><img src=\"https://avatars.githubusercontent.com/u/13176504?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Lyncee59</b></sub></a><br /><a href=\"#ideas-Lyncee59\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"https://github.com/questdb/questdb/commits?author=Lyncee59\" title=\"Code\">üíª</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rrjanbiah\"><img src=\"https://avatars.githubusercontent.com/u/4907427?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>rrjanbiah</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Arrjanbiah\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sarunas-stasaitis\"><img src=\"https://avatars.githubusercontent.com/u/57004257?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>sarunas-stasaitis</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Asarunas-stasaitis\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/RiccardoGiro\"><img src=\"https://avatars.githubusercontent.com/u/60734967?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>RiccardoGiro</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3ARiccardoGiro\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/duggar\"><img src=\"https://avatars.githubusercontent.com/u/37486846?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>duggar</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Aduggar\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/postol\"><img src=\"https://avatars.githubusercontent.com/u/7983951?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>postol</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Apostol\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/petrjahoda\"><img src=\"https://avatars.githubusercontent.com/u/45359845?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>petrjahoda</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Apetrjahoda\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.turecki.net\"><img src=\"https://avatars.githubusercontent.com/u/1933165?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>t00</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3At00\" title=\"Bug reports\">üêõ</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/snenkov\"><img src=\"https://avatars.githubusercontent.com/u/13110986?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>snenkov</b></sub></a><br /><a href=\"#userTesting-snenkov\" title=\"User Testing\">üìì</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Asnenkov\" title=\"Bug reports\">üêõ</a> <a href=\"#ideas-snenkov\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/marregui\"><img src=\"https://avatars.githubusercontent.com/u/255796?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>marregui</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=marregui\" title=\"Code\">üíª</a> <a href=\"#ideas-marregui\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"#design-marregui\" title=\"Design\">üé®</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/bratseth\"><img src=\"https://avatars.githubusercontent.com/u/16574012?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>bratseth</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=bratseth\" title=\"Code\">üíª</a> <a href=\"#ideas-bratseth\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"#userTesting-bratseth\" title=\"User Testing\">üìì</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://medium.com/@wellytambunan/\"><img src=\"https://avatars.githubusercontent.com/u/242694?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>welly87</b></sub></a><br /><a href=\"#ideas-welly87\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://johnleung.com\"><img src=\"https://avatars.githubusercontent.com/u/20699?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>fuzzthink</b></sub></a><br /><a href=\"#ideas-fuzzthink\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"#userTesting-fuzzthink\" title=\"User Testing\">üìì</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nexthack\"><img src=\"https://avatars.githubusercontent.com/u/6803956?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>nexthack</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=nexthack\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/g-metan\"><img src=\"https://avatars.githubusercontent.com/u/88013490?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>g-metan</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Ag-metan\" title=\"Bug reports\">üêõ</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tim2skew\"><img src=\"https://avatars.githubusercontent.com/u/54268285?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>tim2skew</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Atim2skew\" title=\"Bug reports\">üêõ</a> <a href=\"#userTesting-tim2skew\" title=\"User Testing\">üìì</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ospqsp\"><img src=\"https://avatars.githubusercontent.com/u/84992434?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ospqsp</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Aospqsp\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/SuperFluffy\"><img src=\"https://avatars.githubusercontent.com/u/701177?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>SuperFluffy</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3ASuperFluffy\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nu11ptr\"><img src=\"https://avatars.githubusercontent.com/u/3615587?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>nu11ptr</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Anu11ptr\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/comunidadio\"><img src=\"https://avatars.githubusercontent.com/u/10286013?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>comunidadio</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Acomunidadio\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mugendi\"><img src=\"https://avatars.githubusercontent.com/u/5348246?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>mugendi</b></sub></a><br /><a href=\"#ideas-mugendi\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Amugendi\" title=\"Bug reports\">üêõ</a> <a href=\"https://github.com/questdb/questdb/commits?author=mugendi\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/paulwoods222\"><img src=\"https://avatars.githubusercontent.com/u/86227717?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>paulwoods222</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Apaulwoods222\" title=\"Bug reports\">üêõ</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mingodad\"><img src=\"https://avatars.githubusercontent.com/u/462618?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>mingodad</b></sub></a><br /><a href=\"#ideas-mingodad\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Amingodad\" title=\"Bug reports\">üêõ</a> <a href=\"https://github.com/questdb/questdb/commits?author=mingodad\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/houarizegai\"><img src=\"https://avatars.githubusercontent.com/houarizegai?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>houarizegai</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=houarizegai\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://scrapfly.io\"><img src=\"https://avatars.githubusercontent.com/u/1763341?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>jjsaunier</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Ajjsaunier\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/zanek\"><img src=\"https://avatars.githubusercontent.com/u/333102?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>zanek</b></sub></a><br /><a href=\"#ideas-zanek\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"#projectManagement-zanek\" title=\"Project Management\">üìÜ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Geekaylee\"><img src=\"https://avatars.githubusercontent.com/u/12583377?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Geekaylee</b></sub></a><br /><a href=\"#userTesting-Geekaylee\" title=\"User Testing\">üìì</a> <a href=\"#ideas-Geekaylee\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lg31415\"><img src=\"https://avatars.githubusercontent.com/u/3609384?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>lg31415</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Alg31415\" title=\"Bug reports\">üêõ</a> <a href=\"#projectManagement-lg31415\" title=\"Project Management\">üìÜ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://nulldev.xyz/\"><img src=\"https://avatars.githubusercontent.com/u/9571936?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>null-dev</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Anull-dev\" title=\"Bug reports\">üêõ</a> <a href=\"#projectManagement-null-dev\" title=\"Project Management\">üìÜ</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://ultd.io\"><img src=\"https://avatars.githubusercontent.com/u/12675427?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ultd</b></sub></a><br /><a href=\"#ideas-ultd\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"#projectManagement-ultd\" title=\"Project Management\">üìÜ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ericsun2\"><img src=\"https://avatars.githubusercontent.com/u/8866410?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ericsun2</b></sub></a><br /><a href=\"#ideas-ericsun2\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Aericsun2\" title=\"Bug reports\">üêõ</a> <a href=\"#projectManagement-ericsun2\" title=\"Project Management\">üìÜ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/giovanni-k-bonetti-2809345/\"><img src=\"https://avatars.githubusercontent.com/u/3451581?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>giovannibonetti</b></sub></a><br /><a href=\"#userTesting-giovannibonetti\" title=\"User Testing\">üìì</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Agiovannibonetti\" title=\"Bug reports\">üêõ</a> <a href=\"#projectManagement-giovannibonetti\" title=\"Project Management\">üìÜ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://wavded.com\"><img src=\"https://avatars.githubusercontent.com/u/26638?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>wavded</b></sub></a><br /><a href=\"#userTesting-wavded\" title=\"User Testing\">üìì</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Awavded\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://medium.com/@apechkurov\"><img src=\"https://avatars.githubusercontent.com/u/37772591?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>puzpuzpuz</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=puzpuzpuz\" title=\"Documentation\">üìñ</a> <a href=\"https://github.com/questdb/questdb/commits?author=puzpuzpuz\" title=\"Code\">üíª</a> <a href=\"#userTesting-puzpuzpuz\" title=\"User Testing\">üìì</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rstreics\"><img src=\"https://avatars.githubusercontent.com/u/50323347?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>rstreics</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=rstreics\" title=\"Code\">üíª</a> <a href=\"#infra-rstreics\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">üöá</a> <a href=\"https://github.com/questdb/questdb/commits?author=rstreics\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mariusgheorghies\"><img src=\"https://avatars.githubusercontent.com/u/84250061?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>mariusgheorghies</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=mariusgheorghies\" title=\"Code\">üíª</a> <a href=\"#infra-mariusgheorghies\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">üöá</a> <a href=\"https://github.com/questdb/questdb/commits?author=mariusgheorghies\" title=\"Documentation\">üìñ</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pswu11\"><img src=\"https://avatars.githubusercontent.com/u/48913707?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>pswu11</b></sub></a><br /><a href=\"#content-pswu11\" title=\"Content\">üñã</a> <a href=\"#ideas-pswu11\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"#design-pswu11\" title=\"Design\">üé®</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/insmac\"><img src=\"https://avatars.githubusercontent.com/u/1871646?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>insmac</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=insmac\" title=\"Code\">üíª</a> <a href=\"#ideas-insmac\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"#design-insmac\" title=\"Design\">üé®</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/eugenels\"><img src=\"https://avatars.githubusercontent.com/u/79919431?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>eugenels</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=eugenels\" title=\"Code\">üíª</a> <a href=\"#ideas-eugenels\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"#maintenance-eugenels\" title=\"Maintenance\">üöß</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/bziobrowski\"><img src=\"https://avatars.githubusercontent.com/u/26925920?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>bziobrowski</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=bziobrowski\" title=\"Code\">üíª</a> <a href=\"#projectManagement-bziobrowski\" title=\"Project Management\">üìÜ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Zapfmeister\"><img src=\"https://avatars.githubusercontent.com/u/20150586?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Zapfmeister</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=Zapfmeister\" title=\"Code\">üíª</a> <a href=\"#userTesting-Zapfmeister\" title=\"User Testing\">üìì</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mkaruza\"><img src=\"https://avatars.githubusercontent.com/u/3676457?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>mkaruza</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=mkaruza\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/DylanDKnight\"><img src=\"https://avatars.githubusercontent.com/u/17187287?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>DylanDKnight</b></sub></a><br /><a href=\"#userTesting-DylanDKnight\" title=\"User Testing\">üìì</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3ADylanDKnight\" title=\"Bug reports\">üêõ</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/enolal826\"><img src=\"https://avatars.githubusercontent.com/u/51820585?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>enolal826</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=enolal826\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/glasstiger\"><img src=\"https://avatars.githubusercontent.com/u/94906625?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>glasstiger</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=glasstiger\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://arijus.net\"><img src=\"https://avatars.githubusercontent.com/u/4284659?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>argshook</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=argshook\" title=\"Code\">üíª</a> <a href=\"#ideas-argshook\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"#design-argshook\" title=\"Design\">üé®</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Aargshook\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/amunra\"><img src=\"https://avatars.githubusercontent.com/u/1499096?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>amunra</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=amunra\" title=\"Code\">üíª</a> <a href=\"https://github.com/questdb/questdb/commits?author=amunra\" title=\"Documentation\">üìñ</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Aamunra\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://lamottsjourney.wordpress.com/\"><img src=\"https://avatars.githubusercontent.com/u/66742430?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>GothamsJoker</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=GothamsJoker\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kocko\"><img src=\"https://avatars.githubusercontent.com/u/862000?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kocko</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=kocko\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jerrinot\"><img src=\"https://avatars.githubusercontent.com/u/158619?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>jerrinot</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=jerrinot\" title=\"Code\">üíª</a> <a href=\"#ideas-jerrinot\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Ajerrinot\" title=\"Bug reports\">üêõ</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://ramiroberrelleza.com\"><img src=\"https://avatars.githubusercontent.com/u/475313?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>rberrelleza</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=rberrelleza\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Cobalt-27\"><img src=\"https://avatars.githubusercontent.com/u/34511059?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Cobalt-27</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=Cobalt-27\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/eschultz\"><img src=\"https://avatars.githubusercontent.com/u/390064?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>eschultz</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=eschultz\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/xinyi-qiao/\"><img src=\"https://avatars.githubusercontent.com/u/47307374?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>XinyiQiao</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=XinyiQiao\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://chenquan.me\"><img src=\"https://avatars.githubusercontent.com/u/20042193?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>terasum</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=terasum\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/hristovdeveloper\"><img src=\"https://avatars.githubusercontent.com/u/3893599?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>PlamenHristov</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=PlamenHristov\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tris0laris\"><img src=\"https://avatars.githubusercontent.com/u/57298792?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>tris0laris</b></sub></a><br /><a href=\"#blog-tris0laris\" title=\"Blogposts\">üìù</a> <a href=\"#ideas-tris0laris\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/HeZean\"><img src=\"https://avatars.githubusercontent.com/u/49837965?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>HeZean</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=HeZean\" title=\"Code\">üíª</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3AHeZean\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/iridess\"><img src=\"https://avatars.githubusercontent.com/u/104518201?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>iridess</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=iridess\" title=\"Code\">üíª</a> <a href=\"https://github.com/questdb/questdb/commits?author=iridess\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/selmanfaruky%C4%B1lmaz/\"><img src=\"https://avatars.githubusercontent.com/u/96119894?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>selmanfarukyilmaz</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Aselmanfarukyilmaz\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.donet5.com\"><img src=\"https://avatars.githubusercontent.com/u/12455385?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>donet5</b></sub></a><br /><a href=\"#ideas-donet5\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Adonet5\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Zahlii\"><img src=\"https://avatars.githubusercontent.com/u/218582?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Zahlii</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3AZahlii\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/salsasepp\"><img src=\"https://avatars.githubusercontent.com/u/4884807?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>salsasepp</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Asalsasepp\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/EmmettM\"><img src=\"https://avatars.githubusercontent.com/u/4196372?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>EmmettM</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3AEmmettM\" title=\"Bug reports\">üêõ</a> <a href=\"https://github.com/questdb/questdb/commits?author=EmmettM\" title=\"Tests\">‚ö†Ô∏è</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://allfactors.com\"><img src=\"https://avatars.githubusercontent.com/u/571328?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>robd003</b></sub></a><br /><a href=\"#ideas-robd003\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/AllenEdison\"><img src=\"https://avatars.githubusercontent.com/u/46532217?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>AllenEdison</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3AAllenEdison\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/CSharpDummy\"><img src=\"https://avatars.githubusercontent.com/u/7610502?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>CSharpDummy</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3ACSharpDummy\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/shimondoodkin\"><img src=\"https://avatars.githubusercontent.com/u/314464?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>shimondoodkin</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Ashimondoodkin\" title=\"Bug reports\">üêõ</a> <a href=\"#ideas-shimondoodkin\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.zsmart.tech/\"><img src=\"https://avatars.githubusercontent.com/u/40519768?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>huuhait</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Ahuuhait\" title=\"Bug reports\">üêõ</a> <a href=\"#ideas-huuhait\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://clickhouse.com/\"><img src=\"https://avatars.githubusercontent.com/u/18581488?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>alexey-milovidov</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Aalexey-milovidov\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://blog.suconghou.cn\"><img src=\"https://avatars.githubusercontent.com/u/4580719?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>suconghou</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Asuconghou\" title=\"Bug reports\">üêõ</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/allegraharris\"><img src=\"https://avatars.githubusercontent.com/u/89586969?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>allegraharris</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=allegraharris\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/oliver-daniel\"><img src=\"https://avatars.githubusercontent.com/u/17235417?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>oliver-daniel</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=oliver-daniel\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kerimsenturk5734\"><img src=\"https://avatars.githubusercontent.com/u/72925170?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kerimsenturk5734</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=kerimsenturk5734\" title=\"Documentation\">üìñ</a></td>\n    </tr>\n  </tbody>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n\nThis project adheres to the\n[all-contributors](https://github.com/all-contributors/all-contributors)\nspecification. Contributions of any kind are welcome!\n",
      "stars_today": 2
    },
    {
      "id": 1459486,
      "name": "ideavim",
      "full_name": "JetBrains/ideavim",
      "description": "IdeaVim ‚Äì A Vim engine for JetBrains IDEs",
      "html_url": "https://github.com/JetBrains/ideavim",
      "stars": 10100,
      "forks": 808,
      "language": "Kotlin",
      "topics": [
        "ideavim",
        "intellij",
        "intellij-platform",
        "intellij-plugin",
        "jb-official",
        "jetbrains",
        "jetbrains-ides",
        "kotlin",
        "vim"
      ],
      "created_at": "2011-03-09T15:22:27Z",
      "updated_at": "2026-01-13T09:03:32Z",
      "pushed_at": "2026-01-13T10:37:25Z",
      "open_issues": 18,
      "owner": {
        "login": "JetBrains",
        "avatar_url": "https://avatars.githubusercontent.com/u/878437?v=4"
      },
      "readme": "<img src=\"src/main/resources/META-INF/pluginIcon.svg\" width=\"80\" height=\"80\" alt=\"icon\" align=\"left\"/>\n\nIdeaVim\n===\n\n[![Official JetBrains Project][jb-official-svg]][jb-official]\n[![Contributions welcome][contributions-welcome-svg]][contributions-welcome]\n[![Downloads][plugin-downloads-svg]][plugin-repo]\n[![Rating][plugin-rating-svg]][plugin-repo]\n[![Version][plugin-version-svg]][plugin-repo]\n[![Gitter][gitter-svg]][gitter]\n[![codecov](https://codecov.io/gh/JetBrains/ideavim/branch/master/graph/badge.svg)](https://codecov.io/gh/JetBrains/ideavim)\n[![Twitter][twitter-svg]][twitter]\n\nIdeaVim is a Vim engine for JetBrains IDEs.\n\n##### Contact maintainers:\n* [Bug tracker](https://youtrack.jetbrains.com/issues/VIM)\n* [@IdeaVim](https://twitter.com/ideavim) on Twitter\n* [Chat on gitter](https://gitter.im/JetBrains/ideavim)\n* [IdeaVim Channel](https://jb.gg/bi6zp7) on [JetBrains Server](https://discord.gg/jetbrains)\n\n##### Resources:\n\n* [Plugin homepage](https://lp.jetbrains.com/ideavim/)\n* [Plugin on Marketplace](https://plugins.jetbrains.com/plugin/164-ideavim)\n* [Changelog](CHANGES.md)\n* [Continuous integration builds](https://ideavim.teamcity.com/)\n\n#### Compatibility\n\nIntelliJ IDEA, PyCharm, GoLand, CLion, PhpStorm, WebStorm, RubyMine, DataGrip, DataSpell, Rider, Cursive,\nAndroid Studio, and other [JetBrains IDEs](https://www.jetbrains.com/ides/).\n\nSetup\n------------\n\n- IdeaVim can be installed via `Settings | Plugins`.\nSee the [detailed instructions](https://www.jetbrains.com/help/idea/managing-plugins.html#).\n\n- Use `Tools | Vim` in the menu to enable or disable vim.\n\n- Use the `~/.ideavimrc` file as an analog of `~/.vimrc` ([learn more](#Files)). The XDG standard is supported, as well.\n\n- Shortcut conflicts can be resolved by using:\n     - On Linux & Windows: `File | Settings | Editor | Vim` & `File | Settings | Keymap`,\n     - On macOS: `Preferences | Editor | Vim` & `Preferences | Keymap`,\n     - Regular Vim mappings in the  `~/.ideavimrc` file.\n\nGet Early Access\n-------------------\n\nWould you like to try new features and fixes? Join the Early Access Program and\nreceive EAP builds as updates!  \n\n1. Click the  IdeaVim icon <img src=\"src/main/resources/META-INF/pluginIcon_noBorders.svg\" width=\"16\" height=\"16\" alt=\"icon\"/>\nin the status bar  | `Early Access Program` | `Subscribe to EAP`\n\n\nOr subscribe to EAP updates manually:\n\n1. Open `Settings | Plugins`\n2. Click the gear icon :gear:, select `Manage Plugin Repositories`, and add the following url:\n```\nhttps://plugins.jetbrains.com/plugins/eap/ideavim\n```\n\nSee [the changelog](CHANGES.md) for the list of unreleased features.\n\nIt is important to distinguish EAP builds from traditional pre-release software.\nPlease note that the quality of EAP versions may at times be way below even\nusual beta standards.\n\nYou can always leave your feedback with:\n* [@IdeaVim](https://twitter.com/ideavim) in Twitter\n* [Bug tracker](https://youtrack.jetbrains.com/issues/VIM)\n\n\nSummary of Supported Vim Features\n---------------------------------\n\nHere are some examples of supported vim features and commands:\n\n* Normal / insert / visual / select / etc. modes\n* Motion / deletion / change / window / etc. commands\n* Key mappings\n* Marks / Macros / Digraphs / Registers\n* Some [set commands](https://github.com/JetBrains/ideavim/wiki/set-commands)\n* Full Vim regexps for search and search/replace\n* Vim web help\n* `~/.ideavimrc` configuration file\n* Vim script, including some [builtin functions](vimscript-info/FUNCTIONS_INFO.MD)\n* IdeaVim plugins\n\nSee also:\n\n* [Top feature requests and bugs](https://youtrack.jetbrains.com/issues/VIM?q=%23Unresolved+sort+by%3A+votes)\n\nFiles\n-----\n\n* `~/.ideavimrc`\n    * Your IdeaVim-specific Vim initialization commands\n    \n<details>\n<summary><strong>Example</strong> (click to see)</summary>\n\n```vim\n\"\"\" Map leader to space ---------------------\nlet mapleader=\" \"\n\n\"\"\" Plugins  --------------------------------\nset surround\nset multiple-cursors\nset commentary\nset argtextobj\nset easymotion\nset textobj-entire\nset ReplaceWithRegister\n\n\"\"\" Plugin settings -------------------------\nlet g:argtextobj_pairs=\"[:],(:),<:>\"\n\n\"\"\" Common settings -------------------------\nset showmode\nset so=5\nset incsearch\nset nu\n\n\"\"\" Idea specific settings ------------------\nset ideajoin\nset ideastatusicon=gray\nset idearefactormode=keep\n\n\"\"\" Mappings --------------------------------\nmap <leader>f <Plug>(easymotion-s)\nmap <leader>e <Plug>(easymotion-f)\n\nmap <leader>d <Action>(Debug)\nmap <leader>r <Action>(RenameElement)\nmap <leader>c <Action>(Stop)\nmap <leader>z <Action>(ToggleDistractionFreeMode)\n\nmap <leader>s <Action>(SelectInProjectView)\nmap <leader>a <Action>(Annotate)\nmap <leader>h <Action>(Vcs.ShowTabbedFileHistory)\nmap <S-Space> <Action>(GotoNextError)\n\nmap <leader>b <Action>(ToggleLineBreakpoint)\nmap <leader>o <Action>(FileStructurePopup)\n```\n</details>\n\n<details>\n<summary><strong>Suggested options</strong> (click to see)</summary>\n\nHere is also a list of the suggested options from [defaults.vim](https://github.com/vim/vim/blob/master/runtime/defaults.vim)\n\n```vim\n\" Show a few lines of context around the cursor. Note that this makes the\n\" text scroll if you mouse-click near the start or end of the window.\nset scrolloff=5\n\n\" Do incremental searching.\nset incsearch\n\n\" Don't use Ex mode, use Q for formatting.\nmap Q gq\n```\n</details>\n\n\nYou can read your `~/.vimrc` file from `~/.ideavimrc` with this command:\n\n    source ~/.vimrc\n\nAlso note that if you have overridden the `user.home` JVM option, this\nwill affect where IdeaVim looks for your `.ideavimrc` file. For example, if you\nhave `-Duser.home=/my/alternate/home` then IdeaVim will source\n`/my/alternate/home/.ideavimrc` instead of `~/.ideavimrc`.\n\nAlternatively, you can set up initialization commands using [XDG](https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html) standard.\nPut your settings to `$XDG_CONFIG_HOME/ideavim/ideavimrc` file.\n\n\nIdeaVim Plugins\n--------------------\n\nSee [doc/IdeaVim Plugins.md](https://github.com/JetBrains/ideavim/wiki/IdeaVim-Plugins)\n\nExecuting IDE Actions\n---------------------\n\nIdeaVim adds various commands for listing and executing arbitrary IDE actions as\nEx commands or via `:map` command mappings:\n\n### Executing actions:\n* `<Action>({action_id})`\n    * For the mappings you can use a special `<Action>` keyword. Don't forget the parentheses.\n    * E.g. `map gh <Action>(ShowErrorDescription)`  <- execute hover on `gh`.\n    * :warning: Mappings to `<Action>` don't work with `noremap`. \n      If you know the case when it's needed, please [let us know](https://github.com/JetBrains/ideavim#contact-maintainers).\n* `:action {action_id}`\n    * Execute an action by `{action_id}`. Works from Ex command line.\n    * Please don't use `:action` in mappings. Use `<Action>` instead.\n\n### Finding action IDs:\n\n* IJ provides `IdeaVim: track action IDs` command to show the id of the executed actions.\n  This command can be found in \"Search everywhere\" (double `shift`).\n\n    <details>\n        <summary><strong>\"Track action IDs\" Details</strong> (click to see)</summary>\n        <picture>\n            <source media=\"(prefers-color-scheme: dark)\" srcset=\"assets/readme/track_action_dark.gif\">\n            <img src=\"assets/readme/track_action_light.gif\" alt=\"track action ids\"/>\n        </picture>\n    </details>\n\n\n* `:actionlist [pattern]`\n    * Find IDE actions by id or keymap pattern (E.g. `:actionlist extract`, `:actionlist <C-D`)\n\n##### Examples:\n\n```vim\n\" Map \\r to the Reformat Code action\n:map \\r <Action>(ReformatCode)\n\n\" Map <leader>d to start debug\n:map <leader>d <Action>(Debug)\n\n\" Map \\b to toggle the breakpoint on the current line\n:map \\b <Action>(ToggleLineBreakpoint)\n```\n\n##### Some popular actions:\n\n```\nShowHoverInfo - Quick Documentation and Error Description\nQuickImplementations - Quick Definition\n```\n\nVim Script\n------------\n\nIdeaVim can execute custom scripts that are written with Vim Script.\nAt the moment we support all language features, but not all of the built-in functions and options are supported.\n\nAdditionally, you may be interested in the\n[Vim Script Discussion](https://github.com/JetBrains/ideavim/discussions/357).\n\n\n### IDE specific options\n\nYou can evaluate the `has('ide')` function call and get `1` if it was called with IdeaVim or `0` if the function was called from Vim/NeoVim.  \nThe option `&ide` contains the name and edition of your IDE, for example, \"IntelliJ IDEA Ultimate Edition\".  \nTo see its value for the current IDE you are using, execute the `:echo &ide` command.  \nTo write an IDE-specific configuration, use Vim's regexp match operators `=~?` (case-insensitive) / `=~#`  (case-sensitive)\n\n**Example config:**\n\n```vim\n\" options and mappings that are supported by both Vim and IdeaVim\nset nu\nset relativenumber\n\nif has('ide')\n  \" mappings and options that exist only in IdeaVim\n  map <leader>f <Action>(GotoFile)\n  map <leader>g <Action>(FindInPath)\n  map <leader>b <Action>(Switcher)\n\n  if &ide =~? 'intellij idea'\n    if &ide =~? 'community'\n      \" some mappings and options for IntelliJ IDEA Community Edition\n    elseif &ide =~? 'ultimate'\n      \" some mappings and options for IntelliJ IDEA Ultimate Edition\n    endif\n  elseif &ide =~? 'pycharm'\n    \" PyCharm specific mappings and options\n  endif\nelse\n  \" some mappings for Vim/Neovim\n  nnoremap <leader>f <cmd>Telescope find_files<cr>\nendif\n```\n\n:gem: Contributing\n------------\n\nThe power of contributing drives IdeaVim :muscle:. Even small contributions matter!\n\nSee the contribution guide in [CONTRIBUTING.md](CONTRIBUTING.md) to start bringing your value to the project.\n\nüòé In 2025, we launched a rewards program. See the guide for details.\n\nAuthors\n-------\n\nSee [AUTHORS.md](AUTHORS.md)\nfor a list of authors and contributors.\n\nIdeaVim tips and tricks\n-------\n\n- Use the power of IJ and Vim:\n    - `set ideajoin` to enable join via the IDE. See the [examples](https://jb.gg/f9zji9).\n    - Make sure `ideaput` is enabled for `clipboard` to enable native IJ insertion in Vim.\n    - Sync IJ bookmarks and IdeaVim global marks: `set ideamarks` (works for marks with capital letters only)\n    - Check out more [ex commands](https://github.com/JetBrains/ideavim/wiki/set-commands).\n\n- Use your vim settings with IdeaVim. Put `source ~/.vimrc` in `~/.ideavimrc`.\n- Control the status bar icon via the [`ideastatusicon` option](https://github.com/JetBrains/ideavim/wiki/set-commands).\n- Not familiar with the default behaviour during a refactoring? See the [`idearefactormode` option](https://github.com/JetBrains/ideavim/wiki/set-commands).\n\nSome facts about Vim\n-------\n\nLet‚Äôs relax and have some fun now! Here are a few things we've found interesting during development\nand would like to share with you.\n\n- There are no such commands as `dd`, `yy`, or `cc`. For example, `dd` is not a separate command for deleting the line,\nbut a `d` command with a `d` motion.  \nWait, but there isn't a `d` motion in Vim! That‚Äôs right, and that‚Äôs why Vim has a dedicated set of commands\nfor which it checks whether the \n[command equals to motion](https://github.com/vim/vim/blob/759d81549c1340185f0d92524c563bb37697ea88/src/normal.c#L6468)\nand if so, it executes `_` motion instead.  \n`_` is an interesting motion that isn't even documented in vi, and it refers to the current line.\nSo, commands like `dd`, `yy`, and similar ones are simply translated to `d_`, `y_`, etc.\n[Here](https://github.com/vim/vim/blob/759d81549c1340185f0d92524c563bb37697ea88/src/normal.c#L6502)\nis the source of this knowledge.\n\n- `x`, `D`, and `&` are not separate commands either. They are synonyms of `dl`, `d$`, and `:s\\r`, respectively.\n[Here](https://github.com/vim/vim/blob/759d81549c1340185f0d92524c563bb37697ea88/src/normal.c#L5365)\nis the full list of synonyms.\n\n- You can read a [post](https://github.com/JetBrains/ideavim/wiki/how-many-modes-does-vim-have) about how modes work in Vim and IdeaVim.\n\n- Have you ever used `U` after `dd`? [Don't even try](https://github.com/vim/vim/blob/759d81549c1340185f0d92524c563bb37697ea88/src/ops.c#L874).\n\n- A lot of variables that refer to visual mode start with two uppercase letters, e.g. `VIsual_active`. [Some examples](https://github.com/vim/vim/blob/master/src/normal.c#L17).\n  As mentioned [here](https://vi.stackexchange.com/a/42885/12441), this was done this way to avoid the clash with X11.\n\n- Other [strange things](https://github.com/vim/vim/blob/759d81549c1340185f0d92524c563bb37697ea88/src/ex_docmd.c#L1845) from vi:\n    * \":3\"       jumps to line 3\n    * \":3|...\"   prints line 3\n    * \":|\"       prints current line\n\n- Vim script doesn't skip white space before comma. `F(a ,b)` => E475.\n\n- Fancy constants for [undolevels](https://vimhelp.org/options.txt.html#%27undolevels%27):\n  > The local value is set to -123456 when the global value is to be used.\n\n- Vi (not Vim) is a POSIX standard, and [has a spec](https://pubs.opengroup.org/onlinepubs/9699919799/utilities/vi.html)! Vim is mostly POSIX compliant when Vi compatibility is selected with the `'compatible'` option, but there are still some differences that can be changed with `'copoptions'`. The spec is interesting because it documents the behaviour of different commands in a stricter style than the user documentation, describing the current line and column after the command, for example. [More details can be found by reading `:help posix`](https://vimhelp.org/vi_diff.txt.html#posix).\n\n- The Vim documentation contains many easter eggs. We encounter them occasionally, but GitHub user mikesmithgh has compiled a substantial collection [here](https://github.com/mikesmithgh/vimpromptu).\n  - In addition to `:call err_teapot()`, which returns `E418: I'm a teapot`, there is also `:call err_teapot(1)`, which returns `E503: Coffee is currently not available`. Naturally, this is also supported in IdeaVim.\n\n- Insert mode has all `Ctrl` keys mapped, except `Ctrl-B`. In the documentation, it is marked as **\"CTRL-B in Insert\n  mode gone\"**. Call `:h i_CTRL-B-gone` in Vim to read why `Ctrl-B` was removed.\n\nLicense\n-------\n\nIdeaVim is licensed under the MIT license.\n\nThird-party components and licenses are listed in [ThirdPartyLicenses.md](ThirdPartyLicenses.md).\n\nAll releases before 2.0.0 were licensed under terms of GPL-2.0 or later.\nThe last commit before switch to MIT is 05852b07c6090ad40fde7d3cafe0b074604f7ac5.\nYou can read more about the license change here: https://github.com/JetBrains/ideavim/discussions/543\n\n\n<!-- Badges -->\n[jb-official]: https://confluence.jetbrains.com/display/ALL/JetBrains+on+GitHub\n[jb-official-svg]: https://jb.gg/badges/official.svg\n\n[plugin-repo]: https://plugins.jetbrains.com/plugin/164-ideavim\n[plugin-downloads-svg]: http://img.shields.io/jetbrains/plugin/d/IdeaVIM\n[plugin-rating-svg]: http://img.shields.io/jetbrains/plugin/r/rating/IdeaVIM\n[plugin-version-svg]: https://img.shields.io/jetbrains/plugin/v/ideavim?label=version\n\n[gitter-svg]: https://badges.gitter.im/JetBrains/ideavim.svg\n[gitter]: https://gitter.im/JetBrains/ideavim?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge\n\n[twitter]: https://twitter.com/ideavim\n[twitter-svg]: https://img.shields.io/twitter/follow/ideavim?label=twitter%20%40ideavim\n\n[contributions-welcome-svg]: http://img.shields.io/badge/contributions-welcome-brightgreen\n[contributions-welcome]: https://github.com/JetBrains/ideavim/blob/master/CONTRIBUTING.md\n",
      "stars_today": 2
    },
    {
      "id": 63882194,
      "name": "calico",
      "full_name": "projectcalico/calico",
      "description": "Cloud native networking and network security",
      "html_url": "https://github.com/projectcalico/calico",
      "stars": 6995,
      "forks": 1526,
      "language": "Go",
      "topics": [
        "cats",
        "cni",
        "cni-plugin",
        "ebpf",
        "host-protection",
        "identity-aware-policy",
        "k8s",
        "kubernetes",
        "kubernetes-networking",
        "kubernetes-windows",
        "network-policy",
        "networking",
        "observability",
        "openstack",
        "security",
        "windows",
        "xdp"
      ],
      "created_at": "2016-07-21T15:45:54Z",
      "updated_at": "2026-01-13T11:27:13Z",
      "pushed_at": "2026-01-13T18:02:25Z",
      "open_issues": 185,
      "owner": {
        "login": "projectcalico",
        "avatar_url": "https://avatars.githubusercontent.com/u/12304728?v=4"
      },
      "readme": "[![Go Report Card](https://goreportcard.com/badge/github.com/projectcalico/calico)](https://goreportcard.com/report/github.com/projectcalico/calico)\n[![ArtifactHub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/tigera-operator)](https://artifacthub.io/packages/helm/projectcalico/tigera-operator)\n[![License](https://img.shields.io/badge/license-Apache-blue.svg)](calico/LICENSE)\n[![GoPkg](https://pkg.go.dev/badge/k8s.io/kubernetes.svg)](https://pkg.go.dev/github.com/projectcalico/api)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/6064/badge)](https://bestpractices.coreinfrastructure.org/projects/6064)\n\n<div align=center>\n<h1>Calico</h1>\n<h2>\n<a href=\"https://projectcalico.docs.tigera.io/getting-started/kubernetes/quickstart\">Quickstart</a> |\n<a href=\"https://projectcalico.docs.tigera.io\">Docs</a> |\n<a href=\"CONTRIBUTING.md\">Contribute</a> |\n<a href=\"https://slack.projectcalico.org\">Slack</a> |\n<a href=\"https://github.com/projectcalico/calico/releases\">Releases</a>\n</h2>\n</div>\n\n## üêæ Welcome to Project Calico!\n\nProject Calico, created and maintained by [Tigera][tigera], is an open-source project with an active development and user community. Calico Open Source has grown to be the most widely adopted solution for container networking and security, powering 8M+ nodes daily across 166 countries.\n\n## üåü Why use Calico?\n\n- **Data Plane Choice**: eBPF, standard Linux, Windows, and VPP ‚Äî versatility in network solutions.\n- **Interoperability**: Works across multiple distros, multiple clouds, bare metal, and VMs.\n- **Optimized Performance**: Engineered for high speed and low CPU usage, maximizing your cluster investments.\n- **Scalable Architecture**: Grows seamlessly with your Kubernetes clusters without sacrificing performance.\n- **Advanced Security**: Get granular access controls and WireGuard encryption.\n- **Kubernetes Networking Policy Support**: Continually defining excellence in Kubernetes network policy standards and support.\n- **Vibrant Contributor Community**: Over 200 contributors from a wide array of global companies.\n- **Flexible networking**: An array of networking tools at your disposal, including BGP, VXLAN, service advertisement, and more.\n\n<div align=center>\n<img src=\"https://www.tigera.io/app/uploads/2024/02/Ecosystem_shrunken_2023.svg\">\n</div>\n\n## ü§ù Join the Calico Community\n\n- [Calico Big Cats][big-cats]: Become an ambassador and share your journey\n- [Community Meetings][community-meetings]: Engage and contribute\n- [Contribute on GitHub][first-issues]: Start with 'good first issues'\n- [Connect on Slack][slack]: Join the conversation with fellow contributors and our developers\n\n## üí° Contributing to Project Calico\n\n- [Get Started with Project Calico][get-started]\n- [Repositories][repos]\n- [Contribute to our docs][docs-contrib]\n- Documentation: [Dive into our training and resources][resources]\n- [Make Calico better][issues]\n\n## üõ†Ô∏è Projects We Maintain\n\n- [Calico Golang API][api]\n- [Calico operator][operator]\n- [VPP dataplane][vpp]\n- [Calico BIRD][bird]\n\n## üì¢ Stay Connected\n\n- Subscribe: [Join our newsletter][news]\n- [YouTube channel for updates & tutorials][youtube]\n- [Technical Blog][blog]\n- [Careers][join]: Passionate about open source? Join our team.\n\n[tigera]: https://www.tigera.io/\n[big-cats]: https://www.tigera.io/project-calico/calico-big-cats-ambassador-program/#meet-calico-big-cats\n[community-meetings]: https://calendar.google.com/calendar/u/0/embed?src=tigera.io_uunmavdev5ndovf0hc4frtl0i0@group.calendar.google.com\n[first-issues]: https://github.com/projectcalico/calico/labels/good%20first%20issue\n[slack]: https://slack.projectcalico.org/\n[get-started]: https://docs.tigera.io/calico/latest/about\n[repos]: https://github.com/orgs/projectcalico/repositories\n[docs-contrib]: https://github.com/projectcalico/calico/blob/master/CONTRIBUTING_DOCS.md\n[resources]: https://docs.tigera.io/calico/latest/about/training-resources\n[issues]: https://github.com/projectcalico/calico/issues\n[api]: https://github.com/projectcalico/api\n[operator]: https://github.com/tigera/operator\n[vpp]: https://github.com/projectcalico/vpp-dataplane\n[news]: https://www.tigera.io/project-calico/#:~:text=Join%20Calico%20Open%20Source%20community%20newsletter\n[youtube]: https://www.youtube.com/channel/UCFpTnXDNcBoXI4gqCDmegFA\n[blog]: https://www.tigera.io/blog/?_sft_category=technical-blog\n[join]: https://www.tigera.io/careers/\n[bird]: https://github.com/projectcalico/bird\n",
      "stars_today": 2
    },
    {
      "id": 38617,
      "name": "sqlcipher",
      "full_name": "sqlcipher/sqlcipher",
      "description": "SQLCipher is a standalone fork of SQLite that adds 256 bit AES encryption of database files and other security features.",
      "html_url": "https://github.com/sqlcipher/sqlcipher",
      "stars": 6963,
      "forks": 1357,
      "language": "C",
      "topics": [],
      "created_at": "2008-07-30T17:20:41Z",
      "updated_at": "2026-01-13T21:42:41Z",
      "pushed_at": "2025-12-08T15:25:58Z",
      "open_issues": 7,
      "owner": {
        "login": "sqlcipher",
        "avatar_url": "https://avatars.githubusercontent.com/u/649049?v=4"
      },
      "readme": "## SQLCipher\n\nSQLCipher is a standalone fork of the [SQLite](https://www.sqlite.org/) database library that adds 256 bit AES encryption of database files and other security features like:\n\n- on-the-fly encryption\n- tamper detection\n- memory sanitization\n- strong key derivation\n\nSQLCipher is based on SQLite and stable upstream release features are periodically integrated. While SQLCipher is maintained as a separate version of the source tree, the project minimizes alterations to core SQLite code whenever possible.\n\nSQLCipher is maintained by Zetetic, LLC, and additional information and documentation is available on the official [SQLCipher site](https://www.zetetic.net/sqlcipher/).\n\n## Features\n\n- Fast performance with as little as 5-15% overhead for encryption on many operations\n- 100% of data in the database file is encrypted\n- Good security practices (CBC mode, HMAC, key derivation)\n- Zero-configuration and application level cryptography\n- Support for multiple cryptographic providers\n\n## Compatibility\n\nSQLCipher maintains database format compatibility within the same major version number so an application on any platform can open databases created by any other application provided the major version of SQLCipher is the same between them. However, major version updates (e.g. from 3.x to 4.x) often include changes to default settings. This means that newer major versions of SQLCipher will not open databases created by older versions without using special settings. For example, SQLCipher 4 introduces many new performance and security enhancements. The new default algorithms, increased KDF iterations, and larger page size mean that SQLCipher 4 will not open databases created by SQLCipher 1.x, 2.x, or 3.x by default. Instead, an application would either need to migrate the older databases to use the new format or enable a special backwards-compatibility mode. The available options are described in SQLCipher's [upgrade documentation](https://discuss.zetetic.net/t/upgrading-to-sqlcipher-4/3283). \n\nSQLCipher is also compatible with standard SQLite databases. When a key is not provided, SQLCipher will behave just like the standard SQLite library. It is also possible to convert from a plaintext database (standard SQLite) to an encrypted SQLCipher database using [ATTACH and the sqlcipher_export() convenience function](https://discuss.zetetic.net/t/how-to-encrypt-a-plaintext-sqlite-database-to-use-sqlcipher-and-avoid-file-is-encrypted-or-is-not-a-database-errors/868).\n\n## Contributions\n\nThe SQLCipher team welcomes contributions to the core library. All contributions including pull requests and patches should be based on the `prerelease` branch, and must be accompanied by a [contributor agreement](https://www.zetetic.net/contributions/). We strongly encourage [discussion](https://discuss.zetetic.net/c/sqlcipher) of the proposed change prior to development and submission.\n\n## Compiling\n\nBuilding SQLCipher is similar to compiling a regular version of SQLite from source, with a few small exceptions. You must:\n\n 1. define `SQLITE_HAS_CODEC`\n 2. define `SQLITE_TEMP_STORE=2` or `SQLITE_TEMP_STORE=3` (or use `configure`'s --with-tempstore=yes option)\n 3. define `SQLITE_EXTRA_INIT=sqlcipher_extra_init` and `SQLITE_EXTRA_SHUTDOWN=sqlcipher_extra_shutdown`\n 4. define `SQLITE_THREADSAFE` to `1` or `2` (enabled automatically by `configure`)\n 2. compile and link with a supported cryptographic provider (OpenSSL, LibTomCrypt, CommonCrypto/Security.framework, or NSS)\n \nThe following examples demonstrate use of OpenSSL, which is a readily available provider on most Unix-like systems. Note that, in this example, `--with-tempstore=yes` is setting `SQLITE_TEMP_STORE=2` for the build, and `SQLITE_THREADSAFE` has a default value of `1`.\n\n```\n$ ./configure --with-tempstore=yes CFLAGS=\"-DSQLITE_HAS_CODEC -DSQLITE_EXTRA_INIT=sqlcipher_extra_init -DSQLITE_EXTRA_SHUTDOWN=sqlcipher_extra_shutdown\" \\\n\tLDFLAGS=\"-lcrypto\"\n$ make\n```\n\n## Testing\n\nThe full SQLite test suite will not complete successfully when using SQLCipher. In some cases encryption interferes with low-level tests that require access to database file data or features which are unsupported by SQLCipher. Those tests that are intended to support encryption are intended for non-SQLCipher implementations. In addition, because SQLite tests are not always isolated, if one test fails it can trigger a domino effect with other failures in later steps.\n\nAs a result, the SQLCipher package includes it's own independent tests that exercise and verify the core functionality of the SQLCipher extensions. This test suite is intended to provide an abbreviated verification of SQLCipher's internal logic; it does not perform an exhaustive test of the SQLite database system as a whole or verify functionality on specific platforms. Because SQLCipher is based on stable upstream builds of SQLite, it is considered a basic assumption that the core SQLite library code is operating properly (the SQLite core is almost untouched in SQLCipher). Thus, the additional SQLCipher-specific test provide the requisite verification that the library is operating as expected with SQLCipher's security features enabled.\n\nTo run SQLCipher specific tests, configure as described here and run the following to execute the tests and receive a report of the results:\n\n```\n$ ./configure --with-tempstore=yes --enable-fts5 CFLAGS=\"-DSQLITE_HAS_CODEC -DSQLITE_EXTRA_INIT=sqlcipher_extra_init -DSQLITE_EXTRA_SHUTDOWN=sqlcipher_extra_shutdown -DSQLCIPHER_TEST\" \\\n\tLDFLAGS=\"-lcrypto\"\n$ make testfixture\n$ ./testfixture test/sqlcipher.test\n```\n\n## Encrypting a database\n\nTo specify an encryption passphrase for the database via the SQL interface you \nuse a PRAGMA. The passphrase you enter is passed through PBKDF2 key derivation to\nobtain the encryption key for the database \n\n\tPRAGMA key = 'passphrase';\n\nAlternately, you can specify an exact byte sequence using a blob literal. If you\nuse this method it is your responsibility to ensure that the data you provide is a\n64 character hex string, which will be converted directly to 32 bytes (256 bits) of \nkey data without key derivation.\n\n\tPRAGMA key = \"x'2DD29CA851E7B56E4697B0E1F08507293D761A05CE4D1B628663F411A8086D99'\";\n\nTo encrypt a database programmatically you can use the `sqlite3_key` function. \nThe data provided in `pKey` is converted to an encryption key according to the \nsame rules as `PRAGMA key`. \n\n\tint sqlite3_key(sqlite3 *db, const void *pKey, int nKey);\n\n`PRAGMA key` or `sqlite3_key` should be called as the first operation when a database is open.\n\n## Changing a database key\n\nTo change the encryption passphrase for an existing database you may use the rekey PRAGMA\nafter you've supplied the correct database password;\n\n\tPRAGMA key = 'passphrase'; -- start with the existing database passphrase\n\tPRAGMA rekey = 'new-passphrase'; -- rekey will reencrypt with the new passphrase\n\nThe hex rekey pragma may be used to rekey to a specific binary value\n\n\tPRAGMA rekey = \"x'2DD29CA851E7B56E4697B0E1F08507293D761A05CE4D1B628663F411A8086D99'\";\n\nThis can be accomplished programmatically by using sqlite3_rekey;\n  \n\tsqlite3_rekey(sqlite3 *db, const void *pKey, int nKey)\n\n## Support\n\nThe primary source for complete documentation (design, API, platforms, usage) is the SQLCipher website:\n\nhttps://www.zetetic.net/sqlcipher/documentation\n\nThe primary avenue for support and discussions is the SQLCipher discuss site:\n\nhttps://discuss.zetetic.net/c/sqlcipher\n\nIssues or support questions on using SQLCipher should be entered into the \nGitHub Issue tracker:\n\nhttps://github.com/sqlcipher/sqlcipher/issues\n\nPlease DO NOT post issues, support questions, or other problems to blog \nposts about SQLCipher as we do not monitor them frequently.\n\nIf you are using SQLCipher in your own software please let us know at \nsupport@zetetic.net!\n\n## Community Edition Open Source License\n\nCopyright (c) 2025, ZETETIC LLC\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n    * Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in the\n      documentation and/or other materials provided with the distribution.\n    * Neither the name of the ZETETIC LLC nor the\n      names of its contributors may be used to endorse or promote products\n      derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY ZETETIC LLC ''AS IS'' AND ANY\nEXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL ZETETIC LLC BE LIABLE FOR ANY\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n# Begin SQLite README.md\n\n<h1 align=\"center\">SQLite Source Repository</h1>\n\nThis repository contains the complete source code for the\n[SQLite database engine](https://sqlite.org/), including\nmany tests.  Additional tests and most documentation\nare managed separately.\n\nSee the [on-line documentation](https://sqlite.org/) for more information\nabout what SQLite is and how it works from a user's perspective.  This\nREADME file is about the source code that goes into building SQLite,\nnot about how SQLite is used.\n\n## Version Control\n\nSQLite sources are managed using\n[Fossil](https://fossil-scm.org/), a distributed version control system\nthat was specifically designed and written to support SQLite development.\nThe [Fossil repository](https://sqlite.org/src/timeline) contains the urtext.\n\nIf you are reading this on GitHub or some other Git repository or service,\nthen you are looking at a mirror.  The names of check-ins and\nother artifacts in a Git mirror are different from the official\nnames for those objects.  The official names for check-ins are\nfound in a footer on the check-in comment for authorized mirrors.\nThe official check-in name can also be seen in the `manifest.uuid` file\nin the root of the tree.  Always use the official name, not  the\nGit-name, when communicating about an SQLite check-in.\n\nIf you pulled your SQLite source code from a secondary source and want to\nverify its integrity, there are hints on how to do that in the\n[Verifying Code Authenticity](#vauth) section below.\n\n## Contacting The SQLite Developers\n\nThe preferred way to ask questions or make comments about SQLite or to\nreport bugs against SQLite is to visit the \n[SQLite Forum](https://sqlite.org/forum) at <https://sqlite.org/forum/>.\nAnonymous postings are permitted.\n\nIf you think you have found a bug that has security implications and\nyou do not want to report it on the public forum, you can send a private\nemail to drh at sqlite dot org.\n\n## Public Domain\n\nThe SQLite source code is in the public domain.  See\n<https://sqlite.org/copyright.html> for details. \n\nBecause SQLite is in the public domain, we do not normally accept pull\nrequests, because if we did take a pull request, the changes in that\npull request might carry a copyright and the SQLite source code would\nthen no longer be fully in the public domain.\n\n## Obtaining The SQLite Source Code\n\nSource code tarballs or ZIP archives are available at:\n\n  *  [Latest trunk check-in](https://sqlite.org/src/rchvdwnld/trunk).\n\n  *  [Latest release](https://sqlite.org/src/rchvdwnld/release)\n\n  *  For other check-ins, browse the\n     [project timeline](https://sqlite.org/src/timeline?y=ci) and\n     click on the check-in hash of the check-in you want to download.\n     On the resulting \"info\" page, click one of the options to the\n     right of the \"**Downloads:**\" label in the \"**Overview**\" section\n     near the top.\n\nTo access sources directly using [Fossil](https://fossil-scm.org/home),\nfirst install Fossil version 2.0 or later.\nSource tarballs and precompiled binaries for Fossil are available at\n<https://fossil-scm.org/home/uv/download.html>.  Fossil is\na stand-alone program.  To install, simply download or build the single\nexecutable file and put that file someplace on your $PATH or %PATH%.\nThen run commands like this:\n\n        mkdir -p ~/sqlite\n        cd ~/sqlite\n        fossil open https://sqlite.org/src\n\nThe initial \"fossil open\" command will take two or three minutes.  Afterwards,\nyou can do fast, bandwidth-efficient updates to the whatever versions\nof SQLite you like.  Some examples:\n\n        fossil update trunk             ;# latest trunk check-in\n        fossil update release           ;# latest official release\n        fossil update trunk:2024-01-01  ;# First trunk check-in after 2024-01-01\n        fossil update version-3.39.0    ;# Version 3.39.0\n\nOr type \"fossil ui\" to get a web-based user interface.\n\n## Compiling for Unix-like systems\n\nFirst create a directory in which to place\nthe build products.  It is recommended, but not required, that the\nbuild directory be separate from the source directory.  Cd into the\nbuild directory and then from the build directory run the configure\nscript found at the root of the source tree.  Then run \"make\".\n\nFor example:\n\n        apt install gcc make tcl-dev  ;#  Make sure you have all the necessary build tools\n        tar xzf sqlite.tar.gz         ;#  Unpack the source tree into \"sqlite\"\n        mkdir bld                     ;#  Build will occur in a sibling directory\n        cd bld                        ;#  Change to the build directory\n        ../sqlite/configure           ;#  Run the configure script\n        make sqlite3                  ;#  Builds the \"sqlite3\" command-line tool\n        make sqlite3.c                ;#  Build the \"amalgamation\" source file\n        make sqldiff                  ;#  Builds the \"sqldiff\" command-line tool\n        # Makefile targets below this point require tcl-dev\n        make tclextension-install     ;#  Build and install the SQLite TCL extension\n        make devtest                  ;#  Run development tests\n        make releasetest              ;#  Run full release tests\n        make sqlite3_analyzer         ;#  Builds the \"sqlite3_analyzer\" tool\n\nSee the makefile for additional targets.  For debugging builds, the\ncore developers typically run \"configure\" with options like this:\n\n        ../sqlite/configure --enable-all --enable-debug CFLAGS='-O0 -g'\n\nFor release builds, the core developers usually do:\n\n        ../sqlite/configure --enable-all\n\nAlmost all makefile targets require a \"tclsh\" TCL interpreter version 8.6 or\nlater.  The \"tclextension-install\" target and the test targets that follow\nall require TCL development libraries too.  (\"apt install tcl-dev\").  It is\nhelpful, but is not required, to install the SQLite TCL extension (the\n\"tclextension-install\" target) prior to running tests.  The \"releasetest\"\ntarget has additional requirements, such as \"valgrind\".\n\nOn \"make\" command-lines, one can add \"OPTIONS=...\" to specify additional\ncompile-time options over and above those set by ./configure.  For example,\nto compile with the SQLITE_OMIT_DEPRECATED compile-time option, one could say:\n\n        ./configure --enable-all\n        make OPTIONS=-DSQLITE_OMIT_DEPRECATED sqlite3\n\nThe configure script uses autoconf 2.61 and libtool.  If the configure\nscript does not work out for you, there is a generic makefile named\n\"Makefile.linux-gcc\" in the top directory of the source tree that you\ncan copy and edit to suit your needs.  Comments on the generic makefile\nshow what changes are needed.\n\n## Compiling for Windows Using MSVC\n\nOn Windows, everything can be compiled with MSVC.\nYou will also need a working installation of TCL if you want to run tests.\nTCL is not required if you just want to build SQLite itself.\nSee the [compile-for-windows.md](doc/compile-for-windows.md) document for\nadditional information about how to install MSVC and TCL and configure your\nbuild environment.\n\nIf you want to run tests, you need to let SQLite know the location of your\nTCL library, using a command like this:\n\n        set TCLDIR=c:\\Tcl\n\nSQLite uses \"tclsh.exe\" as part of the build process, and so that\nprogram will need to be somewhere on your %PATH%.  SQLite itself\ndoes not contain any TCL code, but it does use TCL to run tests.\nYou may need to install TCL development\nlibraries in order to successfully complete some makefile targets.\nIt is helpful, but is not required, to install the SQLite TCL extension\n(the \"tclextension-install\" target) prior to running tests.\n\nBuild using Makefile.msc.  Example:\n\n        nmake /f Makefile.msc sqlite3.exe\n        nmake /f Makefile.msc sqlite3.c\n        nmake /f Makefile.msc sqldiff.exe\n        # Makefile targets below this point require TCL development libraries\n        nmake /f Makefile.msc tclextension-install\n        nmake /f Makefile.msc devtest\n        nmake /f Makefile.msc releasetest\n        nmake /f Makefile.msc sqlite3_analyzer.exe\n \nThere are many other makefile targets.  See comments in Makefile.msc for\ndetails.\n\nAs with the unix Makefile, the OPTIONS=... argument can be passed on the nmake\ncommand-line to enable new compile-time options.  For example:\n\n        nmake /f Makefile.msc OPTIONS=-DSQLITE_OMIT_DEPRECATED sqlite3.exe\n\n## Source Tree Map\n\n  *  **src/** - This directory contains the primary source code for the\n     SQLite core.  For historical reasons, C-code used for testing is\n     also found here.  Source files intended for testing begin with \"`test`\".\n     The `tclsqlite3.c` and `tclsqlite3.h` files are the TCL interface\n     for SQLite and are also not part of the core.\n\n  *  **test/** - This directory and its subdirectories contains code used\n     for testing.  Files that end in \"`.test`\" are TCL scripts that run\n     tests using an augmented TCL interpreter named \"testfixture\".  Use\n     a command like \"`make testfixture`\" (unix) or \n     \"`nmake /f Makefile.msc testfixture.exe`\" (windows) to build that\n     augmented TCL interpreter, then run individual tests using commands like\n     \"`testfixture test/main.test`\".  This test/ subdirectory also contains\n     additional C code modules and scripts for other kinds of testing.\n\n  *  **tool/** - This directory contains programs and scripts used to\n     build some of the machine-generated code that goes into the SQLite\n     core, as well as to build and run tests and perform diagnostics.\n     The source code to [the Lemon parser generator](./doc/lemon.html) is\n     found here.  There are also TCL scripts used to build and/or transform\n     source code files.  For example, the tool/mksqlite3h.tcl script reads\n     the src/sqlite.h.in file and uses it as a template to construct\n     the deliverable \"sqlite3.h\" file that defines the SQLite interface.\n\n  *  **ext/** - Various extensions to SQLite are found under this\n     directory.  For example, the FTS5 subsystem is in \"ext/fts5/\".\n     Some of these extensions (ex: FTS3/4, FTS5, RTREE) might get built\n     into the SQLite amalgamation, but not all of them.  The\n     \"ext/misc/\" subdirectory contains an assortment of one-file extensions,\n     many of which are omitted from the SQLite core, but which are included\n     in the [SQLite CLI](https://sqlite.org/cli.html).\n     \n  *  **doc/** - Some documentation files about SQLite internals are found\n     here.  Note, however, that the primary documentation designed for\n     application developers and users of SQLite is in a completely separate\n     repository.  Note also that the primary API documentation is derived\n     from specially constructed comments in the src/sqlite.h.in file.\n\n### Generated Source Code Files\n\nSeveral of the C-language source files used by SQLite are generated from\nother sources rather than being typed in manually by a programmer.  This\nsection will summarize those automatically-generated files.  To create all\nof the automatically-generated files, simply run \"make target&#95;source\".\nThe \"target&#95;source\" make target will create a subdirectory \"tsrc/\" and\nfill it with all the source files needed to build SQLite, both\nmanually-edited files and automatically-generated files.\n\nThe SQLite interface is defined by the **sqlite3.h** header file, which is\ngenerated from src/sqlite.h.in, ./manifest.uuid, and ./VERSION.  The\n[Tcl script](https://www.tcl.tk) at tool/mksqlite3h.tcl does the conversion.\nThe manifest.uuid file contains the SHA3 hash of the particular check-in\nand is used to generate the SQLITE\\_SOURCE\\_ID macro.  The VERSION file\ncontains the current SQLite version number.  The sqlite3.h header is really\njust a copy of src/sqlite.h.in with the source-id and version number inserted\nat just the right spots. Note that comment text in the sqlite3.h file is\nused to generate much of the SQLite API documentation.  The Tcl scripts\nused to generate that documentation are in a separate source repository.\n\nThe SQL language parser is **parse.c** which is generated from a grammar in\nthe src/parse.y file.  The conversion of \"parse.y\" into \"parse.c\" is done\nby the [lemon](./doc/lemon.html) LALR(1) parser generator.  The source code\nfor lemon is at tool/lemon.c.  Lemon uses the tool/lempar.c file as a\ntemplate for generating its parser.\nLemon also generates the **parse.h** header file, at the same time it\ngenerates parse.c.\n\nThe **opcodes.h** header file contains macros that define the numbers\ncorresponding to opcodes in the \"VDBE\" virtual machine.  The opcodes.h\nfile is generated by scanning the src/vdbe.c source file.  The\nTcl script at ./mkopcodeh.tcl does this scan and generates opcodes.h.\nA second Tcl script, ./mkopcodec.tcl, then scans opcodes.h to generate\nthe **opcodes.c** source file, which contains a reverse mapping from\nopcode-number to opcode-name that is used for EXPLAIN output.\n\nThe **keywordhash.h** header file contains the definition of a hash table\nthat maps SQL language keywords (ex: \"CREATE\", \"SELECT\", \"INDEX\", etc.) into\nthe numeric codes used by the parse.c parser.  The keywordhash.h file is\ngenerated by a C-language program at tool mkkeywordhash.c.\n\nThe **pragma.h** header file contains various definitions used to parse\nand implement the PRAGMA statements.  The header is generated by a\nscript **tool/mkpragmatab.tcl**. If you want to add a new PRAGMA, edit\nthe **tool/mkpragmatab.tcl** file to insert the information needed by the\nparser for your new PRAGMA, then run the script to regenerate the\n**pragma.h** header file.\n\n### The Amalgamation\n\nAll of the individual C source code and header files (both manually-edited\nand automatically-generated) can be combined into a single big source file\n**sqlite3.c** called \"the amalgamation\".  The amalgamation is the recommended\nway of using SQLite in a larger application.  Combining all individual\nsource code files into a single big source code file allows the C compiler\nto perform more cross-procedure analysis and generate better code.  SQLite\nruns about 5% faster when compiled from the amalgamation versus when compiled\nfrom individual source files.\n\nThe amalgamation is generated from the tool/mksqlite3c.tcl Tcl script.\nFirst, all of the individual source files must be gathered into the tsrc/\nsubdirectory (using the equivalent of \"make target_source\") then the\ntool/mksqlite3c.tcl script is run to copy them all together in just the\nright order while resolving internal \"#include\" references.\n\nThe amalgamation source file is more than 200K lines long.  Some symbolic\ndebuggers (most notably MSVC) are unable to deal with files longer than 64K\nlines.  To work around this, a separate Tcl script, tool/split-sqlite3c.tcl,\ncan be run on the amalgamation to break it up into a single small C file\ncalled **sqlite3-all.c** that does #include on about seven other files\nnamed **sqlite3-1.c**, **sqlite3-2.c**, ..., **sqlite3-7.c**.  In this way,\nall of the source code is contained within a single translation unit so\nthat the compiler can do extra cross-procedure optimization, but no\nindividual source file exceeds 32K lines in length.\n\n## How It All Fits Together\n\nSQLite is modular in design.\nSee the [architectural description](https://sqlite.org/arch.html)\nfor details. Other documents that are useful in\nhelping to understand how SQLite works include the\n[file format](https://sqlite.org/fileformat2.html) description,\nthe [virtual machine](https://sqlite.org/opcode.html) that runs\nprepared statements, the description of\n[how transactions work](https://sqlite.org/atomiccommit.html), and\nthe [overview of the query planner](https://sqlite.org/optoverview.html).\n\nDecades of effort have gone into optimizing SQLite, both\nfor small size and high performance.  And optimizations tend to result in\ncomplex code.  So there is a lot of complexity in the current SQLite\nimplementation.  It will not be the easiest library in the world to hack.\n\n### Key source code files\n\n  *  **sqlite.h.in** - This file defines the public interface to the SQLite\n     library.  Readers will need to be familiar with this interface before\n     trying to understand how the library works internally.  This file is\n     really a template that is transformed into the \"sqlite3.h\" deliverable\n     using a script invoked by the makefile.\n\n  *  **sqliteInt.h** - this header file defines many of the data objects\n     used internally by SQLite.  In addition to \"sqliteInt.h\", some\n     subsystems inside of sQLite have their own header files.  These internal\n     interfaces are not for use by applications.  They can and do change\n     from one release of SQLite to the next.\n\n  *  **parse.y** - This file describes the LALR(1) grammar that SQLite uses\n     to parse SQL statements, and the actions that are taken at each step\n     in the parsing process.  The file is processed by the\n     [Lemon Parser Generator](./doc/lemon.html) to produce the actual C code\n     used for parsing.\n\n  *  **vdbe.c** - This file implements the virtual machine that runs\n     prepared statements.  There are various helper files whose names\n     begin with \"vdbe\".  The VDBE has access to the vdbeInt.h header file\n     which defines internal data objects.  The rest of SQLite interacts\n     with the VDBE through an interface defined by vdbe.h.\n\n  *  **where.c** - This file (together with its helper files named\n     by \"where*.c\") analyzes the WHERE clause and generates\n     virtual machine code to run queries efficiently.  This file is\n     sometimes called the \"query optimizer\".  It has its own private\n     header file, whereInt.h, that defines data objects used internally.\n\n  *  **btree.c** - This file contains the implementation of the B-Tree\n     storage engine used by SQLite.  The interface to the rest of the system\n     is defined by \"btree.h\".  The \"btreeInt.h\" header defines objects\n     used internally by btree.c and not published to the rest of the system.\n\n  *  **pager.c** - This file contains the \"pager\" implementation, the\n     module that implements transactions.  The \"pager.h\" header file\n     defines the interface between pager.c and the rest of the system.\n\n  *  **os_unix.c** and **os_win.c** - These two files implement the interface\n     between SQLite and the underlying operating system using the run-time\n     pluggable VFS interface.\n\n  *  **shell.c.in** - This file is not part of the core SQLite library.  This\n     is the file that, when linked against sqlite3.a, generates the\n     \"sqlite3.exe\" command-line shell.  The \"shell.c.in\" file is transformed\n     into \"shell.c\" as part of the build process.\n\n  *  **tclsqlite.c** - This file implements the Tcl bindings for SQLite.  It\n     is not part of the core SQLite library.  But as most of the tests in this\n     repository are written in Tcl, the Tcl language bindings are important.\n\n  *  **test\\*.c** - Files in the src/ folder that begin with \"test\" go into\n     building the \"testfixture.exe\" program.  The testfixture.exe program is\n     an enhanced Tcl shell.  The testfixture.exe program runs scripts in the\n     test/ folder to validate the core SQLite code.  The testfixture program\n     (and some other test programs too) is built and run when you type\n     \"make test\".\n\n  *  **VERSION**, **manifest**, and **manifest.uuid** - These files define\n     the current SQLite version number.  The \"VERSION\" file is human generated,\n     but the \"manifest\" and \"manifest.uuid\" files are automatically generated\n     by the [Fossil version control system](https://fossil-scm.org/).\n\nThere are many other source files.  Each has a succinct header comment that\ndescribes its purpose and role within the larger system.\n\n<a name=\"vauth\"></a>\n## Verifying Code Authenticity\n\nThe `manifest` file at the root directory of the source tree\ncontains either a SHA3-256 hash or a SHA1 hash\nfor every source file in the repository.\nThe name of the version of the entire source tree is just the\nSHA3-256 hash of the `manifest` file itself, possibly with the\nlast line of that file omitted if the last line begins with\n\"`# Remove this line`\".\nThe `manifest.uuid` file should contain the SHA3-256 hash of the\n`manifest` file. If all of the above hash comparisons are correct, then\nyou can be confident that your source tree is authentic and unadulterated.\nDetails on the format for the `manifest` files are available\n[on the Fossil website](https://fossil-scm.org/home/doc/trunk/www/fileformat.wiki#manifest).\n\nThe process of checking source code authenticity is automated by the \nmakefile:\n\n>   make verify-source\n\nOr on windows:\n\n>   nmake /f Makefile.msc verify-source\n\nUsing the makefile to verify source integrity is good for detecting\naccidental changes to the source tree, but malicious changes could be\nhidden by also modifying the makefiles.\n\n## Contacts\n\nThe main SQLite website is [https://sqlite.org/](https://sqlite.org/)\nwith geographically distributed backups at\n[https://www2.sqlite.org/](https://www2.sqlite.org) and\n[https://www3.sqlite.org/](https://www3.sqlite.org).\n\nContact the SQLite developers through the\n[SQLite Forum](https://sqlite.org/forum/).  In an emergency, you\ncan send private email to the lead developer at drh at sqlite dot org.\n",
      "stars_today": 2
    },
    {
      "id": 60377070,
      "name": "vespa",
      "full_name": "vespa-engine/vespa",
      "description": "AI + Data, online. https://vespa.ai",
      "html_url": "https://github.com/vespa-engine/vespa",
      "stars": 6720,
      "forks": 692,
      "language": "Java",
      "topics": [
        "ai",
        "big-data",
        "java",
        "machine-learning",
        "rag",
        "search",
        "search-engine",
        "server",
        "serving-recommendation",
        "tensor",
        "vector",
        "vector-database",
        "vector-search",
        "vespa"
      ],
      "created_at": "2016-06-03T20:54:20Z",
      "updated_at": "2026-01-13T23:32:47Z",
      "pushed_at": "2026-01-13T23:32:43Z",
      "open_issues": 229,
      "owner": {
        "login": "vespa-engine",
        "avatar_url": "https://avatars.githubusercontent.com/u/29299694?v=4"
      },
      "readme": "<!-- Copyright Vespa.ai. Licensed under the terms of the Apache 2.0 license. See LICENSE in the project root. -->\n\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://assets.vespa.ai/logos/Vespa-logo-green-RGB.svg\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"https://assets.vespa.ai/logos/Vespa-logo-dark-RGB.svg\">\n  <img alt=\"#Vespa\" width=\"200\" src=\"https://assets.vespa.ai/logos/Vespa-logo-dark-RGB.svg\" style=\"margin-bottom: 25px;\">\n</picture>\n<br/><br/>\n\n[![Build status](https://badge.buildkite.com/34f7cb35b91da4f929794c5fd7aa722fc15ca0224ad240270b.svg)](https://buildkite.com/vespaai/vespa-engine-vespa)\n![GitHub License](https://img.shields.io/github/license/vespa-engine/vespa)\n![Maven metadata URL](https://img.shields.io/maven-metadata/v?metadataUrl=https%3A%2F%2Frepo1.maven.org%2Fmaven2%2Fcom%2Fyahoo%2Fvespa%2Fparent%2Fmaven-metadata.xml)\n\n\n\nSearch, make inferences in and organize vectors, tensors, text and structured data, at serving time and any scale.\n\nThis repository contains all the code required to build and run all of Vespa yourself,\nand where you can see all development as it happens.\nAll the content in this repository is licensed under the Apache 2.0 license.\n\nA new release of Vespa is made from this repository's master branch every morning CET Monday through Thursday.\n\n- Home page: [https://vespa.ai](https://vespa.ai)\n- Documentation: [https://docs.vespa.ai](https://docs.vespa.ai)\n- Continuous build: [https://factory.vespa.ai](https://factory.vespa.ai)\n- Run applications in the cloud for free: [vespa.ai/free-trial](https://vespa.ai/free-trial/)\n\n## Table of contents\n\n- [Background](#background)\n- [Install](#install)\n- [Usage](#usage)\n- [Contribute](#contribute)\n- [Building](#building)\n- [License](#license)\n\n## Background\n\nUse cases such as search, recommendation and personalization need to select a subset of data in a large corpus,\nevaluate machine-learned models over the selected data, organize and aggregate it and return it, typically in less\nthan 100 milliseconds, all while the data corpus is continuously changing.\n\nThis is hard to do, especially with large data sets that need to be distributed over multiple nodes and evaluated in\nparallel. Vespa is a platform that performs these operations for you with high availability and performance.\nIt has been in development for many years and is used on several large internet services and apps which serve\nhundreds of thousands of queries from Vespa per second.\n\n## Install\n\nDeploy your Vespa applications to the cloud service: [console.vespa-cloud.com](https://console.vespa-cloud.com/),\nor run your own Vespa instance: [https://docs.vespa.ai/en/getting-started.html](https://docs.vespa.ai/en/getting-started.html)\n\n## Usage\n\n- The application created in the getting started guides linked above is fully functional and production-ready, but you may want to [add more nodes](https://docs.vespa.ai/en/multinode-systems.html) for redundancy.\n- See [developing applications](https://docs.vespa.ai/en/developer-guide.html) on adding your own Java components to your Vespa application.\n- [Vespa APIs](https://docs.vespa.ai/en/api.html) is useful to understand how to interface with Vespa\n- Explore the [sample applications](https://github.com/vespa-engine/sample-apps/tree/master)\n- Follow the [Vespa Blog](https://blog.vespa.ai/) for feature updates / use cases\n- Join the [Vespa Slack community](https://slack.vespa.ai/) to ask questions and share feedback\n\nFull documentation is at [https://docs.vespa.ai](https://docs.vespa.ai).\n\n## Contribute\n\nWe welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) to learn how to contribute.\n\nIf you want to contribute to the documentation, see\n[https://github.com/vespa-engine/documentation](https://github.com/vespa-engine/documentation)\n\n## Building\n\nYou do not need to build Vespa to use it, but if you want to contribute you need to be able to build the code.\nThis section explains how to build and test Vespa. To understand where to make changes, see [Code-map.md](Code-map.md).\nSome suggested improvements with pointers to code are in [TODO.md](TODO.md).\n\n### Development environment\n\nC++ and Java building is supported on AlmaLinux 8.\nThe Java source can also be built on any platform having Java 17 and Maven 3.8+ installed.\nUse the following guide to set up a complete development environment using Docker\nfor building Vespa, running unit tests and running system tests:\n[Vespa development on AlmaLinux 8](https://github.com/vespa-engine/docker-image-dev#vespa-development-on-almalinux-8).\n\n#### Java environment for Mac\n1. Install [JDK17](https://openjdk.org/projects/jdk/17/), \n   [Maven Version Manager](https://bitbucket.org/mjensen/mvnvm/src/master/) and [jEnv](https://www.jenv.be)\n   through [Homebrew](https://brew.sh/).\n```sh\nbrew install jenv mvnvm openjdk@17\n```\n\n2. On ARM Macs (M1, M2 etc.), install intel compatibility since [grpc isn't properly maintained](https://github.com/grpc/grpc-java/issues/7690): \n\n```sh\nsoftwareupdate --install-rosetta\n```\n\n3. For the system Java wrappers to find this JDK, symlink it with\n```sh\nsudo ln -sfn /opt/homebrew/opt/openjdk@17/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk-17.jdk\n```\n\n4. Follow \"Configure your shell\" in https://www.jenv.be. Configuration is shell specific. For `zsh` use the below commands:\n```sh\necho 'export PATH=\"$HOME/.jenv/bin:$PATH\"' >> ~/.zshrc\necho 'eval \"$(jenv init -)\"' >> ~/.zshrc\neval \"$(jenv init -)\"\njenv enable-plugin export\nexec $SHELL -l\n```\n\n5. Add JDK17 to jEnv\n```sh\njenv add $(/usr/libexec/java_home -v 17)\n```\n\n6. Verify configuration with Maven by executing below command in the root of the source code.\n   Output should refer to the JDK and Maven version specified in the [.java-version](.java-version) and [mvnvm.properties](mvnvm.properties).\n```sh\nmvn -v\n```\n\n### Build Java modules\n\n    export MAVEN_OPTS=\"-Xms128m -Xmx1024m\"\n    ./bootstrap.sh java\n    mvn install --threads 1C\n\nUse this if you only need to build the Java modules, otherwise follow the complete development guide above.\n\n### Run tests for shell scripts (on Mac)\nShell scripts are tested with [BATS](https://bats-core.readthedocs.io/en/stable/).\nTo run the tests locally, install the testing framework and its plugins.:\n```bash\nbrew install node\nsudo npm install -g bats bats-assert bats-support bats-mock\n```\nExport the `BATS_PLUGIN_PATH` environment variable to point to the global npm modules directory, which contains the BATS plugins:\n```bash\nexport BATS_PLUGIN_PATH=\"$(npm root -g)\"\n```\nThen run all tests with the following command (from the root of the repository):\n```bash\nbats -r .\n```\nTo run a specific test, use:\n```bash\nbats test_dir/test_name.bats\n```\nTests can also be run in IntelliJ IDEA with the [BashSupport Pro](https://plugins.jetbrains.com/plugin/13841-bashsupport-pro)\nplugin. Ensure the `BATS_PLUGIN_PATH` environment variable is exported before launching the IDE\nto avoid setting it in each run configuration.\n\n## License\n\nCode licensed under the Apache 2.0 license. See [LICENSE](LICENSE) for terms.\n",
      "stars_today": 2
    },
    {
      "id": 228103273,
      "name": "nuttx",
      "full_name": "apache/nuttx",
      "description": "Apache NuttX is a mature, real-time embedded operating system (RTOS)",
      "html_url": "https://github.com/apache/nuttx",
      "stars": 3630,
      "forks": 1450,
      "language": "C",
      "topics": [
        "embedded",
        "mcu",
        "microcontroller",
        "nuttx",
        "real-time",
        "rtos"
      ],
      "created_at": "2019-12-14T23:27:55Z",
      "updated_at": "2026-01-13T21:56:43Z",
      "pushed_at": "2026-01-13T21:56:39Z",
      "open_issues": 767,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/apache/nuttx/master/Documentation/_static/NuttX320.png\" width=\"175\">\n</p>\n\n![POSIX Badge](https://img.shields.io/badge/POSIX-Compliant-brightgreen?style=flat&label=POSIX)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue\n)](https://nuttx.apache.org/docs/latest/introduction/licensing.html)\n![Issues Tracking Badge](https://img.shields.io/badge/issue_track-github-blue?style=flat&label=Issue%20Tracking)\n[![Contributors](https://img.shields.io/github/contributors/apache/nuttx\n)](https://github.com/apache/nuttx/graphs/contributors)\n[![GitHub Build Badge](https://github.com/apache/nuttx/workflows/Build/badge.svg)](https://github.com/apache/nuttx/actions/workflows/build.yml)\n[![Documentation Badge](https://github.com/apache/nuttx/workflows/Build%20Documentation/badge.svg)](https://nuttx.apache.org/docs/latest/index.html)\n\nApache NuttX is a real-time operating system (RTOS) with an emphasis on\nstandards compliance and small footprint. Scalable from 8-bit to 64-bit\nmicrocontroller environments, the primary governing standards in NuttX are POSIX\nand ANSI standards. Additional standard APIs from Unix and other common RTOSs\n(such as VxWorks) are adopted for functionality not available under these\nstandards, or for functionality that is not appropriate for deeply-embedded\nenvironments (such as fork()).\n\nFor brevity, many parts of the documentation will refer to Apache NuttX as simply NuttX.\n\n## Getting Started\nFirst time on NuttX? Read the [Getting Started](https://nuttx.apache.org/docs/latest/quickstart/index.html) guide!\nIf you don't have a board available, NuttX has its own simulator that you can run on terminal.\n\n## Documentation\nYou can find the current NuttX documentation on the [Documentation Page](https://nuttx.apache.org/docs/latest/).\n\nAlternatively, you can build the documentation yourself by following the Documentation Build [Instructions](https://nuttx.apache.org/docs/latest/contributing/documentation.html).\n\nThe old NuttX documentation is still available in the [Apache wiki](https://cwiki.apache.org/NUTTX/NuttX).\n\n## Supported Boards\nNuttX supports a wide variety of platforms. See the full list on the [Supported Platforms](https://nuttx.apache.org/docs/latest/platforms/index.html) page.\n\n## Contributing\nIf you wish to contribute to the NuttX project, read the [Contributing](https://nuttx.apache.org/docs/latest/contributing/index.html) guidelines for information on Git usage, coding standard, workflow and the NuttX principles.\n\n## License\nThe code in this repository is under either the Apache 2 license, or a license compatible with the Apache 2 license. See the [License Page](https://nuttx.apache.org/docs/latest/introduction/licensing.html) for more information.\n",
      "stars_today": 2
    },
    {
      "id": 184341774,
      "name": "cloud-hypervisor",
      "full_name": "cloud-hypervisor/cloud-hypervisor",
      "description": "A Virtual Machine Monitor for modern Cloud workloads. Features include CPU, memory and device hotplug, support for running Windows and Linux guests, device offload with vhost-user and a minimal compact footprint. Written in Rust with a strong focus on security.",
      "html_url": "https://github.com/cloud-hypervisor/cloud-hypervisor",
      "stars": 5157,
      "forks": 566,
      "language": "Rust",
      "topics": [
        "cloud-workloads",
        "kvm",
        "rust-vmm",
        "virtualization"
      ],
      "created_at": "2019-04-30T22:49:03Z",
      "updated_at": "2026-01-13T15:28:09Z",
      "pushed_at": "2026-01-13T21:45:51Z",
      "open_issues": 151,
      "owner": {
        "login": "cloud-hypervisor",
        "avatar_url": "https://avatars.githubusercontent.com/u/50487650?v=4"
      },
      "readme": "- [1. What is Cloud Hypervisor?](#1-what-is-cloud-hypervisor)\n  - [Objectives](#objectives)\n    - [High Level](#high-level)\n    - [Architectures](#architectures)\n    - [Guest OS](#guest-os)\n- [2. Getting Started](#2-getting-started)\n  - [Host OS](#host-os)\n  - [Use Pre-built Binaries](#use-pre-built-binaries)\n  - [Packages](#packages)\n  - [Building from Source](#building-from-source)\n  - [Booting Linux](#booting-linux)\n    - [Firmware Booting](#firmware-booting)\n    - [Custom Kernel and Disk Image](#custom-kernel-and-disk-image)\n      - [Building your Kernel](#building-your-kernel)\n      - [Disk image](#disk-image)\n      - [Booting the guest VM](#booting-the-guest-vm)\n- [3. Status](#3-status)\n  - [Hot Plug](#hot-plug)\n  - [Device Model](#device-model)\n  - [Roadmap](#roadmap)\n- [4. Relationship with _Rust VMM_ Project](#4-relationship-with-rust-vmm-project)\n  - [Differences with Firecracker and crosvm](#differences-with-firecracker-and-crosvm)\n- [5. Community](#5-community)\n  - [Contribute](#contribute)\n  - [Slack](#slack)\n  - [Mailing list](#mailing-list)\n  - [Security issues](#security-issues)\n\n# 1. What is Cloud Hypervisor?\n\nCloud Hypervisor is an open source Virtual Machine Monitor (VMM) that runs on\ntop of the [KVM](https://www.kernel.org/doc/Documentation/virtual/kvm/api.txt)\nhypervisor and the Microsoft Hypervisor (MSHV).\n\nThe project focuses on running modern, _Cloud Workloads_, on specific, common,\nhardware architectures. In this case _Cloud Workloads_ refers to those that are\nrun by customers inside a Cloud Service Provider. This means modern operating\nsystems with most I/O handled by\nparavirtualised devices (e.g. _virtio_), no requirement for legacy devices, and\n64-bit CPUs.\n\nCloud Hypervisor is implemented in [Rust](https://www.rust-lang.org/) and is\nbased on the [Rust VMM](https://github.com/rust-vmm) crates.\n\n## Objectives\n\n### High Level\n\n- Runs on KVM or MSHV\n- Minimal emulation\n- Low latency\n- Low memory footprint\n- Low complexity\n- High performance\n- Small attack surface\n- 64-bit support only\n- CPU, memory, PCI hotplug\n- Machine to machine migration\n\n### Architectures\n\nCloud Hypervisor supports the `x86-64`, `AArch64` and `riscv64`\narchitectures, with functionality varying across these platforms. The\nfunctionality differences between `x86-64` and `AArch64` are documented\nin [#1125](https://github.com/cloud-hypervisor/cloud-hypervisor/issues/1125).\nThe `riscv64` architecture support is experimental and offers limited\nfunctionality. For more details and instructions, please refer to [riscv\ndocumentation](docs/riscv.md).\n\n### Guest OS\n\nCloud Hypervisor supports `64-bit Linux` and Windows 10/Windows Server 2019.\n\n# 2. Getting Started\n\nThe following sections describe how to build and run Cloud Hypervisor.\n\n## Prerequisites for AArch64\n\n- AArch64 servers (recommended) or development boards equipped with the GICv3\n  interrupt controller.\n\n## Host OS\n\nFor required KVM functionality and adequate performance the recommended host\nkernel version is 5.13. The majority of the CI currently tests with kernel\nversion 5.15.\n\n## Use Pre-built Binaries\n\nThe recommended approach to getting started with Cloud Hypervisor is by using a\npre-built binary. Binaries are available for the [latest\nrelease](https://github.com/cloud-hypervisor/cloud-hypervisor/releases/latest).\nUse `cloud-hypervisor-static` for `x86-64` or `cloud-hypervisor-static-aarch64`\nfor `AArch64` platform.\n\n## Packages\n\nFor convenience, packages are also available targeting some popular Linux\ndistributions. This is thanks to the [Open Build\nService](https://build.opensuse.org). The [OBS\nREADME](https://github.com/cloud-hypervisor/obs-packaging) explains how to\nenable the repository in a supported Linux distribution and install Cloud Hypervisor\nand accompanying packages. Please report any packaging issues in the\n[obs-packaging](https://github.com/cloud-hypervisor/obs-packaging) repository.\n\n## Building from Source\n\nPlease see the [instructions for building from source](docs/building.md) if you\ndo not wish to use the pre-built binaries.\n\n## Booting Linux\n\nCloud Hypervisor supports direct kernel boot (the x86-64 kernel requires the kernel\nbuilt with PVH support or a bzImage) or booting via a firmware (either [Rust Hypervisor\nFirmware](https://github.com/cloud-hypervisor/rust-hypervisor-firmware) or an\nedk2 UEFI firmware called `CLOUDHV` / `CLOUDHV_EFI`.)\n\nBinary builds of the firmware files are available for the latest release of\n[Rust Hypervisor\nFirmware](https://github.com/cloud-hypervisor/rust-hypervisor-firmware/releases/latest)\nand [our edk2\nrepository](https://github.com/cloud-hypervisor/edk2/releases/latest)\n\nThe choice of firmware depends on your guest OS choice; some experimentation\nmay be required.\n\n### Firmware Booting\n\nCloud Hypervisor supports booting disk images containing all needed components\nto run cloud workloads, a.k.a. cloud images.\n\nThe following sample commands will download an Ubuntu Cloud image, converting\nit into a format that Cloud Hypervisor can use and a firmware to boot the image\nwith.\n\n```shell\n$ wget https://cloud-images.ubuntu.com/focal/current/focal-server-cloudimg-amd64.img\n$ qemu-img convert -p -f qcow2 -O raw focal-server-cloudimg-amd64.img focal-server-cloudimg-amd64.raw\n$ wget https://github.com/cloud-hypervisor/rust-hypervisor-firmware/releases/download/0.4.2/hypervisor-fw\n```\n\nThe Ubuntu cloud images do not ship with a default password so it necessary to\nuse a `cloud-init` disk image to customise the image on the first boot. A basic\n`cloud-init` image is generated by this [script](scripts/create-cloud-init.sh).\nThis seeds the image with a default username/password of `cloud/cloud123`. It\nis only necessary to add this disk image on the first boot. Script also assigns\ndefault IP address using `test_data/cloud-init/ubuntu/local/network-config` details\nwith `--net \"mac=12:34:56:78:90:ab,tap=\"` option. Then the matching mac address\ninterface will be enabled as per `network-config` details.\n\n```shell\n$ sudo setcap cap_net_admin+ep ./cloud-hypervisor\n$ ./create-cloud-init.sh\n$ ./cloud-hypervisor \\\n\t--firmware ./hypervisor-fw \\\n\t--disk path=focal-server-cloudimg-amd64.raw path=/tmp/ubuntu-cloudinit.img \\\n\t--cpus boot=4 \\\n\t--memory size=1024M \\\n\t--net \"tap=,mac=,ip=,mask=\"\n```\n\nIf access to the firmware messages or interaction with the boot loader (e.g.\nGRUB) is required then it necessary to switch to the serial console instead of\n`virtio-console`.\n\n```shell\n$ ./cloud-hypervisor \\\n\t--kernel ./hypervisor-fw \\\n\t--disk path=focal-server-cloudimg-amd64.raw path=/tmp/ubuntu-cloudinit.img \\\n\t--cpus boot=4 \\\n\t--memory size=1024M \\\n\t--net \"tap=,mac=,ip=,mask=\" \\\n\t--serial tty \\\n\t--console off\n```\n\n## Booting: `--firmware` vs `--kernel`\n\nThe following scenarios are supported by Cloud Hypervisor to bootstrap a VM, i.e.,\nto load a payload/bootitem(s):\n\n- Provide firmware\n- Provide kernel \\[+ cmdline\\]\\ [+ initrd\\]\n\nPlease note that our Cloud Hypervisor firmware (`hypervisor-fw`) has a Xen PVH\nboot entry, therefore it can also be booted via the `--kernel` parameter, as \nseen in some examples.\n\n### Custom Kernel and Disk Image\n\n#### Building your Kernel\n\nCloud Hypervisor also supports direct kernel boot. For x86-64, a `vmlinux` ELF kernel (compiled with PVH support) or a regular bzImage are supported. In order to support development there is a custom branch; however provided the required options are enabled any recent kernel will suffice.\n\nTo build the kernel:\n\n```shell\n# Clone the Cloud Hypervisor Linux branch\n$ git clone --depth 1 https://github.com/cloud-hypervisor/linux.git -b ch-6.12.8 linux-cloud-hypervisor\n$ pushd linux-cloud-hypervisor\n$ make ch_defconfig\n# Do native build of the x86-64 kernel\n$ KCFLAGS=\"-Wa,-mx86-used-note=no\" make bzImage -j `nproc`\n# Do native build of the AArch64 kernel\n$ make -j `nproc`\n$ popd\n```\n\nFor x86-64, the `vmlinux` kernel image will then be located at\n`linux-cloud-hypervisor/arch/x86/boot/compressed/vmlinux.bin`.\nFor AArch64, the `Image` kernel image will then be located at\n`linux-cloud-hypervisor/arch/arm64/boot/Image`.\n\n#### Disk image\n\nFor the disk image the same Ubuntu image as before can be used. This contains\nan `ext4` root filesystem.\n\n```shell\n$ wget https://cloud-images.ubuntu.com/focal/current/focal-server-cloudimg-amd64.img # x86-64\n$ wget https://cloud-images.ubuntu.com/focal/current/focal-server-cloudimg-arm64.img # AArch64\n$ qemu-img convert -p -f qcow2 -O raw focal-server-cloudimg-amd64.img focal-server-cloudimg-amd64.raw # x86-64\n$ qemu-img convert -p -f qcow2 -O raw focal-server-cloudimg-arm64.img focal-server-cloudimg-arm64.raw # AArch64\n```\n\n#### Booting the guest VM\n\nThese sample commands boot the disk image using the custom kernel whilst also\nsupplying the desired kernel command line.\n\n- x86-64\n\n```shell\n$ sudo setcap cap_net_admin+ep ./cloud-hypervisor\n$ ./create-cloud-init.sh\n$ ./cloud-hypervisor \\\n\t--kernel ./linux-cloud-hypervisor/arch/x86/boot/compressed/vmlinux.bin \\\n\t--disk path=focal-server-cloudimg-amd64.raw path=/tmp/ubuntu-cloudinit.img \\\n\t--cmdline \"console=hvc0 root=/dev/vda1 rw\" \\\n\t--cpus boot=4 \\\n\t--memory size=1024M \\\n\t--net \"tap=,mac=,ip=,mask=\"\n```\n\n- AArch64\n\n```shell\n$ sudo setcap cap_net_admin+ep ./cloud-hypervisor\n$ ./create-cloud-init.sh\n$ ./cloud-hypervisor \\\n\t--kernel ./linux-cloud-hypervisor/arch/arm64/boot/Image \\\n\t--disk path=focal-server-cloudimg-arm64.raw path=/tmp/ubuntu-cloudinit.img \\\n\t--cmdline \"console=hvc0 root=/dev/vda1 rw\" \\\n\t--cpus boot=4 \\\n\t--memory size=1024M \\\n\t--net \"tap=,mac=,ip=,mask=\"\n```\n\nIf earlier kernel messages are required the serial console should be used instead of `virtio-console`.\n\n- x86-64\n\n```shell\n$ ./cloud-hypervisor \\\n\t--kernel ./linux-cloud-hypervisor/arch/x86/boot/compressed/vmlinux.bin \\\n\t--console off \\\n\t--serial tty \\\n\t--disk path=focal-server-cloudimg-amd64.raw \\\n\t--cmdline \"console=ttyS0 root=/dev/vda1 rw\" \\\n\t--cpus boot=4 \\\n\t--memory size=1024M \\\n\t--net \"tap=,mac=,ip=,mask=\"\n```\n\n- AArch64\n\n```shell\n$ ./cloud-hypervisor \\\n\t--kernel ./linux-cloud-hypervisor/arch/arm64/boot/Image \\\n\t--console off \\\n\t--serial tty \\\n\t--disk path=focal-server-cloudimg-arm64.raw \\\n\t--cmdline \"console=ttyAMA0 root=/dev/vda1 rw\" \\\n\t--cpus boot=4 \\\n\t--memory size=1024M \\\n\t--net \"tap=,mac=,ip=,mask=\"\n```\n\n# 3. Status\n\nCloud Hypervisor is under active development. The following stability\nguarantees are currently made:\n\n* The API (including command line options) will not be removed or changed in a\n  breaking way without a minimum of 2 major releases notice. Where possible\n  warnings will be given about the use of deprecated functionality and the\n  deprecations will be documented in the release notes.\n\n* Point releases will be made between individual releases where there are\n  substantial bug fixes or security issues that need to be fixed. These point\n  releases will only include bug fixes.\n\nCurrently the following items are **not** guaranteed across updates:\n\n* Snapshot/restore is not supported across different versions\n* Live migration is not supported across different versions\n* The following features are considered experimental and may change\n  substantially between releases: TDX, vfio-user, vDPA.\n\nFurther details can be found in the [release documentation](docs/releases.md).\n\nAs of 2023-01-03, the following cloud images are supported:\n\n- [Ubuntu Focal](https://cloud-images.ubuntu.com/focal/current/) (focal-server-cloudimg-{amd64,arm64}.img)\n- [Ubuntu Jammy](https://cloud-images.ubuntu.com/jammy/current/) (jammy-server-cloudimg-{amd64,arm64}.img)\n- [Ubuntu Noble](https://cloud-images.ubuntu.com/noble/current/) (noble-server-cloudimg-{amd64,arm64}.img)\n- [Fedora 36](https://archives.fedoraproject.org/pub/archive/fedora/linux/releases/36/Cloud/) ([Fedora-Cloud-Base-36-1.5.x86_64.raw.xz](https://archives.fedoraproject.org/pub/archive/fedora/linux/releases/36/Cloud/x86_64/images/) / [Fedora-Cloud-Base-36-1.5.aarch64.raw.xz](https://archives.fedoraproject.org/pub/archive/fedora/linux/releases/36/Cloud/aarch64/images/))\n\nDirect kernel boot to userspace should work with a rootfs from most\ndistributions although you may need to enable exotic filesystem types in the\nreference kernel configuration (e.g. XFS or btrfs.)\n\n## Hot Plug\n\nCloud Hypervisor supports hotplug of CPUs, passthrough devices (VFIO),\n`virtio-{net,block,pmem,fs,vsock}` and memory resizing. This\n[document](docs/hotplug.md) details how to add devices to a running VM.\n\n## Device Model\n\nDetails of the device model can be found in this\n[documentation](docs/device_model.md).\n\n## Roadmap\n\nThe project roadmap is tracked through a [GitHub\nproject](https://github.com/orgs/cloud-hypervisor/projects/6).\n\n# 4. Relationship with _Rust VMM_ Project\n\nIn order to satisfy the design goal of having a high-performance,\nsecurity-focused hypervisor the decision was made to use the\n[Rust](https://www.rust-lang.org/) programming language. The language's strong\nfocus on memory and thread safety makes it an ideal candidate for implementing\nVMMs.\n\nInstead of implementing the VMM components from scratch, Cloud Hypervisor is\nimporting the [Rust VMM](https://github.com/rust-vmm) crates, and sharing code\nand architecture together with other VMMs like e.g. Amazon's\n[Firecracker](https://firecracker-microvm.github.io/) and Google's\n[crosvm](https://chromium.googlesource.com/chromiumos/platform/crosvm/).\n\nCloud Hypervisor embraces the _Rust VMM_ project's goals, which is to be able\nto share and re-use as many virtualization crates as possible.\n\n## Differences with Firecracker and crosvm\n\nA large part of the Cloud Hypervisor code is based on either the Firecracker or\nthe crosvm project's implementations. Both of these are VMMs written in Rust\nwith a focus on safety and security, like Cloud Hypervisor.\n\nThe goal of the Cloud Hypervisor project differs from the aforementioned\nprojects in that it aims to be a general purpose VMM for _Cloud Workloads_ and\nnot limited to container/serverless or client workloads.\n\nThe Cloud Hypervisor community thanks the communities of both the Firecracker\nand crosvm projects for their excellent work.\n\n# 5. Community\n\nThe Cloud Hypervisor project follows the governance, and community guidelines\ndescribed in the [Community](https://github.com/cloud-hypervisor/community)\nrepository.\n\n## Contribute\n\nThe project strongly believes in building a global, diverse and collaborative\ncommunity around the Cloud Hypervisor project. Anyone who is interested in\n[contributing](CONTRIBUTING.md) to the project is welcome to participate.\n\nContributing to a open source project like Cloud Hypervisor covers a lot more\nthan just sending code. Testing, documentation, pull request\nreviews, bug reports, feature requests, project improvement suggestions, etc,\nare all equal and welcome means of contribution. See the\n[CONTRIBUTING](CONTRIBUTING.md) document for more details.\n\n## Slack\n\nGet an [invite to our Slack channel](https://join.slack.com/t/cloud-hypervisor/shared_invite/enQtNjY3MTE3MDkwNDQ4LWQ1MTA1ZDVmODkwMWQ1MTRhYzk4ZGNlN2UwNTI3ZmFlODU0OTcwOWZjMTkwZDExYWE3YjFmNzgzY2FmNDAyMjI),\n [join us on Slack](https://cloud-hypervisor.slack.com/), and [participate in our community activities](https://cloud-hypervisor.slack.com/archives/C04R5DUQVBN).\n\n## Mailing list\n\nPlease report bugs using the [GitHub issue\ntracker](https://github.com/cloud-hypervisor/cloud-hypervisor/issues) but for\nbroader community discussions you may use our [mailing\nlist](https://lists.cloudhypervisor.org/g/dev/).\n\n## Security issues\n\nPlease contact the maintainers listed in the MAINTAINERS.md file with security issues.\n",
      "stars_today": 2
    },
    {
      "id": 35890002,
      "name": "list",
      "full_name": "publicsuffix/list",
      "description": "The Public Suffix List",
      "html_url": "https://github.com/publicsuffix/list",
      "stars": 2700,
      "forks": 1479,
      "language": "Go",
      "topics": [],
      "created_at": "2015-05-19T15:12:26Z",
      "updated_at": "2026-01-13T21:23:42Z",
      "pushed_at": "2026-01-13T11:09:54Z",
      "open_issues": 33,
      "owner": {
        "login": "publicsuffix",
        "avatar_url": "https://avatars.githubusercontent.com/u/2463634?v=4"
      },
      "readme": "# The Public Suffix List\n\nA \"public suffix\" is one under which Internet users can (or historically could)\ndirectly register names. Some examples of public suffixes are `com`, `co.uk` and\n`pvt.k12.ma.us`. The Public Suffix List is a list of all known public suffixes.\n\nSee https://publicsuffix.org/ and the [Wiki](https://github.com/publicsuffix/list/wiki) link above for more information.\n\n## Are you here to add or update something?\n\nAll submissions must conform to the [validation and acceptance factors](https://github.com/publicsuffix/list/wiki/Guidelines#validation-and-non-acceptance-factors) and provide sufficient rationale or basically be as complete as possible, and follow the [Guidelines](https://github.com/publicsuffix/list/wiki/Guidelines), especially as they relate to format and [sorting](https://github.com/publicsuffix/list/wiki/Guidelines#sort-your-submission-correctly-important).\n\nThe list is currently maintained by people who are volunteering their time towards universal acceptance and ensuring there is a bridge between the ICANN world of domain names and the crucial last mile - the world of developers and human users.\n\nIteration back and forth will delay PR review or inclusion. Be extremely thorough, and patient.\n\n## Important Notices\n\n### 2025-05-27\nWere you directed here to be able to add a subdomain to your **Cloudflare** account? If so, please work directly with Cloudflare for these account limitations. The PSL is **NOT** intended as a workaround for Cloudflare's subdomain restrictions. \n\nConsult [Cloudflare's subdomain setup documentation](https://developers.cloudflare.com/dns/zone-setups/subdomain-setup/) or contact Cloudflare directly for subdomain setup questions. Only submit a request to the PSL if your domain truly meets our criteria outlined in [Guidelines](https://github.com/publicsuffix/list/wiki/Guidelines).\n\n### 2024-07-26\nWe are sending emails asking for confirmation if certain entries are still required or need updating.\n\nCurrently, this process is purely manual and extremely low volume but if you do get an email, please respond.\n\nPlease see the [Email Communication Policy](#email-communication-policy) to see how we will often communicate these changes.\n\n### 2023-02-20\nDid [guidance from Google related to the changes that they are making to adsense subdomains](https://support.google.com/adsense/answer/12170421) bring you here? Work with Google Adsense [Help Link](https://support.google.com/adsense/gethelp) with any support questions you have. The PSL is thinly resourced, and the volunteer maintainers are unable to answer questions about Adsense changes or support Adsense.\n\nThe PSL is volunteer-resourced and is absolutely not resourced to answer questions or support changes. Guidance is in the form of self-help (READ THE [WIKI](https://github.com/publicsuffix/list/wiki)), THERE IS NO PSL CUSTOMER SERVICE RESOURCE TO ASSIST YOU. *Please work directly with Google to ensure your domain does in fact need an entry, and they should help you know what the benefits and consequences are. __IT POSSIBLE TO HARM YOUR WEBSITE COOKIES BY REQUESTING A MALFORMED PSL ENTRY__. Also, understand what propagation delays and rollback processing entail before making requests.*\n\n### 2021-04-23\nDid guidance related to an issue with Facebook or Apple bring you here? [Read this before submitting requests](https://github.com/publicsuffix/list/issues/1245) We are not approving workaround requests per the validation and acceptance standards, but do have open discussion with Facebook on the matter.\n\n## Email Communication Policy\n\nWe tend to use the subject line tag \"[PSL notification]\" in all Public Suffix List communications. For effective spam filtering, you can create a case-insensitive filter to allow only emails with exact \"[PSL notification]\" in the subject line. If you choose to set up such a filter in your email application, please verify the filter is implemented correctly and test it thoroughly to ensure you don't accidentally miss important communications from us.\n\n## Code of Conduct\n\nYour participation in the Public Suffix List project should follow the [Mozilla Community Participation Guidelines](https://www.mozilla.org/en-US/about/governance/policies/participation/ \"Mozilla Community Participation Guidelines\") as well as the [GitHub Community Participation Guidelines](https://help.github.com/en/github/site-policy/github-community-guidelines \"GitHub Community Participation Guidelines\"). Behavior that falls into the areas forbidden by either document is unwelcome and will result in further escalation.\n",
      "stars_today": 2
    },
    {
      "id": 65514205,
      "name": "liboqs",
      "full_name": "open-quantum-safe/liboqs",
      "description": "C library for prototyping and experimenting with quantum-resistant cryptography",
      "html_url": "https://github.com/open-quantum-safe/liboqs",
      "stars": 2698,
      "forks": 675,
      "language": "C",
      "topics": [
        "cryptography",
        "key-exchange-algorithms",
        "lattice-based-crypto",
        "post-quantum-cryptography"
      ],
      "created_at": "2016-08-12T01:46:12Z",
      "updated_at": "2026-01-13T13:06:12Z",
      "pushed_at": "2026-01-11T01:42:15Z",
      "open_issues": 97,
      "owner": {
        "login": "open-quantum-safe",
        "avatar_url": "https://avatars.githubusercontent.com/u/20689385?v=4"
      },
      "readme": "liboqs\n======================\n\n[![Main Branch Tests](https://github.com/open-quantum-safe/liboqs/actions/workflows/commit-to-main.yml/badge.svg)](https://github.com/open-quantum-safe/liboqs/actions/workflows/commit-to-main.yml)\n[![Weekly Tests](https://github.com/open-quantum-safe/liboqs/actions/workflows/weekly.yml/badge.svg)](https://github.com/open-quantum-safe/liboqs/actions/workflows/weekly.yml)\n[![Coverage Status](https://coveralls.io/repos/github/open-quantum-safe/liboqs/badge.svg?branch=main)](https://coveralls.io/github/open-quantum-safe/liboqs?branch=main)\n\nliboqs is an open source C library for quantum-safe cryptographic algorithms.\n\n- [liboqs](#liboqs)\n\t- [Overview](#overview)\n\t- [Status](#status)\n\t\t- [Supported Algorithms](#supported-algorithms)\n\t\t\t- [Key encapsulation mechanisms](#key-encapsulation-mechanisms)\n\t\t\t- [Signature schemes](#signature-schemes)\n\t\t\t- [Stateful signature schemes](#stateful-signature-schemes)\n\t\t- [Limitations and Security](#limitations-and-security)\n\t\t\t- [Platform limitations](#platform-limitations)\n\t\t\t- [Support limitations](#support-limitations)\n\t- [Quickstart](#quickstart)\n\t\t- [Linux and Mac](#linux-and-mac)\n\t\t- [Windows](#windows)\n\t\t- [Cross compilation](#cross-compilation)\n\t- [Documentation](#documentation)\n\t- [Contributing](#contributing)\n\t- [License](#license)\n\t- [Acknowledgements](#acknowledgements)\n\n## Overview\n\nliboqs provides:\n\n- a collection of open source implementations of quantum-safe key encapsulation mechanisms (KEMs) and digital signature algorithms; the full list can be found [below](#supported-algorithms)\n- a common API for these algorithms\n- a test harness and benchmarking routines\n\nliboqs is part of the **Open Quantum Safe (OQS)** project, which aims to develop and integrate into applications quantum-safe cryptography to facilitate deployment and testing in real world contexts. In particular, OQS provides prototype integrations of liboqs into protocols like TLS, X.509, and S/MIME, through our [OpenSSL 3 Provider](https://github.com/open-quantum-safe/oqs-provider) and we provide a variety of other [post-quantum-enabled demos](https://github.com/open-quantum-safe/oqs-demos).\n\nThe OQS project is supported by the [Post-Quantum Cryptography Alliance](https://pqca.org/) as part of the [Linux Foundation](https://linuxfoundation.org/). More information about the Open Quantum Safe project can be found at [openquantumsafe.org](https://openquantumsafe.org/).\n\nOQS is running a survey to better understand our community. We would like to hear from organizations and individuals about their interest in and use of the Open Quantum Safe project. Please take a few minutes to fill out the survey: https://linuxfoundation.surveymonkey.com/r/oqssurvey\n\n## Status\n\n### Supported Algorithms\n\nDetails on each supported algorithm can be found in the [docs/algorithms](https://github.com/open-quantum-safe/liboqs/tree/main/docs/algorithms) folder.\n\nThe list below indicates all algorithms currently supported by liboqs, including experimental algorithms and already excluding algorithm variants pruned during the NIST competition, such as Kyber-90s or Dilithium-AES.\n\nThe only algorithms in `liboqs` that implement NIST standards are the [`ML-KEM`](https://csrc.nist.gov/pubs/fips/203/final) (final standard) and [`ML-DSA`](https://csrc.nist.gov/pubs/fips/204/final) (final standard) variants with their respective different bit strengths. `liboqs` will retain these algorithm names selected by NIST throughout the finishing stages of the standardization process, so users can rely on their presence going forward. If NIST changes the implementation details of these algorithms, `liboqs` will adjust the implementation so that users are protected from such potential changes.\n\nFalcon and SPHINCS+ have also been [selected for standardization](https://csrc.nist.gov/Projects/post-quantum-cryptography/selected-algorithms-2022), but the `liboqs` implementations of these algorithms are currently tracking Round 3 submissions and not NIST standards drafts.\n\nAll names other than `ML-KEM` and `ML-DSA` are subject to change. `liboqs` makes available a [selection mechanism for algorithms on the NIST standards track, continued NIST competition, or purely experimental nature by way of the configuration variable OQS_ALGS_ENABLED](CONFIGURE.md#oQS_ALGS_ENABLED). By default `liboqs` is built supporting all, incl. experimental, PQ algorithms listed below.\n\n<!-- OQS_TEMPLATE_FRAGMENT_ALG_SUPPORT_START -->\n#### Key encapsulation mechanisms\n| Algorithm family   | Standardization status                                                                                                                                                                                                                    | Primary implementation                                                                                                                    |\n|:-------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------|\n| BIKE               | Not selected by [NIST](https://bikesuite.org/files/v5.1/BIKE_Spec.2022.10.10.1.pdf)                                                                                                                                                       | [`awslabs/bike-kem`](https://github.com/awslabs/bike-kem)                                                                                 |\n| Classic McEliece   | Under [ISO](https://classic.mceliece.org/iso.html) consideration                                                                                                                                                                          | [`PQClean/PQClean@1eacfda`](https://github.com/PQClean/PQClean/commit/1eacfdafc15ddc5d5759d0b85b4cef26627df181)                           |\n| FrodoKEM           | Under [ISO](https://frodokem.org/) consideration                                                                                                                                                                                          | [`microsoft/PQCrypto-LWEKE@b6609d3`](https://github.com/microsoft/PQCrypto-LWEKE/commit/b6609d30a9982318d7f2937aa3c7b92147b917a2)         |\n| HQC                | Selected by [NIST](https://pqc-hqc.org/doc/hqc_specifications_2025_08_22.pdf) for upcoming standardization                                                                                                                                | [`PQClean/PQClean@1eacfda`](https://github.com/PQClean/PQClean/commit/1eacfdafc15ddc5d5759d0b85b4cef26627df181)                           |\n| Kyber              | Selected by [NIST](https://csrc.nist.gov/CSRC/media/Projects/post-quantum-cryptography/documents/round-3/submissions/Kyber-Round3.zip) as basis for ML-KEM (FIPS 203)                                                                     | [`pq-crystals/kyber@441c051`](https://github.com/pq-crystals/kyber/commit/441c0519a07e8b86c8d079954a6b10bd31d29efc)                       |\n| ML-KEM             | Standardized by [NIST](https://csrc.nist.gov/pubs/fips/203/final)                                                                                                                                                                         | [`pq-code-package/mlkem-native@048fc2a`](https://github.com/pq-code-package/mlkem-native/commit/048fc2a7a7b4ba0ad4c989c1ac82491aa94d5bfa) |\n| NTRU               | Not selected by [NIST](https://csrc.nist.gov/CSRC/media/Projects/post-quantum-cryptography/documents/round-3/submissions/NTRU-Round3.zip), under standardization consideration by [NTT](https://info.isl.ntt.co.jp/crypt/ntru/index.html) | [`PQClean/PQClean@4c9e5a3`](https://github.com/PQClean/PQClean/commit/4c9e5a3aa715cc8d1d0e377e4e6e682ebd7602d6)                           |\n| NTRU-Prime         | Not selected by [NIST](https://csrc.nist.gov/CSRC/media/Projects/post-quantum-cryptography/documents/round-3/submissions/NTRU-Prime-Round3.zip)                                                                                           | [`PQClean/PQClean@4c9e5a3`](https://github.com/PQClean/PQClean/commit/4c9e5a3aa715cc8d1d0e377e4e6e682ebd7602d6)                           |\n\n#### Signature schemes\n| Algorithm family   | Standardization status                                                                                                                                               | Primary implementation                                                                                                                      |\n|:-------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------|\n| CROSS              | Under [NIST](https://www.cross-crypto.com/CROSS_Specification_v2.2.pdf) consideration                                                                                | [`CROSS-signature/CROSS-lib-oqs@c8f7411`](https://github.com/CROSS-signature/CROSS-lib-oqs/commit/c8f7411fed136f0e37600973fa3dbed53465e54f) |\n| Falcon             | Selected by [NIST](https://csrc.nist.gov/CSRC/media/Projects/post-quantum-cryptography/documents/round-3/submissions/Falcon-Round3.zip) for upcoming standardization | [`PQClean/PQClean@1eacfda`](https://github.com/PQClean/PQClean/commit/1eacfdafc15ddc5d5759d0b85b4cef26627df181)                             |\n| MAYO               | Under [NIST](https://csrc.nist.gov/csrc/media/Projects/pqc-dig-sig/documents/round-2/spec-files/mayo-spec-round2-web.pdf) consideration                              | [`PQCMayo/MAYO-C@4b7cd94`](https://github.com/PQCMayo/MAYO-C/commit/4b7cd94c96b9522864efe40c6ad1fa269584a807)                               |\n| ML-DSA             | Standardized by [NIST](https://csrc.nist.gov/pubs/fips/204/final)                                                                                                    | [`pq-crystals/dilithium@444cdcc`](https://github.com/pq-crystals/dilithium/commit/444cdcc84eb36b66fe27b3a2529ee48f6d8150c2)                 |\n| SLH-DSA            | Standardized by [NIST](https://csrc.nist.gov/pubs/fips/205/final)                                                                                                    | [`pq-code-package/slhdsa-c@a0fc1ff`](https://github.com/pq-code-package/slhdsa-c/commit/a0fc1ff253930060d0246aebca06c2538eb92b88)           |\n| SNOVA              | Under [NIST](https://csrc.nist.gov/csrc/media/Projects/pqc-dig-sig/documents/round-2/spec-files/snova-spec-round2-web.pdf) consideration                             | [`vacuas/SNOVA@1c3ca6f`](https://github.com/vacuas/SNOVA/commit/1c3ca6f4f7286c0bde98d7d6f222cf63b9d52bff)                                   |\n| SPHINCS+           | Selected by [NIST](https://sphincs.org/data/sphincs+-r3.1-specification.pdf) as basis for SLH-DSA (FIPS 205)                                                         | [`PQClean/PQClean@1eacfda`](https://github.com/PQClean/PQClean/commit/1eacfdafc15ddc5d5759d0b85b4cef26627df181)                             |\n| UOV                | Under [NIST](https://csrc.nist.gov/csrc/media/Projects/pqc-dig-sig/documents/round-2/spec-files/uov-spec-round2-web.pdf) consideration                               | [`pqov/pqov@33fa527`](https://github.com/pqov/pqov/commit/33fa5278754a32064c55901c3a17d48b06cc2351)                                         |\n\n#### Stateful signature schemes\n| Algorithm family   | Standardization status                                                                                                                                         | Primary implementation                                          |\n|:-------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------|\n| LMS                | Standardized by [IRTF](https://www.rfc-editor.org/info/rfc8554), approved by [NIST](https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-208.pdf) | [`cisco/hash-sigs`](https://github.com/cisco/hash-sigs)         |\n| XMSS               | Standardized by [IRTF](https://www.rfc-editor.org/info/rfc8391), approved by [NIST](https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-208.pdf) | [`XMSS/xmss-reference`](https://github.com/XMSS/xmss-reference) |\n<!-- OQS_TEMPLATE_FRAGMENT_ALG_SUPPORT_END -->\n\n### Limitations and Security\n\nWhile at the time of this writing there are no vulnerabilities known in any of the quantum-safe algorithms used in this library, caution is advised when deploying quantum-safe algorithms as most of the algorithms and software have not been subject to the same degree of scrutiny as for currently deployed algorithms. Particular attention should be paid to guidance provided by the standards community, especially from the NIST [Post-Quantum Cryptography Standardization](https://csrc.nist.gov/Projects/Post-Quantum-Cryptography/Post-Quantum-Cryptography-Standardization) project.  As research advances, the supported algorithms may see rapid changes in their security, and may even prove insecure against both classical and quantum computers. Moreover, note that the `sntrup761` is only included for interop testing.\n\nliboqs does not intend to \"pick winners\": algorithm support is informed by the NIST PQC standardization project. We strongly recommend that applications and protocols rely on the outcomes of this effort when deploying post-quantum cryptography.\n\nWe realize some parties may want to deploy quantum-safe cryptography prior to the conclusion of the NIST PQC standardization project.  We strongly recommend such attempts make use of so-called **hybrid cryptography**, in which quantum-safe public-key algorithms are used alongside traditional public key algorithms (like RSA or elliptic curves) so that the solution is at least no less secure than existing traditional cryptography.\n\n**WE DO NOT CURRENTLY RECOMMEND RELYING ON THIS LIBRARY IN A PRODUCTION ENVIRONMENT OR TO PROTECT ANY SENSITIVE DATA.** This library is meant to help with research and prototyping.  While we make a best-effort approach to avoid security bugs, this library has not received the level of auditing and analysis that would be necessary to rely on it for high security use.\n\nPlease see [SECURITY.md](SECURITY.md#security-policy) for details on how to report a vulnerability and the OQS vulnerability response process.\n\n#### Platform limitations\n\nIn order to optimize support effort,\n- not all algorithms are equally well supported on all platforms. In case of questions, it is first advised to review the [documentation files for each algorithm](docs/algorithms).\n- not all compilers are equally well supported. For example, at least v7.1.0 of the GNU compiler is required.\n\n#### Support limitations\n\nThis project is not commercially supported. All guidelines and goals for liboqs are reflections of current practices, executed by a community of academic, part-time, and/or voluntary contributors on a best-effort basis and may change at any time. Any entity seeking more reliable commitments is strongly encouraged to join the OQS community and thus enhance the code and support that the community can provide.\n\n\n## Quickstart\n\n### Linux and Mac\n\n1. Install dependencies:\n\n\tOn Ubuntu:\n\n\t\t sudo apt install astyle cmake gcc ninja-build libssl-dev python3-pytest python3-pytest-xdist unzip xsltproc doxygen graphviz python3-yaml valgrind\n\n\tOn macOS, using a package manager of your choice (we've picked Homebrew):\n\n\t\tbrew install cmake ninja openssl@3 wget doxygen graphviz astyle valgrind\n\t\tpip3 install pytest pytest-xdist pyyaml\n\n\tUsing Nix:\n\n\t    nix develop\n\n\tNote that, if you want liboqs to use OpenSSL for various symmetric crypto algorithms (AES, SHA-2, etc.) then you must have OpenSSL installed (version 3.x recommended; EOL version 1.1.1 also still possible).\n\n2. Get the source:\n\n\t\tgit clone -b main https://github.com/open-quantum-safe/liboqs.git\n\t\tcd liboqs\n\n\tand build:\n\n\t\tmkdir build && cd build\n\t\tcmake -GNinja ..\n\t\tninja\n\nVarious `cmake` build options to customize the resultant artifacts are available and are [documented in CONFIGURE.md](CONFIGURE.md#options-for-configuring-liboqs-builds). All supported options are also listed in the `.CMake/alg-support.cmake` file, and can be viewed by running `cmake -LAH -N ..` in the `build` directory.\n\nThe following instructions assume we are in `build`.\n\n3. By default the main build result is `lib/liboqs.a`, a static library. If you want to build a shared/dynamic library, append [`-DBUILD_SHARED_LIBS=ON`](CONFIGURE.md#bUILD_SHARED_LIBS) to the `cmake -GNinja ..` command above and the result will be `lib/liboqs.so|dylib|dll`. The public headers are located in the `include` directory. There are also a variety of programs built under the `tests` directory:\n\n\t- `test_kem`: Simple test harness for key encapsulation mechanisms\n\t- `test_sig`: Simple test harness for signature schemes\n\t- `test_sig_stfl`: Simple test harness for stateful signature schemes\n\t- `test_kem_mem`: Simple test harness for checking memory consumption of key encapsulation mechanisms\n\t- `test_sig_mem`: Simple test harness for checking memory consumption of signature schemes\n\t- `kat_kem`: Program that generates known answer test (KAT) values for key encapsulation mechanisms using the same procedure as the NIST submission requirements, for checking against submitted KAT values using `tests/test_kat.py`\n\t- `kat_sig`: Program that generates known answer test (KAT) values for signature schemes using the same procedure as the NIST submission requirements, for checking against submitted KAT values using `tests/test_kat.py`\n\t- `kat_sig_stfl`: Program for checking results against submitted KAT values using `tests/test_kat.py`\n\t- `speed_kem`: Benchmarking program for key encapsulation mechanisms; see `./speed_kem --help` for usage instructions\n\t- `speed_sig`: Benchmarking program for signature mechanisms; see `./speed_sig --help` for usage instructions\n\t- `speed_sig_stfl`: Benchmarking program for stateful signature mechanisms; see `./speed_sig_stfl --help` for usage instructions\n\t- `example_kem`: Minimal runnable example showing the usage of the KEM API\n\t- `example_sig`: Minimal runnable example showing the usage of the signature API\n\t- `example_sig_stfl`: Minimal runnable example showing the usage of the stateful signature API\n\t- `test_aes`, `test_sha3`: Simple test harnesses for crypto sub-components\n\t- `test_portability`: Simple test harnesses for checking cross-CPU code portability; requires presence of `qemu`; proper operation validated only on Ubuntu\n\n\tThe complete test suite can be run using\n\n\t\tninja run_tests\n\n4. To generate HTML documentation of the API, run:\n\n\t\tninja gen_docs\n\n\tThen open `docs/html/index.html` in your web browser.\n\n4. `ninja install` can be run to install the built library and `include` files to a location of choice, which can be specified by passing the `-DCMAKE_INSTALL_PREFIX=<dir>` option to `cmake` at configure time. Alternatively, `ninja package` can be run to create an install package.\n\n5. `ninja uninstall` can be run to remove all installation files.\n\n\n### Windows\n\nBinaries can be generated using Visual Studio 2019 with the [CMake Tools](https://marketplace.visualstudio.com/items?itemName=ms-vscode.cmake-tools) extension installed. The same options as explained above for Linux/macOS can be used and build artifacts are generated in the specified `build` folders.\n\nIf you want to create Visual Studio build files, e.g., if not using `ninja`, be sure to _not_ pass the parameter `-GNinja` to the `cmake` command as exemplified above. You can then build all components using `msbuild`, e.g. as follows: `msbuild ALL_BUILD.vcxproj` and install all artifacts e.g. using this command `msbuild INSTALL.vcxproj`.\n\n\n### Cross compilation\n\nYou can cross compile liboqs for various platforms. Detailed information is available [in the Wiki](https://github.com/open-quantum-safe/liboqs/wiki/Platform-specific-notes-for-building-liboqs#cross-compiling).\n\n## Documentation\n\nMore detailed information on building, optional build parameters, example applications, coding conventions and more can be found in the [wiki](https://github.com/open-quantum-safe/liboqs/wiki).\n\n## Contributing\n\nContributions that meet the acceptance criteria are gratefully welcomed. See our [Contributing Guide](https://github.com/open-quantum-safe/liboqs/wiki/Contributing-Guide) for more details.\n\n## License\n\nliboqs is licensed under the MIT License; see [LICENSE.txt](https://github.com/open-quantum-safe/liboqs/blob/main/LICENSE.txt) for details.\n\nliboqs includes some third party libraries or modules that are licensed differently; the corresponding subfolder contains the license that applies in that case.  In particular:\n\n- `.CMake/CMakeDependentOption.cmake`: BSD 3-Clause License\n- `src/common/common.c`: includes portions which are Apache License v2.0\n- `src/common/crypto/aes/aes_c.c`: public domain or any OSI-approved license\n- `src/common/crypto/aes/aes*_ni.c`: public domain\n- `src/common/crypto/sha2/sha2_c.c`: public domain\n- `src/common/crypto/sha3/xkcp_low` : CC0 (public domain), except `brg_endian.h` and `KeccakP-1600-AVX2.s`\n- `src/common/crypto/sha3/xkcp_low/.../brg_endian.h` : BSD 3-Clause License\n- `src/common/crypto/sha3/xkcp_low/.../KeccakP-1600-AVX2.s` : BSD-like [CRYPTOGAMS license](http://www.openssl.org/~appro/cryptogams/)\n- `src/common/rand/rand_nist.c`: See file\n- `src/kem/bike/additional`: Apache License v2.0\n- `src/kem/classic_mceliece/pqclean_*`: public domain\n- `src/kem/kyber/pqcrystals-*`: public domain (CC0) or Apache License v2.0\n- `src/kem/kyber/pqclean_*`: public domain (CC0), and public domain (CC0) or Apache License v2.0, and public domain (CC0) or MIT, and MIT\n- `src/kem/kyber/libjade_*` public domain (CC0) or Apache License v2.\n- `src/kem/ml_kem/mlkem-native_*`: MIT or Apache License v2.0 or ISC License\n- `src/kem/ntru/pqclean_*`: public domain (CC0)\n-  src/sig/falcon/pqclean_\\*\\_aarch64 : Apache License v2.0\n- `src/sig/mayo/*`: Apache License v2.0\n- `src/sig/ml_dsa/pqcrystals-*`: public domain (CC0) or Apache License v2.0\n- `src/sig/sphincs/pqclean_*`: CC0 (public domain)\n\n## Acknowledgements\n\nThe OQS project is supported by the [Post-Quantum Cryptography Alliance](https://pqca.org/) as part of the [Linux Foundation](https://linuxfoundation.org/).\n\nThe OQS project was founded by Douglas Stebila and Michele Mosca at the University of Waterloo.  [Contributors to liboqs](https://github.com/open-quantum-safe/liboqs/blob/main/CONTRIBUTORS) include individual contributors, academics and researchers, and various companies, including Amazon Web Services, Cisco Systems, evolutionQ, IBM Research, Microsoft Research, SandboxAQ, and softwareQ.\n\nFinancial support for the development of Open Quantum Safe has been provided by Amazon Web Services, the Canadian Centre for Cyber Security, Cisco, the Unitary Fund, the NGI Assure Fund, and VeriSign Inc.\n\nResearch projects which developed specific components of OQS have been supported by various research grants, including funding from the Natural Sciences and Engineering Research Council of Canada (NSERC); see the source papers for funding acknowledgments.\n",
      "stars_today": 2
    },
    {
      "id": 982577878,
      "name": "nav3-recipes",
      "full_name": "android/nav3-recipes",
      "description": "Implement common use cases with Jetpack Navigation 3",
      "html_url": "https://github.com/android/nav3-recipes",
      "stars": 1100,
      "forks": 116,
      "language": "Kotlin",
      "topics": [
        "android",
        "compose",
        "navigation"
      ],
      "created_at": "2025-05-13T05:23:51Z",
      "updated_at": "2026-01-13T07:38:35Z",
      "pushed_at": "2026-01-12T18:14:19Z",
      "open_issues": 56,
      "owner": {
        "login": "android",
        "avatar_url": "https://avatars.githubusercontent.com/u/32689599?v=4"
      },
      "readme": "# Navigation 3 - Code recipes\n[Jetpack Navigation 3](https://goo.gle/nav3) is a library for app navigation. This repository contains recipes for how to \nuse its APIs to implement common navigation use cases. Each recipe introduces a single concept. Instead\nof making existing recipes more complex, there should be a new recipe for that particular concept.\n\nEvery Navigation 3 release will be an opportunity for patterns you see in recipes to \"graduate\" and become\n(optional) helpers in the library itself. Then we'll update the recipe to use that prebuilt helper, thus\nensuring that the recipes continue to be a good way to approach these kinds of problems.\n\nRecipes on the `main` branch use the **latest** (which may be an alpha or snapshot) version of Nav3. For recipes that use **stable** versions, check the [releases page](https://github.com/android/nav3-recipes/releases).\n\n## Recipes\nThese are the recipes and what they demonstrate. \n\n### Basic API examples\n- **[Basic](app/src/main/java/com/example/nav3recipes/basic)**: Shows most basic API usage.\n- **[Saveable back stack](app/src/main/java/com/example/nav3recipes/basicsaveable)**: As above, with a persistent back stack.\n- **[Entry provider DSL](app/src/main/java/com/example/nav3recipes/basicdsl)**: As above, using the entryProvider DSL.\n\n### Deep links\nRead the [guide to deeplinking](docs/deeplink-guide.md). Upvote [this issue](https://issuetracker.google.com/470282247) if you would like an API for deeplinks.\n- **[Basic](app/src/main/java/com/example/nav3recipes/deeplink/basic)**: Shows how to parse a deep link URL from an Android Intent into a navigation key.\n- **[Advanced](app/src/main/java/com/example/nav3recipes/deeplink/advanced)**: Shows how to handle deep links with a synthetic back stack and correct \"Up\" navigation behavior.\n\n### Layouts using Scenes\n- **[List-Detail Scene](app/src/main/java/com/example/nav3recipes/scenes/listdetail)**: Shows how to create a custom, list-detail layout using a `Scene` and `SceneStrategy` (see video of UI behavior below).\n- **[Two pane Scene](app/src/main/java/com/example/nav3recipes/scenes/twopane)**: Shows how to create a custom, 2-pane layout.\n- **[BottomSheet](app/src/main/java/com/example/nav3recipes/bottomsheet)**: Shows how to create a BottomSheet destination.\n- **[Dialog](app/src/main/java/com/example/nav3recipes/dialog)**: Shows how to create a Dialog.\n\n### Material adaptive layouts\nExamples showing how to use the layouts provided by the [Compose Material3 Adaptive Navigation3 library](https://developer.android.com/jetpack/androidx/releases/compose-material3-adaptive#compose_material3_adaptive_navigation3_version_10_2)\n- **[List-Detail](app/src/main/java/com/example/nav3recipes/material/listdetail)**: Shows how to use a Material adaptive list-detail layout.\n- **[Supporting Pane](app/src/main/java/com/example/nav3recipes/material/supportingpane)**: Shows how to use a Material adaptive supporting pane layout.\n\nNote: If you find a bug or have a feature request for Material3 Adaptive Scenes [please file it here](https://issuetracker.google.com/issues/new?component=1467081). Don't file an issue on this repository.\n\n### Animations\n- **[Animations](app/src/main/java/com/example/nav3recipes/animations)**: Shows how to override the default animations for all destinations and a single destination.\n\n### Common use cases\n- **[Common navigation UI](app/src/main/java/com/example/nav3recipes/commonui)**: A common navigation toolbar where each item in the toolbar navigates to a top level destination.  \n- **[Multiple back stacks](app/src/main/java/com/example/nav3recipes/multiplestacks)**: Shows how to create multiple top level routes, each with its own back stack. Top level routes are displayed in a navigation bar allowing users to switch between them. State is retained for each top level route, and the navigation state persists config changes and process death.  \n- **[Conditional navigation](app/src/main/java/com/example/nav3recipes/conditional)**: Switch to a different navigation flow when a condition is met. For example, for authentication or first-time user onboarding.\n\n### Architecture\n- **[Hilt - Modularized navigation code](app/src/main/java/com/example/nav3recipes/modular/hilt)**: Demonstrates how to decouple navigation code into separate modules (uses Dagger/Hilt for DI). \n- **[Koin - Modularized navigation code](app/src/main/java/com/example/nav3recipes/modular/koin)**: Demonstrates how to decouple navigation code into separate modules (uses Koin for DI).\n\n### Passing navigation arguments to ViewModels\n- **[Basic ViewModel](app/src/main/java/com/example/nav3recipes/passingarguments/viewmodels/basic)**: Navigation arguments are passed to a ViewModel constructed using `viewModel()`\n- **[Hilt injected ViewModel](app/src/main/java/com/example/nav3recipes/passingarguments/viewmodels/hilt)**: Navigation arguments are passed to a ViewModel constructed using `hiltViewModel()`\n- **[Koin injected ViewModel](app/src/main/java/com/example/nav3recipes/passingarguments/viewmodels/koin)**: Navigation arguments are passed to a ViewModel constructed using `koinViewModel()`\n\n### Returning Results\n- **[Returning Results as Events](app/src/main/java/com/example/nav3recipes/results/event)**: Returning results as events to content in another NavEntry.\n- **[Returning Results as State](app/src/main/java/com/example/nav3recipes/results/state)**: Returning results as state stored in a CompositionLocal.\n\n### Future recipes\nThe most upvoted [recipe requests]([url](https://github.com/android/nav3-recipes/issues?q=is%3Aissue%20state%3Aopen%20label%3Arecipe-request)) will be considered for implementation. Don't see your recipe? [File a request for one here](https://github.com/android/nav3-recipes/issues/new?template=1-recipe-request.md)\n\n## Custom layout example\nThe following is a screen recording showing the navigation behavior of a [custom, list-detail Scene](app/src/main/java/com/example/nav3recipes/scenes/listdetail).\n\n![Custom layout example](/docs/images/ListDetailScene.gif)\n\n## Instructions\nClone this repository and open the root folder in [Android Studio](https://developer.android.com/studio). Each recipe is contained in its own package with its own `Activity`.\n\n## Found an issue?\nIf the issue is _directly related to this project_, as in, it's reproducible without modifying this project's source code, then please [file an issue on github](https://github.com/android/nav3-recipes/issues/new?template=2-bug-report.md). If you've found an issue with the Jetpack Navigation 3 library, please [file an issue on the issue tracker](https://issuetracker.google.com/issues/new?component=1750212&template=2102223).\n\n## Contributing\nWe'd love to accept your contributions. Please follow [these instructions](CONTRIBUTING.md).\n\n## Compose Multiplatform Recipes\nCMP recipes can be found [here](https://github.com/terrakok/nav3-recipes).\n\n## License\n```\nCopyright 2025 The Android Open Source Project\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    https://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n",
      "stars_today": 2
    },
    {
      "id": 735441880,
      "name": "OpenTune",
      "full_name": "Arturo254/OpenTune",
      "description": "Un cliente de YouTube Music con Material Design 3, para Android",
      "html_url": "https://github.com/Arturo254/OpenTune",
      "stars": 1103,
      "forks": 82,
      "language": "Kotlin",
      "topics": [
        "client",
        "material-design-3",
        "open-source",
        "opspec",
        "youtube-api",
        "youtube-music-api",
        "youtubemusic"
      ],
      "created_at": "2023-12-25T00:23:00Z",
      "updated_at": "2026-01-13T11:17:15Z",
      "pushed_at": "2026-01-12T03:38:50Z",
      "open_issues": 243,
      "owner": {
        "login": "Arturo254",
        "avatar_url": "https://avatars.githubusercontent.com/u/87346871?v=4"
      },
      "readme": "# OpenTune\n\n<div align=\"center\">\n  <img src=\"https://github.com/Arturo254/OpenTune/blob/master/fastlane/metadata/android/en-US/images/featureGraphic.png\" alt=\"Banner de OpenTune\" width=\"100%\"/>\n  \n  ### Cliente Avanzado de YouTube Music con Material Design 3 para Android\n  \n  [![√öltima Versi√≥n](https://img.shields.io/github/v/release/Arturo254/OpenTune?style=flat-square&logo=github&color=0D1117&labelColor=161B22)](https://github.com/Arturo254/OpenTune/releases)\n  [![Licencia](https://img.shields.io/github/license/Arturo254/OpenTune?style=flat-square&logo=gnu&color=2B3137&labelColor=161B22)](https://github.com/Arturo254/OpenTune/blob/main/LICENSE)\n  [![Estado de Traducci√≥n](https://badges.crowdin.net/opentune/localized.svg)](https://crowdin.com/project/opentune)\n  [![Android](https://img.shields.io/badge/Plataforma-Android%206.0+-3DDC84.svg?style=flat-square&logo=android&logoColor=white&labelColor=161B22)](https://www.android.com)\n  [![Estrellas](https://img.shields.io/github/stars/Arturo254/OpenTune?style=flat-square&logo=github&color=yellow&labelColor=161B22)](https://github.com/Arturo254/OpenTune/stargazers)\n  [![Forks](https://img.shields.io/github/forks/Arturo254/OpenTune?style=flat-square&logo=github&color=blue&labelColor=161B22)](https://github.com/Arturo254/OpenTune/network/members)\n</div>\n\n\n\n\n[![English](https://img.shields.io/badge/readme.md-english-blue?style=for-the-badge)](README.en.md)\n\n\n\n---\n\n## Tabla de Contenido\n\n- [Visi√≥n General](#visi√≥n-general)\n- [Stack Tecnol√≥gico](#stack-tecnol√≥gico)\n- [Caracter√≠sticas Principales](#caracter√≠sticas-principales)\n- [Documentaci√≥n](#documentaci√≥n)\n- [Instalaci√≥n](#instalaci√≥n)\n- [Compilaci√≥n desde C√≥digo Fuente](#compilaci√≥n-desde-c√≥digo-fuente)\n- [Contribuciones](#contribuciones)\n- [Apoya el Proyecto](#apoya-el-proyecto)\n- [Reconocimientos](#reconocimientos)\n- [Licencia](#licencia)\n\n---\n\n## Visi√≥n General\n\n**OpenTune** es un cliente de YouTube Music de c√≥digo abierto dise√±ado para dispositivos Android. Ofrece una experiencia de usuario superior con una interfaz moderna que implementa Material Design 3, proporcionando funcionalidades avanzadas para explorar, reproducir y gestionar contenido musical sin las limitaciones de la aplicaci√≥n oficial.\n\n### Beneficios Clave\n\n- **Experiencia sin Anuncios**: Disfruta de m√∫sica sin interrupciones publicitarias\n- **Rendimiento Mejorado**: Optimizado para reproducci√≥n y navegaci√≥n fluida\n- **Enfoque en la Privacidad**: Sin recolecci√≥n de datos ni seguimiento\n- **Interfaz Personalizable**: Personaliza tu experiencia musical\n- **Capacidades Offline**: Descarga y reproduce m√∫sica sin conexi√≥n a internet\n\n> **Nota**: OpenTune es un proyecto independiente y no est√° afiliado, patrocinado ni respaldado por YouTube o Google.\n\n---\n\n## Stack Tecnol√≥gico\n\n<div align=\"center\">\n  \n| Frontend | Backend | Herramientas de Desarrollo |\n|:--------:|:-------:|:-------------------------:|\n| ![Kotlin](https://img.shields.io/badge/Kotlin-7F52FF?style=for-the-badge&logo=kotlin&logoColor=white) | ![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white) | ![Android Studio](https://img.shields.io/badge/Android%20Studio-3DDC84?style=for-the-badge&logo=androidstudio&logoColor=white) |\n| ![Jetpack Compose](https://img.shields.io/badge/Jetpack%20Compose-4285F4?style=for-the-badge&logo=jetpackcompose&logoColor=white) | ![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white) | ![Gradle](https://img.shields.io/badge/Gradle-02303A?style=for-the-badge&logo=gradle&logoColor=white) |\n| ![Material Design 3](https://img.shields.io/badge/Material%20Design%203-757575?style=for-the-badge&logo=materialdesign&logoColor=white) | | ![Git](https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=git&logoColor=white) |\n\n</div>\n\n---\n\n## Caracter√≠sticas Principales\n\n### Funcionalidad Principal\n<table>\n<tr>\n<th width=\"30%\">Caracter√≠stica</th>\n<th width=\"70%\">Descripci√≥n</th>\n</tr>\n<tr>\n<td><strong>üéµ Reproducci√≥n sin Anuncios</strong></td>\n<td>Disfruta de m√∫sica sin interrupciones publicitarias</td>\n</tr>\n<tr>\n<td><strong>üîÑ Reproducci√≥n en Segundo Plano</strong></td>\n<td>Contin√∫a escuchando mientras usas otras aplicaciones</td>\n</tr>\n<tr>\n<td><strong>üîç B√∫squeda Avanzada</strong></td>\n<td>Encuentra r√°pidamente canciones, v√≠deos, √°lbumes y listas de reproducci√≥n</td>\n</tr>\n<tr>\n<td><strong>üë§ Integraci√≥n de Cuenta</strong></td>\n<td>Inicia sesi√≥n para sincronizar preferencias y colecciones</td>\n</tr>\n<tr>\n<td><strong>üìö Gesti√≥n de Biblioteca</strong></td>\n<td>Organiza y administra completamente tu colecci√≥n musical</td>\n</tr>\n<tr>\n<td><strong>üì± Modo Offline</strong></td>\n<td>Descarga contenido para escuchar sin conexi√≥n</td>\n</tr>\n</table>\n\n### Mejoras de Audio\n<table>\n<tr>\n<th width=\"30%\">Caracter√≠stica</th>\n<th width=\"70%\">Descripci√≥n</th>\n</tr>\n<tr>\n<td><strong>üé§ Letras Sincronizadas</strong></td>\n<td>Visualiza letras de canciones perfectamente sincronizadas</td>\n</tr>\n<tr>\n<td><strong>‚ö° Omisi√≥n Inteligente de Silencios</strong></td>\n<td>Omite autom√°ticamente segmentos sin audio</td>\n</tr>\n<tr>\n<td><strong>üîä Normalizaci√≥n de Volumen</strong></td>\n<td>Equilibra los niveles de sonido entre diferentes pistas</td>\n</tr>\n<tr>\n<td><strong>üéõÔ∏è Control de Tempo y Tono</strong></td>\n<td>Ajusta la velocidad y el tono de reproducci√≥n seg√∫n preferencias</td>\n</tr>\n</table>\n\n### Personalizaci√≥n e Integraci√≥n\n<table>\n<tr>\n<th width=\"30%\">Caracter√≠stica</th>\n<th width=\"70%\">Descripci√≥n</th>\n</tr>\n<tr>\n<td><strong>üé® Temas Din√°micos</strong></td>\n<td>La interfaz se adapta a los colores de las portadas de √°lbumes</td>\n</tr>\n<tr>\n<td><strong>üåê Soporte Multiidioma</strong></td>\n<td>Disponible en numerosos idiomas para usuarios globales</td>\n</tr>\n<tr>\n<td><strong>üöó Compatible con Android Auto</strong></td>\n<td>Integraci√≥n con sistemas de infoentretenimiento vehicular</td>\n</tr>\n<tr>\n<td><strong>üéØ Material Design 3</strong></td>\n<td>Dise√±o alineado con las √∫ltimas directrices de dise√±o de Google</td>\n</tr>\n<tr>\n<td><strong>üñºÔ∏è Exportaci√≥n de Portadas</strong></td>\n<td>Guarda im√°genes de √°lbumes en alta resoluci√≥n</td>\n</tr>\n</table>\n\n---\n\n## Documentaci√≥n\n\nPara informaci√≥n detallada sobre configuraci√≥n, caracter√≠sticas avanzadas y gu√≠as de uso, consulta nuestra documentaci√≥n oficial:\n\n<div align=\"center\">\n  \n[![Documentaci√≥n](https://img.shields.io/badge/Documentaci√≥n-GitBook-4285F4?style=for-the-badge&logo=gitbook&logoColor=white)](https://opentune.gitbook.io/)\n\n</div>\n\n---\n\n## Instalaci√≥n\n\n### Requisitos del Sistema\n\n| Componente | Requisito M√≠nimo |\n|:-----------|:-----------------|\n| Sistema Operativo | Android 6.0 (Marshmallow) o superior |\n| Espacio de Almacenamiento | 10 MB disponibles |\n| Red | Conexi√≥n a Internet para streaming |\n| RAM | 2 GB recomendados |\n\n### M√©todos de Instalaci√≥n\n\n#### Opci√≥n 1: Releases de GitHub (Recomendado)\n\n1. Navega a la secci√≥n de [Releases](https://github.com/Arturo254/OpenTune/releases) en GitHub\n2. Descarga el archivo APK de la √∫ltima versi√≥n estable\n3. Habilita \"Instalar desde fuentes desconocidas\" en la configuraci√≥n de seguridad de tu dispositivo\n4. Abre el archivo APK descargado para completar la instalaci√≥n\n\n#### Opci√≥n 2: Sitio Web Oficial\n\n1. Visita el [sitio web oficial de OpenTune](https://opentune.netlify.app/)\n2. Selecciona la opci√≥n de descarga para Android\n3. Sigue las instrucciones de instalaci√≥n proporcionadas\n\n#### Opci√≥n 3: F-Droid\n\n<div align=\"center\">\n  \n[![F-Droid](https://img.shields.io/badge/F--Droid-1976D2?style=for-the-badge&logo=f-droid&logoColor=white)](https://f-droid.org/es/packages/com.Arturo254.opentune/)\n\n</div>\n\n#### Opci√≥n 4: OpenApk\n\n<div align=\"center\">\n  \n[![OpenApk](https://img.shields.io/badge/OpenApk-FF6B35?style=for-the-badge&logo=android&logoColor=white)](https://www.openapk.net/opentune/com.Arturo254.opentune/)\n\n</div>\n\n> **Aviso de Seguridad**: Por razones de seguridad, se recomienda obtener la aplicaci√≥n exclusivamente a trav√©s de los canales oficiales mencionados anteriormente. Evita descargar APKs de fuentes no verificadas.\n\n---\n\n## Compilaci√≥n desde C√≥digo Fuente\n\n### Requisitos Previos\n\n<table>\n<tr>\n<th>Herramienta</th>\n<th>Versi√≥n Recomendada</th>\n<th>Prop√≥sito</th>\n</tr>\n<tr>\n<td>Gradle</td>\n<td>7.5 o superior</td>\n<td>Automatizaci√≥n de construcci√≥n</td>\n</tr>\n<tr>\n<td>Kotlin</td>\n<td>1.7 o superior</td>\n<td>Lenguaje de programaci√≥n</td>\n</tr>\n<tr>\n<td>Android Studio</td>\n<td>2022.1 o superior</td>\n<td>IDE y entorno de desarrollo</td>\n</tr>\n<tr>\n<td>JDK</td>\n<td>11 o superior</td>\n<td>Entorno de ejecuci√≥n Java</td>\n</tr>\n<tr>\n<td>Android SDK</td>\n<td>API nivel 33 (Android 13)</td>\n<td>Herramientas de desarrollo Android</td>\n</tr>\n</table>\n\n### Configuraci√≥n del Entorno\n\n```bash\n# Clonar el repositorio\ngit clone https://github.com/Arturo254/OpenTune.git\n\n# Navegar al directorio del proyecto\ncd OpenTune\n\n# Actualizar subm√≥dulos (si los hay)\ngit submodule update --init --recursive\n```\n\n### M√©todos de Compilaci√≥n\n\n#### Compilaci√≥n con Android Studio\n\n1. Abre Android Studio\n2. Selecciona \"Abrir un proyecto existente de Android Studio\"\n3. Navega y selecciona el directorio de OpenTune\n4. Espera a que se complete la sincronizaci√≥n del proyecto y la indexaci√≥n\n5. Selecciona Construir ‚Üí Construir Bundle(s) / APK(s) ‚Üí Construir APK(s)\n\n#### Compilaci√≥n por L√≠nea de Comandos\n\n```bash\n# Construir versi√≥n de producci√≥n\n./gradlew assembleRelease\n\n# Construir versi√≥n de depuraci√≥n\n./gradlew assembleDebug\n\n# Construcci√≥n completa con pruebas\n./gradlew build\n\n# Ejecutar pruebas unitarias\n./gradlew test\n\n# Limpiar construcci√≥n\n./gradlew clean\n```\n\n> **Nota**: Los archivos APK compilados se ubicar√°n en el directorio `app/build/outputs/apk/`.\n\n---\n\n## Contribuciones\n\n### C√≥digo de Conducta\n\nTodos los participantes en este proyecto deben adherirse a nuestro c√≥digo de conducta que promueve un entorno inclusivo, respetuoso y constructivo. Por favor, revisa el [C√≥digo de Conducta completo](https://github.com/Arturo254/OpenTune/blob/master/CODE_OF_CONDUCT.md) antes de contribuir.\n\n### Traducci√≥n\n\nAyuda a traducir OpenTune a tu idioma o mejorar las traducciones existentes:\n\n<div align=\"center\">\n  \n[![POEditor](https://img.shields.io/badge/POEditor-2196F3?style=for-the-badge&logo=translate&logoColor=white)](https://poeditor.com/join/project/208BwCVazA)\n[![Crowdin](https://img.shields.io/badge/Crowdin-2E3440?style=for-the-badge&logo=crowdin&logoColor=white)](https://crowdin.com/project/opentune)\n\n</div>\n\n### Canales de Comunidad\n\n<div align=\"center\">\n  \n[![Chat de Telegram](https://img.shields.io/badge/Telegram-Chat-2CA5E0?style=for-the-badge&logo=telegram&logoColor=white)](https://t.me/OpenTune_chat)\n[![Actualizaciones de Telegram](https://img.shields.io/badge/Telegram-Actualizaciones-2CA5E0?style=for-the-badge&logo=telegram&logoColor=white)](https://t.me/opentune_updates)\n\n</div>\n\n### Flujo de Trabajo de Desarrollo\n\n1. **Revisi√≥n de Issues**: Verifica [issues abiertas](https://github.com/Arturo254/OpenTune/issues) o crea una nueva describiendo el problema o caracter√≠stica\n2. **Fork del Repositorio**: Crea un fork personal del repositorio\n3. **Rama de Caracter√≠stica**: Crea una rama para tu caracter√≠stica (`git checkout -b feature/nueva-caracteristica`)\n4. **Implementaci√≥n**: Implementa cambios siguiendo las convenciones de c√≥digo del proyecto\n5. **Pruebas**: Aseg√∫rate de que el c√≥digo pase todas las pruebas (`./gradlew test`)\n6. **Commit**: Realiza commits con mensajes descriptivos (`git commit -m 'feat: a√±adir nueva caracter√≠stica'`)\n7. **Push de Cambios**: Sube cambios a tu fork (`git push origin feature/nueva-caracteristica`)\n8. **Pull Request**: Abre un PR detallando los cambios y referenciando la issue correspondiente\n\n> **Directrices de Desarrollo**: Revisa nuestras [directrices de contribuci√≥n](https://github.com/Arturo254/OpenTune/blob/master/CONTRIBUTING.md) para informaci√≥n detallada sobre el proceso de desarrollo, est√°ndares de c√≥digo y flujo de trabajo.\n\n---\n\n## Apoya el Proyecto\n\nSi encuentras valor en **OpenTune** y quieres contribuir a su desarrollo continuo, considera hacer una donaci√≥n. Tu apoyo financiero nos permite:\n\n- Implementar nuevas caracter√≠sticas y mejoras\n- Corregir errores y optimizar el rendimiento\n- Mantener la infraestructura del proyecto\n- Dedicar m√°s tiempo al desarrollo y mantenimiento\n\n<div align=\"center\">\n  \n[![GitHub Sponsors](https://img.shields.io/badge/GitHub_Sponsors-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/sponsors/Arturo254)\n[![PayPal](https://img.shields.io/badge/PayPal-00457C?style=for-the-badge&logo=paypal&logoColor=white)](mailto:cervantesarturo254@gmail.com)\n\n</div>\n\n> **Nota**: Las donaciones son completamente opcionales. OpenTune siempre ser√° gratuito y de c√≥digo abierto, independientemente del apoyo financiero recibido.\n\n---\n\n## Reconocimientos\n\nAgradecimientos especiales a los siguientes contribuidores y colaboradores:\n\n- **mostafaalagamy** - Implementaci√≥n de MetroList\n‚ÄéVivi Music (Inspiraci√≥n de dise√±o) \n- **Fabito02** - Apoyo incondicional desde el principio\n- **Traductores de la comunidad** - Haciendo OpenTune accesible mundialmente\n- **Testers beta** - Ayudando a mejorar la estabilidad y usabilidad\n\n---\n\n## Licencia\n\n**Copyright ¬© 2025 Arturo Cervantes**\n\nEste programa es software libre: puedes redistribuirlo y/o modificarlo bajo los t√©rminos de la Licencia P√∫blica General GNU publicada por la Free Software Foundation, ya sea la versi√≥n 3 de la Licencia, o (a tu elecci√≥n) cualquier versi√≥n posterior.\n\nEste programa se distribuye con la esperanza de que sea √∫til, pero **SIN NINGUNA GARANT√çA**; ni siquiera la garant√≠a impl√≠cita de COMERCIABILIDAD o IDONEIDAD PARA UN PROP√ìSITO PARTICULAR. Consulta la [Licencia P√∫blica General GNU](https://github.com/Arturo254/OpenTune/blob/main/LICENSE) para m√°s detalles.\n\n<div align=\"center\">\n  \n[![GPL v3](https://img.shields.io/badge/Licencia-GPLv3-blue.svg?style=for-the-badge&logo=gnu&logoColor=white)](https://www.gnu.org/licenses/gpl-3.0)\n\n</div>\n\n> **Importante**: Cualquier uso comercial no autorizado de este software o sus derivados constituye una violaci√≥n de los t√©rminos de licencia.\n\n---\n\n<div align=\"center\">\n  <p><strong>¬© 2023-2024 Proyectos de C√≥digo Abierto</strong></p>\n  <p>Desarrollado con pasi√≥n por <a href=\"https://github.com/Arturo254\">Arturo Cervantes</a></p>\n  \n  <br>\n  \n  [![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/Arturo254)\n  [![Email](https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:cervantesarturo254@gmail.com)\n  \n</div>\n",
      "stars_today": 2
    },
    {
      "id": 33486016,
      "name": "Kingfisher",
      "full_name": "onevcat/Kingfisher",
      "description": "A lightweight, pure-Swift library for downloading and caching images from the web.",
      "html_url": "https://github.com/onevcat/Kingfisher",
      "stars": 24234,
      "forks": 2744,
      "language": "Swift",
      "topics": [
        "cache",
        "filters",
        "image",
        "image-processor",
        "ios",
        "kingfisher",
        "macos",
        "swift",
        "xcode"
      ],
      "created_at": "2015-04-06T14:26:21Z",
      "updated_at": "2026-01-13T19:22:58Z",
      "pushed_at": "2026-01-05T14:19:51Z",
      "open_issues": 172,
      "owner": {
        "login": "onevcat",
        "avatar_url": "https://avatars.githubusercontent.com/u/1019875?v=4"
      },
      "readme": "<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/onevcat/Kingfisher/master/images/logo.png\" alt=\"Kingfisher\" title=\"Kingfisher\" width=\"557\"/>\n</p>\n\n<p align=\"center\">\n<a href=\"https://github.com/onevcat/Kingfisher/actions?query=workflow%3Abuild\"><img src=\"https://github.com/onevcat/kingfisher/workflows/build/badge.svg?branch=master\"></a>\n<a href=\"https://swiftpackageindex.com/onevcat/Kingfisher/master/documentation/kingfisher\"><img src=\"https://img.shields.io/badge/Swift-Doc-DE5C43.svg?style=flat\"></a>\n<a href=\"https://cocoapods.org/pods/Kingfisher\"><img src=\"https://img.shields.io/github/v/tag/onevcat/Kingfisher.svg?color=blue&include_prereleases=&sort=semver\"></a>\n<a href=\"https://swift.org/package-manager/\"><img src=\"https://img.shields.io/badge/SPM-supported-DE5C43.svg?style=flat\"></a>\n<a href=\"https://raw.githubusercontent.com/onevcat/Kingfisher/master/LICENSE\"><img src=\"https://img.shields.io/badge/license-MIT-black\"></a>\n</p>\n\nKingfisher is a powerful, pure-Swift library for downloading and caching images from the web. It provides you a chance to use a pure-Swift way to work with remote images in your next app.\n\n## Features\n\n- [x] Asynchronous image downloading and caching.\n- [x] Loading image from either `URLSession`-based networking or local provided data.\n- [x] Useful image processors and filters provided.\n- [x] Multiple-layer hybrid cache for both memory and disk.\n- [x] Fine control on cache behavior. Customizable expiration date and size limit.\n- [x] Cancelable downloading and auto-reusing previous downloaded content to improve performance.\n- [x] Independent components. Use the downloader, caching system, and image processors separately as you need.\n- [x] Prefetching images and showing them from the cache to boost your app.\n- [x] Extensions for `UIImageView`, `NSImageView`, `NSButton`, `UIButton`, `NSTextAttachment`, `WKInterfaceImage`, `TVMonogramView` and `CPListItem` to directly set an image from a URL.\n- [x] Built-in transition animation when setting images.\n- [x] Customizable placeholder and indicator while loading images.\n- [x] Extensible image processing and image format easily.\n- [x] Low Data Mode support.\n- [x] SwiftUI support.\n- [x] Swift 6 & Swift Concurrency (strict mode) prepared.\n- [x] Load & cache for Live Photo.\n\n### Kingfisher 101\n\nThe simplest use-case is setting an image to an image view with the `UIImageView` extension:\n\n```swift\nimport Kingfisher\n\nlet url = URL(string: \"https://example.com/image.png\")\nimageView.kf.setImage(with: url)\n```\n\nKingfisher will download the image from `url`, send it to both memory cache and disk cache, and display it in `imageView`. \nWhen you set it with the same URL later, the image will be retrieved from the cache and shown immediately.\n\nIt also works if you use SwiftUI:\n\n```swift\nvar body: some View {\n    KFImage(URL(string: \"https://example.com/image.png\")!)\n}\n```\n\n### A More Advanced Example\n\nWith the powerful options, you can do hard tasks with Kingfisher in a simple way. For example, the code below: \n\n1. Downloads a high-resolution image.\n2. Downsamples it to match the image view size.\n3. Makes it round cornered with a given radius.\n4. Shows a system indicator and a placeholder image while downloading.\n5. When prepared, it animates the small thumbnail image with a \"fade in\" effect. \n6. The original large image is also cached to disk for later use, to get rid of downloading it again in a detail view.\n7. A console log is printed when the task finishes, either for success or failure.\n\n```swift\nlet url = URL(string: \"https://example.com/high_resolution_image.png\")\nlet processor = DownsamplingImageProcessor(size: imageView.bounds.size)\n             |> RoundCornerImageProcessor(cornerRadius: 20)\nimageView.kf.indicatorType = .activity\nimageView.kf.setImage(\n    with: url,\n    placeholder: UIImage(named: \"placeholderImage\"),\n    options: [\n        .processor(processor),\n        .scaleFactor(UIScreen.main.scale),\n        .transition(.fade(1)),\n        .cacheOriginalImage\n    ])\n{\n    result in\n    switch result {\n    case .success(let value):\n        print(\"Task done for: \\(value.source.url?.absoluteString ?? \"\")\")\n    case .failure(let error):\n        print(\"Job failed: \\(error.localizedDescription)\")\n    }\n}\n```\n\nIt is a common situation I can meet in my daily work. Think about how many lines you need to write without\nKingfisher!\n\n### Method Chaining\n\nIf you are not a fan of the `kf` extension, you can also prefer to use the `KF` builder and chained the method \ninvocations. The code below is doing the same thing:\n\n```swift\n// Use `kf` extension\nimageView.kf.setImage(\n    with: url,\n    placeholder: placeholderImage,\n    options: [\n        .processor(processor),\n        .loadDiskFileSynchronously,\n        .cacheOriginalImage,\n        .transition(.fade(0.25)),\n        .lowDataMode(.network(lowResolutionURL))\n    ],\n    progressBlock: { receivedSize, totalSize in\n        // Progress updated\n    },\n    completionHandler: { result in\n        // Done\n    }\n)\n\n// Use `KF` builder\nKF.url(url)\n  .placeholder(placeholderImage)\n  .setProcessor(processor)\n  .loadDiskFileSynchronously()\n  .cacheMemoryOnly()\n  .fade(duration: 0.25)\n  .lowDataModeSource(.network(lowResolutionURL))\n  .onProgress { receivedSize, totalSize in  }\n  .onSuccess { result in  }\n  .onFailure { error in }\n  .set(to: imageView)\n```\n\nAnd even better, if later you want to switch to SwiftUI, just change the `KF` above to `KFImage`, and you've done:\n\n```swift\nstruct ContentView: View {\n    var body: some View {\n        KFImage.url(url)\n          .placeholder(placeholderImage)\n          .setProcessor(processor)\n          .loadDiskFileSynchronously()\n          .cacheMemoryOnly()\n          .fade(duration: 0.25)\n          .lowDataModeSource(.network(lowResolutionURL))\n          .onProgress { receivedSize, totalSize in  }\n          .onSuccess { result in  }\n          .onFailure { error in }\n    }\n}\n```\n\n## Requirements\n\n### Kingfisher 8.0\n\n- (UIKit/AppKit) iOS 13.0+ / macOS 10.15+ / tvOS 13.0+ / watchOS 6.0+ / visionOS 1.0+\n- (SwiftUI) iOS 14.0+ / macOS 11.0+ / tvOS 14.0+ / watchOS 7.0+ / visionOS 1.0+\n- Swift 5.9+\n\n### Kingfisher 7.0\n\n- (UIKit/AppKit) iOS 12.0+ / macOS 10.14+ / tvOS 12.0+ / watchOS 5.0+ / visionOS 1.0+\n- (SwiftUI) iOS 14.0+ / macOS 11.0+ / tvOS 14.0+ / watchOS 7.0+ / visionOS 1.0+\n- Swift 5.0+\n\n### Installation\n\nRefer to one of the following tutorials to install and use the framework:\n\n- [UIKit Tutorial](https://swiftpackageindex.com/onevcat/kingfisher/master/tutorials/kingfisher/gettingstarteduikit)\n- [SwiftUI Tutorial](https://swiftpackageindex.com/onevcat/kingfisher/master/tutorials/kingfisher/gettingstartedswiftui)\n\nAlternatively, you can follow either of the methods below.\n\n#### Swift Package Manager\n\n- File > Swift Packages > Add Package Dependency\n- Add `https://github.com/onevcat/Kingfisher.git`\n- Select \"Up to Next Major\" with \"8.0.0\"\n\n#### CocoaPods\n\n```ruby\nsource 'https://github.com/CocoaPods/Specs.git'\nplatform :ios, '13.0'\nuse_frameworks!\n\ntarget 'MyApp' do\n  pod 'Kingfisher', '~> 8.0'\nend\n```\n\n#### Pre-built Framework\n\n1. Open the release page, download the latest version of Kingfisher from the assets section. \n2. Drag the `Kingfisher.xcframework` into your project and add it to the target (usually the app target).\n3. Select your target, in the \"General\" Tab, find the \"Frameworks, Libraries, and Embedded Content\" section, set the `Embed Without Signing` to Kingfisher.\n\n## Documentation\n\nCheck the documentation and tutorials:\n\n- [Documentation Home](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher)\n- [Getting Started](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/gettingstarted)\n    - [UIKit Tutorial](https://swiftpackageindex.com/onevcat/kingfisher/master/tutorials/kingfisher/gettingstarteduikit)\n    - [SwiftUI Tutorial](https://swiftpackageindex.com/onevcat/kingfisher/master/tutorials/kingfisher/gettingstartedswiftui)\n- [Common Tasks - General](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/commontasks)\n    - [Common Tasks - Cache](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/commontasks_cache)\n    - [Common Tasks - Downloader](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/commontasks_downloader)\n    - [Common tasks - Processor](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/commontasks_processor)\n\n### Migrating\n\n- [Kingfisher 8.0 Migration](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/migration-to-8)\n- [Kingfisher 7.0 Migration](https://github.com/onevcat/Kingfisher/wiki/Kingfisher-7.0-Migration-Guide)\n\nIf you are using an even earlier version, see the guides below to know the steps for migrating.\n\n## Other\n\n### Future of Kingfisher\n\nI want to keep Kingfisher lightweight. This framework focuses on providing a simple solution for downloading and caching images. This doesn‚Äôt mean the framework can‚Äôt be improved. Kingfisher is far from perfect, so necessary and useful updates will be made to make it better.\n\n### Developments and Tests\n\nAny contributing and pull requests are warmly welcome. However, before you plan to implement some features or try to fix an uncertain issue, it is recommended to open a discussion first. It would be appreciated if your pull requests could build with all tests green. :)\n\n### About the logo\n\nThe logo of Kingfisher is inspired by [Tangram (‰∏ÉÂ∑ßÊùø)](http://en.wikipedia.org/wiki/Tangram), a dissection puzzle consisting of seven flat shapes from China. I believe she's a kingfisher bird instead of a swift, but someone insists that she is a pigeon. I guess I should give her a name. Hi, guys, do you have any suggestions?\n\n### Contact\n\nFollow and contact me on [Twitter](http://twitter.com/onevcat) or [Sina Weibo](http://weibo.com/onevcat). If you find an issue, [open a ticket](https://github.com/onevcat/Kingfisher/issues/new). Pull requests are warmly welcome as well.\n\n## Backers & Sponsors\n\nOpen-source projects cannot live long without your help. If you find Kingfisher to be useful, please consider supporting this \nproject by becoming a sponsor. Your user icon or company logo shows up [on my blog](https://onevcat.com/tabs/about/) with a link to your home page. \n\nBecome a sponsor through [GitHub Sponsors](https://github.com/sponsors/onevcat). :heart:\n\nSpecial thanks to:\n\n[![imgly](https://user-images.githubusercontent.com/1812216/106253726-271ed000-6218-11eb-98e0-c9c681925770.png)](https://img.ly/)\n\n[![emergetools](https://github-production-user-asset-6210df.s3.amazonaws.com/1019875/254794187-d44f6f50-993f-42e3-b79c-960f69c4adc1.png)](https://www.emergetools.com)\n\n\n\n### License\n\nKingfisher is released under the MIT license. See LICENSE for details.\n",
      "stars_today": 1
    },
    {
      "id": 6687936,
      "name": "mbedtls",
      "full_name": "Mbed-TLS/mbedtls",
      "description": "An open source, portable, easy to use, readable and flexible TLS library, and reference implementation of the PSA Cryptography API. Releases are on a varying cadence, typically around 3 - 6 months between releases.",
      "html_url": "https://github.com/Mbed-TLS/mbedtls",
      "stars": 6392,
      "forks": 2828,
      "language": "C",
      "topics": [
        "crypto",
        "cryptography-library",
        "psa",
        "ssl",
        "tls"
      ],
      "created_at": "2012-11-14T13:13:13Z",
      "updated_at": "2026-01-13T23:41:02Z",
      "pushed_at": "2026-01-13T23:40:56Z",
      "open_issues": 1563,
      "owner": {
        "login": "Mbed-TLS",
        "avatar_url": "https://avatars.githubusercontent.com/u/97226525?v=4"
      },
      "readme": "README for Mbed TLS\n===================\n\nMbed TLS is a C library that implements X.509 certificate manipulation and the TLS and DTLS protocols. Its small code footprint makes it suitable for embedded systems.\nMbed TLS includes the [TF-PSA-Crypto repository](https://github.com/Mbed-TLS/TF-PSA-Crypto) that provides an implementation of the [PSA Cryptography API](https://arm-software.github.io/psa-api).\n\nConfiguration\n-------------\nConfiguration options related to X.509 and TLS are available in `include/mbedtls/mbedtls_config.h`, while cryptography and platform options are located in the TF-PSA-Crypto configuration file `tf-psa-crypto/include/psa/crypto_config.h`.\n\nWith the default platform options, Mbed TLS should build out of the box on most systems.\n\nThese configuration files can be edited manually, or programmatically using the Python script `scripts/config.py` (run with --help for usage instructions).\n\nWe provide some non-standard configurations focused on specific use cases in the `configs/` directory. You can read more about those in `configs/README.txt`.\n\nDocumentation\n-------------\n\nThe main Mbed TLS documentation is available via [ReadTheDocs](https://mbed-tls.readthedocs.io/).\n\nTo generate a local copy of the library documentation in HTML format, tailored to your compile-time configuration:\n\n1. Make sure that [Doxygen](http://www.doxygen.nl/) is installed.\n1. Run `cmake -B /path/to/build_dir /path/to/mbedtls/source`\n1. Run `cmake --build /path/to/build_dir --target mbedtls-apidoc`\n1. Open one of the main generated HTML files:\n   * `apidoc/index.html`\n   * `apidoc/modules.html` or `apidoc/topics.html`\n\nFor other sources of documentation, see the [SUPPORT](SUPPORT.md) document.\n\nCompiling\n---------\n\nWe use CMake to configure and drive our build process. Three libraries are built: `libtfpsacrypto`, `libmbedx509`, and `libmbedtls`. Note that `libmbedtls` depends on `libmbedx509` and `libtfpsacrypto`, and `libmbedx509` depends on `libtfpsacrypto`. As a result, some linkers will expect flags to be in a specific order, for example the GNU linker wants `-lmbedtls -lmbedx509 -ltfpsacrypto`. The cryptographic library `libtfpsacrypto` is also provided under its legacy name, `libmbedcrypto`.\n\n### Tool versions\n\nYou need the following tools to build the library from the main branch with the provided CMake files. Mbed TLS minimum tool version requirements are set based on the versions shipped in the latest or penultimate (depending on the release cadence) long-term support releases of major Linux distributions, namely at time of writing: Ubuntu 22.04, RHEL 9, and SLES 15 SP4.\n\n* CMake 3.20.2 or later.\n* A build system like Make or Ninja for which CMake can generate build files.\n* A C99 toolchain (compiler, linker, archiver). We actively test with GCC 5.4, Clang 3.8, Arm Compiler 6, and Visual Studio 2017 Compiler. More recent versions should work. Slightly older versions may work.\n* Python 3.8 or later to generate the test code. Python is also needed to build the development branch (see next section).\n* Perl to run the tests, and to generate some source files in the development branch.\n* Doxygen 1.8.14 or later (if building the documentation; slightly older versions should work).\n\n### Git usage\n\nThe supported branches (see [`BRANCHES.md`](BRANCHES.md)) use [Git submodules](https://git-scm.com/book/en/v2/Git-Tools-Submodules#_cloning_submodules). They contain two submodules: the [framework](https://github.com/Mbed-TLS/mbedtls-framework) submodule and the [tf-psa-crypto](https://github.com/Mbed-TLS/TF-PSA-Crypto) submodule, except for the 3.6 LTS branch, which contains only the framework submodule. Release tags also use Git submodules.\n\nAfter cloning or checking out a branch or tag, run:\n    ```\n    git submodule update --init --recursive\n    ```\n to initialize and update the submodules before building.\n\nHowever, the official source release tarballs (e.g. [mbedtls-4.0.0.tar.bz2](https://github.com/Mbed-TLS/mbedtls/releases/download/mbedtls-4.0.0/mbedtls-4.0.0.tar.bz2)) include the contents of the submodules.\n\n### Generated source files in the development branch\n\nThe source code of Mbed TLS includes some files that are automatically generated by scripts and whose content depends only on the Mbed TLS source, not on the platform or on the library configuration. These files are not included in the development branch of Mbed TLS, but the generated files are included in official releases. This section explains how to generate the missing files in the development branch.\n\nThe following tools are required:\n\n* Perl, for some library source files.\n* Python 3 and some Python packages, for some library source files, sample programs and test data. To install the necessary packages, run:\n    ```\n    python3 -m pip install --user -r scripts/basic.requirements.txt\n    ```\n    Depending on your Python installation, you may need to invoke `python` instead of `python3`. To install the packages system-wide or in a virtual environment, omit the `--user` option.\n* A C compiler for the host platform, for some test data.\n\nThe scripts that generate the configuration-independent files will look for a host C compiler in the following places (in order of preference):\n\n1. The `HOSTCC` environment variable. This can be used if `CC` is pointing to a cross-compiler.\n2. The `CC` environment variable.\n3. An executable called `cc` in the current path.\n\nNote: If you have multiple toolchains installed, it is recommended to set `CC` or `HOSTCC` to the intended host compiler before generating the files.\n\nAny of the following methods are available to generate the configuration-independent files:\n\n* On non-Windows systems, when not cross-compiling, CMake generates the required files automatically.\n* Run `framework/scripts/make_generated_files.py` to generate all the configuration-independent files.\n\n### CMake\n\nIn order to build the libraries using CMake in a separate directory (recommended), just enter at the command line:\n\n    mkdir /path/to/build_dir && cd /path/to/build_dir\n    cmake /path/to/mbedtls_source\n    cmake --build .\n\nIn order to run the tests, enter:\n\n    ctest\n\nThe test suites need Python to be built. If you don't have Python installed, you'll want to disable the test suites with:\n\n    cmake -DENABLE_TESTING=Off /path/to/mbedtls_source\n\nTo configure CMake for building shared libraries, use:\n\n    cmake -DUSE_SHARED_MBEDTLS_LIBRARY=On /path/to/mbedtls_source\n\nThere are many different build types available with CMake. Most of them are available for gcc and clang, though some are compiler-specific:\n\n-   `Release`. This generates the default code without any unnecessary information in the binary files.\n-   `Debug`. This generates debug information and disables optimization of the code.\n-   `Coverage`. This generates code coverage information in addition to debug information.\n-   `ASan`. This instruments the code with AddressSanitizer to check for memory errors. (This includes LeakSanitizer, with recent version of gcc and clang.) (With recent version of clang, this mode also instruments the code with UndefinedSanitizer to check for undefined behaviour.)\n-   `ASanDbg`. Same as ASan but slower, with debug information and better stack traces.\n-   `MemSan`. This instruments the code with MemorySanitizer to check for uninitialised memory reads.\n-   `MemSanDbg`. Same as MemSan but slower, with debug information, better stack traces and origin tracking.\n-   `Check`. This activates the compiler warnings that depend on optimization and treats all warnings as errors.\n-   `TSan`. This instruments the code with ThreadSanitizer to detect data races and other threading-related concurrency issues at runtime.\n-   `TSanDbg`. Same as TSan but slower, with debug information, better stack traces and origin tracking.\n\nSwitching build types in CMake is simple. For debug mode, enter at the command line:\n\n    cmake -D CMAKE_BUILD_TYPE=Debug /path/to/mbedtls_source\n\nTo list other available CMake options, use:\n\n    cmake -LH\n\nNote that, with CMake, you can't adjust the compiler or its flags after the\ninitial invocation of cmake. This means that `CC=your_cc make` and `make\nCC=your_cc` will *not* work (similarly with `CFLAGS` and other variables).\nThese variables need to be adjusted when invoking cmake for the first time,\nfor example:\n\n    CC=your_cc cmake /path/to/mbedtls_source\n\nIf you already invoked cmake and want to change those settings, you need to\ninvoke the configuration phase of CMake again with the new settings.\n\nNote that it is possible to build in-place; this will however overwrite the\nlegacy Makefiles still used for testing purposes (see\n`scripts/tmp_ignore_makefiles.sh` if you want to prevent `git status` from\nshowing them as modified). In order to do so, from the Mbed TLS source\ndirectory, use:\n\n    cmake .\n    cmake --build .\n\nIf you want to change `CC` or `CFLAGS` afterwards, you will need to remove the\nCMake cache. This can be done with the following command using GNU find:\n\n    find . -iname '*cmake*' -not -name CMakeLists.txt -exec rm -rf {} +\n\nYou can now make the desired change:\n\n    CC=your_cc cmake .\n    cmake --build .\n\nRegarding variables, also note that if you set CFLAGS when invoking cmake,\nyour value of CFLAGS doesn't override the content provided by CMake (depending\non the build mode as seen above), it's merely prepended to it.\n\n#### Consuming Mbed TLS\n\nMbed TLS provides a CMake package configuration file for consumption as a\ndependency in other CMake projects. You can load its CMake targets with:\n\n    find_package(MbedTLS REQUIRED)\n\nYou can help CMake find the package:\n\n- By setting the variable `MbedTLS_DIR` to `${YOUR_MBEDTLS_BUILD_DIR}/cmake`,\n  as shown in `programs/test/cmake_package/CMakeLists.txt`, or\n- By adding the Mbed TLS installation prefix to `CMAKE_PREFIX_PATH`,\n  as shown in `programs/test/cmake_package_install/CMakeLists.txt`.\n\nAfter a successful `find_package(MbedTLS)`, the following imported targets are available:\n\n- `MbedTLS::tfpsacrypto`, the crypto library\n- `MbedTLS::mbedtls`, the TLS library\n- `MbedTLS::mbedx509`, the X.509 library\n\nYou can then use these directly through `target_link_libraries()`:\n\n    add_executable(xyz)\n\n    target_link_libraries(xyz\n        PUBLIC MbedTLS::mbedtls\n               MbedTLS::tfpsacrypto\n               MbedTLS::mbedx509)\n\nThis will link the Mbed TLS libraries to your library or application, and add\nits include directories to your target (transitively, in the case of `PUBLIC` or\n`INTERFACE` link libraries).\n\n#### Mbed TLS as a subproject\n\nMbed TLS supports being built as a CMake subproject. One can\nuse `add_subdirectory()` from a parent CMake project to include Mbed TLS as a\nsubproject.\n\nExample programs\n----------------\n\nWe've included example programs for a lot of different features and uses in [`programs/`](programs/README.md).\nPlease note that the goal of these sample programs is to demonstrate specific features of the library, and the code may need to be adapted to build a real-world application.\n\nTests\n-----\n\nMbed TLS includes an elaborate test suite in `tests/` that initially requires Python to generate the tests files (e.g. `test_suite_ssl.c`). These files are generated from a `function file` (e.g. `suites/test_suite_ssl.function`) and a `data file` (e.g. `suites/test_suite_ssl.data`). The `function file` contains the test functions. The `data file` contains the test cases, specified as parameters that will be passed to the test function.\n\nFor machines with a Unix shell and OpenSSL (and optionally GnuTLS) installed, additional test scripts are available:\n\n-   `tests/ssl-opt.sh` runs integration tests for various TLS options (renegotiation, resumption, etc.) and tests interoperability of these options with other implementations.\n-   `tests/compat.sh` tests interoperability of every ciphersuite with other implementations.\n-   `tests/scripts/depends.py` tests builds in configurations with a single curve, key exchange, hash, cipher, or pkalg on.\n-   `tests/scripts/all.sh` runs a combination of the above tests, plus some more, with various build options (such as ASan, full `mbedtls_config.h`, etc).\n\nInstead of manually installing the required versions of all tools required for testing, it is possible to use the Docker images from our CI systems, as explained in [our testing infrastructure repository](https://github.com/Mbed-TLS/mbedtls-test/blob/main/README.md#quick-start).\n\nPorting Mbed TLS\n----------------\n\nMbed TLS can be ported to many different architectures, OS's and platforms. Before starting a port, you may find the following Knowledge Base articles useful:\n\n-   [Porting Mbed TLS to a new environment or OS](https://mbed-tls.readthedocs.io/en/latest/kb/how-to/how-do-i-port-mbed-tls-to-a-new-environment-OS/)\n-   [What external dependencies does Mbed TLS rely on?](https://mbed-tls.readthedocs.io/en/latest/kb/development/what-external-dependencies-does-mbedtls-rely-on/)\n-   [How do I configure Mbed TLS](https://mbed-tls.readthedocs.io/en/latest/kb/compiling-and-building/how-do-i-configure-mbedtls/)\n\nMbed TLS is mostly written in portable C99; however, it has a few platform requirements that go beyond the standard, but are met by most modern architectures:\n\n- Bytes must be 8 bits.\n- All-bits-zero must be a valid representation of a null pointer.\n- Signed integers must be represented using two's complement.\n- `int` and `size_t` must be at least 32 bits wide.\n- The types `uint8_t`, `uint16_t`, `uint32_t` and their signed equivalents must be available.\n- Mixed-endian platforms are not supported.\n- SIZE_MAX must be at least as big as INT_MAX and UINT_MAX.\n\nLicense\n-------\n\nUnless specifically indicated otherwise in a file, Mbed TLS files are provided under a dual [Apache-2.0](https://spdx.org/licenses/Apache-2.0.html) OR [GPL-2.0-or-later](https://spdx.org/licenses/GPL-2.0-or-later.html) license. See the [LICENSE](LICENSE) file for the full text of these licenses, and [the 'License and Copyright' section in the contributing guidelines](CONTRIBUTING.md#License-and-Copyright) for more information.\n\nContributing\n------------\n\nWe gratefully accept bug reports and contributions from the community. Please see the [contributing guidelines](CONTRIBUTING.md) for details on how to do this.\n\nContact\n-------\n\n* To report a security vulnerability in Mbed TLS, please email <mbed-tls-security@lists.trustedfirmware.org>. For more information, see [`SECURITY.md`](SECURITY.md).\n* To report a bug or request a feature in Mbed TLS, please [file an issue on GitHub](https://github.com/Mbed-TLS/mbedtls/issues/new/choose).\n* Please see [`SUPPORT.md`](SUPPORT.md) for other channels for discussion and support about Mbed TLS.\n",
      "stars_today": 1
    },
    {
      "id": 19438,
      "name": "ggplot2",
      "full_name": "tidyverse/ggplot2",
      "description": "An implementation of the Grammar of Graphics in R",
      "html_url": "https://github.com/tidyverse/ggplot2",
      "stars": 6853,
      "forks": 2117,
      "language": "R",
      "topics": [
        "data-visualisation",
        "r",
        "visualisation"
      ],
      "created_at": "2008-05-25T01:21:32Z",
      "updated_at": "2026-01-13T19:24:38Z",
      "pushed_at": "2025-12-18T13:22:01Z",
      "open_issues": 92,
      "owner": {
        "login": "tidyverse",
        "avatar_url": "https://avatars.githubusercontent.com/u/22032646?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# ggplot2 <a href=\"https://ggplot2.tidyverse.org\"><img src=\"man/figures/logo.png\" align=\"right\" height=\"138\" alt=\"ggplot2 website\" /></a>\n\n<!-- badges: start -->\n\n[![R-CMD-check](https://github.com/tidyverse/ggplot2/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/tidyverse/ggplot2/actions/workflows/R-CMD-check.yaml)\n[![CRAN_Status_Badge](https://www.r-pkg.org/badges/version/ggplot2)](https://cran.r-project.org/package=ggplot2)\n[![Codecov test\ncoverage](https://codecov.io/gh/tidyverse/ggplot2/graph/badge.svg)](https://app.codecov.io/gh/tidyverse/ggplot2)\n<!-- badges: end -->\n\n## Overview\n\nggplot2 is a system for declaratively creating graphics, based on [The\nGrammar of\nGraphics](https://link.springer.com/book/10.1007/0-387-28695-0). You\nprovide the data, tell ggplot2 how to map variables to aesthetics, what\ngraphical primitives to use, and it takes care of the details.\n\n## Installation\n\n``` r\n# The easiest way to get ggplot2 is to install the whole tidyverse:\ninstall.packages(\"tidyverse\")\n\n# Alternatively, install just ggplot2:\ninstall.packages(\"ggplot2\")\n\n# Or the development version from GitHub:\n# install.packages(\"pak\")\npak::pak(\"tidyverse/ggplot2\")\n```\n\n## Cheatsheet\n\n<a href=\"https://github.com/rstudio/cheatsheets/blob/main/data-visualization.pdf\"><img src=\"https://raw.githubusercontent.com/rstudio/cheatsheets/main/pngs/thumbnails/data-visualization-cheatsheet-thumbs.png\" width=\"630\" height=\"252\" alt=\"ggplot2 cheatsheet\" /></a>\n\n## Usage\n\nIt‚Äôs hard to succinctly describe how ggplot2 works because it embodies a\ndeep philosophy of visualisation. However, in most cases you start with\n`ggplot()`, supply a dataset and aesthetic mapping (with `aes()`). You\nthen add on layers (like `geom_point()` or `geom_histogram()`), scales\n(like `scale_colour_brewer()`), faceting specifications (like\n`facet_wrap()`) and coordinate systems (like `coord_flip()`).\n\n``` r\nlibrary(ggplot2)\n\nggplot(mpg, aes(displ, hwy, colour = class)) +\n  geom_point()\n```\n\n<img src=\"man/figures/README-example-1.png\" alt=\"Scatterplot of engine displacement versus highway miles per gallon, for 234 cars coloured by 7 'types' of car. The displacement and miles per gallon are inversely correlated.\"  />\n\n## Lifecycle\n\n[![lifecycle](https://img.shields.io/badge/lifecycle-stable-brightgreen.svg)](https://lifecycle.r-lib.org/articles/stages.html)\n\nggplot2 is now 18 years old and is used by hundreds of thousands of\npeople to make millions of plots. That means, by-and-large, ggplot2\nitself changes relatively little. When we do make changes, they will be\ngenerally to add new functions or arguments rather than changing the\nbehaviour of existing functions, and if we do make changes to existing\nbehaviour we will do them for compelling reasons.\n\nIf you are looking for innovation, look to ggplot2‚Äôs rich ecosystem of\nextensions. See a community maintained list at\n<https://exts.ggplot2.tidyverse.org/gallery/>.\n\n## Learning ggplot2\n\nIf you are new to ggplot2 you are better off starting with a systematic\nintroduction, rather than trying to learn from reading individual\ndocumentation pages. Currently, there are several good places to start:\n\n1.  The [Data Visualization](https://r4ds.hadley.nz/data-visualize) and\n    [Communication](https://r4ds.hadley.nz/communication) chapters in [R\n    for Data Science](https://r4ds.hadley.nz). R for Data Science is\n    designed to give you a comprehensive introduction to the\n    [tidyverse](https://tidyverse.org/), and these two chapters will get\n    you up to speed with the essentials of ggplot2 as quickly as\n    possible.\n\n2.  If you‚Äôd like to take an online course, try [Data Visualization in R\n    With\n    ggplot2](https://learning.oreilly.com/videos/data-visualization-in/9781491963661/)\n    by Kara Woo.\n\n3.  If you‚Äôd like to follow a webinar, try [Plotting Anything with\n    ggplot2](https://youtu.be/h29g21z0a68) by Thomas Lin Pedersen.\n\n4.  If you want to dive into making common graphics as quickly as\n    possible, I recommend [The R Graphics\n    Cookbook](https://r-graphics.org) by Winston Chang. It provides a\n    set of recipes to solve common graphics problems.\n\n5.  If you‚Äôve mastered the basics and want to learn more, read [ggplot2:\n    Elegant Graphics for Data Analysis](https://ggplot2-book.org). It\n    describes the theoretical underpinnings of ggplot2 and shows you how\n    all the pieces fit together. This book helps you understand the\n    theory that underpins ggplot2, and will help you create new types of\n    graphics specifically tailored to your needs.\n\n6.  For articles about announcements and deep-dives you can visit the\n    [tidyverse blog](https://tidyverse.org/tags/ggplot2/).\n\n## Getting help\n\nThere are two main places to get help with ggplot2:\n\n1.  The [Posit Community](https://forum.posit.co/) (formerly RStudio\n    Community) is a friendly place to ask any questions about ggplot2.\n\n2.  [Stack\n    Overflow](https://stackoverflow.com/questions/tagged/ggplot2?sort=frequent&pageSize=50)\n    is a great source of answers to common ggplot2 questions. It is also\n    a great place to get help, once you have created a reproducible\n    example that illustrates your problem.\n",
      "stars_today": 1
    },
    {
      "id": 5050525,
      "name": "harfbuzz",
      "full_name": "harfbuzz/harfbuzz",
      "description": "HarfBuzz text shaping engine",
      "html_url": "https://github.com/harfbuzz/harfbuzz",
      "stars": 5280,
      "forks": 708,
      "language": "C++",
      "topics": [
        "aat",
        "c",
        "c-plus-plus",
        "fonts",
        "library",
        "opentype",
        "text-rendering",
        "text-shaping",
        "typography",
        "unicode",
        "variable-fonts"
      ],
      "created_at": "2012-07-14T19:50:26Z",
      "updated_at": "2026-01-14T00:21:12Z",
      "pushed_at": "2026-01-12T20:41:22Z",
      "open_issues": 86,
      "owner": {
        "login": "harfbuzz",
        "avatar_url": "https://avatars.githubusercontent.com/u/33817416?v=4"
      },
      "readme": "# HarfBuzz\n\n<div align=\"center\">\n\n<p><img src=\"HarfBuzz.png\" alt=\"HarfBuzz Logo\" width=\"256\"/></p>\n\n[![Linux CI Status](https://github.com/harfbuzz/harfbuzz/actions/workflows/linux.yml/badge.svg)](https://github.com/harfbuzz/harfbuzz/actions/workflows/linux.yml)\n[![macoOS CI Status](https://github.com/harfbuzz/harfbuzz/actions/workflows/macos.yml/badge.svg)](https://github.com/harfbuzz/harfbuzz/actions/workflows/macos.yml)\n[![Windows CI Status](https://github.com/harfbuzz/harfbuzz/actions/workflows/msvc.yml/badge.svg)](https://github.com/harfbuzz/harfbuzz/actions/workflows/msvc.yml)\n[![OSS-Fuzz Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/harfbuzz.svg)](https://oss-fuzz-build-logs.storage.googleapis.com/index.html#harfbuzz)\n[![Coverity Scan Build Status](https://scan.coverity.com/projects/15166/badge.svg)](https://scan.coverity.com/projects/harfbuzz)\n[![Packaging status](https://repology.org/badge/tiny-repos/harfbuzz.svg)](https://repology.org/project/harfbuzz/versions)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/harfbuzz/harfbuzz/badge)](https://securityscorecards.dev/viewer/?uri=github.com/harfbuzz/harfbuzz)\n\n</div>\n\nHarfBuzz is a text shaping engine. It primarily supports [OpenType][1], but also\n[Apple Advanced Typography][2].\nCheck ‚Äú[What is HarfBuzz?](https://harfbuzz.github.io/what-is-harfbuzz.html)‚Äù chapter\nin the user manual for more inforamation on what HarfBuzz do and what it doesn‚Äôt do.\n\nThe canonical source tree and bug trackers are available on [github][4].\nBoth development and user support discussion around HarfBuzz happen on\n[github][4] as well.\n\nFor license information, see [COPYING](COPYING).\n\n## API stability\n\nThe API that comes with `hb.h` will not change incompatibly. Other, peripheral,\nheaders are more likely to go through minor modifications, but again, we do our\nbest to never change API in an incompatible way. We will never break the ABI.\n\nThe API and ABI are stable even across major version number jumps. In fact,\ncurrent HarfBuzz is API/ABI compatible all the way back to the 0.9.x series.\nIf one day we need to break the API/ABI, that would be called a new library.\n\nAs such, we bump the major version number only when we add major new features,\nthe minor version when there is new API, and the micro version when there\nare bug fixes.\n\n## Documentation\n\nFor user manual as well as API documentation, check: https://harfbuzz.github.io\n\n## Download\n\nTarball releases of HarfBuzz are available on [github releases][3] page. At the same place you\nwill also find Win32/Win64 binary bundles that include `libharfbuzz` DLL,\n`hb-view.exe`, `hb-shape.exe`, and all dependencies.\n\n## Development\n\nFor build information, see [BUILD.md](BUILD.md).\n\nFor custom configurations, see [CONFIG.md](CONFIG.md).\n\nFor testing and profiling, see [TESTING.md](TESTING.md).\n\nFor using with Python, see [README.python.md](README.python.md). There is also [uharfbuzz](https://github.com/harfbuzz/uharfbuzz).\n\nFor cross-compiling to Windows from Linux or macOS, see [README.mingw.md](README.mingw.md).\n\nTo report bugs or submit patches please use [github][4] issues and pull-requests.\n\n### Developer documents\n\nTo get a better idea of where HarfBuzz stands in the text rendering stack you\nmay want to read [State of Text Rendering 2024][6].\nHere are a few presentation slides about HarfBuzz at the\nInternationalization and Unicode Conference over the years:\n\n- 2014 ‚Äì [Unicode, OpenType, and HarfBuzz: Closing the Circle][7]\n- 2012 ‚Äì [HarfBuzz, The Free and Open Text Shaping Engine][8]\n- 2016 ‚Äì [Ten Years of HarfBuzz][20]\n- 2009 ‚Äì [HarfBuzz: the Free and Open Shaping Engine][9]\n\nMore presentations and papers are available on [behdad][11]'s website.\nIn particular, the following _studies_ are relevant to HarfBuzz development:\n\n- 2025 ‚Äì [AAT layout caches][24]\n- 2025 ‚Äì [OpenType Layout lookup caches][23]\n- 2025 ‚Äì [Introducing HarfRust][22]\n- 2025 ‚Äì [Subsetting][21]\n- 2025 ‚Äì [Caching][12]\n- 2025 ‚Äì [`hb-decycler`][13]\n- 2022 ‚Äì [`hb-iter`][14]\n- 2022 ‚Äì [A C library written in C++][15]\n- 2022 ‚Äì [The case of the slow `hb-ft` `>h_advance` function][18]\n- 2022 ‚Äì [PackTab: A static integer table packer][16]\n- 2020 ‚Äì [HarfBuzz OT+AAT \"Unishaper\"][19]\n- 2014 ‚Äì [Building the Indic Shaper][17]\n- 2012 ‚Äì [Memory Consumption][10]\n\n\n## Name\n\nHarfBuzz (ÿ≠ÿ±ŸÅ‚Äåÿ®ÿßÿ≤) is the literal Persian translation of ‚Äú[OpenType][1]‚Äù,\ntransliterated using the Latin script. It also means \"talkative\" or\n\"glib\" (also a nod to the GNOME project where HarfBuzz originates from).\n\n> Background: Originally there was this font format called TrueType. People and\n> companies started calling their type engines all things ending in Type:\n> FreeType, CoolType, ClearType, etc. And then came OpenType, which is the\n> successor of TrueType. So, for my OpenType implementation, I decided to stick\n> with the concept but use the Persian translation. Which is fitting given that\n> Persian is written in the Arabic script, and OpenType is an extension of\n> TrueType that adds support for complex script rendering, and HarfBuzz is an\n> implementation of OpenType complex text shaping.\n\n## Users\n\nHarfBuzz is used in Android, Chrome,\nChromeOS, Firefox, GNOME, GTK+, KDE, Qt, LibreOffice, OpenJDK, XeTeX, Scribus,\nPlayStation, Microsoft Edge, Amazon Kindle, Adobe Photoshop, Illustrator,\nInDesign, Godot Engine, Unreal Engine, QuarkXPress, Figma, and other places.\n\n<p align=\"center\">\n  <a href=\"https://xkcd.com/2347/\" rel=\"nofollow\">\n    <img src=\"xkcd.png\" width=\"256\" alt=\"xkcd-derived image\">\n  </a>\n</p>\n\n## Distribution\n\n<details>\n  <summary>Packaging status of HarfBuzz</summary>\n\n[![Packaging status](https://repology.org/badge/vertical-allrepos/harfbuzz.svg?header=harfbuzz)](https://repology.org/project/harfbuzz/versions)\n\n</details>\n\n[1]: https://docs.microsoft.com/en-us/typography/opentype/spec/\n[2]: https://developer.apple.com/fonts/TrueType-Reference-Manual/RM06/Chap6AATIntro.html\n[3]: https://github.com/harfbuzz/harfbuzz/releases\n[4]: https://github.com/harfbuzz/harfbuzz\n[6]: https://behdad.org/text2024\n[7]: https://docs.google.com/presentation/d/1x97pfbB1gbD53Yhz6-_yBUozQMVJ_5yMqqR_D-R7b7I/preview\n[8]: https://docs.google.com/presentation/d/1ySTZaXP5XKFg0OpmHZM00v5b17GSr3ojnzJekl4U8qI/preview\n[9]: https://behdad.org/doc/harfbuzz2009-slides.pdf\n[10]: https://docs.google.com/document/d/12jfNpQJzeVIAxoUSpk7KziyINAa1msbGliyXqguS86M/preview\n[11]: https://behdad.org/\n[12]: https://docs.google.com/document/d/1_VgObf6Je0J8byMLsi7HCQHnKo2emGnx_ib_sHo-bt4/preview\n[13]: https://docs.google.com/document/d/1Y-u08l9YhObRVObETZt1k8f_5lQdOix9TRH3zEXaoAw/preview\n[14]: https://docs.google.com/document/d/1o-xvxCbgMe9JYFHLVnPjk01ZY_8Cj0vB9-KTI1d0nyk/preview\n[15]: https://docs.google.com/document/d/18hI56KJpvXtwWbc9QSaz9zzhJwIMnrJ-zkAaKS-W-8k/preview\n[16]: https://docs.google.com/document/d/1Xq3owVt61HVkJqbLFHl73il6pcTy6PdPJJ7bSouQiQw/preview\n[17]: https://docs.google.com/document/d/1wMPwVNBvsIriamcyBO5aNs7Cdr8lmbwLJ8GmZBAswF4/preview\n[18]: https://docs.google.com/document/d/1wskYbA-czBt57oH9gEuGf3sWbTx7bfOiEIcDs36-heo/preview\n[19]: https://prezi.com/view/THNPJGFVDUCWoM20syev/\n[20]: https://behdad.org/doc/harfbuzz10years-slides.pdf\n[21]: https://docs.google.com/document/d/1_vZrt97OorJ0jA1YzJ29LRcGr3YGrNJANdOABjVZGEs/preview\n[22]: https://docs.google.com/document/d/1aH_waagdEM5UhslQxCeFEb82ECBhPlZjy5_MwLNLBYo/preview\n[23]: https://docs.google.com/document/d/1hRd5oYQJLrt0JuwWhEJWi7wh_9rbaIJkX6IR9DW7rZQ/preview\n[24]: https://docs.google.com/document/d/1a3K6fHjsiWW36vSzwJwCwEBOgznunKs80PSpBbpfHiA/preview\n",
      "stars_today": 1
    },
    {
      "id": 96496250,
      "name": "swift-snapshot-testing",
      "full_name": "pointfreeco/swift-snapshot-testing",
      "description": "üì∏ Delightful Swift snapshot testing.",
      "html_url": "https://github.com/pointfreeco/swift-snapshot-testing",
      "stars": 4111,
      "forks": 641,
      "language": "Swift",
      "topics": [
        "screenshot-testing",
        "snapshot-testing",
        "swift",
        "testing"
      ],
      "created_at": "2017-07-07T03:38:51Z",
      "updated_at": "2026-01-13T15:28:50Z",
      "pushed_at": "2025-11-17T17:51:33Z",
      "open_issues": 194,
      "owner": {
        "login": "pointfreeco",
        "avatar_url": "https://avatars.githubusercontent.com/u/29466629?v=4"
      },
      "readme": "# üì∏ SnapshotTesting\n\n[![CI](https://github.com/pointfreeco/swift-snapshot-testing/workflows/CI/badge.svg)](https://actions-badge.atrox.dev/pointfreeco/swift-snapshot-testing/goto)\n[![Slack](https://img.shields.io/badge/slack-chat-informational.svg?label=Slack&logo=slack)](http://pointfree.co/slack-invite)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-snapshot-testing%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-snapshot-testing%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing)\n\nDelightful Swift snapshot testing.\n\n## Usage\n\nOnce [installed](#installation), _no additional configuration is required_. You can import the\n`SnapshotTesting` module and call the `assertSnapshot` function.\n\n``` swift\nimport SnapshotTesting\nimport Testing\n\n@MainActor\nstruct MyViewControllerTests {\n  @Test func myViewController() {\n    let vc = MyViewController()\n\n    assertSnapshot(of: vc, as: .image)\n  }\n}\n```\n\nWhen an assertion first runs, a snapshot is automatically recorded to disk and the test will fail,\nprinting out the file path of any newly-recorded reference.\n\n> ‚ùå failed - No reference was found on disk. Automatically recorded snapshot: ‚Ä¶\n>\n> open \"‚Ä¶/MyAppTests/\\_\\_Snapshots\\_\\_/MyViewControllerTests/testMyViewController.png\"\n>\n> Re-run \"testMyViewController\" to test against the newly-recorded snapshot.\n\nRepeat test runs will load this reference and compare it with the runtime value. If they don't\nmatch, the test will fail and describe the difference. Failures can be inspected from Xcode's Report\nNavigator or by inspecting the file URLs of the failure.\n\nYou can record a new reference by customizing snapshots inline with the assertion, or using the\n`withSnapshotTesting` tool:\n\n```swift\n// Record just this one snapshot\nassertSnapshot(of: vc, as: .image, record: .all)\n\n// Record all snapshots in a scope:\nwithSnapshotTesting(record: .all) {\n  assertSnapshot(of: vc1, as: .image)\n  assertSnapshot(of: vc2, as: .image)\n  assertSnapshot(of: vc3, as: .image)\n}\n\n// Record all snapshot failures in a Swift Testing suite:\n@Suite(.snapshots(record: .failed))\nstruct FeatureTests {}\n\n// Record all snapshot failures in an 'XCTestCase' subclass:\nclass FeatureTests: XCTestCase {\n  override func invokeTest() {\n    withSnapshotTesting(record: .failed) {\n      super.invokeTest()\n    }\n  }\n}\n```\n\n## Snapshot Anything\n\nWhile most snapshot testing libraries in the Swift community are limited to `UIImage`s of `UIView`s,\nSnapshotTesting can work with _any_ format of _any_ value on _any_ Swift platform!\n\nThe `assertSnapshot` function accepts a value and any snapshot strategy that value supports. This\nmeans that a view or view controller can be tested against an image representation _and_ against a\ntextual representation of its properties and subview hierarchy.\n\n``` swift\nassertSnapshot(of: vc, as: .image)\nassertSnapshot(of: vc, as: .recursiveDescription)\n```\n\nView testing is highly configurable. You can override trait collections (for specific size classes\nand content size categories) and generate device-agnostic snapshots, all from a single simulator.\n\n``` swift\nassertSnapshot(of: vc, as: .image(on: .iPhoneSe))\nassertSnapshot(of: vc, as: .recursiveDescription(on: .iPhoneSe))\n\nassertSnapshot(of: vc, as: .image(on: .iPhoneSe(.landscape)))\nassertSnapshot(of: vc, as: .recursiveDescription(on: .iPhoneSe(.landscape)))\n\nassertSnapshot(of: vc, as: .image(on: .iPhoneX))\nassertSnapshot(of: vc, as: .recursiveDescription(on: .iPhoneX))\n\nassertSnapshot(of: vc, as: .image(on: .iPadMini(.portrait)))\nassertSnapshot(of: vc, as: .recursiveDescription(on: .iPadMini(.portrait)))\n```\n\n> **Warning**\n> Snapshots must be compared using the exact same simulator that originally took the reference to\n> avoid discrepancies between images.\n\nBetter yet, SnapshotTesting isn't limited to views and view controllers! There are a number of\navailable snapshot strategies to choose from.\n\nFor example, you can snapshot test URL requests (_e.g._, those that your API client prepares).\n\n``` swift\nassertSnapshot(of: urlRequest, as: .raw)\n// POST http://localhost:8080/account\n// Cookie: pf_session={\"userId\":\"1\"}\n//\n// email=blob%40pointfree.co&name=Blob\n```\n\nAnd you can snapshot test `Encodable` values against their JSON _and_ property list representations.\n\n``` swift\nassertSnapshot(of: user, as: .json)\n// {\n//   \"bio\" : \"Blobbed around the world.\",\n//   \"id\" : 1,\n//   \"name\" : \"Blobby\"\n// }\n\nassertSnapshot(of: user, as: .plist)\n// <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n// <!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\"\n//  \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n// <plist version=\"1.0\">\n// <dict>\n//   <key>bio</key>\n//   <string>Blobbed around the world.</string>\n//   <key>id</key>\n//   <integer>1</integer>\n//   <key>name</key>\n//   <string>Blobby</string>\n// </dict>\n// </plist>\n```\n\nIn fact, _any_ value can be snapshot-tested by default using its\n[mirror](https://developer.apple.com/documentation/swift/mirror)!\n\n``` swift\nassertSnapshot(of: user, as: .dump)\n// ‚ñø User\n//   - bio: \"Blobbed around the world.\"\n//   - id: 1\n//   - name: \"Blobby\"\n```\n\nIf your data can be represented as an image, text, or data, you can write a snapshot test for it!\n\n## Documentation\n\nThe latest documentation is available\n[here](https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing/main/documentation/snapshottesting).\n\n## Installation\n\n### Xcode\n\n> **Warning**\n> By default, Xcode will try to add the SnapshotTesting package to your project's main\n> application/framework target. Please ensure that SnapshotTesting is added to a _test_ target\n> instead, as documented in the last step, below.\n\n 1. From the **File** menu, navigate through **Swift Packages** and select\n    **Add Package Dependency‚Ä¶**.\n 2. Enter package repository URL: `https://github.com/pointfreeco/swift-snapshot-testing`.\n 3. Confirm the version and let Xcode resolve the package.\n 4. On the final dialog, update SnapshotTesting's **Add to Target** column to a test target that\n    will contain snapshot tests (if you have more than one test target, you can later add\n    SnapshotTesting to them by manually linking the library in its build phase).\n\n### Swift Package Manager\n\nIf you want to use SnapshotTesting in any other project that uses\n[SwiftPM](https://swift.org/package-manager/), add the package as a dependency in `Package.swift`:\n\n```swift\ndependencies: [\n  .package(\n    url: \"https://github.com/pointfreeco/swift-snapshot-testing\",\n    from: \"1.12.0\"\n  ),\n]\n```\n\nNext, add `SnapshotTesting` as a dependency of your test target:\n\n```swift\ntargets: [\n  .target(name: \"MyApp\"),\n  .testTarget(\n    name: \"MyAppTests\",\n    dependencies: [\n      \"MyApp\",\n      .product(name: \"SnapshotTesting\", package: \"swift-snapshot-testing\"),\n    ]\n  )\n]\n```\n\n## Features\n\n  - [**Dozens of snapshot strategies**][available-strategies]. Snapshot\n    testing isn't just for `UIView`s and `CALayer`s. Write snapshots against _any_ value.\n  - [**Write your own snapshot strategies**][defining-strategies].\n    If you can convert it to an image, string, data, or your own diffable format, you can snapshot\n    test it! Build your own snapshot strategies from scratch or transform existing ones.\n  - **No configuration required.** Don't fuss with scheme settings and environment variables.\n    Snapshots are automatically saved alongside your tests.\n  - **More hands-off.** New snapshots are recorded whether `isRecording` mode is `true` or not.\n  - **Subclass-free.** Assert from any XCTest case or Quick spec.\n  - **Device-agnostic snapshots.** Render views and view controllers for specific devices and trait\n    collections from a single simulator.\n  - **First-class Xcode support.** Image differences are captured as XCTest attachments. Text\n    differences are rendered in inline error messages.\n  - **Supports any platform that supports Swift.** Write snapshot tests for iOS, Linux, macOS, and\n    tvOS.\n  - **SceneKit, SpriteKit, and WebKit support.** Most snapshot testing libraries don't support these\n    view subclasses.\n  - **`Codable` support**. Snapshot encodable data structures into their JSON and property list\n    representations.\n  - **Custom diff tool integration**. Configure failure messages to print diff commands for\n    [Kaleidoscope](https://kaleidoscope.app) or your diff tool of choice.\n    ``` swift\n    SnapshotTesting.diffToolCommand = { \"ksdiff \\($0) \\($1)\" }\n    ```\n\n[available-strategies]: https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing/main/documentation/snapshottesting/snapshotting\n[defining-strategies]: https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing/main/documentation/snapshottesting/customstrategies\n\n## Plug-ins\n\n  - [AccessibilitySnapshot](https://github.com/cashapp/AccessibilitySnapshot) adds easy regression\n    testing for iOS accessibility.\n    \n  - [AccessibilitySnapshotColorBlindness](https://github.com/Sherlouk/AccessibilitySnapshotColorBlindness)\n    adds snapshot strategies for color blindness simulation on iOS views, view controllers and images.\n\n  - [GRDBSnapshotTesting](https://github.com/SebastianOsinski/GRDBSnapshotTesting) adds snapshot\n    strategy for testing SQLite database migrations made with [GRDB](https://github.com/groue/GRDB.swift).\n\n  - [Nimble-SnapshotTesting](https://github.com/tahirmt/Nimble-SnapshotTesting) adds \n    [Nimble](https://github.com/Quick/Nimble) matchers for SnapshotTesting to be used by Swift\n    Package Manager.\n\n  - [Prefire](https://github.com/BarredEwe/Prefire) generating Snapshot Tests via\n    [Swift Package Plugins](https://github.com/apple/swift-package-manager/blob/main/Documentation/Plugins.md)\n    using SwiftUI `Preview`\n  \n  - [PreviewSnapshots](https://github.com/doordash-oss/swiftui-preview-snapshots) share `View`\n    configurations between SwiftUI Previews and snapshot tests and generate several snapshots with a\n    single test assertion.\n\n  - [swift-html](https://github.com/pointfreeco/swift-html) is a Swift DSL for type-safe,\n    extensible, and transformable HTML documents and includes an `HtmlSnapshotTesting` module to\n    snapshot test its HTML documents.\n\n  - [swift-snapshot-testing-nimble](https://github.com/Killectro/swift-snapshot-testing-nimble) adds\n    [Nimble](https://github.com/Quick/Nimble) matchers for SnapshotTesting.\n\n  - [swift-snapshot-testing-stitch](https://github.com/Sherlouk/swift-snapshot-testing-stitch/) adds\n    the ability to stitch multiple UIView's or UIViewController's together in a single test.\n\n  - [SnapshotTestingDump](https://github.com/tahirmt/swift-snapshot-testing-dump) Adds support to\n    use [swift-custom-dump](https://github.com/pointfreeco/swift-custom-dump/) by using `customDump`\n    strategy for `Any`\n\n  - [SnapshotTestingHEIC](https://github.com/alexey1312/SnapshotTestingHEIC) adds image support\n  using the HEIC storage format which reduces file sizes in comparison to PNG.\n\n  - [SnapshotVision](https://github.com/gregersson/swift-snapshot-testing-vision) adds snapshot\n    strategy for text recognition on views and images. Uses Apples Vision framework.\n\nHave you written your own SnapshotTesting plug-in?\n[Add it here](https://github.com/pointfreeco/swift-snapshot-testing/edit/master/README.md) and\nsubmit a pull request!\n\n## Related Tools\n\n  - [`iOSSnapshotTestCase`](https://github.com/uber/ios-snapshot-test-case/) helped introduce screen\n    shot testing to a broad audience in the iOS community. Experience with it inspired the creation\n    of this library.\n\n  - [Jest](https://jestjs.io) brought generalized snapshot testing to the JavaScript community with\n    a polished user experience. Several features of this library (diffing, automatically capturing\n    new snapshots) were directly influenced.\n\n## Learn More\n\nSnapshotTesting was designed with [witness-oriented programming](https://www.pointfree.co/episodes/ep39-witness-oriented-library-design).\n\nThis concept (and more) are explored thoroughly in a series of episodes on\n[Point-Free](https://www.pointfree.co), a video series exploring functional programming and Swift\nhosted by [Brandon Williams](https://twitter.com/mbrandonw) and\n[Stephen Celis](https://twitter.com/stephencelis).\n\nWitness-oriented programming and the design of this library was explored in the following\n[Point-Free](https://www.pointfree.co) episodes:\n\n  - [Episode 33](https://www.pointfree.co/episodes/ep33-protocol-witnesses-part-1): Protocol Witnesses: Part 1\n  - [Episode 34](https://www.pointfree.co/episodes/ep34-protocol-witnesses-part-1): Protocol Witnesses: Part 2\n  - [Episode 35](https://www.pointfree.co/episodes/ep35-advanced-protocol-witnesses-part-1): Advanced Protocol Witnesses: Part 1\n  - [Episode 36](https://www.pointfree.co/episodes/ep36-advanced-protocol-witnesses-part-2): Advanced Protocol Witnesses: Part 2\n  - [Episode 37](https://www.pointfree.co/episodes/ep37-protocol-oriented-library-design-part-1): Protocol-Oriented Library Design: Part 1\n  - [Episode 38](https://www.pointfree.co/episodes/ep38-protocol-oriented-library-design-part-2): Protocol-Oriented Library Design: Part 2\n  - [Episode 39](https://www.pointfree.co/episodes/ep39-witness-oriented-library-design): Witness-Oriented Library Design\n  - [Episode 40](https://www.pointfree.co/episodes/ep40-async-functional-refactoring): Async Functional Refactoring\n  - [Episode 41](https://www.pointfree.co/episodes/ep41-a-tour-of-snapshot-testing): A Tour of Snapshot Testing üÜì\n\n<a href=\"https://www.pointfree.co/episodes/ep41-a-tour-of-snapshot-testing\">\n  <img alt=\"video poster image\" src=\"https://d3rccdn33rt8ze.cloudfront.net/episodes/0041.jpeg\" width=\"480\">\n</a>\n\n## License\n\nThis library is released under the MIT license. See [LICENSE](LICENSE) for details.\n",
      "stars_today": 1
    },
    {
      "id": 35927665,
      "name": "seurat",
      "full_name": "satijalab/seurat",
      "description": "R toolkit for single cell genomics",
      "html_url": "https://github.com/satijalab/seurat",
      "stars": 2611,
      "forks": 977,
      "language": "R",
      "topics": [
        "cran",
        "human-cell-atlas",
        "single-cell-genomics",
        "single-cell-rna-seq"
      ],
      "created_at": "2015-05-20T05:23:02Z",
      "updated_at": "2026-01-13T19:17:45Z",
      "pushed_at": "2026-01-13T22:53:18Z",
      "open_issues": 315,
      "owner": {
        "login": "satijalab",
        "avatar_url": "https://avatars.githubusercontent.com/u/8411851?v=4"
      },
      "readme": "[![CRAN Version](https://www.r-pkg.org/badges/version/Seurat)](https://cran.r-project.org/package=Seurat)\n[![CRAN Downloads](https://cranlogs.r-pkg.org/badges/Seurat)](https://cran.r-project.org/package=Seurat)\n\n\n# Seurat v5\n\nSeurat is an R toolkit for single cell genomics, developed and maintained by the Satija Lab at NYGC.\n\nWe are excited to release Seurat v5! This updates introduces new functionality for spatial, multimodal, and scalable single-cell analysis.\n\nSeurat v5 is backwards-compatible with previous versions, so that users will continue to be able to re-run existing workflows. \n\nInstructions, documentation, and tutorials can be found at:\n\n* https://satijalab.org/seurat\n\nSeurat is also hosted on GitHub, you can view and clone the repository at\n\n* https://github.com/satijalab/seurat\n\nSeurat has been successfully installed on Mac OS X, Linux, and Windows, using the devtools package to install directly from GitHub\n\nImprovements and new features will be added on a regular basis, please post on the [github page](https://github.com/satijalab/seurat) with any questions or if you would like to contribute\n\nFor a version history/changelog, please see the [NEWS file](https://github.com/satijalab/seurat/blob/master/NEWS.md).\n",
      "stars_today": 1
    },
    {
      "id": 39321023,
      "name": "Prebid.js",
      "full_name": "prebid/Prebid.js",
      "description": "Setup and manage header bidding advertising partners without writing code or confusing line items. Prebid.js is open source and free.",
      "html_url": "https://github.com/prebid/Prebid.js",
      "stars": 1526,
      "forks": 2294,
      "language": "JavaScript",
      "topics": [
        "bidder-adapter",
        "header-bidding",
        "prebid"
      ],
      "created_at": "2015-07-19T03:26:23Z",
      "updated_at": "2026-01-13T21:10:49Z",
      "pushed_at": "2026-01-13T21:10:45Z",
      "open_issues": 142,
      "owner": {
        "login": "prebid",
        "avatar_url": "https://avatars.githubusercontent.com/u/13242760?v=4"
      },
      "readme": "[![Percentage of issues still open](http://isitmaintained.com/badge/open/prebid/Prebid.js.svg)](https://isitmaintained.com/project/prebid/Prebid.js \"Percentage of issues still open\")\n[![Coverage Status](https://coveralls.io/repos/github/prebid/Prebid.js/badge.svg?branch=master)](https://coveralls.io/github/prebid/Prebid.js?branch=master)\n\n# Prebid.js\n\n> A free and open source library for publishers to quickly implement header bidding.\n\nThis README is for developers who want to contribute to Prebid.js.\nAdditional documentation can be found at [the Prebid.js documentation homepage](https://docs.prebid.org/prebid/prebidjs.html).\nWorking examples can be found in [the developer docs](https://prebid.org/dev-docs/getting-started.html).\n\nPrebid.js is open source software that is offered for free as a convenience. While it is designed to help companies address legal requirements associated with header bidding, we cannot and do not warrant that your use of Prebid.js will satisfy legal requirements. You are solely responsible for ensuring that your use of Prebid.js complies with all applicable laws.  We strongly encourage you to obtain legal advice when using Prebid.js to ensure your implementation complies with all laws where you operate.\n\n**Table of Contents**\n\n- [Usage](#Usage)\n- [Install](#Install)\n- [Build](#Build)\n- [Run](#Run)\n- [Contribute](#Contribute)\n\n<a name=\"Usage\"></a>\n\n## Usage (as a npm dependency)\n\n**Note**: versions prior to v10 required some Babel plugins to be configured when used as an NPM dependency -\nrefer to [v9 README](https://github.com/prebid/Prebid.js/blob/9.43.0/README.md). See also [customize build options](#customize-options)\n\n```javascript\nimport pbjs from 'prebid.js';\nimport 'prebid.js/modules/rubiconBidAdapter'; // imported modules will register themselves automatically with prebid\nimport 'prebid.js/modules/appnexusBidAdapter';\npbjs.processQueue();  // required to process existing pbjs.queue blocks and setup any further pbjs.queue execution\n\npbjs.requestBids({\n  ...\n})\n```\n\nYou can import just type definitions for every module from `types.d.ts`, and for the `pbjs` global from `global.d.ts`:\n\n```typescript\nimport 'prebid.js/types.d.ts';\nimport 'prebid.js/global.d.ts';\npbjs.que.push(/* ... */)\n```\n\nOr, if your Prebid bundle uses a different global variable name:\n\n```typescript\nimport type {PrebidJS} from 'prebid.js/types.d.ts';\ndeclare global {\n    interface Window {\n        myCustomPrebidGlobal: PrebidJS;\n    }\n}\n```\n\n<a id=\"customize-options\"></a>\n\n### Customize build options\n\nIf you're using Webpack, you can use the `prebid.js/customize/webpackLoader` loader to set the following options:\n\n| Name | Type | Description | Default | \n| ---- | ---- | ----------- | ------- |\n| globalVarName | String | Prebid global variable name | `\"pbjs\"` | \n| defineGlobal | Boolean | If false, do not set a global variable | `true` | \n| distUrlBase |  String | Base URL to use for dynamically loaded modules (e.g. debugging-standalone.js) | `\"https://cdn.jsdelivr.net/npm/prebid.js/dist/chunks/\"` |\n\nFor example, to set a custom global variable name:\n\n```javascript\n// webpack.conf.js\nmodule.exports = {\n  module: {\n    rules: [\n      {\n        loader: 'prebid.js/customize/webpackLoader',\n        options: {\n          globalVarName: 'myCustomGlobal'\n        }\n      },\n    ]\n  }\n}\n```\n\n\n<a name=\"Install\"></a>\n\n## Install\n\n\n\n    $ git clone https://github.com/prebid/Prebid.js.git\n    $ cd Prebid.js\n    $ npm ci\n\n*Note:* You need to have `NodeJS` 12.16.1 or greater installed.\n\n*Note:* In the 1.24.0 release of Prebid.js we have transitioned to using gulp 4.0 from using gulp 3.9.1.  To comply with gulp's recommended setup for 4.0, you'll need to have `gulp-cli` installed globally prior to running the general `npm ci`.  This shouldn't impact any other projects you may work on that use an earlier version of gulp in its setup.\n\nIf you have a previous version of `gulp` installed globally, you'll need to remove it before installing `gulp-cli`.  You can check if this is installed by running `gulp -v` and seeing the version that's listed in the `CLI` field of the output.  If you have the `gulp` package installed globally, it's likely the same version that you'll see in the `Local` field.  If you already have `gulp-cli` installed, it should be a lower major version (it's at version `2.0.1` at the time of the transition).\n\nTo remove the old package, you can use the command: `npm rm gulp -g`\n\nOnce setup, run the following command to globally install the `gulp-cli` package: `npm install gulp-cli -g`\n\n\n<a name=\"Build\"></a>\n\n## Build for Development\n\nTo build the project on your local machine we recommend, running:\n\n    $ gulp serve-and-test --file <spec_file.js>\n\nThis will run testing but not linting. A web server will start at `http://localhost:9999` serving from the project root and generates the following files:\n\n+ `./build/dev/prebid.js` - Full source code for dev and debug\n+ `./build/dev/prebid.js.map` - Source map for dev and debug\n+ `./build/dev/prebid-core.js`\n+ `./build/dev/prebid-core.js.map`\n\n\nDevelopment may be a bit slower but if you prefer linting and additional watch files you can also still run just:\n\n    $ gulp serve\n\n\n### Build Optimization\n\nThe standard build output contains all the available modules from within the `modules` folder.  Note, however that there are bid adapters which support multiple bidders through aliases, so if you don't see a file in modules for a bid adapter, you may need to grep the repository to find the name of the module you need to include.\n\nYou might want to exclude some/most of them from the final bundle.  To make sure the build only includes the modules you want, you can specify the modules to be included with the `--modules` CLI argument.\n\nFor example, when running the serve command: `gulp serve --modules=openxBidAdapter,rubiconBidAdapter,sovrnBidAdapter`\n\nBuilding with just these adapters will result in a smaller bundle which should allow your pages to load faster.\n\n**Build standalone prebid.js**\n\n- Clone the repo, run `npm ci`\n- Then run the build:\n\n        $ gulp build --modules=openxBidAdapter,rubiconBidAdapter,sovrnBidAdapter\n\nAlternatively, a `.json` file can be specified that contains a list of modules you would like to include.\n\n    $ gulp build --modules=modules.json\n\nWith `modules.json` containing the following\n```json modules.json\n[\n  \"openxBidAdapter\",\n  \"rubiconBidAdapter\",\n  \"sovrnBidAdapter\"\n]\n```\n\n**Build prebid.js using npm for bundling**\n\nIn case you'd like to explicitly show that your project uses `prebid.js` and want a reproducible build, consider adding it as an `npm` dependency.\n\n- Add `prebid.js` as a `npm` dependency of your project: `npm install prebid.js`\n- Run the `prebid.js` build under the `node_modules/prebid.js/` folder\n\n        $ gulp build --modules=path/to/your/list-of-modules.json\n\nMost likely your custom `prebid.js` will only change when there's:\n\n- A change in your list of modules\n- A new release of `prebid.js`\n\nHaving said that, you are probably safe to check your custom bundle into your project.  You can also generate it in your build process.\n\n**Build once, bundle multiple times**\n\nIf you need to generate multiple distinct bundles from the same Prebid version, you can reuse a single build with:\n\n```\ngulp build\ngulp bundle --tag one --modules=one.json\ngulp bundle --tag two --modules=two.json\n```\n\nThis generates slightly larger files, but has the advantage of being much faster to run (after the initial `gulp build`). It's also the method used by [the Prebid.org download page](https://docs.prebid.org/download.html).\n\n<a name=\"Run\"></a>\n\n### Excluding particular features from the build\n\nSince version 7.2.0, you may instruct the build to exclude code for some features - for example, if you don't need support for native ads:\n\n```\ngulp build --disable NATIVE --modules=openxBidAdapter,rubiconBidAdapter,sovrnBidAdapter # substitute your module list\n```\n\nFeatures that can be disabled this way are:\n\n - `VIDEO` - support for video bids;\n - `NATIVE` - support for native bids;\n- `UID2_CSTG` - support for UID2 client side token generation (see [Unified ID 2.0](https://docs.prebid.org/dev-docs/modules/userid-submodules/unified2.html))\n- `GREEDY` - disables the use blocking, \"greedy\" promises within Prebid (see [note](#greedy-promise)).\n- `LOG_NON_ERROR` - support for non-error console messages. (see [note](#log-features))\n- `LOG_ERROR` - support for error console messages (see [note](#log-features))\n\n`GREEDY` is disabled and all other features are enabled when no features are explicitly chosen. Use `--enable GREEDY` on the `gulp build` command or remove it from `disableFeatures` to restore the original behavior. If you disable any feature, you must explicitly also disable `GREEDY` to get the default behavior on promises.\n\n<a id=\"greedy-promise\"></a>\n\n#### Greedy promises\n\nWhen `GREEDY` is enabled, Prebid attempts to hold control of the main thread when possible, using a [custom implementation of `Promise`](https://github.com/prebid/Prebid.js/blob/master/libraries/greedy/greedyPromise.js) that does not submit callbacks to the scheduler once the promise is resolved (running them immediately instead).\nDisabling this behavior instructs Prebid to use the standard `window.Promise` instead; this has the effect of breaking up task execution, making them slower overall but giving the browser more chances to run other tasks in between, which can improve UX.         \n\nYou may also override the `Promise` constructor used by Prebid through `pbjs.Promise`, for example:\n\n```javascript\nvar pbjs = pbjs || {};\npbjs.Promise = myCustomPromiseConstructor;\n```\n\n<a id=\"log-features\"></a>\n\n#### Logging\n\nDisabling `LOG_NON_ERROR` and `LOG_ERROR` removes most logging statements from source, which can save on bundle size. Beware, however, that there is no test coverage with either of these disabled. Turn them off at your own risk.\n\nDisabling logging ‚Äî especially `LOG_ERROR` ‚Äî also makes debugging more difficult. Consider building a separate version with logging enabled for debugging purposes.\n\nWe suggest running the build with logging off only if you are able to confirm a real world metric improvement via a testing framework. Using this build without such a framework may result in unexpectedly worse performance.\n\n## Unminified code\n\nYou can get a version of the code that's unminified for debugging with `build-bundle-dev`:\n\n```bash\ngulp build-bundle-dev --modules=bidderA,module1,...\n```\n\nThe results will be in build/dev/prebid.js.\n\n## ES5 Output Support\n\nFor compatibility with older parsers or environments that require ES5 syntax, you can generate ES5-compatible output using the `--ES5` flag:\n\n```bash\ngulp build-bundle-dev --modules=bidderA,module1,... --ES5\n```\n\nThis will:\n- Transpile all code to ES5 syntax using CommonJS modules\n- Target browsers: IE11+, Chrome 50+, Firefox 50+, Safari 10+\n- Ensure compatibility with older JavaScript parsers\n\n**Note:** Without the `--ES5` flag, the build will use modern ES6+ syntax by default for better performance and smaller bundle sizes.\n\n## Test locally\n\nTo lint the code:\n\n```bash\ngulp lint\n```\n\nTo lint and only show errors\n\n```bash\ngulp lint --no-lint-warnings\n```\n\nTo run the unit tests:\n\n```bash\ngulp test\n```\n\nTo run the unit tests for a particular file (example for pubmaticBidAdapter_spec.js):\n```bash\ngulp test --file \"test/spec/modules/pubmaticBidAdapter_spec.js\" --nolint\n```\n\nTo generate and view the code coverage reports:\n\n```bash\ngulp test-coverage\ngulp view-coverage\n```\n\nLocal end-to-end testing can be done with:\n\n```bash\ngulp e2e-test --local\n```\n\nFor Prebid.org members with access to BrowserStack, additional end-to-end testing can be done with:\n\n```bash\ngulp e2e-test --host=test.localhost\n```\n\nTo run these tests, the following items are required:\n- setup an alias of localhost in your `hosts` file (eg `127.0.0.1  test.localhost`); note - you can use any alias.  Use this alias in the command-line argument above.\n- access to [BrowserStack](https://www.browserstack.com/) account.  Assign the following variables in your bash_profile:\n```bash\nexport BROWSERSTACK_USERNAME='YourUserNameHere'\nexport BROWSERSTACK_ACCESS_KEY='YourAccessKeyHere'\n```\nYou can get these BrowserStack values from your profile page.\n\nFor development:\n\n```javascript\n(function() {\n    var d = document, pbs = d.createElement('script'), pro = d.location.protocol;\n    pbs.type = 'text/javascript';\n    pbs.src = ((pro === 'https:') ? 'https' : 'http') + './build/dev/prebid.js';\n    var target = document.getElementsByTagName('head')[0];\n    target.insertBefore(pbs, target.firstChild);\n})();\n```\n\nFor deployment:\n\n```javascript\n(function() {\n    var d = document, pbs = d.createElement('script'), pro = d.location.protocol;\n    pbs.type = 'text/javascript';\n    pbs.src = ((pro === 'https:') ? 'https' : 'http') + './build/dist/prebid.js';\n    var target = document.getElementsByTagName('head')[0];\n    target.insertBefore(pbs, target.firstChild);\n})();\n```\n\nBuild and run the project locally with:\n\n```bash\ngulp serve\n```\n\nThis runs `lint` and `test`, then starts a web server at `http://localhost:9999` serving from the project root.\nNavigate to your example implementation to test, and if your `prebid.js` file is sourced from the `./build/dev`\ndirectory you will have sourcemaps available in your browser's developer tools.\n\nTo run the example file, go to:\n\n+ `http://localhost:9999/integrationExamples/gpt/hello_world.html`\n\nAs you make code changes, the bundles will be rebuilt and the page reloaded automatically.\n\n<a name=\"Contribute\"></a>\n\n## Contribute\n\nMany SSPs, bidders, and publishers have contributed to this project. [Hundreds of bidders](https://github.com/prebid/Prebid.js/tree/master/modules) are supported by Prebid.js.\n\nFor guidelines, see [Contributing](./CONTRIBUTING.md).\n\nOur PR review process can be found [here](https://github.com/prebid/Prebid.js/tree/master/PR_REVIEW.md).\n\n### Add a Bidder Adapter\n\nTo add a bidder adapter module, see the instructions in [How to add a bidder adapter](https://docs.prebid.org/dev-docs/bidder-adaptor.html).\n\n### Code Quality\n\nCode quality is defined by `.eslintrc` and errors are reported in the terminal.\n\nIf you are contributing code, you should [configure your editor](http://eslint.org/docs/user-guide/integrations#editors) with the provided `.eslintrc` settings.\n\n### Unit Testing with Karma\n\n        $ gulp test --watch --browsers=chrome\n\nThis will run tests and keep the Karma test browser open. If your `prebid.js` file is sourced from the `./build/dev` directory you will also have sourcemaps available when using your browser's developer tools.\n\n+ To access the Karma debug page, go to `http://localhost:9876/debug.html`\n\n+ For test results, see the console\n\n+ To set breakpoints in source code, see the developer tools\n\nDetailed code coverage reporting can be generated explicitly with\n\n        $ gulp test --coverage\n\nThe results will be in\n\n        ./build/coverage\n\n*Note*: Starting in June 2016, all pull requests to Prebid.js need to include tests with greater than 80% code coverage before they can be merged.  For more information, see [#421](https://github.com/prebid/Prebid.js/issues/421).\n\nFor instructions on writing tests for Prebid.js, see [Testing Prebid.js](https://prebid.org/dev-docs/testing-prebid.html).\n\n### Supported Browsers\n\nPrebid.js is supported on IE11 and modern browsers until 5.x. 6.x+ transpiles to target >0.25%; not dead; not Opera Mini; not IE11.\n\n### Governance\nReview our governance model [here](https://github.com/prebid/Prebid.js/tree/master/governance.md).\n### END\n",
      "stars_today": 1
    },
    {
      "id": 459870310,
      "name": "kueue",
      "full_name": "kubernetes-sigs/kueue",
      "description": "Kubernetes-native Job Queueing",
      "html_url": "https://github.com/kubernetes-sigs/kueue",
      "stars": 2253,
      "forks": 505,
      "language": "Go",
      "topics": [
        "k8s",
        "k8s-sig-scheduling",
        "kubernetes"
      ],
      "created_at": "2022-02-16T05:52:19Z",
      "updated_at": "2026-01-13T20:54:54Z",
      "pushed_at": "2026-01-13T21:45:36Z",
      "open_issues": 354,
      "owner": {
        "login": "kubernetes-sigs",
        "avatar_url": "https://avatars.githubusercontent.com/u/36015203?v=4"
      },
      "readme": "# Kueue\n\n[![GoReport Widget]][GoReport Status]\n[![Latest Release](https://img.shields.io/github/v/release/kubernetes-sigs/kueue?include_prereleases)](https://github.com/kubernetes-sigs/kueue/releases/latest)\n\n[GoReport Widget]: https://goreportcard.com/badge/sigs.k8s.io/kueue\n[GoReport Status]: https://goreportcard.com/report/sigs.k8s.io/kueue\n\n<img src=\"https://github.com/kubernetes-sigs/kueue/blob/main/site/static/images/logo.svg\" width=\"100\" alt=\"kueue logo\">\n\nKueue is a set of APIs and controller for [job](https://kueue.sigs.k8s.io/docs/concepts/workload)\n[queueing](https://kueue.sigs.k8s.io/docs/concepts#queueing). It is a job-level manager that decides when\na job should be [admitted](https://kueue.sigs.k8s.io/docs/concepts#admission) to start (as in pods can be\ncreated) and when it should stop (as in active pods should be deleted).\n\nRead the [overview](https://kueue.sigs.k8s.io/docs/overview/) and watch the Kueue-related [talks & presentations](https://kueue.sigs.k8s.io/docs/talks_and_presentations/) to learn more.\n\n## Features overview\n\n- **Job management:** Support job queueing based on [priorities](https://kueue.sigs.k8s.io/docs/concepts/workload/#priority) with different [strategies](https://kueue.sigs.k8s.io/docs/concepts/cluster_queue/#queueing-strategy): `StrictFIFO` and `BestEffortFIFO`.\n- **Advanced Resource management:** Comprising: [resource flavor fungibility](https://kueue.sigs.k8s.io/docs/concepts/cluster_queue/#flavorfungibility), [Fair Sharing](https://kueue.sigs.k8s.io/docs/concepts/preemption/#fair-sharing), [cohorts](https://kueue.sigs.k8s.io/docs/concepts/cluster_queue/#cohort) and [preemption](https://kueue.sigs.k8s.io/docs/concepts/cluster_queue/#preemption) with a variety of policies between different tenants.\n- **Integrations:** Built-in support for popular jobs, e.g. [BatchJob](https://kueue.sigs.k8s.io/docs/tasks/run/jobs/), [Kubeflow training jobs](https://kueue.sigs.k8s.io/docs/tasks/run/kubeflow/), [RayJob](https://kueue.sigs.k8s.io/docs/tasks/run/rayjobs/), [RayCluster](https://kueue.sigs.k8s.io/docs/tasks/run/rayclusters/), [JobSet](https://kueue.sigs.k8s.io/docs/tasks/run/jobsets/),  [plain Pod and Pod Groups](https://kueue.sigs.k8s.io/docs/tasks/run/plain_pods/).\n- **System insight:** Build-in [prometheus metrics](https://kueue.sigs.k8s.io/docs/reference/metrics/) to help monitor the state of the system, and on-demand visibility endpoint for [monitoring of pending workloads](https://kueue.sigs.k8s.io/docs/tasks/manage/monitor_pending_workloads/pending_workloads_on_demand/).\n- **AdmissionChecks:** A mechanism for internal or external components to influence whether a workload can be [admitted](https://kueue.sigs.k8s.io/docs/concepts/admission_check/).\n- **Advanced autoscaling support:** Integration with cluster-autoscaler's [provisioningRequest](https://kueue.sigs.k8s.io/docs/concepts/admission_check/provisioning_request/#job-using-a-provisioningrequest) via admissionChecks.\n- **All-or-nothing with ready Pods:** A timeout-based implementation of [All-or-nothing scheduling](https://kueue.sigs.k8s.io/docs/tasks/manage/setup_wait_for_pods_ready/).\n- **Partial admission and dynamic reclaim:** mechanisms to run a job with [reduced parallelism](https://kueue.sigs.k8s.io/docs/tasks/run/jobs/#partial-admission), based on available quota, and to [release](https://kueue.sigs.k8s.io/docs/concepts/workload/#dynamic-reclaim) the quota the pods complete..\n- **Mixing training and inference**: Simultaneous management of batch workloads along with serving workloads (such as [Deployments](https://kueue.sigs.k8s.io/docs/tasks/run/deployment/) or [StatefulSets](https://kueue.sigs.k8s.io/docs/tasks/run/statefulset/))\n- **Multi-cluster job dispatching:** called [MultiKueue](https://kueue.sigs.k8s.io/docs/concepts/multikueue/), allows to search for capacity and off-load the main cluster.\n- **Topology-Aware Scheduling**: Allows to optimize the Pod-to-Pod communication throughput by [scheduling aware of the data-center topology](https://kueue.sigs.k8s.io/docs/concepts/topology_aware_scheduling/).\n\n## Production Readiness status\n\n- ‚úîÔ∏è API version: v1beta2, respecting [Kubernetes Deprecation Policy](https://kubernetes.io/docs/reference/using-api/deprecation-policy/)\n- ‚úîÔ∏è Up-to-date [documentation](https://kueue.sigs.k8s.io/docs).\n- ‚úîÔ∏è Test Coverage:\n  - ‚úîÔ∏è Unit Test [testgrid](https://testgrid.k8s.io/sig-scheduling#periodic-kueue-test-unit-main).\n  - ‚úîÔ∏è Integration Test [testgrid](https://testgrid.k8s.io/sig-scheduling#periodic-kueue-test-integration-main)\n  - ‚úîÔ∏è Integration MultiKueue Tests [testgrid](https://testgrid.k8s.io/sig-scheduling#periodic-kueue-test-integration-multikueue-main)\n  - ‚úîÔ∏è E2E Tests for Kubernetes\n    [1.32](https://testgrid.k8s.io/sig-scheduling#periodic-kueue-test-e2e-main-1-32),\n    [1.33](https://testgrid.k8s.io/sig-scheduling#periodic-kueue-test-e2e-main-1-33),\n    [1.34](https://testgrid.k8s.io/sig-scheduling#periodic-kueue-test-e2e-main-1-34),\n    [1.35](https://testgrid.k8s.io/sig-scheduling#periodic-kueue-test-e2e-main-1-35),\n    on Kind.\n  - ‚úîÔ∏è E2E TAS Test [testgrid](https://testgrid.k8s.io/sig-scheduling#periodic-kueue-test-e2e-tas-main)\n  - ‚úîÔ∏è E2E Custom Configs Test [testgrid](https://testgrid.k8s.io/sig-scheduling#periodic-kueue-test-e2e-customconfigs-main)\n  - ‚úîÔ∏è E2E Cert Manager Test [testgrid](https://testgrid.k8s.io/sig-scheduling#periodic-kueue-test-e2e-certmanager-main)\n  - ‚úîÔ∏è Performance Test [testgrid](https://testgrid.k8s.io/sig-scheduling#periodic-kueue-test-scheduling-perf-main)\n- ‚úîÔ∏è Scalability verification via [performance tests](https://github.com/kubernetes-sigs/kueue/tree/main/test/performance).\n- ‚úîÔ∏è Monitoring via [metrics](https://kueue.sigs.k8s.io/docs/reference/metrics).\n- ‚úîÔ∏è Security: RBAC based accessibility.\n- ‚úîÔ∏è Stable [release](RELEASE.md) cycle (2-3 months).\n- ‚úîÔ∏è [Adopters](https://kueue.sigs.k8s.io/docs/adopters/) running on production.\n\n  _Based on community feedback, we continue to simplify and evolve the API to\n  address new use cases_.\n\n## Installation\n\n**Requires Kubernetes 1.29 or newer**.\n\nTo install the latest release of Kueue in your cluster, run the following command:\n\n```shell\nkubectl apply --server-side -f https://github.com/kubernetes-sigs/kueue/releases/download/v0.15.2/manifests.yaml\n```\n\nThe controller runs in the `kueue-system` namespace.\n\nRead the [installation guide](https://kueue.sigs.k8s.io/docs/installation/) to learn more.\n\n## Usage\n\nA minimal configuration can be set by running the [examples](site/static/examples):\n\n```shell\nkubectl apply -f examples/admin/single-clusterqueue-setup.yaml\n```\n\nThen you can run a job with:\n\n```shell\nkubectl create -f examples/jobs/sample-job.yaml\n```\n\nLearn more about:\n\n- Kueue [concepts](https://kueue.sigs.k8s.io/docs/concepts).\n- Common and advanced [tasks](https://kueue.sigs.k8s.io/docs/tasks).\n\n## Roadmap\n\nHigh-level overview of the main priorities for 2025:\n- Improve user experience for [MultiKueue](https://kueue.sigs.k8s.io/docs/concepts/multikueue/) - multi-cluster Job dispatching, in particular:\n  * sequential attempts to try worker clusters [#3757](https://github.com/kubernetes-sigs/kueue/issues/3757)\n  * log retrieval from worker clusters [3526](https://github.com/kubernetes-sigs/kueue/issues/3526)\n- Improve user experience for [Topology Aware Scheduling](https://kueue.sigs.k8s.io/docs/concepts/topology_aware_scheduling/), in particular:\n  * make Topology Aware Scheduling compatible with cohorts and preemption [#3761](https://github.com/kubernetes-sigs/kueue/issues/3761)\n  * optimize the algorithm to minimize fragmentation [#3756](https://github.com/kubernetes-sigs/kueue/issues/3756)\n  * better accuracy of scheduling by tighter integration with kube-scheduler [#3755](https://github.com/kubernetes-sigs/kueue/issues/3755)\n  * reduce friction by defaulting the PodSet annotations [#3754](https://github.com/kubernetes-sigs/kueue/issues/3754)\n- Productization of the Kueue dashboard [#940](https://github.com/kubernetes-sigs/kueue/issues/940)\n- Support Hierarchical Cohorts with FairSharing [#3759](https://github.com/kubernetes-sigs/kueue/issues/3759)\n- Improved support for AI inference, including:\n  * partial preemption of serving workloads [#3762](https://github.com/kubernetes-sigs/kueue/issues/3762)\n  * LeaderWorkerSet support [#3232](https://github.com/kubernetes-sigs/kueue/issues/3232)\n- Progress towards the stable API (v1beta2) [#768](https://github.com/kubernetes-sigs/kueue/issues/768)\n\nLong-term aspirational goals:\n- Integration with workflow frameworks [#74](https://github.com/kubernetes-sigs/kueue/issues/74)\n- Support dynamically-sized Jobs [#77](https://github.com/kubernetes-sigs/kueue/issues/77)\n- Budget support [#28](https://github.com/kubernetes-sigs/kueue/issues/28)\n- Flavor assignment strategies, e.g. _minimizing cost_ vs _minimizing borrowing_ [#312](https://github.com/kubernetes-sigs/kueue/issues/312)\n- Cooperative preemption support for workloads that implement checkpointing [#477](https://github.com/kubernetes-sigs/kueue/issues/477)\n- Delayed preemption for two-stage admission [#3758](https://github.com/kubernetes-sigs/kueue/issues/3758)\n- Support Structured Parameters (DRA) in Kueue [#2941](https://github.com/kubernetes-sigs/kueue/issues/2941)\n- Graduate the API to v1 [#3476](https://github.com/kubernetes-sigs/kueue/issues/3476)\n\n## Community, discussion, contribution, and support\n\nLearn how to engage with the Kubernetes community on the [community page](http://kubernetes.io/community/)\nand the [contributor's guide](CONTRIBUTING.md).\n\nYou can reach the maintainers of this project at:\n\n- [Slack](https://kubernetes.slack.com/messages/wg-batch)\n- [Mailing List](https://groups.google.com/a/kubernetes.io/g/wg-batch)\n\n### Graphic assets\n\n- [Kueue](https://github.com/cncf/artwork/tree/main/projects/kubernetes/sub-projects/kueue)\n- [KueueViz](https://github.com/cncf/artwork/tree/main/projects/kubernetes/sub-projects/kueueviz)\n\n### Code of conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes Code of Conduct](code-of-conduct.md).\n",
      "stars_today": 1
    },
    {
      "id": 53432472,
      "name": "sonic-buildimage",
      "full_name": "sonic-net/sonic-buildimage",
      "description": "Scripts which perform an installable binary image build for SONiC",
      "html_url": "https://github.com/sonic-net/sonic-buildimage",
      "stars": 907,
      "forks": 1693,
      "language": "C",
      "topics": [
        "hacktoberfest",
        "sonic"
      ],
      "created_at": "2016-03-08T17:42:37Z",
      "updated_at": "2026-01-13T19:12:12Z",
      "pushed_at": "2026-01-13T22:29:41Z",
      "open_issues": 2539,
      "owner": {
        "login": "sonic-net",
        "avatar_url": "https://avatars.githubusercontent.com/u/102750714?v=4"
      },
      "readme": "*master builds*:\n\n[![Broadcom](https://dev.azure.com/mssonic/build/_apis/build/status/broadcom/Azure.sonic-buildimage.official.broadcom?branchName=master&label=Broadcom)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=138&branchName=master)\n[![Mellanox](https://dev.azure.com/mssonic/build/_apis/build/status/mellanox/Azure.sonic-buildimage.official.mellanox?branchName=master&label=Mellanox)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=139&branchName=master)\n[![Marvell-Teralynx](https://dev.azure.com/mssonic/build/_apis/build/status/innovium/Azure.sonic-buildimage.official.marvell-teralynx?branchName=master&label=Marvell-Teralynx)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=2432&branchName=master)\n[![Marvell-Prestera(armhf)](https://dev.azure.com/mssonic/build/_apis/build/status/marvell/Azure.sonic-buildimage.official.marvell-prestera-armhf?branchName=master&label=Marvell-Prestera-armhf)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=141&branchName=master)\n[![Marvell-Prestera(arm64)](https://dev.azure.com/mssonic/build/_apis/build/status/marvell/Azure.sonic-buildimage.official.marvell-prestera-arm64?branchName=master&label=Marvell-Prestera-arm64)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=999&branchName=master)\n[![Nvidia-Bluefield](https://dev.azure.com/mssonic/build/_apis/build/status/nvidia/Azure.sonic-buildimage.official.nvidia-bluefield?branchName=master&label=Nvidia-Bluefield)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=1665&branchName=master)\n[![VS](https://dev.azure.com/mssonic/build/_apis/build/status/vs/Azure.sonic-buildimage.official.vs?branchName=master&label=VS)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=142&branchName=master)\n\n*202511 builds*:\n\n[![Broadcom](https://dev.azure.com/mssonic/build/_apis/build/status/broadcom/Azure.sonic-buildimage.official.broadcom?branchName=202511&label=Broadcom)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=138&branchName=202511)\n[![Mellanox](https://dev.azure.com/mssonic/build/_apis/build/status/mellanox/Azure.sonic-buildimage.official.mellanox?branchName=202511&label=Mellanox)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=139&branchName=202511)\n[![Marvell-Teralynx](https://dev.azure.com/mssonic/build/_apis/build/status/innovium/Azure.sonic-buildimage.official.marvell-teralynx?branchName=202511&label=Marvell-Teralynx)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=2432&branchName=202511)\n[![Marvell-Prestera(armhf)](https://dev.azure.com/mssonic/build/_apis/build/status/marvell/Azure.sonic-buildimage.official.marvell-prestera-armhf?branchName=202511&label=Marvell-Prestera-armhf)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=141&branchName=202511)\n[![Marvell-Prestera(arm64)](https://dev.azure.com/mssonic/build/_apis/build/status/marvell/Azure.sonic-buildimage.official.marvell-prestera-arm64?branchName=202511&label=Marvell-Prestera-arm64)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=999&branchName=202511)\n[![Nvidia-Bluefield](https://dev.azure.com/mssonic/build/_apis/build/status/nvidia/Azure.sonic-buildimage.official.nvidia-bluefield?branchName=202511&label=Nvidia-Bluefield)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=1665&branchName=202511)\n[![VS](https://dev.azure.com/mssonic/build/_apis/build/status/vs/Azure.sonic-buildimage.official.vs?branchName=202511&label=VS)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=142&branchName=202511)\n\n*202505 builds*:\n\n[![Broadcom](https://dev.azure.com/mssonic/build/_apis/build/status/broadcom/Azure.sonic-buildimage.official.broadcom?branchName=202505&label=Broadcom)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=138&branchName=202505)\n[![Mellanox](https://dev.azure.com/mssonic/build/_apis/build/status/mellanox/Azure.sonic-buildimage.official.mellanox?branchName=202505&label=Mellanox)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=139&branchName=202505)\n[![Marvell(armhf)](https://dev.azure.com/mssonic/build/_apis/build/status/marvell/Azure.sonic-buildimage.official.marvell-armhf?branchName=202505&label=Marvell-armhf)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=141&branchName=202505)\n[![Marvell(arm64)](https://dev.azure.com/mssonic/build/_apis/build/status/marvell/Azure.sonic-buildimage.official.marvell-arm64?branchName=202505&label=Marvell-arm64)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=999&branchName=202505)\n[![Nvidia-Bluefield](https://dev.azure.com/mssonic/build/_apis/build/status/nvidia/Azure.sonic-buildimage.official.nvidia-bluefield?branchName=202505&label=Nvidia-Bluefield)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=1665&branchName=202505)\n[![VS](https://dev.azure.com/mssonic/build/_apis/build/status/vs/Azure.sonic-buildimage.official.vs?branchName=202505&label=VS)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=142&branchName=202505)\n\n*202411 builds*:\n\n[![Broadcom](https://dev.azure.com/mssonic/build/_apis/build/status/broadcom/Azure.sonic-buildimage.official.broadcom?branchName=202411&label=Broadcom)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=138&branchName=202411)\n[![Centec](https://dev.azure.com/mssonic/build/_apis/build/status/centec/Azure.sonic-buildimage.official.centec?branchName=202411&label=Centec)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=143&branchName=202411)\n[![Centec(arm64)](https://dev.azure.com/mssonic/build/_apis/build/status/centec/Azure.sonic-buildimage.official.centec-arm64?branchName=202411&label=Centec-arm64)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=140&branchName=202411)\n[![Mellanox](https://dev.azure.com/mssonic/build/_apis/build/status/mellanox/Azure.sonic-buildimage.official.mellanox?branchName=202411&label=Mellanox)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=139&branchName=202411)\n[![Marvell(armhf)](https://dev.azure.com/mssonic/build/_apis/build/status/marvell/Azure.sonic-buildimage.official.marvell-armhf?branchName=202411&label=Marvell-armhf)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=141&branchName=202411)\n[![Marvell(arm64)](https://dev.azure.com/mssonic/build/_apis/build/status/marvell/Azure.sonic-buildimage.official.marvell-arm64?branchName=202411&label=Marvell-arm64)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=999&branchName=202411)\n[![Nvidia-Bluefield](https://dev.azure.com/mssonic/build/_apis/build/status/nvidia/Azure.sonic-buildimage.official.nvidia-bluefield?branchName=202411&label=Nvidia-Bluefield)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=1665&branchName=202411)\n[![VS](https://dev.azure.com/mssonic/build/_apis/build/status/vs/Azure.sonic-buildimage.official.vs?branchName=202411&label=VS)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=142&branchName=202411)\n\n*202405 builds*:\n\n[![Broadcom](https://dev.azure.com/mssonic/build/_apis/build/status/broadcom/Azure.sonic-buildimage.official.broadcom?branchName=202405&label=Broadcom)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=138&branchName=202405)\n[![Centec](https://dev.azure.com/mssonic/build/_apis/build/status/centec/Azure.sonic-buildimage.official.centec?branchName=202405&label=Centec)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=143&branchName=202405)\n[![Centec(arm64)](https://dev.azure.com/mssonic/build/_apis/build/status/centec/Azure.sonic-buildimage.official.centec-arm64?branchName=202405&label=Centec-arm64)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=140&branchName=202405)\n[![Mellanox](https://dev.azure.com/mssonic/build/_apis/build/status/mellanox/Azure.sonic-buildimage.official.mellanox?branchName=202405&label=Mellanox)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=139&branchName=202405)\n[![Marvell(armhf)](https://dev.azure.com/mssonic/build/_apis/build/status/marvell/Azure.sonic-buildimage.official.marvell-armhf?branchName=202405&label=Marvell-armhf)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=141&branchName=202405)\n[![Marvell(arm64)](https://dev.azure.com/mssonic/build/_apis/build/status/marvell/Azure.sonic-buildimage.official.marvell-arm64?branchName=202405&label=Marvell-arm64)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=999&branchName=202405)\n[![Nvidia-Bluefield](https://dev.azure.com/mssonic/build/_apis/build/status/nvidia/Azure.sonic-buildimage.official.nvidia-bluefield?branchName=202405&label=Nvidia-Bluefield)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=1665&branchName=202405)\n[![VS](https://dev.azure.com/mssonic/build/_apis/build/status/vs/Azure.sonic-buildimage.official.vs?branchName=202405&label=VS)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=142&branchName=202405)\n\n## SONiC Image Azure Pipelines\n\nAll SONiC project build pipelines can be found at [Download Portal for SONiC Images](https://sonic-build.azurewebsites.net/pipelines)\n\n# sonic-buildimage\n\n## Build SONiC Switch Images\n\n# Description\n\nFollowing are the instructions on how to build an [(ONIE)](https://github.com/opencomputeproject/onie)\ncompatible network operating system (NOS) installer image for network switches,\nand also how to build docker images running inside the NOS.\nNote that SONiC images are build per ASIC platform.\nSwitches using the same ASIC platform share a common image.\nFor a list of supported switches and ASIC, please refer to this [list](https://github.com/sonic-net/SONiC/wiki/Supported-Devices-and-Platforms)\n\n# Hardware\n\nAny server can be a build image server as long as it has:\n\n* Multiple cores to increase build speed\n* Plenty of RAM (less than 8 GiB is likely to cause issues)\n* 300G of free disk space\n* KVM Virtualization Support.\n\n> Note: If you are in a VM, make sure you have support for nested virtualization.\n> Some cases (e.g. building OVS image) also requires extra configuration\n> options to expose the full KVM interface to the VM\n> (e.g. [the KVM paravirtualization support on VirtualBox](https://www.virtualbox.org/manual/ch10.html#gimproviders)).\n\nA good choice of OS for building SONiC is currently Ubuntu 22.04.\n\n## Automated prerequisites installation and repository cloning\n\nFor convenience, you can use the automated prerequisites script to handle both prerequisites installation and repository cloning:\n\n```shell\ncurl -sSL https://raw.githubusercontent.com/sonic-net/sonic-buildimage/master/scripts/prerequisites.sh | bash\n```\n\nThis script will automatically:\n* Install required packages (pip, jinja, Docker)\n* Configure Docker for non-root usage\n* Clone the repository with all submodules\n\nAfter completing this step, proceed to the [Usage](#usage) section below.\n\n## Manual prerequisites installation\n\n* Install pip and jinja in host build machine, execute below commands\n   if j2/jinjanator is not available:\n\n```shell\nsudo apt install -y python3-pip\npip3 install --user jinjanator\n```\n\n> **Note:** If you cannot run the `j2` command after installation, this is likely because the `~/.local/bin` directory was just created and is not yet included in your `$PATH`. Please log out and log back in to refresh your environment, then test the command again.\n\n\n* Install [Docker](https://docs.docker.com/engine/install/) and configure your\n  system to allow running the 'docker' command without 'sudo':\n  * Add current user to the docker group: `sudo gpasswd -a ${USER} docker`\n  * Log out and log back in so that your group membership is re-evaluated\n  * If you are using Linux kernel 5.3 or newer, then you must use Docker 20.10.10 or newer. This is because older Docker versions did not allow the `clone3` syscall, which is now used in Bookworm.\n\n> Note: If a previous installation of Docker using snap was present on the\n> system, remove it and also remove docker from snap before reinstallating docker.\n> This will avoid [known bugs that falsely report read-only filesystems issues](https://stackoverflow.com/questions/52526219/docker-mkdir-read-only-file-system)\n> during the build process.\n\n## Manual clone the repository with all the git submodules\n\nTo clone the code repository recursively:\n\n```shell\ngit clone --recurse-submodules https://github.com/sonic-net/sonic-buildimage.git\n```\n\n## Usage\n\nTo build SONiC installer image and docker images, run the following commands:\n\n```shell\n# Ensure the 'overlay' module is loaded on your development system\nsudo modprobe overlay\n\n# Enter the source directory\ncd sonic-buildimage\n\n# (Optional) Checkout a specific branch. By default, it uses master branch.\n# For example, to checkout the branch 201911, use \"git checkout 201911\"\ngit checkout [branch_name]\n\n# Execute make init once after cloning the repo,\n# or after fetching remote repo with submodule updates\nmake init\n\n# Execute make configure once to configure ASIC\nmake configure PLATFORM=[ASIC_VENDOR]\n\n# Build SONiC image with 4 jobs in parallel.\n# Note: You can set this higher, but 4 is a good number for most cases\n#       and is well-tested.\nmake SONIC_BUILD_JOBS=4 all\n```\n\nThe supported ASIC vendors are:\n\n* PLATFORM=barefoot\n* PLATFORM=broadcom\n* PLATFORM=marvell-prestera\n* PLATFORM=marvell-teralynx\n* PLATFORM=mellanox\n* PLATFORM=centec\n* PLATFORM=nephos\n* PLATFORM=nvidia-bluefield\n* PLATFORM=vs\n\n## Usage for ARM Architecture\n\n```shell\nsudo apt-get install --allow-downgrades -y docker-ce=5:18.09.0~3-0~ubuntu-xenial\nsudo apt-get install --allow-downgrades -y docker-ce-cli=5:18.09.0~3-0~ubuntu-xenial\n```\n\nTo build Arm32 bit for (ARMHF) platform\n\n```shell\n# Execute make configure once to configure ASIC and ARCH\nmake configure PLATFORM=[ASIC_VENDOR] PLATFORM_ARCH=armhf\nmake target/sonic-[ASIC_VENDER]-armhf.bin\n```\n\n_example:_\n\n```shell\nmake configure PLATFORM=marvell-prestera PLATFORM_ARCH=armhf\nmake target/sonic-marvell-prestera-armhf.bin\n```\n\nTo build Arm32 bit for (ARMHF) Marvell Prestera platform on amd64 host for debian buster\nusing cross-compilation, run the following commands:\n\n```shell\n# Execute make configure once to configure ASIC and ARCH for cross-compilation build\n\nNOJESSIE=1 NOSTRETCH=1 BLDENV=buster CROSS_BLDENV=1 \\\nmake configure PLATFORM=marvell-prestera PLATFORM_ARCH=armhf\n\n# Execute Arm32 build using cross-compilation environment\n\nNOJESSIE=1 NOSTRETCH=1 BLDENV=buster CROSS_BLDENV=1 make target/sonic-marvell-prestera-armhf.bin\n```\n\nRunning the above Arm32 build using cross-compilation instead of qemu emulator\ndrastically reduces the build time.\n\nTo build Arm64 bit for platform\n\n```shell\n# Execute make configure once to configure ASIC and ARCH\n\nmake configure PLATFORM=[ASIC_VENDOR] PLATFORM_ARCH=arm64\n\n# example:\n\nmake configure PLATFORM=marvell-prestera PLATFORM_ARCH=arm64\n```\n\n **NOTE**:\n\n* Recommend reserving at least 100G free space to build one platform\n  with a single job.\n  The build process will use more disk if you are setting `SONIC_BUILD_JOBS`\n  to more than 1.\n* If Docker's workspace folder, `/var/lib/docker`,\n  resides on a partition without sufficient free space,\n  you may encounter an error like the following during a Docker container build job:\n\n    `/usr/bin/tar: /path/to/sonic-buildimage/<some_file>:\n     Cannot write: No space left on device`\n\n    The solution is to [move the directory](https://www.ibm.com/docs/en/z-logdata-analytics/5.1.0?topic=compose-relocating-docker-root-directory)\n    to a partition with more free space.\n* Use\n  `http_proxy=[your_proxy] https_proxy=[your_proxy] no_proxy=[your_no_proxy] make`\n  to enable http(s) proxy in the build process.\n* Add your user account to `docker` group and use your user account to make.\n  `root` or `sudo` are not supported.\n* For more details on cross-compilation errors, please refer to [README.arm64_build_on_amd64.md](https://github.com/sonic-net/sonic-buildimage/blob/master/README.arm64_build_on_amd64.md)\n\nThe SONiC installer contains all docker images needed.\nSONiC uses one image for all devices of a same ASIC vendor.\n\nFor Broadcom ASIC, we build ONIE and EOS image.\nEOS image is used for Arista devices,\nONIE image is used for all other Broadcom ASIC based devices.\n\n```shell\nmake configure PLATFORM=broadcom\n# build debian stretch required targets\nBLDENV=stretch make stretch\n# build ONIE image\nmake target/sonic-broadcom.bin\n# build EOS image\nmake target/sonic-aboot-broadcom.swi\n```\n\nYou may find the rules/config file useful.\nIt contains configuration options for the build process,\nlike adding more verbosity or showing dependencies,\nusername and password for base image etc.\n\nEvery docker image is built and saved to target/ directory.\nSo, for instance, to build only docker-database, execute:\n\n```shell\nmake target/docker-database.gz\n```\n\nSame goes for debian packages, which are under target/debs/:\n\n```shell\nmake target/debs/swss_1.0.0_amd64.deb\n```\n\nEvery target has a clean target, so in order to clean swss, execute:\n\n```shell\nmake target/debs/swss_1.0.0_amd64.deb-clean\n```\n\nIt is recommended to use clean targets to clean all packages that are built together,\nlike dev packages for instance.\nIn order to be more familiar with build process and make some changes to it,\nit is recommended to read this short [Documentation](README.buildsystem.md).\n\n## Build debug dockers and debug SONiC installer image\n\nSONiC build system supports building dockers and ONIE-image with debug tools\nand debug symbols, to help with live & core debugging.\nFor details refer to [SONiC Buildimage Guide](https://github.com/sonic-net/sonic-buildimage/blob/master/README.buildsystem.md).\n\n## SAI Version\n\nPlease refer to [SONiC roadmap](https://github.com/sonic-net/SONiC/wiki/Sonic-Roadmap-Planning)\non the SAI version for each SONiC release.\n\n## Notes\n\n* If you are running make for the first time, a sonic-slave-${USER} docker image\n  will be built automatically.\n  This may take a while, but it is a one-time action, so please be patient.\n* The root user account is disabled. However, the created user can `sudo`.\n* The target directory is `./target`, containing the NOS installer image\n  and docker images.\n  * sonic-generic.bin: SONiC switch installer image (ONIE compatible)\n  * sonic-aboot.bin: SONiC switch installer image (Aboot compatible)\n  * docker-base.gz: base docker image where other docker images are built from,\n    only used in build process (gzip tar archive)\n  * docker-database.gz: docker image for in-memory key-value store,\n    used as inter-process communication (gzip tar archive)\n  * docker-fpm.gz: docker image for quagga with fpm module enabled\n    (gzip tar archive)\n  * docker-orchagent.gz: docker image for SWitch State Service (SWSS)\n    (gzip tar archive)\n  * docker-syncd-brcm.gz: docker image for the daemon to sync database\n    and Broadcom switch ASIC (gzip tar archive)\n  * docker-syncd-cavm.gz: docker image for the daemon to sync database\n    and Cavium switch ASIC (gzip tar archive)\n  * docker-syncd-mlnx.gz: docker image for the daemon to sync database\n    and Mellanox switch ASIC (gzip tar archive)\n  * docker-syncd-nephos.gz: docker image for the daemon to sync database\n    and Nephos switch ASIC (gzip tar archive)\n  * docker-syncd-mrvl-teralynx.gz: docker image for the daemon to sync database\n    and Marvell-Teralynx switch ASIC (gzip tar archive)\n  * docker-syncd-mrvl-prestera.gz: docker image for the daemon to sync database\n    and Marvell-Prestera switch ASIC (gzip tar archive)\n  * docker-sonic-p4.gz: docker image for all-in-one for p4 software switch\n    (gzip tar archive)\n  * docker-sonic-vs.gz: docker image for all-in-one for software virtual switch\n    (gzip tar archive)\n  * docker-sonic-mgmt.gz: docker image for\n    [managing, configuring and monitoring SONiC](https://github.com/sonic-net/sonic-mgmt)\n    (gzip tar archive)\n\n## Contribution Guide\n\nAll contributors must sign a contribution license agreement before contributions\ncan be accepted.\nVisit [EasyCLA - Linux Foundation](https://easycla.lfx.linuxfoundation.org).\n\n## GitHub Workflow\n\nWe're following basic GitHub Flow.\nIf you have no idea what we're talking about, check out [GitHub's official guide](https://guides.github.com/introduction/flow/).\nNote that merge is only performed by the repository maintainer.\n\nGuide for performing commits:\n\n* Isolate each commit to one component/bugfix/issue/feature\n* Use a standard commit message format:\n\n> [component/folder touched]: Description intent of your changes\n>\n> [List of changes]\n>\n> Signed-off-by: Your Name your@email.com\n\nFor example:\n\n> swss-common: Stabilize the ConsumerTable\n>\n> * Fixing autoreconf\n> * Fixing unit-tests by adding checkers and initialize the DB before start\n> * Adding the ability to select from multiple channels\n> * Health-Monitor - The idea of the patch is that if something went wrong\n>   with the notification channel,\n>   we will have the option to know about it (Query the LLEN table length).\n>\n> Signed-off-by: user@dev.null\n\n* Each developer should fork this repository and [add the team as a Contributor](https://help.github.com/articles/adding-collaborators-to-a-personal-repository)\n* Push your changes to your private fork and do \"pull-request\" to this repository\n* Use a pull request to do code review\n* Use issues to keep track of what is going on\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)\nor contact [opencode@microsoft.com](mailto:opencode@microsoft.com)\nwith any additional questions or comments.\n",
      "stars_today": 1
    },
    {
      "id": 17101828,
      "name": "swirl_courses",
      "full_name": "swirldev/swirl_courses",
      "description": ":mortar_board: A collection of interactive courses for the swirl R package.",
      "html_url": "https://github.com/swirldev/swirl_courses",
      "stars": 4519,
      "forks": 7243,
      "language": "R",
      "topics": [],
      "created_at": "2014-02-23T04:48:04Z",
      "updated_at": "2026-01-12T21:17:04Z",
      "pushed_at": "2024-01-10T17:38:19Z",
      "open_issues": 206,
      "owner": {
        "login": "swirldev",
        "avatar_url": "https://avatars.githubusercontent.com/u/5671732?v=4"
      },
      "readme": "# swirl courses\n\nThis is a collection of interactive courses for use with the [swirl R package](http://swirlstats.com). You'll find instructions for installing courses further down on this page. Some courses are still in development and we'd love to hear any [suggestions](https://github.com/swirldev/swirl_courses/issues/new) you have as you work through them.\n\nFor more information regarding swirl, visit [swirlstats.com](http://swirlstats.com) or the [swirl GitHub repository](https://github.com/swirldev/swirl). If you'd like to write your own interactive content, please visit the [Instructors page](http://swirlstats.com/instructors.html) of our website.\n\nHere are our current offerings, organized by level of difficulty:\n\n#### Beginner\n\n- **R Programming**: The basics of programming in R\n- [**R Programming E**](https://github.com/swirldev/R_Programming_E): Same as the original, but modified slightly for in-class use (see below ***)\n- [**The R Programming Environment**](https://swirlstats.com/scn/rpe.html)\n<!-- - **Data Analysis**: Basic ideas in statistics and data visualization -->\n<!-- - **Mathematical Biostatistics Boot Camp**: One- and two-sample t-tests, power, and sample size -->\n<!-- - **Open Intro**: A very basic introduction to statistics, data analysis, and data visualization -->\n\n\\*\\*\\* *R Programming E is identical to R Programming, except we've eliminated the prompts for Coursera credentials at the end of each lesson and instead give students the option to send an email to their instructor notifying them of completion. Admittedly, it's sort of a hack until we come up with a more robust solution for in-class use (i.e. an instructor \"dashboard\").*\n\n#### Intermediate\n\n- **Regression Models**: The basics of regression modeling in R\n- **Getting and Cleaning Data**: dplyr, tidyr, lubridate, oh my!\n\n#### Advanced\n\n- **Statistical Inference**: This intermediate to advanced level course closely follows the\n[Statistical Inference course](https://www.coursera.org/course/statinference) of the Johns Hopkins \n[Data Science Specialization](https://www.coursera.org/specialization/jhudatascience/1) on Coursera. It\nintroduces the student to basic concepts of statistical inference\nincluding probability, hypothesis testing, confidence intervals and\np-values. It concludes with an initiation to topics of particular\nrelevance to big data, issues of multiple testing and resampling.\n- [**Advanced R Programming**](https://swirlstats.com/scn/arp.html)\n\nSince our users come from a variety backgrounds, it's very hard to label material as **Beginner**, **Intermediate**, or **Advanced**. If you find something that is labelled **Beginner** to be challenging, please don't be discouraged. The first step of learning anything is to acknowledge that you are capable of understanding it. True understanding will come with time and practice.\n\n#### Course Authors\n\n- **Writing swirl Courses**: An interactive guides and example \n  for swirl course authors. The first group of lessons cover basics. The rest cover \n  special topics useful primarily as samples--points of departure for one's own material.\n  For more comprehensive documentation about writing your own swirl courses see http://swirlstats.com/swirlify/.\n\n## Install and run a course automatically from swirl\n\n**This is the preferred method of installing courses.** It automates the process by allowing you to do everything right from the R console.\n\n1) Make sure you have a recent version version of swirl:\n\n```\ninstall.packages(\"swirl\")\n```\n\n2) Enter the following from the R console, **substituting the name of the course** that you wish to install:\n\n```\nlibrary(swirl)\ninstall_course(\"Course Name Here\")\nswirl()\n```\n\nFor example, `install_course(\"R Programming\")` will install the R Programming course. **Please note that course names are case sensitive!**\n\nIf that doesn't work for you...\n\n## Install and run a course manually\n\nIf the automatic course installation method outlined above does not work for you, then there's a simple alternative.\n\n1. Find the course you want to install on the [Swirl Course network website](https://swirlstats.com/scn/title.html).\n2. Follow the manual installation instructions on the course page.\n\nIf that does not work for you, consider taking a look at the \n[legacy manual install instructions](https://github.com/swirldev/swirl_courses/wiki/Legacy-Manual-Install-Instructions-for-Swirl-Courses).\n\n## Uninstall a course\n\nIf you'd like to remove a course at any time, you can use `uninstall_course(\"Course Name Here\")`.\n\n## Using swirl in the classroom\n\nInstructors around the world are using swirl in their classrooms. We think this is awesome. If you're an instructor, please feel free to do the same -- free of charge. While your students may be paying to take your course or attend your institution, we simply ask that you don't charge people *directly* for the use of our software or instructional content.\n\nIf you are not sure about a particular use case, don't hesitate to post a\nquestion to our [Google Group](https://groups.google.com/forum/#!forum/swirl-discuss).\n",
      "stars_today": 0
    },
    {
      "id": 39799721,
      "name": "r4ds",
      "full_name": "hadley/r4ds",
      "description": "R for data science: a book",
      "html_url": "https://github.com/hadley/r4ds",
      "stars": 4967,
      "forks": 4390,
      "language": "R",
      "topics": [
        "book",
        "bookdown",
        "data-science",
        "r"
      ],
      "created_at": "2015-07-27T21:52:44Z",
      "updated_at": "2026-01-12T17:42:15Z",
      "pushed_at": "2025-11-14T20:54:38Z",
      "open_issues": 18,
      "owner": {
        "login": "hadley",
        "avatar_url": "https://avatars.githubusercontent.com/u/4196?v=4"
      },
      "readme": "# R for Data Science\n\n<!-- badges: start -->\n\n[![Render and deploy Book to Netlify](https://github.com/hadley/r4ds/actions/workflows/build_book.yaml/badge.svg)](https://github.com/hadley/r4ds/actions/workflows/build_book.yaml)\n\n<!-- badges: end -->\n\nThis repository contains the source of [R for Data Science](http://r4ds.hadley.nz) book.\nThe book is built using [Quarto](https://quarto.org/).\n\n## Images\n\n### Omnigraffle drawings\n\n-   Font: 12pt Guardian Sans Condensed / Ubuntu mono\n\n-   Export as 300 dpi png.\n\n-   Website font is 18 px = 13.5 pt, so scale dpi to match font sizes: 270 = 300 \\* 12 / 13.5.\n    (I also verified this empirically by screenshotting.)\n\n    ``` r\n    #| echo: FALSE\n    #| out.width: NULL\n    knitr::include_graphics(\"diagrams/transform.png\", dpi = 270)\n    ```\n\n### Screenshots\n\n-   Make sure you're using a light theme.\n    For small interface elements (eg. toolbars), zoom in twice.\n\n-   Screenshot with Cmd + Shift + 4.\n\n-   Don't need to set dpi:\n\n    ``` r\n    #| echo: FALSE\n    #| out.width: NULL\n    knitr::include_graphics(\"screenshots/rstudio-wg.png\")\n    ```\n\n### O'Reilly\n\nTo generate book for O'Reilly, build the book then:\n\n```{r}\n# pak::pak(\"hadley/htmlbook\")\nhtmlbook::convert_book()\n\nhtml <- list.files(\"oreilly\", pattern = \"[.]html$\", full.names = TRUE)\nfile.copy(html, \"../r-for-data-science-2e/\", overwrite = TRUE)\n\npngs <- list.files(\"oreilly\", pattern = \"[.]png$\", full.names = TRUE, recursive = TRUE)\ndest <- gsub(\"oreilly\", \"../r-for-data-science-2e/\", pngs)\nfs::dir_create(unique(dirname(dest)))\nfile.copy(pngs, dest, overwrite = TRUE)\n```\n\nThen commit and push to atlas.\n\n## Code of Conduct\n\nPlease note that r4ds uses a [Contributor Code of Conduct](https://contributor-covenant.org/version/2/0/CODE_OF_CONDUCT.html).\nBy contributing to this book, you agree to abide by its terms.\n",
      "stars_today": 0
    },
    {
      "id": 4729944,
      "name": "shiny",
      "full_name": "rstudio/shiny",
      "description": "Easy interactive web applications with R",
      "html_url": "https://github.com/rstudio/shiny",
      "stars": 5580,
      "forks": 1880,
      "language": "R",
      "topics": [
        "r",
        "reactive",
        "rstudio",
        "shiny",
        "web-app",
        "web-development"
      ],
      "created_at": "2012-06-20T18:45:11Z",
      "updated_at": "2026-01-13T10:41:23Z",
      "pushed_at": "2026-01-12T16:26:11Z",
      "open_issues": 868,
      "owner": {
        "login": "rstudio",
        "avatar_url": "https://avatars.githubusercontent.com/u/513560?v=4"
      },
      "readme": "# shiny <img src=\"man/figures/logo.png\" align=\"right\" width=120 height=139 alt=\"\" />\n\n<!-- badges: start -->\n[![CRAN](https://www.r-pkg.org/badges/version/shiny)](https://CRAN.R-project.org/package=shiny)\n[![R build status](https://github.com/rstudio/shiny/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/rstudio/shiny/actions)\n[![RStudio community](https://img.shields.io/badge/community-shiny-blue?style=social&logo=rstudio&logoColor=75AADB)](https://forum.posit.co/new-topic?category=shiny&tags=shiny)\n\n<!-- badges: end -->\n\nEasily build rich and productive interactive web apps in R &mdash; no HTML/CSS/JavaScript required.\n\n## Features\n\n* An intuitive and extensible [reactive programming](https://en.wikipedia.org/wiki/Reactive_programming) model which makes it easy to transform existing R code into a \"live app\" where outputs automatically react to new user input.\n  * Compared to event-based programming, reactivity allows Shiny to do the minimum amount of work when input(s) change, and allows humans to more easily reason about complex [MVC logic](https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller).\n* A prebuilt set of highly sophisticated, customizable, and easy-to-use widgets (e.g., plots, tables, sliders, dropdowns, date pickers, and more).\n* An attractive default look based on [Bootstrap](https://getbootstrap.com/) which can also be easily customized with the [bslib](https://github.com/rstudio/bslib) package or avoided entirely with more direct R bindings to HTML/CSS/JavaScript.\n* Seamless integration with [R Markdown](https://shiny.rstudio.com/articles/interactive-docs.html), making it easy to embed numerous applications natively within a larger dynamic document.\n* Tools for improving and monitoring performance, including native support for [async programming](https://posit.co/blog/shiny-1-1-0/), [caching](https://talks.cpsievert.me/20201117), [load testing](https://rstudio.github.io/shinyloadtest/), and more.\n* [Modules](https://shiny.rstudio.com/articles/modules.html): a framework for reducing code duplication and complexity.\n* An ability to [bookmark application state](https://shiny.rstudio.com/articles/bookmarking-state.html) and/or [generate code to reproduce output(s)](https://github.com/rstudio/shinymeta).\n* A rich ecosystem of extension packages for more [custom widgets](http://www.htmlwidgets.org/), [input validation](https://github.com/rstudio/shinyvalidate), [unit testing](https://github.com/rstudio/shinytest), and more.\n\n## Installation\n\nTo install the stable version from CRAN:\n\n```r\ninstall.packages(\"shiny\")\n```\n\n## Getting Started\n\nOnce installed, load the library and run an example:\n\n```r\nlibrary(shiny)\n# Launches an app, with the app's source code included\nrunExample(\"06_tabsets\")\n# Lists more prepackaged examples\nrunExample()\n```\n\nFor more examples and inspiration, check out the [Shiny User Gallery](https://shiny.rstudio.com/gallery/).\n\nFor help with learning fundamental Shiny programming concepts, check out the [Mastering Shiny](https://mastering-shiny.org/) book and the [Shiny Tutorial](https://shiny.rstudio.com/tutorial/). The former is currently more up-to-date with modern Shiny features, whereas the latter takes a deeper, more visual, dive into fundamental concepts.\n\n## Join the conversation\n\nIf you want to chat about Shiny, meet other developers, or help us decide what to work on next, [join us on Discord](https://discord.com/invite/yMGCamUMnS).\n\n## Getting Help\n\nTo ask a question about Shiny, please use the [RStudio Community website](https://forum.posit.co/new-topic?category=shiny&tags=shiny).\n\nFor bug reports, please use the [issue tracker](https://github.com/rstudio/shiny/issues) and also keep in mind that by [writing a good bug report](https://github.com/rstudio/shiny/wiki/Writing-Good-Bug-Reports), you're more likely to get help with your problem.\n\n## Contributing\n\nWe welcome contributions to the **shiny** package. Please see our [CONTRIBUTING.md](https://github.com/rstudio/shiny/blob/main/.github/CONTRIBUTING.md) file for detailed guidelines of how to contribute.\n\n## License\n\nThe shiny package as a whole is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.\n\n## R version support\n\nShiny is supported on the latest release version of R, as well as the previous four minor release versions of R. For example, if the latest release R version is 4.3, then that version is supported, as well as 4.2, 4.1, 4.0, 3.6.\n",
      "stars_today": 0
    },
    {
      "id": 6427813,
      "name": "dplyr",
      "full_name": "tidyverse/dplyr",
      "description": "dplyr: A grammar of data manipulation",
      "html_url": "https://github.com/tidyverse/dplyr",
      "stars": 4981,
      "forks": 2132,
      "language": "R",
      "topics": [
        "data-manipulation",
        "grammar",
        "r"
      ],
      "created_at": "2012-10-28T13:39:17Z",
      "updated_at": "2026-01-09T01:48:36Z",
      "pushed_at": "2025-12-19T19:01:08Z",
      "open_issues": 76,
      "owner": {
        "login": "tidyverse",
        "avatar_url": "https://avatars.githubusercontent.com/u/22032646?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# dplyr <a href=\"https://dplyr.tidyverse.org\"><img src=\"man/figures/logo.png\" align=\"right\" height=\"138\" /></a>\n\n<!-- badges: start -->\n\n[![CRAN\nstatus](https://www.r-pkg.org/badges/version/dplyr)](https://cran.r-project.org/package=dplyr)\n[![R-CMD-check](https://github.com/tidyverse/dplyr/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/tidyverse/dplyr/actions/workflows/R-CMD-check.yaml)\n[![Codecov test\ncoverage](https://codecov.io/gh/tidyverse/dplyr/graph/badge.svg)](https://app.codecov.io/gh/tidyverse/dplyr)\n<!-- badges: end -->\n\n## Overview\n\ndplyr is a grammar of data manipulation, providing a consistent set of\nverbs that help you solve the most common data manipulation challenges:\n\n- `mutate()` adds new variables that are functions of existing variables\n- `select()` picks variables based on their names.\n- `filter()` picks cases based on their values.\n- `summarise()` reduces multiple values down to a single summary.\n- `arrange()` changes the ordering of the rows.\n\nThese all combine naturally with `group_by()` which allows you to\nperform any operation ‚Äúby group‚Äù. You can learn more about them in\n`vignette(\"dplyr\")`. As well as these single-table verbs, dplyr also\nprovides a variety of two-table verbs, which you can learn about in\n`vignette(\"two-table\")`.\n\nIf you are new to dplyr, the best place to start is the [data\ntransformation chapter](https://r4ds.hadley.nz/data-transform) in R for\nData Science.\n\n## Backends\n\nIn addition to data frames/tibbles, dplyr makes working with other\ncomputational backends accessible and efficient. Below is a list of\nalternative backends:\n\n- [arrow](https://arrow.apache.org/docs/r/) for larger-than-memory\n  datasets, including on remote cloud storage like AWS S3, using the\n  Apache Arrow C++ engine,\n  [Acero](https://arrow.apache.org/docs/cpp/acero/overview.html).\n\n- [dbplyr](https://dbplyr.tidyverse.org/) for data stored in a\n  relational database. Translates your dplyr code to SQL.\n\n- [dtplyr](https://dtplyr.tidyverse.org/) for large, in-memory datasets.\n  Translates your dplyr code to high performance\n  [data.table](https://rdatatable.gitlab.io/data.table/) code.\n\n- [duckplyr](https://duckplyr.tidyverse.org/) for large, in-memory\n  datasets. Translates your dplyr code to high performance\n  [duckdb](https://duckdb.org) queries with zero extra copies and an\n  automatic R fallback when translation isn‚Äôt possible.\n\n- [sparklyr](https://spark.posit.co/) for very large datasets stored in\n  [Apache Spark](https://spark.apache.org).\n\n## Installation\n\n``` r\n# The easiest way to get dplyr is to install the whole tidyverse:\ninstall.packages(\"tidyverse\")\n\n# Alternatively, install just dplyr:\ninstall.packages(\"dplyr\")\n```\n\n### Development version\n\nTo get a bug fix or to use a feature from the development version, you\ncan install the development version of dplyr from GitHub.\n\n``` r\n# install.packages(\"pak\")\npak::pak(\"tidyverse/dplyr\")\n```\n\n## Cheat Sheet\n\n<a href=\"https://github.com/rstudio/cheatsheets/blob/main/data-transformation.pdf\"><img src=\"https://raw.githubusercontent.com/rstudio/cheatsheets/main/pngs/thumbnails/data-transformation-cheatsheet-thumbs.png\" width=\"630\" height=\"252\"/></a>\n\n## Usage\n\n``` r\nlibrary(dplyr)\n\nstarwars |>\n  filter(species == \"Droid\")\n#> # A tibble: 6 √ó 14\n#>   name   height  mass hair_color skin_color  eye_color birth_year sex   gender  \n#>   <chr>   <int> <dbl> <chr>      <chr>       <chr>          <dbl> <chr> <chr>   \n#> 1 C-3PO     167    75 <NA>       gold        yellow           112 none  masculi‚Ä¶\n#> 2 R2-D2      96    32 <NA>       white, blue red               33 none  masculi‚Ä¶\n#> 3 R5-D4      97    32 <NA>       white, red  red               NA none  masculi‚Ä¶\n#> 4 IG-88     200   140 none       metal       red               15 none  masculi‚Ä¶\n#> 5 R4-P17     96    NA none       silver, red red, blue         NA none  feminine\n#> # ‚Ñπ 1 more row\n#> # ‚Ñπ 5 more variables: homeworld <chr>, species <chr>, films <list>,\n#> #   vehicles <list>, starships <list>\n\nstarwars |>\n  select(name, ends_with(\"color\"))\n#> # A tibble: 87 √ó 4\n#>   name           hair_color skin_color  eye_color\n#>   <chr>          <chr>      <chr>       <chr>    \n#> 1 Luke Skywalker blond      fair        blue     \n#> 2 C-3PO          <NA>       gold        yellow   \n#> 3 R2-D2          <NA>       white, blue red      \n#> 4 Darth Vader    none       white       yellow   \n#> 5 Leia Organa    brown      light       brown    \n#> # ‚Ñπ 82 more rows\n\nstarwars |>\n  mutate(name, bmi = mass / ((height / 100)^2)) |>\n  select(name:mass, bmi)\n#> # A tibble: 87 √ó 4\n#>   name           height  mass   bmi\n#>   <chr>           <int> <dbl> <dbl>\n#> 1 Luke Skywalker    172    77  26.0\n#> 2 C-3PO             167    75  26.9\n#> 3 R2-D2              96    32  34.7\n#> 4 Darth Vader       202   136  33.3\n#> 5 Leia Organa       150    49  21.8\n#> # ‚Ñπ 82 more rows\n\nstarwars |>\n  arrange(desc(mass))\n#> # A tibble: 87 √ó 14\n#>   name      height  mass hair_color skin_color eye_color birth_year sex   gender\n#>   <chr>      <int> <dbl> <chr>      <chr>      <chr>          <dbl> <chr> <chr> \n#> 1 Jabba De‚Ä¶    175  1358 <NA>       green-tan‚Ä¶ orange         600   herm‚Ä¶ mascu‚Ä¶\n#> 2 Grievous     216   159 none       brown, wh‚Ä¶ green, y‚Ä¶       NA   male  mascu‚Ä¶\n#> 3 IG-88        200   140 none       metal      red             15   none  mascu‚Ä¶\n#> 4 Darth Va‚Ä¶    202   136 none       white      yellow          41.9 male  mascu‚Ä¶\n#> 5 Tarfful      234   136 brown      brown      blue            NA   male  mascu‚Ä¶\n#> # ‚Ñπ 82 more rows\n#> # ‚Ñπ 5 more variables: homeworld <chr>, species <chr>, films <list>,\n#> #   vehicles <list>, starships <list>\n\nstarwars |>\n  group_by(species) |>\n  summarise(\n    n = n(),\n    mass = mean(mass, na.rm = TRUE)\n  ) |>\n  filter(\n    n > 1,\n    mass > 50\n  )\n#> # A tibble: 9 √ó 3\n#>   species      n  mass\n#>   <chr>    <int> <dbl>\n#> 1 Droid        6  69.8\n#> 2 Gungan       3  74  \n#> 3 Human       35  81.3\n#> 4 Kaminoan     2  88  \n#> 5 Mirialan     2  53.1\n#> # ‚Ñπ 4 more rows\n```\n\n## Getting help\n\nIf you encounter a clear bug, please file an issue with a minimal\nreproducible example on\n[GitHub](https://github.com/tidyverse/dplyr/issues). For questions and\nother discussion, please use [forum.posit.co](https://forum.posit.co/).\n\n## Code of conduct\n\nPlease note that this project is released with a [Contributor Code of\nConduct](https://dplyr.tidyverse.org/CODE_OF_CONDUCT). By participating\nin this project you agree to abide by its terms.\n",
      "stars_today": 0
    },
    {
      "id": 2045207,
      "name": "jetty.project",
      "full_name": "jetty/jetty.project",
      "description": "Eclipse Jetty¬Æ - Web Container & Clients - supports HTTP/3, HTTP/2, HTTP/1, websocket, servlets, and more",
      "html_url": "https://github.com/jetty/jetty.project",
      "stars": 4050,
      "forks": 1989,
      "language": "Java",
      "topics": [
        "eclipse",
        "embedded",
        "fcgi",
        "http",
        "http-client",
        "http-server",
        "http2",
        "http3",
        "https",
        "jakartaee",
        "java",
        "jetty",
        "jpms",
        "jsp",
        "osgi",
        "servlet",
        "ssl",
        "tls",
        "unix-socket",
        "websockets"
      ],
      "created_at": "2011-07-14T01:11:57Z",
      "updated_at": "2026-01-14T00:43:30Z",
      "pushed_at": "2026-01-13T23:09:27Z",
      "open_issues": 262,
      "owner": {
        "login": "jetty",
        "avatar_url": "https://avatars.githubusercontent.com/u/143739000?v=4"
      },
      "readme": "# Eclipse Jetty\n\nEclipse Jetty is a lightweight, highly scalable, Java-based web server and Servlet engine.\nJetty's goal is to support web protocols (HTTP/1, HTTP/2, HTTP/3, WebSocket, etc.) in a high volume low latency way that provides maximum performance while retaining the ease of use and compatibility with years of Servlet development.\nJetty is a modern fully asynchronous web server that has a long history as a component oriented technology, and can be easily embedded into applications while still offering a solid traditional distribution for webapp deployment.\n\n- https://jetty.org\n- https://projects.eclipse.org/projects/rt.jetty\n\n## Webapp Example\n\n```shell\n$ mkdir jetty-base && cd jetty-base\n$ java -jar $JETTY_HOME/start.jar --add-modules=http,ee11-deploy\n$ cp ~/src/myproj/target/mywebapp.war webapps\n$ java -jar $JETTY_HOME/start.jar \n```\n\n## Multiple Versions Webapp Example\n\n```shell\n$ mkdir jetty-base && cd jetty-base\n$ java -jar $JETTY_HOME/start.jar --add-modules=http,ee11-deploy,ee8-deploy\n$ cp ~/src/myproj/target/mywebapp10.war webapps\n$ cp ~/src/myproj/target/mywebapp8.war webapps\n$ echo \"environment: ee8\" > webapps/mywebapp8.properties\n$ java -jar $JETTY_HOME/start.jar \n```\n\n## Embedded Jetty Example\n\n```java\nServer server = new Server(port);\nserver.setHandler(new MyHandler());\nserver.start();\n```\n\n## Embedded Servlet Example\n\n```java\nServer server = new Server(port);\nServletContextHandler context = new ServletContextHandler(\"/\");\ncontext.addServlet(MyServlet.class, \"/*\");\nserver.setHandler(context);\nserver.start();\n```\n\n## Building Jetty from Source\n\n```shell\n$ git clone https://github.com/jetty/jetty.project.git\n$ cd jetty.project\n$ mvn -Pfast clean install # fast build bypasses tests and other checks\n```\n\nFor more detailed information on building and contributing to the Jetty project, please see the [Contribution Guide](https://jetty.org/docs/contribution-guide/index.html).\n\n# Documentation\n\n[Jetty's documentation](https://jetty.org/docs) is available on the Eclipse Jetty website.\n\nThe documentation is divided into three guides, based on use case:\n\n* The [Operations Guide](https://jetty.org/docs/jetty/12/operations-guide/index.html) targets sysops, devops, and developers who want to install Eclipse Jetty as a standalone server to deploy web applications.\n\n* The [Programming Guide](https://jetty.org/docs/jetty/12/programming-guide/index.html) targets developers who want to use the Eclipse Jetty libraries in their applications, and advanced sysops/devops that want to customize the deployment of web applications.\n\n* The [Contribution Guide](https://jetty.org/docs/contribution-guide/index.html) targets developers that wish to contribute to the Jetty Project with code patches or documentation improvements.\n\n\n# Commercial Support\n\nExpert advice and production support of Jetty are provided by [Webtide](https://webtide.com).\n",
      "stars_today": 0
    },
    {
      "id": 15333809,
      "name": "open62541",
      "full_name": "open62541/open62541",
      "description": "Open source implementation of OPC UA (OPC Unified Architecture) aka IEC 62541 licensed under Mozilla Public License v2.0",
      "html_url": "https://github.com/open62541/open62541",
      "stars": 2997,
      "forks": 1381,
      "language": "C",
      "topics": [
        "c",
        "client",
        "iec-62541",
        "industrial-automation",
        "opc",
        "opc-ua",
        "opcua",
        "publish-subscribe",
        "pubsub",
        "sdk",
        "server",
        "tsn"
      ],
      "created_at": "2013-12-20T08:45:05Z",
      "updated_at": "2026-01-13T15:18:29Z",
      "pushed_at": "2026-01-13T15:18:08Z",
      "open_issues": 864,
      "owner": {
        "login": "open62541",
        "avatar_url": "https://avatars.githubusercontent.com/u/16096536?v=4"
      },
      "readme": "<div align=\"center\">\n  <a href=\"https://open62541.org\">\n    <img alt=\"open62541 Logo\" src=\"https://open62541.org/images/logo-open62541.svg\" width=\"400px\">\n  </a>\n  <br />\n  <a href=\"https://open62541.org\" target=\"_blank\" rel=\"noopener\">https://open62541.org</a> | <a href=\"https://www.o6-automation.com\" target=\"_blank\" rel=\"noopener\">https://www.o6-automation.com</a>\n</div>\n<br />\n\nopen62541 (<http://open62541.org>) is an open source implementation of OPC UA (OPC Unified Architecture / IEC 62541) written in the C language. The library is usable with all major compilers and provides the necessary tools to implement dedicated OPC UA clients and servers, or to integrate OPC UA-based communication into existing applications. See the [features overview](FEATURES.md) for full details.\nThe open62541 library is platform independent: All platform-specific functionality is implemented via exchangeable plugins for easy porting to different (embedded) targets.\n\nopen62541 is licensed under the Mozilla Public License v2.0 (MPLv2). This allows the open62541 library to be combined and distributed with any proprietary software. Only changes to the open62541 library itself need to be licensed under the MPLv2 when copied and distributed. Some plugins and examples are in the public domain (CC0 license) and some are licensed under MPLv2. The CC0 licensed ones can be reused under any license and changes do not have to be published.\n\nThe library is available in standard source and binary form. In addition, the single-file source distribution merges the entire library into a single .c and .h file that can be easily added to existing projects. Example server and client implementations can be found in the [/examples](examples/) directory or further down on this page.\n\n[![Open Hub Project Status](https://www.openhub.net/p/open62541/widgets/project_thin_badge.gif)](https://www.openhub.net/p/open62541/)\n[![Build Status](https://ci.appveyor.com/api/projects/status/github/open62541/open62541?branch=master&svg=true)](https://ci.appveyor.com/project/open62541/open62541/branch/master)\n[![Code Scanning](https://github.com/open62541/open62541/actions/workflows/codeql.yml/badge.svg)](https://github.com/open62541/open62541/actions/workflows/codeql.yml)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/open62541.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:open62541)\n[![codecov](https://codecov.io/gh/open62541/open62541/branch/master/graph/badge.svg)](https://codecov.io/gh/open62541/open62541)\n\n## Documentation and Support\n\nA general introduction to OPC UA and the open62541 documentation can be found at http://open62541.org.\nPast releases of the library can be downloaded at https://github.com/open62541/open62541/releases.\n\nThe overall open62541 community handles public support requests on Github and the mailing list.\nFor individual discussion and support, use the following channels:\n\n- [Mailing List](https://groups.google.com/d/forum/open62541)\n- [Issue Tracker](https://github.com/open62541/open62541/issues)\n- [Pull Requests](https://github.com/open62541/open62541/pulls)\n\n[o6 Automation GmbH](https://www.o6-automation.com/) employs the core contributors to open62541 and provides **[commercial support](https://www.o6-automation.com/services)**.\nThe project is however open to outside contributions and **contributors retain their individual copyright**. This prevents future relicensing under different license conditions.\n\nWe want to foster an open and welcoming community. Please take our [code of conduct](CODE_OF_CONDUCT.md) into regard.\n\n## Commercial Use\n\nopen62541 is licensed under the MPLv2. That is, changes to files under MPLv2 fall under the same open-source license.\nBut the library can be combined with private development from separate files, also if a static binary is produced, without the license affecting the private files.\nSee the full [license document](LICENSE) for details.\n\n## Official Certification\n\nAn example server built with open62541 v1.4 was certified for the 'Standard Server 2017 Profile' by the OPC Foundation.\nSee https://open62541.org/certification for more details.\n\n## Build System, Code Structure and Dependencies\n\nThe build environment of open62541 is generated via CMake. See the [build documentation](https://www.open62541.org/doc/master/building.html) for details.\nTo simplify the integration with existing software projects, the open62541 sources can be compressed (amalgamated) into a single-file-distribution, a pair of `open62541.c/.h` files.\nThe functionality included in the single-file-distribution depends on the current CMake configuration.\n\nThe source code is structured as follows:\n\n- Public API (`/include`): The public API is exposed to applications using open62541. The headers for plugin implementations are in `/plugins/include`.\n- Core Library (`/src`): The core library has no dependencies besides the C99 standard headers.\n- Architecture Support (`/arch`): Architecture support is implemented via the `EventLoop` plugin. This keeps the architecture-specific code - for example to use the POSIX APIs - out of the core library. Ports to different (embedded) architectures are provided.\n- Default Plugins Implementations (`/plugins`): The plugin interfaces allow the integration with different backend systems and libraries. For example concerning crypto primitives, storage of the information model, and so on. Default implementations are provided.\n- Dependencies (`/deps`): Some additional libraries are used via git submodules or have been internalized in the `deps/` folder. More information on the third-party libraries and their respective licenses can be found in [deps/README.md](deps/README.md)\n- Building and Code Generation: Some code is auto-generated from XML definitions that are part of the OPC UA standard. The code generation scripts use Python as part of the build process.\n\nOn most systems, a bare-bones open62541 requires the C standard library only.\nDepending on the build configuration, open62541 depends on additional libraries, such as mbedTLS or OpenSSL for encryption.\n\n## Development\n\nAs an open source project, new contributors are encouraged to help improve open62541.\nThe file [CONTRIBUTING.md](CONTRIBUTING.md) aggregates good practices that we expect for code contributions.\nThe following are good starting points for new contributors:\n\n- [Report bugs](https://github.com/open62541/open62541/issues)\n- Improve the [documentation](http://open62541.org/doc/current)\n- Work on issues marked as \"[good first issue](https://github.com/open62541/open62541/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22)\"\n\nFor custom development that shall eventually become part of the open62541 library, please keep one of the core maintainers in the loop.\n\n### Code Quality\n\nWe emphasize code quality. The following quality metrics are continuously checked and are ensured to hold before an official release is made:\n\n- Zero errors indicated by the Compliance Testing Tool (CTT) of the OPC Foundation for the supported features\n- Zero compiler warnings from GCC/Clang/MSVC with very strict compilation flags\n- Zero issues indicated by unit tests (we target more than 80% code coverage)\n- Zero issues indicated by clang-analyzer, clang-tidy, cpp-check and the Codacy static code analysis tools\n- Zero unresolved issues from fuzzing the library in Google's oss-fuzz infrastructure\n- Zero issues indicated by Valgrind (Linux), DrMemory (Windows) and Clang AddressSanitizer / MemorySanitizer for the CTT tests, unit tests and fuzzing\n\n### Security and Vulnerability Handling\n\nThe project has established a process for handling vulnerabilities.\nSee the [SECURITY.md](SECURITY.md) for details and how to responsibly disclose findings to the maintainers.\n\n## Installation and Examples\n\nOn Debian/Ubuntu systems, a simple ```apt install libopen62541-1.4-dev``` installs the library and the development header files.\nUsing the GCC compiler, just run ```gcc -std=c99 <server.c> -lopen62541 -o server```.\n\nA more detailed explanation on how to install the open62541 SDK is given in our [documentation](https://www.open62541.org/doc/master/building.html#building-the-library).\nIn essence, clone the repository and initialize all the submodules using `git submodule update --init --recursive`. Then use CMake to configure your build.\n\nA complete list of examples can be found in the [examples directory](https://github.com/open62541/open62541/tree/master/examples).\n\n### Example Server Implementation\n\n```c\n#include <open62541/server.h>\n\nint main(int argc, char** argv)\n{\n    /* Create a server listening on port 4840 (default) */\n    UA_Server *server = UA_Server_new();\n\n    /* Add a variable node to the server */\n\n    /* 1) Define the variable attributes */\n    UA_VariableAttributes attr = UA_VariableAttributes_default;\n    attr.displayName = UA_LOCALIZEDTEXT(\"en-US\", \"the answer\");\n    UA_Int32 myInteger = 42;\n    UA_Variant_setScalar(&attr.value, &myInteger, &UA_TYPES[UA_TYPES_INT32]);\n\n    /* 2) Define where the node shall be added with which browsename */\n    UA_NodeId newNodeId = UA_NODEID_STRING(1, \"the.answer\");\n    UA_NodeId parentNodeId = UA_NS0ID(OBJECTSFOLDER);\n    UA_NodeId parentReferenceNodeId = UA_NS0ID(ORGANIZES);\n    UA_NodeId variableType = UA_NODEID_NULL; /* take the default variable type */\n    UA_QualifiedName browseName = UA_QUALIFIEDNAME(1, \"the answer\");\n\n    /* 3) Add the node */\n    UA_Server_addVariableNode(server, newNodeId, parentNodeId,\n                              parentReferenceNodeId, browseName,\n                              variableType, attr, NULL, NULL);\n\n    /* Run the server (until ctrl-c interrupt) */\n    UA_StatusCode status = UA_Server_runUntilInterrupt(server);\n\n    /* Clean up */\n    UA_Server_delete(server);\n    return status == UA_STATUSCODE_GOOD ? EXIT_SUCCESS : EXIT_FAILURE;\n}\n```\n\n### Example Client Implementation\n\n```c\n#include <stdio.h>\n#include <open62541/client.h>\n#include <open62541/client_highlevel.h>\n\nint main(int argc, char *argv[])\n{\n    /* Create a client and connect */\n    UA_Client *client = UA_Client_new();\n    UA_ClientConfig_setDefault(UA_Client_getConfig(client));\n    UA_StatusCode status = UA_Client_connect(client, \"opc.tcp://localhost:4840\");\n    if(status != UA_STATUSCODE_GOOD) {\n        UA_Client_delete(client);\n        return status;\n    }\n\n    /* Read the value attribute of the node. UA_Client_readValueAttribute is a\n     * wrapper for the raw read service available as UA_Client_Service_read. */\n    UA_Variant value; /* Variants can hold scalar values and arrays of any type */\n    UA_Variant_init(&value);\n    status = UA_Client_readValueAttribute(client, UA_NODEID_STRING(1, \"the.answer\"), &value);\n    if(status == UA_STATUSCODE_GOOD &&\n       UA_Variant_hasScalarType(&value, &UA_TYPES[UA_TYPES_INT32])) {\n        printf(\"the value is: %i\\n\", *(UA_Int32*)value.data);\n    }\n\n    /* Clean up */\n    UA_Variant_clear(&value);\n    UA_Client_delete(client); /* Disconnects the client internally */\n    return status == UA_STATUSCODE_GOOD ? EXIT_SUCCESS : EXIT_FAILURE;\n}\n```\n",
      "stars_today": 0
    },
    {
      "id": 312716297,
      "name": "DefiLlama-Adapters",
      "full_name": "DefiLlama/DefiLlama-Adapters",
      "description": null,
      "html_url": "https://github.com/DefiLlama/DefiLlama-Adapters",
      "stars": 1105,
      "forks": 6816,
      "language": "JavaScript",
      "topics": [],
      "created_at": "2020-11-14T00:41:54Z",
      "updated_at": "2026-01-13T20:04:12Z",
      "pushed_at": "2026-01-13T16:47:52Z",
      "open_issues": 186,
      "owner": {
        "login": "DefiLlama",
        "avatar_url": "https://avatars.githubusercontent.com/u/82048198?v=4"
      },
      "readme": "# Defillama Adapters\n\nFollow [this guide](https://docs.llama.fi/submit-a-project) to create an adapter and submit a PR with it.\n\nAlso, don't hesitate to send a message on [our discord](https://discord.defillama.com/) if we're late to merge your PR.\n\n> If you would like to add a `volume` adapter please submit the PR [here](https://github.com/DefiLlama/adapters)\n> - If you would like to add a `liquidations` adapter, please refer to [this readme document](https://github.com/DefiLlama/DefiLlama-Adapters/tree/main/liquidations) for details.\n\n1. PLEASE PLEASE **enable \"Allow edits by maintainers\" while putting up the PR.**\n2. Once your adapter has been merged, it takes time to show on the UI. No need to notify us on Discord.\n3. TVL must be computed from blockchain data (reason: https://github.com/DefiLlama/DefiLlama-Adapters/discussions/432), if you have trouble with creating the adapter, please hop onto our discord, we are happy to assist you.\n4. **For updating listing info** It is a different repo, you can find your listing in this file: https://github.com/DefiLlama/defillama-server/blob/master/defi/src/protocols/data2.ts, you can  edit it there and put up a PR\n5. Do not edit/push `package-lock.json` file as part of your changes, we use lockfileVersion 2, and most use v1 and using that messes up our CI\n6. No need to go to our discord and announce that you've created a PR, we monitor all PRs and will review it asap\n\n## Getting listed\n\nPlease send answers to questions there https://github.com/DefiLlama/DefiLlama-Adapters/blob/main/pull_request_template.md when creating a PR.\n\n## Work in progress\n\nThis is a work in progress. DefiLlama aims to be transparent, accurate, and open source.\n\nIf you have any suggestions, want to contribute or want to chat, please join [our discord](https://discord.defillama.com/) and drop a message.\n\n## Testing adapters\n```bash\nnode test.js projects/pangolin/index.js\n# Add a timestamp at the end to run the adapter at a historical timestamp\nnode test.js projects/aave/v3.js 1729080692\n# or using YYYY-MM-DD\nnode test.js projects/aave/v3.js 2024-10-16\n```\n\n## Changing RPC providers\nIf you want to change RPC providers because you need archive node access or because the default ones don't work well enough you can do so by creating an `.env` file and filling it with the env variables to overwrite:\n```\nETHEREUM_RPC=\"...\"\nBSC_RPC=\"...\"\nPOLYGON_RPC=\"...\"\n```\n\nThe name of each rpc is `{CHAIN-NAME}_RPC`, and the name we use for each chain can be found [here](https://unpkg.com/@defillama/sdk@latest/build/providers.json). If you run into issues with a chain make sure to update the sdk with `npm update @defillama/sdk`.\n\n## Adapter rules\n- Never add extra npm packages, if you need a chain-level package for your chain, ask us, and we'll consider it, but we can't accept any npm package that is project-specific\n",
      "stars_today": 0
    },
    {
      "id": 546522002,
      "name": "element-x-android",
      "full_name": "element-hq/element-x-android",
      "description": "Android Matrix messenger application using the Matrix Rust Sdk and Jetpack Compose",
      "html_url": "https://github.com/element-hq/element-x-android",
      "stars": 1770,
      "forks": 372,
      "language": "Kotlin",
      "topics": [
        "hacktoberfest",
        "matrix"
      ],
      "created_at": "2022-10-06T07:59:24Z",
      "updated_at": "2026-01-13T22:19:05Z",
      "pushed_at": "2026-01-13T17:19:09Z",
      "open_issues": 548,
      "owner": {
        "login": "element-hq",
        "avatar_url": "https://avatars.githubusercontent.com/u/13446337?v=4"
      },
      "readme": "[![Latest build](https://github.com/element-hq/element-x-android/actions/workflows/build.yml/badge.svg?query=branch%3Adevelop)](https://github.com/element-hq/element-x-android/actions/workflows/build.yml?query=branch%3Adevelop)\n[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=element-x-android&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=element-x-android)\n[![Vulnerabilities](https://sonarcloud.io/api/project_badges/measure?project=element-x-android&metric=vulnerabilities)](https://sonarcloud.io/summary/new_code?id=element-x-android)\n[![Bugs](https://sonarcloud.io/api/project_badges/measure?project=element-x-android&metric=bugs)](https://sonarcloud.io/summary/new_code?id=element-x-android)\n[![codecov](https://codecov.io/github/element-hq/element-x-android/branch/develop/graph/badge.svg?token=ecwvia7amV)](https://codecov.io/github/element-hq/element-x-android)\n[![Element X Android Matrix room #element-x-android:matrix.org](https://img.shields.io/matrix/element-x-android:matrix.org.svg?label=%23element-x-android:matrix.org&logo=matrix&server_fqdn=matrix.org)](https://matrix.to/#/#element-x-android:matrix.org)\n[![Localazy](https://img.shields.io/endpoint?url=https%3A%2F%2Fconnect.localazy.com%2Fstatus%2Felement%2Fdata%3Fcontent%3Dall%26title%3Dlocalazy%26logo%3Dtrue)](https://localazy.com/p/element)\n\n# Element X Android\n\nElement X Android is the next-generation [Matrix](https://matrix.org/) client provided by [Element](https://element.io/).\n\nCompared to the previous-generation [Element Classic](https://github.com/element-hq/element-android), the application is a total rewrite, using the [Matrix Rust SDK](https://github.com/matrix-org/matrix-rust-sdk) underneath and targeting devices running Android 7+. The UI layer is written using [Jetpack Compose](https://developer.android.com/jetpack/compose), and the navigation is managed using [Appyx](https://github.com/bumble-tech/appyx).\n\n[<img src=\"https://play.google.com/intl/en_us/badges/static/images/badges/en_badge_web_generic.png\" alt=\"Get it on Google Play\" height=\"80\">](https://play.google.com/store/apps/details?id=io.element.android.x)[<img src=\"https://fdroid.gitlab.io/artwork/badge/get-it-on.png\" alt=\"Get it on F-Droid\" height=\"80\">](https://f-droid.org/packages/io.element.android.x)\n\n## Table of contents\n\n<!--- TOC -->\n\n* [Screenshots](#screenshots)\n* [Translations](#translations)\n* [Rust SDK](#rust-sdk)\n* [Status](#status)\n* [Minimum SDK version](#minimum-sdk-version)\n* [Contributing](#contributing)\n* [Build instructions](#build-instructions)\n* [Support](#support)\n* [Copyright and License](#copyright-and-license)\n\n<!--- END -->\n\n## Screenshots\n\nHere are some screenshots of the application:\n\n<!--\nCommands run before taking the screenshots:\nadb shell settings put system time_12_24 24\nadb shell am broadcast -a com.android.systemui.demo -e command enter\nadb shell am broadcast -a com.android.systemui.demo -e command clock -e hhmm 1337\nadb shell am broadcast -a com.android.systemui.demo -e command network -e mobile show -e level 4\nadb shell am broadcast -a com.android.systemui.demo -e command network -e wifi show -e level 4\nadb shell am broadcast -a com.android.systemui.demo -e command notifications -e visible false\nadb shell am broadcast -a com.android.systemui.demo -e command battery -e plugged false -e level 100\n\nAnd to exit demo mode:\nadb shell am broadcast -a com.android.systemui.demo -e command exit\n-->\n\n|<img src=\"./docs/images-lfs/screen_1_light.png\" width=\"280\" />|<img src=\"./docs/images-lfs/screen_2_light.png\" width=\"280\" />|<img src=\"./docs/images-lfs/screen_3_light.png\" width=\"280\" />|<img src=\"./docs/images-lfs/screen_4_light.png\" width=\"280\" />|\n|-|-|-|-|\n|<img src=\"./docs/images-lfs/screen_1_dark.png\" width=\"280\" />|<img src=\"./docs/images-lfs/screen_2_dark.png\" width=\"280\" />|<img src=\"./docs/images-lfs/screen_3_dark.png\" width=\"280\" />|<img src=\"./docs/images-lfs/screen_4_dark.png\" width=\"280\" />|\n\n## Translations\n\nElement X Android supports many languages. You can help us to translate the app in your language by joining our [Localazy project](https://localazy.com/p/element). You can also help us to improve the existing translations.\n\nNote that for now, we keep control on the French and German translations.\n\nTranslations can be checked screen per screen using our tool Element X Android Gallery, available at https://element-hq.github.io/element-x-android/. Note that this page is updated every Tuesday.\n\nMore instructions about translating the application can be found at [CONTRIBUTING.md](CONTRIBUTING.md#strings).\n\n## Rust SDK\n\nElement X leverages the [Matrix Rust SDK](https://github.com/matrix-org/matrix-rust-sdk) through an FFI layer that the final client can directly import and use.\n\nWe're doing this as a way to share code between platforms and while we've seen promising results it's still in the experimental stage and bound to change.\n\n## Status\n\nThis project is actively developed and supported. New users are recommended to use Element X instead of the previous-generation app.\n\n## Minimum SDK version\n\nElement X Android requires a minimum SDK version of 24 (Android 7.0, Nougat). We aim to support devices running Android 7.0 and above, which covers a wide range of devices still in use today.\n\nElement Android Enterprise requires a minimum SDK version of 33 (Android 13, Tiramisu). For Element Enterprise, we support only devices that still receive security updates, which means devices running Android 13 and above. Android does not have a documented support policy, but some information can be found at [https://endoflife.date/android](https://endoflife.date/android).\n\n## Contributing\n\nWant to get actively involved in the project? You're more than welcome! A good way to start is to check the issues that are labelled with the [good first issue](https://github.com/element-hq/element-x-android/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) label. Let us know by commenting the issue that you're starting working on it.\n\nBut first make sure to read our [contribution guide](CONTRIBUTING.md) first.\n\nYou can also come chat with the community in the Matrix [room](https://matrix.to/#/#element-x-android:matrix.org) dedicated to the project.\n\n## Build instructions\n\nJust clone the project and open it in Android Studio. Make sure to select the\n`app` configuration when building (as we also have sample apps in the project).\n\nTo build against a local copy of the Rust SDK, see the [Developer\nonboarding](docs/_developer_onboarding.md#building-the-sdk-locally) instructions.\n\n## Support\n\nWhen you are experiencing an issue on Element X Android, please first search in [GitHub issues](https://github.com/element-hq/element-x-android/issues)\nand then in [#element-x-android:matrix.org](https://matrix.to/#/#element-x-android:matrix.org).\nIf after your research you still have a question, ask at [#element-x-android:matrix.org](https://matrix.to/#/#element-x-android:matrix.org). Otherwise feel free to create a GitHub issue if you encounter a bug or a crash, by explaining clearly in detail what happened. You can also perform bug reporting from the application settings. This is especially recommended when you encounter a crash.\n\n## Copyright and License\n\nCopyright (c) 2025 Element Creations Ltd.\nCopyright (c) 2022 - 2025 New Vector Ltd.\n\nThis software is dual licensed by Element Creations Ltd (Element). It can be used either:\n\n(1) for free under the terms of the GNU Affero General Public License (as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version); OR\n\n(2) under the terms of a paid-for Element Commercial License agreement between you and Element (the terms of which may vary depending on what you and Element have agreed to).\n\nUnless required by applicable law or agreed to in writing, software distributed under the Licenses is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the Licenses for the specific language governing permissions and limitations under the Licenses.\n",
      "stars_today": 0
    },
    {
      "id": 45709704,
      "name": "sf",
      "full_name": "r-spatial/sf",
      "description": "Simple Features for R",
      "html_url": "https://github.com/r-spatial/sf",
      "stars": 1415,
      "forks": 299,
      "language": "R",
      "topics": [
        "gdal",
        "geos",
        "proj",
        "r",
        "r-package",
        "rstats",
        "spatial"
      ],
      "created_at": "2015-11-06T21:49:34Z",
      "updated_at": "2026-01-13T08:11:35Z",
      "pushed_at": "2026-01-13T20:51:14Z",
      "open_issues": 73,
      "owner": {
        "login": "r-spatial",
        "avatar_url": "https://avatars.githubusercontent.com/u/25086656?v=4"
      },
      "readme": "<!-- badges: start -->\n[![R-CMD-check](https://github.com/r-spatial/sf/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/r-spatial/sf/actions/workflows/R-CMD-check.yaml)\n[![tic-db](https://github.com/r-spatial/sf/actions/workflows/tic-db.yml/badge.svg)](https://github.com/r-spatial/sf/actions/workflows/tic-db.yml)\n[![Coverage Status](https://img.shields.io/codecov/c/github/r-spatial/sf/main.svg)](https://app.codecov.io/gh/r-spatial/sf)\n[![License](http://img.shields.io/badge/license-GPL%20%28%3E=%202%29-brightgreen.svg?style=flat)](http://www.gnu.org/licenses/gpl-2.0.html)\n[![CRAN](https://www.r-pkg.org/badges/version/sf)](https://cran.r-project.org/package=sf)\n[![cran checks](https://badges.cranchecks.info/worst/sf.svg)](https://cran.r-project.org/web/checks/check_results_sf.html)\n[![Downloads](https://cranlogs.r-pkg.org/badges/sf?color=brightgreen)](https://www.r-pkg.org/pkg/sf)\n[![status](https://tinyverse.netlify.app/badge/sf)](https://CRAN.R-project.org/package=sf)\n<!-- badges: end -->\n\n# Simple Features for R\n\n<a href=\"https://gist.github.com/edzer/f461a3a95570c4ab7edf3125c2f19d20\"><img align=\"right\" src=\"https://user-images.githubusercontent.com/520851/34887433-ce1d130e-f7c6-11e7-83fc-d60ad4fae6bd.gif\" /></a>\n\nA package that provides [simple features access](https://en.wikipedia.org/wiki/Simple_Features) for R. \n\n[Blogs, links](#blogs-presentations-vignettes-sp-sf-wiki) ‚Ä¢ [Cheatsheet](#cheatsheet) ‚Ä¢ [Installing](#installing)\n‚Ä¢ [Contributing](#contributing) ‚Ä¢ [Acknowledgment](#acknowledgment) ‚Ä¢ [How to cite](#how-to-cite)\n\nPackage sf:\n\n* represents simple features as records in a `data.frame` or `tibble` with a geometry list-column\n* represents natively in R all 17 simple feature types for all dimensions (XY, XYZ, XYM, XYZM)\n* interfaces to [GEOS](https://libgeos.org) for geometrical operations on projected coordinates, and (through R package [s2](https://cran.r-project.org/package=s2)) to [s2geometry](http://s2geometry.io/) for geometrical operations on ellipsoidal coordinates\n* interfaces to [GDAL](https://gdal.org/), supporting all driver options, `Date` and `POSIXct` and list-columns\n* interfaces to [PR√òJ](http://proj.org/) for coordinate reference system conversion and transformation\n* uses [well-known-binary](https://en.wikipedia.org/wiki/Well-known_text#Well-known_binary) serialisations written in C++/Rcpp for fast I/O with GDAL and GEOS \n* reads from and writes to spatial databases such as [PostGIS](http://postgis.net/) using [DBI](https://cran.r-project.org/package=DBI)\n* is extended by \n    * [lwgeom](https://github.com/r-spatial/lwgeom/) for selected liblwgeom/PostGIS functions\n    * [stars](https://github.com/r-spatial/stars/) for raster data, and raster or vector data cubes (spatial time series)\n    * [sfnetworks](https://luukvdmeer.github.io/sfnetworks/) for geospatial network data\n\n<a href=\"https://gist.github.com/edzer/442d74a5775abcd5068cf3e73b23687b\"><img align=\"left\" src=\"https://user-images.githubusercontent.com/520851/50280460-e35c1880-044c-11e9-9ed7-cc46754e49db.jpg\" /></a>\n\n(Illustration (c) 2018 by <a href=\"https://twitter.com/allison_horst/status/1071456081308614656\">Allison Horst</a>)\n\n## Books, journal articles, blogs, presentations, vignettes, sp-sf wiki\n\n* an open access [R Journal article](https://journal.r-project.org/archive/2018/RJ-2018-009/index.html) summarizes the package\n* two books: [Spatial Data Science: with applications in R](https://r-spatial.org/book/), [Geocomputation with R](https://r.geocompx.org/)\n* package vignettes: [first](https://r-spatial.github.io/sf/articles/sf1.html), [second](https://r-spatial.github.io/sf/articles/sf2.html), [third](https://r-spatial.github.io/sf/articles/sf3.html), [fourth](https://r-spatial.github.io/sf/articles/sf4.html), [fifth](https://r-spatial.github.io/sf/articles/sf5.html), [sixth](https://r-spatial.github.io/sf/articles/sf6.html), [seventh](https://r-spatial.github.io/sf/articles/sf7.html)\n* blog posts: [first](https://r-spatial.org/r/2016/02/15/simple-features-for-r.html), [second](https://r-spatial.org/r/2016/07/18/sf2.html), [third](https://r-spatial.org/r/2016/11/02/sfcran.html), [fourth](https://r-spatial.org/r/2017/01/12/newssf.html)\n* the original R Consortium ISC [proposal](PROPOSAL.md), the R Consortium [blog post](https://www.r-consortium.org/blog/2017/01/03/simple-features-now-on-cran)\n* presentations: [rstudio::conf 2018](https://edzer.github.io/rstudio_conf/#1) ([video](https://posit.co/resources/videos/tidy-spatial-data-analysis/)), [UseR! 2016](http://pebesma.staff.ifgi.de/pebesma_sfr.pdf)\n* wiki page describing [sp-sf migration](https://github.com/r-spatial/sf/wiki/Migrating)\n\n## Cheatsheet\n[CC 4.0](https://creativecommons.org/licenses/by/4.0/) BY [Ryan Garnett](https://github.com/ryangarnett)  \n\n<a href=\"https://github.com/rstudio/cheatsheets/blob/main/sf.pdf\"><img src=\"https://raw.githubusercontent.com/rstudio/cheatsheets/main/pngs/sf.png\" /></a>\n\n## Installing\n\nInstall either from CRAN with:\n```r\ninstall.packages(\"sf\")\n```\nThis will install binary packages on Windows and MacOS, unless you configured R such that it tries to install source packages; in that case, see below.\n\nInstall development versions from GitHub with:\n```r\nlibrary(remotes)\ninstall_github(\"r-spatial/sf\")\n```\n\n### Windows\n\nInstalling sf from source works under Windows when [Rtools](https://cran.r-project.org/bin/windows/Rtools/) is installed.\n\n### MacOS\n\nMacOS users are strongly encouraged to install the `sf` binary packages from CRAN, unless they are familiar with compilers, linking, C++ source code, and homebrew. If you experience that R tries to install `sf` from source (or otherwise your install fails but you don't understand what is going on) try again by explicitly installing the binary, using\n\n```r\ninstall.packages(\"sf\", type = \"binary\")\n```\n\nThe remainder of this section is for those who understand what source installs mean, and imply.\n\nPerhaps the easiest way of an install from source is to first install `gdal` using Homebrew. Recent versions of Homebrew include a full-featured up-to-date [gdal formula](https://github.com/Homebrew/homebrew-core/blob/master/Formula/g/gdal.rb), which installs `proj` and `gdal` at the same time:\n\n```\nbrew install pkg-config\nbrew install gdal\n```\n\nOnce gdal is installed, you may be able to install `sf` package from source in R. With the current version of `proj` on homebrew, installation requires additional configuration:\n\n```r\ninstall.packages(\"sf\", type = \"source\", configure.args = \"--with-proj-lib=$(brew --prefix)/lib/\")\n```\n\nOr the development version:\n\n```r\nlibrary(remotes)\ninstall_github(\"r-spatial/sf\", configure.args = \"--with-proj-lib=$(brew --prefix)/lib/\")\n```\n\nAlternatively, [these instructions](https://stat.ethz.ch/pipermail/r-sig-mac/2017-June/012429.html) explain how to install gdal using kyngchaos frameworks.\n\nFor Mac OS 11 Big Sur source install instruction, see [here](https://github.com/r-spatial/sf/issues/1536#issuecomment-727342736)\n\n### Linux\n\nFor Unix-alikes, GDAL (>= 2.0.1), GEOS (>= 3.4.0) and Proj.4 (>= 4.8.0) are required.\n\n#### Ubuntu\n\nDependencies for recent versions of Ubuntu (18.04 and later) are available in the official repositories; you can install them with:\n\n```sh\nsudo apt -y update && apt install -y libudunits2-dev libgdal-dev libgeos-dev libproj-dev libsqlite3-dev\n```\n\nHowever, to get more up-to-date versions of dependencies such as GDAL, GEOS and PROJ we recommend adding the [ubuntugis-unstable](http://ppa.launchpad.net/ubuntugis/ubuntugis-unstable/ubuntu/) PPA to the package repositories and installing them as follows:\n\n```sh\nsudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable\nsudo apt update\nsudo apt install libudunits2-dev libgdal-dev libgeos-dev libproj-dev libsqlite3-dev\n```\n\nAdding this PPA is required for installing `sf` on older versions of Ubuntu (e.g. Xenial).\n\nAnother option, for advanced users, is to install dependencies from source; see e.g. an older [Travis](https://github.com/r-spatial/sf/blob/593ee48b34001fe3b383ea73ea57063ecf690732/.travis.yml) config file for hints.\n\n#### Fedora\nThe following command installs all required dependencies:\n```sh\nsudo dnf install gdal-devel proj-devel geos-devel sqlite-devel udunits2-devel\n```\n\n#### Arch\n\nGet gdal, proj, geos and podofo from the main repos, and udunits from the AUR:\n\n```\npacman -S gdal proj geos arrow podofo\nyay/pacaur/yaourt/whatever -S udunits\n```\n\n#### `renv` or `conda`\n\nThere are several reports that `sf` fails to install as a source package when R is used with `renv`, or when R is installed in a `conda` environment. If you experience this, please do not raise an issue here, but \n\n* try to sort this out with the `renv` developers or the `conda` maintainers, or\n* try to use binary installs of the `sf` package, e.g. from [r2u](https://github.com/eddelbuettel/r2u), or the Posit package manager\n\n#### Other\n\nTo install on Debian, the [rocker geospatial](https://github.com/rocker-org/geospatial) Dockerfiles may be helpful. Ubuntu Dockerfiles are found [here](https://github.com/r-spatial/sf/tree/main/inst/docker).\n\n### Multiple GDAL, GEOS and/or PROJ versions on your system\n\nIf you use dynamic linking (installation from source) and have multiple versions of these libraries installed (e.g. one from ubuntugis-unstable, another installed from source in `/usr/local/lib`) then this will in general not work, even when setting `LD_LIBRARY_PATH` manually. See [here](https://github.com/r-spatial/sf/issues/844) for the reason why. \n\n### lwgeom\n\nFunctions and methods that require `liblwgeom`, including ellipsoidal (not spherical or Euclidean) metrics (area, distances), are provide by and used from [lwgeom](https://github.com/r-spatial/lwgeom), which is also on [CRAN](https://cran.r-project.org/package=lwgeom).\n\n## Contributing\n\n* Contributions of all sorts are most welcome, issues and pull requests are the preferred ways of sharing them.\n* When contributing pull requests, please adhere to the package style (in package code use `=` rather than `<-`; don't change indentation; tab stops of 4 spaces are preferred).\n* This project is released with a [Contributor Code of Conduct](CONDUCT.md). By participating in this project, you agree to abide by its terms.\n\n## How to cite\n\nPackage `sf` can be cited as: \n\n* Edzer Pebesma, 2018.  Simple Features for R: Standardized Support\nfor Spatial Vector Data. The R Journal [10:1, 439-446.](https://journal.r-project.org/archive/2018/RJ-2018-009/index.html)\n\n* Pebesma, E.; Bivand, R. (2023). [Spatial Data Science: With Applications in R](https://r-spatial.org/book/) \n(1st ed.). 314 pages. [Chapman and Hall/CRC](https://doi.org/10.1201/9780429459016).\n\n## Acknowledgment\n\nThis project gratefully acknowledges financial [support](https://www.r-consortium.org/projects) from the\n\n<a href=\"https://r-consortium.org/all-projects/2016-group-1.html#simple-features-for-r\">\n<img src=\"https://r-consortium.org/images/RConsortium_Horizontal_Pantone.webp\" width=\"300\">\n</a>\n<!--\n<img src=\"http://pebesma.staff.ifgi.de/RConsortium_Horizontal_Pantone.png\" width=\"300\">\n-->\n\n",
      "stars_today": 0
    },
    {
      "id": 30017750,
      "name": "ComplexHeatmap",
      "full_name": "jokergoo/ComplexHeatmap",
      "description": "Make Complex Heatmaps ",
      "html_url": "https://github.com/jokergoo/ComplexHeatmap",
      "stars": 1457,
      "forks": 243,
      "language": "R",
      "topics": [
        "clustering",
        "complex-heatmaps",
        "heatmap"
      ],
      "created_at": "2015-01-29T11:45:58Z",
      "updated_at": "2026-01-08T05:16:59Z",
      "pushed_at": "2025-06-23T15:51:50Z",
      "open_issues": 227,
      "owner": {
        "login": "jokergoo",
        "avatar_url": "https://avatars.githubusercontent.com/u/449218?v=4"
      },
      "readme": "# Make Complex Heatmaps <a href=\"https://jokergoo.github.io/ComplexHeatmap-reference/book/\"><img src=\"https://jokergoo.github.io/ComplexHeatmap-reference/book/complexheatmap-cover.jpg\" width=240 align=\"right\" style=\"border:2px solid black;\" ></a>\n\n[![R-CMD-check](https://github.com/jokergoo/ComplexHeatmap/workflows/R-CMD-check/badge.svg)](https://github.com/jokergoo/ComplexHeatmap/actions)\n[![codecov](https://img.shields.io/codecov/c/github/jokergoo/ComplexHeatmap.svg)](https://codecov.io/github/jokergoo/ComplexHeatmap) \n[![bioc](http://www.bioconductor.org/shields/downloads/devel/ComplexHeatmap.svg)](https://bioconductor.org/packages/stats/bioc/ComplexHeatmap/) \n[![bioc](http://www.bioconductor.org/shields/years-in-bioc/ComplexHeatmap.svg)](http://bioconductor.org/packages/devel/bioc/html/ComplexHeatmap.html)\n\n<img src=\"http://jokergoo.github.io/complexheatmap_logo.svg\" width=\"550\">\n\n\nComplex heatmaps are efficient to visualize associations between different\nsources of data sets and reveal potential patterns. Here the\n**ComplexHeatmap** package provides a highly flexible way to arrange multiple\nheatmaps and supports various annotation graphics.\n\nThe [**InteractiveComplexHeatmap**](https://github.com/jokergoo/InteractiveComplexHeatmap) package can directly export static complex heatmaps into an interactive Shiny app. Have a try!\n\n## Citation\n\nZuguang Gu, et al., [Complex heatmaps reveal patterns and correlations in multidimensional genomic data](http://bioinformatics.oxfordjournals.org/content/early/2016/05/20/bioinformatics.btw313.abstract), Bioinformatics, 2016.\n\nZuguang Gu. [Complex Heatmap Visualization](https://doi.org/10.1002/imt2.43), iMeta, 2022. \n\n\n## Install\n\n`ComplexHeatmap` is available on [Bioconductor](http://www.bioconductor.org/packages/devel/bioc/html/ComplexHeatmap.html), you can install it by:\n\n```r\nif (!requireNamespace(\"BiocManager\", quietly=TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"ComplexHeatmap\")\n```\n\nIf you want the latest version, install it directly from GitHub:\n\n```r\nlibrary(devtools)\ninstall_github(\"jokergoo/ComplexHeatmap\")\n```\n\n## Usage\n\nMake a single heatmap:\n\n```r\nHeatmap(mat, ...)\n```\n\nA single Heatmap with column annotations:\n\n```r\nha = HeatmapAnnotation(df = anno1, anno_fun = anno2, ...)\nHeatmap(mat, ..., top_annotation = ha)\n```\n\nMake a list of heatmaps:\n\n```r\nHeatmap(mat1, ...) + Heatmap(mat2, ...)\n```\n\nMake a list of heatmaps and row annotations:\n\n```r\nha = HeatmapAnnotation(df = anno1, anno_fun = anno2, ..., which = \"row\")\nHeatmap(mat1, ...) + Heatmap(mat2, ...) + ha\n```\n\n## Documentation\n\nThe full documentations are available at https://jokergoo.github.io/ComplexHeatmap-reference/book/ and the website is at https://jokergoo.github.io/ComplexHeatmap.\n\n## Blog posts\n\nThere are following blog posts focusing on specific topics:\n\n- [Make 3D heatmap](https://jokergoo.github.io/2021/03/24/3d-heatmap/)\n- [Translate from pheatmap to ComplexHeatmap](https://jokergoo.github.io/2020/05/06/translate-from-pheatmap-to-complexheatmap/)\n- [Set cell width/height in the heatmap](https://jokergoo.github.io/2020/05/11/set-cell-width/height-in-the-heatmap/)\n- [Interactive ComplexHeatmap](https://jokergoo.github.io/2020/05/15/interactive-complexheatmap/)\n- [Word cloud as heatmap annotation](https://jokergoo.github.io/2020/05/31/word-cloud-as-heatmap-annotation/)\n- [Which heatmap function is faster?](https://jokergoo.github.io/2020/06/19/which-heatmap-function-is-faster/)\n- [Rasterization in ComplexHeatmap](https://jokergoo.github.io/2020/06/30/rasterization-in-complexheatmap/)\n- [Block annotation over several slices](https://jokergoo.github.io/2020/07/06/block-annotation-over-several-slices/)\n- [Integrate ComplexHeatmap with cowplot package](https://jokergoo.github.io/2020/07/14/integrate-complexheatmap-with-cowplot-package/)\n\n\n## Examples\n\n### Visualize Methylation Profile with Complex Annotations\n\n![complexheatmap_example4](https://user-images.githubusercontent.com/449218/47718635-2ec22980-dc49-11e8-9f01-37becb19e0d5.png)\n\n### Correlations between methylation, expression and other genomic features\n\n![complexheatmap_example3](https://user-images.githubusercontent.com/449218/47718636-2ec22980-dc49-11e8-8db0-1659c27dcf40.png)\n\n### Visualize Cell Heterogeneity from Single Cell RNASeq\n\n![complexheatmap_example2](https://user-images.githubusercontent.com/449218/47718637-2ec22980-dc49-11e8-925e-955c16cfa982.png)\n\n### Making Enhanced OncoPrint\n\n![complexheatmap_example1](https://user-images.githubusercontent.com/449218/47718638-2ec22980-dc49-11e8-845e-21e51d3b8e73.png)\n\n### UpSet plot\n\n<img src=\"https://user-images.githubusercontent.com/449218/102615477-48c76a80-4136-11eb-98d9-3c528844fbe8.png\" width=500 />\n\n### 3D heatmap\n\n![image](https://user-images.githubusercontent.com/449218/112284448-8c77c600-8c89-11eb-8d38-c5538900df20.png)\n\n\n\n## License\n\nMIT @ Zuguang Gu\n\n",
      "stars_today": 0
    },
    {
      "id": 159560389,
      "name": "renv",
      "full_name": "rstudio/renv",
      "description": "renv: Project environments for R.",
      "html_url": "https://github.com/rstudio/renv",
      "stars": 1122,
      "forks": 162,
      "language": "R",
      "topics": [],
      "created_at": "2018-11-28T20:25:39Z",
      "updated_at": "2026-01-10T14:35:21Z",
      "pushed_at": "2026-01-06T17:48:32Z",
      "open_issues": 211,
      "owner": {
        "login": "rstudio",
        "avatar_url": "https://avatars.githubusercontent.com/u/513560?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# renv <img src=\"man/figures/logo.svg\" align=\"right\" height=\"115\"/>\n\n<!-- badges: start -->\n\n[![Lifecycle:\nstable](https://img.shields.io/badge/lifecycle-stable-brightgreen.svg)](https://lifecycle.r-lib.org/articles/stages.html)\n[![CRAN\nstatus](https://www.r-pkg.org/badges/version/renv)](https://CRAN.R-project.org/package=renv)\n[![R-CMD-check](https://github.com/rstudio/renv/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/rstudio/renv/actions/workflows/R-CMD-check.yaml)\n\n<!-- badges: end -->\n\n## Overview\n\nThe renv package[^1] helps you create **r**eproducible **env**ironments\nfor your R projects. Use renv to make your R projects more isolated,\nportable and reproducible.\n\n- **Isolated**: Installing a new or updated package for one project\n  won‚Äôt break your other projects, and vice versa. That‚Äôs because renv\n  gives each project its own private library.\n- **Portable**: Easily transport your projects from one computer to\n  another, even across different platforms. renv makes it easy to\n  install the packages your project depends on.\n- **Reproducible**: renv records the exact package versions you depend\n  on, and ensures those exact versions are the ones that get installed\n  wherever you go.\n\n## Installation\n\nInstall the latest version of renv from CRAN with:\n\n``` r\ninstall.packages(\"renv\")\n```\n\nAlternatively, install the development version from\n[r-universe](https://rstudio.r-universe.dev/renv) with:\n\n``` r\ninstall.packages(\"renv\", repos = \"https://rstudio.r-universe.dev\")\n```\n\n## Workflow\n\n<img src=\"vignettes/renv.png\" alt=\"A diagram showing the most important verbs and nouns of renv. Projects start with init(), which creates a project library using packages from the system library. snapshot() updates the lockfile using the packages installed in the project library, where restore() installs packages into the project library using the metadata from the lockfile, and status() compares the lockfile to the project library. You install and update packages from CRAN and GitHub using install() and update(), but because you'll need to do this for multiple projects, renv uses cache to make this fast.\" width=\"408\" style=\"display: block; margin: auto;\" />\n\nUse `renv::init()` to initialize renv in a new or existing project. This\nwill set up a **project library**, containing all the packages you‚Äôre\ncurrently using. The packages (and all the metadata needed to reinstall\nthem) are recorded into a **lockfile**, `renv.lock`, and a `.Rprofile`\nensures that the library is used every time you open that project.\n\nAs you continue to work on your project, you will install and upgrade\npackages, either using `install.packages()` and `update.packages()` or\n`renv::install()` and `renv::update()`. After you‚Äôve confirmed your code\nworks as expected, use `renv::snapshot()` to record the packages and\ntheir sources in the lockfile.\n\nLater, if you need to share your code with someone else or run your code\non new machine, your collaborator (or you) can call `renv::restore()` to\nreinstall the specific package versions recorded in the lockfile.\n\n## Learning more\n\nIf this is your first time using renv, we strongly recommend starting\nwith the [Introduction to\nrenv](https://rstudio.github.io/renv/articles/renv.html) vignette: this\nwill help you understand the most important verbs and nouns of renv.\n\nIf you have a question about renv, please first check the\n[FAQ](https://rstudio.github.io/renv/articles/faq.html) to see whether\nyour question has already been addressed. If it hasn‚Äôt, please feel free\nto ask on the [Posit Forum](https://forum.posit.co).\n\nIf you believe you‚Äôve found a bug in renv, please file a bug (and, if\npossible, a [reproducible example](https://reprex.tidyverse.org)) at\n<https://github.com/rstudio/renv/issues>.\n\n[^1]: Pronounced ‚ÄúR‚Äù ‚Äúenv‚Äù\n",
      "stars_today": 0
    },
    {
      "id": 259225467,
      "name": "CellChat",
      "full_name": "sqjin/CellChat",
      "description": "R toolkit for inference, visualization and analysis of cell-cell communication from single-cell data",
      "html_url": "https://github.com/sqjin/CellChat",
      "stars": 756,
      "forks": 167,
      "language": "R",
      "topics": [
        "cell-cell-communication",
        "cell-cell-interaction",
        "microenvironment",
        "single-cell-analysis"
      ],
      "created_at": "2020-04-27T06:28:33Z",
      "updated_at": "2026-01-11T17:20:28Z",
      "pushed_at": "2024-01-06T18:23:14Z",
      "open_issues": 455,
      "owner": {
        "login": "sqjin",
        "avatar_url": "https://avatars.githubusercontent.com/u/32399212?v=4"
      },
      "readme": "\n<p align=\"center\">\n  <img width=\"200\"  src=\"https://github.com/sqjin/CellChat/blob/master/CellChat_Logo.png\">\n</p>\n\n# CAUTION\nWe have updated CellChat to v2 and migrated CellChat to a new repository. This repository will be NOT updated and maintained any more. Please check the new repository [jinworks/CellChat](https://github.com/jinworks/CellChat) for the new updates, and the [CellChat v2 paper](https://biorxiv.org/cgi/content/short/2023.11.05.565674v1) for a comprehensive protocol of CellChat.  \n\n# About CellChat and CellChatDB\nCellChat is an R package designed for inference, analysis, and visualization of cell-cell communication from single-cell data. CellChat aims to enable users to identify and interpret cell-cell communication within an easily interpretable framework, with the emphasis of clear, attractive, and interpretable visualizations.  \n\nCellChatDB is a manually curated database of literature-supported ligand-receptor interactions in mutiple species, leading to a comprehensive recapitulation of known molecular interaction mechanisms including multi-subunit structure of ligand-receptor complexes and co-factors.\n\nIf you use CellChat in your research, please considering citing our papers: \n- [Suoqin Jin et al., CellChat for systematic analysis of cell-cell communication from single-cell and spatially resolved transcriptomics, bioRxiv 2023](https://biorxiv.org/cgi/content/short/2023.11.05.565674v1) [CellChat v2]\n- [Suoqin Jin et al., Inference and analysis of cell-cell communication using CellChat, Nature Communications 2021](https://www.nature.com/articles/s41467-021-21246-9) [CellChat v1]\n\n# Capabilities\nIn addition to infer the intercellular communication from any given single-cell data, CellChat provides functionality for further data exploration, analysis, and visualization. \n\n- It can quantitatively characterize and compare the inferred cell-cell communication networks using a systems approach by combining social network analysis, pattern recognition, and manifold learning approaches.\n- It provides an easy-to-use tool for extracting and visualizing high-order information of the inferred networks. For example, it allows ready prediction of major signaling inputs and outputs for all cell populations and how these populations and signals coordinate together for functions.\n- It enables comparative analysis of cell-cell communication across different conditions and identification of altered signaling and cell populations. \n- It provides several visualization outputs to facilitate intuitive user-guided data interpretation.\n\n<p align=\"center\">\n  <img width=\"700\"  src=\"https://github.com/sqjin/CellChat/blob/master/overview_CellChat.png\">\n</p>\n\n\n<p align=\"center\">\n  <a href=\"https://clustrmaps.com/site/1bpq2\">\n     <img width=\"200\"  src=\"https://clustrmaps.com/map_v2.png?cl=ffffff&w=a&t=n&d=42WqeykSXznN_NSaBlpf6CtSXQxhqmIs6QusUsguFdY\" />\n   </a>\n</p>\n<p align=\"center\">\n  <a href=\"#\">\n     <img src=\"https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fsqjin%2FCellChat&labelColor=%233499cc&countColor=%2370c168\" />\n   </a>\n</p>\n\n\n\n\n\n",
      "stars_today": 0
    },
    {
      "id": 53894616,
      "name": "infercnv",
      "full_name": "broadinstitute/infercnv",
      "description": "Inferring CNV from Single-Cell RNA-Seq",
      "html_url": "https://github.com/broadinstitute/infercnv",
      "stars": 648,
      "forks": 177,
      "language": "R",
      "topics": [],
      "created_at": "2016-03-14T21:53:54Z",
      "updated_at": "2026-01-12T23:27:31Z",
      "pushed_at": "2025-11-14T17:35:17Z",
      "open_issues": 236,
      "owner": {
        "login": "broadinstitute",
        "avatar_url": "https://avatars.githubusercontent.com/u/393552?v=4"
      },
      "readme": "\n***********************************************\n>InferCNV is no longer supported. Please explore alternatives such as InferCNA (https://jlaffy.github.io/infercna/)[https://jlaffy.github.io/infercna/], CopyKAT (https://github.com/navinlabcode/copykat)[https://github.com/navinlabcode/copykat], and Numbat (https://github.com/kharchenkolab/numbat)[https://github.com/kharchenkolab/numbat]\n***********************************************\n\n# Subclustering\n\nSubclustering resolution is one of the primary settings that will need to be adjusted in most runs to avoid oversplitting. The tutorial below explains how it works and details about it can also be found on the [wiki](https://github.com/broadinstitute/infercnv/wiki/infercnv-tumor-subclusters#tumor-subclustering-by-leiden-clustering-preferred).\n\n# Documentation\n### Full documentation\n\nVisit project [wiki](https://github.com/broadinstitute/inferCNV/wiki) for InferCNV documentation.\n\n\n### Infercnv video tutorial\n\nA **video** tutorial giving on overview of infercnv features and how to run an analysis can be found below **(click on the image)**:\n\n[![Tutorial: Running infercnv](http://img.youtube.com/vi/-qOcHAavZT8/0.jpg)](http://www.youtube.com/watch?v=-qOcHAavZT8 \"Tutorial: Running infercnv\")\n\n\n\n",
      "stars_today": 0
    },
    {
      "id": 28114218,
      "name": "dada2",
      "full_name": "benjjneb/dada2",
      "description": "Accurate sample inference from amplicon data with single nucleotide resolution",
      "html_url": "https://github.com/benjjneb/dada2",
      "stars": 532,
      "forks": 162,
      "language": "R",
      "topics": [
        "amplicon",
        "bioconductor",
        "bioinformatics",
        "metabarcoding",
        "metagenomics",
        "microbiome",
        "taxonomy"
      ],
      "created_at": "2014-12-17T00:53:58Z",
      "updated_at": "2026-01-07T21:19:32Z",
      "pushed_at": "2025-12-15T19:22:15Z",
      "open_issues": 193,
      "owner": {
        "login": "benjjneb",
        "avatar_url": "https://avatars.githubusercontent.com/u/5797204?v=4"
      },
      "readme": "\n[![Build Status](https://app.travis-ci.com/benjjneb/dada2.svg?branch=master)](https://app.travis-ci.com/benjjneb/dada2)\n\n# dada2\n\nExact sample inference from high-throughput amplicon data. Resolves real variants differing by as little as one nucleotide. Visit [the DADA2 website](https://benjjneb.github.io/dada2/index.html) for the most detailed and up-to-date documentation.\n\n### Installation\n\nThe dada2 package binaries are available through Bioconductor:\n\n```S\n## try http:// if https:// URLs are not supported\nif (!requireNamespace(\"BiocManager\", quietly=TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"dada2\")\n```\n\nIn order to install dada2 from source (and get the latest and greatest new features) see our [installation from source instructions](https://benjjneb.github.io/dada2/dada-installation.html).\n\n### Documentation\n\nThe [tutorial walkthrough of the DADA2 pipeline on paired end Illumina Miseq data](https://benjjneb.github.io/dada2/tutorial.html). \n\nThe [dada2 R package manual](https://www.bioconductor.org/packages/3.6/bioc/manuals/dada2/man/dada2.pdf).\n\nFurther documentation is available on [the DADA2 front page](http://benjjneb.github.io/dada2/). \n\n### DADA2 Articles\n\n[DADA2: High resolution sample inference from Illumina amplicon data. Nature Methods, 2016.](http://dx.doi.org/10.1038/nmeth.3869) [(Open Access link.)](http://rdcu.be/ipGh)\n\n[Bioconductor workflow for microbiome data analysis: from raw reads to community analyses. F1000 Research, 2016.](https://f1000research.com/articles/5-1492)\n\n[Exact sequence variants should replace operational taxonomic units in marker-gene data analysis. ISMEJ, 2017.](http://dx.doi.org/10.1038/ismej.2017.119)\n\n[High-throughput amplicon sequencing of the full-length 16S rRNA gene with single-nucleotide resolution. Nucleic Acids Research, 2019.](http://dx.doi.org/10.1093/nar/gkz569)\n\n### Other Resources\n\nPlanned feature improvements are publicly catalogued at the main DADA2 development site on github, specifically on the \"Issues\" page for DADA2:\n\nhttps://github.com/benjjneb/dada2/issues\n\nIf the feature you are hoping for is not listed, you are welcome to add it as a feature request \"issue\" on this page. This request will be publicly available and listed on the page.\n\nBugs and difficulties in using DADA2 are also welcome on [the issue tracker](https://github.com/benjjneb/dada2/issues).\n",
      "stars_today": 0
    },
    {
      "id": 138660553,
      "name": "DoubletFinder",
      "full_name": "chris-mcginnis-ucsf/DoubletFinder",
      "description": "R package for detecting doublets in single-cell RNA sequencing data",
      "html_url": "https://github.com/chris-mcginnis-ucsf/DoubletFinder",
      "stars": 517,
      "forks": 123,
      "language": "R",
      "topics": [],
      "created_at": "2018-06-25T23:32:45Z",
      "updated_at": "2026-01-10T20:29:11Z",
      "pushed_at": "2025-03-21T11:20:52Z",
      "open_issues": 23,
      "owner": {
        "login": "chris-mcginnis-ucsf",
        "avatar_url": "https://avatars.githubusercontent.com/u/40582930?v=4"
      },
      "readme": "~~ Announcement (11/24/21) ~~\nI'm now a postdoc at Stanford and my UCSF email will be decommissioned soon. I also only check my github repos about once per month, so please reach out directly at cmcginni@stanford[dot]edu if you run into any issues. \n\n# DoubletFinder\n\nDoubletFinder is an R package that predicts doublets in single-cell RNA sequencing data. \n\nDoubletFinder is implemented to interface with Seurat >= 2.0 (https://satijalab.org/seurat/) \n\nDoubletFinder was published by Cell Systems in April, 2019: https://www.cell.com/cell-systems/fulltext/S2405-4712(19)30073-0\n\n## Updates\n\n(02/02/2025) Haibo Liu (Senior Bioinformatician at UMass, @haibol2016) added as maintainer after his much-needed improvement updates to the package.\n\n(11/21/2023) Made compatible with Seurat v5 and removed '_v3' flag from relevant function names.\n\n(03/31/2020) Internalized functions normally in 'modes' package to enable compatibility with R v3.6 and highger.\n\n(06/21/2019) Added parallelization to paramSweep_v3 (thanks NathanSkeen!) -- Note: progress no longer updated, but the process is much faster! Fixed bug with smaller datasets. Updated readme.\n\n(04/12/2019) Added SCTransform compatibilities to 'paramSweep_v3' and 'doubletFinder_v3'\n\n(04/08/2019) Added 'PCs' argument to 'doubletFinder', 'doubletFinder_v3', 'paramSweep', and 'paramSweep_v3' to avoid conflicts with dimension reduction preferences. Updated readme.\n\n(01/12/2019) Seurat V3 compatibility: 'doubletFinder_v3' and 'paramSweep_v3' functions added, other functions for parameter estimation remain compatible.  \n\n## DoubletFinder V2.0 (11/28/2018) \n\nNew Features:\n1. Increased computational efficiency during pANN computation\n2. Implemented strategy for determining optimal pK values for any scRNA-seq data using pN-pK parameter sweeps and mean-variance-normalized bimodality coefficient (BCmvn)\n3. Included vignette describing 'best-practices' for applying DoubletFinder to scRNA-seq data generated without sample multiplexing\n\n## Installation (in R/RStudio)\n\n```{r}\nremotes::install_github('chris-mcginnis-ucsf/DoubletFinder', force = TRUE)\n```\n\n## Dependencies\n\nDoubletFinder requires the following R packages: \n* Seurat (>= 2.0) \n* Matrix (1.2.14) \n* fields (9.6) \n* KernSmooth (2.23-15)\n* ROCR (1.0-7)\n* parallel (3.5.1)\n* NOTE: These package versions were used in the bioRxiv paper, but other versions may work, as well.\n\n## Frequently Asked Questions\n\nQuestion: What is my anticipated doublet rate? \nAnswer: This is dependent on your platform (10x, parse, etc.) and will vary with the number of input cells. It will not always be 7.5% as is used in the tutorial. This information is available in the user guides for each technology. See https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/76 and https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/156\n\nQuestion: Can I run DoubletFinder on merged data from multiple 10x lanes?\nAnswer: Technically yes but I would only do this if you were splitting the same sample across multiple lanes. You want to avoid instances where DoubletFinder is attempting to find doublets that do not actually exist in the data. I would also not advise running DF on integrated Seurat objects. See https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/101 \n\nQuestion: I see multiple potential pK values when visualizing BCmvn -- what should I do?\nAnswer: I would spot check the results in GEX space to see what makes the most sense given your understanding of the data. See https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/62 and https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/40\n\n# DoubletFinder Overview\n\nDoubletFinder can be broken up into 4 steps:\n\n(1) Generate artificial doublets from existing scRNA-seq data \n\n(2) Pre-process merged real-artificial data\n\n(3) Perform PCA and use the PC distance matrix to find each cell's proportion of artificial k nearest neighbors (pANN)\n\n(4) Rank order and threshold pANN values according to the expected number of doublets\n\n![alternativetext](DF.screenshots/DoubletFinderOverview.png)\n\nDoubletFinder takes the following arguments:\n\nseu ~ This is a fully-processed Seurat object (i.e., after NormalizeData, FindVariableGenes, ScaleData, RunPCA, and RunTSNE have all been run).\n\nPCs ~ The number of statistically-significant principal components, specified as a range (e.g., PCs = 1:10)\n\npN ~ This defines the number of generated artificial doublets, expressed as a proportion of the merged real-artificial data. Default is set to 25%, based on observation that DoubletFinder performance is largely pN-invariant (see McGinnis, Murrow and Gartner 2019, Cell Systems).\n\npK ~ This defines the PC neighborhood size used to compute pANN, expressed as a proportion of the merged real-artificial data. No default is set, as pK should be adjusted for each scRNA-seq dataset. Optimal pK values should be estimated using the strategy described below.\n\nnExp ~ This defines the pANN threshold used to make final doublet/singlet predictions. This value can best be estimated from cell loading densities into the 10X/Drop-Seq device, and adjusted according to the estimated proportion of homotypic doublets.\n\n## Application to Cell Hashing and Demuxlet data\n\nDoubletFinder successfully recapitulates ground-truth doublet classifications determined using antibody-barcode sample multiplexing (Cell Hashing) and SNP deconvolution (Demuxlet). DoubletFinder identifies false-negative Demuxlet classifications caused by doublets formed from cells with identical SNP profiles. DoubletFinder is insensitive to homotypic doublets -- i.e., doublets dervied from transcriptionally-similar cell states. \n\n![alternativetext](DF.screenshots/Results_Demux.png)\n![alternativetext](DF.screenshots/Results_Hashing.png)\n\n# 'Best-Practices' for scRNA-seq data generated without sample multiplexing\n\n## Input scRNA-seq Data\n\n* Do not apply DoubletFinder to aggregated scRNA-seq data representing multiple *distinct* samples (e.g., multiple 10X lanes). For example, if you run DoubletFinder on aggregated data representing WT and mutant cell lines sequenced across different 10X lanes, artificial doublets will be generated from WT and mutant cells, which cannot exist in your data. These artificial doublets will skew results. Notably, it is okay to run DoubletFinder on data generated by splitting a single sample across multiple 10X lanes. \n\n* Ensure that input data is cleared of low-quality cell clusters. There are a variety of ways to do this, but I usually use the following workflow:\n1. Manually threshold raw gene expression matrices according to RNA nUMIs (especially important when dealing with super-loaded 10X data because of the way CellRanger threholds data -- See Lun et al., 2019, Genome Biology.\n2. Pre-process data using standard workflow.\n3. Identify clusters with (A) low RNA UMIs, (B) High % mitochondrial reads, and/or (C) Uninformative marker genes.\n4. Remove clusters, pre-process again, and run DoubletFinder.\n\n## pK Selection\n\nROC analysis across pN-pK parameter sweeps for Cell Hashing and Demuxlet datasets demonstrate that DoubletFinder performance is largely invariant of pN value selection:\n\n![alternativetext](DF.screenshots/ParamSweep_Schematic.png)\n![alternativetext](DF.screenshots/ParamSweep_HeatMap.png)\n\nROC analysis across pN-pK parameter sweeps for simulated scRNA-seq data with (I) Variable numbers of cell states and (II) Variable magnitudes of transcriptional heterogeneity demonstrates that (I) Optimal pK value selection depends on the total number of cell states and (II) DoubletFinder performance suffers when applied to transcriptionally-homogenous data. Simulated data was generated using a strategy similar to as described in Wolock, Lopex & Klein 2019, Cell Systems.\n\n![alternativetext](DF.screenshots/Simulation_Schematic.png)\n![alternativetext](DF.screenshots/Results_Simulation.png)\n\nSimulated and sample-multiplexed data are unique in that ground-truth doublet classifications can be leveraged to characterize how DoubletFinder parameters must be 'fit' to distinct scRNA-seq datasets. However, doublets remain unknown in real-world contexts -- which is likely why you are interested in DoubletFinder, at all!\n\nTo maximize the accuracy of DoubletFinder predictions, we sought a ground-truth-agnostic metric that coincides with pK values that maximize AUC in Cell Hashing and Demuxlet data. Mean-variance normalized bimodality coefficient (BCmvn) achieves this goal, featuring a single, easily-discernible maximum at pK values that optimize AUC. \n\n![alternativetext](DF.screenshots/BCmvn.png)\n\nBCmvn distributions also feature a single maximum for scRNA-seq datasets generated without sample-multiplexing (e.g., Mouse pancreas, Byrnes et al., 2018, Nature Communcations; Mouse kidney, Park et al., 2018, Science), enabling pK selection.\n\n## Doublet Number Estimation\n\nDoubletFinder is sensitive to heterotypic doublets -- i.e., doublets formed from transcriptionally-distinct cell states -- but is insensitive to homotypic doublets -- i.e., doublets formed from transcriptionally-similar cell states. In our original manuscript, we suggested using DoubletFinder to predict the number of doublets expected from Poisson statistical estimates realting to the droplet microfluidics cell loading density. However, Poisson estimates are agnostic of homotypic doublets, and will thus invariably overestimate the number of *detectable* doublets.\n\nTo address this issue, we suggest users utilize literature-supported cell type annotations to model the proportion of homotypic doublets present in their data. As an example, we present an analysis of mouse kidney scRNA-seq data (Park et al., 2018, Science):\n\n![alternativetext](DF.screenshots/HomotypicAdjustment.png)\n\nNotably, it is conceivable that literature-suppoted cell type annotations may not accurately recapitulate the magnitude of transcriptional divergence necessary for DoubletFinder sensitivity. For example, nominally-homogenous cells (e.g., CD4+ T-cells) may exist along a spectrum of gene expression states (e.g., distinct anatomical locations, disease states, naive/Tregs/Th17 cells, etc.), and doublets formed by cell sub-types may be detectable by DoubletFinder. Thus, we consider doublet number estimates based on Poisson statistics with and without homotypic doublet proportion adjustment to 'bookend' the real detectable doublet rate. \n\n## Example code for 'real-world' applications\n\n```R\n## Pre-process Seurat object (standard) --------------------------------------------------------------------------------------\nseu_kidney <- CreateSeuratObject(kidney.data)\nseu_kidney <- NormalizeData(seu_kidney)\nseu_kidney <- FindVariableFeatures(seu_kidney, selection.method = \"vst\", nfeatures = 2000)\nseu_kidney <- ScaleData(seu_kidney)\nseu_kidney <- RunPCA(seu_kidney)\nseu_kidney <- RunUMAP(seu_kidney, dims = 1:10)\n\n## Pre-process Seurat object (sctransform) -----------------------------------------------------------------------------------\nseu_kidney <- CreateSeuratObject(kidney.data)\nseu_kidney <- SCTransform(seu_kidney)\nseu_kidney <- RunPCA(seu_kidney)\nseu_kidney <- RunUMAP(seu_kidney, dims = 1:10)\n\n## pK Identification (no ground-truth) ---------------------------------------------------------------------------------------\nsweep.res.list_kidney <- paramSweep(seu_kidney, PCs = 1:10, sct = FALSE)\nsweep.stats_kidney <- summarizeSweep(sweep.res.list_kidney, GT = FALSE)\nbcmvn_kidney <- find.pK(sweep.stats_kidney)\n\n## pK Identification (ground-truth) ------------------------------------------------------------------------------------------\nsweep.res.list_kidney <- paramSweep(seu_kidney, PCs = 1:10, sct = FALSE)\ngt.calls <- seu_kidney@meta.data[rownames(sweep.res.list_kidney[[1]]), \"GT\"].   ## GT is a vector containing \"Singlet\" and \"Doublet\" calls recorded using sample multiplexing classification and/or in silico geneotyping results \nsweep.stats_kidney <- summarizeSweep(sweep.res.list_kidney, GT = TRUE, GT.calls = gt.calls)\nbcmvn_kidney <- find.pK(sweep.stats_kidney)\n\n## Homotypic Doublet Proportion Estimate -------------------------------------------------------------------------------------\nhomotypic.prop <- modelHomotypic(annotations)           ## ex: annotations <- seu_kidney@meta.data$ClusteringResults\nnExp_poi <- round(0.075*nrow(seu_kidney@meta.data))  ## Assuming 7.5% doublet formation rate - tailor for your dataset\nnExp_poi.adj <- round(nExp_poi*(1-homotypic.prop))\n\n## Run DoubletFinder with varying classification stringencies ----------------------------------------------------------------\nseu_kidney <- doubletFinder(seu_kidney, PCs = 1:10, pN = 0.25, pK = 0.09, nExp = nExp_poi, reuse.pANN = NULL, sct = FALSE)\nseu_kidney <- doubletFinder(seu_kidney, PCs = 1:10, pN = 0.25, pK = 0.09, nExp = nExp_poi.adj, reuse.pANN = \"pANN_0.25_0.09_913\", sct = FALSE)\n```\n\n![alternativetext](DF.screenshots/DFkidney_low.vs.high.png)\n\n## Other Doublet Detection Methods\n[Scrublet (Py)](https://github.com/AllonKleinLab/scrublet)\n[DoubletDecon (R)](https://github.com/EDePasquale/DoubletDecon)\n[DoubletDetection (Py)](https://github.com/JonathanShor/DoubletDetection)\n[Solo (Py)](https://github.com/calico/solo)\n[scds (R)](https://github.com/kostkalab/scds)\n[scDblFinder (R)](https://github.com/plger/scDblFinder)\n\n## References\n\n1.\tStoeckius M, Zheng S, Houck-Loomis B, Hao S, Yeung BZ, Smibert P, Satija R. Cell Hashing with barcoded antibodies enables multiplexing and doublet detection for single cell genomics. Genome Biology. 2018. 19:224.\n\n2.  Kang HM, Subramaniam M, Targ S, Nguyen M, Maliskova L, McCarthy E, Wan E, Wong S, Byrnes L, Lanata CM, Gate RE, Mostafavi S, Marson A, Zaitlen N, Criswell LA, Ye JC. Multiplexed droplet single-cell RNA-sequencing using natural genetic variation. Nature Biotechnology. 2018. 36(1):89-94. \n\n3.  Wolock SL, Lopez R, Klein AM. Scrublet: Computational Identification of Cell Doublets in Single-Cell Transcriptomic Data. Cell Systems. 2019. 8(4):281-291.e9.\n\n4.  Park J, Shrestha R, Qiu C, Kondo A, Huang S, Werth M, Li M, Barasch J, Suszt√°k K. Single-cell transcriptomics of the mouse kidney reveals potential cellular targets of kidney disease. Science. 2018. 360(6390):758-63.\n\n5.  Byrnes LE, Wong DM, Subramaniam M, Meyer NP, Gilchrist CL, Knox SM, Tward AD, Ye CJ, Sneddon JB. Lineage dynamics of murine pancreatic development at single-cell resolution. Nature Communications. 2018; 9:3922.\n\n6.  Bais AS, Kostka D. scds: computational annotation of doublets in single-cell RNA sequencing data. Bioinformatics. 2020. 36(4):1150-8.\n\n7.  Bernstein NJ, Fong NL, Lam I, Roy MA, Hendrickson DG, Kelley DR. Solo: Doublet Identification in Single-Cell RNA-Seq via Semi-Supervised Deep Learning. Cell Systems. 2020. S2405-4712(20)30195-2.\n\n8.  DePasquale EAK, Schnell DJ, Van Camp PJ, Valiente-Alandi I, Blaxall BC, Grimes HL, Singh H, Salomonis N. DoubletDecon: Deconvoluting Doublets from Single-Cell RNA-Sequencing Data. Cell Reports. 2019. 29(6):1718-27.e8.\n",
      "stars_today": 0
    },
    {
      "id": 50672978,
      "name": "gcam-core",
      "full_name": "JGCRI/gcam-core",
      "description": "GCAM -- The Global Change Analysis Model",
      "html_url": "https://github.com/JGCRI/gcam-core",
      "stars": 375,
      "forks": 203,
      "language": "R",
      "topics": [
        "climate",
        "coupled-human-natural-systems",
        "economics",
        "energy",
        "gcam",
        "human-earth-system",
        "integrated-assessment",
        "land",
        "water"
      ],
      "created_at": "2016-01-29T15:57:28Z",
      "updated_at": "2026-01-06T13:17:29Z",
      "pushed_at": "2025-12-12T20:56:28Z",
      "open_issues": 252,
      "owner": {
        "login": "JGCRI",
        "avatar_url": "https://avatars.githubusercontent.com/u/8431983?v=4"
      },
      "readme": "# Global Change Analysis Model (GCAM)\n\nThe Joint Global Change Research Institute (JGCRI) of the Pacific \nNorthwest National Laboratory (PNNL) is the home and primary \ndevelopment institution for GCAM, a multisector model for exploring \nconsequences of and responses to global to local changes and stressors. \nRegional energy, water, land, and economic systems are connected to the\nrest of the globe through trade and interactions with environmental systems.\nThese systems are also connected with each other.\nMultisector models such as GCAM capture these \ninterconnected impacts in an economic framework in order to explore \nthese dynamic interactions and feedbacks between regions and sectors.\n\nGCAM has been developed at PNNL-JGCRI for over 20 years and is a freely\navailable community model and documented online (See below). The team\nat JGCRI is comprised of physical scientists, engineers, economists, energy\nexperts, forest ecologists, agricultural scientists, and environmental system\nscientists who develop the model and apply it to a range of research questions.\nThe JGCRI team works closely with the developers of other Earth system and\necosystem models to integrate the effects of human actions modeled in GCAM\ninto their research.\n\n## Model Overview\n\nGCAM is a dynamic-recursive model with technology-rich representations\nof the economy, energy sector, land use, and water linked to a reduced complexity\nEarth system model that can be used to explore many science and decision-relevant\nquestions including the effects of changes in trade patterns, critical minerals\n& materials availability, and deployment of energy technologies on human and\nEarth systems. Regional population and labor productivity growth assumptions\ndrive the energy and land-use systems, employing numerous technology options to\nproduce, transform, and provide energy services, as well as to produce\nagriculture and forest products, and to determine land use and land cover.\nUsing a run period extending from 1990 ‚Äì 2100 (historical years through 2021)\nwith annual results computed at 1-5 year intervals, GCAM has been used to\nexplore the potential role of emerging energy supply technologies and\nthe consequences of specific measures or energy technology adoption, including\nbioenergy; critical minerals & materials; hydrogen systems; nuclear energy;\nrenewable energy technologies; carbon capture, storage, and utilization and\nenergy use technology in buildings, industry, and the transportation\nsectors. GCAM outputs include projections of future energy and critical mineral\nsupply, trade, and demand and the resulting radiative forcing and other effects\nof 16 greenhouse gases, aerosols, and short-lived species at 0.5√ó0.5 degree\nresolution, contingent on assumptions about future population, economy, technology,\ntrade and other polices.\n\n## Community guidelines for peer-reviewed journal articles using GCAM\n\nThis section outlines some suggested language which the GCAM user community \ncan employ to describe GCAM in papers in peer-reviewed journal articles,\nreports, or other public documents using GCAM or versions of GCAM. GCAM is\nunder continuous development. The suggested language for the opening paragraphs\nof a methodology or introduction section of a paper describing GCAM is as\nfollows:\n\n\"The Global Change Analysis Model (GCAM) is a multisector model developed and maintained at the Pacific Northwest National Laboratory‚Äôs Joint Global Change Research Institute (JGCRI, 2023) _\\<include additional citations to previous GCAM studies as relevant\\>_. GCAM is an open-source community model. In this study, we use GCAM v NN. The documentation of the model is available at the GCAM documentation page ([http://jgcri.github.io/gcam-doc](http://jgcri.github.io/gcam-doc)) and the description below is a summary. GCAM includes representations of: economy, energy, agriculture, and water supply in 32 geopolitical regions across the globe; their GHG and air pollutant emissions and global GHG concentrations, radiative forcing, and temperature change; and the associated land allocation, water use, and agriculture production across 396 land sub-regions and 235 water basins.  _\\<If using GCAM-USA, include without quotes: \"This study uses a U.S.-focused version of GCAM called GCAM-USA that includes representation of energy, economy, and water systems for the fifty states and the District of Columbia in addition to 31 regions outside of the United States.‚Äù\\>_. The version of GCAM used in this study is available ‚Äì along with full source code and instructions for use ‚Äì in a public repository _\\<include citation including link to the GCAM repository with doi used in paper\\>_. \n\nSubsequent paragraphs of the description might expound on particular capabilities, systems, or sectors of focus in the paper. Details in the GCAM documentation page can be used as a reference to develop these paragraphs.\n\nCommunity users of GCAM might also undertake their own model developments and/or assumptions for papers. It is recommended that these departures from the publicly available version of the model be clearly described. In addition, if these developments are substantial, we suggest making this clear by including an additional phrase (e.g. region name or name of institution) in the name of the model and explicitly calling it out in place of or immediately following the italicized portion in the above paragraphs. For example: _\"This study uses a modified version of GCAM/GCAM-USA called GCAM-\\<institution name\\>/GCAM-USA-\\<institution name\\>. GCAM-\\<institution name\\>/GCAM-USA-\\<institution name\\> incorporates additional details and modified assumptions from GCAM v NN as described subsequently\"_. \n\n## Documentation\n\n* [GCAM Documentation](http://jgcri.github.io/gcam-doc/)\n* [Getting Started with GCAM](http://jgcri.github.io/gcam-doc/user-guide.html)\n* [GCAM Community](https://gcims.pnnl.gov/community)\n* [GCAM Videos and Tutorial Slides](https://gcims.pnnl.gov/community)\n* [GCAM Citation and Co-authorship Guidelines](http://jgcri.github.io/gcam-doc/community-guide.html)\n\n## Selected Publications\n\nCalvin, K., Patel, P., Clarke, L., Asrar, G., Bond-Lamberty, B., Cui, R. Y., Di Vittorio, A., Dorheim, K., Edmonds, J., Hartin, C., Hejazi, M., Horowitz, R., Iyer, G., Kyle, P., Kim, S., Link, R., McJeon, H., Smith, S. J., Snyder, A., Waldhoff, S., and Wise, M.: GCAM v5.1: representing the linkages between energy, water, land, climate, and economic systems, Geosci. Model Dev., 12, 677‚Äì698, https://doi.org/10.5194/gmd-12-677-2019, 2019.\n\nEdmonds, J., and J. Reilly (1985)Global Energy: Assessing the Future (Oxford University Press, New York) pp.317.\n\nEdmonds, J., M. Wise, H. Pitcher, R. Richels, T. Wigley, and C. MacCracken. (1997) ‚ÄúAn Integrated Assessment of Climate Change and the Accelerated Introduction of Advanced Energy Technologies‚Äù, Mitigation and Adaptation Strategies for Global Change, 1, pp. 311-39\n\nKim, S.H., J. Edmonds, J. Lurz, S. J. Smith, and M. Wise (2006) ‚ÄúThe ObjECTS Framework for Integrated Assessment: Hybrid Modeling of Transportation ‚Äù Energy Journal (Special Issue #2) pp 51-80.\n\n[Full list of GCAM publications](http://jgcri.github.io/gcam-doc/references.html)\n",
      "stars_today": 0
    },
    {
      "id": 167440342,
      "name": "monocle3",
      "full_name": "cole-trapnell-lab/monocle3",
      "description": null,
      "html_url": "https://github.com/cole-trapnell-lab/monocle3",
      "stars": 430,
      "forks": 114,
      "language": "R",
      "topics": [
        "single-cell-rna-seq"
      ],
      "created_at": "2019-01-24T21:26:18Z",
      "updated_at": "2026-01-12T00:26:39Z",
      "pushed_at": "2026-01-08T18:32:17Z",
      "open_issues": 259,
      "owner": {
        "login": "cole-trapnell-lab",
        "avatar_url": "https://avatars.githubusercontent.com/u/8060918?v=4"
      },
      "readme": "MONOCLE 3\n=======================\n\nMonocle 3 is an analysis toolkit for single-cell RNA-Seq experiments.  To use this package, you will need the R statistical computing environment (version 3.0 or later) and several packages available through Bioconductor and CRAN.\n\nDetails on how to install and use Monocle 3 are available on our website:\n\nhttp://cole-trapnell-lab.github.io/monocle3/\n\n## Monocle3 with BPCells counts matrix support\n\nThis development branch version of Monocle3 adds the ability to store the counts matrix on-disk using the BPCells package. By default, Monocle3 stores the counts matrix in-memory as a sparse matrix, as in previous versions. In order to store the matrix on-disk, you must set the matrix_control list value `matrix_class=\"BPCells\"` in the affected commands. For example, to load a MatrixMarket file as an on-disk matrix, use the command\n\n```\ncds <- load_mm_data(mat_path=<path_to_mtx_file>,\n                    feature_anno_path=<path_to_feature_anno_file>,\n                    cell_anno_path=<path_to_cell_anno_file>,\n                    matrix_control=list(matrix_class='BPCells'))\n```\n\n### Install Monocle3 with BPCells\n\nYou must install BPCells from Github before you can install this Monocle3 version, and BPCells requires an HDF5 object library for installation. After installing the HDF5 library, you install BPCells using the command\n\n```\nremotes::install_github(\"bnprks/BPCells/r\")\n```\n\nThe [BPCells Github site](https://github.com/bnprks/BPCells)  has additional information.\n\nSome Linux distributions provide the HDF5 library as an option. The\nBPCells site has information about installing the HDF5 library on various operating systems.\n\nI used Homebrew to install an HDF5 library on MacOS. I seemed to need to install the pkg-config package as well, and add a pkg-config configuration file for HDF5. Homebrew installed pkg-config in '/opt/homebrew' so I added the hdf5.pc file in\n\n> /opt/homebrew/lib/pkgconfig/hdf5.pc\n\nwith the contents\n\n```\nprefix=/opt/homebrew/Cellar/hdf5/1.12.2_2\nexec_prefix=${prefix}\nincludedir=${prefix}/include\nlibdir=/opt/homebrew/Cellar/hdf5/1.12.2_2/lib\n  \nName: hdf5\nDescription: HDF5\nURL: xx\nVersion: 1.12.2_2\nCflags: -I${includedir}\nLibs: -L${libdir} -lhdf5\n```\n\nYou may need to update the version strings in your hdf5.pc file.\n\nMonocle3 no longer uses the terra package, so it does not need to be installed.\n\n### Notes\n\n- Monocle3 can use the BPCells package to store the feature-cell counts matrix on-disk rather than in-memory, which enables analysis of considerably larger data sets than before. By default, Monocle3 stores the counts matrix in-memory as a sparse matrix, as it has in the past. To store the counts matrix on-disk, use the parameter `matrix_control=list(matrix_class=\"BPCells\")` when you make the CDS or convert the counts matrix using one of the functions\n  - `load_mm_data()`\n  - `load_mtx_data()`\n  - `load_cellranger_data()`\n  - `load_a549()`\n  - `load_worm_embryo()`\n  - `load_worm_l2()`\n  - `convert_counts_matrix()`\n\n  For example, to convert a dgCMatrix counts matrix to a BPCells on-disk matrix in an existing CDS, use the command `cds <- convert_counts_matrix(cds, matrix_control=list(matrix_class=\"BPCells\"))`.\n- BPCells stores the count matrix information in directories with names similar to `monocle.bpcells.20230830.4c4b1bebe4b4.tmp`. Monocle3 tries to remove those directories when you quit R. Please do not remove them while Monocle3 is running because doing so eliminates the count matrix data. You *can* remove them after quitting R if Monocle3 fails to remove them.\n- The method `new_cell_data_set()` accepts a BPCells on-disk counts matrix.\n- The functions `save_monocle_objects()` and `load_monocle_objects()` store and load BPCells on-disk matrices when the CDS counts matrix is an on-disk BPCells matrix.\n- The Monocle3 `saveRDS()` function warns the user to use `save_monocle_objects()` when saving a CDS with a BPCells on-disk counts matrix. If you insist on using the `saveRDS()` function, the BPCells on-disk matrix directory will not be stored and you will be unable to load it with the `readRDS()` function.\n- The function `combine_cds()` combines CDSes with mixes of dgCMatrix and BPCells on-disk counts matrices into a BPCells on-disk counts matrix. When called with the `matrix_control=list(matrix_class=\"BPCells\")` parameter, `combine_cds()` combines CDSes with all dgCMatrix counts matrices into a BPCells on-disk counts matrix.\n- Note that when the counts matrix is stored as a BPCells on-disk matrix, the `new_cell_data_set()` method stores a second BPCells on-disk copy of the matrix in the CDS assays slot with the name `counts_row_order`. The `counts_row_order` matrix is used by Monocle3 when the counts matrix is accessed intensively by row. The reason is that, by default, BPCells stores the matrix as a one-dimensional vector in column-major order, as does R. As a result, column access is fast and row access is slow. We use BPCell's ability to also store and access matrices in row-major order, which gives fast row access. However, this means that the two copies of the counts matrix must have the same count values. If you replace or change the CDS's counts matrix, you must also update the `counts_row_order` matrix, which you can do using the function `set_cds_row_order_matrix()`.\n  - The CDS assays slot is a named list where the standard, column-major order, matrix is called `counts` and the BPCells row-major order matrix is called `counts_row_order`.\n  - The `counts` matrix getter and setter methods are `counts(cds)` and `counts(cds)<-`.\n  - The Monocle3 setter warns about re-setting the BPCells `counts_row_order` matrix, unless called with the parameter `bpcells_warn=FALSE`.\n  - The `counts_row_order` getter method is called `counts_row_order`.\n  - There is no corresponding `counts_row_order` setter method\n- By default, the BPCells on-disk matrix is stored in a directory that is created where R is started. You can change the directory location using the `matrix_path` value in the `matrix_control` parameter.\n- For more information about the `matrix_control` values, see the help document for the function `set_matrix_control()`.\n- I tested this version using BPCells counts matrices on the examples in the Monocle3 documentation although I did not try all of the plotting functions.\n\n",
      "stars_today": 0
    },
    {
      "id": 1070177613,
      "name": "AnyLanguageModel",
      "full_name": "mattt/AnyLanguageModel",
      "description": "An API-compatible, drop-in replacement for Apple's Foundation Models framework with support for custom language model providers.",
      "html_url": "https://github.com/mattt/AnyLanguageModel",
      "stars": 649,
      "forks": 45,
      "language": "Swift",
      "topics": [],
      "created_at": "2025-10-05T12:32:00Z",
      "updated_at": "2026-01-13T21:05:57Z",
      "pushed_at": "2026-01-05T17:03:39Z",
      "open_issues": 17,
      "owner": {
        "login": "mattt",
        "avatar_url": "https://avatars.githubusercontent.com/u/7659?v=4"
      },
      "readme": "# AnyLanguageModel\n\nA Swift package that provides a drop-in replacement for\n[Apple's Foundation Models framework](https://developer.apple.com/documentation/FoundationModels)\nwith support for custom language model providers.\nAll you need to do is change your import statement:\n\n```diff\n- import FoundationModels\n+ import AnyLanguageModel\n```\n\n```swift\nstruct WeatherTool: Tool {\n    let name = \"getWeather\"\n    let description = \"Retrieve the latest weather information for a city\"\n\n    @Generable\n    struct Arguments {\n        @Guide(description: \"The city to fetch the weather for\")\n        var city: String\n    }\n\n    func call(arguments: Arguments) async throws -> String {\n        \"The weather in \\(arguments.city) is sunny and 72¬∞F / 23¬∞C\"\n    }\n}\n\nlet model = SystemLanguageModel.default\nlet session = LanguageModelSession(model: model, tools: [WeatherTool()])\n\nlet response = try await session.respond {\n    Prompt(\"How's the weather in Cupertino?\")\n}\nprint(response.content)\n```\n\n## Features\n\n### Supported Providers\n\n- [x] [Apple Foundation Models](https://developer.apple.com/documentation/FoundationModels)\n- [x] [Core ML](https://developer.apple.com/documentation/coreml) models\n- [x] [MLX](https://github.com/ml-explore/mlx-swift) models\n- [x] [llama.cpp](https://github.com/ggml-org/llama.cpp) (GGUF models)\n- [x] Ollama [HTTP API](https://github.com/ollama/ollama/blob/main/docs/api.md)\n- [x] Anthropic [Messages API](https://docs.claude.com/en/api/messages)\n- [x] Google [Gemini API](https://ai.google.dev/api/generate-content)\n- [x] OpenAI [Chat Completions API](https://platform.openai.com/docs/api-reference/chat)\n- [x] OpenAI [Responses API](https://platform.openai.com/docs/api-reference/responses)\n\n## Requirements\n\n- Swift 6.1+\n- iOS 17.0+ / macOS 14.0+ / visionOS 1.0+ / Linux\n\n> [!IMPORTANT]\n> A bug in Xcode 26 may cause build errors\n> when targeting macOS 15 / iOS 18 or earlier\n> (e.g. `Conformance of 'String' to 'Generable' is only available in macOS 26.0 or newer`).\n> As a workaround, build your project with Xcode 16.\n> For more information, see [issue #15](https://github.com/mattt/AnyLanguageModel/issues/15).\n\n## Installation\n\nAdd this package to your `Package.swift`:\n\n```swift\ndependencies: [\n    .package(url: \"https://github.com/mattt/AnyLanguageModel\", from: \"0.5.0\")\n]\n```\n\n### Package Traits\n\nAnyLanguageModel uses [Swift 6.1 traits](https://docs.swift.org/swiftpm/documentation/packagemanagerdocs/packagetraits/)\nto conditionally include heavy dependencies,\nallowing you to opt-in only to the language model backends you need.\nThis results in smaller binary sizes and faster build times.\n\n**Available traits**:\n\n- `CoreML`: Enables Core ML model support\n  (depends on `huggingface/swift-transformers`)\n- `MLX`: Enables MLX model support\n  (depends on `ml-explore/mlx-swift-lm`)\n- `Llama`: Enables llama.cpp support\n  (requires `mattt/llama.swift`)\n\nBy default, no traits are enabled.\nTo enable specific traits, specify them in your package's dependencies:\n\n```swift\n// In your Package.swift\ndependencies: [\n    .package(\n        url: \"https://github.com/mattt/AnyLanguageModel.git\",\n        from: \"0.5.0\",\n        traits: [\"CoreML\", \"MLX\"] // Enable CoreML and MLX support\n    )\n]\n```\n\n### Using Traits in Xcode Projects\n\nXcode doesn't yet provide a built-in way to declare package dependencies with traits.\nAs a workaround,\nyou can create an internal Swift package that acts as a shim,\nexporting the `AnyLanguageModel` module with the desired traits enabled.\nYour Xcode project can then add this internal package as a local dependency.\n\nFor example,\nto use AnyLanguageModel with MLX support in an Xcode app project:\n\n**1. Create a local Swift package**\n(in root directory containing Xcode project):\n\n```shell\nmkdir -p Packages/MyAppKit\ncd Packages/MyAppKit\nswift package init\n```\n\n**2. Specify AnyLanguageModel package dependency**\n(in `Packages/MyAppKit/Package.swift`):\n\n```swift\n// swift-tools-version: 6.1\nimport PackageDescription\n\nlet package = Package(\n    name: \"MyAppKit\",\n    platforms: [\n        .macOS(.v14),\n        .iOS(.v17),\n        .visionOS(.v1),\n    ],\n    products: [\n        .library(\n            name: \"MyAppKit\",\n            targets: [\"MyAppKit\"]\n        )\n    ],\n    dependencies: [\n        .package(\n            url: \"https://github.com/mattt/AnyLanguageModel\",\n            from: \"0.4.0\",\n            traits: [\"MLX\"]\n        )\n    ],\n    targets: [\n        .target(\n            name: \"MyAppKit\",\n            dependencies: [\n                .product(name: \"AnyLanguageModel\", package: \"AnyLanguageModel\")\n            ]\n        )\n    ]\n)\n```\n\n**3. Export the AnyLanguageModel module**\n(in `Sources/MyAppKit/Export.swift`):\n\n```swift\n@_exported import AnyLanguageModel\n```\n\n**4. Add the local package to your Xcode project**:\n\nOpen your project settings,\nnavigate to the \"Package Dependencies\" tab,\nand click \"+\" ‚Üí \"Add Local...\" to select the `Packages/MyAppKit` directory.\n\nYour app can now import `AnyLanguageModel` with MLX support enabled.\n\n> [!TIP]\n> For a working example of package traits in an Xcode app project,\n> see [chat-ui-swift](https://github.com/mattt/chat-ui-swift).\n\n## API Credentials and Security\n\nWhen using third-party language model providers like OpenAI, Anthropic, or Google Gemini,\nyou must handle API credentials securely.\n\n> [!CAUTION]\n> **Never hardcode API credentials in your app**.\n> Malicious actors can reverse‚Äëengineer your application binary\n> or observe outgoing network requests\n> (for example, on a compromised device or via a debugging proxy)\n> to extract embedded credentials.\n> There have been documented cases of attackers successfully exfiltrating\n> API keys from mobile apps and racking up thousands of dollars in charges.\n\nHere are two approaches for managing API credentials in production apps:\n\n### Bring Your Own Key (BYO)\n\nUsers provide their own API keys,\nwhich are stored securely in the system Keychain\nand sent directly to the provider in API requests.\n\n**Security considerations**:\n\n- Keychain data is encrypted using hardware-backed keys\n  (protected by the Secure Enclave on supported devices)\n- An attacker would need access to a running process to intercept credentials\n- TLS encryption protects credentials in transit on the network\n- Users can only compromise their own keys, not other users' keys\n\n**Trade-offs**:\n\n- Apple App Review has often rejected apps using this model\n- Reviewers may be unable to test functionality ‚Äî even with provided credentials\n- Apple may require in-app purchase integration for usage credits\n- Some users may find it inconvenient to obtain and enter API keys\n\n### Proxy Server\n\nInstead of connecting directly to the provider,\nroute requests through your own authenticated service endpoint.\nAPI credentials are stored securely on your server,\nnever in the client app.\n\nAuthenticate users with [OAuth 2.1](https://oauth.net/2.1/) or similar,\nissuing short-lived, scoped bearer tokens for client requests.\nIf an attacker extracts tokens from your app,\nthey're limited in scope and expire automatically.\n\n**Security considerations**:\n\n- API keys never leave your server infrastructure\n- Client tokens can be scoped\n  (e.g., rate-limited, feature-restricted)\n- Client tokens can be revoked or expired independently\n- Compromised tokens have limited blast radius\n\n**Trade-offs**:\n\n- Additional infrastructure complexity\n  (server, authentication, monitoring)\n- Operational costs\n  (hosting, maintenance, support)\n- Network latency from additional hop\n\nFortunately, there are platforms and services that simplify proxy implementation,\nhandling authentication, rate limiting, and billing for you.\n\n> [!TIP]\n> For development and testing, it's fine to use API keys from environment variables.\n> Just make sure production builds use one of the secure approaches above.\n\nFor more information about security best practices for your app,\nsee OWASP's\n[Mobile Application Security Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Mobile_Application_Security_Cheat_Sheet.html).\n\n## Usage\n\n### Apple Foundation Models\n\nUses Apple's [system language model](https://developer.apple.com/documentation/FoundationModels)\n(requires macOS 26 / iOS 26 / visionOS 26 or later).\n\n```swift\nlet model = SystemLanguageModel.default\nlet session = LanguageModelSession(model: model)\n\nlet response = try await session.respond {\n    Prompt(\"Explain quantum computing in one sentence\")\n}\n```\n\n> [!NOTE]\n> Image inputs are not yet supported by Apple Foundation Models.\n\n### Core ML\n\nRun [Core ML](https://developer.apple.com/documentation/coreml) models\n(requires `CoreML` trait):\n\n```swift\nlet model = CoreMLLanguageModel(url: URL(fileURLWithPath: \"path/to/model.mlmodelc\"))\n\nlet session = LanguageModelSession(model: model)\nlet response = try await session.respond {\n    Prompt(\"Summarize this text\")\n}\n```\n\nEnable the trait in Package.swift:\n\n```swift\n.package(\n    url: \"https://github.com/mattt/AnyLanguageModel.git\",\n    branch: \"main\",\n    traits: [\"CoreML\"]\n)\n```\n\n> [!NOTE]\n> Image inputs are not currently supported with `CoreMLLanguageModel`.\n\n### MLX\n\nRun [MLX](https://github.com/ml-explore/mlx-swift) models on Apple Silicon\n(requires `MLX` trait):\n\n```swift\nlet model = MLXLanguageModel(modelId: \"mlx-community/Qwen3-0.6B-4bit\")\n\nlet session = LanguageModelSession(model: model)\nlet response = try await session.respond {\n    Prompt(\"What is the capital of France?\")\n}\n```\n\nVision support depends on the specific MLX model you load.\nUse a vision‚Äëcapable model for multimodal prompts\n(for example, a VLM variant).\nThe following shows extracting text from an image:\n\n```swift\nlet ocr = try await session.respond(\n    to: \"Extract the total amount from this receipt\",\n    images: [\n        .init(url: URL(fileURLWithPath: \"/path/to/receipt_page1.png\")),\n        .init(url: URL(fileURLWithPath: \"/path/to/receipt_page2.png\"))\n    ]\n)\nprint(ocr.content)\n```\n\nEnable the trait in Package.swift:\n\n```swift\n.package(\n    url: \"https://github.com/mattt/AnyLanguageModel.git\",\n    branch: \"main\",\n    traits: [\"MLX\"]\n)\n```\n\n### llama.cpp (GGUF)\n\nRun GGUF quantized models via [llama.cpp](https://github.com/ggml-org/llama.cpp)\n(requires `Llama` trait):\n\n```swift\nlet model = LlamaLanguageModel(modelPath: \"/path/to/model.gguf\")\n\nlet session = LanguageModelSession(model: model)\nlet response = try await session.respond {\n    Prompt(\"Translate 'hello world' to Spanish\")\n}\n```\n\nEnable the trait in Package.swift:\n\n```swift\n.package(\n    url: \"https://github.com/mattt/AnyLanguageModel.git\",\n    branch: \"main\",\n    traits: [\"Llama\"]\n)\n```\n\nConfiguration is done via custom generation options,\nallowing you to control runtime parameters per request:\n\n```swift\nvar options = GenerationOptions(temperature: 0.8)\noptions[custom: LlamaLanguageModel.self] = .init(\n    contextSize: 4096,        // Context window size\n    batchSize: 512,           // Batch size for evaluation\n    threads: 8,               // Number of threads\n    seed: 42,                 // Random seed for deterministic output\n    temperature: 0.7,         // Sampling temperature\n    topK: 40,                 // Top-K sampling\n    topP: 0.95,               // Top-P (nucleus) sampling\n    repeatPenalty: 1.2,       // Penalty for repeated tokens\n    repeatLastN: 128,         // Number of tokens to consider for repeat penalty\n    frequencyPenalty: 0.1,    // Frequency-based penalty\n    presencePenalty: 0.1,     // Presence-based penalty\n    mirostat: .v2(tau: 5.0, eta: 0.1)  // Adaptive perplexity control\n)\n\nlet response = try await session.respond(\n    to: \"Write a story\",\n    options: options\n)\n```\n\n> [!NOTE]\n> Image inputs are not currently supported with `LlamaLanguageModel`.\n\n### OpenAI\n\nSupports both\n[Chat Completions](https://platform.openai.com/docs/api-reference/chat) and\n[Responses](https://platform.openai.com/docs/api-reference/responses) APIs:\n\n```swift\nlet model = OpenAILanguageModel(\n    apiKey: ProcessInfo.processInfo.environment[\"OPENAI_API_KEY\"]!,\n    model: \"gpt-4o-mini\"\n)\n\nlet session = LanguageModelSession(model: model)\nlet response = try await session.respond(\n    to: \"List the objects you see\",\n    images: [\n        .init(url: URL(string: \"https://example.com/desk.jpg\")!),\n        .init(\n            data: try Data(contentsOf: URL(fileURLWithPath: \"/path/to/closeup.png\")),\n            mimeType: \"image/png\"\n        )\n    ]\n)\nprint(response.content)\n```\n\nFor OpenAI-compatible endpoints that use older Chat Completions API:\n\n```swift\nlet model = OpenAILanguageModel(\n    baseURL: URL(string: \"https://api.example.com\")!,\n    apiKey: apiKey,\n    model: \"gpt-4o-mini\",\n    apiVariant: .chatCompletions\n)\n```\n\nUse custom generation options for advanced parameters like sampling controls,\nreasoning effort (for o-series models), and vendor-specific extensions:\n\n```swift\nvar options = GenerationOptions(temperature: 0.8)\noptions[custom: OpenAILanguageModel.self] = .init(\n    topP: 0.9,\n    frequencyPenalty: 0.5,\n    presencePenalty: 0.3,\n    stopSequences: [\"END\"],\n    reasoningEffort: .high,        // For reasoning models (o3, o4-mini)\n    serviceTier: .priority,\n    extraBody: [                   // Vendor-specific parameters\n        \"custom_param\": .string(\"value\")\n    ]\n)\n```\n\n### Anthropic\n\nUses the [Messages API](https://docs.claude.com/en/api/messages) with Claude models:\n\n```swift\nlet model = AnthropicLanguageModel(\n    apiKey: ProcessInfo.processInfo.environment[\"ANTHROPIC_API_KEY\"]!,\n    model: \"claude-sonnet-4-5-20250929\"\n)\n\nlet session = LanguageModelSession(model: model, tools: [WeatherTool()])\nlet response = try await session.respond {\n    Prompt(\"What's the weather like in San Francisco?\")\n}\n```\n\nYou can include images with your prompt.\nYou can point to remote URLs or construct from image data:\n\n```swift\nlet response = try await session.respond(\n    to: \"Explain the key parts of this diagram\",\n    image: .init(\n        data: try Data(contentsOf: URL(fileURLWithPath: \"/path/to/diagram.png\")),\n        mimeType: \"image/png\"\n    )\n)\nprint(response.content)\n```\n\nUse custom generation options for Anthropic-specific parameters like\nextended thinking, tool choice control, and sampling parameters:\n\n```swift\nvar options = GenerationOptions(temperature: 0.7)\noptions[custom: AnthropicLanguageModel.self] = .init(\n    topP: 0.9,\n    topK: 40,\n    stopSequences: [\"END\", \"STOP\"],\n    thinking: .init(budgetTokens: 4096),  // Extended thinking\n    toolChoice: .auto,                     // Tool selection control\n    serviceTier: .priority\n)\n```\n\n### Google Gemini\n\nUses the [Gemini API](https://ai.google.dev/api/generate-content) with Gemini models:\n\n```swift\nlet model = GeminiLanguageModel(\n    apiKey: ProcessInfo.processInfo.environment[\"GEMINI_API_KEY\"]!,\n    model: \"gemini-2.5-flash\"\n)\n\nlet session = LanguageModelSession(model: model, tools: [WeatherTool()])\nlet response = try await session.respond {\n    Prompt(\"What's the weather like in Tokyo?\")\n}\n```\n\nSend images with your prompt using remote or local sources:\n\n```swift\nlet response = try await session.respond(\n    to: \"Identify the plants in this photo\",\n    image: .init(url: URL(string: \"https://example.com/garden.jpg\")!)\n)\nprint(response.content)\n```\n\nGemini models use an internal [\"thinking process\"](https://ai.google.dev/gemini-api/docs/thinking)\nthat improves reasoning and multi-step planning.\nConfigure thinking mode through custom generation options:\n\n```swift\nvar options = GenerationOptions()\n\n// Enable thinking with dynamic budget allocation\noptions[custom: GeminiLanguageModel.self] = .init(thinking: .dynamic)\n\n// Or set an explicit number of tokens for its thinking budget\noptions[custom: GeminiLanguageModel.self] = .init(thinking: .budget(1024))\n\n// Disable thinking (default)\noptions[custom: GeminiLanguageModel.self] = .init(thinking: .disabled)\n\nlet response = try await session.respond(to: \"Solve this problem\", options: options)\n```\n\nGemini supports [server-side tools](https://ai.google.dev/gemini-api/docs/google-search)\nthat execute transparently on Google's infrastructure:\n\n```swift\nvar options = GenerationOptions()\noptions[custom: GeminiLanguageModel.self] = .init(\n    serverTools: [\n        .googleSearch,\n        .googleMaps(latitude: 35.6580, longitude: 139.7016)\n    ]\n)\n\nlet response = try await session.respond(\n    to: \"What coffee shops are nearby?\",\n    options: options\n)\n```\n\n**Available server tools**:\n\n- `.googleSearch`\n  Grounds responses with real-time web information\n- `.googleMaps`\n  Provides location-aware responses\n- `.codeExecution`\n  Generates and runs Python code to solve problems\n- `.urlContext`\n  Fetches and analyzes content from URLs mentioned in prompts\n\n> [!TIP]\n> Gemini server tools are not available as client tools (`Tool`) for other models.\n\n### Ollama\n\nRun models locally via Ollama's\n[HTTP API](https://github.com/ollama/ollama/blob/main/docs/api.md):\n\n```swift\n// Default: connects to http://localhost:11434\nlet model = OllamaLanguageModel(model: \"qwen3\") // `ollama pull qwen3:8b`\n\n// Custom endpoint\nlet model = OllamaLanguageModel(\n    endpoint: URL(string: \"http://remote-server:11434\")!,\n    model: \"llama3.2\"\n)\n\nlet session = LanguageModelSession(model: model)\nlet response = try await session.respond {\n    Prompt(\"Tell me a joke\")\n}\n```\n\nFor local models, make sure you're using a vision‚Äëcapable model\n(for example, a `-vl` variant).\nYou can combine multiple images:\n\n```swift\nlet model = OllamaLanguageModel(model: \"qwen3-vl\") // `ollama pull qwen3-vl:8b`\nlet session = LanguageModelSession(model: model)\nlet response = try await session.respond(\n    to: \"Compare these posters and summarize their differences\",\n    images: [\n        .init(url: URL(string: \"https://example.com/poster1.jpg\")!),\n        .init(url: URL(fileURLWithPath: \"/path/to/poster2.jpg\"))\n    ]\n)\nprint(response.content)\n```\n\nPass any model-specific parameters using custom generation options:\n\n```swift\nvar options = GenerationOptions(temperature: 0.8)\noptions[custom: OllamaLanguageModel.self] = [\n    \"seed\": .int(42),\n    \"repeat_penalty\": .double(1.2),\n    \"num_ctx\": .int(4096),\n    \"stop\": .array([.string(\"###\")])\n]\n```\n\n## Testing\n\nRun the test suite to verify everything works correctly:\n\n```bash\nswift test\n```\n\nTests for different language model backends have varying requirements:\n\n| Backend | Traits | Environment Variables |\n|---------|--------|----------------------|\n| CoreML | `CoreML` | `HF_TOKEN` |\n| MLX | `MLX` | `HF_TOKEN` |\n| Llama | `Llama` | `LLAMA_MODEL_PATH` |\n| Anthropic | ‚Äî | `ANTHROPIC_API_KEY` |\n| OpenAI | ‚Äî | `OPENAI_API_KEY` |\n| Ollama | ‚Äî | ‚Äî |\n\nExample setup for running multiple tests at once:\n\n```bash\nexport HF_TOKEN=your_huggingface_token\nexport LLAMA_MODEL_PATH=/path/to/model.gguf\nexport ANTHROPIC_API_KEY=your_anthropic_key\nexport OPENAI_API_KEY=your_openai_key\n\nswift test --traits CoreML,Llama\n```\n\n> [!TIP]\n> Tests that perform generation are skipped in CI environments (when `CI` is set).\n> Override this by setting `ENABLE_COREML_TESTS=1` or `ENABLE_MLX_TESTS=1`.\n\n> [!NOTE]\n> MLX tests must be run with `xcodebuild` rather than `swift test`\n> due to Metal library loading requirements.\n> Since `xcodebuild` doesn't support package traits directly,\n> you'll first need to update `Package.swift` to enable the MLX trait by default.\n>\n> ```diff\n> - .default(enabledTraits: []),\n> + .default(enabledTraits: [\"MLX\"]),\n> ```\n> \n> Pass environment variables with `TEST_RUNNER_` prefix:\n>\n> ```bash\n> export TEST_RUNNER_HF_TOKEN=your_huggingface_token\n> xcodebuild test \\\n>   -scheme AnyLanguageModel \\\n>   -destination 'platform=macOS' \\\n>   -only-testing:AnyLanguageModelTests/MLXLanguageModelTests\n> ```\n\n## License\n\nThis project is available under the MIT license.\nSee the LICENSE file for more info.\n",
      "stars_today": 0
    },
    {
      "id": 185880527,
      "name": "signac",
      "full_name": "stuart-lab/signac",
      "description": "R toolkit for the analysis of single-cell chromatin data",
      "html_url": "https://github.com/stuart-lab/signac",
      "stars": 400,
      "forks": 102,
      "language": "R",
      "topics": [
        "atac",
        "bioinformatics",
        "single-cell"
      ],
      "created_at": "2019-05-09T22:32:26Z",
      "updated_at": "2026-01-10T20:34:16Z",
      "pushed_at": "2025-12-11T05:17:49Z",
      "open_issues": 19,
      "owner": {
        "login": "stuart-lab",
        "avatar_url": "https://avatars.githubusercontent.com/u/102445397?v=4"
      },
      "readme": "# Signac <img align=\"right\" src=\"man/figures/logo.svg\" style=\"height:100px;\" />\n\n[![R-CMD-check](https://github.com/stuart-lab/signac/workflows/R-CMD-check/badge.svg)](https://github.com/stuart-lab/signac/actions)\n[![CRAN\nVersion](https://www.r-pkg.org/badges/version/Signac)](https://cran.r-project.org/package=Signac)\n[![CRAN\nDownloads](https://cranlogs.r-pkg.org/badges/Signac)](https://cran.r-project.org/package=Signac)\n\n## Overview\n\nSignac is a comprehensive R package for the analysis of single-cell\nchromatin data. Signac includes functions for quality control,\nnormalization, dimension reduction, clustering, differential activity,\nand more.\n\nDocumentation and tutorials can be found at\n<https://stuartlab.org/signac/>\n\n## Installation\n\nTo install the latest release of Signac from CRAN:\n\n``` r\nsetRepositories(ind=1:3) # needed to automatically install Bioconductor dependencies\ninstall.packages(\"Signac\")\n```\n\nTo release the latest develop version from GitHub:\n\n``` r\nif (!requireNamespace(\"remotes\", quietly = TRUE))\n    install.packages(\"remotes\")\nremotes::install_github(\"stuart-lab/signac\", ref = \"develop\")\n```\n\n## Release notes\n\nFor a changelog please see the [NEWS\nfile](https://github.com/stuart-lab/signac/blob/develop/NEWS.md), also\navailable on the [Signac\nwebsite](https://stuartlab.org/signac/news/index.html).\n\n## Contributing\n\nWe welcome contributions to the Signac package. Please see the\n[contribution guide](https://github.com/stuart-lab/signac/blob/develop/CONTRIBUTING.md)\nfor more information.\n\n## Getting help\n\nIf you encounter a bug or have a feature request, please open an\n[issue](https://github.com/stuart-lab/signac/issues).\n\nIf you would like to discuss questions related to single-cell analysis,\nyou can open a\n[discussion](https://github.com/stuart-lab/signac/discussions).\n\n## Citing Signac\n\nIf you use the Signac package in your work please cite [Stuart et\nal. 2021](https://doi.org/10.1038/s41592-021-01282-5)\n\n```\n@ARTICLE{signac,\n  title     = \"Single-cell chromatin state analysis with Signac\",\n  author    = \"Stuart, Tim and Srivastava, Avi and Madad, Shaista and Lareau,\n               Caleb A and Satija, Rahul\",\n  journal   = \"Nat. Methods\",\n  publisher = \"Nature Publishing Group\",\n  pages     = \"1--9\",\n  month     =  nov,\n  year      =  2021,\n  url       = \"https://www.nature.com/articles/s41592-021-01282-5\",\n  language  = \"en\"\n}\n```\n\n## Related packages\n\n-   [Seurat](https://github.com/satijalab/seurat)\n-   [SeuratObject](https://github.com/satijalab/seurat-object)\n-   [SeuratDisk](https://github.com/mojaveazure/seurat-disk)\n-   [SeuratData](https://github.com/satijalab/seurat-data)\n-   [SeuratWrappers](https://github.com/satijalab/seurat-wrappers)\n-   [Azimuth](https://github.com/satijalab/azimuth)\n",
      "stars_today": 0
    },
    {
      "id": 452908115,
      "name": "nflverse-data",
      "full_name": "nflverse/nflverse-data",
      "description": "Automated nflverse data repository",
      "html_url": "https://github.com/nflverse/nflverse-data",
      "stars": 324,
      "forks": 33,
      "language": "R",
      "topics": [],
      "created_at": "2022-01-28T02:01:18Z",
      "updated_at": "2026-01-11T19:19:29Z",
      "pushed_at": "2026-01-01T03:28:54Z",
      "open_issues": 5,
      "owner": {
        "login": "nflverse",
        "avatar_url": "https://avatars.githubusercontent.com/u/79467114?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# nflverse-data\n\n<!-- badges: start -->\n<!-- badges: end -->\n\nThis repository holds automated data releases for nflverse projects\n(i.e.¬†all of the data powered/scraped via GitHub Actions).\n\n## Usage\n\nYou can download data hosted here with the `{nflreadr}` package, or\nmanually download and access the\n[releases](https://github.com/nflverse/nflverse-data/releases) page.\nReleases are roughly organized along the [main\nfunctions](https://nflreadr.nflverse.com/reference/) of nflreadr.\n\n## Automation Status\n\nPlease see https://nflreadr.nflverse.com/articles/nflverse_data_schedule.html#automation-status for the status table. \n",
      "stars_today": 0
    },
    {
      "id": 308437751,
      "name": "tree-sitter-r",
      "full_name": "r-lib/tree-sitter-r",
      "description": "Tree-sitter grammar for R",
      "html_url": "https://github.com/r-lib/tree-sitter-r",
      "stars": 123,
      "forks": 37,
      "language": "R",
      "topics": [],
      "created_at": "2020-10-29T20:06:05Z",
      "updated_at": "2025-12-29T20:00:02Z",
      "pushed_at": "2025-09-16T20:52:48Z",
      "open_issues": 16,
      "owner": {
        "login": "r-lib",
        "avatar_url": "https://avatars.githubusercontent.com/u/22618716?v=4"
      },
      "readme": "# tree-sitter-r\n\nAn R grammar for [tree-sitter](https://github.com/tree-sitter/tree-sitter).\n\n## R package\n\nThis grammar is available as an [R package](https://cran.r-project.org/web/packages/treesitter.r/index.html).\n\nYou'll also want the [R package providing bindings to tree-sitter](https://davisvaughan.github.io/r-tree-sitter/) itself.\n\n## Rust bindings\n\nThis grammar is available as a [Rust crate on crates.io](https://crates.io/crates/tree-sitter-r).\n\n## Node bindings\n\nThis grammar is available as an [npm package](https://www.npmjs.com/package/@davisvaughan/tree-sitter-r).\n\nNote that it is currently listed as a scoped package under the name `@davisvaughan/tree-sitter-r`.\nWe are working with the npm team to gain ownership of the `tree-sitter-r` package.\nOnce that happens, we will move the npm package there instead.\n\n## References\n\n- [The R Draft Spec](https://cran.r-project.org/doc/manuals/r-release/R-lang.pdf)\n- [gram.y](https://github.com/wch/r-source/blob/trunk/src/main/gram.y)\n\n## Known deviations\n\nThis section describes known deviations from the R grammar.\n\n### `]]` as a literal token\n\nThe following is valid R syntax, note how `]]` has been split over multiple lines.\n\n```r\nx[[\"a\"]\n]\n```\n\nThis applies to `]]`, but not to `[[`, for example, this is not valid R syntax:\n\n```r\nx[\n[\"a\"]]\n```\n\nThe technical reason for this is that [in the grammar](https://github.com/wch/r-source/blob/988774e05497bcf2cfac47bfbec59d551432e3fb/src/main/gram.y#L508) R treats `[[` as a single token, but `]]` is treated as two individual `]` tokens.\nTreating `]]` as two individual `]` tokens allows whitespace, newlines, and even comments to appear between the two `]` tokens:\n\n```r\nx[[\"a\"] # comment\n]\n```\n\nWhile we'd like to precisely support the R grammar, it is also extremely useful to treat all of `(`, `)`, `[`, `]`, `[[`, and `]]` as literal tokens when using the tree-sitter grammar.\nThis allows you to treat call, subset, and subset2 nodes in the same way, since they all have exactly the same node structure.\n\nBecause treating `]]` as a literal token is so useful, and because we've never seen any R code \"in the wild\" written this way, this grammar does not allow whitespace, newlines, or comments between the two `]` tokens.\n",
      "stars_today": 0
    }
  ],
  "created_at": "2026-01-14T01:08:16.397107802Z"
}